; ModuleID = 'binary/test.mcsema.inline.ll'
source_filename = "llvm-link"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu-elf"

%union.anon = type { i64 }
%seg_404070__rodata_type = type <{ [24 x i8], [88 x i8], [45 x i8], [7 x i8] }>
%seg_604df0__init_array_type = type <{ i64, i64 }>
%seg_604ff0__got_type = type <{ i64, i64 }>
%__bss_start_type = type <{ [8 x i8] }>
%struct.State = type { %struct.ArchState, [32 x %union.VectorReg], %struct.ArithFlags, %union.anon, %struct.Segments, %struct.AddressSpace, %struct.GPR, %struct.X87Stack, %struct.MMX, %struct.FPUStatusFlags, %union.anon, %union.FPU, %struct.SegmentCaches }
%struct.ArchState = type { i32, i32, %union.anon }
%union.VectorReg = type { %union.vec512_t }
%union.vec512_t = type { %struct.uint64v8_t }
%struct.uint64v8_t = type { [8 x i64] }
%struct.ArithFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8 }
%struct.Segments = type { i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector }
%union.SegmentSelector = type { i16 }
%struct.AddressSpace = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.Reg = type { %union.anon }
%struct.GPR = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.X87Stack = type { [8 x %struct.anon.3] }
%struct.anon.3 = type { i64, double }
%struct.MMX = type { [8 x %struct.anon.4] }
%struct.anon.4 = type { i64, %union.vec64_t }
%union.vec64_t = type { %struct.uint64v1_t }
%struct.uint64v1_t = type { [1 x i64] }
%struct.FPUStatusFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, [4 x i8] }
%union.FPU = type { %struct.anon.13 }
%struct.anon.13 = type { %struct.FpuFXSAVE, [96 x i8] }
%struct.FpuFXSAVE = type { %union.SegmentSelector, %union.SegmentSelector, %union.FPUAbridgedTagWord, i8, i16, i32, %union.SegmentSelector, i16, i32, %union.SegmentSelector, i16, %union.FPUControlStatus, %union.FPUControlStatus, [8 x %struct.FPUStackElem], [16 x %union.vec128_t] }
%union.FPUAbridgedTagWord = type { i8 }
%union.FPUControlStatus = type { i32 }
%struct.FPUStackElem = type { %union.anon.11, [6 x i8] }
%union.anon.11 = type { %struct.float80_t }
%struct.float80_t = type { [10 x i8] }
%union.vec128_t = type { %struct.uint128v1_t }
%struct.uint128v1_t = type { [1 x i128] }
%struct.SegmentCaches = type { %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow }
%struct.SegmentShadow = type { %union.anon, i32, i32 }
%struct.Memory = type opaque
%struct.anon.2 = type { i8, i8 }
%"class.std::bitset" = type { %struct.uint64v4_t }
%struct.uint64v4_t = type { [4 x i64] }

@DR0 = external global i64, align 8
@DR1 = external global i64, align 8
@DR2 = external global i64, align 8
@DR3 = external global i64, align 8
@DR4 = external global i64, align 8
@DR5 = external global i64, align 8
@DR6 = external global i64, align 8
@DR7 = external global i64, align 8
@gCR0 = external global %union.anon, align 1
@gCR1 = external global %union.anon, align 1
@gCR2 = external global %union.anon, align 1
@gCR3 = external global %union.anon, align 1
@gCR4 = external global %union.anon, align 1
@gCR8 = external global %union.anon, align 1
@seg_404070__rodata = internal constant %seg_404070__rodata_type <{ [24 x i8] c"\01\00\02\00\00\00\00\00\BB\BD\D7\D9\DF|\DB=\00\00\00\00\00\00P?", [88 x i8] c"\00\00\00\00\00\00\90@\00\00\00\00\00\00\10@\00\00\00\00\00\00\E0C\95\D6&\E8\0B.\11>\8D\ED\B5\A0\F7\C6\B0>\00\00\00\00\00\00\F0?q\8B\89\C0\85.\D0>\00\00\00\00\00\00\00@\00\00\00\00\00\00\00\00\FF\FF\FF\FF\FF\FF\FF\7F\FF\FF\FF\FF\FF\FF\FF\7F", [45 x i8] c"FFT sanity check failed! Difference is: %le\0A\00", [7 x i8] c"%e %e\0A\00" }>
@seg_604df0__init_array = internal global %seg_604df0__init_array_type <{ i64 ptrtoint (void ()* @callback_sub_4007f0_frame_dummy to i64), i64 ptrtoint (void ()* @callback_sub_4007c0___do_global_dtors_aux to i64) }>
@seg_604ff0__got = internal global %seg_604ff0__got_type <{ i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64)* @__libc_start_main to i64), i64 ptrtoint (i64 ()* @__gmon_start__ to i64) }>
@__bss_start = global %__bss_start_type zeroinitializer
@0 = internal global i1 false
@1 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_4007f0_frame_dummy_wrapper
@2 = internal constant void ()* @__mcsema_attach_call
@3 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_4007c0___do_global_dtors_aux_wrapper
@4 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_404060___libc_csu_fini_wrapper
@5 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_403ff0___libc_csu_init_wrapper
@6 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @main_wrapper
@7 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @errorcheck_wrapper
@8 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @.term_proc_wrapper
@9 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @get_time_wrapper
@10 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @makewt_wrapper
@11 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @.init_proc_wrapper
@12 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @cdft_wrapper
@13 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @putdata_wrapper
@llvm.global_ctors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 101, void ()* @__mcsema_constructor, i8* null }]
@llvm.global_dtors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 101, void ()* @__mcsema_destructor, i8* null }]

declare %struct.Memory* @sub_400de0_get_time_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_403300_cftmdl_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_402870_cft1st_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401840_cftfsub_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4011c0_bitrv2_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400750_deregister_tm_clones_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400e30_makewt_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_402480_cftbsub_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400fb0_putdata_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401030_cdft_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400638__init_proc_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4010d0_errorcheck_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401be0_bitrv2conj_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

; Function Attrs: nounwind readnone
declare i32 @llvm.ctpop.i32(i32) #0

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_error(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #1

; Function Attrs: nounwind readnone
declare double @llvm.fabs.f64(double) #0

; Function Attrs: nounwind readnone
declare double @llvm.trunc.f64(double) #0

; Function Attrs: nounwind readnone
declare double @sqrt(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @cos(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @sin(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @atan(double) local_unnamed_addr #2

; Function Attrs: noinline nounwind optnone
define %struct.Memory* @__remill_basic_block(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #3 !dbg !1261 {
  %state = alloca %struct.State*, align 8
  %curr_pc = alloca i64, align 8
  %memory = alloca %struct.Memory*, align 8
  %BRANCH_TAKEN = alloca i8, align 1
  %SS_BASE = alloca i64, align 8
  %ES_BASE = alloca i64, align 8
  %DS_BASE = alloca i64, align 8
  %CS_BASE = alloca i64, align 8
  %STATE = alloca %struct.State*, align 8
  %MEMORY = alloca %struct.Memory*, align 8
  %_DR0 = alloca i64*, align 8
  %_DR1 = alloca i64*, align 8
  %_DR2 = alloca i64*, align 8
  %_DR3 = alloca i64*, align 8
  %_DR4 = alloca i64*, align 8
  %_DR5 = alloca i64*, align 8
  %_DR6 = alloca i64*, align 8
  %_DR7 = alloca i64*, align 8
  %CR0 = alloca i64*, align 8
  %CR1 = alloca i64*, align 8
  %CR2 = alloca i64*, align 8
  %CR3 = alloca i64*, align 8
  %CR4 = alloca i64*, align 8
  %CR8 = alloca i64*, align 8
  store %struct.State* %0, %struct.State** %state, align 8
  store i64 %1, i64* %curr_pc, align 8
  store %struct.Memory* %2, %struct.Memory** %memory, align 8
  store i8 0, i8* %BRANCH_TAKEN, align 1, !dbg !1952
  store i64 0, i64* %SS_BASE, align 8, !dbg !1953
  store i64 0, i64* %ES_BASE, align 8, !dbg !1954
  store i64 0, i64* %DS_BASE, align 8, !dbg !1955
  store i64 0, i64* %CS_BASE, align 8, !dbg !1956
  store %struct.State* %0, %struct.State** %STATE, align 8, !dbg !1957
  store %struct.Memory* %2, %struct.Memory** %MEMORY, align 8, !dbg !1958
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1959
  %5 = getelementptr inbounds %struct.GPR, %struct.GPR* %4, i32 0, i32 33, !dbg !1960
  %6 = getelementptr inbounds %struct.Reg, %struct.Reg* %5, i32 0, i32 0, !dbg !1961
  %PC = bitcast %union.anon* %6 to i64*, !dbg !1961
  store i64 %1, i64* %PC, align 8, !dbg !1962
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1963
  %8 = getelementptr inbounds %struct.GPR, %struct.GPR* %7, i32 0, i32 1, !dbg !1964
  %9 = getelementptr inbounds %struct.Reg, %struct.Reg* %8, i32 0, i32 0, !dbg !1965
  %10 = bitcast %union.anon* %9 to %struct.anon.2*, !dbg !1965
  %AH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %10, i32 0, i32 1, !dbg !1966
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1967
  %12 = getelementptr inbounds %struct.GPR, %struct.GPR* %11, i32 0, i32 3, !dbg !1968
  %13 = getelementptr inbounds %struct.Reg, %struct.Reg* %12, i32 0, i32 0, !dbg !1969
  %14 = bitcast %union.anon* %13 to %struct.anon.2*, !dbg !1969
  %BH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %14, i32 0, i32 1, !dbg !1970
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1971
  %16 = getelementptr inbounds %struct.GPR, %struct.GPR* %15, i32 0, i32 5, !dbg !1972
  %17 = getelementptr inbounds %struct.Reg, %struct.Reg* %16, i32 0, i32 0, !dbg !1973
  %18 = bitcast %union.anon* %17 to %struct.anon.2*, !dbg !1973
  %CH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %18, i32 0, i32 1, !dbg !1974
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1975
  %20 = getelementptr inbounds %struct.GPR, %struct.GPR* %19, i32 0, i32 7, !dbg !1976
  %21 = getelementptr inbounds %struct.Reg, %struct.Reg* %20, i32 0, i32 0, !dbg !1977
  %22 = bitcast %union.anon* %21 to %struct.anon.2*, !dbg !1977
  %DH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %22, i32 0, i32 1, !dbg !1978
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1979
  %24 = getelementptr inbounds %struct.GPR, %struct.GPR* %23, i32 0, i32 1, !dbg !1980
  %25 = getelementptr inbounds %struct.Reg, %struct.Reg* %24, i32 0, i32 0, !dbg !1981
  %26 = bitcast %union.anon* %25 to %struct.anon.2*, !dbg !1981
  %AL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %26, i32 0, i32 0, !dbg !1982
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1983
  %28 = getelementptr inbounds %struct.GPR, %struct.GPR* %27, i32 0, i32 3, !dbg !1984
  %29 = getelementptr inbounds %struct.Reg, %struct.Reg* %28, i32 0, i32 0, !dbg !1985
  %30 = bitcast %union.anon* %29 to %struct.anon.2*, !dbg !1985
  %BL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %30, i32 0, i32 0, !dbg !1986
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1987
  %32 = getelementptr inbounds %struct.GPR, %struct.GPR* %31, i32 0, i32 5, !dbg !1988
  %33 = getelementptr inbounds %struct.Reg, %struct.Reg* %32, i32 0, i32 0, !dbg !1989
  %34 = bitcast %union.anon* %33 to %struct.anon.2*, !dbg !1989
  %CL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %34, i32 0, i32 0, !dbg !1990
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1991
  %36 = getelementptr inbounds %struct.GPR, %struct.GPR* %35, i32 0, i32 7, !dbg !1992
  %37 = getelementptr inbounds %struct.Reg, %struct.Reg* %36, i32 0, i32 0, !dbg !1993
  %38 = bitcast %union.anon* %37 to %struct.anon.2*, !dbg !1993
  %DL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %38, i32 0, i32 0, !dbg !1994
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1995
  %40 = getelementptr inbounds %struct.GPR, %struct.GPR* %39, i32 0, i32 9, !dbg !1996
  %41 = getelementptr inbounds %struct.Reg, %struct.Reg* %40, i32 0, i32 0, !dbg !1997
  %42 = bitcast %union.anon* %41 to %struct.anon.2*, !dbg !1997
  %SIL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %42, i32 0, i32 0, !dbg !1998
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1999
  %44 = getelementptr inbounds %struct.GPR, %struct.GPR* %43, i32 0, i32 11, !dbg !2000
  %45 = getelementptr inbounds %struct.Reg, %struct.Reg* %44, i32 0, i32 0, !dbg !2001
  %46 = bitcast %union.anon* %45 to %struct.anon.2*, !dbg !2001
  %DIL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %46, i32 0, i32 0, !dbg !2002
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2003
  %48 = getelementptr inbounds %struct.GPR, %struct.GPR* %47, i32 0, i32 13, !dbg !2004
  %49 = getelementptr inbounds %struct.Reg, %struct.Reg* %48, i32 0, i32 0, !dbg !2005
  %50 = bitcast %union.anon* %49 to %struct.anon.2*, !dbg !2005
  %SPL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %50, i32 0, i32 0, !dbg !2006
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2007
  %52 = getelementptr inbounds %struct.GPR, %struct.GPR* %51, i32 0, i32 15, !dbg !2008
  %53 = getelementptr inbounds %struct.Reg, %struct.Reg* %52, i32 0, i32 0, !dbg !2009
  %54 = bitcast %union.anon* %53 to %struct.anon.2*, !dbg !2009
  %BPL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %54, i32 0, i32 0, !dbg !2010
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2011
  %56 = getelementptr inbounds %struct.GPR, %struct.GPR* %55, i32 0, i32 17, !dbg !2012
  %57 = getelementptr inbounds %struct.Reg, %struct.Reg* %56, i32 0, i32 0, !dbg !2013
  %58 = bitcast %union.anon* %57 to %struct.anon.2*, !dbg !2013
  %R8B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %58, i32 0, i32 0, !dbg !2014
  %59 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2015
  %60 = getelementptr inbounds %struct.GPR, %struct.GPR* %59, i32 0, i32 19, !dbg !2016
  %61 = getelementptr inbounds %struct.Reg, %struct.Reg* %60, i32 0, i32 0, !dbg !2017
  %62 = bitcast %union.anon* %61 to %struct.anon.2*, !dbg !2017
  %R9B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %62, i32 0, i32 0, !dbg !2018
  %63 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2019
  %64 = getelementptr inbounds %struct.GPR, %struct.GPR* %63, i32 0, i32 21, !dbg !2020
  %65 = getelementptr inbounds %struct.Reg, %struct.Reg* %64, i32 0, i32 0, !dbg !2021
  %66 = bitcast %union.anon* %65 to %struct.anon.2*, !dbg !2021
  %R10B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %66, i32 0, i32 0, !dbg !2022
  %67 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2023
  %68 = getelementptr inbounds %struct.GPR, %struct.GPR* %67, i32 0, i32 23, !dbg !2024
  %69 = getelementptr inbounds %struct.Reg, %struct.Reg* %68, i32 0, i32 0, !dbg !2025
  %70 = bitcast %union.anon* %69 to %struct.anon.2*, !dbg !2025
  %R11B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %70, i32 0, i32 0, !dbg !2026
  %71 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2027
  %72 = getelementptr inbounds %struct.GPR, %struct.GPR* %71, i32 0, i32 25, !dbg !2028
  %73 = getelementptr inbounds %struct.Reg, %struct.Reg* %72, i32 0, i32 0, !dbg !2029
  %74 = bitcast %union.anon* %73 to %struct.anon.2*, !dbg !2029
  %R12B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %74, i32 0, i32 0, !dbg !2030
  %75 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2031
  %76 = getelementptr inbounds %struct.GPR, %struct.GPR* %75, i32 0, i32 27, !dbg !2032
  %77 = getelementptr inbounds %struct.Reg, %struct.Reg* %76, i32 0, i32 0, !dbg !2033
  %78 = bitcast %union.anon* %77 to %struct.anon.2*, !dbg !2033
  %R13B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %78, i32 0, i32 0, !dbg !2034
  %79 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2035
  %80 = getelementptr inbounds %struct.GPR, %struct.GPR* %79, i32 0, i32 29, !dbg !2036
  %81 = getelementptr inbounds %struct.Reg, %struct.Reg* %80, i32 0, i32 0, !dbg !2037
  %82 = bitcast %union.anon* %81 to %struct.anon.2*, !dbg !2037
  %R14B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %82, i32 0, i32 0, !dbg !2038
  %83 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2039
  %84 = getelementptr inbounds %struct.GPR, %struct.GPR* %83, i32 0, i32 31, !dbg !2040
  %85 = getelementptr inbounds %struct.Reg, %struct.Reg* %84, i32 0, i32 0, !dbg !2041
  %86 = bitcast %union.anon* %85 to %struct.anon.2*, !dbg !2041
  %R15B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %86, i32 0, i32 0, !dbg !2042
  %87 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2043
  %88 = getelementptr inbounds %struct.GPR, %struct.GPR* %87, i32 0, i32 1, !dbg !2044
  %89 = getelementptr inbounds %struct.Reg, %struct.Reg* %88, i32 0, i32 0, !dbg !2045
  %AX = bitcast %union.anon* %89 to i16*, !dbg !2045
  %90 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2046
  %91 = getelementptr inbounds %struct.GPR, %struct.GPR* %90, i32 0, i32 3, !dbg !2047
  %92 = getelementptr inbounds %struct.Reg, %struct.Reg* %91, i32 0, i32 0, !dbg !2048
  %BX = bitcast %union.anon* %92 to i16*, !dbg !2048
  %93 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2049
  %94 = getelementptr inbounds %struct.GPR, %struct.GPR* %93, i32 0, i32 5, !dbg !2050
  %95 = getelementptr inbounds %struct.Reg, %struct.Reg* %94, i32 0, i32 0, !dbg !2051
  %CX = bitcast %union.anon* %95 to i16*, !dbg !2051
  %96 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2052
  %97 = getelementptr inbounds %struct.GPR, %struct.GPR* %96, i32 0, i32 7, !dbg !2053
  %98 = getelementptr inbounds %struct.Reg, %struct.Reg* %97, i32 0, i32 0, !dbg !2054
  %DX = bitcast %union.anon* %98 to i16*, !dbg !2054
  %99 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2055
  %100 = getelementptr inbounds %struct.GPR, %struct.GPR* %99, i32 0, i32 9, !dbg !2056
  %101 = getelementptr inbounds %struct.Reg, %struct.Reg* %100, i32 0, i32 0, !dbg !2057
  %SI = bitcast %union.anon* %101 to i16*, !dbg !2057
  %102 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2058
  %103 = getelementptr inbounds %struct.GPR, %struct.GPR* %102, i32 0, i32 11, !dbg !2059
  %104 = getelementptr inbounds %struct.Reg, %struct.Reg* %103, i32 0, i32 0, !dbg !2060
  %DI = bitcast %union.anon* %104 to i16*, !dbg !2060
  %105 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2061
  %106 = getelementptr inbounds %struct.GPR, %struct.GPR* %105, i32 0, i32 13, !dbg !2062
  %107 = getelementptr inbounds %struct.Reg, %struct.Reg* %106, i32 0, i32 0, !dbg !2063
  %SP = bitcast %union.anon* %107 to i16*, !dbg !2063
  %108 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2064
  %109 = getelementptr inbounds %struct.GPR, %struct.GPR* %108, i32 0, i32 15, !dbg !2065
  %110 = getelementptr inbounds %struct.Reg, %struct.Reg* %109, i32 0, i32 0, !dbg !2066
  %BP = bitcast %union.anon* %110 to i16*, !dbg !2066
  %111 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2067
  %112 = getelementptr inbounds %struct.GPR, %struct.GPR* %111, i32 0, i32 17, !dbg !2068
  %113 = getelementptr inbounds %struct.Reg, %struct.Reg* %112, i32 0, i32 0, !dbg !2069
  %R8W = bitcast %union.anon* %113 to i16*, !dbg !2069
  %114 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2070
  %115 = getelementptr inbounds %struct.GPR, %struct.GPR* %114, i32 0, i32 19, !dbg !2071
  %116 = getelementptr inbounds %struct.Reg, %struct.Reg* %115, i32 0, i32 0, !dbg !2072
  %R9W = bitcast %union.anon* %116 to i16*, !dbg !2072
  %117 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2073
  %118 = getelementptr inbounds %struct.GPR, %struct.GPR* %117, i32 0, i32 21, !dbg !2074
  %119 = getelementptr inbounds %struct.Reg, %struct.Reg* %118, i32 0, i32 0, !dbg !2075
  %R10W = bitcast %union.anon* %119 to i16*, !dbg !2075
  %120 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2076
  %121 = getelementptr inbounds %struct.GPR, %struct.GPR* %120, i32 0, i32 23, !dbg !2077
  %122 = getelementptr inbounds %struct.Reg, %struct.Reg* %121, i32 0, i32 0, !dbg !2078
  %R11W = bitcast %union.anon* %122 to i16*, !dbg !2078
  %123 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2079
  %124 = getelementptr inbounds %struct.GPR, %struct.GPR* %123, i32 0, i32 25, !dbg !2080
  %125 = getelementptr inbounds %struct.Reg, %struct.Reg* %124, i32 0, i32 0, !dbg !2081
  %R12W = bitcast %union.anon* %125 to i16*, !dbg !2081
  %126 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2082
  %127 = getelementptr inbounds %struct.GPR, %struct.GPR* %126, i32 0, i32 27, !dbg !2083
  %128 = getelementptr inbounds %struct.Reg, %struct.Reg* %127, i32 0, i32 0, !dbg !2084
  %R13W = bitcast %union.anon* %128 to i16*, !dbg !2084
  %129 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2085
  %130 = getelementptr inbounds %struct.GPR, %struct.GPR* %129, i32 0, i32 29, !dbg !2086
  %131 = getelementptr inbounds %struct.Reg, %struct.Reg* %130, i32 0, i32 0, !dbg !2087
  %R14W = bitcast %union.anon* %131 to i16*, !dbg !2087
  %132 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2088
  %133 = getelementptr inbounds %struct.GPR, %struct.GPR* %132, i32 0, i32 31, !dbg !2089
  %134 = getelementptr inbounds %struct.Reg, %struct.Reg* %133, i32 0, i32 0, !dbg !2090
  %R15W = bitcast %union.anon* %134 to i16*, !dbg !2090
  %135 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2091
  %136 = getelementptr inbounds %struct.GPR, %struct.GPR* %135, i32 0, i32 33, !dbg !2092
  %137 = getelementptr inbounds %struct.Reg, %struct.Reg* %136, i32 0, i32 0, !dbg !2093
  %IP = bitcast %union.anon* %137 to i16*, !dbg !2093
  %138 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2094
  %139 = getelementptr inbounds %struct.GPR, %struct.GPR* %138, i32 0, i32 1, !dbg !2095
  %140 = getelementptr inbounds %struct.Reg, %struct.Reg* %139, i32 0, i32 0, !dbg !2096
  %EAX = bitcast %union.anon* %140 to i32*, !dbg !2096
  %141 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2097
  %142 = getelementptr inbounds %struct.GPR, %struct.GPR* %141, i32 0, i32 3, !dbg !2098
  %143 = getelementptr inbounds %struct.Reg, %struct.Reg* %142, i32 0, i32 0, !dbg !2099
  %EBX = bitcast %union.anon* %143 to i32*, !dbg !2099
  %144 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2100
  %145 = getelementptr inbounds %struct.GPR, %struct.GPR* %144, i32 0, i32 5, !dbg !2101
  %146 = getelementptr inbounds %struct.Reg, %struct.Reg* %145, i32 0, i32 0, !dbg !2102
  %ECX = bitcast %union.anon* %146 to i32*, !dbg !2102
  %147 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2103
  %148 = getelementptr inbounds %struct.GPR, %struct.GPR* %147, i32 0, i32 7, !dbg !2104
  %149 = getelementptr inbounds %struct.Reg, %struct.Reg* %148, i32 0, i32 0, !dbg !2105
  %EDX = bitcast %union.anon* %149 to i32*, !dbg !2105
  %150 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2106
  %151 = getelementptr inbounds %struct.GPR, %struct.GPR* %150, i32 0, i32 9, !dbg !2107
  %152 = getelementptr inbounds %struct.Reg, %struct.Reg* %151, i32 0, i32 0, !dbg !2108
  %ESI = bitcast %union.anon* %152 to i32*, !dbg !2108
  %153 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2109
  %154 = getelementptr inbounds %struct.GPR, %struct.GPR* %153, i32 0, i32 11, !dbg !2110
  %155 = getelementptr inbounds %struct.Reg, %struct.Reg* %154, i32 0, i32 0, !dbg !2111
  %EDI = bitcast %union.anon* %155 to i32*, !dbg !2111
  %156 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2112
  %157 = getelementptr inbounds %struct.GPR, %struct.GPR* %156, i32 0, i32 13, !dbg !2113
  %158 = getelementptr inbounds %struct.Reg, %struct.Reg* %157, i32 0, i32 0, !dbg !2114
  %ESP = bitcast %union.anon* %158 to i32*, !dbg !2114
  %159 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2115
  %160 = getelementptr inbounds %struct.GPR, %struct.GPR* %159, i32 0, i32 15, !dbg !2116
  %161 = getelementptr inbounds %struct.Reg, %struct.Reg* %160, i32 0, i32 0, !dbg !2117
  %EBP = bitcast %union.anon* %161 to i32*, !dbg !2117
  %162 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2118
  %163 = getelementptr inbounds %struct.GPR, %struct.GPR* %162, i32 0, i32 33, !dbg !2119
  %164 = getelementptr inbounds %struct.Reg, %struct.Reg* %163, i32 0, i32 0, !dbg !2120
  %EIP = bitcast %union.anon* %164 to i32*, !dbg !2120
  %165 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2121
  %166 = getelementptr inbounds %struct.GPR, %struct.GPR* %165, i32 0, i32 17, !dbg !2122
  %167 = getelementptr inbounds %struct.Reg, %struct.Reg* %166, i32 0, i32 0, !dbg !2123
  %R8D = bitcast %union.anon* %167 to i32*, !dbg !2123
  %168 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2124
  %169 = getelementptr inbounds %struct.GPR, %struct.GPR* %168, i32 0, i32 19, !dbg !2125
  %170 = getelementptr inbounds %struct.Reg, %struct.Reg* %169, i32 0, i32 0, !dbg !2126
  %R9D = bitcast %union.anon* %170 to i32*, !dbg !2126
  %171 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2127
  %172 = getelementptr inbounds %struct.GPR, %struct.GPR* %171, i32 0, i32 21, !dbg !2128
  %173 = getelementptr inbounds %struct.Reg, %struct.Reg* %172, i32 0, i32 0, !dbg !2129
  %R10D = bitcast %union.anon* %173 to i32*, !dbg !2129
  %174 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2130
  %175 = getelementptr inbounds %struct.GPR, %struct.GPR* %174, i32 0, i32 23, !dbg !2131
  %176 = getelementptr inbounds %struct.Reg, %struct.Reg* %175, i32 0, i32 0, !dbg !2132
  %R11D = bitcast %union.anon* %176 to i32*, !dbg !2132
  %177 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2133
  %178 = getelementptr inbounds %struct.GPR, %struct.GPR* %177, i32 0, i32 25, !dbg !2134
  %179 = getelementptr inbounds %struct.Reg, %struct.Reg* %178, i32 0, i32 0, !dbg !2135
  %R12D = bitcast %union.anon* %179 to i32*, !dbg !2135
  %180 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2136
  %181 = getelementptr inbounds %struct.GPR, %struct.GPR* %180, i32 0, i32 27, !dbg !2137
  %182 = getelementptr inbounds %struct.Reg, %struct.Reg* %181, i32 0, i32 0, !dbg !2138
  %R13D = bitcast %union.anon* %182 to i32*, !dbg !2138
  %183 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2139
  %184 = getelementptr inbounds %struct.GPR, %struct.GPR* %183, i32 0, i32 29, !dbg !2140
  %185 = getelementptr inbounds %struct.Reg, %struct.Reg* %184, i32 0, i32 0, !dbg !2141
  %R14D = bitcast %union.anon* %185 to i32*, !dbg !2141
  %186 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2142
  %187 = getelementptr inbounds %struct.GPR, %struct.GPR* %186, i32 0, i32 31, !dbg !2143
  %188 = getelementptr inbounds %struct.Reg, %struct.Reg* %187, i32 0, i32 0, !dbg !2144
  %R15D = bitcast %union.anon* %188 to i32*, !dbg !2144
  %189 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2145
  %190 = getelementptr inbounds %struct.GPR, %struct.GPR* %189, i32 0, i32 1, !dbg !2146
  %191 = getelementptr inbounds %struct.Reg, %struct.Reg* %190, i32 0, i32 0, !dbg !2147
  %RAX = bitcast %union.anon* %191 to i64*, !dbg !2147
  %192 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2148
  %193 = getelementptr inbounds %struct.GPR, %struct.GPR* %192, i32 0, i32 3, !dbg !2149
  %194 = getelementptr inbounds %struct.Reg, %struct.Reg* %193, i32 0, i32 0, !dbg !2150
  %RBX = bitcast %union.anon* %194 to i64*, !dbg !2150
  %195 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2151
  %196 = getelementptr inbounds %struct.GPR, %struct.GPR* %195, i32 0, i32 5, !dbg !2152
  %197 = getelementptr inbounds %struct.Reg, %struct.Reg* %196, i32 0, i32 0, !dbg !2153
  %RCX = bitcast %union.anon* %197 to i64*, !dbg !2153
  %198 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2154
  %199 = getelementptr inbounds %struct.GPR, %struct.GPR* %198, i32 0, i32 7, !dbg !2155
  %200 = getelementptr inbounds %struct.Reg, %struct.Reg* %199, i32 0, i32 0, !dbg !2156
  %RDX = bitcast %union.anon* %200 to i64*, !dbg !2156
  %201 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2157
  %202 = getelementptr inbounds %struct.GPR, %struct.GPR* %201, i32 0, i32 9, !dbg !2158
  %203 = getelementptr inbounds %struct.Reg, %struct.Reg* %202, i32 0, i32 0, !dbg !2159
  %RSI = bitcast %union.anon* %203 to i64*, !dbg !2159
  %204 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2160
  %205 = getelementptr inbounds %struct.GPR, %struct.GPR* %204, i32 0, i32 11, !dbg !2161
  %206 = getelementptr inbounds %struct.Reg, %struct.Reg* %205, i32 0, i32 0, !dbg !2162
  %RDI = bitcast %union.anon* %206 to i64*, !dbg !2162
  %207 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2163
  %208 = getelementptr inbounds %struct.GPR, %struct.GPR* %207, i32 0, i32 13, !dbg !2164
  %209 = getelementptr inbounds %struct.Reg, %struct.Reg* %208, i32 0, i32 0, !dbg !2165
  %RSP = bitcast %union.anon* %209 to i64*, !dbg !2165
  %210 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2166
  %211 = getelementptr inbounds %struct.GPR, %struct.GPR* %210, i32 0, i32 15, !dbg !2167
  %212 = getelementptr inbounds %struct.Reg, %struct.Reg* %211, i32 0, i32 0, !dbg !2168
  %RBP = bitcast %union.anon* %212 to i64*, !dbg !2168
  %213 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2169
  %214 = getelementptr inbounds %struct.GPR, %struct.GPR* %213, i32 0, i32 17, !dbg !2170
  %215 = getelementptr inbounds %struct.Reg, %struct.Reg* %214, i32 0, i32 0, !dbg !2171
  %R8 = bitcast %union.anon* %215 to i64*, !dbg !2171
  %216 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2172
  %217 = getelementptr inbounds %struct.GPR, %struct.GPR* %216, i32 0, i32 19, !dbg !2173
  %218 = getelementptr inbounds %struct.Reg, %struct.Reg* %217, i32 0, i32 0, !dbg !2174
  %R9 = bitcast %union.anon* %218 to i64*, !dbg !2174
  %219 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2175
  %220 = getelementptr inbounds %struct.GPR, %struct.GPR* %219, i32 0, i32 21, !dbg !2176
  %221 = getelementptr inbounds %struct.Reg, %struct.Reg* %220, i32 0, i32 0, !dbg !2177
  %R10 = bitcast %union.anon* %221 to i64*, !dbg !2177
  %222 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2178
  %223 = getelementptr inbounds %struct.GPR, %struct.GPR* %222, i32 0, i32 23, !dbg !2179
  %224 = getelementptr inbounds %struct.Reg, %struct.Reg* %223, i32 0, i32 0, !dbg !2180
  %R11 = bitcast %union.anon* %224 to i64*, !dbg !2180
  %225 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2181
  %226 = getelementptr inbounds %struct.GPR, %struct.GPR* %225, i32 0, i32 25, !dbg !2182
  %227 = getelementptr inbounds %struct.Reg, %struct.Reg* %226, i32 0, i32 0, !dbg !2183
  %R12 = bitcast %union.anon* %227 to i64*, !dbg !2183
  %228 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2184
  %229 = getelementptr inbounds %struct.GPR, %struct.GPR* %228, i32 0, i32 27, !dbg !2185
  %230 = getelementptr inbounds %struct.Reg, %struct.Reg* %229, i32 0, i32 0, !dbg !2186
  %R13 = bitcast %union.anon* %230 to i64*, !dbg !2186
  %231 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2187
  %232 = getelementptr inbounds %struct.GPR, %struct.GPR* %231, i32 0, i32 29, !dbg !2188
  %233 = getelementptr inbounds %struct.Reg, %struct.Reg* %232, i32 0, i32 0, !dbg !2189
  %R14 = bitcast %union.anon* %233 to i64*, !dbg !2189
  %234 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2190
  %235 = getelementptr inbounds %struct.GPR, %struct.GPR* %234, i32 0, i32 31, !dbg !2191
  %236 = getelementptr inbounds %struct.Reg, %struct.Reg* %235, i32 0, i32 0, !dbg !2192
  %R15 = bitcast %union.anon* %236 to i64*, !dbg !2192
  %237 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2193
  %238 = getelementptr inbounds %struct.GPR, %struct.GPR* %237, i32 0, i32 33, !dbg !2194
  %239 = getelementptr inbounds %struct.Reg, %struct.Reg* %238, i32 0, i32 0, !dbg !2195
  %RIP = bitcast %union.anon* %239 to i64*, !dbg !2195
  %240 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2196
  %241 = getelementptr inbounds %struct.Segments, %struct.Segments* %240, i32 0, i32 1, !dbg !2197
  %SS = bitcast %union.SegmentSelector* %241 to i16*, !dbg !2198
  %242 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2199
  %243 = getelementptr inbounds %struct.Segments, %struct.Segments* %242, i32 0, i32 3, !dbg !2200
  %ES = bitcast %union.SegmentSelector* %243 to i16*, !dbg !2201
  %244 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2202
  %245 = getelementptr inbounds %struct.Segments, %struct.Segments* %244, i32 0, i32 5, !dbg !2203
  %GS = bitcast %union.SegmentSelector* %245 to i16*, !dbg !2204
  %246 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2205
  %247 = getelementptr inbounds %struct.Segments, %struct.Segments* %246, i32 0, i32 7, !dbg !2206
  %FS = bitcast %union.SegmentSelector* %247 to i16*, !dbg !2207
  %248 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2208
  %249 = getelementptr inbounds %struct.Segments, %struct.Segments* %248, i32 0, i32 9, !dbg !2209
  %DS = bitcast %union.SegmentSelector* %249 to i16*, !dbg !2210
  %250 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2211
  %251 = getelementptr inbounds %struct.Segments, %struct.Segments* %250, i32 0, i32 11, !dbg !2212
  %CS = bitcast %union.SegmentSelector* %251 to i16*, !dbg !2213
  %252 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 5, !dbg !2214
  %253 = getelementptr inbounds %struct.AddressSpace, %struct.AddressSpace* %252, i32 0, i32 5, !dbg !2215
  %254 = getelementptr inbounds %struct.Reg, %struct.Reg* %253, i32 0, i32 0, !dbg !2216
  %GS_BASE = bitcast %union.anon* %254 to i64*, !dbg !2216
  %255 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 5, !dbg !2217
  %256 = getelementptr inbounds %struct.AddressSpace, %struct.AddressSpace* %255, i32 0, i32 7, !dbg !2218
  %257 = getelementptr inbounds %struct.Reg, %struct.Reg* %256, i32 0, i32 0, !dbg !2219
  %FS_BASE = bitcast %union.anon* %257 to i64*, !dbg !2219
  %258 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2220
  %259 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %258, i64 0, i64 0, !dbg !2221
  %YMM0 = bitcast %union.VectorReg* %259 to %"class.std::bitset"*, !dbg !2222
  %260 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2223
  %261 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %260, i64 0, i64 1, !dbg !2224
  %YMM1 = bitcast %union.VectorReg* %261 to %"class.std::bitset"*, !dbg !2225
  %262 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2226
  %263 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %262, i64 0, i64 2, !dbg !2227
  %YMM2 = bitcast %union.VectorReg* %263 to %"class.std::bitset"*, !dbg !2228
  %264 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2229
  %265 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %264, i64 0, i64 3, !dbg !2230
  %YMM3 = bitcast %union.VectorReg* %265 to %"class.std::bitset"*, !dbg !2231
  %266 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2232
  %267 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %266, i64 0, i64 4, !dbg !2233
  %YMM4 = bitcast %union.VectorReg* %267 to %"class.std::bitset"*, !dbg !2234
  %268 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2235
  %269 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %268, i64 0, i64 5, !dbg !2236
  %YMM5 = bitcast %union.VectorReg* %269 to %"class.std::bitset"*, !dbg !2237
  %270 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2238
  %271 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %270, i64 0, i64 6, !dbg !2239
  %YMM6 = bitcast %union.VectorReg* %271 to %"class.std::bitset"*, !dbg !2240
  %272 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2241
  %273 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %272, i64 0, i64 7, !dbg !2242
  %YMM7 = bitcast %union.VectorReg* %273 to %"class.std::bitset"*, !dbg !2243
  %274 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2244
  %275 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %274, i64 0, i64 8, !dbg !2245
  %YMM8 = bitcast %union.VectorReg* %275 to %"class.std::bitset"*, !dbg !2246
  %276 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2247
  %277 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %276, i64 0, i64 9, !dbg !2248
  %YMM9 = bitcast %union.VectorReg* %277 to %"class.std::bitset"*, !dbg !2249
  %278 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2250
  %279 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %278, i64 0, i64 10, !dbg !2251
  %YMM10 = bitcast %union.VectorReg* %279 to %"class.std::bitset"*, !dbg !2252
  %280 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2253
  %281 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %280, i64 0, i64 11, !dbg !2254
  %YMM11 = bitcast %union.VectorReg* %281 to %"class.std::bitset"*, !dbg !2255
  %282 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2256
  %283 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %282, i64 0, i64 12, !dbg !2257
  %YMM12 = bitcast %union.VectorReg* %283 to %"class.std::bitset"*, !dbg !2258
  %284 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2259
  %285 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %284, i64 0, i64 13, !dbg !2260
  %YMM13 = bitcast %union.VectorReg* %285 to %"class.std::bitset"*, !dbg !2261
  %286 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2262
  %287 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %286, i64 0, i64 14, !dbg !2263
  %YMM14 = bitcast %union.VectorReg* %287 to %"class.std::bitset"*, !dbg !2264
  %288 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2265
  %289 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %288, i64 0, i64 15, !dbg !2266
  %YMM15 = bitcast %union.VectorReg* %289 to %"class.std::bitset"*, !dbg !2267
  %290 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2268
  %291 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %290, i64 0, i64 0, !dbg !2269
  %XMM0 = bitcast %union.VectorReg* %291 to %union.vec128_t*, !dbg !2270
  %292 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2271
  %293 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %292, i64 0, i64 1, !dbg !2272
  %XMM1 = bitcast %union.VectorReg* %293 to %union.vec128_t*, !dbg !2273
  %294 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2274
  %295 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %294, i64 0, i64 2, !dbg !2275
  %XMM2 = bitcast %union.VectorReg* %295 to %union.vec128_t*, !dbg !2276
  %296 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2277
  %297 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %296, i64 0, i64 3, !dbg !2278
  %XMM3 = bitcast %union.VectorReg* %297 to %union.vec128_t*, !dbg !2279
  %298 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2280
  %299 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %298, i64 0, i64 4, !dbg !2281
  %XMM4 = bitcast %union.VectorReg* %299 to %union.vec128_t*, !dbg !2282
  %300 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2283
  %301 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %300, i64 0, i64 5, !dbg !2284
  %XMM5 = bitcast %union.VectorReg* %301 to %union.vec128_t*, !dbg !2285
  %302 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2286
  %303 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %302, i64 0, i64 6, !dbg !2287
  %XMM6 = bitcast %union.VectorReg* %303 to %union.vec128_t*, !dbg !2288
  %304 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2289
  %305 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %304, i64 0, i64 7, !dbg !2290
  %XMM7 = bitcast %union.VectorReg* %305 to %union.vec128_t*, !dbg !2291
  %306 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2292
  %307 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %306, i64 0, i64 8, !dbg !2293
  %XMM8 = bitcast %union.VectorReg* %307 to %union.vec128_t*, !dbg !2294
  %308 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2295
  %309 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %308, i64 0, i64 9, !dbg !2296
  %XMM9 = bitcast %union.VectorReg* %309 to %union.vec128_t*, !dbg !2297
  %310 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2298
  %311 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %310, i64 0, i64 10, !dbg !2299
  %XMM10 = bitcast %union.VectorReg* %311 to %union.vec128_t*, !dbg !2300
  %312 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2301
  %313 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %312, i64 0, i64 11, !dbg !2302
  %XMM11 = bitcast %union.VectorReg* %313 to %union.vec128_t*, !dbg !2303
  %314 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2304
  %315 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %314, i64 0, i64 12, !dbg !2305
  %XMM12 = bitcast %union.VectorReg* %315 to %union.vec128_t*, !dbg !2306
  %316 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2307
  %317 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %316, i64 0, i64 13, !dbg !2308
  %XMM13 = bitcast %union.VectorReg* %317 to %union.vec128_t*, !dbg !2309
  %318 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2310
  %319 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %318, i64 0, i64 14, !dbg !2311
  %XMM14 = bitcast %union.VectorReg* %319 to %union.vec128_t*, !dbg !2312
  %320 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2313
  %321 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %320, i64 0, i64 15, !dbg !2314
  %XMM15 = bitcast %union.VectorReg* %321 to %union.vec128_t*, !dbg !2315
  %322 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2316
  %323 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %322, i32 0, i32 0, !dbg !2317
  %324 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %323, i64 0, i64 0, !dbg !2318
  %ST0 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %324, i32 0, i32 1, !dbg !2319
  %325 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2320
  %326 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %325, i32 0, i32 0, !dbg !2321
  %327 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %326, i64 0, i64 1, !dbg !2322
  %ST1 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %327, i32 0, i32 1, !dbg !2323
  %328 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2324
  %329 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %328, i32 0, i32 0, !dbg !2325
  %330 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %329, i64 0, i64 2, !dbg !2326
  %ST2 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %330, i32 0, i32 1, !dbg !2327
  %331 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2328
  %332 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %331, i32 0, i32 0, !dbg !2329
  %333 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %332, i64 0, i64 3, !dbg !2330
  %ST3 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %333, i32 0, i32 1, !dbg !2331
  %334 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2332
  %335 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %334, i32 0, i32 0, !dbg !2333
  %336 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %335, i64 0, i64 4, !dbg !2334
  %ST4 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %336, i32 0, i32 1, !dbg !2335
  %337 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2336
  %338 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %337, i32 0, i32 0, !dbg !2337
  %339 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %338, i64 0, i64 5, !dbg !2338
  %ST5 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %339, i32 0, i32 1, !dbg !2339
  %340 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2340
  %341 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %340, i32 0, i32 0, !dbg !2341
  %342 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %341, i64 0, i64 6, !dbg !2342
  %ST6 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %342, i32 0, i32 1, !dbg !2343
  %343 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2344
  %344 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %343, i32 0, i32 0, !dbg !2345
  %345 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %344, i64 0, i64 7, !dbg !2346
  %ST7 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %345, i32 0, i32 1, !dbg !2347
  %346 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2348
  %347 = getelementptr inbounds %struct.MMX, %struct.MMX* %346, i32 0, i32 0, !dbg !2349
  %348 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %347, i64 0, i64 0, !dbg !2350
  %349 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %348, i32 0, i32 1, !dbg !2351
  %350 = bitcast %union.vec64_t* %349 to %struct.uint64v1_t*, !dbg !2352
  %351 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %350, i32 0, i32 0, !dbg !2353
  %MM0 = getelementptr inbounds [1 x i64], [1 x i64]* %351, i64 0, i64 0, !dbg !2350
  %352 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2354
  %353 = getelementptr inbounds %struct.MMX, %struct.MMX* %352, i32 0, i32 0, !dbg !2355
  %354 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %353, i64 0, i64 1, !dbg !2356
  %355 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %354, i32 0, i32 1, !dbg !2357
  %356 = bitcast %union.vec64_t* %355 to %struct.uint64v1_t*, !dbg !2358
  %357 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %356, i32 0, i32 0, !dbg !2359
  %MM1 = getelementptr inbounds [1 x i64], [1 x i64]* %357, i64 0, i64 0, !dbg !2356
  %358 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2360
  %359 = getelementptr inbounds %struct.MMX, %struct.MMX* %358, i32 0, i32 0, !dbg !2361
  %360 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %359, i64 0, i64 2, !dbg !2362
  %361 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %360, i32 0, i32 1, !dbg !2363
  %362 = bitcast %union.vec64_t* %361 to %struct.uint64v1_t*, !dbg !2364
  %363 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %362, i32 0, i32 0, !dbg !2365
  %MM2 = getelementptr inbounds [1 x i64], [1 x i64]* %363, i64 0, i64 0, !dbg !2362
  %364 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2366
  %365 = getelementptr inbounds %struct.MMX, %struct.MMX* %364, i32 0, i32 0, !dbg !2367
  %366 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %365, i64 0, i64 3, !dbg !2368
  %367 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %366, i32 0, i32 1, !dbg !2369
  %368 = bitcast %union.vec64_t* %367 to %struct.uint64v1_t*, !dbg !2370
  %369 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %368, i32 0, i32 0, !dbg !2371
  %MM3 = getelementptr inbounds [1 x i64], [1 x i64]* %369, i64 0, i64 0, !dbg !2368
  %370 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2372
  %371 = getelementptr inbounds %struct.MMX, %struct.MMX* %370, i32 0, i32 0, !dbg !2373
  %372 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %371, i64 0, i64 4, !dbg !2374
  %373 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %372, i32 0, i32 1, !dbg !2375
  %374 = bitcast %union.vec64_t* %373 to %struct.uint64v1_t*, !dbg !2376
  %375 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %374, i32 0, i32 0, !dbg !2377
  %MM4 = getelementptr inbounds [1 x i64], [1 x i64]* %375, i64 0, i64 0, !dbg !2374
  %376 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2378
  %377 = getelementptr inbounds %struct.MMX, %struct.MMX* %376, i32 0, i32 0, !dbg !2379
  %378 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %377, i64 0, i64 5, !dbg !2380
  %379 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %378, i32 0, i32 1, !dbg !2381
  %380 = bitcast %union.vec64_t* %379 to %struct.uint64v1_t*, !dbg !2382
  %381 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %380, i32 0, i32 0, !dbg !2383
  %MM5 = getelementptr inbounds [1 x i64], [1 x i64]* %381, i64 0, i64 0, !dbg !2380
  %382 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2384
  %383 = getelementptr inbounds %struct.MMX, %struct.MMX* %382, i32 0, i32 0, !dbg !2385
  %384 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %383, i64 0, i64 6, !dbg !2386
  %385 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %384, i32 0, i32 1, !dbg !2387
  %386 = bitcast %union.vec64_t* %385 to %struct.uint64v1_t*, !dbg !2388
  %387 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %386, i32 0, i32 0, !dbg !2389
  %MM6 = getelementptr inbounds [1 x i64], [1 x i64]* %387, i64 0, i64 0, !dbg !2386
  %388 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2390
  %389 = getelementptr inbounds %struct.MMX, %struct.MMX* %388, i32 0, i32 0, !dbg !2391
  %390 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %389, i64 0, i64 7, !dbg !2392
  %391 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %390, i32 0, i32 1, !dbg !2393
  %392 = bitcast %union.vec64_t* %391 to %struct.uint64v1_t*, !dbg !2394
  %393 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %392, i32 0, i32 0, !dbg !2395
  %MM7 = getelementptr inbounds [1 x i64], [1 x i64]* %393, i64 0, i64 0, !dbg !2392
  %394 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2396
  %AF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %394, i32 0, i32 5, !dbg !2397
  %395 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2398
  %CF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %395, i32 0, i32 1, !dbg !2399
  %396 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2400
  %DF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %396, i32 0, i32 11, !dbg !2401
  %397 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2402
  %OF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %397, i32 0, i32 13, !dbg !2403
  %398 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2404
  %PF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %398, i32 0, i32 3, !dbg !2405
  %399 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2406
  %SF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %399, i32 0, i32 9, !dbg !2407
  %400 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2408
  %ZF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %400, i32 0, i32 7, !dbg !2409
  store i64* @DR0, i64** %_DR0, align 8, !dbg !2410
  store i64* @DR1, i64** %_DR1, align 8, !dbg !2411
  store i64* @DR2, i64** %_DR2, align 8, !dbg !2412
  store i64* @DR3, i64** %_DR3, align 8, !dbg !2413
  store i64* @DR4, i64** %_DR4, align 8, !dbg !2414
  store i64* @DR5, i64** %_DR5, align 8, !dbg !2415
  store i64* @DR6, i64** %_DR6, align 8, !dbg !2416
  store i64* @DR7, i64** %_DR7, align 8, !dbg !2417
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR0, i32 0, i32 0), i64** %CR0, align 8, !dbg !2418
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR1, i32 0, i32 0), i64** %CR1, align 8, !dbg !2419
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR2, i32 0, i32 0), i64** %CR2, align 8, !dbg !2420
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR3, i32 0, i32 0), i64** %CR3, align 8, !dbg !2421
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR4, i32 0, i32 0), i64** %CR4, align 8, !dbg !2422
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR8, i32 0, i32 0), i64** %CR8, align 8, !dbg !2423
  ret %struct.Memory* %2, !dbg !2424
}

; Function Attrs: noduplicate noinline nounwind optnone
define void @__remill_intrinsics() local_unnamed_addr #4 !dbg !2425 {
  ret void, !dbg !2427
}

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_function_call(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #5

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_jump(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #5

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memcpy(i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @abort() #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memset(i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @printf(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @free(i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @__libc_start_main(i64, i64, i64, i64, i64, i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @gettimeofday(i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @__gmon_start__() #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memalign(i64, i64) #6

; Function Attrs: noinline
define %struct.Memory* @sub_403ff0___libc_csu_init(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_403ff0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 27, i32 0
  %R13D = bitcast %union.anon* %4 to i32*
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 25, i32 0, i32 0
  %R13 = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %R14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 29, i32 0, i32 0
  %R15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 31, i32 0, i32 0
  %5 = load i64, i64* %R15, align 8
  %6 = add i64 %1, 2
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %8 = load i64, i64* %7, align 8, !tbaa !2428
  %9 = add i64 %8, -8
  %10 = inttoptr i64 %9 to i64*
  store i64 %5, i64* %10, align 8
  %11 = load i64, i64* %R14, align 8
  %12 = load i64, i64* %PC, align 8
  %13 = add i64 %12, 2
  store i64 %13, i64* %PC, align 8
  %14 = add i64 %8, -16
  %15 = inttoptr i64 %14 to i64*
  store i64 %11, i64* %15, align 8
  %16 = load i64, i64* %RDX, align 8
  %17 = load i64, i64* %PC, align 8
  store i64 %16, i64* %R15, align 8, !tbaa !2428
  %18 = load i64, i64* %R13, align 8
  %19 = add i64 %17, 5
  store i64 %19, i64* %PC, align 8
  %20 = add i64 %8, -24
  %21 = inttoptr i64 %20 to i64*
  store i64 %18, i64* %21, align 8
  %22 = load i64, i64* %R12, align 8
  %23 = load i64, i64* %PC, align 8
  %24 = add i64 %23, 2
  store i64 %24, i64* %PC, align 8
  %25 = add i64 %8, -32
  %26 = inttoptr i64 %25 to i64*
  store i64 %22, i64* %26, align 8
  %27 = load i64, i64* %PC, align 8
  store i64 ptrtoint (%seg_604df0__init_array_type* @seg_604df0__init_array to i64), i64* %R12, align 8, !tbaa !2428
  %28 = load i64, i64* %RBP, align 8
  %29 = add i64 %27, 8
  store i64 %29, i64* %PC, align 8
  %30 = add i64 %8, -40
  %31 = inttoptr i64 %30 to i64*
  store i64 %28, i64* %31, align 8
  %32 = load i64, i64* %PC, align 8
  store i64 add (i64 ptrtoint (%seg_604df0__init_array_type* @seg_604df0__init_array to i64), i64 8), i64* %RBP, align 8, !tbaa !2428
  %33 = load i64, i64* %RBX, align 8
  %34 = add i64 %32, 8
  store i64 %34, i64* %PC, align 8
  %35 = add i64 %8, -48
  %36 = inttoptr i64 %35 to i64*
  store i64 %33, i64* %36, align 8
  %37 = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %38 = load i32, i32* %EDI, align 4
  %39 = zext i32 %38 to i64
  %40 = load i64, i64* %PC, align 8
  store i64 %39, i64* %37, align 8, !tbaa !2428
  %41 = load i64, i64* %RSI, align 8
  store i64 %41, i64* %R14, align 8, !tbaa !2428
  %42 = load i64, i64* %RBP, align 8
  %43 = load i64, i64* %R12, align 8
  %44 = sub i64 %42, %43
  %45 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %48 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %49 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %50 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %51 = lshr i64 %44, 2
  %52 = trunc i64 %51 to i8
  %53 = and i8 %52, 1
  %54 = ashr i64 %44, 3
  store i64 %54, i64* %RBP, align 8, !tbaa !2428
  store i8 %53, i8* %45, align 1, !tbaa !2432
  %55 = trunc i64 %54 to i32
  %56 = and i32 %55, 255
  %57 = tail call i32 @llvm.ctpop.i32(i32 %56) #10
  %58 = trunc i32 %57 to i8
  %59 = and i8 %58, 1
  %60 = xor i8 %59, 1
  store i8 %60, i8* %46, align 1, !tbaa !2432
  store i8 0, i8* %47, align 1, !tbaa !2432
  %61 = icmp eq i64 %54, 0
  %62 = zext i1 %61 to i8
  store i8 %62, i8* %48, align 1, !tbaa !2432
  %63 = lshr i64 %54, 63
  %64 = trunc i64 %63 to i8
  store i8 %64, i8* %49, align 1, !tbaa !2432
  store i8 0, i8* %50, align 1, !tbaa !2432
  %65 = add i64 %40, -14803
  %66 = add i64 %40, 22
  %67 = add i64 %8, -64
  %68 = inttoptr i64 %67 to i64*
  store i64 %66, i64* %68, align 8
  store i64 %67, i64* %7, align 8, !tbaa !2428
  %69 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %65, i64* %69, align 8, !tbaa !2428
  %70 = tail call %struct.Memory* @sub_400638__init_proc_renamed_(%struct.State* nonnull %0, i64 %65, %struct.Memory* %2)
  %71 = load i64, i64* %RBP, align 8
  %72 = load i64, i64* %PC, align 8
  store i8 0, i8* %45, align 1, !tbaa !2433
  %73 = trunc i64 %71 to i32
  %74 = and i32 %73, 255
  %75 = tail call i32 @llvm.ctpop.i32(i32 %74) #10
  %76 = trunc i32 %75 to i8
  %77 = and i8 %76, 1
  %78 = xor i8 %77, 1
  store i8 %78, i8* %46, align 1, !tbaa !2447
  %79 = icmp eq i64 %71, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %48, align 1, !tbaa !2448
  %81 = lshr i64 %71, 63
  %82 = trunc i64 %81 to i8
  store i8 %82, i8* %49, align 1, !tbaa !2449
  store i8 0, i8* %50, align 1, !tbaa !2450
  store i8 0, i8* %47, align 1, !tbaa !2451
  %.v = select i1 %79, i64 37, i64 5
  %83 = add i64 %72, %.v
  store i64 %83, i64* %69, align 8, !tbaa !2428
  br i1 %79, label %block_404046, label %block_404026

block_404046:                                     ; preds = %block_404030, %block_403ff0
  %84 = phi i64 [ %83, %block_403ff0 ], [ %182, %block_404030 ]
  %MEMORY.0 = phi %struct.Memory* [ %70, %block_403ff0 ], [ %152, %block_404030 ]
  %85 = load i64, i64* %RSP, align 8
  %86 = add i64 %85, 8
  store i64 %86, i64* %RSP, align 8, !tbaa !2428
  %87 = icmp ugt i64 %85, -9
  %88 = zext i1 %87 to i8
  store i8 %88, i8* %45, align 1, !tbaa !2433
  %89 = trunc i64 %86 to i32
  %90 = and i32 %89, 255
  %91 = tail call i32 @llvm.ctpop.i32(i32 %90) #10
  %92 = trunc i32 %91 to i8
  %93 = and i8 %92, 1
  %94 = xor i8 %93, 1
  store i8 %94, i8* %46, align 1, !tbaa !2447
  %95 = xor i64 %85, %86
  %96 = lshr i64 %95, 4
  %97 = trunc i64 %96 to i8
  %98 = and i8 %97, 1
  store i8 %98, i8* %47, align 1, !tbaa !2451
  %99 = icmp eq i64 %86, 0
  %100 = zext i1 %99 to i8
  store i8 %100, i8* %48, align 1, !tbaa !2448
  %101 = lshr i64 %86, 63
  %102 = trunc i64 %101 to i8
  store i8 %102, i8* %49, align 1, !tbaa !2449
  %103 = lshr i64 %85, 63
  %104 = xor i64 %101, %103
  %105 = add nuw nsw i64 %104, %101
  %106 = icmp eq i64 %105, 2
  %107 = zext i1 %106 to i8
  store i8 %107, i8* %50, align 1, !tbaa !2450
  %108 = add i64 %84, 5
  store i64 %108, i64* %PC, align 8
  %109 = add i64 %85, 16
  %110 = inttoptr i64 %86 to i64*
  %111 = load i64, i64* %110, align 8
  store i64 %111, i64* %RBX, align 8, !tbaa !2428
  store i64 %109, i64* %7, align 8, !tbaa !2428
  %112 = add i64 %84, 6
  store i64 %112, i64* %PC, align 8
  %113 = add i64 %85, 24
  %114 = inttoptr i64 %109 to i64*
  %115 = load i64, i64* %114, align 8
  store i64 %115, i64* %RBP, align 8, !tbaa !2428
  store i64 %113, i64* %7, align 8, !tbaa !2428
  %116 = add i64 %84, 8
  store i64 %116, i64* %PC, align 8
  %117 = add i64 %85, 32
  %118 = inttoptr i64 %113 to i64*
  %119 = load i64, i64* %118, align 8
  store i64 %119, i64* %R12, align 8, !tbaa !2428
  store i64 %117, i64* %7, align 8, !tbaa !2428
  %120 = add i64 %84, 10
  store i64 %120, i64* %PC, align 8
  %121 = add i64 %85, 40
  %122 = inttoptr i64 %117 to i64*
  %123 = load i64, i64* %122, align 8
  store i64 %123, i64* %R13, align 8, !tbaa !2428
  store i64 %121, i64* %7, align 8, !tbaa !2428
  %124 = add i64 %84, 12
  store i64 %124, i64* %PC, align 8
  %125 = add i64 %85, 48
  %126 = inttoptr i64 %121 to i64*
  %127 = load i64, i64* %126, align 8
  store i64 %127, i64* %R14, align 8, !tbaa !2428
  store i64 %125, i64* %7, align 8, !tbaa !2428
  %128 = add i64 %84, 14
  store i64 %128, i64* %PC, align 8
  %129 = add i64 %85, 56
  %130 = inttoptr i64 %125 to i64*
  %131 = load i64, i64* %130, align 8
  store i64 %131, i64* %R15, align 8, !tbaa !2428
  store i64 %129, i64* %7, align 8, !tbaa !2428
  %132 = add i64 %84, 15
  store i64 %132, i64* %PC, align 8
  %133 = inttoptr i64 %129 to i64*
  %134 = load i64, i64* %133, align 8
  store i64 %134, i64* %69, align 8, !tbaa !2428
  %135 = add i64 %85, 64
  store i64 %135, i64* %7, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_404026:                                     ; preds = %block_403ff0
  store i64 0, i64* %RBX, align 8, !tbaa !2428
  store i8 0, i8* %45, align 1, !tbaa !2433
  store i8 1, i8* %46, align 1, !tbaa !2447
  store i8 1, i8* %48, align 1, !tbaa !2448
  store i8 0, i8* %49, align 1, !tbaa !2449
  store i8 0, i8* %50, align 1, !tbaa !2450
  store i8 0, i8* %47, align 1, !tbaa !2451
  %136 = add i64 %83, 10
  store i64 %136, i64* %PC, align 8
  br label %block_404030

block_404030:                                     ; preds = %block_404030, %block_404026
  %137 = phi i64 [ 0, %block_404026 ], [ %155, %block_404030 ]
  %138 = phi i64 [ %136, %block_404026 ], [ %182, %block_404030 ]
  %MEMORY.1 = phi %struct.Memory* [ %70, %block_404026 ], [ %152, %block_404030 ]
  %139 = load i64, i64* %R15, align 8
  store i64 %139, i64* %RDX, align 8, !tbaa !2428
  %140 = load i64, i64* %R14, align 8
  store i64 %140, i64* %RSI, align 8, !tbaa !2428
  %141 = load i32, i32* %R13D, align 4
  %142 = zext i32 %141 to i64
  store i64 %142, i64* %RDI, align 8, !tbaa !2428
  %143 = load i64, i64* %R12, align 8
  %144 = shl i64 %137, 3
  %145 = add i64 %144, %143
  %146 = add i64 %138, 13
  store i64 %146, i64* %PC, align 8
  %147 = load i64, i64* %7, align 8, !tbaa !2428
  %148 = add i64 %147, -8
  %149 = inttoptr i64 %148 to i64*
  store i64 %146, i64* %149, align 8
  store i64 %148, i64* %7, align 8, !tbaa !2428
  %150 = inttoptr i64 %145 to i64*
  %151 = load i64, i64* %150, align 8
  store i64 %151, i64* %69, align 8, !tbaa !2428
  %152 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 %151, %struct.Memory* %MEMORY.1)
  %153 = load i64, i64* %RBX, align 8
  %154 = load i64, i64* %PC, align 8
  %155 = add i64 %153, 1
  store i64 %155, i64* %RBX, align 8, !tbaa !2428
  %156 = lshr i64 %155, 63
  %157 = load i64, i64* %RBP, align 8
  %158 = sub i64 %157, %155
  %159 = icmp ult i64 %157, %155
  %160 = zext i1 %159 to i8
  store i8 %160, i8* %45, align 1, !tbaa !2433
  %161 = trunc i64 %158 to i32
  %162 = and i32 %161, 255
  %163 = tail call i32 @llvm.ctpop.i32(i32 %162) #10
  %164 = trunc i32 %163 to i8
  %165 = and i8 %164, 1
  %166 = xor i8 %165, 1
  store i8 %166, i8* %46, align 1, !tbaa !2447
  %167 = xor i64 %155, %157
  %168 = xor i64 %167, %158
  %169 = lshr i64 %168, 4
  %170 = trunc i64 %169 to i8
  %171 = and i8 %170, 1
  store i8 %171, i8* %47, align 1, !tbaa !2451
  %172 = icmp eq i64 %158, 0
  %173 = zext i1 %172 to i8
  store i8 %173, i8* %48, align 1, !tbaa !2448
  %174 = lshr i64 %158, 63
  %175 = trunc i64 %174 to i8
  store i8 %175, i8* %49, align 1, !tbaa !2449
  %176 = lshr i64 %157, 63
  %177 = xor i64 %156, %176
  %178 = xor i64 %174, %176
  %179 = add nuw nsw i64 %178, %177
  %180 = icmp eq i64 %179, 2
  %181 = zext i1 %180 to i8
  store i8 %181, i8* %50, align 1, !tbaa !2450
  %.v1 = select i1 %172, i64 9, i64 -13
  %182 = add i64 %154, %.v1
  store i64 %182, i64* %69, align 8, !tbaa !2428
  br i1 %172, label %block_404046, label %block_404030
}

; Function Attrs: noinline
define %struct.Memory* @sub_400fb0_putdata(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400fb0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %5 to i32*
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %6 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %6, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %9 = load i64, i64* %RBP, align 8
  %10 = add i64 %1, 1
  store i64 %10, i64* %PC, align 8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %12 = load i64, i64* %11, align 8, !tbaa !2428
  %13 = add i64 %12, -8
  %14 = inttoptr i64 %13 to i64*
  store i64 %9, i64* %14, align 8
  store i64 %13, i64* %11, align 8, !tbaa !2428
  %15 = load i64, i64* %PC, align 8
  store i64 %13, i64* %RBP, align 8, !tbaa !2428
  %16 = add i64 %12, -12
  %17 = load i32, i32* %EDI, align 4
  %18 = add i64 %15, 6
  store i64 %18, i64* %PC, align 8
  %19 = inttoptr i64 %16 to i32*
  store i32 %17, i32* %19, align 4
  %20 = load i64, i64* %RBP, align 8
  %21 = add i64 %20, -8
  %22 = load i32, i32* %ESI, align 4
  %23 = load i64, i64* %PC, align 8
  %24 = add i64 %23, 3
  store i64 %24, i64* %PC, align 8
  %25 = inttoptr i64 %21 to i32*
  store i32 %22, i32* %25, align 4
  %26 = load i64, i64* %RBP, align 8
  %27 = add i64 %26, -16
  %28 = load i64, i64* %RDX, align 8
  %29 = load i64, i64* %PC, align 8
  %30 = add i64 %29, 4
  store i64 %30, i64* %PC, align 8
  %31 = inttoptr i64 %27 to i64*
  store i64 %28, i64* %31, align 8
  %32 = load i64, i64* %RBP, align 8
  %33 = add i64 %32, -24
  %34 = load i64, i64* %PC, align 8
  %35 = add i64 %34, 7
  store i64 %35, i64* %PC, align 8
  %36 = inttoptr i64 %33 to i32*
  store i32 0, i32* %36, align 4
  %37 = load i64, i64* %RBP, align 8
  %38 = add i64 %37, -4
  %39 = load i64, i64* %PC, align 8
  %40 = add i64 %39, 3
  store i64 %40, i64* %PC, align 8
  %41 = inttoptr i64 %38 to i32*
  %42 = load i32, i32* %41, align 4
  %43 = zext i32 %42 to i64
  store i64 %43, i64* %RSI, align 8, !tbaa !2428
  %44 = add i64 %37, -20
  %45 = add i64 %39, 6
  store i64 %45, i64* %PC, align 8
  %46 = inttoptr i64 %44 to i32*
  store i32 %42, i32* %46, align 4
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %48 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %49 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %50 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %53 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %55 = bitcast i64* %54 to double*
  %56 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %57 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %58 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %59 = bitcast %union.VectorReg* %8 to double*
  %60 = bitcast [32 x %union.VectorReg]* %7 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_400fcb

block_400fcb:                                     ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit, %block_400fb0
  %61 = phi i64 [ %.pre, %block_400fb0 ], [ %220, %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_400fb0 ], [ %165, %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit ]
  %62 = load i64, i64* %RBP, align 8
  %63 = add i64 %62, -20
  %64 = add i64 %61, 3
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %63 to i32*
  %66 = load i32, i32* %65, align 4
  %67 = zext i32 %66 to i64
  store i64 %67, i64* %RAX, align 8, !tbaa !2428
  %68 = add i64 %62, -8
  %69 = add i64 %61, 6
  store i64 %69, i64* %PC, align 8
  %70 = inttoptr i64 %68 to i32*
  %71 = load i32, i32* %70, align 4
  %72 = sub i32 %66, %71
  %73 = icmp ult i32 %66, %71
  %74 = zext i1 %73 to i8
  store i8 %74, i8* %47, align 1, !tbaa !2433
  %75 = and i32 %72, 255
  %76 = tail call i32 @llvm.ctpop.i32(i32 %75) #10
  %77 = trunc i32 %76 to i8
  %78 = and i8 %77, 1
  %79 = xor i8 %78, 1
  store i8 %79, i8* %48, align 1, !tbaa !2447
  %80 = xor i32 %71, %66
  %81 = xor i32 %80, %72
  %82 = lshr i32 %81, 4
  %83 = trunc i32 %82 to i8
  %84 = and i8 %83, 1
  store i8 %84, i8* %49, align 1, !tbaa !2451
  %85 = icmp eq i32 %72, 0
  %86 = zext i1 %85 to i8
  store i8 %86, i8* %50, align 1, !tbaa !2448
  %87 = lshr i32 %72, 31
  %88 = trunc i32 %87 to i8
  store i8 %88, i8* %51, align 1, !tbaa !2449
  %89 = lshr i32 %66, 31
  %90 = lshr i32 %71, 31
  %91 = xor i32 %90, %89
  %92 = xor i32 %87, %89
  %93 = add nuw nsw i32 %92, %91
  %94 = icmp eq i32 %93, 2
  %95 = zext i1 %94 to i8
  store i8 %95, i8* %52, align 1, !tbaa !2450
  %96 = icmp ne i8 %88, 0
  %97 = xor i1 %96, %94
  %.demorgan = or i1 %85, %97
  %.v = select i1 %.demorgan, i64 12, i64 87
  %98 = add i64 %61, %.v
  store i64 %98, i64* %53, align 8, !tbaa !2428
  br i1 %.demorgan, label %block_400fd7, label %block_401022

block_400fd7:                                     ; preds = %block_400fcb
  %99 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 72) to i64*), align 8
  %100 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %99, i64* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %55, align 1, !tbaa !2452
  store i64 259200, i64* %RAX, align 8, !tbaa !2428
  %101 = add i64 %62, -24
  %102 = add i64 %98, 20
  store i64 %102, i64* %PC, align 8
  %103 = inttoptr i64 %101 to i32*
  %104 = load i32, i32* %103, align 4
  %105 = sext i32 %104 to i64
  %106 = mul nsw i64 %105, 7141
  %107 = trunc i64 %106 to i32
  %108 = add i32 %107, 54773
  %109 = zext i32 %108 to i64
  store i64 %109, i64* %RCX, align 8, !tbaa !2428
  %110 = icmp ugt i32 %107, -54774
  %111 = zext i1 %110 to i8
  store i8 %111, i8* %47, align 1, !tbaa !2433
  %112 = and i32 %108, 255
  %113 = tail call i32 @llvm.ctpop.i32(i32 %112) #10
  %114 = trunc i32 %113 to i8
  %115 = and i8 %114, 1
  %116 = xor i8 %115, 1
  store i8 %116, i8* %48, align 1, !tbaa !2447
  %117 = trunc i64 %106 to i32
  %118 = xor i32 %117, 16
  %119 = xor i32 %118, %108
  %120 = lshr i32 %119, 4
  %121 = trunc i32 %120 to i8
  %122 = and i8 %121, 1
  store i8 %122, i8* %49, align 1, !tbaa !2451
  %123 = icmp eq i32 %108, 0
  %124 = zext i1 %123 to i8
  store i8 %124, i8* %50, align 1, !tbaa !2448
  %125 = lshr i32 %108, 31
  %126 = trunc i32 %125 to i8
  store i8 %126, i8* %51, align 1, !tbaa !2449
  %127 = lshr i32 %107, 31
  %128 = xor i32 %125, %127
  %129 = add nuw nsw i32 %128, %125
  %130 = icmp eq i32 %129, 2
  %131 = zext i1 %130 to i8
  store i8 %131, i8* %52, align 1, !tbaa !2450
  %132 = add i64 %62, -28
  %133 = add i64 %98, 29
  store i64 %133, i64* %PC, align 8
  %134 = inttoptr i64 %132 to i32*
  store i32 259200, i32* %134, align 4
  %135 = load i32, i32* %ECX, align 4
  %136 = zext i32 %135 to i64
  %137 = load i64, i64* %PC, align 8
  store i64 %136, i64* %RAX, align 8, !tbaa !2428
  %138 = sext i32 %135 to i64
  %139 = lshr i64 %138, 32
  store i64 %139, i64* %56, align 8, !tbaa !2428
  %140 = load i64, i64* %RBP, align 8
  %141 = add i64 %140, -28
  %142 = add i64 %137, 6
  store i64 %142, i64* %PC, align 8
  %143 = inttoptr i64 %141 to i32*
  %144 = load i32, i32* %143, align 4
  %145 = zext i32 %144 to i64
  store i64 %145, i64* %RCX, align 8, !tbaa !2428
  %146 = add i64 %137, 8
  store i64 %146, i64* %PC, align 8
  %147 = zext i32 %135 to i64
  %148 = sext i32 %144 to i64
  %149 = shl nuw i64 %139, 32
  %150 = or i64 %149, %147
  %151 = sdiv i64 %150, %148
  %152 = shl i64 %151, 32
  %153 = ashr exact i64 %152, 32
  %154 = icmp eq i64 %151, %153
  br i1 %154, label %157, label %155

; <label>:155:                                    ; preds = %block_400fd7
  %156 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %146, %struct.Memory* %MEMORY.0) #11
  %.pre1 = load i64, i64* %RBP, align 8
  %.pre2 = load i32, i32* %EDX, align 4
  %.pre3 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:157:                                    ; preds = %block_400fd7
  %158 = srem i64 %150, %148
  %159 = and i64 %151, 4294967295
  store i64 %159, i64* %57, align 8, !tbaa !2428
  %160 = and i64 %158, 4294967295
  store i64 %160, i64* %58, align 8, !tbaa !2428
  store i8 0, i8* %47, align 1, !tbaa !2433
  store i8 0, i8* %48, align 1, !tbaa !2447
  store i8 0, i8* %49, align 1, !tbaa !2451
  store i8 0, i8* %50, align 1, !tbaa !2448
  store i8 0, i8* %51, align 1, !tbaa !2449
  store i8 0, i8* %52, align 1, !tbaa !2450
  %161 = trunc i64 %158 to i32
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %157, %155
  %162 = phi i64 [ %.pre3, %155 ], [ %146, %157 ]
  %163 = phi i32 [ %.pre2, %155 ], [ %161, %157 ]
  %164 = phi i64 [ %.pre1, %155 ], [ %140, %157 ]
  %165 = phi %struct.Memory* [ %156, %155 ], [ %MEMORY.0, %157 ]
  %166 = add i64 %164, -24
  %167 = add i64 %162, 3
  store i64 %167, i64* %PC, align 8
  %168 = inttoptr i64 %166 to i32*
  store i32 %163, i32* %168, align 4
  %169 = load i32, i32* %EDX, align 4
  %170 = load i64, i64* %PC, align 8
  %171 = sitofp i32 %169 to double
  %172 = load double, double* %60, align 1
  %173 = fmul double %171, %172
  store double %173, double* %59, align 1, !tbaa !2452
  %174 = load i64, i64* %RBP, align 8
  %175 = add i64 %174, -16
  %176 = add i64 %170, 12
  store i64 %176, i64* %PC, align 8
  %177 = inttoptr i64 %175 to i64*
  %178 = load i64, i64* %177, align 8
  store i64 %178, i64* %RSI, align 8, !tbaa !2428
  %179 = add i64 %174, -20
  %180 = add i64 %170, 16
  store i64 %180, i64* %PC, align 8
  %181 = inttoptr i64 %179 to i32*
  %182 = load i32, i32* %181, align 4
  %183 = sext i32 %182 to i64
  store i64 %183, i64* %RDI, align 8, !tbaa !2428
  %184 = shl nsw i64 %183, 3
  %185 = add i64 %184, %178
  %186 = add i64 %170, 21
  store i64 %186, i64* %PC, align 8
  %187 = inttoptr i64 %185 to double*
  store double %173, double* %187, align 8
  %188 = load i64, i64* %RBP, align 8
  %189 = add i64 %188, -20
  %190 = load i64, i64* %PC, align 8
  %191 = add i64 %190, 3
  store i64 %191, i64* %PC, align 8
  %192 = inttoptr i64 %189 to i32*
  %193 = load i32, i32* %192, align 4
  %194 = add i32 %193, 1
  %195 = zext i32 %194 to i64
  store i64 %195, i64* %RAX, align 8, !tbaa !2428
  %196 = icmp eq i32 %193, -1
  %197 = icmp eq i32 %194, 0
  %198 = or i1 %196, %197
  %199 = zext i1 %198 to i8
  store i8 %199, i8* %47, align 1, !tbaa !2433
  %200 = and i32 %194, 255
  %201 = tail call i32 @llvm.ctpop.i32(i32 %200) #10
  %202 = trunc i32 %201 to i8
  %203 = and i8 %202, 1
  %204 = xor i8 %203, 1
  store i8 %204, i8* %48, align 1, !tbaa !2447
  %205 = xor i32 %193, %194
  %206 = lshr i32 %205, 4
  %207 = trunc i32 %206 to i8
  %208 = and i8 %207, 1
  store i8 %208, i8* %49, align 1, !tbaa !2451
  %209 = icmp eq i32 %194, 0
  %210 = zext i1 %209 to i8
  store i8 %210, i8* %50, align 1, !tbaa !2448
  %211 = lshr i32 %194, 31
  %212 = trunc i32 %211 to i8
  store i8 %212, i8* %51, align 1, !tbaa !2449
  %213 = lshr i32 %193, 31
  %214 = xor i32 %211, %213
  %215 = add nuw nsw i32 %214, %211
  %216 = icmp eq i32 %215, 2
  %217 = zext i1 %216 to i8
  store i8 %217, i8* %52, align 1, !tbaa !2450
  %218 = add i64 %190, 9
  store i64 %218, i64* %PC, align 8
  store i32 %194, i32* %192, align 4
  %219 = load i64, i64* %PC, align 8
  %220 = add i64 %219, -82
  store i64 %220, i64* %53, align 8, !tbaa !2428
  br label %block_400fcb

block_401022:                                     ; preds = %block_400fcb
  %221 = add i64 %98, 1
  store i64 %221, i64* %PC, align 8
  %222 = load i64, i64* %11, align 8, !tbaa !2428
  %223 = add i64 %222, 8
  %224 = inttoptr i64 %222 to i64*
  %225 = load i64, i64* %224, align 8
  store i64 %225, i64* %RBP, align 8, !tbaa !2428
  store i64 %223, i64* %11, align 8, !tbaa !2428
  %226 = add i64 %98, 2
  store i64 %226, i64* %PC, align 8
  %227 = inttoptr i64 %223 to i64*
  %228 = load i64, i64* %227, align 8
  store i64 %228, i64* %53, align 8, !tbaa !2428
  %229 = add i64 %222, 16
  store i64 %229, i64* %11, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0
}

; Function Attrs: noinline
define %struct.Memory* @sub_4011c0_bitrv2(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_4011c0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %8 = load i64, i64* %7, align 8, !tbaa !2428
  %9 = add i64 %8, -8
  %10 = inttoptr i64 %9 to i64*
  store i64 %5, i64* %10, align 8
  store i64 %9, i64* %7, align 8, !tbaa !2428
  %11 = load i64, i64* %PC, align 8
  store i64 %9, i64* %RBP, align 8, !tbaa !2428
  %12 = add i64 %8, -12
  %13 = load i32, i32* %EDI, align 4
  %14 = add i64 %11, 6
  store i64 %14, i64* %PC, align 8
  %15 = inttoptr i64 %12 to i32*
  store i32 %13, i32* %15, align 4
  %16 = load i64, i64* %RBP, align 8
  %17 = add i64 %16, -16
  %18 = load i64, i64* %RSI, align 8
  %19 = load i64, i64* %PC, align 8
  %20 = add i64 %19, 4
  store i64 %20, i64* %PC, align 8
  %21 = inttoptr i64 %17 to i64*
  store i64 %18, i64* %21, align 8
  %22 = load i64, i64* %RBP, align 8
  %23 = add i64 %22, -24
  %24 = load i64, i64* %RDX, align 8
  %25 = load i64, i64* %PC, align 8
  %26 = add i64 %25, 4
  store i64 %26, i64* %PC, align 8
  %27 = inttoptr i64 %23 to i64*
  store i64 %24, i64* %27, align 8
  %28 = load i64, i64* %RBP, align 8
  %29 = add i64 %28, -16
  %30 = load i64, i64* %PC, align 8
  %31 = add i64 %30, 4
  store i64 %31, i64* %PC, align 8
  %32 = inttoptr i64 %29 to i64*
  %33 = load i64, i64* %32, align 8
  store i64 %33, i64* %RDX, align 8, !tbaa !2428
  %34 = add i64 %30, 10
  store i64 %34, i64* %PC, align 8
  %35 = inttoptr i64 %33 to i32*
  store i32 0, i32* %35, align 4
  %36 = load i64, i64* %RBP, align 8
  %37 = add i64 %36, -4
  %38 = load i64, i64* %PC, align 8
  %39 = add i64 %38, 3
  store i64 %39, i64* %PC, align 8
  %40 = inttoptr i64 %37 to i32*
  %41 = load i32, i32* %40, align 4
  %42 = zext i32 %41 to i64
  store i64 %42, i64* %RDI, align 8, !tbaa !2428
  %43 = add i64 %36, -44
  %44 = add i64 %38, 6
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %43 to i32*
  store i32 %41, i32* %45, align 4
  %46 = load i64, i64* %RBP, align 8
  %47 = add i64 %46, -48
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 7
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %47 to i32*
  store i32 1, i32* %50, align 4
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %53 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %56 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %57 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %.pre = load i64, i64* %PC, align 8
  br label %block_4011e6

block_40127d:                                     ; preds = %block_401289, %block_401276
  %58 = phi i64 [ %3161, %block_401289 ], [ %.pre5, %block_401276 ]
  %59 = load i64, i64* %RBP, align 8
  %60 = add i64 %59, -28
  %61 = add i64 %58, 3
  store i64 %61, i64* %PC, align 8
  %62 = inttoptr i64 %60 to i32*
  %63 = load i32, i32* %62, align 4
  %64 = zext i32 %63 to i64
  store i64 %64, i64* %RAX, align 8, !tbaa !2428
  %65 = add i64 %59, -36
  %66 = add i64 %58, 6
  store i64 %66, i64* %PC, align 8
  %67 = inttoptr i64 %65 to i32*
  %68 = load i32, i32* %67, align 4
  %69 = sub i32 %63, %68
  %70 = icmp ult i32 %63, %68
  %71 = zext i1 %70 to i8
  store i8 %71, i8* %51, align 1, !tbaa !2433
  %72 = and i32 %69, 255
  %73 = tail call i32 @llvm.ctpop.i32(i32 %72) #10
  %74 = trunc i32 %73 to i8
  %75 = and i8 %74, 1
  %76 = xor i8 %75, 1
  store i8 %76, i8* %52, align 1, !tbaa !2447
  %77 = xor i32 %68, %63
  %78 = xor i32 %77, %69
  %79 = lshr i32 %78, 4
  %80 = trunc i32 %79 to i8
  %81 = and i8 %80, 1
  store i8 %81, i8* %53, align 1, !tbaa !2451
  %82 = icmp eq i32 %69, 0
  %83 = zext i1 %82 to i8
  store i8 %83, i8* %54, align 1, !tbaa !2448
  %84 = lshr i32 %69, 31
  %85 = trunc i32 %84 to i8
  store i8 %85, i8* %55, align 1, !tbaa !2449
  %86 = lshr i32 %63, 31
  %87 = lshr i32 %68, 31
  %88 = xor i32 %87, %86
  %89 = xor i32 %84, %86
  %90 = add nuw nsw i32 %89, %88
  %91 = icmp eq i32 %90, 2
  %92 = zext i1 %91 to i8
  store i8 %92, i8* %56, align 1, !tbaa !2450
  %93 = icmp ne i8 %85, 0
  %94 = xor i1 %93, %91
  %.v14 = select i1 %94, i64 12, i64 784
  %95 = add i64 %58, %.v14
  %96 = add i64 %95, 3
  store i64 %96, i64* %PC, align 8
  br i1 %94, label %block_401289, label %block_40158d

block_4011f5:                                     ; preds = %block_4011e6
  %97 = load i32, i32* %264, align 4
  %98 = zext i32 %97 to i64
  %99 = shl nuw i64 %98, 32
  %100 = ashr i64 %99, 33
  %101 = trunc i32 %97 to i8
  %102 = and i8 %101, 1
  %103 = trunc i64 %100 to i32
  %104 = and i64 %100, 4294967295
  store i64 %104, i64* %RAX, align 8, !tbaa !2428
  store i8 %102, i8* %51, align 1, !tbaa !2432
  %105 = and i32 %103, 255
  %106 = tail call i32 @llvm.ctpop.i32(i32 %105) #10
  %107 = trunc i32 %106 to i8
  %108 = and i8 %107, 1
  %109 = xor i8 %108, 1
  store i8 %109, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %110 = icmp eq i32 %103, 0
  %111 = zext i1 %110 to i8
  store i8 %111, i8* %54, align 1, !tbaa !2432
  %112 = lshr i64 %100, 31
  %113 = trunc i64 %112 to i8
  %114 = and i8 %113, 1
  store i8 %114, i8* %55, align 1, !tbaa !2432
  store i8 0, i8* %56, align 1, !tbaa !2432
  %115 = trunc i64 %100 to i32
  %116 = add i64 %291, 9
  store i64 %116, i64* %PC, align 8
  store i32 %115, i32* %264, align 4
  %117 = load i64, i64* %RBP, align 8
  %118 = add i64 %117, -28
  %119 = load i64, i64* %PC, align 8
  %120 = add i64 %119, 7
  store i64 %120, i64* %PC, align 8
  %121 = inttoptr i64 %118 to i32*
  store i32 0, i32* %121, align 4
  %.pre3 = load i64, i64* %PC, align 8
  br label %block_401205

block_40166b:                                     ; preds = %block_40181a, %block_401664
  %122 = phi i64 [ %355, %block_40181a ], [ %.pre6, %block_401664 ]
  %123 = load i64, i64* %RBP, align 8
  %124 = add i64 %123, -36
  %125 = add i64 %122, 3
  store i64 %125, i64* %PC, align 8
  %126 = inttoptr i64 %124 to i32*
  %127 = load i32, i32* %126, align 4
  %128 = zext i32 %127 to i64
  store i64 %128, i64* %RAX, align 8, !tbaa !2428
  %129 = add i64 %123, -48
  %130 = add i64 %122, 6
  store i64 %130, i64* %PC, align 8
  %131 = inttoptr i64 %129 to i32*
  %132 = load i32, i32* %131, align 4
  %133 = sub i32 %127, %132
  %134 = icmp ult i32 %127, %132
  %135 = zext i1 %134 to i8
  store i8 %135, i8* %51, align 1, !tbaa !2433
  %136 = and i32 %133, 255
  %137 = tail call i32 @llvm.ctpop.i32(i32 %136) #10
  %138 = trunc i32 %137 to i8
  %139 = and i8 %138, 1
  %140 = xor i8 %139, 1
  store i8 %140, i8* %52, align 1, !tbaa !2447
  %141 = xor i32 %132, %127
  %142 = xor i32 %141, %133
  %143 = lshr i32 %142, 4
  %144 = trunc i32 %143 to i8
  %145 = and i8 %144, 1
  store i8 %145, i8* %53, align 1, !tbaa !2451
  %146 = icmp eq i32 %133, 0
  %147 = zext i1 %146 to i8
  store i8 %147, i8* %54, align 1, !tbaa !2448
  %148 = lshr i32 %133, 31
  %149 = trunc i32 %148 to i8
  store i8 %149, i8* %55, align 1, !tbaa !2449
  %150 = lshr i32 %127, 31
  %151 = lshr i32 %132, 31
  %152 = xor i32 %151, %150
  %153 = xor i32 %148, %150
  %154 = add nuw nsw i32 %153, %152
  %155 = icmp eq i32 %154, 2
  %156 = zext i1 %155 to i8
  store i8 %156, i8* %56, align 1, !tbaa !2450
  %157 = icmp ne i8 %149, 0
  %158 = xor i1 %157, %155
  %.v20 = select i1 %158, i64 12, i64 450
  %159 = add i64 %122, %.v20
  store i64 %159, i64* %57, align 8, !tbaa !2428
  br i1 %158, label %block_401677, label %block_40182d

block_40167e:                                     ; preds = %block_40168a, %block_401677
  %160 = phi i64 [ %1717, %block_40168a ], [ %.pre7, %block_401677 ]
  %161 = load i64, i64* %RBP, align 8
  %162 = add i64 %161, -28
  %163 = add i64 %160, 3
  store i64 %163, i64* %PC, align 8
  %164 = inttoptr i64 %162 to i32*
  %165 = load i32, i32* %164, align 4
  %166 = zext i32 %165 to i64
  store i64 %166, i64* %RAX, align 8, !tbaa !2428
  %167 = add i64 %161, -36
  %168 = add i64 %160, 6
  store i64 %168, i64* %PC, align 8
  %169 = inttoptr i64 %167 to i32*
  %170 = load i32, i32* %169, align 4
  %171 = sub i32 %165, %170
  %172 = icmp ult i32 %165, %170
  %173 = zext i1 %172 to i8
  store i8 %173, i8* %51, align 1, !tbaa !2433
  %174 = and i32 %171, 255
  %175 = tail call i32 @llvm.ctpop.i32(i32 %174) #10
  %176 = trunc i32 %175 to i8
  %177 = and i8 %176, 1
  %178 = xor i8 %177, 1
  store i8 %178, i8* %52, align 1, !tbaa !2447
  %179 = xor i32 %170, %165
  %180 = xor i32 %179, %171
  %181 = lshr i32 %180, 4
  %182 = trunc i32 %181 to i8
  %183 = and i8 %182, 1
  store i8 %183, i8* %53, align 1, !tbaa !2451
  %184 = icmp eq i32 %171, 0
  %185 = zext i1 %184 to i8
  store i8 %185, i8* %54, align 1, !tbaa !2448
  %186 = lshr i32 %171, 31
  %187 = trunc i32 %186 to i8
  store i8 %187, i8* %55, align 1, !tbaa !2449
  %188 = lshr i32 %165, 31
  %189 = lshr i32 %170, 31
  %190 = xor i32 %189, %188
  %191 = xor i32 %186, %188
  %192 = add nuw nsw i32 %191, %190
  %193 = icmp eq i32 %192, 2
  %194 = zext i1 %193 to i8
  store i8 %194, i8* %56, align 1, !tbaa !2450
  %195 = icmp ne i8 %187, 0
  %196 = xor i1 %195, %193
  %.v21 = select i1 %196, i64 12, i64 412
  %197 = add i64 %160, %.v21
  store i64 %197, i64* %57, align 8, !tbaa !2428
  br i1 %196, label %block_40168a, label %block_40181a

block_40126a:                                     ; preds = %block_40158d, %block_401263
  %198 = phi i64 [ %965, %block_40158d ], [ %.pre4, %block_401263 ]
  %199 = load i64, i64* %RBP, align 8
  %200 = add i64 %199, -36
  %201 = add i64 %198, 3
  store i64 %201, i64* %PC, align 8
  %202 = inttoptr i64 %200 to i32*
  %203 = load i32, i32* %202, align 4
  %204 = zext i32 %203 to i64
  store i64 %204, i64* %RAX, align 8, !tbaa !2428
  %205 = add i64 %199, -48
  %206 = add i64 %198, 6
  store i64 %206, i64* %PC, align 8
  %207 = inttoptr i64 %205 to i32*
  %208 = load i32, i32* %207, align 4
  %209 = sub i32 %203, %208
  %210 = icmp ult i32 %203, %208
  %211 = zext i1 %210 to i8
  store i8 %211, i8* %51, align 1, !tbaa !2433
  %212 = and i32 %209, 255
  %213 = tail call i32 @llvm.ctpop.i32(i32 %212) #10
  %214 = trunc i32 %213 to i8
  %215 = and i8 %214, 1
  %216 = xor i8 %215, 1
  store i8 %216, i8* %52, align 1, !tbaa !2447
  %217 = xor i32 %208, %203
  %218 = xor i32 %217, %209
  %219 = lshr i32 %218, 4
  %220 = trunc i32 %219 to i8
  %221 = and i8 %220, 1
  store i8 %221, i8* %53, align 1, !tbaa !2451
  %222 = icmp eq i32 %209, 0
  %223 = zext i1 %222 to i8
  store i8 %223, i8* %54, align 1, !tbaa !2448
  %224 = lshr i32 %209, 31
  %225 = trunc i32 %224 to i8
  store i8 %225, i8* %55, align 1, !tbaa !2449
  %226 = lshr i32 %203, 31
  %227 = lshr i32 %208, 31
  %228 = xor i32 %227, %226
  %229 = xor i32 %224, %226
  %230 = add nuw nsw i32 %229, %228
  %231 = icmp eq i32 %230, 2
  %232 = zext i1 %231 to i8
  store i8 %232, i8* %56, align 1, !tbaa !2450
  %233 = icmp ne i8 %225, 0
  %234 = xor i1 %233, %231
  %.v13 = select i1 %234, i64 12, i64 1013
  %235 = add i64 %198, %.v13
  store i64 %235, i64* %57, align 8, !tbaa !2428
  br i1 %234, label %block_401276, label %block_40165f

block_401677:                                     ; preds = %block_40166b
  %236 = add i64 %123, -28
  %237 = add i64 %159, 7
  store i64 %237, i64* %PC, align 8
  %238 = inttoptr i64 %236 to i32*
  store i32 0, i32* %238, align 4
  %.pre7 = load i64, i64* %PC, align 8
  br label %block_40167e

block_401263:                                     ; preds = %block_40124b
  store i32 0, i32* %429, align 4
  %239 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %240 = bitcast i64* %239 to double*
  %.pre4 = load i64, i64* %PC, align 8
  br label %block_40126a

block_4011e6:                                     ; preds = %block_40123d, %block_4011c0
  %241 = phi i64 [ %314, %block_40123d ], [ %.pre, %block_4011c0 ]
  %242 = load i64, i64* %RBP, align 8
  %243 = add i64 %242, -48
  %244 = add i64 %241, 3
  store i64 %244, i64* %PC, align 8
  %245 = inttoptr i64 %243 to i32*
  %246 = load i32, i32* %245, align 4
  %247 = shl i32 %246, 3
  %248 = zext i32 %247 to i64
  store i64 %248, i64* %RAX, align 8, !tbaa !2428
  %249 = lshr i32 %246, 29
  %250 = trunc i32 %249 to i8
  %251 = and i8 %250, 1
  store i8 %251, i8* %51, align 1, !tbaa !2432
  %252 = and i32 %247, 248
  %253 = tail call i32 @llvm.ctpop.i32(i32 %252) #10
  %254 = trunc i32 %253 to i8
  %255 = and i8 %254, 1
  %256 = xor i8 %255, 1
  store i8 %256, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %257 = icmp eq i32 %247, 0
  %258 = zext i1 %257 to i8
  store i8 %258, i8* %54, align 1, !tbaa !2432
  %259 = lshr i32 %246, 28
  %260 = and i32 %259, 1
  %261 = trunc i32 %260 to i8
  store i8 %261, i8* %55, align 1, !tbaa !2432
  store i8 0, i8* %56, align 1, !tbaa !2432
  %262 = add i64 %242, -44
  %263 = add i64 %241, 9
  store i64 %263, i64* %PC, align 8
  %264 = inttoptr i64 %262 to i32*
  %265 = load i32, i32* %264, align 4
  %266 = sub i32 %247, %265
  %267 = icmp ult i32 %247, %265
  %268 = zext i1 %267 to i8
  store i8 %268, i8* %51, align 1, !tbaa !2433
  %269 = and i32 %266, 255
  %270 = tail call i32 @llvm.ctpop.i32(i32 %269) #10
  %271 = trunc i32 %270 to i8
  %272 = and i8 %271, 1
  %273 = xor i8 %272, 1
  store i8 %273, i8* %52, align 1, !tbaa !2447
  %274 = xor i32 %265, %247
  %275 = xor i32 %274, %266
  %276 = lshr i32 %275, 4
  %277 = trunc i32 %276 to i8
  %278 = and i8 %277, 1
  store i8 %278, i8* %53, align 1, !tbaa !2451
  %279 = icmp eq i32 %266, 0
  %280 = zext i1 %279 to i8
  store i8 %280, i8* %54, align 1, !tbaa !2448
  %281 = lshr i32 %266, 31
  %282 = trunc i32 %281 to i8
  store i8 %282, i8* %55, align 1, !tbaa !2449
  %283 = lshr i32 %265, 31
  %284 = xor i32 %283, %260
  %285 = xor i32 %281, %260
  %286 = add nuw nsw i32 %285, %284
  %287 = icmp eq i32 %286, 2
  %288 = zext i1 %287 to i8
  store i8 %288, i8* %56, align 1, !tbaa !2450
  %289 = icmp ne i8 %282, 0
  %290 = xor i1 %289, %287
  %.v = select i1 %290, i64 15, i64 101
  %291 = add i64 %241, %.v
  %292 = add i64 %291, 3
  store i64 %292, i64* %PC, align 8
  br i1 %290, label %block_4011f5, label %block_40124b

block_40123d:                                     ; preds = %block_401205
  %293 = add i64 %3199, 3
  store i64 %293, i64* %PC, align 8
  %294 = load i32, i32* %3171, align 4
  %295 = shl i32 %294, 1
  %296 = icmp slt i32 %294, 0
  %297 = icmp slt i32 %295, 0
  %298 = xor i1 %296, %297
  %299 = zext i32 %295 to i64
  store i64 %299, i64* %RAX, align 8, !tbaa !2428
  %.lobit = lshr i32 %294, 31
  %300 = trunc i32 %.lobit to i8
  store i8 %300, i8* %51, align 1, !tbaa !2432
  %301 = and i32 %295, 254
  %302 = tail call i32 @llvm.ctpop.i32(i32 %301) #10
  %303 = trunc i32 %302 to i8
  %304 = and i8 %303, 1
  %305 = xor i8 %304, 1
  store i8 %305, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %306 = icmp eq i32 %295, 0
  %307 = zext i1 %306 to i8
  store i8 %307, i8* %54, align 1, !tbaa !2432
  %308 = lshr i32 %294, 30
  %309 = trunc i32 %308 to i8
  %310 = and i8 %309, 1
  store i8 %310, i8* %55, align 1, !tbaa !2432
  %311 = zext i1 %298 to i8
  store i8 %311, i8* %56, align 1, !tbaa !2432
  %312 = add i64 %3199, 9
  store i64 %312, i64* %PC, align 8
  store i32 %295, i32* %3171, align 4
  %313 = load i64, i64* %PC, align 8
  %314 = add i64 %313, -96
  store i64 %314, i64* %57, align 8, !tbaa !2428
  br label %block_4011e6

block_401664:                                     ; preds = %block_40124b
  store i32 1, i32* %429, align 4
  %315 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %316 = bitcast i64* %315 to double*
  %.pre6 = load i64, i64* %PC, align 8
  br label %block_40166b

block_401832:                                     ; preds = %block_40165f, %block_40182d
  %.sink = phi i64 [ %356, %block_40165f ], [ %326, %block_40182d ]
  %317 = add i64 %.sink, 1
  store i64 %317, i64* %PC, align 8
  %318 = load i64, i64* %7, align 8, !tbaa !2428
  %319 = add i64 %318, 8
  %320 = inttoptr i64 %318 to i64*
  %321 = load i64, i64* %320, align 8
  store i64 %321, i64* %RBP, align 8, !tbaa !2428
  store i64 %319, i64* %7, align 8, !tbaa !2428
  %322 = add i64 %.sink, 2
  store i64 %322, i64* %PC, align 8
  %323 = inttoptr i64 %319 to i64*
  %324 = load i64, i64* %323, align 8
  store i64 %324, i64* %57, align 8, !tbaa !2428
  %325 = add i64 %318, 16
  store i64 %325, i64* %7, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_40182d:                                     ; preds = %block_40166b
  %326 = add i64 %159, 5
  br label %block_401832

block_40181a:                                     ; preds = %block_40167e
  %327 = add i64 %197, 8
  store i64 %327, i64* %PC, align 8
  %328 = load i32, i32* %169, align 4
  %329 = add i32 %328, 1
  %330 = zext i32 %329 to i64
  store i64 %330, i64* %RAX, align 8, !tbaa !2428
  %331 = icmp eq i32 %328, -1
  %332 = icmp eq i32 %329, 0
  %333 = or i1 %331, %332
  %334 = zext i1 %333 to i8
  store i8 %334, i8* %51, align 1, !tbaa !2433
  %335 = and i32 %329, 255
  %336 = tail call i32 @llvm.ctpop.i32(i32 %335) #10
  %337 = trunc i32 %336 to i8
  %338 = and i8 %337, 1
  %339 = xor i8 %338, 1
  store i8 %339, i8* %52, align 1, !tbaa !2447
  %340 = xor i32 %328, %329
  %341 = lshr i32 %340, 4
  %342 = trunc i32 %341 to i8
  %343 = and i8 %342, 1
  store i8 %343, i8* %53, align 1, !tbaa !2451
  %344 = icmp eq i32 %329, 0
  %345 = zext i1 %344 to i8
  store i8 %345, i8* %54, align 1, !tbaa !2448
  %346 = lshr i32 %329, 31
  %347 = trunc i32 %346 to i8
  store i8 %347, i8* %55, align 1, !tbaa !2449
  %348 = lshr i32 %328, 31
  %349 = xor i32 %346, %348
  %350 = add nuw nsw i32 %349, %346
  %351 = icmp eq i32 %350, 2
  %352 = zext i1 %351 to i8
  store i8 %352, i8* %56, align 1, !tbaa !2450
  %353 = add i64 %197, 14
  store i64 %353, i64* %PC, align 8
  store i32 %329, i32* %169, align 4
  %354 = load i64, i64* %PC, align 8
  %355 = add i64 %354, -445
  store i64 %355, i64* %57, align 8, !tbaa !2428
  br label %block_40166b

block_40165f:                                     ; preds = %block_40126a
  %356 = add i64 %235, 467
  br label %block_401832

block_40124b:                                     ; preds = %block_4011e6
  %357 = load i32, i32* %245, align 4
  %358 = shl i32 %357, 1
  %359 = icmp slt i32 %357, 0
  %360 = icmp slt i32 %358, 0
  %361 = xor i1 %359, %360
  %362 = zext i32 %358 to i64
  store i64 %362, i64* %RAX, align 8, !tbaa !2428
  %.lobit10 = lshr i32 %357, 31
  %363 = trunc i32 %.lobit10 to i8
  store i8 %363, i8* %51, align 1, !tbaa !2432
  %364 = and i32 %358, 254
  %365 = tail call i32 @llvm.ctpop.i32(i32 %364) #10
  %366 = trunc i32 %365 to i8
  %367 = and i8 %366, 1
  %368 = xor i8 %367, 1
  store i8 %368, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %369 = icmp eq i32 %358, 0
  %370 = zext i1 %369 to i8
  store i8 %370, i8* %54, align 1, !tbaa !2432
  %371 = lshr i32 %357, 30
  %372 = trunc i32 %371 to i8
  %373 = and i8 %372, 1
  store i8 %373, i8* %55, align 1, !tbaa !2432
  %374 = zext i1 %361 to i8
  store i8 %374, i8* %56, align 1, !tbaa !2432
  %375 = add i64 %242, -52
  %376 = add i64 %291, 9
  store i64 %376, i64* %PC, align 8
  %377 = inttoptr i64 %375 to i32*
  store i32 %358, i32* %377, align 4
  %378 = load i64, i64* %RBP, align 8
  %379 = add i64 %378, -48
  %380 = load i64, i64* %PC, align 8
  %381 = add i64 %380, 3
  store i64 %381, i64* %PC, align 8
  %382 = inttoptr i64 %379 to i32*
  %383 = load i32, i32* %382, align 4
  %384 = shl i32 %383, 3
  %385 = zext i32 %384 to i64
  store i64 %385, i64* %RAX, align 8, !tbaa !2428
  %386 = lshr i32 %383, 29
  %387 = trunc i32 %386 to i8
  %388 = and i8 %387, 1
  store i8 %388, i8* %51, align 1, !tbaa !2432
  %389 = and i32 %384, 248
  %390 = tail call i32 @llvm.ctpop.i32(i32 %389) #10
  %391 = trunc i32 %390 to i8
  %392 = and i8 %391, 1
  %393 = xor i8 %392, 1
  store i8 %393, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %394 = icmp eq i32 %384, 0
  %395 = zext i1 %394 to i8
  store i8 %395, i8* %54, align 1, !tbaa !2432
  %396 = lshr i32 %383, 28
  %397 = and i32 %396, 1
  %398 = trunc i32 %397 to i8
  store i8 %398, i8* %55, align 1, !tbaa !2432
  store i8 0, i8* %56, align 1, !tbaa !2432
  %399 = add i64 %378, -44
  %400 = add i64 %380, 9
  store i64 %400, i64* %PC, align 8
  %401 = inttoptr i64 %399 to i32*
  %402 = load i32, i32* %401, align 4
  %403 = sub i32 %384, %402
  %404 = icmp ult i32 %384, %402
  %405 = zext i1 %404 to i8
  store i8 %405, i8* %51, align 1, !tbaa !2433
  %406 = and i32 %403, 255
  %407 = tail call i32 @llvm.ctpop.i32(i32 %406) #10
  %408 = trunc i32 %407 to i8
  %409 = and i8 %408, 1
  %410 = xor i8 %409, 1
  store i8 %410, i8* %52, align 1, !tbaa !2447
  %411 = xor i32 %402, %384
  %412 = xor i32 %411, %403
  %413 = lshr i32 %412, 4
  %414 = trunc i32 %413 to i8
  %415 = and i8 %414, 1
  store i8 %415, i8* %53, align 1, !tbaa !2451
  %416 = icmp eq i32 %403, 0
  %417 = zext i1 %416 to i8
  store i8 %417, i8* %54, align 1, !tbaa !2448
  %418 = lshr i32 %403, 31
  %419 = trunc i32 %418 to i8
  store i8 %419, i8* %55, align 1, !tbaa !2449
  %420 = lshr i32 %402, 31
  %421 = xor i32 %420, %397
  %422 = xor i32 %418, %397
  %423 = add nuw nsw i32 %422, %421
  %424 = icmp eq i32 %423, 2
  %425 = zext i1 %424 to i8
  store i8 %425, i8* %56, align 1, !tbaa !2450
  %.v12 = select i1 %416, i64 15, i64 1040
  %426 = add i64 %380, %.v12
  %427 = add i64 %378, -36
  %428 = add i64 %426, 7
  store i64 %428, i64* %PC, align 8
  %429 = inttoptr i64 %427 to i32*
  br i1 %416, label %block_401263, label %block_401664

block_401211:                                     ; preds = %block_401205
  %430 = add i64 %3163, -16
  %431 = add i64 %3199, 4
  store i64 %431, i64* %PC, align 8
  %432 = inttoptr i64 %430 to i64*
  %433 = load i64, i64* %432, align 8
  store i64 %433, i64* %RAX, align 8, !tbaa !2428
  %434 = add i64 %3199, 8
  store i64 %434, i64* %PC, align 8
  %435 = load i32, i32* %3166, align 4
  %436 = sext i32 %435 to i64
  store i64 %436, i64* %RCX, align 8, !tbaa !2428
  %437 = shl nsw i64 %436, 2
  %438 = add i64 %437, %433
  %439 = add i64 %3199, 11
  store i64 %439, i64* %PC, align 8
  %440 = inttoptr i64 %438 to i32*
  %441 = load i32, i32* %440, align 4
  %442 = zext i32 %441 to i64
  store i64 %442, i64* %RDX, align 8, !tbaa !2428
  %443 = add i64 %3163, -44
  %444 = add i64 %3199, 14
  store i64 %444, i64* %PC, align 8
  %445 = inttoptr i64 %443 to i32*
  %446 = load i32, i32* %445, align 4
  %447 = add i32 %446, %441
  %448 = zext i32 %447 to i64
  store i64 %448, i64* %RDX, align 8, !tbaa !2428
  %449 = icmp ult i32 %447, %441
  %450 = icmp ult i32 %447, %446
  %451 = or i1 %449, %450
  %452 = zext i1 %451 to i8
  store i8 %452, i8* %51, align 1, !tbaa !2433
  %453 = and i32 %447, 255
  %454 = tail call i32 @llvm.ctpop.i32(i32 %453) #10
  %455 = trunc i32 %454 to i8
  %456 = and i8 %455, 1
  %457 = xor i8 %456, 1
  store i8 %457, i8* %52, align 1, !tbaa !2447
  %458 = xor i32 %446, %441
  %459 = xor i32 %458, %447
  %460 = lshr i32 %459, 4
  %461 = trunc i32 %460 to i8
  %462 = and i8 %461, 1
  store i8 %462, i8* %53, align 1, !tbaa !2451
  %463 = icmp eq i32 %447, 0
  %464 = zext i1 %463 to i8
  store i8 %464, i8* %54, align 1, !tbaa !2448
  %465 = lshr i32 %447, 31
  %466 = trunc i32 %465 to i8
  store i8 %466, i8* %55, align 1, !tbaa !2449
  %467 = lshr i32 %441, 31
  %468 = lshr i32 %446, 31
  %469 = xor i32 %465, %467
  %470 = xor i32 %465, %468
  %471 = add nuw nsw i32 %469, %470
  %472 = icmp eq i32 %471, 2
  %473 = zext i1 %472 to i8
  store i8 %473, i8* %56, align 1, !tbaa !2450
  %474 = add i64 %3199, 18
  store i64 %474, i64* %PC, align 8
  %475 = load i64, i64* %432, align 8
  store i64 %475, i64* %RAX, align 8, !tbaa !2428
  %476 = add i64 %3199, 21
  store i64 %476, i64* %PC, align 8
  %477 = load i32, i32* %3171, align 4
  %478 = zext i32 %477 to i64
  store i64 %478, i64* %RSI, align 8, !tbaa !2428
  %479 = add i64 %3199, 24
  store i64 %479, i64* %PC, align 8
  %480 = load i32, i32* %3166, align 4
  %481 = add i32 %480, %477
  %482 = zext i32 %481 to i64
  store i64 %482, i64* %RSI, align 8, !tbaa !2428
  %483 = icmp ult i32 %481, %477
  %484 = icmp ult i32 %481, %480
  %485 = or i1 %483, %484
  %486 = zext i1 %485 to i8
  store i8 %486, i8* %51, align 1, !tbaa !2433
  %487 = and i32 %481, 255
  %488 = tail call i32 @llvm.ctpop.i32(i32 %487) #10
  %489 = trunc i32 %488 to i8
  %490 = and i8 %489, 1
  %491 = xor i8 %490, 1
  store i8 %491, i8* %52, align 1, !tbaa !2447
  %492 = xor i32 %480, %477
  %493 = xor i32 %492, %481
  %494 = lshr i32 %493, 4
  %495 = trunc i32 %494 to i8
  %496 = and i8 %495, 1
  store i8 %496, i8* %53, align 1, !tbaa !2451
  %497 = icmp eq i32 %481, 0
  %498 = zext i1 %497 to i8
  store i8 %498, i8* %54, align 1, !tbaa !2448
  %499 = lshr i32 %481, 31
  %500 = trunc i32 %499 to i8
  store i8 %500, i8* %55, align 1, !tbaa !2449
  %501 = lshr i32 %477, 31
  %502 = lshr i32 %480, 31
  %503 = xor i32 %499, %501
  %504 = xor i32 %499, %502
  %505 = add nuw nsw i32 %503, %504
  %506 = icmp eq i32 %505, 2
  %507 = zext i1 %506 to i8
  store i8 %507, i8* %56, align 1, !tbaa !2450
  %508 = sext i32 %481 to i64
  store i64 %508, i64* %RCX, align 8, !tbaa !2428
  %509 = shl nsw i64 %508, 2
  %510 = add i64 %509, %475
  %511 = add i64 %3199, 30
  store i64 %511, i64* %PC, align 8
  %512 = inttoptr i64 %510 to i32*
  store i32 %447, i32* %512, align 4
  %513 = load i64, i64* %RBP, align 8
  %514 = add i64 %513, -28
  %515 = load i64, i64* %PC, align 8
  %516 = add i64 %515, 3
  store i64 %516, i64* %PC, align 8
  %517 = inttoptr i64 %514 to i32*
  %518 = load i32, i32* %517, align 4
  %519 = add i32 %518, 1
  %520 = zext i32 %519 to i64
  store i64 %520, i64* %RAX, align 8, !tbaa !2428
  %521 = icmp eq i32 %518, -1
  %522 = icmp eq i32 %519, 0
  %523 = or i1 %521, %522
  %524 = zext i1 %523 to i8
  store i8 %524, i8* %51, align 1, !tbaa !2433
  %525 = and i32 %519, 255
  %526 = tail call i32 @llvm.ctpop.i32(i32 %525) #10
  %527 = trunc i32 %526 to i8
  %528 = and i8 %527, 1
  %529 = xor i8 %528, 1
  store i8 %529, i8* %52, align 1, !tbaa !2447
  %530 = xor i32 %518, %519
  %531 = lshr i32 %530, 4
  %532 = trunc i32 %531 to i8
  %533 = and i8 %532, 1
  store i8 %533, i8* %53, align 1, !tbaa !2451
  %534 = icmp eq i32 %519, 0
  %535 = zext i1 %534 to i8
  store i8 %535, i8* %54, align 1, !tbaa !2448
  %536 = lshr i32 %519, 31
  %537 = trunc i32 %536 to i8
  store i8 %537, i8* %55, align 1, !tbaa !2449
  %538 = lshr i32 %518, 31
  %539 = xor i32 %536, %538
  %540 = add nuw nsw i32 %539, %536
  %541 = icmp eq i32 %540, 2
  %542 = zext i1 %541 to i8
  store i8 %542, i8* %56, align 1, !tbaa !2450
  %543 = add i64 %515, 9
  store i64 %543, i64* %PC, align 8
  store i32 %519, i32* %517, align 4
  %544 = load i64, i64* %PC, align 8
  %545 = add i64 %544, -51
  store i64 %545, i64* %57, align 8, !tbaa !2428
  br label %block_401205

block_40158d:                                     ; preds = %block_40127d
  %546 = load i32, i32* %67, align 4
  %547 = shl i32 %546, 1
  %548 = icmp slt i32 %546, 0
  %549 = icmp slt i32 %547, 0
  %550 = xor i1 %548, %549
  %551 = zext i32 %547 to i64
  store i64 %551, i64* %RAX, align 8, !tbaa !2428
  %.lobit19 = lshr i32 %546, 31
  %552 = trunc i32 %.lobit19 to i8
  store i8 %552, i8* %51, align 1, !tbaa !2432
  %553 = and i32 %547, 254
  %554 = tail call i32 @llvm.ctpop.i32(i32 %553) #10
  %555 = trunc i32 %554 to i8
  %556 = and i8 %555, 1
  %557 = xor i8 %556, 1
  store i8 %557, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %558 = icmp eq i32 %547, 0
  %559 = zext i1 %558 to i8
  store i8 %559, i8* %54, align 1, !tbaa !2432
  %560 = lshr i32 %546, 30
  %561 = and i32 %560, 1
  %562 = trunc i32 %561 to i8
  store i8 %562, i8* %55, align 1, !tbaa !2432
  %563 = zext i1 %550 to i8
  store i8 %563, i8* %56, align 1, !tbaa !2432
  %564 = add i64 %59, -52
  %565 = add i64 %95, 9
  store i64 %565, i64* %PC, align 8
  %566 = inttoptr i64 %564 to i32*
  %567 = load i32, i32* %566, align 4
  %568 = add i32 %567, %547
  %569 = zext i32 %568 to i64
  store i64 %569, i64* %RAX, align 8, !tbaa !2428
  %570 = icmp ult i32 %568, %547
  %571 = icmp ult i32 %568, %567
  %572 = or i1 %570, %571
  %573 = zext i1 %572 to i8
  store i8 %573, i8* %51, align 1, !tbaa !2433
  %574 = and i32 %568, 255
  %575 = tail call i32 @llvm.ctpop.i32(i32 %574) #10
  %576 = trunc i32 %575 to i8
  %577 = and i8 %576, 1
  %578 = xor i8 %577, 1
  store i8 %578, i8* %52, align 1, !tbaa !2447
  %579 = xor i32 %567, %547
  %580 = xor i32 %579, %568
  %581 = lshr i32 %580, 4
  %582 = trunc i32 %581 to i8
  %583 = and i8 %582, 1
  store i8 %583, i8* %53, align 1, !tbaa !2451
  %584 = icmp eq i32 %568, 0
  %585 = zext i1 %584 to i8
  store i8 %585, i8* %54, align 1, !tbaa !2448
  %586 = lshr i32 %568, 31
  %587 = trunc i32 %586 to i8
  store i8 %587, i8* %55, align 1, !tbaa !2449
  %588 = lshr i32 %567, 31
  %589 = xor i32 %586, %561
  %590 = xor i32 %586, %588
  %591 = add nuw nsw i32 %589, %590
  %592 = icmp eq i32 %591, 2
  %593 = zext i1 %592 to i8
  store i8 %593, i8* %56, align 1, !tbaa !2450
  %594 = add i64 %59, -16
  %595 = add i64 %95, 13
  store i64 %595, i64* %PC, align 8
  %596 = inttoptr i64 %594 to i64*
  %597 = load i64, i64* %596, align 8
  store i64 %597, i64* %RCX, align 8, !tbaa !2428
  %598 = add i64 %95, 17
  store i64 %598, i64* %PC, align 8
  %599 = load i32, i32* %67, align 4
  %600 = sext i32 %599 to i64
  store i64 %600, i64* %RDX, align 8, !tbaa !2428
  %601 = shl nsw i64 %600, 2
  %602 = add i64 %601, %597
  %603 = add i64 %95, 20
  store i64 %603, i64* %PC, align 8
  %604 = inttoptr i64 %602 to i32*
  %605 = load i32, i32* %604, align 4
  %606 = add i32 %605, %568
  %607 = zext i32 %606 to i64
  store i64 %607, i64* %RAX, align 8, !tbaa !2428
  %608 = icmp ult i32 %606, %568
  %609 = icmp ult i32 %606, %605
  %610 = or i1 %608, %609
  %611 = zext i1 %610 to i8
  store i8 %611, i8* %51, align 1, !tbaa !2433
  %612 = and i32 %606, 255
  %613 = tail call i32 @llvm.ctpop.i32(i32 %612) #10
  %614 = trunc i32 %613 to i8
  %615 = and i8 %614, 1
  %616 = xor i8 %615, 1
  store i8 %616, i8* %52, align 1, !tbaa !2447
  %617 = xor i32 %605, %568
  %618 = xor i32 %617, %606
  %619 = lshr i32 %618, 4
  %620 = trunc i32 %619 to i8
  %621 = and i8 %620, 1
  store i8 %621, i8* %53, align 1, !tbaa !2451
  %622 = icmp eq i32 %606, 0
  %623 = zext i1 %622 to i8
  store i8 %623, i8* %54, align 1, !tbaa !2448
  %624 = lshr i32 %606, 31
  %625 = trunc i32 %624 to i8
  store i8 %625, i8* %55, align 1, !tbaa !2449
  %626 = lshr i32 %605, 31
  %627 = xor i32 %624, %586
  %628 = xor i32 %624, %626
  %629 = add nuw nsw i32 %627, %628
  %630 = icmp eq i32 %629, 2
  %631 = zext i1 %630 to i8
  store i8 %631, i8* %56, align 1, !tbaa !2450
  %632 = load i64, i64* %RBP, align 8
  %633 = add i64 %632, -32
  %634 = add i64 %95, 23
  store i64 %634, i64* %PC, align 8
  %635 = inttoptr i64 %633 to i32*
  store i32 %606, i32* %635, align 4
  %636 = load i64, i64* %RBP, align 8
  %637 = add i64 %636, -32
  %638 = load i64, i64* %PC, align 8
  %639 = add i64 %638, 3
  store i64 %639, i64* %PC, align 8
  %640 = inttoptr i64 %637 to i32*
  %641 = load i32, i32* %640, align 4
  %642 = zext i32 %641 to i64
  store i64 %642, i64* %RAX, align 8, !tbaa !2428
  %643 = add i64 %636, -52
  %644 = add i64 %638, 6
  store i64 %644, i64* %PC, align 8
  %645 = inttoptr i64 %643 to i32*
  %646 = load i32, i32* %645, align 4
  %647 = add i32 %646, %641
  %648 = zext i32 %647 to i64
  store i64 %648, i64* %RAX, align 8, !tbaa !2428
  %649 = icmp ult i32 %647, %641
  %650 = icmp ult i32 %647, %646
  %651 = or i1 %649, %650
  %652 = zext i1 %651 to i8
  store i8 %652, i8* %51, align 1, !tbaa !2433
  %653 = and i32 %647, 255
  %654 = tail call i32 @llvm.ctpop.i32(i32 %653) #10
  %655 = trunc i32 %654 to i8
  %656 = and i8 %655, 1
  %657 = xor i8 %656, 1
  store i8 %657, i8* %52, align 1, !tbaa !2447
  %658 = xor i32 %646, %641
  %659 = xor i32 %658, %647
  %660 = lshr i32 %659, 4
  %661 = trunc i32 %660 to i8
  %662 = and i8 %661, 1
  store i8 %662, i8* %53, align 1, !tbaa !2451
  %663 = icmp eq i32 %647, 0
  %664 = zext i1 %663 to i8
  store i8 %664, i8* %54, align 1, !tbaa !2448
  %665 = lshr i32 %647, 31
  %666 = trunc i32 %665 to i8
  store i8 %666, i8* %55, align 1, !tbaa !2449
  %667 = lshr i32 %641, 31
  %668 = lshr i32 %646, 31
  %669 = xor i32 %665, %667
  %670 = xor i32 %665, %668
  %671 = add nuw nsw i32 %669, %670
  %672 = icmp eq i32 %671, 2
  %673 = zext i1 %672 to i8
  store i8 %673, i8* %56, align 1, !tbaa !2450
  %674 = add i64 %636, -40
  %675 = add i64 %638, 9
  store i64 %675, i64* %PC, align 8
  %676 = inttoptr i64 %674 to i32*
  store i32 %647, i32* %676, align 4
  %677 = load i64, i64* %RBP, align 8
  %678 = add i64 %677, -24
  %679 = load i64, i64* %PC, align 8
  %680 = add i64 %679, 4
  store i64 %680, i64* %PC, align 8
  %681 = inttoptr i64 %678 to i64*
  %682 = load i64, i64* %681, align 8
  store i64 %682, i64* %RCX, align 8, !tbaa !2428
  %683 = add i64 %677, -32
  %684 = add i64 %679, 8
  store i64 %684, i64* %PC, align 8
  %685 = inttoptr i64 %683 to i32*
  %686 = load i32, i32* %685, align 4
  %687 = sext i32 %686 to i64
  store i64 %687, i64* %RDX, align 8, !tbaa !2428
  %688 = shl nsw i64 %687, 3
  %689 = add i64 %688, %682
  %690 = add i64 %679, 13
  store i64 %690, i64* %PC, align 8
  %691 = inttoptr i64 %689 to i64*
  %692 = load i64, i64* %691, align 8
  %693 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %692, i64* %693, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %694 = add i64 %677, -64
  %695 = add i64 %679, 18
  store i64 %695, i64* %PC, align 8
  %696 = inttoptr i64 %694 to i64*
  store i64 %692, i64* %696, align 8
  %697 = load i64, i64* %RBP, align 8
  %698 = add i64 %697, -24
  %699 = load i64, i64* %PC, align 8
  %700 = add i64 %699, 4
  store i64 %700, i64* %PC, align 8
  %701 = inttoptr i64 %698 to i64*
  %702 = load i64, i64* %701, align 8
  store i64 %702, i64* %RCX, align 8, !tbaa !2428
  %703 = add i64 %697, -32
  %704 = add i64 %699, 7
  store i64 %704, i64* %PC, align 8
  %705 = inttoptr i64 %703 to i32*
  %706 = load i32, i32* %705, align 4
  %707 = add i32 %706, 1
  %708 = zext i32 %707 to i64
  store i64 %708, i64* %RAX, align 8, !tbaa !2428
  %709 = icmp eq i32 %706, -1
  %710 = icmp eq i32 %707, 0
  %711 = or i1 %709, %710
  %712 = zext i1 %711 to i8
  store i8 %712, i8* %51, align 1, !tbaa !2433
  %713 = and i32 %707, 255
  %714 = tail call i32 @llvm.ctpop.i32(i32 %713) #10
  %715 = trunc i32 %714 to i8
  %716 = and i8 %715, 1
  %717 = xor i8 %716, 1
  store i8 %717, i8* %52, align 1, !tbaa !2447
  %718 = xor i32 %706, %707
  %719 = lshr i32 %718, 4
  %720 = trunc i32 %719 to i8
  %721 = and i8 %720, 1
  store i8 %721, i8* %53, align 1, !tbaa !2451
  %722 = icmp eq i32 %707, 0
  %723 = zext i1 %722 to i8
  store i8 %723, i8* %54, align 1, !tbaa !2448
  %724 = lshr i32 %707, 31
  %725 = trunc i32 %724 to i8
  store i8 %725, i8* %55, align 1, !tbaa !2449
  %726 = lshr i32 %706, 31
  %727 = xor i32 %724, %726
  %728 = add nuw nsw i32 %727, %724
  %729 = icmp eq i32 %728, 2
  %730 = zext i1 %729 to i8
  store i8 %730, i8* %56, align 1, !tbaa !2450
  %731 = sext i32 %707 to i64
  store i64 %731, i64* %RDX, align 8, !tbaa !2428
  %732 = shl nsw i64 %731, 3
  %733 = add i64 %732, %702
  %734 = add i64 %699, 18
  store i64 %734, i64* %PC, align 8
  %735 = inttoptr i64 %733 to i64*
  %736 = load i64, i64* %735, align 8
  %737 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %736, i64* %737, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %738 = add i64 %697, -72
  %739 = add i64 %699, 23
  store i64 %739, i64* %PC, align 8
  %740 = inttoptr i64 %738 to i64*
  store i64 %736, i64* %740, align 8
  %741 = load i64, i64* %RBP, align 8
  %742 = add i64 %741, -24
  %743 = load i64, i64* %PC, align 8
  %744 = add i64 %743, 4
  store i64 %744, i64* %PC, align 8
  %745 = inttoptr i64 %742 to i64*
  %746 = load i64, i64* %745, align 8
  store i64 %746, i64* %RCX, align 8, !tbaa !2428
  %747 = add i64 %741, -40
  %748 = add i64 %743, 8
  store i64 %748, i64* %PC, align 8
  %749 = inttoptr i64 %747 to i32*
  %750 = load i32, i32* %749, align 4
  %751 = sext i32 %750 to i64
  store i64 %751, i64* %RDX, align 8, !tbaa !2428
  %752 = shl nsw i64 %751, 3
  %753 = add i64 %752, %746
  %754 = add i64 %743, 13
  store i64 %754, i64* %PC, align 8
  %755 = inttoptr i64 %753 to i64*
  %756 = load i64, i64* %755, align 8
  %757 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %756, i64* %757, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %758 = add i64 %741, -80
  %759 = add i64 %743, 18
  store i64 %759, i64* %PC, align 8
  %760 = inttoptr i64 %758 to i64*
  store i64 %756, i64* %760, align 8
  %761 = load i64, i64* %RBP, align 8
  %762 = add i64 %761, -24
  %763 = load i64, i64* %PC, align 8
  %764 = add i64 %763, 4
  store i64 %764, i64* %PC, align 8
  %765 = inttoptr i64 %762 to i64*
  %766 = load i64, i64* %765, align 8
  store i64 %766, i64* %RCX, align 8, !tbaa !2428
  %767 = add i64 %761, -40
  %768 = add i64 %763, 7
  store i64 %768, i64* %PC, align 8
  %769 = inttoptr i64 %767 to i32*
  %770 = load i32, i32* %769, align 4
  %771 = add i32 %770, 1
  %772 = zext i32 %771 to i64
  store i64 %772, i64* %RAX, align 8, !tbaa !2428
  %773 = icmp eq i32 %770, -1
  %774 = icmp eq i32 %771, 0
  %775 = or i1 %773, %774
  %776 = zext i1 %775 to i8
  store i8 %776, i8* %51, align 1, !tbaa !2433
  %777 = and i32 %771, 255
  %778 = tail call i32 @llvm.ctpop.i32(i32 %777) #10
  %779 = trunc i32 %778 to i8
  %780 = and i8 %779, 1
  %781 = xor i8 %780, 1
  store i8 %781, i8* %52, align 1, !tbaa !2447
  %782 = xor i32 %770, %771
  %783 = lshr i32 %782, 4
  %784 = trunc i32 %783 to i8
  %785 = and i8 %784, 1
  store i8 %785, i8* %53, align 1, !tbaa !2451
  %786 = icmp eq i32 %771, 0
  %787 = zext i1 %786 to i8
  store i8 %787, i8* %54, align 1, !tbaa !2448
  %788 = lshr i32 %771, 31
  %789 = trunc i32 %788 to i8
  store i8 %789, i8* %55, align 1, !tbaa !2449
  %790 = lshr i32 %770, 31
  %791 = xor i32 %788, %790
  %792 = add nuw nsw i32 %791, %788
  %793 = icmp eq i32 %792, 2
  %794 = zext i1 %793 to i8
  store i8 %794, i8* %56, align 1, !tbaa !2450
  %795 = sext i32 %771 to i64
  store i64 %795, i64* %RDX, align 8, !tbaa !2428
  %796 = shl nsw i64 %795, 3
  %797 = add i64 %796, %766
  %798 = add i64 %763, 18
  store i64 %798, i64* %PC, align 8
  %799 = inttoptr i64 %797 to i64*
  %800 = load i64, i64* %799, align 8
  %801 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %800, i64* %801, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %802 = add i64 %761, -88
  %803 = add i64 %763, 23
  store i64 %803, i64* %PC, align 8
  %804 = inttoptr i64 %802 to i64*
  store i64 %800, i64* %804, align 8
  %805 = load i64, i64* %RBP, align 8
  %806 = add i64 %805, -80
  %807 = load i64, i64* %PC, align 8
  %808 = add i64 %807, 5
  store i64 %808, i64* %PC, align 8
  %809 = inttoptr i64 %806 to i64*
  %810 = load i64, i64* %809, align 8
  %811 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %810, i64* %811, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %812 = add i64 %805, -24
  %813 = add i64 %807, 9
  store i64 %813, i64* %PC, align 8
  %814 = inttoptr i64 %812 to i64*
  %815 = load i64, i64* %814, align 8
  store i64 %815, i64* %RCX, align 8, !tbaa !2428
  %816 = add i64 %805, -32
  %817 = add i64 %807, 13
  store i64 %817, i64* %PC, align 8
  %818 = inttoptr i64 %816 to i32*
  %819 = load i32, i32* %818, align 4
  %820 = sext i32 %819 to i64
  store i64 %820, i64* %RDX, align 8, !tbaa !2428
  %821 = shl nsw i64 %820, 3
  %822 = add i64 %821, %815
  %823 = add i64 %807, 18
  store i64 %823, i64* %PC, align 8
  %824 = inttoptr i64 %822 to i64*
  store i64 %810, i64* %824, align 8
  %825 = load i64, i64* %RBP, align 8
  %826 = add i64 %825, -88
  %827 = load i64, i64* %PC, align 8
  %828 = add i64 %827, 5
  store i64 %828, i64* %PC, align 8
  %829 = inttoptr i64 %826 to i64*
  %830 = load i64, i64* %829, align 8
  %831 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %830, i64* %831, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %832 = add i64 %825, -24
  %833 = add i64 %827, 9
  store i64 %833, i64* %PC, align 8
  %834 = inttoptr i64 %832 to i64*
  %835 = load i64, i64* %834, align 8
  store i64 %835, i64* %RCX, align 8, !tbaa !2428
  %836 = add i64 %825, -32
  %837 = add i64 %827, 12
  store i64 %837, i64* %PC, align 8
  %838 = inttoptr i64 %836 to i32*
  %839 = load i32, i32* %838, align 4
  %840 = add i32 %839, 1
  %841 = zext i32 %840 to i64
  store i64 %841, i64* %RAX, align 8, !tbaa !2428
  %842 = icmp eq i32 %839, -1
  %843 = icmp eq i32 %840, 0
  %844 = or i1 %842, %843
  %845 = zext i1 %844 to i8
  store i8 %845, i8* %51, align 1, !tbaa !2433
  %846 = and i32 %840, 255
  %847 = tail call i32 @llvm.ctpop.i32(i32 %846) #10
  %848 = trunc i32 %847 to i8
  %849 = and i8 %848, 1
  %850 = xor i8 %849, 1
  store i8 %850, i8* %52, align 1, !tbaa !2447
  %851 = xor i32 %839, %840
  %852 = lshr i32 %851, 4
  %853 = trunc i32 %852 to i8
  %854 = and i8 %853, 1
  store i8 %854, i8* %53, align 1, !tbaa !2451
  %855 = icmp eq i32 %840, 0
  %856 = zext i1 %855 to i8
  store i8 %856, i8* %54, align 1, !tbaa !2448
  %857 = lshr i32 %840, 31
  %858 = trunc i32 %857 to i8
  store i8 %858, i8* %55, align 1, !tbaa !2449
  %859 = lshr i32 %839, 31
  %860 = xor i32 %857, %859
  %861 = add nuw nsw i32 %860, %857
  %862 = icmp eq i32 %861, 2
  %863 = zext i1 %862 to i8
  store i8 %863, i8* %56, align 1, !tbaa !2450
  %864 = sext i32 %840 to i64
  store i64 %864, i64* %RDX, align 8, !tbaa !2428
  %865 = shl nsw i64 %864, 3
  %866 = add i64 %865, %835
  %867 = add i64 %827, 23
  store i64 %867, i64* %PC, align 8
  %868 = inttoptr i64 %866 to i64*
  store i64 %830, i64* %868, align 8
  %869 = load i64, i64* %RBP, align 8
  %870 = add i64 %869, -64
  %871 = load i64, i64* %PC, align 8
  %872 = add i64 %871, 5
  store i64 %872, i64* %PC, align 8
  %873 = inttoptr i64 %870 to i64*
  %874 = load i64, i64* %873, align 8
  %875 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %874, i64* %875, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %876 = add i64 %869, -24
  %877 = add i64 %871, 9
  store i64 %877, i64* %PC, align 8
  %878 = inttoptr i64 %876 to i64*
  %879 = load i64, i64* %878, align 8
  store i64 %879, i64* %RCX, align 8, !tbaa !2428
  %880 = add i64 %869, -40
  %881 = add i64 %871, 13
  store i64 %881, i64* %PC, align 8
  %882 = inttoptr i64 %880 to i32*
  %883 = load i32, i32* %882, align 4
  %884 = sext i32 %883 to i64
  store i64 %884, i64* %RDX, align 8, !tbaa !2428
  %885 = shl nsw i64 %884, 3
  %886 = add i64 %885, %879
  %887 = add i64 %871, 18
  store i64 %887, i64* %PC, align 8
  %888 = inttoptr i64 %886 to i64*
  store i64 %874, i64* %888, align 8
  %889 = load i64, i64* %RBP, align 8
  %890 = add i64 %889, -72
  %891 = load i64, i64* %PC, align 8
  %892 = add i64 %891, 5
  store i64 %892, i64* %PC, align 8
  %893 = inttoptr i64 %890 to i64*
  %894 = load i64, i64* %893, align 8
  %895 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %894, i64* %895, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %896 = add i64 %889, -24
  %897 = add i64 %891, 9
  store i64 %897, i64* %PC, align 8
  %898 = inttoptr i64 %896 to i64*
  %899 = load i64, i64* %898, align 8
  store i64 %899, i64* %RCX, align 8, !tbaa !2428
  %900 = add i64 %889, -40
  %901 = add i64 %891, 12
  store i64 %901, i64* %PC, align 8
  %902 = inttoptr i64 %900 to i32*
  %903 = load i32, i32* %902, align 4
  %904 = add i32 %903, 1
  %905 = zext i32 %904 to i64
  store i64 %905, i64* %RAX, align 8, !tbaa !2428
  %906 = icmp eq i32 %903, -1
  %907 = icmp eq i32 %904, 0
  %908 = or i1 %906, %907
  %909 = zext i1 %908 to i8
  store i8 %909, i8* %51, align 1, !tbaa !2433
  %910 = and i32 %904, 255
  %911 = tail call i32 @llvm.ctpop.i32(i32 %910) #10
  %912 = trunc i32 %911 to i8
  %913 = and i8 %912, 1
  %914 = xor i8 %913, 1
  store i8 %914, i8* %52, align 1, !tbaa !2447
  %915 = xor i32 %903, %904
  %916 = lshr i32 %915, 4
  %917 = trunc i32 %916 to i8
  %918 = and i8 %917, 1
  store i8 %918, i8* %53, align 1, !tbaa !2451
  %919 = icmp eq i32 %904, 0
  %920 = zext i1 %919 to i8
  store i8 %920, i8* %54, align 1, !tbaa !2448
  %921 = lshr i32 %904, 31
  %922 = trunc i32 %921 to i8
  store i8 %922, i8* %55, align 1, !tbaa !2449
  %923 = lshr i32 %903, 31
  %924 = xor i32 %921, %923
  %925 = add nuw nsw i32 %924, %921
  %926 = icmp eq i32 %925, 2
  %927 = zext i1 %926 to i8
  store i8 %927, i8* %56, align 1, !tbaa !2450
  %928 = sext i32 %904 to i64
  store i64 %928, i64* %RDX, align 8, !tbaa !2428
  %929 = shl nsw i64 %928, 3
  %930 = add i64 %929, %899
  %931 = add i64 %891, 23
  store i64 %931, i64* %PC, align 8
  %932 = inttoptr i64 %930 to i64*
  store i64 %894, i64* %932, align 8
  %933 = load i64, i64* %RBP, align 8
  %934 = add i64 %933, -36
  %935 = load i64, i64* %PC, align 8
  %936 = add i64 %935, 3
  store i64 %936, i64* %PC, align 8
  %937 = inttoptr i64 %934 to i32*
  %938 = load i32, i32* %937, align 4
  %939 = add i32 %938, 1
  %940 = zext i32 %939 to i64
  store i64 %940, i64* %RAX, align 8, !tbaa !2428
  %941 = icmp eq i32 %938, -1
  %942 = icmp eq i32 %939, 0
  %943 = or i1 %941, %942
  %944 = zext i1 %943 to i8
  store i8 %944, i8* %51, align 1, !tbaa !2433
  %945 = and i32 %939, 255
  %946 = tail call i32 @llvm.ctpop.i32(i32 %945) #10
  %947 = trunc i32 %946 to i8
  %948 = and i8 %947, 1
  %949 = xor i8 %948, 1
  store i8 %949, i8* %52, align 1, !tbaa !2447
  %950 = xor i32 %938, %939
  %951 = lshr i32 %950, 4
  %952 = trunc i32 %951 to i8
  %953 = and i8 %952, 1
  store i8 %953, i8* %53, align 1, !tbaa !2451
  %954 = icmp eq i32 %939, 0
  %955 = zext i1 %954 to i8
  store i8 %955, i8* %54, align 1, !tbaa !2448
  %956 = lshr i32 %939, 31
  %957 = trunc i32 %956 to i8
  store i8 %957, i8* %55, align 1, !tbaa !2449
  %958 = lshr i32 %938, 31
  %959 = xor i32 %956, %958
  %960 = add nuw nsw i32 %959, %956
  %961 = icmp eq i32 %960, 2
  %962 = zext i1 %961 to i8
  store i8 %962, i8* %56, align 1, !tbaa !2450
  %963 = add i64 %935, 9
  store i64 %963, i64* %PC, align 8
  store i32 %939, i32* %937, align 4
  %964 = load i64, i64* %PC, align 8
  %965 = add i64 %964, -1008
  store i64 %965, i64* %57, align 8, !tbaa !2428
  br label %block_40126a

block_401276:                                     ; preds = %block_40126a
  %966 = add i64 %199, -28
  %967 = add i64 %235, 7
  store i64 %967, i64* %PC, align 8
  %968 = inttoptr i64 %966 to i32*
  store i32 0, i32* %968, align 4
  %.pre5 = load i64, i64* %PC, align 8
  br label %block_40127d

block_40168a:                                     ; preds = %block_40167e
  %969 = add i64 %197, 3
  store i64 %969, i64* %PC, align 8
  %970 = load i32, i32* %164, align 4
  %971 = shl i32 %970, 1
  %972 = icmp slt i32 %970, 0
  %973 = icmp slt i32 %971, 0
  %974 = xor i1 %972, %973
  %975 = zext i32 %971 to i64
  store i64 %975, i64* %RAX, align 8, !tbaa !2428
  %.lobit22 = lshr i32 %970, 31
  %976 = trunc i32 %.lobit22 to i8
  store i8 %976, i8* %51, align 1, !tbaa !2432
  %977 = and i32 %971, 254
  %978 = tail call i32 @llvm.ctpop.i32(i32 %977) #10
  %979 = trunc i32 %978 to i8
  %980 = and i8 %979, 1
  %981 = xor i8 %980, 1
  store i8 %981, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %982 = icmp eq i32 %971, 0
  %983 = zext i1 %982 to i8
  store i8 %983, i8* %54, align 1, !tbaa !2432
  %984 = lshr i32 %970, 30
  %985 = and i32 %984, 1
  %986 = trunc i32 %985 to i8
  store i8 %986, i8* %55, align 1, !tbaa !2432
  %987 = zext i1 %974 to i8
  store i8 %987, i8* %56, align 1, !tbaa !2432
  %988 = add i64 %161, -16
  %989 = add i64 %197, 10
  store i64 %989, i64* %PC, align 8
  %990 = inttoptr i64 %988 to i64*
  %991 = load i64, i64* %990, align 8
  store i64 %991, i64* %RCX, align 8, !tbaa !2428
  %992 = add i64 %197, 14
  store i64 %992, i64* %PC, align 8
  %993 = load i32, i32* %169, align 4
  %994 = sext i32 %993 to i64
  store i64 %994, i64* %RDX, align 8, !tbaa !2428
  %995 = shl nsw i64 %994, 2
  %996 = add i64 %995, %991
  %997 = add i64 %197, 17
  store i64 %997, i64* %PC, align 8
  %998 = inttoptr i64 %996 to i32*
  %999 = load i32, i32* %998, align 4
  %1000 = add i32 %999, %971
  %1001 = zext i32 %1000 to i64
  store i64 %1001, i64* %RAX, align 8, !tbaa !2428
  %1002 = icmp ult i32 %1000, %971
  %1003 = icmp ult i32 %1000, %999
  %1004 = or i1 %1002, %1003
  %1005 = zext i1 %1004 to i8
  store i8 %1005, i8* %51, align 1, !tbaa !2433
  %1006 = and i32 %1000, 255
  %1007 = tail call i32 @llvm.ctpop.i32(i32 %1006) #10
  %1008 = trunc i32 %1007 to i8
  %1009 = and i8 %1008, 1
  %1010 = xor i8 %1009, 1
  store i8 %1010, i8* %52, align 1, !tbaa !2447
  %1011 = xor i32 %999, %971
  %1012 = xor i32 %1011, %1000
  %1013 = lshr i32 %1012, 4
  %1014 = trunc i32 %1013 to i8
  %1015 = and i8 %1014, 1
  store i8 %1015, i8* %53, align 1, !tbaa !2451
  %1016 = icmp eq i32 %1000, 0
  %1017 = zext i1 %1016 to i8
  store i8 %1017, i8* %54, align 1, !tbaa !2448
  %1018 = lshr i32 %1000, 31
  %1019 = trunc i32 %1018 to i8
  store i8 %1019, i8* %55, align 1, !tbaa !2449
  %1020 = lshr i32 %999, 31
  %1021 = xor i32 %1018, %985
  %1022 = xor i32 %1018, %1020
  %1023 = add nuw nsw i32 %1021, %1022
  %1024 = icmp eq i32 %1023, 2
  %1025 = zext i1 %1024 to i8
  store i8 %1025, i8* %56, align 1, !tbaa !2450
  %1026 = add i64 %161, -32
  %1027 = add i64 %197, 20
  store i64 %1027, i64* %PC, align 8
  %1028 = inttoptr i64 %1026 to i32*
  store i32 %1000, i32* %1028, align 4
  %1029 = load i64, i64* %RBP, align 8
  %1030 = add i64 %1029, -36
  %1031 = load i64, i64* %PC, align 8
  %1032 = add i64 %1031, 3
  store i64 %1032, i64* %PC, align 8
  %1033 = inttoptr i64 %1030 to i32*
  %1034 = load i32, i32* %1033, align 4
  %1035 = shl i32 %1034, 1
  %1036 = icmp slt i32 %1034, 0
  %1037 = icmp slt i32 %1035, 0
  %1038 = xor i1 %1036, %1037
  %1039 = zext i32 %1035 to i64
  store i64 %1039, i64* %RAX, align 8, !tbaa !2428
  %.lobit23 = lshr i32 %1034, 31
  %1040 = trunc i32 %.lobit23 to i8
  store i8 %1040, i8* %51, align 1, !tbaa !2432
  %1041 = and i32 %1035, 254
  %1042 = tail call i32 @llvm.ctpop.i32(i32 %1041) #10
  %1043 = trunc i32 %1042 to i8
  %1044 = and i8 %1043, 1
  %1045 = xor i8 %1044, 1
  store i8 %1045, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %1046 = icmp eq i32 %1035, 0
  %1047 = zext i1 %1046 to i8
  store i8 %1047, i8* %54, align 1, !tbaa !2432
  %1048 = lshr i32 %1034, 30
  %1049 = and i32 %1048, 1
  %1050 = trunc i32 %1049 to i8
  store i8 %1050, i8* %55, align 1, !tbaa !2432
  %1051 = zext i1 %1038 to i8
  store i8 %1051, i8* %56, align 1, !tbaa !2432
  %1052 = add i64 %1029, -16
  %1053 = add i64 %1031, 10
  store i64 %1053, i64* %PC, align 8
  %1054 = inttoptr i64 %1052 to i64*
  %1055 = load i64, i64* %1054, align 8
  store i64 %1055, i64* %RCX, align 8, !tbaa !2428
  %1056 = add i64 %1029, -28
  %1057 = add i64 %1031, 14
  store i64 %1057, i64* %PC, align 8
  %1058 = inttoptr i64 %1056 to i32*
  %1059 = load i32, i32* %1058, align 4
  %1060 = sext i32 %1059 to i64
  store i64 %1060, i64* %RDX, align 8, !tbaa !2428
  %1061 = shl nsw i64 %1060, 2
  %1062 = add i64 %1061, %1055
  %1063 = add i64 %1031, 17
  store i64 %1063, i64* %PC, align 8
  %1064 = inttoptr i64 %1062 to i32*
  %1065 = load i32, i32* %1064, align 4
  %1066 = add i32 %1065, %1035
  %1067 = zext i32 %1066 to i64
  store i64 %1067, i64* %RAX, align 8, !tbaa !2428
  %1068 = icmp ult i32 %1066, %1035
  %1069 = icmp ult i32 %1066, %1065
  %1070 = or i1 %1068, %1069
  %1071 = zext i1 %1070 to i8
  store i8 %1071, i8* %51, align 1, !tbaa !2433
  %1072 = and i32 %1066, 255
  %1073 = tail call i32 @llvm.ctpop.i32(i32 %1072) #10
  %1074 = trunc i32 %1073 to i8
  %1075 = and i8 %1074, 1
  %1076 = xor i8 %1075, 1
  store i8 %1076, i8* %52, align 1, !tbaa !2447
  %1077 = xor i32 %1065, %1035
  %1078 = xor i32 %1077, %1066
  %1079 = lshr i32 %1078, 4
  %1080 = trunc i32 %1079 to i8
  %1081 = and i8 %1080, 1
  store i8 %1081, i8* %53, align 1, !tbaa !2451
  %1082 = icmp eq i32 %1066, 0
  %1083 = zext i1 %1082 to i8
  store i8 %1083, i8* %54, align 1, !tbaa !2448
  %1084 = lshr i32 %1066, 31
  %1085 = trunc i32 %1084 to i8
  store i8 %1085, i8* %55, align 1, !tbaa !2449
  %1086 = lshr i32 %1065, 31
  %1087 = xor i32 %1084, %1049
  %1088 = xor i32 %1084, %1086
  %1089 = add nuw nsw i32 %1087, %1088
  %1090 = icmp eq i32 %1089, 2
  %1091 = zext i1 %1090 to i8
  store i8 %1091, i8* %56, align 1, !tbaa !2450
  %1092 = add i64 %1029, -40
  %1093 = add i64 %1031, 20
  store i64 %1093, i64* %PC, align 8
  %1094 = inttoptr i64 %1092 to i32*
  store i32 %1066, i32* %1094, align 4
  %1095 = load i64, i64* %RBP, align 8
  %1096 = add i64 %1095, -24
  %1097 = load i64, i64* %PC, align 8
  %1098 = add i64 %1097, 4
  store i64 %1098, i64* %PC, align 8
  %1099 = inttoptr i64 %1096 to i64*
  %1100 = load i64, i64* %1099, align 8
  store i64 %1100, i64* %RCX, align 8, !tbaa !2428
  %1101 = add i64 %1095, -32
  %1102 = add i64 %1097, 8
  store i64 %1102, i64* %PC, align 8
  %1103 = inttoptr i64 %1101 to i32*
  %1104 = load i32, i32* %1103, align 4
  %1105 = sext i32 %1104 to i64
  store i64 %1105, i64* %RDX, align 8, !tbaa !2428
  %1106 = shl nsw i64 %1105, 3
  %1107 = add i64 %1106, %1100
  %1108 = add i64 %1097, 13
  store i64 %1108, i64* %PC, align 8
  %1109 = inttoptr i64 %1107 to i64*
  %1110 = load i64, i64* %1109, align 8
  %1111 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1110, i64* %1111, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1112 = add i64 %1095, -64
  %1113 = add i64 %1097, 18
  store i64 %1113, i64* %PC, align 8
  %1114 = inttoptr i64 %1112 to i64*
  store i64 %1110, i64* %1114, align 8
  %1115 = load i64, i64* %RBP, align 8
  %1116 = add i64 %1115, -24
  %1117 = load i64, i64* %PC, align 8
  %1118 = add i64 %1117, 4
  store i64 %1118, i64* %PC, align 8
  %1119 = inttoptr i64 %1116 to i64*
  %1120 = load i64, i64* %1119, align 8
  store i64 %1120, i64* %RCX, align 8, !tbaa !2428
  %1121 = add i64 %1115, -32
  %1122 = add i64 %1117, 7
  store i64 %1122, i64* %PC, align 8
  %1123 = inttoptr i64 %1121 to i32*
  %1124 = load i32, i32* %1123, align 4
  %1125 = add i32 %1124, 1
  %1126 = zext i32 %1125 to i64
  store i64 %1126, i64* %RAX, align 8, !tbaa !2428
  %1127 = icmp eq i32 %1124, -1
  %1128 = icmp eq i32 %1125, 0
  %1129 = or i1 %1127, %1128
  %1130 = zext i1 %1129 to i8
  store i8 %1130, i8* %51, align 1, !tbaa !2433
  %1131 = and i32 %1125, 255
  %1132 = tail call i32 @llvm.ctpop.i32(i32 %1131) #10
  %1133 = trunc i32 %1132 to i8
  %1134 = and i8 %1133, 1
  %1135 = xor i8 %1134, 1
  store i8 %1135, i8* %52, align 1, !tbaa !2447
  %1136 = xor i32 %1124, %1125
  %1137 = lshr i32 %1136, 4
  %1138 = trunc i32 %1137 to i8
  %1139 = and i8 %1138, 1
  store i8 %1139, i8* %53, align 1, !tbaa !2451
  %1140 = icmp eq i32 %1125, 0
  %1141 = zext i1 %1140 to i8
  store i8 %1141, i8* %54, align 1, !tbaa !2448
  %1142 = lshr i32 %1125, 31
  %1143 = trunc i32 %1142 to i8
  store i8 %1143, i8* %55, align 1, !tbaa !2449
  %1144 = lshr i32 %1124, 31
  %1145 = xor i32 %1142, %1144
  %1146 = add nuw nsw i32 %1145, %1142
  %1147 = icmp eq i32 %1146, 2
  %1148 = zext i1 %1147 to i8
  store i8 %1148, i8* %56, align 1, !tbaa !2450
  %1149 = sext i32 %1125 to i64
  store i64 %1149, i64* %RDX, align 8, !tbaa !2428
  %1150 = shl nsw i64 %1149, 3
  %1151 = add i64 %1150, %1120
  %1152 = add i64 %1117, 18
  store i64 %1152, i64* %PC, align 8
  %1153 = inttoptr i64 %1151 to i64*
  %1154 = load i64, i64* %1153, align 8
  %1155 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1154, i64* %1155, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1156 = add i64 %1115, -72
  %1157 = add i64 %1117, 23
  store i64 %1157, i64* %PC, align 8
  %1158 = inttoptr i64 %1156 to i64*
  store i64 %1154, i64* %1158, align 8
  %1159 = load i64, i64* %RBP, align 8
  %1160 = add i64 %1159, -24
  %1161 = load i64, i64* %PC, align 8
  %1162 = add i64 %1161, 4
  store i64 %1162, i64* %PC, align 8
  %1163 = inttoptr i64 %1160 to i64*
  %1164 = load i64, i64* %1163, align 8
  store i64 %1164, i64* %RCX, align 8, !tbaa !2428
  %1165 = add i64 %1159, -40
  %1166 = add i64 %1161, 8
  store i64 %1166, i64* %PC, align 8
  %1167 = inttoptr i64 %1165 to i32*
  %1168 = load i32, i32* %1167, align 4
  %1169 = sext i32 %1168 to i64
  store i64 %1169, i64* %RDX, align 8, !tbaa !2428
  %1170 = shl nsw i64 %1169, 3
  %1171 = add i64 %1170, %1164
  %1172 = add i64 %1161, 13
  store i64 %1172, i64* %PC, align 8
  %1173 = inttoptr i64 %1171 to i64*
  %1174 = load i64, i64* %1173, align 8
  %1175 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1174, i64* %1175, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1176 = add i64 %1159, -80
  %1177 = add i64 %1161, 18
  store i64 %1177, i64* %PC, align 8
  %1178 = inttoptr i64 %1176 to i64*
  store i64 %1174, i64* %1178, align 8
  %1179 = load i64, i64* %RBP, align 8
  %1180 = add i64 %1179, -24
  %1181 = load i64, i64* %PC, align 8
  %1182 = add i64 %1181, 4
  store i64 %1182, i64* %PC, align 8
  %1183 = inttoptr i64 %1180 to i64*
  %1184 = load i64, i64* %1183, align 8
  store i64 %1184, i64* %RCX, align 8, !tbaa !2428
  %1185 = add i64 %1179, -40
  %1186 = add i64 %1181, 7
  store i64 %1186, i64* %PC, align 8
  %1187 = inttoptr i64 %1185 to i32*
  %1188 = load i32, i32* %1187, align 4
  %1189 = add i32 %1188, 1
  %1190 = zext i32 %1189 to i64
  store i64 %1190, i64* %RAX, align 8, !tbaa !2428
  %1191 = icmp eq i32 %1188, -1
  %1192 = icmp eq i32 %1189, 0
  %1193 = or i1 %1191, %1192
  %1194 = zext i1 %1193 to i8
  store i8 %1194, i8* %51, align 1, !tbaa !2433
  %1195 = and i32 %1189, 255
  %1196 = tail call i32 @llvm.ctpop.i32(i32 %1195) #10
  %1197 = trunc i32 %1196 to i8
  %1198 = and i8 %1197, 1
  %1199 = xor i8 %1198, 1
  store i8 %1199, i8* %52, align 1, !tbaa !2447
  %1200 = xor i32 %1188, %1189
  %1201 = lshr i32 %1200, 4
  %1202 = trunc i32 %1201 to i8
  %1203 = and i8 %1202, 1
  store i8 %1203, i8* %53, align 1, !tbaa !2451
  %1204 = icmp eq i32 %1189, 0
  %1205 = zext i1 %1204 to i8
  store i8 %1205, i8* %54, align 1, !tbaa !2448
  %1206 = lshr i32 %1189, 31
  %1207 = trunc i32 %1206 to i8
  store i8 %1207, i8* %55, align 1, !tbaa !2449
  %1208 = lshr i32 %1188, 31
  %1209 = xor i32 %1206, %1208
  %1210 = add nuw nsw i32 %1209, %1206
  %1211 = icmp eq i32 %1210, 2
  %1212 = zext i1 %1211 to i8
  store i8 %1212, i8* %56, align 1, !tbaa !2450
  %1213 = sext i32 %1189 to i64
  store i64 %1213, i64* %RDX, align 8, !tbaa !2428
  %1214 = shl nsw i64 %1213, 3
  %1215 = add i64 %1214, %1184
  %1216 = add i64 %1181, 18
  store i64 %1216, i64* %PC, align 8
  %1217 = inttoptr i64 %1215 to i64*
  %1218 = load i64, i64* %1217, align 8
  %1219 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1218, i64* %1219, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1220 = add i64 %1179, -88
  %1221 = add i64 %1181, 23
  store i64 %1221, i64* %PC, align 8
  %1222 = inttoptr i64 %1220 to i64*
  store i64 %1218, i64* %1222, align 8
  %1223 = load i64, i64* %RBP, align 8
  %1224 = add i64 %1223, -80
  %1225 = load i64, i64* %PC, align 8
  %1226 = add i64 %1225, 5
  store i64 %1226, i64* %PC, align 8
  %1227 = inttoptr i64 %1224 to i64*
  %1228 = load i64, i64* %1227, align 8
  %1229 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1228, i64* %1229, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1230 = add i64 %1223, -24
  %1231 = add i64 %1225, 9
  store i64 %1231, i64* %PC, align 8
  %1232 = inttoptr i64 %1230 to i64*
  %1233 = load i64, i64* %1232, align 8
  store i64 %1233, i64* %RCX, align 8, !tbaa !2428
  %1234 = add i64 %1223, -32
  %1235 = add i64 %1225, 13
  store i64 %1235, i64* %PC, align 8
  %1236 = inttoptr i64 %1234 to i32*
  %1237 = load i32, i32* %1236, align 4
  %1238 = sext i32 %1237 to i64
  store i64 %1238, i64* %RDX, align 8, !tbaa !2428
  %1239 = shl nsw i64 %1238, 3
  %1240 = add i64 %1239, %1233
  %1241 = add i64 %1225, 18
  store i64 %1241, i64* %PC, align 8
  %1242 = inttoptr i64 %1240 to i64*
  store i64 %1228, i64* %1242, align 8
  %1243 = load i64, i64* %RBP, align 8
  %1244 = add i64 %1243, -88
  %1245 = load i64, i64* %PC, align 8
  %1246 = add i64 %1245, 5
  store i64 %1246, i64* %PC, align 8
  %1247 = inttoptr i64 %1244 to i64*
  %1248 = load i64, i64* %1247, align 8
  %1249 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1248, i64* %1249, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1250 = add i64 %1243, -24
  %1251 = add i64 %1245, 9
  store i64 %1251, i64* %PC, align 8
  %1252 = inttoptr i64 %1250 to i64*
  %1253 = load i64, i64* %1252, align 8
  store i64 %1253, i64* %RCX, align 8, !tbaa !2428
  %1254 = add i64 %1243, -32
  %1255 = add i64 %1245, 12
  store i64 %1255, i64* %PC, align 8
  %1256 = inttoptr i64 %1254 to i32*
  %1257 = load i32, i32* %1256, align 4
  %1258 = add i32 %1257, 1
  %1259 = zext i32 %1258 to i64
  store i64 %1259, i64* %RAX, align 8, !tbaa !2428
  %1260 = icmp eq i32 %1257, -1
  %1261 = icmp eq i32 %1258, 0
  %1262 = or i1 %1260, %1261
  %1263 = zext i1 %1262 to i8
  store i8 %1263, i8* %51, align 1, !tbaa !2433
  %1264 = and i32 %1258, 255
  %1265 = tail call i32 @llvm.ctpop.i32(i32 %1264) #10
  %1266 = trunc i32 %1265 to i8
  %1267 = and i8 %1266, 1
  %1268 = xor i8 %1267, 1
  store i8 %1268, i8* %52, align 1, !tbaa !2447
  %1269 = xor i32 %1257, %1258
  %1270 = lshr i32 %1269, 4
  %1271 = trunc i32 %1270 to i8
  %1272 = and i8 %1271, 1
  store i8 %1272, i8* %53, align 1, !tbaa !2451
  %1273 = icmp eq i32 %1258, 0
  %1274 = zext i1 %1273 to i8
  store i8 %1274, i8* %54, align 1, !tbaa !2448
  %1275 = lshr i32 %1258, 31
  %1276 = trunc i32 %1275 to i8
  store i8 %1276, i8* %55, align 1, !tbaa !2449
  %1277 = lshr i32 %1257, 31
  %1278 = xor i32 %1275, %1277
  %1279 = add nuw nsw i32 %1278, %1275
  %1280 = icmp eq i32 %1279, 2
  %1281 = zext i1 %1280 to i8
  store i8 %1281, i8* %56, align 1, !tbaa !2450
  %1282 = sext i32 %1258 to i64
  store i64 %1282, i64* %RDX, align 8, !tbaa !2428
  %1283 = shl nsw i64 %1282, 3
  %1284 = add i64 %1283, %1253
  %1285 = add i64 %1245, 23
  store i64 %1285, i64* %PC, align 8
  %1286 = inttoptr i64 %1284 to i64*
  store i64 %1248, i64* %1286, align 8
  %1287 = load i64, i64* %RBP, align 8
  %1288 = add i64 %1287, -64
  %1289 = load i64, i64* %PC, align 8
  %1290 = add i64 %1289, 5
  store i64 %1290, i64* %PC, align 8
  %1291 = inttoptr i64 %1288 to i64*
  %1292 = load i64, i64* %1291, align 8
  %1293 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1292, i64* %1293, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1294 = add i64 %1287, -24
  %1295 = add i64 %1289, 9
  store i64 %1295, i64* %PC, align 8
  %1296 = inttoptr i64 %1294 to i64*
  %1297 = load i64, i64* %1296, align 8
  store i64 %1297, i64* %RCX, align 8, !tbaa !2428
  %1298 = add i64 %1287, -40
  %1299 = add i64 %1289, 13
  store i64 %1299, i64* %PC, align 8
  %1300 = inttoptr i64 %1298 to i32*
  %1301 = load i32, i32* %1300, align 4
  %1302 = sext i32 %1301 to i64
  store i64 %1302, i64* %RDX, align 8, !tbaa !2428
  %1303 = shl nsw i64 %1302, 3
  %1304 = add i64 %1303, %1297
  %1305 = add i64 %1289, 18
  store i64 %1305, i64* %PC, align 8
  %1306 = inttoptr i64 %1304 to i64*
  store i64 %1292, i64* %1306, align 8
  %1307 = load i64, i64* %RBP, align 8
  %1308 = add i64 %1307, -72
  %1309 = load i64, i64* %PC, align 8
  %1310 = add i64 %1309, 5
  store i64 %1310, i64* %PC, align 8
  %1311 = inttoptr i64 %1308 to i64*
  %1312 = load i64, i64* %1311, align 8
  %1313 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1312, i64* %1313, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1314 = add i64 %1307, -24
  %1315 = add i64 %1309, 9
  store i64 %1315, i64* %PC, align 8
  %1316 = inttoptr i64 %1314 to i64*
  %1317 = load i64, i64* %1316, align 8
  store i64 %1317, i64* %RCX, align 8, !tbaa !2428
  %1318 = add i64 %1307, -40
  %1319 = add i64 %1309, 12
  store i64 %1319, i64* %PC, align 8
  %1320 = inttoptr i64 %1318 to i32*
  %1321 = load i32, i32* %1320, align 4
  %1322 = add i32 %1321, 1
  %1323 = zext i32 %1322 to i64
  store i64 %1323, i64* %RAX, align 8, !tbaa !2428
  %1324 = icmp eq i32 %1321, -1
  %1325 = icmp eq i32 %1322, 0
  %1326 = or i1 %1324, %1325
  %1327 = zext i1 %1326 to i8
  store i8 %1327, i8* %51, align 1, !tbaa !2433
  %1328 = and i32 %1322, 255
  %1329 = tail call i32 @llvm.ctpop.i32(i32 %1328) #10
  %1330 = trunc i32 %1329 to i8
  %1331 = and i8 %1330, 1
  %1332 = xor i8 %1331, 1
  store i8 %1332, i8* %52, align 1, !tbaa !2447
  %1333 = xor i32 %1321, %1322
  %1334 = lshr i32 %1333, 4
  %1335 = trunc i32 %1334 to i8
  %1336 = and i8 %1335, 1
  store i8 %1336, i8* %53, align 1, !tbaa !2451
  %1337 = icmp eq i32 %1322, 0
  %1338 = zext i1 %1337 to i8
  store i8 %1338, i8* %54, align 1, !tbaa !2448
  %1339 = lshr i32 %1322, 31
  %1340 = trunc i32 %1339 to i8
  store i8 %1340, i8* %55, align 1, !tbaa !2449
  %1341 = lshr i32 %1321, 31
  %1342 = xor i32 %1339, %1341
  %1343 = add nuw nsw i32 %1342, %1339
  %1344 = icmp eq i32 %1343, 2
  %1345 = zext i1 %1344 to i8
  store i8 %1345, i8* %56, align 1, !tbaa !2450
  %1346 = sext i32 %1322 to i64
  store i64 %1346, i64* %RDX, align 8, !tbaa !2428
  %1347 = shl nsw i64 %1346, 3
  %1348 = add i64 %1347, %1317
  %1349 = add i64 %1309, 23
  store i64 %1349, i64* %PC, align 8
  %1350 = inttoptr i64 %1348 to i64*
  store i64 %1312, i64* %1350, align 8
  %1351 = load i64, i64* %RBP, align 8
  %1352 = add i64 %1351, -52
  %1353 = load i64, i64* %PC, align 8
  %1354 = add i64 %1353, 3
  store i64 %1354, i64* %PC, align 8
  %1355 = inttoptr i64 %1352 to i32*
  %1356 = load i32, i32* %1355, align 4
  %1357 = zext i32 %1356 to i64
  store i64 %1357, i64* %RAX, align 8, !tbaa !2428
  %1358 = add i64 %1351, -32
  %1359 = add i64 %1353, 6
  store i64 %1359, i64* %PC, align 8
  %1360 = inttoptr i64 %1358 to i32*
  %1361 = load i32, i32* %1360, align 4
  %1362 = add i32 %1361, %1356
  %1363 = zext i32 %1362 to i64
  store i64 %1363, i64* %RAX, align 8, !tbaa !2428
  %1364 = icmp ult i32 %1362, %1356
  %1365 = icmp ult i32 %1362, %1361
  %1366 = or i1 %1364, %1365
  %1367 = zext i1 %1366 to i8
  store i8 %1367, i8* %51, align 1, !tbaa !2433
  %1368 = and i32 %1362, 255
  %1369 = tail call i32 @llvm.ctpop.i32(i32 %1368) #10
  %1370 = trunc i32 %1369 to i8
  %1371 = and i8 %1370, 1
  %1372 = xor i8 %1371, 1
  store i8 %1372, i8* %52, align 1, !tbaa !2447
  %1373 = xor i32 %1361, %1356
  %1374 = xor i32 %1373, %1362
  %1375 = lshr i32 %1374, 4
  %1376 = trunc i32 %1375 to i8
  %1377 = and i8 %1376, 1
  store i8 %1377, i8* %53, align 1, !tbaa !2451
  %1378 = icmp eq i32 %1362, 0
  %1379 = zext i1 %1378 to i8
  store i8 %1379, i8* %54, align 1, !tbaa !2448
  %1380 = lshr i32 %1362, 31
  %1381 = trunc i32 %1380 to i8
  store i8 %1381, i8* %55, align 1, !tbaa !2449
  %1382 = lshr i32 %1356, 31
  %1383 = lshr i32 %1361, 31
  %1384 = xor i32 %1380, %1382
  %1385 = xor i32 %1380, %1383
  %1386 = add nuw nsw i32 %1384, %1385
  %1387 = icmp eq i32 %1386, 2
  %1388 = zext i1 %1387 to i8
  store i8 %1388, i8* %56, align 1, !tbaa !2450
  %1389 = add i64 %1353, 9
  store i64 %1389, i64* %PC, align 8
  store i32 %1362, i32* %1360, align 4
  %1390 = load i64, i64* %RBP, align 8
  %1391 = add i64 %1390, -52
  %1392 = load i64, i64* %PC, align 8
  %1393 = add i64 %1392, 3
  store i64 %1393, i64* %PC, align 8
  %1394 = inttoptr i64 %1391 to i32*
  %1395 = load i32, i32* %1394, align 4
  %1396 = zext i32 %1395 to i64
  store i64 %1396, i64* %RAX, align 8, !tbaa !2428
  %1397 = add i64 %1390, -40
  %1398 = add i64 %1392, 6
  store i64 %1398, i64* %PC, align 8
  %1399 = inttoptr i64 %1397 to i32*
  %1400 = load i32, i32* %1399, align 4
  %1401 = add i32 %1400, %1395
  %1402 = zext i32 %1401 to i64
  store i64 %1402, i64* %RAX, align 8, !tbaa !2428
  %1403 = icmp ult i32 %1401, %1395
  %1404 = icmp ult i32 %1401, %1400
  %1405 = or i1 %1403, %1404
  %1406 = zext i1 %1405 to i8
  store i8 %1406, i8* %51, align 1, !tbaa !2433
  %1407 = and i32 %1401, 255
  %1408 = tail call i32 @llvm.ctpop.i32(i32 %1407) #10
  %1409 = trunc i32 %1408 to i8
  %1410 = and i8 %1409, 1
  %1411 = xor i8 %1410, 1
  store i8 %1411, i8* %52, align 1, !tbaa !2447
  %1412 = xor i32 %1400, %1395
  %1413 = xor i32 %1412, %1401
  %1414 = lshr i32 %1413, 4
  %1415 = trunc i32 %1414 to i8
  %1416 = and i8 %1415, 1
  store i8 %1416, i8* %53, align 1, !tbaa !2451
  %1417 = icmp eq i32 %1401, 0
  %1418 = zext i1 %1417 to i8
  store i8 %1418, i8* %54, align 1, !tbaa !2448
  %1419 = lshr i32 %1401, 31
  %1420 = trunc i32 %1419 to i8
  store i8 %1420, i8* %55, align 1, !tbaa !2449
  %1421 = lshr i32 %1395, 31
  %1422 = lshr i32 %1400, 31
  %1423 = xor i32 %1419, %1421
  %1424 = xor i32 %1419, %1422
  %1425 = add nuw nsw i32 %1423, %1424
  %1426 = icmp eq i32 %1425, 2
  %1427 = zext i1 %1426 to i8
  store i8 %1427, i8* %56, align 1, !tbaa !2450
  %1428 = add i64 %1392, 9
  store i64 %1428, i64* %PC, align 8
  store i32 %1401, i32* %1399, align 4
  %1429 = load i64, i64* %RBP, align 8
  %1430 = add i64 %1429, -24
  %1431 = load i64, i64* %PC, align 8
  %1432 = add i64 %1431, 4
  store i64 %1432, i64* %PC, align 8
  %1433 = inttoptr i64 %1430 to i64*
  %1434 = load i64, i64* %1433, align 8
  store i64 %1434, i64* %RCX, align 8, !tbaa !2428
  %1435 = add i64 %1429, -32
  %1436 = add i64 %1431, 8
  store i64 %1436, i64* %PC, align 8
  %1437 = inttoptr i64 %1435 to i32*
  %1438 = load i32, i32* %1437, align 4
  %1439 = sext i32 %1438 to i64
  store i64 %1439, i64* %RDX, align 8, !tbaa !2428
  %1440 = shl nsw i64 %1439, 3
  %1441 = add i64 %1440, %1434
  %1442 = add i64 %1431, 13
  store i64 %1442, i64* %PC, align 8
  %1443 = inttoptr i64 %1441 to i64*
  %1444 = load i64, i64* %1443, align 8
  %1445 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1444, i64* %1445, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1446 = add i64 %1429, -64
  %1447 = add i64 %1431, 18
  store i64 %1447, i64* %PC, align 8
  %1448 = inttoptr i64 %1446 to i64*
  store i64 %1444, i64* %1448, align 8
  %1449 = load i64, i64* %RBP, align 8
  %1450 = add i64 %1449, -24
  %1451 = load i64, i64* %PC, align 8
  %1452 = add i64 %1451, 4
  store i64 %1452, i64* %PC, align 8
  %1453 = inttoptr i64 %1450 to i64*
  %1454 = load i64, i64* %1453, align 8
  store i64 %1454, i64* %RCX, align 8, !tbaa !2428
  %1455 = add i64 %1449, -32
  %1456 = add i64 %1451, 7
  store i64 %1456, i64* %PC, align 8
  %1457 = inttoptr i64 %1455 to i32*
  %1458 = load i32, i32* %1457, align 4
  %1459 = add i32 %1458, 1
  %1460 = zext i32 %1459 to i64
  store i64 %1460, i64* %RAX, align 8, !tbaa !2428
  %1461 = icmp eq i32 %1458, -1
  %1462 = icmp eq i32 %1459, 0
  %1463 = or i1 %1461, %1462
  %1464 = zext i1 %1463 to i8
  store i8 %1464, i8* %51, align 1, !tbaa !2433
  %1465 = and i32 %1459, 255
  %1466 = tail call i32 @llvm.ctpop.i32(i32 %1465) #10
  %1467 = trunc i32 %1466 to i8
  %1468 = and i8 %1467, 1
  %1469 = xor i8 %1468, 1
  store i8 %1469, i8* %52, align 1, !tbaa !2447
  %1470 = xor i32 %1458, %1459
  %1471 = lshr i32 %1470, 4
  %1472 = trunc i32 %1471 to i8
  %1473 = and i8 %1472, 1
  store i8 %1473, i8* %53, align 1, !tbaa !2451
  %1474 = icmp eq i32 %1459, 0
  %1475 = zext i1 %1474 to i8
  store i8 %1475, i8* %54, align 1, !tbaa !2448
  %1476 = lshr i32 %1459, 31
  %1477 = trunc i32 %1476 to i8
  store i8 %1477, i8* %55, align 1, !tbaa !2449
  %1478 = lshr i32 %1458, 31
  %1479 = xor i32 %1476, %1478
  %1480 = add nuw nsw i32 %1479, %1476
  %1481 = icmp eq i32 %1480, 2
  %1482 = zext i1 %1481 to i8
  store i8 %1482, i8* %56, align 1, !tbaa !2450
  %1483 = sext i32 %1459 to i64
  store i64 %1483, i64* %RDX, align 8, !tbaa !2428
  %1484 = shl nsw i64 %1483, 3
  %1485 = add i64 %1484, %1454
  %1486 = add i64 %1451, 18
  store i64 %1486, i64* %PC, align 8
  %1487 = inttoptr i64 %1485 to i64*
  %1488 = load i64, i64* %1487, align 8
  %1489 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1488, i64* %1489, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1490 = add i64 %1449, -72
  %1491 = add i64 %1451, 23
  store i64 %1491, i64* %PC, align 8
  %1492 = inttoptr i64 %1490 to i64*
  store i64 %1488, i64* %1492, align 8
  %1493 = load i64, i64* %RBP, align 8
  %1494 = add i64 %1493, -24
  %1495 = load i64, i64* %PC, align 8
  %1496 = add i64 %1495, 4
  store i64 %1496, i64* %PC, align 8
  %1497 = inttoptr i64 %1494 to i64*
  %1498 = load i64, i64* %1497, align 8
  store i64 %1498, i64* %RCX, align 8, !tbaa !2428
  %1499 = add i64 %1493, -40
  %1500 = add i64 %1495, 8
  store i64 %1500, i64* %PC, align 8
  %1501 = inttoptr i64 %1499 to i32*
  %1502 = load i32, i32* %1501, align 4
  %1503 = sext i32 %1502 to i64
  store i64 %1503, i64* %RDX, align 8, !tbaa !2428
  %1504 = shl nsw i64 %1503, 3
  %1505 = add i64 %1504, %1498
  %1506 = add i64 %1495, 13
  store i64 %1506, i64* %PC, align 8
  %1507 = inttoptr i64 %1505 to i64*
  %1508 = load i64, i64* %1507, align 8
  %1509 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1508, i64* %1509, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1510 = add i64 %1493, -80
  %1511 = add i64 %1495, 18
  store i64 %1511, i64* %PC, align 8
  %1512 = inttoptr i64 %1510 to i64*
  store i64 %1508, i64* %1512, align 8
  %1513 = load i64, i64* %RBP, align 8
  %1514 = add i64 %1513, -24
  %1515 = load i64, i64* %PC, align 8
  %1516 = add i64 %1515, 4
  store i64 %1516, i64* %PC, align 8
  %1517 = inttoptr i64 %1514 to i64*
  %1518 = load i64, i64* %1517, align 8
  store i64 %1518, i64* %RCX, align 8, !tbaa !2428
  %1519 = add i64 %1513, -40
  %1520 = add i64 %1515, 7
  store i64 %1520, i64* %PC, align 8
  %1521 = inttoptr i64 %1519 to i32*
  %1522 = load i32, i32* %1521, align 4
  %1523 = add i32 %1522, 1
  %1524 = zext i32 %1523 to i64
  store i64 %1524, i64* %RAX, align 8, !tbaa !2428
  %1525 = icmp eq i32 %1522, -1
  %1526 = icmp eq i32 %1523, 0
  %1527 = or i1 %1525, %1526
  %1528 = zext i1 %1527 to i8
  store i8 %1528, i8* %51, align 1, !tbaa !2433
  %1529 = and i32 %1523, 255
  %1530 = tail call i32 @llvm.ctpop.i32(i32 %1529) #10
  %1531 = trunc i32 %1530 to i8
  %1532 = and i8 %1531, 1
  %1533 = xor i8 %1532, 1
  store i8 %1533, i8* %52, align 1, !tbaa !2447
  %1534 = xor i32 %1522, %1523
  %1535 = lshr i32 %1534, 4
  %1536 = trunc i32 %1535 to i8
  %1537 = and i8 %1536, 1
  store i8 %1537, i8* %53, align 1, !tbaa !2451
  %1538 = icmp eq i32 %1523, 0
  %1539 = zext i1 %1538 to i8
  store i8 %1539, i8* %54, align 1, !tbaa !2448
  %1540 = lshr i32 %1523, 31
  %1541 = trunc i32 %1540 to i8
  store i8 %1541, i8* %55, align 1, !tbaa !2449
  %1542 = lshr i32 %1522, 31
  %1543 = xor i32 %1540, %1542
  %1544 = add nuw nsw i32 %1543, %1540
  %1545 = icmp eq i32 %1544, 2
  %1546 = zext i1 %1545 to i8
  store i8 %1546, i8* %56, align 1, !tbaa !2450
  %1547 = sext i32 %1523 to i64
  store i64 %1547, i64* %RDX, align 8, !tbaa !2428
  %1548 = shl nsw i64 %1547, 3
  %1549 = add i64 %1548, %1518
  %1550 = add i64 %1515, 18
  store i64 %1550, i64* %PC, align 8
  %1551 = inttoptr i64 %1549 to i64*
  %1552 = load i64, i64* %1551, align 8
  %1553 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1552, i64* %1553, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1554 = add i64 %1513, -88
  %1555 = add i64 %1515, 23
  store i64 %1555, i64* %PC, align 8
  %1556 = inttoptr i64 %1554 to i64*
  store i64 %1552, i64* %1556, align 8
  %1557 = load i64, i64* %RBP, align 8
  %1558 = add i64 %1557, -80
  %1559 = load i64, i64* %PC, align 8
  %1560 = add i64 %1559, 5
  store i64 %1560, i64* %PC, align 8
  %1561 = inttoptr i64 %1558 to i64*
  %1562 = load i64, i64* %1561, align 8
  %1563 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1562, i64* %1563, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1564 = add i64 %1557, -24
  %1565 = add i64 %1559, 9
  store i64 %1565, i64* %PC, align 8
  %1566 = inttoptr i64 %1564 to i64*
  %1567 = load i64, i64* %1566, align 8
  store i64 %1567, i64* %RCX, align 8, !tbaa !2428
  %1568 = add i64 %1557, -32
  %1569 = add i64 %1559, 13
  store i64 %1569, i64* %PC, align 8
  %1570 = inttoptr i64 %1568 to i32*
  %1571 = load i32, i32* %1570, align 4
  %1572 = sext i32 %1571 to i64
  store i64 %1572, i64* %RDX, align 8, !tbaa !2428
  %1573 = shl nsw i64 %1572, 3
  %1574 = add i64 %1573, %1567
  %1575 = add i64 %1559, 18
  store i64 %1575, i64* %PC, align 8
  %1576 = inttoptr i64 %1574 to i64*
  store i64 %1562, i64* %1576, align 8
  %1577 = load i64, i64* %RBP, align 8
  %1578 = add i64 %1577, -88
  %1579 = load i64, i64* %PC, align 8
  %1580 = add i64 %1579, 5
  store i64 %1580, i64* %PC, align 8
  %1581 = inttoptr i64 %1578 to i64*
  %1582 = load i64, i64* %1581, align 8
  %1583 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1582, i64* %1583, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1584 = add i64 %1577, -24
  %1585 = add i64 %1579, 9
  store i64 %1585, i64* %PC, align 8
  %1586 = inttoptr i64 %1584 to i64*
  %1587 = load i64, i64* %1586, align 8
  store i64 %1587, i64* %RCX, align 8, !tbaa !2428
  %1588 = add i64 %1577, -32
  %1589 = add i64 %1579, 12
  store i64 %1589, i64* %PC, align 8
  %1590 = inttoptr i64 %1588 to i32*
  %1591 = load i32, i32* %1590, align 4
  %1592 = add i32 %1591, 1
  %1593 = zext i32 %1592 to i64
  store i64 %1593, i64* %RAX, align 8, !tbaa !2428
  %1594 = icmp eq i32 %1591, -1
  %1595 = icmp eq i32 %1592, 0
  %1596 = or i1 %1594, %1595
  %1597 = zext i1 %1596 to i8
  store i8 %1597, i8* %51, align 1, !tbaa !2433
  %1598 = and i32 %1592, 255
  %1599 = tail call i32 @llvm.ctpop.i32(i32 %1598) #10
  %1600 = trunc i32 %1599 to i8
  %1601 = and i8 %1600, 1
  %1602 = xor i8 %1601, 1
  store i8 %1602, i8* %52, align 1, !tbaa !2447
  %1603 = xor i32 %1591, %1592
  %1604 = lshr i32 %1603, 4
  %1605 = trunc i32 %1604 to i8
  %1606 = and i8 %1605, 1
  store i8 %1606, i8* %53, align 1, !tbaa !2451
  %1607 = icmp eq i32 %1592, 0
  %1608 = zext i1 %1607 to i8
  store i8 %1608, i8* %54, align 1, !tbaa !2448
  %1609 = lshr i32 %1592, 31
  %1610 = trunc i32 %1609 to i8
  store i8 %1610, i8* %55, align 1, !tbaa !2449
  %1611 = lshr i32 %1591, 31
  %1612 = xor i32 %1609, %1611
  %1613 = add nuw nsw i32 %1612, %1609
  %1614 = icmp eq i32 %1613, 2
  %1615 = zext i1 %1614 to i8
  store i8 %1615, i8* %56, align 1, !tbaa !2450
  %1616 = sext i32 %1592 to i64
  store i64 %1616, i64* %RDX, align 8, !tbaa !2428
  %1617 = shl nsw i64 %1616, 3
  %1618 = add i64 %1617, %1587
  %1619 = add i64 %1579, 23
  store i64 %1619, i64* %PC, align 8
  %1620 = inttoptr i64 %1618 to i64*
  store i64 %1582, i64* %1620, align 8
  %1621 = load i64, i64* %RBP, align 8
  %1622 = add i64 %1621, -64
  %1623 = load i64, i64* %PC, align 8
  %1624 = add i64 %1623, 5
  store i64 %1624, i64* %PC, align 8
  %1625 = inttoptr i64 %1622 to i64*
  %1626 = load i64, i64* %1625, align 8
  %1627 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1626, i64* %1627, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1628 = add i64 %1621, -24
  %1629 = add i64 %1623, 9
  store i64 %1629, i64* %PC, align 8
  %1630 = inttoptr i64 %1628 to i64*
  %1631 = load i64, i64* %1630, align 8
  store i64 %1631, i64* %RCX, align 8, !tbaa !2428
  %1632 = add i64 %1621, -40
  %1633 = add i64 %1623, 13
  store i64 %1633, i64* %PC, align 8
  %1634 = inttoptr i64 %1632 to i32*
  %1635 = load i32, i32* %1634, align 4
  %1636 = sext i32 %1635 to i64
  store i64 %1636, i64* %RDX, align 8, !tbaa !2428
  %1637 = shl nsw i64 %1636, 3
  %1638 = add i64 %1637, %1631
  %1639 = add i64 %1623, 18
  store i64 %1639, i64* %PC, align 8
  %1640 = inttoptr i64 %1638 to i64*
  store i64 %1626, i64* %1640, align 8
  %1641 = load i64, i64* %RBP, align 8
  %1642 = add i64 %1641, -72
  %1643 = load i64, i64* %PC, align 8
  %1644 = add i64 %1643, 5
  store i64 %1644, i64* %PC, align 8
  %1645 = inttoptr i64 %1642 to i64*
  %1646 = load i64, i64* %1645, align 8
  %1647 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1646, i64* %1647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %316, align 1, !tbaa !2452
  %1648 = add i64 %1641, -24
  %1649 = add i64 %1643, 9
  store i64 %1649, i64* %PC, align 8
  %1650 = inttoptr i64 %1648 to i64*
  %1651 = load i64, i64* %1650, align 8
  store i64 %1651, i64* %RCX, align 8, !tbaa !2428
  %1652 = add i64 %1641, -40
  %1653 = add i64 %1643, 12
  store i64 %1653, i64* %PC, align 8
  %1654 = inttoptr i64 %1652 to i32*
  %1655 = load i32, i32* %1654, align 4
  %1656 = add i32 %1655, 1
  %1657 = zext i32 %1656 to i64
  store i64 %1657, i64* %RAX, align 8, !tbaa !2428
  %1658 = icmp eq i32 %1655, -1
  %1659 = icmp eq i32 %1656, 0
  %1660 = or i1 %1658, %1659
  %1661 = zext i1 %1660 to i8
  store i8 %1661, i8* %51, align 1, !tbaa !2433
  %1662 = and i32 %1656, 255
  %1663 = tail call i32 @llvm.ctpop.i32(i32 %1662) #10
  %1664 = trunc i32 %1663 to i8
  %1665 = and i8 %1664, 1
  %1666 = xor i8 %1665, 1
  store i8 %1666, i8* %52, align 1, !tbaa !2447
  %1667 = xor i32 %1655, %1656
  %1668 = lshr i32 %1667, 4
  %1669 = trunc i32 %1668 to i8
  %1670 = and i8 %1669, 1
  store i8 %1670, i8* %53, align 1, !tbaa !2451
  %1671 = icmp eq i32 %1656, 0
  %1672 = zext i1 %1671 to i8
  store i8 %1672, i8* %54, align 1, !tbaa !2448
  %1673 = lshr i32 %1656, 31
  %1674 = trunc i32 %1673 to i8
  store i8 %1674, i8* %55, align 1, !tbaa !2449
  %1675 = lshr i32 %1655, 31
  %1676 = xor i32 %1673, %1675
  %1677 = add nuw nsw i32 %1676, %1673
  %1678 = icmp eq i32 %1677, 2
  %1679 = zext i1 %1678 to i8
  store i8 %1679, i8* %56, align 1, !tbaa !2450
  %1680 = sext i32 %1656 to i64
  store i64 %1680, i64* %RDX, align 8, !tbaa !2428
  %1681 = shl nsw i64 %1680, 3
  %1682 = add i64 %1681, %1651
  %1683 = add i64 %1643, 23
  store i64 %1683, i64* %PC, align 8
  %1684 = inttoptr i64 %1682 to i64*
  store i64 %1646, i64* %1684, align 8
  %1685 = load i64, i64* %RBP, align 8
  %1686 = add i64 %1685, -28
  %1687 = load i64, i64* %PC, align 8
  %1688 = add i64 %1687, 3
  store i64 %1688, i64* %PC, align 8
  %1689 = inttoptr i64 %1686 to i32*
  %1690 = load i32, i32* %1689, align 4
  %1691 = add i32 %1690, 1
  %1692 = zext i32 %1691 to i64
  store i64 %1692, i64* %RAX, align 8, !tbaa !2428
  %1693 = icmp eq i32 %1690, -1
  %1694 = icmp eq i32 %1691, 0
  %1695 = or i1 %1693, %1694
  %1696 = zext i1 %1695 to i8
  store i8 %1696, i8* %51, align 1, !tbaa !2433
  %1697 = and i32 %1691, 255
  %1698 = tail call i32 @llvm.ctpop.i32(i32 %1697) #10
  %1699 = trunc i32 %1698 to i8
  %1700 = and i8 %1699, 1
  %1701 = xor i8 %1700, 1
  store i8 %1701, i8* %52, align 1, !tbaa !2447
  %1702 = xor i32 %1690, %1691
  %1703 = lshr i32 %1702, 4
  %1704 = trunc i32 %1703 to i8
  %1705 = and i8 %1704, 1
  store i8 %1705, i8* %53, align 1, !tbaa !2451
  %1706 = icmp eq i32 %1691, 0
  %1707 = zext i1 %1706 to i8
  store i8 %1707, i8* %54, align 1, !tbaa !2448
  %1708 = lshr i32 %1691, 31
  %1709 = trunc i32 %1708 to i8
  store i8 %1709, i8* %55, align 1, !tbaa !2449
  %1710 = lshr i32 %1690, 31
  %1711 = xor i32 %1708, %1710
  %1712 = add nuw nsw i32 %1711, %1708
  %1713 = icmp eq i32 %1712, 2
  %1714 = zext i1 %1713 to i8
  store i8 %1714, i8* %56, align 1, !tbaa !2450
  %1715 = add i64 %1687, 9
  store i64 %1715, i64* %PC, align 8
  store i32 %1691, i32* %1689, align 4
  %1716 = load i64, i64* %PC, align 8
  %1717 = add i64 %1716, -407
  store i64 %1717, i64* %57, align 8, !tbaa !2428
  br label %block_40167e

block_401289:                                     ; preds = %block_40127d
  %1718 = load i32, i32* %62, align 4
  %1719 = shl i32 %1718, 1
  %1720 = icmp slt i32 %1718, 0
  %1721 = icmp slt i32 %1719, 0
  %1722 = xor i1 %1720, %1721
  %1723 = zext i32 %1719 to i64
  store i64 %1723, i64* %RAX, align 8, !tbaa !2428
  %.lobit15 = lshr i32 %1718, 31
  %1724 = trunc i32 %.lobit15 to i8
  store i8 %1724, i8* %51, align 1, !tbaa !2432
  %1725 = and i32 %1719, 254
  %1726 = tail call i32 @llvm.ctpop.i32(i32 %1725) #10
  %1727 = trunc i32 %1726 to i8
  %1728 = and i8 %1727, 1
  %1729 = xor i8 %1728, 1
  store i8 %1729, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %1730 = icmp eq i32 %1719, 0
  %1731 = zext i1 %1730 to i8
  store i8 %1731, i8* %54, align 1, !tbaa !2432
  %1732 = lshr i32 %1718, 30
  %1733 = and i32 %1732, 1
  %1734 = trunc i32 %1733 to i8
  store i8 %1734, i8* %55, align 1, !tbaa !2432
  %1735 = zext i1 %1722 to i8
  store i8 %1735, i8* %56, align 1, !tbaa !2432
  %1736 = add i64 %59, -16
  %1737 = add i64 %95, 10
  store i64 %1737, i64* %PC, align 8
  %1738 = inttoptr i64 %1736 to i64*
  %1739 = load i64, i64* %1738, align 8
  store i64 %1739, i64* %RCX, align 8, !tbaa !2428
  %1740 = add i64 %95, 14
  store i64 %1740, i64* %PC, align 8
  %1741 = load i32, i32* %67, align 4
  %1742 = sext i32 %1741 to i64
  store i64 %1742, i64* %RDX, align 8, !tbaa !2428
  %1743 = shl nsw i64 %1742, 2
  %1744 = add i64 %1743, %1739
  %1745 = add i64 %95, 17
  store i64 %1745, i64* %PC, align 8
  %1746 = inttoptr i64 %1744 to i32*
  %1747 = load i32, i32* %1746, align 4
  %1748 = add i32 %1747, %1719
  %1749 = zext i32 %1748 to i64
  store i64 %1749, i64* %RAX, align 8, !tbaa !2428
  %1750 = icmp ult i32 %1748, %1719
  %1751 = icmp ult i32 %1748, %1747
  %1752 = or i1 %1750, %1751
  %1753 = zext i1 %1752 to i8
  store i8 %1753, i8* %51, align 1, !tbaa !2433
  %1754 = and i32 %1748, 255
  %1755 = tail call i32 @llvm.ctpop.i32(i32 %1754) #10
  %1756 = trunc i32 %1755 to i8
  %1757 = and i8 %1756, 1
  %1758 = xor i8 %1757, 1
  store i8 %1758, i8* %52, align 1, !tbaa !2447
  %1759 = xor i32 %1747, %1719
  %1760 = xor i32 %1759, %1748
  %1761 = lshr i32 %1760, 4
  %1762 = trunc i32 %1761 to i8
  %1763 = and i8 %1762, 1
  store i8 %1763, i8* %53, align 1, !tbaa !2451
  %1764 = icmp eq i32 %1748, 0
  %1765 = zext i1 %1764 to i8
  store i8 %1765, i8* %54, align 1, !tbaa !2448
  %1766 = lshr i32 %1748, 31
  %1767 = trunc i32 %1766 to i8
  store i8 %1767, i8* %55, align 1, !tbaa !2449
  %1768 = lshr i32 %1747, 31
  %1769 = xor i32 %1766, %1733
  %1770 = xor i32 %1766, %1768
  %1771 = add nuw nsw i32 %1769, %1770
  %1772 = icmp eq i32 %1771, 2
  %1773 = zext i1 %1772 to i8
  store i8 %1773, i8* %56, align 1, !tbaa !2450
  %1774 = add i64 %59, -32
  %1775 = add i64 %95, 20
  store i64 %1775, i64* %PC, align 8
  %1776 = inttoptr i64 %1774 to i32*
  store i32 %1748, i32* %1776, align 4
  %1777 = load i64, i64* %RBP, align 8
  %1778 = add i64 %1777, -36
  %1779 = load i64, i64* %PC, align 8
  %1780 = add i64 %1779, 3
  store i64 %1780, i64* %PC, align 8
  %1781 = inttoptr i64 %1778 to i32*
  %1782 = load i32, i32* %1781, align 4
  %1783 = shl i32 %1782, 1
  %1784 = icmp slt i32 %1782, 0
  %1785 = icmp slt i32 %1783, 0
  %1786 = xor i1 %1784, %1785
  %1787 = zext i32 %1783 to i64
  store i64 %1787, i64* %RAX, align 8, !tbaa !2428
  %.lobit16 = lshr i32 %1782, 31
  %1788 = trunc i32 %.lobit16 to i8
  store i8 %1788, i8* %51, align 1, !tbaa !2432
  %1789 = and i32 %1783, 254
  %1790 = tail call i32 @llvm.ctpop.i32(i32 %1789) #10
  %1791 = trunc i32 %1790 to i8
  %1792 = and i8 %1791, 1
  %1793 = xor i8 %1792, 1
  store i8 %1793, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %1794 = icmp eq i32 %1783, 0
  %1795 = zext i1 %1794 to i8
  store i8 %1795, i8* %54, align 1, !tbaa !2432
  %1796 = lshr i32 %1782, 30
  %1797 = and i32 %1796, 1
  %1798 = trunc i32 %1797 to i8
  store i8 %1798, i8* %55, align 1, !tbaa !2432
  %1799 = zext i1 %1786 to i8
  store i8 %1799, i8* %56, align 1, !tbaa !2432
  %1800 = add i64 %1777, -16
  %1801 = add i64 %1779, 10
  store i64 %1801, i64* %PC, align 8
  %1802 = inttoptr i64 %1800 to i64*
  %1803 = load i64, i64* %1802, align 8
  store i64 %1803, i64* %RCX, align 8, !tbaa !2428
  %1804 = add i64 %1777, -28
  %1805 = add i64 %1779, 14
  store i64 %1805, i64* %PC, align 8
  %1806 = inttoptr i64 %1804 to i32*
  %1807 = load i32, i32* %1806, align 4
  %1808 = sext i32 %1807 to i64
  store i64 %1808, i64* %RDX, align 8, !tbaa !2428
  %1809 = shl nsw i64 %1808, 2
  %1810 = add i64 %1809, %1803
  %1811 = add i64 %1779, 17
  store i64 %1811, i64* %PC, align 8
  %1812 = inttoptr i64 %1810 to i32*
  %1813 = load i32, i32* %1812, align 4
  %1814 = add i32 %1813, %1783
  %1815 = zext i32 %1814 to i64
  store i64 %1815, i64* %RAX, align 8, !tbaa !2428
  %1816 = icmp ult i32 %1814, %1783
  %1817 = icmp ult i32 %1814, %1813
  %1818 = or i1 %1816, %1817
  %1819 = zext i1 %1818 to i8
  store i8 %1819, i8* %51, align 1, !tbaa !2433
  %1820 = and i32 %1814, 255
  %1821 = tail call i32 @llvm.ctpop.i32(i32 %1820) #10
  %1822 = trunc i32 %1821 to i8
  %1823 = and i8 %1822, 1
  %1824 = xor i8 %1823, 1
  store i8 %1824, i8* %52, align 1, !tbaa !2447
  %1825 = xor i32 %1813, %1783
  %1826 = xor i32 %1825, %1814
  %1827 = lshr i32 %1826, 4
  %1828 = trunc i32 %1827 to i8
  %1829 = and i8 %1828, 1
  store i8 %1829, i8* %53, align 1, !tbaa !2451
  %1830 = icmp eq i32 %1814, 0
  %1831 = zext i1 %1830 to i8
  store i8 %1831, i8* %54, align 1, !tbaa !2448
  %1832 = lshr i32 %1814, 31
  %1833 = trunc i32 %1832 to i8
  store i8 %1833, i8* %55, align 1, !tbaa !2449
  %1834 = lshr i32 %1813, 31
  %1835 = xor i32 %1832, %1797
  %1836 = xor i32 %1832, %1834
  %1837 = add nuw nsw i32 %1835, %1836
  %1838 = icmp eq i32 %1837, 2
  %1839 = zext i1 %1838 to i8
  store i8 %1839, i8* %56, align 1, !tbaa !2450
  %1840 = add i64 %1777, -40
  %1841 = add i64 %1779, 20
  store i64 %1841, i64* %PC, align 8
  %1842 = inttoptr i64 %1840 to i32*
  store i32 %1814, i32* %1842, align 4
  %1843 = load i64, i64* %RBP, align 8
  %1844 = add i64 %1843, -24
  %1845 = load i64, i64* %PC, align 8
  %1846 = add i64 %1845, 4
  store i64 %1846, i64* %PC, align 8
  %1847 = inttoptr i64 %1844 to i64*
  %1848 = load i64, i64* %1847, align 8
  store i64 %1848, i64* %RCX, align 8, !tbaa !2428
  %1849 = add i64 %1843, -32
  %1850 = add i64 %1845, 8
  store i64 %1850, i64* %PC, align 8
  %1851 = inttoptr i64 %1849 to i32*
  %1852 = load i32, i32* %1851, align 4
  %1853 = sext i32 %1852 to i64
  store i64 %1853, i64* %RDX, align 8, !tbaa !2428
  %1854 = shl nsw i64 %1853, 3
  %1855 = add i64 %1854, %1848
  %1856 = add i64 %1845, 13
  store i64 %1856, i64* %PC, align 8
  %1857 = inttoptr i64 %1855 to i64*
  %1858 = load i64, i64* %1857, align 8
  %1859 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1858, i64* %1859, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %1860 = add i64 %1843, -64
  %1861 = add i64 %1845, 18
  store i64 %1861, i64* %PC, align 8
  %1862 = inttoptr i64 %1860 to i64*
  store i64 %1858, i64* %1862, align 8
  %1863 = load i64, i64* %RBP, align 8
  %1864 = add i64 %1863, -24
  %1865 = load i64, i64* %PC, align 8
  %1866 = add i64 %1865, 4
  store i64 %1866, i64* %PC, align 8
  %1867 = inttoptr i64 %1864 to i64*
  %1868 = load i64, i64* %1867, align 8
  store i64 %1868, i64* %RCX, align 8, !tbaa !2428
  %1869 = add i64 %1863, -32
  %1870 = add i64 %1865, 7
  store i64 %1870, i64* %PC, align 8
  %1871 = inttoptr i64 %1869 to i32*
  %1872 = load i32, i32* %1871, align 4
  %1873 = add i32 %1872, 1
  %1874 = zext i32 %1873 to i64
  store i64 %1874, i64* %RAX, align 8, !tbaa !2428
  %1875 = icmp eq i32 %1872, -1
  %1876 = icmp eq i32 %1873, 0
  %1877 = or i1 %1875, %1876
  %1878 = zext i1 %1877 to i8
  store i8 %1878, i8* %51, align 1, !tbaa !2433
  %1879 = and i32 %1873, 255
  %1880 = tail call i32 @llvm.ctpop.i32(i32 %1879) #10
  %1881 = trunc i32 %1880 to i8
  %1882 = and i8 %1881, 1
  %1883 = xor i8 %1882, 1
  store i8 %1883, i8* %52, align 1, !tbaa !2447
  %1884 = xor i32 %1872, %1873
  %1885 = lshr i32 %1884, 4
  %1886 = trunc i32 %1885 to i8
  %1887 = and i8 %1886, 1
  store i8 %1887, i8* %53, align 1, !tbaa !2451
  %1888 = icmp eq i32 %1873, 0
  %1889 = zext i1 %1888 to i8
  store i8 %1889, i8* %54, align 1, !tbaa !2448
  %1890 = lshr i32 %1873, 31
  %1891 = trunc i32 %1890 to i8
  store i8 %1891, i8* %55, align 1, !tbaa !2449
  %1892 = lshr i32 %1872, 31
  %1893 = xor i32 %1890, %1892
  %1894 = add nuw nsw i32 %1893, %1890
  %1895 = icmp eq i32 %1894, 2
  %1896 = zext i1 %1895 to i8
  store i8 %1896, i8* %56, align 1, !tbaa !2450
  %1897 = sext i32 %1873 to i64
  store i64 %1897, i64* %RDX, align 8, !tbaa !2428
  %1898 = shl nsw i64 %1897, 3
  %1899 = add i64 %1898, %1868
  %1900 = add i64 %1865, 18
  store i64 %1900, i64* %PC, align 8
  %1901 = inttoptr i64 %1899 to i64*
  %1902 = load i64, i64* %1901, align 8
  %1903 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1902, i64* %1903, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %1904 = add i64 %1863, -72
  %1905 = add i64 %1865, 23
  store i64 %1905, i64* %PC, align 8
  %1906 = inttoptr i64 %1904 to i64*
  store i64 %1902, i64* %1906, align 8
  %1907 = load i64, i64* %RBP, align 8
  %1908 = add i64 %1907, -24
  %1909 = load i64, i64* %PC, align 8
  %1910 = add i64 %1909, 4
  store i64 %1910, i64* %PC, align 8
  %1911 = inttoptr i64 %1908 to i64*
  %1912 = load i64, i64* %1911, align 8
  store i64 %1912, i64* %RCX, align 8, !tbaa !2428
  %1913 = add i64 %1907, -40
  %1914 = add i64 %1909, 8
  store i64 %1914, i64* %PC, align 8
  %1915 = inttoptr i64 %1913 to i32*
  %1916 = load i32, i32* %1915, align 4
  %1917 = sext i32 %1916 to i64
  store i64 %1917, i64* %RDX, align 8, !tbaa !2428
  %1918 = shl nsw i64 %1917, 3
  %1919 = add i64 %1918, %1912
  %1920 = add i64 %1909, 13
  store i64 %1920, i64* %PC, align 8
  %1921 = inttoptr i64 %1919 to i64*
  %1922 = load i64, i64* %1921, align 8
  %1923 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1922, i64* %1923, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %1924 = add i64 %1907, -80
  %1925 = add i64 %1909, 18
  store i64 %1925, i64* %PC, align 8
  %1926 = inttoptr i64 %1924 to i64*
  store i64 %1922, i64* %1926, align 8
  %1927 = load i64, i64* %RBP, align 8
  %1928 = add i64 %1927, -24
  %1929 = load i64, i64* %PC, align 8
  %1930 = add i64 %1929, 4
  store i64 %1930, i64* %PC, align 8
  %1931 = inttoptr i64 %1928 to i64*
  %1932 = load i64, i64* %1931, align 8
  store i64 %1932, i64* %RCX, align 8, !tbaa !2428
  %1933 = add i64 %1927, -40
  %1934 = add i64 %1929, 7
  store i64 %1934, i64* %PC, align 8
  %1935 = inttoptr i64 %1933 to i32*
  %1936 = load i32, i32* %1935, align 4
  %1937 = add i32 %1936, 1
  %1938 = zext i32 %1937 to i64
  store i64 %1938, i64* %RAX, align 8, !tbaa !2428
  %1939 = icmp eq i32 %1936, -1
  %1940 = icmp eq i32 %1937, 0
  %1941 = or i1 %1939, %1940
  %1942 = zext i1 %1941 to i8
  store i8 %1942, i8* %51, align 1, !tbaa !2433
  %1943 = and i32 %1937, 255
  %1944 = tail call i32 @llvm.ctpop.i32(i32 %1943) #10
  %1945 = trunc i32 %1944 to i8
  %1946 = and i8 %1945, 1
  %1947 = xor i8 %1946, 1
  store i8 %1947, i8* %52, align 1, !tbaa !2447
  %1948 = xor i32 %1936, %1937
  %1949 = lshr i32 %1948, 4
  %1950 = trunc i32 %1949 to i8
  %1951 = and i8 %1950, 1
  store i8 %1951, i8* %53, align 1, !tbaa !2451
  %1952 = icmp eq i32 %1937, 0
  %1953 = zext i1 %1952 to i8
  store i8 %1953, i8* %54, align 1, !tbaa !2448
  %1954 = lshr i32 %1937, 31
  %1955 = trunc i32 %1954 to i8
  store i8 %1955, i8* %55, align 1, !tbaa !2449
  %1956 = lshr i32 %1936, 31
  %1957 = xor i32 %1954, %1956
  %1958 = add nuw nsw i32 %1957, %1954
  %1959 = icmp eq i32 %1958, 2
  %1960 = zext i1 %1959 to i8
  store i8 %1960, i8* %56, align 1, !tbaa !2450
  %1961 = sext i32 %1937 to i64
  store i64 %1961, i64* %RDX, align 8, !tbaa !2428
  %1962 = shl nsw i64 %1961, 3
  %1963 = add i64 %1962, %1932
  %1964 = add i64 %1929, 18
  store i64 %1964, i64* %PC, align 8
  %1965 = inttoptr i64 %1963 to i64*
  %1966 = load i64, i64* %1965, align 8
  %1967 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1966, i64* %1967, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %1968 = add i64 %1927, -88
  %1969 = add i64 %1929, 23
  store i64 %1969, i64* %PC, align 8
  %1970 = inttoptr i64 %1968 to i64*
  store i64 %1966, i64* %1970, align 8
  %1971 = load i64, i64* %RBP, align 8
  %1972 = add i64 %1971, -80
  %1973 = load i64, i64* %PC, align 8
  %1974 = add i64 %1973, 5
  store i64 %1974, i64* %PC, align 8
  %1975 = inttoptr i64 %1972 to i64*
  %1976 = load i64, i64* %1975, align 8
  %1977 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1976, i64* %1977, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %1978 = add i64 %1971, -24
  %1979 = add i64 %1973, 9
  store i64 %1979, i64* %PC, align 8
  %1980 = inttoptr i64 %1978 to i64*
  %1981 = load i64, i64* %1980, align 8
  store i64 %1981, i64* %RCX, align 8, !tbaa !2428
  %1982 = add i64 %1971, -32
  %1983 = add i64 %1973, 13
  store i64 %1983, i64* %PC, align 8
  %1984 = inttoptr i64 %1982 to i32*
  %1985 = load i32, i32* %1984, align 4
  %1986 = sext i32 %1985 to i64
  store i64 %1986, i64* %RDX, align 8, !tbaa !2428
  %1987 = shl nsw i64 %1986, 3
  %1988 = add i64 %1987, %1981
  %1989 = add i64 %1973, 18
  store i64 %1989, i64* %PC, align 8
  %1990 = inttoptr i64 %1988 to i64*
  store i64 %1976, i64* %1990, align 8
  %1991 = load i64, i64* %RBP, align 8
  %1992 = add i64 %1991, -88
  %1993 = load i64, i64* %PC, align 8
  %1994 = add i64 %1993, 5
  store i64 %1994, i64* %PC, align 8
  %1995 = inttoptr i64 %1992 to i64*
  %1996 = load i64, i64* %1995, align 8
  %1997 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1996, i64* %1997, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %1998 = add i64 %1991, -24
  %1999 = add i64 %1993, 9
  store i64 %1999, i64* %PC, align 8
  %2000 = inttoptr i64 %1998 to i64*
  %2001 = load i64, i64* %2000, align 8
  store i64 %2001, i64* %RCX, align 8, !tbaa !2428
  %2002 = add i64 %1991, -32
  %2003 = add i64 %1993, 12
  store i64 %2003, i64* %PC, align 8
  %2004 = inttoptr i64 %2002 to i32*
  %2005 = load i32, i32* %2004, align 4
  %2006 = add i32 %2005, 1
  %2007 = zext i32 %2006 to i64
  store i64 %2007, i64* %RAX, align 8, !tbaa !2428
  %2008 = icmp eq i32 %2005, -1
  %2009 = icmp eq i32 %2006, 0
  %2010 = or i1 %2008, %2009
  %2011 = zext i1 %2010 to i8
  store i8 %2011, i8* %51, align 1, !tbaa !2433
  %2012 = and i32 %2006, 255
  %2013 = tail call i32 @llvm.ctpop.i32(i32 %2012) #10
  %2014 = trunc i32 %2013 to i8
  %2015 = and i8 %2014, 1
  %2016 = xor i8 %2015, 1
  store i8 %2016, i8* %52, align 1, !tbaa !2447
  %2017 = xor i32 %2005, %2006
  %2018 = lshr i32 %2017, 4
  %2019 = trunc i32 %2018 to i8
  %2020 = and i8 %2019, 1
  store i8 %2020, i8* %53, align 1, !tbaa !2451
  %2021 = icmp eq i32 %2006, 0
  %2022 = zext i1 %2021 to i8
  store i8 %2022, i8* %54, align 1, !tbaa !2448
  %2023 = lshr i32 %2006, 31
  %2024 = trunc i32 %2023 to i8
  store i8 %2024, i8* %55, align 1, !tbaa !2449
  %2025 = lshr i32 %2005, 31
  %2026 = xor i32 %2023, %2025
  %2027 = add nuw nsw i32 %2026, %2023
  %2028 = icmp eq i32 %2027, 2
  %2029 = zext i1 %2028 to i8
  store i8 %2029, i8* %56, align 1, !tbaa !2450
  %2030 = sext i32 %2006 to i64
  store i64 %2030, i64* %RDX, align 8, !tbaa !2428
  %2031 = shl nsw i64 %2030, 3
  %2032 = add i64 %2031, %2001
  %2033 = add i64 %1993, 23
  store i64 %2033, i64* %PC, align 8
  %2034 = inttoptr i64 %2032 to i64*
  store i64 %1996, i64* %2034, align 8
  %2035 = load i64, i64* %RBP, align 8
  %2036 = add i64 %2035, -64
  %2037 = load i64, i64* %PC, align 8
  %2038 = add i64 %2037, 5
  store i64 %2038, i64* %PC, align 8
  %2039 = inttoptr i64 %2036 to i64*
  %2040 = load i64, i64* %2039, align 8
  %2041 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2040, i64* %2041, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2042 = add i64 %2035, -24
  %2043 = add i64 %2037, 9
  store i64 %2043, i64* %PC, align 8
  %2044 = inttoptr i64 %2042 to i64*
  %2045 = load i64, i64* %2044, align 8
  store i64 %2045, i64* %RCX, align 8, !tbaa !2428
  %2046 = add i64 %2035, -40
  %2047 = add i64 %2037, 13
  store i64 %2047, i64* %PC, align 8
  %2048 = inttoptr i64 %2046 to i32*
  %2049 = load i32, i32* %2048, align 4
  %2050 = sext i32 %2049 to i64
  store i64 %2050, i64* %RDX, align 8, !tbaa !2428
  %2051 = shl nsw i64 %2050, 3
  %2052 = add i64 %2051, %2045
  %2053 = add i64 %2037, 18
  store i64 %2053, i64* %PC, align 8
  %2054 = inttoptr i64 %2052 to i64*
  store i64 %2040, i64* %2054, align 8
  %2055 = load i64, i64* %RBP, align 8
  %2056 = add i64 %2055, -72
  %2057 = load i64, i64* %PC, align 8
  %2058 = add i64 %2057, 5
  store i64 %2058, i64* %PC, align 8
  %2059 = inttoptr i64 %2056 to i64*
  %2060 = load i64, i64* %2059, align 8
  %2061 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2060, i64* %2061, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2062 = add i64 %2055, -24
  %2063 = add i64 %2057, 9
  store i64 %2063, i64* %PC, align 8
  %2064 = inttoptr i64 %2062 to i64*
  %2065 = load i64, i64* %2064, align 8
  store i64 %2065, i64* %RCX, align 8, !tbaa !2428
  %2066 = add i64 %2055, -40
  %2067 = add i64 %2057, 12
  store i64 %2067, i64* %PC, align 8
  %2068 = inttoptr i64 %2066 to i32*
  %2069 = load i32, i32* %2068, align 4
  %2070 = add i32 %2069, 1
  %2071 = zext i32 %2070 to i64
  store i64 %2071, i64* %RAX, align 8, !tbaa !2428
  %2072 = icmp eq i32 %2069, -1
  %2073 = icmp eq i32 %2070, 0
  %2074 = or i1 %2072, %2073
  %2075 = zext i1 %2074 to i8
  store i8 %2075, i8* %51, align 1, !tbaa !2433
  %2076 = and i32 %2070, 255
  %2077 = tail call i32 @llvm.ctpop.i32(i32 %2076) #10
  %2078 = trunc i32 %2077 to i8
  %2079 = and i8 %2078, 1
  %2080 = xor i8 %2079, 1
  store i8 %2080, i8* %52, align 1, !tbaa !2447
  %2081 = xor i32 %2069, %2070
  %2082 = lshr i32 %2081, 4
  %2083 = trunc i32 %2082 to i8
  %2084 = and i8 %2083, 1
  store i8 %2084, i8* %53, align 1, !tbaa !2451
  %2085 = icmp eq i32 %2070, 0
  %2086 = zext i1 %2085 to i8
  store i8 %2086, i8* %54, align 1, !tbaa !2448
  %2087 = lshr i32 %2070, 31
  %2088 = trunc i32 %2087 to i8
  store i8 %2088, i8* %55, align 1, !tbaa !2449
  %2089 = lshr i32 %2069, 31
  %2090 = xor i32 %2087, %2089
  %2091 = add nuw nsw i32 %2090, %2087
  %2092 = icmp eq i32 %2091, 2
  %2093 = zext i1 %2092 to i8
  store i8 %2093, i8* %56, align 1, !tbaa !2450
  %2094 = sext i32 %2070 to i64
  store i64 %2094, i64* %RDX, align 8, !tbaa !2428
  %2095 = shl nsw i64 %2094, 3
  %2096 = add i64 %2095, %2065
  %2097 = add i64 %2057, 23
  store i64 %2097, i64* %PC, align 8
  %2098 = inttoptr i64 %2096 to i64*
  store i64 %2060, i64* %2098, align 8
  %2099 = load i64, i64* %RBP, align 8
  %2100 = add i64 %2099, -52
  %2101 = load i64, i64* %PC, align 8
  %2102 = add i64 %2101, 3
  store i64 %2102, i64* %PC, align 8
  %2103 = inttoptr i64 %2100 to i32*
  %2104 = load i32, i32* %2103, align 4
  %2105 = zext i32 %2104 to i64
  store i64 %2105, i64* %RAX, align 8, !tbaa !2428
  %2106 = add i64 %2099, -32
  %2107 = add i64 %2101, 6
  store i64 %2107, i64* %PC, align 8
  %2108 = inttoptr i64 %2106 to i32*
  %2109 = load i32, i32* %2108, align 4
  %2110 = add i32 %2109, %2104
  %2111 = zext i32 %2110 to i64
  store i64 %2111, i64* %RAX, align 8, !tbaa !2428
  %2112 = icmp ult i32 %2110, %2104
  %2113 = icmp ult i32 %2110, %2109
  %2114 = or i1 %2112, %2113
  %2115 = zext i1 %2114 to i8
  store i8 %2115, i8* %51, align 1, !tbaa !2433
  %2116 = and i32 %2110, 255
  %2117 = tail call i32 @llvm.ctpop.i32(i32 %2116) #10
  %2118 = trunc i32 %2117 to i8
  %2119 = and i8 %2118, 1
  %2120 = xor i8 %2119, 1
  store i8 %2120, i8* %52, align 1, !tbaa !2447
  %2121 = xor i32 %2109, %2104
  %2122 = xor i32 %2121, %2110
  %2123 = lshr i32 %2122, 4
  %2124 = trunc i32 %2123 to i8
  %2125 = and i8 %2124, 1
  store i8 %2125, i8* %53, align 1, !tbaa !2451
  %2126 = icmp eq i32 %2110, 0
  %2127 = zext i1 %2126 to i8
  store i8 %2127, i8* %54, align 1, !tbaa !2448
  %2128 = lshr i32 %2110, 31
  %2129 = trunc i32 %2128 to i8
  store i8 %2129, i8* %55, align 1, !tbaa !2449
  %2130 = lshr i32 %2104, 31
  %2131 = lshr i32 %2109, 31
  %2132 = xor i32 %2128, %2130
  %2133 = xor i32 %2128, %2131
  %2134 = add nuw nsw i32 %2132, %2133
  %2135 = icmp eq i32 %2134, 2
  %2136 = zext i1 %2135 to i8
  store i8 %2136, i8* %56, align 1, !tbaa !2450
  %2137 = add i64 %2101, 9
  store i64 %2137, i64* %PC, align 8
  store i32 %2110, i32* %2108, align 4
  %2138 = load i64, i64* %RBP, align 8
  %2139 = add i64 %2138, -52
  %2140 = load i64, i64* %PC, align 8
  %2141 = add i64 %2140, 3
  store i64 %2141, i64* %PC, align 8
  %2142 = inttoptr i64 %2139 to i32*
  %2143 = load i32, i32* %2142, align 4
  %2144 = shl i32 %2143, 1
  %2145 = icmp slt i32 %2143, 0
  %2146 = icmp slt i32 %2144, 0
  %2147 = xor i1 %2145, %2146
  %2148 = zext i32 %2144 to i64
  store i64 %2148, i64* %RAX, align 8, !tbaa !2428
  %.lobit17 = lshr i32 %2143, 31
  %2149 = trunc i32 %.lobit17 to i8
  store i8 %2149, i8* %51, align 1, !tbaa !2432
  %2150 = and i32 %2144, 254
  %2151 = tail call i32 @llvm.ctpop.i32(i32 %2150) #10
  %2152 = trunc i32 %2151 to i8
  %2153 = and i8 %2152, 1
  %2154 = xor i8 %2153, 1
  store i8 %2154, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %2155 = icmp eq i32 %2144, 0
  %2156 = zext i1 %2155 to i8
  store i8 %2156, i8* %54, align 1, !tbaa !2432
  %2157 = lshr i32 %2143, 30
  %2158 = and i32 %2157, 1
  %2159 = trunc i32 %2158 to i8
  store i8 %2159, i8* %55, align 1, !tbaa !2432
  %2160 = zext i1 %2147 to i8
  store i8 %2160, i8* %56, align 1, !tbaa !2432
  %2161 = add i64 %2138, -40
  %2162 = add i64 %2140, 9
  store i64 %2162, i64* %PC, align 8
  %2163 = inttoptr i64 %2161 to i32*
  %2164 = load i32, i32* %2163, align 4
  %2165 = add i32 %2164, %2144
  %2166 = zext i32 %2165 to i64
  store i64 %2166, i64* %RAX, align 8, !tbaa !2428
  %2167 = icmp ult i32 %2165, %2144
  %2168 = icmp ult i32 %2165, %2164
  %2169 = or i1 %2167, %2168
  %2170 = zext i1 %2169 to i8
  store i8 %2170, i8* %51, align 1, !tbaa !2433
  %2171 = and i32 %2165, 255
  %2172 = tail call i32 @llvm.ctpop.i32(i32 %2171) #10
  %2173 = trunc i32 %2172 to i8
  %2174 = and i8 %2173, 1
  %2175 = xor i8 %2174, 1
  store i8 %2175, i8* %52, align 1, !tbaa !2447
  %2176 = xor i32 %2164, %2144
  %2177 = xor i32 %2176, %2165
  %2178 = lshr i32 %2177, 4
  %2179 = trunc i32 %2178 to i8
  %2180 = and i8 %2179, 1
  store i8 %2180, i8* %53, align 1, !tbaa !2451
  %2181 = icmp eq i32 %2165, 0
  %2182 = zext i1 %2181 to i8
  store i8 %2182, i8* %54, align 1, !tbaa !2448
  %2183 = lshr i32 %2165, 31
  %2184 = trunc i32 %2183 to i8
  store i8 %2184, i8* %55, align 1, !tbaa !2449
  %2185 = lshr i32 %2164, 31
  %2186 = xor i32 %2183, %2158
  %2187 = xor i32 %2183, %2185
  %2188 = add nuw nsw i32 %2186, %2187
  %2189 = icmp eq i32 %2188, 2
  %2190 = zext i1 %2189 to i8
  store i8 %2190, i8* %56, align 1, !tbaa !2450
  %2191 = add i64 %2140, 12
  store i64 %2191, i64* %PC, align 8
  store i32 %2165, i32* %2163, align 4
  %2192 = load i64, i64* %RBP, align 8
  %2193 = add i64 %2192, -24
  %2194 = load i64, i64* %PC, align 8
  %2195 = add i64 %2194, 4
  store i64 %2195, i64* %PC, align 8
  %2196 = inttoptr i64 %2193 to i64*
  %2197 = load i64, i64* %2196, align 8
  store i64 %2197, i64* %RCX, align 8, !tbaa !2428
  %2198 = add i64 %2192, -32
  %2199 = add i64 %2194, 8
  store i64 %2199, i64* %PC, align 8
  %2200 = inttoptr i64 %2198 to i32*
  %2201 = load i32, i32* %2200, align 4
  %2202 = sext i32 %2201 to i64
  store i64 %2202, i64* %RDX, align 8, !tbaa !2428
  %2203 = shl nsw i64 %2202, 3
  %2204 = add i64 %2203, %2197
  %2205 = add i64 %2194, 13
  store i64 %2205, i64* %PC, align 8
  %2206 = inttoptr i64 %2204 to i64*
  %2207 = load i64, i64* %2206, align 8
  %2208 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2207, i64* %2208, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2209 = add i64 %2192, -64
  %2210 = add i64 %2194, 18
  store i64 %2210, i64* %PC, align 8
  %2211 = inttoptr i64 %2209 to i64*
  store i64 %2207, i64* %2211, align 8
  %2212 = load i64, i64* %RBP, align 8
  %2213 = add i64 %2212, -24
  %2214 = load i64, i64* %PC, align 8
  %2215 = add i64 %2214, 4
  store i64 %2215, i64* %PC, align 8
  %2216 = inttoptr i64 %2213 to i64*
  %2217 = load i64, i64* %2216, align 8
  store i64 %2217, i64* %RCX, align 8, !tbaa !2428
  %2218 = add i64 %2212, -32
  %2219 = add i64 %2214, 7
  store i64 %2219, i64* %PC, align 8
  %2220 = inttoptr i64 %2218 to i32*
  %2221 = load i32, i32* %2220, align 4
  %2222 = add i32 %2221, 1
  %2223 = zext i32 %2222 to i64
  store i64 %2223, i64* %RAX, align 8, !tbaa !2428
  %2224 = icmp eq i32 %2221, -1
  %2225 = icmp eq i32 %2222, 0
  %2226 = or i1 %2224, %2225
  %2227 = zext i1 %2226 to i8
  store i8 %2227, i8* %51, align 1, !tbaa !2433
  %2228 = and i32 %2222, 255
  %2229 = tail call i32 @llvm.ctpop.i32(i32 %2228) #10
  %2230 = trunc i32 %2229 to i8
  %2231 = and i8 %2230, 1
  %2232 = xor i8 %2231, 1
  store i8 %2232, i8* %52, align 1, !tbaa !2447
  %2233 = xor i32 %2221, %2222
  %2234 = lshr i32 %2233, 4
  %2235 = trunc i32 %2234 to i8
  %2236 = and i8 %2235, 1
  store i8 %2236, i8* %53, align 1, !tbaa !2451
  %2237 = icmp eq i32 %2222, 0
  %2238 = zext i1 %2237 to i8
  store i8 %2238, i8* %54, align 1, !tbaa !2448
  %2239 = lshr i32 %2222, 31
  %2240 = trunc i32 %2239 to i8
  store i8 %2240, i8* %55, align 1, !tbaa !2449
  %2241 = lshr i32 %2221, 31
  %2242 = xor i32 %2239, %2241
  %2243 = add nuw nsw i32 %2242, %2239
  %2244 = icmp eq i32 %2243, 2
  %2245 = zext i1 %2244 to i8
  store i8 %2245, i8* %56, align 1, !tbaa !2450
  %2246 = sext i32 %2222 to i64
  store i64 %2246, i64* %RDX, align 8, !tbaa !2428
  %2247 = shl nsw i64 %2246, 3
  %2248 = add i64 %2247, %2217
  %2249 = add i64 %2214, 18
  store i64 %2249, i64* %PC, align 8
  %2250 = inttoptr i64 %2248 to i64*
  %2251 = load i64, i64* %2250, align 8
  %2252 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2251, i64* %2252, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2253 = add i64 %2212, -72
  %2254 = add i64 %2214, 23
  store i64 %2254, i64* %PC, align 8
  %2255 = inttoptr i64 %2253 to i64*
  store i64 %2251, i64* %2255, align 8
  %2256 = load i64, i64* %RBP, align 8
  %2257 = add i64 %2256, -24
  %2258 = load i64, i64* %PC, align 8
  %2259 = add i64 %2258, 4
  store i64 %2259, i64* %PC, align 8
  %2260 = inttoptr i64 %2257 to i64*
  %2261 = load i64, i64* %2260, align 8
  store i64 %2261, i64* %RCX, align 8, !tbaa !2428
  %2262 = add i64 %2256, -40
  %2263 = add i64 %2258, 8
  store i64 %2263, i64* %PC, align 8
  %2264 = inttoptr i64 %2262 to i32*
  %2265 = load i32, i32* %2264, align 4
  %2266 = sext i32 %2265 to i64
  store i64 %2266, i64* %RDX, align 8, !tbaa !2428
  %2267 = shl nsw i64 %2266, 3
  %2268 = add i64 %2267, %2261
  %2269 = add i64 %2258, 13
  store i64 %2269, i64* %PC, align 8
  %2270 = inttoptr i64 %2268 to i64*
  %2271 = load i64, i64* %2270, align 8
  %2272 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2271, i64* %2272, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2273 = add i64 %2256, -80
  %2274 = add i64 %2258, 18
  store i64 %2274, i64* %PC, align 8
  %2275 = inttoptr i64 %2273 to i64*
  store i64 %2271, i64* %2275, align 8
  %2276 = load i64, i64* %RBP, align 8
  %2277 = add i64 %2276, -24
  %2278 = load i64, i64* %PC, align 8
  %2279 = add i64 %2278, 4
  store i64 %2279, i64* %PC, align 8
  %2280 = inttoptr i64 %2277 to i64*
  %2281 = load i64, i64* %2280, align 8
  store i64 %2281, i64* %RCX, align 8, !tbaa !2428
  %2282 = add i64 %2276, -40
  %2283 = add i64 %2278, 7
  store i64 %2283, i64* %PC, align 8
  %2284 = inttoptr i64 %2282 to i32*
  %2285 = load i32, i32* %2284, align 4
  %2286 = add i32 %2285, 1
  %2287 = zext i32 %2286 to i64
  store i64 %2287, i64* %RAX, align 8, !tbaa !2428
  %2288 = icmp eq i32 %2285, -1
  %2289 = icmp eq i32 %2286, 0
  %2290 = or i1 %2288, %2289
  %2291 = zext i1 %2290 to i8
  store i8 %2291, i8* %51, align 1, !tbaa !2433
  %2292 = and i32 %2286, 255
  %2293 = tail call i32 @llvm.ctpop.i32(i32 %2292) #10
  %2294 = trunc i32 %2293 to i8
  %2295 = and i8 %2294, 1
  %2296 = xor i8 %2295, 1
  store i8 %2296, i8* %52, align 1, !tbaa !2447
  %2297 = xor i32 %2285, %2286
  %2298 = lshr i32 %2297, 4
  %2299 = trunc i32 %2298 to i8
  %2300 = and i8 %2299, 1
  store i8 %2300, i8* %53, align 1, !tbaa !2451
  %2301 = icmp eq i32 %2286, 0
  %2302 = zext i1 %2301 to i8
  store i8 %2302, i8* %54, align 1, !tbaa !2448
  %2303 = lshr i32 %2286, 31
  %2304 = trunc i32 %2303 to i8
  store i8 %2304, i8* %55, align 1, !tbaa !2449
  %2305 = lshr i32 %2285, 31
  %2306 = xor i32 %2303, %2305
  %2307 = add nuw nsw i32 %2306, %2303
  %2308 = icmp eq i32 %2307, 2
  %2309 = zext i1 %2308 to i8
  store i8 %2309, i8* %56, align 1, !tbaa !2450
  %2310 = sext i32 %2286 to i64
  store i64 %2310, i64* %RDX, align 8, !tbaa !2428
  %2311 = shl nsw i64 %2310, 3
  %2312 = add i64 %2311, %2281
  %2313 = add i64 %2278, 18
  store i64 %2313, i64* %PC, align 8
  %2314 = inttoptr i64 %2312 to i64*
  %2315 = load i64, i64* %2314, align 8
  %2316 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2315, i64* %2316, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2317 = add i64 %2276, -88
  %2318 = add i64 %2278, 23
  store i64 %2318, i64* %PC, align 8
  %2319 = inttoptr i64 %2317 to i64*
  store i64 %2315, i64* %2319, align 8
  %2320 = load i64, i64* %RBP, align 8
  %2321 = add i64 %2320, -80
  %2322 = load i64, i64* %PC, align 8
  %2323 = add i64 %2322, 5
  store i64 %2323, i64* %PC, align 8
  %2324 = inttoptr i64 %2321 to i64*
  %2325 = load i64, i64* %2324, align 8
  %2326 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2325, i64* %2326, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2327 = add i64 %2320, -24
  %2328 = add i64 %2322, 9
  store i64 %2328, i64* %PC, align 8
  %2329 = inttoptr i64 %2327 to i64*
  %2330 = load i64, i64* %2329, align 8
  store i64 %2330, i64* %RCX, align 8, !tbaa !2428
  %2331 = add i64 %2320, -32
  %2332 = add i64 %2322, 13
  store i64 %2332, i64* %PC, align 8
  %2333 = inttoptr i64 %2331 to i32*
  %2334 = load i32, i32* %2333, align 4
  %2335 = sext i32 %2334 to i64
  store i64 %2335, i64* %RDX, align 8, !tbaa !2428
  %2336 = shl nsw i64 %2335, 3
  %2337 = add i64 %2336, %2330
  %2338 = add i64 %2322, 18
  store i64 %2338, i64* %PC, align 8
  %2339 = inttoptr i64 %2337 to i64*
  store i64 %2325, i64* %2339, align 8
  %2340 = load i64, i64* %RBP, align 8
  %2341 = add i64 %2340, -88
  %2342 = load i64, i64* %PC, align 8
  %2343 = add i64 %2342, 5
  store i64 %2343, i64* %PC, align 8
  %2344 = inttoptr i64 %2341 to i64*
  %2345 = load i64, i64* %2344, align 8
  %2346 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2345, i64* %2346, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2347 = add i64 %2340, -24
  %2348 = add i64 %2342, 9
  store i64 %2348, i64* %PC, align 8
  %2349 = inttoptr i64 %2347 to i64*
  %2350 = load i64, i64* %2349, align 8
  store i64 %2350, i64* %RCX, align 8, !tbaa !2428
  %2351 = add i64 %2340, -32
  %2352 = add i64 %2342, 12
  store i64 %2352, i64* %PC, align 8
  %2353 = inttoptr i64 %2351 to i32*
  %2354 = load i32, i32* %2353, align 4
  %2355 = add i32 %2354, 1
  %2356 = zext i32 %2355 to i64
  store i64 %2356, i64* %RAX, align 8, !tbaa !2428
  %2357 = icmp eq i32 %2354, -1
  %2358 = icmp eq i32 %2355, 0
  %2359 = or i1 %2357, %2358
  %2360 = zext i1 %2359 to i8
  store i8 %2360, i8* %51, align 1, !tbaa !2433
  %2361 = and i32 %2355, 255
  %2362 = tail call i32 @llvm.ctpop.i32(i32 %2361) #10
  %2363 = trunc i32 %2362 to i8
  %2364 = and i8 %2363, 1
  %2365 = xor i8 %2364, 1
  store i8 %2365, i8* %52, align 1, !tbaa !2447
  %2366 = xor i32 %2354, %2355
  %2367 = lshr i32 %2366, 4
  %2368 = trunc i32 %2367 to i8
  %2369 = and i8 %2368, 1
  store i8 %2369, i8* %53, align 1, !tbaa !2451
  %2370 = icmp eq i32 %2355, 0
  %2371 = zext i1 %2370 to i8
  store i8 %2371, i8* %54, align 1, !tbaa !2448
  %2372 = lshr i32 %2355, 31
  %2373 = trunc i32 %2372 to i8
  store i8 %2373, i8* %55, align 1, !tbaa !2449
  %2374 = lshr i32 %2354, 31
  %2375 = xor i32 %2372, %2374
  %2376 = add nuw nsw i32 %2375, %2372
  %2377 = icmp eq i32 %2376, 2
  %2378 = zext i1 %2377 to i8
  store i8 %2378, i8* %56, align 1, !tbaa !2450
  %2379 = sext i32 %2355 to i64
  store i64 %2379, i64* %RDX, align 8, !tbaa !2428
  %2380 = shl nsw i64 %2379, 3
  %2381 = add i64 %2380, %2350
  %2382 = add i64 %2342, 23
  store i64 %2382, i64* %PC, align 8
  %2383 = inttoptr i64 %2381 to i64*
  store i64 %2345, i64* %2383, align 8
  %2384 = load i64, i64* %RBP, align 8
  %2385 = add i64 %2384, -64
  %2386 = load i64, i64* %PC, align 8
  %2387 = add i64 %2386, 5
  store i64 %2387, i64* %PC, align 8
  %2388 = inttoptr i64 %2385 to i64*
  %2389 = load i64, i64* %2388, align 8
  %2390 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2389, i64* %2390, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2391 = add i64 %2384, -24
  %2392 = add i64 %2386, 9
  store i64 %2392, i64* %PC, align 8
  %2393 = inttoptr i64 %2391 to i64*
  %2394 = load i64, i64* %2393, align 8
  store i64 %2394, i64* %RCX, align 8, !tbaa !2428
  %2395 = add i64 %2384, -40
  %2396 = add i64 %2386, 13
  store i64 %2396, i64* %PC, align 8
  %2397 = inttoptr i64 %2395 to i32*
  %2398 = load i32, i32* %2397, align 4
  %2399 = sext i32 %2398 to i64
  store i64 %2399, i64* %RDX, align 8, !tbaa !2428
  %2400 = shl nsw i64 %2399, 3
  %2401 = add i64 %2400, %2394
  %2402 = add i64 %2386, 18
  store i64 %2402, i64* %PC, align 8
  %2403 = inttoptr i64 %2401 to i64*
  store i64 %2389, i64* %2403, align 8
  %2404 = load i64, i64* %RBP, align 8
  %2405 = add i64 %2404, -72
  %2406 = load i64, i64* %PC, align 8
  %2407 = add i64 %2406, 5
  store i64 %2407, i64* %PC, align 8
  %2408 = inttoptr i64 %2405 to i64*
  %2409 = load i64, i64* %2408, align 8
  %2410 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2409, i64* %2410, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2411 = add i64 %2404, -24
  %2412 = add i64 %2406, 9
  store i64 %2412, i64* %PC, align 8
  %2413 = inttoptr i64 %2411 to i64*
  %2414 = load i64, i64* %2413, align 8
  store i64 %2414, i64* %RCX, align 8, !tbaa !2428
  %2415 = add i64 %2404, -40
  %2416 = add i64 %2406, 12
  store i64 %2416, i64* %PC, align 8
  %2417 = inttoptr i64 %2415 to i32*
  %2418 = load i32, i32* %2417, align 4
  %2419 = add i32 %2418, 1
  %2420 = zext i32 %2419 to i64
  store i64 %2420, i64* %RAX, align 8, !tbaa !2428
  %2421 = icmp eq i32 %2418, -1
  %2422 = icmp eq i32 %2419, 0
  %2423 = or i1 %2421, %2422
  %2424 = zext i1 %2423 to i8
  store i8 %2424, i8* %51, align 1, !tbaa !2433
  %2425 = and i32 %2419, 255
  %2426 = tail call i32 @llvm.ctpop.i32(i32 %2425) #10
  %2427 = trunc i32 %2426 to i8
  %2428 = and i8 %2427, 1
  %2429 = xor i8 %2428, 1
  store i8 %2429, i8* %52, align 1, !tbaa !2447
  %2430 = xor i32 %2418, %2419
  %2431 = lshr i32 %2430, 4
  %2432 = trunc i32 %2431 to i8
  %2433 = and i8 %2432, 1
  store i8 %2433, i8* %53, align 1, !tbaa !2451
  %2434 = icmp eq i32 %2419, 0
  %2435 = zext i1 %2434 to i8
  store i8 %2435, i8* %54, align 1, !tbaa !2448
  %2436 = lshr i32 %2419, 31
  %2437 = trunc i32 %2436 to i8
  store i8 %2437, i8* %55, align 1, !tbaa !2449
  %2438 = lshr i32 %2418, 31
  %2439 = xor i32 %2436, %2438
  %2440 = add nuw nsw i32 %2439, %2436
  %2441 = icmp eq i32 %2440, 2
  %2442 = zext i1 %2441 to i8
  store i8 %2442, i8* %56, align 1, !tbaa !2450
  %2443 = sext i32 %2419 to i64
  store i64 %2443, i64* %RDX, align 8, !tbaa !2428
  %2444 = shl nsw i64 %2443, 3
  %2445 = add i64 %2444, %2414
  %2446 = add i64 %2406, 23
  store i64 %2446, i64* %PC, align 8
  %2447 = inttoptr i64 %2445 to i64*
  store i64 %2409, i64* %2447, align 8
  %2448 = load i64, i64* %RBP, align 8
  %2449 = add i64 %2448, -52
  %2450 = load i64, i64* %PC, align 8
  %2451 = add i64 %2450, 3
  store i64 %2451, i64* %PC, align 8
  %2452 = inttoptr i64 %2449 to i32*
  %2453 = load i32, i32* %2452, align 4
  %2454 = zext i32 %2453 to i64
  store i64 %2454, i64* %RAX, align 8, !tbaa !2428
  %2455 = add i64 %2448, -32
  %2456 = add i64 %2450, 6
  store i64 %2456, i64* %PC, align 8
  %2457 = inttoptr i64 %2455 to i32*
  %2458 = load i32, i32* %2457, align 4
  %2459 = add i32 %2458, %2453
  %2460 = zext i32 %2459 to i64
  store i64 %2460, i64* %RAX, align 8, !tbaa !2428
  %2461 = icmp ult i32 %2459, %2453
  %2462 = icmp ult i32 %2459, %2458
  %2463 = or i1 %2461, %2462
  %2464 = zext i1 %2463 to i8
  store i8 %2464, i8* %51, align 1, !tbaa !2433
  %2465 = and i32 %2459, 255
  %2466 = tail call i32 @llvm.ctpop.i32(i32 %2465) #10
  %2467 = trunc i32 %2466 to i8
  %2468 = and i8 %2467, 1
  %2469 = xor i8 %2468, 1
  store i8 %2469, i8* %52, align 1, !tbaa !2447
  %2470 = xor i32 %2458, %2453
  %2471 = xor i32 %2470, %2459
  %2472 = lshr i32 %2471, 4
  %2473 = trunc i32 %2472 to i8
  %2474 = and i8 %2473, 1
  store i8 %2474, i8* %53, align 1, !tbaa !2451
  %2475 = icmp eq i32 %2459, 0
  %2476 = zext i1 %2475 to i8
  store i8 %2476, i8* %54, align 1, !tbaa !2448
  %2477 = lshr i32 %2459, 31
  %2478 = trunc i32 %2477 to i8
  store i8 %2478, i8* %55, align 1, !tbaa !2449
  %2479 = lshr i32 %2453, 31
  %2480 = lshr i32 %2458, 31
  %2481 = xor i32 %2477, %2479
  %2482 = xor i32 %2477, %2480
  %2483 = add nuw nsw i32 %2481, %2482
  %2484 = icmp eq i32 %2483, 2
  %2485 = zext i1 %2484 to i8
  store i8 %2485, i8* %56, align 1, !tbaa !2450
  %2486 = add i64 %2450, 9
  store i64 %2486, i64* %PC, align 8
  store i32 %2459, i32* %2457, align 4
  %2487 = load i64, i64* %RBP, align 8
  %2488 = add i64 %2487, -52
  %2489 = load i64, i64* %PC, align 8
  %2490 = add i64 %2489, 3
  store i64 %2490, i64* %PC, align 8
  %2491 = inttoptr i64 %2488 to i32*
  %2492 = load i32, i32* %2491, align 4
  %2493 = zext i32 %2492 to i64
  store i64 %2493, i64* %RAX, align 8, !tbaa !2428
  %2494 = add i64 %2487, -40
  %2495 = add i64 %2489, 6
  store i64 %2495, i64* %PC, align 8
  %2496 = inttoptr i64 %2494 to i32*
  %2497 = load i32, i32* %2496, align 4
  %2498 = sub i32 %2497, %2492
  %2499 = zext i32 %2498 to i64
  store i64 %2499, i64* %RSI, align 8, !tbaa !2428
  %2500 = icmp ult i32 %2497, %2492
  %2501 = zext i1 %2500 to i8
  store i8 %2501, i8* %51, align 1, !tbaa !2433
  %2502 = and i32 %2498, 255
  %2503 = tail call i32 @llvm.ctpop.i32(i32 %2502) #10
  %2504 = trunc i32 %2503 to i8
  %2505 = and i8 %2504, 1
  %2506 = xor i8 %2505, 1
  store i8 %2506, i8* %52, align 1, !tbaa !2447
  %2507 = xor i32 %2492, %2497
  %2508 = xor i32 %2507, %2498
  %2509 = lshr i32 %2508, 4
  %2510 = trunc i32 %2509 to i8
  %2511 = and i8 %2510, 1
  store i8 %2511, i8* %53, align 1, !tbaa !2451
  %2512 = icmp eq i32 %2498, 0
  %2513 = zext i1 %2512 to i8
  store i8 %2513, i8* %54, align 1, !tbaa !2448
  %2514 = lshr i32 %2498, 31
  %2515 = trunc i32 %2514 to i8
  store i8 %2515, i8* %55, align 1, !tbaa !2449
  %2516 = lshr i32 %2497, 31
  %2517 = lshr i32 %2492, 31
  %2518 = xor i32 %2517, %2516
  %2519 = xor i32 %2514, %2516
  %2520 = add nuw nsw i32 %2519, %2518
  %2521 = icmp eq i32 %2520, 2
  %2522 = zext i1 %2521 to i8
  store i8 %2522, i8* %56, align 1, !tbaa !2450
  %2523 = add i64 %2489, 11
  store i64 %2523, i64* %PC, align 8
  store i32 %2498, i32* %2496, align 4
  %2524 = load i64, i64* %RBP, align 8
  %2525 = add i64 %2524, -24
  %2526 = load i64, i64* %PC, align 8
  %2527 = add i64 %2526, 4
  store i64 %2527, i64* %PC, align 8
  %2528 = inttoptr i64 %2525 to i64*
  %2529 = load i64, i64* %2528, align 8
  store i64 %2529, i64* %RCX, align 8, !tbaa !2428
  %2530 = add i64 %2524, -32
  %2531 = add i64 %2526, 8
  store i64 %2531, i64* %PC, align 8
  %2532 = inttoptr i64 %2530 to i32*
  %2533 = load i32, i32* %2532, align 4
  %2534 = sext i32 %2533 to i64
  store i64 %2534, i64* %RDX, align 8, !tbaa !2428
  %2535 = shl nsw i64 %2534, 3
  %2536 = add i64 %2535, %2529
  %2537 = add i64 %2526, 13
  store i64 %2537, i64* %PC, align 8
  %2538 = inttoptr i64 %2536 to i64*
  %2539 = load i64, i64* %2538, align 8
  %2540 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2539, i64* %2540, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2541 = add i64 %2524, -64
  %2542 = add i64 %2526, 18
  store i64 %2542, i64* %PC, align 8
  %2543 = inttoptr i64 %2541 to i64*
  store i64 %2539, i64* %2543, align 8
  %2544 = load i64, i64* %RBP, align 8
  %2545 = add i64 %2544, -24
  %2546 = load i64, i64* %PC, align 8
  %2547 = add i64 %2546, 4
  store i64 %2547, i64* %PC, align 8
  %2548 = inttoptr i64 %2545 to i64*
  %2549 = load i64, i64* %2548, align 8
  store i64 %2549, i64* %RCX, align 8, !tbaa !2428
  %2550 = add i64 %2544, -32
  %2551 = add i64 %2546, 7
  store i64 %2551, i64* %PC, align 8
  %2552 = inttoptr i64 %2550 to i32*
  %2553 = load i32, i32* %2552, align 4
  %2554 = add i32 %2553, 1
  %2555 = zext i32 %2554 to i64
  store i64 %2555, i64* %RAX, align 8, !tbaa !2428
  %2556 = icmp eq i32 %2553, -1
  %2557 = icmp eq i32 %2554, 0
  %2558 = or i1 %2556, %2557
  %2559 = zext i1 %2558 to i8
  store i8 %2559, i8* %51, align 1, !tbaa !2433
  %2560 = and i32 %2554, 255
  %2561 = tail call i32 @llvm.ctpop.i32(i32 %2560) #10
  %2562 = trunc i32 %2561 to i8
  %2563 = and i8 %2562, 1
  %2564 = xor i8 %2563, 1
  store i8 %2564, i8* %52, align 1, !tbaa !2447
  %2565 = xor i32 %2553, %2554
  %2566 = lshr i32 %2565, 4
  %2567 = trunc i32 %2566 to i8
  %2568 = and i8 %2567, 1
  store i8 %2568, i8* %53, align 1, !tbaa !2451
  %2569 = icmp eq i32 %2554, 0
  %2570 = zext i1 %2569 to i8
  store i8 %2570, i8* %54, align 1, !tbaa !2448
  %2571 = lshr i32 %2554, 31
  %2572 = trunc i32 %2571 to i8
  store i8 %2572, i8* %55, align 1, !tbaa !2449
  %2573 = lshr i32 %2553, 31
  %2574 = xor i32 %2571, %2573
  %2575 = add nuw nsw i32 %2574, %2571
  %2576 = icmp eq i32 %2575, 2
  %2577 = zext i1 %2576 to i8
  store i8 %2577, i8* %56, align 1, !tbaa !2450
  %2578 = sext i32 %2554 to i64
  store i64 %2578, i64* %RDX, align 8, !tbaa !2428
  %2579 = shl nsw i64 %2578, 3
  %2580 = add i64 %2579, %2549
  %2581 = add i64 %2546, 18
  store i64 %2581, i64* %PC, align 8
  %2582 = inttoptr i64 %2580 to i64*
  %2583 = load i64, i64* %2582, align 8
  %2584 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2583, i64* %2584, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2585 = add i64 %2544, -72
  %2586 = add i64 %2546, 23
  store i64 %2586, i64* %PC, align 8
  %2587 = inttoptr i64 %2585 to i64*
  store i64 %2583, i64* %2587, align 8
  %2588 = load i64, i64* %RBP, align 8
  %2589 = add i64 %2588, -24
  %2590 = load i64, i64* %PC, align 8
  %2591 = add i64 %2590, 4
  store i64 %2591, i64* %PC, align 8
  %2592 = inttoptr i64 %2589 to i64*
  %2593 = load i64, i64* %2592, align 8
  store i64 %2593, i64* %RCX, align 8, !tbaa !2428
  %2594 = add i64 %2588, -40
  %2595 = add i64 %2590, 8
  store i64 %2595, i64* %PC, align 8
  %2596 = inttoptr i64 %2594 to i32*
  %2597 = load i32, i32* %2596, align 4
  %2598 = sext i32 %2597 to i64
  store i64 %2598, i64* %RDX, align 8, !tbaa !2428
  %2599 = shl nsw i64 %2598, 3
  %2600 = add i64 %2599, %2593
  %2601 = add i64 %2590, 13
  store i64 %2601, i64* %PC, align 8
  %2602 = inttoptr i64 %2600 to i64*
  %2603 = load i64, i64* %2602, align 8
  %2604 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2603, i64* %2604, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2605 = add i64 %2588, -80
  %2606 = add i64 %2590, 18
  store i64 %2606, i64* %PC, align 8
  %2607 = inttoptr i64 %2605 to i64*
  store i64 %2603, i64* %2607, align 8
  %2608 = load i64, i64* %RBP, align 8
  %2609 = add i64 %2608, -24
  %2610 = load i64, i64* %PC, align 8
  %2611 = add i64 %2610, 4
  store i64 %2611, i64* %PC, align 8
  %2612 = inttoptr i64 %2609 to i64*
  %2613 = load i64, i64* %2612, align 8
  store i64 %2613, i64* %RCX, align 8, !tbaa !2428
  %2614 = add i64 %2608, -40
  %2615 = add i64 %2610, 7
  store i64 %2615, i64* %PC, align 8
  %2616 = inttoptr i64 %2614 to i32*
  %2617 = load i32, i32* %2616, align 4
  %2618 = add i32 %2617, 1
  %2619 = zext i32 %2618 to i64
  store i64 %2619, i64* %RAX, align 8, !tbaa !2428
  %2620 = icmp eq i32 %2617, -1
  %2621 = icmp eq i32 %2618, 0
  %2622 = or i1 %2620, %2621
  %2623 = zext i1 %2622 to i8
  store i8 %2623, i8* %51, align 1, !tbaa !2433
  %2624 = and i32 %2618, 255
  %2625 = tail call i32 @llvm.ctpop.i32(i32 %2624) #10
  %2626 = trunc i32 %2625 to i8
  %2627 = and i8 %2626, 1
  %2628 = xor i8 %2627, 1
  store i8 %2628, i8* %52, align 1, !tbaa !2447
  %2629 = xor i32 %2617, %2618
  %2630 = lshr i32 %2629, 4
  %2631 = trunc i32 %2630 to i8
  %2632 = and i8 %2631, 1
  store i8 %2632, i8* %53, align 1, !tbaa !2451
  %2633 = icmp eq i32 %2618, 0
  %2634 = zext i1 %2633 to i8
  store i8 %2634, i8* %54, align 1, !tbaa !2448
  %2635 = lshr i32 %2618, 31
  %2636 = trunc i32 %2635 to i8
  store i8 %2636, i8* %55, align 1, !tbaa !2449
  %2637 = lshr i32 %2617, 31
  %2638 = xor i32 %2635, %2637
  %2639 = add nuw nsw i32 %2638, %2635
  %2640 = icmp eq i32 %2639, 2
  %2641 = zext i1 %2640 to i8
  store i8 %2641, i8* %56, align 1, !tbaa !2450
  %2642 = sext i32 %2618 to i64
  store i64 %2642, i64* %RDX, align 8, !tbaa !2428
  %2643 = shl nsw i64 %2642, 3
  %2644 = add i64 %2643, %2613
  %2645 = add i64 %2610, 18
  store i64 %2645, i64* %PC, align 8
  %2646 = inttoptr i64 %2644 to i64*
  %2647 = load i64, i64* %2646, align 8
  %2648 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2647, i64* %2648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2649 = add i64 %2608, -88
  %2650 = add i64 %2610, 23
  store i64 %2650, i64* %PC, align 8
  %2651 = inttoptr i64 %2649 to i64*
  store i64 %2647, i64* %2651, align 8
  %2652 = load i64, i64* %RBP, align 8
  %2653 = add i64 %2652, -80
  %2654 = load i64, i64* %PC, align 8
  %2655 = add i64 %2654, 5
  store i64 %2655, i64* %PC, align 8
  %2656 = inttoptr i64 %2653 to i64*
  %2657 = load i64, i64* %2656, align 8
  %2658 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2657, i64* %2658, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2659 = add i64 %2652, -24
  %2660 = add i64 %2654, 9
  store i64 %2660, i64* %PC, align 8
  %2661 = inttoptr i64 %2659 to i64*
  %2662 = load i64, i64* %2661, align 8
  store i64 %2662, i64* %RCX, align 8, !tbaa !2428
  %2663 = add i64 %2652, -32
  %2664 = add i64 %2654, 13
  store i64 %2664, i64* %PC, align 8
  %2665 = inttoptr i64 %2663 to i32*
  %2666 = load i32, i32* %2665, align 4
  %2667 = sext i32 %2666 to i64
  store i64 %2667, i64* %RDX, align 8, !tbaa !2428
  %2668 = shl nsw i64 %2667, 3
  %2669 = add i64 %2668, %2662
  %2670 = add i64 %2654, 18
  store i64 %2670, i64* %PC, align 8
  %2671 = inttoptr i64 %2669 to i64*
  store i64 %2657, i64* %2671, align 8
  %2672 = load i64, i64* %RBP, align 8
  %2673 = add i64 %2672, -88
  %2674 = load i64, i64* %PC, align 8
  %2675 = add i64 %2674, 5
  store i64 %2675, i64* %PC, align 8
  %2676 = inttoptr i64 %2673 to i64*
  %2677 = load i64, i64* %2676, align 8
  %2678 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2677, i64* %2678, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2679 = add i64 %2672, -24
  %2680 = add i64 %2674, 9
  store i64 %2680, i64* %PC, align 8
  %2681 = inttoptr i64 %2679 to i64*
  %2682 = load i64, i64* %2681, align 8
  store i64 %2682, i64* %RCX, align 8, !tbaa !2428
  %2683 = add i64 %2672, -32
  %2684 = add i64 %2674, 12
  store i64 %2684, i64* %PC, align 8
  %2685 = inttoptr i64 %2683 to i32*
  %2686 = load i32, i32* %2685, align 4
  %2687 = add i32 %2686, 1
  %2688 = zext i32 %2687 to i64
  store i64 %2688, i64* %RAX, align 8, !tbaa !2428
  %2689 = icmp eq i32 %2686, -1
  %2690 = icmp eq i32 %2687, 0
  %2691 = or i1 %2689, %2690
  %2692 = zext i1 %2691 to i8
  store i8 %2692, i8* %51, align 1, !tbaa !2433
  %2693 = and i32 %2687, 255
  %2694 = tail call i32 @llvm.ctpop.i32(i32 %2693) #10
  %2695 = trunc i32 %2694 to i8
  %2696 = and i8 %2695, 1
  %2697 = xor i8 %2696, 1
  store i8 %2697, i8* %52, align 1, !tbaa !2447
  %2698 = xor i32 %2686, %2687
  %2699 = lshr i32 %2698, 4
  %2700 = trunc i32 %2699 to i8
  %2701 = and i8 %2700, 1
  store i8 %2701, i8* %53, align 1, !tbaa !2451
  %2702 = icmp eq i32 %2687, 0
  %2703 = zext i1 %2702 to i8
  store i8 %2703, i8* %54, align 1, !tbaa !2448
  %2704 = lshr i32 %2687, 31
  %2705 = trunc i32 %2704 to i8
  store i8 %2705, i8* %55, align 1, !tbaa !2449
  %2706 = lshr i32 %2686, 31
  %2707 = xor i32 %2704, %2706
  %2708 = add nuw nsw i32 %2707, %2704
  %2709 = icmp eq i32 %2708, 2
  %2710 = zext i1 %2709 to i8
  store i8 %2710, i8* %56, align 1, !tbaa !2450
  %2711 = sext i32 %2687 to i64
  store i64 %2711, i64* %RDX, align 8, !tbaa !2428
  %2712 = shl nsw i64 %2711, 3
  %2713 = add i64 %2712, %2682
  %2714 = add i64 %2674, 23
  store i64 %2714, i64* %PC, align 8
  %2715 = inttoptr i64 %2713 to i64*
  store i64 %2677, i64* %2715, align 8
  %2716 = load i64, i64* %RBP, align 8
  %2717 = add i64 %2716, -64
  %2718 = load i64, i64* %PC, align 8
  %2719 = add i64 %2718, 5
  store i64 %2719, i64* %PC, align 8
  %2720 = inttoptr i64 %2717 to i64*
  %2721 = load i64, i64* %2720, align 8
  %2722 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2721, i64* %2722, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2723 = add i64 %2716, -24
  %2724 = add i64 %2718, 9
  store i64 %2724, i64* %PC, align 8
  %2725 = inttoptr i64 %2723 to i64*
  %2726 = load i64, i64* %2725, align 8
  store i64 %2726, i64* %RCX, align 8, !tbaa !2428
  %2727 = add i64 %2716, -40
  %2728 = add i64 %2718, 13
  store i64 %2728, i64* %PC, align 8
  %2729 = inttoptr i64 %2727 to i32*
  %2730 = load i32, i32* %2729, align 4
  %2731 = sext i32 %2730 to i64
  store i64 %2731, i64* %RDX, align 8, !tbaa !2428
  %2732 = shl nsw i64 %2731, 3
  %2733 = add i64 %2732, %2726
  %2734 = add i64 %2718, 18
  store i64 %2734, i64* %PC, align 8
  %2735 = inttoptr i64 %2733 to i64*
  store i64 %2721, i64* %2735, align 8
  %2736 = load i64, i64* %RBP, align 8
  %2737 = add i64 %2736, -72
  %2738 = load i64, i64* %PC, align 8
  %2739 = add i64 %2738, 5
  store i64 %2739, i64* %PC, align 8
  %2740 = inttoptr i64 %2737 to i64*
  %2741 = load i64, i64* %2740, align 8
  %2742 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2741, i64* %2742, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2743 = add i64 %2736, -24
  %2744 = add i64 %2738, 9
  store i64 %2744, i64* %PC, align 8
  %2745 = inttoptr i64 %2743 to i64*
  %2746 = load i64, i64* %2745, align 8
  store i64 %2746, i64* %RCX, align 8, !tbaa !2428
  %2747 = add i64 %2736, -40
  %2748 = add i64 %2738, 12
  store i64 %2748, i64* %PC, align 8
  %2749 = inttoptr i64 %2747 to i32*
  %2750 = load i32, i32* %2749, align 4
  %2751 = add i32 %2750, 1
  %2752 = zext i32 %2751 to i64
  store i64 %2752, i64* %RAX, align 8, !tbaa !2428
  %2753 = icmp eq i32 %2750, -1
  %2754 = icmp eq i32 %2751, 0
  %2755 = or i1 %2753, %2754
  %2756 = zext i1 %2755 to i8
  store i8 %2756, i8* %51, align 1, !tbaa !2433
  %2757 = and i32 %2751, 255
  %2758 = tail call i32 @llvm.ctpop.i32(i32 %2757) #10
  %2759 = trunc i32 %2758 to i8
  %2760 = and i8 %2759, 1
  %2761 = xor i8 %2760, 1
  store i8 %2761, i8* %52, align 1, !tbaa !2447
  %2762 = xor i32 %2750, %2751
  %2763 = lshr i32 %2762, 4
  %2764 = trunc i32 %2763 to i8
  %2765 = and i8 %2764, 1
  store i8 %2765, i8* %53, align 1, !tbaa !2451
  %2766 = icmp eq i32 %2751, 0
  %2767 = zext i1 %2766 to i8
  store i8 %2767, i8* %54, align 1, !tbaa !2448
  %2768 = lshr i32 %2751, 31
  %2769 = trunc i32 %2768 to i8
  store i8 %2769, i8* %55, align 1, !tbaa !2449
  %2770 = lshr i32 %2750, 31
  %2771 = xor i32 %2768, %2770
  %2772 = add nuw nsw i32 %2771, %2768
  %2773 = icmp eq i32 %2772, 2
  %2774 = zext i1 %2773 to i8
  store i8 %2774, i8* %56, align 1, !tbaa !2450
  %2775 = sext i32 %2751 to i64
  store i64 %2775, i64* %RDX, align 8, !tbaa !2428
  %2776 = shl nsw i64 %2775, 3
  %2777 = add i64 %2776, %2746
  %2778 = add i64 %2738, 23
  store i64 %2778, i64* %PC, align 8
  %2779 = inttoptr i64 %2777 to i64*
  store i64 %2741, i64* %2779, align 8
  %2780 = load i64, i64* %RBP, align 8
  %2781 = add i64 %2780, -52
  %2782 = load i64, i64* %PC, align 8
  %2783 = add i64 %2782, 3
  store i64 %2783, i64* %PC, align 8
  %2784 = inttoptr i64 %2781 to i32*
  %2785 = load i32, i32* %2784, align 4
  %2786 = zext i32 %2785 to i64
  store i64 %2786, i64* %RAX, align 8, !tbaa !2428
  %2787 = add i64 %2780, -32
  %2788 = add i64 %2782, 6
  store i64 %2788, i64* %PC, align 8
  %2789 = inttoptr i64 %2787 to i32*
  %2790 = load i32, i32* %2789, align 4
  %2791 = add i32 %2790, %2785
  %2792 = zext i32 %2791 to i64
  store i64 %2792, i64* %RAX, align 8, !tbaa !2428
  %2793 = icmp ult i32 %2791, %2785
  %2794 = icmp ult i32 %2791, %2790
  %2795 = or i1 %2793, %2794
  %2796 = zext i1 %2795 to i8
  store i8 %2796, i8* %51, align 1, !tbaa !2433
  %2797 = and i32 %2791, 255
  %2798 = tail call i32 @llvm.ctpop.i32(i32 %2797) #10
  %2799 = trunc i32 %2798 to i8
  %2800 = and i8 %2799, 1
  %2801 = xor i8 %2800, 1
  store i8 %2801, i8* %52, align 1, !tbaa !2447
  %2802 = xor i32 %2790, %2785
  %2803 = xor i32 %2802, %2791
  %2804 = lshr i32 %2803, 4
  %2805 = trunc i32 %2804 to i8
  %2806 = and i8 %2805, 1
  store i8 %2806, i8* %53, align 1, !tbaa !2451
  %2807 = icmp eq i32 %2791, 0
  %2808 = zext i1 %2807 to i8
  store i8 %2808, i8* %54, align 1, !tbaa !2448
  %2809 = lshr i32 %2791, 31
  %2810 = trunc i32 %2809 to i8
  store i8 %2810, i8* %55, align 1, !tbaa !2449
  %2811 = lshr i32 %2785, 31
  %2812 = lshr i32 %2790, 31
  %2813 = xor i32 %2809, %2811
  %2814 = xor i32 %2809, %2812
  %2815 = add nuw nsw i32 %2813, %2814
  %2816 = icmp eq i32 %2815, 2
  %2817 = zext i1 %2816 to i8
  store i8 %2817, i8* %56, align 1, !tbaa !2450
  %2818 = add i64 %2782, 9
  store i64 %2818, i64* %PC, align 8
  store i32 %2791, i32* %2789, align 4
  %2819 = load i64, i64* %RBP, align 8
  %2820 = add i64 %2819, -52
  %2821 = load i64, i64* %PC, align 8
  %2822 = add i64 %2821, 3
  store i64 %2822, i64* %PC, align 8
  %2823 = inttoptr i64 %2820 to i32*
  %2824 = load i32, i32* %2823, align 4
  %2825 = shl i32 %2824, 1
  %2826 = icmp slt i32 %2824, 0
  %2827 = icmp slt i32 %2825, 0
  %2828 = xor i1 %2826, %2827
  %2829 = zext i32 %2825 to i64
  store i64 %2829, i64* %RAX, align 8, !tbaa !2428
  %.lobit18 = lshr i32 %2824, 31
  %2830 = trunc i32 %.lobit18 to i8
  store i8 %2830, i8* %51, align 1, !tbaa !2432
  %2831 = and i32 %2825, 254
  %2832 = tail call i32 @llvm.ctpop.i32(i32 %2831) #10
  %2833 = trunc i32 %2832 to i8
  %2834 = and i8 %2833, 1
  %2835 = xor i8 %2834, 1
  store i8 %2835, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %2836 = icmp eq i32 %2825, 0
  %2837 = zext i1 %2836 to i8
  store i8 %2837, i8* %54, align 1, !tbaa !2432
  %2838 = lshr i32 %2824, 30
  %2839 = and i32 %2838, 1
  %2840 = trunc i32 %2839 to i8
  store i8 %2840, i8* %55, align 1, !tbaa !2432
  %2841 = zext i1 %2828 to i8
  store i8 %2841, i8* %56, align 1, !tbaa !2432
  %2842 = add i64 %2819, -40
  %2843 = add i64 %2821, 9
  store i64 %2843, i64* %PC, align 8
  %2844 = inttoptr i64 %2842 to i32*
  %2845 = load i32, i32* %2844, align 4
  %2846 = add i32 %2845, %2825
  %2847 = zext i32 %2846 to i64
  store i64 %2847, i64* %RAX, align 8, !tbaa !2428
  %2848 = icmp ult i32 %2846, %2825
  %2849 = icmp ult i32 %2846, %2845
  %2850 = or i1 %2848, %2849
  %2851 = zext i1 %2850 to i8
  store i8 %2851, i8* %51, align 1, !tbaa !2433
  %2852 = and i32 %2846, 255
  %2853 = tail call i32 @llvm.ctpop.i32(i32 %2852) #10
  %2854 = trunc i32 %2853 to i8
  %2855 = and i8 %2854, 1
  %2856 = xor i8 %2855, 1
  store i8 %2856, i8* %52, align 1, !tbaa !2447
  %2857 = xor i32 %2845, %2825
  %2858 = xor i32 %2857, %2846
  %2859 = lshr i32 %2858, 4
  %2860 = trunc i32 %2859 to i8
  %2861 = and i8 %2860, 1
  store i8 %2861, i8* %53, align 1, !tbaa !2451
  %2862 = icmp eq i32 %2846, 0
  %2863 = zext i1 %2862 to i8
  store i8 %2863, i8* %54, align 1, !tbaa !2448
  %2864 = lshr i32 %2846, 31
  %2865 = trunc i32 %2864 to i8
  store i8 %2865, i8* %55, align 1, !tbaa !2449
  %2866 = lshr i32 %2845, 31
  %2867 = xor i32 %2864, %2839
  %2868 = xor i32 %2864, %2866
  %2869 = add nuw nsw i32 %2867, %2868
  %2870 = icmp eq i32 %2869, 2
  %2871 = zext i1 %2870 to i8
  store i8 %2871, i8* %56, align 1, !tbaa !2450
  %2872 = add i64 %2821, 12
  store i64 %2872, i64* %PC, align 8
  store i32 %2846, i32* %2844, align 4
  %2873 = load i64, i64* %RBP, align 8
  %2874 = add i64 %2873, -24
  %2875 = load i64, i64* %PC, align 8
  %2876 = add i64 %2875, 4
  store i64 %2876, i64* %PC, align 8
  %2877 = inttoptr i64 %2874 to i64*
  %2878 = load i64, i64* %2877, align 8
  store i64 %2878, i64* %RCX, align 8, !tbaa !2428
  %2879 = add i64 %2873, -32
  %2880 = add i64 %2875, 8
  store i64 %2880, i64* %PC, align 8
  %2881 = inttoptr i64 %2879 to i32*
  %2882 = load i32, i32* %2881, align 4
  %2883 = sext i32 %2882 to i64
  store i64 %2883, i64* %RDX, align 8, !tbaa !2428
  %2884 = shl nsw i64 %2883, 3
  %2885 = add i64 %2884, %2878
  %2886 = add i64 %2875, 13
  store i64 %2886, i64* %PC, align 8
  %2887 = inttoptr i64 %2885 to i64*
  %2888 = load i64, i64* %2887, align 8
  %2889 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2888, i64* %2889, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2890 = add i64 %2873, -64
  %2891 = add i64 %2875, 18
  store i64 %2891, i64* %PC, align 8
  %2892 = inttoptr i64 %2890 to i64*
  store i64 %2888, i64* %2892, align 8
  %2893 = load i64, i64* %RBP, align 8
  %2894 = add i64 %2893, -24
  %2895 = load i64, i64* %PC, align 8
  %2896 = add i64 %2895, 4
  store i64 %2896, i64* %PC, align 8
  %2897 = inttoptr i64 %2894 to i64*
  %2898 = load i64, i64* %2897, align 8
  store i64 %2898, i64* %RCX, align 8, !tbaa !2428
  %2899 = add i64 %2893, -32
  %2900 = add i64 %2895, 7
  store i64 %2900, i64* %PC, align 8
  %2901 = inttoptr i64 %2899 to i32*
  %2902 = load i32, i32* %2901, align 4
  %2903 = add i32 %2902, 1
  %2904 = zext i32 %2903 to i64
  store i64 %2904, i64* %RAX, align 8, !tbaa !2428
  %2905 = icmp eq i32 %2902, -1
  %2906 = icmp eq i32 %2903, 0
  %2907 = or i1 %2905, %2906
  %2908 = zext i1 %2907 to i8
  store i8 %2908, i8* %51, align 1, !tbaa !2433
  %2909 = and i32 %2903, 255
  %2910 = tail call i32 @llvm.ctpop.i32(i32 %2909) #10
  %2911 = trunc i32 %2910 to i8
  %2912 = and i8 %2911, 1
  %2913 = xor i8 %2912, 1
  store i8 %2913, i8* %52, align 1, !tbaa !2447
  %2914 = xor i32 %2902, %2903
  %2915 = lshr i32 %2914, 4
  %2916 = trunc i32 %2915 to i8
  %2917 = and i8 %2916, 1
  store i8 %2917, i8* %53, align 1, !tbaa !2451
  %2918 = icmp eq i32 %2903, 0
  %2919 = zext i1 %2918 to i8
  store i8 %2919, i8* %54, align 1, !tbaa !2448
  %2920 = lshr i32 %2903, 31
  %2921 = trunc i32 %2920 to i8
  store i8 %2921, i8* %55, align 1, !tbaa !2449
  %2922 = lshr i32 %2902, 31
  %2923 = xor i32 %2920, %2922
  %2924 = add nuw nsw i32 %2923, %2920
  %2925 = icmp eq i32 %2924, 2
  %2926 = zext i1 %2925 to i8
  store i8 %2926, i8* %56, align 1, !tbaa !2450
  %2927 = sext i32 %2903 to i64
  store i64 %2927, i64* %RDX, align 8, !tbaa !2428
  %2928 = shl nsw i64 %2927, 3
  %2929 = add i64 %2928, %2898
  %2930 = add i64 %2895, 18
  store i64 %2930, i64* %PC, align 8
  %2931 = inttoptr i64 %2929 to i64*
  %2932 = load i64, i64* %2931, align 8
  %2933 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2932, i64* %2933, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2934 = add i64 %2893, -72
  %2935 = add i64 %2895, 23
  store i64 %2935, i64* %PC, align 8
  %2936 = inttoptr i64 %2934 to i64*
  store i64 %2932, i64* %2936, align 8
  %2937 = load i64, i64* %RBP, align 8
  %2938 = add i64 %2937, -24
  %2939 = load i64, i64* %PC, align 8
  %2940 = add i64 %2939, 4
  store i64 %2940, i64* %PC, align 8
  %2941 = inttoptr i64 %2938 to i64*
  %2942 = load i64, i64* %2941, align 8
  store i64 %2942, i64* %RCX, align 8, !tbaa !2428
  %2943 = add i64 %2937, -40
  %2944 = add i64 %2939, 8
  store i64 %2944, i64* %PC, align 8
  %2945 = inttoptr i64 %2943 to i32*
  %2946 = load i32, i32* %2945, align 4
  %2947 = sext i32 %2946 to i64
  store i64 %2947, i64* %RDX, align 8, !tbaa !2428
  %2948 = shl nsw i64 %2947, 3
  %2949 = add i64 %2948, %2942
  %2950 = add i64 %2939, 13
  store i64 %2950, i64* %PC, align 8
  %2951 = inttoptr i64 %2949 to i64*
  %2952 = load i64, i64* %2951, align 8
  %2953 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2952, i64* %2953, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2954 = add i64 %2937, -80
  %2955 = add i64 %2939, 18
  store i64 %2955, i64* %PC, align 8
  %2956 = inttoptr i64 %2954 to i64*
  store i64 %2952, i64* %2956, align 8
  %2957 = load i64, i64* %RBP, align 8
  %2958 = add i64 %2957, -24
  %2959 = load i64, i64* %PC, align 8
  %2960 = add i64 %2959, 4
  store i64 %2960, i64* %PC, align 8
  %2961 = inttoptr i64 %2958 to i64*
  %2962 = load i64, i64* %2961, align 8
  store i64 %2962, i64* %RCX, align 8, !tbaa !2428
  %2963 = add i64 %2957, -40
  %2964 = add i64 %2959, 7
  store i64 %2964, i64* %PC, align 8
  %2965 = inttoptr i64 %2963 to i32*
  %2966 = load i32, i32* %2965, align 4
  %2967 = add i32 %2966, 1
  %2968 = zext i32 %2967 to i64
  store i64 %2968, i64* %RAX, align 8, !tbaa !2428
  %2969 = icmp eq i32 %2966, -1
  %2970 = icmp eq i32 %2967, 0
  %2971 = or i1 %2969, %2970
  %2972 = zext i1 %2971 to i8
  store i8 %2972, i8* %51, align 1, !tbaa !2433
  %2973 = and i32 %2967, 255
  %2974 = tail call i32 @llvm.ctpop.i32(i32 %2973) #10
  %2975 = trunc i32 %2974 to i8
  %2976 = and i8 %2975, 1
  %2977 = xor i8 %2976, 1
  store i8 %2977, i8* %52, align 1, !tbaa !2447
  %2978 = xor i32 %2966, %2967
  %2979 = lshr i32 %2978, 4
  %2980 = trunc i32 %2979 to i8
  %2981 = and i8 %2980, 1
  store i8 %2981, i8* %53, align 1, !tbaa !2451
  %2982 = icmp eq i32 %2967, 0
  %2983 = zext i1 %2982 to i8
  store i8 %2983, i8* %54, align 1, !tbaa !2448
  %2984 = lshr i32 %2967, 31
  %2985 = trunc i32 %2984 to i8
  store i8 %2985, i8* %55, align 1, !tbaa !2449
  %2986 = lshr i32 %2966, 31
  %2987 = xor i32 %2984, %2986
  %2988 = add nuw nsw i32 %2987, %2984
  %2989 = icmp eq i32 %2988, 2
  %2990 = zext i1 %2989 to i8
  store i8 %2990, i8* %56, align 1, !tbaa !2450
  %2991 = sext i32 %2967 to i64
  store i64 %2991, i64* %RDX, align 8, !tbaa !2428
  %2992 = shl nsw i64 %2991, 3
  %2993 = add i64 %2992, %2962
  %2994 = add i64 %2959, 18
  store i64 %2994, i64* %PC, align 8
  %2995 = inttoptr i64 %2993 to i64*
  %2996 = load i64, i64* %2995, align 8
  %2997 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2996, i64* %2997, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %2998 = add i64 %2957, -88
  %2999 = add i64 %2959, 23
  store i64 %2999, i64* %PC, align 8
  %3000 = inttoptr i64 %2998 to i64*
  store i64 %2996, i64* %3000, align 8
  %3001 = load i64, i64* %RBP, align 8
  %3002 = add i64 %3001, -80
  %3003 = load i64, i64* %PC, align 8
  %3004 = add i64 %3003, 5
  store i64 %3004, i64* %PC, align 8
  %3005 = inttoptr i64 %3002 to i64*
  %3006 = load i64, i64* %3005, align 8
  %3007 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3006, i64* %3007, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %3008 = add i64 %3001, -24
  %3009 = add i64 %3003, 9
  store i64 %3009, i64* %PC, align 8
  %3010 = inttoptr i64 %3008 to i64*
  %3011 = load i64, i64* %3010, align 8
  store i64 %3011, i64* %RCX, align 8, !tbaa !2428
  %3012 = add i64 %3001, -32
  %3013 = add i64 %3003, 13
  store i64 %3013, i64* %PC, align 8
  %3014 = inttoptr i64 %3012 to i32*
  %3015 = load i32, i32* %3014, align 4
  %3016 = sext i32 %3015 to i64
  store i64 %3016, i64* %RDX, align 8, !tbaa !2428
  %3017 = shl nsw i64 %3016, 3
  %3018 = add i64 %3017, %3011
  %3019 = add i64 %3003, 18
  store i64 %3019, i64* %PC, align 8
  %3020 = inttoptr i64 %3018 to i64*
  store i64 %3006, i64* %3020, align 8
  %3021 = load i64, i64* %RBP, align 8
  %3022 = add i64 %3021, -88
  %3023 = load i64, i64* %PC, align 8
  %3024 = add i64 %3023, 5
  store i64 %3024, i64* %PC, align 8
  %3025 = inttoptr i64 %3022 to i64*
  %3026 = load i64, i64* %3025, align 8
  %3027 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3026, i64* %3027, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %3028 = add i64 %3021, -24
  %3029 = add i64 %3023, 9
  store i64 %3029, i64* %PC, align 8
  %3030 = inttoptr i64 %3028 to i64*
  %3031 = load i64, i64* %3030, align 8
  store i64 %3031, i64* %RCX, align 8, !tbaa !2428
  %3032 = add i64 %3021, -32
  %3033 = add i64 %3023, 12
  store i64 %3033, i64* %PC, align 8
  %3034 = inttoptr i64 %3032 to i32*
  %3035 = load i32, i32* %3034, align 4
  %3036 = add i32 %3035, 1
  %3037 = zext i32 %3036 to i64
  store i64 %3037, i64* %RAX, align 8, !tbaa !2428
  %3038 = icmp eq i32 %3035, -1
  %3039 = icmp eq i32 %3036, 0
  %3040 = or i1 %3038, %3039
  %3041 = zext i1 %3040 to i8
  store i8 %3041, i8* %51, align 1, !tbaa !2433
  %3042 = and i32 %3036, 255
  %3043 = tail call i32 @llvm.ctpop.i32(i32 %3042) #10
  %3044 = trunc i32 %3043 to i8
  %3045 = and i8 %3044, 1
  %3046 = xor i8 %3045, 1
  store i8 %3046, i8* %52, align 1, !tbaa !2447
  %3047 = xor i32 %3035, %3036
  %3048 = lshr i32 %3047, 4
  %3049 = trunc i32 %3048 to i8
  %3050 = and i8 %3049, 1
  store i8 %3050, i8* %53, align 1, !tbaa !2451
  %3051 = icmp eq i32 %3036, 0
  %3052 = zext i1 %3051 to i8
  store i8 %3052, i8* %54, align 1, !tbaa !2448
  %3053 = lshr i32 %3036, 31
  %3054 = trunc i32 %3053 to i8
  store i8 %3054, i8* %55, align 1, !tbaa !2449
  %3055 = lshr i32 %3035, 31
  %3056 = xor i32 %3053, %3055
  %3057 = add nuw nsw i32 %3056, %3053
  %3058 = icmp eq i32 %3057, 2
  %3059 = zext i1 %3058 to i8
  store i8 %3059, i8* %56, align 1, !tbaa !2450
  %3060 = sext i32 %3036 to i64
  store i64 %3060, i64* %RDX, align 8, !tbaa !2428
  %3061 = shl nsw i64 %3060, 3
  %3062 = add i64 %3061, %3031
  %3063 = add i64 %3023, 23
  store i64 %3063, i64* %PC, align 8
  %3064 = inttoptr i64 %3062 to i64*
  store i64 %3026, i64* %3064, align 8
  %3065 = load i64, i64* %RBP, align 8
  %3066 = add i64 %3065, -64
  %3067 = load i64, i64* %PC, align 8
  %3068 = add i64 %3067, 5
  store i64 %3068, i64* %PC, align 8
  %3069 = inttoptr i64 %3066 to i64*
  %3070 = load i64, i64* %3069, align 8
  %3071 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3070, i64* %3071, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %3072 = add i64 %3065, -24
  %3073 = add i64 %3067, 9
  store i64 %3073, i64* %PC, align 8
  %3074 = inttoptr i64 %3072 to i64*
  %3075 = load i64, i64* %3074, align 8
  store i64 %3075, i64* %RCX, align 8, !tbaa !2428
  %3076 = add i64 %3065, -40
  %3077 = add i64 %3067, 13
  store i64 %3077, i64* %PC, align 8
  %3078 = inttoptr i64 %3076 to i32*
  %3079 = load i32, i32* %3078, align 4
  %3080 = sext i32 %3079 to i64
  store i64 %3080, i64* %RDX, align 8, !tbaa !2428
  %3081 = shl nsw i64 %3080, 3
  %3082 = add i64 %3081, %3075
  %3083 = add i64 %3067, 18
  store i64 %3083, i64* %PC, align 8
  %3084 = inttoptr i64 %3082 to i64*
  store i64 %3070, i64* %3084, align 8
  %3085 = load i64, i64* %RBP, align 8
  %3086 = add i64 %3085, -72
  %3087 = load i64, i64* %PC, align 8
  %3088 = add i64 %3087, 5
  store i64 %3088, i64* %PC, align 8
  %3089 = inttoptr i64 %3086 to i64*
  %3090 = load i64, i64* %3089, align 8
  %3091 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3090, i64* %3091, align 1, !tbaa !2452
  store double 0.000000e+00, double* %240, align 1, !tbaa !2452
  %3092 = add i64 %3085, -24
  %3093 = add i64 %3087, 9
  store i64 %3093, i64* %PC, align 8
  %3094 = inttoptr i64 %3092 to i64*
  %3095 = load i64, i64* %3094, align 8
  store i64 %3095, i64* %RCX, align 8, !tbaa !2428
  %3096 = add i64 %3085, -40
  %3097 = add i64 %3087, 12
  store i64 %3097, i64* %PC, align 8
  %3098 = inttoptr i64 %3096 to i32*
  %3099 = load i32, i32* %3098, align 4
  %3100 = add i32 %3099, 1
  %3101 = zext i32 %3100 to i64
  store i64 %3101, i64* %RAX, align 8, !tbaa !2428
  %3102 = icmp eq i32 %3099, -1
  %3103 = icmp eq i32 %3100, 0
  %3104 = or i1 %3102, %3103
  %3105 = zext i1 %3104 to i8
  store i8 %3105, i8* %51, align 1, !tbaa !2433
  %3106 = and i32 %3100, 255
  %3107 = tail call i32 @llvm.ctpop.i32(i32 %3106) #10
  %3108 = trunc i32 %3107 to i8
  %3109 = and i8 %3108, 1
  %3110 = xor i8 %3109, 1
  store i8 %3110, i8* %52, align 1, !tbaa !2447
  %3111 = xor i32 %3099, %3100
  %3112 = lshr i32 %3111, 4
  %3113 = trunc i32 %3112 to i8
  %3114 = and i8 %3113, 1
  store i8 %3114, i8* %53, align 1, !tbaa !2451
  %3115 = icmp eq i32 %3100, 0
  %3116 = zext i1 %3115 to i8
  store i8 %3116, i8* %54, align 1, !tbaa !2448
  %3117 = lshr i32 %3100, 31
  %3118 = trunc i32 %3117 to i8
  store i8 %3118, i8* %55, align 1, !tbaa !2449
  %3119 = lshr i32 %3099, 31
  %3120 = xor i32 %3117, %3119
  %3121 = add nuw nsw i32 %3120, %3117
  %3122 = icmp eq i32 %3121, 2
  %3123 = zext i1 %3122 to i8
  store i8 %3123, i8* %56, align 1, !tbaa !2450
  %3124 = sext i32 %3100 to i64
  store i64 %3124, i64* %RDX, align 8, !tbaa !2428
  %3125 = shl nsw i64 %3124, 3
  %3126 = add i64 %3125, %3095
  %3127 = add i64 %3087, 23
  store i64 %3127, i64* %PC, align 8
  %3128 = inttoptr i64 %3126 to i64*
  store i64 %3090, i64* %3128, align 8
  %3129 = load i64, i64* %RBP, align 8
  %3130 = add i64 %3129, -28
  %3131 = load i64, i64* %PC, align 8
  %3132 = add i64 %3131, 3
  store i64 %3132, i64* %PC, align 8
  %3133 = inttoptr i64 %3130 to i32*
  %3134 = load i32, i32* %3133, align 4
  %3135 = add i32 %3134, 1
  %3136 = zext i32 %3135 to i64
  store i64 %3136, i64* %RAX, align 8, !tbaa !2428
  %3137 = icmp eq i32 %3134, -1
  %3138 = icmp eq i32 %3135, 0
  %3139 = or i1 %3137, %3138
  %3140 = zext i1 %3139 to i8
  store i8 %3140, i8* %51, align 1, !tbaa !2433
  %3141 = and i32 %3135, 255
  %3142 = tail call i32 @llvm.ctpop.i32(i32 %3141) #10
  %3143 = trunc i32 %3142 to i8
  %3144 = and i8 %3143, 1
  %3145 = xor i8 %3144, 1
  store i8 %3145, i8* %52, align 1, !tbaa !2447
  %3146 = xor i32 %3134, %3135
  %3147 = lshr i32 %3146, 4
  %3148 = trunc i32 %3147 to i8
  %3149 = and i8 %3148, 1
  store i8 %3149, i8* %53, align 1, !tbaa !2451
  %3150 = icmp eq i32 %3135, 0
  %3151 = zext i1 %3150 to i8
  store i8 %3151, i8* %54, align 1, !tbaa !2448
  %3152 = lshr i32 %3135, 31
  %3153 = trunc i32 %3152 to i8
  store i8 %3153, i8* %55, align 1, !tbaa !2449
  %3154 = lshr i32 %3134, 31
  %3155 = xor i32 %3152, %3154
  %3156 = add nuw nsw i32 %3155, %3152
  %3157 = icmp eq i32 %3156, 2
  %3158 = zext i1 %3157 to i8
  store i8 %3158, i8* %56, align 1, !tbaa !2450
  %3159 = add i64 %3131, 9
  store i64 %3159, i64* %PC, align 8
  store i32 %3135, i32* %3133, align 4
  %3160 = load i64, i64* %PC, align 8
  %3161 = add i64 %3160, -779
  store i64 %3161, i64* %57, align 8, !tbaa !2428
  br label %block_40127d

block_401205:                                     ; preds = %block_401211, %block_4011f5
  %3162 = phi i64 [ %545, %block_401211 ], [ %.pre3, %block_4011f5 ]
  %3163 = load i64, i64* %RBP, align 8
  %3164 = add i64 %3163, -28
  %3165 = add i64 %3162, 3
  store i64 %3165, i64* %PC, align 8
  %3166 = inttoptr i64 %3164 to i32*
  %3167 = load i32, i32* %3166, align 4
  %3168 = zext i32 %3167 to i64
  store i64 %3168, i64* %RAX, align 8, !tbaa !2428
  %3169 = add i64 %3163, -48
  %3170 = add i64 %3162, 6
  store i64 %3170, i64* %PC, align 8
  %3171 = inttoptr i64 %3169 to i32*
  %3172 = load i32, i32* %3171, align 4
  %3173 = sub i32 %3167, %3172
  %3174 = icmp ult i32 %3167, %3172
  %3175 = zext i1 %3174 to i8
  store i8 %3175, i8* %51, align 1, !tbaa !2433
  %3176 = and i32 %3173, 255
  %3177 = tail call i32 @llvm.ctpop.i32(i32 %3176) #10
  %3178 = trunc i32 %3177 to i8
  %3179 = and i8 %3178, 1
  %3180 = xor i8 %3179, 1
  store i8 %3180, i8* %52, align 1, !tbaa !2447
  %3181 = xor i32 %3172, %3167
  %3182 = xor i32 %3181, %3173
  %3183 = lshr i32 %3182, 4
  %3184 = trunc i32 %3183 to i8
  %3185 = and i8 %3184, 1
  store i8 %3185, i8* %53, align 1, !tbaa !2451
  %3186 = icmp eq i32 %3173, 0
  %3187 = zext i1 %3186 to i8
  store i8 %3187, i8* %54, align 1, !tbaa !2448
  %3188 = lshr i32 %3173, 31
  %3189 = trunc i32 %3188 to i8
  store i8 %3189, i8* %55, align 1, !tbaa !2449
  %3190 = lshr i32 %3167, 31
  %3191 = lshr i32 %3172, 31
  %3192 = xor i32 %3191, %3190
  %3193 = xor i32 %3188, %3190
  %3194 = add nuw nsw i32 %3193, %3192
  %3195 = icmp eq i32 %3194, 2
  %3196 = zext i1 %3195 to i8
  store i8 %3196, i8* %56, align 1, !tbaa !2450
  %3197 = icmp ne i8 %3189, 0
  %3198 = xor i1 %3197, %3195
  %.v9 = select i1 %3198, i64 12, i64 56
  %3199 = add i64 %3162, %.v9
  store i64 %3199, i64* %57, align 8, !tbaa !2428
  br i1 %3198, label %block_401211, label %block_40123d
}

; Function Attrs: noinline
define %struct.Memory* @sub_400e30_makewt(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400e30:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %7 = load i64, i64* %RBP, align 8
  %8 = add i64 %1, 1
  store i64 %8, i64* %PC, align 8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %10 = load i64, i64* %9, align 8, !tbaa !2428
  %11 = add i64 %10, -8
  %12 = inttoptr i64 %11 to i64*
  store i64 %7, i64* %12, align 8
  %13 = load i64, i64* %PC, align 8
  store i64 %11, i64* %RBP, align 8, !tbaa !2428
  %14 = add i64 %10, -72
  store i64 %14, i64* %RSP, align 8, !tbaa !2428
  %15 = icmp ult i64 %11, 64
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1, !tbaa !2433
  %18 = trunc i64 %14 to i32
  %19 = and i32 %18, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19) #10
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1, !tbaa !2447
  %25 = xor i64 %11, %14
  %26 = lshr i64 %25, 4
  %27 = trunc i64 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1, !tbaa !2451
  %30 = icmp eq i64 %14, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1, !tbaa !2448
  %33 = lshr i64 %14, 63
  %34 = trunc i64 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1, !tbaa !2449
  %36 = lshr i64 %11, 63
  %37 = xor i64 %33, %36
  %38 = add nuw nsw i64 %37, %36
  %39 = icmp eq i64 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1, !tbaa !2450
  %42 = add i64 %10, -12
  %43 = load i32, i32* %EDI, align 4
  %44 = add i64 %13, 10
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %42 to i32*
  store i32 %43, i32* %45, align 4
  %46 = load i64, i64* %RBP, align 8
  %47 = add i64 %46, -16
  %48 = load i64, i64* %RSI, align 8
  %49 = load i64, i64* %PC, align 8
  %50 = add i64 %49, 4
  store i64 %50, i64* %PC, align 8
  %51 = inttoptr i64 %47 to i64*
  store i64 %48, i64* %51, align 8
  %52 = load i64, i64* %RBP, align 8
  %53 = add i64 %52, -24
  %54 = load i64, i64* %RDX, align 8
  %55 = load i64, i64* %PC, align 8
  %56 = add i64 %55, 4
  store i64 %56, i64* %PC, align 8
  %57 = inttoptr i64 %53 to i64*
  store i64 %54, i64* %57, align 8
  %58 = load i64, i64* %RBP, align 8
  %59 = add i64 %58, -4
  %60 = load i64, i64* %PC, align 8
  %61 = add i64 %60, 4
  store i64 %61, i64* %PC, align 8
  %62 = inttoptr i64 %59 to i32*
  %63 = load i32, i32* %62, align 4
  %64 = add i32 %63, -2
  %65 = icmp ult i32 %63, 2
  %66 = zext i1 %65 to i8
  store i8 %66, i8* %17, align 1, !tbaa !2433
  %67 = and i32 %64, 255
  %68 = tail call i32 @llvm.ctpop.i32(i32 %67) #10
  %69 = trunc i32 %68 to i8
  %70 = and i8 %69, 1
  %71 = xor i8 %70, 1
  store i8 %71, i8* %24, align 1, !tbaa !2447
  %72 = xor i32 %63, %64
  %73 = lshr i32 %72, 4
  %74 = trunc i32 %73 to i8
  %75 = and i8 %74, 1
  store i8 %75, i8* %29, align 1, !tbaa !2451
  %76 = icmp eq i32 %64, 0
  %77 = zext i1 %76 to i8
  store i8 %77, i8* %32, align 1, !tbaa !2448
  %78 = lshr i32 %64, 31
  %79 = trunc i32 %78 to i8
  store i8 %79, i8* %35, align 1, !tbaa !2449
  %80 = lshr i32 %63, 31
  %81 = xor i32 %78, %80
  %82 = add nuw nsw i32 %81, %80
  %83 = icmp eq i32 %82, 2
  %84 = zext i1 %83 to i8
  store i8 %84, i8* %41, align 1, !tbaa !2450
  %85 = icmp ne i8 %79, 0
  %86 = xor i1 %85, %83
  %87 = or i1 %76, %86
  %88 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %.v = select i1 %87, i64 347, i64 10
  %89 = add i64 %60, %.v
  store i64 %89, i64* %88, align 8, !tbaa !2428
  br i1 %87, label %block_400f9e, label %block_400e4d

block_400f9e:                                     ; preds = %block_400f99, %block_400e30
  %90 = phi i64 [ %89, %block_400e30 ], [ %600, %block_400f99 ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_400e30 ], [ %MEMORY.1, %block_400f99 ]
  %91 = load i64, i64* %RSP, align 8
  %92 = add i64 %91, 64
  store i64 %92, i64* %RSP, align 8, !tbaa !2428
  %93 = icmp ugt i64 %91, -65
  %94 = zext i1 %93 to i8
  store i8 %94, i8* %17, align 1, !tbaa !2433
  %95 = trunc i64 %92 to i32
  %96 = and i32 %95, 255
  %97 = tail call i32 @llvm.ctpop.i32(i32 %96) #10
  %98 = trunc i32 %97 to i8
  %99 = and i8 %98, 1
  %100 = xor i8 %99, 1
  store i8 %100, i8* %24, align 1, !tbaa !2447
  %101 = xor i64 %91, %92
  %102 = lshr i64 %101, 4
  %103 = trunc i64 %102 to i8
  %104 = and i8 %103, 1
  store i8 %104, i8* %29, align 1, !tbaa !2451
  %105 = icmp eq i64 %92, 0
  %106 = zext i1 %105 to i8
  store i8 %106, i8* %32, align 1, !tbaa !2448
  %107 = lshr i64 %92, 63
  %108 = trunc i64 %107 to i8
  store i8 %108, i8* %35, align 1, !tbaa !2449
  %109 = lshr i64 %91, 63
  %110 = xor i64 %107, %109
  %111 = add nuw nsw i64 %110, %107
  %112 = icmp eq i64 %111, 2
  %113 = zext i1 %112 to i8
  store i8 %113, i8* %41, align 1, !tbaa !2450
  %114 = add i64 %90, 5
  store i64 %114, i64* %PC, align 8
  %115 = add i64 %91, 72
  %116 = inttoptr i64 %92 to i64*
  %117 = load i64, i64* %116, align 8
  store i64 %117, i64* %RBP, align 8, !tbaa !2428
  store i64 %115, i64* %9, align 8, !tbaa !2428
  %118 = add i64 %90, 6
  store i64 %118, i64* %PC, align 8
  %119 = inttoptr i64 %115 to i64*
  %120 = load i64, i64* %119, align 8
  store i64 %120, i64* %88, align 8, !tbaa !2428
  %121 = add i64 %91, 80
  store i64 %121, i64* %9, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_400eda:                                     ; preds = %block_400e4d
  %122 = add i64 %302, -28
  %123 = add i64 %332, 7
  store i64 %123, i64* %PC, align 8
  %124 = inttoptr i64 %122 to i32*
  store i32 2, i32* %124, align 4
  %.pre = load i64, i64* %PC, align 8
  br label %block_400ee1

block_400e4d:                                     ; preds = %block_400e30
  %125 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3
  %126 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 64) to i64*), align 16
  %127 = bitcast [32 x %union.VectorReg]* %4 to double*
  %128 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %126, i64* %128, align 1, !tbaa !2452
  %129 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %130 = bitcast i64* %129 to double*
  store double 0.000000e+00, double* %130, align 1, !tbaa !2452
  %131 = add i64 %89, 11
  store i64 %131, i64* %PC, align 8
  %132 = load i32, i32* %62, align 4
  %133 = zext i32 %132 to i64
  %134 = shl nuw i64 %133, 32
  %135 = ashr i64 %134, 33
  %136 = trunc i32 %132 to i8
  %137 = and i8 %136, 1
  %138 = trunc i64 %135 to i32
  %139 = and i64 %135, 4294967295
  store i64 %139, i64* %RAX, align 8, !tbaa !2428
  store i8 %137, i8* %17, align 1, !tbaa !2432
  %140 = and i32 %138, 255
  %141 = tail call i32 @llvm.ctpop.i32(i32 %140) #10
  %142 = trunc i32 %141 to i8
  %143 = and i8 %142, 1
  %144 = xor i8 %143, 1
  store i8 %144, i8* %24, align 1, !tbaa !2432
  store i8 0, i8* %29, align 1, !tbaa !2432
  %145 = icmp eq i32 %138, 0
  %146 = zext i1 %145 to i8
  store i8 %146, i8* %32, align 1, !tbaa !2432
  %147 = lshr i64 %135, 31
  %148 = trunc i64 %147 to i8
  %149 = and i8 %148, 1
  store i8 %149, i8* %35, align 1, !tbaa !2432
  store i8 0, i8* %41, align 1, !tbaa !2432
  %150 = add i64 %58, -32
  %151 = trunc i64 %135 to i32
  %152 = add i64 %89, 17
  store i64 %152, i64* %PC, align 8
  %153 = inttoptr i64 %150 to i32*
  store i32 %151, i32* %153, align 4
  %154 = load i64, i64* %PC, align 8
  %155 = add i64 %154, -2014
  %156 = add i64 %154, 5
  %157 = load i64, i64* %9, align 8, !tbaa !2428
  %158 = add i64 %157, -8
  %159 = inttoptr i64 %158 to i64*
  store i64 %156, i64* %159, align 8
  store i64 %158, i64* %9, align 8, !tbaa !2428
  store i64 %155, i64* %PC, align 8, !alias.scope !2454, !noalias !2457
  %160 = bitcast [32 x %union.VectorReg]* %4 to double*
  %161 = load double, double* %160, align 8, !alias.scope !2454, !noalias !2457
  %162 = inttoptr i64 %158 to i64*
  %163 = load i64, i64* %162, align 8
  store i64 %157, i64* %RSP, align 8, !alias.scope !2454, !noalias !2457
  %164 = tail call double @atan(double %161)
  %.repack = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 0, i64* %.repack, align 8
  %165 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  store i64 0, i64* %165, align 8
  %166 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %166, align 8
  %167 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %167, align 8
  store double %164, double* %160, align 8, !alias.scope !2454, !noalias !2457
  %168 = bitcast %union.VectorReg* %5 to i8*
  %169 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %170 = bitcast %union.VectorReg* %5 to i32*
  store i32 0, i32* %170, align 1, !tbaa !2459
  %171 = getelementptr inbounds i8, i8* %168, i64 4
  %172 = bitcast i8* %171 to i32*
  store i32 0, i32* %172, align 1, !tbaa !2459
  %173 = bitcast i64* %169 to i32*
  store i32 0, i32* %173, align 1, !tbaa !2459
  %174 = getelementptr inbounds i8, i8* %168, i64 12
  %175 = bitcast i8* %174 to i32*
  store i32 0, i32* %175, align 1, !tbaa !2459
  %176 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 64) to i64*), align 16
  %177 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %176, i64* %177, align 1, !tbaa !2452
  %178 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %179 = bitcast i64* %178 to double*
  store double 0.000000e+00, double* %179, align 1, !tbaa !2452
  %180 = load i64, i64* %RBP, align 8
  %181 = add i64 %180, -32
  %182 = add i64 %163, 14
  store i64 %182, i64* %PC, align 8
  %183 = inttoptr i64 %181 to i32*
  %184 = load i32, i32* %183, align 4
  %185 = zext i32 %184 to i64
  store i64 %185, i64* %RAX, align 8, !tbaa !2428
  %186 = sitofp i32 %184 to double
  %187 = bitcast %union.VectorReg* %125 to double*
  store double %186, double* %187, align 1, !tbaa !2452
  %188 = fdiv double %164, %186
  store double %188, double* %127, align 1, !tbaa !2452
  %189 = add i64 %180, -40
  %190 = add i64 %163, 27
  store i64 %190, i64* %PC, align 8
  %191 = inttoptr i64 %189 to double*
  store double %188, double* %191, align 8
  %192 = load i64, i64* %RBP, align 8
  %193 = add i64 %192, -24
  %194 = load i64, i64* %PC, align 8
  %195 = add i64 %194, 4
  store i64 %195, i64* %PC, align 8
  %196 = inttoptr i64 %193 to i64*
  %197 = load i64, i64* %196, align 8
  store i64 %197, i64* %RCX, align 8, !tbaa !2428
  %198 = add i64 %194, 8
  store i64 %198, i64* %PC, align 8
  %199 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  %200 = load i64, i64* %199, align 1
  %201 = inttoptr i64 %197 to i64*
  store i64 %200, i64* %201, align 8
  %202 = load i64, i64* %RBP, align 8
  %203 = add i64 %202, -24
  %204 = load i64, i64* %PC, align 8
  %205 = add i64 %204, 4
  store i64 %205, i64* %PC, align 8
  %206 = inttoptr i64 %203 to i64*
  %207 = load i64, i64* %206, align 8
  store i64 %207, i64* %RCX, align 8, !tbaa !2428
  %208 = add i64 %207, 8
  %209 = add i64 %204, 9
  store i64 %209, i64* %PC, align 8
  %210 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  %211 = load i64, i64* %210, align 1
  %212 = inttoptr i64 %208 to i64*
  store i64 %211, i64* %212, align 8
  %213 = load i64, i64* %RBP, align 8
  %214 = add i64 %213, -40
  %215 = load i64, i64* %PC, align 8
  %216 = add i64 %215, 5
  store i64 %216, i64* %PC, align 8
  %217 = inttoptr i64 %214 to double*
  %218 = load double, double* %217, align 8
  store double %218, double* %127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %130, align 1, !tbaa !2452
  %219 = add i64 %213, -32
  %220 = add i64 %215, 8
  store i64 %220, i64* %PC, align 8
  %221 = inttoptr i64 %219 to i32*
  %222 = load i32, i32* %221, align 4
  %223 = zext i32 %222 to i64
  store i64 %223, i64* %RAX, align 8, !tbaa !2428
  %224 = sitofp i32 %222 to double
  %225 = bitcast %union.VectorReg* %5 to double*
  store double %224, double* %225, align 1, !tbaa !2452
  %226 = fmul double %218, %224
  store double %226, double* %127, align 1, !tbaa !2452
  store i64 0, i64* %129, align 1, !tbaa !2452
  %227 = add i64 %215, -1999
  %228 = add i64 %215, 21
  %229 = load i64, i64* %9, align 8, !tbaa !2428
  %230 = add i64 %229, -8
  %231 = inttoptr i64 %230 to i64*
  store i64 %228, i64* %231, align 8
  store i64 %230, i64* %9, align 8, !tbaa !2428
  store i64 %227, i64* %PC, align 8, !alias.scope !2460, !noalias !2463
  %232 = load double, double* %160, align 8, !alias.scope !2460, !noalias !2463
  %233 = load i64, i64* %231, align 8
  store i64 %229, i64* %RSP, align 8, !alias.scope !2460, !noalias !2463
  %234 = tail call double @cos(double %232)
  %.repack5 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 0, i64* %.repack5, align 8
  %235 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  store i64 0, i64* %235, align 8
  %236 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %236, align 8
  %237 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %237, align 8
  store double %234, double* %160, align 8, !alias.scope !2460, !noalias !2463
  %238 = load i64, i64* %RBP, align 8
  %239 = add i64 %238, -24
  %240 = add i64 %233, 4
  store i64 %240, i64* %PC, align 8
  %241 = inttoptr i64 %239 to i64*
  %242 = load i64, i64* %241, align 8
  store i64 %242, i64* %RCX, align 8, !tbaa !2428
  %243 = add i64 %238, -32
  %244 = add i64 %233, 8
  store i64 %244, i64* %PC, align 8
  %245 = inttoptr i64 %243 to i32*
  %246 = load i32, i32* %245, align 4
  %247 = sext i32 %246 to i64
  store i64 %247, i64* %RDX, align 8, !tbaa !2428
  %248 = shl nsw i64 %247, 3
  %249 = add i64 %248, %242
  %250 = add i64 %233, 13
  store i64 %250, i64* %PC, align 8
  %251 = inttoptr i64 %249 to double*
  store double %234, double* %251, align 8
  %252 = load i64, i64* %RBP, align 8
  %253 = add i64 %252, -24
  %254 = load i64, i64* %PC, align 8
  %255 = add i64 %254, 4
  store i64 %255, i64* %PC, align 8
  %256 = inttoptr i64 %253 to i64*
  %257 = load i64, i64* %256, align 8
  store i64 %257, i64* %RCX, align 8, !tbaa !2428
  %258 = add i64 %252, -32
  %259 = add i64 %254, 8
  store i64 %259, i64* %PC, align 8
  %260 = inttoptr i64 %258 to i32*
  %261 = load i32, i32* %260, align 4
  %262 = sext i32 %261 to i64
  store i64 %262, i64* %RDX, align 8, !tbaa !2428
  %263 = shl nsw i64 %262, 3
  %264 = add i64 %263, %257
  %265 = add i64 %254, 13
  store i64 %265, i64* %PC, align 8
  %266 = inttoptr i64 %264 to i64*
  %267 = load i64, i64* %266, align 8
  %268 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %267, i64* %268, align 1, !tbaa !2452
  store double 0.000000e+00, double* %130, align 1, !tbaa !2452
  %269 = add i64 %254, 17
  store i64 %269, i64* %PC, align 8
  %270 = load i64, i64* %256, align 8
  store i64 %270, i64* %RCX, align 8, !tbaa !2428
  %271 = add i64 %254, 20
  store i64 %271, i64* %PC, align 8
  %272 = load i32, i32* %260, align 4
  %273 = add i32 %272, 1
  %274 = zext i32 %273 to i64
  store i64 %274, i64* %RAX, align 8, !tbaa !2428
  %275 = icmp eq i32 %272, -1
  %276 = icmp eq i32 %273, 0
  %277 = or i1 %275, %276
  %278 = zext i1 %277 to i8
  store i8 %278, i8* %17, align 1, !tbaa !2433
  %279 = and i32 %273, 255
  %280 = tail call i32 @llvm.ctpop.i32(i32 %279) #10
  %281 = trunc i32 %280 to i8
  %282 = and i8 %281, 1
  %283 = xor i8 %282, 1
  store i8 %283, i8* %24, align 1, !tbaa !2447
  %284 = xor i32 %272, %273
  %285 = lshr i32 %284, 4
  %286 = trunc i32 %285 to i8
  %287 = and i8 %286, 1
  store i8 %287, i8* %29, align 1, !tbaa !2451
  %288 = icmp eq i32 %273, 0
  %289 = zext i1 %288 to i8
  store i8 %289, i8* %32, align 1, !tbaa !2448
  %290 = lshr i32 %273, 31
  %291 = trunc i32 %290 to i8
  store i8 %291, i8* %35, align 1, !tbaa !2449
  %292 = lshr i32 %272, 31
  %293 = xor i32 %290, %292
  %294 = add nuw nsw i32 %293, %290
  %295 = icmp eq i32 %294, 2
  %296 = zext i1 %295 to i8
  store i8 %296, i8* %41, align 1, !tbaa !2450
  %297 = sext i32 %273 to i64
  store i64 %297, i64* %RDX, align 8, !tbaa !2428
  %298 = shl nsw i64 %297, 3
  %299 = add i64 %298, %270
  %300 = add i64 %254, 31
  store i64 %300, i64* %PC, align 8
  %301 = inttoptr i64 %299 to i64*
  store i64 %267, i64* %301, align 8
  %302 = load i64, i64* %RBP, align 8
  %303 = add i64 %302, -32
  %304 = load i64, i64* %PC, align 8
  %305 = add i64 %304, 4
  store i64 %305, i64* %PC, align 8
  %306 = inttoptr i64 %303 to i32*
  %307 = load i32, i32* %306, align 4
  %308 = add i32 %307, -2
  %309 = icmp ult i32 %307, 2
  %310 = zext i1 %309 to i8
  store i8 %310, i8* %17, align 1, !tbaa !2433
  %311 = and i32 %308, 255
  %312 = tail call i32 @llvm.ctpop.i32(i32 %311) #10
  %313 = trunc i32 %312 to i8
  %314 = and i8 %313, 1
  %315 = xor i8 %314, 1
  store i8 %315, i8* %24, align 1, !tbaa !2447
  %316 = xor i32 %307, %308
  %317 = lshr i32 %316, 4
  %318 = trunc i32 %317 to i8
  %319 = and i8 %318, 1
  store i8 %319, i8* %29, align 1, !tbaa !2451
  %320 = icmp eq i32 %308, 0
  %321 = zext i1 %320 to i8
  store i8 %321, i8* %32, align 1, !tbaa !2448
  %322 = lshr i32 %308, 31
  %323 = trunc i32 %322 to i8
  store i8 %323, i8* %35, align 1, !tbaa !2449
  %324 = lshr i32 %307, 31
  %325 = xor i32 %322, %324
  %326 = add nuw nsw i32 %325, %324
  %327 = icmp eq i32 %326, 2
  %328 = zext i1 %327 to i8
  store i8 %328, i8* %41, align 1, !tbaa !2450
  %329 = icmp ne i8 %323, 0
  %330 = xor i1 %329, %327
  %331 = or i1 %320, %330
  %.v9 = select i1 %331, i64 201, i64 10
  %332 = add i64 %304, %.v9
  store i64 %332, i64* %88, align 8, !tbaa !2428
  br i1 %331, label %block_400f99, label %block_400eda

block_400eed:                                     ; preds = %block_400ee1
  %333 = add i64 %602, -40
  %334 = add i64 %638, 5
  store i64 %334, i64* %PC, align 8
  %335 = inttoptr i64 %333 to double*
  %336 = load double, double* %335, align 8
  store double %336, double* %127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %130, align 1, !tbaa !2452
  %337 = add i64 %638, 8
  store i64 %337, i64* %PC, align 8
  %338 = load i32, i32* %605, align 4
  %339 = zext i32 %338 to i64
  store i64 %339, i64* %RAX, align 8, !tbaa !2428
  %340 = sitofp i32 %338 to double
  store double %340, double* %225, align 1, !tbaa !2452
  %341 = fmul double %336, %340
  store double %341, double* %127, align 1, !tbaa !2452
  store i64 0, i64* %129, align 1, !tbaa !2452
  %342 = add i64 %638, -2093
  %343 = add i64 %638, 21
  %344 = load i64, i64* %9, align 8, !tbaa !2428
  %345 = add i64 %344, -8
  %346 = inttoptr i64 %345 to i64*
  store i64 %343, i64* %346, align 8
  store i64 %345, i64* %9, align 8, !tbaa !2428
  store i64 %342, i64* %PC, align 8, !alias.scope !2465, !noalias !2468
  %347 = load double, double* %160, align 8, !alias.scope !2465, !noalias !2468
  %348 = load i64, i64* %346, align 8
  store i64 %344, i64* %RSP, align 8, !alias.scope !2465, !noalias !2468
  %349 = tail call double @cos(double %347)
  %.repack11 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 0, i64* %.repack11, align 8
  %350 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  store i64 0, i64* %350, align 8
  %351 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %351, align 8
  %352 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %352, align 8
  store double %349, double* %160, align 8, !alias.scope !2465, !noalias !2468
  %353 = load i64, i64* %RBP, align 8
  %354 = add i64 %353, -48
  %355 = add i64 %348, 5
  store i64 %355, i64* %PC, align 8
  %356 = inttoptr i64 %354 to double*
  store double %349, double* %356, align 8
  %357 = load i64, i64* %RBP, align 8
  %358 = add i64 %357, -40
  %359 = load i64, i64* %PC, align 8
  %360 = add i64 %359, 5
  store i64 %360, i64* %PC, align 8
  %361 = inttoptr i64 %358 to double*
  %362 = load double, double* %361, align 8
  store double %362, double* %127, align 1, !tbaa !2452
  store double 0.000000e+00, double* %130, align 1, !tbaa !2452
  %363 = add i64 %357, -28
  %364 = add i64 %359, 8
  store i64 %364, i64* %PC, align 8
  %365 = inttoptr i64 %363 to i32*
  %366 = load i32, i32* %365, align 4
  %367 = zext i32 %366 to i64
  store i64 %367, i64* %RAX, align 8, !tbaa !2428
  %368 = sitofp i32 %366 to double
  store double %368, double* %225, align 1, !tbaa !2452
  %369 = fmul double %362, %368
  store double %369, double* %127, align 1, !tbaa !2452
  store i64 0, i64* %129, align 1, !tbaa !2452
  %370 = add i64 %359, -2071
  %371 = add i64 %359, 21
  %372 = load i64, i64* %9, align 8, !tbaa !2428
  %373 = add i64 %372, -8
  %374 = inttoptr i64 %373 to i64*
  store i64 %371, i64* %374, align 8
  store i64 %373, i64* %9, align 8, !tbaa !2428
  store i64 %370, i64* %PC, align 8, !alias.scope !2470, !noalias !2473
  %375 = load double, double* %160, align 8, !alias.scope !2470, !noalias !2473
  %376 = load i64, i64* %374, align 8
  store i64 %372, i64* %RSP, align 8, !alias.scope !2470, !noalias !2473
  %377 = tail call double @sin(double %375)
  %.repack15 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 0, i64* %.repack15, align 8
  %378 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  store i64 0, i64* %378, align 8
  %379 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %379, align 8
  %380 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %380, align 8
  store double %377, double* %160, align 8, !alias.scope !2470, !noalias !2473
  %381 = load i64, i64* %RBP, align 8
  %382 = add i64 %381, -56
  %383 = add i64 %376, 5
  store i64 %383, i64* %PC, align 8
  %384 = inttoptr i64 %382 to double*
  store double %377, double* %384, align 8
  %385 = load i64, i64* %RBP, align 8
  %386 = add i64 %385, -48
  %387 = load i64, i64* %PC, align 8
  %388 = add i64 %387, 5
  store i64 %388, i64* %PC, align 8
  %389 = inttoptr i64 %386 to i64*
  %390 = load i64, i64* %389, align 8
  %391 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %390, i64* %391, align 1, !tbaa !2452
  store double 0.000000e+00, double* %130, align 1, !tbaa !2452
  %392 = add i64 %385, -24
  %393 = add i64 %387, 9
  store i64 %393, i64* %PC, align 8
  %394 = inttoptr i64 %392 to i64*
  %395 = load i64, i64* %394, align 8
  store i64 %395, i64* %RCX, align 8, !tbaa !2428
  %396 = add i64 %385, -28
  %397 = add i64 %387, 13
  store i64 %397, i64* %PC, align 8
  %398 = inttoptr i64 %396 to i32*
  %399 = load i32, i32* %398, align 4
  %400 = sext i32 %399 to i64
  store i64 %400, i64* %RDX, align 8, !tbaa !2428
  %401 = shl nsw i64 %400, 3
  %402 = add i64 %401, %395
  %403 = add i64 %387, 18
  store i64 %403, i64* %PC, align 8
  %404 = inttoptr i64 %402 to i64*
  store i64 %390, i64* %404, align 8
  %405 = load i64, i64* %RBP, align 8
  %406 = add i64 %405, -56
  %407 = load i64, i64* %PC, align 8
  %408 = add i64 %407, 5
  store i64 %408, i64* %PC, align 8
  %409 = inttoptr i64 %406 to i64*
  %410 = load i64, i64* %409, align 8
  %411 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %410, i64* %411, align 1, !tbaa !2452
  store double 0.000000e+00, double* %130, align 1, !tbaa !2452
  %412 = add i64 %405, -24
  %413 = add i64 %407, 9
  store i64 %413, i64* %PC, align 8
  %414 = inttoptr i64 %412 to i64*
  %415 = load i64, i64* %414, align 8
  store i64 %415, i64* %RCX, align 8, !tbaa !2428
  %416 = add i64 %405, -28
  %417 = add i64 %407, 12
  store i64 %417, i64* %PC, align 8
  %418 = inttoptr i64 %416 to i32*
  %419 = load i32, i32* %418, align 4
  %420 = add i32 %419, 1
  %421 = zext i32 %420 to i64
  store i64 %421, i64* %RAX, align 8, !tbaa !2428
  %422 = icmp eq i32 %419, -1
  %423 = icmp eq i32 %420, 0
  %424 = or i1 %422, %423
  %425 = zext i1 %424 to i8
  store i8 %425, i8* %17, align 1, !tbaa !2433
  %426 = and i32 %420, 255
  %427 = tail call i32 @llvm.ctpop.i32(i32 %426) #10
  %428 = trunc i32 %427 to i8
  %429 = and i8 %428, 1
  %430 = xor i8 %429, 1
  store i8 %430, i8* %24, align 1, !tbaa !2447
  %431 = xor i32 %419, %420
  %432 = lshr i32 %431, 4
  %433 = trunc i32 %432 to i8
  %434 = and i8 %433, 1
  store i8 %434, i8* %29, align 1, !tbaa !2451
  %435 = icmp eq i32 %420, 0
  %436 = zext i1 %435 to i8
  store i8 %436, i8* %32, align 1, !tbaa !2448
  %437 = lshr i32 %420, 31
  %438 = trunc i32 %437 to i8
  store i8 %438, i8* %35, align 1, !tbaa !2449
  %439 = lshr i32 %419, 31
  %440 = xor i32 %437, %439
  %441 = add nuw nsw i32 %440, %437
  %442 = icmp eq i32 %441, 2
  %443 = zext i1 %442 to i8
  store i8 %443, i8* %41, align 1, !tbaa !2450
  %444 = sext i32 %420 to i64
  store i64 %444, i64* %RDX, align 8, !tbaa !2428
  %445 = shl nsw i64 %444, 3
  %446 = add i64 %445, %415
  %447 = add i64 %407, 23
  store i64 %447, i64* %PC, align 8
  %448 = inttoptr i64 %446 to i64*
  store i64 %410, i64* %448, align 8
  %449 = load i64, i64* %RBP, align 8
  %450 = add i64 %449, -56
  %451 = load i64, i64* %PC, align 8
  %452 = add i64 %451, 5
  store i64 %452, i64* %PC, align 8
  %453 = inttoptr i64 %450 to i64*
  %454 = load i64, i64* %453, align 8
  %455 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %454, i64* %455, align 1, !tbaa !2452
  store double 0.000000e+00, double* %130, align 1, !tbaa !2452
  %456 = add i64 %449, -24
  %457 = add i64 %451, 9
  store i64 %457, i64* %PC, align 8
  %458 = inttoptr i64 %456 to i64*
  %459 = load i64, i64* %458, align 8
  store i64 %459, i64* %RCX, align 8, !tbaa !2428
  %460 = add i64 %449, -4
  %461 = add i64 %451, 12
  store i64 %461, i64* %PC, align 8
  %462 = inttoptr i64 %460 to i32*
  %463 = load i32, i32* %462, align 4
  %464 = zext i32 %463 to i64
  store i64 %464, i64* %RAX, align 8, !tbaa !2428
  %465 = add i64 %449, -28
  %466 = add i64 %451, 15
  store i64 %466, i64* %PC, align 8
  %467 = inttoptr i64 %465 to i32*
  %468 = load i32, i32* %467, align 4
  %469 = sub i32 %463, %468
  %470 = zext i32 %469 to i64
  store i64 %470, i64* %RAX, align 8, !tbaa !2428
  %471 = icmp ult i32 %463, %468
  %472 = zext i1 %471 to i8
  store i8 %472, i8* %17, align 1, !tbaa !2433
  %473 = and i32 %469, 255
  %474 = tail call i32 @llvm.ctpop.i32(i32 %473) #10
  %475 = trunc i32 %474 to i8
  %476 = and i8 %475, 1
  %477 = xor i8 %476, 1
  store i8 %477, i8* %24, align 1, !tbaa !2447
  %478 = xor i32 %468, %463
  %479 = xor i32 %478, %469
  %480 = lshr i32 %479, 4
  %481 = trunc i32 %480 to i8
  %482 = and i8 %481, 1
  store i8 %482, i8* %29, align 1, !tbaa !2451
  %483 = icmp eq i32 %469, 0
  %484 = zext i1 %483 to i8
  store i8 %484, i8* %32, align 1, !tbaa !2448
  %485 = lshr i32 %469, 31
  %486 = trunc i32 %485 to i8
  store i8 %486, i8* %35, align 1, !tbaa !2449
  %487 = lshr i32 %463, 31
  %488 = lshr i32 %468, 31
  %489 = xor i32 %488, %487
  %490 = xor i32 %485, %487
  %491 = add nuw nsw i32 %490, %489
  %492 = icmp eq i32 %491, 2
  %493 = zext i1 %492 to i8
  store i8 %493, i8* %41, align 1, !tbaa !2450
  %494 = sext i32 %469 to i64
  store i64 %494, i64* %RDX, align 8, !tbaa !2428
  %495 = shl nsw i64 %494, 3
  %496 = add i64 %495, %459
  %497 = add i64 %451, 23
  store i64 %497, i64* %PC, align 8
  %498 = inttoptr i64 %496 to i64*
  store i64 %454, i64* %498, align 8
  %499 = load i64, i64* %RBP, align 8
  %500 = add i64 %499, -48
  %501 = load i64, i64* %PC, align 8
  %502 = add i64 %501, 5
  store i64 %502, i64* %PC, align 8
  %503 = inttoptr i64 %500 to i64*
  %504 = load i64, i64* %503, align 8
  %505 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %504, i64* %505, align 1, !tbaa !2452
  store double 0.000000e+00, double* %130, align 1, !tbaa !2452
  %506 = add i64 %499, -24
  %507 = add i64 %501, 9
  store i64 %507, i64* %PC, align 8
  %508 = inttoptr i64 %506 to i64*
  %509 = load i64, i64* %508, align 8
  store i64 %509, i64* %RCX, align 8, !tbaa !2428
  %510 = add i64 %499, -4
  %511 = add i64 %501, 12
  store i64 %511, i64* %PC, align 8
  %512 = inttoptr i64 %510 to i32*
  %513 = load i32, i32* %512, align 4
  %514 = zext i32 %513 to i64
  store i64 %514, i64* %RAX, align 8, !tbaa !2428
  %515 = add i64 %499, -28
  %516 = add i64 %501, 15
  store i64 %516, i64* %PC, align 8
  %517 = inttoptr i64 %515 to i32*
  %518 = load i32, i32* %517, align 4
  %519 = sub i32 %513, %518
  %520 = lshr i32 %519, 31
  %521 = add i32 %519, 1
  %522 = zext i32 %521 to i64
  store i64 %522, i64* %RAX, align 8, !tbaa !2428
  %523 = icmp eq i32 %519, -1
  %524 = icmp eq i32 %521, 0
  %525 = or i1 %523, %524
  %526 = zext i1 %525 to i8
  store i8 %526, i8* %17, align 1, !tbaa !2433
  %527 = and i32 %521, 255
  %528 = tail call i32 @llvm.ctpop.i32(i32 %527) #10
  %529 = trunc i32 %528 to i8
  %530 = and i8 %529, 1
  %531 = xor i8 %530, 1
  store i8 %531, i8* %24, align 1, !tbaa !2447
  %532 = xor i32 %519, %521
  %533 = lshr i32 %532, 4
  %534 = trunc i32 %533 to i8
  %535 = and i8 %534, 1
  store i8 %535, i8* %29, align 1, !tbaa !2451
  %536 = icmp eq i32 %521, 0
  %537 = zext i1 %536 to i8
  store i8 %537, i8* %32, align 1, !tbaa !2448
  %538 = lshr i32 %521, 31
  %539 = trunc i32 %538 to i8
  store i8 %539, i8* %35, align 1, !tbaa !2449
  %540 = xor i32 %538, %520
  %541 = add nuw nsw i32 %540, %538
  %542 = icmp eq i32 %541, 2
  %543 = zext i1 %542 to i8
  store i8 %543, i8* %41, align 1, !tbaa !2450
  %544 = sext i32 %521 to i64
  store i64 %544, i64* %RDX, align 8, !tbaa !2428
  %545 = shl nsw i64 %544, 3
  %546 = add i64 %545, %509
  %547 = add i64 %501, 26
  store i64 %547, i64* %PC, align 8
  %548 = inttoptr i64 %546 to i64*
  store i64 %504, i64* %548, align 8
  %549 = load i64, i64* %RBP, align 8
  %550 = add i64 %549, -28
  %551 = load i64, i64* %PC, align 8
  %552 = add i64 %551, 3
  store i64 %552, i64* %PC, align 8
  %553 = inttoptr i64 %550 to i32*
  %554 = load i32, i32* %553, align 4
  %555 = add i32 %554, 2
  %556 = zext i32 %555 to i64
  store i64 %556, i64* %RAX, align 8, !tbaa !2428
  %557 = icmp ugt i32 %554, -3
  %558 = zext i1 %557 to i8
  store i8 %558, i8* %17, align 1, !tbaa !2433
  %559 = and i32 %555, 255
  %560 = tail call i32 @llvm.ctpop.i32(i32 %559) #10
  %561 = trunc i32 %560 to i8
  %562 = and i8 %561, 1
  %563 = xor i8 %562, 1
  store i8 %563, i8* %24, align 1, !tbaa !2447
  %564 = xor i32 %554, %555
  %565 = lshr i32 %564, 4
  %566 = trunc i32 %565 to i8
  %567 = and i8 %566, 1
  store i8 %567, i8* %29, align 1, !tbaa !2451
  %568 = icmp eq i32 %555, 0
  %569 = zext i1 %568 to i8
  store i8 %569, i8* %32, align 1, !tbaa !2448
  %570 = lshr i32 %555, 31
  %571 = trunc i32 %570 to i8
  store i8 %571, i8* %35, align 1, !tbaa !2449
  %572 = lshr i32 %554, 31
  %573 = xor i32 %570, %572
  %574 = add nuw nsw i32 %573, %570
  %575 = icmp eq i32 %574, 2
  %576 = zext i1 %575 to i8
  store i8 %576, i8* %41, align 1, !tbaa !2450
  %577 = add i64 %551, 9
  store i64 %577, i64* %PC, align 8
  store i32 %555, i32* %553, align 4
  %578 = load i64, i64* %PC, align 8
  %579 = add i64 %578, -163
  store i64 %579, i64* %88, align 8, !tbaa !2428
  br label %block_400ee1

block_400f89:                                     ; preds = %block_400ee1
  %580 = add i64 %602, -4
  %581 = add i64 %638, 3
  store i64 %581, i64* %PC, align 8
  %582 = inttoptr i64 %580 to i32*
  %583 = load i32, i32* %582, align 4
  %584 = zext i32 %583 to i64
  store i64 %584, i64* %RDI, align 8, !tbaa !2428
  %585 = add i64 %602, -16
  %586 = add i64 %638, 7
  store i64 %586, i64* %PC, align 8
  %587 = inttoptr i64 %585 to i64*
  %588 = load i64, i64* %587, align 8
  store i64 %588, i64* %RSI, align 8, !tbaa !2428
  %589 = add i64 %602, -24
  %590 = add i64 %638, 11
  store i64 %590, i64* %PC, align 8
  %591 = inttoptr i64 %589 to i64*
  %592 = load i64, i64* %591, align 8
  store i64 %592, i64* %RDX, align 8, !tbaa !2428
  %593 = add i64 %638, 567
  %594 = add i64 %638, 16
  %595 = load i64, i64* %9, align 8, !tbaa !2428
  %596 = add i64 %595, -8
  %597 = inttoptr i64 %596 to i64*
  store i64 %594, i64* %597, align 8
  store i64 %596, i64* %9, align 8, !tbaa !2428
  store i64 %593, i64* %88, align 8, !tbaa !2428
  %598 = tail call %struct.Memory* @sub_4011c0_bitrv2_renamed_(%struct.State* nonnull %0, i64 %593, %struct.Memory* %2)
  %.pre1 = load i64, i64* %PC, align 8
  br label %block_400f99

block_400f99:                                     ; preds = %block_400f89, %block_400e4d
  %599 = phi i64 [ %332, %block_400e4d ], [ %.pre1, %block_400f89 ]
  %MEMORY.1 = phi %struct.Memory* [ %2, %block_400e4d ], [ %598, %block_400f89 ]
  %600 = add i64 %599, 5
  store i64 %600, i64* %88, align 8, !tbaa !2428
  br label %block_400f9e

block_400ee1:                                     ; preds = %block_400eed, %block_400eda
  %601 = phi i64 [ %579, %block_400eed ], [ %.pre, %block_400eda ]
  %602 = load i64, i64* %RBP, align 8
  %603 = add i64 %602, -28
  %604 = add i64 %601, 3
  store i64 %604, i64* %PC, align 8
  %605 = inttoptr i64 %603 to i32*
  %606 = load i32, i32* %605, align 4
  %607 = zext i32 %606 to i64
  store i64 %607, i64* %RAX, align 8, !tbaa !2428
  %608 = add i64 %602, -32
  %609 = add i64 %601, 6
  store i64 %609, i64* %PC, align 8
  %610 = inttoptr i64 %608 to i32*
  %611 = load i32, i32* %610, align 4
  %612 = sub i32 %606, %611
  %613 = icmp ult i32 %606, %611
  %614 = zext i1 %613 to i8
  store i8 %614, i8* %17, align 1, !tbaa !2433
  %615 = and i32 %612, 255
  %616 = tail call i32 @llvm.ctpop.i32(i32 %615) #10
  %617 = trunc i32 %616 to i8
  %618 = and i8 %617, 1
  %619 = xor i8 %618, 1
  store i8 %619, i8* %24, align 1, !tbaa !2447
  %620 = xor i32 %611, %606
  %621 = xor i32 %620, %612
  %622 = lshr i32 %621, 4
  %623 = trunc i32 %622 to i8
  %624 = and i8 %623, 1
  store i8 %624, i8* %29, align 1, !tbaa !2451
  %625 = icmp eq i32 %612, 0
  %626 = zext i1 %625 to i8
  store i8 %626, i8* %32, align 1, !tbaa !2448
  %627 = lshr i32 %612, 31
  %628 = trunc i32 %627 to i8
  store i8 %628, i8* %35, align 1, !tbaa !2449
  %629 = lshr i32 %606, 31
  %630 = lshr i32 %611, 31
  %631 = xor i32 %630, %629
  %632 = xor i32 %627, %629
  %633 = add nuw nsw i32 %632, %631
  %634 = icmp eq i32 %633, 2
  %635 = zext i1 %634 to i8
  store i8 %635, i8* %41, align 1, !tbaa !2450
  %636 = icmp ne i8 %628, 0
  %637 = xor i1 %636, %634
  %.v10 = select i1 %637, i64 12, i64 168
  %638 = add i64 %601, %.v10
  store i64 %638, i64* %88, align 8, !tbaa !2428
  br i1 %637, label %block_400eed, label %block_400f89
}

; Function Attrs: noinline
define %struct.Memory* @sub_404060___libc_csu_fini(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_404060:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = add i64 %1, 2
  store i64 %3, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = inttoptr i64 %6 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %4, align 8, !tbaa !2428
  %9 = add i64 %6, 8
  store i64 %9, i64* %5, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_401840_cftfsub(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_401840:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %8 = load i64, i64* %7, align 8, !tbaa !2428
  %9 = add i64 %8, -8
  %10 = inttoptr i64 %9 to i64*
  store i64 %5, i64* %10, align 8
  %11 = load i64, i64* %PC, align 8
  store i64 %9, i64* %RBP, align 8, !tbaa !2428
  %12 = add i64 %8, -120
  store i64 %12, i64* %RSP, align 8, !tbaa !2428
  %13 = icmp ult i64 %9, 112
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1, !tbaa !2433
  %16 = trunc i64 %12 to i32
  %17 = and i32 %16, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17) #10
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1, !tbaa !2447
  %23 = xor i64 %9, 16
  %24 = xor i64 %23, %12
  %25 = lshr i64 %24, 4
  %26 = trunc i64 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1, !tbaa !2451
  %29 = icmp eq i64 %12, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1, !tbaa !2448
  %32 = lshr i64 %12, 63
  %33 = trunc i64 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1, !tbaa !2449
  %35 = lshr i64 %9, 63
  %36 = xor i64 %32, %35
  %37 = add nuw nsw i64 %36, %35
  %38 = icmp eq i64 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1, !tbaa !2450
  %41 = add i64 %8, -12
  %42 = load i32, i32* %EDI, align 4
  %43 = add i64 %11, 10
  store i64 %43, i64* %PC, align 8
  %44 = inttoptr i64 %41 to i32*
  store i32 %42, i32* %44, align 4
  %45 = load i64, i64* %RBP, align 8
  %46 = add i64 %45, -16
  %47 = load i64, i64* %RSI, align 8
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 4
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %46 to i64*
  store i64 %47, i64* %50, align 8
  %51 = load i64, i64* %RBP, align 8
  %52 = add i64 %51, -24
  %53 = load i64, i64* %RDX, align 8
  %54 = load i64, i64* %PC, align 8
  %55 = add i64 %54, 4
  store i64 %55, i64* %PC, align 8
  %56 = inttoptr i64 %52 to i64*
  store i64 %53, i64* %56, align 8
  %57 = load i64, i64* %RBP, align 8
  %58 = add i64 %57, -44
  %59 = load i64, i64* %PC, align 8
  %60 = add i64 %59, 7
  store i64 %60, i64* %PC, align 8
  %61 = inttoptr i64 %58 to i32*
  store i32 2, i32* %61, align 4
  %62 = load i64, i64* %RBP, align 8
  %63 = add i64 %62, -4
  %64 = load i64, i64* %PC, align 8
  %65 = add i64 %64, 4
  store i64 %65, i64* %PC, align 8
  %66 = inttoptr i64 %63 to i32*
  %67 = load i32, i32* %66, align 4
  %68 = add i32 %67, -8
  %69 = icmp ult i32 %67, 8
  %70 = zext i1 %69 to i8
  store i8 %70, i8* %15, align 1, !tbaa !2433
  %71 = and i32 %68, 255
  %72 = tail call i32 @llvm.ctpop.i32(i32 %71) #10
  %73 = trunc i32 %72 to i8
  %74 = and i8 %73, 1
  %75 = xor i8 %74, 1
  store i8 %75, i8* %22, align 1, !tbaa !2447
  %76 = xor i32 %67, %68
  %77 = lshr i32 %76, 4
  %78 = trunc i32 %77 to i8
  %79 = and i8 %78, 1
  store i8 %79, i8* %28, align 1, !tbaa !2451
  %80 = icmp eq i32 %68, 0
  %81 = zext i1 %80 to i8
  store i8 %81, i8* %31, align 1, !tbaa !2448
  %82 = lshr i32 %68, 31
  %83 = trunc i32 %82 to i8
  store i8 %83, i8* %34, align 1, !tbaa !2449
  %84 = lshr i32 %67, 31
  %85 = xor i32 %82, %84
  %86 = add nuw nsw i32 %85, %84
  %87 = icmp eq i32 %86, 2
  %88 = zext i1 %87 to i8
  store i8 %88, i8* %40, align 1, !tbaa !2450
  %89 = icmp ne i8 %83, 0
  %90 = xor i1 %89, %87
  %91 = or i1 %80, %90
  %92 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %.v = select i1 %91, i64 86, i64 10
  %93 = add i64 %64, %.v
  store i64 %93, i64* %92, align 8, !tbaa !2428
  br i1 %91, label %block_4018b0, label %block_401864

block_401af3:                                     ; preds = %block_4018b0, %block_401aff
  %94 = phi i64 [ %1478, %block_401aff ], [ %.pre2, %block_4018b0 ]
  %95 = load i64, i64* %RBP, align 8
  %96 = add i64 %95, -28
  %97 = add i64 %94, 3
  store i64 %97, i64* %PC, align 8
  %98 = inttoptr i64 %96 to i32*
  %99 = load i32, i32* %98, align 4
  %100 = zext i32 %99 to i64
  store i64 %100, i64* %RAX, align 8, !tbaa !2428
  %101 = add i64 %95, -44
  %102 = add i64 %94, 6
  store i64 %102, i64* %PC, align 8
  %103 = inttoptr i64 %101 to i32*
  %104 = load i32, i32* %103, align 4
  %105 = sub i32 %99, %104
  %106 = icmp ult i32 %99, %104
  %107 = zext i1 %106 to i8
  store i8 %107, i8* %15, align 1, !tbaa !2433
  %108 = and i32 %105, 255
  %109 = tail call i32 @llvm.ctpop.i32(i32 %108) #10
  %110 = trunc i32 %109 to i8
  %111 = and i8 %110, 1
  %112 = xor i8 %111, 1
  store i8 %112, i8* %22, align 1, !tbaa !2447
  %113 = xor i32 %104, %99
  %114 = xor i32 %113, %105
  %115 = lshr i32 %114, 4
  %116 = trunc i32 %115 to i8
  %117 = and i8 %116, 1
  store i8 %117, i8* %28, align 1, !tbaa !2451
  %118 = icmp eq i32 %105, 0
  %119 = zext i1 %118 to i8
  store i8 %119, i8* %31, align 1, !tbaa !2448
  %120 = lshr i32 %105, 31
  %121 = trunc i32 %120 to i8
  store i8 %121, i8* %34, align 1, !tbaa !2449
  %122 = lshr i32 %99, 31
  %123 = lshr i32 %104, 31
  %124 = xor i32 %123, %122
  %125 = xor i32 %120, %122
  %126 = add nuw nsw i32 %125, %124
  %127 = icmp eq i32 %126, 2
  %128 = zext i1 %127 to i8
  store i8 %128, i8* %40, align 1, !tbaa !2450
  %129 = icmp ne i8 %121, 0
  %130 = xor i1 %129, %127
  %.v7 = select i1 %130, i64 12, i64 220
  %131 = add i64 %94, %.v7
  store i64 %131, i64* %92, align 8, !tbaa !2428
  br i1 %130, label %block_401aff, label %block_401bcf

block_4018d2:                                     ; preds = %block_4018c6
  %132 = add i64 %1593, 3
  store i64 %132, i64* %PC, align 8
  %133 = load i32, i32* %1560, align 4
  %134 = zext i32 %133 to i64
  store i64 %134, i64* %RAX, align 8, !tbaa !2428
  %135 = add i64 %1593, 6
  store i64 %135, i64* %PC, align 8
  %136 = load i32, i32* %1565, align 4
  %137 = add i32 %136, %133
  %138 = zext i32 %137 to i64
  store i64 %138, i64* %RAX, align 8, !tbaa !2428
  %139 = icmp ult i32 %137, %133
  %140 = icmp ult i32 %137, %136
  %141 = or i1 %139, %140
  %142 = zext i1 %141 to i8
  store i8 %142, i8* %15, align 1, !tbaa !2433
  %143 = and i32 %137, 255
  %144 = tail call i32 @llvm.ctpop.i32(i32 %143) #10
  %145 = trunc i32 %144 to i8
  %146 = and i8 %145, 1
  %147 = xor i8 %146, 1
  store i8 %147, i8* %22, align 1, !tbaa !2447
  %148 = xor i32 %136, %133
  %149 = xor i32 %148, %137
  %150 = lshr i32 %149, 4
  %151 = trunc i32 %150 to i8
  %152 = and i8 %151, 1
  store i8 %152, i8* %28, align 1, !tbaa !2451
  %153 = icmp eq i32 %137, 0
  %154 = zext i1 %153 to i8
  store i8 %154, i8* %31, align 1, !tbaa !2448
  %155 = lshr i32 %137, 31
  %156 = trunc i32 %155 to i8
  store i8 %156, i8* %34, align 1, !tbaa !2449
  %157 = lshr i32 %133, 31
  %158 = lshr i32 %136, 31
  %159 = xor i32 %155, %157
  %160 = xor i32 %155, %158
  %161 = add nuw nsw i32 %159, %160
  %162 = icmp eq i32 %161, 2
  %163 = zext i1 %162 to i8
  store i8 %163, i8* %40, align 1, !tbaa !2450
  %164 = add i64 %1557, -32
  %165 = add i64 %1593, 9
  store i64 %165, i64* %PC, align 8
  %166 = inttoptr i64 %164 to i32*
  store i32 %137, i32* %166, align 4
  %167 = load i64, i64* %RBP, align 8
  %168 = add i64 %167, -32
  %169 = load i64, i64* %PC, align 8
  %170 = add i64 %169, 3
  store i64 %170, i64* %PC, align 8
  %171 = inttoptr i64 %168 to i32*
  %172 = load i32, i32* %171, align 4
  %173 = zext i32 %172 to i64
  store i64 %173, i64* %RAX, align 8, !tbaa !2428
  %174 = add i64 %167, -44
  %175 = add i64 %169, 6
  store i64 %175, i64* %PC, align 8
  %176 = inttoptr i64 %174 to i32*
  %177 = load i32, i32* %176, align 4
  %178 = add i32 %177, %172
  %179 = zext i32 %178 to i64
  store i64 %179, i64* %RAX, align 8, !tbaa !2428
  %180 = icmp ult i32 %178, %172
  %181 = icmp ult i32 %178, %177
  %182 = or i1 %180, %181
  %183 = zext i1 %182 to i8
  store i8 %183, i8* %15, align 1, !tbaa !2433
  %184 = and i32 %178, 255
  %185 = tail call i32 @llvm.ctpop.i32(i32 %184) #10
  %186 = trunc i32 %185 to i8
  %187 = and i8 %186, 1
  %188 = xor i8 %187, 1
  store i8 %188, i8* %22, align 1, !tbaa !2447
  %189 = xor i32 %177, %172
  %190 = xor i32 %189, %178
  %191 = lshr i32 %190, 4
  %192 = trunc i32 %191 to i8
  %193 = and i8 %192, 1
  store i8 %193, i8* %28, align 1, !tbaa !2451
  %194 = icmp eq i32 %178, 0
  %195 = zext i1 %194 to i8
  store i8 %195, i8* %31, align 1, !tbaa !2448
  %196 = lshr i32 %178, 31
  %197 = trunc i32 %196 to i8
  store i8 %197, i8* %34, align 1, !tbaa !2449
  %198 = lshr i32 %172, 31
  %199 = lshr i32 %177, 31
  %200 = xor i32 %196, %198
  %201 = xor i32 %196, %199
  %202 = add nuw nsw i32 %200, %201
  %203 = icmp eq i32 %202, 2
  %204 = zext i1 %203 to i8
  store i8 %204, i8* %40, align 1, !tbaa !2450
  %205 = add i64 %167, -36
  %206 = add i64 %169, 9
  store i64 %206, i64* %PC, align 8
  %207 = inttoptr i64 %205 to i32*
  store i32 %178, i32* %207, align 4
  %208 = load i64, i64* %RBP, align 8
  %209 = add i64 %208, -36
  %210 = load i64, i64* %PC, align 8
  %211 = add i64 %210, 3
  store i64 %211, i64* %PC, align 8
  %212 = inttoptr i64 %209 to i32*
  %213 = load i32, i32* %212, align 4
  %214 = zext i32 %213 to i64
  store i64 %214, i64* %RAX, align 8, !tbaa !2428
  %215 = add i64 %208, -44
  %216 = add i64 %210, 6
  store i64 %216, i64* %PC, align 8
  %217 = inttoptr i64 %215 to i32*
  %218 = load i32, i32* %217, align 4
  %219 = add i32 %218, %213
  %220 = zext i32 %219 to i64
  store i64 %220, i64* %RAX, align 8, !tbaa !2428
  %221 = icmp ult i32 %219, %213
  %222 = icmp ult i32 %219, %218
  %223 = or i1 %221, %222
  %224 = zext i1 %223 to i8
  store i8 %224, i8* %15, align 1, !tbaa !2433
  %225 = and i32 %219, 255
  %226 = tail call i32 @llvm.ctpop.i32(i32 %225) #10
  %227 = trunc i32 %226 to i8
  %228 = and i8 %227, 1
  %229 = xor i8 %228, 1
  store i8 %229, i8* %22, align 1, !tbaa !2447
  %230 = xor i32 %218, %213
  %231 = xor i32 %230, %219
  %232 = lshr i32 %231, 4
  %233 = trunc i32 %232 to i8
  %234 = and i8 %233, 1
  store i8 %234, i8* %28, align 1, !tbaa !2451
  %235 = icmp eq i32 %219, 0
  %236 = zext i1 %235 to i8
  store i8 %236, i8* %31, align 1, !tbaa !2448
  %237 = lshr i32 %219, 31
  %238 = trunc i32 %237 to i8
  store i8 %238, i8* %34, align 1, !tbaa !2449
  %239 = lshr i32 %213, 31
  %240 = lshr i32 %218, 31
  %241 = xor i32 %237, %239
  %242 = xor i32 %237, %240
  %243 = add nuw nsw i32 %241, %242
  %244 = icmp eq i32 %243, 2
  %245 = zext i1 %244 to i8
  store i8 %245, i8* %40, align 1, !tbaa !2450
  %246 = add i64 %208, -40
  %247 = add i64 %210, 9
  store i64 %247, i64* %PC, align 8
  %248 = inttoptr i64 %246 to i32*
  store i32 %219, i32* %248, align 4
  %249 = load i64, i64* %RBP, align 8
  %250 = add i64 %249, -16
  %251 = load i64, i64* %PC, align 8
  %252 = add i64 %251, 4
  store i64 %252, i64* %PC, align 8
  %253 = inttoptr i64 %250 to i64*
  %254 = load i64, i64* %253, align 8
  store i64 %254, i64* %RCX, align 8, !tbaa !2428
  %255 = add i64 %249, -28
  %256 = add i64 %251, 8
  store i64 %256, i64* %PC, align 8
  %257 = inttoptr i64 %255 to i32*
  %258 = load i32, i32* %257, align 4
  %259 = sext i32 %258 to i64
  store i64 %259, i64* %RDX, align 8, !tbaa !2428
  %260 = shl nsw i64 %259, 3
  %261 = add i64 %260, %254
  %262 = add i64 %251, 13
  store i64 %262, i64* %PC, align 8
  %263 = inttoptr i64 %261 to double*
  %264 = load double, double* %263, align 8
  store double %264, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %265 = add i64 %251, 17
  store i64 %265, i64* %PC, align 8
  %266 = load i64, i64* %253, align 8
  store i64 %266, i64* %RCX, align 8, !tbaa !2428
  %267 = add i64 %249, -32
  %268 = add i64 %251, 21
  store i64 %268, i64* %PC, align 8
  %269 = inttoptr i64 %267 to i32*
  %270 = load i32, i32* %269, align 4
  %271 = sext i32 %270 to i64
  store i64 %271, i64* %RDX, align 8, !tbaa !2428
  %272 = shl nsw i64 %271, 3
  %273 = add i64 %272, %266
  %274 = add i64 %251, 26
  store i64 %274, i64* %PC, align 8
  %275 = inttoptr i64 %273 to double*
  %276 = load double, double* %275, align 8
  %277 = fadd double %264, %276
  store double %277, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %278 = add i64 %249, -56
  %279 = add i64 %251, 31
  store i64 %279, i64* %PC, align 8
  %280 = inttoptr i64 %278 to double*
  store double %277, double* %280, align 8
  %281 = load i64, i64* %RBP, align 8
  %282 = add i64 %281, -16
  %283 = load i64, i64* %PC, align 8
  %284 = add i64 %283, 4
  store i64 %284, i64* %PC, align 8
  %285 = inttoptr i64 %282 to i64*
  %286 = load i64, i64* %285, align 8
  store i64 %286, i64* %RCX, align 8, !tbaa !2428
  %287 = add i64 %281, -28
  %288 = add i64 %283, 7
  store i64 %288, i64* %PC, align 8
  %289 = inttoptr i64 %287 to i32*
  %290 = load i32, i32* %289, align 4
  %291 = add i32 %290, 1
  %292 = zext i32 %291 to i64
  store i64 %292, i64* %RAX, align 8, !tbaa !2428
  %293 = icmp eq i32 %290, -1
  %294 = icmp eq i32 %291, 0
  %295 = or i1 %293, %294
  %296 = zext i1 %295 to i8
  store i8 %296, i8* %15, align 1, !tbaa !2433
  %297 = and i32 %291, 255
  %298 = tail call i32 @llvm.ctpop.i32(i32 %297) #10
  %299 = trunc i32 %298 to i8
  %300 = and i8 %299, 1
  %301 = xor i8 %300, 1
  store i8 %301, i8* %22, align 1, !tbaa !2447
  %302 = xor i32 %290, %291
  %303 = lshr i32 %302, 4
  %304 = trunc i32 %303 to i8
  %305 = and i8 %304, 1
  store i8 %305, i8* %28, align 1, !tbaa !2451
  %306 = icmp eq i32 %291, 0
  %307 = zext i1 %306 to i8
  store i8 %307, i8* %31, align 1, !tbaa !2448
  %308 = lshr i32 %291, 31
  %309 = trunc i32 %308 to i8
  store i8 %309, i8* %34, align 1, !tbaa !2449
  %310 = lshr i32 %290, 31
  %311 = xor i32 %308, %310
  %312 = add nuw nsw i32 %311, %308
  %313 = icmp eq i32 %312, 2
  %314 = zext i1 %313 to i8
  store i8 %314, i8* %40, align 1, !tbaa !2450
  %315 = sext i32 %291 to i64
  store i64 %315, i64* %RDX, align 8, !tbaa !2428
  %316 = shl nsw i64 %315, 3
  %317 = add i64 %316, %286
  %318 = add i64 %283, 18
  store i64 %318, i64* %PC, align 8
  %319 = inttoptr i64 %317 to double*
  %320 = load double, double* %319, align 8
  store double %320, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %321 = add i64 %283, 22
  store i64 %321, i64* %PC, align 8
  %322 = load i64, i64* %285, align 8
  store i64 %322, i64* %RCX, align 8, !tbaa !2428
  %323 = add i64 %281, -32
  %324 = add i64 %283, 25
  store i64 %324, i64* %PC, align 8
  %325 = inttoptr i64 %323 to i32*
  %326 = load i32, i32* %325, align 4
  %327 = add i32 %326, 1
  %328 = zext i32 %327 to i64
  store i64 %328, i64* %RAX, align 8, !tbaa !2428
  %329 = icmp eq i32 %326, -1
  %330 = icmp eq i32 %327, 0
  %331 = or i1 %329, %330
  %332 = zext i1 %331 to i8
  store i8 %332, i8* %15, align 1, !tbaa !2433
  %333 = and i32 %327, 255
  %334 = tail call i32 @llvm.ctpop.i32(i32 %333) #10
  %335 = trunc i32 %334 to i8
  %336 = and i8 %335, 1
  %337 = xor i8 %336, 1
  store i8 %337, i8* %22, align 1, !tbaa !2447
  %338 = xor i32 %326, %327
  %339 = lshr i32 %338, 4
  %340 = trunc i32 %339 to i8
  %341 = and i8 %340, 1
  store i8 %341, i8* %28, align 1, !tbaa !2451
  %342 = icmp eq i32 %327, 0
  %343 = zext i1 %342 to i8
  store i8 %343, i8* %31, align 1, !tbaa !2448
  %344 = lshr i32 %327, 31
  %345 = trunc i32 %344 to i8
  store i8 %345, i8* %34, align 1, !tbaa !2449
  %346 = lshr i32 %326, 31
  %347 = xor i32 %344, %346
  %348 = add nuw nsw i32 %347, %344
  %349 = icmp eq i32 %348, 2
  %350 = zext i1 %349 to i8
  store i8 %350, i8* %40, align 1, !tbaa !2450
  %351 = sext i32 %327 to i64
  store i64 %351, i64* %RDX, align 8, !tbaa !2428
  %352 = shl nsw i64 %351, 3
  %353 = add i64 %352, %322
  %354 = add i64 %283, 36
  store i64 %354, i64* %PC, align 8
  %355 = inttoptr i64 %353 to double*
  %356 = load double, double* %355, align 8
  %357 = fadd double %320, %356
  store double %357, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %358 = load i64, i64* %RBP, align 8
  %359 = add i64 %358, -64
  %360 = add i64 %283, 41
  store i64 %360, i64* %PC, align 8
  %361 = inttoptr i64 %359 to double*
  store double %357, double* %361, align 8
  %362 = load i64, i64* %RBP, align 8
  %363 = add i64 %362, -16
  %364 = load i64, i64* %PC, align 8
  %365 = add i64 %364, 4
  store i64 %365, i64* %PC, align 8
  %366 = inttoptr i64 %363 to i64*
  %367 = load i64, i64* %366, align 8
  store i64 %367, i64* %RCX, align 8, !tbaa !2428
  %368 = add i64 %362, -28
  %369 = add i64 %364, 8
  store i64 %369, i64* %PC, align 8
  %370 = inttoptr i64 %368 to i32*
  %371 = load i32, i32* %370, align 4
  %372 = sext i32 %371 to i64
  store i64 %372, i64* %RDX, align 8, !tbaa !2428
  %373 = shl nsw i64 %372, 3
  %374 = add i64 %373, %367
  %375 = add i64 %364, 13
  store i64 %375, i64* %PC, align 8
  %376 = inttoptr i64 %374 to double*
  %377 = load double, double* %376, align 8
  store double %377, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %378 = add i64 %364, 17
  store i64 %378, i64* %PC, align 8
  %379 = load i64, i64* %366, align 8
  store i64 %379, i64* %RCX, align 8, !tbaa !2428
  %380 = add i64 %362, -32
  %381 = add i64 %364, 21
  store i64 %381, i64* %PC, align 8
  %382 = inttoptr i64 %380 to i32*
  %383 = load i32, i32* %382, align 4
  %384 = sext i32 %383 to i64
  store i64 %384, i64* %RDX, align 8, !tbaa !2428
  %385 = shl nsw i64 %384, 3
  %386 = add i64 %385, %379
  %387 = add i64 %364, 26
  store i64 %387, i64* %PC, align 8
  %388 = inttoptr i64 %386 to double*
  %389 = load double, double* %388, align 8
  %390 = fsub double %377, %389
  store double %390, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %391 = add i64 %362, -72
  %392 = add i64 %364, 31
  store i64 %392, i64* %PC, align 8
  %393 = inttoptr i64 %391 to double*
  store double %390, double* %393, align 8
  %394 = load i64, i64* %RBP, align 8
  %395 = add i64 %394, -16
  %396 = load i64, i64* %PC, align 8
  %397 = add i64 %396, 4
  store i64 %397, i64* %PC, align 8
  %398 = inttoptr i64 %395 to i64*
  %399 = load i64, i64* %398, align 8
  store i64 %399, i64* %RCX, align 8, !tbaa !2428
  %400 = add i64 %394, -28
  %401 = add i64 %396, 7
  store i64 %401, i64* %PC, align 8
  %402 = inttoptr i64 %400 to i32*
  %403 = load i32, i32* %402, align 4
  %404 = add i32 %403, 1
  %405 = zext i32 %404 to i64
  store i64 %405, i64* %RAX, align 8, !tbaa !2428
  %406 = icmp eq i32 %403, -1
  %407 = icmp eq i32 %404, 0
  %408 = or i1 %406, %407
  %409 = zext i1 %408 to i8
  store i8 %409, i8* %15, align 1, !tbaa !2433
  %410 = and i32 %404, 255
  %411 = tail call i32 @llvm.ctpop.i32(i32 %410) #10
  %412 = trunc i32 %411 to i8
  %413 = and i8 %412, 1
  %414 = xor i8 %413, 1
  store i8 %414, i8* %22, align 1, !tbaa !2447
  %415 = xor i32 %403, %404
  %416 = lshr i32 %415, 4
  %417 = trunc i32 %416 to i8
  %418 = and i8 %417, 1
  store i8 %418, i8* %28, align 1, !tbaa !2451
  %419 = icmp eq i32 %404, 0
  %420 = zext i1 %419 to i8
  store i8 %420, i8* %31, align 1, !tbaa !2448
  %421 = lshr i32 %404, 31
  %422 = trunc i32 %421 to i8
  store i8 %422, i8* %34, align 1, !tbaa !2449
  %423 = lshr i32 %403, 31
  %424 = xor i32 %421, %423
  %425 = add nuw nsw i32 %424, %421
  %426 = icmp eq i32 %425, 2
  %427 = zext i1 %426 to i8
  store i8 %427, i8* %40, align 1, !tbaa !2450
  %428 = sext i32 %404 to i64
  store i64 %428, i64* %RDX, align 8, !tbaa !2428
  %429 = shl nsw i64 %428, 3
  %430 = add i64 %429, %399
  %431 = add i64 %396, 18
  store i64 %431, i64* %PC, align 8
  %432 = inttoptr i64 %430 to double*
  %433 = load double, double* %432, align 8
  store double %433, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %434 = add i64 %396, 22
  store i64 %434, i64* %PC, align 8
  %435 = load i64, i64* %398, align 8
  store i64 %435, i64* %RCX, align 8, !tbaa !2428
  %436 = add i64 %394, -32
  %437 = add i64 %396, 25
  store i64 %437, i64* %PC, align 8
  %438 = inttoptr i64 %436 to i32*
  %439 = load i32, i32* %438, align 4
  %440 = add i32 %439, 1
  %441 = zext i32 %440 to i64
  store i64 %441, i64* %RAX, align 8, !tbaa !2428
  %442 = icmp eq i32 %439, -1
  %443 = icmp eq i32 %440, 0
  %444 = or i1 %442, %443
  %445 = zext i1 %444 to i8
  store i8 %445, i8* %15, align 1, !tbaa !2433
  %446 = and i32 %440, 255
  %447 = tail call i32 @llvm.ctpop.i32(i32 %446) #10
  %448 = trunc i32 %447 to i8
  %449 = and i8 %448, 1
  %450 = xor i8 %449, 1
  store i8 %450, i8* %22, align 1, !tbaa !2447
  %451 = xor i32 %439, %440
  %452 = lshr i32 %451, 4
  %453 = trunc i32 %452 to i8
  %454 = and i8 %453, 1
  store i8 %454, i8* %28, align 1, !tbaa !2451
  %455 = icmp eq i32 %440, 0
  %456 = zext i1 %455 to i8
  store i8 %456, i8* %31, align 1, !tbaa !2448
  %457 = lshr i32 %440, 31
  %458 = trunc i32 %457 to i8
  store i8 %458, i8* %34, align 1, !tbaa !2449
  %459 = lshr i32 %439, 31
  %460 = xor i32 %457, %459
  %461 = add nuw nsw i32 %460, %457
  %462 = icmp eq i32 %461, 2
  %463 = zext i1 %462 to i8
  store i8 %463, i8* %40, align 1, !tbaa !2450
  %464 = sext i32 %440 to i64
  store i64 %464, i64* %RDX, align 8, !tbaa !2428
  %465 = shl nsw i64 %464, 3
  %466 = add i64 %465, %435
  %467 = add i64 %396, 36
  store i64 %467, i64* %PC, align 8
  %468 = inttoptr i64 %466 to double*
  %469 = load double, double* %468, align 8
  %470 = fsub double %433, %469
  store double %470, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %471 = load i64, i64* %RBP, align 8
  %472 = add i64 %471, -80
  %473 = add i64 %396, 41
  store i64 %473, i64* %PC, align 8
  %474 = inttoptr i64 %472 to double*
  store double %470, double* %474, align 8
  %475 = load i64, i64* %RBP, align 8
  %476 = add i64 %475, -16
  %477 = load i64, i64* %PC, align 8
  %478 = add i64 %477, 4
  store i64 %478, i64* %PC, align 8
  %479 = inttoptr i64 %476 to i64*
  %480 = load i64, i64* %479, align 8
  store i64 %480, i64* %RCX, align 8, !tbaa !2428
  %481 = add i64 %475, -36
  %482 = add i64 %477, 8
  store i64 %482, i64* %PC, align 8
  %483 = inttoptr i64 %481 to i32*
  %484 = load i32, i32* %483, align 4
  %485 = sext i32 %484 to i64
  store i64 %485, i64* %RDX, align 8, !tbaa !2428
  %486 = shl nsw i64 %485, 3
  %487 = add i64 %486, %480
  %488 = add i64 %477, 13
  store i64 %488, i64* %PC, align 8
  %489 = inttoptr i64 %487 to double*
  %490 = load double, double* %489, align 8
  store double %490, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %491 = add i64 %477, 17
  store i64 %491, i64* %PC, align 8
  %492 = load i64, i64* %479, align 8
  store i64 %492, i64* %RCX, align 8, !tbaa !2428
  %493 = add i64 %475, -40
  %494 = add i64 %477, 21
  store i64 %494, i64* %PC, align 8
  %495 = inttoptr i64 %493 to i32*
  %496 = load i32, i32* %495, align 4
  %497 = sext i32 %496 to i64
  store i64 %497, i64* %RDX, align 8, !tbaa !2428
  %498 = shl nsw i64 %497, 3
  %499 = add i64 %498, %492
  %500 = add i64 %477, 26
  store i64 %500, i64* %PC, align 8
  %501 = inttoptr i64 %499 to double*
  %502 = load double, double* %501, align 8
  %503 = fadd double %490, %502
  store double %503, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %504 = add i64 %475, -88
  %505 = add i64 %477, 31
  store i64 %505, i64* %PC, align 8
  %506 = inttoptr i64 %504 to double*
  store double %503, double* %506, align 8
  %507 = load i64, i64* %RBP, align 8
  %508 = add i64 %507, -16
  %509 = load i64, i64* %PC, align 8
  %510 = add i64 %509, 4
  store i64 %510, i64* %PC, align 8
  %511 = inttoptr i64 %508 to i64*
  %512 = load i64, i64* %511, align 8
  store i64 %512, i64* %RCX, align 8, !tbaa !2428
  %513 = add i64 %507, -36
  %514 = add i64 %509, 7
  store i64 %514, i64* %PC, align 8
  %515 = inttoptr i64 %513 to i32*
  %516 = load i32, i32* %515, align 4
  %517 = add i32 %516, 1
  %518 = zext i32 %517 to i64
  store i64 %518, i64* %RAX, align 8, !tbaa !2428
  %519 = icmp eq i32 %516, -1
  %520 = icmp eq i32 %517, 0
  %521 = or i1 %519, %520
  %522 = zext i1 %521 to i8
  store i8 %522, i8* %15, align 1, !tbaa !2433
  %523 = and i32 %517, 255
  %524 = tail call i32 @llvm.ctpop.i32(i32 %523) #10
  %525 = trunc i32 %524 to i8
  %526 = and i8 %525, 1
  %527 = xor i8 %526, 1
  store i8 %527, i8* %22, align 1, !tbaa !2447
  %528 = xor i32 %516, %517
  %529 = lshr i32 %528, 4
  %530 = trunc i32 %529 to i8
  %531 = and i8 %530, 1
  store i8 %531, i8* %28, align 1, !tbaa !2451
  %532 = icmp eq i32 %517, 0
  %533 = zext i1 %532 to i8
  store i8 %533, i8* %31, align 1, !tbaa !2448
  %534 = lshr i32 %517, 31
  %535 = trunc i32 %534 to i8
  store i8 %535, i8* %34, align 1, !tbaa !2449
  %536 = lshr i32 %516, 31
  %537 = xor i32 %534, %536
  %538 = add nuw nsw i32 %537, %534
  %539 = icmp eq i32 %538, 2
  %540 = zext i1 %539 to i8
  store i8 %540, i8* %40, align 1, !tbaa !2450
  %541 = sext i32 %517 to i64
  store i64 %541, i64* %RDX, align 8, !tbaa !2428
  %542 = shl nsw i64 %541, 3
  %543 = add i64 %542, %512
  %544 = add i64 %509, 18
  store i64 %544, i64* %PC, align 8
  %545 = inttoptr i64 %543 to double*
  %546 = load double, double* %545, align 8
  store double %546, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %547 = add i64 %509, 22
  store i64 %547, i64* %PC, align 8
  %548 = load i64, i64* %511, align 8
  store i64 %548, i64* %RCX, align 8, !tbaa !2428
  %549 = add i64 %507, -40
  %550 = add i64 %509, 25
  store i64 %550, i64* %PC, align 8
  %551 = inttoptr i64 %549 to i32*
  %552 = load i32, i32* %551, align 4
  %553 = add i32 %552, 1
  %554 = zext i32 %553 to i64
  store i64 %554, i64* %RAX, align 8, !tbaa !2428
  %555 = icmp eq i32 %552, -1
  %556 = icmp eq i32 %553, 0
  %557 = or i1 %555, %556
  %558 = zext i1 %557 to i8
  store i8 %558, i8* %15, align 1, !tbaa !2433
  %559 = and i32 %553, 255
  %560 = tail call i32 @llvm.ctpop.i32(i32 %559) #10
  %561 = trunc i32 %560 to i8
  %562 = and i8 %561, 1
  %563 = xor i8 %562, 1
  store i8 %563, i8* %22, align 1, !tbaa !2447
  %564 = xor i32 %552, %553
  %565 = lshr i32 %564, 4
  %566 = trunc i32 %565 to i8
  %567 = and i8 %566, 1
  store i8 %567, i8* %28, align 1, !tbaa !2451
  %568 = icmp eq i32 %553, 0
  %569 = zext i1 %568 to i8
  store i8 %569, i8* %31, align 1, !tbaa !2448
  %570 = lshr i32 %553, 31
  %571 = trunc i32 %570 to i8
  store i8 %571, i8* %34, align 1, !tbaa !2449
  %572 = lshr i32 %552, 31
  %573 = xor i32 %570, %572
  %574 = add nuw nsw i32 %573, %570
  %575 = icmp eq i32 %574, 2
  %576 = zext i1 %575 to i8
  store i8 %576, i8* %40, align 1, !tbaa !2450
  %577 = sext i32 %553 to i64
  store i64 %577, i64* %RDX, align 8, !tbaa !2428
  %578 = shl nsw i64 %577, 3
  %579 = add i64 %578, %548
  %580 = add i64 %509, 36
  store i64 %580, i64* %PC, align 8
  %581 = inttoptr i64 %579 to double*
  %582 = load double, double* %581, align 8
  %583 = fadd double %546, %582
  store double %583, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %584 = load i64, i64* %RBP, align 8
  %585 = add i64 %584, -96
  %586 = add i64 %509, 41
  store i64 %586, i64* %PC, align 8
  %587 = inttoptr i64 %585 to double*
  store double %583, double* %587, align 8
  %588 = load i64, i64* %RBP, align 8
  %589 = add i64 %588, -16
  %590 = load i64, i64* %PC, align 8
  %591 = add i64 %590, 4
  store i64 %591, i64* %PC, align 8
  %592 = inttoptr i64 %589 to i64*
  %593 = load i64, i64* %592, align 8
  store i64 %593, i64* %RCX, align 8, !tbaa !2428
  %594 = add i64 %588, -36
  %595 = add i64 %590, 8
  store i64 %595, i64* %PC, align 8
  %596 = inttoptr i64 %594 to i32*
  %597 = load i32, i32* %596, align 4
  %598 = sext i32 %597 to i64
  store i64 %598, i64* %RDX, align 8, !tbaa !2428
  %599 = shl nsw i64 %598, 3
  %600 = add i64 %599, %593
  %601 = add i64 %590, 13
  store i64 %601, i64* %PC, align 8
  %602 = inttoptr i64 %600 to double*
  %603 = load double, double* %602, align 8
  store double %603, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %604 = add i64 %590, 17
  store i64 %604, i64* %PC, align 8
  %605 = load i64, i64* %592, align 8
  store i64 %605, i64* %RCX, align 8, !tbaa !2428
  %606 = add i64 %588, -40
  %607 = add i64 %590, 21
  store i64 %607, i64* %PC, align 8
  %608 = inttoptr i64 %606 to i32*
  %609 = load i32, i32* %608, align 4
  %610 = sext i32 %609 to i64
  store i64 %610, i64* %RDX, align 8, !tbaa !2428
  %611 = shl nsw i64 %610, 3
  %612 = add i64 %611, %605
  %613 = add i64 %590, 26
  store i64 %613, i64* %PC, align 8
  %614 = inttoptr i64 %612 to double*
  %615 = load double, double* %614, align 8
  %616 = fsub double %603, %615
  store double %616, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %617 = add i64 %588, -104
  %618 = add i64 %590, 31
  store i64 %618, i64* %PC, align 8
  %619 = inttoptr i64 %617 to double*
  store double %616, double* %619, align 8
  %620 = load i64, i64* %RBP, align 8
  %621 = add i64 %620, -16
  %622 = load i64, i64* %PC, align 8
  %623 = add i64 %622, 4
  store i64 %623, i64* %PC, align 8
  %624 = inttoptr i64 %621 to i64*
  %625 = load i64, i64* %624, align 8
  store i64 %625, i64* %RCX, align 8, !tbaa !2428
  %626 = add i64 %620, -36
  %627 = add i64 %622, 7
  store i64 %627, i64* %PC, align 8
  %628 = inttoptr i64 %626 to i32*
  %629 = load i32, i32* %628, align 4
  %630 = add i32 %629, 1
  %631 = zext i32 %630 to i64
  store i64 %631, i64* %RAX, align 8, !tbaa !2428
  %632 = icmp eq i32 %629, -1
  %633 = icmp eq i32 %630, 0
  %634 = or i1 %632, %633
  %635 = zext i1 %634 to i8
  store i8 %635, i8* %15, align 1, !tbaa !2433
  %636 = and i32 %630, 255
  %637 = tail call i32 @llvm.ctpop.i32(i32 %636) #10
  %638 = trunc i32 %637 to i8
  %639 = and i8 %638, 1
  %640 = xor i8 %639, 1
  store i8 %640, i8* %22, align 1, !tbaa !2447
  %641 = xor i32 %629, %630
  %642 = lshr i32 %641, 4
  %643 = trunc i32 %642 to i8
  %644 = and i8 %643, 1
  store i8 %644, i8* %28, align 1, !tbaa !2451
  %645 = icmp eq i32 %630, 0
  %646 = zext i1 %645 to i8
  store i8 %646, i8* %31, align 1, !tbaa !2448
  %647 = lshr i32 %630, 31
  %648 = trunc i32 %647 to i8
  store i8 %648, i8* %34, align 1, !tbaa !2449
  %649 = lshr i32 %629, 31
  %650 = xor i32 %647, %649
  %651 = add nuw nsw i32 %650, %647
  %652 = icmp eq i32 %651, 2
  %653 = zext i1 %652 to i8
  store i8 %653, i8* %40, align 1, !tbaa !2450
  %654 = sext i32 %630 to i64
  store i64 %654, i64* %RDX, align 8, !tbaa !2428
  %655 = shl nsw i64 %654, 3
  %656 = add i64 %655, %625
  %657 = add i64 %622, 18
  store i64 %657, i64* %PC, align 8
  %658 = inttoptr i64 %656 to double*
  %659 = load double, double* %658, align 8
  store double %659, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %660 = add i64 %622, 22
  store i64 %660, i64* %PC, align 8
  %661 = load i64, i64* %624, align 8
  store i64 %661, i64* %RCX, align 8, !tbaa !2428
  %662 = add i64 %620, -40
  %663 = add i64 %622, 25
  store i64 %663, i64* %PC, align 8
  %664 = inttoptr i64 %662 to i32*
  %665 = load i32, i32* %664, align 4
  %666 = add i32 %665, 1
  %667 = zext i32 %666 to i64
  store i64 %667, i64* %RAX, align 8, !tbaa !2428
  %668 = icmp eq i32 %665, -1
  %669 = icmp eq i32 %666, 0
  %670 = or i1 %668, %669
  %671 = zext i1 %670 to i8
  store i8 %671, i8* %15, align 1, !tbaa !2433
  %672 = and i32 %666, 255
  %673 = tail call i32 @llvm.ctpop.i32(i32 %672) #10
  %674 = trunc i32 %673 to i8
  %675 = and i8 %674, 1
  %676 = xor i8 %675, 1
  store i8 %676, i8* %22, align 1, !tbaa !2447
  %677 = xor i32 %665, %666
  %678 = lshr i32 %677, 4
  %679 = trunc i32 %678 to i8
  %680 = and i8 %679, 1
  store i8 %680, i8* %28, align 1, !tbaa !2451
  %681 = icmp eq i32 %666, 0
  %682 = zext i1 %681 to i8
  store i8 %682, i8* %31, align 1, !tbaa !2448
  %683 = lshr i32 %666, 31
  %684 = trunc i32 %683 to i8
  store i8 %684, i8* %34, align 1, !tbaa !2449
  %685 = lshr i32 %665, 31
  %686 = xor i32 %683, %685
  %687 = add nuw nsw i32 %686, %683
  %688 = icmp eq i32 %687, 2
  %689 = zext i1 %688 to i8
  store i8 %689, i8* %40, align 1, !tbaa !2450
  %690 = sext i32 %666 to i64
  store i64 %690, i64* %RDX, align 8, !tbaa !2428
  %691 = shl nsw i64 %690, 3
  %692 = add i64 %691, %661
  %693 = add i64 %622, 36
  store i64 %693, i64* %PC, align 8
  %694 = inttoptr i64 %692 to double*
  %695 = load double, double* %694, align 8
  %696 = fsub double %659, %695
  store double %696, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %697 = load i64, i64* %RBP, align 8
  %698 = add i64 %697, -112
  %699 = add i64 %622, 41
  store i64 %699, i64* %PC, align 8
  %700 = inttoptr i64 %698 to double*
  store double %696, double* %700, align 8
  %701 = load i64, i64* %RBP, align 8
  %702 = add i64 %701, -56
  %703 = load i64, i64* %PC, align 8
  %704 = add i64 %703, 5
  store i64 %704, i64* %PC, align 8
  %705 = inttoptr i64 %702 to double*
  %706 = load double, double* %705, align 8
  store double %706, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %707 = add i64 %701, -88
  %708 = add i64 %703, 10
  store i64 %708, i64* %PC, align 8
  %709 = inttoptr i64 %707 to double*
  %710 = load double, double* %709, align 8
  %711 = fadd double %706, %710
  store double %711, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %712 = add i64 %701, -16
  %713 = add i64 %703, 14
  store i64 %713, i64* %PC, align 8
  %714 = inttoptr i64 %712 to i64*
  %715 = load i64, i64* %714, align 8
  store i64 %715, i64* %RCX, align 8, !tbaa !2428
  %716 = add i64 %701, -28
  %717 = add i64 %703, 18
  store i64 %717, i64* %PC, align 8
  %718 = inttoptr i64 %716 to i32*
  %719 = load i32, i32* %718, align 4
  %720 = sext i32 %719 to i64
  store i64 %720, i64* %RDX, align 8, !tbaa !2428
  %721 = shl nsw i64 %720, 3
  %722 = add i64 %721, %715
  %723 = add i64 %703, 23
  store i64 %723, i64* %PC, align 8
  %724 = inttoptr i64 %722 to double*
  store double %711, double* %724, align 8
  %725 = load i64, i64* %RBP, align 8
  %726 = add i64 %725, -64
  %727 = load i64, i64* %PC, align 8
  %728 = add i64 %727, 5
  store i64 %728, i64* %PC, align 8
  %729 = inttoptr i64 %726 to double*
  %730 = load double, double* %729, align 8
  store double %730, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %731 = add i64 %725, -96
  %732 = add i64 %727, 10
  store i64 %732, i64* %PC, align 8
  %733 = inttoptr i64 %731 to double*
  %734 = load double, double* %733, align 8
  %735 = fadd double %730, %734
  store double %735, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %736 = add i64 %725, -16
  %737 = add i64 %727, 14
  store i64 %737, i64* %PC, align 8
  %738 = inttoptr i64 %736 to i64*
  %739 = load i64, i64* %738, align 8
  store i64 %739, i64* %RCX, align 8, !tbaa !2428
  %740 = add i64 %725, -28
  %741 = add i64 %727, 17
  store i64 %741, i64* %PC, align 8
  %742 = inttoptr i64 %740 to i32*
  %743 = load i32, i32* %742, align 4
  %744 = add i32 %743, 1
  %745 = zext i32 %744 to i64
  store i64 %745, i64* %RAX, align 8, !tbaa !2428
  %746 = icmp eq i32 %743, -1
  %747 = icmp eq i32 %744, 0
  %748 = or i1 %746, %747
  %749 = zext i1 %748 to i8
  store i8 %749, i8* %15, align 1, !tbaa !2433
  %750 = and i32 %744, 255
  %751 = tail call i32 @llvm.ctpop.i32(i32 %750) #10
  %752 = trunc i32 %751 to i8
  %753 = and i8 %752, 1
  %754 = xor i8 %753, 1
  store i8 %754, i8* %22, align 1, !tbaa !2447
  %755 = xor i32 %743, %744
  %756 = lshr i32 %755, 4
  %757 = trunc i32 %756 to i8
  %758 = and i8 %757, 1
  store i8 %758, i8* %28, align 1, !tbaa !2451
  %759 = icmp eq i32 %744, 0
  %760 = zext i1 %759 to i8
  store i8 %760, i8* %31, align 1, !tbaa !2448
  %761 = lshr i32 %744, 31
  %762 = trunc i32 %761 to i8
  store i8 %762, i8* %34, align 1, !tbaa !2449
  %763 = lshr i32 %743, 31
  %764 = xor i32 %761, %763
  %765 = add nuw nsw i32 %764, %761
  %766 = icmp eq i32 %765, 2
  %767 = zext i1 %766 to i8
  store i8 %767, i8* %40, align 1, !tbaa !2450
  %768 = sext i32 %744 to i64
  store i64 %768, i64* %RDX, align 8, !tbaa !2428
  %769 = shl nsw i64 %768, 3
  %770 = add i64 %769, %739
  %771 = add i64 %727, 28
  store i64 %771, i64* %PC, align 8
  %772 = inttoptr i64 %770 to double*
  store double %735, double* %772, align 8
  %773 = load i64, i64* %RBP, align 8
  %774 = add i64 %773, -56
  %775 = load i64, i64* %PC, align 8
  %776 = add i64 %775, 5
  store i64 %776, i64* %PC, align 8
  %777 = inttoptr i64 %774 to double*
  %778 = load double, double* %777, align 8
  store double %778, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %779 = add i64 %773, -88
  %780 = add i64 %775, 10
  store i64 %780, i64* %PC, align 8
  %781 = inttoptr i64 %779 to double*
  %782 = load double, double* %781, align 8
  %783 = fsub double %778, %782
  store double %783, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %784 = add i64 %773, -16
  %785 = add i64 %775, 14
  store i64 %785, i64* %PC, align 8
  %786 = inttoptr i64 %784 to i64*
  %787 = load i64, i64* %786, align 8
  store i64 %787, i64* %RCX, align 8, !tbaa !2428
  %788 = add i64 %773, -36
  %789 = add i64 %775, 18
  store i64 %789, i64* %PC, align 8
  %790 = inttoptr i64 %788 to i32*
  %791 = load i32, i32* %790, align 4
  %792 = sext i32 %791 to i64
  store i64 %792, i64* %RDX, align 8, !tbaa !2428
  %793 = shl nsw i64 %792, 3
  %794 = add i64 %793, %787
  %795 = add i64 %775, 23
  store i64 %795, i64* %PC, align 8
  %796 = inttoptr i64 %794 to double*
  store double %783, double* %796, align 8
  %797 = load i64, i64* %RBP, align 8
  %798 = add i64 %797, -64
  %799 = load i64, i64* %PC, align 8
  %800 = add i64 %799, 5
  store i64 %800, i64* %PC, align 8
  %801 = inttoptr i64 %798 to double*
  %802 = load double, double* %801, align 8
  store double %802, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %803 = add i64 %797, -96
  %804 = add i64 %799, 10
  store i64 %804, i64* %PC, align 8
  %805 = inttoptr i64 %803 to double*
  %806 = load double, double* %805, align 8
  %807 = fsub double %802, %806
  store double %807, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %808 = add i64 %797, -16
  %809 = add i64 %799, 14
  store i64 %809, i64* %PC, align 8
  %810 = inttoptr i64 %808 to i64*
  %811 = load i64, i64* %810, align 8
  store i64 %811, i64* %RCX, align 8, !tbaa !2428
  %812 = add i64 %797, -36
  %813 = add i64 %799, 17
  store i64 %813, i64* %PC, align 8
  %814 = inttoptr i64 %812 to i32*
  %815 = load i32, i32* %814, align 4
  %816 = add i32 %815, 1
  %817 = zext i32 %816 to i64
  store i64 %817, i64* %RAX, align 8, !tbaa !2428
  %818 = icmp eq i32 %815, -1
  %819 = icmp eq i32 %816, 0
  %820 = or i1 %818, %819
  %821 = zext i1 %820 to i8
  store i8 %821, i8* %15, align 1, !tbaa !2433
  %822 = and i32 %816, 255
  %823 = tail call i32 @llvm.ctpop.i32(i32 %822) #10
  %824 = trunc i32 %823 to i8
  %825 = and i8 %824, 1
  %826 = xor i8 %825, 1
  store i8 %826, i8* %22, align 1, !tbaa !2447
  %827 = xor i32 %815, %816
  %828 = lshr i32 %827, 4
  %829 = trunc i32 %828 to i8
  %830 = and i8 %829, 1
  store i8 %830, i8* %28, align 1, !tbaa !2451
  %831 = icmp eq i32 %816, 0
  %832 = zext i1 %831 to i8
  store i8 %832, i8* %31, align 1, !tbaa !2448
  %833 = lshr i32 %816, 31
  %834 = trunc i32 %833 to i8
  store i8 %834, i8* %34, align 1, !tbaa !2449
  %835 = lshr i32 %815, 31
  %836 = xor i32 %833, %835
  %837 = add nuw nsw i32 %836, %833
  %838 = icmp eq i32 %837, 2
  %839 = zext i1 %838 to i8
  store i8 %839, i8* %40, align 1, !tbaa !2450
  %840 = sext i32 %816 to i64
  store i64 %840, i64* %RDX, align 8, !tbaa !2428
  %841 = shl nsw i64 %840, 3
  %842 = add i64 %841, %811
  %843 = add i64 %799, 28
  store i64 %843, i64* %PC, align 8
  %844 = inttoptr i64 %842 to double*
  store double %807, double* %844, align 8
  %845 = load i64, i64* %RBP, align 8
  %846 = add i64 %845, -72
  %847 = load i64, i64* %PC, align 8
  %848 = add i64 %847, 5
  store i64 %848, i64* %PC, align 8
  %849 = inttoptr i64 %846 to double*
  %850 = load double, double* %849, align 8
  store double %850, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %851 = add i64 %845, -112
  %852 = add i64 %847, 10
  store i64 %852, i64* %PC, align 8
  %853 = inttoptr i64 %851 to double*
  %854 = load double, double* %853, align 8
  %855 = fsub double %850, %854
  store double %855, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %856 = add i64 %845, -16
  %857 = add i64 %847, 14
  store i64 %857, i64* %PC, align 8
  %858 = inttoptr i64 %856 to i64*
  %859 = load i64, i64* %858, align 8
  store i64 %859, i64* %RCX, align 8, !tbaa !2428
  %860 = add i64 %845, -32
  %861 = add i64 %847, 18
  store i64 %861, i64* %PC, align 8
  %862 = inttoptr i64 %860 to i32*
  %863 = load i32, i32* %862, align 4
  %864 = sext i32 %863 to i64
  store i64 %864, i64* %RDX, align 8, !tbaa !2428
  %865 = shl nsw i64 %864, 3
  %866 = add i64 %865, %859
  %867 = add i64 %847, 23
  store i64 %867, i64* %PC, align 8
  %868 = inttoptr i64 %866 to double*
  store double %855, double* %868, align 8
  %869 = load i64, i64* %RBP, align 8
  %870 = add i64 %869, -80
  %871 = load i64, i64* %PC, align 8
  %872 = add i64 %871, 5
  store i64 %872, i64* %PC, align 8
  %873 = inttoptr i64 %870 to double*
  %874 = load double, double* %873, align 8
  store double %874, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %875 = add i64 %869, -104
  %876 = add i64 %871, 10
  store i64 %876, i64* %PC, align 8
  %877 = inttoptr i64 %875 to double*
  %878 = load double, double* %877, align 8
  %879 = fadd double %874, %878
  store double %879, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %880 = add i64 %869, -16
  %881 = add i64 %871, 14
  store i64 %881, i64* %PC, align 8
  %882 = inttoptr i64 %880 to i64*
  %883 = load i64, i64* %882, align 8
  store i64 %883, i64* %RCX, align 8, !tbaa !2428
  %884 = add i64 %869, -32
  %885 = add i64 %871, 17
  store i64 %885, i64* %PC, align 8
  %886 = inttoptr i64 %884 to i32*
  %887 = load i32, i32* %886, align 4
  %888 = add i32 %887, 1
  %889 = zext i32 %888 to i64
  store i64 %889, i64* %RAX, align 8, !tbaa !2428
  %890 = icmp eq i32 %887, -1
  %891 = icmp eq i32 %888, 0
  %892 = or i1 %890, %891
  %893 = zext i1 %892 to i8
  store i8 %893, i8* %15, align 1, !tbaa !2433
  %894 = and i32 %888, 255
  %895 = tail call i32 @llvm.ctpop.i32(i32 %894) #10
  %896 = trunc i32 %895 to i8
  %897 = and i8 %896, 1
  %898 = xor i8 %897, 1
  store i8 %898, i8* %22, align 1, !tbaa !2447
  %899 = xor i32 %887, %888
  %900 = lshr i32 %899, 4
  %901 = trunc i32 %900 to i8
  %902 = and i8 %901, 1
  store i8 %902, i8* %28, align 1, !tbaa !2451
  %903 = icmp eq i32 %888, 0
  %904 = zext i1 %903 to i8
  store i8 %904, i8* %31, align 1, !tbaa !2448
  %905 = lshr i32 %888, 31
  %906 = trunc i32 %905 to i8
  store i8 %906, i8* %34, align 1, !tbaa !2449
  %907 = lshr i32 %887, 31
  %908 = xor i32 %905, %907
  %909 = add nuw nsw i32 %908, %905
  %910 = icmp eq i32 %909, 2
  %911 = zext i1 %910 to i8
  store i8 %911, i8* %40, align 1, !tbaa !2450
  %912 = sext i32 %888 to i64
  store i64 %912, i64* %RDX, align 8, !tbaa !2428
  %913 = shl nsw i64 %912, 3
  %914 = add i64 %913, %883
  %915 = add i64 %871, 28
  store i64 %915, i64* %PC, align 8
  %916 = inttoptr i64 %914 to double*
  store double %879, double* %916, align 8
  %917 = load i64, i64* %RBP, align 8
  %918 = add i64 %917, -72
  %919 = load i64, i64* %PC, align 8
  %920 = add i64 %919, 5
  store i64 %920, i64* %PC, align 8
  %921 = inttoptr i64 %918 to double*
  %922 = load double, double* %921, align 8
  store double %922, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %923 = add i64 %917, -112
  %924 = add i64 %919, 10
  store i64 %924, i64* %PC, align 8
  %925 = inttoptr i64 %923 to double*
  %926 = load double, double* %925, align 8
  %927 = fadd double %922, %926
  store double %927, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %928 = add i64 %917, -16
  %929 = add i64 %919, 14
  store i64 %929, i64* %PC, align 8
  %930 = inttoptr i64 %928 to i64*
  %931 = load i64, i64* %930, align 8
  store i64 %931, i64* %RCX, align 8, !tbaa !2428
  %932 = add i64 %917, -40
  %933 = add i64 %919, 18
  store i64 %933, i64* %PC, align 8
  %934 = inttoptr i64 %932 to i32*
  %935 = load i32, i32* %934, align 4
  %936 = sext i32 %935 to i64
  store i64 %936, i64* %RDX, align 8, !tbaa !2428
  %937 = shl nsw i64 %936, 3
  %938 = add i64 %937, %931
  %939 = add i64 %919, 23
  store i64 %939, i64* %PC, align 8
  %940 = inttoptr i64 %938 to double*
  store double %927, double* %940, align 8
  %941 = load i64, i64* %RBP, align 8
  %942 = add i64 %941, -80
  %943 = load i64, i64* %PC, align 8
  %944 = add i64 %943, 5
  store i64 %944, i64* %PC, align 8
  %945 = inttoptr i64 %942 to double*
  %946 = load double, double* %945, align 8
  store double %946, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %947 = add i64 %941, -104
  %948 = add i64 %943, 10
  store i64 %948, i64* %PC, align 8
  %949 = inttoptr i64 %947 to double*
  %950 = load double, double* %949, align 8
  %951 = fsub double %946, %950
  store double %951, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %952 = add i64 %941, -16
  %953 = add i64 %943, 14
  store i64 %953, i64* %PC, align 8
  %954 = inttoptr i64 %952 to i64*
  %955 = load i64, i64* %954, align 8
  store i64 %955, i64* %RCX, align 8, !tbaa !2428
  %956 = add i64 %941, -40
  %957 = add i64 %943, 17
  store i64 %957, i64* %PC, align 8
  %958 = inttoptr i64 %956 to i32*
  %959 = load i32, i32* %958, align 4
  %960 = add i32 %959, 1
  %961 = zext i32 %960 to i64
  store i64 %961, i64* %RAX, align 8, !tbaa !2428
  %962 = icmp eq i32 %959, -1
  %963 = icmp eq i32 %960, 0
  %964 = or i1 %962, %963
  %965 = zext i1 %964 to i8
  store i8 %965, i8* %15, align 1, !tbaa !2433
  %966 = and i32 %960, 255
  %967 = tail call i32 @llvm.ctpop.i32(i32 %966) #10
  %968 = trunc i32 %967 to i8
  %969 = and i8 %968, 1
  %970 = xor i8 %969, 1
  store i8 %970, i8* %22, align 1, !tbaa !2447
  %971 = xor i32 %959, %960
  %972 = lshr i32 %971, 4
  %973 = trunc i32 %972 to i8
  %974 = and i8 %973, 1
  store i8 %974, i8* %28, align 1, !tbaa !2451
  %975 = icmp eq i32 %960, 0
  %976 = zext i1 %975 to i8
  store i8 %976, i8* %31, align 1, !tbaa !2448
  %977 = lshr i32 %960, 31
  %978 = trunc i32 %977 to i8
  store i8 %978, i8* %34, align 1, !tbaa !2449
  %979 = lshr i32 %959, 31
  %980 = xor i32 %977, %979
  %981 = add nuw nsw i32 %980, %977
  %982 = icmp eq i32 %981, 2
  %983 = zext i1 %982 to i8
  store i8 %983, i8* %40, align 1, !tbaa !2450
  %984 = sext i32 %960 to i64
  store i64 %984, i64* %RDX, align 8, !tbaa !2428
  %985 = shl nsw i64 %984, 3
  %986 = add i64 %985, %955
  %987 = add i64 %943, 28
  store i64 %987, i64* %PC, align 8
  %988 = inttoptr i64 %986 to double*
  store double %951, double* %988, align 8
  %989 = load i64, i64* %RBP, align 8
  %990 = add i64 %989, -28
  %991 = load i64, i64* %PC, align 8
  %992 = add i64 %991, 3
  store i64 %992, i64* %PC, align 8
  %993 = inttoptr i64 %990 to i32*
  %994 = load i32, i32* %993, align 4
  %995 = add i32 %994, 2
  %996 = zext i32 %995 to i64
  store i64 %996, i64* %RAX, align 8, !tbaa !2428
  %997 = icmp ugt i32 %994, -3
  %998 = zext i1 %997 to i8
  store i8 %998, i8* %15, align 1, !tbaa !2433
  %999 = and i32 %995, 255
  %1000 = tail call i32 @llvm.ctpop.i32(i32 %999) #10
  %1001 = trunc i32 %1000 to i8
  %1002 = and i8 %1001, 1
  %1003 = xor i8 %1002, 1
  store i8 %1003, i8* %22, align 1, !tbaa !2447
  %1004 = xor i32 %994, %995
  %1005 = lshr i32 %1004, 4
  %1006 = trunc i32 %1005 to i8
  %1007 = and i8 %1006, 1
  store i8 %1007, i8* %28, align 1, !tbaa !2451
  %1008 = icmp eq i32 %995, 0
  %1009 = zext i1 %1008 to i8
  store i8 %1009, i8* %31, align 1, !tbaa !2448
  %1010 = lshr i32 %995, 31
  %1011 = trunc i32 %1010 to i8
  store i8 %1011, i8* %34, align 1, !tbaa !2449
  %1012 = lshr i32 %994, 31
  %1013 = xor i32 %1010, %1012
  %1014 = add nuw nsw i32 %1013, %1010
  %1015 = icmp eq i32 %1014, 2
  %1016 = zext i1 %1015 to i8
  store i8 %1016, i8* %40, align 1, !tbaa !2450
  %1017 = add i64 %991, 9
  store i64 %1017, i64* %PC, align 8
  store i32 %995, i32* %993, align 4
  %1018 = load i64, i64* %PC, align 8
  %1019 = add i64 %1018, -540
  store i64 %1019, i64* %92, align 8, !tbaa !2428
  br label %block_4018c6

block_4018b0:                                     ; preds = %block_4018ab, %block_401840
  %1020 = phi i64 [ %93, %block_401840 ], [ %1127, %block_4018ab ]
  %1021 = phi i64 [ %62, %block_401840 ], [ %1077, %block_4018ab ]
  %MEMORY.1 = phi %struct.Memory* [ %2, %block_401840 ], [ %MEMORY.2, %block_4018ab ]
  %1022 = add i64 %1021, -44
  %1023 = add i64 %1020, 3
  store i64 %1023, i64* %PC, align 8
  %1024 = inttoptr i64 %1022 to i32*
  %1025 = load i32, i32* %1024, align 4
  %1026 = shl i32 %1025, 2
  %1027 = zext i32 %1026 to i64
  store i64 %1027, i64* %RAX, align 8, !tbaa !2428
  %1028 = lshr i32 %1025, 30
  %1029 = trunc i32 %1028 to i8
  %1030 = and i8 %1029, 1
  store i8 %1030, i8* %15, align 1, !tbaa !2432
  %1031 = and i32 %1026, 252
  %1032 = tail call i32 @llvm.ctpop.i32(i32 %1031) #10
  %1033 = trunc i32 %1032 to i8
  %1034 = and i8 %1033, 1
  %1035 = xor i8 %1034, 1
  store i8 %1035, i8* %22, align 1, !tbaa !2432
  store i8 0, i8* %28, align 1, !tbaa !2432
  %1036 = icmp eq i32 %1026, 0
  %1037 = zext i1 %1036 to i8
  store i8 %1037, i8* %31, align 1, !tbaa !2432
  %1038 = lshr i32 %1025, 29
  %1039 = and i32 %1038, 1
  %1040 = trunc i32 %1039 to i8
  store i8 %1040, i8* %34, align 1, !tbaa !2432
  store i8 0, i8* %40, align 1, !tbaa !2432
  %1041 = add i64 %1021, -4
  %1042 = add i64 %1020, 9
  store i64 %1042, i64* %PC, align 8
  %1043 = inttoptr i64 %1041 to i32*
  %1044 = load i32, i32* %1043, align 4
  %1045 = sub i32 %1026, %1044
  %1046 = icmp ult i32 %1026, %1044
  %1047 = zext i1 %1046 to i8
  store i8 %1047, i8* %15, align 1, !tbaa !2433
  %1048 = and i32 %1045, 255
  %1049 = tail call i32 @llvm.ctpop.i32(i32 %1048) #10
  %1050 = trunc i32 %1049 to i8
  %1051 = and i8 %1050, 1
  %1052 = xor i8 %1051, 1
  store i8 %1052, i8* %22, align 1, !tbaa !2447
  %1053 = xor i32 %1044, %1026
  %1054 = xor i32 %1053, %1045
  %1055 = lshr i32 %1054, 4
  %1056 = trunc i32 %1055 to i8
  %1057 = and i8 %1056, 1
  store i8 %1057, i8* %28, align 1, !tbaa !2451
  %1058 = icmp eq i32 %1045, 0
  %1059 = zext i1 %1058 to i8
  store i8 %1059, i8* %31, align 1, !tbaa !2448
  %1060 = lshr i32 %1045, 31
  %1061 = trunc i32 %1060 to i8
  store i8 %1061, i8* %34, align 1, !tbaa !2449
  %1062 = lshr i32 %1044, 31
  %1063 = xor i32 %1062, %1039
  %1064 = xor i32 %1060, %1039
  %1065 = add nuw nsw i32 %1064, %1063
  %1066 = icmp eq i32 %1065, 2
  %1067 = zext i1 %1066 to i8
  store i8 %1067, i8* %40, align 1, !tbaa !2450
  %.v5 = select i1 %1058, i64 15, i64 572
  %1068 = add i64 %1020, %.v5
  %1069 = add i64 %1021, -28
  %1070 = add i64 %1068, 7
  store i64 %1070, i64* %PC, align 8
  %1071 = inttoptr i64 %1069 to i32*
  store i32 0, i32* %1071, align 4
  %1072 = bitcast %union.VectorReg* %4 to double*
  %1073 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1074 = bitcast i64* %1073 to double*
  %.pre2 = load i64, i64* %PC, align 8
  br i1 %1058, label %block_4018c6, label %block_401af3

block_401bcf:                                     ; preds = %block_401af3
  %1075 = add i64 %131, 5
  br label %block_401bd4

block_40187b:                                     ; preds = %block_401864, %block_40188a
  %1076 = phi i64 [ %.pre, %block_401864 ], [ %1522, %block_40188a ]
  %MEMORY.2 = phi %struct.Memory* [ %1610, %block_401864 ], [ %1498, %block_40188a ]
  %1077 = load i64, i64* %RBP, align 8
  %1078 = add i64 %1077, -44
  %1079 = add i64 %1076, 3
  store i64 %1079, i64* %PC, align 8
  %1080 = inttoptr i64 %1078 to i32*
  %1081 = load i32, i32* %1080, align 4
  %1082 = shl i32 %1081, 2
  %1083 = zext i32 %1082 to i64
  store i64 %1083, i64* %RAX, align 8, !tbaa !2428
  %1084 = lshr i32 %1081, 30
  %1085 = trunc i32 %1084 to i8
  %1086 = and i8 %1085, 1
  store i8 %1086, i8* %15, align 1, !tbaa !2432
  %1087 = and i32 %1082, 252
  %1088 = tail call i32 @llvm.ctpop.i32(i32 %1087) #10
  %1089 = trunc i32 %1088 to i8
  %1090 = and i8 %1089, 1
  %1091 = xor i8 %1090, 1
  store i8 %1091, i8* %22, align 1, !tbaa !2432
  store i8 0, i8* %28, align 1, !tbaa !2432
  %1092 = icmp eq i32 %1082, 0
  %1093 = zext i1 %1092 to i8
  store i8 %1093, i8* %31, align 1, !tbaa !2432
  %1094 = lshr i32 %1081, 29
  %1095 = and i32 %1094, 1
  %1096 = trunc i32 %1095 to i8
  store i8 %1096, i8* %34, align 1, !tbaa !2432
  store i8 0, i8* %40, align 1, !tbaa !2432
  %1097 = add i64 %1077, -4
  %1098 = add i64 %1076, 9
  store i64 %1098, i64* %PC, align 8
  %1099 = inttoptr i64 %1097 to i32*
  %1100 = load i32, i32* %1099, align 4
  %1101 = sub i32 %1082, %1100
  %1102 = icmp ult i32 %1082, %1100
  %1103 = zext i1 %1102 to i8
  store i8 %1103, i8* %15, align 1, !tbaa !2433
  %1104 = and i32 %1101, 255
  %1105 = tail call i32 @llvm.ctpop.i32(i32 %1104) #10
  %1106 = trunc i32 %1105 to i8
  %1107 = and i8 %1106, 1
  %1108 = xor i8 %1107, 1
  store i8 %1108, i8* %22, align 1, !tbaa !2447
  %1109 = xor i32 %1100, %1082
  %1110 = xor i32 %1109, %1101
  %1111 = lshr i32 %1110, 4
  %1112 = trunc i32 %1111 to i8
  %1113 = and i8 %1112, 1
  store i8 %1113, i8* %28, align 1, !tbaa !2451
  %1114 = icmp eq i32 %1101, 0
  %1115 = zext i1 %1114 to i8
  store i8 %1115, i8* %31, align 1, !tbaa !2448
  %1116 = lshr i32 %1101, 31
  %1117 = trunc i32 %1116 to i8
  store i8 %1117, i8* %34, align 1, !tbaa !2449
  %1118 = lshr i32 %1100, 31
  %1119 = xor i32 %1118, %1095
  %1120 = xor i32 %1116, %1095
  %1121 = add nuw nsw i32 %1120, %1119
  %1122 = icmp eq i32 %1121, 2
  %1123 = zext i1 %1122 to i8
  store i8 %1123, i8* %40, align 1, !tbaa !2450
  %1124 = icmp ne i8 %1117, 0
  %1125 = xor i1 %1124, %1122
  %.v4 = select i1 %1125, i64 15, i64 48
  %1126 = add i64 %1076, %.v4
  store i64 %1126, i64* %92, align 8, !tbaa !2428
  br i1 %1125, label %block_40188a, label %block_4018ab

block_4018ab:                                     ; preds = %block_40187b
  %1127 = add i64 %1126, 5
  store i64 %1127, i64* %92, align 8, !tbaa !2428
  br label %block_4018b0

block_401aff:                                     ; preds = %block_401af3
  %1128 = add i64 %131, 3
  store i64 %1128, i64* %PC, align 8
  %1129 = load i32, i32* %98, align 4
  %1130 = zext i32 %1129 to i64
  store i64 %1130, i64* %RAX, align 8, !tbaa !2428
  %1131 = add i64 %131, 6
  store i64 %1131, i64* %PC, align 8
  %1132 = load i32, i32* %103, align 4
  %1133 = add i32 %1132, %1129
  %1134 = zext i32 %1133 to i64
  store i64 %1134, i64* %RAX, align 8, !tbaa !2428
  %1135 = icmp ult i32 %1133, %1129
  %1136 = icmp ult i32 %1133, %1132
  %1137 = or i1 %1135, %1136
  %1138 = zext i1 %1137 to i8
  store i8 %1138, i8* %15, align 1, !tbaa !2433
  %1139 = and i32 %1133, 255
  %1140 = tail call i32 @llvm.ctpop.i32(i32 %1139) #10
  %1141 = trunc i32 %1140 to i8
  %1142 = and i8 %1141, 1
  %1143 = xor i8 %1142, 1
  store i8 %1143, i8* %22, align 1, !tbaa !2447
  %1144 = xor i32 %1132, %1129
  %1145 = xor i32 %1144, %1133
  %1146 = lshr i32 %1145, 4
  %1147 = trunc i32 %1146 to i8
  %1148 = and i8 %1147, 1
  store i8 %1148, i8* %28, align 1, !tbaa !2451
  %1149 = icmp eq i32 %1133, 0
  %1150 = zext i1 %1149 to i8
  store i8 %1150, i8* %31, align 1, !tbaa !2448
  %1151 = lshr i32 %1133, 31
  %1152 = trunc i32 %1151 to i8
  store i8 %1152, i8* %34, align 1, !tbaa !2449
  %1153 = lshr i32 %1129, 31
  %1154 = lshr i32 %1132, 31
  %1155 = xor i32 %1151, %1153
  %1156 = xor i32 %1151, %1154
  %1157 = add nuw nsw i32 %1155, %1156
  %1158 = icmp eq i32 %1157, 2
  %1159 = zext i1 %1158 to i8
  store i8 %1159, i8* %40, align 1, !tbaa !2450
  %1160 = add i64 %95, -32
  %1161 = add i64 %131, 9
  store i64 %1161, i64* %PC, align 8
  %1162 = inttoptr i64 %1160 to i32*
  store i32 %1133, i32* %1162, align 4
  %1163 = load i64, i64* %RBP, align 8
  %1164 = add i64 %1163, -16
  %1165 = load i64, i64* %PC, align 8
  %1166 = add i64 %1165, 4
  store i64 %1166, i64* %PC, align 8
  %1167 = inttoptr i64 %1164 to i64*
  %1168 = load i64, i64* %1167, align 8
  store i64 %1168, i64* %RCX, align 8, !tbaa !2428
  %1169 = add i64 %1163, -28
  %1170 = add i64 %1165, 8
  store i64 %1170, i64* %PC, align 8
  %1171 = inttoptr i64 %1169 to i32*
  %1172 = load i32, i32* %1171, align 4
  %1173 = sext i32 %1172 to i64
  store i64 %1173, i64* %RDX, align 8, !tbaa !2428
  %1174 = shl nsw i64 %1173, 3
  %1175 = add i64 %1174, %1168
  %1176 = add i64 %1165, 13
  store i64 %1176, i64* %PC, align 8
  %1177 = inttoptr i64 %1175 to double*
  %1178 = load double, double* %1177, align 8
  store double %1178, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %1179 = add i64 %1165, 17
  store i64 %1179, i64* %PC, align 8
  %1180 = load i64, i64* %1167, align 8
  store i64 %1180, i64* %RCX, align 8, !tbaa !2428
  %1181 = add i64 %1163, -32
  %1182 = add i64 %1165, 21
  store i64 %1182, i64* %PC, align 8
  %1183 = inttoptr i64 %1181 to i32*
  %1184 = load i32, i32* %1183, align 4
  %1185 = sext i32 %1184 to i64
  store i64 %1185, i64* %RDX, align 8, !tbaa !2428
  %1186 = shl nsw i64 %1185, 3
  %1187 = add i64 %1186, %1180
  %1188 = add i64 %1165, 26
  store i64 %1188, i64* %PC, align 8
  %1189 = inttoptr i64 %1187 to double*
  %1190 = load double, double* %1189, align 8
  %1191 = fsub double %1178, %1190
  store double %1191, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %1192 = add i64 %1163, -56
  %1193 = add i64 %1165, 31
  store i64 %1193, i64* %PC, align 8
  %1194 = inttoptr i64 %1192 to double*
  store double %1191, double* %1194, align 8
  %1195 = load i64, i64* %RBP, align 8
  %1196 = add i64 %1195, -16
  %1197 = load i64, i64* %PC, align 8
  %1198 = add i64 %1197, 4
  store i64 %1198, i64* %PC, align 8
  %1199 = inttoptr i64 %1196 to i64*
  %1200 = load i64, i64* %1199, align 8
  store i64 %1200, i64* %RCX, align 8, !tbaa !2428
  %1201 = add i64 %1195, -28
  %1202 = add i64 %1197, 7
  store i64 %1202, i64* %PC, align 8
  %1203 = inttoptr i64 %1201 to i32*
  %1204 = load i32, i32* %1203, align 4
  %1205 = add i32 %1204, 1
  %1206 = zext i32 %1205 to i64
  store i64 %1206, i64* %RAX, align 8, !tbaa !2428
  %1207 = icmp eq i32 %1204, -1
  %1208 = icmp eq i32 %1205, 0
  %1209 = or i1 %1207, %1208
  %1210 = zext i1 %1209 to i8
  store i8 %1210, i8* %15, align 1, !tbaa !2433
  %1211 = and i32 %1205, 255
  %1212 = tail call i32 @llvm.ctpop.i32(i32 %1211) #10
  %1213 = trunc i32 %1212 to i8
  %1214 = and i8 %1213, 1
  %1215 = xor i8 %1214, 1
  store i8 %1215, i8* %22, align 1, !tbaa !2447
  %1216 = xor i32 %1204, %1205
  %1217 = lshr i32 %1216, 4
  %1218 = trunc i32 %1217 to i8
  %1219 = and i8 %1218, 1
  store i8 %1219, i8* %28, align 1, !tbaa !2451
  %1220 = icmp eq i32 %1205, 0
  %1221 = zext i1 %1220 to i8
  store i8 %1221, i8* %31, align 1, !tbaa !2448
  %1222 = lshr i32 %1205, 31
  %1223 = trunc i32 %1222 to i8
  store i8 %1223, i8* %34, align 1, !tbaa !2449
  %1224 = lshr i32 %1204, 31
  %1225 = xor i32 %1222, %1224
  %1226 = add nuw nsw i32 %1225, %1222
  %1227 = icmp eq i32 %1226, 2
  %1228 = zext i1 %1227 to i8
  store i8 %1228, i8* %40, align 1, !tbaa !2450
  %1229 = sext i32 %1205 to i64
  store i64 %1229, i64* %RDX, align 8, !tbaa !2428
  %1230 = shl nsw i64 %1229, 3
  %1231 = add i64 %1230, %1200
  %1232 = add i64 %1197, 18
  store i64 %1232, i64* %PC, align 8
  %1233 = inttoptr i64 %1231 to double*
  %1234 = load double, double* %1233, align 8
  store double %1234, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %1235 = add i64 %1197, 22
  store i64 %1235, i64* %PC, align 8
  %1236 = load i64, i64* %1199, align 8
  store i64 %1236, i64* %RCX, align 8, !tbaa !2428
  %1237 = add i64 %1195, -32
  %1238 = add i64 %1197, 25
  store i64 %1238, i64* %PC, align 8
  %1239 = inttoptr i64 %1237 to i32*
  %1240 = load i32, i32* %1239, align 4
  %1241 = add i32 %1240, 1
  %1242 = zext i32 %1241 to i64
  store i64 %1242, i64* %RAX, align 8, !tbaa !2428
  %1243 = icmp eq i32 %1240, -1
  %1244 = icmp eq i32 %1241, 0
  %1245 = or i1 %1243, %1244
  %1246 = zext i1 %1245 to i8
  store i8 %1246, i8* %15, align 1, !tbaa !2433
  %1247 = and i32 %1241, 255
  %1248 = tail call i32 @llvm.ctpop.i32(i32 %1247) #10
  %1249 = trunc i32 %1248 to i8
  %1250 = and i8 %1249, 1
  %1251 = xor i8 %1250, 1
  store i8 %1251, i8* %22, align 1, !tbaa !2447
  %1252 = xor i32 %1240, %1241
  %1253 = lshr i32 %1252, 4
  %1254 = trunc i32 %1253 to i8
  %1255 = and i8 %1254, 1
  store i8 %1255, i8* %28, align 1, !tbaa !2451
  %1256 = icmp eq i32 %1241, 0
  %1257 = zext i1 %1256 to i8
  store i8 %1257, i8* %31, align 1, !tbaa !2448
  %1258 = lshr i32 %1241, 31
  %1259 = trunc i32 %1258 to i8
  store i8 %1259, i8* %34, align 1, !tbaa !2449
  %1260 = lshr i32 %1240, 31
  %1261 = xor i32 %1258, %1260
  %1262 = add nuw nsw i32 %1261, %1258
  %1263 = icmp eq i32 %1262, 2
  %1264 = zext i1 %1263 to i8
  store i8 %1264, i8* %40, align 1, !tbaa !2450
  %1265 = sext i32 %1241 to i64
  store i64 %1265, i64* %RDX, align 8, !tbaa !2428
  %1266 = shl nsw i64 %1265, 3
  %1267 = add i64 %1266, %1236
  %1268 = add i64 %1197, 36
  store i64 %1268, i64* %PC, align 8
  %1269 = inttoptr i64 %1267 to double*
  %1270 = load double, double* %1269, align 8
  %1271 = fsub double %1234, %1270
  store double %1271, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %1272 = load i64, i64* %RBP, align 8
  %1273 = add i64 %1272, -64
  %1274 = add i64 %1197, 41
  store i64 %1274, i64* %PC, align 8
  %1275 = inttoptr i64 %1273 to double*
  store double %1271, double* %1275, align 8
  %1276 = load i64, i64* %RBP, align 8
  %1277 = add i64 %1276, -16
  %1278 = load i64, i64* %PC, align 8
  %1279 = add i64 %1278, 4
  store i64 %1279, i64* %PC, align 8
  %1280 = inttoptr i64 %1277 to i64*
  %1281 = load i64, i64* %1280, align 8
  store i64 %1281, i64* %RCX, align 8, !tbaa !2428
  %1282 = add i64 %1276, -32
  %1283 = add i64 %1278, 8
  store i64 %1283, i64* %PC, align 8
  %1284 = inttoptr i64 %1282 to i32*
  %1285 = load i32, i32* %1284, align 4
  %1286 = sext i32 %1285 to i64
  store i64 %1286, i64* %RDX, align 8, !tbaa !2428
  %1287 = shl nsw i64 %1286, 3
  %1288 = add i64 %1287, %1281
  %1289 = add i64 %1278, 13
  store i64 %1289, i64* %PC, align 8
  %1290 = inttoptr i64 %1288 to double*
  %1291 = load double, double* %1290, align 8
  store double %1291, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %1292 = add i64 %1278, 17
  store i64 %1292, i64* %PC, align 8
  %1293 = load i64, i64* %1280, align 8
  store i64 %1293, i64* %RCX, align 8, !tbaa !2428
  %1294 = add i64 %1276, -28
  %1295 = add i64 %1278, 21
  store i64 %1295, i64* %PC, align 8
  %1296 = inttoptr i64 %1294 to i32*
  %1297 = load i32, i32* %1296, align 4
  %1298 = sext i32 %1297 to i64
  store i64 %1298, i64* %RDX, align 8, !tbaa !2428
  %1299 = shl nsw i64 %1298, 3
  %1300 = add i64 %1299, %1293
  %1301 = add i64 %1278, 26
  store i64 %1301, i64* %PC, align 8
  %1302 = inttoptr i64 %1300 to double*
  %1303 = load double, double* %1302, align 8
  %1304 = fadd double %1291, %1303
  store double %1304, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %1305 = add i64 %1278, 31
  store i64 %1305, i64* %PC, align 8
  store double %1304, double* %1302, align 8
  %1306 = load i64, i64* %RBP, align 8
  %1307 = add i64 %1306, -16
  %1308 = load i64, i64* %PC, align 8
  %1309 = add i64 %1308, 4
  store i64 %1309, i64* %PC, align 8
  %1310 = inttoptr i64 %1307 to i64*
  %1311 = load i64, i64* %1310, align 8
  store i64 %1311, i64* %RCX, align 8, !tbaa !2428
  %1312 = add i64 %1306, -32
  %1313 = add i64 %1308, 7
  store i64 %1313, i64* %PC, align 8
  %1314 = inttoptr i64 %1312 to i32*
  %1315 = load i32, i32* %1314, align 4
  %1316 = add i32 %1315, 1
  %1317 = zext i32 %1316 to i64
  store i64 %1317, i64* %RAX, align 8, !tbaa !2428
  %1318 = icmp eq i32 %1315, -1
  %1319 = icmp eq i32 %1316, 0
  %1320 = or i1 %1318, %1319
  %1321 = zext i1 %1320 to i8
  store i8 %1321, i8* %15, align 1, !tbaa !2433
  %1322 = and i32 %1316, 255
  %1323 = tail call i32 @llvm.ctpop.i32(i32 %1322) #10
  %1324 = trunc i32 %1323 to i8
  %1325 = and i8 %1324, 1
  %1326 = xor i8 %1325, 1
  store i8 %1326, i8* %22, align 1, !tbaa !2447
  %1327 = xor i32 %1315, %1316
  %1328 = lshr i32 %1327, 4
  %1329 = trunc i32 %1328 to i8
  %1330 = and i8 %1329, 1
  store i8 %1330, i8* %28, align 1, !tbaa !2451
  %1331 = icmp eq i32 %1316, 0
  %1332 = zext i1 %1331 to i8
  store i8 %1332, i8* %31, align 1, !tbaa !2448
  %1333 = lshr i32 %1316, 31
  %1334 = trunc i32 %1333 to i8
  store i8 %1334, i8* %34, align 1, !tbaa !2449
  %1335 = lshr i32 %1315, 31
  %1336 = xor i32 %1333, %1335
  %1337 = add nuw nsw i32 %1336, %1333
  %1338 = icmp eq i32 %1337, 2
  %1339 = zext i1 %1338 to i8
  store i8 %1339, i8* %40, align 1, !tbaa !2450
  %1340 = sext i32 %1316 to i64
  store i64 %1340, i64* %RDX, align 8, !tbaa !2428
  %1341 = shl nsw i64 %1340, 3
  %1342 = add i64 %1341, %1311
  %1343 = add i64 %1308, 18
  store i64 %1343, i64* %PC, align 8
  %1344 = inttoptr i64 %1342 to double*
  %1345 = load double, double* %1344, align 8
  store double %1345, double* %1072, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %1346 = add i64 %1308, 22
  store i64 %1346, i64* %PC, align 8
  %1347 = load i64, i64* %1310, align 8
  store i64 %1347, i64* %RCX, align 8, !tbaa !2428
  %1348 = add i64 %1306, -28
  %1349 = add i64 %1308, 25
  store i64 %1349, i64* %PC, align 8
  %1350 = inttoptr i64 %1348 to i32*
  %1351 = load i32, i32* %1350, align 4
  %1352 = add i32 %1351, 1
  %1353 = zext i32 %1352 to i64
  store i64 %1353, i64* %RAX, align 8, !tbaa !2428
  %1354 = icmp eq i32 %1351, -1
  %1355 = icmp eq i32 %1352, 0
  %1356 = or i1 %1354, %1355
  %1357 = zext i1 %1356 to i8
  store i8 %1357, i8* %15, align 1, !tbaa !2433
  %1358 = and i32 %1352, 255
  %1359 = tail call i32 @llvm.ctpop.i32(i32 %1358) #10
  %1360 = trunc i32 %1359 to i8
  %1361 = and i8 %1360, 1
  %1362 = xor i8 %1361, 1
  store i8 %1362, i8* %22, align 1, !tbaa !2447
  %1363 = xor i32 %1351, %1352
  %1364 = lshr i32 %1363, 4
  %1365 = trunc i32 %1364 to i8
  %1366 = and i8 %1365, 1
  store i8 %1366, i8* %28, align 1, !tbaa !2451
  %1367 = icmp eq i32 %1352, 0
  %1368 = zext i1 %1367 to i8
  store i8 %1368, i8* %31, align 1, !tbaa !2448
  %1369 = lshr i32 %1352, 31
  %1370 = trunc i32 %1369 to i8
  store i8 %1370, i8* %34, align 1, !tbaa !2449
  %1371 = lshr i32 %1351, 31
  %1372 = xor i32 %1369, %1371
  %1373 = add nuw nsw i32 %1372, %1369
  %1374 = icmp eq i32 %1373, 2
  %1375 = zext i1 %1374 to i8
  store i8 %1375, i8* %40, align 1, !tbaa !2450
  %1376 = sext i32 %1352 to i64
  store i64 %1376, i64* %RDX, align 8, !tbaa !2428
  %1377 = shl nsw i64 %1376, 3
  %1378 = add i64 %1377, %1347
  %1379 = add i64 %1308, 36
  store i64 %1379, i64* %PC, align 8
  %1380 = inttoptr i64 %1378 to double*
  %1381 = load double, double* %1380, align 8
  %1382 = fadd double %1345, %1381
  store double %1382, double* %1072, align 1, !tbaa !2452
  store i64 0, i64* %1073, align 1, !tbaa !2452
  %1383 = add i64 %1308, 41
  store i64 %1383, i64* %PC, align 8
  store double %1382, double* %1380, align 8
  %1384 = load i64, i64* %RBP, align 8
  %1385 = add i64 %1384, -56
  %1386 = load i64, i64* %PC, align 8
  %1387 = add i64 %1386, 5
  store i64 %1387, i64* %PC, align 8
  %1388 = inttoptr i64 %1385 to i64*
  %1389 = load i64, i64* %1388, align 8
  %1390 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1389, i64* %1390, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %1391 = add i64 %1384, -16
  %1392 = add i64 %1386, 9
  store i64 %1392, i64* %PC, align 8
  %1393 = inttoptr i64 %1391 to i64*
  %1394 = load i64, i64* %1393, align 8
  store i64 %1394, i64* %RCX, align 8, !tbaa !2428
  %1395 = add i64 %1384, -32
  %1396 = add i64 %1386, 13
  store i64 %1396, i64* %PC, align 8
  %1397 = inttoptr i64 %1395 to i32*
  %1398 = load i32, i32* %1397, align 4
  %1399 = sext i32 %1398 to i64
  store i64 %1399, i64* %RDX, align 8, !tbaa !2428
  %1400 = shl nsw i64 %1399, 3
  %1401 = add i64 %1400, %1394
  %1402 = add i64 %1386, 18
  store i64 %1402, i64* %PC, align 8
  %1403 = inttoptr i64 %1401 to i64*
  store i64 %1389, i64* %1403, align 8
  %1404 = load i64, i64* %RBP, align 8
  %1405 = add i64 %1404, -64
  %1406 = load i64, i64* %PC, align 8
  %1407 = add i64 %1406, 5
  store i64 %1407, i64* %PC, align 8
  %1408 = inttoptr i64 %1405 to i64*
  %1409 = load i64, i64* %1408, align 8
  %1410 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1409, i64* %1410, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1074, align 1, !tbaa !2452
  %1411 = add i64 %1404, -16
  %1412 = add i64 %1406, 9
  store i64 %1412, i64* %PC, align 8
  %1413 = inttoptr i64 %1411 to i64*
  %1414 = load i64, i64* %1413, align 8
  store i64 %1414, i64* %RCX, align 8, !tbaa !2428
  %1415 = add i64 %1404, -32
  %1416 = add i64 %1406, 12
  store i64 %1416, i64* %PC, align 8
  %1417 = inttoptr i64 %1415 to i32*
  %1418 = load i32, i32* %1417, align 4
  %1419 = add i32 %1418, 1
  %1420 = zext i32 %1419 to i64
  store i64 %1420, i64* %RAX, align 8, !tbaa !2428
  %1421 = icmp eq i32 %1418, -1
  %1422 = icmp eq i32 %1419, 0
  %1423 = or i1 %1421, %1422
  %1424 = zext i1 %1423 to i8
  store i8 %1424, i8* %15, align 1, !tbaa !2433
  %1425 = and i32 %1419, 255
  %1426 = tail call i32 @llvm.ctpop.i32(i32 %1425) #10
  %1427 = trunc i32 %1426 to i8
  %1428 = and i8 %1427, 1
  %1429 = xor i8 %1428, 1
  store i8 %1429, i8* %22, align 1, !tbaa !2447
  %1430 = xor i32 %1418, %1419
  %1431 = lshr i32 %1430, 4
  %1432 = trunc i32 %1431 to i8
  %1433 = and i8 %1432, 1
  store i8 %1433, i8* %28, align 1, !tbaa !2451
  %1434 = icmp eq i32 %1419, 0
  %1435 = zext i1 %1434 to i8
  store i8 %1435, i8* %31, align 1, !tbaa !2448
  %1436 = lshr i32 %1419, 31
  %1437 = trunc i32 %1436 to i8
  store i8 %1437, i8* %34, align 1, !tbaa !2449
  %1438 = lshr i32 %1418, 31
  %1439 = xor i32 %1436, %1438
  %1440 = add nuw nsw i32 %1439, %1436
  %1441 = icmp eq i32 %1440, 2
  %1442 = zext i1 %1441 to i8
  store i8 %1442, i8* %40, align 1, !tbaa !2450
  %1443 = sext i32 %1419 to i64
  store i64 %1443, i64* %RDX, align 8, !tbaa !2428
  %1444 = shl nsw i64 %1443, 3
  %1445 = add i64 %1444, %1414
  %1446 = add i64 %1406, 23
  store i64 %1446, i64* %PC, align 8
  %1447 = inttoptr i64 %1445 to i64*
  store i64 %1409, i64* %1447, align 8
  %1448 = load i64, i64* %RBP, align 8
  %1449 = add i64 %1448, -28
  %1450 = load i64, i64* %PC, align 8
  %1451 = add i64 %1450, 3
  store i64 %1451, i64* %PC, align 8
  %1452 = inttoptr i64 %1449 to i32*
  %1453 = load i32, i32* %1452, align 4
  %1454 = add i32 %1453, 2
  %1455 = zext i32 %1454 to i64
  store i64 %1455, i64* %RAX, align 8, !tbaa !2428
  %1456 = icmp ugt i32 %1453, -3
  %1457 = zext i1 %1456 to i8
  store i8 %1457, i8* %15, align 1, !tbaa !2433
  %1458 = and i32 %1454, 255
  %1459 = tail call i32 @llvm.ctpop.i32(i32 %1458) #10
  %1460 = trunc i32 %1459 to i8
  %1461 = and i8 %1460, 1
  %1462 = xor i8 %1461, 1
  store i8 %1462, i8* %22, align 1, !tbaa !2447
  %1463 = xor i32 %1453, %1454
  %1464 = lshr i32 %1463, 4
  %1465 = trunc i32 %1464 to i8
  %1466 = and i8 %1465, 1
  store i8 %1466, i8* %28, align 1, !tbaa !2451
  %1467 = icmp eq i32 %1454, 0
  %1468 = zext i1 %1467 to i8
  store i8 %1468, i8* %31, align 1, !tbaa !2448
  %1469 = lshr i32 %1454, 31
  %1470 = trunc i32 %1469 to i8
  store i8 %1470, i8* %34, align 1, !tbaa !2449
  %1471 = lshr i32 %1453, 31
  %1472 = xor i32 %1469, %1471
  %1473 = add nuw nsw i32 %1472, %1469
  %1474 = icmp eq i32 %1473, 2
  %1475 = zext i1 %1474 to i8
  store i8 %1475, i8* %40, align 1, !tbaa !2450
  %1476 = add i64 %1450, 9
  store i64 %1476, i64* %PC, align 8
  store i32 %1454, i32* %1452, align 4
  %1477 = load i64, i64* %PC, align 8
  %1478 = add i64 %1477, -215
  store i64 %1478, i64* %92, align 8, !tbaa !2428
  br label %block_401af3

block_40188a:                                     ; preds = %block_40187b
  %1479 = add i64 %1126, 3
  store i64 %1479, i64* %PC, align 8
  %1480 = load i32, i32* %1099, align 4
  %1481 = zext i32 %1480 to i64
  store i64 %1481, i64* %RDI, align 8, !tbaa !2428
  %1482 = add i64 %1126, 6
  store i64 %1482, i64* %PC, align 8
  %1483 = load i32, i32* %1080, align 4
  %1484 = zext i32 %1483 to i64
  store i64 %1484, i64* %RSI, align 8, !tbaa !2428
  %1485 = add i64 %1077, -16
  %1486 = add i64 %1126, 10
  store i64 %1486, i64* %PC, align 8
  %1487 = inttoptr i64 %1485 to i64*
  %1488 = load i64, i64* %1487, align 8
  store i64 %1488, i64* %RDX, align 8, !tbaa !2428
  %1489 = add i64 %1077, -24
  %1490 = add i64 %1126, 14
  store i64 %1490, i64* %PC, align 8
  %1491 = inttoptr i64 %1489 to i64*
  %1492 = load i64, i64* %1491, align 8
  store i64 %1492, i64* %RCX, align 8, !tbaa !2428
  %1493 = add i64 %1126, 6774
  %1494 = add i64 %1126, 19
  %1495 = load i64, i64* %7, align 8, !tbaa !2428
  %1496 = add i64 %1495, -8
  %1497 = inttoptr i64 %1496 to i64*
  store i64 %1494, i64* %1497, align 8
  store i64 %1496, i64* %7, align 8, !tbaa !2428
  store i64 %1493, i64* %92, align 8, !tbaa !2428
  %1498 = tail call %struct.Memory* @sub_403300_cftmdl_renamed_(%struct.State* nonnull %0, i64 %1493, %struct.Memory* %MEMORY.2)
  %1499 = load i64, i64* %RBP, align 8
  %1500 = add i64 %1499, -44
  %1501 = load i64, i64* %PC, align 8
  %1502 = add i64 %1501, 3
  store i64 %1502, i64* %PC, align 8
  %1503 = inttoptr i64 %1500 to i32*
  %1504 = load i32, i32* %1503, align 4
  %1505 = shl i32 %1504, 2
  %1506 = zext i32 %1505 to i64
  store i64 %1506, i64* %RSI, align 8, !tbaa !2428
  %1507 = lshr i32 %1504, 30
  %1508 = trunc i32 %1507 to i8
  %1509 = and i8 %1508, 1
  store i8 %1509, i8* %15, align 1, !tbaa !2432
  %1510 = and i32 %1505, 252
  %1511 = tail call i32 @llvm.ctpop.i32(i32 %1510) #10
  %1512 = trunc i32 %1511 to i8
  %1513 = and i8 %1512, 1
  %1514 = xor i8 %1513, 1
  store i8 %1514, i8* %22, align 1, !tbaa !2432
  store i8 0, i8* %28, align 1, !tbaa !2432
  %1515 = icmp eq i32 %1505, 0
  %1516 = zext i1 %1515 to i8
  store i8 %1516, i8* %31, align 1, !tbaa !2432
  %1517 = lshr i32 %1504, 29
  %1518 = trunc i32 %1517 to i8
  %1519 = and i8 %1518, 1
  store i8 %1519, i8* %34, align 1, !tbaa !2432
  store i8 0, i8* %40, align 1, !tbaa !2432
  %1520 = add i64 %1501, 9
  store i64 %1520, i64* %PC, align 8
  store i32 %1505, i32* %1503, align 4
  %1521 = load i64, i64* %PC, align 8
  %1522 = add i64 %1521, -43
  store i64 %1522, i64* %92, align 8, !tbaa !2428
  br label %block_40187b

block_401ae7:                                     ; preds = %block_4018c6
  %1523 = add i64 %1593, 237
  br label %block_401bd4

block_401bd4:                                     ; preds = %block_401ae7, %block_401bcf
  %.sink = phi i64 [ %1523, %block_401ae7 ], [ %1075, %block_401bcf ]
  %1524 = load i64, i64* %RSP, align 8
  %1525 = add i64 %1524, 112
  store i64 %1525, i64* %RSP, align 8, !tbaa !2428
  %1526 = icmp ugt i64 %1524, -113
  %1527 = zext i1 %1526 to i8
  store i8 %1527, i8* %15, align 1, !tbaa !2433
  %1528 = trunc i64 %1525 to i32
  %1529 = and i32 %1528, 255
  %1530 = tail call i32 @llvm.ctpop.i32(i32 %1529) #10
  %1531 = trunc i32 %1530 to i8
  %1532 = and i8 %1531, 1
  %1533 = xor i8 %1532, 1
  store i8 %1533, i8* %22, align 1, !tbaa !2447
  %1534 = xor i64 %1524, 16
  %1535 = xor i64 %1534, %1525
  %1536 = lshr i64 %1535, 4
  %1537 = trunc i64 %1536 to i8
  %1538 = and i8 %1537, 1
  store i8 %1538, i8* %28, align 1, !tbaa !2451
  %1539 = icmp eq i64 %1525, 0
  %1540 = zext i1 %1539 to i8
  store i8 %1540, i8* %31, align 1, !tbaa !2448
  %1541 = lshr i64 %1525, 63
  %1542 = trunc i64 %1541 to i8
  store i8 %1542, i8* %34, align 1, !tbaa !2449
  %1543 = lshr i64 %1524, 63
  %1544 = xor i64 %1541, %1543
  %1545 = add nuw nsw i64 %1544, %1541
  %1546 = icmp eq i64 %1545, 2
  %1547 = zext i1 %1546 to i8
  store i8 %1547, i8* %40, align 1, !tbaa !2450
  %1548 = add i64 %.sink, 5
  store i64 %1548, i64* %PC, align 8
  %1549 = add i64 %1524, 120
  %1550 = inttoptr i64 %1525 to i64*
  %1551 = load i64, i64* %1550, align 8
  store i64 %1551, i64* %RBP, align 8, !tbaa !2428
  store i64 %1549, i64* %7, align 8, !tbaa !2428
  %1552 = add i64 %.sink, 6
  store i64 %1552, i64* %PC, align 8
  %1553 = inttoptr i64 %1549 to i64*
  %1554 = load i64, i64* %1553, align 8
  store i64 %1554, i64* %92, align 8, !tbaa !2428
  %1555 = add i64 %1524, 128
  store i64 %1555, i64* %7, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.1

block_4018c6:                                     ; preds = %block_4018b0, %block_4018d2
  %1556 = phi i64 [ %1019, %block_4018d2 ], [ %.pre2, %block_4018b0 ]
  %1557 = load i64, i64* %RBP, align 8
  %1558 = add i64 %1557, -28
  %1559 = add i64 %1556, 3
  store i64 %1559, i64* %PC, align 8
  %1560 = inttoptr i64 %1558 to i32*
  %1561 = load i32, i32* %1560, align 4
  %1562 = zext i32 %1561 to i64
  store i64 %1562, i64* %RAX, align 8, !tbaa !2428
  %1563 = add i64 %1557, -44
  %1564 = add i64 %1556, 6
  store i64 %1564, i64* %PC, align 8
  %1565 = inttoptr i64 %1563 to i32*
  %1566 = load i32, i32* %1565, align 4
  %1567 = sub i32 %1561, %1566
  %1568 = icmp ult i32 %1561, %1566
  %1569 = zext i1 %1568 to i8
  store i8 %1569, i8* %15, align 1, !tbaa !2433
  %1570 = and i32 %1567, 255
  %1571 = tail call i32 @llvm.ctpop.i32(i32 %1570) #10
  %1572 = trunc i32 %1571 to i8
  %1573 = and i8 %1572, 1
  %1574 = xor i8 %1573, 1
  store i8 %1574, i8* %22, align 1, !tbaa !2447
  %1575 = xor i32 %1566, %1561
  %1576 = xor i32 %1575, %1567
  %1577 = lshr i32 %1576, 4
  %1578 = trunc i32 %1577 to i8
  %1579 = and i8 %1578, 1
  store i8 %1579, i8* %28, align 1, !tbaa !2451
  %1580 = icmp eq i32 %1567, 0
  %1581 = zext i1 %1580 to i8
  store i8 %1581, i8* %31, align 1, !tbaa !2448
  %1582 = lshr i32 %1567, 31
  %1583 = trunc i32 %1582 to i8
  store i8 %1583, i8* %34, align 1, !tbaa !2449
  %1584 = lshr i32 %1561, 31
  %1585 = lshr i32 %1566, 31
  %1586 = xor i32 %1585, %1584
  %1587 = xor i32 %1582, %1584
  %1588 = add nuw nsw i32 %1587, %1586
  %1589 = icmp eq i32 %1588, 2
  %1590 = zext i1 %1589 to i8
  store i8 %1590, i8* %40, align 1, !tbaa !2450
  %1591 = icmp ne i8 %1583, 0
  %1592 = xor i1 %1591, %1589
  %.v6 = select i1 %1592, i64 12, i64 545
  %1593 = add i64 %1556, %.v6
  store i64 %1593, i64* %92, align 8, !tbaa !2428
  br i1 %1592, label %block_4018d2, label %block_401ae7

block_401864:                                     ; preds = %block_401840
  %1594 = add i64 %93, 3
  store i64 %1594, i64* %PC, align 8
  %1595 = load i32, i32* %66, align 4
  %1596 = zext i32 %1595 to i64
  store i64 %1596, i64* %RDI, align 8, !tbaa !2428
  %1597 = add i64 %62, -16
  %1598 = add i64 %93, 7
  store i64 %1598, i64* %PC, align 8
  %1599 = inttoptr i64 %1597 to i64*
  %1600 = load i64, i64* %1599, align 8
  store i64 %1600, i64* %RSI, align 8, !tbaa !2428
  %1601 = add i64 %62, -24
  %1602 = add i64 %93, 11
  store i64 %1602, i64* %PC, align 8
  %1603 = inttoptr i64 %1601 to i64*
  %1604 = load i64, i64* %1603, align 8
  store i64 %1604, i64* %RDX, align 8, !tbaa !2428
  %1605 = add i64 %93, 4108
  %1606 = add i64 %93, 16
  %1607 = load i64, i64* %7, align 8, !tbaa !2428
  %1608 = add i64 %1607, -8
  %1609 = inttoptr i64 %1608 to i64*
  store i64 %1606, i64* %1609, align 8
  store i64 %1608, i64* %7, align 8, !tbaa !2428
  store i64 %1605, i64* %92, align 8, !tbaa !2428
  %1610 = tail call %struct.Memory* @sub_402870_cft1st_renamed_(%struct.State* nonnull %0, i64 %1605, %struct.Memory* %2)
  %1611 = load i64, i64* %RBP, align 8
  %1612 = add i64 %1611, -44
  %1613 = load i64, i64* %PC, align 8
  %1614 = add i64 %1613, 7
  store i64 %1614, i64* %PC, align 8
  %1615 = inttoptr i64 %1612 to i32*
  store i32 8, i32* %1615, align 4
  %.pre = load i64, i64* %PC, align 8
  br label %block_40187b
}

; Function Attrs: noinline
define %struct.Memory* @sub_403300_cftmdl(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_403300:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %4 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %8 = load i64, i64* %RBP, align 8
  %9 = add i64 %1, 1
  store i64 %9, i64* %PC, align 8
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %11 = load i64, i64* %10, align 8, !tbaa !2428
  %12 = add i64 %11, -8
  %13 = inttoptr i64 %12 to i64*
  store i64 %8, i64* %13, align 8
  %14 = load i64, i64* %PC, align 8
  store i64 %12, i64* %RBP, align 8, !tbaa !2428
  %15 = add i64 %11, -56
  store i64 %15, i64* %RSP, align 8, !tbaa !2428
  %16 = icmp ult i64 %12, 48
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1, !tbaa !2433
  %19 = trunc i64 %15 to i32
  %20 = and i32 %19, 255
  %21 = tail call i32 @llvm.ctpop.i32(i32 %20) #10
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = xor i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %24, i8* %25, align 1, !tbaa !2447
  %26 = xor i64 %12, 16
  %27 = xor i64 %26, %15
  %28 = lshr i64 %27, 4
  %29 = trunc i64 %28 to i8
  %30 = and i8 %29, 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %30, i8* %31, align 1, !tbaa !2451
  %32 = icmp eq i64 %15, 0
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %33, i8* %34, align 1, !tbaa !2448
  %35 = lshr i64 %15, 63
  %36 = trunc i64 %35 to i8
  %37 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %36, i8* %37, align 1, !tbaa !2449
  %38 = lshr i64 %12, 63
  %39 = xor i64 %35, %38
  %40 = add nuw nsw i64 %39, %38
  %41 = icmp eq i64 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1, !tbaa !2450
  %44 = add i64 %11, -12
  %45 = load i32, i32* %EDI, align 4
  %46 = add i64 %14, 10
  store i64 %46, i64* %PC, align 8
  %47 = inttoptr i64 %44 to i32*
  store i32 %45, i32* %47, align 4
  %48 = load i64, i64* %RBP, align 8
  %49 = add i64 %48, -8
  %50 = load i32, i32* %ESI, align 4
  %51 = load i64, i64* %PC, align 8
  %52 = add i64 %51, 3
  store i64 %52, i64* %PC, align 8
  %53 = inttoptr i64 %49 to i32*
  store i32 %50, i32* %53, align 4
  %54 = load i64, i64* %RBP, align 8
  %55 = add i64 %54, -16
  %56 = load i64, i64* %RDX, align 8
  %57 = load i64, i64* %PC, align 8
  %58 = add i64 %57, 4
  store i64 %58, i64* %PC, align 8
  %59 = inttoptr i64 %55 to i64*
  store i64 %56, i64* %59, align 8
  %60 = load i64, i64* %RBP, align 8
  %61 = add i64 %60, -24
  %62 = load i64, i64* %RCX, align 8
  %63 = load i64, i64* %PC, align 8
  %64 = add i64 %63, 4
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %61 to i64*
  store i64 %62, i64* %65, align 8
  %66 = load i64, i64* %RBP, align 8
  %67 = add i64 %66, -8
  %68 = load i64, i64* %PC, align 8
  %69 = add i64 %68, 3
  store i64 %69, i64* %PC, align 8
  %70 = inttoptr i64 %67 to i32*
  %71 = load i32, i32* %70, align 4
  %72 = shl i32 %71, 2
  %73 = zext i32 %72 to i64
  store i64 %73, i64* %RSI, align 8, !tbaa !2428
  %74 = lshr i32 %71, 30
  %75 = trunc i32 %74 to i8
  %76 = and i8 %75, 1
  store i8 %76, i8* %18, align 1, !tbaa !2432
  %77 = and i32 %72, 252
  %78 = tail call i32 @llvm.ctpop.i32(i32 %77) #10
  %79 = trunc i32 %78 to i8
  %80 = and i8 %79, 1
  %81 = xor i8 %80, 1
  store i8 %81, i8* %25, align 1, !tbaa !2432
  store i8 0, i8* %31, align 1, !tbaa !2432
  %82 = icmp eq i32 %72, 0
  %83 = zext i1 %82 to i8
  store i8 %83, i8* %34, align 1, !tbaa !2432
  %84 = lshr i32 %71, 29
  %85 = trunc i32 %84 to i8
  %86 = and i8 %85, 1
  store i8 %86, i8* %37, align 1, !tbaa !2432
  store i8 0, i8* %43, align 1, !tbaa !2432
  %87 = add i64 %66, -56
  %88 = add i64 %68, 9
  store i64 %88, i64* %PC, align 8
  %89 = inttoptr i64 %87 to i32*
  store i32 %72, i32* %89, align 4
  %90 = load i64, i64* %RBP, align 8
  %91 = add i64 %90, -28
  %92 = load i64, i64* %PC, align 8
  %93 = add i64 %92, 7
  store i64 %93, i64* %PC, align 8
  %94 = inttoptr i64 %91 to i32*
  store i32 0, i32* %94, align 4
  %95 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %96 = bitcast [32 x %union.VectorReg]* %5 to double*
  %97 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %98 = bitcast i64* %97 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_403326

block_403c22:                                     ; preds = %block_403910
  %99 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 80) to i64*), align 16
  %100 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %5, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %99, i64* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %101 = load i64, i64* %RBP, align 8
  %102 = add i64 %101, -24
  %103 = add i64 %1647, 12
  store i64 %103, i64* %PC, align 8
  %104 = inttoptr i64 %102 to i64*
  %105 = load i64, i64* %104, align 8
  store i64 %105, i64* %RAX, align 8, !tbaa !2428
  %106 = add i64 %101, -52
  %107 = add i64 %1647, 15
  store i64 %107, i64* %PC, align 8
  %108 = inttoptr i64 %106 to i32*
  %109 = load i32, i32* %108, align 4
  %110 = add i32 %109, 2
  %111 = zext i32 %110 to i64
  store i64 %111, i64* %RCX, align 8, !tbaa !2428
  %112 = icmp ugt i32 %109, -3
  %113 = zext i1 %112 to i8
  store i8 %113, i8* %18, align 1, !tbaa !2433
  %114 = and i32 %110, 255
  %115 = tail call i32 @llvm.ctpop.i32(i32 %114) #10
  %116 = trunc i32 %115 to i8
  %117 = and i8 %116, 1
  %118 = xor i8 %117, 1
  store i8 %118, i8* %25, align 1, !tbaa !2447
  %119 = xor i32 %109, %110
  %120 = lshr i32 %119, 4
  %121 = trunc i32 %120 to i8
  %122 = and i8 %121, 1
  store i8 %122, i8* %31, align 1, !tbaa !2451
  %123 = icmp eq i32 %110, 0
  %124 = zext i1 %123 to i8
  store i8 %124, i8* %34, align 1, !tbaa !2448
  %125 = lshr i32 %110, 31
  %126 = trunc i32 %125 to i8
  store i8 %126, i8* %37, align 1, !tbaa !2449
  %127 = lshr i32 %109, 31
  %128 = xor i32 %125, %127
  %129 = add nuw nsw i32 %128, %125
  %130 = icmp eq i32 %129, 2
  %131 = zext i1 %130 to i8
  store i8 %131, i8* %43, align 1, !tbaa !2450
  %132 = sext i32 %110 to i64
  store i64 %132, i64* %RDX, align 8, !tbaa !2428
  %133 = shl nsw i64 %132, 3
  %134 = add i64 %133, %105
  %135 = add i64 %1647, 26
  store i64 %135, i64* %PC, align 8
  %136 = inttoptr i64 %134 to i64*
  %137 = load i64, i64* %136, align 8
  %138 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %137, i64* %138, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %139 = add i64 %101, -72
  %140 = add i64 %1647, 31
  store i64 %140, i64* %PC, align 8
  %141 = inttoptr i64 %139 to i64*
  store i64 %137, i64* %141, align 8
  %142 = load i64, i64* %RBP, align 8
  %143 = add i64 %142, -24
  %144 = load i64, i64* %PC, align 8
  %145 = add i64 %144, 4
  store i64 %145, i64* %PC, align 8
  %146 = inttoptr i64 %143 to i64*
  %147 = load i64, i64* %146, align 8
  store i64 %147, i64* %RAX, align 8, !tbaa !2428
  %148 = add i64 %142, -52
  %149 = add i64 %144, 7
  store i64 %149, i64* %PC, align 8
  %150 = inttoptr i64 %148 to i32*
  %151 = load i32, i32* %150, align 4
  %152 = add i32 %151, 3
  %153 = zext i32 %152 to i64
  store i64 %153, i64* %RCX, align 8, !tbaa !2428
  %154 = icmp ugt i32 %151, -4
  %155 = zext i1 %154 to i8
  store i8 %155, i8* %18, align 1, !tbaa !2433
  %156 = and i32 %152, 255
  %157 = tail call i32 @llvm.ctpop.i32(i32 %156) #10
  %158 = trunc i32 %157 to i8
  %159 = and i8 %158, 1
  %160 = xor i8 %159, 1
  store i8 %160, i8* %25, align 1, !tbaa !2447
  %161 = xor i32 %151, %152
  %162 = lshr i32 %161, 4
  %163 = trunc i32 %162 to i8
  %164 = and i8 %163, 1
  store i8 %164, i8* %31, align 1, !tbaa !2451
  %165 = icmp eq i32 %152, 0
  %166 = zext i1 %165 to i8
  store i8 %166, i8* %34, align 1, !tbaa !2448
  %167 = lshr i32 %152, 31
  %168 = trunc i32 %167 to i8
  store i8 %168, i8* %37, align 1, !tbaa !2449
  %169 = lshr i32 %151, 31
  %170 = xor i32 %167, %169
  %171 = add nuw nsw i32 %170, %167
  %172 = icmp eq i32 %171, 2
  %173 = zext i1 %172 to i8
  store i8 %173, i8* %43, align 1, !tbaa !2450
  %174 = sext i32 %152 to i64
  store i64 %174, i64* %RDX, align 8, !tbaa !2428
  %175 = shl nsw i64 %174, 3
  %176 = add i64 %175, %147
  %177 = add i64 %144, 18
  store i64 %177, i64* %PC, align 8
  %178 = inttoptr i64 %176 to i64*
  %179 = load i64, i64* %178, align 8
  %180 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %179, i64* %180, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %181 = add i64 %142, -80
  %182 = add i64 %144, 23
  store i64 %182, i64* %PC, align 8
  %183 = inttoptr i64 %181 to i64*
  store i64 %179, i64* %183, align 8
  %184 = load i64, i64* %RBP, align 8
  %185 = add i64 %184, -72
  %186 = load i64, i64* %PC, align 8
  %187 = add i64 %186, 5
  store i64 %187, i64* %PC, align 8
  %188 = inttoptr i64 %185 to double*
  %189 = load double, double* %188, align 8
  store double %189, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %190 = load <2 x i32>, <2 x i32>* %1467, align 1
  %191 = load <2 x i32>, <2 x i32>* %1469, align 1
  %192 = extractelement <2 x i32> %190, i32 0
  store i32 %192, i32* %1470, align 1, !tbaa !2475
  %193 = extractelement <2 x i32> %190, i32 1
  store i32 %193, i32* %1472, align 1, !tbaa !2475
  %194 = extractelement <2 x i32> %191, i32 0
  store i32 %194, i32* %1474, align 1, !tbaa !2475
  %195 = extractelement <2 x i32> %191, i32 1
  store i32 %195, i32* %1476, align 1, !tbaa !2475
  %196 = add i64 %184, -88
  %197 = add i64 %186, 13
  store i64 %197, i64* %PC, align 8
  %198 = load double, double* %1477, align 1
  %199 = inttoptr i64 %196 to double*
  %200 = load double, double* %199, align 8
  %201 = fmul double %198, %200
  store double %201, double* %1477, align 1, !tbaa !2452
  %202 = add i64 %184, -80
  %203 = add i64 %186, 18
  store i64 %203, i64* %PC, align 8
  %204 = inttoptr i64 %202 to double*
  %205 = load double, double* %204, align 8
  %206 = fmul double %201, %205
  store double %206, double* %1477, align 1, !tbaa !2452
  %207 = fsub double %189, %206
  store double %207, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %208 = add i64 %184, -104
  %209 = add i64 %186, 27
  store i64 %209, i64* %PC, align 8
  %210 = inttoptr i64 %208 to double*
  store double %207, double* %210, align 8
  %211 = load i64, i64* %RBP, align 8
  %212 = add i64 %211, -88
  %213 = load i64, i64* %PC, align 8
  %214 = add i64 %213, 5
  store i64 %214, i64* %PC, align 8
  %215 = load double, double* %96, align 1
  %216 = inttoptr i64 %212 to double*
  %217 = load double, double* %216, align 8
  %218 = fmul double %215, %217
  store double %218, double* %96, align 1, !tbaa !2452
  %219 = add i64 %211, -72
  %220 = add i64 %213, 10
  store i64 %220, i64* %PC, align 8
  %221 = inttoptr i64 %219 to double*
  %222 = load double, double* %221, align 8
  %223 = fmul double %218, %222
  store double %223, double* %96, align 1, !tbaa !2452
  %224 = add i64 %211, -80
  %225 = add i64 %213, 15
  store i64 %225, i64* %PC, align 8
  %226 = inttoptr i64 %224 to double*
  %227 = load double, double* %226, align 8
  %228 = fsub double %223, %227
  store double %228, double* %96, align 1, !tbaa !2452
  %229 = add i64 %211, -112
  %230 = add i64 %213, 20
  store i64 %230, i64* %PC, align 8
  %231 = inttoptr i64 %229 to double*
  store double %228, double* %231, align 8
  %232 = load i64, i64* %RBP, align 8
  %233 = add i64 %232, -44
  %234 = load i64, i64* %PC, align 8
  %235 = add i64 %234, 3
  store i64 %235, i64* %PC, align 8
  %236 = inttoptr i64 %233 to i32*
  %237 = load i32, i32* %236, align 4
  %238 = zext i32 %237 to i64
  store i64 %238, i64* %RCX, align 8, !tbaa !2428
  %239 = add i64 %232, -56
  %240 = add i64 %234, 6
  store i64 %240, i64* %PC, align 8
  %241 = inttoptr i64 %239 to i32*
  %242 = load i32, i32* %241, align 4
  %243 = add i32 %242, %237
  %244 = zext i32 %243 to i64
  store i64 %244, i64* %RCX, align 8, !tbaa !2428
  %245 = icmp ult i32 %243, %237
  %246 = icmp ult i32 %243, %242
  %247 = or i1 %245, %246
  %248 = zext i1 %247 to i8
  store i8 %248, i8* %18, align 1, !tbaa !2433
  %249 = and i32 %243, 255
  %250 = tail call i32 @llvm.ctpop.i32(i32 %249) #10
  %251 = trunc i32 %250 to i8
  %252 = and i8 %251, 1
  %253 = xor i8 %252, 1
  store i8 %253, i8* %25, align 1, !tbaa !2447
  %254 = xor i32 %242, %237
  %255 = xor i32 %254, %243
  %256 = lshr i32 %255, 4
  %257 = trunc i32 %256 to i8
  %258 = and i8 %257, 1
  store i8 %258, i8* %31, align 1, !tbaa !2451
  %259 = icmp eq i32 %243, 0
  %260 = zext i1 %259 to i8
  store i8 %260, i8* %34, align 1, !tbaa !2448
  %261 = lshr i32 %243, 31
  %262 = trunc i32 %261 to i8
  store i8 %262, i8* %37, align 1, !tbaa !2449
  %263 = lshr i32 %237, 31
  %264 = lshr i32 %242, 31
  %265 = xor i32 %261, %263
  %266 = xor i32 %261, %264
  %267 = add nuw nsw i32 %265, %266
  %268 = icmp eq i32 %267, 2
  %269 = zext i1 %268 to i8
  store i8 %269, i8* %43, align 1, !tbaa !2450
  %270 = add i64 %232, -28
  %271 = add i64 %234, 9
  store i64 %271, i64* %PC, align 8
  %272 = inttoptr i64 %270 to i32*
  store i32 %243, i32* %272, align 4
  %.pre6 = load i64, i64* %PC, align 8
  br label %block_403c90

block_40357d:                                     ; preds = %block_403326
  %273 = add i64 %4793, -24
  %274 = add i64 %4829, 4
  store i64 %274, i64* %PC, align 8
  %275 = inttoptr i64 %273 to i64*
  %276 = load i64, i64* %275, align 8
  store i64 %276, i64* %RAX, align 8, !tbaa !2428
  %277 = add i64 %276, 16
  %278 = add i64 %4829, 9
  store i64 %278, i64* %PC, align 8
  %279 = inttoptr i64 %277 to i64*
  %280 = load i64, i64* %279, align 8
  %281 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %5, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %280, i64* %281, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %282 = add i64 %4793, -72
  %283 = add i64 %4829, 14
  store i64 %283, i64* %PC, align 8
  %284 = inttoptr i64 %282 to i64*
  store i64 %280, i64* %284, align 8
  %285 = load i64, i64* %RBP, align 8
  %286 = add i64 %285, -56
  %287 = load i64, i64* %PC, align 8
  %288 = add i64 %287, 3
  store i64 %288, i64* %PC, align 8
  %289 = inttoptr i64 %286 to i32*
  %290 = load i32, i32* %289, align 4
  %291 = zext i32 %290 to i64
  store i64 %291, i64* %RCX, align 8, !tbaa !2428
  %292 = add i64 %285, -28
  %293 = add i64 %287, 6
  store i64 %293, i64* %PC, align 8
  %294 = inttoptr i64 %292 to i32*
  store i32 %290, i32* %294, align 4
  %295 = bitcast %union.VectorReg* %6 to double*
  %296 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %297 = bitcast i64* %296 to double*
  %.pre3 = load i64, i64* %PC, align 8
  br label %block_403591

block_403332:                                     ; preds = %block_403326
  %298 = add i64 %4829, 3
  store i64 %298, i64* %PC, align 8
  %299 = load i32, i32* %4796, align 4
  %300 = zext i32 %299 to i64
  store i64 %300, i64* %RAX, align 8, !tbaa !2428
  %301 = add i64 %4829, 6
  store i64 %301, i64* %PC, align 8
  %302 = load i32, i32* %4801, align 4
  %303 = add i32 %302, %299
  %304 = zext i32 %303 to i64
  store i64 %304, i64* %RAX, align 8, !tbaa !2428
  %305 = icmp ult i32 %303, %299
  %306 = icmp ult i32 %303, %302
  %307 = or i1 %305, %306
  %308 = zext i1 %307 to i8
  store i8 %308, i8* %18, align 1, !tbaa !2433
  %309 = and i32 %303, 255
  %310 = tail call i32 @llvm.ctpop.i32(i32 %309) #10
  %311 = trunc i32 %310 to i8
  %312 = and i8 %311, 1
  %313 = xor i8 %312, 1
  store i8 %313, i8* %25, align 1, !tbaa !2447
  %314 = xor i32 %302, %299
  %315 = xor i32 %314, %303
  %316 = lshr i32 %315, 4
  %317 = trunc i32 %316 to i8
  %318 = and i8 %317, 1
  store i8 %318, i8* %31, align 1, !tbaa !2451
  %319 = icmp eq i32 %303, 0
  %320 = zext i1 %319 to i8
  store i8 %320, i8* %34, align 1, !tbaa !2448
  %321 = lshr i32 %303, 31
  %322 = trunc i32 %321 to i8
  store i8 %322, i8* %37, align 1, !tbaa !2449
  %323 = lshr i32 %299, 31
  %324 = lshr i32 %302, 31
  %325 = xor i32 %321, %323
  %326 = xor i32 %321, %324
  %327 = add nuw nsw i32 %325, %326
  %328 = icmp eq i32 %327, 2
  %329 = zext i1 %328 to i8
  store i8 %329, i8* %43, align 1, !tbaa !2450
  %330 = add i64 %4793, -32
  %331 = add i64 %4829, 9
  store i64 %331, i64* %PC, align 8
  %332 = inttoptr i64 %330 to i32*
  store i32 %303, i32* %332, align 4
  %333 = load i64, i64* %RBP, align 8
  %334 = add i64 %333, -32
  %335 = load i64, i64* %PC, align 8
  %336 = add i64 %335, 3
  store i64 %336, i64* %PC, align 8
  %337 = inttoptr i64 %334 to i32*
  %338 = load i32, i32* %337, align 4
  %339 = zext i32 %338 to i64
  store i64 %339, i64* %RAX, align 8, !tbaa !2428
  %340 = add i64 %333, -8
  %341 = add i64 %335, 6
  store i64 %341, i64* %PC, align 8
  %342 = inttoptr i64 %340 to i32*
  %343 = load i32, i32* %342, align 4
  %344 = add i32 %343, %338
  %345 = zext i32 %344 to i64
  store i64 %345, i64* %RAX, align 8, !tbaa !2428
  %346 = icmp ult i32 %344, %338
  %347 = icmp ult i32 %344, %343
  %348 = or i1 %346, %347
  %349 = zext i1 %348 to i8
  store i8 %349, i8* %18, align 1, !tbaa !2433
  %350 = and i32 %344, 255
  %351 = tail call i32 @llvm.ctpop.i32(i32 %350) #10
  %352 = trunc i32 %351 to i8
  %353 = and i8 %352, 1
  %354 = xor i8 %353, 1
  store i8 %354, i8* %25, align 1, !tbaa !2447
  %355 = xor i32 %343, %338
  %356 = xor i32 %355, %344
  %357 = lshr i32 %356, 4
  %358 = trunc i32 %357 to i8
  %359 = and i8 %358, 1
  store i8 %359, i8* %31, align 1, !tbaa !2451
  %360 = icmp eq i32 %344, 0
  %361 = zext i1 %360 to i8
  store i8 %361, i8* %34, align 1, !tbaa !2448
  %362 = lshr i32 %344, 31
  %363 = trunc i32 %362 to i8
  store i8 %363, i8* %37, align 1, !tbaa !2449
  %364 = lshr i32 %338, 31
  %365 = lshr i32 %343, 31
  %366 = xor i32 %362, %364
  %367 = xor i32 %362, %365
  %368 = add nuw nsw i32 %366, %367
  %369 = icmp eq i32 %368, 2
  %370 = zext i1 %369 to i8
  store i8 %370, i8* %43, align 1, !tbaa !2450
  %371 = add i64 %333, -36
  %372 = add i64 %335, 9
  store i64 %372, i64* %PC, align 8
  %373 = inttoptr i64 %371 to i32*
  store i32 %344, i32* %373, align 4
  %374 = load i64, i64* %RBP, align 8
  %375 = add i64 %374, -36
  %376 = load i64, i64* %PC, align 8
  %377 = add i64 %376, 3
  store i64 %377, i64* %PC, align 8
  %378 = inttoptr i64 %375 to i32*
  %379 = load i32, i32* %378, align 4
  %380 = zext i32 %379 to i64
  store i64 %380, i64* %RAX, align 8, !tbaa !2428
  %381 = add i64 %374, -8
  %382 = add i64 %376, 6
  store i64 %382, i64* %PC, align 8
  %383 = inttoptr i64 %381 to i32*
  %384 = load i32, i32* %383, align 4
  %385 = add i32 %384, %379
  %386 = zext i32 %385 to i64
  store i64 %386, i64* %RAX, align 8, !tbaa !2428
  %387 = icmp ult i32 %385, %379
  %388 = icmp ult i32 %385, %384
  %389 = or i1 %387, %388
  %390 = zext i1 %389 to i8
  store i8 %390, i8* %18, align 1, !tbaa !2433
  %391 = and i32 %385, 255
  %392 = tail call i32 @llvm.ctpop.i32(i32 %391) #10
  %393 = trunc i32 %392 to i8
  %394 = and i8 %393, 1
  %395 = xor i8 %394, 1
  store i8 %395, i8* %25, align 1, !tbaa !2447
  %396 = xor i32 %384, %379
  %397 = xor i32 %396, %385
  %398 = lshr i32 %397, 4
  %399 = trunc i32 %398 to i8
  %400 = and i8 %399, 1
  store i8 %400, i8* %31, align 1, !tbaa !2451
  %401 = icmp eq i32 %385, 0
  %402 = zext i1 %401 to i8
  store i8 %402, i8* %34, align 1, !tbaa !2448
  %403 = lshr i32 %385, 31
  %404 = trunc i32 %403 to i8
  store i8 %404, i8* %37, align 1, !tbaa !2449
  %405 = lshr i32 %379, 31
  %406 = lshr i32 %384, 31
  %407 = xor i32 %403, %405
  %408 = xor i32 %403, %406
  %409 = add nuw nsw i32 %407, %408
  %410 = icmp eq i32 %409, 2
  %411 = zext i1 %410 to i8
  store i8 %411, i8* %43, align 1, !tbaa !2450
  %412 = add i64 %374, -40
  %413 = add i64 %376, 9
  store i64 %413, i64* %PC, align 8
  %414 = inttoptr i64 %412 to i32*
  store i32 %385, i32* %414, align 4
  %415 = load i64, i64* %RBP, align 8
  %416 = add i64 %415, -16
  %417 = load i64, i64* %PC, align 8
  %418 = add i64 %417, 4
  store i64 %418, i64* %PC, align 8
  %419 = inttoptr i64 %416 to i64*
  %420 = load i64, i64* %419, align 8
  store i64 %420, i64* %RCX, align 8, !tbaa !2428
  %421 = add i64 %415, -28
  %422 = add i64 %417, 8
  store i64 %422, i64* %PC, align 8
  %423 = inttoptr i64 %421 to i32*
  %424 = load i32, i32* %423, align 4
  %425 = sext i32 %424 to i64
  store i64 %425, i64* %RDX, align 8, !tbaa !2428
  %426 = shl nsw i64 %425, 3
  %427 = add i64 %426, %420
  %428 = add i64 %417, 13
  store i64 %428, i64* %PC, align 8
  %429 = inttoptr i64 %427 to double*
  %430 = load double, double* %429, align 8
  store double %430, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %431 = add i64 %417, 17
  store i64 %431, i64* %PC, align 8
  %432 = load i64, i64* %419, align 8
  store i64 %432, i64* %RCX, align 8, !tbaa !2428
  %433 = add i64 %415, -32
  %434 = add i64 %417, 21
  store i64 %434, i64* %PC, align 8
  %435 = inttoptr i64 %433 to i32*
  %436 = load i32, i32* %435, align 4
  %437 = sext i32 %436 to i64
  store i64 %437, i64* %RDX, align 8, !tbaa !2428
  %438 = shl nsw i64 %437, 3
  %439 = add i64 %438, %432
  %440 = add i64 %417, 26
  store i64 %440, i64* %PC, align 8
  %441 = inttoptr i64 %439 to double*
  %442 = load double, double* %441, align 8
  %443 = fadd double %430, %442
  store double %443, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %444 = add i64 %415, -120
  %445 = add i64 %417, 31
  store i64 %445, i64* %PC, align 8
  %446 = inttoptr i64 %444 to double*
  store double %443, double* %446, align 8
  %447 = load i64, i64* %RBP, align 8
  %448 = add i64 %447, -16
  %449 = load i64, i64* %PC, align 8
  %450 = add i64 %449, 4
  store i64 %450, i64* %PC, align 8
  %451 = inttoptr i64 %448 to i64*
  %452 = load i64, i64* %451, align 8
  store i64 %452, i64* %RCX, align 8, !tbaa !2428
  %453 = add i64 %447, -28
  %454 = add i64 %449, 7
  store i64 %454, i64* %PC, align 8
  %455 = inttoptr i64 %453 to i32*
  %456 = load i32, i32* %455, align 4
  %457 = add i32 %456, 1
  %458 = zext i32 %457 to i64
  store i64 %458, i64* %RAX, align 8, !tbaa !2428
  %459 = icmp eq i32 %456, -1
  %460 = icmp eq i32 %457, 0
  %461 = or i1 %459, %460
  %462 = zext i1 %461 to i8
  store i8 %462, i8* %18, align 1, !tbaa !2433
  %463 = and i32 %457, 255
  %464 = tail call i32 @llvm.ctpop.i32(i32 %463) #10
  %465 = trunc i32 %464 to i8
  %466 = and i8 %465, 1
  %467 = xor i8 %466, 1
  store i8 %467, i8* %25, align 1, !tbaa !2447
  %468 = xor i32 %456, %457
  %469 = lshr i32 %468, 4
  %470 = trunc i32 %469 to i8
  %471 = and i8 %470, 1
  store i8 %471, i8* %31, align 1, !tbaa !2451
  %472 = icmp eq i32 %457, 0
  %473 = zext i1 %472 to i8
  store i8 %473, i8* %34, align 1, !tbaa !2448
  %474 = lshr i32 %457, 31
  %475 = trunc i32 %474 to i8
  store i8 %475, i8* %37, align 1, !tbaa !2449
  %476 = lshr i32 %456, 31
  %477 = xor i32 %474, %476
  %478 = add nuw nsw i32 %477, %474
  %479 = icmp eq i32 %478, 2
  %480 = zext i1 %479 to i8
  store i8 %480, i8* %43, align 1, !tbaa !2450
  %481 = sext i32 %457 to i64
  store i64 %481, i64* %RDX, align 8, !tbaa !2428
  %482 = shl nsw i64 %481, 3
  %483 = add i64 %482, %452
  %484 = add i64 %449, 18
  store i64 %484, i64* %PC, align 8
  %485 = inttoptr i64 %483 to double*
  %486 = load double, double* %485, align 8
  store double %486, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %487 = add i64 %449, 22
  store i64 %487, i64* %PC, align 8
  %488 = load i64, i64* %451, align 8
  store i64 %488, i64* %RCX, align 8, !tbaa !2428
  %489 = add i64 %447, -32
  %490 = add i64 %449, 25
  store i64 %490, i64* %PC, align 8
  %491 = inttoptr i64 %489 to i32*
  %492 = load i32, i32* %491, align 4
  %493 = add i32 %492, 1
  %494 = zext i32 %493 to i64
  store i64 %494, i64* %RAX, align 8, !tbaa !2428
  %495 = icmp eq i32 %492, -1
  %496 = icmp eq i32 %493, 0
  %497 = or i1 %495, %496
  %498 = zext i1 %497 to i8
  store i8 %498, i8* %18, align 1, !tbaa !2433
  %499 = and i32 %493, 255
  %500 = tail call i32 @llvm.ctpop.i32(i32 %499) #10
  %501 = trunc i32 %500 to i8
  %502 = and i8 %501, 1
  %503 = xor i8 %502, 1
  store i8 %503, i8* %25, align 1, !tbaa !2447
  %504 = xor i32 %492, %493
  %505 = lshr i32 %504, 4
  %506 = trunc i32 %505 to i8
  %507 = and i8 %506, 1
  store i8 %507, i8* %31, align 1, !tbaa !2451
  %508 = icmp eq i32 %493, 0
  %509 = zext i1 %508 to i8
  store i8 %509, i8* %34, align 1, !tbaa !2448
  %510 = lshr i32 %493, 31
  %511 = trunc i32 %510 to i8
  store i8 %511, i8* %37, align 1, !tbaa !2449
  %512 = lshr i32 %492, 31
  %513 = xor i32 %510, %512
  %514 = add nuw nsw i32 %513, %510
  %515 = icmp eq i32 %514, 2
  %516 = zext i1 %515 to i8
  store i8 %516, i8* %43, align 1, !tbaa !2450
  %517 = sext i32 %493 to i64
  store i64 %517, i64* %RDX, align 8, !tbaa !2428
  %518 = shl nsw i64 %517, 3
  %519 = add i64 %518, %488
  %520 = add i64 %449, 36
  store i64 %520, i64* %PC, align 8
  %521 = inttoptr i64 %519 to double*
  %522 = load double, double* %521, align 8
  %523 = fadd double %486, %522
  store double %523, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %524 = load i64, i64* %RBP, align 8
  %525 = add i64 %524, -128
  %526 = add i64 %449, 41
  store i64 %526, i64* %PC, align 8
  %527 = inttoptr i64 %525 to double*
  store double %523, double* %527, align 8
  %528 = load i64, i64* %RBP, align 8
  %529 = add i64 %528, -16
  %530 = load i64, i64* %PC, align 8
  %531 = add i64 %530, 4
  store i64 %531, i64* %PC, align 8
  %532 = inttoptr i64 %529 to i64*
  %533 = load i64, i64* %532, align 8
  store i64 %533, i64* %RCX, align 8, !tbaa !2428
  %534 = add i64 %528, -28
  %535 = add i64 %530, 8
  store i64 %535, i64* %PC, align 8
  %536 = inttoptr i64 %534 to i32*
  %537 = load i32, i32* %536, align 4
  %538 = sext i32 %537 to i64
  store i64 %538, i64* %RDX, align 8, !tbaa !2428
  %539 = shl nsw i64 %538, 3
  %540 = add i64 %539, %533
  %541 = add i64 %530, 13
  store i64 %541, i64* %PC, align 8
  %542 = inttoptr i64 %540 to double*
  %543 = load double, double* %542, align 8
  store double %543, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %544 = add i64 %530, 17
  store i64 %544, i64* %PC, align 8
  %545 = load i64, i64* %532, align 8
  store i64 %545, i64* %RCX, align 8, !tbaa !2428
  %546 = add i64 %528, -32
  %547 = add i64 %530, 21
  store i64 %547, i64* %PC, align 8
  %548 = inttoptr i64 %546 to i32*
  %549 = load i32, i32* %548, align 4
  %550 = sext i32 %549 to i64
  store i64 %550, i64* %RDX, align 8, !tbaa !2428
  %551 = shl nsw i64 %550, 3
  %552 = add i64 %551, %545
  %553 = add i64 %530, 26
  store i64 %553, i64* %PC, align 8
  %554 = inttoptr i64 %552 to double*
  %555 = load double, double* %554, align 8
  %556 = fsub double %543, %555
  store double %556, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %557 = add i64 %528, -136
  %558 = add i64 %530, 34
  store i64 %558, i64* %PC, align 8
  %559 = inttoptr i64 %557 to double*
  store double %556, double* %559, align 8
  %560 = load i64, i64* %RBP, align 8
  %561 = add i64 %560, -16
  %562 = load i64, i64* %PC, align 8
  %563 = add i64 %562, 4
  store i64 %563, i64* %PC, align 8
  %564 = inttoptr i64 %561 to i64*
  %565 = load i64, i64* %564, align 8
  store i64 %565, i64* %RCX, align 8, !tbaa !2428
  %566 = add i64 %560, -28
  %567 = add i64 %562, 7
  store i64 %567, i64* %PC, align 8
  %568 = inttoptr i64 %566 to i32*
  %569 = load i32, i32* %568, align 4
  %570 = add i32 %569, 1
  %571 = zext i32 %570 to i64
  store i64 %571, i64* %RAX, align 8, !tbaa !2428
  %572 = icmp eq i32 %569, -1
  %573 = icmp eq i32 %570, 0
  %574 = or i1 %572, %573
  %575 = zext i1 %574 to i8
  store i8 %575, i8* %18, align 1, !tbaa !2433
  %576 = and i32 %570, 255
  %577 = tail call i32 @llvm.ctpop.i32(i32 %576) #10
  %578 = trunc i32 %577 to i8
  %579 = and i8 %578, 1
  %580 = xor i8 %579, 1
  store i8 %580, i8* %25, align 1, !tbaa !2447
  %581 = xor i32 %569, %570
  %582 = lshr i32 %581, 4
  %583 = trunc i32 %582 to i8
  %584 = and i8 %583, 1
  store i8 %584, i8* %31, align 1, !tbaa !2451
  %585 = icmp eq i32 %570, 0
  %586 = zext i1 %585 to i8
  store i8 %586, i8* %34, align 1, !tbaa !2448
  %587 = lshr i32 %570, 31
  %588 = trunc i32 %587 to i8
  store i8 %588, i8* %37, align 1, !tbaa !2449
  %589 = lshr i32 %569, 31
  %590 = xor i32 %587, %589
  %591 = add nuw nsw i32 %590, %587
  %592 = icmp eq i32 %591, 2
  %593 = zext i1 %592 to i8
  store i8 %593, i8* %43, align 1, !tbaa !2450
  %594 = sext i32 %570 to i64
  store i64 %594, i64* %RDX, align 8, !tbaa !2428
  %595 = shl nsw i64 %594, 3
  %596 = add i64 %595, %565
  %597 = add i64 %562, 18
  store i64 %597, i64* %PC, align 8
  %598 = inttoptr i64 %596 to double*
  %599 = load double, double* %598, align 8
  store double %599, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %600 = add i64 %562, 22
  store i64 %600, i64* %PC, align 8
  %601 = load i64, i64* %564, align 8
  store i64 %601, i64* %RCX, align 8, !tbaa !2428
  %602 = add i64 %560, -32
  %603 = add i64 %562, 25
  store i64 %603, i64* %PC, align 8
  %604 = inttoptr i64 %602 to i32*
  %605 = load i32, i32* %604, align 4
  %606 = add i32 %605, 1
  %607 = zext i32 %606 to i64
  store i64 %607, i64* %RAX, align 8, !tbaa !2428
  %608 = icmp eq i32 %605, -1
  %609 = icmp eq i32 %606, 0
  %610 = or i1 %608, %609
  %611 = zext i1 %610 to i8
  store i8 %611, i8* %18, align 1, !tbaa !2433
  %612 = and i32 %606, 255
  %613 = tail call i32 @llvm.ctpop.i32(i32 %612) #10
  %614 = trunc i32 %613 to i8
  %615 = and i8 %614, 1
  %616 = xor i8 %615, 1
  store i8 %616, i8* %25, align 1, !tbaa !2447
  %617 = xor i32 %605, %606
  %618 = lshr i32 %617, 4
  %619 = trunc i32 %618 to i8
  %620 = and i8 %619, 1
  store i8 %620, i8* %31, align 1, !tbaa !2451
  %621 = icmp eq i32 %606, 0
  %622 = zext i1 %621 to i8
  store i8 %622, i8* %34, align 1, !tbaa !2448
  %623 = lshr i32 %606, 31
  %624 = trunc i32 %623 to i8
  store i8 %624, i8* %37, align 1, !tbaa !2449
  %625 = lshr i32 %605, 31
  %626 = xor i32 %623, %625
  %627 = add nuw nsw i32 %626, %623
  %628 = icmp eq i32 %627, 2
  %629 = zext i1 %628 to i8
  store i8 %629, i8* %43, align 1, !tbaa !2450
  %630 = sext i32 %606 to i64
  store i64 %630, i64* %RDX, align 8, !tbaa !2428
  %631 = shl nsw i64 %630, 3
  %632 = add i64 %631, %601
  %633 = add i64 %562, 36
  store i64 %633, i64* %PC, align 8
  %634 = inttoptr i64 %632 to double*
  %635 = load double, double* %634, align 8
  %636 = fsub double %599, %635
  store double %636, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %637 = load i64, i64* %RBP, align 8
  %638 = add i64 %637, -144
  %639 = add i64 %562, 44
  store i64 %639, i64* %PC, align 8
  %640 = inttoptr i64 %638 to double*
  store double %636, double* %640, align 8
  %641 = load i64, i64* %RBP, align 8
  %642 = add i64 %641, -16
  %643 = load i64, i64* %PC, align 8
  %644 = add i64 %643, 4
  store i64 %644, i64* %PC, align 8
  %645 = inttoptr i64 %642 to i64*
  %646 = load i64, i64* %645, align 8
  store i64 %646, i64* %RCX, align 8, !tbaa !2428
  %647 = add i64 %641, -36
  %648 = add i64 %643, 8
  store i64 %648, i64* %PC, align 8
  %649 = inttoptr i64 %647 to i32*
  %650 = load i32, i32* %649, align 4
  %651 = sext i32 %650 to i64
  store i64 %651, i64* %RDX, align 8, !tbaa !2428
  %652 = shl nsw i64 %651, 3
  %653 = add i64 %652, %646
  %654 = add i64 %643, 13
  store i64 %654, i64* %PC, align 8
  %655 = inttoptr i64 %653 to double*
  %656 = load double, double* %655, align 8
  store double %656, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %657 = add i64 %643, 17
  store i64 %657, i64* %PC, align 8
  %658 = load i64, i64* %645, align 8
  store i64 %658, i64* %RCX, align 8, !tbaa !2428
  %659 = add i64 %641, -40
  %660 = add i64 %643, 21
  store i64 %660, i64* %PC, align 8
  %661 = inttoptr i64 %659 to i32*
  %662 = load i32, i32* %661, align 4
  %663 = sext i32 %662 to i64
  store i64 %663, i64* %RDX, align 8, !tbaa !2428
  %664 = shl nsw i64 %663, 3
  %665 = add i64 %664, %658
  %666 = add i64 %643, 26
  store i64 %666, i64* %PC, align 8
  %667 = inttoptr i64 %665 to double*
  %668 = load double, double* %667, align 8
  %669 = fadd double %656, %668
  store double %669, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %670 = add i64 %641, -152
  %671 = add i64 %643, 34
  store i64 %671, i64* %PC, align 8
  %672 = inttoptr i64 %670 to double*
  store double %669, double* %672, align 8
  %673 = load i64, i64* %RBP, align 8
  %674 = add i64 %673, -16
  %675 = load i64, i64* %PC, align 8
  %676 = add i64 %675, 4
  store i64 %676, i64* %PC, align 8
  %677 = inttoptr i64 %674 to i64*
  %678 = load i64, i64* %677, align 8
  store i64 %678, i64* %RCX, align 8, !tbaa !2428
  %679 = add i64 %673, -36
  %680 = add i64 %675, 7
  store i64 %680, i64* %PC, align 8
  %681 = inttoptr i64 %679 to i32*
  %682 = load i32, i32* %681, align 4
  %683 = add i32 %682, 1
  %684 = zext i32 %683 to i64
  store i64 %684, i64* %RAX, align 8, !tbaa !2428
  %685 = icmp eq i32 %682, -1
  %686 = icmp eq i32 %683, 0
  %687 = or i1 %685, %686
  %688 = zext i1 %687 to i8
  store i8 %688, i8* %18, align 1, !tbaa !2433
  %689 = and i32 %683, 255
  %690 = tail call i32 @llvm.ctpop.i32(i32 %689) #10
  %691 = trunc i32 %690 to i8
  %692 = and i8 %691, 1
  %693 = xor i8 %692, 1
  store i8 %693, i8* %25, align 1, !tbaa !2447
  %694 = xor i32 %682, %683
  %695 = lshr i32 %694, 4
  %696 = trunc i32 %695 to i8
  %697 = and i8 %696, 1
  store i8 %697, i8* %31, align 1, !tbaa !2451
  %698 = icmp eq i32 %683, 0
  %699 = zext i1 %698 to i8
  store i8 %699, i8* %34, align 1, !tbaa !2448
  %700 = lshr i32 %683, 31
  %701 = trunc i32 %700 to i8
  store i8 %701, i8* %37, align 1, !tbaa !2449
  %702 = lshr i32 %682, 31
  %703 = xor i32 %700, %702
  %704 = add nuw nsw i32 %703, %700
  %705 = icmp eq i32 %704, 2
  %706 = zext i1 %705 to i8
  store i8 %706, i8* %43, align 1, !tbaa !2450
  %707 = sext i32 %683 to i64
  store i64 %707, i64* %RDX, align 8, !tbaa !2428
  %708 = shl nsw i64 %707, 3
  %709 = add i64 %708, %678
  %710 = add i64 %675, 18
  store i64 %710, i64* %PC, align 8
  %711 = inttoptr i64 %709 to double*
  %712 = load double, double* %711, align 8
  store double %712, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %713 = add i64 %675, 22
  store i64 %713, i64* %PC, align 8
  %714 = load i64, i64* %677, align 8
  store i64 %714, i64* %RCX, align 8, !tbaa !2428
  %715 = add i64 %673, -40
  %716 = add i64 %675, 25
  store i64 %716, i64* %PC, align 8
  %717 = inttoptr i64 %715 to i32*
  %718 = load i32, i32* %717, align 4
  %719 = add i32 %718, 1
  %720 = zext i32 %719 to i64
  store i64 %720, i64* %RAX, align 8, !tbaa !2428
  %721 = icmp eq i32 %718, -1
  %722 = icmp eq i32 %719, 0
  %723 = or i1 %721, %722
  %724 = zext i1 %723 to i8
  store i8 %724, i8* %18, align 1, !tbaa !2433
  %725 = and i32 %719, 255
  %726 = tail call i32 @llvm.ctpop.i32(i32 %725) #10
  %727 = trunc i32 %726 to i8
  %728 = and i8 %727, 1
  %729 = xor i8 %728, 1
  store i8 %729, i8* %25, align 1, !tbaa !2447
  %730 = xor i32 %718, %719
  %731 = lshr i32 %730, 4
  %732 = trunc i32 %731 to i8
  %733 = and i8 %732, 1
  store i8 %733, i8* %31, align 1, !tbaa !2451
  %734 = icmp eq i32 %719, 0
  %735 = zext i1 %734 to i8
  store i8 %735, i8* %34, align 1, !tbaa !2448
  %736 = lshr i32 %719, 31
  %737 = trunc i32 %736 to i8
  store i8 %737, i8* %37, align 1, !tbaa !2449
  %738 = lshr i32 %718, 31
  %739 = xor i32 %736, %738
  %740 = add nuw nsw i32 %739, %736
  %741 = icmp eq i32 %740, 2
  %742 = zext i1 %741 to i8
  store i8 %742, i8* %43, align 1, !tbaa !2450
  %743 = sext i32 %719 to i64
  store i64 %743, i64* %RDX, align 8, !tbaa !2428
  %744 = shl nsw i64 %743, 3
  %745 = add i64 %744, %714
  %746 = add i64 %675, 36
  store i64 %746, i64* %PC, align 8
  %747 = inttoptr i64 %745 to double*
  %748 = load double, double* %747, align 8
  %749 = fadd double %712, %748
  store double %749, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %750 = load i64, i64* %RBP, align 8
  %751 = add i64 %750, -160
  %752 = add i64 %675, 44
  store i64 %752, i64* %PC, align 8
  %753 = inttoptr i64 %751 to double*
  store double %749, double* %753, align 8
  %754 = load i64, i64* %RBP, align 8
  %755 = add i64 %754, -16
  %756 = load i64, i64* %PC, align 8
  %757 = add i64 %756, 4
  store i64 %757, i64* %PC, align 8
  %758 = inttoptr i64 %755 to i64*
  %759 = load i64, i64* %758, align 8
  store i64 %759, i64* %RCX, align 8, !tbaa !2428
  %760 = add i64 %754, -36
  %761 = add i64 %756, 8
  store i64 %761, i64* %PC, align 8
  %762 = inttoptr i64 %760 to i32*
  %763 = load i32, i32* %762, align 4
  %764 = sext i32 %763 to i64
  store i64 %764, i64* %RDX, align 8, !tbaa !2428
  %765 = shl nsw i64 %764, 3
  %766 = add i64 %765, %759
  %767 = add i64 %756, 13
  store i64 %767, i64* %PC, align 8
  %768 = inttoptr i64 %766 to double*
  %769 = load double, double* %768, align 8
  store double %769, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %770 = add i64 %756, 17
  store i64 %770, i64* %PC, align 8
  %771 = load i64, i64* %758, align 8
  store i64 %771, i64* %RCX, align 8, !tbaa !2428
  %772 = add i64 %754, -40
  %773 = add i64 %756, 21
  store i64 %773, i64* %PC, align 8
  %774 = inttoptr i64 %772 to i32*
  %775 = load i32, i32* %774, align 4
  %776 = sext i32 %775 to i64
  store i64 %776, i64* %RDX, align 8, !tbaa !2428
  %777 = shl nsw i64 %776, 3
  %778 = add i64 %777, %771
  %779 = add i64 %756, 26
  store i64 %779, i64* %PC, align 8
  %780 = inttoptr i64 %778 to double*
  %781 = load double, double* %780, align 8
  %782 = fsub double %769, %781
  store double %782, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %783 = add i64 %754, -168
  %784 = add i64 %756, 34
  store i64 %784, i64* %PC, align 8
  %785 = inttoptr i64 %783 to double*
  store double %782, double* %785, align 8
  %786 = load i64, i64* %RBP, align 8
  %787 = add i64 %786, -16
  %788 = load i64, i64* %PC, align 8
  %789 = add i64 %788, 4
  store i64 %789, i64* %PC, align 8
  %790 = inttoptr i64 %787 to i64*
  %791 = load i64, i64* %790, align 8
  store i64 %791, i64* %RCX, align 8, !tbaa !2428
  %792 = add i64 %786, -36
  %793 = add i64 %788, 7
  store i64 %793, i64* %PC, align 8
  %794 = inttoptr i64 %792 to i32*
  %795 = load i32, i32* %794, align 4
  %796 = add i32 %795, 1
  %797 = zext i32 %796 to i64
  store i64 %797, i64* %RAX, align 8, !tbaa !2428
  %798 = icmp eq i32 %795, -1
  %799 = icmp eq i32 %796, 0
  %800 = or i1 %798, %799
  %801 = zext i1 %800 to i8
  store i8 %801, i8* %18, align 1, !tbaa !2433
  %802 = and i32 %796, 255
  %803 = tail call i32 @llvm.ctpop.i32(i32 %802) #10
  %804 = trunc i32 %803 to i8
  %805 = and i8 %804, 1
  %806 = xor i8 %805, 1
  store i8 %806, i8* %25, align 1, !tbaa !2447
  %807 = xor i32 %795, %796
  %808 = lshr i32 %807, 4
  %809 = trunc i32 %808 to i8
  %810 = and i8 %809, 1
  store i8 %810, i8* %31, align 1, !tbaa !2451
  %811 = icmp eq i32 %796, 0
  %812 = zext i1 %811 to i8
  store i8 %812, i8* %34, align 1, !tbaa !2448
  %813 = lshr i32 %796, 31
  %814 = trunc i32 %813 to i8
  store i8 %814, i8* %37, align 1, !tbaa !2449
  %815 = lshr i32 %795, 31
  %816 = xor i32 %813, %815
  %817 = add nuw nsw i32 %816, %813
  %818 = icmp eq i32 %817, 2
  %819 = zext i1 %818 to i8
  store i8 %819, i8* %43, align 1, !tbaa !2450
  %820 = sext i32 %796 to i64
  store i64 %820, i64* %RDX, align 8, !tbaa !2428
  %821 = shl nsw i64 %820, 3
  %822 = add i64 %821, %791
  %823 = add i64 %788, 18
  store i64 %823, i64* %PC, align 8
  %824 = inttoptr i64 %822 to double*
  %825 = load double, double* %824, align 8
  store double %825, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %826 = add i64 %788, 22
  store i64 %826, i64* %PC, align 8
  %827 = load i64, i64* %790, align 8
  store i64 %827, i64* %RCX, align 8, !tbaa !2428
  %828 = add i64 %786, -40
  %829 = add i64 %788, 25
  store i64 %829, i64* %PC, align 8
  %830 = inttoptr i64 %828 to i32*
  %831 = load i32, i32* %830, align 4
  %832 = add i32 %831, 1
  %833 = zext i32 %832 to i64
  store i64 %833, i64* %RAX, align 8, !tbaa !2428
  %834 = icmp eq i32 %831, -1
  %835 = icmp eq i32 %832, 0
  %836 = or i1 %834, %835
  %837 = zext i1 %836 to i8
  store i8 %837, i8* %18, align 1, !tbaa !2433
  %838 = and i32 %832, 255
  %839 = tail call i32 @llvm.ctpop.i32(i32 %838) #10
  %840 = trunc i32 %839 to i8
  %841 = and i8 %840, 1
  %842 = xor i8 %841, 1
  store i8 %842, i8* %25, align 1, !tbaa !2447
  %843 = xor i32 %831, %832
  %844 = lshr i32 %843, 4
  %845 = trunc i32 %844 to i8
  %846 = and i8 %845, 1
  store i8 %846, i8* %31, align 1, !tbaa !2451
  %847 = icmp eq i32 %832, 0
  %848 = zext i1 %847 to i8
  store i8 %848, i8* %34, align 1, !tbaa !2448
  %849 = lshr i32 %832, 31
  %850 = trunc i32 %849 to i8
  store i8 %850, i8* %37, align 1, !tbaa !2449
  %851 = lshr i32 %831, 31
  %852 = xor i32 %849, %851
  %853 = add nuw nsw i32 %852, %849
  %854 = icmp eq i32 %853, 2
  %855 = zext i1 %854 to i8
  store i8 %855, i8* %43, align 1, !tbaa !2450
  %856 = sext i32 %832 to i64
  store i64 %856, i64* %RDX, align 8, !tbaa !2428
  %857 = shl nsw i64 %856, 3
  %858 = add i64 %857, %827
  %859 = add i64 %788, 36
  store i64 %859, i64* %PC, align 8
  %860 = inttoptr i64 %858 to double*
  %861 = load double, double* %860, align 8
  %862 = fsub double %825, %861
  store double %862, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %863 = load i64, i64* %RBP, align 8
  %864 = add i64 %863, -176
  %865 = add i64 %788, 44
  store i64 %865, i64* %PC, align 8
  %866 = inttoptr i64 %864 to double*
  store double %862, double* %866, align 8
  %867 = load i64, i64* %RBP, align 8
  %868 = add i64 %867, -120
  %869 = load i64, i64* %PC, align 8
  %870 = add i64 %869, 5
  store i64 %870, i64* %PC, align 8
  %871 = inttoptr i64 %868 to double*
  %872 = load double, double* %871, align 8
  store double %872, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %873 = add i64 %867, -152
  %874 = add i64 %869, 13
  store i64 %874, i64* %PC, align 8
  %875 = inttoptr i64 %873 to double*
  %876 = load double, double* %875, align 8
  %877 = fadd double %872, %876
  store double %877, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %878 = add i64 %867, -16
  %879 = add i64 %869, 17
  store i64 %879, i64* %PC, align 8
  %880 = inttoptr i64 %878 to i64*
  %881 = load i64, i64* %880, align 8
  store i64 %881, i64* %RCX, align 8, !tbaa !2428
  %882 = add i64 %867, -28
  %883 = add i64 %869, 21
  store i64 %883, i64* %PC, align 8
  %884 = inttoptr i64 %882 to i32*
  %885 = load i32, i32* %884, align 4
  %886 = sext i32 %885 to i64
  store i64 %886, i64* %RDX, align 8, !tbaa !2428
  %887 = shl nsw i64 %886, 3
  %888 = add i64 %887, %881
  %889 = add i64 %869, 26
  store i64 %889, i64* %PC, align 8
  %890 = inttoptr i64 %888 to double*
  store double %877, double* %890, align 8
  %891 = load i64, i64* %RBP, align 8
  %892 = add i64 %891, -128
  %893 = load i64, i64* %PC, align 8
  %894 = add i64 %893, 5
  store i64 %894, i64* %PC, align 8
  %895 = inttoptr i64 %892 to double*
  %896 = load double, double* %895, align 8
  store double %896, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %897 = add i64 %891, -160
  %898 = add i64 %893, 13
  store i64 %898, i64* %PC, align 8
  %899 = inttoptr i64 %897 to double*
  %900 = load double, double* %899, align 8
  %901 = fadd double %896, %900
  store double %901, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %902 = add i64 %891, -16
  %903 = add i64 %893, 17
  store i64 %903, i64* %PC, align 8
  %904 = inttoptr i64 %902 to i64*
  %905 = load i64, i64* %904, align 8
  store i64 %905, i64* %RCX, align 8, !tbaa !2428
  %906 = add i64 %891, -28
  %907 = add i64 %893, 20
  store i64 %907, i64* %PC, align 8
  %908 = inttoptr i64 %906 to i32*
  %909 = load i32, i32* %908, align 4
  %910 = add i32 %909, 1
  %911 = zext i32 %910 to i64
  store i64 %911, i64* %RAX, align 8, !tbaa !2428
  %912 = icmp eq i32 %909, -1
  %913 = icmp eq i32 %910, 0
  %914 = or i1 %912, %913
  %915 = zext i1 %914 to i8
  store i8 %915, i8* %18, align 1, !tbaa !2433
  %916 = and i32 %910, 255
  %917 = tail call i32 @llvm.ctpop.i32(i32 %916) #10
  %918 = trunc i32 %917 to i8
  %919 = and i8 %918, 1
  %920 = xor i8 %919, 1
  store i8 %920, i8* %25, align 1, !tbaa !2447
  %921 = xor i32 %909, %910
  %922 = lshr i32 %921, 4
  %923 = trunc i32 %922 to i8
  %924 = and i8 %923, 1
  store i8 %924, i8* %31, align 1, !tbaa !2451
  %925 = icmp eq i32 %910, 0
  %926 = zext i1 %925 to i8
  store i8 %926, i8* %34, align 1, !tbaa !2448
  %927 = lshr i32 %910, 31
  %928 = trunc i32 %927 to i8
  store i8 %928, i8* %37, align 1, !tbaa !2449
  %929 = lshr i32 %909, 31
  %930 = xor i32 %927, %929
  %931 = add nuw nsw i32 %930, %927
  %932 = icmp eq i32 %931, 2
  %933 = zext i1 %932 to i8
  store i8 %933, i8* %43, align 1, !tbaa !2450
  %934 = sext i32 %910 to i64
  store i64 %934, i64* %RDX, align 8, !tbaa !2428
  %935 = shl nsw i64 %934, 3
  %936 = add i64 %935, %905
  %937 = add i64 %893, 31
  store i64 %937, i64* %PC, align 8
  %938 = inttoptr i64 %936 to double*
  store double %901, double* %938, align 8
  %939 = load i64, i64* %RBP, align 8
  %940 = add i64 %939, -120
  %941 = load i64, i64* %PC, align 8
  %942 = add i64 %941, 5
  store i64 %942, i64* %PC, align 8
  %943 = inttoptr i64 %940 to double*
  %944 = load double, double* %943, align 8
  store double %944, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %945 = add i64 %939, -152
  %946 = add i64 %941, 13
  store i64 %946, i64* %PC, align 8
  %947 = inttoptr i64 %945 to double*
  %948 = load double, double* %947, align 8
  %949 = fsub double %944, %948
  store double %949, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %950 = add i64 %939, -16
  %951 = add i64 %941, 17
  store i64 %951, i64* %PC, align 8
  %952 = inttoptr i64 %950 to i64*
  %953 = load i64, i64* %952, align 8
  store i64 %953, i64* %RCX, align 8, !tbaa !2428
  %954 = add i64 %939, -36
  %955 = add i64 %941, 21
  store i64 %955, i64* %PC, align 8
  %956 = inttoptr i64 %954 to i32*
  %957 = load i32, i32* %956, align 4
  %958 = sext i32 %957 to i64
  store i64 %958, i64* %RDX, align 8, !tbaa !2428
  %959 = shl nsw i64 %958, 3
  %960 = add i64 %959, %953
  %961 = add i64 %941, 26
  store i64 %961, i64* %PC, align 8
  %962 = inttoptr i64 %960 to double*
  store double %949, double* %962, align 8
  %963 = load i64, i64* %RBP, align 8
  %964 = add i64 %963, -128
  %965 = load i64, i64* %PC, align 8
  %966 = add i64 %965, 5
  store i64 %966, i64* %PC, align 8
  %967 = inttoptr i64 %964 to double*
  %968 = load double, double* %967, align 8
  store double %968, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %969 = add i64 %963, -160
  %970 = add i64 %965, 13
  store i64 %970, i64* %PC, align 8
  %971 = inttoptr i64 %969 to double*
  %972 = load double, double* %971, align 8
  %973 = fsub double %968, %972
  store double %973, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %974 = add i64 %963, -16
  %975 = add i64 %965, 17
  store i64 %975, i64* %PC, align 8
  %976 = inttoptr i64 %974 to i64*
  %977 = load i64, i64* %976, align 8
  store i64 %977, i64* %RCX, align 8, !tbaa !2428
  %978 = add i64 %963, -36
  %979 = add i64 %965, 20
  store i64 %979, i64* %PC, align 8
  %980 = inttoptr i64 %978 to i32*
  %981 = load i32, i32* %980, align 4
  %982 = add i32 %981, 1
  %983 = zext i32 %982 to i64
  store i64 %983, i64* %RAX, align 8, !tbaa !2428
  %984 = icmp eq i32 %981, -1
  %985 = icmp eq i32 %982, 0
  %986 = or i1 %984, %985
  %987 = zext i1 %986 to i8
  store i8 %987, i8* %18, align 1, !tbaa !2433
  %988 = and i32 %982, 255
  %989 = tail call i32 @llvm.ctpop.i32(i32 %988) #10
  %990 = trunc i32 %989 to i8
  %991 = and i8 %990, 1
  %992 = xor i8 %991, 1
  store i8 %992, i8* %25, align 1, !tbaa !2447
  %993 = xor i32 %981, %982
  %994 = lshr i32 %993, 4
  %995 = trunc i32 %994 to i8
  %996 = and i8 %995, 1
  store i8 %996, i8* %31, align 1, !tbaa !2451
  %997 = icmp eq i32 %982, 0
  %998 = zext i1 %997 to i8
  store i8 %998, i8* %34, align 1, !tbaa !2448
  %999 = lshr i32 %982, 31
  %1000 = trunc i32 %999 to i8
  store i8 %1000, i8* %37, align 1, !tbaa !2449
  %1001 = lshr i32 %981, 31
  %1002 = xor i32 %999, %1001
  %1003 = add nuw nsw i32 %1002, %999
  %1004 = icmp eq i32 %1003, 2
  %1005 = zext i1 %1004 to i8
  store i8 %1005, i8* %43, align 1, !tbaa !2450
  %1006 = sext i32 %982 to i64
  store i64 %1006, i64* %RDX, align 8, !tbaa !2428
  %1007 = shl nsw i64 %1006, 3
  %1008 = add i64 %1007, %977
  %1009 = add i64 %965, 31
  store i64 %1009, i64* %PC, align 8
  %1010 = inttoptr i64 %1008 to double*
  store double %973, double* %1010, align 8
  %1011 = load i64, i64* %RBP, align 8
  %1012 = add i64 %1011, -136
  %1013 = load i64, i64* %PC, align 8
  %1014 = add i64 %1013, 8
  store i64 %1014, i64* %PC, align 8
  %1015 = inttoptr i64 %1012 to double*
  %1016 = load double, double* %1015, align 8
  store double %1016, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %1017 = add i64 %1011, -176
  %1018 = add i64 %1013, 16
  store i64 %1018, i64* %PC, align 8
  %1019 = inttoptr i64 %1017 to double*
  %1020 = load double, double* %1019, align 8
  %1021 = fsub double %1016, %1020
  store double %1021, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %1022 = add i64 %1011, -16
  %1023 = add i64 %1013, 20
  store i64 %1023, i64* %PC, align 8
  %1024 = inttoptr i64 %1022 to i64*
  %1025 = load i64, i64* %1024, align 8
  store i64 %1025, i64* %RCX, align 8, !tbaa !2428
  %1026 = add i64 %1011, -32
  %1027 = add i64 %1013, 24
  store i64 %1027, i64* %PC, align 8
  %1028 = inttoptr i64 %1026 to i32*
  %1029 = load i32, i32* %1028, align 4
  %1030 = sext i32 %1029 to i64
  store i64 %1030, i64* %RDX, align 8, !tbaa !2428
  %1031 = shl nsw i64 %1030, 3
  %1032 = add i64 %1031, %1025
  %1033 = add i64 %1013, 29
  store i64 %1033, i64* %PC, align 8
  %1034 = inttoptr i64 %1032 to double*
  store double %1021, double* %1034, align 8
  %1035 = load i64, i64* %RBP, align 8
  %1036 = add i64 %1035, -144
  %1037 = load i64, i64* %PC, align 8
  %1038 = add i64 %1037, 8
  store i64 %1038, i64* %PC, align 8
  %1039 = inttoptr i64 %1036 to double*
  %1040 = load double, double* %1039, align 8
  store double %1040, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %1041 = add i64 %1035, -168
  %1042 = add i64 %1037, 16
  store i64 %1042, i64* %PC, align 8
  %1043 = inttoptr i64 %1041 to double*
  %1044 = load double, double* %1043, align 8
  %1045 = fadd double %1040, %1044
  store double %1045, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %1046 = add i64 %1035, -16
  %1047 = add i64 %1037, 20
  store i64 %1047, i64* %PC, align 8
  %1048 = inttoptr i64 %1046 to i64*
  %1049 = load i64, i64* %1048, align 8
  store i64 %1049, i64* %RCX, align 8, !tbaa !2428
  %1050 = add i64 %1035, -32
  %1051 = add i64 %1037, 23
  store i64 %1051, i64* %PC, align 8
  %1052 = inttoptr i64 %1050 to i32*
  %1053 = load i32, i32* %1052, align 4
  %1054 = add i32 %1053, 1
  %1055 = zext i32 %1054 to i64
  store i64 %1055, i64* %RAX, align 8, !tbaa !2428
  %1056 = icmp eq i32 %1053, -1
  %1057 = icmp eq i32 %1054, 0
  %1058 = or i1 %1056, %1057
  %1059 = zext i1 %1058 to i8
  store i8 %1059, i8* %18, align 1, !tbaa !2433
  %1060 = and i32 %1054, 255
  %1061 = tail call i32 @llvm.ctpop.i32(i32 %1060) #10
  %1062 = trunc i32 %1061 to i8
  %1063 = and i8 %1062, 1
  %1064 = xor i8 %1063, 1
  store i8 %1064, i8* %25, align 1, !tbaa !2447
  %1065 = xor i32 %1053, %1054
  %1066 = lshr i32 %1065, 4
  %1067 = trunc i32 %1066 to i8
  %1068 = and i8 %1067, 1
  store i8 %1068, i8* %31, align 1, !tbaa !2451
  %1069 = icmp eq i32 %1054, 0
  %1070 = zext i1 %1069 to i8
  store i8 %1070, i8* %34, align 1, !tbaa !2448
  %1071 = lshr i32 %1054, 31
  %1072 = trunc i32 %1071 to i8
  store i8 %1072, i8* %37, align 1, !tbaa !2449
  %1073 = lshr i32 %1053, 31
  %1074 = xor i32 %1071, %1073
  %1075 = add nuw nsw i32 %1074, %1071
  %1076 = icmp eq i32 %1075, 2
  %1077 = zext i1 %1076 to i8
  store i8 %1077, i8* %43, align 1, !tbaa !2450
  %1078 = sext i32 %1054 to i64
  store i64 %1078, i64* %RDX, align 8, !tbaa !2428
  %1079 = shl nsw i64 %1078, 3
  %1080 = add i64 %1079, %1049
  %1081 = add i64 %1037, 34
  store i64 %1081, i64* %PC, align 8
  %1082 = inttoptr i64 %1080 to double*
  store double %1045, double* %1082, align 8
  %1083 = load i64, i64* %RBP, align 8
  %1084 = add i64 %1083, -136
  %1085 = load i64, i64* %PC, align 8
  %1086 = add i64 %1085, 8
  store i64 %1086, i64* %PC, align 8
  %1087 = inttoptr i64 %1084 to double*
  %1088 = load double, double* %1087, align 8
  store double %1088, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %1089 = add i64 %1083, -176
  %1090 = add i64 %1085, 16
  store i64 %1090, i64* %PC, align 8
  %1091 = inttoptr i64 %1089 to double*
  %1092 = load double, double* %1091, align 8
  %1093 = fadd double %1088, %1092
  store double %1093, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %1094 = add i64 %1083, -16
  %1095 = add i64 %1085, 20
  store i64 %1095, i64* %PC, align 8
  %1096 = inttoptr i64 %1094 to i64*
  %1097 = load i64, i64* %1096, align 8
  store i64 %1097, i64* %RCX, align 8, !tbaa !2428
  %1098 = add i64 %1083, -40
  %1099 = add i64 %1085, 24
  store i64 %1099, i64* %PC, align 8
  %1100 = inttoptr i64 %1098 to i32*
  %1101 = load i32, i32* %1100, align 4
  %1102 = sext i32 %1101 to i64
  store i64 %1102, i64* %RDX, align 8, !tbaa !2428
  %1103 = shl nsw i64 %1102, 3
  %1104 = add i64 %1103, %1097
  %1105 = add i64 %1085, 29
  store i64 %1105, i64* %PC, align 8
  %1106 = inttoptr i64 %1104 to double*
  store double %1093, double* %1106, align 8
  %1107 = load i64, i64* %RBP, align 8
  %1108 = add i64 %1107, -144
  %1109 = load i64, i64* %PC, align 8
  %1110 = add i64 %1109, 8
  store i64 %1110, i64* %PC, align 8
  %1111 = inttoptr i64 %1108 to double*
  %1112 = load double, double* %1111, align 8
  store double %1112, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %1113 = add i64 %1107, -168
  %1114 = add i64 %1109, 16
  store i64 %1114, i64* %PC, align 8
  %1115 = inttoptr i64 %1113 to double*
  %1116 = load double, double* %1115, align 8
  %1117 = fsub double %1112, %1116
  store double %1117, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %1118 = add i64 %1107, -16
  %1119 = add i64 %1109, 20
  store i64 %1119, i64* %PC, align 8
  %1120 = inttoptr i64 %1118 to i64*
  %1121 = load i64, i64* %1120, align 8
  store i64 %1121, i64* %RCX, align 8, !tbaa !2428
  %1122 = add i64 %1107, -40
  %1123 = add i64 %1109, 23
  store i64 %1123, i64* %PC, align 8
  %1124 = inttoptr i64 %1122 to i32*
  %1125 = load i32, i32* %1124, align 4
  %1126 = add i32 %1125, 1
  %1127 = zext i32 %1126 to i64
  store i64 %1127, i64* %RAX, align 8, !tbaa !2428
  %1128 = icmp eq i32 %1125, -1
  %1129 = icmp eq i32 %1126, 0
  %1130 = or i1 %1128, %1129
  %1131 = zext i1 %1130 to i8
  store i8 %1131, i8* %18, align 1, !tbaa !2433
  %1132 = and i32 %1126, 255
  %1133 = tail call i32 @llvm.ctpop.i32(i32 %1132) #10
  %1134 = trunc i32 %1133 to i8
  %1135 = and i8 %1134, 1
  %1136 = xor i8 %1135, 1
  store i8 %1136, i8* %25, align 1, !tbaa !2447
  %1137 = xor i32 %1125, %1126
  %1138 = lshr i32 %1137, 4
  %1139 = trunc i32 %1138 to i8
  %1140 = and i8 %1139, 1
  store i8 %1140, i8* %31, align 1, !tbaa !2451
  %1141 = icmp eq i32 %1126, 0
  %1142 = zext i1 %1141 to i8
  store i8 %1142, i8* %34, align 1, !tbaa !2448
  %1143 = lshr i32 %1126, 31
  %1144 = trunc i32 %1143 to i8
  store i8 %1144, i8* %37, align 1, !tbaa !2449
  %1145 = lshr i32 %1125, 31
  %1146 = xor i32 %1143, %1145
  %1147 = add nuw nsw i32 %1146, %1143
  %1148 = icmp eq i32 %1147, 2
  %1149 = zext i1 %1148 to i8
  store i8 %1149, i8* %43, align 1, !tbaa !2450
  %1150 = sext i32 %1126 to i64
  store i64 %1150, i64* %RDX, align 8, !tbaa !2428
  %1151 = shl nsw i64 %1150, 3
  %1152 = add i64 %1151, %1121
  %1153 = add i64 %1109, 34
  store i64 %1153, i64* %PC, align 8
  %1154 = inttoptr i64 %1152 to double*
  store double %1117, double* %1154, align 8
  %1155 = load i64, i64* %RBP, align 8
  %1156 = add i64 %1155, -28
  %1157 = load i64, i64* %PC, align 8
  %1158 = add i64 %1157, 3
  store i64 %1158, i64* %PC, align 8
  %1159 = inttoptr i64 %1156 to i32*
  %1160 = load i32, i32* %1159, align 4
  %1161 = add i32 %1160, 2
  %1162 = zext i32 %1161 to i64
  store i64 %1162, i64* %RAX, align 8, !tbaa !2428
  %1163 = icmp ugt i32 %1160, -3
  %1164 = zext i1 %1163 to i8
  store i8 %1164, i8* %18, align 1, !tbaa !2433
  %1165 = and i32 %1161, 255
  %1166 = tail call i32 @llvm.ctpop.i32(i32 %1165) #10
  %1167 = trunc i32 %1166 to i8
  %1168 = and i8 %1167, 1
  %1169 = xor i8 %1168, 1
  store i8 %1169, i8* %25, align 1, !tbaa !2447
  %1170 = xor i32 %1160, %1161
  %1171 = lshr i32 %1170, 4
  %1172 = trunc i32 %1171 to i8
  %1173 = and i8 %1172, 1
  store i8 %1173, i8* %31, align 1, !tbaa !2451
  %1174 = icmp eq i32 %1161, 0
  %1175 = zext i1 %1174 to i8
  store i8 %1175, i8* %34, align 1, !tbaa !2448
  %1176 = lshr i32 %1161, 31
  %1177 = trunc i32 %1176 to i8
  store i8 %1177, i8* %37, align 1, !tbaa !2449
  %1178 = lshr i32 %1160, 31
  %1179 = xor i32 %1176, %1178
  %1180 = add nuw nsw i32 %1179, %1176
  %1181 = icmp eq i32 %1180, 2
  %1182 = zext i1 %1181 to i8
  store i8 %1182, i8* %43, align 1, !tbaa !2450
  %1183 = add i64 %1157, 9
  store i64 %1183, i64* %PC, align 8
  store i32 %1161, i32* %1159, align 4
  %1184 = load i64, i64* %PC, align 8
  %1185 = add i64 %1184, -594
  store i64 %1185, i64* %95, align 8, !tbaa !2428
  br label %block_403326

block_40386f:                                     ; preds = %block_403863
  %1186 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 80) to i64*), align 16
  %1187 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %5, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1186, i64* %1187, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %1188 = add i64 %2663, -48
  %1189 = add i64 %2699, 11
  store i64 %1189, i64* %PC, align 8
  %1190 = inttoptr i64 %1188 to i32*
  %1191 = load i32, i32* %1190, align 4
  %1192 = add i32 %1191, 2
  %1193 = zext i32 %1192 to i64
  store i64 %1193, i64* %RAX, align 8, !tbaa !2428
  %1194 = icmp ugt i32 %1191, -3
  %1195 = zext i1 %1194 to i8
  store i8 %1195, i8* %18, align 1, !tbaa !2433
  %1196 = and i32 %1192, 255
  %1197 = tail call i32 @llvm.ctpop.i32(i32 %1196) #10
  %1198 = trunc i32 %1197 to i8
  %1199 = and i8 %1198, 1
  %1200 = xor i8 %1199, 1
  store i8 %1200, i8* %25, align 1, !tbaa !2447
  %1201 = xor i32 %1191, %1192
  %1202 = lshr i32 %1201, 4
  %1203 = trunc i32 %1202 to i8
  %1204 = and i8 %1203, 1
  store i8 %1204, i8* %31, align 1, !tbaa !2451
  %1205 = icmp eq i32 %1192, 0
  %1206 = zext i1 %1205 to i8
  store i8 %1206, i8* %34, align 1, !tbaa !2448
  %1207 = lshr i32 %1192, 31
  %1208 = trunc i32 %1207 to i8
  store i8 %1208, i8* %37, align 1, !tbaa !2449
  %1209 = lshr i32 %1191, 31
  %1210 = xor i32 %1207, %1209
  %1211 = add nuw nsw i32 %1210, %1207
  %1212 = icmp eq i32 %1211, 2
  %1213 = zext i1 %1212 to i8
  store i8 %1213, i8* %43, align 1, !tbaa !2450
  %1214 = add i64 %2699, 17
  store i64 %1214, i64* %PC, align 8
  store i32 %1192, i32* %1190, align 4
  %1215 = load i64, i64* %RBP, align 8
  %1216 = add i64 %1215, -48
  %1217 = load i64, i64* %PC, align 8
  %1218 = add i64 %1217, 3
  store i64 %1218, i64* %PC, align 8
  %1219 = inttoptr i64 %1216 to i32*
  %1220 = load i32, i32* %1219, align 4
  %1221 = shl i32 %1220, 1
  %1222 = icmp slt i32 %1220, 0
  %1223 = icmp slt i32 %1221, 0
  %1224 = xor i1 %1222, %1223
  %1225 = zext i32 %1221 to i64
  store i64 %1225, i64* %RAX, align 8, !tbaa !2428
  %.lobit9 = lshr i32 %1220, 31
  %1226 = trunc i32 %.lobit9 to i8
  store i8 %1226, i8* %18, align 1, !tbaa !2432
  %1227 = and i32 %1221, 254
  %1228 = tail call i32 @llvm.ctpop.i32(i32 %1227) #10
  %1229 = trunc i32 %1228 to i8
  %1230 = and i8 %1229, 1
  %1231 = xor i8 %1230, 1
  store i8 %1231, i8* %25, align 1, !tbaa !2432
  store i8 0, i8* %31, align 1, !tbaa !2432
  %1232 = icmp eq i32 %1221, 0
  %1233 = zext i1 %1232 to i8
  store i8 %1233, i8* %34, align 1, !tbaa !2432
  %1234 = lshr i32 %1220, 30
  %1235 = trunc i32 %1234 to i8
  %1236 = and i8 %1235, 1
  store i8 %1236, i8* %37, align 1, !tbaa !2432
  %1237 = zext i1 %1224 to i8
  store i8 %1237, i8* %43, align 1, !tbaa !2432
  %1238 = add i64 %1215, -52
  %1239 = add i64 %1217, 9
  store i64 %1239, i64* %PC, align 8
  %1240 = inttoptr i64 %1238 to i32*
  store i32 %1221, i32* %1240, align 4
  %1241 = load i64, i64* %RBP, align 8
  %1242 = add i64 %1241, -24
  %1243 = load i64, i64* %PC, align 8
  %1244 = add i64 %1243, 4
  store i64 %1244, i64* %PC, align 8
  %1245 = inttoptr i64 %1242 to i64*
  %1246 = load i64, i64* %1245, align 8
  store i64 %1246, i64* %RCX, align 8, !tbaa !2428
  %1247 = add i64 %1241, -48
  %1248 = add i64 %1243, 8
  store i64 %1248, i64* %PC, align 8
  %1249 = inttoptr i64 %1247 to i32*
  %1250 = load i32, i32* %1249, align 4
  %1251 = sext i32 %1250 to i64
  store i64 %1251, i64* %RDX, align 8, !tbaa !2428
  %1252 = shl nsw i64 %1251, 3
  %1253 = add i64 %1252, %1246
  %1254 = add i64 %1243, 13
  store i64 %1254, i64* %PC, align 8
  %1255 = inttoptr i64 %1253 to i64*
  %1256 = load i64, i64* %1255, align 8
  %1257 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1256, i64* %1257, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %1258 = add i64 %1241, -88
  %1259 = add i64 %1243, 18
  store i64 %1259, i64* %PC, align 8
  %1260 = inttoptr i64 %1258 to i64*
  store i64 %1256, i64* %1260, align 8
  %1261 = load i64, i64* %RBP, align 8
  %1262 = add i64 %1261, -24
  %1263 = load i64, i64* %PC, align 8
  %1264 = add i64 %1263, 4
  store i64 %1264, i64* %PC, align 8
  %1265 = inttoptr i64 %1262 to i64*
  %1266 = load i64, i64* %1265, align 8
  store i64 %1266, i64* %RCX, align 8, !tbaa !2428
  %1267 = add i64 %1261, -48
  %1268 = add i64 %1263, 7
  store i64 %1268, i64* %PC, align 8
  %1269 = inttoptr i64 %1267 to i32*
  %1270 = load i32, i32* %1269, align 4
  %1271 = add i32 %1270, 1
  %1272 = zext i32 %1271 to i64
  store i64 %1272, i64* %RAX, align 8, !tbaa !2428
  %1273 = icmp eq i32 %1270, -1
  %1274 = icmp eq i32 %1271, 0
  %1275 = or i1 %1273, %1274
  %1276 = zext i1 %1275 to i8
  store i8 %1276, i8* %18, align 1, !tbaa !2433
  %1277 = and i32 %1271, 255
  %1278 = tail call i32 @llvm.ctpop.i32(i32 %1277) #10
  %1279 = trunc i32 %1278 to i8
  %1280 = and i8 %1279, 1
  %1281 = xor i8 %1280, 1
  store i8 %1281, i8* %25, align 1, !tbaa !2447
  %1282 = xor i32 %1270, %1271
  %1283 = lshr i32 %1282, 4
  %1284 = trunc i32 %1283 to i8
  %1285 = and i8 %1284, 1
  store i8 %1285, i8* %31, align 1, !tbaa !2451
  %1286 = icmp eq i32 %1271, 0
  %1287 = zext i1 %1286 to i8
  store i8 %1287, i8* %34, align 1, !tbaa !2448
  %1288 = lshr i32 %1271, 31
  %1289 = trunc i32 %1288 to i8
  store i8 %1289, i8* %37, align 1, !tbaa !2449
  %1290 = lshr i32 %1270, 31
  %1291 = xor i32 %1288, %1290
  %1292 = add nuw nsw i32 %1291, %1288
  %1293 = icmp eq i32 %1292, 2
  %1294 = zext i1 %1293 to i8
  store i8 %1294, i8* %43, align 1, !tbaa !2450
  %1295 = sext i32 %1271 to i64
  store i64 %1295, i64* %RDX, align 8, !tbaa !2428
  %1296 = shl nsw i64 %1295, 3
  %1297 = add i64 %1296, %1266
  %1298 = add i64 %1263, 18
  store i64 %1298, i64* %PC, align 8
  %1299 = inttoptr i64 %1297 to i64*
  %1300 = load i64, i64* %1299, align 8
  %1301 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1300, i64* %1301, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %1302 = add i64 %1261, -96
  %1303 = add i64 %1263, 23
  store i64 %1303, i64* %PC, align 8
  %1304 = inttoptr i64 %1302 to i64*
  store i64 %1300, i64* %1304, align 8
  %1305 = load i64, i64* %RBP, align 8
  %1306 = add i64 %1305, -24
  %1307 = load i64, i64* %PC, align 8
  %1308 = add i64 %1307, 4
  store i64 %1308, i64* %PC, align 8
  %1309 = inttoptr i64 %1306 to i64*
  %1310 = load i64, i64* %1309, align 8
  store i64 %1310, i64* %RCX, align 8, !tbaa !2428
  %1311 = add i64 %1305, -52
  %1312 = add i64 %1307, 8
  store i64 %1312, i64* %PC, align 8
  %1313 = inttoptr i64 %1311 to i32*
  %1314 = load i32, i32* %1313, align 4
  %1315 = sext i32 %1314 to i64
  store i64 %1315, i64* %RDX, align 8, !tbaa !2428
  %1316 = shl nsw i64 %1315, 3
  %1317 = add i64 %1316, %1310
  %1318 = add i64 %1307, 13
  store i64 %1318, i64* %PC, align 8
  %1319 = inttoptr i64 %1317 to i64*
  %1320 = load i64, i64* %1319, align 8
  %1321 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1320, i64* %1321, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %1322 = add i64 %1305, -72
  %1323 = add i64 %1307, 18
  store i64 %1323, i64* %PC, align 8
  %1324 = inttoptr i64 %1322 to i64*
  store i64 %1320, i64* %1324, align 8
  %1325 = load i64, i64* %RBP, align 8
  %1326 = add i64 %1325, -24
  %1327 = load i64, i64* %PC, align 8
  %1328 = add i64 %1327, 4
  store i64 %1328, i64* %PC, align 8
  %1329 = inttoptr i64 %1326 to i64*
  %1330 = load i64, i64* %1329, align 8
  store i64 %1330, i64* %RCX, align 8, !tbaa !2428
  %1331 = add i64 %1325, -52
  %1332 = add i64 %1327, 7
  store i64 %1332, i64* %PC, align 8
  %1333 = inttoptr i64 %1331 to i32*
  %1334 = load i32, i32* %1333, align 4
  %1335 = add i32 %1334, 1
  %1336 = zext i32 %1335 to i64
  store i64 %1336, i64* %RAX, align 8, !tbaa !2428
  %1337 = icmp eq i32 %1334, -1
  %1338 = icmp eq i32 %1335, 0
  %1339 = or i1 %1337, %1338
  %1340 = zext i1 %1339 to i8
  store i8 %1340, i8* %18, align 1, !tbaa !2433
  %1341 = and i32 %1335, 255
  %1342 = tail call i32 @llvm.ctpop.i32(i32 %1341) #10
  %1343 = trunc i32 %1342 to i8
  %1344 = and i8 %1343, 1
  %1345 = xor i8 %1344, 1
  store i8 %1345, i8* %25, align 1, !tbaa !2447
  %1346 = xor i32 %1334, %1335
  %1347 = lshr i32 %1346, 4
  %1348 = trunc i32 %1347 to i8
  %1349 = and i8 %1348, 1
  store i8 %1349, i8* %31, align 1, !tbaa !2451
  %1350 = icmp eq i32 %1335, 0
  %1351 = zext i1 %1350 to i8
  store i8 %1351, i8* %34, align 1, !tbaa !2448
  %1352 = lshr i32 %1335, 31
  %1353 = trunc i32 %1352 to i8
  store i8 %1353, i8* %37, align 1, !tbaa !2449
  %1354 = lshr i32 %1334, 31
  %1355 = xor i32 %1352, %1354
  %1356 = add nuw nsw i32 %1355, %1352
  %1357 = icmp eq i32 %1356, 2
  %1358 = zext i1 %1357 to i8
  store i8 %1358, i8* %43, align 1, !tbaa !2450
  %1359 = sext i32 %1335 to i64
  store i64 %1359, i64* %RDX, align 8, !tbaa !2428
  %1360 = shl nsw i64 %1359, 3
  %1361 = add i64 %1360, %1330
  %1362 = add i64 %1327, 18
  store i64 %1362, i64* %PC, align 8
  %1363 = inttoptr i64 %1361 to i64*
  %1364 = load i64, i64* %1363, align 8
  %1365 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1364, i64* %1365, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %1366 = add i64 %1325, -80
  %1367 = add i64 %1327, 23
  store i64 %1367, i64* %PC, align 8
  %1368 = inttoptr i64 %1366 to i64*
  store i64 %1364, i64* %1368, align 8
  %1369 = load i64, i64* %RBP, align 8
  %1370 = add i64 %1369, -72
  %1371 = load i64, i64* %PC, align 8
  %1372 = add i64 %1371, 5
  store i64 %1372, i64* %PC, align 8
  %1373 = inttoptr i64 %1370 to double*
  %1374 = load double, double* %1373, align 8
  store double %1374, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %1375 = load <2 x i32>, <2 x i32>* %1467, align 1
  %1376 = load <2 x i32>, <2 x i32>* %1469, align 1
  %1377 = extractelement <2 x i32> %1375, i32 0
  store i32 %1377, i32* %1470, align 1, !tbaa !2475
  %1378 = extractelement <2 x i32> %1375, i32 1
  store i32 %1378, i32* %1472, align 1, !tbaa !2475
  %1379 = extractelement <2 x i32> %1376, i32 0
  store i32 %1379, i32* %1474, align 1, !tbaa !2475
  %1380 = extractelement <2 x i32> %1376, i32 1
  store i32 %1380, i32* %1476, align 1, !tbaa !2475
  %1381 = add i64 %1369, -96
  %1382 = add i64 %1371, 13
  store i64 %1382, i64* %PC, align 8
  %1383 = load double, double* %1477, align 1
  %1384 = inttoptr i64 %1381 to double*
  %1385 = load double, double* %1384, align 8
  %1386 = fmul double %1383, %1385
  store double %1386, double* %1477, align 1, !tbaa !2452
  %1387 = add i64 %1369, -80
  %1388 = add i64 %1371, 18
  store i64 %1388, i64* %PC, align 8
  %1389 = inttoptr i64 %1387 to double*
  %1390 = load double, double* %1389, align 8
  %1391 = fmul double %1386, %1390
  store double %1391, double* %1477, align 1, !tbaa !2452
  %1392 = fsub double %1374, %1391
  store double %1392, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %1393 = add i64 %1369, -104
  %1394 = add i64 %1371, 27
  store i64 %1394, i64* %PC, align 8
  %1395 = inttoptr i64 %1393 to double*
  store double %1392, double* %1395, align 8
  %1396 = load i64, i64* %RBP, align 8
  %1397 = add i64 %1396, -96
  %1398 = load i64, i64* %PC, align 8
  %1399 = add i64 %1398, 5
  store i64 %1399, i64* %PC, align 8
  %1400 = load double, double* %96, align 1
  %1401 = inttoptr i64 %1397 to double*
  %1402 = load double, double* %1401, align 8
  %1403 = fmul double %1400, %1402
  store double %1403, double* %96, align 1, !tbaa !2452
  %1404 = add i64 %1396, -72
  %1405 = add i64 %1398, 10
  store i64 %1405, i64* %PC, align 8
  %1406 = inttoptr i64 %1404 to double*
  %1407 = load double, double* %1406, align 8
  %1408 = fmul double %1403, %1407
  store double %1408, double* %96, align 1, !tbaa !2452
  %1409 = add i64 %1396, -80
  %1410 = add i64 %1398, 15
  store i64 %1410, i64* %PC, align 8
  %1411 = inttoptr i64 %1409 to double*
  %1412 = load double, double* %1411, align 8
  %1413 = fsub double %1408, %1412
  store double %1413, double* %96, align 1, !tbaa !2452
  %1414 = add i64 %1396, -112
  %1415 = add i64 %1398, 20
  store i64 %1415, i64* %PC, align 8
  %1416 = inttoptr i64 %1414 to double*
  store double %1413, double* %1416, align 8
  %1417 = load i64, i64* %RBP, align 8
  %1418 = add i64 %1417, -44
  %1419 = load i64, i64* %PC, align 8
  %1420 = add i64 %1419, 3
  store i64 %1420, i64* %PC, align 8
  %1421 = inttoptr i64 %1418 to i32*
  %1422 = load i32, i32* %1421, align 4
  %1423 = zext i32 %1422 to i64
  store i64 %1423, i64* %RAX, align 8, !tbaa !2428
  %1424 = add i64 %1417, -28
  %1425 = add i64 %1419, 6
  store i64 %1425, i64* %PC, align 8
  %1426 = inttoptr i64 %1424 to i32*
  store i32 %1422, i32* %1426, align 4
  %.pre5 = load i64, i64* %PC, align 8
  br label %block_403910

block_40384d:                                     ; preds = %block_403591
  %1427 = add i64 %2661, -48
  %1428 = add i64 %2660, 7
  store i64 %1428, i64* %PC, align 8
  %1429 = inttoptr i64 %1427 to i32*
  store i32 0, i32* %1429, align 4
  %1430 = load i64, i64* %RBP, align 8
  %1431 = add i64 %1430, -56
  %1432 = load i64, i64* %PC, align 8
  %1433 = add i64 %1432, 3
  store i64 %1433, i64* %PC, align 8
  %1434 = inttoptr i64 %1431 to i32*
  %1435 = load i32, i32* %1434, align 4
  %1436 = shl i32 %1435, 1
  %1437 = icmp slt i32 %1435, 0
  %1438 = icmp slt i32 %1436, 0
  %1439 = xor i1 %1437, %1438
  %1440 = zext i32 %1436 to i64
  store i64 %1440, i64* %RAX, align 8, !tbaa !2428
  %.lobit = lshr i32 %1435, 31
  %1441 = trunc i32 %.lobit to i8
  store i8 %1441, i8* %18, align 1, !tbaa !2432
  %1442 = and i32 %1436, 254
  %1443 = tail call i32 @llvm.ctpop.i32(i32 %1442) #10
  %1444 = trunc i32 %1443 to i8
  %1445 = and i8 %1444, 1
  %1446 = xor i8 %1445, 1
  store i8 %1446, i8* %25, align 1, !tbaa !2432
  store i8 0, i8* %31, align 1, !tbaa !2432
  %1447 = icmp eq i32 %1436, 0
  %1448 = zext i1 %1447 to i8
  store i8 %1448, i8* %34, align 1, !tbaa !2432
  %1449 = lshr i32 %1435, 30
  %1450 = trunc i32 %1449 to i8
  %1451 = and i8 %1450, 1
  store i8 %1451, i8* %37, align 1, !tbaa !2432
  %1452 = zext i1 %1439 to i8
  store i8 %1452, i8* %43, align 1, !tbaa !2432
  %1453 = add i64 %1430, -60
  %1454 = add i64 %1432, 9
  store i64 %1454, i64* %PC, align 8
  %1455 = inttoptr i64 %1453 to i32*
  store i32 %1436, i32* %1455, align 4
  %1456 = load i64, i64* %RBP, align 8
  %1457 = add i64 %1456, -60
  %1458 = load i64, i64* %PC, align 8
  %1459 = add i64 %1458, 3
  store i64 %1459, i64* %PC, align 8
  %1460 = inttoptr i64 %1457 to i32*
  %1461 = load i32, i32* %1460, align 4
  %1462 = zext i32 %1461 to i64
  store i64 %1462, i64* %RAX, align 8, !tbaa !2428
  %1463 = add i64 %1456, -44
  %1464 = add i64 %1458, 6
  store i64 %1464, i64* %PC, align 8
  %1465 = inttoptr i64 %1463 to i32*
  store i32 %1461, i32* %1465, align 4
  %1466 = bitcast %union.VectorReg* %7 to i8*
  %1467 = bitcast [32 x %union.VectorReg]* %5 to <2 x i32>*
  %1468 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1469 = bitcast i64* %1468 to <2 x i32>*
  %1470 = bitcast %union.VectorReg* %7 to i32*
  %1471 = getelementptr inbounds i8, i8* %1466, i64 4
  %1472 = bitcast i8* %1471 to i32*
  %1473 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %1474 = bitcast i64* %1473 to i32*
  %1475 = getelementptr inbounds i8, i8* %1466, i64 12
  %1476 = bitcast i8* %1475 to i32*
  %1477 = bitcast %union.VectorReg* %7 to double*
  %1478 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %5, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %.pre4 = load i64, i64* %PC, align 8
  br label %block_403863

block_403fde:                                     ; preds = %block_403863
  %1479 = load i64, i64* %RSP, align 8
  %1480 = add i64 %1479, 48
  store i64 %1480, i64* %RSP, align 8, !tbaa !2428
  %1481 = icmp ugt i64 %1479, -49
  %1482 = zext i1 %1481 to i8
  store i8 %1482, i8* %18, align 1, !tbaa !2433
  %1483 = trunc i64 %1480 to i32
  %1484 = and i32 %1483, 255
  %1485 = tail call i32 @llvm.ctpop.i32(i32 %1484) #10
  %1486 = trunc i32 %1485 to i8
  %1487 = and i8 %1486, 1
  %1488 = xor i8 %1487, 1
  store i8 %1488, i8* %25, align 1, !tbaa !2447
  %1489 = xor i64 %1479, 16
  %1490 = xor i64 %1489, %1480
  %1491 = lshr i64 %1490, 4
  %1492 = trunc i64 %1491 to i8
  %1493 = and i8 %1492, 1
  store i8 %1493, i8* %31, align 1, !tbaa !2451
  %1494 = icmp eq i64 %1480, 0
  %1495 = zext i1 %1494 to i8
  store i8 %1495, i8* %34, align 1, !tbaa !2448
  %1496 = lshr i64 %1480, 63
  %1497 = trunc i64 %1496 to i8
  store i8 %1497, i8* %37, align 1, !tbaa !2449
  %1498 = lshr i64 %1479, 63
  %1499 = xor i64 %1496, %1498
  %1500 = add nuw nsw i64 %1499, %1496
  %1501 = icmp eq i64 %1500, 2
  %1502 = zext i1 %1501 to i8
  store i8 %1502, i8* %43, align 1, !tbaa !2450
  %1503 = add i64 %2699, 5
  store i64 %1503, i64* %PC, align 8
  %1504 = add i64 %1479, 56
  %1505 = inttoptr i64 %1480 to i64*
  %1506 = load i64, i64* %1505, align 8
  store i64 %1506, i64* %RBP, align 8, !tbaa !2428
  store i64 %1504, i64* %10, align 8, !tbaa !2428
  %1507 = add i64 %2699, 6
  store i64 %1507, i64* %PC, align 8
  %1508 = inttoptr i64 %1504 to i64*
  %1509 = load i64, i64* %1508, align 8
  store i64 %1509, i64* %95, align 8, !tbaa !2428
  %1510 = add i64 %1479, 64
  store i64 %1510, i64* %10, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_403fcb:                                     ; preds = %block_403c90
  %1511 = load i64, i64* %RBP, align 8
  %1512 = add i64 %1511, -60
  %1513 = add i64 %1602, 8
  store i64 %1513, i64* %PC, align 8
  %1514 = inttoptr i64 %1512 to i32*
  %1515 = load i32, i32* %1514, align 4
  %1516 = zext i32 %1515 to i64
  store i64 %1516, i64* %RAX, align 8, !tbaa !2428
  %1517 = add i64 %1511, -44
  %1518 = add i64 %1602, 11
  store i64 %1518, i64* %PC, align 8
  %1519 = inttoptr i64 %1517 to i32*
  %1520 = load i32, i32* %1519, align 4
  %1521 = add i32 %1520, %1515
  %1522 = zext i32 %1521 to i64
  store i64 %1522, i64* %RAX, align 8, !tbaa !2428
  %1523 = icmp ult i32 %1521, %1515
  %1524 = icmp ult i32 %1521, %1520
  %1525 = or i1 %1523, %1524
  %1526 = zext i1 %1525 to i8
  store i8 %1526, i8* %18, align 1, !tbaa !2433
  %1527 = and i32 %1521, 255
  %1528 = tail call i32 @llvm.ctpop.i32(i32 %1527) #10
  %1529 = trunc i32 %1528 to i8
  %1530 = and i8 %1529, 1
  %1531 = xor i8 %1530, 1
  store i8 %1531, i8* %25, align 1, !tbaa !2447
  %1532 = xor i32 %1520, %1515
  %1533 = xor i32 %1532, %1521
  %1534 = lshr i32 %1533, 4
  %1535 = trunc i32 %1534 to i8
  %1536 = and i8 %1535, 1
  store i8 %1536, i8* %31, align 1, !tbaa !2451
  %1537 = icmp eq i32 %1521, 0
  %1538 = zext i1 %1537 to i8
  store i8 %1538, i8* %34, align 1, !tbaa !2448
  %1539 = lshr i32 %1521, 31
  %1540 = trunc i32 %1539 to i8
  store i8 %1540, i8* %37, align 1, !tbaa !2449
  %1541 = lshr i32 %1515, 31
  %1542 = lshr i32 %1520, 31
  %1543 = xor i32 %1539, %1541
  %1544 = xor i32 %1539, %1542
  %1545 = add nuw nsw i32 %1543, %1544
  %1546 = icmp eq i32 %1545, 2
  %1547 = zext i1 %1546 to i8
  store i8 %1547, i8* %43, align 1, !tbaa !2450
  %1548 = add i64 %1602, 14
  store i64 %1548, i64* %PC, align 8
  store i32 %1521, i32* %1519, align 4
  %1549 = load i64, i64* %PC, align 8
  %1550 = add i64 %1549, -1910
  store i64 %1550, i64* %95, align 8, !tbaa !2428
  br label %block_403863

block_403c90:                                     ; preds = %block_403ca6, %block_403c22
  %1551 = phi i64 [ %4791, %block_403ca6 ], [ %.pre6, %block_403c22 ]
  %1552 = load i64, i64* %RBP, align 8
  %1553 = add i64 %1552, -28
  %1554 = add i64 %1551, 3
  store i64 %1554, i64* %PC, align 8
  %1555 = inttoptr i64 %1553 to i32*
  %1556 = load i32, i32* %1555, align 4
  %1557 = zext i32 %1556 to i64
  store i64 %1557, i64* %RAX, align 8, !tbaa !2428
  %1558 = add i64 %1552, -8
  %1559 = add i64 %1551, 6
  store i64 %1559, i64* %PC, align 8
  %1560 = inttoptr i64 %1558 to i32*
  %1561 = load i32, i32* %1560, align 4
  %1562 = zext i32 %1561 to i64
  store i64 %1562, i64* %RCX, align 8, !tbaa !2428
  %1563 = add i64 %1552, -44
  %1564 = add i64 %1551, 9
  store i64 %1564, i64* %PC, align 8
  %1565 = inttoptr i64 %1563 to i32*
  %1566 = load i32, i32* %1565, align 4
  %1567 = zext i32 %1566 to i64
  store i64 %1567, i64* %RDX, align 8, !tbaa !2428
  %1568 = add i64 %1552, -56
  %1569 = add i64 %1551, 12
  store i64 %1569, i64* %PC, align 8
  %1570 = inttoptr i64 %1568 to i32*
  %1571 = load i32, i32* %1570, align 4
  %1572 = add i32 %1571, %1566
  %1573 = zext i32 %1572 to i64
  store i64 %1573, i64* %RDX, align 8, !tbaa !2428
  %1574 = add i32 %1572, %1561
  %1575 = zext i32 %1574 to i64
  store i64 %1575, i64* %RCX, align 8, !tbaa !2428
  %1576 = lshr i32 %1574, 31
  %1577 = sub i32 %1556, %1574
  %1578 = icmp ult i32 %1556, %1574
  %1579 = zext i1 %1578 to i8
  store i8 %1579, i8* %18, align 1, !tbaa !2433
  %1580 = and i32 %1577, 255
  %1581 = tail call i32 @llvm.ctpop.i32(i32 %1580) #10
  %1582 = trunc i32 %1581 to i8
  %1583 = and i8 %1582, 1
  %1584 = xor i8 %1583, 1
  store i8 %1584, i8* %25, align 1, !tbaa !2447
  %1585 = xor i32 %1574, %1556
  %1586 = xor i32 %1585, %1577
  %1587 = lshr i32 %1586, 4
  %1588 = trunc i32 %1587 to i8
  %1589 = and i8 %1588, 1
  store i8 %1589, i8* %31, align 1, !tbaa !2451
  %1590 = icmp eq i32 %1577, 0
  %1591 = zext i1 %1590 to i8
  store i8 %1591, i8* %34, align 1, !tbaa !2448
  %1592 = lshr i32 %1577, 31
  %1593 = trunc i32 %1592 to i8
  store i8 %1593, i8* %37, align 1, !tbaa !2449
  %1594 = lshr i32 %1556, 31
  %1595 = xor i32 %1576, %1594
  %1596 = xor i32 %1592, %1594
  %1597 = add nuw nsw i32 %1596, %1595
  %1598 = icmp eq i32 %1597, 2
  %1599 = zext i1 %1598 to i8
  store i8 %1599, i8* %43, align 1, !tbaa !2450
  %1600 = icmp ne i8 %1593, 0
  %1601 = xor i1 %1600, %1598
  %.v11 = select i1 %1601, i64 22, i64 827
  %1602 = add i64 %1551, %.v11
  store i64 %1602, i64* %95, align 8, !tbaa !2428
  br i1 %1601, label %block_403ca6, label %block_403fcb

block_403910:                                     ; preds = %block_403921, %block_40386f
  %1603 = phi i64 [ %3732, %block_403921 ], [ %.pre5, %block_40386f ]
  %1604 = load i64, i64* %RBP, align 8
  %1605 = add i64 %1604, -28
  %1606 = add i64 %1603, 3
  store i64 %1606, i64* %PC, align 8
  %1607 = inttoptr i64 %1605 to i32*
  %1608 = load i32, i32* %1607, align 4
  %1609 = zext i32 %1608 to i64
  store i64 %1609, i64* %RAX, align 8, !tbaa !2428
  %1610 = add i64 %1604, -8
  %1611 = add i64 %1603, 6
  store i64 %1611, i64* %PC, align 8
  %1612 = inttoptr i64 %1610 to i32*
  %1613 = load i32, i32* %1612, align 4
  %1614 = zext i32 %1613 to i64
  store i64 %1614, i64* %RCX, align 8, !tbaa !2428
  %1615 = add i64 %1604, -44
  %1616 = add i64 %1603, 9
  store i64 %1616, i64* %PC, align 8
  %1617 = inttoptr i64 %1615 to i32*
  %1618 = load i32, i32* %1617, align 4
  %1619 = add i32 %1618, %1613
  %1620 = zext i32 %1619 to i64
  store i64 %1620, i64* %RCX, align 8, !tbaa !2428
  %1621 = lshr i32 %1619, 31
  %1622 = sub i32 %1608, %1619
  %1623 = icmp ult i32 %1608, %1619
  %1624 = zext i1 %1623 to i8
  store i8 %1624, i8* %18, align 1, !tbaa !2433
  %1625 = and i32 %1622, 255
  %1626 = tail call i32 @llvm.ctpop.i32(i32 %1625) #10
  %1627 = trunc i32 %1626 to i8
  %1628 = and i8 %1627, 1
  %1629 = xor i8 %1628, 1
  store i8 %1629, i8* %25, align 1, !tbaa !2447
  %1630 = xor i32 %1619, %1608
  %1631 = xor i32 %1630, %1622
  %1632 = lshr i32 %1631, 4
  %1633 = trunc i32 %1632 to i8
  %1634 = and i8 %1633, 1
  store i8 %1634, i8* %31, align 1, !tbaa !2451
  %1635 = icmp eq i32 %1622, 0
  %1636 = zext i1 %1635 to i8
  store i8 %1636, i8* %34, align 1, !tbaa !2448
  %1637 = lshr i32 %1622, 31
  %1638 = trunc i32 %1637 to i8
  store i8 %1638, i8* %37, align 1, !tbaa !2449
  %1639 = lshr i32 %1608, 31
  %1640 = xor i32 %1621, %1639
  %1641 = xor i32 %1637, %1639
  %1642 = add nuw nsw i32 %1641, %1640
  %1643 = icmp eq i32 %1642, 2
  %1644 = zext i1 %1643 to i8
  store i8 %1644, i8* %43, align 1, !tbaa !2450
  %1645 = icmp ne i8 %1638, 0
  %1646 = xor i1 %1645, %1643
  %.v10 = select i1 %1646, i64 17, i64 786
  %1647 = add i64 %1603, %.v10
  store i64 %1647, i64* %95, align 8, !tbaa !2428
  br i1 %1646, label %block_403921, label %block_403c22

block_4035a2:                                     ; preds = %block_403591
  %1648 = add i64 %2661, -28
  %1649 = add i64 %2660, 3
  store i64 %1649, i64* %PC, align 8
  %1650 = inttoptr i64 %1648 to i32*
  %1651 = load i32, i32* %1650, align 4
  %1652 = zext i32 %1651 to i64
  store i64 %1652, i64* %RAX, align 8, !tbaa !2428
  %1653 = add i64 %2661, -8
  %1654 = add i64 %2660, 6
  store i64 %1654, i64* %PC, align 8
  %1655 = inttoptr i64 %1653 to i32*
  %1656 = load i32, i32* %1655, align 4
  %1657 = add i32 %1656, %1651
  %1658 = zext i32 %1657 to i64
  store i64 %1658, i64* %RAX, align 8, !tbaa !2428
  %1659 = icmp ult i32 %1657, %1651
  %1660 = icmp ult i32 %1657, %1656
  %1661 = or i1 %1659, %1660
  %1662 = zext i1 %1661 to i8
  store i8 %1662, i8* %18, align 1, !tbaa !2433
  %1663 = and i32 %1657, 255
  %1664 = tail call i32 @llvm.ctpop.i32(i32 %1663) #10
  %1665 = trunc i32 %1664 to i8
  %1666 = and i8 %1665, 1
  %1667 = xor i8 %1666, 1
  store i8 %1667, i8* %25, align 1, !tbaa !2447
  %1668 = xor i32 %1656, %1651
  %1669 = xor i32 %1668, %1657
  %1670 = lshr i32 %1669, 4
  %1671 = trunc i32 %1670 to i8
  %1672 = and i8 %1671, 1
  store i8 %1672, i8* %31, align 1, !tbaa !2451
  %1673 = icmp eq i32 %1657, 0
  %1674 = zext i1 %1673 to i8
  store i8 %1674, i8* %34, align 1, !tbaa !2448
  %1675 = lshr i32 %1657, 31
  %1676 = trunc i32 %1675 to i8
  store i8 %1676, i8* %37, align 1, !tbaa !2449
  %1677 = lshr i32 %1651, 31
  %1678 = lshr i32 %1656, 31
  %1679 = xor i32 %1675, %1677
  %1680 = xor i32 %1675, %1678
  %1681 = add nuw nsw i32 %1679, %1680
  %1682 = icmp eq i32 %1681, 2
  %1683 = zext i1 %1682 to i8
  store i8 %1683, i8* %43, align 1, !tbaa !2450
  %1684 = add i64 %2661, -32
  %1685 = add i64 %2660, 9
  store i64 %1685, i64* %PC, align 8
  %1686 = inttoptr i64 %1684 to i32*
  store i32 %1657, i32* %1686, align 4
  %1687 = load i64, i64* %RBP, align 8
  %1688 = add i64 %1687, -32
  %1689 = load i64, i64* %PC, align 8
  %1690 = add i64 %1689, 3
  store i64 %1690, i64* %PC, align 8
  %1691 = inttoptr i64 %1688 to i32*
  %1692 = load i32, i32* %1691, align 4
  %1693 = zext i32 %1692 to i64
  store i64 %1693, i64* %RAX, align 8, !tbaa !2428
  %1694 = add i64 %1687, -8
  %1695 = add i64 %1689, 6
  store i64 %1695, i64* %PC, align 8
  %1696 = inttoptr i64 %1694 to i32*
  %1697 = load i32, i32* %1696, align 4
  %1698 = add i32 %1697, %1692
  %1699 = zext i32 %1698 to i64
  store i64 %1699, i64* %RAX, align 8, !tbaa !2428
  %1700 = icmp ult i32 %1698, %1692
  %1701 = icmp ult i32 %1698, %1697
  %1702 = or i1 %1700, %1701
  %1703 = zext i1 %1702 to i8
  store i8 %1703, i8* %18, align 1, !tbaa !2433
  %1704 = and i32 %1698, 255
  %1705 = tail call i32 @llvm.ctpop.i32(i32 %1704) #10
  %1706 = trunc i32 %1705 to i8
  %1707 = and i8 %1706, 1
  %1708 = xor i8 %1707, 1
  store i8 %1708, i8* %25, align 1, !tbaa !2447
  %1709 = xor i32 %1697, %1692
  %1710 = xor i32 %1709, %1698
  %1711 = lshr i32 %1710, 4
  %1712 = trunc i32 %1711 to i8
  %1713 = and i8 %1712, 1
  store i8 %1713, i8* %31, align 1, !tbaa !2451
  %1714 = icmp eq i32 %1698, 0
  %1715 = zext i1 %1714 to i8
  store i8 %1715, i8* %34, align 1, !tbaa !2448
  %1716 = lshr i32 %1698, 31
  %1717 = trunc i32 %1716 to i8
  store i8 %1717, i8* %37, align 1, !tbaa !2449
  %1718 = lshr i32 %1692, 31
  %1719 = lshr i32 %1697, 31
  %1720 = xor i32 %1716, %1718
  %1721 = xor i32 %1716, %1719
  %1722 = add nuw nsw i32 %1720, %1721
  %1723 = icmp eq i32 %1722, 2
  %1724 = zext i1 %1723 to i8
  store i8 %1724, i8* %43, align 1, !tbaa !2450
  %1725 = add i64 %1687, -36
  %1726 = add i64 %1689, 9
  store i64 %1726, i64* %PC, align 8
  %1727 = inttoptr i64 %1725 to i32*
  store i32 %1698, i32* %1727, align 4
  %1728 = load i64, i64* %RBP, align 8
  %1729 = add i64 %1728, -36
  %1730 = load i64, i64* %PC, align 8
  %1731 = add i64 %1730, 3
  store i64 %1731, i64* %PC, align 8
  %1732 = inttoptr i64 %1729 to i32*
  %1733 = load i32, i32* %1732, align 4
  %1734 = zext i32 %1733 to i64
  store i64 %1734, i64* %RAX, align 8, !tbaa !2428
  %1735 = add i64 %1728, -8
  %1736 = add i64 %1730, 6
  store i64 %1736, i64* %PC, align 8
  %1737 = inttoptr i64 %1735 to i32*
  %1738 = load i32, i32* %1737, align 4
  %1739 = add i32 %1738, %1733
  %1740 = zext i32 %1739 to i64
  store i64 %1740, i64* %RAX, align 8, !tbaa !2428
  %1741 = icmp ult i32 %1739, %1733
  %1742 = icmp ult i32 %1739, %1738
  %1743 = or i1 %1741, %1742
  %1744 = zext i1 %1743 to i8
  store i8 %1744, i8* %18, align 1, !tbaa !2433
  %1745 = and i32 %1739, 255
  %1746 = tail call i32 @llvm.ctpop.i32(i32 %1745) #10
  %1747 = trunc i32 %1746 to i8
  %1748 = and i8 %1747, 1
  %1749 = xor i8 %1748, 1
  store i8 %1749, i8* %25, align 1, !tbaa !2447
  %1750 = xor i32 %1738, %1733
  %1751 = xor i32 %1750, %1739
  %1752 = lshr i32 %1751, 4
  %1753 = trunc i32 %1752 to i8
  %1754 = and i8 %1753, 1
  store i8 %1754, i8* %31, align 1, !tbaa !2451
  %1755 = icmp eq i32 %1739, 0
  %1756 = zext i1 %1755 to i8
  store i8 %1756, i8* %34, align 1, !tbaa !2448
  %1757 = lshr i32 %1739, 31
  %1758 = trunc i32 %1757 to i8
  store i8 %1758, i8* %37, align 1, !tbaa !2449
  %1759 = lshr i32 %1733, 31
  %1760 = lshr i32 %1738, 31
  %1761 = xor i32 %1757, %1759
  %1762 = xor i32 %1757, %1760
  %1763 = add nuw nsw i32 %1761, %1762
  %1764 = icmp eq i32 %1763, 2
  %1765 = zext i1 %1764 to i8
  store i8 %1765, i8* %43, align 1, !tbaa !2450
  %1766 = add i64 %1728, -40
  %1767 = add i64 %1730, 9
  store i64 %1767, i64* %PC, align 8
  %1768 = inttoptr i64 %1766 to i32*
  store i32 %1739, i32* %1768, align 4
  %1769 = load i64, i64* %RBP, align 8
  %1770 = add i64 %1769, -16
  %1771 = load i64, i64* %PC, align 8
  %1772 = add i64 %1771, 4
  store i64 %1772, i64* %PC, align 8
  %1773 = inttoptr i64 %1770 to i64*
  %1774 = load i64, i64* %1773, align 8
  store i64 %1774, i64* %RCX, align 8, !tbaa !2428
  %1775 = add i64 %1769, -28
  %1776 = add i64 %1771, 8
  store i64 %1776, i64* %PC, align 8
  %1777 = inttoptr i64 %1775 to i32*
  %1778 = load i32, i32* %1777, align 4
  %1779 = sext i32 %1778 to i64
  store i64 %1779, i64* %RDX, align 8, !tbaa !2428
  %1780 = shl nsw i64 %1779, 3
  %1781 = add i64 %1780, %1774
  %1782 = add i64 %1771, 13
  store i64 %1782, i64* %PC, align 8
  %1783 = inttoptr i64 %1781 to double*
  %1784 = load double, double* %1783, align 8
  store double %1784, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %1785 = add i64 %1771, 17
  store i64 %1785, i64* %PC, align 8
  %1786 = load i64, i64* %1773, align 8
  store i64 %1786, i64* %RCX, align 8, !tbaa !2428
  %1787 = add i64 %1769, -32
  %1788 = add i64 %1771, 21
  store i64 %1788, i64* %PC, align 8
  %1789 = inttoptr i64 %1787 to i32*
  %1790 = load i32, i32* %1789, align 4
  %1791 = sext i32 %1790 to i64
  store i64 %1791, i64* %RDX, align 8, !tbaa !2428
  %1792 = shl nsw i64 %1791, 3
  %1793 = add i64 %1792, %1786
  %1794 = add i64 %1771, 26
  store i64 %1794, i64* %PC, align 8
  %1795 = inttoptr i64 %1793 to double*
  %1796 = load double, double* %1795, align 8
  %1797 = fadd double %1784, %1796
  store double %1797, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %1798 = add i64 %1769, -120
  %1799 = add i64 %1771, 31
  store i64 %1799, i64* %PC, align 8
  %1800 = inttoptr i64 %1798 to double*
  store double %1797, double* %1800, align 8
  %1801 = load i64, i64* %RBP, align 8
  %1802 = add i64 %1801, -16
  %1803 = load i64, i64* %PC, align 8
  %1804 = add i64 %1803, 4
  store i64 %1804, i64* %PC, align 8
  %1805 = inttoptr i64 %1802 to i64*
  %1806 = load i64, i64* %1805, align 8
  store i64 %1806, i64* %RCX, align 8, !tbaa !2428
  %1807 = add i64 %1801, -28
  %1808 = add i64 %1803, 7
  store i64 %1808, i64* %PC, align 8
  %1809 = inttoptr i64 %1807 to i32*
  %1810 = load i32, i32* %1809, align 4
  %1811 = add i32 %1810, 1
  %1812 = zext i32 %1811 to i64
  store i64 %1812, i64* %RAX, align 8, !tbaa !2428
  %1813 = icmp eq i32 %1810, -1
  %1814 = icmp eq i32 %1811, 0
  %1815 = or i1 %1813, %1814
  %1816 = zext i1 %1815 to i8
  store i8 %1816, i8* %18, align 1, !tbaa !2433
  %1817 = and i32 %1811, 255
  %1818 = tail call i32 @llvm.ctpop.i32(i32 %1817) #10
  %1819 = trunc i32 %1818 to i8
  %1820 = and i8 %1819, 1
  %1821 = xor i8 %1820, 1
  store i8 %1821, i8* %25, align 1, !tbaa !2447
  %1822 = xor i32 %1810, %1811
  %1823 = lshr i32 %1822, 4
  %1824 = trunc i32 %1823 to i8
  %1825 = and i8 %1824, 1
  store i8 %1825, i8* %31, align 1, !tbaa !2451
  %1826 = icmp eq i32 %1811, 0
  %1827 = zext i1 %1826 to i8
  store i8 %1827, i8* %34, align 1, !tbaa !2448
  %1828 = lshr i32 %1811, 31
  %1829 = trunc i32 %1828 to i8
  store i8 %1829, i8* %37, align 1, !tbaa !2449
  %1830 = lshr i32 %1810, 31
  %1831 = xor i32 %1828, %1830
  %1832 = add nuw nsw i32 %1831, %1828
  %1833 = icmp eq i32 %1832, 2
  %1834 = zext i1 %1833 to i8
  store i8 %1834, i8* %43, align 1, !tbaa !2450
  %1835 = sext i32 %1811 to i64
  store i64 %1835, i64* %RDX, align 8, !tbaa !2428
  %1836 = shl nsw i64 %1835, 3
  %1837 = add i64 %1836, %1806
  %1838 = add i64 %1803, 18
  store i64 %1838, i64* %PC, align 8
  %1839 = inttoptr i64 %1837 to double*
  %1840 = load double, double* %1839, align 8
  store double %1840, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %1841 = add i64 %1803, 22
  store i64 %1841, i64* %PC, align 8
  %1842 = load i64, i64* %1805, align 8
  store i64 %1842, i64* %RCX, align 8, !tbaa !2428
  %1843 = add i64 %1801, -32
  %1844 = add i64 %1803, 25
  store i64 %1844, i64* %PC, align 8
  %1845 = inttoptr i64 %1843 to i32*
  %1846 = load i32, i32* %1845, align 4
  %1847 = add i32 %1846, 1
  %1848 = zext i32 %1847 to i64
  store i64 %1848, i64* %RAX, align 8, !tbaa !2428
  %1849 = icmp eq i32 %1846, -1
  %1850 = icmp eq i32 %1847, 0
  %1851 = or i1 %1849, %1850
  %1852 = zext i1 %1851 to i8
  store i8 %1852, i8* %18, align 1, !tbaa !2433
  %1853 = and i32 %1847, 255
  %1854 = tail call i32 @llvm.ctpop.i32(i32 %1853) #10
  %1855 = trunc i32 %1854 to i8
  %1856 = and i8 %1855, 1
  %1857 = xor i8 %1856, 1
  store i8 %1857, i8* %25, align 1, !tbaa !2447
  %1858 = xor i32 %1846, %1847
  %1859 = lshr i32 %1858, 4
  %1860 = trunc i32 %1859 to i8
  %1861 = and i8 %1860, 1
  store i8 %1861, i8* %31, align 1, !tbaa !2451
  %1862 = icmp eq i32 %1847, 0
  %1863 = zext i1 %1862 to i8
  store i8 %1863, i8* %34, align 1, !tbaa !2448
  %1864 = lshr i32 %1847, 31
  %1865 = trunc i32 %1864 to i8
  store i8 %1865, i8* %37, align 1, !tbaa !2449
  %1866 = lshr i32 %1846, 31
  %1867 = xor i32 %1864, %1866
  %1868 = add nuw nsw i32 %1867, %1864
  %1869 = icmp eq i32 %1868, 2
  %1870 = zext i1 %1869 to i8
  store i8 %1870, i8* %43, align 1, !tbaa !2450
  %1871 = sext i32 %1847 to i64
  store i64 %1871, i64* %RDX, align 8, !tbaa !2428
  %1872 = shl nsw i64 %1871, 3
  %1873 = add i64 %1872, %1842
  %1874 = add i64 %1803, 36
  store i64 %1874, i64* %PC, align 8
  %1875 = inttoptr i64 %1873 to double*
  %1876 = load double, double* %1875, align 8
  %1877 = fadd double %1840, %1876
  store double %1877, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %1878 = load i64, i64* %RBP, align 8
  %1879 = add i64 %1878, -128
  %1880 = add i64 %1803, 41
  store i64 %1880, i64* %PC, align 8
  %1881 = inttoptr i64 %1879 to double*
  store double %1877, double* %1881, align 8
  %1882 = load i64, i64* %RBP, align 8
  %1883 = add i64 %1882, -16
  %1884 = load i64, i64* %PC, align 8
  %1885 = add i64 %1884, 4
  store i64 %1885, i64* %PC, align 8
  %1886 = inttoptr i64 %1883 to i64*
  %1887 = load i64, i64* %1886, align 8
  store i64 %1887, i64* %RCX, align 8, !tbaa !2428
  %1888 = add i64 %1882, -28
  %1889 = add i64 %1884, 8
  store i64 %1889, i64* %PC, align 8
  %1890 = inttoptr i64 %1888 to i32*
  %1891 = load i32, i32* %1890, align 4
  %1892 = sext i32 %1891 to i64
  store i64 %1892, i64* %RDX, align 8, !tbaa !2428
  %1893 = shl nsw i64 %1892, 3
  %1894 = add i64 %1893, %1887
  %1895 = add i64 %1884, 13
  store i64 %1895, i64* %PC, align 8
  %1896 = inttoptr i64 %1894 to double*
  %1897 = load double, double* %1896, align 8
  store double %1897, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %1898 = add i64 %1884, 17
  store i64 %1898, i64* %PC, align 8
  %1899 = load i64, i64* %1886, align 8
  store i64 %1899, i64* %RCX, align 8, !tbaa !2428
  %1900 = add i64 %1882, -32
  %1901 = add i64 %1884, 21
  store i64 %1901, i64* %PC, align 8
  %1902 = inttoptr i64 %1900 to i32*
  %1903 = load i32, i32* %1902, align 4
  %1904 = sext i32 %1903 to i64
  store i64 %1904, i64* %RDX, align 8, !tbaa !2428
  %1905 = shl nsw i64 %1904, 3
  %1906 = add i64 %1905, %1899
  %1907 = add i64 %1884, 26
  store i64 %1907, i64* %PC, align 8
  %1908 = inttoptr i64 %1906 to double*
  %1909 = load double, double* %1908, align 8
  %1910 = fsub double %1897, %1909
  store double %1910, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %1911 = add i64 %1882, -136
  %1912 = add i64 %1884, 34
  store i64 %1912, i64* %PC, align 8
  %1913 = inttoptr i64 %1911 to double*
  store double %1910, double* %1913, align 8
  %1914 = load i64, i64* %RBP, align 8
  %1915 = add i64 %1914, -16
  %1916 = load i64, i64* %PC, align 8
  %1917 = add i64 %1916, 4
  store i64 %1917, i64* %PC, align 8
  %1918 = inttoptr i64 %1915 to i64*
  %1919 = load i64, i64* %1918, align 8
  store i64 %1919, i64* %RCX, align 8, !tbaa !2428
  %1920 = add i64 %1914, -28
  %1921 = add i64 %1916, 7
  store i64 %1921, i64* %PC, align 8
  %1922 = inttoptr i64 %1920 to i32*
  %1923 = load i32, i32* %1922, align 4
  %1924 = add i32 %1923, 1
  %1925 = zext i32 %1924 to i64
  store i64 %1925, i64* %RAX, align 8, !tbaa !2428
  %1926 = icmp eq i32 %1923, -1
  %1927 = icmp eq i32 %1924, 0
  %1928 = or i1 %1926, %1927
  %1929 = zext i1 %1928 to i8
  store i8 %1929, i8* %18, align 1, !tbaa !2433
  %1930 = and i32 %1924, 255
  %1931 = tail call i32 @llvm.ctpop.i32(i32 %1930) #10
  %1932 = trunc i32 %1931 to i8
  %1933 = and i8 %1932, 1
  %1934 = xor i8 %1933, 1
  store i8 %1934, i8* %25, align 1, !tbaa !2447
  %1935 = xor i32 %1923, %1924
  %1936 = lshr i32 %1935, 4
  %1937 = trunc i32 %1936 to i8
  %1938 = and i8 %1937, 1
  store i8 %1938, i8* %31, align 1, !tbaa !2451
  %1939 = icmp eq i32 %1924, 0
  %1940 = zext i1 %1939 to i8
  store i8 %1940, i8* %34, align 1, !tbaa !2448
  %1941 = lshr i32 %1924, 31
  %1942 = trunc i32 %1941 to i8
  store i8 %1942, i8* %37, align 1, !tbaa !2449
  %1943 = lshr i32 %1923, 31
  %1944 = xor i32 %1941, %1943
  %1945 = add nuw nsw i32 %1944, %1941
  %1946 = icmp eq i32 %1945, 2
  %1947 = zext i1 %1946 to i8
  store i8 %1947, i8* %43, align 1, !tbaa !2450
  %1948 = sext i32 %1924 to i64
  store i64 %1948, i64* %RDX, align 8, !tbaa !2428
  %1949 = shl nsw i64 %1948, 3
  %1950 = add i64 %1949, %1919
  %1951 = add i64 %1916, 18
  store i64 %1951, i64* %PC, align 8
  %1952 = inttoptr i64 %1950 to double*
  %1953 = load double, double* %1952, align 8
  store double %1953, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %1954 = add i64 %1916, 22
  store i64 %1954, i64* %PC, align 8
  %1955 = load i64, i64* %1918, align 8
  store i64 %1955, i64* %RCX, align 8, !tbaa !2428
  %1956 = add i64 %1914, -32
  %1957 = add i64 %1916, 25
  store i64 %1957, i64* %PC, align 8
  %1958 = inttoptr i64 %1956 to i32*
  %1959 = load i32, i32* %1958, align 4
  %1960 = add i32 %1959, 1
  %1961 = zext i32 %1960 to i64
  store i64 %1961, i64* %RAX, align 8, !tbaa !2428
  %1962 = icmp eq i32 %1959, -1
  %1963 = icmp eq i32 %1960, 0
  %1964 = or i1 %1962, %1963
  %1965 = zext i1 %1964 to i8
  store i8 %1965, i8* %18, align 1, !tbaa !2433
  %1966 = and i32 %1960, 255
  %1967 = tail call i32 @llvm.ctpop.i32(i32 %1966) #10
  %1968 = trunc i32 %1967 to i8
  %1969 = and i8 %1968, 1
  %1970 = xor i8 %1969, 1
  store i8 %1970, i8* %25, align 1, !tbaa !2447
  %1971 = xor i32 %1959, %1960
  %1972 = lshr i32 %1971, 4
  %1973 = trunc i32 %1972 to i8
  %1974 = and i8 %1973, 1
  store i8 %1974, i8* %31, align 1, !tbaa !2451
  %1975 = icmp eq i32 %1960, 0
  %1976 = zext i1 %1975 to i8
  store i8 %1976, i8* %34, align 1, !tbaa !2448
  %1977 = lshr i32 %1960, 31
  %1978 = trunc i32 %1977 to i8
  store i8 %1978, i8* %37, align 1, !tbaa !2449
  %1979 = lshr i32 %1959, 31
  %1980 = xor i32 %1977, %1979
  %1981 = add nuw nsw i32 %1980, %1977
  %1982 = icmp eq i32 %1981, 2
  %1983 = zext i1 %1982 to i8
  store i8 %1983, i8* %43, align 1, !tbaa !2450
  %1984 = sext i32 %1960 to i64
  store i64 %1984, i64* %RDX, align 8, !tbaa !2428
  %1985 = shl nsw i64 %1984, 3
  %1986 = add i64 %1985, %1955
  %1987 = add i64 %1916, 36
  store i64 %1987, i64* %PC, align 8
  %1988 = inttoptr i64 %1986 to double*
  %1989 = load double, double* %1988, align 8
  %1990 = fsub double %1953, %1989
  store double %1990, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %1991 = load i64, i64* %RBP, align 8
  %1992 = add i64 %1991, -144
  %1993 = add i64 %1916, 44
  store i64 %1993, i64* %PC, align 8
  %1994 = inttoptr i64 %1992 to double*
  store double %1990, double* %1994, align 8
  %1995 = load i64, i64* %RBP, align 8
  %1996 = add i64 %1995, -16
  %1997 = load i64, i64* %PC, align 8
  %1998 = add i64 %1997, 4
  store i64 %1998, i64* %PC, align 8
  %1999 = inttoptr i64 %1996 to i64*
  %2000 = load i64, i64* %1999, align 8
  store i64 %2000, i64* %RCX, align 8, !tbaa !2428
  %2001 = add i64 %1995, -36
  %2002 = add i64 %1997, 8
  store i64 %2002, i64* %PC, align 8
  %2003 = inttoptr i64 %2001 to i32*
  %2004 = load i32, i32* %2003, align 4
  %2005 = sext i32 %2004 to i64
  store i64 %2005, i64* %RDX, align 8, !tbaa !2428
  %2006 = shl nsw i64 %2005, 3
  %2007 = add i64 %2006, %2000
  %2008 = add i64 %1997, 13
  store i64 %2008, i64* %PC, align 8
  %2009 = inttoptr i64 %2007 to double*
  %2010 = load double, double* %2009, align 8
  store double %2010, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2011 = add i64 %1997, 17
  store i64 %2011, i64* %PC, align 8
  %2012 = load i64, i64* %1999, align 8
  store i64 %2012, i64* %RCX, align 8, !tbaa !2428
  %2013 = add i64 %1995, -40
  %2014 = add i64 %1997, 21
  store i64 %2014, i64* %PC, align 8
  %2015 = inttoptr i64 %2013 to i32*
  %2016 = load i32, i32* %2015, align 4
  %2017 = sext i32 %2016 to i64
  store i64 %2017, i64* %RDX, align 8, !tbaa !2428
  %2018 = shl nsw i64 %2017, 3
  %2019 = add i64 %2018, %2012
  %2020 = add i64 %1997, 26
  store i64 %2020, i64* %PC, align 8
  %2021 = inttoptr i64 %2019 to double*
  %2022 = load double, double* %2021, align 8
  %2023 = fadd double %2010, %2022
  store double %2023, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2024 = add i64 %1995, -152
  %2025 = add i64 %1997, 34
  store i64 %2025, i64* %PC, align 8
  %2026 = inttoptr i64 %2024 to double*
  store double %2023, double* %2026, align 8
  %2027 = load i64, i64* %RBP, align 8
  %2028 = add i64 %2027, -16
  %2029 = load i64, i64* %PC, align 8
  %2030 = add i64 %2029, 4
  store i64 %2030, i64* %PC, align 8
  %2031 = inttoptr i64 %2028 to i64*
  %2032 = load i64, i64* %2031, align 8
  store i64 %2032, i64* %RCX, align 8, !tbaa !2428
  %2033 = add i64 %2027, -36
  %2034 = add i64 %2029, 7
  store i64 %2034, i64* %PC, align 8
  %2035 = inttoptr i64 %2033 to i32*
  %2036 = load i32, i32* %2035, align 4
  %2037 = add i32 %2036, 1
  %2038 = zext i32 %2037 to i64
  store i64 %2038, i64* %RAX, align 8, !tbaa !2428
  %2039 = icmp eq i32 %2036, -1
  %2040 = icmp eq i32 %2037, 0
  %2041 = or i1 %2039, %2040
  %2042 = zext i1 %2041 to i8
  store i8 %2042, i8* %18, align 1, !tbaa !2433
  %2043 = and i32 %2037, 255
  %2044 = tail call i32 @llvm.ctpop.i32(i32 %2043) #10
  %2045 = trunc i32 %2044 to i8
  %2046 = and i8 %2045, 1
  %2047 = xor i8 %2046, 1
  store i8 %2047, i8* %25, align 1, !tbaa !2447
  %2048 = xor i32 %2036, %2037
  %2049 = lshr i32 %2048, 4
  %2050 = trunc i32 %2049 to i8
  %2051 = and i8 %2050, 1
  store i8 %2051, i8* %31, align 1, !tbaa !2451
  %2052 = icmp eq i32 %2037, 0
  %2053 = zext i1 %2052 to i8
  store i8 %2053, i8* %34, align 1, !tbaa !2448
  %2054 = lshr i32 %2037, 31
  %2055 = trunc i32 %2054 to i8
  store i8 %2055, i8* %37, align 1, !tbaa !2449
  %2056 = lshr i32 %2036, 31
  %2057 = xor i32 %2054, %2056
  %2058 = add nuw nsw i32 %2057, %2054
  %2059 = icmp eq i32 %2058, 2
  %2060 = zext i1 %2059 to i8
  store i8 %2060, i8* %43, align 1, !tbaa !2450
  %2061 = sext i32 %2037 to i64
  store i64 %2061, i64* %RDX, align 8, !tbaa !2428
  %2062 = shl nsw i64 %2061, 3
  %2063 = add i64 %2062, %2032
  %2064 = add i64 %2029, 18
  store i64 %2064, i64* %PC, align 8
  %2065 = inttoptr i64 %2063 to double*
  %2066 = load double, double* %2065, align 8
  store double %2066, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2067 = add i64 %2029, 22
  store i64 %2067, i64* %PC, align 8
  %2068 = load i64, i64* %2031, align 8
  store i64 %2068, i64* %RCX, align 8, !tbaa !2428
  %2069 = add i64 %2027, -40
  %2070 = add i64 %2029, 25
  store i64 %2070, i64* %PC, align 8
  %2071 = inttoptr i64 %2069 to i32*
  %2072 = load i32, i32* %2071, align 4
  %2073 = add i32 %2072, 1
  %2074 = zext i32 %2073 to i64
  store i64 %2074, i64* %RAX, align 8, !tbaa !2428
  %2075 = icmp eq i32 %2072, -1
  %2076 = icmp eq i32 %2073, 0
  %2077 = or i1 %2075, %2076
  %2078 = zext i1 %2077 to i8
  store i8 %2078, i8* %18, align 1, !tbaa !2433
  %2079 = and i32 %2073, 255
  %2080 = tail call i32 @llvm.ctpop.i32(i32 %2079) #10
  %2081 = trunc i32 %2080 to i8
  %2082 = and i8 %2081, 1
  %2083 = xor i8 %2082, 1
  store i8 %2083, i8* %25, align 1, !tbaa !2447
  %2084 = xor i32 %2072, %2073
  %2085 = lshr i32 %2084, 4
  %2086 = trunc i32 %2085 to i8
  %2087 = and i8 %2086, 1
  store i8 %2087, i8* %31, align 1, !tbaa !2451
  %2088 = icmp eq i32 %2073, 0
  %2089 = zext i1 %2088 to i8
  store i8 %2089, i8* %34, align 1, !tbaa !2448
  %2090 = lshr i32 %2073, 31
  %2091 = trunc i32 %2090 to i8
  store i8 %2091, i8* %37, align 1, !tbaa !2449
  %2092 = lshr i32 %2072, 31
  %2093 = xor i32 %2090, %2092
  %2094 = add nuw nsw i32 %2093, %2090
  %2095 = icmp eq i32 %2094, 2
  %2096 = zext i1 %2095 to i8
  store i8 %2096, i8* %43, align 1, !tbaa !2450
  %2097 = sext i32 %2073 to i64
  store i64 %2097, i64* %RDX, align 8, !tbaa !2428
  %2098 = shl nsw i64 %2097, 3
  %2099 = add i64 %2098, %2068
  %2100 = add i64 %2029, 36
  store i64 %2100, i64* %PC, align 8
  %2101 = inttoptr i64 %2099 to double*
  %2102 = load double, double* %2101, align 8
  %2103 = fadd double %2066, %2102
  store double %2103, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2104 = load i64, i64* %RBP, align 8
  %2105 = add i64 %2104, -160
  %2106 = add i64 %2029, 44
  store i64 %2106, i64* %PC, align 8
  %2107 = inttoptr i64 %2105 to double*
  store double %2103, double* %2107, align 8
  %2108 = load i64, i64* %RBP, align 8
  %2109 = add i64 %2108, -16
  %2110 = load i64, i64* %PC, align 8
  %2111 = add i64 %2110, 4
  store i64 %2111, i64* %PC, align 8
  %2112 = inttoptr i64 %2109 to i64*
  %2113 = load i64, i64* %2112, align 8
  store i64 %2113, i64* %RCX, align 8, !tbaa !2428
  %2114 = add i64 %2108, -36
  %2115 = add i64 %2110, 8
  store i64 %2115, i64* %PC, align 8
  %2116 = inttoptr i64 %2114 to i32*
  %2117 = load i32, i32* %2116, align 4
  %2118 = sext i32 %2117 to i64
  store i64 %2118, i64* %RDX, align 8, !tbaa !2428
  %2119 = shl nsw i64 %2118, 3
  %2120 = add i64 %2119, %2113
  %2121 = add i64 %2110, 13
  store i64 %2121, i64* %PC, align 8
  %2122 = inttoptr i64 %2120 to double*
  %2123 = load double, double* %2122, align 8
  store double %2123, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2124 = add i64 %2110, 17
  store i64 %2124, i64* %PC, align 8
  %2125 = load i64, i64* %2112, align 8
  store i64 %2125, i64* %RCX, align 8, !tbaa !2428
  %2126 = add i64 %2108, -40
  %2127 = add i64 %2110, 21
  store i64 %2127, i64* %PC, align 8
  %2128 = inttoptr i64 %2126 to i32*
  %2129 = load i32, i32* %2128, align 4
  %2130 = sext i32 %2129 to i64
  store i64 %2130, i64* %RDX, align 8, !tbaa !2428
  %2131 = shl nsw i64 %2130, 3
  %2132 = add i64 %2131, %2125
  %2133 = add i64 %2110, 26
  store i64 %2133, i64* %PC, align 8
  %2134 = inttoptr i64 %2132 to double*
  %2135 = load double, double* %2134, align 8
  %2136 = fsub double %2123, %2135
  store double %2136, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2137 = add i64 %2108, -168
  %2138 = add i64 %2110, 34
  store i64 %2138, i64* %PC, align 8
  %2139 = inttoptr i64 %2137 to double*
  store double %2136, double* %2139, align 8
  %2140 = load i64, i64* %RBP, align 8
  %2141 = add i64 %2140, -16
  %2142 = load i64, i64* %PC, align 8
  %2143 = add i64 %2142, 4
  store i64 %2143, i64* %PC, align 8
  %2144 = inttoptr i64 %2141 to i64*
  %2145 = load i64, i64* %2144, align 8
  store i64 %2145, i64* %RCX, align 8, !tbaa !2428
  %2146 = add i64 %2140, -36
  %2147 = add i64 %2142, 7
  store i64 %2147, i64* %PC, align 8
  %2148 = inttoptr i64 %2146 to i32*
  %2149 = load i32, i32* %2148, align 4
  %2150 = add i32 %2149, 1
  %2151 = zext i32 %2150 to i64
  store i64 %2151, i64* %RAX, align 8, !tbaa !2428
  %2152 = icmp eq i32 %2149, -1
  %2153 = icmp eq i32 %2150, 0
  %2154 = or i1 %2152, %2153
  %2155 = zext i1 %2154 to i8
  store i8 %2155, i8* %18, align 1, !tbaa !2433
  %2156 = and i32 %2150, 255
  %2157 = tail call i32 @llvm.ctpop.i32(i32 %2156) #10
  %2158 = trunc i32 %2157 to i8
  %2159 = and i8 %2158, 1
  %2160 = xor i8 %2159, 1
  store i8 %2160, i8* %25, align 1, !tbaa !2447
  %2161 = xor i32 %2149, %2150
  %2162 = lshr i32 %2161, 4
  %2163 = trunc i32 %2162 to i8
  %2164 = and i8 %2163, 1
  store i8 %2164, i8* %31, align 1, !tbaa !2451
  %2165 = icmp eq i32 %2150, 0
  %2166 = zext i1 %2165 to i8
  store i8 %2166, i8* %34, align 1, !tbaa !2448
  %2167 = lshr i32 %2150, 31
  %2168 = trunc i32 %2167 to i8
  store i8 %2168, i8* %37, align 1, !tbaa !2449
  %2169 = lshr i32 %2149, 31
  %2170 = xor i32 %2167, %2169
  %2171 = add nuw nsw i32 %2170, %2167
  %2172 = icmp eq i32 %2171, 2
  %2173 = zext i1 %2172 to i8
  store i8 %2173, i8* %43, align 1, !tbaa !2450
  %2174 = sext i32 %2150 to i64
  store i64 %2174, i64* %RDX, align 8, !tbaa !2428
  %2175 = shl nsw i64 %2174, 3
  %2176 = add i64 %2175, %2145
  %2177 = add i64 %2142, 18
  store i64 %2177, i64* %PC, align 8
  %2178 = inttoptr i64 %2176 to double*
  %2179 = load double, double* %2178, align 8
  store double %2179, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2180 = add i64 %2142, 22
  store i64 %2180, i64* %PC, align 8
  %2181 = load i64, i64* %2144, align 8
  store i64 %2181, i64* %RCX, align 8, !tbaa !2428
  %2182 = add i64 %2140, -40
  %2183 = add i64 %2142, 25
  store i64 %2183, i64* %PC, align 8
  %2184 = inttoptr i64 %2182 to i32*
  %2185 = load i32, i32* %2184, align 4
  %2186 = add i32 %2185, 1
  %2187 = zext i32 %2186 to i64
  store i64 %2187, i64* %RAX, align 8, !tbaa !2428
  %2188 = icmp eq i32 %2185, -1
  %2189 = icmp eq i32 %2186, 0
  %2190 = or i1 %2188, %2189
  %2191 = zext i1 %2190 to i8
  store i8 %2191, i8* %18, align 1, !tbaa !2433
  %2192 = and i32 %2186, 255
  %2193 = tail call i32 @llvm.ctpop.i32(i32 %2192) #10
  %2194 = trunc i32 %2193 to i8
  %2195 = and i8 %2194, 1
  %2196 = xor i8 %2195, 1
  store i8 %2196, i8* %25, align 1, !tbaa !2447
  %2197 = xor i32 %2185, %2186
  %2198 = lshr i32 %2197, 4
  %2199 = trunc i32 %2198 to i8
  %2200 = and i8 %2199, 1
  store i8 %2200, i8* %31, align 1, !tbaa !2451
  %2201 = icmp eq i32 %2186, 0
  %2202 = zext i1 %2201 to i8
  store i8 %2202, i8* %34, align 1, !tbaa !2448
  %2203 = lshr i32 %2186, 31
  %2204 = trunc i32 %2203 to i8
  store i8 %2204, i8* %37, align 1, !tbaa !2449
  %2205 = lshr i32 %2185, 31
  %2206 = xor i32 %2203, %2205
  %2207 = add nuw nsw i32 %2206, %2203
  %2208 = icmp eq i32 %2207, 2
  %2209 = zext i1 %2208 to i8
  store i8 %2209, i8* %43, align 1, !tbaa !2450
  %2210 = sext i32 %2186 to i64
  store i64 %2210, i64* %RDX, align 8, !tbaa !2428
  %2211 = shl nsw i64 %2210, 3
  %2212 = add i64 %2211, %2181
  %2213 = add i64 %2142, 36
  store i64 %2213, i64* %PC, align 8
  %2214 = inttoptr i64 %2212 to double*
  %2215 = load double, double* %2214, align 8
  %2216 = fsub double %2179, %2215
  store double %2216, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2217 = load i64, i64* %RBP, align 8
  %2218 = add i64 %2217, -176
  %2219 = add i64 %2142, 44
  store i64 %2219, i64* %PC, align 8
  %2220 = inttoptr i64 %2218 to double*
  store double %2216, double* %2220, align 8
  %2221 = load i64, i64* %RBP, align 8
  %2222 = add i64 %2221, -120
  %2223 = load i64, i64* %PC, align 8
  %2224 = add i64 %2223, 5
  store i64 %2224, i64* %PC, align 8
  %2225 = inttoptr i64 %2222 to double*
  %2226 = load double, double* %2225, align 8
  store double %2226, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2227 = add i64 %2221, -152
  %2228 = add i64 %2223, 13
  store i64 %2228, i64* %PC, align 8
  %2229 = inttoptr i64 %2227 to double*
  %2230 = load double, double* %2229, align 8
  %2231 = fadd double %2226, %2230
  store double %2231, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2232 = add i64 %2221, -16
  %2233 = add i64 %2223, 17
  store i64 %2233, i64* %PC, align 8
  %2234 = inttoptr i64 %2232 to i64*
  %2235 = load i64, i64* %2234, align 8
  store i64 %2235, i64* %RCX, align 8, !tbaa !2428
  %2236 = add i64 %2221, -28
  %2237 = add i64 %2223, 21
  store i64 %2237, i64* %PC, align 8
  %2238 = inttoptr i64 %2236 to i32*
  %2239 = load i32, i32* %2238, align 4
  %2240 = sext i32 %2239 to i64
  store i64 %2240, i64* %RDX, align 8, !tbaa !2428
  %2241 = shl nsw i64 %2240, 3
  %2242 = add i64 %2241, %2235
  %2243 = add i64 %2223, 26
  store i64 %2243, i64* %PC, align 8
  %2244 = inttoptr i64 %2242 to double*
  store double %2231, double* %2244, align 8
  %2245 = load i64, i64* %RBP, align 8
  %2246 = add i64 %2245, -128
  %2247 = load i64, i64* %PC, align 8
  %2248 = add i64 %2247, 5
  store i64 %2248, i64* %PC, align 8
  %2249 = inttoptr i64 %2246 to double*
  %2250 = load double, double* %2249, align 8
  store double %2250, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2251 = add i64 %2245, -160
  %2252 = add i64 %2247, 13
  store i64 %2252, i64* %PC, align 8
  %2253 = inttoptr i64 %2251 to double*
  %2254 = load double, double* %2253, align 8
  %2255 = fadd double %2250, %2254
  store double %2255, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2256 = add i64 %2245, -16
  %2257 = add i64 %2247, 17
  store i64 %2257, i64* %PC, align 8
  %2258 = inttoptr i64 %2256 to i64*
  %2259 = load i64, i64* %2258, align 8
  store i64 %2259, i64* %RCX, align 8, !tbaa !2428
  %2260 = add i64 %2245, -28
  %2261 = add i64 %2247, 20
  store i64 %2261, i64* %PC, align 8
  %2262 = inttoptr i64 %2260 to i32*
  %2263 = load i32, i32* %2262, align 4
  %2264 = add i32 %2263, 1
  %2265 = zext i32 %2264 to i64
  store i64 %2265, i64* %RAX, align 8, !tbaa !2428
  %2266 = icmp eq i32 %2263, -1
  %2267 = icmp eq i32 %2264, 0
  %2268 = or i1 %2266, %2267
  %2269 = zext i1 %2268 to i8
  store i8 %2269, i8* %18, align 1, !tbaa !2433
  %2270 = and i32 %2264, 255
  %2271 = tail call i32 @llvm.ctpop.i32(i32 %2270) #10
  %2272 = trunc i32 %2271 to i8
  %2273 = and i8 %2272, 1
  %2274 = xor i8 %2273, 1
  store i8 %2274, i8* %25, align 1, !tbaa !2447
  %2275 = xor i32 %2263, %2264
  %2276 = lshr i32 %2275, 4
  %2277 = trunc i32 %2276 to i8
  %2278 = and i8 %2277, 1
  store i8 %2278, i8* %31, align 1, !tbaa !2451
  %2279 = icmp eq i32 %2264, 0
  %2280 = zext i1 %2279 to i8
  store i8 %2280, i8* %34, align 1, !tbaa !2448
  %2281 = lshr i32 %2264, 31
  %2282 = trunc i32 %2281 to i8
  store i8 %2282, i8* %37, align 1, !tbaa !2449
  %2283 = lshr i32 %2263, 31
  %2284 = xor i32 %2281, %2283
  %2285 = add nuw nsw i32 %2284, %2281
  %2286 = icmp eq i32 %2285, 2
  %2287 = zext i1 %2286 to i8
  store i8 %2287, i8* %43, align 1, !tbaa !2450
  %2288 = sext i32 %2264 to i64
  store i64 %2288, i64* %RDX, align 8, !tbaa !2428
  %2289 = shl nsw i64 %2288, 3
  %2290 = add i64 %2289, %2259
  %2291 = add i64 %2247, 31
  store i64 %2291, i64* %PC, align 8
  %2292 = inttoptr i64 %2290 to double*
  store double %2255, double* %2292, align 8
  %2293 = load i64, i64* %RBP, align 8
  %2294 = add i64 %2293, -160
  %2295 = load i64, i64* %PC, align 8
  %2296 = add i64 %2295, 8
  store i64 %2296, i64* %PC, align 8
  %2297 = inttoptr i64 %2294 to double*
  %2298 = load double, double* %2297, align 8
  store double %2298, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2299 = add i64 %2293, -128
  %2300 = add i64 %2295, 13
  store i64 %2300, i64* %PC, align 8
  %2301 = inttoptr i64 %2299 to double*
  %2302 = load double, double* %2301, align 8
  %2303 = fsub double %2298, %2302
  store double %2303, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2304 = add i64 %2293, -16
  %2305 = add i64 %2295, 17
  store i64 %2305, i64* %PC, align 8
  %2306 = inttoptr i64 %2304 to i64*
  %2307 = load i64, i64* %2306, align 8
  store i64 %2307, i64* %RCX, align 8, !tbaa !2428
  %2308 = add i64 %2293, -36
  %2309 = add i64 %2295, 21
  store i64 %2309, i64* %PC, align 8
  %2310 = inttoptr i64 %2308 to i32*
  %2311 = load i32, i32* %2310, align 4
  %2312 = sext i32 %2311 to i64
  store i64 %2312, i64* %RDX, align 8, !tbaa !2428
  %2313 = shl nsw i64 %2312, 3
  %2314 = add i64 %2313, %2307
  %2315 = add i64 %2295, 26
  store i64 %2315, i64* %PC, align 8
  %2316 = inttoptr i64 %2314 to double*
  store double %2303, double* %2316, align 8
  %2317 = load i64, i64* %RBP, align 8
  %2318 = add i64 %2317, -120
  %2319 = load i64, i64* %PC, align 8
  %2320 = add i64 %2319, 5
  store i64 %2320, i64* %PC, align 8
  %2321 = inttoptr i64 %2318 to double*
  %2322 = load double, double* %2321, align 8
  store double %2322, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2323 = add i64 %2317, -152
  %2324 = add i64 %2319, 13
  store i64 %2324, i64* %PC, align 8
  %2325 = inttoptr i64 %2323 to double*
  %2326 = load double, double* %2325, align 8
  %2327 = fsub double %2322, %2326
  store double %2327, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2328 = add i64 %2317, -16
  %2329 = add i64 %2319, 17
  store i64 %2329, i64* %PC, align 8
  %2330 = inttoptr i64 %2328 to i64*
  %2331 = load i64, i64* %2330, align 8
  store i64 %2331, i64* %RCX, align 8, !tbaa !2428
  %2332 = add i64 %2317, -36
  %2333 = add i64 %2319, 20
  store i64 %2333, i64* %PC, align 8
  %2334 = inttoptr i64 %2332 to i32*
  %2335 = load i32, i32* %2334, align 4
  %2336 = add i32 %2335, 1
  %2337 = zext i32 %2336 to i64
  store i64 %2337, i64* %RAX, align 8, !tbaa !2428
  %2338 = icmp eq i32 %2335, -1
  %2339 = icmp eq i32 %2336, 0
  %2340 = or i1 %2338, %2339
  %2341 = zext i1 %2340 to i8
  store i8 %2341, i8* %18, align 1, !tbaa !2433
  %2342 = and i32 %2336, 255
  %2343 = tail call i32 @llvm.ctpop.i32(i32 %2342) #10
  %2344 = trunc i32 %2343 to i8
  %2345 = and i8 %2344, 1
  %2346 = xor i8 %2345, 1
  store i8 %2346, i8* %25, align 1, !tbaa !2447
  %2347 = xor i32 %2335, %2336
  %2348 = lshr i32 %2347, 4
  %2349 = trunc i32 %2348 to i8
  %2350 = and i8 %2349, 1
  store i8 %2350, i8* %31, align 1, !tbaa !2451
  %2351 = icmp eq i32 %2336, 0
  %2352 = zext i1 %2351 to i8
  store i8 %2352, i8* %34, align 1, !tbaa !2448
  %2353 = lshr i32 %2336, 31
  %2354 = trunc i32 %2353 to i8
  store i8 %2354, i8* %37, align 1, !tbaa !2449
  %2355 = lshr i32 %2335, 31
  %2356 = xor i32 %2353, %2355
  %2357 = add nuw nsw i32 %2356, %2353
  %2358 = icmp eq i32 %2357, 2
  %2359 = zext i1 %2358 to i8
  store i8 %2359, i8* %43, align 1, !tbaa !2450
  %2360 = sext i32 %2336 to i64
  store i64 %2360, i64* %RDX, align 8, !tbaa !2428
  %2361 = shl nsw i64 %2360, 3
  %2362 = add i64 %2361, %2331
  %2363 = add i64 %2319, 31
  store i64 %2363, i64* %PC, align 8
  %2364 = inttoptr i64 %2362 to double*
  store double %2327, double* %2364, align 8
  %2365 = load i64, i64* %RBP, align 8
  %2366 = add i64 %2365, -136
  %2367 = load i64, i64* %PC, align 8
  %2368 = add i64 %2367, 8
  store i64 %2368, i64* %PC, align 8
  %2369 = inttoptr i64 %2366 to double*
  %2370 = load double, double* %2369, align 8
  store double %2370, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2371 = add i64 %2365, -176
  %2372 = add i64 %2367, 16
  store i64 %2372, i64* %PC, align 8
  %2373 = inttoptr i64 %2371 to double*
  %2374 = load double, double* %2373, align 8
  %2375 = fsub double %2370, %2374
  store double %2375, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2376 = add i64 %2365, -120
  %2377 = add i64 %2367, 21
  store i64 %2377, i64* %PC, align 8
  %2378 = inttoptr i64 %2376 to double*
  store double %2375, double* %2378, align 8
  %2379 = load i64, i64* %RBP, align 8
  %2380 = add i64 %2379, -144
  %2381 = load i64, i64* %PC, align 8
  %2382 = add i64 %2381, 8
  store i64 %2382, i64* %PC, align 8
  %2383 = inttoptr i64 %2380 to double*
  %2384 = load double, double* %2383, align 8
  store double %2384, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2385 = add i64 %2379, -168
  %2386 = add i64 %2381, 16
  store i64 %2386, i64* %PC, align 8
  %2387 = inttoptr i64 %2385 to double*
  %2388 = load double, double* %2387, align 8
  %2389 = fadd double %2384, %2388
  store double %2389, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2390 = add i64 %2379, -128
  %2391 = add i64 %2381, 21
  store i64 %2391, i64* %PC, align 8
  %2392 = inttoptr i64 %2390 to double*
  store double %2389, double* %2392, align 8
  %2393 = load i64, i64* %RBP, align 8
  %2394 = add i64 %2393, -72
  %2395 = load i64, i64* %PC, align 8
  %2396 = add i64 %2395, 5
  store i64 %2396, i64* %PC, align 8
  %2397 = inttoptr i64 %2394 to double*
  %2398 = load double, double* %2397, align 8
  store double %2398, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2399 = add i64 %2393, -120
  %2400 = add i64 %2395, 10
  store i64 %2400, i64* %PC, align 8
  %2401 = inttoptr i64 %2399 to double*
  %2402 = load double, double* %2401, align 8
  store double %2402, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %2403 = add i64 %2393, -128
  %2404 = add i64 %2395, 15
  store i64 %2404, i64* %PC, align 8
  %2405 = inttoptr i64 %2403 to double*
  %2406 = load double, double* %2405, align 8
  %2407 = fsub double %2402, %2406
  store double %2407, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %2408 = fmul double %2398, %2407
  store double %2408, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2409 = add i64 %2393, -16
  %2410 = add i64 %2395, 23
  store i64 %2410, i64* %PC, align 8
  %2411 = inttoptr i64 %2409 to i64*
  %2412 = load i64, i64* %2411, align 8
  store i64 %2412, i64* %RCX, align 8, !tbaa !2428
  %2413 = add i64 %2393, -32
  %2414 = add i64 %2395, 27
  store i64 %2414, i64* %PC, align 8
  %2415 = inttoptr i64 %2413 to i32*
  %2416 = load i32, i32* %2415, align 4
  %2417 = sext i32 %2416 to i64
  store i64 %2417, i64* %RDX, align 8, !tbaa !2428
  %2418 = shl nsw i64 %2417, 3
  %2419 = add i64 %2418, %2412
  %2420 = add i64 %2395, 32
  store i64 %2420, i64* %PC, align 8
  %2421 = inttoptr i64 %2419 to double*
  store double %2408, double* %2421, align 8
  %2422 = load i64, i64* %RBP, align 8
  %2423 = add i64 %2422, -72
  %2424 = load i64, i64* %PC, align 8
  %2425 = add i64 %2424, 5
  store i64 %2425, i64* %PC, align 8
  %2426 = inttoptr i64 %2423 to double*
  %2427 = load double, double* %2426, align 8
  store double %2427, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2428 = add i64 %2422, -120
  %2429 = add i64 %2424, 10
  store i64 %2429, i64* %PC, align 8
  %2430 = inttoptr i64 %2428 to double*
  %2431 = load double, double* %2430, align 8
  store double %2431, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %2432 = add i64 %2422, -128
  %2433 = add i64 %2424, 15
  store i64 %2433, i64* %PC, align 8
  %2434 = inttoptr i64 %2432 to double*
  %2435 = load double, double* %2434, align 8
  %2436 = fadd double %2431, %2435
  store double %2436, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %2437 = fmul double %2427, %2436
  store double %2437, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2438 = add i64 %2422, -16
  %2439 = add i64 %2424, 23
  store i64 %2439, i64* %PC, align 8
  %2440 = inttoptr i64 %2438 to i64*
  %2441 = load i64, i64* %2440, align 8
  store i64 %2441, i64* %RCX, align 8, !tbaa !2428
  %2442 = add i64 %2422, -32
  %2443 = add i64 %2424, 26
  store i64 %2443, i64* %PC, align 8
  %2444 = inttoptr i64 %2442 to i32*
  %2445 = load i32, i32* %2444, align 4
  %2446 = add i32 %2445, 1
  %2447 = zext i32 %2446 to i64
  store i64 %2447, i64* %RAX, align 8, !tbaa !2428
  %2448 = icmp eq i32 %2445, -1
  %2449 = icmp eq i32 %2446, 0
  %2450 = or i1 %2448, %2449
  %2451 = zext i1 %2450 to i8
  store i8 %2451, i8* %18, align 1, !tbaa !2433
  %2452 = and i32 %2446, 255
  %2453 = tail call i32 @llvm.ctpop.i32(i32 %2452) #10
  %2454 = trunc i32 %2453 to i8
  %2455 = and i8 %2454, 1
  %2456 = xor i8 %2455, 1
  store i8 %2456, i8* %25, align 1, !tbaa !2447
  %2457 = xor i32 %2445, %2446
  %2458 = lshr i32 %2457, 4
  %2459 = trunc i32 %2458 to i8
  %2460 = and i8 %2459, 1
  store i8 %2460, i8* %31, align 1, !tbaa !2451
  %2461 = icmp eq i32 %2446, 0
  %2462 = zext i1 %2461 to i8
  store i8 %2462, i8* %34, align 1, !tbaa !2448
  %2463 = lshr i32 %2446, 31
  %2464 = trunc i32 %2463 to i8
  store i8 %2464, i8* %37, align 1, !tbaa !2449
  %2465 = lshr i32 %2445, 31
  %2466 = xor i32 %2463, %2465
  %2467 = add nuw nsw i32 %2466, %2463
  %2468 = icmp eq i32 %2467, 2
  %2469 = zext i1 %2468 to i8
  store i8 %2469, i8* %43, align 1, !tbaa !2450
  %2470 = sext i32 %2446 to i64
  store i64 %2470, i64* %RDX, align 8, !tbaa !2428
  %2471 = shl nsw i64 %2470, 3
  %2472 = add i64 %2471, %2441
  %2473 = add i64 %2424, 37
  store i64 %2473, i64* %PC, align 8
  %2474 = inttoptr i64 %2472 to double*
  store double %2437, double* %2474, align 8
  %2475 = load i64, i64* %RBP, align 8
  %2476 = add i64 %2475, -176
  %2477 = load i64, i64* %PC, align 8
  %2478 = add i64 %2477, 8
  store i64 %2478, i64* %PC, align 8
  %2479 = inttoptr i64 %2476 to double*
  %2480 = load double, double* %2479, align 8
  store double %2480, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2481 = add i64 %2475, -136
  %2482 = add i64 %2477, 16
  store i64 %2482, i64* %PC, align 8
  %2483 = inttoptr i64 %2481 to double*
  %2484 = load double, double* %2483, align 8
  %2485 = fadd double %2480, %2484
  store double %2485, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2486 = add i64 %2475, -120
  %2487 = add i64 %2477, 21
  store i64 %2487, i64* %PC, align 8
  %2488 = inttoptr i64 %2486 to double*
  store double %2485, double* %2488, align 8
  %2489 = load i64, i64* %RBP, align 8
  %2490 = add i64 %2489, -168
  %2491 = load i64, i64* %PC, align 8
  %2492 = add i64 %2491, 8
  store i64 %2492, i64* %PC, align 8
  %2493 = inttoptr i64 %2490 to double*
  %2494 = load double, double* %2493, align 8
  store double %2494, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2495 = add i64 %2489, -144
  %2496 = add i64 %2491, 16
  store i64 %2496, i64* %PC, align 8
  %2497 = inttoptr i64 %2495 to double*
  %2498 = load double, double* %2497, align 8
  %2499 = fsub double %2494, %2498
  store double %2499, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2500 = add i64 %2489, -128
  %2501 = add i64 %2491, 21
  store i64 %2501, i64* %PC, align 8
  %2502 = inttoptr i64 %2500 to double*
  store double %2499, double* %2502, align 8
  %2503 = load i64, i64* %RBP, align 8
  %2504 = add i64 %2503, -72
  %2505 = load i64, i64* %PC, align 8
  %2506 = add i64 %2505, 5
  store i64 %2506, i64* %PC, align 8
  %2507 = inttoptr i64 %2504 to double*
  %2508 = load double, double* %2507, align 8
  store double %2508, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2509 = add i64 %2503, -128
  %2510 = add i64 %2505, 10
  store i64 %2510, i64* %PC, align 8
  %2511 = inttoptr i64 %2509 to double*
  %2512 = load double, double* %2511, align 8
  store double %2512, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %2513 = add i64 %2503, -120
  %2514 = add i64 %2505, 15
  store i64 %2514, i64* %PC, align 8
  %2515 = inttoptr i64 %2513 to double*
  %2516 = load double, double* %2515, align 8
  %2517 = fsub double %2512, %2516
  store double %2517, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %2518 = fmul double %2508, %2517
  store double %2518, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2519 = add i64 %2503, -16
  %2520 = add i64 %2505, 23
  store i64 %2520, i64* %PC, align 8
  %2521 = inttoptr i64 %2519 to i64*
  %2522 = load i64, i64* %2521, align 8
  store i64 %2522, i64* %RCX, align 8, !tbaa !2428
  %2523 = add i64 %2503, -40
  %2524 = add i64 %2505, 27
  store i64 %2524, i64* %PC, align 8
  %2525 = inttoptr i64 %2523 to i32*
  %2526 = load i32, i32* %2525, align 4
  %2527 = sext i32 %2526 to i64
  store i64 %2527, i64* %RDX, align 8, !tbaa !2428
  %2528 = shl nsw i64 %2527, 3
  %2529 = add i64 %2528, %2522
  %2530 = add i64 %2505, 32
  store i64 %2530, i64* %PC, align 8
  %2531 = inttoptr i64 %2529 to double*
  store double %2518, double* %2531, align 8
  %2532 = load i64, i64* %RBP, align 8
  %2533 = add i64 %2532, -72
  %2534 = load i64, i64* %PC, align 8
  %2535 = add i64 %2534, 5
  store i64 %2535, i64* %PC, align 8
  %2536 = inttoptr i64 %2533 to double*
  %2537 = load double, double* %2536, align 8
  store double %2537, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2538 = add i64 %2532, -128
  %2539 = add i64 %2534, 10
  store i64 %2539, i64* %PC, align 8
  %2540 = inttoptr i64 %2538 to double*
  %2541 = load double, double* %2540, align 8
  store double %2541, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %2542 = add i64 %2532, -120
  %2543 = add i64 %2534, 15
  store i64 %2543, i64* %PC, align 8
  %2544 = inttoptr i64 %2542 to double*
  %2545 = load double, double* %2544, align 8
  %2546 = fadd double %2541, %2545
  store double %2546, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %2547 = fmul double %2537, %2546
  store double %2547, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2548 = add i64 %2532, -16
  %2549 = add i64 %2534, 23
  store i64 %2549, i64* %PC, align 8
  %2550 = inttoptr i64 %2548 to i64*
  %2551 = load i64, i64* %2550, align 8
  store i64 %2551, i64* %RCX, align 8, !tbaa !2428
  %2552 = add i64 %2532, -40
  %2553 = add i64 %2534, 26
  store i64 %2553, i64* %PC, align 8
  %2554 = inttoptr i64 %2552 to i32*
  %2555 = load i32, i32* %2554, align 4
  %2556 = add i32 %2555, 1
  %2557 = zext i32 %2556 to i64
  store i64 %2557, i64* %RAX, align 8, !tbaa !2428
  %2558 = icmp eq i32 %2555, -1
  %2559 = icmp eq i32 %2556, 0
  %2560 = or i1 %2558, %2559
  %2561 = zext i1 %2560 to i8
  store i8 %2561, i8* %18, align 1, !tbaa !2433
  %2562 = and i32 %2556, 255
  %2563 = tail call i32 @llvm.ctpop.i32(i32 %2562) #10
  %2564 = trunc i32 %2563 to i8
  %2565 = and i8 %2564, 1
  %2566 = xor i8 %2565, 1
  store i8 %2566, i8* %25, align 1, !tbaa !2447
  %2567 = xor i32 %2555, %2556
  %2568 = lshr i32 %2567, 4
  %2569 = trunc i32 %2568 to i8
  %2570 = and i8 %2569, 1
  store i8 %2570, i8* %31, align 1, !tbaa !2451
  %2571 = icmp eq i32 %2556, 0
  %2572 = zext i1 %2571 to i8
  store i8 %2572, i8* %34, align 1, !tbaa !2448
  %2573 = lshr i32 %2556, 31
  %2574 = trunc i32 %2573 to i8
  store i8 %2574, i8* %37, align 1, !tbaa !2449
  %2575 = lshr i32 %2555, 31
  %2576 = xor i32 %2573, %2575
  %2577 = add nuw nsw i32 %2576, %2573
  %2578 = icmp eq i32 %2577, 2
  %2579 = zext i1 %2578 to i8
  store i8 %2579, i8* %43, align 1, !tbaa !2450
  %2580 = sext i32 %2556 to i64
  store i64 %2580, i64* %RDX, align 8, !tbaa !2428
  %2581 = shl nsw i64 %2580, 3
  %2582 = add i64 %2581, %2551
  %2583 = add i64 %2534, 37
  store i64 %2583, i64* %PC, align 8
  %2584 = inttoptr i64 %2582 to double*
  store double %2547, double* %2584, align 8
  %2585 = load i64, i64* %RBP, align 8
  %2586 = add i64 %2585, -28
  %2587 = load i64, i64* %PC, align 8
  %2588 = add i64 %2587, 3
  store i64 %2588, i64* %PC, align 8
  %2589 = inttoptr i64 %2586 to i32*
  %2590 = load i32, i32* %2589, align 4
  %2591 = add i32 %2590, 2
  %2592 = zext i32 %2591 to i64
  store i64 %2592, i64* %RAX, align 8, !tbaa !2428
  %2593 = icmp ugt i32 %2590, -3
  %2594 = zext i1 %2593 to i8
  store i8 %2594, i8* %18, align 1, !tbaa !2433
  %2595 = and i32 %2591, 255
  %2596 = tail call i32 @llvm.ctpop.i32(i32 %2595) #10
  %2597 = trunc i32 %2596 to i8
  %2598 = and i8 %2597, 1
  %2599 = xor i8 %2598, 1
  store i8 %2599, i8* %25, align 1, !tbaa !2447
  %2600 = xor i32 %2590, %2591
  %2601 = lshr i32 %2600, 4
  %2602 = trunc i32 %2601 to i8
  %2603 = and i8 %2602, 1
  store i8 %2603, i8* %31, align 1, !tbaa !2451
  %2604 = icmp eq i32 %2591, 0
  %2605 = zext i1 %2604 to i8
  store i8 %2605, i8* %34, align 1, !tbaa !2448
  %2606 = lshr i32 %2591, 31
  %2607 = trunc i32 %2606 to i8
  store i8 %2607, i8* %37, align 1, !tbaa !2449
  %2608 = lshr i32 %2590, 31
  %2609 = xor i32 %2606, %2608
  %2610 = add nuw nsw i32 %2609, %2606
  %2611 = icmp eq i32 %2610, 2
  %2612 = zext i1 %2611 to i8
  store i8 %2612, i8* %43, align 1, !tbaa !2450
  %2613 = add i64 %2587, 9
  store i64 %2613, i64* %PC, align 8
  store i32 %2591, i32* %2589, align 4
  %2614 = load i64, i64* %PC, align 8
  %2615 = add i64 %2614, -695
  store i64 %2615, i64* %95, align 8, !tbaa !2428
  br label %block_403591

block_403591:                                     ; preds = %block_4035a2, %block_40357d
  %2616 = phi i64 [ %2615, %block_4035a2 ], [ %.pre3, %block_40357d ]
  %2617 = load i64, i64* %RBP, align 8
  %2618 = add i64 %2617, -28
  %2619 = add i64 %2616, 3
  store i64 %2619, i64* %PC, align 8
  %2620 = inttoptr i64 %2618 to i32*
  %2621 = load i32, i32* %2620, align 4
  %2622 = zext i32 %2621 to i64
  store i64 %2622, i64* %RAX, align 8, !tbaa !2428
  %2623 = add i64 %2617, -8
  %2624 = add i64 %2616, 6
  store i64 %2624, i64* %PC, align 8
  %2625 = inttoptr i64 %2623 to i32*
  %2626 = load i32, i32* %2625, align 4
  %2627 = zext i32 %2626 to i64
  store i64 %2627, i64* %RCX, align 8, !tbaa !2428
  %2628 = add i64 %2617, -56
  %2629 = add i64 %2616, 9
  store i64 %2629, i64* %PC, align 8
  %2630 = inttoptr i64 %2628 to i32*
  %2631 = load i32, i32* %2630, align 4
  %2632 = add i32 %2631, %2626
  %2633 = zext i32 %2632 to i64
  store i64 %2633, i64* %RCX, align 8, !tbaa !2428
  %2634 = lshr i32 %2632, 31
  %2635 = sub i32 %2621, %2632
  %2636 = icmp ult i32 %2621, %2632
  %2637 = zext i1 %2636 to i8
  store i8 %2637, i8* %18, align 1, !tbaa !2433
  %2638 = and i32 %2635, 255
  %2639 = tail call i32 @llvm.ctpop.i32(i32 %2638) #10
  %2640 = trunc i32 %2639 to i8
  %2641 = and i8 %2640, 1
  %2642 = xor i8 %2641, 1
  store i8 %2642, i8* %25, align 1, !tbaa !2447
  %2643 = xor i32 %2632, %2621
  %2644 = xor i32 %2643, %2635
  %2645 = lshr i32 %2644, 4
  %2646 = trunc i32 %2645 to i8
  %2647 = and i8 %2646, 1
  store i8 %2647, i8* %31, align 1, !tbaa !2451
  %2648 = icmp eq i32 %2635, 0
  %2649 = zext i1 %2648 to i8
  store i8 %2649, i8* %34, align 1, !tbaa !2448
  %2650 = lshr i32 %2635, 31
  %2651 = trunc i32 %2650 to i8
  store i8 %2651, i8* %37, align 1, !tbaa !2449
  %2652 = lshr i32 %2621, 31
  %2653 = xor i32 %2634, %2652
  %2654 = xor i32 %2650, %2652
  %2655 = add nuw nsw i32 %2654, %2653
  %2656 = icmp eq i32 %2655, 2
  %2657 = zext i1 %2656 to i8
  store i8 %2657, i8* %43, align 1, !tbaa !2450
  %2658 = icmp ne i8 %2651, 0
  %2659 = xor i1 %2658, %2656
  %.v7 = select i1 %2659, i64 17, i64 700
  %2660 = add i64 %2616, %.v7
  store i64 %2660, i64* %95, align 8, !tbaa !2428
  %2661 = load i64, i64* %RBP, align 8
  br i1 %2659, label %block_4035a2, label %block_40384d

block_403863:                                     ; preds = %block_403fcb, %block_40384d
  %2662 = phi i64 [ %1550, %block_403fcb ], [ %.pre4, %block_40384d ]
  %2663 = load i64, i64* %RBP, align 8
  %2664 = add i64 %2663, -44
  %2665 = add i64 %2662, 3
  store i64 %2665, i64* %PC, align 8
  %2666 = inttoptr i64 %2664 to i32*
  %2667 = load i32, i32* %2666, align 4
  %2668 = zext i32 %2667 to i64
  store i64 %2668, i64* %RAX, align 8, !tbaa !2428
  %2669 = add i64 %2663, -4
  %2670 = add i64 %2662, 6
  store i64 %2670, i64* %PC, align 8
  %2671 = inttoptr i64 %2669 to i32*
  %2672 = load i32, i32* %2671, align 4
  %2673 = sub i32 %2667, %2672
  %2674 = icmp ult i32 %2667, %2672
  %2675 = zext i1 %2674 to i8
  store i8 %2675, i8* %18, align 1, !tbaa !2433
  %2676 = and i32 %2673, 255
  %2677 = tail call i32 @llvm.ctpop.i32(i32 %2676) #10
  %2678 = trunc i32 %2677 to i8
  %2679 = and i8 %2678, 1
  %2680 = xor i8 %2679, 1
  store i8 %2680, i8* %25, align 1, !tbaa !2447
  %2681 = xor i32 %2672, %2667
  %2682 = xor i32 %2681, %2673
  %2683 = lshr i32 %2682, 4
  %2684 = trunc i32 %2683 to i8
  %2685 = and i8 %2684, 1
  store i8 %2685, i8* %31, align 1, !tbaa !2451
  %2686 = icmp eq i32 %2673, 0
  %2687 = zext i1 %2686 to i8
  store i8 %2687, i8* %34, align 1, !tbaa !2448
  %2688 = lshr i32 %2673, 31
  %2689 = trunc i32 %2688 to i8
  store i8 %2689, i8* %37, align 1, !tbaa !2449
  %2690 = lshr i32 %2667, 31
  %2691 = lshr i32 %2672, 31
  %2692 = xor i32 %2691, %2690
  %2693 = xor i32 %2688, %2690
  %2694 = add nuw nsw i32 %2693, %2692
  %2695 = icmp eq i32 %2694, 2
  %2696 = zext i1 %2695 to i8
  store i8 %2696, i8* %43, align 1, !tbaa !2450
  %2697 = icmp ne i8 %2689, 0
  %2698 = xor i1 %2697, %2695
  %.v8 = select i1 %2698, i64 12, i64 1915
  %2699 = add i64 %2662, %.v8
  store i64 %2699, i64* %95, align 8, !tbaa !2428
  br i1 %2698, label %block_40386f, label %block_403fde

block_403921:                                     ; preds = %block_403910
  %2700 = load i64, i64* %RBP, align 8
  %2701 = add i64 %2700, -28
  %2702 = add i64 %1647, 3
  store i64 %2702, i64* %PC, align 8
  %2703 = inttoptr i64 %2701 to i32*
  %2704 = load i32, i32* %2703, align 4
  %2705 = zext i32 %2704 to i64
  store i64 %2705, i64* %RAX, align 8, !tbaa !2428
  %2706 = add i64 %2700, -8
  %2707 = add i64 %1647, 6
  store i64 %2707, i64* %PC, align 8
  %2708 = inttoptr i64 %2706 to i32*
  %2709 = load i32, i32* %2708, align 4
  %2710 = add i32 %2709, %2704
  %2711 = zext i32 %2710 to i64
  store i64 %2711, i64* %RAX, align 8, !tbaa !2428
  %2712 = icmp ult i32 %2710, %2704
  %2713 = icmp ult i32 %2710, %2709
  %2714 = or i1 %2712, %2713
  %2715 = zext i1 %2714 to i8
  store i8 %2715, i8* %18, align 1, !tbaa !2433
  %2716 = and i32 %2710, 255
  %2717 = tail call i32 @llvm.ctpop.i32(i32 %2716) #10
  %2718 = trunc i32 %2717 to i8
  %2719 = and i8 %2718, 1
  %2720 = xor i8 %2719, 1
  store i8 %2720, i8* %25, align 1, !tbaa !2447
  %2721 = xor i32 %2709, %2704
  %2722 = xor i32 %2721, %2710
  %2723 = lshr i32 %2722, 4
  %2724 = trunc i32 %2723 to i8
  %2725 = and i8 %2724, 1
  store i8 %2725, i8* %31, align 1, !tbaa !2451
  %2726 = icmp eq i32 %2710, 0
  %2727 = zext i1 %2726 to i8
  store i8 %2727, i8* %34, align 1, !tbaa !2448
  %2728 = lshr i32 %2710, 31
  %2729 = trunc i32 %2728 to i8
  store i8 %2729, i8* %37, align 1, !tbaa !2449
  %2730 = lshr i32 %2704, 31
  %2731 = lshr i32 %2709, 31
  %2732 = xor i32 %2728, %2730
  %2733 = xor i32 %2728, %2731
  %2734 = add nuw nsw i32 %2732, %2733
  %2735 = icmp eq i32 %2734, 2
  %2736 = zext i1 %2735 to i8
  store i8 %2736, i8* %43, align 1, !tbaa !2450
  %2737 = add i64 %2700, -32
  %2738 = add i64 %1647, 9
  store i64 %2738, i64* %PC, align 8
  %2739 = inttoptr i64 %2737 to i32*
  store i32 %2710, i32* %2739, align 4
  %2740 = load i64, i64* %RBP, align 8
  %2741 = add i64 %2740, -32
  %2742 = load i64, i64* %PC, align 8
  %2743 = add i64 %2742, 3
  store i64 %2743, i64* %PC, align 8
  %2744 = inttoptr i64 %2741 to i32*
  %2745 = load i32, i32* %2744, align 4
  %2746 = zext i32 %2745 to i64
  store i64 %2746, i64* %RAX, align 8, !tbaa !2428
  %2747 = add i64 %2740, -8
  %2748 = add i64 %2742, 6
  store i64 %2748, i64* %PC, align 8
  %2749 = inttoptr i64 %2747 to i32*
  %2750 = load i32, i32* %2749, align 4
  %2751 = add i32 %2750, %2745
  %2752 = zext i32 %2751 to i64
  store i64 %2752, i64* %RAX, align 8, !tbaa !2428
  %2753 = icmp ult i32 %2751, %2745
  %2754 = icmp ult i32 %2751, %2750
  %2755 = or i1 %2753, %2754
  %2756 = zext i1 %2755 to i8
  store i8 %2756, i8* %18, align 1, !tbaa !2433
  %2757 = and i32 %2751, 255
  %2758 = tail call i32 @llvm.ctpop.i32(i32 %2757) #10
  %2759 = trunc i32 %2758 to i8
  %2760 = and i8 %2759, 1
  %2761 = xor i8 %2760, 1
  store i8 %2761, i8* %25, align 1, !tbaa !2447
  %2762 = xor i32 %2750, %2745
  %2763 = xor i32 %2762, %2751
  %2764 = lshr i32 %2763, 4
  %2765 = trunc i32 %2764 to i8
  %2766 = and i8 %2765, 1
  store i8 %2766, i8* %31, align 1, !tbaa !2451
  %2767 = icmp eq i32 %2751, 0
  %2768 = zext i1 %2767 to i8
  store i8 %2768, i8* %34, align 1, !tbaa !2448
  %2769 = lshr i32 %2751, 31
  %2770 = trunc i32 %2769 to i8
  store i8 %2770, i8* %37, align 1, !tbaa !2449
  %2771 = lshr i32 %2745, 31
  %2772 = lshr i32 %2750, 31
  %2773 = xor i32 %2769, %2771
  %2774 = xor i32 %2769, %2772
  %2775 = add nuw nsw i32 %2773, %2774
  %2776 = icmp eq i32 %2775, 2
  %2777 = zext i1 %2776 to i8
  store i8 %2777, i8* %43, align 1, !tbaa !2450
  %2778 = add i64 %2740, -36
  %2779 = add i64 %2742, 9
  store i64 %2779, i64* %PC, align 8
  %2780 = inttoptr i64 %2778 to i32*
  store i32 %2751, i32* %2780, align 4
  %2781 = load i64, i64* %RBP, align 8
  %2782 = add i64 %2781, -36
  %2783 = load i64, i64* %PC, align 8
  %2784 = add i64 %2783, 3
  store i64 %2784, i64* %PC, align 8
  %2785 = inttoptr i64 %2782 to i32*
  %2786 = load i32, i32* %2785, align 4
  %2787 = zext i32 %2786 to i64
  store i64 %2787, i64* %RAX, align 8, !tbaa !2428
  %2788 = add i64 %2781, -8
  %2789 = add i64 %2783, 6
  store i64 %2789, i64* %PC, align 8
  %2790 = inttoptr i64 %2788 to i32*
  %2791 = load i32, i32* %2790, align 4
  %2792 = add i32 %2791, %2786
  %2793 = zext i32 %2792 to i64
  store i64 %2793, i64* %RAX, align 8, !tbaa !2428
  %2794 = icmp ult i32 %2792, %2786
  %2795 = icmp ult i32 %2792, %2791
  %2796 = or i1 %2794, %2795
  %2797 = zext i1 %2796 to i8
  store i8 %2797, i8* %18, align 1, !tbaa !2433
  %2798 = and i32 %2792, 255
  %2799 = tail call i32 @llvm.ctpop.i32(i32 %2798) #10
  %2800 = trunc i32 %2799 to i8
  %2801 = and i8 %2800, 1
  %2802 = xor i8 %2801, 1
  store i8 %2802, i8* %25, align 1, !tbaa !2447
  %2803 = xor i32 %2791, %2786
  %2804 = xor i32 %2803, %2792
  %2805 = lshr i32 %2804, 4
  %2806 = trunc i32 %2805 to i8
  %2807 = and i8 %2806, 1
  store i8 %2807, i8* %31, align 1, !tbaa !2451
  %2808 = icmp eq i32 %2792, 0
  %2809 = zext i1 %2808 to i8
  store i8 %2809, i8* %34, align 1, !tbaa !2448
  %2810 = lshr i32 %2792, 31
  %2811 = trunc i32 %2810 to i8
  store i8 %2811, i8* %37, align 1, !tbaa !2449
  %2812 = lshr i32 %2786, 31
  %2813 = lshr i32 %2791, 31
  %2814 = xor i32 %2810, %2812
  %2815 = xor i32 %2810, %2813
  %2816 = add nuw nsw i32 %2814, %2815
  %2817 = icmp eq i32 %2816, 2
  %2818 = zext i1 %2817 to i8
  store i8 %2818, i8* %43, align 1, !tbaa !2450
  %2819 = add i64 %2781, -40
  %2820 = add i64 %2783, 9
  store i64 %2820, i64* %PC, align 8
  %2821 = inttoptr i64 %2819 to i32*
  store i32 %2792, i32* %2821, align 4
  %2822 = load i64, i64* %RBP, align 8
  %2823 = add i64 %2822, -16
  %2824 = load i64, i64* %PC, align 8
  %2825 = add i64 %2824, 4
  store i64 %2825, i64* %PC, align 8
  %2826 = inttoptr i64 %2823 to i64*
  %2827 = load i64, i64* %2826, align 8
  store i64 %2827, i64* %RCX, align 8, !tbaa !2428
  %2828 = add i64 %2822, -28
  %2829 = add i64 %2824, 8
  store i64 %2829, i64* %PC, align 8
  %2830 = inttoptr i64 %2828 to i32*
  %2831 = load i32, i32* %2830, align 4
  %2832 = sext i32 %2831 to i64
  store i64 %2832, i64* %RDX, align 8, !tbaa !2428
  %2833 = shl nsw i64 %2832, 3
  %2834 = add i64 %2833, %2827
  %2835 = add i64 %2824, 13
  store i64 %2835, i64* %PC, align 8
  %2836 = inttoptr i64 %2834 to double*
  %2837 = load double, double* %2836, align 8
  store double %2837, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2838 = add i64 %2824, 17
  store i64 %2838, i64* %PC, align 8
  %2839 = load i64, i64* %2826, align 8
  store i64 %2839, i64* %RCX, align 8, !tbaa !2428
  %2840 = add i64 %2822, -32
  %2841 = add i64 %2824, 21
  store i64 %2841, i64* %PC, align 8
  %2842 = inttoptr i64 %2840 to i32*
  %2843 = load i32, i32* %2842, align 4
  %2844 = sext i32 %2843 to i64
  store i64 %2844, i64* %RDX, align 8, !tbaa !2428
  %2845 = shl nsw i64 %2844, 3
  %2846 = add i64 %2845, %2839
  %2847 = add i64 %2824, 26
  store i64 %2847, i64* %PC, align 8
  %2848 = inttoptr i64 %2846 to double*
  %2849 = load double, double* %2848, align 8
  %2850 = fadd double %2837, %2849
  store double %2850, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2851 = add i64 %2822, -120
  %2852 = add i64 %2824, 31
  store i64 %2852, i64* %PC, align 8
  %2853 = inttoptr i64 %2851 to double*
  store double %2850, double* %2853, align 8
  %2854 = load i64, i64* %RBP, align 8
  %2855 = add i64 %2854, -16
  %2856 = load i64, i64* %PC, align 8
  %2857 = add i64 %2856, 4
  store i64 %2857, i64* %PC, align 8
  %2858 = inttoptr i64 %2855 to i64*
  %2859 = load i64, i64* %2858, align 8
  store i64 %2859, i64* %RCX, align 8, !tbaa !2428
  %2860 = add i64 %2854, -28
  %2861 = add i64 %2856, 7
  store i64 %2861, i64* %PC, align 8
  %2862 = inttoptr i64 %2860 to i32*
  %2863 = load i32, i32* %2862, align 4
  %2864 = add i32 %2863, 1
  %2865 = zext i32 %2864 to i64
  store i64 %2865, i64* %RAX, align 8, !tbaa !2428
  %2866 = icmp eq i32 %2863, -1
  %2867 = icmp eq i32 %2864, 0
  %2868 = or i1 %2866, %2867
  %2869 = zext i1 %2868 to i8
  store i8 %2869, i8* %18, align 1, !tbaa !2433
  %2870 = and i32 %2864, 255
  %2871 = tail call i32 @llvm.ctpop.i32(i32 %2870) #10
  %2872 = trunc i32 %2871 to i8
  %2873 = and i8 %2872, 1
  %2874 = xor i8 %2873, 1
  store i8 %2874, i8* %25, align 1, !tbaa !2447
  %2875 = xor i32 %2863, %2864
  %2876 = lshr i32 %2875, 4
  %2877 = trunc i32 %2876 to i8
  %2878 = and i8 %2877, 1
  store i8 %2878, i8* %31, align 1, !tbaa !2451
  %2879 = icmp eq i32 %2864, 0
  %2880 = zext i1 %2879 to i8
  store i8 %2880, i8* %34, align 1, !tbaa !2448
  %2881 = lshr i32 %2864, 31
  %2882 = trunc i32 %2881 to i8
  store i8 %2882, i8* %37, align 1, !tbaa !2449
  %2883 = lshr i32 %2863, 31
  %2884 = xor i32 %2881, %2883
  %2885 = add nuw nsw i32 %2884, %2881
  %2886 = icmp eq i32 %2885, 2
  %2887 = zext i1 %2886 to i8
  store i8 %2887, i8* %43, align 1, !tbaa !2450
  %2888 = sext i32 %2864 to i64
  store i64 %2888, i64* %RDX, align 8, !tbaa !2428
  %2889 = shl nsw i64 %2888, 3
  %2890 = add i64 %2889, %2859
  %2891 = add i64 %2856, 18
  store i64 %2891, i64* %PC, align 8
  %2892 = inttoptr i64 %2890 to double*
  %2893 = load double, double* %2892, align 8
  store double %2893, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2894 = add i64 %2856, 22
  store i64 %2894, i64* %PC, align 8
  %2895 = load i64, i64* %2858, align 8
  store i64 %2895, i64* %RCX, align 8, !tbaa !2428
  %2896 = add i64 %2854, -32
  %2897 = add i64 %2856, 25
  store i64 %2897, i64* %PC, align 8
  %2898 = inttoptr i64 %2896 to i32*
  %2899 = load i32, i32* %2898, align 4
  %2900 = add i32 %2899, 1
  %2901 = zext i32 %2900 to i64
  store i64 %2901, i64* %RAX, align 8, !tbaa !2428
  %2902 = icmp eq i32 %2899, -1
  %2903 = icmp eq i32 %2900, 0
  %2904 = or i1 %2902, %2903
  %2905 = zext i1 %2904 to i8
  store i8 %2905, i8* %18, align 1, !tbaa !2433
  %2906 = and i32 %2900, 255
  %2907 = tail call i32 @llvm.ctpop.i32(i32 %2906) #10
  %2908 = trunc i32 %2907 to i8
  %2909 = and i8 %2908, 1
  %2910 = xor i8 %2909, 1
  store i8 %2910, i8* %25, align 1, !tbaa !2447
  %2911 = xor i32 %2899, %2900
  %2912 = lshr i32 %2911, 4
  %2913 = trunc i32 %2912 to i8
  %2914 = and i8 %2913, 1
  store i8 %2914, i8* %31, align 1, !tbaa !2451
  %2915 = icmp eq i32 %2900, 0
  %2916 = zext i1 %2915 to i8
  store i8 %2916, i8* %34, align 1, !tbaa !2448
  %2917 = lshr i32 %2900, 31
  %2918 = trunc i32 %2917 to i8
  store i8 %2918, i8* %37, align 1, !tbaa !2449
  %2919 = lshr i32 %2899, 31
  %2920 = xor i32 %2917, %2919
  %2921 = add nuw nsw i32 %2920, %2917
  %2922 = icmp eq i32 %2921, 2
  %2923 = zext i1 %2922 to i8
  store i8 %2923, i8* %43, align 1, !tbaa !2450
  %2924 = sext i32 %2900 to i64
  store i64 %2924, i64* %RDX, align 8, !tbaa !2428
  %2925 = shl nsw i64 %2924, 3
  %2926 = add i64 %2925, %2895
  %2927 = add i64 %2856, 36
  store i64 %2927, i64* %PC, align 8
  %2928 = inttoptr i64 %2926 to double*
  %2929 = load double, double* %2928, align 8
  %2930 = fadd double %2893, %2929
  store double %2930, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2931 = load i64, i64* %RBP, align 8
  %2932 = add i64 %2931, -128
  %2933 = add i64 %2856, 41
  store i64 %2933, i64* %PC, align 8
  %2934 = inttoptr i64 %2932 to double*
  store double %2930, double* %2934, align 8
  %2935 = load i64, i64* %RBP, align 8
  %2936 = add i64 %2935, -16
  %2937 = load i64, i64* %PC, align 8
  %2938 = add i64 %2937, 4
  store i64 %2938, i64* %PC, align 8
  %2939 = inttoptr i64 %2936 to i64*
  %2940 = load i64, i64* %2939, align 8
  store i64 %2940, i64* %RCX, align 8, !tbaa !2428
  %2941 = add i64 %2935, -28
  %2942 = add i64 %2937, 8
  store i64 %2942, i64* %PC, align 8
  %2943 = inttoptr i64 %2941 to i32*
  %2944 = load i32, i32* %2943, align 4
  %2945 = sext i32 %2944 to i64
  store i64 %2945, i64* %RDX, align 8, !tbaa !2428
  %2946 = shl nsw i64 %2945, 3
  %2947 = add i64 %2946, %2940
  %2948 = add i64 %2937, 13
  store i64 %2948, i64* %PC, align 8
  %2949 = inttoptr i64 %2947 to double*
  %2950 = load double, double* %2949, align 8
  store double %2950, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %2951 = add i64 %2937, 17
  store i64 %2951, i64* %PC, align 8
  %2952 = load i64, i64* %2939, align 8
  store i64 %2952, i64* %RCX, align 8, !tbaa !2428
  %2953 = add i64 %2935, -32
  %2954 = add i64 %2937, 21
  store i64 %2954, i64* %PC, align 8
  %2955 = inttoptr i64 %2953 to i32*
  %2956 = load i32, i32* %2955, align 4
  %2957 = sext i32 %2956 to i64
  store i64 %2957, i64* %RDX, align 8, !tbaa !2428
  %2958 = shl nsw i64 %2957, 3
  %2959 = add i64 %2958, %2952
  %2960 = add i64 %2937, 26
  store i64 %2960, i64* %PC, align 8
  %2961 = inttoptr i64 %2959 to double*
  %2962 = load double, double* %2961, align 8
  %2963 = fsub double %2950, %2962
  store double %2963, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %2964 = add i64 %2935, -136
  %2965 = add i64 %2937, 34
  store i64 %2965, i64* %PC, align 8
  %2966 = inttoptr i64 %2964 to double*
  store double %2963, double* %2966, align 8
  %2967 = load i64, i64* %RBP, align 8
  %2968 = add i64 %2967, -16
  %2969 = load i64, i64* %PC, align 8
  %2970 = add i64 %2969, 4
  store i64 %2970, i64* %PC, align 8
  %2971 = inttoptr i64 %2968 to i64*
  %2972 = load i64, i64* %2971, align 8
  store i64 %2972, i64* %RCX, align 8, !tbaa !2428
  %2973 = add i64 %2967, -28
  %2974 = add i64 %2969, 7
  store i64 %2974, i64* %PC, align 8
  %2975 = inttoptr i64 %2973 to i32*
  %2976 = load i32, i32* %2975, align 4
  %2977 = add i32 %2976, 1
  %2978 = zext i32 %2977 to i64
  store i64 %2978, i64* %RAX, align 8, !tbaa !2428
  %2979 = icmp eq i32 %2976, -1
  %2980 = icmp eq i32 %2977, 0
  %2981 = or i1 %2979, %2980
  %2982 = zext i1 %2981 to i8
  store i8 %2982, i8* %18, align 1, !tbaa !2433
  %2983 = and i32 %2977, 255
  %2984 = tail call i32 @llvm.ctpop.i32(i32 %2983) #10
  %2985 = trunc i32 %2984 to i8
  %2986 = and i8 %2985, 1
  %2987 = xor i8 %2986, 1
  store i8 %2987, i8* %25, align 1, !tbaa !2447
  %2988 = xor i32 %2976, %2977
  %2989 = lshr i32 %2988, 4
  %2990 = trunc i32 %2989 to i8
  %2991 = and i8 %2990, 1
  store i8 %2991, i8* %31, align 1, !tbaa !2451
  %2992 = icmp eq i32 %2977, 0
  %2993 = zext i1 %2992 to i8
  store i8 %2993, i8* %34, align 1, !tbaa !2448
  %2994 = lshr i32 %2977, 31
  %2995 = trunc i32 %2994 to i8
  store i8 %2995, i8* %37, align 1, !tbaa !2449
  %2996 = lshr i32 %2976, 31
  %2997 = xor i32 %2994, %2996
  %2998 = add nuw nsw i32 %2997, %2994
  %2999 = icmp eq i32 %2998, 2
  %3000 = zext i1 %2999 to i8
  store i8 %3000, i8* %43, align 1, !tbaa !2450
  %3001 = sext i32 %2977 to i64
  store i64 %3001, i64* %RDX, align 8, !tbaa !2428
  %3002 = shl nsw i64 %3001, 3
  %3003 = add i64 %3002, %2972
  %3004 = add i64 %2969, 18
  store i64 %3004, i64* %PC, align 8
  %3005 = inttoptr i64 %3003 to double*
  %3006 = load double, double* %3005, align 8
  store double %3006, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3007 = add i64 %2969, 22
  store i64 %3007, i64* %PC, align 8
  %3008 = load i64, i64* %2971, align 8
  store i64 %3008, i64* %RCX, align 8, !tbaa !2428
  %3009 = add i64 %2967, -32
  %3010 = add i64 %2969, 25
  store i64 %3010, i64* %PC, align 8
  %3011 = inttoptr i64 %3009 to i32*
  %3012 = load i32, i32* %3011, align 4
  %3013 = add i32 %3012, 1
  %3014 = zext i32 %3013 to i64
  store i64 %3014, i64* %RAX, align 8, !tbaa !2428
  %3015 = icmp eq i32 %3012, -1
  %3016 = icmp eq i32 %3013, 0
  %3017 = or i1 %3015, %3016
  %3018 = zext i1 %3017 to i8
  store i8 %3018, i8* %18, align 1, !tbaa !2433
  %3019 = and i32 %3013, 255
  %3020 = tail call i32 @llvm.ctpop.i32(i32 %3019) #10
  %3021 = trunc i32 %3020 to i8
  %3022 = and i8 %3021, 1
  %3023 = xor i8 %3022, 1
  store i8 %3023, i8* %25, align 1, !tbaa !2447
  %3024 = xor i32 %3012, %3013
  %3025 = lshr i32 %3024, 4
  %3026 = trunc i32 %3025 to i8
  %3027 = and i8 %3026, 1
  store i8 %3027, i8* %31, align 1, !tbaa !2451
  %3028 = icmp eq i32 %3013, 0
  %3029 = zext i1 %3028 to i8
  store i8 %3029, i8* %34, align 1, !tbaa !2448
  %3030 = lshr i32 %3013, 31
  %3031 = trunc i32 %3030 to i8
  store i8 %3031, i8* %37, align 1, !tbaa !2449
  %3032 = lshr i32 %3012, 31
  %3033 = xor i32 %3030, %3032
  %3034 = add nuw nsw i32 %3033, %3030
  %3035 = icmp eq i32 %3034, 2
  %3036 = zext i1 %3035 to i8
  store i8 %3036, i8* %43, align 1, !tbaa !2450
  %3037 = sext i32 %3013 to i64
  store i64 %3037, i64* %RDX, align 8, !tbaa !2428
  %3038 = shl nsw i64 %3037, 3
  %3039 = add i64 %3038, %3008
  %3040 = add i64 %2969, 36
  store i64 %3040, i64* %PC, align 8
  %3041 = inttoptr i64 %3039 to double*
  %3042 = load double, double* %3041, align 8
  %3043 = fsub double %3006, %3042
  store double %3043, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3044 = load i64, i64* %RBP, align 8
  %3045 = add i64 %3044, -144
  %3046 = add i64 %2969, 44
  store i64 %3046, i64* %PC, align 8
  %3047 = inttoptr i64 %3045 to double*
  store double %3043, double* %3047, align 8
  %3048 = load i64, i64* %RBP, align 8
  %3049 = add i64 %3048, -16
  %3050 = load i64, i64* %PC, align 8
  %3051 = add i64 %3050, 4
  store i64 %3051, i64* %PC, align 8
  %3052 = inttoptr i64 %3049 to i64*
  %3053 = load i64, i64* %3052, align 8
  store i64 %3053, i64* %RCX, align 8, !tbaa !2428
  %3054 = add i64 %3048, -36
  %3055 = add i64 %3050, 8
  store i64 %3055, i64* %PC, align 8
  %3056 = inttoptr i64 %3054 to i32*
  %3057 = load i32, i32* %3056, align 4
  %3058 = sext i32 %3057 to i64
  store i64 %3058, i64* %RDX, align 8, !tbaa !2428
  %3059 = shl nsw i64 %3058, 3
  %3060 = add i64 %3059, %3053
  %3061 = add i64 %3050, 13
  store i64 %3061, i64* %PC, align 8
  %3062 = inttoptr i64 %3060 to double*
  %3063 = load double, double* %3062, align 8
  store double %3063, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3064 = add i64 %3050, 17
  store i64 %3064, i64* %PC, align 8
  %3065 = load i64, i64* %3052, align 8
  store i64 %3065, i64* %RCX, align 8, !tbaa !2428
  %3066 = add i64 %3048, -40
  %3067 = add i64 %3050, 21
  store i64 %3067, i64* %PC, align 8
  %3068 = inttoptr i64 %3066 to i32*
  %3069 = load i32, i32* %3068, align 4
  %3070 = sext i32 %3069 to i64
  store i64 %3070, i64* %RDX, align 8, !tbaa !2428
  %3071 = shl nsw i64 %3070, 3
  %3072 = add i64 %3071, %3065
  %3073 = add i64 %3050, 26
  store i64 %3073, i64* %PC, align 8
  %3074 = inttoptr i64 %3072 to double*
  %3075 = load double, double* %3074, align 8
  %3076 = fadd double %3063, %3075
  store double %3076, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3077 = add i64 %3048, -152
  %3078 = add i64 %3050, 34
  store i64 %3078, i64* %PC, align 8
  %3079 = inttoptr i64 %3077 to double*
  store double %3076, double* %3079, align 8
  %3080 = load i64, i64* %RBP, align 8
  %3081 = add i64 %3080, -16
  %3082 = load i64, i64* %PC, align 8
  %3083 = add i64 %3082, 4
  store i64 %3083, i64* %PC, align 8
  %3084 = inttoptr i64 %3081 to i64*
  %3085 = load i64, i64* %3084, align 8
  store i64 %3085, i64* %RCX, align 8, !tbaa !2428
  %3086 = add i64 %3080, -36
  %3087 = add i64 %3082, 7
  store i64 %3087, i64* %PC, align 8
  %3088 = inttoptr i64 %3086 to i32*
  %3089 = load i32, i32* %3088, align 4
  %3090 = add i32 %3089, 1
  %3091 = zext i32 %3090 to i64
  store i64 %3091, i64* %RAX, align 8, !tbaa !2428
  %3092 = icmp eq i32 %3089, -1
  %3093 = icmp eq i32 %3090, 0
  %3094 = or i1 %3092, %3093
  %3095 = zext i1 %3094 to i8
  store i8 %3095, i8* %18, align 1, !tbaa !2433
  %3096 = and i32 %3090, 255
  %3097 = tail call i32 @llvm.ctpop.i32(i32 %3096) #10
  %3098 = trunc i32 %3097 to i8
  %3099 = and i8 %3098, 1
  %3100 = xor i8 %3099, 1
  store i8 %3100, i8* %25, align 1, !tbaa !2447
  %3101 = xor i32 %3089, %3090
  %3102 = lshr i32 %3101, 4
  %3103 = trunc i32 %3102 to i8
  %3104 = and i8 %3103, 1
  store i8 %3104, i8* %31, align 1, !tbaa !2451
  %3105 = icmp eq i32 %3090, 0
  %3106 = zext i1 %3105 to i8
  store i8 %3106, i8* %34, align 1, !tbaa !2448
  %3107 = lshr i32 %3090, 31
  %3108 = trunc i32 %3107 to i8
  store i8 %3108, i8* %37, align 1, !tbaa !2449
  %3109 = lshr i32 %3089, 31
  %3110 = xor i32 %3107, %3109
  %3111 = add nuw nsw i32 %3110, %3107
  %3112 = icmp eq i32 %3111, 2
  %3113 = zext i1 %3112 to i8
  store i8 %3113, i8* %43, align 1, !tbaa !2450
  %3114 = sext i32 %3090 to i64
  store i64 %3114, i64* %RDX, align 8, !tbaa !2428
  %3115 = shl nsw i64 %3114, 3
  %3116 = add i64 %3115, %3085
  %3117 = add i64 %3082, 18
  store i64 %3117, i64* %PC, align 8
  %3118 = inttoptr i64 %3116 to double*
  %3119 = load double, double* %3118, align 8
  store double %3119, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3120 = add i64 %3082, 22
  store i64 %3120, i64* %PC, align 8
  %3121 = load i64, i64* %3084, align 8
  store i64 %3121, i64* %RCX, align 8, !tbaa !2428
  %3122 = add i64 %3080, -40
  %3123 = add i64 %3082, 25
  store i64 %3123, i64* %PC, align 8
  %3124 = inttoptr i64 %3122 to i32*
  %3125 = load i32, i32* %3124, align 4
  %3126 = add i32 %3125, 1
  %3127 = zext i32 %3126 to i64
  store i64 %3127, i64* %RAX, align 8, !tbaa !2428
  %3128 = icmp eq i32 %3125, -1
  %3129 = icmp eq i32 %3126, 0
  %3130 = or i1 %3128, %3129
  %3131 = zext i1 %3130 to i8
  store i8 %3131, i8* %18, align 1, !tbaa !2433
  %3132 = and i32 %3126, 255
  %3133 = tail call i32 @llvm.ctpop.i32(i32 %3132) #10
  %3134 = trunc i32 %3133 to i8
  %3135 = and i8 %3134, 1
  %3136 = xor i8 %3135, 1
  store i8 %3136, i8* %25, align 1, !tbaa !2447
  %3137 = xor i32 %3125, %3126
  %3138 = lshr i32 %3137, 4
  %3139 = trunc i32 %3138 to i8
  %3140 = and i8 %3139, 1
  store i8 %3140, i8* %31, align 1, !tbaa !2451
  %3141 = icmp eq i32 %3126, 0
  %3142 = zext i1 %3141 to i8
  store i8 %3142, i8* %34, align 1, !tbaa !2448
  %3143 = lshr i32 %3126, 31
  %3144 = trunc i32 %3143 to i8
  store i8 %3144, i8* %37, align 1, !tbaa !2449
  %3145 = lshr i32 %3125, 31
  %3146 = xor i32 %3143, %3145
  %3147 = add nuw nsw i32 %3146, %3143
  %3148 = icmp eq i32 %3147, 2
  %3149 = zext i1 %3148 to i8
  store i8 %3149, i8* %43, align 1, !tbaa !2450
  %3150 = sext i32 %3126 to i64
  store i64 %3150, i64* %RDX, align 8, !tbaa !2428
  %3151 = shl nsw i64 %3150, 3
  %3152 = add i64 %3151, %3121
  %3153 = add i64 %3082, 36
  store i64 %3153, i64* %PC, align 8
  %3154 = inttoptr i64 %3152 to double*
  %3155 = load double, double* %3154, align 8
  %3156 = fadd double %3119, %3155
  store double %3156, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3157 = load i64, i64* %RBP, align 8
  %3158 = add i64 %3157, -160
  %3159 = add i64 %3082, 44
  store i64 %3159, i64* %PC, align 8
  %3160 = inttoptr i64 %3158 to double*
  store double %3156, double* %3160, align 8
  %3161 = load i64, i64* %RBP, align 8
  %3162 = add i64 %3161, -16
  %3163 = load i64, i64* %PC, align 8
  %3164 = add i64 %3163, 4
  store i64 %3164, i64* %PC, align 8
  %3165 = inttoptr i64 %3162 to i64*
  %3166 = load i64, i64* %3165, align 8
  store i64 %3166, i64* %RCX, align 8, !tbaa !2428
  %3167 = add i64 %3161, -36
  %3168 = add i64 %3163, 8
  store i64 %3168, i64* %PC, align 8
  %3169 = inttoptr i64 %3167 to i32*
  %3170 = load i32, i32* %3169, align 4
  %3171 = sext i32 %3170 to i64
  store i64 %3171, i64* %RDX, align 8, !tbaa !2428
  %3172 = shl nsw i64 %3171, 3
  %3173 = add i64 %3172, %3166
  %3174 = add i64 %3163, 13
  store i64 %3174, i64* %PC, align 8
  %3175 = inttoptr i64 %3173 to double*
  %3176 = load double, double* %3175, align 8
  store double %3176, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3177 = add i64 %3163, 17
  store i64 %3177, i64* %PC, align 8
  %3178 = load i64, i64* %3165, align 8
  store i64 %3178, i64* %RCX, align 8, !tbaa !2428
  %3179 = add i64 %3161, -40
  %3180 = add i64 %3163, 21
  store i64 %3180, i64* %PC, align 8
  %3181 = inttoptr i64 %3179 to i32*
  %3182 = load i32, i32* %3181, align 4
  %3183 = sext i32 %3182 to i64
  store i64 %3183, i64* %RDX, align 8, !tbaa !2428
  %3184 = shl nsw i64 %3183, 3
  %3185 = add i64 %3184, %3178
  %3186 = add i64 %3163, 26
  store i64 %3186, i64* %PC, align 8
  %3187 = inttoptr i64 %3185 to double*
  %3188 = load double, double* %3187, align 8
  %3189 = fsub double %3176, %3188
  store double %3189, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3190 = add i64 %3161, -168
  %3191 = add i64 %3163, 34
  store i64 %3191, i64* %PC, align 8
  %3192 = inttoptr i64 %3190 to double*
  store double %3189, double* %3192, align 8
  %3193 = load i64, i64* %RBP, align 8
  %3194 = add i64 %3193, -16
  %3195 = load i64, i64* %PC, align 8
  %3196 = add i64 %3195, 4
  store i64 %3196, i64* %PC, align 8
  %3197 = inttoptr i64 %3194 to i64*
  %3198 = load i64, i64* %3197, align 8
  store i64 %3198, i64* %RCX, align 8, !tbaa !2428
  %3199 = add i64 %3193, -36
  %3200 = add i64 %3195, 7
  store i64 %3200, i64* %PC, align 8
  %3201 = inttoptr i64 %3199 to i32*
  %3202 = load i32, i32* %3201, align 4
  %3203 = add i32 %3202, 1
  %3204 = zext i32 %3203 to i64
  store i64 %3204, i64* %RAX, align 8, !tbaa !2428
  %3205 = icmp eq i32 %3202, -1
  %3206 = icmp eq i32 %3203, 0
  %3207 = or i1 %3205, %3206
  %3208 = zext i1 %3207 to i8
  store i8 %3208, i8* %18, align 1, !tbaa !2433
  %3209 = and i32 %3203, 255
  %3210 = tail call i32 @llvm.ctpop.i32(i32 %3209) #10
  %3211 = trunc i32 %3210 to i8
  %3212 = and i8 %3211, 1
  %3213 = xor i8 %3212, 1
  store i8 %3213, i8* %25, align 1, !tbaa !2447
  %3214 = xor i32 %3202, %3203
  %3215 = lshr i32 %3214, 4
  %3216 = trunc i32 %3215 to i8
  %3217 = and i8 %3216, 1
  store i8 %3217, i8* %31, align 1, !tbaa !2451
  %3218 = icmp eq i32 %3203, 0
  %3219 = zext i1 %3218 to i8
  store i8 %3219, i8* %34, align 1, !tbaa !2448
  %3220 = lshr i32 %3203, 31
  %3221 = trunc i32 %3220 to i8
  store i8 %3221, i8* %37, align 1, !tbaa !2449
  %3222 = lshr i32 %3202, 31
  %3223 = xor i32 %3220, %3222
  %3224 = add nuw nsw i32 %3223, %3220
  %3225 = icmp eq i32 %3224, 2
  %3226 = zext i1 %3225 to i8
  store i8 %3226, i8* %43, align 1, !tbaa !2450
  %3227 = sext i32 %3203 to i64
  store i64 %3227, i64* %RDX, align 8, !tbaa !2428
  %3228 = shl nsw i64 %3227, 3
  %3229 = add i64 %3228, %3198
  %3230 = add i64 %3195, 18
  store i64 %3230, i64* %PC, align 8
  %3231 = inttoptr i64 %3229 to double*
  %3232 = load double, double* %3231, align 8
  store double %3232, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3233 = add i64 %3195, 22
  store i64 %3233, i64* %PC, align 8
  %3234 = load i64, i64* %3197, align 8
  store i64 %3234, i64* %RCX, align 8, !tbaa !2428
  %3235 = add i64 %3193, -40
  %3236 = add i64 %3195, 25
  store i64 %3236, i64* %PC, align 8
  %3237 = inttoptr i64 %3235 to i32*
  %3238 = load i32, i32* %3237, align 4
  %3239 = add i32 %3238, 1
  %3240 = zext i32 %3239 to i64
  store i64 %3240, i64* %RAX, align 8, !tbaa !2428
  %3241 = icmp eq i32 %3238, -1
  %3242 = icmp eq i32 %3239, 0
  %3243 = or i1 %3241, %3242
  %3244 = zext i1 %3243 to i8
  store i8 %3244, i8* %18, align 1, !tbaa !2433
  %3245 = and i32 %3239, 255
  %3246 = tail call i32 @llvm.ctpop.i32(i32 %3245) #10
  %3247 = trunc i32 %3246 to i8
  %3248 = and i8 %3247, 1
  %3249 = xor i8 %3248, 1
  store i8 %3249, i8* %25, align 1, !tbaa !2447
  %3250 = xor i32 %3238, %3239
  %3251 = lshr i32 %3250, 4
  %3252 = trunc i32 %3251 to i8
  %3253 = and i8 %3252, 1
  store i8 %3253, i8* %31, align 1, !tbaa !2451
  %3254 = icmp eq i32 %3239, 0
  %3255 = zext i1 %3254 to i8
  store i8 %3255, i8* %34, align 1, !tbaa !2448
  %3256 = lshr i32 %3239, 31
  %3257 = trunc i32 %3256 to i8
  store i8 %3257, i8* %37, align 1, !tbaa !2449
  %3258 = lshr i32 %3238, 31
  %3259 = xor i32 %3256, %3258
  %3260 = add nuw nsw i32 %3259, %3256
  %3261 = icmp eq i32 %3260, 2
  %3262 = zext i1 %3261 to i8
  store i8 %3262, i8* %43, align 1, !tbaa !2450
  %3263 = sext i32 %3239 to i64
  store i64 %3263, i64* %RDX, align 8, !tbaa !2428
  %3264 = shl nsw i64 %3263, 3
  %3265 = add i64 %3264, %3234
  %3266 = add i64 %3195, 36
  store i64 %3266, i64* %PC, align 8
  %3267 = inttoptr i64 %3265 to double*
  %3268 = load double, double* %3267, align 8
  %3269 = fsub double %3232, %3268
  store double %3269, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3270 = load i64, i64* %RBP, align 8
  %3271 = add i64 %3270, -176
  %3272 = add i64 %3195, 44
  store i64 %3272, i64* %PC, align 8
  %3273 = inttoptr i64 %3271 to double*
  store double %3269, double* %3273, align 8
  %3274 = load i64, i64* %RBP, align 8
  %3275 = add i64 %3274, -120
  %3276 = load i64, i64* %PC, align 8
  %3277 = add i64 %3276, 5
  store i64 %3277, i64* %PC, align 8
  %3278 = inttoptr i64 %3275 to double*
  %3279 = load double, double* %3278, align 8
  store double %3279, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3280 = add i64 %3274, -152
  %3281 = add i64 %3276, 13
  store i64 %3281, i64* %PC, align 8
  %3282 = inttoptr i64 %3280 to double*
  %3283 = load double, double* %3282, align 8
  %3284 = fadd double %3279, %3283
  store double %3284, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3285 = add i64 %3274, -16
  %3286 = add i64 %3276, 17
  store i64 %3286, i64* %PC, align 8
  %3287 = inttoptr i64 %3285 to i64*
  %3288 = load i64, i64* %3287, align 8
  store i64 %3288, i64* %RCX, align 8, !tbaa !2428
  %3289 = add i64 %3274, -28
  %3290 = add i64 %3276, 21
  store i64 %3290, i64* %PC, align 8
  %3291 = inttoptr i64 %3289 to i32*
  %3292 = load i32, i32* %3291, align 4
  %3293 = sext i32 %3292 to i64
  store i64 %3293, i64* %RDX, align 8, !tbaa !2428
  %3294 = shl nsw i64 %3293, 3
  %3295 = add i64 %3294, %3288
  %3296 = add i64 %3276, 26
  store i64 %3296, i64* %PC, align 8
  %3297 = inttoptr i64 %3295 to double*
  store double %3284, double* %3297, align 8
  %3298 = load i64, i64* %RBP, align 8
  %3299 = add i64 %3298, -128
  %3300 = load i64, i64* %PC, align 8
  %3301 = add i64 %3300, 5
  store i64 %3301, i64* %PC, align 8
  %3302 = inttoptr i64 %3299 to double*
  %3303 = load double, double* %3302, align 8
  store double %3303, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3304 = add i64 %3298, -160
  %3305 = add i64 %3300, 13
  store i64 %3305, i64* %PC, align 8
  %3306 = inttoptr i64 %3304 to double*
  %3307 = load double, double* %3306, align 8
  %3308 = fadd double %3303, %3307
  store double %3308, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3309 = add i64 %3298, -16
  %3310 = add i64 %3300, 17
  store i64 %3310, i64* %PC, align 8
  %3311 = inttoptr i64 %3309 to i64*
  %3312 = load i64, i64* %3311, align 8
  store i64 %3312, i64* %RCX, align 8, !tbaa !2428
  %3313 = add i64 %3298, -28
  %3314 = add i64 %3300, 20
  store i64 %3314, i64* %PC, align 8
  %3315 = inttoptr i64 %3313 to i32*
  %3316 = load i32, i32* %3315, align 4
  %3317 = add i32 %3316, 1
  %3318 = zext i32 %3317 to i64
  store i64 %3318, i64* %RAX, align 8, !tbaa !2428
  %3319 = icmp eq i32 %3316, -1
  %3320 = icmp eq i32 %3317, 0
  %3321 = or i1 %3319, %3320
  %3322 = zext i1 %3321 to i8
  store i8 %3322, i8* %18, align 1, !tbaa !2433
  %3323 = and i32 %3317, 255
  %3324 = tail call i32 @llvm.ctpop.i32(i32 %3323) #10
  %3325 = trunc i32 %3324 to i8
  %3326 = and i8 %3325, 1
  %3327 = xor i8 %3326, 1
  store i8 %3327, i8* %25, align 1, !tbaa !2447
  %3328 = xor i32 %3316, %3317
  %3329 = lshr i32 %3328, 4
  %3330 = trunc i32 %3329 to i8
  %3331 = and i8 %3330, 1
  store i8 %3331, i8* %31, align 1, !tbaa !2451
  %3332 = icmp eq i32 %3317, 0
  %3333 = zext i1 %3332 to i8
  store i8 %3333, i8* %34, align 1, !tbaa !2448
  %3334 = lshr i32 %3317, 31
  %3335 = trunc i32 %3334 to i8
  store i8 %3335, i8* %37, align 1, !tbaa !2449
  %3336 = lshr i32 %3316, 31
  %3337 = xor i32 %3334, %3336
  %3338 = add nuw nsw i32 %3337, %3334
  %3339 = icmp eq i32 %3338, 2
  %3340 = zext i1 %3339 to i8
  store i8 %3340, i8* %43, align 1, !tbaa !2450
  %3341 = sext i32 %3317 to i64
  store i64 %3341, i64* %RDX, align 8, !tbaa !2428
  %3342 = shl nsw i64 %3341, 3
  %3343 = add i64 %3342, %3312
  %3344 = add i64 %3300, 31
  store i64 %3344, i64* %PC, align 8
  %3345 = inttoptr i64 %3343 to double*
  store double %3308, double* %3345, align 8
  %3346 = load i64, i64* %RBP, align 8
  %3347 = add i64 %3346, -152
  %3348 = load i64, i64* %PC, align 8
  %3349 = add i64 %3348, 8
  store i64 %3349, i64* %PC, align 8
  %3350 = inttoptr i64 %3347 to double*
  %3351 = load double, double* %3350, align 8
  store double %3351, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3352 = add i64 %3346, -120
  %3353 = add i64 %3348, 13
  store i64 %3353, i64* %PC, align 8
  %3354 = inttoptr i64 %3352 to double*
  %3355 = load double, double* %3354, align 8
  %3356 = fsub double %3355, %3351
  store double %3356, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %3357 = add i64 %3348, 22
  store i64 %3357, i64* %PC, align 8
  store double %3356, double* %3354, align 8
  %3358 = load i64, i64* %RBP, align 8
  %3359 = add i64 %3358, -160
  %3360 = load i64, i64* %PC, align 8
  %3361 = add i64 %3360, 8
  store i64 %3361, i64* %PC, align 8
  %3362 = inttoptr i64 %3359 to double*
  %3363 = load double, double* %3362, align 8
  store double %3363, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3364 = add i64 %3358, -128
  %3365 = add i64 %3360, 13
  store i64 %3365, i64* %PC, align 8
  %3366 = inttoptr i64 %3364 to double*
  %3367 = load double, double* %3366, align 8
  %3368 = fsub double %3367, %3363
  store double %3368, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %3369 = add i64 %3360, 22
  store i64 %3369, i64* %PC, align 8
  store double %3368, double* %3366, align 8
  %3370 = load i64, i64* %RBP, align 8
  %3371 = add i64 %3370, -88
  %3372 = load i64, i64* %PC, align 8
  %3373 = add i64 %3372, 5
  store i64 %3373, i64* %PC, align 8
  %3374 = inttoptr i64 %3371 to double*
  %3375 = load double, double* %3374, align 8
  store double %3375, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3376 = add i64 %3370, -120
  %3377 = add i64 %3372, 10
  store i64 %3377, i64* %PC, align 8
  %3378 = inttoptr i64 %3376 to double*
  %3379 = load double, double* %3378, align 8
  %3380 = fmul double %3375, %3379
  store double %3380, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3381 = add i64 %3370, -96
  %3382 = add i64 %3372, 15
  store i64 %3382, i64* %PC, align 8
  %3383 = inttoptr i64 %3381 to double*
  %3384 = load double, double* %3383, align 8
  store double %3384, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %3385 = add i64 %3370, -128
  %3386 = add i64 %3372, 20
  store i64 %3386, i64* %PC, align 8
  %3387 = inttoptr i64 %3385 to double*
  %3388 = load double, double* %3387, align 8
  %3389 = fmul double %3384, %3388
  store double %3389, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %3390 = fsub double %3380, %3389
  store double %3390, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3391 = add i64 %3370, -16
  %3392 = add i64 %3372, 28
  store i64 %3392, i64* %PC, align 8
  %3393 = inttoptr i64 %3391 to i64*
  %3394 = load i64, i64* %3393, align 8
  store i64 %3394, i64* %RCX, align 8, !tbaa !2428
  %3395 = add i64 %3370, -36
  %3396 = add i64 %3372, 32
  store i64 %3396, i64* %PC, align 8
  %3397 = inttoptr i64 %3395 to i32*
  %3398 = load i32, i32* %3397, align 4
  %3399 = sext i32 %3398 to i64
  store i64 %3399, i64* %RDX, align 8, !tbaa !2428
  %3400 = shl nsw i64 %3399, 3
  %3401 = add i64 %3400, %3394
  %3402 = add i64 %3372, 37
  store i64 %3402, i64* %PC, align 8
  %3403 = inttoptr i64 %3401 to double*
  store double %3390, double* %3403, align 8
  %3404 = load i64, i64* %RBP, align 8
  %3405 = add i64 %3404, -88
  %3406 = load i64, i64* %PC, align 8
  %3407 = add i64 %3406, 5
  store i64 %3407, i64* %PC, align 8
  %3408 = inttoptr i64 %3405 to double*
  %3409 = load double, double* %3408, align 8
  store double %3409, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3410 = add i64 %3404, -128
  %3411 = add i64 %3406, 10
  store i64 %3411, i64* %PC, align 8
  %3412 = inttoptr i64 %3410 to double*
  %3413 = load double, double* %3412, align 8
  %3414 = fmul double %3409, %3413
  store double %3414, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3415 = add i64 %3404, -96
  %3416 = add i64 %3406, 15
  store i64 %3416, i64* %PC, align 8
  %3417 = inttoptr i64 %3415 to double*
  %3418 = load double, double* %3417, align 8
  store double %3418, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %3419 = add i64 %3404, -120
  %3420 = add i64 %3406, 20
  store i64 %3420, i64* %PC, align 8
  %3421 = inttoptr i64 %3419 to double*
  %3422 = load double, double* %3421, align 8
  %3423 = fmul double %3418, %3422
  store double %3423, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %3424 = fadd double %3414, %3423
  store double %3424, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3425 = add i64 %3404, -16
  %3426 = add i64 %3406, 28
  store i64 %3426, i64* %PC, align 8
  %3427 = inttoptr i64 %3425 to i64*
  %3428 = load i64, i64* %3427, align 8
  store i64 %3428, i64* %RCX, align 8, !tbaa !2428
  %3429 = add i64 %3404, -36
  %3430 = add i64 %3406, 31
  store i64 %3430, i64* %PC, align 8
  %3431 = inttoptr i64 %3429 to i32*
  %3432 = load i32, i32* %3431, align 4
  %3433 = add i32 %3432, 1
  %3434 = zext i32 %3433 to i64
  store i64 %3434, i64* %RAX, align 8, !tbaa !2428
  %3435 = icmp eq i32 %3432, -1
  %3436 = icmp eq i32 %3433, 0
  %3437 = or i1 %3435, %3436
  %3438 = zext i1 %3437 to i8
  store i8 %3438, i8* %18, align 1, !tbaa !2433
  %3439 = and i32 %3433, 255
  %3440 = tail call i32 @llvm.ctpop.i32(i32 %3439) #10
  %3441 = trunc i32 %3440 to i8
  %3442 = and i8 %3441, 1
  %3443 = xor i8 %3442, 1
  store i8 %3443, i8* %25, align 1, !tbaa !2447
  %3444 = xor i32 %3432, %3433
  %3445 = lshr i32 %3444, 4
  %3446 = trunc i32 %3445 to i8
  %3447 = and i8 %3446, 1
  store i8 %3447, i8* %31, align 1, !tbaa !2451
  %3448 = icmp eq i32 %3433, 0
  %3449 = zext i1 %3448 to i8
  store i8 %3449, i8* %34, align 1, !tbaa !2448
  %3450 = lshr i32 %3433, 31
  %3451 = trunc i32 %3450 to i8
  store i8 %3451, i8* %37, align 1, !tbaa !2449
  %3452 = lshr i32 %3432, 31
  %3453 = xor i32 %3450, %3452
  %3454 = add nuw nsw i32 %3453, %3450
  %3455 = icmp eq i32 %3454, 2
  %3456 = zext i1 %3455 to i8
  store i8 %3456, i8* %43, align 1, !tbaa !2450
  %3457 = sext i32 %3433 to i64
  store i64 %3457, i64* %RDX, align 8, !tbaa !2428
  %3458 = shl nsw i64 %3457, 3
  %3459 = add i64 %3458, %3428
  %3460 = add i64 %3406, 42
  store i64 %3460, i64* %PC, align 8
  %3461 = inttoptr i64 %3459 to double*
  store double %3424, double* %3461, align 8
  %3462 = load i64, i64* %RBP, align 8
  %3463 = add i64 %3462, -136
  %3464 = load i64, i64* %PC, align 8
  %3465 = add i64 %3464, 8
  store i64 %3465, i64* %PC, align 8
  %3466 = inttoptr i64 %3463 to double*
  %3467 = load double, double* %3466, align 8
  store double %3467, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3468 = add i64 %3462, -176
  %3469 = add i64 %3464, 16
  store i64 %3469, i64* %PC, align 8
  %3470 = inttoptr i64 %3468 to double*
  %3471 = load double, double* %3470, align 8
  %3472 = fsub double %3467, %3471
  store double %3472, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3473 = add i64 %3462, -120
  %3474 = add i64 %3464, 21
  store i64 %3474, i64* %PC, align 8
  %3475 = inttoptr i64 %3473 to double*
  store double %3472, double* %3475, align 8
  %3476 = load i64, i64* %RBP, align 8
  %3477 = add i64 %3476, -144
  %3478 = load i64, i64* %PC, align 8
  %3479 = add i64 %3478, 8
  store i64 %3479, i64* %PC, align 8
  %3480 = inttoptr i64 %3477 to double*
  %3481 = load double, double* %3480, align 8
  store double %3481, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3482 = add i64 %3476, -168
  %3483 = add i64 %3478, 16
  store i64 %3483, i64* %PC, align 8
  %3484 = inttoptr i64 %3482 to double*
  %3485 = load double, double* %3484, align 8
  %3486 = fadd double %3481, %3485
  store double %3486, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3487 = add i64 %3476, -128
  %3488 = add i64 %3478, 21
  store i64 %3488, i64* %PC, align 8
  %3489 = inttoptr i64 %3487 to double*
  store double %3486, double* %3489, align 8
  %3490 = load i64, i64* %RBP, align 8
  %3491 = add i64 %3490, -72
  %3492 = load i64, i64* %PC, align 8
  %3493 = add i64 %3492, 5
  store i64 %3493, i64* %PC, align 8
  %3494 = inttoptr i64 %3491 to double*
  %3495 = load double, double* %3494, align 8
  store double %3495, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3496 = add i64 %3490, -120
  %3497 = add i64 %3492, 10
  store i64 %3497, i64* %PC, align 8
  %3498 = inttoptr i64 %3496 to double*
  %3499 = load double, double* %3498, align 8
  %3500 = fmul double %3495, %3499
  store double %3500, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3501 = add i64 %3490, -80
  %3502 = add i64 %3492, 15
  store i64 %3502, i64* %PC, align 8
  %3503 = inttoptr i64 %3501 to double*
  %3504 = load double, double* %3503, align 8
  store double %3504, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %3505 = add i64 %3490, -128
  %3506 = add i64 %3492, 20
  store i64 %3506, i64* %PC, align 8
  %3507 = inttoptr i64 %3505 to double*
  %3508 = load double, double* %3507, align 8
  %3509 = fmul double %3504, %3508
  store double %3509, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %3510 = fsub double %3500, %3509
  store double %3510, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3511 = add i64 %3490, -16
  %3512 = add i64 %3492, 28
  store i64 %3512, i64* %PC, align 8
  %3513 = inttoptr i64 %3511 to i64*
  %3514 = load i64, i64* %3513, align 8
  store i64 %3514, i64* %RCX, align 8, !tbaa !2428
  %3515 = add i64 %3490, -32
  %3516 = add i64 %3492, 32
  store i64 %3516, i64* %PC, align 8
  %3517 = inttoptr i64 %3515 to i32*
  %3518 = load i32, i32* %3517, align 4
  %3519 = sext i32 %3518 to i64
  store i64 %3519, i64* %RDX, align 8, !tbaa !2428
  %3520 = shl nsw i64 %3519, 3
  %3521 = add i64 %3520, %3514
  %3522 = add i64 %3492, 37
  store i64 %3522, i64* %PC, align 8
  %3523 = inttoptr i64 %3521 to double*
  store double %3510, double* %3523, align 8
  %3524 = load i64, i64* %RBP, align 8
  %3525 = add i64 %3524, -72
  %3526 = load i64, i64* %PC, align 8
  %3527 = add i64 %3526, 5
  store i64 %3527, i64* %PC, align 8
  %3528 = inttoptr i64 %3525 to double*
  %3529 = load double, double* %3528, align 8
  store double %3529, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3530 = add i64 %3524, -128
  %3531 = add i64 %3526, 10
  store i64 %3531, i64* %PC, align 8
  %3532 = inttoptr i64 %3530 to double*
  %3533 = load double, double* %3532, align 8
  %3534 = fmul double %3529, %3533
  store double %3534, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3535 = add i64 %3524, -80
  %3536 = add i64 %3526, 15
  store i64 %3536, i64* %PC, align 8
  %3537 = inttoptr i64 %3535 to double*
  %3538 = load double, double* %3537, align 8
  store double %3538, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %3539 = add i64 %3524, -120
  %3540 = add i64 %3526, 20
  store i64 %3540, i64* %PC, align 8
  %3541 = inttoptr i64 %3539 to double*
  %3542 = load double, double* %3541, align 8
  %3543 = fmul double %3538, %3542
  store double %3543, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %3544 = fadd double %3534, %3543
  store double %3544, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3545 = add i64 %3524, -16
  %3546 = add i64 %3526, 28
  store i64 %3546, i64* %PC, align 8
  %3547 = inttoptr i64 %3545 to i64*
  %3548 = load i64, i64* %3547, align 8
  store i64 %3548, i64* %RCX, align 8, !tbaa !2428
  %3549 = add i64 %3524, -32
  %3550 = add i64 %3526, 31
  store i64 %3550, i64* %PC, align 8
  %3551 = inttoptr i64 %3549 to i32*
  %3552 = load i32, i32* %3551, align 4
  %3553 = add i32 %3552, 1
  %3554 = zext i32 %3553 to i64
  store i64 %3554, i64* %RAX, align 8, !tbaa !2428
  %3555 = icmp eq i32 %3552, -1
  %3556 = icmp eq i32 %3553, 0
  %3557 = or i1 %3555, %3556
  %3558 = zext i1 %3557 to i8
  store i8 %3558, i8* %18, align 1, !tbaa !2433
  %3559 = and i32 %3553, 255
  %3560 = tail call i32 @llvm.ctpop.i32(i32 %3559) #10
  %3561 = trunc i32 %3560 to i8
  %3562 = and i8 %3561, 1
  %3563 = xor i8 %3562, 1
  store i8 %3563, i8* %25, align 1, !tbaa !2447
  %3564 = xor i32 %3552, %3553
  %3565 = lshr i32 %3564, 4
  %3566 = trunc i32 %3565 to i8
  %3567 = and i8 %3566, 1
  store i8 %3567, i8* %31, align 1, !tbaa !2451
  %3568 = icmp eq i32 %3553, 0
  %3569 = zext i1 %3568 to i8
  store i8 %3569, i8* %34, align 1, !tbaa !2448
  %3570 = lshr i32 %3553, 31
  %3571 = trunc i32 %3570 to i8
  store i8 %3571, i8* %37, align 1, !tbaa !2449
  %3572 = lshr i32 %3552, 31
  %3573 = xor i32 %3570, %3572
  %3574 = add nuw nsw i32 %3573, %3570
  %3575 = icmp eq i32 %3574, 2
  %3576 = zext i1 %3575 to i8
  store i8 %3576, i8* %43, align 1, !tbaa !2450
  %3577 = sext i32 %3553 to i64
  store i64 %3577, i64* %RDX, align 8, !tbaa !2428
  %3578 = shl nsw i64 %3577, 3
  %3579 = add i64 %3578, %3548
  %3580 = add i64 %3526, 42
  store i64 %3580, i64* %PC, align 8
  %3581 = inttoptr i64 %3579 to double*
  store double %3544, double* %3581, align 8
  %3582 = load i64, i64* %RBP, align 8
  %3583 = add i64 %3582, -136
  %3584 = load i64, i64* %PC, align 8
  %3585 = add i64 %3584, 8
  store i64 %3585, i64* %PC, align 8
  %3586 = inttoptr i64 %3583 to double*
  %3587 = load double, double* %3586, align 8
  store double %3587, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3588 = add i64 %3582, -176
  %3589 = add i64 %3584, 16
  store i64 %3589, i64* %PC, align 8
  %3590 = inttoptr i64 %3588 to double*
  %3591 = load double, double* %3590, align 8
  %3592 = fadd double %3587, %3591
  store double %3592, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3593 = add i64 %3582, -120
  %3594 = add i64 %3584, 21
  store i64 %3594, i64* %PC, align 8
  %3595 = inttoptr i64 %3593 to double*
  store double %3592, double* %3595, align 8
  %3596 = load i64, i64* %RBP, align 8
  %3597 = add i64 %3596, -144
  %3598 = load i64, i64* %PC, align 8
  %3599 = add i64 %3598, 8
  store i64 %3599, i64* %PC, align 8
  %3600 = inttoptr i64 %3597 to double*
  %3601 = load double, double* %3600, align 8
  store double %3601, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3602 = add i64 %3596, -168
  %3603 = add i64 %3598, 16
  store i64 %3603, i64* %PC, align 8
  %3604 = inttoptr i64 %3602 to double*
  %3605 = load double, double* %3604, align 8
  %3606 = fsub double %3601, %3605
  store double %3606, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3607 = add i64 %3596, -128
  %3608 = add i64 %3598, 21
  store i64 %3608, i64* %PC, align 8
  %3609 = inttoptr i64 %3607 to double*
  store double %3606, double* %3609, align 8
  %3610 = load i64, i64* %RBP, align 8
  %3611 = add i64 %3610, -104
  %3612 = load i64, i64* %PC, align 8
  %3613 = add i64 %3612, 5
  store i64 %3613, i64* %PC, align 8
  %3614 = inttoptr i64 %3611 to double*
  %3615 = load double, double* %3614, align 8
  store double %3615, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3616 = add i64 %3610, -120
  %3617 = add i64 %3612, 10
  store i64 %3617, i64* %PC, align 8
  %3618 = inttoptr i64 %3616 to double*
  %3619 = load double, double* %3618, align 8
  %3620 = fmul double %3615, %3619
  store double %3620, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3621 = add i64 %3610, -112
  %3622 = add i64 %3612, 15
  store i64 %3622, i64* %PC, align 8
  %3623 = inttoptr i64 %3621 to double*
  %3624 = load double, double* %3623, align 8
  store double %3624, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %3625 = add i64 %3610, -128
  %3626 = add i64 %3612, 20
  store i64 %3626, i64* %PC, align 8
  %3627 = inttoptr i64 %3625 to double*
  %3628 = load double, double* %3627, align 8
  %3629 = fmul double %3624, %3628
  store double %3629, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %3630 = fsub double %3620, %3629
  store double %3630, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3631 = add i64 %3610, -16
  %3632 = add i64 %3612, 28
  store i64 %3632, i64* %PC, align 8
  %3633 = inttoptr i64 %3631 to i64*
  %3634 = load i64, i64* %3633, align 8
  store i64 %3634, i64* %RCX, align 8, !tbaa !2428
  %3635 = add i64 %3610, -40
  %3636 = add i64 %3612, 32
  store i64 %3636, i64* %PC, align 8
  %3637 = inttoptr i64 %3635 to i32*
  %3638 = load i32, i32* %3637, align 4
  %3639 = sext i32 %3638 to i64
  store i64 %3639, i64* %RDX, align 8, !tbaa !2428
  %3640 = shl nsw i64 %3639, 3
  %3641 = add i64 %3640, %3634
  %3642 = add i64 %3612, 37
  store i64 %3642, i64* %PC, align 8
  %3643 = inttoptr i64 %3641 to double*
  store double %3630, double* %3643, align 8
  %3644 = load i64, i64* %RBP, align 8
  %3645 = add i64 %3644, -104
  %3646 = load i64, i64* %PC, align 8
  %3647 = add i64 %3646, 5
  store i64 %3647, i64* %PC, align 8
  %3648 = inttoptr i64 %3645 to double*
  %3649 = load double, double* %3648, align 8
  store double %3649, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3650 = add i64 %3644, -128
  %3651 = add i64 %3646, 10
  store i64 %3651, i64* %PC, align 8
  %3652 = inttoptr i64 %3650 to double*
  %3653 = load double, double* %3652, align 8
  %3654 = fmul double %3649, %3653
  store double %3654, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3655 = add i64 %3644, -112
  %3656 = add i64 %3646, 15
  store i64 %3656, i64* %PC, align 8
  %3657 = inttoptr i64 %3655 to double*
  %3658 = load double, double* %3657, align 8
  store double %3658, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %3659 = add i64 %3644, -120
  %3660 = add i64 %3646, 20
  store i64 %3660, i64* %PC, align 8
  %3661 = inttoptr i64 %3659 to double*
  %3662 = load double, double* %3661, align 8
  %3663 = fmul double %3658, %3662
  store double %3663, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %3664 = fadd double %3654, %3663
  store double %3664, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3665 = add i64 %3644, -16
  %3666 = add i64 %3646, 28
  store i64 %3666, i64* %PC, align 8
  %3667 = inttoptr i64 %3665 to i64*
  %3668 = load i64, i64* %3667, align 8
  store i64 %3668, i64* %RCX, align 8, !tbaa !2428
  %3669 = add i64 %3644, -40
  %3670 = add i64 %3646, 31
  store i64 %3670, i64* %PC, align 8
  %3671 = inttoptr i64 %3669 to i32*
  %3672 = load i32, i32* %3671, align 4
  %3673 = add i32 %3672, 1
  %3674 = zext i32 %3673 to i64
  store i64 %3674, i64* %RAX, align 8, !tbaa !2428
  %3675 = icmp eq i32 %3672, -1
  %3676 = icmp eq i32 %3673, 0
  %3677 = or i1 %3675, %3676
  %3678 = zext i1 %3677 to i8
  store i8 %3678, i8* %18, align 1, !tbaa !2433
  %3679 = and i32 %3673, 255
  %3680 = tail call i32 @llvm.ctpop.i32(i32 %3679) #10
  %3681 = trunc i32 %3680 to i8
  %3682 = and i8 %3681, 1
  %3683 = xor i8 %3682, 1
  store i8 %3683, i8* %25, align 1, !tbaa !2447
  %3684 = xor i32 %3672, %3673
  %3685 = lshr i32 %3684, 4
  %3686 = trunc i32 %3685 to i8
  %3687 = and i8 %3686, 1
  store i8 %3687, i8* %31, align 1, !tbaa !2451
  %3688 = icmp eq i32 %3673, 0
  %3689 = zext i1 %3688 to i8
  store i8 %3689, i8* %34, align 1, !tbaa !2448
  %3690 = lshr i32 %3673, 31
  %3691 = trunc i32 %3690 to i8
  store i8 %3691, i8* %37, align 1, !tbaa !2449
  %3692 = lshr i32 %3672, 31
  %3693 = xor i32 %3690, %3692
  %3694 = add nuw nsw i32 %3693, %3690
  %3695 = icmp eq i32 %3694, 2
  %3696 = zext i1 %3695 to i8
  store i8 %3696, i8* %43, align 1, !tbaa !2450
  %3697 = sext i32 %3673 to i64
  store i64 %3697, i64* %RDX, align 8, !tbaa !2428
  %3698 = shl nsw i64 %3697, 3
  %3699 = add i64 %3698, %3668
  %3700 = add i64 %3646, 42
  store i64 %3700, i64* %PC, align 8
  %3701 = inttoptr i64 %3699 to double*
  store double %3664, double* %3701, align 8
  %3702 = load i64, i64* %RBP, align 8
  %3703 = add i64 %3702, -28
  %3704 = load i64, i64* %PC, align 8
  %3705 = add i64 %3704, 3
  store i64 %3705, i64* %PC, align 8
  %3706 = inttoptr i64 %3703 to i32*
  %3707 = load i32, i32* %3706, align 4
  %3708 = add i32 %3707, 2
  %3709 = zext i32 %3708 to i64
  store i64 %3709, i64* %RAX, align 8, !tbaa !2428
  %3710 = icmp ugt i32 %3707, -3
  %3711 = zext i1 %3710 to i8
  store i8 %3711, i8* %18, align 1, !tbaa !2433
  %3712 = and i32 %3708, 255
  %3713 = tail call i32 @llvm.ctpop.i32(i32 %3712) #10
  %3714 = trunc i32 %3713 to i8
  %3715 = and i8 %3714, 1
  %3716 = xor i8 %3715, 1
  store i8 %3716, i8* %25, align 1, !tbaa !2447
  %3717 = xor i32 %3707, %3708
  %3718 = lshr i32 %3717, 4
  %3719 = trunc i32 %3718 to i8
  %3720 = and i8 %3719, 1
  store i8 %3720, i8* %31, align 1, !tbaa !2451
  %3721 = icmp eq i32 %3708, 0
  %3722 = zext i1 %3721 to i8
  store i8 %3722, i8* %34, align 1, !tbaa !2448
  %3723 = lshr i32 %3708, 31
  %3724 = trunc i32 %3723 to i8
  store i8 %3724, i8* %37, align 1, !tbaa !2449
  %3725 = lshr i32 %3707, 31
  %3726 = xor i32 %3723, %3725
  %3727 = add nuw nsw i32 %3726, %3723
  %3728 = icmp eq i32 %3727, 2
  %3729 = zext i1 %3728 to i8
  store i8 %3729, i8* %43, align 1, !tbaa !2450
  %3730 = add i64 %3704, 9
  store i64 %3730, i64* %PC, align 8
  store i32 %3708, i32* %3706, align 4
  %3731 = load i64, i64* %PC, align 8
  %3732 = add i64 %3731, -781
  store i64 %3732, i64* %95, align 8, !tbaa !2428
  br label %block_403910

block_403ca6:                                     ; preds = %block_403c90
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %3733 = load i64, i64* %RBP, align 8
  %3734 = add i64 %3733, -28
  %3735 = add i64 %1602, 13
  store i64 %3735, i64* %PC, align 8
  %3736 = inttoptr i64 %3734 to i32*
  %3737 = load i32, i32* %3736, align 4
  %3738 = zext i32 %3737 to i64
  store i64 %3738, i64* %RCX, align 8, !tbaa !2428
  %3739 = add i64 %3733, -8
  %3740 = add i64 %1602, 16
  store i64 %3740, i64* %PC, align 8
  %3741 = inttoptr i64 %3739 to i32*
  %3742 = load i32, i32* %3741, align 4
  %3743 = add i32 %3742, %3737
  %3744 = zext i32 %3743 to i64
  store i64 %3744, i64* %RCX, align 8, !tbaa !2428
  %3745 = icmp ult i32 %3743, %3737
  %3746 = icmp ult i32 %3743, %3742
  %3747 = or i1 %3745, %3746
  %3748 = zext i1 %3747 to i8
  store i8 %3748, i8* %18, align 1, !tbaa !2433
  %3749 = and i32 %3743, 255
  %3750 = tail call i32 @llvm.ctpop.i32(i32 %3749) #10
  %3751 = trunc i32 %3750 to i8
  %3752 = and i8 %3751, 1
  %3753 = xor i8 %3752, 1
  store i8 %3753, i8* %25, align 1, !tbaa !2447
  %3754 = xor i32 %3742, %3737
  %3755 = xor i32 %3754, %3743
  %3756 = lshr i32 %3755, 4
  %3757 = trunc i32 %3756 to i8
  %3758 = and i8 %3757, 1
  store i8 %3758, i8* %31, align 1, !tbaa !2451
  %3759 = icmp eq i32 %3743, 0
  %3760 = zext i1 %3759 to i8
  store i8 %3760, i8* %34, align 1, !tbaa !2448
  %3761 = lshr i32 %3743, 31
  %3762 = trunc i32 %3761 to i8
  store i8 %3762, i8* %37, align 1, !tbaa !2449
  %3763 = lshr i32 %3737, 31
  %3764 = lshr i32 %3742, 31
  %3765 = xor i32 %3761, %3763
  %3766 = xor i32 %3761, %3764
  %3767 = add nuw nsw i32 %3765, %3766
  %3768 = icmp eq i32 %3767, 2
  %3769 = zext i1 %3768 to i8
  store i8 %3769, i8* %43, align 1, !tbaa !2450
  %3770 = add i64 %3733, -32
  %3771 = add i64 %1602, 19
  store i64 %3771, i64* %PC, align 8
  %3772 = inttoptr i64 %3770 to i32*
  store i32 %3743, i32* %3772, align 4
  %3773 = load i64, i64* %RBP, align 8
  %3774 = add i64 %3773, -32
  %3775 = load i64, i64* %PC, align 8
  %3776 = add i64 %3775, 3
  store i64 %3776, i64* %PC, align 8
  %3777 = inttoptr i64 %3774 to i32*
  %3778 = load i32, i32* %3777, align 4
  %3779 = zext i32 %3778 to i64
  store i64 %3779, i64* %RCX, align 8, !tbaa !2428
  %3780 = add i64 %3773, -8
  %3781 = add i64 %3775, 6
  store i64 %3781, i64* %PC, align 8
  %3782 = inttoptr i64 %3780 to i32*
  %3783 = load i32, i32* %3782, align 4
  %3784 = add i32 %3783, %3778
  %3785 = zext i32 %3784 to i64
  store i64 %3785, i64* %RCX, align 8, !tbaa !2428
  %3786 = icmp ult i32 %3784, %3778
  %3787 = icmp ult i32 %3784, %3783
  %3788 = or i1 %3786, %3787
  %3789 = zext i1 %3788 to i8
  store i8 %3789, i8* %18, align 1, !tbaa !2433
  %3790 = and i32 %3784, 255
  %3791 = tail call i32 @llvm.ctpop.i32(i32 %3790) #10
  %3792 = trunc i32 %3791 to i8
  %3793 = and i8 %3792, 1
  %3794 = xor i8 %3793, 1
  store i8 %3794, i8* %25, align 1, !tbaa !2447
  %3795 = xor i32 %3783, %3778
  %3796 = xor i32 %3795, %3784
  %3797 = lshr i32 %3796, 4
  %3798 = trunc i32 %3797 to i8
  %3799 = and i8 %3798, 1
  store i8 %3799, i8* %31, align 1, !tbaa !2451
  %3800 = icmp eq i32 %3784, 0
  %3801 = zext i1 %3800 to i8
  store i8 %3801, i8* %34, align 1, !tbaa !2448
  %3802 = lshr i32 %3784, 31
  %3803 = trunc i32 %3802 to i8
  store i8 %3803, i8* %37, align 1, !tbaa !2449
  %3804 = lshr i32 %3778, 31
  %3805 = lshr i32 %3783, 31
  %3806 = xor i32 %3802, %3804
  %3807 = xor i32 %3802, %3805
  %3808 = add nuw nsw i32 %3806, %3807
  %3809 = icmp eq i32 %3808, 2
  %3810 = zext i1 %3809 to i8
  store i8 %3810, i8* %43, align 1, !tbaa !2450
  %3811 = add i64 %3773, -36
  %3812 = add i64 %3775, 9
  store i64 %3812, i64* %PC, align 8
  %3813 = inttoptr i64 %3811 to i32*
  store i32 %3784, i32* %3813, align 4
  %3814 = load i64, i64* %RBP, align 8
  %3815 = add i64 %3814, -36
  %3816 = load i64, i64* %PC, align 8
  %3817 = add i64 %3816, 3
  store i64 %3817, i64* %PC, align 8
  %3818 = inttoptr i64 %3815 to i32*
  %3819 = load i32, i32* %3818, align 4
  %3820 = zext i32 %3819 to i64
  store i64 %3820, i64* %RCX, align 8, !tbaa !2428
  %3821 = add i64 %3814, -8
  %3822 = add i64 %3816, 6
  store i64 %3822, i64* %PC, align 8
  %3823 = inttoptr i64 %3821 to i32*
  %3824 = load i32, i32* %3823, align 4
  %3825 = add i32 %3824, %3819
  %3826 = zext i32 %3825 to i64
  store i64 %3826, i64* %RCX, align 8, !tbaa !2428
  %3827 = icmp ult i32 %3825, %3819
  %3828 = icmp ult i32 %3825, %3824
  %3829 = or i1 %3827, %3828
  %3830 = zext i1 %3829 to i8
  store i8 %3830, i8* %18, align 1, !tbaa !2433
  %3831 = and i32 %3825, 255
  %3832 = tail call i32 @llvm.ctpop.i32(i32 %3831) #10
  %3833 = trunc i32 %3832 to i8
  %3834 = and i8 %3833, 1
  %3835 = xor i8 %3834, 1
  store i8 %3835, i8* %25, align 1, !tbaa !2447
  %3836 = xor i32 %3824, %3819
  %3837 = xor i32 %3836, %3825
  %3838 = lshr i32 %3837, 4
  %3839 = trunc i32 %3838 to i8
  %3840 = and i8 %3839, 1
  store i8 %3840, i8* %31, align 1, !tbaa !2451
  %3841 = icmp eq i32 %3825, 0
  %3842 = zext i1 %3841 to i8
  store i8 %3842, i8* %34, align 1, !tbaa !2448
  %3843 = lshr i32 %3825, 31
  %3844 = trunc i32 %3843 to i8
  store i8 %3844, i8* %37, align 1, !tbaa !2449
  %3845 = lshr i32 %3819, 31
  %3846 = lshr i32 %3824, 31
  %3847 = xor i32 %3843, %3845
  %3848 = xor i32 %3843, %3846
  %3849 = add nuw nsw i32 %3847, %3848
  %3850 = icmp eq i32 %3849, 2
  %3851 = zext i1 %3850 to i8
  store i8 %3851, i8* %43, align 1, !tbaa !2450
  %3852 = add i64 %3814, -40
  %3853 = add i64 %3816, 9
  store i64 %3853, i64* %PC, align 8
  %3854 = inttoptr i64 %3852 to i32*
  store i32 %3825, i32* %3854, align 4
  %3855 = load i64, i64* %RBP, align 8
  %3856 = add i64 %3855, -16
  %3857 = load i64, i64* %PC, align 8
  %3858 = add i64 %3857, 4
  store i64 %3858, i64* %PC, align 8
  %3859 = inttoptr i64 %3856 to i64*
  %3860 = load i64, i64* %3859, align 8
  store i64 %3860, i64* %RDX, align 8, !tbaa !2428
  %3861 = add i64 %3855, -28
  %3862 = add i64 %3857, 8
  store i64 %3862, i64* %PC, align 8
  %3863 = inttoptr i64 %3861 to i32*
  %3864 = load i32, i32* %3863, align 4
  %3865 = sext i32 %3864 to i64
  store i64 %3865, i64* %RSI, align 8, !tbaa !2428
  %3866 = shl nsw i64 %3865, 3
  %3867 = add i64 %3866, %3860
  %3868 = add i64 %3857, 13
  store i64 %3868, i64* %PC, align 8
  %3869 = inttoptr i64 %3867 to double*
  %3870 = load double, double* %3869, align 8
  store double %3870, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3871 = add i64 %3857, 17
  store i64 %3871, i64* %PC, align 8
  %3872 = load i64, i64* %3859, align 8
  store i64 %3872, i64* %RDX, align 8, !tbaa !2428
  %3873 = add i64 %3855, -32
  %3874 = add i64 %3857, 21
  store i64 %3874, i64* %PC, align 8
  %3875 = inttoptr i64 %3873 to i32*
  %3876 = load i32, i32* %3875, align 4
  %3877 = sext i32 %3876 to i64
  store i64 %3877, i64* %RSI, align 8, !tbaa !2428
  %3878 = shl nsw i64 %3877, 3
  %3879 = add i64 %3878, %3872
  %3880 = add i64 %3857, 26
  store i64 %3880, i64* %PC, align 8
  %3881 = inttoptr i64 %3879 to double*
  %3882 = load double, double* %3881, align 8
  %3883 = fadd double %3870, %3882
  store double %3883, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3884 = add i64 %3855, -120
  %3885 = add i64 %3857, 31
  store i64 %3885, i64* %PC, align 8
  %3886 = inttoptr i64 %3884 to double*
  store double %3883, double* %3886, align 8
  %3887 = load i64, i64* %RBP, align 8
  %3888 = add i64 %3887, -16
  %3889 = load i64, i64* %PC, align 8
  %3890 = add i64 %3889, 4
  store i64 %3890, i64* %PC, align 8
  %3891 = inttoptr i64 %3888 to i64*
  %3892 = load i64, i64* %3891, align 8
  store i64 %3892, i64* %RDX, align 8, !tbaa !2428
  %3893 = add i64 %3887, -28
  %3894 = add i64 %3889, 7
  store i64 %3894, i64* %PC, align 8
  %3895 = inttoptr i64 %3893 to i32*
  %3896 = load i32, i32* %3895, align 4
  %3897 = add i32 %3896, 1
  %3898 = zext i32 %3897 to i64
  store i64 %3898, i64* %RCX, align 8, !tbaa !2428
  %3899 = icmp eq i32 %3896, -1
  %3900 = icmp eq i32 %3897, 0
  %3901 = or i1 %3899, %3900
  %3902 = zext i1 %3901 to i8
  store i8 %3902, i8* %18, align 1, !tbaa !2433
  %3903 = and i32 %3897, 255
  %3904 = tail call i32 @llvm.ctpop.i32(i32 %3903) #10
  %3905 = trunc i32 %3904 to i8
  %3906 = and i8 %3905, 1
  %3907 = xor i8 %3906, 1
  store i8 %3907, i8* %25, align 1, !tbaa !2447
  %3908 = xor i32 %3896, %3897
  %3909 = lshr i32 %3908, 4
  %3910 = trunc i32 %3909 to i8
  %3911 = and i8 %3910, 1
  store i8 %3911, i8* %31, align 1, !tbaa !2451
  %3912 = icmp eq i32 %3897, 0
  %3913 = zext i1 %3912 to i8
  store i8 %3913, i8* %34, align 1, !tbaa !2448
  %3914 = lshr i32 %3897, 31
  %3915 = trunc i32 %3914 to i8
  store i8 %3915, i8* %37, align 1, !tbaa !2449
  %3916 = lshr i32 %3896, 31
  %3917 = xor i32 %3914, %3916
  %3918 = add nuw nsw i32 %3917, %3914
  %3919 = icmp eq i32 %3918, 2
  %3920 = zext i1 %3919 to i8
  store i8 %3920, i8* %43, align 1, !tbaa !2450
  %3921 = sext i32 %3897 to i64
  store i64 %3921, i64* %RSI, align 8, !tbaa !2428
  %3922 = shl nsw i64 %3921, 3
  %3923 = add i64 %3922, %3892
  %3924 = add i64 %3889, 18
  store i64 %3924, i64* %PC, align 8
  %3925 = inttoptr i64 %3923 to double*
  %3926 = load double, double* %3925, align 8
  store double %3926, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3927 = add i64 %3889, 22
  store i64 %3927, i64* %PC, align 8
  %3928 = load i64, i64* %3891, align 8
  store i64 %3928, i64* %RDX, align 8, !tbaa !2428
  %3929 = add i64 %3887, -32
  %3930 = add i64 %3889, 25
  store i64 %3930, i64* %PC, align 8
  %3931 = inttoptr i64 %3929 to i32*
  %3932 = load i32, i32* %3931, align 4
  %3933 = add i32 %3932, 1
  %3934 = zext i32 %3933 to i64
  store i64 %3934, i64* %RCX, align 8, !tbaa !2428
  %3935 = icmp eq i32 %3932, -1
  %3936 = icmp eq i32 %3933, 0
  %3937 = or i1 %3935, %3936
  %3938 = zext i1 %3937 to i8
  store i8 %3938, i8* %18, align 1, !tbaa !2433
  %3939 = and i32 %3933, 255
  %3940 = tail call i32 @llvm.ctpop.i32(i32 %3939) #10
  %3941 = trunc i32 %3940 to i8
  %3942 = and i8 %3941, 1
  %3943 = xor i8 %3942, 1
  store i8 %3943, i8* %25, align 1, !tbaa !2447
  %3944 = xor i32 %3932, %3933
  %3945 = lshr i32 %3944, 4
  %3946 = trunc i32 %3945 to i8
  %3947 = and i8 %3946, 1
  store i8 %3947, i8* %31, align 1, !tbaa !2451
  %3948 = icmp eq i32 %3933, 0
  %3949 = zext i1 %3948 to i8
  store i8 %3949, i8* %34, align 1, !tbaa !2448
  %3950 = lshr i32 %3933, 31
  %3951 = trunc i32 %3950 to i8
  store i8 %3951, i8* %37, align 1, !tbaa !2449
  %3952 = lshr i32 %3932, 31
  %3953 = xor i32 %3950, %3952
  %3954 = add nuw nsw i32 %3953, %3950
  %3955 = icmp eq i32 %3954, 2
  %3956 = zext i1 %3955 to i8
  store i8 %3956, i8* %43, align 1, !tbaa !2450
  %3957 = sext i32 %3933 to i64
  store i64 %3957, i64* %RSI, align 8, !tbaa !2428
  %3958 = shl nsw i64 %3957, 3
  %3959 = add i64 %3958, %3928
  %3960 = add i64 %3889, 36
  store i64 %3960, i64* %PC, align 8
  %3961 = inttoptr i64 %3959 to double*
  %3962 = load double, double* %3961, align 8
  %3963 = fadd double %3926, %3962
  store double %3963, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3964 = load i64, i64* %RBP, align 8
  %3965 = add i64 %3964, -128
  %3966 = add i64 %3889, 41
  store i64 %3966, i64* %PC, align 8
  %3967 = inttoptr i64 %3965 to double*
  store double %3963, double* %3967, align 8
  %3968 = load i64, i64* %RBP, align 8
  %3969 = add i64 %3968, -16
  %3970 = load i64, i64* %PC, align 8
  %3971 = add i64 %3970, 4
  store i64 %3971, i64* %PC, align 8
  %3972 = inttoptr i64 %3969 to i64*
  %3973 = load i64, i64* %3972, align 8
  store i64 %3973, i64* %RDX, align 8, !tbaa !2428
  %3974 = add i64 %3968, -28
  %3975 = add i64 %3970, 8
  store i64 %3975, i64* %PC, align 8
  %3976 = inttoptr i64 %3974 to i32*
  %3977 = load i32, i32* %3976, align 4
  %3978 = sext i32 %3977 to i64
  store i64 %3978, i64* %RSI, align 8, !tbaa !2428
  %3979 = shl nsw i64 %3978, 3
  %3980 = add i64 %3979, %3973
  %3981 = add i64 %3970, 13
  store i64 %3981, i64* %PC, align 8
  %3982 = inttoptr i64 %3980 to double*
  %3983 = load double, double* %3982, align 8
  store double %3983, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %3984 = add i64 %3970, 17
  store i64 %3984, i64* %PC, align 8
  %3985 = load i64, i64* %3972, align 8
  store i64 %3985, i64* %RDX, align 8, !tbaa !2428
  %3986 = add i64 %3968, -32
  %3987 = add i64 %3970, 21
  store i64 %3987, i64* %PC, align 8
  %3988 = inttoptr i64 %3986 to i32*
  %3989 = load i32, i32* %3988, align 4
  %3990 = sext i32 %3989 to i64
  store i64 %3990, i64* %RSI, align 8, !tbaa !2428
  %3991 = shl nsw i64 %3990, 3
  %3992 = add i64 %3991, %3985
  %3993 = add i64 %3970, 26
  store i64 %3993, i64* %PC, align 8
  %3994 = inttoptr i64 %3992 to double*
  %3995 = load double, double* %3994, align 8
  %3996 = fsub double %3983, %3995
  store double %3996, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %3997 = add i64 %3968, -136
  %3998 = add i64 %3970, 34
  store i64 %3998, i64* %PC, align 8
  %3999 = inttoptr i64 %3997 to double*
  store double %3996, double* %3999, align 8
  %4000 = load i64, i64* %RBP, align 8
  %4001 = add i64 %4000, -16
  %4002 = load i64, i64* %PC, align 8
  %4003 = add i64 %4002, 4
  store i64 %4003, i64* %PC, align 8
  %4004 = inttoptr i64 %4001 to i64*
  %4005 = load i64, i64* %4004, align 8
  store i64 %4005, i64* %RDX, align 8, !tbaa !2428
  %4006 = add i64 %4000, -28
  %4007 = add i64 %4002, 7
  store i64 %4007, i64* %PC, align 8
  %4008 = inttoptr i64 %4006 to i32*
  %4009 = load i32, i32* %4008, align 4
  %4010 = add i32 %4009, 1
  %4011 = zext i32 %4010 to i64
  store i64 %4011, i64* %RCX, align 8, !tbaa !2428
  %4012 = icmp eq i32 %4009, -1
  %4013 = icmp eq i32 %4010, 0
  %4014 = or i1 %4012, %4013
  %4015 = zext i1 %4014 to i8
  store i8 %4015, i8* %18, align 1, !tbaa !2433
  %4016 = and i32 %4010, 255
  %4017 = tail call i32 @llvm.ctpop.i32(i32 %4016) #10
  %4018 = trunc i32 %4017 to i8
  %4019 = and i8 %4018, 1
  %4020 = xor i8 %4019, 1
  store i8 %4020, i8* %25, align 1, !tbaa !2447
  %4021 = xor i32 %4009, %4010
  %4022 = lshr i32 %4021, 4
  %4023 = trunc i32 %4022 to i8
  %4024 = and i8 %4023, 1
  store i8 %4024, i8* %31, align 1, !tbaa !2451
  %4025 = icmp eq i32 %4010, 0
  %4026 = zext i1 %4025 to i8
  store i8 %4026, i8* %34, align 1, !tbaa !2448
  %4027 = lshr i32 %4010, 31
  %4028 = trunc i32 %4027 to i8
  store i8 %4028, i8* %37, align 1, !tbaa !2449
  %4029 = lshr i32 %4009, 31
  %4030 = xor i32 %4027, %4029
  %4031 = add nuw nsw i32 %4030, %4027
  %4032 = icmp eq i32 %4031, 2
  %4033 = zext i1 %4032 to i8
  store i8 %4033, i8* %43, align 1, !tbaa !2450
  %4034 = sext i32 %4010 to i64
  store i64 %4034, i64* %RSI, align 8, !tbaa !2428
  %4035 = shl nsw i64 %4034, 3
  %4036 = add i64 %4035, %4005
  %4037 = add i64 %4002, 18
  store i64 %4037, i64* %PC, align 8
  %4038 = inttoptr i64 %4036 to double*
  %4039 = load double, double* %4038, align 8
  store double %4039, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4040 = add i64 %4002, 22
  store i64 %4040, i64* %PC, align 8
  %4041 = load i64, i64* %4004, align 8
  store i64 %4041, i64* %RDX, align 8, !tbaa !2428
  %4042 = add i64 %4000, -32
  %4043 = add i64 %4002, 25
  store i64 %4043, i64* %PC, align 8
  %4044 = inttoptr i64 %4042 to i32*
  %4045 = load i32, i32* %4044, align 4
  %4046 = add i32 %4045, 1
  %4047 = zext i32 %4046 to i64
  store i64 %4047, i64* %RCX, align 8, !tbaa !2428
  %4048 = icmp eq i32 %4045, -1
  %4049 = icmp eq i32 %4046, 0
  %4050 = or i1 %4048, %4049
  %4051 = zext i1 %4050 to i8
  store i8 %4051, i8* %18, align 1, !tbaa !2433
  %4052 = and i32 %4046, 255
  %4053 = tail call i32 @llvm.ctpop.i32(i32 %4052) #10
  %4054 = trunc i32 %4053 to i8
  %4055 = and i8 %4054, 1
  %4056 = xor i8 %4055, 1
  store i8 %4056, i8* %25, align 1, !tbaa !2447
  %4057 = xor i32 %4045, %4046
  %4058 = lshr i32 %4057, 4
  %4059 = trunc i32 %4058 to i8
  %4060 = and i8 %4059, 1
  store i8 %4060, i8* %31, align 1, !tbaa !2451
  %4061 = icmp eq i32 %4046, 0
  %4062 = zext i1 %4061 to i8
  store i8 %4062, i8* %34, align 1, !tbaa !2448
  %4063 = lshr i32 %4046, 31
  %4064 = trunc i32 %4063 to i8
  store i8 %4064, i8* %37, align 1, !tbaa !2449
  %4065 = lshr i32 %4045, 31
  %4066 = xor i32 %4063, %4065
  %4067 = add nuw nsw i32 %4066, %4063
  %4068 = icmp eq i32 %4067, 2
  %4069 = zext i1 %4068 to i8
  store i8 %4069, i8* %43, align 1, !tbaa !2450
  %4070 = sext i32 %4046 to i64
  store i64 %4070, i64* %RSI, align 8, !tbaa !2428
  %4071 = shl nsw i64 %4070, 3
  %4072 = add i64 %4071, %4041
  %4073 = add i64 %4002, 36
  store i64 %4073, i64* %PC, align 8
  %4074 = inttoptr i64 %4072 to double*
  %4075 = load double, double* %4074, align 8
  %4076 = fsub double %4039, %4075
  store double %4076, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4077 = load i64, i64* %RBP, align 8
  %4078 = add i64 %4077, -144
  %4079 = add i64 %4002, 44
  store i64 %4079, i64* %PC, align 8
  %4080 = inttoptr i64 %4078 to double*
  store double %4076, double* %4080, align 8
  %4081 = load i64, i64* %RBP, align 8
  %4082 = add i64 %4081, -16
  %4083 = load i64, i64* %PC, align 8
  %4084 = add i64 %4083, 4
  store i64 %4084, i64* %PC, align 8
  %4085 = inttoptr i64 %4082 to i64*
  %4086 = load i64, i64* %4085, align 8
  store i64 %4086, i64* %RDX, align 8, !tbaa !2428
  %4087 = add i64 %4081, -36
  %4088 = add i64 %4083, 8
  store i64 %4088, i64* %PC, align 8
  %4089 = inttoptr i64 %4087 to i32*
  %4090 = load i32, i32* %4089, align 4
  %4091 = sext i32 %4090 to i64
  store i64 %4091, i64* %RSI, align 8, !tbaa !2428
  %4092 = shl nsw i64 %4091, 3
  %4093 = add i64 %4092, %4086
  %4094 = add i64 %4083, 13
  store i64 %4094, i64* %PC, align 8
  %4095 = inttoptr i64 %4093 to double*
  %4096 = load double, double* %4095, align 8
  store double %4096, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4097 = add i64 %4083, 17
  store i64 %4097, i64* %PC, align 8
  %4098 = load i64, i64* %4085, align 8
  store i64 %4098, i64* %RDX, align 8, !tbaa !2428
  %4099 = add i64 %4081, -40
  %4100 = add i64 %4083, 21
  store i64 %4100, i64* %PC, align 8
  %4101 = inttoptr i64 %4099 to i32*
  %4102 = load i32, i32* %4101, align 4
  %4103 = sext i32 %4102 to i64
  store i64 %4103, i64* %RSI, align 8, !tbaa !2428
  %4104 = shl nsw i64 %4103, 3
  %4105 = add i64 %4104, %4098
  %4106 = add i64 %4083, 26
  store i64 %4106, i64* %PC, align 8
  %4107 = inttoptr i64 %4105 to double*
  %4108 = load double, double* %4107, align 8
  %4109 = fadd double %4096, %4108
  store double %4109, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4110 = add i64 %4081, -152
  %4111 = add i64 %4083, 34
  store i64 %4111, i64* %PC, align 8
  %4112 = inttoptr i64 %4110 to double*
  store double %4109, double* %4112, align 8
  %4113 = load i64, i64* %RBP, align 8
  %4114 = add i64 %4113, -16
  %4115 = load i64, i64* %PC, align 8
  %4116 = add i64 %4115, 4
  store i64 %4116, i64* %PC, align 8
  %4117 = inttoptr i64 %4114 to i64*
  %4118 = load i64, i64* %4117, align 8
  store i64 %4118, i64* %RDX, align 8, !tbaa !2428
  %4119 = add i64 %4113, -36
  %4120 = add i64 %4115, 7
  store i64 %4120, i64* %PC, align 8
  %4121 = inttoptr i64 %4119 to i32*
  %4122 = load i32, i32* %4121, align 4
  %4123 = add i32 %4122, 1
  %4124 = zext i32 %4123 to i64
  store i64 %4124, i64* %RCX, align 8, !tbaa !2428
  %4125 = icmp eq i32 %4122, -1
  %4126 = icmp eq i32 %4123, 0
  %4127 = or i1 %4125, %4126
  %4128 = zext i1 %4127 to i8
  store i8 %4128, i8* %18, align 1, !tbaa !2433
  %4129 = and i32 %4123, 255
  %4130 = tail call i32 @llvm.ctpop.i32(i32 %4129) #10
  %4131 = trunc i32 %4130 to i8
  %4132 = and i8 %4131, 1
  %4133 = xor i8 %4132, 1
  store i8 %4133, i8* %25, align 1, !tbaa !2447
  %4134 = xor i32 %4122, %4123
  %4135 = lshr i32 %4134, 4
  %4136 = trunc i32 %4135 to i8
  %4137 = and i8 %4136, 1
  store i8 %4137, i8* %31, align 1, !tbaa !2451
  %4138 = icmp eq i32 %4123, 0
  %4139 = zext i1 %4138 to i8
  store i8 %4139, i8* %34, align 1, !tbaa !2448
  %4140 = lshr i32 %4123, 31
  %4141 = trunc i32 %4140 to i8
  store i8 %4141, i8* %37, align 1, !tbaa !2449
  %4142 = lshr i32 %4122, 31
  %4143 = xor i32 %4140, %4142
  %4144 = add nuw nsw i32 %4143, %4140
  %4145 = icmp eq i32 %4144, 2
  %4146 = zext i1 %4145 to i8
  store i8 %4146, i8* %43, align 1, !tbaa !2450
  %4147 = sext i32 %4123 to i64
  store i64 %4147, i64* %RSI, align 8, !tbaa !2428
  %4148 = shl nsw i64 %4147, 3
  %4149 = add i64 %4148, %4118
  %4150 = add i64 %4115, 18
  store i64 %4150, i64* %PC, align 8
  %4151 = inttoptr i64 %4149 to double*
  %4152 = load double, double* %4151, align 8
  store double %4152, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4153 = add i64 %4115, 22
  store i64 %4153, i64* %PC, align 8
  %4154 = load i64, i64* %4117, align 8
  store i64 %4154, i64* %RDX, align 8, !tbaa !2428
  %4155 = add i64 %4113, -40
  %4156 = add i64 %4115, 25
  store i64 %4156, i64* %PC, align 8
  %4157 = inttoptr i64 %4155 to i32*
  %4158 = load i32, i32* %4157, align 4
  %4159 = add i32 %4158, 1
  %4160 = zext i32 %4159 to i64
  store i64 %4160, i64* %RCX, align 8, !tbaa !2428
  %4161 = icmp eq i32 %4158, -1
  %4162 = icmp eq i32 %4159, 0
  %4163 = or i1 %4161, %4162
  %4164 = zext i1 %4163 to i8
  store i8 %4164, i8* %18, align 1, !tbaa !2433
  %4165 = and i32 %4159, 255
  %4166 = tail call i32 @llvm.ctpop.i32(i32 %4165) #10
  %4167 = trunc i32 %4166 to i8
  %4168 = and i8 %4167, 1
  %4169 = xor i8 %4168, 1
  store i8 %4169, i8* %25, align 1, !tbaa !2447
  %4170 = xor i32 %4158, %4159
  %4171 = lshr i32 %4170, 4
  %4172 = trunc i32 %4171 to i8
  %4173 = and i8 %4172, 1
  store i8 %4173, i8* %31, align 1, !tbaa !2451
  %4174 = icmp eq i32 %4159, 0
  %4175 = zext i1 %4174 to i8
  store i8 %4175, i8* %34, align 1, !tbaa !2448
  %4176 = lshr i32 %4159, 31
  %4177 = trunc i32 %4176 to i8
  store i8 %4177, i8* %37, align 1, !tbaa !2449
  %4178 = lshr i32 %4158, 31
  %4179 = xor i32 %4176, %4178
  %4180 = add nuw nsw i32 %4179, %4176
  %4181 = icmp eq i32 %4180, 2
  %4182 = zext i1 %4181 to i8
  store i8 %4182, i8* %43, align 1, !tbaa !2450
  %4183 = sext i32 %4159 to i64
  store i64 %4183, i64* %RSI, align 8, !tbaa !2428
  %4184 = shl nsw i64 %4183, 3
  %4185 = add i64 %4184, %4154
  %4186 = add i64 %4115, 36
  store i64 %4186, i64* %PC, align 8
  %4187 = inttoptr i64 %4185 to double*
  %4188 = load double, double* %4187, align 8
  %4189 = fadd double %4152, %4188
  store double %4189, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4190 = load i64, i64* %RBP, align 8
  %4191 = add i64 %4190, -160
  %4192 = add i64 %4115, 44
  store i64 %4192, i64* %PC, align 8
  %4193 = inttoptr i64 %4191 to double*
  store double %4189, double* %4193, align 8
  %4194 = load i64, i64* %RBP, align 8
  %4195 = add i64 %4194, -16
  %4196 = load i64, i64* %PC, align 8
  %4197 = add i64 %4196, 4
  store i64 %4197, i64* %PC, align 8
  %4198 = inttoptr i64 %4195 to i64*
  %4199 = load i64, i64* %4198, align 8
  store i64 %4199, i64* %RDX, align 8, !tbaa !2428
  %4200 = add i64 %4194, -36
  %4201 = add i64 %4196, 8
  store i64 %4201, i64* %PC, align 8
  %4202 = inttoptr i64 %4200 to i32*
  %4203 = load i32, i32* %4202, align 4
  %4204 = sext i32 %4203 to i64
  store i64 %4204, i64* %RSI, align 8, !tbaa !2428
  %4205 = shl nsw i64 %4204, 3
  %4206 = add i64 %4205, %4199
  %4207 = add i64 %4196, 13
  store i64 %4207, i64* %PC, align 8
  %4208 = inttoptr i64 %4206 to double*
  %4209 = load double, double* %4208, align 8
  store double %4209, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4210 = add i64 %4196, 17
  store i64 %4210, i64* %PC, align 8
  %4211 = load i64, i64* %4198, align 8
  store i64 %4211, i64* %RDX, align 8, !tbaa !2428
  %4212 = add i64 %4194, -40
  %4213 = add i64 %4196, 21
  store i64 %4213, i64* %PC, align 8
  %4214 = inttoptr i64 %4212 to i32*
  %4215 = load i32, i32* %4214, align 4
  %4216 = sext i32 %4215 to i64
  store i64 %4216, i64* %RSI, align 8, !tbaa !2428
  %4217 = shl nsw i64 %4216, 3
  %4218 = add i64 %4217, %4211
  %4219 = add i64 %4196, 26
  store i64 %4219, i64* %PC, align 8
  %4220 = inttoptr i64 %4218 to double*
  %4221 = load double, double* %4220, align 8
  %4222 = fsub double %4209, %4221
  store double %4222, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4223 = add i64 %4194, -168
  %4224 = add i64 %4196, 34
  store i64 %4224, i64* %PC, align 8
  %4225 = inttoptr i64 %4223 to double*
  store double %4222, double* %4225, align 8
  %4226 = load i64, i64* %RBP, align 8
  %4227 = add i64 %4226, -16
  %4228 = load i64, i64* %PC, align 8
  %4229 = add i64 %4228, 4
  store i64 %4229, i64* %PC, align 8
  %4230 = inttoptr i64 %4227 to i64*
  %4231 = load i64, i64* %4230, align 8
  store i64 %4231, i64* %RDX, align 8, !tbaa !2428
  %4232 = add i64 %4226, -36
  %4233 = add i64 %4228, 7
  store i64 %4233, i64* %PC, align 8
  %4234 = inttoptr i64 %4232 to i32*
  %4235 = load i32, i32* %4234, align 4
  %4236 = add i32 %4235, 1
  %4237 = zext i32 %4236 to i64
  store i64 %4237, i64* %RCX, align 8, !tbaa !2428
  %4238 = icmp eq i32 %4235, -1
  %4239 = icmp eq i32 %4236, 0
  %4240 = or i1 %4238, %4239
  %4241 = zext i1 %4240 to i8
  store i8 %4241, i8* %18, align 1, !tbaa !2433
  %4242 = and i32 %4236, 255
  %4243 = tail call i32 @llvm.ctpop.i32(i32 %4242) #10
  %4244 = trunc i32 %4243 to i8
  %4245 = and i8 %4244, 1
  %4246 = xor i8 %4245, 1
  store i8 %4246, i8* %25, align 1, !tbaa !2447
  %4247 = xor i32 %4235, %4236
  %4248 = lshr i32 %4247, 4
  %4249 = trunc i32 %4248 to i8
  %4250 = and i8 %4249, 1
  store i8 %4250, i8* %31, align 1, !tbaa !2451
  %4251 = icmp eq i32 %4236, 0
  %4252 = zext i1 %4251 to i8
  store i8 %4252, i8* %34, align 1, !tbaa !2448
  %4253 = lshr i32 %4236, 31
  %4254 = trunc i32 %4253 to i8
  store i8 %4254, i8* %37, align 1, !tbaa !2449
  %4255 = lshr i32 %4235, 31
  %4256 = xor i32 %4253, %4255
  %4257 = add nuw nsw i32 %4256, %4253
  %4258 = icmp eq i32 %4257, 2
  %4259 = zext i1 %4258 to i8
  store i8 %4259, i8* %43, align 1, !tbaa !2450
  %4260 = sext i32 %4236 to i64
  store i64 %4260, i64* %RSI, align 8, !tbaa !2428
  %4261 = shl nsw i64 %4260, 3
  %4262 = add i64 %4261, %4231
  %4263 = add i64 %4228, 18
  store i64 %4263, i64* %PC, align 8
  %4264 = inttoptr i64 %4262 to double*
  %4265 = load double, double* %4264, align 8
  store double %4265, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4266 = add i64 %4228, 22
  store i64 %4266, i64* %PC, align 8
  %4267 = load i64, i64* %4230, align 8
  store i64 %4267, i64* %RDX, align 8, !tbaa !2428
  %4268 = add i64 %4226, -40
  %4269 = add i64 %4228, 25
  store i64 %4269, i64* %PC, align 8
  %4270 = inttoptr i64 %4268 to i32*
  %4271 = load i32, i32* %4270, align 4
  %4272 = add i32 %4271, 1
  %4273 = zext i32 %4272 to i64
  store i64 %4273, i64* %RCX, align 8, !tbaa !2428
  %4274 = icmp eq i32 %4271, -1
  %4275 = icmp eq i32 %4272, 0
  %4276 = or i1 %4274, %4275
  %4277 = zext i1 %4276 to i8
  store i8 %4277, i8* %18, align 1, !tbaa !2433
  %4278 = and i32 %4272, 255
  %4279 = tail call i32 @llvm.ctpop.i32(i32 %4278) #10
  %4280 = trunc i32 %4279 to i8
  %4281 = and i8 %4280, 1
  %4282 = xor i8 %4281, 1
  store i8 %4282, i8* %25, align 1, !tbaa !2447
  %4283 = xor i32 %4271, %4272
  %4284 = lshr i32 %4283, 4
  %4285 = trunc i32 %4284 to i8
  %4286 = and i8 %4285, 1
  store i8 %4286, i8* %31, align 1, !tbaa !2451
  %4287 = icmp eq i32 %4272, 0
  %4288 = zext i1 %4287 to i8
  store i8 %4288, i8* %34, align 1, !tbaa !2448
  %4289 = lshr i32 %4272, 31
  %4290 = trunc i32 %4289 to i8
  store i8 %4290, i8* %37, align 1, !tbaa !2449
  %4291 = lshr i32 %4271, 31
  %4292 = xor i32 %4289, %4291
  %4293 = add nuw nsw i32 %4292, %4289
  %4294 = icmp eq i32 %4293, 2
  %4295 = zext i1 %4294 to i8
  store i8 %4295, i8* %43, align 1, !tbaa !2450
  %4296 = sext i32 %4272 to i64
  store i64 %4296, i64* %RSI, align 8, !tbaa !2428
  %4297 = shl nsw i64 %4296, 3
  %4298 = add i64 %4297, %4267
  %4299 = add i64 %4228, 36
  store i64 %4299, i64* %PC, align 8
  %4300 = inttoptr i64 %4298 to double*
  %4301 = load double, double* %4300, align 8
  %4302 = fsub double %4265, %4301
  store double %4302, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4303 = load i64, i64* %RBP, align 8
  %4304 = add i64 %4303, -176
  %4305 = add i64 %4228, 44
  store i64 %4305, i64* %PC, align 8
  %4306 = inttoptr i64 %4304 to double*
  store double %4302, double* %4306, align 8
  %4307 = load i64, i64* %RBP, align 8
  %4308 = add i64 %4307, -120
  %4309 = load i64, i64* %PC, align 8
  %4310 = add i64 %4309, 5
  store i64 %4310, i64* %PC, align 8
  %4311 = inttoptr i64 %4308 to double*
  %4312 = load double, double* %4311, align 8
  store double %4312, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4313 = add i64 %4307, -152
  %4314 = add i64 %4309, 13
  store i64 %4314, i64* %PC, align 8
  %4315 = inttoptr i64 %4313 to double*
  %4316 = load double, double* %4315, align 8
  %4317 = fadd double %4312, %4316
  store double %4317, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4318 = add i64 %4307, -16
  %4319 = add i64 %4309, 17
  store i64 %4319, i64* %PC, align 8
  %4320 = inttoptr i64 %4318 to i64*
  %4321 = load i64, i64* %4320, align 8
  store i64 %4321, i64* %RDX, align 8, !tbaa !2428
  %4322 = add i64 %4307, -28
  %4323 = add i64 %4309, 21
  store i64 %4323, i64* %PC, align 8
  %4324 = inttoptr i64 %4322 to i32*
  %4325 = load i32, i32* %4324, align 4
  %4326 = sext i32 %4325 to i64
  store i64 %4326, i64* %RSI, align 8, !tbaa !2428
  %4327 = shl nsw i64 %4326, 3
  %4328 = add i64 %4327, %4321
  %4329 = add i64 %4309, 26
  store i64 %4329, i64* %PC, align 8
  %4330 = inttoptr i64 %4328 to double*
  store double %4317, double* %4330, align 8
  %4331 = load i64, i64* %RBP, align 8
  %4332 = add i64 %4331, -128
  %4333 = load i64, i64* %PC, align 8
  %4334 = add i64 %4333, 5
  store i64 %4334, i64* %PC, align 8
  %4335 = inttoptr i64 %4332 to double*
  %4336 = load double, double* %4335, align 8
  store double %4336, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4337 = add i64 %4331, -160
  %4338 = add i64 %4333, 13
  store i64 %4338, i64* %PC, align 8
  %4339 = inttoptr i64 %4337 to double*
  %4340 = load double, double* %4339, align 8
  %4341 = fadd double %4336, %4340
  store double %4341, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4342 = add i64 %4331, -16
  %4343 = add i64 %4333, 17
  store i64 %4343, i64* %PC, align 8
  %4344 = inttoptr i64 %4342 to i64*
  %4345 = load i64, i64* %4344, align 8
  store i64 %4345, i64* %RDX, align 8, !tbaa !2428
  %4346 = add i64 %4331, -28
  %4347 = add i64 %4333, 20
  store i64 %4347, i64* %PC, align 8
  %4348 = inttoptr i64 %4346 to i32*
  %4349 = load i32, i32* %4348, align 4
  %4350 = add i32 %4349, 1
  %4351 = zext i32 %4350 to i64
  store i64 %4351, i64* %RCX, align 8, !tbaa !2428
  %4352 = icmp eq i32 %4349, -1
  %4353 = icmp eq i32 %4350, 0
  %4354 = or i1 %4352, %4353
  %4355 = zext i1 %4354 to i8
  store i8 %4355, i8* %18, align 1, !tbaa !2433
  %4356 = and i32 %4350, 255
  %4357 = tail call i32 @llvm.ctpop.i32(i32 %4356) #10
  %4358 = trunc i32 %4357 to i8
  %4359 = and i8 %4358, 1
  %4360 = xor i8 %4359, 1
  store i8 %4360, i8* %25, align 1, !tbaa !2447
  %4361 = xor i32 %4349, %4350
  %4362 = lshr i32 %4361, 4
  %4363 = trunc i32 %4362 to i8
  %4364 = and i8 %4363, 1
  store i8 %4364, i8* %31, align 1, !tbaa !2451
  %4365 = icmp eq i32 %4350, 0
  %4366 = zext i1 %4365 to i8
  store i8 %4366, i8* %34, align 1, !tbaa !2448
  %4367 = lshr i32 %4350, 31
  %4368 = trunc i32 %4367 to i8
  store i8 %4368, i8* %37, align 1, !tbaa !2449
  %4369 = lshr i32 %4349, 31
  %4370 = xor i32 %4367, %4369
  %4371 = add nuw nsw i32 %4370, %4367
  %4372 = icmp eq i32 %4371, 2
  %4373 = zext i1 %4372 to i8
  store i8 %4373, i8* %43, align 1, !tbaa !2450
  %4374 = sext i32 %4350 to i64
  store i64 %4374, i64* %RSI, align 8, !tbaa !2428
  %4375 = shl nsw i64 %4374, 3
  %4376 = add i64 %4375, %4345
  %4377 = add i64 %4333, 31
  store i64 %4377, i64* %PC, align 8
  %4378 = inttoptr i64 %4376 to double*
  store double %4341, double* %4378, align 8
  %4379 = load i64, i64* %RBP, align 8
  %4380 = add i64 %4379, -152
  %4381 = load i64, i64* %PC, align 8
  %4382 = add i64 %4381, 8
  store i64 %4382, i64* %PC, align 8
  %4383 = inttoptr i64 %4380 to double*
  %4384 = load double, double* %4383, align 8
  store double %4384, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4385 = add i64 %4379, -120
  %4386 = add i64 %4381, 13
  store i64 %4386, i64* %PC, align 8
  %4387 = inttoptr i64 %4385 to double*
  %4388 = load double, double* %4387, align 8
  %4389 = fsub double %4388, %4384
  store double %4389, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %4390 = add i64 %4381, 22
  store i64 %4390, i64* %PC, align 8
  store double %4389, double* %4387, align 8
  %4391 = load i64, i64* %RBP, align 8
  %4392 = add i64 %4391, -160
  %4393 = load i64, i64* %PC, align 8
  %4394 = add i64 %4393, 8
  store i64 %4394, i64* %PC, align 8
  %4395 = inttoptr i64 %4392 to double*
  %4396 = load double, double* %4395, align 8
  store double %4396, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4397 = add i64 %4391, -128
  %4398 = add i64 %4393, 13
  store i64 %4398, i64* %PC, align 8
  %4399 = inttoptr i64 %4397 to double*
  %4400 = load double, double* %4399, align 8
  %4401 = fsub double %4400, %4396
  store double %4401, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %4402 = add i64 %4393, 22
  store i64 %4402, i64* %PC, align 8
  store double %4401, double* %4399, align 8
  %4403 = load i64, i64* %RBP, align 8
  %4404 = add i64 %4403, -96
  %4405 = load i64, i64* %PC, align 8
  %4406 = add i64 %4405, 5
  store i64 %4406, i64* %PC, align 8
  %4407 = inttoptr i64 %4404 to i64*
  %4408 = load i64, i64* %4407, align 8
  %4409 = load i64, i64* %RAX, align 8
  %4410 = xor i64 %4409, %4408
  store i64 %4410, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  %4411 = trunc i64 %4410 to i32
  %4412 = and i32 %4411, 255
  %4413 = tail call i32 @llvm.ctpop.i32(i32 %4412) #10
  %4414 = trunc i32 %4413 to i8
  %4415 = and i8 %4414, 1
  %4416 = xor i8 %4415, 1
  store i8 %4416, i8* %25, align 1, !tbaa !2447
  %4417 = icmp eq i64 %4410, 0
  %4418 = zext i1 %4417 to i8
  store i8 %4418, i8* %34, align 1, !tbaa !2448
  %4419 = lshr i64 %4410, 63
  %4420 = trunc i64 %4419 to i8
  store i8 %4420, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  store i8 0, i8* %31, align 1, !tbaa !2451
  store i64 %4410, i64* %1478, align 1, !tbaa !2428
  store i64 0, i64* %97, align 1, !tbaa !2428
  %4421 = add i64 %4403, -120
  %4422 = add i64 %4405, 23
  store i64 %4422, i64* %PC, align 8
  %4423 = bitcast i64 %4410 to double
  %4424 = inttoptr i64 %4421 to double*
  %4425 = load double, double* %4424, align 8
  %4426 = fmul double %4423, %4425
  store double %4426, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4427 = add i64 %4403, -88
  %4428 = add i64 %4405, 28
  store i64 %4428, i64* %PC, align 8
  %4429 = inttoptr i64 %4427 to double*
  %4430 = load double, double* %4429, align 8
  store double %4430, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %4431 = add i64 %4403, -128
  %4432 = add i64 %4405, 33
  store i64 %4432, i64* %PC, align 8
  %4433 = inttoptr i64 %4431 to double*
  %4434 = load double, double* %4433, align 8
  %4435 = fmul double %4430, %4434
  store double %4435, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %4436 = fsub double %4426, %4435
  store double %4436, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4437 = add i64 %4403, -16
  %4438 = add i64 %4405, 41
  store i64 %4438, i64* %PC, align 8
  %4439 = inttoptr i64 %4437 to i64*
  %4440 = load i64, i64* %4439, align 8
  store i64 %4440, i64* %RDX, align 8, !tbaa !2428
  %4441 = add i64 %4403, -36
  %4442 = add i64 %4405, 45
  store i64 %4442, i64* %PC, align 8
  %4443 = inttoptr i64 %4441 to i32*
  %4444 = load i32, i32* %4443, align 4
  %4445 = sext i32 %4444 to i64
  store i64 %4445, i64* %RSI, align 8, !tbaa !2428
  %4446 = shl nsw i64 %4445, 3
  %4447 = add i64 %4446, %4440
  %4448 = add i64 %4405, 50
  store i64 %4448, i64* %PC, align 8
  %4449 = inttoptr i64 %4447 to double*
  store double %4436, double* %4449, align 8
  %4450 = load i64, i64* %RBP, align 8
  %4451 = add i64 %4450, -96
  %4452 = load i64, i64* %PC, align 8
  %4453 = add i64 %4452, 5
  store i64 %4453, i64* %PC, align 8
  %4454 = inttoptr i64 %4451 to i64*
  %4455 = load i64, i64* %4454, align 8
  %4456 = load i64, i64* %RAX, align 8
  %4457 = xor i64 %4456, %4455
  store i64 %4457, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2433
  %4458 = trunc i64 %4457 to i32
  %4459 = and i32 %4458, 255
  %4460 = tail call i32 @llvm.ctpop.i32(i32 %4459) #10
  %4461 = trunc i32 %4460 to i8
  %4462 = and i8 %4461, 1
  %4463 = xor i8 %4462, 1
  store i8 %4463, i8* %25, align 1, !tbaa !2447
  %4464 = icmp eq i64 %4457, 0
  %4465 = zext i1 %4464 to i8
  store i8 %4465, i8* %34, align 1, !tbaa !2448
  %4466 = lshr i64 %4457, 63
  %4467 = trunc i64 %4466 to i8
  store i8 %4467, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  store i8 0, i8* %31, align 1, !tbaa !2451
  store i64 %4457, i64* %1478, align 1, !tbaa !2428
  store i64 0, i64* %97, align 1, !tbaa !2428
  %4468 = add i64 %4450, -128
  %4469 = add i64 %4452, 23
  store i64 %4469, i64* %PC, align 8
  %4470 = bitcast i64 %4457 to double
  %4471 = inttoptr i64 %4468 to double*
  %4472 = load double, double* %4471, align 8
  %4473 = fmul double %4470, %4472
  store double %4473, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4474 = add i64 %4450, -88
  %4475 = add i64 %4452, 28
  store i64 %4475, i64* %PC, align 8
  %4476 = inttoptr i64 %4474 to double*
  %4477 = load double, double* %4476, align 8
  store double %4477, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %4478 = add i64 %4450, -120
  %4479 = add i64 %4452, 33
  store i64 %4479, i64* %PC, align 8
  %4480 = inttoptr i64 %4478 to double*
  %4481 = load double, double* %4480, align 8
  %4482 = fmul double %4477, %4481
  store double %4482, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %4483 = fadd double %4473, %4482
  store double %4483, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4484 = add i64 %4450, -16
  %4485 = add i64 %4452, 41
  store i64 %4485, i64* %PC, align 8
  %4486 = inttoptr i64 %4484 to i64*
  %4487 = load i64, i64* %4486, align 8
  store i64 %4487, i64* %RAX, align 8, !tbaa !2428
  %4488 = add i64 %4450, -36
  %4489 = add i64 %4452, 44
  store i64 %4489, i64* %PC, align 8
  %4490 = inttoptr i64 %4488 to i32*
  %4491 = load i32, i32* %4490, align 4
  %4492 = add i32 %4491, 1
  %4493 = zext i32 %4492 to i64
  store i64 %4493, i64* %RCX, align 8, !tbaa !2428
  %4494 = icmp eq i32 %4491, -1
  %4495 = icmp eq i32 %4492, 0
  %4496 = or i1 %4494, %4495
  %4497 = zext i1 %4496 to i8
  store i8 %4497, i8* %18, align 1, !tbaa !2433
  %4498 = and i32 %4492, 255
  %4499 = tail call i32 @llvm.ctpop.i32(i32 %4498) #10
  %4500 = trunc i32 %4499 to i8
  %4501 = and i8 %4500, 1
  %4502 = xor i8 %4501, 1
  store i8 %4502, i8* %25, align 1, !tbaa !2447
  %4503 = xor i32 %4491, %4492
  %4504 = lshr i32 %4503, 4
  %4505 = trunc i32 %4504 to i8
  %4506 = and i8 %4505, 1
  store i8 %4506, i8* %31, align 1, !tbaa !2451
  %4507 = icmp eq i32 %4492, 0
  %4508 = zext i1 %4507 to i8
  store i8 %4508, i8* %34, align 1, !tbaa !2448
  %4509 = lshr i32 %4492, 31
  %4510 = trunc i32 %4509 to i8
  store i8 %4510, i8* %37, align 1, !tbaa !2449
  %4511 = lshr i32 %4491, 31
  %4512 = xor i32 %4509, %4511
  %4513 = add nuw nsw i32 %4512, %4509
  %4514 = icmp eq i32 %4513, 2
  %4515 = zext i1 %4514 to i8
  store i8 %4515, i8* %43, align 1, !tbaa !2450
  %4516 = sext i32 %4492 to i64
  store i64 %4516, i64* %RDX, align 8, !tbaa !2428
  %4517 = shl nsw i64 %4516, 3
  %4518 = add i64 %4517, %4487
  %4519 = add i64 %4452, 55
  store i64 %4519, i64* %PC, align 8
  %4520 = inttoptr i64 %4518 to double*
  store double %4483, double* %4520, align 8
  %4521 = load i64, i64* %RBP, align 8
  %4522 = add i64 %4521, -136
  %4523 = load i64, i64* %PC, align 8
  %4524 = add i64 %4523, 8
  store i64 %4524, i64* %PC, align 8
  %4525 = inttoptr i64 %4522 to double*
  %4526 = load double, double* %4525, align 8
  store double %4526, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4527 = add i64 %4521, -176
  %4528 = add i64 %4523, 16
  store i64 %4528, i64* %PC, align 8
  %4529 = inttoptr i64 %4527 to double*
  %4530 = load double, double* %4529, align 8
  %4531 = fsub double %4526, %4530
  store double %4531, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4532 = add i64 %4521, -120
  %4533 = add i64 %4523, 21
  store i64 %4533, i64* %PC, align 8
  %4534 = inttoptr i64 %4532 to double*
  store double %4531, double* %4534, align 8
  %4535 = load i64, i64* %RBP, align 8
  %4536 = add i64 %4535, -144
  %4537 = load i64, i64* %PC, align 8
  %4538 = add i64 %4537, 8
  store i64 %4538, i64* %PC, align 8
  %4539 = inttoptr i64 %4536 to double*
  %4540 = load double, double* %4539, align 8
  store double %4540, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4541 = add i64 %4535, -168
  %4542 = add i64 %4537, 16
  store i64 %4542, i64* %PC, align 8
  %4543 = inttoptr i64 %4541 to double*
  %4544 = load double, double* %4543, align 8
  %4545 = fadd double %4540, %4544
  store double %4545, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4546 = add i64 %4535, -128
  %4547 = add i64 %4537, 21
  store i64 %4547, i64* %PC, align 8
  %4548 = inttoptr i64 %4546 to double*
  store double %4545, double* %4548, align 8
  %4549 = load i64, i64* %RBP, align 8
  %4550 = add i64 %4549, -72
  %4551 = load i64, i64* %PC, align 8
  %4552 = add i64 %4551, 5
  store i64 %4552, i64* %PC, align 8
  %4553 = inttoptr i64 %4550 to double*
  %4554 = load double, double* %4553, align 8
  store double %4554, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4555 = add i64 %4549, -120
  %4556 = add i64 %4551, 10
  store i64 %4556, i64* %PC, align 8
  %4557 = inttoptr i64 %4555 to double*
  %4558 = load double, double* %4557, align 8
  %4559 = fmul double %4554, %4558
  store double %4559, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4560 = add i64 %4549, -80
  %4561 = add i64 %4551, 15
  store i64 %4561, i64* %PC, align 8
  %4562 = inttoptr i64 %4560 to double*
  %4563 = load double, double* %4562, align 8
  store double %4563, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %4564 = add i64 %4549, -128
  %4565 = add i64 %4551, 20
  store i64 %4565, i64* %PC, align 8
  %4566 = inttoptr i64 %4564 to double*
  %4567 = load double, double* %4566, align 8
  %4568 = fmul double %4563, %4567
  store double %4568, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %4569 = fsub double %4559, %4568
  store double %4569, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4570 = add i64 %4549, -16
  %4571 = add i64 %4551, 28
  store i64 %4571, i64* %PC, align 8
  %4572 = inttoptr i64 %4570 to i64*
  %4573 = load i64, i64* %4572, align 8
  store i64 %4573, i64* %RAX, align 8, !tbaa !2428
  %4574 = add i64 %4549, -32
  %4575 = add i64 %4551, 32
  store i64 %4575, i64* %PC, align 8
  %4576 = inttoptr i64 %4574 to i32*
  %4577 = load i32, i32* %4576, align 4
  %4578 = sext i32 %4577 to i64
  store i64 %4578, i64* %RDX, align 8, !tbaa !2428
  %4579 = shl nsw i64 %4578, 3
  %4580 = add i64 %4579, %4573
  %4581 = add i64 %4551, 37
  store i64 %4581, i64* %PC, align 8
  %4582 = inttoptr i64 %4580 to double*
  store double %4569, double* %4582, align 8
  %4583 = load i64, i64* %RBP, align 8
  %4584 = add i64 %4583, -72
  %4585 = load i64, i64* %PC, align 8
  %4586 = add i64 %4585, 5
  store i64 %4586, i64* %PC, align 8
  %4587 = inttoptr i64 %4584 to double*
  %4588 = load double, double* %4587, align 8
  store double %4588, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4589 = add i64 %4583, -128
  %4590 = add i64 %4585, 10
  store i64 %4590, i64* %PC, align 8
  %4591 = inttoptr i64 %4589 to double*
  %4592 = load double, double* %4591, align 8
  %4593 = fmul double %4588, %4592
  store double %4593, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4594 = add i64 %4583, -80
  %4595 = add i64 %4585, 15
  store i64 %4595, i64* %PC, align 8
  %4596 = inttoptr i64 %4594 to double*
  %4597 = load double, double* %4596, align 8
  store double %4597, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %4598 = add i64 %4583, -120
  %4599 = add i64 %4585, 20
  store i64 %4599, i64* %PC, align 8
  %4600 = inttoptr i64 %4598 to double*
  %4601 = load double, double* %4600, align 8
  %4602 = fmul double %4597, %4601
  store double %4602, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %4603 = fadd double %4593, %4602
  store double %4603, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4604 = add i64 %4583, -16
  %4605 = add i64 %4585, 28
  store i64 %4605, i64* %PC, align 8
  %4606 = inttoptr i64 %4604 to i64*
  %4607 = load i64, i64* %4606, align 8
  store i64 %4607, i64* %RAX, align 8, !tbaa !2428
  %4608 = add i64 %4583, -32
  %4609 = add i64 %4585, 31
  store i64 %4609, i64* %PC, align 8
  %4610 = inttoptr i64 %4608 to i32*
  %4611 = load i32, i32* %4610, align 4
  %4612 = add i32 %4611, 1
  %4613 = zext i32 %4612 to i64
  store i64 %4613, i64* %RCX, align 8, !tbaa !2428
  %4614 = icmp eq i32 %4611, -1
  %4615 = icmp eq i32 %4612, 0
  %4616 = or i1 %4614, %4615
  %4617 = zext i1 %4616 to i8
  store i8 %4617, i8* %18, align 1, !tbaa !2433
  %4618 = and i32 %4612, 255
  %4619 = tail call i32 @llvm.ctpop.i32(i32 %4618) #10
  %4620 = trunc i32 %4619 to i8
  %4621 = and i8 %4620, 1
  %4622 = xor i8 %4621, 1
  store i8 %4622, i8* %25, align 1, !tbaa !2447
  %4623 = xor i32 %4611, %4612
  %4624 = lshr i32 %4623, 4
  %4625 = trunc i32 %4624 to i8
  %4626 = and i8 %4625, 1
  store i8 %4626, i8* %31, align 1, !tbaa !2451
  %4627 = icmp eq i32 %4612, 0
  %4628 = zext i1 %4627 to i8
  store i8 %4628, i8* %34, align 1, !tbaa !2448
  %4629 = lshr i32 %4612, 31
  %4630 = trunc i32 %4629 to i8
  store i8 %4630, i8* %37, align 1, !tbaa !2449
  %4631 = lshr i32 %4611, 31
  %4632 = xor i32 %4629, %4631
  %4633 = add nuw nsw i32 %4632, %4629
  %4634 = icmp eq i32 %4633, 2
  %4635 = zext i1 %4634 to i8
  store i8 %4635, i8* %43, align 1, !tbaa !2450
  %4636 = sext i32 %4612 to i64
  store i64 %4636, i64* %RDX, align 8, !tbaa !2428
  %4637 = shl nsw i64 %4636, 3
  %4638 = add i64 %4637, %4607
  %4639 = add i64 %4585, 42
  store i64 %4639, i64* %PC, align 8
  %4640 = inttoptr i64 %4638 to double*
  store double %4603, double* %4640, align 8
  %4641 = load i64, i64* %RBP, align 8
  %4642 = add i64 %4641, -136
  %4643 = load i64, i64* %PC, align 8
  %4644 = add i64 %4643, 8
  store i64 %4644, i64* %PC, align 8
  %4645 = inttoptr i64 %4642 to double*
  %4646 = load double, double* %4645, align 8
  store double %4646, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4647 = add i64 %4641, -176
  %4648 = add i64 %4643, 16
  store i64 %4648, i64* %PC, align 8
  %4649 = inttoptr i64 %4647 to double*
  %4650 = load double, double* %4649, align 8
  %4651 = fadd double %4646, %4650
  store double %4651, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4652 = add i64 %4641, -120
  %4653 = add i64 %4643, 21
  store i64 %4653, i64* %PC, align 8
  %4654 = inttoptr i64 %4652 to double*
  store double %4651, double* %4654, align 8
  %4655 = load i64, i64* %RBP, align 8
  %4656 = add i64 %4655, -144
  %4657 = load i64, i64* %PC, align 8
  %4658 = add i64 %4657, 8
  store i64 %4658, i64* %PC, align 8
  %4659 = inttoptr i64 %4656 to double*
  %4660 = load double, double* %4659, align 8
  store double %4660, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4661 = add i64 %4655, -168
  %4662 = add i64 %4657, 16
  store i64 %4662, i64* %PC, align 8
  %4663 = inttoptr i64 %4661 to double*
  %4664 = load double, double* %4663, align 8
  %4665 = fsub double %4660, %4664
  store double %4665, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4666 = add i64 %4655, -128
  %4667 = add i64 %4657, 21
  store i64 %4667, i64* %PC, align 8
  %4668 = inttoptr i64 %4666 to double*
  store double %4665, double* %4668, align 8
  %4669 = load i64, i64* %RBP, align 8
  %4670 = add i64 %4669, -104
  %4671 = load i64, i64* %PC, align 8
  %4672 = add i64 %4671, 5
  store i64 %4672, i64* %PC, align 8
  %4673 = inttoptr i64 %4670 to double*
  %4674 = load double, double* %4673, align 8
  store double %4674, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4675 = add i64 %4669, -120
  %4676 = add i64 %4671, 10
  store i64 %4676, i64* %PC, align 8
  %4677 = inttoptr i64 %4675 to double*
  %4678 = load double, double* %4677, align 8
  %4679 = fmul double %4674, %4678
  store double %4679, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4680 = add i64 %4669, -112
  %4681 = add i64 %4671, 15
  store i64 %4681, i64* %PC, align 8
  %4682 = inttoptr i64 %4680 to double*
  %4683 = load double, double* %4682, align 8
  store double %4683, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %4684 = add i64 %4669, -128
  %4685 = add i64 %4671, 20
  store i64 %4685, i64* %PC, align 8
  %4686 = inttoptr i64 %4684 to double*
  %4687 = load double, double* %4686, align 8
  %4688 = fmul double %4683, %4687
  store double %4688, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %4689 = fsub double %4679, %4688
  store double %4689, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4690 = add i64 %4669, -16
  %4691 = add i64 %4671, 28
  store i64 %4691, i64* %PC, align 8
  %4692 = inttoptr i64 %4690 to i64*
  %4693 = load i64, i64* %4692, align 8
  store i64 %4693, i64* %RAX, align 8, !tbaa !2428
  %4694 = add i64 %4669, -40
  %4695 = add i64 %4671, 32
  store i64 %4695, i64* %PC, align 8
  %4696 = inttoptr i64 %4694 to i32*
  %4697 = load i32, i32* %4696, align 4
  %4698 = sext i32 %4697 to i64
  store i64 %4698, i64* %RDX, align 8, !tbaa !2428
  %4699 = shl nsw i64 %4698, 3
  %4700 = add i64 %4699, %4693
  %4701 = add i64 %4671, 37
  store i64 %4701, i64* %PC, align 8
  %4702 = inttoptr i64 %4700 to double*
  store double %4689, double* %4702, align 8
  %4703 = load i64, i64* %RBP, align 8
  %4704 = add i64 %4703, -104
  %4705 = load i64, i64* %PC, align 8
  %4706 = add i64 %4705, 5
  store i64 %4706, i64* %PC, align 8
  %4707 = inttoptr i64 %4704 to double*
  %4708 = load double, double* %4707, align 8
  store double %4708, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %4709 = add i64 %4703, -128
  %4710 = add i64 %4705, 10
  store i64 %4710, i64* %PC, align 8
  %4711 = inttoptr i64 %4709 to double*
  %4712 = load double, double* %4711, align 8
  %4713 = fmul double %4708, %4712
  store double %4713, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4714 = add i64 %4703, -112
  %4715 = add i64 %4705, 15
  store i64 %4715, i64* %PC, align 8
  %4716 = inttoptr i64 %4714 to double*
  %4717 = load double, double* %4716, align 8
  store double %4717, double* %295, align 1, !tbaa !2452
  store double 0.000000e+00, double* %297, align 1, !tbaa !2452
  %4718 = add i64 %4703, -120
  %4719 = add i64 %4705, 20
  store i64 %4719, i64* %PC, align 8
  %4720 = inttoptr i64 %4718 to double*
  %4721 = load double, double* %4720, align 8
  %4722 = fmul double %4717, %4721
  store double %4722, double* %295, align 1, !tbaa !2452
  store i64 0, i64* %296, align 1, !tbaa !2452
  %4723 = fadd double %4713, %4722
  store double %4723, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %4724 = add i64 %4703, -16
  %4725 = add i64 %4705, 28
  store i64 %4725, i64* %PC, align 8
  %4726 = inttoptr i64 %4724 to i64*
  %4727 = load i64, i64* %4726, align 8
  store i64 %4727, i64* %RAX, align 8, !tbaa !2428
  %4728 = add i64 %4703, -40
  %4729 = add i64 %4705, 31
  store i64 %4729, i64* %PC, align 8
  %4730 = inttoptr i64 %4728 to i32*
  %4731 = load i32, i32* %4730, align 4
  %4732 = add i32 %4731, 1
  %4733 = zext i32 %4732 to i64
  store i64 %4733, i64* %RCX, align 8, !tbaa !2428
  %4734 = icmp eq i32 %4731, -1
  %4735 = icmp eq i32 %4732, 0
  %4736 = or i1 %4734, %4735
  %4737 = zext i1 %4736 to i8
  store i8 %4737, i8* %18, align 1, !tbaa !2433
  %4738 = and i32 %4732, 255
  %4739 = tail call i32 @llvm.ctpop.i32(i32 %4738) #10
  %4740 = trunc i32 %4739 to i8
  %4741 = and i8 %4740, 1
  %4742 = xor i8 %4741, 1
  store i8 %4742, i8* %25, align 1, !tbaa !2447
  %4743 = xor i32 %4731, %4732
  %4744 = lshr i32 %4743, 4
  %4745 = trunc i32 %4744 to i8
  %4746 = and i8 %4745, 1
  store i8 %4746, i8* %31, align 1, !tbaa !2451
  %4747 = icmp eq i32 %4732, 0
  %4748 = zext i1 %4747 to i8
  store i8 %4748, i8* %34, align 1, !tbaa !2448
  %4749 = lshr i32 %4732, 31
  %4750 = trunc i32 %4749 to i8
  store i8 %4750, i8* %37, align 1, !tbaa !2449
  %4751 = lshr i32 %4731, 31
  %4752 = xor i32 %4749, %4751
  %4753 = add nuw nsw i32 %4752, %4749
  %4754 = icmp eq i32 %4753, 2
  %4755 = zext i1 %4754 to i8
  store i8 %4755, i8* %43, align 1, !tbaa !2450
  %4756 = sext i32 %4732 to i64
  store i64 %4756, i64* %RDX, align 8, !tbaa !2428
  %4757 = shl nsw i64 %4756, 3
  %4758 = add i64 %4757, %4727
  %4759 = add i64 %4705, 42
  store i64 %4759, i64* %PC, align 8
  %4760 = inttoptr i64 %4758 to double*
  store double %4723, double* %4760, align 8
  %4761 = load i64, i64* %RBP, align 8
  %4762 = add i64 %4761, -28
  %4763 = load i64, i64* %PC, align 8
  %4764 = add i64 %4763, 3
  store i64 %4764, i64* %PC, align 8
  %4765 = inttoptr i64 %4762 to i32*
  %4766 = load i32, i32* %4765, align 4
  %4767 = add i32 %4766, 2
  %4768 = zext i32 %4767 to i64
  store i64 %4768, i64* %RAX, align 8, !tbaa !2428
  %4769 = icmp ugt i32 %4766, -3
  %4770 = zext i1 %4769 to i8
  store i8 %4770, i8* %18, align 1, !tbaa !2433
  %4771 = and i32 %4767, 255
  %4772 = tail call i32 @llvm.ctpop.i32(i32 %4771) #10
  %4773 = trunc i32 %4772 to i8
  %4774 = and i8 %4773, 1
  %4775 = xor i8 %4774, 1
  store i8 %4775, i8* %25, align 1, !tbaa !2447
  %4776 = xor i32 %4766, %4767
  %4777 = lshr i32 %4776, 4
  %4778 = trunc i32 %4777 to i8
  %4779 = and i8 %4778, 1
  store i8 %4779, i8* %31, align 1, !tbaa !2451
  %4780 = icmp eq i32 %4767, 0
  %4781 = zext i1 %4780 to i8
  store i8 %4781, i8* %34, align 1, !tbaa !2448
  %4782 = lshr i32 %4767, 31
  %4783 = trunc i32 %4782 to i8
  store i8 %4783, i8* %37, align 1, !tbaa !2449
  %4784 = lshr i32 %4766, 31
  %4785 = xor i32 %4782, %4784
  %4786 = add nuw nsw i32 %4785, %4782
  %4787 = icmp eq i32 %4786, 2
  %4788 = zext i1 %4787 to i8
  store i8 %4788, i8* %43, align 1, !tbaa !2450
  %4789 = add i64 %4763, 9
  store i64 %4789, i64* %PC, align 8
  store i32 %4767, i32* %4765, align 4
  %4790 = load i64, i64* %PC, align 8
  %4791 = add i64 %4790, -822
  store i64 %4791, i64* %95, align 8, !tbaa !2428
  br label %block_403c90

block_403326:                                     ; preds = %block_403332, %block_403300
  %4792 = phi i64 [ %1185, %block_403332 ], [ %.pre, %block_403300 ]
  %4793 = load i64, i64* %RBP, align 8
  %4794 = add i64 %4793, -28
  %4795 = add i64 %4792, 3
  store i64 %4795, i64* %PC, align 8
  %4796 = inttoptr i64 %4794 to i32*
  %4797 = load i32, i32* %4796, align 4
  %4798 = zext i32 %4797 to i64
  store i64 %4798, i64* %RAX, align 8, !tbaa !2428
  %4799 = add i64 %4793, -8
  %4800 = add i64 %4792, 6
  store i64 %4800, i64* %PC, align 8
  %4801 = inttoptr i64 %4799 to i32*
  %4802 = load i32, i32* %4801, align 4
  %4803 = sub i32 %4797, %4802
  %4804 = icmp ult i32 %4797, %4802
  %4805 = zext i1 %4804 to i8
  store i8 %4805, i8* %18, align 1, !tbaa !2433
  %4806 = and i32 %4803, 255
  %4807 = tail call i32 @llvm.ctpop.i32(i32 %4806) #10
  %4808 = trunc i32 %4807 to i8
  %4809 = and i8 %4808, 1
  %4810 = xor i8 %4809, 1
  store i8 %4810, i8* %25, align 1, !tbaa !2447
  %4811 = xor i32 %4802, %4797
  %4812 = xor i32 %4811, %4803
  %4813 = lshr i32 %4812, 4
  %4814 = trunc i32 %4813 to i8
  %4815 = and i8 %4814, 1
  store i8 %4815, i8* %31, align 1, !tbaa !2451
  %4816 = icmp eq i32 %4803, 0
  %4817 = zext i1 %4816 to i8
  store i8 %4817, i8* %34, align 1, !tbaa !2448
  %4818 = lshr i32 %4803, 31
  %4819 = trunc i32 %4818 to i8
  store i8 %4819, i8* %37, align 1, !tbaa !2449
  %4820 = lshr i32 %4797, 31
  %4821 = lshr i32 %4802, 31
  %4822 = xor i32 %4821, %4820
  %4823 = xor i32 %4818, %4820
  %4824 = add nuw nsw i32 %4823, %4822
  %4825 = icmp eq i32 %4824, 2
  %4826 = zext i1 %4825 to i8
  store i8 %4826, i8* %43, align 1, !tbaa !2450
  %4827 = icmp ne i8 %4819, 0
  %4828 = xor i1 %4827, %4825
  %.v = select i1 %4828, i64 12, i64 599
  %4829 = add i64 %4792, %.v
  store i64 %4829, i64* %95, align 8, !tbaa !2428
  br i1 %4828, label %block_403332, label %block_40357d
}

; Function Attrs: noinline
define %struct.Memory* @sub_402480_cftbsub(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_402480:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %8 = load i64, i64* %7, align 8, !tbaa !2428
  %9 = add i64 %8, -8
  %10 = inttoptr i64 %9 to i64*
  store i64 %5, i64* %10, align 8
  %11 = load i64, i64* %PC, align 8
  store i64 %9, i64* %RBP, align 8, !tbaa !2428
  %12 = add i64 %8, -120
  store i64 %12, i64* %RSP, align 8, !tbaa !2428
  %13 = icmp ult i64 %9, 112
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1, !tbaa !2433
  %16 = trunc i64 %12 to i32
  %17 = and i32 %16, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17) #10
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1, !tbaa !2447
  %23 = xor i64 %9, 16
  %24 = xor i64 %23, %12
  %25 = lshr i64 %24, 4
  %26 = trunc i64 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1, !tbaa !2451
  %29 = icmp eq i64 %12, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1, !tbaa !2448
  %32 = lshr i64 %12, 63
  %33 = trunc i64 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1, !tbaa !2449
  %35 = lshr i64 %9, 63
  %36 = xor i64 %32, %35
  %37 = add nuw nsw i64 %36, %35
  %38 = icmp eq i64 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1, !tbaa !2450
  %41 = add i64 %8, -12
  %42 = load i32, i32* %EDI, align 4
  %43 = add i64 %11, 10
  store i64 %43, i64* %PC, align 8
  %44 = inttoptr i64 %41 to i32*
  store i32 %42, i32* %44, align 4
  %45 = load i64, i64* %RBP, align 8
  %46 = add i64 %45, -16
  %47 = load i64, i64* %RSI, align 8
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 4
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %46 to i64*
  store i64 %47, i64* %50, align 8
  %51 = load i64, i64* %RBP, align 8
  %52 = add i64 %51, -24
  %53 = load i64, i64* %RDX, align 8
  %54 = load i64, i64* %PC, align 8
  %55 = add i64 %54, 4
  store i64 %55, i64* %PC, align 8
  %56 = inttoptr i64 %52 to i64*
  store i64 %53, i64* %56, align 8
  %57 = load i64, i64* %RBP, align 8
  %58 = add i64 %57, -44
  %59 = load i64, i64* %PC, align 8
  %60 = add i64 %59, 7
  store i64 %60, i64* %PC, align 8
  %61 = inttoptr i64 %58 to i32*
  store i32 2, i32* %61, align 4
  %62 = load i64, i64* %RBP, align 8
  %63 = add i64 %62, -4
  %64 = load i64, i64* %PC, align 8
  %65 = add i64 %64, 4
  store i64 %65, i64* %PC, align 8
  %66 = inttoptr i64 %63 to i32*
  %67 = load i32, i32* %66, align 4
  %68 = add i32 %67, -8
  %69 = icmp ult i32 %67, 8
  %70 = zext i1 %69 to i8
  store i8 %70, i8* %15, align 1, !tbaa !2433
  %71 = and i32 %68, 255
  %72 = tail call i32 @llvm.ctpop.i32(i32 %71) #10
  %73 = trunc i32 %72 to i8
  %74 = and i8 %73, 1
  %75 = xor i8 %74, 1
  store i8 %75, i8* %22, align 1, !tbaa !2447
  %76 = xor i32 %67, %68
  %77 = lshr i32 %76, 4
  %78 = trunc i32 %77 to i8
  %79 = and i8 %78, 1
  store i8 %79, i8* %28, align 1, !tbaa !2451
  %80 = icmp eq i32 %68, 0
  %81 = zext i1 %80 to i8
  store i8 %81, i8* %31, align 1, !tbaa !2448
  %82 = lshr i32 %68, 31
  %83 = trunc i32 %82 to i8
  store i8 %83, i8* %34, align 1, !tbaa !2449
  %84 = lshr i32 %67, 31
  %85 = xor i32 %82, %84
  %86 = add nuw nsw i32 %85, %84
  %87 = icmp eq i32 %86, 2
  %88 = zext i1 %87 to i8
  store i8 %88, i8* %40, align 1, !tbaa !2450
  %89 = icmp ne i8 %83, 0
  %90 = xor i1 %89, %87
  %91 = or i1 %80, %90
  %92 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %.v = select i1 %91, i64 86, i64 10
  %93 = add i64 %64, %.v
  store i64 %93, i64* %92, align 8, !tbaa !2428
  br i1 %91, label %block_4024f0, label %block_4024a4

block_402757:                                     ; preds = %block_4024f0, %block_402763
  %94 = phi i64 [ %596, %block_402763 ], [ %.pre3, %block_4024f0 ]
  %95 = load i64, i64* %RBP, align 8
  %96 = add i64 %95, -28
  %97 = add i64 %94, 3
  store i64 %97, i64* %PC, align 8
  %98 = inttoptr i64 %96 to i32*
  %99 = load i32, i32* %98, align 4
  %100 = zext i32 %99 to i64
  store i64 %100, i64* %RAX, align 8, !tbaa !2428
  %101 = add i64 %95, -44
  %102 = add i64 %94, 6
  store i64 %102, i64* %PC, align 8
  %103 = inttoptr i64 %101 to i32*
  %104 = load i32, i32* %103, align 4
  %105 = sub i32 %99, %104
  %106 = icmp ult i32 %99, %104
  %107 = zext i1 %106 to i8
  store i8 %107, i8* %15, align 1, !tbaa !2433
  %108 = and i32 %105, 255
  %109 = tail call i32 @llvm.ctpop.i32(i32 %108) #10
  %110 = trunc i32 %109 to i8
  %111 = and i8 %110, 1
  %112 = xor i8 %111, 1
  store i8 %112, i8* %22, align 1, !tbaa !2447
  %113 = xor i32 %104, %99
  %114 = xor i32 %113, %105
  %115 = lshr i32 %114, 4
  %116 = trunc i32 %115 to i8
  %117 = and i8 %116, 1
  store i8 %117, i8* %28, align 1, !tbaa !2451
  %118 = icmp eq i32 %105, 0
  %119 = zext i1 %118 to i8
  store i8 %119, i8* %31, align 1, !tbaa !2448
  %120 = lshr i32 %105, 31
  %121 = trunc i32 %120 to i8
  store i8 %121, i8* %34, align 1, !tbaa !2449
  %122 = lshr i32 %99, 31
  %123 = lshr i32 %104, 31
  %124 = xor i32 %123, %122
  %125 = xor i32 %120, %122
  %126 = add nuw nsw i32 %125, %124
  %127 = icmp eq i32 %126, 2
  %128 = zext i1 %127 to i8
  store i8 %128, i8* %40, align 1, !tbaa !2450
  %129 = icmp ne i8 %121, 0
  %130 = xor i1 %129, %127
  %.v8 = select i1 %130, i64 12, i64 269
  %131 = add i64 %94, %.v8
  store i64 %131, i64* %92, align 8, !tbaa !2428
  br i1 %130, label %block_402763, label %block_402864

block_4024bb:                                     ; preds = %block_4024a4, %block_4024ca
  %132 = phi i64 [ %.pre, %block_4024a4 ], [ %641, %block_4024ca ]
  %MEMORY.1 = phi %struct.Memory* [ %728, %block_4024a4 ], [ %617, %block_4024ca ]
  %133 = load i64, i64* %RBP, align 8
  %134 = add i64 %133, -44
  %135 = add i64 %132, 3
  store i64 %135, i64* %PC, align 8
  %136 = inttoptr i64 %134 to i32*
  %137 = load i32, i32* %136, align 4
  %138 = shl i32 %137, 2
  %139 = zext i32 %138 to i64
  store i64 %139, i64* %RAX, align 8, !tbaa !2428
  %140 = lshr i32 %137, 30
  %141 = trunc i32 %140 to i8
  %142 = and i8 %141, 1
  store i8 %142, i8* %15, align 1, !tbaa !2432
  %143 = and i32 %138, 252
  %144 = tail call i32 @llvm.ctpop.i32(i32 %143) #10
  %145 = trunc i32 %144 to i8
  %146 = and i8 %145, 1
  %147 = xor i8 %146, 1
  store i8 %147, i8* %22, align 1, !tbaa !2432
  store i8 0, i8* %28, align 1, !tbaa !2432
  %148 = icmp eq i32 %138, 0
  %149 = zext i1 %148 to i8
  store i8 %149, i8* %31, align 1, !tbaa !2432
  %150 = lshr i32 %137, 29
  %151 = and i32 %150, 1
  %152 = trunc i32 %151 to i8
  store i8 %152, i8* %34, align 1, !tbaa !2432
  store i8 0, i8* %40, align 1, !tbaa !2432
  %153 = add i64 %133, -4
  %154 = add i64 %132, 9
  store i64 %154, i64* %PC, align 8
  %155 = inttoptr i64 %153 to i32*
  %156 = load i32, i32* %155, align 4
  %157 = sub i32 %138, %156
  %158 = icmp ult i32 %138, %156
  %159 = zext i1 %158 to i8
  store i8 %159, i8* %15, align 1, !tbaa !2433
  %160 = and i32 %157, 255
  %161 = tail call i32 @llvm.ctpop.i32(i32 %160) #10
  %162 = trunc i32 %161 to i8
  %163 = and i8 %162, 1
  %164 = xor i8 %163, 1
  store i8 %164, i8* %22, align 1, !tbaa !2447
  %165 = xor i32 %156, %138
  %166 = xor i32 %165, %157
  %167 = lshr i32 %166, 4
  %168 = trunc i32 %167 to i8
  %169 = and i8 %168, 1
  store i8 %169, i8* %28, align 1, !tbaa !2451
  %170 = icmp eq i32 %157, 0
  %171 = zext i1 %170 to i8
  store i8 %171, i8* %31, align 1, !tbaa !2448
  %172 = lshr i32 %157, 31
  %173 = trunc i32 %172 to i8
  store i8 %173, i8* %34, align 1, !tbaa !2449
  %174 = lshr i32 %156, 31
  %175 = xor i32 %174, %151
  %176 = xor i32 %172, %151
  %177 = add nuw nsw i32 %176, %175
  %178 = icmp eq i32 %177, 2
  %179 = zext i1 %178 to i8
  store i8 %179, i8* %40, align 1, !tbaa !2450
  %180 = icmp ne i8 %173, 0
  %181 = xor i1 %180, %178
  %.v5 = select i1 %181, i64 15, i64 48
  %182 = add i64 %132, %.v5
  store i64 %182, i64* %92, align 8, !tbaa !2428
  br i1 %181, label %block_4024ca, label %block_4024eb

block_402763:                                     ; preds = %block_402757
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %183 = add i64 %131, 13
  store i64 %183, i64* %PC, align 8
  %184 = load i32, i32* %98, align 4
  %185 = zext i32 %184 to i64
  store i64 %185, i64* %RCX, align 8, !tbaa !2428
  %186 = add i64 %131, 16
  store i64 %186, i64* %PC, align 8
  %187 = load i32, i32* %103, align 4
  %188 = add i32 %187, %184
  %189 = zext i32 %188 to i64
  store i64 %189, i64* %RCX, align 8, !tbaa !2428
  %190 = icmp ult i32 %188, %184
  %191 = icmp ult i32 %188, %187
  %192 = or i1 %190, %191
  %193 = zext i1 %192 to i8
  store i8 %193, i8* %15, align 1, !tbaa !2433
  %194 = and i32 %188, 255
  %195 = tail call i32 @llvm.ctpop.i32(i32 %194) #10
  %196 = trunc i32 %195 to i8
  %197 = and i8 %196, 1
  %198 = xor i8 %197, 1
  store i8 %198, i8* %22, align 1, !tbaa !2447
  %199 = xor i32 %187, %184
  %200 = xor i32 %199, %188
  %201 = lshr i32 %200, 4
  %202 = trunc i32 %201 to i8
  %203 = and i8 %202, 1
  store i8 %203, i8* %28, align 1, !tbaa !2451
  %204 = icmp eq i32 %188, 0
  %205 = zext i1 %204 to i8
  store i8 %205, i8* %31, align 1, !tbaa !2448
  %206 = lshr i32 %188, 31
  %207 = trunc i32 %206 to i8
  store i8 %207, i8* %34, align 1, !tbaa !2449
  %208 = lshr i32 %184, 31
  %209 = lshr i32 %187, 31
  %210 = xor i32 %206, %208
  %211 = xor i32 %206, %209
  %212 = add nuw nsw i32 %210, %211
  %213 = icmp eq i32 %212, 2
  %214 = zext i1 %213 to i8
  store i8 %214, i8* %40, align 1, !tbaa !2450
  %215 = add i64 %95, -32
  %216 = add i64 %131, 19
  store i64 %216, i64* %PC, align 8
  %217 = inttoptr i64 %215 to i32*
  store i32 %188, i32* %217, align 4
  %218 = load i64, i64* %RBP, align 8
  %219 = add i64 %218, -16
  %220 = load i64, i64* %PC, align 8
  %221 = add i64 %220, 4
  store i64 %221, i64* %PC, align 8
  %222 = inttoptr i64 %219 to i64*
  %223 = load i64, i64* %222, align 8
  store i64 %223, i64* %RDX, align 8, !tbaa !2428
  %224 = add i64 %218, -28
  %225 = add i64 %220, 8
  store i64 %225, i64* %PC, align 8
  %226 = inttoptr i64 %224 to i32*
  %227 = load i32, i32* %226, align 4
  %228 = sext i32 %227 to i64
  store i64 %228, i64* %RSI, align 8, !tbaa !2428
  %229 = shl nsw i64 %228, 3
  %230 = add i64 %229, %223
  %231 = add i64 %220, 13
  store i64 %231, i64* %PC, align 8
  %232 = inttoptr i64 %230 to double*
  %233 = load double, double* %232, align 8
  store double %233, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %234 = add i64 %220, 17
  store i64 %234, i64* %PC, align 8
  %235 = load i64, i64* %222, align 8
  store i64 %235, i64* %RDX, align 8, !tbaa !2428
  %236 = add i64 %218, -32
  %237 = add i64 %220, 21
  store i64 %237, i64* %PC, align 8
  %238 = inttoptr i64 %236 to i32*
  %239 = load i32, i32* %238, align 4
  %240 = sext i32 %239 to i64
  store i64 %240, i64* %RSI, align 8, !tbaa !2428
  %241 = shl nsw i64 %240, 3
  %242 = add i64 %241, %235
  %243 = add i64 %220, 26
  store i64 %243, i64* %PC, align 8
  %244 = inttoptr i64 %242 to double*
  %245 = load double, double* %244, align 8
  %246 = fsub double %233, %245
  store double %246, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %247 = add i64 %218, -56
  %248 = add i64 %220, 31
  store i64 %248, i64* %PC, align 8
  %249 = inttoptr i64 %247 to double*
  store double %246, double* %249, align 8
  %250 = load i64, i64* %RBP, align 8
  %251 = add i64 %250, -16
  %252 = load i64, i64* %PC, align 8
  %253 = add i64 %252, 4
  store i64 %253, i64* %PC, align 8
  %254 = inttoptr i64 %251 to i64*
  %255 = load i64, i64* %254, align 8
  store i64 %255, i64* %RDX, align 8, !tbaa !2428
  %256 = add i64 %250, -28
  %257 = add i64 %252, 7
  store i64 %257, i64* %PC, align 8
  %258 = inttoptr i64 %256 to i32*
  %259 = load i32, i32* %258, align 4
  %260 = add i32 %259, 1
  %261 = zext i32 %260 to i64
  store i64 %261, i64* %RCX, align 8, !tbaa !2428
  %262 = icmp eq i32 %259, -1
  %263 = icmp eq i32 %260, 0
  %264 = or i1 %262, %263
  %265 = zext i1 %264 to i8
  store i8 %265, i8* %15, align 1, !tbaa !2433
  %266 = and i32 %260, 255
  %267 = tail call i32 @llvm.ctpop.i32(i32 %266) #10
  %268 = trunc i32 %267 to i8
  %269 = and i8 %268, 1
  %270 = xor i8 %269, 1
  store i8 %270, i8* %22, align 1, !tbaa !2447
  %271 = xor i32 %259, %260
  %272 = lshr i32 %271, 4
  %273 = trunc i32 %272 to i8
  %274 = and i8 %273, 1
  store i8 %274, i8* %28, align 1, !tbaa !2451
  %275 = icmp eq i32 %260, 0
  %276 = zext i1 %275 to i8
  store i8 %276, i8* %31, align 1, !tbaa !2448
  %277 = lshr i32 %260, 31
  %278 = trunc i32 %277 to i8
  store i8 %278, i8* %34, align 1, !tbaa !2449
  %279 = lshr i32 %259, 31
  %280 = xor i32 %277, %279
  %281 = add nuw nsw i32 %280, %277
  %282 = icmp eq i32 %281, 2
  %283 = zext i1 %282 to i8
  store i8 %283, i8* %40, align 1, !tbaa !2450
  %284 = sext i32 %260 to i64
  store i64 %284, i64* %RSI, align 8, !tbaa !2428
  %285 = shl nsw i64 %284, 3
  %286 = add i64 %285, %255
  %287 = add i64 %252, 18
  store i64 %287, i64* %PC, align 8
  %288 = inttoptr i64 %286 to i64*
  %289 = load i64, i64* %288, align 8
  %290 = load i64, i64* %RAX, align 8
  %291 = xor i64 %290, %289
  store i64 %291, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %15, align 1, !tbaa !2433
  %292 = trunc i64 %291 to i32
  %293 = and i32 %292, 255
  %294 = tail call i32 @llvm.ctpop.i32(i32 %293) #10
  %295 = trunc i32 %294 to i8
  %296 = and i8 %295, 1
  %297 = xor i8 %296, 1
  store i8 %297, i8* %22, align 1, !tbaa !2447
  %298 = icmp eq i64 %291, 0
  %299 = zext i1 %298 to i8
  store i8 %299, i8* %31, align 1, !tbaa !2448
  %300 = lshr i64 %291, 63
  %301 = trunc i64 %300 to i8
  store i8 %301, i8* %34, align 1, !tbaa !2449
  store i8 0, i8* %40, align 1, !tbaa !2450
  store i8 0, i8* %28, align 1, !tbaa !2451
  store i64 %291, i64* %1705, align 1, !tbaa !2428
  store i64 0, i64* %1703, align 1, !tbaa !2428
  %302 = add i64 %252, 35
  store i64 %302, i64* %PC, align 8
  %303 = load i64, i64* %254, align 8
  store i64 %303, i64* %RDX, align 8, !tbaa !2428
  %304 = add i64 %250, -32
  %305 = add i64 %252, 38
  store i64 %305, i64* %PC, align 8
  %306 = inttoptr i64 %304 to i32*
  %307 = load i32, i32* %306, align 4
  %308 = add i32 %307, 1
  %309 = zext i32 %308 to i64
  store i64 %309, i64* %RCX, align 8, !tbaa !2428
  %310 = icmp eq i32 %307, -1
  %311 = icmp eq i32 %308, 0
  %312 = or i1 %310, %311
  %313 = zext i1 %312 to i8
  store i8 %313, i8* %15, align 1, !tbaa !2433
  %314 = and i32 %308, 255
  %315 = tail call i32 @llvm.ctpop.i32(i32 %314) #10
  %316 = trunc i32 %315 to i8
  %317 = and i8 %316, 1
  %318 = xor i8 %317, 1
  store i8 %318, i8* %22, align 1, !tbaa !2447
  %319 = xor i32 %307, %308
  %320 = lshr i32 %319, 4
  %321 = trunc i32 %320 to i8
  %322 = and i8 %321, 1
  store i8 %322, i8* %28, align 1, !tbaa !2451
  %323 = icmp eq i32 %308, 0
  %324 = zext i1 %323 to i8
  store i8 %324, i8* %31, align 1, !tbaa !2448
  %325 = lshr i32 %308, 31
  %326 = trunc i32 %325 to i8
  store i8 %326, i8* %34, align 1, !tbaa !2449
  %327 = lshr i32 %307, 31
  %328 = xor i32 %325, %327
  %329 = add nuw nsw i32 %328, %325
  %330 = icmp eq i32 %329, 2
  %331 = zext i1 %330 to i8
  store i8 %331, i8* %40, align 1, !tbaa !2450
  %332 = sext i32 %308 to i64
  store i64 %332, i64* %RSI, align 8, !tbaa !2428
  %333 = shl nsw i64 %332, 3
  %334 = add i64 %333, %303
  %335 = add i64 %252, 49
  store i64 %335, i64* %PC, align 8
  %336 = bitcast i64 %291 to double
  %337 = inttoptr i64 %334 to double*
  %338 = load double, double* %337, align 8
  %339 = fadd double %336, %338
  store double %339, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %340 = load i64, i64* %RBP, align 8
  %341 = add i64 %340, -64
  %342 = add i64 %252, 54
  store i64 %342, i64* %PC, align 8
  %343 = inttoptr i64 %341 to double*
  store double %339, double* %343, align 8
  %344 = load i64, i64* %RBP, align 8
  %345 = add i64 %344, -16
  %346 = load i64, i64* %PC, align 8
  %347 = add i64 %346, 4
  store i64 %347, i64* %PC, align 8
  %348 = inttoptr i64 %345 to i64*
  %349 = load i64, i64* %348, align 8
  store i64 %349, i64* %RDX, align 8, !tbaa !2428
  %350 = add i64 %344, -32
  %351 = add i64 %346, 8
  store i64 %351, i64* %PC, align 8
  %352 = inttoptr i64 %350 to i32*
  %353 = load i32, i32* %352, align 4
  %354 = sext i32 %353 to i64
  store i64 %354, i64* %RSI, align 8, !tbaa !2428
  %355 = shl nsw i64 %354, 3
  %356 = add i64 %355, %349
  %357 = add i64 %346, 13
  store i64 %357, i64* %PC, align 8
  %358 = inttoptr i64 %356 to double*
  %359 = load double, double* %358, align 8
  store double %359, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %360 = add i64 %346, 17
  store i64 %360, i64* %PC, align 8
  %361 = load i64, i64* %348, align 8
  store i64 %361, i64* %RDX, align 8, !tbaa !2428
  %362 = add i64 %344, -28
  %363 = add i64 %346, 21
  store i64 %363, i64* %PC, align 8
  %364 = inttoptr i64 %362 to i32*
  %365 = load i32, i32* %364, align 4
  %366 = sext i32 %365 to i64
  store i64 %366, i64* %RSI, align 8, !tbaa !2428
  %367 = shl nsw i64 %366, 3
  %368 = add i64 %367, %361
  %369 = add i64 %346, 26
  store i64 %369, i64* %PC, align 8
  %370 = inttoptr i64 %368 to double*
  %371 = load double, double* %370, align 8
  %372 = fadd double %359, %371
  store double %372, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %373 = add i64 %346, 31
  store i64 %373, i64* %PC, align 8
  store double %372, double* %370, align 8
  %374 = load i64, i64* %RBP, align 8
  %375 = add i64 %374, -16
  %376 = load i64, i64* %PC, align 8
  %377 = add i64 %376, 4
  store i64 %377, i64* %PC, align 8
  %378 = inttoptr i64 %375 to i64*
  %379 = load i64, i64* %378, align 8
  store i64 %379, i64* %RDX, align 8, !tbaa !2428
  %380 = add i64 %374, -28
  %381 = add i64 %376, 7
  store i64 %381, i64* %PC, align 8
  %382 = inttoptr i64 %380 to i32*
  %383 = load i32, i32* %382, align 4
  %384 = add i32 %383, 1
  %385 = zext i32 %384 to i64
  store i64 %385, i64* %RCX, align 8, !tbaa !2428
  %386 = icmp eq i32 %383, -1
  %387 = icmp eq i32 %384, 0
  %388 = or i1 %386, %387
  %389 = zext i1 %388 to i8
  store i8 %389, i8* %15, align 1, !tbaa !2433
  %390 = and i32 %384, 255
  %391 = tail call i32 @llvm.ctpop.i32(i32 %390) #10
  %392 = trunc i32 %391 to i8
  %393 = and i8 %392, 1
  %394 = xor i8 %393, 1
  store i8 %394, i8* %22, align 1, !tbaa !2447
  %395 = xor i32 %383, %384
  %396 = lshr i32 %395, 4
  %397 = trunc i32 %396 to i8
  %398 = and i8 %397, 1
  store i8 %398, i8* %28, align 1, !tbaa !2451
  %399 = icmp eq i32 %384, 0
  %400 = zext i1 %399 to i8
  store i8 %400, i8* %31, align 1, !tbaa !2448
  %401 = lshr i32 %384, 31
  %402 = trunc i32 %401 to i8
  store i8 %402, i8* %34, align 1, !tbaa !2449
  %403 = lshr i32 %383, 31
  %404 = xor i32 %401, %403
  %405 = add nuw nsw i32 %404, %401
  %406 = icmp eq i32 %405, 2
  %407 = zext i1 %406 to i8
  store i8 %407, i8* %40, align 1, !tbaa !2450
  %408 = sext i32 %384 to i64
  store i64 %408, i64* %RSI, align 8, !tbaa !2428
  %409 = shl nsw i64 %408, 3
  %410 = add i64 %409, %379
  %411 = add i64 %376, 18
  store i64 %411, i64* %PC, align 8
  %412 = inttoptr i64 %410 to i64*
  %413 = load i64, i64* %412, align 8
  %414 = load i64, i64* %RAX, align 8
  %415 = xor i64 %414, %413
  store i64 %415, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %15, align 1, !tbaa !2433
  %416 = trunc i64 %415 to i32
  %417 = and i32 %416, 255
  %418 = tail call i32 @llvm.ctpop.i32(i32 %417) #10
  %419 = trunc i32 %418 to i8
  %420 = and i8 %419, 1
  %421 = xor i8 %420, 1
  store i8 %421, i8* %22, align 1, !tbaa !2447
  %422 = icmp eq i64 %415, 0
  %423 = zext i1 %422 to i8
  store i8 %423, i8* %31, align 1, !tbaa !2448
  %424 = lshr i64 %415, 63
  %425 = trunc i64 %424 to i8
  store i8 %425, i8* %34, align 1, !tbaa !2449
  store i8 0, i8* %40, align 1, !tbaa !2450
  store i8 0, i8* %28, align 1, !tbaa !2451
  store i64 %415, i64* %1705, align 1, !tbaa !2428
  store i64 0, i64* %1703, align 1, !tbaa !2428
  %426 = add i64 %376, 35
  store i64 %426, i64* %PC, align 8
  %427 = load i64, i64* %378, align 8
  store i64 %427, i64* %RAX, align 8, !tbaa !2428
  %428 = add i64 %374, -32
  %429 = add i64 %376, 38
  store i64 %429, i64* %PC, align 8
  %430 = inttoptr i64 %428 to i32*
  %431 = load i32, i32* %430, align 4
  %432 = add i32 %431, 1
  %433 = zext i32 %432 to i64
  store i64 %433, i64* %RCX, align 8, !tbaa !2428
  %434 = icmp eq i32 %431, -1
  %435 = icmp eq i32 %432, 0
  %436 = or i1 %434, %435
  %437 = zext i1 %436 to i8
  store i8 %437, i8* %15, align 1, !tbaa !2433
  %438 = and i32 %432, 255
  %439 = tail call i32 @llvm.ctpop.i32(i32 %438) #10
  %440 = trunc i32 %439 to i8
  %441 = and i8 %440, 1
  %442 = xor i8 %441, 1
  store i8 %442, i8* %22, align 1, !tbaa !2447
  %443 = xor i32 %431, %432
  %444 = lshr i32 %443, 4
  %445 = trunc i32 %444 to i8
  %446 = and i8 %445, 1
  store i8 %446, i8* %28, align 1, !tbaa !2451
  %447 = icmp eq i32 %432, 0
  %448 = zext i1 %447 to i8
  store i8 %448, i8* %31, align 1, !tbaa !2448
  %449 = lshr i32 %432, 31
  %450 = trunc i32 %449 to i8
  store i8 %450, i8* %34, align 1, !tbaa !2449
  %451 = lshr i32 %431, 31
  %452 = xor i32 %449, %451
  %453 = add nuw nsw i32 %452, %449
  %454 = icmp eq i32 %453, 2
  %455 = zext i1 %454 to i8
  store i8 %455, i8* %40, align 1, !tbaa !2450
  %456 = sext i32 %432 to i64
  store i64 %456, i64* %RDX, align 8, !tbaa !2428
  %457 = shl nsw i64 %456, 3
  %458 = add i64 %457, %427
  %459 = add i64 %376, 49
  store i64 %459, i64* %PC, align 8
  %460 = bitcast i64 %415 to double
  %461 = inttoptr i64 %458 to double*
  %462 = load double, double* %461, align 8
  %463 = fsub double %460, %462
  store double %463, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %464 = load i64, i64* %RBP, align 8
  %465 = add i64 %464, -16
  %466 = add i64 %376, 53
  store i64 %466, i64* %PC, align 8
  %467 = inttoptr i64 %465 to i64*
  %468 = load i64, i64* %467, align 8
  store i64 %468, i64* %RAX, align 8, !tbaa !2428
  %469 = add i64 %464, -28
  %470 = add i64 %376, 56
  store i64 %470, i64* %PC, align 8
  %471 = inttoptr i64 %469 to i32*
  %472 = load i32, i32* %471, align 4
  %473 = add i32 %472, 1
  %474 = zext i32 %473 to i64
  store i64 %474, i64* %RCX, align 8, !tbaa !2428
  %475 = icmp eq i32 %472, -1
  %476 = icmp eq i32 %473, 0
  %477 = or i1 %475, %476
  %478 = zext i1 %477 to i8
  store i8 %478, i8* %15, align 1, !tbaa !2433
  %479 = and i32 %473, 255
  %480 = tail call i32 @llvm.ctpop.i32(i32 %479) #10
  %481 = trunc i32 %480 to i8
  %482 = and i8 %481, 1
  %483 = xor i8 %482, 1
  store i8 %483, i8* %22, align 1, !tbaa !2447
  %484 = xor i32 %472, %473
  %485 = lshr i32 %484, 4
  %486 = trunc i32 %485 to i8
  %487 = and i8 %486, 1
  store i8 %487, i8* %28, align 1, !tbaa !2451
  %488 = icmp eq i32 %473, 0
  %489 = zext i1 %488 to i8
  store i8 %489, i8* %31, align 1, !tbaa !2448
  %490 = lshr i32 %473, 31
  %491 = trunc i32 %490 to i8
  store i8 %491, i8* %34, align 1, !tbaa !2449
  %492 = lshr i32 %472, 31
  %493 = xor i32 %490, %492
  %494 = add nuw nsw i32 %493, %490
  %495 = icmp eq i32 %494, 2
  %496 = zext i1 %495 to i8
  store i8 %496, i8* %40, align 1, !tbaa !2450
  %497 = sext i32 %473 to i64
  store i64 %497, i64* %RDX, align 8, !tbaa !2428
  %498 = shl nsw i64 %497, 3
  %499 = add i64 %498, %468
  %500 = add i64 %376, 67
  store i64 %500, i64* %PC, align 8
  %501 = inttoptr i64 %499 to double*
  store double %463, double* %501, align 8
  %502 = load i64, i64* %RBP, align 8
  %503 = add i64 %502, -56
  %504 = load i64, i64* %PC, align 8
  %505 = add i64 %504, 5
  store i64 %505, i64* %PC, align 8
  %506 = inttoptr i64 %503 to i64*
  %507 = load i64, i64* %506, align 8
  %508 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %507, i64* %508, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %509 = add i64 %502, -16
  %510 = add i64 %504, 9
  store i64 %510, i64* %PC, align 8
  %511 = inttoptr i64 %509 to i64*
  %512 = load i64, i64* %511, align 8
  store i64 %512, i64* %RAX, align 8, !tbaa !2428
  %513 = add i64 %502, -32
  %514 = add i64 %504, 13
  store i64 %514, i64* %PC, align 8
  %515 = inttoptr i64 %513 to i32*
  %516 = load i32, i32* %515, align 4
  %517 = sext i32 %516 to i64
  store i64 %517, i64* %RDX, align 8, !tbaa !2428
  %518 = shl nsw i64 %517, 3
  %519 = add i64 %518, %512
  %520 = add i64 %504, 18
  store i64 %520, i64* %PC, align 8
  %521 = inttoptr i64 %519 to i64*
  store i64 %507, i64* %521, align 8
  %522 = load i64, i64* %RBP, align 8
  %523 = add i64 %522, -64
  %524 = load i64, i64* %PC, align 8
  %525 = add i64 %524, 5
  store i64 %525, i64* %PC, align 8
  %526 = inttoptr i64 %523 to i64*
  %527 = load i64, i64* %526, align 8
  %528 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %527, i64* %528, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %529 = add i64 %522, -16
  %530 = add i64 %524, 9
  store i64 %530, i64* %PC, align 8
  %531 = inttoptr i64 %529 to i64*
  %532 = load i64, i64* %531, align 8
  store i64 %532, i64* %RAX, align 8, !tbaa !2428
  %533 = add i64 %522, -32
  %534 = add i64 %524, 12
  store i64 %534, i64* %PC, align 8
  %535 = inttoptr i64 %533 to i32*
  %536 = load i32, i32* %535, align 4
  %537 = add i32 %536, 1
  %538 = zext i32 %537 to i64
  store i64 %538, i64* %RCX, align 8, !tbaa !2428
  %539 = icmp eq i32 %536, -1
  %540 = icmp eq i32 %537, 0
  %541 = or i1 %539, %540
  %542 = zext i1 %541 to i8
  store i8 %542, i8* %15, align 1, !tbaa !2433
  %543 = and i32 %537, 255
  %544 = tail call i32 @llvm.ctpop.i32(i32 %543) #10
  %545 = trunc i32 %544 to i8
  %546 = and i8 %545, 1
  %547 = xor i8 %546, 1
  store i8 %547, i8* %22, align 1, !tbaa !2447
  %548 = xor i32 %536, %537
  %549 = lshr i32 %548, 4
  %550 = trunc i32 %549 to i8
  %551 = and i8 %550, 1
  store i8 %551, i8* %28, align 1, !tbaa !2451
  %552 = icmp eq i32 %537, 0
  %553 = zext i1 %552 to i8
  store i8 %553, i8* %31, align 1, !tbaa !2448
  %554 = lshr i32 %537, 31
  %555 = trunc i32 %554 to i8
  store i8 %555, i8* %34, align 1, !tbaa !2449
  %556 = lshr i32 %536, 31
  %557 = xor i32 %554, %556
  %558 = add nuw nsw i32 %557, %554
  %559 = icmp eq i32 %558, 2
  %560 = zext i1 %559 to i8
  store i8 %560, i8* %40, align 1, !tbaa !2450
  %561 = sext i32 %537 to i64
  store i64 %561, i64* %RDX, align 8, !tbaa !2428
  %562 = shl nsw i64 %561, 3
  %563 = add i64 %562, %532
  %564 = add i64 %524, 23
  store i64 %564, i64* %PC, align 8
  %565 = inttoptr i64 %563 to i64*
  store i64 %527, i64* %565, align 8
  %566 = load i64, i64* %RBP, align 8
  %567 = add i64 %566, -28
  %568 = load i64, i64* %PC, align 8
  %569 = add i64 %568, 3
  store i64 %569, i64* %PC, align 8
  %570 = inttoptr i64 %567 to i32*
  %571 = load i32, i32* %570, align 4
  %572 = add i32 %571, 2
  %573 = zext i32 %572 to i64
  store i64 %573, i64* %RAX, align 8, !tbaa !2428
  %574 = icmp ugt i32 %571, -3
  %575 = zext i1 %574 to i8
  store i8 %575, i8* %15, align 1, !tbaa !2433
  %576 = and i32 %572, 255
  %577 = tail call i32 @llvm.ctpop.i32(i32 %576) #10
  %578 = trunc i32 %577 to i8
  %579 = and i8 %578, 1
  %580 = xor i8 %579, 1
  store i8 %580, i8* %22, align 1, !tbaa !2447
  %581 = xor i32 %571, %572
  %582 = lshr i32 %581, 4
  %583 = trunc i32 %582 to i8
  %584 = and i8 %583, 1
  store i8 %584, i8* %28, align 1, !tbaa !2451
  %585 = icmp eq i32 %572, 0
  %586 = zext i1 %585 to i8
  store i8 %586, i8* %31, align 1, !tbaa !2448
  %587 = lshr i32 %572, 31
  %588 = trunc i32 %587 to i8
  store i8 %588, i8* %34, align 1, !tbaa !2449
  %589 = lshr i32 %571, 31
  %590 = xor i32 %587, %589
  %591 = add nuw nsw i32 %590, %587
  %592 = icmp eq i32 %591, 2
  %593 = zext i1 %592 to i8
  store i8 %593, i8* %40, align 1, !tbaa !2450
  %594 = add i64 %568, 9
  store i64 %594, i64* %PC, align 8
  store i32 %572, i32* %570, align 4
  %595 = load i64, i64* %PC, align 8
  %596 = add i64 %595, -264
  store i64 %596, i64* %92, align 8, !tbaa !2428
  br label %block_402757

block_40274b:                                     ; preds = %block_402506
  %597 = add i64 %711, 286
  br label %block_402869

block_4024ca:                                     ; preds = %block_4024bb
  %598 = add i64 %182, 3
  store i64 %598, i64* %PC, align 8
  %599 = load i32, i32* %155, align 4
  %600 = zext i32 %599 to i64
  store i64 %600, i64* %RDI, align 8, !tbaa !2428
  %601 = add i64 %182, 6
  store i64 %601, i64* %PC, align 8
  %602 = load i32, i32* %136, align 4
  %603 = zext i32 %602 to i64
  store i64 %603, i64* %RSI, align 8, !tbaa !2428
  %604 = add i64 %133, -16
  %605 = add i64 %182, 10
  store i64 %605, i64* %PC, align 8
  %606 = inttoptr i64 %604 to i64*
  %607 = load i64, i64* %606, align 8
  store i64 %607, i64* %RDX, align 8, !tbaa !2428
  %608 = add i64 %133, -24
  %609 = add i64 %182, 14
  store i64 %609, i64* %PC, align 8
  %610 = inttoptr i64 %608 to i64*
  %611 = load i64, i64* %610, align 8
  store i64 %611, i64* %RCX, align 8, !tbaa !2428
  %612 = add i64 %182, 3638
  %613 = add i64 %182, 19
  %614 = load i64, i64* %7, align 8, !tbaa !2428
  %615 = add i64 %614, -8
  %616 = inttoptr i64 %615 to i64*
  store i64 %613, i64* %616, align 8
  store i64 %615, i64* %7, align 8, !tbaa !2428
  store i64 %612, i64* %92, align 8, !tbaa !2428
  %617 = tail call %struct.Memory* @sub_403300_cftmdl_renamed_(%struct.State* nonnull %0, i64 %612, %struct.Memory* %MEMORY.1)
  %618 = load i64, i64* %RBP, align 8
  %619 = add i64 %618, -44
  %620 = load i64, i64* %PC, align 8
  %621 = add i64 %620, 3
  store i64 %621, i64* %PC, align 8
  %622 = inttoptr i64 %619 to i32*
  %623 = load i32, i32* %622, align 4
  %624 = shl i32 %623, 2
  %625 = zext i32 %624 to i64
  store i64 %625, i64* %RSI, align 8, !tbaa !2428
  %626 = lshr i32 %623, 30
  %627 = trunc i32 %626 to i8
  %628 = and i8 %627, 1
  store i8 %628, i8* %15, align 1, !tbaa !2432
  %629 = and i32 %624, 252
  %630 = tail call i32 @llvm.ctpop.i32(i32 %629) #10
  %631 = trunc i32 %630 to i8
  %632 = and i8 %631, 1
  %633 = xor i8 %632, 1
  store i8 %633, i8* %22, align 1, !tbaa !2432
  store i8 0, i8* %28, align 1, !tbaa !2432
  %634 = icmp eq i32 %624, 0
  %635 = zext i1 %634 to i8
  store i8 %635, i8* %31, align 1, !tbaa !2432
  %636 = lshr i32 %623, 29
  %637 = trunc i32 %636 to i8
  %638 = and i8 %637, 1
  store i8 %638, i8* %34, align 1, !tbaa !2432
  store i8 0, i8* %40, align 1, !tbaa !2432
  %639 = add i64 %620, 9
  store i64 %639, i64* %PC, align 8
  store i32 %624, i32* %622, align 4
  %640 = load i64, i64* %PC, align 8
  %641 = add i64 %640, -43
  store i64 %641, i64* %92, align 8, !tbaa !2428
  br label %block_4024bb

block_402869:                                     ; preds = %block_402864, %block_40274b
  %.sink = phi i64 [ %735, %block_402864 ], [ %597, %block_40274b ]
  %642 = load i64, i64* %RSP, align 8
  %643 = add i64 %642, 112
  store i64 %643, i64* %RSP, align 8, !tbaa !2428
  %644 = icmp ugt i64 %642, -113
  %645 = zext i1 %644 to i8
  store i8 %645, i8* %15, align 1, !tbaa !2433
  %646 = trunc i64 %643 to i32
  %647 = and i32 %646, 255
  %648 = tail call i32 @llvm.ctpop.i32(i32 %647) #10
  %649 = trunc i32 %648 to i8
  %650 = and i8 %649, 1
  %651 = xor i8 %650, 1
  store i8 %651, i8* %22, align 1, !tbaa !2447
  %652 = xor i64 %642, 16
  %653 = xor i64 %652, %643
  %654 = lshr i64 %653, 4
  %655 = trunc i64 %654 to i8
  %656 = and i8 %655, 1
  store i8 %656, i8* %28, align 1, !tbaa !2451
  %657 = icmp eq i64 %643, 0
  %658 = zext i1 %657 to i8
  store i8 %658, i8* %31, align 1, !tbaa !2448
  %659 = lshr i64 %643, 63
  %660 = trunc i64 %659 to i8
  store i8 %660, i8* %34, align 1, !tbaa !2449
  %661 = lshr i64 %642, 63
  %662 = xor i64 %659, %661
  %663 = add nuw nsw i64 %662, %659
  %664 = icmp eq i64 %663, 2
  %665 = zext i1 %664 to i8
  store i8 %665, i8* %40, align 1, !tbaa !2450
  %666 = add i64 %.sink, 5
  store i64 %666, i64* %PC, align 8
  %667 = add i64 %642, 120
  %668 = inttoptr i64 %643 to i64*
  %669 = load i64, i64* %668, align 8
  store i64 %669, i64* %RBP, align 8, !tbaa !2428
  store i64 %667, i64* %7, align 8, !tbaa !2428
  %670 = add i64 %.sink, 6
  store i64 %670, i64* %PC, align 8
  %671 = inttoptr i64 %667 to i64*
  %672 = load i64, i64* %671, align 8
  store i64 %672, i64* %92, align 8, !tbaa !2428
  %673 = add i64 %642, 128
  store i64 %673, i64* %7, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.4

block_402506:                                     ; preds = %block_4024f0, %block_402512
  %674 = phi i64 [ %1649, %block_402512 ], [ %.pre3, %block_4024f0 ]
  %675 = load i64, i64* %RBP, align 8
  %676 = add i64 %675, -28
  %677 = add i64 %674, 3
  store i64 %677, i64* %PC, align 8
  %678 = inttoptr i64 %676 to i32*
  %679 = load i32, i32* %678, align 4
  %680 = zext i32 %679 to i64
  store i64 %680, i64* %RAX, align 8, !tbaa !2428
  %681 = add i64 %675, -44
  %682 = add i64 %674, 6
  store i64 %682, i64* %PC, align 8
  %683 = inttoptr i64 %681 to i32*
  %684 = load i32, i32* %683, align 4
  %685 = sub i32 %679, %684
  %686 = icmp ult i32 %679, %684
  %687 = zext i1 %686 to i8
  store i8 %687, i8* %15, align 1, !tbaa !2433
  %688 = and i32 %685, 255
  %689 = tail call i32 @llvm.ctpop.i32(i32 %688) #10
  %690 = trunc i32 %689 to i8
  %691 = and i8 %690, 1
  %692 = xor i8 %691, 1
  store i8 %692, i8* %22, align 1, !tbaa !2447
  %693 = xor i32 %684, %679
  %694 = xor i32 %693, %685
  %695 = lshr i32 %694, 4
  %696 = trunc i32 %695 to i8
  %697 = and i8 %696, 1
  store i8 %697, i8* %28, align 1, !tbaa !2451
  %698 = icmp eq i32 %685, 0
  %699 = zext i1 %698 to i8
  store i8 %699, i8* %31, align 1, !tbaa !2448
  %700 = lshr i32 %685, 31
  %701 = trunc i32 %700 to i8
  store i8 %701, i8* %34, align 1, !tbaa !2449
  %702 = lshr i32 %679, 31
  %703 = lshr i32 %684, 31
  %704 = xor i32 %703, %702
  %705 = xor i32 %700, %702
  %706 = add nuw nsw i32 %705, %704
  %707 = icmp eq i32 %706, 2
  %708 = zext i1 %707 to i8
  store i8 %708, i8* %40, align 1, !tbaa !2450
  %709 = icmp ne i8 %701, 0
  %710 = xor i1 %709, %707
  %.v7 = select i1 %710, i64 12, i64 581
  %711 = add i64 %674, %.v7
  store i64 %711, i64* %92, align 8, !tbaa !2428
  br i1 %710, label %block_402512, label %block_40274b

block_4024a4:                                     ; preds = %block_402480
  %712 = add i64 %93, 3
  store i64 %712, i64* %PC, align 8
  %713 = load i32, i32* %66, align 4
  %714 = zext i32 %713 to i64
  store i64 %714, i64* %RDI, align 8, !tbaa !2428
  %715 = add i64 %62, -16
  %716 = add i64 %93, 7
  store i64 %716, i64* %PC, align 8
  %717 = inttoptr i64 %715 to i64*
  %718 = load i64, i64* %717, align 8
  store i64 %718, i64* %RSI, align 8, !tbaa !2428
  %719 = add i64 %62, -24
  %720 = add i64 %93, 11
  store i64 %720, i64* %PC, align 8
  %721 = inttoptr i64 %719 to i64*
  %722 = load i64, i64* %721, align 8
  store i64 %722, i64* %RDX, align 8, !tbaa !2428
  %723 = add i64 %93, 972
  %724 = add i64 %93, 16
  %725 = load i64, i64* %7, align 8, !tbaa !2428
  %726 = add i64 %725, -8
  %727 = inttoptr i64 %726 to i64*
  store i64 %724, i64* %727, align 8
  store i64 %726, i64* %7, align 8, !tbaa !2428
  store i64 %723, i64* %92, align 8, !tbaa !2428
  %728 = tail call %struct.Memory* @sub_402870_cft1st_renamed_(%struct.State* nonnull %0, i64 %723, %struct.Memory* %2)
  %729 = load i64, i64* %RBP, align 8
  %730 = add i64 %729, -44
  %731 = load i64, i64* %PC, align 8
  %732 = add i64 %731, 7
  store i64 %732, i64* %PC, align 8
  %733 = inttoptr i64 %730 to i32*
  store i32 8, i32* %733, align 4
  %.pre = load i64, i64* %PC, align 8
  br label %block_4024bb

block_4024eb:                                     ; preds = %block_4024bb
  %734 = add i64 %182, 5
  store i64 %734, i64* %92, align 8, !tbaa !2428
  br label %block_4024f0

block_402864:                                     ; preds = %block_402757
  %735 = add i64 %131, 5
  br label %block_402869

block_402512:                                     ; preds = %block_402506
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %736 = add i64 %711, 13
  store i64 %736, i64* %PC, align 8
  %737 = load i32, i32* %678, align 4
  %738 = zext i32 %737 to i64
  store i64 %738, i64* %RCX, align 8, !tbaa !2428
  %739 = add i64 %711, 16
  store i64 %739, i64* %PC, align 8
  %740 = load i32, i32* %683, align 4
  %741 = add i32 %740, %737
  %742 = zext i32 %741 to i64
  store i64 %742, i64* %RCX, align 8, !tbaa !2428
  %743 = icmp ult i32 %741, %737
  %744 = icmp ult i32 %741, %740
  %745 = or i1 %743, %744
  %746 = zext i1 %745 to i8
  store i8 %746, i8* %15, align 1, !tbaa !2433
  %747 = and i32 %741, 255
  %748 = tail call i32 @llvm.ctpop.i32(i32 %747) #10
  %749 = trunc i32 %748 to i8
  %750 = and i8 %749, 1
  %751 = xor i8 %750, 1
  store i8 %751, i8* %22, align 1, !tbaa !2447
  %752 = xor i32 %740, %737
  %753 = xor i32 %752, %741
  %754 = lshr i32 %753, 4
  %755 = trunc i32 %754 to i8
  %756 = and i8 %755, 1
  store i8 %756, i8* %28, align 1, !tbaa !2451
  %757 = icmp eq i32 %741, 0
  %758 = zext i1 %757 to i8
  store i8 %758, i8* %31, align 1, !tbaa !2448
  %759 = lshr i32 %741, 31
  %760 = trunc i32 %759 to i8
  store i8 %760, i8* %34, align 1, !tbaa !2449
  %761 = lshr i32 %737, 31
  %762 = lshr i32 %740, 31
  %763 = xor i32 %759, %761
  %764 = xor i32 %759, %762
  %765 = add nuw nsw i32 %763, %764
  %766 = icmp eq i32 %765, 2
  %767 = zext i1 %766 to i8
  store i8 %767, i8* %40, align 1, !tbaa !2450
  %768 = add i64 %675, -32
  %769 = add i64 %711, 19
  store i64 %769, i64* %PC, align 8
  %770 = inttoptr i64 %768 to i32*
  store i32 %741, i32* %770, align 4
  %771 = load i64, i64* %RBP, align 8
  %772 = add i64 %771, -32
  %773 = load i64, i64* %PC, align 8
  %774 = add i64 %773, 3
  store i64 %774, i64* %PC, align 8
  %775 = inttoptr i64 %772 to i32*
  %776 = load i32, i32* %775, align 4
  %777 = zext i32 %776 to i64
  store i64 %777, i64* %RCX, align 8, !tbaa !2428
  %778 = add i64 %771, -44
  %779 = add i64 %773, 6
  store i64 %779, i64* %PC, align 8
  %780 = inttoptr i64 %778 to i32*
  %781 = load i32, i32* %780, align 4
  %782 = add i32 %781, %776
  %783 = zext i32 %782 to i64
  store i64 %783, i64* %RCX, align 8, !tbaa !2428
  %784 = icmp ult i32 %782, %776
  %785 = icmp ult i32 %782, %781
  %786 = or i1 %784, %785
  %787 = zext i1 %786 to i8
  store i8 %787, i8* %15, align 1, !tbaa !2433
  %788 = and i32 %782, 255
  %789 = tail call i32 @llvm.ctpop.i32(i32 %788) #10
  %790 = trunc i32 %789 to i8
  %791 = and i8 %790, 1
  %792 = xor i8 %791, 1
  store i8 %792, i8* %22, align 1, !tbaa !2447
  %793 = xor i32 %781, %776
  %794 = xor i32 %793, %782
  %795 = lshr i32 %794, 4
  %796 = trunc i32 %795 to i8
  %797 = and i8 %796, 1
  store i8 %797, i8* %28, align 1, !tbaa !2451
  %798 = icmp eq i32 %782, 0
  %799 = zext i1 %798 to i8
  store i8 %799, i8* %31, align 1, !tbaa !2448
  %800 = lshr i32 %782, 31
  %801 = trunc i32 %800 to i8
  store i8 %801, i8* %34, align 1, !tbaa !2449
  %802 = lshr i32 %776, 31
  %803 = lshr i32 %781, 31
  %804 = xor i32 %800, %802
  %805 = xor i32 %800, %803
  %806 = add nuw nsw i32 %804, %805
  %807 = icmp eq i32 %806, 2
  %808 = zext i1 %807 to i8
  store i8 %808, i8* %40, align 1, !tbaa !2450
  %809 = add i64 %771, -36
  %810 = add i64 %773, 9
  store i64 %810, i64* %PC, align 8
  %811 = inttoptr i64 %809 to i32*
  store i32 %782, i32* %811, align 4
  %812 = load i64, i64* %RBP, align 8
  %813 = add i64 %812, -36
  %814 = load i64, i64* %PC, align 8
  %815 = add i64 %814, 3
  store i64 %815, i64* %PC, align 8
  %816 = inttoptr i64 %813 to i32*
  %817 = load i32, i32* %816, align 4
  %818 = zext i32 %817 to i64
  store i64 %818, i64* %RCX, align 8, !tbaa !2428
  %819 = add i64 %812, -44
  %820 = add i64 %814, 6
  store i64 %820, i64* %PC, align 8
  %821 = inttoptr i64 %819 to i32*
  %822 = load i32, i32* %821, align 4
  %823 = add i32 %822, %817
  %824 = zext i32 %823 to i64
  store i64 %824, i64* %RCX, align 8, !tbaa !2428
  %825 = icmp ult i32 %823, %817
  %826 = icmp ult i32 %823, %822
  %827 = or i1 %825, %826
  %828 = zext i1 %827 to i8
  store i8 %828, i8* %15, align 1, !tbaa !2433
  %829 = and i32 %823, 255
  %830 = tail call i32 @llvm.ctpop.i32(i32 %829) #10
  %831 = trunc i32 %830 to i8
  %832 = and i8 %831, 1
  %833 = xor i8 %832, 1
  store i8 %833, i8* %22, align 1, !tbaa !2447
  %834 = xor i32 %822, %817
  %835 = xor i32 %834, %823
  %836 = lshr i32 %835, 4
  %837 = trunc i32 %836 to i8
  %838 = and i8 %837, 1
  store i8 %838, i8* %28, align 1, !tbaa !2451
  %839 = icmp eq i32 %823, 0
  %840 = zext i1 %839 to i8
  store i8 %840, i8* %31, align 1, !tbaa !2448
  %841 = lshr i32 %823, 31
  %842 = trunc i32 %841 to i8
  store i8 %842, i8* %34, align 1, !tbaa !2449
  %843 = lshr i32 %817, 31
  %844 = lshr i32 %822, 31
  %845 = xor i32 %841, %843
  %846 = xor i32 %841, %844
  %847 = add nuw nsw i32 %845, %846
  %848 = icmp eq i32 %847, 2
  %849 = zext i1 %848 to i8
  store i8 %849, i8* %40, align 1, !tbaa !2450
  %850 = add i64 %812, -40
  %851 = add i64 %814, 9
  store i64 %851, i64* %PC, align 8
  %852 = inttoptr i64 %850 to i32*
  store i32 %823, i32* %852, align 4
  %853 = load i64, i64* %RBP, align 8
  %854 = add i64 %853, -16
  %855 = load i64, i64* %PC, align 8
  %856 = add i64 %855, 4
  store i64 %856, i64* %PC, align 8
  %857 = inttoptr i64 %854 to i64*
  %858 = load i64, i64* %857, align 8
  store i64 %858, i64* %RDX, align 8, !tbaa !2428
  %859 = add i64 %853, -28
  %860 = add i64 %855, 8
  store i64 %860, i64* %PC, align 8
  %861 = inttoptr i64 %859 to i32*
  %862 = load i32, i32* %861, align 4
  %863 = sext i32 %862 to i64
  store i64 %863, i64* %RSI, align 8, !tbaa !2428
  %864 = shl nsw i64 %863, 3
  %865 = add i64 %864, %858
  %866 = add i64 %855, 13
  store i64 %866, i64* %PC, align 8
  %867 = inttoptr i64 %865 to double*
  %868 = load double, double* %867, align 8
  store double %868, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %869 = add i64 %855, 17
  store i64 %869, i64* %PC, align 8
  %870 = load i64, i64* %857, align 8
  store i64 %870, i64* %RDX, align 8, !tbaa !2428
  %871 = add i64 %853, -32
  %872 = add i64 %855, 21
  store i64 %872, i64* %PC, align 8
  %873 = inttoptr i64 %871 to i32*
  %874 = load i32, i32* %873, align 4
  %875 = sext i32 %874 to i64
  store i64 %875, i64* %RSI, align 8, !tbaa !2428
  %876 = shl nsw i64 %875, 3
  %877 = add i64 %876, %870
  %878 = add i64 %855, 26
  store i64 %878, i64* %PC, align 8
  %879 = inttoptr i64 %877 to double*
  %880 = load double, double* %879, align 8
  %881 = fadd double %868, %880
  store double %881, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %882 = add i64 %853, -56
  %883 = add i64 %855, 31
  store i64 %883, i64* %PC, align 8
  %884 = inttoptr i64 %882 to double*
  store double %881, double* %884, align 8
  %885 = load i64, i64* %RBP, align 8
  %886 = add i64 %885, -16
  %887 = load i64, i64* %PC, align 8
  %888 = add i64 %887, 4
  store i64 %888, i64* %PC, align 8
  %889 = inttoptr i64 %886 to i64*
  %890 = load i64, i64* %889, align 8
  store i64 %890, i64* %RDX, align 8, !tbaa !2428
  %891 = add i64 %885, -28
  %892 = add i64 %887, 7
  store i64 %892, i64* %PC, align 8
  %893 = inttoptr i64 %891 to i32*
  %894 = load i32, i32* %893, align 4
  %895 = add i32 %894, 1
  %896 = zext i32 %895 to i64
  store i64 %896, i64* %RCX, align 8, !tbaa !2428
  %897 = icmp eq i32 %894, -1
  %898 = icmp eq i32 %895, 0
  %899 = or i1 %897, %898
  %900 = zext i1 %899 to i8
  store i8 %900, i8* %15, align 1, !tbaa !2433
  %901 = and i32 %895, 255
  %902 = tail call i32 @llvm.ctpop.i32(i32 %901) #10
  %903 = trunc i32 %902 to i8
  %904 = and i8 %903, 1
  %905 = xor i8 %904, 1
  store i8 %905, i8* %22, align 1, !tbaa !2447
  %906 = xor i32 %894, %895
  %907 = lshr i32 %906, 4
  %908 = trunc i32 %907 to i8
  %909 = and i8 %908, 1
  store i8 %909, i8* %28, align 1, !tbaa !2451
  %910 = icmp eq i32 %895, 0
  %911 = zext i1 %910 to i8
  store i8 %911, i8* %31, align 1, !tbaa !2448
  %912 = lshr i32 %895, 31
  %913 = trunc i32 %912 to i8
  store i8 %913, i8* %34, align 1, !tbaa !2449
  %914 = lshr i32 %894, 31
  %915 = xor i32 %912, %914
  %916 = add nuw nsw i32 %915, %912
  %917 = icmp eq i32 %916, 2
  %918 = zext i1 %917 to i8
  store i8 %918, i8* %40, align 1, !tbaa !2450
  %919 = sext i32 %895 to i64
  store i64 %919, i64* %RSI, align 8, !tbaa !2428
  %920 = shl nsw i64 %919, 3
  %921 = add i64 %920, %890
  %922 = add i64 %887, 18
  store i64 %922, i64* %PC, align 8
  %923 = inttoptr i64 %921 to i64*
  %924 = load i64, i64* %923, align 8
  %925 = load i64, i64* %RAX, align 8
  %926 = xor i64 %925, %924
  store i64 %926, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %15, align 1, !tbaa !2433
  %927 = trunc i64 %926 to i32
  %928 = and i32 %927, 255
  %929 = tail call i32 @llvm.ctpop.i32(i32 %928) #10
  %930 = trunc i32 %929 to i8
  %931 = and i8 %930, 1
  %932 = xor i8 %931, 1
  store i8 %932, i8* %22, align 1, !tbaa !2447
  %933 = icmp eq i64 %926, 0
  %934 = zext i1 %933 to i8
  store i8 %934, i8* %31, align 1, !tbaa !2448
  %935 = lshr i64 %926, 63
  %936 = trunc i64 %935 to i8
  store i8 %936, i8* %34, align 1, !tbaa !2449
  store i8 0, i8* %40, align 1, !tbaa !2450
  store i8 0, i8* %28, align 1, !tbaa !2451
  store i64 %926, i64* %1705, align 1, !tbaa !2428
  store i64 0, i64* %1703, align 1, !tbaa !2428
  %937 = add i64 %887, 35
  store i64 %937, i64* %PC, align 8
  %938 = load i64, i64* %889, align 8
  store i64 %938, i64* %RDX, align 8, !tbaa !2428
  %939 = add i64 %885, -32
  %940 = add i64 %887, 38
  store i64 %940, i64* %PC, align 8
  %941 = inttoptr i64 %939 to i32*
  %942 = load i32, i32* %941, align 4
  %943 = add i32 %942, 1
  %944 = zext i32 %943 to i64
  store i64 %944, i64* %RCX, align 8, !tbaa !2428
  %945 = icmp eq i32 %942, -1
  %946 = icmp eq i32 %943, 0
  %947 = or i1 %945, %946
  %948 = zext i1 %947 to i8
  store i8 %948, i8* %15, align 1, !tbaa !2433
  %949 = and i32 %943, 255
  %950 = tail call i32 @llvm.ctpop.i32(i32 %949) #10
  %951 = trunc i32 %950 to i8
  %952 = and i8 %951, 1
  %953 = xor i8 %952, 1
  store i8 %953, i8* %22, align 1, !tbaa !2447
  %954 = xor i32 %942, %943
  %955 = lshr i32 %954, 4
  %956 = trunc i32 %955 to i8
  %957 = and i8 %956, 1
  store i8 %957, i8* %28, align 1, !tbaa !2451
  %958 = icmp eq i32 %943, 0
  %959 = zext i1 %958 to i8
  store i8 %959, i8* %31, align 1, !tbaa !2448
  %960 = lshr i32 %943, 31
  %961 = trunc i32 %960 to i8
  store i8 %961, i8* %34, align 1, !tbaa !2449
  %962 = lshr i32 %942, 31
  %963 = xor i32 %960, %962
  %964 = add nuw nsw i32 %963, %960
  %965 = icmp eq i32 %964, 2
  %966 = zext i1 %965 to i8
  store i8 %966, i8* %40, align 1, !tbaa !2450
  %967 = sext i32 %943 to i64
  store i64 %967, i64* %RSI, align 8, !tbaa !2428
  %968 = shl nsw i64 %967, 3
  %969 = add i64 %968, %938
  %970 = add i64 %887, 49
  store i64 %970, i64* %PC, align 8
  %971 = bitcast i64 %926 to double
  %972 = inttoptr i64 %969 to double*
  %973 = load double, double* %972, align 8
  %974 = fsub double %971, %973
  store double %974, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %975 = load i64, i64* %RBP, align 8
  %976 = add i64 %975, -64
  %977 = add i64 %887, 54
  store i64 %977, i64* %PC, align 8
  %978 = inttoptr i64 %976 to double*
  store double %974, double* %978, align 8
  %979 = load i64, i64* %RBP, align 8
  %980 = add i64 %979, -16
  %981 = load i64, i64* %PC, align 8
  %982 = add i64 %981, 4
  store i64 %982, i64* %PC, align 8
  %983 = inttoptr i64 %980 to i64*
  %984 = load i64, i64* %983, align 8
  store i64 %984, i64* %RDX, align 8, !tbaa !2428
  %985 = add i64 %979, -28
  %986 = add i64 %981, 8
  store i64 %986, i64* %PC, align 8
  %987 = inttoptr i64 %985 to i32*
  %988 = load i32, i32* %987, align 4
  %989 = sext i32 %988 to i64
  store i64 %989, i64* %RSI, align 8, !tbaa !2428
  %990 = shl nsw i64 %989, 3
  %991 = add i64 %990, %984
  %992 = add i64 %981, 13
  store i64 %992, i64* %PC, align 8
  %993 = inttoptr i64 %991 to double*
  %994 = load double, double* %993, align 8
  store double %994, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %995 = add i64 %981, 17
  store i64 %995, i64* %PC, align 8
  %996 = load i64, i64* %983, align 8
  store i64 %996, i64* %RDX, align 8, !tbaa !2428
  %997 = add i64 %979, -32
  %998 = add i64 %981, 21
  store i64 %998, i64* %PC, align 8
  %999 = inttoptr i64 %997 to i32*
  %1000 = load i32, i32* %999, align 4
  %1001 = sext i32 %1000 to i64
  store i64 %1001, i64* %RSI, align 8, !tbaa !2428
  %1002 = shl nsw i64 %1001, 3
  %1003 = add i64 %1002, %996
  %1004 = add i64 %981, 26
  store i64 %1004, i64* %PC, align 8
  %1005 = inttoptr i64 %1003 to double*
  %1006 = load double, double* %1005, align 8
  %1007 = fsub double %994, %1006
  store double %1007, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1008 = add i64 %979, -72
  %1009 = add i64 %981, 31
  store i64 %1009, i64* %PC, align 8
  %1010 = inttoptr i64 %1008 to double*
  store double %1007, double* %1010, align 8
  %1011 = load i64, i64* %RBP, align 8
  %1012 = add i64 %1011, -16
  %1013 = load i64, i64* %PC, align 8
  %1014 = add i64 %1013, 4
  store i64 %1014, i64* %PC, align 8
  %1015 = inttoptr i64 %1012 to i64*
  %1016 = load i64, i64* %1015, align 8
  store i64 %1016, i64* %RDX, align 8, !tbaa !2428
  %1017 = add i64 %1011, -28
  %1018 = add i64 %1013, 7
  store i64 %1018, i64* %PC, align 8
  %1019 = inttoptr i64 %1017 to i32*
  %1020 = load i32, i32* %1019, align 4
  %1021 = add i32 %1020, 1
  %1022 = zext i32 %1021 to i64
  store i64 %1022, i64* %RCX, align 8, !tbaa !2428
  %1023 = icmp eq i32 %1020, -1
  %1024 = icmp eq i32 %1021, 0
  %1025 = or i1 %1023, %1024
  %1026 = zext i1 %1025 to i8
  store i8 %1026, i8* %15, align 1, !tbaa !2433
  %1027 = and i32 %1021, 255
  %1028 = tail call i32 @llvm.ctpop.i32(i32 %1027) #10
  %1029 = trunc i32 %1028 to i8
  %1030 = and i8 %1029, 1
  %1031 = xor i8 %1030, 1
  store i8 %1031, i8* %22, align 1, !tbaa !2447
  %1032 = xor i32 %1020, %1021
  %1033 = lshr i32 %1032, 4
  %1034 = trunc i32 %1033 to i8
  %1035 = and i8 %1034, 1
  store i8 %1035, i8* %28, align 1, !tbaa !2451
  %1036 = icmp eq i32 %1021, 0
  %1037 = zext i1 %1036 to i8
  store i8 %1037, i8* %31, align 1, !tbaa !2448
  %1038 = lshr i32 %1021, 31
  %1039 = trunc i32 %1038 to i8
  store i8 %1039, i8* %34, align 1, !tbaa !2449
  %1040 = lshr i32 %1020, 31
  %1041 = xor i32 %1038, %1040
  %1042 = add nuw nsw i32 %1041, %1038
  %1043 = icmp eq i32 %1042, 2
  %1044 = zext i1 %1043 to i8
  store i8 %1044, i8* %40, align 1, !tbaa !2450
  %1045 = sext i32 %1021 to i64
  store i64 %1045, i64* %RSI, align 8, !tbaa !2428
  %1046 = shl nsw i64 %1045, 3
  %1047 = add i64 %1046, %1016
  %1048 = add i64 %1013, 18
  store i64 %1048, i64* %PC, align 8
  %1049 = inttoptr i64 %1047 to i64*
  %1050 = load i64, i64* %1049, align 8
  %1051 = load i64, i64* %RAX, align 8
  %1052 = xor i64 %1051, %1050
  store i64 %1052, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %15, align 1, !tbaa !2433
  %1053 = trunc i64 %1052 to i32
  %1054 = and i32 %1053, 255
  %1055 = tail call i32 @llvm.ctpop.i32(i32 %1054) #10
  %1056 = trunc i32 %1055 to i8
  %1057 = and i8 %1056, 1
  %1058 = xor i8 %1057, 1
  store i8 %1058, i8* %22, align 1, !tbaa !2447
  %1059 = icmp eq i64 %1052, 0
  %1060 = zext i1 %1059 to i8
  store i8 %1060, i8* %31, align 1, !tbaa !2448
  %1061 = lshr i64 %1052, 63
  %1062 = trunc i64 %1061 to i8
  store i8 %1062, i8* %34, align 1, !tbaa !2449
  store i8 0, i8* %40, align 1, !tbaa !2450
  store i8 0, i8* %28, align 1, !tbaa !2451
  store i64 %1052, i64* %1705, align 1, !tbaa !2428
  store i64 0, i64* %1703, align 1, !tbaa !2428
  %1063 = add i64 %1013, 35
  store i64 %1063, i64* %PC, align 8
  %1064 = load i64, i64* %1015, align 8
  store i64 %1064, i64* %RAX, align 8, !tbaa !2428
  %1065 = add i64 %1011, -32
  %1066 = add i64 %1013, 38
  store i64 %1066, i64* %PC, align 8
  %1067 = inttoptr i64 %1065 to i32*
  %1068 = load i32, i32* %1067, align 4
  %1069 = add i32 %1068, 1
  %1070 = zext i32 %1069 to i64
  store i64 %1070, i64* %RCX, align 8, !tbaa !2428
  %1071 = icmp eq i32 %1068, -1
  %1072 = icmp eq i32 %1069, 0
  %1073 = or i1 %1071, %1072
  %1074 = zext i1 %1073 to i8
  store i8 %1074, i8* %15, align 1, !tbaa !2433
  %1075 = and i32 %1069, 255
  %1076 = tail call i32 @llvm.ctpop.i32(i32 %1075) #10
  %1077 = trunc i32 %1076 to i8
  %1078 = and i8 %1077, 1
  %1079 = xor i8 %1078, 1
  store i8 %1079, i8* %22, align 1, !tbaa !2447
  %1080 = xor i32 %1068, %1069
  %1081 = lshr i32 %1080, 4
  %1082 = trunc i32 %1081 to i8
  %1083 = and i8 %1082, 1
  store i8 %1083, i8* %28, align 1, !tbaa !2451
  %1084 = icmp eq i32 %1069, 0
  %1085 = zext i1 %1084 to i8
  store i8 %1085, i8* %31, align 1, !tbaa !2448
  %1086 = lshr i32 %1069, 31
  %1087 = trunc i32 %1086 to i8
  store i8 %1087, i8* %34, align 1, !tbaa !2449
  %1088 = lshr i32 %1068, 31
  %1089 = xor i32 %1086, %1088
  %1090 = add nuw nsw i32 %1089, %1086
  %1091 = icmp eq i32 %1090, 2
  %1092 = zext i1 %1091 to i8
  store i8 %1092, i8* %40, align 1, !tbaa !2450
  %1093 = sext i32 %1069 to i64
  store i64 %1093, i64* %RDX, align 8, !tbaa !2428
  %1094 = shl nsw i64 %1093, 3
  %1095 = add i64 %1094, %1064
  %1096 = add i64 %1013, 49
  store i64 %1096, i64* %PC, align 8
  %1097 = bitcast i64 %1052 to double
  %1098 = inttoptr i64 %1095 to double*
  %1099 = load double, double* %1098, align 8
  %1100 = fadd double %1097, %1099
  store double %1100, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1101 = load i64, i64* %RBP, align 8
  %1102 = add i64 %1101, -80
  %1103 = add i64 %1013, 54
  store i64 %1103, i64* %PC, align 8
  %1104 = inttoptr i64 %1102 to double*
  store double %1100, double* %1104, align 8
  %1105 = load i64, i64* %RBP, align 8
  %1106 = add i64 %1105, -16
  %1107 = load i64, i64* %PC, align 8
  %1108 = add i64 %1107, 4
  store i64 %1108, i64* %PC, align 8
  %1109 = inttoptr i64 %1106 to i64*
  %1110 = load i64, i64* %1109, align 8
  store i64 %1110, i64* %RAX, align 8, !tbaa !2428
  %1111 = add i64 %1105, -36
  %1112 = add i64 %1107, 8
  store i64 %1112, i64* %PC, align 8
  %1113 = inttoptr i64 %1111 to i32*
  %1114 = load i32, i32* %1113, align 4
  %1115 = sext i32 %1114 to i64
  store i64 %1115, i64* %RDX, align 8, !tbaa !2428
  %1116 = shl nsw i64 %1115, 3
  %1117 = add i64 %1116, %1110
  %1118 = add i64 %1107, 13
  store i64 %1118, i64* %PC, align 8
  %1119 = inttoptr i64 %1117 to double*
  %1120 = load double, double* %1119, align 8
  store double %1120, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1121 = add i64 %1107, 17
  store i64 %1121, i64* %PC, align 8
  %1122 = load i64, i64* %1109, align 8
  store i64 %1122, i64* %RAX, align 8, !tbaa !2428
  %1123 = add i64 %1105, -40
  %1124 = add i64 %1107, 21
  store i64 %1124, i64* %PC, align 8
  %1125 = inttoptr i64 %1123 to i32*
  %1126 = load i32, i32* %1125, align 4
  %1127 = sext i32 %1126 to i64
  store i64 %1127, i64* %RDX, align 8, !tbaa !2428
  %1128 = shl nsw i64 %1127, 3
  %1129 = add i64 %1128, %1122
  %1130 = add i64 %1107, 26
  store i64 %1130, i64* %PC, align 8
  %1131 = inttoptr i64 %1129 to double*
  %1132 = load double, double* %1131, align 8
  %1133 = fadd double %1120, %1132
  store double %1133, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1134 = add i64 %1105, -88
  %1135 = add i64 %1107, 31
  store i64 %1135, i64* %PC, align 8
  %1136 = inttoptr i64 %1134 to double*
  store double %1133, double* %1136, align 8
  %1137 = load i64, i64* %RBP, align 8
  %1138 = add i64 %1137, -16
  %1139 = load i64, i64* %PC, align 8
  %1140 = add i64 %1139, 4
  store i64 %1140, i64* %PC, align 8
  %1141 = inttoptr i64 %1138 to i64*
  %1142 = load i64, i64* %1141, align 8
  store i64 %1142, i64* %RAX, align 8, !tbaa !2428
  %1143 = add i64 %1137, -36
  %1144 = add i64 %1139, 7
  store i64 %1144, i64* %PC, align 8
  %1145 = inttoptr i64 %1143 to i32*
  %1146 = load i32, i32* %1145, align 4
  %1147 = add i32 %1146, 1
  %1148 = zext i32 %1147 to i64
  store i64 %1148, i64* %RCX, align 8, !tbaa !2428
  %1149 = icmp eq i32 %1146, -1
  %1150 = icmp eq i32 %1147, 0
  %1151 = or i1 %1149, %1150
  %1152 = zext i1 %1151 to i8
  store i8 %1152, i8* %15, align 1, !tbaa !2433
  %1153 = and i32 %1147, 255
  %1154 = tail call i32 @llvm.ctpop.i32(i32 %1153) #10
  %1155 = trunc i32 %1154 to i8
  %1156 = and i8 %1155, 1
  %1157 = xor i8 %1156, 1
  store i8 %1157, i8* %22, align 1, !tbaa !2447
  %1158 = xor i32 %1146, %1147
  %1159 = lshr i32 %1158, 4
  %1160 = trunc i32 %1159 to i8
  %1161 = and i8 %1160, 1
  store i8 %1161, i8* %28, align 1, !tbaa !2451
  %1162 = icmp eq i32 %1147, 0
  %1163 = zext i1 %1162 to i8
  store i8 %1163, i8* %31, align 1, !tbaa !2448
  %1164 = lshr i32 %1147, 31
  %1165 = trunc i32 %1164 to i8
  store i8 %1165, i8* %34, align 1, !tbaa !2449
  %1166 = lshr i32 %1146, 31
  %1167 = xor i32 %1164, %1166
  %1168 = add nuw nsw i32 %1167, %1164
  %1169 = icmp eq i32 %1168, 2
  %1170 = zext i1 %1169 to i8
  store i8 %1170, i8* %40, align 1, !tbaa !2450
  %1171 = sext i32 %1147 to i64
  store i64 %1171, i64* %RDX, align 8, !tbaa !2428
  %1172 = shl nsw i64 %1171, 3
  %1173 = add i64 %1172, %1142
  %1174 = add i64 %1139, 18
  store i64 %1174, i64* %PC, align 8
  %1175 = inttoptr i64 %1173 to double*
  %1176 = load double, double* %1175, align 8
  store double %1176, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1177 = add i64 %1139, 22
  store i64 %1177, i64* %PC, align 8
  %1178 = load i64, i64* %1141, align 8
  store i64 %1178, i64* %RAX, align 8, !tbaa !2428
  %1179 = add i64 %1137, -40
  %1180 = add i64 %1139, 25
  store i64 %1180, i64* %PC, align 8
  %1181 = inttoptr i64 %1179 to i32*
  %1182 = load i32, i32* %1181, align 4
  %1183 = add i32 %1182, 1
  %1184 = zext i32 %1183 to i64
  store i64 %1184, i64* %RCX, align 8, !tbaa !2428
  %1185 = icmp eq i32 %1182, -1
  %1186 = icmp eq i32 %1183, 0
  %1187 = or i1 %1185, %1186
  %1188 = zext i1 %1187 to i8
  store i8 %1188, i8* %15, align 1, !tbaa !2433
  %1189 = and i32 %1183, 255
  %1190 = tail call i32 @llvm.ctpop.i32(i32 %1189) #10
  %1191 = trunc i32 %1190 to i8
  %1192 = and i8 %1191, 1
  %1193 = xor i8 %1192, 1
  store i8 %1193, i8* %22, align 1, !tbaa !2447
  %1194 = xor i32 %1182, %1183
  %1195 = lshr i32 %1194, 4
  %1196 = trunc i32 %1195 to i8
  %1197 = and i8 %1196, 1
  store i8 %1197, i8* %28, align 1, !tbaa !2451
  %1198 = icmp eq i32 %1183, 0
  %1199 = zext i1 %1198 to i8
  store i8 %1199, i8* %31, align 1, !tbaa !2448
  %1200 = lshr i32 %1183, 31
  %1201 = trunc i32 %1200 to i8
  store i8 %1201, i8* %34, align 1, !tbaa !2449
  %1202 = lshr i32 %1182, 31
  %1203 = xor i32 %1200, %1202
  %1204 = add nuw nsw i32 %1203, %1200
  %1205 = icmp eq i32 %1204, 2
  %1206 = zext i1 %1205 to i8
  store i8 %1206, i8* %40, align 1, !tbaa !2450
  %1207 = sext i32 %1183 to i64
  store i64 %1207, i64* %RDX, align 8, !tbaa !2428
  %1208 = shl nsw i64 %1207, 3
  %1209 = add i64 %1208, %1178
  %1210 = add i64 %1139, 36
  store i64 %1210, i64* %PC, align 8
  %1211 = inttoptr i64 %1209 to double*
  %1212 = load double, double* %1211, align 8
  %1213 = fadd double %1176, %1212
  store double %1213, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1214 = load i64, i64* %RBP, align 8
  %1215 = add i64 %1214, -96
  %1216 = add i64 %1139, 41
  store i64 %1216, i64* %PC, align 8
  %1217 = inttoptr i64 %1215 to double*
  store double %1213, double* %1217, align 8
  %1218 = load i64, i64* %RBP, align 8
  %1219 = add i64 %1218, -16
  %1220 = load i64, i64* %PC, align 8
  %1221 = add i64 %1220, 4
  store i64 %1221, i64* %PC, align 8
  %1222 = inttoptr i64 %1219 to i64*
  %1223 = load i64, i64* %1222, align 8
  store i64 %1223, i64* %RAX, align 8, !tbaa !2428
  %1224 = add i64 %1218, -36
  %1225 = add i64 %1220, 8
  store i64 %1225, i64* %PC, align 8
  %1226 = inttoptr i64 %1224 to i32*
  %1227 = load i32, i32* %1226, align 4
  %1228 = sext i32 %1227 to i64
  store i64 %1228, i64* %RDX, align 8, !tbaa !2428
  %1229 = shl nsw i64 %1228, 3
  %1230 = add i64 %1229, %1223
  %1231 = add i64 %1220, 13
  store i64 %1231, i64* %PC, align 8
  %1232 = inttoptr i64 %1230 to double*
  %1233 = load double, double* %1232, align 8
  store double %1233, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1234 = add i64 %1220, 17
  store i64 %1234, i64* %PC, align 8
  %1235 = load i64, i64* %1222, align 8
  store i64 %1235, i64* %RAX, align 8, !tbaa !2428
  %1236 = add i64 %1218, -40
  %1237 = add i64 %1220, 21
  store i64 %1237, i64* %PC, align 8
  %1238 = inttoptr i64 %1236 to i32*
  %1239 = load i32, i32* %1238, align 4
  %1240 = sext i32 %1239 to i64
  store i64 %1240, i64* %RDX, align 8, !tbaa !2428
  %1241 = shl nsw i64 %1240, 3
  %1242 = add i64 %1241, %1235
  %1243 = add i64 %1220, 26
  store i64 %1243, i64* %PC, align 8
  %1244 = inttoptr i64 %1242 to double*
  %1245 = load double, double* %1244, align 8
  %1246 = fsub double %1233, %1245
  store double %1246, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1247 = add i64 %1218, -104
  %1248 = add i64 %1220, 31
  store i64 %1248, i64* %PC, align 8
  %1249 = inttoptr i64 %1247 to double*
  store double %1246, double* %1249, align 8
  %1250 = load i64, i64* %RBP, align 8
  %1251 = add i64 %1250, -16
  %1252 = load i64, i64* %PC, align 8
  %1253 = add i64 %1252, 4
  store i64 %1253, i64* %PC, align 8
  %1254 = inttoptr i64 %1251 to i64*
  %1255 = load i64, i64* %1254, align 8
  store i64 %1255, i64* %RAX, align 8, !tbaa !2428
  %1256 = add i64 %1250, -36
  %1257 = add i64 %1252, 7
  store i64 %1257, i64* %PC, align 8
  %1258 = inttoptr i64 %1256 to i32*
  %1259 = load i32, i32* %1258, align 4
  %1260 = add i32 %1259, 1
  %1261 = zext i32 %1260 to i64
  store i64 %1261, i64* %RCX, align 8, !tbaa !2428
  %1262 = icmp eq i32 %1259, -1
  %1263 = icmp eq i32 %1260, 0
  %1264 = or i1 %1262, %1263
  %1265 = zext i1 %1264 to i8
  store i8 %1265, i8* %15, align 1, !tbaa !2433
  %1266 = and i32 %1260, 255
  %1267 = tail call i32 @llvm.ctpop.i32(i32 %1266) #10
  %1268 = trunc i32 %1267 to i8
  %1269 = and i8 %1268, 1
  %1270 = xor i8 %1269, 1
  store i8 %1270, i8* %22, align 1, !tbaa !2447
  %1271 = xor i32 %1259, %1260
  %1272 = lshr i32 %1271, 4
  %1273 = trunc i32 %1272 to i8
  %1274 = and i8 %1273, 1
  store i8 %1274, i8* %28, align 1, !tbaa !2451
  %1275 = icmp eq i32 %1260, 0
  %1276 = zext i1 %1275 to i8
  store i8 %1276, i8* %31, align 1, !tbaa !2448
  %1277 = lshr i32 %1260, 31
  %1278 = trunc i32 %1277 to i8
  store i8 %1278, i8* %34, align 1, !tbaa !2449
  %1279 = lshr i32 %1259, 31
  %1280 = xor i32 %1277, %1279
  %1281 = add nuw nsw i32 %1280, %1277
  %1282 = icmp eq i32 %1281, 2
  %1283 = zext i1 %1282 to i8
  store i8 %1283, i8* %40, align 1, !tbaa !2450
  %1284 = sext i32 %1260 to i64
  store i64 %1284, i64* %RDX, align 8, !tbaa !2428
  %1285 = shl nsw i64 %1284, 3
  %1286 = add i64 %1285, %1255
  %1287 = add i64 %1252, 18
  store i64 %1287, i64* %PC, align 8
  %1288 = inttoptr i64 %1286 to double*
  %1289 = load double, double* %1288, align 8
  store double %1289, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1290 = add i64 %1252, 22
  store i64 %1290, i64* %PC, align 8
  %1291 = load i64, i64* %1254, align 8
  store i64 %1291, i64* %RAX, align 8, !tbaa !2428
  %1292 = add i64 %1250, -40
  %1293 = add i64 %1252, 25
  store i64 %1293, i64* %PC, align 8
  %1294 = inttoptr i64 %1292 to i32*
  %1295 = load i32, i32* %1294, align 4
  %1296 = add i32 %1295, 1
  %1297 = zext i32 %1296 to i64
  store i64 %1297, i64* %RCX, align 8, !tbaa !2428
  %1298 = icmp eq i32 %1295, -1
  %1299 = icmp eq i32 %1296, 0
  %1300 = or i1 %1298, %1299
  %1301 = zext i1 %1300 to i8
  store i8 %1301, i8* %15, align 1, !tbaa !2433
  %1302 = and i32 %1296, 255
  %1303 = tail call i32 @llvm.ctpop.i32(i32 %1302) #10
  %1304 = trunc i32 %1303 to i8
  %1305 = and i8 %1304, 1
  %1306 = xor i8 %1305, 1
  store i8 %1306, i8* %22, align 1, !tbaa !2447
  %1307 = xor i32 %1295, %1296
  %1308 = lshr i32 %1307, 4
  %1309 = trunc i32 %1308 to i8
  %1310 = and i8 %1309, 1
  store i8 %1310, i8* %28, align 1, !tbaa !2451
  %1311 = icmp eq i32 %1296, 0
  %1312 = zext i1 %1311 to i8
  store i8 %1312, i8* %31, align 1, !tbaa !2448
  %1313 = lshr i32 %1296, 31
  %1314 = trunc i32 %1313 to i8
  store i8 %1314, i8* %34, align 1, !tbaa !2449
  %1315 = lshr i32 %1295, 31
  %1316 = xor i32 %1313, %1315
  %1317 = add nuw nsw i32 %1316, %1313
  %1318 = icmp eq i32 %1317, 2
  %1319 = zext i1 %1318 to i8
  store i8 %1319, i8* %40, align 1, !tbaa !2450
  %1320 = sext i32 %1296 to i64
  store i64 %1320, i64* %RDX, align 8, !tbaa !2428
  %1321 = shl nsw i64 %1320, 3
  %1322 = add i64 %1321, %1291
  %1323 = add i64 %1252, 36
  store i64 %1323, i64* %PC, align 8
  %1324 = inttoptr i64 %1322 to double*
  %1325 = load double, double* %1324, align 8
  %1326 = fsub double %1289, %1325
  store double %1326, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1327 = load i64, i64* %RBP, align 8
  %1328 = add i64 %1327, -112
  %1329 = add i64 %1252, 41
  store i64 %1329, i64* %PC, align 8
  %1330 = inttoptr i64 %1328 to double*
  store double %1326, double* %1330, align 8
  %1331 = load i64, i64* %RBP, align 8
  %1332 = add i64 %1331, -56
  %1333 = load i64, i64* %PC, align 8
  %1334 = add i64 %1333, 5
  store i64 %1334, i64* %PC, align 8
  %1335 = inttoptr i64 %1332 to double*
  %1336 = load double, double* %1335, align 8
  store double %1336, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1337 = add i64 %1331, -88
  %1338 = add i64 %1333, 10
  store i64 %1338, i64* %PC, align 8
  %1339 = inttoptr i64 %1337 to double*
  %1340 = load double, double* %1339, align 8
  %1341 = fadd double %1336, %1340
  store double %1341, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1342 = add i64 %1331, -16
  %1343 = add i64 %1333, 14
  store i64 %1343, i64* %PC, align 8
  %1344 = inttoptr i64 %1342 to i64*
  %1345 = load i64, i64* %1344, align 8
  store i64 %1345, i64* %RAX, align 8, !tbaa !2428
  %1346 = add i64 %1331, -28
  %1347 = add i64 %1333, 18
  store i64 %1347, i64* %PC, align 8
  %1348 = inttoptr i64 %1346 to i32*
  %1349 = load i32, i32* %1348, align 4
  %1350 = sext i32 %1349 to i64
  store i64 %1350, i64* %RDX, align 8, !tbaa !2428
  %1351 = shl nsw i64 %1350, 3
  %1352 = add i64 %1351, %1345
  %1353 = add i64 %1333, 23
  store i64 %1353, i64* %PC, align 8
  %1354 = inttoptr i64 %1352 to double*
  store double %1341, double* %1354, align 8
  %1355 = load i64, i64* %RBP, align 8
  %1356 = add i64 %1355, -64
  %1357 = load i64, i64* %PC, align 8
  %1358 = add i64 %1357, 5
  store i64 %1358, i64* %PC, align 8
  %1359 = inttoptr i64 %1356 to double*
  %1360 = load double, double* %1359, align 8
  store double %1360, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1361 = add i64 %1355, -96
  %1362 = add i64 %1357, 10
  store i64 %1362, i64* %PC, align 8
  %1363 = inttoptr i64 %1361 to double*
  %1364 = load double, double* %1363, align 8
  %1365 = fsub double %1360, %1364
  store double %1365, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1366 = add i64 %1355, -16
  %1367 = add i64 %1357, 14
  store i64 %1367, i64* %PC, align 8
  %1368 = inttoptr i64 %1366 to i64*
  %1369 = load i64, i64* %1368, align 8
  store i64 %1369, i64* %RAX, align 8, !tbaa !2428
  %1370 = add i64 %1355, -28
  %1371 = add i64 %1357, 17
  store i64 %1371, i64* %PC, align 8
  %1372 = inttoptr i64 %1370 to i32*
  %1373 = load i32, i32* %1372, align 4
  %1374 = add i32 %1373, 1
  %1375 = zext i32 %1374 to i64
  store i64 %1375, i64* %RCX, align 8, !tbaa !2428
  %1376 = icmp eq i32 %1373, -1
  %1377 = icmp eq i32 %1374, 0
  %1378 = or i1 %1376, %1377
  %1379 = zext i1 %1378 to i8
  store i8 %1379, i8* %15, align 1, !tbaa !2433
  %1380 = and i32 %1374, 255
  %1381 = tail call i32 @llvm.ctpop.i32(i32 %1380) #10
  %1382 = trunc i32 %1381 to i8
  %1383 = and i8 %1382, 1
  %1384 = xor i8 %1383, 1
  store i8 %1384, i8* %22, align 1, !tbaa !2447
  %1385 = xor i32 %1373, %1374
  %1386 = lshr i32 %1385, 4
  %1387 = trunc i32 %1386 to i8
  %1388 = and i8 %1387, 1
  store i8 %1388, i8* %28, align 1, !tbaa !2451
  %1389 = icmp eq i32 %1374, 0
  %1390 = zext i1 %1389 to i8
  store i8 %1390, i8* %31, align 1, !tbaa !2448
  %1391 = lshr i32 %1374, 31
  %1392 = trunc i32 %1391 to i8
  store i8 %1392, i8* %34, align 1, !tbaa !2449
  %1393 = lshr i32 %1373, 31
  %1394 = xor i32 %1391, %1393
  %1395 = add nuw nsw i32 %1394, %1391
  %1396 = icmp eq i32 %1395, 2
  %1397 = zext i1 %1396 to i8
  store i8 %1397, i8* %40, align 1, !tbaa !2450
  %1398 = sext i32 %1374 to i64
  store i64 %1398, i64* %RDX, align 8, !tbaa !2428
  %1399 = shl nsw i64 %1398, 3
  %1400 = add i64 %1399, %1369
  %1401 = add i64 %1357, 28
  store i64 %1401, i64* %PC, align 8
  %1402 = inttoptr i64 %1400 to double*
  store double %1365, double* %1402, align 8
  %1403 = load i64, i64* %RBP, align 8
  %1404 = add i64 %1403, -56
  %1405 = load i64, i64* %PC, align 8
  %1406 = add i64 %1405, 5
  store i64 %1406, i64* %PC, align 8
  %1407 = inttoptr i64 %1404 to double*
  %1408 = load double, double* %1407, align 8
  store double %1408, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1409 = add i64 %1403, -88
  %1410 = add i64 %1405, 10
  store i64 %1410, i64* %PC, align 8
  %1411 = inttoptr i64 %1409 to double*
  %1412 = load double, double* %1411, align 8
  %1413 = fsub double %1408, %1412
  store double %1413, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1414 = add i64 %1403, -16
  %1415 = add i64 %1405, 14
  store i64 %1415, i64* %PC, align 8
  %1416 = inttoptr i64 %1414 to i64*
  %1417 = load i64, i64* %1416, align 8
  store i64 %1417, i64* %RAX, align 8, !tbaa !2428
  %1418 = add i64 %1403, -36
  %1419 = add i64 %1405, 18
  store i64 %1419, i64* %PC, align 8
  %1420 = inttoptr i64 %1418 to i32*
  %1421 = load i32, i32* %1420, align 4
  %1422 = sext i32 %1421 to i64
  store i64 %1422, i64* %RDX, align 8, !tbaa !2428
  %1423 = shl nsw i64 %1422, 3
  %1424 = add i64 %1423, %1417
  %1425 = add i64 %1405, 23
  store i64 %1425, i64* %PC, align 8
  %1426 = inttoptr i64 %1424 to double*
  store double %1413, double* %1426, align 8
  %1427 = load i64, i64* %RBP, align 8
  %1428 = add i64 %1427, -64
  %1429 = load i64, i64* %PC, align 8
  %1430 = add i64 %1429, 5
  store i64 %1430, i64* %PC, align 8
  %1431 = inttoptr i64 %1428 to double*
  %1432 = load double, double* %1431, align 8
  store double %1432, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1433 = add i64 %1427, -96
  %1434 = add i64 %1429, 10
  store i64 %1434, i64* %PC, align 8
  %1435 = inttoptr i64 %1433 to double*
  %1436 = load double, double* %1435, align 8
  %1437 = fadd double %1432, %1436
  store double %1437, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1438 = add i64 %1427, -16
  %1439 = add i64 %1429, 14
  store i64 %1439, i64* %PC, align 8
  %1440 = inttoptr i64 %1438 to i64*
  %1441 = load i64, i64* %1440, align 8
  store i64 %1441, i64* %RAX, align 8, !tbaa !2428
  %1442 = add i64 %1427, -36
  %1443 = add i64 %1429, 17
  store i64 %1443, i64* %PC, align 8
  %1444 = inttoptr i64 %1442 to i32*
  %1445 = load i32, i32* %1444, align 4
  %1446 = add i32 %1445, 1
  %1447 = zext i32 %1446 to i64
  store i64 %1447, i64* %RCX, align 8, !tbaa !2428
  %1448 = icmp eq i32 %1445, -1
  %1449 = icmp eq i32 %1446, 0
  %1450 = or i1 %1448, %1449
  %1451 = zext i1 %1450 to i8
  store i8 %1451, i8* %15, align 1, !tbaa !2433
  %1452 = and i32 %1446, 255
  %1453 = tail call i32 @llvm.ctpop.i32(i32 %1452) #10
  %1454 = trunc i32 %1453 to i8
  %1455 = and i8 %1454, 1
  %1456 = xor i8 %1455, 1
  store i8 %1456, i8* %22, align 1, !tbaa !2447
  %1457 = xor i32 %1445, %1446
  %1458 = lshr i32 %1457, 4
  %1459 = trunc i32 %1458 to i8
  %1460 = and i8 %1459, 1
  store i8 %1460, i8* %28, align 1, !tbaa !2451
  %1461 = icmp eq i32 %1446, 0
  %1462 = zext i1 %1461 to i8
  store i8 %1462, i8* %31, align 1, !tbaa !2448
  %1463 = lshr i32 %1446, 31
  %1464 = trunc i32 %1463 to i8
  store i8 %1464, i8* %34, align 1, !tbaa !2449
  %1465 = lshr i32 %1445, 31
  %1466 = xor i32 %1463, %1465
  %1467 = add nuw nsw i32 %1466, %1463
  %1468 = icmp eq i32 %1467, 2
  %1469 = zext i1 %1468 to i8
  store i8 %1469, i8* %40, align 1, !tbaa !2450
  %1470 = sext i32 %1446 to i64
  store i64 %1470, i64* %RDX, align 8, !tbaa !2428
  %1471 = shl nsw i64 %1470, 3
  %1472 = add i64 %1471, %1441
  %1473 = add i64 %1429, 28
  store i64 %1473, i64* %PC, align 8
  %1474 = inttoptr i64 %1472 to double*
  store double %1437, double* %1474, align 8
  %1475 = load i64, i64* %RBP, align 8
  %1476 = add i64 %1475, -72
  %1477 = load i64, i64* %PC, align 8
  %1478 = add i64 %1477, 5
  store i64 %1478, i64* %PC, align 8
  %1479 = inttoptr i64 %1476 to double*
  %1480 = load double, double* %1479, align 8
  store double %1480, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1481 = add i64 %1475, -112
  %1482 = add i64 %1477, 10
  store i64 %1482, i64* %PC, align 8
  %1483 = inttoptr i64 %1481 to double*
  %1484 = load double, double* %1483, align 8
  %1485 = fsub double %1480, %1484
  store double %1485, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1486 = add i64 %1475, -16
  %1487 = add i64 %1477, 14
  store i64 %1487, i64* %PC, align 8
  %1488 = inttoptr i64 %1486 to i64*
  %1489 = load i64, i64* %1488, align 8
  store i64 %1489, i64* %RAX, align 8, !tbaa !2428
  %1490 = add i64 %1475, -32
  %1491 = add i64 %1477, 18
  store i64 %1491, i64* %PC, align 8
  %1492 = inttoptr i64 %1490 to i32*
  %1493 = load i32, i32* %1492, align 4
  %1494 = sext i32 %1493 to i64
  store i64 %1494, i64* %RDX, align 8, !tbaa !2428
  %1495 = shl nsw i64 %1494, 3
  %1496 = add i64 %1495, %1489
  %1497 = add i64 %1477, 23
  store i64 %1497, i64* %PC, align 8
  %1498 = inttoptr i64 %1496 to double*
  store double %1485, double* %1498, align 8
  %1499 = load i64, i64* %RBP, align 8
  %1500 = add i64 %1499, -80
  %1501 = load i64, i64* %PC, align 8
  %1502 = add i64 %1501, 5
  store i64 %1502, i64* %PC, align 8
  %1503 = inttoptr i64 %1500 to double*
  %1504 = load double, double* %1503, align 8
  store double %1504, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1505 = add i64 %1499, -104
  %1506 = add i64 %1501, 10
  store i64 %1506, i64* %PC, align 8
  %1507 = inttoptr i64 %1505 to double*
  %1508 = load double, double* %1507, align 8
  %1509 = fsub double %1504, %1508
  store double %1509, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1510 = add i64 %1499, -16
  %1511 = add i64 %1501, 14
  store i64 %1511, i64* %PC, align 8
  %1512 = inttoptr i64 %1510 to i64*
  %1513 = load i64, i64* %1512, align 8
  store i64 %1513, i64* %RAX, align 8, !tbaa !2428
  %1514 = add i64 %1499, -32
  %1515 = add i64 %1501, 17
  store i64 %1515, i64* %PC, align 8
  %1516 = inttoptr i64 %1514 to i32*
  %1517 = load i32, i32* %1516, align 4
  %1518 = add i32 %1517, 1
  %1519 = zext i32 %1518 to i64
  store i64 %1519, i64* %RCX, align 8, !tbaa !2428
  %1520 = icmp eq i32 %1517, -1
  %1521 = icmp eq i32 %1518, 0
  %1522 = or i1 %1520, %1521
  %1523 = zext i1 %1522 to i8
  store i8 %1523, i8* %15, align 1, !tbaa !2433
  %1524 = and i32 %1518, 255
  %1525 = tail call i32 @llvm.ctpop.i32(i32 %1524) #10
  %1526 = trunc i32 %1525 to i8
  %1527 = and i8 %1526, 1
  %1528 = xor i8 %1527, 1
  store i8 %1528, i8* %22, align 1, !tbaa !2447
  %1529 = xor i32 %1517, %1518
  %1530 = lshr i32 %1529, 4
  %1531 = trunc i32 %1530 to i8
  %1532 = and i8 %1531, 1
  store i8 %1532, i8* %28, align 1, !tbaa !2451
  %1533 = icmp eq i32 %1518, 0
  %1534 = zext i1 %1533 to i8
  store i8 %1534, i8* %31, align 1, !tbaa !2448
  %1535 = lshr i32 %1518, 31
  %1536 = trunc i32 %1535 to i8
  store i8 %1536, i8* %34, align 1, !tbaa !2449
  %1537 = lshr i32 %1517, 31
  %1538 = xor i32 %1535, %1537
  %1539 = add nuw nsw i32 %1538, %1535
  %1540 = icmp eq i32 %1539, 2
  %1541 = zext i1 %1540 to i8
  store i8 %1541, i8* %40, align 1, !tbaa !2450
  %1542 = sext i32 %1518 to i64
  store i64 %1542, i64* %RDX, align 8, !tbaa !2428
  %1543 = shl nsw i64 %1542, 3
  %1544 = add i64 %1543, %1513
  %1545 = add i64 %1501, 28
  store i64 %1545, i64* %PC, align 8
  %1546 = inttoptr i64 %1544 to double*
  store double %1509, double* %1546, align 8
  %1547 = load i64, i64* %RBP, align 8
  %1548 = add i64 %1547, -72
  %1549 = load i64, i64* %PC, align 8
  %1550 = add i64 %1549, 5
  store i64 %1550, i64* %PC, align 8
  %1551 = inttoptr i64 %1548 to double*
  %1552 = load double, double* %1551, align 8
  store double %1552, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1553 = add i64 %1547, -112
  %1554 = add i64 %1549, 10
  store i64 %1554, i64* %PC, align 8
  %1555 = inttoptr i64 %1553 to double*
  %1556 = load double, double* %1555, align 8
  %1557 = fadd double %1552, %1556
  store double %1557, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1558 = add i64 %1547, -16
  %1559 = add i64 %1549, 14
  store i64 %1559, i64* %PC, align 8
  %1560 = inttoptr i64 %1558 to i64*
  %1561 = load i64, i64* %1560, align 8
  store i64 %1561, i64* %RAX, align 8, !tbaa !2428
  %1562 = add i64 %1547, -40
  %1563 = add i64 %1549, 18
  store i64 %1563, i64* %PC, align 8
  %1564 = inttoptr i64 %1562 to i32*
  %1565 = load i32, i32* %1564, align 4
  %1566 = sext i32 %1565 to i64
  store i64 %1566, i64* %RDX, align 8, !tbaa !2428
  %1567 = shl nsw i64 %1566, 3
  %1568 = add i64 %1567, %1561
  %1569 = add i64 %1549, 23
  store i64 %1569, i64* %PC, align 8
  %1570 = inttoptr i64 %1568 to double*
  store double %1557, double* %1570, align 8
  %1571 = load i64, i64* %RBP, align 8
  %1572 = add i64 %1571, -80
  %1573 = load i64, i64* %PC, align 8
  %1574 = add i64 %1573, 5
  store i64 %1574, i64* %PC, align 8
  %1575 = inttoptr i64 %1572 to double*
  %1576 = load double, double* %1575, align 8
  store double %1576, double* %1702, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2452
  %1577 = add i64 %1571, -104
  %1578 = add i64 %1573, 10
  store i64 %1578, i64* %PC, align 8
  %1579 = inttoptr i64 %1577 to double*
  %1580 = load double, double* %1579, align 8
  %1581 = fadd double %1576, %1580
  store double %1581, double* %1702, align 1, !tbaa !2452
  store i64 0, i64* %1703, align 1, !tbaa !2452
  %1582 = add i64 %1571, -16
  %1583 = add i64 %1573, 14
  store i64 %1583, i64* %PC, align 8
  %1584 = inttoptr i64 %1582 to i64*
  %1585 = load i64, i64* %1584, align 8
  store i64 %1585, i64* %RAX, align 8, !tbaa !2428
  %1586 = add i64 %1571, -40
  %1587 = add i64 %1573, 17
  store i64 %1587, i64* %PC, align 8
  %1588 = inttoptr i64 %1586 to i32*
  %1589 = load i32, i32* %1588, align 4
  %1590 = add i32 %1589, 1
  %1591 = zext i32 %1590 to i64
  store i64 %1591, i64* %RCX, align 8, !tbaa !2428
  %1592 = icmp eq i32 %1589, -1
  %1593 = icmp eq i32 %1590, 0
  %1594 = or i1 %1592, %1593
  %1595 = zext i1 %1594 to i8
  store i8 %1595, i8* %15, align 1, !tbaa !2433
  %1596 = and i32 %1590, 255
  %1597 = tail call i32 @llvm.ctpop.i32(i32 %1596) #10
  %1598 = trunc i32 %1597 to i8
  %1599 = and i8 %1598, 1
  %1600 = xor i8 %1599, 1
  store i8 %1600, i8* %22, align 1, !tbaa !2447
  %1601 = xor i32 %1589, %1590
  %1602 = lshr i32 %1601, 4
  %1603 = trunc i32 %1602 to i8
  %1604 = and i8 %1603, 1
  store i8 %1604, i8* %28, align 1, !tbaa !2451
  %1605 = icmp eq i32 %1590, 0
  %1606 = zext i1 %1605 to i8
  store i8 %1606, i8* %31, align 1, !tbaa !2448
  %1607 = lshr i32 %1590, 31
  %1608 = trunc i32 %1607 to i8
  store i8 %1608, i8* %34, align 1, !tbaa !2449
  %1609 = lshr i32 %1589, 31
  %1610 = xor i32 %1607, %1609
  %1611 = add nuw nsw i32 %1610, %1607
  %1612 = icmp eq i32 %1611, 2
  %1613 = zext i1 %1612 to i8
  store i8 %1613, i8* %40, align 1, !tbaa !2450
  %1614 = sext i32 %1590 to i64
  store i64 %1614, i64* %RDX, align 8, !tbaa !2428
  %1615 = shl nsw i64 %1614, 3
  %1616 = add i64 %1615, %1585
  %1617 = add i64 %1573, 28
  store i64 %1617, i64* %PC, align 8
  %1618 = inttoptr i64 %1616 to double*
  store double %1581, double* %1618, align 8
  %1619 = load i64, i64* %RBP, align 8
  %1620 = add i64 %1619, -28
  %1621 = load i64, i64* %PC, align 8
  %1622 = add i64 %1621, 3
  store i64 %1622, i64* %PC, align 8
  %1623 = inttoptr i64 %1620 to i32*
  %1624 = load i32, i32* %1623, align 4
  %1625 = add i32 %1624, 2
  %1626 = zext i32 %1625 to i64
  store i64 %1626, i64* %RAX, align 8, !tbaa !2428
  %1627 = icmp ugt i32 %1624, -3
  %1628 = zext i1 %1627 to i8
  store i8 %1628, i8* %15, align 1, !tbaa !2433
  %1629 = and i32 %1625, 255
  %1630 = tail call i32 @llvm.ctpop.i32(i32 %1629) #10
  %1631 = trunc i32 %1630 to i8
  %1632 = and i8 %1631, 1
  %1633 = xor i8 %1632, 1
  store i8 %1633, i8* %22, align 1, !tbaa !2447
  %1634 = xor i32 %1624, %1625
  %1635 = lshr i32 %1634, 4
  %1636 = trunc i32 %1635 to i8
  %1637 = and i8 %1636, 1
  store i8 %1637, i8* %28, align 1, !tbaa !2451
  %1638 = icmp eq i32 %1625, 0
  %1639 = zext i1 %1638 to i8
  store i8 %1639, i8* %31, align 1, !tbaa !2448
  %1640 = lshr i32 %1625, 31
  %1641 = trunc i32 %1640 to i8
  store i8 %1641, i8* %34, align 1, !tbaa !2449
  %1642 = lshr i32 %1624, 31
  %1643 = xor i32 %1640, %1642
  %1644 = add nuw nsw i32 %1643, %1640
  %1645 = icmp eq i32 %1644, 2
  %1646 = zext i1 %1645 to i8
  store i8 %1646, i8* %40, align 1, !tbaa !2450
  %1647 = add i64 %1621, 9
  store i64 %1647, i64* %PC, align 8
  store i32 %1625, i32* %1623, align 4
  %1648 = load i64, i64* %PC, align 8
  %1649 = add i64 %1648, -576
  store i64 %1649, i64* %92, align 8, !tbaa !2428
  br label %block_402506

block_4024f0:                                     ; preds = %block_4024eb, %block_402480
  %1650 = phi i64 [ %93, %block_402480 ], [ %734, %block_4024eb ]
  %1651 = phi i64 [ %62, %block_402480 ], [ %133, %block_4024eb ]
  %MEMORY.4 = phi %struct.Memory* [ %2, %block_402480 ], [ %MEMORY.1, %block_4024eb ]
  %1652 = add i64 %1651, -44
  %1653 = add i64 %1650, 3
  store i64 %1653, i64* %PC, align 8
  %1654 = inttoptr i64 %1652 to i32*
  %1655 = load i32, i32* %1654, align 4
  %1656 = shl i32 %1655, 2
  %1657 = zext i32 %1656 to i64
  store i64 %1657, i64* %RAX, align 8, !tbaa !2428
  %1658 = lshr i32 %1655, 30
  %1659 = trunc i32 %1658 to i8
  %1660 = and i8 %1659, 1
  store i8 %1660, i8* %15, align 1, !tbaa !2432
  %1661 = and i32 %1656, 252
  %1662 = tail call i32 @llvm.ctpop.i32(i32 %1661) #10
  %1663 = trunc i32 %1662 to i8
  %1664 = and i8 %1663, 1
  %1665 = xor i8 %1664, 1
  store i8 %1665, i8* %22, align 1, !tbaa !2432
  store i8 0, i8* %28, align 1, !tbaa !2432
  %1666 = icmp eq i32 %1656, 0
  %1667 = zext i1 %1666 to i8
  store i8 %1667, i8* %31, align 1, !tbaa !2432
  %1668 = lshr i32 %1655, 29
  %1669 = and i32 %1668, 1
  %1670 = trunc i32 %1669 to i8
  store i8 %1670, i8* %34, align 1, !tbaa !2432
  store i8 0, i8* %40, align 1, !tbaa !2432
  %1671 = add i64 %1651, -4
  %1672 = add i64 %1650, 9
  store i64 %1672, i64* %PC, align 8
  %1673 = inttoptr i64 %1671 to i32*
  %1674 = load i32, i32* %1673, align 4
  %1675 = sub i32 %1656, %1674
  %1676 = icmp ult i32 %1656, %1674
  %1677 = zext i1 %1676 to i8
  store i8 %1677, i8* %15, align 1, !tbaa !2433
  %1678 = and i32 %1675, 255
  %1679 = tail call i32 @llvm.ctpop.i32(i32 %1678) #10
  %1680 = trunc i32 %1679 to i8
  %1681 = and i8 %1680, 1
  %1682 = xor i8 %1681, 1
  store i8 %1682, i8* %22, align 1, !tbaa !2447
  %1683 = xor i32 %1674, %1656
  %1684 = xor i32 %1683, %1675
  %1685 = lshr i32 %1684, 4
  %1686 = trunc i32 %1685 to i8
  %1687 = and i8 %1686, 1
  store i8 %1687, i8* %28, align 1, !tbaa !2451
  %1688 = icmp eq i32 %1675, 0
  %1689 = zext i1 %1688 to i8
  store i8 %1689, i8* %31, align 1, !tbaa !2448
  %1690 = lshr i32 %1675, 31
  %1691 = trunc i32 %1690 to i8
  store i8 %1691, i8* %34, align 1, !tbaa !2449
  %1692 = lshr i32 %1674, 31
  %1693 = xor i32 %1692, %1669
  %1694 = xor i32 %1690, %1669
  %1695 = add nuw nsw i32 %1694, %1693
  %1696 = icmp eq i32 %1695, 2
  %1697 = zext i1 %1696 to i8
  store i8 %1697, i8* %40, align 1, !tbaa !2450
  %.v6 = select i1 %1688, i64 15, i64 608
  %1698 = add i64 %1650, %.v6
  %1699 = add i64 %1651, -28
  %1700 = add i64 %1698, 7
  store i64 %1700, i64* %PC, align 8
  %1701 = inttoptr i64 %1699 to i32*
  store i32 0, i32* %1701, align 4
  %1702 = bitcast %union.VectorReg* %4 to double*
  %1703 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1704 = bitcast i64* %1703 to double*
  %1705 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  %.pre3 = load i64, i64* %PC, align 8
  br i1 %1688, label %block_402506, label %block_402757
}

; Function Attrs: noinline
define %struct.Memory* @sub_4007c0___do_global_dtors_aux(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_4007c0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i8, i8* getelementptr inbounds (%__bss_start_type, %__bss_start_type* @__bss_start, i64 0, i32 0, i64 0), align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %4, align 1, !tbaa !2433
  %5 = zext i8 %3 to i32
  %6 = tail call i32 @llvm.ctpop.i32(i32 %5) #10
  %7 = trunc i32 %6 to i8
  %8 = and i8 %7, 1
  %9 = xor i8 %8, 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %9, i8* %10, align 1, !tbaa !2447
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %11, align 1, !tbaa !2451
  %12 = icmp eq i8 %3, 0
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %13, i8* %14, align 1, !tbaa !2448
  %15 = lshr i8 %3, 7
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %15, i8* %16, align 1, !tbaa !2449
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %17, align 1, !tbaa !2450
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %.v = select i1 %12, i64 9, i64 32
  %19 = add i64 %.v, %1
  store i64 %19, i64* %18, align 8, !tbaa !2428
  br i1 %12, label %block_4007c9, label %block_4007e0

block_4007e0:                                     ; preds = %block_4007c0
  %20 = add i64 %19, 2
  store i64 %20, i64* %PC, align 8
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %22 = load i64, i64* %21, align 8, !tbaa !2428
  %23 = inttoptr i64 %22 to i64*
  %24 = load i64, i64* %23, align 8
  store i64 %24, i64* %18, align 8, !tbaa !2428
  %25 = add i64 %22, 8
  store i64 %25, i64* %21, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_4007c9:                                     ; preds = %block_4007c0
  %26 = load i64, i64* %RBP, align 8
  %27 = add i64 %19, 1
  store i64 %27, i64* %PC, align 8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %29 = load i64, i64* %28, align 8, !tbaa !2428
  %30 = add i64 %29, -8
  %31 = inttoptr i64 %30 to i64*
  store i64 %26, i64* %31, align 8
  %32 = load i64, i64* %PC, align 8
  store i64 %30, i64* %RBP, align 8, !tbaa !2428
  %33 = add i64 %32, -122
  %34 = add i64 %32, 8
  %35 = add i64 %29, -16
  %36 = inttoptr i64 %35 to i64*
  store i64 %34, i64* %36, align 8
  store i64 %35, i64* %28, align 8, !tbaa !2428
  store i64 %33, i64* %18, align 8, !tbaa !2428
  %37 = tail call %struct.Memory* @sub_400750_deregister_tm_clones_renamed_(%struct.State* nonnull %0, i64 %33, %struct.Memory* %2)
  %38 = load i64, i64* %PC, align 8
  store i8 1, i8* getelementptr inbounds (%__bss_start_type, %__bss_start_type* @__bss_start, i64 0, i32 0, i64 0), align 8
  %39 = add i64 %38, 8
  store i64 %39, i64* %PC, align 8
  %40 = load i64, i64* %28, align 8, !tbaa !2428
  %41 = add i64 %40, 8
  %42 = inttoptr i64 %40 to i64*
  %43 = load i64, i64* %42, align 8
  store i64 %43, i64* %RBP, align 8, !tbaa !2428
  store i64 %41, i64* %28, align 8, !tbaa !2428
  %44 = add i64 %38, 9
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %41 to i64*
  %46 = load i64, i64* %45, align 8
  store i64 %46, i64* %18, align 8, !tbaa !2428
  %47 = add i64 %40, 16
  store i64 %47, i64* %28, align 8, !tbaa !2428
  ret %struct.Memory* %37
}

; Function Attrs: noinline
define %struct.Memory* @sub_401030_cdft(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_401030:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %4 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %8 = load i64, i64* %7, align 8, !tbaa !2428
  %9 = add i64 %8, -8
  %10 = inttoptr i64 %9 to i64*
  store i64 %5, i64* %10, align 8
  %11 = load i64, i64* %PC, align 8
  store i64 %9, i64* %RBP, align 8, !tbaa !2428
  %12 = add i64 %8, -40
  store i64 %12, i64* %RSP, align 8, !tbaa !2428
  %13 = icmp ult i64 %9, 32
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1, !tbaa !2433
  %16 = trunc i64 %12 to i32
  %17 = and i32 %16, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17) #10
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1, !tbaa !2447
  %23 = xor i64 %9, %12
  %24 = lshr i64 %23, 4
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1, !tbaa !2451
  %28 = icmp eq i64 %12, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1, !tbaa !2448
  %31 = lshr i64 %12, 63
  %32 = trunc i64 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1, !tbaa !2449
  %34 = lshr i64 %9, 63
  %35 = xor i64 %31, %34
  %36 = add nuw nsw i64 %35, %34
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1, !tbaa !2450
  %40 = add i64 %8, -12
  %41 = load i32, i32* %EDI, align 4
  %42 = add i64 %11, 10
  store i64 %42, i64* %PC, align 8
  %43 = inttoptr i64 %40 to i32*
  store i32 %41, i32* %43, align 4
  %44 = load i64, i64* %RBP, align 8
  %45 = add i64 %44, -8
  %46 = load i32, i32* %ESI, align 4
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 3
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %45 to i32*
  store i32 %46, i32* %49, align 4
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -16
  %52 = load i64, i64* %RDX, align 8
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 4
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %51 to i64*
  store i64 %52, i64* %55, align 8
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -24
  %58 = load i64, i64* %RCX, align 8
  %59 = load i64, i64* %PC, align 8
  %60 = add i64 %59, 4
  store i64 %60, i64* %PC, align 8
  %61 = inttoptr i64 %57 to i64*
  store i64 %58, i64* %61, align 8
  %62 = load i64, i64* %RBP, align 8
  %63 = add i64 %62, -32
  %64 = load i64, i64* %R8, align 8
  %65 = load i64, i64* %PC, align 8
  %66 = add i64 %65, 4
  store i64 %66, i64* %PC, align 8
  %67 = inttoptr i64 %63 to i64*
  store i64 %64, i64* %67, align 8
  %68 = load i64, i64* %RBP, align 8
  %69 = add i64 %68, -4
  %70 = load i64, i64* %PC, align 8
  %71 = add i64 %70, 4
  store i64 %71, i64* %PC, align 8
  %72 = inttoptr i64 %69 to i32*
  %73 = load i32, i32* %72, align 4
  %74 = add i32 %73, -4
  %75 = icmp ult i32 %73, 4
  %76 = zext i1 %75 to i8
  store i8 %76, i8* %15, align 1, !tbaa !2433
  %77 = and i32 %74, 255
  %78 = tail call i32 @llvm.ctpop.i32(i32 %77) #10
  %79 = trunc i32 %78 to i8
  %80 = and i8 %79, 1
  %81 = xor i8 %80, 1
  store i8 %81, i8* %22, align 1, !tbaa !2447
  %82 = xor i32 %73, %74
  %83 = lshr i32 %82, 4
  %84 = trunc i32 %83 to i8
  %85 = and i8 %84, 1
  store i8 %85, i8* %27, align 1, !tbaa !2451
  %86 = icmp eq i32 %74, 0
  %87 = zext i1 %86 to i8
  store i8 %87, i8* %30, align 1, !tbaa !2448
  %88 = lshr i32 %74, 31
  %89 = trunc i32 %88 to i8
  store i8 %89, i8* %33, align 1, !tbaa !2449
  %90 = lshr i32 %73, 31
  %91 = xor i32 %88, %90
  %92 = add nuw nsw i32 %91, %90
  %93 = icmp eq i32 %92, 2
  %94 = zext i1 %93 to i8
  store i8 %94, i8* %39, align 1, !tbaa !2450
  %95 = icmp ne i8 %89, 0
  %96 = xor i1 %95, %93
  %97 = or i1 %86, %96
  %98 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %.v = select i1 %97, i64 94, i64 10
  %99 = add i64 %70, %.v
  store i64 %99, i64* %98, align 8, !tbaa !2428
  br i1 %97, label %block_4010a8, label %block_401054

block_40105e:                                     ; preds = %block_401054
  %100 = add i64 %244, 354
  %101 = add i64 %244, 16
  %102 = load i64, i64* %7, align 8, !tbaa !2428
  %103 = add i64 %102, -8
  %104 = inttoptr i64 %103 to i64*
  store i64 %101, i64* %104, align 8
  store i64 %103, i64* %7, align 8, !tbaa !2428
  store i64 %100, i64* %98, align 8, !tbaa !2428
  %105 = tail call %struct.Memory* @sub_4011c0_bitrv2_renamed_(%struct.State* nonnull %0, i64 %100, %struct.Memory* %2)
  %106 = load i64, i64* %RBP, align 8
  %107 = add i64 %106, -4
  %108 = load i64, i64* %PC, align 8
  %109 = add i64 %108, 3
  store i64 %109, i64* %PC, align 8
  %110 = inttoptr i64 %107 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = zext i32 %111 to i64
  store i64 %112, i64* %RDI, align 8, !tbaa !2428
  %113 = add i64 %106, -16
  %114 = add i64 %108, 7
  store i64 %114, i64* %PC, align 8
  %115 = inttoptr i64 %113 to i64*
  %116 = load i64, i64* %115, align 8
  store i64 %116, i64* %RSI, align 8, !tbaa !2428
  %117 = add i64 %106, -32
  %118 = add i64 %108, 11
  store i64 %118, i64* %PC, align 8
  %119 = inttoptr i64 %117 to i64*
  %120 = load i64, i64* %119, align 8
  store i64 %120, i64* %RDX, align 8, !tbaa !2428
  %121 = add i64 %108, 2002
  %122 = add i64 %108, 16
  %123 = load i64, i64* %7, align 8, !tbaa !2428
  %124 = add i64 %123, -8
  %125 = inttoptr i64 %124 to i64*
  store i64 %122, i64* %125, align 8
  store i64 %124, i64* %7, align 8, !tbaa !2428
  store i64 %121, i64* %98, align 8, !tbaa !2428
  %126 = tail call %struct.Memory* @sub_401840_cftfsub_renamed_(%struct.State* nonnull %0, i64 %121, %struct.Memory* %105)
  %127 = load i64, i64* %PC, align 8
  %128 = add i64 %127, 37
  store i64 %128, i64* %98, align 8, !tbaa !2428
  br label %block_4010a3

block_4010a3:                                     ; preds = %block_401083, %block_40105e
  %129 = phi i64 [ %.pre, %block_401083 ], [ %128, %block_40105e ]
  %MEMORY.0 = phi %struct.Memory* [ %229, %block_401083 ], [ %126, %block_40105e ]
  %130 = add i64 %129, 36
  br label %block_4010c7

block_4010b2:                                     ; preds = %block_4010a8
  %131 = add i64 %171, 3
  store i64 %131, i64* %PC, align 8
  %132 = load i32, i32* %72, align 4
  %133 = zext i32 %132 to i64
  store i64 %133, i64* %RDI, align 8, !tbaa !2428
  %134 = add i64 %68, -16
  %135 = add i64 %171, 7
  store i64 %135, i64* %PC, align 8
  %136 = inttoptr i64 %134 to i64*
  %137 = load i64, i64* %136, align 8
  store i64 %137, i64* %RSI, align 8, !tbaa !2428
  %138 = add i64 %68, -32
  %139 = add i64 %171, 11
  store i64 %139, i64* %PC, align 8
  %140 = inttoptr i64 %138 to i64*
  %141 = load i64, i64* %140, align 8
  store i64 %141, i64* %RDX, align 8, !tbaa !2428
  %142 = add i64 %171, 1934
  %143 = add i64 %171, 16
  %144 = load i64, i64* %7, align 8, !tbaa !2428
  %145 = add i64 %144, -8
  %146 = inttoptr i64 %145 to i64*
  store i64 %143, i64* %146, align 8
  store i64 %145, i64* %7, align 8, !tbaa !2428
  store i64 %142, i64* %98, align 8, !tbaa !2428
  %147 = tail call %struct.Memory* @sub_401840_cftfsub_renamed_(%struct.State* nonnull %0, i64 %142, %struct.Memory* %2)
  %.pre1 = load i64, i64* %PC, align 8
  br label %block_4010c2

block_4010a8:                                     ; preds = %block_401030
  %148 = add i64 %99, 4
  store i64 %148, i64* %PC, align 8
  %149 = load i32, i32* %72, align 4
  %150 = add i32 %149, -4
  %151 = icmp ult i32 %149, 4
  %152 = zext i1 %151 to i8
  store i8 %152, i8* %15, align 1, !tbaa !2433
  %153 = and i32 %150, 255
  %154 = tail call i32 @llvm.ctpop.i32(i32 %153) #10
  %155 = trunc i32 %154 to i8
  %156 = and i8 %155, 1
  %157 = xor i8 %156, 1
  store i8 %157, i8* %22, align 1, !tbaa !2447
  %158 = xor i32 %149, %150
  %159 = lshr i32 %158, 4
  %160 = trunc i32 %159 to i8
  %161 = and i8 %160, 1
  store i8 %161, i8* %27, align 1, !tbaa !2451
  %162 = icmp eq i32 %150, 0
  %163 = zext i1 %162 to i8
  store i8 %163, i8* %30, align 1, !tbaa !2448
  %164 = lshr i32 %150, 31
  %165 = trunc i32 %164 to i8
  store i8 %165, i8* %33, align 1, !tbaa !2449
  %166 = lshr i32 %149, 31
  %167 = xor i32 %164, %166
  %168 = add nuw nsw i32 %167, %166
  %169 = icmp eq i32 %168, 2
  %170 = zext i1 %169 to i8
  store i8 %170, i8* %39, align 1, !tbaa !2450
  %.v4 = select i1 %162, i64 10, i64 26
  %171 = add i64 %99, %.v4
  store i64 %171, i64* %98, align 8, !tbaa !2428
  br i1 %162, label %block_4010b2, label %block_4010c2

block_4010c7:                                     ; preds = %block_4010c2, %block_4010a3
  %.sink = phi i64 [ %257, %block_4010c2 ], [ %130, %block_4010a3 ]
  %MEMORY.1 = phi %struct.Memory* [ %MEMORY.2, %block_4010c2 ], [ %MEMORY.0, %block_4010a3 ]
  %172 = load i64, i64* %RSP, align 8
  %173 = add i64 %172, 32
  store i64 %173, i64* %RSP, align 8, !tbaa !2428
  %174 = icmp ugt i64 %172, -33
  %175 = zext i1 %174 to i8
  store i8 %175, i8* %15, align 1, !tbaa !2433
  %176 = trunc i64 %173 to i32
  %177 = and i32 %176, 255
  %178 = tail call i32 @llvm.ctpop.i32(i32 %177) #10
  %179 = trunc i32 %178 to i8
  %180 = and i8 %179, 1
  %181 = xor i8 %180, 1
  store i8 %181, i8* %22, align 1, !tbaa !2447
  %182 = xor i64 %172, %173
  %183 = lshr i64 %182, 4
  %184 = trunc i64 %183 to i8
  %185 = and i8 %184, 1
  store i8 %185, i8* %27, align 1, !tbaa !2451
  %186 = icmp eq i64 %173, 0
  %187 = zext i1 %186 to i8
  store i8 %187, i8* %30, align 1, !tbaa !2448
  %188 = lshr i64 %173, 63
  %189 = trunc i64 %188 to i8
  store i8 %189, i8* %33, align 1, !tbaa !2449
  %190 = lshr i64 %172, 63
  %191 = xor i64 %188, %190
  %192 = add nuw nsw i64 %191, %188
  %193 = icmp eq i64 %192, 2
  %194 = zext i1 %193 to i8
  store i8 %194, i8* %39, align 1, !tbaa !2450
  %195 = add i64 %.sink, 5
  store i64 %195, i64* %PC, align 8
  %196 = add i64 %172, 40
  %197 = inttoptr i64 %173 to i64*
  %198 = load i64, i64* %197, align 8
  store i64 %198, i64* %RBP, align 8, !tbaa !2428
  store i64 %196, i64* %7, align 8, !tbaa !2428
  %199 = add i64 %.sink, 6
  store i64 %199, i64* %PC, align 8
  %200 = inttoptr i64 %196 to i64*
  %201 = load i64, i64* %200, align 8
  store i64 %201, i64* %98, align 8, !tbaa !2428
  %202 = add i64 %172, 48
  store i64 %202, i64* %7, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.1

block_401083:                                     ; preds = %block_401054
  %203 = add i64 %244, 2909
  %204 = add i64 %244, 16
  %205 = load i64, i64* %7, align 8, !tbaa !2428
  %206 = add i64 %205, -8
  %207 = inttoptr i64 %206 to i64*
  store i64 %204, i64* %207, align 8
  store i64 %206, i64* %7, align 8, !tbaa !2428
  store i64 %203, i64* %98, align 8, !tbaa !2428
  %208 = tail call %struct.Memory* @sub_401be0_bitrv2conj_renamed_(%struct.State* nonnull %0, i64 %203, %struct.Memory* %2)
  %209 = load i64, i64* %RBP, align 8
  %210 = add i64 %209, -4
  %211 = load i64, i64* %PC, align 8
  %212 = add i64 %211, 3
  store i64 %212, i64* %PC, align 8
  %213 = inttoptr i64 %210 to i32*
  %214 = load i32, i32* %213, align 4
  %215 = zext i32 %214 to i64
  store i64 %215, i64* %RDI, align 8, !tbaa !2428
  %216 = add i64 %209, -16
  %217 = add i64 %211, 7
  store i64 %217, i64* %PC, align 8
  %218 = inttoptr i64 %216 to i64*
  %219 = load i64, i64* %218, align 8
  store i64 %219, i64* %RSI, align 8, !tbaa !2428
  %220 = add i64 %209, -32
  %221 = add i64 %211, 11
  store i64 %221, i64* %PC, align 8
  %222 = inttoptr i64 %220 to i64*
  %223 = load i64, i64* %222, align 8
  store i64 %223, i64* %RDX, align 8, !tbaa !2428
  %224 = add i64 %211, 5101
  %225 = add i64 %211, 16
  %226 = load i64, i64* %7, align 8, !tbaa !2428
  %227 = add i64 %226, -8
  %228 = inttoptr i64 %227 to i64*
  store i64 %225, i64* %228, align 8
  store i64 %227, i64* %7, align 8, !tbaa !2428
  store i64 %224, i64* %98, align 8, !tbaa !2428
  %229 = tail call %struct.Memory* @sub_402480_cftbsub_renamed_(%struct.State* nonnull %0, i64 %224, %struct.Memory* %208)
  %.pre = load i64, i64* %PC, align 8
  br label %block_4010a3

block_401054:                                     ; preds = %block_401030
  %230 = add i64 %68, -8
  %231 = add i64 %99, 4
  store i64 %231, i64* %PC, align 8
  %232 = inttoptr i64 %230 to i32*
  %233 = load i32, i32* %232, align 4
  store i8 0, i8* %15, align 1, !tbaa !2433
  %234 = and i32 %233, 255
  %235 = tail call i32 @llvm.ctpop.i32(i32 %234) #10
  %236 = trunc i32 %235 to i8
  %237 = and i8 %236, 1
  %238 = xor i8 %237, 1
  store i8 %238, i8* %22, align 1, !tbaa !2447
  store i8 0, i8* %27, align 1, !tbaa !2451
  %239 = icmp eq i32 %233, 0
  %240 = zext i1 %239 to i8
  store i8 %240, i8* %30, align 1, !tbaa !2448
  %241 = lshr i32 %233, 31
  %242 = trunc i32 %241 to i8
  store i8 %242, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  %243 = icmp ne i8 %242, 0
  %.v3 = select i1 %243, i64 47, i64 10
  %244 = add i64 %99, %.v3
  %245 = add i64 %244, 3
  store i64 %245, i64* %PC, align 8
  %246 = load i32, i32* %72, align 4
  %247 = zext i32 %246 to i64
  store i64 %247, i64* %RDI, align 8, !tbaa !2428
  %248 = add i64 %68, -24
  %249 = add i64 %244, 7
  store i64 %249, i64* %PC, align 8
  %250 = inttoptr i64 %248 to i64*
  %251 = load i64, i64* %250, align 8
  store i64 %251, i64* %RSI, align 8, !tbaa !2428
  %252 = add i64 %68, -16
  %253 = add i64 %244, 11
  store i64 %253, i64* %PC, align 8
  %254 = inttoptr i64 %252 to i64*
  %255 = load i64, i64* %254, align 8
  store i64 %255, i64* %RDX, align 8, !tbaa !2428
  br i1 %243, label %block_401083, label %block_40105e

block_4010c2:                                     ; preds = %block_4010a8, %block_4010b2
  %256 = phi i64 [ %171, %block_4010a8 ], [ %.pre1, %block_4010b2 ]
  %MEMORY.2 = phi %struct.Memory* [ %2, %block_4010a8 ], [ %147, %block_4010b2 ]
  %257 = add i64 %256, 5
  br label %block_4010c7
}

; Function Attrs: noinline
define %struct.Memory* @sub_400638__init_proc(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400638:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = add i64 %3, -8
  store i64 %4, i64* %RSP, align 8, !tbaa !2428
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_604ff0__got_type* @seg_604ff0__got to i64), i64 8) to i64*), align 8
  store i64 %11, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %5, align 1, !tbaa !2433
  %12 = trunc i64 %11 to i32
  %13 = and i32 %12, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13) #10
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %6, align 1, !tbaa !2447
  %18 = icmp eq i64 %11, 0
  %19 = zext i1 %18 to i8
  store i8 %19, i8* %8, align 1, !tbaa !2448
  %20 = lshr i64 %11, 63
  %21 = trunc i64 %20 to i8
  store i8 %21, i8* %9, align 1, !tbaa !2449
  store i8 0, i8* %10, align 1, !tbaa !2450
  store i8 0, i8* %7, align 1, !tbaa !2451
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %.v = select i1 %18, i64 18, i64 16
  %23 = add i64 %.v, %1
  store i64 %23, i64* %22, align 8, !tbaa !2428
  br i1 %18, label %block_400638.block_40064a_crit_edge, label %block_400648

block_400638.block_40064a_crit_edge:              ; preds = %block_400638
  %.pre2 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  br label %block_40064a

block_400648:                                     ; preds = %block_400638
  %24 = add i64 %23, 2
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %26 = add i64 %3, -16
  %27 = inttoptr i64 %26 to i64*
  store i64 %24, i64* %27, align 8
  store i64 %26, i64* %25, align 8, !tbaa !2428
  store i64 %11, i64* %22, align 8, !tbaa !2428
  %28 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 %11, %struct.Memory* %2)
  %.pre = load i64, i64* %RSP, align 8
  %.pre1 = load i64, i64* %PC, align 8
  br label %block_40064a

block_40064a:                                     ; preds = %block_400638.block_40064a_crit_edge, %block_400648
  %.pre-phi = phi i64* [ %.pre2, %block_400638.block_40064a_crit_edge ], [ %25, %block_400648 ]
  %29 = phi i64 [ %23, %block_400638.block_40064a_crit_edge ], [ %.pre1, %block_400648 ]
  %30 = phi i64 [ %4, %block_400638.block_40064a_crit_edge ], [ %.pre, %block_400648 ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_400638.block_40064a_crit_edge ], [ %28, %block_400648 ]
  %31 = add i64 %30, 8
  store i64 %31, i64* %RSP, align 8, !tbaa !2428
  %32 = icmp ugt i64 %30, -9
  %33 = zext i1 %32 to i8
  store i8 %33, i8* %5, align 1, !tbaa !2433
  %34 = trunc i64 %31 to i32
  %35 = and i32 %34, 255
  %36 = tail call i32 @llvm.ctpop.i32(i32 %35) #10
  %37 = trunc i32 %36 to i8
  %38 = and i8 %37, 1
  %39 = xor i8 %38, 1
  store i8 %39, i8* %6, align 1, !tbaa !2447
  %40 = xor i64 %30, %31
  %41 = lshr i64 %40, 4
  %42 = trunc i64 %41 to i8
  %43 = and i8 %42, 1
  store i8 %43, i8* %7, align 1, !tbaa !2451
  %44 = icmp eq i64 %31, 0
  %45 = zext i1 %44 to i8
  store i8 %45, i8* %8, align 1, !tbaa !2448
  %46 = lshr i64 %31, 63
  %47 = trunc i64 %46 to i8
  store i8 %47, i8* %9, align 1, !tbaa !2449
  %48 = lshr i64 %30, 63
  %49 = xor i64 %46, %48
  %50 = add nuw nsw i64 %49, %46
  %51 = icmp eq i64 %50, 2
  %52 = zext i1 %51 to i8
  store i8 %52, i8* %10, align 1, !tbaa !2450
  %53 = add i64 %29, 5
  store i64 %53, i64* %PC, align 8
  %54 = inttoptr i64 %31 to i64*
  %55 = load i64, i64* %54, align 8
  store i64 %55, i64* %22, align 8, !tbaa !2428
  %56 = add i64 %30, 16
  store i64 %56, i64* %.pre-phi, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0
}

; Function Attrs: noinline
define %struct.Memory* @sub_402870_cft1st(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_402870:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %7 = load i64, i64* %RBP, align 8
  %8 = add i64 %1, 1
  store i64 %8, i64* %PC, align 8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %10 = load i64, i64* %9, align 8, !tbaa !2428
  %11 = add i64 %10, -8
  %12 = inttoptr i64 %11 to i64*
  store i64 %7, i64* %12, align 8
  %13 = load i64, i64* %PC, align 8
  store i64 %11, i64* %RBP, align 8, !tbaa !2428
  %14 = add i64 %10, -32
  store i64 %14, i64* %RSP, align 8, !tbaa !2428
  %15 = icmp ult i64 %11, 24
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1, !tbaa !2433
  %18 = trunc i64 %14 to i32
  %19 = and i32 %18, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19) #10
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1, !tbaa !2447
  %25 = xor i64 %11, 16
  %26 = xor i64 %25, %14
  %27 = lshr i64 %26, 4
  %28 = trunc i64 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1, !tbaa !2451
  %31 = icmp eq i64 %14, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1, !tbaa !2448
  %34 = lshr i64 %14, 63
  %35 = trunc i64 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1, !tbaa !2449
  %37 = lshr i64 %11, 63
  %38 = xor i64 %34, %37
  %39 = add nuw nsw i64 %38, %37
  %40 = icmp eq i64 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1, !tbaa !2450
  %43 = add i64 %10, -12
  %44 = load i32, i32* %EDI, align 4
  %45 = add i64 %13, 10
  store i64 %45, i64* %PC, align 8
  %46 = inttoptr i64 %43 to i32*
  store i32 %44, i32* %46, align 4
  %47 = load i64, i64* %RBP, align 8
  %48 = add i64 %47, -16
  %49 = load i64, i64* %RSI, align 8
  %50 = load i64, i64* %PC, align 8
  %51 = add i64 %50, 4
  store i64 %51, i64* %PC, align 8
  %52 = inttoptr i64 %48 to i64*
  store i64 %49, i64* %52, align 8
  %53 = load i64, i64* %RBP, align 8
  %54 = add i64 %53, -24
  %55 = load i64, i64* %RDX, align 8
  %56 = load i64, i64* %PC, align 8
  %57 = add i64 %56, 4
  store i64 %57, i64* %PC, align 8
  %58 = inttoptr i64 %54 to i64*
  store i64 %55, i64* %58, align 8
  %59 = load i64, i64* %RBP, align 8
  %60 = add i64 %59, -16
  %61 = load i64, i64* %PC, align 8
  %62 = add i64 %61, 4
  store i64 %62, i64* %PC, align 8
  %63 = inttoptr i64 %60 to i64*
  %64 = load i64, i64* %63, align 8
  store i64 %64, i64* %RDX, align 8, !tbaa !2428
  %65 = add i64 %61, 8
  store i64 %65, i64* %PC, align 8
  %66 = inttoptr i64 %64 to double*
  %67 = load double, double* %66, align 8
  %68 = bitcast [32 x %union.VectorReg]* %4 to double*
  store double %67, double* %68, align 1, !tbaa !2452
  %69 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %70 = bitcast i64* %69 to double*
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %71 = add i64 %61, 12
  store i64 %71, i64* %PC, align 8
  %72 = load i64, i64* %63, align 8
  store i64 %72, i64* %RDX, align 8, !tbaa !2428
  %73 = add i64 %72, 16
  %74 = add i64 %61, 17
  store i64 %74, i64* %PC, align 8
  %75 = inttoptr i64 %73 to double*
  %76 = load double, double* %75, align 8
  %77 = fadd double %67, %76
  store double %77, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %78 = add i64 %59, -96
  %79 = add i64 %61, 22
  store i64 %79, i64* %PC, align 8
  %80 = inttoptr i64 %78 to double*
  store double %77, double* %80, align 8
  %81 = load i64, i64* %RBP, align 8
  %82 = add i64 %81, -16
  %83 = load i64, i64* %PC, align 8
  %84 = add i64 %83, 4
  store i64 %84, i64* %PC, align 8
  %85 = inttoptr i64 %82 to i64*
  %86 = load i64, i64* %85, align 8
  store i64 %86, i64* %RDX, align 8, !tbaa !2428
  %87 = add i64 %86, 8
  %88 = add i64 %83, 9
  store i64 %88, i64* %PC, align 8
  %89 = inttoptr i64 %87 to double*
  %90 = load double, double* %89, align 8
  store double %90, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %91 = add i64 %83, 13
  store i64 %91, i64* %PC, align 8
  %92 = load i64, i64* %85, align 8
  store i64 %92, i64* %RDX, align 8, !tbaa !2428
  %93 = add i64 %92, 24
  %94 = add i64 %83, 18
  store i64 %94, i64* %PC, align 8
  %95 = inttoptr i64 %93 to double*
  %96 = load double, double* %95, align 8
  %97 = fadd double %90, %96
  store double %97, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %98 = add i64 %81, -104
  %99 = add i64 %83, 23
  store i64 %99, i64* %PC, align 8
  %100 = inttoptr i64 %98 to double*
  store double %97, double* %100, align 8
  %101 = load i64, i64* %RBP, align 8
  %102 = add i64 %101, -16
  %103 = load i64, i64* %PC, align 8
  %104 = add i64 %103, 4
  store i64 %104, i64* %PC, align 8
  %105 = inttoptr i64 %102 to i64*
  %106 = load i64, i64* %105, align 8
  store i64 %106, i64* %RDX, align 8, !tbaa !2428
  %107 = add i64 %103, 8
  store i64 %107, i64* %PC, align 8
  %108 = inttoptr i64 %106 to double*
  %109 = load double, double* %108, align 8
  store double %109, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %110 = add i64 %103, 12
  store i64 %110, i64* %PC, align 8
  %111 = load i64, i64* %105, align 8
  store i64 %111, i64* %RDX, align 8, !tbaa !2428
  %112 = add i64 %111, 16
  %113 = add i64 %103, 17
  store i64 %113, i64* %PC, align 8
  %114 = inttoptr i64 %112 to double*
  %115 = load double, double* %114, align 8
  %116 = fsub double %109, %115
  store double %116, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %117 = add i64 %101, -112
  %118 = add i64 %103, 22
  store i64 %118, i64* %PC, align 8
  %119 = inttoptr i64 %117 to double*
  store double %116, double* %119, align 8
  %120 = load i64, i64* %RBP, align 8
  %121 = add i64 %120, -16
  %122 = load i64, i64* %PC, align 8
  %123 = add i64 %122, 4
  store i64 %123, i64* %PC, align 8
  %124 = inttoptr i64 %121 to i64*
  %125 = load i64, i64* %124, align 8
  store i64 %125, i64* %RDX, align 8, !tbaa !2428
  %126 = add i64 %125, 8
  %127 = add i64 %122, 9
  store i64 %127, i64* %PC, align 8
  %128 = inttoptr i64 %126 to double*
  %129 = load double, double* %128, align 8
  store double %129, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %130 = add i64 %122, 13
  store i64 %130, i64* %PC, align 8
  %131 = load i64, i64* %124, align 8
  store i64 %131, i64* %RDX, align 8, !tbaa !2428
  %132 = add i64 %131, 24
  %133 = add i64 %122, 18
  store i64 %133, i64* %PC, align 8
  %134 = inttoptr i64 %132 to double*
  %135 = load double, double* %134, align 8
  %136 = fsub double %129, %135
  store double %136, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %137 = add i64 %120, -120
  %138 = add i64 %122, 23
  store i64 %138, i64* %PC, align 8
  %139 = inttoptr i64 %137 to double*
  store double %136, double* %139, align 8
  %140 = load i64, i64* %RBP, align 8
  %141 = add i64 %140, -16
  %142 = load i64, i64* %PC, align 8
  %143 = add i64 %142, 4
  store i64 %143, i64* %PC, align 8
  %144 = inttoptr i64 %141 to i64*
  %145 = load i64, i64* %144, align 8
  store i64 %145, i64* %RDX, align 8, !tbaa !2428
  %146 = add i64 %145, 32
  %147 = add i64 %142, 9
  store i64 %147, i64* %PC, align 8
  %148 = inttoptr i64 %146 to double*
  %149 = load double, double* %148, align 8
  store double %149, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %150 = add i64 %142, 13
  store i64 %150, i64* %PC, align 8
  %151 = load i64, i64* %144, align 8
  store i64 %151, i64* %RDX, align 8, !tbaa !2428
  %152 = add i64 %151, 48
  %153 = add i64 %142, 18
  store i64 %153, i64* %PC, align 8
  %154 = inttoptr i64 %152 to double*
  %155 = load double, double* %154, align 8
  %156 = fadd double %149, %155
  store double %156, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %157 = add i64 %140, -128
  %158 = add i64 %142, 23
  store i64 %158, i64* %PC, align 8
  %159 = inttoptr i64 %157 to double*
  store double %156, double* %159, align 8
  %160 = load i64, i64* %RBP, align 8
  %161 = add i64 %160, -16
  %162 = load i64, i64* %PC, align 8
  %163 = add i64 %162, 4
  store i64 %163, i64* %PC, align 8
  %164 = inttoptr i64 %161 to i64*
  %165 = load i64, i64* %164, align 8
  store i64 %165, i64* %RDX, align 8, !tbaa !2428
  %166 = add i64 %165, 40
  %167 = add i64 %162, 9
  store i64 %167, i64* %PC, align 8
  %168 = inttoptr i64 %166 to double*
  %169 = load double, double* %168, align 8
  store double %169, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %170 = add i64 %162, 13
  store i64 %170, i64* %PC, align 8
  %171 = load i64, i64* %164, align 8
  store i64 %171, i64* %RDX, align 8, !tbaa !2428
  %172 = add i64 %171, 56
  %173 = add i64 %162, 18
  store i64 %173, i64* %PC, align 8
  %174 = inttoptr i64 %172 to double*
  %175 = load double, double* %174, align 8
  %176 = fadd double %169, %175
  store double %176, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %177 = add i64 %160, -136
  %178 = add i64 %162, 26
  store i64 %178, i64* %PC, align 8
  %179 = inttoptr i64 %177 to double*
  store double %176, double* %179, align 8
  %180 = load i64, i64* %RBP, align 8
  %181 = add i64 %180, -16
  %182 = load i64, i64* %PC, align 8
  %183 = add i64 %182, 4
  store i64 %183, i64* %PC, align 8
  %184 = inttoptr i64 %181 to i64*
  %185 = load i64, i64* %184, align 8
  store i64 %185, i64* %RDX, align 8, !tbaa !2428
  %186 = add i64 %185, 32
  %187 = add i64 %182, 9
  store i64 %187, i64* %PC, align 8
  %188 = inttoptr i64 %186 to double*
  %189 = load double, double* %188, align 8
  store double %189, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %190 = add i64 %182, 13
  store i64 %190, i64* %PC, align 8
  %191 = load i64, i64* %184, align 8
  store i64 %191, i64* %RDX, align 8, !tbaa !2428
  %192 = add i64 %191, 48
  %193 = add i64 %182, 18
  store i64 %193, i64* %PC, align 8
  %194 = inttoptr i64 %192 to double*
  %195 = load double, double* %194, align 8
  %196 = fsub double %189, %195
  store double %196, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %197 = add i64 %180, -144
  %198 = add i64 %182, 26
  store i64 %198, i64* %PC, align 8
  %199 = inttoptr i64 %197 to double*
  store double %196, double* %199, align 8
  %200 = load i64, i64* %RBP, align 8
  %201 = add i64 %200, -16
  %202 = load i64, i64* %PC, align 8
  %203 = add i64 %202, 4
  store i64 %203, i64* %PC, align 8
  %204 = inttoptr i64 %201 to i64*
  %205 = load i64, i64* %204, align 8
  store i64 %205, i64* %RDX, align 8, !tbaa !2428
  %206 = add i64 %205, 40
  %207 = add i64 %202, 9
  store i64 %207, i64* %PC, align 8
  %208 = inttoptr i64 %206 to double*
  %209 = load double, double* %208, align 8
  store double %209, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %210 = add i64 %202, 13
  store i64 %210, i64* %PC, align 8
  %211 = load i64, i64* %204, align 8
  store i64 %211, i64* %RDX, align 8, !tbaa !2428
  %212 = add i64 %211, 56
  %213 = add i64 %202, 18
  store i64 %213, i64* %PC, align 8
  %214 = inttoptr i64 %212 to double*
  %215 = load double, double* %214, align 8
  %216 = fsub double %209, %215
  store double %216, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %217 = add i64 %200, -152
  %218 = add i64 %202, 26
  store i64 %218, i64* %PC, align 8
  %219 = inttoptr i64 %217 to double*
  store double %216, double* %219, align 8
  %220 = load i64, i64* %RBP, align 8
  %221 = add i64 %220, -96
  %222 = load i64, i64* %PC, align 8
  %223 = add i64 %222, 5
  store i64 %223, i64* %PC, align 8
  %224 = inttoptr i64 %221 to double*
  %225 = load double, double* %224, align 8
  store double %225, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %226 = add i64 %220, -128
  %227 = add i64 %222, 10
  store i64 %227, i64* %PC, align 8
  %228 = inttoptr i64 %226 to double*
  %229 = load double, double* %228, align 8
  %230 = fadd double %225, %229
  store double %230, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %231 = add i64 %220, -16
  %232 = add i64 %222, 14
  store i64 %232, i64* %PC, align 8
  %233 = inttoptr i64 %231 to i64*
  %234 = load i64, i64* %233, align 8
  store i64 %234, i64* %RDX, align 8, !tbaa !2428
  %235 = add i64 %222, 18
  store i64 %235, i64* %PC, align 8
  %236 = inttoptr i64 %234 to double*
  store double %230, double* %236, align 8
  %237 = load i64, i64* %RBP, align 8
  %238 = add i64 %237, -104
  %239 = load i64, i64* %PC, align 8
  %240 = add i64 %239, 5
  store i64 %240, i64* %PC, align 8
  %241 = inttoptr i64 %238 to double*
  %242 = load double, double* %241, align 8
  store double %242, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %243 = add i64 %237, -136
  %244 = add i64 %239, 13
  store i64 %244, i64* %PC, align 8
  %245 = inttoptr i64 %243 to double*
  %246 = load double, double* %245, align 8
  %247 = fadd double %242, %246
  store double %247, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %248 = add i64 %237, -16
  %249 = add i64 %239, 17
  store i64 %249, i64* %PC, align 8
  %250 = inttoptr i64 %248 to i64*
  %251 = load i64, i64* %250, align 8
  store i64 %251, i64* %RDX, align 8, !tbaa !2428
  %252 = add i64 %251, 8
  %253 = add i64 %239, 22
  store i64 %253, i64* %PC, align 8
  %254 = inttoptr i64 %252 to double*
  store double %247, double* %254, align 8
  %255 = load i64, i64* %RBP, align 8
  %256 = add i64 %255, -96
  %257 = load i64, i64* %PC, align 8
  %258 = add i64 %257, 5
  store i64 %258, i64* %PC, align 8
  %259 = inttoptr i64 %256 to double*
  %260 = load double, double* %259, align 8
  store double %260, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %261 = add i64 %255, -128
  %262 = add i64 %257, 10
  store i64 %262, i64* %PC, align 8
  %263 = inttoptr i64 %261 to double*
  %264 = load double, double* %263, align 8
  %265 = fsub double %260, %264
  store double %265, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %266 = add i64 %255, -16
  %267 = add i64 %257, 14
  store i64 %267, i64* %PC, align 8
  %268 = inttoptr i64 %266 to i64*
  %269 = load i64, i64* %268, align 8
  store i64 %269, i64* %RDX, align 8, !tbaa !2428
  %270 = add i64 %269, 32
  %271 = add i64 %257, 19
  store i64 %271, i64* %PC, align 8
  %272 = inttoptr i64 %270 to double*
  store double %265, double* %272, align 8
  %273 = load i64, i64* %RBP, align 8
  %274 = add i64 %273, -104
  %275 = load i64, i64* %PC, align 8
  %276 = add i64 %275, 5
  store i64 %276, i64* %PC, align 8
  %277 = inttoptr i64 %274 to double*
  %278 = load double, double* %277, align 8
  store double %278, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %279 = add i64 %273, -136
  %280 = add i64 %275, 13
  store i64 %280, i64* %PC, align 8
  %281 = inttoptr i64 %279 to double*
  %282 = load double, double* %281, align 8
  %283 = fsub double %278, %282
  store double %283, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %284 = add i64 %273, -16
  %285 = add i64 %275, 17
  store i64 %285, i64* %PC, align 8
  %286 = inttoptr i64 %284 to i64*
  %287 = load i64, i64* %286, align 8
  store i64 %287, i64* %RDX, align 8, !tbaa !2428
  %288 = add i64 %287, 40
  %289 = add i64 %275, 22
  store i64 %289, i64* %PC, align 8
  %290 = inttoptr i64 %288 to double*
  store double %283, double* %290, align 8
  %291 = load i64, i64* %RBP, align 8
  %292 = add i64 %291, -112
  %293 = load i64, i64* %PC, align 8
  %294 = add i64 %293, 5
  store i64 %294, i64* %PC, align 8
  %295 = inttoptr i64 %292 to double*
  %296 = load double, double* %295, align 8
  store double %296, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %297 = add i64 %291, -152
  %298 = add i64 %293, 13
  store i64 %298, i64* %PC, align 8
  %299 = inttoptr i64 %297 to double*
  %300 = load double, double* %299, align 8
  %301 = fsub double %296, %300
  store double %301, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %302 = add i64 %291, -16
  %303 = add i64 %293, 17
  store i64 %303, i64* %PC, align 8
  %304 = inttoptr i64 %302 to i64*
  %305 = load i64, i64* %304, align 8
  store i64 %305, i64* %RDX, align 8, !tbaa !2428
  %306 = add i64 %305, 16
  %307 = add i64 %293, 22
  store i64 %307, i64* %PC, align 8
  %308 = inttoptr i64 %306 to double*
  store double %301, double* %308, align 8
  %309 = load i64, i64* %RBP, align 8
  %310 = add i64 %309, -120
  %311 = load i64, i64* %PC, align 8
  %312 = add i64 %311, 5
  store i64 %312, i64* %PC, align 8
  %313 = inttoptr i64 %310 to double*
  %314 = load double, double* %313, align 8
  store double %314, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %315 = add i64 %309, -144
  %316 = add i64 %311, 13
  store i64 %316, i64* %PC, align 8
  %317 = inttoptr i64 %315 to double*
  %318 = load double, double* %317, align 8
  %319 = fadd double %314, %318
  store double %319, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %320 = add i64 %309, -16
  %321 = add i64 %311, 17
  store i64 %321, i64* %PC, align 8
  %322 = inttoptr i64 %320 to i64*
  %323 = load i64, i64* %322, align 8
  store i64 %323, i64* %RDX, align 8, !tbaa !2428
  %324 = add i64 %323, 24
  %325 = add i64 %311, 22
  store i64 %325, i64* %PC, align 8
  %326 = inttoptr i64 %324 to double*
  store double %319, double* %326, align 8
  %327 = load i64, i64* %RBP, align 8
  %328 = add i64 %327, -112
  %329 = load i64, i64* %PC, align 8
  %330 = add i64 %329, 5
  store i64 %330, i64* %PC, align 8
  %331 = inttoptr i64 %328 to double*
  %332 = load double, double* %331, align 8
  store double %332, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %333 = add i64 %327, -152
  %334 = add i64 %329, 13
  store i64 %334, i64* %PC, align 8
  %335 = inttoptr i64 %333 to double*
  %336 = load double, double* %335, align 8
  %337 = fadd double %332, %336
  store double %337, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %338 = add i64 %327, -16
  %339 = add i64 %329, 17
  store i64 %339, i64* %PC, align 8
  %340 = inttoptr i64 %338 to i64*
  %341 = load i64, i64* %340, align 8
  store i64 %341, i64* %RDX, align 8, !tbaa !2428
  %342 = add i64 %341, 48
  %343 = add i64 %329, 22
  store i64 %343, i64* %PC, align 8
  %344 = inttoptr i64 %342 to double*
  store double %337, double* %344, align 8
  %345 = load i64, i64* %RBP, align 8
  %346 = add i64 %345, -120
  %347 = load i64, i64* %PC, align 8
  %348 = add i64 %347, 5
  store i64 %348, i64* %PC, align 8
  %349 = inttoptr i64 %346 to double*
  %350 = load double, double* %349, align 8
  store double %350, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %351 = add i64 %345, -144
  %352 = add i64 %347, 13
  store i64 %352, i64* %PC, align 8
  %353 = inttoptr i64 %351 to double*
  %354 = load double, double* %353, align 8
  %355 = fsub double %350, %354
  store double %355, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %356 = add i64 %345, -16
  %357 = add i64 %347, 17
  store i64 %357, i64* %PC, align 8
  %358 = inttoptr i64 %356 to i64*
  %359 = load i64, i64* %358, align 8
  store i64 %359, i64* %RDX, align 8, !tbaa !2428
  %360 = add i64 %359, 56
  %361 = add i64 %347, 22
  store i64 %361, i64* %PC, align 8
  %362 = inttoptr i64 %360 to double*
  store double %355, double* %362, align 8
  %363 = load i64, i64* %RBP, align 8
  %364 = add i64 %363, -24
  %365 = load i64, i64* %PC, align 8
  %366 = add i64 %365, 4
  store i64 %366, i64* %PC, align 8
  %367 = inttoptr i64 %364 to i64*
  %368 = load i64, i64* %367, align 8
  store i64 %368, i64* %RDX, align 8, !tbaa !2428
  %369 = add i64 %368, 16
  %370 = add i64 %365, 9
  store i64 %370, i64* %PC, align 8
  %371 = inttoptr i64 %369 to i64*
  %372 = load i64, i64* %371, align 8
  %373 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %372, i64* %373, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %374 = add i64 %363, -48
  %375 = add i64 %365, 14
  store i64 %375, i64* %PC, align 8
  %376 = inttoptr i64 %374 to i64*
  store i64 %372, i64* %376, align 8
  %377 = load i64, i64* %RBP, align 8
  %378 = add i64 %377, -16
  %379 = load i64, i64* %PC, align 8
  %380 = add i64 %379, 4
  store i64 %380, i64* %PC, align 8
  %381 = inttoptr i64 %378 to i64*
  %382 = load i64, i64* %381, align 8
  store i64 %382, i64* %RDX, align 8, !tbaa !2428
  %383 = add i64 %382, 64
  %384 = add i64 %379, 9
  store i64 %384, i64* %PC, align 8
  %385 = inttoptr i64 %383 to double*
  %386 = load double, double* %385, align 8
  store double %386, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %387 = add i64 %379, 13
  store i64 %387, i64* %PC, align 8
  %388 = load i64, i64* %381, align 8
  store i64 %388, i64* %RDX, align 8, !tbaa !2428
  %389 = add i64 %388, 80
  %390 = add i64 %379, 18
  store i64 %390, i64* %PC, align 8
  %391 = inttoptr i64 %389 to double*
  %392 = load double, double* %391, align 8
  %393 = fadd double %386, %392
  store double %393, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %394 = add i64 %377, -96
  %395 = add i64 %379, 23
  store i64 %395, i64* %PC, align 8
  %396 = inttoptr i64 %394 to double*
  store double %393, double* %396, align 8
  %397 = load i64, i64* %RBP, align 8
  %398 = add i64 %397, -16
  %399 = load i64, i64* %PC, align 8
  %400 = add i64 %399, 4
  store i64 %400, i64* %PC, align 8
  %401 = inttoptr i64 %398 to i64*
  %402 = load i64, i64* %401, align 8
  store i64 %402, i64* %RDX, align 8, !tbaa !2428
  %403 = add i64 %402, 72
  %404 = add i64 %399, 9
  store i64 %404, i64* %PC, align 8
  %405 = inttoptr i64 %403 to double*
  %406 = load double, double* %405, align 8
  store double %406, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %407 = add i64 %399, 13
  store i64 %407, i64* %PC, align 8
  %408 = load i64, i64* %401, align 8
  store i64 %408, i64* %RDX, align 8, !tbaa !2428
  %409 = add i64 %408, 88
  %410 = add i64 %399, 18
  store i64 %410, i64* %PC, align 8
  %411 = inttoptr i64 %409 to double*
  %412 = load double, double* %411, align 8
  %413 = fadd double %406, %412
  store double %413, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %414 = add i64 %397, -104
  %415 = add i64 %399, 23
  store i64 %415, i64* %PC, align 8
  %416 = inttoptr i64 %414 to double*
  store double %413, double* %416, align 8
  %417 = load i64, i64* %RBP, align 8
  %418 = add i64 %417, -16
  %419 = load i64, i64* %PC, align 8
  %420 = add i64 %419, 4
  store i64 %420, i64* %PC, align 8
  %421 = inttoptr i64 %418 to i64*
  %422 = load i64, i64* %421, align 8
  store i64 %422, i64* %RDX, align 8, !tbaa !2428
  %423 = add i64 %422, 64
  %424 = add i64 %419, 9
  store i64 %424, i64* %PC, align 8
  %425 = inttoptr i64 %423 to double*
  %426 = load double, double* %425, align 8
  store double %426, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %427 = add i64 %419, 13
  store i64 %427, i64* %PC, align 8
  %428 = load i64, i64* %421, align 8
  store i64 %428, i64* %RDX, align 8, !tbaa !2428
  %429 = add i64 %428, 80
  %430 = add i64 %419, 18
  store i64 %430, i64* %PC, align 8
  %431 = inttoptr i64 %429 to double*
  %432 = load double, double* %431, align 8
  %433 = fsub double %426, %432
  store double %433, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %434 = add i64 %417, -112
  %435 = add i64 %419, 23
  store i64 %435, i64* %PC, align 8
  %436 = inttoptr i64 %434 to double*
  store double %433, double* %436, align 8
  %437 = load i64, i64* %RBP, align 8
  %438 = add i64 %437, -16
  %439 = load i64, i64* %PC, align 8
  %440 = add i64 %439, 4
  store i64 %440, i64* %PC, align 8
  %441 = inttoptr i64 %438 to i64*
  %442 = load i64, i64* %441, align 8
  store i64 %442, i64* %RDX, align 8, !tbaa !2428
  %443 = add i64 %442, 72
  %444 = add i64 %439, 9
  store i64 %444, i64* %PC, align 8
  %445 = inttoptr i64 %443 to double*
  %446 = load double, double* %445, align 8
  store double %446, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %447 = add i64 %439, 13
  store i64 %447, i64* %PC, align 8
  %448 = load i64, i64* %441, align 8
  store i64 %448, i64* %RDX, align 8, !tbaa !2428
  %449 = add i64 %448, 88
  %450 = add i64 %439, 18
  store i64 %450, i64* %PC, align 8
  %451 = inttoptr i64 %449 to double*
  %452 = load double, double* %451, align 8
  %453 = fsub double %446, %452
  store double %453, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %454 = add i64 %437, -120
  %455 = add i64 %439, 23
  store i64 %455, i64* %PC, align 8
  %456 = inttoptr i64 %454 to double*
  store double %453, double* %456, align 8
  %457 = load i64, i64* %RBP, align 8
  %458 = add i64 %457, -16
  %459 = load i64, i64* %PC, align 8
  %460 = add i64 %459, 4
  store i64 %460, i64* %PC, align 8
  %461 = inttoptr i64 %458 to i64*
  %462 = load i64, i64* %461, align 8
  store i64 %462, i64* %RDX, align 8, !tbaa !2428
  %463 = add i64 %462, 96
  %464 = add i64 %459, 9
  store i64 %464, i64* %PC, align 8
  %465 = inttoptr i64 %463 to double*
  %466 = load double, double* %465, align 8
  store double %466, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %467 = add i64 %459, 13
  store i64 %467, i64* %PC, align 8
  %468 = load i64, i64* %461, align 8
  store i64 %468, i64* %RDX, align 8, !tbaa !2428
  %469 = add i64 %468, 112
  %470 = add i64 %459, 18
  store i64 %470, i64* %PC, align 8
  %471 = inttoptr i64 %469 to double*
  %472 = load double, double* %471, align 8
  %473 = fadd double %466, %472
  store double %473, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %474 = add i64 %457, -128
  %475 = add i64 %459, 23
  store i64 %475, i64* %PC, align 8
  %476 = inttoptr i64 %474 to double*
  store double %473, double* %476, align 8
  %477 = load i64, i64* %RBP, align 8
  %478 = add i64 %477, -16
  %479 = load i64, i64* %PC, align 8
  %480 = add i64 %479, 4
  store i64 %480, i64* %PC, align 8
  %481 = inttoptr i64 %478 to i64*
  %482 = load i64, i64* %481, align 8
  store i64 %482, i64* %RDX, align 8, !tbaa !2428
  %483 = add i64 %482, 104
  %484 = add i64 %479, 9
  store i64 %484, i64* %PC, align 8
  %485 = inttoptr i64 %483 to double*
  %486 = load double, double* %485, align 8
  store double %486, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %487 = add i64 %479, 13
  store i64 %487, i64* %PC, align 8
  %488 = load i64, i64* %481, align 8
  store i64 %488, i64* %RDX, align 8, !tbaa !2428
  %489 = add i64 %488, 120
  %490 = add i64 %479, 18
  store i64 %490, i64* %PC, align 8
  %491 = inttoptr i64 %489 to double*
  %492 = load double, double* %491, align 8
  %493 = fadd double %486, %492
  store double %493, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %494 = add i64 %477, -136
  %495 = add i64 %479, 26
  store i64 %495, i64* %PC, align 8
  %496 = inttoptr i64 %494 to double*
  store double %493, double* %496, align 8
  %497 = load i64, i64* %RBP, align 8
  %498 = add i64 %497, -16
  %499 = load i64, i64* %PC, align 8
  %500 = add i64 %499, 4
  store i64 %500, i64* %PC, align 8
  %501 = inttoptr i64 %498 to i64*
  %502 = load i64, i64* %501, align 8
  store i64 %502, i64* %RDX, align 8, !tbaa !2428
  %503 = add i64 %502, 96
  %504 = add i64 %499, 9
  store i64 %504, i64* %PC, align 8
  %505 = inttoptr i64 %503 to double*
  %506 = load double, double* %505, align 8
  store double %506, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %507 = add i64 %499, 13
  store i64 %507, i64* %PC, align 8
  %508 = load i64, i64* %501, align 8
  store i64 %508, i64* %RDX, align 8, !tbaa !2428
  %509 = add i64 %508, 112
  %510 = add i64 %499, 18
  store i64 %510, i64* %PC, align 8
  %511 = inttoptr i64 %509 to double*
  %512 = load double, double* %511, align 8
  %513 = fsub double %506, %512
  store double %513, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %514 = add i64 %497, -144
  %515 = add i64 %499, 26
  store i64 %515, i64* %PC, align 8
  %516 = inttoptr i64 %514 to double*
  store double %513, double* %516, align 8
  %517 = load i64, i64* %RBP, align 8
  %518 = add i64 %517, -16
  %519 = load i64, i64* %PC, align 8
  %520 = add i64 %519, 4
  store i64 %520, i64* %PC, align 8
  %521 = inttoptr i64 %518 to i64*
  %522 = load i64, i64* %521, align 8
  store i64 %522, i64* %RDX, align 8, !tbaa !2428
  %523 = add i64 %522, 104
  %524 = add i64 %519, 9
  store i64 %524, i64* %PC, align 8
  %525 = inttoptr i64 %523 to double*
  %526 = load double, double* %525, align 8
  store double %526, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %527 = add i64 %519, 13
  store i64 %527, i64* %PC, align 8
  %528 = load i64, i64* %521, align 8
  store i64 %528, i64* %RDX, align 8, !tbaa !2428
  %529 = add i64 %528, 120
  %530 = add i64 %519, 18
  store i64 %530, i64* %PC, align 8
  %531 = inttoptr i64 %529 to double*
  %532 = load double, double* %531, align 8
  %533 = fsub double %526, %532
  store double %533, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %534 = add i64 %517, -152
  %535 = add i64 %519, 26
  store i64 %535, i64* %PC, align 8
  %536 = inttoptr i64 %534 to double*
  store double %533, double* %536, align 8
  %537 = load i64, i64* %RBP, align 8
  %538 = add i64 %537, -96
  %539 = load i64, i64* %PC, align 8
  %540 = add i64 %539, 5
  store i64 %540, i64* %PC, align 8
  %541 = inttoptr i64 %538 to double*
  %542 = load double, double* %541, align 8
  store double %542, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %543 = add i64 %537, -128
  %544 = add i64 %539, 10
  store i64 %544, i64* %PC, align 8
  %545 = inttoptr i64 %543 to double*
  %546 = load double, double* %545, align 8
  %547 = fadd double %542, %546
  store double %547, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %548 = add i64 %537, -16
  %549 = add i64 %539, 14
  store i64 %549, i64* %PC, align 8
  %550 = inttoptr i64 %548 to i64*
  %551 = load i64, i64* %550, align 8
  store i64 %551, i64* %RDX, align 8, !tbaa !2428
  %552 = add i64 %551, 64
  %553 = add i64 %539, 19
  store i64 %553, i64* %PC, align 8
  %554 = inttoptr i64 %552 to double*
  store double %547, double* %554, align 8
  %555 = load i64, i64* %RBP, align 8
  %556 = add i64 %555, -104
  %557 = load i64, i64* %PC, align 8
  %558 = add i64 %557, 5
  store i64 %558, i64* %PC, align 8
  %559 = inttoptr i64 %556 to double*
  %560 = load double, double* %559, align 8
  store double %560, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %561 = add i64 %555, -136
  %562 = add i64 %557, 13
  store i64 %562, i64* %PC, align 8
  %563 = inttoptr i64 %561 to double*
  %564 = load double, double* %563, align 8
  %565 = fadd double %560, %564
  store double %565, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %566 = add i64 %555, -16
  %567 = add i64 %557, 17
  store i64 %567, i64* %PC, align 8
  %568 = inttoptr i64 %566 to i64*
  %569 = load i64, i64* %568, align 8
  store i64 %569, i64* %RDX, align 8, !tbaa !2428
  %570 = add i64 %569, 72
  %571 = add i64 %557, 22
  store i64 %571, i64* %PC, align 8
  %572 = inttoptr i64 %570 to double*
  store double %565, double* %572, align 8
  %573 = load i64, i64* %RBP, align 8
  %574 = add i64 %573, -136
  %575 = load i64, i64* %PC, align 8
  %576 = add i64 %575, 8
  store i64 %576, i64* %PC, align 8
  %577 = inttoptr i64 %574 to double*
  %578 = load double, double* %577, align 8
  store double %578, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %579 = add i64 %573, -104
  %580 = add i64 %575, 13
  store i64 %580, i64* %PC, align 8
  %581 = inttoptr i64 %579 to double*
  %582 = load double, double* %581, align 8
  %583 = fsub double %578, %582
  store double %583, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %584 = add i64 %573, -16
  %585 = add i64 %575, 17
  store i64 %585, i64* %PC, align 8
  %586 = inttoptr i64 %584 to i64*
  %587 = load i64, i64* %586, align 8
  store i64 %587, i64* %RDX, align 8, !tbaa !2428
  %588 = add i64 %587, 96
  %589 = add i64 %575, 22
  store i64 %589, i64* %PC, align 8
  %590 = inttoptr i64 %588 to double*
  store double %583, double* %590, align 8
  %591 = load i64, i64* %RBP, align 8
  %592 = add i64 %591, -96
  %593 = load i64, i64* %PC, align 8
  %594 = add i64 %593, 5
  store i64 %594, i64* %PC, align 8
  %595 = inttoptr i64 %592 to double*
  %596 = load double, double* %595, align 8
  store double %596, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %597 = add i64 %591, -128
  %598 = add i64 %593, 10
  store i64 %598, i64* %PC, align 8
  %599 = inttoptr i64 %597 to double*
  %600 = load double, double* %599, align 8
  %601 = fsub double %596, %600
  store double %601, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %602 = add i64 %591, -16
  %603 = add i64 %593, 14
  store i64 %603, i64* %PC, align 8
  %604 = inttoptr i64 %602 to i64*
  %605 = load i64, i64* %604, align 8
  store i64 %605, i64* %RDX, align 8, !tbaa !2428
  %606 = add i64 %605, 104
  %607 = add i64 %593, 19
  store i64 %607, i64* %PC, align 8
  %608 = inttoptr i64 %606 to double*
  store double %601, double* %608, align 8
  %609 = load i64, i64* %RBP, align 8
  %610 = add i64 %609, -112
  %611 = load i64, i64* %PC, align 8
  %612 = add i64 %611, 5
  store i64 %612, i64* %PC, align 8
  %613 = inttoptr i64 %610 to double*
  %614 = load double, double* %613, align 8
  store double %614, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %615 = add i64 %609, -152
  %616 = add i64 %611, 13
  store i64 %616, i64* %PC, align 8
  %617 = inttoptr i64 %615 to double*
  %618 = load double, double* %617, align 8
  %619 = fsub double %614, %618
  store double %619, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %620 = add i64 %609, -96
  %621 = add i64 %611, 18
  store i64 %621, i64* %PC, align 8
  %622 = inttoptr i64 %620 to double*
  store double %619, double* %622, align 8
  %623 = load i64, i64* %RBP, align 8
  %624 = add i64 %623, -120
  %625 = load i64, i64* %PC, align 8
  %626 = add i64 %625, 5
  store i64 %626, i64* %PC, align 8
  %627 = inttoptr i64 %624 to double*
  %628 = load double, double* %627, align 8
  store double %628, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %629 = add i64 %623, -144
  %630 = add i64 %625, 13
  store i64 %630, i64* %PC, align 8
  %631 = inttoptr i64 %629 to double*
  %632 = load double, double* %631, align 8
  %633 = fadd double %628, %632
  store double %633, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %634 = add i64 %623, -104
  %635 = add i64 %625, 18
  store i64 %635, i64* %PC, align 8
  %636 = inttoptr i64 %634 to double*
  store double %633, double* %636, align 8
  %637 = load i64, i64* %RBP, align 8
  %638 = add i64 %637, -48
  %639 = load i64, i64* %PC, align 8
  %640 = add i64 %639, 5
  store i64 %640, i64* %PC, align 8
  %641 = inttoptr i64 %638 to double*
  %642 = load double, double* %641, align 8
  store double %642, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %643 = bitcast %union.VectorReg* %5 to i8*
  %644 = add i64 %637, -96
  %645 = add i64 %639, 10
  store i64 %645, i64* %PC, align 8
  %646 = inttoptr i64 %644 to double*
  %647 = load double, double* %646, align 8
  %648 = bitcast %union.VectorReg* %5 to double*
  store double %647, double* %648, align 1, !tbaa !2452
  %649 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %650 = bitcast i64* %649 to double*
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %651 = add i64 %637, -104
  %652 = add i64 %639, 15
  store i64 %652, i64* %PC, align 8
  %653 = inttoptr i64 %651 to double*
  %654 = load double, double* %653, align 8
  %655 = fsub double %647, %654
  store double %655, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %656 = fmul double %642, %655
  store double %656, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %657 = add i64 %637, -16
  %658 = add i64 %639, 23
  store i64 %658, i64* %PC, align 8
  %659 = inttoptr i64 %657 to i64*
  %660 = load i64, i64* %659, align 8
  store i64 %660, i64* %RDX, align 8, !tbaa !2428
  %661 = add i64 %660, 80
  %662 = add i64 %639, 28
  store i64 %662, i64* %PC, align 8
  %663 = inttoptr i64 %661 to double*
  store double %656, double* %663, align 8
  %664 = load i64, i64* %RBP, align 8
  %665 = add i64 %664, -48
  %666 = load i64, i64* %PC, align 8
  %667 = add i64 %666, 5
  store i64 %667, i64* %PC, align 8
  %668 = inttoptr i64 %665 to double*
  %669 = load double, double* %668, align 8
  store double %669, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %670 = add i64 %664, -96
  %671 = add i64 %666, 10
  store i64 %671, i64* %PC, align 8
  %672 = inttoptr i64 %670 to double*
  %673 = load double, double* %672, align 8
  store double %673, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %674 = add i64 %664, -104
  %675 = add i64 %666, 15
  store i64 %675, i64* %PC, align 8
  %676 = inttoptr i64 %674 to double*
  %677 = load double, double* %676, align 8
  %678 = fadd double %673, %677
  store double %678, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %679 = fmul double %669, %678
  store double %679, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %680 = add i64 %664, -16
  %681 = add i64 %666, 23
  store i64 %681, i64* %PC, align 8
  %682 = inttoptr i64 %680 to i64*
  %683 = load i64, i64* %682, align 8
  store i64 %683, i64* %RDX, align 8, !tbaa !2428
  %684 = add i64 %683, 88
  %685 = add i64 %666, 28
  store i64 %685, i64* %PC, align 8
  %686 = inttoptr i64 %684 to double*
  store double %679, double* %686, align 8
  %687 = load i64, i64* %RBP, align 8
  %688 = add i64 %687, -152
  %689 = load i64, i64* %PC, align 8
  %690 = add i64 %689, 8
  store i64 %690, i64* %PC, align 8
  %691 = inttoptr i64 %688 to double*
  %692 = load double, double* %691, align 8
  store double %692, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %693 = add i64 %687, -112
  %694 = add i64 %689, 13
  store i64 %694, i64* %PC, align 8
  %695 = inttoptr i64 %693 to double*
  %696 = load double, double* %695, align 8
  %697 = fadd double %692, %696
  store double %697, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %698 = add i64 %687, -96
  %699 = add i64 %689, 18
  store i64 %699, i64* %PC, align 8
  %700 = inttoptr i64 %698 to double*
  store double %697, double* %700, align 8
  %701 = load i64, i64* %RBP, align 8
  %702 = add i64 %701, -144
  %703 = load i64, i64* %PC, align 8
  %704 = add i64 %703, 8
  store i64 %704, i64* %PC, align 8
  %705 = inttoptr i64 %702 to double*
  %706 = load double, double* %705, align 8
  store double %706, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %707 = add i64 %701, -120
  %708 = add i64 %703, 13
  store i64 %708, i64* %PC, align 8
  %709 = inttoptr i64 %707 to double*
  %710 = load double, double* %709, align 8
  %711 = fsub double %706, %710
  store double %711, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %712 = add i64 %701, -104
  %713 = add i64 %703, 18
  store i64 %713, i64* %PC, align 8
  %714 = inttoptr i64 %712 to double*
  store double %711, double* %714, align 8
  %715 = load i64, i64* %RBP, align 8
  %716 = add i64 %715, -48
  %717 = load i64, i64* %PC, align 8
  %718 = add i64 %717, 5
  store i64 %718, i64* %PC, align 8
  %719 = inttoptr i64 %716 to double*
  %720 = load double, double* %719, align 8
  store double %720, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %721 = add i64 %715, -104
  %722 = add i64 %717, 10
  store i64 %722, i64* %PC, align 8
  %723 = inttoptr i64 %721 to double*
  %724 = load double, double* %723, align 8
  store double %724, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %725 = add i64 %715, -96
  %726 = add i64 %717, 15
  store i64 %726, i64* %PC, align 8
  %727 = inttoptr i64 %725 to double*
  %728 = load double, double* %727, align 8
  %729 = fsub double %724, %728
  store double %729, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %730 = fmul double %720, %729
  store double %730, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %731 = add i64 %715, -16
  %732 = add i64 %717, 23
  store i64 %732, i64* %PC, align 8
  %733 = inttoptr i64 %731 to i64*
  %734 = load i64, i64* %733, align 8
  store i64 %734, i64* %RDX, align 8, !tbaa !2428
  %735 = add i64 %734, 112
  %736 = add i64 %717, 28
  store i64 %736, i64* %PC, align 8
  %737 = inttoptr i64 %735 to double*
  store double %730, double* %737, align 8
  %738 = load i64, i64* %RBP, align 8
  %739 = add i64 %738, -48
  %740 = load i64, i64* %PC, align 8
  %741 = add i64 %740, 5
  store i64 %741, i64* %PC, align 8
  %742 = inttoptr i64 %739 to double*
  %743 = load double, double* %742, align 8
  store double %743, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %744 = add i64 %738, -104
  %745 = add i64 %740, 10
  store i64 %745, i64* %PC, align 8
  %746 = inttoptr i64 %744 to double*
  %747 = load double, double* %746, align 8
  store double %747, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %748 = add i64 %738, -96
  %749 = add i64 %740, 15
  store i64 %749, i64* %PC, align 8
  %750 = inttoptr i64 %748 to double*
  %751 = load double, double* %750, align 8
  %752 = fadd double %747, %751
  store double %752, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %753 = fmul double %743, %752
  store double %753, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %754 = add i64 %738, -16
  %755 = add i64 %740, 23
  store i64 %755, i64* %PC, align 8
  %756 = inttoptr i64 %754 to i64*
  %757 = load i64, i64* %756, align 8
  store i64 %757, i64* %RDX, align 8, !tbaa !2428
  %758 = add i64 %757, 120
  %759 = add i64 %740, 28
  store i64 %759, i64* %PC, align 8
  %760 = inttoptr i64 %758 to double*
  store double %753, double* %760, align 8
  %761 = load i64, i64* %RBP, align 8
  %762 = add i64 %761, -32
  %763 = load i64, i64* %PC, align 8
  %764 = add i64 %763, 7
  store i64 %764, i64* %PC, align 8
  %765 = inttoptr i64 %762 to i32*
  store i32 0, i32* %765, align 4
  %766 = load i64, i64* %RBP, align 8
  %767 = add i64 %766, -28
  %768 = load i64, i64* %PC, align 8
  %769 = add i64 %768, 7
  store i64 %769, i64* %PC, align 8
  %770 = inttoptr i64 %767 to i32*
  store i32 16, i32* %770, align 4
  %771 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %772 = bitcast %union.VectorReg* %6 to i8*
  %773 = bitcast [32 x %union.VectorReg]* %4 to <2 x i32>*
  %774 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %775 = bitcast i64* %774 to <2 x i32>*
  %776 = bitcast %union.VectorReg* %6 to i32*
  %777 = getelementptr inbounds i8, i8* %772, i64 4
  %778 = bitcast i8* %777 to i32*
  %779 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %780 = bitcast i64* %779 to i32*
  %781 = getelementptr inbounds i8, i8* %772, i64 12
  %782 = bitcast i8* %781 to i32*
  %783 = bitcast %union.VectorReg* %6 to double*
  %784 = bitcast %union.VectorReg* %5 to i32*
  %785 = getelementptr inbounds i8, i8* %643, i64 4
  %786 = bitcast i8* %785 to i32*
  %787 = bitcast i64* %649 to i32*
  %788 = getelementptr inbounds i8, i8* %643, i64 12
  %789 = bitcast i8* %788 to i32*
  %790 = bitcast i64* %779 to double*
  %791 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %.pre = load i64, i64* %PC, align 8
  br label %block_402bd2

block_402bde:                                     ; preds = %block_402bd2
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %792 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 80) to i64*), align 16
  %793 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %792, i64* %793, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %794 = add i64 %3374, -32
  %795 = add i64 %3410, 21
  store i64 %795, i64* %PC, align 8
  %796 = inttoptr i64 %794 to i32*
  %797 = load i32, i32* %796, align 4
  %798 = add i32 %797, 2
  %799 = zext i32 %798 to i64
  store i64 %799, i64* %RCX, align 8, !tbaa !2428
  %800 = icmp ugt i32 %797, -3
  %801 = zext i1 %800 to i8
  store i8 %801, i8* %17, align 1, !tbaa !2433
  %802 = and i32 %798, 255
  %803 = tail call i32 @llvm.ctpop.i32(i32 %802) #10
  %804 = trunc i32 %803 to i8
  %805 = and i8 %804, 1
  %806 = xor i8 %805, 1
  store i8 %806, i8* %24, align 1, !tbaa !2447
  %807 = xor i32 %797, %798
  %808 = lshr i32 %807, 4
  %809 = trunc i32 %808 to i8
  %810 = and i8 %809, 1
  store i8 %810, i8* %30, align 1, !tbaa !2451
  %811 = icmp eq i32 %798, 0
  %812 = zext i1 %811 to i8
  store i8 %812, i8* %33, align 1, !tbaa !2448
  %813 = lshr i32 %798, 31
  %814 = trunc i32 %813 to i8
  store i8 %814, i8* %36, align 1, !tbaa !2449
  %815 = lshr i32 %797, 31
  %816 = xor i32 %813, %815
  %817 = add nuw nsw i32 %816, %813
  %818 = icmp eq i32 %817, 2
  %819 = zext i1 %818 to i8
  store i8 %819, i8* %42, align 1, !tbaa !2450
  %820 = add i64 %3410, 27
  store i64 %820, i64* %PC, align 8
  store i32 %798, i32* %796, align 4
  %821 = load i64, i64* %RBP, align 8
  %822 = add i64 %821, -32
  %823 = load i64, i64* %PC, align 8
  %824 = add i64 %823, 3
  store i64 %824, i64* %PC, align 8
  %825 = inttoptr i64 %822 to i32*
  %826 = load i32, i32* %825, align 4
  %827 = shl i32 %826, 1
  %828 = icmp slt i32 %826, 0
  %829 = icmp slt i32 %827, 0
  %830 = xor i1 %828, %829
  %831 = zext i32 %827 to i64
  store i64 %831, i64* %RCX, align 8, !tbaa !2428
  %.lobit = lshr i32 %826, 31
  %832 = trunc i32 %.lobit to i8
  store i8 %832, i8* %17, align 1, !tbaa !2432
  %833 = and i32 %827, 254
  %834 = tail call i32 @llvm.ctpop.i32(i32 %833) #10
  %835 = trunc i32 %834 to i8
  %836 = and i8 %835, 1
  %837 = xor i8 %836, 1
  store i8 %837, i8* %24, align 1, !tbaa !2432
  store i8 0, i8* %30, align 1, !tbaa !2432
  %838 = icmp eq i32 %827, 0
  %839 = zext i1 %838 to i8
  store i8 %839, i8* %33, align 1, !tbaa !2432
  %840 = lshr i32 %826, 30
  %841 = trunc i32 %840 to i8
  %842 = and i8 %841, 1
  store i8 %842, i8* %36, align 1, !tbaa !2432
  %843 = zext i1 %830 to i8
  store i8 %843, i8* %42, align 1, !tbaa !2432
  %844 = add i64 %821, -36
  %845 = add i64 %823, 9
  store i64 %845, i64* %PC, align 8
  %846 = inttoptr i64 %844 to i32*
  store i32 %827, i32* %846, align 4
  %847 = load i64, i64* %RBP, align 8
  %848 = add i64 %847, -24
  %849 = load i64, i64* %PC, align 8
  %850 = add i64 %849, 4
  store i64 %850, i64* %PC, align 8
  %851 = inttoptr i64 %848 to i64*
  %852 = load i64, i64* %851, align 8
  store i64 %852, i64* %RDX, align 8, !tbaa !2428
  %853 = add i64 %847, -32
  %854 = add i64 %849, 8
  store i64 %854, i64* %PC, align 8
  %855 = inttoptr i64 %853 to i32*
  %856 = load i32, i32* %855, align 4
  %857 = sext i32 %856 to i64
  store i64 %857, i64* %RSI, align 8, !tbaa !2428
  %858 = shl nsw i64 %857, 3
  %859 = add i64 %858, %852
  %860 = add i64 %849, 13
  store i64 %860, i64* %PC, align 8
  %861 = inttoptr i64 %859 to i64*
  %862 = load i64, i64* %861, align 8
  %863 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %862, i64* %863, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %864 = add i64 %847, -64
  %865 = add i64 %849, 18
  store i64 %865, i64* %PC, align 8
  %866 = inttoptr i64 %864 to i64*
  store i64 %862, i64* %866, align 8
  %867 = load i64, i64* %RBP, align 8
  %868 = add i64 %867, -24
  %869 = load i64, i64* %PC, align 8
  %870 = add i64 %869, 4
  store i64 %870, i64* %PC, align 8
  %871 = inttoptr i64 %868 to i64*
  %872 = load i64, i64* %871, align 8
  store i64 %872, i64* %RDX, align 8, !tbaa !2428
  %873 = add i64 %867, -32
  %874 = add i64 %869, 7
  store i64 %874, i64* %PC, align 8
  %875 = inttoptr i64 %873 to i32*
  %876 = load i32, i32* %875, align 4
  %877 = add i32 %876, 1
  %878 = zext i32 %877 to i64
  store i64 %878, i64* %RCX, align 8, !tbaa !2428
  %879 = icmp eq i32 %876, -1
  %880 = icmp eq i32 %877, 0
  %881 = or i1 %879, %880
  %882 = zext i1 %881 to i8
  store i8 %882, i8* %17, align 1, !tbaa !2433
  %883 = and i32 %877, 255
  %884 = tail call i32 @llvm.ctpop.i32(i32 %883) #10
  %885 = trunc i32 %884 to i8
  %886 = and i8 %885, 1
  %887 = xor i8 %886, 1
  store i8 %887, i8* %24, align 1, !tbaa !2447
  %888 = xor i32 %876, %877
  %889 = lshr i32 %888, 4
  %890 = trunc i32 %889 to i8
  %891 = and i8 %890, 1
  store i8 %891, i8* %30, align 1, !tbaa !2451
  %892 = icmp eq i32 %877, 0
  %893 = zext i1 %892 to i8
  store i8 %893, i8* %33, align 1, !tbaa !2448
  %894 = lshr i32 %877, 31
  %895 = trunc i32 %894 to i8
  store i8 %895, i8* %36, align 1, !tbaa !2449
  %896 = lshr i32 %876, 31
  %897 = xor i32 %894, %896
  %898 = add nuw nsw i32 %897, %894
  %899 = icmp eq i32 %898, 2
  %900 = zext i1 %899 to i8
  store i8 %900, i8* %42, align 1, !tbaa !2450
  %901 = sext i32 %877 to i64
  store i64 %901, i64* %RSI, align 8, !tbaa !2428
  %902 = shl nsw i64 %901, 3
  %903 = add i64 %902, %872
  %904 = add i64 %869, 18
  store i64 %904, i64* %PC, align 8
  %905 = inttoptr i64 %903 to i64*
  %906 = load i64, i64* %905, align 8
  %907 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %906, i64* %907, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %908 = add i64 %867, -72
  %909 = add i64 %869, 23
  store i64 %909, i64* %PC, align 8
  %910 = inttoptr i64 %908 to i64*
  store i64 %906, i64* %910, align 8
  %911 = load i64, i64* %RBP, align 8
  %912 = add i64 %911, -24
  %913 = load i64, i64* %PC, align 8
  %914 = add i64 %913, 4
  store i64 %914, i64* %PC, align 8
  %915 = inttoptr i64 %912 to i64*
  %916 = load i64, i64* %915, align 8
  store i64 %916, i64* %RDX, align 8, !tbaa !2428
  %917 = add i64 %911, -36
  %918 = add i64 %913, 8
  store i64 %918, i64* %PC, align 8
  %919 = inttoptr i64 %917 to i32*
  %920 = load i32, i32* %919, align 4
  %921 = sext i32 %920 to i64
  store i64 %921, i64* %RSI, align 8, !tbaa !2428
  %922 = shl nsw i64 %921, 3
  %923 = add i64 %922, %916
  %924 = add i64 %913, 13
  store i64 %924, i64* %PC, align 8
  %925 = inttoptr i64 %923 to i64*
  %926 = load i64, i64* %925, align 8
  %927 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %926, i64* %927, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %928 = add i64 %911, -48
  %929 = add i64 %913, 18
  store i64 %929, i64* %PC, align 8
  %930 = inttoptr i64 %928 to i64*
  store i64 %926, i64* %930, align 8
  %931 = load i64, i64* %RBP, align 8
  %932 = add i64 %931, -24
  %933 = load i64, i64* %PC, align 8
  %934 = add i64 %933, 4
  store i64 %934, i64* %PC, align 8
  %935 = inttoptr i64 %932 to i64*
  %936 = load i64, i64* %935, align 8
  store i64 %936, i64* %RDX, align 8, !tbaa !2428
  %937 = add i64 %931, -36
  %938 = add i64 %933, 7
  store i64 %938, i64* %PC, align 8
  %939 = inttoptr i64 %937 to i32*
  %940 = load i32, i32* %939, align 4
  %941 = add i32 %940, 1
  %942 = zext i32 %941 to i64
  store i64 %942, i64* %RCX, align 8, !tbaa !2428
  %943 = icmp eq i32 %940, -1
  %944 = icmp eq i32 %941, 0
  %945 = or i1 %943, %944
  %946 = zext i1 %945 to i8
  store i8 %946, i8* %17, align 1, !tbaa !2433
  %947 = and i32 %941, 255
  %948 = tail call i32 @llvm.ctpop.i32(i32 %947) #10
  %949 = trunc i32 %948 to i8
  %950 = and i8 %949, 1
  %951 = xor i8 %950, 1
  store i8 %951, i8* %24, align 1, !tbaa !2447
  %952 = xor i32 %940, %941
  %953 = lshr i32 %952, 4
  %954 = trunc i32 %953 to i8
  %955 = and i8 %954, 1
  store i8 %955, i8* %30, align 1, !tbaa !2451
  %956 = icmp eq i32 %941, 0
  %957 = zext i1 %956 to i8
  store i8 %957, i8* %33, align 1, !tbaa !2448
  %958 = lshr i32 %941, 31
  %959 = trunc i32 %958 to i8
  store i8 %959, i8* %36, align 1, !tbaa !2449
  %960 = lshr i32 %940, 31
  %961 = xor i32 %958, %960
  %962 = add nuw nsw i32 %961, %958
  %963 = icmp eq i32 %962, 2
  %964 = zext i1 %963 to i8
  store i8 %964, i8* %42, align 1, !tbaa !2450
  %965 = sext i32 %941 to i64
  store i64 %965, i64* %RSI, align 8, !tbaa !2428
  %966 = shl nsw i64 %965, 3
  %967 = add i64 %966, %936
  %968 = add i64 %933, 18
  store i64 %968, i64* %PC, align 8
  %969 = inttoptr i64 %967 to i64*
  %970 = load i64, i64* %969, align 8
  %971 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %970, i64* %971, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %972 = add i64 %931, -56
  %973 = add i64 %933, 23
  store i64 %973, i64* %PC, align 8
  %974 = inttoptr i64 %972 to i64*
  store i64 %970, i64* %974, align 8
  %975 = load i64, i64* %RBP, align 8
  %976 = add i64 %975, -48
  %977 = load i64, i64* %PC, align 8
  %978 = add i64 %977, 5
  store i64 %978, i64* %PC, align 8
  %979 = inttoptr i64 %976 to double*
  %980 = load double, double* %979, align 8
  store double %980, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %981 = load <2 x i32>, <2 x i32>* %773, align 1
  %982 = load <2 x i32>, <2 x i32>* %775, align 1
  %983 = extractelement <2 x i32> %981, i32 0
  store i32 %983, i32* %776, align 1, !tbaa !2475
  %984 = extractelement <2 x i32> %981, i32 1
  store i32 %984, i32* %778, align 1, !tbaa !2475
  %985 = extractelement <2 x i32> %982, i32 0
  store i32 %985, i32* %780, align 1, !tbaa !2475
  %986 = extractelement <2 x i32> %982, i32 1
  store i32 %986, i32* %782, align 1, !tbaa !2475
  %987 = add i64 %975, -72
  %988 = add i64 %977, 13
  store i64 %988, i64* %PC, align 8
  %989 = load double, double* %783, align 1
  %990 = inttoptr i64 %987 to double*
  %991 = load double, double* %990, align 8
  %992 = fmul double %989, %991
  store double %992, double* %783, align 1, !tbaa !2452
  %993 = add i64 %975, -56
  %994 = add i64 %977, 18
  store i64 %994, i64* %PC, align 8
  %995 = inttoptr i64 %993 to double*
  %996 = load double, double* %995, align 8
  %997 = fmul double %992, %996
  store double %997, double* %783, align 1, !tbaa !2452
  %998 = fsub double %980, %997
  %999 = add i64 %975, -80
  %1000 = add i64 %977, 27
  store i64 %1000, i64* %PC, align 8
  %1001 = inttoptr i64 %999 to double*
  store double %998, double* %1001, align 8
  %1002 = load i64, i64* %PC, align 8
  %1003 = load <2 x i32>, <2 x i32>* %773, align 1
  %1004 = load <2 x i32>, <2 x i32>* %775, align 1
  %1005 = extractelement <2 x i32> %1003, i32 0
  store i32 %1005, i32* %784, align 1, !tbaa !2475
  %1006 = extractelement <2 x i32> %1003, i32 1
  store i32 %1006, i32* %786, align 1, !tbaa !2475
  %1007 = extractelement <2 x i32> %1004, i32 0
  store i32 %1007, i32* %787, align 1, !tbaa !2475
  %1008 = extractelement <2 x i32> %1004, i32 1
  store i32 %1008, i32* %789, align 1, !tbaa !2475
  %1009 = load i64, i64* %RBP, align 8
  %1010 = add i64 %1009, -72
  %1011 = add i64 %1002, 8
  store i64 %1011, i64* %PC, align 8
  %1012 = load double, double* %648, align 1
  %1013 = inttoptr i64 %1010 to double*
  %1014 = load double, double* %1013, align 8
  %1015 = fmul double %1012, %1014
  store double %1015, double* %648, align 1, !tbaa !2452
  %1016 = add i64 %1009, -48
  %1017 = add i64 %1002, 13
  store i64 %1017, i64* %PC, align 8
  %1018 = inttoptr i64 %1016 to double*
  %1019 = load double, double* %1018, align 8
  %1020 = fmul double %1015, %1019
  store double %1020, double* %648, align 1, !tbaa !2452
  %1021 = add i64 %1009, -56
  %1022 = add i64 %1002, 18
  store i64 %1022, i64* %PC, align 8
  %1023 = inttoptr i64 %1021 to double*
  %1024 = load double, double* %1023, align 8
  %1025 = fsub double %1020, %1024
  store double %1025, double* %648, align 1, !tbaa !2452
  %1026 = add i64 %1009, -88
  %1027 = add i64 %1002, 23
  store i64 %1027, i64* %PC, align 8
  %1028 = inttoptr i64 %1026 to double*
  store double %1025, double* %1028, align 8
  %1029 = load i64, i64* %RBP, align 8
  %1030 = add i64 %1029, -16
  %1031 = load i64, i64* %PC, align 8
  %1032 = add i64 %1031, 4
  store i64 %1032, i64* %PC, align 8
  %1033 = inttoptr i64 %1030 to i64*
  %1034 = load i64, i64* %1033, align 8
  store i64 %1034, i64* %RDX, align 8, !tbaa !2428
  %1035 = add i64 %1029, -28
  %1036 = add i64 %1031, 8
  store i64 %1036, i64* %PC, align 8
  %1037 = inttoptr i64 %1035 to i32*
  %1038 = load i32, i32* %1037, align 4
  %1039 = sext i32 %1038 to i64
  store i64 %1039, i64* %RSI, align 8, !tbaa !2428
  %1040 = shl nsw i64 %1039, 3
  %1041 = add i64 %1040, %1034
  %1042 = add i64 %1031, 13
  store i64 %1042, i64* %PC, align 8
  %1043 = inttoptr i64 %1041 to double*
  %1044 = load double, double* %1043, align 8
  store double %1044, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1045 = add i64 %1031, 17
  store i64 %1045, i64* %PC, align 8
  %1046 = load i64, i64* %1033, align 8
  store i64 %1046, i64* %RDX, align 8, !tbaa !2428
  %1047 = add i64 %1031, 20
  store i64 %1047, i64* %PC, align 8
  %1048 = load i32, i32* %1037, align 4
  %1049 = add i32 %1048, 2
  %1050 = zext i32 %1049 to i64
  store i64 %1050, i64* %RCX, align 8, !tbaa !2428
  %1051 = icmp ugt i32 %1048, -3
  %1052 = zext i1 %1051 to i8
  store i8 %1052, i8* %17, align 1, !tbaa !2433
  %1053 = and i32 %1049, 255
  %1054 = tail call i32 @llvm.ctpop.i32(i32 %1053) #10
  %1055 = trunc i32 %1054 to i8
  %1056 = and i8 %1055, 1
  %1057 = xor i8 %1056, 1
  store i8 %1057, i8* %24, align 1, !tbaa !2447
  %1058 = xor i32 %1048, %1049
  %1059 = lshr i32 %1058, 4
  %1060 = trunc i32 %1059 to i8
  %1061 = and i8 %1060, 1
  store i8 %1061, i8* %30, align 1, !tbaa !2451
  %1062 = icmp eq i32 %1049, 0
  %1063 = zext i1 %1062 to i8
  store i8 %1063, i8* %33, align 1, !tbaa !2448
  %1064 = lshr i32 %1049, 31
  %1065 = trunc i32 %1064 to i8
  store i8 %1065, i8* %36, align 1, !tbaa !2449
  %1066 = lshr i32 %1048, 31
  %1067 = xor i32 %1064, %1066
  %1068 = add nuw nsw i32 %1067, %1064
  %1069 = icmp eq i32 %1068, 2
  %1070 = zext i1 %1069 to i8
  store i8 %1070, i8* %42, align 1, !tbaa !2450
  %1071 = sext i32 %1049 to i64
  store i64 %1071, i64* %RSI, align 8, !tbaa !2428
  %1072 = shl nsw i64 %1071, 3
  %1073 = add i64 %1072, %1046
  %1074 = add i64 %1031, 31
  store i64 %1074, i64* %PC, align 8
  %1075 = inttoptr i64 %1073 to double*
  %1076 = load double, double* %1075, align 8
  %1077 = fadd double %1044, %1076
  store double %1077, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1078 = add i64 %1029, -96
  %1079 = add i64 %1031, 36
  store i64 %1079, i64* %PC, align 8
  %1080 = inttoptr i64 %1078 to double*
  store double %1077, double* %1080, align 8
  %1081 = load i64, i64* %RBP, align 8
  %1082 = add i64 %1081, -16
  %1083 = load i64, i64* %PC, align 8
  %1084 = add i64 %1083, 4
  store i64 %1084, i64* %PC, align 8
  %1085 = inttoptr i64 %1082 to i64*
  %1086 = load i64, i64* %1085, align 8
  store i64 %1086, i64* %RDX, align 8, !tbaa !2428
  %1087 = add i64 %1081, -28
  %1088 = add i64 %1083, 7
  store i64 %1088, i64* %PC, align 8
  %1089 = inttoptr i64 %1087 to i32*
  %1090 = load i32, i32* %1089, align 4
  %1091 = add i32 %1090, 1
  %1092 = zext i32 %1091 to i64
  store i64 %1092, i64* %RCX, align 8, !tbaa !2428
  %1093 = icmp eq i32 %1090, -1
  %1094 = icmp eq i32 %1091, 0
  %1095 = or i1 %1093, %1094
  %1096 = zext i1 %1095 to i8
  store i8 %1096, i8* %17, align 1, !tbaa !2433
  %1097 = and i32 %1091, 255
  %1098 = tail call i32 @llvm.ctpop.i32(i32 %1097) #10
  %1099 = trunc i32 %1098 to i8
  %1100 = and i8 %1099, 1
  %1101 = xor i8 %1100, 1
  store i8 %1101, i8* %24, align 1, !tbaa !2447
  %1102 = xor i32 %1090, %1091
  %1103 = lshr i32 %1102, 4
  %1104 = trunc i32 %1103 to i8
  %1105 = and i8 %1104, 1
  store i8 %1105, i8* %30, align 1, !tbaa !2451
  %1106 = icmp eq i32 %1091, 0
  %1107 = zext i1 %1106 to i8
  store i8 %1107, i8* %33, align 1, !tbaa !2448
  %1108 = lshr i32 %1091, 31
  %1109 = trunc i32 %1108 to i8
  store i8 %1109, i8* %36, align 1, !tbaa !2449
  %1110 = lshr i32 %1090, 31
  %1111 = xor i32 %1108, %1110
  %1112 = add nuw nsw i32 %1111, %1108
  %1113 = icmp eq i32 %1112, 2
  %1114 = zext i1 %1113 to i8
  store i8 %1114, i8* %42, align 1, !tbaa !2450
  %1115 = sext i32 %1091 to i64
  store i64 %1115, i64* %RSI, align 8, !tbaa !2428
  %1116 = shl nsw i64 %1115, 3
  %1117 = add i64 %1116, %1086
  %1118 = add i64 %1083, 18
  store i64 %1118, i64* %PC, align 8
  %1119 = inttoptr i64 %1117 to double*
  %1120 = load double, double* %1119, align 8
  store double %1120, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1121 = add i64 %1083, 22
  store i64 %1121, i64* %PC, align 8
  %1122 = load i64, i64* %1085, align 8
  store i64 %1122, i64* %RDX, align 8, !tbaa !2428
  %1123 = add i64 %1083, 25
  store i64 %1123, i64* %PC, align 8
  %1124 = load i32, i32* %1089, align 4
  %1125 = add i32 %1124, 3
  %1126 = zext i32 %1125 to i64
  store i64 %1126, i64* %RCX, align 8, !tbaa !2428
  %1127 = icmp ugt i32 %1124, -4
  %1128 = zext i1 %1127 to i8
  store i8 %1128, i8* %17, align 1, !tbaa !2433
  %1129 = and i32 %1125, 255
  %1130 = tail call i32 @llvm.ctpop.i32(i32 %1129) #10
  %1131 = trunc i32 %1130 to i8
  %1132 = and i8 %1131, 1
  %1133 = xor i8 %1132, 1
  store i8 %1133, i8* %24, align 1, !tbaa !2447
  %1134 = xor i32 %1124, %1125
  %1135 = lshr i32 %1134, 4
  %1136 = trunc i32 %1135 to i8
  %1137 = and i8 %1136, 1
  store i8 %1137, i8* %30, align 1, !tbaa !2451
  %1138 = icmp eq i32 %1125, 0
  %1139 = zext i1 %1138 to i8
  store i8 %1139, i8* %33, align 1, !tbaa !2448
  %1140 = lshr i32 %1125, 31
  %1141 = trunc i32 %1140 to i8
  store i8 %1141, i8* %36, align 1, !tbaa !2449
  %1142 = lshr i32 %1124, 31
  %1143 = xor i32 %1140, %1142
  %1144 = add nuw nsw i32 %1143, %1140
  %1145 = icmp eq i32 %1144, 2
  %1146 = zext i1 %1145 to i8
  store i8 %1146, i8* %42, align 1, !tbaa !2450
  %1147 = sext i32 %1125 to i64
  store i64 %1147, i64* %RSI, align 8, !tbaa !2428
  %1148 = shl nsw i64 %1147, 3
  %1149 = add i64 %1148, %1122
  %1150 = add i64 %1083, 36
  store i64 %1150, i64* %PC, align 8
  %1151 = inttoptr i64 %1149 to double*
  %1152 = load double, double* %1151, align 8
  %1153 = fadd double %1120, %1152
  store double %1153, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1154 = load i64, i64* %RBP, align 8
  %1155 = add i64 %1154, -104
  %1156 = add i64 %1083, 41
  store i64 %1156, i64* %PC, align 8
  %1157 = inttoptr i64 %1155 to double*
  store double %1153, double* %1157, align 8
  %1158 = load i64, i64* %RBP, align 8
  %1159 = add i64 %1158, -16
  %1160 = load i64, i64* %PC, align 8
  %1161 = add i64 %1160, 4
  store i64 %1161, i64* %PC, align 8
  %1162 = inttoptr i64 %1159 to i64*
  %1163 = load i64, i64* %1162, align 8
  store i64 %1163, i64* %RDX, align 8, !tbaa !2428
  %1164 = add i64 %1158, -28
  %1165 = add i64 %1160, 8
  store i64 %1165, i64* %PC, align 8
  %1166 = inttoptr i64 %1164 to i32*
  %1167 = load i32, i32* %1166, align 4
  %1168 = sext i32 %1167 to i64
  store i64 %1168, i64* %RSI, align 8, !tbaa !2428
  %1169 = shl nsw i64 %1168, 3
  %1170 = add i64 %1169, %1163
  %1171 = add i64 %1160, 13
  store i64 %1171, i64* %PC, align 8
  %1172 = inttoptr i64 %1170 to double*
  %1173 = load double, double* %1172, align 8
  store double %1173, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1174 = add i64 %1160, 17
  store i64 %1174, i64* %PC, align 8
  %1175 = load i64, i64* %1162, align 8
  store i64 %1175, i64* %RDX, align 8, !tbaa !2428
  %1176 = add i64 %1160, 20
  store i64 %1176, i64* %PC, align 8
  %1177 = load i32, i32* %1166, align 4
  %1178 = add i32 %1177, 2
  %1179 = zext i32 %1178 to i64
  store i64 %1179, i64* %RCX, align 8, !tbaa !2428
  %1180 = icmp ugt i32 %1177, -3
  %1181 = zext i1 %1180 to i8
  store i8 %1181, i8* %17, align 1, !tbaa !2433
  %1182 = and i32 %1178, 255
  %1183 = tail call i32 @llvm.ctpop.i32(i32 %1182) #10
  %1184 = trunc i32 %1183 to i8
  %1185 = and i8 %1184, 1
  %1186 = xor i8 %1185, 1
  store i8 %1186, i8* %24, align 1, !tbaa !2447
  %1187 = xor i32 %1177, %1178
  %1188 = lshr i32 %1187, 4
  %1189 = trunc i32 %1188 to i8
  %1190 = and i8 %1189, 1
  store i8 %1190, i8* %30, align 1, !tbaa !2451
  %1191 = icmp eq i32 %1178, 0
  %1192 = zext i1 %1191 to i8
  store i8 %1192, i8* %33, align 1, !tbaa !2448
  %1193 = lshr i32 %1178, 31
  %1194 = trunc i32 %1193 to i8
  store i8 %1194, i8* %36, align 1, !tbaa !2449
  %1195 = lshr i32 %1177, 31
  %1196 = xor i32 %1193, %1195
  %1197 = add nuw nsw i32 %1196, %1193
  %1198 = icmp eq i32 %1197, 2
  %1199 = zext i1 %1198 to i8
  store i8 %1199, i8* %42, align 1, !tbaa !2450
  %1200 = sext i32 %1178 to i64
  store i64 %1200, i64* %RSI, align 8, !tbaa !2428
  %1201 = shl nsw i64 %1200, 3
  %1202 = add i64 %1201, %1175
  %1203 = add i64 %1160, 31
  store i64 %1203, i64* %PC, align 8
  %1204 = inttoptr i64 %1202 to double*
  %1205 = load double, double* %1204, align 8
  %1206 = fsub double %1173, %1205
  store double %1206, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1207 = add i64 %1158, -112
  %1208 = add i64 %1160, 36
  store i64 %1208, i64* %PC, align 8
  %1209 = inttoptr i64 %1207 to double*
  store double %1206, double* %1209, align 8
  %1210 = load i64, i64* %RBP, align 8
  %1211 = add i64 %1210, -16
  %1212 = load i64, i64* %PC, align 8
  %1213 = add i64 %1212, 4
  store i64 %1213, i64* %PC, align 8
  %1214 = inttoptr i64 %1211 to i64*
  %1215 = load i64, i64* %1214, align 8
  store i64 %1215, i64* %RDX, align 8, !tbaa !2428
  %1216 = add i64 %1210, -28
  %1217 = add i64 %1212, 7
  store i64 %1217, i64* %PC, align 8
  %1218 = inttoptr i64 %1216 to i32*
  %1219 = load i32, i32* %1218, align 4
  %1220 = add i32 %1219, 1
  %1221 = zext i32 %1220 to i64
  store i64 %1221, i64* %RCX, align 8, !tbaa !2428
  %1222 = icmp eq i32 %1219, -1
  %1223 = icmp eq i32 %1220, 0
  %1224 = or i1 %1222, %1223
  %1225 = zext i1 %1224 to i8
  store i8 %1225, i8* %17, align 1, !tbaa !2433
  %1226 = and i32 %1220, 255
  %1227 = tail call i32 @llvm.ctpop.i32(i32 %1226) #10
  %1228 = trunc i32 %1227 to i8
  %1229 = and i8 %1228, 1
  %1230 = xor i8 %1229, 1
  store i8 %1230, i8* %24, align 1, !tbaa !2447
  %1231 = xor i32 %1219, %1220
  %1232 = lshr i32 %1231, 4
  %1233 = trunc i32 %1232 to i8
  %1234 = and i8 %1233, 1
  store i8 %1234, i8* %30, align 1, !tbaa !2451
  %1235 = icmp eq i32 %1220, 0
  %1236 = zext i1 %1235 to i8
  store i8 %1236, i8* %33, align 1, !tbaa !2448
  %1237 = lshr i32 %1220, 31
  %1238 = trunc i32 %1237 to i8
  store i8 %1238, i8* %36, align 1, !tbaa !2449
  %1239 = lshr i32 %1219, 31
  %1240 = xor i32 %1237, %1239
  %1241 = add nuw nsw i32 %1240, %1237
  %1242 = icmp eq i32 %1241, 2
  %1243 = zext i1 %1242 to i8
  store i8 %1243, i8* %42, align 1, !tbaa !2450
  %1244 = sext i32 %1220 to i64
  store i64 %1244, i64* %RSI, align 8, !tbaa !2428
  %1245 = shl nsw i64 %1244, 3
  %1246 = add i64 %1245, %1215
  %1247 = add i64 %1212, 18
  store i64 %1247, i64* %PC, align 8
  %1248 = inttoptr i64 %1246 to double*
  %1249 = load double, double* %1248, align 8
  store double %1249, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1250 = add i64 %1212, 22
  store i64 %1250, i64* %PC, align 8
  %1251 = load i64, i64* %1214, align 8
  store i64 %1251, i64* %RDX, align 8, !tbaa !2428
  %1252 = add i64 %1212, 25
  store i64 %1252, i64* %PC, align 8
  %1253 = load i32, i32* %1218, align 4
  %1254 = add i32 %1253, 3
  %1255 = zext i32 %1254 to i64
  store i64 %1255, i64* %RCX, align 8, !tbaa !2428
  %1256 = icmp ugt i32 %1253, -4
  %1257 = zext i1 %1256 to i8
  store i8 %1257, i8* %17, align 1, !tbaa !2433
  %1258 = and i32 %1254, 255
  %1259 = tail call i32 @llvm.ctpop.i32(i32 %1258) #10
  %1260 = trunc i32 %1259 to i8
  %1261 = and i8 %1260, 1
  %1262 = xor i8 %1261, 1
  store i8 %1262, i8* %24, align 1, !tbaa !2447
  %1263 = xor i32 %1253, %1254
  %1264 = lshr i32 %1263, 4
  %1265 = trunc i32 %1264 to i8
  %1266 = and i8 %1265, 1
  store i8 %1266, i8* %30, align 1, !tbaa !2451
  %1267 = icmp eq i32 %1254, 0
  %1268 = zext i1 %1267 to i8
  store i8 %1268, i8* %33, align 1, !tbaa !2448
  %1269 = lshr i32 %1254, 31
  %1270 = trunc i32 %1269 to i8
  store i8 %1270, i8* %36, align 1, !tbaa !2449
  %1271 = lshr i32 %1253, 31
  %1272 = xor i32 %1269, %1271
  %1273 = add nuw nsw i32 %1272, %1269
  %1274 = icmp eq i32 %1273, 2
  %1275 = zext i1 %1274 to i8
  store i8 %1275, i8* %42, align 1, !tbaa !2450
  %1276 = sext i32 %1254 to i64
  store i64 %1276, i64* %RSI, align 8, !tbaa !2428
  %1277 = shl nsw i64 %1276, 3
  %1278 = add i64 %1277, %1251
  %1279 = add i64 %1212, 36
  store i64 %1279, i64* %PC, align 8
  %1280 = inttoptr i64 %1278 to double*
  %1281 = load double, double* %1280, align 8
  %1282 = fsub double %1249, %1281
  store double %1282, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1283 = load i64, i64* %RBP, align 8
  %1284 = add i64 %1283, -120
  %1285 = add i64 %1212, 41
  store i64 %1285, i64* %PC, align 8
  %1286 = inttoptr i64 %1284 to double*
  store double %1282, double* %1286, align 8
  %1287 = load i64, i64* %RBP, align 8
  %1288 = add i64 %1287, -16
  %1289 = load i64, i64* %PC, align 8
  %1290 = add i64 %1289, 4
  store i64 %1290, i64* %PC, align 8
  %1291 = inttoptr i64 %1288 to i64*
  %1292 = load i64, i64* %1291, align 8
  store i64 %1292, i64* %RDX, align 8, !tbaa !2428
  %1293 = add i64 %1287, -28
  %1294 = add i64 %1289, 7
  store i64 %1294, i64* %PC, align 8
  %1295 = inttoptr i64 %1293 to i32*
  %1296 = load i32, i32* %1295, align 4
  %1297 = add i32 %1296, 4
  %1298 = zext i32 %1297 to i64
  store i64 %1298, i64* %RCX, align 8, !tbaa !2428
  %1299 = icmp ugt i32 %1296, -5
  %1300 = zext i1 %1299 to i8
  store i8 %1300, i8* %17, align 1, !tbaa !2433
  %1301 = and i32 %1297, 255
  %1302 = tail call i32 @llvm.ctpop.i32(i32 %1301) #10
  %1303 = trunc i32 %1302 to i8
  %1304 = and i8 %1303, 1
  %1305 = xor i8 %1304, 1
  store i8 %1305, i8* %24, align 1, !tbaa !2447
  %1306 = xor i32 %1296, %1297
  %1307 = lshr i32 %1306, 4
  %1308 = trunc i32 %1307 to i8
  %1309 = and i8 %1308, 1
  store i8 %1309, i8* %30, align 1, !tbaa !2451
  %1310 = icmp eq i32 %1297, 0
  %1311 = zext i1 %1310 to i8
  store i8 %1311, i8* %33, align 1, !tbaa !2448
  %1312 = lshr i32 %1297, 31
  %1313 = trunc i32 %1312 to i8
  store i8 %1313, i8* %36, align 1, !tbaa !2449
  %1314 = lshr i32 %1296, 31
  %1315 = xor i32 %1312, %1314
  %1316 = add nuw nsw i32 %1315, %1312
  %1317 = icmp eq i32 %1316, 2
  %1318 = zext i1 %1317 to i8
  store i8 %1318, i8* %42, align 1, !tbaa !2450
  %1319 = sext i32 %1297 to i64
  store i64 %1319, i64* %RSI, align 8, !tbaa !2428
  %1320 = shl nsw i64 %1319, 3
  %1321 = add i64 %1320, %1292
  %1322 = add i64 %1289, 18
  store i64 %1322, i64* %PC, align 8
  %1323 = inttoptr i64 %1321 to double*
  %1324 = load double, double* %1323, align 8
  store double %1324, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1325 = add i64 %1289, 22
  store i64 %1325, i64* %PC, align 8
  %1326 = load i64, i64* %1291, align 8
  store i64 %1326, i64* %RDX, align 8, !tbaa !2428
  %1327 = add i64 %1289, 25
  store i64 %1327, i64* %PC, align 8
  %1328 = load i32, i32* %1295, align 4
  %1329 = add i32 %1328, 6
  %1330 = zext i32 %1329 to i64
  store i64 %1330, i64* %RCX, align 8, !tbaa !2428
  %1331 = icmp ugt i32 %1328, -7
  %1332 = zext i1 %1331 to i8
  store i8 %1332, i8* %17, align 1, !tbaa !2433
  %1333 = and i32 %1329, 255
  %1334 = tail call i32 @llvm.ctpop.i32(i32 %1333) #10
  %1335 = trunc i32 %1334 to i8
  %1336 = and i8 %1335, 1
  %1337 = xor i8 %1336, 1
  store i8 %1337, i8* %24, align 1, !tbaa !2447
  %1338 = xor i32 %1328, %1329
  %1339 = lshr i32 %1338, 4
  %1340 = trunc i32 %1339 to i8
  %1341 = and i8 %1340, 1
  store i8 %1341, i8* %30, align 1, !tbaa !2451
  %1342 = icmp eq i32 %1329, 0
  %1343 = zext i1 %1342 to i8
  store i8 %1343, i8* %33, align 1, !tbaa !2448
  %1344 = lshr i32 %1329, 31
  %1345 = trunc i32 %1344 to i8
  store i8 %1345, i8* %36, align 1, !tbaa !2449
  %1346 = lshr i32 %1328, 31
  %1347 = xor i32 %1344, %1346
  %1348 = add nuw nsw i32 %1347, %1344
  %1349 = icmp eq i32 %1348, 2
  %1350 = zext i1 %1349 to i8
  store i8 %1350, i8* %42, align 1, !tbaa !2450
  %1351 = sext i32 %1329 to i64
  store i64 %1351, i64* %RSI, align 8, !tbaa !2428
  %1352 = shl nsw i64 %1351, 3
  %1353 = add i64 %1352, %1326
  %1354 = add i64 %1289, 36
  store i64 %1354, i64* %PC, align 8
  %1355 = inttoptr i64 %1353 to double*
  %1356 = load double, double* %1355, align 8
  %1357 = fadd double %1324, %1356
  store double %1357, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1358 = load i64, i64* %RBP, align 8
  %1359 = add i64 %1358, -128
  %1360 = add i64 %1289, 41
  store i64 %1360, i64* %PC, align 8
  %1361 = inttoptr i64 %1359 to double*
  store double %1357, double* %1361, align 8
  %1362 = load i64, i64* %RBP, align 8
  %1363 = add i64 %1362, -16
  %1364 = load i64, i64* %PC, align 8
  %1365 = add i64 %1364, 4
  store i64 %1365, i64* %PC, align 8
  %1366 = inttoptr i64 %1363 to i64*
  %1367 = load i64, i64* %1366, align 8
  store i64 %1367, i64* %RDX, align 8, !tbaa !2428
  %1368 = add i64 %1362, -28
  %1369 = add i64 %1364, 7
  store i64 %1369, i64* %PC, align 8
  %1370 = inttoptr i64 %1368 to i32*
  %1371 = load i32, i32* %1370, align 4
  %1372 = add i32 %1371, 5
  %1373 = zext i32 %1372 to i64
  store i64 %1373, i64* %RCX, align 8, !tbaa !2428
  %1374 = icmp ugt i32 %1371, -6
  %1375 = zext i1 %1374 to i8
  store i8 %1375, i8* %17, align 1, !tbaa !2433
  %1376 = and i32 %1372, 255
  %1377 = tail call i32 @llvm.ctpop.i32(i32 %1376) #10
  %1378 = trunc i32 %1377 to i8
  %1379 = and i8 %1378, 1
  %1380 = xor i8 %1379, 1
  store i8 %1380, i8* %24, align 1, !tbaa !2447
  %1381 = xor i32 %1371, %1372
  %1382 = lshr i32 %1381, 4
  %1383 = trunc i32 %1382 to i8
  %1384 = and i8 %1383, 1
  store i8 %1384, i8* %30, align 1, !tbaa !2451
  %1385 = icmp eq i32 %1372, 0
  %1386 = zext i1 %1385 to i8
  store i8 %1386, i8* %33, align 1, !tbaa !2448
  %1387 = lshr i32 %1372, 31
  %1388 = trunc i32 %1387 to i8
  store i8 %1388, i8* %36, align 1, !tbaa !2449
  %1389 = lshr i32 %1371, 31
  %1390 = xor i32 %1387, %1389
  %1391 = add nuw nsw i32 %1390, %1387
  %1392 = icmp eq i32 %1391, 2
  %1393 = zext i1 %1392 to i8
  store i8 %1393, i8* %42, align 1, !tbaa !2450
  %1394 = sext i32 %1372 to i64
  store i64 %1394, i64* %RSI, align 8, !tbaa !2428
  %1395 = shl nsw i64 %1394, 3
  %1396 = add i64 %1395, %1367
  %1397 = add i64 %1364, 18
  store i64 %1397, i64* %PC, align 8
  %1398 = inttoptr i64 %1396 to double*
  %1399 = load double, double* %1398, align 8
  store double %1399, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1400 = add i64 %1364, 22
  store i64 %1400, i64* %PC, align 8
  %1401 = load i64, i64* %1366, align 8
  store i64 %1401, i64* %RDX, align 8, !tbaa !2428
  %1402 = add i64 %1364, 25
  store i64 %1402, i64* %PC, align 8
  %1403 = load i32, i32* %1370, align 4
  %1404 = add i32 %1403, 7
  %1405 = zext i32 %1404 to i64
  store i64 %1405, i64* %RCX, align 8, !tbaa !2428
  %1406 = icmp ugt i32 %1403, -8
  %1407 = zext i1 %1406 to i8
  store i8 %1407, i8* %17, align 1, !tbaa !2433
  %1408 = and i32 %1404, 255
  %1409 = tail call i32 @llvm.ctpop.i32(i32 %1408) #10
  %1410 = trunc i32 %1409 to i8
  %1411 = and i8 %1410, 1
  %1412 = xor i8 %1411, 1
  store i8 %1412, i8* %24, align 1, !tbaa !2447
  %1413 = xor i32 %1403, %1404
  %1414 = lshr i32 %1413, 4
  %1415 = trunc i32 %1414 to i8
  %1416 = and i8 %1415, 1
  store i8 %1416, i8* %30, align 1, !tbaa !2451
  %1417 = icmp eq i32 %1404, 0
  %1418 = zext i1 %1417 to i8
  store i8 %1418, i8* %33, align 1, !tbaa !2448
  %1419 = lshr i32 %1404, 31
  %1420 = trunc i32 %1419 to i8
  store i8 %1420, i8* %36, align 1, !tbaa !2449
  %1421 = lshr i32 %1403, 31
  %1422 = xor i32 %1419, %1421
  %1423 = add nuw nsw i32 %1422, %1419
  %1424 = icmp eq i32 %1423, 2
  %1425 = zext i1 %1424 to i8
  store i8 %1425, i8* %42, align 1, !tbaa !2450
  %1426 = sext i32 %1404 to i64
  store i64 %1426, i64* %RSI, align 8, !tbaa !2428
  %1427 = shl nsw i64 %1426, 3
  %1428 = add i64 %1427, %1401
  %1429 = add i64 %1364, 36
  store i64 %1429, i64* %PC, align 8
  %1430 = inttoptr i64 %1428 to double*
  %1431 = load double, double* %1430, align 8
  %1432 = fadd double %1399, %1431
  store double %1432, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1433 = load i64, i64* %RBP, align 8
  %1434 = add i64 %1433, -136
  %1435 = add i64 %1364, 44
  store i64 %1435, i64* %PC, align 8
  %1436 = inttoptr i64 %1434 to double*
  store double %1432, double* %1436, align 8
  %1437 = load i64, i64* %RBP, align 8
  %1438 = add i64 %1437, -16
  %1439 = load i64, i64* %PC, align 8
  %1440 = add i64 %1439, 4
  store i64 %1440, i64* %PC, align 8
  %1441 = inttoptr i64 %1438 to i64*
  %1442 = load i64, i64* %1441, align 8
  store i64 %1442, i64* %RDX, align 8, !tbaa !2428
  %1443 = add i64 %1437, -28
  %1444 = add i64 %1439, 7
  store i64 %1444, i64* %PC, align 8
  %1445 = inttoptr i64 %1443 to i32*
  %1446 = load i32, i32* %1445, align 4
  %1447 = add i32 %1446, 4
  %1448 = zext i32 %1447 to i64
  store i64 %1448, i64* %RCX, align 8, !tbaa !2428
  %1449 = icmp ugt i32 %1446, -5
  %1450 = zext i1 %1449 to i8
  store i8 %1450, i8* %17, align 1, !tbaa !2433
  %1451 = and i32 %1447, 255
  %1452 = tail call i32 @llvm.ctpop.i32(i32 %1451) #10
  %1453 = trunc i32 %1452 to i8
  %1454 = and i8 %1453, 1
  %1455 = xor i8 %1454, 1
  store i8 %1455, i8* %24, align 1, !tbaa !2447
  %1456 = xor i32 %1446, %1447
  %1457 = lshr i32 %1456, 4
  %1458 = trunc i32 %1457 to i8
  %1459 = and i8 %1458, 1
  store i8 %1459, i8* %30, align 1, !tbaa !2451
  %1460 = icmp eq i32 %1447, 0
  %1461 = zext i1 %1460 to i8
  store i8 %1461, i8* %33, align 1, !tbaa !2448
  %1462 = lshr i32 %1447, 31
  %1463 = trunc i32 %1462 to i8
  store i8 %1463, i8* %36, align 1, !tbaa !2449
  %1464 = lshr i32 %1446, 31
  %1465 = xor i32 %1462, %1464
  %1466 = add nuw nsw i32 %1465, %1462
  %1467 = icmp eq i32 %1466, 2
  %1468 = zext i1 %1467 to i8
  store i8 %1468, i8* %42, align 1, !tbaa !2450
  %1469 = sext i32 %1447 to i64
  store i64 %1469, i64* %RSI, align 8, !tbaa !2428
  %1470 = shl nsw i64 %1469, 3
  %1471 = add i64 %1470, %1442
  %1472 = add i64 %1439, 18
  store i64 %1472, i64* %PC, align 8
  %1473 = inttoptr i64 %1471 to double*
  %1474 = load double, double* %1473, align 8
  store double %1474, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1475 = add i64 %1439, 22
  store i64 %1475, i64* %PC, align 8
  %1476 = load i64, i64* %1441, align 8
  store i64 %1476, i64* %RDX, align 8, !tbaa !2428
  %1477 = add i64 %1439, 25
  store i64 %1477, i64* %PC, align 8
  %1478 = load i32, i32* %1445, align 4
  %1479 = add i32 %1478, 6
  %1480 = zext i32 %1479 to i64
  store i64 %1480, i64* %RCX, align 8, !tbaa !2428
  %1481 = icmp ugt i32 %1478, -7
  %1482 = zext i1 %1481 to i8
  store i8 %1482, i8* %17, align 1, !tbaa !2433
  %1483 = and i32 %1479, 255
  %1484 = tail call i32 @llvm.ctpop.i32(i32 %1483) #10
  %1485 = trunc i32 %1484 to i8
  %1486 = and i8 %1485, 1
  %1487 = xor i8 %1486, 1
  store i8 %1487, i8* %24, align 1, !tbaa !2447
  %1488 = xor i32 %1478, %1479
  %1489 = lshr i32 %1488, 4
  %1490 = trunc i32 %1489 to i8
  %1491 = and i8 %1490, 1
  store i8 %1491, i8* %30, align 1, !tbaa !2451
  %1492 = icmp eq i32 %1479, 0
  %1493 = zext i1 %1492 to i8
  store i8 %1493, i8* %33, align 1, !tbaa !2448
  %1494 = lshr i32 %1479, 31
  %1495 = trunc i32 %1494 to i8
  store i8 %1495, i8* %36, align 1, !tbaa !2449
  %1496 = lshr i32 %1478, 31
  %1497 = xor i32 %1494, %1496
  %1498 = add nuw nsw i32 %1497, %1494
  %1499 = icmp eq i32 %1498, 2
  %1500 = zext i1 %1499 to i8
  store i8 %1500, i8* %42, align 1, !tbaa !2450
  %1501 = sext i32 %1479 to i64
  store i64 %1501, i64* %RSI, align 8, !tbaa !2428
  %1502 = shl nsw i64 %1501, 3
  %1503 = add i64 %1502, %1476
  %1504 = add i64 %1439, 36
  store i64 %1504, i64* %PC, align 8
  %1505 = inttoptr i64 %1503 to double*
  %1506 = load double, double* %1505, align 8
  %1507 = fsub double %1474, %1506
  store double %1507, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1508 = load i64, i64* %RBP, align 8
  %1509 = add i64 %1508, -144
  %1510 = add i64 %1439, 44
  store i64 %1510, i64* %PC, align 8
  %1511 = inttoptr i64 %1509 to double*
  store double %1507, double* %1511, align 8
  %1512 = load i64, i64* %RBP, align 8
  %1513 = add i64 %1512, -16
  %1514 = load i64, i64* %PC, align 8
  %1515 = add i64 %1514, 4
  store i64 %1515, i64* %PC, align 8
  %1516 = inttoptr i64 %1513 to i64*
  %1517 = load i64, i64* %1516, align 8
  store i64 %1517, i64* %RDX, align 8, !tbaa !2428
  %1518 = add i64 %1512, -28
  %1519 = add i64 %1514, 7
  store i64 %1519, i64* %PC, align 8
  %1520 = inttoptr i64 %1518 to i32*
  %1521 = load i32, i32* %1520, align 4
  %1522 = add i32 %1521, 5
  %1523 = zext i32 %1522 to i64
  store i64 %1523, i64* %RCX, align 8, !tbaa !2428
  %1524 = icmp ugt i32 %1521, -6
  %1525 = zext i1 %1524 to i8
  store i8 %1525, i8* %17, align 1, !tbaa !2433
  %1526 = and i32 %1522, 255
  %1527 = tail call i32 @llvm.ctpop.i32(i32 %1526) #10
  %1528 = trunc i32 %1527 to i8
  %1529 = and i8 %1528, 1
  %1530 = xor i8 %1529, 1
  store i8 %1530, i8* %24, align 1, !tbaa !2447
  %1531 = xor i32 %1521, %1522
  %1532 = lshr i32 %1531, 4
  %1533 = trunc i32 %1532 to i8
  %1534 = and i8 %1533, 1
  store i8 %1534, i8* %30, align 1, !tbaa !2451
  %1535 = icmp eq i32 %1522, 0
  %1536 = zext i1 %1535 to i8
  store i8 %1536, i8* %33, align 1, !tbaa !2448
  %1537 = lshr i32 %1522, 31
  %1538 = trunc i32 %1537 to i8
  store i8 %1538, i8* %36, align 1, !tbaa !2449
  %1539 = lshr i32 %1521, 31
  %1540 = xor i32 %1537, %1539
  %1541 = add nuw nsw i32 %1540, %1537
  %1542 = icmp eq i32 %1541, 2
  %1543 = zext i1 %1542 to i8
  store i8 %1543, i8* %42, align 1, !tbaa !2450
  %1544 = sext i32 %1522 to i64
  store i64 %1544, i64* %RSI, align 8, !tbaa !2428
  %1545 = shl nsw i64 %1544, 3
  %1546 = add i64 %1545, %1517
  %1547 = add i64 %1514, 18
  store i64 %1547, i64* %PC, align 8
  %1548 = inttoptr i64 %1546 to double*
  %1549 = load double, double* %1548, align 8
  store double %1549, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1550 = add i64 %1514, 22
  store i64 %1550, i64* %PC, align 8
  %1551 = load i64, i64* %1516, align 8
  store i64 %1551, i64* %RDX, align 8, !tbaa !2428
  %1552 = add i64 %1514, 25
  store i64 %1552, i64* %PC, align 8
  %1553 = load i32, i32* %1520, align 4
  %1554 = add i32 %1553, 7
  %1555 = zext i32 %1554 to i64
  store i64 %1555, i64* %RCX, align 8, !tbaa !2428
  %1556 = icmp ugt i32 %1553, -8
  %1557 = zext i1 %1556 to i8
  store i8 %1557, i8* %17, align 1, !tbaa !2433
  %1558 = and i32 %1554, 255
  %1559 = tail call i32 @llvm.ctpop.i32(i32 %1558) #10
  %1560 = trunc i32 %1559 to i8
  %1561 = and i8 %1560, 1
  %1562 = xor i8 %1561, 1
  store i8 %1562, i8* %24, align 1, !tbaa !2447
  %1563 = xor i32 %1553, %1554
  %1564 = lshr i32 %1563, 4
  %1565 = trunc i32 %1564 to i8
  %1566 = and i8 %1565, 1
  store i8 %1566, i8* %30, align 1, !tbaa !2451
  %1567 = icmp eq i32 %1554, 0
  %1568 = zext i1 %1567 to i8
  store i8 %1568, i8* %33, align 1, !tbaa !2448
  %1569 = lshr i32 %1554, 31
  %1570 = trunc i32 %1569 to i8
  store i8 %1570, i8* %36, align 1, !tbaa !2449
  %1571 = lshr i32 %1553, 31
  %1572 = xor i32 %1569, %1571
  %1573 = add nuw nsw i32 %1572, %1569
  %1574 = icmp eq i32 %1573, 2
  %1575 = zext i1 %1574 to i8
  store i8 %1575, i8* %42, align 1, !tbaa !2450
  %1576 = sext i32 %1554 to i64
  store i64 %1576, i64* %RSI, align 8, !tbaa !2428
  %1577 = shl nsw i64 %1576, 3
  %1578 = add i64 %1577, %1551
  %1579 = add i64 %1514, 36
  store i64 %1579, i64* %PC, align 8
  %1580 = inttoptr i64 %1578 to double*
  %1581 = load double, double* %1580, align 8
  %1582 = fsub double %1549, %1581
  store double %1582, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1583 = load i64, i64* %RBP, align 8
  %1584 = add i64 %1583, -152
  %1585 = add i64 %1514, 44
  store i64 %1585, i64* %PC, align 8
  %1586 = inttoptr i64 %1584 to double*
  store double %1582, double* %1586, align 8
  %1587 = load i64, i64* %RBP, align 8
  %1588 = add i64 %1587, -96
  %1589 = load i64, i64* %PC, align 8
  %1590 = add i64 %1589, 5
  store i64 %1590, i64* %PC, align 8
  %1591 = inttoptr i64 %1588 to double*
  %1592 = load double, double* %1591, align 8
  store double %1592, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1593 = add i64 %1587, -128
  %1594 = add i64 %1589, 10
  store i64 %1594, i64* %PC, align 8
  %1595 = inttoptr i64 %1593 to double*
  %1596 = load double, double* %1595, align 8
  %1597 = fadd double %1592, %1596
  store double %1597, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1598 = add i64 %1587, -16
  %1599 = add i64 %1589, 14
  store i64 %1599, i64* %PC, align 8
  %1600 = inttoptr i64 %1598 to i64*
  %1601 = load i64, i64* %1600, align 8
  store i64 %1601, i64* %RDX, align 8, !tbaa !2428
  %1602 = add i64 %1587, -28
  %1603 = add i64 %1589, 18
  store i64 %1603, i64* %PC, align 8
  %1604 = inttoptr i64 %1602 to i32*
  %1605 = load i32, i32* %1604, align 4
  %1606 = sext i32 %1605 to i64
  store i64 %1606, i64* %RSI, align 8, !tbaa !2428
  %1607 = shl nsw i64 %1606, 3
  %1608 = add i64 %1607, %1601
  %1609 = add i64 %1589, 23
  store i64 %1609, i64* %PC, align 8
  %1610 = inttoptr i64 %1608 to double*
  store double %1597, double* %1610, align 8
  %1611 = load i64, i64* %RBP, align 8
  %1612 = add i64 %1611, -104
  %1613 = load i64, i64* %PC, align 8
  %1614 = add i64 %1613, 5
  store i64 %1614, i64* %PC, align 8
  %1615 = inttoptr i64 %1612 to double*
  %1616 = load double, double* %1615, align 8
  store double %1616, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1617 = add i64 %1611, -136
  %1618 = add i64 %1613, 13
  store i64 %1618, i64* %PC, align 8
  %1619 = inttoptr i64 %1617 to double*
  %1620 = load double, double* %1619, align 8
  %1621 = fadd double %1616, %1620
  store double %1621, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1622 = add i64 %1611, -16
  %1623 = add i64 %1613, 17
  store i64 %1623, i64* %PC, align 8
  %1624 = inttoptr i64 %1622 to i64*
  %1625 = load i64, i64* %1624, align 8
  store i64 %1625, i64* %RDX, align 8, !tbaa !2428
  %1626 = add i64 %1611, -28
  %1627 = add i64 %1613, 20
  store i64 %1627, i64* %PC, align 8
  %1628 = inttoptr i64 %1626 to i32*
  %1629 = load i32, i32* %1628, align 4
  %1630 = add i32 %1629, 1
  %1631 = zext i32 %1630 to i64
  store i64 %1631, i64* %RCX, align 8, !tbaa !2428
  %1632 = icmp eq i32 %1629, -1
  %1633 = icmp eq i32 %1630, 0
  %1634 = or i1 %1632, %1633
  %1635 = zext i1 %1634 to i8
  store i8 %1635, i8* %17, align 1, !tbaa !2433
  %1636 = and i32 %1630, 255
  %1637 = tail call i32 @llvm.ctpop.i32(i32 %1636) #10
  %1638 = trunc i32 %1637 to i8
  %1639 = and i8 %1638, 1
  %1640 = xor i8 %1639, 1
  store i8 %1640, i8* %24, align 1, !tbaa !2447
  %1641 = xor i32 %1629, %1630
  %1642 = lshr i32 %1641, 4
  %1643 = trunc i32 %1642 to i8
  %1644 = and i8 %1643, 1
  store i8 %1644, i8* %30, align 1, !tbaa !2451
  %1645 = icmp eq i32 %1630, 0
  %1646 = zext i1 %1645 to i8
  store i8 %1646, i8* %33, align 1, !tbaa !2448
  %1647 = lshr i32 %1630, 31
  %1648 = trunc i32 %1647 to i8
  store i8 %1648, i8* %36, align 1, !tbaa !2449
  %1649 = lshr i32 %1629, 31
  %1650 = xor i32 %1647, %1649
  %1651 = add nuw nsw i32 %1650, %1647
  %1652 = icmp eq i32 %1651, 2
  %1653 = zext i1 %1652 to i8
  store i8 %1653, i8* %42, align 1, !tbaa !2450
  %1654 = sext i32 %1630 to i64
  store i64 %1654, i64* %RSI, align 8, !tbaa !2428
  %1655 = shl nsw i64 %1654, 3
  %1656 = add i64 %1655, %1625
  %1657 = add i64 %1613, 31
  store i64 %1657, i64* %PC, align 8
  %1658 = inttoptr i64 %1656 to double*
  store double %1621, double* %1658, align 8
  %1659 = load i64, i64* %RBP, align 8
  %1660 = add i64 %1659, -128
  %1661 = load i64, i64* %PC, align 8
  %1662 = add i64 %1661, 5
  store i64 %1662, i64* %PC, align 8
  %1663 = inttoptr i64 %1660 to double*
  %1664 = load double, double* %1663, align 8
  store double %1664, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1665 = add i64 %1659, -96
  %1666 = add i64 %1661, 10
  store i64 %1666, i64* %PC, align 8
  %1667 = inttoptr i64 %1665 to double*
  %1668 = load double, double* %1667, align 8
  %1669 = fsub double %1668, %1664
  store double %1669, double* %783, align 1, !tbaa !2452
  store i64 0, i64* %779, align 1, !tbaa !2452
  %1670 = add i64 %1661, 19
  store i64 %1670, i64* %PC, align 8
  store double %1669, double* %1667, align 8
  %1671 = load i64, i64* %RBP, align 8
  %1672 = add i64 %1671, -136
  %1673 = load i64, i64* %PC, align 8
  %1674 = add i64 %1673, 8
  store i64 %1674, i64* %PC, align 8
  %1675 = inttoptr i64 %1672 to double*
  %1676 = load double, double* %1675, align 8
  store double %1676, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1677 = add i64 %1671, -104
  %1678 = add i64 %1673, 13
  store i64 %1678, i64* %PC, align 8
  %1679 = inttoptr i64 %1677 to double*
  %1680 = load double, double* %1679, align 8
  %1681 = fsub double %1680, %1676
  store double %1681, double* %783, align 1, !tbaa !2452
  store i64 0, i64* %779, align 1, !tbaa !2452
  %1682 = add i64 %1673, 22
  store i64 %1682, i64* %PC, align 8
  store double %1681, double* %1679, align 8
  %1683 = load i64, i64* %RBP, align 8
  %1684 = add i64 %1683, -64
  %1685 = load i64, i64* %PC, align 8
  %1686 = add i64 %1685, 5
  store i64 %1686, i64* %PC, align 8
  %1687 = inttoptr i64 %1684 to double*
  %1688 = load double, double* %1687, align 8
  store double %1688, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1689 = add i64 %1683, -96
  %1690 = add i64 %1685, 10
  store i64 %1690, i64* %PC, align 8
  %1691 = inttoptr i64 %1689 to double*
  %1692 = load double, double* %1691, align 8
  %1693 = fmul double %1688, %1692
  store double %1693, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1694 = add i64 %1683, -72
  %1695 = add i64 %1685, 15
  store i64 %1695, i64* %PC, align 8
  %1696 = inttoptr i64 %1694 to double*
  %1697 = load double, double* %1696, align 8
  store double %1697, double* %783, align 1, !tbaa !2452
  store double 0.000000e+00, double* %790, align 1, !tbaa !2452
  %1698 = add i64 %1683, -104
  %1699 = add i64 %1685, 20
  store i64 %1699, i64* %PC, align 8
  %1700 = inttoptr i64 %1698 to double*
  %1701 = load double, double* %1700, align 8
  %1702 = fmul double %1697, %1701
  store double %1702, double* %783, align 1, !tbaa !2452
  store i64 0, i64* %779, align 1, !tbaa !2452
  %1703 = fsub double %1693, %1702
  store double %1703, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1704 = add i64 %1683, -16
  %1705 = add i64 %1685, 28
  store i64 %1705, i64* %PC, align 8
  %1706 = inttoptr i64 %1704 to i64*
  %1707 = load i64, i64* %1706, align 8
  store i64 %1707, i64* %RDX, align 8, !tbaa !2428
  %1708 = add i64 %1683, -28
  %1709 = add i64 %1685, 31
  store i64 %1709, i64* %PC, align 8
  %1710 = inttoptr i64 %1708 to i32*
  %1711 = load i32, i32* %1710, align 4
  %1712 = add i32 %1711, 4
  %1713 = zext i32 %1712 to i64
  store i64 %1713, i64* %RCX, align 8, !tbaa !2428
  %1714 = icmp ugt i32 %1711, -5
  %1715 = zext i1 %1714 to i8
  store i8 %1715, i8* %17, align 1, !tbaa !2433
  %1716 = and i32 %1712, 255
  %1717 = tail call i32 @llvm.ctpop.i32(i32 %1716) #10
  %1718 = trunc i32 %1717 to i8
  %1719 = and i8 %1718, 1
  %1720 = xor i8 %1719, 1
  store i8 %1720, i8* %24, align 1, !tbaa !2447
  %1721 = xor i32 %1711, %1712
  %1722 = lshr i32 %1721, 4
  %1723 = trunc i32 %1722 to i8
  %1724 = and i8 %1723, 1
  store i8 %1724, i8* %30, align 1, !tbaa !2451
  %1725 = icmp eq i32 %1712, 0
  %1726 = zext i1 %1725 to i8
  store i8 %1726, i8* %33, align 1, !tbaa !2448
  %1727 = lshr i32 %1712, 31
  %1728 = trunc i32 %1727 to i8
  store i8 %1728, i8* %36, align 1, !tbaa !2449
  %1729 = lshr i32 %1711, 31
  %1730 = xor i32 %1727, %1729
  %1731 = add nuw nsw i32 %1730, %1727
  %1732 = icmp eq i32 %1731, 2
  %1733 = zext i1 %1732 to i8
  store i8 %1733, i8* %42, align 1, !tbaa !2450
  %1734 = sext i32 %1712 to i64
  store i64 %1734, i64* %RSI, align 8, !tbaa !2428
  %1735 = shl nsw i64 %1734, 3
  %1736 = add i64 %1735, %1707
  %1737 = add i64 %1685, 42
  store i64 %1737, i64* %PC, align 8
  %1738 = inttoptr i64 %1736 to double*
  store double %1703, double* %1738, align 8
  %1739 = load i64, i64* %RBP, align 8
  %1740 = add i64 %1739, -64
  %1741 = load i64, i64* %PC, align 8
  %1742 = add i64 %1741, 5
  store i64 %1742, i64* %PC, align 8
  %1743 = inttoptr i64 %1740 to double*
  %1744 = load double, double* %1743, align 8
  store double %1744, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1745 = add i64 %1739, -104
  %1746 = add i64 %1741, 10
  store i64 %1746, i64* %PC, align 8
  %1747 = inttoptr i64 %1745 to double*
  %1748 = load double, double* %1747, align 8
  %1749 = fmul double %1744, %1748
  store double %1749, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1750 = add i64 %1739, -72
  %1751 = add i64 %1741, 15
  store i64 %1751, i64* %PC, align 8
  %1752 = inttoptr i64 %1750 to double*
  %1753 = load double, double* %1752, align 8
  store double %1753, double* %783, align 1, !tbaa !2452
  store double 0.000000e+00, double* %790, align 1, !tbaa !2452
  %1754 = add i64 %1739, -96
  %1755 = add i64 %1741, 20
  store i64 %1755, i64* %PC, align 8
  %1756 = inttoptr i64 %1754 to double*
  %1757 = load double, double* %1756, align 8
  %1758 = fmul double %1753, %1757
  store double %1758, double* %783, align 1, !tbaa !2452
  store i64 0, i64* %779, align 1, !tbaa !2452
  %1759 = fadd double %1749, %1758
  store double %1759, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1760 = add i64 %1739, -16
  %1761 = add i64 %1741, 28
  store i64 %1761, i64* %PC, align 8
  %1762 = inttoptr i64 %1760 to i64*
  %1763 = load i64, i64* %1762, align 8
  store i64 %1763, i64* %RDX, align 8, !tbaa !2428
  %1764 = add i64 %1739, -28
  %1765 = add i64 %1741, 31
  store i64 %1765, i64* %PC, align 8
  %1766 = inttoptr i64 %1764 to i32*
  %1767 = load i32, i32* %1766, align 4
  %1768 = add i32 %1767, 5
  %1769 = zext i32 %1768 to i64
  store i64 %1769, i64* %RCX, align 8, !tbaa !2428
  %1770 = icmp ugt i32 %1767, -6
  %1771 = zext i1 %1770 to i8
  store i8 %1771, i8* %17, align 1, !tbaa !2433
  %1772 = and i32 %1768, 255
  %1773 = tail call i32 @llvm.ctpop.i32(i32 %1772) #10
  %1774 = trunc i32 %1773 to i8
  %1775 = and i8 %1774, 1
  %1776 = xor i8 %1775, 1
  store i8 %1776, i8* %24, align 1, !tbaa !2447
  %1777 = xor i32 %1767, %1768
  %1778 = lshr i32 %1777, 4
  %1779 = trunc i32 %1778 to i8
  %1780 = and i8 %1779, 1
  store i8 %1780, i8* %30, align 1, !tbaa !2451
  %1781 = icmp eq i32 %1768, 0
  %1782 = zext i1 %1781 to i8
  store i8 %1782, i8* %33, align 1, !tbaa !2448
  %1783 = lshr i32 %1768, 31
  %1784 = trunc i32 %1783 to i8
  store i8 %1784, i8* %36, align 1, !tbaa !2449
  %1785 = lshr i32 %1767, 31
  %1786 = xor i32 %1783, %1785
  %1787 = add nuw nsw i32 %1786, %1783
  %1788 = icmp eq i32 %1787, 2
  %1789 = zext i1 %1788 to i8
  store i8 %1789, i8* %42, align 1, !tbaa !2450
  %1790 = sext i32 %1768 to i64
  store i64 %1790, i64* %RSI, align 8, !tbaa !2428
  %1791 = shl nsw i64 %1790, 3
  %1792 = add i64 %1791, %1763
  %1793 = add i64 %1741, 42
  store i64 %1793, i64* %PC, align 8
  %1794 = inttoptr i64 %1792 to double*
  store double %1759, double* %1794, align 8
  %1795 = load i64, i64* %RBP, align 8
  %1796 = add i64 %1795, -112
  %1797 = load i64, i64* %PC, align 8
  %1798 = add i64 %1797, 5
  store i64 %1798, i64* %PC, align 8
  %1799 = inttoptr i64 %1796 to double*
  %1800 = load double, double* %1799, align 8
  store double %1800, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1801 = add i64 %1795, -152
  %1802 = add i64 %1797, 13
  store i64 %1802, i64* %PC, align 8
  %1803 = inttoptr i64 %1801 to double*
  %1804 = load double, double* %1803, align 8
  %1805 = fsub double %1800, %1804
  store double %1805, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1806 = add i64 %1795, -96
  %1807 = add i64 %1797, 18
  store i64 %1807, i64* %PC, align 8
  %1808 = inttoptr i64 %1806 to double*
  store double %1805, double* %1808, align 8
  %1809 = load i64, i64* %RBP, align 8
  %1810 = add i64 %1809, -120
  %1811 = load i64, i64* %PC, align 8
  %1812 = add i64 %1811, 5
  store i64 %1812, i64* %PC, align 8
  %1813 = inttoptr i64 %1810 to double*
  %1814 = load double, double* %1813, align 8
  store double %1814, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1815 = add i64 %1809, -144
  %1816 = add i64 %1811, 13
  store i64 %1816, i64* %PC, align 8
  %1817 = inttoptr i64 %1815 to double*
  %1818 = load double, double* %1817, align 8
  %1819 = fadd double %1814, %1818
  store double %1819, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1820 = add i64 %1809, -104
  %1821 = add i64 %1811, 18
  store i64 %1821, i64* %PC, align 8
  %1822 = inttoptr i64 %1820 to double*
  store double %1819, double* %1822, align 8
  %1823 = load i64, i64* %RBP, align 8
  %1824 = add i64 %1823, -48
  %1825 = load i64, i64* %PC, align 8
  %1826 = add i64 %1825, 5
  store i64 %1826, i64* %PC, align 8
  %1827 = inttoptr i64 %1824 to double*
  %1828 = load double, double* %1827, align 8
  store double %1828, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1829 = add i64 %1823, -96
  %1830 = add i64 %1825, 10
  store i64 %1830, i64* %PC, align 8
  %1831 = inttoptr i64 %1829 to double*
  %1832 = load double, double* %1831, align 8
  %1833 = fmul double %1828, %1832
  store double %1833, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1834 = add i64 %1823, -56
  %1835 = add i64 %1825, 15
  store i64 %1835, i64* %PC, align 8
  %1836 = inttoptr i64 %1834 to double*
  %1837 = load double, double* %1836, align 8
  store double %1837, double* %783, align 1, !tbaa !2452
  store double 0.000000e+00, double* %790, align 1, !tbaa !2452
  %1838 = add i64 %1823, -104
  %1839 = add i64 %1825, 20
  store i64 %1839, i64* %PC, align 8
  %1840 = inttoptr i64 %1838 to double*
  %1841 = load double, double* %1840, align 8
  %1842 = fmul double %1837, %1841
  store double %1842, double* %783, align 1, !tbaa !2452
  store i64 0, i64* %779, align 1, !tbaa !2452
  %1843 = fsub double %1833, %1842
  store double %1843, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1844 = add i64 %1823, -16
  %1845 = add i64 %1825, 28
  store i64 %1845, i64* %PC, align 8
  %1846 = inttoptr i64 %1844 to i64*
  %1847 = load i64, i64* %1846, align 8
  store i64 %1847, i64* %RDX, align 8, !tbaa !2428
  %1848 = add i64 %1823, -28
  %1849 = add i64 %1825, 31
  store i64 %1849, i64* %PC, align 8
  %1850 = inttoptr i64 %1848 to i32*
  %1851 = load i32, i32* %1850, align 4
  %1852 = add i32 %1851, 2
  %1853 = zext i32 %1852 to i64
  store i64 %1853, i64* %RCX, align 8, !tbaa !2428
  %1854 = icmp ugt i32 %1851, -3
  %1855 = zext i1 %1854 to i8
  store i8 %1855, i8* %17, align 1, !tbaa !2433
  %1856 = and i32 %1852, 255
  %1857 = tail call i32 @llvm.ctpop.i32(i32 %1856) #10
  %1858 = trunc i32 %1857 to i8
  %1859 = and i8 %1858, 1
  %1860 = xor i8 %1859, 1
  store i8 %1860, i8* %24, align 1, !tbaa !2447
  %1861 = xor i32 %1851, %1852
  %1862 = lshr i32 %1861, 4
  %1863 = trunc i32 %1862 to i8
  %1864 = and i8 %1863, 1
  store i8 %1864, i8* %30, align 1, !tbaa !2451
  %1865 = icmp eq i32 %1852, 0
  %1866 = zext i1 %1865 to i8
  store i8 %1866, i8* %33, align 1, !tbaa !2448
  %1867 = lshr i32 %1852, 31
  %1868 = trunc i32 %1867 to i8
  store i8 %1868, i8* %36, align 1, !tbaa !2449
  %1869 = lshr i32 %1851, 31
  %1870 = xor i32 %1867, %1869
  %1871 = add nuw nsw i32 %1870, %1867
  %1872 = icmp eq i32 %1871, 2
  %1873 = zext i1 %1872 to i8
  store i8 %1873, i8* %42, align 1, !tbaa !2450
  %1874 = sext i32 %1852 to i64
  store i64 %1874, i64* %RSI, align 8, !tbaa !2428
  %1875 = shl nsw i64 %1874, 3
  %1876 = add i64 %1875, %1847
  %1877 = add i64 %1825, 42
  store i64 %1877, i64* %PC, align 8
  %1878 = inttoptr i64 %1876 to double*
  store double %1843, double* %1878, align 8
  %1879 = load i64, i64* %RBP, align 8
  %1880 = add i64 %1879, -48
  %1881 = load i64, i64* %PC, align 8
  %1882 = add i64 %1881, 5
  store i64 %1882, i64* %PC, align 8
  %1883 = inttoptr i64 %1880 to double*
  %1884 = load double, double* %1883, align 8
  store double %1884, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1885 = add i64 %1879, -104
  %1886 = add i64 %1881, 10
  store i64 %1886, i64* %PC, align 8
  %1887 = inttoptr i64 %1885 to double*
  %1888 = load double, double* %1887, align 8
  %1889 = fmul double %1884, %1888
  store double %1889, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1890 = add i64 %1879, -56
  %1891 = add i64 %1881, 15
  store i64 %1891, i64* %PC, align 8
  %1892 = inttoptr i64 %1890 to double*
  %1893 = load double, double* %1892, align 8
  store double %1893, double* %783, align 1, !tbaa !2452
  store double 0.000000e+00, double* %790, align 1, !tbaa !2452
  %1894 = add i64 %1879, -96
  %1895 = add i64 %1881, 20
  store i64 %1895, i64* %PC, align 8
  %1896 = inttoptr i64 %1894 to double*
  %1897 = load double, double* %1896, align 8
  %1898 = fmul double %1893, %1897
  store double %1898, double* %783, align 1, !tbaa !2452
  store i64 0, i64* %779, align 1, !tbaa !2452
  %1899 = fadd double %1889, %1898
  store double %1899, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1900 = add i64 %1879, -16
  %1901 = add i64 %1881, 28
  store i64 %1901, i64* %PC, align 8
  %1902 = inttoptr i64 %1900 to i64*
  %1903 = load i64, i64* %1902, align 8
  store i64 %1903, i64* %RDX, align 8, !tbaa !2428
  %1904 = add i64 %1879, -28
  %1905 = add i64 %1881, 31
  store i64 %1905, i64* %PC, align 8
  %1906 = inttoptr i64 %1904 to i32*
  %1907 = load i32, i32* %1906, align 4
  %1908 = add i32 %1907, 3
  %1909 = zext i32 %1908 to i64
  store i64 %1909, i64* %RCX, align 8, !tbaa !2428
  %1910 = icmp ugt i32 %1907, -4
  %1911 = zext i1 %1910 to i8
  store i8 %1911, i8* %17, align 1, !tbaa !2433
  %1912 = and i32 %1908, 255
  %1913 = tail call i32 @llvm.ctpop.i32(i32 %1912) #10
  %1914 = trunc i32 %1913 to i8
  %1915 = and i8 %1914, 1
  %1916 = xor i8 %1915, 1
  store i8 %1916, i8* %24, align 1, !tbaa !2447
  %1917 = xor i32 %1907, %1908
  %1918 = lshr i32 %1917, 4
  %1919 = trunc i32 %1918 to i8
  %1920 = and i8 %1919, 1
  store i8 %1920, i8* %30, align 1, !tbaa !2451
  %1921 = icmp eq i32 %1908, 0
  %1922 = zext i1 %1921 to i8
  store i8 %1922, i8* %33, align 1, !tbaa !2448
  %1923 = lshr i32 %1908, 31
  %1924 = trunc i32 %1923 to i8
  store i8 %1924, i8* %36, align 1, !tbaa !2449
  %1925 = lshr i32 %1907, 31
  %1926 = xor i32 %1923, %1925
  %1927 = add nuw nsw i32 %1926, %1923
  %1928 = icmp eq i32 %1927, 2
  %1929 = zext i1 %1928 to i8
  store i8 %1929, i8* %42, align 1, !tbaa !2450
  %1930 = sext i32 %1908 to i64
  store i64 %1930, i64* %RSI, align 8, !tbaa !2428
  %1931 = shl nsw i64 %1930, 3
  %1932 = add i64 %1931, %1903
  %1933 = add i64 %1881, 42
  store i64 %1933, i64* %PC, align 8
  %1934 = inttoptr i64 %1932 to double*
  store double %1899, double* %1934, align 8
  %1935 = load i64, i64* %RBP, align 8
  %1936 = add i64 %1935, -112
  %1937 = load i64, i64* %PC, align 8
  %1938 = add i64 %1937, 5
  store i64 %1938, i64* %PC, align 8
  %1939 = inttoptr i64 %1936 to double*
  %1940 = load double, double* %1939, align 8
  store double %1940, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1941 = add i64 %1935, -152
  %1942 = add i64 %1937, 13
  store i64 %1942, i64* %PC, align 8
  %1943 = inttoptr i64 %1941 to double*
  %1944 = load double, double* %1943, align 8
  %1945 = fadd double %1940, %1944
  store double %1945, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1946 = add i64 %1935, -96
  %1947 = add i64 %1937, 18
  store i64 %1947, i64* %PC, align 8
  %1948 = inttoptr i64 %1946 to double*
  store double %1945, double* %1948, align 8
  %1949 = load i64, i64* %RBP, align 8
  %1950 = add i64 %1949, -120
  %1951 = load i64, i64* %PC, align 8
  %1952 = add i64 %1951, 5
  store i64 %1952, i64* %PC, align 8
  %1953 = inttoptr i64 %1950 to double*
  %1954 = load double, double* %1953, align 8
  store double %1954, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1955 = add i64 %1949, -144
  %1956 = add i64 %1951, 13
  store i64 %1956, i64* %PC, align 8
  %1957 = inttoptr i64 %1955 to double*
  %1958 = load double, double* %1957, align 8
  %1959 = fsub double %1954, %1958
  store double %1959, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1960 = add i64 %1949, -104
  %1961 = add i64 %1951, 18
  store i64 %1961, i64* %PC, align 8
  %1962 = inttoptr i64 %1960 to double*
  store double %1959, double* %1962, align 8
  %1963 = load i64, i64* %RBP, align 8
  %1964 = add i64 %1963, -80
  %1965 = load i64, i64* %PC, align 8
  %1966 = add i64 %1965, 5
  store i64 %1966, i64* %PC, align 8
  %1967 = inttoptr i64 %1964 to double*
  %1968 = load double, double* %1967, align 8
  store double %1968, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %1969 = add i64 %1963, -96
  %1970 = add i64 %1965, 10
  store i64 %1970, i64* %PC, align 8
  %1971 = inttoptr i64 %1969 to double*
  %1972 = load double, double* %1971, align 8
  %1973 = fmul double %1968, %1972
  store double %1973, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1974 = add i64 %1963, -88
  %1975 = add i64 %1965, 15
  store i64 %1975, i64* %PC, align 8
  %1976 = inttoptr i64 %1974 to double*
  %1977 = load double, double* %1976, align 8
  store double %1977, double* %783, align 1, !tbaa !2452
  store double 0.000000e+00, double* %790, align 1, !tbaa !2452
  %1978 = add i64 %1963, -104
  %1979 = add i64 %1965, 20
  store i64 %1979, i64* %PC, align 8
  %1980 = inttoptr i64 %1978 to double*
  %1981 = load double, double* %1980, align 8
  %1982 = fmul double %1977, %1981
  store double %1982, double* %783, align 1, !tbaa !2452
  store i64 0, i64* %779, align 1, !tbaa !2452
  %1983 = fsub double %1973, %1982
  store double %1983, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %1984 = add i64 %1963, -16
  %1985 = add i64 %1965, 28
  store i64 %1985, i64* %PC, align 8
  %1986 = inttoptr i64 %1984 to i64*
  %1987 = load i64, i64* %1986, align 8
  store i64 %1987, i64* %RDX, align 8, !tbaa !2428
  %1988 = add i64 %1963, -28
  %1989 = add i64 %1965, 31
  store i64 %1989, i64* %PC, align 8
  %1990 = inttoptr i64 %1988 to i32*
  %1991 = load i32, i32* %1990, align 4
  %1992 = add i32 %1991, 6
  %1993 = zext i32 %1992 to i64
  store i64 %1993, i64* %RCX, align 8, !tbaa !2428
  %1994 = icmp ugt i32 %1991, -7
  %1995 = zext i1 %1994 to i8
  store i8 %1995, i8* %17, align 1, !tbaa !2433
  %1996 = and i32 %1992, 255
  %1997 = tail call i32 @llvm.ctpop.i32(i32 %1996) #10
  %1998 = trunc i32 %1997 to i8
  %1999 = and i8 %1998, 1
  %2000 = xor i8 %1999, 1
  store i8 %2000, i8* %24, align 1, !tbaa !2447
  %2001 = xor i32 %1991, %1992
  %2002 = lshr i32 %2001, 4
  %2003 = trunc i32 %2002 to i8
  %2004 = and i8 %2003, 1
  store i8 %2004, i8* %30, align 1, !tbaa !2451
  %2005 = icmp eq i32 %1992, 0
  %2006 = zext i1 %2005 to i8
  store i8 %2006, i8* %33, align 1, !tbaa !2448
  %2007 = lshr i32 %1992, 31
  %2008 = trunc i32 %2007 to i8
  store i8 %2008, i8* %36, align 1, !tbaa !2449
  %2009 = lshr i32 %1991, 31
  %2010 = xor i32 %2007, %2009
  %2011 = add nuw nsw i32 %2010, %2007
  %2012 = icmp eq i32 %2011, 2
  %2013 = zext i1 %2012 to i8
  store i8 %2013, i8* %42, align 1, !tbaa !2450
  %2014 = sext i32 %1992 to i64
  store i64 %2014, i64* %RSI, align 8, !tbaa !2428
  %2015 = shl nsw i64 %2014, 3
  %2016 = add i64 %2015, %1987
  %2017 = add i64 %1965, 42
  store i64 %2017, i64* %PC, align 8
  %2018 = inttoptr i64 %2016 to double*
  store double %1983, double* %2018, align 8
  %2019 = load i64, i64* %RBP, align 8
  %2020 = add i64 %2019, -80
  %2021 = load i64, i64* %PC, align 8
  %2022 = add i64 %2021, 5
  store i64 %2022, i64* %PC, align 8
  %2023 = inttoptr i64 %2020 to double*
  %2024 = load double, double* %2023, align 8
  store double %2024, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %2025 = add i64 %2019, -104
  %2026 = add i64 %2021, 10
  store i64 %2026, i64* %PC, align 8
  %2027 = inttoptr i64 %2025 to double*
  %2028 = load double, double* %2027, align 8
  %2029 = fmul double %2024, %2028
  store double %2029, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %2030 = add i64 %2019, -88
  %2031 = add i64 %2021, 15
  store i64 %2031, i64* %PC, align 8
  %2032 = inttoptr i64 %2030 to double*
  %2033 = load double, double* %2032, align 8
  store double %2033, double* %783, align 1, !tbaa !2452
  store double 0.000000e+00, double* %790, align 1, !tbaa !2452
  %2034 = add i64 %2019, -96
  %2035 = add i64 %2021, 20
  store i64 %2035, i64* %PC, align 8
  %2036 = inttoptr i64 %2034 to double*
  %2037 = load double, double* %2036, align 8
  %2038 = fmul double %2033, %2037
  store double %2038, double* %783, align 1, !tbaa !2452
  store i64 0, i64* %779, align 1, !tbaa !2452
  %2039 = fadd double %2029, %2038
  store double %2039, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %2040 = add i64 %2019, -16
  %2041 = add i64 %2021, 28
  store i64 %2041, i64* %PC, align 8
  %2042 = inttoptr i64 %2040 to i64*
  %2043 = load i64, i64* %2042, align 8
  store i64 %2043, i64* %RDX, align 8, !tbaa !2428
  %2044 = add i64 %2019, -28
  %2045 = add i64 %2021, 31
  store i64 %2045, i64* %PC, align 8
  %2046 = inttoptr i64 %2044 to i32*
  %2047 = load i32, i32* %2046, align 4
  %2048 = add i32 %2047, 7
  %2049 = zext i32 %2048 to i64
  store i64 %2049, i64* %RCX, align 8, !tbaa !2428
  %2050 = icmp ugt i32 %2047, -8
  %2051 = zext i1 %2050 to i8
  store i8 %2051, i8* %17, align 1, !tbaa !2433
  %2052 = and i32 %2048, 255
  %2053 = tail call i32 @llvm.ctpop.i32(i32 %2052) #10
  %2054 = trunc i32 %2053 to i8
  %2055 = and i8 %2054, 1
  %2056 = xor i8 %2055, 1
  store i8 %2056, i8* %24, align 1, !tbaa !2447
  %2057 = xor i32 %2047, %2048
  %2058 = lshr i32 %2057, 4
  %2059 = trunc i32 %2058 to i8
  %2060 = and i8 %2059, 1
  store i8 %2060, i8* %30, align 1, !tbaa !2451
  %2061 = icmp eq i32 %2048, 0
  %2062 = zext i1 %2061 to i8
  store i8 %2062, i8* %33, align 1, !tbaa !2448
  %2063 = lshr i32 %2048, 31
  %2064 = trunc i32 %2063 to i8
  store i8 %2064, i8* %36, align 1, !tbaa !2449
  %2065 = lshr i32 %2047, 31
  %2066 = xor i32 %2063, %2065
  %2067 = add nuw nsw i32 %2066, %2063
  %2068 = icmp eq i32 %2067, 2
  %2069 = zext i1 %2068 to i8
  store i8 %2069, i8* %42, align 1, !tbaa !2450
  %2070 = sext i32 %2048 to i64
  store i64 %2070, i64* %RSI, align 8, !tbaa !2428
  %2071 = shl nsw i64 %2070, 3
  %2072 = add i64 %2071, %2043
  %2073 = add i64 %2021, 42
  store i64 %2073, i64* %PC, align 8
  %2074 = inttoptr i64 %2072 to double*
  store double %2039, double* %2074, align 8
  %2075 = load i64, i64* %RBP, align 8
  %2076 = add i64 %2075, -24
  %2077 = load i64, i64* %PC, align 8
  %2078 = add i64 %2077, 4
  store i64 %2078, i64* %PC, align 8
  %2079 = inttoptr i64 %2076 to i64*
  %2080 = load i64, i64* %2079, align 8
  store i64 %2080, i64* %RDX, align 8, !tbaa !2428
  %2081 = add i64 %2075, -36
  %2082 = add i64 %2077, 7
  store i64 %2082, i64* %PC, align 8
  %2083 = inttoptr i64 %2081 to i32*
  %2084 = load i32, i32* %2083, align 4
  %2085 = add i32 %2084, 2
  %2086 = zext i32 %2085 to i64
  store i64 %2086, i64* %RCX, align 8, !tbaa !2428
  %2087 = icmp ugt i32 %2084, -3
  %2088 = zext i1 %2087 to i8
  store i8 %2088, i8* %17, align 1, !tbaa !2433
  %2089 = and i32 %2085, 255
  %2090 = tail call i32 @llvm.ctpop.i32(i32 %2089) #10
  %2091 = trunc i32 %2090 to i8
  %2092 = and i8 %2091, 1
  %2093 = xor i8 %2092, 1
  store i8 %2093, i8* %24, align 1, !tbaa !2447
  %2094 = xor i32 %2084, %2085
  %2095 = lshr i32 %2094, 4
  %2096 = trunc i32 %2095 to i8
  %2097 = and i8 %2096, 1
  store i8 %2097, i8* %30, align 1, !tbaa !2451
  %2098 = icmp eq i32 %2085, 0
  %2099 = zext i1 %2098 to i8
  store i8 %2099, i8* %33, align 1, !tbaa !2448
  %2100 = lshr i32 %2085, 31
  %2101 = trunc i32 %2100 to i8
  store i8 %2101, i8* %36, align 1, !tbaa !2449
  %2102 = lshr i32 %2084, 31
  %2103 = xor i32 %2100, %2102
  %2104 = add nuw nsw i32 %2103, %2100
  %2105 = icmp eq i32 %2104, 2
  %2106 = zext i1 %2105 to i8
  store i8 %2106, i8* %42, align 1, !tbaa !2450
  %2107 = sext i32 %2085 to i64
  store i64 %2107, i64* %RSI, align 8, !tbaa !2428
  %2108 = shl nsw i64 %2107, 3
  %2109 = add i64 %2108, %2080
  %2110 = add i64 %2077, 18
  store i64 %2110, i64* %PC, align 8
  %2111 = inttoptr i64 %2109 to i64*
  %2112 = load i64, i64* %2111, align 8
  %2113 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2112, i64* %2113, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %2114 = add i64 %2075, -48
  %2115 = add i64 %2077, 23
  store i64 %2115, i64* %PC, align 8
  %2116 = inttoptr i64 %2114 to i64*
  store i64 %2112, i64* %2116, align 8
  %2117 = load i64, i64* %RBP, align 8
  %2118 = add i64 %2117, -24
  %2119 = load i64, i64* %PC, align 8
  %2120 = add i64 %2119, 4
  store i64 %2120, i64* %PC, align 8
  %2121 = inttoptr i64 %2118 to i64*
  %2122 = load i64, i64* %2121, align 8
  store i64 %2122, i64* %RDX, align 8, !tbaa !2428
  %2123 = add i64 %2117, -36
  %2124 = add i64 %2119, 7
  store i64 %2124, i64* %PC, align 8
  %2125 = inttoptr i64 %2123 to i32*
  %2126 = load i32, i32* %2125, align 4
  %2127 = add i32 %2126, 3
  %2128 = zext i32 %2127 to i64
  store i64 %2128, i64* %RCX, align 8, !tbaa !2428
  %2129 = icmp ugt i32 %2126, -4
  %2130 = zext i1 %2129 to i8
  store i8 %2130, i8* %17, align 1, !tbaa !2433
  %2131 = and i32 %2127, 255
  %2132 = tail call i32 @llvm.ctpop.i32(i32 %2131) #10
  %2133 = trunc i32 %2132 to i8
  %2134 = and i8 %2133, 1
  %2135 = xor i8 %2134, 1
  store i8 %2135, i8* %24, align 1, !tbaa !2447
  %2136 = xor i32 %2126, %2127
  %2137 = lshr i32 %2136, 4
  %2138 = trunc i32 %2137 to i8
  %2139 = and i8 %2138, 1
  store i8 %2139, i8* %30, align 1, !tbaa !2451
  %2140 = icmp eq i32 %2127, 0
  %2141 = zext i1 %2140 to i8
  store i8 %2141, i8* %33, align 1, !tbaa !2448
  %2142 = lshr i32 %2127, 31
  %2143 = trunc i32 %2142 to i8
  store i8 %2143, i8* %36, align 1, !tbaa !2449
  %2144 = lshr i32 %2126, 31
  %2145 = xor i32 %2142, %2144
  %2146 = add nuw nsw i32 %2145, %2142
  %2147 = icmp eq i32 %2146, 2
  %2148 = zext i1 %2147 to i8
  store i8 %2148, i8* %42, align 1, !tbaa !2450
  %2149 = sext i32 %2127 to i64
  store i64 %2149, i64* %RSI, align 8, !tbaa !2428
  %2150 = shl nsw i64 %2149, 3
  %2151 = add i64 %2150, %2122
  %2152 = add i64 %2119, 18
  store i64 %2152, i64* %PC, align 8
  %2153 = inttoptr i64 %2151 to i64*
  %2154 = load i64, i64* %2153, align 8
  %2155 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2154, i64* %2155, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %2156 = add i64 %2117, -56
  %2157 = add i64 %2119, 23
  store i64 %2157, i64* %PC, align 8
  %2158 = inttoptr i64 %2156 to i64*
  store i64 %2154, i64* %2158, align 8
  %2159 = load i64, i64* %RBP, align 8
  %2160 = add i64 %2159, -48
  %2161 = load i64, i64* %PC, align 8
  %2162 = add i64 %2161, 5
  store i64 %2162, i64* %PC, align 8
  %2163 = inttoptr i64 %2160 to double*
  %2164 = load double, double* %2163, align 8
  store double %2164, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %2165 = load <2 x i32>, <2 x i32>* %773, align 1
  %2166 = load <2 x i32>, <2 x i32>* %775, align 1
  %2167 = extractelement <2 x i32> %2165, i32 0
  store i32 %2167, i32* %776, align 1, !tbaa !2475
  %2168 = extractelement <2 x i32> %2165, i32 1
  store i32 %2168, i32* %778, align 1, !tbaa !2475
  %2169 = extractelement <2 x i32> %2166, i32 0
  store i32 %2169, i32* %780, align 1, !tbaa !2475
  %2170 = extractelement <2 x i32> %2166, i32 1
  store i32 %2170, i32* %782, align 1, !tbaa !2475
  %2171 = add i64 %2159, -64
  %2172 = add i64 %2161, 13
  store i64 %2172, i64* %PC, align 8
  %2173 = load double, double* %783, align 1
  %2174 = inttoptr i64 %2171 to double*
  %2175 = load double, double* %2174, align 8
  %2176 = fmul double %2173, %2175
  store double %2176, double* %783, align 1, !tbaa !2452
  %2177 = add i64 %2159, -56
  %2178 = add i64 %2161, 18
  store i64 %2178, i64* %PC, align 8
  %2179 = inttoptr i64 %2177 to double*
  %2180 = load double, double* %2179, align 8
  %2181 = fmul double %2176, %2180
  store double %2181, double* %783, align 1, !tbaa !2452
  %2182 = fsub double %2164, %2181
  store double %2182, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %2183 = add i64 %2159, -80
  %2184 = add i64 %2161, 27
  store i64 %2184, i64* %PC, align 8
  %2185 = inttoptr i64 %2183 to double*
  store double %2182, double* %2185, align 8
  %2186 = load i64, i64* %RBP, align 8
  %2187 = add i64 %2186, -64
  %2188 = load i64, i64* %PC, align 8
  %2189 = add i64 %2188, 5
  store i64 %2189, i64* %PC, align 8
  %2190 = load double, double* %68, align 1
  %2191 = inttoptr i64 %2187 to double*
  %2192 = load double, double* %2191, align 8
  %2193 = fmul double %2190, %2192
  store double %2193, double* %68, align 1, !tbaa !2452
  %2194 = add i64 %2186, -48
  %2195 = add i64 %2188, 10
  store i64 %2195, i64* %PC, align 8
  %2196 = inttoptr i64 %2194 to double*
  %2197 = load double, double* %2196, align 8
  %2198 = fmul double %2193, %2197
  store double %2198, double* %68, align 1, !tbaa !2452
  %2199 = add i64 %2186, -56
  %2200 = add i64 %2188, 15
  store i64 %2200, i64* %PC, align 8
  %2201 = inttoptr i64 %2199 to double*
  %2202 = load double, double* %2201, align 8
  %2203 = fsub double %2198, %2202
  store double %2203, double* %68, align 1, !tbaa !2452
  %2204 = add i64 %2186, -88
  %2205 = add i64 %2188, 20
  store i64 %2205, i64* %PC, align 8
  %2206 = inttoptr i64 %2204 to double*
  store double %2203, double* %2206, align 8
  %2207 = load i64, i64* %RBP, align 8
  %2208 = add i64 %2207, -16
  %2209 = load i64, i64* %PC, align 8
  %2210 = add i64 %2209, 4
  store i64 %2210, i64* %PC, align 8
  %2211 = inttoptr i64 %2208 to i64*
  %2212 = load i64, i64* %2211, align 8
  store i64 %2212, i64* %RDX, align 8, !tbaa !2428
  %2213 = add i64 %2207, -28
  %2214 = add i64 %2209, 7
  store i64 %2214, i64* %PC, align 8
  %2215 = inttoptr i64 %2213 to i32*
  %2216 = load i32, i32* %2215, align 4
  %2217 = add i32 %2216, 8
  %2218 = zext i32 %2217 to i64
  store i64 %2218, i64* %RCX, align 8, !tbaa !2428
  %2219 = icmp ugt i32 %2216, -9
  %2220 = zext i1 %2219 to i8
  store i8 %2220, i8* %17, align 1, !tbaa !2433
  %2221 = and i32 %2217, 255
  %2222 = tail call i32 @llvm.ctpop.i32(i32 %2221) #10
  %2223 = trunc i32 %2222 to i8
  %2224 = and i8 %2223, 1
  %2225 = xor i8 %2224, 1
  store i8 %2225, i8* %24, align 1, !tbaa !2447
  %2226 = xor i32 %2216, %2217
  %2227 = lshr i32 %2226, 4
  %2228 = trunc i32 %2227 to i8
  %2229 = and i8 %2228, 1
  store i8 %2229, i8* %30, align 1, !tbaa !2451
  %2230 = icmp eq i32 %2217, 0
  %2231 = zext i1 %2230 to i8
  store i8 %2231, i8* %33, align 1, !tbaa !2448
  %2232 = lshr i32 %2217, 31
  %2233 = trunc i32 %2232 to i8
  store i8 %2233, i8* %36, align 1, !tbaa !2449
  %2234 = lshr i32 %2216, 31
  %2235 = xor i32 %2232, %2234
  %2236 = add nuw nsw i32 %2235, %2232
  %2237 = icmp eq i32 %2236, 2
  %2238 = zext i1 %2237 to i8
  store i8 %2238, i8* %42, align 1, !tbaa !2450
  %2239 = sext i32 %2217 to i64
  store i64 %2239, i64* %RSI, align 8, !tbaa !2428
  %2240 = shl nsw i64 %2239, 3
  %2241 = add i64 %2240, %2212
  %2242 = add i64 %2209, 18
  store i64 %2242, i64* %PC, align 8
  %2243 = inttoptr i64 %2241 to double*
  %2244 = load double, double* %2243, align 8
  store double %2244, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2245 = add i64 %2209, 22
  store i64 %2245, i64* %PC, align 8
  %2246 = load i64, i64* %2211, align 8
  store i64 %2246, i64* %RDX, align 8, !tbaa !2428
  %2247 = add i64 %2209, 25
  store i64 %2247, i64* %PC, align 8
  %2248 = load i32, i32* %2215, align 4
  %2249 = add i32 %2248, 10
  %2250 = zext i32 %2249 to i64
  store i64 %2250, i64* %RCX, align 8, !tbaa !2428
  %2251 = icmp ugt i32 %2248, -11
  %2252 = zext i1 %2251 to i8
  store i8 %2252, i8* %17, align 1, !tbaa !2433
  %2253 = and i32 %2249, 255
  %2254 = tail call i32 @llvm.ctpop.i32(i32 %2253) #10
  %2255 = trunc i32 %2254 to i8
  %2256 = and i8 %2255, 1
  %2257 = xor i8 %2256, 1
  store i8 %2257, i8* %24, align 1, !tbaa !2447
  %2258 = xor i32 %2248, %2249
  %2259 = lshr i32 %2258, 4
  %2260 = trunc i32 %2259 to i8
  %2261 = and i8 %2260, 1
  store i8 %2261, i8* %30, align 1, !tbaa !2451
  %2262 = icmp eq i32 %2249, 0
  %2263 = zext i1 %2262 to i8
  store i8 %2263, i8* %33, align 1, !tbaa !2448
  %2264 = lshr i32 %2249, 31
  %2265 = trunc i32 %2264 to i8
  store i8 %2265, i8* %36, align 1, !tbaa !2449
  %2266 = lshr i32 %2248, 31
  %2267 = xor i32 %2264, %2266
  %2268 = add nuw nsw i32 %2267, %2264
  %2269 = icmp eq i32 %2268, 2
  %2270 = zext i1 %2269 to i8
  store i8 %2270, i8* %42, align 1, !tbaa !2450
  %2271 = sext i32 %2249 to i64
  store i64 %2271, i64* %RSI, align 8, !tbaa !2428
  %2272 = shl nsw i64 %2271, 3
  %2273 = add i64 %2272, %2246
  %2274 = add i64 %2209, 36
  store i64 %2274, i64* %PC, align 8
  %2275 = inttoptr i64 %2273 to double*
  %2276 = load double, double* %2275, align 8
  %2277 = fadd double %2244, %2276
  store double %2277, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2278 = load i64, i64* %RBP, align 8
  %2279 = add i64 %2278, -96
  %2280 = add i64 %2209, 41
  store i64 %2280, i64* %PC, align 8
  %2281 = inttoptr i64 %2279 to double*
  store double %2277, double* %2281, align 8
  %2282 = load i64, i64* %RBP, align 8
  %2283 = add i64 %2282, -16
  %2284 = load i64, i64* %PC, align 8
  %2285 = add i64 %2284, 4
  store i64 %2285, i64* %PC, align 8
  %2286 = inttoptr i64 %2283 to i64*
  %2287 = load i64, i64* %2286, align 8
  store i64 %2287, i64* %RDX, align 8, !tbaa !2428
  %2288 = add i64 %2282, -28
  %2289 = add i64 %2284, 7
  store i64 %2289, i64* %PC, align 8
  %2290 = inttoptr i64 %2288 to i32*
  %2291 = load i32, i32* %2290, align 4
  %2292 = add i32 %2291, 9
  %2293 = zext i32 %2292 to i64
  store i64 %2293, i64* %RCX, align 8, !tbaa !2428
  %2294 = icmp ugt i32 %2291, -10
  %2295 = zext i1 %2294 to i8
  store i8 %2295, i8* %17, align 1, !tbaa !2433
  %2296 = and i32 %2292, 255
  %2297 = tail call i32 @llvm.ctpop.i32(i32 %2296) #10
  %2298 = trunc i32 %2297 to i8
  %2299 = and i8 %2298, 1
  %2300 = xor i8 %2299, 1
  store i8 %2300, i8* %24, align 1, !tbaa !2447
  %2301 = xor i32 %2291, %2292
  %2302 = lshr i32 %2301, 4
  %2303 = trunc i32 %2302 to i8
  %2304 = and i8 %2303, 1
  store i8 %2304, i8* %30, align 1, !tbaa !2451
  %2305 = icmp eq i32 %2292, 0
  %2306 = zext i1 %2305 to i8
  store i8 %2306, i8* %33, align 1, !tbaa !2448
  %2307 = lshr i32 %2292, 31
  %2308 = trunc i32 %2307 to i8
  store i8 %2308, i8* %36, align 1, !tbaa !2449
  %2309 = lshr i32 %2291, 31
  %2310 = xor i32 %2307, %2309
  %2311 = add nuw nsw i32 %2310, %2307
  %2312 = icmp eq i32 %2311, 2
  %2313 = zext i1 %2312 to i8
  store i8 %2313, i8* %42, align 1, !tbaa !2450
  %2314 = sext i32 %2292 to i64
  store i64 %2314, i64* %RSI, align 8, !tbaa !2428
  %2315 = shl nsw i64 %2314, 3
  %2316 = add i64 %2315, %2287
  %2317 = add i64 %2284, 18
  store i64 %2317, i64* %PC, align 8
  %2318 = inttoptr i64 %2316 to double*
  %2319 = load double, double* %2318, align 8
  store double %2319, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2320 = add i64 %2284, 22
  store i64 %2320, i64* %PC, align 8
  %2321 = load i64, i64* %2286, align 8
  store i64 %2321, i64* %RDX, align 8, !tbaa !2428
  %2322 = add i64 %2284, 25
  store i64 %2322, i64* %PC, align 8
  %2323 = load i32, i32* %2290, align 4
  %2324 = add i32 %2323, 11
  %2325 = zext i32 %2324 to i64
  store i64 %2325, i64* %RCX, align 8, !tbaa !2428
  %2326 = icmp ugt i32 %2323, -12
  %2327 = zext i1 %2326 to i8
  store i8 %2327, i8* %17, align 1, !tbaa !2433
  %2328 = and i32 %2324, 255
  %2329 = tail call i32 @llvm.ctpop.i32(i32 %2328) #10
  %2330 = trunc i32 %2329 to i8
  %2331 = and i8 %2330, 1
  %2332 = xor i8 %2331, 1
  store i8 %2332, i8* %24, align 1, !tbaa !2447
  %2333 = xor i32 %2323, %2324
  %2334 = lshr i32 %2333, 4
  %2335 = trunc i32 %2334 to i8
  %2336 = and i8 %2335, 1
  store i8 %2336, i8* %30, align 1, !tbaa !2451
  %2337 = icmp eq i32 %2324, 0
  %2338 = zext i1 %2337 to i8
  store i8 %2338, i8* %33, align 1, !tbaa !2448
  %2339 = lshr i32 %2324, 31
  %2340 = trunc i32 %2339 to i8
  store i8 %2340, i8* %36, align 1, !tbaa !2449
  %2341 = lshr i32 %2323, 31
  %2342 = xor i32 %2339, %2341
  %2343 = add nuw nsw i32 %2342, %2339
  %2344 = icmp eq i32 %2343, 2
  %2345 = zext i1 %2344 to i8
  store i8 %2345, i8* %42, align 1, !tbaa !2450
  %2346 = sext i32 %2324 to i64
  store i64 %2346, i64* %RSI, align 8, !tbaa !2428
  %2347 = shl nsw i64 %2346, 3
  %2348 = add i64 %2347, %2321
  %2349 = add i64 %2284, 36
  store i64 %2349, i64* %PC, align 8
  %2350 = inttoptr i64 %2348 to double*
  %2351 = load double, double* %2350, align 8
  %2352 = fadd double %2319, %2351
  store double %2352, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2353 = load i64, i64* %RBP, align 8
  %2354 = add i64 %2353, -104
  %2355 = add i64 %2284, 41
  store i64 %2355, i64* %PC, align 8
  %2356 = inttoptr i64 %2354 to double*
  store double %2352, double* %2356, align 8
  %2357 = load i64, i64* %RBP, align 8
  %2358 = add i64 %2357, -16
  %2359 = load i64, i64* %PC, align 8
  %2360 = add i64 %2359, 4
  store i64 %2360, i64* %PC, align 8
  %2361 = inttoptr i64 %2358 to i64*
  %2362 = load i64, i64* %2361, align 8
  store i64 %2362, i64* %RDX, align 8, !tbaa !2428
  %2363 = add i64 %2357, -28
  %2364 = add i64 %2359, 7
  store i64 %2364, i64* %PC, align 8
  %2365 = inttoptr i64 %2363 to i32*
  %2366 = load i32, i32* %2365, align 4
  %2367 = add i32 %2366, 8
  %2368 = zext i32 %2367 to i64
  store i64 %2368, i64* %RCX, align 8, !tbaa !2428
  %2369 = icmp ugt i32 %2366, -9
  %2370 = zext i1 %2369 to i8
  store i8 %2370, i8* %17, align 1, !tbaa !2433
  %2371 = and i32 %2367, 255
  %2372 = tail call i32 @llvm.ctpop.i32(i32 %2371) #10
  %2373 = trunc i32 %2372 to i8
  %2374 = and i8 %2373, 1
  %2375 = xor i8 %2374, 1
  store i8 %2375, i8* %24, align 1, !tbaa !2447
  %2376 = xor i32 %2366, %2367
  %2377 = lshr i32 %2376, 4
  %2378 = trunc i32 %2377 to i8
  %2379 = and i8 %2378, 1
  store i8 %2379, i8* %30, align 1, !tbaa !2451
  %2380 = icmp eq i32 %2367, 0
  %2381 = zext i1 %2380 to i8
  store i8 %2381, i8* %33, align 1, !tbaa !2448
  %2382 = lshr i32 %2367, 31
  %2383 = trunc i32 %2382 to i8
  store i8 %2383, i8* %36, align 1, !tbaa !2449
  %2384 = lshr i32 %2366, 31
  %2385 = xor i32 %2382, %2384
  %2386 = add nuw nsw i32 %2385, %2382
  %2387 = icmp eq i32 %2386, 2
  %2388 = zext i1 %2387 to i8
  store i8 %2388, i8* %42, align 1, !tbaa !2450
  %2389 = sext i32 %2367 to i64
  store i64 %2389, i64* %RSI, align 8, !tbaa !2428
  %2390 = shl nsw i64 %2389, 3
  %2391 = add i64 %2390, %2362
  %2392 = add i64 %2359, 18
  store i64 %2392, i64* %PC, align 8
  %2393 = inttoptr i64 %2391 to double*
  %2394 = load double, double* %2393, align 8
  store double %2394, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2395 = add i64 %2359, 22
  store i64 %2395, i64* %PC, align 8
  %2396 = load i64, i64* %2361, align 8
  store i64 %2396, i64* %RDX, align 8, !tbaa !2428
  %2397 = add i64 %2359, 25
  store i64 %2397, i64* %PC, align 8
  %2398 = load i32, i32* %2365, align 4
  %2399 = add i32 %2398, 10
  %2400 = zext i32 %2399 to i64
  store i64 %2400, i64* %RCX, align 8, !tbaa !2428
  %2401 = icmp ugt i32 %2398, -11
  %2402 = zext i1 %2401 to i8
  store i8 %2402, i8* %17, align 1, !tbaa !2433
  %2403 = and i32 %2399, 255
  %2404 = tail call i32 @llvm.ctpop.i32(i32 %2403) #10
  %2405 = trunc i32 %2404 to i8
  %2406 = and i8 %2405, 1
  %2407 = xor i8 %2406, 1
  store i8 %2407, i8* %24, align 1, !tbaa !2447
  %2408 = xor i32 %2398, %2399
  %2409 = lshr i32 %2408, 4
  %2410 = trunc i32 %2409 to i8
  %2411 = and i8 %2410, 1
  store i8 %2411, i8* %30, align 1, !tbaa !2451
  %2412 = icmp eq i32 %2399, 0
  %2413 = zext i1 %2412 to i8
  store i8 %2413, i8* %33, align 1, !tbaa !2448
  %2414 = lshr i32 %2399, 31
  %2415 = trunc i32 %2414 to i8
  store i8 %2415, i8* %36, align 1, !tbaa !2449
  %2416 = lshr i32 %2398, 31
  %2417 = xor i32 %2414, %2416
  %2418 = add nuw nsw i32 %2417, %2414
  %2419 = icmp eq i32 %2418, 2
  %2420 = zext i1 %2419 to i8
  store i8 %2420, i8* %42, align 1, !tbaa !2450
  %2421 = sext i32 %2399 to i64
  store i64 %2421, i64* %RSI, align 8, !tbaa !2428
  %2422 = shl nsw i64 %2421, 3
  %2423 = add i64 %2422, %2396
  %2424 = add i64 %2359, 36
  store i64 %2424, i64* %PC, align 8
  %2425 = inttoptr i64 %2423 to double*
  %2426 = load double, double* %2425, align 8
  %2427 = fsub double %2394, %2426
  store double %2427, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2428 = load i64, i64* %RBP, align 8
  %2429 = add i64 %2428, -112
  %2430 = add i64 %2359, 41
  store i64 %2430, i64* %PC, align 8
  %2431 = inttoptr i64 %2429 to double*
  store double %2427, double* %2431, align 8
  %2432 = load i64, i64* %RBP, align 8
  %2433 = add i64 %2432, -16
  %2434 = load i64, i64* %PC, align 8
  %2435 = add i64 %2434, 4
  store i64 %2435, i64* %PC, align 8
  %2436 = inttoptr i64 %2433 to i64*
  %2437 = load i64, i64* %2436, align 8
  store i64 %2437, i64* %RDX, align 8, !tbaa !2428
  %2438 = add i64 %2432, -28
  %2439 = add i64 %2434, 7
  store i64 %2439, i64* %PC, align 8
  %2440 = inttoptr i64 %2438 to i32*
  %2441 = load i32, i32* %2440, align 4
  %2442 = add i32 %2441, 9
  %2443 = zext i32 %2442 to i64
  store i64 %2443, i64* %RCX, align 8, !tbaa !2428
  %2444 = icmp ugt i32 %2441, -10
  %2445 = zext i1 %2444 to i8
  store i8 %2445, i8* %17, align 1, !tbaa !2433
  %2446 = and i32 %2442, 255
  %2447 = tail call i32 @llvm.ctpop.i32(i32 %2446) #10
  %2448 = trunc i32 %2447 to i8
  %2449 = and i8 %2448, 1
  %2450 = xor i8 %2449, 1
  store i8 %2450, i8* %24, align 1, !tbaa !2447
  %2451 = xor i32 %2441, %2442
  %2452 = lshr i32 %2451, 4
  %2453 = trunc i32 %2452 to i8
  %2454 = and i8 %2453, 1
  store i8 %2454, i8* %30, align 1, !tbaa !2451
  %2455 = icmp eq i32 %2442, 0
  %2456 = zext i1 %2455 to i8
  store i8 %2456, i8* %33, align 1, !tbaa !2448
  %2457 = lshr i32 %2442, 31
  %2458 = trunc i32 %2457 to i8
  store i8 %2458, i8* %36, align 1, !tbaa !2449
  %2459 = lshr i32 %2441, 31
  %2460 = xor i32 %2457, %2459
  %2461 = add nuw nsw i32 %2460, %2457
  %2462 = icmp eq i32 %2461, 2
  %2463 = zext i1 %2462 to i8
  store i8 %2463, i8* %42, align 1, !tbaa !2450
  %2464 = sext i32 %2442 to i64
  store i64 %2464, i64* %RSI, align 8, !tbaa !2428
  %2465 = shl nsw i64 %2464, 3
  %2466 = add i64 %2465, %2437
  %2467 = add i64 %2434, 18
  store i64 %2467, i64* %PC, align 8
  %2468 = inttoptr i64 %2466 to double*
  %2469 = load double, double* %2468, align 8
  store double %2469, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2470 = add i64 %2434, 22
  store i64 %2470, i64* %PC, align 8
  %2471 = load i64, i64* %2436, align 8
  store i64 %2471, i64* %RDX, align 8, !tbaa !2428
  %2472 = add i64 %2434, 25
  store i64 %2472, i64* %PC, align 8
  %2473 = load i32, i32* %2440, align 4
  %2474 = add i32 %2473, 11
  %2475 = zext i32 %2474 to i64
  store i64 %2475, i64* %RCX, align 8, !tbaa !2428
  %2476 = icmp ugt i32 %2473, -12
  %2477 = zext i1 %2476 to i8
  store i8 %2477, i8* %17, align 1, !tbaa !2433
  %2478 = and i32 %2474, 255
  %2479 = tail call i32 @llvm.ctpop.i32(i32 %2478) #10
  %2480 = trunc i32 %2479 to i8
  %2481 = and i8 %2480, 1
  %2482 = xor i8 %2481, 1
  store i8 %2482, i8* %24, align 1, !tbaa !2447
  %2483 = xor i32 %2473, %2474
  %2484 = lshr i32 %2483, 4
  %2485 = trunc i32 %2484 to i8
  %2486 = and i8 %2485, 1
  store i8 %2486, i8* %30, align 1, !tbaa !2451
  %2487 = icmp eq i32 %2474, 0
  %2488 = zext i1 %2487 to i8
  store i8 %2488, i8* %33, align 1, !tbaa !2448
  %2489 = lshr i32 %2474, 31
  %2490 = trunc i32 %2489 to i8
  store i8 %2490, i8* %36, align 1, !tbaa !2449
  %2491 = lshr i32 %2473, 31
  %2492 = xor i32 %2489, %2491
  %2493 = add nuw nsw i32 %2492, %2489
  %2494 = icmp eq i32 %2493, 2
  %2495 = zext i1 %2494 to i8
  store i8 %2495, i8* %42, align 1, !tbaa !2450
  %2496 = sext i32 %2474 to i64
  store i64 %2496, i64* %RSI, align 8, !tbaa !2428
  %2497 = shl nsw i64 %2496, 3
  %2498 = add i64 %2497, %2471
  %2499 = add i64 %2434, 36
  store i64 %2499, i64* %PC, align 8
  %2500 = inttoptr i64 %2498 to double*
  %2501 = load double, double* %2500, align 8
  %2502 = fsub double %2469, %2501
  store double %2502, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2503 = load i64, i64* %RBP, align 8
  %2504 = add i64 %2503, -120
  %2505 = add i64 %2434, 41
  store i64 %2505, i64* %PC, align 8
  %2506 = inttoptr i64 %2504 to double*
  store double %2502, double* %2506, align 8
  %2507 = load i64, i64* %RBP, align 8
  %2508 = add i64 %2507, -16
  %2509 = load i64, i64* %PC, align 8
  %2510 = add i64 %2509, 4
  store i64 %2510, i64* %PC, align 8
  %2511 = inttoptr i64 %2508 to i64*
  %2512 = load i64, i64* %2511, align 8
  store i64 %2512, i64* %RDX, align 8, !tbaa !2428
  %2513 = add i64 %2507, -28
  %2514 = add i64 %2509, 7
  store i64 %2514, i64* %PC, align 8
  %2515 = inttoptr i64 %2513 to i32*
  %2516 = load i32, i32* %2515, align 4
  %2517 = add i32 %2516, 12
  %2518 = zext i32 %2517 to i64
  store i64 %2518, i64* %RCX, align 8, !tbaa !2428
  %2519 = icmp ugt i32 %2516, -13
  %2520 = zext i1 %2519 to i8
  store i8 %2520, i8* %17, align 1, !tbaa !2433
  %2521 = and i32 %2517, 255
  %2522 = tail call i32 @llvm.ctpop.i32(i32 %2521) #10
  %2523 = trunc i32 %2522 to i8
  %2524 = and i8 %2523, 1
  %2525 = xor i8 %2524, 1
  store i8 %2525, i8* %24, align 1, !tbaa !2447
  %2526 = xor i32 %2516, %2517
  %2527 = lshr i32 %2526, 4
  %2528 = trunc i32 %2527 to i8
  %2529 = and i8 %2528, 1
  store i8 %2529, i8* %30, align 1, !tbaa !2451
  %2530 = icmp eq i32 %2517, 0
  %2531 = zext i1 %2530 to i8
  store i8 %2531, i8* %33, align 1, !tbaa !2448
  %2532 = lshr i32 %2517, 31
  %2533 = trunc i32 %2532 to i8
  store i8 %2533, i8* %36, align 1, !tbaa !2449
  %2534 = lshr i32 %2516, 31
  %2535 = xor i32 %2532, %2534
  %2536 = add nuw nsw i32 %2535, %2532
  %2537 = icmp eq i32 %2536, 2
  %2538 = zext i1 %2537 to i8
  store i8 %2538, i8* %42, align 1, !tbaa !2450
  %2539 = sext i32 %2517 to i64
  store i64 %2539, i64* %RSI, align 8, !tbaa !2428
  %2540 = shl nsw i64 %2539, 3
  %2541 = add i64 %2540, %2512
  %2542 = add i64 %2509, 18
  store i64 %2542, i64* %PC, align 8
  %2543 = inttoptr i64 %2541 to double*
  %2544 = load double, double* %2543, align 8
  store double %2544, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2545 = add i64 %2509, 22
  store i64 %2545, i64* %PC, align 8
  %2546 = load i64, i64* %2511, align 8
  store i64 %2546, i64* %RDX, align 8, !tbaa !2428
  %2547 = add i64 %2509, 25
  store i64 %2547, i64* %PC, align 8
  %2548 = load i32, i32* %2515, align 4
  %2549 = add i32 %2548, 14
  %2550 = zext i32 %2549 to i64
  store i64 %2550, i64* %RCX, align 8, !tbaa !2428
  %2551 = icmp ugt i32 %2548, -15
  %2552 = zext i1 %2551 to i8
  store i8 %2552, i8* %17, align 1, !tbaa !2433
  %2553 = and i32 %2549, 255
  %2554 = tail call i32 @llvm.ctpop.i32(i32 %2553) #10
  %2555 = trunc i32 %2554 to i8
  %2556 = and i8 %2555, 1
  %2557 = xor i8 %2556, 1
  store i8 %2557, i8* %24, align 1, !tbaa !2447
  %2558 = xor i32 %2548, %2549
  %2559 = lshr i32 %2558, 4
  %2560 = trunc i32 %2559 to i8
  %2561 = and i8 %2560, 1
  store i8 %2561, i8* %30, align 1, !tbaa !2451
  %2562 = icmp eq i32 %2549, 0
  %2563 = zext i1 %2562 to i8
  store i8 %2563, i8* %33, align 1, !tbaa !2448
  %2564 = lshr i32 %2549, 31
  %2565 = trunc i32 %2564 to i8
  store i8 %2565, i8* %36, align 1, !tbaa !2449
  %2566 = lshr i32 %2548, 31
  %2567 = xor i32 %2564, %2566
  %2568 = add nuw nsw i32 %2567, %2564
  %2569 = icmp eq i32 %2568, 2
  %2570 = zext i1 %2569 to i8
  store i8 %2570, i8* %42, align 1, !tbaa !2450
  %2571 = sext i32 %2549 to i64
  store i64 %2571, i64* %RSI, align 8, !tbaa !2428
  %2572 = shl nsw i64 %2571, 3
  %2573 = add i64 %2572, %2546
  %2574 = add i64 %2509, 36
  store i64 %2574, i64* %PC, align 8
  %2575 = inttoptr i64 %2573 to double*
  %2576 = load double, double* %2575, align 8
  %2577 = fadd double %2544, %2576
  store double %2577, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2578 = load i64, i64* %RBP, align 8
  %2579 = add i64 %2578, -128
  %2580 = add i64 %2509, 41
  store i64 %2580, i64* %PC, align 8
  %2581 = inttoptr i64 %2579 to double*
  store double %2577, double* %2581, align 8
  %2582 = load i64, i64* %RBP, align 8
  %2583 = add i64 %2582, -16
  %2584 = load i64, i64* %PC, align 8
  %2585 = add i64 %2584, 4
  store i64 %2585, i64* %PC, align 8
  %2586 = inttoptr i64 %2583 to i64*
  %2587 = load i64, i64* %2586, align 8
  store i64 %2587, i64* %RDX, align 8, !tbaa !2428
  %2588 = add i64 %2582, -28
  %2589 = add i64 %2584, 7
  store i64 %2589, i64* %PC, align 8
  %2590 = inttoptr i64 %2588 to i32*
  %2591 = load i32, i32* %2590, align 4
  %2592 = add i32 %2591, 13
  %2593 = zext i32 %2592 to i64
  store i64 %2593, i64* %RCX, align 8, !tbaa !2428
  %2594 = icmp ugt i32 %2591, -14
  %2595 = zext i1 %2594 to i8
  store i8 %2595, i8* %17, align 1, !tbaa !2433
  %2596 = and i32 %2592, 255
  %2597 = tail call i32 @llvm.ctpop.i32(i32 %2596) #10
  %2598 = trunc i32 %2597 to i8
  %2599 = and i8 %2598, 1
  %2600 = xor i8 %2599, 1
  store i8 %2600, i8* %24, align 1, !tbaa !2447
  %2601 = xor i32 %2591, %2592
  %2602 = lshr i32 %2601, 4
  %2603 = trunc i32 %2602 to i8
  %2604 = and i8 %2603, 1
  store i8 %2604, i8* %30, align 1, !tbaa !2451
  %2605 = icmp eq i32 %2592, 0
  %2606 = zext i1 %2605 to i8
  store i8 %2606, i8* %33, align 1, !tbaa !2448
  %2607 = lshr i32 %2592, 31
  %2608 = trunc i32 %2607 to i8
  store i8 %2608, i8* %36, align 1, !tbaa !2449
  %2609 = lshr i32 %2591, 31
  %2610 = xor i32 %2607, %2609
  %2611 = add nuw nsw i32 %2610, %2607
  %2612 = icmp eq i32 %2611, 2
  %2613 = zext i1 %2612 to i8
  store i8 %2613, i8* %42, align 1, !tbaa !2450
  %2614 = sext i32 %2592 to i64
  store i64 %2614, i64* %RSI, align 8, !tbaa !2428
  %2615 = shl nsw i64 %2614, 3
  %2616 = add i64 %2615, %2587
  %2617 = add i64 %2584, 18
  store i64 %2617, i64* %PC, align 8
  %2618 = inttoptr i64 %2616 to double*
  %2619 = load double, double* %2618, align 8
  store double %2619, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2620 = add i64 %2584, 22
  store i64 %2620, i64* %PC, align 8
  %2621 = load i64, i64* %2586, align 8
  store i64 %2621, i64* %RDX, align 8, !tbaa !2428
  %2622 = add i64 %2584, 25
  store i64 %2622, i64* %PC, align 8
  %2623 = load i32, i32* %2590, align 4
  %2624 = add i32 %2623, 15
  %2625 = zext i32 %2624 to i64
  store i64 %2625, i64* %RCX, align 8, !tbaa !2428
  %2626 = icmp ugt i32 %2623, -16
  %2627 = zext i1 %2626 to i8
  store i8 %2627, i8* %17, align 1, !tbaa !2433
  %2628 = and i32 %2624, 255
  %2629 = tail call i32 @llvm.ctpop.i32(i32 %2628) #10
  %2630 = trunc i32 %2629 to i8
  %2631 = and i8 %2630, 1
  %2632 = xor i8 %2631, 1
  store i8 %2632, i8* %24, align 1, !tbaa !2447
  %2633 = xor i32 %2623, %2624
  %2634 = lshr i32 %2633, 4
  %2635 = trunc i32 %2634 to i8
  %2636 = and i8 %2635, 1
  store i8 %2636, i8* %30, align 1, !tbaa !2451
  %2637 = icmp eq i32 %2624, 0
  %2638 = zext i1 %2637 to i8
  store i8 %2638, i8* %33, align 1, !tbaa !2448
  %2639 = lshr i32 %2624, 31
  %2640 = trunc i32 %2639 to i8
  store i8 %2640, i8* %36, align 1, !tbaa !2449
  %2641 = lshr i32 %2623, 31
  %2642 = xor i32 %2639, %2641
  %2643 = add nuw nsw i32 %2642, %2639
  %2644 = icmp eq i32 %2643, 2
  %2645 = zext i1 %2644 to i8
  store i8 %2645, i8* %42, align 1, !tbaa !2450
  %2646 = sext i32 %2624 to i64
  store i64 %2646, i64* %RSI, align 8, !tbaa !2428
  %2647 = shl nsw i64 %2646, 3
  %2648 = add i64 %2647, %2621
  %2649 = add i64 %2584, 36
  store i64 %2649, i64* %PC, align 8
  %2650 = inttoptr i64 %2648 to double*
  %2651 = load double, double* %2650, align 8
  %2652 = fadd double %2619, %2651
  store double %2652, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2653 = load i64, i64* %RBP, align 8
  %2654 = add i64 %2653, -136
  %2655 = add i64 %2584, 44
  store i64 %2655, i64* %PC, align 8
  %2656 = inttoptr i64 %2654 to double*
  store double %2652, double* %2656, align 8
  %2657 = load i64, i64* %RBP, align 8
  %2658 = add i64 %2657, -16
  %2659 = load i64, i64* %PC, align 8
  %2660 = add i64 %2659, 4
  store i64 %2660, i64* %PC, align 8
  %2661 = inttoptr i64 %2658 to i64*
  %2662 = load i64, i64* %2661, align 8
  store i64 %2662, i64* %RDX, align 8, !tbaa !2428
  %2663 = add i64 %2657, -28
  %2664 = add i64 %2659, 7
  store i64 %2664, i64* %PC, align 8
  %2665 = inttoptr i64 %2663 to i32*
  %2666 = load i32, i32* %2665, align 4
  %2667 = add i32 %2666, 12
  %2668 = zext i32 %2667 to i64
  store i64 %2668, i64* %RCX, align 8, !tbaa !2428
  %2669 = icmp ugt i32 %2666, -13
  %2670 = zext i1 %2669 to i8
  store i8 %2670, i8* %17, align 1, !tbaa !2433
  %2671 = and i32 %2667, 255
  %2672 = tail call i32 @llvm.ctpop.i32(i32 %2671) #10
  %2673 = trunc i32 %2672 to i8
  %2674 = and i8 %2673, 1
  %2675 = xor i8 %2674, 1
  store i8 %2675, i8* %24, align 1, !tbaa !2447
  %2676 = xor i32 %2666, %2667
  %2677 = lshr i32 %2676, 4
  %2678 = trunc i32 %2677 to i8
  %2679 = and i8 %2678, 1
  store i8 %2679, i8* %30, align 1, !tbaa !2451
  %2680 = icmp eq i32 %2667, 0
  %2681 = zext i1 %2680 to i8
  store i8 %2681, i8* %33, align 1, !tbaa !2448
  %2682 = lshr i32 %2667, 31
  %2683 = trunc i32 %2682 to i8
  store i8 %2683, i8* %36, align 1, !tbaa !2449
  %2684 = lshr i32 %2666, 31
  %2685 = xor i32 %2682, %2684
  %2686 = add nuw nsw i32 %2685, %2682
  %2687 = icmp eq i32 %2686, 2
  %2688 = zext i1 %2687 to i8
  store i8 %2688, i8* %42, align 1, !tbaa !2450
  %2689 = sext i32 %2667 to i64
  store i64 %2689, i64* %RSI, align 8, !tbaa !2428
  %2690 = shl nsw i64 %2689, 3
  %2691 = add i64 %2690, %2662
  %2692 = add i64 %2659, 18
  store i64 %2692, i64* %PC, align 8
  %2693 = inttoptr i64 %2691 to double*
  %2694 = load double, double* %2693, align 8
  store double %2694, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2695 = add i64 %2659, 22
  store i64 %2695, i64* %PC, align 8
  %2696 = load i64, i64* %2661, align 8
  store i64 %2696, i64* %RDX, align 8, !tbaa !2428
  %2697 = add i64 %2659, 25
  store i64 %2697, i64* %PC, align 8
  %2698 = load i32, i32* %2665, align 4
  %2699 = add i32 %2698, 14
  %2700 = zext i32 %2699 to i64
  store i64 %2700, i64* %RCX, align 8, !tbaa !2428
  %2701 = icmp ugt i32 %2698, -15
  %2702 = zext i1 %2701 to i8
  store i8 %2702, i8* %17, align 1, !tbaa !2433
  %2703 = and i32 %2699, 255
  %2704 = tail call i32 @llvm.ctpop.i32(i32 %2703) #10
  %2705 = trunc i32 %2704 to i8
  %2706 = and i8 %2705, 1
  %2707 = xor i8 %2706, 1
  store i8 %2707, i8* %24, align 1, !tbaa !2447
  %2708 = xor i32 %2698, %2699
  %2709 = lshr i32 %2708, 4
  %2710 = trunc i32 %2709 to i8
  %2711 = and i8 %2710, 1
  store i8 %2711, i8* %30, align 1, !tbaa !2451
  %2712 = icmp eq i32 %2699, 0
  %2713 = zext i1 %2712 to i8
  store i8 %2713, i8* %33, align 1, !tbaa !2448
  %2714 = lshr i32 %2699, 31
  %2715 = trunc i32 %2714 to i8
  store i8 %2715, i8* %36, align 1, !tbaa !2449
  %2716 = lshr i32 %2698, 31
  %2717 = xor i32 %2714, %2716
  %2718 = add nuw nsw i32 %2717, %2714
  %2719 = icmp eq i32 %2718, 2
  %2720 = zext i1 %2719 to i8
  store i8 %2720, i8* %42, align 1, !tbaa !2450
  %2721 = sext i32 %2699 to i64
  store i64 %2721, i64* %RSI, align 8, !tbaa !2428
  %2722 = shl nsw i64 %2721, 3
  %2723 = add i64 %2722, %2696
  %2724 = add i64 %2659, 36
  store i64 %2724, i64* %PC, align 8
  %2725 = inttoptr i64 %2723 to double*
  %2726 = load double, double* %2725, align 8
  %2727 = fsub double %2694, %2726
  store double %2727, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2728 = load i64, i64* %RBP, align 8
  %2729 = add i64 %2728, -144
  %2730 = add i64 %2659, 44
  store i64 %2730, i64* %PC, align 8
  %2731 = inttoptr i64 %2729 to double*
  store double %2727, double* %2731, align 8
  %2732 = load i64, i64* %RBP, align 8
  %2733 = add i64 %2732, -16
  %2734 = load i64, i64* %PC, align 8
  %2735 = add i64 %2734, 4
  store i64 %2735, i64* %PC, align 8
  %2736 = inttoptr i64 %2733 to i64*
  %2737 = load i64, i64* %2736, align 8
  store i64 %2737, i64* %RDX, align 8, !tbaa !2428
  %2738 = add i64 %2732, -28
  %2739 = add i64 %2734, 7
  store i64 %2739, i64* %PC, align 8
  %2740 = inttoptr i64 %2738 to i32*
  %2741 = load i32, i32* %2740, align 4
  %2742 = add i32 %2741, 13
  %2743 = zext i32 %2742 to i64
  store i64 %2743, i64* %RCX, align 8, !tbaa !2428
  %2744 = icmp ugt i32 %2741, -14
  %2745 = zext i1 %2744 to i8
  store i8 %2745, i8* %17, align 1, !tbaa !2433
  %2746 = and i32 %2742, 255
  %2747 = tail call i32 @llvm.ctpop.i32(i32 %2746) #10
  %2748 = trunc i32 %2747 to i8
  %2749 = and i8 %2748, 1
  %2750 = xor i8 %2749, 1
  store i8 %2750, i8* %24, align 1, !tbaa !2447
  %2751 = xor i32 %2741, %2742
  %2752 = lshr i32 %2751, 4
  %2753 = trunc i32 %2752 to i8
  %2754 = and i8 %2753, 1
  store i8 %2754, i8* %30, align 1, !tbaa !2451
  %2755 = icmp eq i32 %2742, 0
  %2756 = zext i1 %2755 to i8
  store i8 %2756, i8* %33, align 1, !tbaa !2448
  %2757 = lshr i32 %2742, 31
  %2758 = trunc i32 %2757 to i8
  store i8 %2758, i8* %36, align 1, !tbaa !2449
  %2759 = lshr i32 %2741, 31
  %2760 = xor i32 %2757, %2759
  %2761 = add nuw nsw i32 %2760, %2757
  %2762 = icmp eq i32 %2761, 2
  %2763 = zext i1 %2762 to i8
  store i8 %2763, i8* %42, align 1, !tbaa !2450
  %2764 = sext i32 %2742 to i64
  store i64 %2764, i64* %RSI, align 8, !tbaa !2428
  %2765 = shl nsw i64 %2764, 3
  %2766 = add i64 %2765, %2737
  %2767 = add i64 %2734, 18
  store i64 %2767, i64* %PC, align 8
  %2768 = inttoptr i64 %2766 to double*
  %2769 = load double, double* %2768, align 8
  store double %2769, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2770 = add i64 %2734, 22
  store i64 %2770, i64* %PC, align 8
  %2771 = load i64, i64* %2736, align 8
  store i64 %2771, i64* %RDX, align 8, !tbaa !2428
  %2772 = add i64 %2734, 25
  store i64 %2772, i64* %PC, align 8
  %2773 = load i32, i32* %2740, align 4
  %2774 = add i32 %2773, 15
  %2775 = zext i32 %2774 to i64
  store i64 %2775, i64* %RCX, align 8, !tbaa !2428
  %2776 = icmp ugt i32 %2773, -16
  %2777 = zext i1 %2776 to i8
  store i8 %2777, i8* %17, align 1, !tbaa !2433
  %2778 = and i32 %2774, 255
  %2779 = tail call i32 @llvm.ctpop.i32(i32 %2778) #10
  %2780 = trunc i32 %2779 to i8
  %2781 = and i8 %2780, 1
  %2782 = xor i8 %2781, 1
  store i8 %2782, i8* %24, align 1, !tbaa !2447
  %2783 = xor i32 %2773, %2774
  %2784 = lshr i32 %2783, 4
  %2785 = trunc i32 %2784 to i8
  %2786 = and i8 %2785, 1
  store i8 %2786, i8* %30, align 1, !tbaa !2451
  %2787 = icmp eq i32 %2774, 0
  %2788 = zext i1 %2787 to i8
  store i8 %2788, i8* %33, align 1, !tbaa !2448
  %2789 = lshr i32 %2774, 31
  %2790 = trunc i32 %2789 to i8
  store i8 %2790, i8* %36, align 1, !tbaa !2449
  %2791 = lshr i32 %2773, 31
  %2792 = xor i32 %2789, %2791
  %2793 = add nuw nsw i32 %2792, %2789
  %2794 = icmp eq i32 %2793, 2
  %2795 = zext i1 %2794 to i8
  store i8 %2795, i8* %42, align 1, !tbaa !2450
  %2796 = sext i32 %2774 to i64
  store i64 %2796, i64* %RSI, align 8, !tbaa !2428
  %2797 = shl nsw i64 %2796, 3
  %2798 = add i64 %2797, %2771
  %2799 = add i64 %2734, 36
  store i64 %2799, i64* %PC, align 8
  %2800 = inttoptr i64 %2798 to double*
  %2801 = load double, double* %2800, align 8
  %2802 = fsub double %2769, %2801
  store double %2802, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2803 = load i64, i64* %RBP, align 8
  %2804 = add i64 %2803, -152
  %2805 = add i64 %2734, 44
  store i64 %2805, i64* %PC, align 8
  %2806 = inttoptr i64 %2804 to double*
  store double %2802, double* %2806, align 8
  %2807 = load i64, i64* %RBP, align 8
  %2808 = add i64 %2807, -96
  %2809 = load i64, i64* %PC, align 8
  %2810 = add i64 %2809, 5
  store i64 %2810, i64* %PC, align 8
  %2811 = inttoptr i64 %2808 to double*
  %2812 = load double, double* %2811, align 8
  store double %2812, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2813 = add i64 %2807, -128
  %2814 = add i64 %2809, 10
  store i64 %2814, i64* %PC, align 8
  %2815 = inttoptr i64 %2813 to double*
  %2816 = load double, double* %2815, align 8
  %2817 = fadd double %2812, %2816
  store double %2817, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2818 = add i64 %2807, -16
  %2819 = add i64 %2809, 14
  store i64 %2819, i64* %PC, align 8
  %2820 = inttoptr i64 %2818 to i64*
  %2821 = load i64, i64* %2820, align 8
  store i64 %2821, i64* %RDX, align 8, !tbaa !2428
  %2822 = add i64 %2807, -28
  %2823 = add i64 %2809, 17
  store i64 %2823, i64* %PC, align 8
  %2824 = inttoptr i64 %2822 to i32*
  %2825 = load i32, i32* %2824, align 4
  %2826 = add i32 %2825, 8
  %2827 = zext i32 %2826 to i64
  store i64 %2827, i64* %RCX, align 8, !tbaa !2428
  %2828 = icmp ugt i32 %2825, -9
  %2829 = zext i1 %2828 to i8
  store i8 %2829, i8* %17, align 1, !tbaa !2433
  %2830 = and i32 %2826, 255
  %2831 = tail call i32 @llvm.ctpop.i32(i32 %2830) #10
  %2832 = trunc i32 %2831 to i8
  %2833 = and i8 %2832, 1
  %2834 = xor i8 %2833, 1
  store i8 %2834, i8* %24, align 1, !tbaa !2447
  %2835 = xor i32 %2825, %2826
  %2836 = lshr i32 %2835, 4
  %2837 = trunc i32 %2836 to i8
  %2838 = and i8 %2837, 1
  store i8 %2838, i8* %30, align 1, !tbaa !2451
  %2839 = icmp eq i32 %2826, 0
  %2840 = zext i1 %2839 to i8
  store i8 %2840, i8* %33, align 1, !tbaa !2448
  %2841 = lshr i32 %2826, 31
  %2842 = trunc i32 %2841 to i8
  store i8 %2842, i8* %36, align 1, !tbaa !2449
  %2843 = lshr i32 %2825, 31
  %2844 = xor i32 %2841, %2843
  %2845 = add nuw nsw i32 %2844, %2841
  %2846 = icmp eq i32 %2845, 2
  %2847 = zext i1 %2846 to i8
  store i8 %2847, i8* %42, align 1, !tbaa !2450
  %2848 = sext i32 %2826 to i64
  store i64 %2848, i64* %RSI, align 8, !tbaa !2428
  %2849 = shl nsw i64 %2848, 3
  %2850 = add i64 %2849, %2821
  %2851 = add i64 %2809, 28
  store i64 %2851, i64* %PC, align 8
  %2852 = inttoptr i64 %2850 to double*
  store double %2817, double* %2852, align 8
  %2853 = load i64, i64* %RBP, align 8
  %2854 = add i64 %2853, -104
  %2855 = load i64, i64* %PC, align 8
  %2856 = add i64 %2855, 5
  store i64 %2856, i64* %PC, align 8
  %2857 = inttoptr i64 %2854 to double*
  %2858 = load double, double* %2857, align 8
  store double %2858, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2859 = add i64 %2853, -136
  %2860 = add i64 %2855, 13
  store i64 %2860, i64* %PC, align 8
  %2861 = inttoptr i64 %2859 to double*
  %2862 = load double, double* %2861, align 8
  %2863 = fadd double %2858, %2862
  store double %2863, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2864 = add i64 %2853, -16
  %2865 = add i64 %2855, 17
  store i64 %2865, i64* %PC, align 8
  %2866 = inttoptr i64 %2864 to i64*
  %2867 = load i64, i64* %2866, align 8
  store i64 %2867, i64* %RDX, align 8, !tbaa !2428
  %2868 = add i64 %2853, -28
  %2869 = add i64 %2855, 20
  store i64 %2869, i64* %PC, align 8
  %2870 = inttoptr i64 %2868 to i32*
  %2871 = load i32, i32* %2870, align 4
  %2872 = add i32 %2871, 9
  %2873 = zext i32 %2872 to i64
  store i64 %2873, i64* %RCX, align 8, !tbaa !2428
  %2874 = icmp ugt i32 %2871, -10
  %2875 = zext i1 %2874 to i8
  store i8 %2875, i8* %17, align 1, !tbaa !2433
  %2876 = and i32 %2872, 255
  %2877 = tail call i32 @llvm.ctpop.i32(i32 %2876) #10
  %2878 = trunc i32 %2877 to i8
  %2879 = and i8 %2878, 1
  %2880 = xor i8 %2879, 1
  store i8 %2880, i8* %24, align 1, !tbaa !2447
  %2881 = xor i32 %2871, %2872
  %2882 = lshr i32 %2881, 4
  %2883 = trunc i32 %2882 to i8
  %2884 = and i8 %2883, 1
  store i8 %2884, i8* %30, align 1, !tbaa !2451
  %2885 = icmp eq i32 %2872, 0
  %2886 = zext i1 %2885 to i8
  store i8 %2886, i8* %33, align 1, !tbaa !2448
  %2887 = lshr i32 %2872, 31
  %2888 = trunc i32 %2887 to i8
  store i8 %2888, i8* %36, align 1, !tbaa !2449
  %2889 = lshr i32 %2871, 31
  %2890 = xor i32 %2887, %2889
  %2891 = add nuw nsw i32 %2890, %2887
  %2892 = icmp eq i32 %2891, 2
  %2893 = zext i1 %2892 to i8
  store i8 %2893, i8* %42, align 1, !tbaa !2450
  %2894 = sext i32 %2872 to i64
  store i64 %2894, i64* %RSI, align 8, !tbaa !2428
  %2895 = shl nsw i64 %2894, 3
  %2896 = add i64 %2895, %2867
  %2897 = add i64 %2855, 31
  store i64 %2897, i64* %PC, align 8
  %2898 = inttoptr i64 %2896 to double*
  store double %2863, double* %2898, align 8
  %2899 = load i64, i64* %RBP, align 8
  %2900 = add i64 %2899, -128
  %2901 = load i64, i64* %PC, align 8
  %2902 = add i64 %2901, 5
  store i64 %2902, i64* %PC, align 8
  %2903 = inttoptr i64 %2900 to double*
  %2904 = load double, double* %2903, align 8
  store double %2904, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2905 = add i64 %2899, -96
  %2906 = add i64 %2901, 10
  store i64 %2906, i64* %PC, align 8
  %2907 = inttoptr i64 %2905 to double*
  %2908 = load double, double* %2907, align 8
  %2909 = fsub double %2908, %2904
  store double %2909, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %2910 = add i64 %2901, 19
  store i64 %2910, i64* %PC, align 8
  store double %2909, double* %2907, align 8
  %2911 = load i64, i64* %RBP, align 8
  %2912 = add i64 %2911, -136
  %2913 = load i64, i64* %PC, align 8
  %2914 = add i64 %2913, 8
  store i64 %2914, i64* %PC, align 8
  %2915 = inttoptr i64 %2912 to double*
  %2916 = load double, double* %2915, align 8
  store double %2916, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %2917 = add i64 %2911, -104
  %2918 = add i64 %2913, 13
  store i64 %2918, i64* %PC, align 8
  %2919 = inttoptr i64 %2917 to double*
  %2920 = load double, double* %2919, align 8
  %2921 = fsub double %2920, %2916
  store double %2921, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %2922 = add i64 %2913, 22
  store i64 %2922, i64* %PC, align 8
  store double %2921, double* %2919, align 8
  %2923 = load i64, i64* %RBP, align 8
  %2924 = add i64 %2923, -72
  %2925 = load i64, i64* %PC, align 8
  %2926 = add i64 %2925, 5
  store i64 %2926, i64* %PC, align 8
  %2927 = inttoptr i64 %2924 to i64*
  %2928 = load i64, i64* %2927, align 8
  %2929 = load i64, i64* %RAX, align 8
  %2930 = xor i64 %2929, %2928
  store i64 %2930, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %17, align 1, !tbaa !2433
  %2931 = trunc i64 %2930 to i32
  %2932 = and i32 %2931, 255
  %2933 = tail call i32 @llvm.ctpop.i32(i32 %2932) #10
  %2934 = trunc i32 %2933 to i8
  %2935 = and i8 %2934, 1
  %2936 = xor i8 %2935, 1
  store i8 %2936, i8* %24, align 1, !tbaa !2447
  %2937 = icmp eq i64 %2930, 0
  %2938 = zext i1 %2937 to i8
  store i8 %2938, i8* %33, align 1, !tbaa !2448
  %2939 = lshr i64 %2930, 63
  %2940 = trunc i64 %2939 to i8
  store i8 %2940, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i64 %2930, i64* %791, align 1, !tbaa !2428
  store i64 0, i64* %69, align 1, !tbaa !2428
  %2941 = add i64 %2923, -96
  %2942 = add i64 %2925, 23
  store i64 %2942, i64* %PC, align 8
  %2943 = bitcast i64 %2930 to double
  %2944 = inttoptr i64 %2941 to double*
  %2945 = load double, double* %2944, align 8
  %2946 = fmul double %2943, %2945
  store double %2946, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2947 = add i64 %2923, -64
  %2948 = add i64 %2925, 28
  store i64 %2948, i64* %PC, align 8
  %2949 = inttoptr i64 %2947 to double*
  %2950 = load double, double* %2949, align 8
  store double %2950, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %2951 = add i64 %2923, -104
  %2952 = add i64 %2925, 33
  store i64 %2952, i64* %PC, align 8
  %2953 = inttoptr i64 %2951 to double*
  %2954 = load double, double* %2953, align 8
  %2955 = fmul double %2950, %2954
  store double %2955, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %2956 = fsub double %2946, %2955
  store double %2956, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %2957 = add i64 %2923, -16
  %2958 = add i64 %2925, 41
  store i64 %2958, i64* %PC, align 8
  %2959 = inttoptr i64 %2957 to i64*
  %2960 = load i64, i64* %2959, align 8
  store i64 %2960, i64* %RDX, align 8, !tbaa !2428
  %2961 = add i64 %2923, -28
  %2962 = add i64 %2925, 44
  store i64 %2962, i64* %PC, align 8
  %2963 = inttoptr i64 %2961 to i32*
  %2964 = load i32, i32* %2963, align 4
  %2965 = add i32 %2964, 12
  %2966 = zext i32 %2965 to i64
  store i64 %2966, i64* %RCX, align 8, !tbaa !2428
  %2967 = icmp ugt i32 %2964, -13
  %2968 = zext i1 %2967 to i8
  store i8 %2968, i8* %17, align 1, !tbaa !2433
  %2969 = and i32 %2965, 255
  %2970 = tail call i32 @llvm.ctpop.i32(i32 %2969) #10
  %2971 = trunc i32 %2970 to i8
  %2972 = and i8 %2971, 1
  %2973 = xor i8 %2972, 1
  store i8 %2973, i8* %24, align 1, !tbaa !2447
  %2974 = xor i32 %2964, %2965
  %2975 = lshr i32 %2974, 4
  %2976 = trunc i32 %2975 to i8
  %2977 = and i8 %2976, 1
  store i8 %2977, i8* %30, align 1, !tbaa !2451
  %2978 = icmp eq i32 %2965, 0
  %2979 = zext i1 %2978 to i8
  store i8 %2979, i8* %33, align 1, !tbaa !2448
  %2980 = lshr i32 %2965, 31
  %2981 = trunc i32 %2980 to i8
  store i8 %2981, i8* %36, align 1, !tbaa !2449
  %2982 = lshr i32 %2964, 31
  %2983 = xor i32 %2980, %2982
  %2984 = add nuw nsw i32 %2983, %2980
  %2985 = icmp eq i32 %2984, 2
  %2986 = zext i1 %2985 to i8
  store i8 %2986, i8* %42, align 1, !tbaa !2450
  %2987 = sext i32 %2965 to i64
  store i64 %2987, i64* %RSI, align 8, !tbaa !2428
  %2988 = shl nsw i64 %2987, 3
  %2989 = add i64 %2988, %2960
  %2990 = add i64 %2925, 55
  store i64 %2990, i64* %PC, align 8
  %2991 = inttoptr i64 %2989 to double*
  store double %2956, double* %2991, align 8
  %2992 = load i64, i64* %RBP, align 8
  %2993 = add i64 %2992, -72
  %2994 = load i64, i64* %PC, align 8
  %2995 = add i64 %2994, 5
  store i64 %2995, i64* %PC, align 8
  %2996 = inttoptr i64 %2993 to i64*
  %2997 = load i64, i64* %2996, align 8
  %2998 = load i64, i64* %RAX, align 8
  %2999 = xor i64 %2998, %2997
  store i64 %2999, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %17, align 1, !tbaa !2433
  %3000 = trunc i64 %2999 to i32
  %3001 = and i32 %3000, 255
  %3002 = tail call i32 @llvm.ctpop.i32(i32 %3001) #10
  %3003 = trunc i32 %3002 to i8
  %3004 = and i8 %3003, 1
  %3005 = xor i8 %3004, 1
  store i8 %3005, i8* %24, align 1, !tbaa !2447
  %3006 = icmp eq i64 %2999, 0
  %3007 = zext i1 %3006 to i8
  store i8 %3007, i8* %33, align 1, !tbaa !2448
  %3008 = lshr i64 %2999, 63
  %3009 = trunc i64 %3008 to i8
  store i8 %3009, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i64 %2999, i64* %791, align 1, !tbaa !2428
  store i64 0, i64* %69, align 1, !tbaa !2428
  %3010 = add i64 %2992, -104
  %3011 = add i64 %2994, 23
  store i64 %3011, i64* %PC, align 8
  %3012 = bitcast i64 %2999 to double
  %3013 = inttoptr i64 %3010 to double*
  %3014 = load double, double* %3013, align 8
  %3015 = fmul double %3012, %3014
  store double %3015, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3016 = add i64 %2992, -64
  %3017 = add i64 %2994, 28
  store i64 %3017, i64* %PC, align 8
  %3018 = inttoptr i64 %3016 to double*
  %3019 = load double, double* %3018, align 8
  store double %3019, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %3020 = add i64 %2992, -96
  %3021 = add i64 %2994, 33
  store i64 %3021, i64* %PC, align 8
  %3022 = inttoptr i64 %3020 to double*
  %3023 = load double, double* %3022, align 8
  %3024 = fmul double %3019, %3023
  store double %3024, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %3025 = fadd double %3015, %3024
  store double %3025, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3026 = add i64 %2992, -16
  %3027 = add i64 %2994, 41
  store i64 %3027, i64* %PC, align 8
  %3028 = inttoptr i64 %3026 to i64*
  %3029 = load i64, i64* %3028, align 8
  store i64 %3029, i64* %RAX, align 8, !tbaa !2428
  %3030 = add i64 %2992, -28
  %3031 = add i64 %2994, 44
  store i64 %3031, i64* %PC, align 8
  %3032 = inttoptr i64 %3030 to i32*
  %3033 = load i32, i32* %3032, align 4
  %3034 = add i32 %3033, 13
  %3035 = zext i32 %3034 to i64
  store i64 %3035, i64* %RCX, align 8, !tbaa !2428
  %3036 = icmp ugt i32 %3033, -14
  %3037 = zext i1 %3036 to i8
  store i8 %3037, i8* %17, align 1, !tbaa !2433
  %3038 = and i32 %3034, 255
  %3039 = tail call i32 @llvm.ctpop.i32(i32 %3038) #10
  %3040 = trunc i32 %3039 to i8
  %3041 = and i8 %3040, 1
  %3042 = xor i8 %3041, 1
  store i8 %3042, i8* %24, align 1, !tbaa !2447
  %3043 = xor i32 %3033, %3034
  %3044 = lshr i32 %3043, 4
  %3045 = trunc i32 %3044 to i8
  %3046 = and i8 %3045, 1
  store i8 %3046, i8* %30, align 1, !tbaa !2451
  %3047 = icmp eq i32 %3034, 0
  %3048 = zext i1 %3047 to i8
  store i8 %3048, i8* %33, align 1, !tbaa !2448
  %3049 = lshr i32 %3034, 31
  %3050 = trunc i32 %3049 to i8
  store i8 %3050, i8* %36, align 1, !tbaa !2449
  %3051 = lshr i32 %3033, 31
  %3052 = xor i32 %3049, %3051
  %3053 = add nuw nsw i32 %3052, %3049
  %3054 = icmp eq i32 %3053, 2
  %3055 = zext i1 %3054 to i8
  store i8 %3055, i8* %42, align 1, !tbaa !2450
  %3056 = sext i32 %3034 to i64
  store i64 %3056, i64* %RDX, align 8, !tbaa !2428
  %3057 = shl nsw i64 %3056, 3
  %3058 = add i64 %3057, %3029
  %3059 = add i64 %2994, 55
  store i64 %3059, i64* %PC, align 8
  %3060 = inttoptr i64 %3058 to double*
  store double %3025, double* %3060, align 8
  %3061 = load i64, i64* %RBP, align 8
  %3062 = add i64 %3061, -112
  %3063 = load i64, i64* %PC, align 8
  %3064 = add i64 %3063, 5
  store i64 %3064, i64* %PC, align 8
  %3065 = inttoptr i64 %3062 to double*
  %3066 = load double, double* %3065, align 8
  store double %3066, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3067 = add i64 %3061, -152
  %3068 = add i64 %3063, 13
  store i64 %3068, i64* %PC, align 8
  %3069 = inttoptr i64 %3067 to double*
  %3070 = load double, double* %3069, align 8
  %3071 = fsub double %3066, %3070
  store double %3071, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3072 = add i64 %3061, -96
  %3073 = add i64 %3063, 18
  store i64 %3073, i64* %PC, align 8
  %3074 = inttoptr i64 %3072 to double*
  store double %3071, double* %3074, align 8
  %3075 = load i64, i64* %RBP, align 8
  %3076 = add i64 %3075, -120
  %3077 = load i64, i64* %PC, align 8
  %3078 = add i64 %3077, 5
  store i64 %3078, i64* %PC, align 8
  %3079 = inttoptr i64 %3076 to double*
  %3080 = load double, double* %3079, align 8
  store double %3080, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3081 = add i64 %3075, -144
  %3082 = add i64 %3077, 13
  store i64 %3082, i64* %PC, align 8
  %3083 = inttoptr i64 %3081 to double*
  %3084 = load double, double* %3083, align 8
  %3085 = fadd double %3080, %3084
  store double %3085, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3086 = add i64 %3075, -104
  %3087 = add i64 %3077, 18
  store i64 %3087, i64* %PC, align 8
  %3088 = inttoptr i64 %3086 to double*
  store double %3085, double* %3088, align 8
  %3089 = load i64, i64* %RBP, align 8
  %3090 = add i64 %3089, -48
  %3091 = load i64, i64* %PC, align 8
  %3092 = add i64 %3091, 5
  store i64 %3092, i64* %PC, align 8
  %3093 = inttoptr i64 %3090 to double*
  %3094 = load double, double* %3093, align 8
  store double %3094, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3095 = add i64 %3089, -96
  %3096 = add i64 %3091, 10
  store i64 %3096, i64* %PC, align 8
  %3097 = inttoptr i64 %3095 to double*
  %3098 = load double, double* %3097, align 8
  %3099 = fmul double %3094, %3098
  store double %3099, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3100 = add i64 %3089, -56
  %3101 = add i64 %3091, 15
  store i64 %3101, i64* %PC, align 8
  %3102 = inttoptr i64 %3100 to double*
  %3103 = load double, double* %3102, align 8
  store double %3103, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %3104 = add i64 %3089, -104
  %3105 = add i64 %3091, 20
  store i64 %3105, i64* %PC, align 8
  %3106 = inttoptr i64 %3104 to double*
  %3107 = load double, double* %3106, align 8
  %3108 = fmul double %3103, %3107
  store double %3108, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %3109 = fsub double %3099, %3108
  store double %3109, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3110 = add i64 %3089, -16
  %3111 = add i64 %3091, 28
  store i64 %3111, i64* %PC, align 8
  %3112 = inttoptr i64 %3110 to i64*
  %3113 = load i64, i64* %3112, align 8
  store i64 %3113, i64* %RAX, align 8, !tbaa !2428
  %3114 = add i64 %3089, -28
  %3115 = add i64 %3091, 31
  store i64 %3115, i64* %PC, align 8
  %3116 = inttoptr i64 %3114 to i32*
  %3117 = load i32, i32* %3116, align 4
  %3118 = add i32 %3117, 10
  %3119 = zext i32 %3118 to i64
  store i64 %3119, i64* %RCX, align 8, !tbaa !2428
  %3120 = icmp ugt i32 %3117, -11
  %3121 = zext i1 %3120 to i8
  store i8 %3121, i8* %17, align 1, !tbaa !2433
  %3122 = and i32 %3118, 255
  %3123 = tail call i32 @llvm.ctpop.i32(i32 %3122) #10
  %3124 = trunc i32 %3123 to i8
  %3125 = and i8 %3124, 1
  %3126 = xor i8 %3125, 1
  store i8 %3126, i8* %24, align 1, !tbaa !2447
  %3127 = xor i32 %3117, %3118
  %3128 = lshr i32 %3127, 4
  %3129 = trunc i32 %3128 to i8
  %3130 = and i8 %3129, 1
  store i8 %3130, i8* %30, align 1, !tbaa !2451
  %3131 = icmp eq i32 %3118, 0
  %3132 = zext i1 %3131 to i8
  store i8 %3132, i8* %33, align 1, !tbaa !2448
  %3133 = lshr i32 %3118, 31
  %3134 = trunc i32 %3133 to i8
  store i8 %3134, i8* %36, align 1, !tbaa !2449
  %3135 = lshr i32 %3117, 31
  %3136 = xor i32 %3133, %3135
  %3137 = add nuw nsw i32 %3136, %3133
  %3138 = icmp eq i32 %3137, 2
  %3139 = zext i1 %3138 to i8
  store i8 %3139, i8* %42, align 1, !tbaa !2450
  %3140 = sext i32 %3118 to i64
  store i64 %3140, i64* %RDX, align 8, !tbaa !2428
  %3141 = shl nsw i64 %3140, 3
  %3142 = add i64 %3141, %3113
  %3143 = add i64 %3091, 42
  store i64 %3143, i64* %PC, align 8
  %3144 = inttoptr i64 %3142 to double*
  store double %3109, double* %3144, align 8
  %3145 = load i64, i64* %RBP, align 8
  %3146 = add i64 %3145, -48
  %3147 = load i64, i64* %PC, align 8
  %3148 = add i64 %3147, 5
  store i64 %3148, i64* %PC, align 8
  %3149 = inttoptr i64 %3146 to double*
  %3150 = load double, double* %3149, align 8
  store double %3150, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3151 = add i64 %3145, -104
  %3152 = add i64 %3147, 10
  store i64 %3152, i64* %PC, align 8
  %3153 = inttoptr i64 %3151 to double*
  %3154 = load double, double* %3153, align 8
  %3155 = fmul double %3150, %3154
  store double %3155, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3156 = add i64 %3145, -56
  %3157 = add i64 %3147, 15
  store i64 %3157, i64* %PC, align 8
  %3158 = inttoptr i64 %3156 to double*
  %3159 = load double, double* %3158, align 8
  store double %3159, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %3160 = add i64 %3145, -96
  %3161 = add i64 %3147, 20
  store i64 %3161, i64* %PC, align 8
  %3162 = inttoptr i64 %3160 to double*
  %3163 = load double, double* %3162, align 8
  %3164 = fmul double %3159, %3163
  store double %3164, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %3165 = fadd double %3155, %3164
  store double %3165, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3166 = add i64 %3145, -16
  %3167 = add i64 %3147, 28
  store i64 %3167, i64* %PC, align 8
  %3168 = inttoptr i64 %3166 to i64*
  %3169 = load i64, i64* %3168, align 8
  store i64 %3169, i64* %RAX, align 8, !tbaa !2428
  %3170 = add i64 %3145, -28
  %3171 = add i64 %3147, 31
  store i64 %3171, i64* %PC, align 8
  %3172 = inttoptr i64 %3170 to i32*
  %3173 = load i32, i32* %3172, align 4
  %3174 = add i32 %3173, 11
  %3175 = zext i32 %3174 to i64
  store i64 %3175, i64* %RCX, align 8, !tbaa !2428
  %3176 = icmp ugt i32 %3173, -12
  %3177 = zext i1 %3176 to i8
  store i8 %3177, i8* %17, align 1, !tbaa !2433
  %3178 = and i32 %3174, 255
  %3179 = tail call i32 @llvm.ctpop.i32(i32 %3178) #10
  %3180 = trunc i32 %3179 to i8
  %3181 = and i8 %3180, 1
  %3182 = xor i8 %3181, 1
  store i8 %3182, i8* %24, align 1, !tbaa !2447
  %3183 = xor i32 %3173, %3174
  %3184 = lshr i32 %3183, 4
  %3185 = trunc i32 %3184 to i8
  %3186 = and i8 %3185, 1
  store i8 %3186, i8* %30, align 1, !tbaa !2451
  %3187 = icmp eq i32 %3174, 0
  %3188 = zext i1 %3187 to i8
  store i8 %3188, i8* %33, align 1, !tbaa !2448
  %3189 = lshr i32 %3174, 31
  %3190 = trunc i32 %3189 to i8
  store i8 %3190, i8* %36, align 1, !tbaa !2449
  %3191 = lshr i32 %3173, 31
  %3192 = xor i32 %3189, %3191
  %3193 = add nuw nsw i32 %3192, %3189
  %3194 = icmp eq i32 %3193, 2
  %3195 = zext i1 %3194 to i8
  store i8 %3195, i8* %42, align 1, !tbaa !2450
  %3196 = sext i32 %3174 to i64
  store i64 %3196, i64* %RDX, align 8, !tbaa !2428
  %3197 = shl nsw i64 %3196, 3
  %3198 = add i64 %3197, %3169
  %3199 = add i64 %3147, 42
  store i64 %3199, i64* %PC, align 8
  %3200 = inttoptr i64 %3198 to double*
  store double %3165, double* %3200, align 8
  %3201 = load i64, i64* %RBP, align 8
  %3202 = add i64 %3201, -112
  %3203 = load i64, i64* %PC, align 8
  %3204 = add i64 %3203, 5
  store i64 %3204, i64* %PC, align 8
  %3205 = inttoptr i64 %3202 to double*
  %3206 = load double, double* %3205, align 8
  store double %3206, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3207 = add i64 %3201, -152
  %3208 = add i64 %3203, 13
  store i64 %3208, i64* %PC, align 8
  %3209 = inttoptr i64 %3207 to double*
  %3210 = load double, double* %3209, align 8
  %3211 = fadd double %3206, %3210
  store double %3211, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3212 = add i64 %3201, -96
  %3213 = add i64 %3203, 18
  store i64 %3213, i64* %PC, align 8
  %3214 = inttoptr i64 %3212 to double*
  store double %3211, double* %3214, align 8
  %3215 = load i64, i64* %RBP, align 8
  %3216 = add i64 %3215, -120
  %3217 = load i64, i64* %PC, align 8
  %3218 = add i64 %3217, 5
  store i64 %3218, i64* %PC, align 8
  %3219 = inttoptr i64 %3216 to double*
  %3220 = load double, double* %3219, align 8
  store double %3220, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3221 = add i64 %3215, -144
  %3222 = add i64 %3217, 13
  store i64 %3222, i64* %PC, align 8
  %3223 = inttoptr i64 %3221 to double*
  %3224 = load double, double* %3223, align 8
  %3225 = fsub double %3220, %3224
  store double %3225, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3226 = add i64 %3215, -104
  %3227 = add i64 %3217, 18
  store i64 %3227, i64* %PC, align 8
  %3228 = inttoptr i64 %3226 to double*
  store double %3225, double* %3228, align 8
  %3229 = load i64, i64* %RBP, align 8
  %3230 = add i64 %3229, -80
  %3231 = load i64, i64* %PC, align 8
  %3232 = add i64 %3231, 5
  store i64 %3232, i64* %PC, align 8
  %3233 = inttoptr i64 %3230 to double*
  %3234 = load double, double* %3233, align 8
  store double %3234, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3235 = add i64 %3229, -96
  %3236 = add i64 %3231, 10
  store i64 %3236, i64* %PC, align 8
  %3237 = inttoptr i64 %3235 to double*
  %3238 = load double, double* %3237, align 8
  %3239 = fmul double %3234, %3238
  store double %3239, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3240 = add i64 %3229, -88
  %3241 = add i64 %3231, 15
  store i64 %3241, i64* %PC, align 8
  %3242 = inttoptr i64 %3240 to double*
  %3243 = load double, double* %3242, align 8
  store double %3243, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %3244 = add i64 %3229, -104
  %3245 = add i64 %3231, 20
  store i64 %3245, i64* %PC, align 8
  %3246 = inttoptr i64 %3244 to double*
  %3247 = load double, double* %3246, align 8
  %3248 = fmul double %3243, %3247
  store double %3248, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %3249 = fsub double %3239, %3248
  store double %3249, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3250 = add i64 %3229, -16
  %3251 = add i64 %3231, 28
  store i64 %3251, i64* %PC, align 8
  %3252 = inttoptr i64 %3250 to i64*
  %3253 = load i64, i64* %3252, align 8
  store i64 %3253, i64* %RAX, align 8, !tbaa !2428
  %3254 = add i64 %3229, -28
  %3255 = add i64 %3231, 31
  store i64 %3255, i64* %PC, align 8
  %3256 = inttoptr i64 %3254 to i32*
  %3257 = load i32, i32* %3256, align 4
  %3258 = add i32 %3257, 14
  %3259 = zext i32 %3258 to i64
  store i64 %3259, i64* %RCX, align 8, !tbaa !2428
  %3260 = icmp ugt i32 %3257, -15
  %3261 = zext i1 %3260 to i8
  store i8 %3261, i8* %17, align 1, !tbaa !2433
  %3262 = and i32 %3258, 255
  %3263 = tail call i32 @llvm.ctpop.i32(i32 %3262) #10
  %3264 = trunc i32 %3263 to i8
  %3265 = and i8 %3264, 1
  %3266 = xor i8 %3265, 1
  store i8 %3266, i8* %24, align 1, !tbaa !2447
  %3267 = xor i32 %3257, %3258
  %3268 = lshr i32 %3267, 4
  %3269 = trunc i32 %3268 to i8
  %3270 = and i8 %3269, 1
  store i8 %3270, i8* %30, align 1, !tbaa !2451
  %3271 = icmp eq i32 %3258, 0
  %3272 = zext i1 %3271 to i8
  store i8 %3272, i8* %33, align 1, !tbaa !2448
  %3273 = lshr i32 %3258, 31
  %3274 = trunc i32 %3273 to i8
  store i8 %3274, i8* %36, align 1, !tbaa !2449
  %3275 = lshr i32 %3257, 31
  %3276 = xor i32 %3273, %3275
  %3277 = add nuw nsw i32 %3276, %3273
  %3278 = icmp eq i32 %3277, 2
  %3279 = zext i1 %3278 to i8
  store i8 %3279, i8* %42, align 1, !tbaa !2450
  %3280 = sext i32 %3258 to i64
  store i64 %3280, i64* %RDX, align 8, !tbaa !2428
  %3281 = shl nsw i64 %3280, 3
  %3282 = add i64 %3281, %3253
  %3283 = add i64 %3231, 42
  store i64 %3283, i64* %PC, align 8
  %3284 = inttoptr i64 %3282 to double*
  store double %3249, double* %3284, align 8
  %3285 = load i64, i64* %RBP, align 8
  %3286 = add i64 %3285, -80
  %3287 = load i64, i64* %PC, align 8
  %3288 = add i64 %3287, 5
  store i64 %3288, i64* %PC, align 8
  %3289 = inttoptr i64 %3286 to double*
  %3290 = load double, double* %3289, align 8
  store double %3290, double* %68, align 1, !tbaa !2452
  store double 0.000000e+00, double* %70, align 1, !tbaa !2452
  %3291 = add i64 %3285, -104
  %3292 = add i64 %3287, 10
  store i64 %3292, i64* %PC, align 8
  %3293 = inttoptr i64 %3291 to double*
  %3294 = load double, double* %3293, align 8
  %3295 = fmul double %3290, %3294
  store double %3295, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3296 = add i64 %3285, -88
  %3297 = add i64 %3287, 15
  store i64 %3297, i64* %PC, align 8
  %3298 = inttoptr i64 %3296 to double*
  %3299 = load double, double* %3298, align 8
  store double %3299, double* %648, align 1, !tbaa !2452
  store double 0.000000e+00, double* %650, align 1, !tbaa !2452
  %3300 = add i64 %3285, -96
  %3301 = add i64 %3287, 20
  store i64 %3301, i64* %PC, align 8
  %3302 = inttoptr i64 %3300 to double*
  %3303 = load double, double* %3302, align 8
  %3304 = fmul double %3299, %3303
  store double %3304, double* %648, align 1, !tbaa !2452
  store i64 0, i64* %649, align 1, !tbaa !2452
  %3305 = fadd double %3295, %3304
  store double %3305, double* %68, align 1, !tbaa !2452
  store i64 0, i64* %69, align 1, !tbaa !2452
  %3306 = add i64 %3285, -16
  %3307 = add i64 %3287, 28
  store i64 %3307, i64* %PC, align 8
  %3308 = inttoptr i64 %3306 to i64*
  %3309 = load i64, i64* %3308, align 8
  store i64 %3309, i64* %RAX, align 8, !tbaa !2428
  %3310 = add i64 %3285, -28
  %3311 = add i64 %3287, 31
  store i64 %3311, i64* %PC, align 8
  %3312 = inttoptr i64 %3310 to i32*
  %3313 = load i32, i32* %3312, align 4
  %3314 = add i32 %3313, 15
  %3315 = zext i32 %3314 to i64
  store i64 %3315, i64* %RCX, align 8, !tbaa !2428
  %3316 = icmp ugt i32 %3313, -16
  %3317 = zext i1 %3316 to i8
  store i8 %3317, i8* %17, align 1, !tbaa !2433
  %3318 = and i32 %3314, 255
  %3319 = tail call i32 @llvm.ctpop.i32(i32 %3318) #10
  %3320 = trunc i32 %3319 to i8
  %3321 = and i8 %3320, 1
  %3322 = xor i8 %3321, 1
  store i8 %3322, i8* %24, align 1, !tbaa !2447
  %3323 = xor i32 %3313, %3314
  %3324 = lshr i32 %3323, 4
  %3325 = trunc i32 %3324 to i8
  %3326 = and i8 %3325, 1
  store i8 %3326, i8* %30, align 1, !tbaa !2451
  %3327 = icmp eq i32 %3314, 0
  %3328 = zext i1 %3327 to i8
  store i8 %3328, i8* %33, align 1, !tbaa !2448
  %3329 = lshr i32 %3314, 31
  %3330 = trunc i32 %3329 to i8
  store i8 %3330, i8* %36, align 1, !tbaa !2449
  %3331 = lshr i32 %3313, 31
  %3332 = xor i32 %3329, %3331
  %3333 = add nuw nsw i32 %3332, %3329
  %3334 = icmp eq i32 %3333, 2
  %3335 = zext i1 %3334 to i8
  store i8 %3335, i8* %42, align 1, !tbaa !2450
  %3336 = sext i32 %3314 to i64
  store i64 %3336, i64* %RDX, align 8, !tbaa !2428
  %3337 = shl nsw i64 %3336, 3
  %3338 = add i64 %3337, %3309
  %3339 = add i64 %3287, 42
  store i64 %3339, i64* %PC, align 8
  %3340 = inttoptr i64 %3338 to double*
  store double %3305, double* %3340, align 8
  %3341 = load i64, i64* %RBP, align 8
  %3342 = add i64 %3341, -28
  %3343 = load i64, i64* %PC, align 8
  %3344 = add i64 %3343, 3
  store i64 %3344, i64* %PC, align 8
  %3345 = inttoptr i64 %3342 to i32*
  %3346 = load i32, i32* %3345, align 4
  %3347 = add i32 %3346, 16
  %3348 = zext i32 %3347 to i64
  store i64 %3348, i64* %RAX, align 8, !tbaa !2428
  %3349 = icmp ugt i32 %3346, -17
  %3350 = zext i1 %3349 to i8
  store i8 %3350, i8* %17, align 1, !tbaa !2433
  %3351 = and i32 %3347, 255
  %3352 = tail call i32 @llvm.ctpop.i32(i32 %3351) #10
  %3353 = trunc i32 %3352 to i8
  %3354 = and i8 %3353, 1
  %3355 = xor i8 %3354, 1
  store i8 %3355, i8* %24, align 1, !tbaa !2447
  %3356 = xor i32 %3346, 16
  %3357 = xor i32 %3356, %3347
  %3358 = lshr i32 %3357, 4
  %3359 = trunc i32 %3358 to i8
  %3360 = and i8 %3359, 1
  store i8 %3360, i8* %30, align 1, !tbaa !2451
  %3361 = icmp eq i32 %3347, 0
  %3362 = zext i1 %3361 to i8
  store i8 %3362, i8* %33, align 1, !tbaa !2448
  %3363 = lshr i32 %3347, 31
  %3364 = trunc i32 %3363 to i8
  store i8 %3364, i8* %36, align 1, !tbaa !2449
  %3365 = lshr i32 %3346, 31
  %3366 = xor i32 %3363, %3365
  %3367 = add nuw nsw i32 %3366, %3363
  %3368 = icmp eq i32 %3367, 2
  %3369 = zext i1 %3368 to i8
  store i8 %3369, i8* %42, align 1, !tbaa !2450
  %3370 = add i64 %3343, 9
  store i64 %3370, i64* %PC, align 8
  store i32 %3347, i32* %3345, align 4
  %3371 = load i64, i64* %PC, align 8
  %3372 = add i64 %3371, -1815
  store i64 %3372, i64* %771, align 8, !tbaa !2428
  br label %block_402bd2

block_402bd2:                                     ; preds = %block_402bde, %block_402870
  %3373 = phi i64 [ %3372, %block_402bde ], [ %.pre, %block_402870 ]
  %3374 = load i64, i64* %RBP, align 8
  %3375 = add i64 %3374, -28
  %3376 = add i64 %3373, 3
  store i64 %3376, i64* %PC, align 8
  %3377 = inttoptr i64 %3375 to i32*
  %3378 = load i32, i32* %3377, align 4
  %3379 = zext i32 %3378 to i64
  store i64 %3379, i64* %RAX, align 8, !tbaa !2428
  %3380 = add i64 %3374, -4
  %3381 = add i64 %3373, 6
  store i64 %3381, i64* %PC, align 8
  %3382 = inttoptr i64 %3380 to i32*
  %3383 = load i32, i32* %3382, align 4
  %3384 = sub i32 %3378, %3383
  %3385 = icmp ult i32 %3378, %3383
  %3386 = zext i1 %3385 to i8
  store i8 %3386, i8* %17, align 1, !tbaa !2433
  %3387 = and i32 %3384, 255
  %3388 = tail call i32 @llvm.ctpop.i32(i32 %3387) #10
  %3389 = trunc i32 %3388 to i8
  %3390 = and i8 %3389, 1
  %3391 = xor i8 %3390, 1
  store i8 %3391, i8* %24, align 1, !tbaa !2447
  %3392 = xor i32 %3383, %3378
  %3393 = xor i32 %3392, %3384
  %3394 = lshr i32 %3393, 4
  %3395 = trunc i32 %3394 to i8
  %3396 = and i8 %3395, 1
  store i8 %3396, i8* %30, align 1, !tbaa !2451
  %3397 = icmp eq i32 %3384, 0
  %3398 = zext i1 %3397 to i8
  store i8 %3398, i8* %33, align 1, !tbaa !2448
  %3399 = lshr i32 %3384, 31
  %3400 = trunc i32 %3399 to i8
  store i8 %3400, i8* %36, align 1, !tbaa !2449
  %3401 = lshr i32 %3378, 31
  %3402 = lshr i32 %3383, 31
  %3403 = xor i32 %3402, %3401
  %3404 = xor i32 %3399, %3401
  %3405 = add nuw nsw i32 %3404, %3403
  %3406 = icmp eq i32 %3405, 2
  %3407 = zext i1 %3406 to i8
  store i8 %3407, i8* %42, align 1, !tbaa !2450
  %3408 = icmp ne i8 %3400, 0
  %3409 = xor i1 %3408, %3406
  %.v = select i1 %3409, i64 12, i64 1820
  %3410 = add i64 %3373, %.v
  store i64 %3410, i64* %771, align 8, !tbaa !2428
  br i1 %3409, label %block_402bde, label %block_4032ee

block_4032ee:                                     ; preds = %block_402bd2
  %3411 = load i64, i64* %RSP, align 8
  %3412 = add i64 %3411, 24
  store i64 %3412, i64* %RSP, align 8, !tbaa !2428
  %3413 = icmp ugt i64 %3411, -25
  %3414 = zext i1 %3413 to i8
  store i8 %3414, i8* %17, align 1, !tbaa !2433
  %3415 = trunc i64 %3412 to i32
  %3416 = and i32 %3415, 255
  %3417 = tail call i32 @llvm.ctpop.i32(i32 %3416) #10
  %3418 = trunc i32 %3417 to i8
  %3419 = and i8 %3418, 1
  %3420 = xor i8 %3419, 1
  store i8 %3420, i8* %24, align 1, !tbaa !2447
  %3421 = xor i64 %3411, 16
  %3422 = xor i64 %3421, %3412
  %3423 = lshr i64 %3422, 4
  %3424 = trunc i64 %3423 to i8
  %3425 = and i8 %3424, 1
  store i8 %3425, i8* %30, align 1, !tbaa !2451
  %3426 = icmp eq i64 %3412, 0
  %3427 = zext i1 %3426 to i8
  store i8 %3427, i8* %33, align 1, !tbaa !2448
  %3428 = lshr i64 %3412, 63
  %3429 = trunc i64 %3428 to i8
  store i8 %3429, i8* %36, align 1, !tbaa !2449
  %3430 = lshr i64 %3411, 63
  %3431 = xor i64 %3428, %3430
  %3432 = add nuw nsw i64 %3431, %3428
  %3433 = icmp eq i64 %3432, 2
  %3434 = zext i1 %3433 to i8
  store i8 %3434, i8* %42, align 1, !tbaa !2450
  %3435 = add i64 %3410, 5
  store i64 %3435, i64* %PC, align 8
  %3436 = add i64 %3411, 32
  %3437 = inttoptr i64 %3412 to i64*
  %3438 = load i64, i64* %3437, align 8
  store i64 %3438, i64* %RBP, align 8, !tbaa !2428
  store i64 %3436, i64* %9, align 8, !tbaa !2428
  %3439 = add i64 %3410, 6
  store i64 %3439, i64* %PC, align 8
  %3440 = inttoptr i64 %3436 to i64*
  %3441 = load i64, i64* %3440, align 8
  store i64 %3441, i64* %771, align 8, !tbaa !2428
  %3442 = add i64 %3411, 40
  store i64 %3442, i64* %9, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_400740__dl_relocate_static_pie(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400740:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = add i64 %1, 2
  store i64 %3, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = inttoptr i64 %6 to i64*
  %8 = load i64, i64* %7, align 8
  store i64 %8, i64* %4, align 8, !tbaa !2428
  %9 = add i64 %6, 8
  store i64 %9, i64* %5, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_404064__term_proc(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_404064:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = add i64 %3, -8
  %5 = icmp ult i64 %3, 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %10 = lshr i64 %4, 63
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %12 = lshr i64 %3, 63
  %13 = xor i64 %10, %12
  %14 = add nuw nsw i64 %13, %12
  %15 = icmp eq i64 %14, 2
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i64 %3, i64* %RSP, align 8, !tbaa !2428
  %18 = zext i1 %5 to i8
  store i8 %18, i8* %6, align 1, !tbaa !2433
  %19 = trunc i64 %3 to i32
  %20 = and i32 %19, 255
  %21 = tail call i32 @llvm.ctpop.i32(i32 %20) #10
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = xor i8 %23, 1
  store i8 %24, i8* %7, align 1, !tbaa !2447
  %25 = xor i64 %4, %3
  %26 = lshr i64 %25, 4
  %27 = trunc i64 %26 to i8
  %28 = and i8 %27, 1
  store i8 %28, i8* %8, align 1, !tbaa !2451
  %29 = icmp eq i64 %3, 0
  %30 = zext i1 %29 to i8
  store i8 %30, i8* %9, align 1, !tbaa !2448
  %31 = trunc i64 %12 to i8
  store i8 %31, i8* %11, align 1, !tbaa !2449
  store i8 %16, i8* %17, align 1, !tbaa !2450
  %32 = add i64 %1, 9
  store i64 %32, i64* %PC, align 8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %35 = inttoptr i64 %3 to i64*
  %36 = load i64, i64* %35, align 8
  store i64 %36, i64* %33, align 8, !tbaa !2428
  %37 = add i64 %3, 8
  store i64 %37, i64* %34, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_400780_register_tm_clones(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400780:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  store i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64* %RSI, align 8, !tbaa !2428
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 6
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  store i64 %7, i64* %5, align 8, !tbaa !2428
  %9 = load i64, i64* %RSI, align 8
  %10 = load i64, i64* %PC, align 8
  %11 = sub i64 %9, ptrtoint (%__bss_start_type* @__bss_start to i64)
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %18 = ashr i64 %11, 3
  %19 = lshr i64 %18, 63
  store i64 %19, i64* %RAX, align 8, !tbaa !2428
  %20 = add nsw i64 %19, %18
  %21 = trunc i64 %20 to i8
  %22 = and i8 %21, 1
  %23 = ashr i64 %20, 1
  store i64 %23, i64* %RSI, align 8, !tbaa !2428
  store i8 %22, i8* %12, align 1, !tbaa !2432
  %24 = trunc i64 %23 to i32
  %25 = and i32 %24, 255
  %26 = tail call i32 @llvm.ctpop.i32(i32 %25) #10
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = xor i8 %28, 1
  store i8 %29, i8* %13, align 1, !tbaa !2432
  store i8 0, i8* %14, align 1, !tbaa !2432
  %30 = icmp eq i64 %23, 0
  %31 = zext i1 %30 to i8
  store i8 %31, i8* %15, align 1, !tbaa !2432
  %32 = lshr i64 %23, 63
  %33 = trunc i64 %32 to i8
  store i8 %33, i8* %16, align 1, !tbaa !2432
  store i8 0, i8* %17, align 1, !tbaa !2432
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %.v = select i1 %30, i64 50, i64 29
  %35 = add i64 %10, %.v
  store i64 %35, i64* %34, align 8, !tbaa !2428
  br i1 %30, label %block_4007b8, label %block_4007a3

block_4007b8:                                     ; preds = %block_4007a3, %block_400780
  %36 = phi i64 [ %46, %block_4007a3 ], [ %35, %block_400780 ]
  %37 = add i64 %36, 1
  store i64 %37, i64* %PC, align 8
  %38 = load i64, i64* %5, align 8, !tbaa !2428
  %39 = add i64 %38, 8
  %40 = inttoptr i64 %38 to i64*
  %41 = load i64, i64* %40, align 8
  store i64 %41, i64* %RBP, align 8, !tbaa !2428
  store i64 %39, i64* %5, align 8, !tbaa !2428
  %42 = add i64 %36, 2
  store i64 %42, i64* %PC, align 8
  %43 = inttoptr i64 %39 to i64*
  %44 = load i64, i64* %43, align 8
  store i64 %44, i64* %34, align 8, !tbaa !2428
  %45 = add i64 %38, 16
  store i64 %45, i64* %5, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_4007a3:                                     ; preds = %block_400780
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %12, align 1, !tbaa !2433
  store i8 1, i8* %13, align 1, !tbaa !2447
  store i8 1, i8* %15, align 1, !tbaa !2448
  store i8 0, i8* %16, align 1, !tbaa !2449
  store i8 0, i8* %17, align 1, !tbaa !2450
  store i8 0, i8* %14, align 1, !tbaa !2451
  %46 = add i64 %35, 21
  store i64 %46, i64* %34, align 8, !tbaa !2428
  br label %block_4007b8
}

; Function Attrs: noinline
define %struct.Memory* @sub_400750_deregister_tm_clones(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400750:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  store i64 %7, i64* %5, align 8, !tbaa !2428
  %9 = load i64, i64* %PC, align 8
  store i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64* %RAX, align 8, !tbaa !2428
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 zext (i1 icmp ult (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)) to i8), i8* %10, align 1, !tbaa !2433
  %11 = tail call i32 @llvm.ctpop.i32(i32 and (i32 trunc (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)) to i32), i32 255)) #10
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1, !tbaa !2447
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 and (i8 trunc (i64 lshr (i64 xor (i64 xor (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295)), i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64))), i64 4) to i8), i8 1), i8* %16, align 1, !tbaa !2451
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 zext (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0) to i8), i8* %17, align 1, !tbaa !2448
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 trunc (i64 lshr (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 63) to i8), i8* %18, align 1, !tbaa !2449
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 zext (i1 icmp eq (i64 add (i64 xor (i64 lshr (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 63), i64 lshr (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 63)), i64 xor (i64 lshr (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 63), i64 lshr (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 63))), i64 2) to i8), i8* %19, align 1, !tbaa !2450
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %21 = add i64 %9, select (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), i64 39, i64 16)
  store i64 %21, i64* %20, align 8, !tbaa !2428
  br i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), label %block_400778, label %block_400761

block_400778:                                     ; preds = %block_400761, %block_400750
  %22 = phi i64 [ %29, %block_400761 ], [ %21, %block_400750 ]
  %23 = add i64 %22, 1
  store i64 %23, i64* %PC, align 8
  %24 = load i64, i64* %8, align 8
  store i64 %24, i64* %RBP, align 8, !tbaa !2428
  store i64 %6, i64* %5, align 8, !tbaa !2428
  %25 = add i64 %22, 2
  store i64 %25, i64* %PC, align 8
  %26 = inttoptr i64 %6 to i64*
  %27 = load i64, i64* %26, align 8
  store i64 %27, i64* %20, align 8, !tbaa !2428
  %28 = add i64 %6, 8
  store i64 %28, i64* %5, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_400761:                                     ; preds = %block_400750
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %10, align 1, !tbaa !2433
  store i8 1, i8* %15, align 1, !tbaa !2447
  store i8 1, i8* %17, align 1, !tbaa !2448
  store i8 0, i8* %18, align 1, !tbaa !2449
  store i8 0, i8* %19, align 1, !tbaa !2450
  store i8 0, i8* %16, align 1, !tbaa !2451
  %29 = add i64 %9, add (i64 select (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), i64 39, i64 16), i64 23)
  store i64 %29, i64* %20, align 8, !tbaa !2428
  br label %block_400778
}

; Function Attrs: noinline
define %struct.Memory* @sub_400800_main(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400800:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %RAX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3
  %10 = load i64, i64* %RBP, align 8
  %11 = add i64 %1, 1
  store i64 %11, i64* %PC, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %13 = load i64, i64* %12, align 8, !tbaa !2428
  %14 = add i64 %13, -8
  %15 = inttoptr i64 %14 to i64*
  store i64 %10, i64* %15, align 8
  %16 = load i64, i64* %PC, align 8
  store i64 %14, i64* %RBP, align 8, !tbaa !2428
  %17 = add i64 %13, -232
  store i64 %17, i64* %RSP, align 8, !tbaa !2428
  %18 = icmp ult i64 %14, 224
  %19 = zext i1 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %19, i8* %20, align 1, !tbaa !2433
  %21 = trunc i64 %17 to i32
  %22 = and i32 %21, 255
  %23 = tail call i32 @llvm.ctpop.i32(i32 %22) #10
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = xor i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %26, i8* %27, align 1, !tbaa !2447
  %28 = xor i64 %14, %17
  %29 = lshr i64 %28, 4
  %30 = trunc i64 %29 to i8
  %31 = and i8 %30, 1
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %31, i8* %32, align 1, !tbaa !2451
  %33 = icmp eq i64 %17, 0
  %34 = zext i1 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %34, i8* %35, align 1, !tbaa !2448
  %36 = lshr i64 %17, 63
  %37 = trunc i64 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %37, i8* %38, align 1, !tbaa !2449
  %39 = lshr i64 %14, 63
  %40 = xor i64 %36, %39
  %41 = add nuw nsw i64 %40, %39
  %42 = icmp eq i64 %41, 2
  %43 = zext i1 %42 to i8
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %43, i8* %44, align 1, !tbaa !2450
  store i64 16, i64* %RAX, align 8, !tbaa !2428
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  %45 = add i64 %13, -12
  %46 = add i64 %16, 24
  store i64 %46, i64* %PC, align 8
  %47 = inttoptr i64 %45 to i32*
  store i32 0, i32* %47, align 4
  %48 = load i64, i64* %RBP, align 8
  %49 = add i64 %48, -88
  %50 = load i64, i64* %PC, align 8
  %51 = add i64 %50, 8
  store i64 %51, i64* %PC, align 8
  %52 = inttoptr i64 %49 to i64*
  store i64 0, i64* %52, align 8
  %53 = load i64, i64* %RBP, align 8
  %54 = add i64 %53, -144
  %55 = load i64, i64* %RDI, align 8
  %56 = load i64, i64* %PC, align 8
  %57 = add i64 %56, 7
  store i64 %57, i64* %PC, align 8
  %58 = inttoptr i64 %54 to i64*
  store i64 %55, i64* %58, align 8
  %59 = load i64, i64* %PC, align 8
  %60 = add i64 %59, 1464
  %61 = add i64 %59, 5
  %62 = load i64, i64* %12, align 8, !tbaa !2428
  %63 = add i64 %62, -8
  %64 = inttoptr i64 %63 to i64*
  store i64 %61, i64* %64, align 8
  store i64 %63, i64* %12, align 8, !tbaa !2428
  %65 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %60, i64* %65, align 8, !tbaa !2428
  %66 = tail call %struct.Memory* @sub_400de0_get_time_renamed_(%struct.State* nonnull %0, i64 %60, %struct.Memory* %2)
  %67 = load i64, i64* %RBP, align 8
  %68 = add i64 %67, -64
  %69 = load i64, i64* %PC, align 8
  %70 = add i64 %69, 5
  store i64 %70, i64* %PC, align 8
  %71 = bitcast [32 x %union.VectorReg]* %6 to double*
  %72 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %73 = load i64, i64* %72, align 1
  %74 = inttoptr i64 %68 to i64*
  store i64 %73, i64* %74, align 8
  %75 = load i64, i64* %PC, align 8
  %76 = add i64 %75, 1454
  %77 = add i64 %75, 5
  %78 = load i64, i64* %12, align 8, !tbaa !2428
  %79 = add i64 %78, -8
  %80 = inttoptr i64 %79 to i64*
  store i64 %77, i64* %80, align 8
  store i64 %79, i64* %12, align 8, !tbaa !2428
  store i64 %76, i64* %65, align 8, !tbaa !2428
  %81 = tail call %struct.Memory* @sub_400de0_get_time_renamed_(%struct.State* nonnull %0, i64 %76, %struct.Memory* %66)
  %82 = load i64, i64* %RBP, align 8
  %83 = add i64 %82, -72
  %84 = load i64, i64* %PC, align 8
  %85 = add i64 %84, 5
  store i64 %85, i64* %PC, align 8
  %86 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %87 = load i64, i64* %86, align 1
  %88 = inttoptr i64 %83 to i64*
  store i64 %87, i64* %88, align 8
  %89 = bitcast [32 x %union.VectorReg]* %6 to i8*
  %90 = load i64, i64* %RBP, align 8
  %91 = add i64 %90, -72
  %92 = load i64, i64* %PC, align 8
  %93 = add i64 %92, 5
  store i64 %93, i64* %PC, align 8
  %94 = inttoptr i64 %91 to double*
  %95 = load double, double* %94, align 8
  %96 = bitcast [32 x %union.VectorReg]* %6 to double*
  store double %95, double* %96, align 1, !tbaa !2452
  %97 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %98 = bitcast i64* %97 to double*
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %99 = bitcast %union.VectorReg* %7 to i8*
  %100 = add i64 %90, -64
  %101 = add i64 %92, 10
  store i64 %101, i64* %PC, align 8
  %102 = inttoptr i64 %100 to double*
  %103 = load double, double* %102, align 8
  %104 = bitcast %union.VectorReg* %7 to double*
  store double %103, double* %104, align 1, !tbaa !2452
  %105 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %106 = bitcast i64* %105 to double*
  store double 0.000000e+00, double* %106, align 1, !tbaa !2452
  %107 = bitcast %union.VectorReg* %7 to double*
  %108 = fsub double %95, %103
  %109 = add i64 %90, -80
  %110 = add i64 %92, 19
  store i64 %110, i64* %PC, align 8
  %111 = inttoptr i64 %109 to double*
  store double %108, double* %111, align 8
  %112 = load i64, i64* %PC, align 8
  %113 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 24) to i64*), align 8
  %114 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %113, i64* %114, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %115 = add i64 %112, -335
  %116 = add i64 %112, 13
  %117 = load i64, i64* %12, align 8, !tbaa !2428
  %118 = add i64 %117, -8
  %119 = inttoptr i64 %118 to i64*
  store i64 %116, i64* %119, align 8
  store i64 %118, i64* %12, align 8, !tbaa !2428
  store i64 %115, i64* %PC, align 8, !alias.scope !2477, !noalias !2480
  %120 = bitcast [32 x %union.VectorReg]* %6 to double*
  %121 = load double, double* %120, align 8, !alias.scope !2477, !noalias !2480
  %122 = inttoptr i64 %118 to i64*
  %123 = load i64, i64* %122, align 8
  store i64 %117, i64* %RSP, align 8, !alias.scope !2477, !noalias !2480
  %124 = tail call double @sqrt(double %121)
  %.repack = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 0, i64* %.repack, align 8
  %125 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  store i64 0, i64* %125, align 8
  %126 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %126, align 8
  %127 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %127, align 8
  %128 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 32) to double*), align 16
  %129 = bitcast i64* %97 to <2 x i32>*
  %130 = load <2 x i32>, <2 x i32>* %129, align 1
  %131 = fmul double %124, %128
  store double %131, double* %96, align 1, !tbaa !2452
  %132 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 40) to double*), align 8
  store double %132, double* %104, align 1, !tbaa !2452
  store double 0.000000e+00, double* %106, align 1, !tbaa !2452
  %133 = bitcast %union.VectorReg* %8 to i8*
  %134 = bitcast double %131 to <2 x i32>
  %135 = extractelement <2 x i32> %134, i32 0
  %136 = bitcast %union.VectorReg* %8 to i32*
  store i32 %135, i32* %136, align 1, !tbaa !2475
  %137 = extractelement <2 x i32> %134, i32 1
  %138 = getelementptr inbounds i8, i8* %133, i64 4
  %139 = bitcast i8* %138 to i32*
  store i32 %137, i32* %139, align 1, !tbaa !2475
  %140 = extractelement <2 x i32> %130, i32 0
  %141 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %142 = bitcast i64* %141 to i32*
  store i32 %140, i32* %142, align 1, !tbaa !2475
  %143 = extractelement <2 x i32> %130, i32 1
  %144 = getelementptr inbounds i8, i8* %133, i64 12
  %145 = bitcast i8* %144 to i32*
  store i32 %143, i32* %145, align 1, !tbaa !2475
  %146 = bitcast %union.VectorReg* %8 to double*
  %147 = load double, double* %146, align 1
  %148 = fsub double %147, %132
  store double %148, double* %146, align 1, !tbaa !2452
  %149 = bitcast %union.VectorReg* %8 to double*
  %150 = tail call double @llvm.trunc.f64(double %148) #10
  %151 = tail call double @llvm.fabs.f64(double %150) #10
  %152 = fcmp ogt double %151, 0x43E0000000000000
  %153 = fptosi double %150 to i64
  %.op = xor i64 %153, -9223372036854775808
  %154 = select i1 %152, i64 0, i64 %.op
  store i64 %154, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %20, align 1, !tbaa !2433
  %155 = trunc i64 %154 to i32
  %156 = and i32 %155, 255
  %157 = tail call i32 @llvm.ctpop.i32(i32 %156) #10
  %158 = trunc i32 %157 to i8
  %159 = and i8 %158, 1
  %160 = xor i8 %159, 1
  store i8 %160, i8* %27, align 1, !tbaa !2447
  %161 = icmp eq i64 %154, 0
  %162 = zext i1 %161 to i8
  store i8 %162, i8* %35, align 1, !tbaa !2448
  %163 = lshr i64 %154, 63
  %164 = trunc i64 %163 to i8
  store i8 %164, i8* %38, align 1, !tbaa !2449
  store i8 0, i8* %44, align 1, !tbaa !2450
  store i8 0, i8* %32, align 1, !tbaa !2451
  %165 = tail call double @llvm.trunc.f64(double %131) #10
  %166 = tail call double @llvm.fabs.f64(double %165) #10
  %167 = fcmp ogt double %166, 0x43E0000000000000
  %168 = fptosi double %165 to i64
  %169 = select i1 %167, i64 -9223372036854775808, i64 %168
  store i64 %169, i64* %RCX, align 8, !tbaa !2428
  %170 = add i64 %123, 54
  store i64 %170, i64* %PC, align 8
  %171 = fcmp uno double %131, %132
  br i1 %171, label %172, label %182

; <label>:172:                                    ; preds = %block_400800
  %173 = fadd double %131, %132
  %174 = bitcast double %173 to i64
  %175 = and i64 %174, 9221120237041090560
  %176 = icmp eq i64 %175, 9218868437227405312
  %177 = and i64 %174, 2251799813685247
  %178 = icmp ne i64 %177, 0
  %179 = and i1 %176, %178
  br i1 %179, label %180, label %188

; <label>:180:                                    ; preds = %172
  %181 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %170, %struct.Memory* %81) #11
  %.pre = load i64, i64* %RCX, align 8
  %.pre1 = load i64, i64* %PC, align 8
  %.pre2 = load i8, i8* %20, align 1, !tbaa !2433
  %.pre3 = load i64, i64* %RDI, align 8, !tbaa !2428
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3

; <label>:182:                                    ; preds = %block_400800
  %183 = fcmp ogt double %131, %132
  br i1 %183, label %188, label %184

; <label>:184:                                    ; preds = %182
  %185 = fcmp olt double %131, %132
  br i1 %185, label %188, label %186

; <label>:186:                                    ; preds = %184
  %187 = fcmp oeq double %131, %132
  br i1 %187, label %188, label %192

; <label>:188:                                    ; preds = %186, %184, %182, %172
  %189 = phi i8 [ 0, %182 ], [ 0, %184 ], [ 1, %186 ], [ 1, %172 ]
  %190 = phi i8 [ 0, %182 ], [ 0, %184 ], [ 0, %186 ], [ 1, %172 ]
  %191 = phi i8 [ 0, %182 ], [ 1, %184 ], [ 0, %186 ], [ 1, %172 ]
  store i8 %189, i8* %35, align 1, !tbaa !2432
  store i8 %190, i8* %27, align 1, !tbaa !2432
  store i8 %191, i8* %20, align 1, !tbaa !2432
  br label %192

; <label>:192:                                    ; preds = %188, %186
  %193 = phi i8 [ %191, %188 ], [ 0, %186 ]
  store i8 0, i8* %44, align 1, !tbaa !2432
  store i8 0, i8* %38, align 1, !tbaa !2432
  store i8 0, i8* %32, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3: ; preds = %192, %180
  %194 = phi i64 [ %.pre3, %180 ], [ %154, %192 ]
  %195 = phi i8 [ %.pre2, %180 ], [ %193, %192 ]
  %196 = phi i64 [ %.pre1, %180 ], [ %170, %192 ]
  %197 = phi i64 [ %.pre, %180 ], [ %169, %192 ]
  %198 = phi %struct.Memory* [ %181, %180 ], [ %81, %192 ]
  %199 = icmp ne i8 %195, 0
  %200 = select i1 %199, i64 %197, i64 %194
  store i64 %200, i64* %RDI, align 8, !tbaa !2428
  %201 = load i64, i64* %RBP, align 8
  %202 = add i64 %201, -144
  %203 = add i64 %196, 11
  store i64 %203, i64* %PC, align 8
  %204 = inttoptr i64 %202 to i64*
  %205 = load i64, i64* %204, align 8
  store i64 %205, i64* %RCX, align 8, !tbaa !2428
  %206 = add i64 %201, -152
  %207 = add i64 %196, 18
  store i64 %207, i64* %PC, align 8
  %208 = inttoptr i64 %206 to i64*
  store i64 %200, i64* %208, align 8
  %209 = load i64, i64* %RCX, align 8
  %210 = load i64, i64* %PC, align 8
  store i64 %209, i64* %RDI, align 8, !tbaa !2428
  %211 = load i64, i64* %RBP, align 8
  %212 = add i64 %211, -152
  %213 = add i64 %210, 10
  store i64 %213, i64* %PC, align 8
  %214 = inttoptr i64 %212 to i64*
  %215 = load i64, i64* %214, align 8
  store i64 %215, i64* %RSI, align 8, !tbaa !2428
  %216 = add i64 %210, -452
  %217 = add i64 %210, 15
  %218 = load i64, i64* %12, align 8, !tbaa !2428
  %219 = add i64 %218, -8
  %220 = inttoptr i64 %219 to i64*
  store i64 %217, i64* %220, align 8
  store i64 %219, i64* %12, align 8, !tbaa !2428
  store i64 %216, i64* %65, align 8, !tbaa !2428
  %221 = tail call fastcc %struct.Memory* @ext_4006e0_memalign(%struct.State* nonnull %0, %struct.Memory* %198)
  %222 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 20480, i64* %RDX, align 8, !tbaa !2428
  store i64 20480, i64* %RSI, align 8, !tbaa !2428
  %223 = load i64, i64* %RBP, align 8
  %224 = add i64 %223, -24
  %225 = load i64, i64* %RAX, align 8
  %226 = add i64 %222, 18
  store i64 %226, i64* %PC, align 8
  %227 = inttoptr i64 %224 to i64*
  store i64 %225, i64* %227, align 8
  %228 = load i64, i64* %PC, align 8
  %229 = add i64 %228, -485
  %230 = add i64 %228, 5
  %231 = load i64, i64* %12, align 8, !tbaa !2428
  %232 = add i64 %231, -8
  %233 = inttoptr i64 %232 to i64*
  store i64 %230, i64* %233, align 8
  store i64 %232, i64* %12, align 8, !tbaa !2428
  store i64 %229, i64* %65, align 8, !tbaa !2428
  %234 = tail call fastcc %struct.Memory* @ext_4006e0_memalign(%struct.State* nonnull %0, %struct.Memory* %221)
  %235 = load i64, i64* %PC, align 8
  store i64 512, i64* %RDI, align 8, !tbaa !2428
  %236 = load i64, i64* %RBP, align 8
  %237 = add i64 %236, -56
  %238 = load i64, i64* %RAX, align 8
  %239 = add i64 %235, 9
  store i64 %239, i64* %PC, align 8
  %240 = inttoptr i64 %237 to i64*
  store i64 %238, i64* %240, align 8
  %241 = load i64, i64* %RBP, align 8
  %242 = add i64 %241, -24
  %243 = load i64, i64* %PC, align 8
  %244 = add i64 %243, 4
  store i64 %244, i64* %PC, align 8
  %245 = inttoptr i64 %242 to i64*
  %246 = load i64, i64* %245, align 8
  store i64 %246, i64* %RSI, align 8, !tbaa !2428
  %247 = add i64 %241, -56
  %248 = add i64 %243, 8
  store i64 %248, i64* %PC, align 8
  %249 = inttoptr i64 %247 to i64*
  %250 = load i64, i64* %249, align 8
  store i64 %250, i64* %RDX, align 8, !tbaa !2428
  %251 = add i64 %243, 1373
  %252 = add i64 %243, 13
  %253 = load i64, i64* %12, align 8, !tbaa !2428
  %254 = add i64 %253, -8
  %255 = inttoptr i64 %254 to i64*
  store i64 %252, i64* %255, align 8
  store i64 %254, i64* %12, align 8, !tbaa !2428
  store i64 %251, i64* %65, align 8, !tbaa !2428
  %256 = tail call %struct.Memory* @sub_400e30_makewt_renamed_(%struct.State* nonnull %0, i64 %251, %struct.Memory* %234)
  %257 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  %258 = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  store i64 16384, i64* %258, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %259 = add i64 %257, -512
  %260 = add i64 %257, 19
  %261 = load i64, i64* %12, align 8, !tbaa !2428
  %262 = add i64 %261, -8
  %263 = inttoptr i64 %262 to i64*
  store i64 %260, i64* %263, align 8
  store i64 %262, i64* %12, align 8, !tbaa !2428
  store i64 %259, i64* %65, align 8, !tbaa !2428
  %264 = tail call fastcc %struct.Memory* @ext_4006e0_memalign(%struct.State* nonnull %0, %struct.Memory* %256)
  %265 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 16384, i64* %258, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %266 = load i64, i64* %RBP, align 8
  %267 = add i64 %266, -32
  %268 = load i64, i64* %RAX, align 8
  %269 = add i64 %265, 22
  store i64 %269, i64* %PC, align 8
  %270 = inttoptr i64 %267 to i64*
  store i64 %268, i64* %270, align 8
  %271 = load i64, i64* %PC, align 8
  %272 = add i64 %271, -553
  %273 = add i64 %271, 5
  %274 = load i64, i64* %12, align 8, !tbaa !2428
  %275 = add i64 %274, -8
  %276 = inttoptr i64 %275 to i64*
  store i64 %273, i64* %276, align 8
  store i64 %275, i64* %12, align 8, !tbaa !2428
  store i64 %272, i64* %65, align 8, !tbaa !2428
  %277 = tail call fastcc %struct.Memory* @ext_4006e0_memalign(%struct.State* nonnull %0, %struct.Memory* %264)
  %278 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 16384, i64* %258, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %279 = load i64, i64* %RBP, align 8
  %280 = add i64 %279, -40
  %281 = load i64, i64* %RAX, align 8
  %282 = add i64 %278, 22
  store i64 %282, i64* %PC, align 8
  %283 = inttoptr i64 %280 to i64*
  store i64 %281, i64* %283, align 8
  %284 = load i64, i64* %PC, align 8
  %285 = add i64 %284, -580
  %286 = add i64 %284, 5
  %287 = load i64, i64* %12, align 8, !tbaa !2428
  %288 = add i64 %287, -8
  %289 = inttoptr i64 %288 to i64*
  store i64 %286, i64* %289, align 8
  store i64 %288, i64* %12, align 8, !tbaa !2428
  store i64 %285, i64* %65, align 8, !tbaa !2428
  %290 = tail call fastcc %struct.Memory* @ext_4006e0_memalign(%struct.State* nonnull %0, %struct.Memory* %277)
  %291 = load i64, i64* %PC, align 8
  store i64 0, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %20, align 1, !tbaa !2433
  store i8 1, i8* %27, align 1, !tbaa !2447
  store i8 1, i8* %35, align 1, !tbaa !2448
  store i8 0, i8* %38, align 1, !tbaa !2449
  store i8 0, i8* %44, align 1, !tbaa !2450
  store i8 0, i8* %32, align 1, !tbaa !2451
  store i64 2047, i64* %RSI, align 8, !tbaa !2428
  %292 = load i64, i64* %RBP, align 8
  %293 = add i64 %292, -48
  %294 = load i64, i64* %RAX, align 8
  %295 = add i64 %291, 11
  store i64 %295, i64* %PC, align 8
  %296 = inttoptr i64 %293 to i64*
  store i64 %294, i64* %296, align 8
  %297 = load i64, i64* %RBP, align 8
  %298 = add i64 %297, -32
  %299 = load i64, i64* %PC, align 8
  %300 = add i64 %299, 4
  store i64 %300, i64* %PC, align 8
  %301 = inttoptr i64 %298 to i64*
  %302 = load i64, i64* %301, align 8
  store i64 %302, i64* %RDX, align 8, !tbaa !2428
  %303 = add i64 %299, 1660
  %304 = add i64 %299, 9
  %305 = load i64, i64* %12, align 8, !tbaa !2428
  %306 = add i64 %305, -8
  %307 = inttoptr i64 %306 to i64*
  store i64 %304, i64* %307, align 8
  store i64 %306, i64* %12, align 8, !tbaa !2428
  store i64 %303, i64* %65, align 8, !tbaa !2428
  %308 = tail call %struct.Memory* @sub_400fb0_putdata_renamed_(%struct.State* nonnull %0, i64 %303, %struct.Memory* %290)
  %309 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  %310 = load i64, i64* %RBP, align 8
  %311 = add i64 %310, -32
  %312 = add i64 %309, 14
  store i64 %312, i64* %PC, align 8
  %313 = inttoptr i64 %311 to i64*
  %314 = load i64, i64* %313, align 8
  store i64 %314, i64* %RDX, align 8, !tbaa !2428
  %315 = add i64 %310, -24
  %316 = add i64 %309, 18
  store i64 %316, i64* %PC, align 8
  %317 = inttoptr i64 %315 to i64*
  %318 = load i64, i64* %317, align 8
  store i64 %318, i64* %RCX, align 8, !tbaa !2428
  %319 = add i64 %310, -56
  %320 = add i64 %309, 22
  store i64 %320, i64* %PC, align 8
  %321 = inttoptr i64 %319 to i64*
  %322 = load i64, i64* %321, align 8
  store i64 %322, i64* %R8, align 8, !tbaa !2428
  %323 = add i64 %309, 1779
  %324 = add i64 %309, 27
  %325 = load i64, i64* %12, align 8, !tbaa !2428
  %326 = add i64 %325, -8
  %327 = inttoptr i64 %326 to i64*
  store i64 %324, i64* %327, align 8
  store i64 %326, i64* %12, align 8, !tbaa !2428
  store i64 %323, i64* %65, align 8, !tbaa !2428
  %328 = tail call %struct.Memory* @sub_401030_cdft_renamed_(%struct.State* nonnull %0, i64 %323, %struct.Memory* %308)
  %329 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 4294967295, i64* %RSI, align 8, !tbaa !2428
  %330 = load i64, i64* %RBP, align 8
  %331 = add i64 %330, -32
  %332 = add i64 %329, 14
  store i64 %332, i64* %PC, align 8
  %333 = inttoptr i64 %331 to i64*
  %334 = load i64, i64* %333, align 8
  store i64 %334, i64* %RDX, align 8, !tbaa !2428
  %335 = add i64 %330, -24
  %336 = add i64 %329, 18
  store i64 %336, i64* %PC, align 8
  %337 = inttoptr i64 %335 to i64*
  %338 = load i64, i64* %337, align 8
  store i64 %338, i64* %RCX, align 8, !tbaa !2428
  %339 = add i64 %330, -56
  %340 = add i64 %329, 22
  store i64 %340, i64* %PC, align 8
  %341 = inttoptr i64 %339 to i64*
  %342 = load i64, i64* %341, align 8
  store i64 %342, i64* %R8, align 8, !tbaa !2428
  %343 = add i64 %329, 1752
  %344 = add i64 %329, 27
  %345 = load i64, i64* %12, align 8, !tbaa !2428
  %346 = add i64 %345, -8
  %347 = inttoptr i64 %346 to i64*
  store i64 %344, i64* %347, align 8
  store i64 %346, i64* %12, align 8, !tbaa !2428
  store i64 %343, i64* %65, align 8, !tbaa !2428
  %348 = tail call %struct.Memory* @sub_401030_cdft_renamed_(%struct.State* nonnull %0, i64 %343, %struct.Memory* %328)
  %349 = load i64, i64* %PC, align 8
  store i64 0, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %20, align 1, !tbaa !2433
  store i8 1, i8* %27, align 1, !tbaa !2447
  store i8 1, i8* %35, align 1, !tbaa !2448
  store i8 0, i8* %38, align 1, !tbaa !2449
  store i8 0, i8* %44, align 1, !tbaa !2450
  store i8 0, i8* %32, align 1, !tbaa !2451
  store i64 2047, i64* %RSI, align 8, !tbaa !2428
  %350 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 16) to i64*), align 16
  %351 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %350, i64* %351, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %352 = load i64, i64* %RBP, align 8
  %353 = add i64 %352, -32
  %354 = add i64 %349, 19
  store i64 %354, i64* %PC, align 8
  %355 = inttoptr i64 %353 to i64*
  %356 = load i64, i64* %355, align 8
  store i64 %356, i64* %RDX, align 8, !tbaa !2428
  %357 = add i64 %349, 1885
  %358 = add i64 %349, 24
  %359 = load i64, i64* %12, align 8, !tbaa !2428
  %360 = add i64 %359, -8
  %361 = inttoptr i64 %360 to i64*
  store i64 %358, i64* %361, align 8
  store i64 %360, i64* %12, align 8, !tbaa !2428
  store i64 %357, i64* %65, align 8, !tbaa !2428
  %362 = tail call %struct.Memory* @sub_4010d0_errorcheck_renamed_(%struct.State* nonnull %0, i64 %357, %struct.Memory* %348)
  %363 = load i64, i64* %PC, align 8
  %364 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 8) to i64*), align 8
  %365 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %7, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %364, i64* %365, align 1, !tbaa !2452
  store double 0.000000e+00, double* %106, align 1, !tbaa !2452
  %366 = load i64, i64* %RBP, align 8
  %367 = add i64 %366, -96
  %368 = add i64 %363, 13
  store i64 %368, i64* %PC, align 8
  %369 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %370 = load i64, i64* %369, align 1
  %371 = inttoptr i64 %367 to i64*
  store i64 %370, i64* %371, align 8
  %372 = load i64, i64* %RBP, align 8
  %373 = add i64 %372, -96
  %374 = load i64, i64* %PC, align 8
  %375 = add i64 %374, 5
  store i64 %375, i64* %PC, align 8
  %376 = inttoptr i64 %373 to i64*
  %377 = load i64, i64* %376, align 8
  %378 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 96) to i32*), align 16
  %379 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 100) to i32*), align 4
  %380 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 104) to i32*), align 8
  %381 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 108) to i32*), align 4
  %382 = bitcast %union.VectorReg* %8 to i32*
  store i32 %378, i32* %382, align 1, !tbaa !2475
  %383 = bitcast i8* %138 to i32*
  store i32 %379, i32* %383, align 1, !tbaa !2475
  %384 = bitcast i64* %141 to i32*
  store i32 %380, i32* %384, align 1, !tbaa !2475
  %385 = bitcast i8* %144 to i32*
  store i32 %381, i32* %385, align 1, !tbaa !2475
  %386 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %387 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %8, i64 0, i32 0, i32 0, i32 0, i64 0
  %388 = load i64, i64* %387, align 1
  %389 = and i64 %388, %377
  %390 = trunc i64 %389 to i32
  %391 = lshr i64 %389, 32
  %392 = trunc i64 %391 to i32
  %393 = bitcast [32 x %union.VectorReg]* %6 to i32*
  store i32 %390, i32* %393, align 1, !tbaa !2459
  %394 = getelementptr inbounds i8, i8* %89, i64 4
  %395 = bitcast i8* %394 to i32*
  store i32 %392, i32* %395, align 1, !tbaa !2459
  %396 = bitcast i64* %97 to i32*
  store i32 0, i32* %396, align 1, !tbaa !2459
  %397 = getelementptr inbounds i8, i8* %89, i64 12
  %398 = bitcast i8* %397 to i32*
  store i32 0, i32* %398, align 1, !tbaa !2459
  %399 = add i64 %374, 20
  store i64 %399, i64* %PC, align 8
  %400 = load double, double* %71, align 1
  %401 = load double, double* %107, align 1
  %402 = fcmp uno double %400, %401
  br i1 %402, label %403, label %413

; <label>:403:                                    ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3
  %404 = fadd double %400, %401
  %405 = bitcast double %404 to i64
  %406 = and i64 %405, 9221120237041090560
  %407 = icmp eq i64 %406, 9218868437227405312
  %408 = and i64 %405, 2251799813685247
  %409 = icmp ne i64 %408, 0
  %410 = and i1 %407, %409
  br i1 %410, label %411, label %419

; <label>:411:                                    ; preds = %403
  %412 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %399, %struct.Memory* %362) #11
  %.pre4 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2

; <label>:413:                                    ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3
  %414 = fcmp ogt double %400, %401
  br i1 %414, label %419, label %415

; <label>:415:                                    ; preds = %413
  %416 = fcmp olt double %400, %401
  br i1 %416, label %419, label %417

; <label>:417:                                    ; preds = %415
  %418 = fcmp oeq double %400, %401
  br i1 %418, label %419, label %423

; <label>:419:                                    ; preds = %417, %415, %413, %403
  %420 = phi i8 [ 0, %413 ], [ 0, %415 ], [ 1, %417 ], [ 1, %403 ]
  %421 = phi i8 [ 0, %413 ], [ 0, %415 ], [ 0, %417 ], [ 1, %403 ]
  %422 = phi i8 [ 0, %413 ], [ 1, %415 ], [ 0, %417 ], [ 1, %403 ]
  store i8 %420, i8* %35, align 1, !tbaa !2432
  store i8 %421, i8* %27, align 1, !tbaa !2432
  store i8 %422, i8* %20, align 1, !tbaa !2432
  br label %423

; <label>:423:                                    ; preds = %419, %417
  store i8 0, i8* %44, align 1, !tbaa !2432
  store i8 0, i8* %38, align 1, !tbaa !2432
  store i8 0, i8* %32, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2: ; preds = %423, %411
  %424 = phi i64 [ %.pre4, %411 ], [ %399, %423 ]
  %425 = phi %struct.Memory* [ %412, %411 ], [ %362, %423 ]
  %426 = load i8, i8* %20, align 1, !tbaa !2433
  %427 = load i8, i8* %35, align 1, !tbaa !2448
  %428 = or i8 %427, %426
  %429 = icmp ne i8 %428, 0
  %.v = select i1 %429, i64 39, i64 6
  %430 = add i64 %424, %.v
  store i64 %430, i64* %65, align 8, !tbaa !2428
  br i1 %429, label %block_4009d3, label %block_4009b2

block_400c14:                                     ; preds = %block_400b37
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 4294967295, i64* %RSI, align 8, !tbaa !2428
  %431 = add i64 %1156, -40
  %432 = add i64 %1184, 14
  store i64 %432, i64* %PC, align 8
  %433 = inttoptr i64 %431 to i64*
  %434 = load i64, i64* %433, align 8
  store i64 %434, i64* %RDX, align 8, !tbaa !2428
  %435 = add i64 %1156, -24
  %436 = add i64 %1184, 18
  store i64 %436, i64* %PC, align 8
  %437 = inttoptr i64 %435 to i64*
  %438 = load i64, i64* %437, align 8
  store i64 %438, i64* %RCX, align 8, !tbaa !2428
  %439 = add i64 %1156, -56
  %440 = add i64 %1184, 22
  store i64 %440, i64* %PC, align 8
  %441 = inttoptr i64 %439 to i64*
  %442 = load i64, i64* %441, align 8
  store i64 %442, i64* %R8, align 8, !tbaa !2428
  %443 = add i64 %1184, 1052
  %444 = add i64 %1184, 27
  %445 = load i64, i64* %12, align 8, !tbaa !2428
  %446 = add i64 %445, -8
  %447 = inttoptr i64 %446 to i64*
  store i64 %444, i64* %447, align 8
  store i64 %446, i64* %12, align 8, !tbaa !2428
  store i64 %443, i64* %65, align 8, !tbaa !2428
  %448 = tail call %struct.Memory* @sub_401030_cdft_renamed_(%struct.State* nonnull %0, i64 %443, %struct.Memory* %537)
  %449 = load i64, i64* %RBP, align 8
  %450 = add i64 %449, -8
  %451 = load i64, i64* %PC, align 8
  %452 = add i64 %451, 3
  store i64 %452, i64* %PC, align 8
  %453 = inttoptr i64 %450 to i32*
  %454 = load i32, i32* %453, align 4
  %455 = add i32 %454, 1
  %456 = zext i32 %455 to i64
  store i64 %456, i64* %RAX, align 8, !tbaa !2428
  %457 = icmp eq i32 %454, -1
  %458 = icmp eq i32 %455, 0
  %459 = or i1 %457, %458
  %460 = zext i1 %459 to i8
  store i8 %460, i8* %20, align 1, !tbaa !2433
  %461 = and i32 %455, 255
  %462 = tail call i32 @llvm.ctpop.i32(i32 %461) #10
  %463 = trunc i32 %462 to i8
  %464 = and i8 %463, 1
  %465 = xor i8 %464, 1
  store i8 %465, i8* %27, align 1, !tbaa !2447
  %466 = xor i32 %454, %455
  %467 = lshr i32 %466, 4
  %468 = trunc i32 %467 to i8
  %469 = and i8 %468, 1
  store i8 %469, i8* %32, align 1, !tbaa !2451
  %470 = icmp eq i32 %455, 0
  %471 = zext i1 %470 to i8
  store i8 %471, i8* %35, align 1, !tbaa !2448
  %472 = lshr i32 %455, 31
  %473 = trunc i32 %472 to i8
  store i8 %473, i8* %38, align 1, !tbaa !2449
  %474 = lshr i32 %454, 31
  %475 = xor i32 %472, %474
  %476 = add nuw nsw i32 %475, %472
  %477 = icmp eq i32 %476, 2
  %478 = zext i1 %477 to i8
  store i8 %478, i8* %44, align 1, !tbaa !2450
  %479 = add i64 %451, 9
  store i64 %479, i64* %PC, align 8
  store i32 %455, i32* %453, align 4
  %480 = load i64, i64* %PC, align 8
  %481 = add i64 %480, -354
  store i64 %481, i64* %65, align 8, !tbaa !2428
  br label %block_400ad6

block_400ae3:                                     ; preds = %block_400ad6
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RAX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %482 = add i64 %620, -40
  %483 = add i64 %649, 21
  store i64 %483, i64* %PC, align 8
  %484 = inttoptr i64 %482 to i64*
  %485 = load i64, i64* %484, align 8
  store i64 %485, i64* %RCX, align 8, !tbaa !2428
  %486 = add i64 %620, -48
  %487 = add i64 %649, 25
  store i64 %487, i64* %PC, align 8
  %488 = inttoptr i64 %486 to i64*
  %489 = load i64, i64* %488, align 8
  store i64 %489, i64* %R8, align 8, !tbaa !2428
  %490 = add i64 %620, -176
  %491 = add i64 %649, 31
  store i64 %491, i64* %PC, align 8
  %492 = inttoptr i64 %490 to i32*
  store i32 2048, i32* %492, align 4
  %493 = load i64, i64* %RCX, align 8
  %494 = load i64, i64* %PC, align 8
  store i64 %493, i64* %RDI, align 8, !tbaa !2428
  %495 = load i64, i64* %RBP, align 8
  %496 = add i64 %495, -180
  %497 = load i32, i32* %ESI, align 4
  %498 = add i64 %494, 9
  store i64 %498, i64* %PC, align 8
  %499 = inttoptr i64 %496 to i32*
  store i32 %497, i32* %499, align 4
  %500 = load i64, i64* %R8, align 8
  %501 = load i64, i64* %PC, align 8
  store i64 %500, i64* %RSI, align 8, !tbaa !2428
  %502 = add i64 %501, -1083
  %503 = add i64 %501, 8
  %504 = load i64, i64* %12, align 8, !tbaa !2428
  %505 = add i64 %504, -8
  %506 = inttoptr i64 %505 to i64*
  store i64 %503, i64* %506, align 8
  store i64 %505, i64* %12, align 8, !tbaa !2428
  store i64 %502, i64* %65, align 8, !tbaa !2428
  %507 = tail call fastcc %struct.Memory* @ext_605128_memcpy(%struct.State* nonnull %0, %struct.Memory* %MEMORY.0)
  %508 = load i64, i64* %RBP, align 8
  %509 = add i64 %508, -40
  %510 = load i64, i64* %PC, align 8
  %511 = add i64 %510, 4
  store i64 %511, i64* %PC, align 8
  %512 = inttoptr i64 %509 to i64*
  %513 = load i64, i64* %512, align 8
  store i64 %513, i64* %RDX, align 8, !tbaa !2428
  %514 = add i64 %508, -24
  %515 = add i64 %510, 8
  store i64 %515, i64* %PC, align 8
  %516 = inttoptr i64 %514 to i64*
  %517 = load i64, i64* %516, align 8
  store i64 %517, i64* %RCX, align 8, !tbaa !2428
  %518 = add i64 %508, -56
  %519 = add i64 %510, 12
  store i64 %519, i64* %PC, align 8
  %520 = inttoptr i64 %518 to i64*
  %521 = load i64, i64* %520, align 8
  store i64 %521, i64* %R8, align 8, !tbaa !2428
  %522 = add i64 %508, -176
  %523 = add i64 %510, 18
  store i64 %523, i64* %PC, align 8
  %524 = inttoptr i64 %522 to i32*
  %525 = load i32, i32* %524, align 4
  %526 = zext i32 %525 to i64
  store i64 %526, i64* %RDI, align 8, !tbaa !2428
  %527 = add i64 %508, -180
  %528 = add i64 %510, 24
  store i64 %528, i64* %PC, align 8
  %529 = inttoptr i64 %527 to i32*
  %530 = load i32, i32* %529, align 4
  %531 = zext i32 %530 to i64
  store i64 %531, i64* %RSI, align 8, !tbaa !2428
  %532 = add i64 %510, 1309
  %533 = add i64 %510, 29
  %534 = load i64, i64* %12, align 8, !tbaa !2428
  %535 = add i64 %534, -8
  %536 = inttoptr i64 %535 to i64*
  store i64 %533, i64* %536, align 8
  store i64 %535, i64* %12, align 8, !tbaa !2428
  store i64 %532, i64* %65, align 8, !tbaa !2428
  %537 = tail call %struct.Memory* @sub_401030_cdft_renamed_(%struct.State* nonnull %0, i64 %532, %struct.Memory* %507)
  %538 = load i64, i64* %RBP, align 8
  %539 = add i64 %538, -100
  %540 = load i64, i64* %PC, align 8
  %541 = add i64 %540, 7
  store i64 %541, i64* %PC, align 8
  %542 = inttoptr i64 %539 to i32*
  store i32 0, i32* %542, align 4
  %.pre7 = load i64, i64* %PC, align 8
  br label %block_400b37

block_400c74:                                     ; preds = %block_400c67
  %543 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 48) to double*), align 16
  store double %543, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %544 = add i64 %1634, -40
  %545 = add i64 %1662, 12
  store i64 %545, i64* %PC, align 8
  %546 = inttoptr i64 %544 to i64*
  %547 = load i64, i64* %546, align 8
  store i64 %547, i64* %RAX, align 8, !tbaa !2428
  %548 = add i64 %1662, 15
  store i64 %548, i64* %PC, align 8
  %549 = load i32, i32* %1637, align 4
  %550 = shl i32 %549, 1
  %551 = icmp slt i32 %549, 0
  %552 = icmp slt i32 %550, 0
  %553 = xor i1 %551, %552
  %554 = zext i32 %550 to i64
  store i64 %554, i64* %RCX, align 8, !tbaa !2428
  %.lobit34 = lshr i32 %549, 31
  %555 = trunc i32 %.lobit34 to i8
  store i8 %555, i8* %20, align 1, !tbaa !2432
  %556 = and i32 %550, 254
  %557 = tail call i32 @llvm.ctpop.i32(i32 %556) #10
  %558 = trunc i32 %557 to i8
  %559 = and i8 %558, 1
  %560 = xor i8 %559, 1
  store i8 %560, i8* %27, align 1, !tbaa !2432
  store i8 0, i8* %32, align 1, !tbaa !2432
  %561 = icmp eq i32 %550, 0
  %562 = zext i1 %561 to i8
  store i8 %562, i8* %35, align 1, !tbaa !2432
  %563 = lshr i32 %549, 30
  %564 = trunc i32 %563 to i8
  %565 = and i8 %564, 1
  store i8 %565, i8* %38, align 1, !tbaa !2432
  %566 = zext i1 %553 to i8
  store i8 %566, i8* %44, align 1, !tbaa !2432
  %567 = sext i32 %550 to i64
  store i64 %567, i64* %RDX, align 8, !tbaa !2428
  %568 = shl nsw i64 %567, 3
  %569 = add i64 %568, %547
  %570 = add i64 %1662, 26
  store i64 %570, i64* %PC, align 8
  %571 = inttoptr i64 %569 to i64*
  %572 = load i64, i64* %571, align 8
  %573 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 96) to i32*), align 16
  %574 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 100) to i32*), align 4
  %575 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 104) to i32*), align 8
  %576 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 108) to i32*), align 4
  %577 = bitcast %union.VectorReg* %8 to i32*
  store i32 %573, i32* %577, align 1, !tbaa !2475
  %578 = bitcast i8* %138 to i32*
  store i32 %574, i32* %578, align 1, !tbaa !2475
  %579 = bitcast i64* %141 to i32*
  store i32 %575, i32* %579, align 1, !tbaa !2475
  %580 = bitcast i8* %144 to i32*
  store i32 %576, i32* %580, align 1, !tbaa !2475
  %581 = load i64, i64* %387, align 1
  %582 = and i64 %581, %572
  %583 = trunc i64 %582 to i32
  %584 = lshr i64 %582, 32
  %585 = trunc i64 %584 to i32
  store i32 %583, i32* %1141, align 1, !tbaa !2459
  store i32 %585, i32* %1143, align 1, !tbaa !2459
  store i32 0, i32* %1144, align 1, !tbaa !2459
  store i32 0, i32* %1146, align 1, !tbaa !2459
  %586 = add i64 %1662, 41
  store i64 %586, i64* %PC, align 8
  %587 = load double, double* %107, align 1
  %588 = fcmp uno double %587, %543
  br i1 %588, label %589, label %599

; <label>:589:                                    ; preds = %block_400c74
  %590 = fadd double %587, %543
  %591 = bitcast double %590 to i64
  %592 = and i64 %591, 9221120237041090560
  %593 = icmp eq i64 %592, 9218868437227405312
  %594 = and i64 %591, 2251799813685247
  %595 = icmp ne i64 %594, 0
  %596 = and i1 %593, %595
  br i1 %596, label %597, label %605

; <label>:597:                                    ; preds = %589
  %598 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %586, %struct.Memory* %MEMORY.5) #11
  %.pre9 = load i64, i64* %PC, align 8
  %.pre10 = load i8, i8* %20, align 1, !tbaa !2433
  %.pre11 = load i8, i8* %35, align 1, !tbaa !2448
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1

; <label>:599:                                    ; preds = %block_400c74
  %600 = fcmp ogt double %587, %543
  br i1 %600, label %605, label %601

; <label>:601:                                    ; preds = %599
  %602 = fcmp olt double %587, %543
  br i1 %602, label %605, label %603

; <label>:603:                                    ; preds = %601
  %604 = fcmp oeq double %587, %543
  br i1 %604, label %605, label %609

; <label>:605:                                    ; preds = %603, %601, %599, %589
  %606 = phi i8 [ 0, %599 ], [ 0, %601 ], [ 1, %603 ], [ 1, %589 ]
  %607 = phi i8 [ 0, %599 ], [ 0, %601 ], [ 0, %603 ], [ 1, %589 ]
  %608 = phi i8 [ 0, %599 ], [ 1, %601 ], [ 0, %603 ], [ 1, %589 ]
  store i8 %606, i8* %35, align 1, !tbaa !2432
  store i8 %607, i8* %27, align 1, !tbaa !2432
  store i8 %608, i8* %20, align 1, !tbaa !2432
  br label %609

; <label>:609:                                    ; preds = %605, %603
  %610 = phi i8 [ %606, %605 ], [ %562, %603 ]
  %611 = phi i8 [ %608, %605 ], [ %555, %603 ]
  store i8 0, i8* %44, align 1, !tbaa !2432
  store i8 0, i8* %38, align 1, !tbaa !2432
  store i8 0, i8* %32, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1: ; preds = %609, %597
  %612 = phi i8 [ %.pre11, %597 ], [ %610, %609 ]
  %613 = phi i8 [ %.pre10, %597 ], [ %611, %609 ]
  %614 = phi i64 [ %.pre9, %597 ], [ %586, %609 ]
  %615 = phi %struct.Memory* [ %598, %597 ], [ %MEMORY.5, %609 ]
  %616 = or i8 %612, %613
  %617 = icmp ne i8 %616, 0
  %.v35 = select i1 %617, i64 37, i64 6
  %618 = add i64 %614, %.v35
  store i64 %618, i64* %65, align 8, !tbaa !2428
  br i1 %617, label %block_400cc2, label %block_400ca3

block_400ad6:                                     ; preds = %block_400a8b, %block_400c14
  %619 = phi i64 [ %.pre6, %block_400a8b ], [ %481, %block_400c14 ]
  %MEMORY.0 = phi %struct.Memory* [ %1620, %block_400a8b ], [ %448, %block_400c14 ]
  %620 = load i64, i64* %RBP, align 8
  %621 = add i64 %620, -8
  %622 = add i64 %619, 7
  store i64 %622, i64* %PC, align 8
  %623 = inttoptr i64 %621 to i32*
  %624 = load i32, i32* %623, align 4
  %625 = add i32 %624, -150000
  %626 = icmp ult i32 %624, 150000
  %627 = zext i1 %626 to i8
  store i8 %627, i8* %20, align 1, !tbaa !2433
  %628 = and i32 %625, 255
  %629 = tail call i32 @llvm.ctpop.i32(i32 %628) #10
  %630 = trunc i32 %629 to i8
  %631 = and i8 %630, 1
  %632 = xor i8 %631, 1
  store i8 %632, i8* %27, align 1, !tbaa !2447
  %633 = xor i32 %624, 16
  %634 = xor i32 %633, %625
  %635 = lshr i32 %634, 4
  %636 = trunc i32 %635 to i8
  %637 = and i8 %636, 1
  store i8 %637, i8* %32, align 1, !tbaa !2451
  %638 = icmp eq i32 %625, 0
  %639 = zext i1 %638 to i8
  store i8 %639, i8* %35, align 1, !tbaa !2448
  %640 = lshr i32 %625, 31
  %641 = trunc i32 %640 to i8
  store i8 %641, i8* %38, align 1, !tbaa !2449
  %642 = lshr i32 %624, 31
  %643 = xor i32 %640, %642
  %644 = add nuw nsw i32 %643, %642
  %645 = icmp eq i32 %644, 2
  %646 = zext i1 %645 to i8
  store i8 %646, i8* %44, align 1, !tbaa !2450
  %647 = icmp ne i8 %641, 0
  %648 = xor i1 %647, %645
  %.v29 = select i1 %648, i64 13, i64 359
  %649 = add i64 %619, %.v29
  store i64 %649, i64* %65, align 8, !tbaa !2428
  br i1 %648, label %block_400ae3, label %block_400c3d

block_400cd2:                                     ; preds = %block_400ca3, %block_400cc2
  %.sink19.in = phi i64 [ %1316, %block_400ca3 ], [ %1098, %block_400cc2 ]
  %.sink = phi double [ %1347, %block_400ca3 ], [ %1100, %block_400cc2 ]
  %.sink17 = phi i64 [ 21, %block_400ca3 ], [ 5, %block_400cc2 ]
  %.sink19 = add i64 %.sink19.in, -192
  %650 = inttoptr i64 %.sink19 to double*
  store double %.sink, double* %650, align 8
  %651 = load i64, i64* %PC, align 8
  %652 = add i64 %651, %.sink17
  %653 = load i64, i64* %RBP, align 8
  %654 = add i64 %653, -192
  %655 = add i64 %652, 8
  store i64 %655, i64* %PC, align 8
  %656 = inttoptr i64 %654 to i64*
  %657 = load i64, i64* %656, align 8
  %658 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %657, i64* %658, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %659 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 48) to i64*), align 16
  %660 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %7, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %659, i64* %660, align 1, !tbaa !2452
  store double 0.000000e+00, double* %106, align 1, !tbaa !2452
  %661 = add i64 %653, -40
  %662 = add i64 %652, 20
  store i64 %662, i64* %PC, align 8
  %663 = inttoptr i64 %661 to i64*
  %664 = load i64, i64* %663, align 8
  store i64 %664, i64* %RAX, align 8, !tbaa !2428
  %665 = add i64 %653, -12
  %666 = add i64 %652, 23
  store i64 %666, i64* %PC, align 8
  %667 = inttoptr i64 %665 to i32*
  %668 = load i32, i32* %667, align 4
  %669 = shl i32 %668, 1
  %670 = lshr i32 %668, 30
  %671 = and i32 %670, 1
  %672 = or i32 %669, 1
  %673 = zext i32 %672 to i64
  store i64 %673, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %20, align 1, !tbaa !2433
  %674 = and i32 %672, 255
  %675 = tail call i32 @llvm.ctpop.i32(i32 %674) #10
  %676 = trunc i32 %675 to i8
  %677 = and i8 %676, 1
  %678 = xor i8 %677, 1
  store i8 %678, i8* %27, align 1, !tbaa !2447
  store i8 0, i8* %32, align 1, !tbaa !2451
  store i8 0, i8* %35, align 1, !tbaa !2448
  %679 = lshr i32 %668, 30
  %680 = and i32 %679, 1
  %681 = trunc i32 %680 to i8
  store i8 %681, i8* %38, align 1, !tbaa !2449
  %682 = xor i32 %680, %671
  %683 = add nuw nsw i32 %682, %680
  %684 = icmp eq i32 %683, 2
  %685 = zext i1 %684 to i8
  store i8 %685, i8* %44, align 1, !tbaa !2450
  %686 = sext i32 %672 to i64
  store i64 %686, i64* %RDX, align 8, !tbaa !2428
  %687 = shl nsw i64 %686, 3
  %688 = add i64 %687, %664
  %689 = add i64 %652, 37
  store i64 %689, i64* %PC, align 8
  %690 = inttoptr i64 %688 to i64*
  %691 = load i64, i64* %690, align 8
  %692 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 96) to i32*), align 16
  %693 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 100) to i32*), align 4
  %694 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 104) to i32*), align 8
  %695 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 108) to i32*), align 4
  %696 = bitcast %union.VectorReg* %9 to i32*
  store i32 %692, i32* %696, align 1, !tbaa !2475
  %697 = bitcast i8* %1148 to i32*
  store i32 %693, i32* %697, align 1, !tbaa !2475
  %698 = bitcast i64* %1149 to i32*
  store i32 %694, i32* %698, align 1, !tbaa !2475
  %699 = bitcast i8* %1150 to i32*
  store i32 %695, i32* %699, align 1, !tbaa !2475
  %700 = load i64, i64* %1151, align 1
  %701 = and i64 %700, %691
  %702 = trunc i64 %701 to i32
  %703 = lshr i64 %701, 32
  %704 = trunc i64 %703 to i32
  store i32 %702, i32* %136, align 1, !tbaa !2459
  store i32 %704, i32* %139, align 1, !tbaa !2459
  store i32 0, i32* %142, align 1, !tbaa !2459
  store i32 0, i32* %145, align 1, !tbaa !2459
  %705 = add i64 %652, 52
  store i64 %705, i64* %PC, align 8
  %706 = load double, double* %149, align 1
  %707 = load double, double* %107, align 1
  %708 = fcmp uno double %706, %707
  br i1 %708, label %709, label %719

; <label>:709:                                    ; preds = %block_400cd2
  %710 = fadd double %706, %707
  %711 = bitcast double %710 to i64
  %712 = and i64 %711, 9221120237041090560
  %713 = icmp eq i64 %712, 9218868437227405312
  %714 = and i64 %711, 2251799813685247
  %715 = icmp ne i64 %714, 0
  %716 = and i1 %713, %715
  br i1 %716, label %717, label %725

; <label>:717:                                    ; preds = %709
  %718 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %705, %struct.Memory* %615) #11
  %.pre12 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

; <label>:719:                                    ; preds = %block_400cd2
  %720 = fcmp ogt double %706, %707
  br i1 %720, label %725, label %721

; <label>:721:                                    ; preds = %719
  %722 = fcmp olt double %706, %707
  br i1 %722, label %725, label %723

; <label>:723:                                    ; preds = %721
  %724 = fcmp oeq double %706, %707
  br i1 %724, label %725, label %729

; <label>:725:                                    ; preds = %723, %721, %719, %709
  %726 = phi i8 [ 0, %719 ], [ 0, %721 ], [ 1, %723 ], [ 1, %709 ]
  %727 = phi i8 [ 0, %719 ], [ 0, %721 ], [ 0, %723 ], [ 1, %709 ]
  %728 = phi i8 [ 0, %719 ], [ 1, %721 ], [ 0, %723 ], [ 1, %709 ]
  store i8 %726, i8* %35, align 1, !tbaa !2432
  store i8 %727, i8* %27, align 1, !tbaa !2432
  store i8 %728, i8* %20, align 1, !tbaa !2432
  br label %729

; <label>:729:                                    ; preds = %725, %723
  store i8 0, i8* %44, align 1, !tbaa !2432
  store i8 0, i8* %38, align 1, !tbaa !2432
  store i8 0, i8* %32, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit: ; preds = %729, %717
  %730 = phi i64 [ %.pre12, %717 ], [ %705, %729 ]
  %731 = phi %struct.Memory* [ %718, %717 ], [ %615, %729 ]
  %732 = load i64, i64* %RBP, align 8
  %733 = add i64 %732, -200
  %734 = add i64 %730, 8
  store i64 %734, i64* %PC, align 8
  %735 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %736 = load i64, i64* %735, align 1
  %737 = inttoptr i64 %733 to i64*
  store i64 %736, i64* %737, align 8
  %738 = load i64, i64* %PC, align 8
  %739 = load i8, i8* %20, align 1, !tbaa !2433
  %740 = load i8, i8* %35, align 1, !tbaa !2448
  %741 = or i8 %740, %739
  %742 = icmp ne i8 %741, 0
  %.v37 = select i1 %742, i64 40, i64 6
  %743 = add i64 %738, %.v37
  store i64 %743, i64* %65, align 8, !tbaa !2428
  br i1 %742, label %block_400d36, label %block_400d14

block_400d46:                                     ; preds = %block_400d36, %block_400d14
  %.sink24.in = phi i64 [ %1663, %block_400d36 ], [ %1349, %block_400d14 ]
  %.sink22 = phi double [ %1665, %block_400d36 ], [ %1380, %block_400d14 ]
  %.sink21 = phi i64 [ 5, %block_400d36 ], [ 21, %block_400d14 ]
  %.sink24 = add i64 %.sink24.in, -208
  %744 = inttoptr i64 %.sink24 to double*
  store double %.sink22, double* %744, align 8
  %745 = load i64, i64* %PC, align 8
  %746 = add i64 %745, %.sink21
  %747 = load i64, i64* %RBP, align 8
  %748 = add i64 %747, -208
  %749 = add i64 %746, 8
  store i64 %749, i64* %PC, align 8
  %750 = inttoptr i64 %748 to i64*
  %751 = load i64, i64* %750, align 8
  %752 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %751, i64* %752, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  store i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 157), i64* %RDI, align 8, !tbaa !2428
  %753 = add i64 %747, -200
  %754 = add i64 %746, 26
  store i64 %754, i64* %PC, align 8
  %755 = inttoptr i64 %753 to i64*
  %756 = load i64, i64* %755, align 8
  %757 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %7, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %756, i64* %757, align 1, !tbaa !2452
  store double 0.000000e+00, double* %106, align 1, !tbaa !2452
  %758 = add i64 %747, -216
  %759 = add i64 %746, 34
  store i64 %759, i64* %PC, align 8
  %760 = inttoptr i64 %758 to i64*
  store i64 %751, i64* %760, align 8
  %761 = load i64, i64* %PC, align 8
  %762 = load <2 x i32>, <2 x i32>* %1152, align 1
  %763 = load <2 x i32>, <2 x i32>* %1154, align 1
  %764 = extractelement <2 x i32> %762, i32 0
  store i32 %764, i32* %393, align 1, !tbaa !2475
  %765 = extractelement <2 x i32> %762, i32 1
  store i32 %765, i32* %395, align 1, !tbaa !2475
  %766 = extractelement <2 x i32> %763, i32 0
  store i32 %766, i32* %396, align 1, !tbaa !2475
  %767 = extractelement <2 x i32> %763, i32 1
  store i32 %767, i32* %398, align 1, !tbaa !2475
  %768 = load i64, i64* %RBP, align 8
  %769 = add i64 %768, -216
  %770 = add i64 %761, 11
  store i64 %770, i64* %PC, align 8
  %771 = inttoptr i64 %769 to i64*
  %772 = load i64, i64* %771, align 8
  %773 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %7, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %772, i64* %773, align 1, !tbaa !2452
  store double 0.000000e+00, double* %106, align 1, !tbaa !2452
  store i8 2, i8* %AL, align 1, !tbaa !2432
  %774 = add i64 %761, -1752
  %775 = add i64 %761, 18
  %776 = load i64, i64* %12, align 8, !tbaa !2428
  %777 = add i64 %776, -8
  %778 = inttoptr i64 %777 to i64*
  store i64 %775, i64* %778, align 8
  store i64 %777, i64* %12, align 8, !tbaa !2428
  store i64 %774, i64* %65, align 8, !tbaa !2428
  %779 = tail call fastcc %struct.Memory* @ext_6050a0_printf(%struct.State* nonnull %0, %struct.Memory* %731)
  %780 = load i64, i64* %RBP, align 8
  %781 = add i64 %780, -220
  %782 = load i32, i32* %EAX, align 4
  %783 = load i64, i64* %PC, align 8
  %784 = add i64 %783, 6
  store i64 %784, i64* %PC, align 8
  %785 = inttoptr i64 %781 to i32*
  store i32 %782, i32* %785, align 4
  %786 = load i64, i64* %RBP, align 8
  %787 = add i64 %786, -12
  %788 = load i64, i64* %PC, align 8
  %789 = add i64 %788, 3
  store i64 %789, i64* %PC, align 8
  %790 = inttoptr i64 %787 to i32*
  %791 = load i32, i32* %790, align 4
  %792 = add i32 %791, 1
  %793 = zext i32 %792 to i64
  store i64 %793, i64* %RAX, align 8, !tbaa !2428
  %794 = icmp eq i32 %791, -1
  %795 = icmp eq i32 %792, 0
  %796 = or i1 %794, %795
  %797 = zext i1 %796 to i8
  store i8 %797, i8* %20, align 1, !tbaa !2433
  %798 = and i32 %792, 255
  %799 = tail call i32 @llvm.ctpop.i32(i32 %798) #10
  %800 = trunc i32 %799 to i8
  %801 = and i8 %800, 1
  %802 = xor i8 %801, 1
  store i8 %802, i8* %27, align 1, !tbaa !2447
  %803 = xor i32 %791, %792
  %804 = lshr i32 %803, 4
  %805 = trunc i32 %804 to i8
  %806 = and i8 %805, 1
  store i8 %806, i8* %32, align 1, !tbaa !2451
  %807 = icmp eq i32 %792, 0
  %808 = zext i1 %807 to i8
  store i8 %808, i8* %35, align 1, !tbaa !2448
  %809 = lshr i32 %792, 31
  %810 = trunc i32 %809 to i8
  store i8 %810, i8* %38, align 1, !tbaa !2449
  %811 = lshr i32 %791, 31
  %812 = xor i32 %809, %811
  %813 = add nuw nsw i32 %812, %809
  %814 = icmp eq i32 %813, 2
  %815 = zext i1 %814 to i8
  store i8 %815, i8* %44, align 1, !tbaa !2450
  %816 = add i64 %788, 9
  store i64 %816, i64* %PC, align 8
  store i32 %792, i32* %790, align 4
  %817 = load i64, i64* %PC, align 8
  %818 = add i64 %817, -290
  store i64 %818, i64* %65, align 8, !tbaa !2428
  br label %block_400c67

block_400b44:                                     ; preds = %block_400b37
  %819 = add i64 %1156, -40
  %820 = add i64 %1184, 4
  store i64 %820, i64* %PC, align 8
  %821 = inttoptr i64 %819 to i64*
  %822 = load i64, i64* %821, align 8
  store i64 %822, i64* %RAX, align 8, !tbaa !2428
  %823 = add i64 %1184, 7
  store i64 %823, i64* %PC, align 8
  %824 = load i32, i32* %1159, align 4
  %825 = shl i32 %824, 1
  %826 = icmp slt i32 %824, 0
  %827 = icmp slt i32 %825, 0
  %828 = xor i1 %826, %827
  %829 = zext i32 %825 to i64
  store i64 %829, i64* %RCX, align 8, !tbaa !2428
  %.lobit = lshr i32 %824, 31
  %830 = trunc i32 %.lobit to i8
  store i8 %830, i8* %20, align 1, !tbaa !2432
  %831 = and i32 %825, 254
  %832 = tail call i32 @llvm.ctpop.i32(i32 %831) #10
  %833 = trunc i32 %832 to i8
  %834 = and i8 %833, 1
  %835 = xor i8 %834, 1
  store i8 %835, i8* %27, align 1, !tbaa !2432
  store i8 0, i8* %32, align 1, !tbaa !2432
  %836 = icmp eq i32 %825, 0
  %837 = zext i1 %836 to i8
  store i8 %837, i8* %35, align 1, !tbaa !2432
  %838 = lshr i32 %824, 30
  %839 = trunc i32 %838 to i8
  %840 = and i8 %839, 1
  store i8 %840, i8* %38, align 1, !tbaa !2432
  %841 = zext i1 %828 to i8
  store i8 %841, i8* %44, align 1, !tbaa !2432
  %842 = sext i32 %825 to i64
  store i64 %842, i64* %RDX, align 8, !tbaa !2428
  %843 = shl nsw i64 %842, 3
  %844 = add i64 %843, %822
  %845 = add i64 %1184, 18
  store i64 %845, i64* %PC, align 8
  %846 = inttoptr i64 %844 to i64*
  %847 = load i64, i64* %846, align 8
  %848 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %847, i64* %848, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %849 = add i64 %1156, -112
  %850 = add i64 %1184, 23
  store i64 %850, i64* %PC, align 8
  %851 = inttoptr i64 %849 to i64*
  store i64 %847, i64* %851, align 8
  %852 = load i64, i64* %RBP, align 8
  %853 = add i64 %852, -32
  %854 = load i64, i64* %PC, align 8
  %855 = add i64 %854, 4
  store i64 %855, i64* %PC, align 8
  %856 = inttoptr i64 %853 to i64*
  %857 = load i64, i64* %856, align 8
  store i64 %857, i64* %RAX, align 8, !tbaa !2428
  %858 = add i64 %852, -100
  %859 = add i64 %854, 7
  store i64 %859, i64* %PC, align 8
  %860 = inttoptr i64 %858 to i32*
  %861 = load i32, i32* %860, align 4
  %862 = shl i32 %861, 1
  %863 = icmp slt i32 %861, 0
  %864 = icmp slt i32 %862, 0
  %865 = xor i1 %863, %864
  %866 = zext i32 %862 to i64
  store i64 %866, i64* %RCX, align 8, !tbaa !2428
  %.lobit31 = lshr i32 %861, 31
  %867 = trunc i32 %.lobit31 to i8
  store i8 %867, i8* %20, align 1, !tbaa !2432
  %868 = and i32 %862, 254
  %869 = tail call i32 @llvm.ctpop.i32(i32 %868) #10
  %870 = trunc i32 %869 to i8
  %871 = and i8 %870, 1
  %872 = xor i8 %871, 1
  store i8 %872, i8* %27, align 1, !tbaa !2432
  store i8 0, i8* %32, align 1, !tbaa !2432
  %873 = icmp eq i32 %862, 0
  %874 = zext i1 %873 to i8
  store i8 %874, i8* %35, align 1, !tbaa !2432
  %875 = lshr i32 %861, 30
  %876 = trunc i32 %875 to i8
  %877 = and i8 %876, 1
  store i8 %877, i8* %38, align 1, !tbaa !2432
  %878 = zext i1 %865 to i8
  store i8 %878, i8* %44, align 1, !tbaa !2432
  %879 = sext i32 %862 to i64
  store i64 %879, i64* %RDX, align 8, !tbaa !2428
  %880 = shl nsw i64 %879, 3
  %881 = add i64 %880, %857
  %882 = add i64 %854, 18
  store i64 %882, i64* %PC, align 8
  %883 = inttoptr i64 %881 to i64*
  %884 = load i64, i64* %883, align 8
  %885 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %884, i64* %885, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %886 = add i64 %852, -120
  %887 = add i64 %854, 23
  store i64 %887, i64* %PC, align 8
  %888 = inttoptr i64 %886 to i64*
  store i64 %884, i64* %888, align 8
  %889 = load i64, i64* %RBP, align 8
  %890 = add i64 %889, -40
  %891 = load i64, i64* %PC, align 8
  %892 = add i64 %891, 4
  store i64 %892, i64* %PC, align 8
  %893 = inttoptr i64 %890 to i64*
  %894 = load i64, i64* %893, align 8
  store i64 %894, i64* %RAX, align 8, !tbaa !2428
  %895 = add i64 %889, -100
  %896 = add i64 %891, 7
  store i64 %896, i64* %PC, align 8
  %897 = inttoptr i64 %895 to i32*
  %898 = load i32, i32* %897, align 4
  %899 = shl i32 %898, 1
  %900 = lshr i32 %898, 30
  %901 = and i32 %900, 1
  %902 = or i32 %899, 1
  %903 = zext i32 %902 to i64
  store i64 %903, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %20, align 1, !tbaa !2433
  %904 = and i32 %902, 255
  %905 = tail call i32 @llvm.ctpop.i32(i32 %904) #10
  %906 = trunc i32 %905 to i8
  %907 = and i8 %906, 1
  %908 = xor i8 %907, 1
  store i8 %908, i8* %27, align 1, !tbaa !2447
  store i8 0, i8* %32, align 1, !tbaa !2451
  store i8 0, i8* %35, align 1, !tbaa !2448
  %909 = lshr i32 %898, 30
  %910 = and i32 %909, 1
  %911 = trunc i32 %910 to i8
  store i8 %911, i8* %38, align 1, !tbaa !2449
  %912 = xor i32 %910, %901
  %913 = add nuw nsw i32 %912, %910
  %914 = icmp eq i32 %913, 2
  %915 = zext i1 %914 to i8
  store i8 %915, i8* %44, align 1, !tbaa !2450
  %916 = sext i32 %902 to i64
  store i64 %916, i64* %RDX, align 8, !tbaa !2428
  %917 = shl nsw i64 %916, 3
  %918 = add i64 %917, %894
  %919 = add i64 %891, 21
  store i64 %919, i64* %PC, align 8
  %920 = inttoptr i64 %918 to i64*
  %921 = load i64, i64* %920, align 8
  %922 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %921, i64* %922, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %923 = add i64 %889, -128
  %924 = add i64 %891, 26
  store i64 %924, i64* %PC, align 8
  %925 = inttoptr i64 %923 to i64*
  store i64 %921, i64* %925, align 8
  %926 = load i64, i64* %RBP, align 8
  %927 = add i64 %926, -32
  %928 = load i64, i64* %PC, align 8
  %929 = add i64 %928, 4
  store i64 %929, i64* %PC, align 8
  %930 = inttoptr i64 %927 to i64*
  %931 = load i64, i64* %930, align 8
  store i64 %931, i64* %RAX, align 8, !tbaa !2428
  %932 = add i64 %926, -100
  %933 = add i64 %928, 7
  store i64 %933, i64* %PC, align 8
  %934 = inttoptr i64 %932 to i32*
  %935 = load i32, i32* %934, align 4
  %936 = shl i32 %935, 1
  %937 = lshr i32 %935, 30
  %938 = and i32 %937, 1
  %939 = or i32 %936, 1
  %940 = zext i32 %939 to i64
  store i64 %940, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %20, align 1, !tbaa !2433
  %941 = and i32 %939, 255
  %942 = tail call i32 @llvm.ctpop.i32(i32 %941) #10
  %943 = trunc i32 %942 to i8
  %944 = and i8 %943, 1
  %945 = xor i8 %944, 1
  store i8 %945, i8* %27, align 1, !tbaa !2447
  store i8 0, i8* %32, align 1, !tbaa !2451
  store i8 0, i8* %35, align 1, !tbaa !2448
  %946 = lshr i32 %935, 30
  %947 = and i32 %946, 1
  %948 = trunc i32 %947 to i8
  store i8 %948, i8* %38, align 1, !tbaa !2449
  %949 = xor i32 %947, %938
  %950 = add nuw nsw i32 %949, %947
  %951 = icmp eq i32 %950, 2
  %952 = zext i1 %951 to i8
  store i8 %952, i8* %44, align 1, !tbaa !2450
  %953 = sext i32 %939 to i64
  store i64 %953, i64* %RDX, align 8, !tbaa !2428
  %954 = shl nsw i64 %953, 3
  %955 = add i64 %954, %931
  %956 = add i64 %928, 21
  store i64 %956, i64* %PC, align 8
  %957 = inttoptr i64 %955 to i64*
  %958 = load i64, i64* %957, align 8
  %959 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %958, i64* %959, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %960 = add i64 %926, -136
  %961 = add i64 %928, 29
  store i64 %961, i64* %PC, align 8
  %962 = inttoptr i64 %960 to i64*
  store i64 %958, i64* %962, align 8
  %963 = load i64, i64* %RBP, align 8
  %964 = add i64 %963, -112
  %965 = load i64, i64* %PC, align 8
  %966 = add i64 %965, 5
  store i64 %966, i64* %PC, align 8
  %967 = inttoptr i64 %964 to double*
  %968 = load double, double* %967, align 8
  store double %968, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %969 = add i64 %963, -120
  %970 = add i64 %965, 10
  store i64 %970, i64* %PC, align 8
  %971 = inttoptr i64 %969 to double*
  %972 = load double, double* %971, align 8
  %973 = fmul double %968, %972
  store double %973, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %974 = add i64 %963, -128
  %975 = add i64 %965, 15
  store i64 %975, i64* %PC, align 8
  %976 = inttoptr i64 %974 to double*
  %977 = load double, double* %976, align 8
  store double %977, double* %104, align 1, !tbaa !2452
  store double 0.000000e+00, double* %106, align 1, !tbaa !2452
  %978 = add i64 %963, -136
  %979 = add i64 %965, 23
  store i64 %979, i64* %PC, align 8
  %980 = inttoptr i64 %978 to double*
  %981 = load double, double* %980, align 8
  %982 = fmul double %977, %981
  store double %982, double* %104, align 1, !tbaa !2452
  store i64 0, i64* %105, align 1, !tbaa !2452
  %983 = fsub double %973, %982
  store double %983, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %984 = add i64 %963, -40
  %985 = add i64 %965, 31
  store i64 %985, i64* %PC, align 8
  %986 = inttoptr i64 %984 to i64*
  %987 = load i64, i64* %986, align 8
  store i64 %987, i64* %RAX, align 8, !tbaa !2428
  %988 = add i64 %963, -100
  %989 = add i64 %965, 34
  store i64 %989, i64* %PC, align 8
  %990 = inttoptr i64 %988 to i32*
  %991 = load i32, i32* %990, align 4
  %992 = shl i32 %991, 1
  %993 = icmp slt i32 %991, 0
  %994 = icmp slt i32 %992, 0
  %995 = xor i1 %993, %994
  %996 = zext i32 %992 to i64
  store i64 %996, i64* %RCX, align 8, !tbaa !2428
  %.lobit32 = lshr i32 %991, 31
  %997 = trunc i32 %.lobit32 to i8
  store i8 %997, i8* %20, align 1, !tbaa !2432
  %998 = and i32 %992, 254
  %999 = tail call i32 @llvm.ctpop.i32(i32 %998) #10
  %1000 = trunc i32 %999 to i8
  %1001 = and i8 %1000, 1
  %1002 = xor i8 %1001, 1
  store i8 %1002, i8* %27, align 1, !tbaa !2432
  store i8 0, i8* %32, align 1, !tbaa !2432
  %1003 = icmp eq i32 %992, 0
  %1004 = zext i1 %1003 to i8
  store i8 %1004, i8* %35, align 1, !tbaa !2432
  %1005 = lshr i32 %991, 30
  %1006 = trunc i32 %1005 to i8
  %1007 = and i8 %1006, 1
  store i8 %1007, i8* %38, align 1, !tbaa !2432
  %1008 = zext i1 %995 to i8
  store i8 %1008, i8* %44, align 1, !tbaa !2432
  %1009 = sext i32 %992 to i64
  store i64 %1009, i64* %RDX, align 8, !tbaa !2428
  %1010 = shl nsw i64 %1009, 3
  %1011 = add i64 %1010, %987
  %1012 = add i64 %965, 45
  store i64 %1012, i64* %PC, align 8
  %1013 = inttoptr i64 %1011 to double*
  store double %983, double* %1013, align 8
  %1014 = load i64, i64* %RBP, align 8
  %1015 = add i64 %1014, -112
  %1016 = load i64, i64* %PC, align 8
  %1017 = add i64 %1016, 5
  store i64 %1017, i64* %PC, align 8
  %1018 = inttoptr i64 %1015 to double*
  %1019 = load double, double* %1018, align 8
  store double %1019, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %1020 = add i64 %1014, -136
  %1021 = add i64 %1016, 13
  store i64 %1021, i64* %PC, align 8
  %1022 = inttoptr i64 %1020 to double*
  %1023 = load double, double* %1022, align 8
  %1024 = fmul double %1019, %1023
  store double %1024, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %1025 = add i64 %1014, -128
  %1026 = add i64 %1016, 18
  store i64 %1026, i64* %PC, align 8
  %1027 = inttoptr i64 %1025 to double*
  %1028 = load double, double* %1027, align 8
  store double %1028, double* %104, align 1, !tbaa !2452
  store double 0.000000e+00, double* %106, align 1, !tbaa !2452
  %1029 = add i64 %1014, -120
  %1030 = add i64 %1016, 23
  store i64 %1030, i64* %PC, align 8
  %1031 = inttoptr i64 %1029 to double*
  %1032 = load double, double* %1031, align 8
  %1033 = fmul double %1028, %1032
  store double %1033, double* %104, align 1, !tbaa !2452
  store i64 0, i64* %105, align 1, !tbaa !2452
  %1034 = fadd double %1024, %1033
  store double %1034, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %1035 = add i64 %1014, -40
  %1036 = add i64 %1016, 31
  store i64 %1036, i64* %PC, align 8
  %1037 = inttoptr i64 %1035 to i64*
  %1038 = load i64, i64* %1037, align 8
  store i64 %1038, i64* %RAX, align 8, !tbaa !2428
  %1039 = add i64 %1014, -100
  %1040 = add i64 %1016, 34
  store i64 %1040, i64* %PC, align 8
  %1041 = inttoptr i64 %1039 to i32*
  %1042 = load i32, i32* %1041, align 4
  %1043 = shl i32 %1042, 1
  %1044 = lshr i32 %1042, 30
  %1045 = and i32 %1044, 1
  %1046 = or i32 %1043, 1
  %1047 = zext i32 %1046 to i64
  store i64 %1047, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %20, align 1, !tbaa !2433
  %1048 = and i32 %1046, 255
  %1049 = tail call i32 @llvm.ctpop.i32(i32 %1048) #10
  %1050 = trunc i32 %1049 to i8
  %1051 = and i8 %1050, 1
  %1052 = xor i8 %1051, 1
  store i8 %1052, i8* %27, align 1, !tbaa !2447
  store i8 0, i8* %32, align 1, !tbaa !2451
  store i8 0, i8* %35, align 1, !tbaa !2448
  %1053 = lshr i32 %1042, 30
  %1054 = and i32 %1053, 1
  %1055 = trunc i32 %1054 to i8
  store i8 %1055, i8* %38, align 1, !tbaa !2449
  %1056 = xor i32 %1054, %1045
  %1057 = add nuw nsw i32 %1056, %1054
  %1058 = icmp eq i32 %1057, 2
  %1059 = zext i1 %1058 to i8
  store i8 %1059, i8* %44, align 1, !tbaa !2450
  %1060 = sext i32 %1046 to i64
  store i64 %1060, i64* %RDX, align 8, !tbaa !2428
  %1061 = shl nsw i64 %1060, 3
  %1062 = add i64 %1061, %1038
  %1063 = add i64 %1016, 48
  store i64 %1063, i64* %PC, align 8
  %1064 = inttoptr i64 %1062 to double*
  store double %1034, double* %1064, align 8
  %1065 = load i64, i64* %RBP, align 8
  %1066 = add i64 %1065, -100
  %1067 = load i64, i64* %PC, align 8
  %1068 = add i64 %1067, 3
  store i64 %1068, i64* %PC, align 8
  %1069 = inttoptr i64 %1066 to i32*
  %1070 = load i32, i32* %1069, align 4
  %1071 = add i32 %1070, 1
  %1072 = zext i32 %1071 to i64
  store i64 %1072, i64* %RAX, align 8, !tbaa !2428
  %1073 = icmp eq i32 %1070, -1
  %1074 = icmp eq i32 %1071, 0
  %1075 = or i1 %1073, %1074
  %1076 = zext i1 %1075 to i8
  store i8 %1076, i8* %20, align 1, !tbaa !2433
  %1077 = and i32 %1071, 255
  %1078 = tail call i32 @llvm.ctpop.i32(i32 %1077) #10
  %1079 = trunc i32 %1078 to i8
  %1080 = and i8 %1079, 1
  %1081 = xor i8 %1080, 1
  store i8 %1081, i8* %27, align 1, !tbaa !2447
  %1082 = xor i32 %1070, %1071
  %1083 = lshr i32 %1082, 4
  %1084 = trunc i32 %1083 to i8
  %1085 = and i8 %1084, 1
  store i8 %1085, i8* %32, align 1, !tbaa !2451
  %1086 = icmp eq i32 %1071, 0
  %1087 = zext i1 %1086 to i8
  store i8 %1087, i8* %35, align 1, !tbaa !2448
  %1088 = lshr i32 %1071, 31
  %1089 = trunc i32 %1088 to i8
  store i8 %1089, i8* %38, align 1, !tbaa !2449
  %1090 = lshr i32 %1070, 31
  %1091 = xor i32 %1088, %1090
  %1092 = add nuw nsw i32 %1091, %1088
  %1093 = icmp eq i32 %1092, 2
  %1094 = zext i1 %1093 to i8
  store i8 %1094, i8* %44, align 1, !tbaa !2450
  %1095 = add i64 %1067, 9
  store i64 %1095, i64* %PC, align 8
  store i32 %1071, i32* %1069, align 4
  %1096 = load i64, i64* %PC, align 8
  %1097 = add i64 %1096, -216
  store i64 %1097, i64* %65, align 8, !tbaa !2428
  br label %block_400b37

block_400cc2:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1
  store i32 0, i32* %393, align 1, !tbaa !2459
  store i32 0, i32* %395, align 1, !tbaa !2459
  store i32 0, i32* %396, align 1, !tbaa !2459
  store i32 0, i32* %398, align 1, !tbaa !2459
  %1098 = load i64, i64* %RBP, align 8
  %1099 = add i64 %618, 11
  store i64 %1099, i64* %PC, align 8
  %1100 = load double, double* %71, align 1
  br label %block_400cd2

block_400c3d:                                     ; preds = %block_400ad6
  %1101 = add i64 %649, 419
  %1102 = add i64 %649, 5
  %1103 = load i64, i64* %12, align 8, !tbaa !2428
  %1104 = add i64 %1103, -8
  %1105 = inttoptr i64 %1104 to i64*
  store i64 %1102, i64* %1105, align 8
  store i64 %1104, i64* %12, align 8, !tbaa !2428
  store i64 %1101, i64* %65, align 8, !tbaa !2428
  %1106 = tail call %struct.Memory* @sub_400de0_get_time_renamed_(%struct.State* nonnull %0, i64 %1101, %struct.Memory* %MEMORY.0)
  %1107 = load i64, i64* %RBP, align 8
  %1108 = add i64 %1107, -72
  %1109 = load i64, i64* %PC, align 8
  %1110 = add i64 %1109, 5
  store i64 %1110, i64* %PC, align 8
  %1111 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %1112 = load i64, i64* %1111, align 1
  %1113 = inttoptr i64 %1108 to i64*
  store i64 %1112, i64* %1113, align 8
  %1114 = load i64, i64* %RBP, align 8
  %1115 = add i64 %1114, -72
  %1116 = load i64, i64* %PC, align 8
  %1117 = add i64 %1116, 5
  store i64 %1117, i64* %PC, align 8
  %1118 = inttoptr i64 %1115 to double*
  %1119 = load double, double* %1118, align 8
  store double %1119, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %1120 = add i64 %1114, -64
  %1121 = add i64 %1116, 10
  store i64 %1121, i64* %PC, align 8
  %1122 = inttoptr i64 %1120 to double*
  %1123 = load double, double* %1122, align 8
  %1124 = fsub double %1119, %1123
  store double %1124, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %1125 = add i64 %1114, -80
  %1126 = add i64 %1116, 15
  store i64 %1126, i64* %PC, align 8
  %1127 = inttoptr i64 %1125 to double*
  %1128 = load double, double* %1127, align 8
  %1129 = fsub double %1124, %1128
  store double %1129, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %1130 = add i64 %1114, -88
  %1131 = add i64 %1116, 20
  store i64 %1131, i64* %PC, align 8
  %1132 = inttoptr i64 %1130 to double*
  %1133 = load double, double* %1132, align 8
  %1134 = fadd double %1129, %1133
  store double %1134, double* %96, align 1, !tbaa !2452
  store i64 0, i64* %97, align 1, !tbaa !2452
  %1135 = add i64 %1116, 25
  store i64 %1135, i64* %PC, align 8
  store double %1134, double* %1132, align 8
  %1136 = load i64, i64* %RBP, align 8
  %1137 = add i64 %1136, -12
  %1138 = load i64, i64* %PC, align 8
  %1139 = add i64 %1138, 7
  store i64 %1139, i64* %PC, align 8
  %1140 = inttoptr i64 %1137 to i32*
  store i32 0, i32* %1140, align 4
  %1141 = bitcast %union.VectorReg* %7 to i32*
  %1142 = getelementptr inbounds i8, i8* %99, i64 4
  %1143 = bitcast i8* %1142 to i32*
  %1144 = bitcast i64* %105 to i32*
  %1145 = getelementptr inbounds i8, i8* %99, i64 12
  %1146 = bitcast i8* %1145 to i32*
  %1147 = bitcast %union.VectorReg* %9 to i8*
  %1148 = getelementptr inbounds i8, i8* %1147, i64 4
  %1149 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3, i32 0, i32 0, i32 0, i64 1
  %1150 = getelementptr inbounds i8, i8* %1147, i64 12
  %1151 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %9, i64 0, i32 0, i32 0, i32 0, i64 0
  %1152 = bitcast %union.VectorReg* %7 to <2 x i32>*
  %1153 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %1154 = bitcast i64* %1153 to <2 x i32>*
  %.pre8 = load i64, i64* %PC, align 8
  br label %block_400c67

block_400b37:                                     ; preds = %block_400b44, %block_400ae3
  %1155 = phi i64 [ %1097, %block_400b44 ], [ %.pre7, %block_400ae3 ]
  %1156 = load i64, i64* %RBP, align 8
  %1157 = add i64 %1156, -100
  %1158 = add i64 %1155, 7
  store i64 %1158, i64* %PC, align 8
  %1159 = inttoptr i64 %1157 to i32*
  %1160 = load i32, i32* %1159, align 4
  %1161 = add i32 %1160, -1024
  %1162 = icmp ult i32 %1160, 1024
  %1163 = zext i1 %1162 to i8
  store i8 %1163, i8* %20, align 1, !tbaa !2433
  %1164 = and i32 %1161, 255
  %1165 = tail call i32 @llvm.ctpop.i32(i32 %1164) #10
  %1166 = trunc i32 %1165 to i8
  %1167 = and i8 %1166, 1
  %1168 = xor i8 %1167, 1
  store i8 %1168, i8* %27, align 1, !tbaa !2447
  %1169 = xor i32 %1160, %1161
  %1170 = lshr i32 %1169, 4
  %1171 = trunc i32 %1170 to i8
  %1172 = and i8 %1171, 1
  store i8 %1172, i8* %32, align 1, !tbaa !2451
  %1173 = icmp eq i32 %1161, 0
  %1174 = zext i1 %1173 to i8
  store i8 %1174, i8* %35, align 1, !tbaa !2448
  %1175 = lshr i32 %1161, 31
  %1176 = trunc i32 %1175 to i8
  store i8 %1176, i8* %38, align 1, !tbaa !2449
  %1177 = lshr i32 %1160, 31
  %1178 = xor i32 %1175, %1177
  %1179 = add nuw nsw i32 %1178, %1177
  %1180 = icmp eq i32 %1179, 2
  %1181 = zext i1 %1180 to i8
  store i8 %1181, i8* %44, align 1, !tbaa !2450
  %1182 = icmp ne i8 %1176, 0
  %1183 = xor i1 %1182, %1180
  %.v30 = select i1 %1183, i64 13, i64 221
  %1184 = add i64 %1155, %.v30
  store i64 %1184, i64* %65, align 8, !tbaa !2428
  br i1 %1183, label %block_400b44, label %block_400c14

block_400a3c:                                     ; preds = %block_400a2f
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %1185 = add i64 %1542, -32
  %1186 = add i64 %1570, 14
  store i64 %1186, i64* %PC, align 8
  %1187 = inttoptr i64 %1185 to i64*
  %1188 = load i64, i64* %1187, align 8
  store i64 %1188, i64* %RCX, align 8, !tbaa !2428
  %1189 = add i64 %1570, 17
  store i64 %1189, i64* %PC, align 8
  %1190 = load i32, i32* %1545, align 4
  %1191 = shl i32 %1190, 1
  %1192 = lshr i32 %1190, 30
  %1193 = and i32 %1192, 1
  %1194 = or i32 %1191, 1
  %1195 = zext i32 %1194 to i64
  store i64 %1195, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %20, align 1, !tbaa !2433
  %1196 = and i32 %1194, 255
  %1197 = tail call i32 @llvm.ctpop.i32(i32 %1196) #10
  %1198 = trunc i32 %1197 to i8
  %1199 = and i8 %1198, 1
  %1200 = xor i8 %1199, 1
  store i8 %1200, i8* %27, align 1, !tbaa !2447
  store i8 0, i8* %32, align 1, !tbaa !2451
  store i8 0, i8* %35, align 1, !tbaa !2448
  %1201 = lshr i32 %1190, 30
  %1202 = and i32 %1201, 1
  %1203 = trunc i32 %1202 to i8
  store i8 %1203, i8* %38, align 1, !tbaa !2449
  %1204 = xor i32 %1202, %1193
  %1205 = add nuw nsw i32 %1204, %1202
  %1206 = icmp eq i32 %1205, 2
  %1207 = zext i1 %1206 to i8
  store i8 %1207, i8* %44, align 1, !tbaa !2450
  %1208 = sext i32 %1194 to i64
  store i64 %1208, i64* %RSI, align 8, !tbaa !2428
  %1209 = shl nsw i64 %1208, 3
  %1210 = add i64 %1209, %1188
  %1211 = add i64 %1570, 31
  store i64 %1211, i64* %PC, align 8
  %1212 = inttoptr i64 %1210 to i64*
  %1213 = load i64, i64* %1212, align 8
  %1214 = xor i64 %1213, -9223372036854775808
  store i64 %1214, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %20, align 1, !tbaa !2433
  %1215 = trunc i64 %1213 to i32
  %1216 = and i32 %1215, 255
  %1217 = tail call i32 @llvm.ctpop.i32(i32 %1216) #10
  %1218 = trunc i32 %1217 to i8
  %1219 = and i8 %1218, 1
  %1220 = xor i8 %1219, 1
  store i8 %1220, i8* %27, align 1, !tbaa !2447
  %1221 = icmp eq i64 %1214, 0
  %1222 = zext i1 %1221 to i8
  store i8 %1222, i8* %35, align 1, !tbaa !2448
  %1223 = lshr i64 %1214, 63
  %1224 = trunc i64 %1223 to i8
  store i8 %1224, i8* %38, align 1, !tbaa !2449
  store i8 0, i8* %44, align 1, !tbaa !2450
  store i8 0, i8* %32, align 1, !tbaa !2451
  store i64 %1214, i64* %386, align 1, !tbaa !2428
  store i64 0, i64* %97, align 1, !tbaa !2428
  %1225 = load i64, i64* %RBP, align 8
  %1226 = add i64 %1225, -32
  %1227 = add i64 %1570, 48
  store i64 %1227, i64* %PC, align 8
  %1228 = inttoptr i64 %1226 to i64*
  %1229 = load i64, i64* %1228, align 8
  store i64 %1229, i64* %RAX, align 8, !tbaa !2428
  %1230 = add i64 %1225, -12
  %1231 = add i64 %1570, 51
  store i64 %1231, i64* %PC, align 8
  %1232 = inttoptr i64 %1230 to i32*
  %1233 = load i32, i32* %1232, align 4
  %1234 = shl i32 %1233, 1
  %1235 = lshr i32 %1233, 30
  %1236 = and i32 %1235, 1
  %1237 = or i32 %1234, 1
  %1238 = zext i32 %1237 to i64
  store i64 %1238, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %20, align 1, !tbaa !2433
  %1239 = and i32 %1237, 255
  %1240 = tail call i32 @llvm.ctpop.i32(i32 %1239) #10
  %1241 = trunc i32 %1240 to i8
  %1242 = and i8 %1241, 1
  %1243 = xor i8 %1242, 1
  store i8 %1243, i8* %27, align 1, !tbaa !2447
  store i8 0, i8* %32, align 1, !tbaa !2451
  store i8 0, i8* %35, align 1, !tbaa !2448
  %1244 = lshr i32 %1233, 30
  %1245 = and i32 %1244, 1
  %1246 = trunc i32 %1245 to i8
  store i8 %1246, i8* %38, align 1, !tbaa !2449
  %1247 = xor i32 %1245, %1236
  %1248 = add nuw nsw i32 %1247, %1245
  %1249 = icmp eq i32 %1248, 2
  %1250 = zext i1 %1249 to i8
  store i8 %1250, i8* %44, align 1, !tbaa !2450
  %1251 = sext i32 %1237 to i64
  store i64 %1251, i64* %RCX, align 8, !tbaa !2428
  %1252 = shl nsw i64 %1251, 3
  %1253 = add i64 %1252, %1229
  %1254 = add i64 %1570, 65
  store i64 %1254, i64* %PC, align 8
  %1255 = inttoptr i64 %1253 to i64*
  store i64 %1214, i64* %1255, align 8
  %1256 = load i64, i64* %RBP, align 8
  %1257 = add i64 %1256, -12
  %1258 = load i64, i64* %PC, align 8
  %1259 = add i64 %1258, 3
  store i64 %1259, i64* %PC, align 8
  %1260 = inttoptr i64 %1257 to i32*
  %1261 = load i32, i32* %1260, align 4
  %1262 = add i32 %1261, 1
  %1263 = zext i32 %1262 to i64
  store i64 %1263, i64* %RAX, align 8, !tbaa !2428
  %1264 = icmp eq i32 %1261, -1
  %1265 = icmp eq i32 %1262, 0
  %1266 = or i1 %1264, %1265
  %1267 = zext i1 %1266 to i8
  store i8 %1267, i8* %20, align 1, !tbaa !2433
  %1268 = and i32 %1262, 255
  %1269 = tail call i32 @llvm.ctpop.i32(i32 %1268) #10
  %1270 = trunc i32 %1269 to i8
  %1271 = and i8 %1270, 1
  %1272 = xor i8 %1271, 1
  store i8 %1272, i8* %27, align 1, !tbaa !2447
  %1273 = xor i32 %1261, %1262
  %1274 = lshr i32 %1273, 4
  %1275 = trunc i32 %1274 to i8
  %1276 = and i8 %1275, 1
  store i8 %1276, i8* %32, align 1, !tbaa !2451
  %1277 = icmp eq i32 %1262, 0
  %1278 = zext i1 %1277 to i8
  store i8 %1278, i8* %35, align 1, !tbaa !2448
  %1279 = lshr i32 %1262, 31
  %1280 = trunc i32 %1279 to i8
  store i8 %1280, i8* %38, align 1, !tbaa !2449
  %1281 = lshr i32 %1261, 31
  %1282 = xor i32 %1279, %1281
  %1283 = add nuw nsw i32 %1282, %1279
  %1284 = icmp eq i32 %1283, 2
  %1285 = zext i1 %1284 to i8
  store i8 %1285, i8* %44, align 1, !tbaa !2450
  %1286 = add i64 %1258, 9
  store i64 %1286, i64* %PC, align 8
  store i32 %1262, i32* %1260, align 4
  %1287 = load i64, i64* %PC, align 8
  %1288 = add i64 %1287, -87
  store i64 %1288, i64* %65, align 8, !tbaa !2428
  br label %block_400a2f

block_4009b2:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2
  store i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 112), i64* %RDI, align 8, !tbaa !2428
  %1289 = load i64, i64* %RBP, align 8
  %1290 = add i64 %1289, -96
  %1291 = add i64 %430, 15
  store i64 %1291, i64* %PC, align 8
  %1292 = inttoptr i64 %1290 to i64*
  %1293 = load i64, i64* %1292, align 8
  %1294 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1293, i64* %1294, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  store i8 1, i8* %AL, align 1, !tbaa !2432
  %1295 = add i64 %430, -802
  %1296 = add i64 %430, 22
  %1297 = load i64, i64* %12, align 8, !tbaa !2428
  %1298 = add i64 %1297, -8
  %1299 = inttoptr i64 %1298 to i64*
  store i64 %1296, i64* %1299, align 8
  store i64 %1298, i64* %12, align 8, !tbaa !2428
  store i64 %1295, i64* %65, align 8, !tbaa !2428
  %1300 = tail call fastcc %struct.Memory* @ext_6050a0_printf(%struct.State* nonnull %0, %struct.Memory* %425)
  %1301 = load i64, i64* %RBP, align 8
  %1302 = add i64 %1301, -156
  %1303 = load i32, i32* %EAX, align 4
  %1304 = load i64, i64* %PC, align 8
  %1305 = add i64 %1304, 6
  store i64 %1305, i64* %PC, align 8
  %1306 = inttoptr i64 %1302 to i32*
  store i32 %1303, i32* %1306, align 4
  %1307 = load i64, i64* %PC, align 8
  %1308 = add i64 %1307, -862
  %1309 = add i64 %1307, 5
  %1310 = load i64, i64* %12, align 8, !tbaa !2428
  %1311 = add i64 %1310, -8
  %1312 = inttoptr i64 %1311 to i64*
  store i64 %1309, i64* %1312, align 8
  store i64 %1311, i64* %12, align 8, !tbaa !2428
  store i64 %1308, i64* %65, align 8, !tbaa !2428
  %1313 = tail call fastcc %struct.Memory* @ext_400670_abort(%struct.State* nonnull %0, %struct.Memory* %1300)
  %1314 = load i64, i64* %PC, align 8
  %1315 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull %0, i64 %1314, %struct.Memory* %1313)
  ret %struct.Memory* %1315

block_400ca3:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1
  %1316 = load i64, i64* %RBP, align 8
  %1317 = add i64 %1316, -40
  %1318 = add i64 %618, 4
  store i64 %1318, i64* %PC, align 8
  %1319 = inttoptr i64 %1317 to i64*
  %1320 = load i64, i64* %1319, align 8
  store i64 %1320, i64* %RAX, align 8, !tbaa !2428
  %1321 = add i64 %1316, -12
  %1322 = add i64 %618, 7
  store i64 %1322, i64* %PC, align 8
  %1323 = inttoptr i64 %1321 to i32*
  %1324 = load i32, i32* %1323, align 4
  %1325 = shl i32 %1324, 1
  %1326 = icmp slt i32 %1324, 0
  %1327 = icmp slt i32 %1325, 0
  %1328 = xor i1 %1326, %1327
  %1329 = zext i32 %1325 to i64
  store i64 %1329, i64* %RCX, align 8, !tbaa !2428
  %.lobit36 = lshr i32 %1324, 31
  %1330 = trunc i32 %.lobit36 to i8
  store i8 %1330, i8* %20, align 1, !tbaa !2432
  %1331 = and i32 %1325, 254
  %1332 = tail call i32 @llvm.ctpop.i32(i32 %1331) #10
  %1333 = trunc i32 %1332 to i8
  %1334 = and i8 %1333, 1
  %1335 = xor i8 %1334, 1
  store i8 %1335, i8* %27, align 1, !tbaa !2432
  store i8 0, i8* %32, align 1, !tbaa !2432
  %1336 = icmp eq i32 %1325, 0
  %1337 = zext i1 %1336 to i8
  store i8 %1337, i8* %35, align 1, !tbaa !2432
  %1338 = lshr i32 %1324, 30
  %1339 = trunc i32 %1338 to i8
  %1340 = and i8 %1339, 1
  store i8 %1340, i8* %38, align 1, !tbaa !2432
  %1341 = zext i1 %1328 to i8
  store i8 %1341, i8* %44, align 1, !tbaa !2432
  %1342 = sext i32 %1325 to i64
  store i64 %1342, i64* %RDX, align 8, !tbaa !2428
  %1343 = shl nsw i64 %1342, 3
  %1344 = add i64 %1343, %1320
  %1345 = add i64 %618, 18
  store i64 %1345, i64* %PC, align 8
  %1346 = inttoptr i64 %1344 to double*
  %1347 = load double, double* %1346, align 8
  store double %1347, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %1348 = add i64 %618, 26
  store i64 %1348, i64* %PC, align 8
  br label %block_400cd2

block_400d14:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %1349 = load i64, i64* %RBP, align 8
  %1350 = add i64 %1349, -40
  %1351 = add i64 %743, 4
  store i64 %1351, i64* %PC, align 8
  %1352 = inttoptr i64 %1350 to i64*
  %1353 = load i64, i64* %1352, align 8
  store i64 %1353, i64* %RAX, align 8, !tbaa !2428
  %1354 = add i64 %1349, -12
  %1355 = add i64 %743, 7
  store i64 %1355, i64* %PC, align 8
  %1356 = inttoptr i64 %1354 to i32*
  %1357 = load i32, i32* %1356, align 4
  %1358 = shl i32 %1357, 1
  %1359 = lshr i32 %1357, 30
  %1360 = and i32 %1359, 1
  %1361 = or i32 %1358, 1
  %1362 = zext i32 %1361 to i64
  store i64 %1362, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %20, align 1, !tbaa !2433
  %1363 = and i32 %1361, 255
  %1364 = tail call i32 @llvm.ctpop.i32(i32 %1363) #10
  %1365 = trunc i32 %1364 to i8
  %1366 = and i8 %1365, 1
  %1367 = xor i8 %1366, 1
  store i8 %1367, i8* %27, align 1, !tbaa !2447
  store i8 0, i8* %32, align 1, !tbaa !2451
  store i8 0, i8* %35, align 1, !tbaa !2448
  %1368 = lshr i32 %1357, 30
  %1369 = and i32 %1368, 1
  %1370 = trunc i32 %1369 to i8
  store i8 %1370, i8* %38, align 1, !tbaa !2449
  %1371 = xor i32 %1369, %1360
  %1372 = add nuw nsw i32 %1371, %1369
  %1373 = icmp eq i32 %1372, 2
  %1374 = zext i1 %1373 to i8
  store i8 %1374, i8* %44, align 1, !tbaa !2450
  %1375 = sext i32 %1361 to i64
  store i64 %1375, i64* %RDX, align 8, !tbaa !2428
  %1376 = shl nsw i64 %1375, 3
  %1377 = add i64 %1376, %1353
  %1378 = add i64 %743, 21
  store i64 %1378, i64* %PC, align 8
  %1379 = inttoptr i64 %1377 to double*
  %1380 = load double, double* %1379, align 8
  store double %1380, double* %96, align 1, !tbaa !2452
  store double 0.000000e+00, double* %98, align 1, !tbaa !2452
  %1381 = add i64 %743, 29
  store i64 %1381, i64* %PC, align 8
  br label %block_400d46

block_400d8e:                                     ; preds = %block_400c67
  %1382 = add i64 %1634, -32
  %1383 = add i64 %1662, 4
  store i64 %1383, i64* %PC, align 8
  %1384 = inttoptr i64 %1382 to i64*
  %1385 = load i64, i64* %1384, align 8
  store i64 %1385, i64* %RAX, align 8, !tbaa !2428
  store i64 %1385, i64* %RDI, align 8, !tbaa !2428
  %1386 = add i64 %1662, -1838
  %1387 = add i64 %1662, 12
  %1388 = load i64, i64* %12, align 8, !tbaa !2428
  %1389 = add i64 %1388, -8
  %1390 = inttoptr i64 %1389 to i64*
  store i64 %1387, i64* %1390, align 8
  store i64 %1389, i64* %12, align 8, !tbaa !2428
  store i64 %1386, i64* %65, align 8, !tbaa !2428
  %1391 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %MEMORY.5)
  %1392 = load i64, i64* %RBP, align 8
  %1393 = add i64 %1392, -56
  %1394 = load i64, i64* %PC, align 8
  %1395 = add i64 %1394, 4
  store i64 %1395, i64* %PC, align 8
  %1396 = inttoptr i64 %1393 to i64*
  %1397 = load i64, i64* %1396, align 8
  store i64 %1397, i64* %RAX, align 8, !tbaa !2428
  store i64 %1397, i64* %RDI, align 8, !tbaa !2428
  %1398 = add i64 %1394, -1850
  %1399 = add i64 %1394, 12
  %1400 = load i64, i64* %12, align 8, !tbaa !2428
  %1401 = add i64 %1400, -8
  %1402 = inttoptr i64 %1401 to i64*
  store i64 %1399, i64* %1402, align 8
  store i64 %1401, i64* %12, align 8, !tbaa !2428
  store i64 %1398, i64* %65, align 8, !tbaa !2428
  %1403 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %1391)
  %1404 = load i64, i64* %RBP, align 8
  %1405 = add i64 %1404, -24
  %1406 = load i64, i64* %PC, align 8
  %1407 = add i64 %1406, 4
  store i64 %1407, i64* %PC, align 8
  %1408 = inttoptr i64 %1405 to i64*
  %1409 = load i64, i64* %1408, align 8
  store i64 %1409, i64* %RAX, align 8, !tbaa !2428
  store i64 %1409, i64* %RDI, align 8, !tbaa !2428
  %1410 = add i64 %1406, -1862
  %1411 = add i64 %1406, 12
  %1412 = load i64, i64* %12, align 8, !tbaa !2428
  %1413 = add i64 %1412, -8
  %1414 = inttoptr i64 %1413 to i64*
  store i64 %1411, i64* %1414, align 8
  store i64 %1413, i64* %12, align 8, !tbaa !2428
  store i64 %1410, i64* %65, align 8, !tbaa !2428
  %1415 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %1403)
  %1416 = load i64, i64* %RBP, align 8
  %1417 = add i64 %1416, -40
  %1418 = load i64, i64* %PC, align 8
  %1419 = add i64 %1418, 4
  store i64 %1419, i64* %PC, align 8
  %1420 = inttoptr i64 %1417 to i64*
  %1421 = load i64, i64* %1420, align 8
  store i64 %1421, i64* %RAX, align 8, !tbaa !2428
  store i64 %1421, i64* %RDI, align 8, !tbaa !2428
  %1422 = add i64 %1418, -1874
  %1423 = add i64 %1418, 12
  %1424 = load i64, i64* %12, align 8, !tbaa !2428
  %1425 = add i64 %1424, -8
  %1426 = inttoptr i64 %1425 to i64*
  store i64 %1423, i64* %1426, align 8
  store i64 %1425, i64* %12, align 8, !tbaa !2428
  store i64 %1422, i64* %65, align 8, !tbaa !2428
  %1427 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %1415)
  %1428 = load i64, i64* %RBP, align 8
  %1429 = add i64 %1428, -48
  %1430 = load i64, i64* %PC, align 8
  %1431 = add i64 %1430, 4
  store i64 %1431, i64* %PC, align 8
  %1432 = inttoptr i64 %1429 to i64*
  %1433 = load i64, i64* %1432, align 8
  store i64 %1433, i64* %RAX, align 8, !tbaa !2428
  store i64 %1433, i64* %RDI, align 8, !tbaa !2428
  %1434 = add i64 %1430, -1886
  %1435 = add i64 %1430, 12
  %1436 = load i64, i64* %12, align 8, !tbaa !2428
  %1437 = add i64 %1436, -8
  %1438 = inttoptr i64 %1437 to i64*
  store i64 %1435, i64* %1438, align 8
  store i64 %1437, i64* %12, align 8, !tbaa !2428
  store i64 %1434, i64* %65, align 8, !tbaa !2428
  %1439 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %1427)
  %1440 = load i64, i64* %PC, align 8
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  %1441 = load i64, i64* %RSP, align 8
  %1442 = add i64 %1441, 224
  store i64 %1442, i64* %RSP, align 8, !tbaa !2428
  %1443 = icmp ugt i64 %1441, -225
  %1444 = zext i1 %1443 to i8
  store i8 %1444, i8* %20, align 1, !tbaa !2433
  %1445 = trunc i64 %1442 to i32
  %1446 = and i32 %1445, 255
  %1447 = tail call i32 @llvm.ctpop.i32(i32 %1446) #10
  %1448 = trunc i32 %1447 to i8
  %1449 = and i8 %1448, 1
  %1450 = xor i8 %1449, 1
  store i8 %1450, i8* %27, align 1, !tbaa !2447
  %1451 = xor i64 %1441, %1442
  %1452 = lshr i64 %1451, 4
  %1453 = trunc i64 %1452 to i8
  %1454 = and i8 %1453, 1
  store i8 %1454, i8* %32, align 1, !tbaa !2451
  %1455 = icmp eq i64 %1442, 0
  %1456 = zext i1 %1455 to i8
  store i8 %1456, i8* %35, align 1, !tbaa !2448
  %1457 = lshr i64 %1442, 63
  %1458 = trunc i64 %1457 to i8
  store i8 %1458, i8* %38, align 1, !tbaa !2449
  %1459 = lshr i64 %1441, 63
  %1460 = xor i64 %1457, %1459
  %1461 = add nuw nsw i64 %1460, %1457
  %1462 = icmp eq i64 %1461, 2
  %1463 = zext i1 %1462 to i8
  store i8 %1463, i8* %44, align 1, !tbaa !2450
  %1464 = add i64 %1440, 10
  store i64 %1464, i64* %PC, align 8
  %1465 = add i64 %1441, 232
  %1466 = inttoptr i64 %1442 to i64*
  %1467 = load i64, i64* %1466, align 8
  store i64 %1467, i64* %RBP, align 8, !tbaa !2428
  store i64 %1465, i64* %12, align 8, !tbaa !2428
  %1468 = add i64 %1440, 11
  store i64 %1468, i64* %PC, align 8
  %1469 = inttoptr i64 %1465 to i64*
  %1470 = load i64, i64* %1469, align 8
  store i64 %1470, i64* %65, align 8, !tbaa !2428
  %1471 = add i64 %1441, 240
  store i64 %1471, i64* %12, align 8, !tbaa !2428
  ret %struct.Memory* %1439

block_4009d3:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %20, align 1, !tbaa !2433
  store i8 1, i8* %27, align 1, !tbaa !2447
  store i8 1, i8* %35, align 1, !tbaa !2448
  store i8 0, i8* %38, align 1, !tbaa !2449
  store i8 0, i8* %44, align 1, !tbaa !2450
  store i8 0, i8* %32, align 1, !tbaa !2451
  store i64 1023, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RCX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %1472 = load i64, i64* %RBP, align 8
  %1473 = add i64 %1472, -32
  %1474 = add i64 %430, 18
  store i64 %1474, i64* %PC, align 8
  %1475 = inttoptr i64 %1473 to i64*
  %1476 = load i64, i64* %1475, align 8
  store i64 %1476, i64* %RDI, align 8, !tbaa !2428
  %1477 = add i64 %1472, -160
  %1478 = add i64 %430, 24
  store i64 %1478, i64* %PC, align 8
  %1479 = inttoptr i64 %1477 to i32*
  store i32 1023, i32* %1479, align 4
  %1480 = load i32, i32* %EAX, align 4
  %1481 = zext i32 %1480 to i64
  %1482 = load i64, i64* %PC, align 8
  store i64 %1481, i64* %RSI, align 8, !tbaa !2428
  %1483 = load i64, i64* %RBP, align 8
  %1484 = add i64 %1483, -164
  %1485 = add i64 %1482, 8
  store i64 %1485, i64* %PC, align 8
  %1486 = inttoptr i64 %1484 to i32*
  store i32 %1480, i32* %1486, align 4
  %1487 = load i64, i64* %PC, align 8
  %1488 = add i64 %1487, -835
  %1489 = add i64 %1487, 5
  %1490 = load i64, i64* %12, align 8, !tbaa !2428
  %1491 = add i64 %1490, -8
  %1492 = inttoptr i64 %1491 to i64*
  store i64 %1489, i64* %1492, align 8
  store i64 %1491, i64* %12, align 8, !tbaa !2428
  store i64 %1488, i64* %65, align 8, !tbaa !2428
  %1493 = tail call fastcc %struct.Memory* @ext_605110_memset(%struct.State* nonnull %0, %struct.Memory* %425)
  %1494 = load i64, i64* %RBP, align 8
  %1495 = add i64 %1494, -32
  %1496 = load i64, i64* %PC, align 8
  %1497 = add i64 %1496, 4
  store i64 %1497, i64* %PC, align 8
  %1498 = inttoptr i64 %1495 to i64*
  %1499 = load i64, i64* %1498, align 8
  store i64 %1499, i64* %RDX, align 8, !tbaa !2428
  %1500 = add i64 %1494, -164
  %1501 = add i64 %1496, 10
  store i64 %1501, i64* %PC, align 8
  %1502 = inttoptr i64 %1500 to i32*
  %1503 = load i32, i32* %1502, align 4
  %1504 = zext i32 %1503 to i64
  store i64 %1504, i64* %RDI, align 8, !tbaa !2428
  %1505 = add i64 %1494, -160
  %1506 = add i64 %1496, 16
  store i64 %1506, i64* %PC, align 8
  %1507 = inttoptr i64 %1505 to i32*
  %1508 = load i32, i32* %1507, align 4
  %1509 = zext i32 %1508 to i64
  store i64 %1509, i64* %RSI, align 8, !tbaa !2428
  %1510 = add i64 %1496, 1464
  %1511 = add i64 %1496, 21
  %1512 = load i64, i64* %12, align 8, !tbaa !2428
  %1513 = add i64 %1512, -8
  %1514 = inttoptr i64 %1513 to i64*
  store i64 %1511, i64* %1514, align 8
  store i64 %1513, i64* %12, align 8, !tbaa !2428
  store i64 %1510, i64* %65, align 8, !tbaa !2428
  %1515 = tail call %struct.Memory* @sub_400fb0_putdata_renamed_(%struct.State* nonnull %0, i64 %1510, %struct.Memory* %1493)
  %1516 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  %1517 = load i64, i64* %RBP, align 8
  %1518 = add i64 %1517, -32
  %1519 = add i64 %1516, 14
  store i64 %1519, i64* %PC, align 8
  %1520 = inttoptr i64 %1518 to i64*
  %1521 = load i64, i64* %1520, align 8
  store i64 %1521, i64* %RDX, align 8, !tbaa !2428
  %1522 = add i64 %1517, -24
  %1523 = add i64 %1516, 18
  store i64 %1523, i64* %PC, align 8
  %1524 = inttoptr i64 %1522 to i64*
  %1525 = load i64, i64* %1524, align 8
  store i64 %1525, i64* %RCX, align 8, !tbaa !2428
  %1526 = add i64 %1517, -56
  %1527 = add i64 %1516, 22
  store i64 %1527, i64* %PC, align 8
  %1528 = inttoptr i64 %1526 to i64*
  %1529 = load i64, i64* %1528, align 8
  store i64 %1529, i64* %R8, align 8, !tbaa !2428
  %1530 = add i64 %1516, 1571
  %1531 = add i64 %1516, 27
  %1532 = load i64, i64* %12, align 8, !tbaa !2428
  %1533 = add i64 %1532, -8
  %1534 = inttoptr i64 %1533 to i64*
  store i64 %1531, i64* %1534, align 8
  store i64 %1533, i64* %12, align 8, !tbaa !2428
  store i64 %1530, i64* %65, align 8, !tbaa !2428
  %1535 = tail call %struct.Memory* @sub_401030_cdft_renamed_(%struct.State* nonnull %0, i64 %1530, %struct.Memory* %1515)
  %1536 = load i64, i64* %RBP, align 8
  %1537 = add i64 %1536, -12
  %1538 = load i64, i64* %PC, align 8
  %1539 = add i64 %1538, 7
  store i64 %1539, i64* %PC, align 8
  %1540 = inttoptr i64 %1537 to i32*
  store i32 0, i32* %1540, align 4
  %.pre5 = load i64, i64* %PC, align 8
  br label %block_400a2f

block_400a2f:                                     ; preds = %block_4009d3, %block_400a3c
  %1541 = phi i64 [ %.pre5, %block_4009d3 ], [ %1288, %block_400a3c ]
  %1542 = load i64, i64* %RBP, align 8
  %1543 = add i64 %1542, -12
  %1544 = add i64 %1541, 7
  store i64 %1544, i64* %PC, align 8
  %1545 = inttoptr i64 %1543 to i32*
  %1546 = load i32, i32* %1545, align 4
  %1547 = add i32 %1546, -1024
  %1548 = icmp ult i32 %1546, 1024
  %1549 = zext i1 %1548 to i8
  store i8 %1549, i8* %20, align 1, !tbaa !2433
  %1550 = and i32 %1547, 255
  %1551 = tail call i32 @llvm.ctpop.i32(i32 %1550) #10
  %1552 = trunc i32 %1551 to i8
  %1553 = and i8 %1552, 1
  %1554 = xor i8 %1553, 1
  store i8 %1554, i8* %27, align 1, !tbaa !2447
  %1555 = xor i32 %1546, %1547
  %1556 = lshr i32 %1555, 4
  %1557 = trunc i32 %1556 to i8
  %1558 = and i8 %1557, 1
  store i8 %1558, i8* %32, align 1, !tbaa !2451
  %1559 = icmp eq i32 %1547, 0
  %1560 = zext i1 %1559 to i8
  store i8 %1560, i8* %35, align 1, !tbaa !2448
  %1561 = lshr i32 %1547, 31
  %1562 = trunc i32 %1561 to i8
  store i8 %1562, i8* %38, align 1, !tbaa !2449
  %1563 = lshr i32 %1546, 31
  %1564 = xor i32 %1561, %1563
  %1565 = add nuw nsw i32 %1564, %1563
  %1566 = icmp eq i32 %1565, 2
  %1567 = zext i1 %1566 to i8
  store i8 %1567, i8* %44, align 1, !tbaa !2450
  %1568 = icmp ne i8 %1562, 0
  %1569 = xor i1 %1568, %1566
  %.v28 = select i1 %1569, i64 13, i64 92
  %1570 = add i64 %1541, %.v28
  store i64 %1570, i64* %65, align 8, !tbaa !2428
  br i1 %1569, label %block_400a3c, label %block_400a8b

block_400a8b:                                     ; preds = %block_400a2f
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %20, align 1, !tbaa !2433
  store i8 1, i8* %27, align 1, !tbaa !2447
  store i8 1, i8* %35, align 1, !tbaa !2448
  store i8 0, i8* %38, align 1, !tbaa !2449
  store i8 0, i8* %44, align 1, !tbaa !2450
  store i8 0, i8* %32, align 1, !tbaa !2451
  store i64 1023, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RCX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %1571 = add i64 %1542, -48
  %1572 = add i64 %1570, 18
  store i64 %1572, i64* %PC, align 8
  %1573 = inttoptr i64 %1571 to i64*
  %1574 = load i64, i64* %1573, align 8
  store i64 %1574, i64* %RDI, align 8, !tbaa !2428
  %1575 = add i64 %1542, -168
  %1576 = add i64 %1570, 24
  store i64 %1576, i64* %PC, align 8
  %1577 = inttoptr i64 %1575 to i32*
  store i32 1023, i32* %1577, align 4
  %1578 = load i32, i32* %EAX, align 4
  %1579 = zext i32 %1578 to i64
  %1580 = load i64, i64* %PC, align 8
  store i64 %1579, i64* %RSI, align 8, !tbaa !2428
  %1581 = load i64, i64* %RBP, align 8
  %1582 = add i64 %1581, -172
  %1583 = add i64 %1580, 8
  store i64 %1583, i64* %PC, align 8
  %1584 = inttoptr i64 %1582 to i32*
  store i32 %1578, i32* %1584, align 4
  %1585 = load i64, i64* %PC, align 8
  %1586 = add i64 %1585, -1019
  %1587 = add i64 %1585, 5
  %1588 = load i64, i64* %12, align 8, !tbaa !2428
  %1589 = add i64 %1588, -8
  %1590 = inttoptr i64 %1589 to i64*
  store i64 %1587, i64* %1590, align 8
  store i64 %1589, i64* %12, align 8, !tbaa !2428
  store i64 %1586, i64* %65, align 8, !tbaa !2428
  %1591 = tail call fastcc %struct.Memory* @ext_605110_memset(%struct.State* nonnull %0, %struct.Memory* %1535)
  %1592 = load i64, i64* %RBP, align 8
  %1593 = add i64 %1592, -48
  %1594 = load i64, i64* %PC, align 8
  %1595 = add i64 %1594, 4
  store i64 %1595, i64* %PC, align 8
  %1596 = inttoptr i64 %1593 to i64*
  %1597 = load i64, i64* %1596, align 8
  store i64 %1597, i64* %RDX, align 8, !tbaa !2428
  %1598 = add i64 %1592, -172
  %1599 = add i64 %1594, 10
  store i64 %1599, i64* %PC, align 8
  %1600 = inttoptr i64 %1598 to i32*
  %1601 = load i32, i32* %1600, align 4
  %1602 = zext i32 %1601 to i64
  store i64 %1602, i64* %RDI, align 8, !tbaa !2428
  %1603 = add i64 %1592, -168
  %1604 = add i64 %1594, 16
  store i64 %1604, i64* %PC, align 8
  %1605 = inttoptr i64 %1603 to i32*
  %1606 = load i32, i32* %1605, align 4
  %1607 = zext i32 %1606 to i64
  store i64 %1607, i64* %RSI, align 8, !tbaa !2428
  %1608 = add i64 %1594, 1280
  %1609 = add i64 %1594, 21
  %1610 = load i64, i64* %12, align 8, !tbaa !2428
  %1611 = add i64 %1610, -8
  %1612 = inttoptr i64 %1611 to i64*
  store i64 %1609, i64* %1612, align 8
  store i64 %1611, i64* %12, align 8, !tbaa !2428
  store i64 %1608, i64* %65, align 8, !tbaa !2428
  %1613 = tail call %struct.Memory* @sub_400fb0_putdata_renamed_(%struct.State* nonnull %0, i64 %1608, %struct.Memory* %1591)
  %1614 = load i64, i64* %PC, align 8
  %1615 = add i64 %1614, 795
  %1616 = add i64 %1614, 5
  %1617 = load i64, i64* %12, align 8, !tbaa !2428
  %1618 = add i64 %1617, -8
  %1619 = inttoptr i64 %1618 to i64*
  store i64 %1616, i64* %1619, align 8
  store i64 %1618, i64* %12, align 8, !tbaa !2428
  store i64 %1615, i64* %65, align 8, !tbaa !2428
  %1620 = tail call %struct.Memory* @sub_400de0_get_time_renamed_(%struct.State* nonnull %0, i64 %1615, %struct.Memory* %1613)
  %1621 = load i64, i64* %RBP, align 8
  %1622 = add i64 %1621, -64
  %1623 = load i64, i64* %PC, align 8
  %1624 = add i64 %1623, 5
  store i64 %1624, i64* %PC, align 8
  %1625 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %1626 = load i64, i64* %1625, align 1
  %1627 = inttoptr i64 %1622 to i64*
  store i64 %1626, i64* %1627, align 8
  %1628 = load i64, i64* %RBP, align 8
  %1629 = add i64 %1628, -8
  %1630 = load i64, i64* %PC, align 8
  %1631 = add i64 %1630, 7
  store i64 %1631, i64* %PC, align 8
  %1632 = inttoptr i64 %1629 to i32*
  store i32 0, i32* %1632, align 4
  %.pre6 = load i64, i64* %PC, align 8
  br label %block_400ad6

block_400c67:                                     ; preds = %block_400c3d, %block_400d46
  %1633 = phi i64 [ %.pre8, %block_400c3d ], [ %818, %block_400d46 ]
  %MEMORY.5 = phi %struct.Memory* [ %1106, %block_400c3d ], [ %779, %block_400d46 ]
  %1634 = load i64, i64* %RBP, align 8
  %1635 = add i64 %1634, -12
  %1636 = add i64 %1633, 7
  store i64 %1636, i64* %PC, align 8
  %1637 = inttoptr i64 %1635 to i32*
  %1638 = load i32, i32* %1637, align 4
  %1639 = add i32 %1638, -1024
  %1640 = icmp ult i32 %1638, 1024
  %1641 = zext i1 %1640 to i8
  store i8 %1641, i8* %20, align 1, !tbaa !2433
  %1642 = and i32 %1639, 255
  %1643 = tail call i32 @llvm.ctpop.i32(i32 %1642) #10
  %1644 = trunc i32 %1643 to i8
  %1645 = and i8 %1644, 1
  %1646 = xor i8 %1645, 1
  store i8 %1646, i8* %27, align 1, !tbaa !2447
  %1647 = xor i32 %1638, %1639
  %1648 = lshr i32 %1647, 4
  %1649 = trunc i32 %1648 to i8
  %1650 = and i8 %1649, 1
  store i8 %1650, i8* %32, align 1, !tbaa !2451
  %1651 = icmp eq i32 %1639, 0
  %1652 = zext i1 %1651 to i8
  store i8 %1652, i8* %35, align 1, !tbaa !2448
  %1653 = lshr i32 %1639, 31
  %1654 = trunc i32 %1653 to i8
  store i8 %1654, i8* %38, align 1, !tbaa !2449
  %1655 = lshr i32 %1638, 31
  %1656 = xor i32 %1653, %1655
  %1657 = add nuw nsw i32 %1656, %1655
  %1658 = icmp eq i32 %1657, 2
  %1659 = zext i1 %1658 to i8
  store i8 %1659, i8* %44, align 1, !tbaa !2450
  %1660 = icmp ne i8 %1654, 0
  %1661 = xor i1 %1660, %1658
  %.v33 = select i1 %1661, i64 13, i64 295
  %1662 = add i64 %1633, %.v33
  store i64 %1662, i64* %65, align 8, !tbaa !2428
  br i1 %1661, label %block_400c74, label %block_400d8e

block_400d36:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  store i32 0, i32* %393, align 1, !tbaa !2459
  store i32 0, i32* %395, align 1, !tbaa !2459
  store i32 0, i32* %396, align 1, !tbaa !2459
  store i32 0, i32* %398, align 1, !tbaa !2459
  %1663 = load i64, i64* %RBP, align 8
  %1664 = add i64 %743, 11
  store i64 %1664, i64* %PC, align 8
  %1665 = load double, double* %71, align 1
  br label %block_400d46
}

; Function Attrs: noinline
define %struct.Memory* @sub_400de0_get_time(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400de0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %7 = load i64, i64* %RBP, align 8
  %8 = add i64 %1, 1
  store i64 %8, i64* %PC, align 8
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %10 = load i64, i64* %9, align 8, !tbaa !2428
  %11 = add i64 %10, -8
  %12 = inttoptr i64 %11 to i64*
  store i64 %7, i64* %12, align 8
  %13 = load i64, i64* %PC, align 8
  store i64 %11, i64* %RBP, align 8, !tbaa !2428
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %20 = add i64 %10, -24
  store i64 %20, i64* %RDI, align 8, !tbaa !2428
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2433
  store i8 1, i8* %15, align 1, !tbaa !2447
  store i8 1, i8* %17, align 1, !tbaa !2448
  store i8 0, i8* %18, align 1, !tbaa !2449
  store i8 0, i8* %19, align 1, !tbaa !2450
  store i8 0, i8* %16, align 1, !tbaa !2451
  store i64 0, i64* %RSI, align 8, !tbaa !2428
  %21 = add i64 %13, -1857
  %22 = add i64 %13, 20
  %23 = add i64 %10, -48
  %24 = inttoptr i64 %23 to i64*
  store i64 %22, i64* %24, align 8
  store i64 %23, i64* %9, align 8, !tbaa !2428
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %21, i64* %25, align 8, !tbaa !2428
  %26 = tail call fastcc %struct.Memory* @ext_4006a0_gettimeofday(%struct.State* nonnull %0, %struct.Memory* %2)
  %27 = bitcast [32 x %union.VectorReg]* %4 to i8*
  %28 = load i64, i64* %PC, align 8
  %29 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 56) to double*), align 8
  %30 = bitcast [32 x %union.VectorReg]* %4 to double*
  store double %29, double* %30, align 1, !tbaa !2452
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %32 = bitcast i64* %31 to double*
  store double 0.000000e+00, double* %32, align 1, !tbaa !2452
  %33 = load i64, i64* %RBP, align 8
  %34 = add i64 %33, -16
  %35 = add i64 %28, 12
  store i64 %35, i64* %PC, align 8
  %36 = inttoptr i64 %34 to i64*
  %37 = load i64, i64* %36, align 8
  store i64 %37, i64* %RSI, align 8, !tbaa !2428
  %38 = sitofp i64 %37 to double
  %39 = bitcast %union.VectorReg* %5 to double*
  store double %38, double* %39, align 1, !tbaa !2452
  %40 = add i64 %33, -8
  %41 = add i64 %28, 21
  store i64 %41, i64* %PC, align 8
  %42 = inttoptr i64 %40 to i64*
  %43 = load i64, i64* %42, align 8
  store i64 %43, i64* %RSI, align 8, !tbaa !2428
  %44 = sitofp i64 %43 to double
  %45 = bitcast %union.VectorReg* %6 to double*
  %46 = fmul double %44, %29
  store double %46, double* %45, align 1, !tbaa !2452
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %48 = bitcast i64* %47 to <2 x i32>*
  %49 = load <2 x i32>, <2 x i32>* %48, align 1
  %50 = fadd double %38, %46
  store double %50, double* %39, align 1, !tbaa !2452
  %51 = bitcast double %50 to <2 x i32>
  %52 = extractelement <2 x i32> %51, i32 0
  %53 = bitcast [32 x %union.VectorReg]* %4 to i32*
  store i32 %52, i32* %53, align 1, !tbaa !2475
  %54 = extractelement <2 x i32> %51, i32 1
  %55 = getelementptr inbounds i8, i8* %27, i64 4
  %56 = bitcast i8* %55 to i32*
  store i32 %54, i32* %56, align 1, !tbaa !2475
  %57 = extractelement <2 x i32> %49, i32 0
  %58 = bitcast i64* %31 to i32*
  store i32 %57, i32* %58, align 1, !tbaa !2475
  %59 = extractelement <2 x i32> %49, i32 1
  %60 = getelementptr inbounds i8, i8* %27, i64 12
  %61 = bitcast i8* %60 to i32*
  store i32 %59, i32* %61, align 1, !tbaa !2475
  %62 = add i64 %33, -20
  %63 = load i32, i32* %EAX, align 4
  %64 = add i64 %28, 40
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %62 to i32*
  store i32 %63, i32* %65, align 4
  %66 = load i64, i64* %RSP, align 8
  %67 = load i64, i64* %PC, align 8
  %68 = add i64 %66, 32
  store i64 %68, i64* %RSP, align 8, !tbaa !2428
  %69 = icmp ugt i64 %66, -33
  %70 = zext i1 %69 to i8
  store i8 %70, i8* %14, align 1, !tbaa !2433
  %71 = trunc i64 %68 to i32
  %72 = and i32 %71, 255
  %73 = tail call i32 @llvm.ctpop.i32(i32 %72) #10
  %74 = trunc i32 %73 to i8
  %75 = and i8 %74, 1
  %76 = xor i8 %75, 1
  store i8 %76, i8* %15, align 1, !tbaa !2447
  %77 = xor i64 %66, %68
  %78 = lshr i64 %77, 4
  %79 = trunc i64 %78 to i8
  %80 = and i8 %79, 1
  store i8 %80, i8* %16, align 1, !tbaa !2451
  %81 = icmp eq i64 %68, 0
  %82 = zext i1 %81 to i8
  store i8 %82, i8* %17, align 1, !tbaa !2448
  %83 = lshr i64 %68, 63
  %84 = trunc i64 %83 to i8
  store i8 %84, i8* %18, align 1, !tbaa !2449
  %85 = lshr i64 %66, 63
  %86 = xor i64 %83, %85
  %87 = add nuw nsw i64 %86, %83
  %88 = icmp eq i64 %87, 2
  %89 = zext i1 %88 to i8
  store i8 %89, i8* %19, align 1, !tbaa !2450
  %90 = add i64 %67, 5
  store i64 %90, i64* %PC, align 8
  %91 = add i64 %66, 40
  %92 = inttoptr i64 %68 to i64*
  %93 = load i64, i64* %92, align 8
  store i64 %93, i64* %RBP, align 8, !tbaa !2428
  store i64 %91, i64* %9, align 8, !tbaa !2428
  %94 = add i64 %67, 6
  store i64 %94, i64* %PC, align 8
  %95 = inttoptr i64 %91 to i64*
  %96 = load i64, i64* %95, align 8
  store i64 %96, i64* %25, align 8, !tbaa !2428
  %97 = add i64 %66, 48
  store i64 %97, i64* %9, align 8, !tbaa !2428
  ret %struct.Memory* %26
}

; Function Attrs: noinline
define %struct.Memory* @sub_401be0_bitrv2conj(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_401be0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %8 = load i64, i64* %7, align 8, !tbaa !2428
  %9 = add i64 %8, -8
  %10 = inttoptr i64 %9 to i64*
  store i64 %5, i64* %10, align 8
  store i64 %9, i64* %7, align 8, !tbaa !2428
  %11 = load i64, i64* %PC, align 8
  store i64 %9, i64* %RBP, align 8, !tbaa !2428
  %12 = add i64 %8, -12
  %13 = load i32, i32* %EDI, align 4
  %14 = add i64 %11, 6
  store i64 %14, i64* %PC, align 8
  %15 = inttoptr i64 %12 to i32*
  store i32 %13, i32* %15, align 4
  %16 = load i64, i64* %RBP, align 8
  %17 = add i64 %16, -16
  %18 = load i64, i64* %RSI, align 8
  %19 = load i64, i64* %PC, align 8
  %20 = add i64 %19, 4
  store i64 %20, i64* %PC, align 8
  %21 = inttoptr i64 %17 to i64*
  store i64 %18, i64* %21, align 8
  %22 = load i64, i64* %RBP, align 8
  %23 = add i64 %22, -24
  %24 = load i64, i64* %RDX, align 8
  %25 = load i64, i64* %PC, align 8
  %26 = add i64 %25, 4
  store i64 %26, i64* %PC, align 8
  %27 = inttoptr i64 %23 to i64*
  store i64 %24, i64* %27, align 8
  %28 = load i64, i64* %RBP, align 8
  %29 = add i64 %28, -16
  %30 = load i64, i64* %PC, align 8
  %31 = add i64 %30, 4
  store i64 %31, i64* %PC, align 8
  %32 = inttoptr i64 %29 to i64*
  %33 = load i64, i64* %32, align 8
  store i64 %33, i64* %RDX, align 8, !tbaa !2428
  %34 = add i64 %30, 10
  store i64 %34, i64* %PC, align 8
  %35 = inttoptr i64 %33 to i32*
  store i32 0, i32* %35, align 4
  %36 = load i64, i64* %RBP, align 8
  %37 = add i64 %36, -4
  %38 = load i64, i64* %PC, align 8
  %39 = add i64 %38, 3
  store i64 %39, i64* %PC, align 8
  %40 = inttoptr i64 %37 to i32*
  %41 = load i32, i32* %40, align 4
  %42 = zext i32 %41 to i64
  store i64 %42, i64* %RDI, align 8, !tbaa !2428
  %43 = add i64 %36, -44
  %44 = add i64 %38, 6
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %43 to i32*
  store i32 %41, i32* %45, align 4
  %46 = load i64, i64* %RBP, align 8
  %47 = add i64 %46, -48
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 7
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %47 to i32*
  store i32 1, i32* %50, align 4
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %53 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %56 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %57 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %.pre = load i64, i64* %PC, align 8
  br label %block_401c06

block_4021ff:                                     ; preds = %block_40220b, %block_4021f8
  %58 = phi i64 [ %3765, %block_40220b ], [ %.pre8, %block_4021f8 ]
  %59 = load i64, i64* %RBP, align 8
  %60 = add i64 %59, -28
  %61 = add i64 %58, 3
  store i64 %61, i64* %PC, align 8
  %62 = inttoptr i64 %60 to i32*
  %63 = load i32, i32* %62, align 4
  %64 = zext i32 %63 to i64
  store i64 %64, i64* %RAX, align 8, !tbaa !2428
  %65 = add i64 %59, -36
  %66 = add i64 %58, 6
  store i64 %66, i64* %PC, align 8
  %67 = inttoptr i64 %65 to i32*
  %68 = load i32, i32* %67, align 4
  %69 = sub i32 %63, %68
  %70 = icmp ult i32 %63, %68
  %71 = zext i1 %70 to i8
  store i8 %71, i8* %51, align 1, !tbaa !2433
  %72 = and i32 %69, 255
  %73 = tail call i32 @llvm.ctpop.i32(i32 %72) #10
  %74 = trunc i32 %73 to i8
  %75 = and i8 %74, 1
  %76 = xor i8 %75, 1
  store i8 %76, i8* %52, align 1, !tbaa !2447
  %77 = xor i32 %68, %63
  %78 = xor i32 %77, %69
  %79 = lshr i32 %78, 4
  %80 = trunc i32 %79 to i8
  %81 = and i8 %80, 1
  store i8 %81, i8* %53, align 1, !tbaa !2451
  %82 = icmp eq i32 %69, 0
  %83 = zext i1 %82 to i8
  store i8 %83, i8* %54, align 1, !tbaa !2448
  %84 = lshr i32 %69, 31
  %85 = trunc i32 %84 to i8
  store i8 %85, i8* %55, align 1, !tbaa !2449
  %86 = lshr i32 %63, 31
  %87 = lshr i32 %68, 31
  %88 = xor i32 %87, %86
  %89 = xor i32 %84, %86
  %90 = add nuw nsw i32 %89, %88
  %91 = icmp eq i32 %90, 2
  %92 = zext i1 %91 to i8
  store i8 %92, i8* %56, align 1, !tbaa !2450
  %93 = icmp ne i8 %85, 0
  %94 = xor i1 %93, %91
  %.v22 = select i1 %94, i64 12, i64 474
  %95 = add i64 %58, %.v22
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %96 = add i64 %95, 13
  store i64 %96, i64* %PC, align 8
  br i1 %94, label %block_40220b, label %block_4023d9

block_4021f8:                                     ; preds = %block_4021ec
  %97 = add i64 %2865, -28
  %98 = add i64 %2901, 7
  store i64 %98, i64* %PC, align 8
  %99 = inttoptr i64 %97 to i32*
  store i32 0, i32* %99, align 4
  %.pre8 = load i64, i64* %PC, align 8
  br label %block_4021ff

block_40246d:                                     ; preds = %block_4021ec
  %100 = add i64 %2901, 5
  br label %block_402472

block_401c6b:                                     ; preds = %block_401c06
  %101 = load i32, i32* %3770, align 4
  %102 = shl i32 %101, 1
  %103 = icmp slt i32 %101, 0
  %104 = icmp slt i32 %102, 0
  %105 = xor i1 %103, %104
  %106 = zext i32 %102 to i64
  store i64 %106, i64* %RAX, align 8, !tbaa !2428
  %.lobit11 = lshr i32 %101, 31
  %107 = trunc i32 %.lobit11 to i8
  store i8 %107, i8* %51, align 1, !tbaa !2432
  %108 = and i32 %102, 254
  %109 = tail call i32 @llvm.ctpop.i32(i32 %108) #10
  %110 = trunc i32 %109 to i8
  %111 = and i8 %110, 1
  %112 = xor i8 %111, 1
  store i8 %112, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %113 = icmp eq i32 %102, 0
  %114 = zext i1 %113 to i8
  store i8 %114, i8* %54, align 1, !tbaa !2432
  %115 = lshr i32 %101, 30
  %116 = trunc i32 %115 to i8
  %117 = and i8 %116, 1
  store i8 %117, i8* %55, align 1, !tbaa !2432
  %118 = zext i1 %105 to i8
  store i8 %118, i8* %56, align 1, !tbaa !2432
  %119 = add i64 %3767, -52
  %120 = add i64 %3816, 9
  store i64 %120, i64* %PC, align 8
  %121 = inttoptr i64 %119 to i32*
  store i32 %102, i32* %121, align 4
  %122 = load i64, i64* %RBP, align 8
  %123 = add i64 %122, -48
  %124 = load i64, i64* %PC, align 8
  %125 = add i64 %124, 3
  store i64 %125, i64* %PC, align 8
  %126 = inttoptr i64 %123 to i32*
  %127 = load i32, i32* %126, align 4
  %128 = shl i32 %127, 3
  %129 = zext i32 %128 to i64
  store i64 %129, i64* %RAX, align 8, !tbaa !2428
  %130 = lshr i32 %127, 29
  %131 = trunc i32 %130 to i8
  %132 = and i8 %131, 1
  store i8 %132, i8* %51, align 1, !tbaa !2432
  %133 = and i32 %128, 248
  %134 = tail call i32 @llvm.ctpop.i32(i32 %133) #10
  %135 = trunc i32 %134 to i8
  %136 = and i8 %135, 1
  %137 = xor i8 %136, 1
  store i8 %137, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %138 = icmp eq i32 %128, 0
  %139 = zext i1 %138 to i8
  store i8 %139, i8* %54, align 1, !tbaa !2432
  %140 = lshr i32 %127, 28
  %141 = and i32 %140, 1
  %142 = trunc i32 %141 to i8
  store i8 %142, i8* %55, align 1, !tbaa !2432
  store i8 0, i8* %56, align 1, !tbaa !2432
  %143 = add i64 %122, -44
  %144 = add i64 %124, 9
  store i64 %144, i64* %PC, align 8
  %145 = inttoptr i64 %143 to i32*
  %146 = load i32, i32* %145, align 4
  %147 = sub i32 %128, %146
  %148 = icmp ult i32 %128, %146
  %149 = zext i1 %148 to i8
  store i8 %149, i8* %51, align 1, !tbaa !2433
  %150 = and i32 %147, 255
  %151 = tail call i32 @llvm.ctpop.i32(i32 %150) #10
  %152 = trunc i32 %151 to i8
  %153 = and i8 %152, 1
  %154 = xor i8 %153, 1
  store i8 %154, i8* %52, align 1, !tbaa !2447
  %155 = xor i32 %146, %128
  %156 = xor i32 %155, %147
  %157 = lshr i32 %156, 4
  %158 = trunc i32 %157 to i8
  %159 = and i8 %158, 1
  store i8 %159, i8* %53, align 1, !tbaa !2451
  %160 = icmp eq i32 %147, 0
  %161 = zext i1 %160 to i8
  store i8 %161, i8* %54, align 1, !tbaa !2448
  %162 = lshr i32 %147, 31
  %163 = trunc i32 %162 to i8
  store i8 %163, i8* %55, align 1, !tbaa !2449
  %164 = lshr i32 %146, 31
  %165 = xor i32 %164, %141
  %166 = xor i32 %162, %141
  %167 = add nuw nsw i32 %166, %165
  %168 = icmp eq i32 %167, 2
  %169 = zext i1 %168 to i8
  store i8 %169, i8* %56, align 1, !tbaa !2450
  %.v13 = select i1 %160, i64 15, i64 1303
  %170 = add i64 %124, %.v13
  store i64 %170, i64* %57, align 8, !tbaa !2428
  br i1 %160, label %block_401c83, label %block_40218b

block_401c5d:                                     ; preds = %block_401c25
  %171 = add i64 %2160, 3
  store i64 %171, i64* %PC, align 8
  %172 = load i32, i32* %2132, align 4
  %173 = shl i32 %172, 1
  %174 = icmp slt i32 %172, 0
  %175 = icmp slt i32 %173, 0
  %176 = xor i1 %174, %175
  %177 = zext i32 %173 to i64
  store i64 %177, i64* %RAX, align 8, !tbaa !2428
  %.lobit = lshr i32 %172, 31
  %178 = trunc i32 %.lobit to i8
  store i8 %178, i8* %51, align 1, !tbaa !2432
  %179 = and i32 %173, 254
  %180 = tail call i32 @llvm.ctpop.i32(i32 %179) #10
  %181 = trunc i32 %180 to i8
  %182 = and i8 %181, 1
  %183 = xor i8 %182, 1
  store i8 %183, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %184 = icmp eq i32 %173, 0
  %185 = zext i1 %184 to i8
  store i8 %185, i8* %54, align 1, !tbaa !2432
  %186 = lshr i32 %172, 30
  %187 = trunc i32 %186 to i8
  %188 = and i8 %187, 1
  store i8 %188, i8* %55, align 1, !tbaa !2432
  %189 = zext i1 %176 to i8
  store i8 %189, i8* %56, align 1, !tbaa !2432
  %190 = add i64 %2160, 9
  store i64 %190, i64* %PC, align 8
  store i32 %173, i32* %2132, align 4
  %191 = load i64, i64* %PC, align 8
  %192 = add i64 %191, -96
  store i64 %192, i64* %57, align 8, !tbaa !2428
  br label %block_401c06

block_402186:                                     ; preds = %block_401c8a
  %193 = add i64 %2973, 748
  br label %block_402472

block_401c31:                                     ; preds = %block_401c25
  %194 = add i64 %2124, -16
  %195 = add i64 %2160, 4
  store i64 %195, i64* %PC, align 8
  %196 = inttoptr i64 %194 to i64*
  %197 = load i64, i64* %196, align 8
  store i64 %197, i64* %RAX, align 8, !tbaa !2428
  %198 = add i64 %2160, 8
  store i64 %198, i64* %PC, align 8
  %199 = load i32, i32* %2127, align 4
  %200 = sext i32 %199 to i64
  store i64 %200, i64* %RCX, align 8, !tbaa !2428
  %201 = shl nsw i64 %200, 2
  %202 = add i64 %201, %197
  %203 = add i64 %2160, 11
  store i64 %203, i64* %PC, align 8
  %204 = inttoptr i64 %202 to i32*
  %205 = load i32, i32* %204, align 4
  %206 = zext i32 %205 to i64
  store i64 %206, i64* %RDX, align 8, !tbaa !2428
  %207 = add i64 %2124, -44
  %208 = add i64 %2160, 14
  store i64 %208, i64* %PC, align 8
  %209 = inttoptr i64 %207 to i32*
  %210 = load i32, i32* %209, align 4
  %211 = add i32 %210, %205
  %212 = zext i32 %211 to i64
  store i64 %212, i64* %RDX, align 8, !tbaa !2428
  %213 = icmp ult i32 %211, %205
  %214 = icmp ult i32 %211, %210
  %215 = or i1 %213, %214
  %216 = zext i1 %215 to i8
  store i8 %216, i8* %51, align 1, !tbaa !2433
  %217 = and i32 %211, 255
  %218 = tail call i32 @llvm.ctpop.i32(i32 %217) #10
  %219 = trunc i32 %218 to i8
  %220 = and i8 %219, 1
  %221 = xor i8 %220, 1
  store i8 %221, i8* %52, align 1, !tbaa !2447
  %222 = xor i32 %210, %205
  %223 = xor i32 %222, %211
  %224 = lshr i32 %223, 4
  %225 = trunc i32 %224 to i8
  %226 = and i8 %225, 1
  store i8 %226, i8* %53, align 1, !tbaa !2451
  %227 = icmp eq i32 %211, 0
  %228 = zext i1 %227 to i8
  store i8 %228, i8* %54, align 1, !tbaa !2448
  %229 = lshr i32 %211, 31
  %230 = trunc i32 %229 to i8
  store i8 %230, i8* %55, align 1, !tbaa !2449
  %231 = lshr i32 %205, 31
  %232 = lshr i32 %210, 31
  %233 = xor i32 %229, %231
  %234 = xor i32 %229, %232
  %235 = add nuw nsw i32 %233, %234
  %236 = icmp eq i32 %235, 2
  %237 = zext i1 %236 to i8
  store i8 %237, i8* %56, align 1, !tbaa !2450
  %238 = add i64 %2160, 18
  store i64 %238, i64* %PC, align 8
  %239 = load i64, i64* %196, align 8
  store i64 %239, i64* %RAX, align 8, !tbaa !2428
  %240 = add i64 %2160, 21
  store i64 %240, i64* %PC, align 8
  %241 = load i32, i32* %2132, align 4
  %242 = zext i32 %241 to i64
  store i64 %242, i64* %RSI, align 8, !tbaa !2428
  %243 = add i64 %2160, 24
  store i64 %243, i64* %PC, align 8
  %244 = load i32, i32* %2127, align 4
  %245 = add i32 %244, %241
  %246 = zext i32 %245 to i64
  store i64 %246, i64* %RSI, align 8, !tbaa !2428
  %247 = icmp ult i32 %245, %241
  %248 = icmp ult i32 %245, %244
  %249 = or i1 %247, %248
  %250 = zext i1 %249 to i8
  store i8 %250, i8* %51, align 1, !tbaa !2433
  %251 = and i32 %245, 255
  %252 = tail call i32 @llvm.ctpop.i32(i32 %251) #10
  %253 = trunc i32 %252 to i8
  %254 = and i8 %253, 1
  %255 = xor i8 %254, 1
  store i8 %255, i8* %52, align 1, !tbaa !2447
  %256 = xor i32 %244, %241
  %257 = xor i32 %256, %245
  %258 = lshr i32 %257, 4
  %259 = trunc i32 %258 to i8
  %260 = and i8 %259, 1
  store i8 %260, i8* %53, align 1, !tbaa !2451
  %261 = icmp eq i32 %245, 0
  %262 = zext i1 %261 to i8
  store i8 %262, i8* %54, align 1, !tbaa !2448
  %263 = lshr i32 %245, 31
  %264 = trunc i32 %263 to i8
  store i8 %264, i8* %55, align 1, !tbaa !2449
  %265 = lshr i32 %241, 31
  %266 = lshr i32 %244, 31
  %267 = xor i32 %263, %265
  %268 = xor i32 %263, %266
  %269 = add nuw nsw i32 %267, %268
  %270 = icmp eq i32 %269, 2
  %271 = zext i1 %270 to i8
  store i8 %271, i8* %56, align 1, !tbaa !2450
  %272 = sext i32 %245 to i64
  store i64 %272, i64* %RCX, align 8, !tbaa !2428
  %273 = shl nsw i64 %272, 2
  %274 = add i64 %273, %239
  %275 = add i64 %2160, 30
  store i64 %275, i64* %PC, align 8
  %276 = inttoptr i64 %274 to i32*
  store i32 %211, i32* %276, align 4
  %277 = load i64, i64* %RBP, align 8
  %278 = add i64 %277, -28
  %279 = load i64, i64* %PC, align 8
  %280 = add i64 %279, 3
  store i64 %280, i64* %PC, align 8
  %281 = inttoptr i64 %278 to i32*
  %282 = load i32, i32* %281, align 4
  %283 = add i32 %282, 1
  %284 = zext i32 %283 to i64
  store i64 %284, i64* %RAX, align 8, !tbaa !2428
  %285 = icmp eq i32 %282, -1
  %286 = icmp eq i32 %283, 0
  %287 = or i1 %285, %286
  %288 = zext i1 %287 to i8
  store i8 %288, i8* %51, align 1, !tbaa !2433
  %289 = and i32 %283, 255
  %290 = tail call i32 @llvm.ctpop.i32(i32 %289) #10
  %291 = trunc i32 %290 to i8
  %292 = and i8 %291, 1
  %293 = xor i8 %292, 1
  store i8 %293, i8* %52, align 1, !tbaa !2447
  %294 = xor i32 %282, %283
  %295 = lshr i32 %294, 4
  %296 = trunc i32 %295 to i8
  %297 = and i8 %296, 1
  store i8 %297, i8* %53, align 1, !tbaa !2451
  %298 = icmp eq i32 %283, 0
  %299 = zext i1 %298 to i8
  store i8 %299, i8* %54, align 1, !tbaa !2448
  %300 = lshr i32 %283, 31
  %301 = trunc i32 %300 to i8
  store i8 %301, i8* %55, align 1, !tbaa !2449
  %302 = lshr i32 %282, 31
  %303 = xor i32 %300, %302
  %304 = add nuw nsw i32 %303, %300
  %305 = icmp eq i32 %304, 2
  %306 = zext i1 %305 to i8
  store i8 %306, i8* %56, align 1, !tbaa !2450
  %307 = add i64 %279, 9
  store i64 %307, i64* %PC, align 8
  store i32 %283, i32* %281, align 4
  %308 = load i64, i64* %PC, align 8
  %309 = add i64 %308, -51
  store i64 %309, i64* %57, align 8, !tbaa !2428
  br label %block_401c25

block_4023d9:                                     ; preds = %block_4021ff
  %310 = load i32, i32* %67, align 4
  %311 = shl i32 %310, 1
  %312 = icmp slt i32 %310, 0
  %313 = icmp slt i32 %311, 0
  %314 = xor i1 %312, %313
  %315 = zext i32 %311 to i64
  store i64 %315, i64* %RCX, align 8, !tbaa !2428
  %.lobit25 = lshr i32 %310, 31
  %316 = trunc i32 %.lobit25 to i8
  store i8 %316, i8* %51, align 1, !tbaa !2432
  %317 = and i32 %311, 254
  %318 = tail call i32 @llvm.ctpop.i32(i32 %317) #10
  %319 = trunc i32 %318 to i8
  %320 = and i8 %319, 1
  %321 = xor i8 %320, 1
  store i8 %321, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %322 = icmp eq i32 %311, 0
  %323 = zext i1 %322 to i8
  store i8 %323, i8* %54, align 1, !tbaa !2432
  %324 = lshr i32 %310, 30
  %325 = and i32 %324, 1
  %326 = trunc i32 %325 to i8
  store i8 %326, i8* %55, align 1, !tbaa !2432
  %327 = zext i1 %314 to i8
  store i8 %327, i8* %56, align 1, !tbaa !2432
  %328 = add i64 %59, -16
  %329 = add i64 %95, 20
  store i64 %329, i64* %PC, align 8
  %330 = inttoptr i64 %328 to i64*
  %331 = load i64, i64* %330, align 8
  store i64 %331, i64* %RDX, align 8, !tbaa !2428
  %332 = add i64 %95, 24
  store i64 %332, i64* %PC, align 8
  %333 = load i32, i32* %67, align 4
  %334 = sext i32 %333 to i64
  store i64 %334, i64* %RSI, align 8, !tbaa !2428
  %335 = shl nsw i64 %334, 2
  %336 = add i64 %335, %331
  %337 = add i64 %95, 27
  store i64 %337, i64* %PC, align 8
  %338 = inttoptr i64 %336 to i32*
  %339 = load i32, i32* %338, align 4
  %340 = add i32 %339, %311
  %341 = zext i32 %340 to i64
  store i64 %341, i64* %RCX, align 8, !tbaa !2428
  %342 = icmp ult i32 %340, %311
  %343 = icmp ult i32 %340, %339
  %344 = or i1 %342, %343
  %345 = zext i1 %344 to i8
  store i8 %345, i8* %51, align 1, !tbaa !2433
  %346 = and i32 %340, 255
  %347 = tail call i32 @llvm.ctpop.i32(i32 %346) #10
  %348 = trunc i32 %347 to i8
  %349 = and i8 %348, 1
  %350 = xor i8 %349, 1
  store i8 %350, i8* %52, align 1, !tbaa !2447
  %351 = xor i32 %339, %311
  %352 = xor i32 %351, %340
  %353 = lshr i32 %352, 4
  %354 = trunc i32 %353 to i8
  %355 = and i8 %354, 1
  store i8 %355, i8* %53, align 1, !tbaa !2451
  %356 = icmp eq i32 %340, 0
  %357 = zext i1 %356 to i8
  store i8 %357, i8* %54, align 1, !tbaa !2448
  %358 = lshr i32 %340, 31
  %359 = trunc i32 %358 to i8
  store i8 %359, i8* %55, align 1, !tbaa !2449
  %360 = lshr i32 %339, 31
  %361 = xor i32 %358, %325
  %362 = xor i32 %358, %360
  %363 = add nuw nsw i32 %361, %362
  %364 = icmp eq i32 %363, 2
  %365 = zext i1 %364 to i8
  store i8 %365, i8* %56, align 1, !tbaa !2450
  %366 = add i64 %59, -40
  %367 = add i64 %95, 30
  store i64 %367, i64* %PC, align 8
  %368 = inttoptr i64 %366 to i32*
  store i32 %340, i32* %368, align 4
  %369 = load i64, i64* %RBP, align 8
  %370 = add i64 %369, -24
  %371 = load i64, i64* %PC, align 8
  %372 = add i64 %371, 4
  store i64 %372, i64* %PC, align 8
  %373 = inttoptr i64 %370 to i64*
  %374 = load i64, i64* %373, align 8
  store i64 %374, i64* %RDX, align 8, !tbaa !2428
  %375 = add i64 %369, -40
  %376 = add i64 %371, 7
  store i64 %376, i64* %PC, align 8
  %377 = inttoptr i64 %375 to i32*
  %378 = load i32, i32* %377, align 4
  %379 = add i32 %378, 1
  %380 = zext i32 %379 to i64
  store i64 %380, i64* %RCX, align 8, !tbaa !2428
  %381 = icmp eq i32 %378, -1
  %382 = icmp eq i32 %379, 0
  %383 = or i1 %381, %382
  %384 = zext i1 %383 to i8
  store i8 %384, i8* %51, align 1, !tbaa !2433
  %385 = and i32 %379, 255
  %386 = tail call i32 @llvm.ctpop.i32(i32 %385) #10
  %387 = trunc i32 %386 to i8
  %388 = and i8 %387, 1
  %389 = xor i8 %388, 1
  store i8 %389, i8* %52, align 1, !tbaa !2447
  %390 = xor i32 %378, %379
  %391 = lshr i32 %390, 4
  %392 = trunc i32 %391 to i8
  %393 = and i8 %392, 1
  store i8 %393, i8* %53, align 1, !tbaa !2451
  %394 = icmp eq i32 %379, 0
  %395 = zext i1 %394 to i8
  store i8 %395, i8* %54, align 1, !tbaa !2448
  %396 = lshr i32 %379, 31
  %397 = trunc i32 %396 to i8
  store i8 %397, i8* %55, align 1, !tbaa !2449
  %398 = lshr i32 %378, 31
  %399 = xor i32 %396, %398
  %400 = add nuw nsw i32 %399, %396
  %401 = icmp eq i32 %400, 2
  %402 = zext i1 %401 to i8
  store i8 %402, i8* %56, align 1, !tbaa !2450
  %403 = sext i32 %379 to i64
  store i64 %403, i64* %RSI, align 8, !tbaa !2428
  %404 = shl nsw i64 %403, 3
  %405 = add i64 %404, %374
  %406 = add i64 %371, 18
  store i64 %406, i64* %PC, align 8
  %407 = inttoptr i64 %405 to i64*
  %408 = load i64, i64* %407, align 8
  %409 = load i64, i64* %RAX, align 8
  %410 = xor i64 %409, %408
  store i64 %410, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %411 = trunc i64 %410 to i32
  %412 = and i32 %411, 255
  %413 = tail call i32 @llvm.ctpop.i32(i32 %412) #10
  %414 = trunc i32 %413 to i8
  %415 = and i8 %414, 1
  %416 = xor i8 %415, 1
  store i8 %416, i8* %52, align 1, !tbaa !2447
  %417 = icmp eq i64 %410, 0
  %418 = zext i1 %417 to i8
  store i8 %418, i8* %54, align 1, !tbaa !2448
  %419 = lshr i64 %410, 63
  %420 = trunc i64 %419 to i8
  store i8 %420, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %410, i64* %3839, align 1, !tbaa !2428
  store i64 0, i64* %3826, align 1, !tbaa !2428
  %421 = add i64 %371, 35
  store i64 %421, i64* %PC, align 8
  %422 = load i64, i64* %373, align 8
  store i64 %422, i64* %RDX, align 8, !tbaa !2428
  %423 = add i64 %371, 38
  store i64 %423, i64* %PC, align 8
  %424 = load i32, i32* %377, align 4
  %425 = add i32 %424, 1
  %426 = zext i32 %425 to i64
  store i64 %426, i64* %RCX, align 8, !tbaa !2428
  %427 = icmp eq i32 %424, -1
  %428 = icmp eq i32 %425, 0
  %429 = or i1 %427, %428
  %430 = zext i1 %429 to i8
  store i8 %430, i8* %51, align 1, !tbaa !2433
  %431 = and i32 %425, 255
  %432 = tail call i32 @llvm.ctpop.i32(i32 %431) #10
  %433 = trunc i32 %432 to i8
  %434 = and i8 %433, 1
  %435 = xor i8 %434, 1
  store i8 %435, i8* %52, align 1, !tbaa !2447
  %436 = xor i32 %424, %425
  %437 = lshr i32 %436, 4
  %438 = trunc i32 %437 to i8
  %439 = and i8 %438, 1
  store i8 %439, i8* %53, align 1, !tbaa !2451
  %440 = icmp eq i32 %425, 0
  %441 = zext i1 %440 to i8
  store i8 %441, i8* %54, align 1, !tbaa !2448
  %442 = lshr i32 %425, 31
  %443 = trunc i32 %442 to i8
  store i8 %443, i8* %55, align 1, !tbaa !2449
  %444 = lshr i32 %424, 31
  %445 = xor i32 %442, %444
  %446 = add nuw nsw i32 %445, %442
  %447 = icmp eq i32 %446, 2
  %448 = zext i1 %447 to i8
  store i8 %448, i8* %56, align 1, !tbaa !2450
  %449 = sext i32 %425 to i64
  store i64 %449, i64* %RSI, align 8, !tbaa !2428
  %450 = shl nsw i64 %449, 3
  %451 = add i64 %450, %422
  %452 = add i64 %371, 49
  store i64 %452, i64* %PC, align 8
  %453 = inttoptr i64 %451 to i64*
  store i64 %410, i64* %453, align 8
  %454 = load i64, i64* %RBP, align 8
  %455 = add i64 %454, -24
  %456 = load i64, i64* %PC, align 8
  %457 = add i64 %456, 4
  store i64 %457, i64* %PC, align 8
  %458 = inttoptr i64 %455 to i64*
  %459 = load i64, i64* %458, align 8
  store i64 %459, i64* %RDX, align 8, !tbaa !2428
  %460 = add i64 %454, -40
  %461 = add i64 %456, 7
  store i64 %461, i64* %PC, align 8
  %462 = inttoptr i64 %460 to i32*
  %463 = load i32, i32* %462, align 4
  %464 = zext i32 %463 to i64
  store i64 %464, i64* %RCX, align 8, !tbaa !2428
  %465 = add i64 %454, -52
  %466 = add i64 %456, 10
  store i64 %466, i64* %PC, align 8
  %467 = inttoptr i64 %465 to i32*
  %468 = load i32, i32* %467, align 4
  %469 = add i32 %468, %463
  %470 = lshr i32 %469, 31
  %471 = add i32 %469, 1
  %472 = zext i32 %471 to i64
  store i64 %472, i64* %RCX, align 8, !tbaa !2428
  %473 = icmp eq i32 %469, -1
  %474 = icmp eq i32 %471, 0
  %475 = or i1 %473, %474
  %476 = zext i1 %475 to i8
  store i8 %476, i8* %51, align 1, !tbaa !2433
  %477 = and i32 %471, 255
  %478 = tail call i32 @llvm.ctpop.i32(i32 %477) #10
  %479 = trunc i32 %478 to i8
  %480 = and i8 %479, 1
  %481 = xor i8 %480, 1
  store i8 %481, i8* %52, align 1, !tbaa !2447
  %482 = xor i32 %469, %471
  %483 = lshr i32 %482, 4
  %484 = trunc i32 %483 to i8
  %485 = and i8 %484, 1
  store i8 %485, i8* %53, align 1, !tbaa !2451
  %486 = icmp eq i32 %471, 0
  %487 = zext i1 %486 to i8
  store i8 %487, i8* %54, align 1, !tbaa !2448
  %488 = lshr i32 %471, 31
  %489 = trunc i32 %488 to i8
  store i8 %489, i8* %55, align 1, !tbaa !2449
  %490 = xor i32 %488, %470
  %491 = add nuw nsw i32 %490, %488
  %492 = icmp eq i32 %491, 2
  %493 = zext i1 %492 to i8
  store i8 %493, i8* %56, align 1, !tbaa !2450
  %494 = sext i32 %471 to i64
  store i64 %494, i64* %RSI, align 8, !tbaa !2428
  %495 = shl nsw i64 %494, 3
  %496 = add i64 %495, %459
  %497 = add i64 %456, 21
  store i64 %497, i64* %PC, align 8
  %498 = inttoptr i64 %496 to i64*
  %499 = load i64, i64* %498, align 8
  %500 = load i64, i64* %RAX, align 8
  %501 = xor i64 %500, %499
  store i64 %501, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %502 = trunc i64 %501 to i32
  %503 = and i32 %502, 255
  %504 = tail call i32 @llvm.ctpop.i32(i32 %503) #10
  %505 = trunc i32 %504 to i8
  %506 = and i8 %505, 1
  %507 = xor i8 %506, 1
  store i8 %507, i8* %52, align 1, !tbaa !2447
  %508 = icmp eq i64 %501, 0
  %509 = zext i1 %508 to i8
  store i8 %509, i8* %54, align 1, !tbaa !2448
  %510 = lshr i64 %501, 63
  %511 = trunc i64 %510 to i8
  store i8 %511, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %501, i64* %3839, align 1, !tbaa !2428
  store i64 0, i64* %3826, align 1, !tbaa !2428
  %512 = load i64, i64* %RBP, align 8
  %513 = add i64 %512, -24
  %514 = add i64 %456, 38
  store i64 %514, i64* %PC, align 8
  %515 = inttoptr i64 %513 to i64*
  %516 = load i64, i64* %515, align 8
  store i64 %516, i64* %RAX, align 8, !tbaa !2428
  %517 = add i64 %512, -40
  %518 = add i64 %456, 41
  store i64 %518, i64* %PC, align 8
  %519 = inttoptr i64 %517 to i32*
  %520 = load i32, i32* %519, align 4
  %521 = zext i32 %520 to i64
  store i64 %521, i64* %RCX, align 8, !tbaa !2428
  %522 = add i64 %512, -52
  %523 = add i64 %456, 44
  store i64 %523, i64* %PC, align 8
  %524 = inttoptr i64 %522 to i32*
  %525 = load i32, i32* %524, align 4
  %526 = add i32 %525, %520
  %527 = lshr i32 %526, 31
  %528 = add i32 %526, 1
  %529 = zext i32 %528 to i64
  store i64 %529, i64* %RCX, align 8, !tbaa !2428
  %530 = icmp eq i32 %526, -1
  %531 = icmp eq i32 %528, 0
  %532 = or i1 %530, %531
  %533 = zext i1 %532 to i8
  store i8 %533, i8* %51, align 1, !tbaa !2433
  %534 = and i32 %528, 255
  %535 = tail call i32 @llvm.ctpop.i32(i32 %534) #10
  %536 = trunc i32 %535 to i8
  %537 = and i8 %536, 1
  %538 = xor i8 %537, 1
  store i8 %538, i8* %52, align 1, !tbaa !2447
  %539 = xor i32 %526, %528
  %540 = lshr i32 %539, 4
  %541 = trunc i32 %540 to i8
  %542 = and i8 %541, 1
  store i8 %542, i8* %53, align 1, !tbaa !2451
  %543 = icmp eq i32 %528, 0
  %544 = zext i1 %543 to i8
  store i8 %544, i8* %54, align 1, !tbaa !2448
  %545 = lshr i32 %528, 31
  %546 = trunc i32 %545 to i8
  store i8 %546, i8* %55, align 1, !tbaa !2449
  %547 = xor i32 %545, %527
  %548 = add nuw nsw i32 %547, %545
  %549 = icmp eq i32 %548, 2
  %550 = zext i1 %549 to i8
  store i8 %550, i8* %56, align 1, !tbaa !2450
  %551 = sext i32 %528 to i64
  store i64 %551, i64* %RDX, align 8, !tbaa !2428
  %552 = shl nsw i64 %551, 3
  %553 = add i64 %552, %516
  %554 = add i64 %456, 55
  store i64 %554, i64* %PC, align 8
  %555 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  %556 = load i64, i64* %555, align 1
  %557 = inttoptr i64 %553 to i64*
  store i64 %556, i64* %557, align 8
  %558 = load i64, i64* %RBP, align 8
  %559 = add i64 %558, -36
  %560 = load i64, i64* %PC, align 8
  %561 = add i64 %560, 3
  store i64 %561, i64* %PC, align 8
  %562 = inttoptr i64 %559 to i32*
  %563 = load i32, i32* %562, align 4
  %564 = add i32 %563, 1
  %565 = zext i32 %564 to i64
  store i64 %565, i64* %RAX, align 8, !tbaa !2428
  %566 = icmp eq i32 %563, -1
  %567 = icmp eq i32 %564, 0
  %568 = or i1 %566, %567
  %569 = zext i1 %568 to i8
  store i8 %569, i8* %51, align 1, !tbaa !2433
  %570 = and i32 %564, 255
  %571 = tail call i32 @llvm.ctpop.i32(i32 %570) #10
  %572 = trunc i32 %571 to i8
  %573 = and i8 %572, 1
  %574 = xor i8 %573, 1
  store i8 %574, i8* %52, align 1, !tbaa !2447
  %575 = xor i32 %563, %564
  %576 = lshr i32 %575, 4
  %577 = trunc i32 %576 to i8
  %578 = and i8 %577, 1
  store i8 %578, i8* %53, align 1, !tbaa !2451
  %579 = icmp eq i32 %564, 0
  %580 = zext i1 %579 to i8
  store i8 %580, i8* %54, align 1, !tbaa !2448
  %581 = lshr i32 %564, 31
  %582 = trunc i32 %581 to i8
  store i8 %582, i8* %55, align 1, !tbaa !2449
  %583 = lshr i32 %563, 31
  %584 = xor i32 %581, %583
  %585 = add nuw nsw i32 %584, %581
  %586 = icmp eq i32 %585, 2
  %587 = zext i1 %586 to i8
  store i8 %587, i8* %56, align 1, !tbaa !2450
  %588 = add i64 %560, 9
  store i64 %588, i64* %PC, align 8
  store i32 %564, i32* %562, align 4
  %589 = load i64, i64* %PC, align 8
  %590 = add i64 %589, -636
  store i64 %590, i64* %57, align 8, !tbaa !2428
  br label %block_4021ec

block_401ca9:                                     ; preds = %block_401c9d
  %591 = load i32, i32* %2826, align 4
  %592 = shl i32 %591, 1
  %593 = icmp slt i32 %591, 0
  %594 = icmp slt i32 %592, 0
  %595 = xor i1 %593, %594
  %596 = zext i32 %592 to i64
  store i64 %596, i64* %RCX, align 8, !tbaa !2428
  %.lobit16 = lshr i32 %591, 31
  %597 = trunc i32 %.lobit16 to i8
  store i8 %597, i8* %51, align 1, !tbaa !2432
  %598 = and i32 %592, 254
  %599 = tail call i32 @llvm.ctpop.i32(i32 %598) #10
  %600 = trunc i32 %599 to i8
  %601 = and i8 %600, 1
  %602 = xor i8 %601, 1
  store i8 %602, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %603 = icmp eq i32 %592, 0
  %604 = zext i1 %603 to i8
  store i8 %604, i8* %54, align 1, !tbaa !2432
  %605 = lshr i32 %591, 30
  %606 = and i32 %605, 1
  %607 = trunc i32 %606 to i8
  store i8 %607, i8* %55, align 1, !tbaa !2432
  %608 = zext i1 %595 to i8
  store i8 %608, i8* %56, align 1, !tbaa !2432
  %609 = add i64 %2823, -16
  %610 = add i64 %2859, 20
  store i64 %610, i64* %PC, align 8
  %611 = inttoptr i64 %609 to i64*
  %612 = load i64, i64* %611, align 8
  store i64 %612, i64* %RDX, align 8, !tbaa !2428
  %613 = add i64 %2859, 24
  store i64 %613, i64* %PC, align 8
  %614 = load i32, i32* %2831, align 4
  %615 = sext i32 %614 to i64
  store i64 %615, i64* %RSI, align 8, !tbaa !2428
  %616 = shl nsw i64 %615, 2
  %617 = add i64 %616, %612
  %618 = add i64 %2859, 27
  store i64 %618, i64* %PC, align 8
  %619 = inttoptr i64 %617 to i32*
  %620 = load i32, i32* %619, align 4
  %621 = add i32 %620, %592
  %622 = zext i32 %621 to i64
  store i64 %622, i64* %RCX, align 8, !tbaa !2428
  %623 = icmp ult i32 %621, %592
  %624 = icmp ult i32 %621, %620
  %625 = or i1 %623, %624
  %626 = zext i1 %625 to i8
  store i8 %626, i8* %51, align 1, !tbaa !2433
  %627 = and i32 %621, 255
  %628 = tail call i32 @llvm.ctpop.i32(i32 %627) #10
  %629 = trunc i32 %628 to i8
  %630 = and i8 %629, 1
  %631 = xor i8 %630, 1
  store i8 %631, i8* %52, align 1, !tbaa !2447
  %632 = xor i32 %620, %592
  %633 = xor i32 %632, %621
  %634 = lshr i32 %633, 4
  %635 = trunc i32 %634 to i8
  %636 = and i8 %635, 1
  store i8 %636, i8* %53, align 1, !tbaa !2451
  %637 = icmp eq i32 %621, 0
  %638 = zext i1 %637 to i8
  store i8 %638, i8* %54, align 1, !tbaa !2448
  %639 = lshr i32 %621, 31
  %640 = trunc i32 %639 to i8
  store i8 %640, i8* %55, align 1, !tbaa !2449
  %641 = lshr i32 %620, 31
  %642 = xor i32 %639, %606
  %643 = xor i32 %639, %641
  %644 = add nuw nsw i32 %642, %643
  %645 = icmp eq i32 %644, 2
  %646 = zext i1 %645 to i8
  store i8 %646, i8* %56, align 1, !tbaa !2450
  %647 = add i64 %2823, -32
  %648 = add i64 %2859, 30
  store i64 %648, i64* %PC, align 8
  %649 = inttoptr i64 %647 to i32*
  store i32 %621, i32* %649, align 4
  %650 = load i64, i64* %RBP, align 8
  %651 = add i64 %650, -36
  %652 = load i64, i64* %PC, align 8
  %653 = add i64 %652, 3
  store i64 %653, i64* %PC, align 8
  %654 = inttoptr i64 %651 to i32*
  %655 = load i32, i32* %654, align 4
  %656 = shl i32 %655, 1
  %657 = icmp slt i32 %655, 0
  %658 = icmp slt i32 %656, 0
  %659 = xor i1 %657, %658
  %660 = zext i32 %656 to i64
  store i64 %660, i64* %RCX, align 8, !tbaa !2428
  %.lobit17 = lshr i32 %655, 31
  %661 = trunc i32 %.lobit17 to i8
  store i8 %661, i8* %51, align 1, !tbaa !2432
  %662 = and i32 %656, 254
  %663 = tail call i32 @llvm.ctpop.i32(i32 %662) #10
  %664 = trunc i32 %663 to i8
  %665 = and i8 %664, 1
  %666 = xor i8 %665, 1
  store i8 %666, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %667 = icmp eq i32 %656, 0
  %668 = zext i1 %667 to i8
  store i8 %668, i8* %54, align 1, !tbaa !2432
  %669 = lshr i32 %655, 30
  %670 = and i32 %669, 1
  %671 = trunc i32 %670 to i8
  store i8 %671, i8* %55, align 1, !tbaa !2432
  %672 = zext i1 %659 to i8
  store i8 %672, i8* %56, align 1, !tbaa !2432
  %673 = add i64 %650, -16
  %674 = add i64 %652, 10
  store i64 %674, i64* %PC, align 8
  %675 = inttoptr i64 %673 to i64*
  %676 = load i64, i64* %675, align 8
  store i64 %676, i64* %RDX, align 8, !tbaa !2428
  %677 = add i64 %650, -28
  %678 = add i64 %652, 14
  store i64 %678, i64* %PC, align 8
  %679 = inttoptr i64 %677 to i32*
  %680 = load i32, i32* %679, align 4
  %681 = sext i32 %680 to i64
  store i64 %681, i64* %RSI, align 8, !tbaa !2428
  %682 = shl nsw i64 %681, 2
  %683 = add i64 %682, %676
  %684 = add i64 %652, 17
  store i64 %684, i64* %PC, align 8
  %685 = inttoptr i64 %683 to i32*
  %686 = load i32, i32* %685, align 4
  %687 = add i32 %686, %656
  %688 = zext i32 %687 to i64
  store i64 %688, i64* %RCX, align 8, !tbaa !2428
  %689 = icmp ult i32 %687, %656
  %690 = icmp ult i32 %687, %686
  %691 = or i1 %689, %690
  %692 = zext i1 %691 to i8
  store i8 %692, i8* %51, align 1, !tbaa !2433
  %693 = and i32 %687, 255
  %694 = tail call i32 @llvm.ctpop.i32(i32 %693) #10
  %695 = trunc i32 %694 to i8
  %696 = and i8 %695, 1
  %697 = xor i8 %696, 1
  store i8 %697, i8* %52, align 1, !tbaa !2447
  %698 = xor i32 %686, %656
  %699 = xor i32 %698, %687
  %700 = lshr i32 %699, 4
  %701 = trunc i32 %700 to i8
  %702 = and i8 %701, 1
  store i8 %702, i8* %53, align 1, !tbaa !2451
  %703 = icmp eq i32 %687, 0
  %704 = zext i1 %703 to i8
  store i8 %704, i8* %54, align 1, !tbaa !2448
  %705 = lshr i32 %687, 31
  %706 = trunc i32 %705 to i8
  store i8 %706, i8* %55, align 1, !tbaa !2449
  %707 = lshr i32 %686, 31
  %708 = xor i32 %705, %670
  %709 = xor i32 %705, %707
  %710 = add nuw nsw i32 %708, %709
  %711 = icmp eq i32 %710, 2
  %712 = zext i1 %711 to i8
  store i8 %712, i8* %56, align 1, !tbaa !2450
  %713 = add i64 %650, -40
  %714 = add i64 %652, 20
  store i64 %714, i64* %PC, align 8
  %715 = inttoptr i64 %713 to i32*
  store i32 %687, i32* %715, align 4
  %716 = load i64, i64* %RBP, align 8
  %717 = add i64 %716, -24
  %718 = load i64, i64* %PC, align 8
  %719 = add i64 %718, 4
  store i64 %719, i64* %PC, align 8
  %720 = inttoptr i64 %717 to i64*
  %721 = load i64, i64* %720, align 8
  store i64 %721, i64* %RDX, align 8, !tbaa !2428
  %722 = add i64 %716, -32
  %723 = add i64 %718, 8
  store i64 %723, i64* %PC, align 8
  %724 = inttoptr i64 %722 to i32*
  %725 = load i32, i32* %724, align 4
  %726 = sext i32 %725 to i64
  store i64 %726, i64* %RSI, align 8, !tbaa !2428
  %727 = shl nsw i64 %726, 3
  %728 = add i64 %727, %721
  %729 = add i64 %718, 13
  store i64 %729, i64* %PC, align 8
  %730 = inttoptr i64 %728 to i64*
  %731 = load i64, i64* %730, align 8
  %732 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %731, i64* %732, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %733 = add i64 %716, -64
  %734 = add i64 %718, 18
  store i64 %734, i64* %PC, align 8
  %735 = inttoptr i64 %733 to i64*
  store i64 %731, i64* %735, align 8
  %736 = load i64, i64* %RBP, align 8
  %737 = add i64 %736, -24
  %738 = load i64, i64* %PC, align 8
  %739 = add i64 %738, 4
  store i64 %739, i64* %PC, align 8
  %740 = inttoptr i64 %737 to i64*
  %741 = load i64, i64* %740, align 8
  store i64 %741, i64* %RDX, align 8, !tbaa !2428
  %742 = add i64 %736, -32
  %743 = add i64 %738, 7
  store i64 %743, i64* %PC, align 8
  %744 = inttoptr i64 %742 to i32*
  %745 = load i32, i32* %744, align 4
  %746 = add i32 %745, 1
  %747 = zext i32 %746 to i64
  store i64 %747, i64* %RCX, align 8, !tbaa !2428
  %748 = icmp eq i32 %745, -1
  %749 = icmp eq i32 %746, 0
  %750 = or i1 %748, %749
  %751 = zext i1 %750 to i8
  store i8 %751, i8* %51, align 1, !tbaa !2433
  %752 = and i32 %746, 255
  %753 = tail call i32 @llvm.ctpop.i32(i32 %752) #10
  %754 = trunc i32 %753 to i8
  %755 = and i8 %754, 1
  %756 = xor i8 %755, 1
  store i8 %756, i8* %52, align 1, !tbaa !2447
  %757 = xor i32 %745, %746
  %758 = lshr i32 %757, 4
  %759 = trunc i32 %758 to i8
  %760 = and i8 %759, 1
  store i8 %760, i8* %53, align 1, !tbaa !2451
  %761 = icmp eq i32 %746, 0
  %762 = zext i1 %761 to i8
  store i8 %762, i8* %54, align 1, !tbaa !2448
  %763 = lshr i32 %746, 31
  %764 = trunc i32 %763 to i8
  store i8 %764, i8* %55, align 1, !tbaa !2449
  %765 = lshr i32 %745, 31
  %766 = xor i32 %763, %765
  %767 = add nuw nsw i32 %766, %763
  %768 = icmp eq i32 %767, 2
  %769 = zext i1 %768 to i8
  store i8 %769, i8* %56, align 1, !tbaa !2450
  %770 = sext i32 %746 to i64
  store i64 %770, i64* %RSI, align 8, !tbaa !2428
  %771 = shl nsw i64 %770, 3
  %772 = add i64 %771, %741
  %773 = add i64 %738, 18
  store i64 %773, i64* %PC, align 8
  %774 = inttoptr i64 %772 to i64*
  %775 = load i64, i64* %774, align 8
  %776 = load i64, i64* %RAX, align 8
  %777 = xor i64 %776, %775
  store i64 %777, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %778 = trunc i64 %777 to i32
  %779 = and i32 %778, 255
  %780 = tail call i32 @llvm.ctpop.i32(i32 %779) #10
  %781 = trunc i32 %780 to i8
  %782 = and i8 %781, 1
  %783 = xor i8 %782, 1
  store i8 %783, i8* %52, align 1, !tbaa !2447
  %784 = icmp eq i64 %777, 0
  %785 = zext i1 %784 to i8
  store i8 %785, i8* %54, align 1, !tbaa !2448
  %786 = lshr i64 %777, 63
  %787 = trunc i64 %786 to i8
  store i8 %787, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %777, i64* %3940, align 1, !tbaa !2428
  store i64 0, i64* %3938, align 1, !tbaa !2428
  %788 = add i64 %736, -72
  %789 = add i64 %738, 36
  store i64 %789, i64* %PC, align 8
  %790 = inttoptr i64 %788 to i64*
  store i64 %777, i64* %790, align 8
  %791 = load i64, i64* %RBP, align 8
  %792 = add i64 %791, -24
  %793 = load i64, i64* %PC, align 8
  %794 = add i64 %793, 4
  store i64 %794, i64* %PC, align 8
  %795 = inttoptr i64 %792 to i64*
  %796 = load i64, i64* %795, align 8
  store i64 %796, i64* %RDX, align 8, !tbaa !2428
  %797 = add i64 %791, -40
  %798 = add i64 %793, 8
  store i64 %798, i64* %PC, align 8
  %799 = inttoptr i64 %797 to i32*
  %800 = load i32, i32* %799, align 4
  %801 = sext i32 %800 to i64
  store i64 %801, i64* %RSI, align 8, !tbaa !2428
  %802 = shl nsw i64 %801, 3
  %803 = add i64 %802, %796
  %804 = add i64 %793, 13
  store i64 %804, i64* %PC, align 8
  %805 = inttoptr i64 %803 to i64*
  %806 = load i64, i64* %805, align 8
  %807 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %806, i64* %807, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %808 = add i64 %791, -80
  %809 = add i64 %793, 18
  store i64 %809, i64* %PC, align 8
  %810 = inttoptr i64 %808 to i64*
  store i64 %806, i64* %810, align 8
  %811 = load i64, i64* %RBP, align 8
  %812 = add i64 %811, -24
  %813 = load i64, i64* %PC, align 8
  %814 = add i64 %813, 4
  store i64 %814, i64* %PC, align 8
  %815 = inttoptr i64 %812 to i64*
  %816 = load i64, i64* %815, align 8
  store i64 %816, i64* %RDX, align 8, !tbaa !2428
  %817 = add i64 %811, -40
  %818 = add i64 %813, 7
  store i64 %818, i64* %PC, align 8
  %819 = inttoptr i64 %817 to i32*
  %820 = load i32, i32* %819, align 4
  %821 = add i32 %820, 1
  %822 = zext i32 %821 to i64
  store i64 %822, i64* %RCX, align 8, !tbaa !2428
  %823 = icmp eq i32 %820, -1
  %824 = icmp eq i32 %821, 0
  %825 = or i1 %823, %824
  %826 = zext i1 %825 to i8
  store i8 %826, i8* %51, align 1, !tbaa !2433
  %827 = and i32 %821, 255
  %828 = tail call i32 @llvm.ctpop.i32(i32 %827) #10
  %829 = trunc i32 %828 to i8
  %830 = and i8 %829, 1
  %831 = xor i8 %830, 1
  store i8 %831, i8* %52, align 1, !tbaa !2447
  %832 = xor i32 %820, %821
  %833 = lshr i32 %832, 4
  %834 = trunc i32 %833 to i8
  %835 = and i8 %834, 1
  store i8 %835, i8* %53, align 1, !tbaa !2451
  %836 = icmp eq i32 %821, 0
  %837 = zext i1 %836 to i8
  store i8 %837, i8* %54, align 1, !tbaa !2448
  %838 = lshr i32 %821, 31
  %839 = trunc i32 %838 to i8
  store i8 %839, i8* %55, align 1, !tbaa !2449
  %840 = lshr i32 %820, 31
  %841 = xor i32 %838, %840
  %842 = add nuw nsw i32 %841, %838
  %843 = icmp eq i32 %842, 2
  %844 = zext i1 %843 to i8
  store i8 %844, i8* %56, align 1, !tbaa !2450
  %845 = sext i32 %821 to i64
  store i64 %845, i64* %RSI, align 8, !tbaa !2428
  %846 = shl nsw i64 %845, 3
  %847 = add i64 %846, %816
  %848 = add i64 %813, 18
  store i64 %848, i64* %PC, align 8
  %849 = inttoptr i64 %847 to i64*
  %850 = load i64, i64* %849, align 8
  %851 = load i64, i64* %RAX, align 8
  %852 = xor i64 %851, %850
  store i64 %852, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %853 = trunc i64 %852 to i32
  %854 = and i32 %853, 255
  %855 = tail call i32 @llvm.ctpop.i32(i32 %854) #10
  %856 = trunc i32 %855 to i8
  %857 = and i8 %856, 1
  %858 = xor i8 %857, 1
  store i8 %858, i8* %52, align 1, !tbaa !2447
  %859 = icmp eq i64 %852, 0
  %860 = zext i1 %859 to i8
  store i8 %860, i8* %54, align 1, !tbaa !2448
  %861 = lshr i64 %852, 63
  %862 = trunc i64 %861 to i8
  store i8 %862, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %852, i64* %3940, align 1, !tbaa !2428
  store i64 0, i64* %3938, align 1, !tbaa !2428
  %863 = add i64 %811, -88
  %864 = add i64 %813, 36
  store i64 %864, i64* %PC, align 8
  %865 = inttoptr i64 %863 to i64*
  store i64 %852, i64* %865, align 8
  %866 = load i64, i64* %RBP, align 8
  %867 = add i64 %866, -80
  %868 = load i64, i64* %PC, align 8
  %869 = add i64 %868, 5
  store i64 %869, i64* %PC, align 8
  %870 = inttoptr i64 %867 to i64*
  %871 = load i64, i64* %870, align 8
  %872 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %871, i64* %872, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %873 = add i64 %866, -24
  %874 = add i64 %868, 9
  store i64 %874, i64* %PC, align 8
  %875 = inttoptr i64 %873 to i64*
  %876 = load i64, i64* %875, align 8
  store i64 %876, i64* %RDX, align 8, !tbaa !2428
  %877 = add i64 %866, -32
  %878 = add i64 %868, 13
  store i64 %878, i64* %PC, align 8
  %879 = inttoptr i64 %877 to i32*
  %880 = load i32, i32* %879, align 4
  %881 = sext i32 %880 to i64
  store i64 %881, i64* %RSI, align 8, !tbaa !2428
  %882 = shl nsw i64 %881, 3
  %883 = add i64 %882, %876
  %884 = add i64 %868, 18
  store i64 %884, i64* %PC, align 8
  %885 = inttoptr i64 %883 to i64*
  store i64 %871, i64* %885, align 8
  %886 = load i64, i64* %RBP, align 8
  %887 = add i64 %886, -88
  %888 = load i64, i64* %PC, align 8
  %889 = add i64 %888, 5
  store i64 %889, i64* %PC, align 8
  %890 = inttoptr i64 %887 to i64*
  %891 = load i64, i64* %890, align 8
  %892 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %891, i64* %892, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %893 = add i64 %886, -24
  %894 = add i64 %888, 9
  store i64 %894, i64* %PC, align 8
  %895 = inttoptr i64 %893 to i64*
  %896 = load i64, i64* %895, align 8
  store i64 %896, i64* %RDX, align 8, !tbaa !2428
  %897 = add i64 %886, -32
  %898 = add i64 %888, 12
  store i64 %898, i64* %PC, align 8
  %899 = inttoptr i64 %897 to i32*
  %900 = load i32, i32* %899, align 4
  %901 = add i32 %900, 1
  %902 = zext i32 %901 to i64
  store i64 %902, i64* %RCX, align 8, !tbaa !2428
  %903 = icmp eq i32 %900, -1
  %904 = icmp eq i32 %901, 0
  %905 = or i1 %903, %904
  %906 = zext i1 %905 to i8
  store i8 %906, i8* %51, align 1, !tbaa !2433
  %907 = and i32 %901, 255
  %908 = tail call i32 @llvm.ctpop.i32(i32 %907) #10
  %909 = trunc i32 %908 to i8
  %910 = and i8 %909, 1
  %911 = xor i8 %910, 1
  store i8 %911, i8* %52, align 1, !tbaa !2447
  %912 = xor i32 %900, %901
  %913 = lshr i32 %912, 4
  %914 = trunc i32 %913 to i8
  %915 = and i8 %914, 1
  store i8 %915, i8* %53, align 1, !tbaa !2451
  %916 = icmp eq i32 %901, 0
  %917 = zext i1 %916 to i8
  store i8 %917, i8* %54, align 1, !tbaa !2448
  %918 = lshr i32 %901, 31
  %919 = trunc i32 %918 to i8
  store i8 %919, i8* %55, align 1, !tbaa !2449
  %920 = lshr i32 %900, 31
  %921 = xor i32 %918, %920
  %922 = add nuw nsw i32 %921, %918
  %923 = icmp eq i32 %922, 2
  %924 = zext i1 %923 to i8
  store i8 %924, i8* %56, align 1, !tbaa !2450
  %925 = sext i32 %901 to i64
  store i64 %925, i64* %RSI, align 8, !tbaa !2428
  %926 = shl nsw i64 %925, 3
  %927 = add i64 %926, %896
  %928 = add i64 %888, 23
  store i64 %928, i64* %PC, align 8
  %929 = inttoptr i64 %927 to i64*
  store i64 %891, i64* %929, align 8
  %930 = load i64, i64* %RBP, align 8
  %931 = add i64 %930, -64
  %932 = load i64, i64* %PC, align 8
  %933 = add i64 %932, 5
  store i64 %933, i64* %PC, align 8
  %934 = inttoptr i64 %931 to i64*
  %935 = load i64, i64* %934, align 8
  %936 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %935, i64* %936, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %937 = add i64 %930, -24
  %938 = add i64 %932, 9
  store i64 %938, i64* %PC, align 8
  %939 = inttoptr i64 %937 to i64*
  %940 = load i64, i64* %939, align 8
  store i64 %940, i64* %RDX, align 8, !tbaa !2428
  %941 = add i64 %930, -40
  %942 = add i64 %932, 13
  store i64 %942, i64* %PC, align 8
  %943 = inttoptr i64 %941 to i32*
  %944 = load i32, i32* %943, align 4
  %945 = sext i32 %944 to i64
  store i64 %945, i64* %RSI, align 8, !tbaa !2428
  %946 = shl nsw i64 %945, 3
  %947 = add i64 %946, %940
  %948 = add i64 %932, 18
  store i64 %948, i64* %PC, align 8
  %949 = inttoptr i64 %947 to i64*
  store i64 %935, i64* %949, align 8
  %950 = load i64, i64* %RBP, align 8
  %951 = add i64 %950, -72
  %952 = load i64, i64* %PC, align 8
  %953 = add i64 %952, 5
  store i64 %953, i64* %PC, align 8
  %954 = inttoptr i64 %951 to i64*
  %955 = load i64, i64* %954, align 8
  %956 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %955, i64* %956, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %957 = add i64 %950, -24
  %958 = add i64 %952, 9
  store i64 %958, i64* %PC, align 8
  %959 = inttoptr i64 %957 to i64*
  %960 = load i64, i64* %959, align 8
  store i64 %960, i64* %RDX, align 8, !tbaa !2428
  %961 = add i64 %950, -40
  %962 = add i64 %952, 12
  store i64 %962, i64* %PC, align 8
  %963 = inttoptr i64 %961 to i32*
  %964 = load i32, i32* %963, align 4
  %965 = add i32 %964, 1
  %966 = zext i32 %965 to i64
  store i64 %966, i64* %RCX, align 8, !tbaa !2428
  %967 = icmp eq i32 %964, -1
  %968 = icmp eq i32 %965, 0
  %969 = or i1 %967, %968
  %970 = zext i1 %969 to i8
  store i8 %970, i8* %51, align 1, !tbaa !2433
  %971 = and i32 %965, 255
  %972 = tail call i32 @llvm.ctpop.i32(i32 %971) #10
  %973 = trunc i32 %972 to i8
  %974 = and i8 %973, 1
  %975 = xor i8 %974, 1
  store i8 %975, i8* %52, align 1, !tbaa !2447
  %976 = xor i32 %964, %965
  %977 = lshr i32 %976, 4
  %978 = trunc i32 %977 to i8
  %979 = and i8 %978, 1
  store i8 %979, i8* %53, align 1, !tbaa !2451
  %980 = icmp eq i32 %965, 0
  %981 = zext i1 %980 to i8
  store i8 %981, i8* %54, align 1, !tbaa !2448
  %982 = lshr i32 %965, 31
  %983 = trunc i32 %982 to i8
  store i8 %983, i8* %55, align 1, !tbaa !2449
  %984 = lshr i32 %964, 31
  %985 = xor i32 %982, %984
  %986 = add nuw nsw i32 %985, %982
  %987 = icmp eq i32 %986, 2
  %988 = zext i1 %987 to i8
  store i8 %988, i8* %56, align 1, !tbaa !2450
  %989 = sext i32 %965 to i64
  store i64 %989, i64* %RSI, align 8, !tbaa !2428
  %990 = shl nsw i64 %989, 3
  %991 = add i64 %990, %960
  %992 = add i64 %952, 23
  store i64 %992, i64* %PC, align 8
  %993 = inttoptr i64 %991 to i64*
  store i64 %955, i64* %993, align 8
  %994 = load i64, i64* %RBP, align 8
  %995 = add i64 %994, -52
  %996 = load i64, i64* %PC, align 8
  %997 = add i64 %996, 3
  store i64 %997, i64* %PC, align 8
  %998 = inttoptr i64 %995 to i32*
  %999 = load i32, i32* %998, align 4
  %1000 = zext i32 %999 to i64
  store i64 %1000, i64* %RCX, align 8, !tbaa !2428
  %1001 = add i64 %994, -32
  %1002 = add i64 %996, 6
  store i64 %1002, i64* %PC, align 8
  %1003 = inttoptr i64 %1001 to i32*
  %1004 = load i32, i32* %1003, align 4
  %1005 = add i32 %1004, %999
  %1006 = zext i32 %1005 to i64
  store i64 %1006, i64* %RCX, align 8, !tbaa !2428
  %1007 = icmp ult i32 %1005, %999
  %1008 = icmp ult i32 %1005, %1004
  %1009 = or i1 %1007, %1008
  %1010 = zext i1 %1009 to i8
  store i8 %1010, i8* %51, align 1, !tbaa !2433
  %1011 = and i32 %1005, 255
  %1012 = tail call i32 @llvm.ctpop.i32(i32 %1011) #10
  %1013 = trunc i32 %1012 to i8
  %1014 = and i8 %1013, 1
  %1015 = xor i8 %1014, 1
  store i8 %1015, i8* %52, align 1, !tbaa !2447
  %1016 = xor i32 %1004, %999
  %1017 = xor i32 %1016, %1005
  %1018 = lshr i32 %1017, 4
  %1019 = trunc i32 %1018 to i8
  %1020 = and i8 %1019, 1
  store i8 %1020, i8* %53, align 1, !tbaa !2451
  %1021 = icmp eq i32 %1005, 0
  %1022 = zext i1 %1021 to i8
  store i8 %1022, i8* %54, align 1, !tbaa !2448
  %1023 = lshr i32 %1005, 31
  %1024 = trunc i32 %1023 to i8
  store i8 %1024, i8* %55, align 1, !tbaa !2449
  %1025 = lshr i32 %999, 31
  %1026 = lshr i32 %1004, 31
  %1027 = xor i32 %1023, %1025
  %1028 = xor i32 %1023, %1026
  %1029 = add nuw nsw i32 %1027, %1028
  %1030 = icmp eq i32 %1029, 2
  %1031 = zext i1 %1030 to i8
  store i8 %1031, i8* %56, align 1, !tbaa !2450
  %1032 = add i64 %996, 9
  store i64 %1032, i64* %PC, align 8
  store i32 %1005, i32* %1003, align 4
  %1033 = load i64, i64* %RBP, align 8
  %1034 = add i64 %1033, -52
  %1035 = load i64, i64* %PC, align 8
  %1036 = add i64 %1035, 3
  store i64 %1036, i64* %PC, align 8
  %1037 = inttoptr i64 %1034 to i32*
  %1038 = load i32, i32* %1037, align 4
  %1039 = shl i32 %1038, 1
  %1040 = icmp slt i32 %1038, 0
  %1041 = icmp slt i32 %1039, 0
  %1042 = xor i1 %1040, %1041
  %1043 = zext i32 %1039 to i64
  store i64 %1043, i64* %RCX, align 8, !tbaa !2428
  %.lobit18 = lshr i32 %1038, 31
  %1044 = trunc i32 %.lobit18 to i8
  store i8 %1044, i8* %51, align 1, !tbaa !2432
  %1045 = and i32 %1039, 254
  %1046 = tail call i32 @llvm.ctpop.i32(i32 %1045) #10
  %1047 = trunc i32 %1046 to i8
  %1048 = and i8 %1047, 1
  %1049 = xor i8 %1048, 1
  store i8 %1049, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %1050 = icmp eq i32 %1039, 0
  %1051 = zext i1 %1050 to i8
  store i8 %1051, i8* %54, align 1, !tbaa !2432
  %1052 = lshr i32 %1038, 30
  %1053 = and i32 %1052, 1
  %1054 = trunc i32 %1053 to i8
  store i8 %1054, i8* %55, align 1, !tbaa !2432
  %1055 = zext i1 %1042 to i8
  store i8 %1055, i8* %56, align 1, !tbaa !2432
  %1056 = add i64 %1033, -40
  %1057 = add i64 %1035, 9
  store i64 %1057, i64* %PC, align 8
  %1058 = inttoptr i64 %1056 to i32*
  %1059 = load i32, i32* %1058, align 4
  %1060 = add i32 %1059, %1039
  %1061 = zext i32 %1060 to i64
  store i64 %1061, i64* %RCX, align 8, !tbaa !2428
  %1062 = icmp ult i32 %1060, %1039
  %1063 = icmp ult i32 %1060, %1059
  %1064 = or i1 %1062, %1063
  %1065 = zext i1 %1064 to i8
  store i8 %1065, i8* %51, align 1, !tbaa !2433
  %1066 = and i32 %1060, 255
  %1067 = tail call i32 @llvm.ctpop.i32(i32 %1066) #10
  %1068 = trunc i32 %1067 to i8
  %1069 = and i8 %1068, 1
  %1070 = xor i8 %1069, 1
  store i8 %1070, i8* %52, align 1, !tbaa !2447
  %1071 = xor i32 %1059, %1039
  %1072 = xor i32 %1071, %1060
  %1073 = lshr i32 %1072, 4
  %1074 = trunc i32 %1073 to i8
  %1075 = and i8 %1074, 1
  store i8 %1075, i8* %53, align 1, !tbaa !2451
  %1076 = icmp eq i32 %1060, 0
  %1077 = zext i1 %1076 to i8
  store i8 %1077, i8* %54, align 1, !tbaa !2448
  %1078 = lshr i32 %1060, 31
  %1079 = trunc i32 %1078 to i8
  store i8 %1079, i8* %55, align 1, !tbaa !2449
  %1080 = lshr i32 %1059, 31
  %1081 = xor i32 %1078, %1053
  %1082 = xor i32 %1078, %1080
  %1083 = add nuw nsw i32 %1081, %1082
  %1084 = icmp eq i32 %1083, 2
  %1085 = zext i1 %1084 to i8
  store i8 %1085, i8* %56, align 1, !tbaa !2450
  %1086 = add i64 %1035, 12
  store i64 %1086, i64* %PC, align 8
  store i32 %1060, i32* %1058, align 4
  %1087 = load i64, i64* %RBP, align 8
  %1088 = add i64 %1087, -24
  %1089 = load i64, i64* %PC, align 8
  %1090 = add i64 %1089, 4
  store i64 %1090, i64* %PC, align 8
  %1091 = inttoptr i64 %1088 to i64*
  %1092 = load i64, i64* %1091, align 8
  store i64 %1092, i64* %RDX, align 8, !tbaa !2428
  %1093 = add i64 %1087, -32
  %1094 = add i64 %1089, 8
  store i64 %1094, i64* %PC, align 8
  %1095 = inttoptr i64 %1093 to i32*
  %1096 = load i32, i32* %1095, align 4
  %1097 = sext i32 %1096 to i64
  store i64 %1097, i64* %RSI, align 8, !tbaa !2428
  %1098 = shl nsw i64 %1097, 3
  %1099 = add i64 %1098, %1092
  %1100 = add i64 %1089, 13
  store i64 %1100, i64* %PC, align 8
  %1101 = inttoptr i64 %1099 to i64*
  %1102 = load i64, i64* %1101, align 8
  %1103 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1102, i64* %1103, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1104 = add i64 %1087, -64
  %1105 = add i64 %1089, 18
  store i64 %1105, i64* %PC, align 8
  %1106 = inttoptr i64 %1104 to i64*
  store i64 %1102, i64* %1106, align 8
  %1107 = load i64, i64* %RBP, align 8
  %1108 = add i64 %1107, -24
  %1109 = load i64, i64* %PC, align 8
  %1110 = add i64 %1109, 4
  store i64 %1110, i64* %PC, align 8
  %1111 = inttoptr i64 %1108 to i64*
  %1112 = load i64, i64* %1111, align 8
  store i64 %1112, i64* %RDX, align 8, !tbaa !2428
  %1113 = add i64 %1107, -32
  %1114 = add i64 %1109, 7
  store i64 %1114, i64* %PC, align 8
  %1115 = inttoptr i64 %1113 to i32*
  %1116 = load i32, i32* %1115, align 4
  %1117 = add i32 %1116, 1
  %1118 = zext i32 %1117 to i64
  store i64 %1118, i64* %RCX, align 8, !tbaa !2428
  %1119 = icmp eq i32 %1116, -1
  %1120 = icmp eq i32 %1117, 0
  %1121 = or i1 %1119, %1120
  %1122 = zext i1 %1121 to i8
  store i8 %1122, i8* %51, align 1, !tbaa !2433
  %1123 = and i32 %1117, 255
  %1124 = tail call i32 @llvm.ctpop.i32(i32 %1123) #10
  %1125 = trunc i32 %1124 to i8
  %1126 = and i8 %1125, 1
  %1127 = xor i8 %1126, 1
  store i8 %1127, i8* %52, align 1, !tbaa !2447
  %1128 = xor i32 %1116, %1117
  %1129 = lshr i32 %1128, 4
  %1130 = trunc i32 %1129 to i8
  %1131 = and i8 %1130, 1
  store i8 %1131, i8* %53, align 1, !tbaa !2451
  %1132 = icmp eq i32 %1117, 0
  %1133 = zext i1 %1132 to i8
  store i8 %1133, i8* %54, align 1, !tbaa !2448
  %1134 = lshr i32 %1117, 31
  %1135 = trunc i32 %1134 to i8
  store i8 %1135, i8* %55, align 1, !tbaa !2449
  %1136 = lshr i32 %1116, 31
  %1137 = xor i32 %1134, %1136
  %1138 = add nuw nsw i32 %1137, %1134
  %1139 = icmp eq i32 %1138, 2
  %1140 = zext i1 %1139 to i8
  store i8 %1140, i8* %56, align 1, !tbaa !2450
  %1141 = sext i32 %1117 to i64
  store i64 %1141, i64* %RSI, align 8, !tbaa !2428
  %1142 = shl nsw i64 %1141, 3
  %1143 = add i64 %1142, %1112
  %1144 = add i64 %1109, 18
  store i64 %1144, i64* %PC, align 8
  %1145 = inttoptr i64 %1143 to i64*
  %1146 = load i64, i64* %1145, align 8
  %1147 = load i64, i64* %RAX, align 8
  %1148 = xor i64 %1147, %1146
  store i64 %1148, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %1149 = trunc i64 %1148 to i32
  %1150 = and i32 %1149, 255
  %1151 = tail call i32 @llvm.ctpop.i32(i32 %1150) #10
  %1152 = trunc i32 %1151 to i8
  %1153 = and i8 %1152, 1
  %1154 = xor i8 %1153, 1
  store i8 %1154, i8* %52, align 1, !tbaa !2447
  %1155 = icmp eq i64 %1148, 0
  %1156 = zext i1 %1155 to i8
  store i8 %1156, i8* %54, align 1, !tbaa !2448
  %1157 = lshr i64 %1148, 63
  %1158 = trunc i64 %1157 to i8
  store i8 %1158, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %1148, i64* %3940, align 1, !tbaa !2428
  store i64 0, i64* %3938, align 1, !tbaa !2428
  %1159 = add i64 %1107, -72
  %1160 = add i64 %1109, 36
  store i64 %1160, i64* %PC, align 8
  %1161 = inttoptr i64 %1159 to i64*
  store i64 %1148, i64* %1161, align 8
  %1162 = load i64, i64* %RBP, align 8
  %1163 = add i64 %1162, -24
  %1164 = load i64, i64* %PC, align 8
  %1165 = add i64 %1164, 4
  store i64 %1165, i64* %PC, align 8
  %1166 = inttoptr i64 %1163 to i64*
  %1167 = load i64, i64* %1166, align 8
  store i64 %1167, i64* %RDX, align 8, !tbaa !2428
  %1168 = add i64 %1162, -40
  %1169 = add i64 %1164, 8
  store i64 %1169, i64* %PC, align 8
  %1170 = inttoptr i64 %1168 to i32*
  %1171 = load i32, i32* %1170, align 4
  %1172 = sext i32 %1171 to i64
  store i64 %1172, i64* %RSI, align 8, !tbaa !2428
  %1173 = shl nsw i64 %1172, 3
  %1174 = add i64 %1173, %1167
  %1175 = add i64 %1164, 13
  store i64 %1175, i64* %PC, align 8
  %1176 = inttoptr i64 %1174 to i64*
  %1177 = load i64, i64* %1176, align 8
  %1178 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1177, i64* %1178, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1179 = add i64 %1162, -80
  %1180 = add i64 %1164, 18
  store i64 %1180, i64* %PC, align 8
  %1181 = inttoptr i64 %1179 to i64*
  store i64 %1177, i64* %1181, align 8
  %1182 = load i64, i64* %RBP, align 8
  %1183 = add i64 %1182, -24
  %1184 = load i64, i64* %PC, align 8
  %1185 = add i64 %1184, 4
  store i64 %1185, i64* %PC, align 8
  %1186 = inttoptr i64 %1183 to i64*
  %1187 = load i64, i64* %1186, align 8
  store i64 %1187, i64* %RDX, align 8, !tbaa !2428
  %1188 = add i64 %1182, -40
  %1189 = add i64 %1184, 7
  store i64 %1189, i64* %PC, align 8
  %1190 = inttoptr i64 %1188 to i32*
  %1191 = load i32, i32* %1190, align 4
  %1192 = add i32 %1191, 1
  %1193 = zext i32 %1192 to i64
  store i64 %1193, i64* %RCX, align 8, !tbaa !2428
  %1194 = icmp eq i32 %1191, -1
  %1195 = icmp eq i32 %1192, 0
  %1196 = or i1 %1194, %1195
  %1197 = zext i1 %1196 to i8
  store i8 %1197, i8* %51, align 1, !tbaa !2433
  %1198 = and i32 %1192, 255
  %1199 = tail call i32 @llvm.ctpop.i32(i32 %1198) #10
  %1200 = trunc i32 %1199 to i8
  %1201 = and i8 %1200, 1
  %1202 = xor i8 %1201, 1
  store i8 %1202, i8* %52, align 1, !tbaa !2447
  %1203 = xor i32 %1191, %1192
  %1204 = lshr i32 %1203, 4
  %1205 = trunc i32 %1204 to i8
  %1206 = and i8 %1205, 1
  store i8 %1206, i8* %53, align 1, !tbaa !2451
  %1207 = icmp eq i32 %1192, 0
  %1208 = zext i1 %1207 to i8
  store i8 %1208, i8* %54, align 1, !tbaa !2448
  %1209 = lshr i32 %1192, 31
  %1210 = trunc i32 %1209 to i8
  store i8 %1210, i8* %55, align 1, !tbaa !2449
  %1211 = lshr i32 %1191, 31
  %1212 = xor i32 %1209, %1211
  %1213 = add nuw nsw i32 %1212, %1209
  %1214 = icmp eq i32 %1213, 2
  %1215 = zext i1 %1214 to i8
  store i8 %1215, i8* %56, align 1, !tbaa !2450
  %1216 = sext i32 %1192 to i64
  store i64 %1216, i64* %RSI, align 8, !tbaa !2428
  %1217 = shl nsw i64 %1216, 3
  %1218 = add i64 %1217, %1187
  %1219 = add i64 %1184, 18
  store i64 %1219, i64* %PC, align 8
  %1220 = inttoptr i64 %1218 to i64*
  %1221 = load i64, i64* %1220, align 8
  %1222 = load i64, i64* %RAX, align 8
  %1223 = xor i64 %1222, %1221
  store i64 %1223, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %1224 = trunc i64 %1223 to i32
  %1225 = and i32 %1224, 255
  %1226 = tail call i32 @llvm.ctpop.i32(i32 %1225) #10
  %1227 = trunc i32 %1226 to i8
  %1228 = and i8 %1227, 1
  %1229 = xor i8 %1228, 1
  store i8 %1229, i8* %52, align 1, !tbaa !2447
  %1230 = icmp eq i64 %1223, 0
  %1231 = zext i1 %1230 to i8
  store i8 %1231, i8* %54, align 1, !tbaa !2448
  %1232 = lshr i64 %1223, 63
  %1233 = trunc i64 %1232 to i8
  store i8 %1233, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %1223, i64* %3940, align 1, !tbaa !2428
  store i64 0, i64* %3938, align 1, !tbaa !2428
  %1234 = add i64 %1182, -88
  %1235 = add i64 %1184, 36
  store i64 %1235, i64* %PC, align 8
  %1236 = inttoptr i64 %1234 to i64*
  store i64 %1223, i64* %1236, align 8
  %1237 = load i64, i64* %RBP, align 8
  %1238 = add i64 %1237, -80
  %1239 = load i64, i64* %PC, align 8
  %1240 = add i64 %1239, 5
  store i64 %1240, i64* %PC, align 8
  %1241 = inttoptr i64 %1238 to i64*
  %1242 = load i64, i64* %1241, align 8
  %1243 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1242, i64* %1243, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1244 = add i64 %1237, -24
  %1245 = add i64 %1239, 9
  store i64 %1245, i64* %PC, align 8
  %1246 = inttoptr i64 %1244 to i64*
  %1247 = load i64, i64* %1246, align 8
  store i64 %1247, i64* %RDX, align 8, !tbaa !2428
  %1248 = add i64 %1237, -32
  %1249 = add i64 %1239, 13
  store i64 %1249, i64* %PC, align 8
  %1250 = inttoptr i64 %1248 to i32*
  %1251 = load i32, i32* %1250, align 4
  %1252 = sext i32 %1251 to i64
  store i64 %1252, i64* %RSI, align 8, !tbaa !2428
  %1253 = shl nsw i64 %1252, 3
  %1254 = add i64 %1253, %1247
  %1255 = add i64 %1239, 18
  store i64 %1255, i64* %PC, align 8
  %1256 = inttoptr i64 %1254 to i64*
  store i64 %1242, i64* %1256, align 8
  %1257 = load i64, i64* %RBP, align 8
  %1258 = add i64 %1257, -88
  %1259 = load i64, i64* %PC, align 8
  %1260 = add i64 %1259, 5
  store i64 %1260, i64* %PC, align 8
  %1261 = inttoptr i64 %1258 to i64*
  %1262 = load i64, i64* %1261, align 8
  %1263 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1262, i64* %1263, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1264 = add i64 %1257, -24
  %1265 = add i64 %1259, 9
  store i64 %1265, i64* %PC, align 8
  %1266 = inttoptr i64 %1264 to i64*
  %1267 = load i64, i64* %1266, align 8
  store i64 %1267, i64* %RDX, align 8, !tbaa !2428
  %1268 = add i64 %1257, -32
  %1269 = add i64 %1259, 12
  store i64 %1269, i64* %PC, align 8
  %1270 = inttoptr i64 %1268 to i32*
  %1271 = load i32, i32* %1270, align 4
  %1272 = add i32 %1271, 1
  %1273 = zext i32 %1272 to i64
  store i64 %1273, i64* %RCX, align 8, !tbaa !2428
  %1274 = icmp eq i32 %1271, -1
  %1275 = icmp eq i32 %1272, 0
  %1276 = or i1 %1274, %1275
  %1277 = zext i1 %1276 to i8
  store i8 %1277, i8* %51, align 1, !tbaa !2433
  %1278 = and i32 %1272, 255
  %1279 = tail call i32 @llvm.ctpop.i32(i32 %1278) #10
  %1280 = trunc i32 %1279 to i8
  %1281 = and i8 %1280, 1
  %1282 = xor i8 %1281, 1
  store i8 %1282, i8* %52, align 1, !tbaa !2447
  %1283 = xor i32 %1271, %1272
  %1284 = lshr i32 %1283, 4
  %1285 = trunc i32 %1284 to i8
  %1286 = and i8 %1285, 1
  store i8 %1286, i8* %53, align 1, !tbaa !2451
  %1287 = icmp eq i32 %1272, 0
  %1288 = zext i1 %1287 to i8
  store i8 %1288, i8* %54, align 1, !tbaa !2448
  %1289 = lshr i32 %1272, 31
  %1290 = trunc i32 %1289 to i8
  store i8 %1290, i8* %55, align 1, !tbaa !2449
  %1291 = lshr i32 %1271, 31
  %1292 = xor i32 %1289, %1291
  %1293 = add nuw nsw i32 %1292, %1289
  %1294 = icmp eq i32 %1293, 2
  %1295 = zext i1 %1294 to i8
  store i8 %1295, i8* %56, align 1, !tbaa !2450
  %1296 = sext i32 %1272 to i64
  store i64 %1296, i64* %RSI, align 8, !tbaa !2428
  %1297 = shl nsw i64 %1296, 3
  %1298 = add i64 %1297, %1267
  %1299 = add i64 %1259, 23
  store i64 %1299, i64* %PC, align 8
  %1300 = inttoptr i64 %1298 to i64*
  store i64 %1262, i64* %1300, align 8
  %1301 = load i64, i64* %RBP, align 8
  %1302 = add i64 %1301, -64
  %1303 = load i64, i64* %PC, align 8
  %1304 = add i64 %1303, 5
  store i64 %1304, i64* %PC, align 8
  %1305 = inttoptr i64 %1302 to i64*
  %1306 = load i64, i64* %1305, align 8
  %1307 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1306, i64* %1307, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1308 = add i64 %1301, -24
  %1309 = add i64 %1303, 9
  store i64 %1309, i64* %PC, align 8
  %1310 = inttoptr i64 %1308 to i64*
  %1311 = load i64, i64* %1310, align 8
  store i64 %1311, i64* %RDX, align 8, !tbaa !2428
  %1312 = add i64 %1301, -40
  %1313 = add i64 %1303, 13
  store i64 %1313, i64* %PC, align 8
  %1314 = inttoptr i64 %1312 to i32*
  %1315 = load i32, i32* %1314, align 4
  %1316 = sext i32 %1315 to i64
  store i64 %1316, i64* %RSI, align 8, !tbaa !2428
  %1317 = shl nsw i64 %1316, 3
  %1318 = add i64 %1317, %1311
  %1319 = add i64 %1303, 18
  store i64 %1319, i64* %PC, align 8
  %1320 = inttoptr i64 %1318 to i64*
  store i64 %1306, i64* %1320, align 8
  %1321 = load i64, i64* %RBP, align 8
  %1322 = add i64 %1321, -72
  %1323 = load i64, i64* %PC, align 8
  %1324 = add i64 %1323, 5
  store i64 %1324, i64* %PC, align 8
  %1325 = inttoptr i64 %1322 to i64*
  %1326 = load i64, i64* %1325, align 8
  %1327 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1326, i64* %1327, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1328 = add i64 %1321, -24
  %1329 = add i64 %1323, 9
  store i64 %1329, i64* %PC, align 8
  %1330 = inttoptr i64 %1328 to i64*
  %1331 = load i64, i64* %1330, align 8
  store i64 %1331, i64* %RDX, align 8, !tbaa !2428
  %1332 = add i64 %1321, -40
  %1333 = add i64 %1323, 12
  store i64 %1333, i64* %PC, align 8
  %1334 = inttoptr i64 %1332 to i32*
  %1335 = load i32, i32* %1334, align 4
  %1336 = add i32 %1335, 1
  %1337 = zext i32 %1336 to i64
  store i64 %1337, i64* %RCX, align 8, !tbaa !2428
  %1338 = icmp eq i32 %1335, -1
  %1339 = icmp eq i32 %1336, 0
  %1340 = or i1 %1338, %1339
  %1341 = zext i1 %1340 to i8
  store i8 %1341, i8* %51, align 1, !tbaa !2433
  %1342 = and i32 %1336, 255
  %1343 = tail call i32 @llvm.ctpop.i32(i32 %1342) #10
  %1344 = trunc i32 %1343 to i8
  %1345 = and i8 %1344, 1
  %1346 = xor i8 %1345, 1
  store i8 %1346, i8* %52, align 1, !tbaa !2447
  %1347 = xor i32 %1335, %1336
  %1348 = lshr i32 %1347, 4
  %1349 = trunc i32 %1348 to i8
  %1350 = and i8 %1349, 1
  store i8 %1350, i8* %53, align 1, !tbaa !2451
  %1351 = icmp eq i32 %1336, 0
  %1352 = zext i1 %1351 to i8
  store i8 %1352, i8* %54, align 1, !tbaa !2448
  %1353 = lshr i32 %1336, 31
  %1354 = trunc i32 %1353 to i8
  store i8 %1354, i8* %55, align 1, !tbaa !2449
  %1355 = lshr i32 %1335, 31
  %1356 = xor i32 %1353, %1355
  %1357 = add nuw nsw i32 %1356, %1353
  %1358 = icmp eq i32 %1357, 2
  %1359 = zext i1 %1358 to i8
  store i8 %1359, i8* %56, align 1, !tbaa !2450
  %1360 = sext i32 %1336 to i64
  store i64 %1360, i64* %RSI, align 8, !tbaa !2428
  %1361 = shl nsw i64 %1360, 3
  %1362 = add i64 %1361, %1331
  %1363 = add i64 %1323, 23
  store i64 %1363, i64* %PC, align 8
  %1364 = inttoptr i64 %1362 to i64*
  store i64 %1326, i64* %1364, align 8
  %1365 = load i64, i64* %RBP, align 8
  %1366 = add i64 %1365, -52
  %1367 = load i64, i64* %PC, align 8
  %1368 = add i64 %1367, 3
  store i64 %1368, i64* %PC, align 8
  %1369 = inttoptr i64 %1366 to i32*
  %1370 = load i32, i32* %1369, align 4
  %1371 = zext i32 %1370 to i64
  store i64 %1371, i64* %RCX, align 8, !tbaa !2428
  %1372 = add i64 %1365, -32
  %1373 = add i64 %1367, 6
  store i64 %1373, i64* %PC, align 8
  %1374 = inttoptr i64 %1372 to i32*
  %1375 = load i32, i32* %1374, align 4
  %1376 = add i32 %1375, %1370
  %1377 = zext i32 %1376 to i64
  store i64 %1377, i64* %RCX, align 8, !tbaa !2428
  %1378 = icmp ult i32 %1376, %1370
  %1379 = icmp ult i32 %1376, %1375
  %1380 = or i1 %1378, %1379
  %1381 = zext i1 %1380 to i8
  store i8 %1381, i8* %51, align 1, !tbaa !2433
  %1382 = and i32 %1376, 255
  %1383 = tail call i32 @llvm.ctpop.i32(i32 %1382) #10
  %1384 = trunc i32 %1383 to i8
  %1385 = and i8 %1384, 1
  %1386 = xor i8 %1385, 1
  store i8 %1386, i8* %52, align 1, !tbaa !2447
  %1387 = xor i32 %1375, %1370
  %1388 = xor i32 %1387, %1376
  %1389 = lshr i32 %1388, 4
  %1390 = trunc i32 %1389 to i8
  %1391 = and i8 %1390, 1
  store i8 %1391, i8* %53, align 1, !tbaa !2451
  %1392 = icmp eq i32 %1376, 0
  %1393 = zext i1 %1392 to i8
  store i8 %1393, i8* %54, align 1, !tbaa !2448
  %1394 = lshr i32 %1376, 31
  %1395 = trunc i32 %1394 to i8
  store i8 %1395, i8* %55, align 1, !tbaa !2449
  %1396 = lshr i32 %1370, 31
  %1397 = lshr i32 %1375, 31
  %1398 = xor i32 %1394, %1396
  %1399 = xor i32 %1394, %1397
  %1400 = add nuw nsw i32 %1398, %1399
  %1401 = icmp eq i32 %1400, 2
  %1402 = zext i1 %1401 to i8
  store i8 %1402, i8* %56, align 1, !tbaa !2450
  %1403 = add i64 %1367, 9
  store i64 %1403, i64* %PC, align 8
  store i32 %1376, i32* %1374, align 4
  %1404 = load i64, i64* %RBP, align 8
  %1405 = add i64 %1404, -52
  %1406 = load i64, i64* %PC, align 8
  %1407 = add i64 %1406, 3
  store i64 %1407, i64* %PC, align 8
  %1408 = inttoptr i64 %1405 to i32*
  %1409 = load i32, i32* %1408, align 4
  %1410 = zext i32 %1409 to i64
  store i64 %1410, i64* %RCX, align 8, !tbaa !2428
  %1411 = add i64 %1404, -40
  %1412 = add i64 %1406, 6
  store i64 %1412, i64* %PC, align 8
  %1413 = inttoptr i64 %1411 to i32*
  %1414 = load i32, i32* %1413, align 4
  %1415 = sub i32 %1414, %1409
  %1416 = zext i32 %1415 to i64
  store i64 %1416, i64* %RDI, align 8, !tbaa !2428
  %1417 = icmp ult i32 %1414, %1409
  %1418 = zext i1 %1417 to i8
  store i8 %1418, i8* %51, align 1, !tbaa !2433
  %1419 = and i32 %1415, 255
  %1420 = tail call i32 @llvm.ctpop.i32(i32 %1419) #10
  %1421 = trunc i32 %1420 to i8
  %1422 = and i8 %1421, 1
  %1423 = xor i8 %1422, 1
  store i8 %1423, i8* %52, align 1, !tbaa !2447
  %1424 = xor i32 %1409, %1414
  %1425 = xor i32 %1424, %1415
  %1426 = lshr i32 %1425, 4
  %1427 = trunc i32 %1426 to i8
  %1428 = and i8 %1427, 1
  store i8 %1428, i8* %53, align 1, !tbaa !2451
  %1429 = icmp eq i32 %1415, 0
  %1430 = zext i1 %1429 to i8
  store i8 %1430, i8* %54, align 1, !tbaa !2448
  %1431 = lshr i32 %1415, 31
  %1432 = trunc i32 %1431 to i8
  store i8 %1432, i8* %55, align 1, !tbaa !2449
  %1433 = lshr i32 %1414, 31
  %1434 = lshr i32 %1409, 31
  %1435 = xor i32 %1434, %1433
  %1436 = xor i32 %1431, %1433
  %1437 = add nuw nsw i32 %1436, %1435
  %1438 = icmp eq i32 %1437, 2
  %1439 = zext i1 %1438 to i8
  store i8 %1439, i8* %56, align 1, !tbaa !2450
  %1440 = add i64 %1406, 11
  store i64 %1440, i64* %PC, align 8
  store i32 %1415, i32* %1413, align 4
  %1441 = load i64, i64* %RBP, align 8
  %1442 = add i64 %1441, -24
  %1443 = load i64, i64* %PC, align 8
  %1444 = add i64 %1443, 4
  store i64 %1444, i64* %PC, align 8
  %1445 = inttoptr i64 %1442 to i64*
  %1446 = load i64, i64* %1445, align 8
  store i64 %1446, i64* %RDX, align 8, !tbaa !2428
  %1447 = add i64 %1441, -32
  %1448 = add i64 %1443, 8
  store i64 %1448, i64* %PC, align 8
  %1449 = inttoptr i64 %1447 to i32*
  %1450 = load i32, i32* %1449, align 4
  %1451 = sext i32 %1450 to i64
  store i64 %1451, i64* %RSI, align 8, !tbaa !2428
  %1452 = shl nsw i64 %1451, 3
  %1453 = add i64 %1452, %1446
  %1454 = add i64 %1443, 13
  store i64 %1454, i64* %PC, align 8
  %1455 = inttoptr i64 %1453 to i64*
  %1456 = load i64, i64* %1455, align 8
  %1457 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1456, i64* %1457, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1458 = add i64 %1441, -64
  %1459 = add i64 %1443, 18
  store i64 %1459, i64* %PC, align 8
  %1460 = inttoptr i64 %1458 to i64*
  store i64 %1456, i64* %1460, align 8
  %1461 = load i64, i64* %RBP, align 8
  %1462 = add i64 %1461, -24
  %1463 = load i64, i64* %PC, align 8
  %1464 = add i64 %1463, 4
  store i64 %1464, i64* %PC, align 8
  %1465 = inttoptr i64 %1462 to i64*
  %1466 = load i64, i64* %1465, align 8
  store i64 %1466, i64* %RDX, align 8, !tbaa !2428
  %1467 = add i64 %1461, -32
  %1468 = add i64 %1463, 7
  store i64 %1468, i64* %PC, align 8
  %1469 = inttoptr i64 %1467 to i32*
  %1470 = load i32, i32* %1469, align 4
  %1471 = add i32 %1470, 1
  %1472 = zext i32 %1471 to i64
  store i64 %1472, i64* %RCX, align 8, !tbaa !2428
  %1473 = icmp eq i32 %1470, -1
  %1474 = icmp eq i32 %1471, 0
  %1475 = or i1 %1473, %1474
  %1476 = zext i1 %1475 to i8
  store i8 %1476, i8* %51, align 1, !tbaa !2433
  %1477 = and i32 %1471, 255
  %1478 = tail call i32 @llvm.ctpop.i32(i32 %1477) #10
  %1479 = trunc i32 %1478 to i8
  %1480 = and i8 %1479, 1
  %1481 = xor i8 %1480, 1
  store i8 %1481, i8* %52, align 1, !tbaa !2447
  %1482 = xor i32 %1470, %1471
  %1483 = lshr i32 %1482, 4
  %1484 = trunc i32 %1483 to i8
  %1485 = and i8 %1484, 1
  store i8 %1485, i8* %53, align 1, !tbaa !2451
  %1486 = icmp eq i32 %1471, 0
  %1487 = zext i1 %1486 to i8
  store i8 %1487, i8* %54, align 1, !tbaa !2448
  %1488 = lshr i32 %1471, 31
  %1489 = trunc i32 %1488 to i8
  store i8 %1489, i8* %55, align 1, !tbaa !2449
  %1490 = lshr i32 %1470, 31
  %1491 = xor i32 %1488, %1490
  %1492 = add nuw nsw i32 %1491, %1488
  %1493 = icmp eq i32 %1492, 2
  %1494 = zext i1 %1493 to i8
  store i8 %1494, i8* %56, align 1, !tbaa !2450
  %1495 = sext i32 %1471 to i64
  store i64 %1495, i64* %RSI, align 8, !tbaa !2428
  %1496 = shl nsw i64 %1495, 3
  %1497 = add i64 %1496, %1466
  %1498 = add i64 %1463, 18
  store i64 %1498, i64* %PC, align 8
  %1499 = inttoptr i64 %1497 to i64*
  %1500 = load i64, i64* %1499, align 8
  %1501 = load i64, i64* %RAX, align 8
  %1502 = xor i64 %1501, %1500
  store i64 %1502, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %1503 = trunc i64 %1502 to i32
  %1504 = and i32 %1503, 255
  %1505 = tail call i32 @llvm.ctpop.i32(i32 %1504) #10
  %1506 = trunc i32 %1505 to i8
  %1507 = and i8 %1506, 1
  %1508 = xor i8 %1507, 1
  store i8 %1508, i8* %52, align 1, !tbaa !2447
  %1509 = icmp eq i64 %1502, 0
  %1510 = zext i1 %1509 to i8
  store i8 %1510, i8* %54, align 1, !tbaa !2448
  %1511 = lshr i64 %1502, 63
  %1512 = trunc i64 %1511 to i8
  store i8 %1512, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %1502, i64* %3940, align 1, !tbaa !2428
  store i64 0, i64* %3938, align 1, !tbaa !2428
  %1513 = add i64 %1461, -72
  %1514 = add i64 %1463, 36
  store i64 %1514, i64* %PC, align 8
  %1515 = inttoptr i64 %1513 to i64*
  store i64 %1502, i64* %1515, align 8
  %1516 = load i64, i64* %RBP, align 8
  %1517 = add i64 %1516, -24
  %1518 = load i64, i64* %PC, align 8
  %1519 = add i64 %1518, 4
  store i64 %1519, i64* %PC, align 8
  %1520 = inttoptr i64 %1517 to i64*
  %1521 = load i64, i64* %1520, align 8
  store i64 %1521, i64* %RDX, align 8, !tbaa !2428
  %1522 = add i64 %1516, -40
  %1523 = add i64 %1518, 8
  store i64 %1523, i64* %PC, align 8
  %1524 = inttoptr i64 %1522 to i32*
  %1525 = load i32, i32* %1524, align 4
  %1526 = sext i32 %1525 to i64
  store i64 %1526, i64* %RSI, align 8, !tbaa !2428
  %1527 = shl nsw i64 %1526, 3
  %1528 = add i64 %1527, %1521
  %1529 = add i64 %1518, 13
  store i64 %1529, i64* %PC, align 8
  %1530 = inttoptr i64 %1528 to i64*
  %1531 = load i64, i64* %1530, align 8
  %1532 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1531, i64* %1532, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1533 = add i64 %1516, -80
  %1534 = add i64 %1518, 18
  store i64 %1534, i64* %PC, align 8
  %1535 = inttoptr i64 %1533 to i64*
  store i64 %1531, i64* %1535, align 8
  %1536 = load i64, i64* %RBP, align 8
  %1537 = add i64 %1536, -24
  %1538 = load i64, i64* %PC, align 8
  %1539 = add i64 %1538, 4
  store i64 %1539, i64* %PC, align 8
  %1540 = inttoptr i64 %1537 to i64*
  %1541 = load i64, i64* %1540, align 8
  store i64 %1541, i64* %RDX, align 8, !tbaa !2428
  %1542 = add i64 %1536, -40
  %1543 = add i64 %1538, 7
  store i64 %1543, i64* %PC, align 8
  %1544 = inttoptr i64 %1542 to i32*
  %1545 = load i32, i32* %1544, align 4
  %1546 = add i32 %1545, 1
  %1547 = zext i32 %1546 to i64
  store i64 %1547, i64* %RCX, align 8, !tbaa !2428
  %1548 = icmp eq i32 %1545, -1
  %1549 = icmp eq i32 %1546, 0
  %1550 = or i1 %1548, %1549
  %1551 = zext i1 %1550 to i8
  store i8 %1551, i8* %51, align 1, !tbaa !2433
  %1552 = and i32 %1546, 255
  %1553 = tail call i32 @llvm.ctpop.i32(i32 %1552) #10
  %1554 = trunc i32 %1553 to i8
  %1555 = and i8 %1554, 1
  %1556 = xor i8 %1555, 1
  store i8 %1556, i8* %52, align 1, !tbaa !2447
  %1557 = xor i32 %1545, %1546
  %1558 = lshr i32 %1557, 4
  %1559 = trunc i32 %1558 to i8
  %1560 = and i8 %1559, 1
  store i8 %1560, i8* %53, align 1, !tbaa !2451
  %1561 = icmp eq i32 %1546, 0
  %1562 = zext i1 %1561 to i8
  store i8 %1562, i8* %54, align 1, !tbaa !2448
  %1563 = lshr i32 %1546, 31
  %1564 = trunc i32 %1563 to i8
  store i8 %1564, i8* %55, align 1, !tbaa !2449
  %1565 = lshr i32 %1545, 31
  %1566 = xor i32 %1563, %1565
  %1567 = add nuw nsw i32 %1566, %1563
  %1568 = icmp eq i32 %1567, 2
  %1569 = zext i1 %1568 to i8
  store i8 %1569, i8* %56, align 1, !tbaa !2450
  %1570 = sext i32 %1546 to i64
  store i64 %1570, i64* %RSI, align 8, !tbaa !2428
  %1571 = shl nsw i64 %1570, 3
  %1572 = add i64 %1571, %1541
  %1573 = add i64 %1538, 18
  store i64 %1573, i64* %PC, align 8
  %1574 = inttoptr i64 %1572 to i64*
  %1575 = load i64, i64* %1574, align 8
  %1576 = load i64, i64* %RAX, align 8
  %1577 = xor i64 %1576, %1575
  store i64 %1577, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %1578 = trunc i64 %1577 to i32
  %1579 = and i32 %1578, 255
  %1580 = tail call i32 @llvm.ctpop.i32(i32 %1579) #10
  %1581 = trunc i32 %1580 to i8
  %1582 = and i8 %1581, 1
  %1583 = xor i8 %1582, 1
  store i8 %1583, i8* %52, align 1, !tbaa !2447
  %1584 = icmp eq i64 %1577, 0
  %1585 = zext i1 %1584 to i8
  store i8 %1585, i8* %54, align 1, !tbaa !2448
  %1586 = lshr i64 %1577, 63
  %1587 = trunc i64 %1586 to i8
  store i8 %1587, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %1577, i64* %3940, align 1, !tbaa !2428
  store i64 0, i64* %3938, align 1, !tbaa !2428
  %1588 = add i64 %1536, -88
  %1589 = add i64 %1538, 36
  store i64 %1589, i64* %PC, align 8
  %1590 = inttoptr i64 %1588 to i64*
  store i64 %1577, i64* %1590, align 8
  %1591 = load i64, i64* %RBP, align 8
  %1592 = add i64 %1591, -80
  %1593 = load i64, i64* %PC, align 8
  %1594 = add i64 %1593, 5
  store i64 %1594, i64* %PC, align 8
  %1595 = inttoptr i64 %1592 to i64*
  %1596 = load i64, i64* %1595, align 8
  %1597 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1596, i64* %1597, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1598 = add i64 %1591, -24
  %1599 = add i64 %1593, 9
  store i64 %1599, i64* %PC, align 8
  %1600 = inttoptr i64 %1598 to i64*
  %1601 = load i64, i64* %1600, align 8
  store i64 %1601, i64* %RDX, align 8, !tbaa !2428
  %1602 = add i64 %1591, -32
  %1603 = add i64 %1593, 13
  store i64 %1603, i64* %PC, align 8
  %1604 = inttoptr i64 %1602 to i32*
  %1605 = load i32, i32* %1604, align 4
  %1606 = sext i32 %1605 to i64
  store i64 %1606, i64* %RSI, align 8, !tbaa !2428
  %1607 = shl nsw i64 %1606, 3
  %1608 = add i64 %1607, %1601
  %1609 = add i64 %1593, 18
  store i64 %1609, i64* %PC, align 8
  %1610 = inttoptr i64 %1608 to i64*
  store i64 %1596, i64* %1610, align 8
  %1611 = load i64, i64* %RBP, align 8
  %1612 = add i64 %1611, -88
  %1613 = load i64, i64* %PC, align 8
  %1614 = add i64 %1613, 5
  store i64 %1614, i64* %PC, align 8
  %1615 = inttoptr i64 %1612 to i64*
  %1616 = load i64, i64* %1615, align 8
  %1617 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1616, i64* %1617, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1618 = add i64 %1611, -24
  %1619 = add i64 %1613, 9
  store i64 %1619, i64* %PC, align 8
  %1620 = inttoptr i64 %1618 to i64*
  %1621 = load i64, i64* %1620, align 8
  store i64 %1621, i64* %RDX, align 8, !tbaa !2428
  %1622 = add i64 %1611, -32
  %1623 = add i64 %1613, 12
  store i64 %1623, i64* %PC, align 8
  %1624 = inttoptr i64 %1622 to i32*
  %1625 = load i32, i32* %1624, align 4
  %1626 = add i32 %1625, 1
  %1627 = zext i32 %1626 to i64
  store i64 %1627, i64* %RCX, align 8, !tbaa !2428
  %1628 = icmp eq i32 %1625, -1
  %1629 = icmp eq i32 %1626, 0
  %1630 = or i1 %1628, %1629
  %1631 = zext i1 %1630 to i8
  store i8 %1631, i8* %51, align 1, !tbaa !2433
  %1632 = and i32 %1626, 255
  %1633 = tail call i32 @llvm.ctpop.i32(i32 %1632) #10
  %1634 = trunc i32 %1633 to i8
  %1635 = and i8 %1634, 1
  %1636 = xor i8 %1635, 1
  store i8 %1636, i8* %52, align 1, !tbaa !2447
  %1637 = xor i32 %1625, %1626
  %1638 = lshr i32 %1637, 4
  %1639 = trunc i32 %1638 to i8
  %1640 = and i8 %1639, 1
  store i8 %1640, i8* %53, align 1, !tbaa !2451
  %1641 = icmp eq i32 %1626, 0
  %1642 = zext i1 %1641 to i8
  store i8 %1642, i8* %54, align 1, !tbaa !2448
  %1643 = lshr i32 %1626, 31
  %1644 = trunc i32 %1643 to i8
  store i8 %1644, i8* %55, align 1, !tbaa !2449
  %1645 = lshr i32 %1625, 31
  %1646 = xor i32 %1643, %1645
  %1647 = add nuw nsw i32 %1646, %1643
  %1648 = icmp eq i32 %1647, 2
  %1649 = zext i1 %1648 to i8
  store i8 %1649, i8* %56, align 1, !tbaa !2450
  %1650 = sext i32 %1626 to i64
  store i64 %1650, i64* %RSI, align 8, !tbaa !2428
  %1651 = shl nsw i64 %1650, 3
  %1652 = add i64 %1651, %1621
  %1653 = add i64 %1613, 23
  store i64 %1653, i64* %PC, align 8
  %1654 = inttoptr i64 %1652 to i64*
  store i64 %1616, i64* %1654, align 8
  %1655 = load i64, i64* %RBP, align 8
  %1656 = add i64 %1655, -64
  %1657 = load i64, i64* %PC, align 8
  %1658 = add i64 %1657, 5
  store i64 %1658, i64* %PC, align 8
  %1659 = inttoptr i64 %1656 to i64*
  %1660 = load i64, i64* %1659, align 8
  %1661 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1660, i64* %1661, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1662 = add i64 %1655, -24
  %1663 = add i64 %1657, 9
  store i64 %1663, i64* %PC, align 8
  %1664 = inttoptr i64 %1662 to i64*
  %1665 = load i64, i64* %1664, align 8
  store i64 %1665, i64* %RDX, align 8, !tbaa !2428
  %1666 = add i64 %1655, -40
  %1667 = add i64 %1657, 13
  store i64 %1667, i64* %PC, align 8
  %1668 = inttoptr i64 %1666 to i32*
  %1669 = load i32, i32* %1668, align 4
  %1670 = sext i32 %1669 to i64
  store i64 %1670, i64* %RSI, align 8, !tbaa !2428
  %1671 = shl nsw i64 %1670, 3
  %1672 = add i64 %1671, %1665
  %1673 = add i64 %1657, 18
  store i64 %1673, i64* %PC, align 8
  %1674 = inttoptr i64 %1672 to i64*
  store i64 %1660, i64* %1674, align 8
  %1675 = load i64, i64* %RBP, align 8
  %1676 = add i64 %1675, -72
  %1677 = load i64, i64* %PC, align 8
  %1678 = add i64 %1677, 5
  store i64 %1678, i64* %PC, align 8
  %1679 = inttoptr i64 %1676 to i64*
  %1680 = load i64, i64* %1679, align 8
  %1681 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1680, i64* %1681, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1682 = add i64 %1675, -24
  %1683 = add i64 %1677, 9
  store i64 %1683, i64* %PC, align 8
  %1684 = inttoptr i64 %1682 to i64*
  %1685 = load i64, i64* %1684, align 8
  store i64 %1685, i64* %RDX, align 8, !tbaa !2428
  %1686 = add i64 %1675, -40
  %1687 = add i64 %1677, 12
  store i64 %1687, i64* %PC, align 8
  %1688 = inttoptr i64 %1686 to i32*
  %1689 = load i32, i32* %1688, align 4
  %1690 = add i32 %1689, 1
  %1691 = zext i32 %1690 to i64
  store i64 %1691, i64* %RCX, align 8, !tbaa !2428
  %1692 = icmp eq i32 %1689, -1
  %1693 = icmp eq i32 %1690, 0
  %1694 = or i1 %1692, %1693
  %1695 = zext i1 %1694 to i8
  store i8 %1695, i8* %51, align 1, !tbaa !2433
  %1696 = and i32 %1690, 255
  %1697 = tail call i32 @llvm.ctpop.i32(i32 %1696) #10
  %1698 = trunc i32 %1697 to i8
  %1699 = and i8 %1698, 1
  %1700 = xor i8 %1699, 1
  store i8 %1700, i8* %52, align 1, !tbaa !2447
  %1701 = xor i32 %1689, %1690
  %1702 = lshr i32 %1701, 4
  %1703 = trunc i32 %1702 to i8
  %1704 = and i8 %1703, 1
  store i8 %1704, i8* %53, align 1, !tbaa !2451
  %1705 = icmp eq i32 %1690, 0
  %1706 = zext i1 %1705 to i8
  store i8 %1706, i8* %54, align 1, !tbaa !2448
  %1707 = lshr i32 %1690, 31
  %1708 = trunc i32 %1707 to i8
  store i8 %1708, i8* %55, align 1, !tbaa !2449
  %1709 = lshr i32 %1689, 31
  %1710 = xor i32 %1707, %1709
  %1711 = add nuw nsw i32 %1710, %1707
  %1712 = icmp eq i32 %1711, 2
  %1713 = zext i1 %1712 to i8
  store i8 %1713, i8* %56, align 1, !tbaa !2450
  %1714 = sext i32 %1690 to i64
  store i64 %1714, i64* %RSI, align 8, !tbaa !2428
  %1715 = shl nsw i64 %1714, 3
  %1716 = add i64 %1715, %1685
  %1717 = add i64 %1677, 23
  store i64 %1717, i64* %PC, align 8
  %1718 = inttoptr i64 %1716 to i64*
  store i64 %1680, i64* %1718, align 8
  %1719 = load i64, i64* %RBP, align 8
  %1720 = add i64 %1719, -52
  %1721 = load i64, i64* %PC, align 8
  %1722 = add i64 %1721, 3
  store i64 %1722, i64* %PC, align 8
  %1723 = inttoptr i64 %1720 to i32*
  %1724 = load i32, i32* %1723, align 4
  %1725 = zext i32 %1724 to i64
  store i64 %1725, i64* %RCX, align 8, !tbaa !2428
  %1726 = add i64 %1719, -32
  %1727 = add i64 %1721, 6
  store i64 %1727, i64* %PC, align 8
  %1728 = inttoptr i64 %1726 to i32*
  %1729 = load i32, i32* %1728, align 4
  %1730 = add i32 %1729, %1724
  %1731 = zext i32 %1730 to i64
  store i64 %1731, i64* %RCX, align 8, !tbaa !2428
  %1732 = icmp ult i32 %1730, %1724
  %1733 = icmp ult i32 %1730, %1729
  %1734 = or i1 %1732, %1733
  %1735 = zext i1 %1734 to i8
  store i8 %1735, i8* %51, align 1, !tbaa !2433
  %1736 = and i32 %1730, 255
  %1737 = tail call i32 @llvm.ctpop.i32(i32 %1736) #10
  %1738 = trunc i32 %1737 to i8
  %1739 = and i8 %1738, 1
  %1740 = xor i8 %1739, 1
  store i8 %1740, i8* %52, align 1, !tbaa !2447
  %1741 = xor i32 %1729, %1724
  %1742 = xor i32 %1741, %1730
  %1743 = lshr i32 %1742, 4
  %1744 = trunc i32 %1743 to i8
  %1745 = and i8 %1744, 1
  store i8 %1745, i8* %53, align 1, !tbaa !2451
  %1746 = icmp eq i32 %1730, 0
  %1747 = zext i1 %1746 to i8
  store i8 %1747, i8* %54, align 1, !tbaa !2448
  %1748 = lshr i32 %1730, 31
  %1749 = trunc i32 %1748 to i8
  store i8 %1749, i8* %55, align 1, !tbaa !2449
  %1750 = lshr i32 %1724, 31
  %1751 = lshr i32 %1729, 31
  %1752 = xor i32 %1748, %1750
  %1753 = xor i32 %1748, %1751
  %1754 = add nuw nsw i32 %1752, %1753
  %1755 = icmp eq i32 %1754, 2
  %1756 = zext i1 %1755 to i8
  store i8 %1756, i8* %56, align 1, !tbaa !2450
  %1757 = add i64 %1721, 9
  store i64 %1757, i64* %PC, align 8
  store i32 %1730, i32* %1728, align 4
  %1758 = load i64, i64* %RBP, align 8
  %1759 = add i64 %1758, -52
  %1760 = load i64, i64* %PC, align 8
  %1761 = add i64 %1760, 3
  store i64 %1761, i64* %PC, align 8
  %1762 = inttoptr i64 %1759 to i32*
  %1763 = load i32, i32* %1762, align 4
  %1764 = shl i32 %1763, 1
  %1765 = icmp slt i32 %1763, 0
  %1766 = icmp slt i32 %1764, 0
  %1767 = xor i1 %1765, %1766
  %1768 = zext i32 %1764 to i64
  store i64 %1768, i64* %RCX, align 8, !tbaa !2428
  %.lobit19 = lshr i32 %1763, 31
  %1769 = trunc i32 %.lobit19 to i8
  store i8 %1769, i8* %51, align 1, !tbaa !2432
  %1770 = and i32 %1764, 254
  %1771 = tail call i32 @llvm.ctpop.i32(i32 %1770) #10
  %1772 = trunc i32 %1771 to i8
  %1773 = and i8 %1772, 1
  %1774 = xor i8 %1773, 1
  store i8 %1774, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %1775 = icmp eq i32 %1764, 0
  %1776 = zext i1 %1775 to i8
  store i8 %1776, i8* %54, align 1, !tbaa !2432
  %1777 = lshr i32 %1763, 30
  %1778 = and i32 %1777, 1
  %1779 = trunc i32 %1778 to i8
  store i8 %1779, i8* %55, align 1, !tbaa !2432
  %1780 = zext i1 %1767 to i8
  store i8 %1780, i8* %56, align 1, !tbaa !2432
  %1781 = add i64 %1758, -40
  %1782 = add i64 %1760, 9
  store i64 %1782, i64* %PC, align 8
  %1783 = inttoptr i64 %1781 to i32*
  %1784 = load i32, i32* %1783, align 4
  %1785 = add i32 %1784, %1764
  %1786 = zext i32 %1785 to i64
  store i64 %1786, i64* %RCX, align 8, !tbaa !2428
  %1787 = icmp ult i32 %1785, %1764
  %1788 = icmp ult i32 %1785, %1784
  %1789 = or i1 %1787, %1788
  %1790 = zext i1 %1789 to i8
  store i8 %1790, i8* %51, align 1, !tbaa !2433
  %1791 = and i32 %1785, 255
  %1792 = tail call i32 @llvm.ctpop.i32(i32 %1791) #10
  %1793 = trunc i32 %1792 to i8
  %1794 = and i8 %1793, 1
  %1795 = xor i8 %1794, 1
  store i8 %1795, i8* %52, align 1, !tbaa !2447
  %1796 = xor i32 %1784, %1764
  %1797 = xor i32 %1796, %1785
  %1798 = lshr i32 %1797, 4
  %1799 = trunc i32 %1798 to i8
  %1800 = and i8 %1799, 1
  store i8 %1800, i8* %53, align 1, !tbaa !2451
  %1801 = icmp eq i32 %1785, 0
  %1802 = zext i1 %1801 to i8
  store i8 %1802, i8* %54, align 1, !tbaa !2448
  %1803 = lshr i32 %1785, 31
  %1804 = trunc i32 %1803 to i8
  store i8 %1804, i8* %55, align 1, !tbaa !2449
  %1805 = lshr i32 %1784, 31
  %1806 = xor i32 %1803, %1778
  %1807 = xor i32 %1803, %1805
  %1808 = add nuw nsw i32 %1806, %1807
  %1809 = icmp eq i32 %1808, 2
  %1810 = zext i1 %1809 to i8
  store i8 %1810, i8* %56, align 1, !tbaa !2450
  %1811 = add i64 %1760, 12
  store i64 %1811, i64* %PC, align 8
  store i32 %1785, i32* %1783, align 4
  %1812 = load i64, i64* %RBP, align 8
  %1813 = add i64 %1812, -24
  %1814 = load i64, i64* %PC, align 8
  %1815 = add i64 %1814, 4
  store i64 %1815, i64* %PC, align 8
  %1816 = inttoptr i64 %1813 to i64*
  %1817 = load i64, i64* %1816, align 8
  store i64 %1817, i64* %RDX, align 8, !tbaa !2428
  %1818 = add i64 %1812, -32
  %1819 = add i64 %1814, 8
  store i64 %1819, i64* %PC, align 8
  %1820 = inttoptr i64 %1818 to i32*
  %1821 = load i32, i32* %1820, align 4
  %1822 = sext i32 %1821 to i64
  store i64 %1822, i64* %RSI, align 8, !tbaa !2428
  %1823 = shl nsw i64 %1822, 3
  %1824 = add i64 %1823, %1817
  %1825 = add i64 %1814, 13
  store i64 %1825, i64* %PC, align 8
  %1826 = inttoptr i64 %1824 to i64*
  %1827 = load i64, i64* %1826, align 8
  %1828 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1827, i64* %1828, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1829 = add i64 %1812, -64
  %1830 = add i64 %1814, 18
  store i64 %1830, i64* %PC, align 8
  %1831 = inttoptr i64 %1829 to i64*
  store i64 %1827, i64* %1831, align 8
  %1832 = load i64, i64* %RBP, align 8
  %1833 = add i64 %1832, -24
  %1834 = load i64, i64* %PC, align 8
  %1835 = add i64 %1834, 4
  store i64 %1835, i64* %PC, align 8
  %1836 = inttoptr i64 %1833 to i64*
  %1837 = load i64, i64* %1836, align 8
  store i64 %1837, i64* %RDX, align 8, !tbaa !2428
  %1838 = add i64 %1832, -32
  %1839 = add i64 %1834, 7
  store i64 %1839, i64* %PC, align 8
  %1840 = inttoptr i64 %1838 to i32*
  %1841 = load i32, i32* %1840, align 4
  %1842 = add i32 %1841, 1
  %1843 = zext i32 %1842 to i64
  store i64 %1843, i64* %RCX, align 8, !tbaa !2428
  %1844 = icmp eq i32 %1841, -1
  %1845 = icmp eq i32 %1842, 0
  %1846 = or i1 %1844, %1845
  %1847 = zext i1 %1846 to i8
  store i8 %1847, i8* %51, align 1, !tbaa !2433
  %1848 = and i32 %1842, 255
  %1849 = tail call i32 @llvm.ctpop.i32(i32 %1848) #10
  %1850 = trunc i32 %1849 to i8
  %1851 = and i8 %1850, 1
  %1852 = xor i8 %1851, 1
  store i8 %1852, i8* %52, align 1, !tbaa !2447
  %1853 = xor i32 %1841, %1842
  %1854 = lshr i32 %1853, 4
  %1855 = trunc i32 %1854 to i8
  %1856 = and i8 %1855, 1
  store i8 %1856, i8* %53, align 1, !tbaa !2451
  %1857 = icmp eq i32 %1842, 0
  %1858 = zext i1 %1857 to i8
  store i8 %1858, i8* %54, align 1, !tbaa !2448
  %1859 = lshr i32 %1842, 31
  %1860 = trunc i32 %1859 to i8
  store i8 %1860, i8* %55, align 1, !tbaa !2449
  %1861 = lshr i32 %1841, 31
  %1862 = xor i32 %1859, %1861
  %1863 = add nuw nsw i32 %1862, %1859
  %1864 = icmp eq i32 %1863, 2
  %1865 = zext i1 %1864 to i8
  store i8 %1865, i8* %56, align 1, !tbaa !2450
  %1866 = sext i32 %1842 to i64
  store i64 %1866, i64* %RSI, align 8, !tbaa !2428
  %1867 = shl nsw i64 %1866, 3
  %1868 = add i64 %1867, %1837
  %1869 = add i64 %1834, 18
  store i64 %1869, i64* %PC, align 8
  %1870 = inttoptr i64 %1868 to i64*
  %1871 = load i64, i64* %1870, align 8
  %1872 = load i64, i64* %RAX, align 8
  %1873 = xor i64 %1872, %1871
  store i64 %1873, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %1874 = trunc i64 %1873 to i32
  %1875 = and i32 %1874, 255
  %1876 = tail call i32 @llvm.ctpop.i32(i32 %1875) #10
  %1877 = trunc i32 %1876 to i8
  %1878 = and i8 %1877, 1
  %1879 = xor i8 %1878, 1
  store i8 %1879, i8* %52, align 1, !tbaa !2447
  %1880 = icmp eq i64 %1873, 0
  %1881 = zext i1 %1880 to i8
  store i8 %1881, i8* %54, align 1, !tbaa !2448
  %1882 = lshr i64 %1873, 63
  %1883 = trunc i64 %1882 to i8
  store i8 %1883, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %1873, i64* %3940, align 1, !tbaa !2428
  store i64 0, i64* %3938, align 1, !tbaa !2428
  %1884 = add i64 %1832, -72
  %1885 = add i64 %1834, 36
  store i64 %1885, i64* %PC, align 8
  %1886 = inttoptr i64 %1884 to i64*
  store i64 %1873, i64* %1886, align 8
  %1887 = load i64, i64* %RBP, align 8
  %1888 = add i64 %1887, -24
  %1889 = load i64, i64* %PC, align 8
  %1890 = add i64 %1889, 4
  store i64 %1890, i64* %PC, align 8
  %1891 = inttoptr i64 %1888 to i64*
  %1892 = load i64, i64* %1891, align 8
  store i64 %1892, i64* %RDX, align 8, !tbaa !2428
  %1893 = add i64 %1887, -40
  %1894 = add i64 %1889, 8
  store i64 %1894, i64* %PC, align 8
  %1895 = inttoptr i64 %1893 to i32*
  %1896 = load i32, i32* %1895, align 4
  %1897 = sext i32 %1896 to i64
  store i64 %1897, i64* %RSI, align 8, !tbaa !2428
  %1898 = shl nsw i64 %1897, 3
  %1899 = add i64 %1898, %1892
  %1900 = add i64 %1889, 13
  store i64 %1900, i64* %PC, align 8
  %1901 = inttoptr i64 %1899 to i64*
  %1902 = load i64, i64* %1901, align 8
  %1903 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1902, i64* %1903, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1904 = add i64 %1887, -80
  %1905 = add i64 %1889, 18
  store i64 %1905, i64* %PC, align 8
  %1906 = inttoptr i64 %1904 to i64*
  store i64 %1902, i64* %1906, align 8
  %1907 = load i64, i64* %RBP, align 8
  %1908 = add i64 %1907, -24
  %1909 = load i64, i64* %PC, align 8
  %1910 = add i64 %1909, 4
  store i64 %1910, i64* %PC, align 8
  %1911 = inttoptr i64 %1908 to i64*
  %1912 = load i64, i64* %1911, align 8
  store i64 %1912, i64* %RDX, align 8, !tbaa !2428
  %1913 = add i64 %1907, -40
  %1914 = add i64 %1909, 7
  store i64 %1914, i64* %PC, align 8
  %1915 = inttoptr i64 %1913 to i32*
  %1916 = load i32, i32* %1915, align 4
  %1917 = add i32 %1916, 1
  %1918 = zext i32 %1917 to i64
  store i64 %1918, i64* %RCX, align 8, !tbaa !2428
  %1919 = icmp eq i32 %1916, -1
  %1920 = icmp eq i32 %1917, 0
  %1921 = or i1 %1919, %1920
  %1922 = zext i1 %1921 to i8
  store i8 %1922, i8* %51, align 1, !tbaa !2433
  %1923 = and i32 %1917, 255
  %1924 = tail call i32 @llvm.ctpop.i32(i32 %1923) #10
  %1925 = trunc i32 %1924 to i8
  %1926 = and i8 %1925, 1
  %1927 = xor i8 %1926, 1
  store i8 %1927, i8* %52, align 1, !tbaa !2447
  %1928 = xor i32 %1916, %1917
  %1929 = lshr i32 %1928, 4
  %1930 = trunc i32 %1929 to i8
  %1931 = and i8 %1930, 1
  store i8 %1931, i8* %53, align 1, !tbaa !2451
  %1932 = icmp eq i32 %1917, 0
  %1933 = zext i1 %1932 to i8
  store i8 %1933, i8* %54, align 1, !tbaa !2448
  %1934 = lshr i32 %1917, 31
  %1935 = trunc i32 %1934 to i8
  store i8 %1935, i8* %55, align 1, !tbaa !2449
  %1936 = lshr i32 %1916, 31
  %1937 = xor i32 %1934, %1936
  %1938 = add nuw nsw i32 %1937, %1934
  %1939 = icmp eq i32 %1938, 2
  %1940 = zext i1 %1939 to i8
  store i8 %1940, i8* %56, align 1, !tbaa !2450
  %1941 = sext i32 %1917 to i64
  store i64 %1941, i64* %RSI, align 8, !tbaa !2428
  %1942 = shl nsw i64 %1941, 3
  %1943 = add i64 %1942, %1912
  %1944 = add i64 %1909, 18
  store i64 %1944, i64* %PC, align 8
  %1945 = inttoptr i64 %1943 to i64*
  %1946 = load i64, i64* %1945, align 8
  %1947 = load i64, i64* %RAX, align 8
  %1948 = xor i64 %1947, %1946
  store i64 %1948, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %1949 = trunc i64 %1948 to i32
  %1950 = and i32 %1949, 255
  %1951 = tail call i32 @llvm.ctpop.i32(i32 %1950) #10
  %1952 = trunc i32 %1951 to i8
  %1953 = and i8 %1952, 1
  %1954 = xor i8 %1953, 1
  store i8 %1954, i8* %52, align 1, !tbaa !2447
  %1955 = icmp eq i64 %1948, 0
  %1956 = zext i1 %1955 to i8
  store i8 %1956, i8* %54, align 1, !tbaa !2448
  %1957 = lshr i64 %1948, 63
  %1958 = trunc i64 %1957 to i8
  store i8 %1958, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %1948, i64* %3940, align 1, !tbaa !2428
  store i64 0, i64* %3938, align 1, !tbaa !2428
  %1959 = add i64 %1907, -88
  %1960 = add i64 %1909, 36
  store i64 %1960, i64* %PC, align 8
  %1961 = inttoptr i64 %1959 to i64*
  store i64 %1948, i64* %1961, align 8
  %1962 = load i64, i64* %RBP, align 8
  %1963 = add i64 %1962, -80
  %1964 = load i64, i64* %PC, align 8
  %1965 = add i64 %1964, 5
  store i64 %1965, i64* %PC, align 8
  %1966 = inttoptr i64 %1963 to i64*
  %1967 = load i64, i64* %1966, align 8
  %1968 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1967, i64* %1968, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1969 = add i64 %1962, -24
  %1970 = add i64 %1964, 9
  store i64 %1970, i64* %PC, align 8
  %1971 = inttoptr i64 %1969 to i64*
  %1972 = load i64, i64* %1971, align 8
  store i64 %1972, i64* %RAX, align 8, !tbaa !2428
  %1973 = add i64 %1962, -32
  %1974 = add i64 %1964, 13
  store i64 %1974, i64* %PC, align 8
  %1975 = inttoptr i64 %1973 to i32*
  %1976 = load i32, i32* %1975, align 4
  %1977 = sext i32 %1976 to i64
  store i64 %1977, i64* %RDX, align 8, !tbaa !2428
  %1978 = shl nsw i64 %1977, 3
  %1979 = add i64 %1978, %1972
  %1980 = add i64 %1964, 18
  store i64 %1980, i64* %PC, align 8
  %1981 = inttoptr i64 %1979 to i64*
  store i64 %1967, i64* %1981, align 8
  %1982 = load i64, i64* %RBP, align 8
  %1983 = add i64 %1982, -88
  %1984 = load i64, i64* %PC, align 8
  %1985 = add i64 %1984, 5
  store i64 %1985, i64* %PC, align 8
  %1986 = inttoptr i64 %1983 to i64*
  %1987 = load i64, i64* %1986, align 8
  %1988 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1987, i64* %1988, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %1989 = add i64 %1982, -24
  %1990 = add i64 %1984, 9
  store i64 %1990, i64* %PC, align 8
  %1991 = inttoptr i64 %1989 to i64*
  %1992 = load i64, i64* %1991, align 8
  store i64 %1992, i64* %RAX, align 8, !tbaa !2428
  %1993 = add i64 %1982, -32
  %1994 = add i64 %1984, 12
  store i64 %1994, i64* %PC, align 8
  %1995 = inttoptr i64 %1993 to i32*
  %1996 = load i32, i32* %1995, align 4
  %1997 = add i32 %1996, 1
  %1998 = zext i32 %1997 to i64
  store i64 %1998, i64* %RCX, align 8, !tbaa !2428
  %1999 = icmp eq i32 %1996, -1
  %2000 = icmp eq i32 %1997, 0
  %2001 = or i1 %1999, %2000
  %2002 = zext i1 %2001 to i8
  store i8 %2002, i8* %51, align 1, !tbaa !2433
  %2003 = and i32 %1997, 255
  %2004 = tail call i32 @llvm.ctpop.i32(i32 %2003) #10
  %2005 = trunc i32 %2004 to i8
  %2006 = and i8 %2005, 1
  %2007 = xor i8 %2006, 1
  store i8 %2007, i8* %52, align 1, !tbaa !2447
  %2008 = xor i32 %1996, %1997
  %2009 = lshr i32 %2008, 4
  %2010 = trunc i32 %2009 to i8
  %2011 = and i8 %2010, 1
  store i8 %2011, i8* %53, align 1, !tbaa !2451
  %2012 = icmp eq i32 %1997, 0
  %2013 = zext i1 %2012 to i8
  store i8 %2013, i8* %54, align 1, !tbaa !2448
  %2014 = lshr i32 %1997, 31
  %2015 = trunc i32 %2014 to i8
  store i8 %2015, i8* %55, align 1, !tbaa !2449
  %2016 = lshr i32 %1996, 31
  %2017 = xor i32 %2014, %2016
  %2018 = add nuw nsw i32 %2017, %2014
  %2019 = icmp eq i32 %2018, 2
  %2020 = zext i1 %2019 to i8
  store i8 %2020, i8* %56, align 1, !tbaa !2450
  %2021 = sext i32 %1997 to i64
  store i64 %2021, i64* %RDX, align 8, !tbaa !2428
  %2022 = shl nsw i64 %2021, 3
  %2023 = add i64 %2022, %1992
  %2024 = add i64 %1984, 23
  store i64 %2024, i64* %PC, align 8
  %2025 = inttoptr i64 %2023 to i64*
  store i64 %1987, i64* %2025, align 8
  %2026 = load i64, i64* %RBP, align 8
  %2027 = add i64 %2026, -64
  %2028 = load i64, i64* %PC, align 8
  %2029 = add i64 %2028, 5
  store i64 %2029, i64* %PC, align 8
  %2030 = inttoptr i64 %2027 to i64*
  %2031 = load i64, i64* %2030, align 8
  %2032 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2031, i64* %2032, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %2033 = add i64 %2026, -24
  %2034 = add i64 %2028, 9
  store i64 %2034, i64* %PC, align 8
  %2035 = inttoptr i64 %2033 to i64*
  %2036 = load i64, i64* %2035, align 8
  store i64 %2036, i64* %RAX, align 8, !tbaa !2428
  %2037 = add i64 %2026, -40
  %2038 = add i64 %2028, 13
  store i64 %2038, i64* %PC, align 8
  %2039 = inttoptr i64 %2037 to i32*
  %2040 = load i32, i32* %2039, align 4
  %2041 = sext i32 %2040 to i64
  store i64 %2041, i64* %RDX, align 8, !tbaa !2428
  %2042 = shl nsw i64 %2041, 3
  %2043 = add i64 %2042, %2036
  %2044 = add i64 %2028, 18
  store i64 %2044, i64* %PC, align 8
  %2045 = inttoptr i64 %2043 to i64*
  store i64 %2031, i64* %2045, align 8
  %2046 = load i64, i64* %RBP, align 8
  %2047 = add i64 %2046, -72
  %2048 = load i64, i64* %PC, align 8
  %2049 = add i64 %2048, 5
  store i64 %2049, i64* %PC, align 8
  %2050 = inttoptr i64 %2047 to i64*
  %2051 = load i64, i64* %2050, align 8
  %2052 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2051, i64* %2052, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %2053 = add i64 %2046, -24
  %2054 = add i64 %2048, 9
  store i64 %2054, i64* %PC, align 8
  %2055 = inttoptr i64 %2053 to i64*
  %2056 = load i64, i64* %2055, align 8
  store i64 %2056, i64* %RAX, align 8, !tbaa !2428
  %2057 = add i64 %2046, -40
  %2058 = add i64 %2048, 12
  store i64 %2058, i64* %PC, align 8
  %2059 = inttoptr i64 %2057 to i32*
  %2060 = load i32, i32* %2059, align 4
  %2061 = add i32 %2060, 1
  %2062 = zext i32 %2061 to i64
  store i64 %2062, i64* %RCX, align 8, !tbaa !2428
  %2063 = icmp eq i32 %2060, -1
  %2064 = icmp eq i32 %2061, 0
  %2065 = or i1 %2063, %2064
  %2066 = zext i1 %2065 to i8
  store i8 %2066, i8* %51, align 1, !tbaa !2433
  %2067 = and i32 %2061, 255
  %2068 = tail call i32 @llvm.ctpop.i32(i32 %2067) #10
  %2069 = trunc i32 %2068 to i8
  %2070 = and i8 %2069, 1
  %2071 = xor i8 %2070, 1
  store i8 %2071, i8* %52, align 1, !tbaa !2447
  %2072 = xor i32 %2060, %2061
  %2073 = lshr i32 %2072, 4
  %2074 = trunc i32 %2073 to i8
  %2075 = and i8 %2074, 1
  store i8 %2075, i8* %53, align 1, !tbaa !2451
  %2076 = icmp eq i32 %2061, 0
  %2077 = zext i1 %2076 to i8
  store i8 %2077, i8* %54, align 1, !tbaa !2448
  %2078 = lshr i32 %2061, 31
  %2079 = trunc i32 %2078 to i8
  store i8 %2079, i8* %55, align 1, !tbaa !2449
  %2080 = lshr i32 %2060, 31
  %2081 = xor i32 %2078, %2080
  %2082 = add nuw nsw i32 %2081, %2078
  %2083 = icmp eq i32 %2082, 2
  %2084 = zext i1 %2083 to i8
  store i8 %2084, i8* %56, align 1, !tbaa !2450
  %2085 = sext i32 %2061 to i64
  store i64 %2085, i64* %RDX, align 8, !tbaa !2428
  %2086 = shl nsw i64 %2085, 3
  %2087 = add i64 %2086, %2056
  %2088 = add i64 %2048, 23
  store i64 %2088, i64* %PC, align 8
  %2089 = inttoptr i64 %2087 to i64*
  store i64 %2051, i64* %2089, align 8
  %2090 = load i64, i64* %RBP, align 8
  %2091 = add i64 %2090, -28
  %2092 = load i64, i64* %PC, align 8
  %2093 = add i64 %2092, 3
  store i64 %2093, i64* %PC, align 8
  %2094 = inttoptr i64 %2091 to i32*
  %2095 = load i32, i32* %2094, align 4
  %2096 = add i32 %2095, 1
  %2097 = zext i32 %2096 to i64
  store i64 %2097, i64* %RAX, align 8, !tbaa !2428
  %2098 = icmp eq i32 %2095, -1
  %2099 = icmp eq i32 %2096, 0
  %2100 = or i1 %2098, %2099
  %2101 = zext i1 %2100 to i8
  store i8 %2101, i8* %51, align 1, !tbaa !2433
  %2102 = and i32 %2096, 255
  %2103 = tail call i32 @llvm.ctpop.i32(i32 %2102) #10
  %2104 = trunc i32 %2103 to i8
  %2105 = and i8 %2104, 1
  %2106 = xor i8 %2105, 1
  store i8 %2106, i8* %52, align 1, !tbaa !2447
  %2107 = xor i32 %2095, %2096
  %2108 = lshr i32 %2107, 4
  %2109 = trunc i32 %2108 to i8
  %2110 = and i8 %2109, 1
  store i8 %2110, i8* %53, align 1, !tbaa !2451
  %2111 = icmp eq i32 %2096, 0
  %2112 = zext i1 %2111 to i8
  store i8 %2112, i8* %54, align 1, !tbaa !2448
  %2113 = lshr i32 %2096, 31
  %2114 = trunc i32 %2113 to i8
  store i8 %2114, i8* %55, align 1, !tbaa !2449
  %2115 = lshr i32 %2095, 31
  %2116 = xor i32 %2113, %2115
  %2117 = add nuw nsw i32 %2116, %2113
  %2118 = icmp eq i32 %2117, 2
  %2119 = zext i1 %2118 to i8
  store i8 %2119, i8* %56, align 1, !tbaa !2450
  %2120 = add i64 %2092, 9
  store i64 %2120, i64* %PC, align 8
  store i32 %2096, i32* %2094, align 4
  %2121 = load i64, i64* %PC, align 8
  %2122 = add i64 %2121, -893
  store i64 %2122, i64* %57, align 8, !tbaa !2428
  br label %block_401c9d

block_401c25:                                     ; preds = %block_401c15, %block_401c31
  %2123 = phi i64 [ %.pre4, %block_401c15 ], [ %309, %block_401c31 ]
  %2124 = load i64, i64* %RBP, align 8
  %2125 = add i64 %2124, -28
  %2126 = add i64 %2123, 3
  store i64 %2126, i64* %PC, align 8
  %2127 = inttoptr i64 %2125 to i32*
  %2128 = load i32, i32* %2127, align 4
  %2129 = zext i32 %2128 to i64
  store i64 %2129, i64* %RAX, align 8, !tbaa !2428
  %2130 = add i64 %2124, -48
  %2131 = add i64 %2123, 6
  store i64 %2131, i64* %PC, align 8
  %2132 = inttoptr i64 %2130 to i32*
  %2133 = load i32, i32* %2132, align 4
  %2134 = sub i32 %2128, %2133
  %2135 = icmp ult i32 %2128, %2133
  %2136 = zext i1 %2135 to i8
  store i8 %2136, i8* %51, align 1, !tbaa !2433
  %2137 = and i32 %2134, 255
  %2138 = tail call i32 @llvm.ctpop.i32(i32 %2137) #10
  %2139 = trunc i32 %2138 to i8
  %2140 = and i8 %2139, 1
  %2141 = xor i8 %2140, 1
  store i8 %2141, i8* %52, align 1, !tbaa !2447
  %2142 = xor i32 %2133, %2128
  %2143 = xor i32 %2142, %2134
  %2144 = lshr i32 %2143, 4
  %2145 = trunc i32 %2144 to i8
  %2146 = and i8 %2145, 1
  store i8 %2146, i8* %53, align 1, !tbaa !2451
  %2147 = icmp eq i32 %2134, 0
  %2148 = zext i1 %2147 to i8
  store i8 %2148, i8* %54, align 1, !tbaa !2448
  %2149 = lshr i32 %2134, 31
  %2150 = trunc i32 %2149 to i8
  store i8 %2150, i8* %55, align 1, !tbaa !2449
  %2151 = lshr i32 %2128, 31
  %2152 = lshr i32 %2133, 31
  %2153 = xor i32 %2152, %2151
  %2154 = xor i32 %2149, %2151
  %2155 = add nuw nsw i32 %2154, %2153
  %2156 = icmp eq i32 %2155, 2
  %2157 = zext i1 %2156 to i8
  store i8 %2157, i8* %56, align 1, !tbaa !2450
  %2158 = icmp ne i8 %2150, 0
  %2159 = xor i1 %2158, %2156
  %.v10 = select i1 %2159, i64 12, i64 56
  %2160 = add i64 %2123, %.v10
  store i64 %2160, i64* %57, align 8, !tbaa !2428
  br i1 %2159, label %block_401c31, label %block_401c5d

block_40201f:                                     ; preds = %block_401c9d
  %2161 = load i32, i32* %2831, align 4
  %2162 = shl i32 %2161, 1
  %2163 = icmp slt i32 %2161, 0
  %2164 = icmp slt i32 %2162, 0
  %2165 = xor i1 %2163, %2164
  %2166 = zext i32 %2162 to i64
  store i64 %2166, i64* %RCX, align 8, !tbaa !2428
  %.lobit20 = lshr i32 %2161, 31
  %2167 = trunc i32 %.lobit20 to i8
  store i8 %2167, i8* %51, align 1, !tbaa !2432
  %2168 = and i32 %2162, 254
  %2169 = tail call i32 @llvm.ctpop.i32(i32 %2168) #10
  %2170 = trunc i32 %2169 to i8
  %2171 = and i8 %2170, 1
  %2172 = xor i8 %2171, 1
  store i8 %2172, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %2173 = icmp eq i32 %2162, 0
  %2174 = zext i1 %2173 to i8
  store i8 %2174, i8* %54, align 1, !tbaa !2432
  %2175 = lshr i32 %2161, 30
  %2176 = and i32 %2175, 1
  %2177 = trunc i32 %2176 to i8
  store i8 %2177, i8* %55, align 1, !tbaa !2432
  %2178 = zext i1 %2165 to i8
  store i8 %2178, i8* %56, align 1, !tbaa !2432
  %2179 = add i64 %2823, -16
  %2180 = add i64 %2859, 20
  store i64 %2180, i64* %PC, align 8
  %2181 = inttoptr i64 %2179 to i64*
  %2182 = load i64, i64* %2181, align 8
  store i64 %2182, i64* %RDX, align 8, !tbaa !2428
  %2183 = add i64 %2859, 24
  store i64 %2183, i64* %PC, align 8
  %2184 = load i32, i32* %2831, align 4
  %2185 = sext i32 %2184 to i64
  store i64 %2185, i64* %RSI, align 8, !tbaa !2428
  %2186 = shl nsw i64 %2185, 2
  %2187 = add i64 %2186, %2182
  %2188 = add i64 %2859, 27
  store i64 %2188, i64* %PC, align 8
  %2189 = inttoptr i64 %2187 to i32*
  %2190 = load i32, i32* %2189, align 4
  %2191 = add i32 %2190, %2162
  %2192 = zext i32 %2191 to i64
  store i64 %2192, i64* %RCX, align 8, !tbaa !2428
  %2193 = icmp ult i32 %2191, %2162
  %2194 = icmp ult i32 %2191, %2190
  %2195 = or i1 %2193, %2194
  %2196 = zext i1 %2195 to i8
  store i8 %2196, i8* %51, align 1, !tbaa !2433
  %2197 = and i32 %2191, 255
  %2198 = tail call i32 @llvm.ctpop.i32(i32 %2197) #10
  %2199 = trunc i32 %2198 to i8
  %2200 = and i8 %2199, 1
  %2201 = xor i8 %2200, 1
  store i8 %2201, i8* %52, align 1, !tbaa !2447
  %2202 = xor i32 %2190, %2162
  %2203 = xor i32 %2202, %2191
  %2204 = lshr i32 %2203, 4
  %2205 = trunc i32 %2204 to i8
  %2206 = and i8 %2205, 1
  store i8 %2206, i8* %53, align 1, !tbaa !2451
  %2207 = icmp eq i32 %2191, 0
  %2208 = zext i1 %2207 to i8
  store i8 %2208, i8* %54, align 1, !tbaa !2448
  %2209 = lshr i32 %2191, 31
  %2210 = trunc i32 %2209 to i8
  store i8 %2210, i8* %55, align 1, !tbaa !2449
  %2211 = lshr i32 %2190, 31
  %2212 = xor i32 %2209, %2176
  %2213 = xor i32 %2209, %2211
  %2214 = add nuw nsw i32 %2212, %2213
  %2215 = icmp eq i32 %2214, 2
  %2216 = zext i1 %2215 to i8
  store i8 %2216, i8* %56, align 1, !tbaa !2450
  %2217 = add i64 %2823, -40
  %2218 = add i64 %2859, 30
  store i64 %2218, i64* %PC, align 8
  %2219 = inttoptr i64 %2217 to i32*
  store i32 %2191, i32* %2219, align 4
  %2220 = load i64, i64* %RBP, align 8
  %2221 = add i64 %2220, -24
  %2222 = load i64, i64* %PC, align 8
  %2223 = add i64 %2222, 4
  store i64 %2223, i64* %PC, align 8
  %2224 = inttoptr i64 %2221 to i64*
  %2225 = load i64, i64* %2224, align 8
  store i64 %2225, i64* %RDX, align 8, !tbaa !2428
  %2226 = add i64 %2220, -40
  %2227 = add i64 %2222, 7
  store i64 %2227, i64* %PC, align 8
  %2228 = inttoptr i64 %2226 to i32*
  %2229 = load i32, i32* %2228, align 4
  %2230 = add i32 %2229, 1
  %2231 = zext i32 %2230 to i64
  store i64 %2231, i64* %RCX, align 8, !tbaa !2428
  %2232 = icmp eq i32 %2229, -1
  %2233 = icmp eq i32 %2230, 0
  %2234 = or i1 %2232, %2233
  %2235 = zext i1 %2234 to i8
  store i8 %2235, i8* %51, align 1, !tbaa !2433
  %2236 = and i32 %2230, 255
  %2237 = tail call i32 @llvm.ctpop.i32(i32 %2236) #10
  %2238 = trunc i32 %2237 to i8
  %2239 = and i8 %2238, 1
  %2240 = xor i8 %2239, 1
  store i8 %2240, i8* %52, align 1, !tbaa !2447
  %2241 = xor i32 %2229, %2230
  %2242 = lshr i32 %2241, 4
  %2243 = trunc i32 %2242 to i8
  %2244 = and i8 %2243, 1
  store i8 %2244, i8* %53, align 1, !tbaa !2451
  %2245 = icmp eq i32 %2230, 0
  %2246 = zext i1 %2245 to i8
  store i8 %2246, i8* %54, align 1, !tbaa !2448
  %2247 = lshr i32 %2230, 31
  %2248 = trunc i32 %2247 to i8
  store i8 %2248, i8* %55, align 1, !tbaa !2449
  %2249 = lshr i32 %2229, 31
  %2250 = xor i32 %2247, %2249
  %2251 = add nuw nsw i32 %2250, %2247
  %2252 = icmp eq i32 %2251, 2
  %2253 = zext i1 %2252 to i8
  store i8 %2253, i8* %56, align 1, !tbaa !2450
  %2254 = sext i32 %2230 to i64
  store i64 %2254, i64* %RSI, align 8, !tbaa !2428
  %2255 = shl nsw i64 %2254, 3
  %2256 = add i64 %2255, %2225
  %2257 = add i64 %2222, 18
  store i64 %2257, i64* %PC, align 8
  %2258 = inttoptr i64 %2256 to i64*
  %2259 = load i64, i64* %2258, align 8
  %2260 = load i64, i64* %RAX, align 8
  %2261 = xor i64 %2260, %2259
  store i64 %2261, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %2262 = trunc i64 %2261 to i32
  %2263 = and i32 %2262, 255
  %2264 = tail call i32 @llvm.ctpop.i32(i32 %2263) #10
  %2265 = trunc i32 %2264 to i8
  %2266 = and i8 %2265, 1
  %2267 = xor i8 %2266, 1
  store i8 %2267, i8* %52, align 1, !tbaa !2447
  %2268 = icmp eq i64 %2261, 0
  %2269 = zext i1 %2268 to i8
  store i8 %2269, i8* %54, align 1, !tbaa !2448
  %2270 = lshr i64 %2261, 63
  %2271 = trunc i64 %2270 to i8
  store i8 %2271, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %2261, i64* %3940, align 1, !tbaa !2428
  store i64 0, i64* %3938, align 1, !tbaa !2428
  %2272 = add i64 %2222, 35
  store i64 %2272, i64* %PC, align 8
  %2273 = load i64, i64* %2224, align 8
  store i64 %2273, i64* %RDX, align 8, !tbaa !2428
  %2274 = add i64 %2222, 38
  store i64 %2274, i64* %PC, align 8
  %2275 = load i32, i32* %2228, align 4
  %2276 = add i32 %2275, 1
  %2277 = zext i32 %2276 to i64
  store i64 %2277, i64* %RCX, align 8, !tbaa !2428
  %2278 = icmp eq i32 %2275, -1
  %2279 = icmp eq i32 %2276, 0
  %2280 = or i1 %2278, %2279
  %2281 = zext i1 %2280 to i8
  store i8 %2281, i8* %51, align 1, !tbaa !2433
  %2282 = and i32 %2276, 255
  %2283 = tail call i32 @llvm.ctpop.i32(i32 %2282) #10
  %2284 = trunc i32 %2283 to i8
  %2285 = and i8 %2284, 1
  %2286 = xor i8 %2285, 1
  store i8 %2286, i8* %52, align 1, !tbaa !2447
  %2287 = xor i32 %2275, %2276
  %2288 = lshr i32 %2287, 4
  %2289 = trunc i32 %2288 to i8
  %2290 = and i8 %2289, 1
  store i8 %2290, i8* %53, align 1, !tbaa !2451
  %2291 = icmp eq i32 %2276, 0
  %2292 = zext i1 %2291 to i8
  store i8 %2292, i8* %54, align 1, !tbaa !2448
  %2293 = lshr i32 %2276, 31
  %2294 = trunc i32 %2293 to i8
  store i8 %2294, i8* %55, align 1, !tbaa !2449
  %2295 = lshr i32 %2275, 31
  %2296 = xor i32 %2293, %2295
  %2297 = add nuw nsw i32 %2296, %2293
  %2298 = icmp eq i32 %2297, 2
  %2299 = zext i1 %2298 to i8
  store i8 %2299, i8* %56, align 1, !tbaa !2450
  %2300 = sext i32 %2276 to i64
  store i64 %2300, i64* %RSI, align 8, !tbaa !2428
  %2301 = shl nsw i64 %2300, 3
  %2302 = add i64 %2301, %2273
  %2303 = add i64 %2222, 49
  store i64 %2303, i64* %PC, align 8
  %2304 = inttoptr i64 %2302 to i64*
  store i64 %2261, i64* %2304, align 8
  %2305 = load i64, i64* %RBP, align 8
  %2306 = add i64 %2305, -40
  %2307 = load i64, i64* %PC, align 8
  %2308 = add i64 %2307, 3
  store i64 %2308, i64* %PC, align 8
  %2309 = inttoptr i64 %2306 to i32*
  %2310 = load i32, i32* %2309, align 4
  %2311 = zext i32 %2310 to i64
  store i64 %2311, i64* %RCX, align 8, !tbaa !2428
  %2312 = add i64 %2305, -52
  %2313 = add i64 %2307, 6
  store i64 %2313, i64* %PC, align 8
  %2314 = inttoptr i64 %2312 to i32*
  %2315 = load i32, i32* %2314, align 4
  %2316 = add i32 %2315, %2310
  %2317 = zext i32 %2316 to i64
  store i64 %2317, i64* %RCX, align 8, !tbaa !2428
  %2318 = icmp ult i32 %2316, %2310
  %2319 = icmp ult i32 %2316, %2315
  %2320 = or i1 %2318, %2319
  %2321 = zext i1 %2320 to i8
  store i8 %2321, i8* %51, align 1, !tbaa !2433
  %2322 = and i32 %2316, 255
  %2323 = tail call i32 @llvm.ctpop.i32(i32 %2322) #10
  %2324 = trunc i32 %2323 to i8
  %2325 = and i8 %2324, 1
  %2326 = xor i8 %2325, 1
  store i8 %2326, i8* %52, align 1, !tbaa !2447
  %2327 = xor i32 %2315, %2310
  %2328 = xor i32 %2327, %2316
  %2329 = lshr i32 %2328, 4
  %2330 = trunc i32 %2329 to i8
  %2331 = and i8 %2330, 1
  store i8 %2331, i8* %53, align 1, !tbaa !2451
  %2332 = icmp eq i32 %2316, 0
  %2333 = zext i1 %2332 to i8
  store i8 %2333, i8* %54, align 1, !tbaa !2448
  %2334 = lshr i32 %2316, 31
  %2335 = trunc i32 %2334 to i8
  store i8 %2335, i8* %55, align 1, !tbaa !2449
  %2336 = lshr i32 %2310, 31
  %2337 = lshr i32 %2315, 31
  %2338 = xor i32 %2334, %2336
  %2339 = xor i32 %2334, %2337
  %2340 = add nuw nsw i32 %2338, %2339
  %2341 = icmp eq i32 %2340, 2
  %2342 = zext i1 %2341 to i8
  store i8 %2342, i8* %56, align 1, !tbaa !2450
  %2343 = add i64 %2305, -32
  %2344 = add i64 %2307, 9
  store i64 %2344, i64* %PC, align 8
  %2345 = inttoptr i64 %2343 to i32*
  store i32 %2316, i32* %2345, align 4
  %2346 = load i64, i64* %RBP, align 8
  %2347 = add i64 %2346, -32
  %2348 = load i64, i64* %PC, align 8
  %2349 = add i64 %2348, 3
  store i64 %2349, i64* %PC, align 8
  %2350 = inttoptr i64 %2347 to i32*
  %2351 = load i32, i32* %2350, align 4
  %2352 = zext i32 %2351 to i64
  store i64 %2352, i64* %RCX, align 8, !tbaa !2428
  %2353 = add i64 %2346, -52
  %2354 = add i64 %2348, 6
  store i64 %2354, i64* %PC, align 8
  %2355 = inttoptr i64 %2353 to i32*
  %2356 = load i32, i32* %2355, align 4
  %2357 = add i32 %2356, %2351
  %2358 = zext i32 %2357 to i64
  store i64 %2358, i64* %RCX, align 8, !tbaa !2428
  %2359 = icmp ult i32 %2357, %2351
  %2360 = icmp ult i32 %2357, %2356
  %2361 = or i1 %2359, %2360
  %2362 = zext i1 %2361 to i8
  store i8 %2362, i8* %51, align 1, !tbaa !2433
  %2363 = and i32 %2357, 255
  %2364 = tail call i32 @llvm.ctpop.i32(i32 %2363) #10
  %2365 = trunc i32 %2364 to i8
  %2366 = and i8 %2365, 1
  %2367 = xor i8 %2366, 1
  store i8 %2367, i8* %52, align 1, !tbaa !2447
  %2368 = xor i32 %2356, %2351
  %2369 = xor i32 %2368, %2357
  %2370 = lshr i32 %2369, 4
  %2371 = trunc i32 %2370 to i8
  %2372 = and i8 %2371, 1
  store i8 %2372, i8* %53, align 1, !tbaa !2451
  %2373 = icmp eq i32 %2357, 0
  %2374 = zext i1 %2373 to i8
  store i8 %2374, i8* %54, align 1, !tbaa !2448
  %2375 = lshr i32 %2357, 31
  %2376 = trunc i32 %2375 to i8
  store i8 %2376, i8* %55, align 1, !tbaa !2449
  %2377 = lshr i32 %2351, 31
  %2378 = lshr i32 %2356, 31
  %2379 = xor i32 %2375, %2377
  %2380 = xor i32 %2375, %2378
  %2381 = add nuw nsw i32 %2379, %2380
  %2382 = icmp eq i32 %2381, 2
  %2383 = zext i1 %2382 to i8
  store i8 %2383, i8* %56, align 1, !tbaa !2450
  %2384 = add i64 %2346, -40
  %2385 = add i64 %2348, 9
  store i64 %2385, i64* %PC, align 8
  %2386 = inttoptr i64 %2384 to i32*
  store i32 %2357, i32* %2386, align 4
  %2387 = load i64, i64* %RBP, align 8
  %2388 = add i64 %2387, -24
  %2389 = load i64, i64* %PC, align 8
  %2390 = add i64 %2389, 4
  store i64 %2390, i64* %PC, align 8
  %2391 = inttoptr i64 %2388 to i64*
  %2392 = load i64, i64* %2391, align 8
  store i64 %2392, i64* %RDX, align 8, !tbaa !2428
  %2393 = add i64 %2387, -32
  %2394 = add i64 %2389, 8
  store i64 %2394, i64* %PC, align 8
  %2395 = inttoptr i64 %2393 to i32*
  %2396 = load i32, i32* %2395, align 4
  %2397 = sext i32 %2396 to i64
  store i64 %2397, i64* %RSI, align 8, !tbaa !2428
  %2398 = shl nsw i64 %2397, 3
  %2399 = add i64 %2398, %2392
  %2400 = add i64 %2389, 13
  store i64 %2400, i64* %PC, align 8
  %2401 = inttoptr i64 %2399 to i64*
  %2402 = load i64, i64* %2401, align 8
  %2403 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2402, i64* %2403, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %2404 = add i64 %2387, -64
  %2405 = add i64 %2389, 18
  store i64 %2405, i64* %PC, align 8
  %2406 = inttoptr i64 %2404 to i64*
  store i64 %2402, i64* %2406, align 8
  %2407 = load i64, i64* %RBP, align 8
  %2408 = add i64 %2407, -24
  %2409 = load i64, i64* %PC, align 8
  %2410 = add i64 %2409, 4
  store i64 %2410, i64* %PC, align 8
  %2411 = inttoptr i64 %2408 to i64*
  %2412 = load i64, i64* %2411, align 8
  store i64 %2412, i64* %RDX, align 8, !tbaa !2428
  %2413 = add i64 %2407, -32
  %2414 = add i64 %2409, 7
  store i64 %2414, i64* %PC, align 8
  %2415 = inttoptr i64 %2413 to i32*
  %2416 = load i32, i32* %2415, align 4
  %2417 = add i32 %2416, 1
  %2418 = zext i32 %2417 to i64
  store i64 %2418, i64* %RCX, align 8, !tbaa !2428
  %2419 = icmp eq i32 %2416, -1
  %2420 = icmp eq i32 %2417, 0
  %2421 = or i1 %2419, %2420
  %2422 = zext i1 %2421 to i8
  store i8 %2422, i8* %51, align 1, !tbaa !2433
  %2423 = and i32 %2417, 255
  %2424 = tail call i32 @llvm.ctpop.i32(i32 %2423) #10
  %2425 = trunc i32 %2424 to i8
  %2426 = and i8 %2425, 1
  %2427 = xor i8 %2426, 1
  store i8 %2427, i8* %52, align 1, !tbaa !2447
  %2428 = xor i32 %2416, %2417
  %2429 = lshr i32 %2428, 4
  %2430 = trunc i32 %2429 to i8
  %2431 = and i8 %2430, 1
  store i8 %2431, i8* %53, align 1, !tbaa !2451
  %2432 = icmp eq i32 %2417, 0
  %2433 = zext i1 %2432 to i8
  store i8 %2433, i8* %54, align 1, !tbaa !2448
  %2434 = lshr i32 %2417, 31
  %2435 = trunc i32 %2434 to i8
  store i8 %2435, i8* %55, align 1, !tbaa !2449
  %2436 = lshr i32 %2416, 31
  %2437 = xor i32 %2434, %2436
  %2438 = add nuw nsw i32 %2437, %2434
  %2439 = icmp eq i32 %2438, 2
  %2440 = zext i1 %2439 to i8
  store i8 %2440, i8* %56, align 1, !tbaa !2450
  %2441 = sext i32 %2417 to i64
  store i64 %2441, i64* %RSI, align 8, !tbaa !2428
  %2442 = shl nsw i64 %2441, 3
  %2443 = add i64 %2442, %2412
  %2444 = add i64 %2409, 18
  store i64 %2444, i64* %PC, align 8
  %2445 = inttoptr i64 %2443 to i64*
  %2446 = load i64, i64* %2445, align 8
  %2447 = load i64, i64* %RAX, align 8
  %2448 = xor i64 %2447, %2446
  store i64 %2448, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %2449 = trunc i64 %2448 to i32
  %2450 = and i32 %2449, 255
  %2451 = tail call i32 @llvm.ctpop.i32(i32 %2450) #10
  %2452 = trunc i32 %2451 to i8
  %2453 = and i8 %2452, 1
  %2454 = xor i8 %2453, 1
  store i8 %2454, i8* %52, align 1, !tbaa !2447
  %2455 = icmp eq i64 %2448, 0
  %2456 = zext i1 %2455 to i8
  store i8 %2456, i8* %54, align 1, !tbaa !2448
  %2457 = lshr i64 %2448, 63
  %2458 = trunc i64 %2457 to i8
  store i8 %2458, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %2448, i64* %3940, align 1, !tbaa !2428
  store i64 0, i64* %3938, align 1, !tbaa !2428
  %2459 = add i64 %2407, -72
  %2460 = add i64 %2409, 36
  store i64 %2460, i64* %PC, align 8
  %2461 = inttoptr i64 %2459 to i64*
  store i64 %2448, i64* %2461, align 8
  %2462 = load i64, i64* %RBP, align 8
  %2463 = add i64 %2462, -24
  %2464 = load i64, i64* %PC, align 8
  %2465 = add i64 %2464, 4
  store i64 %2465, i64* %PC, align 8
  %2466 = inttoptr i64 %2463 to i64*
  %2467 = load i64, i64* %2466, align 8
  store i64 %2467, i64* %RDX, align 8, !tbaa !2428
  %2468 = add i64 %2462, -40
  %2469 = add i64 %2464, 8
  store i64 %2469, i64* %PC, align 8
  %2470 = inttoptr i64 %2468 to i32*
  %2471 = load i32, i32* %2470, align 4
  %2472 = sext i32 %2471 to i64
  store i64 %2472, i64* %RSI, align 8, !tbaa !2428
  %2473 = shl nsw i64 %2472, 3
  %2474 = add i64 %2473, %2467
  %2475 = add i64 %2464, 13
  store i64 %2475, i64* %PC, align 8
  %2476 = inttoptr i64 %2474 to i64*
  %2477 = load i64, i64* %2476, align 8
  %2478 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2477, i64* %2478, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %2479 = add i64 %2462, -80
  %2480 = add i64 %2464, 18
  store i64 %2480, i64* %PC, align 8
  %2481 = inttoptr i64 %2479 to i64*
  store i64 %2477, i64* %2481, align 8
  %2482 = load i64, i64* %RBP, align 8
  %2483 = add i64 %2482, -24
  %2484 = load i64, i64* %PC, align 8
  %2485 = add i64 %2484, 4
  store i64 %2485, i64* %PC, align 8
  %2486 = inttoptr i64 %2483 to i64*
  %2487 = load i64, i64* %2486, align 8
  store i64 %2487, i64* %RDX, align 8, !tbaa !2428
  %2488 = add i64 %2482, -40
  %2489 = add i64 %2484, 7
  store i64 %2489, i64* %PC, align 8
  %2490 = inttoptr i64 %2488 to i32*
  %2491 = load i32, i32* %2490, align 4
  %2492 = add i32 %2491, 1
  %2493 = zext i32 %2492 to i64
  store i64 %2493, i64* %RCX, align 8, !tbaa !2428
  %2494 = icmp eq i32 %2491, -1
  %2495 = icmp eq i32 %2492, 0
  %2496 = or i1 %2494, %2495
  %2497 = zext i1 %2496 to i8
  store i8 %2497, i8* %51, align 1, !tbaa !2433
  %2498 = and i32 %2492, 255
  %2499 = tail call i32 @llvm.ctpop.i32(i32 %2498) #10
  %2500 = trunc i32 %2499 to i8
  %2501 = and i8 %2500, 1
  %2502 = xor i8 %2501, 1
  store i8 %2502, i8* %52, align 1, !tbaa !2447
  %2503 = xor i32 %2491, %2492
  %2504 = lshr i32 %2503, 4
  %2505 = trunc i32 %2504 to i8
  %2506 = and i8 %2505, 1
  store i8 %2506, i8* %53, align 1, !tbaa !2451
  %2507 = icmp eq i32 %2492, 0
  %2508 = zext i1 %2507 to i8
  store i8 %2508, i8* %54, align 1, !tbaa !2448
  %2509 = lshr i32 %2492, 31
  %2510 = trunc i32 %2509 to i8
  store i8 %2510, i8* %55, align 1, !tbaa !2449
  %2511 = lshr i32 %2491, 31
  %2512 = xor i32 %2509, %2511
  %2513 = add nuw nsw i32 %2512, %2509
  %2514 = icmp eq i32 %2513, 2
  %2515 = zext i1 %2514 to i8
  store i8 %2515, i8* %56, align 1, !tbaa !2450
  %2516 = sext i32 %2492 to i64
  store i64 %2516, i64* %RSI, align 8, !tbaa !2428
  %2517 = shl nsw i64 %2516, 3
  %2518 = add i64 %2517, %2487
  %2519 = add i64 %2484, 18
  store i64 %2519, i64* %PC, align 8
  %2520 = inttoptr i64 %2518 to i64*
  %2521 = load i64, i64* %2520, align 8
  %2522 = load i64, i64* %RAX, align 8
  %2523 = xor i64 %2522, %2521
  store i64 %2523, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %2524 = trunc i64 %2523 to i32
  %2525 = and i32 %2524, 255
  %2526 = tail call i32 @llvm.ctpop.i32(i32 %2525) #10
  %2527 = trunc i32 %2526 to i8
  %2528 = and i8 %2527, 1
  %2529 = xor i8 %2528, 1
  store i8 %2529, i8* %52, align 1, !tbaa !2447
  %2530 = icmp eq i64 %2523, 0
  %2531 = zext i1 %2530 to i8
  store i8 %2531, i8* %54, align 1, !tbaa !2448
  %2532 = lshr i64 %2523, 63
  %2533 = trunc i64 %2532 to i8
  store i8 %2533, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %2523, i64* %3940, align 1, !tbaa !2428
  store i64 0, i64* %3938, align 1, !tbaa !2428
  %2534 = add i64 %2482, -88
  %2535 = add i64 %2484, 36
  store i64 %2535, i64* %PC, align 8
  %2536 = inttoptr i64 %2534 to i64*
  store i64 %2523, i64* %2536, align 8
  %2537 = load i64, i64* %RBP, align 8
  %2538 = add i64 %2537, -80
  %2539 = load i64, i64* %PC, align 8
  %2540 = add i64 %2539, 5
  store i64 %2540, i64* %PC, align 8
  %2541 = inttoptr i64 %2538 to i64*
  %2542 = load i64, i64* %2541, align 8
  %2543 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2542, i64* %2543, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %2544 = add i64 %2537, -24
  %2545 = add i64 %2539, 9
  store i64 %2545, i64* %PC, align 8
  %2546 = inttoptr i64 %2544 to i64*
  %2547 = load i64, i64* %2546, align 8
  store i64 %2547, i64* %RDX, align 8, !tbaa !2428
  %2548 = add i64 %2537, -32
  %2549 = add i64 %2539, 13
  store i64 %2549, i64* %PC, align 8
  %2550 = inttoptr i64 %2548 to i32*
  %2551 = load i32, i32* %2550, align 4
  %2552 = sext i32 %2551 to i64
  store i64 %2552, i64* %RSI, align 8, !tbaa !2428
  %2553 = shl nsw i64 %2552, 3
  %2554 = add i64 %2553, %2547
  %2555 = add i64 %2539, 18
  store i64 %2555, i64* %PC, align 8
  %2556 = inttoptr i64 %2554 to i64*
  store i64 %2542, i64* %2556, align 8
  %2557 = load i64, i64* %RBP, align 8
  %2558 = add i64 %2557, -88
  %2559 = load i64, i64* %PC, align 8
  %2560 = add i64 %2559, 5
  store i64 %2560, i64* %PC, align 8
  %2561 = inttoptr i64 %2558 to i64*
  %2562 = load i64, i64* %2561, align 8
  %2563 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2562, i64* %2563, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %2564 = add i64 %2557, -24
  %2565 = add i64 %2559, 9
  store i64 %2565, i64* %PC, align 8
  %2566 = inttoptr i64 %2564 to i64*
  %2567 = load i64, i64* %2566, align 8
  store i64 %2567, i64* %RDX, align 8, !tbaa !2428
  %2568 = add i64 %2557, -32
  %2569 = add i64 %2559, 12
  store i64 %2569, i64* %PC, align 8
  %2570 = inttoptr i64 %2568 to i32*
  %2571 = load i32, i32* %2570, align 4
  %2572 = add i32 %2571, 1
  %2573 = zext i32 %2572 to i64
  store i64 %2573, i64* %RCX, align 8, !tbaa !2428
  %2574 = icmp eq i32 %2571, -1
  %2575 = icmp eq i32 %2572, 0
  %2576 = or i1 %2574, %2575
  %2577 = zext i1 %2576 to i8
  store i8 %2577, i8* %51, align 1, !tbaa !2433
  %2578 = and i32 %2572, 255
  %2579 = tail call i32 @llvm.ctpop.i32(i32 %2578) #10
  %2580 = trunc i32 %2579 to i8
  %2581 = and i8 %2580, 1
  %2582 = xor i8 %2581, 1
  store i8 %2582, i8* %52, align 1, !tbaa !2447
  %2583 = xor i32 %2571, %2572
  %2584 = lshr i32 %2583, 4
  %2585 = trunc i32 %2584 to i8
  %2586 = and i8 %2585, 1
  store i8 %2586, i8* %53, align 1, !tbaa !2451
  %2587 = icmp eq i32 %2572, 0
  %2588 = zext i1 %2587 to i8
  store i8 %2588, i8* %54, align 1, !tbaa !2448
  %2589 = lshr i32 %2572, 31
  %2590 = trunc i32 %2589 to i8
  store i8 %2590, i8* %55, align 1, !tbaa !2449
  %2591 = lshr i32 %2571, 31
  %2592 = xor i32 %2589, %2591
  %2593 = add nuw nsw i32 %2592, %2589
  %2594 = icmp eq i32 %2593, 2
  %2595 = zext i1 %2594 to i8
  store i8 %2595, i8* %56, align 1, !tbaa !2450
  %2596 = sext i32 %2572 to i64
  store i64 %2596, i64* %RSI, align 8, !tbaa !2428
  %2597 = shl nsw i64 %2596, 3
  %2598 = add i64 %2597, %2567
  %2599 = add i64 %2559, 23
  store i64 %2599, i64* %PC, align 8
  %2600 = inttoptr i64 %2598 to i64*
  store i64 %2562, i64* %2600, align 8
  %2601 = load i64, i64* %RBP, align 8
  %2602 = add i64 %2601, -64
  %2603 = load i64, i64* %PC, align 8
  %2604 = add i64 %2603, 5
  store i64 %2604, i64* %PC, align 8
  %2605 = inttoptr i64 %2602 to i64*
  %2606 = load i64, i64* %2605, align 8
  %2607 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2606, i64* %2607, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %2608 = add i64 %2601, -24
  %2609 = add i64 %2603, 9
  store i64 %2609, i64* %PC, align 8
  %2610 = inttoptr i64 %2608 to i64*
  %2611 = load i64, i64* %2610, align 8
  store i64 %2611, i64* %RDX, align 8, !tbaa !2428
  %2612 = add i64 %2601, -40
  %2613 = add i64 %2603, 13
  store i64 %2613, i64* %PC, align 8
  %2614 = inttoptr i64 %2612 to i32*
  %2615 = load i32, i32* %2614, align 4
  %2616 = sext i32 %2615 to i64
  store i64 %2616, i64* %RSI, align 8, !tbaa !2428
  %2617 = shl nsw i64 %2616, 3
  %2618 = add i64 %2617, %2611
  %2619 = add i64 %2603, 18
  store i64 %2619, i64* %PC, align 8
  %2620 = inttoptr i64 %2618 to i64*
  store i64 %2606, i64* %2620, align 8
  %2621 = load i64, i64* %RBP, align 8
  %2622 = add i64 %2621, -72
  %2623 = load i64, i64* %PC, align 8
  %2624 = add i64 %2623, 5
  store i64 %2624, i64* %PC, align 8
  %2625 = inttoptr i64 %2622 to i64*
  %2626 = load i64, i64* %2625, align 8
  %2627 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %2626, i64* %2627, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3939, align 1, !tbaa !2452
  %2628 = add i64 %2621, -24
  %2629 = add i64 %2623, 9
  store i64 %2629, i64* %PC, align 8
  %2630 = inttoptr i64 %2628 to i64*
  %2631 = load i64, i64* %2630, align 8
  store i64 %2631, i64* %RDX, align 8, !tbaa !2428
  %2632 = add i64 %2621, -40
  %2633 = add i64 %2623, 12
  store i64 %2633, i64* %PC, align 8
  %2634 = inttoptr i64 %2632 to i32*
  %2635 = load i32, i32* %2634, align 4
  %2636 = add i32 %2635, 1
  %2637 = zext i32 %2636 to i64
  store i64 %2637, i64* %RCX, align 8, !tbaa !2428
  %2638 = icmp eq i32 %2635, -1
  %2639 = icmp eq i32 %2636, 0
  %2640 = or i1 %2638, %2639
  %2641 = zext i1 %2640 to i8
  store i8 %2641, i8* %51, align 1, !tbaa !2433
  %2642 = and i32 %2636, 255
  %2643 = tail call i32 @llvm.ctpop.i32(i32 %2642) #10
  %2644 = trunc i32 %2643 to i8
  %2645 = and i8 %2644, 1
  %2646 = xor i8 %2645, 1
  store i8 %2646, i8* %52, align 1, !tbaa !2447
  %2647 = xor i32 %2635, %2636
  %2648 = lshr i32 %2647, 4
  %2649 = trunc i32 %2648 to i8
  %2650 = and i8 %2649, 1
  store i8 %2650, i8* %53, align 1, !tbaa !2451
  %2651 = icmp eq i32 %2636, 0
  %2652 = zext i1 %2651 to i8
  store i8 %2652, i8* %54, align 1, !tbaa !2448
  %2653 = lshr i32 %2636, 31
  %2654 = trunc i32 %2653 to i8
  store i8 %2654, i8* %55, align 1, !tbaa !2449
  %2655 = lshr i32 %2635, 31
  %2656 = xor i32 %2653, %2655
  %2657 = add nuw nsw i32 %2656, %2653
  %2658 = icmp eq i32 %2657, 2
  %2659 = zext i1 %2658 to i8
  store i8 %2659, i8* %56, align 1, !tbaa !2450
  %2660 = sext i32 %2636 to i64
  store i64 %2660, i64* %RSI, align 8, !tbaa !2428
  %2661 = shl nsw i64 %2660, 3
  %2662 = add i64 %2661, %2631
  %2663 = add i64 %2623, 23
  store i64 %2663, i64* %PC, align 8
  %2664 = inttoptr i64 %2662 to i64*
  store i64 %2626, i64* %2664, align 8
  %2665 = load i64, i64* %RBP, align 8
  %2666 = add i64 %2665, -52
  %2667 = load i64, i64* %PC, align 8
  %2668 = add i64 %2667, 3
  store i64 %2668, i64* %PC, align 8
  %2669 = inttoptr i64 %2666 to i32*
  %2670 = load i32, i32* %2669, align 4
  %2671 = zext i32 %2670 to i64
  store i64 %2671, i64* %RCX, align 8, !tbaa !2428
  %2672 = add i64 %2665, -40
  %2673 = add i64 %2667, 6
  store i64 %2673, i64* %PC, align 8
  %2674 = inttoptr i64 %2672 to i32*
  %2675 = load i32, i32* %2674, align 4
  %2676 = add i32 %2675, %2670
  %2677 = zext i32 %2676 to i64
  store i64 %2677, i64* %RCX, align 8, !tbaa !2428
  %2678 = icmp ult i32 %2676, %2670
  %2679 = icmp ult i32 %2676, %2675
  %2680 = or i1 %2678, %2679
  %2681 = zext i1 %2680 to i8
  store i8 %2681, i8* %51, align 1, !tbaa !2433
  %2682 = and i32 %2676, 255
  %2683 = tail call i32 @llvm.ctpop.i32(i32 %2682) #10
  %2684 = trunc i32 %2683 to i8
  %2685 = and i8 %2684, 1
  %2686 = xor i8 %2685, 1
  store i8 %2686, i8* %52, align 1, !tbaa !2447
  %2687 = xor i32 %2675, %2670
  %2688 = xor i32 %2687, %2676
  %2689 = lshr i32 %2688, 4
  %2690 = trunc i32 %2689 to i8
  %2691 = and i8 %2690, 1
  store i8 %2691, i8* %53, align 1, !tbaa !2451
  %2692 = icmp eq i32 %2676, 0
  %2693 = zext i1 %2692 to i8
  store i8 %2693, i8* %54, align 1, !tbaa !2448
  %2694 = lshr i32 %2676, 31
  %2695 = trunc i32 %2694 to i8
  store i8 %2695, i8* %55, align 1, !tbaa !2449
  %2696 = lshr i32 %2670, 31
  %2697 = lshr i32 %2675, 31
  %2698 = xor i32 %2694, %2696
  %2699 = xor i32 %2694, %2697
  %2700 = add nuw nsw i32 %2698, %2699
  %2701 = icmp eq i32 %2700, 2
  %2702 = zext i1 %2701 to i8
  store i8 %2702, i8* %56, align 1, !tbaa !2450
  %2703 = add i64 %2667, 9
  store i64 %2703, i64* %PC, align 8
  store i32 %2676, i32* %2674, align 4
  %2704 = load i64, i64* %RBP, align 8
  %2705 = add i64 %2704, -24
  %2706 = load i64, i64* %PC, align 8
  %2707 = add i64 %2706, 4
  store i64 %2707, i64* %PC, align 8
  %2708 = inttoptr i64 %2705 to i64*
  %2709 = load i64, i64* %2708, align 8
  store i64 %2709, i64* %RDX, align 8, !tbaa !2428
  %2710 = add i64 %2704, -40
  %2711 = add i64 %2706, 7
  store i64 %2711, i64* %PC, align 8
  %2712 = inttoptr i64 %2710 to i32*
  %2713 = load i32, i32* %2712, align 4
  %2714 = add i32 %2713, 1
  %2715 = zext i32 %2714 to i64
  store i64 %2715, i64* %RCX, align 8, !tbaa !2428
  %2716 = icmp eq i32 %2713, -1
  %2717 = icmp eq i32 %2714, 0
  %2718 = or i1 %2716, %2717
  %2719 = zext i1 %2718 to i8
  store i8 %2719, i8* %51, align 1, !tbaa !2433
  %2720 = and i32 %2714, 255
  %2721 = tail call i32 @llvm.ctpop.i32(i32 %2720) #10
  %2722 = trunc i32 %2721 to i8
  %2723 = and i8 %2722, 1
  %2724 = xor i8 %2723, 1
  store i8 %2724, i8* %52, align 1, !tbaa !2447
  %2725 = xor i32 %2713, %2714
  %2726 = lshr i32 %2725, 4
  %2727 = trunc i32 %2726 to i8
  %2728 = and i8 %2727, 1
  store i8 %2728, i8* %53, align 1, !tbaa !2451
  %2729 = icmp eq i32 %2714, 0
  %2730 = zext i1 %2729 to i8
  store i8 %2730, i8* %54, align 1, !tbaa !2448
  %2731 = lshr i32 %2714, 31
  %2732 = trunc i32 %2731 to i8
  store i8 %2732, i8* %55, align 1, !tbaa !2449
  %2733 = lshr i32 %2713, 31
  %2734 = xor i32 %2731, %2733
  %2735 = add nuw nsw i32 %2734, %2731
  %2736 = icmp eq i32 %2735, 2
  %2737 = zext i1 %2736 to i8
  store i8 %2737, i8* %56, align 1, !tbaa !2450
  %2738 = sext i32 %2714 to i64
  store i64 %2738, i64* %RSI, align 8, !tbaa !2428
  %2739 = shl nsw i64 %2738, 3
  %2740 = add i64 %2739, %2709
  %2741 = add i64 %2706, 18
  store i64 %2741, i64* %PC, align 8
  %2742 = inttoptr i64 %2740 to i64*
  %2743 = load i64, i64* %2742, align 8
  %2744 = load i64, i64* %RAX, align 8
  %2745 = xor i64 %2744, %2743
  store i64 %2745, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %2746 = trunc i64 %2745 to i32
  %2747 = and i32 %2746, 255
  %2748 = tail call i32 @llvm.ctpop.i32(i32 %2747) #10
  %2749 = trunc i32 %2748 to i8
  %2750 = and i8 %2749, 1
  %2751 = xor i8 %2750, 1
  store i8 %2751, i8* %52, align 1, !tbaa !2447
  %2752 = icmp eq i64 %2745, 0
  %2753 = zext i1 %2752 to i8
  store i8 %2753, i8* %54, align 1, !tbaa !2448
  %2754 = lshr i64 %2745, 63
  %2755 = trunc i64 %2754 to i8
  store i8 %2755, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %2745, i64* %3940, align 1, !tbaa !2428
  store i64 0, i64* %3938, align 1, !tbaa !2428
  %2756 = add i64 %2706, 35
  store i64 %2756, i64* %PC, align 8
  %2757 = load i64, i64* %2708, align 8
  store i64 %2757, i64* %RAX, align 8, !tbaa !2428
  %2758 = add i64 %2706, 38
  store i64 %2758, i64* %PC, align 8
  %2759 = load i32, i32* %2712, align 4
  %2760 = add i32 %2759, 1
  %2761 = zext i32 %2760 to i64
  store i64 %2761, i64* %RCX, align 8, !tbaa !2428
  %2762 = icmp eq i32 %2759, -1
  %2763 = icmp eq i32 %2760, 0
  %2764 = or i1 %2762, %2763
  %2765 = zext i1 %2764 to i8
  store i8 %2765, i8* %51, align 1, !tbaa !2433
  %2766 = and i32 %2760, 255
  %2767 = tail call i32 @llvm.ctpop.i32(i32 %2766) #10
  %2768 = trunc i32 %2767 to i8
  %2769 = and i8 %2768, 1
  %2770 = xor i8 %2769, 1
  store i8 %2770, i8* %52, align 1, !tbaa !2447
  %2771 = xor i32 %2759, %2760
  %2772 = lshr i32 %2771, 4
  %2773 = trunc i32 %2772 to i8
  %2774 = and i8 %2773, 1
  store i8 %2774, i8* %53, align 1, !tbaa !2451
  %2775 = icmp eq i32 %2760, 0
  %2776 = zext i1 %2775 to i8
  store i8 %2776, i8* %54, align 1, !tbaa !2448
  %2777 = lshr i32 %2760, 31
  %2778 = trunc i32 %2777 to i8
  store i8 %2778, i8* %55, align 1, !tbaa !2449
  %2779 = lshr i32 %2759, 31
  %2780 = xor i32 %2777, %2779
  %2781 = add nuw nsw i32 %2780, %2777
  %2782 = icmp eq i32 %2781, 2
  %2783 = zext i1 %2782 to i8
  store i8 %2783, i8* %56, align 1, !tbaa !2450
  %2784 = sext i32 %2760 to i64
  store i64 %2784, i64* %RDX, align 8, !tbaa !2428
  %2785 = shl nsw i64 %2784, 3
  %2786 = add i64 %2785, %2757
  %2787 = add i64 %2706, 49
  store i64 %2787, i64* %PC, align 8
  %2788 = inttoptr i64 %2786 to i64*
  store i64 %2745, i64* %2788, align 8
  %2789 = load i64, i64* %RBP, align 8
  %2790 = add i64 %2789, -36
  %2791 = load i64, i64* %PC, align 8
  %2792 = add i64 %2791, 3
  store i64 %2792, i64* %PC, align 8
  %2793 = inttoptr i64 %2790 to i32*
  %2794 = load i32, i32* %2793, align 4
  %2795 = add i32 %2794, 1
  %2796 = zext i32 %2795 to i64
  store i64 %2796, i64* %RAX, align 8, !tbaa !2428
  %2797 = icmp eq i32 %2794, -1
  %2798 = icmp eq i32 %2795, 0
  %2799 = or i1 %2797, %2798
  %2800 = zext i1 %2799 to i8
  store i8 %2800, i8* %51, align 1, !tbaa !2433
  %2801 = and i32 %2795, 255
  %2802 = tail call i32 @llvm.ctpop.i32(i32 %2801) #10
  %2803 = trunc i32 %2802 to i8
  %2804 = and i8 %2803, 1
  %2805 = xor i8 %2804, 1
  store i8 %2805, i8* %52, align 1, !tbaa !2447
  %2806 = xor i32 %2794, %2795
  %2807 = lshr i32 %2806, 4
  %2808 = trunc i32 %2807 to i8
  %2809 = and i8 %2808, 1
  store i8 %2809, i8* %53, align 1, !tbaa !2451
  %2810 = icmp eq i32 %2795, 0
  %2811 = zext i1 %2810 to i8
  store i8 %2811, i8* %54, align 1, !tbaa !2448
  %2812 = lshr i32 %2795, 31
  %2813 = trunc i32 %2812 to i8
  store i8 %2813, i8* %55, align 1, !tbaa !2449
  %2814 = lshr i32 %2794, 31
  %2815 = xor i32 %2812, %2814
  %2816 = add nuw nsw i32 %2815, %2812
  %2817 = icmp eq i32 %2816, 2
  %2818 = zext i1 %2817 to i8
  store i8 %2818, i8* %56, align 1, !tbaa !2450
  %2819 = add i64 %2791, 9
  store i64 %2819, i64* %PC, align 8
  store i32 %2795, i32* %2793, align 4
  %2820 = load i64, i64* %PC, align 8
  %2821 = add i64 %2820, -1271
  store i64 %2821, i64* %57, align 8, !tbaa !2428
  br label %block_401c8a

block_401c9d:                                     ; preds = %block_401c96, %block_401ca9
  %2822 = phi i64 [ %.pre6, %block_401c96 ], [ %2122, %block_401ca9 ]
  %2823 = load i64, i64* %RBP, align 8
  %2824 = add i64 %2823, -28
  %2825 = add i64 %2822, 3
  store i64 %2825, i64* %PC, align 8
  %2826 = inttoptr i64 %2824 to i32*
  %2827 = load i32, i32* %2826, align 4
  %2828 = zext i32 %2827 to i64
  store i64 %2828, i64* %RAX, align 8, !tbaa !2428
  %2829 = add i64 %2823, -36
  %2830 = add i64 %2822, 6
  store i64 %2830, i64* %PC, align 8
  %2831 = inttoptr i64 %2829 to i32*
  %2832 = load i32, i32* %2831, align 4
  %2833 = sub i32 %2827, %2832
  %2834 = icmp ult i32 %2827, %2832
  %2835 = zext i1 %2834 to i8
  store i8 %2835, i8* %51, align 1, !tbaa !2433
  %2836 = and i32 %2833, 255
  %2837 = tail call i32 @llvm.ctpop.i32(i32 %2836) #10
  %2838 = trunc i32 %2837 to i8
  %2839 = and i8 %2838, 1
  %2840 = xor i8 %2839, 1
  store i8 %2840, i8* %52, align 1, !tbaa !2447
  %2841 = xor i32 %2832, %2827
  %2842 = xor i32 %2841, %2833
  %2843 = lshr i32 %2842, 4
  %2844 = trunc i32 %2843 to i8
  %2845 = and i8 %2844, 1
  store i8 %2845, i8* %53, align 1, !tbaa !2451
  %2846 = icmp eq i32 %2833, 0
  %2847 = zext i1 %2846 to i8
  store i8 %2847, i8* %54, align 1, !tbaa !2448
  %2848 = lshr i32 %2833, 31
  %2849 = trunc i32 %2848 to i8
  store i8 %2849, i8* %55, align 1, !tbaa !2449
  %2850 = lshr i32 %2827, 31
  %2851 = lshr i32 %2832, 31
  %2852 = xor i32 %2851, %2850
  %2853 = xor i32 %2848, %2850
  %2854 = add nuw nsw i32 %2853, %2852
  %2855 = icmp eq i32 %2854, 2
  %2856 = zext i1 %2855 to i8
  store i8 %2856, i8* %56, align 1, !tbaa !2450
  %2857 = icmp ne i8 %2849, 0
  %2858 = xor i1 %2857, %2855
  %.v15 = select i1 %2858, i64 12, i64 898
  %2859 = add i64 %2822, %.v15
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %2860 = add i64 %2859, 13
  store i64 %2860, i64* %PC, align 8
  br i1 %2858, label %block_401ca9, label %block_40201f

block_401c96:                                     ; preds = %block_401c8a
  %2861 = add i64 %2937, -28
  %2862 = add i64 %2973, 7
  store i64 %2862, i64* %PC, align 8
  %2863 = inttoptr i64 %2861 to i32*
  store i32 0, i32* %2863, align 4
  %.pre6 = load i64, i64* %PC, align 8
  br label %block_401c9d

block_4021ec:                                     ; preds = %block_40218b, %block_4023d9
  %2864 = phi i64 [ %.pre7, %block_40218b ], [ %590, %block_4023d9 ]
  %2865 = load i64, i64* %RBP, align 8
  %2866 = add i64 %2865, -36
  %2867 = add i64 %2864, 3
  store i64 %2867, i64* %PC, align 8
  %2868 = inttoptr i64 %2866 to i32*
  %2869 = load i32, i32* %2868, align 4
  %2870 = zext i32 %2869 to i64
  store i64 %2870, i64* %RAX, align 8, !tbaa !2428
  %2871 = add i64 %2865, -48
  %2872 = add i64 %2864, 6
  store i64 %2872, i64* %PC, align 8
  %2873 = inttoptr i64 %2871 to i32*
  %2874 = load i32, i32* %2873, align 4
  %2875 = sub i32 %2869, %2874
  %2876 = icmp ult i32 %2869, %2874
  %2877 = zext i1 %2876 to i8
  store i8 %2877, i8* %51, align 1, !tbaa !2433
  %2878 = and i32 %2875, 255
  %2879 = tail call i32 @llvm.ctpop.i32(i32 %2878) #10
  %2880 = trunc i32 %2879 to i8
  %2881 = and i8 %2880, 1
  %2882 = xor i8 %2881, 1
  store i8 %2882, i8* %52, align 1, !tbaa !2447
  %2883 = xor i32 %2874, %2869
  %2884 = xor i32 %2883, %2875
  %2885 = lshr i32 %2884, 4
  %2886 = trunc i32 %2885 to i8
  %2887 = and i8 %2886, 1
  store i8 %2887, i8* %53, align 1, !tbaa !2451
  %2888 = icmp eq i32 %2875, 0
  %2889 = zext i1 %2888 to i8
  store i8 %2889, i8* %54, align 1, !tbaa !2448
  %2890 = lshr i32 %2875, 31
  %2891 = trunc i32 %2890 to i8
  store i8 %2891, i8* %55, align 1, !tbaa !2449
  %2892 = lshr i32 %2869, 31
  %2893 = lshr i32 %2874, 31
  %2894 = xor i32 %2893, %2892
  %2895 = xor i32 %2890, %2892
  %2896 = add nuw nsw i32 %2895, %2894
  %2897 = icmp eq i32 %2896, 2
  %2898 = zext i1 %2897 to i8
  store i8 %2898, i8* %56, align 1, !tbaa !2450
  %2899 = icmp ne i8 %2891, 0
  %2900 = xor i1 %2899, %2897
  %.v21 = select i1 %2900, i64 12, i64 641
  %2901 = add i64 %2864, %.v21
  store i64 %2901, i64* %57, align 8, !tbaa !2428
  br i1 %2900, label %block_4021f8, label %block_40246d

block_401c15:                                     ; preds = %block_401c06
  %2902 = load i32, i32* %3789, align 4
  %2903 = zext i32 %2902 to i64
  %2904 = shl nuw i64 %2903, 32
  %2905 = ashr i64 %2904, 33
  %2906 = trunc i32 %2902 to i8
  %2907 = and i8 %2906, 1
  %2908 = trunc i64 %2905 to i32
  %2909 = and i64 %2905, 4294967295
  store i64 %2909, i64* %RAX, align 8, !tbaa !2428
  store i8 %2907, i8* %51, align 1, !tbaa !2432
  %2910 = and i32 %2908, 255
  %2911 = tail call i32 @llvm.ctpop.i32(i32 %2910) #10
  %2912 = trunc i32 %2911 to i8
  %2913 = and i8 %2912, 1
  %2914 = xor i8 %2913, 1
  store i8 %2914, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %2915 = icmp eq i32 %2908, 0
  %2916 = zext i1 %2915 to i8
  store i8 %2916, i8* %54, align 1, !tbaa !2432
  %2917 = lshr i64 %2905, 31
  %2918 = trunc i64 %2917 to i8
  %2919 = and i8 %2918, 1
  store i8 %2919, i8* %55, align 1, !tbaa !2432
  store i8 0, i8* %56, align 1, !tbaa !2432
  %2920 = trunc i64 %2905 to i32
  %2921 = add i64 %3816, 9
  store i64 %2921, i64* %PC, align 8
  store i32 %2920, i32* %3789, align 4
  %2922 = load i64, i64* %RBP, align 8
  %2923 = add i64 %2922, -28
  %2924 = load i64, i64* %PC, align 8
  %2925 = add i64 %2924, 7
  store i64 %2925, i64* %PC, align 8
  %2926 = inttoptr i64 %2923 to i32*
  store i32 0, i32* %2926, align 4
  %.pre4 = load i64, i64* %PC, align 8
  br label %block_401c25

block_402472:                                     ; preds = %block_402186, %block_40246d
  %.sink = phi i64 [ %193, %block_402186 ], [ %100, %block_40246d ]
  %2927 = add i64 %.sink, 1
  store i64 %2927, i64* %PC, align 8
  %2928 = load i64, i64* %7, align 8, !tbaa !2428
  %2929 = add i64 %2928, 8
  %2930 = inttoptr i64 %2928 to i64*
  %2931 = load i64, i64* %2930, align 8
  store i64 %2931, i64* %RBP, align 8, !tbaa !2428
  store i64 %2929, i64* %7, align 8, !tbaa !2428
  %2932 = add i64 %.sink, 2
  store i64 %2932, i64* %PC, align 8
  %2933 = inttoptr i64 %2929 to i64*
  %2934 = load i64, i64* %2933, align 8
  store i64 %2934, i64* %57, align 8, !tbaa !2428
  %2935 = add i64 %2928, 16
  store i64 %2935, i64* %7, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_401c8a:                                     ; preds = %block_401c83, %block_40201f
  %2936 = phi i64 [ %.pre5, %block_401c83 ], [ %2821, %block_40201f ]
  %2937 = load i64, i64* %RBP, align 8
  %2938 = add i64 %2937, -36
  %2939 = add i64 %2936, 3
  store i64 %2939, i64* %PC, align 8
  %2940 = inttoptr i64 %2938 to i32*
  %2941 = load i32, i32* %2940, align 4
  %2942 = zext i32 %2941 to i64
  store i64 %2942, i64* %RAX, align 8, !tbaa !2428
  %2943 = add i64 %2937, -48
  %2944 = add i64 %2936, 6
  store i64 %2944, i64* %PC, align 8
  %2945 = inttoptr i64 %2943 to i32*
  %2946 = load i32, i32* %2945, align 4
  %2947 = sub i32 %2941, %2946
  %2948 = icmp ult i32 %2941, %2946
  %2949 = zext i1 %2948 to i8
  store i8 %2949, i8* %51, align 1, !tbaa !2433
  %2950 = and i32 %2947, 255
  %2951 = tail call i32 @llvm.ctpop.i32(i32 %2950) #10
  %2952 = trunc i32 %2951 to i8
  %2953 = and i8 %2952, 1
  %2954 = xor i8 %2953, 1
  store i8 %2954, i8* %52, align 1, !tbaa !2447
  %2955 = xor i32 %2946, %2941
  %2956 = xor i32 %2955, %2947
  %2957 = lshr i32 %2956, 4
  %2958 = trunc i32 %2957 to i8
  %2959 = and i8 %2958, 1
  store i8 %2959, i8* %53, align 1, !tbaa !2451
  %2960 = icmp eq i32 %2947, 0
  %2961 = zext i1 %2960 to i8
  store i8 %2961, i8* %54, align 1, !tbaa !2448
  %2962 = lshr i32 %2947, 31
  %2963 = trunc i32 %2962 to i8
  store i8 %2963, i8* %55, align 1, !tbaa !2449
  %2964 = lshr i32 %2941, 31
  %2965 = lshr i32 %2946, 31
  %2966 = xor i32 %2965, %2964
  %2967 = xor i32 %2962, %2964
  %2968 = add nuw nsw i32 %2967, %2966
  %2969 = icmp eq i32 %2968, 2
  %2970 = zext i1 %2969 to i8
  store i8 %2970, i8* %56, align 1, !tbaa !2450
  %2971 = icmp ne i8 %2963, 0
  %2972 = xor i1 %2971, %2969
  %.v14 = select i1 %2972, i64 12, i64 1276
  %2973 = add i64 %2936, %.v14
  store i64 %2973, i64* %57, align 8, !tbaa !2428
  br i1 %2972, label %block_401c96, label %block_402186

block_40220b:                                     ; preds = %block_4021ff
  %2974 = load i32, i32* %62, align 4
  %2975 = shl i32 %2974, 1
  %2976 = icmp slt i32 %2974, 0
  %2977 = icmp slt i32 %2975, 0
  %2978 = xor i1 %2976, %2977
  %2979 = zext i32 %2975 to i64
  store i64 %2979, i64* %RCX, align 8, !tbaa !2428
  %.lobit23 = lshr i32 %2974, 31
  %2980 = trunc i32 %.lobit23 to i8
  store i8 %2980, i8* %51, align 1, !tbaa !2432
  %2981 = and i32 %2975, 254
  %2982 = tail call i32 @llvm.ctpop.i32(i32 %2981) #10
  %2983 = trunc i32 %2982 to i8
  %2984 = and i8 %2983, 1
  %2985 = xor i8 %2984, 1
  store i8 %2985, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %2986 = icmp eq i32 %2975, 0
  %2987 = zext i1 %2986 to i8
  store i8 %2987, i8* %54, align 1, !tbaa !2432
  %2988 = lshr i32 %2974, 30
  %2989 = and i32 %2988, 1
  %2990 = trunc i32 %2989 to i8
  store i8 %2990, i8* %55, align 1, !tbaa !2432
  %2991 = zext i1 %2978 to i8
  store i8 %2991, i8* %56, align 1, !tbaa !2432
  %2992 = add i64 %59, -16
  %2993 = add i64 %95, 20
  store i64 %2993, i64* %PC, align 8
  %2994 = inttoptr i64 %2992 to i64*
  %2995 = load i64, i64* %2994, align 8
  store i64 %2995, i64* %RDX, align 8, !tbaa !2428
  %2996 = add i64 %95, 24
  store i64 %2996, i64* %PC, align 8
  %2997 = load i32, i32* %67, align 4
  %2998 = sext i32 %2997 to i64
  store i64 %2998, i64* %RSI, align 8, !tbaa !2428
  %2999 = shl nsw i64 %2998, 2
  %3000 = add i64 %2999, %2995
  %3001 = add i64 %95, 27
  store i64 %3001, i64* %PC, align 8
  %3002 = inttoptr i64 %3000 to i32*
  %3003 = load i32, i32* %3002, align 4
  %3004 = add i32 %3003, %2975
  %3005 = zext i32 %3004 to i64
  store i64 %3005, i64* %RCX, align 8, !tbaa !2428
  %3006 = icmp ult i32 %3004, %2975
  %3007 = icmp ult i32 %3004, %3003
  %3008 = or i1 %3006, %3007
  %3009 = zext i1 %3008 to i8
  store i8 %3009, i8* %51, align 1, !tbaa !2433
  %3010 = and i32 %3004, 255
  %3011 = tail call i32 @llvm.ctpop.i32(i32 %3010) #10
  %3012 = trunc i32 %3011 to i8
  %3013 = and i8 %3012, 1
  %3014 = xor i8 %3013, 1
  store i8 %3014, i8* %52, align 1, !tbaa !2447
  %3015 = xor i32 %3003, %2975
  %3016 = xor i32 %3015, %3004
  %3017 = lshr i32 %3016, 4
  %3018 = trunc i32 %3017 to i8
  %3019 = and i8 %3018, 1
  store i8 %3019, i8* %53, align 1, !tbaa !2451
  %3020 = icmp eq i32 %3004, 0
  %3021 = zext i1 %3020 to i8
  store i8 %3021, i8* %54, align 1, !tbaa !2448
  %3022 = lshr i32 %3004, 31
  %3023 = trunc i32 %3022 to i8
  store i8 %3023, i8* %55, align 1, !tbaa !2449
  %3024 = lshr i32 %3003, 31
  %3025 = xor i32 %3022, %2989
  %3026 = xor i32 %3022, %3024
  %3027 = add nuw nsw i32 %3025, %3026
  %3028 = icmp eq i32 %3027, 2
  %3029 = zext i1 %3028 to i8
  store i8 %3029, i8* %56, align 1, !tbaa !2450
  %3030 = add i64 %59, -32
  %3031 = add i64 %95, 30
  store i64 %3031, i64* %PC, align 8
  %3032 = inttoptr i64 %3030 to i32*
  store i32 %3004, i32* %3032, align 4
  %3033 = load i64, i64* %RBP, align 8
  %3034 = add i64 %3033, -36
  %3035 = load i64, i64* %PC, align 8
  %3036 = add i64 %3035, 3
  store i64 %3036, i64* %PC, align 8
  %3037 = inttoptr i64 %3034 to i32*
  %3038 = load i32, i32* %3037, align 4
  %3039 = shl i32 %3038, 1
  %3040 = icmp slt i32 %3038, 0
  %3041 = icmp slt i32 %3039, 0
  %3042 = xor i1 %3040, %3041
  %3043 = zext i32 %3039 to i64
  store i64 %3043, i64* %RCX, align 8, !tbaa !2428
  %.lobit24 = lshr i32 %3038, 31
  %3044 = trunc i32 %.lobit24 to i8
  store i8 %3044, i8* %51, align 1, !tbaa !2432
  %3045 = and i32 %3039, 254
  %3046 = tail call i32 @llvm.ctpop.i32(i32 %3045) #10
  %3047 = trunc i32 %3046 to i8
  %3048 = and i8 %3047, 1
  %3049 = xor i8 %3048, 1
  store i8 %3049, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %3050 = icmp eq i32 %3039, 0
  %3051 = zext i1 %3050 to i8
  store i8 %3051, i8* %54, align 1, !tbaa !2432
  %3052 = lshr i32 %3038, 30
  %3053 = and i32 %3052, 1
  %3054 = trunc i32 %3053 to i8
  store i8 %3054, i8* %55, align 1, !tbaa !2432
  %3055 = zext i1 %3042 to i8
  store i8 %3055, i8* %56, align 1, !tbaa !2432
  %3056 = add i64 %3033, -16
  %3057 = add i64 %3035, 10
  store i64 %3057, i64* %PC, align 8
  %3058 = inttoptr i64 %3056 to i64*
  %3059 = load i64, i64* %3058, align 8
  store i64 %3059, i64* %RDX, align 8, !tbaa !2428
  %3060 = add i64 %3033, -28
  %3061 = add i64 %3035, 14
  store i64 %3061, i64* %PC, align 8
  %3062 = inttoptr i64 %3060 to i32*
  %3063 = load i32, i32* %3062, align 4
  %3064 = sext i32 %3063 to i64
  store i64 %3064, i64* %RSI, align 8, !tbaa !2428
  %3065 = shl nsw i64 %3064, 2
  %3066 = add i64 %3065, %3059
  %3067 = add i64 %3035, 17
  store i64 %3067, i64* %PC, align 8
  %3068 = inttoptr i64 %3066 to i32*
  %3069 = load i32, i32* %3068, align 4
  %3070 = add i32 %3069, %3039
  %3071 = zext i32 %3070 to i64
  store i64 %3071, i64* %RCX, align 8, !tbaa !2428
  %3072 = icmp ult i32 %3070, %3039
  %3073 = icmp ult i32 %3070, %3069
  %3074 = or i1 %3072, %3073
  %3075 = zext i1 %3074 to i8
  store i8 %3075, i8* %51, align 1, !tbaa !2433
  %3076 = and i32 %3070, 255
  %3077 = tail call i32 @llvm.ctpop.i32(i32 %3076) #10
  %3078 = trunc i32 %3077 to i8
  %3079 = and i8 %3078, 1
  %3080 = xor i8 %3079, 1
  store i8 %3080, i8* %52, align 1, !tbaa !2447
  %3081 = xor i32 %3069, %3039
  %3082 = xor i32 %3081, %3070
  %3083 = lshr i32 %3082, 4
  %3084 = trunc i32 %3083 to i8
  %3085 = and i8 %3084, 1
  store i8 %3085, i8* %53, align 1, !tbaa !2451
  %3086 = icmp eq i32 %3070, 0
  %3087 = zext i1 %3086 to i8
  store i8 %3087, i8* %54, align 1, !tbaa !2448
  %3088 = lshr i32 %3070, 31
  %3089 = trunc i32 %3088 to i8
  store i8 %3089, i8* %55, align 1, !tbaa !2449
  %3090 = lshr i32 %3069, 31
  %3091 = xor i32 %3088, %3053
  %3092 = xor i32 %3088, %3090
  %3093 = add nuw nsw i32 %3091, %3092
  %3094 = icmp eq i32 %3093, 2
  %3095 = zext i1 %3094 to i8
  store i8 %3095, i8* %56, align 1, !tbaa !2450
  %3096 = add i64 %3033, -40
  %3097 = add i64 %3035, 20
  store i64 %3097, i64* %PC, align 8
  %3098 = inttoptr i64 %3096 to i32*
  store i32 %3070, i32* %3098, align 4
  %3099 = load i64, i64* %RBP, align 8
  %3100 = add i64 %3099, -24
  %3101 = load i64, i64* %PC, align 8
  %3102 = add i64 %3101, 4
  store i64 %3102, i64* %PC, align 8
  %3103 = inttoptr i64 %3100 to i64*
  %3104 = load i64, i64* %3103, align 8
  store i64 %3104, i64* %RDX, align 8, !tbaa !2428
  %3105 = add i64 %3099, -32
  %3106 = add i64 %3101, 8
  store i64 %3106, i64* %PC, align 8
  %3107 = inttoptr i64 %3105 to i32*
  %3108 = load i32, i32* %3107, align 4
  %3109 = sext i32 %3108 to i64
  store i64 %3109, i64* %RSI, align 8, !tbaa !2428
  %3110 = shl nsw i64 %3109, 3
  %3111 = add i64 %3110, %3104
  %3112 = add i64 %3101, 13
  store i64 %3112, i64* %PC, align 8
  %3113 = inttoptr i64 %3111 to i64*
  %3114 = load i64, i64* %3113, align 8
  %3115 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3114, i64* %3115, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3827, align 1, !tbaa !2452
  %3116 = add i64 %3099, -64
  %3117 = add i64 %3101, 18
  store i64 %3117, i64* %PC, align 8
  %3118 = inttoptr i64 %3116 to i64*
  store i64 %3114, i64* %3118, align 8
  %3119 = load i64, i64* %RBP, align 8
  %3120 = add i64 %3119, -24
  %3121 = load i64, i64* %PC, align 8
  %3122 = add i64 %3121, 4
  store i64 %3122, i64* %PC, align 8
  %3123 = inttoptr i64 %3120 to i64*
  %3124 = load i64, i64* %3123, align 8
  store i64 %3124, i64* %RDX, align 8, !tbaa !2428
  %3125 = add i64 %3119, -32
  %3126 = add i64 %3121, 7
  store i64 %3126, i64* %PC, align 8
  %3127 = inttoptr i64 %3125 to i32*
  %3128 = load i32, i32* %3127, align 4
  %3129 = add i32 %3128, 1
  %3130 = zext i32 %3129 to i64
  store i64 %3130, i64* %RCX, align 8, !tbaa !2428
  %3131 = icmp eq i32 %3128, -1
  %3132 = icmp eq i32 %3129, 0
  %3133 = or i1 %3131, %3132
  %3134 = zext i1 %3133 to i8
  store i8 %3134, i8* %51, align 1, !tbaa !2433
  %3135 = and i32 %3129, 255
  %3136 = tail call i32 @llvm.ctpop.i32(i32 %3135) #10
  %3137 = trunc i32 %3136 to i8
  %3138 = and i8 %3137, 1
  %3139 = xor i8 %3138, 1
  store i8 %3139, i8* %52, align 1, !tbaa !2447
  %3140 = xor i32 %3128, %3129
  %3141 = lshr i32 %3140, 4
  %3142 = trunc i32 %3141 to i8
  %3143 = and i8 %3142, 1
  store i8 %3143, i8* %53, align 1, !tbaa !2451
  %3144 = icmp eq i32 %3129, 0
  %3145 = zext i1 %3144 to i8
  store i8 %3145, i8* %54, align 1, !tbaa !2448
  %3146 = lshr i32 %3129, 31
  %3147 = trunc i32 %3146 to i8
  store i8 %3147, i8* %55, align 1, !tbaa !2449
  %3148 = lshr i32 %3128, 31
  %3149 = xor i32 %3146, %3148
  %3150 = add nuw nsw i32 %3149, %3146
  %3151 = icmp eq i32 %3150, 2
  %3152 = zext i1 %3151 to i8
  store i8 %3152, i8* %56, align 1, !tbaa !2450
  %3153 = sext i32 %3129 to i64
  store i64 %3153, i64* %RSI, align 8, !tbaa !2428
  %3154 = shl nsw i64 %3153, 3
  %3155 = add i64 %3154, %3124
  %3156 = add i64 %3121, 18
  store i64 %3156, i64* %PC, align 8
  %3157 = inttoptr i64 %3155 to i64*
  %3158 = load i64, i64* %3157, align 8
  %3159 = load i64, i64* %RAX, align 8
  %3160 = xor i64 %3159, %3158
  store i64 %3160, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %3161 = trunc i64 %3160 to i32
  %3162 = and i32 %3161, 255
  %3163 = tail call i32 @llvm.ctpop.i32(i32 %3162) #10
  %3164 = trunc i32 %3163 to i8
  %3165 = and i8 %3164, 1
  %3166 = xor i8 %3165, 1
  store i8 %3166, i8* %52, align 1, !tbaa !2447
  %3167 = icmp eq i64 %3160, 0
  %3168 = zext i1 %3167 to i8
  store i8 %3168, i8* %54, align 1, !tbaa !2448
  %3169 = lshr i64 %3160, 63
  %3170 = trunc i64 %3169 to i8
  store i8 %3170, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %3160, i64* %3839, align 1, !tbaa !2428
  store i64 0, i64* %3826, align 1, !tbaa !2428
  %3171 = add i64 %3119, -72
  %3172 = add i64 %3121, 36
  store i64 %3172, i64* %PC, align 8
  %3173 = inttoptr i64 %3171 to i64*
  store i64 %3160, i64* %3173, align 8
  %3174 = load i64, i64* %RBP, align 8
  %3175 = add i64 %3174, -24
  %3176 = load i64, i64* %PC, align 8
  %3177 = add i64 %3176, 4
  store i64 %3177, i64* %PC, align 8
  %3178 = inttoptr i64 %3175 to i64*
  %3179 = load i64, i64* %3178, align 8
  store i64 %3179, i64* %RDX, align 8, !tbaa !2428
  %3180 = add i64 %3174, -40
  %3181 = add i64 %3176, 8
  store i64 %3181, i64* %PC, align 8
  %3182 = inttoptr i64 %3180 to i32*
  %3183 = load i32, i32* %3182, align 4
  %3184 = sext i32 %3183 to i64
  store i64 %3184, i64* %RSI, align 8, !tbaa !2428
  %3185 = shl nsw i64 %3184, 3
  %3186 = add i64 %3185, %3179
  %3187 = add i64 %3176, 13
  store i64 %3187, i64* %PC, align 8
  %3188 = inttoptr i64 %3186 to i64*
  %3189 = load i64, i64* %3188, align 8
  %3190 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3189, i64* %3190, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3827, align 1, !tbaa !2452
  %3191 = add i64 %3174, -80
  %3192 = add i64 %3176, 18
  store i64 %3192, i64* %PC, align 8
  %3193 = inttoptr i64 %3191 to i64*
  store i64 %3189, i64* %3193, align 8
  %3194 = load i64, i64* %RBP, align 8
  %3195 = add i64 %3194, -24
  %3196 = load i64, i64* %PC, align 8
  %3197 = add i64 %3196, 4
  store i64 %3197, i64* %PC, align 8
  %3198 = inttoptr i64 %3195 to i64*
  %3199 = load i64, i64* %3198, align 8
  store i64 %3199, i64* %RDX, align 8, !tbaa !2428
  %3200 = add i64 %3194, -40
  %3201 = add i64 %3196, 7
  store i64 %3201, i64* %PC, align 8
  %3202 = inttoptr i64 %3200 to i32*
  %3203 = load i32, i32* %3202, align 4
  %3204 = add i32 %3203, 1
  %3205 = zext i32 %3204 to i64
  store i64 %3205, i64* %RCX, align 8, !tbaa !2428
  %3206 = icmp eq i32 %3203, -1
  %3207 = icmp eq i32 %3204, 0
  %3208 = or i1 %3206, %3207
  %3209 = zext i1 %3208 to i8
  store i8 %3209, i8* %51, align 1, !tbaa !2433
  %3210 = and i32 %3204, 255
  %3211 = tail call i32 @llvm.ctpop.i32(i32 %3210) #10
  %3212 = trunc i32 %3211 to i8
  %3213 = and i8 %3212, 1
  %3214 = xor i8 %3213, 1
  store i8 %3214, i8* %52, align 1, !tbaa !2447
  %3215 = xor i32 %3203, %3204
  %3216 = lshr i32 %3215, 4
  %3217 = trunc i32 %3216 to i8
  %3218 = and i8 %3217, 1
  store i8 %3218, i8* %53, align 1, !tbaa !2451
  %3219 = icmp eq i32 %3204, 0
  %3220 = zext i1 %3219 to i8
  store i8 %3220, i8* %54, align 1, !tbaa !2448
  %3221 = lshr i32 %3204, 31
  %3222 = trunc i32 %3221 to i8
  store i8 %3222, i8* %55, align 1, !tbaa !2449
  %3223 = lshr i32 %3203, 31
  %3224 = xor i32 %3221, %3223
  %3225 = add nuw nsw i32 %3224, %3221
  %3226 = icmp eq i32 %3225, 2
  %3227 = zext i1 %3226 to i8
  store i8 %3227, i8* %56, align 1, !tbaa !2450
  %3228 = sext i32 %3204 to i64
  store i64 %3228, i64* %RSI, align 8, !tbaa !2428
  %3229 = shl nsw i64 %3228, 3
  %3230 = add i64 %3229, %3199
  %3231 = add i64 %3196, 18
  store i64 %3231, i64* %PC, align 8
  %3232 = inttoptr i64 %3230 to i64*
  %3233 = load i64, i64* %3232, align 8
  %3234 = load i64, i64* %RAX, align 8
  %3235 = xor i64 %3234, %3233
  store i64 %3235, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %3236 = trunc i64 %3235 to i32
  %3237 = and i32 %3236, 255
  %3238 = tail call i32 @llvm.ctpop.i32(i32 %3237) #10
  %3239 = trunc i32 %3238 to i8
  %3240 = and i8 %3239, 1
  %3241 = xor i8 %3240, 1
  store i8 %3241, i8* %52, align 1, !tbaa !2447
  %3242 = icmp eq i64 %3235, 0
  %3243 = zext i1 %3242 to i8
  store i8 %3243, i8* %54, align 1, !tbaa !2448
  %3244 = lshr i64 %3235, 63
  %3245 = trunc i64 %3244 to i8
  store i8 %3245, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %3235, i64* %3839, align 1, !tbaa !2428
  store i64 0, i64* %3826, align 1, !tbaa !2428
  %3246 = add i64 %3194, -88
  %3247 = add i64 %3196, 36
  store i64 %3247, i64* %PC, align 8
  %3248 = inttoptr i64 %3246 to i64*
  store i64 %3235, i64* %3248, align 8
  %3249 = load i64, i64* %RBP, align 8
  %3250 = add i64 %3249, -80
  %3251 = load i64, i64* %PC, align 8
  %3252 = add i64 %3251, 5
  store i64 %3252, i64* %PC, align 8
  %3253 = inttoptr i64 %3250 to i64*
  %3254 = load i64, i64* %3253, align 8
  %3255 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3254, i64* %3255, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3827, align 1, !tbaa !2452
  %3256 = add i64 %3249, -24
  %3257 = add i64 %3251, 9
  store i64 %3257, i64* %PC, align 8
  %3258 = inttoptr i64 %3256 to i64*
  %3259 = load i64, i64* %3258, align 8
  store i64 %3259, i64* %RDX, align 8, !tbaa !2428
  %3260 = add i64 %3249, -32
  %3261 = add i64 %3251, 13
  store i64 %3261, i64* %PC, align 8
  %3262 = inttoptr i64 %3260 to i32*
  %3263 = load i32, i32* %3262, align 4
  %3264 = sext i32 %3263 to i64
  store i64 %3264, i64* %RSI, align 8, !tbaa !2428
  %3265 = shl nsw i64 %3264, 3
  %3266 = add i64 %3265, %3259
  %3267 = add i64 %3251, 18
  store i64 %3267, i64* %PC, align 8
  %3268 = inttoptr i64 %3266 to i64*
  store i64 %3254, i64* %3268, align 8
  %3269 = load i64, i64* %RBP, align 8
  %3270 = add i64 %3269, -88
  %3271 = load i64, i64* %PC, align 8
  %3272 = add i64 %3271, 5
  store i64 %3272, i64* %PC, align 8
  %3273 = inttoptr i64 %3270 to i64*
  %3274 = load i64, i64* %3273, align 8
  %3275 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3274, i64* %3275, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3827, align 1, !tbaa !2452
  %3276 = add i64 %3269, -24
  %3277 = add i64 %3271, 9
  store i64 %3277, i64* %PC, align 8
  %3278 = inttoptr i64 %3276 to i64*
  %3279 = load i64, i64* %3278, align 8
  store i64 %3279, i64* %RDX, align 8, !tbaa !2428
  %3280 = add i64 %3269, -32
  %3281 = add i64 %3271, 12
  store i64 %3281, i64* %PC, align 8
  %3282 = inttoptr i64 %3280 to i32*
  %3283 = load i32, i32* %3282, align 4
  %3284 = add i32 %3283, 1
  %3285 = zext i32 %3284 to i64
  store i64 %3285, i64* %RCX, align 8, !tbaa !2428
  %3286 = icmp eq i32 %3283, -1
  %3287 = icmp eq i32 %3284, 0
  %3288 = or i1 %3286, %3287
  %3289 = zext i1 %3288 to i8
  store i8 %3289, i8* %51, align 1, !tbaa !2433
  %3290 = and i32 %3284, 255
  %3291 = tail call i32 @llvm.ctpop.i32(i32 %3290) #10
  %3292 = trunc i32 %3291 to i8
  %3293 = and i8 %3292, 1
  %3294 = xor i8 %3293, 1
  store i8 %3294, i8* %52, align 1, !tbaa !2447
  %3295 = xor i32 %3283, %3284
  %3296 = lshr i32 %3295, 4
  %3297 = trunc i32 %3296 to i8
  %3298 = and i8 %3297, 1
  store i8 %3298, i8* %53, align 1, !tbaa !2451
  %3299 = icmp eq i32 %3284, 0
  %3300 = zext i1 %3299 to i8
  store i8 %3300, i8* %54, align 1, !tbaa !2448
  %3301 = lshr i32 %3284, 31
  %3302 = trunc i32 %3301 to i8
  store i8 %3302, i8* %55, align 1, !tbaa !2449
  %3303 = lshr i32 %3283, 31
  %3304 = xor i32 %3301, %3303
  %3305 = add nuw nsw i32 %3304, %3301
  %3306 = icmp eq i32 %3305, 2
  %3307 = zext i1 %3306 to i8
  store i8 %3307, i8* %56, align 1, !tbaa !2450
  %3308 = sext i32 %3284 to i64
  store i64 %3308, i64* %RSI, align 8, !tbaa !2428
  %3309 = shl nsw i64 %3308, 3
  %3310 = add i64 %3309, %3279
  %3311 = add i64 %3271, 23
  store i64 %3311, i64* %PC, align 8
  %3312 = inttoptr i64 %3310 to i64*
  store i64 %3274, i64* %3312, align 8
  %3313 = load i64, i64* %RBP, align 8
  %3314 = add i64 %3313, -64
  %3315 = load i64, i64* %PC, align 8
  %3316 = add i64 %3315, 5
  store i64 %3316, i64* %PC, align 8
  %3317 = inttoptr i64 %3314 to i64*
  %3318 = load i64, i64* %3317, align 8
  %3319 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3318, i64* %3319, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3827, align 1, !tbaa !2452
  %3320 = add i64 %3313, -24
  %3321 = add i64 %3315, 9
  store i64 %3321, i64* %PC, align 8
  %3322 = inttoptr i64 %3320 to i64*
  %3323 = load i64, i64* %3322, align 8
  store i64 %3323, i64* %RDX, align 8, !tbaa !2428
  %3324 = add i64 %3313, -40
  %3325 = add i64 %3315, 13
  store i64 %3325, i64* %PC, align 8
  %3326 = inttoptr i64 %3324 to i32*
  %3327 = load i32, i32* %3326, align 4
  %3328 = sext i32 %3327 to i64
  store i64 %3328, i64* %RSI, align 8, !tbaa !2428
  %3329 = shl nsw i64 %3328, 3
  %3330 = add i64 %3329, %3323
  %3331 = add i64 %3315, 18
  store i64 %3331, i64* %PC, align 8
  %3332 = inttoptr i64 %3330 to i64*
  store i64 %3318, i64* %3332, align 8
  %3333 = load i64, i64* %RBP, align 8
  %3334 = add i64 %3333, -72
  %3335 = load i64, i64* %PC, align 8
  %3336 = add i64 %3335, 5
  store i64 %3336, i64* %PC, align 8
  %3337 = inttoptr i64 %3334 to i64*
  %3338 = load i64, i64* %3337, align 8
  %3339 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3338, i64* %3339, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3827, align 1, !tbaa !2452
  %3340 = add i64 %3333, -24
  %3341 = add i64 %3335, 9
  store i64 %3341, i64* %PC, align 8
  %3342 = inttoptr i64 %3340 to i64*
  %3343 = load i64, i64* %3342, align 8
  store i64 %3343, i64* %RDX, align 8, !tbaa !2428
  %3344 = add i64 %3333, -40
  %3345 = add i64 %3335, 12
  store i64 %3345, i64* %PC, align 8
  %3346 = inttoptr i64 %3344 to i32*
  %3347 = load i32, i32* %3346, align 4
  %3348 = add i32 %3347, 1
  %3349 = zext i32 %3348 to i64
  store i64 %3349, i64* %RCX, align 8, !tbaa !2428
  %3350 = icmp eq i32 %3347, -1
  %3351 = icmp eq i32 %3348, 0
  %3352 = or i1 %3350, %3351
  %3353 = zext i1 %3352 to i8
  store i8 %3353, i8* %51, align 1, !tbaa !2433
  %3354 = and i32 %3348, 255
  %3355 = tail call i32 @llvm.ctpop.i32(i32 %3354) #10
  %3356 = trunc i32 %3355 to i8
  %3357 = and i8 %3356, 1
  %3358 = xor i8 %3357, 1
  store i8 %3358, i8* %52, align 1, !tbaa !2447
  %3359 = xor i32 %3347, %3348
  %3360 = lshr i32 %3359, 4
  %3361 = trunc i32 %3360 to i8
  %3362 = and i8 %3361, 1
  store i8 %3362, i8* %53, align 1, !tbaa !2451
  %3363 = icmp eq i32 %3348, 0
  %3364 = zext i1 %3363 to i8
  store i8 %3364, i8* %54, align 1, !tbaa !2448
  %3365 = lshr i32 %3348, 31
  %3366 = trunc i32 %3365 to i8
  store i8 %3366, i8* %55, align 1, !tbaa !2449
  %3367 = lshr i32 %3347, 31
  %3368 = xor i32 %3365, %3367
  %3369 = add nuw nsw i32 %3368, %3365
  %3370 = icmp eq i32 %3369, 2
  %3371 = zext i1 %3370 to i8
  store i8 %3371, i8* %56, align 1, !tbaa !2450
  %3372 = sext i32 %3348 to i64
  store i64 %3372, i64* %RSI, align 8, !tbaa !2428
  %3373 = shl nsw i64 %3372, 3
  %3374 = add i64 %3373, %3343
  %3375 = add i64 %3335, 23
  store i64 %3375, i64* %PC, align 8
  %3376 = inttoptr i64 %3374 to i64*
  store i64 %3338, i64* %3376, align 8
  %3377 = load i64, i64* %RBP, align 8
  %3378 = add i64 %3377, -52
  %3379 = load i64, i64* %PC, align 8
  %3380 = add i64 %3379, 3
  store i64 %3380, i64* %PC, align 8
  %3381 = inttoptr i64 %3378 to i32*
  %3382 = load i32, i32* %3381, align 4
  %3383 = zext i32 %3382 to i64
  store i64 %3383, i64* %RCX, align 8, !tbaa !2428
  %3384 = add i64 %3377, -32
  %3385 = add i64 %3379, 6
  store i64 %3385, i64* %PC, align 8
  %3386 = inttoptr i64 %3384 to i32*
  %3387 = load i32, i32* %3386, align 4
  %3388 = add i32 %3387, %3382
  %3389 = zext i32 %3388 to i64
  store i64 %3389, i64* %RCX, align 8, !tbaa !2428
  %3390 = icmp ult i32 %3388, %3382
  %3391 = icmp ult i32 %3388, %3387
  %3392 = or i1 %3390, %3391
  %3393 = zext i1 %3392 to i8
  store i8 %3393, i8* %51, align 1, !tbaa !2433
  %3394 = and i32 %3388, 255
  %3395 = tail call i32 @llvm.ctpop.i32(i32 %3394) #10
  %3396 = trunc i32 %3395 to i8
  %3397 = and i8 %3396, 1
  %3398 = xor i8 %3397, 1
  store i8 %3398, i8* %52, align 1, !tbaa !2447
  %3399 = xor i32 %3387, %3382
  %3400 = xor i32 %3399, %3388
  %3401 = lshr i32 %3400, 4
  %3402 = trunc i32 %3401 to i8
  %3403 = and i8 %3402, 1
  store i8 %3403, i8* %53, align 1, !tbaa !2451
  %3404 = icmp eq i32 %3388, 0
  %3405 = zext i1 %3404 to i8
  store i8 %3405, i8* %54, align 1, !tbaa !2448
  %3406 = lshr i32 %3388, 31
  %3407 = trunc i32 %3406 to i8
  store i8 %3407, i8* %55, align 1, !tbaa !2449
  %3408 = lshr i32 %3382, 31
  %3409 = lshr i32 %3387, 31
  %3410 = xor i32 %3406, %3408
  %3411 = xor i32 %3406, %3409
  %3412 = add nuw nsw i32 %3410, %3411
  %3413 = icmp eq i32 %3412, 2
  %3414 = zext i1 %3413 to i8
  store i8 %3414, i8* %56, align 1, !tbaa !2450
  %3415 = add i64 %3379, 9
  store i64 %3415, i64* %PC, align 8
  store i32 %3388, i32* %3386, align 4
  %3416 = load i64, i64* %RBP, align 8
  %3417 = add i64 %3416, -52
  %3418 = load i64, i64* %PC, align 8
  %3419 = add i64 %3418, 3
  store i64 %3419, i64* %PC, align 8
  %3420 = inttoptr i64 %3417 to i32*
  %3421 = load i32, i32* %3420, align 4
  %3422 = zext i32 %3421 to i64
  store i64 %3422, i64* %RCX, align 8, !tbaa !2428
  %3423 = add i64 %3416, -40
  %3424 = add i64 %3418, 6
  store i64 %3424, i64* %PC, align 8
  %3425 = inttoptr i64 %3423 to i32*
  %3426 = load i32, i32* %3425, align 4
  %3427 = add i32 %3426, %3421
  %3428 = zext i32 %3427 to i64
  store i64 %3428, i64* %RCX, align 8, !tbaa !2428
  %3429 = icmp ult i32 %3427, %3421
  %3430 = icmp ult i32 %3427, %3426
  %3431 = or i1 %3429, %3430
  %3432 = zext i1 %3431 to i8
  store i8 %3432, i8* %51, align 1, !tbaa !2433
  %3433 = and i32 %3427, 255
  %3434 = tail call i32 @llvm.ctpop.i32(i32 %3433) #10
  %3435 = trunc i32 %3434 to i8
  %3436 = and i8 %3435, 1
  %3437 = xor i8 %3436, 1
  store i8 %3437, i8* %52, align 1, !tbaa !2447
  %3438 = xor i32 %3426, %3421
  %3439 = xor i32 %3438, %3427
  %3440 = lshr i32 %3439, 4
  %3441 = trunc i32 %3440 to i8
  %3442 = and i8 %3441, 1
  store i8 %3442, i8* %53, align 1, !tbaa !2451
  %3443 = icmp eq i32 %3427, 0
  %3444 = zext i1 %3443 to i8
  store i8 %3444, i8* %54, align 1, !tbaa !2448
  %3445 = lshr i32 %3427, 31
  %3446 = trunc i32 %3445 to i8
  store i8 %3446, i8* %55, align 1, !tbaa !2449
  %3447 = lshr i32 %3421, 31
  %3448 = lshr i32 %3426, 31
  %3449 = xor i32 %3445, %3447
  %3450 = xor i32 %3445, %3448
  %3451 = add nuw nsw i32 %3449, %3450
  %3452 = icmp eq i32 %3451, 2
  %3453 = zext i1 %3452 to i8
  store i8 %3453, i8* %56, align 1, !tbaa !2450
  %3454 = add i64 %3418, 9
  store i64 %3454, i64* %PC, align 8
  store i32 %3427, i32* %3425, align 4
  %3455 = load i64, i64* %RBP, align 8
  %3456 = add i64 %3455, -24
  %3457 = load i64, i64* %PC, align 8
  %3458 = add i64 %3457, 4
  store i64 %3458, i64* %PC, align 8
  %3459 = inttoptr i64 %3456 to i64*
  %3460 = load i64, i64* %3459, align 8
  store i64 %3460, i64* %RDX, align 8, !tbaa !2428
  %3461 = add i64 %3455, -32
  %3462 = add i64 %3457, 8
  store i64 %3462, i64* %PC, align 8
  %3463 = inttoptr i64 %3461 to i32*
  %3464 = load i32, i32* %3463, align 4
  %3465 = sext i32 %3464 to i64
  store i64 %3465, i64* %RSI, align 8, !tbaa !2428
  %3466 = shl nsw i64 %3465, 3
  %3467 = add i64 %3466, %3460
  %3468 = add i64 %3457, 13
  store i64 %3468, i64* %PC, align 8
  %3469 = inttoptr i64 %3467 to i64*
  %3470 = load i64, i64* %3469, align 8
  %3471 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3470, i64* %3471, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3827, align 1, !tbaa !2452
  %3472 = add i64 %3455, -64
  %3473 = add i64 %3457, 18
  store i64 %3473, i64* %PC, align 8
  %3474 = inttoptr i64 %3472 to i64*
  store i64 %3470, i64* %3474, align 8
  %3475 = load i64, i64* %RBP, align 8
  %3476 = add i64 %3475, -24
  %3477 = load i64, i64* %PC, align 8
  %3478 = add i64 %3477, 4
  store i64 %3478, i64* %PC, align 8
  %3479 = inttoptr i64 %3476 to i64*
  %3480 = load i64, i64* %3479, align 8
  store i64 %3480, i64* %RDX, align 8, !tbaa !2428
  %3481 = add i64 %3475, -32
  %3482 = add i64 %3477, 7
  store i64 %3482, i64* %PC, align 8
  %3483 = inttoptr i64 %3481 to i32*
  %3484 = load i32, i32* %3483, align 4
  %3485 = add i32 %3484, 1
  %3486 = zext i32 %3485 to i64
  store i64 %3486, i64* %RCX, align 8, !tbaa !2428
  %3487 = icmp eq i32 %3484, -1
  %3488 = icmp eq i32 %3485, 0
  %3489 = or i1 %3487, %3488
  %3490 = zext i1 %3489 to i8
  store i8 %3490, i8* %51, align 1, !tbaa !2433
  %3491 = and i32 %3485, 255
  %3492 = tail call i32 @llvm.ctpop.i32(i32 %3491) #10
  %3493 = trunc i32 %3492 to i8
  %3494 = and i8 %3493, 1
  %3495 = xor i8 %3494, 1
  store i8 %3495, i8* %52, align 1, !tbaa !2447
  %3496 = xor i32 %3484, %3485
  %3497 = lshr i32 %3496, 4
  %3498 = trunc i32 %3497 to i8
  %3499 = and i8 %3498, 1
  store i8 %3499, i8* %53, align 1, !tbaa !2451
  %3500 = icmp eq i32 %3485, 0
  %3501 = zext i1 %3500 to i8
  store i8 %3501, i8* %54, align 1, !tbaa !2448
  %3502 = lshr i32 %3485, 31
  %3503 = trunc i32 %3502 to i8
  store i8 %3503, i8* %55, align 1, !tbaa !2449
  %3504 = lshr i32 %3484, 31
  %3505 = xor i32 %3502, %3504
  %3506 = add nuw nsw i32 %3505, %3502
  %3507 = icmp eq i32 %3506, 2
  %3508 = zext i1 %3507 to i8
  store i8 %3508, i8* %56, align 1, !tbaa !2450
  %3509 = sext i32 %3485 to i64
  store i64 %3509, i64* %RSI, align 8, !tbaa !2428
  %3510 = shl nsw i64 %3509, 3
  %3511 = add i64 %3510, %3480
  %3512 = add i64 %3477, 18
  store i64 %3512, i64* %PC, align 8
  %3513 = inttoptr i64 %3511 to i64*
  %3514 = load i64, i64* %3513, align 8
  %3515 = load i64, i64* %RAX, align 8
  %3516 = xor i64 %3515, %3514
  store i64 %3516, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %3517 = trunc i64 %3516 to i32
  %3518 = and i32 %3517, 255
  %3519 = tail call i32 @llvm.ctpop.i32(i32 %3518) #10
  %3520 = trunc i32 %3519 to i8
  %3521 = and i8 %3520, 1
  %3522 = xor i8 %3521, 1
  store i8 %3522, i8* %52, align 1, !tbaa !2447
  %3523 = icmp eq i64 %3516, 0
  %3524 = zext i1 %3523 to i8
  store i8 %3524, i8* %54, align 1, !tbaa !2448
  %3525 = lshr i64 %3516, 63
  %3526 = trunc i64 %3525 to i8
  store i8 %3526, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %3516, i64* %3839, align 1, !tbaa !2428
  store i64 0, i64* %3826, align 1, !tbaa !2428
  %3527 = add i64 %3475, -72
  %3528 = add i64 %3477, 36
  store i64 %3528, i64* %PC, align 8
  %3529 = inttoptr i64 %3527 to i64*
  store i64 %3516, i64* %3529, align 8
  %3530 = load i64, i64* %RBP, align 8
  %3531 = add i64 %3530, -24
  %3532 = load i64, i64* %PC, align 8
  %3533 = add i64 %3532, 4
  store i64 %3533, i64* %PC, align 8
  %3534 = inttoptr i64 %3531 to i64*
  %3535 = load i64, i64* %3534, align 8
  store i64 %3535, i64* %RDX, align 8, !tbaa !2428
  %3536 = add i64 %3530, -40
  %3537 = add i64 %3532, 8
  store i64 %3537, i64* %PC, align 8
  %3538 = inttoptr i64 %3536 to i32*
  %3539 = load i32, i32* %3538, align 4
  %3540 = sext i32 %3539 to i64
  store i64 %3540, i64* %RSI, align 8, !tbaa !2428
  %3541 = shl nsw i64 %3540, 3
  %3542 = add i64 %3541, %3535
  %3543 = add i64 %3532, 13
  store i64 %3543, i64* %PC, align 8
  %3544 = inttoptr i64 %3542 to i64*
  %3545 = load i64, i64* %3544, align 8
  %3546 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3545, i64* %3546, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3827, align 1, !tbaa !2452
  %3547 = add i64 %3530, -80
  %3548 = add i64 %3532, 18
  store i64 %3548, i64* %PC, align 8
  %3549 = inttoptr i64 %3547 to i64*
  store i64 %3545, i64* %3549, align 8
  %3550 = load i64, i64* %RBP, align 8
  %3551 = add i64 %3550, -24
  %3552 = load i64, i64* %PC, align 8
  %3553 = add i64 %3552, 4
  store i64 %3553, i64* %PC, align 8
  %3554 = inttoptr i64 %3551 to i64*
  %3555 = load i64, i64* %3554, align 8
  store i64 %3555, i64* %RDX, align 8, !tbaa !2428
  %3556 = add i64 %3550, -40
  %3557 = add i64 %3552, 7
  store i64 %3557, i64* %PC, align 8
  %3558 = inttoptr i64 %3556 to i32*
  %3559 = load i32, i32* %3558, align 4
  %3560 = add i32 %3559, 1
  %3561 = zext i32 %3560 to i64
  store i64 %3561, i64* %RCX, align 8, !tbaa !2428
  %3562 = icmp eq i32 %3559, -1
  %3563 = icmp eq i32 %3560, 0
  %3564 = or i1 %3562, %3563
  %3565 = zext i1 %3564 to i8
  store i8 %3565, i8* %51, align 1, !tbaa !2433
  %3566 = and i32 %3560, 255
  %3567 = tail call i32 @llvm.ctpop.i32(i32 %3566) #10
  %3568 = trunc i32 %3567 to i8
  %3569 = and i8 %3568, 1
  %3570 = xor i8 %3569, 1
  store i8 %3570, i8* %52, align 1, !tbaa !2447
  %3571 = xor i32 %3559, %3560
  %3572 = lshr i32 %3571, 4
  %3573 = trunc i32 %3572 to i8
  %3574 = and i8 %3573, 1
  store i8 %3574, i8* %53, align 1, !tbaa !2451
  %3575 = icmp eq i32 %3560, 0
  %3576 = zext i1 %3575 to i8
  store i8 %3576, i8* %54, align 1, !tbaa !2448
  %3577 = lshr i32 %3560, 31
  %3578 = trunc i32 %3577 to i8
  store i8 %3578, i8* %55, align 1, !tbaa !2449
  %3579 = lshr i32 %3559, 31
  %3580 = xor i32 %3577, %3579
  %3581 = add nuw nsw i32 %3580, %3577
  %3582 = icmp eq i32 %3581, 2
  %3583 = zext i1 %3582 to i8
  store i8 %3583, i8* %56, align 1, !tbaa !2450
  %3584 = sext i32 %3560 to i64
  store i64 %3584, i64* %RSI, align 8, !tbaa !2428
  %3585 = shl nsw i64 %3584, 3
  %3586 = add i64 %3585, %3555
  %3587 = add i64 %3552, 18
  store i64 %3587, i64* %PC, align 8
  %3588 = inttoptr i64 %3586 to i64*
  %3589 = load i64, i64* %3588, align 8
  %3590 = load i64, i64* %RAX, align 8
  %3591 = xor i64 %3590, %3589
  store i64 %3591, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %3592 = trunc i64 %3591 to i32
  %3593 = and i32 %3592, 255
  %3594 = tail call i32 @llvm.ctpop.i32(i32 %3593) #10
  %3595 = trunc i32 %3594 to i8
  %3596 = and i8 %3595, 1
  %3597 = xor i8 %3596, 1
  store i8 %3597, i8* %52, align 1, !tbaa !2447
  %3598 = icmp eq i64 %3591, 0
  %3599 = zext i1 %3598 to i8
  store i8 %3599, i8* %54, align 1, !tbaa !2448
  %3600 = lshr i64 %3591, 63
  %3601 = trunc i64 %3600 to i8
  store i8 %3601, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %3591, i64* %3839, align 1, !tbaa !2428
  store i64 0, i64* %3826, align 1, !tbaa !2428
  %3602 = add i64 %3550, -88
  %3603 = add i64 %3552, 36
  store i64 %3603, i64* %PC, align 8
  %3604 = inttoptr i64 %3602 to i64*
  store i64 %3591, i64* %3604, align 8
  %3605 = load i64, i64* %RBP, align 8
  %3606 = add i64 %3605, -80
  %3607 = load i64, i64* %PC, align 8
  %3608 = add i64 %3607, 5
  store i64 %3608, i64* %PC, align 8
  %3609 = inttoptr i64 %3606 to i64*
  %3610 = load i64, i64* %3609, align 8
  %3611 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3610, i64* %3611, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3827, align 1, !tbaa !2452
  %3612 = add i64 %3605, -24
  %3613 = add i64 %3607, 9
  store i64 %3613, i64* %PC, align 8
  %3614 = inttoptr i64 %3612 to i64*
  %3615 = load i64, i64* %3614, align 8
  store i64 %3615, i64* %RAX, align 8, !tbaa !2428
  %3616 = add i64 %3605, -32
  %3617 = add i64 %3607, 13
  store i64 %3617, i64* %PC, align 8
  %3618 = inttoptr i64 %3616 to i32*
  %3619 = load i32, i32* %3618, align 4
  %3620 = sext i32 %3619 to i64
  store i64 %3620, i64* %RDX, align 8, !tbaa !2428
  %3621 = shl nsw i64 %3620, 3
  %3622 = add i64 %3621, %3615
  %3623 = add i64 %3607, 18
  store i64 %3623, i64* %PC, align 8
  %3624 = inttoptr i64 %3622 to i64*
  store i64 %3610, i64* %3624, align 8
  %3625 = load i64, i64* %RBP, align 8
  %3626 = add i64 %3625, -88
  %3627 = load i64, i64* %PC, align 8
  %3628 = add i64 %3627, 5
  store i64 %3628, i64* %PC, align 8
  %3629 = inttoptr i64 %3626 to i64*
  %3630 = load i64, i64* %3629, align 8
  %3631 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3630, i64* %3631, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3827, align 1, !tbaa !2452
  %3632 = add i64 %3625, -24
  %3633 = add i64 %3627, 9
  store i64 %3633, i64* %PC, align 8
  %3634 = inttoptr i64 %3632 to i64*
  %3635 = load i64, i64* %3634, align 8
  store i64 %3635, i64* %RAX, align 8, !tbaa !2428
  %3636 = add i64 %3625, -32
  %3637 = add i64 %3627, 12
  store i64 %3637, i64* %PC, align 8
  %3638 = inttoptr i64 %3636 to i32*
  %3639 = load i32, i32* %3638, align 4
  %3640 = add i32 %3639, 1
  %3641 = zext i32 %3640 to i64
  store i64 %3641, i64* %RCX, align 8, !tbaa !2428
  %3642 = icmp eq i32 %3639, -1
  %3643 = icmp eq i32 %3640, 0
  %3644 = or i1 %3642, %3643
  %3645 = zext i1 %3644 to i8
  store i8 %3645, i8* %51, align 1, !tbaa !2433
  %3646 = and i32 %3640, 255
  %3647 = tail call i32 @llvm.ctpop.i32(i32 %3646) #10
  %3648 = trunc i32 %3647 to i8
  %3649 = and i8 %3648, 1
  %3650 = xor i8 %3649, 1
  store i8 %3650, i8* %52, align 1, !tbaa !2447
  %3651 = xor i32 %3639, %3640
  %3652 = lshr i32 %3651, 4
  %3653 = trunc i32 %3652 to i8
  %3654 = and i8 %3653, 1
  store i8 %3654, i8* %53, align 1, !tbaa !2451
  %3655 = icmp eq i32 %3640, 0
  %3656 = zext i1 %3655 to i8
  store i8 %3656, i8* %54, align 1, !tbaa !2448
  %3657 = lshr i32 %3640, 31
  %3658 = trunc i32 %3657 to i8
  store i8 %3658, i8* %55, align 1, !tbaa !2449
  %3659 = lshr i32 %3639, 31
  %3660 = xor i32 %3657, %3659
  %3661 = add nuw nsw i32 %3660, %3657
  %3662 = icmp eq i32 %3661, 2
  %3663 = zext i1 %3662 to i8
  store i8 %3663, i8* %56, align 1, !tbaa !2450
  %3664 = sext i32 %3640 to i64
  store i64 %3664, i64* %RDX, align 8, !tbaa !2428
  %3665 = shl nsw i64 %3664, 3
  %3666 = add i64 %3665, %3635
  %3667 = add i64 %3627, 23
  store i64 %3667, i64* %PC, align 8
  %3668 = inttoptr i64 %3666 to i64*
  store i64 %3630, i64* %3668, align 8
  %3669 = load i64, i64* %RBP, align 8
  %3670 = add i64 %3669, -64
  %3671 = load i64, i64* %PC, align 8
  %3672 = add i64 %3671, 5
  store i64 %3672, i64* %PC, align 8
  %3673 = inttoptr i64 %3670 to i64*
  %3674 = load i64, i64* %3673, align 8
  %3675 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3674, i64* %3675, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3827, align 1, !tbaa !2452
  %3676 = add i64 %3669, -24
  %3677 = add i64 %3671, 9
  store i64 %3677, i64* %PC, align 8
  %3678 = inttoptr i64 %3676 to i64*
  %3679 = load i64, i64* %3678, align 8
  store i64 %3679, i64* %RAX, align 8, !tbaa !2428
  %3680 = add i64 %3669, -40
  %3681 = add i64 %3671, 13
  store i64 %3681, i64* %PC, align 8
  %3682 = inttoptr i64 %3680 to i32*
  %3683 = load i32, i32* %3682, align 4
  %3684 = sext i32 %3683 to i64
  store i64 %3684, i64* %RDX, align 8, !tbaa !2428
  %3685 = shl nsw i64 %3684, 3
  %3686 = add i64 %3685, %3679
  %3687 = add i64 %3671, 18
  store i64 %3687, i64* %PC, align 8
  %3688 = inttoptr i64 %3686 to i64*
  store i64 %3674, i64* %3688, align 8
  %3689 = load i64, i64* %RBP, align 8
  %3690 = add i64 %3689, -72
  %3691 = load i64, i64* %PC, align 8
  %3692 = add i64 %3691, 5
  store i64 %3692, i64* %PC, align 8
  %3693 = inttoptr i64 %3690 to i64*
  %3694 = load i64, i64* %3693, align 8
  %3695 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3694, i64* %3695, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3827, align 1, !tbaa !2452
  %3696 = add i64 %3689, -24
  %3697 = add i64 %3691, 9
  store i64 %3697, i64* %PC, align 8
  %3698 = inttoptr i64 %3696 to i64*
  %3699 = load i64, i64* %3698, align 8
  store i64 %3699, i64* %RAX, align 8, !tbaa !2428
  %3700 = add i64 %3689, -40
  %3701 = add i64 %3691, 12
  store i64 %3701, i64* %PC, align 8
  %3702 = inttoptr i64 %3700 to i32*
  %3703 = load i32, i32* %3702, align 4
  %3704 = add i32 %3703, 1
  %3705 = zext i32 %3704 to i64
  store i64 %3705, i64* %RCX, align 8, !tbaa !2428
  %3706 = icmp eq i32 %3703, -1
  %3707 = icmp eq i32 %3704, 0
  %3708 = or i1 %3706, %3707
  %3709 = zext i1 %3708 to i8
  store i8 %3709, i8* %51, align 1, !tbaa !2433
  %3710 = and i32 %3704, 255
  %3711 = tail call i32 @llvm.ctpop.i32(i32 %3710) #10
  %3712 = trunc i32 %3711 to i8
  %3713 = and i8 %3712, 1
  %3714 = xor i8 %3713, 1
  store i8 %3714, i8* %52, align 1, !tbaa !2447
  %3715 = xor i32 %3703, %3704
  %3716 = lshr i32 %3715, 4
  %3717 = trunc i32 %3716 to i8
  %3718 = and i8 %3717, 1
  store i8 %3718, i8* %53, align 1, !tbaa !2451
  %3719 = icmp eq i32 %3704, 0
  %3720 = zext i1 %3719 to i8
  store i8 %3720, i8* %54, align 1, !tbaa !2448
  %3721 = lshr i32 %3704, 31
  %3722 = trunc i32 %3721 to i8
  store i8 %3722, i8* %55, align 1, !tbaa !2449
  %3723 = lshr i32 %3703, 31
  %3724 = xor i32 %3721, %3723
  %3725 = add nuw nsw i32 %3724, %3721
  %3726 = icmp eq i32 %3725, 2
  %3727 = zext i1 %3726 to i8
  store i8 %3727, i8* %56, align 1, !tbaa !2450
  %3728 = sext i32 %3704 to i64
  store i64 %3728, i64* %RDX, align 8, !tbaa !2428
  %3729 = shl nsw i64 %3728, 3
  %3730 = add i64 %3729, %3699
  %3731 = add i64 %3691, 23
  store i64 %3731, i64* %PC, align 8
  %3732 = inttoptr i64 %3730 to i64*
  store i64 %3694, i64* %3732, align 8
  %3733 = load i64, i64* %RBP, align 8
  %3734 = add i64 %3733, -28
  %3735 = load i64, i64* %PC, align 8
  %3736 = add i64 %3735, 3
  store i64 %3736, i64* %PC, align 8
  %3737 = inttoptr i64 %3734 to i32*
  %3738 = load i32, i32* %3737, align 4
  %3739 = add i32 %3738, 1
  %3740 = zext i32 %3739 to i64
  store i64 %3740, i64* %RAX, align 8, !tbaa !2428
  %3741 = icmp eq i32 %3738, -1
  %3742 = icmp eq i32 %3739, 0
  %3743 = or i1 %3741, %3742
  %3744 = zext i1 %3743 to i8
  store i8 %3744, i8* %51, align 1, !tbaa !2433
  %3745 = and i32 %3739, 255
  %3746 = tail call i32 @llvm.ctpop.i32(i32 %3745) #10
  %3747 = trunc i32 %3746 to i8
  %3748 = and i8 %3747, 1
  %3749 = xor i8 %3748, 1
  store i8 %3749, i8* %52, align 1, !tbaa !2447
  %3750 = xor i32 %3738, %3739
  %3751 = lshr i32 %3750, 4
  %3752 = trunc i32 %3751 to i8
  %3753 = and i8 %3752, 1
  store i8 %3753, i8* %53, align 1, !tbaa !2451
  %3754 = icmp eq i32 %3739, 0
  %3755 = zext i1 %3754 to i8
  store i8 %3755, i8* %54, align 1, !tbaa !2448
  %3756 = lshr i32 %3739, 31
  %3757 = trunc i32 %3756 to i8
  store i8 %3757, i8* %55, align 1, !tbaa !2449
  %3758 = lshr i32 %3738, 31
  %3759 = xor i32 %3756, %3758
  %3760 = add nuw nsw i32 %3759, %3756
  %3761 = icmp eq i32 %3760, 2
  %3762 = zext i1 %3761 to i8
  store i8 %3762, i8* %56, align 1, !tbaa !2450
  %3763 = add i64 %3735, 9
  store i64 %3763, i64* %PC, align 8
  store i32 %3739, i32* %3737, align 4
  %3764 = load i64, i64* %PC, align 8
  %3765 = add i64 %3764, -469
  store i64 %3765, i64* %57, align 8, !tbaa !2428
  br label %block_4021ff

block_401c06:                                     ; preds = %block_401c5d, %block_401be0
  %3766 = phi i64 [ %192, %block_401c5d ], [ %.pre, %block_401be0 ]
  %3767 = load i64, i64* %RBP, align 8
  %3768 = add i64 %3767, -48
  %3769 = add i64 %3766, 3
  store i64 %3769, i64* %PC, align 8
  %3770 = inttoptr i64 %3768 to i32*
  %3771 = load i32, i32* %3770, align 4
  %3772 = shl i32 %3771, 3
  %3773 = zext i32 %3772 to i64
  store i64 %3773, i64* %RAX, align 8, !tbaa !2428
  %3774 = lshr i32 %3771, 29
  %3775 = trunc i32 %3774 to i8
  %3776 = and i8 %3775, 1
  store i8 %3776, i8* %51, align 1, !tbaa !2432
  %3777 = and i32 %3772, 248
  %3778 = tail call i32 @llvm.ctpop.i32(i32 %3777) #10
  %3779 = trunc i32 %3778 to i8
  %3780 = and i8 %3779, 1
  %3781 = xor i8 %3780, 1
  store i8 %3781, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %3782 = icmp eq i32 %3772, 0
  %3783 = zext i1 %3782 to i8
  store i8 %3783, i8* %54, align 1, !tbaa !2432
  %3784 = lshr i32 %3771, 28
  %3785 = and i32 %3784, 1
  %3786 = trunc i32 %3785 to i8
  store i8 %3786, i8* %55, align 1, !tbaa !2432
  store i8 0, i8* %56, align 1, !tbaa !2432
  %3787 = add i64 %3767, -44
  %3788 = add i64 %3766, 9
  store i64 %3788, i64* %PC, align 8
  %3789 = inttoptr i64 %3787 to i32*
  %3790 = load i32, i32* %3789, align 4
  %3791 = sub i32 %3772, %3790
  %3792 = icmp ult i32 %3772, %3790
  %3793 = zext i1 %3792 to i8
  store i8 %3793, i8* %51, align 1, !tbaa !2433
  %3794 = and i32 %3791, 255
  %3795 = tail call i32 @llvm.ctpop.i32(i32 %3794) #10
  %3796 = trunc i32 %3795 to i8
  %3797 = and i8 %3796, 1
  %3798 = xor i8 %3797, 1
  store i8 %3798, i8* %52, align 1, !tbaa !2447
  %3799 = xor i32 %3790, %3772
  %3800 = xor i32 %3799, %3791
  %3801 = lshr i32 %3800, 4
  %3802 = trunc i32 %3801 to i8
  %3803 = and i8 %3802, 1
  store i8 %3803, i8* %53, align 1, !tbaa !2451
  %3804 = icmp eq i32 %3791, 0
  %3805 = zext i1 %3804 to i8
  store i8 %3805, i8* %54, align 1, !tbaa !2448
  %3806 = lshr i32 %3791, 31
  %3807 = trunc i32 %3806 to i8
  store i8 %3807, i8* %55, align 1, !tbaa !2449
  %3808 = lshr i32 %3790, 31
  %3809 = xor i32 %3808, %3785
  %3810 = xor i32 %3806, %3785
  %3811 = add nuw nsw i32 %3810, %3809
  %3812 = icmp eq i32 %3811, 2
  %3813 = zext i1 %3812 to i8
  store i8 %3813, i8* %56, align 1, !tbaa !2450
  %3814 = icmp ne i8 %3807, 0
  %3815 = xor i1 %3814, %3812
  %.v = select i1 %3815, i64 15, i64 101
  %3816 = add i64 %3766, %.v
  %3817 = add i64 %3816, 3
  store i64 %3817, i64* %PC, align 8
  br i1 %3815, label %block_401c15, label %block_401c6b

block_40218b:                                     ; preds = %block_401c6b
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %3818 = add i64 %122, -24
  %3819 = add i64 %170, 14
  store i64 %3819, i64* %PC, align 8
  %3820 = inttoptr i64 %3818 to i64*
  %3821 = load i64, i64* %3820, align 8
  store i64 %3821, i64* %RCX, align 8, !tbaa !2428
  %3822 = add i64 %3821, 8
  %3823 = add i64 %170, 19
  store i64 %3823, i64* %PC, align 8
  %3824 = inttoptr i64 %3822 to i64*
  %3825 = load i64, i64* %3824, align 8
  %3826 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %3827 = bitcast i64* %3826 to double*
  %3828 = xor i64 %3825, -9223372036854775808
  store i64 %3828, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %3829 = trunc i64 %3825 to i32
  %3830 = and i32 %3829, 255
  %3831 = tail call i32 @llvm.ctpop.i32(i32 %3830) #10
  %3832 = trunc i32 %3831 to i8
  %3833 = and i8 %3832, 1
  %3834 = xor i8 %3833, 1
  store i8 %3834, i8* %52, align 1, !tbaa !2447
  %3835 = icmp eq i64 %3828, 0
  %3836 = zext i1 %3835 to i8
  store i8 %3836, i8* %54, align 1, !tbaa !2448
  %3837 = lshr i64 %3828, 63
  %3838 = trunc i64 %3837 to i8
  store i8 %3838, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  %3839 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3828, i64* %3839, align 1, !tbaa !2428
  store i64 0, i64* %3826, align 1, !tbaa !2428
  %3840 = add i64 %170, 36
  store i64 %3840, i64* %PC, align 8
  %3841 = load i64, i64* %3820, align 8
  store i64 %3841, i64* %RCX, align 8, !tbaa !2428
  %3842 = add i64 %3841, 8
  %3843 = add i64 %170, 41
  store i64 %3843, i64* %PC, align 8
  %3844 = inttoptr i64 %3842 to i64*
  store i64 %3828, i64* %3844, align 8
  %3845 = load i64, i64* %RBP, align 8
  %3846 = add i64 %3845, -24
  %3847 = load i64, i64* %PC, align 8
  %3848 = add i64 %3847, 4
  store i64 %3848, i64* %PC, align 8
  %3849 = inttoptr i64 %3846 to i64*
  %3850 = load i64, i64* %3849, align 8
  store i64 %3850, i64* %RCX, align 8, !tbaa !2428
  %3851 = add i64 %3845, -52
  %3852 = add i64 %3847, 7
  store i64 %3852, i64* %PC, align 8
  %3853 = inttoptr i64 %3851 to i32*
  %3854 = load i32, i32* %3853, align 4
  %3855 = add i32 %3854, 1
  %3856 = zext i32 %3855 to i64
  store i64 %3856, i64* %RDX, align 8, !tbaa !2428
  %3857 = icmp eq i32 %3854, -1
  %3858 = icmp eq i32 %3855, 0
  %3859 = or i1 %3857, %3858
  %3860 = zext i1 %3859 to i8
  store i8 %3860, i8* %51, align 1, !tbaa !2433
  %3861 = and i32 %3855, 255
  %3862 = tail call i32 @llvm.ctpop.i32(i32 %3861) #10
  %3863 = trunc i32 %3862 to i8
  %3864 = and i8 %3863, 1
  %3865 = xor i8 %3864, 1
  store i8 %3865, i8* %52, align 1, !tbaa !2447
  %3866 = xor i32 %3854, %3855
  %3867 = lshr i32 %3866, 4
  %3868 = trunc i32 %3867 to i8
  %3869 = and i8 %3868, 1
  store i8 %3869, i8* %53, align 1, !tbaa !2451
  %3870 = icmp eq i32 %3855, 0
  %3871 = zext i1 %3870 to i8
  store i8 %3871, i8* %54, align 1, !tbaa !2448
  %3872 = lshr i32 %3855, 31
  %3873 = trunc i32 %3872 to i8
  store i8 %3873, i8* %55, align 1, !tbaa !2449
  %3874 = lshr i32 %3854, 31
  %3875 = xor i32 %3872, %3874
  %3876 = add nuw nsw i32 %3875, %3872
  %3877 = icmp eq i32 %3876, 2
  %3878 = zext i1 %3877 to i8
  store i8 %3878, i8* %56, align 1, !tbaa !2450
  %3879 = sext i32 %3855 to i64
  store i64 %3879, i64* %RSI, align 8, !tbaa !2428
  %3880 = shl nsw i64 %3879, 3
  %3881 = add i64 %3880, %3850
  %3882 = add i64 %3847, 18
  store i64 %3882, i64* %PC, align 8
  %3883 = inttoptr i64 %3881 to i64*
  %3884 = load i64, i64* %3883, align 8
  %3885 = load i64, i64* %RAX, align 8
  %3886 = xor i64 %3885, %3884
  store i64 %3886, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %3887 = trunc i64 %3886 to i32
  %3888 = and i32 %3887, 255
  %3889 = tail call i32 @llvm.ctpop.i32(i32 %3888) #10
  %3890 = trunc i32 %3889 to i8
  %3891 = and i8 %3890, 1
  %3892 = xor i8 %3891, 1
  store i8 %3892, i8* %52, align 1, !tbaa !2447
  %3893 = icmp eq i64 %3886, 0
  %3894 = zext i1 %3893 to i8
  store i8 %3894, i8* %54, align 1, !tbaa !2448
  %3895 = lshr i64 %3886, 63
  %3896 = trunc i64 %3895 to i8
  store i8 %3896, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %3886, i64* %3839, align 1, !tbaa !2428
  store i64 0, i64* %3826, align 1, !tbaa !2428
  %3897 = add i64 %3847, 35
  store i64 %3897, i64* %PC, align 8
  %3898 = load i64, i64* %3849, align 8
  store i64 %3898, i64* %RAX, align 8, !tbaa !2428
  %3899 = add i64 %3847, 38
  store i64 %3899, i64* %PC, align 8
  %3900 = load i32, i32* %3853, align 4
  %3901 = add i32 %3900, 1
  %3902 = zext i32 %3901 to i64
  store i64 %3902, i64* %RDX, align 8, !tbaa !2428
  %3903 = icmp eq i32 %3900, -1
  %3904 = icmp eq i32 %3901, 0
  %3905 = or i1 %3903, %3904
  %3906 = zext i1 %3905 to i8
  store i8 %3906, i8* %51, align 1, !tbaa !2433
  %3907 = and i32 %3901, 255
  %3908 = tail call i32 @llvm.ctpop.i32(i32 %3907) #10
  %3909 = trunc i32 %3908 to i8
  %3910 = and i8 %3909, 1
  %3911 = xor i8 %3910, 1
  store i8 %3911, i8* %52, align 1, !tbaa !2447
  %3912 = xor i32 %3900, %3901
  %3913 = lshr i32 %3912, 4
  %3914 = trunc i32 %3913 to i8
  %3915 = and i8 %3914, 1
  store i8 %3915, i8* %53, align 1, !tbaa !2451
  %3916 = icmp eq i32 %3901, 0
  %3917 = zext i1 %3916 to i8
  store i8 %3917, i8* %54, align 1, !tbaa !2448
  %3918 = lshr i32 %3901, 31
  %3919 = trunc i32 %3918 to i8
  store i8 %3919, i8* %55, align 1, !tbaa !2449
  %3920 = lshr i32 %3900, 31
  %3921 = xor i32 %3918, %3920
  %3922 = add nuw nsw i32 %3921, %3918
  %3923 = icmp eq i32 %3922, 2
  %3924 = zext i1 %3923 to i8
  store i8 %3924, i8* %56, align 1, !tbaa !2450
  %3925 = sext i32 %3901 to i64
  store i64 %3925, i64* %RCX, align 8, !tbaa !2428
  %3926 = shl nsw i64 %3925, 3
  %3927 = add i64 %3926, %3898
  %3928 = add i64 %3847, 49
  store i64 %3928, i64* %PC, align 8
  %3929 = inttoptr i64 %3927 to i64*
  store i64 %3886, i64* %3929, align 8
  %3930 = load i64, i64* %RBP, align 8
  %3931 = add i64 %3930, -36
  %3932 = load i64, i64* %PC, align 8
  %3933 = add i64 %3932, 7
  store i64 %3933, i64* %PC, align 8
  %3934 = inttoptr i64 %3931 to i32*
  store i32 1, i32* %3934, align 4
  %.pre7 = load i64, i64* %PC, align 8
  br label %block_4021ec

block_401c83:                                     ; preds = %block_401c6b
  %3935 = add i64 %122, -36
  %3936 = add i64 %170, 7
  store i64 %3936, i64* %PC, align 8
  %3937 = inttoptr i64 %3935 to i32*
  store i32 0, i32* %3937, align 4
  %3938 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %3939 = bitcast i64* %3938 to double*
  %3940 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  %.pre5 = load i64, i64* %PC, align 8
  br label %block_401c8a
}

; Function Attrs: noinline
define %struct.Memory* @sub_4010d0_errorcheck(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_4010d0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %5 to i32*
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %6 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %6, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %10 = load i64, i64* %RBP, align 8
  %11 = add i64 %1, 1
  store i64 %11, i64* %PC, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %13 = load i64, i64* %12, align 8, !tbaa !2428
  %14 = add i64 %13, -8
  %15 = inttoptr i64 %14 to i64*
  store i64 %10, i64* %15, align 8
  store i64 %14, i64* %12, align 8, !tbaa !2428
  %16 = load i64, i64* %PC, align 8
  store i64 %14, i64* %RBP, align 8, !tbaa !2428
  %17 = bitcast %union.VectorReg* %8 to i8*
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %19 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %8, i64 0, i32 0, i32 0, i32 0, i64 0
  %20 = bitcast %union.VectorReg* %8 to i32*
  store i32 0, i32* %20, align 1, !tbaa !2459
  %21 = getelementptr inbounds i8, i8* %17, i64 4
  %22 = bitcast i8* %21 to i32*
  store i32 0, i32* %22, align 1, !tbaa !2459
  %23 = bitcast i64* %18 to i32*
  store i32 0, i32* %23, align 1, !tbaa !2459
  %24 = getelementptr inbounds i8, i8* %17, i64 12
  %25 = bitcast i8* %24 to i32*
  store i32 0, i32* %25, align 1, !tbaa !2459
  %26 = add i64 %13, -12
  %27 = load i32, i32* %EDI, align 4
  %28 = add i64 %16, 9
  store i64 %28, i64* %PC, align 8
  %29 = inttoptr i64 %26 to i32*
  store i32 %27, i32* %29, align 4
  %30 = load i64, i64* %RBP, align 8
  %31 = add i64 %30, -8
  %32 = load i32, i32* %ESI, align 4
  %33 = load i64, i64* %PC, align 8
  %34 = add i64 %33, 3
  store i64 %34, i64* %PC, align 8
  %35 = inttoptr i64 %31 to i32*
  store i32 %32, i32* %35, align 4
  %36 = load i64, i64* %RBP, align 8
  %37 = add i64 %36, -16
  %38 = load i64, i64* %PC, align 8
  %39 = add i64 %38, 5
  store i64 %39, i64* %PC, align 8
  %40 = bitcast [32 x %union.VectorReg]* %7 to double*
  %41 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %42 = load i64, i64* %41, align 1
  %43 = inttoptr i64 %37 to i64*
  store i64 %42, i64* %43, align 8
  %44 = load i64, i64* %RBP, align 8
  %45 = add i64 %44, -24
  %46 = load i64, i64* %RDX, align 8
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 4
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %45 to i64*
  store i64 %46, i64* %49, align 8
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -32
  %52 = load i64, i64* %PC, align 8
  %53 = add i64 %52, 7
  store i64 %53, i64* %PC, align 8
  %54 = inttoptr i64 %51 to i32*
  store i32 0, i32* %54, align 4
  %55 = load i64, i64* %RBP, align 8
  %56 = add i64 %55, -40
  %57 = load i64, i64* %PC, align 8
  %58 = add i64 %57, 5
  store i64 %58, i64* %PC, align 8
  %59 = bitcast %union.VectorReg* %8 to double*
  %60 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %8, i64 0, i32 0, i32 0, i32 0, i64 0
  %61 = load i64, i64* %60, align 1
  %62 = inttoptr i64 %56 to i64*
  store i64 %61, i64* %62, align 8
  %63 = load i64, i64* %RBP, align 8
  %64 = add i64 %63, -4
  %65 = load i64, i64* %PC, align 8
  %66 = add i64 %65, 3
  store i64 %66, i64* %PC, align 8
  %67 = inttoptr i64 %64 to i32*
  %68 = load i32, i32* %67, align 4
  %69 = zext i32 %68 to i64
  store i64 %69, i64* %RSI, align 8, !tbaa !2428
  %70 = add i64 %63, -28
  %71 = add i64 %65, 6
  store i64 %71, i64* %PC, align 8
  %72 = inttoptr i64 %70 to i32*
  store i32 %68, i32* %72, align 4
  %73 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %74 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %75 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %76 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %77 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %78 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %79 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %80 = bitcast [32 x %union.VectorReg]* %7 to i8*
  %81 = bitcast [32 x %union.VectorReg]* %7 to double*
  %82 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %83 = bitcast i64* %82 to double*
  %84 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %85 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %86 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %87 = bitcast %union.VectorReg* %8 to double*
  %88 = bitcast %union.VectorReg* %9 to i8*
  %89 = getelementptr inbounds i8, i8* %88, i64 4
  %90 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %91 = getelementptr inbounds i8, i8* %88, i64 12
  %92 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %9, i64 0, i32 0, i32 0, i32 0, i64 0
  %93 = bitcast [32 x %union.VectorReg]* %7 to i32*
  %94 = getelementptr inbounds i8, i8* %80, i64 4
  %95 = bitcast i8* %94 to i32*
  %96 = bitcast i64* %82 to i32*
  %97 = getelementptr inbounds i8, i8* %80, i64 12
  %98 = bitcast i8* %97 to i32*
  %.pre = load i64, i64* %PC, align 8
  br label %block_4010f8

block_4010f8:                                     ; preds = %block_401192, %block_4010d0
  %99 = phi i64 [ %.pre, %block_4010d0 ], [ %179, %block_401192 ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_4010d0 ], [ %374, %block_401192 ]
  %100 = load i64, i64* %RBP, align 8
  %101 = add i64 %100, -28
  %102 = add i64 %99, 3
  store i64 %102, i64* %PC, align 8
  %103 = inttoptr i64 %101 to i32*
  %104 = load i32, i32* %103, align 4
  %105 = zext i32 %104 to i64
  store i64 %105, i64* %RAX, align 8, !tbaa !2428
  %106 = add i64 %100, -8
  %107 = add i64 %99, 6
  store i64 %107, i64* %PC, align 8
  %108 = inttoptr i64 %106 to i32*
  %109 = load i32, i32* %108, align 4
  %110 = sub i32 %104, %109
  %111 = icmp ult i32 %104, %109
  %112 = zext i1 %111 to i8
  store i8 %112, i8* %73, align 1, !tbaa !2433
  %113 = and i32 %110, 255
  %114 = tail call i32 @llvm.ctpop.i32(i32 %113) #10
  %115 = trunc i32 %114 to i8
  %116 = and i8 %115, 1
  %117 = xor i8 %116, 1
  store i8 %117, i8* %74, align 1, !tbaa !2447
  %118 = xor i32 %109, %104
  %119 = xor i32 %118, %110
  %120 = lshr i32 %119, 4
  %121 = trunc i32 %120 to i8
  %122 = and i8 %121, 1
  store i8 %122, i8* %75, align 1, !tbaa !2451
  %123 = icmp eq i32 %110, 0
  %124 = zext i1 %123 to i8
  store i8 %124, i8* %76, align 1, !tbaa !2448
  %125 = lshr i32 %110, 31
  %126 = trunc i32 %125 to i8
  store i8 %126, i8* %77, align 1, !tbaa !2449
  %127 = lshr i32 %104, 31
  %128 = lshr i32 %109, 31
  %129 = xor i32 %128, %127
  %130 = xor i32 %125, %127
  %131 = add nuw nsw i32 %130, %129
  %132 = icmp eq i32 %131, 2
  %133 = zext i1 %132 to i8
  store i8 %133, i8* %78, align 1, !tbaa !2450
  %134 = icmp ne i8 %126, 0
  %135 = xor i1 %134, %132
  %.demorgan = or i1 %123, %135
  %.v = select i1 %.demorgan, i64 12, i64 178
  %136 = add i64 %99, %.v
  store i64 %136, i64* %79, align 8, !tbaa !2428
  br i1 %.demorgan, label %block_401104, label %block_4011aa

block_401192:                                     ; preds = %block_40117d, %block_40116e
  %137 = phi i64 [ %.pre6, %block_40117d ], [ %189, %block_40116e ]
  %138 = load i64, i64* %RBP, align 8
  %139 = add i64 %138, -64
  %140 = add i64 %137, 5
  store i64 %140, i64* %PC, align 8
  %141 = inttoptr i64 %139 to i64*
  %142 = load i64, i64* %141, align 8
  %143 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %142, i64* %143, align 1, !tbaa !2452
  store double 0.000000e+00, double* %83, align 1, !tbaa !2452
  %144 = add i64 %138, -40
  %145 = add i64 %137, 10
  store i64 %145, i64* %PC, align 8
  %146 = inttoptr i64 %144 to i64*
  store i64 %142, i64* %146, align 8
  %147 = load i64, i64* %RBP, align 8
  %148 = add i64 %147, -28
  %149 = load i64, i64* %PC, align 8
  %150 = add i64 %149, 3
  store i64 %150, i64* %PC, align 8
  %151 = inttoptr i64 %148 to i32*
  %152 = load i32, i32* %151, align 4
  %153 = add i32 %152, 1
  %154 = zext i32 %153 to i64
  store i64 %154, i64* %RAX, align 8, !tbaa !2428
  %155 = icmp eq i32 %152, -1
  %156 = icmp eq i32 %153, 0
  %157 = or i1 %155, %156
  %158 = zext i1 %157 to i8
  store i8 %158, i8* %73, align 1, !tbaa !2433
  %159 = and i32 %153, 255
  %160 = tail call i32 @llvm.ctpop.i32(i32 %159) #10
  %161 = trunc i32 %160 to i8
  %162 = and i8 %161, 1
  %163 = xor i8 %162, 1
  store i8 %163, i8* %74, align 1, !tbaa !2447
  %164 = xor i32 %152, %153
  %165 = lshr i32 %164, 4
  %166 = trunc i32 %165 to i8
  %167 = and i8 %166, 1
  store i8 %167, i8* %75, align 1, !tbaa !2451
  %168 = icmp eq i32 %153, 0
  %169 = zext i1 %168 to i8
  store i8 %169, i8* %76, align 1, !tbaa !2448
  %170 = lshr i32 %153, 31
  %171 = trunc i32 %170 to i8
  store i8 %171, i8* %77, align 1, !tbaa !2449
  %172 = lshr i32 %152, 31
  %173 = xor i32 %170, %172
  %174 = add nuw nsw i32 %173, %170
  %175 = icmp eq i32 %174, 2
  %176 = zext i1 %175 to i8
  store i8 %176, i8* %78, align 1, !tbaa !2450
  %177 = add i64 %149, 9
  store i64 %177, i64* %PC, align 8
  store i32 %153, i32* %151, align 4
  %178 = load i64, i64* %PC, align 8
  %179 = add i64 %178, -173
  store i64 %179, i64* %79, align 8, !tbaa !2428
  br label %block_4010f8

block_40116e:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %180 = add i64 %372, -40
  %181 = add i64 %379, 5
  store i64 %181, i64* %PC, align 8
  %182 = inttoptr i64 %180 to i64*
  %183 = load i64, i64* %182, align 8
  %184 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %183, i64* %184, align 1, !tbaa !2452
  store double 0.000000e+00, double* %83, align 1, !tbaa !2452
  %185 = add i64 %372, -64
  %186 = add i64 %379, 10
  store i64 %186, i64* %PC, align 8
  %187 = inttoptr i64 %185 to i64*
  store i64 %183, i64* %187, align 8
  %188 = load i64, i64* %PC, align 8
  %189 = add i64 %188, 26
  store i64 %189, i64* %79, align 8, !tbaa !2428
  br label %block_401192

block_4011aa:                                     ; preds = %block_4010f8
  %190 = add i64 %100, -40
  %191 = add i64 %136, 5
  store i64 %191, i64* %PC, align 8
  %192 = inttoptr i64 %190 to i64*
  %193 = load i64, i64* %192, align 8
  %194 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %193, i64* %194, align 1, !tbaa !2452
  store double 0.000000e+00, double* %83, align 1, !tbaa !2452
  %195 = add i64 %136, 6
  store i64 %195, i64* %PC, align 8
  %196 = load i64, i64* %12, align 8, !tbaa !2428
  %197 = add i64 %196, 8
  %198 = inttoptr i64 %196 to i64*
  %199 = load i64, i64* %198, align 8
  store i64 %199, i64* %RBP, align 8, !tbaa !2428
  store i64 %197, i64* %12, align 8, !tbaa !2428
  %200 = add i64 %136, 7
  store i64 %200, i64* %PC, align 8
  %201 = inttoptr i64 %197 to i64*
  %202 = load i64, i64* %201, align 8
  store i64 %202, i64* %79, align 8, !tbaa !2428
  %203 = add i64 %196, 16
  store i64 %203, i64* %12, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_40117d:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %204 = add i64 %372, -48
  %205 = add i64 %379, 5
  store i64 %205, i64* %PC, align 8
  %206 = inttoptr i64 %204 to i64*
  %207 = load i64, i64* %206, align 8
  %208 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 96) to i32*), align 16
  %209 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 100) to i32*), align 4
  %210 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 104) to i32*), align 8
  %211 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 108) to i32*), align 4
  %212 = bitcast %union.VectorReg* %8 to i32*
  store i32 %208, i32* %212, align 1, !tbaa !2475
  %213 = bitcast i8* %21 to i32*
  store i32 %209, i32* %213, align 1, !tbaa !2475
  %214 = bitcast i64* %18 to i32*
  store i32 %210, i32* %214, align 1, !tbaa !2475
  %215 = bitcast i8* %24 to i32*
  store i32 %211, i32* %215, align 1, !tbaa !2475
  %216 = load i64, i64* %19, align 1
  %217 = and i64 %216, %207
  %218 = trunc i64 %217 to i32
  %219 = lshr i64 %217, 32
  %220 = trunc i64 %219 to i32
  store i32 %218, i32* %93, align 1, !tbaa !2459
  store i32 %220, i32* %95, align 1, !tbaa !2459
  store i32 0, i32* %96, align 1, !tbaa !2459
  store i32 0, i32* %98, align 1, !tbaa !2459
  %221 = add i64 %372, -64
  %222 = add i64 %379, 21
  store i64 %222, i64* %PC, align 8
  %223 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %224 = load i64, i64* %223, align 1
  %225 = inttoptr i64 %221 to i64*
  store i64 %224, i64* %225, align 8
  %.pre6 = load i64, i64* %PC, align 8
  br label %block_401192

block_401104:                                     ; preds = %block_4010f8
  %226 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 72) to i64*), align 8
  %227 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %226, i64* %227, align 1, !tbaa !2452
  store double 0.000000e+00, double* %83, align 1, !tbaa !2452
  store i64 259200, i64* %RAX, align 8, !tbaa !2428
  %228 = add i64 %100, -32
  %229 = add i64 %136, 20
  store i64 %229, i64* %PC, align 8
  %230 = inttoptr i64 %228 to i32*
  %231 = load i32, i32* %230, align 4
  %232 = sext i32 %231 to i64
  %233 = mul nsw i64 %232, 7141
  %234 = trunc i64 %233 to i32
  %235 = add i32 %234, 54773
  %236 = zext i32 %235 to i64
  store i64 %236, i64* %RCX, align 8, !tbaa !2428
  %237 = icmp ugt i32 %234, -54774
  %238 = zext i1 %237 to i8
  store i8 %238, i8* %73, align 1, !tbaa !2433
  %239 = and i32 %235, 255
  %240 = tail call i32 @llvm.ctpop.i32(i32 %239) #10
  %241 = trunc i32 %240 to i8
  %242 = and i8 %241, 1
  %243 = xor i8 %242, 1
  store i8 %243, i8* %74, align 1, !tbaa !2447
  %244 = trunc i64 %233 to i32
  %245 = xor i32 %244, 16
  %246 = xor i32 %245, %235
  %247 = lshr i32 %246, 4
  %248 = trunc i32 %247 to i8
  %249 = and i8 %248, 1
  store i8 %249, i8* %75, align 1, !tbaa !2451
  %250 = icmp eq i32 %235, 0
  %251 = zext i1 %250 to i8
  store i8 %251, i8* %76, align 1, !tbaa !2448
  %252 = lshr i32 %235, 31
  %253 = trunc i32 %252 to i8
  store i8 %253, i8* %77, align 1, !tbaa !2449
  %254 = lshr i32 %234, 31
  %255 = xor i32 %252, %254
  %256 = add nuw nsw i32 %255, %252
  %257 = icmp eq i32 %256, 2
  %258 = zext i1 %257 to i8
  store i8 %258, i8* %78, align 1, !tbaa !2450
  %259 = add i64 %100, -52
  %260 = add i64 %136, 29
  store i64 %260, i64* %PC, align 8
  %261 = inttoptr i64 %259 to i32*
  store i32 259200, i32* %261, align 4
  %262 = load i32, i32* %ECX, align 4
  %263 = zext i32 %262 to i64
  %264 = load i64, i64* %PC, align 8
  store i64 %263, i64* %RAX, align 8, !tbaa !2428
  %265 = sext i32 %262 to i64
  %266 = lshr i64 %265, 32
  store i64 %266, i64* %84, align 8, !tbaa !2428
  %267 = load i64, i64* %RBP, align 8
  %268 = add i64 %267, -52
  %269 = add i64 %264, 6
  store i64 %269, i64* %PC, align 8
  %270 = inttoptr i64 %268 to i32*
  %271 = load i32, i32* %270, align 4
  %272 = zext i32 %271 to i64
  store i64 %272, i64* %RCX, align 8, !tbaa !2428
  %273 = add i64 %264, 8
  store i64 %273, i64* %PC, align 8
  %274 = zext i32 %262 to i64
  %275 = sext i32 %271 to i64
  %276 = shl nuw i64 %266, 32
  %277 = or i64 %276, %274
  %278 = sdiv i64 %277, %275
  %279 = shl i64 %278, 32
  %280 = ashr exact i64 %279, 32
  %281 = icmp eq i64 %278, %280
  br i1 %281, label %284, label %282

; <label>:282:                                    ; preds = %block_401104
  %283 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %273, %struct.Memory* %MEMORY.0) #11
  %.pre1 = load i64, i64* %RBP, align 8
  %.pre2 = load i32, i32* %EDX, align 4
  %.pre3 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:284:                                    ; preds = %block_401104
  %285 = srem i64 %277, %275
  %286 = and i64 %278, 4294967295
  store i64 %286, i64* %85, align 8, !tbaa !2428
  %287 = and i64 %285, 4294967295
  store i64 %287, i64* %86, align 8, !tbaa !2428
  store i8 0, i8* %73, align 1, !tbaa !2433
  store i8 0, i8* %74, align 1, !tbaa !2447
  store i8 0, i8* %75, align 1, !tbaa !2451
  store i8 0, i8* %76, align 1, !tbaa !2448
  store i8 0, i8* %77, align 1, !tbaa !2449
  store i8 0, i8* %78, align 1, !tbaa !2450
  %288 = trunc i64 %285 to i32
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %284, %282
  %289 = phi i64 [ %.pre3, %282 ], [ %273, %284 ]
  %290 = phi i32 [ %.pre2, %282 ], [ %288, %284 ]
  %291 = phi i64 [ %.pre1, %282 ], [ %267, %284 ]
  %292 = phi %struct.Memory* [ %283, %282 ], [ %MEMORY.0, %284 ]
  %293 = add i64 %291, -32
  %294 = add i64 %289, 3
  store i64 %294, i64* %PC, align 8
  %295 = inttoptr i64 %293 to i32*
  store i32 %290, i32* %295, align 4
  %296 = load i32, i32* %EDX, align 4
  %297 = load i64, i64* %PC, align 8
  %298 = sitofp i32 %296 to double
  %299 = load double, double* %40, align 1
  %300 = fmul double %298, %299
  store double %300, double* %87, align 1, !tbaa !2452
  %301 = load i64, i64* %RBP, align 8
  %302 = add i64 %301, -24
  %303 = add i64 %297, 12
  store i64 %303, i64* %PC, align 8
  %304 = inttoptr i64 %302 to i64*
  %305 = load i64, i64* %304, align 8
  store i64 %305, i64* %RSI, align 8, !tbaa !2428
  %306 = add i64 %301, -28
  %307 = add i64 %297, 16
  store i64 %307, i64* %PC, align 8
  %308 = inttoptr i64 %306 to i32*
  %309 = load i32, i32* %308, align 4
  %310 = sext i32 %309 to i64
  store i64 %310, i64* %RDI, align 8, !tbaa !2428
  %311 = shl nsw i64 %310, 3
  %312 = add i64 %311, %305
  %313 = add i64 %297, 21
  store i64 %313, i64* %PC, align 8
  %314 = inttoptr i64 %312 to double*
  %315 = load double, double* %314, align 8
  store double %315, double* %81, align 1, !tbaa !2452
  store double 0.000000e+00, double* %83, align 1, !tbaa !2452
  %316 = add i64 %301, -16
  %317 = add i64 %297, 26
  store i64 %317, i64* %PC, align 8
  %318 = inttoptr i64 %316 to double*
  %319 = load double, double* %318, align 8
  %320 = fmul double %315, %319
  store double %320, double* %81, align 1, !tbaa !2452
  store i64 0, i64* %82, align 1, !tbaa !2452
  %321 = fsub double %300, %320
  store double %321, double* %87, align 1, !tbaa !2452
  %322 = add i64 %301, -48
  %323 = add i64 %297, 35
  store i64 %323, i64* %PC, align 8
  %324 = inttoptr i64 %322 to double*
  store double %321, double* %324, align 8
  %325 = load i64, i64* %RBP, align 8
  %326 = add i64 %325, -40
  %327 = load i64, i64* %PC, align 8
  %328 = add i64 %327, 5
  store i64 %328, i64* %PC, align 8
  %329 = inttoptr i64 %326 to double*
  %330 = load double, double* %329, align 8
  store double %330, double* %81, align 1, !tbaa !2452
  store double 0.000000e+00, double* %83, align 1, !tbaa !2452
  %331 = add i64 %325, -48
  %332 = add i64 %327, 10
  store i64 %332, i64* %PC, align 8
  %333 = inttoptr i64 %331 to i64*
  %334 = load i64, i64* %333, align 8
  %335 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 96) to i32*), align 16
  %336 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 100) to i32*), align 4
  %337 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 104) to i32*), align 8
  %338 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 108) to i32*), align 4
  %339 = bitcast %union.VectorReg* %9 to i32*
  store i32 %335, i32* %339, align 1, !tbaa !2475
  %340 = bitcast i8* %89 to i32*
  store i32 %336, i32* %340, align 1, !tbaa !2475
  %341 = bitcast i64* %90 to i32*
  store i32 %337, i32* %341, align 1, !tbaa !2475
  %342 = bitcast i8* %91 to i32*
  store i32 %338, i32* %342, align 1, !tbaa !2475
  %343 = load i64, i64* %92, align 1
  %344 = and i64 %343, %334
  %345 = trunc i64 %344 to i32
  %346 = lshr i64 %344, 32
  %347 = trunc i64 %346 to i32
  store i32 %345, i32* %20, align 1, !tbaa !2459
  store i32 %347, i32* %22, align 1, !tbaa !2459
  store i32 0, i32* %23, align 1, !tbaa !2459
  store i32 0, i32* %25, align 1, !tbaa !2459
  %348 = add i64 %327, 25
  store i64 %348, i64* %PC, align 8
  %349 = load double, double* %59, align 1
  %350 = fcmp uno double %330, %349
  br i1 %350, label %351, label %361

; <label>:351:                                    ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit
  %352 = fadd double %330, %349
  %353 = bitcast double %352 to i64
  %354 = and i64 %353, 9221120237041090560
  %355 = icmp eq i64 %354, 9218868437227405312
  %356 = and i64 %353, 2251799813685247
  %357 = icmp ne i64 %356, 0
  %358 = and i1 %355, %357
  br i1 %358, label %359, label %367

; <label>:359:                                    ; preds = %351
  %360 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %348, %struct.Memory* %292) #11
  %.pre4 = load i64, i64* %PC, align 8
  %.pre5 = load i64, i64* %RBP, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

; <label>:361:                                    ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit
  %362 = fcmp ogt double %330, %349
  br i1 %362, label %367, label %363

; <label>:363:                                    ; preds = %361
  %364 = fcmp olt double %330, %349
  br i1 %364, label %367, label %365

; <label>:365:                                    ; preds = %363
  %366 = fcmp oeq double %330, %349
  br i1 %366, label %367, label %371

; <label>:367:                                    ; preds = %365, %363, %361, %351
  %368 = phi i8 [ 0, %361 ], [ 0, %363 ], [ 1, %365 ], [ 1, %351 ]
  %369 = phi i8 [ 0, %361 ], [ 0, %363 ], [ 0, %365 ], [ 1, %351 ]
  %370 = phi i8 [ 0, %361 ], [ 1, %363 ], [ 0, %365 ], [ 1, %351 ]
  store i8 %368, i8* %76, align 1, !tbaa !2432
  store i8 %369, i8* %74, align 1, !tbaa !2432
  store i8 %370, i8* %73, align 1, !tbaa !2432
  br label %371

; <label>:371:                                    ; preds = %367, %365
  store i8 0, i8* %78, align 1, !tbaa !2432
  store i8 0, i8* %77, align 1, !tbaa !2432
  store i8 0, i8* %75, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit: ; preds = %371, %359
  %372 = phi i64 [ %.pre5, %359 ], [ %325, %371 ]
  %373 = phi i64 [ %.pre4, %359 ], [ %348, %371 ]
  %374 = phi %struct.Memory* [ %360, %359 ], [ %292, %371 ]
  %375 = load i8, i8* %73, align 1, !tbaa !2433
  %376 = load i8, i8* %76, align 1, !tbaa !2448
  %377 = or i8 %376, %375
  %378 = icmp ne i8 %377, 0
  %.v7 = select i1 %378, i64 21, i64 6
  %379 = add i64 %373, %.v7
  store i64 %379, i64* %79, align 8, !tbaa !2428
  br i1 %378, label %block_40117d, label %block_40116e
}

; Function Attrs: noinline
define %struct.Memory* @sub_400710__start(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400710:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  store i64 0, i64* %RBP, align 8, !tbaa !2428
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %3, align 1, !tbaa !2433
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %4, align 1, !tbaa !2447
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %5, align 1, !tbaa !2448
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %6, align 1, !tbaa !2449
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %7, align 1, !tbaa !2450
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %8, align 1, !tbaa !2451
  %9 = load i64, i64* %RDX, align 8
  store i64 %9, i64* %R9, align 8, !tbaa !2428
  %10 = add i64 %1, 6
  store i64 %10, i64* %PC, align 8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %12 = load i64, i64* %11, align 8, !tbaa !2428
  %13 = add i64 %12, 8
  %14 = inttoptr i64 %12 to i64*
  %15 = load i64, i64* %14, align 8
  store i64 %15, i64* %RSI, align 8, !tbaa !2428
  store i64 %13, i64* %RDX, align 8, !tbaa !2428
  %16 = and i64 %13, -16
  store i8 0, i8* %3, align 1, !tbaa !2433
  %17 = trunc i64 %13 to i32
  %18 = and i32 %17, 240
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18) #10
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  store i8 %22, i8* %4, align 1, !tbaa !2447
  %23 = icmp eq i64 %16, 0
  %24 = zext i1 %23 to i8
  store i8 %24, i8* %5, align 1, !tbaa !2448
  %25 = lshr i64 %13, 63
  %26 = trunc i64 %25 to i8
  store i8 %26, i8* %6, align 1, !tbaa !2449
  store i8 0, i8* %7, align 1, !tbaa !2450
  store i8 0, i8* %8, align 1, !tbaa !2451
  %27 = load i64, i64* %RAX, align 8
  %28 = add i64 %1, 14
  store i64 %28, i64* %PC, align 8
  %29 = add i64 %16, -8
  %30 = inttoptr i64 %29 to i64*
  store i64 %27, i64* %30, align 8
  %31 = load i64, i64* %PC, align 8
  %32 = add i64 %31, 1
  store i64 %32, i64* %PC, align 8
  %33 = add i64 %16, -16
  %34 = inttoptr i64 %33 to i64*
  store i64 %29, i64* %34, align 16
  %35 = load i64, i64* %PC, align 8
  store i64 ptrtoint (void ()* @callback_sub_404060___libc_csu_fini to i64), i64* %R8, align 8, !tbaa !2428
  store i64 ptrtoint (void ()* @callback_sub_403ff0___libc_csu_init to i64), i64* %RCX, align 8, !tbaa !2428
  store i64 ptrtoint (void ()* @main to i64), i64* %RDI, align 8, !tbaa !2428
  %36 = add i64 %35, 27
  %37 = add i64 %16, -24
  %38 = inttoptr i64 %37 to i64*
  store i64 %36, i64* %38, align 8
  store i64 %37, i64* %11, align 8, !tbaa !2428
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %40 = load i64, i64* getelementptr inbounds (%seg_604ff0__got_type, %seg_604ff0__got_type* @seg_604ff0__got, i64 0, i32 0), align 8
  store i64 %40, i64* %39, align 8, !tbaa !2428
  %41 = tail call fastcc %struct.Memory* @ext_605120___libc_start_main(%struct.State* nonnull %0, %struct.Memory* %2)
  %42 = load i64, i64* %PC, align 8
  %43 = add i64 %42, 1
  store i64 %43, i64* %PC, align 8
  %44 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull %0, i64 %43, %struct.Memory* %41)
  ret %struct.Memory* %44
}

; Function Attrs: noinline
define %struct.Memory* @sub_4007f0_frame_dummy(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_4007f0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  store i64 %7, i64* %5, align 8, !tbaa !2428
  %9 = load i64, i64* %PC, align 8
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = load i64, i64* %8, align 8
  store i64 %11, i64* %RBP, align 8, !tbaa !2428
  store i64 %6, i64* %5, align 8, !tbaa !2428
  %12 = add i64 %9, -113
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %12, i64* %13, align 8, !tbaa !2428
  %14 = tail call %struct.Memory* @sub_400780_register_tm_clones(%struct.State* nonnull %0, i64 %12, %struct.Memory* %2)
  ret %struct.Memory* %14
}

; Function Attrs: noinline
declare void @__mcsema_attach_call() #6

; Function Attrs: naked nobuiltin noinline
define internal void @callback_sub_4007f0_frame_dummy() #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x4007f0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @1, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @callback_sub_4007f0_frame_dummy_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_4007f0_frame_dummy(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define internal void @callback_sub_4007c0___do_global_dtors_aux() #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x4007c0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @3, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @callback_sub_4007c0___do_global_dtors_aux_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_4007c0___do_global_dtors_aux(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: alwaysinline inlinehint
define %struct.Memory* @ext_6050f8_atan(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #9 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @atan(double %6)
  %.repack = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 0, i64* %.repack, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  store i64 0, i64* %12, align 8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %13, align 8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %14, align 8
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: alwaysinline inlinehint
define %struct.Memory* @ext_6050b8_cos(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #9 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @cos(double %6)
  %.repack = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 0, i64* %.repack, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  store i64 0, i64* %12, align 8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %13, align 8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %14, align 8
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: alwaysinline inlinehint
define %struct.Memory* @ext_4006f0_sin(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #9 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @sin(double %6)
  %.repack = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 0, i64* %.repack, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  store i64 0, i64* %12, align 8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %13, align 8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %14, align 8
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_605128_memcpy(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64)* @memcpy to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_6050a0_printf(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64)* @printf to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_400670_abort(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 ()* @abort to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_6050e8_free(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64)* @free to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_605110_memset(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64)* @memset to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: alwaysinline inlinehint
define %struct.Memory* @ext_605140_sqrt(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #9 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @sqrt(double %6)
  %.repack = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 0, i64* %.repack, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  store i64 0, i64* %12, align 8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %13, align 8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %14, align 8
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_4006e0_memalign(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64)* @memalign to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_4006a0_gettimeofday(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64)* @gettimeofday to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: naked nobuiltin noinline
define internal void @callback_sub_404060___libc_csu_fini() #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x404060;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @4, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @callback_sub_404060___libc_csu_fini_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_404060___libc_csu_fini(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define internal void @callback_sub_403ff0___libc_csu_init() #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x403ff0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @5, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @callback_sub_403ff0___libc_csu_init_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_403ff0___libc_csu_init(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @main() #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400800;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @6, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @main_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400800_main(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_605120___libc_start_main(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64)* @__libc_start_main to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @errorcheck() local_unnamed_addr #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x4010d0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @7, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @errorcheck_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_4010d0_errorcheck(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @.term_proc() local_unnamed_addr #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x404064;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @8, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @.term_proc_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_404064__term_proc(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @get_time() local_unnamed_addr #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400de0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @9, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @get_time_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400de0_get_time(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @makewt() local_unnamed_addr #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400e30;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @10, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @makewt_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400e30_makewt(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @.init_proc() local_unnamed_addr #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400638;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @11, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @.init_proc_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400638__init_proc(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @cdft() local_unnamed_addr #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x401030;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @12, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @cdft_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_401030_cdft(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @putdata() local_unnamed_addr #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400fb0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @13, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @putdata_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400fb0_putdata(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

define internal void @__mcsema_constructor() {
  %1 = load volatile i1, i1* @0, align 1
  br i1 %1, label %__mcsema_early_init.exit, label %2

; <label>:2:                                      ; preds = %0
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %0, %2
  tail call void @callback_sub_403ff0___libc_csu_init()
  ret void
}

define internal void @__mcsema_destructor() {
  tail call void @callback_sub_404060___libc_csu_fini()
  ret void
}

attributes #0 = { nounwind readnone }
attributes #1 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind readnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { noinline }
attributes #7 = { noinline "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { naked nobuiltin noinline }
attributes #9 = { alwaysinline inlinehint "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #10 = { nounwind }
attributes #11 = { alwaysinline nobuiltin nounwind }

!llvm.ident = !{!0, !0}
!llvm.dbg.cu = !{!1}
!llvm.module.flags = !{!1259, !1260}

!0 = !{!"clang version 4.0.1 (tags/RELEASE_401/final)"}
!1 = distinct !DICompileUnit(language: DW_LANG_C_plus_plus, file: !2, producer: "clang version 4.0.1 (tags/RELEASE_401/final)", isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug, enums: !3, retainedTypes: !67, imports: !70)
!2 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/X86/Runtime/BasicBlock.cpp", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!3 = !{!4, !26, !35, !39, !45, !51, !55, !61}
!4 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "Name", scope: !6, file: !5, line: 70, baseType: !8, size: 32, elements: !11, identifier: "_ZTSN14AsyncHyperCall4NameE")
!5 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/HyperCall.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!6 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "AsyncHyperCall", file: !5, line: 68, size: 8, elements: !7, identifier: "_ZTS14AsyncHyperCall")
!7 = !{}
!8 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint32_t", file: !9, line: 183, baseType: !10)
!9 = !DIFile(filename: "/home/ubuntu/Github/remill/remill-build/libraries/llvm/bin/../lib/clang/4.0.1/include/stdint.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!10 = !DIBasicType(name: "unsigned int", size: 32, encoding: DW_ATE_unsigned)
!11 = !{!12, !13, !14, !15, !16, !17, !18, !19, !20, !21, !22, !23, !24, !25}
!12 = !DIEnumerator(name: "kInvalid", value: 0)
!13 = !DIEnumerator(name: "kX86Int1", value: 1)
!14 = !DIEnumerator(name: "kX86Int3", value: 2)
!15 = !DIEnumerator(name: "kX86IntO", value: 3)
!16 = !DIEnumerator(name: "kX86IntN", value: 4)
!17 = !DIEnumerator(name: "kX86Bound", value: 5)
!18 = !DIEnumerator(name: "kX86IRet", value: 6)
!19 = !DIEnumerator(name: "kX86SysCall", value: 7)
!20 = !DIEnumerator(name: "kX86SysRet", value: 8)
!21 = !DIEnumerator(name: "kX86SysEnter", value: 9)
!22 = !DIEnumerator(name: "kX86SysExit", value: 10)
!23 = !DIEnumerator(name: "kX86JmpFar", value: 11)
!24 = !DIEnumerator(name: "kAArch64SupervisorCall", value: 12)
!25 = !DIEnumerator(name: "kInvalidInstruction", value: 13)
!26 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "RequestPrivilegeLevel", file: !27, line: 64, baseType: !28, size: 16, elements: !30, identifier: "_ZTS21RequestPrivilegeLevel")
!27 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/X86/Runtime/State.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!28 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint16_t", file: !9, line: 218, baseType: !29)
!29 = !DIBasicType(name: "unsigned short", size: 16, encoding: DW_ATE_unsigned)
!30 = !{!31, !32, !33, !34}
!31 = !DIEnumerator(name: "kRPLRingZero", value: 0)
!32 = !DIEnumerator(name: "kRPLRingOne", value: 1)
!33 = !DIEnumerator(name: "kRPLRingTwo", value: 2)
!34 = !DIEnumerator(name: "kRPLRingThree", value: 3)
!35 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "TableIndicator", file: !27, line: 71, baseType: !28, size: 16, elements: !36, identifier: "_ZTS14TableIndicator")
!36 = !{!37, !38}
!37 = !DIEnumerator(name: "kGlobalDescriptorTable", value: 0)
!38 = !DIEnumerator(name: "kLocalDescriptorTable", value: 1)
!39 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUPrecisionControl", file: !27, line: 123, baseType: !28, size: 16, elements: !40, identifier: "_ZTS19FPUPrecisionControl")
!40 = !{!41, !42, !43, !44}
!41 = !DIEnumerator(name: "kPrecisionSingle", value: 0)
!42 = !DIEnumerator(name: "kPrecisionReserved", value: 1)
!43 = !DIEnumerator(name: "kPrecisionDouble", value: 2)
!44 = !DIEnumerator(name: "kPrecisionExtended", value: 3)
!45 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPURoundingControl", file: !27, line: 130, baseType: !28, size: 16, elements: !46, identifier: "_ZTS18FPURoundingControl")
!46 = !{!47, !48, !49, !50}
!47 = !DIEnumerator(name: "kFPURoundToNearestEven", value: 0)
!48 = !DIEnumerator(name: "kFPURoundDownNegInf", value: 1)
!49 = !DIEnumerator(name: "kFPURoundUpInf", value: 2)
!50 = !DIEnumerator(name: "kFPURoundToZero", value: 3)
!51 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUInfinityControl", file: !27, line: 137, baseType: !28, size: 16, elements: !52, identifier: "_ZTS18FPUInfinityControl")
!52 = !{!53, !54}
!53 = !DIEnumerator(name: "kInfinityProjective", value: 0)
!54 = !DIEnumerator(name: "kInfinityAffine", value: 1)
!55 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUTag", file: !27, line: 214, baseType: !28, size: 16, elements: !56, identifier: "_ZTS6FPUTag")
!56 = !{!57, !58, !59, !60}
!57 = !DIEnumerator(name: "kFPUTagNonZero", value: 0)
!58 = !DIEnumerator(name: "kFPUTagZero", value: 1)
!59 = !DIEnumerator(name: "kFPUTagSpecial", value: 2)
!60 = !DIEnumerator(name: "kFPUTagEmpty", value: 3)
!61 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUAbridgedTag", file: !27, line: 221, baseType: !62, size: 8, elements: !64, identifier: "_ZTS14FPUAbridgedTag")
!62 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint8_t", file: !9, line: 237, baseType: !63)
!63 = !DIBasicType(name: "unsigned char", size: 8, encoding: DW_ATE_unsigned_char)
!64 = !{!65, !66}
!65 = !DIEnumerator(name: "kFPUAbridgedTagEmpty", value: 0)
!66 = !DIEnumerator(name: "kFPUAbridgedTagValid", value: 1)
!67 = !{!68}
!68 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !69, size: 64)
!69 = !DIDerivedType(tag: DW_TAG_const_type, baseType: null)
!70 = !{!71, !77, !83, !86, !93, !97, !102, !104, !112, !116, !120, !132, !136, !140, !144, !148, !153, !157, !161, !165, !169, !177, !181, !185, !187, !191, !195, !199, !205, !209, !213, !215, !223, !227, !235, !237, !241, !245, !249, !253, !258, !263, !268, !269, !270, !271, !274, !275, !276, !277, !278, !279, !280, !335, !339, !355, !358, !363, !371, !376, !380, !384, !388, !392, !394, !396, !400, !406, !410, !416, !422, !424, !428, !432, !436, !440, !451, !453, !457, !461, !465, !467, !471, !475, !479, !481, !483, !487, !495, !499, !503, !507, !509, !515, !517, !523, !527, !531, !535, !539, !543, !547, !549, !551, !555, !559, !563, !565, !569, !573, !575, !577, !581, !585, !589, !593, !594, !595, !596, !597, !598, !599, !600, !601, !602, !603, !606, !609, !611, !613, !615, !617, !619, !621, !623, !625, !627, !629, !631, !633, !634, !635, !636, !638, !640, !642, !644, !646, !648, !650, !652, !654, !656, !658, !660, !662, !665, !669, !674, !677, !679, !681, !683, !685, !687, !689, !691, !693, !695, !697, !699, !701, !703, !706, !712, !717, !721, !723, !725, !727, !729, !736, !740, !744, !748, !752, !756, !761, !765, !767, !771, !777, !781, !786, !788, !790, !794, !798, !802, !804, !806, !808, !810, !814, !816, !818, !822, !826, !830, !834, !838, !840, !842, !846, !850, !854, !858, !860, !862, !866, !870, !871, !872, !873, !874, !875, !880, !882, !884, !888, !890, !892, !894, !896, !898, !900, !902, !907, !911, !913, !915, !920, !922, !924, !926, !928, !930, !932, !935, !937, !939, !943, !947, !949, !951, !953, !955, !957, !959, !961, !963, !965, !967, !971, !975, !977, !979, !981, !983, !985, !987, !989, !991, !993, !995, !997, !999, !1001, !1003, !1005, !1009, !1013, !1017, !1019, !1021, !1023, !1025, !1027, !1029, !1031, !1033, !1035, !1039, !1043, !1047, !1049, !1051, !1053, !1057, !1061, !1065, !1067, !1069, !1071, !1073, !1075, !1077, !1079, !1081, !1083, !1085, !1087, !1089, !1093, !1097, !1101, !1103, !1105, !1107, !1109, !1113, !1117, !1119, !1121, !1123, !1125, !1127, !1129, !1133, !1137, !1139, !1141, !1143, !1145, !1149, !1153, !1157, !1159, !1161, !1163, !1165, !1167, !1169, !1173, !1177, !1181, !1183, !1187, !1191, !1193, !1195, !1197, !1199, !1201, !1203, !1207, !1209, !1212, !1217, !1219, !1225, !1227, !1229, !1231, !1236, !1238, !1244, !1246, !1247, !1248, !1249, !1250, !1251, !1252, !1253, !1254, !1255, !1256, !1257, !1258}
!71 = !DIImportedEntity(tag: DW_TAG_imported_module, scope: !72, entity: !74, line: 58)
!72 = !DINamespace(name: "__gnu_debug", scope: null, file: !73, line: 56)
!73 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/debug/debug.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!74 = !DINamespace(name: "__debug", scope: !75, file: !73, line: 50)
!75 = !DINamespace(name: "std", scope: null, file: !76, line: 229)
!76 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/x86_64-linux-gnu/c++/7.4.0/bits/c++config.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!77 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !78, line: 52)
!78 = !DISubprogram(name: "abs", scope: !79, file: !79, line: 837, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!79 = !DIFile(filename: "/usr/include/stdlib.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!80 = !DISubroutineType(types: !81)
!81 = !{!82, !82}
!82 = !DIBasicType(name: "int", size: 32, encoding: DW_ATE_signed)
!83 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !84, line: 127)
!84 = !DIDerivedType(tag: DW_TAG_typedef, name: "div_t", file: !79, line: 62, baseType: !85)
!85 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 58, flags: DIFlagFwdDecl, identifier: "_ZTS5div_t")
!86 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !87, line: 128)
!87 = !DIDerivedType(tag: DW_TAG_typedef, name: "ldiv_t", file: !79, line: 70, baseType: !88)
!88 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 66, size: 128, elements: !89, identifier: "_ZTS6ldiv_t")
!89 = !{!90, !92}
!90 = !DIDerivedType(tag: DW_TAG_member, name: "quot", scope: !88, file: !79, line: 68, baseType: !91, size: 64)
!91 = !DIBasicType(name: "long int", size: 64, encoding: DW_ATE_signed)
!92 = !DIDerivedType(tag: DW_TAG_member, name: "rem", scope: !88, file: !79, line: 69, baseType: !91, size: 64, offset: 64)
!93 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !94, line: 130)
!94 = !DISubprogram(name: "abort", scope: !79, file: !79, line: 588, type: !95, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!95 = !DISubroutineType(types: !96)
!96 = !{null}
!97 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !98, line: 134)
!98 = !DISubprogram(name: "atexit", scope: !79, file: !79, line: 592, type: !99, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!99 = !DISubroutineType(types: !100)
!100 = !{!82, !101}
!101 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !95, size: 64)
!102 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !103, line: 137)
!103 = !DISubprogram(name: "at_quick_exit", scope: !79, file: !79, line: 597, type: !99, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!104 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !105, line: 140)
!105 = !DISubprogram(name: "atof", scope: !79, file: !79, line: 101, type: !106, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!106 = !DISubroutineType(types: !107)
!107 = !{!108, !109}
!108 = !DIBasicType(name: "double", size: 64, encoding: DW_ATE_float)
!109 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !110, size: 64)
!110 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !111)
!111 = !DIBasicType(name: "char", size: 8, encoding: DW_ATE_signed_char)
!112 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !113, line: 141)
!113 = !DISubprogram(name: "atoi", scope: !79, file: !79, line: 104, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!114 = !DISubroutineType(types: !115)
!115 = !{!82, !109}
!116 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !117, line: 142)
!117 = !DISubprogram(name: "atol", scope: !79, file: !79, line: 107, type: !118, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!118 = !DISubroutineType(types: !119)
!119 = !{!91, !109}
!120 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !121, line: 143)
!121 = !DISubprogram(name: "bsearch", scope: !79, file: !79, line: 817, type: !122, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!122 = !DISubroutineType(types: !123)
!123 = !{!124, !68, !68, !125, !125, !128}
!124 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: null, size: 64)
!125 = !DIDerivedType(tag: DW_TAG_typedef, name: "size_t", file: !126, line: 62, baseType: !127)
!126 = !DIFile(filename: "/home/ubuntu/Github/remill/remill-build/libraries/llvm/bin/../lib/clang/4.0.1/include/stddef.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!127 = !DIBasicType(name: "long unsigned int", size: 64, encoding: DW_ATE_unsigned)
!128 = !DIDerivedType(tag: DW_TAG_typedef, name: "__compar_fn_t", file: !79, line: 805, baseType: !129)
!129 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !130, size: 64)
!130 = !DISubroutineType(types: !131)
!131 = !{!82, !68, !68}
!132 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !133, line: 144)
!133 = !DISubprogram(name: "calloc", scope: !79, file: !79, line: 541, type: !134, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!134 = !DISubroutineType(types: !135)
!135 = !{!124, !125, !125}
!136 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !137, line: 145)
!137 = !DISubprogram(name: "div", scope: !79, file: !79, line: 849, type: !138, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!138 = !DISubroutineType(types: !139)
!139 = !{!84, !82, !82}
!140 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !141, line: 146)
!141 = !DISubprogram(name: "exit", scope: !79, file: !79, line: 614, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!142 = !DISubroutineType(types: !143)
!143 = !{null, !82}
!144 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !145, line: 147)
!145 = !DISubprogram(name: "free", scope: !79, file: !79, line: 563, type: !146, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!146 = !DISubroutineType(types: !147)
!147 = !{null, !124}
!148 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !149, line: 148)
!149 = !DISubprogram(name: "getenv", scope: !79, file: !79, line: 631, type: !150, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!150 = !DISubroutineType(types: !151)
!151 = !{!152, !109}
!152 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !111, size: 64)
!153 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !154, line: 149)
!154 = !DISubprogram(name: "labs", scope: !79, file: !79, line: 838, type: !155, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!155 = !DISubroutineType(types: !156)
!156 = !{!91, !91}
!157 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !158, line: 150)
!158 = !DISubprogram(name: "ldiv", scope: !79, file: !79, line: 851, type: !159, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!159 = !DISubroutineType(types: !160)
!160 = !{!87, !91, !91}
!161 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !162, line: 151)
!162 = !DISubprogram(name: "malloc", scope: !79, file: !79, line: 539, type: !163, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!163 = !DISubroutineType(types: !164)
!164 = !{!124, !125}
!165 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !166, line: 153)
!166 = !DISubprogram(name: "mblen", scope: !79, file: !79, line: 919, type: !167, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!167 = !DISubroutineType(types: !168)
!168 = !{!82, !109, !125}
!169 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !170, line: 154)
!170 = !DISubprogram(name: "mbstowcs", scope: !79, file: !79, line: 930, type: !171, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!171 = !DISubroutineType(types: !172)
!172 = !{!125, !173, !176, !125}
!173 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !174)
!174 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !175, size: 64)
!175 = !DIBasicType(name: "wchar_t", size: 32, encoding: DW_ATE_signed)
!176 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !109)
!177 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !178, line: 155)
!178 = !DISubprogram(name: "mbtowc", scope: !79, file: !79, line: 922, type: !179, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!179 = !DISubroutineType(types: !180)
!180 = !{!82, !173, !176, !125}
!181 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !182, line: 157)
!182 = !DISubprogram(name: "qsort", scope: !79, file: !79, line: 827, type: !183, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!183 = !DISubroutineType(types: !184)
!184 = !{null, !124, !125, !125, !128}
!185 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !186, line: 160)
!186 = !DISubprogram(name: "quick_exit", scope: !79, file: !79, line: 620, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!187 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !188, line: 163)
!188 = !DISubprogram(name: "rand", scope: !79, file: !79, line: 453, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!189 = !DISubroutineType(types: !190)
!190 = !{!82}
!191 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !192, line: 164)
!192 = !DISubprogram(name: "realloc", scope: !79, file: !79, line: 549, type: !193, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!193 = !DISubroutineType(types: !194)
!194 = !{!124, !124, !125}
!195 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !196, line: 165)
!196 = !DISubprogram(name: "srand", scope: !79, file: !79, line: 455, type: !197, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!197 = !DISubroutineType(types: !198)
!198 = !{null, !10}
!199 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !200, line: 166)
!200 = !DISubprogram(name: "strtod", scope: !79, file: !79, line: 117, type: !201, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!201 = !DISubroutineType(types: !202)
!202 = !{!108, !176, !203}
!203 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !204)
!204 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !152, size: 64)
!205 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !206, line: 167)
!206 = !DISubprogram(name: "strtol", scope: !79, file: !79, line: 176, type: !207, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!207 = !DISubroutineType(types: !208)
!208 = !{!91, !176, !203, !82}
!209 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !210, line: 168)
!210 = !DISubprogram(name: "strtoul", scope: !79, file: !79, line: 180, type: !211, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!211 = !DISubroutineType(types: !212)
!212 = !{!127, !176, !203, !82}
!213 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !214, line: 169)
!214 = !DISubprogram(name: "system", scope: !79, file: !79, line: 781, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!215 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !216, line: 171)
!216 = !DISubprogram(name: "wcstombs", scope: !79, file: !79, line: 933, type: !217, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!217 = !DISubroutineType(types: !218)
!218 = !{!125, !219, !220, !125}
!219 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !152)
!220 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !221)
!221 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !222, size: 64)
!222 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !175)
!223 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !224, line: 172)
!224 = !DISubprogram(name: "wctomb", scope: !79, file: !79, line: 926, type: !225, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!225 = !DISubroutineType(types: !226)
!226 = !{!82, !152, !175}
!227 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !229, line: 200)
!228 = !DINamespace(name: "__gnu_cxx", scope: null, file: !76, line: 255)
!229 = !DIDerivedType(tag: DW_TAG_typedef, name: "lldiv_t", file: !79, line: 80, baseType: !230)
!230 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 76, size: 128, elements: !231, identifier: "_ZTS7lldiv_t")
!231 = !{!232, !234}
!232 = !DIDerivedType(tag: DW_TAG_member, name: "quot", scope: !230, file: !79, line: 78, baseType: !233, size: 64)
!233 = !DIBasicType(name: "long long int", size: 64, encoding: DW_ATE_signed)
!234 = !DIDerivedType(tag: DW_TAG_member, name: "rem", scope: !230, file: !79, line: 79, baseType: !233, size: 64, offset: 64)
!235 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !236, line: 206)
!236 = !DISubprogram(name: "_Exit", scope: !79, file: !79, line: 626, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!237 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !238, line: 210)
!238 = !DISubprogram(name: "llabs", scope: !79, file: !79, line: 841, type: !239, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!239 = !DISubroutineType(types: !240)
!240 = !{!233, !233}
!241 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !242, line: 216)
!242 = !DISubprogram(name: "lldiv", scope: !79, file: !79, line: 855, type: !243, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!243 = !DISubroutineType(types: !244)
!244 = !{!229, !233, !233}
!245 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !246, line: 227)
!246 = !DISubprogram(name: "atoll", scope: !79, file: !79, line: 112, type: !247, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!247 = !DISubroutineType(types: !248)
!248 = !{!233, !109}
!249 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !250, line: 228)
!250 = !DISubprogram(name: "strtoll", scope: !79, file: !79, line: 200, type: !251, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!251 = !DISubroutineType(types: !252)
!252 = !{!233, !176, !203, !82}
!253 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !254, line: 229)
!254 = !DISubprogram(name: "strtoull", scope: !79, file: !79, line: 205, type: !255, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!255 = !DISubroutineType(types: !256)
!256 = !{!257, !176, !203, !82}
!257 = !DIBasicType(name: "long long unsigned int", size: 64, encoding: DW_ATE_unsigned)
!258 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !259, line: 231)
!259 = !DISubprogram(name: "strtof", scope: !79, file: !79, line: 123, type: !260, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!260 = !DISubroutineType(types: !261)
!261 = !{!262, !176, !203}
!262 = !DIBasicType(name: "float", size: 32, encoding: DW_ATE_float)
!263 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !264, line: 232)
!264 = !DISubprogram(name: "strtold", scope: !79, file: !79, line: 126, type: !265, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!265 = !DISubroutineType(types: !266)
!266 = !{!267, !176, !203}
!267 = !DIBasicType(name: "long double", size: 128, encoding: DW_ATE_float)
!268 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !229, line: 240)
!269 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !236, line: 242)
!270 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !238, line: 244)
!271 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !272, line: 245)
!272 = !DISubprogram(name: "div", linkageName: "_ZN9__gnu_cxx3divExx", scope: !228, file: !273, line: 213, type: !243, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!273 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/cstdlib", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!274 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !242, line: 246)
!275 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !246, line: 248)
!276 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !259, line: 249)
!277 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !250, line: 250)
!278 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !254, line: 251)
!279 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !264, line: 252)
!280 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !281, line: 57)
!281 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "exception_ptr", scope: !283, file: !282, line: 79, size: 64, elements: !284, identifier: "_ZTSNSt15__exception_ptr13exception_ptrE")
!282 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/bits/exception_ptr.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!283 = !DINamespace(name: "__exception_ptr", scope: !75, file: !282, line: 52)
!284 = !{!285, !286, !290, !293, !294, !299, !300, !304, !309, !313, !317, !320, !321, !324, !328}
!285 = !DIDerivedType(tag: DW_TAG_member, name: "_M_exception_object", scope: !281, file: !282, line: 81, baseType: !124, size: 64)
!286 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 83, type: !287, isLocal: false, isDefinition: false, scopeLine: 83, flags: DIFlagExplicit | DIFlagPrototyped, isOptimized: false)
!287 = !DISubroutineType(types: !288)
!288 = !{null, !289, !124}
!289 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !281, size: 64, flags: DIFlagArtificial | DIFlagObjectPointer)
!290 = !DISubprogram(name: "_M_addref", linkageName: "_ZNSt15__exception_ptr13exception_ptr9_M_addrefEv", scope: !281, file: !282, line: 85, type: !291, isLocal: false, isDefinition: false, scopeLine: 85, flags: DIFlagPrototyped, isOptimized: false)
!291 = !DISubroutineType(types: !292)
!292 = !{null, !289}
!293 = !DISubprogram(name: "_M_release", linkageName: "_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv", scope: !281, file: !282, line: 86, type: !291, isLocal: false, isDefinition: false, scopeLine: 86, flags: DIFlagPrototyped, isOptimized: false)
!294 = !DISubprogram(name: "_M_get", linkageName: "_ZNKSt15__exception_ptr13exception_ptr6_M_getEv", scope: !281, file: !282, line: 88, type: !295, isLocal: false, isDefinition: false, scopeLine: 88, flags: DIFlagPrototyped, isOptimized: false)
!295 = !DISubroutineType(types: !296)
!296 = !{!124, !297}
!297 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !298, size: 64, flags: DIFlagArtificial | DIFlagObjectPointer)
!298 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !281)
!299 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 96, type: !291, isLocal: false, isDefinition: false, scopeLine: 96, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!300 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 98, type: !301, isLocal: false, isDefinition: false, scopeLine: 98, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!301 = !DISubroutineType(types: !302)
!302 = !{null, !289, !303}
!303 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !298, size: 64)
!304 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 101, type: !305, isLocal: false, isDefinition: false, scopeLine: 101, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!305 = !DISubroutineType(types: !306)
!306 = !{null, !289, !307}
!307 = !DIDerivedType(tag: DW_TAG_typedef, name: "nullptr_t", scope: !75, file: !76, line: 235, baseType: !308)
!308 = !DIBasicType(tag: DW_TAG_unspecified_type, name: "decltype(nullptr)")
!309 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 105, type: !310, isLocal: false, isDefinition: false, scopeLine: 105, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!310 = !DISubroutineType(types: !311)
!311 = !{null, !289, !312}
!312 = !DIDerivedType(tag: DW_TAG_rvalue_reference_type, baseType: !281, size: 64)
!313 = !DISubprogram(name: "operator=", linkageName: "_ZNSt15__exception_ptr13exception_ptraSERKS0_", scope: !281, file: !282, line: 118, type: !314, isLocal: false, isDefinition: false, scopeLine: 118, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!314 = !DISubroutineType(types: !315)
!315 = !{!316, !289, !303}
!316 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !281, size: 64)
!317 = !DISubprogram(name: "operator=", linkageName: "_ZNSt15__exception_ptr13exception_ptraSEOS0_", scope: !281, file: !282, line: 122, type: !318, isLocal: false, isDefinition: false, scopeLine: 122, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!318 = !DISubroutineType(types: !319)
!319 = !{!316, !289, !312}
!320 = !DISubprogram(name: "~exception_ptr", scope: !281, file: !282, line: 129, type: !291, isLocal: false, isDefinition: false, scopeLine: 129, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!321 = !DISubprogram(name: "swap", linkageName: "_ZNSt15__exception_ptr13exception_ptr4swapERS0_", scope: !281, file: !282, line: 132, type: !322, isLocal: false, isDefinition: false, scopeLine: 132, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!322 = !DISubroutineType(types: !323)
!323 = !{null, !289, !316}
!324 = !DISubprogram(name: "operator bool", linkageName: "_ZNKSt15__exception_ptr13exception_ptrcvbEv", scope: !281, file: !282, line: 144, type: !325, isLocal: false, isDefinition: false, scopeLine: 144, flags: DIFlagPublic | DIFlagExplicit | DIFlagPrototyped, isOptimized: false)
!325 = !DISubroutineType(types: !326)
!326 = !{!327, !297}
!327 = !DIBasicType(name: "bool", size: 8, encoding: DW_ATE_boolean)
!328 = !DISubprogram(name: "__cxa_exception_type", linkageName: "_ZNKSt15__exception_ptr13exception_ptr20__cxa_exception_typeEv", scope: !281, file: !282, line: 153, type: !329, isLocal: false, isDefinition: false, scopeLine: 153, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!329 = !DISubroutineType(types: !330)
!330 = !{!331, !297}
!331 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !332, size: 64)
!332 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !333)
!333 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "type_info", scope: !75, file: !334, line: 88, flags: DIFlagFwdDecl, identifier: "_ZTSSt9type_info")
!334 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/typeinfo", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!335 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !283, entity: !336, line: 73)
!336 = !DISubprogram(name: "rethrow_exception", linkageName: "_ZSt17rethrow_exceptionNSt15__exception_ptr13exception_ptrE", scope: !75, file: !282, line: 69, type: !337, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!337 = !DISubroutineType(types: !338)
!338 = !{null, !281}
!339 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !340, line: 64)
!340 = !DIDerivedType(tag: DW_TAG_typedef, name: "mbstate_t", file: !341, line: 6, baseType: !342)
!341 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/mbstate_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!342 = !DIDerivedType(tag: DW_TAG_typedef, name: "__mbstate_t", file: !343, line: 21, baseType: !344)
!343 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/__mbstate_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!344 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !343, line: 13, size: 64, elements: !345, identifier: "_ZTS11__mbstate_t")
!345 = !{!346, !347}
!346 = !DIDerivedType(tag: DW_TAG_member, name: "__count", scope: !344, file: !343, line: 15, baseType: !82, size: 32)
!347 = !DIDerivedType(tag: DW_TAG_member, name: "__value", scope: !344, file: !343, line: 20, baseType: !348, size: 32, offset: 32)
!348 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !344, file: !343, line: 16, size: 32, elements: !349, identifier: "_ZTSN11__mbstate_tUt_E")
!349 = !{!350, !351}
!350 = !DIDerivedType(tag: DW_TAG_member, name: "__wch", scope: !348, file: !343, line: 18, baseType: !10, size: 32)
!351 = !DIDerivedType(tag: DW_TAG_member, name: "__wchb", scope: !348, file: !343, line: 19, baseType: !352, size: 32)
!352 = !DICompositeType(tag: DW_TAG_array_type, baseType: !111, size: 32, elements: !353)
!353 = !{!354}
!354 = !DISubrange(count: 4)
!355 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !356, line: 139)
!356 = !DIDerivedType(tag: DW_TAG_typedef, name: "wint_t", file: !357, line: 20, baseType: !10)
!357 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/wint_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!358 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !359, line: 141)
!359 = !DISubprogram(name: "btowc", scope: !360, file: !360, line: 284, type: !361, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!360 = !DIFile(filename: "/usr/include/wchar.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!361 = !DISubroutineType(types: !362)
!362 = !{!356, !82}
!363 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !364, line: 142)
!364 = !DISubprogram(name: "fgetwc", scope: !360, file: !360, line: 727, type: !365, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!365 = !DISubroutineType(types: !366)
!366 = !{!356, !367}
!367 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !368, size: 64)
!368 = !DIDerivedType(tag: DW_TAG_typedef, name: "__FILE", file: !369, line: 5, baseType: !370)
!369 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/__FILE.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!370 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "_IO_FILE", file: !369, line: 4, flags: DIFlagFwdDecl, identifier: "_ZTS8_IO_FILE")
!371 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !372, line: 143)
!372 = !DISubprogram(name: "fgetws", scope: !360, file: !360, line: 756, type: !373, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!373 = !DISubroutineType(types: !374)
!374 = !{!174, !173, !82, !375}
!375 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !367)
!376 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !377, line: 144)
!377 = !DISubprogram(name: "fputwc", scope: !360, file: !360, line: 741, type: !378, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!378 = !DISubroutineType(types: !379)
!379 = !{!356, !175, !367}
!380 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !381, line: 145)
!381 = !DISubprogram(name: "fputws", scope: !360, file: !360, line: 763, type: !382, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!382 = !DISubroutineType(types: !383)
!383 = !{!82, !220, !375}
!384 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !385, line: 146)
!385 = !DISubprogram(name: "fwide", scope: !360, file: !360, line: 573, type: !386, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!386 = !DISubroutineType(types: !387)
!387 = !{!82, !367, !82}
!388 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !389, line: 147)
!389 = !DISubprogram(name: "fwprintf", scope: !360, file: !360, line: 580, type: !390, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!390 = !DISubroutineType(types: !391)
!391 = !{!82, !375, !220, null}
!392 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !393, line: 148)
!393 = !DISubprogram(name: "fwscanf", scope: !360, file: !360, line: 621, type: !390, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!394 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !395, line: 149)
!395 = !DISubprogram(name: "getwc", scope: !360, file: !360, line: 728, type: !365, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!396 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !397, line: 150)
!397 = !DISubprogram(name: "getwchar", scope: !360, file: !360, line: 734, type: !398, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!398 = !DISubroutineType(types: !399)
!399 = !{!356}
!400 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !401, line: 151)
!401 = !DISubprogram(name: "mbrlen", scope: !360, file: !360, line: 307, type: !402, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!402 = !DISubroutineType(types: !403)
!403 = !{!125, !176, !125, !404}
!404 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !405)
!405 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !340, size: 64)
!406 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !407, line: 152)
!407 = !DISubprogram(name: "mbrtowc", scope: !360, file: !360, line: 296, type: !408, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!408 = !DISubroutineType(types: !409)
!409 = !{!125, !173, !176, !125, !404}
!410 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !411, line: 153)
!411 = !DISubprogram(name: "mbsinit", scope: !360, file: !360, line: 292, type: !412, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!412 = !DISubroutineType(types: !413)
!413 = !{!82, !414}
!414 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !415, size: 64)
!415 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !340)
!416 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !417, line: 154)
!417 = !DISubprogram(name: "mbsrtowcs", scope: !360, file: !360, line: 337, type: !418, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!418 = !DISubroutineType(types: !419)
!419 = !{!125, !173, !420, !125, !404}
!420 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !421)
!421 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !109, size: 64)
!422 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !423, line: 155)
!423 = !DISubprogram(name: "putwc", scope: !360, file: !360, line: 742, type: !378, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!424 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !425, line: 156)
!425 = !DISubprogram(name: "putwchar", scope: !360, file: !360, line: 748, type: !426, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!426 = !DISubroutineType(types: !427)
!427 = !{!356, !175}
!428 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !429, line: 158)
!429 = !DISubprogram(name: "swprintf", scope: !360, file: !360, line: 590, type: !430, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!430 = !DISubroutineType(types: !431)
!431 = !{!82, !173, !125, !220, null}
!432 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !433, line: 160)
!433 = !DISubprogram(name: "swscanf", scope: !360, file: !360, line: 631, type: !434, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!434 = !DISubroutineType(types: !435)
!435 = !{!82, !220, !220, null}
!436 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !437, line: 161)
!437 = !DISubprogram(name: "ungetwc", scope: !360, file: !360, line: 771, type: !438, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!438 = !DISubroutineType(types: !439)
!439 = !{!356, !356, !367}
!440 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !441, line: 162)
!441 = !DISubprogram(name: "vfwprintf", scope: !360, file: !360, line: 598, type: !442, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!442 = !DISubroutineType(types: !443)
!443 = !{!82, !375, !220, !444}
!444 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !445, size: 64)
!445 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "__va_list_tag", file: !2, size: 192, elements: !446, identifier: "_ZTS13__va_list_tag")
!446 = !{!447, !448, !449, !450}
!447 = !DIDerivedType(tag: DW_TAG_member, name: "gp_offset", scope: !445, file: !2, baseType: !10, size: 32)
!448 = !DIDerivedType(tag: DW_TAG_member, name: "fp_offset", scope: !445, file: !2, baseType: !10, size: 32, offset: 32)
!449 = !DIDerivedType(tag: DW_TAG_member, name: "overflow_arg_area", scope: !445, file: !2, baseType: !124, size: 64, offset: 64)
!450 = !DIDerivedType(tag: DW_TAG_member, name: "reg_save_area", scope: !445, file: !2, baseType: !124, size: 64, offset: 128)
!451 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !452, line: 164)
!452 = !DISubprogram(name: "vfwscanf", scope: !360, file: !360, line: 673, type: !442, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!453 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !454, line: 167)
!454 = !DISubprogram(name: "vswprintf", scope: !360, file: !360, line: 611, type: !455, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!455 = !DISubroutineType(types: !456)
!456 = !{!82, !173, !125, !220, !444}
!457 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !458, line: 170)
!458 = !DISubprogram(name: "vswscanf", scope: !360, file: !360, line: 685, type: !459, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!459 = !DISubroutineType(types: !460)
!460 = !{!82, !220, !220, !444}
!461 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !462, line: 172)
!462 = !DISubprogram(name: "vwprintf", scope: !360, file: !360, line: 606, type: !463, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!463 = !DISubroutineType(types: !464)
!464 = !{!82, !220, !444}
!465 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !466, line: 174)
!466 = !DISubprogram(name: "vwscanf", scope: !360, file: !360, line: 681, type: !463, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!467 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !468, line: 176)
!468 = !DISubprogram(name: "wcrtomb", scope: !360, file: !360, line: 301, type: !469, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!469 = !DISubroutineType(types: !470)
!470 = !{!125, !219, !175, !404}
!471 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !472, line: 177)
!472 = !DISubprogram(name: "wcscat", scope: !360, file: !360, line: 97, type: !473, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!473 = !DISubroutineType(types: !474)
!474 = !{!174, !173, !220}
!475 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !476, line: 178)
!476 = !DISubprogram(name: "wcscmp", scope: !360, file: !360, line: 106, type: !477, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!477 = !DISubroutineType(types: !478)
!478 = !{!82, !221, !221}
!479 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !480, line: 179)
!480 = !DISubprogram(name: "wcscoll", scope: !360, file: !360, line: 131, type: !477, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!481 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !482, line: 180)
!482 = !DISubprogram(name: "wcscpy", scope: !360, file: !360, line: 87, type: !473, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!483 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !484, line: 181)
!484 = !DISubprogram(name: "wcscspn", scope: !360, file: !360, line: 187, type: !485, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!485 = !DISubroutineType(types: !486)
!486 = !{!125, !221, !221}
!487 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !488, line: 182)
!488 = !DISubprogram(name: "wcsftime", scope: !360, file: !360, line: 835, type: !489, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!489 = !DISubroutineType(types: !490)
!490 = !{!125, !173, !125, !220, !491}
!491 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !492)
!492 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !493, size: 64)
!493 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !494)
!494 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "tm", file: !360, line: 83, flags: DIFlagFwdDecl, identifier: "_ZTS2tm")
!495 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !496, line: 183)
!496 = !DISubprogram(name: "wcslen", scope: !360, file: !360, line: 222, type: !497, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!497 = !DISubroutineType(types: !498)
!498 = !{!125, !221}
!499 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !500, line: 184)
!500 = !DISubprogram(name: "wcsncat", scope: !360, file: !360, line: 101, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!501 = !DISubroutineType(types: !502)
!502 = !{!174, !173, !220, !125}
!503 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !504, line: 185)
!504 = !DISubprogram(name: "wcsncmp", scope: !360, file: !360, line: 109, type: !505, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!505 = !DISubroutineType(types: !506)
!506 = !{!82, !221, !221, !125}
!507 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !508, line: 186)
!508 = !DISubprogram(name: "wcsncpy", scope: !360, file: !360, line: 92, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!509 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !510, line: 187)
!510 = !DISubprogram(name: "wcsrtombs", scope: !360, file: !360, line: 343, type: !511, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!511 = !DISubroutineType(types: !512)
!512 = !{!125, !219, !513, !125, !404}
!513 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !514)
!514 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !221, size: 64)
!515 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !516, line: 188)
!516 = !DISubprogram(name: "wcsspn", scope: !360, file: !360, line: 191, type: !485, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!517 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !518, line: 189)
!518 = !DISubprogram(name: "wcstod", scope: !360, file: !360, line: 377, type: !519, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!519 = !DISubroutineType(types: !520)
!520 = !{!108, !220, !521}
!521 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !522)
!522 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !174, size: 64)
!523 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !524, line: 191)
!524 = !DISubprogram(name: "wcstof", scope: !360, file: !360, line: 382, type: !525, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!525 = !DISubroutineType(types: !526)
!526 = !{!262, !220, !521}
!527 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !528, line: 193)
!528 = !DISubprogram(name: "wcstok", scope: !360, file: !360, line: 217, type: !529, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!529 = !DISubroutineType(types: !530)
!530 = !{!174, !173, !220, !521}
!531 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !532, line: 194)
!532 = !DISubprogram(name: "wcstol", scope: !360, file: !360, line: 428, type: !533, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!533 = !DISubroutineType(types: !534)
!534 = !{!91, !220, !521, !82}
!535 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !536, line: 195)
!536 = !DISubprogram(name: "wcstoul", scope: !360, file: !360, line: 433, type: !537, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!537 = !DISubroutineType(types: !538)
!538 = !{!127, !220, !521, !82}
!539 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !540, line: 196)
!540 = !DISubprogram(name: "wcsxfrm", scope: !360, file: !360, line: 135, type: !541, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!541 = !DISubroutineType(types: !542)
!542 = !{!125, !173, !220, !125}
!543 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !544, line: 197)
!544 = !DISubprogram(name: "wctob", scope: !360, file: !360, line: 288, type: !545, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!545 = !DISubroutineType(types: !546)
!546 = !{!82, !356}
!547 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !548, line: 198)
!548 = !DISubprogram(name: "wmemcmp", scope: !360, file: !360, line: 258, type: !505, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!549 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !550, line: 199)
!550 = !DISubprogram(name: "wmemcpy", scope: !360, file: !360, line: 262, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!551 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !552, line: 200)
!552 = !DISubprogram(name: "wmemmove", scope: !360, file: !360, line: 267, type: !553, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!553 = !DISubroutineType(types: !554)
!554 = !{!174, !174, !221, !125}
!555 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !556, line: 201)
!556 = !DISubprogram(name: "wmemset", scope: !360, file: !360, line: 271, type: !557, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!557 = !DISubroutineType(types: !558)
!558 = !{!174, !174, !175, !125}
!559 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !560, line: 202)
!560 = !DISubprogram(name: "wprintf", scope: !360, file: !360, line: 587, type: !561, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!561 = !DISubroutineType(types: !562)
!562 = !{!82, !220, null}
!563 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !564, line: 203)
!564 = !DISubprogram(name: "wscanf", scope: !360, file: !360, line: 628, type: !561, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!565 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !566, line: 204)
!566 = !DISubprogram(name: "wcschr", scope: !360, file: !360, line: 164, type: !567, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!567 = !DISubroutineType(types: !568)
!568 = !{!174, !221, !175}
!569 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !570, line: 205)
!570 = !DISubprogram(name: "wcspbrk", scope: !360, file: !360, line: 201, type: !571, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!571 = !DISubroutineType(types: !572)
!572 = !{!174, !221, !221}
!573 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !574, line: 206)
!574 = !DISubprogram(name: "wcsrchr", scope: !360, file: !360, line: 174, type: !567, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!575 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !576, line: 207)
!576 = !DISubprogram(name: "wcsstr", scope: !360, file: !360, line: 212, type: !571, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!577 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !578, line: 208)
!578 = !DISubprogram(name: "wmemchr", scope: !360, file: !360, line: 253, type: !579, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!579 = !DISubroutineType(types: !580)
!580 = !{!174, !221, !175, !125}
!581 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !582, line: 248)
!582 = !DISubprogram(name: "wcstold", scope: !360, file: !360, line: 384, type: !583, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!583 = !DISubroutineType(types: !584)
!584 = !{!267, !220, !521}
!585 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !586, line: 257)
!586 = !DISubprogram(name: "wcstoll", scope: !360, file: !360, line: 441, type: !587, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!587 = !DISubroutineType(types: !588)
!588 = !{!233, !220, !521, !82}
!589 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !590, line: 258)
!590 = !DISubprogram(name: "wcstoull", scope: !360, file: !360, line: 448, type: !591, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!591 = !DISubroutineType(types: !592)
!592 = !{!257, !220, !521, !82}
!593 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !582, line: 264)
!594 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !586, line: 265)
!595 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !590, line: 266)
!596 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !524, line: 280)
!597 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !452, line: 283)
!598 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !458, line: 286)
!599 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !466, line: 289)
!600 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !582, line: 293)
!601 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !586, line: 294)
!602 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !590, line: 295)
!603 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !604, line: 48)
!604 = !DIDerivedType(tag: DW_TAG_typedef, name: "int8_t", file: !9, line: 235, baseType: !605)
!605 = !DIBasicType(name: "signed char", size: 8, encoding: DW_ATE_signed_char)
!606 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !607, line: 49)
!607 = !DIDerivedType(tag: DW_TAG_typedef, name: "int16_t", file: !9, line: 216, baseType: !608)
!608 = !DIBasicType(name: "short", size: 16, encoding: DW_ATE_signed)
!609 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !610, line: 50)
!610 = !DIDerivedType(tag: DW_TAG_typedef, name: "int32_t", file: !9, line: 178, baseType: !82)
!611 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !612, line: 51)
!612 = !DIDerivedType(tag: DW_TAG_typedef, name: "int64_t", file: !9, line: 107, baseType: !91)
!613 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !614, line: 53)
!614 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast8_t", file: !9, line: 245, baseType: !604)
!615 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !616, line: 54)
!616 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast16_t", file: !9, line: 228, baseType: !607)
!617 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !618, line: 55)
!618 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast32_t", file: !9, line: 197, baseType: !610)
!619 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !620, line: 56)
!620 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast64_t", file: !9, line: 123, baseType: !612)
!621 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !622, line: 58)
!622 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least8_t", file: !9, line: 243, baseType: !604)
!623 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !624, line: 59)
!624 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least16_t", file: !9, line: 226, baseType: !607)
!625 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !626, line: 60)
!626 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least32_t", file: !9, line: 195, baseType: !610)
!627 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !628, line: 61)
!628 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least64_t", file: !9, line: 121, baseType: !612)
!629 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !630, line: 63)
!630 = !DIDerivedType(tag: DW_TAG_typedef, name: "intmax_t", file: !9, line: 276, baseType: !91)
!631 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !632, line: 64)
!632 = !DIDerivedType(tag: DW_TAG_typedef, name: "intptr_t", file: !9, line: 263, baseType: !612)
!633 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !62, line: 66)
!634 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !28, line: 67)
!635 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !8, line: 68)
!636 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !637, line: 69)
!637 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint64_t", file: !9, line: 109, baseType: !127)
!638 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !639, line: 71)
!639 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast8_t", file: !9, line: 246, baseType: !62)
!640 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !641, line: 72)
!641 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast16_t", file: !9, line: 229, baseType: !28)
!642 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !643, line: 73)
!643 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast32_t", file: !9, line: 198, baseType: !8)
!644 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !645, line: 74)
!645 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast64_t", file: !9, line: 124, baseType: !637)
!646 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !647, line: 76)
!647 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least8_t", file: !9, line: 244, baseType: !62)
!648 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !649, line: 77)
!649 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least16_t", file: !9, line: 227, baseType: !28)
!650 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !651, line: 78)
!651 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least32_t", file: !9, line: 196, baseType: !8)
!652 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !653, line: 79)
!653 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least64_t", file: !9, line: 122, baseType: !637)
!654 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !655, line: 81)
!655 = !DIDerivedType(tag: DW_TAG_typedef, name: "uintmax_t", file: !9, line: 277, baseType: !127)
!656 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !657, line: 82)
!657 = !DIDerivedType(tag: DW_TAG_typedef, name: "uintptr_t", file: !9, line: 270, baseType: !637)
!658 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !659, line: 44)
!659 = !DIDerivedType(tag: DW_TAG_typedef, name: "size_t", scope: !75, file: !76, line: 231, baseType: !127)
!660 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !661, line: 45)
!661 = !DIDerivedType(tag: DW_TAG_typedef, name: "ptrdiff_t", scope: !75, file: !76, line: 232, baseType: !91)
!662 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !663, line: 53)
!663 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "lconv", file: !664, line: 51, flags: DIFlagFwdDecl, identifier: "_ZTS5lconv")
!664 = !DIFile(filename: "/usr/include/locale.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!665 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !666, line: 54)
!666 = !DISubprogram(name: "setlocale", scope: !664, file: !664, line: 122, type: !667, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!667 = !DISubroutineType(types: !668)
!668 = !{!152, !82, !109}
!669 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !670, line: 55)
!670 = !DISubprogram(name: "localeconv", scope: !664, file: !664, line: 125, type: !671, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!671 = !DISubroutineType(types: !672)
!672 = !{!673}
!673 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !663, size: 64)
!674 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !675, line: 64)
!675 = !DISubprogram(name: "isalnum", scope: !676, file: !676, line: 108, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!676 = !DIFile(filename: "/usr/include/ctype.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!677 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !678, line: 65)
!678 = !DISubprogram(name: "isalpha", scope: !676, file: !676, line: 109, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!679 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !680, line: 66)
!680 = !DISubprogram(name: "iscntrl", scope: !676, file: !676, line: 110, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!681 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !682, line: 67)
!682 = !DISubprogram(name: "isdigit", scope: !676, file: !676, line: 111, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!683 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !684, line: 68)
!684 = !DISubprogram(name: "isgraph", scope: !676, file: !676, line: 113, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!685 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !686, line: 69)
!686 = !DISubprogram(name: "islower", scope: !676, file: !676, line: 112, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!687 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !688, line: 70)
!688 = !DISubprogram(name: "isprint", scope: !676, file: !676, line: 114, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!689 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !690, line: 71)
!690 = !DISubprogram(name: "ispunct", scope: !676, file: !676, line: 115, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!691 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !692, line: 72)
!692 = !DISubprogram(name: "isspace", scope: !676, file: !676, line: 116, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!693 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !694, line: 73)
!694 = !DISubprogram(name: "isupper", scope: !676, file: !676, line: 117, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!695 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !696, line: 74)
!696 = !DISubprogram(name: "isxdigit", scope: !676, file: !676, line: 118, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!697 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !698, line: 75)
!698 = !DISubprogram(name: "tolower", scope: !676, file: !676, line: 122, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!699 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !700, line: 76)
!700 = !DISubprogram(name: "toupper", scope: !676, file: !676, line: 125, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!701 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !702, line: 87)
!702 = !DISubprogram(name: "isblank", scope: !676, file: !676, line: 130, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!703 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !704, line: 98)
!704 = !DIDerivedType(tag: DW_TAG_typedef, name: "FILE", file: !705, line: 7, baseType: !370)
!705 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/FILE.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!706 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !707, line: 99)
!707 = !DIDerivedType(tag: DW_TAG_typedef, name: "fpos_t", file: !708, line: 78, baseType: !709)
!708 = !DIFile(filename: "/usr/include/stdio.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!709 = !DIDerivedType(tag: DW_TAG_typedef, name: "_G_fpos_t", file: !710, line: 30, baseType: !711)
!710 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/_G_config.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!711 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !710, line: 26, flags: DIFlagFwdDecl, identifier: "_ZTS9_G_fpos_t")
!712 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !713, line: 101)
!713 = !DISubprogram(name: "clearerr", scope: !708, file: !708, line: 757, type: !714, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!714 = !DISubroutineType(types: !715)
!715 = !{null, !716}
!716 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !704, size: 64)
!717 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !718, line: 102)
!718 = !DISubprogram(name: "fclose", scope: !708, file: !708, line: 199, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!719 = !DISubroutineType(types: !720)
!720 = !{!82, !716}
!721 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !722, line: 103)
!722 = !DISubprogram(name: "feof", scope: !708, file: !708, line: 759, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!723 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !724, line: 104)
!724 = !DISubprogram(name: "ferror", scope: !708, file: !708, line: 761, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!725 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !726, line: 105)
!726 = !DISubprogram(name: "fflush", scope: !708, file: !708, line: 204, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!727 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !728, line: 106)
!728 = !DISubprogram(name: "fgetc", scope: !708, file: !708, line: 477, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!729 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !730, line: 107)
!730 = !DISubprogram(name: "fgetpos", scope: !708, file: !708, line: 731, type: !731, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!731 = !DISubroutineType(types: !732)
!732 = !{!82, !733, !734}
!733 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !716)
!734 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !735)
!735 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !707, size: 64)
!736 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !737, line: 108)
!737 = !DISubprogram(name: "fgets", scope: !708, file: !708, line: 564, type: !738, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!738 = !DISubroutineType(types: !739)
!739 = !{!152, !219, !82, !733}
!740 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !741, line: 109)
!741 = !DISubprogram(name: "fopen", scope: !708, file: !708, line: 232, type: !742, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!742 = !DISubroutineType(types: !743)
!743 = !{!716, !176, !176}
!744 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !745, line: 110)
!745 = !DISubprogram(name: "fprintf", scope: !708, file: !708, line: 312, type: !746, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!746 = !DISubroutineType(types: !747)
!747 = !{!82, !733, !176, null}
!748 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !749, line: 111)
!749 = !DISubprogram(name: "fputc", scope: !708, file: !708, line: 517, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!750 = !DISubroutineType(types: !751)
!751 = !{!82, !82, !716}
!752 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !753, line: 112)
!753 = !DISubprogram(name: "fputs", scope: !708, file: !708, line: 626, type: !754, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!754 = !DISubroutineType(types: !755)
!755 = !{!82, !176, !733}
!756 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !757, line: 113)
!757 = !DISubprogram(name: "fread", scope: !708, file: !708, line: 646, type: !758, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!758 = !DISubroutineType(types: !759)
!759 = !{!125, !760, !125, !125, !733}
!760 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !124)
!761 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !762, line: 114)
!762 = !DISubprogram(name: "freopen", scope: !708, file: !708, line: 238, type: !763, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!763 = !DISubroutineType(types: !764)
!764 = !{!716, !176, !176, !733}
!765 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !766, line: 115)
!766 = !DISubprogram(name: "fscanf", scope: !708, file: !708, line: 377, type: !746, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!767 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !768, line: 116)
!768 = !DISubprogram(name: "fseek", scope: !708, file: !708, line: 684, type: !769, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!769 = !DISubroutineType(types: !770)
!770 = !{!82, !716, !91, !82}
!771 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !772, line: 117)
!772 = !DISubprogram(name: "fsetpos", scope: !708, file: !708, line: 736, type: !773, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!773 = !DISubroutineType(types: !774)
!774 = !{!82, !716, !775}
!775 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !776, size: 64)
!776 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !707)
!777 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !778, line: 118)
!778 = !DISubprogram(name: "ftell", scope: !708, file: !708, line: 689, type: !779, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!779 = !DISubroutineType(types: !780)
!780 = !{!91, !716}
!781 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !782, line: 119)
!782 = !DISubprogram(name: "fwrite", scope: !708, file: !708, line: 652, type: !783, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!783 = !DISubroutineType(types: !784)
!784 = !{!125, !785, !125, !125, !733}
!785 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !68)
!786 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !787, line: 120)
!787 = !DISubprogram(name: "getc", scope: !708, file: !708, line: 478, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!788 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !789, line: 121)
!789 = !DISubprogram(name: "getchar", scope: !708, file: !708, line: 484, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!790 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !791, line: 124)
!791 = !DISubprogram(name: "gets", scope: !708, file: !708, line: 577, type: !792, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!792 = !DISubroutineType(types: !793)
!793 = !{!152, !152}
!794 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !795, line: 126)
!795 = !DISubprogram(name: "perror", scope: !708, file: !708, line: 775, type: !796, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!796 = !DISubroutineType(types: !797)
!797 = !{null, !109}
!798 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !799, line: 127)
!799 = !DISubprogram(name: "printf", scope: !708, file: !708, line: 318, type: !800, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!800 = !DISubroutineType(types: !801)
!801 = !{!82, !176, null}
!802 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !803, line: 128)
!803 = !DISubprogram(name: "putc", scope: !708, file: !708, line: 518, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!804 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !805, line: 129)
!805 = !DISubprogram(name: "putchar", scope: !708, file: !708, line: 524, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!806 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !807, line: 130)
!807 = !DISubprogram(name: "puts", scope: !708, file: !708, line: 632, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!808 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !809, line: 131)
!809 = !DISubprogram(name: "remove", scope: !708, file: !708, line: 144, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!810 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !811, line: 132)
!811 = !DISubprogram(name: "rename", scope: !708, file: !708, line: 146, type: !812, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!812 = !DISubroutineType(types: !813)
!813 = !{!82, !109, !109}
!814 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !815, line: 133)
!815 = !DISubprogram(name: "rewind", scope: !708, file: !708, line: 694, type: !714, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!816 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !817, line: 134)
!817 = !DISubprogram(name: "scanf", scope: !708, file: !708, line: 383, type: !800, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!818 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !819, line: 135)
!819 = !DISubprogram(name: "setbuf", scope: !708, file: !708, line: 290, type: !820, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!820 = !DISubroutineType(types: !821)
!821 = !{null, !733, !219}
!822 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !823, line: 136)
!823 = !DISubprogram(name: "setvbuf", scope: !708, file: !708, line: 294, type: !824, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!824 = !DISubroutineType(types: !825)
!825 = !{!82, !733, !219, !82, !125}
!826 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !827, line: 137)
!827 = !DISubprogram(name: "sprintf", scope: !708, file: !708, line: 320, type: !828, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!828 = !DISubroutineType(types: !829)
!829 = !{!82, !219, !176, null}
!830 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !831, line: 138)
!831 = !DISubprogram(name: "sscanf", scope: !708, file: !708, line: 385, type: !832, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!832 = !DISubroutineType(types: !833)
!833 = !{!82, !176, !176, null}
!834 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !835, line: 139)
!835 = !DISubprogram(name: "tmpfile", scope: !708, file: !708, line: 159, type: !836, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!836 = !DISubroutineType(types: !837)
!837 = !{!716}
!838 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !839, line: 141)
!839 = !DISubprogram(name: "tmpnam", scope: !708, file: !708, line: 173, type: !792, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!840 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !841, line: 143)
!841 = !DISubprogram(name: "ungetc", scope: !708, file: !708, line: 639, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!842 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !843, line: 144)
!843 = !DISubprogram(name: "vfprintf", scope: !708, file: !708, line: 327, type: !844, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!844 = !DISubroutineType(types: !845)
!845 = !{!82, !733, !176, !444}
!846 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !847, line: 145)
!847 = !DISubprogram(name: "vprintf", scope: !708, file: !708, line: 333, type: !848, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!848 = !DISubroutineType(types: !849)
!849 = !{!82, !176, !444}
!850 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !851, line: 146)
!851 = !DISubprogram(name: "vsprintf", scope: !708, file: !708, line: 335, type: !852, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!852 = !DISubroutineType(types: !853)
!853 = !{!82, !219, !176, !444}
!854 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !855, line: 175)
!855 = !DISubprogram(name: "snprintf", scope: !708, file: !708, line: 340, type: !856, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!856 = !DISubroutineType(types: !857)
!857 = !{!82, !219, !125, !176, null}
!858 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !859, line: 176)
!859 = !DISubprogram(name: "vfscanf", scope: !708, file: !708, line: 420, type: !844, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!860 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !861, line: 177)
!861 = !DISubprogram(name: "vscanf", scope: !708, file: !708, line: 428, type: !848, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!862 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !863, line: 178)
!863 = !DISubprogram(name: "vsnprintf", scope: !708, file: !708, line: 344, type: !864, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!864 = !DISubroutineType(types: !865)
!865 = !{!82, !219, !125, !176, !444}
!866 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !867, line: 179)
!867 = !DISubprogram(name: "vsscanf", scope: !708, file: !708, line: 432, type: !868, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!868 = !DISubroutineType(types: !869)
!869 = !{!82, !176, !176, !444}
!870 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !855, line: 185)
!871 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !859, line: 186)
!872 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !861, line: 187)
!873 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !863, line: 188)
!874 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !867, line: 189)
!875 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !876, line: 83)
!876 = !DISubprogram(name: "acos", scope: !877, file: !877, line: 53, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!877 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/mathcalls.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!878 = !DISubroutineType(types: !879)
!879 = !{!108, !108}
!880 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !881, line: 102)
!881 = !DISubprogram(name: "asin", scope: !877, file: !877, line: 55, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!882 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !883, line: 121)
!883 = !DISubprogram(name: "atan", scope: !877, file: !877, line: 57, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!884 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !885, line: 140)
!885 = !DISubprogram(name: "atan2", scope: !877, file: !877, line: 59, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!886 = !DISubroutineType(types: !887)
!887 = !{!108, !108, !108}
!888 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !889, line: 161)
!889 = !DISubprogram(name: "ceil", scope: !877, file: !877, line: 159, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!890 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !891, line: 180)
!891 = !DISubprogram(name: "cos", scope: !877, file: !877, line: 62, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!892 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !893, line: 199)
!893 = !DISubprogram(name: "cosh", scope: !877, file: !877, line: 71, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!894 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !895, line: 218)
!895 = !DISubprogram(name: "exp", scope: !877, file: !877, line: 95, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!896 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !897, line: 237)
!897 = !DISubprogram(name: "fabs", scope: !877, file: !877, line: 162, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!898 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !899, line: 256)
!899 = !DISubprogram(name: "floor", scope: !877, file: !877, line: 165, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!900 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !901, line: 275)
!901 = !DISubprogram(name: "fmod", scope: !877, file: !877, line: 168, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!902 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !903, line: 296)
!903 = !DISubprogram(name: "frexp", scope: !877, file: !877, line: 98, type: !904, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!904 = !DISubroutineType(types: !905)
!905 = !{!108, !108, !906}
!906 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !82, size: 64)
!907 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !908, line: 315)
!908 = !DISubprogram(name: "ldexp", scope: !877, file: !877, line: 101, type: !909, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!909 = !DISubroutineType(types: !910)
!910 = !{!108, !108, !82}
!911 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !912, line: 334)
!912 = !DISubprogram(name: "log", scope: !877, file: !877, line: 104, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!913 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !914, line: 353)
!914 = !DISubprogram(name: "log10", scope: !877, file: !877, line: 107, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!915 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !916, line: 372)
!916 = !DISubprogram(name: "modf", scope: !877, file: !877, line: 110, type: !917, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!917 = !DISubroutineType(types: !918)
!918 = !{!108, !108, !919}
!919 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !108, size: 64)
!920 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !921, line: 384)
!921 = !DISubprogram(name: "pow", scope: !877, file: !877, line: 140, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!922 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !923, line: 421)
!923 = !DISubprogram(name: "sin", scope: !877, file: !877, line: 64, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!924 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !925, line: 440)
!925 = !DISubprogram(name: "sinh", scope: !877, file: !877, line: 73, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!926 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !927, line: 459)
!927 = !DISubprogram(name: "sqrt", scope: !877, file: !877, line: 143, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!928 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !929, line: 478)
!929 = !DISubprogram(name: "tan", scope: !877, file: !877, line: 66, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!930 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !931, line: 497)
!931 = !DISubprogram(name: "tanh", scope: !877, file: !877, line: 75, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!932 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !933, line: 1080)
!933 = !DIDerivedType(tag: DW_TAG_typedef, name: "double_t", file: !934, line: 150, baseType: !108)
!934 = !DIFile(filename: "/usr/include/math.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!935 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !936, line: 1081)
!936 = !DIDerivedType(tag: DW_TAG_typedef, name: "float_t", file: !934, line: 149, baseType: !262)
!937 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !938, line: 1084)
!938 = !DISubprogram(name: "acosh", scope: !877, file: !877, line: 85, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!939 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !940, line: 1085)
!940 = !DISubprogram(name: "acoshf", scope: !877, file: !877, line: 85, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!941 = !DISubroutineType(types: !942)
!942 = !{!262, !262}
!943 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !944, line: 1086)
!944 = !DISubprogram(name: "acoshl", scope: !877, file: !877, line: 85, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!945 = !DISubroutineType(types: !946)
!946 = !{!267, !267}
!947 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !948, line: 1088)
!948 = !DISubprogram(name: "asinh", scope: !877, file: !877, line: 87, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!949 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !950, line: 1089)
!950 = !DISubprogram(name: "asinhf", scope: !877, file: !877, line: 87, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!951 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !952, line: 1090)
!952 = !DISubprogram(name: "asinhl", scope: !877, file: !877, line: 87, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!953 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !954, line: 1092)
!954 = !DISubprogram(name: "atanh", scope: !877, file: !877, line: 89, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!955 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !956, line: 1093)
!956 = !DISubprogram(name: "atanhf", scope: !877, file: !877, line: 89, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!957 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !958, line: 1094)
!958 = !DISubprogram(name: "atanhl", scope: !877, file: !877, line: 89, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!959 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !960, line: 1096)
!960 = !DISubprogram(name: "cbrt", scope: !877, file: !877, line: 152, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!961 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !962, line: 1097)
!962 = !DISubprogram(name: "cbrtf", scope: !877, file: !877, line: 152, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!963 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !964, line: 1098)
!964 = !DISubprogram(name: "cbrtl", scope: !877, file: !877, line: 152, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!965 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !966, line: 1100)
!966 = !DISubprogram(name: "copysign", scope: !877, file: !877, line: 196, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!967 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !968, line: 1101)
!968 = !DISubprogram(name: "copysignf", scope: !877, file: !877, line: 196, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!969 = !DISubroutineType(types: !970)
!970 = !{!262, !262, !262}
!971 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !972, line: 1102)
!972 = !DISubprogram(name: "copysignl", scope: !877, file: !877, line: 196, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!973 = !DISubroutineType(types: !974)
!974 = !{!267, !267, !267}
!975 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !976, line: 1104)
!976 = !DISubprogram(name: "erf", scope: !877, file: !877, line: 228, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!977 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !978, line: 1105)
!978 = !DISubprogram(name: "erff", scope: !877, file: !877, line: 228, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!979 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !980, line: 1106)
!980 = !DISubprogram(name: "erfl", scope: !877, file: !877, line: 228, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!981 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !982, line: 1108)
!982 = !DISubprogram(name: "erfc", scope: !877, file: !877, line: 229, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!983 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !984, line: 1109)
!984 = !DISubprogram(name: "erfcf", scope: !877, file: !877, line: 229, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!985 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !986, line: 1110)
!986 = !DISubprogram(name: "erfcl", scope: !877, file: !877, line: 229, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!987 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !988, line: 1112)
!988 = !DISubprogram(name: "exp2", scope: !877, file: !877, line: 130, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!989 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !990, line: 1113)
!990 = !DISubprogram(name: "exp2f", scope: !877, file: !877, line: 130, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!991 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !992, line: 1114)
!992 = !DISubprogram(name: "exp2l", scope: !877, file: !877, line: 130, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!993 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !994, line: 1116)
!994 = !DISubprogram(name: "expm1", scope: !877, file: !877, line: 119, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!995 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !996, line: 1117)
!996 = !DISubprogram(name: "expm1f", scope: !877, file: !877, line: 119, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!997 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !998, line: 1118)
!998 = !DISubprogram(name: "expm1l", scope: !877, file: !877, line: 119, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!999 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1000, line: 1120)
!1000 = !DISubprogram(name: "fdim", scope: !877, file: !877, line: 326, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1001 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1002, line: 1121)
!1002 = !DISubprogram(name: "fdimf", scope: !877, file: !877, line: 326, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1003 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1004, line: 1122)
!1004 = !DISubprogram(name: "fdiml", scope: !877, file: !877, line: 326, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1005 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1006, line: 1124)
!1006 = !DISubprogram(name: "fma", scope: !877, file: !877, line: 335, type: !1007, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1007 = !DISubroutineType(types: !1008)
!1008 = !{!108, !108, !108, !108}
!1009 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1010, line: 1125)
!1010 = !DISubprogram(name: "fmaf", scope: !877, file: !877, line: 335, type: !1011, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1011 = !DISubroutineType(types: !1012)
!1012 = !{!262, !262, !262, !262}
!1013 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1014, line: 1126)
!1014 = !DISubprogram(name: "fmal", scope: !877, file: !877, line: 335, type: !1015, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1015 = !DISubroutineType(types: !1016)
!1016 = !{!267, !267, !267, !267}
!1017 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1018, line: 1128)
!1018 = !DISubprogram(name: "fmax", scope: !877, file: !877, line: 329, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1019 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1020, line: 1129)
!1020 = !DISubprogram(name: "fmaxf", scope: !877, file: !877, line: 329, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1021 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1022, line: 1130)
!1022 = !DISubprogram(name: "fmaxl", scope: !877, file: !877, line: 329, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1023 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1024, line: 1132)
!1024 = !DISubprogram(name: "fmin", scope: !877, file: !877, line: 332, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1025 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1026, line: 1133)
!1026 = !DISubprogram(name: "fminf", scope: !877, file: !877, line: 332, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1027 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1028, line: 1134)
!1028 = !DISubprogram(name: "fminl", scope: !877, file: !877, line: 332, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1029 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1030, line: 1136)
!1030 = !DISubprogram(name: "hypot", scope: !877, file: !877, line: 147, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1031 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1032, line: 1137)
!1032 = !DISubprogram(name: "hypotf", scope: !877, file: !877, line: 147, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1033 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1034, line: 1138)
!1034 = !DISubprogram(name: "hypotl", scope: !877, file: !877, line: 147, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1035 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1036, line: 1140)
!1036 = !DISubprogram(name: "ilogb", scope: !877, file: !877, line: 280, type: !1037, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1037 = !DISubroutineType(types: !1038)
!1038 = !{!82, !108}
!1039 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1040, line: 1141)
!1040 = !DISubprogram(name: "ilogbf", scope: !877, file: !877, line: 280, type: !1041, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1041 = !DISubroutineType(types: !1042)
!1042 = !{!82, !262}
!1043 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1044, line: 1142)
!1044 = !DISubprogram(name: "ilogbl", scope: !877, file: !877, line: 280, type: !1045, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1045 = !DISubroutineType(types: !1046)
!1046 = !{!82, !267}
!1047 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1048, line: 1144)
!1048 = !DISubprogram(name: "lgamma", scope: !877, file: !877, line: 230, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1049 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1050, line: 1145)
!1050 = !DISubprogram(name: "lgammaf", scope: !877, file: !877, line: 230, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1051 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1052, line: 1146)
!1052 = !DISubprogram(name: "lgammal", scope: !877, file: !877, line: 230, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1053 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1054, line: 1149)
!1054 = !DISubprogram(name: "llrint", scope: !877, file: !877, line: 316, type: !1055, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1055 = !DISubroutineType(types: !1056)
!1056 = !{!233, !108}
!1057 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1058, line: 1150)
!1058 = !DISubprogram(name: "llrintf", scope: !877, file: !877, line: 316, type: !1059, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1059 = !DISubroutineType(types: !1060)
!1060 = !{!233, !262}
!1061 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1062, line: 1151)
!1062 = !DISubprogram(name: "llrintl", scope: !877, file: !877, line: 316, type: !1063, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1063 = !DISubroutineType(types: !1064)
!1064 = !{!233, !267}
!1065 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1066, line: 1153)
!1066 = !DISubprogram(name: "llround", scope: !877, file: !877, line: 322, type: !1055, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1067 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1068, line: 1154)
!1068 = !DISubprogram(name: "llroundf", scope: !877, file: !877, line: 322, type: !1059, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1069 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1070, line: 1155)
!1070 = !DISubprogram(name: "llroundl", scope: !877, file: !877, line: 322, type: !1063, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1071 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1072, line: 1158)
!1072 = !DISubprogram(name: "log1p", scope: !877, file: !877, line: 122, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1073 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1074, line: 1159)
!1074 = !DISubprogram(name: "log1pf", scope: !877, file: !877, line: 122, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1075 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1076, line: 1160)
!1076 = !DISubprogram(name: "log1pl", scope: !877, file: !877, line: 122, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1077 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1078, line: 1162)
!1078 = !DISubprogram(name: "log2", scope: !877, file: !877, line: 133, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1079 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1080, line: 1163)
!1080 = !DISubprogram(name: "log2f", scope: !877, file: !877, line: 133, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1081 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1082, line: 1164)
!1082 = !DISubprogram(name: "log2l", scope: !877, file: !877, line: 133, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1083 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1084, line: 1166)
!1084 = !DISubprogram(name: "logb", scope: !877, file: !877, line: 125, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1085 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1086, line: 1167)
!1086 = !DISubprogram(name: "logbf", scope: !877, file: !877, line: 125, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1087 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1088, line: 1168)
!1088 = !DISubprogram(name: "logbl", scope: !877, file: !877, line: 125, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1089 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1090, line: 1170)
!1090 = !DISubprogram(name: "lrint", scope: !877, file: !877, line: 314, type: !1091, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1091 = !DISubroutineType(types: !1092)
!1092 = !{!91, !108}
!1093 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1094, line: 1171)
!1094 = !DISubprogram(name: "lrintf", scope: !877, file: !877, line: 314, type: !1095, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1095 = !DISubroutineType(types: !1096)
!1096 = !{!91, !262}
!1097 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1098, line: 1172)
!1098 = !DISubprogram(name: "lrintl", scope: !877, file: !877, line: 314, type: !1099, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1099 = !DISubroutineType(types: !1100)
!1100 = !{!91, !267}
!1101 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1102, line: 1174)
!1102 = !DISubprogram(name: "lround", scope: !877, file: !877, line: 320, type: !1091, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1103 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1104, line: 1175)
!1104 = !DISubprogram(name: "lroundf", scope: !877, file: !877, line: 320, type: !1095, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1105 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1106, line: 1176)
!1106 = !DISubprogram(name: "lroundl", scope: !877, file: !877, line: 320, type: !1099, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1107 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1108, line: 1178)
!1108 = !DISubprogram(name: "nan", scope: !877, file: !877, line: 201, type: !106, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1109 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1110, line: 1179)
!1110 = !DISubprogram(name: "nanf", scope: !877, file: !877, line: 201, type: !1111, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1111 = !DISubroutineType(types: !1112)
!1112 = !{!262, !109}
!1113 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1114, line: 1180)
!1114 = !DISubprogram(name: "nanl", scope: !877, file: !877, line: 201, type: !1115, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1115 = !DISubroutineType(types: !1116)
!1116 = !{!267, !109}
!1117 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1118, line: 1182)
!1118 = !DISubprogram(name: "nearbyint", scope: !877, file: !877, line: 294, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1119 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1120, line: 1183)
!1120 = !DISubprogram(name: "nearbyintf", scope: !877, file: !877, line: 294, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1121 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1122, line: 1184)
!1122 = !DISubprogram(name: "nearbyintl", scope: !877, file: !877, line: 294, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1123 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1124, line: 1186)
!1124 = !DISubprogram(name: "nextafter", scope: !877, file: !877, line: 259, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1125 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1126, line: 1187)
!1126 = !DISubprogram(name: "nextafterf", scope: !877, file: !877, line: 259, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1127 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1128, line: 1188)
!1128 = !DISubprogram(name: "nextafterl", scope: !877, file: !877, line: 259, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1129 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1130, line: 1190)
!1130 = !DISubprogram(name: "nexttoward", scope: !877, file: !877, line: 261, type: !1131, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1131 = !DISubroutineType(types: !1132)
!1132 = !{!108, !108, !267}
!1133 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1134, line: 1191)
!1134 = !DISubprogram(name: "nexttowardf", scope: !877, file: !877, line: 261, type: !1135, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1135 = !DISubroutineType(types: !1136)
!1136 = !{!262, !262, !267}
!1137 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1138, line: 1192)
!1138 = !DISubprogram(name: "nexttowardl", scope: !877, file: !877, line: 261, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1139 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1140, line: 1194)
!1140 = !DISubprogram(name: "remainder", scope: !877, file: !877, line: 272, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1141 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1142, line: 1195)
!1142 = !DISubprogram(name: "remainderf", scope: !877, file: !877, line: 272, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1143 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1144, line: 1196)
!1144 = !DISubprogram(name: "remainderl", scope: !877, file: !877, line: 272, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1145 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1146, line: 1198)
!1146 = !DISubprogram(name: "remquo", scope: !877, file: !877, line: 307, type: !1147, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1147 = !DISubroutineType(types: !1148)
!1148 = !{!108, !108, !108, !906}
!1149 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1150, line: 1199)
!1150 = !DISubprogram(name: "remquof", scope: !877, file: !877, line: 307, type: !1151, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1151 = !DISubroutineType(types: !1152)
!1152 = !{!262, !262, !262, !906}
!1153 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1154, line: 1200)
!1154 = !DISubprogram(name: "remquol", scope: !877, file: !877, line: 307, type: !1155, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1155 = !DISubroutineType(types: !1156)
!1156 = !{!267, !267, !267, !906}
!1157 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1158, line: 1202)
!1158 = !DISubprogram(name: "rint", scope: !877, file: !877, line: 256, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1159 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1160, line: 1203)
!1160 = !DISubprogram(name: "rintf", scope: !877, file: !877, line: 256, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1161 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1162, line: 1204)
!1162 = !DISubprogram(name: "rintl", scope: !877, file: !877, line: 256, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1163 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1164, line: 1206)
!1164 = !DISubprogram(name: "round", scope: !877, file: !877, line: 298, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1165 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1166, line: 1207)
!1166 = !DISubprogram(name: "roundf", scope: !877, file: !877, line: 298, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1167 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1168, line: 1208)
!1168 = !DISubprogram(name: "roundl", scope: !877, file: !877, line: 298, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1169 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1170, line: 1210)
!1170 = !DISubprogram(name: "scalbln", scope: !877, file: !877, line: 290, type: !1171, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1171 = !DISubroutineType(types: !1172)
!1172 = !{!108, !108, !91}
!1173 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1174, line: 1211)
!1174 = !DISubprogram(name: "scalblnf", scope: !877, file: !877, line: 290, type: !1175, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1175 = !DISubroutineType(types: !1176)
!1176 = !{!262, !262, !91}
!1177 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1178, line: 1212)
!1178 = !DISubprogram(name: "scalblnl", scope: !877, file: !877, line: 290, type: !1179, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1179 = !DISubroutineType(types: !1180)
!1180 = !{!267, !267, !91}
!1181 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1182, line: 1214)
!1182 = !DISubprogram(name: "scalbn", scope: !877, file: !877, line: 276, type: !909, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1183 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1184, line: 1215)
!1184 = !DISubprogram(name: "scalbnf", scope: !877, file: !877, line: 276, type: !1185, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1185 = !DISubroutineType(types: !1186)
!1186 = !{!262, !262, !82}
!1187 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1188, line: 1216)
!1188 = !DISubprogram(name: "scalbnl", scope: !877, file: !877, line: 276, type: !1189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1189 = !DISubroutineType(types: !1190)
!1190 = !{!267, !267, !82}
!1191 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1192, line: 1218)
!1192 = !DISubprogram(name: "tgamma", scope: !877, file: !877, line: 235, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1193 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1194, line: 1219)
!1194 = !DISubprogram(name: "tgammaf", scope: !877, file: !877, line: 235, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1195 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1196, line: 1220)
!1196 = !DISubprogram(name: "tgammal", scope: !877, file: !877, line: 235, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1197 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1198, line: 1222)
!1198 = !DISubprogram(name: "trunc", scope: !877, file: !877, line: 302, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1199 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1200, line: 1223)
!1200 = !DISubprogram(name: "truncf", scope: !877, file: !877, line: 302, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1201 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1202, line: 1224)
!1202 = !DISubprogram(name: "truncl", scope: !877, file: !877, line: 302, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1203 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1204, line: 58)
!1204 = !DIDerivedType(tag: DW_TAG_typedef, name: "fenv_t", file: !1205, line: 94, baseType: !1206)
!1205 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/fenv.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1206 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !1205, line: 75, flags: DIFlagFwdDecl, identifier: "_ZTS6fenv_t")
!1207 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1208, line: 59)
!1208 = !DIDerivedType(tag: DW_TAG_typedef, name: "fexcept_t", file: !1205, line: 68, baseType: !29)
!1209 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1210, line: 62)
!1210 = !DISubprogram(name: "feclearexcept", scope: !1211, file: !1211, line: 71, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1211 = !DIFile(filename: "/usr/include/fenv.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1212 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1213, line: 63)
!1213 = !DISubprogram(name: "fegetexceptflag", scope: !1211, file: !1211, line: 75, type: !1214, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1214 = !DISubroutineType(types: !1215)
!1215 = !{!82, !1216, !82}
!1216 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1208, size: 64)
!1217 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1218, line: 64)
!1218 = !DISubprogram(name: "feraiseexcept", scope: !1211, file: !1211, line: 78, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1219 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1220, line: 65)
!1220 = !DISubprogram(name: "fesetexceptflag", scope: !1211, file: !1211, line: 88, type: !1221, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1221 = !DISubroutineType(types: !1222)
!1222 = !{!82, !1223, !82}
!1223 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1224, size: 64)
!1224 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !1208)
!1225 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1226, line: 66)
!1226 = !DISubprogram(name: "fetestexcept", scope: !1211, file: !1211, line: 92, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1227 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1228, line: 68)
!1228 = !DISubprogram(name: "fegetround", scope: !1211, file: !1211, line: 104, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1229 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1230, line: 69)
!1230 = !DISubprogram(name: "fesetround", scope: !1211, file: !1211, line: 107, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1231 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1232, line: 71)
!1232 = !DISubprogram(name: "fegetenv", scope: !1211, file: !1211, line: 114, type: !1233, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1233 = !DISubroutineType(types: !1234)
!1234 = !{!82, !1235}
!1235 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1204, size: 64)
!1236 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1237, line: 72)
!1237 = !DISubprogram(name: "feholdexcept", scope: !1211, file: !1211, line: 119, type: !1233, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1238 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1239, line: 73)
!1239 = !DISubprogram(name: "fesetenv", scope: !1211, file: !1211, line: 123, type: !1240, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1240 = !DISubroutineType(types: !1241)
!1241 = !{!82, !1242}
!1242 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1243, size: 64)
!1243 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !1204)
!1244 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1245, line: 74)
!1245 = !DISubprogram(name: "feupdateenv", scope: !1211, file: !1211, line: 128, type: !1240, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1246 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1204, line: 61)
!1247 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1208, line: 62)
!1248 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1210, line: 65)
!1249 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1213, line: 66)
!1250 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1218, line: 67)
!1251 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1220, line: 68)
!1252 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1226, line: 69)
!1253 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1228, line: 71)
!1254 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1230, line: 72)
!1255 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1232, line: 74)
!1256 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1237, line: 75)
!1257 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1239, line: 76)
!1258 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1245, line: 77)
!1259 = !{i32 2, !"Dwarf Version", i32 4}
!1260 = !{i32 2, !"Debug Info Version", i32 3}
!1261 = distinct !DISubprogram(name: "__remill_basic_block", scope: !2, file: !2, line: 52, type: !1262, isLocal: false, isDefinition: true, scopeLine: 52, flags: DIFlagPrototyped, isOptimized: false, unit: !1, variables: !7)
!1262 = !DISubroutineType(types: !1263)
!1263 = !{!1264, !1267, !1950, !1264}
!1264 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1265, size: 64)
!1265 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Memory", file: !1266, line: 36, flags: DIFlagFwdDecl, identifier: "_ZTS6Memory")
!1266 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/Types.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1267 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !1268, size: 64)
!1268 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "State", file: !27, line: 742, size: 27008, align: 128, elements: !1269, identifier: "_ZTS5State")
!1269 = !{!1270, !1282, !1491, !1511, !1541, !1566, !1595, !1632, !1642, !1703, !1728, !1752, !1932}
!1270 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1268, baseType: !1271)
!1271 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "ArchState", file: !1272, line: 21, size: 128, elements: !1273, identifier: "_ZTS9ArchState")
!1272 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/State.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1273 = !{!1274, !1275, !1276}
!1274 = !DIDerivedType(tag: DW_TAG_member, name: "hyper_call", scope: !1271, file: !1272, line: 23, baseType: !4, size: 32)
!1275 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1271, file: !1272, line: 25, baseType: !8, size: 32, offset: 32)
!1276 = !DIDerivedType(tag: DW_TAG_member, scope: !1271, file: !1272, line: 31, baseType: !1277, size: 64, offset: 64)
!1277 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1271, file: !1272, line: 31, size: 64, elements: !1278, identifier: "_ZTSN9ArchStateUt_E")
!1278 = !{!1279, !1280, !1281}
!1279 = !DIDerivedType(tag: DW_TAG_member, name: "addr_to_load", scope: !1277, file: !1272, line: 32, baseType: !637, size: 64)
!1280 = !DIDerivedType(tag: DW_TAG_member, name: "addr_to_store", scope: !1277, file: !1272, line: 33, baseType: !637, size: 64)
!1281 = !DIDerivedType(tag: DW_TAG_member, name: "hyper_call_vector", scope: !1277, file: !1272, line: 34, baseType: !8, size: 32)
!1282 = !DIDerivedType(tag: DW_TAG_member, name: "vec", scope: !1268, file: !27, line: 747, baseType: !1283, size: 16384, offset: 128)
!1283 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1284, size: 16384, elements: !1369)
!1284 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "VectorReg", file: !27, line: 636, size: 512, align: 128, elements: !1285, identifier: "_ZTS9VectorReg")
!1285 = !{!1286, !1361, !1426}
!1286 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1284, file: !27, line: 637, baseType: !1287, size: 128, align: 128)
!1287 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec128_t", file: !1266, line: 317, size: 128, elements: !1288, identifier: "_ZTS8vec128_t")
!1288 = !{!1289, !1298, !1305, !1312, !1317, !1324, !1329, !1334, !1339, !1344, !1349, !1354}
!1289 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1287, file: !1266, line: 321, baseType: !1290, size: 128)
!1290 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v1_t", file: !1266, line: 205, size: 128, elements: !1291, identifier: "_ZTS11uint128v1_t")
!1291 = !{!1292}
!1292 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1290, file: !1266, line: 205, baseType: !1293, size: 128)
!1293 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 128, elements: !1296)
!1294 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint128_t", file: !1266, line: 46, baseType: !1295)
!1295 = !DIBasicType(name: "unsigned __int128", size: 128, encoding: DW_ATE_unsigned)
!1296 = !{!1297}
!1297 = !DISubrange(count: 1)
!1298 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1287, file: !1266, line: 323, baseType: !1299, size: 128)
!1299 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v16_t", file: !1266, line: 182, size: 128, elements: !1300, identifier: "_ZTS10uint8v16_t")
!1300 = !{!1301}
!1301 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1299, file: !1266, line: 182, baseType: !1302, size: 128)
!1302 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 128, elements: !1303)
!1303 = !{!1304}
!1304 = !DISubrange(count: 16)
!1305 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1287, file: !1266, line: 324, baseType: !1306, size: 128)
!1306 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v8_t", file: !1266, line: 189, size: 128, elements: !1307, identifier: "_ZTS10uint16v8_t")
!1307 = !{!1308}
!1308 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1306, file: !1266, line: 189, baseType: !1309, size: 128)
!1309 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 128, elements: !1310)
!1310 = !{!1311}
!1311 = !DISubrange(count: 8)
!1312 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1287, file: !1266, line: 325, baseType: !1313, size: 128)
!1313 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v4_t", file: !1266, line: 195, size: 128, elements: !1314, identifier: "_ZTS10uint32v4_t")
!1314 = !{!1315}
!1315 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1313, file: !1266, line: 195, baseType: !1316, size: 128)
!1316 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 128, elements: !353)
!1317 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1287, file: !1266, line: 326, baseType: !1318, size: 128)
!1318 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v2_t", file: !1266, line: 200, size: 128, elements: !1319, identifier: "_ZTS10uint64v2_t")
!1319 = !{!1320}
!1320 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1318, file: !1266, line: 200, baseType: !1321, size: 128)
!1321 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 128, elements: !1322)
!1322 = !{!1323}
!1323 = !DISubrange(count: 2)
!1324 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1287, file: !1266, line: 327, baseType: !1325, size: 128)
!1325 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v4_t", file: !1266, line: 242, size: 128, elements: !1326, identifier: "_ZTS11float32v4_t")
!1326 = !{!1327}
!1327 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1325, file: !1266, line: 242, baseType: !1328, size: 128)
!1328 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 128, elements: !353)
!1329 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1287, file: !1266, line: 328, baseType: !1330, size: 128)
!1330 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v2_t", file: !1266, line: 247, size: 128, elements: !1331, identifier: "_ZTS11float64v2_t")
!1331 = !{!1332}
!1332 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1330, file: !1266, line: 247, baseType: !1333, size: 128)
!1333 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 128, elements: !1322)
!1334 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1287, file: !1266, line: 330, baseType: !1335, size: 128)
!1335 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v16_t", file: !1266, line: 213, size: 128, elements: !1336, identifier: "_ZTS9int8v16_t")
!1336 = !{!1337}
!1337 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1335, file: !1266, line: 213, baseType: !1338, size: 128)
!1338 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 128, elements: !1303)
!1339 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1287, file: !1266, line: 331, baseType: !1340, size: 128)
!1340 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v8_t", file: !1266, line: 220, size: 128, elements: !1341, identifier: "_ZTS9int16v8_t")
!1341 = !{!1342}
!1342 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1340, file: !1266, line: 220, baseType: !1343, size: 128)
!1343 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 128, elements: !1310)
!1344 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1287, file: !1266, line: 332, baseType: !1345, size: 128)
!1345 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v4_t", file: !1266, line: 226, size: 128, elements: !1346, identifier: "_ZTS9int32v4_t")
!1346 = !{!1347}
!1347 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1345, file: !1266, line: 226, baseType: !1348, size: 128)
!1348 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 128, elements: !353)
!1349 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1287, file: !1266, line: 333, baseType: !1350, size: 128)
!1350 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v2_t", file: !1266, line: 231, size: 128, elements: !1351, identifier: "_ZTS9int64v2_t")
!1351 = !{!1352}
!1352 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1350, file: !1266, line: 231, baseType: !1353, size: 128)
!1353 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 128, elements: !1322)
!1354 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1287, file: !1266, line: 334, baseType: !1355, size: 128)
!1355 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v1_t", file: !1266, line: 236, size: 128, elements: !1356, identifier: "_ZTS10int128v1_t")
!1356 = !{!1357}
!1357 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1355, file: !1266, line: 236, baseType: !1358, size: 128)
!1358 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 128, elements: !1296)
!1359 = !DIDerivedType(tag: DW_TAG_typedef, name: "int128_t", file: !1266, line: 47, baseType: !1360)
!1360 = !DIBasicType(name: "__int128", size: 128, encoding: DW_ATE_signed)
!1361 = !DIDerivedType(tag: DW_TAG_member, name: "ymm", scope: !1284, file: !27, line: 638, baseType: !1362, size: 256, align: 128)
!1362 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec256_t", file: !1266, line: 340, size: 256, elements: !1363, identifier: "_ZTS8vec256_t")
!1363 = !{!1364, !1371, !1376, !1381, !1386, !1391, !1396, !1401, !1406, !1411, !1416, !1421}
!1364 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1362, file: !1266, line: 341, baseType: !1365, size: 256)
!1365 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v32_t", file: !1266, line: 183, size: 256, elements: !1366, identifier: "_ZTS10uint8v32_t")
!1366 = !{!1367}
!1367 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1365, file: !1266, line: 183, baseType: !1368, size: 256)
!1368 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 256, elements: !1369)
!1369 = !{!1370}
!1370 = !DISubrange(count: 32)
!1371 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1362, file: !1266, line: 342, baseType: !1372, size: 256)
!1372 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v16_t", file: !1266, line: 190, size: 256, elements: !1373, identifier: "_ZTS11uint16v16_t")
!1373 = !{!1374}
!1374 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1372, file: !1266, line: 190, baseType: !1375, size: 256)
!1375 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 256, elements: !1303)
!1376 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1362, file: !1266, line: 343, baseType: !1377, size: 256)
!1377 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v8_t", file: !1266, line: 196, size: 256, elements: !1378, identifier: "_ZTS10uint32v8_t")
!1378 = !{!1379}
!1379 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1377, file: !1266, line: 196, baseType: !1380, size: 256)
!1380 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 256, elements: !1310)
!1381 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1362, file: !1266, line: 344, baseType: !1382, size: 256)
!1382 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v4_t", file: !1266, line: 201, size: 256, elements: !1383, identifier: "_ZTS10uint64v4_t")
!1383 = !{!1384}
!1384 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1382, file: !1266, line: 201, baseType: !1385, size: 256)
!1385 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 256, elements: !353)
!1386 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1362, file: !1266, line: 345, baseType: !1387, size: 256)
!1387 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v2_t", file: !1266, line: 206, size: 256, elements: !1388, identifier: "_ZTS11uint128v2_t")
!1388 = !{!1389}
!1389 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1387, file: !1266, line: 206, baseType: !1390, size: 256)
!1390 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 256, elements: !1322)
!1391 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1362, file: !1266, line: 346, baseType: !1392, size: 256)
!1392 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v8_t", file: !1266, line: 243, size: 256, elements: !1393, identifier: "_ZTS11float32v8_t")
!1393 = !{!1394}
!1394 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1392, file: !1266, line: 243, baseType: !1395, size: 256)
!1395 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 256, elements: !1310)
!1396 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1362, file: !1266, line: 347, baseType: !1397, size: 256)
!1397 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v4_t", file: !1266, line: 248, size: 256, elements: !1398, identifier: "_ZTS11float64v4_t")
!1398 = !{!1399}
!1399 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1397, file: !1266, line: 248, baseType: !1400, size: 256)
!1400 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 256, elements: !353)
!1401 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1362, file: !1266, line: 349, baseType: !1402, size: 256)
!1402 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v32_t", file: !1266, line: 214, size: 256, elements: !1403, identifier: "_ZTS9int8v32_t")
!1403 = !{!1404}
!1404 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1402, file: !1266, line: 214, baseType: !1405, size: 256)
!1405 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 256, elements: !1369)
!1406 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1362, file: !1266, line: 350, baseType: !1407, size: 256)
!1407 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v16_t", file: !1266, line: 221, size: 256, elements: !1408, identifier: "_ZTS10int16v16_t")
!1408 = !{!1409}
!1409 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1407, file: !1266, line: 221, baseType: !1410, size: 256)
!1410 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 256, elements: !1303)
!1411 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1362, file: !1266, line: 351, baseType: !1412, size: 256)
!1412 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v8_t", file: !1266, line: 227, size: 256, elements: !1413, identifier: "_ZTS9int32v8_t")
!1413 = !{!1414}
!1414 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1412, file: !1266, line: 227, baseType: !1415, size: 256)
!1415 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 256, elements: !1310)
!1416 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1362, file: !1266, line: 352, baseType: !1417, size: 256)
!1417 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v4_t", file: !1266, line: 232, size: 256, elements: !1418, identifier: "_ZTS9int64v4_t")
!1418 = !{!1419}
!1419 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1417, file: !1266, line: 232, baseType: !1420, size: 256)
!1420 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 256, elements: !353)
!1421 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1362, file: !1266, line: 353, baseType: !1422, size: 256)
!1422 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v2_t", file: !1266, line: 237, size: 256, elements: !1423, identifier: "_ZTS10int128v2_t")
!1423 = !{!1424}
!1424 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1422, file: !1266, line: 237, baseType: !1425, size: 256)
!1425 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 256, elements: !1322)
!1426 = !DIDerivedType(tag: DW_TAG_member, name: "zmm", scope: !1284, file: !27, line: 639, baseType: !1427, size: 512, align: 128)
!1427 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec512_t", file: !1266, line: 359, size: 512, elements: !1428, identifier: "_ZTS8vec512_t")
!1428 = !{!1429, !1436, !1441, !1446, !1451, !1456, !1461, !1466, !1471, !1476, !1481, !1486}
!1429 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1427, file: !1266, line: 360, baseType: !1430, size: 512)
!1430 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v64_t", file: !1266, line: 184, size: 512, elements: !1431, identifier: "_ZTS10uint8v64_t")
!1431 = !{!1432}
!1432 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1430, file: !1266, line: 184, baseType: !1433, size: 512)
!1433 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 512, elements: !1434)
!1434 = !{!1435}
!1435 = !DISubrange(count: 64)
!1436 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1427, file: !1266, line: 361, baseType: !1437, size: 512)
!1437 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v32_t", file: !1266, line: 191, size: 512, elements: !1438, identifier: "_ZTS11uint16v32_t")
!1438 = !{!1439}
!1439 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1437, file: !1266, line: 191, baseType: !1440, size: 512)
!1440 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 512, elements: !1369)
!1441 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1427, file: !1266, line: 362, baseType: !1442, size: 512)
!1442 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v16_t", file: !1266, line: 197, size: 512, elements: !1443, identifier: "_ZTS11uint32v16_t")
!1443 = !{!1444}
!1444 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1442, file: !1266, line: 197, baseType: !1445, size: 512)
!1445 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 512, elements: !1303)
!1446 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1427, file: !1266, line: 363, baseType: !1447, size: 512)
!1447 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v8_t", file: !1266, line: 202, size: 512, elements: !1448, identifier: "_ZTS10uint64v8_t")
!1448 = !{!1449}
!1449 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1447, file: !1266, line: 202, baseType: !1450, size: 512)
!1450 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 512, elements: !1310)
!1451 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1427, file: !1266, line: 364, baseType: !1452, size: 512)
!1452 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v4_t", file: !1266, line: 207, size: 512, elements: !1453, identifier: "_ZTS11uint128v4_t")
!1453 = !{!1454}
!1454 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1452, file: !1266, line: 207, baseType: !1455, size: 512)
!1455 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 512, elements: !353)
!1456 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1427, file: !1266, line: 365, baseType: !1457, size: 512)
!1457 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v16_t", file: !1266, line: 244, size: 512, elements: !1458, identifier: "_ZTS12float32v16_t")
!1458 = !{!1459}
!1459 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1457, file: !1266, line: 244, baseType: !1460, size: 512)
!1460 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 512, elements: !1303)
!1461 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1427, file: !1266, line: 366, baseType: !1462, size: 512)
!1462 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v8_t", file: !1266, line: 249, size: 512, elements: !1463, identifier: "_ZTS11float64v8_t")
!1463 = !{!1464}
!1464 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1462, file: !1266, line: 249, baseType: !1465, size: 512)
!1465 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 512, elements: !1310)
!1466 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1427, file: !1266, line: 368, baseType: !1467, size: 512)
!1467 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v64_t", file: !1266, line: 215, size: 512, elements: !1468, identifier: "_ZTS9int8v64_t")
!1468 = !{!1469}
!1469 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1467, file: !1266, line: 215, baseType: !1470, size: 512)
!1470 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 512, elements: !1434)
!1471 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1427, file: !1266, line: 369, baseType: !1472, size: 512)
!1472 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v32_t", file: !1266, line: 222, size: 512, elements: !1473, identifier: "_ZTS10int16v32_t")
!1473 = !{!1474}
!1474 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1472, file: !1266, line: 222, baseType: !1475, size: 512)
!1475 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 512, elements: !1369)
!1476 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1427, file: !1266, line: 370, baseType: !1477, size: 512)
!1477 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v16_t", file: !1266, line: 228, size: 512, elements: !1478, identifier: "_ZTS10int32v16_t")
!1478 = !{!1479}
!1479 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1477, file: !1266, line: 228, baseType: !1480, size: 512)
!1480 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 512, elements: !1303)
!1481 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1427, file: !1266, line: 371, baseType: !1482, size: 512)
!1482 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v8_t", file: !1266, line: 233, size: 512, elements: !1483, identifier: "_ZTS9int64v8_t")
!1483 = !{!1484}
!1484 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1482, file: !1266, line: 233, baseType: !1485, size: 512)
!1485 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 512, elements: !1310)
!1486 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1427, file: !1266, line: 372, baseType: !1487, size: 512)
!1487 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v4_t", file: !1266, line: 238, size: 512, elements: !1488, identifier: "_ZTS10int128v4_t")
!1488 = !{!1489}
!1489 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1487, file: !1266, line: 238, baseType: !1490, size: 512)
!1490 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 512, elements: !353)
!1491 = !DIDerivedType(tag: DW_TAG_member, name: "aflag", scope: !1268, file: !27, line: 751, baseType: !1492, size: 128, align: 64, offset: 16512)
!1492 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "ArithFlags", file: !27, line: 402, size: 128, align: 64, elements: !1493, identifier: "_ZTS10ArithFlags")
!1493 = !{!1494, !1496, !1497, !1498, !1499, !1500, !1501, !1502, !1503, !1504, !1505, !1506, !1507, !1508, !1509, !1510}
!1494 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1492, file: !27, line: 404, baseType: !1495, size: 8)
!1495 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !62)
!1496 = !DIDerivedType(tag: DW_TAG_member, name: "cf", scope: !1492, file: !27, line: 405, baseType: !62, size: 8, offset: 8)
!1497 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1492, file: !27, line: 406, baseType: !1495, size: 8, offset: 16)
!1498 = !DIDerivedType(tag: DW_TAG_member, name: "pf", scope: !1492, file: !27, line: 407, baseType: !62, size: 8, offset: 24)
!1499 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1492, file: !27, line: 408, baseType: !1495, size: 8, offset: 32)
!1500 = !DIDerivedType(tag: DW_TAG_member, name: "af", scope: !1492, file: !27, line: 409, baseType: !62, size: 8, offset: 40)
!1501 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1492, file: !27, line: 410, baseType: !1495, size: 8, offset: 48)
!1502 = !DIDerivedType(tag: DW_TAG_member, name: "zf", scope: !1492, file: !27, line: 411, baseType: !62, size: 8, offset: 56)
!1503 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1492, file: !27, line: 412, baseType: !1495, size: 8, offset: 64)
!1504 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1492, file: !27, line: 413, baseType: !62, size: 8, offset: 72)
!1505 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1492, file: !27, line: 414, baseType: !1495, size: 8, offset: 80)
!1506 = !DIDerivedType(tag: DW_TAG_member, name: "df", scope: !1492, file: !27, line: 415, baseType: !62, size: 8, offset: 88)
!1507 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1492, file: !27, line: 416, baseType: !1495, size: 8, offset: 96)
!1508 = !DIDerivedType(tag: DW_TAG_member, name: "of", scope: !1492, file: !27, line: 417, baseType: !62, size: 8, offset: 104)
!1509 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1492, file: !27, line: 418, baseType: !1495, size: 8, offset: 112)
!1510 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1492, file: !27, line: 419, baseType: !1495, size: 8, offset: 120)
!1511 = !DIDerivedType(tag: DW_TAG_member, name: "rflag", scope: !1268, file: !27, line: 752, baseType: !1512, size: 64, align: 64, offset: 16640)
!1512 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "Flags", file: !27, line: 366, size: 64, align: 64, elements: !1513, identifier: "_ZTS5Flags")
!1513 = !{!1514, !1515}
!1514 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1512, file: !27, line: 367, baseType: !637, size: 64)
!1515 = !DIDerivedType(tag: DW_TAG_member, scope: !1512, file: !27, line: 368, baseType: !1516, size: 64)
!1516 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1512, file: !27, line: 368, size: 64, elements: !1517, identifier: "_ZTSN5FlagsUt_E")
!1517 = !{!1518, !1519, !1520, !1521, !1522, !1523, !1524, !1525, !1526, !1527, !1528, !1529, !1530, !1531, !1532, !1533, !1534, !1535, !1536, !1537, !1538, !1539, !1540}
!1518 = !DIDerivedType(tag: DW_TAG_member, name: "cf", scope: !1516, file: !27, line: 369, baseType: !8, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1519 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_1", scope: !1516, file: !27, line: 370, baseType: !8, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1520 = !DIDerivedType(tag: DW_TAG_member, name: "pf", scope: !1516, file: !27, line: 371, baseType: !8, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1521 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0a", scope: !1516, file: !27, line: 372, baseType: !8, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1522 = !DIDerivedType(tag: DW_TAG_member, name: "af", scope: !1516, file: !27, line: 374, baseType: !8, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1523 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0b", scope: !1516, file: !27, line: 375, baseType: !8, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1524 = !DIDerivedType(tag: DW_TAG_member, name: "zf", scope: !1516, file: !27, line: 376, baseType: !8, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1525 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1516, file: !27, line: 377, baseType: !8, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1526 = !DIDerivedType(tag: DW_TAG_member, name: "tf", scope: !1516, file: !27, line: 379, baseType: !8, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1527 = !DIDerivedType(tag: DW_TAG_member, name: "_if", scope: !1516, file: !27, line: 380, baseType: !8, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1528 = !DIDerivedType(tag: DW_TAG_member, name: "df", scope: !1516, file: !27, line: 381, baseType: !8, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1529 = !DIDerivedType(tag: DW_TAG_member, name: "of", scope: !1516, file: !27, line: 382, baseType: !8, size: 1, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1530 = !DIDerivedType(tag: DW_TAG_member, name: "iopl", scope: !1516, file: !27, line: 384, baseType: !8, size: 2, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1531 = !DIDerivedType(tag: DW_TAG_member, name: "nt", scope: !1516, file: !27, line: 385, baseType: !8, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1532 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0c", scope: !1516, file: !27, line: 386, baseType: !8, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1533 = !DIDerivedType(tag: DW_TAG_member, name: "rf", scope: !1516, file: !27, line: 388, baseType: !8, size: 1, offset: 16, flags: DIFlagBitField, extraData: i64 0)
!1534 = !DIDerivedType(tag: DW_TAG_member, name: "vm", scope: !1516, file: !27, line: 389, baseType: !8, size: 1, offset: 17, flags: DIFlagBitField, extraData: i64 0)
!1535 = !DIDerivedType(tag: DW_TAG_member, name: "ac", scope: !1516, file: !27, line: 390, baseType: !8, size: 1, offset: 18, flags: DIFlagBitField, extraData: i64 0)
!1536 = !DIDerivedType(tag: DW_TAG_member, name: "vif", scope: !1516, file: !27, line: 391, baseType: !8, size: 1, offset: 19, flags: DIFlagBitField, extraData: i64 0)
!1537 = !DIDerivedType(tag: DW_TAG_member, name: "vip", scope: !1516, file: !27, line: 393, baseType: !8, size: 1, offset: 20, flags: DIFlagBitField, extraData: i64 0)
!1538 = !DIDerivedType(tag: DW_TAG_member, name: "id", scope: !1516, file: !27, line: 394, baseType: !8, size: 1, offset: 21, flags: DIFlagBitField, extraData: i64 0)
!1539 = !DIDerivedType(tag: DW_TAG_member, name: "reserved_eflags", scope: !1516, file: !27, line: 395, baseType: !8, size: 10, offset: 22, flags: DIFlagBitField, extraData: i64 0)
!1540 = !DIDerivedType(tag: DW_TAG_member, name: "reserved_rflags", scope: !1516, file: !27, line: 396, baseType: !8, size: 32, offset: 32)
!1541 = !DIDerivedType(tag: DW_TAG_member, name: "seg", scope: !1268, file: !27, line: 753, baseType: !1542, size: 192, align: 64, offset: 16704)
!1542 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Segments", file: !27, line: 451, size: 192, align: 64, elements: !1543, identifier: "_ZTS8Segments")
!1543 = !{!1544, !1546, !1556, !1557, !1558, !1559, !1560, !1561, !1562, !1563, !1564, !1565}
!1544 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1542, file: !27, line: 452, baseType: !1545, size: 16)
!1545 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !28)
!1546 = !DIDerivedType(tag: DW_TAG_member, name: "ss", scope: !1542, file: !27, line: 453, baseType: !1547, size: 16, offset: 16)
!1547 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "SegmentSelector", file: !27, line: 76, size: 16, elements: !1548, identifier: "_ZTS15SegmentSelector")
!1548 = !{!1549, !1550}
!1549 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1547, file: !27, line: 77, baseType: !28, size: 16)
!1550 = !DIDerivedType(tag: DW_TAG_member, scope: !1547, file: !27, line: 78, baseType: !1551, size: 16)
!1551 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1547, file: !27, line: 78, size: 16, elements: !1552, identifier: "_ZTSN15SegmentSelectorUt_E")
!1552 = !{!1553, !1554, !1555}
!1553 = !DIDerivedType(tag: DW_TAG_member, name: "rpi", scope: !1551, file: !27, line: 79, baseType: !26, size: 2, flags: DIFlagBitField, extraData: i64 0)
!1554 = !DIDerivedType(tag: DW_TAG_member, name: "ti", scope: !1551, file: !27, line: 80, baseType: !35, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1555 = !DIDerivedType(tag: DW_TAG_member, name: "index", scope: !1551, file: !27, line: 81, baseType: !28, size: 13, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1556 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1542, file: !27, line: 454, baseType: !1545, size: 16, offset: 32)
!1557 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1542, file: !27, line: 455, baseType: !1547, size: 16, offset: 48)
!1558 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1542, file: !27, line: 456, baseType: !1545, size: 16, offset: 64)
!1559 = !DIDerivedType(tag: DW_TAG_member, name: "gs", scope: !1542, file: !27, line: 457, baseType: !1547, size: 16, offset: 80)
!1560 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1542, file: !27, line: 458, baseType: !1545, size: 16, offset: 96)
!1561 = !DIDerivedType(tag: DW_TAG_member, name: "fs", scope: !1542, file: !27, line: 459, baseType: !1547, size: 16, offset: 112)
!1562 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1542, file: !27, line: 460, baseType: !1545, size: 16, offset: 128)
!1563 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1542, file: !27, line: 461, baseType: !1547, size: 16, offset: 144)
!1564 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1542, file: !27, line: 462, baseType: !1545, size: 16, offset: 160)
!1565 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1542, file: !27, line: 463, baseType: !1547, size: 16, offset: 176)
!1566 = !DIDerivedType(tag: DW_TAG_member, name: "addr", scope: !1268, file: !27, line: 754, baseType: !1567, size: 768, align: 64, offset: 16896)
!1567 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "AddressSpace", file: !27, line: 654, size: 768, align: 64, elements: !1568, identifier: "_ZTS12AddressSpace")
!1568 = !{!1569, !1571, !1585, !1586, !1587, !1588, !1589, !1590, !1591, !1592, !1593, !1594}
!1569 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1567, file: !27, line: 655, baseType: !1570, size: 64)
!1570 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !637)
!1571 = !DIDerivedType(tag: DW_TAG_member, name: "ss_base", scope: !1567, file: !27, line: 656, baseType: !1572, size: 64, offset: 64)
!1572 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Reg", file: !27, line: 610, size: 64, elements: !1573, identifier: "_ZTS3Reg")
!1573 = !{!1574}
!1574 = !DIDerivedType(tag: DW_TAG_member, scope: !1572, file: !27, line: 611, baseType: !1575, size: 64)
!1575 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1572, file: !27, line: 611, size: 64, elements: !1576, identifier: "_ZTSN3RegUt_E")
!1576 = !{!1577, !1582, !1583, !1584}
!1577 = !DIDerivedType(tag: DW_TAG_member, name: "byte", scope: !1575, file: !27, line: 615, baseType: !1578, size: 16, align: 8)
!1578 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1575, file: !27, line: 612, size: 16, elements: !1579, identifier: "_ZTSN3RegUt_Ut_E")
!1579 = !{!1580, !1581}
!1580 = !DIDerivedType(tag: DW_TAG_member, name: "low", scope: !1578, file: !27, line: 613, baseType: !62, size: 8)
!1581 = !DIDerivedType(tag: DW_TAG_member, name: "high", scope: !1578, file: !27, line: 614, baseType: !62, size: 8, offset: 8)
!1582 = !DIDerivedType(tag: DW_TAG_member, name: "word", scope: !1575, file: !27, line: 616, baseType: !28, size: 16, align: 16)
!1583 = !DIDerivedType(tag: DW_TAG_member, name: "dword", scope: !1575, file: !27, line: 617, baseType: !8, size: 32, align: 32)
!1584 = !DIDerivedType(tag: DW_TAG_member, name: "qword", scope: !1575, file: !27, line: 618, baseType: !637, size: 64, align: 64)
!1585 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1567, file: !27, line: 657, baseType: !1570, size: 64, offset: 128)
!1586 = !DIDerivedType(tag: DW_TAG_member, name: "es_base", scope: !1567, file: !27, line: 658, baseType: !1572, size: 64, offset: 192)
!1587 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1567, file: !27, line: 659, baseType: !1570, size: 64, offset: 256)
!1588 = !DIDerivedType(tag: DW_TAG_member, name: "gs_base", scope: !1567, file: !27, line: 660, baseType: !1572, size: 64, offset: 320)
!1589 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1567, file: !27, line: 661, baseType: !1570, size: 64, offset: 384)
!1590 = !DIDerivedType(tag: DW_TAG_member, name: "fs_base", scope: !1567, file: !27, line: 662, baseType: !1572, size: 64, offset: 448)
!1591 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1567, file: !27, line: 663, baseType: !1570, size: 64, offset: 512)
!1592 = !DIDerivedType(tag: DW_TAG_member, name: "ds_base", scope: !1567, file: !27, line: 664, baseType: !1572, size: 64, offset: 576)
!1593 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1567, file: !27, line: 665, baseType: !1570, size: 64, offset: 640)
!1594 = !DIDerivedType(tag: DW_TAG_member, name: "cs_base", scope: !1567, file: !27, line: 666, baseType: !1572, size: 64, offset: 704)
!1595 = !DIDerivedType(tag: DW_TAG_member, name: "gpr", scope: !1268, file: !27, line: 755, baseType: !1596, size: 2176, align: 64, offset: 17664)
!1596 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "GPR", file: !27, line: 677, size: 2176, align: 64, elements: !1597, identifier: "_ZTS3GPR")
!1597 = !{!1598, !1599, !1600, !1601, !1602, !1603, !1604, !1605, !1606, !1607, !1608, !1609, !1610, !1611, !1612, !1613, !1614, !1615, !1616, !1617, !1618, !1619, !1620, !1621, !1622, !1623, !1624, !1625, !1626, !1627, !1628, !1629, !1630, !1631}
!1598 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1596, file: !27, line: 679, baseType: !1570, size: 64)
!1599 = !DIDerivedType(tag: DW_TAG_member, name: "rax", scope: !1596, file: !27, line: 680, baseType: !1572, size: 64, offset: 64)
!1600 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1596, file: !27, line: 681, baseType: !1570, size: 64, offset: 128)
!1601 = !DIDerivedType(tag: DW_TAG_member, name: "rbx", scope: !1596, file: !27, line: 682, baseType: !1572, size: 64, offset: 192)
!1602 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1596, file: !27, line: 683, baseType: !1570, size: 64, offset: 256)
!1603 = !DIDerivedType(tag: DW_TAG_member, name: "rcx", scope: !1596, file: !27, line: 684, baseType: !1572, size: 64, offset: 320)
!1604 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1596, file: !27, line: 685, baseType: !1570, size: 64, offset: 384)
!1605 = !DIDerivedType(tag: DW_TAG_member, name: "rdx", scope: !1596, file: !27, line: 686, baseType: !1572, size: 64, offset: 448)
!1606 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1596, file: !27, line: 687, baseType: !1570, size: 64, offset: 512)
!1607 = !DIDerivedType(tag: DW_TAG_member, name: "rsi", scope: !1596, file: !27, line: 688, baseType: !1572, size: 64, offset: 576)
!1608 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1596, file: !27, line: 689, baseType: !1570, size: 64, offset: 640)
!1609 = !DIDerivedType(tag: DW_TAG_member, name: "rdi", scope: !1596, file: !27, line: 690, baseType: !1572, size: 64, offset: 704)
!1610 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1596, file: !27, line: 691, baseType: !1570, size: 64, offset: 768)
!1611 = !DIDerivedType(tag: DW_TAG_member, name: "rsp", scope: !1596, file: !27, line: 692, baseType: !1572, size: 64, offset: 832)
!1612 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1596, file: !27, line: 693, baseType: !1570, size: 64, offset: 896)
!1613 = !DIDerivedType(tag: DW_TAG_member, name: "rbp", scope: !1596, file: !27, line: 694, baseType: !1572, size: 64, offset: 960)
!1614 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1596, file: !27, line: 695, baseType: !1570, size: 64, offset: 1024)
!1615 = !DIDerivedType(tag: DW_TAG_member, name: "r8", scope: !1596, file: !27, line: 696, baseType: !1572, size: 64, offset: 1088)
!1616 = !DIDerivedType(tag: DW_TAG_member, name: "_9", scope: !1596, file: !27, line: 697, baseType: !1570, size: 64, offset: 1152)
!1617 = !DIDerivedType(tag: DW_TAG_member, name: "r9", scope: !1596, file: !27, line: 698, baseType: !1572, size: 64, offset: 1216)
!1618 = !DIDerivedType(tag: DW_TAG_member, name: "_10", scope: !1596, file: !27, line: 699, baseType: !1570, size: 64, offset: 1280)
!1619 = !DIDerivedType(tag: DW_TAG_member, name: "r10", scope: !1596, file: !27, line: 700, baseType: !1572, size: 64, offset: 1344)
!1620 = !DIDerivedType(tag: DW_TAG_member, name: "_11", scope: !1596, file: !27, line: 701, baseType: !1570, size: 64, offset: 1408)
!1621 = !DIDerivedType(tag: DW_TAG_member, name: "r11", scope: !1596, file: !27, line: 702, baseType: !1572, size: 64, offset: 1472)
!1622 = !DIDerivedType(tag: DW_TAG_member, name: "_12", scope: !1596, file: !27, line: 703, baseType: !1570, size: 64, offset: 1536)
!1623 = !DIDerivedType(tag: DW_TAG_member, name: "r12", scope: !1596, file: !27, line: 704, baseType: !1572, size: 64, offset: 1600)
!1624 = !DIDerivedType(tag: DW_TAG_member, name: "_13", scope: !1596, file: !27, line: 705, baseType: !1570, size: 64, offset: 1664)
!1625 = !DIDerivedType(tag: DW_TAG_member, name: "r13", scope: !1596, file: !27, line: 706, baseType: !1572, size: 64, offset: 1728)
!1626 = !DIDerivedType(tag: DW_TAG_member, name: "_14", scope: !1596, file: !27, line: 707, baseType: !1570, size: 64, offset: 1792)
!1627 = !DIDerivedType(tag: DW_TAG_member, name: "r14", scope: !1596, file: !27, line: 708, baseType: !1572, size: 64, offset: 1856)
!1628 = !DIDerivedType(tag: DW_TAG_member, name: "_15", scope: !1596, file: !27, line: 709, baseType: !1570, size: 64, offset: 1920)
!1629 = !DIDerivedType(tag: DW_TAG_member, name: "r15", scope: !1596, file: !27, line: 710, baseType: !1572, size: 64, offset: 1984)
!1630 = !DIDerivedType(tag: DW_TAG_member, name: "_16", scope: !1596, file: !27, line: 711, baseType: !1570, size: 64, offset: 2048)
!1631 = !DIDerivedType(tag: DW_TAG_member, name: "rip", scope: !1596, file: !27, line: 714, baseType: !1572, size: 64, offset: 2112)
!1632 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1268, file: !27, line: 756, baseType: !1633, size: 1024, align: 64, offset: 19840)
!1633 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "X87Stack", file: !27, line: 719, size: 1024, align: 64, elements: !1634, identifier: "_ZTS8X87Stack")
!1634 = !{!1635}
!1635 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1633, file: !27, line: 723, baseType: !1636, size: 1024)
!1636 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1637, size: 1024, elements: !1310)
!1637 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1633, file: !27, line: 720, size: 128, align: 64, elements: !1638, identifier: "_ZTSN8X87StackUt_E")
!1638 = !{!1639, !1640}
!1639 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1637, file: !27, line: 721, baseType: !637, size: 64)
!1640 = !DIDerivedType(tag: DW_TAG_member, name: "val", scope: !1637, file: !27, line: 722, baseType: !1641, size: 64, offset: 64)
!1641 = !DIDerivedType(tag: DW_TAG_typedef, name: "float64_t", file: !1266, line: 61, baseType: !108)
!1642 = !DIDerivedType(tag: DW_TAG_member, name: "mmx", scope: !1268, file: !27, line: 757, baseType: !1643, size: 1024, align: 64, offset: 20864)
!1643 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "MMX", file: !27, line: 729, size: 1024, align: 64, elements: !1644, identifier: "_ZTS3MMX")
!1644 = !{!1645}
!1645 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1643, file: !27, line: 733, baseType: !1646, size: 1024)
!1646 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1647, size: 1024, elements: !1310)
!1647 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1643, file: !27, line: 730, size: 128, align: 64, elements: !1648, identifier: "_ZTSN3MMXUt_E")
!1648 = !{!1649, !1650}
!1649 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1647, file: !27, line: 731, baseType: !637, size: 64)
!1650 = !DIDerivedType(tag: DW_TAG_member, name: "val", scope: !1647, file: !27, line: 732, baseType: !1651, size: 64, offset: 64)
!1651 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec64_t", file: !1266, line: 294, size: 64, elements: !1652, identifier: "_ZTS7vec64_t")
!1652 = !{!1653, !1658, !1663, !1668, !1673, !1678, !1683, !1688, !1693, !1698}
!1653 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1651, file: !1266, line: 298, baseType: !1654, size: 64)
!1654 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v1_t", file: !1266, line: 199, size: 64, elements: !1655, identifier: "_ZTS10uint64v1_t")
!1655 = !{!1656}
!1656 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1654, file: !1266, line: 199, baseType: !1657, size: 64)
!1657 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 64, elements: !1296)
!1658 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1651, file: !1266, line: 300, baseType: !1659, size: 64)
!1659 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v8_t", file: !1266, line: 181, size: 64, elements: !1660, identifier: "_ZTS9uint8v8_t")
!1660 = !{!1661}
!1661 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1659, file: !1266, line: 181, baseType: !1662, size: 64)
!1662 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 64, elements: !1310)
!1663 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1651, file: !1266, line: 301, baseType: !1664, size: 64)
!1664 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v4_t", file: !1266, line: 188, size: 64, elements: !1665, identifier: "_ZTS10uint16v4_t")
!1665 = !{!1666}
!1666 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1664, file: !1266, line: 188, baseType: !1667, size: 64)
!1667 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 64, elements: !353)
!1668 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1651, file: !1266, line: 302, baseType: !1669, size: 64)
!1669 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v2_t", file: !1266, line: 194, size: 64, elements: !1670, identifier: "_ZTS10uint32v2_t")
!1670 = !{!1671}
!1671 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1669, file: !1266, line: 194, baseType: !1672, size: 64)
!1672 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 64, elements: !1322)
!1673 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1651, file: !1266, line: 303, baseType: !1674, size: 64)
!1674 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v2_t", file: !1266, line: 241, size: 64, elements: !1675, identifier: "_ZTS11float32v2_t")
!1675 = !{!1676}
!1676 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1674, file: !1266, line: 241, baseType: !1677, size: 64)
!1677 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 64, elements: !1322)
!1678 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1651, file: !1266, line: 304, baseType: !1679, size: 64)
!1679 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v1_t", file: !1266, line: 246, size: 64, elements: !1680, identifier: "_ZTS11float64v1_t")
!1680 = !{!1681}
!1681 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1679, file: !1266, line: 246, baseType: !1682, size: 64)
!1682 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 64, elements: !1296)
!1683 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1651, file: !1266, line: 306, baseType: !1684, size: 64)
!1684 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v8_t", file: !1266, line: 212, size: 64, elements: !1685, identifier: "_ZTS8int8v8_t")
!1685 = !{!1686}
!1686 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1684, file: !1266, line: 212, baseType: !1687, size: 64)
!1687 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 64, elements: !1310)
!1688 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1651, file: !1266, line: 307, baseType: !1689, size: 64)
!1689 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v4_t", file: !1266, line: 219, size: 64, elements: !1690, identifier: "_ZTS9int16v4_t")
!1690 = !{!1691}
!1691 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1689, file: !1266, line: 219, baseType: !1692, size: 64)
!1692 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 64, elements: !353)
!1693 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1651, file: !1266, line: 308, baseType: !1694, size: 64)
!1694 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v2_t", file: !1266, line: 225, size: 64, elements: !1695, identifier: "_ZTS9int32v2_t")
!1695 = !{!1696}
!1696 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1694, file: !1266, line: 225, baseType: !1697, size: 64)
!1697 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 64, elements: !1322)
!1698 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1651, file: !1266, line: 309, baseType: !1699, size: 64)
!1699 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v1_t", file: !1266, line: 230, size: 64, elements: !1700, identifier: "_ZTS9int64v1_t")
!1700 = !{!1701}
!1701 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1699, file: !1266, line: 230, baseType: !1702, size: 64)
!1702 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 64, elements: !1296)
!1703 = !DIDerivedType(tag: DW_TAG_member, name: "sw", scope: !1268, file: !27, line: 758, baseType: !1704, size: 192, offset: 21888)
!1704 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FPUStatusFlags", file: !27, line: 332, size: 192, elements: !1705, identifier: "_ZTS14FPUStatusFlags")
!1705 = !{!1706, !1707, !1708, !1709, !1710, !1711, !1712, !1713, !1714, !1715, !1716, !1717, !1718, !1719, !1720, !1721, !1722, !1723, !1724, !1725, !1726}
!1706 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1704, file: !27, line: 333, baseType: !62, size: 8)
!1707 = !DIDerivedType(tag: DW_TAG_member, name: "c0", scope: !1704, file: !27, line: 334, baseType: !62, size: 8, offset: 8)
!1708 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1704, file: !27, line: 335, baseType: !62, size: 8, offset: 16)
!1709 = !DIDerivedType(tag: DW_TAG_member, name: "c1", scope: !1704, file: !27, line: 336, baseType: !62, size: 8, offset: 24)
!1710 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1704, file: !27, line: 337, baseType: !62, size: 8, offset: 32)
!1711 = !DIDerivedType(tag: DW_TAG_member, name: "c2", scope: !1704, file: !27, line: 338, baseType: !62, size: 8, offset: 40)
!1712 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1704, file: !27, line: 339, baseType: !62, size: 8, offset: 48)
!1713 = !DIDerivedType(tag: DW_TAG_member, name: "c3", scope: !1704, file: !27, line: 340, baseType: !62, size: 8, offset: 56)
!1714 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1704, file: !27, line: 342, baseType: !62, size: 8, offset: 64)
!1715 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1704, file: !27, line: 343, baseType: !62, size: 8, offset: 72)
!1716 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1704, file: !27, line: 345, baseType: !62, size: 8, offset: 80)
!1717 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1704, file: !27, line: 346, baseType: !62, size: 8, offset: 88)
!1718 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1704, file: !27, line: 348, baseType: !62, size: 8, offset: 96)
!1719 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1704, file: !27, line: 349, baseType: !62, size: 8, offset: 104)
!1720 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1704, file: !27, line: 351, baseType: !62, size: 8, offset: 112)
!1721 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1704, file: !27, line: 352, baseType: !62, size: 8, offset: 120)
!1722 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1704, file: !27, line: 354, baseType: !62, size: 8, offset: 128)
!1723 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1704, file: !27, line: 355, baseType: !62, size: 8, offset: 136)
!1724 = !DIDerivedType(tag: DW_TAG_member, name: "_9", scope: !1704, file: !27, line: 357, baseType: !62, size: 8, offset: 144)
!1725 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1704, file: !27, line: 358, baseType: !62, size: 8, offset: 152)
!1726 = !DIDerivedType(tag: DW_TAG_member, name: "_padding", scope: !1704, file: !27, line: 360, baseType: !1727, size: 32, offset: 160)
!1727 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 32, elements: !353)
!1728 = !DIDerivedType(tag: DW_TAG_member, name: "xcr0", scope: !1268, file: !27, line: 759, baseType: !1729, size: 64, offset: 22080)
!1729 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "XCR0", file: !27, line: 424, size: 64, elements: !1730, identifier: "_ZTS4XCR0")
!1730 = !{!1731, !1732, !1737}
!1731 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1729, file: !27, line: 425, baseType: !637, size: 64)
!1732 = !DIDerivedType(tag: DW_TAG_member, scope: !1729, file: !27, line: 427, baseType: !1733, size: 64)
!1733 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1729, file: !27, line: 427, size: 64, elements: !1734, identifier: "_ZTSN4XCR0Ut_E")
!1734 = !{!1735, !1736}
!1735 = !DIDerivedType(tag: DW_TAG_member, name: "eax", scope: !1733, file: !27, line: 428, baseType: !8, size: 32)
!1736 = !DIDerivedType(tag: DW_TAG_member, name: "edx", scope: !1733, file: !27, line: 429, baseType: !8, size: 32, offset: 32)
!1737 = !DIDerivedType(tag: DW_TAG_member, scope: !1729, file: !27, line: 433, baseType: !1738, size: 64)
!1738 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1729, file: !27, line: 433, size: 64, elements: !1739, identifier: "_ZTSN4XCR0Ut0_E")
!1739 = !{!1740, !1741, !1742, !1743, !1744, !1745, !1746, !1747, !1748, !1749, !1750, !1751}
!1740 = !DIDerivedType(tag: DW_TAG_member, name: "x87_fpu_mmx", scope: !1738, file: !27, line: 434, baseType: !637, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1741 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1738, file: !27, line: 435, baseType: !637, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1742 = !DIDerivedType(tag: DW_TAG_member, name: "ymm", scope: !1738, file: !27, line: 436, baseType: !637, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1743 = !DIDerivedType(tag: DW_TAG_member, name: "bndreg", scope: !1738, file: !27, line: 437, baseType: !637, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1744 = !DIDerivedType(tag: DW_TAG_member, name: "bndcsr", scope: !1738, file: !27, line: 438, baseType: !637, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1745 = !DIDerivedType(tag: DW_TAG_member, name: "opmask", scope: !1738, file: !27, line: 439, baseType: !637, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1746 = !DIDerivedType(tag: DW_TAG_member, name: "zmm_hi256", scope: !1738, file: !27, line: 440, baseType: !637, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1747 = !DIDerivedType(tag: DW_TAG_member, name: "hi16_zmm", scope: !1738, file: !27, line: 441, baseType: !637, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1748 = !DIDerivedType(tag: DW_TAG_member, name: "pkru", scope: !1738, file: !27, line: 442, baseType: !637, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1749 = !DIDerivedType(tag: DW_TAG_member, name: "_reserved0", scope: !1738, file: !27, line: 443, baseType: !637, size: 53, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1750 = !DIDerivedType(tag: DW_TAG_member, name: "lwp", scope: !1738, file: !27, line: 444, baseType: !637, size: 1, offset: 62, flags: DIFlagBitField, extraData: i64 0)
!1751 = !DIDerivedType(tag: DW_TAG_member, name: "_reserved1", scope: !1738, file: !27, line: 445, baseType: !637, size: 1, offset: 63, flags: DIFlagBitField, extraData: i64 0)
!1752 = !DIDerivedType(tag: DW_TAG_member, name: "x87", scope: !1268, file: !27, line: 760, baseType: !1753, size: 4096, align: 128, offset: 22144)
!1753 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPU", file: !27, line: 314, size: 4096, align: 128, elements: !1754, identifier: "_ZTS3FPU")
!1754 = !{!1755, !1851, !1914}
!1755 = !DIDerivedType(tag: DW_TAG_member, name: "fsave", scope: !1753, file: !27, line: 317, baseType: !1756, size: 4096)
!1756 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 315, size: 4096, elements: !1757, identifier: "_ZTSN3FPUUt_E")
!1757 = !{!1758, !1847}
!1758 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1756, baseType: !1759)
!1759 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFSAVE", file: !27, line: 263, size: 1248, elements: !1760, identifier: "_ZTS8FpuFSAVE")
!1760 = !{!1761, !1779, !1780, !1801, !1802, !1817, !1818, !1819, !1820, !1821, !1822, !1823, !1824}
!1761 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1759, file: !27, line: 264, baseType: !1762, size: 16)
!1762 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUControlWord", file: !27, line: 142, size: 16, elements: !1763, identifier: "_ZTS14FPUControlWord")
!1763 = !{!1764, !1765}
!1764 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1762, file: !27, line: 143, baseType: !28, size: 16)
!1765 = !DIDerivedType(tag: DW_TAG_member, scope: !1762, file: !27, line: 144, baseType: !1766, size: 16)
!1766 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1762, file: !27, line: 144, size: 16, elements: !1767, identifier: "_ZTSN14FPUControlWordUt_E")
!1767 = !{!1768, !1769, !1770, !1771, !1772, !1773, !1774, !1775, !1776, !1777, !1778}
!1768 = !DIDerivedType(tag: DW_TAG_member, name: "im", scope: !1766, file: !27, line: 145, baseType: !28, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1769 = !DIDerivedType(tag: DW_TAG_member, name: "dm", scope: !1766, file: !27, line: 146, baseType: !28, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1770 = !DIDerivedType(tag: DW_TAG_member, name: "zm", scope: !1766, file: !27, line: 147, baseType: !28, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1771 = !DIDerivedType(tag: DW_TAG_member, name: "om", scope: !1766, file: !27, line: 148, baseType: !28, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1772 = !DIDerivedType(tag: DW_TAG_member, name: "um", scope: !1766, file: !27, line: 149, baseType: !28, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1773 = !DIDerivedType(tag: DW_TAG_member, name: "pm", scope: !1766, file: !27, line: 150, baseType: !28, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1774 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1766, file: !27, line: 151, baseType: !28, size: 2, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1775 = !DIDerivedType(tag: DW_TAG_member, name: "pc", scope: !1766, file: !27, line: 152, baseType: !39, size: 2, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1776 = !DIDerivedType(tag: DW_TAG_member, name: "rc", scope: !1766, file: !27, line: 153, baseType: !45, size: 2, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1777 = !DIDerivedType(tag: DW_TAG_member, name: "x", scope: !1766, file: !27, line: 154, baseType: !51, size: 1, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1778 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1766, file: !27, line: 155, baseType: !28, size: 3, offset: 13, flags: DIFlagBitField, extraData: i64 0)
!1779 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1759, file: !27, line: 265, baseType: !28, size: 16, offset: 16)
!1780 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1759, file: !27, line: 266, baseType: !1781, size: 16, offset: 32)
!1781 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUStatusWord", file: !27, line: 100, size: 16, elements: !1782, identifier: "_ZTS13FPUStatusWord")
!1782 = !{!1783, !1784}
!1783 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1781, file: !27, line: 101, baseType: !28, size: 16)
!1784 = !DIDerivedType(tag: DW_TAG_member, scope: !1781, file: !27, line: 102, baseType: !1785, size: 16)
!1785 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1781, file: !27, line: 102, size: 16, elements: !1786, identifier: "_ZTSN13FPUStatusWordUt_E")
!1786 = !{!1787, !1788, !1789, !1790, !1791, !1792, !1793, !1794, !1795, !1796, !1797, !1798, !1799, !1800}
!1787 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1785, file: !27, line: 103, baseType: !28, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1788 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1785, file: !27, line: 104, baseType: !28, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1789 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1785, file: !27, line: 105, baseType: !28, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1790 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1785, file: !27, line: 106, baseType: !28, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1791 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1785, file: !27, line: 107, baseType: !28, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1792 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1785, file: !27, line: 108, baseType: !28, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1793 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1785, file: !27, line: 109, baseType: !28, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1794 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1785, file: !27, line: 110, baseType: !28, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1795 = !DIDerivedType(tag: DW_TAG_member, name: "c0", scope: !1785, file: !27, line: 111, baseType: !28, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1796 = !DIDerivedType(tag: DW_TAG_member, name: "c1", scope: !1785, file: !27, line: 112, baseType: !28, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1797 = !DIDerivedType(tag: DW_TAG_member, name: "c2", scope: !1785, file: !27, line: 113, baseType: !28, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1798 = !DIDerivedType(tag: DW_TAG_member, name: "top", scope: !1785, file: !27, line: 114, baseType: !28, size: 3, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1799 = !DIDerivedType(tag: DW_TAG_member, name: "c3", scope: !1785, file: !27, line: 115, baseType: !28, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1800 = !DIDerivedType(tag: DW_TAG_member, name: "b", scope: !1785, file: !27, line: 116, baseType: !28, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1801 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1759, file: !27, line: 267, baseType: !28, size: 16, offset: 48)
!1802 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1759, file: !27, line: 268, baseType: !1803, size: 16, offset: 64)
!1803 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUTagWord", file: !27, line: 227, size: 16, elements: !1804, identifier: "_ZTS10FPUTagWord")
!1804 = !{!1805, !1806}
!1805 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1803, file: !27, line: 228, baseType: !28, size: 16)
!1806 = !DIDerivedType(tag: DW_TAG_member, scope: !1803, file: !27, line: 229, baseType: !1807, size: 16)
!1807 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1803, file: !27, line: 229, size: 16, elements: !1808, identifier: "_ZTSN10FPUTagWordUt_E")
!1808 = !{!1809, !1810, !1811, !1812, !1813, !1814, !1815, !1816}
!1809 = !DIDerivedType(tag: DW_TAG_member, name: "tag0", scope: !1807, file: !27, line: 230, baseType: !55, size: 2, flags: DIFlagBitField, extraData: i64 0)
!1810 = !DIDerivedType(tag: DW_TAG_member, name: "tag1", scope: !1807, file: !27, line: 231, baseType: !55, size: 2, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1811 = !DIDerivedType(tag: DW_TAG_member, name: "tag2", scope: !1807, file: !27, line: 232, baseType: !55, size: 2, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1812 = !DIDerivedType(tag: DW_TAG_member, name: "tag3", scope: !1807, file: !27, line: 233, baseType: !55, size: 2, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1813 = !DIDerivedType(tag: DW_TAG_member, name: "tag4", scope: !1807, file: !27, line: 234, baseType: !55, size: 2, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1814 = !DIDerivedType(tag: DW_TAG_member, name: "tag5", scope: !1807, file: !27, line: 235, baseType: !55, size: 2, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1815 = !DIDerivedType(tag: DW_TAG_member, name: "tag6", scope: !1807, file: !27, line: 236, baseType: !55, size: 2, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1816 = !DIDerivedType(tag: DW_TAG_member, name: "tag7", scope: !1807, file: !27, line: 237, baseType: !55, size: 2, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1817 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1759, file: !27, line: 269, baseType: !28, size: 16, offset: 80)
!1818 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1759, file: !27, line: 270, baseType: !8, size: 32, offset: 96)
!1819 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1759, file: !27, line: 271, baseType: !1547, size: 16, offset: 128)
!1820 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd2", scope: !1759, file: !27, line: 272, baseType: !28, size: 16, offset: 144)
!1821 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1759, file: !27, line: 273, baseType: !8, size: 32, offset: 160)
!1822 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1759, file: !27, line: 274, baseType: !1547, size: 16, offset: 192)
!1823 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd3", scope: !1759, file: !27, line: 275, baseType: !28, size: 16, offset: 208)
!1824 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1759, file: !27, line: 276, baseType: !1825, size: 1024, offset: 224)
!1825 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1826, size: 1024, elements: !1310)
!1826 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FPUStackElem", file: !27, line: 162, size: 128, elements: !1827, identifier: "_ZTS12FPUStackElem")
!1827 = !{!1828, !1843}
!1828 = !DIDerivedType(tag: DW_TAG_member, scope: !1826, file: !27, line: 163, baseType: !1829, size: 80)
!1829 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1826, file: !27, line: 163, size: 80, elements: !1830, identifier: "_ZTSN12FPUStackElemUt_E")
!1830 = !{!1831, !1838}
!1831 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1829, file: !27, line: 164, baseType: !1832, size: 80)
!1832 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float80_t", file: !1266, line: 65, size: 80, elements: !1833, identifier: "_ZTS9float80_t")
!1833 = !{!1834}
!1834 = !DIDerivedType(tag: DW_TAG_member, name: "data", scope: !1832, file: !1266, line: 66, baseType: !1835, size: 80)
!1835 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 80, elements: !1836)
!1836 = !{!1837}
!1837 = !DISubrange(count: 10)
!1838 = !DIDerivedType(tag: DW_TAG_member, scope: !1829, file: !27, line: 165, baseType: !1839, size: 80)
!1839 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1829, file: !27, line: 165, size: 80, elements: !1840, identifier: "_ZTSN12FPUStackElemUt_Ut_E")
!1840 = !{!1841, !1842}
!1841 = !DIDerivedType(tag: DW_TAG_member, name: "mmx", scope: !1839, file: !27, line: 166, baseType: !637, size: 64)
!1842 = !DIDerivedType(tag: DW_TAG_member, name: "infinity", scope: !1839, file: !27, line: 167, baseType: !28, size: 16, offset: 64)
!1843 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd", scope: !1826, file: !27, line: 170, baseType: !1844, size: 48, offset: 80)
!1844 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 48, elements: !1845)
!1845 = !{!1846}
!1846 = !DISubrange(count: 6)
!1847 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1756, file: !27, line: 316, baseType: !1848, size: 2848, offset: 1248)
!1848 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 2848, elements: !1849)
!1849 = !{!1850}
!1850 = !DISubrange(count: 356)
!1851 = !DIDerivedType(tag: DW_TAG_member, name: "fxsave32", scope: !1753, file: !27, line: 321, baseType: !1852, size: 4096)
!1852 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 319, size: 4096, elements: !1853, identifier: "_ZTSN3FPUUt0_E")
!1853 = !{!1854, !1910}
!1854 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1852, baseType: !1855)
!1855 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFXSAVE", file: !27, line: 280, size: 3328, elements: !1856, identifier: "_ZTS9FpuFXSAVE")
!1856 = !{!1857, !1858, !1859, !1874, !1875, !1876, !1877, !1878, !1879, !1880, !1881, !1882, !1906, !1907, !1908}
!1857 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1855, file: !27, line: 281, baseType: !1762, size: 16)
!1858 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1855, file: !27, line: 282, baseType: !1781, size: 16, offset: 16)
!1859 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1855, file: !27, line: 283, baseType: !1860, size: 8, offset: 32)
!1860 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUAbridgedTagWord", file: !27, line: 245, size: 8, elements: !1861, identifier: "_ZTS18FPUAbridgedTagWord")
!1861 = !{!1862, !1863}
!1862 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1860, file: !27, line: 246, baseType: !62, size: 8)
!1863 = !DIDerivedType(tag: DW_TAG_member, scope: !1860, file: !27, line: 247, baseType: !1864, size: 8)
!1864 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1860, file: !27, line: 247, size: 8, elements: !1865, identifier: "_ZTSN18FPUAbridgedTagWordUt_E")
!1865 = !{!1866, !1867, !1868, !1869, !1870, !1871, !1872, !1873}
!1866 = !DIDerivedType(tag: DW_TAG_member, name: "r0", scope: !1864, file: !27, line: 248, baseType: !61, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1867 = !DIDerivedType(tag: DW_TAG_member, name: "r1", scope: !1864, file: !27, line: 249, baseType: !61, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1868 = !DIDerivedType(tag: DW_TAG_member, name: "r2", scope: !1864, file: !27, line: 250, baseType: !61, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1869 = !DIDerivedType(tag: DW_TAG_member, name: "r3", scope: !1864, file: !27, line: 251, baseType: !61, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1870 = !DIDerivedType(tag: DW_TAG_member, name: "r4", scope: !1864, file: !27, line: 252, baseType: !61, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1871 = !DIDerivedType(tag: DW_TAG_member, name: "r5", scope: !1864, file: !27, line: 253, baseType: !61, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1872 = !DIDerivedType(tag: DW_TAG_member, name: "r6", scope: !1864, file: !27, line: 254, baseType: !61, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1873 = !DIDerivedType(tag: DW_TAG_member, name: "r7", scope: !1864, file: !27, line: 255, baseType: !61, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1874 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1855, file: !27, line: 284, baseType: !62, size: 8, offset: 40)
!1875 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1855, file: !27, line: 285, baseType: !28, size: 16, offset: 48)
!1876 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1855, file: !27, line: 286, baseType: !8, size: 32, offset: 64)
!1877 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1855, file: !27, line: 287, baseType: !1547, size: 16, offset: 96)
!1878 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1855, file: !27, line: 288, baseType: !28, size: 16, offset: 112)
!1879 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1855, file: !27, line: 289, baseType: !8, size: 32, offset: 128)
!1880 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1855, file: !27, line: 290, baseType: !1547, size: 16, offset: 160)
!1881 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd2", scope: !1855, file: !27, line: 291, baseType: !28, size: 16, offset: 176)
!1882 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr", scope: !1855, file: !27, line: 292, baseType: !1883, size: 32, offset: 192)
!1883 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUControlStatus", file: !27, line: 188, size: 32, elements: !1884, identifier: "_ZTS16FPUControlStatus")
!1884 = !{!1885, !1886}
!1885 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1883, file: !27, line: 189, baseType: !8, size: 32)
!1886 = !DIDerivedType(tag: DW_TAG_member, scope: !1883, file: !27, line: 190, baseType: !1887, size: 32)
!1887 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1883, file: !27, line: 190, size: 32, elements: !1888, identifier: "_ZTSN16FPUControlStatusUt_E")
!1888 = !{!1889, !1890, !1891, !1892, !1893, !1894, !1895, !1896, !1897, !1898, !1899, !1900, !1901, !1902, !1903, !1904, !1905}
!1889 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1887, file: !27, line: 191, baseType: !8, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1890 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1887, file: !27, line: 192, baseType: !8, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1891 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1887, file: !27, line: 193, baseType: !8, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1892 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1887, file: !27, line: 194, baseType: !8, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1893 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1887, file: !27, line: 195, baseType: !8, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1894 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1887, file: !27, line: 196, baseType: !8, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1895 = !DIDerivedType(tag: DW_TAG_member, name: "daz", scope: !1887, file: !27, line: 197, baseType: !8, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1896 = !DIDerivedType(tag: DW_TAG_member, name: "im", scope: !1887, file: !27, line: 198, baseType: !8, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1897 = !DIDerivedType(tag: DW_TAG_member, name: "dm", scope: !1887, file: !27, line: 199, baseType: !8, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1898 = !DIDerivedType(tag: DW_TAG_member, name: "zm", scope: !1887, file: !27, line: 200, baseType: !8, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1899 = !DIDerivedType(tag: DW_TAG_member, name: "om", scope: !1887, file: !27, line: 201, baseType: !8, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1900 = !DIDerivedType(tag: DW_TAG_member, name: "um", scope: !1887, file: !27, line: 202, baseType: !8, size: 1, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1901 = !DIDerivedType(tag: DW_TAG_member, name: "pm", scope: !1887, file: !27, line: 203, baseType: !8, size: 1, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1902 = !DIDerivedType(tag: DW_TAG_member, name: "rn", scope: !1887, file: !27, line: 204, baseType: !8, size: 1, offset: 13, flags: DIFlagBitField, extraData: i64 0)
!1903 = !DIDerivedType(tag: DW_TAG_member, name: "rp", scope: !1887, file: !27, line: 205, baseType: !8, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1904 = !DIDerivedType(tag: DW_TAG_member, name: "fz", scope: !1887, file: !27, line: 206, baseType: !8, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1905 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd", scope: !1887, file: !27, line: 207, baseType: !8, size: 16, offset: 16, flags: DIFlagBitField, extraData: i64 0)
!1906 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr_mask", scope: !1855, file: !27, line: 293, baseType: !1883, size: 32, offset: 224)
!1907 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1855, file: !27, line: 294, baseType: !1825, size: 1024, offset: 256)
!1908 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1855, file: !27, line: 295, baseType: !1909, size: 2048, offset: 1280)
!1909 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1287, size: 2048, elements: !1303)
!1910 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1852, file: !27, line: 320, baseType: !1911, size: 768, offset: 3328)
!1911 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 768, elements: !1912)
!1912 = !{!1913}
!1913 = !DISubrange(count: 96)
!1914 = !DIDerivedType(tag: DW_TAG_member, name: "fxsave64", scope: !1753, file: !27, line: 325, baseType: !1915, size: 4096)
!1915 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 323, size: 4096, elements: !1916, identifier: "_ZTSN3FPUUt1_E")
!1916 = !{!1917, !1931}
!1917 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1915, baseType: !1918)
!1918 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFXSAVE64", file: !27, line: 299, size: 3328, elements: !1919, identifier: "_ZTS11FpuFXSAVE64")
!1919 = !{!1920, !1921, !1922, !1923, !1924, !1925, !1926, !1927, !1928, !1929, !1930}
!1920 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1918, file: !27, line: 300, baseType: !1762, size: 16)
!1921 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1918, file: !27, line: 301, baseType: !1781, size: 16, offset: 16)
!1922 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1918, file: !27, line: 302, baseType: !1860, size: 8, offset: 32)
!1923 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1918, file: !27, line: 303, baseType: !62, size: 8, offset: 40)
!1924 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1918, file: !27, line: 304, baseType: !28, size: 16, offset: 48)
!1925 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1918, file: !27, line: 305, baseType: !637, size: 64, offset: 64)
!1926 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1918, file: !27, line: 306, baseType: !637, size: 64, offset: 128)
!1927 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr", scope: !1918, file: !27, line: 307, baseType: !1883, size: 32, offset: 192)
!1928 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr_mask", scope: !1918, file: !27, line: 308, baseType: !1883, size: 32, offset: 224)
!1929 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1918, file: !27, line: 309, baseType: !1825, size: 1024, offset: 256)
!1930 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1918, file: !27, line: 310, baseType: !1909, size: 2048, offset: 1280)
!1931 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1915, file: !27, line: 324, baseType: !1911, size: 768, offset: 3328)
!1932 = !DIDerivedType(tag: DW_TAG_member, name: "seg_caches", scope: !1268, file: !27, line: 761, baseType: !1933, size: 768, align: 64, offset: 26240)
!1933 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "SegmentCaches", file: !27, line: 468, size: 768, align: 64, elements: !1934, identifier: "_ZTS13SegmentCaches")
!1934 = !{!1935, !1945, !1946, !1947, !1948, !1949}
!1935 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1933, file: !27, line: 469, baseType: !1936, size: 128)
!1936 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "SegmentShadow", file: !27, line: 88, size: 128, elements: !1937, identifier: "_ZTS13SegmentShadow")
!1937 = !{!1938, !1943, !1944}
!1938 = !DIDerivedType(tag: DW_TAG_member, name: "base", scope: !1936, file: !27, line: 92, baseType: !1939, size: 64)
!1939 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1936, file: !27, line: 89, size: 64, elements: !1940, identifier: "_ZTSN13SegmentShadowUt_E")
!1940 = !{!1941, !1942}
!1941 = !DIDerivedType(tag: DW_TAG_member, name: "dword", scope: !1939, file: !27, line: 90, baseType: !8, size: 32)
!1942 = !DIDerivedType(tag: DW_TAG_member, name: "qword", scope: !1939, file: !27, line: 91, baseType: !637, size: 64)
!1943 = !DIDerivedType(tag: DW_TAG_member, name: "limit", scope: !1936, file: !27, line: 93, baseType: !8, size: 32, offset: 64)
!1944 = !DIDerivedType(tag: DW_TAG_member, name: "flags", scope: !1936, file: !27, line: 94, baseType: !8, size: 32, offset: 96)
!1945 = !DIDerivedType(tag: DW_TAG_member, name: "ss", scope: !1933, file: !27, line: 470, baseType: !1936, size: 128, offset: 128)
!1946 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1933, file: !27, line: 471, baseType: !1936, size: 128, offset: 256)
!1947 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1933, file: !27, line: 472, baseType: !1936, size: 128, offset: 384)
!1948 = !DIDerivedType(tag: DW_TAG_member, name: "fs", scope: !1933, file: !27, line: 473, baseType: !1936, size: 128, offset: 512)
!1949 = !DIDerivedType(tag: DW_TAG_member, name: "gs", scope: !1933, file: !27, line: 474, baseType: !1936, size: 128, offset: 640)
!1950 = !DIDerivedType(tag: DW_TAG_typedef, name: "addr_t", file: !1266, line: 42, baseType: !1951)
!1951 = !DIDerivedType(tag: DW_TAG_typedef, name: "addr64_t", file: !1266, line: 41, baseType: !637)
!1952 = !DILocation(line: 54, column: 8, scope: !1261)
!1953 = !DILocation(line: 55, column: 10, scope: !1261)
!1954 = !DILocation(line: 56, column: 10, scope: !1261)
!1955 = !DILocation(line: 57, column: 10, scope: !1261)
!1956 = !DILocation(line: 58, column: 10, scope: !1261)
!1957 = !DILocation(line: 61, column: 9, scope: !1261)
!1958 = !DILocation(line: 62, column: 9, scope: !1261)
!1959 = !DILocation(line: 63, column: 20, scope: !1261)
!1960 = !DILocation(line: 63, column: 24, scope: !1261)
!1961 = !DILocation(line: 63, column: 28, scope: !1261)
!1962 = !DILocation(line: 69, column: 6, scope: !1261)
!1963 = !DILocation(line: 74, column: 20, scope: !1261)
!1964 = !DILocation(line: 74, column: 24, scope: !1261)
!1965 = !DILocation(line: 74, column: 28, scope: !1261)
!1966 = !DILocation(line: 74, column: 33, scope: !1261)
!1967 = !DILocation(line: 75, column: 20, scope: !1261)
!1968 = !DILocation(line: 75, column: 24, scope: !1261)
!1969 = !DILocation(line: 75, column: 28, scope: !1261)
!1970 = !DILocation(line: 75, column: 33, scope: !1261)
!1971 = !DILocation(line: 76, column: 20, scope: !1261)
!1972 = !DILocation(line: 76, column: 24, scope: !1261)
!1973 = !DILocation(line: 76, column: 28, scope: !1261)
!1974 = !DILocation(line: 76, column: 33, scope: !1261)
!1975 = !DILocation(line: 77, column: 20, scope: !1261)
!1976 = !DILocation(line: 77, column: 24, scope: !1261)
!1977 = !DILocation(line: 77, column: 28, scope: !1261)
!1978 = !DILocation(line: 77, column: 33, scope: !1261)
!1979 = !DILocation(line: 78, column: 20, scope: !1261)
!1980 = !DILocation(line: 78, column: 24, scope: !1261)
!1981 = !DILocation(line: 78, column: 28, scope: !1261)
!1982 = !DILocation(line: 78, column: 33, scope: !1261)
!1983 = !DILocation(line: 79, column: 20, scope: !1261)
!1984 = !DILocation(line: 79, column: 24, scope: !1261)
!1985 = !DILocation(line: 79, column: 28, scope: !1261)
!1986 = !DILocation(line: 79, column: 33, scope: !1261)
!1987 = !DILocation(line: 80, column: 20, scope: !1261)
!1988 = !DILocation(line: 80, column: 24, scope: !1261)
!1989 = !DILocation(line: 80, column: 28, scope: !1261)
!1990 = !DILocation(line: 80, column: 33, scope: !1261)
!1991 = !DILocation(line: 81, column: 20, scope: !1261)
!1992 = !DILocation(line: 81, column: 24, scope: !1261)
!1993 = !DILocation(line: 81, column: 28, scope: !1261)
!1994 = !DILocation(line: 81, column: 33, scope: !1261)
!1995 = !DILocation(line: 83, column: 21, scope: !1261)
!1996 = !DILocation(line: 83, column: 25, scope: !1261)
!1997 = !DILocation(line: 83, column: 29, scope: !1261)
!1998 = !DILocation(line: 83, column: 34, scope: !1261)
!1999 = !DILocation(line: 84, column: 21, scope: !1261)
!2000 = !DILocation(line: 84, column: 25, scope: !1261)
!2001 = !DILocation(line: 84, column: 29, scope: !1261)
!2002 = !DILocation(line: 84, column: 34, scope: !1261)
!2003 = !DILocation(line: 85, column: 21, scope: !1261)
!2004 = !DILocation(line: 85, column: 25, scope: !1261)
!2005 = !DILocation(line: 85, column: 29, scope: !1261)
!2006 = !DILocation(line: 85, column: 34, scope: !1261)
!2007 = !DILocation(line: 86, column: 21, scope: !1261)
!2008 = !DILocation(line: 86, column: 25, scope: !1261)
!2009 = !DILocation(line: 86, column: 29, scope: !1261)
!2010 = !DILocation(line: 86, column: 34, scope: !1261)
!2011 = !DILocation(line: 87, column: 21, scope: !1261)
!2012 = !DILocation(line: 87, column: 25, scope: !1261)
!2013 = !DILocation(line: 87, column: 28, scope: !1261)
!2014 = !DILocation(line: 87, column: 33, scope: !1261)
!2015 = !DILocation(line: 88, column: 21, scope: !1261)
!2016 = !DILocation(line: 88, column: 25, scope: !1261)
!2017 = !DILocation(line: 88, column: 28, scope: !1261)
!2018 = !DILocation(line: 88, column: 33, scope: !1261)
!2019 = !DILocation(line: 89, column: 22, scope: !1261)
!2020 = !DILocation(line: 89, column: 26, scope: !1261)
!2021 = !DILocation(line: 89, column: 30, scope: !1261)
!2022 = !DILocation(line: 89, column: 35, scope: !1261)
!2023 = !DILocation(line: 90, column: 22, scope: !1261)
!2024 = !DILocation(line: 90, column: 26, scope: !1261)
!2025 = !DILocation(line: 90, column: 30, scope: !1261)
!2026 = !DILocation(line: 90, column: 35, scope: !1261)
!2027 = !DILocation(line: 91, column: 22, scope: !1261)
!2028 = !DILocation(line: 91, column: 26, scope: !1261)
!2029 = !DILocation(line: 91, column: 30, scope: !1261)
!2030 = !DILocation(line: 91, column: 35, scope: !1261)
!2031 = !DILocation(line: 92, column: 22, scope: !1261)
!2032 = !DILocation(line: 92, column: 26, scope: !1261)
!2033 = !DILocation(line: 92, column: 30, scope: !1261)
!2034 = !DILocation(line: 92, column: 35, scope: !1261)
!2035 = !DILocation(line: 93, column: 22, scope: !1261)
!2036 = !DILocation(line: 93, column: 26, scope: !1261)
!2037 = !DILocation(line: 93, column: 30, scope: !1261)
!2038 = !DILocation(line: 93, column: 35, scope: !1261)
!2039 = !DILocation(line: 94, column: 22, scope: !1261)
!2040 = !DILocation(line: 94, column: 26, scope: !1261)
!2041 = !DILocation(line: 94, column: 30, scope: !1261)
!2042 = !DILocation(line: 94, column: 35, scope: !1261)
!2043 = !DILocation(line: 96, column: 20, scope: !1261)
!2044 = !DILocation(line: 96, column: 24, scope: !1261)
!2045 = !DILocation(line: 96, column: 28, scope: !1261)
!2046 = !DILocation(line: 97, column: 20, scope: !1261)
!2047 = !DILocation(line: 97, column: 24, scope: !1261)
!2048 = !DILocation(line: 97, column: 28, scope: !1261)
!2049 = !DILocation(line: 98, column: 20, scope: !1261)
!2050 = !DILocation(line: 98, column: 24, scope: !1261)
!2051 = !DILocation(line: 98, column: 28, scope: !1261)
!2052 = !DILocation(line: 99, column: 20, scope: !1261)
!2053 = !DILocation(line: 99, column: 24, scope: !1261)
!2054 = !DILocation(line: 99, column: 28, scope: !1261)
!2055 = !DILocation(line: 100, column: 20, scope: !1261)
!2056 = !DILocation(line: 100, column: 24, scope: !1261)
!2057 = !DILocation(line: 100, column: 28, scope: !1261)
!2058 = !DILocation(line: 101, column: 20, scope: !1261)
!2059 = !DILocation(line: 101, column: 24, scope: !1261)
!2060 = !DILocation(line: 101, column: 28, scope: !1261)
!2061 = !DILocation(line: 102, column: 20, scope: !1261)
!2062 = !DILocation(line: 102, column: 24, scope: !1261)
!2063 = !DILocation(line: 102, column: 28, scope: !1261)
!2064 = !DILocation(line: 103, column: 20, scope: !1261)
!2065 = !DILocation(line: 103, column: 24, scope: !1261)
!2066 = !DILocation(line: 103, column: 28, scope: !1261)
!2067 = !DILocation(line: 105, column: 21, scope: !1261)
!2068 = !DILocation(line: 105, column: 25, scope: !1261)
!2069 = !DILocation(line: 105, column: 28, scope: !1261)
!2070 = !DILocation(line: 106, column: 21, scope: !1261)
!2071 = !DILocation(line: 106, column: 25, scope: !1261)
!2072 = !DILocation(line: 106, column: 28, scope: !1261)
!2073 = !DILocation(line: 107, column: 22, scope: !1261)
!2074 = !DILocation(line: 107, column: 26, scope: !1261)
!2075 = !DILocation(line: 107, column: 30, scope: !1261)
!2076 = !DILocation(line: 108, column: 22, scope: !1261)
!2077 = !DILocation(line: 108, column: 26, scope: !1261)
!2078 = !DILocation(line: 108, column: 30, scope: !1261)
!2079 = !DILocation(line: 109, column: 22, scope: !1261)
!2080 = !DILocation(line: 109, column: 26, scope: !1261)
!2081 = !DILocation(line: 109, column: 30, scope: !1261)
!2082 = !DILocation(line: 110, column: 22, scope: !1261)
!2083 = !DILocation(line: 110, column: 26, scope: !1261)
!2084 = !DILocation(line: 110, column: 30, scope: !1261)
!2085 = !DILocation(line: 111, column: 22, scope: !1261)
!2086 = !DILocation(line: 111, column: 26, scope: !1261)
!2087 = !DILocation(line: 111, column: 30, scope: !1261)
!2088 = !DILocation(line: 112, column: 22, scope: !1261)
!2089 = !DILocation(line: 112, column: 26, scope: !1261)
!2090 = !DILocation(line: 112, column: 30, scope: !1261)
!2091 = !DILocation(line: 114, column: 20, scope: !1261)
!2092 = !DILocation(line: 114, column: 24, scope: !1261)
!2093 = !DILocation(line: 114, column: 28, scope: !1261)
!2094 = !DILocation(line: 116, column: 21, scope: !1261)
!2095 = !DILocation(line: 116, column: 25, scope: !1261)
!2096 = !DILocation(line: 116, column: 29, scope: !1261)
!2097 = !DILocation(line: 117, column: 21, scope: !1261)
!2098 = !DILocation(line: 117, column: 25, scope: !1261)
!2099 = !DILocation(line: 117, column: 29, scope: !1261)
!2100 = !DILocation(line: 118, column: 21, scope: !1261)
!2101 = !DILocation(line: 118, column: 25, scope: !1261)
!2102 = !DILocation(line: 118, column: 29, scope: !1261)
!2103 = !DILocation(line: 119, column: 21, scope: !1261)
!2104 = !DILocation(line: 119, column: 25, scope: !1261)
!2105 = !DILocation(line: 119, column: 29, scope: !1261)
!2106 = !DILocation(line: 120, column: 21, scope: !1261)
!2107 = !DILocation(line: 120, column: 25, scope: !1261)
!2108 = !DILocation(line: 120, column: 29, scope: !1261)
!2109 = !DILocation(line: 121, column: 21, scope: !1261)
!2110 = !DILocation(line: 121, column: 25, scope: !1261)
!2111 = !DILocation(line: 121, column: 29, scope: !1261)
!2112 = !DILocation(line: 122, column: 21, scope: !1261)
!2113 = !DILocation(line: 122, column: 25, scope: !1261)
!2114 = !DILocation(line: 122, column: 29, scope: !1261)
!2115 = !DILocation(line: 123, column: 21, scope: !1261)
!2116 = !DILocation(line: 123, column: 25, scope: !1261)
!2117 = !DILocation(line: 123, column: 29, scope: !1261)
!2118 = !DILocation(line: 124, column: 21, scope: !1261)
!2119 = !DILocation(line: 124, column: 25, scope: !1261)
!2120 = !DILocation(line: 124, column: 29, scope: !1261)
!2121 = !DILocation(line: 127, column: 21, scope: !1261)
!2122 = !DILocation(line: 127, column: 25, scope: !1261)
!2123 = !DILocation(line: 127, column: 28, scope: !1261)
!2124 = !DILocation(line: 128, column: 21, scope: !1261)
!2125 = !DILocation(line: 128, column: 25, scope: !1261)
!2126 = !DILocation(line: 128, column: 28, scope: !1261)
!2127 = !DILocation(line: 129, column: 22, scope: !1261)
!2128 = !DILocation(line: 129, column: 26, scope: !1261)
!2129 = !DILocation(line: 129, column: 30, scope: !1261)
!2130 = !DILocation(line: 130, column: 22, scope: !1261)
!2131 = !DILocation(line: 130, column: 26, scope: !1261)
!2132 = !DILocation(line: 130, column: 30, scope: !1261)
!2133 = !DILocation(line: 131, column: 22, scope: !1261)
!2134 = !DILocation(line: 131, column: 26, scope: !1261)
!2135 = !DILocation(line: 131, column: 30, scope: !1261)
!2136 = !DILocation(line: 132, column: 22, scope: !1261)
!2137 = !DILocation(line: 132, column: 26, scope: !1261)
!2138 = !DILocation(line: 132, column: 30, scope: !1261)
!2139 = !DILocation(line: 133, column: 22, scope: !1261)
!2140 = !DILocation(line: 133, column: 26, scope: !1261)
!2141 = !DILocation(line: 133, column: 30, scope: !1261)
!2142 = !DILocation(line: 134, column: 22, scope: !1261)
!2143 = !DILocation(line: 134, column: 26, scope: !1261)
!2144 = !DILocation(line: 134, column: 30, scope: !1261)
!2145 = !DILocation(line: 136, column: 21, scope: !1261)
!2146 = !DILocation(line: 136, column: 25, scope: !1261)
!2147 = !DILocation(line: 136, column: 29, scope: !1261)
!2148 = !DILocation(line: 137, column: 21, scope: !1261)
!2149 = !DILocation(line: 137, column: 25, scope: !1261)
!2150 = !DILocation(line: 137, column: 29, scope: !1261)
!2151 = !DILocation(line: 138, column: 21, scope: !1261)
!2152 = !DILocation(line: 138, column: 25, scope: !1261)
!2153 = !DILocation(line: 138, column: 29, scope: !1261)
!2154 = !DILocation(line: 139, column: 21, scope: !1261)
!2155 = !DILocation(line: 139, column: 25, scope: !1261)
!2156 = !DILocation(line: 139, column: 29, scope: !1261)
!2157 = !DILocation(line: 140, column: 21, scope: !1261)
!2158 = !DILocation(line: 140, column: 25, scope: !1261)
!2159 = !DILocation(line: 140, column: 29, scope: !1261)
!2160 = !DILocation(line: 141, column: 21, scope: !1261)
!2161 = !DILocation(line: 141, column: 25, scope: !1261)
!2162 = !DILocation(line: 141, column: 29, scope: !1261)
!2163 = !DILocation(line: 142, column: 21, scope: !1261)
!2164 = !DILocation(line: 142, column: 25, scope: !1261)
!2165 = !DILocation(line: 142, column: 29, scope: !1261)
!2166 = !DILocation(line: 143, column: 21, scope: !1261)
!2167 = !DILocation(line: 143, column: 25, scope: !1261)
!2168 = !DILocation(line: 143, column: 29, scope: !1261)
!2169 = !DILocation(line: 144, column: 20, scope: !1261)
!2170 = !DILocation(line: 144, column: 24, scope: !1261)
!2171 = !DILocation(line: 144, column: 27, scope: !1261)
!2172 = !DILocation(line: 145, column: 20, scope: !1261)
!2173 = !DILocation(line: 145, column: 24, scope: !1261)
!2174 = !DILocation(line: 145, column: 27, scope: !1261)
!2175 = !DILocation(line: 146, column: 21, scope: !1261)
!2176 = !DILocation(line: 146, column: 25, scope: !1261)
!2177 = !DILocation(line: 146, column: 29, scope: !1261)
!2178 = !DILocation(line: 147, column: 21, scope: !1261)
!2179 = !DILocation(line: 147, column: 25, scope: !1261)
!2180 = !DILocation(line: 147, column: 29, scope: !1261)
!2181 = !DILocation(line: 148, column: 21, scope: !1261)
!2182 = !DILocation(line: 148, column: 25, scope: !1261)
!2183 = !DILocation(line: 148, column: 29, scope: !1261)
!2184 = !DILocation(line: 149, column: 21, scope: !1261)
!2185 = !DILocation(line: 149, column: 25, scope: !1261)
!2186 = !DILocation(line: 149, column: 29, scope: !1261)
!2187 = !DILocation(line: 150, column: 21, scope: !1261)
!2188 = !DILocation(line: 150, column: 25, scope: !1261)
!2189 = !DILocation(line: 150, column: 29, scope: !1261)
!2190 = !DILocation(line: 151, column: 21, scope: !1261)
!2191 = !DILocation(line: 151, column: 25, scope: !1261)
!2192 = !DILocation(line: 151, column: 29, scope: !1261)
!2193 = !DILocation(line: 152, column: 21, scope: !1261)
!2194 = !DILocation(line: 152, column: 25, scope: !1261)
!2195 = !DILocation(line: 152, column: 29, scope: !1261)
!2196 = !DILocation(line: 155, column: 20, scope: !1261)
!2197 = !DILocation(line: 155, column: 24, scope: !1261)
!2198 = !DILocation(line: 155, column: 27, scope: !1261)
!2199 = !DILocation(line: 156, column: 20, scope: !1261)
!2200 = !DILocation(line: 156, column: 24, scope: !1261)
!2201 = !DILocation(line: 156, column: 27, scope: !1261)
!2202 = !DILocation(line: 157, column: 20, scope: !1261)
!2203 = !DILocation(line: 157, column: 24, scope: !1261)
!2204 = !DILocation(line: 157, column: 27, scope: !1261)
!2205 = !DILocation(line: 158, column: 20, scope: !1261)
!2206 = !DILocation(line: 158, column: 24, scope: !1261)
!2207 = !DILocation(line: 158, column: 27, scope: !1261)
!2208 = !DILocation(line: 159, column: 20, scope: !1261)
!2209 = !DILocation(line: 159, column: 24, scope: !1261)
!2210 = !DILocation(line: 159, column: 27, scope: !1261)
!2211 = !DILocation(line: 160, column: 20, scope: !1261)
!2212 = !DILocation(line: 160, column: 24, scope: !1261)
!2213 = !DILocation(line: 160, column: 27, scope: !1261)
!2214 = !DILocation(line: 164, column: 25, scope: !1261)
!2215 = !DILocation(line: 164, column: 30, scope: !1261)
!2216 = !DILocation(line: 164, column: 38, scope: !1261)
!2217 = !DILocation(line: 165, column: 25, scope: !1261)
!2218 = !DILocation(line: 165, column: 30, scope: !1261)
!2219 = !DILocation(line: 165, column: 38, scope: !1261)
!2220 = !DILocation(line: 205, column: 22, scope: !1261)
!2221 = !DILocation(line: 205, column: 16, scope: !1261)
!2222 = !DILocation(line: 205, column: 29, scope: !1261)
!2223 = !DILocation(line: 206, column: 22, scope: !1261)
!2224 = !DILocation(line: 206, column: 16, scope: !1261)
!2225 = !DILocation(line: 206, column: 29, scope: !1261)
!2226 = !DILocation(line: 207, column: 22, scope: !1261)
!2227 = !DILocation(line: 207, column: 16, scope: !1261)
!2228 = !DILocation(line: 207, column: 29, scope: !1261)
!2229 = !DILocation(line: 208, column: 22, scope: !1261)
!2230 = !DILocation(line: 208, column: 16, scope: !1261)
!2231 = !DILocation(line: 208, column: 29, scope: !1261)
!2232 = !DILocation(line: 209, column: 22, scope: !1261)
!2233 = !DILocation(line: 209, column: 16, scope: !1261)
!2234 = !DILocation(line: 209, column: 29, scope: !1261)
!2235 = !DILocation(line: 210, column: 22, scope: !1261)
!2236 = !DILocation(line: 210, column: 16, scope: !1261)
!2237 = !DILocation(line: 210, column: 29, scope: !1261)
!2238 = !DILocation(line: 211, column: 22, scope: !1261)
!2239 = !DILocation(line: 211, column: 16, scope: !1261)
!2240 = !DILocation(line: 211, column: 29, scope: !1261)
!2241 = !DILocation(line: 212, column: 22, scope: !1261)
!2242 = !DILocation(line: 212, column: 16, scope: !1261)
!2243 = !DILocation(line: 212, column: 29, scope: !1261)
!2244 = !DILocation(line: 214, column: 22, scope: !1261)
!2245 = !DILocation(line: 214, column: 16, scope: !1261)
!2246 = !DILocation(line: 214, column: 29, scope: !1261)
!2247 = !DILocation(line: 215, column: 22, scope: !1261)
!2248 = !DILocation(line: 215, column: 16, scope: !1261)
!2249 = !DILocation(line: 215, column: 29, scope: !1261)
!2250 = !DILocation(line: 216, column: 23, scope: !1261)
!2251 = !DILocation(line: 216, column: 17, scope: !1261)
!2252 = !DILocation(line: 216, column: 31, scope: !1261)
!2253 = !DILocation(line: 217, column: 23, scope: !1261)
!2254 = !DILocation(line: 217, column: 17, scope: !1261)
!2255 = !DILocation(line: 217, column: 31, scope: !1261)
!2256 = !DILocation(line: 218, column: 23, scope: !1261)
!2257 = !DILocation(line: 218, column: 17, scope: !1261)
!2258 = !DILocation(line: 218, column: 31, scope: !1261)
!2259 = !DILocation(line: 219, column: 23, scope: !1261)
!2260 = !DILocation(line: 219, column: 17, scope: !1261)
!2261 = !DILocation(line: 219, column: 31, scope: !1261)
!2262 = !DILocation(line: 220, column: 23, scope: !1261)
!2263 = !DILocation(line: 220, column: 17, scope: !1261)
!2264 = !DILocation(line: 220, column: 31, scope: !1261)
!2265 = !DILocation(line: 221, column: 23, scope: !1261)
!2266 = !DILocation(line: 221, column: 17, scope: !1261)
!2267 = !DILocation(line: 221, column: 31, scope: !1261)
!2268 = !DILocation(line: 245, column: 22, scope: !1261)
!2269 = !DILocation(line: 245, column: 16, scope: !1261)
!2270 = !DILocation(line: 245, column: 29, scope: !1261)
!2271 = !DILocation(line: 246, column: 22, scope: !1261)
!2272 = !DILocation(line: 246, column: 16, scope: !1261)
!2273 = !DILocation(line: 246, column: 29, scope: !1261)
!2274 = !DILocation(line: 247, column: 22, scope: !1261)
!2275 = !DILocation(line: 247, column: 16, scope: !1261)
!2276 = !DILocation(line: 247, column: 29, scope: !1261)
!2277 = !DILocation(line: 248, column: 22, scope: !1261)
!2278 = !DILocation(line: 248, column: 16, scope: !1261)
!2279 = !DILocation(line: 248, column: 29, scope: !1261)
!2280 = !DILocation(line: 249, column: 22, scope: !1261)
!2281 = !DILocation(line: 249, column: 16, scope: !1261)
!2282 = !DILocation(line: 249, column: 29, scope: !1261)
!2283 = !DILocation(line: 250, column: 22, scope: !1261)
!2284 = !DILocation(line: 250, column: 16, scope: !1261)
!2285 = !DILocation(line: 250, column: 29, scope: !1261)
!2286 = !DILocation(line: 251, column: 22, scope: !1261)
!2287 = !DILocation(line: 251, column: 16, scope: !1261)
!2288 = !DILocation(line: 251, column: 29, scope: !1261)
!2289 = !DILocation(line: 252, column: 22, scope: !1261)
!2290 = !DILocation(line: 252, column: 16, scope: !1261)
!2291 = !DILocation(line: 252, column: 29, scope: !1261)
!2292 = !DILocation(line: 255, column: 22, scope: !1261)
!2293 = !DILocation(line: 255, column: 16, scope: !1261)
!2294 = !DILocation(line: 255, column: 29, scope: !1261)
!2295 = !DILocation(line: 256, column: 22, scope: !1261)
!2296 = !DILocation(line: 256, column: 16, scope: !1261)
!2297 = !DILocation(line: 256, column: 29, scope: !1261)
!2298 = !DILocation(line: 257, column: 23, scope: !1261)
!2299 = !DILocation(line: 257, column: 17, scope: !1261)
!2300 = !DILocation(line: 257, column: 31, scope: !1261)
!2301 = !DILocation(line: 258, column: 23, scope: !1261)
!2302 = !DILocation(line: 258, column: 17, scope: !1261)
!2303 = !DILocation(line: 258, column: 31, scope: !1261)
!2304 = !DILocation(line: 259, column: 23, scope: !1261)
!2305 = !DILocation(line: 259, column: 17, scope: !1261)
!2306 = !DILocation(line: 259, column: 31, scope: !1261)
!2307 = !DILocation(line: 260, column: 23, scope: !1261)
!2308 = !DILocation(line: 260, column: 17, scope: !1261)
!2309 = !DILocation(line: 260, column: 31, scope: !1261)
!2310 = !DILocation(line: 261, column: 23, scope: !1261)
!2311 = !DILocation(line: 261, column: 17, scope: !1261)
!2312 = !DILocation(line: 261, column: 31, scope: !1261)
!2313 = !DILocation(line: 262, column: 23, scope: !1261)
!2314 = !DILocation(line: 262, column: 17, scope: !1261)
!2315 = !DILocation(line: 262, column: 31, scope: !1261)
!2316 = !DILocation(line: 285, column: 21, scope: !1261)
!2317 = !DILocation(line: 285, column: 24, scope: !1261)
!2318 = !DILocation(line: 285, column: 15, scope: !1261)
!2319 = !DILocation(line: 285, column: 33, scope: !1261)
!2320 = !DILocation(line: 286, column: 21, scope: !1261)
!2321 = !DILocation(line: 286, column: 24, scope: !1261)
!2322 = !DILocation(line: 286, column: 15, scope: !1261)
!2323 = !DILocation(line: 286, column: 33, scope: !1261)
!2324 = !DILocation(line: 287, column: 21, scope: !1261)
!2325 = !DILocation(line: 287, column: 24, scope: !1261)
!2326 = !DILocation(line: 287, column: 15, scope: !1261)
!2327 = !DILocation(line: 287, column: 33, scope: !1261)
!2328 = !DILocation(line: 288, column: 21, scope: !1261)
!2329 = !DILocation(line: 288, column: 24, scope: !1261)
!2330 = !DILocation(line: 288, column: 15, scope: !1261)
!2331 = !DILocation(line: 288, column: 33, scope: !1261)
!2332 = !DILocation(line: 289, column: 21, scope: !1261)
!2333 = !DILocation(line: 289, column: 24, scope: !1261)
!2334 = !DILocation(line: 289, column: 15, scope: !1261)
!2335 = !DILocation(line: 289, column: 33, scope: !1261)
!2336 = !DILocation(line: 290, column: 21, scope: !1261)
!2337 = !DILocation(line: 290, column: 24, scope: !1261)
!2338 = !DILocation(line: 290, column: 15, scope: !1261)
!2339 = !DILocation(line: 290, column: 33, scope: !1261)
!2340 = !DILocation(line: 291, column: 21, scope: !1261)
!2341 = !DILocation(line: 291, column: 24, scope: !1261)
!2342 = !DILocation(line: 291, column: 15, scope: !1261)
!2343 = !DILocation(line: 291, column: 33, scope: !1261)
!2344 = !DILocation(line: 292, column: 21, scope: !1261)
!2345 = !DILocation(line: 292, column: 24, scope: !1261)
!2346 = !DILocation(line: 292, column: 15, scope: !1261)
!2347 = !DILocation(line: 292, column: 33, scope: !1261)
!2348 = !DILocation(line: 318, column: 21, scope: !1261)
!2349 = !DILocation(line: 318, column: 25, scope: !1261)
!2350 = !DILocation(line: 318, column: 15, scope: !1261)
!2351 = !DILocation(line: 318, column: 34, scope: !1261)
!2352 = !DILocation(line: 318, column: 38, scope: !1261)
!2353 = !DILocation(line: 318, column: 45, scope: !1261)
!2354 = !DILocation(line: 319, column: 21, scope: !1261)
!2355 = !DILocation(line: 319, column: 25, scope: !1261)
!2356 = !DILocation(line: 319, column: 15, scope: !1261)
!2357 = !DILocation(line: 319, column: 34, scope: !1261)
!2358 = !DILocation(line: 319, column: 38, scope: !1261)
!2359 = !DILocation(line: 319, column: 45, scope: !1261)
!2360 = !DILocation(line: 320, column: 21, scope: !1261)
!2361 = !DILocation(line: 320, column: 25, scope: !1261)
!2362 = !DILocation(line: 320, column: 15, scope: !1261)
!2363 = !DILocation(line: 320, column: 34, scope: !1261)
!2364 = !DILocation(line: 320, column: 38, scope: !1261)
!2365 = !DILocation(line: 320, column: 45, scope: !1261)
!2366 = !DILocation(line: 321, column: 21, scope: !1261)
!2367 = !DILocation(line: 321, column: 25, scope: !1261)
!2368 = !DILocation(line: 321, column: 15, scope: !1261)
!2369 = !DILocation(line: 321, column: 34, scope: !1261)
!2370 = !DILocation(line: 321, column: 38, scope: !1261)
!2371 = !DILocation(line: 321, column: 45, scope: !1261)
!2372 = !DILocation(line: 322, column: 21, scope: !1261)
!2373 = !DILocation(line: 322, column: 25, scope: !1261)
!2374 = !DILocation(line: 322, column: 15, scope: !1261)
!2375 = !DILocation(line: 322, column: 34, scope: !1261)
!2376 = !DILocation(line: 322, column: 38, scope: !1261)
!2377 = !DILocation(line: 322, column: 45, scope: !1261)
!2378 = !DILocation(line: 323, column: 21, scope: !1261)
!2379 = !DILocation(line: 323, column: 25, scope: !1261)
!2380 = !DILocation(line: 323, column: 15, scope: !1261)
!2381 = !DILocation(line: 323, column: 34, scope: !1261)
!2382 = !DILocation(line: 323, column: 38, scope: !1261)
!2383 = !DILocation(line: 323, column: 45, scope: !1261)
!2384 = !DILocation(line: 324, column: 21, scope: !1261)
!2385 = !DILocation(line: 324, column: 25, scope: !1261)
!2386 = !DILocation(line: 324, column: 15, scope: !1261)
!2387 = !DILocation(line: 324, column: 34, scope: !1261)
!2388 = !DILocation(line: 324, column: 38, scope: !1261)
!2389 = !DILocation(line: 324, column: 45, scope: !1261)
!2390 = !DILocation(line: 325, column: 21, scope: !1261)
!2391 = !DILocation(line: 325, column: 25, scope: !1261)
!2392 = !DILocation(line: 325, column: 15, scope: !1261)
!2393 = !DILocation(line: 325, column: 34, scope: !1261)
!2394 = !DILocation(line: 325, column: 38, scope: !1261)
!2395 = !DILocation(line: 325, column: 45, scope: !1261)
!2396 = !DILocation(line: 328, column: 20, scope: !1261)
!2397 = !DILocation(line: 328, column: 26, scope: !1261)
!2398 = !DILocation(line: 329, column: 20, scope: !1261)
!2399 = !DILocation(line: 329, column: 26, scope: !1261)
!2400 = !DILocation(line: 330, column: 20, scope: !1261)
!2401 = !DILocation(line: 330, column: 26, scope: !1261)
!2402 = !DILocation(line: 331, column: 20, scope: !1261)
!2403 = !DILocation(line: 331, column: 26, scope: !1261)
!2404 = !DILocation(line: 332, column: 20, scope: !1261)
!2405 = !DILocation(line: 332, column: 26, scope: !1261)
!2406 = !DILocation(line: 333, column: 20, scope: !1261)
!2407 = !DILocation(line: 333, column: 26, scope: !1261)
!2408 = !DILocation(line: 334, column: 20, scope: !1261)
!2409 = !DILocation(line: 334, column: 26, scope: !1261)
!2410 = !DILocation(line: 337, column: 9, scope: !1261)
!2411 = !DILocation(line: 338, column: 9, scope: !1261)
!2412 = !DILocation(line: 339, column: 9, scope: !1261)
!2413 = !DILocation(line: 340, column: 9, scope: !1261)
!2414 = !DILocation(line: 341, column: 9, scope: !1261)
!2415 = !DILocation(line: 342, column: 9, scope: !1261)
!2416 = !DILocation(line: 343, column: 9, scope: !1261)
!2417 = !DILocation(line: 344, column: 9, scope: !1261)
!2418 = !DILocation(line: 347, column: 9, scope: !1261)
!2419 = !DILocation(line: 348, column: 9, scope: !1261)
!2420 = !DILocation(line: 349, column: 9, scope: !1261)
!2421 = !DILocation(line: 350, column: 9, scope: !1261)
!2422 = !DILocation(line: 351, column: 9, scope: !1261)
!2423 = !DILocation(line: 353, column: 9, scope: !1261)
!2424 = !DILocation(line: 357, column: 3, scope: !1261)
!2425 = distinct !DISubprogram(name: "__remill_intrinsics", scope: !2426, file: !2426, line: 35, type: !95, isLocal: false, isDefinition: true, scopeLine: 35, flags: DIFlagPrototyped, isOptimized: false, unit: !1, variables: !7)
!2426 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/Intrinsics.cpp", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!2427 = !DILocation(line: 116, column: 1, scope: !2425)
!2428 = !{!2429, !2429, i64 0}
!2429 = !{!"long", !2430, i64 0}
!2430 = !{!"omnipotent char", !2431, i64 0}
!2431 = !{!"Simple C++ TBAA"}
!2432 = !{!2430, !2430, i64 0}
!2433 = !{!2434, !2430, i64 2065}
!2434 = !{!"_ZTS5State", !2430, i64 16, !2435, i64 2064, !2430, i64 2080, !2436, i64 2088, !2438, i64 2112, !2440, i64 2208, !2441, i64 2480, !2442, i64 2608, !2443, i64 2736, !2430, i64 2760, !2430, i64 2768, !2444, i64 3280}
!2435 = !{!"_ZTS10ArithFlags", !2430, i64 0, !2430, i64 1, !2430, i64 2, !2430, i64 3, !2430, i64 4, !2430, i64 5, !2430, i64 6, !2430, i64 7, !2430, i64 8, !2430, i64 9, !2430, i64 10, !2430, i64 11, !2430, i64 12, !2430, i64 13, !2430, i64 14, !2430, i64 15}
!2436 = !{!"_ZTS8Segments", !2437, i64 0, !2430, i64 2, !2437, i64 4, !2430, i64 6, !2437, i64 8, !2430, i64 10, !2437, i64 12, !2430, i64 14, !2437, i64 16, !2430, i64 18, !2437, i64 20, !2430, i64 22}
!2437 = !{!"short", !2430, i64 0}
!2438 = !{!"_ZTS12AddressSpace", !2429, i64 0, !2439, i64 8, !2429, i64 16, !2439, i64 24, !2429, i64 32, !2439, i64 40, !2429, i64 48, !2439, i64 56, !2429, i64 64, !2439, i64 72, !2429, i64 80, !2439, i64 88}
!2439 = !{!"_ZTS3Reg", !2430, i64 0}
!2440 = !{!"_ZTS3GPR", !2429, i64 0, !2439, i64 8, !2429, i64 16, !2439, i64 24, !2429, i64 32, !2439, i64 40, !2429, i64 48, !2439, i64 56, !2429, i64 64, !2439, i64 72, !2429, i64 80, !2439, i64 88, !2429, i64 96, !2439, i64 104, !2429, i64 112, !2439, i64 120, !2429, i64 128, !2439, i64 136, !2429, i64 144, !2439, i64 152, !2429, i64 160, !2439, i64 168, !2429, i64 176, !2439, i64 184, !2429, i64 192, !2439, i64 200, !2429, i64 208, !2439, i64 216, !2429, i64 224, !2439, i64 232, !2429, i64 240, !2439, i64 248, !2429, i64 256, !2439, i64 264}
!2441 = !{!"_ZTS8X87Stack", !2430, i64 0}
!2442 = !{!"_ZTS3MMX", !2430, i64 0}
!2443 = !{!"_ZTS14FPUStatusFlags", !2430, i64 0, !2430, i64 1, !2430, i64 2, !2430, i64 3, !2430, i64 4, !2430, i64 5, !2430, i64 6, !2430, i64 7, !2430, i64 8, !2430, i64 9, !2430, i64 10, !2430, i64 11, !2430, i64 12, !2430, i64 13, !2430, i64 14, !2430, i64 15, !2430, i64 16, !2430, i64 17, !2430, i64 18, !2430, i64 19, !2430, i64 20}
!2444 = !{!"_ZTS13SegmentCaches", !2445, i64 0, !2445, i64 16, !2445, i64 32, !2445, i64 48, !2445, i64 64, !2445, i64 80}
!2445 = !{!"_ZTS13SegmentShadow", !2430, i64 0, !2446, i64 8, !2446, i64 12}
!2446 = !{!"int", !2430, i64 0}
!2447 = !{!2434, !2430, i64 2067}
!2448 = !{!2434, !2430, i64 2071}
!2449 = !{!2434, !2430, i64 2073}
!2450 = !{!2434, !2430, i64 2077}
!2451 = !{!2434, !2430, i64 2069}
!2452 = !{!2453, !2453, i64 0}
!2453 = !{!"double", !2430, i64 0}
!2454 = !{!2455}
!2455 = distinct !{!2455, !2456, !"ext_6050f8_atan: argument 0"}
!2456 = distinct !{!2456, !"ext_6050f8_atan"}
!2457 = !{!2458}
!2458 = distinct !{!2458, !2456, !"ext_6050f8_atan: argument 1"}
!2459 = !{!2446, !2446, i64 0}
!2460 = !{!2461}
!2461 = distinct !{!2461, !2462, !"ext_6050b8_cos: argument 0"}
!2462 = distinct !{!2462, !"ext_6050b8_cos"}
!2463 = !{!2464}
!2464 = distinct !{!2464, !2462, !"ext_6050b8_cos: argument 1"}
!2465 = !{!2466}
!2466 = distinct !{!2466, !2467, !"ext_6050b8_cos: argument 0"}
!2467 = distinct !{!2467, !"ext_6050b8_cos"}
!2468 = !{!2469}
!2469 = distinct !{!2469, !2467, !"ext_6050b8_cos: argument 1"}
!2470 = !{!2471}
!2471 = distinct !{!2471, !2472, !"ext_4006f0_sin: argument 0"}
!2472 = distinct !{!2472, !"ext_4006f0_sin"}
!2473 = !{!2474}
!2474 = distinct !{!2474, !2472, !"ext_4006f0_sin: argument 1"}
!2475 = !{!2476, !2476, i64 0}
!2476 = !{!"float", !2430, i64 0}
!2477 = !{!2478}
!2478 = distinct !{!2478, !2479, !"ext_605140_sqrt: argument 0"}
!2479 = distinct !{!2479, !"ext_605140_sqrt"}
!2480 = !{!2481}
!2481 = distinct !{!2481, !2479, !"ext_605140_sqrt: argument 1"}
