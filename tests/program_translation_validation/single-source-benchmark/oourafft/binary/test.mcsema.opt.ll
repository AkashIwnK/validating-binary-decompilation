; ModuleID = 'binary/test.mcsema.inline.ll'
source_filename = "llvm-link"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu-elf"

%union.anon = type { i64 }
%seg_404070__rodata_type = type <{ [24 x i8], [88 x i8], [45 x i8], [7 x i8] }>
%seg_604df0__init_array_type = type <{ i64, i64 }>
%seg_604ff0__got_type = type <{ i64, i64 }>
%__bss_start_type = type <{ [8 x i8] }>
%struct.State = type { %struct.ArchState, [32 x %union.VectorReg], %struct.ArithFlags, %union.anon, %struct.Segments, %struct.AddressSpace, %struct.GPR, %struct.X87Stack, %struct.MMX, %struct.FPUStatusFlags, %union.anon, %union.FPU, %struct.SegmentCaches }
%struct.ArchState = type { i32, i32, %union.anon }
%union.VectorReg = type { %union.vec512_t }
%union.vec512_t = type { %struct.uint64v8_t }
%struct.uint64v8_t = type { [8 x i64] }
%struct.ArithFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8 }
%struct.Segments = type { i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector }
%union.SegmentSelector = type { i16 }
%struct.AddressSpace = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.Reg = type { %union.anon }
%struct.GPR = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.X87Stack = type { [8 x %struct.anon.3] }
%struct.anon.3 = type { i64, double }
%struct.MMX = type { [8 x %struct.anon.4] }
%struct.anon.4 = type { i64, %union.vec64_t }
%union.vec64_t = type { %struct.uint64v1_t }
%struct.uint64v1_t = type { [1 x i64] }
%struct.FPUStatusFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, [4 x i8] }
%union.FPU = type { %struct.anon.13 }
%struct.anon.13 = type { %struct.FpuFXSAVE, [96 x i8] }
%struct.FpuFXSAVE = type { %union.SegmentSelector, %union.SegmentSelector, %union.FPUAbridgedTagWord, i8, i16, i32, %union.SegmentSelector, i16, i32, %union.SegmentSelector, i16, %union.FPUControlStatus, %union.FPUControlStatus, [8 x %struct.FPUStackElem], [16 x %union.vec128_t] }
%union.FPUAbridgedTagWord = type { i8 }
%union.FPUControlStatus = type { i32 }
%struct.FPUStackElem = type { %union.anon.11, [6 x i8] }
%union.anon.11 = type { %struct.float80_t }
%struct.float80_t = type { [10 x i8] }
%union.vec128_t = type { %struct.uint128v1_t }
%struct.uint128v1_t = type { [1 x i128] }
%struct.SegmentCaches = type { %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow }
%struct.SegmentShadow = type { %union.anon, i32, i32 }
%struct.Memory = type opaque
%struct.anon.2 = type { i8, i8 }
%"class.std::bitset" = type { %struct.uint64v4_t }
%struct.uint64v4_t = type { [4 x i64] }

@DR0 = external global i64, align 8
@DR1 = external global i64, align 8
@DR2 = external global i64, align 8
@DR3 = external global i64, align 8
@DR4 = external global i64, align 8
@DR5 = external global i64, align 8
@DR6 = external global i64, align 8
@DR7 = external global i64, align 8
@gCR0 = external global %union.anon, align 1
@gCR1 = external global %union.anon, align 1
@gCR2 = external global %union.anon, align 1
@gCR3 = external global %union.anon, align 1
@gCR4 = external global %union.anon, align 1
@gCR8 = external global %union.anon, align 1
@seg_404070__rodata = internal constant %seg_404070__rodata_type <{ [24 x i8] c"\01\00\02\00\00\00\00\00\BB\BD\D7\D9\DF|\DB=\00\00\00\00\00\00P?", [88 x i8] c"\00\00\00\00\00\00\90@\00\00\00\00\00\00\10@\00\00\00\00\00\00\E0C\95\D6&\E8\0B.\11>\8D\ED\B5\A0\F7\C6\B0>\00\00\00\00\00\00\F0?q\8B\89\C0\85.\D0>\00\00\00\00\00\00\00@\00\00\00\00\00\00\00\00\FF\FF\FF\FF\FF\FF\FF\7F\FF\FF\FF\FF\FF\FF\FF\7F", [45 x i8] c"FFT sanity check failed! Difference is: %le\0A\00", [7 x i8] c"%e %e\0A\00" }>
@seg_604df0__init_array = internal global %seg_604df0__init_array_type <{ i64 ptrtoint (void ()* @callback_sub_4007f0_frame_dummy to i64), i64 ptrtoint (void ()* @callback_sub_4007c0___do_global_dtors_aux to i64) }>
@seg_604ff0__got = internal global %seg_604ff0__got_type <{ i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64)* @__libc_start_main to i64), i64 ptrtoint (i64 ()* @__gmon_start__ to i64) }>
@__bss_start = global %__bss_start_type zeroinitializer
@0 = internal global i1 false
@1 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_4007f0_frame_dummy_wrapper
@2 = internal constant void ()* @__mcsema_attach_call
@3 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_4007c0___do_global_dtors_aux_wrapper
@4 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_404060___libc_csu_fini_wrapper
@5 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_403ff0___libc_csu_init_wrapper
@6 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @main_wrapper
@7 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @errorcheck_wrapper
@8 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @.term_proc_wrapper
@9 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @get_time_wrapper
@10 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @makewt_wrapper
@11 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @.init_proc_wrapper
@12 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @cdft_wrapper
@13 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @putdata_wrapper
@llvm.global_ctors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 101, void ()* @__mcsema_constructor, i8* null }]
@llvm.global_dtors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 101, void ()* @__mcsema_destructor, i8* null }]

declare %struct.Memory* @sub_400de0_get_time_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401be0_bitrv2conj_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401840_cftfsub_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400750_deregister_tm_clones_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_403300_cftmdl_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_402480_cftbsub_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400fb0_putdata_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401030_cdft_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4011c0_bitrv2_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400638__init_proc_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_402870_cft1st_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400e30_makewt_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4010d0_errorcheck_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

; Function Attrs: nounwind readnone
declare i32 @llvm.ctpop.i32(i32) #0

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_error(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #1

; Function Attrs: nounwind readnone
declare double @llvm.fabs.f64(double) #0

; Function Attrs: nounwind readnone
declare double @llvm.trunc.f64(double) #0

; Function Attrs: nounwind readnone
declare double @sqrt(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @cos(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @sin(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @atan(double) local_unnamed_addr #2

; Function Attrs: noinline nounwind optnone
define %struct.Memory* @__remill_basic_block(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #3 !dbg !1261 {
  %state = alloca %struct.State*, align 8
  %curr_pc = alloca i64, align 8
  %memory = alloca %struct.Memory*, align 8
  %BRANCH_TAKEN = alloca i8, align 1
  %SS_BASE = alloca i64, align 8
  %ES_BASE = alloca i64, align 8
  %DS_BASE = alloca i64, align 8
  %CS_BASE = alloca i64, align 8
  %STATE = alloca %struct.State*, align 8
  %MEMORY = alloca %struct.Memory*, align 8
  %_DR0 = alloca i64*, align 8
  %_DR1 = alloca i64*, align 8
  %_DR2 = alloca i64*, align 8
  %_DR3 = alloca i64*, align 8
  %_DR4 = alloca i64*, align 8
  %_DR5 = alloca i64*, align 8
  %_DR6 = alloca i64*, align 8
  %_DR7 = alloca i64*, align 8
  %CR0 = alloca i64*, align 8
  %CR1 = alloca i64*, align 8
  %CR2 = alloca i64*, align 8
  %CR3 = alloca i64*, align 8
  %CR4 = alloca i64*, align 8
  %CR8 = alloca i64*, align 8
  store %struct.State* %0, %struct.State** %state, align 8
  store i64 %1, i64* %curr_pc, align 8
  store %struct.Memory* %2, %struct.Memory** %memory, align 8
  store i8 0, i8* %BRANCH_TAKEN, align 1, !dbg !1952
  store i64 0, i64* %SS_BASE, align 8, !dbg !1953
  store i64 0, i64* %ES_BASE, align 8, !dbg !1954
  store i64 0, i64* %DS_BASE, align 8, !dbg !1955
  store i64 0, i64* %CS_BASE, align 8, !dbg !1956
  store %struct.State* %0, %struct.State** %STATE, align 8, !dbg !1957
  store %struct.Memory* %2, %struct.Memory** %MEMORY, align 8, !dbg !1958
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1959
  %5 = getelementptr inbounds %struct.GPR, %struct.GPR* %4, i32 0, i32 33, !dbg !1960
  %6 = getelementptr inbounds %struct.Reg, %struct.Reg* %5, i32 0, i32 0, !dbg !1961
  %PC = bitcast %union.anon* %6 to i64*, !dbg !1961
  store i64 %1, i64* %PC, align 8, !dbg !1962
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1963
  %8 = getelementptr inbounds %struct.GPR, %struct.GPR* %7, i32 0, i32 1, !dbg !1964
  %9 = getelementptr inbounds %struct.Reg, %struct.Reg* %8, i32 0, i32 0, !dbg !1965
  %10 = bitcast %union.anon* %9 to %struct.anon.2*, !dbg !1965
  %AH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %10, i32 0, i32 1, !dbg !1966
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1967
  %12 = getelementptr inbounds %struct.GPR, %struct.GPR* %11, i32 0, i32 3, !dbg !1968
  %13 = getelementptr inbounds %struct.Reg, %struct.Reg* %12, i32 0, i32 0, !dbg !1969
  %14 = bitcast %union.anon* %13 to %struct.anon.2*, !dbg !1969
  %BH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %14, i32 0, i32 1, !dbg !1970
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1971
  %16 = getelementptr inbounds %struct.GPR, %struct.GPR* %15, i32 0, i32 5, !dbg !1972
  %17 = getelementptr inbounds %struct.Reg, %struct.Reg* %16, i32 0, i32 0, !dbg !1973
  %18 = bitcast %union.anon* %17 to %struct.anon.2*, !dbg !1973
  %CH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %18, i32 0, i32 1, !dbg !1974
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1975
  %20 = getelementptr inbounds %struct.GPR, %struct.GPR* %19, i32 0, i32 7, !dbg !1976
  %21 = getelementptr inbounds %struct.Reg, %struct.Reg* %20, i32 0, i32 0, !dbg !1977
  %22 = bitcast %union.anon* %21 to %struct.anon.2*, !dbg !1977
  %DH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %22, i32 0, i32 1, !dbg !1978
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1979
  %24 = getelementptr inbounds %struct.GPR, %struct.GPR* %23, i32 0, i32 1, !dbg !1980
  %25 = getelementptr inbounds %struct.Reg, %struct.Reg* %24, i32 0, i32 0, !dbg !1981
  %26 = bitcast %union.anon* %25 to %struct.anon.2*, !dbg !1981
  %AL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %26, i32 0, i32 0, !dbg !1982
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1983
  %28 = getelementptr inbounds %struct.GPR, %struct.GPR* %27, i32 0, i32 3, !dbg !1984
  %29 = getelementptr inbounds %struct.Reg, %struct.Reg* %28, i32 0, i32 0, !dbg !1985
  %30 = bitcast %union.anon* %29 to %struct.anon.2*, !dbg !1985
  %BL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %30, i32 0, i32 0, !dbg !1986
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1987
  %32 = getelementptr inbounds %struct.GPR, %struct.GPR* %31, i32 0, i32 5, !dbg !1988
  %33 = getelementptr inbounds %struct.Reg, %struct.Reg* %32, i32 0, i32 0, !dbg !1989
  %34 = bitcast %union.anon* %33 to %struct.anon.2*, !dbg !1989
  %CL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %34, i32 0, i32 0, !dbg !1990
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1991
  %36 = getelementptr inbounds %struct.GPR, %struct.GPR* %35, i32 0, i32 7, !dbg !1992
  %37 = getelementptr inbounds %struct.Reg, %struct.Reg* %36, i32 0, i32 0, !dbg !1993
  %38 = bitcast %union.anon* %37 to %struct.anon.2*, !dbg !1993
  %DL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %38, i32 0, i32 0, !dbg !1994
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1995
  %40 = getelementptr inbounds %struct.GPR, %struct.GPR* %39, i32 0, i32 9, !dbg !1996
  %41 = getelementptr inbounds %struct.Reg, %struct.Reg* %40, i32 0, i32 0, !dbg !1997
  %42 = bitcast %union.anon* %41 to %struct.anon.2*, !dbg !1997
  %SIL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %42, i32 0, i32 0, !dbg !1998
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1999
  %44 = getelementptr inbounds %struct.GPR, %struct.GPR* %43, i32 0, i32 11, !dbg !2000
  %45 = getelementptr inbounds %struct.Reg, %struct.Reg* %44, i32 0, i32 0, !dbg !2001
  %46 = bitcast %union.anon* %45 to %struct.anon.2*, !dbg !2001
  %DIL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %46, i32 0, i32 0, !dbg !2002
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2003
  %48 = getelementptr inbounds %struct.GPR, %struct.GPR* %47, i32 0, i32 13, !dbg !2004
  %49 = getelementptr inbounds %struct.Reg, %struct.Reg* %48, i32 0, i32 0, !dbg !2005
  %50 = bitcast %union.anon* %49 to %struct.anon.2*, !dbg !2005
  %SPL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %50, i32 0, i32 0, !dbg !2006
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2007
  %52 = getelementptr inbounds %struct.GPR, %struct.GPR* %51, i32 0, i32 15, !dbg !2008
  %53 = getelementptr inbounds %struct.Reg, %struct.Reg* %52, i32 0, i32 0, !dbg !2009
  %54 = bitcast %union.anon* %53 to %struct.anon.2*, !dbg !2009
  %BPL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %54, i32 0, i32 0, !dbg !2010
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2011
  %56 = getelementptr inbounds %struct.GPR, %struct.GPR* %55, i32 0, i32 17, !dbg !2012
  %57 = getelementptr inbounds %struct.Reg, %struct.Reg* %56, i32 0, i32 0, !dbg !2013
  %58 = bitcast %union.anon* %57 to %struct.anon.2*, !dbg !2013
  %R8B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %58, i32 0, i32 0, !dbg !2014
  %59 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2015
  %60 = getelementptr inbounds %struct.GPR, %struct.GPR* %59, i32 0, i32 19, !dbg !2016
  %61 = getelementptr inbounds %struct.Reg, %struct.Reg* %60, i32 0, i32 0, !dbg !2017
  %62 = bitcast %union.anon* %61 to %struct.anon.2*, !dbg !2017
  %R9B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %62, i32 0, i32 0, !dbg !2018
  %63 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2019
  %64 = getelementptr inbounds %struct.GPR, %struct.GPR* %63, i32 0, i32 21, !dbg !2020
  %65 = getelementptr inbounds %struct.Reg, %struct.Reg* %64, i32 0, i32 0, !dbg !2021
  %66 = bitcast %union.anon* %65 to %struct.anon.2*, !dbg !2021
  %R10B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %66, i32 0, i32 0, !dbg !2022
  %67 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2023
  %68 = getelementptr inbounds %struct.GPR, %struct.GPR* %67, i32 0, i32 23, !dbg !2024
  %69 = getelementptr inbounds %struct.Reg, %struct.Reg* %68, i32 0, i32 0, !dbg !2025
  %70 = bitcast %union.anon* %69 to %struct.anon.2*, !dbg !2025
  %R11B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %70, i32 0, i32 0, !dbg !2026
  %71 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2027
  %72 = getelementptr inbounds %struct.GPR, %struct.GPR* %71, i32 0, i32 25, !dbg !2028
  %73 = getelementptr inbounds %struct.Reg, %struct.Reg* %72, i32 0, i32 0, !dbg !2029
  %74 = bitcast %union.anon* %73 to %struct.anon.2*, !dbg !2029
  %R12B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %74, i32 0, i32 0, !dbg !2030
  %75 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2031
  %76 = getelementptr inbounds %struct.GPR, %struct.GPR* %75, i32 0, i32 27, !dbg !2032
  %77 = getelementptr inbounds %struct.Reg, %struct.Reg* %76, i32 0, i32 0, !dbg !2033
  %78 = bitcast %union.anon* %77 to %struct.anon.2*, !dbg !2033
  %R13B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %78, i32 0, i32 0, !dbg !2034
  %79 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2035
  %80 = getelementptr inbounds %struct.GPR, %struct.GPR* %79, i32 0, i32 29, !dbg !2036
  %81 = getelementptr inbounds %struct.Reg, %struct.Reg* %80, i32 0, i32 0, !dbg !2037
  %82 = bitcast %union.anon* %81 to %struct.anon.2*, !dbg !2037
  %R14B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %82, i32 0, i32 0, !dbg !2038
  %83 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2039
  %84 = getelementptr inbounds %struct.GPR, %struct.GPR* %83, i32 0, i32 31, !dbg !2040
  %85 = getelementptr inbounds %struct.Reg, %struct.Reg* %84, i32 0, i32 0, !dbg !2041
  %86 = bitcast %union.anon* %85 to %struct.anon.2*, !dbg !2041
  %R15B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %86, i32 0, i32 0, !dbg !2042
  %87 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2043
  %88 = getelementptr inbounds %struct.GPR, %struct.GPR* %87, i32 0, i32 1, !dbg !2044
  %89 = getelementptr inbounds %struct.Reg, %struct.Reg* %88, i32 0, i32 0, !dbg !2045
  %AX = bitcast %union.anon* %89 to i16*, !dbg !2045
  %90 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2046
  %91 = getelementptr inbounds %struct.GPR, %struct.GPR* %90, i32 0, i32 3, !dbg !2047
  %92 = getelementptr inbounds %struct.Reg, %struct.Reg* %91, i32 0, i32 0, !dbg !2048
  %BX = bitcast %union.anon* %92 to i16*, !dbg !2048
  %93 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2049
  %94 = getelementptr inbounds %struct.GPR, %struct.GPR* %93, i32 0, i32 5, !dbg !2050
  %95 = getelementptr inbounds %struct.Reg, %struct.Reg* %94, i32 0, i32 0, !dbg !2051
  %CX = bitcast %union.anon* %95 to i16*, !dbg !2051
  %96 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2052
  %97 = getelementptr inbounds %struct.GPR, %struct.GPR* %96, i32 0, i32 7, !dbg !2053
  %98 = getelementptr inbounds %struct.Reg, %struct.Reg* %97, i32 0, i32 0, !dbg !2054
  %DX = bitcast %union.anon* %98 to i16*, !dbg !2054
  %99 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2055
  %100 = getelementptr inbounds %struct.GPR, %struct.GPR* %99, i32 0, i32 9, !dbg !2056
  %101 = getelementptr inbounds %struct.Reg, %struct.Reg* %100, i32 0, i32 0, !dbg !2057
  %SI = bitcast %union.anon* %101 to i16*, !dbg !2057
  %102 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2058
  %103 = getelementptr inbounds %struct.GPR, %struct.GPR* %102, i32 0, i32 11, !dbg !2059
  %104 = getelementptr inbounds %struct.Reg, %struct.Reg* %103, i32 0, i32 0, !dbg !2060
  %DI = bitcast %union.anon* %104 to i16*, !dbg !2060
  %105 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2061
  %106 = getelementptr inbounds %struct.GPR, %struct.GPR* %105, i32 0, i32 13, !dbg !2062
  %107 = getelementptr inbounds %struct.Reg, %struct.Reg* %106, i32 0, i32 0, !dbg !2063
  %SP = bitcast %union.anon* %107 to i16*, !dbg !2063
  %108 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2064
  %109 = getelementptr inbounds %struct.GPR, %struct.GPR* %108, i32 0, i32 15, !dbg !2065
  %110 = getelementptr inbounds %struct.Reg, %struct.Reg* %109, i32 0, i32 0, !dbg !2066
  %BP = bitcast %union.anon* %110 to i16*, !dbg !2066
  %111 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2067
  %112 = getelementptr inbounds %struct.GPR, %struct.GPR* %111, i32 0, i32 17, !dbg !2068
  %113 = getelementptr inbounds %struct.Reg, %struct.Reg* %112, i32 0, i32 0, !dbg !2069
  %R8W = bitcast %union.anon* %113 to i16*, !dbg !2069
  %114 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2070
  %115 = getelementptr inbounds %struct.GPR, %struct.GPR* %114, i32 0, i32 19, !dbg !2071
  %116 = getelementptr inbounds %struct.Reg, %struct.Reg* %115, i32 0, i32 0, !dbg !2072
  %R9W = bitcast %union.anon* %116 to i16*, !dbg !2072
  %117 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2073
  %118 = getelementptr inbounds %struct.GPR, %struct.GPR* %117, i32 0, i32 21, !dbg !2074
  %119 = getelementptr inbounds %struct.Reg, %struct.Reg* %118, i32 0, i32 0, !dbg !2075
  %R10W = bitcast %union.anon* %119 to i16*, !dbg !2075
  %120 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2076
  %121 = getelementptr inbounds %struct.GPR, %struct.GPR* %120, i32 0, i32 23, !dbg !2077
  %122 = getelementptr inbounds %struct.Reg, %struct.Reg* %121, i32 0, i32 0, !dbg !2078
  %R11W = bitcast %union.anon* %122 to i16*, !dbg !2078
  %123 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2079
  %124 = getelementptr inbounds %struct.GPR, %struct.GPR* %123, i32 0, i32 25, !dbg !2080
  %125 = getelementptr inbounds %struct.Reg, %struct.Reg* %124, i32 0, i32 0, !dbg !2081
  %R12W = bitcast %union.anon* %125 to i16*, !dbg !2081
  %126 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2082
  %127 = getelementptr inbounds %struct.GPR, %struct.GPR* %126, i32 0, i32 27, !dbg !2083
  %128 = getelementptr inbounds %struct.Reg, %struct.Reg* %127, i32 0, i32 0, !dbg !2084
  %R13W = bitcast %union.anon* %128 to i16*, !dbg !2084
  %129 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2085
  %130 = getelementptr inbounds %struct.GPR, %struct.GPR* %129, i32 0, i32 29, !dbg !2086
  %131 = getelementptr inbounds %struct.Reg, %struct.Reg* %130, i32 0, i32 0, !dbg !2087
  %R14W = bitcast %union.anon* %131 to i16*, !dbg !2087
  %132 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2088
  %133 = getelementptr inbounds %struct.GPR, %struct.GPR* %132, i32 0, i32 31, !dbg !2089
  %134 = getelementptr inbounds %struct.Reg, %struct.Reg* %133, i32 0, i32 0, !dbg !2090
  %R15W = bitcast %union.anon* %134 to i16*, !dbg !2090
  %135 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2091
  %136 = getelementptr inbounds %struct.GPR, %struct.GPR* %135, i32 0, i32 33, !dbg !2092
  %137 = getelementptr inbounds %struct.Reg, %struct.Reg* %136, i32 0, i32 0, !dbg !2093
  %IP = bitcast %union.anon* %137 to i16*, !dbg !2093
  %138 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2094
  %139 = getelementptr inbounds %struct.GPR, %struct.GPR* %138, i32 0, i32 1, !dbg !2095
  %140 = getelementptr inbounds %struct.Reg, %struct.Reg* %139, i32 0, i32 0, !dbg !2096
  %EAX = bitcast %union.anon* %140 to i32*, !dbg !2096
  %141 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2097
  %142 = getelementptr inbounds %struct.GPR, %struct.GPR* %141, i32 0, i32 3, !dbg !2098
  %143 = getelementptr inbounds %struct.Reg, %struct.Reg* %142, i32 0, i32 0, !dbg !2099
  %EBX = bitcast %union.anon* %143 to i32*, !dbg !2099
  %144 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2100
  %145 = getelementptr inbounds %struct.GPR, %struct.GPR* %144, i32 0, i32 5, !dbg !2101
  %146 = getelementptr inbounds %struct.Reg, %struct.Reg* %145, i32 0, i32 0, !dbg !2102
  %ECX = bitcast %union.anon* %146 to i32*, !dbg !2102
  %147 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2103
  %148 = getelementptr inbounds %struct.GPR, %struct.GPR* %147, i32 0, i32 7, !dbg !2104
  %149 = getelementptr inbounds %struct.Reg, %struct.Reg* %148, i32 0, i32 0, !dbg !2105
  %EDX = bitcast %union.anon* %149 to i32*, !dbg !2105
  %150 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2106
  %151 = getelementptr inbounds %struct.GPR, %struct.GPR* %150, i32 0, i32 9, !dbg !2107
  %152 = getelementptr inbounds %struct.Reg, %struct.Reg* %151, i32 0, i32 0, !dbg !2108
  %ESI = bitcast %union.anon* %152 to i32*, !dbg !2108
  %153 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2109
  %154 = getelementptr inbounds %struct.GPR, %struct.GPR* %153, i32 0, i32 11, !dbg !2110
  %155 = getelementptr inbounds %struct.Reg, %struct.Reg* %154, i32 0, i32 0, !dbg !2111
  %EDI = bitcast %union.anon* %155 to i32*, !dbg !2111
  %156 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2112
  %157 = getelementptr inbounds %struct.GPR, %struct.GPR* %156, i32 0, i32 13, !dbg !2113
  %158 = getelementptr inbounds %struct.Reg, %struct.Reg* %157, i32 0, i32 0, !dbg !2114
  %ESP = bitcast %union.anon* %158 to i32*, !dbg !2114
  %159 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2115
  %160 = getelementptr inbounds %struct.GPR, %struct.GPR* %159, i32 0, i32 15, !dbg !2116
  %161 = getelementptr inbounds %struct.Reg, %struct.Reg* %160, i32 0, i32 0, !dbg !2117
  %EBP = bitcast %union.anon* %161 to i32*, !dbg !2117
  %162 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2118
  %163 = getelementptr inbounds %struct.GPR, %struct.GPR* %162, i32 0, i32 33, !dbg !2119
  %164 = getelementptr inbounds %struct.Reg, %struct.Reg* %163, i32 0, i32 0, !dbg !2120
  %EIP = bitcast %union.anon* %164 to i32*, !dbg !2120
  %165 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2121
  %166 = getelementptr inbounds %struct.GPR, %struct.GPR* %165, i32 0, i32 17, !dbg !2122
  %167 = getelementptr inbounds %struct.Reg, %struct.Reg* %166, i32 0, i32 0, !dbg !2123
  %R8D = bitcast %union.anon* %167 to i32*, !dbg !2123
  %168 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2124
  %169 = getelementptr inbounds %struct.GPR, %struct.GPR* %168, i32 0, i32 19, !dbg !2125
  %170 = getelementptr inbounds %struct.Reg, %struct.Reg* %169, i32 0, i32 0, !dbg !2126
  %R9D = bitcast %union.anon* %170 to i32*, !dbg !2126
  %171 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2127
  %172 = getelementptr inbounds %struct.GPR, %struct.GPR* %171, i32 0, i32 21, !dbg !2128
  %173 = getelementptr inbounds %struct.Reg, %struct.Reg* %172, i32 0, i32 0, !dbg !2129
  %R10D = bitcast %union.anon* %173 to i32*, !dbg !2129
  %174 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2130
  %175 = getelementptr inbounds %struct.GPR, %struct.GPR* %174, i32 0, i32 23, !dbg !2131
  %176 = getelementptr inbounds %struct.Reg, %struct.Reg* %175, i32 0, i32 0, !dbg !2132
  %R11D = bitcast %union.anon* %176 to i32*, !dbg !2132
  %177 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2133
  %178 = getelementptr inbounds %struct.GPR, %struct.GPR* %177, i32 0, i32 25, !dbg !2134
  %179 = getelementptr inbounds %struct.Reg, %struct.Reg* %178, i32 0, i32 0, !dbg !2135
  %R12D = bitcast %union.anon* %179 to i32*, !dbg !2135
  %180 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2136
  %181 = getelementptr inbounds %struct.GPR, %struct.GPR* %180, i32 0, i32 27, !dbg !2137
  %182 = getelementptr inbounds %struct.Reg, %struct.Reg* %181, i32 0, i32 0, !dbg !2138
  %R13D = bitcast %union.anon* %182 to i32*, !dbg !2138
  %183 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2139
  %184 = getelementptr inbounds %struct.GPR, %struct.GPR* %183, i32 0, i32 29, !dbg !2140
  %185 = getelementptr inbounds %struct.Reg, %struct.Reg* %184, i32 0, i32 0, !dbg !2141
  %R14D = bitcast %union.anon* %185 to i32*, !dbg !2141
  %186 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2142
  %187 = getelementptr inbounds %struct.GPR, %struct.GPR* %186, i32 0, i32 31, !dbg !2143
  %188 = getelementptr inbounds %struct.Reg, %struct.Reg* %187, i32 0, i32 0, !dbg !2144
  %R15D = bitcast %union.anon* %188 to i32*, !dbg !2144
  %189 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2145
  %190 = getelementptr inbounds %struct.GPR, %struct.GPR* %189, i32 0, i32 1, !dbg !2146
  %191 = getelementptr inbounds %struct.Reg, %struct.Reg* %190, i32 0, i32 0, !dbg !2147
  %RAX = bitcast %union.anon* %191 to i64*, !dbg !2147
  %192 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2148
  %193 = getelementptr inbounds %struct.GPR, %struct.GPR* %192, i32 0, i32 3, !dbg !2149
  %194 = getelementptr inbounds %struct.Reg, %struct.Reg* %193, i32 0, i32 0, !dbg !2150
  %RBX = bitcast %union.anon* %194 to i64*, !dbg !2150
  %195 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2151
  %196 = getelementptr inbounds %struct.GPR, %struct.GPR* %195, i32 0, i32 5, !dbg !2152
  %197 = getelementptr inbounds %struct.Reg, %struct.Reg* %196, i32 0, i32 0, !dbg !2153
  %RCX = bitcast %union.anon* %197 to i64*, !dbg !2153
  %198 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2154
  %199 = getelementptr inbounds %struct.GPR, %struct.GPR* %198, i32 0, i32 7, !dbg !2155
  %200 = getelementptr inbounds %struct.Reg, %struct.Reg* %199, i32 0, i32 0, !dbg !2156
  %RDX = bitcast %union.anon* %200 to i64*, !dbg !2156
  %201 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2157
  %202 = getelementptr inbounds %struct.GPR, %struct.GPR* %201, i32 0, i32 9, !dbg !2158
  %203 = getelementptr inbounds %struct.Reg, %struct.Reg* %202, i32 0, i32 0, !dbg !2159
  %RSI = bitcast %union.anon* %203 to i64*, !dbg !2159
  %204 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2160
  %205 = getelementptr inbounds %struct.GPR, %struct.GPR* %204, i32 0, i32 11, !dbg !2161
  %206 = getelementptr inbounds %struct.Reg, %struct.Reg* %205, i32 0, i32 0, !dbg !2162
  %RDI = bitcast %union.anon* %206 to i64*, !dbg !2162
  %207 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2163
  %208 = getelementptr inbounds %struct.GPR, %struct.GPR* %207, i32 0, i32 13, !dbg !2164
  %209 = getelementptr inbounds %struct.Reg, %struct.Reg* %208, i32 0, i32 0, !dbg !2165
  %RSP = bitcast %union.anon* %209 to i64*, !dbg !2165
  %210 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2166
  %211 = getelementptr inbounds %struct.GPR, %struct.GPR* %210, i32 0, i32 15, !dbg !2167
  %212 = getelementptr inbounds %struct.Reg, %struct.Reg* %211, i32 0, i32 0, !dbg !2168
  %RBP = bitcast %union.anon* %212 to i64*, !dbg !2168
  %213 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2169
  %214 = getelementptr inbounds %struct.GPR, %struct.GPR* %213, i32 0, i32 17, !dbg !2170
  %215 = getelementptr inbounds %struct.Reg, %struct.Reg* %214, i32 0, i32 0, !dbg !2171
  %R8 = bitcast %union.anon* %215 to i64*, !dbg !2171
  %216 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2172
  %217 = getelementptr inbounds %struct.GPR, %struct.GPR* %216, i32 0, i32 19, !dbg !2173
  %218 = getelementptr inbounds %struct.Reg, %struct.Reg* %217, i32 0, i32 0, !dbg !2174
  %R9 = bitcast %union.anon* %218 to i64*, !dbg !2174
  %219 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2175
  %220 = getelementptr inbounds %struct.GPR, %struct.GPR* %219, i32 0, i32 21, !dbg !2176
  %221 = getelementptr inbounds %struct.Reg, %struct.Reg* %220, i32 0, i32 0, !dbg !2177
  %R10 = bitcast %union.anon* %221 to i64*, !dbg !2177
  %222 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2178
  %223 = getelementptr inbounds %struct.GPR, %struct.GPR* %222, i32 0, i32 23, !dbg !2179
  %224 = getelementptr inbounds %struct.Reg, %struct.Reg* %223, i32 0, i32 0, !dbg !2180
  %R11 = bitcast %union.anon* %224 to i64*, !dbg !2180
  %225 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2181
  %226 = getelementptr inbounds %struct.GPR, %struct.GPR* %225, i32 0, i32 25, !dbg !2182
  %227 = getelementptr inbounds %struct.Reg, %struct.Reg* %226, i32 0, i32 0, !dbg !2183
  %R12 = bitcast %union.anon* %227 to i64*, !dbg !2183
  %228 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2184
  %229 = getelementptr inbounds %struct.GPR, %struct.GPR* %228, i32 0, i32 27, !dbg !2185
  %230 = getelementptr inbounds %struct.Reg, %struct.Reg* %229, i32 0, i32 0, !dbg !2186
  %R13 = bitcast %union.anon* %230 to i64*, !dbg !2186
  %231 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2187
  %232 = getelementptr inbounds %struct.GPR, %struct.GPR* %231, i32 0, i32 29, !dbg !2188
  %233 = getelementptr inbounds %struct.Reg, %struct.Reg* %232, i32 0, i32 0, !dbg !2189
  %R14 = bitcast %union.anon* %233 to i64*, !dbg !2189
  %234 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2190
  %235 = getelementptr inbounds %struct.GPR, %struct.GPR* %234, i32 0, i32 31, !dbg !2191
  %236 = getelementptr inbounds %struct.Reg, %struct.Reg* %235, i32 0, i32 0, !dbg !2192
  %R15 = bitcast %union.anon* %236 to i64*, !dbg !2192
  %237 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2193
  %238 = getelementptr inbounds %struct.GPR, %struct.GPR* %237, i32 0, i32 33, !dbg !2194
  %239 = getelementptr inbounds %struct.Reg, %struct.Reg* %238, i32 0, i32 0, !dbg !2195
  %RIP = bitcast %union.anon* %239 to i64*, !dbg !2195
  %240 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2196
  %241 = getelementptr inbounds %struct.Segments, %struct.Segments* %240, i32 0, i32 1, !dbg !2197
  %SS = bitcast %union.SegmentSelector* %241 to i16*, !dbg !2198
  %242 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2199
  %243 = getelementptr inbounds %struct.Segments, %struct.Segments* %242, i32 0, i32 3, !dbg !2200
  %ES = bitcast %union.SegmentSelector* %243 to i16*, !dbg !2201
  %244 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2202
  %245 = getelementptr inbounds %struct.Segments, %struct.Segments* %244, i32 0, i32 5, !dbg !2203
  %GS = bitcast %union.SegmentSelector* %245 to i16*, !dbg !2204
  %246 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2205
  %247 = getelementptr inbounds %struct.Segments, %struct.Segments* %246, i32 0, i32 7, !dbg !2206
  %FS = bitcast %union.SegmentSelector* %247 to i16*, !dbg !2207
  %248 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2208
  %249 = getelementptr inbounds %struct.Segments, %struct.Segments* %248, i32 0, i32 9, !dbg !2209
  %DS = bitcast %union.SegmentSelector* %249 to i16*, !dbg !2210
  %250 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2211
  %251 = getelementptr inbounds %struct.Segments, %struct.Segments* %250, i32 0, i32 11, !dbg !2212
  %CS = bitcast %union.SegmentSelector* %251 to i16*, !dbg !2213
  %252 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 5, !dbg !2214
  %253 = getelementptr inbounds %struct.AddressSpace, %struct.AddressSpace* %252, i32 0, i32 5, !dbg !2215
  %254 = getelementptr inbounds %struct.Reg, %struct.Reg* %253, i32 0, i32 0, !dbg !2216
  %GS_BASE = bitcast %union.anon* %254 to i64*, !dbg !2216
  %255 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 5, !dbg !2217
  %256 = getelementptr inbounds %struct.AddressSpace, %struct.AddressSpace* %255, i32 0, i32 7, !dbg !2218
  %257 = getelementptr inbounds %struct.Reg, %struct.Reg* %256, i32 0, i32 0, !dbg !2219
  %FS_BASE = bitcast %union.anon* %257 to i64*, !dbg !2219
  %258 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2220
  %259 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %258, i64 0, i64 0, !dbg !2221
  %YMM0 = bitcast %union.VectorReg* %259 to %"class.std::bitset"*, !dbg !2222
  %260 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2223
  %261 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %260, i64 0, i64 1, !dbg !2224
  %YMM1 = bitcast %union.VectorReg* %261 to %"class.std::bitset"*, !dbg !2225
  %262 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2226
  %263 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %262, i64 0, i64 2, !dbg !2227
  %YMM2 = bitcast %union.VectorReg* %263 to %"class.std::bitset"*, !dbg !2228
  %264 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2229
  %265 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %264, i64 0, i64 3, !dbg !2230
  %YMM3 = bitcast %union.VectorReg* %265 to %"class.std::bitset"*, !dbg !2231
  %266 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2232
  %267 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %266, i64 0, i64 4, !dbg !2233
  %YMM4 = bitcast %union.VectorReg* %267 to %"class.std::bitset"*, !dbg !2234
  %268 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2235
  %269 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %268, i64 0, i64 5, !dbg !2236
  %YMM5 = bitcast %union.VectorReg* %269 to %"class.std::bitset"*, !dbg !2237
  %270 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2238
  %271 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %270, i64 0, i64 6, !dbg !2239
  %YMM6 = bitcast %union.VectorReg* %271 to %"class.std::bitset"*, !dbg !2240
  %272 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2241
  %273 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %272, i64 0, i64 7, !dbg !2242
  %YMM7 = bitcast %union.VectorReg* %273 to %"class.std::bitset"*, !dbg !2243
  %274 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2244
  %275 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %274, i64 0, i64 8, !dbg !2245
  %YMM8 = bitcast %union.VectorReg* %275 to %"class.std::bitset"*, !dbg !2246
  %276 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2247
  %277 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %276, i64 0, i64 9, !dbg !2248
  %YMM9 = bitcast %union.VectorReg* %277 to %"class.std::bitset"*, !dbg !2249
  %278 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2250
  %279 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %278, i64 0, i64 10, !dbg !2251
  %YMM10 = bitcast %union.VectorReg* %279 to %"class.std::bitset"*, !dbg !2252
  %280 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2253
  %281 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %280, i64 0, i64 11, !dbg !2254
  %YMM11 = bitcast %union.VectorReg* %281 to %"class.std::bitset"*, !dbg !2255
  %282 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2256
  %283 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %282, i64 0, i64 12, !dbg !2257
  %YMM12 = bitcast %union.VectorReg* %283 to %"class.std::bitset"*, !dbg !2258
  %284 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2259
  %285 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %284, i64 0, i64 13, !dbg !2260
  %YMM13 = bitcast %union.VectorReg* %285 to %"class.std::bitset"*, !dbg !2261
  %286 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2262
  %287 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %286, i64 0, i64 14, !dbg !2263
  %YMM14 = bitcast %union.VectorReg* %287 to %"class.std::bitset"*, !dbg !2264
  %288 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2265
  %289 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %288, i64 0, i64 15, !dbg !2266
  %YMM15 = bitcast %union.VectorReg* %289 to %"class.std::bitset"*, !dbg !2267
  %290 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2268
  %291 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %290, i64 0, i64 0, !dbg !2269
  %XMM0 = bitcast %union.VectorReg* %291 to %union.vec128_t*, !dbg !2270
  %292 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2271
  %293 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %292, i64 0, i64 1, !dbg !2272
  %XMM1 = bitcast %union.VectorReg* %293 to %union.vec128_t*, !dbg !2273
  %294 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2274
  %295 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %294, i64 0, i64 2, !dbg !2275
  %XMM2 = bitcast %union.VectorReg* %295 to %union.vec128_t*, !dbg !2276
  %296 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2277
  %297 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %296, i64 0, i64 3, !dbg !2278
  %XMM3 = bitcast %union.VectorReg* %297 to %union.vec128_t*, !dbg !2279
  %298 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2280
  %299 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %298, i64 0, i64 4, !dbg !2281
  %XMM4 = bitcast %union.VectorReg* %299 to %union.vec128_t*, !dbg !2282
  %300 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2283
  %301 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %300, i64 0, i64 5, !dbg !2284
  %XMM5 = bitcast %union.VectorReg* %301 to %union.vec128_t*, !dbg !2285
  %302 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2286
  %303 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %302, i64 0, i64 6, !dbg !2287
  %XMM6 = bitcast %union.VectorReg* %303 to %union.vec128_t*, !dbg !2288
  %304 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2289
  %305 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %304, i64 0, i64 7, !dbg !2290
  %XMM7 = bitcast %union.VectorReg* %305 to %union.vec128_t*, !dbg !2291
  %306 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2292
  %307 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %306, i64 0, i64 8, !dbg !2293
  %XMM8 = bitcast %union.VectorReg* %307 to %union.vec128_t*, !dbg !2294
  %308 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2295
  %309 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %308, i64 0, i64 9, !dbg !2296
  %XMM9 = bitcast %union.VectorReg* %309 to %union.vec128_t*, !dbg !2297
  %310 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2298
  %311 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %310, i64 0, i64 10, !dbg !2299
  %XMM10 = bitcast %union.VectorReg* %311 to %union.vec128_t*, !dbg !2300
  %312 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2301
  %313 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %312, i64 0, i64 11, !dbg !2302
  %XMM11 = bitcast %union.VectorReg* %313 to %union.vec128_t*, !dbg !2303
  %314 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2304
  %315 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %314, i64 0, i64 12, !dbg !2305
  %XMM12 = bitcast %union.VectorReg* %315 to %union.vec128_t*, !dbg !2306
  %316 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2307
  %317 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %316, i64 0, i64 13, !dbg !2308
  %XMM13 = bitcast %union.VectorReg* %317 to %union.vec128_t*, !dbg !2309
  %318 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2310
  %319 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %318, i64 0, i64 14, !dbg !2311
  %XMM14 = bitcast %union.VectorReg* %319 to %union.vec128_t*, !dbg !2312
  %320 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2313
  %321 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %320, i64 0, i64 15, !dbg !2314
  %XMM15 = bitcast %union.VectorReg* %321 to %union.vec128_t*, !dbg !2315
  %322 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2316
  %323 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %322, i32 0, i32 0, !dbg !2317
  %324 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %323, i64 0, i64 0, !dbg !2318
  %ST0 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %324, i32 0, i32 1, !dbg !2319
  %325 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2320
  %326 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %325, i32 0, i32 0, !dbg !2321
  %327 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %326, i64 0, i64 1, !dbg !2322
  %ST1 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %327, i32 0, i32 1, !dbg !2323
  %328 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2324
  %329 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %328, i32 0, i32 0, !dbg !2325
  %330 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %329, i64 0, i64 2, !dbg !2326
  %ST2 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %330, i32 0, i32 1, !dbg !2327
  %331 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2328
  %332 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %331, i32 0, i32 0, !dbg !2329
  %333 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %332, i64 0, i64 3, !dbg !2330
  %ST3 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %333, i32 0, i32 1, !dbg !2331
  %334 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2332
  %335 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %334, i32 0, i32 0, !dbg !2333
  %336 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %335, i64 0, i64 4, !dbg !2334
  %ST4 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %336, i32 0, i32 1, !dbg !2335
  %337 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2336
  %338 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %337, i32 0, i32 0, !dbg !2337
  %339 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %338, i64 0, i64 5, !dbg !2338
  %ST5 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %339, i32 0, i32 1, !dbg !2339
  %340 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2340
  %341 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %340, i32 0, i32 0, !dbg !2341
  %342 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %341, i64 0, i64 6, !dbg !2342
  %ST6 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %342, i32 0, i32 1, !dbg !2343
  %343 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2344
  %344 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %343, i32 0, i32 0, !dbg !2345
  %345 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %344, i64 0, i64 7, !dbg !2346
  %ST7 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %345, i32 0, i32 1, !dbg !2347
  %346 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2348
  %347 = getelementptr inbounds %struct.MMX, %struct.MMX* %346, i32 0, i32 0, !dbg !2349
  %348 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %347, i64 0, i64 0, !dbg !2350
  %349 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %348, i32 0, i32 1, !dbg !2351
  %350 = bitcast %union.vec64_t* %349 to %struct.uint64v1_t*, !dbg !2352
  %351 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %350, i32 0, i32 0, !dbg !2353
  %MM0 = getelementptr inbounds [1 x i64], [1 x i64]* %351, i64 0, i64 0, !dbg !2350
  %352 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2354
  %353 = getelementptr inbounds %struct.MMX, %struct.MMX* %352, i32 0, i32 0, !dbg !2355
  %354 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %353, i64 0, i64 1, !dbg !2356
  %355 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %354, i32 0, i32 1, !dbg !2357
  %356 = bitcast %union.vec64_t* %355 to %struct.uint64v1_t*, !dbg !2358
  %357 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %356, i32 0, i32 0, !dbg !2359
  %MM1 = getelementptr inbounds [1 x i64], [1 x i64]* %357, i64 0, i64 0, !dbg !2356
  %358 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2360
  %359 = getelementptr inbounds %struct.MMX, %struct.MMX* %358, i32 0, i32 0, !dbg !2361
  %360 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %359, i64 0, i64 2, !dbg !2362
  %361 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %360, i32 0, i32 1, !dbg !2363
  %362 = bitcast %union.vec64_t* %361 to %struct.uint64v1_t*, !dbg !2364
  %363 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %362, i32 0, i32 0, !dbg !2365
  %MM2 = getelementptr inbounds [1 x i64], [1 x i64]* %363, i64 0, i64 0, !dbg !2362
  %364 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2366
  %365 = getelementptr inbounds %struct.MMX, %struct.MMX* %364, i32 0, i32 0, !dbg !2367
  %366 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %365, i64 0, i64 3, !dbg !2368
  %367 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %366, i32 0, i32 1, !dbg !2369
  %368 = bitcast %union.vec64_t* %367 to %struct.uint64v1_t*, !dbg !2370
  %369 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %368, i32 0, i32 0, !dbg !2371
  %MM3 = getelementptr inbounds [1 x i64], [1 x i64]* %369, i64 0, i64 0, !dbg !2368
  %370 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2372
  %371 = getelementptr inbounds %struct.MMX, %struct.MMX* %370, i32 0, i32 0, !dbg !2373
  %372 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %371, i64 0, i64 4, !dbg !2374
  %373 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %372, i32 0, i32 1, !dbg !2375
  %374 = bitcast %union.vec64_t* %373 to %struct.uint64v1_t*, !dbg !2376
  %375 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %374, i32 0, i32 0, !dbg !2377
  %MM4 = getelementptr inbounds [1 x i64], [1 x i64]* %375, i64 0, i64 0, !dbg !2374
  %376 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2378
  %377 = getelementptr inbounds %struct.MMX, %struct.MMX* %376, i32 0, i32 0, !dbg !2379
  %378 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %377, i64 0, i64 5, !dbg !2380
  %379 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %378, i32 0, i32 1, !dbg !2381
  %380 = bitcast %union.vec64_t* %379 to %struct.uint64v1_t*, !dbg !2382
  %381 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %380, i32 0, i32 0, !dbg !2383
  %MM5 = getelementptr inbounds [1 x i64], [1 x i64]* %381, i64 0, i64 0, !dbg !2380
  %382 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2384
  %383 = getelementptr inbounds %struct.MMX, %struct.MMX* %382, i32 0, i32 0, !dbg !2385
  %384 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %383, i64 0, i64 6, !dbg !2386
  %385 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %384, i32 0, i32 1, !dbg !2387
  %386 = bitcast %union.vec64_t* %385 to %struct.uint64v1_t*, !dbg !2388
  %387 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %386, i32 0, i32 0, !dbg !2389
  %MM6 = getelementptr inbounds [1 x i64], [1 x i64]* %387, i64 0, i64 0, !dbg !2386
  %388 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2390
  %389 = getelementptr inbounds %struct.MMX, %struct.MMX* %388, i32 0, i32 0, !dbg !2391
  %390 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %389, i64 0, i64 7, !dbg !2392
  %391 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %390, i32 0, i32 1, !dbg !2393
  %392 = bitcast %union.vec64_t* %391 to %struct.uint64v1_t*, !dbg !2394
  %393 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %392, i32 0, i32 0, !dbg !2395
  %MM7 = getelementptr inbounds [1 x i64], [1 x i64]* %393, i64 0, i64 0, !dbg !2392
  %394 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2396
  %AF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %394, i32 0, i32 5, !dbg !2397
  %395 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2398
  %CF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %395, i32 0, i32 1, !dbg !2399
  %396 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2400
  %DF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %396, i32 0, i32 11, !dbg !2401
  %397 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2402
  %OF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %397, i32 0, i32 13, !dbg !2403
  %398 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2404
  %PF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %398, i32 0, i32 3, !dbg !2405
  %399 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2406
  %SF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %399, i32 0, i32 9, !dbg !2407
  %400 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2408
  %ZF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %400, i32 0, i32 7, !dbg !2409
  store i64* @DR0, i64** %_DR0, align 8, !dbg !2410
  store i64* @DR1, i64** %_DR1, align 8, !dbg !2411
  store i64* @DR2, i64** %_DR2, align 8, !dbg !2412
  store i64* @DR3, i64** %_DR3, align 8, !dbg !2413
  store i64* @DR4, i64** %_DR4, align 8, !dbg !2414
  store i64* @DR5, i64** %_DR5, align 8, !dbg !2415
  store i64* @DR6, i64** %_DR6, align 8, !dbg !2416
  store i64* @DR7, i64** %_DR7, align 8, !dbg !2417
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR0, i32 0, i32 0), i64** %CR0, align 8, !dbg !2418
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR1, i32 0, i32 0), i64** %CR1, align 8, !dbg !2419
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR2, i32 0, i32 0), i64** %CR2, align 8, !dbg !2420
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR3, i32 0, i32 0), i64** %CR3, align 8, !dbg !2421
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR4, i32 0, i32 0), i64** %CR4, align 8, !dbg !2422
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR8, i32 0, i32 0), i64** %CR8, align 8, !dbg !2423
  ret %struct.Memory* %2, !dbg !2424
}

; Function Attrs: noduplicate noinline nounwind optnone
define void @__remill_intrinsics() local_unnamed_addr #4 !dbg !2425 {
  ret void, !dbg !2427
}

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_function_call(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #5

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_jump(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #5

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memcpy(i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @abort() #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memset(i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @printf(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @free(i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @__libc_start_main(i64, i64, i64, i64, i64, i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @gettimeofday(i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @__gmon_start__() #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memalign(i64, i64) #6

; Function Attrs: noinline
define %struct.Memory* @sub_403ff0___libc_csu_init(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_403ff0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 27, i32 0
  %R13D = bitcast %union.anon* %4 to i32*
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 25, i32 0, i32 0
  %R13 = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %R14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 29, i32 0, i32 0
  %R15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 31, i32 0, i32 0
  %5 = load i64, i64* %R15, align 8
  %6 = add i64 %1, 2
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %R14, align 8
  %11 = load i64, i64* %PC, align 8
  %12 = add i64 %11, 2
  store i64 %12, i64* %PC, align 8
  %13 = add i64 %7, -16
  %14 = inttoptr i64 %13 to i64*
  store i64 %10, i64* %14, align 8
  %15 = load i64, i64* %RDX, align 8
  %16 = load i64, i64* %PC, align 8
  store i64 %15, i64* %R15, align 8, !tbaa !2428
  %17 = load i64, i64* %R13, align 8
  %18 = add i64 %16, 5
  store i64 %18, i64* %PC, align 8
  %19 = add i64 %7, -24
  %20 = inttoptr i64 %19 to i64*
  store i64 %17, i64* %20, align 8
  %21 = load i64, i64* %R12, align 8
  %22 = load i64, i64* %PC, align 8
  %23 = add i64 %22, 2
  store i64 %23, i64* %PC, align 8
  %24 = add i64 %7, -32
  %25 = inttoptr i64 %24 to i64*
  store i64 %21, i64* %25, align 8
  %26 = load i64, i64* %PC, align 8
  store i64 ptrtoint (%seg_604df0__init_array_type* @seg_604df0__init_array to i64), i64* %R12, align 8, !tbaa !2428
  %27 = load i64, i64* %RBP, align 8
  %28 = add i64 %26, 8
  store i64 %28, i64* %PC, align 8
  %29 = add i64 %7, -40
  %30 = inttoptr i64 %29 to i64*
  store i64 %27, i64* %30, align 8
  %31 = load i64, i64* %PC, align 8
  store i64 add (i64 ptrtoint (%seg_604df0__init_array_type* @seg_604df0__init_array to i64), i64 8), i64* %RBP, align 8, !tbaa !2428
  %32 = load i64, i64* %RBX, align 8
  %33 = add i64 %31, 8
  store i64 %33, i64* %PC, align 8
  %34 = add i64 %7, -48
  %35 = inttoptr i64 %34 to i64*
  store i64 %32, i64* %35, align 8
  %36 = load i32, i32* %EDI, align 4
  %37 = zext i32 %36 to i64
  %38 = load i64, i64* %PC, align 8
  store i64 %37, i64* %R13, align 8, !tbaa !2428
  %39 = load i64, i64* %RSI, align 8
  store i64 %39, i64* %R14, align 8, !tbaa !2428
  %40 = load i64, i64* %RBP, align 8
  %41 = load i64, i64* %R12, align 8
  %42 = sub i64 %40, %41
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %45 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %48 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %49 = lshr i64 %42, 2
  %50 = trunc i64 %49 to i8
  %51 = and i8 %50, 1
  %52 = ashr i64 %42, 3
  store i64 %52, i64* %RBP, align 8, !tbaa !2428
  store i8 %51, i8* %43, align 1, !tbaa !2432
  %53 = trunc i64 %52 to i32
  %54 = and i32 %53, 255
  %55 = tail call i32 @llvm.ctpop.i32(i32 %54) #10
  %56 = trunc i32 %55 to i8
  %57 = and i8 %56, 1
  %58 = xor i8 %57, 1
  store i8 %58, i8* %44, align 1, !tbaa !2432
  store i8 0, i8* %45, align 1, !tbaa !2432
  %59 = icmp eq i64 %52, 0
  %60 = zext i1 %59 to i8
  store i8 %60, i8* %46, align 1, !tbaa !2432
  %61 = lshr i64 %52, 63
  %62 = trunc i64 %61 to i8
  store i8 %62, i8* %47, align 1, !tbaa !2432
  store i8 0, i8* %48, align 1, !tbaa !2432
  %63 = add i64 %38, -14803
  %64 = add i64 %38, 22
  %65 = add i64 %7, -64
  %66 = inttoptr i64 %65 to i64*
  store i64 %64, i64* %66, align 8
  store i64 %65, i64* %RSP, align 8, !tbaa !2428
  store i64 %63, i64* %PC, align 8, !tbaa !2428
  %67 = tail call %struct.Memory* @sub_400638__init_proc_renamed_(%struct.State* nonnull %0, i64 %63, %struct.Memory* %2)
  %68 = load i64, i64* %RBP, align 8
  %69 = load i64, i64* %PC, align 8
  store i8 0, i8* %43, align 1, !tbaa !2433
  %70 = trunc i64 %68 to i32
  %71 = and i32 %70, 255
  %72 = tail call i32 @llvm.ctpop.i32(i32 %71) #10
  %73 = trunc i32 %72 to i8
  %74 = and i8 %73, 1
  %75 = xor i8 %74, 1
  store i8 %75, i8* %44, align 1, !tbaa !2447
  %76 = icmp eq i64 %68, 0
  %77 = zext i1 %76 to i8
  store i8 %77, i8* %46, align 1, !tbaa !2448
  %78 = lshr i64 %68, 63
  %79 = trunc i64 %78 to i8
  store i8 %79, i8* %47, align 1, !tbaa !2449
  store i8 0, i8* %48, align 1, !tbaa !2450
  store i8 0, i8* %45, align 1, !tbaa !2451
  %.v = select i1 %76, i64 37, i64 5
  %80 = add i64 %69, %.v
  store i64 %80, i64* %PC, align 8, !tbaa !2428
  br i1 %76, label %block_404046, label %block_404026

block_404046:                                     ; preds = %block_404030, %block_403ff0
  %81 = phi i64 [ %80, %block_403ff0 ], [ %179, %block_404030 ]
  %MEMORY.0 = phi %struct.Memory* [ %67, %block_403ff0 ], [ %149, %block_404030 ]
  %82 = load i64, i64* %RSP, align 8
  %83 = add i64 %82, 8
  store i64 %83, i64* %RSP, align 8, !tbaa !2428
  %84 = icmp ugt i64 %82, -9
  %85 = zext i1 %84 to i8
  store i8 %85, i8* %43, align 1, !tbaa !2433
  %86 = trunc i64 %83 to i32
  %87 = and i32 %86, 255
  %88 = tail call i32 @llvm.ctpop.i32(i32 %87) #10
  %89 = trunc i32 %88 to i8
  %90 = and i8 %89, 1
  %91 = xor i8 %90, 1
  store i8 %91, i8* %44, align 1, !tbaa !2447
  %92 = xor i64 %82, %83
  %93 = lshr i64 %92, 4
  %94 = trunc i64 %93 to i8
  %95 = and i8 %94, 1
  store i8 %95, i8* %45, align 1, !tbaa !2451
  %96 = icmp eq i64 %83, 0
  %97 = zext i1 %96 to i8
  store i8 %97, i8* %46, align 1, !tbaa !2448
  %98 = lshr i64 %83, 63
  %99 = trunc i64 %98 to i8
  store i8 %99, i8* %47, align 1, !tbaa !2449
  %100 = lshr i64 %82, 63
  %101 = xor i64 %98, %100
  %102 = add nuw nsw i64 %101, %98
  %103 = icmp eq i64 %102, 2
  %104 = zext i1 %103 to i8
  store i8 %104, i8* %48, align 1, !tbaa !2450
  %105 = add i64 %81, 5
  store i64 %105, i64* %PC, align 8
  %106 = add i64 %82, 16
  %107 = inttoptr i64 %83 to i64*
  %108 = load i64, i64* %107, align 8
  store i64 %108, i64* %RBX, align 8, !tbaa !2428
  store i64 %106, i64* %RSP, align 8, !tbaa !2428
  %109 = add i64 %81, 6
  store i64 %109, i64* %PC, align 8
  %110 = add i64 %82, 24
  %111 = inttoptr i64 %106 to i64*
  %112 = load i64, i64* %111, align 8
  store i64 %112, i64* %RBP, align 8, !tbaa !2428
  store i64 %110, i64* %RSP, align 8, !tbaa !2428
  %113 = add i64 %81, 8
  store i64 %113, i64* %PC, align 8
  %114 = add i64 %82, 32
  %115 = inttoptr i64 %110 to i64*
  %116 = load i64, i64* %115, align 8
  store i64 %116, i64* %R12, align 8, !tbaa !2428
  store i64 %114, i64* %RSP, align 8, !tbaa !2428
  %117 = add i64 %81, 10
  store i64 %117, i64* %PC, align 8
  %118 = add i64 %82, 40
  %119 = inttoptr i64 %114 to i64*
  %120 = load i64, i64* %119, align 8
  store i64 %120, i64* %R13, align 8, !tbaa !2428
  store i64 %118, i64* %RSP, align 8, !tbaa !2428
  %121 = add i64 %81, 12
  store i64 %121, i64* %PC, align 8
  %122 = add i64 %82, 48
  %123 = inttoptr i64 %118 to i64*
  %124 = load i64, i64* %123, align 8
  store i64 %124, i64* %R14, align 8, !tbaa !2428
  store i64 %122, i64* %RSP, align 8, !tbaa !2428
  %125 = add i64 %81, 14
  store i64 %125, i64* %PC, align 8
  %126 = add i64 %82, 56
  %127 = inttoptr i64 %122 to i64*
  %128 = load i64, i64* %127, align 8
  store i64 %128, i64* %R15, align 8, !tbaa !2428
  store i64 %126, i64* %RSP, align 8, !tbaa !2428
  %129 = add i64 %81, 15
  store i64 %129, i64* %PC, align 8
  %130 = inttoptr i64 %126 to i64*
  %131 = load i64, i64* %130, align 8
  store i64 %131, i64* %PC, align 8, !tbaa !2428
  %132 = add i64 %82, 64
  store i64 %132, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_404026:                                     ; preds = %block_403ff0
  store i64 0, i64* %RBX, align 8, !tbaa !2428
  store i8 0, i8* %43, align 1, !tbaa !2433
  store i8 1, i8* %44, align 1, !tbaa !2447
  store i8 1, i8* %46, align 1, !tbaa !2448
  store i8 0, i8* %47, align 1, !tbaa !2449
  store i8 0, i8* %48, align 1, !tbaa !2450
  store i8 0, i8* %45, align 1, !tbaa !2451
  %133 = add i64 %80, 10
  store i64 %133, i64* %PC, align 8
  br label %block_404030

block_404030:                                     ; preds = %block_404030, %block_404026
  %134 = phi i64 [ 0, %block_404026 ], [ %152, %block_404030 ]
  %135 = phi i64 [ %133, %block_404026 ], [ %179, %block_404030 ]
  %MEMORY.1 = phi %struct.Memory* [ %67, %block_404026 ], [ %149, %block_404030 ]
  %136 = load i64, i64* %R15, align 8
  store i64 %136, i64* %RDX, align 8, !tbaa !2428
  %137 = load i64, i64* %R14, align 8
  store i64 %137, i64* %RSI, align 8, !tbaa !2428
  %138 = load i32, i32* %R13D, align 4
  %139 = zext i32 %138 to i64
  store i64 %139, i64* %RDI, align 8, !tbaa !2428
  %140 = load i64, i64* %R12, align 8
  %141 = shl i64 %134, 3
  %142 = add i64 %141, %140
  %143 = add i64 %135, 13
  store i64 %143, i64* %PC, align 8
  %144 = load i64, i64* %RSP, align 8, !tbaa !2428
  %145 = add i64 %144, -8
  %146 = inttoptr i64 %145 to i64*
  store i64 %143, i64* %146, align 8
  store i64 %145, i64* %RSP, align 8, !tbaa !2428
  %147 = inttoptr i64 %142 to i64*
  %148 = load i64, i64* %147, align 8
  store i64 %148, i64* %PC, align 8, !tbaa !2428
  %149 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 %148, %struct.Memory* %MEMORY.1)
  %150 = load i64, i64* %RBX, align 8
  %151 = load i64, i64* %PC, align 8
  %152 = add i64 %150, 1
  store i64 %152, i64* %RBX, align 8, !tbaa !2428
  %153 = lshr i64 %152, 63
  %154 = load i64, i64* %RBP, align 8
  %155 = sub i64 %154, %152
  %156 = icmp ult i64 %154, %152
  %157 = zext i1 %156 to i8
  store i8 %157, i8* %43, align 1, !tbaa !2433
  %158 = trunc i64 %155 to i32
  %159 = and i32 %158, 255
  %160 = tail call i32 @llvm.ctpop.i32(i32 %159) #10
  %161 = trunc i32 %160 to i8
  %162 = and i8 %161, 1
  %163 = xor i8 %162, 1
  store i8 %163, i8* %44, align 1, !tbaa !2447
  %164 = xor i64 %152, %154
  %165 = xor i64 %164, %155
  %166 = lshr i64 %165, 4
  %167 = trunc i64 %166 to i8
  %168 = and i8 %167, 1
  store i8 %168, i8* %45, align 1, !tbaa !2451
  %169 = icmp eq i64 %155, 0
  %170 = zext i1 %169 to i8
  store i8 %170, i8* %46, align 1, !tbaa !2448
  %171 = lshr i64 %155, 63
  %172 = trunc i64 %171 to i8
  store i8 %172, i8* %47, align 1, !tbaa !2449
  %173 = lshr i64 %154, 63
  %174 = xor i64 %153, %173
  %175 = xor i64 %171, %173
  %176 = add nuw nsw i64 %175, %174
  %177 = icmp eq i64 %176, 2
  %178 = zext i1 %177 to i8
  store i8 %178, i8* %48, align 1, !tbaa !2450
  %.v1 = select i1 %169, i64 9, i64 -13
  %179 = add i64 %151, %.v1
  store i64 %179, i64* %PC, align 8, !tbaa !2428
  br i1 %169, label %block_404046, label %block_404030
}

; Function Attrs: noinline
define %struct.Memory* @sub_400fb0_putdata(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400fb0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %5 to i32*
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %6 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %6, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %9 = load i64, i64* %RBP, align 8
  %10 = add i64 %1, 1
  store i64 %10, i64* %PC, align 8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %12 = load i64, i64* %11, align 8, !tbaa !2428
  %13 = add i64 %12, -8
  %14 = inttoptr i64 %13 to i64*
  store i64 %9, i64* %14, align 8
  store i64 %13, i64* %11, align 8, !tbaa !2428
  %15 = load i64, i64* %PC, align 8
  store i64 %13, i64* %RBP, align 8, !tbaa !2428
  %16 = add i64 %12, -12
  %17 = load i32, i32* %EDI, align 4
  %18 = add i64 %15, 6
  store i64 %18, i64* %PC, align 8
  %19 = inttoptr i64 %16 to i32*
  store i32 %17, i32* %19, align 4
  %20 = load i64, i64* %RBP, align 8
  %21 = add i64 %20, -8
  %22 = load i32, i32* %ESI, align 4
  %23 = load i64, i64* %PC, align 8
  %24 = add i64 %23, 3
  store i64 %24, i64* %PC, align 8
  %25 = inttoptr i64 %21 to i32*
  store i32 %22, i32* %25, align 4
  %26 = load i64, i64* %RBP, align 8
  %27 = add i64 %26, -16
  %28 = load i64, i64* %RDX, align 8
  %29 = load i64, i64* %PC, align 8
  %30 = add i64 %29, 4
  store i64 %30, i64* %PC, align 8
  %31 = inttoptr i64 %27 to i64*
  store i64 %28, i64* %31, align 8
  %32 = load i64, i64* %RBP, align 8
  %33 = add i64 %32, -24
  %34 = load i64, i64* %PC, align 8
  %35 = add i64 %34, 7
  store i64 %35, i64* %PC, align 8
  %36 = inttoptr i64 %33 to i32*
  store i32 0, i32* %36, align 4
  %37 = load i64, i64* %RBP, align 8
  %38 = add i64 %37, -4
  %39 = load i64, i64* %PC, align 8
  %40 = add i64 %39, 3
  store i64 %40, i64* %PC, align 8
  %41 = inttoptr i64 %38 to i32*
  %42 = load i32, i32* %41, align 4
  %43 = zext i32 %42 to i64
  store i64 %43, i64* %RSI, align 8, !tbaa !2428
  %44 = add i64 %37, -20
  %45 = add i64 %39, 6
  store i64 %45, i64* %PC, align 8
  %46 = inttoptr i64 %44 to i32*
  store i32 %42, i32* %46, align 4
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %48 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %49 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %50 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %53 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %54 = bitcast i64* %53 to double*
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %56 = bitcast %union.VectorReg* %8 to double*
  %57 = bitcast [32 x %union.VectorReg]* %7 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_400fcb

block_400fcb:                                     ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit, %block_400fb0
  %58 = phi i64 [ %.pre, %block_400fb0 ], [ %214, %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_400fb0 ], [ %160, %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit ]
  %59 = load i64, i64* %RBP, align 8
  %60 = add i64 %59, -20
  %61 = add i64 %58, 3
  store i64 %61, i64* %PC, align 8
  %62 = inttoptr i64 %60 to i32*
  %63 = load i32, i32* %62, align 4
  %64 = zext i32 %63 to i64
  store i64 %64, i64* %RAX, align 8, !tbaa !2428
  %65 = add i64 %59, -8
  %66 = add i64 %58, 6
  store i64 %66, i64* %PC, align 8
  %67 = inttoptr i64 %65 to i32*
  %68 = load i32, i32* %67, align 4
  %69 = sub i32 %63, %68
  %70 = icmp ult i32 %63, %68
  %71 = zext i1 %70 to i8
  store i8 %71, i8* %47, align 1, !tbaa !2433
  %72 = and i32 %69, 255
  %73 = tail call i32 @llvm.ctpop.i32(i32 %72) #10
  %74 = trunc i32 %73 to i8
  %75 = and i8 %74, 1
  %76 = xor i8 %75, 1
  store i8 %76, i8* %48, align 1, !tbaa !2447
  %77 = xor i32 %68, %63
  %78 = xor i32 %77, %69
  %79 = lshr i32 %78, 4
  %80 = trunc i32 %79 to i8
  %81 = and i8 %80, 1
  store i8 %81, i8* %49, align 1, !tbaa !2451
  %82 = icmp eq i32 %69, 0
  %83 = zext i1 %82 to i8
  store i8 %83, i8* %50, align 1, !tbaa !2448
  %84 = lshr i32 %69, 31
  %85 = trunc i32 %84 to i8
  store i8 %85, i8* %51, align 1, !tbaa !2449
  %86 = lshr i32 %63, 31
  %87 = lshr i32 %68, 31
  %88 = xor i32 %87, %86
  %89 = xor i32 %84, %86
  %90 = add nuw nsw i32 %89, %88
  %91 = icmp eq i32 %90, 2
  %92 = zext i1 %91 to i8
  store i8 %92, i8* %52, align 1, !tbaa !2450
  %93 = icmp ne i8 %85, 0
  %94 = xor i1 %93, %91
  %.demorgan = or i1 %82, %94
  %.v = select i1 %.demorgan, i64 12, i64 87
  %95 = add i64 %58, %.v
  store i64 %95, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan, label %block_400fd7, label %block_401022

block_400fd7:                                     ; preds = %block_400fcb
  %96 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 72) to i64*), align 8
  %97 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %96, i64* %97, align 1, !tbaa !2452
  store double 0.000000e+00, double* %54, align 1, !tbaa !2452
  store i64 259200, i64* %RAX, align 8, !tbaa !2428
  %98 = add i64 %59, -24
  %99 = add i64 %95, 20
  store i64 %99, i64* %PC, align 8
  %100 = inttoptr i64 %98 to i32*
  %101 = load i32, i32* %100, align 4
  %102 = sext i32 %101 to i64
  %103 = mul nsw i64 %102, 7141
  %104 = trunc i64 %103 to i32
  %105 = add i32 %104, 54773
  %106 = zext i32 %105 to i64
  store i64 %106, i64* %RCX, align 8, !tbaa !2428
  %107 = icmp ugt i32 %104, -54774
  %108 = zext i1 %107 to i8
  store i8 %108, i8* %47, align 1, !tbaa !2433
  %109 = and i32 %105, 255
  %110 = tail call i32 @llvm.ctpop.i32(i32 %109) #10
  %111 = trunc i32 %110 to i8
  %112 = and i8 %111, 1
  %113 = xor i8 %112, 1
  store i8 %113, i8* %48, align 1, !tbaa !2447
  %114 = xor i32 %104, 16
  %115 = xor i32 %114, %105
  %116 = lshr i32 %115, 4
  %117 = trunc i32 %116 to i8
  %118 = and i8 %117, 1
  store i8 %118, i8* %49, align 1, !tbaa !2451
  %119 = icmp eq i32 %105, 0
  %120 = zext i1 %119 to i8
  store i8 %120, i8* %50, align 1, !tbaa !2448
  %121 = lshr i32 %105, 31
  %122 = trunc i32 %121 to i8
  store i8 %122, i8* %51, align 1, !tbaa !2449
  %123 = lshr i32 %104, 31
  %124 = xor i32 %121, %123
  %125 = add nuw nsw i32 %124, %121
  %126 = icmp eq i32 %125, 2
  %127 = zext i1 %126 to i8
  store i8 %127, i8* %52, align 1, !tbaa !2450
  %128 = add i64 %59, -28
  %129 = add i64 %95, 29
  store i64 %129, i64* %PC, align 8
  %130 = inttoptr i64 %128 to i32*
  store i32 259200, i32* %130, align 4
  %131 = load i32, i32* %ECX, align 4
  %132 = zext i32 %131 to i64
  %133 = load i64, i64* %PC, align 8
  store i64 %132, i64* %RAX, align 8, !tbaa !2428
  %134 = sext i32 %131 to i64
  %135 = lshr i64 %134, 32
  store i64 %135, i64* %55, align 8, !tbaa !2428
  %136 = load i64, i64* %RBP, align 8
  %137 = add i64 %136, -28
  %138 = add i64 %133, 6
  store i64 %138, i64* %PC, align 8
  %139 = inttoptr i64 %137 to i32*
  %140 = load i32, i32* %139, align 4
  %141 = zext i32 %140 to i64
  store i64 %141, i64* %RCX, align 8, !tbaa !2428
  %142 = add i64 %133, 8
  store i64 %142, i64* %PC, align 8
  %143 = sext i32 %140 to i64
  %144 = shl nuw i64 %135, 32
  %145 = or i64 %144, %132
  %146 = sdiv i64 %145, %143
  %147 = shl i64 %146, 32
  %148 = ashr exact i64 %147, 32
  %149 = icmp eq i64 %146, %148
  br i1 %149, label %152, label %150

; <label>:150:                                    ; preds = %block_400fd7
  %151 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %142, %struct.Memory* %MEMORY.0) #11
  %.pre1 = load i64, i64* %RBP, align 8
  %.pre2 = load i32, i32* %EDX, align 4
  %.pre3 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:152:                                    ; preds = %block_400fd7
  %153 = srem i64 %145, %143
  %154 = and i64 %146, 4294967295
  store i64 %154, i64* %RAX, align 8, !tbaa !2428
  %155 = and i64 %153, 4294967295
  store i64 %155, i64* %55, align 8, !tbaa !2428
  store i8 0, i8* %47, align 1, !tbaa !2433
  store i8 0, i8* %48, align 1, !tbaa !2447
  store i8 0, i8* %49, align 1, !tbaa !2451
  store i8 0, i8* %50, align 1, !tbaa !2448
  store i8 0, i8* %51, align 1, !tbaa !2449
  store i8 0, i8* %52, align 1, !tbaa !2450
  %156 = trunc i64 %153 to i32
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %152, %150
  %157 = phi i64 [ %.pre3, %150 ], [ %142, %152 ]
  %158 = phi i32 [ %.pre2, %150 ], [ %156, %152 ]
  %159 = phi i64 [ %.pre1, %150 ], [ %136, %152 ]
  %160 = phi %struct.Memory* [ %151, %150 ], [ %MEMORY.0, %152 ]
  %161 = add i64 %159, -24
  %162 = add i64 %157, 3
  store i64 %162, i64* %PC, align 8
  %163 = inttoptr i64 %161 to i32*
  store i32 %158, i32* %163, align 4
  %164 = load i32, i32* %EDX, align 4
  %165 = load i64, i64* %PC, align 8
  %166 = sitofp i32 %164 to double
  %167 = load double, double* %57, align 1
  %168 = fmul double %166, %167
  store double %168, double* %56, align 1, !tbaa !2452
  %169 = load i64, i64* %RBP, align 8
  %170 = add i64 %169, -16
  %171 = add i64 %165, 12
  store i64 %171, i64* %PC, align 8
  %172 = inttoptr i64 %170 to i64*
  %173 = load i64, i64* %172, align 8
  store i64 %173, i64* %RSI, align 8, !tbaa !2428
  %174 = add i64 %169, -20
  %175 = add i64 %165, 16
  store i64 %175, i64* %PC, align 8
  %176 = inttoptr i64 %174 to i32*
  %177 = load i32, i32* %176, align 4
  %178 = sext i32 %177 to i64
  store i64 %178, i64* %RDI, align 8, !tbaa !2428
  %179 = shl nsw i64 %178, 3
  %180 = add i64 %179, %173
  %181 = add i64 %165, 21
  store i64 %181, i64* %PC, align 8
  %182 = inttoptr i64 %180 to double*
  store double %168, double* %182, align 8
  %183 = load i64, i64* %RBP, align 8
  %184 = add i64 %183, -20
  %185 = load i64, i64* %PC, align 8
  %186 = add i64 %185, 3
  store i64 %186, i64* %PC, align 8
  %187 = inttoptr i64 %184 to i32*
  %188 = load i32, i32* %187, align 4
  %189 = add i32 %188, 1
  %190 = zext i32 %189 to i64
  store i64 %190, i64* %RAX, align 8, !tbaa !2428
  %191 = icmp eq i32 %188, -1
  %192 = icmp eq i32 %189, 0
  %193 = or i1 %191, %192
  %194 = zext i1 %193 to i8
  store i8 %194, i8* %47, align 1, !tbaa !2433
  %195 = and i32 %189, 255
  %196 = tail call i32 @llvm.ctpop.i32(i32 %195) #10
  %197 = trunc i32 %196 to i8
  %198 = and i8 %197, 1
  %199 = xor i8 %198, 1
  store i8 %199, i8* %48, align 1, !tbaa !2447
  %200 = xor i32 %188, %189
  %201 = lshr i32 %200, 4
  %202 = trunc i32 %201 to i8
  %203 = and i8 %202, 1
  store i8 %203, i8* %49, align 1, !tbaa !2451
  %204 = zext i1 %192 to i8
  store i8 %204, i8* %50, align 1, !tbaa !2448
  %205 = lshr i32 %189, 31
  %206 = trunc i32 %205 to i8
  store i8 %206, i8* %51, align 1, !tbaa !2449
  %207 = lshr i32 %188, 31
  %208 = xor i32 %205, %207
  %209 = add nuw nsw i32 %208, %205
  %210 = icmp eq i32 %209, 2
  %211 = zext i1 %210 to i8
  store i8 %211, i8* %52, align 1, !tbaa !2450
  %212 = add i64 %185, 9
  store i64 %212, i64* %PC, align 8
  store i32 %189, i32* %187, align 4
  %213 = load i64, i64* %PC, align 8
  %214 = add i64 %213, -82
  store i64 %214, i64* %PC, align 8, !tbaa !2428
  br label %block_400fcb

block_401022:                                     ; preds = %block_400fcb
  %215 = add i64 %95, 1
  store i64 %215, i64* %PC, align 8
  %216 = load i64, i64* %11, align 8, !tbaa !2428
  %217 = add i64 %216, 8
  %218 = inttoptr i64 %216 to i64*
  %219 = load i64, i64* %218, align 8
  store i64 %219, i64* %RBP, align 8, !tbaa !2428
  store i64 %217, i64* %11, align 8, !tbaa !2428
  %220 = add i64 %95, 2
  store i64 %220, i64* %PC, align 8
  %221 = inttoptr i64 %217 to i64*
  %222 = load i64, i64* %221, align 8
  store i64 %222, i64* %PC, align 8, !tbaa !2428
  %223 = add i64 %216, 16
  store i64 %223, i64* %11, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0
}

; Function Attrs: noinline
define %struct.Memory* @sub_4011c0_bitrv2(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_4011c0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %8 = load i64, i64* %7, align 8, !tbaa !2428
  %9 = add i64 %8, -8
  %10 = inttoptr i64 %9 to i64*
  store i64 %5, i64* %10, align 8
  store i64 %9, i64* %7, align 8, !tbaa !2428
  %11 = load i64, i64* %PC, align 8
  store i64 %9, i64* %RBP, align 8, !tbaa !2428
  %12 = add i64 %8, -12
  %13 = load i32, i32* %EDI, align 4
  %14 = add i64 %11, 6
  store i64 %14, i64* %PC, align 8
  %15 = inttoptr i64 %12 to i32*
  store i32 %13, i32* %15, align 4
  %16 = load i64, i64* %RBP, align 8
  %17 = add i64 %16, -16
  %18 = load i64, i64* %RSI, align 8
  %19 = load i64, i64* %PC, align 8
  %20 = add i64 %19, 4
  store i64 %20, i64* %PC, align 8
  %21 = inttoptr i64 %17 to i64*
  store i64 %18, i64* %21, align 8
  %22 = load i64, i64* %RBP, align 8
  %23 = add i64 %22, -24
  %24 = load i64, i64* %RDX, align 8
  %25 = load i64, i64* %PC, align 8
  %26 = add i64 %25, 4
  store i64 %26, i64* %PC, align 8
  %27 = inttoptr i64 %23 to i64*
  store i64 %24, i64* %27, align 8
  %28 = load i64, i64* %RBP, align 8
  %29 = add i64 %28, -16
  %30 = load i64, i64* %PC, align 8
  %31 = add i64 %30, 4
  store i64 %31, i64* %PC, align 8
  %32 = inttoptr i64 %29 to i64*
  %33 = load i64, i64* %32, align 8
  store i64 %33, i64* %RDX, align 8, !tbaa !2428
  %34 = add i64 %30, 10
  store i64 %34, i64* %PC, align 8
  %35 = inttoptr i64 %33 to i32*
  store i32 0, i32* %35, align 4
  %36 = load i64, i64* %RBP, align 8
  %37 = add i64 %36, -4
  %38 = load i64, i64* %PC, align 8
  %39 = add i64 %38, 3
  store i64 %39, i64* %PC, align 8
  %40 = inttoptr i64 %37 to i32*
  %41 = load i32, i32* %40, align 4
  %42 = zext i32 %41 to i64
  store i64 %42, i64* %RDI, align 8, !tbaa !2428
  %43 = add i64 %36, -44
  %44 = add i64 %38, 6
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %43 to i32*
  store i32 %41, i32* %45, align 4
  %46 = load i64, i64* %RBP, align 8
  %47 = add i64 %46, -48
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 7
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %47 to i32*
  store i32 1, i32* %50, align 4
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %53 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %56 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %.pre = load i64, i64* %PC, align 8
  br label %block_4011e6

block_40127d:                                     ; preds = %block_401289, %block_401276
  %57 = phi i64 [ %3073, %block_401289 ], [ %.pre5, %block_401276 ]
  %58 = load i64, i64* %RBP, align 8
  %59 = add i64 %58, -28
  %60 = add i64 %57, 3
  store i64 %60, i64* %PC, align 8
  %61 = inttoptr i64 %59 to i32*
  %62 = load i32, i32* %61, align 4
  %63 = zext i32 %62 to i64
  store i64 %63, i64* %RAX, align 8, !tbaa !2428
  %64 = add i64 %58, -36
  %65 = add i64 %57, 6
  store i64 %65, i64* %PC, align 8
  %66 = inttoptr i64 %64 to i32*
  %67 = load i32, i32* %66, align 4
  %68 = sub i32 %62, %67
  %69 = icmp ult i32 %62, %67
  %70 = zext i1 %69 to i8
  store i8 %70, i8* %51, align 1, !tbaa !2433
  %71 = and i32 %68, 255
  %72 = tail call i32 @llvm.ctpop.i32(i32 %71) #10
  %73 = trunc i32 %72 to i8
  %74 = and i8 %73, 1
  %75 = xor i8 %74, 1
  store i8 %75, i8* %52, align 1, !tbaa !2447
  %76 = xor i32 %67, %62
  %77 = xor i32 %76, %68
  %78 = lshr i32 %77, 4
  %79 = trunc i32 %78 to i8
  %80 = and i8 %79, 1
  store i8 %80, i8* %53, align 1, !tbaa !2451
  %81 = icmp eq i32 %68, 0
  %82 = zext i1 %81 to i8
  store i8 %82, i8* %54, align 1, !tbaa !2448
  %83 = lshr i32 %68, 31
  %84 = trunc i32 %83 to i8
  store i8 %84, i8* %55, align 1, !tbaa !2449
  %85 = lshr i32 %62, 31
  %86 = lshr i32 %67, 31
  %87 = xor i32 %86, %85
  %88 = xor i32 %83, %85
  %89 = add nuw nsw i32 %88, %87
  %90 = icmp eq i32 %89, 2
  %91 = zext i1 %90 to i8
  store i8 %91, i8* %56, align 1, !tbaa !2450
  %92 = icmp ne i8 %84, 0
  %93 = xor i1 %92, %90
  %.v14 = select i1 %93, i64 12, i64 784
  %94 = add i64 %57, %.v14
  %95 = add i64 %94, 3
  store i64 %95, i64* %PC, align 8
  br i1 %93, label %block_401289, label %block_40158d

block_4011f5:                                     ; preds = %block_4011e6
  %96 = load i32, i32* %262, align 4
  %97 = zext i32 %96 to i64
  %98 = shl nuw i64 %97, 32
  %99 = ashr i64 %98, 33
  %100 = trunc i32 %96 to i8
  %101 = and i8 %100, 1
  %102 = trunc i64 %99 to i32
  %103 = and i64 %99, 4294967295
  store i64 %103, i64* %RAX, align 8, !tbaa !2428
  store i8 %101, i8* %51, align 1, !tbaa !2432
  %104 = and i32 %102, 255
  %105 = tail call i32 @llvm.ctpop.i32(i32 %104) #10
  %106 = trunc i32 %105 to i8
  %107 = and i8 %106, 1
  %108 = xor i8 %107, 1
  store i8 %108, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %109 = icmp eq i32 %102, 0
  %110 = zext i1 %109 to i8
  store i8 %110, i8* %54, align 1, !tbaa !2432
  %111 = lshr i64 %99, 31
  %112 = trunc i64 %111 to i8
  %113 = and i8 %112, 1
  store i8 %113, i8* %55, align 1, !tbaa !2432
  store i8 0, i8* %56, align 1, !tbaa !2432
  %114 = add i64 %289, 9
  store i64 %114, i64* %PC, align 8
  store i32 %102, i32* %262, align 4
  %115 = load i64, i64* %RBP, align 8
  %116 = add i64 %115, -28
  %117 = load i64, i64* %PC, align 8
  %118 = add i64 %117, 7
  store i64 %118, i64* %PC, align 8
  %119 = inttoptr i64 %116 to i32*
  store i32 0, i32* %119, align 4
  %.pre3 = load i64, i64* %PC, align 8
  br label %block_401205

block_40166b:                                     ; preds = %block_40181a, %block_401664
  %120 = phi i64 [ %352, %block_40181a ], [ %.pre6, %block_401664 ]
  %121 = load i64, i64* %RBP, align 8
  %122 = add i64 %121, -36
  %123 = add i64 %120, 3
  store i64 %123, i64* %PC, align 8
  %124 = inttoptr i64 %122 to i32*
  %125 = load i32, i32* %124, align 4
  %126 = zext i32 %125 to i64
  store i64 %126, i64* %RAX, align 8, !tbaa !2428
  %127 = add i64 %121, -48
  %128 = add i64 %120, 6
  store i64 %128, i64* %PC, align 8
  %129 = inttoptr i64 %127 to i32*
  %130 = load i32, i32* %129, align 4
  %131 = sub i32 %125, %130
  %132 = icmp ult i32 %125, %130
  %133 = zext i1 %132 to i8
  store i8 %133, i8* %51, align 1, !tbaa !2433
  %134 = and i32 %131, 255
  %135 = tail call i32 @llvm.ctpop.i32(i32 %134) #10
  %136 = trunc i32 %135 to i8
  %137 = and i8 %136, 1
  %138 = xor i8 %137, 1
  store i8 %138, i8* %52, align 1, !tbaa !2447
  %139 = xor i32 %130, %125
  %140 = xor i32 %139, %131
  %141 = lshr i32 %140, 4
  %142 = trunc i32 %141 to i8
  %143 = and i8 %142, 1
  store i8 %143, i8* %53, align 1, !tbaa !2451
  %144 = icmp eq i32 %131, 0
  %145 = zext i1 %144 to i8
  store i8 %145, i8* %54, align 1, !tbaa !2448
  %146 = lshr i32 %131, 31
  %147 = trunc i32 %146 to i8
  store i8 %147, i8* %55, align 1, !tbaa !2449
  %148 = lshr i32 %125, 31
  %149 = lshr i32 %130, 31
  %150 = xor i32 %149, %148
  %151 = xor i32 %146, %148
  %152 = add nuw nsw i32 %151, %150
  %153 = icmp eq i32 %152, 2
  %154 = zext i1 %153 to i8
  store i8 %154, i8* %56, align 1, !tbaa !2450
  %155 = icmp ne i8 %147, 0
  %156 = xor i1 %155, %153
  %.v20 = select i1 %156, i64 12, i64 450
  %157 = add i64 %120, %.v20
  store i64 %157, i64* %PC, align 8, !tbaa !2428
  br i1 %156, label %block_401677, label %block_40182d

block_40167e:                                     ; preds = %block_40168a, %block_401677
  %158 = phi i64 [ %1677, %block_40168a ], [ %.pre7, %block_401677 ]
  %159 = load i64, i64* %RBP, align 8
  %160 = add i64 %159, -28
  %161 = add i64 %158, 3
  store i64 %161, i64* %PC, align 8
  %162 = inttoptr i64 %160 to i32*
  %163 = load i32, i32* %162, align 4
  %164 = zext i32 %163 to i64
  store i64 %164, i64* %RAX, align 8, !tbaa !2428
  %165 = add i64 %159, -36
  %166 = add i64 %158, 6
  store i64 %166, i64* %PC, align 8
  %167 = inttoptr i64 %165 to i32*
  %168 = load i32, i32* %167, align 4
  %169 = sub i32 %163, %168
  %170 = icmp ult i32 %163, %168
  %171 = zext i1 %170 to i8
  store i8 %171, i8* %51, align 1, !tbaa !2433
  %172 = and i32 %169, 255
  %173 = tail call i32 @llvm.ctpop.i32(i32 %172) #10
  %174 = trunc i32 %173 to i8
  %175 = and i8 %174, 1
  %176 = xor i8 %175, 1
  store i8 %176, i8* %52, align 1, !tbaa !2447
  %177 = xor i32 %168, %163
  %178 = xor i32 %177, %169
  %179 = lshr i32 %178, 4
  %180 = trunc i32 %179 to i8
  %181 = and i8 %180, 1
  store i8 %181, i8* %53, align 1, !tbaa !2451
  %182 = icmp eq i32 %169, 0
  %183 = zext i1 %182 to i8
  store i8 %183, i8* %54, align 1, !tbaa !2448
  %184 = lshr i32 %169, 31
  %185 = trunc i32 %184 to i8
  store i8 %185, i8* %55, align 1, !tbaa !2449
  %186 = lshr i32 %163, 31
  %187 = lshr i32 %168, 31
  %188 = xor i32 %187, %186
  %189 = xor i32 %184, %186
  %190 = add nuw nsw i32 %189, %188
  %191 = icmp eq i32 %190, 2
  %192 = zext i1 %191 to i8
  store i8 %192, i8* %56, align 1, !tbaa !2450
  %193 = icmp ne i8 %185, 0
  %194 = xor i1 %193, %191
  %.v21 = select i1 %194, i64 12, i64 412
  %195 = add i64 %158, %.v21
  store i64 %195, i64* %PC, align 8, !tbaa !2428
  br i1 %194, label %block_40168a, label %block_40181a

block_40126a:                                     ; preds = %block_40158d, %block_401263
  %196 = phi i64 [ %949, %block_40158d ], [ %.pre4, %block_401263 ]
  %197 = load i64, i64* %RBP, align 8
  %198 = add i64 %197, -36
  %199 = add i64 %196, 3
  store i64 %199, i64* %PC, align 8
  %200 = inttoptr i64 %198 to i32*
  %201 = load i32, i32* %200, align 4
  %202 = zext i32 %201 to i64
  store i64 %202, i64* %RAX, align 8, !tbaa !2428
  %203 = add i64 %197, -48
  %204 = add i64 %196, 6
  store i64 %204, i64* %PC, align 8
  %205 = inttoptr i64 %203 to i32*
  %206 = load i32, i32* %205, align 4
  %207 = sub i32 %201, %206
  %208 = icmp ult i32 %201, %206
  %209 = zext i1 %208 to i8
  store i8 %209, i8* %51, align 1, !tbaa !2433
  %210 = and i32 %207, 255
  %211 = tail call i32 @llvm.ctpop.i32(i32 %210) #10
  %212 = trunc i32 %211 to i8
  %213 = and i8 %212, 1
  %214 = xor i8 %213, 1
  store i8 %214, i8* %52, align 1, !tbaa !2447
  %215 = xor i32 %206, %201
  %216 = xor i32 %215, %207
  %217 = lshr i32 %216, 4
  %218 = trunc i32 %217 to i8
  %219 = and i8 %218, 1
  store i8 %219, i8* %53, align 1, !tbaa !2451
  %220 = icmp eq i32 %207, 0
  %221 = zext i1 %220 to i8
  store i8 %221, i8* %54, align 1, !tbaa !2448
  %222 = lshr i32 %207, 31
  %223 = trunc i32 %222 to i8
  store i8 %223, i8* %55, align 1, !tbaa !2449
  %224 = lshr i32 %201, 31
  %225 = lshr i32 %206, 31
  %226 = xor i32 %225, %224
  %227 = xor i32 %222, %224
  %228 = add nuw nsw i32 %227, %226
  %229 = icmp eq i32 %228, 2
  %230 = zext i1 %229 to i8
  store i8 %230, i8* %56, align 1, !tbaa !2450
  %231 = icmp ne i8 %223, 0
  %232 = xor i1 %231, %229
  %.v13 = select i1 %232, i64 12, i64 1013
  %233 = add i64 %196, %.v13
  store i64 %233, i64* %PC, align 8, !tbaa !2428
  br i1 %232, label %block_401276, label %block_40165f

block_401677:                                     ; preds = %block_40166b
  %234 = add i64 %121, -28
  %235 = add i64 %157, 7
  store i64 %235, i64* %PC, align 8
  %236 = inttoptr i64 %234 to i32*
  store i32 0, i32* %236, align 4
  %.pre7 = load i64, i64* %PC, align 8
  br label %block_40167e

block_401263:                                     ; preds = %block_40124b
  store i32 0, i32* %426, align 4
  %237 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %238 = bitcast i64* %237 to double*
  %.pre4 = load i64, i64* %PC, align 8
  br label %block_40126a

block_4011e6:                                     ; preds = %block_40123d, %block_4011c0
  %239 = phi i64 [ %312, %block_40123d ], [ %.pre, %block_4011c0 ]
  %240 = load i64, i64* %RBP, align 8
  %241 = add i64 %240, -48
  %242 = add i64 %239, 3
  store i64 %242, i64* %PC, align 8
  %243 = inttoptr i64 %241 to i32*
  %244 = load i32, i32* %243, align 4
  %245 = shl i32 %244, 3
  %246 = zext i32 %245 to i64
  store i64 %246, i64* %RAX, align 8, !tbaa !2428
  %247 = lshr i32 %244, 29
  %248 = trunc i32 %247 to i8
  %249 = and i8 %248, 1
  store i8 %249, i8* %51, align 1, !tbaa !2432
  %250 = and i32 %245, 248
  %251 = tail call i32 @llvm.ctpop.i32(i32 %250) #10
  %252 = trunc i32 %251 to i8
  %253 = and i8 %252, 1
  %254 = xor i8 %253, 1
  store i8 %254, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %255 = icmp eq i32 %245, 0
  %256 = zext i1 %255 to i8
  store i8 %256, i8* %54, align 1, !tbaa !2432
  %257 = lshr i32 %244, 28
  %258 = and i32 %257, 1
  %259 = trunc i32 %258 to i8
  store i8 %259, i8* %55, align 1, !tbaa !2432
  store i8 0, i8* %56, align 1, !tbaa !2432
  %260 = add i64 %240, -44
  %261 = add i64 %239, 9
  store i64 %261, i64* %PC, align 8
  %262 = inttoptr i64 %260 to i32*
  %263 = load i32, i32* %262, align 4
  %264 = sub i32 %245, %263
  %265 = icmp ult i32 %245, %263
  %266 = zext i1 %265 to i8
  store i8 %266, i8* %51, align 1, !tbaa !2433
  %267 = and i32 %264, 255
  %268 = tail call i32 @llvm.ctpop.i32(i32 %267) #10
  %269 = trunc i32 %268 to i8
  %270 = and i8 %269, 1
  %271 = xor i8 %270, 1
  store i8 %271, i8* %52, align 1, !tbaa !2447
  %272 = xor i32 %263, %245
  %273 = xor i32 %272, %264
  %274 = lshr i32 %273, 4
  %275 = trunc i32 %274 to i8
  %276 = and i8 %275, 1
  store i8 %276, i8* %53, align 1, !tbaa !2451
  %277 = icmp eq i32 %264, 0
  %278 = zext i1 %277 to i8
  store i8 %278, i8* %54, align 1, !tbaa !2448
  %279 = lshr i32 %264, 31
  %280 = trunc i32 %279 to i8
  store i8 %280, i8* %55, align 1, !tbaa !2449
  %281 = lshr i32 %263, 31
  %282 = xor i32 %281, %258
  %283 = xor i32 %279, %258
  %284 = add nuw nsw i32 %283, %282
  %285 = icmp eq i32 %284, 2
  %286 = zext i1 %285 to i8
  store i8 %286, i8* %56, align 1, !tbaa !2450
  %287 = icmp ne i8 %280, 0
  %288 = xor i1 %287, %285
  %.v = select i1 %288, i64 15, i64 101
  %289 = add i64 %239, %.v
  %290 = add i64 %289, 3
  store i64 %290, i64* %PC, align 8
  br i1 %288, label %block_4011f5, label %block_40124b

block_40123d:                                     ; preds = %block_401205
  %291 = add i64 %3111, 3
  store i64 %291, i64* %PC, align 8
  %292 = load i32, i32* %3083, align 4
  %293 = shl i32 %292, 1
  %294 = icmp slt i32 %292, 0
  %295 = icmp slt i32 %293, 0
  %296 = xor i1 %294, %295
  %297 = zext i32 %293 to i64
  store i64 %297, i64* %RAX, align 8, !tbaa !2428
  %.lobit = lshr i32 %292, 31
  %298 = trunc i32 %.lobit to i8
  store i8 %298, i8* %51, align 1, !tbaa !2432
  %299 = and i32 %293, 254
  %300 = tail call i32 @llvm.ctpop.i32(i32 %299) #10
  %301 = trunc i32 %300 to i8
  %302 = and i8 %301, 1
  %303 = xor i8 %302, 1
  store i8 %303, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %304 = icmp eq i32 %293, 0
  %305 = zext i1 %304 to i8
  store i8 %305, i8* %54, align 1, !tbaa !2432
  %306 = lshr i32 %292, 30
  %307 = trunc i32 %306 to i8
  %308 = and i8 %307, 1
  store i8 %308, i8* %55, align 1, !tbaa !2432
  %309 = zext i1 %296 to i8
  store i8 %309, i8* %56, align 1, !tbaa !2432
  %310 = add i64 %3111, 9
  store i64 %310, i64* %PC, align 8
  store i32 %293, i32* %3083, align 4
  %311 = load i64, i64* %PC, align 8
  %312 = add i64 %311, -96
  store i64 %312, i64* %PC, align 8, !tbaa !2428
  br label %block_4011e6

block_401664:                                     ; preds = %block_40124b
  store i32 1, i32* %426, align 4
  %313 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %314 = bitcast i64* %313 to double*
  %.pre6 = load i64, i64* %PC, align 8
  br label %block_40166b

block_401832:                                     ; preds = %block_40165f, %block_40182d
  %.sink = phi i64 [ %353, %block_40165f ], [ %324, %block_40182d ]
  %315 = add i64 %.sink, 1
  store i64 %315, i64* %PC, align 8
  %316 = load i64, i64* %7, align 8, !tbaa !2428
  %317 = add i64 %316, 8
  %318 = inttoptr i64 %316 to i64*
  %319 = load i64, i64* %318, align 8
  store i64 %319, i64* %RBP, align 8, !tbaa !2428
  store i64 %317, i64* %7, align 8, !tbaa !2428
  %320 = add i64 %.sink, 2
  store i64 %320, i64* %PC, align 8
  %321 = inttoptr i64 %317 to i64*
  %322 = load i64, i64* %321, align 8
  store i64 %322, i64* %PC, align 8, !tbaa !2428
  %323 = add i64 %316, 16
  store i64 %323, i64* %7, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_40182d:                                     ; preds = %block_40166b
  %324 = add i64 %157, 5
  br label %block_401832

block_40181a:                                     ; preds = %block_40167e
  %325 = add i64 %195, 8
  store i64 %325, i64* %PC, align 8
  %326 = load i32, i32* %167, align 4
  %327 = add i32 %326, 1
  %328 = zext i32 %327 to i64
  store i64 %328, i64* %RAX, align 8, !tbaa !2428
  %329 = icmp eq i32 %326, -1
  %330 = icmp eq i32 %327, 0
  %331 = or i1 %329, %330
  %332 = zext i1 %331 to i8
  store i8 %332, i8* %51, align 1, !tbaa !2433
  %333 = and i32 %327, 255
  %334 = tail call i32 @llvm.ctpop.i32(i32 %333) #10
  %335 = trunc i32 %334 to i8
  %336 = and i8 %335, 1
  %337 = xor i8 %336, 1
  store i8 %337, i8* %52, align 1, !tbaa !2447
  %338 = xor i32 %326, %327
  %339 = lshr i32 %338, 4
  %340 = trunc i32 %339 to i8
  %341 = and i8 %340, 1
  store i8 %341, i8* %53, align 1, !tbaa !2451
  %342 = zext i1 %330 to i8
  store i8 %342, i8* %54, align 1, !tbaa !2448
  %343 = lshr i32 %327, 31
  %344 = trunc i32 %343 to i8
  store i8 %344, i8* %55, align 1, !tbaa !2449
  %345 = lshr i32 %326, 31
  %346 = xor i32 %343, %345
  %347 = add nuw nsw i32 %346, %343
  %348 = icmp eq i32 %347, 2
  %349 = zext i1 %348 to i8
  store i8 %349, i8* %56, align 1, !tbaa !2450
  %350 = add i64 %195, 14
  store i64 %350, i64* %PC, align 8
  store i32 %327, i32* %167, align 4
  %351 = load i64, i64* %PC, align 8
  %352 = add i64 %351, -445
  store i64 %352, i64* %PC, align 8, !tbaa !2428
  br label %block_40166b

block_40165f:                                     ; preds = %block_40126a
  %353 = add i64 %233, 467
  br label %block_401832

block_40124b:                                     ; preds = %block_4011e6
  %354 = load i32, i32* %243, align 4
  %355 = shl i32 %354, 1
  %356 = icmp slt i32 %354, 0
  %357 = icmp slt i32 %355, 0
  %358 = xor i1 %356, %357
  %359 = zext i32 %355 to i64
  store i64 %359, i64* %RAX, align 8, !tbaa !2428
  %.lobit10 = lshr i32 %354, 31
  %360 = trunc i32 %.lobit10 to i8
  store i8 %360, i8* %51, align 1, !tbaa !2432
  %361 = and i32 %355, 254
  %362 = tail call i32 @llvm.ctpop.i32(i32 %361) #10
  %363 = trunc i32 %362 to i8
  %364 = and i8 %363, 1
  %365 = xor i8 %364, 1
  store i8 %365, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %366 = icmp eq i32 %355, 0
  %367 = zext i1 %366 to i8
  store i8 %367, i8* %54, align 1, !tbaa !2432
  %368 = lshr i32 %354, 30
  %369 = trunc i32 %368 to i8
  %370 = and i8 %369, 1
  store i8 %370, i8* %55, align 1, !tbaa !2432
  %371 = zext i1 %358 to i8
  store i8 %371, i8* %56, align 1, !tbaa !2432
  %372 = add i64 %240, -52
  %373 = add i64 %289, 9
  store i64 %373, i64* %PC, align 8
  %374 = inttoptr i64 %372 to i32*
  store i32 %355, i32* %374, align 4
  %375 = load i64, i64* %RBP, align 8
  %376 = add i64 %375, -48
  %377 = load i64, i64* %PC, align 8
  %378 = add i64 %377, 3
  store i64 %378, i64* %PC, align 8
  %379 = inttoptr i64 %376 to i32*
  %380 = load i32, i32* %379, align 4
  %381 = shl i32 %380, 3
  %382 = zext i32 %381 to i64
  store i64 %382, i64* %RAX, align 8, !tbaa !2428
  %383 = lshr i32 %380, 29
  %384 = trunc i32 %383 to i8
  %385 = and i8 %384, 1
  store i8 %385, i8* %51, align 1, !tbaa !2432
  %386 = and i32 %381, 248
  %387 = tail call i32 @llvm.ctpop.i32(i32 %386) #10
  %388 = trunc i32 %387 to i8
  %389 = and i8 %388, 1
  %390 = xor i8 %389, 1
  store i8 %390, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %391 = icmp eq i32 %381, 0
  %392 = zext i1 %391 to i8
  store i8 %392, i8* %54, align 1, !tbaa !2432
  %393 = lshr i32 %380, 28
  %394 = and i32 %393, 1
  %395 = trunc i32 %394 to i8
  store i8 %395, i8* %55, align 1, !tbaa !2432
  store i8 0, i8* %56, align 1, !tbaa !2432
  %396 = add i64 %375, -44
  %397 = add i64 %377, 9
  store i64 %397, i64* %PC, align 8
  %398 = inttoptr i64 %396 to i32*
  %399 = load i32, i32* %398, align 4
  %400 = sub i32 %381, %399
  %401 = icmp ult i32 %381, %399
  %402 = zext i1 %401 to i8
  store i8 %402, i8* %51, align 1, !tbaa !2433
  %403 = and i32 %400, 255
  %404 = tail call i32 @llvm.ctpop.i32(i32 %403) #10
  %405 = trunc i32 %404 to i8
  %406 = and i8 %405, 1
  %407 = xor i8 %406, 1
  store i8 %407, i8* %52, align 1, !tbaa !2447
  %408 = xor i32 %399, %381
  %409 = xor i32 %408, %400
  %410 = lshr i32 %409, 4
  %411 = trunc i32 %410 to i8
  %412 = and i8 %411, 1
  store i8 %412, i8* %53, align 1, !tbaa !2451
  %413 = icmp eq i32 %400, 0
  %414 = zext i1 %413 to i8
  store i8 %414, i8* %54, align 1, !tbaa !2448
  %415 = lshr i32 %400, 31
  %416 = trunc i32 %415 to i8
  store i8 %416, i8* %55, align 1, !tbaa !2449
  %417 = lshr i32 %399, 31
  %418 = xor i32 %417, %394
  %419 = xor i32 %415, %394
  %420 = add nuw nsw i32 %419, %418
  %421 = icmp eq i32 %420, 2
  %422 = zext i1 %421 to i8
  store i8 %422, i8* %56, align 1, !tbaa !2450
  %.v12 = select i1 %413, i64 15, i64 1040
  %423 = add i64 %377, %.v12
  %424 = add i64 %375, -36
  %425 = add i64 %423, 7
  store i64 %425, i64* %PC, align 8
  %426 = inttoptr i64 %424 to i32*
  br i1 %413, label %block_401263, label %block_401664

block_401211:                                     ; preds = %block_401205
  %427 = add i64 %3075, -16
  %428 = add i64 %3111, 4
  store i64 %428, i64* %PC, align 8
  %429 = inttoptr i64 %427 to i64*
  %430 = load i64, i64* %429, align 8
  store i64 %430, i64* %RAX, align 8, !tbaa !2428
  %431 = add i64 %3111, 8
  store i64 %431, i64* %PC, align 8
  %432 = load i32, i32* %3078, align 4
  %433 = sext i32 %432 to i64
  store i64 %433, i64* %RCX, align 8, !tbaa !2428
  %434 = shl nsw i64 %433, 2
  %435 = add i64 %434, %430
  %436 = add i64 %3111, 11
  store i64 %436, i64* %PC, align 8
  %437 = inttoptr i64 %435 to i32*
  %438 = load i32, i32* %437, align 4
  %439 = zext i32 %438 to i64
  store i64 %439, i64* %RDX, align 8, !tbaa !2428
  %440 = add i64 %3075, -44
  %441 = add i64 %3111, 14
  store i64 %441, i64* %PC, align 8
  %442 = inttoptr i64 %440 to i32*
  %443 = load i32, i32* %442, align 4
  %444 = add i32 %443, %438
  %445 = zext i32 %444 to i64
  store i64 %445, i64* %RDX, align 8, !tbaa !2428
  %446 = icmp ult i32 %444, %438
  %447 = icmp ult i32 %444, %443
  %448 = or i1 %446, %447
  %449 = zext i1 %448 to i8
  store i8 %449, i8* %51, align 1, !tbaa !2433
  %450 = and i32 %444, 255
  %451 = tail call i32 @llvm.ctpop.i32(i32 %450) #10
  %452 = trunc i32 %451 to i8
  %453 = and i8 %452, 1
  %454 = xor i8 %453, 1
  store i8 %454, i8* %52, align 1, !tbaa !2447
  %455 = xor i32 %443, %438
  %456 = xor i32 %455, %444
  %457 = lshr i32 %456, 4
  %458 = trunc i32 %457 to i8
  %459 = and i8 %458, 1
  store i8 %459, i8* %53, align 1, !tbaa !2451
  %460 = icmp eq i32 %444, 0
  %461 = zext i1 %460 to i8
  store i8 %461, i8* %54, align 1, !tbaa !2448
  %462 = lshr i32 %444, 31
  %463 = trunc i32 %462 to i8
  store i8 %463, i8* %55, align 1, !tbaa !2449
  %464 = lshr i32 %438, 31
  %465 = lshr i32 %443, 31
  %466 = xor i32 %462, %464
  %467 = xor i32 %462, %465
  %468 = add nuw nsw i32 %466, %467
  %469 = icmp eq i32 %468, 2
  %470 = zext i1 %469 to i8
  store i8 %470, i8* %56, align 1, !tbaa !2450
  %471 = add i64 %3111, 18
  store i64 %471, i64* %PC, align 8
  %472 = load i64, i64* %429, align 8
  store i64 %472, i64* %RAX, align 8, !tbaa !2428
  %473 = add i64 %3111, 21
  store i64 %473, i64* %PC, align 8
  %474 = load i32, i32* %3083, align 4
  %475 = zext i32 %474 to i64
  store i64 %475, i64* %RSI, align 8, !tbaa !2428
  %476 = add i64 %3111, 24
  store i64 %476, i64* %PC, align 8
  %477 = load i32, i32* %3078, align 4
  %478 = add i32 %477, %474
  %479 = zext i32 %478 to i64
  store i64 %479, i64* %RSI, align 8, !tbaa !2428
  %480 = icmp ult i32 %478, %474
  %481 = icmp ult i32 %478, %477
  %482 = or i1 %480, %481
  %483 = zext i1 %482 to i8
  store i8 %483, i8* %51, align 1, !tbaa !2433
  %484 = and i32 %478, 255
  %485 = tail call i32 @llvm.ctpop.i32(i32 %484) #10
  %486 = trunc i32 %485 to i8
  %487 = and i8 %486, 1
  %488 = xor i8 %487, 1
  store i8 %488, i8* %52, align 1, !tbaa !2447
  %489 = xor i32 %477, %474
  %490 = xor i32 %489, %478
  %491 = lshr i32 %490, 4
  %492 = trunc i32 %491 to i8
  %493 = and i8 %492, 1
  store i8 %493, i8* %53, align 1, !tbaa !2451
  %494 = icmp eq i32 %478, 0
  %495 = zext i1 %494 to i8
  store i8 %495, i8* %54, align 1, !tbaa !2448
  %496 = lshr i32 %478, 31
  %497 = trunc i32 %496 to i8
  store i8 %497, i8* %55, align 1, !tbaa !2449
  %498 = lshr i32 %474, 31
  %499 = lshr i32 %477, 31
  %500 = xor i32 %496, %498
  %501 = xor i32 %496, %499
  %502 = add nuw nsw i32 %500, %501
  %503 = icmp eq i32 %502, 2
  %504 = zext i1 %503 to i8
  store i8 %504, i8* %56, align 1, !tbaa !2450
  %505 = sext i32 %478 to i64
  store i64 %505, i64* %RCX, align 8, !tbaa !2428
  %506 = shl nsw i64 %505, 2
  %507 = add i64 %506, %472
  %508 = add i64 %3111, 30
  store i64 %508, i64* %PC, align 8
  %509 = inttoptr i64 %507 to i32*
  store i32 %444, i32* %509, align 4
  %510 = load i64, i64* %RBP, align 8
  %511 = add i64 %510, -28
  %512 = load i64, i64* %PC, align 8
  %513 = add i64 %512, 3
  store i64 %513, i64* %PC, align 8
  %514 = inttoptr i64 %511 to i32*
  %515 = load i32, i32* %514, align 4
  %516 = add i32 %515, 1
  %517 = zext i32 %516 to i64
  store i64 %517, i64* %RAX, align 8, !tbaa !2428
  %518 = icmp eq i32 %515, -1
  %519 = icmp eq i32 %516, 0
  %520 = or i1 %518, %519
  %521 = zext i1 %520 to i8
  store i8 %521, i8* %51, align 1, !tbaa !2433
  %522 = and i32 %516, 255
  %523 = tail call i32 @llvm.ctpop.i32(i32 %522) #10
  %524 = trunc i32 %523 to i8
  %525 = and i8 %524, 1
  %526 = xor i8 %525, 1
  store i8 %526, i8* %52, align 1, !tbaa !2447
  %527 = xor i32 %515, %516
  %528 = lshr i32 %527, 4
  %529 = trunc i32 %528 to i8
  %530 = and i8 %529, 1
  store i8 %530, i8* %53, align 1, !tbaa !2451
  %531 = zext i1 %519 to i8
  store i8 %531, i8* %54, align 1, !tbaa !2448
  %532 = lshr i32 %516, 31
  %533 = trunc i32 %532 to i8
  store i8 %533, i8* %55, align 1, !tbaa !2449
  %534 = lshr i32 %515, 31
  %535 = xor i32 %532, %534
  %536 = add nuw nsw i32 %535, %532
  %537 = icmp eq i32 %536, 2
  %538 = zext i1 %537 to i8
  store i8 %538, i8* %56, align 1, !tbaa !2450
  %539 = add i64 %512, 9
  store i64 %539, i64* %PC, align 8
  store i32 %516, i32* %514, align 4
  %540 = load i64, i64* %PC, align 8
  %541 = add i64 %540, -51
  store i64 %541, i64* %PC, align 8, !tbaa !2428
  br label %block_401205

block_40158d:                                     ; preds = %block_40127d
  %542 = load i32, i32* %66, align 4
  %543 = shl i32 %542, 1
  %544 = icmp slt i32 %542, 0
  %545 = icmp slt i32 %543, 0
  %546 = xor i1 %544, %545
  %547 = zext i32 %543 to i64
  store i64 %547, i64* %RAX, align 8, !tbaa !2428
  %.lobit19 = lshr i32 %542, 31
  %548 = trunc i32 %.lobit19 to i8
  store i8 %548, i8* %51, align 1, !tbaa !2432
  %549 = and i32 %543, 254
  %550 = tail call i32 @llvm.ctpop.i32(i32 %549) #10
  %551 = trunc i32 %550 to i8
  %552 = and i8 %551, 1
  %553 = xor i8 %552, 1
  store i8 %553, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %554 = icmp eq i32 %543, 0
  %555 = zext i1 %554 to i8
  store i8 %555, i8* %54, align 1, !tbaa !2432
  %556 = lshr i32 %542, 30
  %557 = and i32 %556, 1
  %558 = trunc i32 %557 to i8
  store i8 %558, i8* %55, align 1, !tbaa !2432
  %559 = zext i1 %546 to i8
  store i8 %559, i8* %56, align 1, !tbaa !2432
  %560 = add i64 %58, -52
  %561 = add i64 %94, 9
  store i64 %561, i64* %PC, align 8
  %562 = inttoptr i64 %560 to i32*
  %563 = load i32, i32* %562, align 4
  %564 = add i32 %563, %543
  %565 = zext i32 %564 to i64
  store i64 %565, i64* %RAX, align 8, !tbaa !2428
  %566 = icmp ult i32 %564, %543
  %567 = icmp ult i32 %564, %563
  %568 = or i1 %566, %567
  %569 = zext i1 %568 to i8
  store i8 %569, i8* %51, align 1, !tbaa !2433
  %570 = and i32 %564, 255
  %571 = tail call i32 @llvm.ctpop.i32(i32 %570) #10
  %572 = trunc i32 %571 to i8
  %573 = and i8 %572, 1
  %574 = xor i8 %573, 1
  store i8 %574, i8* %52, align 1, !tbaa !2447
  %575 = xor i32 %563, %543
  %576 = xor i32 %575, %564
  %577 = lshr i32 %576, 4
  %578 = trunc i32 %577 to i8
  %579 = and i8 %578, 1
  store i8 %579, i8* %53, align 1, !tbaa !2451
  %580 = icmp eq i32 %564, 0
  %581 = zext i1 %580 to i8
  store i8 %581, i8* %54, align 1, !tbaa !2448
  %582 = lshr i32 %564, 31
  %583 = trunc i32 %582 to i8
  store i8 %583, i8* %55, align 1, !tbaa !2449
  %584 = lshr i32 %563, 31
  %585 = xor i32 %582, %557
  %586 = xor i32 %582, %584
  %587 = add nuw nsw i32 %585, %586
  %588 = icmp eq i32 %587, 2
  %589 = zext i1 %588 to i8
  store i8 %589, i8* %56, align 1, !tbaa !2450
  %590 = add i64 %58, -16
  %591 = add i64 %94, 13
  store i64 %591, i64* %PC, align 8
  %592 = inttoptr i64 %590 to i64*
  %593 = load i64, i64* %592, align 8
  store i64 %593, i64* %RCX, align 8, !tbaa !2428
  %594 = add i64 %94, 17
  store i64 %594, i64* %PC, align 8
  %595 = load i32, i32* %66, align 4
  %596 = sext i32 %595 to i64
  store i64 %596, i64* %RDX, align 8, !tbaa !2428
  %597 = shl nsw i64 %596, 2
  %598 = add i64 %597, %593
  %599 = add i64 %94, 20
  store i64 %599, i64* %PC, align 8
  %600 = inttoptr i64 %598 to i32*
  %601 = load i32, i32* %600, align 4
  %602 = add i32 %601, %564
  %603 = zext i32 %602 to i64
  store i64 %603, i64* %RAX, align 8, !tbaa !2428
  %604 = icmp ult i32 %602, %564
  %605 = icmp ult i32 %602, %601
  %606 = or i1 %604, %605
  %607 = zext i1 %606 to i8
  store i8 %607, i8* %51, align 1, !tbaa !2433
  %608 = and i32 %602, 255
  %609 = tail call i32 @llvm.ctpop.i32(i32 %608) #10
  %610 = trunc i32 %609 to i8
  %611 = and i8 %610, 1
  %612 = xor i8 %611, 1
  store i8 %612, i8* %52, align 1, !tbaa !2447
  %613 = xor i32 %601, %564
  %614 = xor i32 %613, %602
  %615 = lshr i32 %614, 4
  %616 = trunc i32 %615 to i8
  %617 = and i8 %616, 1
  store i8 %617, i8* %53, align 1, !tbaa !2451
  %618 = icmp eq i32 %602, 0
  %619 = zext i1 %618 to i8
  store i8 %619, i8* %54, align 1, !tbaa !2448
  %620 = lshr i32 %602, 31
  %621 = trunc i32 %620 to i8
  store i8 %621, i8* %55, align 1, !tbaa !2449
  %622 = lshr i32 %601, 31
  %623 = xor i32 %620, %582
  %624 = xor i32 %620, %622
  %625 = add nuw nsw i32 %623, %624
  %626 = icmp eq i32 %625, 2
  %627 = zext i1 %626 to i8
  store i8 %627, i8* %56, align 1, !tbaa !2450
  %628 = load i64, i64* %RBP, align 8
  %629 = add i64 %628, -32
  %630 = add i64 %94, 23
  store i64 %630, i64* %PC, align 8
  %631 = inttoptr i64 %629 to i32*
  store i32 %602, i32* %631, align 4
  %632 = load i64, i64* %RBP, align 8
  %633 = add i64 %632, -32
  %634 = load i64, i64* %PC, align 8
  %635 = add i64 %634, 3
  store i64 %635, i64* %PC, align 8
  %636 = inttoptr i64 %633 to i32*
  %637 = load i32, i32* %636, align 4
  %638 = zext i32 %637 to i64
  store i64 %638, i64* %RAX, align 8, !tbaa !2428
  %639 = add i64 %632, -52
  %640 = add i64 %634, 6
  store i64 %640, i64* %PC, align 8
  %641 = inttoptr i64 %639 to i32*
  %642 = load i32, i32* %641, align 4
  %643 = add i32 %642, %637
  %644 = zext i32 %643 to i64
  store i64 %644, i64* %RAX, align 8, !tbaa !2428
  %645 = icmp ult i32 %643, %637
  %646 = icmp ult i32 %643, %642
  %647 = or i1 %645, %646
  %648 = zext i1 %647 to i8
  store i8 %648, i8* %51, align 1, !tbaa !2433
  %649 = and i32 %643, 255
  %650 = tail call i32 @llvm.ctpop.i32(i32 %649) #10
  %651 = trunc i32 %650 to i8
  %652 = and i8 %651, 1
  %653 = xor i8 %652, 1
  store i8 %653, i8* %52, align 1, !tbaa !2447
  %654 = xor i32 %642, %637
  %655 = xor i32 %654, %643
  %656 = lshr i32 %655, 4
  %657 = trunc i32 %656 to i8
  %658 = and i8 %657, 1
  store i8 %658, i8* %53, align 1, !tbaa !2451
  %659 = icmp eq i32 %643, 0
  %660 = zext i1 %659 to i8
  store i8 %660, i8* %54, align 1, !tbaa !2448
  %661 = lshr i32 %643, 31
  %662 = trunc i32 %661 to i8
  store i8 %662, i8* %55, align 1, !tbaa !2449
  %663 = lshr i32 %637, 31
  %664 = lshr i32 %642, 31
  %665 = xor i32 %661, %663
  %666 = xor i32 %661, %664
  %667 = add nuw nsw i32 %665, %666
  %668 = icmp eq i32 %667, 2
  %669 = zext i1 %668 to i8
  store i8 %669, i8* %56, align 1, !tbaa !2450
  %670 = add i64 %632, -40
  %671 = add i64 %634, 9
  store i64 %671, i64* %PC, align 8
  %672 = inttoptr i64 %670 to i32*
  store i32 %643, i32* %672, align 4
  %673 = load i64, i64* %RBP, align 8
  %674 = add i64 %673, -24
  %675 = load i64, i64* %PC, align 8
  %676 = add i64 %675, 4
  store i64 %676, i64* %PC, align 8
  %677 = inttoptr i64 %674 to i64*
  %678 = load i64, i64* %677, align 8
  store i64 %678, i64* %RCX, align 8, !tbaa !2428
  %679 = add i64 %673, -32
  %680 = add i64 %675, 8
  store i64 %680, i64* %PC, align 8
  %681 = inttoptr i64 %679 to i32*
  %682 = load i32, i32* %681, align 4
  %683 = sext i32 %682 to i64
  store i64 %683, i64* %RDX, align 8, !tbaa !2428
  %684 = shl nsw i64 %683, 3
  %685 = add i64 %684, %678
  %686 = add i64 %675, 13
  store i64 %686, i64* %PC, align 8
  %687 = inttoptr i64 %685 to i64*
  %688 = load i64, i64* %687, align 8
  %689 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %688, i64* %689, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %690 = add i64 %673, -64
  %691 = add i64 %675, 18
  store i64 %691, i64* %PC, align 8
  %692 = inttoptr i64 %690 to i64*
  store i64 %688, i64* %692, align 8
  %693 = load i64, i64* %RBP, align 8
  %694 = add i64 %693, -24
  %695 = load i64, i64* %PC, align 8
  %696 = add i64 %695, 4
  store i64 %696, i64* %PC, align 8
  %697 = inttoptr i64 %694 to i64*
  %698 = load i64, i64* %697, align 8
  store i64 %698, i64* %RCX, align 8, !tbaa !2428
  %699 = add i64 %693, -32
  %700 = add i64 %695, 7
  store i64 %700, i64* %PC, align 8
  %701 = inttoptr i64 %699 to i32*
  %702 = load i32, i32* %701, align 4
  %703 = add i32 %702, 1
  %704 = zext i32 %703 to i64
  store i64 %704, i64* %RAX, align 8, !tbaa !2428
  %705 = icmp eq i32 %702, -1
  %706 = icmp eq i32 %703, 0
  %707 = or i1 %705, %706
  %708 = zext i1 %707 to i8
  store i8 %708, i8* %51, align 1, !tbaa !2433
  %709 = and i32 %703, 255
  %710 = tail call i32 @llvm.ctpop.i32(i32 %709) #10
  %711 = trunc i32 %710 to i8
  %712 = and i8 %711, 1
  %713 = xor i8 %712, 1
  store i8 %713, i8* %52, align 1, !tbaa !2447
  %714 = xor i32 %702, %703
  %715 = lshr i32 %714, 4
  %716 = trunc i32 %715 to i8
  %717 = and i8 %716, 1
  store i8 %717, i8* %53, align 1, !tbaa !2451
  %718 = zext i1 %706 to i8
  store i8 %718, i8* %54, align 1, !tbaa !2448
  %719 = lshr i32 %703, 31
  %720 = trunc i32 %719 to i8
  store i8 %720, i8* %55, align 1, !tbaa !2449
  %721 = lshr i32 %702, 31
  %722 = xor i32 %719, %721
  %723 = add nuw nsw i32 %722, %719
  %724 = icmp eq i32 %723, 2
  %725 = zext i1 %724 to i8
  store i8 %725, i8* %56, align 1, !tbaa !2450
  %726 = sext i32 %703 to i64
  store i64 %726, i64* %RDX, align 8, !tbaa !2428
  %727 = shl nsw i64 %726, 3
  %728 = add i64 %727, %698
  %729 = add i64 %695, 18
  store i64 %729, i64* %PC, align 8
  %730 = inttoptr i64 %728 to i64*
  %731 = load i64, i64* %730, align 8
  store i64 %731, i64* %689, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %732 = add i64 %693, -72
  %733 = add i64 %695, 23
  store i64 %733, i64* %PC, align 8
  %734 = inttoptr i64 %732 to i64*
  store i64 %731, i64* %734, align 8
  %735 = load i64, i64* %RBP, align 8
  %736 = add i64 %735, -24
  %737 = load i64, i64* %PC, align 8
  %738 = add i64 %737, 4
  store i64 %738, i64* %PC, align 8
  %739 = inttoptr i64 %736 to i64*
  %740 = load i64, i64* %739, align 8
  store i64 %740, i64* %RCX, align 8, !tbaa !2428
  %741 = add i64 %735, -40
  %742 = add i64 %737, 8
  store i64 %742, i64* %PC, align 8
  %743 = inttoptr i64 %741 to i32*
  %744 = load i32, i32* %743, align 4
  %745 = sext i32 %744 to i64
  store i64 %745, i64* %RDX, align 8, !tbaa !2428
  %746 = shl nsw i64 %745, 3
  %747 = add i64 %746, %740
  %748 = add i64 %737, 13
  store i64 %748, i64* %PC, align 8
  %749 = inttoptr i64 %747 to i64*
  %750 = load i64, i64* %749, align 8
  store i64 %750, i64* %689, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %751 = add i64 %735, -80
  %752 = add i64 %737, 18
  store i64 %752, i64* %PC, align 8
  %753 = inttoptr i64 %751 to i64*
  store i64 %750, i64* %753, align 8
  %754 = load i64, i64* %RBP, align 8
  %755 = add i64 %754, -24
  %756 = load i64, i64* %PC, align 8
  %757 = add i64 %756, 4
  store i64 %757, i64* %PC, align 8
  %758 = inttoptr i64 %755 to i64*
  %759 = load i64, i64* %758, align 8
  store i64 %759, i64* %RCX, align 8, !tbaa !2428
  %760 = add i64 %754, -40
  %761 = add i64 %756, 7
  store i64 %761, i64* %PC, align 8
  %762 = inttoptr i64 %760 to i32*
  %763 = load i32, i32* %762, align 4
  %764 = add i32 %763, 1
  %765 = zext i32 %764 to i64
  store i64 %765, i64* %RAX, align 8, !tbaa !2428
  %766 = icmp eq i32 %763, -1
  %767 = icmp eq i32 %764, 0
  %768 = or i1 %766, %767
  %769 = zext i1 %768 to i8
  store i8 %769, i8* %51, align 1, !tbaa !2433
  %770 = and i32 %764, 255
  %771 = tail call i32 @llvm.ctpop.i32(i32 %770) #10
  %772 = trunc i32 %771 to i8
  %773 = and i8 %772, 1
  %774 = xor i8 %773, 1
  store i8 %774, i8* %52, align 1, !tbaa !2447
  %775 = xor i32 %763, %764
  %776 = lshr i32 %775, 4
  %777 = trunc i32 %776 to i8
  %778 = and i8 %777, 1
  store i8 %778, i8* %53, align 1, !tbaa !2451
  %779 = zext i1 %767 to i8
  store i8 %779, i8* %54, align 1, !tbaa !2448
  %780 = lshr i32 %764, 31
  %781 = trunc i32 %780 to i8
  store i8 %781, i8* %55, align 1, !tbaa !2449
  %782 = lshr i32 %763, 31
  %783 = xor i32 %780, %782
  %784 = add nuw nsw i32 %783, %780
  %785 = icmp eq i32 %784, 2
  %786 = zext i1 %785 to i8
  store i8 %786, i8* %56, align 1, !tbaa !2450
  %787 = sext i32 %764 to i64
  store i64 %787, i64* %RDX, align 8, !tbaa !2428
  %788 = shl nsw i64 %787, 3
  %789 = add i64 %788, %759
  %790 = add i64 %756, 18
  store i64 %790, i64* %PC, align 8
  %791 = inttoptr i64 %789 to i64*
  %792 = load i64, i64* %791, align 8
  store i64 %792, i64* %689, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %793 = add i64 %754, -88
  %794 = add i64 %756, 23
  store i64 %794, i64* %PC, align 8
  %795 = inttoptr i64 %793 to i64*
  store i64 %792, i64* %795, align 8
  %796 = load i64, i64* %RBP, align 8
  %797 = add i64 %796, -80
  %798 = load i64, i64* %PC, align 8
  %799 = add i64 %798, 5
  store i64 %799, i64* %PC, align 8
  %800 = inttoptr i64 %797 to i64*
  %801 = load i64, i64* %800, align 8
  store i64 %801, i64* %689, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %802 = add i64 %796, -24
  %803 = add i64 %798, 9
  store i64 %803, i64* %PC, align 8
  %804 = inttoptr i64 %802 to i64*
  %805 = load i64, i64* %804, align 8
  store i64 %805, i64* %RCX, align 8, !tbaa !2428
  %806 = add i64 %796, -32
  %807 = add i64 %798, 13
  store i64 %807, i64* %PC, align 8
  %808 = inttoptr i64 %806 to i32*
  %809 = load i32, i32* %808, align 4
  %810 = sext i32 %809 to i64
  store i64 %810, i64* %RDX, align 8, !tbaa !2428
  %811 = shl nsw i64 %810, 3
  %812 = add i64 %811, %805
  %813 = add i64 %798, 18
  store i64 %813, i64* %PC, align 8
  %814 = inttoptr i64 %812 to i64*
  store i64 %801, i64* %814, align 8
  %815 = load i64, i64* %RBP, align 8
  %816 = add i64 %815, -88
  %817 = load i64, i64* %PC, align 8
  %818 = add i64 %817, 5
  store i64 %818, i64* %PC, align 8
  %819 = inttoptr i64 %816 to i64*
  %820 = load i64, i64* %819, align 8
  store i64 %820, i64* %689, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %821 = add i64 %815, -24
  %822 = add i64 %817, 9
  store i64 %822, i64* %PC, align 8
  %823 = inttoptr i64 %821 to i64*
  %824 = load i64, i64* %823, align 8
  store i64 %824, i64* %RCX, align 8, !tbaa !2428
  %825 = add i64 %815, -32
  %826 = add i64 %817, 12
  store i64 %826, i64* %PC, align 8
  %827 = inttoptr i64 %825 to i32*
  %828 = load i32, i32* %827, align 4
  %829 = add i32 %828, 1
  %830 = zext i32 %829 to i64
  store i64 %830, i64* %RAX, align 8, !tbaa !2428
  %831 = icmp eq i32 %828, -1
  %832 = icmp eq i32 %829, 0
  %833 = or i1 %831, %832
  %834 = zext i1 %833 to i8
  store i8 %834, i8* %51, align 1, !tbaa !2433
  %835 = and i32 %829, 255
  %836 = tail call i32 @llvm.ctpop.i32(i32 %835) #10
  %837 = trunc i32 %836 to i8
  %838 = and i8 %837, 1
  %839 = xor i8 %838, 1
  store i8 %839, i8* %52, align 1, !tbaa !2447
  %840 = xor i32 %828, %829
  %841 = lshr i32 %840, 4
  %842 = trunc i32 %841 to i8
  %843 = and i8 %842, 1
  store i8 %843, i8* %53, align 1, !tbaa !2451
  %844 = zext i1 %832 to i8
  store i8 %844, i8* %54, align 1, !tbaa !2448
  %845 = lshr i32 %829, 31
  %846 = trunc i32 %845 to i8
  store i8 %846, i8* %55, align 1, !tbaa !2449
  %847 = lshr i32 %828, 31
  %848 = xor i32 %845, %847
  %849 = add nuw nsw i32 %848, %845
  %850 = icmp eq i32 %849, 2
  %851 = zext i1 %850 to i8
  store i8 %851, i8* %56, align 1, !tbaa !2450
  %852 = sext i32 %829 to i64
  store i64 %852, i64* %RDX, align 8, !tbaa !2428
  %853 = shl nsw i64 %852, 3
  %854 = add i64 %853, %824
  %855 = add i64 %817, 23
  store i64 %855, i64* %PC, align 8
  %856 = inttoptr i64 %854 to i64*
  store i64 %820, i64* %856, align 8
  %857 = load i64, i64* %RBP, align 8
  %858 = add i64 %857, -64
  %859 = load i64, i64* %PC, align 8
  %860 = add i64 %859, 5
  store i64 %860, i64* %PC, align 8
  %861 = inttoptr i64 %858 to i64*
  %862 = load i64, i64* %861, align 8
  store i64 %862, i64* %689, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %863 = add i64 %857, -24
  %864 = add i64 %859, 9
  store i64 %864, i64* %PC, align 8
  %865 = inttoptr i64 %863 to i64*
  %866 = load i64, i64* %865, align 8
  store i64 %866, i64* %RCX, align 8, !tbaa !2428
  %867 = add i64 %857, -40
  %868 = add i64 %859, 13
  store i64 %868, i64* %PC, align 8
  %869 = inttoptr i64 %867 to i32*
  %870 = load i32, i32* %869, align 4
  %871 = sext i32 %870 to i64
  store i64 %871, i64* %RDX, align 8, !tbaa !2428
  %872 = shl nsw i64 %871, 3
  %873 = add i64 %872, %866
  %874 = add i64 %859, 18
  store i64 %874, i64* %PC, align 8
  %875 = inttoptr i64 %873 to i64*
  store i64 %862, i64* %875, align 8
  %876 = load i64, i64* %RBP, align 8
  %877 = add i64 %876, -72
  %878 = load i64, i64* %PC, align 8
  %879 = add i64 %878, 5
  store i64 %879, i64* %PC, align 8
  %880 = inttoptr i64 %877 to i64*
  %881 = load i64, i64* %880, align 8
  store i64 %881, i64* %689, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %882 = add i64 %876, -24
  %883 = add i64 %878, 9
  store i64 %883, i64* %PC, align 8
  %884 = inttoptr i64 %882 to i64*
  %885 = load i64, i64* %884, align 8
  store i64 %885, i64* %RCX, align 8, !tbaa !2428
  %886 = add i64 %876, -40
  %887 = add i64 %878, 12
  store i64 %887, i64* %PC, align 8
  %888 = inttoptr i64 %886 to i32*
  %889 = load i32, i32* %888, align 4
  %890 = add i32 %889, 1
  %891 = zext i32 %890 to i64
  store i64 %891, i64* %RAX, align 8, !tbaa !2428
  %892 = icmp eq i32 %889, -1
  %893 = icmp eq i32 %890, 0
  %894 = or i1 %892, %893
  %895 = zext i1 %894 to i8
  store i8 %895, i8* %51, align 1, !tbaa !2433
  %896 = and i32 %890, 255
  %897 = tail call i32 @llvm.ctpop.i32(i32 %896) #10
  %898 = trunc i32 %897 to i8
  %899 = and i8 %898, 1
  %900 = xor i8 %899, 1
  store i8 %900, i8* %52, align 1, !tbaa !2447
  %901 = xor i32 %889, %890
  %902 = lshr i32 %901, 4
  %903 = trunc i32 %902 to i8
  %904 = and i8 %903, 1
  store i8 %904, i8* %53, align 1, !tbaa !2451
  %905 = zext i1 %893 to i8
  store i8 %905, i8* %54, align 1, !tbaa !2448
  %906 = lshr i32 %890, 31
  %907 = trunc i32 %906 to i8
  store i8 %907, i8* %55, align 1, !tbaa !2449
  %908 = lshr i32 %889, 31
  %909 = xor i32 %906, %908
  %910 = add nuw nsw i32 %909, %906
  %911 = icmp eq i32 %910, 2
  %912 = zext i1 %911 to i8
  store i8 %912, i8* %56, align 1, !tbaa !2450
  %913 = sext i32 %890 to i64
  store i64 %913, i64* %RDX, align 8, !tbaa !2428
  %914 = shl nsw i64 %913, 3
  %915 = add i64 %914, %885
  %916 = add i64 %878, 23
  store i64 %916, i64* %PC, align 8
  %917 = inttoptr i64 %915 to i64*
  store i64 %881, i64* %917, align 8
  %918 = load i64, i64* %RBP, align 8
  %919 = add i64 %918, -36
  %920 = load i64, i64* %PC, align 8
  %921 = add i64 %920, 3
  store i64 %921, i64* %PC, align 8
  %922 = inttoptr i64 %919 to i32*
  %923 = load i32, i32* %922, align 4
  %924 = add i32 %923, 1
  %925 = zext i32 %924 to i64
  store i64 %925, i64* %RAX, align 8, !tbaa !2428
  %926 = icmp eq i32 %923, -1
  %927 = icmp eq i32 %924, 0
  %928 = or i1 %926, %927
  %929 = zext i1 %928 to i8
  store i8 %929, i8* %51, align 1, !tbaa !2433
  %930 = and i32 %924, 255
  %931 = tail call i32 @llvm.ctpop.i32(i32 %930) #10
  %932 = trunc i32 %931 to i8
  %933 = and i8 %932, 1
  %934 = xor i8 %933, 1
  store i8 %934, i8* %52, align 1, !tbaa !2447
  %935 = xor i32 %923, %924
  %936 = lshr i32 %935, 4
  %937 = trunc i32 %936 to i8
  %938 = and i8 %937, 1
  store i8 %938, i8* %53, align 1, !tbaa !2451
  %939 = zext i1 %927 to i8
  store i8 %939, i8* %54, align 1, !tbaa !2448
  %940 = lshr i32 %924, 31
  %941 = trunc i32 %940 to i8
  store i8 %941, i8* %55, align 1, !tbaa !2449
  %942 = lshr i32 %923, 31
  %943 = xor i32 %940, %942
  %944 = add nuw nsw i32 %943, %940
  %945 = icmp eq i32 %944, 2
  %946 = zext i1 %945 to i8
  store i8 %946, i8* %56, align 1, !tbaa !2450
  %947 = add i64 %920, 9
  store i64 %947, i64* %PC, align 8
  store i32 %924, i32* %922, align 4
  %948 = load i64, i64* %PC, align 8
  %949 = add i64 %948, -1008
  store i64 %949, i64* %PC, align 8, !tbaa !2428
  br label %block_40126a

block_401276:                                     ; preds = %block_40126a
  %950 = add i64 %197, -28
  %951 = add i64 %233, 7
  store i64 %951, i64* %PC, align 8
  %952 = inttoptr i64 %950 to i32*
  store i32 0, i32* %952, align 4
  %.pre5 = load i64, i64* %PC, align 8
  br label %block_40127d

block_40168a:                                     ; preds = %block_40167e
  %953 = add i64 %195, 3
  store i64 %953, i64* %PC, align 8
  %954 = load i32, i32* %162, align 4
  %955 = shl i32 %954, 1
  %956 = icmp slt i32 %954, 0
  %957 = icmp slt i32 %955, 0
  %958 = xor i1 %956, %957
  %959 = zext i32 %955 to i64
  store i64 %959, i64* %RAX, align 8, !tbaa !2428
  %.lobit22 = lshr i32 %954, 31
  %960 = trunc i32 %.lobit22 to i8
  store i8 %960, i8* %51, align 1, !tbaa !2432
  %961 = and i32 %955, 254
  %962 = tail call i32 @llvm.ctpop.i32(i32 %961) #10
  %963 = trunc i32 %962 to i8
  %964 = and i8 %963, 1
  %965 = xor i8 %964, 1
  store i8 %965, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %966 = icmp eq i32 %955, 0
  %967 = zext i1 %966 to i8
  store i8 %967, i8* %54, align 1, !tbaa !2432
  %968 = lshr i32 %954, 30
  %969 = and i32 %968, 1
  %970 = trunc i32 %969 to i8
  store i8 %970, i8* %55, align 1, !tbaa !2432
  %971 = zext i1 %958 to i8
  store i8 %971, i8* %56, align 1, !tbaa !2432
  %972 = add i64 %159, -16
  %973 = add i64 %195, 10
  store i64 %973, i64* %PC, align 8
  %974 = inttoptr i64 %972 to i64*
  %975 = load i64, i64* %974, align 8
  store i64 %975, i64* %RCX, align 8, !tbaa !2428
  %976 = add i64 %195, 14
  store i64 %976, i64* %PC, align 8
  %977 = load i32, i32* %167, align 4
  %978 = sext i32 %977 to i64
  store i64 %978, i64* %RDX, align 8, !tbaa !2428
  %979 = shl nsw i64 %978, 2
  %980 = add i64 %979, %975
  %981 = add i64 %195, 17
  store i64 %981, i64* %PC, align 8
  %982 = inttoptr i64 %980 to i32*
  %983 = load i32, i32* %982, align 4
  %984 = add i32 %983, %955
  %985 = zext i32 %984 to i64
  store i64 %985, i64* %RAX, align 8, !tbaa !2428
  %986 = icmp ult i32 %984, %955
  %987 = icmp ult i32 %984, %983
  %988 = or i1 %986, %987
  %989 = zext i1 %988 to i8
  store i8 %989, i8* %51, align 1, !tbaa !2433
  %990 = and i32 %984, 255
  %991 = tail call i32 @llvm.ctpop.i32(i32 %990) #10
  %992 = trunc i32 %991 to i8
  %993 = and i8 %992, 1
  %994 = xor i8 %993, 1
  store i8 %994, i8* %52, align 1, !tbaa !2447
  %995 = xor i32 %983, %955
  %996 = xor i32 %995, %984
  %997 = lshr i32 %996, 4
  %998 = trunc i32 %997 to i8
  %999 = and i8 %998, 1
  store i8 %999, i8* %53, align 1, !tbaa !2451
  %1000 = icmp eq i32 %984, 0
  %1001 = zext i1 %1000 to i8
  store i8 %1001, i8* %54, align 1, !tbaa !2448
  %1002 = lshr i32 %984, 31
  %1003 = trunc i32 %1002 to i8
  store i8 %1003, i8* %55, align 1, !tbaa !2449
  %1004 = lshr i32 %983, 31
  %1005 = xor i32 %1002, %969
  %1006 = xor i32 %1002, %1004
  %1007 = add nuw nsw i32 %1005, %1006
  %1008 = icmp eq i32 %1007, 2
  %1009 = zext i1 %1008 to i8
  store i8 %1009, i8* %56, align 1, !tbaa !2450
  %1010 = add i64 %159, -32
  %1011 = add i64 %195, 20
  store i64 %1011, i64* %PC, align 8
  %1012 = inttoptr i64 %1010 to i32*
  store i32 %984, i32* %1012, align 4
  %1013 = load i64, i64* %RBP, align 8
  %1014 = add i64 %1013, -36
  %1015 = load i64, i64* %PC, align 8
  %1016 = add i64 %1015, 3
  store i64 %1016, i64* %PC, align 8
  %1017 = inttoptr i64 %1014 to i32*
  %1018 = load i32, i32* %1017, align 4
  %1019 = shl i32 %1018, 1
  %1020 = icmp slt i32 %1018, 0
  %1021 = icmp slt i32 %1019, 0
  %1022 = xor i1 %1020, %1021
  %1023 = zext i32 %1019 to i64
  store i64 %1023, i64* %RAX, align 8, !tbaa !2428
  %.lobit23 = lshr i32 %1018, 31
  %1024 = trunc i32 %.lobit23 to i8
  store i8 %1024, i8* %51, align 1, !tbaa !2432
  %1025 = and i32 %1019, 254
  %1026 = tail call i32 @llvm.ctpop.i32(i32 %1025) #10
  %1027 = trunc i32 %1026 to i8
  %1028 = and i8 %1027, 1
  %1029 = xor i8 %1028, 1
  store i8 %1029, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %1030 = icmp eq i32 %1019, 0
  %1031 = zext i1 %1030 to i8
  store i8 %1031, i8* %54, align 1, !tbaa !2432
  %1032 = lshr i32 %1018, 30
  %1033 = and i32 %1032, 1
  %1034 = trunc i32 %1033 to i8
  store i8 %1034, i8* %55, align 1, !tbaa !2432
  %1035 = zext i1 %1022 to i8
  store i8 %1035, i8* %56, align 1, !tbaa !2432
  %1036 = add i64 %1013, -16
  %1037 = add i64 %1015, 10
  store i64 %1037, i64* %PC, align 8
  %1038 = inttoptr i64 %1036 to i64*
  %1039 = load i64, i64* %1038, align 8
  store i64 %1039, i64* %RCX, align 8, !tbaa !2428
  %1040 = add i64 %1013, -28
  %1041 = add i64 %1015, 14
  store i64 %1041, i64* %PC, align 8
  %1042 = inttoptr i64 %1040 to i32*
  %1043 = load i32, i32* %1042, align 4
  %1044 = sext i32 %1043 to i64
  store i64 %1044, i64* %RDX, align 8, !tbaa !2428
  %1045 = shl nsw i64 %1044, 2
  %1046 = add i64 %1045, %1039
  %1047 = add i64 %1015, 17
  store i64 %1047, i64* %PC, align 8
  %1048 = inttoptr i64 %1046 to i32*
  %1049 = load i32, i32* %1048, align 4
  %1050 = add i32 %1049, %1019
  %1051 = zext i32 %1050 to i64
  store i64 %1051, i64* %RAX, align 8, !tbaa !2428
  %1052 = icmp ult i32 %1050, %1019
  %1053 = icmp ult i32 %1050, %1049
  %1054 = or i1 %1052, %1053
  %1055 = zext i1 %1054 to i8
  store i8 %1055, i8* %51, align 1, !tbaa !2433
  %1056 = and i32 %1050, 255
  %1057 = tail call i32 @llvm.ctpop.i32(i32 %1056) #10
  %1058 = trunc i32 %1057 to i8
  %1059 = and i8 %1058, 1
  %1060 = xor i8 %1059, 1
  store i8 %1060, i8* %52, align 1, !tbaa !2447
  %1061 = xor i32 %1049, %1019
  %1062 = xor i32 %1061, %1050
  %1063 = lshr i32 %1062, 4
  %1064 = trunc i32 %1063 to i8
  %1065 = and i8 %1064, 1
  store i8 %1065, i8* %53, align 1, !tbaa !2451
  %1066 = icmp eq i32 %1050, 0
  %1067 = zext i1 %1066 to i8
  store i8 %1067, i8* %54, align 1, !tbaa !2448
  %1068 = lshr i32 %1050, 31
  %1069 = trunc i32 %1068 to i8
  store i8 %1069, i8* %55, align 1, !tbaa !2449
  %1070 = lshr i32 %1049, 31
  %1071 = xor i32 %1068, %1033
  %1072 = xor i32 %1068, %1070
  %1073 = add nuw nsw i32 %1071, %1072
  %1074 = icmp eq i32 %1073, 2
  %1075 = zext i1 %1074 to i8
  store i8 %1075, i8* %56, align 1, !tbaa !2450
  %1076 = add i64 %1013, -40
  %1077 = add i64 %1015, 20
  store i64 %1077, i64* %PC, align 8
  %1078 = inttoptr i64 %1076 to i32*
  store i32 %1050, i32* %1078, align 4
  %1079 = load i64, i64* %RBP, align 8
  %1080 = add i64 %1079, -24
  %1081 = load i64, i64* %PC, align 8
  %1082 = add i64 %1081, 4
  store i64 %1082, i64* %PC, align 8
  %1083 = inttoptr i64 %1080 to i64*
  %1084 = load i64, i64* %1083, align 8
  store i64 %1084, i64* %RCX, align 8, !tbaa !2428
  %1085 = add i64 %1079, -32
  %1086 = add i64 %1081, 8
  store i64 %1086, i64* %PC, align 8
  %1087 = inttoptr i64 %1085 to i32*
  %1088 = load i32, i32* %1087, align 4
  %1089 = sext i32 %1088 to i64
  store i64 %1089, i64* %RDX, align 8, !tbaa !2428
  %1090 = shl nsw i64 %1089, 3
  %1091 = add i64 %1090, %1084
  %1092 = add i64 %1081, 13
  store i64 %1092, i64* %PC, align 8
  %1093 = inttoptr i64 %1091 to i64*
  %1094 = load i64, i64* %1093, align 8
  %1095 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1094, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1096 = add i64 %1079, -64
  %1097 = add i64 %1081, 18
  store i64 %1097, i64* %PC, align 8
  %1098 = inttoptr i64 %1096 to i64*
  store i64 %1094, i64* %1098, align 8
  %1099 = load i64, i64* %RBP, align 8
  %1100 = add i64 %1099, -24
  %1101 = load i64, i64* %PC, align 8
  %1102 = add i64 %1101, 4
  store i64 %1102, i64* %PC, align 8
  %1103 = inttoptr i64 %1100 to i64*
  %1104 = load i64, i64* %1103, align 8
  store i64 %1104, i64* %RCX, align 8, !tbaa !2428
  %1105 = add i64 %1099, -32
  %1106 = add i64 %1101, 7
  store i64 %1106, i64* %PC, align 8
  %1107 = inttoptr i64 %1105 to i32*
  %1108 = load i32, i32* %1107, align 4
  %1109 = add i32 %1108, 1
  %1110 = zext i32 %1109 to i64
  store i64 %1110, i64* %RAX, align 8, !tbaa !2428
  %1111 = icmp eq i32 %1108, -1
  %1112 = icmp eq i32 %1109, 0
  %1113 = or i1 %1111, %1112
  %1114 = zext i1 %1113 to i8
  store i8 %1114, i8* %51, align 1, !tbaa !2433
  %1115 = and i32 %1109, 255
  %1116 = tail call i32 @llvm.ctpop.i32(i32 %1115) #10
  %1117 = trunc i32 %1116 to i8
  %1118 = and i8 %1117, 1
  %1119 = xor i8 %1118, 1
  store i8 %1119, i8* %52, align 1, !tbaa !2447
  %1120 = xor i32 %1108, %1109
  %1121 = lshr i32 %1120, 4
  %1122 = trunc i32 %1121 to i8
  %1123 = and i8 %1122, 1
  store i8 %1123, i8* %53, align 1, !tbaa !2451
  %1124 = zext i1 %1112 to i8
  store i8 %1124, i8* %54, align 1, !tbaa !2448
  %1125 = lshr i32 %1109, 31
  %1126 = trunc i32 %1125 to i8
  store i8 %1126, i8* %55, align 1, !tbaa !2449
  %1127 = lshr i32 %1108, 31
  %1128 = xor i32 %1125, %1127
  %1129 = add nuw nsw i32 %1128, %1125
  %1130 = icmp eq i32 %1129, 2
  %1131 = zext i1 %1130 to i8
  store i8 %1131, i8* %56, align 1, !tbaa !2450
  %1132 = sext i32 %1109 to i64
  store i64 %1132, i64* %RDX, align 8, !tbaa !2428
  %1133 = shl nsw i64 %1132, 3
  %1134 = add i64 %1133, %1104
  %1135 = add i64 %1101, 18
  store i64 %1135, i64* %PC, align 8
  %1136 = inttoptr i64 %1134 to i64*
  %1137 = load i64, i64* %1136, align 8
  store i64 %1137, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1138 = add i64 %1099, -72
  %1139 = add i64 %1101, 23
  store i64 %1139, i64* %PC, align 8
  %1140 = inttoptr i64 %1138 to i64*
  store i64 %1137, i64* %1140, align 8
  %1141 = load i64, i64* %RBP, align 8
  %1142 = add i64 %1141, -24
  %1143 = load i64, i64* %PC, align 8
  %1144 = add i64 %1143, 4
  store i64 %1144, i64* %PC, align 8
  %1145 = inttoptr i64 %1142 to i64*
  %1146 = load i64, i64* %1145, align 8
  store i64 %1146, i64* %RCX, align 8, !tbaa !2428
  %1147 = add i64 %1141, -40
  %1148 = add i64 %1143, 8
  store i64 %1148, i64* %PC, align 8
  %1149 = inttoptr i64 %1147 to i32*
  %1150 = load i32, i32* %1149, align 4
  %1151 = sext i32 %1150 to i64
  store i64 %1151, i64* %RDX, align 8, !tbaa !2428
  %1152 = shl nsw i64 %1151, 3
  %1153 = add i64 %1152, %1146
  %1154 = add i64 %1143, 13
  store i64 %1154, i64* %PC, align 8
  %1155 = inttoptr i64 %1153 to i64*
  %1156 = load i64, i64* %1155, align 8
  store i64 %1156, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1157 = add i64 %1141, -80
  %1158 = add i64 %1143, 18
  store i64 %1158, i64* %PC, align 8
  %1159 = inttoptr i64 %1157 to i64*
  store i64 %1156, i64* %1159, align 8
  %1160 = load i64, i64* %RBP, align 8
  %1161 = add i64 %1160, -24
  %1162 = load i64, i64* %PC, align 8
  %1163 = add i64 %1162, 4
  store i64 %1163, i64* %PC, align 8
  %1164 = inttoptr i64 %1161 to i64*
  %1165 = load i64, i64* %1164, align 8
  store i64 %1165, i64* %RCX, align 8, !tbaa !2428
  %1166 = add i64 %1160, -40
  %1167 = add i64 %1162, 7
  store i64 %1167, i64* %PC, align 8
  %1168 = inttoptr i64 %1166 to i32*
  %1169 = load i32, i32* %1168, align 4
  %1170 = add i32 %1169, 1
  %1171 = zext i32 %1170 to i64
  store i64 %1171, i64* %RAX, align 8, !tbaa !2428
  %1172 = icmp eq i32 %1169, -1
  %1173 = icmp eq i32 %1170, 0
  %1174 = or i1 %1172, %1173
  %1175 = zext i1 %1174 to i8
  store i8 %1175, i8* %51, align 1, !tbaa !2433
  %1176 = and i32 %1170, 255
  %1177 = tail call i32 @llvm.ctpop.i32(i32 %1176) #10
  %1178 = trunc i32 %1177 to i8
  %1179 = and i8 %1178, 1
  %1180 = xor i8 %1179, 1
  store i8 %1180, i8* %52, align 1, !tbaa !2447
  %1181 = xor i32 %1169, %1170
  %1182 = lshr i32 %1181, 4
  %1183 = trunc i32 %1182 to i8
  %1184 = and i8 %1183, 1
  store i8 %1184, i8* %53, align 1, !tbaa !2451
  %1185 = zext i1 %1173 to i8
  store i8 %1185, i8* %54, align 1, !tbaa !2448
  %1186 = lshr i32 %1170, 31
  %1187 = trunc i32 %1186 to i8
  store i8 %1187, i8* %55, align 1, !tbaa !2449
  %1188 = lshr i32 %1169, 31
  %1189 = xor i32 %1186, %1188
  %1190 = add nuw nsw i32 %1189, %1186
  %1191 = icmp eq i32 %1190, 2
  %1192 = zext i1 %1191 to i8
  store i8 %1192, i8* %56, align 1, !tbaa !2450
  %1193 = sext i32 %1170 to i64
  store i64 %1193, i64* %RDX, align 8, !tbaa !2428
  %1194 = shl nsw i64 %1193, 3
  %1195 = add i64 %1194, %1165
  %1196 = add i64 %1162, 18
  store i64 %1196, i64* %PC, align 8
  %1197 = inttoptr i64 %1195 to i64*
  %1198 = load i64, i64* %1197, align 8
  store i64 %1198, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1199 = add i64 %1160, -88
  %1200 = add i64 %1162, 23
  store i64 %1200, i64* %PC, align 8
  %1201 = inttoptr i64 %1199 to i64*
  store i64 %1198, i64* %1201, align 8
  %1202 = load i64, i64* %RBP, align 8
  %1203 = add i64 %1202, -80
  %1204 = load i64, i64* %PC, align 8
  %1205 = add i64 %1204, 5
  store i64 %1205, i64* %PC, align 8
  %1206 = inttoptr i64 %1203 to i64*
  %1207 = load i64, i64* %1206, align 8
  store i64 %1207, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1208 = add i64 %1202, -24
  %1209 = add i64 %1204, 9
  store i64 %1209, i64* %PC, align 8
  %1210 = inttoptr i64 %1208 to i64*
  %1211 = load i64, i64* %1210, align 8
  store i64 %1211, i64* %RCX, align 8, !tbaa !2428
  %1212 = add i64 %1202, -32
  %1213 = add i64 %1204, 13
  store i64 %1213, i64* %PC, align 8
  %1214 = inttoptr i64 %1212 to i32*
  %1215 = load i32, i32* %1214, align 4
  %1216 = sext i32 %1215 to i64
  store i64 %1216, i64* %RDX, align 8, !tbaa !2428
  %1217 = shl nsw i64 %1216, 3
  %1218 = add i64 %1217, %1211
  %1219 = add i64 %1204, 18
  store i64 %1219, i64* %PC, align 8
  %1220 = inttoptr i64 %1218 to i64*
  store i64 %1207, i64* %1220, align 8
  %1221 = load i64, i64* %RBP, align 8
  %1222 = add i64 %1221, -88
  %1223 = load i64, i64* %PC, align 8
  %1224 = add i64 %1223, 5
  store i64 %1224, i64* %PC, align 8
  %1225 = inttoptr i64 %1222 to i64*
  %1226 = load i64, i64* %1225, align 8
  store i64 %1226, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1227 = add i64 %1221, -24
  %1228 = add i64 %1223, 9
  store i64 %1228, i64* %PC, align 8
  %1229 = inttoptr i64 %1227 to i64*
  %1230 = load i64, i64* %1229, align 8
  store i64 %1230, i64* %RCX, align 8, !tbaa !2428
  %1231 = add i64 %1221, -32
  %1232 = add i64 %1223, 12
  store i64 %1232, i64* %PC, align 8
  %1233 = inttoptr i64 %1231 to i32*
  %1234 = load i32, i32* %1233, align 4
  %1235 = add i32 %1234, 1
  %1236 = zext i32 %1235 to i64
  store i64 %1236, i64* %RAX, align 8, !tbaa !2428
  %1237 = icmp eq i32 %1234, -1
  %1238 = icmp eq i32 %1235, 0
  %1239 = or i1 %1237, %1238
  %1240 = zext i1 %1239 to i8
  store i8 %1240, i8* %51, align 1, !tbaa !2433
  %1241 = and i32 %1235, 255
  %1242 = tail call i32 @llvm.ctpop.i32(i32 %1241) #10
  %1243 = trunc i32 %1242 to i8
  %1244 = and i8 %1243, 1
  %1245 = xor i8 %1244, 1
  store i8 %1245, i8* %52, align 1, !tbaa !2447
  %1246 = xor i32 %1234, %1235
  %1247 = lshr i32 %1246, 4
  %1248 = trunc i32 %1247 to i8
  %1249 = and i8 %1248, 1
  store i8 %1249, i8* %53, align 1, !tbaa !2451
  %1250 = zext i1 %1238 to i8
  store i8 %1250, i8* %54, align 1, !tbaa !2448
  %1251 = lshr i32 %1235, 31
  %1252 = trunc i32 %1251 to i8
  store i8 %1252, i8* %55, align 1, !tbaa !2449
  %1253 = lshr i32 %1234, 31
  %1254 = xor i32 %1251, %1253
  %1255 = add nuw nsw i32 %1254, %1251
  %1256 = icmp eq i32 %1255, 2
  %1257 = zext i1 %1256 to i8
  store i8 %1257, i8* %56, align 1, !tbaa !2450
  %1258 = sext i32 %1235 to i64
  store i64 %1258, i64* %RDX, align 8, !tbaa !2428
  %1259 = shl nsw i64 %1258, 3
  %1260 = add i64 %1259, %1230
  %1261 = add i64 %1223, 23
  store i64 %1261, i64* %PC, align 8
  %1262 = inttoptr i64 %1260 to i64*
  store i64 %1226, i64* %1262, align 8
  %1263 = load i64, i64* %RBP, align 8
  %1264 = add i64 %1263, -64
  %1265 = load i64, i64* %PC, align 8
  %1266 = add i64 %1265, 5
  store i64 %1266, i64* %PC, align 8
  %1267 = inttoptr i64 %1264 to i64*
  %1268 = load i64, i64* %1267, align 8
  store i64 %1268, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1269 = add i64 %1263, -24
  %1270 = add i64 %1265, 9
  store i64 %1270, i64* %PC, align 8
  %1271 = inttoptr i64 %1269 to i64*
  %1272 = load i64, i64* %1271, align 8
  store i64 %1272, i64* %RCX, align 8, !tbaa !2428
  %1273 = add i64 %1263, -40
  %1274 = add i64 %1265, 13
  store i64 %1274, i64* %PC, align 8
  %1275 = inttoptr i64 %1273 to i32*
  %1276 = load i32, i32* %1275, align 4
  %1277 = sext i32 %1276 to i64
  store i64 %1277, i64* %RDX, align 8, !tbaa !2428
  %1278 = shl nsw i64 %1277, 3
  %1279 = add i64 %1278, %1272
  %1280 = add i64 %1265, 18
  store i64 %1280, i64* %PC, align 8
  %1281 = inttoptr i64 %1279 to i64*
  store i64 %1268, i64* %1281, align 8
  %1282 = load i64, i64* %RBP, align 8
  %1283 = add i64 %1282, -72
  %1284 = load i64, i64* %PC, align 8
  %1285 = add i64 %1284, 5
  store i64 %1285, i64* %PC, align 8
  %1286 = inttoptr i64 %1283 to i64*
  %1287 = load i64, i64* %1286, align 8
  store i64 %1287, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1288 = add i64 %1282, -24
  %1289 = add i64 %1284, 9
  store i64 %1289, i64* %PC, align 8
  %1290 = inttoptr i64 %1288 to i64*
  %1291 = load i64, i64* %1290, align 8
  store i64 %1291, i64* %RCX, align 8, !tbaa !2428
  %1292 = add i64 %1282, -40
  %1293 = add i64 %1284, 12
  store i64 %1293, i64* %PC, align 8
  %1294 = inttoptr i64 %1292 to i32*
  %1295 = load i32, i32* %1294, align 4
  %1296 = add i32 %1295, 1
  %1297 = zext i32 %1296 to i64
  store i64 %1297, i64* %RAX, align 8, !tbaa !2428
  %1298 = icmp eq i32 %1295, -1
  %1299 = icmp eq i32 %1296, 0
  %1300 = or i1 %1298, %1299
  %1301 = zext i1 %1300 to i8
  store i8 %1301, i8* %51, align 1, !tbaa !2433
  %1302 = and i32 %1296, 255
  %1303 = tail call i32 @llvm.ctpop.i32(i32 %1302) #10
  %1304 = trunc i32 %1303 to i8
  %1305 = and i8 %1304, 1
  %1306 = xor i8 %1305, 1
  store i8 %1306, i8* %52, align 1, !tbaa !2447
  %1307 = xor i32 %1295, %1296
  %1308 = lshr i32 %1307, 4
  %1309 = trunc i32 %1308 to i8
  %1310 = and i8 %1309, 1
  store i8 %1310, i8* %53, align 1, !tbaa !2451
  %1311 = zext i1 %1299 to i8
  store i8 %1311, i8* %54, align 1, !tbaa !2448
  %1312 = lshr i32 %1296, 31
  %1313 = trunc i32 %1312 to i8
  store i8 %1313, i8* %55, align 1, !tbaa !2449
  %1314 = lshr i32 %1295, 31
  %1315 = xor i32 %1312, %1314
  %1316 = add nuw nsw i32 %1315, %1312
  %1317 = icmp eq i32 %1316, 2
  %1318 = zext i1 %1317 to i8
  store i8 %1318, i8* %56, align 1, !tbaa !2450
  %1319 = sext i32 %1296 to i64
  store i64 %1319, i64* %RDX, align 8, !tbaa !2428
  %1320 = shl nsw i64 %1319, 3
  %1321 = add i64 %1320, %1291
  %1322 = add i64 %1284, 23
  store i64 %1322, i64* %PC, align 8
  %1323 = inttoptr i64 %1321 to i64*
  store i64 %1287, i64* %1323, align 8
  %1324 = load i64, i64* %RBP, align 8
  %1325 = add i64 %1324, -52
  %1326 = load i64, i64* %PC, align 8
  %1327 = add i64 %1326, 3
  store i64 %1327, i64* %PC, align 8
  %1328 = inttoptr i64 %1325 to i32*
  %1329 = load i32, i32* %1328, align 4
  %1330 = zext i32 %1329 to i64
  store i64 %1330, i64* %RAX, align 8, !tbaa !2428
  %1331 = add i64 %1324, -32
  %1332 = add i64 %1326, 6
  store i64 %1332, i64* %PC, align 8
  %1333 = inttoptr i64 %1331 to i32*
  %1334 = load i32, i32* %1333, align 4
  %1335 = add i32 %1334, %1329
  %1336 = zext i32 %1335 to i64
  store i64 %1336, i64* %RAX, align 8, !tbaa !2428
  %1337 = icmp ult i32 %1335, %1329
  %1338 = icmp ult i32 %1335, %1334
  %1339 = or i1 %1337, %1338
  %1340 = zext i1 %1339 to i8
  store i8 %1340, i8* %51, align 1, !tbaa !2433
  %1341 = and i32 %1335, 255
  %1342 = tail call i32 @llvm.ctpop.i32(i32 %1341) #10
  %1343 = trunc i32 %1342 to i8
  %1344 = and i8 %1343, 1
  %1345 = xor i8 %1344, 1
  store i8 %1345, i8* %52, align 1, !tbaa !2447
  %1346 = xor i32 %1334, %1329
  %1347 = xor i32 %1346, %1335
  %1348 = lshr i32 %1347, 4
  %1349 = trunc i32 %1348 to i8
  %1350 = and i8 %1349, 1
  store i8 %1350, i8* %53, align 1, !tbaa !2451
  %1351 = icmp eq i32 %1335, 0
  %1352 = zext i1 %1351 to i8
  store i8 %1352, i8* %54, align 1, !tbaa !2448
  %1353 = lshr i32 %1335, 31
  %1354 = trunc i32 %1353 to i8
  store i8 %1354, i8* %55, align 1, !tbaa !2449
  %1355 = lshr i32 %1329, 31
  %1356 = lshr i32 %1334, 31
  %1357 = xor i32 %1353, %1355
  %1358 = xor i32 %1353, %1356
  %1359 = add nuw nsw i32 %1357, %1358
  %1360 = icmp eq i32 %1359, 2
  %1361 = zext i1 %1360 to i8
  store i8 %1361, i8* %56, align 1, !tbaa !2450
  %1362 = add i64 %1326, 9
  store i64 %1362, i64* %PC, align 8
  store i32 %1335, i32* %1333, align 4
  %1363 = load i64, i64* %RBP, align 8
  %1364 = add i64 %1363, -52
  %1365 = load i64, i64* %PC, align 8
  %1366 = add i64 %1365, 3
  store i64 %1366, i64* %PC, align 8
  %1367 = inttoptr i64 %1364 to i32*
  %1368 = load i32, i32* %1367, align 4
  %1369 = zext i32 %1368 to i64
  store i64 %1369, i64* %RAX, align 8, !tbaa !2428
  %1370 = add i64 %1363, -40
  %1371 = add i64 %1365, 6
  store i64 %1371, i64* %PC, align 8
  %1372 = inttoptr i64 %1370 to i32*
  %1373 = load i32, i32* %1372, align 4
  %1374 = add i32 %1373, %1368
  %1375 = zext i32 %1374 to i64
  store i64 %1375, i64* %RAX, align 8, !tbaa !2428
  %1376 = icmp ult i32 %1374, %1368
  %1377 = icmp ult i32 %1374, %1373
  %1378 = or i1 %1376, %1377
  %1379 = zext i1 %1378 to i8
  store i8 %1379, i8* %51, align 1, !tbaa !2433
  %1380 = and i32 %1374, 255
  %1381 = tail call i32 @llvm.ctpop.i32(i32 %1380) #10
  %1382 = trunc i32 %1381 to i8
  %1383 = and i8 %1382, 1
  %1384 = xor i8 %1383, 1
  store i8 %1384, i8* %52, align 1, !tbaa !2447
  %1385 = xor i32 %1373, %1368
  %1386 = xor i32 %1385, %1374
  %1387 = lshr i32 %1386, 4
  %1388 = trunc i32 %1387 to i8
  %1389 = and i8 %1388, 1
  store i8 %1389, i8* %53, align 1, !tbaa !2451
  %1390 = icmp eq i32 %1374, 0
  %1391 = zext i1 %1390 to i8
  store i8 %1391, i8* %54, align 1, !tbaa !2448
  %1392 = lshr i32 %1374, 31
  %1393 = trunc i32 %1392 to i8
  store i8 %1393, i8* %55, align 1, !tbaa !2449
  %1394 = lshr i32 %1368, 31
  %1395 = lshr i32 %1373, 31
  %1396 = xor i32 %1392, %1394
  %1397 = xor i32 %1392, %1395
  %1398 = add nuw nsw i32 %1396, %1397
  %1399 = icmp eq i32 %1398, 2
  %1400 = zext i1 %1399 to i8
  store i8 %1400, i8* %56, align 1, !tbaa !2450
  %1401 = add i64 %1365, 9
  store i64 %1401, i64* %PC, align 8
  store i32 %1374, i32* %1372, align 4
  %1402 = load i64, i64* %RBP, align 8
  %1403 = add i64 %1402, -24
  %1404 = load i64, i64* %PC, align 8
  %1405 = add i64 %1404, 4
  store i64 %1405, i64* %PC, align 8
  %1406 = inttoptr i64 %1403 to i64*
  %1407 = load i64, i64* %1406, align 8
  store i64 %1407, i64* %RCX, align 8, !tbaa !2428
  %1408 = add i64 %1402, -32
  %1409 = add i64 %1404, 8
  store i64 %1409, i64* %PC, align 8
  %1410 = inttoptr i64 %1408 to i32*
  %1411 = load i32, i32* %1410, align 4
  %1412 = sext i32 %1411 to i64
  store i64 %1412, i64* %RDX, align 8, !tbaa !2428
  %1413 = shl nsw i64 %1412, 3
  %1414 = add i64 %1413, %1407
  %1415 = add i64 %1404, 13
  store i64 %1415, i64* %PC, align 8
  %1416 = inttoptr i64 %1414 to i64*
  %1417 = load i64, i64* %1416, align 8
  store i64 %1417, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1418 = add i64 %1402, -64
  %1419 = add i64 %1404, 18
  store i64 %1419, i64* %PC, align 8
  %1420 = inttoptr i64 %1418 to i64*
  store i64 %1417, i64* %1420, align 8
  %1421 = load i64, i64* %RBP, align 8
  %1422 = add i64 %1421, -24
  %1423 = load i64, i64* %PC, align 8
  %1424 = add i64 %1423, 4
  store i64 %1424, i64* %PC, align 8
  %1425 = inttoptr i64 %1422 to i64*
  %1426 = load i64, i64* %1425, align 8
  store i64 %1426, i64* %RCX, align 8, !tbaa !2428
  %1427 = add i64 %1421, -32
  %1428 = add i64 %1423, 7
  store i64 %1428, i64* %PC, align 8
  %1429 = inttoptr i64 %1427 to i32*
  %1430 = load i32, i32* %1429, align 4
  %1431 = add i32 %1430, 1
  %1432 = zext i32 %1431 to i64
  store i64 %1432, i64* %RAX, align 8, !tbaa !2428
  %1433 = icmp eq i32 %1430, -1
  %1434 = icmp eq i32 %1431, 0
  %1435 = or i1 %1433, %1434
  %1436 = zext i1 %1435 to i8
  store i8 %1436, i8* %51, align 1, !tbaa !2433
  %1437 = and i32 %1431, 255
  %1438 = tail call i32 @llvm.ctpop.i32(i32 %1437) #10
  %1439 = trunc i32 %1438 to i8
  %1440 = and i8 %1439, 1
  %1441 = xor i8 %1440, 1
  store i8 %1441, i8* %52, align 1, !tbaa !2447
  %1442 = xor i32 %1430, %1431
  %1443 = lshr i32 %1442, 4
  %1444 = trunc i32 %1443 to i8
  %1445 = and i8 %1444, 1
  store i8 %1445, i8* %53, align 1, !tbaa !2451
  %1446 = zext i1 %1434 to i8
  store i8 %1446, i8* %54, align 1, !tbaa !2448
  %1447 = lshr i32 %1431, 31
  %1448 = trunc i32 %1447 to i8
  store i8 %1448, i8* %55, align 1, !tbaa !2449
  %1449 = lshr i32 %1430, 31
  %1450 = xor i32 %1447, %1449
  %1451 = add nuw nsw i32 %1450, %1447
  %1452 = icmp eq i32 %1451, 2
  %1453 = zext i1 %1452 to i8
  store i8 %1453, i8* %56, align 1, !tbaa !2450
  %1454 = sext i32 %1431 to i64
  store i64 %1454, i64* %RDX, align 8, !tbaa !2428
  %1455 = shl nsw i64 %1454, 3
  %1456 = add i64 %1455, %1426
  %1457 = add i64 %1423, 18
  store i64 %1457, i64* %PC, align 8
  %1458 = inttoptr i64 %1456 to i64*
  %1459 = load i64, i64* %1458, align 8
  store i64 %1459, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1460 = add i64 %1421, -72
  %1461 = add i64 %1423, 23
  store i64 %1461, i64* %PC, align 8
  %1462 = inttoptr i64 %1460 to i64*
  store i64 %1459, i64* %1462, align 8
  %1463 = load i64, i64* %RBP, align 8
  %1464 = add i64 %1463, -24
  %1465 = load i64, i64* %PC, align 8
  %1466 = add i64 %1465, 4
  store i64 %1466, i64* %PC, align 8
  %1467 = inttoptr i64 %1464 to i64*
  %1468 = load i64, i64* %1467, align 8
  store i64 %1468, i64* %RCX, align 8, !tbaa !2428
  %1469 = add i64 %1463, -40
  %1470 = add i64 %1465, 8
  store i64 %1470, i64* %PC, align 8
  %1471 = inttoptr i64 %1469 to i32*
  %1472 = load i32, i32* %1471, align 4
  %1473 = sext i32 %1472 to i64
  store i64 %1473, i64* %RDX, align 8, !tbaa !2428
  %1474 = shl nsw i64 %1473, 3
  %1475 = add i64 %1474, %1468
  %1476 = add i64 %1465, 13
  store i64 %1476, i64* %PC, align 8
  %1477 = inttoptr i64 %1475 to i64*
  %1478 = load i64, i64* %1477, align 8
  store i64 %1478, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1479 = add i64 %1463, -80
  %1480 = add i64 %1465, 18
  store i64 %1480, i64* %PC, align 8
  %1481 = inttoptr i64 %1479 to i64*
  store i64 %1478, i64* %1481, align 8
  %1482 = load i64, i64* %RBP, align 8
  %1483 = add i64 %1482, -24
  %1484 = load i64, i64* %PC, align 8
  %1485 = add i64 %1484, 4
  store i64 %1485, i64* %PC, align 8
  %1486 = inttoptr i64 %1483 to i64*
  %1487 = load i64, i64* %1486, align 8
  store i64 %1487, i64* %RCX, align 8, !tbaa !2428
  %1488 = add i64 %1482, -40
  %1489 = add i64 %1484, 7
  store i64 %1489, i64* %PC, align 8
  %1490 = inttoptr i64 %1488 to i32*
  %1491 = load i32, i32* %1490, align 4
  %1492 = add i32 %1491, 1
  %1493 = zext i32 %1492 to i64
  store i64 %1493, i64* %RAX, align 8, !tbaa !2428
  %1494 = icmp eq i32 %1491, -1
  %1495 = icmp eq i32 %1492, 0
  %1496 = or i1 %1494, %1495
  %1497 = zext i1 %1496 to i8
  store i8 %1497, i8* %51, align 1, !tbaa !2433
  %1498 = and i32 %1492, 255
  %1499 = tail call i32 @llvm.ctpop.i32(i32 %1498) #10
  %1500 = trunc i32 %1499 to i8
  %1501 = and i8 %1500, 1
  %1502 = xor i8 %1501, 1
  store i8 %1502, i8* %52, align 1, !tbaa !2447
  %1503 = xor i32 %1491, %1492
  %1504 = lshr i32 %1503, 4
  %1505 = trunc i32 %1504 to i8
  %1506 = and i8 %1505, 1
  store i8 %1506, i8* %53, align 1, !tbaa !2451
  %1507 = zext i1 %1495 to i8
  store i8 %1507, i8* %54, align 1, !tbaa !2448
  %1508 = lshr i32 %1492, 31
  %1509 = trunc i32 %1508 to i8
  store i8 %1509, i8* %55, align 1, !tbaa !2449
  %1510 = lshr i32 %1491, 31
  %1511 = xor i32 %1508, %1510
  %1512 = add nuw nsw i32 %1511, %1508
  %1513 = icmp eq i32 %1512, 2
  %1514 = zext i1 %1513 to i8
  store i8 %1514, i8* %56, align 1, !tbaa !2450
  %1515 = sext i32 %1492 to i64
  store i64 %1515, i64* %RDX, align 8, !tbaa !2428
  %1516 = shl nsw i64 %1515, 3
  %1517 = add i64 %1516, %1487
  %1518 = add i64 %1484, 18
  store i64 %1518, i64* %PC, align 8
  %1519 = inttoptr i64 %1517 to i64*
  %1520 = load i64, i64* %1519, align 8
  store i64 %1520, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1521 = add i64 %1482, -88
  %1522 = add i64 %1484, 23
  store i64 %1522, i64* %PC, align 8
  %1523 = inttoptr i64 %1521 to i64*
  store i64 %1520, i64* %1523, align 8
  %1524 = load i64, i64* %RBP, align 8
  %1525 = add i64 %1524, -80
  %1526 = load i64, i64* %PC, align 8
  %1527 = add i64 %1526, 5
  store i64 %1527, i64* %PC, align 8
  %1528 = inttoptr i64 %1525 to i64*
  %1529 = load i64, i64* %1528, align 8
  store i64 %1529, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1530 = add i64 %1524, -24
  %1531 = add i64 %1526, 9
  store i64 %1531, i64* %PC, align 8
  %1532 = inttoptr i64 %1530 to i64*
  %1533 = load i64, i64* %1532, align 8
  store i64 %1533, i64* %RCX, align 8, !tbaa !2428
  %1534 = add i64 %1524, -32
  %1535 = add i64 %1526, 13
  store i64 %1535, i64* %PC, align 8
  %1536 = inttoptr i64 %1534 to i32*
  %1537 = load i32, i32* %1536, align 4
  %1538 = sext i32 %1537 to i64
  store i64 %1538, i64* %RDX, align 8, !tbaa !2428
  %1539 = shl nsw i64 %1538, 3
  %1540 = add i64 %1539, %1533
  %1541 = add i64 %1526, 18
  store i64 %1541, i64* %PC, align 8
  %1542 = inttoptr i64 %1540 to i64*
  store i64 %1529, i64* %1542, align 8
  %1543 = load i64, i64* %RBP, align 8
  %1544 = add i64 %1543, -88
  %1545 = load i64, i64* %PC, align 8
  %1546 = add i64 %1545, 5
  store i64 %1546, i64* %PC, align 8
  %1547 = inttoptr i64 %1544 to i64*
  %1548 = load i64, i64* %1547, align 8
  store i64 %1548, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1549 = add i64 %1543, -24
  %1550 = add i64 %1545, 9
  store i64 %1550, i64* %PC, align 8
  %1551 = inttoptr i64 %1549 to i64*
  %1552 = load i64, i64* %1551, align 8
  store i64 %1552, i64* %RCX, align 8, !tbaa !2428
  %1553 = add i64 %1543, -32
  %1554 = add i64 %1545, 12
  store i64 %1554, i64* %PC, align 8
  %1555 = inttoptr i64 %1553 to i32*
  %1556 = load i32, i32* %1555, align 4
  %1557 = add i32 %1556, 1
  %1558 = zext i32 %1557 to i64
  store i64 %1558, i64* %RAX, align 8, !tbaa !2428
  %1559 = icmp eq i32 %1556, -1
  %1560 = icmp eq i32 %1557, 0
  %1561 = or i1 %1559, %1560
  %1562 = zext i1 %1561 to i8
  store i8 %1562, i8* %51, align 1, !tbaa !2433
  %1563 = and i32 %1557, 255
  %1564 = tail call i32 @llvm.ctpop.i32(i32 %1563) #10
  %1565 = trunc i32 %1564 to i8
  %1566 = and i8 %1565, 1
  %1567 = xor i8 %1566, 1
  store i8 %1567, i8* %52, align 1, !tbaa !2447
  %1568 = xor i32 %1556, %1557
  %1569 = lshr i32 %1568, 4
  %1570 = trunc i32 %1569 to i8
  %1571 = and i8 %1570, 1
  store i8 %1571, i8* %53, align 1, !tbaa !2451
  %1572 = zext i1 %1560 to i8
  store i8 %1572, i8* %54, align 1, !tbaa !2448
  %1573 = lshr i32 %1557, 31
  %1574 = trunc i32 %1573 to i8
  store i8 %1574, i8* %55, align 1, !tbaa !2449
  %1575 = lshr i32 %1556, 31
  %1576 = xor i32 %1573, %1575
  %1577 = add nuw nsw i32 %1576, %1573
  %1578 = icmp eq i32 %1577, 2
  %1579 = zext i1 %1578 to i8
  store i8 %1579, i8* %56, align 1, !tbaa !2450
  %1580 = sext i32 %1557 to i64
  store i64 %1580, i64* %RDX, align 8, !tbaa !2428
  %1581 = shl nsw i64 %1580, 3
  %1582 = add i64 %1581, %1552
  %1583 = add i64 %1545, 23
  store i64 %1583, i64* %PC, align 8
  %1584 = inttoptr i64 %1582 to i64*
  store i64 %1548, i64* %1584, align 8
  %1585 = load i64, i64* %RBP, align 8
  %1586 = add i64 %1585, -64
  %1587 = load i64, i64* %PC, align 8
  %1588 = add i64 %1587, 5
  store i64 %1588, i64* %PC, align 8
  %1589 = inttoptr i64 %1586 to i64*
  %1590 = load i64, i64* %1589, align 8
  store i64 %1590, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1591 = add i64 %1585, -24
  %1592 = add i64 %1587, 9
  store i64 %1592, i64* %PC, align 8
  %1593 = inttoptr i64 %1591 to i64*
  %1594 = load i64, i64* %1593, align 8
  store i64 %1594, i64* %RCX, align 8, !tbaa !2428
  %1595 = add i64 %1585, -40
  %1596 = add i64 %1587, 13
  store i64 %1596, i64* %PC, align 8
  %1597 = inttoptr i64 %1595 to i32*
  %1598 = load i32, i32* %1597, align 4
  %1599 = sext i32 %1598 to i64
  store i64 %1599, i64* %RDX, align 8, !tbaa !2428
  %1600 = shl nsw i64 %1599, 3
  %1601 = add i64 %1600, %1594
  %1602 = add i64 %1587, 18
  store i64 %1602, i64* %PC, align 8
  %1603 = inttoptr i64 %1601 to i64*
  store i64 %1590, i64* %1603, align 8
  %1604 = load i64, i64* %RBP, align 8
  %1605 = add i64 %1604, -72
  %1606 = load i64, i64* %PC, align 8
  %1607 = add i64 %1606, 5
  store i64 %1607, i64* %PC, align 8
  %1608 = inttoptr i64 %1605 to i64*
  %1609 = load i64, i64* %1608, align 8
  store i64 %1609, i64* %1095, align 1, !tbaa !2452
  store double 0.000000e+00, double* %314, align 1, !tbaa !2452
  %1610 = add i64 %1604, -24
  %1611 = add i64 %1606, 9
  store i64 %1611, i64* %PC, align 8
  %1612 = inttoptr i64 %1610 to i64*
  %1613 = load i64, i64* %1612, align 8
  store i64 %1613, i64* %RCX, align 8, !tbaa !2428
  %1614 = add i64 %1604, -40
  %1615 = add i64 %1606, 12
  store i64 %1615, i64* %PC, align 8
  %1616 = inttoptr i64 %1614 to i32*
  %1617 = load i32, i32* %1616, align 4
  %1618 = add i32 %1617, 1
  %1619 = zext i32 %1618 to i64
  store i64 %1619, i64* %RAX, align 8, !tbaa !2428
  %1620 = icmp eq i32 %1617, -1
  %1621 = icmp eq i32 %1618, 0
  %1622 = or i1 %1620, %1621
  %1623 = zext i1 %1622 to i8
  store i8 %1623, i8* %51, align 1, !tbaa !2433
  %1624 = and i32 %1618, 255
  %1625 = tail call i32 @llvm.ctpop.i32(i32 %1624) #10
  %1626 = trunc i32 %1625 to i8
  %1627 = and i8 %1626, 1
  %1628 = xor i8 %1627, 1
  store i8 %1628, i8* %52, align 1, !tbaa !2447
  %1629 = xor i32 %1617, %1618
  %1630 = lshr i32 %1629, 4
  %1631 = trunc i32 %1630 to i8
  %1632 = and i8 %1631, 1
  store i8 %1632, i8* %53, align 1, !tbaa !2451
  %1633 = zext i1 %1621 to i8
  store i8 %1633, i8* %54, align 1, !tbaa !2448
  %1634 = lshr i32 %1618, 31
  %1635 = trunc i32 %1634 to i8
  store i8 %1635, i8* %55, align 1, !tbaa !2449
  %1636 = lshr i32 %1617, 31
  %1637 = xor i32 %1634, %1636
  %1638 = add nuw nsw i32 %1637, %1634
  %1639 = icmp eq i32 %1638, 2
  %1640 = zext i1 %1639 to i8
  store i8 %1640, i8* %56, align 1, !tbaa !2450
  %1641 = sext i32 %1618 to i64
  store i64 %1641, i64* %RDX, align 8, !tbaa !2428
  %1642 = shl nsw i64 %1641, 3
  %1643 = add i64 %1642, %1613
  %1644 = add i64 %1606, 23
  store i64 %1644, i64* %PC, align 8
  %1645 = inttoptr i64 %1643 to i64*
  store i64 %1609, i64* %1645, align 8
  %1646 = load i64, i64* %RBP, align 8
  %1647 = add i64 %1646, -28
  %1648 = load i64, i64* %PC, align 8
  %1649 = add i64 %1648, 3
  store i64 %1649, i64* %PC, align 8
  %1650 = inttoptr i64 %1647 to i32*
  %1651 = load i32, i32* %1650, align 4
  %1652 = add i32 %1651, 1
  %1653 = zext i32 %1652 to i64
  store i64 %1653, i64* %RAX, align 8, !tbaa !2428
  %1654 = icmp eq i32 %1651, -1
  %1655 = icmp eq i32 %1652, 0
  %1656 = or i1 %1654, %1655
  %1657 = zext i1 %1656 to i8
  store i8 %1657, i8* %51, align 1, !tbaa !2433
  %1658 = and i32 %1652, 255
  %1659 = tail call i32 @llvm.ctpop.i32(i32 %1658) #10
  %1660 = trunc i32 %1659 to i8
  %1661 = and i8 %1660, 1
  %1662 = xor i8 %1661, 1
  store i8 %1662, i8* %52, align 1, !tbaa !2447
  %1663 = xor i32 %1651, %1652
  %1664 = lshr i32 %1663, 4
  %1665 = trunc i32 %1664 to i8
  %1666 = and i8 %1665, 1
  store i8 %1666, i8* %53, align 1, !tbaa !2451
  %1667 = zext i1 %1655 to i8
  store i8 %1667, i8* %54, align 1, !tbaa !2448
  %1668 = lshr i32 %1652, 31
  %1669 = trunc i32 %1668 to i8
  store i8 %1669, i8* %55, align 1, !tbaa !2449
  %1670 = lshr i32 %1651, 31
  %1671 = xor i32 %1668, %1670
  %1672 = add nuw nsw i32 %1671, %1668
  %1673 = icmp eq i32 %1672, 2
  %1674 = zext i1 %1673 to i8
  store i8 %1674, i8* %56, align 1, !tbaa !2450
  %1675 = add i64 %1648, 9
  store i64 %1675, i64* %PC, align 8
  store i32 %1652, i32* %1650, align 4
  %1676 = load i64, i64* %PC, align 8
  %1677 = add i64 %1676, -407
  store i64 %1677, i64* %PC, align 8, !tbaa !2428
  br label %block_40167e

block_401289:                                     ; preds = %block_40127d
  %1678 = load i32, i32* %61, align 4
  %1679 = shl i32 %1678, 1
  %1680 = icmp slt i32 %1678, 0
  %1681 = icmp slt i32 %1679, 0
  %1682 = xor i1 %1680, %1681
  %1683 = zext i32 %1679 to i64
  store i64 %1683, i64* %RAX, align 8, !tbaa !2428
  %.lobit15 = lshr i32 %1678, 31
  %1684 = trunc i32 %.lobit15 to i8
  store i8 %1684, i8* %51, align 1, !tbaa !2432
  %1685 = and i32 %1679, 254
  %1686 = tail call i32 @llvm.ctpop.i32(i32 %1685) #10
  %1687 = trunc i32 %1686 to i8
  %1688 = and i8 %1687, 1
  %1689 = xor i8 %1688, 1
  store i8 %1689, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %1690 = icmp eq i32 %1679, 0
  %1691 = zext i1 %1690 to i8
  store i8 %1691, i8* %54, align 1, !tbaa !2432
  %1692 = lshr i32 %1678, 30
  %1693 = and i32 %1692, 1
  %1694 = trunc i32 %1693 to i8
  store i8 %1694, i8* %55, align 1, !tbaa !2432
  %1695 = zext i1 %1682 to i8
  store i8 %1695, i8* %56, align 1, !tbaa !2432
  %1696 = add i64 %58, -16
  %1697 = add i64 %94, 10
  store i64 %1697, i64* %PC, align 8
  %1698 = inttoptr i64 %1696 to i64*
  %1699 = load i64, i64* %1698, align 8
  store i64 %1699, i64* %RCX, align 8, !tbaa !2428
  %1700 = add i64 %94, 14
  store i64 %1700, i64* %PC, align 8
  %1701 = load i32, i32* %66, align 4
  %1702 = sext i32 %1701 to i64
  store i64 %1702, i64* %RDX, align 8, !tbaa !2428
  %1703 = shl nsw i64 %1702, 2
  %1704 = add i64 %1703, %1699
  %1705 = add i64 %94, 17
  store i64 %1705, i64* %PC, align 8
  %1706 = inttoptr i64 %1704 to i32*
  %1707 = load i32, i32* %1706, align 4
  %1708 = add i32 %1707, %1679
  %1709 = zext i32 %1708 to i64
  store i64 %1709, i64* %RAX, align 8, !tbaa !2428
  %1710 = icmp ult i32 %1708, %1679
  %1711 = icmp ult i32 %1708, %1707
  %1712 = or i1 %1710, %1711
  %1713 = zext i1 %1712 to i8
  store i8 %1713, i8* %51, align 1, !tbaa !2433
  %1714 = and i32 %1708, 255
  %1715 = tail call i32 @llvm.ctpop.i32(i32 %1714) #10
  %1716 = trunc i32 %1715 to i8
  %1717 = and i8 %1716, 1
  %1718 = xor i8 %1717, 1
  store i8 %1718, i8* %52, align 1, !tbaa !2447
  %1719 = xor i32 %1707, %1679
  %1720 = xor i32 %1719, %1708
  %1721 = lshr i32 %1720, 4
  %1722 = trunc i32 %1721 to i8
  %1723 = and i8 %1722, 1
  store i8 %1723, i8* %53, align 1, !tbaa !2451
  %1724 = icmp eq i32 %1708, 0
  %1725 = zext i1 %1724 to i8
  store i8 %1725, i8* %54, align 1, !tbaa !2448
  %1726 = lshr i32 %1708, 31
  %1727 = trunc i32 %1726 to i8
  store i8 %1727, i8* %55, align 1, !tbaa !2449
  %1728 = lshr i32 %1707, 31
  %1729 = xor i32 %1726, %1693
  %1730 = xor i32 %1726, %1728
  %1731 = add nuw nsw i32 %1729, %1730
  %1732 = icmp eq i32 %1731, 2
  %1733 = zext i1 %1732 to i8
  store i8 %1733, i8* %56, align 1, !tbaa !2450
  %1734 = add i64 %58, -32
  %1735 = add i64 %94, 20
  store i64 %1735, i64* %PC, align 8
  %1736 = inttoptr i64 %1734 to i32*
  store i32 %1708, i32* %1736, align 4
  %1737 = load i64, i64* %RBP, align 8
  %1738 = add i64 %1737, -36
  %1739 = load i64, i64* %PC, align 8
  %1740 = add i64 %1739, 3
  store i64 %1740, i64* %PC, align 8
  %1741 = inttoptr i64 %1738 to i32*
  %1742 = load i32, i32* %1741, align 4
  %1743 = shl i32 %1742, 1
  %1744 = icmp slt i32 %1742, 0
  %1745 = icmp slt i32 %1743, 0
  %1746 = xor i1 %1744, %1745
  %1747 = zext i32 %1743 to i64
  store i64 %1747, i64* %RAX, align 8, !tbaa !2428
  %.lobit16 = lshr i32 %1742, 31
  %1748 = trunc i32 %.lobit16 to i8
  store i8 %1748, i8* %51, align 1, !tbaa !2432
  %1749 = and i32 %1743, 254
  %1750 = tail call i32 @llvm.ctpop.i32(i32 %1749) #10
  %1751 = trunc i32 %1750 to i8
  %1752 = and i8 %1751, 1
  %1753 = xor i8 %1752, 1
  store i8 %1753, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %1754 = icmp eq i32 %1743, 0
  %1755 = zext i1 %1754 to i8
  store i8 %1755, i8* %54, align 1, !tbaa !2432
  %1756 = lshr i32 %1742, 30
  %1757 = and i32 %1756, 1
  %1758 = trunc i32 %1757 to i8
  store i8 %1758, i8* %55, align 1, !tbaa !2432
  %1759 = zext i1 %1746 to i8
  store i8 %1759, i8* %56, align 1, !tbaa !2432
  %1760 = add i64 %1737, -16
  %1761 = add i64 %1739, 10
  store i64 %1761, i64* %PC, align 8
  %1762 = inttoptr i64 %1760 to i64*
  %1763 = load i64, i64* %1762, align 8
  store i64 %1763, i64* %RCX, align 8, !tbaa !2428
  %1764 = add i64 %1737, -28
  %1765 = add i64 %1739, 14
  store i64 %1765, i64* %PC, align 8
  %1766 = inttoptr i64 %1764 to i32*
  %1767 = load i32, i32* %1766, align 4
  %1768 = sext i32 %1767 to i64
  store i64 %1768, i64* %RDX, align 8, !tbaa !2428
  %1769 = shl nsw i64 %1768, 2
  %1770 = add i64 %1769, %1763
  %1771 = add i64 %1739, 17
  store i64 %1771, i64* %PC, align 8
  %1772 = inttoptr i64 %1770 to i32*
  %1773 = load i32, i32* %1772, align 4
  %1774 = add i32 %1773, %1743
  %1775 = zext i32 %1774 to i64
  store i64 %1775, i64* %RAX, align 8, !tbaa !2428
  %1776 = icmp ult i32 %1774, %1743
  %1777 = icmp ult i32 %1774, %1773
  %1778 = or i1 %1776, %1777
  %1779 = zext i1 %1778 to i8
  store i8 %1779, i8* %51, align 1, !tbaa !2433
  %1780 = and i32 %1774, 255
  %1781 = tail call i32 @llvm.ctpop.i32(i32 %1780) #10
  %1782 = trunc i32 %1781 to i8
  %1783 = and i8 %1782, 1
  %1784 = xor i8 %1783, 1
  store i8 %1784, i8* %52, align 1, !tbaa !2447
  %1785 = xor i32 %1773, %1743
  %1786 = xor i32 %1785, %1774
  %1787 = lshr i32 %1786, 4
  %1788 = trunc i32 %1787 to i8
  %1789 = and i8 %1788, 1
  store i8 %1789, i8* %53, align 1, !tbaa !2451
  %1790 = icmp eq i32 %1774, 0
  %1791 = zext i1 %1790 to i8
  store i8 %1791, i8* %54, align 1, !tbaa !2448
  %1792 = lshr i32 %1774, 31
  %1793 = trunc i32 %1792 to i8
  store i8 %1793, i8* %55, align 1, !tbaa !2449
  %1794 = lshr i32 %1773, 31
  %1795 = xor i32 %1792, %1757
  %1796 = xor i32 %1792, %1794
  %1797 = add nuw nsw i32 %1795, %1796
  %1798 = icmp eq i32 %1797, 2
  %1799 = zext i1 %1798 to i8
  store i8 %1799, i8* %56, align 1, !tbaa !2450
  %1800 = add i64 %1737, -40
  %1801 = add i64 %1739, 20
  store i64 %1801, i64* %PC, align 8
  %1802 = inttoptr i64 %1800 to i32*
  store i32 %1774, i32* %1802, align 4
  %1803 = load i64, i64* %RBP, align 8
  %1804 = add i64 %1803, -24
  %1805 = load i64, i64* %PC, align 8
  %1806 = add i64 %1805, 4
  store i64 %1806, i64* %PC, align 8
  %1807 = inttoptr i64 %1804 to i64*
  %1808 = load i64, i64* %1807, align 8
  store i64 %1808, i64* %RCX, align 8, !tbaa !2428
  %1809 = add i64 %1803, -32
  %1810 = add i64 %1805, 8
  store i64 %1810, i64* %PC, align 8
  %1811 = inttoptr i64 %1809 to i32*
  %1812 = load i32, i32* %1811, align 4
  %1813 = sext i32 %1812 to i64
  store i64 %1813, i64* %RDX, align 8, !tbaa !2428
  %1814 = shl nsw i64 %1813, 3
  %1815 = add i64 %1814, %1808
  %1816 = add i64 %1805, 13
  store i64 %1816, i64* %PC, align 8
  %1817 = inttoptr i64 %1815 to i64*
  %1818 = load i64, i64* %1817, align 8
  %1819 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1818, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %1820 = add i64 %1803, -64
  %1821 = add i64 %1805, 18
  store i64 %1821, i64* %PC, align 8
  %1822 = inttoptr i64 %1820 to i64*
  store i64 %1818, i64* %1822, align 8
  %1823 = load i64, i64* %RBP, align 8
  %1824 = add i64 %1823, -24
  %1825 = load i64, i64* %PC, align 8
  %1826 = add i64 %1825, 4
  store i64 %1826, i64* %PC, align 8
  %1827 = inttoptr i64 %1824 to i64*
  %1828 = load i64, i64* %1827, align 8
  store i64 %1828, i64* %RCX, align 8, !tbaa !2428
  %1829 = add i64 %1823, -32
  %1830 = add i64 %1825, 7
  store i64 %1830, i64* %PC, align 8
  %1831 = inttoptr i64 %1829 to i32*
  %1832 = load i32, i32* %1831, align 4
  %1833 = add i32 %1832, 1
  %1834 = zext i32 %1833 to i64
  store i64 %1834, i64* %RAX, align 8, !tbaa !2428
  %1835 = icmp eq i32 %1832, -1
  %1836 = icmp eq i32 %1833, 0
  %1837 = or i1 %1835, %1836
  %1838 = zext i1 %1837 to i8
  store i8 %1838, i8* %51, align 1, !tbaa !2433
  %1839 = and i32 %1833, 255
  %1840 = tail call i32 @llvm.ctpop.i32(i32 %1839) #10
  %1841 = trunc i32 %1840 to i8
  %1842 = and i8 %1841, 1
  %1843 = xor i8 %1842, 1
  store i8 %1843, i8* %52, align 1, !tbaa !2447
  %1844 = xor i32 %1832, %1833
  %1845 = lshr i32 %1844, 4
  %1846 = trunc i32 %1845 to i8
  %1847 = and i8 %1846, 1
  store i8 %1847, i8* %53, align 1, !tbaa !2451
  %1848 = zext i1 %1836 to i8
  store i8 %1848, i8* %54, align 1, !tbaa !2448
  %1849 = lshr i32 %1833, 31
  %1850 = trunc i32 %1849 to i8
  store i8 %1850, i8* %55, align 1, !tbaa !2449
  %1851 = lshr i32 %1832, 31
  %1852 = xor i32 %1849, %1851
  %1853 = add nuw nsw i32 %1852, %1849
  %1854 = icmp eq i32 %1853, 2
  %1855 = zext i1 %1854 to i8
  store i8 %1855, i8* %56, align 1, !tbaa !2450
  %1856 = sext i32 %1833 to i64
  store i64 %1856, i64* %RDX, align 8, !tbaa !2428
  %1857 = shl nsw i64 %1856, 3
  %1858 = add i64 %1857, %1828
  %1859 = add i64 %1825, 18
  store i64 %1859, i64* %PC, align 8
  %1860 = inttoptr i64 %1858 to i64*
  %1861 = load i64, i64* %1860, align 8
  store i64 %1861, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %1862 = add i64 %1823, -72
  %1863 = add i64 %1825, 23
  store i64 %1863, i64* %PC, align 8
  %1864 = inttoptr i64 %1862 to i64*
  store i64 %1861, i64* %1864, align 8
  %1865 = load i64, i64* %RBP, align 8
  %1866 = add i64 %1865, -24
  %1867 = load i64, i64* %PC, align 8
  %1868 = add i64 %1867, 4
  store i64 %1868, i64* %PC, align 8
  %1869 = inttoptr i64 %1866 to i64*
  %1870 = load i64, i64* %1869, align 8
  store i64 %1870, i64* %RCX, align 8, !tbaa !2428
  %1871 = add i64 %1865, -40
  %1872 = add i64 %1867, 8
  store i64 %1872, i64* %PC, align 8
  %1873 = inttoptr i64 %1871 to i32*
  %1874 = load i32, i32* %1873, align 4
  %1875 = sext i32 %1874 to i64
  store i64 %1875, i64* %RDX, align 8, !tbaa !2428
  %1876 = shl nsw i64 %1875, 3
  %1877 = add i64 %1876, %1870
  %1878 = add i64 %1867, 13
  store i64 %1878, i64* %PC, align 8
  %1879 = inttoptr i64 %1877 to i64*
  %1880 = load i64, i64* %1879, align 8
  store i64 %1880, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %1881 = add i64 %1865, -80
  %1882 = add i64 %1867, 18
  store i64 %1882, i64* %PC, align 8
  %1883 = inttoptr i64 %1881 to i64*
  store i64 %1880, i64* %1883, align 8
  %1884 = load i64, i64* %RBP, align 8
  %1885 = add i64 %1884, -24
  %1886 = load i64, i64* %PC, align 8
  %1887 = add i64 %1886, 4
  store i64 %1887, i64* %PC, align 8
  %1888 = inttoptr i64 %1885 to i64*
  %1889 = load i64, i64* %1888, align 8
  store i64 %1889, i64* %RCX, align 8, !tbaa !2428
  %1890 = add i64 %1884, -40
  %1891 = add i64 %1886, 7
  store i64 %1891, i64* %PC, align 8
  %1892 = inttoptr i64 %1890 to i32*
  %1893 = load i32, i32* %1892, align 4
  %1894 = add i32 %1893, 1
  %1895 = zext i32 %1894 to i64
  store i64 %1895, i64* %RAX, align 8, !tbaa !2428
  %1896 = icmp eq i32 %1893, -1
  %1897 = icmp eq i32 %1894, 0
  %1898 = or i1 %1896, %1897
  %1899 = zext i1 %1898 to i8
  store i8 %1899, i8* %51, align 1, !tbaa !2433
  %1900 = and i32 %1894, 255
  %1901 = tail call i32 @llvm.ctpop.i32(i32 %1900) #10
  %1902 = trunc i32 %1901 to i8
  %1903 = and i8 %1902, 1
  %1904 = xor i8 %1903, 1
  store i8 %1904, i8* %52, align 1, !tbaa !2447
  %1905 = xor i32 %1893, %1894
  %1906 = lshr i32 %1905, 4
  %1907 = trunc i32 %1906 to i8
  %1908 = and i8 %1907, 1
  store i8 %1908, i8* %53, align 1, !tbaa !2451
  %1909 = zext i1 %1897 to i8
  store i8 %1909, i8* %54, align 1, !tbaa !2448
  %1910 = lshr i32 %1894, 31
  %1911 = trunc i32 %1910 to i8
  store i8 %1911, i8* %55, align 1, !tbaa !2449
  %1912 = lshr i32 %1893, 31
  %1913 = xor i32 %1910, %1912
  %1914 = add nuw nsw i32 %1913, %1910
  %1915 = icmp eq i32 %1914, 2
  %1916 = zext i1 %1915 to i8
  store i8 %1916, i8* %56, align 1, !tbaa !2450
  %1917 = sext i32 %1894 to i64
  store i64 %1917, i64* %RDX, align 8, !tbaa !2428
  %1918 = shl nsw i64 %1917, 3
  %1919 = add i64 %1918, %1889
  %1920 = add i64 %1886, 18
  store i64 %1920, i64* %PC, align 8
  %1921 = inttoptr i64 %1919 to i64*
  %1922 = load i64, i64* %1921, align 8
  store i64 %1922, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %1923 = add i64 %1884, -88
  %1924 = add i64 %1886, 23
  store i64 %1924, i64* %PC, align 8
  %1925 = inttoptr i64 %1923 to i64*
  store i64 %1922, i64* %1925, align 8
  %1926 = load i64, i64* %RBP, align 8
  %1927 = add i64 %1926, -80
  %1928 = load i64, i64* %PC, align 8
  %1929 = add i64 %1928, 5
  store i64 %1929, i64* %PC, align 8
  %1930 = inttoptr i64 %1927 to i64*
  %1931 = load i64, i64* %1930, align 8
  store i64 %1931, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %1932 = add i64 %1926, -24
  %1933 = add i64 %1928, 9
  store i64 %1933, i64* %PC, align 8
  %1934 = inttoptr i64 %1932 to i64*
  %1935 = load i64, i64* %1934, align 8
  store i64 %1935, i64* %RCX, align 8, !tbaa !2428
  %1936 = add i64 %1926, -32
  %1937 = add i64 %1928, 13
  store i64 %1937, i64* %PC, align 8
  %1938 = inttoptr i64 %1936 to i32*
  %1939 = load i32, i32* %1938, align 4
  %1940 = sext i32 %1939 to i64
  store i64 %1940, i64* %RDX, align 8, !tbaa !2428
  %1941 = shl nsw i64 %1940, 3
  %1942 = add i64 %1941, %1935
  %1943 = add i64 %1928, 18
  store i64 %1943, i64* %PC, align 8
  %1944 = inttoptr i64 %1942 to i64*
  store i64 %1931, i64* %1944, align 8
  %1945 = load i64, i64* %RBP, align 8
  %1946 = add i64 %1945, -88
  %1947 = load i64, i64* %PC, align 8
  %1948 = add i64 %1947, 5
  store i64 %1948, i64* %PC, align 8
  %1949 = inttoptr i64 %1946 to i64*
  %1950 = load i64, i64* %1949, align 8
  store i64 %1950, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %1951 = add i64 %1945, -24
  %1952 = add i64 %1947, 9
  store i64 %1952, i64* %PC, align 8
  %1953 = inttoptr i64 %1951 to i64*
  %1954 = load i64, i64* %1953, align 8
  store i64 %1954, i64* %RCX, align 8, !tbaa !2428
  %1955 = add i64 %1945, -32
  %1956 = add i64 %1947, 12
  store i64 %1956, i64* %PC, align 8
  %1957 = inttoptr i64 %1955 to i32*
  %1958 = load i32, i32* %1957, align 4
  %1959 = add i32 %1958, 1
  %1960 = zext i32 %1959 to i64
  store i64 %1960, i64* %RAX, align 8, !tbaa !2428
  %1961 = icmp eq i32 %1958, -1
  %1962 = icmp eq i32 %1959, 0
  %1963 = or i1 %1961, %1962
  %1964 = zext i1 %1963 to i8
  store i8 %1964, i8* %51, align 1, !tbaa !2433
  %1965 = and i32 %1959, 255
  %1966 = tail call i32 @llvm.ctpop.i32(i32 %1965) #10
  %1967 = trunc i32 %1966 to i8
  %1968 = and i8 %1967, 1
  %1969 = xor i8 %1968, 1
  store i8 %1969, i8* %52, align 1, !tbaa !2447
  %1970 = xor i32 %1958, %1959
  %1971 = lshr i32 %1970, 4
  %1972 = trunc i32 %1971 to i8
  %1973 = and i8 %1972, 1
  store i8 %1973, i8* %53, align 1, !tbaa !2451
  %1974 = zext i1 %1962 to i8
  store i8 %1974, i8* %54, align 1, !tbaa !2448
  %1975 = lshr i32 %1959, 31
  %1976 = trunc i32 %1975 to i8
  store i8 %1976, i8* %55, align 1, !tbaa !2449
  %1977 = lshr i32 %1958, 31
  %1978 = xor i32 %1975, %1977
  %1979 = add nuw nsw i32 %1978, %1975
  %1980 = icmp eq i32 %1979, 2
  %1981 = zext i1 %1980 to i8
  store i8 %1981, i8* %56, align 1, !tbaa !2450
  %1982 = sext i32 %1959 to i64
  store i64 %1982, i64* %RDX, align 8, !tbaa !2428
  %1983 = shl nsw i64 %1982, 3
  %1984 = add i64 %1983, %1954
  %1985 = add i64 %1947, 23
  store i64 %1985, i64* %PC, align 8
  %1986 = inttoptr i64 %1984 to i64*
  store i64 %1950, i64* %1986, align 8
  %1987 = load i64, i64* %RBP, align 8
  %1988 = add i64 %1987, -64
  %1989 = load i64, i64* %PC, align 8
  %1990 = add i64 %1989, 5
  store i64 %1990, i64* %PC, align 8
  %1991 = inttoptr i64 %1988 to i64*
  %1992 = load i64, i64* %1991, align 8
  store i64 %1992, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %1993 = add i64 %1987, -24
  %1994 = add i64 %1989, 9
  store i64 %1994, i64* %PC, align 8
  %1995 = inttoptr i64 %1993 to i64*
  %1996 = load i64, i64* %1995, align 8
  store i64 %1996, i64* %RCX, align 8, !tbaa !2428
  %1997 = add i64 %1987, -40
  %1998 = add i64 %1989, 13
  store i64 %1998, i64* %PC, align 8
  %1999 = inttoptr i64 %1997 to i32*
  %2000 = load i32, i32* %1999, align 4
  %2001 = sext i32 %2000 to i64
  store i64 %2001, i64* %RDX, align 8, !tbaa !2428
  %2002 = shl nsw i64 %2001, 3
  %2003 = add i64 %2002, %1996
  %2004 = add i64 %1989, 18
  store i64 %2004, i64* %PC, align 8
  %2005 = inttoptr i64 %2003 to i64*
  store i64 %1992, i64* %2005, align 8
  %2006 = load i64, i64* %RBP, align 8
  %2007 = add i64 %2006, -72
  %2008 = load i64, i64* %PC, align 8
  %2009 = add i64 %2008, 5
  store i64 %2009, i64* %PC, align 8
  %2010 = inttoptr i64 %2007 to i64*
  %2011 = load i64, i64* %2010, align 8
  store i64 %2011, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2012 = add i64 %2006, -24
  %2013 = add i64 %2008, 9
  store i64 %2013, i64* %PC, align 8
  %2014 = inttoptr i64 %2012 to i64*
  %2015 = load i64, i64* %2014, align 8
  store i64 %2015, i64* %RCX, align 8, !tbaa !2428
  %2016 = add i64 %2006, -40
  %2017 = add i64 %2008, 12
  store i64 %2017, i64* %PC, align 8
  %2018 = inttoptr i64 %2016 to i32*
  %2019 = load i32, i32* %2018, align 4
  %2020 = add i32 %2019, 1
  %2021 = zext i32 %2020 to i64
  store i64 %2021, i64* %RAX, align 8, !tbaa !2428
  %2022 = icmp eq i32 %2019, -1
  %2023 = icmp eq i32 %2020, 0
  %2024 = or i1 %2022, %2023
  %2025 = zext i1 %2024 to i8
  store i8 %2025, i8* %51, align 1, !tbaa !2433
  %2026 = and i32 %2020, 255
  %2027 = tail call i32 @llvm.ctpop.i32(i32 %2026) #10
  %2028 = trunc i32 %2027 to i8
  %2029 = and i8 %2028, 1
  %2030 = xor i8 %2029, 1
  store i8 %2030, i8* %52, align 1, !tbaa !2447
  %2031 = xor i32 %2019, %2020
  %2032 = lshr i32 %2031, 4
  %2033 = trunc i32 %2032 to i8
  %2034 = and i8 %2033, 1
  store i8 %2034, i8* %53, align 1, !tbaa !2451
  %2035 = zext i1 %2023 to i8
  store i8 %2035, i8* %54, align 1, !tbaa !2448
  %2036 = lshr i32 %2020, 31
  %2037 = trunc i32 %2036 to i8
  store i8 %2037, i8* %55, align 1, !tbaa !2449
  %2038 = lshr i32 %2019, 31
  %2039 = xor i32 %2036, %2038
  %2040 = add nuw nsw i32 %2039, %2036
  %2041 = icmp eq i32 %2040, 2
  %2042 = zext i1 %2041 to i8
  store i8 %2042, i8* %56, align 1, !tbaa !2450
  %2043 = sext i32 %2020 to i64
  store i64 %2043, i64* %RDX, align 8, !tbaa !2428
  %2044 = shl nsw i64 %2043, 3
  %2045 = add i64 %2044, %2015
  %2046 = add i64 %2008, 23
  store i64 %2046, i64* %PC, align 8
  %2047 = inttoptr i64 %2045 to i64*
  store i64 %2011, i64* %2047, align 8
  %2048 = load i64, i64* %RBP, align 8
  %2049 = add i64 %2048, -52
  %2050 = load i64, i64* %PC, align 8
  %2051 = add i64 %2050, 3
  store i64 %2051, i64* %PC, align 8
  %2052 = inttoptr i64 %2049 to i32*
  %2053 = load i32, i32* %2052, align 4
  %2054 = zext i32 %2053 to i64
  store i64 %2054, i64* %RAX, align 8, !tbaa !2428
  %2055 = add i64 %2048, -32
  %2056 = add i64 %2050, 6
  store i64 %2056, i64* %PC, align 8
  %2057 = inttoptr i64 %2055 to i32*
  %2058 = load i32, i32* %2057, align 4
  %2059 = add i32 %2058, %2053
  %2060 = zext i32 %2059 to i64
  store i64 %2060, i64* %RAX, align 8, !tbaa !2428
  %2061 = icmp ult i32 %2059, %2053
  %2062 = icmp ult i32 %2059, %2058
  %2063 = or i1 %2061, %2062
  %2064 = zext i1 %2063 to i8
  store i8 %2064, i8* %51, align 1, !tbaa !2433
  %2065 = and i32 %2059, 255
  %2066 = tail call i32 @llvm.ctpop.i32(i32 %2065) #10
  %2067 = trunc i32 %2066 to i8
  %2068 = and i8 %2067, 1
  %2069 = xor i8 %2068, 1
  store i8 %2069, i8* %52, align 1, !tbaa !2447
  %2070 = xor i32 %2058, %2053
  %2071 = xor i32 %2070, %2059
  %2072 = lshr i32 %2071, 4
  %2073 = trunc i32 %2072 to i8
  %2074 = and i8 %2073, 1
  store i8 %2074, i8* %53, align 1, !tbaa !2451
  %2075 = icmp eq i32 %2059, 0
  %2076 = zext i1 %2075 to i8
  store i8 %2076, i8* %54, align 1, !tbaa !2448
  %2077 = lshr i32 %2059, 31
  %2078 = trunc i32 %2077 to i8
  store i8 %2078, i8* %55, align 1, !tbaa !2449
  %2079 = lshr i32 %2053, 31
  %2080 = lshr i32 %2058, 31
  %2081 = xor i32 %2077, %2079
  %2082 = xor i32 %2077, %2080
  %2083 = add nuw nsw i32 %2081, %2082
  %2084 = icmp eq i32 %2083, 2
  %2085 = zext i1 %2084 to i8
  store i8 %2085, i8* %56, align 1, !tbaa !2450
  %2086 = add i64 %2050, 9
  store i64 %2086, i64* %PC, align 8
  store i32 %2059, i32* %2057, align 4
  %2087 = load i64, i64* %RBP, align 8
  %2088 = add i64 %2087, -52
  %2089 = load i64, i64* %PC, align 8
  %2090 = add i64 %2089, 3
  store i64 %2090, i64* %PC, align 8
  %2091 = inttoptr i64 %2088 to i32*
  %2092 = load i32, i32* %2091, align 4
  %2093 = shl i32 %2092, 1
  %2094 = icmp slt i32 %2092, 0
  %2095 = icmp slt i32 %2093, 0
  %2096 = xor i1 %2094, %2095
  %2097 = zext i32 %2093 to i64
  store i64 %2097, i64* %RAX, align 8, !tbaa !2428
  %.lobit17 = lshr i32 %2092, 31
  %2098 = trunc i32 %.lobit17 to i8
  store i8 %2098, i8* %51, align 1, !tbaa !2432
  %2099 = and i32 %2093, 254
  %2100 = tail call i32 @llvm.ctpop.i32(i32 %2099) #10
  %2101 = trunc i32 %2100 to i8
  %2102 = and i8 %2101, 1
  %2103 = xor i8 %2102, 1
  store i8 %2103, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %2104 = icmp eq i32 %2093, 0
  %2105 = zext i1 %2104 to i8
  store i8 %2105, i8* %54, align 1, !tbaa !2432
  %2106 = lshr i32 %2092, 30
  %2107 = and i32 %2106, 1
  %2108 = trunc i32 %2107 to i8
  store i8 %2108, i8* %55, align 1, !tbaa !2432
  %2109 = zext i1 %2096 to i8
  store i8 %2109, i8* %56, align 1, !tbaa !2432
  %2110 = add i64 %2087, -40
  %2111 = add i64 %2089, 9
  store i64 %2111, i64* %PC, align 8
  %2112 = inttoptr i64 %2110 to i32*
  %2113 = load i32, i32* %2112, align 4
  %2114 = add i32 %2113, %2093
  %2115 = zext i32 %2114 to i64
  store i64 %2115, i64* %RAX, align 8, !tbaa !2428
  %2116 = icmp ult i32 %2114, %2093
  %2117 = icmp ult i32 %2114, %2113
  %2118 = or i1 %2116, %2117
  %2119 = zext i1 %2118 to i8
  store i8 %2119, i8* %51, align 1, !tbaa !2433
  %2120 = and i32 %2114, 255
  %2121 = tail call i32 @llvm.ctpop.i32(i32 %2120) #10
  %2122 = trunc i32 %2121 to i8
  %2123 = and i8 %2122, 1
  %2124 = xor i8 %2123, 1
  store i8 %2124, i8* %52, align 1, !tbaa !2447
  %2125 = xor i32 %2113, %2093
  %2126 = xor i32 %2125, %2114
  %2127 = lshr i32 %2126, 4
  %2128 = trunc i32 %2127 to i8
  %2129 = and i8 %2128, 1
  store i8 %2129, i8* %53, align 1, !tbaa !2451
  %2130 = icmp eq i32 %2114, 0
  %2131 = zext i1 %2130 to i8
  store i8 %2131, i8* %54, align 1, !tbaa !2448
  %2132 = lshr i32 %2114, 31
  %2133 = trunc i32 %2132 to i8
  store i8 %2133, i8* %55, align 1, !tbaa !2449
  %2134 = lshr i32 %2113, 31
  %2135 = xor i32 %2132, %2107
  %2136 = xor i32 %2132, %2134
  %2137 = add nuw nsw i32 %2135, %2136
  %2138 = icmp eq i32 %2137, 2
  %2139 = zext i1 %2138 to i8
  store i8 %2139, i8* %56, align 1, !tbaa !2450
  %2140 = add i64 %2089, 12
  store i64 %2140, i64* %PC, align 8
  store i32 %2114, i32* %2112, align 4
  %2141 = load i64, i64* %RBP, align 8
  %2142 = add i64 %2141, -24
  %2143 = load i64, i64* %PC, align 8
  %2144 = add i64 %2143, 4
  store i64 %2144, i64* %PC, align 8
  %2145 = inttoptr i64 %2142 to i64*
  %2146 = load i64, i64* %2145, align 8
  store i64 %2146, i64* %RCX, align 8, !tbaa !2428
  %2147 = add i64 %2141, -32
  %2148 = add i64 %2143, 8
  store i64 %2148, i64* %PC, align 8
  %2149 = inttoptr i64 %2147 to i32*
  %2150 = load i32, i32* %2149, align 4
  %2151 = sext i32 %2150 to i64
  store i64 %2151, i64* %RDX, align 8, !tbaa !2428
  %2152 = shl nsw i64 %2151, 3
  %2153 = add i64 %2152, %2146
  %2154 = add i64 %2143, 13
  store i64 %2154, i64* %PC, align 8
  %2155 = inttoptr i64 %2153 to i64*
  %2156 = load i64, i64* %2155, align 8
  store i64 %2156, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2157 = add i64 %2141, -64
  %2158 = add i64 %2143, 18
  store i64 %2158, i64* %PC, align 8
  %2159 = inttoptr i64 %2157 to i64*
  store i64 %2156, i64* %2159, align 8
  %2160 = load i64, i64* %RBP, align 8
  %2161 = add i64 %2160, -24
  %2162 = load i64, i64* %PC, align 8
  %2163 = add i64 %2162, 4
  store i64 %2163, i64* %PC, align 8
  %2164 = inttoptr i64 %2161 to i64*
  %2165 = load i64, i64* %2164, align 8
  store i64 %2165, i64* %RCX, align 8, !tbaa !2428
  %2166 = add i64 %2160, -32
  %2167 = add i64 %2162, 7
  store i64 %2167, i64* %PC, align 8
  %2168 = inttoptr i64 %2166 to i32*
  %2169 = load i32, i32* %2168, align 4
  %2170 = add i32 %2169, 1
  %2171 = zext i32 %2170 to i64
  store i64 %2171, i64* %RAX, align 8, !tbaa !2428
  %2172 = icmp eq i32 %2169, -1
  %2173 = icmp eq i32 %2170, 0
  %2174 = or i1 %2172, %2173
  %2175 = zext i1 %2174 to i8
  store i8 %2175, i8* %51, align 1, !tbaa !2433
  %2176 = and i32 %2170, 255
  %2177 = tail call i32 @llvm.ctpop.i32(i32 %2176) #10
  %2178 = trunc i32 %2177 to i8
  %2179 = and i8 %2178, 1
  %2180 = xor i8 %2179, 1
  store i8 %2180, i8* %52, align 1, !tbaa !2447
  %2181 = xor i32 %2169, %2170
  %2182 = lshr i32 %2181, 4
  %2183 = trunc i32 %2182 to i8
  %2184 = and i8 %2183, 1
  store i8 %2184, i8* %53, align 1, !tbaa !2451
  %2185 = zext i1 %2173 to i8
  store i8 %2185, i8* %54, align 1, !tbaa !2448
  %2186 = lshr i32 %2170, 31
  %2187 = trunc i32 %2186 to i8
  store i8 %2187, i8* %55, align 1, !tbaa !2449
  %2188 = lshr i32 %2169, 31
  %2189 = xor i32 %2186, %2188
  %2190 = add nuw nsw i32 %2189, %2186
  %2191 = icmp eq i32 %2190, 2
  %2192 = zext i1 %2191 to i8
  store i8 %2192, i8* %56, align 1, !tbaa !2450
  %2193 = sext i32 %2170 to i64
  store i64 %2193, i64* %RDX, align 8, !tbaa !2428
  %2194 = shl nsw i64 %2193, 3
  %2195 = add i64 %2194, %2165
  %2196 = add i64 %2162, 18
  store i64 %2196, i64* %PC, align 8
  %2197 = inttoptr i64 %2195 to i64*
  %2198 = load i64, i64* %2197, align 8
  store i64 %2198, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2199 = add i64 %2160, -72
  %2200 = add i64 %2162, 23
  store i64 %2200, i64* %PC, align 8
  %2201 = inttoptr i64 %2199 to i64*
  store i64 %2198, i64* %2201, align 8
  %2202 = load i64, i64* %RBP, align 8
  %2203 = add i64 %2202, -24
  %2204 = load i64, i64* %PC, align 8
  %2205 = add i64 %2204, 4
  store i64 %2205, i64* %PC, align 8
  %2206 = inttoptr i64 %2203 to i64*
  %2207 = load i64, i64* %2206, align 8
  store i64 %2207, i64* %RCX, align 8, !tbaa !2428
  %2208 = add i64 %2202, -40
  %2209 = add i64 %2204, 8
  store i64 %2209, i64* %PC, align 8
  %2210 = inttoptr i64 %2208 to i32*
  %2211 = load i32, i32* %2210, align 4
  %2212 = sext i32 %2211 to i64
  store i64 %2212, i64* %RDX, align 8, !tbaa !2428
  %2213 = shl nsw i64 %2212, 3
  %2214 = add i64 %2213, %2207
  %2215 = add i64 %2204, 13
  store i64 %2215, i64* %PC, align 8
  %2216 = inttoptr i64 %2214 to i64*
  %2217 = load i64, i64* %2216, align 8
  store i64 %2217, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2218 = add i64 %2202, -80
  %2219 = add i64 %2204, 18
  store i64 %2219, i64* %PC, align 8
  %2220 = inttoptr i64 %2218 to i64*
  store i64 %2217, i64* %2220, align 8
  %2221 = load i64, i64* %RBP, align 8
  %2222 = add i64 %2221, -24
  %2223 = load i64, i64* %PC, align 8
  %2224 = add i64 %2223, 4
  store i64 %2224, i64* %PC, align 8
  %2225 = inttoptr i64 %2222 to i64*
  %2226 = load i64, i64* %2225, align 8
  store i64 %2226, i64* %RCX, align 8, !tbaa !2428
  %2227 = add i64 %2221, -40
  %2228 = add i64 %2223, 7
  store i64 %2228, i64* %PC, align 8
  %2229 = inttoptr i64 %2227 to i32*
  %2230 = load i32, i32* %2229, align 4
  %2231 = add i32 %2230, 1
  %2232 = zext i32 %2231 to i64
  store i64 %2232, i64* %RAX, align 8, !tbaa !2428
  %2233 = icmp eq i32 %2230, -1
  %2234 = icmp eq i32 %2231, 0
  %2235 = or i1 %2233, %2234
  %2236 = zext i1 %2235 to i8
  store i8 %2236, i8* %51, align 1, !tbaa !2433
  %2237 = and i32 %2231, 255
  %2238 = tail call i32 @llvm.ctpop.i32(i32 %2237) #10
  %2239 = trunc i32 %2238 to i8
  %2240 = and i8 %2239, 1
  %2241 = xor i8 %2240, 1
  store i8 %2241, i8* %52, align 1, !tbaa !2447
  %2242 = xor i32 %2230, %2231
  %2243 = lshr i32 %2242, 4
  %2244 = trunc i32 %2243 to i8
  %2245 = and i8 %2244, 1
  store i8 %2245, i8* %53, align 1, !tbaa !2451
  %2246 = zext i1 %2234 to i8
  store i8 %2246, i8* %54, align 1, !tbaa !2448
  %2247 = lshr i32 %2231, 31
  %2248 = trunc i32 %2247 to i8
  store i8 %2248, i8* %55, align 1, !tbaa !2449
  %2249 = lshr i32 %2230, 31
  %2250 = xor i32 %2247, %2249
  %2251 = add nuw nsw i32 %2250, %2247
  %2252 = icmp eq i32 %2251, 2
  %2253 = zext i1 %2252 to i8
  store i8 %2253, i8* %56, align 1, !tbaa !2450
  %2254 = sext i32 %2231 to i64
  store i64 %2254, i64* %RDX, align 8, !tbaa !2428
  %2255 = shl nsw i64 %2254, 3
  %2256 = add i64 %2255, %2226
  %2257 = add i64 %2223, 18
  store i64 %2257, i64* %PC, align 8
  %2258 = inttoptr i64 %2256 to i64*
  %2259 = load i64, i64* %2258, align 8
  store i64 %2259, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2260 = add i64 %2221, -88
  %2261 = add i64 %2223, 23
  store i64 %2261, i64* %PC, align 8
  %2262 = inttoptr i64 %2260 to i64*
  store i64 %2259, i64* %2262, align 8
  %2263 = load i64, i64* %RBP, align 8
  %2264 = add i64 %2263, -80
  %2265 = load i64, i64* %PC, align 8
  %2266 = add i64 %2265, 5
  store i64 %2266, i64* %PC, align 8
  %2267 = inttoptr i64 %2264 to i64*
  %2268 = load i64, i64* %2267, align 8
  store i64 %2268, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2269 = add i64 %2263, -24
  %2270 = add i64 %2265, 9
  store i64 %2270, i64* %PC, align 8
  %2271 = inttoptr i64 %2269 to i64*
  %2272 = load i64, i64* %2271, align 8
  store i64 %2272, i64* %RCX, align 8, !tbaa !2428
  %2273 = add i64 %2263, -32
  %2274 = add i64 %2265, 13
  store i64 %2274, i64* %PC, align 8
  %2275 = inttoptr i64 %2273 to i32*
  %2276 = load i32, i32* %2275, align 4
  %2277 = sext i32 %2276 to i64
  store i64 %2277, i64* %RDX, align 8, !tbaa !2428
  %2278 = shl nsw i64 %2277, 3
  %2279 = add i64 %2278, %2272
  %2280 = add i64 %2265, 18
  store i64 %2280, i64* %PC, align 8
  %2281 = inttoptr i64 %2279 to i64*
  store i64 %2268, i64* %2281, align 8
  %2282 = load i64, i64* %RBP, align 8
  %2283 = add i64 %2282, -88
  %2284 = load i64, i64* %PC, align 8
  %2285 = add i64 %2284, 5
  store i64 %2285, i64* %PC, align 8
  %2286 = inttoptr i64 %2283 to i64*
  %2287 = load i64, i64* %2286, align 8
  store i64 %2287, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2288 = add i64 %2282, -24
  %2289 = add i64 %2284, 9
  store i64 %2289, i64* %PC, align 8
  %2290 = inttoptr i64 %2288 to i64*
  %2291 = load i64, i64* %2290, align 8
  store i64 %2291, i64* %RCX, align 8, !tbaa !2428
  %2292 = add i64 %2282, -32
  %2293 = add i64 %2284, 12
  store i64 %2293, i64* %PC, align 8
  %2294 = inttoptr i64 %2292 to i32*
  %2295 = load i32, i32* %2294, align 4
  %2296 = add i32 %2295, 1
  %2297 = zext i32 %2296 to i64
  store i64 %2297, i64* %RAX, align 8, !tbaa !2428
  %2298 = icmp eq i32 %2295, -1
  %2299 = icmp eq i32 %2296, 0
  %2300 = or i1 %2298, %2299
  %2301 = zext i1 %2300 to i8
  store i8 %2301, i8* %51, align 1, !tbaa !2433
  %2302 = and i32 %2296, 255
  %2303 = tail call i32 @llvm.ctpop.i32(i32 %2302) #10
  %2304 = trunc i32 %2303 to i8
  %2305 = and i8 %2304, 1
  %2306 = xor i8 %2305, 1
  store i8 %2306, i8* %52, align 1, !tbaa !2447
  %2307 = xor i32 %2295, %2296
  %2308 = lshr i32 %2307, 4
  %2309 = trunc i32 %2308 to i8
  %2310 = and i8 %2309, 1
  store i8 %2310, i8* %53, align 1, !tbaa !2451
  %2311 = zext i1 %2299 to i8
  store i8 %2311, i8* %54, align 1, !tbaa !2448
  %2312 = lshr i32 %2296, 31
  %2313 = trunc i32 %2312 to i8
  store i8 %2313, i8* %55, align 1, !tbaa !2449
  %2314 = lshr i32 %2295, 31
  %2315 = xor i32 %2312, %2314
  %2316 = add nuw nsw i32 %2315, %2312
  %2317 = icmp eq i32 %2316, 2
  %2318 = zext i1 %2317 to i8
  store i8 %2318, i8* %56, align 1, !tbaa !2450
  %2319 = sext i32 %2296 to i64
  store i64 %2319, i64* %RDX, align 8, !tbaa !2428
  %2320 = shl nsw i64 %2319, 3
  %2321 = add i64 %2320, %2291
  %2322 = add i64 %2284, 23
  store i64 %2322, i64* %PC, align 8
  %2323 = inttoptr i64 %2321 to i64*
  store i64 %2287, i64* %2323, align 8
  %2324 = load i64, i64* %RBP, align 8
  %2325 = add i64 %2324, -64
  %2326 = load i64, i64* %PC, align 8
  %2327 = add i64 %2326, 5
  store i64 %2327, i64* %PC, align 8
  %2328 = inttoptr i64 %2325 to i64*
  %2329 = load i64, i64* %2328, align 8
  store i64 %2329, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2330 = add i64 %2324, -24
  %2331 = add i64 %2326, 9
  store i64 %2331, i64* %PC, align 8
  %2332 = inttoptr i64 %2330 to i64*
  %2333 = load i64, i64* %2332, align 8
  store i64 %2333, i64* %RCX, align 8, !tbaa !2428
  %2334 = add i64 %2324, -40
  %2335 = add i64 %2326, 13
  store i64 %2335, i64* %PC, align 8
  %2336 = inttoptr i64 %2334 to i32*
  %2337 = load i32, i32* %2336, align 4
  %2338 = sext i32 %2337 to i64
  store i64 %2338, i64* %RDX, align 8, !tbaa !2428
  %2339 = shl nsw i64 %2338, 3
  %2340 = add i64 %2339, %2333
  %2341 = add i64 %2326, 18
  store i64 %2341, i64* %PC, align 8
  %2342 = inttoptr i64 %2340 to i64*
  store i64 %2329, i64* %2342, align 8
  %2343 = load i64, i64* %RBP, align 8
  %2344 = add i64 %2343, -72
  %2345 = load i64, i64* %PC, align 8
  %2346 = add i64 %2345, 5
  store i64 %2346, i64* %PC, align 8
  %2347 = inttoptr i64 %2344 to i64*
  %2348 = load i64, i64* %2347, align 8
  store i64 %2348, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2349 = add i64 %2343, -24
  %2350 = add i64 %2345, 9
  store i64 %2350, i64* %PC, align 8
  %2351 = inttoptr i64 %2349 to i64*
  %2352 = load i64, i64* %2351, align 8
  store i64 %2352, i64* %RCX, align 8, !tbaa !2428
  %2353 = add i64 %2343, -40
  %2354 = add i64 %2345, 12
  store i64 %2354, i64* %PC, align 8
  %2355 = inttoptr i64 %2353 to i32*
  %2356 = load i32, i32* %2355, align 4
  %2357 = add i32 %2356, 1
  %2358 = zext i32 %2357 to i64
  store i64 %2358, i64* %RAX, align 8, !tbaa !2428
  %2359 = icmp eq i32 %2356, -1
  %2360 = icmp eq i32 %2357, 0
  %2361 = or i1 %2359, %2360
  %2362 = zext i1 %2361 to i8
  store i8 %2362, i8* %51, align 1, !tbaa !2433
  %2363 = and i32 %2357, 255
  %2364 = tail call i32 @llvm.ctpop.i32(i32 %2363) #10
  %2365 = trunc i32 %2364 to i8
  %2366 = and i8 %2365, 1
  %2367 = xor i8 %2366, 1
  store i8 %2367, i8* %52, align 1, !tbaa !2447
  %2368 = xor i32 %2356, %2357
  %2369 = lshr i32 %2368, 4
  %2370 = trunc i32 %2369 to i8
  %2371 = and i8 %2370, 1
  store i8 %2371, i8* %53, align 1, !tbaa !2451
  %2372 = zext i1 %2360 to i8
  store i8 %2372, i8* %54, align 1, !tbaa !2448
  %2373 = lshr i32 %2357, 31
  %2374 = trunc i32 %2373 to i8
  store i8 %2374, i8* %55, align 1, !tbaa !2449
  %2375 = lshr i32 %2356, 31
  %2376 = xor i32 %2373, %2375
  %2377 = add nuw nsw i32 %2376, %2373
  %2378 = icmp eq i32 %2377, 2
  %2379 = zext i1 %2378 to i8
  store i8 %2379, i8* %56, align 1, !tbaa !2450
  %2380 = sext i32 %2357 to i64
  store i64 %2380, i64* %RDX, align 8, !tbaa !2428
  %2381 = shl nsw i64 %2380, 3
  %2382 = add i64 %2381, %2352
  %2383 = add i64 %2345, 23
  store i64 %2383, i64* %PC, align 8
  %2384 = inttoptr i64 %2382 to i64*
  store i64 %2348, i64* %2384, align 8
  %2385 = load i64, i64* %RBP, align 8
  %2386 = add i64 %2385, -52
  %2387 = load i64, i64* %PC, align 8
  %2388 = add i64 %2387, 3
  store i64 %2388, i64* %PC, align 8
  %2389 = inttoptr i64 %2386 to i32*
  %2390 = load i32, i32* %2389, align 4
  %2391 = zext i32 %2390 to i64
  store i64 %2391, i64* %RAX, align 8, !tbaa !2428
  %2392 = add i64 %2385, -32
  %2393 = add i64 %2387, 6
  store i64 %2393, i64* %PC, align 8
  %2394 = inttoptr i64 %2392 to i32*
  %2395 = load i32, i32* %2394, align 4
  %2396 = add i32 %2395, %2390
  %2397 = zext i32 %2396 to i64
  store i64 %2397, i64* %RAX, align 8, !tbaa !2428
  %2398 = icmp ult i32 %2396, %2390
  %2399 = icmp ult i32 %2396, %2395
  %2400 = or i1 %2398, %2399
  %2401 = zext i1 %2400 to i8
  store i8 %2401, i8* %51, align 1, !tbaa !2433
  %2402 = and i32 %2396, 255
  %2403 = tail call i32 @llvm.ctpop.i32(i32 %2402) #10
  %2404 = trunc i32 %2403 to i8
  %2405 = and i8 %2404, 1
  %2406 = xor i8 %2405, 1
  store i8 %2406, i8* %52, align 1, !tbaa !2447
  %2407 = xor i32 %2395, %2390
  %2408 = xor i32 %2407, %2396
  %2409 = lshr i32 %2408, 4
  %2410 = trunc i32 %2409 to i8
  %2411 = and i8 %2410, 1
  store i8 %2411, i8* %53, align 1, !tbaa !2451
  %2412 = icmp eq i32 %2396, 0
  %2413 = zext i1 %2412 to i8
  store i8 %2413, i8* %54, align 1, !tbaa !2448
  %2414 = lshr i32 %2396, 31
  %2415 = trunc i32 %2414 to i8
  store i8 %2415, i8* %55, align 1, !tbaa !2449
  %2416 = lshr i32 %2390, 31
  %2417 = lshr i32 %2395, 31
  %2418 = xor i32 %2414, %2416
  %2419 = xor i32 %2414, %2417
  %2420 = add nuw nsw i32 %2418, %2419
  %2421 = icmp eq i32 %2420, 2
  %2422 = zext i1 %2421 to i8
  store i8 %2422, i8* %56, align 1, !tbaa !2450
  %2423 = add i64 %2387, 9
  store i64 %2423, i64* %PC, align 8
  store i32 %2396, i32* %2394, align 4
  %2424 = load i64, i64* %RBP, align 8
  %2425 = add i64 %2424, -52
  %2426 = load i64, i64* %PC, align 8
  %2427 = add i64 %2426, 3
  store i64 %2427, i64* %PC, align 8
  %2428 = inttoptr i64 %2425 to i32*
  %2429 = load i32, i32* %2428, align 4
  %2430 = zext i32 %2429 to i64
  store i64 %2430, i64* %RAX, align 8, !tbaa !2428
  %2431 = add i64 %2424, -40
  %2432 = add i64 %2426, 6
  store i64 %2432, i64* %PC, align 8
  %2433 = inttoptr i64 %2431 to i32*
  %2434 = load i32, i32* %2433, align 4
  %2435 = sub i32 %2434, %2429
  %2436 = zext i32 %2435 to i64
  store i64 %2436, i64* %RSI, align 8, !tbaa !2428
  %2437 = icmp ult i32 %2434, %2429
  %2438 = zext i1 %2437 to i8
  store i8 %2438, i8* %51, align 1, !tbaa !2433
  %2439 = and i32 %2435, 255
  %2440 = tail call i32 @llvm.ctpop.i32(i32 %2439) #10
  %2441 = trunc i32 %2440 to i8
  %2442 = and i8 %2441, 1
  %2443 = xor i8 %2442, 1
  store i8 %2443, i8* %52, align 1, !tbaa !2447
  %2444 = xor i32 %2429, %2434
  %2445 = xor i32 %2444, %2435
  %2446 = lshr i32 %2445, 4
  %2447 = trunc i32 %2446 to i8
  %2448 = and i8 %2447, 1
  store i8 %2448, i8* %53, align 1, !tbaa !2451
  %2449 = icmp eq i32 %2435, 0
  %2450 = zext i1 %2449 to i8
  store i8 %2450, i8* %54, align 1, !tbaa !2448
  %2451 = lshr i32 %2435, 31
  %2452 = trunc i32 %2451 to i8
  store i8 %2452, i8* %55, align 1, !tbaa !2449
  %2453 = lshr i32 %2434, 31
  %2454 = lshr i32 %2429, 31
  %2455 = xor i32 %2454, %2453
  %2456 = xor i32 %2451, %2453
  %2457 = add nuw nsw i32 %2456, %2455
  %2458 = icmp eq i32 %2457, 2
  %2459 = zext i1 %2458 to i8
  store i8 %2459, i8* %56, align 1, !tbaa !2450
  %2460 = add i64 %2426, 11
  store i64 %2460, i64* %PC, align 8
  store i32 %2435, i32* %2433, align 4
  %2461 = load i64, i64* %RBP, align 8
  %2462 = add i64 %2461, -24
  %2463 = load i64, i64* %PC, align 8
  %2464 = add i64 %2463, 4
  store i64 %2464, i64* %PC, align 8
  %2465 = inttoptr i64 %2462 to i64*
  %2466 = load i64, i64* %2465, align 8
  store i64 %2466, i64* %RCX, align 8, !tbaa !2428
  %2467 = add i64 %2461, -32
  %2468 = add i64 %2463, 8
  store i64 %2468, i64* %PC, align 8
  %2469 = inttoptr i64 %2467 to i32*
  %2470 = load i32, i32* %2469, align 4
  %2471 = sext i32 %2470 to i64
  store i64 %2471, i64* %RDX, align 8, !tbaa !2428
  %2472 = shl nsw i64 %2471, 3
  %2473 = add i64 %2472, %2466
  %2474 = add i64 %2463, 13
  store i64 %2474, i64* %PC, align 8
  %2475 = inttoptr i64 %2473 to i64*
  %2476 = load i64, i64* %2475, align 8
  store i64 %2476, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2477 = add i64 %2461, -64
  %2478 = add i64 %2463, 18
  store i64 %2478, i64* %PC, align 8
  %2479 = inttoptr i64 %2477 to i64*
  store i64 %2476, i64* %2479, align 8
  %2480 = load i64, i64* %RBP, align 8
  %2481 = add i64 %2480, -24
  %2482 = load i64, i64* %PC, align 8
  %2483 = add i64 %2482, 4
  store i64 %2483, i64* %PC, align 8
  %2484 = inttoptr i64 %2481 to i64*
  %2485 = load i64, i64* %2484, align 8
  store i64 %2485, i64* %RCX, align 8, !tbaa !2428
  %2486 = add i64 %2480, -32
  %2487 = add i64 %2482, 7
  store i64 %2487, i64* %PC, align 8
  %2488 = inttoptr i64 %2486 to i32*
  %2489 = load i32, i32* %2488, align 4
  %2490 = add i32 %2489, 1
  %2491 = zext i32 %2490 to i64
  store i64 %2491, i64* %RAX, align 8, !tbaa !2428
  %2492 = icmp eq i32 %2489, -1
  %2493 = icmp eq i32 %2490, 0
  %2494 = or i1 %2492, %2493
  %2495 = zext i1 %2494 to i8
  store i8 %2495, i8* %51, align 1, !tbaa !2433
  %2496 = and i32 %2490, 255
  %2497 = tail call i32 @llvm.ctpop.i32(i32 %2496) #10
  %2498 = trunc i32 %2497 to i8
  %2499 = and i8 %2498, 1
  %2500 = xor i8 %2499, 1
  store i8 %2500, i8* %52, align 1, !tbaa !2447
  %2501 = xor i32 %2489, %2490
  %2502 = lshr i32 %2501, 4
  %2503 = trunc i32 %2502 to i8
  %2504 = and i8 %2503, 1
  store i8 %2504, i8* %53, align 1, !tbaa !2451
  %2505 = zext i1 %2493 to i8
  store i8 %2505, i8* %54, align 1, !tbaa !2448
  %2506 = lshr i32 %2490, 31
  %2507 = trunc i32 %2506 to i8
  store i8 %2507, i8* %55, align 1, !tbaa !2449
  %2508 = lshr i32 %2489, 31
  %2509 = xor i32 %2506, %2508
  %2510 = add nuw nsw i32 %2509, %2506
  %2511 = icmp eq i32 %2510, 2
  %2512 = zext i1 %2511 to i8
  store i8 %2512, i8* %56, align 1, !tbaa !2450
  %2513 = sext i32 %2490 to i64
  store i64 %2513, i64* %RDX, align 8, !tbaa !2428
  %2514 = shl nsw i64 %2513, 3
  %2515 = add i64 %2514, %2485
  %2516 = add i64 %2482, 18
  store i64 %2516, i64* %PC, align 8
  %2517 = inttoptr i64 %2515 to i64*
  %2518 = load i64, i64* %2517, align 8
  store i64 %2518, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2519 = add i64 %2480, -72
  %2520 = add i64 %2482, 23
  store i64 %2520, i64* %PC, align 8
  %2521 = inttoptr i64 %2519 to i64*
  store i64 %2518, i64* %2521, align 8
  %2522 = load i64, i64* %RBP, align 8
  %2523 = add i64 %2522, -24
  %2524 = load i64, i64* %PC, align 8
  %2525 = add i64 %2524, 4
  store i64 %2525, i64* %PC, align 8
  %2526 = inttoptr i64 %2523 to i64*
  %2527 = load i64, i64* %2526, align 8
  store i64 %2527, i64* %RCX, align 8, !tbaa !2428
  %2528 = add i64 %2522, -40
  %2529 = add i64 %2524, 8
  store i64 %2529, i64* %PC, align 8
  %2530 = inttoptr i64 %2528 to i32*
  %2531 = load i32, i32* %2530, align 4
  %2532 = sext i32 %2531 to i64
  store i64 %2532, i64* %RDX, align 8, !tbaa !2428
  %2533 = shl nsw i64 %2532, 3
  %2534 = add i64 %2533, %2527
  %2535 = add i64 %2524, 13
  store i64 %2535, i64* %PC, align 8
  %2536 = inttoptr i64 %2534 to i64*
  %2537 = load i64, i64* %2536, align 8
  store i64 %2537, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2538 = add i64 %2522, -80
  %2539 = add i64 %2524, 18
  store i64 %2539, i64* %PC, align 8
  %2540 = inttoptr i64 %2538 to i64*
  store i64 %2537, i64* %2540, align 8
  %2541 = load i64, i64* %RBP, align 8
  %2542 = add i64 %2541, -24
  %2543 = load i64, i64* %PC, align 8
  %2544 = add i64 %2543, 4
  store i64 %2544, i64* %PC, align 8
  %2545 = inttoptr i64 %2542 to i64*
  %2546 = load i64, i64* %2545, align 8
  store i64 %2546, i64* %RCX, align 8, !tbaa !2428
  %2547 = add i64 %2541, -40
  %2548 = add i64 %2543, 7
  store i64 %2548, i64* %PC, align 8
  %2549 = inttoptr i64 %2547 to i32*
  %2550 = load i32, i32* %2549, align 4
  %2551 = add i32 %2550, 1
  %2552 = zext i32 %2551 to i64
  store i64 %2552, i64* %RAX, align 8, !tbaa !2428
  %2553 = icmp eq i32 %2550, -1
  %2554 = icmp eq i32 %2551, 0
  %2555 = or i1 %2553, %2554
  %2556 = zext i1 %2555 to i8
  store i8 %2556, i8* %51, align 1, !tbaa !2433
  %2557 = and i32 %2551, 255
  %2558 = tail call i32 @llvm.ctpop.i32(i32 %2557) #10
  %2559 = trunc i32 %2558 to i8
  %2560 = and i8 %2559, 1
  %2561 = xor i8 %2560, 1
  store i8 %2561, i8* %52, align 1, !tbaa !2447
  %2562 = xor i32 %2550, %2551
  %2563 = lshr i32 %2562, 4
  %2564 = trunc i32 %2563 to i8
  %2565 = and i8 %2564, 1
  store i8 %2565, i8* %53, align 1, !tbaa !2451
  %2566 = zext i1 %2554 to i8
  store i8 %2566, i8* %54, align 1, !tbaa !2448
  %2567 = lshr i32 %2551, 31
  %2568 = trunc i32 %2567 to i8
  store i8 %2568, i8* %55, align 1, !tbaa !2449
  %2569 = lshr i32 %2550, 31
  %2570 = xor i32 %2567, %2569
  %2571 = add nuw nsw i32 %2570, %2567
  %2572 = icmp eq i32 %2571, 2
  %2573 = zext i1 %2572 to i8
  store i8 %2573, i8* %56, align 1, !tbaa !2450
  %2574 = sext i32 %2551 to i64
  store i64 %2574, i64* %RDX, align 8, !tbaa !2428
  %2575 = shl nsw i64 %2574, 3
  %2576 = add i64 %2575, %2546
  %2577 = add i64 %2543, 18
  store i64 %2577, i64* %PC, align 8
  %2578 = inttoptr i64 %2576 to i64*
  %2579 = load i64, i64* %2578, align 8
  store i64 %2579, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2580 = add i64 %2541, -88
  %2581 = add i64 %2543, 23
  store i64 %2581, i64* %PC, align 8
  %2582 = inttoptr i64 %2580 to i64*
  store i64 %2579, i64* %2582, align 8
  %2583 = load i64, i64* %RBP, align 8
  %2584 = add i64 %2583, -80
  %2585 = load i64, i64* %PC, align 8
  %2586 = add i64 %2585, 5
  store i64 %2586, i64* %PC, align 8
  %2587 = inttoptr i64 %2584 to i64*
  %2588 = load i64, i64* %2587, align 8
  store i64 %2588, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2589 = add i64 %2583, -24
  %2590 = add i64 %2585, 9
  store i64 %2590, i64* %PC, align 8
  %2591 = inttoptr i64 %2589 to i64*
  %2592 = load i64, i64* %2591, align 8
  store i64 %2592, i64* %RCX, align 8, !tbaa !2428
  %2593 = add i64 %2583, -32
  %2594 = add i64 %2585, 13
  store i64 %2594, i64* %PC, align 8
  %2595 = inttoptr i64 %2593 to i32*
  %2596 = load i32, i32* %2595, align 4
  %2597 = sext i32 %2596 to i64
  store i64 %2597, i64* %RDX, align 8, !tbaa !2428
  %2598 = shl nsw i64 %2597, 3
  %2599 = add i64 %2598, %2592
  %2600 = add i64 %2585, 18
  store i64 %2600, i64* %PC, align 8
  %2601 = inttoptr i64 %2599 to i64*
  store i64 %2588, i64* %2601, align 8
  %2602 = load i64, i64* %RBP, align 8
  %2603 = add i64 %2602, -88
  %2604 = load i64, i64* %PC, align 8
  %2605 = add i64 %2604, 5
  store i64 %2605, i64* %PC, align 8
  %2606 = inttoptr i64 %2603 to i64*
  %2607 = load i64, i64* %2606, align 8
  store i64 %2607, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2608 = add i64 %2602, -24
  %2609 = add i64 %2604, 9
  store i64 %2609, i64* %PC, align 8
  %2610 = inttoptr i64 %2608 to i64*
  %2611 = load i64, i64* %2610, align 8
  store i64 %2611, i64* %RCX, align 8, !tbaa !2428
  %2612 = add i64 %2602, -32
  %2613 = add i64 %2604, 12
  store i64 %2613, i64* %PC, align 8
  %2614 = inttoptr i64 %2612 to i32*
  %2615 = load i32, i32* %2614, align 4
  %2616 = add i32 %2615, 1
  %2617 = zext i32 %2616 to i64
  store i64 %2617, i64* %RAX, align 8, !tbaa !2428
  %2618 = icmp eq i32 %2615, -1
  %2619 = icmp eq i32 %2616, 0
  %2620 = or i1 %2618, %2619
  %2621 = zext i1 %2620 to i8
  store i8 %2621, i8* %51, align 1, !tbaa !2433
  %2622 = and i32 %2616, 255
  %2623 = tail call i32 @llvm.ctpop.i32(i32 %2622) #10
  %2624 = trunc i32 %2623 to i8
  %2625 = and i8 %2624, 1
  %2626 = xor i8 %2625, 1
  store i8 %2626, i8* %52, align 1, !tbaa !2447
  %2627 = xor i32 %2615, %2616
  %2628 = lshr i32 %2627, 4
  %2629 = trunc i32 %2628 to i8
  %2630 = and i8 %2629, 1
  store i8 %2630, i8* %53, align 1, !tbaa !2451
  %2631 = zext i1 %2619 to i8
  store i8 %2631, i8* %54, align 1, !tbaa !2448
  %2632 = lshr i32 %2616, 31
  %2633 = trunc i32 %2632 to i8
  store i8 %2633, i8* %55, align 1, !tbaa !2449
  %2634 = lshr i32 %2615, 31
  %2635 = xor i32 %2632, %2634
  %2636 = add nuw nsw i32 %2635, %2632
  %2637 = icmp eq i32 %2636, 2
  %2638 = zext i1 %2637 to i8
  store i8 %2638, i8* %56, align 1, !tbaa !2450
  %2639 = sext i32 %2616 to i64
  store i64 %2639, i64* %RDX, align 8, !tbaa !2428
  %2640 = shl nsw i64 %2639, 3
  %2641 = add i64 %2640, %2611
  %2642 = add i64 %2604, 23
  store i64 %2642, i64* %PC, align 8
  %2643 = inttoptr i64 %2641 to i64*
  store i64 %2607, i64* %2643, align 8
  %2644 = load i64, i64* %RBP, align 8
  %2645 = add i64 %2644, -64
  %2646 = load i64, i64* %PC, align 8
  %2647 = add i64 %2646, 5
  store i64 %2647, i64* %PC, align 8
  %2648 = inttoptr i64 %2645 to i64*
  %2649 = load i64, i64* %2648, align 8
  store i64 %2649, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2650 = add i64 %2644, -24
  %2651 = add i64 %2646, 9
  store i64 %2651, i64* %PC, align 8
  %2652 = inttoptr i64 %2650 to i64*
  %2653 = load i64, i64* %2652, align 8
  store i64 %2653, i64* %RCX, align 8, !tbaa !2428
  %2654 = add i64 %2644, -40
  %2655 = add i64 %2646, 13
  store i64 %2655, i64* %PC, align 8
  %2656 = inttoptr i64 %2654 to i32*
  %2657 = load i32, i32* %2656, align 4
  %2658 = sext i32 %2657 to i64
  store i64 %2658, i64* %RDX, align 8, !tbaa !2428
  %2659 = shl nsw i64 %2658, 3
  %2660 = add i64 %2659, %2653
  %2661 = add i64 %2646, 18
  store i64 %2661, i64* %PC, align 8
  %2662 = inttoptr i64 %2660 to i64*
  store i64 %2649, i64* %2662, align 8
  %2663 = load i64, i64* %RBP, align 8
  %2664 = add i64 %2663, -72
  %2665 = load i64, i64* %PC, align 8
  %2666 = add i64 %2665, 5
  store i64 %2666, i64* %PC, align 8
  %2667 = inttoptr i64 %2664 to i64*
  %2668 = load i64, i64* %2667, align 8
  store i64 %2668, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2669 = add i64 %2663, -24
  %2670 = add i64 %2665, 9
  store i64 %2670, i64* %PC, align 8
  %2671 = inttoptr i64 %2669 to i64*
  %2672 = load i64, i64* %2671, align 8
  store i64 %2672, i64* %RCX, align 8, !tbaa !2428
  %2673 = add i64 %2663, -40
  %2674 = add i64 %2665, 12
  store i64 %2674, i64* %PC, align 8
  %2675 = inttoptr i64 %2673 to i32*
  %2676 = load i32, i32* %2675, align 4
  %2677 = add i32 %2676, 1
  %2678 = zext i32 %2677 to i64
  store i64 %2678, i64* %RAX, align 8, !tbaa !2428
  %2679 = icmp eq i32 %2676, -1
  %2680 = icmp eq i32 %2677, 0
  %2681 = or i1 %2679, %2680
  %2682 = zext i1 %2681 to i8
  store i8 %2682, i8* %51, align 1, !tbaa !2433
  %2683 = and i32 %2677, 255
  %2684 = tail call i32 @llvm.ctpop.i32(i32 %2683) #10
  %2685 = trunc i32 %2684 to i8
  %2686 = and i8 %2685, 1
  %2687 = xor i8 %2686, 1
  store i8 %2687, i8* %52, align 1, !tbaa !2447
  %2688 = xor i32 %2676, %2677
  %2689 = lshr i32 %2688, 4
  %2690 = trunc i32 %2689 to i8
  %2691 = and i8 %2690, 1
  store i8 %2691, i8* %53, align 1, !tbaa !2451
  %2692 = zext i1 %2680 to i8
  store i8 %2692, i8* %54, align 1, !tbaa !2448
  %2693 = lshr i32 %2677, 31
  %2694 = trunc i32 %2693 to i8
  store i8 %2694, i8* %55, align 1, !tbaa !2449
  %2695 = lshr i32 %2676, 31
  %2696 = xor i32 %2693, %2695
  %2697 = add nuw nsw i32 %2696, %2693
  %2698 = icmp eq i32 %2697, 2
  %2699 = zext i1 %2698 to i8
  store i8 %2699, i8* %56, align 1, !tbaa !2450
  %2700 = sext i32 %2677 to i64
  store i64 %2700, i64* %RDX, align 8, !tbaa !2428
  %2701 = shl nsw i64 %2700, 3
  %2702 = add i64 %2701, %2672
  %2703 = add i64 %2665, 23
  store i64 %2703, i64* %PC, align 8
  %2704 = inttoptr i64 %2702 to i64*
  store i64 %2668, i64* %2704, align 8
  %2705 = load i64, i64* %RBP, align 8
  %2706 = add i64 %2705, -52
  %2707 = load i64, i64* %PC, align 8
  %2708 = add i64 %2707, 3
  store i64 %2708, i64* %PC, align 8
  %2709 = inttoptr i64 %2706 to i32*
  %2710 = load i32, i32* %2709, align 4
  %2711 = zext i32 %2710 to i64
  store i64 %2711, i64* %RAX, align 8, !tbaa !2428
  %2712 = add i64 %2705, -32
  %2713 = add i64 %2707, 6
  store i64 %2713, i64* %PC, align 8
  %2714 = inttoptr i64 %2712 to i32*
  %2715 = load i32, i32* %2714, align 4
  %2716 = add i32 %2715, %2710
  %2717 = zext i32 %2716 to i64
  store i64 %2717, i64* %RAX, align 8, !tbaa !2428
  %2718 = icmp ult i32 %2716, %2710
  %2719 = icmp ult i32 %2716, %2715
  %2720 = or i1 %2718, %2719
  %2721 = zext i1 %2720 to i8
  store i8 %2721, i8* %51, align 1, !tbaa !2433
  %2722 = and i32 %2716, 255
  %2723 = tail call i32 @llvm.ctpop.i32(i32 %2722) #10
  %2724 = trunc i32 %2723 to i8
  %2725 = and i8 %2724, 1
  %2726 = xor i8 %2725, 1
  store i8 %2726, i8* %52, align 1, !tbaa !2447
  %2727 = xor i32 %2715, %2710
  %2728 = xor i32 %2727, %2716
  %2729 = lshr i32 %2728, 4
  %2730 = trunc i32 %2729 to i8
  %2731 = and i8 %2730, 1
  store i8 %2731, i8* %53, align 1, !tbaa !2451
  %2732 = icmp eq i32 %2716, 0
  %2733 = zext i1 %2732 to i8
  store i8 %2733, i8* %54, align 1, !tbaa !2448
  %2734 = lshr i32 %2716, 31
  %2735 = trunc i32 %2734 to i8
  store i8 %2735, i8* %55, align 1, !tbaa !2449
  %2736 = lshr i32 %2710, 31
  %2737 = lshr i32 %2715, 31
  %2738 = xor i32 %2734, %2736
  %2739 = xor i32 %2734, %2737
  %2740 = add nuw nsw i32 %2738, %2739
  %2741 = icmp eq i32 %2740, 2
  %2742 = zext i1 %2741 to i8
  store i8 %2742, i8* %56, align 1, !tbaa !2450
  %2743 = add i64 %2707, 9
  store i64 %2743, i64* %PC, align 8
  store i32 %2716, i32* %2714, align 4
  %2744 = load i64, i64* %RBP, align 8
  %2745 = add i64 %2744, -52
  %2746 = load i64, i64* %PC, align 8
  %2747 = add i64 %2746, 3
  store i64 %2747, i64* %PC, align 8
  %2748 = inttoptr i64 %2745 to i32*
  %2749 = load i32, i32* %2748, align 4
  %2750 = shl i32 %2749, 1
  %2751 = icmp slt i32 %2749, 0
  %2752 = icmp slt i32 %2750, 0
  %2753 = xor i1 %2751, %2752
  %2754 = zext i32 %2750 to i64
  store i64 %2754, i64* %RAX, align 8, !tbaa !2428
  %.lobit18 = lshr i32 %2749, 31
  %2755 = trunc i32 %.lobit18 to i8
  store i8 %2755, i8* %51, align 1, !tbaa !2432
  %2756 = and i32 %2750, 254
  %2757 = tail call i32 @llvm.ctpop.i32(i32 %2756) #10
  %2758 = trunc i32 %2757 to i8
  %2759 = and i8 %2758, 1
  %2760 = xor i8 %2759, 1
  store i8 %2760, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %2761 = icmp eq i32 %2750, 0
  %2762 = zext i1 %2761 to i8
  store i8 %2762, i8* %54, align 1, !tbaa !2432
  %2763 = lshr i32 %2749, 30
  %2764 = and i32 %2763, 1
  %2765 = trunc i32 %2764 to i8
  store i8 %2765, i8* %55, align 1, !tbaa !2432
  %2766 = zext i1 %2753 to i8
  store i8 %2766, i8* %56, align 1, !tbaa !2432
  %2767 = add i64 %2744, -40
  %2768 = add i64 %2746, 9
  store i64 %2768, i64* %PC, align 8
  %2769 = inttoptr i64 %2767 to i32*
  %2770 = load i32, i32* %2769, align 4
  %2771 = add i32 %2770, %2750
  %2772 = zext i32 %2771 to i64
  store i64 %2772, i64* %RAX, align 8, !tbaa !2428
  %2773 = icmp ult i32 %2771, %2750
  %2774 = icmp ult i32 %2771, %2770
  %2775 = or i1 %2773, %2774
  %2776 = zext i1 %2775 to i8
  store i8 %2776, i8* %51, align 1, !tbaa !2433
  %2777 = and i32 %2771, 255
  %2778 = tail call i32 @llvm.ctpop.i32(i32 %2777) #10
  %2779 = trunc i32 %2778 to i8
  %2780 = and i8 %2779, 1
  %2781 = xor i8 %2780, 1
  store i8 %2781, i8* %52, align 1, !tbaa !2447
  %2782 = xor i32 %2770, %2750
  %2783 = xor i32 %2782, %2771
  %2784 = lshr i32 %2783, 4
  %2785 = trunc i32 %2784 to i8
  %2786 = and i8 %2785, 1
  store i8 %2786, i8* %53, align 1, !tbaa !2451
  %2787 = icmp eq i32 %2771, 0
  %2788 = zext i1 %2787 to i8
  store i8 %2788, i8* %54, align 1, !tbaa !2448
  %2789 = lshr i32 %2771, 31
  %2790 = trunc i32 %2789 to i8
  store i8 %2790, i8* %55, align 1, !tbaa !2449
  %2791 = lshr i32 %2770, 31
  %2792 = xor i32 %2789, %2764
  %2793 = xor i32 %2789, %2791
  %2794 = add nuw nsw i32 %2792, %2793
  %2795 = icmp eq i32 %2794, 2
  %2796 = zext i1 %2795 to i8
  store i8 %2796, i8* %56, align 1, !tbaa !2450
  %2797 = add i64 %2746, 12
  store i64 %2797, i64* %PC, align 8
  store i32 %2771, i32* %2769, align 4
  %2798 = load i64, i64* %RBP, align 8
  %2799 = add i64 %2798, -24
  %2800 = load i64, i64* %PC, align 8
  %2801 = add i64 %2800, 4
  store i64 %2801, i64* %PC, align 8
  %2802 = inttoptr i64 %2799 to i64*
  %2803 = load i64, i64* %2802, align 8
  store i64 %2803, i64* %RCX, align 8, !tbaa !2428
  %2804 = add i64 %2798, -32
  %2805 = add i64 %2800, 8
  store i64 %2805, i64* %PC, align 8
  %2806 = inttoptr i64 %2804 to i32*
  %2807 = load i32, i32* %2806, align 4
  %2808 = sext i32 %2807 to i64
  store i64 %2808, i64* %RDX, align 8, !tbaa !2428
  %2809 = shl nsw i64 %2808, 3
  %2810 = add i64 %2809, %2803
  %2811 = add i64 %2800, 13
  store i64 %2811, i64* %PC, align 8
  %2812 = inttoptr i64 %2810 to i64*
  %2813 = load i64, i64* %2812, align 8
  store i64 %2813, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2814 = add i64 %2798, -64
  %2815 = add i64 %2800, 18
  store i64 %2815, i64* %PC, align 8
  %2816 = inttoptr i64 %2814 to i64*
  store i64 %2813, i64* %2816, align 8
  %2817 = load i64, i64* %RBP, align 8
  %2818 = add i64 %2817, -24
  %2819 = load i64, i64* %PC, align 8
  %2820 = add i64 %2819, 4
  store i64 %2820, i64* %PC, align 8
  %2821 = inttoptr i64 %2818 to i64*
  %2822 = load i64, i64* %2821, align 8
  store i64 %2822, i64* %RCX, align 8, !tbaa !2428
  %2823 = add i64 %2817, -32
  %2824 = add i64 %2819, 7
  store i64 %2824, i64* %PC, align 8
  %2825 = inttoptr i64 %2823 to i32*
  %2826 = load i32, i32* %2825, align 4
  %2827 = add i32 %2826, 1
  %2828 = zext i32 %2827 to i64
  store i64 %2828, i64* %RAX, align 8, !tbaa !2428
  %2829 = icmp eq i32 %2826, -1
  %2830 = icmp eq i32 %2827, 0
  %2831 = or i1 %2829, %2830
  %2832 = zext i1 %2831 to i8
  store i8 %2832, i8* %51, align 1, !tbaa !2433
  %2833 = and i32 %2827, 255
  %2834 = tail call i32 @llvm.ctpop.i32(i32 %2833) #10
  %2835 = trunc i32 %2834 to i8
  %2836 = and i8 %2835, 1
  %2837 = xor i8 %2836, 1
  store i8 %2837, i8* %52, align 1, !tbaa !2447
  %2838 = xor i32 %2826, %2827
  %2839 = lshr i32 %2838, 4
  %2840 = trunc i32 %2839 to i8
  %2841 = and i8 %2840, 1
  store i8 %2841, i8* %53, align 1, !tbaa !2451
  %2842 = zext i1 %2830 to i8
  store i8 %2842, i8* %54, align 1, !tbaa !2448
  %2843 = lshr i32 %2827, 31
  %2844 = trunc i32 %2843 to i8
  store i8 %2844, i8* %55, align 1, !tbaa !2449
  %2845 = lshr i32 %2826, 31
  %2846 = xor i32 %2843, %2845
  %2847 = add nuw nsw i32 %2846, %2843
  %2848 = icmp eq i32 %2847, 2
  %2849 = zext i1 %2848 to i8
  store i8 %2849, i8* %56, align 1, !tbaa !2450
  %2850 = sext i32 %2827 to i64
  store i64 %2850, i64* %RDX, align 8, !tbaa !2428
  %2851 = shl nsw i64 %2850, 3
  %2852 = add i64 %2851, %2822
  %2853 = add i64 %2819, 18
  store i64 %2853, i64* %PC, align 8
  %2854 = inttoptr i64 %2852 to i64*
  %2855 = load i64, i64* %2854, align 8
  store i64 %2855, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2856 = add i64 %2817, -72
  %2857 = add i64 %2819, 23
  store i64 %2857, i64* %PC, align 8
  %2858 = inttoptr i64 %2856 to i64*
  store i64 %2855, i64* %2858, align 8
  %2859 = load i64, i64* %RBP, align 8
  %2860 = add i64 %2859, -24
  %2861 = load i64, i64* %PC, align 8
  %2862 = add i64 %2861, 4
  store i64 %2862, i64* %PC, align 8
  %2863 = inttoptr i64 %2860 to i64*
  %2864 = load i64, i64* %2863, align 8
  store i64 %2864, i64* %RCX, align 8, !tbaa !2428
  %2865 = add i64 %2859, -40
  %2866 = add i64 %2861, 8
  store i64 %2866, i64* %PC, align 8
  %2867 = inttoptr i64 %2865 to i32*
  %2868 = load i32, i32* %2867, align 4
  %2869 = sext i32 %2868 to i64
  store i64 %2869, i64* %RDX, align 8, !tbaa !2428
  %2870 = shl nsw i64 %2869, 3
  %2871 = add i64 %2870, %2864
  %2872 = add i64 %2861, 13
  store i64 %2872, i64* %PC, align 8
  %2873 = inttoptr i64 %2871 to i64*
  %2874 = load i64, i64* %2873, align 8
  store i64 %2874, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2875 = add i64 %2859, -80
  %2876 = add i64 %2861, 18
  store i64 %2876, i64* %PC, align 8
  %2877 = inttoptr i64 %2875 to i64*
  store i64 %2874, i64* %2877, align 8
  %2878 = load i64, i64* %RBP, align 8
  %2879 = add i64 %2878, -24
  %2880 = load i64, i64* %PC, align 8
  %2881 = add i64 %2880, 4
  store i64 %2881, i64* %PC, align 8
  %2882 = inttoptr i64 %2879 to i64*
  %2883 = load i64, i64* %2882, align 8
  store i64 %2883, i64* %RCX, align 8, !tbaa !2428
  %2884 = add i64 %2878, -40
  %2885 = add i64 %2880, 7
  store i64 %2885, i64* %PC, align 8
  %2886 = inttoptr i64 %2884 to i32*
  %2887 = load i32, i32* %2886, align 4
  %2888 = add i32 %2887, 1
  %2889 = zext i32 %2888 to i64
  store i64 %2889, i64* %RAX, align 8, !tbaa !2428
  %2890 = icmp eq i32 %2887, -1
  %2891 = icmp eq i32 %2888, 0
  %2892 = or i1 %2890, %2891
  %2893 = zext i1 %2892 to i8
  store i8 %2893, i8* %51, align 1, !tbaa !2433
  %2894 = and i32 %2888, 255
  %2895 = tail call i32 @llvm.ctpop.i32(i32 %2894) #10
  %2896 = trunc i32 %2895 to i8
  %2897 = and i8 %2896, 1
  %2898 = xor i8 %2897, 1
  store i8 %2898, i8* %52, align 1, !tbaa !2447
  %2899 = xor i32 %2887, %2888
  %2900 = lshr i32 %2899, 4
  %2901 = trunc i32 %2900 to i8
  %2902 = and i8 %2901, 1
  store i8 %2902, i8* %53, align 1, !tbaa !2451
  %2903 = zext i1 %2891 to i8
  store i8 %2903, i8* %54, align 1, !tbaa !2448
  %2904 = lshr i32 %2888, 31
  %2905 = trunc i32 %2904 to i8
  store i8 %2905, i8* %55, align 1, !tbaa !2449
  %2906 = lshr i32 %2887, 31
  %2907 = xor i32 %2904, %2906
  %2908 = add nuw nsw i32 %2907, %2904
  %2909 = icmp eq i32 %2908, 2
  %2910 = zext i1 %2909 to i8
  store i8 %2910, i8* %56, align 1, !tbaa !2450
  %2911 = sext i32 %2888 to i64
  store i64 %2911, i64* %RDX, align 8, !tbaa !2428
  %2912 = shl nsw i64 %2911, 3
  %2913 = add i64 %2912, %2883
  %2914 = add i64 %2880, 18
  store i64 %2914, i64* %PC, align 8
  %2915 = inttoptr i64 %2913 to i64*
  %2916 = load i64, i64* %2915, align 8
  store i64 %2916, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2917 = add i64 %2878, -88
  %2918 = add i64 %2880, 23
  store i64 %2918, i64* %PC, align 8
  %2919 = inttoptr i64 %2917 to i64*
  store i64 %2916, i64* %2919, align 8
  %2920 = load i64, i64* %RBP, align 8
  %2921 = add i64 %2920, -80
  %2922 = load i64, i64* %PC, align 8
  %2923 = add i64 %2922, 5
  store i64 %2923, i64* %PC, align 8
  %2924 = inttoptr i64 %2921 to i64*
  %2925 = load i64, i64* %2924, align 8
  store i64 %2925, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2926 = add i64 %2920, -24
  %2927 = add i64 %2922, 9
  store i64 %2927, i64* %PC, align 8
  %2928 = inttoptr i64 %2926 to i64*
  %2929 = load i64, i64* %2928, align 8
  store i64 %2929, i64* %RCX, align 8, !tbaa !2428
  %2930 = add i64 %2920, -32
  %2931 = add i64 %2922, 13
  store i64 %2931, i64* %PC, align 8
  %2932 = inttoptr i64 %2930 to i32*
  %2933 = load i32, i32* %2932, align 4
  %2934 = sext i32 %2933 to i64
  store i64 %2934, i64* %RDX, align 8, !tbaa !2428
  %2935 = shl nsw i64 %2934, 3
  %2936 = add i64 %2935, %2929
  %2937 = add i64 %2922, 18
  store i64 %2937, i64* %PC, align 8
  %2938 = inttoptr i64 %2936 to i64*
  store i64 %2925, i64* %2938, align 8
  %2939 = load i64, i64* %RBP, align 8
  %2940 = add i64 %2939, -88
  %2941 = load i64, i64* %PC, align 8
  %2942 = add i64 %2941, 5
  store i64 %2942, i64* %PC, align 8
  %2943 = inttoptr i64 %2940 to i64*
  %2944 = load i64, i64* %2943, align 8
  store i64 %2944, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2945 = add i64 %2939, -24
  %2946 = add i64 %2941, 9
  store i64 %2946, i64* %PC, align 8
  %2947 = inttoptr i64 %2945 to i64*
  %2948 = load i64, i64* %2947, align 8
  store i64 %2948, i64* %RCX, align 8, !tbaa !2428
  %2949 = add i64 %2939, -32
  %2950 = add i64 %2941, 12
  store i64 %2950, i64* %PC, align 8
  %2951 = inttoptr i64 %2949 to i32*
  %2952 = load i32, i32* %2951, align 4
  %2953 = add i32 %2952, 1
  %2954 = zext i32 %2953 to i64
  store i64 %2954, i64* %RAX, align 8, !tbaa !2428
  %2955 = icmp eq i32 %2952, -1
  %2956 = icmp eq i32 %2953, 0
  %2957 = or i1 %2955, %2956
  %2958 = zext i1 %2957 to i8
  store i8 %2958, i8* %51, align 1, !tbaa !2433
  %2959 = and i32 %2953, 255
  %2960 = tail call i32 @llvm.ctpop.i32(i32 %2959) #10
  %2961 = trunc i32 %2960 to i8
  %2962 = and i8 %2961, 1
  %2963 = xor i8 %2962, 1
  store i8 %2963, i8* %52, align 1, !tbaa !2447
  %2964 = xor i32 %2952, %2953
  %2965 = lshr i32 %2964, 4
  %2966 = trunc i32 %2965 to i8
  %2967 = and i8 %2966, 1
  store i8 %2967, i8* %53, align 1, !tbaa !2451
  %2968 = zext i1 %2956 to i8
  store i8 %2968, i8* %54, align 1, !tbaa !2448
  %2969 = lshr i32 %2953, 31
  %2970 = trunc i32 %2969 to i8
  store i8 %2970, i8* %55, align 1, !tbaa !2449
  %2971 = lshr i32 %2952, 31
  %2972 = xor i32 %2969, %2971
  %2973 = add nuw nsw i32 %2972, %2969
  %2974 = icmp eq i32 %2973, 2
  %2975 = zext i1 %2974 to i8
  store i8 %2975, i8* %56, align 1, !tbaa !2450
  %2976 = sext i32 %2953 to i64
  store i64 %2976, i64* %RDX, align 8, !tbaa !2428
  %2977 = shl nsw i64 %2976, 3
  %2978 = add i64 %2977, %2948
  %2979 = add i64 %2941, 23
  store i64 %2979, i64* %PC, align 8
  %2980 = inttoptr i64 %2978 to i64*
  store i64 %2944, i64* %2980, align 8
  %2981 = load i64, i64* %RBP, align 8
  %2982 = add i64 %2981, -64
  %2983 = load i64, i64* %PC, align 8
  %2984 = add i64 %2983, 5
  store i64 %2984, i64* %PC, align 8
  %2985 = inttoptr i64 %2982 to i64*
  %2986 = load i64, i64* %2985, align 8
  store i64 %2986, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %2987 = add i64 %2981, -24
  %2988 = add i64 %2983, 9
  store i64 %2988, i64* %PC, align 8
  %2989 = inttoptr i64 %2987 to i64*
  %2990 = load i64, i64* %2989, align 8
  store i64 %2990, i64* %RCX, align 8, !tbaa !2428
  %2991 = add i64 %2981, -40
  %2992 = add i64 %2983, 13
  store i64 %2992, i64* %PC, align 8
  %2993 = inttoptr i64 %2991 to i32*
  %2994 = load i32, i32* %2993, align 4
  %2995 = sext i32 %2994 to i64
  store i64 %2995, i64* %RDX, align 8, !tbaa !2428
  %2996 = shl nsw i64 %2995, 3
  %2997 = add i64 %2996, %2990
  %2998 = add i64 %2983, 18
  store i64 %2998, i64* %PC, align 8
  %2999 = inttoptr i64 %2997 to i64*
  store i64 %2986, i64* %2999, align 8
  %3000 = load i64, i64* %RBP, align 8
  %3001 = add i64 %3000, -72
  %3002 = load i64, i64* %PC, align 8
  %3003 = add i64 %3002, 5
  store i64 %3003, i64* %PC, align 8
  %3004 = inttoptr i64 %3001 to i64*
  %3005 = load i64, i64* %3004, align 8
  store i64 %3005, i64* %1819, align 1, !tbaa !2452
  store double 0.000000e+00, double* %238, align 1, !tbaa !2452
  %3006 = add i64 %3000, -24
  %3007 = add i64 %3002, 9
  store i64 %3007, i64* %PC, align 8
  %3008 = inttoptr i64 %3006 to i64*
  %3009 = load i64, i64* %3008, align 8
  store i64 %3009, i64* %RCX, align 8, !tbaa !2428
  %3010 = add i64 %3000, -40
  %3011 = add i64 %3002, 12
  store i64 %3011, i64* %PC, align 8
  %3012 = inttoptr i64 %3010 to i32*
  %3013 = load i32, i32* %3012, align 4
  %3014 = add i32 %3013, 1
  %3015 = zext i32 %3014 to i64
  store i64 %3015, i64* %RAX, align 8, !tbaa !2428
  %3016 = icmp eq i32 %3013, -1
  %3017 = icmp eq i32 %3014, 0
  %3018 = or i1 %3016, %3017
  %3019 = zext i1 %3018 to i8
  store i8 %3019, i8* %51, align 1, !tbaa !2433
  %3020 = and i32 %3014, 255
  %3021 = tail call i32 @llvm.ctpop.i32(i32 %3020) #10
  %3022 = trunc i32 %3021 to i8
  %3023 = and i8 %3022, 1
  %3024 = xor i8 %3023, 1
  store i8 %3024, i8* %52, align 1, !tbaa !2447
  %3025 = xor i32 %3013, %3014
  %3026 = lshr i32 %3025, 4
  %3027 = trunc i32 %3026 to i8
  %3028 = and i8 %3027, 1
  store i8 %3028, i8* %53, align 1, !tbaa !2451
  %3029 = zext i1 %3017 to i8
  store i8 %3029, i8* %54, align 1, !tbaa !2448
  %3030 = lshr i32 %3014, 31
  %3031 = trunc i32 %3030 to i8
  store i8 %3031, i8* %55, align 1, !tbaa !2449
  %3032 = lshr i32 %3013, 31
  %3033 = xor i32 %3030, %3032
  %3034 = add nuw nsw i32 %3033, %3030
  %3035 = icmp eq i32 %3034, 2
  %3036 = zext i1 %3035 to i8
  store i8 %3036, i8* %56, align 1, !tbaa !2450
  %3037 = sext i32 %3014 to i64
  store i64 %3037, i64* %RDX, align 8, !tbaa !2428
  %3038 = shl nsw i64 %3037, 3
  %3039 = add i64 %3038, %3009
  %3040 = add i64 %3002, 23
  store i64 %3040, i64* %PC, align 8
  %3041 = inttoptr i64 %3039 to i64*
  store i64 %3005, i64* %3041, align 8
  %3042 = load i64, i64* %RBP, align 8
  %3043 = add i64 %3042, -28
  %3044 = load i64, i64* %PC, align 8
  %3045 = add i64 %3044, 3
  store i64 %3045, i64* %PC, align 8
  %3046 = inttoptr i64 %3043 to i32*
  %3047 = load i32, i32* %3046, align 4
  %3048 = add i32 %3047, 1
  %3049 = zext i32 %3048 to i64
  store i64 %3049, i64* %RAX, align 8, !tbaa !2428
  %3050 = icmp eq i32 %3047, -1
  %3051 = icmp eq i32 %3048, 0
  %3052 = or i1 %3050, %3051
  %3053 = zext i1 %3052 to i8
  store i8 %3053, i8* %51, align 1, !tbaa !2433
  %3054 = and i32 %3048, 255
  %3055 = tail call i32 @llvm.ctpop.i32(i32 %3054) #10
  %3056 = trunc i32 %3055 to i8
  %3057 = and i8 %3056, 1
  %3058 = xor i8 %3057, 1
  store i8 %3058, i8* %52, align 1, !tbaa !2447
  %3059 = xor i32 %3047, %3048
  %3060 = lshr i32 %3059, 4
  %3061 = trunc i32 %3060 to i8
  %3062 = and i8 %3061, 1
  store i8 %3062, i8* %53, align 1, !tbaa !2451
  %3063 = zext i1 %3051 to i8
  store i8 %3063, i8* %54, align 1, !tbaa !2448
  %3064 = lshr i32 %3048, 31
  %3065 = trunc i32 %3064 to i8
  store i8 %3065, i8* %55, align 1, !tbaa !2449
  %3066 = lshr i32 %3047, 31
  %3067 = xor i32 %3064, %3066
  %3068 = add nuw nsw i32 %3067, %3064
  %3069 = icmp eq i32 %3068, 2
  %3070 = zext i1 %3069 to i8
  store i8 %3070, i8* %56, align 1, !tbaa !2450
  %3071 = add i64 %3044, 9
  store i64 %3071, i64* %PC, align 8
  store i32 %3048, i32* %3046, align 4
  %3072 = load i64, i64* %PC, align 8
  %3073 = add i64 %3072, -779
  store i64 %3073, i64* %PC, align 8, !tbaa !2428
  br label %block_40127d

block_401205:                                     ; preds = %block_401211, %block_4011f5
  %3074 = phi i64 [ %541, %block_401211 ], [ %.pre3, %block_4011f5 ]
  %3075 = load i64, i64* %RBP, align 8
  %3076 = add i64 %3075, -28
  %3077 = add i64 %3074, 3
  store i64 %3077, i64* %PC, align 8
  %3078 = inttoptr i64 %3076 to i32*
  %3079 = load i32, i32* %3078, align 4
  %3080 = zext i32 %3079 to i64
  store i64 %3080, i64* %RAX, align 8, !tbaa !2428
  %3081 = add i64 %3075, -48
  %3082 = add i64 %3074, 6
  store i64 %3082, i64* %PC, align 8
  %3083 = inttoptr i64 %3081 to i32*
  %3084 = load i32, i32* %3083, align 4
  %3085 = sub i32 %3079, %3084
  %3086 = icmp ult i32 %3079, %3084
  %3087 = zext i1 %3086 to i8
  store i8 %3087, i8* %51, align 1, !tbaa !2433
  %3088 = and i32 %3085, 255
  %3089 = tail call i32 @llvm.ctpop.i32(i32 %3088) #10
  %3090 = trunc i32 %3089 to i8
  %3091 = and i8 %3090, 1
  %3092 = xor i8 %3091, 1
  store i8 %3092, i8* %52, align 1, !tbaa !2447
  %3093 = xor i32 %3084, %3079
  %3094 = xor i32 %3093, %3085
  %3095 = lshr i32 %3094, 4
  %3096 = trunc i32 %3095 to i8
  %3097 = and i8 %3096, 1
  store i8 %3097, i8* %53, align 1, !tbaa !2451
  %3098 = icmp eq i32 %3085, 0
  %3099 = zext i1 %3098 to i8
  store i8 %3099, i8* %54, align 1, !tbaa !2448
  %3100 = lshr i32 %3085, 31
  %3101 = trunc i32 %3100 to i8
  store i8 %3101, i8* %55, align 1, !tbaa !2449
  %3102 = lshr i32 %3079, 31
  %3103 = lshr i32 %3084, 31
  %3104 = xor i32 %3103, %3102
  %3105 = xor i32 %3100, %3102
  %3106 = add nuw nsw i32 %3105, %3104
  %3107 = icmp eq i32 %3106, 2
  %3108 = zext i1 %3107 to i8
  store i8 %3108, i8* %56, align 1, !tbaa !2450
  %3109 = icmp ne i8 %3101, 0
  %3110 = xor i1 %3109, %3107
  %.v9 = select i1 %3110, i64 12, i64 56
  %3111 = add i64 %3074, %.v9
  store i64 %3111, i64* %PC, align 8, !tbaa !2428
  br i1 %3110, label %block_401211, label %block_40123d
}

; Function Attrs: noinline
define %struct.Memory* @sub_400e30_makewt(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400e30:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %7 = load i64, i64* %RBP, align 8
  %8 = add i64 %1, 1
  store i64 %8, i64* %PC, align 8
  %9 = load i64, i64* %RSP, align 8, !tbaa !2428
  %10 = add i64 %9, -8
  %11 = inttoptr i64 %10 to i64*
  store i64 %7, i64* %11, align 8
  %12 = load i64, i64* %PC, align 8
  store i64 %10, i64* %RBP, align 8, !tbaa !2428
  %13 = add i64 %9, -72
  store i64 %13, i64* %RSP, align 8, !tbaa !2428
  %14 = icmp ult i64 %10, 64
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1, !tbaa !2433
  %17 = trunc i64 %13 to i32
  %18 = and i32 %17, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18) #10
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1, !tbaa !2447
  %24 = xor i64 %10, %13
  %25 = lshr i64 %24, 4
  %26 = trunc i64 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1, !tbaa !2451
  %29 = icmp eq i64 %13, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1, !tbaa !2448
  %32 = lshr i64 %13, 63
  %33 = trunc i64 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1, !tbaa !2449
  %35 = lshr i64 %10, 63
  %36 = xor i64 %32, %35
  %37 = add nuw nsw i64 %36, %35
  %38 = icmp eq i64 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1, !tbaa !2450
  %41 = add i64 %9, -12
  %42 = load i32, i32* %EDI, align 4
  %43 = add i64 %12, 10
  store i64 %43, i64* %PC, align 8
  %44 = inttoptr i64 %41 to i32*
  store i32 %42, i32* %44, align 4
  %45 = load i64, i64* %RBP, align 8
  %46 = add i64 %45, -16
  %47 = load i64, i64* %RSI, align 8
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 4
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %46 to i64*
  store i64 %47, i64* %50, align 8
  %51 = load i64, i64* %RBP, align 8
  %52 = add i64 %51, -24
  %53 = load i64, i64* %RDX, align 8
  %54 = load i64, i64* %PC, align 8
  %55 = add i64 %54, 4
  store i64 %55, i64* %PC, align 8
  %56 = inttoptr i64 %52 to i64*
  store i64 %53, i64* %56, align 8
  %57 = load i64, i64* %RBP, align 8
  %58 = add i64 %57, -4
  %59 = load i64, i64* %PC, align 8
  %60 = add i64 %59, 4
  store i64 %60, i64* %PC, align 8
  %61 = inttoptr i64 %58 to i32*
  %62 = load i32, i32* %61, align 4
  %63 = add i32 %62, -2
  %64 = icmp ult i32 %62, 2
  %65 = zext i1 %64 to i8
  store i8 %65, i8* %16, align 1, !tbaa !2433
  %66 = and i32 %63, 255
  %67 = tail call i32 @llvm.ctpop.i32(i32 %66) #10
  %68 = trunc i32 %67 to i8
  %69 = and i8 %68, 1
  %70 = xor i8 %69, 1
  store i8 %70, i8* %23, align 1, !tbaa !2447
  %71 = xor i32 %62, %63
  %72 = lshr i32 %71, 4
  %73 = trunc i32 %72 to i8
  %74 = and i8 %73, 1
  store i8 %74, i8* %28, align 1, !tbaa !2451
  %75 = icmp eq i32 %63, 0
  %76 = zext i1 %75 to i8
  store i8 %76, i8* %31, align 1, !tbaa !2448
  %77 = lshr i32 %63, 31
  %78 = trunc i32 %77 to i8
  store i8 %78, i8* %34, align 1, !tbaa !2449
  %79 = lshr i32 %62, 31
  %80 = xor i32 %77, %79
  %81 = add nuw nsw i32 %80, %79
  %82 = icmp eq i32 %81, 2
  %83 = zext i1 %82 to i8
  store i8 %83, i8* %40, align 1, !tbaa !2450
  %84 = icmp ne i8 %78, 0
  %85 = xor i1 %84, %82
  %86 = or i1 %75, %85
  %.v = select i1 %86, i64 347, i64 10
  %87 = add i64 %59, %.v
  store i64 %87, i64* %PC, align 8, !tbaa !2428
  br i1 %86, label %block_400f9e, label %block_400e4d

block_400f9e:                                     ; preds = %block_400f99, %block_400e30
  %88 = phi i64 [ %87, %block_400e30 ], [ %576, %block_400f99 ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_400e30 ], [ %MEMORY.1, %block_400f99 ]
  %89 = load i64, i64* %RSP, align 8
  %90 = add i64 %89, 64
  store i64 %90, i64* %RSP, align 8, !tbaa !2428
  %91 = icmp ugt i64 %89, -65
  %92 = zext i1 %91 to i8
  store i8 %92, i8* %16, align 1, !tbaa !2433
  %93 = trunc i64 %90 to i32
  %94 = and i32 %93, 255
  %95 = tail call i32 @llvm.ctpop.i32(i32 %94) #10
  %96 = trunc i32 %95 to i8
  %97 = and i8 %96, 1
  %98 = xor i8 %97, 1
  store i8 %98, i8* %23, align 1, !tbaa !2447
  %99 = xor i64 %89, %90
  %100 = lshr i64 %99, 4
  %101 = trunc i64 %100 to i8
  %102 = and i8 %101, 1
  store i8 %102, i8* %28, align 1, !tbaa !2451
  %103 = icmp eq i64 %90, 0
  %104 = zext i1 %103 to i8
  store i8 %104, i8* %31, align 1, !tbaa !2448
  %105 = lshr i64 %90, 63
  %106 = trunc i64 %105 to i8
  store i8 %106, i8* %34, align 1, !tbaa !2449
  %107 = lshr i64 %89, 63
  %108 = xor i64 %105, %107
  %109 = add nuw nsw i64 %108, %105
  %110 = icmp eq i64 %109, 2
  %111 = zext i1 %110 to i8
  store i8 %111, i8* %40, align 1, !tbaa !2450
  %112 = add i64 %88, 5
  store i64 %112, i64* %PC, align 8
  %113 = add i64 %89, 72
  %114 = inttoptr i64 %90 to i64*
  %115 = load i64, i64* %114, align 8
  store i64 %115, i64* %RBP, align 8, !tbaa !2428
  store i64 %113, i64* %RSP, align 8, !tbaa !2428
  %116 = add i64 %88, 6
  store i64 %116, i64* %PC, align 8
  %117 = inttoptr i64 %113 to i64*
  %118 = load i64, i64* %117, align 8
  store i64 %118, i64* %PC, align 8, !tbaa !2428
  %119 = add i64 %89, 80
  store i64 %119, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_400eda:                                     ; preds = %block_400e4d
  %120 = add i64 %290, -28
  %121 = add i64 %320, 7
  store i64 %121, i64* %PC, align 8
  %122 = inttoptr i64 %120 to i32*
  store i32 2, i32* %122, align 4
  %.pre = load i64, i64* %PC, align 8
  br label %block_400ee1

block_400e4d:                                     ; preds = %block_400e30
  %123 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3
  %124 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 64) to i64*), align 16
  %125 = bitcast [32 x %union.VectorReg]* %4 to double*
  %126 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %124, i64* %126, align 1, !tbaa !2452
  %127 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %128 = bitcast i64* %127 to double*
  store double 0.000000e+00, double* %128, align 1, !tbaa !2452
  %129 = add i64 %87, 11
  store i64 %129, i64* %PC, align 8
  %130 = load i32, i32* %61, align 4
  %131 = zext i32 %130 to i64
  %132 = shl nuw i64 %131, 32
  %133 = ashr i64 %132, 33
  %134 = trunc i32 %130 to i8
  %135 = and i8 %134, 1
  %136 = trunc i64 %133 to i32
  %137 = and i64 %133, 4294967295
  store i64 %137, i64* %RAX, align 8, !tbaa !2428
  store i8 %135, i8* %16, align 1, !tbaa !2432
  %138 = and i32 %136, 255
  %139 = tail call i32 @llvm.ctpop.i32(i32 %138) #10
  %140 = trunc i32 %139 to i8
  %141 = and i8 %140, 1
  %142 = xor i8 %141, 1
  store i8 %142, i8* %23, align 1, !tbaa !2432
  store i8 0, i8* %28, align 1, !tbaa !2432
  %143 = icmp eq i32 %136, 0
  %144 = zext i1 %143 to i8
  store i8 %144, i8* %31, align 1, !tbaa !2432
  %145 = lshr i64 %133, 31
  %146 = trunc i64 %145 to i8
  %147 = and i8 %146, 1
  store i8 %147, i8* %34, align 1, !tbaa !2432
  store i8 0, i8* %40, align 1, !tbaa !2432
  %148 = add i64 %57, -32
  %149 = add i64 %87, 17
  store i64 %149, i64* %PC, align 8
  %150 = inttoptr i64 %148 to i32*
  store i32 %136, i32* %150, align 4
  %151 = load i64, i64* %PC, align 8
  %152 = add i64 %151, -2014
  %153 = add i64 %151, 5
  %154 = load i64, i64* %RSP, align 8, !tbaa !2428
  %155 = add i64 %154, -8
  %156 = inttoptr i64 %155 to i64*
  store i64 %153, i64* %156, align 8
  store i64 %155, i64* %RSP, align 8, !tbaa !2428
  store i64 %152, i64* %PC, align 8, !alias.scope !2454, !noalias !2457
  %157 = load double, double* %125, align 8, !alias.scope !2454, !noalias !2457
  %158 = load i64, i64* %156, align 8
  store i64 %154, i64* %RSP, align 8, !alias.scope !2454, !noalias !2457
  %159 = tail call double @atan(double %157)
  store i64 0, i64* %126, align 8
  store i64 0, i64* %127, align 8
  %160 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %160, align 8
  %161 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %161, align 8
  store double %159, double* %125, align 8, !alias.scope !2454, !noalias !2457
  %162 = bitcast %union.VectorReg* %5 to i8*
  %163 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %164 = bitcast %union.VectorReg* %5 to i32*
  store i32 0, i32* %164, align 1, !tbaa !2459
  %165 = getelementptr inbounds i8, i8* %162, i64 4
  %166 = bitcast i8* %165 to i32*
  store i32 0, i32* %166, align 1, !tbaa !2459
  %167 = bitcast i64* %163 to i32*
  store i32 0, i32* %167, align 1, !tbaa !2459
  %168 = getelementptr inbounds i8, i8* %162, i64 12
  %169 = bitcast i8* %168 to i32*
  store i32 0, i32* %169, align 1, !tbaa !2459
  %170 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 64) to i64*), align 16
  %171 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %170, i64* %171, align 1, !tbaa !2452
  %172 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %173 = bitcast i64* %172 to double*
  store double 0.000000e+00, double* %173, align 1, !tbaa !2452
  %174 = load i64, i64* %RBP, align 8
  %175 = add i64 %174, -32
  %176 = add i64 %158, 14
  store i64 %176, i64* %PC, align 8
  %177 = inttoptr i64 %175 to i32*
  %178 = load i32, i32* %177, align 4
  %179 = zext i32 %178 to i64
  store i64 %179, i64* %RAX, align 8, !tbaa !2428
  %180 = sitofp i32 %178 to double
  %181 = bitcast %union.VectorReg* %123 to double*
  store double %180, double* %181, align 1, !tbaa !2452
  %182 = fdiv double %159, %180
  store double %182, double* %125, align 1, !tbaa !2452
  %183 = add i64 %174, -40
  %184 = add i64 %158, 27
  store i64 %184, i64* %PC, align 8
  %185 = inttoptr i64 %183 to double*
  store double %182, double* %185, align 8
  %186 = load i64, i64* %RBP, align 8
  %187 = add i64 %186, -24
  %188 = load i64, i64* %PC, align 8
  %189 = add i64 %188, 4
  store i64 %189, i64* %PC, align 8
  %190 = inttoptr i64 %187 to i64*
  %191 = load i64, i64* %190, align 8
  store i64 %191, i64* %RCX, align 8, !tbaa !2428
  %192 = add i64 %188, 8
  store i64 %192, i64* %PC, align 8
  %193 = load i64, i64* %171, align 1
  %194 = inttoptr i64 %191 to i64*
  store i64 %193, i64* %194, align 8
  %195 = load i64, i64* %RBP, align 8
  %196 = add i64 %195, -24
  %197 = load i64, i64* %PC, align 8
  %198 = add i64 %197, 4
  store i64 %198, i64* %PC, align 8
  %199 = inttoptr i64 %196 to i64*
  %200 = load i64, i64* %199, align 8
  store i64 %200, i64* %RCX, align 8, !tbaa !2428
  %201 = add i64 %200, 8
  %202 = add i64 %197, 9
  store i64 %202, i64* %PC, align 8
  %203 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  %204 = load i64, i64* %203, align 1
  %205 = inttoptr i64 %201 to i64*
  store i64 %204, i64* %205, align 8
  %206 = load i64, i64* %RBP, align 8
  %207 = add i64 %206, -40
  %208 = load i64, i64* %PC, align 8
  %209 = add i64 %208, 5
  store i64 %209, i64* %PC, align 8
  %210 = inttoptr i64 %207 to double*
  %211 = load double, double* %210, align 8
  store double %211, double* %125, align 1, !tbaa !2452
  store double 0.000000e+00, double* %128, align 1, !tbaa !2452
  %212 = add i64 %206, -32
  %213 = add i64 %208, 8
  store i64 %213, i64* %PC, align 8
  %214 = inttoptr i64 %212 to i32*
  %215 = load i32, i32* %214, align 4
  %216 = zext i32 %215 to i64
  store i64 %216, i64* %RAX, align 8, !tbaa !2428
  %217 = sitofp i32 %215 to double
  %218 = bitcast %union.VectorReg* %5 to double*
  store double %217, double* %218, align 1, !tbaa !2452
  %219 = fmul double %211, %217
  store double %219, double* %125, align 1, !tbaa !2452
  store i64 0, i64* %127, align 1, !tbaa !2452
  %220 = add i64 %208, -1999
  %221 = add i64 %208, 21
  %222 = load i64, i64* %RSP, align 8, !tbaa !2428
  %223 = add i64 %222, -8
  %224 = inttoptr i64 %223 to i64*
  store i64 %221, i64* %224, align 8
  store i64 %223, i64* %RSP, align 8, !tbaa !2428
  store i64 %220, i64* %PC, align 8, !alias.scope !2460, !noalias !2463
  %225 = load double, double* %125, align 8, !alias.scope !2460, !noalias !2463
  %226 = load i64, i64* %224, align 8
  store i64 %222, i64* %RSP, align 8, !alias.scope !2460, !noalias !2463
  %227 = tail call double @cos(double %225)
  store i64 0, i64* %126, align 8
  store i64 0, i64* %127, align 8
  store i64 0, i64* %160, align 8
  store i64 0, i64* %161, align 8
  store double %227, double* %125, align 8, !alias.scope !2460, !noalias !2463
  %228 = load i64, i64* %RBP, align 8
  %229 = add i64 %228, -24
  %230 = add i64 %226, 4
  store i64 %230, i64* %PC, align 8
  %231 = inttoptr i64 %229 to i64*
  %232 = load i64, i64* %231, align 8
  store i64 %232, i64* %RCX, align 8, !tbaa !2428
  %233 = add i64 %228, -32
  %234 = add i64 %226, 8
  store i64 %234, i64* %PC, align 8
  %235 = inttoptr i64 %233 to i32*
  %236 = load i32, i32* %235, align 4
  %237 = sext i32 %236 to i64
  store i64 %237, i64* %RDX, align 8, !tbaa !2428
  %238 = shl nsw i64 %237, 3
  %239 = add i64 %238, %232
  %240 = add i64 %226, 13
  store i64 %240, i64* %PC, align 8
  %241 = inttoptr i64 %239 to double*
  store double %227, double* %241, align 8
  %242 = load i64, i64* %RBP, align 8
  %243 = add i64 %242, -24
  %244 = load i64, i64* %PC, align 8
  %245 = add i64 %244, 4
  store i64 %245, i64* %PC, align 8
  %246 = inttoptr i64 %243 to i64*
  %247 = load i64, i64* %246, align 8
  store i64 %247, i64* %RCX, align 8, !tbaa !2428
  %248 = add i64 %242, -32
  %249 = add i64 %244, 8
  store i64 %249, i64* %PC, align 8
  %250 = inttoptr i64 %248 to i32*
  %251 = load i32, i32* %250, align 4
  %252 = sext i32 %251 to i64
  store i64 %252, i64* %RDX, align 8, !tbaa !2428
  %253 = shl nsw i64 %252, 3
  %254 = add i64 %253, %247
  %255 = add i64 %244, 13
  store i64 %255, i64* %PC, align 8
  %256 = inttoptr i64 %254 to i64*
  %257 = load i64, i64* %256, align 8
  store i64 %257, i64* %126, align 1, !tbaa !2452
  store double 0.000000e+00, double* %128, align 1, !tbaa !2452
  %258 = add i64 %244, 17
  store i64 %258, i64* %PC, align 8
  %259 = load i64, i64* %246, align 8
  store i64 %259, i64* %RCX, align 8, !tbaa !2428
  %260 = add i64 %244, 20
  store i64 %260, i64* %PC, align 8
  %261 = load i32, i32* %250, align 4
  %262 = add i32 %261, 1
  %263 = zext i32 %262 to i64
  store i64 %263, i64* %RAX, align 8, !tbaa !2428
  %264 = icmp eq i32 %261, -1
  %265 = icmp eq i32 %262, 0
  %266 = or i1 %264, %265
  %267 = zext i1 %266 to i8
  store i8 %267, i8* %16, align 1, !tbaa !2433
  %268 = and i32 %262, 255
  %269 = tail call i32 @llvm.ctpop.i32(i32 %268) #10
  %270 = trunc i32 %269 to i8
  %271 = and i8 %270, 1
  %272 = xor i8 %271, 1
  store i8 %272, i8* %23, align 1, !tbaa !2447
  %273 = xor i32 %261, %262
  %274 = lshr i32 %273, 4
  %275 = trunc i32 %274 to i8
  %276 = and i8 %275, 1
  store i8 %276, i8* %28, align 1, !tbaa !2451
  %277 = zext i1 %265 to i8
  store i8 %277, i8* %31, align 1, !tbaa !2448
  %278 = lshr i32 %262, 31
  %279 = trunc i32 %278 to i8
  store i8 %279, i8* %34, align 1, !tbaa !2449
  %280 = lshr i32 %261, 31
  %281 = xor i32 %278, %280
  %282 = add nuw nsw i32 %281, %278
  %283 = icmp eq i32 %282, 2
  %284 = zext i1 %283 to i8
  store i8 %284, i8* %40, align 1, !tbaa !2450
  %285 = sext i32 %262 to i64
  store i64 %285, i64* %RDX, align 8, !tbaa !2428
  %286 = shl nsw i64 %285, 3
  %287 = add i64 %286, %259
  %288 = add i64 %244, 31
  store i64 %288, i64* %PC, align 8
  %289 = inttoptr i64 %287 to i64*
  store i64 %257, i64* %289, align 8
  %290 = load i64, i64* %RBP, align 8
  %291 = add i64 %290, -32
  %292 = load i64, i64* %PC, align 8
  %293 = add i64 %292, 4
  store i64 %293, i64* %PC, align 8
  %294 = inttoptr i64 %291 to i32*
  %295 = load i32, i32* %294, align 4
  %296 = add i32 %295, -2
  %297 = icmp ult i32 %295, 2
  %298 = zext i1 %297 to i8
  store i8 %298, i8* %16, align 1, !tbaa !2433
  %299 = and i32 %296, 255
  %300 = tail call i32 @llvm.ctpop.i32(i32 %299) #10
  %301 = trunc i32 %300 to i8
  %302 = and i8 %301, 1
  %303 = xor i8 %302, 1
  store i8 %303, i8* %23, align 1, !tbaa !2447
  %304 = xor i32 %295, %296
  %305 = lshr i32 %304, 4
  %306 = trunc i32 %305 to i8
  %307 = and i8 %306, 1
  store i8 %307, i8* %28, align 1, !tbaa !2451
  %308 = icmp eq i32 %296, 0
  %309 = zext i1 %308 to i8
  store i8 %309, i8* %31, align 1, !tbaa !2448
  %310 = lshr i32 %296, 31
  %311 = trunc i32 %310 to i8
  store i8 %311, i8* %34, align 1, !tbaa !2449
  %312 = lshr i32 %295, 31
  %313 = xor i32 %310, %312
  %314 = add nuw nsw i32 %313, %312
  %315 = icmp eq i32 %314, 2
  %316 = zext i1 %315 to i8
  store i8 %316, i8* %40, align 1, !tbaa !2450
  %317 = icmp ne i8 %311, 0
  %318 = xor i1 %317, %315
  %319 = or i1 %308, %318
  %.v9 = select i1 %319, i64 201, i64 10
  %320 = add i64 %292, %.v9
  store i64 %320, i64* %PC, align 8, !tbaa !2428
  br i1 %319, label %block_400f99, label %block_400eda

block_400eed:                                     ; preds = %block_400ee1
  %321 = add i64 %578, -40
  %322 = add i64 %614, 5
  store i64 %322, i64* %PC, align 8
  %323 = inttoptr i64 %321 to double*
  %324 = load double, double* %323, align 8
  store double %324, double* %125, align 1, !tbaa !2452
  store double 0.000000e+00, double* %128, align 1, !tbaa !2452
  %325 = add i64 %614, 8
  store i64 %325, i64* %PC, align 8
  %326 = load i32, i32* %581, align 4
  %327 = zext i32 %326 to i64
  store i64 %327, i64* %RAX, align 8, !tbaa !2428
  %328 = sitofp i32 %326 to double
  store double %328, double* %218, align 1, !tbaa !2452
  %329 = fmul double %324, %328
  store double %329, double* %125, align 1, !tbaa !2452
  store i64 0, i64* %127, align 1, !tbaa !2452
  %330 = add i64 %614, -2093
  %331 = add i64 %614, 21
  %332 = load i64, i64* %RSP, align 8, !tbaa !2428
  %333 = add i64 %332, -8
  %334 = inttoptr i64 %333 to i64*
  store i64 %331, i64* %334, align 8
  store i64 %333, i64* %RSP, align 8, !tbaa !2428
  store i64 %330, i64* %PC, align 8, !alias.scope !2465, !noalias !2468
  %335 = load double, double* %125, align 8, !alias.scope !2465, !noalias !2468
  %336 = load i64, i64* %334, align 8
  store i64 %332, i64* %RSP, align 8, !alias.scope !2465, !noalias !2468
  %337 = tail call double @cos(double %335)
  store i64 0, i64* %126, align 8
  store i64 0, i64* %127, align 8
  store i64 0, i64* %160, align 8
  store i64 0, i64* %161, align 8
  store double %337, double* %125, align 8, !alias.scope !2465, !noalias !2468
  %338 = load i64, i64* %RBP, align 8
  %339 = add i64 %338, -48
  %340 = add i64 %336, 5
  store i64 %340, i64* %PC, align 8
  %341 = inttoptr i64 %339 to double*
  store double %337, double* %341, align 8
  %342 = load i64, i64* %RBP, align 8
  %343 = add i64 %342, -40
  %344 = load i64, i64* %PC, align 8
  %345 = add i64 %344, 5
  store i64 %345, i64* %PC, align 8
  %346 = inttoptr i64 %343 to double*
  %347 = load double, double* %346, align 8
  store double %347, double* %125, align 1, !tbaa !2452
  store double 0.000000e+00, double* %128, align 1, !tbaa !2452
  %348 = add i64 %342, -28
  %349 = add i64 %344, 8
  store i64 %349, i64* %PC, align 8
  %350 = inttoptr i64 %348 to i32*
  %351 = load i32, i32* %350, align 4
  %352 = zext i32 %351 to i64
  store i64 %352, i64* %RAX, align 8, !tbaa !2428
  %353 = sitofp i32 %351 to double
  store double %353, double* %218, align 1, !tbaa !2452
  %354 = fmul double %347, %353
  store double %354, double* %125, align 1, !tbaa !2452
  store i64 0, i64* %127, align 1, !tbaa !2452
  %355 = add i64 %344, -2071
  %356 = add i64 %344, 21
  %357 = load i64, i64* %RSP, align 8, !tbaa !2428
  %358 = add i64 %357, -8
  %359 = inttoptr i64 %358 to i64*
  store i64 %356, i64* %359, align 8
  store i64 %358, i64* %RSP, align 8, !tbaa !2428
  store i64 %355, i64* %PC, align 8, !alias.scope !2470, !noalias !2473
  %360 = load double, double* %125, align 8, !alias.scope !2470, !noalias !2473
  %361 = load i64, i64* %359, align 8
  store i64 %357, i64* %RSP, align 8, !alias.scope !2470, !noalias !2473
  %362 = tail call double @sin(double %360)
  store i64 0, i64* %126, align 8
  store i64 0, i64* %127, align 8
  store i64 0, i64* %160, align 8
  store i64 0, i64* %161, align 8
  store double %362, double* %125, align 8, !alias.scope !2470, !noalias !2473
  %363 = load i64, i64* %RBP, align 8
  %364 = add i64 %363, -56
  %365 = add i64 %361, 5
  store i64 %365, i64* %PC, align 8
  %366 = inttoptr i64 %364 to double*
  store double %362, double* %366, align 8
  %367 = load i64, i64* %RBP, align 8
  %368 = add i64 %367, -48
  %369 = load i64, i64* %PC, align 8
  %370 = add i64 %369, 5
  store i64 %370, i64* %PC, align 8
  %371 = inttoptr i64 %368 to i64*
  %372 = load i64, i64* %371, align 8
  store i64 %372, i64* %126, align 1, !tbaa !2452
  store double 0.000000e+00, double* %128, align 1, !tbaa !2452
  %373 = add i64 %367, -24
  %374 = add i64 %369, 9
  store i64 %374, i64* %PC, align 8
  %375 = inttoptr i64 %373 to i64*
  %376 = load i64, i64* %375, align 8
  store i64 %376, i64* %RCX, align 8, !tbaa !2428
  %377 = add i64 %367, -28
  %378 = add i64 %369, 13
  store i64 %378, i64* %PC, align 8
  %379 = inttoptr i64 %377 to i32*
  %380 = load i32, i32* %379, align 4
  %381 = sext i32 %380 to i64
  store i64 %381, i64* %RDX, align 8, !tbaa !2428
  %382 = shl nsw i64 %381, 3
  %383 = add i64 %382, %376
  %384 = add i64 %369, 18
  store i64 %384, i64* %PC, align 8
  %385 = inttoptr i64 %383 to i64*
  store i64 %372, i64* %385, align 8
  %386 = load i64, i64* %RBP, align 8
  %387 = add i64 %386, -56
  %388 = load i64, i64* %PC, align 8
  %389 = add i64 %388, 5
  store i64 %389, i64* %PC, align 8
  %390 = inttoptr i64 %387 to i64*
  %391 = load i64, i64* %390, align 8
  store i64 %391, i64* %126, align 1, !tbaa !2452
  store double 0.000000e+00, double* %128, align 1, !tbaa !2452
  %392 = add i64 %386, -24
  %393 = add i64 %388, 9
  store i64 %393, i64* %PC, align 8
  %394 = inttoptr i64 %392 to i64*
  %395 = load i64, i64* %394, align 8
  store i64 %395, i64* %RCX, align 8, !tbaa !2428
  %396 = add i64 %386, -28
  %397 = add i64 %388, 12
  store i64 %397, i64* %PC, align 8
  %398 = inttoptr i64 %396 to i32*
  %399 = load i32, i32* %398, align 4
  %400 = add i32 %399, 1
  %401 = zext i32 %400 to i64
  store i64 %401, i64* %RAX, align 8, !tbaa !2428
  %402 = icmp eq i32 %399, -1
  %403 = icmp eq i32 %400, 0
  %404 = or i1 %402, %403
  %405 = zext i1 %404 to i8
  store i8 %405, i8* %16, align 1, !tbaa !2433
  %406 = and i32 %400, 255
  %407 = tail call i32 @llvm.ctpop.i32(i32 %406) #10
  %408 = trunc i32 %407 to i8
  %409 = and i8 %408, 1
  %410 = xor i8 %409, 1
  store i8 %410, i8* %23, align 1, !tbaa !2447
  %411 = xor i32 %399, %400
  %412 = lshr i32 %411, 4
  %413 = trunc i32 %412 to i8
  %414 = and i8 %413, 1
  store i8 %414, i8* %28, align 1, !tbaa !2451
  %415 = zext i1 %403 to i8
  store i8 %415, i8* %31, align 1, !tbaa !2448
  %416 = lshr i32 %400, 31
  %417 = trunc i32 %416 to i8
  store i8 %417, i8* %34, align 1, !tbaa !2449
  %418 = lshr i32 %399, 31
  %419 = xor i32 %416, %418
  %420 = add nuw nsw i32 %419, %416
  %421 = icmp eq i32 %420, 2
  %422 = zext i1 %421 to i8
  store i8 %422, i8* %40, align 1, !tbaa !2450
  %423 = sext i32 %400 to i64
  store i64 %423, i64* %RDX, align 8, !tbaa !2428
  %424 = shl nsw i64 %423, 3
  %425 = add i64 %424, %395
  %426 = add i64 %388, 23
  store i64 %426, i64* %PC, align 8
  %427 = inttoptr i64 %425 to i64*
  store i64 %391, i64* %427, align 8
  %428 = load i64, i64* %RBP, align 8
  %429 = add i64 %428, -56
  %430 = load i64, i64* %PC, align 8
  %431 = add i64 %430, 5
  store i64 %431, i64* %PC, align 8
  %432 = inttoptr i64 %429 to i64*
  %433 = load i64, i64* %432, align 8
  store i64 %433, i64* %126, align 1, !tbaa !2452
  store double 0.000000e+00, double* %128, align 1, !tbaa !2452
  %434 = add i64 %428, -24
  %435 = add i64 %430, 9
  store i64 %435, i64* %PC, align 8
  %436 = inttoptr i64 %434 to i64*
  %437 = load i64, i64* %436, align 8
  store i64 %437, i64* %RCX, align 8, !tbaa !2428
  %438 = add i64 %428, -4
  %439 = add i64 %430, 12
  store i64 %439, i64* %PC, align 8
  %440 = inttoptr i64 %438 to i32*
  %441 = load i32, i32* %440, align 4
  %442 = zext i32 %441 to i64
  store i64 %442, i64* %RAX, align 8, !tbaa !2428
  %443 = add i64 %428, -28
  %444 = add i64 %430, 15
  store i64 %444, i64* %PC, align 8
  %445 = inttoptr i64 %443 to i32*
  %446 = load i32, i32* %445, align 4
  %447 = sub i32 %441, %446
  %448 = zext i32 %447 to i64
  store i64 %448, i64* %RAX, align 8, !tbaa !2428
  %449 = icmp ult i32 %441, %446
  %450 = zext i1 %449 to i8
  store i8 %450, i8* %16, align 1, !tbaa !2433
  %451 = and i32 %447, 255
  %452 = tail call i32 @llvm.ctpop.i32(i32 %451) #10
  %453 = trunc i32 %452 to i8
  %454 = and i8 %453, 1
  %455 = xor i8 %454, 1
  store i8 %455, i8* %23, align 1, !tbaa !2447
  %456 = xor i32 %446, %441
  %457 = xor i32 %456, %447
  %458 = lshr i32 %457, 4
  %459 = trunc i32 %458 to i8
  %460 = and i8 %459, 1
  store i8 %460, i8* %28, align 1, !tbaa !2451
  %461 = icmp eq i32 %447, 0
  %462 = zext i1 %461 to i8
  store i8 %462, i8* %31, align 1, !tbaa !2448
  %463 = lshr i32 %447, 31
  %464 = trunc i32 %463 to i8
  store i8 %464, i8* %34, align 1, !tbaa !2449
  %465 = lshr i32 %441, 31
  %466 = lshr i32 %446, 31
  %467 = xor i32 %466, %465
  %468 = xor i32 %463, %465
  %469 = add nuw nsw i32 %468, %467
  %470 = icmp eq i32 %469, 2
  %471 = zext i1 %470 to i8
  store i8 %471, i8* %40, align 1, !tbaa !2450
  %472 = sext i32 %447 to i64
  store i64 %472, i64* %RDX, align 8, !tbaa !2428
  %473 = shl nsw i64 %472, 3
  %474 = add i64 %473, %437
  %475 = add i64 %430, 23
  store i64 %475, i64* %PC, align 8
  %476 = inttoptr i64 %474 to i64*
  store i64 %433, i64* %476, align 8
  %477 = load i64, i64* %RBP, align 8
  %478 = add i64 %477, -48
  %479 = load i64, i64* %PC, align 8
  %480 = add i64 %479, 5
  store i64 %480, i64* %PC, align 8
  %481 = inttoptr i64 %478 to i64*
  %482 = load i64, i64* %481, align 8
  store i64 %482, i64* %126, align 1, !tbaa !2452
  store double 0.000000e+00, double* %128, align 1, !tbaa !2452
  %483 = add i64 %477, -24
  %484 = add i64 %479, 9
  store i64 %484, i64* %PC, align 8
  %485 = inttoptr i64 %483 to i64*
  %486 = load i64, i64* %485, align 8
  store i64 %486, i64* %RCX, align 8, !tbaa !2428
  %487 = add i64 %477, -4
  %488 = add i64 %479, 12
  store i64 %488, i64* %PC, align 8
  %489 = inttoptr i64 %487 to i32*
  %490 = load i32, i32* %489, align 4
  %491 = zext i32 %490 to i64
  store i64 %491, i64* %RAX, align 8, !tbaa !2428
  %492 = add i64 %477, -28
  %493 = add i64 %479, 15
  store i64 %493, i64* %PC, align 8
  %494 = inttoptr i64 %492 to i32*
  %495 = load i32, i32* %494, align 4
  %496 = sub i32 %490, %495
  %497 = lshr i32 %496, 31
  %498 = add i32 %496, 1
  %499 = zext i32 %498 to i64
  store i64 %499, i64* %RAX, align 8, !tbaa !2428
  %500 = icmp eq i32 %496, -1
  %501 = icmp eq i32 %498, 0
  %502 = or i1 %500, %501
  %503 = zext i1 %502 to i8
  store i8 %503, i8* %16, align 1, !tbaa !2433
  %504 = and i32 %498, 255
  %505 = tail call i32 @llvm.ctpop.i32(i32 %504) #10
  %506 = trunc i32 %505 to i8
  %507 = and i8 %506, 1
  %508 = xor i8 %507, 1
  store i8 %508, i8* %23, align 1, !tbaa !2447
  %509 = xor i32 %496, %498
  %510 = lshr i32 %509, 4
  %511 = trunc i32 %510 to i8
  %512 = and i8 %511, 1
  store i8 %512, i8* %28, align 1, !tbaa !2451
  %513 = zext i1 %501 to i8
  store i8 %513, i8* %31, align 1, !tbaa !2448
  %514 = lshr i32 %498, 31
  %515 = trunc i32 %514 to i8
  store i8 %515, i8* %34, align 1, !tbaa !2449
  %516 = xor i32 %514, %497
  %517 = add nuw nsw i32 %516, %514
  %518 = icmp eq i32 %517, 2
  %519 = zext i1 %518 to i8
  store i8 %519, i8* %40, align 1, !tbaa !2450
  %520 = sext i32 %498 to i64
  store i64 %520, i64* %RDX, align 8, !tbaa !2428
  %521 = shl nsw i64 %520, 3
  %522 = add i64 %521, %486
  %523 = add i64 %479, 26
  store i64 %523, i64* %PC, align 8
  %524 = inttoptr i64 %522 to i64*
  store i64 %482, i64* %524, align 8
  %525 = load i64, i64* %RBP, align 8
  %526 = add i64 %525, -28
  %527 = load i64, i64* %PC, align 8
  %528 = add i64 %527, 3
  store i64 %528, i64* %PC, align 8
  %529 = inttoptr i64 %526 to i32*
  %530 = load i32, i32* %529, align 4
  %531 = add i32 %530, 2
  %532 = zext i32 %531 to i64
  store i64 %532, i64* %RAX, align 8, !tbaa !2428
  %533 = icmp ugt i32 %530, -3
  %534 = zext i1 %533 to i8
  store i8 %534, i8* %16, align 1, !tbaa !2433
  %535 = and i32 %531, 255
  %536 = tail call i32 @llvm.ctpop.i32(i32 %535) #10
  %537 = trunc i32 %536 to i8
  %538 = and i8 %537, 1
  %539 = xor i8 %538, 1
  store i8 %539, i8* %23, align 1, !tbaa !2447
  %540 = xor i32 %530, %531
  %541 = lshr i32 %540, 4
  %542 = trunc i32 %541 to i8
  %543 = and i8 %542, 1
  store i8 %543, i8* %28, align 1, !tbaa !2451
  %544 = icmp eq i32 %531, 0
  %545 = zext i1 %544 to i8
  store i8 %545, i8* %31, align 1, !tbaa !2448
  %546 = lshr i32 %531, 31
  %547 = trunc i32 %546 to i8
  store i8 %547, i8* %34, align 1, !tbaa !2449
  %548 = lshr i32 %530, 31
  %549 = xor i32 %546, %548
  %550 = add nuw nsw i32 %549, %546
  %551 = icmp eq i32 %550, 2
  %552 = zext i1 %551 to i8
  store i8 %552, i8* %40, align 1, !tbaa !2450
  %553 = add i64 %527, 9
  store i64 %553, i64* %PC, align 8
  store i32 %531, i32* %529, align 4
  %554 = load i64, i64* %PC, align 8
  %555 = add i64 %554, -163
  store i64 %555, i64* %PC, align 8, !tbaa !2428
  br label %block_400ee1

block_400f89:                                     ; preds = %block_400ee1
  %556 = add i64 %578, -4
  %557 = add i64 %614, 3
  store i64 %557, i64* %PC, align 8
  %558 = inttoptr i64 %556 to i32*
  %559 = load i32, i32* %558, align 4
  %560 = zext i32 %559 to i64
  store i64 %560, i64* %RDI, align 8, !tbaa !2428
  %561 = add i64 %578, -16
  %562 = add i64 %614, 7
  store i64 %562, i64* %PC, align 8
  %563 = inttoptr i64 %561 to i64*
  %564 = load i64, i64* %563, align 8
  store i64 %564, i64* %RSI, align 8, !tbaa !2428
  %565 = add i64 %578, -24
  %566 = add i64 %614, 11
  store i64 %566, i64* %PC, align 8
  %567 = inttoptr i64 %565 to i64*
  %568 = load i64, i64* %567, align 8
  store i64 %568, i64* %RDX, align 8, !tbaa !2428
  %569 = add i64 %614, 567
  %570 = add i64 %614, 16
  %571 = load i64, i64* %RSP, align 8, !tbaa !2428
  %572 = add i64 %571, -8
  %573 = inttoptr i64 %572 to i64*
  store i64 %570, i64* %573, align 8
  store i64 %572, i64* %RSP, align 8, !tbaa !2428
  store i64 %569, i64* %PC, align 8, !tbaa !2428
  %574 = tail call %struct.Memory* @sub_4011c0_bitrv2_renamed_(%struct.State* nonnull %0, i64 %569, %struct.Memory* %2)
  %.pre1 = load i64, i64* %PC, align 8
  br label %block_400f99

block_400f99:                                     ; preds = %block_400f89, %block_400e4d
  %575 = phi i64 [ %320, %block_400e4d ], [ %.pre1, %block_400f89 ]
  %MEMORY.1 = phi %struct.Memory* [ %2, %block_400e4d ], [ %574, %block_400f89 ]
  %576 = add i64 %575, 5
  store i64 %576, i64* %PC, align 8, !tbaa !2428
  br label %block_400f9e

block_400ee1:                                     ; preds = %block_400eed, %block_400eda
  %577 = phi i64 [ %555, %block_400eed ], [ %.pre, %block_400eda ]
  %578 = load i64, i64* %RBP, align 8
  %579 = add i64 %578, -28
  %580 = add i64 %577, 3
  store i64 %580, i64* %PC, align 8
  %581 = inttoptr i64 %579 to i32*
  %582 = load i32, i32* %581, align 4
  %583 = zext i32 %582 to i64
  store i64 %583, i64* %RAX, align 8, !tbaa !2428
  %584 = add i64 %578, -32
  %585 = add i64 %577, 6
  store i64 %585, i64* %PC, align 8
  %586 = inttoptr i64 %584 to i32*
  %587 = load i32, i32* %586, align 4
  %588 = sub i32 %582, %587
  %589 = icmp ult i32 %582, %587
  %590 = zext i1 %589 to i8
  store i8 %590, i8* %16, align 1, !tbaa !2433
  %591 = and i32 %588, 255
  %592 = tail call i32 @llvm.ctpop.i32(i32 %591) #10
  %593 = trunc i32 %592 to i8
  %594 = and i8 %593, 1
  %595 = xor i8 %594, 1
  store i8 %595, i8* %23, align 1, !tbaa !2447
  %596 = xor i32 %587, %582
  %597 = xor i32 %596, %588
  %598 = lshr i32 %597, 4
  %599 = trunc i32 %598 to i8
  %600 = and i8 %599, 1
  store i8 %600, i8* %28, align 1, !tbaa !2451
  %601 = icmp eq i32 %588, 0
  %602 = zext i1 %601 to i8
  store i8 %602, i8* %31, align 1, !tbaa !2448
  %603 = lshr i32 %588, 31
  %604 = trunc i32 %603 to i8
  store i8 %604, i8* %34, align 1, !tbaa !2449
  %605 = lshr i32 %582, 31
  %606 = lshr i32 %587, 31
  %607 = xor i32 %606, %605
  %608 = xor i32 %603, %605
  %609 = add nuw nsw i32 %608, %607
  %610 = icmp eq i32 %609, 2
  %611 = zext i1 %610 to i8
  store i8 %611, i8* %40, align 1, !tbaa !2450
  %612 = icmp ne i8 %604, 0
  %613 = xor i1 %612, %610
  %.v10 = select i1 %613, i64 12, i64 168
  %614 = add i64 %577, %.v10
  store i64 %614, i64* %PC, align 8, !tbaa !2428
  br i1 %613, label %block_400eed, label %block_400f89
}

; Function Attrs: noinline
define %struct.Memory* @sub_404060___libc_csu_fini(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_404060:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = add i64 %1, 2
  store i64 %3, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !2428
  %6 = inttoptr i64 %5 to i64*
  %7 = load i64, i64* %6, align 8
  store i64 %7, i64* %PC, align 8, !tbaa !2428
  %8 = add i64 %5, 8
  store i64 %8, i64* %4, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_401840_cftfsub(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_401840:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -120
  store i64 %11, i64* %RSP, align 8, !tbaa !2428
  %12 = icmp ult i64 %8, 112
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1, !tbaa !2433
  %15 = trunc i64 %11 to i32
  %16 = and i32 %15, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16) #10
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1, !tbaa !2447
  %22 = xor i64 %8, 16
  %23 = xor i64 %22, %11
  %24 = lshr i64 %23, 4
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1, !tbaa !2451
  %28 = icmp eq i64 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1, !tbaa !2448
  %31 = lshr i64 %11, 63
  %32 = trunc i64 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1, !tbaa !2449
  %34 = lshr i64 %8, 63
  %35 = xor i64 %31, %34
  %36 = add nuw nsw i64 %35, %34
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1, !tbaa !2450
  %40 = add i64 %7, -12
  %41 = load i32, i32* %EDI, align 4
  %42 = add i64 %10, 10
  store i64 %42, i64* %PC, align 8
  %43 = inttoptr i64 %40 to i32*
  store i32 %41, i32* %43, align 4
  %44 = load i64, i64* %RBP, align 8
  %45 = add i64 %44, -16
  %46 = load i64, i64* %RSI, align 8
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 4
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %45 to i64*
  store i64 %46, i64* %49, align 8
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -24
  %52 = load i64, i64* %RDX, align 8
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 4
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %51 to i64*
  store i64 %52, i64* %55, align 8
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -44
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 7
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %57 to i32*
  store i32 2, i32* %60, align 4
  %61 = load i64, i64* %RBP, align 8
  %62 = add i64 %61, -4
  %63 = load i64, i64* %PC, align 8
  %64 = add i64 %63, 4
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %62 to i32*
  %66 = load i32, i32* %65, align 4
  %67 = add i32 %66, -8
  %68 = icmp ult i32 %66, 8
  %69 = zext i1 %68 to i8
  store i8 %69, i8* %14, align 1, !tbaa !2433
  %70 = and i32 %67, 255
  %71 = tail call i32 @llvm.ctpop.i32(i32 %70) #10
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  %74 = xor i8 %73, 1
  store i8 %74, i8* %21, align 1, !tbaa !2447
  %75 = xor i32 %66, %67
  %76 = lshr i32 %75, 4
  %77 = trunc i32 %76 to i8
  %78 = and i8 %77, 1
  store i8 %78, i8* %27, align 1, !tbaa !2451
  %79 = icmp eq i32 %67, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %30, align 1, !tbaa !2448
  %81 = lshr i32 %67, 31
  %82 = trunc i32 %81 to i8
  store i8 %82, i8* %33, align 1, !tbaa !2449
  %83 = lshr i32 %66, 31
  %84 = xor i32 %81, %83
  %85 = add nuw nsw i32 %84, %83
  %86 = icmp eq i32 %85, 2
  %87 = zext i1 %86 to i8
  store i8 %87, i8* %39, align 1, !tbaa !2450
  %88 = icmp ne i8 %82, 0
  %89 = xor i1 %88, %86
  %90 = or i1 %79, %89
  %.v = select i1 %90, i64 86, i64 10
  %91 = add i64 %63, %.v
  store i64 %91, i64* %PC, align 8, !tbaa !2428
  br i1 %90, label %block_4018b0, label %block_401864

block_401af3:                                     ; preds = %block_4018b0, %block_401aff
  %92 = phi i64 [ %1458, %block_401aff ], [ %.pre2, %block_4018b0 ]
  %93 = load i64, i64* %RBP, align 8
  %94 = add i64 %93, -28
  %95 = add i64 %92, 3
  store i64 %95, i64* %PC, align 8
  %96 = inttoptr i64 %94 to i32*
  %97 = load i32, i32* %96, align 4
  %98 = zext i32 %97 to i64
  store i64 %98, i64* %RAX, align 8, !tbaa !2428
  %99 = add i64 %93, -44
  %100 = add i64 %92, 6
  store i64 %100, i64* %PC, align 8
  %101 = inttoptr i64 %99 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = sub i32 %97, %102
  %104 = icmp ult i32 %97, %102
  %105 = zext i1 %104 to i8
  store i8 %105, i8* %14, align 1, !tbaa !2433
  %106 = and i32 %103, 255
  %107 = tail call i32 @llvm.ctpop.i32(i32 %106) #10
  %108 = trunc i32 %107 to i8
  %109 = and i8 %108, 1
  %110 = xor i8 %109, 1
  store i8 %110, i8* %21, align 1, !tbaa !2447
  %111 = xor i32 %102, %97
  %112 = xor i32 %111, %103
  %113 = lshr i32 %112, 4
  %114 = trunc i32 %113 to i8
  %115 = and i8 %114, 1
  store i8 %115, i8* %27, align 1, !tbaa !2451
  %116 = icmp eq i32 %103, 0
  %117 = zext i1 %116 to i8
  store i8 %117, i8* %30, align 1, !tbaa !2448
  %118 = lshr i32 %103, 31
  %119 = trunc i32 %118 to i8
  store i8 %119, i8* %33, align 1, !tbaa !2449
  %120 = lshr i32 %97, 31
  %121 = lshr i32 %102, 31
  %122 = xor i32 %121, %120
  %123 = xor i32 %118, %120
  %124 = add nuw nsw i32 %123, %122
  %125 = icmp eq i32 %124, 2
  %126 = zext i1 %125 to i8
  store i8 %126, i8* %39, align 1, !tbaa !2450
  %127 = icmp ne i8 %119, 0
  %128 = xor i1 %127, %125
  %.v7 = select i1 %128, i64 12, i64 220
  %129 = add i64 %92, %.v7
  store i64 %129, i64* %PC, align 8, !tbaa !2428
  br i1 %128, label %block_401aff, label %block_401bcf

block_4018d2:                                     ; preds = %block_4018c6
  %130 = add i64 %1573, 3
  store i64 %130, i64* %PC, align 8
  %131 = load i32, i32* %1540, align 4
  %132 = zext i32 %131 to i64
  store i64 %132, i64* %RAX, align 8, !tbaa !2428
  %133 = add i64 %1573, 6
  store i64 %133, i64* %PC, align 8
  %134 = load i32, i32* %1545, align 4
  %135 = add i32 %134, %131
  %136 = zext i32 %135 to i64
  store i64 %136, i64* %RAX, align 8, !tbaa !2428
  %137 = icmp ult i32 %135, %131
  %138 = icmp ult i32 %135, %134
  %139 = or i1 %137, %138
  %140 = zext i1 %139 to i8
  store i8 %140, i8* %14, align 1, !tbaa !2433
  %141 = and i32 %135, 255
  %142 = tail call i32 @llvm.ctpop.i32(i32 %141) #10
  %143 = trunc i32 %142 to i8
  %144 = and i8 %143, 1
  %145 = xor i8 %144, 1
  store i8 %145, i8* %21, align 1, !tbaa !2447
  %146 = xor i32 %134, %131
  %147 = xor i32 %146, %135
  %148 = lshr i32 %147, 4
  %149 = trunc i32 %148 to i8
  %150 = and i8 %149, 1
  store i8 %150, i8* %27, align 1, !tbaa !2451
  %151 = icmp eq i32 %135, 0
  %152 = zext i1 %151 to i8
  store i8 %152, i8* %30, align 1, !tbaa !2448
  %153 = lshr i32 %135, 31
  %154 = trunc i32 %153 to i8
  store i8 %154, i8* %33, align 1, !tbaa !2449
  %155 = lshr i32 %131, 31
  %156 = lshr i32 %134, 31
  %157 = xor i32 %153, %155
  %158 = xor i32 %153, %156
  %159 = add nuw nsw i32 %157, %158
  %160 = icmp eq i32 %159, 2
  %161 = zext i1 %160 to i8
  store i8 %161, i8* %39, align 1, !tbaa !2450
  %162 = add i64 %1537, -32
  %163 = add i64 %1573, 9
  store i64 %163, i64* %PC, align 8
  %164 = inttoptr i64 %162 to i32*
  store i32 %135, i32* %164, align 4
  %165 = load i64, i64* %RBP, align 8
  %166 = add i64 %165, -32
  %167 = load i64, i64* %PC, align 8
  %168 = add i64 %167, 3
  store i64 %168, i64* %PC, align 8
  %169 = inttoptr i64 %166 to i32*
  %170 = load i32, i32* %169, align 4
  %171 = zext i32 %170 to i64
  store i64 %171, i64* %RAX, align 8, !tbaa !2428
  %172 = add i64 %165, -44
  %173 = add i64 %167, 6
  store i64 %173, i64* %PC, align 8
  %174 = inttoptr i64 %172 to i32*
  %175 = load i32, i32* %174, align 4
  %176 = add i32 %175, %170
  %177 = zext i32 %176 to i64
  store i64 %177, i64* %RAX, align 8, !tbaa !2428
  %178 = icmp ult i32 %176, %170
  %179 = icmp ult i32 %176, %175
  %180 = or i1 %178, %179
  %181 = zext i1 %180 to i8
  store i8 %181, i8* %14, align 1, !tbaa !2433
  %182 = and i32 %176, 255
  %183 = tail call i32 @llvm.ctpop.i32(i32 %182) #10
  %184 = trunc i32 %183 to i8
  %185 = and i8 %184, 1
  %186 = xor i8 %185, 1
  store i8 %186, i8* %21, align 1, !tbaa !2447
  %187 = xor i32 %175, %170
  %188 = xor i32 %187, %176
  %189 = lshr i32 %188, 4
  %190 = trunc i32 %189 to i8
  %191 = and i8 %190, 1
  store i8 %191, i8* %27, align 1, !tbaa !2451
  %192 = icmp eq i32 %176, 0
  %193 = zext i1 %192 to i8
  store i8 %193, i8* %30, align 1, !tbaa !2448
  %194 = lshr i32 %176, 31
  %195 = trunc i32 %194 to i8
  store i8 %195, i8* %33, align 1, !tbaa !2449
  %196 = lshr i32 %170, 31
  %197 = lshr i32 %175, 31
  %198 = xor i32 %194, %196
  %199 = xor i32 %194, %197
  %200 = add nuw nsw i32 %198, %199
  %201 = icmp eq i32 %200, 2
  %202 = zext i1 %201 to i8
  store i8 %202, i8* %39, align 1, !tbaa !2450
  %203 = add i64 %165, -36
  %204 = add i64 %167, 9
  store i64 %204, i64* %PC, align 8
  %205 = inttoptr i64 %203 to i32*
  store i32 %176, i32* %205, align 4
  %206 = load i64, i64* %RBP, align 8
  %207 = add i64 %206, -36
  %208 = load i64, i64* %PC, align 8
  %209 = add i64 %208, 3
  store i64 %209, i64* %PC, align 8
  %210 = inttoptr i64 %207 to i32*
  %211 = load i32, i32* %210, align 4
  %212 = zext i32 %211 to i64
  store i64 %212, i64* %RAX, align 8, !tbaa !2428
  %213 = add i64 %206, -44
  %214 = add i64 %208, 6
  store i64 %214, i64* %PC, align 8
  %215 = inttoptr i64 %213 to i32*
  %216 = load i32, i32* %215, align 4
  %217 = add i32 %216, %211
  %218 = zext i32 %217 to i64
  store i64 %218, i64* %RAX, align 8, !tbaa !2428
  %219 = icmp ult i32 %217, %211
  %220 = icmp ult i32 %217, %216
  %221 = or i1 %219, %220
  %222 = zext i1 %221 to i8
  store i8 %222, i8* %14, align 1, !tbaa !2433
  %223 = and i32 %217, 255
  %224 = tail call i32 @llvm.ctpop.i32(i32 %223) #10
  %225 = trunc i32 %224 to i8
  %226 = and i8 %225, 1
  %227 = xor i8 %226, 1
  store i8 %227, i8* %21, align 1, !tbaa !2447
  %228 = xor i32 %216, %211
  %229 = xor i32 %228, %217
  %230 = lshr i32 %229, 4
  %231 = trunc i32 %230 to i8
  %232 = and i8 %231, 1
  store i8 %232, i8* %27, align 1, !tbaa !2451
  %233 = icmp eq i32 %217, 0
  %234 = zext i1 %233 to i8
  store i8 %234, i8* %30, align 1, !tbaa !2448
  %235 = lshr i32 %217, 31
  %236 = trunc i32 %235 to i8
  store i8 %236, i8* %33, align 1, !tbaa !2449
  %237 = lshr i32 %211, 31
  %238 = lshr i32 %216, 31
  %239 = xor i32 %235, %237
  %240 = xor i32 %235, %238
  %241 = add nuw nsw i32 %239, %240
  %242 = icmp eq i32 %241, 2
  %243 = zext i1 %242 to i8
  store i8 %243, i8* %39, align 1, !tbaa !2450
  %244 = add i64 %206, -40
  %245 = add i64 %208, 9
  store i64 %245, i64* %PC, align 8
  %246 = inttoptr i64 %244 to i32*
  store i32 %217, i32* %246, align 4
  %247 = load i64, i64* %RBP, align 8
  %248 = add i64 %247, -16
  %249 = load i64, i64* %PC, align 8
  %250 = add i64 %249, 4
  store i64 %250, i64* %PC, align 8
  %251 = inttoptr i64 %248 to i64*
  %252 = load i64, i64* %251, align 8
  store i64 %252, i64* %RCX, align 8, !tbaa !2428
  %253 = add i64 %247, -28
  %254 = add i64 %249, 8
  store i64 %254, i64* %PC, align 8
  %255 = inttoptr i64 %253 to i32*
  %256 = load i32, i32* %255, align 4
  %257 = sext i32 %256 to i64
  store i64 %257, i64* %RDX, align 8, !tbaa !2428
  %258 = shl nsw i64 %257, 3
  %259 = add i64 %258, %252
  %260 = add i64 %249, 13
  store i64 %260, i64* %PC, align 8
  %261 = inttoptr i64 %259 to double*
  %262 = load double, double* %261, align 8
  store double %262, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %263 = add i64 %249, 17
  store i64 %263, i64* %PC, align 8
  %264 = load i64, i64* %251, align 8
  store i64 %264, i64* %RCX, align 8, !tbaa !2428
  %265 = add i64 %247, -32
  %266 = add i64 %249, 21
  store i64 %266, i64* %PC, align 8
  %267 = inttoptr i64 %265 to i32*
  %268 = load i32, i32* %267, align 4
  %269 = sext i32 %268 to i64
  store i64 %269, i64* %RDX, align 8, !tbaa !2428
  %270 = shl nsw i64 %269, 3
  %271 = add i64 %270, %264
  %272 = add i64 %249, 26
  store i64 %272, i64* %PC, align 8
  %273 = inttoptr i64 %271 to double*
  %274 = load double, double* %273, align 8
  %275 = fadd double %262, %274
  store double %275, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %276 = add i64 %247, -56
  %277 = add i64 %249, 31
  store i64 %277, i64* %PC, align 8
  %278 = inttoptr i64 %276 to double*
  store double %275, double* %278, align 8
  %279 = load i64, i64* %RBP, align 8
  %280 = add i64 %279, -16
  %281 = load i64, i64* %PC, align 8
  %282 = add i64 %281, 4
  store i64 %282, i64* %PC, align 8
  %283 = inttoptr i64 %280 to i64*
  %284 = load i64, i64* %283, align 8
  store i64 %284, i64* %RCX, align 8, !tbaa !2428
  %285 = add i64 %279, -28
  %286 = add i64 %281, 7
  store i64 %286, i64* %PC, align 8
  %287 = inttoptr i64 %285 to i32*
  %288 = load i32, i32* %287, align 4
  %289 = add i32 %288, 1
  %290 = zext i32 %289 to i64
  store i64 %290, i64* %RAX, align 8, !tbaa !2428
  %291 = icmp eq i32 %288, -1
  %292 = icmp eq i32 %289, 0
  %293 = or i1 %291, %292
  %294 = zext i1 %293 to i8
  store i8 %294, i8* %14, align 1, !tbaa !2433
  %295 = and i32 %289, 255
  %296 = tail call i32 @llvm.ctpop.i32(i32 %295) #10
  %297 = trunc i32 %296 to i8
  %298 = and i8 %297, 1
  %299 = xor i8 %298, 1
  store i8 %299, i8* %21, align 1, !tbaa !2447
  %300 = xor i32 %288, %289
  %301 = lshr i32 %300, 4
  %302 = trunc i32 %301 to i8
  %303 = and i8 %302, 1
  store i8 %303, i8* %27, align 1, !tbaa !2451
  %304 = zext i1 %292 to i8
  store i8 %304, i8* %30, align 1, !tbaa !2448
  %305 = lshr i32 %289, 31
  %306 = trunc i32 %305 to i8
  store i8 %306, i8* %33, align 1, !tbaa !2449
  %307 = lshr i32 %288, 31
  %308 = xor i32 %305, %307
  %309 = add nuw nsw i32 %308, %305
  %310 = icmp eq i32 %309, 2
  %311 = zext i1 %310 to i8
  store i8 %311, i8* %39, align 1, !tbaa !2450
  %312 = sext i32 %289 to i64
  store i64 %312, i64* %RDX, align 8, !tbaa !2428
  %313 = shl nsw i64 %312, 3
  %314 = add i64 %313, %284
  %315 = add i64 %281, 18
  store i64 %315, i64* %PC, align 8
  %316 = inttoptr i64 %314 to double*
  %317 = load double, double* %316, align 8
  store double %317, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %318 = add i64 %281, 22
  store i64 %318, i64* %PC, align 8
  %319 = load i64, i64* %283, align 8
  store i64 %319, i64* %RCX, align 8, !tbaa !2428
  %320 = add i64 %279, -32
  %321 = add i64 %281, 25
  store i64 %321, i64* %PC, align 8
  %322 = inttoptr i64 %320 to i32*
  %323 = load i32, i32* %322, align 4
  %324 = add i32 %323, 1
  %325 = zext i32 %324 to i64
  store i64 %325, i64* %RAX, align 8, !tbaa !2428
  %326 = icmp eq i32 %323, -1
  %327 = icmp eq i32 %324, 0
  %328 = or i1 %326, %327
  %329 = zext i1 %328 to i8
  store i8 %329, i8* %14, align 1, !tbaa !2433
  %330 = and i32 %324, 255
  %331 = tail call i32 @llvm.ctpop.i32(i32 %330) #10
  %332 = trunc i32 %331 to i8
  %333 = and i8 %332, 1
  %334 = xor i8 %333, 1
  store i8 %334, i8* %21, align 1, !tbaa !2447
  %335 = xor i32 %323, %324
  %336 = lshr i32 %335, 4
  %337 = trunc i32 %336 to i8
  %338 = and i8 %337, 1
  store i8 %338, i8* %27, align 1, !tbaa !2451
  %339 = zext i1 %327 to i8
  store i8 %339, i8* %30, align 1, !tbaa !2448
  %340 = lshr i32 %324, 31
  %341 = trunc i32 %340 to i8
  store i8 %341, i8* %33, align 1, !tbaa !2449
  %342 = lshr i32 %323, 31
  %343 = xor i32 %340, %342
  %344 = add nuw nsw i32 %343, %340
  %345 = icmp eq i32 %344, 2
  %346 = zext i1 %345 to i8
  store i8 %346, i8* %39, align 1, !tbaa !2450
  %347 = sext i32 %324 to i64
  store i64 %347, i64* %RDX, align 8, !tbaa !2428
  %348 = shl nsw i64 %347, 3
  %349 = add i64 %348, %319
  %350 = add i64 %281, 36
  store i64 %350, i64* %PC, align 8
  %351 = inttoptr i64 %349 to double*
  %352 = load double, double* %351, align 8
  %353 = fadd double %317, %352
  store double %353, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %354 = load i64, i64* %RBP, align 8
  %355 = add i64 %354, -64
  %356 = add i64 %281, 41
  store i64 %356, i64* %PC, align 8
  %357 = inttoptr i64 %355 to double*
  store double %353, double* %357, align 8
  %358 = load i64, i64* %RBP, align 8
  %359 = add i64 %358, -16
  %360 = load i64, i64* %PC, align 8
  %361 = add i64 %360, 4
  store i64 %361, i64* %PC, align 8
  %362 = inttoptr i64 %359 to i64*
  %363 = load i64, i64* %362, align 8
  store i64 %363, i64* %RCX, align 8, !tbaa !2428
  %364 = add i64 %358, -28
  %365 = add i64 %360, 8
  store i64 %365, i64* %PC, align 8
  %366 = inttoptr i64 %364 to i32*
  %367 = load i32, i32* %366, align 4
  %368 = sext i32 %367 to i64
  store i64 %368, i64* %RDX, align 8, !tbaa !2428
  %369 = shl nsw i64 %368, 3
  %370 = add i64 %369, %363
  %371 = add i64 %360, 13
  store i64 %371, i64* %PC, align 8
  %372 = inttoptr i64 %370 to double*
  %373 = load double, double* %372, align 8
  store double %373, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %374 = add i64 %360, 17
  store i64 %374, i64* %PC, align 8
  %375 = load i64, i64* %362, align 8
  store i64 %375, i64* %RCX, align 8, !tbaa !2428
  %376 = add i64 %358, -32
  %377 = add i64 %360, 21
  store i64 %377, i64* %PC, align 8
  %378 = inttoptr i64 %376 to i32*
  %379 = load i32, i32* %378, align 4
  %380 = sext i32 %379 to i64
  store i64 %380, i64* %RDX, align 8, !tbaa !2428
  %381 = shl nsw i64 %380, 3
  %382 = add i64 %381, %375
  %383 = add i64 %360, 26
  store i64 %383, i64* %PC, align 8
  %384 = inttoptr i64 %382 to double*
  %385 = load double, double* %384, align 8
  %386 = fsub double %373, %385
  store double %386, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %387 = add i64 %358, -72
  %388 = add i64 %360, 31
  store i64 %388, i64* %PC, align 8
  %389 = inttoptr i64 %387 to double*
  store double %386, double* %389, align 8
  %390 = load i64, i64* %RBP, align 8
  %391 = add i64 %390, -16
  %392 = load i64, i64* %PC, align 8
  %393 = add i64 %392, 4
  store i64 %393, i64* %PC, align 8
  %394 = inttoptr i64 %391 to i64*
  %395 = load i64, i64* %394, align 8
  store i64 %395, i64* %RCX, align 8, !tbaa !2428
  %396 = add i64 %390, -28
  %397 = add i64 %392, 7
  store i64 %397, i64* %PC, align 8
  %398 = inttoptr i64 %396 to i32*
  %399 = load i32, i32* %398, align 4
  %400 = add i32 %399, 1
  %401 = zext i32 %400 to i64
  store i64 %401, i64* %RAX, align 8, !tbaa !2428
  %402 = icmp eq i32 %399, -1
  %403 = icmp eq i32 %400, 0
  %404 = or i1 %402, %403
  %405 = zext i1 %404 to i8
  store i8 %405, i8* %14, align 1, !tbaa !2433
  %406 = and i32 %400, 255
  %407 = tail call i32 @llvm.ctpop.i32(i32 %406) #10
  %408 = trunc i32 %407 to i8
  %409 = and i8 %408, 1
  %410 = xor i8 %409, 1
  store i8 %410, i8* %21, align 1, !tbaa !2447
  %411 = xor i32 %399, %400
  %412 = lshr i32 %411, 4
  %413 = trunc i32 %412 to i8
  %414 = and i8 %413, 1
  store i8 %414, i8* %27, align 1, !tbaa !2451
  %415 = zext i1 %403 to i8
  store i8 %415, i8* %30, align 1, !tbaa !2448
  %416 = lshr i32 %400, 31
  %417 = trunc i32 %416 to i8
  store i8 %417, i8* %33, align 1, !tbaa !2449
  %418 = lshr i32 %399, 31
  %419 = xor i32 %416, %418
  %420 = add nuw nsw i32 %419, %416
  %421 = icmp eq i32 %420, 2
  %422 = zext i1 %421 to i8
  store i8 %422, i8* %39, align 1, !tbaa !2450
  %423 = sext i32 %400 to i64
  store i64 %423, i64* %RDX, align 8, !tbaa !2428
  %424 = shl nsw i64 %423, 3
  %425 = add i64 %424, %395
  %426 = add i64 %392, 18
  store i64 %426, i64* %PC, align 8
  %427 = inttoptr i64 %425 to double*
  %428 = load double, double* %427, align 8
  store double %428, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %429 = add i64 %392, 22
  store i64 %429, i64* %PC, align 8
  %430 = load i64, i64* %394, align 8
  store i64 %430, i64* %RCX, align 8, !tbaa !2428
  %431 = add i64 %390, -32
  %432 = add i64 %392, 25
  store i64 %432, i64* %PC, align 8
  %433 = inttoptr i64 %431 to i32*
  %434 = load i32, i32* %433, align 4
  %435 = add i32 %434, 1
  %436 = zext i32 %435 to i64
  store i64 %436, i64* %RAX, align 8, !tbaa !2428
  %437 = icmp eq i32 %434, -1
  %438 = icmp eq i32 %435, 0
  %439 = or i1 %437, %438
  %440 = zext i1 %439 to i8
  store i8 %440, i8* %14, align 1, !tbaa !2433
  %441 = and i32 %435, 255
  %442 = tail call i32 @llvm.ctpop.i32(i32 %441) #10
  %443 = trunc i32 %442 to i8
  %444 = and i8 %443, 1
  %445 = xor i8 %444, 1
  store i8 %445, i8* %21, align 1, !tbaa !2447
  %446 = xor i32 %434, %435
  %447 = lshr i32 %446, 4
  %448 = trunc i32 %447 to i8
  %449 = and i8 %448, 1
  store i8 %449, i8* %27, align 1, !tbaa !2451
  %450 = zext i1 %438 to i8
  store i8 %450, i8* %30, align 1, !tbaa !2448
  %451 = lshr i32 %435, 31
  %452 = trunc i32 %451 to i8
  store i8 %452, i8* %33, align 1, !tbaa !2449
  %453 = lshr i32 %434, 31
  %454 = xor i32 %451, %453
  %455 = add nuw nsw i32 %454, %451
  %456 = icmp eq i32 %455, 2
  %457 = zext i1 %456 to i8
  store i8 %457, i8* %39, align 1, !tbaa !2450
  %458 = sext i32 %435 to i64
  store i64 %458, i64* %RDX, align 8, !tbaa !2428
  %459 = shl nsw i64 %458, 3
  %460 = add i64 %459, %430
  %461 = add i64 %392, 36
  store i64 %461, i64* %PC, align 8
  %462 = inttoptr i64 %460 to double*
  %463 = load double, double* %462, align 8
  %464 = fsub double %428, %463
  store double %464, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %465 = load i64, i64* %RBP, align 8
  %466 = add i64 %465, -80
  %467 = add i64 %392, 41
  store i64 %467, i64* %PC, align 8
  %468 = inttoptr i64 %466 to double*
  store double %464, double* %468, align 8
  %469 = load i64, i64* %RBP, align 8
  %470 = add i64 %469, -16
  %471 = load i64, i64* %PC, align 8
  %472 = add i64 %471, 4
  store i64 %472, i64* %PC, align 8
  %473 = inttoptr i64 %470 to i64*
  %474 = load i64, i64* %473, align 8
  store i64 %474, i64* %RCX, align 8, !tbaa !2428
  %475 = add i64 %469, -36
  %476 = add i64 %471, 8
  store i64 %476, i64* %PC, align 8
  %477 = inttoptr i64 %475 to i32*
  %478 = load i32, i32* %477, align 4
  %479 = sext i32 %478 to i64
  store i64 %479, i64* %RDX, align 8, !tbaa !2428
  %480 = shl nsw i64 %479, 3
  %481 = add i64 %480, %474
  %482 = add i64 %471, 13
  store i64 %482, i64* %PC, align 8
  %483 = inttoptr i64 %481 to double*
  %484 = load double, double* %483, align 8
  store double %484, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %485 = add i64 %471, 17
  store i64 %485, i64* %PC, align 8
  %486 = load i64, i64* %473, align 8
  store i64 %486, i64* %RCX, align 8, !tbaa !2428
  %487 = add i64 %469, -40
  %488 = add i64 %471, 21
  store i64 %488, i64* %PC, align 8
  %489 = inttoptr i64 %487 to i32*
  %490 = load i32, i32* %489, align 4
  %491 = sext i32 %490 to i64
  store i64 %491, i64* %RDX, align 8, !tbaa !2428
  %492 = shl nsw i64 %491, 3
  %493 = add i64 %492, %486
  %494 = add i64 %471, 26
  store i64 %494, i64* %PC, align 8
  %495 = inttoptr i64 %493 to double*
  %496 = load double, double* %495, align 8
  %497 = fadd double %484, %496
  store double %497, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %498 = add i64 %469, -88
  %499 = add i64 %471, 31
  store i64 %499, i64* %PC, align 8
  %500 = inttoptr i64 %498 to double*
  store double %497, double* %500, align 8
  %501 = load i64, i64* %RBP, align 8
  %502 = add i64 %501, -16
  %503 = load i64, i64* %PC, align 8
  %504 = add i64 %503, 4
  store i64 %504, i64* %PC, align 8
  %505 = inttoptr i64 %502 to i64*
  %506 = load i64, i64* %505, align 8
  store i64 %506, i64* %RCX, align 8, !tbaa !2428
  %507 = add i64 %501, -36
  %508 = add i64 %503, 7
  store i64 %508, i64* %PC, align 8
  %509 = inttoptr i64 %507 to i32*
  %510 = load i32, i32* %509, align 4
  %511 = add i32 %510, 1
  %512 = zext i32 %511 to i64
  store i64 %512, i64* %RAX, align 8, !tbaa !2428
  %513 = icmp eq i32 %510, -1
  %514 = icmp eq i32 %511, 0
  %515 = or i1 %513, %514
  %516 = zext i1 %515 to i8
  store i8 %516, i8* %14, align 1, !tbaa !2433
  %517 = and i32 %511, 255
  %518 = tail call i32 @llvm.ctpop.i32(i32 %517) #10
  %519 = trunc i32 %518 to i8
  %520 = and i8 %519, 1
  %521 = xor i8 %520, 1
  store i8 %521, i8* %21, align 1, !tbaa !2447
  %522 = xor i32 %510, %511
  %523 = lshr i32 %522, 4
  %524 = trunc i32 %523 to i8
  %525 = and i8 %524, 1
  store i8 %525, i8* %27, align 1, !tbaa !2451
  %526 = zext i1 %514 to i8
  store i8 %526, i8* %30, align 1, !tbaa !2448
  %527 = lshr i32 %511, 31
  %528 = trunc i32 %527 to i8
  store i8 %528, i8* %33, align 1, !tbaa !2449
  %529 = lshr i32 %510, 31
  %530 = xor i32 %527, %529
  %531 = add nuw nsw i32 %530, %527
  %532 = icmp eq i32 %531, 2
  %533 = zext i1 %532 to i8
  store i8 %533, i8* %39, align 1, !tbaa !2450
  %534 = sext i32 %511 to i64
  store i64 %534, i64* %RDX, align 8, !tbaa !2428
  %535 = shl nsw i64 %534, 3
  %536 = add i64 %535, %506
  %537 = add i64 %503, 18
  store i64 %537, i64* %PC, align 8
  %538 = inttoptr i64 %536 to double*
  %539 = load double, double* %538, align 8
  store double %539, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %540 = add i64 %503, 22
  store i64 %540, i64* %PC, align 8
  %541 = load i64, i64* %505, align 8
  store i64 %541, i64* %RCX, align 8, !tbaa !2428
  %542 = add i64 %501, -40
  %543 = add i64 %503, 25
  store i64 %543, i64* %PC, align 8
  %544 = inttoptr i64 %542 to i32*
  %545 = load i32, i32* %544, align 4
  %546 = add i32 %545, 1
  %547 = zext i32 %546 to i64
  store i64 %547, i64* %RAX, align 8, !tbaa !2428
  %548 = icmp eq i32 %545, -1
  %549 = icmp eq i32 %546, 0
  %550 = or i1 %548, %549
  %551 = zext i1 %550 to i8
  store i8 %551, i8* %14, align 1, !tbaa !2433
  %552 = and i32 %546, 255
  %553 = tail call i32 @llvm.ctpop.i32(i32 %552) #10
  %554 = trunc i32 %553 to i8
  %555 = and i8 %554, 1
  %556 = xor i8 %555, 1
  store i8 %556, i8* %21, align 1, !tbaa !2447
  %557 = xor i32 %545, %546
  %558 = lshr i32 %557, 4
  %559 = trunc i32 %558 to i8
  %560 = and i8 %559, 1
  store i8 %560, i8* %27, align 1, !tbaa !2451
  %561 = zext i1 %549 to i8
  store i8 %561, i8* %30, align 1, !tbaa !2448
  %562 = lshr i32 %546, 31
  %563 = trunc i32 %562 to i8
  store i8 %563, i8* %33, align 1, !tbaa !2449
  %564 = lshr i32 %545, 31
  %565 = xor i32 %562, %564
  %566 = add nuw nsw i32 %565, %562
  %567 = icmp eq i32 %566, 2
  %568 = zext i1 %567 to i8
  store i8 %568, i8* %39, align 1, !tbaa !2450
  %569 = sext i32 %546 to i64
  store i64 %569, i64* %RDX, align 8, !tbaa !2428
  %570 = shl nsw i64 %569, 3
  %571 = add i64 %570, %541
  %572 = add i64 %503, 36
  store i64 %572, i64* %PC, align 8
  %573 = inttoptr i64 %571 to double*
  %574 = load double, double* %573, align 8
  %575 = fadd double %539, %574
  store double %575, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %576 = load i64, i64* %RBP, align 8
  %577 = add i64 %576, -96
  %578 = add i64 %503, 41
  store i64 %578, i64* %PC, align 8
  %579 = inttoptr i64 %577 to double*
  store double %575, double* %579, align 8
  %580 = load i64, i64* %RBP, align 8
  %581 = add i64 %580, -16
  %582 = load i64, i64* %PC, align 8
  %583 = add i64 %582, 4
  store i64 %583, i64* %PC, align 8
  %584 = inttoptr i64 %581 to i64*
  %585 = load i64, i64* %584, align 8
  store i64 %585, i64* %RCX, align 8, !tbaa !2428
  %586 = add i64 %580, -36
  %587 = add i64 %582, 8
  store i64 %587, i64* %PC, align 8
  %588 = inttoptr i64 %586 to i32*
  %589 = load i32, i32* %588, align 4
  %590 = sext i32 %589 to i64
  store i64 %590, i64* %RDX, align 8, !tbaa !2428
  %591 = shl nsw i64 %590, 3
  %592 = add i64 %591, %585
  %593 = add i64 %582, 13
  store i64 %593, i64* %PC, align 8
  %594 = inttoptr i64 %592 to double*
  %595 = load double, double* %594, align 8
  store double %595, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %596 = add i64 %582, 17
  store i64 %596, i64* %PC, align 8
  %597 = load i64, i64* %584, align 8
  store i64 %597, i64* %RCX, align 8, !tbaa !2428
  %598 = add i64 %580, -40
  %599 = add i64 %582, 21
  store i64 %599, i64* %PC, align 8
  %600 = inttoptr i64 %598 to i32*
  %601 = load i32, i32* %600, align 4
  %602 = sext i32 %601 to i64
  store i64 %602, i64* %RDX, align 8, !tbaa !2428
  %603 = shl nsw i64 %602, 3
  %604 = add i64 %603, %597
  %605 = add i64 %582, 26
  store i64 %605, i64* %PC, align 8
  %606 = inttoptr i64 %604 to double*
  %607 = load double, double* %606, align 8
  %608 = fsub double %595, %607
  store double %608, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %609 = add i64 %580, -104
  %610 = add i64 %582, 31
  store i64 %610, i64* %PC, align 8
  %611 = inttoptr i64 %609 to double*
  store double %608, double* %611, align 8
  %612 = load i64, i64* %RBP, align 8
  %613 = add i64 %612, -16
  %614 = load i64, i64* %PC, align 8
  %615 = add i64 %614, 4
  store i64 %615, i64* %PC, align 8
  %616 = inttoptr i64 %613 to i64*
  %617 = load i64, i64* %616, align 8
  store i64 %617, i64* %RCX, align 8, !tbaa !2428
  %618 = add i64 %612, -36
  %619 = add i64 %614, 7
  store i64 %619, i64* %PC, align 8
  %620 = inttoptr i64 %618 to i32*
  %621 = load i32, i32* %620, align 4
  %622 = add i32 %621, 1
  %623 = zext i32 %622 to i64
  store i64 %623, i64* %RAX, align 8, !tbaa !2428
  %624 = icmp eq i32 %621, -1
  %625 = icmp eq i32 %622, 0
  %626 = or i1 %624, %625
  %627 = zext i1 %626 to i8
  store i8 %627, i8* %14, align 1, !tbaa !2433
  %628 = and i32 %622, 255
  %629 = tail call i32 @llvm.ctpop.i32(i32 %628) #10
  %630 = trunc i32 %629 to i8
  %631 = and i8 %630, 1
  %632 = xor i8 %631, 1
  store i8 %632, i8* %21, align 1, !tbaa !2447
  %633 = xor i32 %621, %622
  %634 = lshr i32 %633, 4
  %635 = trunc i32 %634 to i8
  %636 = and i8 %635, 1
  store i8 %636, i8* %27, align 1, !tbaa !2451
  %637 = zext i1 %625 to i8
  store i8 %637, i8* %30, align 1, !tbaa !2448
  %638 = lshr i32 %622, 31
  %639 = trunc i32 %638 to i8
  store i8 %639, i8* %33, align 1, !tbaa !2449
  %640 = lshr i32 %621, 31
  %641 = xor i32 %638, %640
  %642 = add nuw nsw i32 %641, %638
  %643 = icmp eq i32 %642, 2
  %644 = zext i1 %643 to i8
  store i8 %644, i8* %39, align 1, !tbaa !2450
  %645 = sext i32 %622 to i64
  store i64 %645, i64* %RDX, align 8, !tbaa !2428
  %646 = shl nsw i64 %645, 3
  %647 = add i64 %646, %617
  %648 = add i64 %614, 18
  store i64 %648, i64* %PC, align 8
  %649 = inttoptr i64 %647 to double*
  %650 = load double, double* %649, align 8
  store double %650, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %651 = add i64 %614, 22
  store i64 %651, i64* %PC, align 8
  %652 = load i64, i64* %616, align 8
  store i64 %652, i64* %RCX, align 8, !tbaa !2428
  %653 = add i64 %612, -40
  %654 = add i64 %614, 25
  store i64 %654, i64* %PC, align 8
  %655 = inttoptr i64 %653 to i32*
  %656 = load i32, i32* %655, align 4
  %657 = add i32 %656, 1
  %658 = zext i32 %657 to i64
  store i64 %658, i64* %RAX, align 8, !tbaa !2428
  %659 = icmp eq i32 %656, -1
  %660 = icmp eq i32 %657, 0
  %661 = or i1 %659, %660
  %662 = zext i1 %661 to i8
  store i8 %662, i8* %14, align 1, !tbaa !2433
  %663 = and i32 %657, 255
  %664 = tail call i32 @llvm.ctpop.i32(i32 %663) #10
  %665 = trunc i32 %664 to i8
  %666 = and i8 %665, 1
  %667 = xor i8 %666, 1
  store i8 %667, i8* %21, align 1, !tbaa !2447
  %668 = xor i32 %656, %657
  %669 = lshr i32 %668, 4
  %670 = trunc i32 %669 to i8
  %671 = and i8 %670, 1
  store i8 %671, i8* %27, align 1, !tbaa !2451
  %672 = zext i1 %660 to i8
  store i8 %672, i8* %30, align 1, !tbaa !2448
  %673 = lshr i32 %657, 31
  %674 = trunc i32 %673 to i8
  store i8 %674, i8* %33, align 1, !tbaa !2449
  %675 = lshr i32 %656, 31
  %676 = xor i32 %673, %675
  %677 = add nuw nsw i32 %676, %673
  %678 = icmp eq i32 %677, 2
  %679 = zext i1 %678 to i8
  store i8 %679, i8* %39, align 1, !tbaa !2450
  %680 = sext i32 %657 to i64
  store i64 %680, i64* %RDX, align 8, !tbaa !2428
  %681 = shl nsw i64 %680, 3
  %682 = add i64 %681, %652
  %683 = add i64 %614, 36
  store i64 %683, i64* %PC, align 8
  %684 = inttoptr i64 %682 to double*
  %685 = load double, double* %684, align 8
  %686 = fsub double %650, %685
  store double %686, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %687 = load i64, i64* %RBP, align 8
  %688 = add i64 %687, -112
  %689 = add i64 %614, 41
  store i64 %689, i64* %PC, align 8
  %690 = inttoptr i64 %688 to double*
  store double %686, double* %690, align 8
  %691 = load i64, i64* %RBP, align 8
  %692 = add i64 %691, -56
  %693 = load i64, i64* %PC, align 8
  %694 = add i64 %693, 5
  store i64 %694, i64* %PC, align 8
  %695 = inttoptr i64 %692 to double*
  %696 = load double, double* %695, align 8
  store double %696, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %697 = add i64 %691, -88
  %698 = add i64 %693, 10
  store i64 %698, i64* %PC, align 8
  %699 = inttoptr i64 %697 to double*
  %700 = load double, double* %699, align 8
  %701 = fadd double %696, %700
  store double %701, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %702 = add i64 %691, -16
  %703 = add i64 %693, 14
  store i64 %703, i64* %PC, align 8
  %704 = inttoptr i64 %702 to i64*
  %705 = load i64, i64* %704, align 8
  store i64 %705, i64* %RCX, align 8, !tbaa !2428
  %706 = add i64 %691, -28
  %707 = add i64 %693, 18
  store i64 %707, i64* %PC, align 8
  %708 = inttoptr i64 %706 to i32*
  %709 = load i32, i32* %708, align 4
  %710 = sext i32 %709 to i64
  store i64 %710, i64* %RDX, align 8, !tbaa !2428
  %711 = shl nsw i64 %710, 3
  %712 = add i64 %711, %705
  %713 = add i64 %693, 23
  store i64 %713, i64* %PC, align 8
  %714 = inttoptr i64 %712 to double*
  store double %701, double* %714, align 8
  %715 = load i64, i64* %RBP, align 8
  %716 = add i64 %715, -64
  %717 = load i64, i64* %PC, align 8
  %718 = add i64 %717, 5
  store i64 %718, i64* %PC, align 8
  %719 = inttoptr i64 %716 to double*
  %720 = load double, double* %719, align 8
  store double %720, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %721 = add i64 %715, -96
  %722 = add i64 %717, 10
  store i64 %722, i64* %PC, align 8
  %723 = inttoptr i64 %721 to double*
  %724 = load double, double* %723, align 8
  %725 = fadd double %720, %724
  store double %725, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %726 = add i64 %715, -16
  %727 = add i64 %717, 14
  store i64 %727, i64* %PC, align 8
  %728 = inttoptr i64 %726 to i64*
  %729 = load i64, i64* %728, align 8
  store i64 %729, i64* %RCX, align 8, !tbaa !2428
  %730 = add i64 %715, -28
  %731 = add i64 %717, 17
  store i64 %731, i64* %PC, align 8
  %732 = inttoptr i64 %730 to i32*
  %733 = load i32, i32* %732, align 4
  %734 = add i32 %733, 1
  %735 = zext i32 %734 to i64
  store i64 %735, i64* %RAX, align 8, !tbaa !2428
  %736 = icmp eq i32 %733, -1
  %737 = icmp eq i32 %734, 0
  %738 = or i1 %736, %737
  %739 = zext i1 %738 to i8
  store i8 %739, i8* %14, align 1, !tbaa !2433
  %740 = and i32 %734, 255
  %741 = tail call i32 @llvm.ctpop.i32(i32 %740) #10
  %742 = trunc i32 %741 to i8
  %743 = and i8 %742, 1
  %744 = xor i8 %743, 1
  store i8 %744, i8* %21, align 1, !tbaa !2447
  %745 = xor i32 %733, %734
  %746 = lshr i32 %745, 4
  %747 = trunc i32 %746 to i8
  %748 = and i8 %747, 1
  store i8 %748, i8* %27, align 1, !tbaa !2451
  %749 = zext i1 %737 to i8
  store i8 %749, i8* %30, align 1, !tbaa !2448
  %750 = lshr i32 %734, 31
  %751 = trunc i32 %750 to i8
  store i8 %751, i8* %33, align 1, !tbaa !2449
  %752 = lshr i32 %733, 31
  %753 = xor i32 %750, %752
  %754 = add nuw nsw i32 %753, %750
  %755 = icmp eq i32 %754, 2
  %756 = zext i1 %755 to i8
  store i8 %756, i8* %39, align 1, !tbaa !2450
  %757 = sext i32 %734 to i64
  store i64 %757, i64* %RDX, align 8, !tbaa !2428
  %758 = shl nsw i64 %757, 3
  %759 = add i64 %758, %729
  %760 = add i64 %717, 28
  store i64 %760, i64* %PC, align 8
  %761 = inttoptr i64 %759 to double*
  store double %725, double* %761, align 8
  %762 = load i64, i64* %RBP, align 8
  %763 = add i64 %762, -56
  %764 = load i64, i64* %PC, align 8
  %765 = add i64 %764, 5
  store i64 %765, i64* %PC, align 8
  %766 = inttoptr i64 %763 to double*
  %767 = load double, double* %766, align 8
  store double %767, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %768 = add i64 %762, -88
  %769 = add i64 %764, 10
  store i64 %769, i64* %PC, align 8
  %770 = inttoptr i64 %768 to double*
  %771 = load double, double* %770, align 8
  %772 = fsub double %767, %771
  store double %772, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %773 = add i64 %762, -16
  %774 = add i64 %764, 14
  store i64 %774, i64* %PC, align 8
  %775 = inttoptr i64 %773 to i64*
  %776 = load i64, i64* %775, align 8
  store i64 %776, i64* %RCX, align 8, !tbaa !2428
  %777 = add i64 %762, -36
  %778 = add i64 %764, 18
  store i64 %778, i64* %PC, align 8
  %779 = inttoptr i64 %777 to i32*
  %780 = load i32, i32* %779, align 4
  %781 = sext i32 %780 to i64
  store i64 %781, i64* %RDX, align 8, !tbaa !2428
  %782 = shl nsw i64 %781, 3
  %783 = add i64 %782, %776
  %784 = add i64 %764, 23
  store i64 %784, i64* %PC, align 8
  %785 = inttoptr i64 %783 to double*
  store double %772, double* %785, align 8
  %786 = load i64, i64* %RBP, align 8
  %787 = add i64 %786, -64
  %788 = load i64, i64* %PC, align 8
  %789 = add i64 %788, 5
  store i64 %789, i64* %PC, align 8
  %790 = inttoptr i64 %787 to double*
  %791 = load double, double* %790, align 8
  store double %791, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %792 = add i64 %786, -96
  %793 = add i64 %788, 10
  store i64 %793, i64* %PC, align 8
  %794 = inttoptr i64 %792 to double*
  %795 = load double, double* %794, align 8
  %796 = fsub double %791, %795
  store double %796, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %797 = add i64 %786, -16
  %798 = add i64 %788, 14
  store i64 %798, i64* %PC, align 8
  %799 = inttoptr i64 %797 to i64*
  %800 = load i64, i64* %799, align 8
  store i64 %800, i64* %RCX, align 8, !tbaa !2428
  %801 = add i64 %786, -36
  %802 = add i64 %788, 17
  store i64 %802, i64* %PC, align 8
  %803 = inttoptr i64 %801 to i32*
  %804 = load i32, i32* %803, align 4
  %805 = add i32 %804, 1
  %806 = zext i32 %805 to i64
  store i64 %806, i64* %RAX, align 8, !tbaa !2428
  %807 = icmp eq i32 %804, -1
  %808 = icmp eq i32 %805, 0
  %809 = or i1 %807, %808
  %810 = zext i1 %809 to i8
  store i8 %810, i8* %14, align 1, !tbaa !2433
  %811 = and i32 %805, 255
  %812 = tail call i32 @llvm.ctpop.i32(i32 %811) #10
  %813 = trunc i32 %812 to i8
  %814 = and i8 %813, 1
  %815 = xor i8 %814, 1
  store i8 %815, i8* %21, align 1, !tbaa !2447
  %816 = xor i32 %804, %805
  %817 = lshr i32 %816, 4
  %818 = trunc i32 %817 to i8
  %819 = and i8 %818, 1
  store i8 %819, i8* %27, align 1, !tbaa !2451
  %820 = zext i1 %808 to i8
  store i8 %820, i8* %30, align 1, !tbaa !2448
  %821 = lshr i32 %805, 31
  %822 = trunc i32 %821 to i8
  store i8 %822, i8* %33, align 1, !tbaa !2449
  %823 = lshr i32 %804, 31
  %824 = xor i32 %821, %823
  %825 = add nuw nsw i32 %824, %821
  %826 = icmp eq i32 %825, 2
  %827 = zext i1 %826 to i8
  store i8 %827, i8* %39, align 1, !tbaa !2450
  %828 = sext i32 %805 to i64
  store i64 %828, i64* %RDX, align 8, !tbaa !2428
  %829 = shl nsw i64 %828, 3
  %830 = add i64 %829, %800
  %831 = add i64 %788, 28
  store i64 %831, i64* %PC, align 8
  %832 = inttoptr i64 %830 to double*
  store double %796, double* %832, align 8
  %833 = load i64, i64* %RBP, align 8
  %834 = add i64 %833, -72
  %835 = load i64, i64* %PC, align 8
  %836 = add i64 %835, 5
  store i64 %836, i64* %PC, align 8
  %837 = inttoptr i64 %834 to double*
  %838 = load double, double* %837, align 8
  store double %838, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %839 = add i64 %833, -112
  %840 = add i64 %835, 10
  store i64 %840, i64* %PC, align 8
  %841 = inttoptr i64 %839 to double*
  %842 = load double, double* %841, align 8
  %843 = fsub double %838, %842
  store double %843, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %844 = add i64 %833, -16
  %845 = add i64 %835, 14
  store i64 %845, i64* %PC, align 8
  %846 = inttoptr i64 %844 to i64*
  %847 = load i64, i64* %846, align 8
  store i64 %847, i64* %RCX, align 8, !tbaa !2428
  %848 = add i64 %833, -32
  %849 = add i64 %835, 18
  store i64 %849, i64* %PC, align 8
  %850 = inttoptr i64 %848 to i32*
  %851 = load i32, i32* %850, align 4
  %852 = sext i32 %851 to i64
  store i64 %852, i64* %RDX, align 8, !tbaa !2428
  %853 = shl nsw i64 %852, 3
  %854 = add i64 %853, %847
  %855 = add i64 %835, 23
  store i64 %855, i64* %PC, align 8
  %856 = inttoptr i64 %854 to double*
  store double %843, double* %856, align 8
  %857 = load i64, i64* %RBP, align 8
  %858 = add i64 %857, -80
  %859 = load i64, i64* %PC, align 8
  %860 = add i64 %859, 5
  store i64 %860, i64* %PC, align 8
  %861 = inttoptr i64 %858 to double*
  %862 = load double, double* %861, align 8
  store double %862, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %863 = add i64 %857, -104
  %864 = add i64 %859, 10
  store i64 %864, i64* %PC, align 8
  %865 = inttoptr i64 %863 to double*
  %866 = load double, double* %865, align 8
  %867 = fadd double %862, %866
  store double %867, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %868 = add i64 %857, -16
  %869 = add i64 %859, 14
  store i64 %869, i64* %PC, align 8
  %870 = inttoptr i64 %868 to i64*
  %871 = load i64, i64* %870, align 8
  store i64 %871, i64* %RCX, align 8, !tbaa !2428
  %872 = add i64 %857, -32
  %873 = add i64 %859, 17
  store i64 %873, i64* %PC, align 8
  %874 = inttoptr i64 %872 to i32*
  %875 = load i32, i32* %874, align 4
  %876 = add i32 %875, 1
  %877 = zext i32 %876 to i64
  store i64 %877, i64* %RAX, align 8, !tbaa !2428
  %878 = icmp eq i32 %875, -1
  %879 = icmp eq i32 %876, 0
  %880 = or i1 %878, %879
  %881 = zext i1 %880 to i8
  store i8 %881, i8* %14, align 1, !tbaa !2433
  %882 = and i32 %876, 255
  %883 = tail call i32 @llvm.ctpop.i32(i32 %882) #10
  %884 = trunc i32 %883 to i8
  %885 = and i8 %884, 1
  %886 = xor i8 %885, 1
  store i8 %886, i8* %21, align 1, !tbaa !2447
  %887 = xor i32 %875, %876
  %888 = lshr i32 %887, 4
  %889 = trunc i32 %888 to i8
  %890 = and i8 %889, 1
  store i8 %890, i8* %27, align 1, !tbaa !2451
  %891 = zext i1 %879 to i8
  store i8 %891, i8* %30, align 1, !tbaa !2448
  %892 = lshr i32 %876, 31
  %893 = trunc i32 %892 to i8
  store i8 %893, i8* %33, align 1, !tbaa !2449
  %894 = lshr i32 %875, 31
  %895 = xor i32 %892, %894
  %896 = add nuw nsw i32 %895, %892
  %897 = icmp eq i32 %896, 2
  %898 = zext i1 %897 to i8
  store i8 %898, i8* %39, align 1, !tbaa !2450
  %899 = sext i32 %876 to i64
  store i64 %899, i64* %RDX, align 8, !tbaa !2428
  %900 = shl nsw i64 %899, 3
  %901 = add i64 %900, %871
  %902 = add i64 %859, 28
  store i64 %902, i64* %PC, align 8
  %903 = inttoptr i64 %901 to double*
  store double %867, double* %903, align 8
  %904 = load i64, i64* %RBP, align 8
  %905 = add i64 %904, -72
  %906 = load i64, i64* %PC, align 8
  %907 = add i64 %906, 5
  store i64 %907, i64* %PC, align 8
  %908 = inttoptr i64 %905 to double*
  %909 = load double, double* %908, align 8
  store double %909, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %910 = add i64 %904, -112
  %911 = add i64 %906, 10
  store i64 %911, i64* %PC, align 8
  %912 = inttoptr i64 %910 to double*
  %913 = load double, double* %912, align 8
  %914 = fadd double %909, %913
  store double %914, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %915 = add i64 %904, -16
  %916 = add i64 %906, 14
  store i64 %916, i64* %PC, align 8
  %917 = inttoptr i64 %915 to i64*
  %918 = load i64, i64* %917, align 8
  store i64 %918, i64* %RCX, align 8, !tbaa !2428
  %919 = add i64 %904, -40
  %920 = add i64 %906, 18
  store i64 %920, i64* %PC, align 8
  %921 = inttoptr i64 %919 to i32*
  %922 = load i32, i32* %921, align 4
  %923 = sext i32 %922 to i64
  store i64 %923, i64* %RDX, align 8, !tbaa !2428
  %924 = shl nsw i64 %923, 3
  %925 = add i64 %924, %918
  %926 = add i64 %906, 23
  store i64 %926, i64* %PC, align 8
  %927 = inttoptr i64 %925 to double*
  store double %914, double* %927, align 8
  %928 = load i64, i64* %RBP, align 8
  %929 = add i64 %928, -80
  %930 = load i64, i64* %PC, align 8
  %931 = add i64 %930, 5
  store i64 %931, i64* %PC, align 8
  %932 = inttoptr i64 %929 to double*
  %933 = load double, double* %932, align 8
  store double %933, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %934 = add i64 %928, -104
  %935 = add i64 %930, 10
  store i64 %935, i64* %PC, align 8
  %936 = inttoptr i64 %934 to double*
  %937 = load double, double* %936, align 8
  %938 = fsub double %933, %937
  store double %938, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %939 = add i64 %928, -16
  %940 = add i64 %930, 14
  store i64 %940, i64* %PC, align 8
  %941 = inttoptr i64 %939 to i64*
  %942 = load i64, i64* %941, align 8
  store i64 %942, i64* %RCX, align 8, !tbaa !2428
  %943 = add i64 %928, -40
  %944 = add i64 %930, 17
  store i64 %944, i64* %PC, align 8
  %945 = inttoptr i64 %943 to i32*
  %946 = load i32, i32* %945, align 4
  %947 = add i32 %946, 1
  %948 = zext i32 %947 to i64
  store i64 %948, i64* %RAX, align 8, !tbaa !2428
  %949 = icmp eq i32 %946, -1
  %950 = icmp eq i32 %947, 0
  %951 = or i1 %949, %950
  %952 = zext i1 %951 to i8
  store i8 %952, i8* %14, align 1, !tbaa !2433
  %953 = and i32 %947, 255
  %954 = tail call i32 @llvm.ctpop.i32(i32 %953) #10
  %955 = trunc i32 %954 to i8
  %956 = and i8 %955, 1
  %957 = xor i8 %956, 1
  store i8 %957, i8* %21, align 1, !tbaa !2447
  %958 = xor i32 %946, %947
  %959 = lshr i32 %958, 4
  %960 = trunc i32 %959 to i8
  %961 = and i8 %960, 1
  store i8 %961, i8* %27, align 1, !tbaa !2451
  %962 = zext i1 %950 to i8
  store i8 %962, i8* %30, align 1, !tbaa !2448
  %963 = lshr i32 %947, 31
  %964 = trunc i32 %963 to i8
  store i8 %964, i8* %33, align 1, !tbaa !2449
  %965 = lshr i32 %946, 31
  %966 = xor i32 %963, %965
  %967 = add nuw nsw i32 %966, %963
  %968 = icmp eq i32 %967, 2
  %969 = zext i1 %968 to i8
  store i8 %969, i8* %39, align 1, !tbaa !2450
  %970 = sext i32 %947 to i64
  store i64 %970, i64* %RDX, align 8, !tbaa !2428
  %971 = shl nsw i64 %970, 3
  %972 = add i64 %971, %942
  %973 = add i64 %930, 28
  store i64 %973, i64* %PC, align 8
  %974 = inttoptr i64 %972 to double*
  store double %938, double* %974, align 8
  %975 = load i64, i64* %RBP, align 8
  %976 = add i64 %975, -28
  %977 = load i64, i64* %PC, align 8
  %978 = add i64 %977, 3
  store i64 %978, i64* %PC, align 8
  %979 = inttoptr i64 %976 to i32*
  %980 = load i32, i32* %979, align 4
  %981 = add i32 %980, 2
  %982 = zext i32 %981 to i64
  store i64 %982, i64* %RAX, align 8, !tbaa !2428
  %983 = icmp ugt i32 %980, -3
  %984 = zext i1 %983 to i8
  store i8 %984, i8* %14, align 1, !tbaa !2433
  %985 = and i32 %981, 255
  %986 = tail call i32 @llvm.ctpop.i32(i32 %985) #10
  %987 = trunc i32 %986 to i8
  %988 = and i8 %987, 1
  %989 = xor i8 %988, 1
  store i8 %989, i8* %21, align 1, !tbaa !2447
  %990 = xor i32 %980, %981
  %991 = lshr i32 %990, 4
  %992 = trunc i32 %991 to i8
  %993 = and i8 %992, 1
  store i8 %993, i8* %27, align 1, !tbaa !2451
  %994 = icmp eq i32 %981, 0
  %995 = zext i1 %994 to i8
  store i8 %995, i8* %30, align 1, !tbaa !2448
  %996 = lshr i32 %981, 31
  %997 = trunc i32 %996 to i8
  store i8 %997, i8* %33, align 1, !tbaa !2449
  %998 = lshr i32 %980, 31
  %999 = xor i32 %996, %998
  %1000 = add nuw nsw i32 %999, %996
  %1001 = icmp eq i32 %1000, 2
  %1002 = zext i1 %1001 to i8
  store i8 %1002, i8* %39, align 1, !tbaa !2450
  %1003 = add i64 %977, 9
  store i64 %1003, i64* %PC, align 8
  store i32 %981, i32* %979, align 4
  %1004 = load i64, i64* %PC, align 8
  %1005 = add i64 %1004, -540
  store i64 %1005, i64* %PC, align 8, !tbaa !2428
  br label %block_4018c6

block_4018b0:                                     ; preds = %block_4018ab, %block_401840
  %1006 = phi i64 [ %91, %block_401840 ], [ %1113, %block_4018ab ]
  %1007 = phi i64 [ %61, %block_401840 ], [ %1063, %block_4018ab ]
  %MEMORY.1 = phi %struct.Memory* [ %2, %block_401840 ], [ %MEMORY.2, %block_4018ab ]
  %1008 = add i64 %1007, -44
  %1009 = add i64 %1006, 3
  store i64 %1009, i64* %PC, align 8
  %1010 = inttoptr i64 %1008 to i32*
  %1011 = load i32, i32* %1010, align 4
  %1012 = shl i32 %1011, 2
  %1013 = zext i32 %1012 to i64
  store i64 %1013, i64* %RAX, align 8, !tbaa !2428
  %1014 = lshr i32 %1011, 30
  %1015 = trunc i32 %1014 to i8
  %1016 = and i8 %1015, 1
  store i8 %1016, i8* %14, align 1, !tbaa !2432
  %1017 = and i32 %1012, 252
  %1018 = tail call i32 @llvm.ctpop.i32(i32 %1017) #10
  %1019 = trunc i32 %1018 to i8
  %1020 = and i8 %1019, 1
  %1021 = xor i8 %1020, 1
  store i8 %1021, i8* %21, align 1, !tbaa !2432
  store i8 0, i8* %27, align 1, !tbaa !2432
  %1022 = icmp eq i32 %1012, 0
  %1023 = zext i1 %1022 to i8
  store i8 %1023, i8* %30, align 1, !tbaa !2432
  %1024 = lshr i32 %1011, 29
  %1025 = and i32 %1024, 1
  %1026 = trunc i32 %1025 to i8
  store i8 %1026, i8* %33, align 1, !tbaa !2432
  store i8 0, i8* %39, align 1, !tbaa !2432
  %1027 = add i64 %1007, -4
  %1028 = add i64 %1006, 9
  store i64 %1028, i64* %PC, align 8
  %1029 = inttoptr i64 %1027 to i32*
  %1030 = load i32, i32* %1029, align 4
  %1031 = sub i32 %1012, %1030
  %1032 = icmp ult i32 %1012, %1030
  %1033 = zext i1 %1032 to i8
  store i8 %1033, i8* %14, align 1, !tbaa !2433
  %1034 = and i32 %1031, 255
  %1035 = tail call i32 @llvm.ctpop.i32(i32 %1034) #10
  %1036 = trunc i32 %1035 to i8
  %1037 = and i8 %1036, 1
  %1038 = xor i8 %1037, 1
  store i8 %1038, i8* %21, align 1, !tbaa !2447
  %1039 = xor i32 %1030, %1012
  %1040 = xor i32 %1039, %1031
  %1041 = lshr i32 %1040, 4
  %1042 = trunc i32 %1041 to i8
  %1043 = and i8 %1042, 1
  store i8 %1043, i8* %27, align 1, !tbaa !2451
  %1044 = icmp eq i32 %1031, 0
  %1045 = zext i1 %1044 to i8
  store i8 %1045, i8* %30, align 1, !tbaa !2448
  %1046 = lshr i32 %1031, 31
  %1047 = trunc i32 %1046 to i8
  store i8 %1047, i8* %33, align 1, !tbaa !2449
  %1048 = lshr i32 %1030, 31
  %1049 = xor i32 %1048, %1025
  %1050 = xor i32 %1046, %1025
  %1051 = add nuw nsw i32 %1050, %1049
  %1052 = icmp eq i32 %1051, 2
  %1053 = zext i1 %1052 to i8
  store i8 %1053, i8* %39, align 1, !tbaa !2450
  %.v5 = select i1 %1044, i64 15, i64 572
  %1054 = add i64 %1006, %.v5
  %1055 = add i64 %1007, -28
  %1056 = add i64 %1054, 7
  store i64 %1056, i64* %PC, align 8
  %1057 = inttoptr i64 %1055 to i32*
  store i32 0, i32* %1057, align 4
  %1058 = bitcast %union.VectorReg* %4 to double*
  %1059 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1060 = bitcast i64* %1059 to double*
  %.pre2 = load i64, i64* %PC, align 8
  br i1 %1044, label %block_4018c6, label %block_401af3

block_401bcf:                                     ; preds = %block_401af3
  %1061 = add i64 %129, 5
  br label %block_401bd4

block_40187b:                                     ; preds = %block_401864, %block_40188a
  %1062 = phi i64 [ %.pre, %block_401864 ], [ %1502, %block_40188a ]
  %MEMORY.2 = phi %struct.Memory* [ %1590, %block_401864 ], [ %1478, %block_40188a ]
  %1063 = load i64, i64* %RBP, align 8
  %1064 = add i64 %1063, -44
  %1065 = add i64 %1062, 3
  store i64 %1065, i64* %PC, align 8
  %1066 = inttoptr i64 %1064 to i32*
  %1067 = load i32, i32* %1066, align 4
  %1068 = shl i32 %1067, 2
  %1069 = zext i32 %1068 to i64
  store i64 %1069, i64* %RAX, align 8, !tbaa !2428
  %1070 = lshr i32 %1067, 30
  %1071 = trunc i32 %1070 to i8
  %1072 = and i8 %1071, 1
  store i8 %1072, i8* %14, align 1, !tbaa !2432
  %1073 = and i32 %1068, 252
  %1074 = tail call i32 @llvm.ctpop.i32(i32 %1073) #10
  %1075 = trunc i32 %1074 to i8
  %1076 = and i8 %1075, 1
  %1077 = xor i8 %1076, 1
  store i8 %1077, i8* %21, align 1, !tbaa !2432
  store i8 0, i8* %27, align 1, !tbaa !2432
  %1078 = icmp eq i32 %1068, 0
  %1079 = zext i1 %1078 to i8
  store i8 %1079, i8* %30, align 1, !tbaa !2432
  %1080 = lshr i32 %1067, 29
  %1081 = and i32 %1080, 1
  %1082 = trunc i32 %1081 to i8
  store i8 %1082, i8* %33, align 1, !tbaa !2432
  store i8 0, i8* %39, align 1, !tbaa !2432
  %1083 = add i64 %1063, -4
  %1084 = add i64 %1062, 9
  store i64 %1084, i64* %PC, align 8
  %1085 = inttoptr i64 %1083 to i32*
  %1086 = load i32, i32* %1085, align 4
  %1087 = sub i32 %1068, %1086
  %1088 = icmp ult i32 %1068, %1086
  %1089 = zext i1 %1088 to i8
  store i8 %1089, i8* %14, align 1, !tbaa !2433
  %1090 = and i32 %1087, 255
  %1091 = tail call i32 @llvm.ctpop.i32(i32 %1090) #10
  %1092 = trunc i32 %1091 to i8
  %1093 = and i8 %1092, 1
  %1094 = xor i8 %1093, 1
  store i8 %1094, i8* %21, align 1, !tbaa !2447
  %1095 = xor i32 %1086, %1068
  %1096 = xor i32 %1095, %1087
  %1097 = lshr i32 %1096, 4
  %1098 = trunc i32 %1097 to i8
  %1099 = and i8 %1098, 1
  store i8 %1099, i8* %27, align 1, !tbaa !2451
  %1100 = icmp eq i32 %1087, 0
  %1101 = zext i1 %1100 to i8
  store i8 %1101, i8* %30, align 1, !tbaa !2448
  %1102 = lshr i32 %1087, 31
  %1103 = trunc i32 %1102 to i8
  store i8 %1103, i8* %33, align 1, !tbaa !2449
  %1104 = lshr i32 %1086, 31
  %1105 = xor i32 %1104, %1081
  %1106 = xor i32 %1102, %1081
  %1107 = add nuw nsw i32 %1106, %1105
  %1108 = icmp eq i32 %1107, 2
  %1109 = zext i1 %1108 to i8
  store i8 %1109, i8* %39, align 1, !tbaa !2450
  %1110 = icmp ne i8 %1103, 0
  %1111 = xor i1 %1110, %1108
  %.v4 = select i1 %1111, i64 15, i64 48
  %1112 = add i64 %1062, %.v4
  store i64 %1112, i64* %PC, align 8, !tbaa !2428
  br i1 %1111, label %block_40188a, label %block_4018ab

block_4018ab:                                     ; preds = %block_40187b
  %1113 = add i64 %1112, 5
  store i64 %1113, i64* %PC, align 8, !tbaa !2428
  br label %block_4018b0

block_401aff:                                     ; preds = %block_401af3
  %1114 = add i64 %129, 3
  store i64 %1114, i64* %PC, align 8
  %1115 = load i32, i32* %96, align 4
  %1116 = zext i32 %1115 to i64
  store i64 %1116, i64* %RAX, align 8, !tbaa !2428
  %1117 = add i64 %129, 6
  store i64 %1117, i64* %PC, align 8
  %1118 = load i32, i32* %101, align 4
  %1119 = add i32 %1118, %1115
  %1120 = zext i32 %1119 to i64
  store i64 %1120, i64* %RAX, align 8, !tbaa !2428
  %1121 = icmp ult i32 %1119, %1115
  %1122 = icmp ult i32 %1119, %1118
  %1123 = or i1 %1121, %1122
  %1124 = zext i1 %1123 to i8
  store i8 %1124, i8* %14, align 1, !tbaa !2433
  %1125 = and i32 %1119, 255
  %1126 = tail call i32 @llvm.ctpop.i32(i32 %1125) #10
  %1127 = trunc i32 %1126 to i8
  %1128 = and i8 %1127, 1
  %1129 = xor i8 %1128, 1
  store i8 %1129, i8* %21, align 1, !tbaa !2447
  %1130 = xor i32 %1118, %1115
  %1131 = xor i32 %1130, %1119
  %1132 = lshr i32 %1131, 4
  %1133 = trunc i32 %1132 to i8
  %1134 = and i8 %1133, 1
  store i8 %1134, i8* %27, align 1, !tbaa !2451
  %1135 = icmp eq i32 %1119, 0
  %1136 = zext i1 %1135 to i8
  store i8 %1136, i8* %30, align 1, !tbaa !2448
  %1137 = lshr i32 %1119, 31
  %1138 = trunc i32 %1137 to i8
  store i8 %1138, i8* %33, align 1, !tbaa !2449
  %1139 = lshr i32 %1115, 31
  %1140 = lshr i32 %1118, 31
  %1141 = xor i32 %1137, %1139
  %1142 = xor i32 %1137, %1140
  %1143 = add nuw nsw i32 %1141, %1142
  %1144 = icmp eq i32 %1143, 2
  %1145 = zext i1 %1144 to i8
  store i8 %1145, i8* %39, align 1, !tbaa !2450
  %1146 = add i64 %93, -32
  %1147 = add i64 %129, 9
  store i64 %1147, i64* %PC, align 8
  %1148 = inttoptr i64 %1146 to i32*
  store i32 %1119, i32* %1148, align 4
  %1149 = load i64, i64* %RBP, align 8
  %1150 = add i64 %1149, -16
  %1151 = load i64, i64* %PC, align 8
  %1152 = add i64 %1151, 4
  store i64 %1152, i64* %PC, align 8
  %1153 = inttoptr i64 %1150 to i64*
  %1154 = load i64, i64* %1153, align 8
  store i64 %1154, i64* %RCX, align 8, !tbaa !2428
  %1155 = add i64 %1149, -28
  %1156 = add i64 %1151, 8
  store i64 %1156, i64* %PC, align 8
  %1157 = inttoptr i64 %1155 to i32*
  %1158 = load i32, i32* %1157, align 4
  %1159 = sext i32 %1158 to i64
  store i64 %1159, i64* %RDX, align 8, !tbaa !2428
  %1160 = shl nsw i64 %1159, 3
  %1161 = add i64 %1160, %1154
  %1162 = add i64 %1151, 13
  store i64 %1162, i64* %PC, align 8
  %1163 = inttoptr i64 %1161 to double*
  %1164 = load double, double* %1163, align 8
  store double %1164, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %1165 = add i64 %1151, 17
  store i64 %1165, i64* %PC, align 8
  %1166 = load i64, i64* %1153, align 8
  store i64 %1166, i64* %RCX, align 8, !tbaa !2428
  %1167 = add i64 %1149, -32
  %1168 = add i64 %1151, 21
  store i64 %1168, i64* %PC, align 8
  %1169 = inttoptr i64 %1167 to i32*
  %1170 = load i32, i32* %1169, align 4
  %1171 = sext i32 %1170 to i64
  store i64 %1171, i64* %RDX, align 8, !tbaa !2428
  %1172 = shl nsw i64 %1171, 3
  %1173 = add i64 %1172, %1166
  %1174 = add i64 %1151, 26
  store i64 %1174, i64* %PC, align 8
  %1175 = inttoptr i64 %1173 to double*
  %1176 = load double, double* %1175, align 8
  %1177 = fsub double %1164, %1176
  store double %1177, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %1178 = add i64 %1149, -56
  %1179 = add i64 %1151, 31
  store i64 %1179, i64* %PC, align 8
  %1180 = inttoptr i64 %1178 to double*
  store double %1177, double* %1180, align 8
  %1181 = load i64, i64* %RBP, align 8
  %1182 = add i64 %1181, -16
  %1183 = load i64, i64* %PC, align 8
  %1184 = add i64 %1183, 4
  store i64 %1184, i64* %PC, align 8
  %1185 = inttoptr i64 %1182 to i64*
  %1186 = load i64, i64* %1185, align 8
  store i64 %1186, i64* %RCX, align 8, !tbaa !2428
  %1187 = add i64 %1181, -28
  %1188 = add i64 %1183, 7
  store i64 %1188, i64* %PC, align 8
  %1189 = inttoptr i64 %1187 to i32*
  %1190 = load i32, i32* %1189, align 4
  %1191 = add i32 %1190, 1
  %1192 = zext i32 %1191 to i64
  store i64 %1192, i64* %RAX, align 8, !tbaa !2428
  %1193 = icmp eq i32 %1190, -1
  %1194 = icmp eq i32 %1191, 0
  %1195 = or i1 %1193, %1194
  %1196 = zext i1 %1195 to i8
  store i8 %1196, i8* %14, align 1, !tbaa !2433
  %1197 = and i32 %1191, 255
  %1198 = tail call i32 @llvm.ctpop.i32(i32 %1197) #10
  %1199 = trunc i32 %1198 to i8
  %1200 = and i8 %1199, 1
  %1201 = xor i8 %1200, 1
  store i8 %1201, i8* %21, align 1, !tbaa !2447
  %1202 = xor i32 %1190, %1191
  %1203 = lshr i32 %1202, 4
  %1204 = trunc i32 %1203 to i8
  %1205 = and i8 %1204, 1
  store i8 %1205, i8* %27, align 1, !tbaa !2451
  %1206 = zext i1 %1194 to i8
  store i8 %1206, i8* %30, align 1, !tbaa !2448
  %1207 = lshr i32 %1191, 31
  %1208 = trunc i32 %1207 to i8
  store i8 %1208, i8* %33, align 1, !tbaa !2449
  %1209 = lshr i32 %1190, 31
  %1210 = xor i32 %1207, %1209
  %1211 = add nuw nsw i32 %1210, %1207
  %1212 = icmp eq i32 %1211, 2
  %1213 = zext i1 %1212 to i8
  store i8 %1213, i8* %39, align 1, !tbaa !2450
  %1214 = sext i32 %1191 to i64
  store i64 %1214, i64* %RDX, align 8, !tbaa !2428
  %1215 = shl nsw i64 %1214, 3
  %1216 = add i64 %1215, %1186
  %1217 = add i64 %1183, 18
  store i64 %1217, i64* %PC, align 8
  %1218 = inttoptr i64 %1216 to double*
  %1219 = load double, double* %1218, align 8
  store double %1219, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %1220 = add i64 %1183, 22
  store i64 %1220, i64* %PC, align 8
  %1221 = load i64, i64* %1185, align 8
  store i64 %1221, i64* %RCX, align 8, !tbaa !2428
  %1222 = add i64 %1181, -32
  %1223 = add i64 %1183, 25
  store i64 %1223, i64* %PC, align 8
  %1224 = inttoptr i64 %1222 to i32*
  %1225 = load i32, i32* %1224, align 4
  %1226 = add i32 %1225, 1
  %1227 = zext i32 %1226 to i64
  store i64 %1227, i64* %RAX, align 8, !tbaa !2428
  %1228 = icmp eq i32 %1225, -1
  %1229 = icmp eq i32 %1226, 0
  %1230 = or i1 %1228, %1229
  %1231 = zext i1 %1230 to i8
  store i8 %1231, i8* %14, align 1, !tbaa !2433
  %1232 = and i32 %1226, 255
  %1233 = tail call i32 @llvm.ctpop.i32(i32 %1232) #10
  %1234 = trunc i32 %1233 to i8
  %1235 = and i8 %1234, 1
  %1236 = xor i8 %1235, 1
  store i8 %1236, i8* %21, align 1, !tbaa !2447
  %1237 = xor i32 %1225, %1226
  %1238 = lshr i32 %1237, 4
  %1239 = trunc i32 %1238 to i8
  %1240 = and i8 %1239, 1
  store i8 %1240, i8* %27, align 1, !tbaa !2451
  %1241 = zext i1 %1229 to i8
  store i8 %1241, i8* %30, align 1, !tbaa !2448
  %1242 = lshr i32 %1226, 31
  %1243 = trunc i32 %1242 to i8
  store i8 %1243, i8* %33, align 1, !tbaa !2449
  %1244 = lshr i32 %1225, 31
  %1245 = xor i32 %1242, %1244
  %1246 = add nuw nsw i32 %1245, %1242
  %1247 = icmp eq i32 %1246, 2
  %1248 = zext i1 %1247 to i8
  store i8 %1248, i8* %39, align 1, !tbaa !2450
  %1249 = sext i32 %1226 to i64
  store i64 %1249, i64* %RDX, align 8, !tbaa !2428
  %1250 = shl nsw i64 %1249, 3
  %1251 = add i64 %1250, %1221
  %1252 = add i64 %1183, 36
  store i64 %1252, i64* %PC, align 8
  %1253 = inttoptr i64 %1251 to double*
  %1254 = load double, double* %1253, align 8
  %1255 = fsub double %1219, %1254
  store double %1255, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %1256 = load i64, i64* %RBP, align 8
  %1257 = add i64 %1256, -64
  %1258 = add i64 %1183, 41
  store i64 %1258, i64* %PC, align 8
  %1259 = inttoptr i64 %1257 to double*
  store double %1255, double* %1259, align 8
  %1260 = load i64, i64* %RBP, align 8
  %1261 = add i64 %1260, -16
  %1262 = load i64, i64* %PC, align 8
  %1263 = add i64 %1262, 4
  store i64 %1263, i64* %PC, align 8
  %1264 = inttoptr i64 %1261 to i64*
  %1265 = load i64, i64* %1264, align 8
  store i64 %1265, i64* %RCX, align 8, !tbaa !2428
  %1266 = add i64 %1260, -32
  %1267 = add i64 %1262, 8
  store i64 %1267, i64* %PC, align 8
  %1268 = inttoptr i64 %1266 to i32*
  %1269 = load i32, i32* %1268, align 4
  %1270 = sext i32 %1269 to i64
  store i64 %1270, i64* %RDX, align 8, !tbaa !2428
  %1271 = shl nsw i64 %1270, 3
  %1272 = add i64 %1271, %1265
  %1273 = add i64 %1262, 13
  store i64 %1273, i64* %PC, align 8
  %1274 = inttoptr i64 %1272 to double*
  %1275 = load double, double* %1274, align 8
  store double %1275, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %1276 = add i64 %1262, 17
  store i64 %1276, i64* %PC, align 8
  %1277 = load i64, i64* %1264, align 8
  store i64 %1277, i64* %RCX, align 8, !tbaa !2428
  %1278 = add i64 %1260, -28
  %1279 = add i64 %1262, 21
  store i64 %1279, i64* %PC, align 8
  %1280 = inttoptr i64 %1278 to i32*
  %1281 = load i32, i32* %1280, align 4
  %1282 = sext i32 %1281 to i64
  store i64 %1282, i64* %RDX, align 8, !tbaa !2428
  %1283 = shl nsw i64 %1282, 3
  %1284 = add i64 %1283, %1277
  %1285 = add i64 %1262, 26
  store i64 %1285, i64* %PC, align 8
  %1286 = inttoptr i64 %1284 to double*
  %1287 = load double, double* %1286, align 8
  %1288 = fadd double %1275, %1287
  store double %1288, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %1289 = add i64 %1262, 31
  store i64 %1289, i64* %PC, align 8
  store double %1288, double* %1286, align 8
  %1290 = load i64, i64* %RBP, align 8
  %1291 = add i64 %1290, -16
  %1292 = load i64, i64* %PC, align 8
  %1293 = add i64 %1292, 4
  store i64 %1293, i64* %PC, align 8
  %1294 = inttoptr i64 %1291 to i64*
  %1295 = load i64, i64* %1294, align 8
  store i64 %1295, i64* %RCX, align 8, !tbaa !2428
  %1296 = add i64 %1290, -32
  %1297 = add i64 %1292, 7
  store i64 %1297, i64* %PC, align 8
  %1298 = inttoptr i64 %1296 to i32*
  %1299 = load i32, i32* %1298, align 4
  %1300 = add i32 %1299, 1
  %1301 = zext i32 %1300 to i64
  store i64 %1301, i64* %RAX, align 8, !tbaa !2428
  %1302 = icmp eq i32 %1299, -1
  %1303 = icmp eq i32 %1300, 0
  %1304 = or i1 %1302, %1303
  %1305 = zext i1 %1304 to i8
  store i8 %1305, i8* %14, align 1, !tbaa !2433
  %1306 = and i32 %1300, 255
  %1307 = tail call i32 @llvm.ctpop.i32(i32 %1306) #10
  %1308 = trunc i32 %1307 to i8
  %1309 = and i8 %1308, 1
  %1310 = xor i8 %1309, 1
  store i8 %1310, i8* %21, align 1, !tbaa !2447
  %1311 = xor i32 %1299, %1300
  %1312 = lshr i32 %1311, 4
  %1313 = trunc i32 %1312 to i8
  %1314 = and i8 %1313, 1
  store i8 %1314, i8* %27, align 1, !tbaa !2451
  %1315 = zext i1 %1303 to i8
  store i8 %1315, i8* %30, align 1, !tbaa !2448
  %1316 = lshr i32 %1300, 31
  %1317 = trunc i32 %1316 to i8
  store i8 %1317, i8* %33, align 1, !tbaa !2449
  %1318 = lshr i32 %1299, 31
  %1319 = xor i32 %1316, %1318
  %1320 = add nuw nsw i32 %1319, %1316
  %1321 = icmp eq i32 %1320, 2
  %1322 = zext i1 %1321 to i8
  store i8 %1322, i8* %39, align 1, !tbaa !2450
  %1323 = sext i32 %1300 to i64
  store i64 %1323, i64* %RDX, align 8, !tbaa !2428
  %1324 = shl nsw i64 %1323, 3
  %1325 = add i64 %1324, %1295
  %1326 = add i64 %1292, 18
  store i64 %1326, i64* %PC, align 8
  %1327 = inttoptr i64 %1325 to double*
  %1328 = load double, double* %1327, align 8
  store double %1328, double* %1058, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %1329 = add i64 %1292, 22
  store i64 %1329, i64* %PC, align 8
  %1330 = load i64, i64* %1294, align 8
  store i64 %1330, i64* %RCX, align 8, !tbaa !2428
  %1331 = add i64 %1290, -28
  %1332 = add i64 %1292, 25
  store i64 %1332, i64* %PC, align 8
  %1333 = inttoptr i64 %1331 to i32*
  %1334 = load i32, i32* %1333, align 4
  %1335 = add i32 %1334, 1
  %1336 = zext i32 %1335 to i64
  store i64 %1336, i64* %RAX, align 8, !tbaa !2428
  %1337 = icmp eq i32 %1334, -1
  %1338 = icmp eq i32 %1335, 0
  %1339 = or i1 %1337, %1338
  %1340 = zext i1 %1339 to i8
  store i8 %1340, i8* %14, align 1, !tbaa !2433
  %1341 = and i32 %1335, 255
  %1342 = tail call i32 @llvm.ctpop.i32(i32 %1341) #10
  %1343 = trunc i32 %1342 to i8
  %1344 = and i8 %1343, 1
  %1345 = xor i8 %1344, 1
  store i8 %1345, i8* %21, align 1, !tbaa !2447
  %1346 = xor i32 %1334, %1335
  %1347 = lshr i32 %1346, 4
  %1348 = trunc i32 %1347 to i8
  %1349 = and i8 %1348, 1
  store i8 %1349, i8* %27, align 1, !tbaa !2451
  %1350 = zext i1 %1338 to i8
  store i8 %1350, i8* %30, align 1, !tbaa !2448
  %1351 = lshr i32 %1335, 31
  %1352 = trunc i32 %1351 to i8
  store i8 %1352, i8* %33, align 1, !tbaa !2449
  %1353 = lshr i32 %1334, 31
  %1354 = xor i32 %1351, %1353
  %1355 = add nuw nsw i32 %1354, %1351
  %1356 = icmp eq i32 %1355, 2
  %1357 = zext i1 %1356 to i8
  store i8 %1357, i8* %39, align 1, !tbaa !2450
  %1358 = sext i32 %1335 to i64
  store i64 %1358, i64* %RDX, align 8, !tbaa !2428
  %1359 = shl nsw i64 %1358, 3
  %1360 = add i64 %1359, %1330
  %1361 = add i64 %1292, 36
  store i64 %1361, i64* %PC, align 8
  %1362 = inttoptr i64 %1360 to double*
  %1363 = load double, double* %1362, align 8
  %1364 = fadd double %1328, %1363
  store double %1364, double* %1058, align 1, !tbaa !2452
  store i64 0, i64* %1059, align 1, !tbaa !2452
  %1365 = add i64 %1292, 41
  store i64 %1365, i64* %PC, align 8
  store double %1364, double* %1362, align 8
  %1366 = load i64, i64* %RBP, align 8
  %1367 = add i64 %1366, -56
  %1368 = load i64, i64* %PC, align 8
  %1369 = add i64 %1368, 5
  store i64 %1369, i64* %PC, align 8
  %1370 = inttoptr i64 %1367 to i64*
  %1371 = load i64, i64* %1370, align 8
  %1372 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1371, i64* %1372, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %1373 = add i64 %1366, -16
  %1374 = add i64 %1368, 9
  store i64 %1374, i64* %PC, align 8
  %1375 = inttoptr i64 %1373 to i64*
  %1376 = load i64, i64* %1375, align 8
  store i64 %1376, i64* %RCX, align 8, !tbaa !2428
  %1377 = add i64 %1366, -32
  %1378 = add i64 %1368, 13
  store i64 %1378, i64* %PC, align 8
  %1379 = inttoptr i64 %1377 to i32*
  %1380 = load i32, i32* %1379, align 4
  %1381 = sext i32 %1380 to i64
  store i64 %1381, i64* %RDX, align 8, !tbaa !2428
  %1382 = shl nsw i64 %1381, 3
  %1383 = add i64 %1382, %1376
  %1384 = add i64 %1368, 18
  store i64 %1384, i64* %PC, align 8
  %1385 = inttoptr i64 %1383 to i64*
  store i64 %1371, i64* %1385, align 8
  %1386 = load i64, i64* %RBP, align 8
  %1387 = add i64 %1386, -64
  %1388 = load i64, i64* %PC, align 8
  %1389 = add i64 %1388, 5
  store i64 %1389, i64* %PC, align 8
  %1390 = inttoptr i64 %1387 to i64*
  %1391 = load i64, i64* %1390, align 8
  store i64 %1391, i64* %1372, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1060, align 1, !tbaa !2452
  %1392 = add i64 %1386, -16
  %1393 = add i64 %1388, 9
  store i64 %1393, i64* %PC, align 8
  %1394 = inttoptr i64 %1392 to i64*
  %1395 = load i64, i64* %1394, align 8
  store i64 %1395, i64* %RCX, align 8, !tbaa !2428
  %1396 = add i64 %1386, -32
  %1397 = add i64 %1388, 12
  store i64 %1397, i64* %PC, align 8
  %1398 = inttoptr i64 %1396 to i32*
  %1399 = load i32, i32* %1398, align 4
  %1400 = add i32 %1399, 1
  %1401 = zext i32 %1400 to i64
  store i64 %1401, i64* %RAX, align 8, !tbaa !2428
  %1402 = icmp eq i32 %1399, -1
  %1403 = icmp eq i32 %1400, 0
  %1404 = or i1 %1402, %1403
  %1405 = zext i1 %1404 to i8
  store i8 %1405, i8* %14, align 1, !tbaa !2433
  %1406 = and i32 %1400, 255
  %1407 = tail call i32 @llvm.ctpop.i32(i32 %1406) #10
  %1408 = trunc i32 %1407 to i8
  %1409 = and i8 %1408, 1
  %1410 = xor i8 %1409, 1
  store i8 %1410, i8* %21, align 1, !tbaa !2447
  %1411 = xor i32 %1399, %1400
  %1412 = lshr i32 %1411, 4
  %1413 = trunc i32 %1412 to i8
  %1414 = and i8 %1413, 1
  store i8 %1414, i8* %27, align 1, !tbaa !2451
  %1415 = zext i1 %1403 to i8
  store i8 %1415, i8* %30, align 1, !tbaa !2448
  %1416 = lshr i32 %1400, 31
  %1417 = trunc i32 %1416 to i8
  store i8 %1417, i8* %33, align 1, !tbaa !2449
  %1418 = lshr i32 %1399, 31
  %1419 = xor i32 %1416, %1418
  %1420 = add nuw nsw i32 %1419, %1416
  %1421 = icmp eq i32 %1420, 2
  %1422 = zext i1 %1421 to i8
  store i8 %1422, i8* %39, align 1, !tbaa !2450
  %1423 = sext i32 %1400 to i64
  store i64 %1423, i64* %RDX, align 8, !tbaa !2428
  %1424 = shl nsw i64 %1423, 3
  %1425 = add i64 %1424, %1395
  %1426 = add i64 %1388, 23
  store i64 %1426, i64* %PC, align 8
  %1427 = inttoptr i64 %1425 to i64*
  store i64 %1391, i64* %1427, align 8
  %1428 = load i64, i64* %RBP, align 8
  %1429 = add i64 %1428, -28
  %1430 = load i64, i64* %PC, align 8
  %1431 = add i64 %1430, 3
  store i64 %1431, i64* %PC, align 8
  %1432 = inttoptr i64 %1429 to i32*
  %1433 = load i32, i32* %1432, align 4
  %1434 = add i32 %1433, 2
  %1435 = zext i32 %1434 to i64
  store i64 %1435, i64* %RAX, align 8, !tbaa !2428
  %1436 = icmp ugt i32 %1433, -3
  %1437 = zext i1 %1436 to i8
  store i8 %1437, i8* %14, align 1, !tbaa !2433
  %1438 = and i32 %1434, 255
  %1439 = tail call i32 @llvm.ctpop.i32(i32 %1438) #10
  %1440 = trunc i32 %1439 to i8
  %1441 = and i8 %1440, 1
  %1442 = xor i8 %1441, 1
  store i8 %1442, i8* %21, align 1, !tbaa !2447
  %1443 = xor i32 %1433, %1434
  %1444 = lshr i32 %1443, 4
  %1445 = trunc i32 %1444 to i8
  %1446 = and i8 %1445, 1
  store i8 %1446, i8* %27, align 1, !tbaa !2451
  %1447 = icmp eq i32 %1434, 0
  %1448 = zext i1 %1447 to i8
  store i8 %1448, i8* %30, align 1, !tbaa !2448
  %1449 = lshr i32 %1434, 31
  %1450 = trunc i32 %1449 to i8
  store i8 %1450, i8* %33, align 1, !tbaa !2449
  %1451 = lshr i32 %1433, 31
  %1452 = xor i32 %1449, %1451
  %1453 = add nuw nsw i32 %1452, %1449
  %1454 = icmp eq i32 %1453, 2
  %1455 = zext i1 %1454 to i8
  store i8 %1455, i8* %39, align 1, !tbaa !2450
  %1456 = add i64 %1430, 9
  store i64 %1456, i64* %PC, align 8
  store i32 %1434, i32* %1432, align 4
  %1457 = load i64, i64* %PC, align 8
  %1458 = add i64 %1457, -215
  store i64 %1458, i64* %PC, align 8, !tbaa !2428
  br label %block_401af3

block_40188a:                                     ; preds = %block_40187b
  %1459 = add i64 %1112, 3
  store i64 %1459, i64* %PC, align 8
  %1460 = load i32, i32* %1085, align 4
  %1461 = zext i32 %1460 to i64
  store i64 %1461, i64* %RDI, align 8, !tbaa !2428
  %1462 = add i64 %1112, 6
  store i64 %1462, i64* %PC, align 8
  %1463 = load i32, i32* %1066, align 4
  %1464 = zext i32 %1463 to i64
  store i64 %1464, i64* %RSI, align 8, !tbaa !2428
  %1465 = add i64 %1063, -16
  %1466 = add i64 %1112, 10
  store i64 %1466, i64* %PC, align 8
  %1467 = inttoptr i64 %1465 to i64*
  %1468 = load i64, i64* %1467, align 8
  store i64 %1468, i64* %RDX, align 8, !tbaa !2428
  %1469 = add i64 %1063, -24
  %1470 = add i64 %1112, 14
  store i64 %1470, i64* %PC, align 8
  %1471 = inttoptr i64 %1469 to i64*
  %1472 = load i64, i64* %1471, align 8
  store i64 %1472, i64* %RCX, align 8, !tbaa !2428
  %1473 = add i64 %1112, 6774
  %1474 = add i64 %1112, 19
  %1475 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1476 = add i64 %1475, -8
  %1477 = inttoptr i64 %1476 to i64*
  store i64 %1474, i64* %1477, align 8
  store i64 %1476, i64* %RSP, align 8, !tbaa !2428
  store i64 %1473, i64* %PC, align 8, !tbaa !2428
  %1478 = tail call %struct.Memory* @sub_403300_cftmdl_renamed_(%struct.State* nonnull %0, i64 %1473, %struct.Memory* %MEMORY.2)
  %1479 = load i64, i64* %RBP, align 8
  %1480 = add i64 %1479, -44
  %1481 = load i64, i64* %PC, align 8
  %1482 = add i64 %1481, 3
  store i64 %1482, i64* %PC, align 8
  %1483 = inttoptr i64 %1480 to i32*
  %1484 = load i32, i32* %1483, align 4
  %1485 = shl i32 %1484, 2
  %1486 = zext i32 %1485 to i64
  store i64 %1486, i64* %RSI, align 8, !tbaa !2428
  %1487 = lshr i32 %1484, 30
  %1488 = trunc i32 %1487 to i8
  %1489 = and i8 %1488, 1
  store i8 %1489, i8* %14, align 1, !tbaa !2432
  %1490 = and i32 %1485, 252
  %1491 = tail call i32 @llvm.ctpop.i32(i32 %1490) #10
  %1492 = trunc i32 %1491 to i8
  %1493 = and i8 %1492, 1
  %1494 = xor i8 %1493, 1
  store i8 %1494, i8* %21, align 1, !tbaa !2432
  store i8 0, i8* %27, align 1, !tbaa !2432
  %1495 = icmp eq i32 %1485, 0
  %1496 = zext i1 %1495 to i8
  store i8 %1496, i8* %30, align 1, !tbaa !2432
  %1497 = lshr i32 %1484, 29
  %1498 = trunc i32 %1497 to i8
  %1499 = and i8 %1498, 1
  store i8 %1499, i8* %33, align 1, !tbaa !2432
  store i8 0, i8* %39, align 1, !tbaa !2432
  %1500 = add i64 %1481, 9
  store i64 %1500, i64* %PC, align 8
  store i32 %1485, i32* %1483, align 4
  %1501 = load i64, i64* %PC, align 8
  %1502 = add i64 %1501, -43
  store i64 %1502, i64* %PC, align 8, !tbaa !2428
  br label %block_40187b

block_401ae7:                                     ; preds = %block_4018c6
  %1503 = add i64 %1573, 237
  br label %block_401bd4

block_401bd4:                                     ; preds = %block_401ae7, %block_401bcf
  %.sink = phi i64 [ %1503, %block_401ae7 ], [ %1061, %block_401bcf ]
  %1504 = load i64, i64* %RSP, align 8
  %1505 = add i64 %1504, 112
  store i64 %1505, i64* %RSP, align 8, !tbaa !2428
  %1506 = icmp ugt i64 %1504, -113
  %1507 = zext i1 %1506 to i8
  store i8 %1507, i8* %14, align 1, !tbaa !2433
  %1508 = trunc i64 %1505 to i32
  %1509 = and i32 %1508, 255
  %1510 = tail call i32 @llvm.ctpop.i32(i32 %1509) #10
  %1511 = trunc i32 %1510 to i8
  %1512 = and i8 %1511, 1
  %1513 = xor i8 %1512, 1
  store i8 %1513, i8* %21, align 1, !tbaa !2447
  %1514 = xor i64 %1504, 16
  %1515 = xor i64 %1514, %1505
  %1516 = lshr i64 %1515, 4
  %1517 = trunc i64 %1516 to i8
  %1518 = and i8 %1517, 1
  store i8 %1518, i8* %27, align 1, !tbaa !2451
  %1519 = icmp eq i64 %1505, 0
  %1520 = zext i1 %1519 to i8
  store i8 %1520, i8* %30, align 1, !tbaa !2448
  %1521 = lshr i64 %1505, 63
  %1522 = trunc i64 %1521 to i8
  store i8 %1522, i8* %33, align 1, !tbaa !2449
  %1523 = lshr i64 %1504, 63
  %1524 = xor i64 %1521, %1523
  %1525 = add nuw nsw i64 %1524, %1521
  %1526 = icmp eq i64 %1525, 2
  %1527 = zext i1 %1526 to i8
  store i8 %1527, i8* %39, align 1, !tbaa !2450
  %1528 = add i64 %.sink, 5
  store i64 %1528, i64* %PC, align 8
  %1529 = add i64 %1504, 120
  %1530 = inttoptr i64 %1505 to i64*
  %1531 = load i64, i64* %1530, align 8
  store i64 %1531, i64* %RBP, align 8, !tbaa !2428
  store i64 %1529, i64* %RSP, align 8, !tbaa !2428
  %1532 = add i64 %.sink, 6
  store i64 %1532, i64* %PC, align 8
  %1533 = inttoptr i64 %1529 to i64*
  %1534 = load i64, i64* %1533, align 8
  store i64 %1534, i64* %PC, align 8, !tbaa !2428
  %1535 = add i64 %1504, 128
  store i64 %1535, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.1

block_4018c6:                                     ; preds = %block_4018b0, %block_4018d2
  %1536 = phi i64 [ %1005, %block_4018d2 ], [ %.pre2, %block_4018b0 ]
  %1537 = load i64, i64* %RBP, align 8
  %1538 = add i64 %1537, -28
  %1539 = add i64 %1536, 3
  store i64 %1539, i64* %PC, align 8
  %1540 = inttoptr i64 %1538 to i32*
  %1541 = load i32, i32* %1540, align 4
  %1542 = zext i32 %1541 to i64
  store i64 %1542, i64* %RAX, align 8, !tbaa !2428
  %1543 = add i64 %1537, -44
  %1544 = add i64 %1536, 6
  store i64 %1544, i64* %PC, align 8
  %1545 = inttoptr i64 %1543 to i32*
  %1546 = load i32, i32* %1545, align 4
  %1547 = sub i32 %1541, %1546
  %1548 = icmp ult i32 %1541, %1546
  %1549 = zext i1 %1548 to i8
  store i8 %1549, i8* %14, align 1, !tbaa !2433
  %1550 = and i32 %1547, 255
  %1551 = tail call i32 @llvm.ctpop.i32(i32 %1550) #10
  %1552 = trunc i32 %1551 to i8
  %1553 = and i8 %1552, 1
  %1554 = xor i8 %1553, 1
  store i8 %1554, i8* %21, align 1, !tbaa !2447
  %1555 = xor i32 %1546, %1541
  %1556 = xor i32 %1555, %1547
  %1557 = lshr i32 %1556, 4
  %1558 = trunc i32 %1557 to i8
  %1559 = and i8 %1558, 1
  store i8 %1559, i8* %27, align 1, !tbaa !2451
  %1560 = icmp eq i32 %1547, 0
  %1561 = zext i1 %1560 to i8
  store i8 %1561, i8* %30, align 1, !tbaa !2448
  %1562 = lshr i32 %1547, 31
  %1563 = trunc i32 %1562 to i8
  store i8 %1563, i8* %33, align 1, !tbaa !2449
  %1564 = lshr i32 %1541, 31
  %1565 = lshr i32 %1546, 31
  %1566 = xor i32 %1565, %1564
  %1567 = xor i32 %1562, %1564
  %1568 = add nuw nsw i32 %1567, %1566
  %1569 = icmp eq i32 %1568, 2
  %1570 = zext i1 %1569 to i8
  store i8 %1570, i8* %39, align 1, !tbaa !2450
  %1571 = icmp ne i8 %1563, 0
  %1572 = xor i1 %1571, %1569
  %.v6 = select i1 %1572, i64 12, i64 545
  %1573 = add i64 %1536, %.v6
  store i64 %1573, i64* %PC, align 8, !tbaa !2428
  br i1 %1572, label %block_4018d2, label %block_401ae7

block_401864:                                     ; preds = %block_401840
  %1574 = add i64 %91, 3
  store i64 %1574, i64* %PC, align 8
  %1575 = load i32, i32* %65, align 4
  %1576 = zext i32 %1575 to i64
  store i64 %1576, i64* %RDI, align 8, !tbaa !2428
  %1577 = add i64 %61, -16
  %1578 = add i64 %91, 7
  store i64 %1578, i64* %PC, align 8
  %1579 = inttoptr i64 %1577 to i64*
  %1580 = load i64, i64* %1579, align 8
  store i64 %1580, i64* %RSI, align 8, !tbaa !2428
  %1581 = add i64 %61, -24
  %1582 = add i64 %91, 11
  store i64 %1582, i64* %PC, align 8
  %1583 = inttoptr i64 %1581 to i64*
  %1584 = load i64, i64* %1583, align 8
  store i64 %1584, i64* %RDX, align 8, !tbaa !2428
  %1585 = add i64 %91, 4108
  %1586 = add i64 %91, 16
  %1587 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1588 = add i64 %1587, -8
  %1589 = inttoptr i64 %1588 to i64*
  store i64 %1586, i64* %1589, align 8
  store i64 %1588, i64* %RSP, align 8, !tbaa !2428
  store i64 %1585, i64* %PC, align 8, !tbaa !2428
  %1590 = tail call %struct.Memory* @sub_402870_cft1st_renamed_(%struct.State* nonnull %0, i64 %1585, %struct.Memory* %2)
  %1591 = load i64, i64* %RBP, align 8
  %1592 = add i64 %1591, -44
  %1593 = load i64, i64* %PC, align 8
  %1594 = add i64 %1593, 7
  store i64 %1594, i64* %PC, align 8
  %1595 = inttoptr i64 %1592 to i32*
  store i32 8, i32* %1595, align 4
  %.pre = load i64, i64* %PC, align 8
  br label %block_40187b
}

; Function Attrs: noinline
define %struct.Memory* @sub_403300_cftmdl(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_403300:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %4 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %8 = load i64, i64* %RBP, align 8
  %9 = add i64 %1, 1
  store i64 %9, i64* %PC, align 8
  %10 = load i64, i64* %RSP, align 8, !tbaa !2428
  %11 = add i64 %10, -8
  %12 = inttoptr i64 %11 to i64*
  store i64 %8, i64* %12, align 8
  %13 = load i64, i64* %PC, align 8
  store i64 %11, i64* %RBP, align 8, !tbaa !2428
  %14 = add i64 %10, -56
  store i64 %14, i64* %RSP, align 8, !tbaa !2428
  %15 = icmp ult i64 %11, 48
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %16, i8* %17, align 1, !tbaa !2433
  %18 = trunc i64 %14 to i32
  %19 = and i32 %18, 255
  %20 = tail call i32 @llvm.ctpop.i32(i32 %19) #10
  %21 = trunc i32 %20 to i8
  %22 = and i8 %21, 1
  %23 = xor i8 %22, 1
  %24 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %23, i8* %24, align 1, !tbaa !2447
  %25 = xor i64 %11, 16
  %26 = xor i64 %25, %14
  %27 = lshr i64 %26, 4
  %28 = trunc i64 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1, !tbaa !2451
  %31 = icmp eq i64 %14, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1, !tbaa !2448
  %34 = lshr i64 %14, 63
  %35 = trunc i64 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1, !tbaa !2449
  %37 = lshr i64 %11, 63
  %38 = xor i64 %34, %37
  %39 = add nuw nsw i64 %38, %37
  %40 = icmp eq i64 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1, !tbaa !2450
  %43 = add i64 %10, -12
  %44 = load i32, i32* %EDI, align 4
  %45 = add i64 %13, 10
  store i64 %45, i64* %PC, align 8
  %46 = inttoptr i64 %43 to i32*
  store i32 %44, i32* %46, align 4
  %47 = load i64, i64* %RBP, align 8
  %48 = add i64 %47, -8
  %49 = load i32, i32* %ESI, align 4
  %50 = load i64, i64* %PC, align 8
  %51 = add i64 %50, 3
  store i64 %51, i64* %PC, align 8
  %52 = inttoptr i64 %48 to i32*
  store i32 %49, i32* %52, align 4
  %53 = load i64, i64* %RBP, align 8
  %54 = add i64 %53, -16
  %55 = load i64, i64* %RDX, align 8
  %56 = load i64, i64* %PC, align 8
  %57 = add i64 %56, 4
  store i64 %57, i64* %PC, align 8
  %58 = inttoptr i64 %54 to i64*
  store i64 %55, i64* %58, align 8
  %59 = load i64, i64* %RBP, align 8
  %60 = add i64 %59, -24
  %61 = load i64, i64* %RCX, align 8
  %62 = load i64, i64* %PC, align 8
  %63 = add i64 %62, 4
  store i64 %63, i64* %PC, align 8
  %64 = inttoptr i64 %60 to i64*
  store i64 %61, i64* %64, align 8
  %65 = load i64, i64* %RBP, align 8
  %66 = add i64 %65, -8
  %67 = load i64, i64* %PC, align 8
  %68 = add i64 %67, 3
  store i64 %68, i64* %PC, align 8
  %69 = inttoptr i64 %66 to i32*
  %70 = load i32, i32* %69, align 4
  %71 = shl i32 %70, 2
  %72 = zext i32 %71 to i64
  store i64 %72, i64* %RSI, align 8, !tbaa !2428
  %73 = lshr i32 %70, 30
  %74 = trunc i32 %73 to i8
  %75 = and i8 %74, 1
  store i8 %75, i8* %17, align 1, !tbaa !2432
  %76 = and i32 %71, 252
  %77 = tail call i32 @llvm.ctpop.i32(i32 %76) #10
  %78 = trunc i32 %77 to i8
  %79 = and i8 %78, 1
  %80 = xor i8 %79, 1
  store i8 %80, i8* %24, align 1, !tbaa !2432
  store i8 0, i8* %30, align 1, !tbaa !2432
  %81 = icmp eq i32 %71, 0
  %82 = zext i1 %81 to i8
  store i8 %82, i8* %33, align 1, !tbaa !2432
  %83 = lshr i32 %70, 29
  %84 = trunc i32 %83 to i8
  %85 = and i8 %84, 1
  store i8 %85, i8* %36, align 1, !tbaa !2432
  store i8 0, i8* %42, align 1, !tbaa !2432
  %86 = add i64 %65, -56
  %87 = add i64 %67, 9
  store i64 %87, i64* %PC, align 8
  %88 = inttoptr i64 %86 to i32*
  store i32 %71, i32* %88, align 4
  %89 = load i64, i64* %RBP, align 8
  %90 = add i64 %89, -28
  %91 = load i64, i64* %PC, align 8
  %92 = add i64 %91, 7
  store i64 %92, i64* %PC, align 8
  %93 = inttoptr i64 %90 to i32*
  store i32 0, i32* %93, align 4
  %94 = bitcast [32 x %union.VectorReg]* %5 to double*
  %95 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %96 = bitcast i64* %95 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_403326

block_403c22:                                     ; preds = %block_403910
  %97 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 80) to i64*), align 16
  store i64 %97, i64* %276, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %98 = load i64, i64* %RBP, align 8
  %99 = add i64 %98, -24
  %100 = add i64 %1622, 12
  store i64 %100, i64* %PC, align 8
  %101 = inttoptr i64 %99 to i64*
  %102 = load i64, i64* %101, align 8
  store i64 %102, i64* %RAX, align 8, !tbaa !2428
  %103 = add i64 %98, -52
  %104 = add i64 %1622, 15
  store i64 %104, i64* %PC, align 8
  %105 = inttoptr i64 %103 to i32*
  %106 = load i32, i32* %105, align 4
  %107 = add i32 %106, 2
  %108 = zext i32 %107 to i64
  store i64 %108, i64* %RCX, align 8, !tbaa !2428
  %109 = icmp ugt i32 %106, -3
  %110 = zext i1 %109 to i8
  store i8 %110, i8* %17, align 1, !tbaa !2433
  %111 = and i32 %107, 255
  %112 = tail call i32 @llvm.ctpop.i32(i32 %111) #10
  %113 = trunc i32 %112 to i8
  %114 = and i8 %113, 1
  %115 = xor i8 %114, 1
  store i8 %115, i8* %24, align 1, !tbaa !2447
  %116 = xor i32 %106, %107
  %117 = lshr i32 %116, 4
  %118 = trunc i32 %117 to i8
  %119 = and i8 %118, 1
  store i8 %119, i8* %30, align 1, !tbaa !2451
  %120 = icmp eq i32 %107, 0
  %121 = zext i1 %120 to i8
  store i8 %121, i8* %33, align 1, !tbaa !2448
  %122 = lshr i32 %107, 31
  %123 = trunc i32 %122 to i8
  store i8 %123, i8* %36, align 1, !tbaa !2449
  %124 = lshr i32 %106, 31
  %125 = xor i32 %122, %124
  %126 = add nuw nsw i32 %125, %122
  %127 = icmp eq i32 %126, 2
  %128 = zext i1 %127 to i8
  store i8 %128, i8* %42, align 1, !tbaa !2450
  %129 = sext i32 %107 to i64
  store i64 %129, i64* %RDX, align 8, !tbaa !2428
  %130 = shl nsw i64 %129, 3
  %131 = add i64 %130, %102
  %132 = add i64 %1622, 26
  store i64 %132, i64* %PC, align 8
  %133 = inttoptr i64 %131 to i64*
  %134 = load i64, i64* %133, align 8
  store i64 %134, i64* %1239, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %135 = add i64 %98, -72
  %136 = add i64 %1622, 31
  store i64 %136, i64* %PC, align 8
  %137 = inttoptr i64 %135 to i64*
  store i64 %134, i64* %137, align 8
  %138 = load i64, i64* %RBP, align 8
  %139 = add i64 %138, -24
  %140 = load i64, i64* %PC, align 8
  %141 = add i64 %140, 4
  store i64 %141, i64* %PC, align 8
  %142 = inttoptr i64 %139 to i64*
  %143 = load i64, i64* %142, align 8
  store i64 %143, i64* %RAX, align 8, !tbaa !2428
  %144 = add i64 %138, -52
  %145 = add i64 %140, 7
  store i64 %145, i64* %PC, align 8
  %146 = inttoptr i64 %144 to i32*
  %147 = load i32, i32* %146, align 4
  %148 = add i32 %147, 3
  %149 = zext i32 %148 to i64
  store i64 %149, i64* %RCX, align 8, !tbaa !2428
  %150 = icmp ugt i32 %147, -4
  %151 = zext i1 %150 to i8
  store i8 %151, i8* %17, align 1, !tbaa !2433
  %152 = and i32 %148, 255
  %153 = tail call i32 @llvm.ctpop.i32(i32 %152) #10
  %154 = trunc i32 %153 to i8
  %155 = and i8 %154, 1
  %156 = xor i8 %155, 1
  store i8 %156, i8* %24, align 1, !tbaa !2447
  %157 = xor i32 %147, %148
  %158 = lshr i32 %157, 4
  %159 = trunc i32 %158 to i8
  %160 = and i8 %159, 1
  store i8 %160, i8* %30, align 1, !tbaa !2451
  %161 = icmp eq i32 %148, 0
  %162 = zext i1 %161 to i8
  store i8 %162, i8* %33, align 1, !tbaa !2448
  %163 = lshr i32 %148, 31
  %164 = trunc i32 %163 to i8
  store i8 %164, i8* %36, align 1, !tbaa !2449
  %165 = lshr i32 %147, 31
  %166 = xor i32 %163, %165
  %167 = add nuw nsw i32 %166, %163
  %168 = icmp eq i32 %167, 2
  %169 = zext i1 %168 to i8
  store i8 %169, i8* %42, align 1, !tbaa !2450
  %170 = sext i32 %148 to i64
  store i64 %170, i64* %RDX, align 8, !tbaa !2428
  %171 = shl nsw i64 %170, 3
  %172 = add i64 %171, %143
  %173 = add i64 %140, 18
  store i64 %173, i64* %PC, align 8
  %174 = inttoptr i64 %172 to i64*
  %175 = load i64, i64* %174, align 8
  store i64 %175, i64* %1239, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %176 = add i64 %138, -80
  %177 = add i64 %140, 23
  store i64 %177, i64* %PC, align 8
  %178 = inttoptr i64 %176 to i64*
  store i64 %175, i64* %178, align 8
  %179 = load i64, i64* %RBP, align 8
  %180 = add i64 %179, -72
  %181 = load i64, i64* %PC, align 8
  %182 = add i64 %181, 5
  store i64 %182, i64* %PC, align 8
  %183 = inttoptr i64 %180 to double*
  %184 = load double, double* %183, align 8
  store double %184, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %185 = load <2 x i32>, <2 x i32>* %1444, align 1
  %186 = load <2 x i32>, <2 x i32>* %1445, align 1
  %187 = extractelement <2 x i32> %185, i32 0
  store i32 %187, i32* %1446, align 1, !tbaa !2475
  %188 = extractelement <2 x i32> %185, i32 1
  store i32 %188, i32* %1448, align 1, !tbaa !2475
  %189 = extractelement <2 x i32> %186, i32 0
  store i32 %189, i32* %1450, align 1, !tbaa !2475
  %190 = extractelement <2 x i32> %186, i32 1
  store i32 %190, i32* %1452, align 1, !tbaa !2475
  %191 = add i64 %179, -88
  %192 = add i64 %181, 13
  store i64 %192, i64* %PC, align 8
  %193 = load double, double* %1453, align 1
  %194 = inttoptr i64 %191 to double*
  %195 = load double, double* %194, align 8
  %196 = fmul double %193, %195
  store double %196, double* %1453, align 1, !tbaa !2452
  %197 = add i64 %179, -80
  %198 = add i64 %181, 18
  store i64 %198, i64* %PC, align 8
  %199 = inttoptr i64 %197 to double*
  %200 = load double, double* %199, align 8
  %201 = fmul double %196, %200
  store double %201, double* %1453, align 1, !tbaa !2452
  %202 = fsub double %184, %201
  store double %202, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %203 = add i64 %179, -104
  %204 = add i64 %181, 27
  store i64 %204, i64* %PC, align 8
  %205 = inttoptr i64 %203 to double*
  store double %202, double* %205, align 8
  %206 = load i64, i64* %RBP, align 8
  %207 = add i64 %206, -88
  %208 = load i64, i64* %PC, align 8
  %209 = add i64 %208, 5
  store i64 %209, i64* %PC, align 8
  %210 = load double, double* %94, align 1
  %211 = inttoptr i64 %207 to double*
  %212 = load double, double* %211, align 8
  %213 = fmul double %210, %212
  store double %213, double* %94, align 1, !tbaa !2452
  %214 = add i64 %206, -72
  %215 = add i64 %208, 10
  store i64 %215, i64* %PC, align 8
  %216 = inttoptr i64 %214 to double*
  %217 = load double, double* %216, align 8
  %218 = fmul double %213, %217
  store double %218, double* %94, align 1, !tbaa !2452
  %219 = add i64 %206, -80
  %220 = add i64 %208, 15
  store i64 %220, i64* %PC, align 8
  %221 = inttoptr i64 %219 to double*
  %222 = load double, double* %221, align 8
  %223 = fsub double %218, %222
  store double %223, double* %94, align 1, !tbaa !2452
  %224 = add i64 %206, -112
  %225 = add i64 %208, 20
  store i64 %225, i64* %PC, align 8
  %226 = inttoptr i64 %224 to double*
  store double %223, double* %226, align 8
  %227 = load i64, i64* %RBP, align 8
  %228 = add i64 %227, -44
  %229 = load i64, i64* %PC, align 8
  %230 = add i64 %229, 3
  store i64 %230, i64* %PC, align 8
  %231 = inttoptr i64 %228 to i32*
  %232 = load i32, i32* %231, align 4
  %233 = zext i32 %232 to i64
  store i64 %233, i64* %RCX, align 8, !tbaa !2428
  %234 = add i64 %227, -56
  %235 = add i64 %229, 6
  store i64 %235, i64* %PC, align 8
  %236 = inttoptr i64 %234 to i32*
  %237 = load i32, i32* %236, align 4
  %238 = add i32 %237, %232
  %239 = zext i32 %238 to i64
  store i64 %239, i64* %RCX, align 8, !tbaa !2428
  %240 = icmp ult i32 %238, %232
  %241 = icmp ult i32 %238, %237
  %242 = or i1 %240, %241
  %243 = zext i1 %242 to i8
  store i8 %243, i8* %17, align 1, !tbaa !2433
  %244 = and i32 %238, 255
  %245 = tail call i32 @llvm.ctpop.i32(i32 %244) #10
  %246 = trunc i32 %245 to i8
  %247 = and i8 %246, 1
  %248 = xor i8 %247, 1
  store i8 %248, i8* %24, align 1, !tbaa !2447
  %249 = xor i32 %237, %232
  %250 = xor i32 %249, %238
  %251 = lshr i32 %250, 4
  %252 = trunc i32 %251 to i8
  %253 = and i8 %252, 1
  store i8 %253, i8* %30, align 1, !tbaa !2451
  %254 = icmp eq i32 %238, 0
  %255 = zext i1 %254 to i8
  store i8 %255, i8* %33, align 1, !tbaa !2448
  %256 = lshr i32 %238, 31
  %257 = trunc i32 %256 to i8
  store i8 %257, i8* %36, align 1, !tbaa !2449
  %258 = lshr i32 %232, 31
  %259 = lshr i32 %237, 31
  %260 = xor i32 %256, %258
  %261 = xor i32 %256, %259
  %262 = add nuw nsw i32 %260, %261
  %263 = icmp eq i32 %262, 2
  %264 = zext i1 %263 to i8
  store i8 %264, i8* %42, align 1, !tbaa !2450
  %265 = add i64 %227, -28
  %266 = add i64 %229, 9
  store i64 %266, i64* %PC, align 8
  %267 = inttoptr i64 %265 to i32*
  store i32 %238, i32* %267, align 4
  %.pre6 = load i64, i64* %PC, align 8
  br label %block_403c90

block_40357d:                                     ; preds = %block_403326
  %268 = add i64 %4732, -24
  %269 = add i64 %4768, 4
  store i64 %269, i64* %PC, align 8
  %270 = inttoptr i64 %268 to i64*
  %271 = load i64, i64* %270, align 8
  store i64 %271, i64* %RAX, align 8, !tbaa !2428
  %272 = add i64 %271, 16
  %273 = add i64 %4768, 9
  store i64 %273, i64* %PC, align 8
  %274 = inttoptr i64 %272 to i64*
  %275 = load i64, i64* %274, align 8
  %276 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %5, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %275, i64* %276, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %277 = add i64 %4732, -72
  %278 = add i64 %4768, 14
  store i64 %278, i64* %PC, align 8
  %279 = inttoptr i64 %277 to i64*
  store i64 %275, i64* %279, align 8
  %280 = load i64, i64* %RBP, align 8
  %281 = add i64 %280, -56
  %282 = load i64, i64* %PC, align 8
  %283 = add i64 %282, 3
  store i64 %283, i64* %PC, align 8
  %284 = inttoptr i64 %281 to i32*
  %285 = load i32, i32* %284, align 4
  %286 = zext i32 %285 to i64
  store i64 %286, i64* %RCX, align 8, !tbaa !2428
  %287 = add i64 %280, -28
  %288 = add i64 %282, 6
  store i64 %288, i64* %PC, align 8
  %289 = inttoptr i64 %287 to i32*
  store i32 %285, i32* %289, align 4
  %290 = bitcast %union.VectorReg* %6 to double*
  %291 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %292 = bitcast i64* %291 to double*
  %.pre3 = load i64, i64* %PC, align 8
  br label %block_403591

block_403332:                                     ; preds = %block_403326
  %293 = add i64 %4768, 3
  store i64 %293, i64* %PC, align 8
  %294 = load i32, i32* %4735, align 4
  %295 = zext i32 %294 to i64
  store i64 %295, i64* %RAX, align 8, !tbaa !2428
  %296 = add i64 %4768, 6
  store i64 %296, i64* %PC, align 8
  %297 = load i32, i32* %4740, align 4
  %298 = add i32 %297, %294
  %299 = zext i32 %298 to i64
  store i64 %299, i64* %RAX, align 8, !tbaa !2428
  %300 = icmp ult i32 %298, %294
  %301 = icmp ult i32 %298, %297
  %302 = or i1 %300, %301
  %303 = zext i1 %302 to i8
  store i8 %303, i8* %17, align 1, !tbaa !2433
  %304 = and i32 %298, 255
  %305 = tail call i32 @llvm.ctpop.i32(i32 %304) #10
  %306 = trunc i32 %305 to i8
  %307 = and i8 %306, 1
  %308 = xor i8 %307, 1
  store i8 %308, i8* %24, align 1, !tbaa !2447
  %309 = xor i32 %297, %294
  %310 = xor i32 %309, %298
  %311 = lshr i32 %310, 4
  %312 = trunc i32 %311 to i8
  %313 = and i8 %312, 1
  store i8 %313, i8* %30, align 1, !tbaa !2451
  %314 = icmp eq i32 %298, 0
  %315 = zext i1 %314 to i8
  store i8 %315, i8* %33, align 1, !tbaa !2448
  %316 = lshr i32 %298, 31
  %317 = trunc i32 %316 to i8
  store i8 %317, i8* %36, align 1, !tbaa !2449
  %318 = lshr i32 %294, 31
  %319 = lshr i32 %297, 31
  %320 = xor i32 %316, %318
  %321 = xor i32 %316, %319
  %322 = add nuw nsw i32 %320, %321
  %323 = icmp eq i32 %322, 2
  %324 = zext i1 %323 to i8
  store i8 %324, i8* %42, align 1, !tbaa !2450
  %325 = add i64 %4732, -32
  %326 = add i64 %4768, 9
  store i64 %326, i64* %PC, align 8
  %327 = inttoptr i64 %325 to i32*
  store i32 %298, i32* %327, align 4
  %328 = load i64, i64* %RBP, align 8
  %329 = add i64 %328, -32
  %330 = load i64, i64* %PC, align 8
  %331 = add i64 %330, 3
  store i64 %331, i64* %PC, align 8
  %332 = inttoptr i64 %329 to i32*
  %333 = load i32, i32* %332, align 4
  %334 = zext i32 %333 to i64
  store i64 %334, i64* %RAX, align 8, !tbaa !2428
  %335 = add i64 %328, -8
  %336 = add i64 %330, 6
  store i64 %336, i64* %PC, align 8
  %337 = inttoptr i64 %335 to i32*
  %338 = load i32, i32* %337, align 4
  %339 = add i32 %338, %333
  %340 = zext i32 %339 to i64
  store i64 %340, i64* %RAX, align 8, !tbaa !2428
  %341 = icmp ult i32 %339, %333
  %342 = icmp ult i32 %339, %338
  %343 = or i1 %341, %342
  %344 = zext i1 %343 to i8
  store i8 %344, i8* %17, align 1, !tbaa !2433
  %345 = and i32 %339, 255
  %346 = tail call i32 @llvm.ctpop.i32(i32 %345) #10
  %347 = trunc i32 %346 to i8
  %348 = and i8 %347, 1
  %349 = xor i8 %348, 1
  store i8 %349, i8* %24, align 1, !tbaa !2447
  %350 = xor i32 %338, %333
  %351 = xor i32 %350, %339
  %352 = lshr i32 %351, 4
  %353 = trunc i32 %352 to i8
  %354 = and i8 %353, 1
  store i8 %354, i8* %30, align 1, !tbaa !2451
  %355 = icmp eq i32 %339, 0
  %356 = zext i1 %355 to i8
  store i8 %356, i8* %33, align 1, !tbaa !2448
  %357 = lshr i32 %339, 31
  %358 = trunc i32 %357 to i8
  store i8 %358, i8* %36, align 1, !tbaa !2449
  %359 = lshr i32 %333, 31
  %360 = lshr i32 %338, 31
  %361 = xor i32 %357, %359
  %362 = xor i32 %357, %360
  %363 = add nuw nsw i32 %361, %362
  %364 = icmp eq i32 %363, 2
  %365 = zext i1 %364 to i8
  store i8 %365, i8* %42, align 1, !tbaa !2450
  %366 = add i64 %328, -36
  %367 = add i64 %330, 9
  store i64 %367, i64* %PC, align 8
  %368 = inttoptr i64 %366 to i32*
  store i32 %339, i32* %368, align 4
  %369 = load i64, i64* %RBP, align 8
  %370 = add i64 %369, -36
  %371 = load i64, i64* %PC, align 8
  %372 = add i64 %371, 3
  store i64 %372, i64* %PC, align 8
  %373 = inttoptr i64 %370 to i32*
  %374 = load i32, i32* %373, align 4
  %375 = zext i32 %374 to i64
  store i64 %375, i64* %RAX, align 8, !tbaa !2428
  %376 = add i64 %369, -8
  %377 = add i64 %371, 6
  store i64 %377, i64* %PC, align 8
  %378 = inttoptr i64 %376 to i32*
  %379 = load i32, i32* %378, align 4
  %380 = add i32 %379, %374
  %381 = zext i32 %380 to i64
  store i64 %381, i64* %RAX, align 8, !tbaa !2428
  %382 = icmp ult i32 %380, %374
  %383 = icmp ult i32 %380, %379
  %384 = or i1 %382, %383
  %385 = zext i1 %384 to i8
  store i8 %385, i8* %17, align 1, !tbaa !2433
  %386 = and i32 %380, 255
  %387 = tail call i32 @llvm.ctpop.i32(i32 %386) #10
  %388 = trunc i32 %387 to i8
  %389 = and i8 %388, 1
  %390 = xor i8 %389, 1
  store i8 %390, i8* %24, align 1, !tbaa !2447
  %391 = xor i32 %379, %374
  %392 = xor i32 %391, %380
  %393 = lshr i32 %392, 4
  %394 = trunc i32 %393 to i8
  %395 = and i8 %394, 1
  store i8 %395, i8* %30, align 1, !tbaa !2451
  %396 = icmp eq i32 %380, 0
  %397 = zext i1 %396 to i8
  store i8 %397, i8* %33, align 1, !tbaa !2448
  %398 = lshr i32 %380, 31
  %399 = trunc i32 %398 to i8
  store i8 %399, i8* %36, align 1, !tbaa !2449
  %400 = lshr i32 %374, 31
  %401 = lshr i32 %379, 31
  %402 = xor i32 %398, %400
  %403 = xor i32 %398, %401
  %404 = add nuw nsw i32 %402, %403
  %405 = icmp eq i32 %404, 2
  %406 = zext i1 %405 to i8
  store i8 %406, i8* %42, align 1, !tbaa !2450
  %407 = add i64 %369, -40
  %408 = add i64 %371, 9
  store i64 %408, i64* %PC, align 8
  %409 = inttoptr i64 %407 to i32*
  store i32 %380, i32* %409, align 4
  %410 = load i64, i64* %RBP, align 8
  %411 = add i64 %410, -16
  %412 = load i64, i64* %PC, align 8
  %413 = add i64 %412, 4
  store i64 %413, i64* %PC, align 8
  %414 = inttoptr i64 %411 to i64*
  %415 = load i64, i64* %414, align 8
  store i64 %415, i64* %RCX, align 8, !tbaa !2428
  %416 = add i64 %410, -28
  %417 = add i64 %412, 8
  store i64 %417, i64* %PC, align 8
  %418 = inttoptr i64 %416 to i32*
  %419 = load i32, i32* %418, align 4
  %420 = sext i32 %419 to i64
  store i64 %420, i64* %RDX, align 8, !tbaa !2428
  %421 = shl nsw i64 %420, 3
  %422 = add i64 %421, %415
  %423 = add i64 %412, 13
  store i64 %423, i64* %PC, align 8
  %424 = inttoptr i64 %422 to double*
  %425 = load double, double* %424, align 8
  store double %425, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %426 = add i64 %412, 17
  store i64 %426, i64* %PC, align 8
  %427 = load i64, i64* %414, align 8
  store i64 %427, i64* %RCX, align 8, !tbaa !2428
  %428 = add i64 %410, -32
  %429 = add i64 %412, 21
  store i64 %429, i64* %PC, align 8
  %430 = inttoptr i64 %428 to i32*
  %431 = load i32, i32* %430, align 4
  %432 = sext i32 %431 to i64
  store i64 %432, i64* %RDX, align 8, !tbaa !2428
  %433 = shl nsw i64 %432, 3
  %434 = add i64 %433, %427
  %435 = add i64 %412, 26
  store i64 %435, i64* %PC, align 8
  %436 = inttoptr i64 %434 to double*
  %437 = load double, double* %436, align 8
  %438 = fadd double %425, %437
  store double %438, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %439 = add i64 %410, -120
  %440 = add i64 %412, 31
  store i64 %440, i64* %PC, align 8
  %441 = inttoptr i64 %439 to double*
  store double %438, double* %441, align 8
  %442 = load i64, i64* %RBP, align 8
  %443 = add i64 %442, -16
  %444 = load i64, i64* %PC, align 8
  %445 = add i64 %444, 4
  store i64 %445, i64* %PC, align 8
  %446 = inttoptr i64 %443 to i64*
  %447 = load i64, i64* %446, align 8
  store i64 %447, i64* %RCX, align 8, !tbaa !2428
  %448 = add i64 %442, -28
  %449 = add i64 %444, 7
  store i64 %449, i64* %PC, align 8
  %450 = inttoptr i64 %448 to i32*
  %451 = load i32, i32* %450, align 4
  %452 = add i32 %451, 1
  %453 = zext i32 %452 to i64
  store i64 %453, i64* %RAX, align 8, !tbaa !2428
  %454 = icmp eq i32 %451, -1
  %455 = icmp eq i32 %452, 0
  %456 = or i1 %454, %455
  %457 = zext i1 %456 to i8
  store i8 %457, i8* %17, align 1, !tbaa !2433
  %458 = and i32 %452, 255
  %459 = tail call i32 @llvm.ctpop.i32(i32 %458) #10
  %460 = trunc i32 %459 to i8
  %461 = and i8 %460, 1
  %462 = xor i8 %461, 1
  store i8 %462, i8* %24, align 1, !tbaa !2447
  %463 = xor i32 %451, %452
  %464 = lshr i32 %463, 4
  %465 = trunc i32 %464 to i8
  %466 = and i8 %465, 1
  store i8 %466, i8* %30, align 1, !tbaa !2451
  %467 = zext i1 %455 to i8
  store i8 %467, i8* %33, align 1, !tbaa !2448
  %468 = lshr i32 %452, 31
  %469 = trunc i32 %468 to i8
  store i8 %469, i8* %36, align 1, !tbaa !2449
  %470 = lshr i32 %451, 31
  %471 = xor i32 %468, %470
  %472 = add nuw nsw i32 %471, %468
  %473 = icmp eq i32 %472, 2
  %474 = zext i1 %473 to i8
  store i8 %474, i8* %42, align 1, !tbaa !2450
  %475 = sext i32 %452 to i64
  store i64 %475, i64* %RDX, align 8, !tbaa !2428
  %476 = shl nsw i64 %475, 3
  %477 = add i64 %476, %447
  %478 = add i64 %444, 18
  store i64 %478, i64* %PC, align 8
  %479 = inttoptr i64 %477 to double*
  %480 = load double, double* %479, align 8
  store double %480, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %481 = add i64 %444, 22
  store i64 %481, i64* %PC, align 8
  %482 = load i64, i64* %446, align 8
  store i64 %482, i64* %RCX, align 8, !tbaa !2428
  %483 = add i64 %442, -32
  %484 = add i64 %444, 25
  store i64 %484, i64* %PC, align 8
  %485 = inttoptr i64 %483 to i32*
  %486 = load i32, i32* %485, align 4
  %487 = add i32 %486, 1
  %488 = zext i32 %487 to i64
  store i64 %488, i64* %RAX, align 8, !tbaa !2428
  %489 = icmp eq i32 %486, -1
  %490 = icmp eq i32 %487, 0
  %491 = or i1 %489, %490
  %492 = zext i1 %491 to i8
  store i8 %492, i8* %17, align 1, !tbaa !2433
  %493 = and i32 %487, 255
  %494 = tail call i32 @llvm.ctpop.i32(i32 %493) #10
  %495 = trunc i32 %494 to i8
  %496 = and i8 %495, 1
  %497 = xor i8 %496, 1
  store i8 %497, i8* %24, align 1, !tbaa !2447
  %498 = xor i32 %486, %487
  %499 = lshr i32 %498, 4
  %500 = trunc i32 %499 to i8
  %501 = and i8 %500, 1
  store i8 %501, i8* %30, align 1, !tbaa !2451
  %502 = zext i1 %490 to i8
  store i8 %502, i8* %33, align 1, !tbaa !2448
  %503 = lshr i32 %487, 31
  %504 = trunc i32 %503 to i8
  store i8 %504, i8* %36, align 1, !tbaa !2449
  %505 = lshr i32 %486, 31
  %506 = xor i32 %503, %505
  %507 = add nuw nsw i32 %506, %503
  %508 = icmp eq i32 %507, 2
  %509 = zext i1 %508 to i8
  store i8 %509, i8* %42, align 1, !tbaa !2450
  %510 = sext i32 %487 to i64
  store i64 %510, i64* %RDX, align 8, !tbaa !2428
  %511 = shl nsw i64 %510, 3
  %512 = add i64 %511, %482
  %513 = add i64 %444, 36
  store i64 %513, i64* %PC, align 8
  %514 = inttoptr i64 %512 to double*
  %515 = load double, double* %514, align 8
  %516 = fadd double %480, %515
  store double %516, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %517 = load i64, i64* %RBP, align 8
  %518 = add i64 %517, -128
  %519 = add i64 %444, 41
  store i64 %519, i64* %PC, align 8
  %520 = inttoptr i64 %518 to double*
  store double %516, double* %520, align 8
  %521 = load i64, i64* %RBP, align 8
  %522 = add i64 %521, -16
  %523 = load i64, i64* %PC, align 8
  %524 = add i64 %523, 4
  store i64 %524, i64* %PC, align 8
  %525 = inttoptr i64 %522 to i64*
  %526 = load i64, i64* %525, align 8
  store i64 %526, i64* %RCX, align 8, !tbaa !2428
  %527 = add i64 %521, -28
  %528 = add i64 %523, 8
  store i64 %528, i64* %PC, align 8
  %529 = inttoptr i64 %527 to i32*
  %530 = load i32, i32* %529, align 4
  %531 = sext i32 %530 to i64
  store i64 %531, i64* %RDX, align 8, !tbaa !2428
  %532 = shl nsw i64 %531, 3
  %533 = add i64 %532, %526
  %534 = add i64 %523, 13
  store i64 %534, i64* %PC, align 8
  %535 = inttoptr i64 %533 to double*
  %536 = load double, double* %535, align 8
  store double %536, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %537 = add i64 %523, 17
  store i64 %537, i64* %PC, align 8
  %538 = load i64, i64* %525, align 8
  store i64 %538, i64* %RCX, align 8, !tbaa !2428
  %539 = add i64 %521, -32
  %540 = add i64 %523, 21
  store i64 %540, i64* %PC, align 8
  %541 = inttoptr i64 %539 to i32*
  %542 = load i32, i32* %541, align 4
  %543 = sext i32 %542 to i64
  store i64 %543, i64* %RDX, align 8, !tbaa !2428
  %544 = shl nsw i64 %543, 3
  %545 = add i64 %544, %538
  %546 = add i64 %523, 26
  store i64 %546, i64* %PC, align 8
  %547 = inttoptr i64 %545 to double*
  %548 = load double, double* %547, align 8
  %549 = fsub double %536, %548
  store double %549, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %550 = add i64 %521, -136
  %551 = add i64 %523, 34
  store i64 %551, i64* %PC, align 8
  %552 = inttoptr i64 %550 to double*
  store double %549, double* %552, align 8
  %553 = load i64, i64* %RBP, align 8
  %554 = add i64 %553, -16
  %555 = load i64, i64* %PC, align 8
  %556 = add i64 %555, 4
  store i64 %556, i64* %PC, align 8
  %557 = inttoptr i64 %554 to i64*
  %558 = load i64, i64* %557, align 8
  store i64 %558, i64* %RCX, align 8, !tbaa !2428
  %559 = add i64 %553, -28
  %560 = add i64 %555, 7
  store i64 %560, i64* %PC, align 8
  %561 = inttoptr i64 %559 to i32*
  %562 = load i32, i32* %561, align 4
  %563 = add i32 %562, 1
  %564 = zext i32 %563 to i64
  store i64 %564, i64* %RAX, align 8, !tbaa !2428
  %565 = icmp eq i32 %562, -1
  %566 = icmp eq i32 %563, 0
  %567 = or i1 %565, %566
  %568 = zext i1 %567 to i8
  store i8 %568, i8* %17, align 1, !tbaa !2433
  %569 = and i32 %563, 255
  %570 = tail call i32 @llvm.ctpop.i32(i32 %569) #10
  %571 = trunc i32 %570 to i8
  %572 = and i8 %571, 1
  %573 = xor i8 %572, 1
  store i8 %573, i8* %24, align 1, !tbaa !2447
  %574 = xor i32 %562, %563
  %575 = lshr i32 %574, 4
  %576 = trunc i32 %575 to i8
  %577 = and i8 %576, 1
  store i8 %577, i8* %30, align 1, !tbaa !2451
  %578 = zext i1 %566 to i8
  store i8 %578, i8* %33, align 1, !tbaa !2448
  %579 = lshr i32 %563, 31
  %580 = trunc i32 %579 to i8
  store i8 %580, i8* %36, align 1, !tbaa !2449
  %581 = lshr i32 %562, 31
  %582 = xor i32 %579, %581
  %583 = add nuw nsw i32 %582, %579
  %584 = icmp eq i32 %583, 2
  %585 = zext i1 %584 to i8
  store i8 %585, i8* %42, align 1, !tbaa !2450
  %586 = sext i32 %563 to i64
  store i64 %586, i64* %RDX, align 8, !tbaa !2428
  %587 = shl nsw i64 %586, 3
  %588 = add i64 %587, %558
  %589 = add i64 %555, 18
  store i64 %589, i64* %PC, align 8
  %590 = inttoptr i64 %588 to double*
  %591 = load double, double* %590, align 8
  store double %591, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %592 = add i64 %555, 22
  store i64 %592, i64* %PC, align 8
  %593 = load i64, i64* %557, align 8
  store i64 %593, i64* %RCX, align 8, !tbaa !2428
  %594 = add i64 %553, -32
  %595 = add i64 %555, 25
  store i64 %595, i64* %PC, align 8
  %596 = inttoptr i64 %594 to i32*
  %597 = load i32, i32* %596, align 4
  %598 = add i32 %597, 1
  %599 = zext i32 %598 to i64
  store i64 %599, i64* %RAX, align 8, !tbaa !2428
  %600 = icmp eq i32 %597, -1
  %601 = icmp eq i32 %598, 0
  %602 = or i1 %600, %601
  %603 = zext i1 %602 to i8
  store i8 %603, i8* %17, align 1, !tbaa !2433
  %604 = and i32 %598, 255
  %605 = tail call i32 @llvm.ctpop.i32(i32 %604) #10
  %606 = trunc i32 %605 to i8
  %607 = and i8 %606, 1
  %608 = xor i8 %607, 1
  store i8 %608, i8* %24, align 1, !tbaa !2447
  %609 = xor i32 %597, %598
  %610 = lshr i32 %609, 4
  %611 = trunc i32 %610 to i8
  %612 = and i8 %611, 1
  store i8 %612, i8* %30, align 1, !tbaa !2451
  %613 = zext i1 %601 to i8
  store i8 %613, i8* %33, align 1, !tbaa !2448
  %614 = lshr i32 %598, 31
  %615 = trunc i32 %614 to i8
  store i8 %615, i8* %36, align 1, !tbaa !2449
  %616 = lshr i32 %597, 31
  %617 = xor i32 %614, %616
  %618 = add nuw nsw i32 %617, %614
  %619 = icmp eq i32 %618, 2
  %620 = zext i1 %619 to i8
  store i8 %620, i8* %42, align 1, !tbaa !2450
  %621 = sext i32 %598 to i64
  store i64 %621, i64* %RDX, align 8, !tbaa !2428
  %622 = shl nsw i64 %621, 3
  %623 = add i64 %622, %593
  %624 = add i64 %555, 36
  store i64 %624, i64* %PC, align 8
  %625 = inttoptr i64 %623 to double*
  %626 = load double, double* %625, align 8
  %627 = fsub double %591, %626
  store double %627, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %628 = load i64, i64* %RBP, align 8
  %629 = add i64 %628, -144
  %630 = add i64 %555, 44
  store i64 %630, i64* %PC, align 8
  %631 = inttoptr i64 %629 to double*
  store double %627, double* %631, align 8
  %632 = load i64, i64* %RBP, align 8
  %633 = add i64 %632, -16
  %634 = load i64, i64* %PC, align 8
  %635 = add i64 %634, 4
  store i64 %635, i64* %PC, align 8
  %636 = inttoptr i64 %633 to i64*
  %637 = load i64, i64* %636, align 8
  store i64 %637, i64* %RCX, align 8, !tbaa !2428
  %638 = add i64 %632, -36
  %639 = add i64 %634, 8
  store i64 %639, i64* %PC, align 8
  %640 = inttoptr i64 %638 to i32*
  %641 = load i32, i32* %640, align 4
  %642 = sext i32 %641 to i64
  store i64 %642, i64* %RDX, align 8, !tbaa !2428
  %643 = shl nsw i64 %642, 3
  %644 = add i64 %643, %637
  %645 = add i64 %634, 13
  store i64 %645, i64* %PC, align 8
  %646 = inttoptr i64 %644 to double*
  %647 = load double, double* %646, align 8
  store double %647, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %648 = add i64 %634, 17
  store i64 %648, i64* %PC, align 8
  %649 = load i64, i64* %636, align 8
  store i64 %649, i64* %RCX, align 8, !tbaa !2428
  %650 = add i64 %632, -40
  %651 = add i64 %634, 21
  store i64 %651, i64* %PC, align 8
  %652 = inttoptr i64 %650 to i32*
  %653 = load i32, i32* %652, align 4
  %654 = sext i32 %653 to i64
  store i64 %654, i64* %RDX, align 8, !tbaa !2428
  %655 = shl nsw i64 %654, 3
  %656 = add i64 %655, %649
  %657 = add i64 %634, 26
  store i64 %657, i64* %PC, align 8
  %658 = inttoptr i64 %656 to double*
  %659 = load double, double* %658, align 8
  %660 = fadd double %647, %659
  store double %660, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %661 = add i64 %632, -152
  %662 = add i64 %634, 34
  store i64 %662, i64* %PC, align 8
  %663 = inttoptr i64 %661 to double*
  store double %660, double* %663, align 8
  %664 = load i64, i64* %RBP, align 8
  %665 = add i64 %664, -16
  %666 = load i64, i64* %PC, align 8
  %667 = add i64 %666, 4
  store i64 %667, i64* %PC, align 8
  %668 = inttoptr i64 %665 to i64*
  %669 = load i64, i64* %668, align 8
  store i64 %669, i64* %RCX, align 8, !tbaa !2428
  %670 = add i64 %664, -36
  %671 = add i64 %666, 7
  store i64 %671, i64* %PC, align 8
  %672 = inttoptr i64 %670 to i32*
  %673 = load i32, i32* %672, align 4
  %674 = add i32 %673, 1
  %675 = zext i32 %674 to i64
  store i64 %675, i64* %RAX, align 8, !tbaa !2428
  %676 = icmp eq i32 %673, -1
  %677 = icmp eq i32 %674, 0
  %678 = or i1 %676, %677
  %679 = zext i1 %678 to i8
  store i8 %679, i8* %17, align 1, !tbaa !2433
  %680 = and i32 %674, 255
  %681 = tail call i32 @llvm.ctpop.i32(i32 %680) #10
  %682 = trunc i32 %681 to i8
  %683 = and i8 %682, 1
  %684 = xor i8 %683, 1
  store i8 %684, i8* %24, align 1, !tbaa !2447
  %685 = xor i32 %673, %674
  %686 = lshr i32 %685, 4
  %687 = trunc i32 %686 to i8
  %688 = and i8 %687, 1
  store i8 %688, i8* %30, align 1, !tbaa !2451
  %689 = zext i1 %677 to i8
  store i8 %689, i8* %33, align 1, !tbaa !2448
  %690 = lshr i32 %674, 31
  %691 = trunc i32 %690 to i8
  store i8 %691, i8* %36, align 1, !tbaa !2449
  %692 = lshr i32 %673, 31
  %693 = xor i32 %690, %692
  %694 = add nuw nsw i32 %693, %690
  %695 = icmp eq i32 %694, 2
  %696 = zext i1 %695 to i8
  store i8 %696, i8* %42, align 1, !tbaa !2450
  %697 = sext i32 %674 to i64
  store i64 %697, i64* %RDX, align 8, !tbaa !2428
  %698 = shl nsw i64 %697, 3
  %699 = add i64 %698, %669
  %700 = add i64 %666, 18
  store i64 %700, i64* %PC, align 8
  %701 = inttoptr i64 %699 to double*
  %702 = load double, double* %701, align 8
  store double %702, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %703 = add i64 %666, 22
  store i64 %703, i64* %PC, align 8
  %704 = load i64, i64* %668, align 8
  store i64 %704, i64* %RCX, align 8, !tbaa !2428
  %705 = add i64 %664, -40
  %706 = add i64 %666, 25
  store i64 %706, i64* %PC, align 8
  %707 = inttoptr i64 %705 to i32*
  %708 = load i32, i32* %707, align 4
  %709 = add i32 %708, 1
  %710 = zext i32 %709 to i64
  store i64 %710, i64* %RAX, align 8, !tbaa !2428
  %711 = icmp eq i32 %708, -1
  %712 = icmp eq i32 %709, 0
  %713 = or i1 %711, %712
  %714 = zext i1 %713 to i8
  store i8 %714, i8* %17, align 1, !tbaa !2433
  %715 = and i32 %709, 255
  %716 = tail call i32 @llvm.ctpop.i32(i32 %715) #10
  %717 = trunc i32 %716 to i8
  %718 = and i8 %717, 1
  %719 = xor i8 %718, 1
  store i8 %719, i8* %24, align 1, !tbaa !2447
  %720 = xor i32 %708, %709
  %721 = lshr i32 %720, 4
  %722 = trunc i32 %721 to i8
  %723 = and i8 %722, 1
  store i8 %723, i8* %30, align 1, !tbaa !2451
  %724 = zext i1 %712 to i8
  store i8 %724, i8* %33, align 1, !tbaa !2448
  %725 = lshr i32 %709, 31
  %726 = trunc i32 %725 to i8
  store i8 %726, i8* %36, align 1, !tbaa !2449
  %727 = lshr i32 %708, 31
  %728 = xor i32 %725, %727
  %729 = add nuw nsw i32 %728, %725
  %730 = icmp eq i32 %729, 2
  %731 = zext i1 %730 to i8
  store i8 %731, i8* %42, align 1, !tbaa !2450
  %732 = sext i32 %709 to i64
  store i64 %732, i64* %RDX, align 8, !tbaa !2428
  %733 = shl nsw i64 %732, 3
  %734 = add i64 %733, %704
  %735 = add i64 %666, 36
  store i64 %735, i64* %PC, align 8
  %736 = inttoptr i64 %734 to double*
  %737 = load double, double* %736, align 8
  %738 = fadd double %702, %737
  store double %738, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %739 = load i64, i64* %RBP, align 8
  %740 = add i64 %739, -160
  %741 = add i64 %666, 44
  store i64 %741, i64* %PC, align 8
  %742 = inttoptr i64 %740 to double*
  store double %738, double* %742, align 8
  %743 = load i64, i64* %RBP, align 8
  %744 = add i64 %743, -16
  %745 = load i64, i64* %PC, align 8
  %746 = add i64 %745, 4
  store i64 %746, i64* %PC, align 8
  %747 = inttoptr i64 %744 to i64*
  %748 = load i64, i64* %747, align 8
  store i64 %748, i64* %RCX, align 8, !tbaa !2428
  %749 = add i64 %743, -36
  %750 = add i64 %745, 8
  store i64 %750, i64* %PC, align 8
  %751 = inttoptr i64 %749 to i32*
  %752 = load i32, i32* %751, align 4
  %753 = sext i32 %752 to i64
  store i64 %753, i64* %RDX, align 8, !tbaa !2428
  %754 = shl nsw i64 %753, 3
  %755 = add i64 %754, %748
  %756 = add i64 %745, 13
  store i64 %756, i64* %PC, align 8
  %757 = inttoptr i64 %755 to double*
  %758 = load double, double* %757, align 8
  store double %758, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %759 = add i64 %745, 17
  store i64 %759, i64* %PC, align 8
  %760 = load i64, i64* %747, align 8
  store i64 %760, i64* %RCX, align 8, !tbaa !2428
  %761 = add i64 %743, -40
  %762 = add i64 %745, 21
  store i64 %762, i64* %PC, align 8
  %763 = inttoptr i64 %761 to i32*
  %764 = load i32, i32* %763, align 4
  %765 = sext i32 %764 to i64
  store i64 %765, i64* %RDX, align 8, !tbaa !2428
  %766 = shl nsw i64 %765, 3
  %767 = add i64 %766, %760
  %768 = add i64 %745, 26
  store i64 %768, i64* %PC, align 8
  %769 = inttoptr i64 %767 to double*
  %770 = load double, double* %769, align 8
  %771 = fsub double %758, %770
  store double %771, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %772 = add i64 %743, -168
  %773 = add i64 %745, 34
  store i64 %773, i64* %PC, align 8
  %774 = inttoptr i64 %772 to double*
  store double %771, double* %774, align 8
  %775 = load i64, i64* %RBP, align 8
  %776 = add i64 %775, -16
  %777 = load i64, i64* %PC, align 8
  %778 = add i64 %777, 4
  store i64 %778, i64* %PC, align 8
  %779 = inttoptr i64 %776 to i64*
  %780 = load i64, i64* %779, align 8
  store i64 %780, i64* %RCX, align 8, !tbaa !2428
  %781 = add i64 %775, -36
  %782 = add i64 %777, 7
  store i64 %782, i64* %PC, align 8
  %783 = inttoptr i64 %781 to i32*
  %784 = load i32, i32* %783, align 4
  %785 = add i32 %784, 1
  %786 = zext i32 %785 to i64
  store i64 %786, i64* %RAX, align 8, !tbaa !2428
  %787 = icmp eq i32 %784, -1
  %788 = icmp eq i32 %785, 0
  %789 = or i1 %787, %788
  %790 = zext i1 %789 to i8
  store i8 %790, i8* %17, align 1, !tbaa !2433
  %791 = and i32 %785, 255
  %792 = tail call i32 @llvm.ctpop.i32(i32 %791) #10
  %793 = trunc i32 %792 to i8
  %794 = and i8 %793, 1
  %795 = xor i8 %794, 1
  store i8 %795, i8* %24, align 1, !tbaa !2447
  %796 = xor i32 %784, %785
  %797 = lshr i32 %796, 4
  %798 = trunc i32 %797 to i8
  %799 = and i8 %798, 1
  store i8 %799, i8* %30, align 1, !tbaa !2451
  %800 = zext i1 %788 to i8
  store i8 %800, i8* %33, align 1, !tbaa !2448
  %801 = lshr i32 %785, 31
  %802 = trunc i32 %801 to i8
  store i8 %802, i8* %36, align 1, !tbaa !2449
  %803 = lshr i32 %784, 31
  %804 = xor i32 %801, %803
  %805 = add nuw nsw i32 %804, %801
  %806 = icmp eq i32 %805, 2
  %807 = zext i1 %806 to i8
  store i8 %807, i8* %42, align 1, !tbaa !2450
  %808 = sext i32 %785 to i64
  store i64 %808, i64* %RDX, align 8, !tbaa !2428
  %809 = shl nsw i64 %808, 3
  %810 = add i64 %809, %780
  %811 = add i64 %777, 18
  store i64 %811, i64* %PC, align 8
  %812 = inttoptr i64 %810 to double*
  %813 = load double, double* %812, align 8
  store double %813, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %814 = add i64 %777, 22
  store i64 %814, i64* %PC, align 8
  %815 = load i64, i64* %779, align 8
  store i64 %815, i64* %RCX, align 8, !tbaa !2428
  %816 = add i64 %775, -40
  %817 = add i64 %777, 25
  store i64 %817, i64* %PC, align 8
  %818 = inttoptr i64 %816 to i32*
  %819 = load i32, i32* %818, align 4
  %820 = add i32 %819, 1
  %821 = zext i32 %820 to i64
  store i64 %821, i64* %RAX, align 8, !tbaa !2428
  %822 = icmp eq i32 %819, -1
  %823 = icmp eq i32 %820, 0
  %824 = or i1 %822, %823
  %825 = zext i1 %824 to i8
  store i8 %825, i8* %17, align 1, !tbaa !2433
  %826 = and i32 %820, 255
  %827 = tail call i32 @llvm.ctpop.i32(i32 %826) #10
  %828 = trunc i32 %827 to i8
  %829 = and i8 %828, 1
  %830 = xor i8 %829, 1
  store i8 %830, i8* %24, align 1, !tbaa !2447
  %831 = xor i32 %819, %820
  %832 = lshr i32 %831, 4
  %833 = trunc i32 %832 to i8
  %834 = and i8 %833, 1
  store i8 %834, i8* %30, align 1, !tbaa !2451
  %835 = zext i1 %823 to i8
  store i8 %835, i8* %33, align 1, !tbaa !2448
  %836 = lshr i32 %820, 31
  %837 = trunc i32 %836 to i8
  store i8 %837, i8* %36, align 1, !tbaa !2449
  %838 = lshr i32 %819, 31
  %839 = xor i32 %836, %838
  %840 = add nuw nsw i32 %839, %836
  %841 = icmp eq i32 %840, 2
  %842 = zext i1 %841 to i8
  store i8 %842, i8* %42, align 1, !tbaa !2450
  %843 = sext i32 %820 to i64
  store i64 %843, i64* %RDX, align 8, !tbaa !2428
  %844 = shl nsw i64 %843, 3
  %845 = add i64 %844, %815
  %846 = add i64 %777, 36
  store i64 %846, i64* %PC, align 8
  %847 = inttoptr i64 %845 to double*
  %848 = load double, double* %847, align 8
  %849 = fsub double %813, %848
  store double %849, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %850 = load i64, i64* %RBP, align 8
  %851 = add i64 %850, -176
  %852 = add i64 %777, 44
  store i64 %852, i64* %PC, align 8
  %853 = inttoptr i64 %851 to double*
  store double %849, double* %853, align 8
  %854 = load i64, i64* %RBP, align 8
  %855 = add i64 %854, -120
  %856 = load i64, i64* %PC, align 8
  %857 = add i64 %856, 5
  store i64 %857, i64* %PC, align 8
  %858 = inttoptr i64 %855 to double*
  %859 = load double, double* %858, align 8
  store double %859, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %860 = add i64 %854, -152
  %861 = add i64 %856, 13
  store i64 %861, i64* %PC, align 8
  %862 = inttoptr i64 %860 to double*
  %863 = load double, double* %862, align 8
  %864 = fadd double %859, %863
  store double %864, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %865 = add i64 %854, -16
  %866 = add i64 %856, 17
  store i64 %866, i64* %PC, align 8
  %867 = inttoptr i64 %865 to i64*
  %868 = load i64, i64* %867, align 8
  store i64 %868, i64* %RCX, align 8, !tbaa !2428
  %869 = add i64 %854, -28
  %870 = add i64 %856, 21
  store i64 %870, i64* %PC, align 8
  %871 = inttoptr i64 %869 to i32*
  %872 = load i32, i32* %871, align 4
  %873 = sext i32 %872 to i64
  store i64 %873, i64* %RDX, align 8, !tbaa !2428
  %874 = shl nsw i64 %873, 3
  %875 = add i64 %874, %868
  %876 = add i64 %856, 26
  store i64 %876, i64* %PC, align 8
  %877 = inttoptr i64 %875 to double*
  store double %864, double* %877, align 8
  %878 = load i64, i64* %RBP, align 8
  %879 = add i64 %878, -128
  %880 = load i64, i64* %PC, align 8
  %881 = add i64 %880, 5
  store i64 %881, i64* %PC, align 8
  %882 = inttoptr i64 %879 to double*
  %883 = load double, double* %882, align 8
  store double %883, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %884 = add i64 %878, -160
  %885 = add i64 %880, 13
  store i64 %885, i64* %PC, align 8
  %886 = inttoptr i64 %884 to double*
  %887 = load double, double* %886, align 8
  %888 = fadd double %883, %887
  store double %888, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %889 = add i64 %878, -16
  %890 = add i64 %880, 17
  store i64 %890, i64* %PC, align 8
  %891 = inttoptr i64 %889 to i64*
  %892 = load i64, i64* %891, align 8
  store i64 %892, i64* %RCX, align 8, !tbaa !2428
  %893 = add i64 %878, -28
  %894 = add i64 %880, 20
  store i64 %894, i64* %PC, align 8
  %895 = inttoptr i64 %893 to i32*
  %896 = load i32, i32* %895, align 4
  %897 = add i32 %896, 1
  %898 = zext i32 %897 to i64
  store i64 %898, i64* %RAX, align 8, !tbaa !2428
  %899 = icmp eq i32 %896, -1
  %900 = icmp eq i32 %897, 0
  %901 = or i1 %899, %900
  %902 = zext i1 %901 to i8
  store i8 %902, i8* %17, align 1, !tbaa !2433
  %903 = and i32 %897, 255
  %904 = tail call i32 @llvm.ctpop.i32(i32 %903) #10
  %905 = trunc i32 %904 to i8
  %906 = and i8 %905, 1
  %907 = xor i8 %906, 1
  store i8 %907, i8* %24, align 1, !tbaa !2447
  %908 = xor i32 %896, %897
  %909 = lshr i32 %908, 4
  %910 = trunc i32 %909 to i8
  %911 = and i8 %910, 1
  store i8 %911, i8* %30, align 1, !tbaa !2451
  %912 = zext i1 %900 to i8
  store i8 %912, i8* %33, align 1, !tbaa !2448
  %913 = lshr i32 %897, 31
  %914 = trunc i32 %913 to i8
  store i8 %914, i8* %36, align 1, !tbaa !2449
  %915 = lshr i32 %896, 31
  %916 = xor i32 %913, %915
  %917 = add nuw nsw i32 %916, %913
  %918 = icmp eq i32 %917, 2
  %919 = zext i1 %918 to i8
  store i8 %919, i8* %42, align 1, !tbaa !2450
  %920 = sext i32 %897 to i64
  store i64 %920, i64* %RDX, align 8, !tbaa !2428
  %921 = shl nsw i64 %920, 3
  %922 = add i64 %921, %892
  %923 = add i64 %880, 31
  store i64 %923, i64* %PC, align 8
  %924 = inttoptr i64 %922 to double*
  store double %888, double* %924, align 8
  %925 = load i64, i64* %RBP, align 8
  %926 = add i64 %925, -120
  %927 = load i64, i64* %PC, align 8
  %928 = add i64 %927, 5
  store i64 %928, i64* %PC, align 8
  %929 = inttoptr i64 %926 to double*
  %930 = load double, double* %929, align 8
  store double %930, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %931 = add i64 %925, -152
  %932 = add i64 %927, 13
  store i64 %932, i64* %PC, align 8
  %933 = inttoptr i64 %931 to double*
  %934 = load double, double* %933, align 8
  %935 = fsub double %930, %934
  store double %935, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %936 = add i64 %925, -16
  %937 = add i64 %927, 17
  store i64 %937, i64* %PC, align 8
  %938 = inttoptr i64 %936 to i64*
  %939 = load i64, i64* %938, align 8
  store i64 %939, i64* %RCX, align 8, !tbaa !2428
  %940 = add i64 %925, -36
  %941 = add i64 %927, 21
  store i64 %941, i64* %PC, align 8
  %942 = inttoptr i64 %940 to i32*
  %943 = load i32, i32* %942, align 4
  %944 = sext i32 %943 to i64
  store i64 %944, i64* %RDX, align 8, !tbaa !2428
  %945 = shl nsw i64 %944, 3
  %946 = add i64 %945, %939
  %947 = add i64 %927, 26
  store i64 %947, i64* %PC, align 8
  %948 = inttoptr i64 %946 to double*
  store double %935, double* %948, align 8
  %949 = load i64, i64* %RBP, align 8
  %950 = add i64 %949, -128
  %951 = load i64, i64* %PC, align 8
  %952 = add i64 %951, 5
  store i64 %952, i64* %PC, align 8
  %953 = inttoptr i64 %950 to double*
  %954 = load double, double* %953, align 8
  store double %954, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %955 = add i64 %949, -160
  %956 = add i64 %951, 13
  store i64 %956, i64* %PC, align 8
  %957 = inttoptr i64 %955 to double*
  %958 = load double, double* %957, align 8
  %959 = fsub double %954, %958
  store double %959, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %960 = add i64 %949, -16
  %961 = add i64 %951, 17
  store i64 %961, i64* %PC, align 8
  %962 = inttoptr i64 %960 to i64*
  %963 = load i64, i64* %962, align 8
  store i64 %963, i64* %RCX, align 8, !tbaa !2428
  %964 = add i64 %949, -36
  %965 = add i64 %951, 20
  store i64 %965, i64* %PC, align 8
  %966 = inttoptr i64 %964 to i32*
  %967 = load i32, i32* %966, align 4
  %968 = add i32 %967, 1
  %969 = zext i32 %968 to i64
  store i64 %969, i64* %RAX, align 8, !tbaa !2428
  %970 = icmp eq i32 %967, -1
  %971 = icmp eq i32 %968, 0
  %972 = or i1 %970, %971
  %973 = zext i1 %972 to i8
  store i8 %973, i8* %17, align 1, !tbaa !2433
  %974 = and i32 %968, 255
  %975 = tail call i32 @llvm.ctpop.i32(i32 %974) #10
  %976 = trunc i32 %975 to i8
  %977 = and i8 %976, 1
  %978 = xor i8 %977, 1
  store i8 %978, i8* %24, align 1, !tbaa !2447
  %979 = xor i32 %967, %968
  %980 = lshr i32 %979, 4
  %981 = trunc i32 %980 to i8
  %982 = and i8 %981, 1
  store i8 %982, i8* %30, align 1, !tbaa !2451
  %983 = zext i1 %971 to i8
  store i8 %983, i8* %33, align 1, !tbaa !2448
  %984 = lshr i32 %968, 31
  %985 = trunc i32 %984 to i8
  store i8 %985, i8* %36, align 1, !tbaa !2449
  %986 = lshr i32 %967, 31
  %987 = xor i32 %984, %986
  %988 = add nuw nsw i32 %987, %984
  %989 = icmp eq i32 %988, 2
  %990 = zext i1 %989 to i8
  store i8 %990, i8* %42, align 1, !tbaa !2450
  %991 = sext i32 %968 to i64
  store i64 %991, i64* %RDX, align 8, !tbaa !2428
  %992 = shl nsw i64 %991, 3
  %993 = add i64 %992, %963
  %994 = add i64 %951, 31
  store i64 %994, i64* %PC, align 8
  %995 = inttoptr i64 %993 to double*
  store double %959, double* %995, align 8
  %996 = load i64, i64* %RBP, align 8
  %997 = add i64 %996, -136
  %998 = load i64, i64* %PC, align 8
  %999 = add i64 %998, 8
  store i64 %999, i64* %PC, align 8
  %1000 = inttoptr i64 %997 to double*
  %1001 = load double, double* %1000, align 8
  store double %1001, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1002 = add i64 %996, -176
  %1003 = add i64 %998, 16
  store i64 %1003, i64* %PC, align 8
  %1004 = inttoptr i64 %1002 to double*
  %1005 = load double, double* %1004, align 8
  %1006 = fsub double %1001, %1005
  store double %1006, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1007 = add i64 %996, -16
  %1008 = add i64 %998, 20
  store i64 %1008, i64* %PC, align 8
  %1009 = inttoptr i64 %1007 to i64*
  %1010 = load i64, i64* %1009, align 8
  store i64 %1010, i64* %RCX, align 8, !tbaa !2428
  %1011 = add i64 %996, -32
  %1012 = add i64 %998, 24
  store i64 %1012, i64* %PC, align 8
  %1013 = inttoptr i64 %1011 to i32*
  %1014 = load i32, i32* %1013, align 4
  %1015 = sext i32 %1014 to i64
  store i64 %1015, i64* %RDX, align 8, !tbaa !2428
  %1016 = shl nsw i64 %1015, 3
  %1017 = add i64 %1016, %1010
  %1018 = add i64 %998, 29
  store i64 %1018, i64* %PC, align 8
  %1019 = inttoptr i64 %1017 to double*
  store double %1006, double* %1019, align 8
  %1020 = load i64, i64* %RBP, align 8
  %1021 = add i64 %1020, -144
  %1022 = load i64, i64* %PC, align 8
  %1023 = add i64 %1022, 8
  store i64 %1023, i64* %PC, align 8
  %1024 = inttoptr i64 %1021 to double*
  %1025 = load double, double* %1024, align 8
  store double %1025, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1026 = add i64 %1020, -168
  %1027 = add i64 %1022, 16
  store i64 %1027, i64* %PC, align 8
  %1028 = inttoptr i64 %1026 to double*
  %1029 = load double, double* %1028, align 8
  %1030 = fadd double %1025, %1029
  store double %1030, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1031 = add i64 %1020, -16
  %1032 = add i64 %1022, 20
  store i64 %1032, i64* %PC, align 8
  %1033 = inttoptr i64 %1031 to i64*
  %1034 = load i64, i64* %1033, align 8
  store i64 %1034, i64* %RCX, align 8, !tbaa !2428
  %1035 = add i64 %1020, -32
  %1036 = add i64 %1022, 23
  store i64 %1036, i64* %PC, align 8
  %1037 = inttoptr i64 %1035 to i32*
  %1038 = load i32, i32* %1037, align 4
  %1039 = add i32 %1038, 1
  %1040 = zext i32 %1039 to i64
  store i64 %1040, i64* %RAX, align 8, !tbaa !2428
  %1041 = icmp eq i32 %1038, -1
  %1042 = icmp eq i32 %1039, 0
  %1043 = or i1 %1041, %1042
  %1044 = zext i1 %1043 to i8
  store i8 %1044, i8* %17, align 1, !tbaa !2433
  %1045 = and i32 %1039, 255
  %1046 = tail call i32 @llvm.ctpop.i32(i32 %1045) #10
  %1047 = trunc i32 %1046 to i8
  %1048 = and i8 %1047, 1
  %1049 = xor i8 %1048, 1
  store i8 %1049, i8* %24, align 1, !tbaa !2447
  %1050 = xor i32 %1038, %1039
  %1051 = lshr i32 %1050, 4
  %1052 = trunc i32 %1051 to i8
  %1053 = and i8 %1052, 1
  store i8 %1053, i8* %30, align 1, !tbaa !2451
  %1054 = zext i1 %1042 to i8
  store i8 %1054, i8* %33, align 1, !tbaa !2448
  %1055 = lshr i32 %1039, 31
  %1056 = trunc i32 %1055 to i8
  store i8 %1056, i8* %36, align 1, !tbaa !2449
  %1057 = lshr i32 %1038, 31
  %1058 = xor i32 %1055, %1057
  %1059 = add nuw nsw i32 %1058, %1055
  %1060 = icmp eq i32 %1059, 2
  %1061 = zext i1 %1060 to i8
  store i8 %1061, i8* %42, align 1, !tbaa !2450
  %1062 = sext i32 %1039 to i64
  store i64 %1062, i64* %RDX, align 8, !tbaa !2428
  %1063 = shl nsw i64 %1062, 3
  %1064 = add i64 %1063, %1034
  %1065 = add i64 %1022, 34
  store i64 %1065, i64* %PC, align 8
  %1066 = inttoptr i64 %1064 to double*
  store double %1030, double* %1066, align 8
  %1067 = load i64, i64* %RBP, align 8
  %1068 = add i64 %1067, -136
  %1069 = load i64, i64* %PC, align 8
  %1070 = add i64 %1069, 8
  store i64 %1070, i64* %PC, align 8
  %1071 = inttoptr i64 %1068 to double*
  %1072 = load double, double* %1071, align 8
  store double %1072, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1073 = add i64 %1067, -176
  %1074 = add i64 %1069, 16
  store i64 %1074, i64* %PC, align 8
  %1075 = inttoptr i64 %1073 to double*
  %1076 = load double, double* %1075, align 8
  %1077 = fadd double %1072, %1076
  store double %1077, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1078 = add i64 %1067, -16
  %1079 = add i64 %1069, 20
  store i64 %1079, i64* %PC, align 8
  %1080 = inttoptr i64 %1078 to i64*
  %1081 = load i64, i64* %1080, align 8
  store i64 %1081, i64* %RCX, align 8, !tbaa !2428
  %1082 = add i64 %1067, -40
  %1083 = add i64 %1069, 24
  store i64 %1083, i64* %PC, align 8
  %1084 = inttoptr i64 %1082 to i32*
  %1085 = load i32, i32* %1084, align 4
  %1086 = sext i32 %1085 to i64
  store i64 %1086, i64* %RDX, align 8, !tbaa !2428
  %1087 = shl nsw i64 %1086, 3
  %1088 = add i64 %1087, %1081
  %1089 = add i64 %1069, 29
  store i64 %1089, i64* %PC, align 8
  %1090 = inttoptr i64 %1088 to double*
  store double %1077, double* %1090, align 8
  %1091 = load i64, i64* %RBP, align 8
  %1092 = add i64 %1091, -144
  %1093 = load i64, i64* %PC, align 8
  %1094 = add i64 %1093, 8
  store i64 %1094, i64* %PC, align 8
  %1095 = inttoptr i64 %1092 to double*
  %1096 = load double, double* %1095, align 8
  store double %1096, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1097 = add i64 %1091, -168
  %1098 = add i64 %1093, 16
  store i64 %1098, i64* %PC, align 8
  %1099 = inttoptr i64 %1097 to double*
  %1100 = load double, double* %1099, align 8
  %1101 = fsub double %1096, %1100
  store double %1101, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1102 = add i64 %1091, -16
  %1103 = add i64 %1093, 20
  store i64 %1103, i64* %PC, align 8
  %1104 = inttoptr i64 %1102 to i64*
  %1105 = load i64, i64* %1104, align 8
  store i64 %1105, i64* %RCX, align 8, !tbaa !2428
  %1106 = add i64 %1091, -40
  %1107 = add i64 %1093, 23
  store i64 %1107, i64* %PC, align 8
  %1108 = inttoptr i64 %1106 to i32*
  %1109 = load i32, i32* %1108, align 4
  %1110 = add i32 %1109, 1
  %1111 = zext i32 %1110 to i64
  store i64 %1111, i64* %RAX, align 8, !tbaa !2428
  %1112 = icmp eq i32 %1109, -1
  %1113 = icmp eq i32 %1110, 0
  %1114 = or i1 %1112, %1113
  %1115 = zext i1 %1114 to i8
  store i8 %1115, i8* %17, align 1, !tbaa !2433
  %1116 = and i32 %1110, 255
  %1117 = tail call i32 @llvm.ctpop.i32(i32 %1116) #10
  %1118 = trunc i32 %1117 to i8
  %1119 = and i8 %1118, 1
  %1120 = xor i8 %1119, 1
  store i8 %1120, i8* %24, align 1, !tbaa !2447
  %1121 = xor i32 %1109, %1110
  %1122 = lshr i32 %1121, 4
  %1123 = trunc i32 %1122 to i8
  %1124 = and i8 %1123, 1
  store i8 %1124, i8* %30, align 1, !tbaa !2451
  %1125 = zext i1 %1113 to i8
  store i8 %1125, i8* %33, align 1, !tbaa !2448
  %1126 = lshr i32 %1110, 31
  %1127 = trunc i32 %1126 to i8
  store i8 %1127, i8* %36, align 1, !tbaa !2449
  %1128 = lshr i32 %1109, 31
  %1129 = xor i32 %1126, %1128
  %1130 = add nuw nsw i32 %1129, %1126
  %1131 = icmp eq i32 %1130, 2
  %1132 = zext i1 %1131 to i8
  store i8 %1132, i8* %42, align 1, !tbaa !2450
  %1133 = sext i32 %1110 to i64
  store i64 %1133, i64* %RDX, align 8, !tbaa !2428
  %1134 = shl nsw i64 %1133, 3
  %1135 = add i64 %1134, %1105
  %1136 = add i64 %1093, 34
  store i64 %1136, i64* %PC, align 8
  %1137 = inttoptr i64 %1135 to double*
  store double %1101, double* %1137, align 8
  %1138 = load i64, i64* %RBP, align 8
  %1139 = add i64 %1138, -28
  %1140 = load i64, i64* %PC, align 8
  %1141 = add i64 %1140, 3
  store i64 %1141, i64* %PC, align 8
  %1142 = inttoptr i64 %1139 to i32*
  %1143 = load i32, i32* %1142, align 4
  %1144 = add i32 %1143, 2
  %1145 = zext i32 %1144 to i64
  store i64 %1145, i64* %RAX, align 8, !tbaa !2428
  %1146 = icmp ugt i32 %1143, -3
  %1147 = zext i1 %1146 to i8
  store i8 %1147, i8* %17, align 1, !tbaa !2433
  %1148 = and i32 %1144, 255
  %1149 = tail call i32 @llvm.ctpop.i32(i32 %1148) #10
  %1150 = trunc i32 %1149 to i8
  %1151 = and i8 %1150, 1
  %1152 = xor i8 %1151, 1
  store i8 %1152, i8* %24, align 1, !tbaa !2447
  %1153 = xor i32 %1143, %1144
  %1154 = lshr i32 %1153, 4
  %1155 = trunc i32 %1154 to i8
  %1156 = and i8 %1155, 1
  store i8 %1156, i8* %30, align 1, !tbaa !2451
  %1157 = icmp eq i32 %1144, 0
  %1158 = zext i1 %1157 to i8
  store i8 %1158, i8* %33, align 1, !tbaa !2448
  %1159 = lshr i32 %1144, 31
  %1160 = trunc i32 %1159 to i8
  store i8 %1160, i8* %36, align 1, !tbaa !2449
  %1161 = lshr i32 %1143, 31
  %1162 = xor i32 %1159, %1161
  %1163 = add nuw nsw i32 %1162, %1159
  %1164 = icmp eq i32 %1163, 2
  %1165 = zext i1 %1164 to i8
  store i8 %1165, i8* %42, align 1, !tbaa !2450
  %1166 = add i64 %1140, 9
  store i64 %1166, i64* %PC, align 8
  store i32 %1144, i32* %1142, align 4
  %1167 = load i64, i64* %PC, align 8
  %1168 = add i64 %1167, -594
  store i64 %1168, i64* %PC, align 8, !tbaa !2428
  br label %block_403326

block_40386f:                                     ; preds = %block_403863
  %1169 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 80) to i64*), align 16
  store i64 %1169, i64* %276, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1170 = add i64 %2626, -48
  %1171 = add i64 %2662, 11
  store i64 %1171, i64* %PC, align 8
  %1172 = inttoptr i64 %1170 to i32*
  %1173 = load i32, i32* %1172, align 4
  %1174 = add i32 %1173, 2
  %1175 = zext i32 %1174 to i64
  store i64 %1175, i64* %RAX, align 8, !tbaa !2428
  %1176 = icmp ugt i32 %1173, -3
  %1177 = zext i1 %1176 to i8
  store i8 %1177, i8* %17, align 1, !tbaa !2433
  %1178 = and i32 %1174, 255
  %1179 = tail call i32 @llvm.ctpop.i32(i32 %1178) #10
  %1180 = trunc i32 %1179 to i8
  %1181 = and i8 %1180, 1
  %1182 = xor i8 %1181, 1
  store i8 %1182, i8* %24, align 1, !tbaa !2447
  %1183 = xor i32 %1173, %1174
  %1184 = lshr i32 %1183, 4
  %1185 = trunc i32 %1184 to i8
  %1186 = and i8 %1185, 1
  store i8 %1186, i8* %30, align 1, !tbaa !2451
  %1187 = icmp eq i32 %1174, 0
  %1188 = zext i1 %1187 to i8
  store i8 %1188, i8* %33, align 1, !tbaa !2448
  %1189 = lshr i32 %1174, 31
  %1190 = trunc i32 %1189 to i8
  store i8 %1190, i8* %36, align 1, !tbaa !2449
  %1191 = lshr i32 %1173, 31
  %1192 = xor i32 %1189, %1191
  %1193 = add nuw nsw i32 %1192, %1189
  %1194 = icmp eq i32 %1193, 2
  %1195 = zext i1 %1194 to i8
  store i8 %1195, i8* %42, align 1, !tbaa !2450
  %1196 = add i64 %2662, 17
  store i64 %1196, i64* %PC, align 8
  store i32 %1174, i32* %1172, align 4
  %1197 = load i64, i64* %RBP, align 8
  %1198 = add i64 %1197, -48
  %1199 = load i64, i64* %PC, align 8
  %1200 = add i64 %1199, 3
  store i64 %1200, i64* %PC, align 8
  %1201 = inttoptr i64 %1198 to i32*
  %1202 = load i32, i32* %1201, align 4
  %1203 = shl i32 %1202, 1
  %1204 = icmp slt i32 %1202, 0
  %1205 = icmp slt i32 %1203, 0
  %1206 = xor i1 %1204, %1205
  %1207 = zext i32 %1203 to i64
  store i64 %1207, i64* %RAX, align 8, !tbaa !2428
  %.lobit9 = lshr i32 %1202, 31
  %1208 = trunc i32 %.lobit9 to i8
  store i8 %1208, i8* %17, align 1, !tbaa !2432
  %1209 = and i32 %1203, 254
  %1210 = tail call i32 @llvm.ctpop.i32(i32 %1209) #10
  %1211 = trunc i32 %1210 to i8
  %1212 = and i8 %1211, 1
  %1213 = xor i8 %1212, 1
  store i8 %1213, i8* %24, align 1, !tbaa !2432
  store i8 0, i8* %30, align 1, !tbaa !2432
  %1214 = icmp eq i32 %1203, 0
  %1215 = zext i1 %1214 to i8
  store i8 %1215, i8* %33, align 1, !tbaa !2432
  %1216 = lshr i32 %1202, 30
  %1217 = trunc i32 %1216 to i8
  %1218 = and i8 %1217, 1
  store i8 %1218, i8* %36, align 1, !tbaa !2432
  %1219 = zext i1 %1206 to i8
  store i8 %1219, i8* %42, align 1, !tbaa !2432
  %1220 = add i64 %1197, -52
  %1221 = add i64 %1199, 9
  store i64 %1221, i64* %PC, align 8
  %1222 = inttoptr i64 %1220 to i32*
  store i32 %1203, i32* %1222, align 4
  %1223 = load i64, i64* %RBP, align 8
  %1224 = add i64 %1223, -24
  %1225 = load i64, i64* %PC, align 8
  %1226 = add i64 %1225, 4
  store i64 %1226, i64* %PC, align 8
  %1227 = inttoptr i64 %1224 to i64*
  %1228 = load i64, i64* %1227, align 8
  store i64 %1228, i64* %RCX, align 8, !tbaa !2428
  %1229 = add i64 %1223, -48
  %1230 = add i64 %1225, 8
  store i64 %1230, i64* %PC, align 8
  %1231 = inttoptr i64 %1229 to i32*
  %1232 = load i32, i32* %1231, align 4
  %1233 = sext i32 %1232 to i64
  store i64 %1233, i64* %RDX, align 8, !tbaa !2428
  %1234 = shl nsw i64 %1233, 3
  %1235 = add i64 %1234, %1228
  %1236 = add i64 %1225, 13
  store i64 %1236, i64* %PC, align 8
  %1237 = inttoptr i64 %1235 to i64*
  %1238 = load i64, i64* %1237, align 8
  %1239 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %1238, i64* %1239, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %1240 = add i64 %1223, -88
  %1241 = add i64 %1225, 18
  store i64 %1241, i64* %PC, align 8
  %1242 = inttoptr i64 %1240 to i64*
  store i64 %1238, i64* %1242, align 8
  %1243 = load i64, i64* %RBP, align 8
  %1244 = add i64 %1243, -24
  %1245 = load i64, i64* %PC, align 8
  %1246 = add i64 %1245, 4
  store i64 %1246, i64* %PC, align 8
  %1247 = inttoptr i64 %1244 to i64*
  %1248 = load i64, i64* %1247, align 8
  store i64 %1248, i64* %RCX, align 8, !tbaa !2428
  %1249 = add i64 %1243, -48
  %1250 = add i64 %1245, 7
  store i64 %1250, i64* %PC, align 8
  %1251 = inttoptr i64 %1249 to i32*
  %1252 = load i32, i32* %1251, align 4
  %1253 = add i32 %1252, 1
  %1254 = zext i32 %1253 to i64
  store i64 %1254, i64* %RAX, align 8, !tbaa !2428
  %1255 = icmp eq i32 %1252, -1
  %1256 = icmp eq i32 %1253, 0
  %1257 = or i1 %1255, %1256
  %1258 = zext i1 %1257 to i8
  store i8 %1258, i8* %17, align 1, !tbaa !2433
  %1259 = and i32 %1253, 255
  %1260 = tail call i32 @llvm.ctpop.i32(i32 %1259) #10
  %1261 = trunc i32 %1260 to i8
  %1262 = and i8 %1261, 1
  %1263 = xor i8 %1262, 1
  store i8 %1263, i8* %24, align 1, !tbaa !2447
  %1264 = xor i32 %1252, %1253
  %1265 = lshr i32 %1264, 4
  %1266 = trunc i32 %1265 to i8
  %1267 = and i8 %1266, 1
  store i8 %1267, i8* %30, align 1, !tbaa !2451
  %1268 = zext i1 %1256 to i8
  store i8 %1268, i8* %33, align 1, !tbaa !2448
  %1269 = lshr i32 %1253, 31
  %1270 = trunc i32 %1269 to i8
  store i8 %1270, i8* %36, align 1, !tbaa !2449
  %1271 = lshr i32 %1252, 31
  %1272 = xor i32 %1269, %1271
  %1273 = add nuw nsw i32 %1272, %1269
  %1274 = icmp eq i32 %1273, 2
  %1275 = zext i1 %1274 to i8
  store i8 %1275, i8* %42, align 1, !tbaa !2450
  %1276 = sext i32 %1253 to i64
  store i64 %1276, i64* %RDX, align 8, !tbaa !2428
  %1277 = shl nsw i64 %1276, 3
  %1278 = add i64 %1277, %1248
  %1279 = add i64 %1245, 18
  store i64 %1279, i64* %PC, align 8
  %1280 = inttoptr i64 %1278 to i64*
  %1281 = load i64, i64* %1280, align 8
  store i64 %1281, i64* %1239, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %1282 = add i64 %1243, -96
  %1283 = add i64 %1245, 23
  store i64 %1283, i64* %PC, align 8
  %1284 = inttoptr i64 %1282 to i64*
  store i64 %1281, i64* %1284, align 8
  %1285 = load i64, i64* %RBP, align 8
  %1286 = add i64 %1285, -24
  %1287 = load i64, i64* %PC, align 8
  %1288 = add i64 %1287, 4
  store i64 %1288, i64* %PC, align 8
  %1289 = inttoptr i64 %1286 to i64*
  %1290 = load i64, i64* %1289, align 8
  store i64 %1290, i64* %RCX, align 8, !tbaa !2428
  %1291 = add i64 %1285, -52
  %1292 = add i64 %1287, 8
  store i64 %1292, i64* %PC, align 8
  %1293 = inttoptr i64 %1291 to i32*
  %1294 = load i32, i32* %1293, align 4
  %1295 = sext i32 %1294 to i64
  store i64 %1295, i64* %RDX, align 8, !tbaa !2428
  %1296 = shl nsw i64 %1295, 3
  %1297 = add i64 %1296, %1290
  %1298 = add i64 %1287, 13
  store i64 %1298, i64* %PC, align 8
  %1299 = inttoptr i64 %1297 to i64*
  %1300 = load i64, i64* %1299, align 8
  store i64 %1300, i64* %1239, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %1301 = add i64 %1285, -72
  %1302 = add i64 %1287, 18
  store i64 %1302, i64* %PC, align 8
  %1303 = inttoptr i64 %1301 to i64*
  store i64 %1300, i64* %1303, align 8
  %1304 = load i64, i64* %RBP, align 8
  %1305 = add i64 %1304, -24
  %1306 = load i64, i64* %PC, align 8
  %1307 = add i64 %1306, 4
  store i64 %1307, i64* %PC, align 8
  %1308 = inttoptr i64 %1305 to i64*
  %1309 = load i64, i64* %1308, align 8
  store i64 %1309, i64* %RCX, align 8, !tbaa !2428
  %1310 = add i64 %1304, -52
  %1311 = add i64 %1306, 7
  store i64 %1311, i64* %PC, align 8
  %1312 = inttoptr i64 %1310 to i32*
  %1313 = load i32, i32* %1312, align 4
  %1314 = add i32 %1313, 1
  %1315 = zext i32 %1314 to i64
  store i64 %1315, i64* %RAX, align 8, !tbaa !2428
  %1316 = icmp eq i32 %1313, -1
  %1317 = icmp eq i32 %1314, 0
  %1318 = or i1 %1316, %1317
  %1319 = zext i1 %1318 to i8
  store i8 %1319, i8* %17, align 1, !tbaa !2433
  %1320 = and i32 %1314, 255
  %1321 = tail call i32 @llvm.ctpop.i32(i32 %1320) #10
  %1322 = trunc i32 %1321 to i8
  %1323 = and i8 %1322, 1
  %1324 = xor i8 %1323, 1
  store i8 %1324, i8* %24, align 1, !tbaa !2447
  %1325 = xor i32 %1313, %1314
  %1326 = lshr i32 %1325, 4
  %1327 = trunc i32 %1326 to i8
  %1328 = and i8 %1327, 1
  store i8 %1328, i8* %30, align 1, !tbaa !2451
  %1329 = zext i1 %1317 to i8
  store i8 %1329, i8* %33, align 1, !tbaa !2448
  %1330 = lshr i32 %1314, 31
  %1331 = trunc i32 %1330 to i8
  store i8 %1331, i8* %36, align 1, !tbaa !2449
  %1332 = lshr i32 %1313, 31
  %1333 = xor i32 %1330, %1332
  %1334 = add nuw nsw i32 %1333, %1330
  %1335 = icmp eq i32 %1334, 2
  %1336 = zext i1 %1335 to i8
  store i8 %1336, i8* %42, align 1, !tbaa !2450
  %1337 = sext i32 %1314 to i64
  store i64 %1337, i64* %RDX, align 8, !tbaa !2428
  %1338 = shl nsw i64 %1337, 3
  %1339 = add i64 %1338, %1309
  %1340 = add i64 %1306, 18
  store i64 %1340, i64* %PC, align 8
  %1341 = inttoptr i64 %1339 to i64*
  %1342 = load i64, i64* %1341, align 8
  store i64 %1342, i64* %1239, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %1343 = add i64 %1304, -80
  %1344 = add i64 %1306, 23
  store i64 %1344, i64* %PC, align 8
  %1345 = inttoptr i64 %1343 to i64*
  store i64 %1342, i64* %1345, align 8
  %1346 = load i64, i64* %RBP, align 8
  %1347 = add i64 %1346, -72
  %1348 = load i64, i64* %PC, align 8
  %1349 = add i64 %1348, 5
  store i64 %1349, i64* %PC, align 8
  %1350 = inttoptr i64 %1347 to double*
  %1351 = load double, double* %1350, align 8
  store double %1351, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %1352 = load <2 x i32>, <2 x i32>* %1444, align 1
  %1353 = load <2 x i32>, <2 x i32>* %1445, align 1
  %1354 = extractelement <2 x i32> %1352, i32 0
  store i32 %1354, i32* %1446, align 1, !tbaa !2475
  %1355 = extractelement <2 x i32> %1352, i32 1
  store i32 %1355, i32* %1448, align 1, !tbaa !2475
  %1356 = extractelement <2 x i32> %1353, i32 0
  store i32 %1356, i32* %1450, align 1, !tbaa !2475
  %1357 = extractelement <2 x i32> %1353, i32 1
  store i32 %1357, i32* %1452, align 1, !tbaa !2475
  %1358 = add i64 %1346, -96
  %1359 = add i64 %1348, 13
  store i64 %1359, i64* %PC, align 8
  %1360 = load double, double* %1453, align 1
  %1361 = inttoptr i64 %1358 to double*
  %1362 = load double, double* %1361, align 8
  %1363 = fmul double %1360, %1362
  store double %1363, double* %1453, align 1, !tbaa !2452
  %1364 = add i64 %1346, -80
  %1365 = add i64 %1348, 18
  store i64 %1365, i64* %PC, align 8
  %1366 = inttoptr i64 %1364 to double*
  %1367 = load double, double* %1366, align 8
  %1368 = fmul double %1363, %1367
  store double %1368, double* %1453, align 1, !tbaa !2452
  %1369 = fsub double %1351, %1368
  store double %1369, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %1370 = add i64 %1346, -104
  %1371 = add i64 %1348, 27
  store i64 %1371, i64* %PC, align 8
  %1372 = inttoptr i64 %1370 to double*
  store double %1369, double* %1372, align 8
  %1373 = load i64, i64* %RBP, align 8
  %1374 = add i64 %1373, -96
  %1375 = load i64, i64* %PC, align 8
  %1376 = add i64 %1375, 5
  store i64 %1376, i64* %PC, align 8
  %1377 = load double, double* %94, align 1
  %1378 = inttoptr i64 %1374 to double*
  %1379 = load double, double* %1378, align 8
  %1380 = fmul double %1377, %1379
  store double %1380, double* %94, align 1, !tbaa !2452
  %1381 = add i64 %1373, -72
  %1382 = add i64 %1375, 10
  store i64 %1382, i64* %PC, align 8
  %1383 = inttoptr i64 %1381 to double*
  %1384 = load double, double* %1383, align 8
  %1385 = fmul double %1380, %1384
  store double %1385, double* %94, align 1, !tbaa !2452
  %1386 = add i64 %1373, -80
  %1387 = add i64 %1375, 15
  store i64 %1387, i64* %PC, align 8
  %1388 = inttoptr i64 %1386 to double*
  %1389 = load double, double* %1388, align 8
  %1390 = fsub double %1385, %1389
  store double %1390, double* %94, align 1, !tbaa !2452
  %1391 = add i64 %1373, -112
  %1392 = add i64 %1375, 20
  store i64 %1392, i64* %PC, align 8
  %1393 = inttoptr i64 %1391 to double*
  store double %1390, double* %1393, align 8
  %1394 = load i64, i64* %RBP, align 8
  %1395 = add i64 %1394, -44
  %1396 = load i64, i64* %PC, align 8
  %1397 = add i64 %1396, 3
  store i64 %1397, i64* %PC, align 8
  %1398 = inttoptr i64 %1395 to i32*
  %1399 = load i32, i32* %1398, align 4
  %1400 = zext i32 %1399 to i64
  store i64 %1400, i64* %RAX, align 8, !tbaa !2428
  %1401 = add i64 %1394, -28
  %1402 = add i64 %1396, 6
  store i64 %1402, i64* %PC, align 8
  %1403 = inttoptr i64 %1401 to i32*
  store i32 %1399, i32* %1403, align 4
  %.pre5 = load i64, i64* %PC, align 8
  br label %block_403910

block_40384d:                                     ; preds = %block_403591
  %1404 = add i64 %2624, -48
  %1405 = add i64 %2623, 7
  store i64 %1405, i64* %PC, align 8
  %1406 = inttoptr i64 %1404 to i32*
  store i32 0, i32* %1406, align 4
  %1407 = load i64, i64* %RBP, align 8
  %1408 = add i64 %1407, -56
  %1409 = load i64, i64* %PC, align 8
  %1410 = add i64 %1409, 3
  store i64 %1410, i64* %PC, align 8
  %1411 = inttoptr i64 %1408 to i32*
  %1412 = load i32, i32* %1411, align 4
  %1413 = shl i32 %1412, 1
  %1414 = icmp slt i32 %1412, 0
  %1415 = icmp slt i32 %1413, 0
  %1416 = xor i1 %1414, %1415
  %1417 = zext i32 %1413 to i64
  store i64 %1417, i64* %RAX, align 8, !tbaa !2428
  %.lobit = lshr i32 %1412, 31
  %1418 = trunc i32 %.lobit to i8
  store i8 %1418, i8* %17, align 1, !tbaa !2432
  %1419 = and i32 %1413, 254
  %1420 = tail call i32 @llvm.ctpop.i32(i32 %1419) #10
  %1421 = trunc i32 %1420 to i8
  %1422 = and i8 %1421, 1
  %1423 = xor i8 %1422, 1
  store i8 %1423, i8* %24, align 1, !tbaa !2432
  store i8 0, i8* %30, align 1, !tbaa !2432
  %1424 = icmp eq i32 %1413, 0
  %1425 = zext i1 %1424 to i8
  store i8 %1425, i8* %33, align 1, !tbaa !2432
  %1426 = lshr i32 %1412, 30
  %1427 = trunc i32 %1426 to i8
  %1428 = and i8 %1427, 1
  store i8 %1428, i8* %36, align 1, !tbaa !2432
  %1429 = zext i1 %1416 to i8
  store i8 %1429, i8* %42, align 1, !tbaa !2432
  %1430 = add i64 %1407, -60
  %1431 = add i64 %1409, 9
  store i64 %1431, i64* %PC, align 8
  %1432 = inttoptr i64 %1430 to i32*
  store i32 %1413, i32* %1432, align 4
  %1433 = load i64, i64* %RBP, align 8
  %1434 = add i64 %1433, -60
  %1435 = load i64, i64* %PC, align 8
  %1436 = add i64 %1435, 3
  store i64 %1436, i64* %PC, align 8
  %1437 = inttoptr i64 %1434 to i32*
  %1438 = load i32, i32* %1437, align 4
  %1439 = zext i32 %1438 to i64
  store i64 %1439, i64* %RAX, align 8, !tbaa !2428
  %1440 = add i64 %1433, -44
  %1441 = add i64 %1435, 6
  store i64 %1441, i64* %PC, align 8
  %1442 = inttoptr i64 %1440 to i32*
  store i32 %1438, i32* %1442, align 4
  %1443 = bitcast %union.VectorReg* %7 to i8*
  %1444 = bitcast [32 x %union.VectorReg]* %5 to <2 x i32>*
  %1445 = bitcast i64* %95 to <2 x i32>*
  %1446 = bitcast %union.VectorReg* %7 to i32*
  %1447 = getelementptr inbounds i8, i8* %1443, i64 4
  %1448 = bitcast i8* %1447 to i32*
  %1449 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %1450 = bitcast i64* %1449 to i32*
  %1451 = getelementptr inbounds i8, i8* %1443, i64 12
  %1452 = bitcast i8* %1451 to i32*
  %1453 = bitcast %union.VectorReg* %7 to double*
  %.pre4 = load i64, i64* %PC, align 8
  br label %block_403863

block_403fde:                                     ; preds = %block_403863
  %1454 = load i64, i64* %RSP, align 8
  %1455 = add i64 %1454, 48
  store i64 %1455, i64* %RSP, align 8, !tbaa !2428
  %1456 = icmp ugt i64 %1454, -49
  %1457 = zext i1 %1456 to i8
  store i8 %1457, i8* %17, align 1, !tbaa !2433
  %1458 = trunc i64 %1455 to i32
  %1459 = and i32 %1458, 255
  %1460 = tail call i32 @llvm.ctpop.i32(i32 %1459) #10
  %1461 = trunc i32 %1460 to i8
  %1462 = and i8 %1461, 1
  %1463 = xor i8 %1462, 1
  store i8 %1463, i8* %24, align 1, !tbaa !2447
  %1464 = xor i64 %1454, 16
  %1465 = xor i64 %1464, %1455
  %1466 = lshr i64 %1465, 4
  %1467 = trunc i64 %1466 to i8
  %1468 = and i8 %1467, 1
  store i8 %1468, i8* %30, align 1, !tbaa !2451
  %1469 = icmp eq i64 %1455, 0
  %1470 = zext i1 %1469 to i8
  store i8 %1470, i8* %33, align 1, !tbaa !2448
  %1471 = lshr i64 %1455, 63
  %1472 = trunc i64 %1471 to i8
  store i8 %1472, i8* %36, align 1, !tbaa !2449
  %1473 = lshr i64 %1454, 63
  %1474 = xor i64 %1471, %1473
  %1475 = add nuw nsw i64 %1474, %1471
  %1476 = icmp eq i64 %1475, 2
  %1477 = zext i1 %1476 to i8
  store i8 %1477, i8* %42, align 1, !tbaa !2450
  %1478 = add i64 %2662, 5
  store i64 %1478, i64* %PC, align 8
  %1479 = add i64 %1454, 56
  %1480 = inttoptr i64 %1455 to i64*
  %1481 = load i64, i64* %1480, align 8
  store i64 %1481, i64* %RBP, align 8, !tbaa !2428
  store i64 %1479, i64* %RSP, align 8, !tbaa !2428
  %1482 = add i64 %2662, 6
  store i64 %1482, i64* %PC, align 8
  %1483 = inttoptr i64 %1479 to i64*
  %1484 = load i64, i64* %1483, align 8
  store i64 %1484, i64* %PC, align 8, !tbaa !2428
  %1485 = add i64 %1454, 64
  store i64 %1485, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_403fcb:                                     ; preds = %block_403c90
  %1486 = load i64, i64* %RBP, align 8
  %1487 = add i64 %1486, -60
  %1488 = add i64 %1577, 8
  store i64 %1488, i64* %PC, align 8
  %1489 = inttoptr i64 %1487 to i32*
  %1490 = load i32, i32* %1489, align 4
  %1491 = zext i32 %1490 to i64
  store i64 %1491, i64* %RAX, align 8, !tbaa !2428
  %1492 = add i64 %1486, -44
  %1493 = add i64 %1577, 11
  store i64 %1493, i64* %PC, align 8
  %1494 = inttoptr i64 %1492 to i32*
  %1495 = load i32, i32* %1494, align 4
  %1496 = add i32 %1495, %1490
  %1497 = zext i32 %1496 to i64
  store i64 %1497, i64* %RAX, align 8, !tbaa !2428
  %1498 = icmp ult i32 %1496, %1490
  %1499 = icmp ult i32 %1496, %1495
  %1500 = or i1 %1498, %1499
  %1501 = zext i1 %1500 to i8
  store i8 %1501, i8* %17, align 1, !tbaa !2433
  %1502 = and i32 %1496, 255
  %1503 = tail call i32 @llvm.ctpop.i32(i32 %1502) #10
  %1504 = trunc i32 %1503 to i8
  %1505 = and i8 %1504, 1
  %1506 = xor i8 %1505, 1
  store i8 %1506, i8* %24, align 1, !tbaa !2447
  %1507 = xor i32 %1495, %1490
  %1508 = xor i32 %1507, %1496
  %1509 = lshr i32 %1508, 4
  %1510 = trunc i32 %1509 to i8
  %1511 = and i8 %1510, 1
  store i8 %1511, i8* %30, align 1, !tbaa !2451
  %1512 = icmp eq i32 %1496, 0
  %1513 = zext i1 %1512 to i8
  store i8 %1513, i8* %33, align 1, !tbaa !2448
  %1514 = lshr i32 %1496, 31
  %1515 = trunc i32 %1514 to i8
  store i8 %1515, i8* %36, align 1, !tbaa !2449
  %1516 = lshr i32 %1490, 31
  %1517 = lshr i32 %1495, 31
  %1518 = xor i32 %1514, %1516
  %1519 = xor i32 %1514, %1517
  %1520 = add nuw nsw i32 %1518, %1519
  %1521 = icmp eq i32 %1520, 2
  %1522 = zext i1 %1521 to i8
  store i8 %1522, i8* %42, align 1, !tbaa !2450
  %1523 = add i64 %1577, 14
  store i64 %1523, i64* %PC, align 8
  store i32 %1496, i32* %1494, align 4
  %1524 = load i64, i64* %PC, align 8
  %1525 = add i64 %1524, -1910
  store i64 %1525, i64* %PC, align 8, !tbaa !2428
  br label %block_403863

block_403c90:                                     ; preds = %block_403ca6, %block_403c22
  %1526 = phi i64 [ %4730, %block_403ca6 ], [ %.pre6, %block_403c22 ]
  %1527 = load i64, i64* %RBP, align 8
  %1528 = add i64 %1527, -28
  %1529 = add i64 %1526, 3
  store i64 %1529, i64* %PC, align 8
  %1530 = inttoptr i64 %1528 to i32*
  %1531 = load i32, i32* %1530, align 4
  %1532 = zext i32 %1531 to i64
  store i64 %1532, i64* %RAX, align 8, !tbaa !2428
  %1533 = add i64 %1527, -8
  %1534 = add i64 %1526, 6
  store i64 %1534, i64* %PC, align 8
  %1535 = inttoptr i64 %1533 to i32*
  %1536 = load i32, i32* %1535, align 4
  %1537 = zext i32 %1536 to i64
  store i64 %1537, i64* %RCX, align 8, !tbaa !2428
  %1538 = add i64 %1527, -44
  %1539 = add i64 %1526, 9
  store i64 %1539, i64* %PC, align 8
  %1540 = inttoptr i64 %1538 to i32*
  %1541 = load i32, i32* %1540, align 4
  %1542 = zext i32 %1541 to i64
  store i64 %1542, i64* %RDX, align 8, !tbaa !2428
  %1543 = add i64 %1527, -56
  %1544 = add i64 %1526, 12
  store i64 %1544, i64* %PC, align 8
  %1545 = inttoptr i64 %1543 to i32*
  %1546 = load i32, i32* %1545, align 4
  %1547 = add i32 %1546, %1541
  %1548 = zext i32 %1547 to i64
  store i64 %1548, i64* %RDX, align 8, !tbaa !2428
  %1549 = add i32 %1547, %1536
  %1550 = zext i32 %1549 to i64
  store i64 %1550, i64* %RCX, align 8, !tbaa !2428
  %1551 = lshr i32 %1549, 31
  %1552 = sub i32 %1531, %1549
  %1553 = icmp ult i32 %1531, %1549
  %1554 = zext i1 %1553 to i8
  store i8 %1554, i8* %17, align 1, !tbaa !2433
  %1555 = and i32 %1552, 255
  %1556 = tail call i32 @llvm.ctpop.i32(i32 %1555) #10
  %1557 = trunc i32 %1556 to i8
  %1558 = and i8 %1557, 1
  %1559 = xor i8 %1558, 1
  store i8 %1559, i8* %24, align 1, !tbaa !2447
  %1560 = xor i32 %1549, %1531
  %1561 = xor i32 %1560, %1552
  %1562 = lshr i32 %1561, 4
  %1563 = trunc i32 %1562 to i8
  %1564 = and i8 %1563, 1
  store i8 %1564, i8* %30, align 1, !tbaa !2451
  %1565 = icmp eq i32 %1552, 0
  %1566 = zext i1 %1565 to i8
  store i8 %1566, i8* %33, align 1, !tbaa !2448
  %1567 = lshr i32 %1552, 31
  %1568 = trunc i32 %1567 to i8
  store i8 %1568, i8* %36, align 1, !tbaa !2449
  %1569 = lshr i32 %1531, 31
  %1570 = xor i32 %1551, %1569
  %1571 = xor i32 %1567, %1569
  %1572 = add nuw nsw i32 %1571, %1570
  %1573 = icmp eq i32 %1572, 2
  %1574 = zext i1 %1573 to i8
  store i8 %1574, i8* %42, align 1, !tbaa !2450
  %1575 = icmp ne i8 %1568, 0
  %1576 = xor i1 %1575, %1573
  %.v11 = select i1 %1576, i64 22, i64 827
  %1577 = add i64 %1526, %.v11
  store i64 %1577, i64* %PC, align 8, !tbaa !2428
  br i1 %1576, label %block_403ca6, label %block_403fcb

block_403910:                                     ; preds = %block_403921, %block_40386f
  %1578 = phi i64 [ %3683, %block_403921 ], [ %.pre5, %block_40386f ]
  %1579 = load i64, i64* %RBP, align 8
  %1580 = add i64 %1579, -28
  %1581 = add i64 %1578, 3
  store i64 %1581, i64* %PC, align 8
  %1582 = inttoptr i64 %1580 to i32*
  %1583 = load i32, i32* %1582, align 4
  %1584 = zext i32 %1583 to i64
  store i64 %1584, i64* %RAX, align 8, !tbaa !2428
  %1585 = add i64 %1579, -8
  %1586 = add i64 %1578, 6
  store i64 %1586, i64* %PC, align 8
  %1587 = inttoptr i64 %1585 to i32*
  %1588 = load i32, i32* %1587, align 4
  %1589 = zext i32 %1588 to i64
  store i64 %1589, i64* %RCX, align 8, !tbaa !2428
  %1590 = add i64 %1579, -44
  %1591 = add i64 %1578, 9
  store i64 %1591, i64* %PC, align 8
  %1592 = inttoptr i64 %1590 to i32*
  %1593 = load i32, i32* %1592, align 4
  %1594 = add i32 %1593, %1588
  %1595 = zext i32 %1594 to i64
  store i64 %1595, i64* %RCX, align 8, !tbaa !2428
  %1596 = lshr i32 %1594, 31
  %1597 = sub i32 %1583, %1594
  %1598 = icmp ult i32 %1583, %1594
  %1599 = zext i1 %1598 to i8
  store i8 %1599, i8* %17, align 1, !tbaa !2433
  %1600 = and i32 %1597, 255
  %1601 = tail call i32 @llvm.ctpop.i32(i32 %1600) #10
  %1602 = trunc i32 %1601 to i8
  %1603 = and i8 %1602, 1
  %1604 = xor i8 %1603, 1
  store i8 %1604, i8* %24, align 1, !tbaa !2447
  %1605 = xor i32 %1594, %1583
  %1606 = xor i32 %1605, %1597
  %1607 = lshr i32 %1606, 4
  %1608 = trunc i32 %1607 to i8
  %1609 = and i8 %1608, 1
  store i8 %1609, i8* %30, align 1, !tbaa !2451
  %1610 = icmp eq i32 %1597, 0
  %1611 = zext i1 %1610 to i8
  store i8 %1611, i8* %33, align 1, !tbaa !2448
  %1612 = lshr i32 %1597, 31
  %1613 = trunc i32 %1612 to i8
  store i8 %1613, i8* %36, align 1, !tbaa !2449
  %1614 = lshr i32 %1583, 31
  %1615 = xor i32 %1596, %1614
  %1616 = xor i32 %1612, %1614
  %1617 = add nuw nsw i32 %1616, %1615
  %1618 = icmp eq i32 %1617, 2
  %1619 = zext i1 %1618 to i8
  store i8 %1619, i8* %42, align 1, !tbaa !2450
  %1620 = icmp ne i8 %1613, 0
  %1621 = xor i1 %1620, %1618
  %.v10 = select i1 %1621, i64 17, i64 786
  %1622 = add i64 %1578, %.v10
  store i64 %1622, i64* %PC, align 8, !tbaa !2428
  br i1 %1621, label %block_403921, label %block_403c22

block_4035a2:                                     ; preds = %block_403591
  %1623 = add i64 %2624, -28
  %1624 = add i64 %2623, 3
  store i64 %1624, i64* %PC, align 8
  %1625 = inttoptr i64 %1623 to i32*
  %1626 = load i32, i32* %1625, align 4
  %1627 = zext i32 %1626 to i64
  store i64 %1627, i64* %RAX, align 8, !tbaa !2428
  %1628 = add i64 %2624, -8
  %1629 = add i64 %2623, 6
  store i64 %1629, i64* %PC, align 8
  %1630 = inttoptr i64 %1628 to i32*
  %1631 = load i32, i32* %1630, align 4
  %1632 = add i32 %1631, %1626
  %1633 = zext i32 %1632 to i64
  store i64 %1633, i64* %RAX, align 8, !tbaa !2428
  %1634 = icmp ult i32 %1632, %1626
  %1635 = icmp ult i32 %1632, %1631
  %1636 = or i1 %1634, %1635
  %1637 = zext i1 %1636 to i8
  store i8 %1637, i8* %17, align 1, !tbaa !2433
  %1638 = and i32 %1632, 255
  %1639 = tail call i32 @llvm.ctpop.i32(i32 %1638) #10
  %1640 = trunc i32 %1639 to i8
  %1641 = and i8 %1640, 1
  %1642 = xor i8 %1641, 1
  store i8 %1642, i8* %24, align 1, !tbaa !2447
  %1643 = xor i32 %1631, %1626
  %1644 = xor i32 %1643, %1632
  %1645 = lshr i32 %1644, 4
  %1646 = trunc i32 %1645 to i8
  %1647 = and i8 %1646, 1
  store i8 %1647, i8* %30, align 1, !tbaa !2451
  %1648 = icmp eq i32 %1632, 0
  %1649 = zext i1 %1648 to i8
  store i8 %1649, i8* %33, align 1, !tbaa !2448
  %1650 = lshr i32 %1632, 31
  %1651 = trunc i32 %1650 to i8
  store i8 %1651, i8* %36, align 1, !tbaa !2449
  %1652 = lshr i32 %1626, 31
  %1653 = lshr i32 %1631, 31
  %1654 = xor i32 %1650, %1652
  %1655 = xor i32 %1650, %1653
  %1656 = add nuw nsw i32 %1654, %1655
  %1657 = icmp eq i32 %1656, 2
  %1658 = zext i1 %1657 to i8
  store i8 %1658, i8* %42, align 1, !tbaa !2450
  %1659 = add i64 %2624, -32
  %1660 = add i64 %2623, 9
  store i64 %1660, i64* %PC, align 8
  %1661 = inttoptr i64 %1659 to i32*
  store i32 %1632, i32* %1661, align 4
  %1662 = load i64, i64* %RBP, align 8
  %1663 = add i64 %1662, -32
  %1664 = load i64, i64* %PC, align 8
  %1665 = add i64 %1664, 3
  store i64 %1665, i64* %PC, align 8
  %1666 = inttoptr i64 %1663 to i32*
  %1667 = load i32, i32* %1666, align 4
  %1668 = zext i32 %1667 to i64
  store i64 %1668, i64* %RAX, align 8, !tbaa !2428
  %1669 = add i64 %1662, -8
  %1670 = add i64 %1664, 6
  store i64 %1670, i64* %PC, align 8
  %1671 = inttoptr i64 %1669 to i32*
  %1672 = load i32, i32* %1671, align 4
  %1673 = add i32 %1672, %1667
  %1674 = zext i32 %1673 to i64
  store i64 %1674, i64* %RAX, align 8, !tbaa !2428
  %1675 = icmp ult i32 %1673, %1667
  %1676 = icmp ult i32 %1673, %1672
  %1677 = or i1 %1675, %1676
  %1678 = zext i1 %1677 to i8
  store i8 %1678, i8* %17, align 1, !tbaa !2433
  %1679 = and i32 %1673, 255
  %1680 = tail call i32 @llvm.ctpop.i32(i32 %1679) #10
  %1681 = trunc i32 %1680 to i8
  %1682 = and i8 %1681, 1
  %1683 = xor i8 %1682, 1
  store i8 %1683, i8* %24, align 1, !tbaa !2447
  %1684 = xor i32 %1672, %1667
  %1685 = xor i32 %1684, %1673
  %1686 = lshr i32 %1685, 4
  %1687 = trunc i32 %1686 to i8
  %1688 = and i8 %1687, 1
  store i8 %1688, i8* %30, align 1, !tbaa !2451
  %1689 = icmp eq i32 %1673, 0
  %1690 = zext i1 %1689 to i8
  store i8 %1690, i8* %33, align 1, !tbaa !2448
  %1691 = lshr i32 %1673, 31
  %1692 = trunc i32 %1691 to i8
  store i8 %1692, i8* %36, align 1, !tbaa !2449
  %1693 = lshr i32 %1667, 31
  %1694 = lshr i32 %1672, 31
  %1695 = xor i32 %1691, %1693
  %1696 = xor i32 %1691, %1694
  %1697 = add nuw nsw i32 %1695, %1696
  %1698 = icmp eq i32 %1697, 2
  %1699 = zext i1 %1698 to i8
  store i8 %1699, i8* %42, align 1, !tbaa !2450
  %1700 = add i64 %1662, -36
  %1701 = add i64 %1664, 9
  store i64 %1701, i64* %PC, align 8
  %1702 = inttoptr i64 %1700 to i32*
  store i32 %1673, i32* %1702, align 4
  %1703 = load i64, i64* %RBP, align 8
  %1704 = add i64 %1703, -36
  %1705 = load i64, i64* %PC, align 8
  %1706 = add i64 %1705, 3
  store i64 %1706, i64* %PC, align 8
  %1707 = inttoptr i64 %1704 to i32*
  %1708 = load i32, i32* %1707, align 4
  %1709 = zext i32 %1708 to i64
  store i64 %1709, i64* %RAX, align 8, !tbaa !2428
  %1710 = add i64 %1703, -8
  %1711 = add i64 %1705, 6
  store i64 %1711, i64* %PC, align 8
  %1712 = inttoptr i64 %1710 to i32*
  %1713 = load i32, i32* %1712, align 4
  %1714 = add i32 %1713, %1708
  %1715 = zext i32 %1714 to i64
  store i64 %1715, i64* %RAX, align 8, !tbaa !2428
  %1716 = icmp ult i32 %1714, %1708
  %1717 = icmp ult i32 %1714, %1713
  %1718 = or i1 %1716, %1717
  %1719 = zext i1 %1718 to i8
  store i8 %1719, i8* %17, align 1, !tbaa !2433
  %1720 = and i32 %1714, 255
  %1721 = tail call i32 @llvm.ctpop.i32(i32 %1720) #10
  %1722 = trunc i32 %1721 to i8
  %1723 = and i8 %1722, 1
  %1724 = xor i8 %1723, 1
  store i8 %1724, i8* %24, align 1, !tbaa !2447
  %1725 = xor i32 %1713, %1708
  %1726 = xor i32 %1725, %1714
  %1727 = lshr i32 %1726, 4
  %1728 = trunc i32 %1727 to i8
  %1729 = and i8 %1728, 1
  store i8 %1729, i8* %30, align 1, !tbaa !2451
  %1730 = icmp eq i32 %1714, 0
  %1731 = zext i1 %1730 to i8
  store i8 %1731, i8* %33, align 1, !tbaa !2448
  %1732 = lshr i32 %1714, 31
  %1733 = trunc i32 %1732 to i8
  store i8 %1733, i8* %36, align 1, !tbaa !2449
  %1734 = lshr i32 %1708, 31
  %1735 = lshr i32 %1713, 31
  %1736 = xor i32 %1732, %1734
  %1737 = xor i32 %1732, %1735
  %1738 = add nuw nsw i32 %1736, %1737
  %1739 = icmp eq i32 %1738, 2
  %1740 = zext i1 %1739 to i8
  store i8 %1740, i8* %42, align 1, !tbaa !2450
  %1741 = add i64 %1703, -40
  %1742 = add i64 %1705, 9
  store i64 %1742, i64* %PC, align 8
  %1743 = inttoptr i64 %1741 to i32*
  store i32 %1714, i32* %1743, align 4
  %1744 = load i64, i64* %RBP, align 8
  %1745 = add i64 %1744, -16
  %1746 = load i64, i64* %PC, align 8
  %1747 = add i64 %1746, 4
  store i64 %1747, i64* %PC, align 8
  %1748 = inttoptr i64 %1745 to i64*
  %1749 = load i64, i64* %1748, align 8
  store i64 %1749, i64* %RCX, align 8, !tbaa !2428
  %1750 = add i64 %1744, -28
  %1751 = add i64 %1746, 8
  store i64 %1751, i64* %PC, align 8
  %1752 = inttoptr i64 %1750 to i32*
  %1753 = load i32, i32* %1752, align 4
  %1754 = sext i32 %1753 to i64
  store i64 %1754, i64* %RDX, align 8, !tbaa !2428
  %1755 = shl nsw i64 %1754, 3
  %1756 = add i64 %1755, %1749
  %1757 = add i64 %1746, 13
  store i64 %1757, i64* %PC, align 8
  %1758 = inttoptr i64 %1756 to double*
  %1759 = load double, double* %1758, align 8
  store double %1759, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1760 = add i64 %1746, 17
  store i64 %1760, i64* %PC, align 8
  %1761 = load i64, i64* %1748, align 8
  store i64 %1761, i64* %RCX, align 8, !tbaa !2428
  %1762 = add i64 %1744, -32
  %1763 = add i64 %1746, 21
  store i64 %1763, i64* %PC, align 8
  %1764 = inttoptr i64 %1762 to i32*
  %1765 = load i32, i32* %1764, align 4
  %1766 = sext i32 %1765 to i64
  store i64 %1766, i64* %RDX, align 8, !tbaa !2428
  %1767 = shl nsw i64 %1766, 3
  %1768 = add i64 %1767, %1761
  %1769 = add i64 %1746, 26
  store i64 %1769, i64* %PC, align 8
  %1770 = inttoptr i64 %1768 to double*
  %1771 = load double, double* %1770, align 8
  %1772 = fadd double %1759, %1771
  store double %1772, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1773 = add i64 %1744, -120
  %1774 = add i64 %1746, 31
  store i64 %1774, i64* %PC, align 8
  %1775 = inttoptr i64 %1773 to double*
  store double %1772, double* %1775, align 8
  %1776 = load i64, i64* %RBP, align 8
  %1777 = add i64 %1776, -16
  %1778 = load i64, i64* %PC, align 8
  %1779 = add i64 %1778, 4
  store i64 %1779, i64* %PC, align 8
  %1780 = inttoptr i64 %1777 to i64*
  %1781 = load i64, i64* %1780, align 8
  store i64 %1781, i64* %RCX, align 8, !tbaa !2428
  %1782 = add i64 %1776, -28
  %1783 = add i64 %1778, 7
  store i64 %1783, i64* %PC, align 8
  %1784 = inttoptr i64 %1782 to i32*
  %1785 = load i32, i32* %1784, align 4
  %1786 = add i32 %1785, 1
  %1787 = zext i32 %1786 to i64
  store i64 %1787, i64* %RAX, align 8, !tbaa !2428
  %1788 = icmp eq i32 %1785, -1
  %1789 = icmp eq i32 %1786, 0
  %1790 = or i1 %1788, %1789
  %1791 = zext i1 %1790 to i8
  store i8 %1791, i8* %17, align 1, !tbaa !2433
  %1792 = and i32 %1786, 255
  %1793 = tail call i32 @llvm.ctpop.i32(i32 %1792) #10
  %1794 = trunc i32 %1793 to i8
  %1795 = and i8 %1794, 1
  %1796 = xor i8 %1795, 1
  store i8 %1796, i8* %24, align 1, !tbaa !2447
  %1797 = xor i32 %1785, %1786
  %1798 = lshr i32 %1797, 4
  %1799 = trunc i32 %1798 to i8
  %1800 = and i8 %1799, 1
  store i8 %1800, i8* %30, align 1, !tbaa !2451
  %1801 = zext i1 %1789 to i8
  store i8 %1801, i8* %33, align 1, !tbaa !2448
  %1802 = lshr i32 %1786, 31
  %1803 = trunc i32 %1802 to i8
  store i8 %1803, i8* %36, align 1, !tbaa !2449
  %1804 = lshr i32 %1785, 31
  %1805 = xor i32 %1802, %1804
  %1806 = add nuw nsw i32 %1805, %1802
  %1807 = icmp eq i32 %1806, 2
  %1808 = zext i1 %1807 to i8
  store i8 %1808, i8* %42, align 1, !tbaa !2450
  %1809 = sext i32 %1786 to i64
  store i64 %1809, i64* %RDX, align 8, !tbaa !2428
  %1810 = shl nsw i64 %1809, 3
  %1811 = add i64 %1810, %1781
  %1812 = add i64 %1778, 18
  store i64 %1812, i64* %PC, align 8
  %1813 = inttoptr i64 %1811 to double*
  %1814 = load double, double* %1813, align 8
  store double %1814, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1815 = add i64 %1778, 22
  store i64 %1815, i64* %PC, align 8
  %1816 = load i64, i64* %1780, align 8
  store i64 %1816, i64* %RCX, align 8, !tbaa !2428
  %1817 = add i64 %1776, -32
  %1818 = add i64 %1778, 25
  store i64 %1818, i64* %PC, align 8
  %1819 = inttoptr i64 %1817 to i32*
  %1820 = load i32, i32* %1819, align 4
  %1821 = add i32 %1820, 1
  %1822 = zext i32 %1821 to i64
  store i64 %1822, i64* %RAX, align 8, !tbaa !2428
  %1823 = icmp eq i32 %1820, -1
  %1824 = icmp eq i32 %1821, 0
  %1825 = or i1 %1823, %1824
  %1826 = zext i1 %1825 to i8
  store i8 %1826, i8* %17, align 1, !tbaa !2433
  %1827 = and i32 %1821, 255
  %1828 = tail call i32 @llvm.ctpop.i32(i32 %1827) #10
  %1829 = trunc i32 %1828 to i8
  %1830 = and i8 %1829, 1
  %1831 = xor i8 %1830, 1
  store i8 %1831, i8* %24, align 1, !tbaa !2447
  %1832 = xor i32 %1820, %1821
  %1833 = lshr i32 %1832, 4
  %1834 = trunc i32 %1833 to i8
  %1835 = and i8 %1834, 1
  store i8 %1835, i8* %30, align 1, !tbaa !2451
  %1836 = zext i1 %1824 to i8
  store i8 %1836, i8* %33, align 1, !tbaa !2448
  %1837 = lshr i32 %1821, 31
  %1838 = trunc i32 %1837 to i8
  store i8 %1838, i8* %36, align 1, !tbaa !2449
  %1839 = lshr i32 %1820, 31
  %1840 = xor i32 %1837, %1839
  %1841 = add nuw nsw i32 %1840, %1837
  %1842 = icmp eq i32 %1841, 2
  %1843 = zext i1 %1842 to i8
  store i8 %1843, i8* %42, align 1, !tbaa !2450
  %1844 = sext i32 %1821 to i64
  store i64 %1844, i64* %RDX, align 8, !tbaa !2428
  %1845 = shl nsw i64 %1844, 3
  %1846 = add i64 %1845, %1816
  %1847 = add i64 %1778, 36
  store i64 %1847, i64* %PC, align 8
  %1848 = inttoptr i64 %1846 to double*
  %1849 = load double, double* %1848, align 8
  %1850 = fadd double %1814, %1849
  store double %1850, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1851 = load i64, i64* %RBP, align 8
  %1852 = add i64 %1851, -128
  %1853 = add i64 %1778, 41
  store i64 %1853, i64* %PC, align 8
  %1854 = inttoptr i64 %1852 to double*
  store double %1850, double* %1854, align 8
  %1855 = load i64, i64* %RBP, align 8
  %1856 = add i64 %1855, -16
  %1857 = load i64, i64* %PC, align 8
  %1858 = add i64 %1857, 4
  store i64 %1858, i64* %PC, align 8
  %1859 = inttoptr i64 %1856 to i64*
  %1860 = load i64, i64* %1859, align 8
  store i64 %1860, i64* %RCX, align 8, !tbaa !2428
  %1861 = add i64 %1855, -28
  %1862 = add i64 %1857, 8
  store i64 %1862, i64* %PC, align 8
  %1863 = inttoptr i64 %1861 to i32*
  %1864 = load i32, i32* %1863, align 4
  %1865 = sext i32 %1864 to i64
  store i64 %1865, i64* %RDX, align 8, !tbaa !2428
  %1866 = shl nsw i64 %1865, 3
  %1867 = add i64 %1866, %1860
  %1868 = add i64 %1857, 13
  store i64 %1868, i64* %PC, align 8
  %1869 = inttoptr i64 %1867 to double*
  %1870 = load double, double* %1869, align 8
  store double %1870, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1871 = add i64 %1857, 17
  store i64 %1871, i64* %PC, align 8
  %1872 = load i64, i64* %1859, align 8
  store i64 %1872, i64* %RCX, align 8, !tbaa !2428
  %1873 = add i64 %1855, -32
  %1874 = add i64 %1857, 21
  store i64 %1874, i64* %PC, align 8
  %1875 = inttoptr i64 %1873 to i32*
  %1876 = load i32, i32* %1875, align 4
  %1877 = sext i32 %1876 to i64
  store i64 %1877, i64* %RDX, align 8, !tbaa !2428
  %1878 = shl nsw i64 %1877, 3
  %1879 = add i64 %1878, %1872
  %1880 = add i64 %1857, 26
  store i64 %1880, i64* %PC, align 8
  %1881 = inttoptr i64 %1879 to double*
  %1882 = load double, double* %1881, align 8
  %1883 = fsub double %1870, %1882
  store double %1883, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1884 = add i64 %1855, -136
  %1885 = add i64 %1857, 34
  store i64 %1885, i64* %PC, align 8
  %1886 = inttoptr i64 %1884 to double*
  store double %1883, double* %1886, align 8
  %1887 = load i64, i64* %RBP, align 8
  %1888 = add i64 %1887, -16
  %1889 = load i64, i64* %PC, align 8
  %1890 = add i64 %1889, 4
  store i64 %1890, i64* %PC, align 8
  %1891 = inttoptr i64 %1888 to i64*
  %1892 = load i64, i64* %1891, align 8
  store i64 %1892, i64* %RCX, align 8, !tbaa !2428
  %1893 = add i64 %1887, -28
  %1894 = add i64 %1889, 7
  store i64 %1894, i64* %PC, align 8
  %1895 = inttoptr i64 %1893 to i32*
  %1896 = load i32, i32* %1895, align 4
  %1897 = add i32 %1896, 1
  %1898 = zext i32 %1897 to i64
  store i64 %1898, i64* %RAX, align 8, !tbaa !2428
  %1899 = icmp eq i32 %1896, -1
  %1900 = icmp eq i32 %1897, 0
  %1901 = or i1 %1899, %1900
  %1902 = zext i1 %1901 to i8
  store i8 %1902, i8* %17, align 1, !tbaa !2433
  %1903 = and i32 %1897, 255
  %1904 = tail call i32 @llvm.ctpop.i32(i32 %1903) #10
  %1905 = trunc i32 %1904 to i8
  %1906 = and i8 %1905, 1
  %1907 = xor i8 %1906, 1
  store i8 %1907, i8* %24, align 1, !tbaa !2447
  %1908 = xor i32 %1896, %1897
  %1909 = lshr i32 %1908, 4
  %1910 = trunc i32 %1909 to i8
  %1911 = and i8 %1910, 1
  store i8 %1911, i8* %30, align 1, !tbaa !2451
  %1912 = zext i1 %1900 to i8
  store i8 %1912, i8* %33, align 1, !tbaa !2448
  %1913 = lshr i32 %1897, 31
  %1914 = trunc i32 %1913 to i8
  store i8 %1914, i8* %36, align 1, !tbaa !2449
  %1915 = lshr i32 %1896, 31
  %1916 = xor i32 %1913, %1915
  %1917 = add nuw nsw i32 %1916, %1913
  %1918 = icmp eq i32 %1917, 2
  %1919 = zext i1 %1918 to i8
  store i8 %1919, i8* %42, align 1, !tbaa !2450
  %1920 = sext i32 %1897 to i64
  store i64 %1920, i64* %RDX, align 8, !tbaa !2428
  %1921 = shl nsw i64 %1920, 3
  %1922 = add i64 %1921, %1892
  %1923 = add i64 %1889, 18
  store i64 %1923, i64* %PC, align 8
  %1924 = inttoptr i64 %1922 to double*
  %1925 = load double, double* %1924, align 8
  store double %1925, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1926 = add i64 %1889, 22
  store i64 %1926, i64* %PC, align 8
  %1927 = load i64, i64* %1891, align 8
  store i64 %1927, i64* %RCX, align 8, !tbaa !2428
  %1928 = add i64 %1887, -32
  %1929 = add i64 %1889, 25
  store i64 %1929, i64* %PC, align 8
  %1930 = inttoptr i64 %1928 to i32*
  %1931 = load i32, i32* %1930, align 4
  %1932 = add i32 %1931, 1
  %1933 = zext i32 %1932 to i64
  store i64 %1933, i64* %RAX, align 8, !tbaa !2428
  %1934 = icmp eq i32 %1931, -1
  %1935 = icmp eq i32 %1932, 0
  %1936 = or i1 %1934, %1935
  %1937 = zext i1 %1936 to i8
  store i8 %1937, i8* %17, align 1, !tbaa !2433
  %1938 = and i32 %1932, 255
  %1939 = tail call i32 @llvm.ctpop.i32(i32 %1938) #10
  %1940 = trunc i32 %1939 to i8
  %1941 = and i8 %1940, 1
  %1942 = xor i8 %1941, 1
  store i8 %1942, i8* %24, align 1, !tbaa !2447
  %1943 = xor i32 %1931, %1932
  %1944 = lshr i32 %1943, 4
  %1945 = trunc i32 %1944 to i8
  %1946 = and i8 %1945, 1
  store i8 %1946, i8* %30, align 1, !tbaa !2451
  %1947 = zext i1 %1935 to i8
  store i8 %1947, i8* %33, align 1, !tbaa !2448
  %1948 = lshr i32 %1932, 31
  %1949 = trunc i32 %1948 to i8
  store i8 %1949, i8* %36, align 1, !tbaa !2449
  %1950 = lshr i32 %1931, 31
  %1951 = xor i32 %1948, %1950
  %1952 = add nuw nsw i32 %1951, %1948
  %1953 = icmp eq i32 %1952, 2
  %1954 = zext i1 %1953 to i8
  store i8 %1954, i8* %42, align 1, !tbaa !2450
  %1955 = sext i32 %1932 to i64
  store i64 %1955, i64* %RDX, align 8, !tbaa !2428
  %1956 = shl nsw i64 %1955, 3
  %1957 = add i64 %1956, %1927
  %1958 = add i64 %1889, 36
  store i64 %1958, i64* %PC, align 8
  %1959 = inttoptr i64 %1957 to double*
  %1960 = load double, double* %1959, align 8
  %1961 = fsub double %1925, %1960
  store double %1961, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1962 = load i64, i64* %RBP, align 8
  %1963 = add i64 %1962, -144
  %1964 = add i64 %1889, 44
  store i64 %1964, i64* %PC, align 8
  %1965 = inttoptr i64 %1963 to double*
  store double %1961, double* %1965, align 8
  %1966 = load i64, i64* %RBP, align 8
  %1967 = add i64 %1966, -16
  %1968 = load i64, i64* %PC, align 8
  %1969 = add i64 %1968, 4
  store i64 %1969, i64* %PC, align 8
  %1970 = inttoptr i64 %1967 to i64*
  %1971 = load i64, i64* %1970, align 8
  store i64 %1971, i64* %RCX, align 8, !tbaa !2428
  %1972 = add i64 %1966, -36
  %1973 = add i64 %1968, 8
  store i64 %1973, i64* %PC, align 8
  %1974 = inttoptr i64 %1972 to i32*
  %1975 = load i32, i32* %1974, align 4
  %1976 = sext i32 %1975 to i64
  store i64 %1976, i64* %RDX, align 8, !tbaa !2428
  %1977 = shl nsw i64 %1976, 3
  %1978 = add i64 %1977, %1971
  %1979 = add i64 %1968, 13
  store i64 %1979, i64* %PC, align 8
  %1980 = inttoptr i64 %1978 to double*
  %1981 = load double, double* %1980, align 8
  store double %1981, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %1982 = add i64 %1968, 17
  store i64 %1982, i64* %PC, align 8
  %1983 = load i64, i64* %1970, align 8
  store i64 %1983, i64* %RCX, align 8, !tbaa !2428
  %1984 = add i64 %1966, -40
  %1985 = add i64 %1968, 21
  store i64 %1985, i64* %PC, align 8
  %1986 = inttoptr i64 %1984 to i32*
  %1987 = load i32, i32* %1986, align 4
  %1988 = sext i32 %1987 to i64
  store i64 %1988, i64* %RDX, align 8, !tbaa !2428
  %1989 = shl nsw i64 %1988, 3
  %1990 = add i64 %1989, %1983
  %1991 = add i64 %1968, 26
  store i64 %1991, i64* %PC, align 8
  %1992 = inttoptr i64 %1990 to double*
  %1993 = load double, double* %1992, align 8
  %1994 = fadd double %1981, %1993
  store double %1994, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %1995 = add i64 %1966, -152
  %1996 = add i64 %1968, 34
  store i64 %1996, i64* %PC, align 8
  %1997 = inttoptr i64 %1995 to double*
  store double %1994, double* %1997, align 8
  %1998 = load i64, i64* %RBP, align 8
  %1999 = add i64 %1998, -16
  %2000 = load i64, i64* %PC, align 8
  %2001 = add i64 %2000, 4
  store i64 %2001, i64* %PC, align 8
  %2002 = inttoptr i64 %1999 to i64*
  %2003 = load i64, i64* %2002, align 8
  store i64 %2003, i64* %RCX, align 8, !tbaa !2428
  %2004 = add i64 %1998, -36
  %2005 = add i64 %2000, 7
  store i64 %2005, i64* %PC, align 8
  %2006 = inttoptr i64 %2004 to i32*
  %2007 = load i32, i32* %2006, align 4
  %2008 = add i32 %2007, 1
  %2009 = zext i32 %2008 to i64
  store i64 %2009, i64* %RAX, align 8, !tbaa !2428
  %2010 = icmp eq i32 %2007, -1
  %2011 = icmp eq i32 %2008, 0
  %2012 = or i1 %2010, %2011
  %2013 = zext i1 %2012 to i8
  store i8 %2013, i8* %17, align 1, !tbaa !2433
  %2014 = and i32 %2008, 255
  %2015 = tail call i32 @llvm.ctpop.i32(i32 %2014) #10
  %2016 = trunc i32 %2015 to i8
  %2017 = and i8 %2016, 1
  %2018 = xor i8 %2017, 1
  store i8 %2018, i8* %24, align 1, !tbaa !2447
  %2019 = xor i32 %2007, %2008
  %2020 = lshr i32 %2019, 4
  %2021 = trunc i32 %2020 to i8
  %2022 = and i8 %2021, 1
  store i8 %2022, i8* %30, align 1, !tbaa !2451
  %2023 = zext i1 %2011 to i8
  store i8 %2023, i8* %33, align 1, !tbaa !2448
  %2024 = lshr i32 %2008, 31
  %2025 = trunc i32 %2024 to i8
  store i8 %2025, i8* %36, align 1, !tbaa !2449
  %2026 = lshr i32 %2007, 31
  %2027 = xor i32 %2024, %2026
  %2028 = add nuw nsw i32 %2027, %2024
  %2029 = icmp eq i32 %2028, 2
  %2030 = zext i1 %2029 to i8
  store i8 %2030, i8* %42, align 1, !tbaa !2450
  %2031 = sext i32 %2008 to i64
  store i64 %2031, i64* %RDX, align 8, !tbaa !2428
  %2032 = shl nsw i64 %2031, 3
  %2033 = add i64 %2032, %2003
  %2034 = add i64 %2000, 18
  store i64 %2034, i64* %PC, align 8
  %2035 = inttoptr i64 %2033 to double*
  %2036 = load double, double* %2035, align 8
  store double %2036, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2037 = add i64 %2000, 22
  store i64 %2037, i64* %PC, align 8
  %2038 = load i64, i64* %2002, align 8
  store i64 %2038, i64* %RCX, align 8, !tbaa !2428
  %2039 = add i64 %1998, -40
  %2040 = add i64 %2000, 25
  store i64 %2040, i64* %PC, align 8
  %2041 = inttoptr i64 %2039 to i32*
  %2042 = load i32, i32* %2041, align 4
  %2043 = add i32 %2042, 1
  %2044 = zext i32 %2043 to i64
  store i64 %2044, i64* %RAX, align 8, !tbaa !2428
  %2045 = icmp eq i32 %2042, -1
  %2046 = icmp eq i32 %2043, 0
  %2047 = or i1 %2045, %2046
  %2048 = zext i1 %2047 to i8
  store i8 %2048, i8* %17, align 1, !tbaa !2433
  %2049 = and i32 %2043, 255
  %2050 = tail call i32 @llvm.ctpop.i32(i32 %2049) #10
  %2051 = trunc i32 %2050 to i8
  %2052 = and i8 %2051, 1
  %2053 = xor i8 %2052, 1
  store i8 %2053, i8* %24, align 1, !tbaa !2447
  %2054 = xor i32 %2042, %2043
  %2055 = lshr i32 %2054, 4
  %2056 = trunc i32 %2055 to i8
  %2057 = and i8 %2056, 1
  store i8 %2057, i8* %30, align 1, !tbaa !2451
  %2058 = zext i1 %2046 to i8
  store i8 %2058, i8* %33, align 1, !tbaa !2448
  %2059 = lshr i32 %2043, 31
  %2060 = trunc i32 %2059 to i8
  store i8 %2060, i8* %36, align 1, !tbaa !2449
  %2061 = lshr i32 %2042, 31
  %2062 = xor i32 %2059, %2061
  %2063 = add nuw nsw i32 %2062, %2059
  %2064 = icmp eq i32 %2063, 2
  %2065 = zext i1 %2064 to i8
  store i8 %2065, i8* %42, align 1, !tbaa !2450
  %2066 = sext i32 %2043 to i64
  store i64 %2066, i64* %RDX, align 8, !tbaa !2428
  %2067 = shl nsw i64 %2066, 3
  %2068 = add i64 %2067, %2038
  %2069 = add i64 %2000, 36
  store i64 %2069, i64* %PC, align 8
  %2070 = inttoptr i64 %2068 to double*
  %2071 = load double, double* %2070, align 8
  %2072 = fadd double %2036, %2071
  store double %2072, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2073 = load i64, i64* %RBP, align 8
  %2074 = add i64 %2073, -160
  %2075 = add i64 %2000, 44
  store i64 %2075, i64* %PC, align 8
  %2076 = inttoptr i64 %2074 to double*
  store double %2072, double* %2076, align 8
  %2077 = load i64, i64* %RBP, align 8
  %2078 = add i64 %2077, -16
  %2079 = load i64, i64* %PC, align 8
  %2080 = add i64 %2079, 4
  store i64 %2080, i64* %PC, align 8
  %2081 = inttoptr i64 %2078 to i64*
  %2082 = load i64, i64* %2081, align 8
  store i64 %2082, i64* %RCX, align 8, !tbaa !2428
  %2083 = add i64 %2077, -36
  %2084 = add i64 %2079, 8
  store i64 %2084, i64* %PC, align 8
  %2085 = inttoptr i64 %2083 to i32*
  %2086 = load i32, i32* %2085, align 4
  %2087 = sext i32 %2086 to i64
  store i64 %2087, i64* %RDX, align 8, !tbaa !2428
  %2088 = shl nsw i64 %2087, 3
  %2089 = add i64 %2088, %2082
  %2090 = add i64 %2079, 13
  store i64 %2090, i64* %PC, align 8
  %2091 = inttoptr i64 %2089 to double*
  %2092 = load double, double* %2091, align 8
  store double %2092, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2093 = add i64 %2079, 17
  store i64 %2093, i64* %PC, align 8
  %2094 = load i64, i64* %2081, align 8
  store i64 %2094, i64* %RCX, align 8, !tbaa !2428
  %2095 = add i64 %2077, -40
  %2096 = add i64 %2079, 21
  store i64 %2096, i64* %PC, align 8
  %2097 = inttoptr i64 %2095 to i32*
  %2098 = load i32, i32* %2097, align 4
  %2099 = sext i32 %2098 to i64
  store i64 %2099, i64* %RDX, align 8, !tbaa !2428
  %2100 = shl nsw i64 %2099, 3
  %2101 = add i64 %2100, %2094
  %2102 = add i64 %2079, 26
  store i64 %2102, i64* %PC, align 8
  %2103 = inttoptr i64 %2101 to double*
  %2104 = load double, double* %2103, align 8
  %2105 = fsub double %2092, %2104
  store double %2105, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2106 = add i64 %2077, -168
  %2107 = add i64 %2079, 34
  store i64 %2107, i64* %PC, align 8
  %2108 = inttoptr i64 %2106 to double*
  store double %2105, double* %2108, align 8
  %2109 = load i64, i64* %RBP, align 8
  %2110 = add i64 %2109, -16
  %2111 = load i64, i64* %PC, align 8
  %2112 = add i64 %2111, 4
  store i64 %2112, i64* %PC, align 8
  %2113 = inttoptr i64 %2110 to i64*
  %2114 = load i64, i64* %2113, align 8
  store i64 %2114, i64* %RCX, align 8, !tbaa !2428
  %2115 = add i64 %2109, -36
  %2116 = add i64 %2111, 7
  store i64 %2116, i64* %PC, align 8
  %2117 = inttoptr i64 %2115 to i32*
  %2118 = load i32, i32* %2117, align 4
  %2119 = add i32 %2118, 1
  %2120 = zext i32 %2119 to i64
  store i64 %2120, i64* %RAX, align 8, !tbaa !2428
  %2121 = icmp eq i32 %2118, -1
  %2122 = icmp eq i32 %2119, 0
  %2123 = or i1 %2121, %2122
  %2124 = zext i1 %2123 to i8
  store i8 %2124, i8* %17, align 1, !tbaa !2433
  %2125 = and i32 %2119, 255
  %2126 = tail call i32 @llvm.ctpop.i32(i32 %2125) #10
  %2127 = trunc i32 %2126 to i8
  %2128 = and i8 %2127, 1
  %2129 = xor i8 %2128, 1
  store i8 %2129, i8* %24, align 1, !tbaa !2447
  %2130 = xor i32 %2118, %2119
  %2131 = lshr i32 %2130, 4
  %2132 = trunc i32 %2131 to i8
  %2133 = and i8 %2132, 1
  store i8 %2133, i8* %30, align 1, !tbaa !2451
  %2134 = zext i1 %2122 to i8
  store i8 %2134, i8* %33, align 1, !tbaa !2448
  %2135 = lshr i32 %2119, 31
  %2136 = trunc i32 %2135 to i8
  store i8 %2136, i8* %36, align 1, !tbaa !2449
  %2137 = lshr i32 %2118, 31
  %2138 = xor i32 %2135, %2137
  %2139 = add nuw nsw i32 %2138, %2135
  %2140 = icmp eq i32 %2139, 2
  %2141 = zext i1 %2140 to i8
  store i8 %2141, i8* %42, align 1, !tbaa !2450
  %2142 = sext i32 %2119 to i64
  store i64 %2142, i64* %RDX, align 8, !tbaa !2428
  %2143 = shl nsw i64 %2142, 3
  %2144 = add i64 %2143, %2114
  %2145 = add i64 %2111, 18
  store i64 %2145, i64* %PC, align 8
  %2146 = inttoptr i64 %2144 to double*
  %2147 = load double, double* %2146, align 8
  store double %2147, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2148 = add i64 %2111, 22
  store i64 %2148, i64* %PC, align 8
  %2149 = load i64, i64* %2113, align 8
  store i64 %2149, i64* %RCX, align 8, !tbaa !2428
  %2150 = add i64 %2109, -40
  %2151 = add i64 %2111, 25
  store i64 %2151, i64* %PC, align 8
  %2152 = inttoptr i64 %2150 to i32*
  %2153 = load i32, i32* %2152, align 4
  %2154 = add i32 %2153, 1
  %2155 = zext i32 %2154 to i64
  store i64 %2155, i64* %RAX, align 8, !tbaa !2428
  %2156 = icmp eq i32 %2153, -1
  %2157 = icmp eq i32 %2154, 0
  %2158 = or i1 %2156, %2157
  %2159 = zext i1 %2158 to i8
  store i8 %2159, i8* %17, align 1, !tbaa !2433
  %2160 = and i32 %2154, 255
  %2161 = tail call i32 @llvm.ctpop.i32(i32 %2160) #10
  %2162 = trunc i32 %2161 to i8
  %2163 = and i8 %2162, 1
  %2164 = xor i8 %2163, 1
  store i8 %2164, i8* %24, align 1, !tbaa !2447
  %2165 = xor i32 %2153, %2154
  %2166 = lshr i32 %2165, 4
  %2167 = trunc i32 %2166 to i8
  %2168 = and i8 %2167, 1
  store i8 %2168, i8* %30, align 1, !tbaa !2451
  %2169 = zext i1 %2157 to i8
  store i8 %2169, i8* %33, align 1, !tbaa !2448
  %2170 = lshr i32 %2154, 31
  %2171 = trunc i32 %2170 to i8
  store i8 %2171, i8* %36, align 1, !tbaa !2449
  %2172 = lshr i32 %2153, 31
  %2173 = xor i32 %2170, %2172
  %2174 = add nuw nsw i32 %2173, %2170
  %2175 = icmp eq i32 %2174, 2
  %2176 = zext i1 %2175 to i8
  store i8 %2176, i8* %42, align 1, !tbaa !2450
  %2177 = sext i32 %2154 to i64
  store i64 %2177, i64* %RDX, align 8, !tbaa !2428
  %2178 = shl nsw i64 %2177, 3
  %2179 = add i64 %2178, %2149
  %2180 = add i64 %2111, 36
  store i64 %2180, i64* %PC, align 8
  %2181 = inttoptr i64 %2179 to double*
  %2182 = load double, double* %2181, align 8
  %2183 = fsub double %2147, %2182
  store double %2183, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2184 = load i64, i64* %RBP, align 8
  %2185 = add i64 %2184, -176
  %2186 = add i64 %2111, 44
  store i64 %2186, i64* %PC, align 8
  %2187 = inttoptr i64 %2185 to double*
  store double %2183, double* %2187, align 8
  %2188 = load i64, i64* %RBP, align 8
  %2189 = add i64 %2188, -120
  %2190 = load i64, i64* %PC, align 8
  %2191 = add i64 %2190, 5
  store i64 %2191, i64* %PC, align 8
  %2192 = inttoptr i64 %2189 to double*
  %2193 = load double, double* %2192, align 8
  store double %2193, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2194 = add i64 %2188, -152
  %2195 = add i64 %2190, 13
  store i64 %2195, i64* %PC, align 8
  %2196 = inttoptr i64 %2194 to double*
  %2197 = load double, double* %2196, align 8
  %2198 = fadd double %2193, %2197
  store double %2198, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2199 = add i64 %2188, -16
  %2200 = add i64 %2190, 17
  store i64 %2200, i64* %PC, align 8
  %2201 = inttoptr i64 %2199 to i64*
  %2202 = load i64, i64* %2201, align 8
  store i64 %2202, i64* %RCX, align 8, !tbaa !2428
  %2203 = add i64 %2188, -28
  %2204 = add i64 %2190, 21
  store i64 %2204, i64* %PC, align 8
  %2205 = inttoptr i64 %2203 to i32*
  %2206 = load i32, i32* %2205, align 4
  %2207 = sext i32 %2206 to i64
  store i64 %2207, i64* %RDX, align 8, !tbaa !2428
  %2208 = shl nsw i64 %2207, 3
  %2209 = add i64 %2208, %2202
  %2210 = add i64 %2190, 26
  store i64 %2210, i64* %PC, align 8
  %2211 = inttoptr i64 %2209 to double*
  store double %2198, double* %2211, align 8
  %2212 = load i64, i64* %RBP, align 8
  %2213 = add i64 %2212, -128
  %2214 = load i64, i64* %PC, align 8
  %2215 = add i64 %2214, 5
  store i64 %2215, i64* %PC, align 8
  %2216 = inttoptr i64 %2213 to double*
  %2217 = load double, double* %2216, align 8
  store double %2217, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2218 = add i64 %2212, -160
  %2219 = add i64 %2214, 13
  store i64 %2219, i64* %PC, align 8
  %2220 = inttoptr i64 %2218 to double*
  %2221 = load double, double* %2220, align 8
  %2222 = fadd double %2217, %2221
  store double %2222, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2223 = add i64 %2212, -16
  %2224 = add i64 %2214, 17
  store i64 %2224, i64* %PC, align 8
  %2225 = inttoptr i64 %2223 to i64*
  %2226 = load i64, i64* %2225, align 8
  store i64 %2226, i64* %RCX, align 8, !tbaa !2428
  %2227 = add i64 %2212, -28
  %2228 = add i64 %2214, 20
  store i64 %2228, i64* %PC, align 8
  %2229 = inttoptr i64 %2227 to i32*
  %2230 = load i32, i32* %2229, align 4
  %2231 = add i32 %2230, 1
  %2232 = zext i32 %2231 to i64
  store i64 %2232, i64* %RAX, align 8, !tbaa !2428
  %2233 = icmp eq i32 %2230, -1
  %2234 = icmp eq i32 %2231, 0
  %2235 = or i1 %2233, %2234
  %2236 = zext i1 %2235 to i8
  store i8 %2236, i8* %17, align 1, !tbaa !2433
  %2237 = and i32 %2231, 255
  %2238 = tail call i32 @llvm.ctpop.i32(i32 %2237) #10
  %2239 = trunc i32 %2238 to i8
  %2240 = and i8 %2239, 1
  %2241 = xor i8 %2240, 1
  store i8 %2241, i8* %24, align 1, !tbaa !2447
  %2242 = xor i32 %2230, %2231
  %2243 = lshr i32 %2242, 4
  %2244 = trunc i32 %2243 to i8
  %2245 = and i8 %2244, 1
  store i8 %2245, i8* %30, align 1, !tbaa !2451
  %2246 = zext i1 %2234 to i8
  store i8 %2246, i8* %33, align 1, !tbaa !2448
  %2247 = lshr i32 %2231, 31
  %2248 = trunc i32 %2247 to i8
  store i8 %2248, i8* %36, align 1, !tbaa !2449
  %2249 = lshr i32 %2230, 31
  %2250 = xor i32 %2247, %2249
  %2251 = add nuw nsw i32 %2250, %2247
  %2252 = icmp eq i32 %2251, 2
  %2253 = zext i1 %2252 to i8
  store i8 %2253, i8* %42, align 1, !tbaa !2450
  %2254 = sext i32 %2231 to i64
  store i64 %2254, i64* %RDX, align 8, !tbaa !2428
  %2255 = shl nsw i64 %2254, 3
  %2256 = add i64 %2255, %2226
  %2257 = add i64 %2214, 31
  store i64 %2257, i64* %PC, align 8
  %2258 = inttoptr i64 %2256 to double*
  store double %2222, double* %2258, align 8
  %2259 = load i64, i64* %RBP, align 8
  %2260 = add i64 %2259, -160
  %2261 = load i64, i64* %PC, align 8
  %2262 = add i64 %2261, 8
  store i64 %2262, i64* %PC, align 8
  %2263 = inttoptr i64 %2260 to double*
  %2264 = load double, double* %2263, align 8
  store double %2264, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2265 = add i64 %2259, -128
  %2266 = add i64 %2261, 13
  store i64 %2266, i64* %PC, align 8
  %2267 = inttoptr i64 %2265 to double*
  %2268 = load double, double* %2267, align 8
  %2269 = fsub double %2264, %2268
  store double %2269, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2270 = add i64 %2259, -16
  %2271 = add i64 %2261, 17
  store i64 %2271, i64* %PC, align 8
  %2272 = inttoptr i64 %2270 to i64*
  %2273 = load i64, i64* %2272, align 8
  store i64 %2273, i64* %RCX, align 8, !tbaa !2428
  %2274 = add i64 %2259, -36
  %2275 = add i64 %2261, 21
  store i64 %2275, i64* %PC, align 8
  %2276 = inttoptr i64 %2274 to i32*
  %2277 = load i32, i32* %2276, align 4
  %2278 = sext i32 %2277 to i64
  store i64 %2278, i64* %RDX, align 8, !tbaa !2428
  %2279 = shl nsw i64 %2278, 3
  %2280 = add i64 %2279, %2273
  %2281 = add i64 %2261, 26
  store i64 %2281, i64* %PC, align 8
  %2282 = inttoptr i64 %2280 to double*
  store double %2269, double* %2282, align 8
  %2283 = load i64, i64* %RBP, align 8
  %2284 = add i64 %2283, -120
  %2285 = load i64, i64* %PC, align 8
  %2286 = add i64 %2285, 5
  store i64 %2286, i64* %PC, align 8
  %2287 = inttoptr i64 %2284 to double*
  %2288 = load double, double* %2287, align 8
  store double %2288, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2289 = add i64 %2283, -152
  %2290 = add i64 %2285, 13
  store i64 %2290, i64* %PC, align 8
  %2291 = inttoptr i64 %2289 to double*
  %2292 = load double, double* %2291, align 8
  %2293 = fsub double %2288, %2292
  store double %2293, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2294 = add i64 %2283, -16
  %2295 = add i64 %2285, 17
  store i64 %2295, i64* %PC, align 8
  %2296 = inttoptr i64 %2294 to i64*
  %2297 = load i64, i64* %2296, align 8
  store i64 %2297, i64* %RCX, align 8, !tbaa !2428
  %2298 = add i64 %2283, -36
  %2299 = add i64 %2285, 20
  store i64 %2299, i64* %PC, align 8
  %2300 = inttoptr i64 %2298 to i32*
  %2301 = load i32, i32* %2300, align 4
  %2302 = add i32 %2301, 1
  %2303 = zext i32 %2302 to i64
  store i64 %2303, i64* %RAX, align 8, !tbaa !2428
  %2304 = icmp eq i32 %2301, -1
  %2305 = icmp eq i32 %2302, 0
  %2306 = or i1 %2304, %2305
  %2307 = zext i1 %2306 to i8
  store i8 %2307, i8* %17, align 1, !tbaa !2433
  %2308 = and i32 %2302, 255
  %2309 = tail call i32 @llvm.ctpop.i32(i32 %2308) #10
  %2310 = trunc i32 %2309 to i8
  %2311 = and i8 %2310, 1
  %2312 = xor i8 %2311, 1
  store i8 %2312, i8* %24, align 1, !tbaa !2447
  %2313 = xor i32 %2301, %2302
  %2314 = lshr i32 %2313, 4
  %2315 = trunc i32 %2314 to i8
  %2316 = and i8 %2315, 1
  store i8 %2316, i8* %30, align 1, !tbaa !2451
  %2317 = zext i1 %2305 to i8
  store i8 %2317, i8* %33, align 1, !tbaa !2448
  %2318 = lshr i32 %2302, 31
  %2319 = trunc i32 %2318 to i8
  store i8 %2319, i8* %36, align 1, !tbaa !2449
  %2320 = lshr i32 %2301, 31
  %2321 = xor i32 %2318, %2320
  %2322 = add nuw nsw i32 %2321, %2318
  %2323 = icmp eq i32 %2322, 2
  %2324 = zext i1 %2323 to i8
  store i8 %2324, i8* %42, align 1, !tbaa !2450
  %2325 = sext i32 %2302 to i64
  store i64 %2325, i64* %RDX, align 8, !tbaa !2428
  %2326 = shl nsw i64 %2325, 3
  %2327 = add i64 %2326, %2297
  %2328 = add i64 %2285, 31
  store i64 %2328, i64* %PC, align 8
  %2329 = inttoptr i64 %2327 to double*
  store double %2293, double* %2329, align 8
  %2330 = load i64, i64* %RBP, align 8
  %2331 = add i64 %2330, -136
  %2332 = load i64, i64* %PC, align 8
  %2333 = add i64 %2332, 8
  store i64 %2333, i64* %PC, align 8
  %2334 = inttoptr i64 %2331 to double*
  %2335 = load double, double* %2334, align 8
  store double %2335, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2336 = add i64 %2330, -176
  %2337 = add i64 %2332, 16
  store i64 %2337, i64* %PC, align 8
  %2338 = inttoptr i64 %2336 to double*
  %2339 = load double, double* %2338, align 8
  %2340 = fsub double %2335, %2339
  store double %2340, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2341 = add i64 %2330, -120
  %2342 = add i64 %2332, 21
  store i64 %2342, i64* %PC, align 8
  %2343 = inttoptr i64 %2341 to double*
  store double %2340, double* %2343, align 8
  %2344 = load i64, i64* %RBP, align 8
  %2345 = add i64 %2344, -144
  %2346 = load i64, i64* %PC, align 8
  %2347 = add i64 %2346, 8
  store i64 %2347, i64* %PC, align 8
  %2348 = inttoptr i64 %2345 to double*
  %2349 = load double, double* %2348, align 8
  store double %2349, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2350 = add i64 %2344, -168
  %2351 = add i64 %2346, 16
  store i64 %2351, i64* %PC, align 8
  %2352 = inttoptr i64 %2350 to double*
  %2353 = load double, double* %2352, align 8
  %2354 = fadd double %2349, %2353
  store double %2354, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2355 = add i64 %2344, -128
  %2356 = add i64 %2346, 21
  store i64 %2356, i64* %PC, align 8
  %2357 = inttoptr i64 %2355 to double*
  store double %2354, double* %2357, align 8
  %2358 = load i64, i64* %RBP, align 8
  %2359 = add i64 %2358, -72
  %2360 = load i64, i64* %PC, align 8
  %2361 = add i64 %2360, 5
  store i64 %2361, i64* %PC, align 8
  %2362 = inttoptr i64 %2359 to double*
  %2363 = load double, double* %2362, align 8
  store double %2363, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2364 = add i64 %2358, -120
  %2365 = add i64 %2360, 10
  store i64 %2365, i64* %PC, align 8
  %2366 = inttoptr i64 %2364 to double*
  %2367 = load double, double* %2366, align 8
  store double %2367, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %2368 = add i64 %2358, -128
  %2369 = add i64 %2360, 15
  store i64 %2369, i64* %PC, align 8
  %2370 = inttoptr i64 %2368 to double*
  %2371 = load double, double* %2370, align 8
  %2372 = fsub double %2367, %2371
  store double %2372, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %2373 = fmul double %2363, %2372
  store double %2373, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2374 = add i64 %2358, -16
  %2375 = add i64 %2360, 23
  store i64 %2375, i64* %PC, align 8
  %2376 = inttoptr i64 %2374 to i64*
  %2377 = load i64, i64* %2376, align 8
  store i64 %2377, i64* %RCX, align 8, !tbaa !2428
  %2378 = add i64 %2358, -32
  %2379 = add i64 %2360, 27
  store i64 %2379, i64* %PC, align 8
  %2380 = inttoptr i64 %2378 to i32*
  %2381 = load i32, i32* %2380, align 4
  %2382 = sext i32 %2381 to i64
  store i64 %2382, i64* %RDX, align 8, !tbaa !2428
  %2383 = shl nsw i64 %2382, 3
  %2384 = add i64 %2383, %2377
  %2385 = add i64 %2360, 32
  store i64 %2385, i64* %PC, align 8
  %2386 = inttoptr i64 %2384 to double*
  store double %2373, double* %2386, align 8
  %2387 = load i64, i64* %RBP, align 8
  %2388 = add i64 %2387, -72
  %2389 = load i64, i64* %PC, align 8
  %2390 = add i64 %2389, 5
  store i64 %2390, i64* %PC, align 8
  %2391 = inttoptr i64 %2388 to double*
  %2392 = load double, double* %2391, align 8
  store double %2392, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2393 = add i64 %2387, -120
  %2394 = add i64 %2389, 10
  store i64 %2394, i64* %PC, align 8
  %2395 = inttoptr i64 %2393 to double*
  %2396 = load double, double* %2395, align 8
  store double %2396, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %2397 = add i64 %2387, -128
  %2398 = add i64 %2389, 15
  store i64 %2398, i64* %PC, align 8
  %2399 = inttoptr i64 %2397 to double*
  %2400 = load double, double* %2399, align 8
  %2401 = fadd double %2396, %2400
  store double %2401, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %2402 = fmul double %2392, %2401
  store double %2402, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2403 = add i64 %2387, -16
  %2404 = add i64 %2389, 23
  store i64 %2404, i64* %PC, align 8
  %2405 = inttoptr i64 %2403 to i64*
  %2406 = load i64, i64* %2405, align 8
  store i64 %2406, i64* %RCX, align 8, !tbaa !2428
  %2407 = add i64 %2387, -32
  %2408 = add i64 %2389, 26
  store i64 %2408, i64* %PC, align 8
  %2409 = inttoptr i64 %2407 to i32*
  %2410 = load i32, i32* %2409, align 4
  %2411 = add i32 %2410, 1
  %2412 = zext i32 %2411 to i64
  store i64 %2412, i64* %RAX, align 8, !tbaa !2428
  %2413 = icmp eq i32 %2410, -1
  %2414 = icmp eq i32 %2411, 0
  %2415 = or i1 %2413, %2414
  %2416 = zext i1 %2415 to i8
  store i8 %2416, i8* %17, align 1, !tbaa !2433
  %2417 = and i32 %2411, 255
  %2418 = tail call i32 @llvm.ctpop.i32(i32 %2417) #10
  %2419 = trunc i32 %2418 to i8
  %2420 = and i8 %2419, 1
  %2421 = xor i8 %2420, 1
  store i8 %2421, i8* %24, align 1, !tbaa !2447
  %2422 = xor i32 %2410, %2411
  %2423 = lshr i32 %2422, 4
  %2424 = trunc i32 %2423 to i8
  %2425 = and i8 %2424, 1
  store i8 %2425, i8* %30, align 1, !tbaa !2451
  %2426 = zext i1 %2414 to i8
  store i8 %2426, i8* %33, align 1, !tbaa !2448
  %2427 = lshr i32 %2411, 31
  %2428 = trunc i32 %2427 to i8
  store i8 %2428, i8* %36, align 1, !tbaa !2449
  %2429 = lshr i32 %2410, 31
  %2430 = xor i32 %2427, %2429
  %2431 = add nuw nsw i32 %2430, %2427
  %2432 = icmp eq i32 %2431, 2
  %2433 = zext i1 %2432 to i8
  store i8 %2433, i8* %42, align 1, !tbaa !2450
  %2434 = sext i32 %2411 to i64
  store i64 %2434, i64* %RDX, align 8, !tbaa !2428
  %2435 = shl nsw i64 %2434, 3
  %2436 = add i64 %2435, %2406
  %2437 = add i64 %2389, 37
  store i64 %2437, i64* %PC, align 8
  %2438 = inttoptr i64 %2436 to double*
  store double %2402, double* %2438, align 8
  %2439 = load i64, i64* %RBP, align 8
  %2440 = add i64 %2439, -176
  %2441 = load i64, i64* %PC, align 8
  %2442 = add i64 %2441, 8
  store i64 %2442, i64* %PC, align 8
  %2443 = inttoptr i64 %2440 to double*
  %2444 = load double, double* %2443, align 8
  store double %2444, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2445 = add i64 %2439, -136
  %2446 = add i64 %2441, 16
  store i64 %2446, i64* %PC, align 8
  %2447 = inttoptr i64 %2445 to double*
  %2448 = load double, double* %2447, align 8
  %2449 = fadd double %2444, %2448
  store double %2449, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2450 = add i64 %2439, -120
  %2451 = add i64 %2441, 21
  store i64 %2451, i64* %PC, align 8
  %2452 = inttoptr i64 %2450 to double*
  store double %2449, double* %2452, align 8
  %2453 = load i64, i64* %RBP, align 8
  %2454 = add i64 %2453, -168
  %2455 = load i64, i64* %PC, align 8
  %2456 = add i64 %2455, 8
  store i64 %2456, i64* %PC, align 8
  %2457 = inttoptr i64 %2454 to double*
  %2458 = load double, double* %2457, align 8
  store double %2458, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2459 = add i64 %2453, -144
  %2460 = add i64 %2455, 16
  store i64 %2460, i64* %PC, align 8
  %2461 = inttoptr i64 %2459 to double*
  %2462 = load double, double* %2461, align 8
  %2463 = fsub double %2458, %2462
  store double %2463, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2464 = add i64 %2453, -128
  %2465 = add i64 %2455, 21
  store i64 %2465, i64* %PC, align 8
  %2466 = inttoptr i64 %2464 to double*
  store double %2463, double* %2466, align 8
  %2467 = load i64, i64* %RBP, align 8
  %2468 = add i64 %2467, -72
  %2469 = load i64, i64* %PC, align 8
  %2470 = add i64 %2469, 5
  store i64 %2470, i64* %PC, align 8
  %2471 = inttoptr i64 %2468 to double*
  %2472 = load double, double* %2471, align 8
  store double %2472, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2473 = add i64 %2467, -128
  %2474 = add i64 %2469, 10
  store i64 %2474, i64* %PC, align 8
  %2475 = inttoptr i64 %2473 to double*
  %2476 = load double, double* %2475, align 8
  store double %2476, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %2477 = add i64 %2467, -120
  %2478 = add i64 %2469, 15
  store i64 %2478, i64* %PC, align 8
  %2479 = inttoptr i64 %2477 to double*
  %2480 = load double, double* %2479, align 8
  %2481 = fsub double %2476, %2480
  store double %2481, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %2482 = fmul double %2472, %2481
  store double %2482, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2483 = add i64 %2467, -16
  %2484 = add i64 %2469, 23
  store i64 %2484, i64* %PC, align 8
  %2485 = inttoptr i64 %2483 to i64*
  %2486 = load i64, i64* %2485, align 8
  store i64 %2486, i64* %RCX, align 8, !tbaa !2428
  %2487 = add i64 %2467, -40
  %2488 = add i64 %2469, 27
  store i64 %2488, i64* %PC, align 8
  %2489 = inttoptr i64 %2487 to i32*
  %2490 = load i32, i32* %2489, align 4
  %2491 = sext i32 %2490 to i64
  store i64 %2491, i64* %RDX, align 8, !tbaa !2428
  %2492 = shl nsw i64 %2491, 3
  %2493 = add i64 %2492, %2486
  %2494 = add i64 %2469, 32
  store i64 %2494, i64* %PC, align 8
  %2495 = inttoptr i64 %2493 to double*
  store double %2482, double* %2495, align 8
  %2496 = load i64, i64* %RBP, align 8
  %2497 = add i64 %2496, -72
  %2498 = load i64, i64* %PC, align 8
  %2499 = add i64 %2498, 5
  store i64 %2499, i64* %PC, align 8
  %2500 = inttoptr i64 %2497 to double*
  %2501 = load double, double* %2500, align 8
  store double %2501, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2502 = add i64 %2496, -128
  %2503 = add i64 %2498, 10
  store i64 %2503, i64* %PC, align 8
  %2504 = inttoptr i64 %2502 to double*
  %2505 = load double, double* %2504, align 8
  store double %2505, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %2506 = add i64 %2496, -120
  %2507 = add i64 %2498, 15
  store i64 %2507, i64* %PC, align 8
  %2508 = inttoptr i64 %2506 to double*
  %2509 = load double, double* %2508, align 8
  %2510 = fadd double %2505, %2509
  store double %2510, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %2511 = fmul double %2501, %2510
  store double %2511, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2512 = add i64 %2496, -16
  %2513 = add i64 %2498, 23
  store i64 %2513, i64* %PC, align 8
  %2514 = inttoptr i64 %2512 to i64*
  %2515 = load i64, i64* %2514, align 8
  store i64 %2515, i64* %RCX, align 8, !tbaa !2428
  %2516 = add i64 %2496, -40
  %2517 = add i64 %2498, 26
  store i64 %2517, i64* %PC, align 8
  %2518 = inttoptr i64 %2516 to i32*
  %2519 = load i32, i32* %2518, align 4
  %2520 = add i32 %2519, 1
  %2521 = zext i32 %2520 to i64
  store i64 %2521, i64* %RAX, align 8, !tbaa !2428
  %2522 = icmp eq i32 %2519, -1
  %2523 = icmp eq i32 %2520, 0
  %2524 = or i1 %2522, %2523
  %2525 = zext i1 %2524 to i8
  store i8 %2525, i8* %17, align 1, !tbaa !2433
  %2526 = and i32 %2520, 255
  %2527 = tail call i32 @llvm.ctpop.i32(i32 %2526) #10
  %2528 = trunc i32 %2527 to i8
  %2529 = and i8 %2528, 1
  %2530 = xor i8 %2529, 1
  store i8 %2530, i8* %24, align 1, !tbaa !2447
  %2531 = xor i32 %2519, %2520
  %2532 = lshr i32 %2531, 4
  %2533 = trunc i32 %2532 to i8
  %2534 = and i8 %2533, 1
  store i8 %2534, i8* %30, align 1, !tbaa !2451
  %2535 = zext i1 %2523 to i8
  store i8 %2535, i8* %33, align 1, !tbaa !2448
  %2536 = lshr i32 %2520, 31
  %2537 = trunc i32 %2536 to i8
  store i8 %2537, i8* %36, align 1, !tbaa !2449
  %2538 = lshr i32 %2519, 31
  %2539 = xor i32 %2536, %2538
  %2540 = add nuw nsw i32 %2539, %2536
  %2541 = icmp eq i32 %2540, 2
  %2542 = zext i1 %2541 to i8
  store i8 %2542, i8* %42, align 1, !tbaa !2450
  %2543 = sext i32 %2520 to i64
  store i64 %2543, i64* %RDX, align 8, !tbaa !2428
  %2544 = shl nsw i64 %2543, 3
  %2545 = add i64 %2544, %2515
  %2546 = add i64 %2498, 37
  store i64 %2546, i64* %PC, align 8
  %2547 = inttoptr i64 %2545 to double*
  store double %2511, double* %2547, align 8
  %2548 = load i64, i64* %RBP, align 8
  %2549 = add i64 %2548, -28
  %2550 = load i64, i64* %PC, align 8
  %2551 = add i64 %2550, 3
  store i64 %2551, i64* %PC, align 8
  %2552 = inttoptr i64 %2549 to i32*
  %2553 = load i32, i32* %2552, align 4
  %2554 = add i32 %2553, 2
  %2555 = zext i32 %2554 to i64
  store i64 %2555, i64* %RAX, align 8, !tbaa !2428
  %2556 = icmp ugt i32 %2553, -3
  %2557 = zext i1 %2556 to i8
  store i8 %2557, i8* %17, align 1, !tbaa !2433
  %2558 = and i32 %2554, 255
  %2559 = tail call i32 @llvm.ctpop.i32(i32 %2558) #10
  %2560 = trunc i32 %2559 to i8
  %2561 = and i8 %2560, 1
  %2562 = xor i8 %2561, 1
  store i8 %2562, i8* %24, align 1, !tbaa !2447
  %2563 = xor i32 %2553, %2554
  %2564 = lshr i32 %2563, 4
  %2565 = trunc i32 %2564 to i8
  %2566 = and i8 %2565, 1
  store i8 %2566, i8* %30, align 1, !tbaa !2451
  %2567 = icmp eq i32 %2554, 0
  %2568 = zext i1 %2567 to i8
  store i8 %2568, i8* %33, align 1, !tbaa !2448
  %2569 = lshr i32 %2554, 31
  %2570 = trunc i32 %2569 to i8
  store i8 %2570, i8* %36, align 1, !tbaa !2449
  %2571 = lshr i32 %2553, 31
  %2572 = xor i32 %2569, %2571
  %2573 = add nuw nsw i32 %2572, %2569
  %2574 = icmp eq i32 %2573, 2
  %2575 = zext i1 %2574 to i8
  store i8 %2575, i8* %42, align 1, !tbaa !2450
  %2576 = add i64 %2550, 9
  store i64 %2576, i64* %PC, align 8
  store i32 %2554, i32* %2552, align 4
  %2577 = load i64, i64* %PC, align 8
  %2578 = add i64 %2577, -695
  store i64 %2578, i64* %PC, align 8, !tbaa !2428
  br label %block_403591

block_403591:                                     ; preds = %block_4035a2, %block_40357d
  %2579 = phi i64 [ %2578, %block_4035a2 ], [ %.pre3, %block_40357d ]
  %2580 = load i64, i64* %RBP, align 8
  %2581 = add i64 %2580, -28
  %2582 = add i64 %2579, 3
  store i64 %2582, i64* %PC, align 8
  %2583 = inttoptr i64 %2581 to i32*
  %2584 = load i32, i32* %2583, align 4
  %2585 = zext i32 %2584 to i64
  store i64 %2585, i64* %RAX, align 8, !tbaa !2428
  %2586 = add i64 %2580, -8
  %2587 = add i64 %2579, 6
  store i64 %2587, i64* %PC, align 8
  %2588 = inttoptr i64 %2586 to i32*
  %2589 = load i32, i32* %2588, align 4
  %2590 = zext i32 %2589 to i64
  store i64 %2590, i64* %RCX, align 8, !tbaa !2428
  %2591 = add i64 %2580, -56
  %2592 = add i64 %2579, 9
  store i64 %2592, i64* %PC, align 8
  %2593 = inttoptr i64 %2591 to i32*
  %2594 = load i32, i32* %2593, align 4
  %2595 = add i32 %2594, %2589
  %2596 = zext i32 %2595 to i64
  store i64 %2596, i64* %RCX, align 8, !tbaa !2428
  %2597 = lshr i32 %2595, 31
  %2598 = sub i32 %2584, %2595
  %2599 = icmp ult i32 %2584, %2595
  %2600 = zext i1 %2599 to i8
  store i8 %2600, i8* %17, align 1, !tbaa !2433
  %2601 = and i32 %2598, 255
  %2602 = tail call i32 @llvm.ctpop.i32(i32 %2601) #10
  %2603 = trunc i32 %2602 to i8
  %2604 = and i8 %2603, 1
  %2605 = xor i8 %2604, 1
  store i8 %2605, i8* %24, align 1, !tbaa !2447
  %2606 = xor i32 %2595, %2584
  %2607 = xor i32 %2606, %2598
  %2608 = lshr i32 %2607, 4
  %2609 = trunc i32 %2608 to i8
  %2610 = and i8 %2609, 1
  store i8 %2610, i8* %30, align 1, !tbaa !2451
  %2611 = icmp eq i32 %2598, 0
  %2612 = zext i1 %2611 to i8
  store i8 %2612, i8* %33, align 1, !tbaa !2448
  %2613 = lshr i32 %2598, 31
  %2614 = trunc i32 %2613 to i8
  store i8 %2614, i8* %36, align 1, !tbaa !2449
  %2615 = lshr i32 %2584, 31
  %2616 = xor i32 %2597, %2615
  %2617 = xor i32 %2613, %2615
  %2618 = add nuw nsw i32 %2617, %2616
  %2619 = icmp eq i32 %2618, 2
  %2620 = zext i1 %2619 to i8
  store i8 %2620, i8* %42, align 1, !tbaa !2450
  %2621 = icmp ne i8 %2614, 0
  %2622 = xor i1 %2621, %2619
  %.v7 = select i1 %2622, i64 17, i64 700
  %2623 = add i64 %2579, %.v7
  store i64 %2623, i64* %PC, align 8, !tbaa !2428
  %2624 = load i64, i64* %RBP, align 8
  br i1 %2622, label %block_4035a2, label %block_40384d

block_403863:                                     ; preds = %block_403fcb, %block_40384d
  %2625 = phi i64 [ %1525, %block_403fcb ], [ %.pre4, %block_40384d ]
  %2626 = load i64, i64* %RBP, align 8
  %2627 = add i64 %2626, -44
  %2628 = add i64 %2625, 3
  store i64 %2628, i64* %PC, align 8
  %2629 = inttoptr i64 %2627 to i32*
  %2630 = load i32, i32* %2629, align 4
  %2631 = zext i32 %2630 to i64
  store i64 %2631, i64* %RAX, align 8, !tbaa !2428
  %2632 = add i64 %2626, -4
  %2633 = add i64 %2625, 6
  store i64 %2633, i64* %PC, align 8
  %2634 = inttoptr i64 %2632 to i32*
  %2635 = load i32, i32* %2634, align 4
  %2636 = sub i32 %2630, %2635
  %2637 = icmp ult i32 %2630, %2635
  %2638 = zext i1 %2637 to i8
  store i8 %2638, i8* %17, align 1, !tbaa !2433
  %2639 = and i32 %2636, 255
  %2640 = tail call i32 @llvm.ctpop.i32(i32 %2639) #10
  %2641 = trunc i32 %2640 to i8
  %2642 = and i8 %2641, 1
  %2643 = xor i8 %2642, 1
  store i8 %2643, i8* %24, align 1, !tbaa !2447
  %2644 = xor i32 %2635, %2630
  %2645 = xor i32 %2644, %2636
  %2646 = lshr i32 %2645, 4
  %2647 = trunc i32 %2646 to i8
  %2648 = and i8 %2647, 1
  store i8 %2648, i8* %30, align 1, !tbaa !2451
  %2649 = icmp eq i32 %2636, 0
  %2650 = zext i1 %2649 to i8
  store i8 %2650, i8* %33, align 1, !tbaa !2448
  %2651 = lshr i32 %2636, 31
  %2652 = trunc i32 %2651 to i8
  store i8 %2652, i8* %36, align 1, !tbaa !2449
  %2653 = lshr i32 %2630, 31
  %2654 = lshr i32 %2635, 31
  %2655 = xor i32 %2654, %2653
  %2656 = xor i32 %2651, %2653
  %2657 = add nuw nsw i32 %2656, %2655
  %2658 = icmp eq i32 %2657, 2
  %2659 = zext i1 %2658 to i8
  store i8 %2659, i8* %42, align 1, !tbaa !2450
  %2660 = icmp ne i8 %2652, 0
  %2661 = xor i1 %2660, %2658
  %.v8 = select i1 %2661, i64 12, i64 1915
  %2662 = add i64 %2625, %.v8
  store i64 %2662, i64* %PC, align 8, !tbaa !2428
  br i1 %2661, label %block_40386f, label %block_403fde

block_403921:                                     ; preds = %block_403910
  %2663 = load i64, i64* %RBP, align 8
  %2664 = add i64 %2663, -28
  %2665 = add i64 %1622, 3
  store i64 %2665, i64* %PC, align 8
  %2666 = inttoptr i64 %2664 to i32*
  %2667 = load i32, i32* %2666, align 4
  %2668 = zext i32 %2667 to i64
  store i64 %2668, i64* %RAX, align 8, !tbaa !2428
  %2669 = add i64 %2663, -8
  %2670 = add i64 %1622, 6
  store i64 %2670, i64* %PC, align 8
  %2671 = inttoptr i64 %2669 to i32*
  %2672 = load i32, i32* %2671, align 4
  %2673 = add i32 %2672, %2667
  %2674 = zext i32 %2673 to i64
  store i64 %2674, i64* %RAX, align 8, !tbaa !2428
  %2675 = icmp ult i32 %2673, %2667
  %2676 = icmp ult i32 %2673, %2672
  %2677 = or i1 %2675, %2676
  %2678 = zext i1 %2677 to i8
  store i8 %2678, i8* %17, align 1, !tbaa !2433
  %2679 = and i32 %2673, 255
  %2680 = tail call i32 @llvm.ctpop.i32(i32 %2679) #10
  %2681 = trunc i32 %2680 to i8
  %2682 = and i8 %2681, 1
  %2683 = xor i8 %2682, 1
  store i8 %2683, i8* %24, align 1, !tbaa !2447
  %2684 = xor i32 %2672, %2667
  %2685 = xor i32 %2684, %2673
  %2686 = lshr i32 %2685, 4
  %2687 = trunc i32 %2686 to i8
  %2688 = and i8 %2687, 1
  store i8 %2688, i8* %30, align 1, !tbaa !2451
  %2689 = icmp eq i32 %2673, 0
  %2690 = zext i1 %2689 to i8
  store i8 %2690, i8* %33, align 1, !tbaa !2448
  %2691 = lshr i32 %2673, 31
  %2692 = trunc i32 %2691 to i8
  store i8 %2692, i8* %36, align 1, !tbaa !2449
  %2693 = lshr i32 %2667, 31
  %2694 = lshr i32 %2672, 31
  %2695 = xor i32 %2691, %2693
  %2696 = xor i32 %2691, %2694
  %2697 = add nuw nsw i32 %2695, %2696
  %2698 = icmp eq i32 %2697, 2
  %2699 = zext i1 %2698 to i8
  store i8 %2699, i8* %42, align 1, !tbaa !2450
  %2700 = add i64 %2663, -32
  %2701 = add i64 %1622, 9
  store i64 %2701, i64* %PC, align 8
  %2702 = inttoptr i64 %2700 to i32*
  store i32 %2673, i32* %2702, align 4
  %2703 = load i64, i64* %RBP, align 8
  %2704 = add i64 %2703, -32
  %2705 = load i64, i64* %PC, align 8
  %2706 = add i64 %2705, 3
  store i64 %2706, i64* %PC, align 8
  %2707 = inttoptr i64 %2704 to i32*
  %2708 = load i32, i32* %2707, align 4
  %2709 = zext i32 %2708 to i64
  store i64 %2709, i64* %RAX, align 8, !tbaa !2428
  %2710 = add i64 %2703, -8
  %2711 = add i64 %2705, 6
  store i64 %2711, i64* %PC, align 8
  %2712 = inttoptr i64 %2710 to i32*
  %2713 = load i32, i32* %2712, align 4
  %2714 = add i32 %2713, %2708
  %2715 = zext i32 %2714 to i64
  store i64 %2715, i64* %RAX, align 8, !tbaa !2428
  %2716 = icmp ult i32 %2714, %2708
  %2717 = icmp ult i32 %2714, %2713
  %2718 = or i1 %2716, %2717
  %2719 = zext i1 %2718 to i8
  store i8 %2719, i8* %17, align 1, !tbaa !2433
  %2720 = and i32 %2714, 255
  %2721 = tail call i32 @llvm.ctpop.i32(i32 %2720) #10
  %2722 = trunc i32 %2721 to i8
  %2723 = and i8 %2722, 1
  %2724 = xor i8 %2723, 1
  store i8 %2724, i8* %24, align 1, !tbaa !2447
  %2725 = xor i32 %2713, %2708
  %2726 = xor i32 %2725, %2714
  %2727 = lshr i32 %2726, 4
  %2728 = trunc i32 %2727 to i8
  %2729 = and i8 %2728, 1
  store i8 %2729, i8* %30, align 1, !tbaa !2451
  %2730 = icmp eq i32 %2714, 0
  %2731 = zext i1 %2730 to i8
  store i8 %2731, i8* %33, align 1, !tbaa !2448
  %2732 = lshr i32 %2714, 31
  %2733 = trunc i32 %2732 to i8
  store i8 %2733, i8* %36, align 1, !tbaa !2449
  %2734 = lshr i32 %2708, 31
  %2735 = lshr i32 %2713, 31
  %2736 = xor i32 %2732, %2734
  %2737 = xor i32 %2732, %2735
  %2738 = add nuw nsw i32 %2736, %2737
  %2739 = icmp eq i32 %2738, 2
  %2740 = zext i1 %2739 to i8
  store i8 %2740, i8* %42, align 1, !tbaa !2450
  %2741 = add i64 %2703, -36
  %2742 = add i64 %2705, 9
  store i64 %2742, i64* %PC, align 8
  %2743 = inttoptr i64 %2741 to i32*
  store i32 %2714, i32* %2743, align 4
  %2744 = load i64, i64* %RBP, align 8
  %2745 = add i64 %2744, -36
  %2746 = load i64, i64* %PC, align 8
  %2747 = add i64 %2746, 3
  store i64 %2747, i64* %PC, align 8
  %2748 = inttoptr i64 %2745 to i32*
  %2749 = load i32, i32* %2748, align 4
  %2750 = zext i32 %2749 to i64
  store i64 %2750, i64* %RAX, align 8, !tbaa !2428
  %2751 = add i64 %2744, -8
  %2752 = add i64 %2746, 6
  store i64 %2752, i64* %PC, align 8
  %2753 = inttoptr i64 %2751 to i32*
  %2754 = load i32, i32* %2753, align 4
  %2755 = add i32 %2754, %2749
  %2756 = zext i32 %2755 to i64
  store i64 %2756, i64* %RAX, align 8, !tbaa !2428
  %2757 = icmp ult i32 %2755, %2749
  %2758 = icmp ult i32 %2755, %2754
  %2759 = or i1 %2757, %2758
  %2760 = zext i1 %2759 to i8
  store i8 %2760, i8* %17, align 1, !tbaa !2433
  %2761 = and i32 %2755, 255
  %2762 = tail call i32 @llvm.ctpop.i32(i32 %2761) #10
  %2763 = trunc i32 %2762 to i8
  %2764 = and i8 %2763, 1
  %2765 = xor i8 %2764, 1
  store i8 %2765, i8* %24, align 1, !tbaa !2447
  %2766 = xor i32 %2754, %2749
  %2767 = xor i32 %2766, %2755
  %2768 = lshr i32 %2767, 4
  %2769 = trunc i32 %2768 to i8
  %2770 = and i8 %2769, 1
  store i8 %2770, i8* %30, align 1, !tbaa !2451
  %2771 = icmp eq i32 %2755, 0
  %2772 = zext i1 %2771 to i8
  store i8 %2772, i8* %33, align 1, !tbaa !2448
  %2773 = lshr i32 %2755, 31
  %2774 = trunc i32 %2773 to i8
  store i8 %2774, i8* %36, align 1, !tbaa !2449
  %2775 = lshr i32 %2749, 31
  %2776 = lshr i32 %2754, 31
  %2777 = xor i32 %2773, %2775
  %2778 = xor i32 %2773, %2776
  %2779 = add nuw nsw i32 %2777, %2778
  %2780 = icmp eq i32 %2779, 2
  %2781 = zext i1 %2780 to i8
  store i8 %2781, i8* %42, align 1, !tbaa !2450
  %2782 = add i64 %2744, -40
  %2783 = add i64 %2746, 9
  store i64 %2783, i64* %PC, align 8
  %2784 = inttoptr i64 %2782 to i32*
  store i32 %2755, i32* %2784, align 4
  %2785 = load i64, i64* %RBP, align 8
  %2786 = add i64 %2785, -16
  %2787 = load i64, i64* %PC, align 8
  %2788 = add i64 %2787, 4
  store i64 %2788, i64* %PC, align 8
  %2789 = inttoptr i64 %2786 to i64*
  %2790 = load i64, i64* %2789, align 8
  store i64 %2790, i64* %RCX, align 8, !tbaa !2428
  %2791 = add i64 %2785, -28
  %2792 = add i64 %2787, 8
  store i64 %2792, i64* %PC, align 8
  %2793 = inttoptr i64 %2791 to i32*
  %2794 = load i32, i32* %2793, align 4
  %2795 = sext i32 %2794 to i64
  store i64 %2795, i64* %RDX, align 8, !tbaa !2428
  %2796 = shl nsw i64 %2795, 3
  %2797 = add i64 %2796, %2790
  %2798 = add i64 %2787, 13
  store i64 %2798, i64* %PC, align 8
  %2799 = inttoptr i64 %2797 to double*
  %2800 = load double, double* %2799, align 8
  store double %2800, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2801 = add i64 %2787, 17
  store i64 %2801, i64* %PC, align 8
  %2802 = load i64, i64* %2789, align 8
  store i64 %2802, i64* %RCX, align 8, !tbaa !2428
  %2803 = add i64 %2785, -32
  %2804 = add i64 %2787, 21
  store i64 %2804, i64* %PC, align 8
  %2805 = inttoptr i64 %2803 to i32*
  %2806 = load i32, i32* %2805, align 4
  %2807 = sext i32 %2806 to i64
  store i64 %2807, i64* %RDX, align 8, !tbaa !2428
  %2808 = shl nsw i64 %2807, 3
  %2809 = add i64 %2808, %2802
  %2810 = add i64 %2787, 26
  store i64 %2810, i64* %PC, align 8
  %2811 = inttoptr i64 %2809 to double*
  %2812 = load double, double* %2811, align 8
  %2813 = fadd double %2800, %2812
  store double %2813, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2814 = add i64 %2785, -120
  %2815 = add i64 %2787, 31
  store i64 %2815, i64* %PC, align 8
  %2816 = inttoptr i64 %2814 to double*
  store double %2813, double* %2816, align 8
  %2817 = load i64, i64* %RBP, align 8
  %2818 = add i64 %2817, -16
  %2819 = load i64, i64* %PC, align 8
  %2820 = add i64 %2819, 4
  store i64 %2820, i64* %PC, align 8
  %2821 = inttoptr i64 %2818 to i64*
  %2822 = load i64, i64* %2821, align 8
  store i64 %2822, i64* %RCX, align 8, !tbaa !2428
  %2823 = add i64 %2817, -28
  %2824 = add i64 %2819, 7
  store i64 %2824, i64* %PC, align 8
  %2825 = inttoptr i64 %2823 to i32*
  %2826 = load i32, i32* %2825, align 4
  %2827 = add i32 %2826, 1
  %2828 = zext i32 %2827 to i64
  store i64 %2828, i64* %RAX, align 8, !tbaa !2428
  %2829 = icmp eq i32 %2826, -1
  %2830 = icmp eq i32 %2827, 0
  %2831 = or i1 %2829, %2830
  %2832 = zext i1 %2831 to i8
  store i8 %2832, i8* %17, align 1, !tbaa !2433
  %2833 = and i32 %2827, 255
  %2834 = tail call i32 @llvm.ctpop.i32(i32 %2833) #10
  %2835 = trunc i32 %2834 to i8
  %2836 = and i8 %2835, 1
  %2837 = xor i8 %2836, 1
  store i8 %2837, i8* %24, align 1, !tbaa !2447
  %2838 = xor i32 %2826, %2827
  %2839 = lshr i32 %2838, 4
  %2840 = trunc i32 %2839 to i8
  %2841 = and i8 %2840, 1
  store i8 %2841, i8* %30, align 1, !tbaa !2451
  %2842 = zext i1 %2830 to i8
  store i8 %2842, i8* %33, align 1, !tbaa !2448
  %2843 = lshr i32 %2827, 31
  %2844 = trunc i32 %2843 to i8
  store i8 %2844, i8* %36, align 1, !tbaa !2449
  %2845 = lshr i32 %2826, 31
  %2846 = xor i32 %2843, %2845
  %2847 = add nuw nsw i32 %2846, %2843
  %2848 = icmp eq i32 %2847, 2
  %2849 = zext i1 %2848 to i8
  store i8 %2849, i8* %42, align 1, !tbaa !2450
  %2850 = sext i32 %2827 to i64
  store i64 %2850, i64* %RDX, align 8, !tbaa !2428
  %2851 = shl nsw i64 %2850, 3
  %2852 = add i64 %2851, %2822
  %2853 = add i64 %2819, 18
  store i64 %2853, i64* %PC, align 8
  %2854 = inttoptr i64 %2852 to double*
  %2855 = load double, double* %2854, align 8
  store double %2855, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2856 = add i64 %2819, 22
  store i64 %2856, i64* %PC, align 8
  %2857 = load i64, i64* %2821, align 8
  store i64 %2857, i64* %RCX, align 8, !tbaa !2428
  %2858 = add i64 %2817, -32
  %2859 = add i64 %2819, 25
  store i64 %2859, i64* %PC, align 8
  %2860 = inttoptr i64 %2858 to i32*
  %2861 = load i32, i32* %2860, align 4
  %2862 = add i32 %2861, 1
  %2863 = zext i32 %2862 to i64
  store i64 %2863, i64* %RAX, align 8, !tbaa !2428
  %2864 = icmp eq i32 %2861, -1
  %2865 = icmp eq i32 %2862, 0
  %2866 = or i1 %2864, %2865
  %2867 = zext i1 %2866 to i8
  store i8 %2867, i8* %17, align 1, !tbaa !2433
  %2868 = and i32 %2862, 255
  %2869 = tail call i32 @llvm.ctpop.i32(i32 %2868) #10
  %2870 = trunc i32 %2869 to i8
  %2871 = and i8 %2870, 1
  %2872 = xor i8 %2871, 1
  store i8 %2872, i8* %24, align 1, !tbaa !2447
  %2873 = xor i32 %2861, %2862
  %2874 = lshr i32 %2873, 4
  %2875 = trunc i32 %2874 to i8
  %2876 = and i8 %2875, 1
  store i8 %2876, i8* %30, align 1, !tbaa !2451
  %2877 = zext i1 %2865 to i8
  store i8 %2877, i8* %33, align 1, !tbaa !2448
  %2878 = lshr i32 %2862, 31
  %2879 = trunc i32 %2878 to i8
  store i8 %2879, i8* %36, align 1, !tbaa !2449
  %2880 = lshr i32 %2861, 31
  %2881 = xor i32 %2878, %2880
  %2882 = add nuw nsw i32 %2881, %2878
  %2883 = icmp eq i32 %2882, 2
  %2884 = zext i1 %2883 to i8
  store i8 %2884, i8* %42, align 1, !tbaa !2450
  %2885 = sext i32 %2862 to i64
  store i64 %2885, i64* %RDX, align 8, !tbaa !2428
  %2886 = shl nsw i64 %2885, 3
  %2887 = add i64 %2886, %2857
  %2888 = add i64 %2819, 36
  store i64 %2888, i64* %PC, align 8
  %2889 = inttoptr i64 %2887 to double*
  %2890 = load double, double* %2889, align 8
  %2891 = fadd double %2855, %2890
  store double %2891, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2892 = load i64, i64* %RBP, align 8
  %2893 = add i64 %2892, -128
  %2894 = add i64 %2819, 41
  store i64 %2894, i64* %PC, align 8
  %2895 = inttoptr i64 %2893 to double*
  store double %2891, double* %2895, align 8
  %2896 = load i64, i64* %RBP, align 8
  %2897 = add i64 %2896, -16
  %2898 = load i64, i64* %PC, align 8
  %2899 = add i64 %2898, 4
  store i64 %2899, i64* %PC, align 8
  %2900 = inttoptr i64 %2897 to i64*
  %2901 = load i64, i64* %2900, align 8
  store i64 %2901, i64* %RCX, align 8, !tbaa !2428
  %2902 = add i64 %2896, -28
  %2903 = add i64 %2898, 8
  store i64 %2903, i64* %PC, align 8
  %2904 = inttoptr i64 %2902 to i32*
  %2905 = load i32, i32* %2904, align 4
  %2906 = sext i32 %2905 to i64
  store i64 %2906, i64* %RDX, align 8, !tbaa !2428
  %2907 = shl nsw i64 %2906, 3
  %2908 = add i64 %2907, %2901
  %2909 = add i64 %2898, 13
  store i64 %2909, i64* %PC, align 8
  %2910 = inttoptr i64 %2908 to double*
  %2911 = load double, double* %2910, align 8
  store double %2911, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2912 = add i64 %2898, 17
  store i64 %2912, i64* %PC, align 8
  %2913 = load i64, i64* %2900, align 8
  store i64 %2913, i64* %RCX, align 8, !tbaa !2428
  %2914 = add i64 %2896, -32
  %2915 = add i64 %2898, 21
  store i64 %2915, i64* %PC, align 8
  %2916 = inttoptr i64 %2914 to i32*
  %2917 = load i32, i32* %2916, align 4
  %2918 = sext i32 %2917 to i64
  store i64 %2918, i64* %RDX, align 8, !tbaa !2428
  %2919 = shl nsw i64 %2918, 3
  %2920 = add i64 %2919, %2913
  %2921 = add i64 %2898, 26
  store i64 %2921, i64* %PC, align 8
  %2922 = inttoptr i64 %2920 to double*
  %2923 = load double, double* %2922, align 8
  %2924 = fsub double %2911, %2923
  store double %2924, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %2925 = add i64 %2896, -136
  %2926 = add i64 %2898, 34
  store i64 %2926, i64* %PC, align 8
  %2927 = inttoptr i64 %2925 to double*
  store double %2924, double* %2927, align 8
  %2928 = load i64, i64* %RBP, align 8
  %2929 = add i64 %2928, -16
  %2930 = load i64, i64* %PC, align 8
  %2931 = add i64 %2930, 4
  store i64 %2931, i64* %PC, align 8
  %2932 = inttoptr i64 %2929 to i64*
  %2933 = load i64, i64* %2932, align 8
  store i64 %2933, i64* %RCX, align 8, !tbaa !2428
  %2934 = add i64 %2928, -28
  %2935 = add i64 %2930, 7
  store i64 %2935, i64* %PC, align 8
  %2936 = inttoptr i64 %2934 to i32*
  %2937 = load i32, i32* %2936, align 4
  %2938 = add i32 %2937, 1
  %2939 = zext i32 %2938 to i64
  store i64 %2939, i64* %RAX, align 8, !tbaa !2428
  %2940 = icmp eq i32 %2937, -1
  %2941 = icmp eq i32 %2938, 0
  %2942 = or i1 %2940, %2941
  %2943 = zext i1 %2942 to i8
  store i8 %2943, i8* %17, align 1, !tbaa !2433
  %2944 = and i32 %2938, 255
  %2945 = tail call i32 @llvm.ctpop.i32(i32 %2944) #10
  %2946 = trunc i32 %2945 to i8
  %2947 = and i8 %2946, 1
  %2948 = xor i8 %2947, 1
  store i8 %2948, i8* %24, align 1, !tbaa !2447
  %2949 = xor i32 %2937, %2938
  %2950 = lshr i32 %2949, 4
  %2951 = trunc i32 %2950 to i8
  %2952 = and i8 %2951, 1
  store i8 %2952, i8* %30, align 1, !tbaa !2451
  %2953 = zext i1 %2941 to i8
  store i8 %2953, i8* %33, align 1, !tbaa !2448
  %2954 = lshr i32 %2938, 31
  %2955 = trunc i32 %2954 to i8
  store i8 %2955, i8* %36, align 1, !tbaa !2449
  %2956 = lshr i32 %2937, 31
  %2957 = xor i32 %2954, %2956
  %2958 = add nuw nsw i32 %2957, %2954
  %2959 = icmp eq i32 %2958, 2
  %2960 = zext i1 %2959 to i8
  store i8 %2960, i8* %42, align 1, !tbaa !2450
  %2961 = sext i32 %2938 to i64
  store i64 %2961, i64* %RDX, align 8, !tbaa !2428
  %2962 = shl nsw i64 %2961, 3
  %2963 = add i64 %2962, %2933
  %2964 = add i64 %2930, 18
  store i64 %2964, i64* %PC, align 8
  %2965 = inttoptr i64 %2963 to double*
  %2966 = load double, double* %2965, align 8
  store double %2966, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %2967 = add i64 %2930, 22
  store i64 %2967, i64* %PC, align 8
  %2968 = load i64, i64* %2932, align 8
  store i64 %2968, i64* %RCX, align 8, !tbaa !2428
  %2969 = add i64 %2928, -32
  %2970 = add i64 %2930, 25
  store i64 %2970, i64* %PC, align 8
  %2971 = inttoptr i64 %2969 to i32*
  %2972 = load i32, i32* %2971, align 4
  %2973 = add i32 %2972, 1
  %2974 = zext i32 %2973 to i64
  store i64 %2974, i64* %RAX, align 8, !tbaa !2428
  %2975 = icmp eq i32 %2972, -1
  %2976 = icmp eq i32 %2973, 0
  %2977 = or i1 %2975, %2976
  %2978 = zext i1 %2977 to i8
  store i8 %2978, i8* %17, align 1, !tbaa !2433
  %2979 = and i32 %2973, 255
  %2980 = tail call i32 @llvm.ctpop.i32(i32 %2979) #10
  %2981 = trunc i32 %2980 to i8
  %2982 = and i8 %2981, 1
  %2983 = xor i8 %2982, 1
  store i8 %2983, i8* %24, align 1, !tbaa !2447
  %2984 = xor i32 %2972, %2973
  %2985 = lshr i32 %2984, 4
  %2986 = trunc i32 %2985 to i8
  %2987 = and i8 %2986, 1
  store i8 %2987, i8* %30, align 1, !tbaa !2451
  %2988 = zext i1 %2976 to i8
  store i8 %2988, i8* %33, align 1, !tbaa !2448
  %2989 = lshr i32 %2973, 31
  %2990 = trunc i32 %2989 to i8
  store i8 %2990, i8* %36, align 1, !tbaa !2449
  %2991 = lshr i32 %2972, 31
  %2992 = xor i32 %2989, %2991
  %2993 = add nuw nsw i32 %2992, %2989
  %2994 = icmp eq i32 %2993, 2
  %2995 = zext i1 %2994 to i8
  store i8 %2995, i8* %42, align 1, !tbaa !2450
  %2996 = sext i32 %2973 to i64
  store i64 %2996, i64* %RDX, align 8, !tbaa !2428
  %2997 = shl nsw i64 %2996, 3
  %2998 = add i64 %2997, %2968
  %2999 = add i64 %2930, 36
  store i64 %2999, i64* %PC, align 8
  %3000 = inttoptr i64 %2998 to double*
  %3001 = load double, double* %3000, align 8
  %3002 = fsub double %2966, %3001
  store double %3002, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3003 = load i64, i64* %RBP, align 8
  %3004 = add i64 %3003, -144
  %3005 = add i64 %2930, 44
  store i64 %3005, i64* %PC, align 8
  %3006 = inttoptr i64 %3004 to double*
  store double %3002, double* %3006, align 8
  %3007 = load i64, i64* %RBP, align 8
  %3008 = add i64 %3007, -16
  %3009 = load i64, i64* %PC, align 8
  %3010 = add i64 %3009, 4
  store i64 %3010, i64* %PC, align 8
  %3011 = inttoptr i64 %3008 to i64*
  %3012 = load i64, i64* %3011, align 8
  store i64 %3012, i64* %RCX, align 8, !tbaa !2428
  %3013 = add i64 %3007, -36
  %3014 = add i64 %3009, 8
  store i64 %3014, i64* %PC, align 8
  %3015 = inttoptr i64 %3013 to i32*
  %3016 = load i32, i32* %3015, align 4
  %3017 = sext i32 %3016 to i64
  store i64 %3017, i64* %RDX, align 8, !tbaa !2428
  %3018 = shl nsw i64 %3017, 3
  %3019 = add i64 %3018, %3012
  %3020 = add i64 %3009, 13
  store i64 %3020, i64* %PC, align 8
  %3021 = inttoptr i64 %3019 to double*
  %3022 = load double, double* %3021, align 8
  store double %3022, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3023 = add i64 %3009, 17
  store i64 %3023, i64* %PC, align 8
  %3024 = load i64, i64* %3011, align 8
  store i64 %3024, i64* %RCX, align 8, !tbaa !2428
  %3025 = add i64 %3007, -40
  %3026 = add i64 %3009, 21
  store i64 %3026, i64* %PC, align 8
  %3027 = inttoptr i64 %3025 to i32*
  %3028 = load i32, i32* %3027, align 4
  %3029 = sext i32 %3028 to i64
  store i64 %3029, i64* %RDX, align 8, !tbaa !2428
  %3030 = shl nsw i64 %3029, 3
  %3031 = add i64 %3030, %3024
  %3032 = add i64 %3009, 26
  store i64 %3032, i64* %PC, align 8
  %3033 = inttoptr i64 %3031 to double*
  %3034 = load double, double* %3033, align 8
  %3035 = fadd double %3022, %3034
  store double %3035, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3036 = add i64 %3007, -152
  %3037 = add i64 %3009, 34
  store i64 %3037, i64* %PC, align 8
  %3038 = inttoptr i64 %3036 to double*
  store double %3035, double* %3038, align 8
  %3039 = load i64, i64* %RBP, align 8
  %3040 = add i64 %3039, -16
  %3041 = load i64, i64* %PC, align 8
  %3042 = add i64 %3041, 4
  store i64 %3042, i64* %PC, align 8
  %3043 = inttoptr i64 %3040 to i64*
  %3044 = load i64, i64* %3043, align 8
  store i64 %3044, i64* %RCX, align 8, !tbaa !2428
  %3045 = add i64 %3039, -36
  %3046 = add i64 %3041, 7
  store i64 %3046, i64* %PC, align 8
  %3047 = inttoptr i64 %3045 to i32*
  %3048 = load i32, i32* %3047, align 4
  %3049 = add i32 %3048, 1
  %3050 = zext i32 %3049 to i64
  store i64 %3050, i64* %RAX, align 8, !tbaa !2428
  %3051 = icmp eq i32 %3048, -1
  %3052 = icmp eq i32 %3049, 0
  %3053 = or i1 %3051, %3052
  %3054 = zext i1 %3053 to i8
  store i8 %3054, i8* %17, align 1, !tbaa !2433
  %3055 = and i32 %3049, 255
  %3056 = tail call i32 @llvm.ctpop.i32(i32 %3055) #10
  %3057 = trunc i32 %3056 to i8
  %3058 = and i8 %3057, 1
  %3059 = xor i8 %3058, 1
  store i8 %3059, i8* %24, align 1, !tbaa !2447
  %3060 = xor i32 %3048, %3049
  %3061 = lshr i32 %3060, 4
  %3062 = trunc i32 %3061 to i8
  %3063 = and i8 %3062, 1
  store i8 %3063, i8* %30, align 1, !tbaa !2451
  %3064 = zext i1 %3052 to i8
  store i8 %3064, i8* %33, align 1, !tbaa !2448
  %3065 = lshr i32 %3049, 31
  %3066 = trunc i32 %3065 to i8
  store i8 %3066, i8* %36, align 1, !tbaa !2449
  %3067 = lshr i32 %3048, 31
  %3068 = xor i32 %3065, %3067
  %3069 = add nuw nsw i32 %3068, %3065
  %3070 = icmp eq i32 %3069, 2
  %3071 = zext i1 %3070 to i8
  store i8 %3071, i8* %42, align 1, !tbaa !2450
  %3072 = sext i32 %3049 to i64
  store i64 %3072, i64* %RDX, align 8, !tbaa !2428
  %3073 = shl nsw i64 %3072, 3
  %3074 = add i64 %3073, %3044
  %3075 = add i64 %3041, 18
  store i64 %3075, i64* %PC, align 8
  %3076 = inttoptr i64 %3074 to double*
  %3077 = load double, double* %3076, align 8
  store double %3077, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3078 = add i64 %3041, 22
  store i64 %3078, i64* %PC, align 8
  %3079 = load i64, i64* %3043, align 8
  store i64 %3079, i64* %RCX, align 8, !tbaa !2428
  %3080 = add i64 %3039, -40
  %3081 = add i64 %3041, 25
  store i64 %3081, i64* %PC, align 8
  %3082 = inttoptr i64 %3080 to i32*
  %3083 = load i32, i32* %3082, align 4
  %3084 = add i32 %3083, 1
  %3085 = zext i32 %3084 to i64
  store i64 %3085, i64* %RAX, align 8, !tbaa !2428
  %3086 = icmp eq i32 %3083, -1
  %3087 = icmp eq i32 %3084, 0
  %3088 = or i1 %3086, %3087
  %3089 = zext i1 %3088 to i8
  store i8 %3089, i8* %17, align 1, !tbaa !2433
  %3090 = and i32 %3084, 255
  %3091 = tail call i32 @llvm.ctpop.i32(i32 %3090) #10
  %3092 = trunc i32 %3091 to i8
  %3093 = and i8 %3092, 1
  %3094 = xor i8 %3093, 1
  store i8 %3094, i8* %24, align 1, !tbaa !2447
  %3095 = xor i32 %3083, %3084
  %3096 = lshr i32 %3095, 4
  %3097 = trunc i32 %3096 to i8
  %3098 = and i8 %3097, 1
  store i8 %3098, i8* %30, align 1, !tbaa !2451
  %3099 = zext i1 %3087 to i8
  store i8 %3099, i8* %33, align 1, !tbaa !2448
  %3100 = lshr i32 %3084, 31
  %3101 = trunc i32 %3100 to i8
  store i8 %3101, i8* %36, align 1, !tbaa !2449
  %3102 = lshr i32 %3083, 31
  %3103 = xor i32 %3100, %3102
  %3104 = add nuw nsw i32 %3103, %3100
  %3105 = icmp eq i32 %3104, 2
  %3106 = zext i1 %3105 to i8
  store i8 %3106, i8* %42, align 1, !tbaa !2450
  %3107 = sext i32 %3084 to i64
  store i64 %3107, i64* %RDX, align 8, !tbaa !2428
  %3108 = shl nsw i64 %3107, 3
  %3109 = add i64 %3108, %3079
  %3110 = add i64 %3041, 36
  store i64 %3110, i64* %PC, align 8
  %3111 = inttoptr i64 %3109 to double*
  %3112 = load double, double* %3111, align 8
  %3113 = fadd double %3077, %3112
  store double %3113, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3114 = load i64, i64* %RBP, align 8
  %3115 = add i64 %3114, -160
  %3116 = add i64 %3041, 44
  store i64 %3116, i64* %PC, align 8
  %3117 = inttoptr i64 %3115 to double*
  store double %3113, double* %3117, align 8
  %3118 = load i64, i64* %RBP, align 8
  %3119 = add i64 %3118, -16
  %3120 = load i64, i64* %PC, align 8
  %3121 = add i64 %3120, 4
  store i64 %3121, i64* %PC, align 8
  %3122 = inttoptr i64 %3119 to i64*
  %3123 = load i64, i64* %3122, align 8
  store i64 %3123, i64* %RCX, align 8, !tbaa !2428
  %3124 = add i64 %3118, -36
  %3125 = add i64 %3120, 8
  store i64 %3125, i64* %PC, align 8
  %3126 = inttoptr i64 %3124 to i32*
  %3127 = load i32, i32* %3126, align 4
  %3128 = sext i32 %3127 to i64
  store i64 %3128, i64* %RDX, align 8, !tbaa !2428
  %3129 = shl nsw i64 %3128, 3
  %3130 = add i64 %3129, %3123
  %3131 = add i64 %3120, 13
  store i64 %3131, i64* %PC, align 8
  %3132 = inttoptr i64 %3130 to double*
  %3133 = load double, double* %3132, align 8
  store double %3133, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3134 = add i64 %3120, 17
  store i64 %3134, i64* %PC, align 8
  %3135 = load i64, i64* %3122, align 8
  store i64 %3135, i64* %RCX, align 8, !tbaa !2428
  %3136 = add i64 %3118, -40
  %3137 = add i64 %3120, 21
  store i64 %3137, i64* %PC, align 8
  %3138 = inttoptr i64 %3136 to i32*
  %3139 = load i32, i32* %3138, align 4
  %3140 = sext i32 %3139 to i64
  store i64 %3140, i64* %RDX, align 8, !tbaa !2428
  %3141 = shl nsw i64 %3140, 3
  %3142 = add i64 %3141, %3135
  %3143 = add i64 %3120, 26
  store i64 %3143, i64* %PC, align 8
  %3144 = inttoptr i64 %3142 to double*
  %3145 = load double, double* %3144, align 8
  %3146 = fsub double %3133, %3145
  store double %3146, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3147 = add i64 %3118, -168
  %3148 = add i64 %3120, 34
  store i64 %3148, i64* %PC, align 8
  %3149 = inttoptr i64 %3147 to double*
  store double %3146, double* %3149, align 8
  %3150 = load i64, i64* %RBP, align 8
  %3151 = add i64 %3150, -16
  %3152 = load i64, i64* %PC, align 8
  %3153 = add i64 %3152, 4
  store i64 %3153, i64* %PC, align 8
  %3154 = inttoptr i64 %3151 to i64*
  %3155 = load i64, i64* %3154, align 8
  store i64 %3155, i64* %RCX, align 8, !tbaa !2428
  %3156 = add i64 %3150, -36
  %3157 = add i64 %3152, 7
  store i64 %3157, i64* %PC, align 8
  %3158 = inttoptr i64 %3156 to i32*
  %3159 = load i32, i32* %3158, align 4
  %3160 = add i32 %3159, 1
  %3161 = zext i32 %3160 to i64
  store i64 %3161, i64* %RAX, align 8, !tbaa !2428
  %3162 = icmp eq i32 %3159, -1
  %3163 = icmp eq i32 %3160, 0
  %3164 = or i1 %3162, %3163
  %3165 = zext i1 %3164 to i8
  store i8 %3165, i8* %17, align 1, !tbaa !2433
  %3166 = and i32 %3160, 255
  %3167 = tail call i32 @llvm.ctpop.i32(i32 %3166) #10
  %3168 = trunc i32 %3167 to i8
  %3169 = and i8 %3168, 1
  %3170 = xor i8 %3169, 1
  store i8 %3170, i8* %24, align 1, !tbaa !2447
  %3171 = xor i32 %3159, %3160
  %3172 = lshr i32 %3171, 4
  %3173 = trunc i32 %3172 to i8
  %3174 = and i8 %3173, 1
  store i8 %3174, i8* %30, align 1, !tbaa !2451
  %3175 = zext i1 %3163 to i8
  store i8 %3175, i8* %33, align 1, !tbaa !2448
  %3176 = lshr i32 %3160, 31
  %3177 = trunc i32 %3176 to i8
  store i8 %3177, i8* %36, align 1, !tbaa !2449
  %3178 = lshr i32 %3159, 31
  %3179 = xor i32 %3176, %3178
  %3180 = add nuw nsw i32 %3179, %3176
  %3181 = icmp eq i32 %3180, 2
  %3182 = zext i1 %3181 to i8
  store i8 %3182, i8* %42, align 1, !tbaa !2450
  %3183 = sext i32 %3160 to i64
  store i64 %3183, i64* %RDX, align 8, !tbaa !2428
  %3184 = shl nsw i64 %3183, 3
  %3185 = add i64 %3184, %3155
  %3186 = add i64 %3152, 18
  store i64 %3186, i64* %PC, align 8
  %3187 = inttoptr i64 %3185 to double*
  %3188 = load double, double* %3187, align 8
  store double %3188, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3189 = add i64 %3152, 22
  store i64 %3189, i64* %PC, align 8
  %3190 = load i64, i64* %3154, align 8
  store i64 %3190, i64* %RCX, align 8, !tbaa !2428
  %3191 = add i64 %3150, -40
  %3192 = add i64 %3152, 25
  store i64 %3192, i64* %PC, align 8
  %3193 = inttoptr i64 %3191 to i32*
  %3194 = load i32, i32* %3193, align 4
  %3195 = add i32 %3194, 1
  %3196 = zext i32 %3195 to i64
  store i64 %3196, i64* %RAX, align 8, !tbaa !2428
  %3197 = icmp eq i32 %3194, -1
  %3198 = icmp eq i32 %3195, 0
  %3199 = or i1 %3197, %3198
  %3200 = zext i1 %3199 to i8
  store i8 %3200, i8* %17, align 1, !tbaa !2433
  %3201 = and i32 %3195, 255
  %3202 = tail call i32 @llvm.ctpop.i32(i32 %3201) #10
  %3203 = trunc i32 %3202 to i8
  %3204 = and i8 %3203, 1
  %3205 = xor i8 %3204, 1
  store i8 %3205, i8* %24, align 1, !tbaa !2447
  %3206 = xor i32 %3194, %3195
  %3207 = lshr i32 %3206, 4
  %3208 = trunc i32 %3207 to i8
  %3209 = and i8 %3208, 1
  store i8 %3209, i8* %30, align 1, !tbaa !2451
  %3210 = zext i1 %3198 to i8
  store i8 %3210, i8* %33, align 1, !tbaa !2448
  %3211 = lshr i32 %3195, 31
  %3212 = trunc i32 %3211 to i8
  store i8 %3212, i8* %36, align 1, !tbaa !2449
  %3213 = lshr i32 %3194, 31
  %3214 = xor i32 %3211, %3213
  %3215 = add nuw nsw i32 %3214, %3211
  %3216 = icmp eq i32 %3215, 2
  %3217 = zext i1 %3216 to i8
  store i8 %3217, i8* %42, align 1, !tbaa !2450
  %3218 = sext i32 %3195 to i64
  store i64 %3218, i64* %RDX, align 8, !tbaa !2428
  %3219 = shl nsw i64 %3218, 3
  %3220 = add i64 %3219, %3190
  %3221 = add i64 %3152, 36
  store i64 %3221, i64* %PC, align 8
  %3222 = inttoptr i64 %3220 to double*
  %3223 = load double, double* %3222, align 8
  %3224 = fsub double %3188, %3223
  store double %3224, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3225 = load i64, i64* %RBP, align 8
  %3226 = add i64 %3225, -176
  %3227 = add i64 %3152, 44
  store i64 %3227, i64* %PC, align 8
  %3228 = inttoptr i64 %3226 to double*
  store double %3224, double* %3228, align 8
  %3229 = load i64, i64* %RBP, align 8
  %3230 = add i64 %3229, -120
  %3231 = load i64, i64* %PC, align 8
  %3232 = add i64 %3231, 5
  store i64 %3232, i64* %PC, align 8
  %3233 = inttoptr i64 %3230 to double*
  %3234 = load double, double* %3233, align 8
  store double %3234, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3235 = add i64 %3229, -152
  %3236 = add i64 %3231, 13
  store i64 %3236, i64* %PC, align 8
  %3237 = inttoptr i64 %3235 to double*
  %3238 = load double, double* %3237, align 8
  %3239 = fadd double %3234, %3238
  store double %3239, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3240 = add i64 %3229, -16
  %3241 = add i64 %3231, 17
  store i64 %3241, i64* %PC, align 8
  %3242 = inttoptr i64 %3240 to i64*
  %3243 = load i64, i64* %3242, align 8
  store i64 %3243, i64* %RCX, align 8, !tbaa !2428
  %3244 = add i64 %3229, -28
  %3245 = add i64 %3231, 21
  store i64 %3245, i64* %PC, align 8
  %3246 = inttoptr i64 %3244 to i32*
  %3247 = load i32, i32* %3246, align 4
  %3248 = sext i32 %3247 to i64
  store i64 %3248, i64* %RDX, align 8, !tbaa !2428
  %3249 = shl nsw i64 %3248, 3
  %3250 = add i64 %3249, %3243
  %3251 = add i64 %3231, 26
  store i64 %3251, i64* %PC, align 8
  %3252 = inttoptr i64 %3250 to double*
  store double %3239, double* %3252, align 8
  %3253 = load i64, i64* %RBP, align 8
  %3254 = add i64 %3253, -128
  %3255 = load i64, i64* %PC, align 8
  %3256 = add i64 %3255, 5
  store i64 %3256, i64* %PC, align 8
  %3257 = inttoptr i64 %3254 to double*
  %3258 = load double, double* %3257, align 8
  store double %3258, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3259 = add i64 %3253, -160
  %3260 = add i64 %3255, 13
  store i64 %3260, i64* %PC, align 8
  %3261 = inttoptr i64 %3259 to double*
  %3262 = load double, double* %3261, align 8
  %3263 = fadd double %3258, %3262
  store double %3263, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3264 = add i64 %3253, -16
  %3265 = add i64 %3255, 17
  store i64 %3265, i64* %PC, align 8
  %3266 = inttoptr i64 %3264 to i64*
  %3267 = load i64, i64* %3266, align 8
  store i64 %3267, i64* %RCX, align 8, !tbaa !2428
  %3268 = add i64 %3253, -28
  %3269 = add i64 %3255, 20
  store i64 %3269, i64* %PC, align 8
  %3270 = inttoptr i64 %3268 to i32*
  %3271 = load i32, i32* %3270, align 4
  %3272 = add i32 %3271, 1
  %3273 = zext i32 %3272 to i64
  store i64 %3273, i64* %RAX, align 8, !tbaa !2428
  %3274 = icmp eq i32 %3271, -1
  %3275 = icmp eq i32 %3272, 0
  %3276 = or i1 %3274, %3275
  %3277 = zext i1 %3276 to i8
  store i8 %3277, i8* %17, align 1, !tbaa !2433
  %3278 = and i32 %3272, 255
  %3279 = tail call i32 @llvm.ctpop.i32(i32 %3278) #10
  %3280 = trunc i32 %3279 to i8
  %3281 = and i8 %3280, 1
  %3282 = xor i8 %3281, 1
  store i8 %3282, i8* %24, align 1, !tbaa !2447
  %3283 = xor i32 %3271, %3272
  %3284 = lshr i32 %3283, 4
  %3285 = trunc i32 %3284 to i8
  %3286 = and i8 %3285, 1
  store i8 %3286, i8* %30, align 1, !tbaa !2451
  %3287 = zext i1 %3275 to i8
  store i8 %3287, i8* %33, align 1, !tbaa !2448
  %3288 = lshr i32 %3272, 31
  %3289 = trunc i32 %3288 to i8
  store i8 %3289, i8* %36, align 1, !tbaa !2449
  %3290 = lshr i32 %3271, 31
  %3291 = xor i32 %3288, %3290
  %3292 = add nuw nsw i32 %3291, %3288
  %3293 = icmp eq i32 %3292, 2
  %3294 = zext i1 %3293 to i8
  store i8 %3294, i8* %42, align 1, !tbaa !2450
  %3295 = sext i32 %3272 to i64
  store i64 %3295, i64* %RDX, align 8, !tbaa !2428
  %3296 = shl nsw i64 %3295, 3
  %3297 = add i64 %3296, %3267
  %3298 = add i64 %3255, 31
  store i64 %3298, i64* %PC, align 8
  %3299 = inttoptr i64 %3297 to double*
  store double %3263, double* %3299, align 8
  %3300 = load i64, i64* %RBP, align 8
  %3301 = add i64 %3300, -152
  %3302 = load i64, i64* %PC, align 8
  %3303 = add i64 %3302, 8
  store i64 %3303, i64* %PC, align 8
  %3304 = inttoptr i64 %3301 to double*
  %3305 = load double, double* %3304, align 8
  store double %3305, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3306 = add i64 %3300, -120
  %3307 = add i64 %3302, 13
  store i64 %3307, i64* %PC, align 8
  %3308 = inttoptr i64 %3306 to double*
  %3309 = load double, double* %3308, align 8
  %3310 = fsub double %3309, %3305
  store double %3310, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %3311 = add i64 %3302, 22
  store i64 %3311, i64* %PC, align 8
  store double %3310, double* %3308, align 8
  %3312 = load i64, i64* %RBP, align 8
  %3313 = add i64 %3312, -160
  %3314 = load i64, i64* %PC, align 8
  %3315 = add i64 %3314, 8
  store i64 %3315, i64* %PC, align 8
  %3316 = inttoptr i64 %3313 to double*
  %3317 = load double, double* %3316, align 8
  store double %3317, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3318 = add i64 %3312, -128
  %3319 = add i64 %3314, 13
  store i64 %3319, i64* %PC, align 8
  %3320 = inttoptr i64 %3318 to double*
  %3321 = load double, double* %3320, align 8
  %3322 = fsub double %3321, %3317
  store double %3322, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %3323 = add i64 %3314, 22
  store i64 %3323, i64* %PC, align 8
  store double %3322, double* %3320, align 8
  %3324 = load i64, i64* %RBP, align 8
  %3325 = add i64 %3324, -88
  %3326 = load i64, i64* %PC, align 8
  %3327 = add i64 %3326, 5
  store i64 %3327, i64* %PC, align 8
  %3328 = inttoptr i64 %3325 to double*
  %3329 = load double, double* %3328, align 8
  store double %3329, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3330 = add i64 %3324, -120
  %3331 = add i64 %3326, 10
  store i64 %3331, i64* %PC, align 8
  %3332 = inttoptr i64 %3330 to double*
  %3333 = load double, double* %3332, align 8
  %3334 = fmul double %3329, %3333
  store double %3334, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3335 = add i64 %3324, -96
  %3336 = add i64 %3326, 15
  store i64 %3336, i64* %PC, align 8
  %3337 = inttoptr i64 %3335 to double*
  %3338 = load double, double* %3337, align 8
  store double %3338, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %3339 = add i64 %3324, -128
  %3340 = add i64 %3326, 20
  store i64 %3340, i64* %PC, align 8
  %3341 = inttoptr i64 %3339 to double*
  %3342 = load double, double* %3341, align 8
  %3343 = fmul double %3338, %3342
  store double %3343, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %3344 = fsub double %3334, %3343
  store double %3344, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3345 = add i64 %3324, -16
  %3346 = add i64 %3326, 28
  store i64 %3346, i64* %PC, align 8
  %3347 = inttoptr i64 %3345 to i64*
  %3348 = load i64, i64* %3347, align 8
  store i64 %3348, i64* %RCX, align 8, !tbaa !2428
  %3349 = add i64 %3324, -36
  %3350 = add i64 %3326, 32
  store i64 %3350, i64* %PC, align 8
  %3351 = inttoptr i64 %3349 to i32*
  %3352 = load i32, i32* %3351, align 4
  %3353 = sext i32 %3352 to i64
  store i64 %3353, i64* %RDX, align 8, !tbaa !2428
  %3354 = shl nsw i64 %3353, 3
  %3355 = add i64 %3354, %3348
  %3356 = add i64 %3326, 37
  store i64 %3356, i64* %PC, align 8
  %3357 = inttoptr i64 %3355 to double*
  store double %3344, double* %3357, align 8
  %3358 = load i64, i64* %RBP, align 8
  %3359 = add i64 %3358, -88
  %3360 = load i64, i64* %PC, align 8
  %3361 = add i64 %3360, 5
  store i64 %3361, i64* %PC, align 8
  %3362 = inttoptr i64 %3359 to double*
  %3363 = load double, double* %3362, align 8
  store double %3363, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3364 = add i64 %3358, -128
  %3365 = add i64 %3360, 10
  store i64 %3365, i64* %PC, align 8
  %3366 = inttoptr i64 %3364 to double*
  %3367 = load double, double* %3366, align 8
  %3368 = fmul double %3363, %3367
  store double %3368, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3369 = add i64 %3358, -96
  %3370 = add i64 %3360, 15
  store i64 %3370, i64* %PC, align 8
  %3371 = inttoptr i64 %3369 to double*
  %3372 = load double, double* %3371, align 8
  store double %3372, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %3373 = add i64 %3358, -120
  %3374 = add i64 %3360, 20
  store i64 %3374, i64* %PC, align 8
  %3375 = inttoptr i64 %3373 to double*
  %3376 = load double, double* %3375, align 8
  %3377 = fmul double %3372, %3376
  store double %3377, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %3378 = fadd double %3368, %3377
  store double %3378, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3379 = add i64 %3358, -16
  %3380 = add i64 %3360, 28
  store i64 %3380, i64* %PC, align 8
  %3381 = inttoptr i64 %3379 to i64*
  %3382 = load i64, i64* %3381, align 8
  store i64 %3382, i64* %RCX, align 8, !tbaa !2428
  %3383 = add i64 %3358, -36
  %3384 = add i64 %3360, 31
  store i64 %3384, i64* %PC, align 8
  %3385 = inttoptr i64 %3383 to i32*
  %3386 = load i32, i32* %3385, align 4
  %3387 = add i32 %3386, 1
  %3388 = zext i32 %3387 to i64
  store i64 %3388, i64* %RAX, align 8, !tbaa !2428
  %3389 = icmp eq i32 %3386, -1
  %3390 = icmp eq i32 %3387, 0
  %3391 = or i1 %3389, %3390
  %3392 = zext i1 %3391 to i8
  store i8 %3392, i8* %17, align 1, !tbaa !2433
  %3393 = and i32 %3387, 255
  %3394 = tail call i32 @llvm.ctpop.i32(i32 %3393) #10
  %3395 = trunc i32 %3394 to i8
  %3396 = and i8 %3395, 1
  %3397 = xor i8 %3396, 1
  store i8 %3397, i8* %24, align 1, !tbaa !2447
  %3398 = xor i32 %3386, %3387
  %3399 = lshr i32 %3398, 4
  %3400 = trunc i32 %3399 to i8
  %3401 = and i8 %3400, 1
  store i8 %3401, i8* %30, align 1, !tbaa !2451
  %3402 = zext i1 %3390 to i8
  store i8 %3402, i8* %33, align 1, !tbaa !2448
  %3403 = lshr i32 %3387, 31
  %3404 = trunc i32 %3403 to i8
  store i8 %3404, i8* %36, align 1, !tbaa !2449
  %3405 = lshr i32 %3386, 31
  %3406 = xor i32 %3403, %3405
  %3407 = add nuw nsw i32 %3406, %3403
  %3408 = icmp eq i32 %3407, 2
  %3409 = zext i1 %3408 to i8
  store i8 %3409, i8* %42, align 1, !tbaa !2450
  %3410 = sext i32 %3387 to i64
  store i64 %3410, i64* %RDX, align 8, !tbaa !2428
  %3411 = shl nsw i64 %3410, 3
  %3412 = add i64 %3411, %3382
  %3413 = add i64 %3360, 42
  store i64 %3413, i64* %PC, align 8
  %3414 = inttoptr i64 %3412 to double*
  store double %3378, double* %3414, align 8
  %3415 = load i64, i64* %RBP, align 8
  %3416 = add i64 %3415, -136
  %3417 = load i64, i64* %PC, align 8
  %3418 = add i64 %3417, 8
  store i64 %3418, i64* %PC, align 8
  %3419 = inttoptr i64 %3416 to double*
  %3420 = load double, double* %3419, align 8
  store double %3420, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3421 = add i64 %3415, -176
  %3422 = add i64 %3417, 16
  store i64 %3422, i64* %PC, align 8
  %3423 = inttoptr i64 %3421 to double*
  %3424 = load double, double* %3423, align 8
  %3425 = fsub double %3420, %3424
  store double %3425, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3426 = add i64 %3415, -120
  %3427 = add i64 %3417, 21
  store i64 %3427, i64* %PC, align 8
  %3428 = inttoptr i64 %3426 to double*
  store double %3425, double* %3428, align 8
  %3429 = load i64, i64* %RBP, align 8
  %3430 = add i64 %3429, -144
  %3431 = load i64, i64* %PC, align 8
  %3432 = add i64 %3431, 8
  store i64 %3432, i64* %PC, align 8
  %3433 = inttoptr i64 %3430 to double*
  %3434 = load double, double* %3433, align 8
  store double %3434, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3435 = add i64 %3429, -168
  %3436 = add i64 %3431, 16
  store i64 %3436, i64* %PC, align 8
  %3437 = inttoptr i64 %3435 to double*
  %3438 = load double, double* %3437, align 8
  %3439 = fadd double %3434, %3438
  store double %3439, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3440 = add i64 %3429, -128
  %3441 = add i64 %3431, 21
  store i64 %3441, i64* %PC, align 8
  %3442 = inttoptr i64 %3440 to double*
  store double %3439, double* %3442, align 8
  %3443 = load i64, i64* %RBP, align 8
  %3444 = add i64 %3443, -72
  %3445 = load i64, i64* %PC, align 8
  %3446 = add i64 %3445, 5
  store i64 %3446, i64* %PC, align 8
  %3447 = inttoptr i64 %3444 to double*
  %3448 = load double, double* %3447, align 8
  store double %3448, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3449 = add i64 %3443, -120
  %3450 = add i64 %3445, 10
  store i64 %3450, i64* %PC, align 8
  %3451 = inttoptr i64 %3449 to double*
  %3452 = load double, double* %3451, align 8
  %3453 = fmul double %3448, %3452
  store double %3453, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3454 = add i64 %3443, -80
  %3455 = add i64 %3445, 15
  store i64 %3455, i64* %PC, align 8
  %3456 = inttoptr i64 %3454 to double*
  %3457 = load double, double* %3456, align 8
  store double %3457, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %3458 = add i64 %3443, -128
  %3459 = add i64 %3445, 20
  store i64 %3459, i64* %PC, align 8
  %3460 = inttoptr i64 %3458 to double*
  %3461 = load double, double* %3460, align 8
  %3462 = fmul double %3457, %3461
  store double %3462, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %3463 = fsub double %3453, %3462
  store double %3463, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3464 = add i64 %3443, -16
  %3465 = add i64 %3445, 28
  store i64 %3465, i64* %PC, align 8
  %3466 = inttoptr i64 %3464 to i64*
  %3467 = load i64, i64* %3466, align 8
  store i64 %3467, i64* %RCX, align 8, !tbaa !2428
  %3468 = add i64 %3443, -32
  %3469 = add i64 %3445, 32
  store i64 %3469, i64* %PC, align 8
  %3470 = inttoptr i64 %3468 to i32*
  %3471 = load i32, i32* %3470, align 4
  %3472 = sext i32 %3471 to i64
  store i64 %3472, i64* %RDX, align 8, !tbaa !2428
  %3473 = shl nsw i64 %3472, 3
  %3474 = add i64 %3473, %3467
  %3475 = add i64 %3445, 37
  store i64 %3475, i64* %PC, align 8
  %3476 = inttoptr i64 %3474 to double*
  store double %3463, double* %3476, align 8
  %3477 = load i64, i64* %RBP, align 8
  %3478 = add i64 %3477, -72
  %3479 = load i64, i64* %PC, align 8
  %3480 = add i64 %3479, 5
  store i64 %3480, i64* %PC, align 8
  %3481 = inttoptr i64 %3478 to double*
  %3482 = load double, double* %3481, align 8
  store double %3482, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3483 = add i64 %3477, -128
  %3484 = add i64 %3479, 10
  store i64 %3484, i64* %PC, align 8
  %3485 = inttoptr i64 %3483 to double*
  %3486 = load double, double* %3485, align 8
  %3487 = fmul double %3482, %3486
  store double %3487, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3488 = add i64 %3477, -80
  %3489 = add i64 %3479, 15
  store i64 %3489, i64* %PC, align 8
  %3490 = inttoptr i64 %3488 to double*
  %3491 = load double, double* %3490, align 8
  store double %3491, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %3492 = add i64 %3477, -120
  %3493 = add i64 %3479, 20
  store i64 %3493, i64* %PC, align 8
  %3494 = inttoptr i64 %3492 to double*
  %3495 = load double, double* %3494, align 8
  %3496 = fmul double %3491, %3495
  store double %3496, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %3497 = fadd double %3487, %3496
  store double %3497, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3498 = add i64 %3477, -16
  %3499 = add i64 %3479, 28
  store i64 %3499, i64* %PC, align 8
  %3500 = inttoptr i64 %3498 to i64*
  %3501 = load i64, i64* %3500, align 8
  store i64 %3501, i64* %RCX, align 8, !tbaa !2428
  %3502 = add i64 %3477, -32
  %3503 = add i64 %3479, 31
  store i64 %3503, i64* %PC, align 8
  %3504 = inttoptr i64 %3502 to i32*
  %3505 = load i32, i32* %3504, align 4
  %3506 = add i32 %3505, 1
  %3507 = zext i32 %3506 to i64
  store i64 %3507, i64* %RAX, align 8, !tbaa !2428
  %3508 = icmp eq i32 %3505, -1
  %3509 = icmp eq i32 %3506, 0
  %3510 = or i1 %3508, %3509
  %3511 = zext i1 %3510 to i8
  store i8 %3511, i8* %17, align 1, !tbaa !2433
  %3512 = and i32 %3506, 255
  %3513 = tail call i32 @llvm.ctpop.i32(i32 %3512) #10
  %3514 = trunc i32 %3513 to i8
  %3515 = and i8 %3514, 1
  %3516 = xor i8 %3515, 1
  store i8 %3516, i8* %24, align 1, !tbaa !2447
  %3517 = xor i32 %3505, %3506
  %3518 = lshr i32 %3517, 4
  %3519 = trunc i32 %3518 to i8
  %3520 = and i8 %3519, 1
  store i8 %3520, i8* %30, align 1, !tbaa !2451
  %3521 = zext i1 %3509 to i8
  store i8 %3521, i8* %33, align 1, !tbaa !2448
  %3522 = lshr i32 %3506, 31
  %3523 = trunc i32 %3522 to i8
  store i8 %3523, i8* %36, align 1, !tbaa !2449
  %3524 = lshr i32 %3505, 31
  %3525 = xor i32 %3522, %3524
  %3526 = add nuw nsw i32 %3525, %3522
  %3527 = icmp eq i32 %3526, 2
  %3528 = zext i1 %3527 to i8
  store i8 %3528, i8* %42, align 1, !tbaa !2450
  %3529 = sext i32 %3506 to i64
  store i64 %3529, i64* %RDX, align 8, !tbaa !2428
  %3530 = shl nsw i64 %3529, 3
  %3531 = add i64 %3530, %3501
  %3532 = add i64 %3479, 42
  store i64 %3532, i64* %PC, align 8
  %3533 = inttoptr i64 %3531 to double*
  store double %3497, double* %3533, align 8
  %3534 = load i64, i64* %RBP, align 8
  %3535 = add i64 %3534, -136
  %3536 = load i64, i64* %PC, align 8
  %3537 = add i64 %3536, 8
  store i64 %3537, i64* %PC, align 8
  %3538 = inttoptr i64 %3535 to double*
  %3539 = load double, double* %3538, align 8
  store double %3539, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3540 = add i64 %3534, -176
  %3541 = add i64 %3536, 16
  store i64 %3541, i64* %PC, align 8
  %3542 = inttoptr i64 %3540 to double*
  %3543 = load double, double* %3542, align 8
  %3544 = fadd double %3539, %3543
  store double %3544, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3545 = add i64 %3534, -120
  %3546 = add i64 %3536, 21
  store i64 %3546, i64* %PC, align 8
  %3547 = inttoptr i64 %3545 to double*
  store double %3544, double* %3547, align 8
  %3548 = load i64, i64* %RBP, align 8
  %3549 = add i64 %3548, -144
  %3550 = load i64, i64* %PC, align 8
  %3551 = add i64 %3550, 8
  store i64 %3551, i64* %PC, align 8
  %3552 = inttoptr i64 %3549 to double*
  %3553 = load double, double* %3552, align 8
  store double %3553, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3554 = add i64 %3548, -168
  %3555 = add i64 %3550, 16
  store i64 %3555, i64* %PC, align 8
  %3556 = inttoptr i64 %3554 to double*
  %3557 = load double, double* %3556, align 8
  %3558 = fsub double %3553, %3557
  store double %3558, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3559 = add i64 %3548, -128
  %3560 = add i64 %3550, 21
  store i64 %3560, i64* %PC, align 8
  %3561 = inttoptr i64 %3559 to double*
  store double %3558, double* %3561, align 8
  %3562 = load i64, i64* %RBP, align 8
  %3563 = add i64 %3562, -104
  %3564 = load i64, i64* %PC, align 8
  %3565 = add i64 %3564, 5
  store i64 %3565, i64* %PC, align 8
  %3566 = inttoptr i64 %3563 to double*
  %3567 = load double, double* %3566, align 8
  store double %3567, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3568 = add i64 %3562, -120
  %3569 = add i64 %3564, 10
  store i64 %3569, i64* %PC, align 8
  %3570 = inttoptr i64 %3568 to double*
  %3571 = load double, double* %3570, align 8
  %3572 = fmul double %3567, %3571
  store double %3572, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3573 = add i64 %3562, -112
  %3574 = add i64 %3564, 15
  store i64 %3574, i64* %PC, align 8
  %3575 = inttoptr i64 %3573 to double*
  %3576 = load double, double* %3575, align 8
  store double %3576, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %3577 = add i64 %3562, -128
  %3578 = add i64 %3564, 20
  store i64 %3578, i64* %PC, align 8
  %3579 = inttoptr i64 %3577 to double*
  %3580 = load double, double* %3579, align 8
  %3581 = fmul double %3576, %3580
  store double %3581, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %3582 = fsub double %3572, %3581
  store double %3582, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3583 = add i64 %3562, -16
  %3584 = add i64 %3564, 28
  store i64 %3584, i64* %PC, align 8
  %3585 = inttoptr i64 %3583 to i64*
  %3586 = load i64, i64* %3585, align 8
  store i64 %3586, i64* %RCX, align 8, !tbaa !2428
  %3587 = add i64 %3562, -40
  %3588 = add i64 %3564, 32
  store i64 %3588, i64* %PC, align 8
  %3589 = inttoptr i64 %3587 to i32*
  %3590 = load i32, i32* %3589, align 4
  %3591 = sext i32 %3590 to i64
  store i64 %3591, i64* %RDX, align 8, !tbaa !2428
  %3592 = shl nsw i64 %3591, 3
  %3593 = add i64 %3592, %3586
  %3594 = add i64 %3564, 37
  store i64 %3594, i64* %PC, align 8
  %3595 = inttoptr i64 %3593 to double*
  store double %3582, double* %3595, align 8
  %3596 = load i64, i64* %RBP, align 8
  %3597 = add i64 %3596, -104
  %3598 = load i64, i64* %PC, align 8
  %3599 = add i64 %3598, 5
  store i64 %3599, i64* %PC, align 8
  %3600 = inttoptr i64 %3597 to double*
  %3601 = load double, double* %3600, align 8
  store double %3601, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3602 = add i64 %3596, -128
  %3603 = add i64 %3598, 10
  store i64 %3603, i64* %PC, align 8
  %3604 = inttoptr i64 %3602 to double*
  %3605 = load double, double* %3604, align 8
  %3606 = fmul double %3601, %3605
  store double %3606, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3607 = add i64 %3596, -112
  %3608 = add i64 %3598, 15
  store i64 %3608, i64* %PC, align 8
  %3609 = inttoptr i64 %3607 to double*
  %3610 = load double, double* %3609, align 8
  store double %3610, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %3611 = add i64 %3596, -120
  %3612 = add i64 %3598, 20
  store i64 %3612, i64* %PC, align 8
  %3613 = inttoptr i64 %3611 to double*
  %3614 = load double, double* %3613, align 8
  %3615 = fmul double %3610, %3614
  store double %3615, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %3616 = fadd double %3606, %3615
  store double %3616, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3617 = add i64 %3596, -16
  %3618 = add i64 %3598, 28
  store i64 %3618, i64* %PC, align 8
  %3619 = inttoptr i64 %3617 to i64*
  %3620 = load i64, i64* %3619, align 8
  store i64 %3620, i64* %RCX, align 8, !tbaa !2428
  %3621 = add i64 %3596, -40
  %3622 = add i64 %3598, 31
  store i64 %3622, i64* %PC, align 8
  %3623 = inttoptr i64 %3621 to i32*
  %3624 = load i32, i32* %3623, align 4
  %3625 = add i32 %3624, 1
  %3626 = zext i32 %3625 to i64
  store i64 %3626, i64* %RAX, align 8, !tbaa !2428
  %3627 = icmp eq i32 %3624, -1
  %3628 = icmp eq i32 %3625, 0
  %3629 = or i1 %3627, %3628
  %3630 = zext i1 %3629 to i8
  store i8 %3630, i8* %17, align 1, !tbaa !2433
  %3631 = and i32 %3625, 255
  %3632 = tail call i32 @llvm.ctpop.i32(i32 %3631) #10
  %3633 = trunc i32 %3632 to i8
  %3634 = and i8 %3633, 1
  %3635 = xor i8 %3634, 1
  store i8 %3635, i8* %24, align 1, !tbaa !2447
  %3636 = xor i32 %3624, %3625
  %3637 = lshr i32 %3636, 4
  %3638 = trunc i32 %3637 to i8
  %3639 = and i8 %3638, 1
  store i8 %3639, i8* %30, align 1, !tbaa !2451
  %3640 = zext i1 %3628 to i8
  store i8 %3640, i8* %33, align 1, !tbaa !2448
  %3641 = lshr i32 %3625, 31
  %3642 = trunc i32 %3641 to i8
  store i8 %3642, i8* %36, align 1, !tbaa !2449
  %3643 = lshr i32 %3624, 31
  %3644 = xor i32 %3641, %3643
  %3645 = add nuw nsw i32 %3644, %3641
  %3646 = icmp eq i32 %3645, 2
  %3647 = zext i1 %3646 to i8
  store i8 %3647, i8* %42, align 1, !tbaa !2450
  %3648 = sext i32 %3625 to i64
  store i64 %3648, i64* %RDX, align 8, !tbaa !2428
  %3649 = shl nsw i64 %3648, 3
  %3650 = add i64 %3649, %3620
  %3651 = add i64 %3598, 42
  store i64 %3651, i64* %PC, align 8
  %3652 = inttoptr i64 %3650 to double*
  store double %3616, double* %3652, align 8
  %3653 = load i64, i64* %RBP, align 8
  %3654 = add i64 %3653, -28
  %3655 = load i64, i64* %PC, align 8
  %3656 = add i64 %3655, 3
  store i64 %3656, i64* %PC, align 8
  %3657 = inttoptr i64 %3654 to i32*
  %3658 = load i32, i32* %3657, align 4
  %3659 = add i32 %3658, 2
  %3660 = zext i32 %3659 to i64
  store i64 %3660, i64* %RAX, align 8, !tbaa !2428
  %3661 = icmp ugt i32 %3658, -3
  %3662 = zext i1 %3661 to i8
  store i8 %3662, i8* %17, align 1, !tbaa !2433
  %3663 = and i32 %3659, 255
  %3664 = tail call i32 @llvm.ctpop.i32(i32 %3663) #10
  %3665 = trunc i32 %3664 to i8
  %3666 = and i8 %3665, 1
  %3667 = xor i8 %3666, 1
  store i8 %3667, i8* %24, align 1, !tbaa !2447
  %3668 = xor i32 %3658, %3659
  %3669 = lshr i32 %3668, 4
  %3670 = trunc i32 %3669 to i8
  %3671 = and i8 %3670, 1
  store i8 %3671, i8* %30, align 1, !tbaa !2451
  %3672 = icmp eq i32 %3659, 0
  %3673 = zext i1 %3672 to i8
  store i8 %3673, i8* %33, align 1, !tbaa !2448
  %3674 = lshr i32 %3659, 31
  %3675 = trunc i32 %3674 to i8
  store i8 %3675, i8* %36, align 1, !tbaa !2449
  %3676 = lshr i32 %3658, 31
  %3677 = xor i32 %3674, %3676
  %3678 = add nuw nsw i32 %3677, %3674
  %3679 = icmp eq i32 %3678, 2
  %3680 = zext i1 %3679 to i8
  store i8 %3680, i8* %42, align 1, !tbaa !2450
  %3681 = add i64 %3655, 9
  store i64 %3681, i64* %PC, align 8
  store i32 %3659, i32* %3657, align 4
  %3682 = load i64, i64* %PC, align 8
  %3683 = add i64 %3682, -781
  store i64 %3683, i64* %PC, align 8, !tbaa !2428
  br label %block_403910

block_403ca6:                                     ; preds = %block_403c90
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %3684 = load i64, i64* %RBP, align 8
  %3685 = add i64 %3684, -28
  %3686 = add i64 %1577, 13
  store i64 %3686, i64* %PC, align 8
  %3687 = inttoptr i64 %3685 to i32*
  %3688 = load i32, i32* %3687, align 4
  %3689 = zext i32 %3688 to i64
  store i64 %3689, i64* %RCX, align 8, !tbaa !2428
  %3690 = add i64 %3684, -8
  %3691 = add i64 %1577, 16
  store i64 %3691, i64* %PC, align 8
  %3692 = inttoptr i64 %3690 to i32*
  %3693 = load i32, i32* %3692, align 4
  %3694 = add i32 %3693, %3688
  %3695 = zext i32 %3694 to i64
  store i64 %3695, i64* %RCX, align 8, !tbaa !2428
  %3696 = icmp ult i32 %3694, %3688
  %3697 = icmp ult i32 %3694, %3693
  %3698 = or i1 %3696, %3697
  %3699 = zext i1 %3698 to i8
  store i8 %3699, i8* %17, align 1, !tbaa !2433
  %3700 = and i32 %3694, 255
  %3701 = tail call i32 @llvm.ctpop.i32(i32 %3700) #10
  %3702 = trunc i32 %3701 to i8
  %3703 = and i8 %3702, 1
  %3704 = xor i8 %3703, 1
  store i8 %3704, i8* %24, align 1, !tbaa !2447
  %3705 = xor i32 %3693, %3688
  %3706 = xor i32 %3705, %3694
  %3707 = lshr i32 %3706, 4
  %3708 = trunc i32 %3707 to i8
  %3709 = and i8 %3708, 1
  store i8 %3709, i8* %30, align 1, !tbaa !2451
  %3710 = icmp eq i32 %3694, 0
  %3711 = zext i1 %3710 to i8
  store i8 %3711, i8* %33, align 1, !tbaa !2448
  %3712 = lshr i32 %3694, 31
  %3713 = trunc i32 %3712 to i8
  store i8 %3713, i8* %36, align 1, !tbaa !2449
  %3714 = lshr i32 %3688, 31
  %3715 = lshr i32 %3693, 31
  %3716 = xor i32 %3712, %3714
  %3717 = xor i32 %3712, %3715
  %3718 = add nuw nsw i32 %3716, %3717
  %3719 = icmp eq i32 %3718, 2
  %3720 = zext i1 %3719 to i8
  store i8 %3720, i8* %42, align 1, !tbaa !2450
  %3721 = add i64 %3684, -32
  %3722 = add i64 %1577, 19
  store i64 %3722, i64* %PC, align 8
  %3723 = inttoptr i64 %3721 to i32*
  store i32 %3694, i32* %3723, align 4
  %3724 = load i64, i64* %RBP, align 8
  %3725 = add i64 %3724, -32
  %3726 = load i64, i64* %PC, align 8
  %3727 = add i64 %3726, 3
  store i64 %3727, i64* %PC, align 8
  %3728 = inttoptr i64 %3725 to i32*
  %3729 = load i32, i32* %3728, align 4
  %3730 = zext i32 %3729 to i64
  store i64 %3730, i64* %RCX, align 8, !tbaa !2428
  %3731 = add i64 %3724, -8
  %3732 = add i64 %3726, 6
  store i64 %3732, i64* %PC, align 8
  %3733 = inttoptr i64 %3731 to i32*
  %3734 = load i32, i32* %3733, align 4
  %3735 = add i32 %3734, %3729
  %3736 = zext i32 %3735 to i64
  store i64 %3736, i64* %RCX, align 8, !tbaa !2428
  %3737 = icmp ult i32 %3735, %3729
  %3738 = icmp ult i32 %3735, %3734
  %3739 = or i1 %3737, %3738
  %3740 = zext i1 %3739 to i8
  store i8 %3740, i8* %17, align 1, !tbaa !2433
  %3741 = and i32 %3735, 255
  %3742 = tail call i32 @llvm.ctpop.i32(i32 %3741) #10
  %3743 = trunc i32 %3742 to i8
  %3744 = and i8 %3743, 1
  %3745 = xor i8 %3744, 1
  store i8 %3745, i8* %24, align 1, !tbaa !2447
  %3746 = xor i32 %3734, %3729
  %3747 = xor i32 %3746, %3735
  %3748 = lshr i32 %3747, 4
  %3749 = trunc i32 %3748 to i8
  %3750 = and i8 %3749, 1
  store i8 %3750, i8* %30, align 1, !tbaa !2451
  %3751 = icmp eq i32 %3735, 0
  %3752 = zext i1 %3751 to i8
  store i8 %3752, i8* %33, align 1, !tbaa !2448
  %3753 = lshr i32 %3735, 31
  %3754 = trunc i32 %3753 to i8
  store i8 %3754, i8* %36, align 1, !tbaa !2449
  %3755 = lshr i32 %3729, 31
  %3756 = lshr i32 %3734, 31
  %3757 = xor i32 %3753, %3755
  %3758 = xor i32 %3753, %3756
  %3759 = add nuw nsw i32 %3757, %3758
  %3760 = icmp eq i32 %3759, 2
  %3761 = zext i1 %3760 to i8
  store i8 %3761, i8* %42, align 1, !tbaa !2450
  %3762 = add i64 %3724, -36
  %3763 = add i64 %3726, 9
  store i64 %3763, i64* %PC, align 8
  %3764 = inttoptr i64 %3762 to i32*
  store i32 %3735, i32* %3764, align 4
  %3765 = load i64, i64* %RBP, align 8
  %3766 = add i64 %3765, -36
  %3767 = load i64, i64* %PC, align 8
  %3768 = add i64 %3767, 3
  store i64 %3768, i64* %PC, align 8
  %3769 = inttoptr i64 %3766 to i32*
  %3770 = load i32, i32* %3769, align 4
  %3771 = zext i32 %3770 to i64
  store i64 %3771, i64* %RCX, align 8, !tbaa !2428
  %3772 = add i64 %3765, -8
  %3773 = add i64 %3767, 6
  store i64 %3773, i64* %PC, align 8
  %3774 = inttoptr i64 %3772 to i32*
  %3775 = load i32, i32* %3774, align 4
  %3776 = add i32 %3775, %3770
  %3777 = zext i32 %3776 to i64
  store i64 %3777, i64* %RCX, align 8, !tbaa !2428
  %3778 = icmp ult i32 %3776, %3770
  %3779 = icmp ult i32 %3776, %3775
  %3780 = or i1 %3778, %3779
  %3781 = zext i1 %3780 to i8
  store i8 %3781, i8* %17, align 1, !tbaa !2433
  %3782 = and i32 %3776, 255
  %3783 = tail call i32 @llvm.ctpop.i32(i32 %3782) #10
  %3784 = trunc i32 %3783 to i8
  %3785 = and i8 %3784, 1
  %3786 = xor i8 %3785, 1
  store i8 %3786, i8* %24, align 1, !tbaa !2447
  %3787 = xor i32 %3775, %3770
  %3788 = xor i32 %3787, %3776
  %3789 = lshr i32 %3788, 4
  %3790 = trunc i32 %3789 to i8
  %3791 = and i8 %3790, 1
  store i8 %3791, i8* %30, align 1, !tbaa !2451
  %3792 = icmp eq i32 %3776, 0
  %3793 = zext i1 %3792 to i8
  store i8 %3793, i8* %33, align 1, !tbaa !2448
  %3794 = lshr i32 %3776, 31
  %3795 = trunc i32 %3794 to i8
  store i8 %3795, i8* %36, align 1, !tbaa !2449
  %3796 = lshr i32 %3770, 31
  %3797 = lshr i32 %3775, 31
  %3798 = xor i32 %3794, %3796
  %3799 = xor i32 %3794, %3797
  %3800 = add nuw nsw i32 %3798, %3799
  %3801 = icmp eq i32 %3800, 2
  %3802 = zext i1 %3801 to i8
  store i8 %3802, i8* %42, align 1, !tbaa !2450
  %3803 = add i64 %3765, -40
  %3804 = add i64 %3767, 9
  store i64 %3804, i64* %PC, align 8
  %3805 = inttoptr i64 %3803 to i32*
  store i32 %3776, i32* %3805, align 4
  %3806 = load i64, i64* %RBP, align 8
  %3807 = add i64 %3806, -16
  %3808 = load i64, i64* %PC, align 8
  %3809 = add i64 %3808, 4
  store i64 %3809, i64* %PC, align 8
  %3810 = inttoptr i64 %3807 to i64*
  %3811 = load i64, i64* %3810, align 8
  store i64 %3811, i64* %RDX, align 8, !tbaa !2428
  %3812 = add i64 %3806, -28
  %3813 = add i64 %3808, 8
  store i64 %3813, i64* %PC, align 8
  %3814 = inttoptr i64 %3812 to i32*
  %3815 = load i32, i32* %3814, align 4
  %3816 = sext i32 %3815 to i64
  store i64 %3816, i64* %RSI, align 8, !tbaa !2428
  %3817 = shl nsw i64 %3816, 3
  %3818 = add i64 %3817, %3811
  %3819 = add i64 %3808, 13
  store i64 %3819, i64* %PC, align 8
  %3820 = inttoptr i64 %3818 to double*
  %3821 = load double, double* %3820, align 8
  store double %3821, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3822 = add i64 %3808, 17
  store i64 %3822, i64* %PC, align 8
  %3823 = load i64, i64* %3810, align 8
  store i64 %3823, i64* %RDX, align 8, !tbaa !2428
  %3824 = add i64 %3806, -32
  %3825 = add i64 %3808, 21
  store i64 %3825, i64* %PC, align 8
  %3826 = inttoptr i64 %3824 to i32*
  %3827 = load i32, i32* %3826, align 4
  %3828 = sext i32 %3827 to i64
  store i64 %3828, i64* %RSI, align 8, !tbaa !2428
  %3829 = shl nsw i64 %3828, 3
  %3830 = add i64 %3829, %3823
  %3831 = add i64 %3808, 26
  store i64 %3831, i64* %PC, align 8
  %3832 = inttoptr i64 %3830 to double*
  %3833 = load double, double* %3832, align 8
  %3834 = fadd double %3821, %3833
  store double %3834, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3835 = add i64 %3806, -120
  %3836 = add i64 %3808, 31
  store i64 %3836, i64* %PC, align 8
  %3837 = inttoptr i64 %3835 to double*
  store double %3834, double* %3837, align 8
  %3838 = load i64, i64* %RBP, align 8
  %3839 = add i64 %3838, -16
  %3840 = load i64, i64* %PC, align 8
  %3841 = add i64 %3840, 4
  store i64 %3841, i64* %PC, align 8
  %3842 = inttoptr i64 %3839 to i64*
  %3843 = load i64, i64* %3842, align 8
  store i64 %3843, i64* %RDX, align 8, !tbaa !2428
  %3844 = add i64 %3838, -28
  %3845 = add i64 %3840, 7
  store i64 %3845, i64* %PC, align 8
  %3846 = inttoptr i64 %3844 to i32*
  %3847 = load i32, i32* %3846, align 4
  %3848 = add i32 %3847, 1
  %3849 = zext i32 %3848 to i64
  store i64 %3849, i64* %RCX, align 8, !tbaa !2428
  %3850 = icmp eq i32 %3847, -1
  %3851 = icmp eq i32 %3848, 0
  %3852 = or i1 %3850, %3851
  %3853 = zext i1 %3852 to i8
  store i8 %3853, i8* %17, align 1, !tbaa !2433
  %3854 = and i32 %3848, 255
  %3855 = tail call i32 @llvm.ctpop.i32(i32 %3854) #10
  %3856 = trunc i32 %3855 to i8
  %3857 = and i8 %3856, 1
  %3858 = xor i8 %3857, 1
  store i8 %3858, i8* %24, align 1, !tbaa !2447
  %3859 = xor i32 %3847, %3848
  %3860 = lshr i32 %3859, 4
  %3861 = trunc i32 %3860 to i8
  %3862 = and i8 %3861, 1
  store i8 %3862, i8* %30, align 1, !tbaa !2451
  %3863 = zext i1 %3851 to i8
  store i8 %3863, i8* %33, align 1, !tbaa !2448
  %3864 = lshr i32 %3848, 31
  %3865 = trunc i32 %3864 to i8
  store i8 %3865, i8* %36, align 1, !tbaa !2449
  %3866 = lshr i32 %3847, 31
  %3867 = xor i32 %3864, %3866
  %3868 = add nuw nsw i32 %3867, %3864
  %3869 = icmp eq i32 %3868, 2
  %3870 = zext i1 %3869 to i8
  store i8 %3870, i8* %42, align 1, !tbaa !2450
  %3871 = sext i32 %3848 to i64
  store i64 %3871, i64* %RSI, align 8, !tbaa !2428
  %3872 = shl nsw i64 %3871, 3
  %3873 = add i64 %3872, %3843
  %3874 = add i64 %3840, 18
  store i64 %3874, i64* %PC, align 8
  %3875 = inttoptr i64 %3873 to double*
  %3876 = load double, double* %3875, align 8
  store double %3876, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3877 = add i64 %3840, 22
  store i64 %3877, i64* %PC, align 8
  %3878 = load i64, i64* %3842, align 8
  store i64 %3878, i64* %RDX, align 8, !tbaa !2428
  %3879 = add i64 %3838, -32
  %3880 = add i64 %3840, 25
  store i64 %3880, i64* %PC, align 8
  %3881 = inttoptr i64 %3879 to i32*
  %3882 = load i32, i32* %3881, align 4
  %3883 = add i32 %3882, 1
  %3884 = zext i32 %3883 to i64
  store i64 %3884, i64* %RCX, align 8, !tbaa !2428
  %3885 = icmp eq i32 %3882, -1
  %3886 = icmp eq i32 %3883, 0
  %3887 = or i1 %3885, %3886
  %3888 = zext i1 %3887 to i8
  store i8 %3888, i8* %17, align 1, !tbaa !2433
  %3889 = and i32 %3883, 255
  %3890 = tail call i32 @llvm.ctpop.i32(i32 %3889) #10
  %3891 = trunc i32 %3890 to i8
  %3892 = and i8 %3891, 1
  %3893 = xor i8 %3892, 1
  store i8 %3893, i8* %24, align 1, !tbaa !2447
  %3894 = xor i32 %3882, %3883
  %3895 = lshr i32 %3894, 4
  %3896 = trunc i32 %3895 to i8
  %3897 = and i8 %3896, 1
  store i8 %3897, i8* %30, align 1, !tbaa !2451
  %3898 = zext i1 %3886 to i8
  store i8 %3898, i8* %33, align 1, !tbaa !2448
  %3899 = lshr i32 %3883, 31
  %3900 = trunc i32 %3899 to i8
  store i8 %3900, i8* %36, align 1, !tbaa !2449
  %3901 = lshr i32 %3882, 31
  %3902 = xor i32 %3899, %3901
  %3903 = add nuw nsw i32 %3902, %3899
  %3904 = icmp eq i32 %3903, 2
  %3905 = zext i1 %3904 to i8
  store i8 %3905, i8* %42, align 1, !tbaa !2450
  %3906 = sext i32 %3883 to i64
  store i64 %3906, i64* %RSI, align 8, !tbaa !2428
  %3907 = shl nsw i64 %3906, 3
  %3908 = add i64 %3907, %3878
  %3909 = add i64 %3840, 36
  store i64 %3909, i64* %PC, align 8
  %3910 = inttoptr i64 %3908 to double*
  %3911 = load double, double* %3910, align 8
  %3912 = fadd double %3876, %3911
  store double %3912, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3913 = load i64, i64* %RBP, align 8
  %3914 = add i64 %3913, -128
  %3915 = add i64 %3840, 41
  store i64 %3915, i64* %PC, align 8
  %3916 = inttoptr i64 %3914 to double*
  store double %3912, double* %3916, align 8
  %3917 = load i64, i64* %RBP, align 8
  %3918 = add i64 %3917, -16
  %3919 = load i64, i64* %PC, align 8
  %3920 = add i64 %3919, 4
  store i64 %3920, i64* %PC, align 8
  %3921 = inttoptr i64 %3918 to i64*
  %3922 = load i64, i64* %3921, align 8
  store i64 %3922, i64* %RDX, align 8, !tbaa !2428
  %3923 = add i64 %3917, -28
  %3924 = add i64 %3919, 8
  store i64 %3924, i64* %PC, align 8
  %3925 = inttoptr i64 %3923 to i32*
  %3926 = load i32, i32* %3925, align 4
  %3927 = sext i32 %3926 to i64
  store i64 %3927, i64* %RSI, align 8, !tbaa !2428
  %3928 = shl nsw i64 %3927, 3
  %3929 = add i64 %3928, %3922
  %3930 = add i64 %3919, 13
  store i64 %3930, i64* %PC, align 8
  %3931 = inttoptr i64 %3929 to double*
  %3932 = load double, double* %3931, align 8
  store double %3932, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3933 = add i64 %3919, 17
  store i64 %3933, i64* %PC, align 8
  %3934 = load i64, i64* %3921, align 8
  store i64 %3934, i64* %RDX, align 8, !tbaa !2428
  %3935 = add i64 %3917, -32
  %3936 = add i64 %3919, 21
  store i64 %3936, i64* %PC, align 8
  %3937 = inttoptr i64 %3935 to i32*
  %3938 = load i32, i32* %3937, align 4
  %3939 = sext i32 %3938 to i64
  store i64 %3939, i64* %RSI, align 8, !tbaa !2428
  %3940 = shl nsw i64 %3939, 3
  %3941 = add i64 %3940, %3934
  %3942 = add i64 %3919, 26
  store i64 %3942, i64* %PC, align 8
  %3943 = inttoptr i64 %3941 to double*
  %3944 = load double, double* %3943, align 8
  %3945 = fsub double %3932, %3944
  store double %3945, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %3946 = add i64 %3917, -136
  %3947 = add i64 %3919, 34
  store i64 %3947, i64* %PC, align 8
  %3948 = inttoptr i64 %3946 to double*
  store double %3945, double* %3948, align 8
  %3949 = load i64, i64* %RBP, align 8
  %3950 = add i64 %3949, -16
  %3951 = load i64, i64* %PC, align 8
  %3952 = add i64 %3951, 4
  store i64 %3952, i64* %PC, align 8
  %3953 = inttoptr i64 %3950 to i64*
  %3954 = load i64, i64* %3953, align 8
  store i64 %3954, i64* %RDX, align 8, !tbaa !2428
  %3955 = add i64 %3949, -28
  %3956 = add i64 %3951, 7
  store i64 %3956, i64* %PC, align 8
  %3957 = inttoptr i64 %3955 to i32*
  %3958 = load i32, i32* %3957, align 4
  %3959 = add i32 %3958, 1
  %3960 = zext i32 %3959 to i64
  store i64 %3960, i64* %RCX, align 8, !tbaa !2428
  %3961 = icmp eq i32 %3958, -1
  %3962 = icmp eq i32 %3959, 0
  %3963 = or i1 %3961, %3962
  %3964 = zext i1 %3963 to i8
  store i8 %3964, i8* %17, align 1, !tbaa !2433
  %3965 = and i32 %3959, 255
  %3966 = tail call i32 @llvm.ctpop.i32(i32 %3965) #10
  %3967 = trunc i32 %3966 to i8
  %3968 = and i8 %3967, 1
  %3969 = xor i8 %3968, 1
  store i8 %3969, i8* %24, align 1, !tbaa !2447
  %3970 = xor i32 %3958, %3959
  %3971 = lshr i32 %3970, 4
  %3972 = trunc i32 %3971 to i8
  %3973 = and i8 %3972, 1
  store i8 %3973, i8* %30, align 1, !tbaa !2451
  %3974 = zext i1 %3962 to i8
  store i8 %3974, i8* %33, align 1, !tbaa !2448
  %3975 = lshr i32 %3959, 31
  %3976 = trunc i32 %3975 to i8
  store i8 %3976, i8* %36, align 1, !tbaa !2449
  %3977 = lshr i32 %3958, 31
  %3978 = xor i32 %3975, %3977
  %3979 = add nuw nsw i32 %3978, %3975
  %3980 = icmp eq i32 %3979, 2
  %3981 = zext i1 %3980 to i8
  store i8 %3981, i8* %42, align 1, !tbaa !2450
  %3982 = sext i32 %3959 to i64
  store i64 %3982, i64* %RSI, align 8, !tbaa !2428
  %3983 = shl nsw i64 %3982, 3
  %3984 = add i64 %3983, %3954
  %3985 = add i64 %3951, 18
  store i64 %3985, i64* %PC, align 8
  %3986 = inttoptr i64 %3984 to double*
  %3987 = load double, double* %3986, align 8
  store double %3987, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %3988 = add i64 %3951, 22
  store i64 %3988, i64* %PC, align 8
  %3989 = load i64, i64* %3953, align 8
  store i64 %3989, i64* %RDX, align 8, !tbaa !2428
  %3990 = add i64 %3949, -32
  %3991 = add i64 %3951, 25
  store i64 %3991, i64* %PC, align 8
  %3992 = inttoptr i64 %3990 to i32*
  %3993 = load i32, i32* %3992, align 4
  %3994 = add i32 %3993, 1
  %3995 = zext i32 %3994 to i64
  store i64 %3995, i64* %RCX, align 8, !tbaa !2428
  %3996 = icmp eq i32 %3993, -1
  %3997 = icmp eq i32 %3994, 0
  %3998 = or i1 %3996, %3997
  %3999 = zext i1 %3998 to i8
  store i8 %3999, i8* %17, align 1, !tbaa !2433
  %4000 = and i32 %3994, 255
  %4001 = tail call i32 @llvm.ctpop.i32(i32 %4000) #10
  %4002 = trunc i32 %4001 to i8
  %4003 = and i8 %4002, 1
  %4004 = xor i8 %4003, 1
  store i8 %4004, i8* %24, align 1, !tbaa !2447
  %4005 = xor i32 %3993, %3994
  %4006 = lshr i32 %4005, 4
  %4007 = trunc i32 %4006 to i8
  %4008 = and i8 %4007, 1
  store i8 %4008, i8* %30, align 1, !tbaa !2451
  %4009 = zext i1 %3997 to i8
  store i8 %4009, i8* %33, align 1, !tbaa !2448
  %4010 = lshr i32 %3994, 31
  %4011 = trunc i32 %4010 to i8
  store i8 %4011, i8* %36, align 1, !tbaa !2449
  %4012 = lshr i32 %3993, 31
  %4013 = xor i32 %4010, %4012
  %4014 = add nuw nsw i32 %4013, %4010
  %4015 = icmp eq i32 %4014, 2
  %4016 = zext i1 %4015 to i8
  store i8 %4016, i8* %42, align 1, !tbaa !2450
  %4017 = sext i32 %3994 to i64
  store i64 %4017, i64* %RSI, align 8, !tbaa !2428
  %4018 = shl nsw i64 %4017, 3
  %4019 = add i64 %4018, %3989
  %4020 = add i64 %3951, 36
  store i64 %4020, i64* %PC, align 8
  %4021 = inttoptr i64 %4019 to double*
  %4022 = load double, double* %4021, align 8
  %4023 = fsub double %3987, %4022
  store double %4023, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4024 = load i64, i64* %RBP, align 8
  %4025 = add i64 %4024, -144
  %4026 = add i64 %3951, 44
  store i64 %4026, i64* %PC, align 8
  %4027 = inttoptr i64 %4025 to double*
  store double %4023, double* %4027, align 8
  %4028 = load i64, i64* %RBP, align 8
  %4029 = add i64 %4028, -16
  %4030 = load i64, i64* %PC, align 8
  %4031 = add i64 %4030, 4
  store i64 %4031, i64* %PC, align 8
  %4032 = inttoptr i64 %4029 to i64*
  %4033 = load i64, i64* %4032, align 8
  store i64 %4033, i64* %RDX, align 8, !tbaa !2428
  %4034 = add i64 %4028, -36
  %4035 = add i64 %4030, 8
  store i64 %4035, i64* %PC, align 8
  %4036 = inttoptr i64 %4034 to i32*
  %4037 = load i32, i32* %4036, align 4
  %4038 = sext i32 %4037 to i64
  store i64 %4038, i64* %RSI, align 8, !tbaa !2428
  %4039 = shl nsw i64 %4038, 3
  %4040 = add i64 %4039, %4033
  %4041 = add i64 %4030, 13
  store i64 %4041, i64* %PC, align 8
  %4042 = inttoptr i64 %4040 to double*
  %4043 = load double, double* %4042, align 8
  store double %4043, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4044 = add i64 %4030, 17
  store i64 %4044, i64* %PC, align 8
  %4045 = load i64, i64* %4032, align 8
  store i64 %4045, i64* %RDX, align 8, !tbaa !2428
  %4046 = add i64 %4028, -40
  %4047 = add i64 %4030, 21
  store i64 %4047, i64* %PC, align 8
  %4048 = inttoptr i64 %4046 to i32*
  %4049 = load i32, i32* %4048, align 4
  %4050 = sext i32 %4049 to i64
  store i64 %4050, i64* %RSI, align 8, !tbaa !2428
  %4051 = shl nsw i64 %4050, 3
  %4052 = add i64 %4051, %4045
  %4053 = add i64 %4030, 26
  store i64 %4053, i64* %PC, align 8
  %4054 = inttoptr i64 %4052 to double*
  %4055 = load double, double* %4054, align 8
  %4056 = fadd double %4043, %4055
  store double %4056, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4057 = add i64 %4028, -152
  %4058 = add i64 %4030, 34
  store i64 %4058, i64* %PC, align 8
  %4059 = inttoptr i64 %4057 to double*
  store double %4056, double* %4059, align 8
  %4060 = load i64, i64* %RBP, align 8
  %4061 = add i64 %4060, -16
  %4062 = load i64, i64* %PC, align 8
  %4063 = add i64 %4062, 4
  store i64 %4063, i64* %PC, align 8
  %4064 = inttoptr i64 %4061 to i64*
  %4065 = load i64, i64* %4064, align 8
  store i64 %4065, i64* %RDX, align 8, !tbaa !2428
  %4066 = add i64 %4060, -36
  %4067 = add i64 %4062, 7
  store i64 %4067, i64* %PC, align 8
  %4068 = inttoptr i64 %4066 to i32*
  %4069 = load i32, i32* %4068, align 4
  %4070 = add i32 %4069, 1
  %4071 = zext i32 %4070 to i64
  store i64 %4071, i64* %RCX, align 8, !tbaa !2428
  %4072 = icmp eq i32 %4069, -1
  %4073 = icmp eq i32 %4070, 0
  %4074 = or i1 %4072, %4073
  %4075 = zext i1 %4074 to i8
  store i8 %4075, i8* %17, align 1, !tbaa !2433
  %4076 = and i32 %4070, 255
  %4077 = tail call i32 @llvm.ctpop.i32(i32 %4076) #10
  %4078 = trunc i32 %4077 to i8
  %4079 = and i8 %4078, 1
  %4080 = xor i8 %4079, 1
  store i8 %4080, i8* %24, align 1, !tbaa !2447
  %4081 = xor i32 %4069, %4070
  %4082 = lshr i32 %4081, 4
  %4083 = trunc i32 %4082 to i8
  %4084 = and i8 %4083, 1
  store i8 %4084, i8* %30, align 1, !tbaa !2451
  %4085 = zext i1 %4073 to i8
  store i8 %4085, i8* %33, align 1, !tbaa !2448
  %4086 = lshr i32 %4070, 31
  %4087 = trunc i32 %4086 to i8
  store i8 %4087, i8* %36, align 1, !tbaa !2449
  %4088 = lshr i32 %4069, 31
  %4089 = xor i32 %4086, %4088
  %4090 = add nuw nsw i32 %4089, %4086
  %4091 = icmp eq i32 %4090, 2
  %4092 = zext i1 %4091 to i8
  store i8 %4092, i8* %42, align 1, !tbaa !2450
  %4093 = sext i32 %4070 to i64
  store i64 %4093, i64* %RSI, align 8, !tbaa !2428
  %4094 = shl nsw i64 %4093, 3
  %4095 = add i64 %4094, %4065
  %4096 = add i64 %4062, 18
  store i64 %4096, i64* %PC, align 8
  %4097 = inttoptr i64 %4095 to double*
  %4098 = load double, double* %4097, align 8
  store double %4098, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4099 = add i64 %4062, 22
  store i64 %4099, i64* %PC, align 8
  %4100 = load i64, i64* %4064, align 8
  store i64 %4100, i64* %RDX, align 8, !tbaa !2428
  %4101 = add i64 %4060, -40
  %4102 = add i64 %4062, 25
  store i64 %4102, i64* %PC, align 8
  %4103 = inttoptr i64 %4101 to i32*
  %4104 = load i32, i32* %4103, align 4
  %4105 = add i32 %4104, 1
  %4106 = zext i32 %4105 to i64
  store i64 %4106, i64* %RCX, align 8, !tbaa !2428
  %4107 = icmp eq i32 %4104, -1
  %4108 = icmp eq i32 %4105, 0
  %4109 = or i1 %4107, %4108
  %4110 = zext i1 %4109 to i8
  store i8 %4110, i8* %17, align 1, !tbaa !2433
  %4111 = and i32 %4105, 255
  %4112 = tail call i32 @llvm.ctpop.i32(i32 %4111) #10
  %4113 = trunc i32 %4112 to i8
  %4114 = and i8 %4113, 1
  %4115 = xor i8 %4114, 1
  store i8 %4115, i8* %24, align 1, !tbaa !2447
  %4116 = xor i32 %4104, %4105
  %4117 = lshr i32 %4116, 4
  %4118 = trunc i32 %4117 to i8
  %4119 = and i8 %4118, 1
  store i8 %4119, i8* %30, align 1, !tbaa !2451
  %4120 = zext i1 %4108 to i8
  store i8 %4120, i8* %33, align 1, !tbaa !2448
  %4121 = lshr i32 %4105, 31
  %4122 = trunc i32 %4121 to i8
  store i8 %4122, i8* %36, align 1, !tbaa !2449
  %4123 = lshr i32 %4104, 31
  %4124 = xor i32 %4121, %4123
  %4125 = add nuw nsw i32 %4124, %4121
  %4126 = icmp eq i32 %4125, 2
  %4127 = zext i1 %4126 to i8
  store i8 %4127, i8* %42, align 1, !tbaa !2450
  %4128 = sext i32 %4105 to i64
  store i64 %4128, i64* %RSI, align 8, !tbaa !2428
  %4129 = shl nsw i64 %4128, 3
  %4130 = add i64 %4129, %4100
  %4131 = add i64 %4062, 36
  store i64 %4131, i64* %PC, align 8
  %4132 = inttoptr i64 %4130 to double*
  %4133 = load double, double* %4132, align 8
  %4134 = fadd double %4098, %4133
  store double %4134, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4135 = load i64, i64* %RBP, align 8
  %4136 = add i64 %4135, -160
  %4137 = add i64 %4062, 44
  store i64 %4137, i64* %PC, align 8
  %4138 = inttoptr i64 %4136 to double*
  store double %4134, double* %4138, align 8
  %4139 = load i64, i64* %RBP, align 8
  %4140 = add i64 %4139, -16
  %4141 = load i64, i64* %PC, align 8
  %4142 = add i64 %4141, 4
  store i64 %4142, i64* %PC, align 8
  %4143 = inttoptr i64 %4140 to i64*
  %4144 = load i64, i64* %4143, align 8
  store i64 %4144, i64* %RDX, align 8, !tbaa !2428
  %4145 = add i64 %4139, -36
  %4146 = add i64 %4141, 8
  store i64 %4146, i64* %PC, align 8
  %4147 = inttoptr i64 %4145 to i32*
  %4148 = load i32, i32* %4147, align 4
  %4149 = sext i32 %4148 to i64
  store i64 %4149, i64* %RSI, align 8, !tbaa !2428
  %4150 = shl nsw i64 %4149, 3
  %4151 = add i64 %4150, %4144
  %4152 = add i64 %4141, 13
  store i64 %4152, i64* %PC, align 8
  %4153 = inttoptr i64 %4151 to double*
  %4154 = load double, double* %4153, align 8
  store double %4154, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4155 = add i64 %4141, 17
  store i64 %4155, i64* %PC, align 8
  %4156 = load i64, i64* %4143, align 8
  store i64 %4156, i64* %RDX, align 8, !tbaa !2428
  %4157 = add i64 %4139, -40
  %4158 = add i64 %4141, 21
  store i64 %4158, i64* %PC, align 8
  %4159 = inttoptr i64 %4157 to i32*
  %4160 = load i32, i32* %4159, align 4
  %4161 = sext i32 %4160 to i64
  store i64 %4161, i64* %RSI, align 8, !tbaa !2428
  %4162 = shl nsw i64 %4161, 3
  %4163 = add i64 %4162, %4156
  %4164 = add i64 %4141, 26
  store i64 %4164, i64* %PC, align 8
  %4165 = inttoptr i64 %4163 to double*
  %4166 = load double, double* %4165, align 8
  %4167 = fsub double %4154, %4166
  store double %4167, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4168 = add i64 %4139, -168
  %4169 = add i64 %4141, 34
  store i64 %4169, i64* %PC, align 8
  %4170 = inttoptr i64 %4168 to double*
  store double %4167, double* %4170, align 8
  %4171 = load i64, i64* %RBP, align 8
  %4172 = add i64 %4171, -16
  %4173 = load i64, i64* %PC, align 8
  %4174 = add i64 %4173, 4
  store i64 %4174, i64* %PC, align 8
  %4175 = inttoptr i64 %4172 to i64*
  %4176 = load i64, i64* %4175, align 8
  store i64 %4176, i64* %RDX, align 8, !tbaa !2428
  %4177 = add i64 %4171, -36
  %4178 = add i64 %4173, 7
  store i64 %4178, i64* %PC, align 8
  %4179 = inttoptr i64 %4177 to i32*
  %4180 = load i32, i32* %4179, align 4
  %4181 = add i32 %4180, 1
  %4182 = zext i32 %4181 to i64
  store i64 %4182, i64* %RCX, align 8, !tbaa !2428
  %4183 = icmp eq i32 %4180, -1
  %4184 = icmp eq i32 %4181, 0
  %4185 = or i1 %4183, %4184
  %4186 = zext i1 %4185 to i8
  store i8 %4186, i8* %17, align 1, !tbaa !2433
  %4187 = and i32 %4181, 255
  %4188 = tail call i32 @llvm.ctpop.i32(i32 %4187) #10
  %4189 = trunc i32 %4188 to i8
  %4190 = and i8 %4189, 1
  %4191 = xor i8 %4190, 1
  store i8 %4191, i8* %24, align 1, !tbaa !2447
  %4192 = xor i32 %4180, %4181
  %4193 = lshr i32 %4192, 4
  %4194 = trunc i32 %4193 to i8
  %4195 = and i8 %4194, 1
  store i8 %4195, i8* %30, align 1, !tbaa !2451
  %4196 = zext i1 %4184 to i8
  store i8 %4196, i8* %33, align 1, !tbaa !2448
  %4197 = lshr i32 %4181, 31
  %4198 = trunc i32 %4197 to i8
  store i8 %4198, i8* %36, align 1, !tbaa !2449
  %4199 = lshr i32 %4180, 31
  %4200 = xor i32 %4197, %4199
  %4201 = add nuw nsw i32 %4200, %4197
  %4202 = icmp eq i32 %4201, 2
  %4203 = zext i1 %4202 to i8
  store i8 %4203, i8* %42, align 1, !tbaa !2450
  %4204 = sext i32 %4181 to i64
  store i64 %4204, i64* %RSI, align 8, !tbaa !2428
  %4205 = shl nsw i64 %4204, 3
  %4206 = add i64 %4205, %4176
  %4207 = add i64 %4173, 18
  store i64 %4207, i64* %PC, align 8
  %4208 = inttoptr i64 %4206 to double*
  %4209 = load double, double* %4208, align 8
  store double %4209, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4210 = add i64 %4173, 22
  store i64 %4210, i64* %PC, align 8
  %4211 = load i64, i64* %4175, align 8
  store i64 %4211, i64* %RDX, align 8, !tbaa !2428
  %4212 = add i64 %4171, -40
  %4213 = add i64 %4173, 25
  store i64 %4213, i64* %PC, align 8
  %4214 = inttoptr i64 %4212 to i32*
  %4215 = load i32, i32* %4214, align 4
  %4216 = add i32 %4215, 1
  %4217 = zext i32 %4216 to i64
  store i64 %4217, i64* %RCX, align 8, !tbaa !2428
  %4218 = icmp eq i32 %4215, -1
  %4219 = icmp eq i32 %4216, 0
  %4220 = or i1 %4218, %4219
  %4221 = zext i1 %4220 to i8
  store i8 %4221, i8* %17, align 1, !tbaa !2433
  %4222 = and i32 %4216, 255
  %4223 = tail call i32 @llvm.ctpop.i32(i32 %4222) #10
  %4224 = trunc i32 %4223 to i8
  %4225 = and i8 %4224, 1
  %4226 = xor i8 %4225, 1
  store i8 %4226, i8* %24, align 1, !tbaa !2447
  %4227 = xor i32 %4215, %4216
  %4228 = lshr i32 %4227, 4
  %4229 = trunc i32 %4228 to i8
  %4230 = and i8 %4229, 1
  store i8 %4230, i8* %30, align 1, !tbaa !2451
  %4231 = zext i1 %4219 to i8
  store i8 %4231, i8* %33, align 1, !tbaa !2448
  %4232 = lshr i32 %4216, 31
  %4233 = trunc i32 %4232 to i8
  store i8 %4233, i8* %36, align 1, !tbaa !2449
  %4234 = lshr i32 %4215, 31
  %4235 = xor i32 %4232, %4234
  %4236 = add nuw nsw i32 %4235, %4232
  %4237 = icmp eq i32 %4236, 2
  %4238 = zext i1 %4237 to i8
  store i8 %4238, i8* %42, align 1, !tbaa !2450
  %4239 = sext i32 %4216 to i64
  store i64 %4239, i64* %RSI, align 8, !tbaa !2428
  %4240 = shl nsw i64 %4239, 3
  %4241 = add i64 %4240, %4211
  %4242 = add i64 %4173, 36
  store i64 %4242, i64* %PC, align 8
  %4243 = inttoptr i64 %4241 to double*
  %4244 = load double, double* %4243, align 8
  %4245 = fsub double %4209, %4244
  store double %4245, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4246 = load i64, i64* %RBP, align 8
  %4247 = add i64 %4246, -176
  %4248 = add i64 %4173, 44
  store i64 %4248, i64* %PC, align 8
  %4249 = inttoptr i64 %4247 to double*
  store double %4245, double* %4249, align 8
  %4250 = load i64, i64* %RBP, align 8
  %4251 = add i64 %4250, -120
  %4252 = load i64, i64* %PC, align 8
  %4253 = add i64 %4252, 5
  store i64 %4253, i64* %PC, align 8
  %4254 = inttoptr i64 %4251 to double*
  %4255 = load double, double* %4254, align 8
  store double %4255, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4256 = add i64 %4250, -152
  %4257 = add i64 %4252, 13
  store i64 %4257, i64* %PC, align 8
  %4258 = inttoptr i64 %4256 to double*
  %4259 = load double, double* %4258, align 8
  %4260 = fadd double %4255, %4259
  store double %4260, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4261 = add i64 %4250, -16
  %4262 = add i64 %4252, 17
  store i64 %4262, i64* %PC, align 8
  %4263 = inttoptr i64 %4261 to i64*
  %4264 = load i64, i64* %4263, align 8
  store i64 %4264, i64* %RDX, align 8, !tbaa !2428
  %4265 = add i64 %4250, -28
  %4266 = add i64 %4252, 21
  store i64 %4266, i64* %PC, align 8
  %4267 = inttoptr i64 %4265 to i32*
  %4268 = load i32, i32* %4267, align 4
  %4269 = sext i32 %4268 to i64
  store i64 %4269, i64* %RSI, align 8, !tbaa !2428
  %4270 = shl nsw i64 %4269, 3
  %4271 = add i64 %4270, %4264
  %4272 = add i64 %4252, 26
  store i64 %4272, i64* %PC, align 8
  %4273 = inttoptr i64 %4271 to double*
  store double %4260, double* %4273, align 8
  %4274 = load i64, i64* %RBP, align 8
  %4275 = add i64 %4274, -128
  %4276 = load i64, i64* %PC, align 8
  %4277 = add i64 %4276, 5
  store i64 %4277, i64* %PC, align 8
  %4278 = inttoptr i64 %4275 to double*
  %4279 = load double, double* %4278, align 8
  store double %4279, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4280 = add i64 %4274, -160
  %4281 = add i64 %4276, 13
  store i64 %4281, i64* %PC, align 8
  %4282 = inttoptr i64 %4280 to double*
  %4283 = load double, double* %4282, align 8
  %4284 = fadd double %4279, %4283
  store double %4284, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4285 = add i64 %4274, -16
  %4286 = add i64 %4276, 17
  store i64 %4286, i64* %PC, align 8
  %4287 = inttoptr i64 %4285 to i64*
  %4288 = load i64, i64* %4287, align 8
  store i64 %4288, i64* %RDX, align 8, !tbaa !2428
  %4289 = add i64 %4274, -28
  %4290 = add i64 %4276, 20
  store i64 %4290, i64* %PC, align 8
  %4291 = inttoptr i64 %4289 to i32*
  %4292 = load i32, i32* %4291, align 4
  %4293 = add i32 %4292, 1
  %4294 = zext i32 %4293 to i64
  store i64 %4294, i64* %RCX, align 8, !tbaa !2428
  %4295 = icmp eq i32 %4292, -1
  %4296 = icmp eq i32 %4293, 0
  %4297 = or i1 %4295, %4296
  %4298 = zext i1 %4297 to i8
  store i8 %4298, i8* %17, align 1, !tbaa !2433
  %4299 = and i32 %4293, 255
  %4300 = tail call i32 @llvm.ctpop.i32(i32 %4299) #10
  %4301 = trunc i32 %4300 to i8
  %4302 = and i8 %4301, 1
  %4303 = xor i8 %4302, 1
  store i8 %4303, i8* %24, align 1, !tbaa !2447
  %4304 = xor i32 %4292, %4293
  %4305 = lshr i32 %4304, 4
  %4306 = trunc i32 %4305 to i8
  %4307 = and i8 %4306, 1
  store i8 %4307, i8* %30, align 1, !tbaa !2451
  %4308 = zext i1 %4296 to i8
  store i8 %4308, i8* %33, align 1, !tbaa !2448
  %4309 = lshr i32 %4293, 31
  %4310 = trunc i32 %4309 to i8
  store i8 %4310, i8* %36, align 1, !tbaa !2449
  %4311 = lshr i32 %4292, 31
  %4312 = xor i32 %4309, %4311
  %4313 = add nuw nsw i32 %4312, %4309
  %4314 = icmp eq i32 %4313, 2
  %4315 = zext i1 %4314 to i8
  store i8 %4315, i8* %42, align 1, !tbaa !2450
  %4316 = sext i32 %4293 to i64
  store i64 %4316, i64* %RSI, align 8, !tbaa !2428
  %4317 = shl nsw i64 %4316, 3
  %4318 = add i64 %4317, %4288
  %4319 = add i64 %4276, 31
  store i64 %4319, i64* %PC, align 8
  %4320 = inttoptr i64 %4318 to double*
  store double %4284, double* %4320, align 8
  %4321 = load i64, i64* %RBP, align 8
  %4322 = add i64 %4321, -152
  %4323 = load i64, i64* %PC, align 8
  %4324 = add i64 %4323, 8
  store i64 %4324, i64* %PC, align 8
  %4325 = inttoptr i64 %4322 to double*
  %4326 = load double, double* %4325, align 8
  store double %4326, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4327 = add i64 %4321, -120
  %4328 = add i64 %4323, 13
  store i64 %4328, i64* %PC, align 8
  %4329 = inttoptr i64 %4327 to double*
  %4330 = load double, double* %4329, align 8
  %4331 = fsub double %4330, %4326
  store double %4331, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %4332 = add i64 %4323, 22
  store i64 %4332, i64* %PC, align 8
  store double %4331, double* %4329, align 8
  %4333 = load i64, i64* %RBP, align 8
  %4334 = add i64 %4333, -160
  %4335 = load i64, i64* %PC, align 8
  %4336 = add i64 %4335, 8
  store i64 %4336, i64* %PC, align 8
  %4337 = inttoptr i64 %4334 to double*
  %4338 = load double, double* %4337, align 8
  store double %4338, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4339 = add i64 %4333, -128
  %4340 = add i64 %4335, 13
  store i64 %4340, i64* %PC, align 8
  %4341 = inttoptr i64 %4339 to double*
  %4342 = load double, double* %4341, align 8
  %4343 = fsub double %4342, %4338
  store double %4343, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %4344 = add i64 %4335, 22
  store i64 %4344, i64* %PC, align 8
  store double %4343, double* %4341, align 8
  %4345 = load i64, i64* %RBP, align 8
  %4346 = add i64 %4345, -96
  %4347 = load i64, i64* %PC, align 8
  %4348 = add i64 %4347, 5
  store i64 %4348, i64* %PC, align 8
  %4349 = inttoptr i64 %4346 to i64*
  %4350 = load i64, i64* %4349, align 8
  %4351 = load i64, i64* %RAX, align 8
  %4352 = xor i64 %4351, %4350
  store i64 %4352, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %17, align 1, !tbaa !2433
  %4353 = trunc i64 %4352 to i32
  %4354 = and i32 %4353, 255
  %4355 = tail call i32 @llvm.ctpop.i32(i32 %4354) #10
  %4356 = trunc i32 %4355 to i8
  %4357 = and i8 %4356, 1
  %4358 = xor i8 %4357, 1
  store i8 %4358, i8* %24, align 1, !tbaa !2447
  %4359 = icmp eq i64 %4352, 0
  %4360 = zext i1 %4359 to i8
  store i8 %4360, i8* %33, align 1, !tbaa !2448
  %4361 = lshr i64 %4352, 63
  %4362 = trunc i64 %4361 to i8
  store i8 %4362, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i64 %4352, i64* %276, align 1, !tbaa !2428
  store i64 0, i64* %95, align 1, !tbaa !2428
  %4363 = add i64 %4345, -120
  %4364 = add i64 %4347, 23
  store i64 %4364, i64* %PC, align 8
  %4365 = bitcast i64 %4352 to double
  %4366 = inttoptr i64 %4363 to double*
  %4367 = load double, double* %4366, align 8
  %4368 = fmul double %4365, %4367
  store double %4368, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4369 = add i64 %4345, -88
  %4370 = add i64 %4347, 28
  store i64 %4370, i64* %PC, align 8
  %4371 = inttoptr i64 %4369 to double*
  %4372 = load double, double* %4371, align 8
  store double %4372, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %4373 = add i64 %4345, -128
  %4374 = add i64 %4347, 33
  store i64 %4374, i64* %PC, align 8
  %4375 = inttoptr i64 %4373 to double*
  %4376 = load double, double* %4375, align 8
  %4377 = fmul double %4372, %4376
  store double %4377, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %4378 = fsub double %4368, %4377
  store double %4378, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4379 = add i64 %4345, -16
  %4380 = add i64 %4347, 41
  store i64 %4380, i64* %PC, align 8
  %4381 = inttoptr i64 %4379 to i64*
  %4382 = load i64, i64* %4381, align 8
  store i64 %4382, i64* %RDX, align 8, !tbaa !2428
  %4383 = add i64 %4345, -36
  %4384 = add i64 %4347, 45
  store i64 %4384, i64* %PC, align 8
  %4385 = inttoptr i64 %4383 to i32*
  %4386 = load i32, i32* %4385, align 4
  %4387 = sext i32 %4386 to i64
  store i64 %4387, i64* %RSI, align 8, !tbaa !2428
  %4388 = shl nsw i64 %4387, 3
  %4389 = add i64 %4388, %4382
  %4390 = add i64 %4347, 50
  store i64 %4390, i64* %PC, align 8
  %4391 = inttoptr i64 %4389 to double*
  store double %4378, double* %4391, align 8
  %4392 = load i64, i64* %RBP, align 8
  %4393 = add i64 %4392, -96
  %4394 = load i64, i64* %PC, align 8
  %4395 = add i64 %4394, 5
  store i64 %4395, i64* %PC, align 8
  %4396 = inttoptr i64 %4393 to i64*
  %4397 = load i64, i64* %4396, align 8
  %4398 = load i64, i64* %RAX, align 8
  %4399 = xor i64 %4398, %4397
  store i64 %4399, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %17, align 1, !tbaa !2433
  %4400 = trunc i64 %4399 to i32
  %4401 = and i32 %4400, 255
  %4402 = tail call i32 @llvm.ctpop.i32(i32 %4401) #10
  %4403 = trunc i32 %4402 to i8
  %4404 = and i8 %4403, 1
  %4405 = xor i8 %4404, 1
  store i8 %4405, i8* %24, align 1, !tbaa !2447
  %4406 = icmp eq i64 %4399, 0
  %4407 = zext i1 %4406 to i8
  store i8 %4407, i8* %33, align 1, !tbaa !2448
  %4408 = lshr i64 %4399, 63
  %4409 = trunc i64 %4408 to i8
  store i8 %4409, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2451
  store i64 %4399, i64* %276, align 1, !tbaa !2428
  store i64 0, i64* %95, align 1, !tbaa !2428
  %4410 = add i64 %4392, -128
  %4411 = add i64 %4394, 23
  store i64 %4411, i64* %PC, align 8
  %4412 = bitcast i64 %4399 to double
  %4413 = inttoptr i64 %4410 to double*
  %4414 = load double, double* %4413, align 8
  %4415 = fmul double %4412, %4414
  store double %4415, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4416 = add i64 %4392, -88
  %4417 = add i64 %4394, 28
  store i64 %4417, i64* %PC, align 8
  %4418 = inttoptr i64 %4416 to double*
  %4419 = load double, double* %4418, align 8
  store double %4419, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %4420 = add i64 %4392, -120
  %4421 = add i64 %4394, 33
  store i64 %4421, i64* %PC, align 8
  %4422 = inttoptr i64 %4420 to double*
  %4423 = load double, double* %4422, align 8
  %4424 = fmul double %4419, %4423
  store double %4424, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %4425 = fadd double %4415, %4424
  store double %4425, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4426 = add i64 %4392, -16
  %4427 = add i64 %4394, 41
  store i64 %4427, i64* %PC, align 8
  %4428 = inttoptr i64 %4426 to i64*
  %4429 = load i64, i64* %4428, align 8
  store i64 %4429, i64* %RAX, align 8, !tbaa !2428
  %4430 = add i64 %4392, -36
  %4431 = add i64 %4394, 44
  store i64 %4431, i64* %PC, align 8
  %4432 = inttoptr i64 %4430 to i32*
  %4433 = load i32, i32* %4432, align 4
  %4434 = add i32 %4433, 1
  %4435 = zext i32 %4434 to i64
  store i64 %4435, i64* %RCX, align 8, !tbaa !2428
  %4436 = icmp eq i32 %4433, -1
  %4437 = icmp eq i32 %4434, 0
  %4438 = or i1 %4436, %4437
  %4439 = zext i1 %4438 to i8
  store i8 %4439, i8* %17, align 1, !tbaa !2433
  %4440 = and i32 %4434, 255
  %4441 = tail call i32 @llvm.ctpop.i32(i32 %4440) #10
  %4442 = trunc i32 %4441 to i8
  %4443 = and i8 %4442, 1
  %4444 = xor i8 %4443, 1
  store i8 %4444, i8* %24, align 1, !tbaa !2447
  %4445 = xor i32 %4433, %4434
  %4446 = lshr i32 %4445, 4
  %4447 = trunc i32 %4446 to i8
  %4448 = and i8 %4447, 1
  store i8 %4448, i8* %30, align 1, !tbaa !2451
  %4449 = zext i1 %4437 to i8
  store i8 %4449, i8* %33, align 1, !tbaa !2448
  %4450 = lshr i32 %4434, 31
  %4451 = trunc i32 %4450 to i8
  store i8 %4451, i8* %36, align 1, !tbaa !2449
  %4452 = lshr i32 %4433, 31
  %4453 = xor i32 %4450, %4452
  %4454 = add nuw nsw i32 %4453, %4450
  %4455 = icmp eq i32 %4454, 2
  %4456 = zext i1 %4455 to i8
  store i8 %4456, i8* %42, align 1, !tbaa !2450
  %4457 = sext i32 %4434 to i64
  store i64 %4457, i64* %RDX, align 8, !tbaa !2428
  %4458 = shl nsw i64 %4457, 3
  %4459 = add i64 %4458, %4429
  %4460 = add i64 %4394, 55
  store i64 %4460, i64* %PC, align 8
  %4461 = inttoptr i64 %4459 to double*
  store double %4425, double* %4461, align 8
  %4462 = load i64, i64* %RBP, align 8
  %4463 = add i64 %4462, -136
  %4464 = load i64, i64* %PC, align 8
  %4465 = add i64 %4464, 8
  store i64 %4465, i64* %PC, align 8
  %4466 = inttoptr i64 %4463 to double*
  %4467 = load double, double* %4466, align 8
  store double %4467, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4468 = add i64 %4462, -176
  %4469 = add i64 %4464, 16
  store i64 %4469, i64* %PC, align 8
  %4470 = inttoptr i64 %4468 to double*
  %4471 = load double, double* %4470, align 8
  %4472 = fsub double %4467, %4471
  store double %4472, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4473 = add i64 %4462, -120
  %4474 = add i64 %4464, 21
  store i64 %4474, i64* %PC, align 8
  %4475 = inttoptr i64 %4473 to double*
  store double %4472, double* %4475, align 8
  %4476 = load i64, i64* %RBP, align 8
  %4477 = add i64 %4476, -144
  %4478 = load i64, i64* %PC, align 8
  %4479 = add i64 %4478, 8
  store i64 %4479, i64* %PC, align 8
  %4480 = inttoptr i64 %4477 to double*
  %4481 = load double, double* %4480, align 8
  store double %4481, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4482 = add i64 %4476, -168
  %4483 = add i64 %4478, 16
  store i64 %4483, i64* %PC, align 8
  %4484 = inttoptr i64 %4482 to double*
  %4485 = load double, double* %4484, align 8
  %4486 = fadd double %4481, %4485
  store double %4486, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4487 = add i64 %4476, -128
  %4488 = add i64 %4478, 21
  store i64 %4488, i64* %PC, align 8
  %4489 = inttoptr i64 %4487 to double*
  store double %4486, double* %4489, align 8
  %4490 = load i64, i64* %RBP, align 8
  %4491 = add i64 %4490, -72
  %4492 = load i64, i64* %PC, align 8
  %4493 = add i64 %4492, 5
  store i64 %4493, i64* %PC, align 8
  %4494 = inttoptr i64 %4491 to double*
  %4495 = load double, double* %4494, align 8
  store double %4495, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4496 = add i64 %4490, -120
  %4497 = add i64 %4492, 10
  store i64 %4497, i64* %PC, align 8
  %4498 = inttoptr i64 %4496 to double*
  %4499 = load double, double* %4498, align 8
  %4500 = fmul double %4495, %4499
  store double %4500, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4501 = add i64 %4490, -80
  %4502 = add i64 %4492, 15
  store i64 %4502, i64* %PC, align 8
  %4503 = inttoptr i64 %4501 to double*
  %4504 = load double, double* %4503, align 8
  store double %4504, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %4505 = add i64 %4490, -128
  %4506 = add i64 %4492, 20
  store i64 %4506, i64* %PC, align 8
  %4507 = inttoptr i64 %4505 to double*
  %4508 = load double, double* %4507, align 8
  %4509 = fmul double %4504, %4508
  store double %4509, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %4510 = fsub double %4500, %4509
  store double %4510, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4511 = add i64 %4490, -16
  %4512 = add i64 %4492, 28
  store i64 %4512, i64* %PC, align 8
  %4513 = inttoptr i64 %4511 to i64*
  %4514 = load i64, i64* %4513, align 8
  store i64 %4514, i64* %RAX, align 8, !tbaa !2428
  %4515 = add i64 %4490, -32
  %4516 = add i64 %4492, 32
  store i64 %4516, i64* %PC, align 8
  %4517 = inttoptr i64 %4515 to i32*
  %4518 = load i32, i32* %4517, align 4
  %4519 = sext i32 %4518 to i64
  store i64 %4519, i64* %RDX, align 8, !tbaa !2428
  %4520 = shl nsw i64 %4519, 3
  %4521 = add i64 %4520, %4514
  %4522 = add i64 %4492, 37
  store i64 %4522, i64* %PC, align 8
  %4523 = inttoptr i64 %4521 to double*
  store double %4510, double* %4523, align 8
  %4524 = load i64, i64* %RBP, align 8
  %4525 = add i64 %4524, -72
  %4526 = load i64, i64* %PC, align 8
  %4527 = add i64 %4526, 5
  store i64 %4527, i64* %PC, align 8
  %4528 = inttoptr i64 %4525 to double*
  %4529 = load double, double* %4528, align 8
  store double %4529, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4530 = add i64 %4524, -128
  %4531 = add i64 %4526, 10
  store i64 %4531, i64* %PC, align 8
  %4532 = inttoptr i64 %4530 to double*
  %4533 = load double, double* %4532, align 8
  %4534 = fmul double %4529, %4533
  store double %4534, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4535 = add i64 %4524, -80
  %4536 = add i64 %4526, 15
  store i64 %4536, i64* %PC, align 8
  %4537 = inttoptr i64 %4535 to double*
  %4538 = load double, double* %4537, align 8
  store double %4538, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %4539 = add i64 %4524, -120
  %4540 = add i64 %4526, 20
  store i64 %4540, i64* %PC, align 8
  %4541 = inttoptr i64 %4539 to double*
  %4542 = load double, double* %4541, align 8
  %4543 = fmul double %4538, %4542
  store double %4543, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %4544 = fadd double %4534, %4543
  store double %4544, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4545 = add i64 %4524, -16
  %4546 = add i64 %4526, 28
  store i64 %4546, i64* %PC, align 8
  %4547 = inttoptr i64 %4545 to i64*
  %4548 = load i64, i64* %4547, align 8
  store i64 %4548, i64* %RAX, align 8, !tbaa !2428
  %4549 = add i64 %4524, -32
  %4550 = add i64 %4526, 31
  store i64 %4550, i64* %PC, align 8
  %4551 = inttoptr i64 %4549 to i32*
  %4552 = load i32, i32* %4551, align 4
  %4553 = add i32 %4552, 1
  %4554 = zext i32 %4553 to i64
  store i64 %4554, i64* %RCX, align 8, !tbaa !2428
  %4555 = icmp eq i32 %4552, -1
  %4556 = icmp eq i32 %4553, 0
  %4557 = or i1 %4555, %4556
  %4558 = zext i1 %4557 to i8
  store i8 %4558, i8* %17, align 1, !tbaa !2433
  %4559 = and i32 %4553, 255
  %4560 = tail call i32 @llvm.ctpop.i32(i32 %4559) #10
  %4561 = trunc i32 %4560 to i8
  %4562 = and i8 %4561, 1
  %4563 = xor i8 %4562, 1
  store i8 %4563, i8* %24, align 1, !tbaa !2447
  %4564 = xor i32 %4552, %4553
  %4565 = lshr i32 %4564, 4
  %4566 = trunc i32 %4565 to i8
  %4567 = and i8 %4566, 1
  store i8 %4567, i8* %30, align 1, !tbaa !2451
  %4568 = zext i1 %4556 to i8
  store i8 %4568, i8* %33, align 1, !tbaa !2448
  %4569 = lshr i32 %4553, 31
  %4570 = trunc i32 %4569 to i8
  store i8 %4570, i8* %36, align 1, !tbaa !2449
  %4571 = lshr i32 %4552, 31
  %4572 = xor i32 %4569, %4571
  %4573 = add nuw nsw i32 %4572, %4569
  %4574 = icmp eq i32 %4573, 2
  %4575 = zext i1 %4574 to i8
  store i8 %4575, i8* %42, align 1, !tbaa !2450
  %4576 = sext i32 %4553 to i64
  store i64 %4576, i64* %RDX, align 8, !tbaa !2428
  %4577 = shl nsw i64 %4576, 3
  %4578 = add i64 %4577, %4548
  %4579 = add i64 %4526, 42
  store i64 %4579, i64* %PC, align 8
  %4580 = inttoptr i64 %4578 to double*
  store double %4544, double* %4580, align 8
  %4581 = load i64, i64* %RBP, align 8
  %4582 = add i64 %4581, -136
  %4583 = load i64, i64* %PC, align 8
  %4584 = add i64 %4583, 8
  store i64 %4584, i64* %PC, align 8
  %4585 = inttoptr i64 %4582 to double*
  %4586 = load double, double* %4585, align 8
  store double %4586, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4587 = add i64 %4581, -176
  %4588 = add i64 %4583, 16
  store i64 %4588, i64* %PC, align 8
  %4589 = inttoptr i64 %4587 to double*
  %4590 = load double, double* %4589, align 8
  %4591 = fadd double %4586, %4590
  store double %4591, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4592 = add i64 %4581, -120
  %4593 = add i64 %4583, 21
  store i64 %4593, i64* %PC, align 8
  %4594 = inttoptr i64 %4592 to double*
  store double %4591, double* %4594, align 8
  %4595 = load i64, i64* %RBP, align 8
  %4596 = add i64 %4595, -144
  %4597 = load i64, i64* %PC, align 8
  %4598 = add i64 %4597, 8
  store i64 %4598, i64* %PC, align 8
  %4599 = inttoptr i64 %4596 to double*
  %4600 = load double, double* %4599, align 8
  store double %4600, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4601 = add i64 %4595, -168
  %4602 = add i64 %4597, 16
  store i64 %4602, i64* %PC, align 8
  %4603 = inttoptr i64 %4601 to double*
  %4604 = load double, double* %4603, align 8
  %4605 = fsub double %4600, %4604
  store double %4605, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4606 = add i64 %4595, -128
  %4607 = add i64 %4597, 21
  store i64 %4607, i64* %PC, align 8
  %4608 = inttoptr i64 %4606 to double*
  store double %4605, double* %4608, align 8
  %4609 = load i64, i64* %RBP, align 8
  %4610 = add i64 %4609, -104
  %4611 = load i64, i64* %PC, align 8
  %4612 = add i64 %4611, 5
  store i64 %4612, i64* %PC, align 8
  %4613 = inttoptr i64 %4610 to double*
  %4614 = load double, double* %4613, align 8
  store double %4614, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4615 = add i64 %4609, -120
  %4616 = add i64 %4611, 10
  store i64 %4616, i64* %PC, align 8
  %4617 = inttoptr i64 %4615 to double*
  %4618 = load double, double* %4617, align 8
  %4619 = fmul double %4614, %4618
  store double %4619, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4620 = add i64 %4609, -112
  %4621 = add i64 %4611, 15
  store i64 %4621, i64* %PC, align 8
  %4622 = inttoptr i64 %4620 to double*
  %4623 = load double, double* %4622, align 8
  store double %4623, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %4624 = add i64 %4609, -128
  %4625 = add i64 %4611, 20
  store i64 %4625, i64* %PC, align 8
  %4626 = inttoptr i64 %4624 to double*
  %4627 = load double, double* %4626, align 8
  %4628 = fmul double %4623, %4627
  store double %4628, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %4629 = fsub double %4619, %4628
  store double %4629, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4630 = add i64 %4609, -16
  %4631 = add i64 %4611, 28
  store i64 %4631, i64* %PC, align 8
  %4632 = inttoptr i64 %4630 to i64*
  %4633 = load i64, i64* %4632, align 8
  store i64 %4633, i64* %RAX, align 8, !tbaa !2428
  %4634 = add i64 %4609, -40
  %4635 = add i64 %4611, 32
  store i64 %4635, i64* %PC, align 8
  %4636 = inttoptr i64 %4634 to i32*
  %4637 = load i32, i32* %4636, align 4
  %4638 = sext i32 %4637 to i64
  store i64 %4638, i64* %RDX, align 8, !tbaa !2428
  %4639 = shl nsw i64 %4638, 3
  %4640 = add i64 %4639, %4633
  %4641 = add i64 %4611, 37
  store i64 %4641, i64* %PC, align 8
  %4642 = inttoptr i64 %4640 to double*
  store double %4629, double* %4642, align 8
  %4643 = load i64, i64* %RBP, align 8
  %4644 = add i64 %4643, -104
  %4645 = load i64, i64* %PC, align 8
  %4646 = add i64 %4645, 5
  store i64 %4646, i64* %PC, align 8
  %4647 = inttoptr i64 %4644 to double*
  %4648 = load double, double* %4647, align 8
  store double %4648, double* %94, align 1, !tbaa !2452
  store double 0.000000e+00, double* %96, align 1, !tbaa !2452
  %4649 = add i64 %4643, -128
  %4650 = add i64 %4645, 10
  store i64 %4650, i64* %PC, align 8
  %4651 = inttoptr i64 %4649 to double*
  %4652 = load double, double* %4651, align 8
  %4653 = fmul double %4648, %4652
  store double %4653, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4654 = add i64 %4643, -112
  %4655 = add i64 %4645, 15
  store i64 %4655, i64* %PC, align 8
  %4656 = inttoptr i64 %4654 to double*
  %4657 = load double, double* %4656, align 8
  store double %4657, double* %290, align 1, !tbaa !2452
  store double 0.000000e+00, double* %292, align 1, !tbaa !2452
  %4658 = add i64 %4643, -120
  %4659 = add i64 %4645, 20
  store i64 %4659, i64* %PC, align 8
  %4660 = inttoptr i64 %4658 to double*
  %4661 = load double, double* %4660, align 8
  %4662 = fmul double %4657, %4661
  store double %4662, double* %290, align 1, !tbaa !2452
  store i64 0, i64* %291, align 1, !tbaa !2452
  %4663 = fadd double %4653, %4662
  store double %4663, double* %94, align 1, !tbaa !2452
  store i64 0, i64* %95, align 1, !tbaa !2452
  %4664 = add i64 %4643, -16
  %4665 = add i64 %4645, 28
  store i64 %4665, i64* %PC, align 8
  %4666 = inttoptr i64 %4664 to i64*
  %4667 = load i64, i64* %4666, align 8
  store i64 %4667, i64* %RAX, align 8, !tbaa !2428
  %4668 = add i64 %4643, -40
  %4669 = add i64 %4645, 31
  store i64 %4669, i64* %PC, align 8
  %4670 = inttoptr i64 %4668 to i32*
  %4671 = load i32, i32* %4670, align 4
  %4672 = add i32 %4671, 1
  %4673 = zext i32 %4672 to i64
  store i64 %4673, i64* %RCX, align 8, !tbaa !2428
  %4674 = icmp eq i32 %4671, -1
  %4675 = icmp eq i32 %4672, 0
  %4676 = or i1 %4674, %4675
  %4677 = zext i1 %4676 to i8
  store i8 %4677, i8* %17, align 1, !tbaa !2433
  %4678 = and i32 %4672, 255
  %4679 = tail call i32 @llvm.ctpop.i32(i32 %4678) #10
  %4680 = trunc i32 %4679 to i8
  %4681 = and i8 %4680, 1
  %4682 = xor i8 %4681, 1
  store i8 %4682, i8* %24, align 1, !tbaa !2447
  %4683 = xor i32 %4671, %4672
  %4684 = lshr i32 %4683, 4
  %4685 = trunc i32 %4684 to i8
  %4686 = and i8 %4685, 1
  store i8 %4686, i8* %30, align 1, !tbaa !2451
  %4687 = zext i1 %4675 to i8
  store i8 %4687, i8* %33, align 1, !tbaa !2448
  %4688 = lshr i32 %4672, 31
  %4689 = trunc i32 %4688 to i8
  store i8 %4689, i8* %36, align 1, !tbaa !2449
  %4690 = lshr i32 %4671, 31
  %4691 = xor i32 %4688, %4690
  %4692 = add nuw nsw i32 %4691, %4688
  %4693 = icmp eq i32 %4692, 2
  %4694 = zext i1 %4693 to i8
  store i8 %4694, i8* %42, align 1, !tbaa !2450
  %4695 = sext i32 %4672 to i64
  store i64 %4695, i64* %RDX, align 8, !tbaa !2428
  %4696 = shl nsw i64 %4695, 3
  %4697 = add i64 %4696, %4667
  %4698 = add i64 %4645, 42
  store i64 %4698, i64* %PC, align 8
  %4699 = inttoptr i64 %4697 to double*
  store double %4663, double* %4699, align 8
  %4700 = load i64, i64* %RBP, align 8
  %4701 = add i64 %4700, -28
  %4702 = load i64, i64* %PC, align 8
  %4703 = add i64 %4702, 3
  store i64 %4703, i64* %PC, align 8
  %4704 = inttoptr i64 %4701 to i32*
  %4705 = load i32, i32* %4704, align 4
  %4706 = add i32 %4705, 2
  %4707 = zext i32 %4706 to i64
  store i64 %4707, i64* %RAX, align 8, !tbaa !2428
  %4708 = icmp ugt i32 %4705, -3
  %4709 = zext i1 %4708 to i8
  store i8 %4709, i8* %17, align 1, !tbaa !2433
  %4710 = and i32 %4706, 255
  %4711 = tail call i32 @llvm.ctpop.i32(i32 %4710) #10
  %4712 = trunc i32 %4711 to i8
  %4713 = and i8 %4712, 1
  %4714 = xor i8 %4713, 1
  store i8 %4714, i8* %24, align 1, !tbaa !2447
  %4715 = xor i32 %4705, %4706
  %4716 = lshr i32 %4715, 4
  %4717 = trunc i32 %4716 to i8
  %4718 = and i8 %4717, 1
  store i8 %4718, i8* %30, align 1, !tbaa !2451
  %4719 = icmp eq i32 %4706, 0
  %4720 = zext i1 %4719 to i8
  store i8 %4720, i8* %33, align 1, !tbaa !2448
  %4721 = lshr i32 %4706, 31
  %4722 = trunc i32 %4721 to i8
  store i8 %4722, i8* %36, align 1, !tbaa !2449
  %4723 = lshr i32 %4705, 31
  %4724 = xor i32 %4721, %4723
  %4725 = add nuw nsw i32 %4724, %4721
  %4726 = icmp eq i32 %4725, 2
  %4727 = zext i1 %4726 to i8
  store i8 %4727, i8* %42, align 1, !tbaa !2450
  %4728 = add i64 %4702, 9
  store i64 %4728, i64* %PC, align 8
  store i32 %4706, i32* %4704, align 4
  %4729 = load i64, i64* %PC, align 8
  %4730 = add i64 %4729, -822
  store i64 %4730, i64* %PC, align 8, !tbaa !2428
  br label %block_403c90

block_403326:                                     ; preds = %block_403332, %block_403300
  %4731 = phi i64 [ %1168, %block_403332 ], [ %.pre, %block_403300 ]
  %4732 = load i64, i64* %RBP, align 8
  %4733 = add i64 %4732, -28
  %4734 = add i64 %4731, 3
  store i64 %4734, i64* %PC, align 8
  %4735 = inttoptr i64 %4733 to i32*
  %4736 = load i32, i32* %4735, align 4
  %4737 = zext i32 %4736 to i64
  store i64 %4737, i64* %RAX, align 8, !tbaa !2428
  %4738 = add i64 %4732, -8
  %4739 = add i64 %4731, 6
  store i64 %4739, i64* %PC, align 8
  %4740 = inttoptr i64 %4738 to i32*
  %4741 = load i32, i32* %4740, align 4
  %4742 = sub i32 %4736, %4741
  %4743 = icmp ult i32 %4736, %4741
  %4744 = zext i1 %4743 to i8
  store i8 %4744, i8* %17, align 1, !tbaa !2433
  %4745 = and i32 %4742, 255
  %4746 = tail call i32 @llvm.ctpop.i32(i32 %4745) #10
  %4747 = trunc i32 %4746 to i8
  %4748 = and i8 %4747, 1
  %4749 = xor i8 %4748, 1
  store i8 %4749, i8* %24, align 1, !tbaa !2447
  %4750 = xor i32 %4741, %4736
  %4751 = xor i32 %4750, %4742
  %4752 = lshr i32 %4751, 4
  %4753 = trunc i32 %4752 to i8
  %4754 = and i8 %4753, 1
  store i8 %4754, i8* %30, align 1, !tbaa !2451
  %4755 = icmp eq i32 %4742, 0
  %4756 = zext i1 %4755 to i8
  store i8 %4756, i8* %33, align 1, !tbaa !2448
  %4757 = lshr i32 %4742, 31
  %4758 = trunc i32 %4757 to i8
  store i8 %4758, i8* %36, align 1, !tbaa !2449
  %4759 = lshr i32 %4736, 31
  %4760 = lshr i32 %4741, 31
  %4761 = xor i32 %4760, %4759
  %4762 = xor i32 %4757, %4759
  %4763 = add nuw nsw i32 %4762, %4761
  %4764 = icmp eq i32 %4763, 2
  %4765 = zext i1 %4764 to i8
  store i8 %4765, i8* %42, align 1, !tbaa !2450
  %4766 = icmp ne i8 %4758, 0
  %4767 = xor i1 %4766, %4764
  %.v = select i1 %4767, i64 12, i64 599
  %4768 = add i64 %4731, %.v
  store i64 %4768, i64* %PC, align 8, !tbaa !2428
  br i1 %4767, label %block_403332, label %block_40357d
}

; Function Attrs: noinline
define %struct.Memory* @sub_402480_cftbsub(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_402480:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -120
  store i64 %11, i64* %RSP, align 8, !tbaa !2428
  %12 = icmp ult i64 %8, 112
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1, !tbaa !2433
  %15 = trunc i64 %11 to i32
  %16 = and i32 %15, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16) #10
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1, !tbaa !2447
  %22 = xor i64 %8, 16
  %23 = xor i64 %22, %11
  %24 = lshr i64 %23, 4
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1, !tbaa !2451
  %28 = icmp eq i64 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1, !tbaa !2448
  %31 = lshr i64 %11, 63
  %32 = trunc i64 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1, !tbaa !2449
  %34 = lshr i64 %8, 63
  %35 = xor i64 %31, %34
  %36 = add nuw nsw i64 %35, %34
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1, !tbaa !2450
  %40 = add i64 %7, -12
  %41 = load i32, i32* %EDI, align 4
  %42 = add i64 %10, 10
  store i64 %42, i64* %PC, align 8
  %43 = inttoptr i64 %40 to i32*
  store i32 %41, i32* %43, align 4
  %44 = load i64, i64* %RBP, align 8
  %45 = add i64 %44, -16
  %46 = load i64, i64* %RSI, align 8
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 4
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %45 to i64*
  store i64 %46, i64* %49, align 8
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -24
  %52 = load i64, i64* %RDX, align 8
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 4
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %51 to i64*
  store i64 %52, i64* %55, align 8
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -44
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 7
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %57 to i32*
  store i32 2, i32* %60, align 4
  %61 = load i64, i64* %RBP, align 8
  %62 = add i64 %61, -4
  %63 = load i64, i64* %PC, align 8
  %64 = add i64 %63, 4
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %62 to i32*
  %66 = load i32, i32* %65, align 4
  %67 = add i32 %66, -8
  %68 = icmp ult i32 %66, 8
  %69 = zext i1 %68 to i8
  store i8 %69, i8* %14, align 1, !tbaa !2433
  %70 = and i32 %67, 255
  %71 = tail call i32 @llvm.ctpop.i32(i32 %70) #10
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  %74 = xor i8 %73, 1
  store i8 %74, i8* %21, align 1, !tbaa !2447
  %75 = xor i32 %66, %67
  %76 = lshr i32 %75, 4
  %77 = trunc i32 %76 to i8
  %78 = and i8 %77, 1
  store i8 %78, i8* %27, align 1, !tbaa !2451
  %79 = icmp eq i32 %67, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %30, align 1, !tbaa !2448
  %81 = lshr i32 %67, 31
  %82 = trunc i32 %81 to i8
  store i8 %82, i8* %33, align 1, !tbaa !2449
  %83 = lshr i32 %66, 31
  %84 = xor i32 %81, %83
  %85 = add nuw nsw i32 %84, %83
  %86 = icmp eq i32 %85, 2
  %87 = zext i1 %86 to i8
  store i8 %87, i8* %39, align 1, !tbaa !2450
  %88 = icmp ne i8 %82, 0
  %89 = xor i1 %88, %86
  %90 = or i1 %79, %89
  %.v = select i1 %90, i64 86, i64 10
  %91 = add i64 %63, %.v
  store i64 %91, i64* %PC, align 8, !tbaa !2428
  br i1 %90, label %block_4024f0, label %block_4024a4

block_402757:                                     ; preds = %block_4024f0, %block_402763
  %92 = phi i64 [ %586, %block_402763 ], [ %.pre3, %block_4024f0 ]
  %93 = load i64, i64* %RBP, align 8
  %94 = add i64 %93, -28
  %95 = add i64 %92, 3
  store i64 %95, i64* %PC, align 8
  %96 = inttoptr i64 %94 to i32*
  %97 = load i32, i32* %96, align 4
  %98 = zext i32 %97 to i64
  store i64 %98, i64* %RAX, align 8, !tbaa !2428
  %99 = add i64 %93, -44
  %100 = add i64 %92, 6
  store i64 %100, i64* %PC, align 8
  %101 = inttoptr i64 %99 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = sub i32 %97, %102
  %104 = icmp ult i32 %97, %102
  %105 = zext i1 %104 to i8
  store i8 %105, i8* %14, align 1, !tbaa !2433
  %106 = and i32 %103, 255
  %107 = tail call i32 @llvm.ctpop.i32(i32 %106) #10
  %108 = trunc i32 %107 to i8
  %109 = and i8 %108, 1
  %110 = xor i8 %109, 1
  store i8 %110, i8* %21, align 1, !tbaa !2447
  %111 = xor i32 %102, %97
  %112 = xor i32 %111, %103
  %113 = lshr i32 %112, 4
  %114 = trunc i32 %113 to i8
  %115 = and i8 %114, 1
  store i8 %115, i8* %27, align 1, !tbaa !2451
  %116 = icmp eq i32 %103, 0
  %117 = zext i1 %116 to i8
  store i8 %117, i8* %30, align 1, !tbaa !2448
  %118 = lshr i32 %103, 31
  %119 = trunc i32 %118 to i8
  store i8 %119, i8* %33, align 1, !tbaa !2449
  %120 = lshr i32 %97, 31
  %121 = lshr i32 %102, 31
  %122 = xor i32 %121, %120
  %123 = xor i32 %118, %120
  %124 = add nuw nsw i32 %123, %122
  %125 = icmp eq i32 %124, 2
  %126 = zext i1 %125 to i8
  store i8 %126, i8* %39, align 1, !tbaa !2450
  %127 = icmp ne i8 %119, 0
  %128 = xor i1 %127, %125
  %.v8 = select i1 %128, i64 12, i64 269
  %129 = add i64 %92, %.v8
  store i64 %129, i64* %PC, align 8, !tbaa !2428
  br i1 %128, label %block_402763, label %block_402864

block_4024bb:                                     ; preds = %block_4024a4, %block_4024ca
  %130 = phi i64 [ %.pre, %block_4024a4 ], [ %631, %block_4024ca ]
  %MEMORY.1 = phi %struct.Memory* [ %718, %block_4024a4 ], [ %607, %block_4024ca ]
  %131 = load i64, i64* %RBP, align 8
  %132 = add i64 %131, -44
  %133 = add i64 %130, 3
  store i64 %133, i64* %PC, align 8
  %134 = inttoptr i64 %132 to i32*
  %135 = load i32, i32* %134, align 4
  %136 = shl i32 %135, 2
  %137 = zext i32 %136 to i64
  store i64 %137, i64* %RAX, align 8, !tbaa !2428
  %138 = lshr i32 %135, 30
  %139 = trunc i32 %138 to i8
  %140 = and i8 %139, 1
  store i8 %140, i8* %14, align 1, !tbaa !2432
  %141 = and i32 %136, 252
  %142 = tail call i32 @llvm.ctpop.i32(i32 %141) #10
  %143 = trunc i32 %142 to i8
  %144 = and i8 %143, 1
  %145 = xor i8 %144, 1
  store i8 %145, i8* %21, align 1, !tbaa !2432
  store i8 0, i8* %27, align 1, !tbaa !2432
  %146 = icmp eq i32 %136, 0
  %147 = zext i1 %146 to i8
  store i8 %147, i8* %30, align 1, !tbaa !2432
  %148 = lshr i32 %135, 29
  %149 = and i32 %148, 1
  %150 = trunc i32 %149 to i8
  store i8 %150, i8* %33, align 1, !tbaa !2432
  store i8 0, i8* %39, align 1, !tbaa !2432
  %151 = add i64 %131, -4
  %152 = add i64 %130, 9
  store i64 %152, i64* %PC, align 8
  %153 = inttoptr i64 %151 to i32*
  %154 = load i32, i32* %153, align 4
  %155 = sub i32 %136, %154
  %156 = icmp ult i32 %136, %154
  %157 = zext i1 %156 to i8
  store i8 %157, i8* %14, align 1, !tbaa !2433
  %158 = and i32 %155, 255
  %159 = tail call i32 @llvm.ctpop.i32(i32 %158) #10
  %160 = trunc i32 %159 to i8
  %161 = and i8 %160, 1
  %162 = xor i8 %161, 1
  store i8 %162, i8* %21, align 1, !tbaa !2447
  %163 = xor i32 %154, %136
  %164 = xor i32 %163, %155
  %165 = lshr i32 %164, 4
  %166 = trunc i32 %165 to i8
  %167 = and i8 %166, 1
  store i8 %167, i8* %27, align 1, !tbaa !2451
  %168 = icmp eq i32 %155, 0
  %169 = zext i1 %168 to i8
  store i8 %169, i8* %30, align 1, !tbaa !2448
  %170 = lshr i32 %155, 31
  %171 = trunc i32 %170 to i8
  store i8 %171, i8* %33, align 1, !tbaa !2449
  %172 = lshr i32 %154, 31
  %173 = xor i32 %172, %149
  %174 = xor i32 %170, %149
  %175 = add nuw nsw i32 %174, %173
  %176 = icmp eq i32 %175, 2
  %177 = zext i1 %176 to i8
  store i8 %177, i8* %39, align 1, !tbaa !2450
  %178 = icmp ne i8 %171, 0
  %179 = xor i1 %178, %176
  %.v5 = select i1 %179, i64 15, i64 48
  %180 = add i64 %130, %.v5
  store i64 %180, i64* %PC, align 8, !tbaa !2428
  br i1 %179, label %block_4024ca, label %block_4024eb

block_402763:                                     ; preds = %block_402757
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %181 = add i64 %129, 13
  store i64 %181, i64* %PC, align 8
  %182 = load i32, i32* %96, align 4
  %183 = zext i32 %182 to i64
  store i64 %183, i64* %RCX, align 8, !tbaa !2428
  %184 = add i64 %129, 16
  store i64 %184, i64* %PC, align 8
  %185 = load i32, i32* %101, align 4
  %186 = add i32 %185, %182
  %187 = zext i32 %186 to i64
  store i64 %187, i64* %RCX, align 8, !tbaa !2428
  %188 = icmp ult i32 %186, %182
  %189 = icmp ult i32 %186, %185
  %190 = or i1 %188, %189
  %191 = zext i1 %190 to i8
  store i8 %191, i8* %14, align 1, !tbaa !2433
  %192 = and i32 %186, 255
  %193 = tail call i32 @llvm.ctpop.i32(i32 %192) #10
  %194 = trunc i32 %193 to i8
  %195 = and i8 %194, 1
  %196 = xor i8 %195, 1
  store i8 %196, i8* %21, align 1, !tbaa !2447
  %197 = xor i32 %185, %182
  %198 = xor i32 %197, %186
  %199 = lshr i32 %198, 4
  %200 = trunc i32 %199 to i8
  %201 = and i8 %200, 1
  store i8 %201, i8* %27, align 1, !tbaa !2451
  %202 = icmp eq i32 %186, 0
  %203 = zext i1 %202 to i8
  store i8 %203, i8* %30, align 1, !tbaa !2448
  %204 = lshr i32 %186, 31
  %205 = trunc i32 %204 to i8
  store i8 %205, i8* %33, align 1, !tbaa !2449
  %206 = lshr i32 %182, 31
  %207 = lshr i32 %185, 31
  %208 = xor i32 %204, %206
  %209 = xor i32 %204, %207
  %210 = add nuw nsw i32 %208, %209
  %211 = icmp eq i32 %210, 2
  %212 = zext i1 %211 to i8
  store i8 %212, i8* %39, align 1, !tbaa !2450
  %213 = add i64 %93, -32
  %214 = add i64 %129, 19
  store i64 %214, i64* %PC, align 8
  %215 = inttoptr i64 %213 to i32*
  store i32 %186, i32* %215, align 4
  %216 = load i64, i64* %RBP, align 8
  %217 = add i64 %216, -16
  %218 = load i64, i64* %PC, align 8
  %219 = add i64 %218, 4
  store i64 %219, i64* %PC, align 8
  %220 = inttoptr i64 %217 to i64*
  %221 = load i64, i64* %220, align 8
  store i64 %221, i64* %RDX, align 8, !tbaa !2428
  %222 = add i64 %216, -28
  %223 = add i64 %218, 8
  store i64 %223, i64* %PC, align 8
  %224 = inttoptr i64 %222 to i32*
  %225 = load i32, i32* %224, align 4
  %226 = sext i32 %225 to i64
  store i64 %226, i64* %RSI, align 8, !tbaa !2428
  %227 = shl nsw i64 %226, 3
  %228 = add i64 %227, %221
  %229 = add i64 %218, 13
  store i64 %229, i64* %PC, align 8
  %230 = inttoptr i64 %228 to double*
  %231 = load double, double* %230, align 8
  store double %231, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %232 = add i64 %218, 17
  store i64 %232, i64* %PC, align 8
  %233 = load i64, i64* %220, align 8
  store i64 %233, i64* %RDX, align 8, !tbaa !2428
  %234 = add i64 %216, -32
  %235 = add i64 %218, 21
  store i64 %235, i64* %PC, align 8
  %236 = inttoptr i64 %234 to i32*
  %237 = load i32, i32* %236, align 4
  %238 = sext i32 %237 to i64
  store i64 %238, i64* %RSI, align 8, !tbaa !2428
  %239 = shl nsw i64 %238, 3
  %240 = add i64 %239, %233
  %241 = add i64 %218, 26
  store i64 %241, i64* %PC, align 8
  %242 = inttoptr i64 %240 to double*
  %243 = load double, double* %242, align 8
  %244 = fsub double %231, %243
  store double %244, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %245 = add i64 %216, -56
  %246 = add i64 %218, 31
  store i64 %246, i64* %PC, align 8
  %247 = inttoptr i64 %245 to double*
  store double %244, double* %247, align 8
  %248 = load i64, i64* %RBP, align 8
  %249 = add i64 %248, -16
  %250 = load i64, i64* %PC, align 8
  %251 = add i64 %250, 4
  store i64 %251, i64* %PC, align 8
  %252 = inttoptr i64 %249 to i64*
  %253 = load i64, i64* %252, align 8
  store i64 %253, i64* %RDX, align 8, !tbaa !2428
  %254 = add i64 %248, -28
  %255 = add i64 %250, 7
  store i64 %255, i64* %PC, align 8
  %256 = inttoptr i64 %254 to i32*
  %257 = load i32, i32* %256, align 4
  %258 = add i32 %257, 1
  %259 = zext i32 %258 to i64
  store i64 %259, i64* %RCX, align 8, !tbaa !2428
  %260 = icmp eq i32 %257, -1
  %261 = icmp eq i32 %258, 0
  %262 = or i1 %260, %261
  %263 = zext i1 %262 to i8
  store i8 %263, i8* %14, align 1, !tbaa !2433
  %264 = and i32 %258, 255
  %265 = tail call i32 @llvm.ctpop.i32(i32 %264) #10
  %266 = trunc i32 %265 to i8
  %267 = and i8 %266, 1
  %268 = xor i8 %267, 1
  store i8 %268, i8* %21, align 1, !tbaa !2447
  %269 = xor i32 %257, %258
  %270 = lshr i32 %269, 4
  %271 = trunc i32 %270 to i8
  %272 = and i8 %271, 1
  store i8 %272, i8* %27, align 1, !tbaa !2451
  %273 = zext i1 %261 to i8
  store i8 %273, i8* %30, align 1, !tbaa !2448
  %274 = lshr i32 %258, 31
  %275 = trunc i32 %274 to i8
  store i8 %275, i8* %33, align 1, !tbaa !2449
  %276 = lshr i32 %257, 31
  %277 = xor i32 %274, %276
  %278 = add nuw nsw i32 %277, %274
  %279 = icmp eq i32 %278, 2
  %280 = zext i1 %279 to i8
  store i8 %280, i8* %39, align 1, !tbaa !2450
  %281 = sext i32 %258 to i64
  store i64 %281, i64* %RSI, align 8, !tbaa !2428
  %282 = shl nsw i64 %281, 3
  %283 = add i64 %282, %253
  %284 = add i64 %250, 18
  store i64 %284, i64* %PC, align 8
  %285 = inttoptr i64 %283 to i64*
  %286 = load i64, i64* %285, align 8
  %287 = load i64, i64* %RAX, align 8
  %288 = xor i64 %287, %286
  store i64 %288, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2433
  %289 = trunc i64 %288 to i32
  %290 = and i32 %289, 255
  %291 = tail call i32 @llvm.ctpop.i32(i32 %290) #10
  %292 = trunc i32 %291 to i8
  %293 = and i8 %292, 1
  %294 = xor i8 %293, 1
  store i8 %294, i8* %21, align 1, !tbaa !2447
  %295 = icmp eq i64 %288, 0
  %296 = zext i1 %295 to i8
  store i8 %296, i8* %30, align 1, !tbaa !2448
  %297 = lshr i64 %288, 63
  %298 = trunc i64 %297 to i8
  store i8 %298, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2451
  store i64 %288, i64* %1683, align 1, !tbaa !2428
  store i64 0, i64* %1681, align 1, !tbaa !2428
  %299 = add i64 %250, 35
  store i64 %299, i64* %PC, align 8
  %300 = load i64, i64* %252, align 8
  store i64 %300, i64* %RDX, align 8, !tbaa !2428
  %301 = add i64 %248, -32
  %302 = add i64 %250, 38
  store i64 %302, i64* %PC, align 8
  %303 = inttoptr i64 %301 to i32*
  %304 = load i32, i32* %303, align 4
  %305 = add i32 %304, 1
  %306 = zext i32 %305 to i64
  store i64 %306, i64* %RCX, align 8, !tbaa !2428
  %307 = icmp eq i32 %304, -1
  %308 = icmp eq i32 %305, 0
  %309 = or i1 %307, %308
  %310 = zext i1 %309 to i8
  store i8 %310, i8* %14, align 1, !tbaa !2433
  %311 = and i32 %305, 255
  %312 = tail call i32 @llvm.ctpop.i32(i32 %311) #10
  %313 = trunc i32 %312 to i8
  %314 = and i8 %313, 1
  %315 = xor i8 %314, 1
  store i8 %315, i8* %21, align 1, !tbaa !2447
  %316 = xor i32 %304, %305
  %317 = lshr i32 %316, 4
  %318 = trunc i32 %317 to i8
  %319 = and i8 %318, 1
  store i8 %319, i8* %27, align 1, !tbaa !2451
  %320 = zext i1 %308 to i8
  store i8 %320, i8* %30, align 1, !tbaa !2448
  %321 = lshr i32 %305, 31
  %322 = trunc i32 %321 to i8
  store i8 %322, i8* %33, align 1, !tbaa !2449
  %323 = lshr i32 %304, 31
  %324 = xor i32 %321, %323
  %325 = add nuw nsw i32 %324, %321
  %326 = icmp eq i32 %325, 2
  %327 = zext i1 %326 to i8
  store i8 %327, i8* %39, align 1, !tbaa !2450
  %328 = sext i32 %305 to i64
  store i64 %328, i64* %RSI, align 8, !tbaa !2428
  %329 = shl nsw i64 %328, 3
  %330 = add i64 %329, %300
  %331 = add i64 %250, 49
  store i64 %331, i64* %PC, align 8
  %332 = bitcast i64 %288 to double
  %333 = inttoptr i64 %330 to double*
  %334 = load double, double* %333, align 8
  %335 = fadd double %332, %334
  store double %335, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %336 = load i64, i64* %RBP, align 8
  %337 = add i64 %336, -64
  %338 = add i64 %250, 54
  store i64 %338, i64* %PC, align 8
  %339 = inttoptr i64 %337 to double*
  store double %335, double* %339, align 8
  %340 = load i64, i64* %RBP, align 8
  %341 = add i64 %340, -16
  %342 = load i64, i64* %PC, align 8
  %343 = add i64 %342, 4
  store i64 %343, i64* %PC, align 8
  %344 = inttoptr i64 %341 to i64*
  %345 = load i64, i64* %344, align 8
  store i64 %345, i64* %RDX, align 8, !tbaa !2428
  %346 = add i64 %340, -32
  %347 = add i64 %342, 8
  store i64 %347, i64* %PC, align 8
  %348 = inttoptr i64 %346 to i32*
  %349 = load i32, i32* %348, align 4
  %350 = sext i32 %349 to i64
  store i64 %350, i64* %RSI, align 8, !tbaa !2428
  %351 = shl nsw i64 %350, 3
  %352 = add i64 %351, %345
  %353 = add i64 %342, 13
  store i64 %353, i64* %PC, align 8
  %354 = inttoptr i64 %352 to double*
  %355 = load double, double* %354, align 8
  store double %355, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %356 = add i64 %342, 17
  store i64 %356, i64* %PC, align 8
  %357 = load i64, i64* %344, align 8
  store i64 %357, i64* %RDX, align 8, !tbaa !2428
  %358 = add i64 %340, -28
  %359 = add i64 %342, 21
  store i64 %359, i64* %PC, align 8
  %360 = inttoptr i64 %358 to i32*
  %361 = load i32, i32* %360, align 4
  %362 = sext i32 %361 to i64
  store i64 %362, i64* %RSI, align 8, !tbaa !2428
  %363 = shl nsw i64 %362, 3
  %364 = add i64 %363, %357
  %365 = add i64 %342, 26
  store i64 %365, i64* %PC, align 8
  %366 = inttoptr i64 %364 to double*
  %367 = load double, double* %366, align 8
  %368 = fadd double %355, %367
  store double %368, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %369 = add i64 %342, 31
  store i64 %369, i64* %PC, align 8
  store double %368, double* %366, align 8
  %370 = load i64, i64* %RBP, align 8
  %371 = add i64 %370, -16
  %372 = load i64, i64* %PC, align 8
  %373 = add i64 %372, 4
  store i64 %373, i64* %PC, align 8
  %374 = inttoptr i64 %371 to i64*
  %375 = load i64, i64* %374, align 8
  store i64 %375, i64* %RDX, align 8, !tbaa !2428
  %376 = add i64 %370, -28
  %377 = add i64 %372, 7
  store i64 %377, i64* %PC, align 8
  %378 = inttoptr i64 %376 to i32*
  %379 = load i32, i32* %378, align 4
  %380 = add i32 %379, 1
  %381 = zext i32 %380 to i64
  store i64 %381, i64* %RCX, align 8, !tbaa !2428
  %382 = icmp eq i32 %379, -1
  %383 = icmp eq i32 %380, 0
  %384 = or i1 %382, %383
  %385 = zext i1 %384 to i8
  store i8 %385, i8* %14, align 1, !tbaa !2433
  %386 = and i32 %380, 255
  %387 = tail call i32 @llvm.ctpop.i32(i32 %386) #10
  %388 = trunc i32 %387 to i8
  %389 = and i8 %388, 1
  %390 = xor i8 %389, 1
  store i8 %390, i8* %21, align 1, !tbaa !2447
  %391 = xor i32 %379, %380
  %392 = lshr i32 %391, 4
  %393 = trunc i32 %392 to i8
  %394 = and i8 %393, 1
  store i8 %394, i8* %27, align 1, !tbaa !2451
  %395 = zext i1 %383 to i8
  store i8 %395, i8* %30, align 1, !tbaa !2448
  %396 = lshr i32 %380, 31
  %397 = trunc i32 %396 to i8
  store i8 %397, i8* %33, align 1, !tbaa !2449
  %398 = lshr i32 %379, 31
  %399 = xor i32 %396, %398
  %400 = add nuw nsw i32 %399, %396
  %401 = icmp eq i32 %400, 2
  %402 = zext i1 %401 to i8
  store i8 %402, i8* %39, align 1, !tbaa !2450
  %403 = sext i32 %380 to i64
  store i64 %403, i64* %RSI, align 8, !tbaa !2428
  %404 = shl nsw i64 %403, 3
  %405 = add i64 %404, %375
  %406 = add i64 %372, 18
  store i64 %406, i64* %PC, align 8
  %407 = inttoptr i64 %405 to i64*
  %408 = load i64, i64* %407, align 8
  %409 = load i64, i64* %RAX, align 8
  %410 = xor i64 %409, %408
  store i64 %410, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2433
  %411 = trunc i64 %410 to i32
  %412 = and i32 %411, 255
  %413 = tail call i32 @llvm.ctpop.i32(i32 %412) #10
  %414 = trunc i32 %413 to i8
  %415 = and i8 %414, 1
  %416 = xor i8 %415, 1
  store i8 %416, i8* %21, align 1, !tbaa !2447
  %417 = icmp eq i64 %410, 0
  %418 = zext i1 %417 to i8
  store i8 %418, i8* %30, align 1, !tbaa !2448
  %419 = lshr i64 %410, 63
  %420 = trunc i64 %419 to i8
  store i8 %420, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2451
  store i64 %410, i64* %1683, align 1, !tbaa !2428
  store i64 0, i64* %1681, align 1, !tbaa !2428
  %421 = add i64 %372, 35
  store i64 %421, i64* %PC, align 8
  %422 = load i64, i64* %374, align 8
  store i64 %422, i64* %RAX, align 8, !tbaa !2428
  %423 = add i64 %370, -32
  %424 = add i64 %372, 38
  store i64 %424, i64* %PC, align 8
  %425 = inttoptr i64 %423 to i32*
  %426 = load i32, i32* %425, align 4
  %427 = add i32 %426, 1
  %428 = zext i32 %427 to i64
  store i64 %428, i64* %RCX, align 8, !tbaa !2428
  %429 = icmp eq i32 %426, -1
  %430 = icmp eq i32 %427, 0
  %431 = or i1 %429, %430
  %432 = zext i1 %431 to i8
  store i8 %432, i8* %14, align 1, !tbaa !2433
  %433 = and i32 %427, 255
  %434 = tail call i32 @llvm.ctpop.i32(i32 %433) #10
  %435 = trunc i32 %434 to i8
  %436 = and i8 %435, 1
  %437 = xor i8 %436, 1
  store i8 %437, i8* %21, align 1, !tbaa !2447
  %438 = xor i32 %426, %427
  %439 = lshr i32 %438, 4
  %440 = trunc i32 %439 to i8
  %441 = and i8 %440, 1
  store i8 %441, i8* %27, align 1, !tbaa !2451
  %442 = zext i1 %430 to i8
  store i8 %442, i8* %30, align 1, !tbaa !2448
  %443 = lshr i32 %427, 31
  %444 = trunc i32 %443 to i8
  store i8 %444, i8* %33, align 1, !tbaa !2449
  %445 = lshr i32 %426, 31
  %446 = xor i32 %443, %445
  %447 = add nuw nsw i32 %446, %443
  %448 = icmp eq i32 %447, 2
  %449 = zext i1 %448 to i8
  store i8 %449, i8* %39, align 1, !tbaa !2450
  %450 = sext i32 %427 to i64
  store i64 %450, i64* %RDX, align 8, !tbaa !2428
  %451 = shl nsw i64 %450, 3
  %452 = add i64 %451, %422
  %453 = add i64 %372, 49
  store i64 %453, i64* %PC, align 8
  %454 = bitcast i64 %410 to double
  %455 = inttoptr i64 %452 to double*
  %456 = load double, double* %455, align 8
  %457 = fsub double %454, %456
  store double %457, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %458 = load i64, i64* %RBP, align 8
  %459 = add i64 %458, -16
  %460 = add i64 %372, 53
  store i64 %460, i64* %PC, align 8
  %461 = inttoptr i64 %459 to i64*
  %462 = load i64, i64* %461, align 8
  store i64 %462, i64* %RAX, align 8, !tbaa !2428
  %463 = add i64 %458, -28
  %464 = add i64 %372, 56
  store i64 %464, i64* %PC, align 8
  %465 = inttoptr i64 %463 to i32*
  %466 = load i32, i32* %465, align 4
  %467 = add i32 %466, 1
  %468 = zext i32 %467 to i64
  store i64 %468, i64* %RCX, align 8, !tbaa !2428
  %469 = icmp eq i32 %466, -1
  %470 = icmp eq i32 %467, 0
  %471 = or i1 %469, %470
  %472 = zext i1 %471 to i8
  store i8 %472, i8* %14, align 1, !tbaa !2433
  %473 = and i32 %467, 255
  %474 = tail call i32 @llvm.ctpop.i32(i32 %473) #10
  %475 = trunc i32 %474 to i8
  %476 = and i8 %475, 1
  %477 = xor i8 %476, 1
  store i8 %477, i8* %21, align 1, !tbaa !2447
  %478 = xor i32 %466, %467
  %479 = lshr i32 %478, 4
  %480 = trunc i32 %479 to i8
  %481 = and i8 %480, 1
  store i8 %481, i8* %27, align 1, !tbaa !2451
  %482 = zext i1 %470 to i8
  store i8 %482, i8* %30, align 1, !tbaa !2448
  %483 = lshr i32 %467, 31
  %484 = trunc i32 %483 to i8
  store i8 %484, i8* %33, align 1, !tbaa !2449
  %485 = lshr i32 %466, 31
  %486 = xor i32 %483, %485
  %487 = add nuw nsw i32 %486, %483
  %488 = icmp eq i32 %487, 2
  %489 = zext i1 %488 to i8
  store i8 %489, i8* %39, align 1, !tbaa !2450
  %490 = sext i32 %467 to i64
  store i64 %490, i64* %RDX, align 8, !tbaa !2428
  %491 = shl nsw i64 %490, 3
  %492 = add i64 %491, %462
  %493 = add i64 %372, 67
  store i64 %493, i64* %PC, align 8
  %494 = inttoptr i64 %492 to double*
  store double %457, double* %494, align 8
  %495 = load i64, i64* %RBP, align 8
  %496 = add i64 %495, -56
  %497 = load i64, i64* %PC, align 8
  %498 = add i64 %497, 5
  store i64 %498, i64* %PC, align 8
  %499 = inttoptr i64 %496 to i64*
  %500 = load i64, i64* %499, align 8
  store i64 %500, i64* %1683, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %501 = add i64 %495, -16
  %502 = add i64 %497, 9
  store i64 %502, i64* %PC, align 8
  %503 = inttoptr i64 %501 to i64*
  %504 = load i64, i64* %503, align 8
  store i64 %504, i64* %RAX, align 8, !tbaa !2428
  %505 = add i64 %495, -32
  %506 = add i64 %497, 13
  store i64 %506, i64* %PC, align 8
  %507 = inttoptr i64 %505 to i32*
  %508 = load i32, i32* %507, align 4
  %509 = sext i32 %508 to i64
  store i64 %509, i64* %RDX, align 8, !tbaa !2428
  %510 = shl nsw i64 %509, 3
  %511 = add i64 %510, %504
  %512 = add i64 %497, 18
  store i64 %512, i64* %PC, align 8
  %513 = inttoptr i64 %511 to i64*
  store i64 %500, i64* %513, align 8
  %514 = load i64, i64* %RBP, align 8
  %515 = add i64 %514, -64
  %516 = load i64, i64* %PC, align 8
  %517 = add i64 %516, 5
  store i64 %517, i64* %PC, align 8
  %518 = inttoptr i64 %515 to i64*
  %519 = load i64, i64* %518, align 8
  store i64 %519, i64* %1683, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %520 = add i64 %514, -16
  %521 = add i64 %516, 9
  store i64 %521, i64* %PC, align 8
  %522 = inttoptr i64 %520 to i64*
  %523 = load i64, i64* %522, align 8
  store i64 %523, i64* %RAX, align 8, !tbaa !2428
  %524 = add i64 %514, -32
  %525 = add i64 %516, 12
  store i64 %525, i64* %PC, align 8
  %526 = inttoptr i64 %524 to i32*
  %527 = load i32, i32* %526, align 4
  %528 = add i32 %527, 1
  %529 = zext i32 %528 to i64
  store i64 %529, i64* %RCX, align 8, !tbaa !2428
  %530 = icmp eq i32 %527, -1
  %531 = icmp eq i32 %528, 0
  %532 = or i1 %530, %531
  %533 = zext i1 %532 to i8
  store i8 %533, i8* %14, align 1, !tbaa !2433
  %534 = and i32 %528, 255
  %535 = tail call i32 @llvm.ctpop.i32(i32 %534) #10
  %536 = trunc i32 %535 to i8
  %537 = and i8 %536, 1
  %538 = xor i8 %537, 1
  store i8 %538, i8* %21, align 1, !tbaa !2447
  %539 = xor i32 %527, %528
  %540 = lshr i32 %539, 4
  %541 = trunc i32 %540 to i8
  %542 = and i8 %541, 1
  store i8 %542, i8* %27, align 1, !tbaa !2451
  %543 = zext i1 %531 to i8
  store i8 %543, i8* %30, align 1, !tbaa !2448
  %544 = lshr i32 %528, 31
  %545 = trunc i32 %544 to i8
  store i8 %545, i8* %33, align 1, !tbaa !2449
  %546 = lshr i32 %527, 31
  %547 = xor i32 %544, %546
  %548 = add nuw nsw i32 %547, %544
  %549 = icmp eq i32 %548, 2
  %550 = zext i1 %549 to i8
  store i8 %550, i8* %39, align 1, !tbaa !2450
  %551 = sext i32 %528 to i64
  store i64 %551, i64* %RDX, align 8, !tbaa !2428
  %552 = shl nsw i64 %551, 3
  %553 = add i64 %552, %523
  %554 = add i64 %516, 23
  store i64 %554, i64* %PC, align 8
  %555 = inttoptr i64 %553 to i64*
  store i64 %519, i64* %555, align 8
  %556 = load i64, i64* %RBP, align 8
  %557 = add i64 %556, -28
  %558 = load i64, i64* %PC, align 8
  %559 = add i64 %558, 3
  store i64 %559, i64* %PC, align 8
  %560 = inttoptr i64 %557 to i32*
  %561 = load i32, i32* %560, align 4
  %562 = add i32 %561, 2
  %563 = zext i32 %562 to i64
  store i64 %563, i64* %RAX, align 8, !tbaa !2428
  %564 = icmp ugt i32 %561, -3
  %565 = zext i1 %564 to i8
  store i8 %565, i8* %14, align 1, !tbaa !2433
  %566 = and i32 %562, 255
  %567 = tail call i32 @llvm.ctpop.i32(i32 %566) #10
  %568 = trunc i32 %567 to i8
  %569 = and i8 %568, 1
  %570 = xor i8 %569, 1
  store i8 %570, i8* %21, align 1, !tbaa !2447
  %571 = xor i32 %561, %562
  %572 = lshr i32 %571, 4
  %573 = trunc i32 %572 to i8
  %574 = and i8 %573, 1
  store i8 %574, i8* %27, align 1, !tbaa !2451
  %575 = icmp eq i32 %562, 0
  %576 = zext i1 %575 to i8
  store i8 %576, i8* %30, align 1, !tbaa !2448
  %577 = lshr i32 %562, 31
  %578 = trunc i32 %577 to i8
  store i8 %578, i8* %33, align 1, !tbaa !2449
  %579 = lshr i32 %561, 31
  %580 = xor i32 %577, %579
  %581 = add nuw nsw i32 %580, %577
  %582 = icmp eq i32 %581, 2
  %583 = zext i1 %582 to i8
  store i8 %583, i8* %39, align 1, !tbaa !2450
  %584 = add i64 %558, 9
  store i64 %584, i64* %PC, align 8
  store i32 %562, i32* %560, align 4
  %585 = load i64, i64* %PC, align 8
  %586 = add i64 %585, -264
  store i64 %586, i64* %PC, align 8, !tbaa !2428
  br label %block_402757

block_40274b:                                     ; preds = %block_402506
  %587 = add i64 %701, 286
  br label %block_402869

block_4024ca:                                     ; preds = %block_4024bb
  %588 = add i64 %180, 3
  store i64 %588, i64* %PC, align 8
  %589 = load i32, i32* %153, align 4
  %590 = zext i32 %589 to i64
  store i64 %590, i64* %RDI, align 8, !tbaa !2428
  %591 = add i64 %180, 6
  store i64 %591, i64* %PC, align 8
  %592 = load i32, i32* %134, align 4
  %593 = zext i32 %592 to i64
  store i64 %593, i64* %RSI, align 8, !tbaa !2428
  %594 = add i64 %131, -16
  %595 = add i64 %180, 10
  store i64 %595, i64* %PC, align 8
  %596 = inttoptr i64 %594 to i64*
  %597 = load i64, i64* %596, align 8
  store i64 %597, i64* %RDX, align 8, !tbaa !2428
  %598 = add i64 %131, -24
  %599 = add i64 %180, 14
  store i64 %599, i64* %PC, align 8
  %600 = inttoptr i64 %598 to i64*
  %601 = load i64, i64* %600, align 8
  store i64 %601, i64* %RCX, align 8, !tbaa !2428
  %602 = add i64 %180, 3638
  %603 = add i64 %180, 19
  %604 = load i64, i64* %RSP, align 8, !tbaa !2428
  %605 = add i64 %604, -8
  %606 = inttoptr i64 %605 to i64*
  store i64 %603, i64* %606, align 8
  store i64 %605, i64* %RSP, align 8, !tbaa !2428
  store i64 %602, i64* %PC, align 8, !tbaa !2428
  %607 = tail call %struct.Memory* @sub_403300_cftmdl_renamed_(%struct.State* nonnull %0, i64 %602, %struct.Memory* %MEMORY.1)
  %608 = load i64, i64* %RBP, align 8
  %609 = add i64 %608, -44
  %610 = load i64, i64* %PC, align 8
  %611 = add i64 %610, 3
  store i64 %611, i64* %PC, align 8
  %612 = inttoptr i64 %609 to i32*
  %613 = load i32, i32* %612, align 4
  %614 = shl i32 %613, 2
  %615 = zext i32 %614 to i64
  store i64 %615, i64* %RSI, align 8, !tbaa !2428
  %616 = lshr i32 %613, 30
  %617 = trunc i32 %616 to i8
  %618 = and i8 %617, 1
  store i8 %618, i8* %14, align 1, !tbaa !2432
  %619 = and i32 %614, 252
  %620 = tail call i32 @llvm.ctpop.i32(i32 %619) #10
  %621 = trunc i32 %620 to i8
  %622 = and i8 %621, 1
  %623 = xor i8 %622, 1
  store i8 %623, i8* %21, align 1, !tbaa !2432
  store i8 0, i8* %27, align 1, !tbaa !2432
  %624 = icmp eq i32 %614, 0
  %625 = zext i1 %624 to i8
  store i8 %625, i8* %30, align 1, !tbaa !2432
  %626 = lshr i32 %613, 29
  %627 = trunc i32 %626 to i8
  %628 = and i8 %627, 1
  store i8 %628, i8* %33, align 1, !tbaa !2432
  store i8 0, i8* %39, align 1, !tbaa !2432
  %629 = add i64 %610, 9
  store i64 %629, i64* %PC, align 8
  store i32 %614, i32* %612, align 4
  %630 = load i64, i64* %PC, align 8
  %631 = add i64 %630, -43
  store i64 %631, i64* %PC, align 8, !tbaa !2428
  br label %block_4024bb

block_402869:                                     ; preds = %block_402864, %block_40274b
  %.sink = phi i64 [ %725, %block_402864 ], [ %587, %block_40274b ]
  %632 = load i64, i64* %RSP, align 8
  %633 = add i64 %632, 112
  store i64 %633, i64* %RSP, align 8, !tbaa !2428
  %634 = icmp ugt i64 %632, -113
  %635 = zext i1 %634 to i8
  store i8 %635, i8* %14, align 1, !tbaa !2433
  %636 = trunc i64 %633 to i32
  %637 = and i32 %636, 255
  %638 = tail call i32 @llvm.ctpop.i32(i32 %637) #10
  %639 = trunc i32 %638 to i8
  %640 = and i8 %639, 1
  %641 = xor i8 %640, 1
  store i8 %641, i8* %21, align 1, !tbaa !2447
  %642 = xor i64 %632, 16
  %643 = xor i64 %642, %633
  %644 = lshr i64 %643, 4
  %645 = trunc i64 %644 to i8
  %646 = and i8 %645, 1
  store i8 %646, i8* %27, align 1, !tbaa !2451
  %647 = icmp eq i64 %633, 0
  %648 = zext i1 %647 to i8
  store i8 %648, i8* %30, align 1, !tbaa !2448
  %649 = lshr i64 %633, 63
  %650 = trunc i64 %649 to i8
  store i8 %650, i8* %33, align 1, !tbaa !2449
  %651 = lshr i64 %632, 63
  %652 = xor i64 %649, %651
  %653 = add nuw nsw i64 %652, %649
  %654 = icmp eq i64 %653, 2
  %655 = zext i1 %654 to i8
  store i8 %655, i8* %39, align 1, !tbaa !2450
  %656 = add i64 %.sink, 5
  store i64 %656, i64* %PC, align 8
  %657 = add i64 %632, 120
  %658 = inttoptr i64 %633 to i64*
  %659 = load i64, i64* %658, align 8
  store i64 %659, i64* %RBP, align 8, !tbaa !2428
  store i64 %657, i64* %RSP, align 8, !tbaa !2428
  %660 = add i64 %.sink, 6
  store i64 %660, i64* %PC, align 8
  %661 = inttoptr i64 %657 to i64*
  %662 = load i64, i64* %661, align 8
  store i64 %662, i64* %PC, align 8, !tbaa !2428
  %663 = add i64 %632, 128
  store i64 %663, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.4

block_402506:                                     ; preds = %block_4024f0, %block_402512
  %664 = phi i64 [ %1627, %block_402512 ], [ %.pre3, %block_4024f0 ]
  %665 = load i64, i64* %RBP, align 8
  %666 = add i64 %665, -28
  %667 = add i64 %664, 3
  store i64 %667, i64* %PC, align 8
  %668 = inttoptr i64 %666 to i32*
  %669 = load i32, i32* %668, align 4
  %670 = zext i32 %669 to i64
  store i64 %670, i64* %RAX, align 8, !tbaa !2428
  %671 = add i64 %665, -44
  %672 = add i64 %664, 6
  store i64 %672, i64* %PC, align 8
  %673 = inttoptr i64 %671 to i32*
  %674 = load i32, i32* %673, align 4
  %675 = sub i32 %669, %674
  %676 = icmp ult i32 %669, %674
  %677 = zext i1 %676 to i8
  store i8 %677, i8* %14, align 1, !tbaa !2433
  %678 = and i32 %675, 255
  %679 = tail call i32 @llvm.ctpop.i32(i32 %678) #10
  %680 = trunc i32 %679 to i8
  %681 = and i8 %680, 1
  %682 = xor i8 %681, 1
  store i8 %682, i8* %21, align 1, !tbaa !2447
  %683 = xor i32 %674, %669
  %684 = xor i32 %683, %675
  %685 = lshr i32 %684, 4
  %686 = trunc i32 %685 to i8
  %687 = and i8 %686, 1
  store i8 %687, i8* %27, align 1, !tbaa !2451
  %688 = icmp eq i32 %675, 0
  %689 = zext i1 %688 to i8
  store i8 %689, i8* %30, align 1, !tbaa !2448
  %690 = lshr i32 %675, 31
  %691 = trunc i32 %690 to i8
  store i8 %691, i8* %33, align 1, !tbaa !2449
  %692 = lshr i32 %669, 31
  %693 = lshr i32 %674, 31
  %694 = xor i32 %693, %692
  %695 = xor i32 %690, %692
  %696 = add nuw nsw i32 %695, %694
  %697 = icmp eq i32 %696, 2
  %698 = zext i1 %697 to i8
  store i8 %698, i8* %39, align 1, !tbaa !2450
  %699 = icmp ne i8 %691, 0
  %700 = xor i1 %699, %697
  %.v7 = select i1 %700, i64 12, i64 581
  %701 = add i64 %664, %.v7
  store i64 %701, i64* %PC, align 8, !tbaa !2428
  br i1 %700, label %block_402512, label %block_40274b

block_4024a4:                                     ; preds = %block_402480
  %702 = add i64 %91, 3
  store i64 %702, i64* %PC, align 8
  %703 = load i32, i32* %65, align 4
  %704 = zext i32 %703 to i64
  store i64 %704, i64* %RDI, align 8, !tbaa !2428
  %705 = add i64 %61, -16
  %706 = add i64 %91, 7
  store i64 %706, i64* %PC, align 8
  %707 = inttoptr i64 %705 to i64*
  %708 = load i64, i64* %707, align 8
  store i64 %708, i64* %RSI, align 8, !tbaa !2428
  %709 = add i64 %61, -24
  %710 = add i64 %91, 11
  store i64 %710, i64* %PC, align 8
  %711 = inttoptr i64 %709 to i64*
  %712 = load i64, i64* %711, align 8
  store i64 %712, i64* %RDX, align 8, !tbaa !2428
  %713 = add i64 %91, 972
  %714 = add i64 %91, 16
  %715 = load i64, i64* %RSP, align 8, !tbaa !2428
  %716 = add i64 %715, -8
  %717 = inttoptr i64 %716 to i64*
  store i64 %714, i64* %717, align 8
  store i64 %716, i64* %RSP, align 8, !tbaa !2428
  store i64 %713, i64* %PC, align 8, !tbaa !2428
  %718 = tail call %struct.Memory* @sub_402870_cft1st_renamed_(%struct.State* nonnull %0, i64 %713, %struct.Memory* %2)
  %719 = load i64, i64* %RBP, align 8
  %720 = add i64 %719, -44
  %721 = load i64, i64* %PC, align 8
  %722 = add i64 %721, 7
  store i64 %722, i64* %PC, align 8
  %723 = inttoptr i64 %720 to i32*
  store i32 8, i32* %723, align 4
  %.pre = load i64, i64* %PC, align 8
  br label %block_4024bb

block_4024eb:                                     ; preds = %block_4024bb
  %724 = add i64 %180, 5
  store i64 %724, i64* %PC, align 8, !tbaa !2428
  br label %block_4024f0

block_402864:                                     ; preds = %block_402757
  %725 = add i64 %129, 5
  br label %block_402869

block_402512:                                     ; preds = %block_402506
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %726 = add i64 %701, 13
  store i64 %726, i64* %PC, align 8
  %727 = load i32, i32* %668, align 4
  %728 = zext i32 %727 to i64
  store i64 %728, i64* %RCX, align 8, !tbaa !2428
  %729 = add i64 %701, 16
  store i64 %729, i64* %PC, align 8
  %730 = load i32, i32* %673, align 4
  %731 = add i32 %730, %727
  %732 = zext i32 %731 to i64
  store i64 %732, i64* %RCX, align 8, !tbaa !2428
  %733 = icmp ult i32 %731, %727
  %734 = icmp ult i32 %731, %730
  %735 = or i1 %733, %734
  %736 = zext i1 %735 to i8
  store i8 %736, i8* %14, align 1, !tbaa !2433
  %737 = and i32 %731, 255
  %738 = tail call i32 @llvm.ctpop.i32(i32 %737) #10
  %739 = trunc i32 %738 to i8
  %740 = and i8 %739, 1
  %741 = xor i8 %740, 1
  store i8 %741, i8* %21, align 1, !tbaa !2447
  %742 = xor i32 %730, %727
  %743 = xor i32 %742, %731
  %744 = lshr i32 %743, 4
  %745 = trunc i32 %744 to i8
  %746 = and i8 %745, 1
  store i8 %746, i8* %27, align 1, !tbaa !2451
  %747 = icmp eq i32 %731, 0
  %748 = zext i1 %747 to i8
  store i8 %748, i8* %30, align 1, !tbaa !2448
  %749 = lshr i32 %731, 31
  %750 = trunc i32 %749 to i8
  store i8 %750, i8* %33, align 1, !tbaa !2449
  %751 = lshr i32 %727, 31
  %752 = lshr i32 %730, 31
  %753 = xor i32 %749, %751
  %754 = xor i32 %749, %752
  %755 = add nuw nsw i32 %753, %754
  %756 = icmp eq i32 %755, 2
  %757 = zext i1 %756 to i8
  store i8 %757, i8* %39, align 1, !tbaa !2450
  %758 = add i64 %665, -32
  %759 = add i64 %701, 19
  store i64 %759, i64* %PC, align 8
  %760 = inttoptr i64 %758 to i32*
  store i32 %731, i32* %760, align 4
  %761 = load i64, i64* %RBP, align 8
  %762 = add i64 %761, -32
  %763 = load i64, i64* %PC, align 8
  %764 = add i64 %763, 3
  store i64 %764, i64* %PC, align 8
  %765 = inttoptr i64 %762 to i32*
  %766 = load i32, i32* %765, align 4
  %767 = zext i32 %766 to i64
  store i64 %767, i64* %RCX, align 8, !tbaa !2428
  %768 = add i64 %761, -44
  %769 = add i64 %763, 6
  store i64 %769, i64* %PC, align 8
  %770 = inttoptr i64 %768 to i32*
  %771 = load i32, i32* %770, align 4
  %772 = add i32 %771, %766
  %773 = zext i32 %772 to i64
  store i64 %773, i64* %RCX, align 8, !tbaa !2428
  %774 = icmp ult i32 %772, %766
  %775 = icmp ult i32 %772, %771
  %776 = or i1 %774, %775
  %777 = zext i1 %776 to i8
  store i8 %777, i8* %14, align 1, !tbaa !2433
  %778 = and i32 %772, 255
  %779 = tail call i32 @llvm.ctpop.i32(i32 %778) #10
  %780 = trunc i32 %779 to i8
  %781 = and i8 %780, 1
  %782 = xor i8 %781, 1
  store i8 %782, i8* %21, align 1, !tbaa !2447
  %783 = xor i32 %771, %766
  %784 = xor i32 %783, %772
  %785 = lshr i32 %784, 4
  %786 = trunc i32 %785 to i8
  %787 = and i8 %786, 1
  store i8 %787, i8* %27, align 1, !tbaa !2451
  %788 = icmp eq i32 %772, 0
  %789 = zext i1 %788 to i8
  store i8 %789, i8* %30, align 1, !tbaa !2448
  %790 = lshr i32 %772, 31
  %791 = trunc i32 %790 to i8
  store i8 %791, i8* %33, align 1, !tbaa !2449
  %792 = lshr i32 %766, 31
  %793 = lshr i32 %771, 31
  %794 = xor i32 %790, %792
  %795 = xor i32 %790, %793
  %796 = add nuw nsw i32 %794, %795
  %797 = icmp eq i32 %796, 2
  %798 = zext i1 %797 to i8
  store i8 %798, i8* %39, align 1, !tbaa !2450
  %799 = add i64 %761, -36
  %800 = add i64 %763, 9
  store i64 %800, i64* %PC, align 8
  %801 = inttoptr i64 %799 to i32*
  store i32 %772, i32* %801, align 4
  %802 = load i64, i64* %RBP, align 8
  %803 = add i64 %802, -36
  %804 = load i64, i64* %PC, align 8
  %805 = add i64 %804, 3
  store i64 %805, i64* %PC, align 8
  %806 = inttoptr i64 %803 to i32*
  %807 = load i32, i32* %806, align 4
  %808 = zext i32 %807 to i64
  store i64 %808, i64* %RCX, align 8, !tbaa !2428
  %809 = add i64 %802, -44
  %810 = add i64 %804, 6
  store i64 %810, i64* %PC, align 8
  %811 = inttoptr i64 %809 to i32*
  %812 = load i32, i32* %811, align 4
  %813 = add i32 %812, %807
  %814 = zext i32 %813 to i64
  store i64 %814, i64* %RCX, align 8, !tbaa !2428
  %815 = icmp ult i32 %813, %807
  %816 = icmp ult i32 %813, %812
  %817 = or i1 %815, %816
  %818 = zext i1 %817 to i8
  store i8 %818, i8* %14, align 1, !tbaa !2433
  %819 = and i32 %813, 255
  %820 = tail call i32 @llvm.ctpop.i32(i32 %819) #10
  %821 = trunc i32 %820 to i8
  %822 = and i8 %821, 1
  %823 = xor i8 %822, 1
  store i8 %823, i8* %21, align 1, !tbaa !2447
  %824 = xor i32 %812, %807
  %825 = xor i32 %824, %813
  %826 = lshr i32 %825, 4
  %827 = trunc i32 %826 to i8
  %828 = and i8 %827, 1
  store i8 %828, i8* %27, align 1, !tbaa !2451
  %829 = icmp eq i32 %813, 0
  %830 = zext i1 %829 to i8
  store i8 %830, i8* %30, align 1, !tbaa !2448
  %831 = lshr i32 %813, 31
  %832 = trunc i32 %831 to i8
  store i8 %832, i8* %33, align 1, !tbaa !2449
  %833 = lshr i32 %807, 31
  %834 = lshr i32 %812, 31
  %835 = xor i32 %831, %833
  %836 = xor i32 %831, %834
  %837 = add nuw nsw i32 %835, %836
  %838 = icmp eq i32 %837, 2
  %839 = zext i1 %838 to i8
  store i8 %839, i8* %39, align 1, !tbaa !2450
  %840 = add i64 %802, -40
  %841 = add i64 %804, 9
  store i64 %841, i64* %PC, align 8
  %842 = inttoptr i64 %840 to i32*
  store i32 %813, i32* %842, align 4
  %843 = load i64, i64* %RBP, align 8
  %844 = add i64 %843, -16
  %845 = load i64, i64* %PC, align 8
  %846 = add i64 %845, 4
  store i64 %846, i64* %PC, align 8
  %847 = inttoptr i64 %844 to i64*
  %848 = load i64, i64* %847, align 8
  store i64 %848, i64* %RDX, align 8, !tbaa !2428
  %849 = add i64 %843, -28
  %850 = add i64 %845, 8
  store i64 %850, i64* %PC, align 8
  %851 = inttoptr i64 %849 to i32*
  %852 = load i32, i32* %851, align 4
  %853 = sext i32 %852 to i64
  store i64 %853, i64* %RSI, align 8, !tbaa !2428
  %854 = shl nsw i64 %853, 3
  %855 = add i64 %854, %848
  %856 = add i64 %845, 13
  store i64 %856, i64* %PC, align 8
  %857 = inttoptr i64 %855 to double*
  %858 = load double, double* %857, align 8
  store double %858, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %859 = add i64 %845, 17
  store i64 %859, i64* %PC, align 8
  %860 = load i64, i64* %847, align 8
  store i64 %860, i64* %RDX, align 8, !tbaa !2428
  %861 = add i64 %843, -32
  %862 = add i64 %845, 21
  store i64 %862, i64* %PC, align 8
  %863 = inttoptr i64 %861 to i32*
  %864 = load i32, i32* %863, align 4
  %865 = sext i32 %864 to i64
  store i64 %865, i64* %RSI, align 8, !tbaa !2428
  %866 = shl nsw i64 %865, 3
  %867 = add i64 %866, %860
  %868 = add i64 %845, 26
  store i64 %868, i64* %PC, align 8
  %869 = inttoptr i64 %867 to double*
  %870 = load double, double* %869, align 8
  %871 = fadd double %858, %870
  store double %871, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %872 = add i64 %843, -56
  %873 = add i64 %845, 31
  store i64 %873, i64* %PC, align 8
  %874 = inttoptr i64 %872 to double*
  store double %871, double* %874, align 8
  %875 = load i64, i64* %RBP, align 8
  %876 = add i64 %875, -16
  %877 = load i64, i64* %PC, align 8
  %878 = add i64 %877, 4
  store i64 %878, i64* %PC, align 8
  %879 = inttoptr i64 %876 to i64*
  %880 = load i64, i64* %879, align 8
  store i64 %880, i64* %RDX, align 8, !tbaa !2428
  %881 = add i64 %875, -28
  %882 = add i64 %877, 7
  store i64 %882, i64* %PC, align 8
  %883 = inttoptr i64 %881 to i32*
  %884 = load i32, i32* %883, align 4
  %885 = add i32 %884, 1
  %886 = zext i32 %885 to i64
  store i64 %886, i64* %RCX, align 8, !tbaa !2428
  %887 = icmp eq i32 %884, -1
  %888 = icmp eq i32 %885, 0
  %889 = or i1 %887, %888
  %890 = zext i1 %889 to i8
  store i8 %890, i8* %14, align 1, !tbaa !2433
  %891 = and i32 %885, 255
  %892 = tail call i32 @llvm.ctpop.i32(i32 %891) #10
  %893 = trunc i32 %892 to i8
  %894 = and i8 %893, 1
  %895 = xor i8 %894, 1
  store i8 %895, i8* %21, align 1, !tbaa !2447
  %896 = xor i32 %884, %885
  %897 = lshr i32 %896, 4
  %898 = trunc i32 %897 to i8
  %899 = and i8 %898, 1
  store i8 %899, i8* %27, align 1, !tbaa !2451
  %900 = zext i1 %888 to i8
  store i8 %900, i8* %30, align 1, !tbaa !2448
  %901 = lshr i32 %885, 31
  %902 = trunc i32 %901 to i8
  store i8 %902, i8* %33, align 1, !tbaa !2449
  %903 = lshr i32 %884, 31
  %904 = xor i32 %901, %903
  %905 = add nuw nsw i32 %904, %901
  %906 = icmp eq i32 %905, 2
  %907 = zext i1 %906 to i8
  store i8 %907, i8* %39, align 1, !tbaa !2450
  %908 = sext i32 %885 to i64
  store i64 %908, i64* %RSI, align 8, !tbaa !2428
  %909 = shl nsw i64 %908, 3
  %910 = add i64 %909, %880
  %911 = add i64 %877, 18
  store i64 %911, i64* %PC, align 8
  %912 = inttoptr i64 %910 to i64*
  %913 = load i64, i64* %912, align 8
  %914 = load i64, i64* %RAX, align 8
  %915 = xor i64 %914, %913
  store i64 %915, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2433
  %916 = trunc i64 %915 to i32
  %917 = and i32 %916, 255
  %918 = tail call i32 @llvm.ctpop.i32(i32 %917) #10
  %919 = trunc i32 %918 to i8
  %920 = and i8 %919, 1
  %921 = xor i8 %920, 1
  store i8 %921, i8* %21, align 1, !tbaa !2447
  %922 = icmp eq i64 %915, 0
  %923 = zext i1 %922 to i8
  store i8 %923, i8* %30, align 1, !tbaa !2448
  %924 = lshr i64 %915, 63
  %925 = trunc i64 %924 to i8
  store i8 %925, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2451
  store i64 %915, i64* %1683, align 1, !tbaa !2428
  store i64 0, i64* %1681, align 1, !tbaa !2428
  %926 = add i64 %877, 35
  store i64 %926, i64* %PC, align 8
  %927 = load i64, i64* %879, align 8
  store i64 %927, i64* %RDX, align 8, !tbaa !2428
  %928 = add i64 %875, -32
  %929 = add i64 %877, 38
  store i64 %929, i64* %PC, align 8
  %930 = inttoptr i64 %928 to i32*
  %931 = load i32, i32* %930, align 4
  %932 = add i32 %931, 1
  %933 = zext i32 %932 to i64
  store i64 %933, i64* %RCX, align 8, !tbaa !2428
  %934 = icmp eq i32 %931, -1
  %935 = icmp eq i32 %932, 0
  %936 = or i1 %934, %935
  %937 = zext i1 %936 to i8
  store i8 %937, i8* %14, align 1, !tbaa !2433
  %938 = and i32 %932, 255
  %939 = tail call i32 @llvm.ctpop.i32(i32 %938) #10
  %940 = trunc i32 %939 to i8
  %941 = and i8 %940, 1
  %942 = xor i8 %941, 1
  store i8 %942, i8* %21, align 1, !tbaa !2447
  %943 = xor i32 %931, %932
  %944 = lshr i32 %943, 4
  %945 = trunc i32 %944 to i8
  %946 = and i8 %945, 1
  store i8 %946, i8* %27, align 1, !tbaa !2451
  %947 = zext i1 %935 to i8
  store i8 %947, i8* %30, align 1, !tbaa !2448
  %948 = lshr i32 %932, 31
  %949 = trunc i32 %948 to i8
  store i8 %949, i8* %33, align 1, !tbaa !2449
  %950 = lshr i32 %931, 31
  %951 = xor i32 %948, %950
  %952 = add nuw nsw i32 %951, %948
  %953 = icmp eq i32 %952, 2
  %954 = zext i1 %953 to i8
  store i8 %954, i8* %39, align 1, !tbaa !2450
  %955 = sext i32 %932 to i64
  store i64 %955, i64* %RSI, align 8, !tbaa !2428
  %956 = shl nsw i64 %955, 3
  %957 = add i64 %956, %927
  %958 = add i64 %877, 49
  store i64 %958, i64* %PC, align 8
  %959 = bitcast i64 %915 to double
  %960 = inttoptr i64 %957 to double*
  %961 = load double, double* %960, align 8
  %962 = fsub double %959, %961
  store double %962, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %963 = load i64, i64* %RBP, align 8
  %964 = add i64 %963, -64
  %965 = add i64 %877, 54
  store i64 %965, i64* %PC, align 8
  %966 = inttoptr i64 %964 to double*
  store double %962, double* %966, align 8
  %967 = load i64, i64* %RBP, align 8
  %968 = add i64 %967, -16
  %969 = load i64, i64* %PC, align 8
  %970 = add i64 %969, 4
  store i64 %970, i64* %PC, align 8
  %971 = inttoptr i64 %968 to i64*
  %972 = load i64, i64* %971, align 8
  store i64 %972, i64* %RDX, align 8, !tbaa !2428
  %973 = add i64 %967, -28
  %974 = add i64 %969, 8
  store i64 %974, i64* %PC, align 8
  %975 = inttoptr i64 %973 to i32*
  %976 = load i32, i32* %975, align 4
  %977 = sext i32 %976 to i64
  store i64 %977, i64* %RSI, align 8, !tbaa !2428
  %978 = shl nsw i64 %977, 3
  %979 = add i64 %978, %972
  %980 = add i64 %969, 13
  store i64 %980, i64* %PC, align 8
  %981 = inttoptr i64 %979 to double*
  %982 = load double, double* %981, align 8
  store double %982, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %983 = add i64 %969, 17
  store i64 %983, i64* %PC, align 8
  %984 = load i64, i64* %971, align 8
  store i64 %984, i64* %RDX, align 8, !tbaa !2428
  %985 = add i64 %967, -32
  %986 = add i64 %969, 21
  store i64 %986, i64* %PC, align 8
  %987 = inttoptr i64 %985 to i32*
  %988 = load i32, i32* %987, align 4
  %989 = sext i32 %988 to i64
  store i64 %989, i64* %RSI, align 8, !tbaa !2428
  %990 = shl nsw i64 %989, 3
  %991 = add i64 %990, %984
  %992 = add i64 %969, 26
  store i64 %992, i64* %PC, align 8
  %993 = inttoptr i64 %991 to double*
  %994 = load double, double* %993, align 8
  %995 = fsub double %982, %994
  store double %995, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %996 = add i64 %967, -72
  %997 = add i64 %969, 31
  store i64 %997, i64* %PC, align 8
  %998 = inttoptr i64 %996 to double*
  store double %995, double* %998, align 8
  %999 = load i64, i64* %RBP, align 8
  %1000 = add i64 %999, -16
  %1001 = load i64, i64* %PC, align 8
  %1002 = add i64 %1001, 4
  store i64 %1002, i64* %PC, align 8
  %1003 = inttoptr i64 %1000 to i64*
  %1004 = load i64, i64* %1003, align 8
  store i64 %1004, i64* %RDX, align 8, !tbaa !2428
  %1005 = add i64 %999, -28
  %1006 = add i64 %1001, 7
  store i64 %1006, i64* %PC, align 8
  %1007 = inttoptr i64 %1005 to i32*
  %1008 = load i32, i32* %1007, align 4
  %1009 = add i32 %1008, 1
  %1010 = zext i32 %1009 to i64
  store i64 %1010, i64* %RCX, align 8, !tbaa !2428
  %1011 = icmp eq i32 %1008, -1
  %1012 = icmp eq i32 %1009, 0
  %1013 = or i1 %1011, %1012
  %1014 = zext i1 %1013 to i8
  store i8 %1014, i8* %14, align 1, !tbaa !2433
  %1015 = and i32 %1009, 255
  %1016 = tail call i32 @llvm.ctpop.i32(i32 %1015) #10
  %1017 = trunc i32 %1016 to i8
  %1018 = and i8 %1017, 1
  %1019 = xor i8 %1018, 1
  store i8 %1019, i8* %21, align 1, !tbaa !2447
  %1020 = xor i32 %1008, %1009
  %1021 = lshr i32 %1020, 4
  %1022 = trunc i32 %1021 to i8
  %1023 = and i8 %1022, 1
  store i8 %1023, i8* %27, align 1, !tbaa !2451
  %1024 = zext i1 %1012 to i8
  store i8 %1024, i8* %30, align 1, !tbaa !2448
  %1025 = lshr i32 %1009, 31
  %1026 = trunc i32 %1025 to i8
  store i8 %1026, i8* %33, align 1, !tbaa !2449
  %1027 = lshr i32 %1008, 31
  %1028 = xor i32 %1025, %1027
  %1029 = add nuw nsw i32 %1028, %1025
  %1030 = icmp eq i32 %1029, 2
  %1031 = zext i1 %1030 to i8
  store i8 %1031, i8* %39, align 1, !tbaa !2450
  %1032 = sext i32 %1009 to i64
  store i64 %1032, i64* %RSI, align 8, !tbaa !2428
  %1033 = shl nsw i64 %1032, 3
  %1034 = add i64 %1033, %1004
  %1035 = add i64 %1001, 18
  store i64 %1035, i64* %PC, align 8
  %1036 = inttoptr i64 %1034 to i64*
  %1037 = load i64, i64* %1036, align 8
  %1038 = load i64, i64* %RAX, align 8
  %1039 = xor i64 %1038, %1037
  store i64 %1039, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2433
  %1040 = trunc i64 %1039 to i32
  %1041 = and i32 %1040, 255
  %1042 = tail call i32 @llvm.ctpop.i32(i32 %1041) #10
  %1043 = trunc i32 %1042 to i8
  %1044 = and i8 %1043, 1
  %1045 = xor i8 %1044, 1
  store i8 %1045, i8* %21, align 1, !tbaa !2447
  %1046 = icmp eq i64 %1039, 0
  %1047 = zext i1 %1046 to i8
  store i8 %1047, i8* %30, align 1, !tbaa !2448
  %1048 = lshr i64 %1039, 63
  %1049 = trunc i64 %1048 to i8
  store i8 %1049, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2451
  store i64 %1039, i64* %1683, align 1, !tbaa !2428
  store i64 0, i64* %1681, align 1, !tbaa !2428
  %1050 = add i64 %1001, 35
  store i64 %1050, i64* %PC, align 8
  %1051 = load i64, i64* %1003, align 8
  store i64 %1051, i64* %RAX, align 8, !tbaa !2428
  %1052 = add i64 %999, -32
  %1053 = add i64 %1001, 38
  store i64 %1053, i64* %PC, align 8
  %1054 = inttoptr i64 %1052 to i32*
  %1055 = load i32, i32* %1054, align 4
  %1056 = add i32 %1055, 1
  %1057 = zext i32 %1056 to i64
  store i64 %1057, i64* %RCX, align 8, !tbaa !2428
  %1058 = icmp eq i32 %1055, -1
  %1059 = icmp eq i32 %1056, 0
  %1060 = or i1 %1058, %1059
  %1061 = zext i1 %1060 to i8
  store i8 %1061, i8* %14, align 1, !tbaa !2433
  %1062 = and i32 %1056, 255
  %1063 = tail call i32 @llvm.ctpop.i32(i32 %1062) #10
  %1064 = trunc i32 %1063 to i8
  %1065 = and i8 %1064, 1
  %1066 = xor i8 %1065, 1
  store i8 %1066, i8* %21, align 1, !tbaa !2447
  %1067 = xor i32 %1055, %1056
  %1068 = lshr i32 %1067, 4
  %1069 = trunc i32 %1068 to i8
  %1070 = and i8 %1069, 1
  store i8 %1070, i8* %27, align 1, !tbaa !2451
  %1071 = zext i1 %1059 to i8
  store i8 %1071, i8* %30, align 1, !tbaa !2448
  %1072 = lshr i32 %1056, 31
  %1073 = trunc i32 %1072 to i8
  store i8 %1073, i8* %33, align 1, !tbaa !2449
  %1074 = lshr i32 %1055, 31
  %1075 = xor i32 %1072, %1074
  %1076 = add nuw nsw i32 %1075, %1072
  %1077 = icmp eq i32 %1076, 2
  %1078 = zext i1 %1077 to i8
  store i8 %1078, i8* %39, align 1, !tbaa !2450
  %1079 = sext i32 %1056 to i64
  store i64 %1079, i64* %RDX, align 8, !tbaa !2428
  %1080 = shl nsw i64 %1079, 3
  %1081 = add i64 %1080, %1051
  %1082 = add i64 %1001, 49
  store i64 %1082, i64* %PC, align 8
  %1083 = bitcast i64 %1039 to double
  %1084 = inttoptr i64 %1081 to double*
  %1085 = load double, double* %1084, align 8
  %1086 = fadd double %1083, %1085
  store double %1086, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %1087 = load i64, i64* %RBP, align 8
  %1088 = add i64 %1087, -80
  %1089 = add i64 %1001, 54
  store i64 %1089, i64* %PC, align 8
  %1090 = inttoptr i64 %1088 to double*
  store double %1086, double* %1090, align 8
  %1091 = load i64, i64* %RBP, align 8
  %1092 = add i64 %1091, -16
  %1093 = load i64, i64* %PC, align 8
  %1094 = add i64 %1093, 4
  store i64 %1094, i64* %PC, align 8
  %1095 = inttoptr i64 %1092 to i64*
  %1096 = load i64, i64* %1095, align 8
  store i64 %1096, i64* %RAX, align 8, !tbaa !2428
  %1097 = add i64 %1091, -36
  %1098 = add i64 %1093, 8
  store i64 %1098, i64* %PC, align 8
  %1099 = inttoptr i64 %1097 to i32*
  %1100 = load i32, i32* %1099, align 4
  %1101 = sext i32 %1100 to i64
  store i64 %1101, i64* %RDX, align 8, !tbaa !2428
  %1102 = shl nsw i64 %1101, 3
  %1103 = add i64 %1102, %1096
  %1104 = add i64 %1093, 13
  store i64 %1104, i64* %PC, align 8
  %1105 = inttoptr i64 %1103 to double*
  %1106 = load double, double* %1105, align 8
  store double %1106, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %1107 = add i64 %1093, 17
  store i64 %1107, i64* %PC, align 8
  %1108 = load i64, i64* %1095, align 8
  store i64 %1108, i64* %RAX, align 8, !tbaa !2428
  %1109 = add i64 %1091, -40
  %1110 = add i64 %1093, 21
  store i64 %1110, i64* %PC, align 8
  %1111 = inttoptr i64 %1109 to i32*
  %1112 = load i32, i32* %1111, align 4
  %1113 = sext i32 %1112 to i64
  store i64 %1113, i64* %RDX, align 8, !tbaa !2428
  %1114 = shl nsw i64 %1113, 3
  %1115 = add i64 %1114, %1108
  %1116 = add i64 %1093, 26
  store i64 %1116, i64* %PC, align 8
  %1117 = inttoptr i64 %1115 to double*
  %1118 = load double, double* %1117, align 8
  %1119 = fadd double %1106, %1118
  store double %1119, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %1120 = add i64 %1091, -88
  %1121 = add i64 %1093, 31
  store i64 %1121, i64* %PC, align 8
  %1122 = inttoptr i64 %1120 to double*
  store double %1119, double* %1122, align 8
  %1123 = load i64, i64* %RBP, align 8
  %1124 = add i64 %1123, -16
  %1125 = load i64, i64* %PC, align 8
  %1126 = add i64 %1125, 4
  store i64 %1126, i64* %PC, align 8
  %1127 = inttoptr i64 %1124 to i64*
  %1128 = load i64, i64* %1127, align 8
  store i64 %1128, i64* %RAX, align 8, !tbaa !2428
  %1129 = add i64 %1123, -36
  %1130 = add i64 %1125, 7
  store i64 %1130, i64* %PC, align 8
  %1131 = inttoptr i64 %1129 to i32*
  %1132 = load i32, i32* %1131, align 4
  %1133 = add i32 %1132, 1
  %1134 = zext i32 %1133 to i64
  store i64 %1134, i64* %RCX, align 8, !tbaa !2428
  %1135 = icmp eq i32 %1132, -1
  %1136 = icmp eq i32 %1133, 0
  %1137 = or i1 %1135, %1136
  %1138 = zext i1 %1137 to i8
  store i8 %1138, i8* %14, align 1, !tbaa !2433
  %1139 = and i32 %1133, 255
  %1140 = tail call i32 @llvm.ctpop.i32(i32 %1139) #10
  %1141 = trunc i32 %1140 to i8
  %1142 = and i8 %1141, 1
  %1143 = xor i8 %1142, 1
  store i8 %1143, i8* %21, align 1, !tbaa !2447
  %1144 = xor i32 %1132, %1133
  %1145 = lshr i32 %1144, 4
  %1146 = trunc i32 %1145 to i8
  %1147 = and i8 %1146, 1
  store i8 %1147, i8* %27, align 1, !tbaa !2451
  %1148 = zext i1 %1136 to i8
  store i8 %1148, i8* %30, align 1, !tbaa !2448
  %1149 = lshr i32 %1133, 31
  %1150 = trunc i32 %1149 to i8
  store i8 %1150, i8* %33, align 1, !tbaa !2449
  %1151 = lshr i32 %1132, 31
  %1152 = xor i32 %1149, %1151
  %1153 = add nuw nsw i32 %1152, %1149
  %1154 = icmp eq i32 %1153, 2
  %1155 = zext i1 %1154 to i8
  store i8 %1155, i8* %39, align 1, !tbaa !2450
  %1156 = sext i32 %1133 to i64
  store i64 %1156, i64* %RDX, align 8, !tbaa !2428
  %1157 = shl nsw i64 %1156, 3
  %1158 = add i64 %1157, %1128
  %1159 = add i64 %1125, 18
  store i64 %1159, i64* %PC, align 8
  %1160 = inttoptr i64 %1158 to double*
  %1161 = load double, double* %1160, align 8
  store double %1161, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %1162 = add i64 %1125, 22
  store i64 %1162, i64* %PC, align 8
  %1163 = load i64, i64* %1127, align 8
  store i64 %1163, i64* %RAX, align 8, !tbaa !2428
  %1164 = add i64 %1123, -40
  %1165 = add i64 %1125, 25
  store i64 %1165, i64* %PC, align 8
  %1166 = inttoptr i64 %1164 to i32*
  %1167 = load i32, i32* %1166, align 4
  %1168 = add i32 %1167, 1
  %1169 = zext i32 %1168 to i64
  store i64 %1169, i64* %RCX, align 8, !tbaa !2428
  %1170 = icmp eq i32 %1167, -1
  %1171 = icmp eq i32 %1168, 0
  %1172 = or i1 %1170, %1171
  %1173 = zext i1 %1172 to i8
  store i8 %1173, i8* %14, align 1, !tbaa !2433
  %1174 = and i32 %1168, 255
  %1175 = tail call i32 @llvm.ctpop.i32(i32 %1174) #10
  %1176 = trunc i32 %1175 to i8
  %1177 = and i8 %1176, 1
  %1178 = xor i8 %1177, 1
  store i8 %1178, i8* %21, align 1, !tbaa !2447
  %1179 = xor i32 %1167, %1168
  %1180 = lshr i32 %1179, 4
  %1181 = trunc i32 %1180 to i8
  %1182 = and i8 %1181, 1
  store i8 %1182, i8* %27, align 1, !tbaa !2451
  %1183 = zext i1 %1171 to i8
  store i8 %1183, i8* %30, align 1, !tbaa !2448
  %1184 = lshr i32 %1168, 31
  %1185 = trunc i32 %1184 to i8
  store i8 %1185, i8* %33, align 1, !tbaa !2449
  %1186 = lshr i32 %1167, 31
  %1187 = xor i32 %1184, %1186
  %1188 = add nuw nsw i32 %1187, %1184
  %1189 = icmp eq i32 %1188, 2
  %1190 = zext i1 %1189 to i8
  store i8 %1190, i8* %39, align 1, !tbaa !2450
  %1191 = sext i32 %1168 to i64
  store i64 %1191, i64* %RDX, align 8, !tbaa !2428
  %1192 = shl nsw i64 %1191, 3
  %1193 = add i64 %1192, %1163
  %1194 = add i64 %1125, 36
  store i64 %1194, i64* %PC, align 8
  %1195 = inttoptr i64 %1193 to double*
  %1196 = load double, double* %1195, align 8
  %1197 = fadd double %1161, %1196
  store double %1197, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %1198 = load i64, i64* %RBP, align 8
  %1199 = add i64 %1198, -96
  %1200 = add i64 %1125, 41
  store i64 %1200, i64* %PC, align 8
  %1201 = inttoptr i64 %1199 to double*
  store double %1197, double* %1201, align 8
  %1202 = load i64, i64* %RBP, align 8
  %1203 = add i64 %1202, -16
  %1204 = load i64, i64* %PC, align 8
  %1205 = add i64 %1204, 4
  store i64 %1205, i64* %PC, align 8
  %1206 = inttoptr i64 %1203 to i64*
  %1207 = load i64, i64* %1206, align 8
  store i64 %1207, i64* %RAX, align 8, !tbaa !2428
  %1208 = add i64 %1202, -36
  %1209 = add i64 %1204, 8
  store i64 %1209, i64* %PC, align 8
  %1210 = inttoptr i64 %1208 to i32*
  %1211 = load i32, i32* %1210, align 4
  %1212 = sext i32 %1211 to i64
  store i64 %1212, i64* %RDX, align 8, !tbaa !2428
  %1213 = shl nsw i64 %1212, 3
  %1214 = add i64 %1213, %1207
  %1215 = add i64 %1204, 13
  store i64 %1215, i64* %PC, align 8
  %1216 = inttoptr i64 %1214 to double*
  %1217 = load double, double* %1216, align 8
  store double %1217, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %1218 = add i64 %1204, 17
  store i64 %1218, i64* %PC, align 8
  %1219 = load i64, i64* %1206, align 8
  store i64 %1219, i64* %RAX, align 8, !tbaa !2428
  %1220 = add i64 %1202, -40
  %1221 = add i64 %1204, 21
  store i64 %1221, i64* %PC, align 8
  %1222 = inttoptr i64 %1220 to i32*
  %1223 = load i32, i32* %1222, align 4
  %1224 = sext i32 %1223 to i64
  store i64 %1224, i64* %RDX, align 8, !tbaa !2428
  %1225 = shl nsw i64 %1224, 3
  %1226 = add i64 %1225, %1219
  %1227 = add i64 %1204, 26
  store i64 %1227, i64* %PC, align 8
  %1228 = inttoptr i64 %1226 to double*
  %1229 = load double, double* %1228, align 8
  %1230 = fsub double %1217, %1229
  store double %1230, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %1231 = add i64 %1202, -104
  %1232 = add i64 %1204, 31
  store i64 %1232, i64* %PC, align 8
  %1233 = inttoptr i64 %1231 to double*
  store double %1230, double* %1233, align 8
  %1234 = load i64, i64* %RBP, align 8
  %1235 = add i64 %1234, -16
  %1236 = load i64, i64* %PC, align 8
  %1237 = add i64 %1236, 4
  store i64 %1237, i64* %PC, align 8
  %1238 = inttoptr i64 %1235 to i64*
  %1239 = load i64, i64* %1238, align 8
  store i64 %1239, i64* %RAX, align 8, !tbaa !2428
  %1240 = add i64 %1234, -36
  %1241 = add i64 %1236, 7
  store i64 %1241, i64* %PC, align 8
  %1242 = inttoptr i64 %1240 to i32*
  %1243 = load i32, i32* %1242, align 4
  %1244 = add i32 %1243, 1
  %1245 = zext i32 %1244 to i64
  store i64 %1245, i64* %RCX, align 8, !tbaa !2428
  %1246 = icmp eq i32 %1243, -1
  %1247 = icmp eq i32 %1244, 0
  %1248 = or i1 %1246, %1247
  %1249 = zext i1 %1248 to i8
  store i8 %1249, i8* %14, align 1, !tbaa !2433
  %1250 = and i32 %1244, 255
  %1251 = tail call i32 @llvm.ctpop.i32(i32 %1250) #10
  %1252 = trunc i32 %1251 to i8
  %1253 = and i8 %1252, 1
  %1254 = xor i8 %1253, 1
  store i8 %1254, i8* %21, align 1, !tbaa !2447
  %1255 = xor i32 %1243, %1244
  %1256 = lshr i32 %1255, 4
  %1257 = trunc i32 %1256 to i8
  %1258 = and i8 %1257, 1
  store i8 %1258, i8* %27, align 1, !tbaa !2451
  %1259 = zext i1 %1247 to i8
  store i8 %1259, i8* %30, align 1, !tbaa !2448
  %1260 = lshr i32 %1244, 31
  %1261 = trunc i32 %1260 to i8
  store i8 %1261, i8* %33, align 1, !tbaa !2449
  %1262 = lshr i32 %1243, 31
  %1263 = xor i32 %1260, %1262
  %1264 = add nuw nsw i32 %1263, %1260
  %1265 = icmp eq i32 %1264, 2
  %1266 = zext i1 %1265 to i8
  store i8 %1266, i8* %39, align 1, !tbaa !2450
  %1267 = sext i32 %1244 to i64
  store i64 %1267, i64* %RDX, align 8, !tbaa !2428
  %1268 = shl nsw i64 %1267, 3
  %1269 = add i64 %1268, %1239
  %1270 = add i64 %1236, 18
  store i64 %1270, i64* %PC, align 8
  %1271 = inttoptr i64 %1269 to double*
  %1272 = load double, double* %1271, align 8
  store double %1272, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %1273 = add i64 %1236, 22
  store i64 %1273, i64* %PC, align 8
  %1274 = load i64, i64* %1238, align 8
  store i64 %1274, i64* %RAX, align 8, !tbaa !2428
  %1275 = add i64 %1234, -40
  %1276 = add i64 %1236, 25
  store i64 %1276, i64* %PC, align 8
  %1277 = inttoptr i64 %1275 to i32*
  %1278 = load i32, i32* %1277, align 4
  %1279 = add i32 %1278, 1
  %1280 = zext i32 %1279 to i64
  store i64 %1280, i64* %RCX, align 8, !tbaa !2428
  %1281 = icmp eq i32 %1278, -1
  %1282 = icmp eq i32 %1279, 0
  %1283 = or i1 %1281, %1282
  %1284 = zext i1 %1283 to i8
  store i8 %1284, i8* %14, align 1, !tbaa !2433
  %1285 = and i32 %1279, 255
  %1286 = tail call i32 @llvm.ctpop.i32(i32 %1285) #10
  %1287 = trunc i32 %1286 to i8
  %1288 = and i8 %1287, 1
  %1289 = xor i8 %1288, 1
  store i8 %1289, i8* %21, align 1, !tbaa !2447
  %1290 = xor i32 %1278, %1279
  %1291 = lshr i32 %1290, 4
  %1292 = trunc i32 %1291 to i8
  %1293 = and i8 %1292, 1
  store i8 %1293, i8* %27, align 1, !tbaa !2451
  %1294 = zext i1 %1282 to i8
  store i8 %1294, i8* %30, align 1, !tbaa !2448
  %1295 = lshr i32 %1279, 31
  %1296 = trunc i32 %1295 to i8
  store i8 %1296, i8* %33, align 1, !tbaa !2449
  %1297 = lshr i32 %1278, 31
  %1298 = xor i32 %1295, %1297
  %1299 = add nuw nsw i32 %1298, %1295
  %1300 = icmp eq i32 %1299, 2
  %1301 = zext i1 %1300 to i8
  store i8 %1301, i8* %39, align 1, !tbaa !2450
  %1302 = sext i32 %1279 to i64
  store i64 %1302, i64* %RDX, align 8, !tbaa !2428
  %1303 = shl nsw i64 %1302, 3
  %1304 = add i64 %1303, %1274
  %1305 = add i64 %1236, 36
  store i64 %1305, i64* %PC, align 8
  %1306 = inttoptr i64 %1304 to double*
  %1307 = load double, double* %1306, align 8
  %1308 = fsub double %1272, %1307
  store double %1308, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %1309 = load i64, i64* %RBP, align 8
  %1310 = add i64 %1309, -112
  %1311 = add i64 %1236, 41
  store i64 %1311, i64* %PC, align 8
  %1312 = inttoptr i64 %1310 to double*
  store double %1308, double* %1312, align 8
  %1313 = load i64, i64* %RBP, align 8
  %1314 = add i64 %1313, -56
  %1315 = load i64, i64* %PC, align 8
  %1316 = add i64 %1315, 5
  store i64 %1316, i64* %PC, align 8
  %1317 = inttoptr i64 %1314 to double*
  %1318 = load double, double* %1317, align 8
  store double %1318, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %1319 = add i64 %1313, -88
  %1320 = add i64 %1315, 10
  store i64 %1320, i64* %PC, align 8
  %1321 = inttoptr i64 %1319 to double*
  %1322 = load double, double* %1321, align 8
  %1323 = fadd double %1318, %1322
  store double %1323, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %1324 = add i64 %1313, -16
  %1325 = add i64 %1315, 14
  store i64 %1325, i64* %PC, align 8
  %1326 = inttoptr i64 %1324 to i64*
  %1327 = load i64, i64* %1326, align 8
  store i64 %1327, i64* %RAX, align 8, !tbaa !2428
  %1328 = add i64 %1313, -28
  %1329 = add i64 %1315, 18
  store i64 %1329, i64* %PC, align 8
  %1330 = inttoptr i64 %1328 to i32*
  %1331 = load i32, i32* %1330, align 4
  %1332 = sext i32 %1331 to i64
  store i64 %1332, i64* %RDX, align 8, !tbaa !2428
  %1333 = shl nsw i64 %1332, 3
  %1334 = add i64 %1333, %1327
  %1335 = add i64 %1315, 23
  store i64 %1335, i64* %PC, align 8
  %1336 = inttoptr i64 %1334 to double*
  store double %1323, double* %1336, align 8
  %1337 = load i64, i64* %RBP, align 8
  %1338 = add i64 %1337, -64
  %1339 = load i64, i64* %PC, align 8
  %1340 = add i64 %1339, 5
  store i64 %1340, i64* %PC, align 8
  %1341 = inttoptr i64 %1338 to double*
  %1342 = load double, double* %1341, align 8
  store double %1342, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %1343 = add i64 %1337, -96
  %1344 = add i64 %1339, 10
  store i64 %1344, i64* %PC, align 8
  %1345 = inttoptr i64 %1343 to double*
  %1346 = load double, double* %1345, align 8
  %1347 = fsub double %1342, %1346
  store double %1347, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %1348 = add i64 %1337, -16
  %1349 = add i64 %1339, 14
  store i64 %1349, i64* %PC, align 8
  %1350 = inttoptr i64 %1348 to i64*
  %1351 = load i64, i64* %1350, align 8
  store i64 %1351, i64* %RAX, align 8, !tbaa !2428
  %1352 = add i64 %1337, -28
  %1353 = add i64 %1339, 17
  store i64 %1353, i64* %PC, align 8
  %1354 = inttoptr i64 %1352 to i32*
  %1355 = load i32, i32* %1354, align 4
  %1356 = add i32 %1355, 1
  %1357 = zext i32 %1356 to i64
  store i64 %1357, i64* %RCX, align 8, !tbaa !2428
  %1358 = icmp eq i32 %1355, -1
  %1359 = icmp eq i32 %1356, 0
  %1360 = or i1 %1358, %1359
  %1361 = zext i1 %1360 to i8
  store i8 %1361, i8* %14, align 1, !tbaa !2433
  %1362 = and i32 %1356, 255
  %1363 = tail call i32 @llvm.ctpop.i32(i32 %1362) #10
  %1364 = trunc i32 %1363 to i8
  %1365 = and i8 %1364, 1
  %1366 = xor i8 %1365, 1
  store i8 %1366, i8* %21, align 1, !tbaa !2447
  %1367 = xor i32 %1355, %1356
  %1368 = lshr i32 %1367, 4
  %1369 = trunc i32 %1368 to i8
  %1370 = and i8 %1369, 1
  store i8 %1370, i8* %27, align 1, !tbaa !2451
  %1371 = zext i1 %1359 to i8
  store i8 %1371, i8* %30, align 1, !tbaa !2448
  %1372 = lshr i32 %1356, 31
  %1373 = trunc i32 %1372 to i8
  store i8 %1373, i8* %33, align 1, !tbaa !2449
  %1374 = lshr i32 %1355, 31
  %1375 = xor i32 %1372, %1374
  %1376 = add nuw nsw i32 %1375, %1372
  %1377 = icmp eq i32 %1376, 2
  %1378 = zext i1 %1377 to i8
  store i8 %1378, i8* %39, align 1, !tbaa !2450
  %1379 = sext i32 %1356 to i64
  store i64 %1379, i64* %RDX, align 8, !tbaa !2428
  %1380 = shl nsw i64 %1379, 3
  %1381 = add i64 %1380, %1351
  %1382 = add i64 %1339, 28
  store i64 %1382, i64* %PC, align 8
  %1383 = inttoptr i64 %1381 to double*
  store double %1347, double* %1383, align 8
  %1384 = load i64, i64* %RBP, align 8
  %1385 = add i64 %1384, -56
  %1386 = load i64, i64* %PC, align 8
  %1387 = add i64 %1386, 5
  store i64 %1387, i64* %PC, align 8
  %1388 = inttoptr i64 %1385 to double*
  %1389 = load double, double* %1388, align 8
  store double %1389, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %1390 = add i64 %1384, -88
  %1391 = add i64 %1386, 10
  store i64 %1391, i64* %PC, align 8
  %1392 = inttoptr i64 %1390 to double*
  %1393 = load double, double* %1392, align 8
  %1394 = fsub double %1389, %1393
  store double %1394, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %1395 = add i64 %1384, -16
  %1396 = add i64 %1386, 14
  store i64 %1396, i64* %PC, align 8
  %1397 = inttoptr i64 %1395 to i64*
  %1398 = load i64, i64* %1397, align 8
  store i64 %1398, i64* %RAX, align 8, !tbaa !2428
  %1399 = add i64 %1384, -36
  %1400 = add i64 %1386, 18
  store i64 %1400, i64* %PC, align 8
  %1401 = inttoptr i64 %1399 to i32*
  %1402 = load i32, i32* %1401, align 4
  %1403 = sext i32 %1402 to i64
  store i64 %1403, i64* %RDX, align 8, !tbaa !2428
  %1404 = shl nsw i64 %1403, 3
  %1405 = add i64 %1404, %1398
  %1406 = add i64 %1386, 23
  store i64 %1406, i64* %PC, align 8
  %1407 = inttoptr i64 %1405 to double*
  store double %1394, double* %1407, align 8
  %1408 = load i64, i64* %RBP, align 8
  %1409 = add i64 %1408, -64
  %1410 = load i64, i64* %PC, align 8
  %1411 = add i64 %1410, 5
  store i64 %1411, i64* %PC, align 8
  %1412 = inttoptr i64 %1409 to double*
  %1413 = load double, double* %1412, align 8
  store double %1413, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %1414 = add i64 %1408, -96
  %1415 = add i64 %1410, 10
  store i64 %1415, i64* %PC, align 8
  %1416 = inttoptr i64 %1414 to double*
  %1417 = load double, double* %1416, align 8
  %1418 = fadd double %1413, %1417
  store double %1418, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %1419 = add i64 %1408, -16
  %1420 = add i64 %1410, 14
  store i64 %1420, i64* %PC, align 8
  %1421 = inttoptr i64 %1419 to i64*
  %1422 = load i64, i64* %1421, align 8
  store i64 %1422, i64* %RAX, align 8, !tbaa !2428
  %1423 = add i64 %1408, -36
  %1424 = add i64 %1410, 17
  store i64 %1424, i64* %PC, align 8
  %1425 = inttoptr i64 %1423 to i32*
  %1426 = load i32, i32* %1425, align 4
  %1427 = add i32 %1426, 1
  %1428 = zext i32 %1427 to i64
  store i64 %1428, i64* %RCX, align 8, !tbaa !2428
  %1429 = icmp eq i32 %1426, -1
  %1430 = icmp eq i32 %1427, 0
  %1431 = or i1 %1429, %1430
  %1432 = zext i1 %1431 to i8
  store i8 %1432, i8* %14, align 1, !tbaa !2433
  %1433 = and i32 %1427, 255
  %1434 = tail call i32 @llvm.ctpop.i32(i32 %1433) #10
  %1435 = trunc i32 %1434 to i8
  %1436 = and i8 %1435, 1
  %1437 = xor i8 %1436, 1
  store i8 %1437, i8* %21, align 1, !tbaa !2447
  %1438 = xor i32 %1426, %1427
  %1439 = lshr i32 %1438, 4
  %1440 = trunc i32 %1439 to i8
  %1441 = and i8 %1440, 1
  store i8 %1441, i8* %27, align 1, !tbaa !2451
  %1442 = zext i1 %1430 to i8
  store i8 %1442, i8* %30, align 1, !tbaa !2448
  %1443 = lshr i32 %1427, 31
  %1444 = trunc i32 %1443 to i8
  store i8 %1444, i8* %33, align 1, !tbaa !2449
  %1445 = lshr i32 %1426, 31
  %1446 = xor i32 %1443, %1445
  %1447 = add nuw nsw i32 %1446, %1443
  %1448 = icmp eq i32 %1447, 2
  %1449 = zext i1 %1448 to i8
  store i8 %1449, i8* %39, align 1, !tbaa !2450
  %1450 = sext i32 %1427 to i64
  store i64 %1450, i64* %RDX, align 8, !tbaa !2428
  %1451 = shl nsw i64 %1450, 3
  %1452 = add i64 %1451, %1422
  %1453 = add i64 %1410, 28
  store i64 %1453, i64* %PC, align 8
  %1454 = inttoptr i64 %1452 to double*
  store double %1418, double* %1454, align 8
  %1455 = load i64, i64* %RBP, align 8
  %1456 = add i64 %1455, -72
  %1457 = load i64, i64* %PC, align 8
  %1458 = add i64 %1457, 5
  store i64 %1458, i64* %PC, align 8
  %1459 = inttoptr i64 %1456 to double*
  %1460 = load double, double* %1459, align 8
  store double %1460, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %1461 = add i64 %1455, -112
  %1462 = add i64 %1457, 10
  store i64 %1462, i64* %PC, align 8
  %1463 = inttoptr i64 %1461 to double*
  %1464 = load double, double* %1463, align 8
  %1465 = fsub double %1460, %1464
  store double %1465, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %1466 = add i64 %1455, -16
  %1467 = add i64 %1457, 14
  store i64 %1467, i64* %PC, align 8
  %1468 = inttoptr i64 %1466 to i64*
  %1469 = load i64, i64* %1468, align 8
  store i64 %1469, i64* %RAX, align 8, !tbaa !2428
  %1470 = add i64 %1455, -32
  %1471 = add i64 %1457, 18
  store i64 %1471, i64* %PC, align 8
  %1472 = inttoptr i64 %1470 to i32*
  %1473 = load i32, i32* %1472, align 4
  %1474 = sext i32 %1473 to i64
  store i64 %1474, i64* %RDX, align 8, !tbaa !2428
  %1475 = shl nsw i64 %1474, 3
  %1476 = add i64 %1475, %1469
  %1477 = add i64 %1457, 23
  store i64 %1477, i64* %PC, align 8
  %1478 = inttoptr i64 %1476 to double*
  store double %1465, double* %1478, align 8
  %1479 = load i64, i64* %RBP, align 8
  %1480 = add i64 %1479, -80
  %1481 = load i64, i64* %PC, align 8
  %1482 = add i64 %1481, 5
  store i64 %1482, i64* %PC, align 8
  %1483 = inttoptr i64 %1480 to double*
  %1484 = load double, double* %1483, align 8
  store double %1484, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %1485 = add i64 %1479, -104
  %1486 = add i64 %1481, 10
  store i64 %1486, i64* %PC, align 8
  %1487 = inttoptr i64 %1485 to double*
  %1488 = load double, double* %1487, align 8
  %1489 = fsub double %1484, %1488
  store double %1489, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %1490 = add i64 %1479, -16
  %1491 = add i64 %1481, 14
  store i64 %1491, i64* %PC, align 8
  %1492 = inttoptr i64 %1490 to i64*
  %1493 = load i64, i64* %1492, align 8
  store i64 %1493, i64* %RAX, align 8, !tbaa !2428
  %1494 = add i64 %1479, -32
  %1495 = add i64 %1481, 17
  store i64 %1495, i64* %PC, align 8
  %1496 = inttoptr i64 %1494 to i32*
  %1497 = load i32, i32* %1496, align 4
  %1498 = add i32 %1497, 1
  %1499 = zext i32 %1498 to i64
  store i64 %1499, i64* %RCX, align 8, !tbaa !2428
  %1500 = icmp eq i32 %1497, -1
  %1501 = icmp eq i32 %1498, 0
  %1502 = or i1 %1500, %1501
  %1503 = zext i1 %1502 to i8
  store i8 %1503, i8* %14, align 1, !tbaa !2433
  %1504 = and i32 %1498, 255
  %1505 = tail call i32 @llvm.ctpop.i32(i32 %1504) #10
  %1506 = trunc i32 %1505 to i8
  %1507 = and i8 %1506, 1
  %1508 = xor i8 %1507, 1
  store i8 %1508, i8* %21, align 1, !tbaa !2447
  %1509 = xor i32 %1497, %1498
  %1510 = lshr i32 %1509, 4
  %1511 = trunc i32 %1510 to i8
  %1512 = and i8 %1511, 1
  store i8 %1512, i8* %27, align 1, !tbaa !2451
  %1513 = zext i1 %1501 to i8
  store i8 %1513, i8* %30, align 1, !tbaa !2448
  %1514 = lshr i32 %1498, 31
  %1515 = trunc i32 %1514 to i8
  store i8 %1515, i8* %33, align 1, !tbaa !2449
  %1516 = lshr i32 %1497, 31
  %1517 = xor i32 %1514, %1516
  %1518 = add nuw nsw i32 %1517, %1514
  %1519 = icmp eq i32 %1518, 2
  %1520 = zext i1 %1519 to i8
  store i8 %1520, i8* %39, align 1, !tbaa !2450
  %1521 = sext i32 %1498 to i64
  store i64 %1521, i64* %RDX, align 8, !tbaa !2428
  %1522 = shl nsw i64 %1521, 3
  %1523 = add i64 %1522, %1493
  %1524 = add i64 %1481, 28
  store i64 %1524, i64* %PC, align 8
  %1525 = inttoptr i64 %1523 to double*
  store double %1489, double* %1525, align 8
  %1526 = load i64, i64* %RBP, align 8
  %1527 = add i64 %1526, -72
  %1528 = load i64, i64* %PC, align 8
  %1529 = add i64 %1528, 5
  store i64 %1529, i64* %PC, align 8
  %1530 = inttoptr i64 %1527 to double*
  %1531 = load double, double* %1530, align 8
  store double %1531, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %1532 = add i64 %1526, -112
  %1533 = add i64 %1528, 10
  store i64 %1533, i64* %PC, align 8
  %1534 = inttoptr i64 %1532 to double*
  %1535 = load double, double* %1534, align 8
  %1536 = fadd double %1531, %1535
  store double %1536, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %1537 = add i64 %1526, -16
  %1538 = add i64 %1528, 14
  store i64 %1538, i64* %PC, align 8
  %1539 = inttoptr i64 %1537 to i64*
  %1540 = load i64, i64* %1539, align 8
  store i64 %1540, i64* %RAX, align 8, !tbaa !2428
  %1541 = add i64 %1526, -40
  %1542 = add i64 %1528, 18
  store i64 %1542, i64* %PC, align 8
  %1543 = inttoptr i64 %1541 to i32*
  %1544 = load i32, i32* %1543, align 4
  %1545 = sext i32 %1544 to i64
  store i64 %1545, i64* %RDX, align 8, !tbaa !2428
  %1546 = shl nsw i64 %1545, 3
  %1547 = add i64 %1546, %1540
  %1548 = add i64 %1528, 23
  store i64 %1548, i64* %PC, align 8
  %1549 = inttoptr i64 %1547 to double*
  store double %1536, double* %1549, align 8
  %1550 = load i64, i64* %RBP, align 8
  %1551 = add i64 %1550, -80
  %1552 = load i64, i64* %PC, align 8
  %1553 = add i64 %1552, 5
  store i64 %1553, i64* %PC, align 8
  %1554 = inttoptr i64 %1551 to double*
  %1555 = load double, double* %1554, align 8
  store double %1555, double* %1680, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1682, align 1, !tbaa !2452
  %1556 = add i64 %1550, -104
  %1557 = add i64 %1552, 10
  store i64 %1557, i64* %PC, align 8
  %1558 = inttoptr i64 %1556 to double*
  %1559 = load double, double* %1558, align 8
  %1560 = fadd double %1555, %1559
  store double %1560, double* %1680, align 1, !tbaa !2452
  store i64 0, i64* %1681, align 1, !tbaa !2452
  %1561 = add i64 %1550, -16
  %1562 = add i64 %1552, 14
  store i64 %1562, i64* %PC, align 8
  %1563 = inttoptr i64 %1561 to i64*
  %1564 = load i64, i64* %1563, align 8
  store i64 %1564, i64* %RAX, align 8, !tbaa !2428
  %1565 = add i64 %1550, -40
  %1566 = add i64 %1552, 17
  store i64 %1566, i64* %PC, align 8
  %1567 = inttoptr i64 %1565 to i32*
  %1568 = load i32, i32* %1567, align 4
  %1569 = add i32 %1568, 1
  %1570 = zext i32 %1569 to i64
  store i64 %1570, i64* %RCX, align 8, !tbaa !2428
  %1571 = icmp eq i32 %1568, -1
  %1572 = icmp eq i32 %1569, 0
  %1573 = or i1 %1571, %1572
  %1574 = zext i1 %1573 to i8
  store i8 %1574, i8* %14, align 1, !tbaa !2433
  %1575 = and i32 %1569, 255
  %1576 = tail call i32 @llvm.ctpop.i32(i32 %1575) #10
  %1577 = trunc i32 %1576 to i8
  %1578 = and i8 %1577, 1
  %1579 = xor i8 %1578, 1
  store i8 %1579, i8* %21, align 1, !tbaa !2447
  %1580 = xor i32 %1568, %1569
  %1581 = lshr i32 %1580, 4
  %1582 = trunc i32 %1581 to i8
  %1583 = and i8 %1582, 1
  store i8 %1583, i8* %27, align 1, !tbaa !2451
  %1584 = zext i1 %1572 to i8
  store i8 %1584, i8* %30, align 1, !tbaa !2448
  %1585 = lshr i32 %1569, 31
  %1586 = trunc i32 %1585 to i8
  store i8 %1586, i8* %33, align 1, !tbaa !2449
  %1587 = lshr i32 %1568, 31
  %1588 = xor i32 %1585, %1587
  %1589 = add nuw nsw i32 %1588, %1585
  %1590 = icmp eq i32 %1589, 2
  %1591 = zext i1 %1590 to i8
  store i8 %1591, i8* %39, align 1, !tbaa !2450
  %1592 = sext i32 %1569 to i64
  store i64 %1592, i64* %RDX, align 8, !tbaa !2428
  %1593 = shl nsw i64 %1592, 3
  %1594 = add i64 %1593, %1564
  %1595 = add i64 %1552, 28
  store i64 %1595, i64* %PC, align 8
  %1596 = inttoptr i64 %1594 to double*
  store double %1560, double* %1596, align 8
  %1597 = load i64, i64* %RBP, align 8
  %1598 = add i64 %1597, -28
  %1599 = load i64, i64* %PC, align 8
  %1600 = add i64 %1599, 3
  store i64 %1600, i64* %PC, align 8
  %1601 = inttoptr i64 %1598 to i32*
  %1602 = load i32, i32* %1601, align 4
  %1603 = add i32 %1602, 2
  %1604 = zext i32 %1603 to i64
  store i64 %1604, i64* %RAX, align 8, !tbaa !2428
  %1605 = icmp ugt i32 %1602, -3
  %1606 = zext i1 %1605 to i8
  store i8 %1606, i8* %14, align 1, !tbaa !2433
  %1607 = and i32 %1603, 255
  %1608 = tail call i32 @llvm.ctpop.i32(i32 %1607) #10
  %1609 = trunc i32 %1608 to i8
  %1610 = and i8 %1609, 1
  %1611 = xor i8 %1610, 1
  store i8 %1611, i8* %21, align 1, !tbaa !2447
  %1612 = xor i32 %1602, %1603
  %1613 = lshr i32 %1612, 4
  %1614 = trunc i32 %1613 to i8
  %1615 = and i8 %1614, 1
  store i8 %1615, i8* %27, align 1, !tbaa !2451
  %1616 = icmp eq i32 %1603, 0
  %1617 = zext i1 %1616 to i8
  store i8 %1617, i8* %30, align 1, !tbaa !2448
  %1618 = lshr i32 %1603, 31
  %1619 = trunc i32 %1618 to i8
  store i8 %1619, i8* %33, align 1, !tbaa !2449
  %1620 = lshr i32 %1602, 31
  %1621 = xor i32 %1618, %1620
  %1622 = add nuw nsw i32 %1621, %1618
  %1623 = icmp eq i32 %1622, 2
  %1624 = zext i1 %1623 to i8
  store i8 %1624, i8* %39, align 1, !tbaa !2450
  %1625 = add i64 %1599, 9
  store i64 %1625, i64* %PC, align 8
  store i32 %1603, i32* %1601, align 4
  %1626 = load i64, i64* %PC, align 8
  %1627 = add i64 %1626, -576
  store i64 %1627, i64* %PC, align 8, !tbaa !2428
  br label %block_402506

block_4024f0:                                     ; preds = %block_4024eb, %block_402480
  %1628 = phi i64 [ %91, %block_402480 ], [ %724, %block_4024eb ]
  %1629 = phi i64 [ %61, %block_402480 ], [ %131, %block_4024eb ]
  %MEMORY.4 = phi %struct.Memory* [ %2, %block_402480 ], [ %MEMORY.1, %block_4024eb ]
  %1630 = add i64 %1629, -44
  %1631 = add i64 %1628, 3
  store i64 %1631, i64* %PC, align 8
  %1632 = inttoptr i64 %1630 to i32*
  %1633 = load i32, i32* %1632, align 4
  %1634 = shl i32 %1633, 2
  %1635 = zext i32 %1634 to i64
  store i64 %1635, i64* %RAX, align 8, !tbaa !2428
  %1636 = lshr i32 %1633, 30
  %1637 = trunc i32 %1636 to i8
  %1638 = and i8 %1637, 1
  store i8 %1638, i8* %14, align 1, !tbaa !2432
  %1639 = and i32 %1634, 252
  %1640 = tail call i32 @llvm.ctpop.i32(i32 %1639) #10
  %1641 = trunc i32 %1640 to i8
  %1642 = and i8 %1641, 1
  %1643 = xor i8 %1642, 1
  store i8 %1643, i8* %21, align 1, !tbaa !2432
  store i8 0, i8* %27, align 1, !tbaa !2432
  %1644 = icmp eq i32 %1634, 0
  %1645 = zext i1 %1644 to i8
  store i8 %1645, i8* %30, align 1, !tbaa !2432
  %1646 = lshr i32 %1633, 29
  %1647 = and i32 %1646, 1
  %1648 = trunc i32 %1647 to i8
  store i8 %1648, i8* %33, align 1, !tbaa !2432
  store i8 0, i8* %39, align 1, !tbaa !2432
  %1649 = add i64 %1629, -4
  %1650 = add i64 %1628, 9
  store i64 %1650, i64* %PC, align 8
  %1651 = inttoptr i64 %1649 to i32*
  %1652 = load i32, i32* %1651, align 4
  %1653 = sub i32 %1634, %1652
  %1654 = icmp ult i32 %1634, %1652
  %1655 = zext i1 %1654 to i8
  store i8 %1655, i8* %14, align 1, !tbaa !2433
  %1656 = and i32 %1653, 255
  %1657 = tail call i32 @llvm.ctpop.i32(i32 %1656) #10
  %1658 = trunc i32 %1657 to i8
  %1659 = and i8 %1658, 1
  %1660 = xor i8 %1659, 1
  store i8 %1660, i8* %21, align 1, !tbaa !2447
  %1661 = xor i32 %1652, %1634
  %1662 = xor i32 %1661, %1653
  %1663 = lshr i32 %1662, 4
  %1664 = trunc i32 %1663 to i8
  %1665 = and i8 %1664, 1
  store i8 %1665, i8* %27, align 1, !tbaa !2451
  %1666 = icmp eq i32 %1653, 0
  %1667 = zext i1 %1666 to i8
  store i8 %1667, i8* %30, align 1, !tbaa !2448
  %1668 = lshr i32 %1653, 31
  %1669 = trunc i32 %1668 to i8
  store i8 %1669, i8* %33, align 1, !tbaa !2449
  %1670 = lshr i32 %1652, 31
  %1671 = xor i32 %1670, %1647
  %1672 = xor i32 %1668, %1647
  %1673 = add nuw nsw i32 %1672, %1671
  %1674 = icmp eq i32 %1673, 2
  %1675 = zext i1 %1674 to i8
  store i8 %1675, i8* %39, align 1, !tbaa !2450
  %.v6 = select i1 %1666, i64 15, i64 608
  %1676 = add i64 %1628, %.v6
  %1677 = add i64 %1629, -28
  %1678 = add i64 %1676, 7
  store i64 %1678, i64* %PC, align 8
  %1679 = inttoptr i64 %1677 to i32*
  store i32 0, i32* %1679, align 4
  %1680 = bitcast %union.VectorReg* %4 to double*
  %1681 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1682 = bitcast i64* %1681 to double*
  %1683 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  %.pre3 = load i64, i64* %PC, align 8
  br i1 %1666, label %block_402506, label %block_402757
}

; Function Attrs: noinline
define %struct.Memory* @sub_4007c0___do_global_dtors_aux(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_4007c0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i8, i8* getelementptr inbounds (%__bss_start_type, %__bss_start_type* @__bss_start, i64 0, i32 0, i64 0), align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %4, align 1, !tbaa !2433
  %5 = zext i8 %3 to i32
  %6 = tail call i32 @llvm.ctpop.i32(i32 %5) #10
  %7 = trunc i32 %6 to i8
  %8 = and i8 %7, 1
  %9 = xor i8 %8, 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %9, i8* %10, align 1, !tbaa !2447
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %11, align 1, !tbaa !2451
  %12 = icmp eq i8 %3, 0
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %13, i8* %14, align 1, !tbaa !2448
  %15 = lshr i8 %3, 7
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %15, i8* %16, align 1, !tbaa !2449
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %17, align 1, !tbaa !2450
  %.v = select i1 %12, i64 9, i64 32
  %18 = add i64 %.v, %1
  store i64 %18, i64* %PC, align 8, !tbaa !2428
  br i1 %12, label %block_4007c9, label %block_4007e0

block_4007e0:                                     ; preds = %block_4007c0
  %19 = add i64 %18, 2
  store i64 %19, i64* %PC, align 8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %21 = load i64, i64* %20, align 8, !tbaa !2428
  %22 = inttoptr i64 %21 to i64*
  %23 = load i64, i64* %22, align 8
  store i64 %23, i64* %PC, align 8, !tbaa !2428
  %24 = add i64 %21, 8
  store i64 %24, i64* %20, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_4007c9:                                     ; preds = %block_4007c0
  %25 = load i64, i64* %RBP, align 8
  %26 = add i64 %18, 1
  store i64 %26, i64* %PC, align 8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %28 = load i64, i64* %27, align 8, !tbaa !2428
  %29 = add i64 %28, -8
  %30 = inttoptr i64 %29 to i64*
  store i64 %25, i64* %30, align 8
  %31 = load i64, i64* %PC, align 8
  store i64 %29, i64* %RBP, align 8, !tbaa !2428
  %32 = add i64 %31, -122
  %33 = add i64 %31, 8
  %34 = add i64 %28, -16
  %35 = inttoptr i64 %34 to i64*
  store i64 %33, i64* %35, align 8
  store i64 %34, i64* %27, align 8, !tbaa !2428
  store i64 %32, i64* %PC, align 8, !tbaa !2428
  %36 = tail call %struct.Memory* @sub_400750_deregister_tm_clones_renamed_(%struct.State* nonnull %0, i64 %32, %struct.Memory* %2)
  %37 = load i64, i64* %PC, align 8
  store i8 1, i8* getelementptr inbounds (%__bss_start_type, %__bss_start_type* @__bss_start, i64 0, i32 0, i64 0), align 8
  %38 = add i64 %37, 8
  store i64 %38, i64* %PC, align 8
  %39 = load i64, i64* %27, align 8, !tbaa !2428
  %40 = add i64 %39, 8
  %41 = inttoptr i64 %39 to i64*
  %42 = load i64, i64* %41, align 8
  store i64 %42, i64* %RBP, align 8, !tbaa !2428
  store i64 %40, i64* %27, align 8, !tbaa !2428
  %43 = add i64 %37, 9
  store i64 %43, i64* %PC, align 8
  %44 = inttoptr i64 %40 to i64*
  %45 = load i64, i64* %44, align 8
  store i64 %45, i64* %PC, align 8, !tbaa !2428
  %46 = add i64 %39, 16
  store i64 %46, i64* %27, align 8, !tbaa !2428
  ret %struct.Memory* %36
}

; Function Attrs: noinline
define %struct.Memory* @sub_401030_cdft(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_401030:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %4 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -40
  store i64 %11, i64* %RSP, align 8, !tbaa !2428
  %12 = icmp ult i64 %8, 32
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1, !tbaa !2433
  %15 = trunc i64 %11 to i32
  %16 = and i32 %15, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16) #10
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1, !tbaa !2447
  %22 = xor i64 %8, %11
  %23 = lshr i64 %22, 4
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1, !tbaa !2451
  %27 = icmp eq i64 %11, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1, !tbaa !2448
  %30 = lshr i64 %11, 63
  %31 = trunc i64 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1, !tbaa !2449
  %33 = lshr i64 %8, 63
  %34 = xor i64 %30, %33
  %35 = add nuw nsw i64 %34, %33
  %36 = icmp eq i64 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1, !tbaa !2450
  %39 = add i64 %7, -12
  %40 = load i32, i32* %EDI, align 4
  %41 = add i64 %10, 10
  store i64 %41, i64* %PC, align 8
  %42 = inttoptr i64 %39 to i32*
  store i32 %40, i32* %42, align 4
  %43 = load i64, i64* %RBP, align 8
  %44 = add i64 %43, -8
  %45 = load i32, i32* %ESI, align 4
  %46 = load i64, i64* %PC, align 8
  %47 = add i64 %46, 3
  store i64 %47, i64* %PC, align 8
  %48 = inttoptr i64 %44 to i32*
  store i32 %45, i32* %48, align 4
  %49 = load i64, i64* %RBP, align 8
  %50 = add i64 %49, -16
  %51 = load i64, i64* %RDX, align 8
  %52 = load i64, i64* %PC, align 8
  %53 = add i64 %52, 4
  store i64 %53, i64* %PC, align 8
  %54 = inttoptr i64 %50 to i64*
  store i64 %51, i64* %54, align 8
  %55 = load i64, i64* %RBP, align 8
  %56 = add i64 %55, -24
  %57 = load i64, i64* %RCX, align 8
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 4
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %56 to i64*
  store i64 %57, i64* %60, align 8
  %61 = load i64, i64* %RBP, align 8
  %62 = add i64 %61, -32
  %63 = load i64, i64* %R8, align 8
  %64 = load i64, i64* %PC, align 8
  %65 = add i64 %64, 4
  store i64 %65, i64* %PC, align 8
  %66 = inttoptr i64 %62 to i64*
  store i64 %63, i64* %66, align 8
  %67 = load i64, i64* %RBP, align 8
  %68 = add i64 %67, -4
  %69 = load i64, i64* %PC, align 8
  %70 = add i64 %69, 4
  store i64 %70, i64* %PC, align 8
  %71 = inttoptr i64 %68 to i32*
  %72 = load i32, i32* %71, align 4
  %73 = add i32 %72, -4
  %74 = icmp ult i32 %72, 4
  %75 = zext i1 %74 to i8
  store i8 %75, i8* %14, align 1, !tbaa !2433
  %76 = and i32 %73, 255
  %77 = tail call i32 @llvm.ctpop.i32(i32 %76) #10
  %78 = trunc i32 %77 to i8
  %79 = and i8 %78, 1
  %80 = xor i8 %79, 1
  store i8 %80, i8* %21, align 1, !tbaa !2447
  %81 = xor i32 %72, %73
  %82 = lshr i32 %81, 4
  %83 = trunc i32 %82 to i8
  %84 = and i8 %83, 1
  store i8 %84, i8* %26, align 1, !tbaa !2451
  %85 = icmp eq i32 %73, 0
  %86 = zext i1 %85 to i8
  store i8 %86, i8* %29, align 1, !tbaa !2448
  %87 = lshr i32 %73, 31
  %88 = trunc i32 %87 to i8
  store i8 %88, i8* %32, align 1, !tbaa !2449
  %89 = lshr i32 %72, 31
  %90 = xor i32 %87, %89
  %91 = add nuw nsw i32 %90, %89
  %92 = icmp eq i32 %91, 2
  %93 = zext i1 %92 to i8
  store i8 %93, i8* %38, align 1, !tbaa !2450
  %94 = icmp ne i8 %88, 0
  %95 = xor i1 %94, %92
  %96 = or i1 %85, %95
  %.v = select i1 %96, i64 94, i64 10
  %97 = add i64 %69, %.v
  store i64 %97, i64* %PC, align 8, !tbaa !2428
  br i1 %96, label %block_4010a8, label %block_401054

block_40105e:                                     ; preds = %block_401054
  %98 = add i64 %242, 354
  %99 = add i64 %242, 16
  %100 = load i64, i64* %RSP, align 8, !tbaa !2428
  %101 = add i64 %100, -8
  %102 = inttoptr i64 %101 to i64*
  store i64 %99, i64* %102, align 8
  store i64 %101, i64* %RSP, align 8, !tbaa !2428
  store i64 %98, i64* %PC, align 8, !tbaa !2428
  %103 = tail call %struct.Memory* @sub_4011c0_bitrv2_renamed_(%struct.State* nonnull %0, i64 %98, %struct.Memory* %2)
  %104 = load i64, i64* %RBP, align 8
  %105 = add i64 %104, -4
  %106 = load i64, i64* %PC, align 8
  %107 = add i64 %106, 3
  store i64 %107, i64* %PC, align 8
  %108 = inttoptr i64 %105 to i32*
  %109 = load i32, i32* %108, align 4
  %110 = zext i32 %109 to i64
  store i64 %110, i64* %RDI, align 8, !tbaa !2428
  %111 = add i64 %104, -16
  %112 = add i64 %106, 7
  store i64 %112, i64* %PC, align 8
  %113 = inttoptr i64 %111 to i64*
  %114 = load i64, i64* %113, align 8
  store i64 %114, i64* %RSI, align 8, !tbaa !2428
  %115 = add i64 %104, -32
  %116 = add i64 %106, 11
  store i64 %116, i64* %PC, align 8
  %117 = inttoptr i64 %115 to i64*
  %118 = load i64, i64* %117, align 8
  store i64 %118, i64* %RDX, align 8, !tbaa !2428
  %119 = add i64 %106, 2002
  %120 = add i64 %106, 16
  %121 = load i64, i64* %RSP, align 8, !tbaa !2428
  %122 = add i64 %121, -8
  %123 = inttoptr i64 %122 to i64*
  store i64 %120, i64* %123, align 8
  store i64 %122, i64* %RSP, align 8, !tbaa !2428
  store i64 %119, i64* %PC, align 8, !tbaa !2428
  %124 = tail call %struct.Memory* @sub_401840_cftfsub_renamed_(%struct.State* nonnull %0, i64 %119, %struct.Memory* %103)
  %125 = load i64, i64* %PC, align 8
  %126 = add i64 %125, 37
  store i64 %126, i64* %PC, align 8, !tbaa !2428
  br label %block_4010a3

block_4010a3:                                     ; preds = %block_401083, %block_40105e
  %127 = phi i64 [ %.pre, %block_401083 ], [ %126, %block_40105e ]
  %MEMORY.0 = phi %struct.Memory* [ %227, %block_401083 ], [ %124, %block_40105e ]
  %128 = add i64 %127, 36
  br label %block_4010c7

block_4010b2:                                     ; preds = %block_4010a8
  %129 = add i64 %169, 3
  store i64 %129, i64* %PC, align 8
  %130 = load i32, i32* %71, align 4
  %131 = zext i32 %130 to i64
  store i64 %131, i64* %RDI, align 8, !tbaa !2428
  %132 = add i64 %67, -16
  %133 = add i64 %169, 7
  store i64 %133, i64* %PC, align 8
  %134 = inttoptr i64 %132 to i64*
  %135 = load i64, i64* %134, align 8
  store i64 %135, i64* %RSI, align 8, !tbaa !2428
  %136 = add i64 %67, -32
  %137 = add i64 %169, 11
  store i64 %137, i64* %PC, align 8
  %138 = inttoptr i64 %136 to i64*
  %139 = load i64, i64* %138, align 8
  store i64 %139, i64* %RDX, align 8, !tbaa !2428
  %140 = add i64 %169, 1934
  %141 = add i64 %169, 16
  %142 = load i64, i64* %RSP, align 8, !tbaa !2428
  %143 = add i64 %142, -8
  %144 = inttoptr i64 %143 to i64*
  store i64 %141, i64* %144, align 8
  store i64 %143, i64* %RSP, align 8, !tbaa !2428
  store i64 %140, i64* %PC, align 8, !tbaa !2428
  %145 = tail call %struct.Memory* @sub_401840_cftfsub_renamed_(%struct.State* nonnull %0, i64 %140, %struct.Memory* %2)
  %.pre1 = load i64, i64* %PC, align 8
  br label %block_4010c2

block_4010a8:                                     ; preds = %block_401030
  %146 = add i64 %97, 4
  store i64 %146, i64* %PC, align 8
  %147 = load i32, i32* %71, align 4
  %148 = add i32 %147, -4
  %149 = icmp ult i32 %147, 4
  %150 = zext i1 %149 to i8
  store i8 %150, i8* %14, align 1, !tbaa !2433
  %151 = and i32 %148, 255
  %152 = tail call i32 @llvm.ctpop.i32(i32 %151) #10
  %153 = trunc i32 %152 to i8
  %154 = and i8 %153, 1
  %155 = xor i8 %154, 1
  store i8 %155, i8* %21, align 1, !tbaa !2447
  %156 = xor i32 %147, %148
  %157 = lshr i32 %156, 4
  %158 = trunc i32 %157 to i8
  %159 = and i8 %158, 1
  store i8 %159, i8* %26, align 1, !tbaa !2451
  %160 = icmp eq i32 %148, 0
  %161 = zext i1 %160 to i8
  store i8 %161, i8* %29, align 1, !tbaa !2448
  %162 = lshr i32 %148, 31
  %163 = trunc i32 %162 to i8
  store i8 %163, i8* %32, align 1, !tbaa !2449
  %164 = lshr i32 %147, 31
  %165 = xor i32 %162, %164
  %166 = add nuw nsw i32 %165, %164
  %167 = icmp eq i32 %166, 2
  %168 = zext i1 %167 to i8
  store i8 %168, i8* %38, align 1, !tbaa !2450
  %.v4 = select i1 %160, i64 10, i64 26
  %169 = add i64 %97, %.v4
  store i64 %169, i64* %PC, align 8, !tbaa !2428
  br i1 %160, label %block_4010b2, label %block_4010c2

block_4010c7:                                     ; preds = %block_4010c2, %block_4010a3
  %.sink = phi i64 [ %255, %block_4010c2 ], [ %128, %block_4010a3 ]
  %MEMORY.1 = phi %struct.Memory* [ %MEMORY.2, %block_4010c2 ], [ %MEMORY.0, %block_4010a3 ]
  %170 = load i64, i64* %RSP, align 8
  %171 = add i64 %170, 32
  store i64 %171, i64* %RSP, align 8, !tbaa !2428
  %172 = icmp ugt i64 %170, -33
  %173 = zext i1 %172 to i8
  store i8 %173, i8* %14, align 1, !tbaa !2433
  %174 = trunc i64 %171 to i32
  %175 = and i32 %174, 255
  %176 = tail call i32 @llvm.ctpop.i32(i32 %175) #10
  %177 = trunc i32 %176 to i8
  %178 = and i8 %177, 1
  %179 = xor i8 %178, 1
  store i8 %179, i8* %21, align 1, !tbaa !2447
  %180 = xor i64 %170, %171
  %181 = lshr i64 %180, 4
  %182 = trunc i64 %181 to i8
  %183 = and i8 %182, 1
  store i8 %183, i8* %26, align 1, !tbaa !2451
  %184 = icmp eq i64 %171, 0
  %185 = zext i1 %184 to i8
  store i8 %185, i8* %29, align 1, !tbaa !2448
  %186 = lshr i64 %171, 63
  %187 = trunc i64 %186 to i8
  store i8 %187, i8* %32, align 1, !tbaa !2449
  %188 = lshr i64 %170, 63
  %189 = xor i64 %186, %188
  %190 = add nuw nsw i64 %189, %186
  %191 = icmp eq i64 %190, 2
  %192 = zext i1 %191 to i8
  store i8 %192, i8* %38, align 1, !tbaa !2450
  %193 = add i64 %.sink, 5
  store i64 %193, i64* %PC, align 8
  %194 = add i64 %170, 40
  %195 = inttoptr i64 %171 to i64*
  %196 = load i64, i64* %195, align 8
  store i64 %196, i64* %RBP, align 8, !tbaa !2428
  store i64 %194, i64* %RSP, align 8, !tbaa !2428
  %197 = add i64 %.sink, 6
  store i64 %197, i64* %PC, align 8
  %198 = inttoptr i64 %194 to i64*
  %199 = load i64, i64* %198, align 8
  store i64 %199, i64* %PC, align 8, !tbaa !2428
  %200 = add i64 %170, 48
  store i64 %200, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.1

block_401083:                                     ; preds = %block_401054
  %201 = add i64 %242, 2909
  %202 = add i64 %242, 16
  %203 = load i64, i64* %RSP, align 8, !tbaa !2428
  %204 = add i64 %203, -8
  %205 = inttoptr i64 %204 to i64*
  store i64 %202, i64* %205, align 8
  store i64 %204, i64* %RSP, align 8, !tbaa !2428
  store i64 %201, i64* %PC, align 8, !tbaa !2428
  %206 = tail call %struct.Memory* @sub_401be0_bitrv2conj_renamed_(%struct.State* nonnull %0, i64 %201, %struct.Memory* %2)
  %207 = load i64, i64* %RBP, align 8
  %208 = add i64 %207, -4
  %209 = load i64, i64* %PC, align 8
  %210 = add i64 %209, 3
  store i64 %210, i64* %PC, align 8
  %211 = inttoptr i64 %208 to i32*
  %212 = load i32, i32* %211, align 4
  %213 = zext i32 %212 to i64
  store i64 %213, i64* %RDI, align 8, !tbaa !2428
  %214 = add i64 %207, -16
  %215 = add i64 %209, 7
  store i64 %215, i64* %PC, align 8
  %216 = inttoptr i64 %214 to i64*
  %217 = load i64, i64* %216, align 8
  store i64 %217, i64* %RSI, align 8, !tbaa !2428
  %218 = add i64 %207, -32
  %219 = add i64 %209, 11
  store i64 %219, i64* %PC, align 8
  %220 = inttoptr i64 %218 to i64*
  %221 = load i64, i64* %220, align 8
  store i64 %221, i64* %RDX, align 8, !tbaa !2428
  %222 = add i64 %209, 5101
  %223 = add i64 %209, 16
  %224 = load i64, i64* %RSP, align 8, !tbaa !2428
  %225 = add i64 %224, -8
  %226 = inttoptr i64 %225 to i64*
  store i64 %223, i64* %226, align 8
  store i64 %225, i64* %RSP, align 8, !tbaa !2428
  store i64 %222, i64* %PC, align 8, !tbaa !2428
  %227 = tail call %struct.Memory* @sub_402480_cftbsub_renamed_(%struct.State* nonnull %0, i64 %222, %struct.Memory* %206)
  %.pre = load i64, i64* %PC, align 8
  br label %block_4010a3

block_401054:                                     ; preds = %block_401030
  %228 = add i64 %67, -8
  %229 = add i64 %97, 4
  store i64 %229, i64* %PC, align 8
  %230 = inttoptr i64 %228 to i32*
  %231 = load i32, i32* %230, align 4
  store i8 0, i8* %14, align 1, !tbaa !2433
  %232 = and i32 %231, 255
  %233 = tail call i32 @llvm.ctpop.i32(i32 %232) #10
  %234 = trunc i32 %233 to i8
  %235 = and i8 %234, 1
  %236 = xor i8 %235, 1
  store i8 %236, i8* %21, align 1, !tbaa !2447
  store i8 0, i8* %26, align 1, !tbaa !2451
  %237 = icmp eq i32 %231, 0
  %238 = zext i1 %237 to i8
  store i8 %238, i8* %29, align 1, !tbaa !2448
  %239 = lshr i32 %231, 31
  %240 = trunc i32 %239 to i8
  store i8 %240, i8* %32, align 1, !tbaa !2449
  store i8 0, i8* %38, align 1, !tbaa !2450
  %241 = icmp ne i8 %240, 0
  %.v3 = select i1 %241, i64 47, i64 10
  %242 = add i64 %97, %.v3
  %243 = add i64 %242, 3
  store i64 %243, i64* %PC, align 8
  %244 = load i32, i32* %71, align 4
  %245 = zext i32 %244 to i64
  store i64 %245, i64* %RDI, align 8, !tbaa !2428
  %246 = add i64 %67, -24
  %247 = add i64 %242, 7
  store i64 %247, i64* %PC, align 8
  %248 = inttoptr i64 %246 to i64*
  %249 = load i64, i64* %248, align 8
  store i64 %249, i64* %RSI, align 8, !tbaa !2428
  %250 = add i64 %67, -16
  %251 = add i64 %242, 11
  store i64 %251, i64* %PC, align 8
  %252 = inttoptr i64 %250 to i64*
  %253 = load i64, i64* %252, align 8
  store i64 %253, i64* %RDX, align 8, !tbaa !2428
  br i1 %241, label %block_401083, label %block_40105e

block_4010c2:                                     ; preds = %block_4010a8, %block_4010b2
  %254 = phi i64 [ %169, %block_4010a8 ], [ %.pre1, %block_4010b2 ]
  %MEMORY.2 = phi %struct.Memory* [ %2, %block_4010a8 ], [ %145, %block_4010b2 ]
  %255 = add i64 %254, 5
  br label %block_4010c7
}

; Function Attrs: noinline
define %struct.Memory* @sub_400638__init_proc(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400638:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = add i64 %3, -8
  store i64 %4, i64* %RSP, align 8, !tbaa !2428
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_604ff0__got_type* @seg_604ff0__got to i64), i64 8) to i64*), align 8
  store i64 %11, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %5, align 1, !tbaa !2433
  %12 = trunc i64 %11 to i32
  %13 = and i32 %12, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13) #10
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %6, align 1, !tbaa !2447
  %18 = icmp eq i64 %11, 0
  %19 = zext i1 %18 to i8
  store i8 %19, i8* %8, align 1, !tbaa !2448
  %20 = lshr i64 %11, 63
  %21 = trunc i64 %20 to i8
  store i8 %21, i8* %9, align 1, !tbaa !2449
  store i8 0, i8* %10, align 1, !tbaa !2450
  store i8 0, i8* %7, align 1, !tbaa !2451
  %.v = select i1 %18, i64 18, i64 16
  %22 = add i64 %.v, %1
  store i64 %22, i64* %PC, align 8, !tbaa !2428
  br i1 %18, label %block_400638.block_40064a_crit_edge, label %block_400648

block_400638.block_40064a_crit_edge:              ; preds = %block_400638
  br label %block_40064a

block_400648:                                     ; preds = %block_400638
  %23 = add i64 %22, 2
  %24 = add i64 %3, -16
  %25 = inttoptr i64 %24 to i64*
  store i64 %23, i64* %25, align 8
  store i64 %24, i64* %RSP, align 8, !tbaa !2428
  store i64 %11, i64* %PC, align 8, !tbaa !2428
  %26 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 %11, %struct.Memory* %2)
  %.pre = load i64, i64* %RSP, align 8
  %.pre1 = load i64, i64* %PC, align 8
  br label %block_40064a

block_40064a:                                     ; preds = %block_400638.block_40064a_crit_edge, %block_400648
  %.pre-phi = phi i64* [ %RSP, %block_400638.block_40064a_crit_edge ], [ %RSP, %block_400648 ]
  %27 = phi i64 [ %22, %block_400638.block_40064a_crit_edge ], [ %.pre1, %block_400648 ]
  %28 = phi i64 [ %4, %block_400638.block_40064a_crit_edge ], [ %.pre, %block_400648 ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_400638.block_40064a_crit_edge ], [ %26, %block_400648 ]
  %29 = add i64 %28, 8
  store i64 %29, i64* %RSP, align 8, !tbaa !2428
  %30 = icmp ugt i64 %28, -9
  %31 = zext i1 %30 to i8
  store i8 %31, i8* %5, align 1, !tbaa !2433
  %32 = trunc i64 %29 to i32
  %33 = and i32 %32, 255
  %34 = tail call i32 @llvm.ctpop.i32(i32 %33) #10
  %35 = trunc i32 %34 to i8
  %36 = and i8 %35, 1
  %37 = xor i8 %36, 1
  store i8 %37, i8* %6, align 1, !tbaa !2447
  %38 = xor i64 %28, %29
  %39 = lshr i64 %38, 4
  %40 = trunc i64 %39 to i8
  %41 = and i8 %40, 1
  store i8 %41, i8* %7, align 1, !tbaa !2451
  %42 = icmp eq i64 %29, 0
  %43 = zext i1 %42 to i8
  store i8 %43, i8* %8, align 1, !tbaa !2448
  %44 = lshr i64 %29, 63
  %45 = trunc i64 %44 to i8
  store i8 %45, i8* %9, align 1, !tbaa !2449
  %46 = lshr i64 %28, 63
  %47 = xor i64 %44, %46
  %48 = add nuw nsw i64 %47, %44
  %49 = icmp eq i64 %48, 2
  %50 = zext i1 %49 to i8
  store i8 %50, i8* %10, align 1, !tbaa !2450
  %51 = add i64 %27, 5
  store i64 %51, i64* %PC, align 8
  %52 = inttoptr i64 %29 to i64*
  %53 = load i64, i64* %52, align 8
  store i64 %53, i64* %PC, align 8, !tbaa !2428
  %54 = add i64 %28, 16
  store i64 %54, i64* %.pre-phi, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0
}

; Function Attrs: noinline
define %struct.Memory* @sub_402870_cft1st(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_402870:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %7 = load i64, i64* %RBP, align 8
  %8 = add i64 %1, 1
  store i64 %8, i64* %PC, align 8
  %9 = load i64, i64* %RSP, align 8, !tbaa !2428
  %10 = add i64 %9, -8
  %11 = inttoptr i64 %10 to i64*
  store i64 %7, i64* %11, align 8
  %12 = load i64, i64* %PC, align 8
  store i64 %10, i64* %RBP, align 8, !tbaa !2428
  %13 = add i64 %9, -32
  store i64 %13, i64* %RSP, align 8, !tbaa !2428
  %14 = icmp ult i64 %10, 24
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1, !tbaa !2433
  %17 = trunc i64 %13 to i32
  %18 = and i32 %17, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18) #10
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1, !tbaa !2447
  %24 = xor i64 %10, 16
  %25 = xor i64 %24, %13
  %26 = lshr i64 %25, 4
  %27 = trunc i64 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1, !tbaa !2451
  %30 = icmp eq i64 %13, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1, !tbaa !2448
  %33 = lshr i64 %13, 63
  %34 = trunc i64 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1, !tbaa !2449
  %36 = lshr i64 %10, 63
  %37 = xor i64 %33, %36
  %38 = add nuw nsw i64 %37, %36
  %39 = icmp eq i64 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1, !tbaa !2450
  %42 = add i64 %9, -12
  %43 = load i32, i32* %EDI, align 4
  %44 = add i64 %12, 10
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %42 to i32*
  store i32 %43, i32* %45, align 4
  %46 = load i64, i64* %RBP, align 8
  %47 = add i64 %46, -16
  %48 = load i64, i64* %RSI, align 8
  %49 = load i64, i64* %PC, align 8
  %50 = add i64 %49, 4
  store i64 %50, i64* %PC, align 8
  %51 = inttoptr i64 %47 to i64*
  store i64 %48, i64* %51, align 8
  %52 = load i64, i64* %RBP, align 8
  %53 = add i64 %52, -24
  %54 = load i64, i64* %RDX, align 8
  %55 = load i64, i64* %PC, align 8
  %56 = add i64 %55, 4
  store i64 %56, i64* %PC, align 8
  %57 = inttoptr i64 %53 to i64*
  store i64 %54, i64* %57, align 8
  %58 = load i64, i64* %RBP, align 8
  %59 = add i64 %58, -16
  %60 = load i64, i64* %PC, align 8
  %61 = add i64 %60, 4
  store i64 %61, i64* %PC, align 8
  %62 = inttoptr i64 %59 to i64*
  %63 = load i64, i64* %62, align 8
  store i64 %63, i64* %RDX, align 8, !tbaa !2428
  %64 = add i64 %60, 8
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %63 to double*
  %66 = load double, double* %65, align 8
  %67 = bitcast [32 x %union.VectorReg]* %4 to double*
  store double %66, double* %67, align 1, !tbaa !2452
  %68 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %69 = bitcast i64* %68 to double*
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %70 = add i64 %60, 12
  store i64 %70, i64* %PC, align 8
  %71 = load i64, i64* %62, align 8
  store i64 %71, i64* %RDX, align 8, !tbaa !2428
  %72 = add i64 %71, 16
  %73 = add i64 %60, 17
  store i64 %73, i64* %PC, align 8
  %74 = inttoptr i64 %72 to double*
  %75 = load double, double* %74, align 8
  %76 = fadd double %66, %75
  store double %76, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %77 = add i64 %58, -96
  %78 = add i64 %60, 22
  store i64 %78, i64* %PC, align 8
  %79 = inttoptr i64 %77 to double*
  store double %76, double* %79, align 8
  %80 = load i64, i64* %RBP, align 8
  %81 = add i64 %80, -16
  %82 = load i64, i64* %PC, align 8
  %83 = add i64 %82, 4
  store i64 %83, i64* %PC, align 8
  %84 = inttoptr i64 %81 to i64*
  %85 = load i64, i64* %84, align 8
  store i64 %85, i64* %RDX, align 8, !tbaa !2428
  %86 = add i64 %85, 8
  %87 = add i64 %82, 9
  store i64 %87, i64* %PC, align 8
  %88 = inttoptr i64 %86 to double*
  %89 = load double, double* %88, align 8
  store double %89, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %90 = add i64 %82, 13
  store i64 %90, i64* %PC, align 8
  %91 = load i64, i64* %84, align 8
  store i64 %91, i64* %RDX, align 8, !tbaa !2428
  %92 = add i64 %91, 24
  %93 = add i64 %82, 18
  store i64 %93, i64* %PC, align 8
  %94 = inttoptr i64 %92 to double*
  %95 = load double, double* %94, align 8
  %96 = fadd double %89, %95
  store double %96, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %97 = add i64 %80, -104
  %98 = add i64 %82, 23
  store i64 %98, i64* %PC, align 8
  %99 = inttoptr i64 %97 to double*
  store double %96, double* %99, align 8
  %100 = load i64, i64* %RBP, align 8
  %101 = add i64 %100, -16
  %102 = load i64, i64* %PC, align 8
  %103 = add i64 %102, 4
  store i64 %103, i64* %PC, align 8
  %104 = inttoptr i64 %101 to i64*
  %105 = load i64, i64* %104, align 8
  store i64 %105, i64* %RDX, align 8, !tbaa !2428
  %106 = add i64 %102, 8
  store i64 %106, i64* %PC, align 8
  %107 = inttoptr i64 %105 to double*
  %108 = load double, double* %107, align 8
  store double %108, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %109 = add i64 %102, 12
  store i64 %109, i64* %PC, align 8
  %110 = load i64, i64* %104, align 8
  store i64 %110, i64* %RDX, align 8, !tbaa !2428
  %111 = add i64 %110, 16
  %112 = add i64 %102, 17
  store i64 %112, i64* %PC, align 8
  %113 = inttoptr i64 %111 to double*
  %114 = load double, double* %113, align 8
  %115 = fsub double %108, %114
  store double %115, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %116 = add i64 %100, -112
  %117 = add i64 %102, 22
  store i64 %117, i64* %PC, align 8
  %118 = inttoptr i64 %116 to double*
  store double %115, double* %118, align 8
  %119 = load i64, i64* %RBP, align 8
  %120 = add i64 %119, -16
  %121 = load i64, i64* %PC, align 8
  %122 = add i64 %121, 4
  store i64 %122, i64* %PC, align 8
  %123 = inttoptr i64 %120 to i64*
  %124 = load i64, i64* %123, align 8
  store i64 %124, i64* %RDX, align 8, !tbaa !2428
  %125 = add i64 %124, 8
  %126 = add i64 %121, 9
  store i64 %126, i64* %PC, align 8
  %127 = inttoptr i64 %125 to double*
  %128 = load double, double* %127, align 8
  store double %128, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %129 = add i64 %121, 13
  store i64 %129, i64* %PC, align 8
  %130 = load i64, i64* %123, align 8
  store i64 %130, i64* %RDX, align 8, !tbaa !2428
  %131 = add i64 %130, 24
  %132 = add i64 %121, 18
  store i64 %132, i64* %PC, align 8
  %133 = inttoptr i64 %131 to double*
  %134 = load double, double* %133, align 8
  %135 = fsub double %128, %134
  store double %135, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %136 = add i64 %119, -120
  %137 = add i64 %121, 23
  store i64 %137, i64* %PC, align 8
  %138 = inttoptr i64 %136 to double*
  store double %135, double* %138, align 8
  %139 = load i64, i64* %RBP, align 8
  %140 = add i64 %139, -16
  %141 = load i64, i64* %PC, align 8
  %142 = add i64 %141, 4
  store i64 %142, i64* %PC, align 8
  %143 = inttoptr i64 %140 to i64*
  %144 = load i64, i64* %143, align 8
  store i64 %144, i64* %RDX, align 8, !tbaa !2428
  %145 = add i64 %144, 32
  %146 = add i64 %141, 9
  store i64 %146, i64* %PC, align 8
  %147 = inttoptr i64 %145 to double*
  %148 = load double, double* %147, align 8
  store double %148, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %149 = add i64 %141, 13
  store i64 %149, i64* %PC, align 8
  %150 = load i64, i64* %143, align 8
  store i64 %150, i64* %RDX, align 8, !tbaa !2428
  %151 = add i64 %150, 48
  %152 = add i64 %141, 18
  store i64 %152, i64* %PC, align 8
  %153 = inttoptr i64 %151 to double*
  %154 = load double, double* %153, align 8
  %155 = fadd double %148, %154
  store double %155, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %156 = add i64 %139, -128
  %157 = add i64 %141, 23
  store i64 %157, i64* %PC, align 8
  %158 = inttoptr i64 %156 to double*
  store double %155, double* %158, align 8
  %159 = load i64, i64* %RBP, align 8
  %160 = add i64 %159, -16
  %161 = load i64, i64* %PC, align 8
  %162 = add i64 %161, 4
  store i64 %162, i64* %PC, align 8
  %163 = inttoptr i64 %160 to i64*
  %164 = load i64, i64* %163, align 8
  store i64 %164, i64* %RDX, align 8, !tbaa !2428
  %165 = add i64 %164, 40
  %166 = add i64 %161, 9
  store i64 %166, i64* %PC, align 8
  %167 = inttoptr i64 %165 to double*
  %168 = load double, double* %167, align 8
  store double %168, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %169 = add i64 %161, 13
  store i64 %169, i64* %PC, align 8
  %170 = load i64, i64* %163, align 8
  store i64 %170, i64* %RDX, align 8, !tbaa !2428
  %171 = add i64 %170, 56
  %172 = add i64 %161, 18
  store i64 %172, i64* %PC, align 8
  %173 = inttoptr i64 %171 to double*
  %174 = load double, double* %173, align 8
  %175 = fadd double %168, %174
  store double %175, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %176 = add i64 %159, -136
  %177 = add i64 %161, 26
  store i64 %177, i64* %PC, align 8
  %178 = inttoptr i64 %176 to double*
  store double %175, double* %178, align 8
  %179 = load i64, i64* %RBP, align 8
  %180 = add i64 %179, -16
  %181 = load i64, i64* %PC, align 8
  %182 = add i64 %181, 4
  store i64 %182, i64* %PC, align 8
  %183 = inttoptr i64 %180 to i64*
  %184 = load i64, i64* %183, align 8
  store i64 %184, i64* %RDX, align 8, !tbaa !2428
  %185 = add i64 %184, 32
  %186 = add i64 %181, 9
  store i64 %186, i64* %PC, align 8
  %187 = inttoptr i64 %185 to double*
  %188 = load double, double* %187, align 8
  store double %188, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %189 = add i64 %181, 13
  store i64 %189, i64* %PC, align 8
  %190 = load i64, i64* %183, align 8
  store i64 %190, i64* %RDX, align 8, !tbaa !2428
  %191 = add i64 %190, 48
  %192 = add i64 %181, 18
  store i64 %192, i64* %PC, align 8
  %193 = inttoptr i64 %191 to double*
  %194 = load double, double* %193, align 8
  %195 = fsub double %188, %194
  store double %195, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %196 = add i64 %179, -144
  %197 = add i64 %181, 26
  store i64 %197, i64* %PC, align 8
  %198 = inttoptr i64 %196 to double*
  store double %195, double* %198, align 8
  %199 = load i64, i64* %RBP, align 8
  %200 = add i64 %199, -16
  %201 = load i64, i64* %PC, align 8
  %202 = add i64 %201, 4
  store i64 %202, i64* %PC, align 8
  %203 = inttoptr i64 %200 to i64*
  %204 = load i64, i64* %203, align 8
  store i64 %204, i64* %RDX, align 8, !tbaa !2428
  %205 = add i64 %204, 40
  %206 = add i64 %201, 9
  store i64 %206, i64* %PC, align 8
  %207 = inttoptr i64 %205 to double*
  %208 = load double, double* %207, align 8
  store double %208, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %209 = add i64 %201, 13
  store i64 %209, i64* %PC, align 8
  %210 = load i64, i64* %203, align 8
  store i64 %210, i64* %RDX, align 8, !tbaa !2428
  %211 = add i64 %210, 56
  %212 = add i64 %201, 18
  store i64 %212, i64* %PC, align 8
  %213 = inttoptr i64 %211 to double*
  %214 = load double, double* %213, align 8
  %215 = fsub double %208, %214
  store double %215, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %216 = add i64 %199, -152
  %217 = add i64 %201, 26
  store i64 %217, i64* %PC, align 8
  %218 = inttoptr i64 %216 to double*
  store double %215, double* %218, align 8
  %219 = load i64, i64* %RBP, align 8
  %220 = add i64 %219, -96
  %221 = load i64, i64* %PC, align 8
  %222 = add i64 %221, 5
  store i64 %222, i64* %PC, align 8
  %223 = inttoptr i64 %220 to double*
  %224 = load double, double* %223, align 8
  store double %224, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %225 = add i64 %219, -128
  %226 = add i64 %221, 10
  store i64 %226, i64* %PC, align 8
  %227 = inttoptr i64 %225 to double*
  %228 = load double, double* %227, align 8
  %229 = fadd double %224, %228
  store double %229, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %230 = add i64 %219, -16
  %231 = add i64 %221, 14
  store i64 %231, i64* %PC, align 8
  %232 = inttoptr i64 %230 to i64*
  %233 = load i64, i64* %232, align 8
  store i64 %233, i64* %RDX, align 8, !tbaa !2428
  %234 = add i64 %221, 18
  store i64 %234, i64* %PC, align 8
  %235 = inttoptr i64 %233 to double*
  store double %229, double* %235, align 8
  %236 = load i64, i64* %RBP, align 8
  %237 = add i64 %236, -104
  %238 = load i64, i64* %PC, align 8
  %239 = add i64 %238, 5
  store i64 %239, i64* %PC, align 8
  %240 = inttoptr i64 %237 to double*
  %241 = load double, double* %240, align 8
  store double %241, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %242 = add i64 %236, -136
  %243 = add i64 %238, 13
  store i64 %243, i64* %PC, align 8
  %244 = inttoptr i64 %242 to double*
  %245 = load double, double* %244, align 8
  %246 = fadd double %241, %245
  store double %246, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %247 = add i64 %236, -16
  %248 = add i64 %238, 17
  store i64 %248, i64* %PC, align 8
  %249 = inttoptr i64 %247 to i64*
  %250 = load i64, i64* %249, align 8
  store i64 %250, i64* %RDX, align 8, !tbaa !2428
  %251 = add i64 %250, 8
  %252 = add i64 %238, 22
  store i64 %252, i64* %PC, align 8
  %253 = inttoptr i64 %251 to double*
  store double %246, double* %253, align 8
  %254 = load i64, i64* %RBP, align 8
  %255 = add i64 %254, -96
  %256 = load i64, i64* %PC, align 8
  %257 = add i64 %256, 5
  store i64 %257, i64* %PC, align 8
  %258 = inttoptr i64 %255 to double*
  %259 = load double, double* %258, align 8
  store double %259, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %260 = add i64 %254, -128
  %261 = add i64 %256, 10
  store i64 %261, i64* %PC, align 8
  %262 = inttoptr i64 %260 to double*
  %263 = load double, double* %262, align 8
  %264 = fsub double %259, %263
  store double %264, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %265 = add i64 %254, -16
  %266 = add i64 %256, 14
  store i64 %266, i64* %PC, align 8
  %267 = inttoptr i64 %265 to i64*
  %268 = load i64, i64* %267, align 8
  store i64 %268, i64* %RDX, align 8, !tbaa !2428
  %269 = add i64 %268, 32
  %270 = add i64 %256, 19
  store i64 %270, i64* %PC, align 8
  %271 = inttoptr i64 %269 to double*
  store double %264, double* %271, align 8
  %272 = load i64, i64* %RBP, align 8
  %273 = add i64 %272, -104
  %274 = load i64, i64* %PC, align 8
  %275 = add i64 %274, 5
  store i64 %275, i64* %PC, align 8
  %276 = inttoptr i64 %273 to double*
  %277 = load double, double* %276, align 8
  store double %277, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %278 = add i64 %272, -136
  %279 = add i64 %274, 13
  store i64 %279, i64* %PC, align 8
  %280 = inttoptr i64 %278 to double*
  %281 = load double, double* %280, align 8
  %282 = fsub double %277, %281
  store double %282, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %283 = add i64 %272, -16
  %284 = add i64 %274, 17
  store i64 %284, i64* %PC, align 8
  %285 = inttoptr i64 %283 to i64*
  %286 = load i64, i64* %285, align 8
  store i64 %286, i64* %RDX, align 8, !tbaa !2428
  %287 = add i64 %286, 40
  %288 = add i64 %274, 22
  store i64 %288, i64* %PC, align 8
  %289 = inttoptr i64 %287 to double*
  store double %282, double* %289, align 8
  %290 = load i64, i64* %RBP, align 8
  %291 = add i64 %290, -112
  %292 = load i64, i64* %PC, align 8
  %293 = add i64 %292, 5
  store i64 %293, i64* %PC, align 8
  %294 = inttoptr i64 %291 to double*
  %295 = load double, double* %294, align 8
  store double %295, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %296 = add i64 %290, -152
  %297 = add i64 %292, 13
  store i64 %297, i64* %PC, align 8
  %298 = inttoptr i64 %296 to double*
  %299 = load double, double* %298, align 8
  %300 = fsub double %295, %299
  store double %300, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %301 = add i64 %290, -16
  %302 = add i64 %292, 17
  store i64 %302, i64* %PC, align 8
  %303 = inttoptr i64 %301 to i64*
  %304 = load i64, i64* %303, align 8
  store i64 %304, i64* %RDX, align 8, !tbaa !2428
  %305 = add i64 %304, 16
  %306 = add i64 %292, 22
  store i64 %306, i64* %PC, align 8
  %307 = inttoptr i64 %305 to double*
  store double %300, double* %307, align 8
  %308 = load i64, i64* %RBP, align 8
  %309 = add i64 %308, -120
  %310 = load i64, i64* %PC, align 8
  %311 = add i64 %310, 5
  store i64 %311, i64* %PC, align 8
  %312 = inttoptr i64 %309 to double*
  %313 = load double, double* %312, align 8
  store double %313, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %314 = add i64 %308, -144
  %315 = add i64 %310, 13
  store i64 %315, i64* %PC, align 8
  %316 = inttoptr i64 %314 to double*
  %317 = load double, double* %316, align 8
  %318 = fadd double %313, %317
  store double %318, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %319 = add i64 %308, -16
  %320 = add i64 %310, 17
  store i64 %320, i64* %PC, align 8
  %321 = inttoptr i64 %319 to i64*
  %322 = load i64, i64* %321, align 8
  store i64 %322, i64* %RDX, align 8, !tbaa !2428
  %323 = add i64 %322, 24
  %324 = add i64 %310, 22
  store i64 %324, i64* %PC, align 8
  %325 = inttoptr i64 %323 to double*
  store double %318, double* %325, align 8
  %326 = load i64, i64* %RBP, align 8
  %327 = add i64 %326, -112
  %328 = load i64, i64* %PC, align 8
  %329 = add i64 %328, 5
  store i64 %329, i64* %PC, align 8
  %330 = inttoptr i64 %327 to double*
  %331 = load double, double* %330, align 8
  store double %331, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %332 = add i64 %326, -152
  %333 = add i64 %328, 13
  store i64 %333, i64* %PC, align 8
  %334 = inttoptr i64 %332 to double*
  %335 = load double, double* %334, align 8
  %336 = fadd double %331, %335
  store double %336, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %337 = add i64 %326, -16
  %338 = add i64 %328, 17
  store i64 %338, i64* %PC, align 8
  %339 = inttoptr i64 %337 to i64*
  %340 = load i64, i64* %339, align 8
  store i64 %340, i64* %RDX, align 8, !tbaa !2428
  %341 = add i64 %340, 48
  %342 = add i64 %328, 22
  store i64 %342, i64* %PC, align 8
  %343 = inttoptr i64 %341 to double*
  store double %336, double* %343, align 8
  %344 = load i64, i64* %RBP, align 8
  %345 = add i64 %344, -120
  %346 = load i64, i64* %PC, align 8
  %347 = add i64 %346, 5
  store i64 %347, i64* %PC, align 8
  %348 = inttoptr i64 %345 to double*
  %349 = load double, double* %348, align 8
  store double %349, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %350 = add i64 %344, -144
  %351 = add i64 %346, 13
  store i64 %351, i64* %PC, align 8
  %352 = inttoptr i64 %350 to double*
  %353 = load double, double* %352, align 8
  %354 = fsub double %349, %353
  store double %354, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %355 = add i64 %344, -16
  %356 = add i64 %346, 17
  store i64 %356, i64* %PC, align 8
  %357 = inttoptr i64 %355 to i64*
  %358 = load i64, i64* %357, align 8
  store i64 %358, i64* %RDX, align 8, !tbaa !2428
  %359 = add i64 %358, 56
  %360 = add i64 %346, 22
  store i64 %360, i64* %PC, align 8
  %361 = inttoptr i64 %359 to double*
  store double %354, double* %361, align 8
  %362 = load i64, i64* %RBP, align 8
  %363 = add i64 %362, -24
  %364 = load i64, i64* %PC, align 8
  %365 = add i64 %364, 4
  store i64 %365, i64* %PC, align 8
  %366 = inttoptr i64 %363 to i64*
  %367 = load i64, i64* %366, align 8
  store i64 %367, i64* %RDX, align 8, !tbaa !2428
  %368 = add i64 %367, 16
  %369 = add i64 %364, 9
  store i64 %369, i64* %PC, align 8
  %370 = inttoptr i64 %368 to i64*
  %371 = load i64, i64* %370, align 8
  %372 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %371, i64* %372, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %373 = add i64 %362, -48
  %374 = add i64 %364, 14
  store i64 %374, i64* %PC, align 8
  %375 = inttoptr i64 %373 to i64*
  store i64 %371, i64* %375, align 8
  %376 = load i64, i64* %RBP, align 8
  %377 = add i64 %376, -16
  %378 = load i64, i64* %PC, align 8
  %379 = add i64 %378, 4
  store i64 %379, i64* %PC, align 8
  %380 = inttoptr i64 %377 to i64*
  %381 = load i64, i64* %380, align 8
  store i64 %381, i64* %RDX, align 8, !tbaa !2428
  %382 = add i64 %381, 64
  %383 = add i64 %378, 9
  store i64 %383, i64* %PC, align 8
  %384 = inttoptr i64 %382 to double*
  %385 = load double, double* %384, align 8
  store double %385, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %386 = add i64 %378, 13
  store i64 %386, i64* %PC, align 8
  %387 = load i64, i64* %380, align 8
  store i64 %387, i64* %RDX, align 8, !tbaa !2428
  %388 = add i64 %387, 80
  %389 = add i64 %378, 18
  store i64 %389, i64* %PC, align 8
  %390 = inttoptr i64 %388 to double*
  %391 = load double, double* %390, align 8
  %392 = fadd double %385, %391
  store double %392, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %393 = add i64 %376, -96
  %394 = add i64 %378, 23
  store i64 %394, i64* %PC, align 8
  %395 = inttoptr i64 %393 to double*
  store double %392, double* %395, align 8
  %396 = load i64, i64* %RBP, align 8
  %397 = add i64 %396, -16
  %398 = load i64, i64* %PC, align 8
  %399 = add i64 %398, 4
  store i64 %399, i64* %PC, align 8
  %400 = inttoptr i64 %397 to i64*
  %401 = load i64, i64* %400, align 8
  store i64 %401, i64* %RDX, align 8, !tbaa !2428
  %402 = add i64 %401, 72
  %403 = add i64 %398, 9
  store i64 %403, i64* %PC, align 8
  %404 = inttoptr i64 %402 to double*
  %405 = load double, double* %404, align 8
  store double %405, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %406 = add i64 %398, 13
  store i64 %406, i64* %PC, align 8
  %407 = load i64, i64* %400, align 8
  store i64 %407, i64* %RDX, align 8, !tbaa !2428
  %408 = add i64 %407, 88
  %409 = add i64 %398, 18
  store i64 %409, i64* %PC, align 8
  %410 = inttoptr i64 %408 to double*
  %411 = load double, double* %410, align 8
  %412 = fadd double %405, %411
  store double %412, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %413 = add i64 %396, -104
  %414 = add i64 %398, 23
  store i64 %414, i64* %PC, align 8
  %415 = inttoptr i64 %413 to double*
  store double %412, double* %415, align 8
  %416 = load i64, i64* %RBP, align 8
  %417 = add i64 %416, -16
  %418 = load i64, i64* %PC, align 8
  %419 = add i64 %418, 4
  store i64 %419, i64* %PC, align 8
  %420 = inttoptr i64 %417 to i64*
  %421 = load i64, i64* %420, align 8
  store i64 %421, i64* %RDX, align 8, !tbaa !2428
  %422 = add i64 %421, 64
  %423 = add i64 %418, 9
  store i64 %423, i64* %PC, align 8
  %424 = inttoptr i64 %422 to double*
  %425 = load double, double* %424, align 8
  store double %425, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %426 = add i64 %418, 13
  store i64 %426, i64* %PC, align 8
  %427 = load i64, i64* %420, align 8
  store i64 %427, i64* %RDX, align 8, !tbaa !2428
  %428 = add i64 %427, 80
  %429 = add i64 %418, 18
  store i64 %429, i64* %PC, align 8
  %430 = inttoptr i64 %428 to double*
  %431 = load double, double* %430, align 8
  %432 = fsub double %425, %431
  store double %432, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %433 = add i64 %416, -112
  %434 = add i64 %418, 23
  store i64 %434, i64* %PC, align 8
  %435 = inttoptr i64 %433 to double*
  store double %432, double* %435, align 8
  %436 = load i64, i64* %RBP, align 8
  %437 = add i64 %436, -16
  %438 = load i64, i64* %PC, align 8
  %439 = add i64 %438, 4
  store i64 %439, i64* %PC, align 8
  %440 = inttoptr i64 %437 to i64*
  %441 = load i64, i64* %440, align 8
  store i64 %441, i64* %RDX, align 8, !tbaa !2428
  %442 = add i64 %441, 72
  %443 = add i64 %438, 9
  store i64 %443, i64* %PC, align 8
  %444 = inttoptr i64 %442 to double*
  %445 = load double, double* %444, align 8
  store double %445, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %446 = add i64 %438, 13
  store i64 %446, i64* %PC, align 8
  %447 = load i64, i64* %440, align 8
  store i64 %447, i64* %RDX, align 8, !tbaa !2428
  %448 = add i64 %447, 88
  %449 = add i64 %438, 18
  store i64 %449, i64* %PC, align 8
  %450 = inttoptr i64 %448 to double*
  %451 = load double, double* %450, align 8
  %452 = fsub double %445, %451
  store double %452, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %453 = add i64 %436, -120
  %454 = add i64 %438, 23
  store i64 %454, i64* %PC, align 8
  %455 = inttoptr i64 %453 to double*
  store double %452, double* %455, align 8
  %456 = load i64, i64* %RBP, align 8
  %457 = add i64 %456, -16
  %458 = load i64, i64* %PC, align 8
  %459 = add i64 %458, 4
  store i64 %459, i64* %PC, align 8
  %460 = inttoptr i64 %457 to i64*
  %461 = load i64, i64* %460, align 8
  store i64 %461, i64* %RDX, align 8, !tbaa !2428
  %462 = add i64 %461, 96
  %463 = add i64 %458, 9
  store i64 %463, i64* %PC, align 8
  %464 = inttoptr i64 %462 to double*
  %465 = load double, double* %464, align 8
  store double %465, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %466 = add i64 %458, 13
  store i64 %466, i64* %PC, align 8
  %467 = load i64, i64* %460, align 8
  store i64 %467, i64* %RDX, align 8, !tbaa !2428
  %468 = add i64 %467, 112
  %469 = add i64 %458, 18
  store i64 %469, i64* %PC, align 8
  %470 = inttoptr i64 %468 to double*
  %471 = load double, double* %470, align 8
  %472 = fadd double %465, %471
  store double %472, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %473 = add i64 %456, -128
  %474 = add i64 %458, 23
  store i64 %474, i64* %PC, align 8
  %475 = inttoptr i64 %473 to double*
  store double %472, double* %475, align 8
  %476 = load i64, i64* %RBP, align 8
  %477 = add i64 %476, -16
  %478 = load i64, i64* %PC, align 8
  %479 = add i64 %478, 4
  store i64 %479, i64* %PC, align 8
  %480 = inttoptr i64 %477 to i64*
  %481 = load i64, i64* %480, align 8
  store i64 %481, i64* %RDX, align 8, !tbaa !2428
  %482 = add i64 %481, 104
  %483 = add i64 %478, 9
  store i64 %483, i64* %PC, align 8
  %484 = inttoptr i64 %482 to double*
  %485 = load double, double* %484, align 8
  store double %485, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %486 = add i64 %478, 13
  store i64 %486, i64* %PC, align 8
  %487 = load i64, i64* %480, align 8
  store i64 %487, i64* %RDX, align 8, !tbaa !2428
  %488 = add i64 %487, 120
  %489 = add i64 %478, 18
  store i64 %489, i64* %PC, align 8
  %490 = inttoptr i64 %488 to double*
  %491 = load double, double* %490, align 8
  %492 = fadd double %485, %491
  store double %492, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %493 = add i64 %476, -136
  %494 = add i64 %478, 26
  store i64 %494, i64* %PC, align 8
  %495 = inttoptr i64 %493 to double*
  store double %492, double* %495, align 8
  %496 = load i64, i64* %RBP, align 8
  %497 = add i64 %496, -16
  %498 = load i64, i64* %PC, align 8
  %499 = add i64 %498, 4
  store i64 %499, i64* %PC, align 8
  %500 = inttoptr i64 %497 to i64*
  %501 = load i64, i64* %500, align 8
  store i64 %501, i64* %RDX, align 8, !tbaa !2428
  %502 = add i64 %501, 96
  %503 = add i64 %498, 9
  store i64 %503, i64* %PC, align 8
  %504 = inttoptr i64 %502 to double*
  %505 = load double, double* %504, align 8
  store double %505, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %506 = add i64 %498, 13
  store i64 %506, i64* %PC, align 8
  %507 = load i64, i64* %500, align 8
  store i64 %507, i64* %RDX, align 8, !tbaa !2428
  %508 = add i64 %507, 112
  %509 = add i64 %498, 18
  store i64 %509, i64* %PC, align 8
  %510 = inttoptr i64 %508 to double*
  %511 = load double, double* %510, align 8
  %512 = fsub double %505, %511
  store double %512, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %513 = add i64 %496, -144
  %514 = add i64 %498, 26
  store i64 %514, i64* %PC, align 8
  %515 = inttoptr i64 %513 to double*
  store double %512, double* %515, align 8
  %516 = load i64, i64* %RBP, align 8
  %517 = add i64 %516, -16
  %518 = load i64, i64* %PC, align 8
  %519 = add i64 %518, 4
  store i64 %519, i64* %PC, align 8
  %520 = inttoptr i64 %517 to i64*
  %521 = load i64, i64* %520, align 8
  store i64 %521, i64* %RDX, align 8, !tbaa !2428
  %522 = add i64 %521, 104
  %523 = add i64 %518, 9
  store i64 %523, i64* %PC, align 8
  %524 = inttoptr i64 %522 to double*
  %525 = load double, double* %524, align 8
  store double %525, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %526 = add i64 %518, 13
  store i64 %526, i64* %PC, align 8
  %527 = load i64, i64* %520, align 8
  store i64 %527, i64* %RDX, align 8, !tbaa !2428
  %528 = add i64 %527, 120
  %529 = add i64 %518, 18
  store i64 %529, i64* %PC, align 8
  %530 = inttoptr i64 %528 to double*
  %531 = load double, double* %530, align 8
  %532 = fsub double %525, %531
  store double %532, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %533 = add i64 %516, -152
  %534 = add i64 %518, 26
  store i64 %534, i64* %PC, align 8
  %535 = inttoptr i64 %533 to double*
  store double %532, double* %535, align 8
  %536 = load i64, i64* %RBP, align 8
  %537 = add i64 %536, -96
  %538 = load i64, i64* %PC, align 8
  %539 = add i64 %538, 5
  store i64 %539, i64* %PC, align 8
  %540 = inttoptr i64 %537 to double*
  %541 = load double, double* %540, align 8
  store double %541, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %542 = add i64 %536, -128
  %543 = add i64 %538, 10
  store i64 %543, i64* %PC, align 8
  %544 = inttoptr i64 %542 to double*
  %545 = load double, double* %544, align 8
  %546 = fadd double %541, %545
  store double %546, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %547 = add i64 %536, -16
  %548 = add i64 %538, 14
  store i64 %548, i64* %PC, align 8
  %549 = inttoptr i64 %547 to i64*
  %550 = load i64, i64* %549, align 8
  store i64 %550, i64* %RDX, align 8, !tbaa !2428
  %551 = add i64 %550, 64
  %552 = add i64 %538, 19
  store i64 %552, i64* %PC, align 8
  %553 = inttoptr i64 %551 to double*
  store double %546, double* %553, align 8
  %554 = load i64, i64* %RBP, align 8
  %555 = add i64 %554, -104
  %556 = load i64, i64* %PC, align 8
  %557 = add i64 %556, 5
  store i64 %557, i64* %PC, align 8
  %558 = inttoptr i64 %555 to double*
  %559 = load double, double* %558, align 8
  store double %559, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %560 = add i64 %554, -136
  %561 = add i64 %556, 13
  store i64 %561, i64* %PC, align 8
  %562 = inttoptr i64 %560 to double*
  %563 = load double, double* %562, align 8
  %564 = fadd double %559, %563
  store double %564, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %565 = add i64 %554, -16
  %566 = add i64 %556, 17
  store i64 %566, i64* %PC, align 8
  %567 = inttoptr i64 %565 to i64*
  %568 = load i64, i64* %567, align 8
  store i64 %568, i64* %RDX, align 8, !tbaa !2428
  %569 = add i64 %568, 72
  %570 = add i64 %556, 22
  store i64 %570, i64* %PC, align 8
  %571 = inttoptr i64 %569 to double*
  store double %564, double* %571, align 8
  %572 = load i64, i64* %RBP, align 8
  %573 = add i64 %572, -136
  %574 = load i64, i64* %PC, align 8
  %575 = add i64 %574, 8
  store i64 %575, i64* %PC, align 8
  %576 = inttoptr i64 %573 to double*
  %577 = load double, double* %576, align 8
  store double %577, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %578 = add i64 %572, -104
  %579 = add i64 %574, 13
  store i64 %579, i64* %PC, align 8
  %580 = inttoptr i64 %578 to double*
  %581 = load double, double* %580, align 8
  %582 = fsub double %577, %581
  store double %582, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %583 = add i64 %572, -16
  %584 = add i64 %574, 17
  store i64 %584, i64* %PC, align 8
  %585 = inttoptr i64 %583 to i64*
  %586 = load i64, i64* %585, align 8
  store i64 %586, i64* %RDX, align 8, !tbaa !2428
  %587 = add i64 %586, 96
  %588 = add i64 %574, 22
  store i64 %588, i64* %PC, align 8
  %589 = inttoptr i64 %587 to double*
  store double %582, double* %589, align 8
  %590 = load i64, i64* %RBP, align 8
  %591 = add i64 %590, -96
  %592 = load i64, i64* %PC, align 8
  %593 = add i64 %592, 5
  store i64 %593, i64* %PC, align 8
  %594 = inttoptr i64 %591 to double*
  %595 = load double, double* %594, align 8
  store double %595, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %596 = add i64 %590, -128
  %597 = add i64 %592, 10
  store i64 %597, i64* %PC, align 8
  %598 = inttoptr i64 %596 to double*
  %599 = load double, double* %598, align 8
  %600 = fsub double %595, %599
  store double %600, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %601 = add i64 %590, -16
  %602 = add i64 %592, 14
  store i64 %602, i64* %PC, align 8
  %603 = inttoptr i64 %601 to i64*
  %604 = load i64, i64* %603, align 8
  store i64 %604, i64* %RDX, align 8, !tbaa !2428
  %605 = add i64 %604, 104
  %606 = add i64 %592, 19
  store i64 %606, i64* %PC, align 8
  %607 = inttoptr i64 %605 to double*
  store double %600, double* %607, align 8
  %608 = load i64, i64* %RBP, align 8
  %609 = add i64 %608, -112
  %610 = load i64, i64* %PC, align 8
  %611 = add i64 %610, 5
  store i64 %611, i64* %PC, align 8
  %612 = inttoptr i64 %609 to double*
  %613 = load double, double* %612, align 8
  store double %613, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %614 = add i64 %608, -152
  %615 = add i64 %610, 13
  store i64 %615, i64* %PC, align 8
  %616 = inttoptr i64 %614 to double*
  %617 = load double, double* %616, align 8
  %618 = fsub double %613, %617
  store double %618, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %619 = add i64 %608, -96
  %620 = add i64 %610, 18
  store i64 %620, i64* %PC, align 8
  %621 = inttoptr i64 %619 to double*
  store double %618, double* %621, align 8
  %622 = load i64, i64* %RBP, align 8
  %623 = add i64 %622, -120
  %624 = load i64, i64* %PC, align 8
  %625 = add i64 %624, 5
  store i64 %625, i64* %PC, align 8
  %626 = inttoptr i64 %623 to double*
  %627 = load double, double* %626, align 8
  store double %627, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %628 = add i64 %622, -144
  %629 = add i64 %624, 13
  store i64 %629, i64* %PC, align 8
  %630 = inttoptr i64 %628 to double*
  %631 = load double, double* %630, align 8
  %632 = fadd double %627, %631
  store double %632, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %633 = add i64 %622, -104
  %634 = add i64 %624, 18
  store i64 %634, i64* %PC, align 8
  %635 = inttoptr i64 %633 to double*
  store double %632, double* %635, align 8
  %636 = load i64, i64* %RBP, align 8
  %637 = add i64 %636, -48
  %638 = load i64, i64* %PC, align 8
  %639 = add i64 %638, 5
  store i64 %639, i64* %PC, align 8
  %640 = inttoptr i64 %637 to double*
  %641 = load double, double* %640, align 8
  store double %641, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %642 = bitcast %union.VectorReg* %5 to i8*
  %643 = add i64 %636, -96
  %644 = add i64 %638, 10
  store i64 %644, i64* %PC, align 8
  %645 = inttoptr i64 %643 to double*
  %646 = load double, double* %645, align 8
  %647 = bitcast %union.VectorReg* %5 to double*
  store double %646, double* %647, align 1, !tbaa !2452
  %648 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %649 = bitcast i64* %648 to double*
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %650 = add i64 %636, -104
  %651 = add i64 %638, 15
  store i64 %651, i64* %PC, align 8
  %652 = inttoptr i64 %650 to double*
  %653 = load double, double* %652, align 8
  %654 = fsub double %646, %653
  store double %654, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %655 = fmul double %641, %654
  store double %655, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %656 = add i64 %636, -16
  %657 = add i64 %638, 23
  store i64 %657, i64* %PC, align 8
  %658 = inttoptr i64 %656 to i64*
  %659 = load i64, i64* %658, align 8
  store i64 %659, i64* %RDX, align 8, !tbaa !2428
  %660 = add i64 %659, 80
  %661 = add i64 %638, 28
  store i64 %661, i64* %PC, align 8
  %662 = inttoptr i64 %660 to double*
  store double %655, double* %662, align 8
  %663 = load i64, i64* %RBP, align 8
  %664 = add i64 %663, -48
  %665 = load i64, i64* %PC, align 8
  %666 = add i64 %665, 5
  store i64 %666, i64* %PC, align 8
  %667 = inttoptr i64 %664 to double*
  %668 = load double, double* %667, align 8
  store double %668, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %669 = add i64 %663, -96
  %670 = add i64 %665, 10
  store i64 %670, i64* %PC, align 8
  %671 = inttoptr i64 %669 to double*
  %672 = load double, double* %671, align 8
  store double %672, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %673 = add i64 %663, -104
  %674 = add i64 %665, 15
  store i64 %674, i64* %PC, align 8
  %675 = inttoptr i64 %673 to double*
  %676 = load double, double* %675, align 8
  %677 = fadd double %672, %676
  store double %677, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %678 = fmul double %668, %677
  store double %678, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %679 = add i64 %663, -16
  %680 = add i64 %665, 23
  store i64 %680, i64* %PC, align 8
  %681 = inttoptr i64 %679 to i64*
  %682 = load i64, i64* %681, align 8
  store i64 %682, i64* %RDX, align 8, !tbaa !2428
  %683 = add i64 %682, 88
  %684 = add i64 %665, 28
  store i64 %684, i64* %PC, align 8
  %685 = inttoptr i64 %683 to double*
  store double %678, double* %685, align 8
  %686 = load i64, i64* %RBP, align 8
  %687 = add i64 %686, -152
  %688 = load i64, i64* %PC, align 8
  %689 = add i64 %688, 8
  store i64 %689, i64* %PC, align 8
  %690 = inttoptr i64 %687 to double*
  %691 = load double, double* %690, align 8
  store double %691, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %692 = add i64 %686, -112
  %693 = add i64 %688, 13
  store i64 %693, i64* %PC, align 8
  %694 = inttoptr i64 %692 to double*
  %695 = load double, double* %694, align 8
  %696 = fadd double %691, %695
  store double %696, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %697 = add i64 %686, -96
  %698 = add i64 %688, 18
  store i64 %698, i64* %PC, align 8
  %699 = inttoptr i64 %697 to double*
  store double %696, double* %699, align 8
  %700 = load i64, i64* %RBP, align 8
  %701 = add i64 %700, -144
  %702 = load i64, i64* %PC, align 8
  %703 = add i64 %702, 8
  store i64 %703, i64* %PC, align 8
  %704 = inttoptr i64 %701 to double*
  %705 = load double, double* %704, align 8
  store double %705, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %706 = add i64 %700, -120
  %707 = add i64 %702, 13
  store i64 %707, i64* %PC, align 8
  %708 = inttoptr i64 %706 to double*
  %709 = load double, double* %708, align 8
  %710 = fsub double %705, %709
  store double %710, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %711 = add i64 %700, -104
  %712 = add i64 %702, 18
  store i64 %712, i64* %PC, align 8
  %713 = inttoptr i64 %711 to double*
  store double %710, double* %713, align 8
  %714 = load i64, i64* %RBP, align 8
  %715 = add i64 %714, -48
  %716 = load i64, i64* %PC, align 8
  %717 = add i64 %716, 5
  store i64 %717, i64* %PC, align 8
  %718 = inttoptr i64 %715 to double*
  %719 = load double, double* %718, align 8
  store double %719, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %720 = add i64 %714, -104
  %721 = add i64 %716, 10
  store i64 %721, i64* %PC, align 8
  %722 = inttoptr i64 %720 to double*
  %723 = load double, double* %722, align 8
  store double %723, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %724 = add i64 %714, -96
  %725 = add i64 %716, 15
  store i64 %725, i64* %PC, align 8
  %726 = inttoptr i64 %724 to double*
  %727 = load double, double* %726, align 8
  %728 = fsub double %723, %727
  store double %728, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %729 = fmul double %719, %728
  store double %729, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %730 = add i64 %714, -16
  %731 = add i64 %716, 23
  store i64 %731, i64* %PC, align 8
  %732 = inttoptr i64 %730 to i64*
  %733 = load i64, i64* %732, align 8
  store i64 %733, i64* %RDX, align 8, !tbaa !2428
  %734 = add i64 %733, 112
  %735 = add i64 %716, 28
  store i64 %735, i64* %PC, align 8
  %736 = inttoptr i64 %734 to double*
  store double %729, double* %736, align 8
  %737 = load i64, i64* %RBP, align 8
  %738 = add i64 %737, -48
  %739 = load i64, i64* %PC, align 8
  %740 = add i64 %739, 5
  store i64 %740, i64* %PC, align 8
  %741 = inttoptr i64 %738 to double*
  %742 = load double, double* %741, align 8
  store double %742, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %743 = add i64 %737, -104
  %744 = add i64 %739, 10
  store i64 %744, i64* %PC, align 8
  %745 = inttoptr i64 %743 to double*
  %746 = load double, double* %745, align 8
  store double %746, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %747 = add i64 %737, -96
  %748 = add i64 %739, 15
  store i64 %748, i64* %PC, align 8
  %749 = inttoptr i64 %747 to double*
  %750 = load double, double* %749, align 8
  %751 = fadd double %746, %750
  store double %751, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %752 = fmul double %742, %751
  store double %752, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %753 = add i64 %737, -16
  %754 = add i64 %739, 23
  store i64 %754, i64* %PC, align 8
  %755 = inttoptr i64 %753 to i64*
  %756 = load i64, i64* %755, align 8
  store i64 %756, i64* %RDX, align 8, !tbaa !2428
  %757 = add i64 %756, 120
  %758 = add i64 %739, 28
  store i64 %758, i64* %PC, align 8
  %759 = inttoptr i64 %757 to double*
  store double %752, double* %759, align 8
  %760 = load i64, i64* %RBP, align 8
  %761 = add i64 %760, -32
  %762 = load i64, i64* %PC, align 8
  %763 = add i64 %762, 7
  store i64 %763, i64* %PC, align 8
  %764 = inttoptr i64 %761 to i32*
  store i32 0, i32* %764, align 4
  %765 = load i64, i64* %RBP, align 8
  %766 = add i64 %765, -28
  %767 = load i64, i64* %PC, align 8
  %768 = add i64 %767, 7
  store i64 %768, i64* %PC, align 8
  %769 = inttoptr i64 %766 to i32*
  store i32 16, i32* %769, align 4
  %770 = bitcast %union.VectorReg* %6 to i8*
  %771 = bitcast [32 x %union.VectorReg]* %4 to <2 x i32>*
  %772 = bitcast i64* %68 to <2 x i32>*
  %773 = bitcast %union.VectorReg* %6 to i32*
  %774 = getelementptr inbounds i8, i8* %770, i64 4
  %775 = bitcast i8* %774 to i32*
  %776 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %777 = bitcast i64* %776 to i32*
  %778 = getelementptr inbounds i8, i8* %770, i64 12
  %779 = bitcast i8* %778 to i32*
  %780 = bitcast %union.VectorReg* %6 to double*
  %781 = bitcast %union.VectorReg* %5 to i32*
  %782 = getelementptr inbounds i8, i8* %642, i64 4
  %783 = bitcast i8* %782 to i32*
  %784 = bitcast i64* %648 to i32*
  %785 = getelementptr inbounds i8, i8* %642, i64 12
  %786 = bitcast i8* %785 to i32*
  %787 = bitcast i64* %776 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_402bd2

block_402bde:                                     ; preds = %block_402bd2
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %788 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 80) to i64*), align 16
  store i64 %788, i64* %372, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %789 = add i64 %3359, -32
  %790 = add i64 %3395, 21
  store i64 %790, i64* %PC, align 8
  %791 = inttoptr i64 %789 to i32*
  %792 = load i32, i32* %791, align 4
  %793 = add i32 %792, 2
  %794 = zext i32 %793 to i64
  store i64 %794, i64* %RCX, align 8, !tbaa !2428
  %795 = icmp ugt i32 %792, -3
  %796 = zext i1 %795 to i8
  store i8 %796, i8* %16, align 1, !tbaa !2433
  %797 = and i32 %793, 255
  %798 = tail call i32 @llvm.ctpop.i32(i32 %797) #10
  %799 = trunc i32 %798 to i8
  %800 = and i8 %799, 1
  %801 = xor i8 %800, 1
  store i8 %801, i8* %23, align 1, !tbaa !2447
  %802 = xor i32 %792, %793
  %803 = lshr i32 %802, 4
  %804 = trunc i32 %803 to i8
  %805 = and i8 %804, 1
  store i8 %805, i8* %29, align 1, !tbaa !2451
  %806 = icmp eq i32 %793, 0
  %807 = zext i1 %806 to i8
  store i8 %807, i8* %32, align 1, !tbaa !2448
  %808 = lshr i32 %793, 31
  %809 = trunc i32 %808 to i8
  store i8 %809, i8* %35, align 1, !tbaa !2449
  %810 = lshr i32 %792, 31
  %811 = xor i32 %808, %810
  %812 = add nuw nsw i32 %811, %808
  %813 = icmp eq i32 %812, 2
  %814 = zext i1 %813 to i8
  store i8 %814, i8* %41, align 1, !tbaa !2450
  %815 = add i64 %3395, 27
  store i64 %815, i64* %PC, align 8
  store i32 %793, i32* %791, align 4
  %816 = load i64, i64* %RBP, align 8
  %817 = add i64 %816, -32
  %818 = load i64, i64* %PC, align 8
  %819 = add i64 %818, 3
  store i64 %819, i64* %PC, align 8
  %820 = inttoptr i64 %817 to i32*
  %821 = load i32, i32* %820, align 4
  %822 = shl i32 %821, 1
  %823 = icmp slt i32 %821, 0
  %824 = icmp slt i32 %822, 0
  %825 = xor i1 %823, %824
  %826 = zext i32 %822 to i64
  store i64 %826, i64* %RCX, align 8, !tbaa !2428
  %.lobit = lshr i32 %821, 31
  %827 = trunc i32 %.lobit to i8
  store i8 %827, i8* %16, align 1, !tbaa !2432
  %828 = and i32 %822, 254
  %829 = tail call i32 @llvm.ctpop.i32(i32 %828) #10
  %830 = trunc i32 %829 to i8
  %831 = and i8 %830, 1
  %832 = xor i8 %831, 1
  store i8 %832, i8* %23, align 1, !tbaa !2432
  store i8 0, i8* %29, align 1, !tbaa !2432
  %833 = icmp eq i32 %822, 0
  %834 = zext i1 %833 to i8
  store i8 %834, i8* %32, align 1, !tbaa !2432
  %835 = lshr i32 %821, 30
  %836 = trunc i32 %835 to i8
  %837 = and i8 %836, 1
  store i8 %837, i8* %35, align 1, !tbaa !2432
  %838 = zext i1 %825 to i8
  store i8 %838, i8* %41, align 1, !tbaa !2432
  %839 = add i64 %816, -36
  %840 = add i64 %818, 9
  store i64 %840, i64* %PC, align 8
  %841 = inttoptr i64 %839 to i32*
  store i32 %822, i32* %841, align 4
  %842 = load i64, i64* %RBP, align 8
  %843 = add i64 %842, -24
  %844 = load i64, i64* %PC, align 8
  %845 = add i64 %844, 4
  store i64 %845, i64* %PC, align 8
  %846 = inttoptr i64 %843 to i64*
  %847 = load i64, i64* %846, align 8
  store i64 %847, i64* %RDX, align 8, !tbaa !2428
  %848 = add i64 %842, -32
  %849 = add i64 %844, 8
  store i64 %849, i64* %PC, align 8
  %850 = inttoptr i64 %848 to i32*
  %851 = load i32, i32* %850, align 4
  %852 = sext i32 %851 to i64
  store i64 %852, i64* %RSI, align 8, !tbaa !2428
  %853 = shl nsw i64 %852, 3
  %854 = add i64 %853, %847
  %855 = add i64 %844, 13
  store i64 %855, i64* %PC, align 8
  %856 = inttoptr i64 %854 to i64*
  %857 = load i64, i64* %856, align 8
  %858 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %857, i64* %858, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %859 = add i64 %842, -64
  %860 = add i64 %844, 18
  store i64 %860, i64* %PC, align 8
  %861 = inttoptr i64 %859 to i64*
  store i64 %857, i64* %861, align 8
  %862 = load i64, i64* %RBP, align 8
  %863 = add i64 %862, -24
  %864 = load i64, i64* %PC, align 8
  %865 = add i64 %864, 4
  store i64 %865, i64* %PC, align 8
  %866 = inttoptr i64 %863 to i64*
  %867 = load i64, i64* %866, align 8
  store i64 %867, i64* %RDX, align 8, !tbaa !2428
  %868 = add i64 %862, -32
  %869 = add i64 %864, 7
  store i64 %869, i64* %PC, align 8
  %870 = inttoptr i64 %868 to i32*
  %871 = load i32, i32* %870, align 4
  %872 = add i32 %871, 1
  %873 = zext i32 %872 to i64
  store i64 %873, i64* %RCX, align 8, !tbaa !2428
  %874 = icmp eq i32 %871, -1
  %875 = icmp eq i32 %872, 0
  %876 = or i1 %874, %875
  %877 = zext i1 %876 to i8
  store i8 %877, i8* %16, align 1, !tbaa !2433
  %878 = and i32 %872, 255
  %879 = tail call i32 @llvm.ctpop.i32(i32 %878) #10
  %880 = trunc i32 %879 to i8
  %881 = and i8 %880, 1
  %882 = xor i8 %881, 1
  store i8 %882, i8* %23, align 1, !tbaa !2447
  %883 = xor i32 %871, %872
  %884 = lshr i32 %883, 4
  %885 = trunc i32 %884 to i8
  %886 = and i8 %885, 1
  store i8 %886, i8* %29, align 1, !tbaa !2451
  %887 = zext i1 %875 to i8
  store i8 %887, i8* %32, align 1, !tbaa !2448
  %888 = lshr i32 %872, 31
  %889 = trunc i32 %888 to i8
  store i8 %889, i8* %35, align 1, !tbaa !2449
  %890 = lshr i32 %871, 31
  %891 = xor i32 %888, %890
  %892 = add nuw nsw i32 %891, %888
  %893 = icmp eq i32 %892, 2
  %894 = zext i1 %893 to i8
  store i8 %894, i8* %41, align 1, !tbaa !2450
  %895 = sext i32 %872 to i64
  store i64 %895, i64* %RSI, align 8, !tbaa !2428
  %896 = shl nsw i64 %895, 3
  %897 = add i64 %896, %867
  %898 = add i64 %864, 18
  store i64 %898, i64* %PC, align 8
  %899 = inttoptr i64 %897 to i64*
  %900 = load i64, i64* %899, align 8
  store i64 %900, i64* %858, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %901 = add i64 %862, -72
  %902 = add i64 %864, 23
  store i64 %902, i64* %PC, align 8
  %903 = inttoptr i64 %901 to i64*
  store i64 %900, i64* %903, align 8
  %904 = load i64, i64* %RBP, align 8
  %905 = add i64 %904, -24
  %906 = load i64, i64* %PC, align 8
  %907 = add i64 %906, 4
  store i64 %907, i64* %PC, align 8
  %908 = inttoptr i64 %905 to i64*
  %909 = load i64, i64* %908, align 8
  store i64 %909, i64* %RDX, align 8, !tbaa !2428
  %910 = add i64 %904, -36
  %911 = add i64 %906, 8
  store i64 %911, i64* %PC, align 8
  %912 = inttoptr i64 %910 to i32*
  %913 = load i32, i32* %912, align 4
  %914 = sext i32 %913 to i64
  store i64 %914, i64* %RSI, align 8, !tbaa !2428
  %915 = shl nsw i64 %914, 3
  %916 = add i64 %915, %909
  %917 = add i64 %906, 13
  store i64 %917, i64* %PC, align 8
  %918 = inttoptr i64 %916 to i64*
  %919 = load i64, i64* %918, align 8
  store i64 %919, i64* %858, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %920 = add i64 %904, -48
  %921 = add i64 %906, 18
  store i64 %921, i64* %PC, align 8
  %922 = inttoptr i64 %920 to i64*
  store i64 %919, i64* %922, align 8
  %923 = load i64, i64* %RBP, align 8
  %924 = add i64 %923, -24
  %925 = load i64, i64* %PC, align 8
  %926 = add i64 %925, 4
  store i64 %926, i64* %PC, align 8
  %927 = inttoptr i64 %924 to i64*
  %928 = load i64, i64* %927, align 8
  store i64 %928, i64* %RDX, align 8, !tbaa !2428
  %929 = add i64 %923, -36
  %930 = add i64 %925, 7
  store i64 %930, i64* %PC, align 8
  %931 = inttoptr i64 %929 to i32*
  %932 = load i32, i32* %931, align 4
  %933 = add i32 %932, 1
  %934 = zext i32 %933 to i64
  store i64 %934, i64* %RCX, align 8, !tbaa !2428
  %935 = icmp eq i32 %932, -1
  %936 = icmp eq i32 %933, 0
  %937 = or i1 %935, %936
  %938 = zext i1 %937 to i8
  store i8 %938, i8* %16, align 1, !tbaa !2433
  %939 = and i32 %933, 255
  %940 = tail call i32 @llvm.ctpop.i32(i32 %939) #10
  %941 = trunc i32 %940 to i8
  %942 = and i8 %941, 1
  %943 = xor i8 %942, 1
  store i8 %943, i8* %23, align 1, !tbaa !2447
  %944 = xor i32 %932, %933
  %945 = lshr i32 %944, 4
  %946 = trunc i32 %945 to i8
  %947 = and i8 %946, 1
  store i8 %947, i8* %29, align 1, !tbaa !2451
  %948 = zext i1 %936 to i8
  store i8 %948, i8* %32, align 1, !tbaa !2448
  %949 = lshr i32 %933, 31
  %950 = trunc i32 %949 to i8
  store i8 %950, i8* %35, align 1, !tbaa !2449
  %951 = lshr i32 %932, 31
  %952 = xor i32 %949, %951
  %953 = add nuw nsw i32 %952, %949
  %954 = icmp eq i32 %953, 2
  %955 = zext i1 %954 to i8
  store i8 %955, i8* %41, align 1, !tbaa !2450
  %956 = sext i32 %933 to i64
  store i64 %956, i64* %RSI, align 8, !tbaa !2428
  %957 = shl nsw i64 %956, 3
  %958 = add i64 %957, %928
  %959 = add i64 %925, 18
  store i64 %959, i64* %PC, align 8
  %960 = inttoptr i64 %958 to i64*
  %961 = load i64, i64* %960, align 8
  store i64 %961, i64* %858, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %962 = add i64 %923, -56
  %963 = add i64 %925, 23
  store i64 %963, i64* %PC, align 8
  %964 = inttoptr i64 %962 to i64*
  store i64 %961, i64* %964, align 8
  %965 = load i64, i64* %RBP, align 8
  %966 = add i64 %965, -48
  %967 = load i64, i64* %PC, align 8
  %968 = add i64 %967, 5
  store i64 %968, i64* %PC, align 8
  %969 = inttoptr i64 %966 to double*
  %970 = load double, double* %969, align 8
  store double %970, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %971 = load <2 x i32>, <2 x i32>* %771, align 1
  %972 = load <2 x i32>, <2 x i32>* %772, align 1
  %973 = extractelement <2 x i32> %971, i32 0
  store i32 %973, i32* %773, align 1, !tbaa !2475
  %974 = extractelement <2 x i32> %971, i32 1
  store i32 %974, i32* %775, align 1, !tbaa !2475
  %975 = extractelement <2 x i32> %972, i32 0
  store i32 %975, i32* %777, align 1, !tbaa !2475
  %976 = extractelement <2 x i32> %972, i32 1
  store i32 %976, i32* %779, align 1, !tbaa !2475
  %977 = add i64 %965, -72
  %978 = add i64 %967, 13
  store i64 %978, i64* %PC, align 8
  %979 = load double, double* %780, align 1
  %980 = inttoptr i64 %977 to double*
  %981 = load double, double* %980, align 8
  %982 = fmul double %979, %981
  store double %982, double* %780, align 1, !tbaa !2452
  %983 = add i64 %965, -56
  %984 = add i64 %967, 18
  store i64 %984, i64* %PC, align 8
  %985 = inttoptr i64 %983 to double*
  %986 = load double, double* %985, align 8
  %987 = fmul double %982, %986
  store double %987, double* %780, align 1, !tbaa !2452
  %988 = fsub double %970, %987
  %989 = add i64 %965, -80
  %990 = add i64 %967, 27
  store i64 %990, i64* %PC, align 8
  %991 = inttoptr i64 %989 to double*
  store double %988, double* %991, align 8
  %992 = load i64, i64* %PC, align 8
  %993 = load <2 x i32>, <2 x i32>* %771, align 1
  %994 = load <2 x i32>, <2 x i32>* %772, align 1
  %995 = extractelement <2 x i32> %993, i32 0
  store i32 %995, i32* %781, align 1, !tbaa !2475
  %996 = extractelement <2 x i32> %993, i32 1
  store i32 %996, i32* %783, align 1, !tbaa !2475
  %997 = extractelement <2 x i32> %994, i32 0
  store i32 %997, i32* %784, align 1, !tbaa !2475
  %998 = extractelement <2 x i32> %994, i32 1
  store i32 %998, i32* %786, align 1, !tbaa !2475
  %999 = load i64, i64* %RBP, align 8
  %1000 = add i64 %999, -72
  %1001 = add i64 %992, 8
  store i64 %1001, i64* %PC, align 8
  %1002 = load double, double* %647, align 1
  %1003 = inttoptr i64 %1000 to double*
  %1004 = load double, double* %1003, align 8
  %1005 = fmul double %1002, %1004
  store double %1005, double* %647, align 1, !tbaa !2452
  %1006 = add i64 %999, -48
  %1007 = add i64 %992, 13
  store i64 %1007, i64* %PC, align 8
  %1008 = inttoptr i64 %1006 to double*
  %1009 = load double, double* %1008, align 8
  %1010 = fmul double %1005, %1009
  store double %1010, double* %647, align 1, !tbaa !2452
  %1011 = add i64 %999, -56
  %1012 = add i64 %992, 18
  store i64 %1012, i64* %PC, align 8
  %1013 = inttoptr i64 %1011 to double*
  %1014 = load double, double* %1013, align 8
  %1015 = fsub double %1010, %1014
  store double %1015, double* %647, align 1, !tbaa !2452
  %1016 = add i64 %999, -88
  %1017 = add i64 %992, 23
  store i64 %1017, i64* %PC, align 8
  %1018 = inttoptr i64 %1016 to double*
  store double %1015, double* %1018, align 8
  %1019 = load i64, i64* %RBP, align 8
  %1020 = add i64 %1019, -16
  %1021 = load i64, i64* %PC, align 8
  %1022 = add i64 %1021, 4
  store i64 %1022, i64* %PC, align 8
  %1023 = inttoptr i64 %1020 to i64*
  %1024 = load i64, i64* %1023, align 8
  store i64 %1024, i64* %RDX, align 8, !tbaa !2428
  %1025 = add i64 %1019, -28
  %1026 = add i64 %1021, 8
  store i64 %1026, i64* %PC, align 8
  %1027 = inttoptr i64 %1025 to i32*
  %1028 = load i32, i32* %1027, align 4
  %1029 = sext i32 %1028 to i64
  store i64 %1029, i64* %RSI, align 8, !tbaa !2428
  %1030 = shl nsw i64 %1029, 3
  %1031 = add i64 %1030, %1024
  %1032 = add i64 %1021, 13
  store i64 %1032, i64* %PC, align 8
  %1033 = inttoptr i64 %1031 to double*
  %1034 = load double, double* %1033, align 8
  store double %1034, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1035 = add i64 %1021, 17
  store i64 %1035, i64* %PC, align 8
  %1036 = load i64, i64* %1023, align 8
  store i64 %1036, i64* %RDX, align 8, !tbaa !2428
  %1037 = add i64 %1021, 20
  store i64 %1037, i64* %PC, align 8
  %1038 = load i32, i32* %1027, align 4
  %1039 = add i32 %1038, 2
  %1040 = zext i32 %1039 to i64
  store i64 %1040, i64* %RCX, align 8, !tbaa !2428
  %1041 = icmp ugt i32 %1038, -3
  %1042 = zext i1 %1041 to i8
  store i8 %1042, i8* %16, align 1, !tbaa !2433
  %1043 = and i32 %1039, 255
  %1044 = tail call i32 @llvm.ctpop.i32(i32 %1043) #10
  %1045 = trunc i32 %1044 to i8
  %1046 = and i8 %1045, 1
  %1047 = xor i8 %1046, 1
  store i8 %1047, i8* %23, align 1, !tbaa !2447
  %1048 = xor i32 %1038, %1039
  %1049 = lshr i32 %1048, 4
  %1050 = trunc i32 %1049 to i8
  %1051 = and i8 %1050, 1
  store i8 %1051, i8* %29, align 1, !tbaa !2451
  %1052 = icmp eq i32 %1039, 0
  %1053 = zext i1 %1052 to i8
  store i8 %1053, i8* %32, align 1, !tbaa !2448
  %1054 = lshr i32 %1039, 31
  %1055 = trunc i32 %1054 to i8
  store i8 %1055, i8* %35, align 1, !tbaa !2449
  %1056 = lshr i32 %1038, 31
  %1057 = xor i32 %1054, %1056
  %1058 = add nuw nsw i32 %1057, %1054
  %1059 = icmp eq i32 %1058, 2
  %1060 = zext i1 %1059 to i8
  store i8 %1060, i8* %41, align 1, !tbaa !2450
  %1061 = sext i32 %1039 to i64
  store i64 %1061, i64* %RSI, align 8, !tbaa !2428
  %1062 = shl nsw i64 %1061, 3
  %1063 = add i64 %1062, %1036
  %1064 = add i64 %1021, 31
  store i64 %1064, i64* %PC, align 8
  %1065 = inttoptr i64 %1063 to double*
  %1066 = load double, double* %1065, align 8
  %1067 = fadd double %1034, %1066
  store double %1067, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1068 = add i64 %1019, -96
  %1069 = add i64 %1021, 36
  store i64 %1069, i64* %PC, align 8
  %1070 = inttoptr i64 %1068 to double*
  store double %1067, double* %1070, align 8
  %1071 = load i64, i64* %RBP, align 8
  %1072 = add i64 %1071, -16
  %1073 = load i64, i64* %PC, align 8
  %1074 = add i64 %1073, 4
  store i64 %1074, i64* %PC, align 8
  %1075 = inttoptr i64 %1072 to i64*
  %1076 = load i64, i64* %1075, align 8
  store i64 %1076, i64* %RDX, align 8, !tbaa !2428
  %1077 = add i64 %1071, -28
  %1078 = add i64 %1073, 7
  store i64 %1078, i64* %PC, align 8
  %1079 = inttoptr i64 %1077 to i32*
  %1080 = load i32, i32* %1079, align 4
  %1081 = add i32 %1080, 1
  %1082 = zext i32 %1081 to i64
  store i64 %1082, i64* %RCX, align 8, !tbaa !2428
  %1083 = icmp eq i32 %1080, -1
  %1084 = icmp eq i32 %1081, 0
  %1085 = or i1 %1083, %1084
  %1086 = zext i1 %1085 to i8
  store i8 %1086, i8* %16, align 1, !tbaa !2433
  %1087 = and i32 %1081, 255
  %1088 = tail call i32 @llvm.ctpop.i32(i32 %1087) #10
  %1089 = trunc i32 %1088 to i8
  %1090 = and i8 %1089, 1
  %1091 = xor i8 %1090, 1
  store i8 %1091, i8* %23, align 1, !tbaa !2447
  %1092 = xor i32 %1080, %1081
  %1093 = lshr i32 %1092, 4
  %1094 = trunc i32 %1093 to i8
  %1095 = and i8 %1094, 1
  store i8 %1095, i8* %29, align 1, !tbaa !2451
  %1096 = zext i1 %1084 to i8
  store i8 %1096, i8* %32, align 1, !tbaa !2448
  %1097 = lshr i32 %1081, 31
  %1098 = trunc i32 %1097 to i8
  store i8 %1098, i8* %35, align 1, !tbaa !2449
  %1099 = lshr i32 %1080, 31
  %1100 = xor i32 %1097, %1099
  %1101 = add nuw nsw i32 %1100, %1097
  %1102 = icmp eq i32 %1101, 2
  %1103 = zext i1 %1102 to i8
  store i8 %1103, i8* %41, align 1, !tbaa !2450
  %1104 = sext i32 %1081 to i64
  store i64 %1104, i64* %RSI, align 8, !tbaa !2428
  %1105 = shl nsw i64 %1104, 3
  %1106 = add i64 %1105, %1076
  %1107 = add i64 %1073, 18
  store i64 %1107, i64* %PC, align 8
  %1108 = inttoptr i64 %1106 to double*
  %1109 = load double, double* %1108, align 8
  store double %1109, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1110 = add i64 %1073, 22
  store i64 %1110, i64* %PC, align 8
  %1111 = load i64, i64* %1075, align 8
  store i64 %1111, i64* %RDX, align 8, !tbaa !2428
  %1112 = add i64 %1073, 25
  store i64 %1112, i64* %PC, align 8
  %1113 = load i32, i32* %1079, align 4
  %1114 = add i32 %1113, 3
  %1115 = zext i32 %1114 to i64
  store i64 %1115, i64* %RCX, align 8, !tbaa !2428
  %1116 = icmp ugt i32 %1113, -4
  %1117 = zext i1 %1116 to i8
  store i8 %1117, i8* %16, align 1, !tbaa !2433
  %1118 = and i32 %1114, 255
  %1119 = tail call i32 @llvm.ctpop.i32(i32 %1118) #10
  %1120 = trunc i32 %1119 to i8
  %1121 = and i8 %1120, 1
  %1122 = xor i8 %1121, 1
  store i8 %1122, i8* %23, align 1, !tbaa !2447
  %1123 = xor i32 %1113, %1114
  %1124 = lshr i32 %1123, 4
  %1125 = trunc i32 %1124 to i8
  %1126 = and i8 %1125, 1
  store i8 %1126, i8* %29, align 1, !tbaa !2451
  %1127 = icmp eq i32 %1114, 0
  %1128 = zext i1 %1127 to i8
  store i8 %1128, i8* %32, align 1, !tbaa !2448
  %1129 = lshr i32 %1114, 31
  %1130 = trunc i32 %1129 to i8
  store i8 %1130, i8* %35, align 1, !tbaa !2449
  %1131 = lshr i32 %1113, 31
  %1132 = xor i32 %1129, %1131
  %1133 = add nuw nsw i32 %1132, %1129
  %1134 = icmp eq i32 %1133, 2
  %1135 = zext i1 %1134 to i8
  store i8 %1135, i8* %41, align 1, !tbaa !2450
  %1136 = sext i32 %1114 to i64
  store i64 %1136, i64* %RSI, align 8, !tbaa !2428
  %1137 = shl nsw i64 %1136, 3
  %1138 = add i64 %1137, %1111
  %1139 = add i64 %1073, 36
  store i64 %1139, i64* %PC, align 8
  %1140 = inttoptr i64 %1138 to double*
  %1141 = load double, double* %1140, align 8
  %1142 = fadd double %1109, %1141
  store double %1142, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1143 = load i64, i64* %RBP, align 8
  %1144 = add i64 %1143, -104
  %1145 = add i64 %1073, 41
  store i64 %1145, i64* %PC, align 8
  %1146 = inttoptr i64 %1144 to double*
  store double %1142, double* %1146, align 8
  %1147 = load i64, i64* %RBP, align 8
  %1148 = add i64 %1147, -16
  %1149 = load i64, i64* %PC, align 8
  %1150 = add i64 %1149, 4
  store i64 %1150, i64* %PC, align 8
  %1151 = inttoptr i64 %1148 to i64*
  %1152 = load i64, i64* %1151, align 8
  store i64 %1152, i64* %RDX, align 8, !tbaa !2428
  %1153 = add i64 %1147, -28
  %1154 = add i64 %1149, 8
  store i64 %1154, i64* %PC, align 8
  %1155 = inttoptr i64 %1153 to i32*
  %1156 = load i32, i32* %1155, align 4
  %1157 = sext i32 %1156 to i64
  store i64 %1157, i64* %RSI, align 8, !tbaa !2428
  %1158 = shl nsw i64 %1157, 3
  %1159 = add i64 %1158, %1152
  %1160 = add i64 %1149, 13
  store i64 %1160, i64* %PC, align 8
  %1161 = inttoptr i64 %1159 to double*
  %1162 = load double, double* %1161, align 8
  store double %1162, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1163 = add i64 %1149, 17
  store i64 %1163, i64* %PC, align 8
  %1164 = load i64, i64* %1151, align 8
  store i64 %1164, i64* %RDX, align 8, !tbaa !2428
  %1165 = add i64 %1149, 20
  store i64 %1165, i64* %PC, align 8
  %1166 = load i32, i32* %1155, align 4
  %1167 = add i32 %1166, 2
  %1168 = zext i32 %1167 to i64
  store i64 %1168, i64* %RCX, align 8, !tbaa !2428
  %1169 = icmp ugt i32 %1166, -3
  %1170 = zext i1 %1169 to i8
  store i8 %1170, i8* %16, align 1, !tbaa !2433
  %1171 = and i32 %1167, 255
  %1172 = tail call i32 @llvm.ctpop.i32(i32 %1171) #10
  %1173 = trunc i32 %1172 to i8
  %1174 = and i8 %1173, 1
  %1175 = xor i8 %1174, 1
  store i8 %1175, i8* %23, align 1, !tbaa !2447
  %1176 = xor i32 %1166, %1167
  %1177 = lshr i32 %1176, 4
  %1178 = trunc i32 %1177 to i8
  %1179 = and i8 %1178, 1
  store i8 %1179, i8* %29, align 1, !tbaa !2451
  %1180 = icmp eq i32 %1167, 0
  %1181 = zext i1 %1180 to i8
  store i8 %1181, i8* %32, align 1, !tbaa !2448
  %1182 = lshr i32 %1167, 31
  %1183 = trunc i32 %1182 to i8
  store i8 %1183, i8* %35, align 1, !tbaa !2449
  %1184 = lshr i32 %1166, 31
  %1185 = xor i32 %1182, %1184
  %1186 = add nuw nsw i32 %1185, %1182
  %1187 = icmp eq i32 %1186, 2
  %1188 = zext i1 %1187 to i8
  store i8 %1188, i8* %41, align 1, !tbaa !2450
  %1189 = sext i32 %1167 to i64
  store i64 %1189, i64* %RSI, align 8, !tbaa !2428
  %1190 = shl nsw i64 %1189, 3
  %1191 = add i64 %1190, %1164
  %1192 = add i64 %1149, 31
  store i64 %1192, i64* %PC, align 8
  %1193 = inttoptr i64 %1191 to double*
  %1194 = load double, double* %1193, align 8
  %1195 = fsub double %1162, %1194
  store double %1195, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1196 = add i64 %1147, -112
  %1197 = add i64 %1149, 36
  store i64 %1197, i64* %PC, align 8
  %1198 = inttoptr i64 %1196 to double*
  store double %1195, double* %1198, align 8
  %1199 = load i64, i64* %RBP, align 8
  %1200 = add i64 %1199, -16
  %1201 = load i64, i64* %PC, align 8
  %1202 = add i64 %1201, 4
  store i64 %1202, i64* %PC, align 8
  %1203 = inttoptr i64 %1200 to i64*
  %1204 = load i64, i64* %1203, align 8
  store i64 %1204, i64* %RDX, align 8, !tbaa !2428
  %1205 = add i64 %1199, -28
  %1206 = add i64 %1201, 7
  store i64 %1206, i64* %PC, align 8
  %1207 = inttoptr i64 %1205 to i32*
  %1208 = load i32, i32* %1207, align 4
  %1209 = add i32 %1208, 1
  %1210 = zext i32 %1209 to i64
  store i64 %1210, i64* %RCX, align 8, !tbaa !2428
  %1211 = icmp eq i32 %1208, -1
  %1212 = icmp eq i32 %1209, 0
  %1213 = or i1 %1211, %1212
  %1214 = zext i1 %1213 to i8
  store i8 %1214, i8* %16, align 1, !tbaa !2433
  %1215 = and i32 %1209, 255
  %1216 = tail call i32 @llvm.ctpop.i32(i32 %1215) #10
  %1217 = trunc i32 %1216 to i8
  %1218 = and i8 %1217, 1
  %1219 = xor i8 %1218, 1
  store i8 %1219, i8* %23, align 1, !tbaa !2447
  %1220 = xor i32 %1208, %1209
  %1221 = lshr i32 %1220, 4
  %1222 = trunc i32 %1221 to i8
  %1223 = and i8 %1222, 1
  store i8 %1223, i8* %29, align 1, !tbaa !2451
  %1224 = zext i1 %1212 to i8
  store i8 %1224, i8* %32, align 1, !tbaa !2448
  %1225 = lshr i32 %1209, 31
  %1226 = trunc i32 %1225 to i8
  store i8 %1226, i8* %35, align 1, !tbaa !2449
  %1227 = lshr i32 %1208, 31
  %1228 = xor i32 %1225, %1227
  %1229 = add nuw nsw i32 %1228, %1225
  %1230 = icmp eq i32 %1229, 2
  %1231 = zext i1 %1230 to i8
  store i8 %1231, i8* %41, align 1, !tbaa !2450
  %1232 = sext i32 %1209 to i64
  store i64 %1232, i64* %RSI, align 8, !tbaa !2428
  %1233 = shl nsw i64 %1232, 3
  %1234 = add i64 %1233, %1204
  %1235 = add i64 %1201, 18
  store i64 %1235, i64* %PC, align 8
  %1236 = inttoptr i64 %1234 to double*
  %1237 = load double, double* %1236, align 8
  store double %1237, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1238 = add i64 %1201, 22
  store i64 %1238, i64* %PC, align 8
  %1239 = load i64, i64* %1203, align 8
  store i64 %1239, i64* %RDX, align 8, !tbaa !2428
  %1240 = add i64 %1201, 25
  store i64 %1240, i64* %PC, align 8
  %1241 = load i32, i32* %1207, align 4
  %1242 = add i32 %1241, 3
  %1243 = zext i32 %1242 to i64
  store i64 %1243, i64* %RCX, align 8, !tbaa !2428
  %1244 = icmp ugt i32 %1241, -4
  %1245 = zext i1 %1244 to i8
  store i8 %1245, i8* %16, align 1, !tbaa !2433
  %1246 = and i32 %1242, 255
  %1247 = tail call i32 @llvm.ctpop.i32(i32 %1246) #10
  %1248 = trunc i32 %1247 to i8
  %1249 = and i8 %1248, 1
  %1250 = xor i8 %1249, 1
  store i8 %1250, i8* %23, align 1, !tbaa !2447
  %1251 = xor i32 %1241, %1242
  %1252 = lshr i32 %1251, 4
  %1253 = trunc i32 %1252 to i8
  %1254 = and i8 %1253, 1
  store i8 %1254, i8* %29, align 1, !tbaa !2451
  %1255 = icmp eq i32 %1242, 0
  %1256 = zext i1 %1255 to i8
  store i8 %1256, i8* %32, align 1, !tbaa !2448
  %1257 = lshr i32 %1242, 31
  %1258 = trunc i32 %1257 to i8
  store i8 %1258, i8* %35, align 1, !tbaa !2449
  %1259 = lshr i32 %1241, 31
  %1260 = xor i32 %1257, %1259
  %1261 = add nuw nsw i32 %1260, %1257
  %1262 = icmp eq i32 %1261, 2
  %1263 = zext i1 %1262 to i8
  store i8 %1263, i8* %41, align 1, !tbaa !2450
  %1264 = sext i32 %1242 to i64
  store i64 %1264, i64* %RSI, align 8, !tbaa !2428
  %1265 = shl nsw i64 %1264, 3
  %1266 = add i64 %1265, %1239
  %1267 = add i64 %1201, 36
  store i64 %1267, i64* %PC, align 8
  %1268 = inttoptr i64 %1266 to double*
  %1269 = load double, double* %1268, align 8
  %1270 = fsub double %1237, %1269
  store double %1270, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1271 = load i64, i64* %RBP, align 8
  %1272 = add i64 %1271, -120
  %1273 = add i64 %1201, 41
  store i64 %1273, i64* %PC, align 8
  %1274 = inttoptr i64 %1272 to double*
  store double %1270, double* %1274, align 8
  %1275 = load i64, i64* %RBP, align 8
  %1276 = add i64 %1275, -16
  %1277 = load i64, i64* %PC, align 8
  %1278 = add i64 %1277, 4
  store i64 %1278, i64* %PC, align 8
  %1279 = inttoptr i64 %1276 to i64*
  %1280 = load i64, i64* %1279, align 8
  store i64 %1280, i64* %RDX, align 8, !tbaa !2428
  %1281 = add i64 %1275, -28
  %1282 = add i64 %1277, 7
  store i64 %1282, i64* %PC, align 8
  %1283 = inttoptr i64 %1281 to i32*
  %1284 = load i32, i32* %1283, align 4
  %1285 = add i32 %1284, 4
  %1286 = zext i32 %1285 to i64
  store i64 %1286, i64* %RCX, align 8, !tbaa !2428
  %1287 = icmp ugt i32 %1284, -5
  %1288 = zext i1 %1287 to i8
  store i8 %1288, i8* %16, align 1, !tbaa !2433
  %1289 = and i32 %1285, 255
  %1290 = tail call i32 @llvm.ctpop.i32(i32 %1289) #10
  %1291 = trunc i32 %1290 to i8
  %1292 = and i8 %1291, 1
  %1293 = xor i8 %1292, 1
  store i8 %1293, i8* %23, align 1, !tbaa !2447
  %1294 = xor i32 %1284, %1285
  %1295 = lshr i32 %1294, 4
  %1296 = trunc i32 %1295 to i8
  %1297 = and i8 %1296, 1
  store i8 %1297, i8* %29, align 1, !tbaa !2451
  %1298 = icmp eq i32 %1285, 0
  %1299 = zext i1 %1298 to i8
  store i8 %1299, i8* %32, align 1, !tbaa !2448
  %1300 = lshr i32 %1285, 31
  %1301 = trunc i32 %1300 to i8
  store i8 %1301, i8* %35, align 1, !tbaa !2449
  %1302 = lshr i32 %1284, 31
  %1303 = xor i32 %1300, %1302
  %1304 = add nuw nsw i32 %1303, %1300
  %1305 = icmp eq i32 %1304, 2
  %1306 = zext i1 %1305 to i8
  store i8 %1306, i8* %41, align 1, !tbaa !2450
  %1307 = sext i32 %1285 to i64
  store i64 %1307, i64* %RSI, align 8, !tbaa !2428
  %1308 = shl nsw i64 %1307, 3
  %1309 = add i64 %1308, %1280
  %1310 = add i64 %1277, 18
  store i64 %1310, i64* %PC, align 8
  %1311 = inttoptr i64 %1309 to double*
  %1312 = load double, double* %1311, align 8
  store double %1312, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1313 = add i64 %1277, 22
  store i64 %1313, i64* %PC, align 8
  %1314 = load i64, i64* %1279, align 8
  store i64 %1314, i64* %RDX, align 8, !tbaa !2428
  %1315 = add i64 %1277, 25
  store i64 %1315, i64* %PC, align 8
  %1316 = load i32, i32* %1283, align 4
  %1317 = add i32 %1316, 6
  %1318 = zext i32 %1317 to i64
  store i64 %1318, i64* %RCX, align 8, !tbaa !2428
  %1319 = icmp ugt i32 %1316, -7
  %1320 = zext i1 %1319 to i8
  store i8 %1320, i8* %16, align 1, !tbaa !2433
  %1321 = and i32 %1317, 255
  %1322 = tail call i32 @llvm.ctpop.i32(i32 %1321) #10
  %1323 = trunc i32 %1322 to i8
  %1324 = and i8 %1323, 1
  %1325 = xor i8 %1324, 1
  store i8 %1325, i8* %23, align 1, !tbaa !2447
  %1326 = xor i32 %1316, %1317
  %1327 = lshr i32 %1326, 4
  %1328 = trunc i32 %1327 to i8
  %1329 = and i8 %1328, 1
  store i8 %1329, i8* %29, align 1, !tbaa !2451
  %1330 = icmp eq i32 %1317, 0
  %1331 = zext i1 %1330 to i8
  store i8 %1331, i8* %32, align 1, !tbaa !2448
  %1332 = lshr i32 %1317, 31
  %1333 = trunc i32 %1332 to i8
  store i8 %1333, i8* %35, align 1, !tbaa !2449
  %1334 = lshr i32 %1316, 31
  %1335 = xor i32 %1332, %1334
  %1336 = add nuw nsw i32 %1335, %1332
  %1337 = icmp eq i32 %1336, 2
  %1338 = zext i1 %1337 to i8
  store i8 %1338, i8* %41, align 1, !tbaa !2450
  %1339 = sext i32 %1317 to i64
  store i64 %1339, i64* %RSI, align 8, !tbaa !2428
  %1340 = shl nsw i64 %1339, 3
  %1341 = add i64 %1340, %1314
  %1342 = add i64 %1277, 36
  store i64 %1342, i64* %PC, align 8
  %1343 = inttoptr i64 %1341 to double*
  %1344 = load double, double* %1343, align 8
  %1345 = fadd double %1312, %1344
  store double %1345, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1346 = load i64, i64* %RBP, align 8
  %1347 = add i64 %1346, -128
  %1348 = add i64 %1277, 41
  store i64 %1348, i64* %PC, align 8
  %1349 = inttoptr i64 %1347 to double*
  store double %1345, double* %1349, align 8
  %1350 = load i64, i64* %RBP, align 8
  %1351 = add i64 %1350, -16
  %1352 = load i64, i64* %PC, align 8
  %1353 = add i64 %1352, 4
  store i64 %1353, i64* %PC, align 8
  %1354 = inttoptr i64 %1351 to i64*
  %1355 = load i64, i64* %1354, align 8
  store i64 %1355, i64* %RDX, align 8, !tbaa !2428
  %1356 = add i64 %1350, -28
  %1357 = add i64 %1352, 7
  store i64 %1357, i64* %PC, align 8
  %1358 = inttoptr i64 %1356 to i32*
  %1359 = load i32, i32* %1358, align 4
  %1360 = add i32 %1359, 5
  %1361 = zext i32 %1360 to i64
  store i64 %1361, i64* %RCX, align 8, !tbaa !2428
  %1362 = icmp ugt i32 %1359, -6
  %1363 = zext i1 %1362 to i8
  store i8 %1363, i8* %16, align 1, !tbaa !2433
  %1364 = and i32 %1360, 255
  %1365 = tail call i32 @llvm.ctpop.i32(i32 %1364) #10
  %1366 = trunc i32 %1365 to i8
  %1367 = and i8 %1366, 1
  %1368 = xor i8 %1367, 1
  store i8 %1368, i8* %23, align 1, !tbaa !2447
  %1369 = xor i32 %1359, %1360
  %1370 = lshr i32 %1369, 4
  %1371 = trunc i32 %1370 to i8
  %1372 = and i8 %1371, 1
  store i8 %1372, i8* %29, align 1, !tbaa !2451
  %1373 = icmp eq i32 %1360, 0
  %1374 = zext i1 %1373 to i8
  store i8 %1374, i8* %32, align 1, !tbaa !2448
  %1375 = lshr i32 %1360, 31
  %1376 = trunc i32 %1375 to i8
  store i8 %1376, i8* %35, align 1, !tbaa !2449
  %1377 = lshr i32 %1359, 31
  %1378 = xor i32 %1375, %1377
  %1379 = add nuw nsw i32 %1378, %1375
  %1380 = icmp eq i32 %1379, 2
  %1381 = zext i1 %1380 to i8
  store i8 %1381, i8* %41, align 1, !tbaa !2450
  %1382 = sext i32 %1360 to i64
  store i64 %1382, i64* %RSI, align 8, !tbaa !2428
  %1383 = shl nsw i64 %1382, 3
  %1384 = add i64 %1383, %1355
  %1385 = add i64 %1352, 18
  store i64 %1385, i64* %PC, align 8
  %1386 = inttoptr i64 %1384 to double*
  %1387 = load double, double* %1386, align 8
  store double %1387, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1388 = add i64 %1352, 22
  store i64 %1388, i64* %PC, align 8
  %1389 = load i64, i64* %1354, align 8
  store i64 %1389, i64* %RDX, align 8, !tbaa !2428
  %1390 = add i64 %1352, 25
  store i64 %1390, i64* %PC, align 8
  %1391 = load i32, i32* %1358, align 4
  %1392 = add i32 %1391, 7
  %1393 = zext i32 %1392 to i64
  store i64 %1393, i64* %RCX, align 8, !tbaa !2428
  %1394 = icmp ugt i32 %1391, -8
  %1395 = zext i1 %1394 to i8
  store i8 %1395, i8* %16, align 1, !tbaa !2433
  %1396 = and i32 %1392, 255
  %1397 = tail call i32 @llvm.ctpop.i32(i32 %1396) #10
  %1398 = trunc i32 %1397 to i8
  %1399 = and i8 %1398, 1
  %1400 = xor i8 %1399, 1
  store i8 %1400, i8* %23, align 1, !tbaa !2447
  %1401 = xor i32 %1391, %1392
  %1402 = lshr i32 %1401, 4
  %1403 = trunc i32 %1402 to i8
  %1404 = and i8 %1403, 1
  store i8 %1404, i8* %29, align 1, !tbaa !2451
  %1405 = icmp eq i32 %1392, 0
  %1406 = zext i1 %1405 to i8
  store i8 %1406, i8* %32, align 1, !tbaa !2448
  %1407 = lshr i32 %1392, 31
  %1408 = trunc i32 %1407 to i8
  store i8 %1408, i8* %35, align 1, !tbaa !2449
  %1409 = lshr i32 %1391, 31
  %1410 = xor i32 %1407, %1409
  %1411 = add nuw nsw i32 %1410, %1407
  %1412 = icmp eq i32 %1411, 2
  %1413 = zext i1 %1412 to i8
  store i8 %1413, i8* %41, align 1, !tbaa !2450
  %1414 = sext i32 %1392 to i64
  store i64 %1414, i64* %RSI, align 8, !tbaa !2428
  %1415 = shl nsw i64 %1414, 3
  %1416 = add i64 %1415, %1389
  %1417 = add i64 %1352, 36
  store i64 %1417, i64* %PC, align 8
  %1418 = inttoptr i64 %1416 to double*
  %1419 = load double, double* %1418, align 8
  %1420 = fadd double %1387, %1419
  store double %1420, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1421 = load i64, i64* %RBP, align 8
  %1422 = add i64 %1421, -136
  %1423 = add i64 %1352, 44
  store i64 %1423, i64* %PC, align 8
  %1424 = inttoptr i64 %1422 to double*
  store double %1420, double* %1424, align 8
  %1425 = load i64, i64* %RBP, align 8
  %1426 = add i64 %1425, -16
  %1427 = load i64, i64* %PC, align 8
  %1428 = add i64 %1427, 4
  store i64 %1428, i64* %PC, align 8
  %1429 = inttoptr i64 %1426 to i64*
  %1430 = load i64, i64* %1429, align 8
  store i64 %1430, i64* %RDX, align 8, !tbaa !2428
  %1431 = add i64 %1425, -28
  %1432 = add i64 %1427, 7
  store i64 %1432, i64* %PC, align 8
  %1433 = inttoptr i64 %1431 to i32*
  %1434 = load i32, i32* %1433, align 4
  %1435 = add i32 %1434, 4
  %1436 = zext i32 %1435 to i64
  store i64 %1436, i64* %RCX, align 8, !tbaa !2428
  %1437 = icmp ugt i32 %1434, -5
  %1438 = zext i1 %1437 to i8
  store i8 %1438, i8* %16, align 1, !tbaa !2433
  %1439 = and i32 %1435, 255
  %1440 = tail call i32 @llvm.ctpop.i32(i32 %1439) #10
  %1441 = trunc i32 %1440 to i8
  %1442 = and i8 %1441, 1
  %1443 = xor i8 %1442, 1
  store i8 %1443, i8* %23, align 1, !tbaa !2447
  %1444 = xor i32 %1434, %1435
  %1445 = lshr i32 %1444, 4
  %1446 = trunc i32 %1445 to i8
  %1447 = and i8 %1446, 1
  store i8 %1447, i8* %29, align 1, !tbaa !2451
  %1448 = icmp eq i32 %1435, 0
  %1449 = zext i1 %1448 to i8
  store i8 %1449, i8* %32, align 1, !tbaa !2448
  %1450 = lshr i32 %1435, 31
  %1451 = trunc i32 %1450 to i8
  store i8 %1451, i8* %35, align 1, !tbaa !2449
  %1452 = lshr i32 %1434, 31
  %1453 = xor i32 %1450, %1452
  %1454 = add nuw nsw i32 %1453, %1450
  %1455 = icmp eq i32 %1454, 2
  %1456 = zext i1 %1455 to i8
  store i8 %1456, i8* %41, align 1, !tbaa !2450
  %1457 = sext i32 %1435 to i64
  store i64 %1457, i64* %RSI, align 8, !tbaa !2428
  %1458 = shl nsw i64 %1457, 3
  %1459 = add i64 %1458, %1430
  %1460 = add i64 %1427, 18
  store i64 %1460, i64* %PC, align 8
  %1461 = inttoptr i64 %1459 to double*
  %1462 = load double, double* %1461, align 8
  store double %1462, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1463 = add i64 %1427, 22
  store i64 %1463, i64* %PC, align 8
  %1464 = load i64, i64* %1429, align 8
  store i64 %1464, i64* %RDX, align 8, !tbaa !2428
  %1465 = add i64 %1427, 25
  store i64 %1465, i64* %PC, align 8
  %1466 = load i32, i32* %1433, align 4
  %1467 = add i32 %1466, 6
  %1468 = zext i32 %1467 to i64
  store i64 %1468, i64* %RCX, align 8, !tbaa !2428
  %1469 = icmp ugt i32 %1466, -7
  %1470 = zext i1 %1469 to i8
  store i8 %1470, i8* %16, align 1, !tbaa !2433
  %1471 = and i32 %1467, 255
  %1472 = tail call i32 @llvm.ctpop.i32(i32 %1471) #10
  %1473 = trunc i32 %1472 to i8
  %1474 = and i8 %1473, 1
  %1475 = xor i8 %1474, 1
  store i8 %1475, i8* %23, align 1, !tbaa !2447
  %1476 = xor i32 %1466, %1467
  %1477 = lshr i32 %1476, 4
  %1478 = trunc i32 %1477 to i8
  %1479 = and i8 %1478, 1
  store i8 %1479, i8* %29, align 1, !tbaa !2451
  %1480 = icmp eq i32 %1467, 0
  %1481 = zext i1 %1480 to i8
  store i8 %1481, i8* %32, align 1, !tbaa !2448
  %1482 = lshr i32 %1467, 31
  %1483 = trunc i32 %1482 to i8
  store i8 %1483, i8* %35, align 1, !tbaa !2449
  %1484 = lshr i32 %1466, 31
  %1485 = xor i32 %1482, %1484
  %1486 = add nuw nsw i32 %1485, %1482
  %1487 = icmp eq i32 %1486, 2
  %1488 = zext i1 %1487 to i8
  store i8 %1488, i8* %41, align 1, !tbaa !2450
  %1489 = sext i32 %1467 to i64
  store i64 %1489, i64* %RSI, align 8, !tbaa !2428
  %1490 = shl nsw i64 %1489, 3
  %1491 = add i64 %1490, %1464
  %1492 = add i64 %1427, 36
  store i64 %1492, i64* %PC, align 8
  %1493 = inttoptr i64 %1491 to double*
  %1494 = load double, double* %1493, align 8
  %1495 = fsub double %1462, %1494
  store double %1495, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1496 = load i64, i64* %RBP, align 8
  %1497 = add i64 %1496, -144
  %1498 = add i64 %1427, 44
  store i64 %1498, i64* %PC, align 8
  %1499 = inttoptr i64 %1497 to double*
  store double %1495, double* %1499, align 8
  %1500 = load i64, i64* %RBP, align 8
  %1501 = add i64 %1500, -16
  %1502 = load i64, i64* %PC, align 8
  %1503 = add i64 %1502, 4
  store i64 %1503, i64* %PC, align 8
  %1504 = inttoptr i64 %1501 to i64*
  %1505 = load i64, i64* %1504, align 8
  store i64 %1505, i64* %RDX, align 8, !tbaa !2428
  %1506 = add i64 %1500, -28
  %1507 = add i64 %1502, 7
  store i64 %1507, i64* %PC, align 8
  %1508 = inttoptr i64 %1506 to i32*
  %1509 = load i32, i32* %1508, align 4
  %1510 = add i32 %1509, 5
  %1511 = zext i32 %1510 to i64
  store i64 %1511, i64* %RCX, align 8, !tbaa !2428
  %1512 = icmp ugt i32 %1509, -6
  %1513 = zext i1 %1512 to i8
  store i8 %1513, i8* %16, align 1, !tbaa !2433
  %1514 = and i32 %1510, 255
  %1515 = tail call i32 @llvm.ctpop.i32(i32 %1514) #10
  %1516 = trunc i32 %1515 to i8
  %1517 = and i8 %1516, 1
  %1518 = xor i8 %1517, 1
  store i8 %1518, i8* %23, align 1, !tbaa !2447
  %1519 = xor i32 %1509, %1510
  %1520 = lshr i32 %1519, 4
  %1521 = trunc i32 %1520 to i8
  %1522 = and i8 %1521, 1
  store i8 %1522, i8* %29, align 1, !tbaa !2451
  %1523 = icmp eq i32 %1510, 0
  %1524 = zext i1 %1523 to i8
  store i8 %1524, i8* %32, align 1, !tbaa !2448
  %1525 = lshr i32 %1510, 31
  %1526 = trunc i32 %1525 to i8
  store i8 %1526, i8* %35, align 1, !tbaa !2449
  %1527 = lshr i32 %1509, 31
  %1528 = xor i32 %1525, %1527
  %1529 = add nuw nsw i32 %1528, %1525
  %1530 = icmp eq i32 %1529, 2
  %1531 = zext i1 %1530 to i8
  store i8 %1531, i8* %41, align 1, !tbaa !2450
  %1532 = sext i32 %1510 to i64
  store i64 %1532, i64* %RSI, align 8, !tbaa !2428
  %1533 = shl nsw i64 %1532, 3
  %1534 = add i64 %1533, %1505
  %1535 = add i64 %1502, 18
  store i64 %1535, i64* %PC, align 8
  %1536 = inttoptr i64 %1534 to double*
  %1537 = load double, double* %1536, align 8
  store double %1537, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1538 = add i64 %1502, 22
  store i64 %1538, i64* %PC, align 8
  %1539 = load i64, i64* %1504, align 8
  store i64 %1539, i64* %RDX, align 8, !tbaa !2428
  %1540 = add i64 %1502, 25
  store i64 %1540, i64* %PC, align 8
  %1541 = load i32, i32* %1508, align 4
  %1542 = add i32 %1541, 7
  %1543 = zext i32 %1542 to i64
  store i64 %1543, i64* %RCX, align 8, !tbaa !2428
  %1544 = icmp ugt i32 %1541, -8
  %1545 = zext i1 %1544 to i8
  store i8 %1545, i8* %16, align 1, !tbaa !2433
  %1546 = and i32 %1542, 255
  %1547 = tail call i32 @llvm.ctpop.i32(i32 %1546) #10
  %1548 = trunc i32 %1547 to i8
  %1549 = and i8 %1548, 1
  %1550 = xor i8 %1549, 1
  store i8 %1550, i8* %23, align 1, !tbaa !2447
  %1551 = xor i32 %1541, %1542
  %1552 = lshr i32 %1551, 4
  %1553 = trunc i32 %1552 to i8
  %1554 = and i8 %1553, 1
  store i8 %1554, i8* %29, align 1, !tbaa !2451
  %1555 = icmp eq i32 %1542, 0
  %1556 = zext i1 %1555 to i8
  store i8 %1556, i8* %32, align 1, !tbaa !2448
  %1557 = lshr i32 %1542, 31
  %1558 = trunc i32 %1557 to i8
  store i8 %1558, i8* %35, align 1, !tbaa !2449
  %1559 = lshr i32 %1541, 31
  %1560 = xor i32 %1557, %1559
  %1561 = add nuw nsw i32 %1560, %1557
  %1562 = icmp eq i32 %1561, 2
  %1563 = zext i1 %1562 to i8
  store i8 %1563, i8* %41, align 1, !tbaa !2450
  %1564 = sext i32 %1542 to i64
  store i64 %1564, i64* %RSI, align 8, !tbaa !2428
  %1565 = shl nsw i64 %1564, 3
  %1566 = add i64 %1565, %1539
  %1567 = add i64 %1502, 36
  store i64 %1567, i64* %PC, align 8
  %1568 = inttoptr i64 %1566 to double*
  %1569 = load double, double* %1568, align 8
  %1570 = fsub double %1537, %1569
  store double %1570, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1571 = load i64, i64* %RBP, align 8
  %1572 = add i64 %1571, -152
  %1573 = add i64 %1502, 44
  store i64 %1573, i64* %PC, align 8
  %1574 = inttoptr i64 %1572 to double*
  store double %1570, double* %1574, align 8
  %1575 = load i64, i64* %RBP, align 8
  %1576 = add i64 %1575, -96
  %1577 = load i64, i64* %PC, align 8
  %1578 = add i64 %1577, 5
  store i64 %1578, i64* %PC, align 8
  %1579 = inttoptr i64 %1576 to double*
  %1580 = load double, double* %1579, align 8
  store double %1580, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1581 = add i64 %1575, -128
  %1582 = add i64 %1577, 10
  store i64 %1582, i64* %PC, align 8
  %1583 = inttoptr i64 %1581 to double*
  %1584 = load double, double* %1583, align 8
  %1585 = fadd double %1580, %1584
  store double %1585, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1586 = add i64 %1575, -16
  %1587 = add i64 %1577, 14
  store i64 %1587, i64* %PC, align 8
  %1588 = inttoptr i64 %1586 to i64*
  %1589 = load i64, i64* %1588, align 8
  store i64 %1589, i64* %RDX, align 8, !tbaa !2428
  %1590 = add i64 %1575, -28
  %1591 = add i64 %1577, 18
  store i64 %1591, i64* %PC, align 8
  %1592 = inttoptr i64 %1590 to i32*
  %1593 = load i32, i32* %1592, align 4
  %1594 = sext i32 %1593 to i64
  store i64 %1594, i64* %RSI, align 8, !tbaa !2428
  %1595 = shl nsw i64 %1594, 3
  %1596 = add i64 %1595, %1589
  %1597 = add i64 %1577, 23
  store i64 %1597, i64* %PC, align 8
  %1598 = inttoptr i64 %1596 to double*
  store double %1585, double* %1598, align 8
  %1599 = load i64, i64* %RBP, align 8
  %1600 = add i64 %1599, -104
  %1601 = load i64, i64* %PC, align 8
  %1602 = add i64 %1601, 5
  store i64 %1602, i64* %PC, align 8
  %1603 = inttoptr i64 %1600 to double*
  %1604 = load double, double* %1603, align 8
  store double %1604, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1605 = add i64 %1599, -136
  %1606 = add i64 %1601, 13
  store i64 %1606, i64* %PC, align 8
  %1607 = inttoptr i64 %1605 to double*
  %1608 = load double, double* %1607, align 8
  %1609 = fadd double %1604, %1608
  store double %1609, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1610 = add i64 %1599, -16
  %1611 = add i64 %1601, 17
  store i64 %1611, i64* %PC, align 8
  %1612 = inttoptr i64 %1610 to i64*
  %1613 = load i64, i64* %1612, align 8
  store i64 %1613, i64* %RDX, align 8, !tbaa !2428
  %1614 = add i64 %1599, -28
  %1615 = add i64 %1601, 20
  store i64 %1615, i64* %PC, align 8
  %1616 = inttoptr i64 %1614 to i32*
  %1617 = load i32, i32* %1616, align 4
  %1618 = add i32 %1617, 1
  %1619 = zext i32 %1618 to i64
  store i64 %1619, i64* %RCX, align 8, !tbaa !2428
  %1620 = icmp eq i32 %1617, -1
  %1621 = icmp eq i32 %1618, 0
  %1622 = or i1 %1620, %1621
  %1623 = zext i1 %1622 to i8
  store i8 %1623, i8* %16, align 1, !tbaa !2433
  %1624 = and i32 %1618, 255
  %1625 = tail call i32 @llvm.ctpop.i32(i32 %1624) #10
  %1626 = trunc i32 %1625 to i8
  %1627 = and i8 %1626, 1
  %1628 = xor i8 %1627, 1
  store i8 %1628, i8* %23, align 1, !tbaa !2447
  %1629 = xor i32 %1617, %1618
  %1630 = lshr i32 %1629, 4
  %1631 = trunc i32 %1630 to i8
  %1632 = and i8 %1631, 1
  store i8 %1632, i8* %29, align 1, !tbaa !2451
  %1633 = zext i1 %1621 to i8
  store i8 %1633, i8* %32, align 1, !tbaa !2448
  %1634 = lshr i32 %1618, 31
  %1635 = trunc i32 %1634 to i8
  store i8 %1635, i8* %35, align 1, !tbaa !2449
  %1636 = lshr i32 %1617, 31
  %1637 = xor i32 %1634, %1636
  %1638 = add nuw nsw i32 %1637, %1634
  %1639 = icmp eq i32 %1638, 2
  %1640 = zext i1 %1639 to i8
  store i8 %1640, i8* %41, align 1, !tbaa !2450
  %1641 = sext i32 %1618 to i64
  store i64 %1641, i64* %RSI, align 8, !tbaa !2428
  %1642 = shl nsw i64 %1641, 3
  %1643 = add i64 %1642, %1613
  %1644 = add i64 %1601, 31
  store i64 %1644, i64* %PC, align 8
  %1645 = inttoptr i64 %1643 to double*
  store double %1609, double* %1645, align 8
  %1646 = load i64, i64* %RBP, align 8
  %1647 = add i64 %1646, -128
  %1648 = load i64, i64* %PC, align 8
  %1649 = add i64 %1648, 5
  store i64 %1649, i64* %PC, align 8
  %1650 = inttoptr i64 %1647 to double*
  %1651 = load double, double* %1650, align 8
  store double %1651, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1652 = add i64 %1646, -96
  %1653 = add i64 %1648, 10
  store i64 %1653, i64* %PC, align 8
  %1654 = inttoptr i64 %1652 to double*
  %1655 = load double, double* %1654, align 8
  %1656 = fsub double %1655, %1651
  store double %1656, double* %780, align 1, !tbaa !2452
  store i64 0, i64* %776, align 1, !tbaa !2452
  %1657 = add i64 %1648, 19
  store i64 %1657, i64* %PC, align 8
  store double %1656, double* %1654, align 8
  %1658 = load i64, i64* %RBP, align 8
  %1659 = add i64 %1658, -136
  %1660 = load i64, i64* %PC, align 8
  %1661 = add i64 %1660, 8
  store i64 %1661, i64* %PC, align 8
  %1662 = inttoptr i64 %1659 to double*
  %1663 = load double, double* %1662, align 8
  store double %1663, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1664 = add i64 %1658, -104
  %1665 = add i64 %1660, 13
  store i64 %1665, i64* %PC, align 8
  %1666 = inttoptr i64 %1664 to double*
  %1667 = load double, double* %1666, align 8
  %1668 = fsub double %1667, %1663
  store double %1668, double* %780, align 1, !tbaa !2452
  store i64 0, i64* %776, align 1, !tbaa !2452
  %1669 = add i64 %1660, 22
  store i64 %1669, i64* %PC, align 8
  store double %1668, double* %1666, align 8
  %1670 = load i64, i64* %RBP, align 8
  %1671 = add i64 %1670, -64
  %1672 = load i64, i64* %PC, align 8
  %1673 = add i64 %1672, 5
  store i64 %1673, i64* %PC, align 8
  %1674 = inttoptr i64 %1671 to double*
  %1675 = load double, double* %1674, align 8
  store double %1675, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1676 = add i64 %1670, -96
  %1677 = add i64 %1672, 10
  store i64 %1677, i64* %PC, align 8
  %1678 = inttoptr i64 %1676 to double*
  %1679 = load double, double* %1678, align 8
  %1680 = fmul double %1675, %1679
  store double %1680, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1681 = add i64 %1670, -72
  %1682 = add i64 %1672, 15
  store i64 %1682, i64* %PC, align 8
  %1683 = inttoptr i64 %1681 to double*
  %1684 = load double, double* %1683, align 8
  store double %1684, double* %780, align 1, !tbaa !2452
  store double 0.000000e+00, double* %787, align 1, !tbaa !2452
  %1685 = add i64 %1670, -104
  %1686 = add i64 %1672, 20
  store i64 %1686, i64* %PC, align 8
  %1687 = inttoptr i64 %1685 to double*
  %1688 = load double, double* %1687, align 8
  %1689 = fmul double %1684, %1688
  store double %1689, double* %780, align 1, !tbaa !2452
  store i64 0, i64* %776, align 1, !tbaa !2452
  %1690 = fsub double %1680, %1689
  store double %1690, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1691 = add i64 %1670, -16
  %1692 = add i64 %1672, 28
  store i64 %1692, i64* %PC, align 8
  %1693 = inttoptr i64 %1691 to i64*
  %1694 = load i64, i64* %1693, align 8
  store i64 %1694, i64* %RDX, align 8, !tbaa !2428
  %1695 = add i64 %1670, -28
  %1696 = add i64 %1672, 31
  store i64 %1696, i64* %PC, align 8
  %1697 = inttoptr i64 %1695 to i32*
  %1698 = load i32, i32* %1697, align 4
  %1699 = add i32 %1698, 4
  %1700 = zext i32 %1699 to i64
  store i64 %1700, i64* %RCX, align 8, !tbaa !2428
  %1701 = icmp ugt i32 %1698, -5
  %1702 = zext i1 %1701 to i8
  store i8 %1702, i8* %16, align 1, !tbaa !2433
  %1703 = and i32 %1699, 255
  %1704 = tail call i32 @llvm.ctpop.i32(i32 %1703) #10
  %1705 = trunc i32 %1704 to i8
  %1706 = and i8 %1705, 1
  %1707 = xor i8 %1706, 1
  store i8 %1707, i8* %23, align 1, !tbaa !2447
  %1708 = xor i32 %1698, %1699
  %1709 = lshr i32 %1708, 4
  %1710 = trunc i32 %1709 to i8
  %1711 = and i8 %1710, 1
  store i8 %1711, i8* %29, align 1, !tbaa !2451
  %1712 = icmp eq i32 %1699, 0
  %1713 = zext i1 %1712 to i8
  store i8 %1713, i8* %32, align 1, !tbaa !2448
  %1714 = lshr i32 %1699, 31
  %1715 = trunc i32 %1714 to i8
  store i8 %1715, i8* %35, align 1, !tbaa !2449
  %1716 = lshr i32 %1698, 31
  %1717 = xor i32 %1714, %1716
  %1718 = add nuw nsw i32 %1717, %1714
  %1719 = icmp eq i32 %1718, 2
  %1720 = zext i1 %1719 to i8
  store i8 %1720, i8* %41, align 1, !tbaa !2450
  %1721 = sext i32 %1699 to i64
  store i64 %1721, i64* %RSI, align 8, !tbaa !2428
  %1722 = shl nsw i64 %1721, 3
  %1723 = add i64 %1722, %1694
  %1724 = add i64 %1672, 42
  store i64 %1724, i64* %PC, align 8
  %1725 = inttoptr i64 %1723 to double*
  store double %1690, double* %1725, align 8
  %1726 = load i64, i64* %RBP, align 8
  %1727 = add i64 %1726, -64
  %1728 = load i64, i64* %PC, align 8
  %1729 = add i64 %1728, 5
  store i64 %1729, i64* %PC, align 8
  %1730 = inttoptr i64 %1727 to double*
  %1731 = load double, double* %1730, align 8
  store double %1731, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1732 = add i64 %1726, -104
  %1733 = add i64 %1728, 10
  store i64 %1733, i64* %PC, align 8
  %1734 = inttoptr i64 %1732 to double*
  %1735 = load double, double* %1734, align 8
  %1736 = fmul double %1731, %1735
  store double %1736, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1737 = add i64 %1726, -72
  %1738 = add i64 %1728, 15
  store i64 %1738, i64* %PC, align 8
  %1739 = inttoptr i64 %1737 to double*
  %1740 = load double, double* %1739, align 8
  store double %1740, double* %780, align 1, !tbaa !2452
  store double 0.000000e+00, double* %787, align 1, !tbaa !2452
  %1741 = add i64 %1726, -96
  %1742 = add i64 %1728, 20
  store i64 %1742, i64* %PC, align 8
  %1743 = inttoptr i64 %1741 to double*
  %1744 = load double, double* %1743, align 8
  %1745 = fmul double %1740, %1744
  store double %1745, double* %780, align 1, !tbaa !2452
  store i64 0, i64* %776, align 1, !tbaa !2452
  %1746 = fadd double %1736, %1745
  store double %1746, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1747 = add i64 %1726, -16
  %1748 = add i64 %1728, 28
  store i64 %1748, i64* %PC, align 8
  %1749 = inttoptr i64 %1747 to i64*
  %1750 = load i64, i64* %1749, align 8
  store i64 %1750, i64* %RDX, align 8, !tbaa !2428
  %1751 = add i64 %1726, -28
  %1752 = add i64 %1728, 31
  store i64 %1752, i64* %PC, align 8
  %1753 = inttoptr i64 %1751 to i32*
  %1754 = load i32, i32* %1753, align 4
  %1755 = add i32 %1754, 5
  %1756 = zext i32 %1755 to i64
  store i64 %1756, i64* %RCX, align 8, !tbaa !2428
  %1757 = icmp ugt i32 %1754, -6
  %1758 = zext i1 %1757 to i8
  store i8 %1758, i8* %16, align 1, !tbaa !2433
  %1759 = and i32 %1755, 255
  %1760 = tail call i32 @llvm.ctpop.i32(i32 %1759) #10
  %1761 = trunc i32 %1760 to i8
  %1762 = and i8 %1761, 1
  %1763 = xor i8 %1762, 1
  store i8 %1763, i8* %23, align 1, !tbaa !2447
  %1764 = xor i32 %1754, %1755
  %1765 = lshr i32 %1764, 4
  %1766 = trunc i32 %1765 to i8
  %1767 = and i8 %1766, 1
  store i8 %1767, i8* %29, align 1, !tbaa !2451
  %1768 = icmp eq i32 %1755, 0
  %1769 = zext i1 %1768 to i8
  store i8 %1769, i8* %32, align 1, !tbaa !2448
  %1770 = lshr i32 %1755, 31
  %1771 = trunc i32 %1770 to i8
  store i8 %1771, i8* %35, align 1, !tbaa !2449
  %1772 = lshr i32 %1754, 31
  %1773 = xor i32 %1770, %1772
  %1774 = add nuw nsw i32 %1773, %1770
  %1775 = icmp eq i32 %1774, 2
  %1776 = zext i1 %1775 to i8
  store i8 %1776, i8* %41, align 1, !tbaa !2450
  %1777 = sext i32 %1755 to i64
  store i64 %1777, i64* %RSI, align 8, !tbaa !2428
  %1778 = shl nsw i64 %1777, 3
  %1779 = add i64 %1778, %1750
  %1780 = add i64 %1728, 42
  store i64 %1780, i64* %PC, align 8
  %1781 = inttoptr i64 %1779 to double*
  store double %1746, double* %1781, align 8
  %1782 = load i64, i64* %RBP, align 8
  %1783 = add i64 %1782, -112
  %1784 = load i64, i64* %PC, align 8
  %1785 = add i64 %1784, 5
  store i64 %1785, i64* %PC, align 8
  %1786 = inttoptr i64 %1783 to double*
  %1787 = load double, double* %1786, align 8
  store double %1787, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1788 = add i64 %1782, -152
  %1789 = add i64 %1784, 13
  store i64 %1789, i64* %PC, align 8
  %1790 = inttoptr i64 %1788 to double*
  %1791 = load double, double* %1790, align 8
  %1792 = fsub double %1787, %1791
  store double %1792, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1793 = add i64 %1782, -96
  %1794 = add i64 %1784, 18
  store i64 %1794, i64* %PC, align 8
  %1795 = inttoptr i64 %1793 to double*
  store double %1792, double* %1795, align 8
  %1796 = load i64, i64* %RBP, align 8
  %1797 = add i64 %1796, -120
  %1798 = load i64, i64* %PC, align 8
  %1799 = add i64 %1798, 5
  store i64 %1799, i64* %PC, align 8
  %1800 = inttoptr i64 %1797 to double*
  %1801 = load double, double* %1800, align 8
  store double %1801, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1802 = add i64 %1796, -144
  %1803 = add i64 %1798, 13
  store i64 %1803, i64* %PC, align 8
  %1804 = inttoptr i64 %1802 to double*
  %1805 = load double, double* %1804, align 8
  %1806 = fadd double %1801, %1805
  store double %1806, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1807 = add i64 %1796, -104
  %1808 = add i64 %1798, 18
  store i64 %1808, i64* %PC, align 8
  %1809 = inttoptr i64 %1807 to double*
  store double %1806, double* %1809, align 8
  %1810 = load i64, i64* %RBP, align 8
  %1811 = add i64 %1810, -48
  %1812 = load i64, i64* %PC, align 8
  %1813 = add i64 %1812, 5
  store i64 %1813, i64* %PC, align 8
  %1814 = inttoptr i64 %1811 to double*
  %1815 = load double, double* %1814, align 8
  store double %1815, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1816 = add i64 %1810, -96
  %1817 = add i64 %1812, 10
  store i64 %1817, i64* %PC, align 8
  %1818 = inttoptr i64 %1816 to double*
  %1819 = load double, double* %1818, align 8
  %1820 = fmul double %1815, %1819
  store double %1820, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1821 = add i64 %1810, -56
  %1822 = add i64 %1812, 15
  store i64 %1822, i64* %PC, align 8
  %1823 = inttoptr i64 %1821 to double*
  %1824 = load double, double* %1823, align 8
  store double %1824, double* %780, align 1, !tbaa !2452
  store double 0.000000e+00, double* %787, align 1, !tbaa !2452
  %1825 = add i64 %1810, -104
  %1826 = add i64 %1812, 20
  store i64 %1826, i64* %PC, align 8
  %1827 = inttoptr i64 %1825 to double*
  %1828 = load double, double* %1827, align 8
  %1829 = fmul double %1824, %1828
  store double %1829, double* %780, align 1, !tbaa !2452
  store i64 0, i64* %776, align 1, !tbaa !2452
  %1830 = fsub double %1820, %1829
  store double %1830, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1831 = add i64 %1810, -16
  %1832 = add i64 %1812, 28
  store i64 %1832, i64* %PC, align 8
  %1833 = inttoptr i64 %1831 to i64*
  %1834 = load i64, i64* %1833, align 8
  store i64 %1834, i64* %RDX, align 8, !tbaa !2428
  %1835 = add i64 %1810, -28
  %1836 = add i64 %1812, 31
  store i64 %1836, i64* %PC, align 8
  %1837 = inttoptr i64 %1835 to i32*
  %1838 = load i32, i32* %1837, align 4
  %1839 = add i32 %1838, 2
  %1840 = zext i32 %1839 to i64
  store i64 %1840, i64* %RCX, align 8, !tbaa !2428
  %1841 = icmp ugt i32 %1838, -3
  %1842 = zext i1 %1841 to i8
  store i8 %1842, i8* %16, align 1, !tbaa !2433
  %1843 = and i32 %1839, 255
  %1844 = tail call i32 @llvm.ctpop.i32(i32 %1843) #10
  %1845 = trunc i32 %1844 to i8
  %1846 = and i8 %1845, 1
  %1847 = xor i8 %1846, 1
  store i8 %1847, i8* %23, align 1, !tbaa !2447
  %1848 = xor i32 %1838, %1839
  %1849 = lshr i32 %1848, 4
  %1850 = trunc i32 %1849 to i8
  %1851 = and i8 %1850, 1
  store i8 %1851, i8* %29, align 1, !tbaa !2451
  %1852 = icmp eq i32 %1839, 0
  %1853 = zext i1 %1852 to i8
  store i8 %1853, i8* %32, align 1, !tbaa !2448
  %1854 = lshr i32 %1839, 31
  %1855 = trunc i32 %1854 to i8
  store i8 %1855, i8* %35, align 1, !tbaa !2449
  %1856 = lshr i32 %1838, 31
  %1857 = xor i32 %1854, %1856
  %1858 = add nuw nsw i32 %1857, %1854
  %1859 = icmp eq i32 %1858, 2
  %1860 = zext i1 %1859 to i8
  store i8 %1860, i8* %41, align 1, !tbaa !2450
  %1861 = sext i32 %1839 to i64
  store i64 %1861, i64* %RSI, align 8, !tbaa !2428
  %1862 = shl nsw i64 %1861, 3
  %1863 = add i64 %1862, %1834
  %1864 = add i64 %1812, 42
  store i64 %1864, i64* %PC, align 8
  %1865 = inttoptr i64 %1863 to double*
  store double %1830, double* %1865, align 8
  %1866 = load i64, i64* %RBP, align 8
  %1867 = add i64 %1866, -48
  %1868 = load i64, i64* %PC, align 8
  %1869 = add i64 %1868, 5
  store i64 %1869, i64* %PC, align 8
  %1870 = inttoptr i64 %1867 to double*
  %1871 = load double, double* %1870, align 8
  store double %1871, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1872 = add i64 %1866, -104
  %1873 = add i64 %1868, 10
  store i64 %1873, i64* %PC, align 8
  %1874 = inttoptr i64 %1872 to double*
  %1875 = load double, double* %1874, align 8
  %1876 = fmul double %1871, %1875
  store double %1876, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1877 = add i64 %1866, -56
  %1878 = add i64 %1868, 15
  store i64 %1878, i64* %PC, align 8
  %1879 = inttoptr i64 %1877 to double*
  %1880 = load double, double* %1879, align 8
  store double %1880, double* %780, align 1, !tbaa !2452
  store double 0.000000e+00, double* %787, align 1, !tbaa !2452
  %1881 = add i64 %1866, -96
  %1882 = add i64 %1868, 20
  store i64 %1882, i64* %PC, align 8
  %1883 = inttoptr i64 %1881 to double*
  %1884 = load double, double* %1883, align 8
  %1885 = fmul double %1880, %1884
  store double %1885, double* %780, align 1, !tbaa !2452
  store i64 0, i64* %776, align 1, !tbaa !2452
  %1886 = fadd double %1876, %1885
  store double %1886, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1887 = add i64 %1866, -16
  %1888 = add i64 %1868, 28
  store i64 %1888, i64* %PC, align 8
  %1889 = inttoptr i64 %1887 to i64*
  %1890 = load i64, i64* %1889, align 8
  store i64 %1890, i64* %RDX, align 8, !tbaa !2428
  %1891 = add i64 %1866, -28
  %1892 = add i64 %1868, 31
  store i64 %1892, i64* %PC, align 8
  %1893 = inttoptr i64 %1891 to i32*
  %1894 = load i32, i32* %1893, align 4
  %1895 = add i32 %1894, 3
  %1896 = zext i32 %1895 to i64
  store i64 %1896, i64* %RCX, align 8, !tbaa !2428
  %1897 = icmp ugt i32 %1894, -4
  %1898 = zext i1 %1897 to i8
  store i8 %1898, i8* %16, align 1, !tbaa !2433
  %1899 = and i32 %1895, 255
  %1900 = tail call i32 @llvm.ctpop.i32(i32 %1899) #10
  %1901 = trunc i32 %1900 to i8
  %1902 = and i8 %1901, 1
  %1903 = xor i8 %1902, 1
  store i8 %1903, i8* %23, align 1, !tbaa !2447
  %1904 = xor i32 %1894, %1895
  %1905 = lshr i32 %1904, 4
  %1906 = trunc i32 %1905 to i8
  %1907 = and i8 %1906, 1
  store i8 %1907, i8* %29, align 1, !tbaa !2451
  %1908 = icmp eq i32 %1895, 0
  %1909 = zext i1 %1908 to i8
  store i8 %1909, i8* %32, align 1, !tbaa !2448
  %1910 = lshr i32 %1895, 31
  %1911 = trunc i32 %1910 to i8
  store i8 %1911, i8* %35, align 1, !tbaa !2449
  %1912 = lshr i32 %1894, 31
  %1913 = xor i32 %1910, %1912
  %1914 = add nuw nsw i32 %1913, %1910
  %1915 = icmp eq i32 %1914, 2
  %1916 = zext i1 %1915 to i8
  store i8 %1916, i8* %41, align 1, !tbaa !2450
  %1917 = sext i32 %1895 to i64
  store i64 %1917, i64* %RSI, align 8, !tbaa !2428
  %1918 = shl nsw i64 %1917, 3
  %1919 = add i64 %1918, %1890
  %1920 = add i64 %1868, 42
  store i64 %1920, i64* %PC, align 8
  %1921 = inttoptr i64 %1919 to double*
  store double %1886, double* %1921, align 8
  %1922 = load i64, i64* %RBP, align 8
  %1923 = add i64 %1922, -112
  %1924 = load i64, i64* %PC, align 8
  %1925 = add i64 %1924, 5
  store i64 %1925, i64* %PC, align 8
  %1926 = inttoptr i64 %1923 to double*
  %1927 = load double, double* %1926, align 8
  store double %1927, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1928 = add i64 %1922, -152
  %1929 = add i64 %1924, 13
  store i64 %1929, i64* %PC, align 8
  %1930 = inttoptr i64 %1928 to double*
  %1931 = load double, double* %1930, align 8
  %1932 = fadd double %1927, %1931
  store double %1932, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1933 = add i64 %1922, -96
  %1934 = add i64 %1924, 18
  store i64 %1934, i64* %PC, align 8
  %1935 = inttoptr i64 %1933 to double*
  store double %1932, double* %1935, align 8
  %1936 = load i64, i64* %RBP, align 8
  %1937 = add i64 %1936, -120
  %1938 = load i64, i64* %PC, align 8
  %1939 = add i64 %1938, 5
  store i64 %1939, i64* %PC, align 8
  %1940 = inttoptr i64 %1937 to double*
  %1941 = load double, double* %1940, align 8
  store double %1941, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1942 = add i64 %1936, -144
  %1943 = add i64 %1938, 13
  store i64 %1943, i64* %PC, align 8
  %1944 = inttoptr i64 %1942 to double*
  %1945 = load double, double* %1944, align 8
  %1946 = fsub double %1941, %1945
  store double %1946, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1947 = add i64 %1936, -104
  %1948 = add i64 %1938, 18
  store i64 %1948, i64* %PC, align 8
  %1949 = inttoptr i64 %1947 to double*
  store double %1946, double* %1949, align 8
  %1950 = load i64, i64* %RBP, align 8
  %1951 = add i64 %1950, -80
  %1952 = load i64, i64* %PC, align 8
  %1953 = add i64 %1952, 5
  store i64 %1953, i64* %PC, align 8
  %1954 = inttoptr i64 %1951 to double*
  %1955 = load double, double* %1954, align 8
  store double %1955, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %1956 = add i64 %1950, -96
  %1957 = add i64 %1952, 10
  store i64 %1957, i64* %PC, align 8
  %1958 = inttoptr i64 %1956 to double*
  %1959 = load double, double* %1958, align 8
  %1960 = fmul double %1955, %1959
  store double %1960, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1961 = add i64 %1950, -88
  %1962 = add i64 %1952, 15
  store i64 %1962, i64* %PC, align 8
  %1963 = inttoptr i64 %1961 to double*
  %1964 = load double, double* %1963, align 8
  store double %1964, double* %780, align 1, !tbaa !2452
  store double 0.000000e+00, double* %787, align 1, !tbaa !2452
  %1965 = add i64 %1950, -104
  %1966 = add i64 %1952, 20
  store i64 %1966, i64* %PC, align 8
  %1967 = inttoptr i64 %1965 to double*
  %1968 = load double, double* %1967, align 8
  %1969 = fmul double %1964, %1968
  store double %1969, double* %780, align 1, !tbaa !2452
  store i64 0, i64* %776, align 1, !tbaa !2452
  %1970 = fsub double %1960, %1969
  store double %1970, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %1971 = add i64 %1950, -16
  %1972 = add i64 %1952, 28
  store i64 %1972, i64* %PC, align 8
  %1973 = inttoptr i64 %1971 to i64*
  %1974 = load i64, i64* %1973, align 8
  store i64 %1974, i64* %RDX, align 8, !tbaa !2428
  %1975 = add i64 %1950, -28
  %1976 = add i64 %1952, 31
  store i64 %1976, i64* %PC, align 8
  %1977 = inttoptr i64 %1975 to i32*
  %1978 = load i32, i32* %1977, align 4
  %1979 = add i32 %1978, 6
  %1980 = zext i32 %1979 to i64
  store i64 %1980, i64* %RCX, align 8, !tbaa !2428
  %1981 = icmp ugt i32 %1978, -7
  %1982 = zext i1 %1981 to i8
  store i8 %1982, i8* %16, align 1, !tbaa !2433
  %1983 = and i32 %1979, 255
  %1984 = tail call i32 @llvm.ctpop.i32(i32 %1983) #10
  %1985 = trunc i32 %1984 to i8
  %1986 = and i8 %1985, 1
  %1987 = xor i8 %1986, 1
  store i8 %1987, i8* %23, align 1, !tbaa !2447
  %1988 = xor i32 %1978, %1979
  %1989 = lshr i32 %1988, 4
  %1990 = trunc i32 %1989 to i8
  %1991 = and i8 %1990, 1
  store i8 %1991, i8* %29, align 1, !tbaa !2451
  %1992 = icmp eq i32 %1979, 0
  %1993 = zext i1 %1992 to i8
  store i8 %1993, i8* %32, align 1, !tbaa !2448
  %1994 = lshr i32 %1979, 31
  %1995 = trunc i32 %1994 to i8
  store i8 %1995, i8* %35, align 1, !tbaa !2449
  %1996 = lshr i32 %1978, 31
  %1997 = xor i32 %1994, %1996
  %1998 = add nuw nsw i32 %1997, %1994
  %1999 = icmp eq i32 %1998, 2
  %2000 = zext i1 %1999 to i8
  store i8 %2000, i8* %41, align 1, !tbaa !2450
  %2001 = sext i32 %1979 to i64
  store i64 %2001, i64* %RSI, align 8, !tbaa !2428
  %2002 = shl nsw i64 %2001, 3
  %2003 = add i64 %2002, %1974
  %2004 = add i64 %1952, 42
  store i64 %2004, i64* %PC, align 8
  %2005 = inttoptr i64 %2003 to double*
  store double %1970, double* %2005, align 8
  %2006 = load i64, i64* %RBP, align 8
  %2007 = add i64 %2006, -80
  %2008 = load i64, i64* %PC, align 8
  %2009 = add i64 %2008, 5
  store i64 %2009, i64* %PC, align 8
  %2010 = inttoptr i64 %2007 to double*
  %2011 = load double, double* %2010, align 8
  store double %2011, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %2012 = add i64 %2006, -104
  %2013 = add i64 %2008, 10
  store i64 %2013, i64* %PC, align 8
  %2014 = inttoptr i64 %2012 to double*
  %2015 = load double, double* %2014, align 8
  %2016 = fmul double %2011, %2015
  store double %2016, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %2017 = add i64 %2006, -88
  %2018 = add i64 %2008, 15
  store i64 %2018, i64* %PC, align 8
  %2019 = inttoptr i64 %2017 to double*
  %2020 = load double, double* %2019, align 8
  store double %2020, double* %780, align 1, !tbaa !2452
  store double 0.000000e+00, double* %787, align 1, !tbaa !2452
  %2021 = add i64 %2006, -96
  %2022 = add i64 %2008, 20
  store i64 %2022, i64* %PC, align 8
  %2023 = inttoptr i64 %2021 to double*
  %2024 = load double, double* %2023, align 8
  %2025 = fmul double %2020, %2024
  store double %2025, double* %780, align 1, !tbaa !2452
  store i64 0, i64* %776, align 1, !tbaa !2452
  %2026 = fadd double %2016, %2025
  store double %2026, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %2027 = add i64 %2006, -16
  %2028 = add i64 %2008, 28
  store i64 %2028, i64* %PC, align 8
  %2029 = inttoptr i64 %2027 to i64*
  %2030 = load i64, i64* %2029, align 8
  store i64 %2030, i64* %RDX, align 8, !tbaa !2428
  %2031 = add i64 %2006, -28
  %2032 = add i64 %2008, 31
  store i64 %2032, i64* %PC, align 8
  %2033 = inttoptr i64 %2031 to i32*
  %2034 = load i32, i32* %2033, align 4
  %2035 = add i32 %2034, 7
  %2036 = zext i32 %2035 to i64
  store i64 %2036, i64* %RCX, align 8, !tbaa !2428
  %2037 = icmp ugt i32 %2034, -8
  %2038 = zext i1 %2037 to i8
  store i8 %2038, i8* %16, align 1, !tbaa !2433
  %2039 = and i32 %2035, 255
  %2040 = tail call i32 @llvm.ctpop.i32(i32 %2039) #10
  %2041 = trunc i32 %2040 to i8
  %2042 = and i8 %2041, 1
  %2043 = xor i8 %2042, 1
  store i8 %2043, i8* %23, align 1, !tbaa !2447
  %2044 = xor i32 %2034, %2035
  %2045 = lshr i32 %2044, 4
  %2046 = trunc i32 %2045 to i8
  %2047 = and i8 %2046, 1
  store i8 %2047, i8* %29, align 1, !tbaa !2451
  %2048 = icmp eq i32 %2035, 0
  %2049 = zext i1 %2048 to i8
  store i8 %2049, i8* %32, align 1, !tbaa !2448
  %2050 = lshr i32 %2035, 31
  %2051 = trunc i32 %2050 to i8
  store i8 %2051, i8* %35, align 1, !tbaa !2449
  %2052 = lshr i32 %2034, 31
  %2053 = xor i32 %2050, %2052
  %2054 = add nuw nsw i32 %2053, %2050
  %2055 = icmp eq i32 %2054, 2
  %2056 = zext i1 %2055 to i8
  store i8 %2056, i8* %41, align 1, !tbaa !2450
  %2057 = sext i32 %2035 to i64
  store i64 %2057, i64* %RSI, align 8, !tbaa !2428
  %2058 = shl nsw i64 %2057, 3
  %2059 = add i64 %2058, %2030
  %2060 = add i64 %2008, 42
  store i64 %2060, i64* %PC, align 8
  %2061 = inttoptr i64 %2059 to double*
  store double %2026, double* %2061, align 8
  %2062 = load i64, i64* %RBP, align 8
  %2063 = add i64 %2062, -24
  %2064 = load i64, i64* %PC, align 8
  %2065 = add i64 %2064, 4
  store i64 %2065, i64* %PC, align 8
  %2066 = inttoptr i64 %2063 to i64*
  %2067 = load i64, i64* %2066, align 8
  store i64 %2067, i64* %RDX, align 8, !tbaa !2428
  %2068 = add i64 %2062, -36
  %2069 = add i64 %2064, 7
  store i64 %2069, i64* %PC, align 8
  %2070 = inttoptr i64 %2068 to i32*
  %2071 = load i32, i32* %2070, align 4
  %2072 = add i32 %2071, 2
  %2073 = zext i32 %2072 to i64
  store i64 %2073, i64* %RCX, align 8, !tbaa !2428
  %2074 = icmp ugt i32 %2071, -3
  %2075 = zext i1 %2074 to i8
  store i8 %2075, i8* %16, align 1, !tbaa !2433
  %2076 = and i32 %2072, 255
  %2077 = tail call i32 @llvm.ctpop.i32(i32 %2076) #10
  %2078 = trunc i32 %2077 to i8
  %2079 = and i8 %2078, 1
  %2080 = xor i8 %2079, 1
  store i8 %2080, i8* %23, align 1, !tbaa !2447
  %2081 = xor i32 %2071, %2072
  %2082 = lshr i32 %2081, 4
  %2083 = trunc i32 %2082 to i8
  %2084 = and i8 %2083, 1
  store i8 %2084, i8* %29, align 1, !tbaa !2451
  %2085 = icmp eq i32 %2072, 0
  %2086 = zext i1 %2085 to i8
  store i8 %2086, i8* %32, align 1, !tbaa !2448
  %2087 = lshr i32 %2072, 31
  %2088 = trunc i32 %2087 to i8
  store i8 %2088, i8* %35, align 1, !tbaa !2449
  %2089 = lshr i32 %2071, 31
  %2090 = xor i32 %2087, %2089
  %2091 = add nuw nsw i32 %2090, %2087
  %2092 = icmp eq i32 %2091, 2
  %2093 = zext i1 %2092 to i8
  store i8 %2093, i8* %41, align 1, !tbaa !2450
  %2094 = sext i32 %2072 to i64
  store i64 %2094, i64* %RSI, align 8, !tbaa !2428
  %2095 = shl nsw i64 %2094, 3
  %2096 = add i64 %2095, %2067
  %2097 = add i64 %2064, 18
  store i64 %2097, i64* %PC, align 8
  %2098 = inttoptr i64 %2096 to i64*
  %2099 = load i64, i64* %2098, align 8
  store i64 %2099, i64* %858, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %2100 = add i64 %2062, -48
  %2101 = add i64 %2064, 23
  store i64 %2101, i64* %PC, align 8
  %2102 = inttoptr i64 %2100 to i64*
  store i64 %2099, i64* %2102, align 8
  %2103 = load i64, i64* %RBP, align 8
  %2104 = add i64 %2103, -24
  %2105 = load i64, i64* %PC, align 8
  %2106 = add i64 %2105, 4
  store i64 %2106, i64* %PC, align 8
  %2107 = inttoptr i64 %2104 to i64*
  %2108 = load i64, i64* %2107, align 8
  store i64 %2108, i64* %RDX, align 8, !tbaa !2428
  %2109 = add i64 %2103, -36
  %2110 = add i64 %2105, 7
  store i64 %2110, i64* %PC, align 8
  %2111 = inttoptr i64 %2109 to i32*
  %2112 = load i32, i32* %2111, align 4
  %2113 = add i32 %2112, 3
  %2114 = zext i32 %2113 to i64
  store i64 %2114, i64* %RCX, align 8, !tbaa !2428
  %2115 = icmp ugt i32 %2112, -4
  %2116 = zext i1 %2115 to i8
  store i8 %2116, i8* %16, align 1, !tbaa !2433
  %2117 = and i32 %2113, 255
  %2118 = tail call i32 @llvm.ctpop.i32(i32 %2117) #10
  %2119 = trunc i32 %2118 to i8
  %2120 = and i8 %2119, 1
  %2121 = xor i8 %2120, 1
  store i8 %2121, i8* %23, align 1, !tbaa !2447
  %2122 = xor i32 %2112, %2113
  %2123 = lshr i32 %2122, 4
  %2124 = trunc i32 %2123 to i8
  %2125 = and i8 %2124, 1
  store i8 %2125, i8* %29, align 1, !tbaa !2451
  %2126 = icmp eq i32 %2113, 0
  %2127 = zext i1 %2126 to i8
  store i8 %2127, i8* %32, align 1, !tbaa !2448
  %2128 = lshr i32 %2113, 31
  %2129 = trunc i32 %2128 to i8
  store i8 %2129, i8* %35, align 1, !tbaa !2449
  %2130 = lshr i32 %2112, 31
  %2131 = xor i32 %2128, %2130
  %2132 = add nuw nsw i32 %2131, %2128
  %2133 = icmp eq i32 %2132, 2
  %2134 = zext i1 %2133 to i8
  store i8 %2134, i8* %41, align 1, !tbaa !2450
  %2135 = sext i32 %2113 to i64
  store i64 %2135, i64* %RSI, align 8, !tbaa !2428
  %2136 = shl nsw i64 %2135, 3
  %2137 = add i64 %2136, %2108
  %2138 = add i64 %2105, 18
  store i64 %2138, i64* %PC, align 8
  %2139 = inttoptr i64 %2137 to i64*
  %2140 = load i64, i64* %2139, align 8
  store i64 %2140, i64* %858, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %2141 = add i64 %2103, -56
  %2142 = add i64 %2105, 23
  store i64 %2142, i64* %PC, align 8
  %2143 = inttoptr i64 %2141 to i64*
  store i64 %2140, i64* %2143, align 8
  %2144 = load i64, i64* %RBP, align 8
  %2145 = add i64 %2144, -48
  %2146 = load i64, i64* %PC, align 8
  %2147 = add i64 %2146, 5
  store i64 %2147, i64* %PC, align 8
  %2148 = inttoptr i64 %2145 to double*
  %2149 = load double, double* %2148, align 8
  store double %2149, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %2150 = load <2 x i32>, <2 x i32>* %771, align 1
  %2151 = load <2 x i32>, <2 x i32>* %772, align 1
  %2152 = extractelement <2 x i32> %2150, i32 0
  store i32 %2152, i32* %773, align 1, !tbaa !2475
  %2153 = extractelement <2 x i32> %2150, i32 1
  store i32 %2153, i32* %775, align 1, !tbaa !2475
  %2154 = extractelement <2 x i32> %2151, i32 0
  store i32 %2154, i32* %777, align 1, !tbaa !2475
  %2155 = extractelement <2 x i32> %2151, i32 1
  store i32 %2155, i32* %779, align 1, !tbaa !2475
  %2156 = add i64 %2144, -64
  %2157 = add i64 %2146, 13
  store i64 %2157, i64* %PC, align 8
  %2158 = load double, double* %780, align 1
  %2159 = inttoptr i64 %2156 to double*
  %2160 = load double, double* %2159, align 8
  %2161 = fmul double %2158, %2160
  store double %2161, double* %780, align 1, !tbaa !2452
  %2162 = add i64 %2144, -56
  %2163 = add i64 %2146, 18
  store i64 %2163, i64* %PC, align 8
  %2164 = inttoptr i64 %2162 to double*
  %2165 = load double, double* %2164, align 8
  %2166 = fmul double %2161, %2165
  store double %2166, double* %780, align 1, !tbaa !2452
  %2167 = fsub double %2149, %2166
  store double %2167, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %2168 = add i64 %2144, -80
  %2169 = add i64 %2146, 27
  store i64 %2169, i64* %PC, align 8
  %2170 = inttoptr i64 %2168 to double*
  store double %2167, double* %2170, align 8
  %2171 = load i64, i64* %RBP, align 8
  %2172 = add i64 %2171, -64
  %2173 = load i64, i64* %PC, align 8
  %2174 = add i64 %2173, 5
  store i64 %2174, i64* %PC, align 8
  %2175 = load double, double* %67, align 1
  %2176 = inttoptr i64 %2172 to double*
  %2177 = load double, double* %2176, align 8
  %2178 = fmul double %2175, %2177
  store double %2178, double* %67, align 1, !tbaa !2452
  %2179 = add i64 %2171, -48
  %2180 = add i64 %2173, 10
  store i64 %2180, i64* %PC, align 8
  %2181 = inttoptr i64 %2179 to double*
  %2182 = load double, double* %2181, align 8
  %2183 = fmul double %2178, %2182
  store double %2183, double* %67, align 1, !tbaa !2452
  %2184 = add i64 %2171, -56
  %2185 = add i64 %2173, 15
  store i64 %2185, i64* %PC, align 8
  %2186 = inttoptr i64 %2184 to double*
  %2187 = load double, double* %2186, align 8
  %2188 = fsub double %2183, %2187
  store double %2188, double* %67, align 1, !tbaa !2452
  %2189 = add i64 %2171, -88
  %2190 = add i64 %2173, 20
  store i64 %2190, i64* %PC, align 8
  %2191 = inttoptr i64 %2189 to double*
  store double %2188, double* %2191, align 8
  %2192 = load i64, i64* %RBP, align 8
  %2193 = add i64 %2192, -16
  %2194 = load i64, i64* %PC, align 8
  %2195 = add i64 %2194, 4
  store i64 %2195, i64* %PC, align 8
  %2196 = inttoptr i64 %2193 to i64*
  %2197 = load i64, i64* %2196, align 8
  store i64 %2197, i64* %RDX, align 8, !tbaa !2428
  %2198 = add i64 %2192, -28
  %2199 = add i64 %2194, 7
  store i64 %2199, i64* %PC, align 8
  %2200 = inttoptr i64 %2198 to i32*
  %2201 = load i32, i32* %2200, align 4
  %2202 = add i32 %2201, 8
  %2203 = zext i32 %2202 to i64
  store i64 %2203, i64* %RCX, align 8, !tbaa !2428
  %2204 = icmp ugt i32 %2201, -9
  %2205 = zext i1 %2204 to i8
  store i8 %2205, i8* %16, align 1, !tbaa !2433
  %2206 = and i32 %2202, 255
  %2207 = tail call i32 @llvm.ctpop.i32(i32 %2206) #10
  %2208 = trunc i32 %2207 to i8
  %2209 = and i8 %2208, 1
  %2210 = xor i8 %2209, 1
  store i8 %2210, i8* %23, align 1, !tbaa !2447
  %2211 = xor i32 %2201, %2202
  %2212 = lshr i32 %2211, 4
  %2213 = trunc i32 %2212 to i8
  %2214 = and i8 %2213, 1
  store i8 %2214, i8* %29, align 1, !tbaa !2451
  %2215 = icmp eq i32 %2202, 0
  %2216 = zext i1 %2215 to i8
  store i8 %2216, i8* %32, align 1, !tbaa !2448
  %2217 = lshr i32 %2202, 31
  %2218 = trunc i32 %2217 to i8
  store i8 %2218, i8* %35, align 1, !tbaa !2449
  %2219 = lshr i32 %2201, 31
  %2220 = xor i32 %2217, %2219
  %2221 = add nuw nsw i32 %2220, %2217
  %2222 = icmp eq i32 %2221, 2
  %2223 = zext i1 %2222 to i8
  store i8 %2223, i8* %41, align 1, !tbaa !2450
  %2224 = sext i32 %2202 to i64
  store i64 %2224, i64* %RSI, align 8, !tbaa !2428
  %2225 = shl nsw i64 %2224, 3
  %2226 = add i64 %2225, %2197
  %2227 = add i64 %2194, 18
  store i64 %2227, i64* %PC, align 8
  %2228 = inttoptr i64 %2226 to double*
  %2229 = load double, double* %2228, align 8
  store double %2229, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %2230 = add i64 %2194, 22
  store i64 %2230, i64* %PC, align 8
  %2231 = load i64, i64* %2196, align 8
  store i64 %2231, i64* %RDX, align 8, !tbaa !2428
  %2232 = add i64 %2194, 25
  store i64 %2232, i64* %PC, align 8
  %2233 = load i32, i32* %2200, align 4
  %2234 = add i32 %2233, 10
  %2235 = zext i32 %2234 to i64
  store i64 %2235, i64* %RCX, align 8, !tbaa !2428
  %2236 = icmp ugt i32 %2233, -11
  %2237 = zext i1 %2236 to i8
  store i8 %2237, i8* %16, align 1, !tbaa !2433
  %2238 = and i32 %2234, 255
  %2239 = tail call i32 @llvm.ctpop.i32(i32 %2238) #10
  %2240 = trunc i32 %2239 to i8
  %2241 = and i8 %2240, 1
  %2242 = xor i8 %2241, 1
  store i8 %2242, i8* %23, align 1, !tbaa !2447
  %2243 = xor i32 %2233, %2234
  %2244 = lshr i32 %2243, 4
  %2245 = trunc i32 %2244 to i8
  %2246 = and i8 %2245, 1
  store i8 %2246, i8* %29, align 1, !tbaa !2451
  %2247 = icmp eq i32 %2234, 0
  %2248 = zext i1 %2247 to i8
  store i8 %2248, i8* %32, align 1, !tbaa !2448
  %2249 = lshr i32 %2234, 31
  %2250 = trunc i32 %2249 to i8
  store i8 %2250, i8* %35, align 1, !tbaa !2449
  %2251 = lshr i32 %2233, 31
  %2252 = xor i32 %2249, %2251
  %2253 = add nuw nsw i32 %2252, %2249
  %2254 = icmp eq i32 %2253, 2
  %2255 = zext i1 %2254 to i8
  store i8 %2255, i8* %41, align 1, !tbaa !2450
  %2256 = sext i32 %2234 to i64
  store i64 %2256, i64* %RSI, align 8, !tbaa !2428
  %2257 = shl nsw i64 %2256, 3
  %2258 = add i64 %2257, %2231
  %2259 = add i64 %2194, 36
  store i64 %2259, i64* %PC, align 8
  %2260 = inttoptr i64 %2258 to double*
  %2261 = load double, double* %2260, align 8
  %2262 = fadd double %2229, %2261
  store double %2262, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %2263 = load i64, i64* %RBP, align 8
  %2264 = add i64 %2263, -96
  %2265 = add i64 %2194, 41
  store i64 %2265, i64* %PC, align 8
  %2266 = inttoptr i64 %2264 to double*
  store double %2262, double* %2266, align 8
  %2267 = load i64, i64* %RBP, align 8
  %2268 = add i64 %2267, -16
  %2269 = load i64, i64* %PC, align 8
  %2270 = add i64 %2269, 4
  store i64 %2270, i64* %PC, align 8
  %2271 = inttoptr i64 %2268 to i64*
  %2272 = load i64, i64* %2271, align 8
  store i64 %2272, i64* %RDX, align 8, !tbaa !2428
  %2273 = add i64 %2267, -28
  %2274 = add i64 %2269, 7
  store i64 %2274, i64* %PC, align 8
  %2275 = inttoptr i64 %2273 to i32*
  %2276 = load i32, i32* %2275, align 4
  %2277 = add i32 %2276, 9
  %2278 = zext i32 %2277 to i64
  store i64 %2278, i64* %RCX, align 8, !tbaa !2428
  %2279 = icmp ugt i32 %2276, -10
  %2280 = zext i1 %2279 to i8
  store i8 %2280, i8* %16, align 1, !tbaa !2433
  %2281 = and i32 %2277, 255
  %2282 = tail call i32 @llvm.ctpop.i32(i32 %2281) #10
  %2283 = trunc i32 %2282 to i8
  %2284 = and i8 %2283, 1
  %2285 = xor i8 %2284, 1
  store i8 %2285, i8* %23, align 1, !tbaa !2447
  %2286 = xor i32 %2276, %2277
  %2287 = lshr i32 %2286, 4
  %2288 = trunc i32 %2287 to i8
  %2289 = and i8 %2288, 1
  store i8 %2289, i8* %29, align 1, !tbaa !2451
  %2290 = icmp eq i32 %2277, 0
  %2291 = zext i1 %2290 to i8
  store i8 %2291, i8* %32, align 1, !tbaa !2448
  %2292 = lshr i32 %2277, 31
  %2293 = trunc i32 %2292 to i8
  store i8 %2293, i8* %35, align 1, !tbaa !2449
  %2294 = lshr i32 %2276, 31
  %2295 = xor i32 %2292, %2294
  %2296 = add nuw nsw i32 %2295, %2292
  %2297 = icmp eq i32 %2296, 2
  %2298 = zext i1 %2297 to i8
  store i8 %2298, i8* %41, align 1, !tbaa !2450
  %2299 = sext i32 %2277 to i64
  store i64 %2299, i64* %RSI, align 8, !tbaa !2428
  %2300 = shl nsw i64 %2299, 3
  %2301 = add i64 %2300, %2272
  %2302 = add i64 %2269, 18
  store i64 %2302, i64* %PC, align 8
  %2303 = inttoptr i64 %2301 to double*
  %2304 = load double, double* %2303, align 8
  store double %2304, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %2305 = add i64 %2269, 22
  store i64 %2305, i64* %PC, align 8
  %2306 = load i64, i64* %2271, align 8
  store i64 %2306, i64* %RDX, align 8, !tbaa !2428
  %2307 = add i64 %2269, 25
  store i64 %2307, i64* %PC, align 8
  %2308 = load i32, i32* %2275, align 4
  %2309 = add i32 %2308, 11
  %2310 = zext i32 %2309 to i64
  store i64 %2310, i64* %RCX, align 8, !tbaa !2428
  %2311 = icmp ugt i32 %2308, -12
  %2312 = zext i1 %2311 to i8
  store i8 %2312, i8* %16, align 1, !tbaa !2433
  %2313 = and i32 %2309, 255
  %2314 = tail call i32 @llvm.ctpop.i32(i32 %2313) #10
  %2315 = trunc i32 %2314 to i8
  %2316 = and i8 %2315, 1
  %2317 = xor i8 %2316, 1
  store i8 %2317, i8* %23, align 1, !tbaa !2447
  %2318 = xor i32 %2308, %2309
  %2319 = lshr i32 %2318, 4
  %2320 = trunc i32 %2319 to i8
  %2321 = and i8 %2320, 1
  store i8 %2321, i8* %29, align 1, !tbaa !2451
  %2322 = icmp eq i32 %2309, 0
  %2323 = zext i1 %2322 to i8
  store i8 %2323, i8* %32, align 1, !tbaa !2448
  %2324 = lshr i32 %2309, 31
  %2325 = trunc i32 %2324 to i8
  store i8 %2325, i8* %35, align 1, !tbaa !2449
  %2326 = lshr i32 %2308, 31
  %2327 = xor i32 %2324, %2326
  %2328 = add nuw nsw i32 %2327, %2324
  %2329 = icmp eq i32 %2328, 2
  %2330 = zext i1 %2329 to i8
  store i8 %2330, i8* %41, align 1, !tbaa !2450
  %2331 = sext i32 %2309 to i64
  store i64 %2331, i64* %RSI, align 8, !tbaa !2428
  %2332 = shl nsw i64 %2331, 3
  %2333 = add i64 %2332, %2306
  %2334 = add i64 %2269, 36
  store i64 %2334, i64* %PC, align 8
  %2335 = inttoptr i64 %2333 to double*
  %2336 = load double, double* %2335, align 8
  %2337 = fadd double %2304, %2336
  store double %2337, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %2338 = load i64, i64* %RBP, align 8
  %2339 = add i64 %2338, -104
  %2340 = add i64 %2269, 41
  store i64 %2340, i64* %PC, align 8
  %2341 = inttoptr i64 %2339 to double*
  store double %2337, double* %2341, align 8
  %2342 = load i64, i64* %RBP, align 8
  %2343 = add i64 %2342, -16
  %2344 = load i64, i64* %PC, align 8
  %2345 = add i64 %2344, 4
  store i64 %2345, i64* %PC, align 8
  %2346 = inttoptr i64 %2343 to i64*
  %2347 = load i64, i64* %2346, align 8
  store i64 %2347, i64* %RDX, align 8, !tbaa !2428
  %2348 = add i64 %2342, -28
  %2349 = add i64 %2344, 7
  store i64 %2349, i64* %PC, align 8
  %2350 = inttoptr i64 %2348 to i32*
  %2351 = load i32, i32* %2350, align 4
  %2352 = add i32 %2351, 8
  %2353 = zext i32 %2352 to i64
  store i64 %2353, i64* %RCX, align 8, !tbaa !2428
  %2354 = icmp ugt i32 %2351, -9
  %2355 = zext i1 %2354 to i8
  store i8 %2355, i8* %16, align 1, !tbaa !2433
  %2356 = and i32 %2352, 255
  %2357 = tail call i32 @llvm.ctpop.i32(i32 %2356) #10
  %2358 = trunc i32 %2357 to i8
  %2359 = and i8 %2358, 1
  %2360 = xor i8 %2359, 1
  store i8 %2360, i8* %23, align 1, !tbaa !2447
  %2361 = xor i32 %2351, %2352
  %2362 = lshr i32 %2361, 4
  %2363 = trunc i32 %2362 to i8
  %2364 = and i8 %2363, 1
  store i8 %2364, i8* %29, align 1, !tbaa !2451
  %2365 = icmp eq i32 %2352, 0
  %2366 = zext i1 %2365 to i8
  store i8 %2366, i8* %32, align 1, !tbaa !2448
  %2367 = lshr i32 %2352, 31
  %2368 = trunc i32 %2367 to i8
  store i8 %2368, i8* %35, align 1, !tbaa !2449
  %2369 = lshr i32 %2351, 31
  %2370 = xor i32 %2367, %2369
  %2371 = add nuw nsw i32 %2370, %2367
  %2372 = icmp eq i32 %2371, 2
  %2373 = zext i1 %2372 to i8
  store i8 %2373, i8* %41, align 1, !tbaa !2450
  %2374 = sext i32 %2352 to i64
  store i64 %2374, i64* %RSI, align 8, !tbaa !2428
  %2375 = shl nsw i64 %2374, 3
  %2376 = add i64 %2375, %2347
  %2377 = add i64 %2344, 18
  store i64 %2377, i64* %PC, align 8
  %2378 = inttoptr i64 %2376 to double*
  %2379 = load double, double* %2378, align 8
  store double %2379, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %2380 = add i64 %2344, 22
  store i64 %2380, i64* %PC, align 8
  %2381 = load i64, i64* %2346, align 8
  store i64 %2381, i64* %RDX, align 8, !tbaa !2428
  %2382 = add i64 %2344, 25
  store i64 %2382, i64* %PC, align 8
  %2383 = load i32, i32* %2350, align 4
  %2384 = add i32 %2383, 10
  %2385 = zext i32 %2384 to i64
  store i64 %2385, i64* %RCX, align 8, !tbaa !2428
  %2386 = icmp ugt i32 %2383, -11
  %2387 = zext i1 %2386 to i8
  store i8 %2387, i8* %16, align 1, !tbaa !2433
  %2388 = and i32 %2384, 255
  %2389 = tail call i32 @llvm.ctpop.i32(i32 %2388) #10
  %2390 = trunc i32 %2389 to i8
  %2391 = and i8 %2390, 1
  %2392 = xor i8 %2391, 1
  store i8 %2392, i8* %23, align 1, !tbaa !2447
  %2393 = xor i32 %2383, %2384
  %2394 = lshr i32 %2393, 4
  %2395 = trunc i32 %2394 to i8
  %2396 = and i8 %2395, 1
  store i8 %2396, i8* %29, align 1, !tbaa !2451
  %2397 = icmp eq i32 %2384, 0
  %2398 = zext i1 %2397 to i8
  store i8 %2398, i8* %32, align 1, !tbaa !2448
  %2399 = lshr i32 %2384, 31
  %2400 = trunc i32 %2399 to i8
  store i8 %2400, i8* %35, align 1, !tbaa !2449
  %2401 = lshr i32 %2383, 31
  %2402 = xor i32 %2399, %2401
  %2403 = add nuw nsw i32 %2402, %2399
  %2404 = icmp eq i32 %2403, 2
  %2405 = zext i1 %2404 to i8
  store i8 %2405, i8* %41, align 1, !tbaa !2450
  %2406 = sext i32 %2384 to i64
  store i64 %2406, i64* %RSI, align 8, !tbaa !2428
  %2407 = shl nsw i64 %2406, 3
  %2408 = add i64 %2407, %2381
  %2409 = add i64 %2344, 36
  store i64 %2409, i64* %PC, align 8
  %2410 = inttoptr i64 %2408 to double*
  %2411 = load double, double* %2410, align 8
  %2412 = fsub double %2379, %2411
  store double %2412, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %2413 = load i64, i64* %RBP, align 8
  %2414 = add i64 %2413, -112
  %2415 = add i64 %2344, 41
  store i64 %2415, i64* %PC, align 8
  %2416 = inttoptr i64 %2414 to double*
  store double %2412, double* %2416, align 8
  %2417 = load i64, i64* %RBP, align 8
  %2418 = add i64 %2417, -16
  %2419 = load i64, i64* %PC, align 8
  %2420 = add i64 %2419, 4
  store i64 %2420, i64* %PC, align 8
  %2421 = inttoptr i64 %2418 to i64*
  %2422 = load i64, i64* %2421, align 8
  store i64 %2422, i64* %RDX, align 8, !tbaa !2428
  %2423 = add i64 %2417, -28
  %2424 = add i64 %2419, 7
  store i64 %2424, i64* %PC, align 8
  %2425 = inttoptr i64 %2423 to i32*
  %2426 = load i32, i32* %2425, align 4
  %2427 = add i32 %2426, 9
  %2428 = zext i32 %2427 to i64
  store i64 %2428, i64* %RCX, align 8, !tbaa !2428
  %2429 = icmp ugt i32 %2426, -10
  %2430 = zext i1 %2429 to i8
  store i8 %2430, i8* %16, align 1, !tbaa !2433
  %2431 = and i32 %2427, 255
  %2432 = tail call i32 @llvm.ctpop.i32(i32 %2431) #10
  %2433 = trunc i32 %2432 to i8
  %2434 = and i8 %2433, 1
  %2435 = xor i8 %2434, 1
  store i8 %2435, i8* %23, align 1, !tbaa !2447
  %2436 = xor i32 %2426, %2427
  %2437 = lshr i32 %2436, 4
  %2438 = trunc i32 %2437 to i8
  %2439 = and i8 %2438, 1
  store i8 %2439, i8* %29, align 1, !tbaa !2451
  %2440 = icmp eq i32 %2427, 0
  %2441 = zext i1 %2440 to i8
  store i8 %2441, i8* %32, align 1, !tbaa !2448
  %2442 = lshr i32 %2427, 31
  %2443 = trunc i32 %2442 to i8
  store i8 %2443, i8* %35, align 1, !tbaa !2449
  %2444 = lshr i32 %2426, 31
  %2445 = xor i32 %2442, %2444
  %2446 = add nuw nsw i32 %2445, %2442
  %2447 = icmp eq i32 %2446, 2
  %2448 = zext i1 %2447 to i8
  store i8 %2448, i8* %41, align 1, !tbaa !2450
  %2449 = sext i32 %2427 to i64
  store i64 %2449, i64* %RSI, align 8, !tbaa !2428
  %2450 = shl nsw i64 %2449, 3
  %2451 = add i64 %2450, %2422
  %2452 = add i64 %2419, 18
  store i64 %2452, i64* %PC, align 8
  %2453 = inttoptr i64 %2451 to double*
  %2454 = load double, double* %2453, align 8
  store double %2454, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %2455 = add i64 %2419, 22
  store i64 %2455, i64* %PC, align 8
  %2456 = load i64, i64* %2421, align 8
  store i64 %2456, i64* %RDX, align 8, !tbaa !2428
  %2457 = add i64 %2419, 25
  store i64 %2457, i64* %PC, align 8
  %2458 = load i32, i32* %2425, align 4
  %2459 = add i32 %2458, 11
  %2460 = zext i32 %2459 to i64
  store i64 %2460, i64* %RCX, align 8, !tbaa !2428
  %2461 = icmp ugt i32 %2458, -12
  %2462 = zext i1 %2461 to i8
  store i8 %2462, i8* %16, align 1, !tbaa !2433
  %2463 = and i32 %2459, 255
  %2464 = tail call i32 @llvm.ctpop.i32(i32 %2463) #10
  %2465 = trunc i32 %2464 to i8
  %2466 = and i8 %2465, 1
  %2467 = xor i8 %2466, 1
  store i8 %2467, i8* %23, align 1, !tbaa !2447
  %2468 = xor i32 %2458, %2459
  %2469 = lshr i32 %2468, 4
  %2470 = trunc i32 %2469 to i8
  %2471 = and i8 %2470, 1
  store i8 %2471, i8* %29, align 1, !tbaa !2451
  %2472 = icmp eq i32 %2459, 0
  %2473 = zext i1 %2472 to i8
  store i8 %2473, i8* %32, align 1, !tbaa !2448
  %2474 = lshr i32 %2459, 31
  %2475 = trunc i32 %2474 to i8
  store i8 %2475, i8* %35, align 1, !tbaa !2449
  %2476 = lshr i32 %2458, 31
  %2477 = xor i32 %2474, %2476
  %2478 = add nuw nsw i32 %2477, %2474
  %2479 = icmp eq i32 %2478, 2
  %2480 = zext i1 %2479 to i8
  store i8 %2480, i8* %41, align 1, !tbaa !2450
  %2481 = sext i32 %2459 to i64
  store i64 %2481, i64* %RSI, align 8, !tbaa !2428
  %2482 = shl nsw i64 %2481, 3
  %2483 = add i64 %2482, %2456
  %2484 = add i64 %2419, 36
  store i64 %2484, i64* %PC, align 8
  %2485 = inttoptr i64 %2483 to double*
  %2486 = load double, double* %2485, align 8
  %2487 = fsub double %2454, %2486
  store double %2487, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %2488 = load i64, i64* %RBP, align 8
  %2489 = add i64 %2488, -120
  %2490 = add i64 %2419, 41
  store i64 %2490, i64* %PC, align 8
  %2491 = inttoptr i64 %2489 to double*
  store double %2487, double* %2491, align 8
  %2492 = load i64, i64* %RBP, align 8
  %2493 = add i64 %2492, -16
  %2494 = load i64, i64* %PC, align 8
  %2495 = add i64 %2494, 4
  store i64 %2495, i64* %PC, align 8
  %2496 = inttoptr i64 %2493 to i64*
  %2497 = load i64, i64* %2496, align 8
  store i64 %2497, i64* %RDX, align 8, !tbaa !2428
  %2498 = add i64 %2492, -28
  %2499 = add i64 %2494, 7
  store i64 %2499, i64* %PC, align 8
  %2500 = inttoptr i64 %2498 to i32*
  %2501 = load i32, i32* %2500, align 4
  %2502 = add i32 %2501, 12
  %2503 = zext i32 %2502 to i64
  store i64 %2503, i64* %RCX, align 8, !tbaa !2428
  %2504 = icmp ugt i32 %2501, -13
  %2505 = zext i1 %2504 to i8
  store i8 %2505, i8* %16, align 1, !tbaa !2433
  %2506 = and i32 %2502, 255
  %2507 = tail call i32 @llvm.ctpop.i32(i32 %2506) #10
  %2508 = trunc i32 %2507 to i8
  %2509 = and i8 %2508, 1
  %2510 = xor i8 %2509, 1
  store i8 %2510, i8* %23, align 1, !tbaa !2447
  %2511 = xor i32 %2501, %2502
  %2512 = lshr i32 %2511, 4
  %2513 = trunc i32 %2512 to i8
  %2514 = and i8 %2513, 1
  store i8 %2514, i8* %29, align 1, !tbaa !2451
  %2515 = icmp eq i32 %2502, 0
  %2516 = zext i1 %2515 to i8
  store i8 %2516, i8* %32, align 1, !tbaa !2448
  %2517 = lshr i32 %2502, 31
  %2518 = trunc i32 %2517 to i8
  store i8 %2518, i8* %35, align 1, !tbaa !2449
  %2519 = lshr i32 %2501, 31
  %2520 = xor i32 %2517, %2519
  %2521 = add nuw nsw i32 %2520, %2517
  %2522 = icmp eq i32 %2521, 2
  %2523 = zext i1 %2522 to i8
  store i8 %2523, i8* %41, align 1, !tbaa !2450
  %2524 = sext i32 %2502 to i64
  store i64 %2524, i64* %RSI, align 8, !tbaa !2428
  %2525 = shl nsw i64 %2524, 3
  %2526 = add i64 %2525, %2497
  %2527 = add i64 %2494, 18
  store i64 %2527, i64* %PC, align 8
  %2528 = inttoptr i64 %2526 to double*
  %2529 = load double, double* %2528, align 8
  store double %2529, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %2530 = add i64 %2494, 22
  store i64 %2530, i64* %PC, align 8
  %2531 = load i64, i64* %2496, align 8
  store i64 %2531, i64* %RDX, align 8, !tbaa !2428
  %2532 = add i64 %2494, 25
  store i64 %2532, i64* %PC, align 8
  %2533 = load i32, i32* %2500, align 4
  %2534 = add i32 %2533, 14
  %2535 = zext i32 %2534 to i64
  store i64 %2535, i64* %RCX, align 8, !tbaa !2428
  %2536 = icmp ugt i32 %2533, -15
  %2537 = zext i1 %2536 to i8
  store i8 %2537, i8* %16, align 1, !tbaa !2433
  %2538 = and i32 %2534, 255
  %2539 = tail call i32 @llvm.ctpop.i32(i32 %2538) #10
  %2540 = trunc i32 %2539 to i8
  %2541 = and i8 %2540, 1
  %2542 = xor i8 %2541, 1
  store i8 %2542, i8* %23, align 1, !tbaa !2447
  %2543 = xor i32 %2533, %2534
  %2544 = lshr i32 %2543, 4
  %2545 = trunc i32 %2544 to i8
  %2546 = and i8 %2545, 1
  store i8 %2546, i8* %29, align 1, !tbaa !2451
  %2547 = icmp eq i32 %2534, 0
  %2548 = zext i1 %2547 to i8
  store i8 %2548, i8* %32, align 1, !tbaa !2448
  %2549 = lshr i32 %2534, 31
  %2550 = trunc i32 %2549 to i8
  store i8 %2550, i8* %35, align 1, !tbaa !2449
  %2551 = lshr i32 %2533, 31
  %2552 = xor i32 %2549, %2551
  %2553 = add nuw nsw i32 %2552, %2549
  %2554 = icmp eq i32 %2553, 2
  %2555 = zext i1 %2554 to i8
  store i8 %2555, i8* %41, align 1, !tbaa !2450
  %2556 = sext i32 %2534 to i64
  store i64 %2556, i64* %RSI, align 8, !tbaa !2428
  %2557 = shl nsw i64 %2556, 3
  %2558 = add i64 %2557, %2531
  %2559 = add i64 %2494, 36
  store i64 %2559, i64* %PC, align 8
  %2560 = inttoptr i64 %2558 to double*
  %2561 = load double, double* %2560, align 8
  %2562 = fadd double %2529, %2561
  store double %2562, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %2563 = load i64, i64* %RBP, align 8
  %2564 = add i64 %2563, -128
  %2565 = add i64 %2494, 41
  store i64 %2565, i64* %PC, align 8
  %2566 = inttoptr i64 %2564 to double*
  store double %2562, double* %2566, align 8
  %2567 = load i64, i64* %RBP, align 8
  %2568 = add i64 %2567, -16
  %2569 = load i64, i64* %PC, align 8
  %2570 = add i64 %2569, 4
  store i64 %2570, i64* %PC, align 8
  %2571 = inttoptr i64 %2568 to i64*
  %2572 = load i64, i64* %2571, align 8
  store i64 %2572, i64* %RDX, align 8, !tbaa !2428
  %2573 = add i64 %2567, -28
  %2574 = add i64 %2569, 7
  store i64 %2574, i64* %PC, align 8
  %2575 = inttoptr i64 %2573 to i32*
  %2576 = load i32, i32* %2575, align 4
  %2577 = add i32 %2576, 13
  %2578 = zext i32 %2577 to i64
  store i64 %2578, i64* %RCX, align 8, !tbaa !2428
  %2579 = icmp ugt i32 %2576, -14
  %2580 = zext i1 %2579 to i8
  store i8 %2580, i8* %16, align 1, !tbaa !2433
  %2581 = and i32 %2577, 255
  %2582 = tail call i32 @llvm.ctpop.i32(i32 %2581) #10
  %2583 = trunc i32 %2582 to i8
  %2584 = and i8 %2583, 1
  %2585 = xor i8 %2584, 1
  store i8 %2585, i8* %23, align 1, !tbaa !2447
  %2586 = xor i32 %2576, %2577
  %2587 = lshr i32 %2586, 4
  %2588 = trunc i32 %2587 to i8
  %2589 = and i8 %2588, 1
  store i8 %2589, i8* %29, align 1, !tbaa !2451
  %2590 = icmp eq i32 %2577, 0
  %2591 = zext i1 %2590 to i8
  store i8 %2591, i8* %32, align 1, !tbaa !2448
  %2592 = lshr i32 %2577, 31
  %2593 = trunc i32 %2592 to i8
  store i8 %2593, i8* %35, align 1, !tbaa !2449
  %2594 = lshr i32 %2576, 31
  %2595 = xor i32 %2592, %2594
  %2596 = add nuw nsw i32 %2595, %2592
  %2597 = icmp eq i32 %2596, 2
  %2598 = zext i1 %2597 to i8
  store i8 %2598, i8* %41, align 1, !tbaa !2450
  %2599 = sext i32 %2577 to i64
  store i64 %2599, i64* %RSI, align 8, !tbaa !2428
  %2600 = shl nsw i64 %2599, 3
  %2601 = add i64 %2600, %2572
  %2602 = add i64 %2569, 18
  store i64 %2602, i64* %PC, align 8
  %2603 = inttoptr i64 %2601 to double*
  %2604 = load double, double* %2603, align 8
  store double %2604, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %2605 = add i64 %2569, 22
  store i64 %2605, i64* %PC, align 8
  %2606 = load i64, i64* %2571, align 8
  store i64 %2606, i64* %RDX, align 8, !tbaa !2428
  %2607 = add i64 %2569, 25
  store i64 %2607, i64* %PC, align 8
  %2608 = load i32, i32* %2575, align 4
  %2609 = add i32 %2608, 15
  %2610 = zext i32 %2609 to i64
  store i64 %2610, i64* %RCX, align 8, !tbaa !2428
  %2611 = icmp ugt i32 %2608, -16
  %2612 = zext i1 %2611 to i8
  store i8 %2612, i8* %16, align 1, !tbaa !2433
  %2613 = and i32 %2609, 255
  %2614 = tail call i32 @llvm.ctpop.i32(i32 %2613) #10
  %2615 = trunc i32 %2614 to i8
  %2616 = and i8 %2615, 1
  %2617 = xor i8 %2616, 1
  store i8 %2617, i8* %23, align 1, !tbaa !2447
  %2618 = xor i32 %2608, %2609
  %2619 = lshr i32 %2618, 4
  %2620 = trunc i32 %2619 to i8
  %2621 = and i8 %2620, 1
  store i8 %2621, i8* %29, align 1, !tbaa !2451
  %2622 = icmp eq i32 %2609, 0
  %2623 = zext i1 %2622 to i8
  store i8 %2623, i8* %32, align 1, !tbaa !2448
  %2624 = lshr i32 %2609, 31
  %2625 = trunc i32 %2624 to i8
  store i8 %2625, i8* %35, align 1, !tbaa !2449
  %2626 = lshr i32 %2608, 31
  %2627 = xor i32 %2624, %2626
  %2628 = add nuw nsw i32 %2627, %2624
  %2629 = icmp eq i32 %2628, 2
  %2630 = zext i1 %2629 to i8
  store i8 %2630, i8* %41, align 1, !tbaa !2450
  %2631 = sext i32 %2609 to i64
  store i64 %2631, i64* %RSI, align 8, !tbaa !2428
  %2632 = shl nsw i64 %2631, 3
  %2633 = add i64 %2632, %2606
  %2634 = add i64 %2569, 36
  store i64 %2634, i64* %PC, align 8
  %2635 = inttoptr i64 %2633 to double*
  %2636 = load double, double* %2635, align 8
  %2637 = fadd double %2604, %2636
  store double %2637, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %2638 = load i64, i64* %RBP, align 8
  %2639 = add i64 %2638, -136
  %2640 = add i64 %2569, 44
  store i64 %2640, i64* %PC, align 8
  %2641 = inttoptr i64 %2639 to double*
  store double %2637, double* %2641, align 8
  %2642 = load i64, i64* %RBP, align 8
  %2643 = add i64 %2642, -16
  %2644 = load i64, i64* %PC, align 8
  %2645 = add i64 %2644, 4
  store i64 %2645, i64* %PC, align 8
  %2646 = inttoptr i64 %2643 to i64*
  %2647 = load i64, i64* %2646, align 8
  store i64 %2647, i64* %RDX, align 8, !tbaa !2428
  %2648 = add i64 %2642, -28
  %2649 = add i64 %2644, 7
  store i64 %2649, i64* %PC, align 8
  %2650 = inttoptr i64 %2648 to i32*
  %2651 = load i32, i32* %2650, align 4
  %2652 = add i32 %2651, 12
  %2653 = zext i32 %2652 to i64
  store i64 %2653, i64* %RCX, align 8, !tbaa !2428
  %2654 = icmp ugt i32 %2651, -13
  %2655 = zext i1 %2654 to i8
  store i8 %2655, i8* %16, align 1, !tbaa !2433
  %2656 = and i32 %2652, 255
  %2657 = tail call i32 @llvm.ctpop.i32(i32 %2656) #10
  %2658 = trunc i32 %2657 to i8
  %2659 = and i8 %2658, 1
  %2660 = xor i8 %2659, 1
  store i8 %2660, i8* %23, align 1, !tbaa !2447
  %2661 = xor i32 %2651, %2652
  %2662 = lshr i32 %2661, 4
  %2663 = trunc i32 %2662 to i8
  %2664 = and i8 %2663, 1
  store i8 %2664, i8* %29, align 1, !tbaa !2451
  %2665 = icmp eq i32 %2652, 0
  %2666 = zext i1 %2665 to i8
  store i8 %2666, i8* %32, align 1, !tbaa !2448
  %2667 = lshr i32 %2652, 31
  %2668 = trunc i32 %2667 to i8
  store i8 %2668, i8* %35, align 1, !tbaa !2449
  %2669 = lshr i32 %2651, 31
  %2670 = xor i32 %2667, %2669
  %2671 = add nuw nsw i32 %2670, %2667
  %2672 = icmp eq i32 %2671, 2
  %2673 = zext i1 %2672 to i8
  store i8 %2673, i8* %41, align 1, !tbaa !2450
  %2674 = sext i32 %2652 to i64
  store i64 %2674, i64* %RSI, align 8, !tbaa !2428
  %2675 = shl nsw i64 %2674, 3
  %2676 = add i64 %2675, %2647
  %2677 = add i64 %2644, 18
  store i64 %2677, i64* %PC, align 8
  %2678 = inttoptr i64 %2676 to double*
  %2679 = load double, double* %2678, align 8
  store double %2679, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %2680 = add i64 %2644, 22
  store i64 %2680, i64* %PC, align 8
  %2681 = load i64, i64* %2646, align 8
  store i64 %2681, i64* %RDX, align 8, !tbaa !2428
  %2682 = add i64 %2644, 25
  store i64 %2682, i64* %PC, align 8
  %2683 = load i32, i32* %2650, align 4
  %2684 = add i32 %2683, 14
  %2685 = zext i32 %2684 to i64
  store i64 %2685, i64* %RCX, align 8, !tbaa !2428
  %2686 = icmp ugt i32 %2683, -15
  %2687 = zext i1 %2686 to i8
  store i8 %2687, i8* %16, align 1, !tbaa !2433
  %2688 = and i32 %2684, 255
  %2689 = tail call i32 @llvm.ctpop.i32(i32 %2688) #10
  %2690 = trunc i32 %2689 to i8
  %2691 = and i8 %2690, 1
  %2692 = xor i8 %2691, 1
  store i8 %2692, i8* %23, align 1, !tbaa !2447
  %2693 = xor i32 %2683, %2684
  %2694 = lshr i32 %2693, 4
  %2695 = trunc i32 %2694 to i8
  %2696 = and i8 %2695, 1
  store i8 %2696, i8* %29, align 1, !tbaa !2451
  %2697 = icmp eq i32 %2684, 0
  %2698 = zext i1 %2697 to i8
  store i8 %2698, i8* %32, align 1, !tbaa !2448
  %2699 = lshr i32 %2684, 31
  %2700 = trunc i32 %2699 to i8
  store i8 %2700, i8* %35, align 1, !tbaa !2449
  %2701 = lshr i32 %2683, 31
  %2702 = xor i32 %2699, %2701
  %2703 = add nuw nsw i32 %2702, %2699
  %2704 = icmp eq i32 %2703, 2
  %2705 = zext i1 %2704 to i8
  store i8 %2705, i8* %41, align 1, !tbaa !2450
  %2706 = sext i32 %2684 to i64
  store i64 %2706, i64* %RSI, align 8, !tbaa !2428
  %2707 = shl nsw i64 %2706, 3
  %2708 = add i64 %2707, %2681
  %2709 = add i64 %2644, 36
  store i64 %2709, i64* %PC, align 8
  %2710 = inttoptr i64 %2708 to double*
  %2711 = load double, double* %2710, align 8
  %2712 = fsub double %2679, %2711
  store double %2712, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %2713 = load i64, i64* %RBP, align 8
  %2714 = add i64 %2713, -144
  %2715 = add i64 %2644, 44
  store i64 %2715, i64* %PC, align 8
  %2716 = inttoptr i64 %2714 to double*
  store double %2712, double* %2716, align 8
  %2717 = load i64, i64* %RBP, align 8
  %2718 = add i64 %2717, -16
  %2719 = load i64, i64* %PC, align 8
  %2720 = add i64 %2719, 4
  store i64 %2720, i64* %PC, align 8
  %2721 = inttoptr i64 %2718 to i64*
  %2722 = load i64, i64* %2721, align 8
  store i64 %2722, i64* %RDX, align 8, !tbaa !2428
  %2723 = add i64 %2717, -28
  %2724 = add i64 %2719, 7
  store i64 %2724, i64* %PC, align 8
  %2725 = inttoptr i64 %2723 to i32*
  %2726 = load i32, i32* %2725, align 4
  %2727 = add i32 %2726, 13
  %2728 = zext i32 %2727 to i64
  store i64 %2728, i64* %RCX, align 8, !tbaa !2428
  %2729 = icmp ugt i32 %2726, -14
  %2730 = zext i1 %2729 to i8
  store i8 %2730, i8* %16, align 1, !tbaa !2433
  %2731 = and i32 %2727, 255
  %2732 = tail call i32 @llvm.ctpop.i32(i32 %2731) #10
  %2733 = trunc i32 %2732 to i8
  %2734 = and i8 %2733, 1
  %2735 = xor i8 %2734, 1
  store i8 %2735, i8* %23, align 1, !tbaa !2447
  %2736 = xor i32 %2726, %2727
  %2737 = lshr i32 %2736, 4
  %2738 = trunc i32 %2737 to i8
  %2739 = and i8 %2738, 1
  store i8 %2739, i8* %29, align 1, !tbaa !2451
  %2740 = icmp eq i32 %2727, 0
  %2741 = zext i1 %2740 to i8
  store i8 %2741, i8* %32, align 1, !tbaa !2448
  %2742 = lshr i32 %2727, 31
  %2743 = trunc i32 %2742 to i8
  store i8 %2743, i8* %35, align 1, !tbaa !2449
  %2744 = lshr i32 %2726, 31
  %2745 = xor i32 %2742, %2744
  %2746 = add nuw nsw i32 %2745, %2742
  %2747 = icmp eq i32 %2746, 2
  %2748 = zext i1 %2747 to i8
  store i8 %2748, i8* %41, align 1, !tbaa !2450
  %2749 = sext i32 %2727 to i64
  store i64 %2749, i64* %RSI, align 8, !tbaa !2428
  %2750 = shl nsw i64 %2749, 3
  %2751 = add i64 %2750, %2722
  %2752 = add i64 %2719, 18
  store i64 %2752, i64* %PC, align 8
  %2753 = inttoptr i64 %2751 to double*
  %2754 = load double, double* %2753, align 8
  store double %2754, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %2755 = add i64 %2719, 22
  store i64 %2755, i64* %PC, align 8
  %2756 = load i64, i64* %2721, align 8
  store i64 %2756, i64* %RDX, align 8, !tbaa !2428
  %2757 = add i64 %2719, 25
  store i64 %2757, i64* %PC, align 8
  %2758 = load i32, i32* %2725, align 4
  %2759 = add i32 %2758, 15
  %2760 = zext i32 %2759 to i64
  store i64 %2760, i64* %RCX, align 8, !tbaa !2428
  %2761 = icmp ugt i32 %2758, -16
  %2762 = zext i1 %2761 to i8
  store i8 %2762, i8* %16, align 1, !tbaa !2433
  %2763 = and i32 %2759, 255
  %2764 = tail call i32 @llvm.ctpop.i32(i32 %2763) #10
  %2765 = trunc i32 %2764 to i8
  %2766 = and i8 %2765, 1
  %2767 = xor i8 %2766, 1
  store i8 %2767, i8* %23, align 1, !tbaa !2447
  %2768 = xor i32 %2758, %2759
  %2769 = lshr i32 %2768, 4
  %2770 = trunc i32 %2769 to i8
  %2771 = and i8 %2770, 1
  store i8 %2771, i8* %29, align 1, !tbaa !2451
  %2772 = icmp eq i32 %2759, 0
  %2773 = zext i1 %2772 to i8
  store i8 %2773, i8* %32, align 1, !tbaa !2448
  %2774 = lshr i32 %2759, 31
  %2775 = trunc i32 %2774 to i8
  store i8 %2775, i8* %35, align 1, !tbaa !2449
  %2776 = lshr i32 %2758, 31
  %2777 = xor i32 %2774, %2776
  %2778 = add nuw nsw i32 %2777, %2774
  %2779 = icmp eq i32 %2778, 2
  %2780 = zext i1 %2779 to i8
  store i8 %2780, i8* %41, align 1, !tbaa !2450
  %2781 = sext i32 %2759 to i64
  store i64 %2781, i64* %RSI, align 8, !tbaa !2428
  %2782 = shl nsw i64 %2781, 3
  %2783 = add i64 %2782, %2756
  %2784 = add i64 %2719, 36
  store i64 %2784, i64* %PC, align 8
  %2785 = inttoptr i64 %2783 to double*
  %2786 = load double, double* %2785, align 8
  %2787 = fsub double %2754, %2786
  store double %2787, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %2788 = load i64, i64* %RBP, align 8
  %2789 = add i64 %2788, -152
  %2790 = add i64 %2719, 44
  store i64 %2790, i64* %PC, align 8
  %2791 = inttoptr i64 %2789 to double*
  store double %2787, double* %2791, align 8
  %2792 = load i64, i64* %RBP, align 8
  %2793 = add i64 %2792, -96
  %2794 = load i64, i64* %PC, align 8
  %2795 = add i64 %2794, 5
  store i64 %2795, i64* %PC, align 8
  %2796 = inttoptr i64 %2793 to double*
  %2797 = load double, double* %2796, align 8
  store double %2797, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %2798 = add i64 %2792, -128
  %2799 = add i64 %2794, 10
  store i64 %2799, i64* %PC, align 8
  %2800 = inttoptr i64 %2798 to double*
  %2801 = load double, double* %2800, align 8
  %2802 = fadd double %2797, %2801
  store double %2802, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %2803 = add i64 %2792, -16
  %2804 = add i64 %2794, 14
  store i64 %2804, i64* %PC, align 8
  %2805 = inttoptr i64 %2803 to i64*
  %2806 = load i64, i64* %2805, align 8
  store i64 %2806, i64* %RDX, align 8, !tbaa !2428
  %2807 = add i64 %2792, -28
  %2808 = add i64 %2794, 17
  store i64 %2808, i64* %PC, align 8
  %2809 = inttoptr i64 %2807 to i32*
  %2810 = load i32, i32* %2809, align 4
  %2811 = add i32 %2810, 8
  %2812 = zext i32 %2811 to i64
  store i64 %2812, i64* %RCX, align 8, !tbaa !2428
  %2813 = icmp ugt i32 %2810, -9
  %2814 = zext i1 %2813 to i8
  store i8 %2814, i8* %16, align 1, !tbaa !2433
  %2815 = and i32 %2811, 255
  %2816 = tail call i32 @llvm.ctpop.i32(i32 %2815) #10
  %2817 = trunc i32 %2816 to i8
  %2818 = and i8 %2817, 1
  %2819 = xor i8 %2818, 1
  store i8 %2819, i8* %23, align 1, !tbaa !2447
  %2820 = xor i32 %2810, %2811
  %2821 = lshr i32 %2820, 4
  %2822 = trunc i32 %2821 to i8
  %2823 = and i8 %2822, 1
  store i8 %2823, i8* %29, align 1, !tbaa !2451
  %2824 = icmp eq i32 %2811, 0
  %2825 = zext i1 %2824 to i8
  store i8 %2825, i8* %32, align 1, !tbaa !2448
  %2826 = lshr i32 %2811, 31
  %2827 = trunc i32 %2826 to i8
  store i8 %2827, i8* %35, align 1, !tbaa !2449
  %2828 = lshr i32 %2810, 31
  %2829 = xor i32 %2826, %2828
  %2830 = add nuw nsw i32 %2829, %2826
  %2831 = icmp eq i32 %2830, 2
  %2832 = zext i1 %2831 to i8
  store i8 %2832, i8* %41, align 1, !tbaa !2450
  %2833 = sext i32 %2811 to i64
  store i64 %2833, i64* %RSI, align 8, !tbaa !2428
  %2834 = shl nsw i64 %2833, 3
  %2835 = add i64 %2834, %2806
  %2836 = add i64 %2794, 28
  store i64 %2836, i64* %PC, align 8
  %2837 = inttoptr i64 %2835 to double*
  store double %2802, double* %2837, align 8
  %2838 = load i64, i64* %RBP, align 8
  %2839 = add i64 %2838, -104
  %2840 = load i64, i64* %PC, align 8
  %2841 = add i64 %2840, 5
  store i64 %2841, i64* %PC, align 8
  %2842 = inttoptr i64 %2839 to double*
  %2843 = load double, double* %2842, align 8
  store double %2843, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %2844 = add i64 %2838, -136
  %2845 = add i64 %2840, 13
  store i64 %2845, i64* %PC, align 8
  %2846 = inttoptr i64 %2844 to double*
  %2847 = load double, double* %2846, align 8
  %2848 = fadd double %2843, %2847
  store double %2848, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %2849 = add i64 %2838, -16
  %2850 = add i64 %2840, 17
  store i64 %2850, i64* %PC, align 8
  %2851 = inttoptr i64 %2849 to i64*
  %2852 = load i64, i64* %2851, align 8
  store i64 %2852, i64* %RDX, align 8, !tbaa !2428
  %2853 = add i64 %2838, -28
  %2854 = add i64 %2840, 20
  store i64 %2854, i64* %PC, align 8
  %2855 = inttoptr i64 %2853 to i32*
  %2856 = load i32, i32* %2855, align 4
  %2857 = add i32 %2856, 9
  %2858 = zext i32 %2857 to i64
  store i64 %2858, i64* %RCX, align 8, !tbaa !2428
  %2859 = icmp ugt i32 %2856, -10
  %2860 = zext i1 %2859 to i8
  store i8 %2860, i8* %16, align 1, !tbaa !2433
  %2861 = and i32 %2857, 255
  %2862 = tail call i32 @llvm.ctpop.i32(i32 %2861) #10
  %2863 = trunc i32 %2862 to i8
  %2864 = and i8 %2863, 1
  %2865 = xor i8 %2864, 1
  store i8 %2865, i8* %23, align 1, !tbaa !2447
  %2866 = xor i32 %2856, %2857
  %2867 = lshr i32 %2866, 4
  %2868 = trunc i32 %2867 to i8
  %2869 = and i8 %2868, 1
  store i8 %2869, i8* %29, align 1, !tbaa !2451
  %2870 = icmp eq i32 %2857, 0
  %2871 = zext i1 %2870 to i8
  store i8 %2871, i8* %32, align 1, !tbaa !2448
  %2872 = lshr i32 %2857, 31
  %2873 = trunc i32 %2872 to i8
  store i8 %2873, i8* %35, align 1, !tbaa !2449
  %2874 = lshr i32 %2856, 31
  %2875 = xor i32 %2872, %2874
  %2876 = add nuw nsw i32 %2875, %2872
  %2877 = icmp eq i32 %2876, 2
  %2878 = zext i1 %2877 to i8
  store i8 %2878, i8* %41, align 1, !tbaa !2450
  %2879 = sext i32 %2857 to i64
  store i64 %2879, i64* %RSI, align 8, !tbaa !2428
  %2880 = shl nsw i64 %2879, 3
  %2881 = add i64 %2880, %2852
  %2882 = add i64 %2840, 31
  store i64 %2882, i64* %PC, align 8
  %2883 = inttoptr i64 %2881 to double*
  store double %2848, double* %2883, align 8
  %2884 = load i64, i64* %RBP, align 8
  %2885 = add i64 %2884, -128
  %2886 = load i64, i64* %PC, align 8
  %2887 = add i64 %2886, 5
  store i64 %2887, i64* %PC, align 8
  %2888 = inttoptr i64 %2885 to double*
  %2889 = load double, double* %2888, align 8
  store double %2889, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %2890 = add i64 %2884, -96
  %2891 = add i64 %2886, 10
  store i64 %2891, i64* %PC, align 8
  %2892 = inttoptr i64 %2890 to double*
  %2893 = load double, double* %2892, align 8
  %2894 = fsub double %2893, %2889
  store double %2894, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %2895 = add i64 %2886, 19
  store i64 %2895, i64* %PC, align 8
  store double %2894, double* %2892, align 8
  %2896 = load i64, i64* %RBP, align 8
  %2897 = add i64 %2896, -136
  %2898 = load i64, i64* %PC, align 8
  %2899 = add i64 %2898, 8
  store i64 %2899, i64* %PC, align 8
  %2900 = inttoptr i64 %2897 to double*
  %2901 = load double, double* %2900, align 8
  store double %2901, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %2902 = add i64 %2896, -104
  %2903 = add i64 %2898, 13
  store i64 %2903, i64* %PC, align 8
  %2904 = inttoptr i64 %2902 to double*
  %2905 = load double, double* %2904, align 8
  %2906 = fsub double %2905, %2901
  store double %2906, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %2907 = add i64 %2898, 22
  store i64 %2907, i64* %PC, align 8
  store double %2906, double* %2904, align 8
  %2908 = load i64, i64* %RBP, align 8
  %2909 = add i64 %2908, -72
  %2910 = load i64, i64* %PC, align 8
  %2911 = add i64 %2910, 5
  store i64 %2911, i64* %PC, align 8
  %2912 = inttoptr i64 %2909 to i64*
  %2913 = load i64, i64* %2912, align 8
  %2914 = load i64, i64* %RAX, align 8
  %2915 = xor i64 %2914, %2913
  store i64 %2915, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %16, align 1, !tbaa !2433
  %2916 = trunc i64 %2915 to i32
  %2917 = and i32 %2916, 255
  %2918 = tail call i32 @llvm.ctpop.i32(i32 %2917) #10
  %2919 = trunc i32 %2918 to i8
  %2920 = and i8 %2919, 1
  %2921 = xor i8 %2920, 1
  store i8 %2921, i8* %23, align 1, !tbaa !2447
  %2922 = icmp eq i64 %2915, 0
  %2923 = zext i1 %2922 to i8
  store i8 %2923, i8* %32, align 1, !tbaa !2448
  %2924 = lshr i64 %2915, 63
  %2925 = trunc i64 %2924 to i8
  store i8 %2925, i8* %35, align 1, !tbaa !2449
  store i8 0, i8* %41, align 1, !tbaa !2450
  store i8 0, i8* %29, align 1, !tbaa !2451
  store i64 %2915, i64* %372, align 1, !tbaa !2428
  store i64 0, i64* %68, align 1, !tbaa !2428
  %2926 = add i64 %2908, -96
  %2927 = add i64 %2910, 23
  store i64 %2927, i64* %PC, align 8
  %2928 = bitcast i64 %2915 to double
  %2929 = inttoptr i64 %2926 to double*
  %2930 = load double, double* %2929, align 8
  %2931 = fmul double %2928, %2930
  store double %2931, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %2932 = add i64 %2908, -64
  %2933 = add i64 %2910, 28
  store i64 %2933, i64* %PC, align 8
  %2934 = inttoptr i64 %2932 to double*
  %2935 = load double, double* %2934, align 8
  store double %2935, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %2936 = add i64 %2908, -104
  %2937 = add i64 %2910, 33
  store i64 %2937, i64* %PC, align 8
  %2938 = inttoptr i64 %2936 to double*
  %2939 = load double, double* %2938, align 8
  %2940 = fmul double %2935, %2939
  store double %2940, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %2941 = fsub double %2931, %2940
  store double %2941, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %2942 = add i64 %2908, -16
  %2943 = add i64 %2910, 41
  store i64 %2943, i64* %PC, align 8
  %2944 = inttoptr i64 %2942 to i64*
  %2945 = load i64, i64* %2944, align 8
  store i64 %2945, i64* %RDX, align 8, !tbaa !2428
  %2946 = add i64 %2908, -28
  %2947 = add i64 %2910, 44
  store i64 %2947, i64* %PC, align 8
  %2948 = inttoptr i64 %2946 to i32*
  %2949 = load i32, i32* %2948, align 4
  %2950 = add i32 %2949, 12
  %2951 = zext i32 %2950 to i64
  store i64 %2951, i64* %RCX, align 8, !tbaa !2428
  %2952 = icmp ugt i32 %2949, -13
  %2953 = zext i1 %2952 to i8
  store i8 %2953, i8* %16, align 1, !tbaa !2433
  %2954 = and i32 %2950, 255
  %2955 = tail call i32 @llvm.ctpop.i32(i32 %2954) #10
  %2956 = trunc i32 %2955 to i8
  %2957 = and i8 %2956, 1
  %2958 = xor i8 %2957, 1
  store i8 %2958, i8* %23, align 1, !tbaa !2447
  %2959 = xor i32 %2949, %2950
  %2960 = lshr i32 %2959, 4
  %2961 = trunc i32 %2960 to i8
  %2962 = and i8 %2961, 1
  store i8 %2962, i8* %29, align 1, !tbaa !2451
  %2963 = icmp eq i32 %2950, 0
  %2964 = zext i1 %2963 to i8
  store i8 %2964, i8* %32, align 1, !tbaa !2448
  %2965 = lshr i32 %2950, 31
  %2966 = trunc i32 %2965 to i8
  store i8 %2966, i8* %35, align 1, !tbaa !2449
  %2967 = lshr i32 %2949, 31
  %2968 = xor i32 %2965, %2967
  %2969 = add nuw nsw i32 %2968, %2965
  %2970 = icmp eq i32 %2969, 2
  %2971 = zext i1 %2970 to i8
  store i8 %2971, i8* %41, align 1, !tbaa !2450
  %2972 = sext i32 %2950 to i64
  store i64 %2972, i64* %RSI, align 8, !tbaa !2428
  %2973 = shl nsw i64 %2972, 3
  %2974 = add i64 %2973, %2945
  %2975 = add i64 %2910, 55
  store i64 %2975, i64* %PC, align 8
  %2976 = inttoptr i64 %2974 to double*
  store double %2941, double* %2976, align 8
  %2977 = load i64, i64* %RBP, align 8
  %2978 = add i64 %2977, -72
  %2979 = load i64, i64* %PC, align 8
  %2980 = add i64 %2979, 5
  store i64 %2980, i64* %PC, align 8
  %2981 = inttoptr i64 %2978 to i64*
  %2982 = load i64, i64* %2981, align 8
  %2983 = load i64, i64* %RAX, align 8
  %2984 = xor i64 %2983, %2982
  store i64 %2984, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %16, align 1, !tbaa !2433
  %2985 = trunc i64 %2984 to i32
  %2986 = and i32 %2985, 255
  %2987 = tail call i32 @llvm.ctpop.i32(i32 %2986) #10
  %2988 = trunc i32 %2987 to i8
  %2989 = and i8 %2988, 1
  %2990 = xor i8 %2989, 1
  store i8 %2990, i8* %23, align 1, !tbaa !2447
  %2991 = icmp eq i64 %2984, 0
  %2992 = zext i1 %2991 to i8
  store i8 %2992, i8* %32, align 1, !tbaa !2448
  %2993 = lshr i64 %2984, 63
  %2994 = trunc i64 %2993 to i8
  store i8 %2994, i8* %35, align 1, !tbaa !2449
  store i8 0, i8* %41, align 1, !tbaa !2450
  store i8 0, i8* %29, align 1, !tbaa !2451
  store i64 %2984, i64* %372, align 1, !tbaa !2428
  store i64 0, i64* %68, align 1, !tbaa !2428
  %2995 = add i64 %2977, -104
  %2996 = add i64 %2979, 23
  store i64 %2996, i64* %PC, align 8
  %2997 = bitcast i64 %2984 to double
  %2998 = inttoptr i64 %2995 to double*
  %2999 = load double, double* %2998, align 8
  %3000 = fmul double %2997, %2999
  store double %3000, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %3001 = add i64 %2977, -64
  %3002 = add i64 %2979, 28
  store i64 %3002, i64* %PC, align 8
  %3003 = inttoptr i64 %3001 to double*
  %3004 = load double, double* %3003, align 8
  store double %3004, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %3005 = add i64 %2977, -96
  %3006 = add i64 %2979, 33
  store i64 %3006, i64* %PC, align 8
  %3007 = inttoptr i64 %3005 to double*
  %3008 = load double, double* %3007, align 8
  %3009 = fmul double %3004, %3008
  store double %3009, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %3010 = fadd double %3000, %3009
  store double %3010, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %3011 = add i64 %2977, -16
  %3012 = add i64 %2979, 41
  store i64 %3012, i64* %PC, align 8
  %3013 = inttoptr i64 %3011 to i64*
  %3014 = load i64, i64* %3013, align 8
  store i64 %3014, i64* %RAX, align 8, !tbaa !2428
  %3015 = add i64 %2977, -28
  %3016 = add i64 %2979, 44
  store i64 %3016, i64* %PC, align 8
  %3017 = inttoptr i64 %3015 to i32*
  %3018 = load i32, i32* %3017, align 4
  %3019 = add i32 %3018, 13
  %3020 = zext i32 %3019 to i64
  store i64 %3020, i64* %RCX, align 8, !tbaa !2428
  %3021 = icmp ugt i32 %3018, -14
  %3022 = zext i1 %3021 to i8
  store i8 %3022, i8* %16, align 1, !tbaa !2433
  %3023 = and i32 %3019, 255
  %3024 = tail call i32 @llvm.ctpop.i32(i32 %3023) #10
  %3025 = trunc i32 %3024 to i8
  %3026 = and i8 %3025, 1
  %3027 = xor i8 %3026, 1
  store i8 %3027, i8* %23, align 1, !tbaa !2447
  %3028 = xor i32 %3018, %3019
  %3029 = lshr i32 %3028, 4
  %3030 = trunc i32 %3029 to i8
  %3031 = and i8 %3030, 1
  store i8 %3031, i8* %29, align 1, !tbaa !2451
  %3032 = icmp eq i32 %3019, 0
  %3033 = zext i1 %3032 to i8
  store i8 %3033, i8* %32, align 1, !tbaa !2448
  %3034 = lshr i32 %3019, 31
  %3035 = trunc i32 %3034 to i8
  store i8 %3035, i8* %35, align 1, !tbaa !2449
  %3036 = lshr i32 %3018, 31
  %3037 = xor i32 %3034, %3036
  %3038 = add nuw nsw i32 %3037, %3034
  %3039 = icmp eq i32 %3038, 2
  %3040 = zext i1 %3039 to i8
  store i8 %3040, i8* %41, align 1, !tbaa !2450
  %3041 = sext i32 %3019 to i64
  store i64 %3041, i64* %RDX, align 8, !tbaa !2428
  %3042 = shl nsw i64 %3041, 3
  %3043 = add i64 %3042, %3014
  %3044 = add i64 %2979, 55
  store i64 %3044, i64* %PC, align 8
  %3045 = inttoptr i64 %3043 to double*
  store double %3010, double* %3045, align 8
  %3046 = load i64, i64* %RBP, align 8
  %3047 = add i64 %3046, -112
  %3048 = load i64, i64* %PC, align 8
  %3049 = add i64 %3048, 5
  store i64 %3049, i64* %PC, align 8
  %3050 = inttoptr i64 %3047 to double*
  %3051 = load double, double* %3050, align 8
  store double %3051, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %3052 = add i64 %3046, -152
  %3053 = add i64 %3048, 13
  store i64 %3053, i64* %PC, align 8
  %3054 = inttoptr i64 %3052 to double*
  %3055 = load double, double* %3054, align 8
  %3056 = fsub double %3051, %3055
  store double %3056, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %3057 = add i64 %3046, -96
  %3058 = add i64 %3048, 18
  store i64 %3058, i64* %PC, align 8
  %3059 = inttoptr i64 %3057 to double*
  store double %3056, double* %3059, align 8
  %3060 = load i64, i64* %RBP, align 8
  %3061 = add i64 %3060, -120
  %3062 = load i64, i64* %PC, align 8
  %3063 = add i64 %3062, 5
  store i64 %3063, i64* %PC, align 8
  %3064 = inttoptr i64 %3061 to double*
  %3065 = load double, double* %3064, align 8
  store double %3065, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %3066 = add i64 %3060, -144
  %3067 = add i64 %3062, 13
  store i64 %3067, i64* %PC, align 8
  %3068 = inttoptr i64 %3066 to double*
  %3069 = load double, double* %3068, align 8
  %3070 = fadd double %3065, %3069
  store double %3070, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %3071 = add i64 %3060, -104
  %3072 = add i64 %3062, 18
  store i64 %3072, i64* %PC, align 8
  %3073 = inttoptr i64 %3071 to double*
  store double %3070, double* %3073, align 8
  %3074 = load i64, i64* %RBP, align 8
  %3075 = add i64 %3074, -48
  %3076 = load i64, i64* %PC, align 8
  %3077 = add i64 %3076, 5
  store i64 %3077, i64* %PC, align 8
  %3078 = inttoptr i64 %3075 to double*
  %3079 = load double, double* %3078, align 8
  store double %3079, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %3080 = add i64 %3074, -96
  %3081 = add i64 %3076, 10
  store i64 %3081, i64* %PC, align 8
  %3082 = inttoptr i64 %3080 to double*
  %3083 = load double, double* %3082, align 8
  %3084 = fmul double %3079, %3083
  store double %3084, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %3085 = add i64 %3074, -56
  %3086 = add i64 %3076, 15
  store i64 %3086, i64* %PC, align 8
  %3087 = inttoptr i64 %3085 to double*
  %3088 = load double, double* %3087, align 8
  store double %3088, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %3089 = add i64 %3074, -104
  %3090 = add i64 %3076, 20
  store i64 %3090, i64* %PC, align 8
  %3091 = inttoptr i64 %3089 to double*
  %3092 = load double, double* %3091, align 8
  %3093 = fmul double %3088, %3092
  store double %3093, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %3094 = fsub double %3084, %3093
  store double %3094, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %3095 = add i64 %3074, -16
  %3096 = add i64 %3076, 28
  store i64 %3096, i64* %PC, align 8
  %3097 = inttoptr i64 %3095 to i64*
  %3098 = load i64, i64* %3097, align 8
  store i64 %3098, i64* %RAX, align 8, !tbaa !2428
  %3099 = add i64 %3074, -28
  %3100 = add i64 %3076, 31
  store i64 %3100, i64* %PC, align 8
  %3101 = inttoptr i64 %3099 to i32*
  %3102 = load i32, i32* %3101, align 4
  %3103 = add i32 %3102, 10
  %3104 = zext i32 %3103 to i64
  store i64 %3104, i64* %RCX, align 8, !tbaa !2428
  %3105 = icmp ugt i32 %3102, -11
  %3106 = zext i1 %3105 to i8
  store i8 %3106, i8* %16, align 1, !tbaa !2433
  %3107 = and i32 %3103, 255
  %3108 = tail call i32 @llvm.ctpop.i32(i32 %3107) #10
  %3109 = trunc i32 %3108 to i8
  %3110 = and i8 %3109, 1
  %3111 = xor i8 %3110, 1
  store i8 %3111, i8* %23, align 1, !tbaa !2447
  %3112 = xor i32 %3102, %3103
  %3113 = lshr i32 %3112, 4
  %3114 = trunc i32 %3113 to i8
  %3115 = and i8 %3114, 1
  store i8 %3115, i8* %29, align 1, !tbaa !2451
  %3116 = icmp eq i32 %3103, 0
  %3117 = zext i1 %3116 to i8
  store i8 %3117, i8* %32, align 1, !tbaa !2448
  %3118 = lshr i32 %3103, 31
  %3119 = trunc i32 %3118 to i8
  store i8 %3119, i8* %35, align 1, !tbaa !2449
  %3120 = lshr i32 %3102, 31
  %3121 = xor i32 %3118, %3120
  %3122 = add nuw nsw i32 %3121, %3118
  %3123 = icmp eq i32 %3122, 2
  %3124 = zext i1 %3123 to i8
  store i8 %3124, i8* %41, align 1, !tbaa !2450
  %3125 = sext i32 %3103 to i64
  store i64 %3125, i64* %RDX, align 8, !tbaa !2428
  %3126 = shl nsw i64 %3125, 3
  %3127 = add i64 %3126, %3098
  %3128 = add i64 %3076, 42
  store i64 %3128, i64* %PC, align 8
  %3129 = inttoptr i64 %3127 to double*
  store double %3094, double* %3129, align 8
  %3130 = load i64, i64* %RBP, align 8
  %3131 = add i64 %3130, -48
  %3132 = load i64, i64* %PC, align 8
  %3133 = add i64 %3132, 5
  store i64 %3133, i64* %PC, align 8
  %3134 = inttoptr i64 %3131 to double*
  %3135 = load double, double* %3134, align 8
  store double %3135, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %3136 = add i64 %3130, -104
  %3137 = add i64 %3132, 10
  store i64 %3137, i64* %PC, align 8
  %3138 = inttoptr i64 %3136 to double*
  %3139 = load double, double* %3138, align 8
  %3140 = fmul double %3135, %3139
  store double %3140, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %3141 = add i64 %3130, -56
  %3142 = add i64 %3132, 15
  store i64 %3142, i64* %PC, align 8
  %3143 = inttoptr i64 %3141 to double*
  %3144 = load double, double* %3143, align 8
  store double %3144, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %3145 = add i64 %3130, -96
  %3146 = add i64 %3132, 20
  store i64 %3146, i64* %PC, align 8
  %3147 = inttoptr i64 %3145 to double*
  %3148 = load double, double* %3147, align 8
  %3149 = fmul double %3144, %3148
  store double %3149, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %3150 = fadd double %3140, %3149
  store double %3150, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %3151 = add i64 %3130, -16
  %3152 = add i64 %3132, 28
  store i64 %3152, i64* %PC, align 8
  %3153 = inttoptr i64 %3151 to i64*
  %3154 = load i64, i64* %3153, align 8
  store i64 %3154, i64* %RAX, align 8, !tbaa !2428
  %3155 = add i64 %3130, -28
  %3156 = add i64 %3132, 31
  store i64 %3156, i64* %PC, align 8
  %3157 = inttoptr i64 %3155 to i32*
  %3158 = load i32, i32* %3157, align 4
  %3159 = add i32 %3158, 11
  %3160 = zext i32 %3159 to i64
  store i64 %3160, i64* %RCX, align 8, !tbaa !2428
  %3161 = icmp ugt i32 %3158, -12
  %3162 = zext i1 %3161 to i8
  store i8 %3162, i8* %16, align 1, !tbaa !2433
  %3163 = and i32 %3159, 255
  %3164 = tail call i32 @llvm.ctpop.i32(i32 %3163) #10
  %3165 = trunc i32 %3164 to i8
  %3166 = and i8 %3165, 1
  %3167 = xor i8 %3166, 1
  store i8 %3167, i8* %23, align 1, !tbaa !2447
  %3168 = xor i32 %3158, %3159
  %3169 = lshr i32 %3168, 4
  %3170 = trunc i32 %3169 to i8
  %3171 = and i8 %3170, 1
  store i8 %3171, i8* %29, align 1, !tbaa !2451
  %3172 = icmp eq i32 %3159, 0
  %3173 = zext i1 %3172 to i8
  store i8 %3173, i8* %32, align 1, !tbaa !2448
  %3174 = lshr i32 %3159, 31
  %3175 = trunc i32 %3174 to i8
  store i8 %3175, i8* %35, align 1, !tbaa !2449
  %3176 = lshr i32 %3158, 31
  %3177 = xor i32 %3174, %3176
  %3178 = add nuw nsw i32 %3177, %3174
  %3179 = icmp eq i32 %3178, 2
  %3180 = zext i1 %3179 to i8
  store i8 %3180, i8* %41, align 1, !tbaa !2450
  %3181 = sext i32 %3159 to i64
  store i64 %3181, i64* %RDX, align 8, !tbaa !2428
  %3182 = shl nsw i64 %3181, 3
  %3183 = add i64 %3182, %3154
  %3184 = add i64 %3132, 42
  store i64 %3184, i64* %PC, align 8
  %3185 = inttoptr i64 %3183 to double*
  store double %3150, double* %3185, align 8
  %3186 = load i64, i64* %RBP, align 8
  %3187 = add i64 %3186, -112
  %3188 = load i64, i64* %PC, align 8
  %3189 = add i64 %3188, 5
  store i64 %3189, i64* %PC, align 8
  %3190 = inttoptr i64 %3187 to double*
  %3191 = load double, double* %3190, align 8
  store double %3191, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %3192 = add i64 %3186, -152
  %3193 = add i64 %3188, 13
  store i64 %3193, i64* %PC, align 8
  %3194 = inttoptr i64 %3192 to double*
  %3195 = load double, double* %3194, align 8
  %3196 = fadd double %3191, %3195
  store double %3196, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %3197 = add i64 %3186, -96
  %3198 = add i64 %3188, 18
  store i64 %3198, i64* %PC, align 8
  %3199 = inttoptr i64 %3197 to double*
  store double %3196, double* %3199, align 8
  %3200 = load i64, i64* %RBP, align 8
  %3201 = add i64 %3200, -120
  %3202 = load i64, i64* %PC, align 8
  %3203 = add i64 %3202, 5
  store i64 %3203, i64* %PC, align 8
  %3204 = inttoptr i64 %3201 to double*
  %3205 = load double, double* %3204, align 8
  store double %3205, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %3206 = add i64 %3200, -144
  %3207 = add i64 %3202, 13
  store i64 %3207, i64* %PC, align 8
  %3208 = inttoptr i64 %3206 to double*
  %3209 = load double, double* %3208, align 8
  %3210 = fsub double %3205, %3209
  store double %3210, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %3211 = add i64 %3200, -104
  %3212 = add i64 %3202, 18
  store i64 %3212, i64* %PC, align 8
  %3213 = inttoptr i64 %3211 to double*
  store double %3210, double* %3213, align 8
  %3214 = load i64, i64* %RBP, align 8
  %3215 = add i64 %3214, -80
  %3216 = load i64, i64* %PC, align 8
  %3217 = add i64 %3216, 5
  store i64 %3217, i64* %PC, align 8
  %3218 = inttoptr i64 %3215 to double*
  %3219 = load double, double* %3218, align 8
  store double %3219, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %3220 = add i64 %3214, -96
  %3221 = add i64 %3216, 10
  store i64 %3221, i64* %PC, align 8
  %3222 = inttoptr i64 %3220 to double*
  %3223 = load double, double* %3222, align 8
  %3224 = fmul double %3219, %3223
  store double %3224, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %3225 = add i64 %3214, -88
  %3226 = add i64 %3216, 15
  store i64 %3226, i64* %PC, align 8
  %3227 = inttoptr i64 %3225 to double*
  %3228 = load double, double* %3227, align 8
  store double %3228, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %3229 = add i64 %3214, -104
  %3230 = add i64 %3216, 20
  store i64 %3230, i64* %PC, align 8
  %3231 = inttoptr i64 %3229 to double*
  %3232 = load double, double* %3231, align 8
  %3233 = fmul double %3228, %3232
  store double %3233, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %3234 = fsub double %3224, %3233
  store double %3234, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %3235 = add i64 %3214, -16
  %3236 = add i64 %3216, 28
  store i64 %3236, i64* %PC, align 8
  %3237 = inttoptr i64 %3235 to i64*
  %3238 = load i64, i64* %3237, align 8
  store i64 %3238, i64* %RAX, align 8, !tbaa !2428
  %3239 = add i64 %3214, -28
  %3240 = add i64 %3216, 31
  store i64 %3240, i64* %PC, align 8
  %3241 = inttoptr i64 %3239 to i32*
  %3242 = load i32, i32* %3241, align 4
  %3243 = add i32 %3242, 14
  %3244 = zext i32 %3243 to i64
  store i64 %3244, i64* %RCX, align 8, !tbaa !2428
  %3245 = icmp ugt i32 %3242, -15
  %3246 = zext i1 %3245 to i8
  store i8 %3246, i8* %16, align 1, !tbaa !2433
  %3247 = and i32 %3243, 255
  %3248 = tail call i32 @llvm.ctpop.i32(i32 %3247) #10
  %3249 = trunc i32 %3248 to i8
  %3250 = and i8 %3249, 1
  %3251 = xor i8 %3250, 1
  store i8 %3251, i8* %23, align 1, !tbaa !2447
  %3252 = xor i32 %3242, %3243
  %3253 = lshr i32 %3252, 4
  %3254 = trunc i32 %3253 to i8
  %3255 = and i8 %3254, 1
  store i8 %3255, i8* %29, align 1, !tbaa !2451
  %3256 = icmp eq i32 %3243, 0
  %3257 = zext i1 %3256 to i8
  store i8 %3257, i8* %32, align 1, !tbaa !2448
  %3258 = lshr i32 %3243, 31
  %3259 = trunc i32 %3258 to i8
  store i8 %3259, i8* %35, align 1, !tbaa !2449
  %3260 = lshr i32 %3242, 31
  %3261 = xor i32 %3258, %3260
  %3262 = add nuw nsw i32 %3261, %3258
  %3263 = icmp eq i32 %3262, 2
  %3264 = zext i1 %3263 to i8
  store i8 %3264, i8* %41, align 1, !tbaa !2450
  %3265 = sext i32 %3243 to i64
  store i64 %3265, i64* %RDX, align 8, !tbaa !2428
  %3266 = shl nsw i64 %3265, 3
  %3267 = add i64 %3266, %3238
  %3268 = add i64 %3216, 42
  store i64 %3268, i64* %PC, align 8
  %3269 = inttoptr i64 %3267 to double*
  store double %3234, double* %3269, align 8
  %3270 = load i64, i64* %RBP, align 8
  %3271 = add i64 %3270, -80
  %3272 = load i64, i64* %PC, align 8
  %3273 = add i64 %3272, 5
  store i64 %3273, i64* %PC, align 8
  %3274 = inttoptr i64 %3271 to double*
  %3275 = load double, double* %3274, align 8
  store double %3275, double* %67, align 1, !tbaa !2452
  store double 0.000000e+00, double* %69, align 1, !tbaa !2452
  %3276 = add i64 %3270, -104
  %3277 = add i64 %3272, 10
  store i64 %3277, i64* %PC, align 8
  %3278 = inttoptr i64 %3276 to double*
  %3279 = load double, double* %3278, align 8
  %3280 = fmul double %3275, %3279
  store double %3280, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %3281 = add i64 %3270, -88
  %3282 = add i64 %3272, 15
  store i64 %3282, i64* %PC, align 8
  %3283 = inttoptr i64 %3281 to double*
  %3284 = load double, double* %3283, align 8
  store double %3284, double* %647, align 1, !tbaa !2452
  store double 0.000000e+00, double* %649, align 1, !tbaa !2452
  %3285 = add i64 %3270, -96
  %3286 = add i64 %3272, 20
  store i64 %3286, i64* %PC, align 8
  %3287 = inttoptr i64 %3285 to double*
  %3288 = load double, double* %3287, align 8
  %3289 = fmul double %3284, %3288
  store double %3289, double* %647, align 1, !tbaa !2452
  store i64 0, i64* %648, align 1, !tbaa !2452
  %3290 = fadd double %3280, %3289
  store double %3290, double* %67, align 1, !tbaa !2452
  store i64 0, i64* %68, align 1, !tbaa !2452
  %3291 = add i64 %3270, -16
  %3292 = add i64 %3272, 28
  store i64 %3292, i64* %PC, align 8
  %3293 = inttoptr i64 %3291 to i64*
  %3294 = load i64, i64* %3293, align 8
  store i64 %3294, i64* %RAX, align 8, !tbaa !2428
  %3295 = add i64 %3270, -28
  %3296 = add i64 %3272, 31
  store i64 %3296, i64* %PC, align 8
  %3297 = inttoptr i64 %3295 to i32*
  %3298 = load i32, i32* %3297, align 4
  %3299 = add i32 %3298, 15
  %3300 = zext i32 %3299 to i64
  store i64 %3300, i64* %RCX, align 8, !tbaa !2428
  %3301 = icmp ugt i32 %3298, -16
  %3302 = zext i1 %3301 to i8
  store i8 %3302, i8* %16, align 1, !tbaa !2433
  %3303 = and i32 %3299, 255
  %3304 = tail call i32 @llvm.ctpop.i32(i32 %3303) #10
  %3305 = trunc i32 %3304 to i8
  %3306 = and i8 %3305, 1
  %3307 = xor i8 %3306, 1
  store i8 %3307, i8* %23, align 1, !tbaa !2447
  %3308 = xor i32 %3298, %3299
  %3309 = lshr i32 %3308, 4
  %3310 = trunc i32 %3309 to i8
  %3311 = and i8 %3310, 1
  store i8 %3311, i8* %29, align 1, !tbaa !2451
  %3312 = icmp eq i32 %3299, 0
  %3313 = zext i1 %3312 to i8
  store i8 %3313, i8* %32, align 1, !tbaa !2448
  %3314 = lshr i32 %3299, 31
  %3315 = trunc i32 %3314 to i8
  store i8 %3315, i8* %35, align 1, !tbaa !2449
  %3316 = lshr i32 %3298, 31
  %3317 = xor i32 %3314, %3316
  %3318 = add nuw nsw i32 %3317, %3314
  %3319 = icmp eq i32 %3318, 2
  %3320 = zext i1 %3319 to i8
  store i8 %3320, i8* %41, align 1, !tbaa !2450
  %3321 = sext i32 %3299 to i64
  store i64 %3321, i64* %RDX, align 8, !tbaa !2428
  %3322 = shl nsw i64 %3321, 3
  %3323 = add i64 %3322, %3294
  %3324 = add i64 %3272, 42
  store i64 %3324, i64* %PC, align 8
  %3325 = inttoptr i64 %3323 to double*
  store double %3290, double* %3325, align 8
  %3326 = load i64, i64* %RBP, align 8
  %3327 = add i64 %3326, -28
  %3328 = load i64, i64* %PC, align 8
  %3329 = add i64 %3328, 3
  store i64 %3329, i64* %PC, align 8
  %3330 = inttoptr i64 %3327 to i32*
  %3331 = load i32, i32* %3330, align 4
  %3332 = add i32 %3331, 16
  %3333 = zext i32 %3332 to i64
  store i64 %3333, i64* %RAX, align 8, !tbaa !2428
  %3334 = icmp ugt i32 %3331, -17
  %3335 = zext i1 %3334 to i8
  store i8 %3335, i8* %16, align 1, !tbaa !2433
  %3336 = and i32 %3332, 255
  %3337 = tail call i32 @llvm.ctpop.i32(i32 %3336) #10
  %3338 = trunc i32 %3337 to i8
  %3339 = and i8 %3338, 1
  %3340 = xor i8 %3339, 1
  store i8 %3340, i8* %23, align 1, !tbaa !2447
  %3341 = xor i32 %3331, 16
  %3342 = xor i32 %3341, %3332
  %3343 = lshr i32 %3342, 4
  %3344 = trunc i32 %3343 to i8
  %3345 = and i8 %3344, 1
  store i8 %3345, i8* %29, align 1, !tbaa !2451
  %3346 = icmp eq i32 %3332, 0
  %3347 = zext i1 %3346 to i8
  store i8 %3347, i8* %32, align 1, !tbaa !2448
  %3348 = lshr i32 %3332, 31
  %3349 = trunc i32 %3348 to i8
  store i8 %3349, i8* %35, align 1, !tbaa !2449
  %3350 = lshr i32 %3331, 31
  %3351 = xor i32 %3348, %3350
  %3352 = add nuw nsw i32 %3351, %3348
  %3353 = icmp eq i32 %3352, 2
  %3354 = zext i1 %3353 to i8
  store i8 %3354, i8* %41, align 1, !tbaa !2450
  %3355 = add i64 %3328, 9
  store i64 %3355, i64* %PC, align 8
  store i32 %3332, i32* %3330, align 4
  %3356 = load i64, i64* %PC, align 8
  %3357 = add i64 %3356, -1815
  store i64 %3357, i64* %PC, align 8, !tbaa !2428
  br label %block_402bd2

block_402bd2:                                     ; preds = %block_402bde, %block_402870
  %3358 = phi i64 [ %3357, %block_402bde ], [ %.pre, %block_402870 ]
  %3359 = load i64, i64* %RBP, align 8
  %3360 = add i64 %3359, -28
  %3361 = add i64 %3358, 3
  store i64 %3361, i64* %PC, align 8
  %3362 = inttoptr i64 %3360 to i32*
  %3363 = load i32, i32* %3362, align 4
  %3364 = zext i32 %3363 to i64
  store i64 %3364, i64* %RAX, align 8, !tbaa !2428
  %3365 = add i64 %3359, -4
  %3366 = add i64 %3358, 6
  store i64 %3366, i64* %PC, align 8
  %3367 = inttoptr i64 %3365 to i32*
  %3368 = load i32, i32* %3367, align 4
  %3369 = sub i32 %3363, %3368
  %3370 = icmp ult i32 %3363, %3368
  %3371 = zext i1 %3370 to i8
  store i8 %3371, i8* %16, align 1, !tbaa !2433
  %3372 = and i32 %3369, 255
  %3373 = tail call i32 @llvm.ctpop.i32(i32 %3372) #10
  %3374 = trunc i32 %3373 to i8
  %3375 = and i8 %3374, 1
  %3376 = xor i8 %3375, 1
  store i8 %3376, i8* %23, align 1, !tbaa !2447
  %3377 = xor i32 %3368, %3363
  %3378 = xor i32 %3377, %3369
  %3379 = lshr i32 %3378, 4
  %3380 = trunc i32 %3379 to i8
  %3381 = and i8 %3380, 1
  store i8 %3381, i8* %29, align 1, !tbaa !2451
  %3382 = icmp eq i32 %3369, 0
  %3383 = zext i1 %3382 to i8
  store i8 %3383, i8* %32, align 1, !tbaa !2448
  %3384 = lshr i32 %3369, 31
  %3385 = trunc i32 %3384 to i8
  store i8 %3385, i8* %35, align 1, !tbaa !2449
  %3386 = lshr i32 %3363, 31
  %3387 = lshr i32 %3368, 31
  %3388 = xor i32 %3387, %3386
  %3389 = xor i32 %3384, %3386
  %3390 = add nuw nsw i32 %3389, %3388
  %3391 = icmp eq i32 %3390, 2
  %3392 = zext i1 %3391 to i8
  store i8 %3392, i8* %41, align 1, !tbaa !2450
  %3393 = icmp ne i8 %3385, 0
  %3394 = xor i1 %3393, %3391
  %.v = select i1 %3394, i64 12, i64 1820
  %3395 = add i64 %3358, %.v
  store i64 %3395, i64* %PC, align 8, !tbaa !2428
  br i1 %3394, label %block_402bde, label %block_4032ee

block_4032ee:                                     ; preds = %block_402bd2
  %3396 = load i64, i64* %RSP, align 8
  %3397 = add i64 %3396, 24
  store i64 %3397, i64* %RSP, align 8, !tbaa !2428
  %3398 = icmp ugt i64 %3396, -25
  %3399 = zext i1 %3398 to i8
  store i8 %3399, i8* %16, align 1, !tbaa !2433
  %3400 = trunc i64 %3397 to i32
  %3401 = and i32 %3400, 255
  %3402 = tail call i32 @llvm.ctpop.i32(i32 %3401) #10
  %3403 = trunc i32 %3402 to i8
  %3404 = and i8 %3403, 1
  %3405 = xor i8 %3404, 1
  store i8 %3405, i8* %23, align 1, !tbaa !2447
  %3406 = xor i64 %3396, 16
  %3407 = xor i64 %3406, %3397
  %3408 = lshr i64 %3407, 4
  %3409 = trunc i64 %3408 to i8
  %3410 = and i8 %3409, 1
  store i8 %3410, i8* %29, align 1, !tbaa !2451
  %3411 = icmp eq i64 %3397, 0
  %3412 = zext i1 %3411 to i8
  store i8 %3412, i8* %32, align 1, !tbaa !2448
  %3413 = lshr i64 %3397, 63
  %3414 = trunc i64 %3413 to i8
  store i8 %3414, i8* %35, align 1, !tbaa !2449
  %3415 = lshr i64 %3396, 63
  %3416 = xor i64 %3413, %3415
  %3417 = add nuw nsw i64 %3416, %3413
  %3418 = icmp eq i64 %3417, 2
  %3419 = zext i1 %3418 to i8
  store i8 %3419, i8* %41, align 1, !tbaa !2450
  %3420 = add i64 %3395, 5
  store i64 %3420, i64* %PC, align 8
  %3421 = add i64 %3396, 32
  %3422 = inttoptr i64 %3397 to i64*
  %3423 = load i64, i64* %3422, align 8
  store i64 %3423, i64* %RBP, align 8, !tbaa !2428
  store i64 %3421, i64* %RSP, align 8, !tbaa !2428
  %3424 = add i64 %3395, 6
  store i64 %3424, i64* %PC, align 8
  %3425 = inttoptr i64 %3421 to i64*
  %3426 = load i64, i64* %3425, align 8
  store i64 %3426, i64* %PC, align 8, !tbaa !2428
  %3427 = add i64 %3396, 40
  store i64 %3427, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_400740__dl_relocate_static_pie(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400740:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = add i64 %1, 2
  store i64 %3, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !2428
  %6 = inttoptr i64 %5 to i64*
  %7 = load i64, i64* %6, align 8
  store i64 %7, i64* %PC, align 8, !tbaa !2428
  %8 = add i64 %5, 8
  store i64 %8, i64* %4, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_404064__term_proc(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_404064:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = add i64 %3, -8
  %5 = icmp ult i64 %3, 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %10 = lshr i64 %4, 63
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %12 = lshr i64 %3, 63
  %13 = xor i64 %10, %12
  %14 = add nuw nsw i64 %13, %12
  %15 = icmp eq i64 %14, 2
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %18 = zext i1 %5 to i8
  store i8 %18, i8* %6, align 1, !tbaa !2433
  %19 = trunc i64 %3 to i32
  %20 = and i32 %19, 255
  %21 = tail call i32 @llvm.ctpop.i32(i32 %20) #10
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = xor i8 %23, 1
  store i8 %24, i8* %7, align 1, !tbaa !2447
  %25 = xor i64 %4, %3
  %26 = lshr i64 %25, 4
  %27 = trunc i64 %26 to i8
  %28 = and i8 %27, 1
  store i8 %28, i8* %8, align 1, !tbaa !2451
  %29 = icmp eq i64 %3, 0
  %30 = zext i1 %29 to i8
  store i8 %30, i8* %9, align 1, !tbaa !2448
  %31 = trunc i64 %12 to i8
  store i8 %31, i8* %11, align 1, !tbaa !2449
  store i8 %16, i8* %17, align 1, !tbaa !2450
  %32 = add i64 %1, 9
  store i64 %32, i64* %PC, align 8
  %33 = inttoptr i64 %3 to i64*
  %34 = load i64, i64* %33, align 8
  store i64 %34, i64* %PC, align 8, !tbaa !2428
  %35 = add i64 %3, 8
  store i64 %35, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_400780_register_tm_clones(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400780:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  store i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64* %RSI, align 8, !tbaa !2428
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 6
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  store i64 %7, i64* %5, align 8, !tbaa !2428
  %9 = load i64, i64* %RSI, align 8
  %10 = load i64, i64* %PC, align 8
  %11 = sub i64 %9, ptrtoint (%__bss_start_type* @__bss_start to i64)
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %18 = ashr i64 %11, 3
  %19 = lshr i64 %18, 63
  store i64 %19, i64* %RAX, align 8, !tbaa !2428
  %20 = add nsw i64 %19, %18
  %21 = trunc i64 %20 to i8
  %22 = and i8 %21, 1
  %23 = ashr i64 %20, 1
  store i64 %23, i64* %RSI, align 8, !tbaa !2428
  store i8 %22, i8* %12, align 1, !tbaa !2432
  %24 = trunc i64 %23 to i32
  %25 = and i32 %24, 255
  %26 = tail call i32 @llvm.ctpop.i32(i32 %25) #10
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = xor i8 %28, 1
  store i8 %29, i8* %13, align 1, !tbaa !2432
  store i8 0, i8* %14, align 1, !tbaa !2432
  %30 = icmp eq i64 %23, 0
  %31 = zext i1 %30 to i8
  store i8 %31, i8* %15, align 1, !tbaa !2432
  %32 = lshr i64 %23, 63
  %33 = trunc i64 %32 to i8
  store i8 %33, i8* %16, align 1, !tbaa !2432
  store i8 0, i8* %17, align 1, !tbaa !2432
  %.v = select i1 %30, i64 50, i64 29
  %34 = add i64 %10, %.v
  store i64 %34, i64* %PC, align 8, !tbaa !2428
  br i1 %30, label %block_4007b8, label %block_4007a3

block_4007b8:                                     ; preds = %block_4007a3, %block_400780
  %35 = phi i64 [ %45, %block_4007a3 ], [ %34, %block_400780 ]
  %36 = add i64 %35, 1
  store i64 %36, i64* %PC, align 8
  %37 = load i64, i64* %5, align 8, !tbaa !2428
  %38 = add i64 %37, 8
  %39 = inttoptr i64 %37 to i64*
  %40 = load i64, i64* %39, align 8
  store i64 %40, i64* %RBP, align 8, !tbaa !2428
  store i64 %38, i64* %5, align 8, !tbaa !2428
  %41 = add i64 %35, 2
  store i64 %41, i64* %PC, align 8
  %42 = inttoptr i64 %38 to i64*
  %43 = load i64, i64* %42, align 8
  store i64 %43, i64* %PC, align 8, !tbaa !2428
  %44 = add i64 %37, 16
  store i64 %44, i64* %5, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_4007a3:                                     ; preds = %block_400780
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %12, align 1, !tbaa !2433
  store i8 1, i8* %13, align 1, !tbaa !2447
  store i8 1, i8* %15, align 1, !tbaa !2448
  store i8 0, i8* %16, align 1, !tbaa !2449
  store i8 0, i8* %17, align 1, !tbaa !2450
  store i8 0, i8* %14, align 1, !tbaa !2451
  %45 = add i64 %34, 21
  store i64 %45, i64* %PC, align 8, !tbaa !2428
  br label %block_4007b8
}

; Function Attrs: noinline
define %struct.Memory* @sub_400750_deregister_tm_clones(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400750:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  store i64 %7, i64* %5, align 8, !tbaa !2428
  %9 = load i64, i64* %PC, align 8
  store i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64* %RAX, align 8, !tbaa !2428
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 zext (i1 icmp ult (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)) to i8), i8* %10, align 1, !tbaa !2433
  %11 = tail call i32 @llvm.ctpop.i32(i32 and (i32 trunc (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)) to i32), i32 255)) #10
  %12 = trunc i32 %11 to i8
  %13 = and i8 %12, 1
  %14 = xor i8 %13, 1
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %14, i8* %15, align 1, !tbaa !2447
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 and (i8 trunc (i64 lshr (i64 xor (i64 xor (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295)), i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64))), i64 4) to i8), i8 1), i8* %16, align 1, !tbaa !2451
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 zext (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0) to i8), i8* %17, align 1, !tbaa !2448
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 trunc (i64 lshr (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 63) to i8), i8* %18, align 1, !tbaa !2449
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 zext (i1 icmp eq (i64 add (i64 xor (i64 lshr (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 63), i64 lshr (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 63)), i64 xor (i64 lshr (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 63), i64 lshr (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 63))), i64 2) to i8), i8* %19, align 1, !tbaa !2450
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %20 = add i64 %9, select (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), i64 39, i64 16)
  store i64 %20, i64* %PC, align 8, !tbaa !2428
  br i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), label %block_400778, label %block_400761

block_400778:                                     ; preds = %block_400761, %block_400750
  %21 = phi i64 [ %28, %block_400761 ], [ %20, %block_400750 ]
  %22 = add i64 %21, 1
  store i64 %22, i64* %PC, align 8
  %23 = load i64, i64* %8, align 8
  store i64 %23, i64* %RBP, align 8, !tbaa !2428
  store i64 %6, i64* %5, align 8, !tbaa !2428
  %24 = add i64 %21, 2
  store i64 %24, i64* %PC, align 8
  %25 = inttoptr i64 %6 to i64*
  %26 = load i64, i64* %25, align 8
  store i64 %26, i64* %PC, align 8, !tbaa !2428
  %27 = add i64 %6, 8
  store i64 %27, i64* %5, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_400761:                                     ; preds = %block_400750
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %10, align 1, !tbaa !2433
  store i8 1, i8* %15, align 1, !tbaa !2447
  store i8 1, i8* %17, align 1, !tbaa !2448
  store i8 0, i8* %18, align 1, !tbaa !2449
  store i8 0, i8* %19, align 1, !tbaa !2450
  store i8 0, i8* %16, align 1, !tbaa !2451
  %28 = add i64 %9, add (i64 select (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), i64 39, i64 16), i64 23)
  store i64 %28, i64* %PC, align 8, !tbaa !2428
  br label %block_400778
}

; Function Attrs: noinline
define %struct.Memory* @sub_400800_main(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400800:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %RAX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3
  %10 = load i64, i64* %RBP, align 8
  %11 = add i64 %1, 1
  store i64 %11, i64* %PC, align 8
  %12 = load i64, i64* %RSP, align 8, !tbaa !2428
  %13 = add i64 %12, -8
  %14 = inttoptr i64 %13 to i64*
  store i64 %10, i64* %14, align 8
  %15 = load i64, i64* %PC, align 8
  store i64 %13, i64* %RBP, align 8, !tbaa !2428
  %16 = add i64 %12, -232
  store i64 %16, i64* %RSP, align 8, !tbaa !2428
  %17 = icmp ult i64 %13, 224
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %18, i8* %19, align 1, !tbaa !2433
  %20 = trunc i64 %16 to i32
  %21 = and i32 %20, 255
  %22 = tail call i32 @llvm.ctpop.i32(i32 %21) #10
  %23 = trunc i32 %22 to i8
  %24 = and i8 %23, 1
  %25 = xor i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %25, i8* %26, align 1, !tbaa !2447
  %27 = xor i64 %13, %16
  %28 = lshr i64 %27, 4
  %29 = trunc i64 %28 to i8
  %30 = and i8 %29, 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %30, i8* %31, align 1, !tbaa !2451
  %32 = icmp eq i64 %16, 0
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %33, i8* %34, align 1, !tbaa !2448
  %35 = lshr i64 %16, 63
  %36 = trunc i64 %35 to i8
  %37 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %36, i8* %37, align 1, !tbaa !2449
  %38 = lshr i64 %13, 63
  %39 = xor i64 %35, %38
  %40 = add nuw nsw i64 %39, %38
  %41 = icmp eq i64 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1, !tbaa !2450
  store i64 16, i64* %RAX, align 8, !tbaa !2428
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  %44 = add i64 %12, -12
  %45 = add i64 %15, 24
  store i64 %45, i64* %PC, align 8
  %46 = inttoptr i64 %44 to i32*
  store i32 0, i32* %46, align 4
  %47 = load i64, i64* %RBP, align 8
  %48 = add i64 %47, -88
  %49 = load i64, i64* %PC, align 8
  %50 = add i64 %49, 8
  store i64 %50, i64* %PC, align 8
  %51 = inttoptr i64 %48 to i64*
  store i64 0, i64* %51, align 8
  %52 = load i64, i64* %RBP, align 8
  %53 = add i64 %52, -144
  %54 = load i64, i64* %RDI, align 8
  %55 = load i64, i64* %PC, align 8
  %56 = add i64 %55, 7
  store i64 %56, i64* %PC, align 8
  %57 = inttoptr i64 %53 to i64*
  store i64 %54, i64* %57, align 8
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 1464
  %60 = add i64 %58, 5
  %61 = load i64, i64* %RSP, align 8, !tbaa !2428
  %62 = add i64 %61, -8
  %63 = inttoptr i64 %62 to i64*
  store i64 %60, i64* %63, align 8
  store i64 %62, i64* %RSP, align 8, !tbaa !2428
  store i64 %59, i64* %PC, align 8, !tbaa !2428
  %64 = tail call %struct.Memory* @sub_400de0_get_time_renamed_(%struct.State* nonnull %0, i64 %59, %struct.Memory* %2)
  %65 = load i64, i64* %RBP, align 8
  %66 = add i64 %65, -64
  %67 = load i64, i64* %PC, align 8
  %68 = add i64 %67, 5
  store i64 %68, i64* %PC, align 8
  %69 = bitcast [32 x %union.VectorReg]* %6 to double*
  %70 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %71 = load i64, i64* %70, align 1
  %72 = inttoptr i64 %66 to i64*
  store i64 %71, i64* %72, align 8
  %73 = load i64, i64* %PC, align 8
  %74 = add i64 %73, 1454
  %75 = add i64 %73, 5
  %76 = load i64, i64* %RSP, align 8, !tbaa !2428
  %77 = add i64 %76, -8
  %78 = inttoptr i64 %77 to i64*
  store i64 %75, i64* %78, align 8
  store i64 %77, i64* %RSP, align 8, !tbaa !2428
  store i64 %74, i64* %PC, align 8, !tbaa !2428
  %79 = tail call %struct.Memory* @sub_400de0_get_time_renamed_(%struct.State* nonnull %0, i64 %74, %struct.Memory* %64)
  %80 = load i64, i64* %RBP, align 8
  %81 = add i64 %80, -72
  %82 = load i64, i64* %PC, align 8
  %83 = add i64 %82, 5
  store i64 %83, i64* %PC, align 8
  %84 = load i64, i64* %70, align 1
  %85 = inttoptr i64 %81 to i64*
  store i64 %84, i64* %85, align 8
  %86 = bitcast [32 x %union.VectorReg]* %6 to i8*
  %87 = load i64, i64* %RBP, align 8
  %88 = add i64 %87, -72
  %89 = load i64, i64* %PC, align 8
  %90 = add i64 %89, 5
  store i64 %90, i64* %PC, align 8
  %91 = inttoptr i64 %88 to double*
  %92 = load double, double* %91, align 8
  store double %92, double* %69, align 1, !tbaa !2452
  %93 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %94 = bitcast i64* %93 to double*
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %95 = bitcast %union.VectorReg* %7 to i8*
  %96 = add i64 %87, -64
  %97 = add i64 %89, 10
  store i64 %97, i64* %PC, align 8
  %98 = inttoptr i64 %96 to double*
  %99 = load double, double* %98, align 8
  %100 = bitcast %union.VectorReg* %7 to double*
  store double %99, double* %100, align 1, !tbaa !2452
  %101 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %102 = bitcast i64* %101 to double*
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %103 = fsub double %92, %99
  %104 = add i64 %87, -80
  %105 = add i64 %89, 19
  store i64 %105, i64* %PC, align 8
  %106 = inttoptr i64 %104 to double*
  store double %103, double* %106, align 8
  %107 = load i64, i64* %PC, align 8
  %108 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 24) to i64*), align 8
  store i64 %108, i64* %70, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %109 = add i64 %107, -335
  %110 = add i64 %107, 13
  %111 = load i64, i64* %RSP, align 8, !tbaa !2428
  %112 = add i64 %111, -8
  %113 = inttoptr i64 %112 to i64*
  store i64 %110, i64* %113, align 8
  store i64 %112, i64* %RSP, align 8, !tbaa !2428
  store i64 %109, i64* %PC, align 8, !alias.scope !2477, !noalias !2480
  %114 = load double, double* %69, align 8, !alias.scope !2477, !noalias !2480
  %115 = load i64, i64* %113, align 8
  store i64 %111, i64* %RSP, align 8, !alias.scope !2477, !noalias !2480
  %116 = tail call double @sqrt(double %114)
  store i64 0, i64* %70, align 8
  store i64 0, i64* %93, align 8
  %117 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %117, align 8
  %118 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %118, align 8
  %119 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 32) to double*), align 16
  %120 = bitcast i64* %93 to <2 x i32>*
  %121 = load <2 x i32>, <2 x i32>* %120, align 1
  %122 = fmul double %116, %119
  store double %122, double* %69, align 1, !tbaa !2452
  %123 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 40) to double*), align 8
  store double %123, double* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %124 = bitcast %union.VectorReg* %8 to i8*
  %125 = bitcast double %122 to <2 x i32>
  %126 = extractelement <2 x i32> %125, i32 0
  %127 = bitcast %union.VectorReg* %8 to i32*
  store i32 %126, i32* %127, align 1, !tbaa !2475
  %128 = extractelement <2 x i32> %125, i32 1
  %129 = getelementptr inbounds i8, i8* %124, i64 4
  %130 = bitcast i8* %129 to i32*
  store i32 %128, i32* %130, align 1, !tbaa !2475
  %131 = extractelement <2 x i32> %121, i32 0
  %132 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %133 = bitcast i64* %132 to i32*
  store i32 %131, i32* %133, align 1, !tbaa !2475
  %134 = extractelement <2 x i32> %121, i32 1
  %135 = getelementptr inbounds i8, i8* %124, i64 12
  %136 = bitcast i8* %135 to i32*
  store i32 %134, i32* %136, align 1, !tbaa !2475
  %137 = bitcast %union.VectorReg* %8 to double*
  %138 = load double, double* %137, align 1
  %139 = fsub double %138, %123
  store double %139, double* %137, align 1, !tbaa !2452
  %140 = tail call double @llvm.trunc.f64(double %139) #10
  %141 = tail call double @llvm.fabs.f64(double %140) #10
  %142 = fcmp ogt double %141, 0x43E0000000000000
  %143 = fptosi double %140 to i64
  %.op = xor i64 %143, -9223372036854775808
  %144 = select i1 %142, i64 0, i64 %.op
  store i64 %144, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %19, align 1, !tbaa !2433
  %145 = trunc i64 %144 to i32
  %146 = and i32 %145, 255
  %147 = tail call i32 @llvm.ctpop.i32(i32 %146) #10
  %148 = trunc i32 %147 to i8
  %149 = and i8 %148, 1
  %150 = xor i8 %149, 1
  store i8 %150, i8* %26, align 1, !tbaa !2447
  %151 = icmp eq i64 %144, 0
  %152 = zext i1 %151 to i8
  store i8 %152, i8* %34, align 1, !tbaa !2448
  %153 = lshr i64 %144, 63
  %154 = trunc i64 %153 to i8
  store i8 %154, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  store i8 0, i8* %31, align 1, !tbaa !2451
  %155 = tail call double @llvm.trunc.f64(double %122) #10
  %156 = tail call double @llvm.fabs.f64(double %155) #10
  %157 = fcmp ogt double %156, 0x43E0000000000000
  %158 = fptosi double %155 to i64
  %159 = select i1 %157, i64 -9223372036854775808, i64 %158
  store i64 %159, i64* %RCX, align 8, !tbaa !2428
  %160 = add i64 %115, 54
  store i64 %160, i64* %PC, align 8
  %161 = fcmp uno double %122, %123
  br i1 %161, label %162, label %172

; <label>:162:                                    ; preds = %block_400800
  %163 = fadd double %122, %123
  %164 = bitcast double %163 to i64
  %165 = and i64 %164, 9221120237041090560
  %166 = icmp eq i64 %165, 9218868437227405312
  %167 = and i64 %164, 2251799813685247
  %168 = icmp ne i64 %167, 0
  %169 = and i1 %166, %168
  br i1 %169, label %170, label %178

; <label>:170:                                    ; preds = %162
  %171 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %160, %struct.Memory* %79) #11
  %.pre = load i64, i64* %RCX, align 8
  %.pre1 = load i64, i64* %PC, align 8
  %.pre2 = load i8, i8* %19, align 1, !tbaa !2433
  %.pre3 = load i64, i64* %RDI, align 8, !tbaa !2428
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3

; <label>:172:                                    ; preds = %block_400800
  %173 = fcmp ogt double %122, %123
  br i1 %173, label %178, label %174

; <label>:174:                                    ; preds = %172
  %175 = fcmp olt double %122, %123
  br i1 %175, label %178, label %176

; <label>:176:                                    ; preds = %174
  %177 = fcmp oeq double %122, %123
  br i1 %177, label %178, label %182

; <label>:178:                                    ; preds = %176, %174, %172, %162
  %179 = phi i8 [ 0, %172 ], [ 0, %174 ], [ 1, %176 ], [ 1, %162 ]
  %180 = phi i8 [ 0, %172 ], [ 0, %174 ], [ 0, %176 ], [ 1, %162 ]
  %181 = phi i8 [ 0, %172 ], [ 1, %174 ], [ 0, %176 ], [ 1, %162 ]
  store i8 %179, i8* %34, align 1, !tbaa !2432
  store i8 %180, i8* %26, align 1, !tbaa !2432
  store i8 %181, i8* %19, align 1, !tbaa !2432
  br label %182

; <label>:182:                                    ; preds = %178, %176
  %183 = phi i8 [ %181, %178 ], [ 0, %176 ]
  store i8 0, i8* %43, align 1, !tbaa !2432
  store i8 0, i8* %37, align 1, !tbaa !2432
  store i8 0, i8* %31, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3: ; preds = %182, %170
  %184 = phi i64 [ %.pre3, %170 ], [ %144, %182 ]
  %185 = phi i8 [ %.pre2, %170 ], [ %183, %182 ]
  %186 = phi i64 [ %.pre1, %170 ], [ %160, %182 ]
  %187 = phi i64 [ %.pre, %170 ], [ %159, %182 ]
  %188 = phi %struct.Memory* [ %171, %170 ], [ %79, %182 ]
  %189 = icmp ne i8 %185, 0
  %190 = select i1 %189, i64 %187, i64 %184
  store i64 %190, i64* %RDI, align 8, !tbaa !2428
  %191 = load i64, i64* %RBP, align 8
  %192 = add i64 %191, -144
  %193 = add i64 %186, 11
  store i64 %193, i64* %PC, align 8
  %194 = inttoptr i64 %192 to i64*
  %195 = load i64, i64* %194, align 8
  store i64 %195, i64* %RCX, align 8, !tbaa !2428
  %196 = add i64 %191, -152
  %197 = add i64 %186, 18
  store i64 %197, i64* %PC, align 8
  %198 = inttoptr i64 %196 to i64*
  store i64 %190, i64* %198, align 8
  %199 = load i64, i64* %RCX, align 8
  %200 = load i64, i64* %PC, align 8
  store i64 %199, i64* %RDI, align 8, !tbaa !2428
  %201 = load i64, i64* %RBP, align 8
  %202 = add i64 %201, -152
  %203 = add i64 %200, 10
  store i64 %203, i64* %PC, align 8
  %204 = inttoptr i64 %202 to i64*
  %205 = load i64, i64* %204, align 8
  store i64 %205, i64* %RSI, align 8, !tbaa !2428
  %206 = add i64 %200, -452
  %207 = add i64 %200, 15
  %208 = load i64, i64* %RSP, align 8, !tbaa !2428
  %209 = add i64 %208, -8
  %210 = inttoptr i64 %209 to i64*
  store i64 %207, i64* %210, align 8
  store i64 %209, i64* %RSP, align 8, !tbaa !2428
  store i64 %206, i64* %PC, align 8, !tbaa !2428
  %211 = tail call fastcc %struct.Memory* @ext_4006e0_memalign(%struct.State* nonnull %0, %struct.Memory* %188)
  %212 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 20480, i64* %RDX, align 8, !tbaa !2428
  store i64 20480, i64* %RSI, align 8, !tbaa !2428
  %213 = load i64, i64* %RBP, align 8
  %214 = add i64 %213, -24
  %215 = load i64, i64* %RAX, align 8
  %216 = add i64 %212, 18
  store i64 %216, i64* %PC, align 8
  %217 = inttoptr i64 %214 to i64*
  store i64 %215, i64* %217, align 8
  %218 = load i64, i64* %PC, align 8
  %219 = add i64 %218, -485
  %220 = add i64 %218, 5
  %221 = load i64, i64* %RSP, align 8, !tbaa !2428
  %222 = add i64 %221, -8
  %223 = inttoptr i64 %222 to i64*
  store i64 %220, i64* %223, align 8
  store i64 %222, i64* %RSP, align 8, !tbaa !2428
  store i64 %219, i64* %PC, align 8, !tbaa !2428
  %224 = tail call fastcc %struct.Memory* @ext_4006e0_memalign(%struct.State* nonnull %0, %struct.Memory* %211)
  %225 = load i64, i64* %PC, align 8
  store i64 512, i64* %RDI, align 8, !tbaa !2428
  %226 = load i64, i64* %RBP, align 8
  %227 = add i64 %226, -56
  %228 = load i64, i64* %RAX, align 8
  %229 = add i64 %225, 9
  store i64 %229, i64* %PC, align 8
  %230 = inttoptr i64 %227 to i64*
  store i64 %228, i64* %230, align 8
  %231 = load i64, i64* %RBP, align 8
  %232 = add i64 %231, -24
  %233 = load i64, i64* %PC, align 8
  %234 = add i64 %233, 4
  store i64 %234, i64* %PC, align 8
  %235 = inttoptr i64 %232 to i64*
  %236 = load i64, i64* %235, align 8
  store i64 %236, i64* %RSI, align 8, !tbaa !2428
  %237 = add i64 %231, -56
  %238 = add i64 %233, 8
  store i64 %238, i64* %PC, align 8
  %239 = inttoptr i64 %237 to i64*
  %240 = load i64, i64* %239, align 8
  store i64 %240, i64* %RDX, align 8, !tbaa !2428
  %241 = add i64 %233, 1373
  %242 = add i64 %233, 13
  %243 = load i64, i64* %RSP, align 8, !tbaa !2428
  %244 = add i64 %243, -8
  %245 = inttoptr i64 %244 to i64*
  store i64 %242, i64* %245, align 8
  store i64 %244, i64* %RSP, align 8, !tbaa !2428
  store i64 %241, i64* %PC, align 8, !tbaa !2428
  %246 = tail call %struct.Memory* @sub_400e30_makewt_renamed_(%struct.State* nonnull %0, i64 %241, %struct.Memory* %224)
  %247 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 16384, i64* %R8, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %248 = add i64 %247, -512
  %249 = add i64 %247, 19
  %250 = load i64, i64* %RSP, align 8, !tbaa !2428
  %251 = add i64 %250, -8
  %252 = inttoptr i64 %251 to i64*
  store i64 %249, i64* %252, align 8
  store i64 %251, i64* %RSP, align 8, !tbaa !2428
  store i64 %248, i64* %PC, align 8, !tbaa !2428
  %253 = tail call fastcc %struct.Memory* @ext_4006e0_memalign(%struct.State* nonnull %0, %struct.Memory* %246)
  %254 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 16384, i64* %R8, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %255 = load i64, i64* %RBP, align 8
  %256 = add i64 %255, -32
  %257 = load i64, i64* %RAX, align 8
  %258 = add i64 %254, 22
  store i64 %258, i64* %PC, align 8
  %259 = inttoptr i64 %256 to i64*
  store i64 %257, i64* %259, align 8
  %260 = load i64, i64* %PC, align 8
  %261 = add i64 %260, -553
  %262 = add i64 %260, 5
  %263 = load i64, i64* %RSP, align 8, !tbaa !2428
  %264 = add i64 %263, -8
  %265 = inttoptr i64 %264 to i64*
  store i64 %262, i64* %265, align 8
  store i64 %264, i64* %RSP, align 8, !tbaa !2428
  store i64 %261, i64* %PC, align 8, !tbaa !2428
  %266 = tail call fastcc %struct.Memory* @ext_4006e0_memalign(%struct.State* nonnull %0, %struct.Memory* %253)
  %267 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 16384, i64* %R8, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %268 = load i64, i64* %RBP, align 8
  %269 = add i64 %268, -40
  %270 = load i64, i64* %RAX, align 8
  %271 = add i64 %267, 22
  store i64 %271, i64* %PC, align 8
  %272 = inttoptr i64 %269 to i64*
  store i64 %270, i64* %272, align 8
  %273 = load i64, i64* %PC, align 8
  %274 = add i64 %273, -580
  %275 = add i64 %273, 5
  %276 = load i64, i64* %RSP, align 8, !tbaa !2428
  %277 = add i64 %276, -8
  %278 = inttoptr i64 %277 to i64*
  store i64 %275, i64* %278, align 8
  store i64 %277, i64* %RSP, align 8, !tbaa !2428
  store i64 %274, i64* %PC, align 8, !tbaa !2428
  %279 = tail call fastcc %struct.Memory* @ext_4006e0_memalign(%struct.State* nonnull %0, %struct.Memory* %266)
  %280 = load i64, i64* %PC, align 8
  store i64 0, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %19, align 1, !tbaa !2433
  store i8 1, i8* %26, align 1, !tbaa !2447
  store i8 1, i8* %34, align 1, !tbaa !2448
  store i8 0, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  store i8 0, i8* %31, align 1, !tbaa !2451
  store i64 2047, i64* %RSI, align 8, !tbaa !2428
  %281 = load i64, i64* %RBP, align 8
  %282 = add i64 %281, -48
  %283 = load i64, i64* %RAX, align 8
  %284 = add i64 %280, 11
  store i64 %284, i64* %PC, align 8
  %285 = inttoptr i64 %282 to i64*
  store i64 %283, i64* %285, align 8
  %286 = load i64, i64* %RBP, align 8
  %287 = add i64 %286, -32
  %288 = load i64, i64* %PC, align 8
  %289 = add i64 %288, 4
  store i64 %289, i64* %PC, align 8
  %290 = inttoptr i64 %287 to i64*
  %291 = load i64, i64* %290, align 8
  store i64 %291, i64* %RDX, align 8, !tbaa !2428
  %292 = add i64 %288, 1660
  %293 = add i64 %288, 9
  %294 = load i64, i64* %RSP, align 8, !tbaa !2428
  %295 = add i64 %294, -8
  %296 = inttoptr i64 %295 to i64*
  store i64 %293, i64* %296, align 8
  store i64 %295, i64* %RSP, align 8, !tbaa !2428
  store i64 %292, i64* %PC, align 8, !tbaa !2428
  %297 = tail call %struct.Memory* @sub_400fb0_putdata_renamed_(%struct.State* nonnull %0, i64 %292, %struct.Memory* %279)
  %298 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  %299 = load i64, i64* %RBP, align 8
  %300 = add i64 %299, -32
  %301 = add i64 %298, 14
  store i64 %301, i64* %PC, align 8
  %302 = inttoptr i64 %300 to i64*
  %303 = load i64, i64* %302, align 8
  store i64 %303, i64* %RDX, align 8, !tbaa !2428
  %304 = add i64 %299, -24
  %305 = add i64 %298, 18
  store i64 %305, i64* %PC, align 8
  %306 = inttoptr i64 %304 to i64*
  %307 = load i64, i64* %306, align 8
  store i64 %307, i64* %RCX, align 8, !tbaa !2428
  %308 = add i64 %299, -56
  %309 = add i64 %298, 22
  store i64 %309, i64* %PC, align 8
  %310 = inttoptr i64 %308 to i64*
  %311 = load i64, i64* %310, align 8
  store i64 %311, i64* %R8, align 8, !tbaa !2428
  %312 = add i64 %298, 1779
  %313 = add i64 %298, 27
  %314 = load i64, i64* %RSP, align 8, !tbaa !2428
  %315 = add i64 %314, -8
  %316 = inttoptr i64 %315 to i64*
  store i64 %313, i64* %316, align 8
  store i64 %315, i64* %RSP, align 8, !tbaa !2428
  store i64 %312, i64* %PC, align 8, !tbaa !2428
  %317 = tail call %struct.Memory* @sub_401030_cdft_renamed_(%struct.State* nonnull %0, i64 %312, %struct.Memory* %297)
  %318 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 4294967295, i64* %RSI, align 8, !tbaa !2428
  %319 = load i64, i64* %RBP, align 8
  %320 = add i64 %319, -32
  %321 = add i64 %318, 14
  store i64 %321, i64* %PC, align 8
  %322 = inttoptr i64 %320 to i64*
  %323 = load i64, i64* %322, align 8
  store i64 %323, i64* %RDX, align 8, !tbaa !2428
  %324 = add i64 %319, -24
  %325 = add i64 %318, 18
  store i64 %325, i64* %PC, align 8
  %326 = inttoptr i64 %324 to i64*
  %327 = load i64, i64* %326, align 8
  store i64 %327, i64* %RCX, align 8, !tbaa !2428
  %328 = add i64 %319, -56
  %329 = add i64 %318, 22
  store i64 %329, i64* %PC, align 8
  %330 = inttoptr i64 %328 to i64*
  %331 = load i64, i64* %330, align 8
  store i64 %331, i64* %R8, align 8, !tbaa !2428
  %332 = add i64 %318, 1752
  %333 = add i64 %318, 27
  %334 = load i64, i64* %RSP, align 8, !tbaa !2428
  %335 = add i64 %334, -8
  %336 = inttoptr i64 %335 to i64*
  store i64 %333, i64* %336, align 8
  store i64 %335, i64* %RSP, align 8, !tbaa !2428
  store i64 %332, i64* %PC, align 8, !tbaa !2428
  %337 = tail call %struct.Memory* @sub_401030_cdft_renamed_(%struct.State* nonnull %0, i64 %332, %struct.Memory* %317)
  %338 = load i64, i64* %PC, align 8
  store i64 0, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %19, align 1, !tbaa !2433
  store i8 1, i8* %26, align 1, !tbaa !2447
  store i8 1, i8* %34, align 1, !tbaa !2448
  store i8 0, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  store i8 0, i8* %31, align 1, !tbaa !2451
  store i64 2047, i64* %RSI, align 8, !tbaa !2428
  %339 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 16) to i64*), align 16
  store i64 %339, i64* %70, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %340 = load i64, i64* %RBP, align 8
  %341 = add i64 %340, -32
  %342 = add i64 %338, 19
  store i64 %342, i64* %PC, align 8
  %343 = inttoptr i64 %341 to i64*
  %344 = load i64, i64* %343, align 8
  store i64 %344, i64* %RDX, align 8, !tbaa !2428
  %345 = add i64 %338, 1885
  %346 = add i64 %338, 24
  %347 = load i64, i64* %RSP, align 8, !tbaa !2428
  %348 = add i64 %347, -8
  %349 = inttoptr i64 %348 to i64*
  store i64 %346, i64* %349, align 8
  store i64 %348, i64* %RSP, align 8, !tbaa !2428
  store i64 %345, i64* %PC, align 8, !tbaa !2428
  %350 = tail call %struct.Memory* @sub_4010d0_errorcheck_renamed_(%struct.State* nonnull %0, i64 %345, %struct.Memory* %337)
  %351 = load i64, i64* %PC, align 8
  %352 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 8) to i64*), align 8
  %353 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %7, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %352, i64* %353, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %354 = load i64, i64* %RBP, align 8
  %355 = add i64 %354, -96
  %356 = add i64 %351, 13
  store i64 %356, i64* %PC, align 8
  %357 = load i64, i64* %70, align 1
  %358 = inttoptr i64 %355 to i64*
  store i64 %357, i64* %358, align 8
  %359 = load i64, i64* %RBP, align 8
  %360 = add i64 %359, -96
  %361 = load i64, i64* %PC, align 8
  %362 = add i64 %361, 5
  store i64 %362, i64* %PC, align 8
  %363 = inttoptr i64 %360 to i64*
  %364 = load i64, i64* %363, align 8
  %365 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 96) to i32*), align 16
  %366 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 100) to i32*), align 4
  %367 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 104) to i32*), align 8
  %368 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 108) to i32*), align 4
  store i32 %365, i32* %127, align 1, !tbaa !2475
  store i32 %366, i32* %130, align 1, !tbaa !2475
  store i32 %367, i32* %133, align 1, !tbaa !2475
  store i32 %368, i32* %136, align 1, !tbaa !2475
  %369 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %8, i64 0, i32 0, i32 0, i32 0, i64 0
  %370 = load i64, i64* %369, align 1
  %371 = and i64 %370, %364
  %372 = trunc i64 %371 to i32
  %373 = lshr i64 %371, 32
  %374 = trunc i64 %373 to i32
  %375 = bitcast [32 x %union.VectorReg]* %6 to i32*
  store i32 %372, i32* %375, align 1, !tbaa !2459
  %376 = getelementptr inbounds i8, i8* %86, i64 4
  %377 = bitcast i8* %376 to i32*
  store i32 %374, i32* %377, align 1, !tbaa !2459
  %378 = bitcast i64* %93 to i32*
  store i32 0, i32* %378, align 1, !tbaa !2459
  %379 = getelementptr inbounds i8, i8* %86, i64 12
  %380 = bitcast i8* %379 to i32*
  store i32 0, i32* %380, align 1, !tbaa !2459
  %381 = add i64 %361, 20
  store i64 %381, i64* %PC, align 8
  %382 = load double, double* %69, align 1
  %383 = load double, double* %100, align 1
  %384 = fcmp uno double %382, %383
  br i1 %384, label %385, label %395

; <label>:385:                                    ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3
  %386 = fadd double %382, %383
  %387 = bitcast double %386 to i64
  %388 = and i64 %387, 9221120237041090560
  %389 = icmp eq i64 %388, 9218868437227405312
  %390 = and i64 %387, 2251799813685247
  %391 = icmp ne i64 %390, 0
  %392 = and i1 %389, %391
  br i1 %392, label %393, label %401

; <label>:393:                                    ; preds = %385
  %394 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %381, %struct.Memory* %350) #11
  %.pre4 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2

; <label>:395:                                    ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3
  %396 = fcmp ogt double %382, %383
  br i1 %396, label %401, label %397

; <label>:397:                                    ; preds = %395
  %398 = fcmp olt double %382, %383
  br i1 %398, label %401, label %399

; <label>:399:                                    ; preds = %397
  %400 = fcmp oeq double %382, %383
  br i1 %400, label %401, label %405

; <label>:401:                                    ; preds = %399, %397, %395, %385
  %402 = phi i8 [ 0, %395 ], [ 0, %397 ], [ 1, %399 ], [ 1, %385 ]
  %403 = phi i8 [ 0, %395 ], [ 0, %397 ], [ 0, %399 ], [ 1, %385 ]
  %404 = phi i8 [ 0, %395 ], [ 1, %397 ], [ 0, %399 ], [ 1, %385 ]
  store i8 %402, i8* %34, align 1, !tbaa !2432
  store i8 %403, i8* %26, align 1, !tbaa !2432
  store i8 %404, i8* %19, align 1, !tbaa !2432
  br label %405

; <label>:405:                                    ; preds = %401, %399
  store i8 0, i8* %43, align 1, !tbaa !2432
  store i8 0, i8* %37, align 1, !tbaa !2432
  store i8 0, i8* %31, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2: ; preds = %405, %393
  %406 = phi i64 [ %.pre4, %393 ], [ %381, %405 ]
  %407 = phi %struct.Memory* [ %394, %393 ], [ %350, %405 ]
  %408 = load i8, i8* %19, align 1, !tbaa !2433
  %409 = load i8, i8* %34, align 1, !tbaa !2448
  %410 = or i8 %409, %408
  %411 = icmp ne i8 %410, 0
  %.v = select i1 %411, i64 39, i64 6
  %412 = add i64 %406, %.v
  store i64 %412, i64* %PC, align 8, !tbaa !2428
  br i1 %411, label %block_4009d3, label %block_4009b2

block_400c14:                                     ; preds = %block_400b37
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 4294967295, i64* %RSI, align 8, !tbaa !2428
  %413 = add i64 %1095, -40
  %414 = add i64 %1123, 14
  store i64 %414, i64* %PC, align 8
  %415 = inttoptr i64 %413 to i64*
  %416 = load i64, i64* %415, align 8
  store i64 %416, i64* %RDX, align 8, !tbaa !2428
  %417 = add i64 %1095, -24
  %418 = add i64 %1123, 18
  store i64 %418, i64* %PC, align 8
  %419 = inttoptr i64 %417 to i64*
  %420 = load i64, i64* %419, align 8
  store i64 %420, i64* %RCX, align 8, !tbaa !2428
  %421 = add i64 %1095, -56
  %422 = add i64 %1123, 22
  store i64 %422, i64* %PC, align 8
  %423 = inttoptr i64 %421 to i64*
  %424 = load i64, i64* %423, align 8
  store i64 %424, i64* %R8, align 8, !tbaa !2428
  %425 = add i64 %1123, 1052
  %426 = add i64 %1123, 27
  %427 = load i64, i64* %RSP, align 8, !tbaa !2428
  %428 = add i64 %427, -8
  %429 = inttoptr i64 %428 to i64*
  store i64 %426, i64* %429, align 8
  store i64 %428, i64* %RSP, align 8, !tbaa !2428
  store i64 %425, i64* %PC, align 8, !tbaa !2428
  %430 = tail call %struct.Memory* @sub_401030_cdft_renamed_(%struct.State* nonnull %0, i64 %425, %struct.Memory* %518)
  %431 = load i64, i64* %RBP, align 8
  %432 = add i64 %431, -8
  %433 = load i64, i64* %PC, align 8
  %434 = add i64 %433, 3
  store i64 %434, i64* %PC, align 8
  %435 = inttoptr i64 %432 to i32*
  %436 = load i32, i32* %435, align 4
  %437 = add i32 %436, 1
  %438 = zext i32 %437 to i64
  store i64 %438, i64* %RAX, align 8, !tbaa !2428
  %439 = icmp eq i32 %436, -1
  %440 = icmp eq i32 %437, 0
  %441 = or i1 %439, %440
  %442 = zext i1 %441 to i8
  store i8 %442, i8* %19, align 1, !tbaa !2433
  %443 = and i32 %437, 255
  %444 = tail call i32 @llvm.ctpop.i32(i32 %443) #10
  %445 = trunc i32 %444 to i8
  %446 = and i8 %445, 1
  %447 = xor i8 %446, 1
  store i8 %447, i8* %26, align 1, !tbaa !2447
  %448 = xor i32 %436, %437
  %449 = lshr i32 %448, 4
  %450 = trunc i32 %449 to i8
  %451 = and i8 %450, 1
  store i8 %451, i8* %31, align 1, !tbaa !2451
  %452 = zext i1 %440 to i8
  store i8 %452, i8* %34, align 1, !tbaa !2448
  %453 = lshr i32 %437, 31
  %454 = trunc i32 %453 to i8
  store i8 %454, i8* %37, align 1, !tbaa !2449
  %455 = lshr i32 %436, 31
  %456 = xor i32 %453, %455
  %457 = add nuw nsw i32 %456, %453
  %458 = icmp eq i32 %457, 2
  %459 = zext i1 %458 to i8
  store i8 %459, i8* %43, align 1, !tbaa !2450
  %460 = add i64 %433, 9
  store i64 %460, i64* %PC, align 8
  store i32 %437, i32* %435, align 4
  %461 = load i64, i64* %PC, align 8
  %462 = add i64 %461, -354
  store i64 %462, i64* %PC, align 8, !tbaa !2428
  br label %block_400ad6

block_400ae3:                                     ; preds = %block_400ad6
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RAX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %463 = add i64 %597, -40
  %464 = add i64 %626, 21
  store i64 %464, i64* %PC, align 8
  %465 = inttoptr i64 %463 to i64*
  %466 = load i64, i64* %465, align 8
  store i64 %466, i64* %RCX, align 8, !tbaa !2428
  %467 = add i64 %597, -48
  %468 = add i64 %626, 25
  store i64 %468, i64* %PC, align 8
  %469 = inttoptr i64 %467 to i64*
  %470 = load i64, i64* %469, align 8
  store i64 %470, i64* %R8, align 8, !tbaa !2428
  %471 = add i64 %597, -176
  %472 = add i64 %626, 31
  store i64 %472, i64* %PC, align 8
  %473 = inttoptr i64 %471 to i32*
  store i32 2048, i32* %473, align 4
  %474 = load i64, i64* %RCX, align 8
  %475 = load i64, i64* %PC, align 8
  store i64 %474, i64* %RDI, align 8, !tbaa !2428
  %476 = load i64, i64* %RBP, align 8
  %477 = add i64 %476, -180
  %478 = load i32, i32* %ESI, align 4
  %479 = add i64 %475, 9
  store i64 %479, i64* %PC, align 8
  %480 = inttoptr i64 %477 to i32*
  store i32 %478, i32* %480, align 4
  %481 = load i64, i64* %R8, align 8
  %482 = load i64, i64* %PC, align 8
  store i64 %481, i64* %RSI, align 8, !tbaa !2428
  %483 = add i64 %482, -1083
  %484 = add i64 %482, 8
  %485 = load i64, i64* %RSP, align 8, !tbaa !2428
  %486 = add i64 %485, -8
  %487 = inttoptr i64 %486 to i64*
  store i64 %484, i64* %487, align 8
  store i64 %486, i64* %RSP, align 8, !tbaa !2428
  store i64 %483, i64* %PC, align 8, !tbaa !2428
  %488 = tail call fastcc %struct.Memory* @ext_605128_memcpy(%struct.State* nonnull %0, %struct.Memory* %MEMORY.0)
  %489 = load i64, i64* %RBP, align 8
  %490 = add i64 %489, -40
  %491 = load i64, i64* %PC, align 8
  %492 = add i64 %491, 4
  store i64 %492, i64* %PC, align 8
  %493 = inttoptr i64 %490 to i64*
  %494 = load i64, i64* %493, align 8
  store i64 %494, i64* %RDX, align 8, !tbaa !2428
  %495 = add i64 %489, -24
  %496 = add i64 %491, 8
  store i64 %496, i64* %PC, align 8
  %497 = inttoptr i64 %495 to i64*
  %498 = load i64, i64* %497, align 8
  store i64 %498, i64* %RCX, align 8, !tbaa !2428
  %499 = add i64 %489, -56
  %500 = add i64 %491, 12
  store i64 %500, i64* %PC, align 8
  %501 = inttoptr i64 %499 to i64*
  %502 = load i64, i64* %501, align 8
  store i64 %502, i64* %R8, align 8, !tbaa !2428
  %503 = add i64 %489, -176
  %504 = add i64 %491, 18
  store i64 %504, i64* %PC, align 8
  %505 = inttoptr i64 %503 to i32*
  %506 = load i32, i32* %505, align 4
  %507 = zext i32 %506 to i64
  store i64 %507, i64* %RDI, align 8, !tbaa !2428
  %508 = add i64 %489, -180
  %509 = add i64 %491, 24
  store i64 %509, i64* %PC, align 8
  %510 = inttoptr i64 %508 to i32*
  %511 = load i32, i32* %510, align 4
  %512 = zext i32 %511 to i64
  store i64 %512, i64* %RSI, align 8, !tbaa !2428
  %513 = add i64 %491, 1309
  %514 = add i64 %491, 29
  %515 = load i64, i64* %RSP, align 8, !tbaa !2428
  %516 = add i64 %515, -8
  %517 = inttoptr i64 %516 to i64*
  store i64 %514, i64* %517, align 8
  store i64 %516, i64* %RSP, align 8, !tbaa !2428
  store i64 %513, i64* %PC, align 8, !tbaa !2428
  %518 = tail call %struct.Memory* @sub_401030_cdft_renamed_(%struct.State* nonnull %0, i64 %513, %struct.Memory* %488)
  %519 = load i64, i64* %RBP, align 8
  %520 = add i64 %519, -100
  %521 = load i64, i64* %PC, align 8
  %522 = add i64 %521, 7
  store i64 %522, i64* %PC, align 8
  %523 = inttoptr i64 %520 to i32*
  store i32 0, i32* %523, align 4
  %.pre7 = load i64, i64* %PC, align 8
  br label %block_400b37

block_400c74:                                     ; preds = %block_400c67
  %524 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 48) to double*), align 16
  store double %524, double* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %525 = add i64 %1552, -40
  %526 = add i64 %1580, 12
  store i64 %526, i64* %PC, align 8
  %527 = inttoptr i64 %525 to i64*
  %528 = load i64, i64* %527, align 8
  store i64 %528, i64* %RAX, align 8, !tbaa !2428
  %529 = add i64 %1580, 15
  store i64 %529, i64* %PC, align 8
  %530 = load i32, i32* %1555, align 4
  %531 = shl i32 %530, 1
  %532 = icmp slt i32 %530, 0
  %533 = icmp slt i32 %531, 0
  %534 = xor i1 %532, %533
  %535 = zext i32 %531 to i64
  store i64 %535, i64* %RCX, align 8, !tbaa !2428
  %.lobit34 = lshr i32 %530, 31
  %536 = trunc i32 %.lobit34 to i8
  store i8 %536, i8* %19, align 1, !tbaa !2432
  %537 = and i32 %531, 254
  %538 = tail call i32 @llvm.ctpop.i32(i32 %537) #10
  %539 = trunc i32 %538 to i8
  %540 = and i8 %539, 1
  %541 = xor i8 %540, 1
  store i8 %541, i8* %26, align 1, !tbaa !2432
  store i8 0, i8* %31, align 1, !tbaa !2432
  %542 = icmp eq i32 %531, 0
  %543 = zext i1 %542 to i8
  store i8 %543, i8* %34, align 1, !tbaa !2432
  %544 = lshr i32 %530, 30
  %545 = trunc i32 %544 to i8
  %546 = and i8 %545, 1
  store i8 %546, i8* %37, align 1, !tbaa !2432
  %547 = zext i1 %534 to i8
  store i8 %547, i8* %43, align 1, !tbaa !2432
  %548 = sext i32 %531 to i64
  store i64 %548, i64* %RDX, align 8, !tbaa !2428
  %549 = shl nsw i64 %548, 3
  %550 = add i64 %549, %528
  %551 = add i64 %1580, 26
  store i64 %551, i64* %PC, align 8
  %552 = inttoptr i64 %550 to i64*
  %553 = load i64, i64* %552, align 8
  %554 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 96) to i32*), align 16
  %555 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 100) to i32*), align 4
  %556 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 104) to i32*), align 8
  %557 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 108) to i32*), align 4
  store i32 %554, i32* %127, align 1, !tbaa !2475
  store i32 %555, i32* %130, align 1, !tbaa !2475
  store i32 %556, i32* %133, align 1, !tbaa !2475
  store i32 %557, i32* %136, align 1, !tbaa !2475
  %558 = load i64, i64* %369, align 1
  %559 = and i64 %558, %553
  %560 = trunc i64 %559 to i32
  %561 = lshr i64 %559, 32
  %562 = trunc i64 %561 to i32
  store i32 %560, i32* %1081, align 1, !tbaa !2459
  store i32 %562, i32* %1083, align 1, !tbaa !2459
  store i32 0, i32* %1084, align 1, !tbaa !2459
  store i32 0, i32* %1086, align 1, !tbaa !2459
  %563 = add i64 %1580, 41
  store i64 %563, i64* %PC, align 8
  %564 = load double, double* %100, align 1
  %565 = fcmp uno double %564, %524
  br i1 %565, label %566, label %576

; <label>:566:                                    ; preds = %block_400c74
  %567 = fadd double %564, %524
  %568 = bitcast double %567 to i64
  %569 = and i64 %568, 9221120237041090560
  %570 = icmp eq i64 %569, 9218868437227405312
  %571 = and i64 %568, 2251799813685247
  %572 = icmp ne i64 %571, 0
  %573 = and i1 %570, %572
  br i1 %573, label %574, label %582

; <label>:574:                                    ; preds = %566
  %575 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %563, %struct.Memory* %MEMORY.5) #11
  %.pre9 = load i64, i64* %PC, align 8
  %.pre10 = load i8, i8* %19, align 1, !tbaa !2433
  %.pre11 = load i8, i8* %34, align 1, !tbaa !2448
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1

; <label>:576:                                    ; preds = %block_400c74
  %577 = fcmp ogt double %564, %524
  br i1 %577, label %582, label %578

; <label>:578:                                    ; preds = %576
  %579 = fcmp olt double %564, %524
  br i1 %579, label %582, label %580

; <label>:580:                                    ; preds = %578
  %581 = fcmp oeq double %564, %524
  br i1 %581, label %582, label %586

; <label>:582:                                    ; preds = %580, %578, %576, %566
  %583 = phi i8 [ 0, %576 ], [ 0, %578 ], [ 1, %580 ], [ 1, %566 ]
  %584 = phi i8 [ 0, %576 ], [ 0, %578 ], [ 0, %580 ], [ 1, %566 ]
  %585 = phi i8 [ 0, %576 ], [ 1, %578 ], [ 0, %580 ], [ 1, %566 ]
  store i8 %583, i8* %34, align 1, !tbaa !2432
  store i8 %584, i8* %26, align 1, !tbaa !2432
  store i8 %585, i8* %19, align 1, !tbaa !2432
  br label %586

; <label>:586:                                    ; preds = %582, %580
  %587 = phi i8 [ %583, %582 ], [ %543, %580 ]
  %588 = phi i8 [ %585, %582 ], [ %536, %580 ]
  store i8 0, i8* %43, align 1, !tbaa !2432
  store i8 0, i8* %37, align 1, !tbaa !2432
  store i8 0, i8* %31, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1: ; preds = %586, %574
  %589 = phi i8 [ %.pre11, %574 ], [ %587, %586 ]
  %590 = phi i8 [ %.pre10, %574 ], [ %588, %586 ]
  %591 = phi i64 [ %.pre9, %574 ], [ %563, %586 ]
  %592 = phi %struct.Memory* [ %575, %574 ], [ %MEMORY.5, %586 ]
  %593 = or i8 %589, %590
  %594 = icmp ne i8 %593, 0
  %.v35 = select i1 %594, i64 37, i64 6
  %595 = add i64 %591, %.v35
  store i64 %595, i64* %PC, align 8, !tbaa !2428
  br i1 %594, label %block_400cc2, label %block_400ca3

block_400ad6:                                     ; preds = %block_400a8b, %block_400c14
  %596 = phi i64 [ %.pre6, %block_400a8b ], [ %462, %block_400c14 ]
  %MEMORY.0 = phi %struct.Memory* [ %1539, %block_400a8b ], [ %430, %block_400c14 ]
  %597 = load i64, i64* %RBP, align 8
  %598 = add i64 %597, -8
  %599 = add i64 %596, 7
  store i64 %599, i64* %PC, align 8
  %600 = inttoptr i64 %598 to i32*
  %601 = load i32, i32* %600, align 4
  %602 = add i32 %601, -150000
  %603 = icmp ult i32 %601, 150000
  %604 = zext i1 %603 to i8
  store i8 %604, i8* %19, align 1, !tbaa !2433
  %605 = and i32 %602, 255
  %606 = tail call i32 @llvm.ctpop.i32(i32 %605) #10
  %607 = trunc i32 %606 to i8
  %608 = and i8 %607, 1
  %609 = xor i8 %608, 1
  store i8 %609, i8* %26, align 1, !tbaa !2447
  %610 = xor i32 %601, 16
  %611 = xor i32 %610, %602
  %612 = lshr i32 %611, 4
  %613 = trunc i32 %612 to i8
  %614 = and i8 %613, 1
  store i8 %614, i8* %31, align 1, !tbaa !2451
  %615 = icmp eq i32 %602, 0
  %616 = zext i1 %615 to i8
  store i8 %616, i8* %34, align 1, !tbaa !2448
  %617 = lshr i32 %602, 31
  %618 = trunc i32 %617 to i8
  store i8 %618, i8* %37, align 1, !tbaa !2449
  %619 = lshr i32 %601, 31
  %620 = xor i32 %617, %619
  %621 = add nuw nsw i32 %620, %619
  %622 = icmp eq i32 %621, 2
  %623 = zext i1 %622 to i8
  store i8 %623, i8* %43, align 1, !tbaa !2450
  %624 = icmp ne i8 %618, 0
  %625 = xor i1 %624, %622
  %.v29 = select i1 %625, i64 13, i64 359
  %626 = add i64 %596, %.v29
  store i64 %626, i64* %PC, align 8, !tbaa !2428
  br i1 %625, label %block_400ae3, label %block_400c3d

block_400cd2:                                     ; preds = %block_400ca3, %block_400cc2
  %.sink19.in = phi i64 [ %1241, %block_400ca3 ], [ %1039, %block_400cc2 ]
  %.sink = phi double [ %1272, %block_400ca3 ], [ %1041, %block_400cc2 ]
  %.sink17 = phi i64 [ 21, %block_400ca3 ], [ 5, %block_400cc2 ]
  %.sink19 = add i64 %.sink19.in, -192
  %627 = inttoptr i64 %.sink19 to double*
  store double %.sink, double* %627, align 8
  %628 = load i64, i64* %PC, align 8
  %629 = add i64 %628, %.sink17
  %630 = load i64, i64* %RBP, align 8
  %631 = add i64 %630, -192
  %632 = add i64 %629, 8
  store i64 %632, i64* %PC, align 8
  %633 = inttoptr i64 %631 to i64*
  %634 = load i64, i64* %633, align 8
  store i64 %634, i64* %70, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %635 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 48) to i64*), align 16
  store i64 %635, i64* %353, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %636 = add i64 %630, -40
  %637 = add i64 %629, 20
  store i64 %637, i64* %PC, align 8
  %638 = inttoptr i64 %636 to i64*
  %639 = load i64, i64* %638, align 8
  store i64 %639, i64* %RAX, align 8, !tbaa !2428
  %640 = add i64 %630, -12
  %641 = add i64 %629, 23
  store i64 %641, i64* %PC, align 8
  %642 = inttoptr i64 %640 to i32*
  %643 = load i32, i32* %642, align 4
  %644 = shl i32 %643, 1
  %645 = lshr i32 %643, 30
  %646 = and i32 %645, 1
  %647 = or i32 %644, 1
  %648 = zext i32 %647 to i64
  store i64 %648, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %19, align 1, !tbaa !2433
  %649 = and i32 %647, 255
  %650 = tail call i32 @llvm.ctpop.i32(i32 %649) #10
  %651 = trunc i32 %650 to i8
  %652 = and i8 %651, 1
  %653 = xor i8 %652, 1
  store i8 %653, i8* %26, align 1, !tbaa !2447
  store i8 0, i8* %31, align 1, !tbaa !2451
  store i8 0, i8* %34, align 1, !tbaa !2448
  %654 = trunc i32 %646 to i8
  store i8 %654, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  %655 = sext i32 %647 to i64
  store i64 %655, i64* %RDX, align 8, !tbaa !2428
  %656 = shl nsw i64 %655, 3
  %657 = add i64 %656, %639
  %658 = add i64 %629, 37
  store i64 %658, i64* %PC, align 8
  %659 = inttoptr i64 %657 to i64*
  %660 = load i64, i64* %659, align 8
  %661 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 96) to i32*), align 16
  %662 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 100) to i32*), align 4
  %663 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 104) to i32*), align 8
  %664 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 108) to i32*), align 4
  %665 = bitcast %union.VectorReg* %9 to i32*
  store i32 %661, i32* %665, align 1, !tbaa !2475
  %666 = bitcast i8* %1088 to i32*
  store i32 %662, i32* %666, align 1, !tbaa !2475
  %667 = bitcast i64* %1089 to i32*
  store i32 %663, i32* %667, align 1, !tbaa !2475
  %668 = bitcast i8* %1090 to i32*
  store i32 %664, i32* %668, align 1, !tbaa !2475
  %669 = load i64, i64* %1091, align 1
  %670 = and i64 %669, %660
  %671 = trunc i64 %670 to i32
  %672 = lshr i64 %670, 32
  %673 = trunc i64 %672 to i32
  store i32 %671, i32* %127, align 1, !tbaa !2459
  store i32 %673, i32* %130, align 1, !tbaa !2459
  store i32 0, i32* %133, align 1, !tbaa !2459
  store i32 0, i32* %136, align 1, !tbaa !2459
  %674 = add i64 %629, 52
  store i64 %674, i64* %PC, align 8
  %675 = load double, double* %137, align 1
  %676 = load double, double* %100, align 1
  %677 = fcmp uno double %675, %676
  br i1 %677, label %678, label %688

; <label>:678:                                    ; preds = %block_400cd2
  %679 = fadd double %675, %676
  %680 = bitcast double %679 to i64
  %681 = and i64 %680, 9221120237041090560
  %682 = icmp eq i64 %681, 9218868437227405312
  %683 = and i64 %680, 2251799813685247
  %684 = icmp ne i64 %683, 0
  %685 = and i1 %682, %684
  br i1 %685, label %686, label %694

; <label>:686:                                    ; preds = %678
  %687 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %674, %struct.Memory* %592) #11
  %.pre12 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

; <label>:688:                                    ; preds = %block_400cd2
  %689 = fcmp ogt double %675, %676
  br i1 %689, label %694, label %690

; <label>:690:                                    ; preds = %688
  %691 = fcmp olt double %675, %676
  br i1 %691, label %694, label %692

; <label>:692:                                    ; preds = %690
  %693 = fcmp oeq double %675, %676
  br i1 %693, label %694, label %698

; <label>:694:                                    ; preds = %692, %690, %688, %678
  %695 = phi i8 [ 0, %688 ], [ 0, %690 ], [ 1, %692 ], [ 1, %678 ]
  %696 = phi i8 [ 0, %688 ], [ 0, %690 ], [ 0, %692 ], [ 1, %678 ]
  %697 = phi i8 [ 0, %688 ], [ 1, %690 ], [ 0, %692 ], [ 1, %678 ]
  store i8 %695, i8* %34, align 1, !tbaa !2432
  store i8 %696, i8* %26, align 1, !tbaa !2432
  store i8 %697, i8* %19, align 1, !tbaa !2432
  br label %698

; <label>:698:                                    ; preds = %694, %692
  store i8 0, i8* %43, align 1, !tbaa !2432
  store i8 0, i8* %37, align 1, !tbaa !2432
  store i8 0, i8* %31, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit: ; preds = %698, %686
  %699 = phi i64 [ %.pre12, %686 ], [ %674, %698 ]
  %700 = phi %struct.Memory* [ %687, %686 ], [ %592, %698 ]
  %701 = load i64, i64* %RBP, align 8
  %702 = add i64 %701, -200
  %703 = add i64 %699, 8
  store i64 %703, i64* %PC, align 8
  %704 = load i64, i64* %70, align 1
  %705 = inttoptr i64 %702 to i64*
  store i64 %704, i64* %705, align 8
  %706 = load i64, i64* %PC, align 8
  %707 = load i8, i8* %19, align 1, !tbaa !2433
  %708 = load i8, i8* %34, align 1, !tbaa !2448
  %709 = or i8 %708, %707
  %710 = icmp ne i8 %709, 0
  %.v37 = select i1 %710, i64 40, i64 6
  %711 = add i64 %706, %.v37
  store i64 %711, i64* %PC, align 8, !tbaa !2428
  br i1 %710, label %block_400d36, label %block_400d14

block_400d46:                                     ; preds = %block_400d36, %block_400d14
  %.sink24.in = phi i64 [ %1581, %block_400d36 ], [ %1274, %block_400d14 ]
  %.sink22 = phi double [ %1583, %block_400d36 ], [ %1299, %block_400d14 ]
  %.sink21 = phi i64 [ 5, %block_400d36 ], [ 21, %block_400d14 ]
  %.sink24 = add i64 %.sink24.in, -208
  %712 = inttoptr i64 %.sink24 to double*
  store double %.sink22, double* %712, align 8
  %713 = load i64, i64* %PC, align 8
  %714 = add i64 %713, %.sink21
  %715 = load i64, i64* %RBP, align 8
  %716 = add i64 %715, -208
  %717 = add i64 %714, 8
  store i64 %717, i64* %PC, align 8
  %718 = inttoptr i64 %716 to i64*
  %719 = load i64, i64* %718, align 8
  store i64 %719, i64* %70, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  store i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 157), i64* %RDI, align 8, !tbaa !2428
  %720 = add i64 %715, -200
  %721 = add i64 %714, 26
  store i64 %721, i64* %PC, align 8
  %722 = inttoptr i64 %720 to i64*
  %723 = load i64, i64* %722, align 8
  store i64 %723, i64* %353, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %724 = add i64 %715, -216
  %725 = add i64 %714, 34
  store i64 %725, i64* %PC, align 8
  %726 = inttoptr i64 %724 to i64*
  store i64 %719, i64* %726, align 8
  %727 = load i64, i64* %PC, align 8
  %728 = load <2 x i32>, <2 x i32>* %1092, align 1
  %729 = load <2 x i32>, <2 x i32>* %1093, align 1
  %730 = extractelement <2 x i32> %728, i32 0
  store i32 %730, i32* %375, align 1, !tbaa !2475
  %731 = extractelement <2 x i32> %728, i32 1
  store i32 %731, i32* %377, align 1, !tbaa !2475
  %732 = extractelement <2 x i32> %729, i32 0
  store i32 %732, i32* %378, align 1, !tbaa !2475
  %733 = extractelement <2 x i32> %729, i32 1
  store i32 %733, i32* %380, align 1, !tbaa !2475
  %734 = load i64, i64* %RBP, align 8
  %735 = add i64 %734, -216
  %736 = add i64 %727, 11
  store i64 %736, i64* %PC, align 8
  %737 = inttoptr i64 %735 to i64*
  %738 = load i64, i64* %737, align 8
  store i64 %738, i64* %353, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  store i8 2, i8* %AL, align 1, !tbaa !2432
  %739 = add i64 %727, -1752
  %740 = add i64 %727, 18
  %741 = load i64, i64* %RSP, align 8, !tbaa !2428
  %742 = add i64 %741, -8
  %743 = inttoptr i64 %742 to i64*
  store i64 %740, i64* %743, align 8
  store i64 %742, i64* %RSP, align 8, !tbaa !2428
  store i64 %739, i64* %PC, align 8, !tbaa !2428
  %744 = tail call fastcc %struct.Memory* @ext_6050a0_printf(%struct.State* nonnull %0, %struct.Memory* %700)
  %745 = load i64, i64* %RBP, align 8
  %746 = add i64 %745, -220
  %747 = load i32, i32* %EAX, align 4
  %748 = load i64, i64* %PC, align 8
  %749 = add i64 %748, 6
  store i64 %749, i64* %PC, align 8
  %750 = inttoptr i64 %746 to i32*
  store i32 %747, i32* %750, align 4
  %751 = load i64, i64* %RBP, align 8
  %752 = add i64 %751, -12
  %753 = load i64, i64* %PC, align 8
  %754 = add i64 %753, 3
  store i64 %754, i64* %PC, align 8
  %755 = inttoptr i64 %752 to i32*
  %756 = load i32, i32* %755, align 4
  %757 = add i32 %756, 1
  %758 = zext i32 %757 to i64
  store i64 %758, i64* %RAX, align 8, !tbaa !2428
  %759 = icmp eq i32 %756, -1
  %760 = icmp eq i32 %757, 0
  %761 = or i1 %759, %760
  %762 = zext i1 %761 to i8
  store i8 %762, i8* %19, align 1, !tbaa !2433
  %763 = and i32 %757, 255
  %764 = tail call i32 @llvm.ctpop.i32(i32 %763) #10
  %765 = trunc i32 %764 to i8
  %766 = and i8 %765, 1
  %767 = xor i8 %766, 1
  store i8 %767, i8* %26, align 1, !tbaa !2447
  %768 = xor i32 %756, %757
  %769 = lshr i32 %768, 4
  %770 = trunc i32 %769 to i8
  %771 = and i8 %770, 1
  store i8 %771, i8* %31, align 1, !tbaa !2451
  %772 = zext i1 %760 to i8
  store i8 %772, i8* %34, align 1, !tbaa !2448
  %773 = lshr i32 %757, 31
  %774 = trunc i32 %773 to i8
  store i8 %774, i8* %37, align 1, !tbaa !2449
  %775 = lshr i32 %756, 31
  %776 = xor i32 %773, %775
  %777 = add nuw nsw i32 %776, %773
  %778 = icmp eq i32 %777, 2
  %779 = zext i1 %778 to i8
  store i8 %779, i8* %43, align 1, !tbaa !2450
  %780 = add i64 %753, 9
  store i64 %780, i64* %PC, align 8
  store i32 %757, i32* %755, align 4
  %781 = load i64, i64* %PC, align 8
  %782 = add i64 %781, -290
  store i64 %782, i64* %PC, align 8, !tbaa !2428
  br label %block_400c67

block_400b44:                                     ; preds = %block_400b37
  %783 = add i64 %1095, -40
  %784 = add i64 %1123, 4
  store i64 %784, i64* %PC, align 8
  %785 = inttoptr i64 %783 to i64*
  %786 = load i64, i64* %785, align 8
  store i64 %786, i64* %RAX, align 8, !tbaa !2428
  %787 = add i64 %1123, 7
  store i64 %787, i64* %PC, align 8
  %788 = load i32, i32* %1098, align 4
  %789 = shl i32 %788, 1
  %790 = icmp slt i32 %788, 0
  %791 = icmp slt i32 %789, 0
  %792 = xor i1 %790, %791
  %793 = zext i32 %789 to i64
  store i64 %793, i64* %RCX, align 8, !tbaa !2428
  %.lobit = lshr i32 %788, 31
  %794 = trunc i32 %.lobit to i8
  store i8 %794, i8* %19, align 1, !tbaa !2432
  %795 = and i32 %789, 254
  %796 = tail call i32 @llvm.ctpop.i32(i32 %795) #10
  %797 = trunc i32 %796 to i8
  %798 = and i8 %797, 1
  %799 = xor i8 %798, 1
  store i8 %799, i8* %26, align 1, !tbaa !2432
  store i8 0, i8* %31, align 1, !tbaa !2432
  %800 = icmp eq i32 %789, 0
  %801 = zext i1 %800 to i8
  store i8 %801, i8* %34, align 1, !tbaa !2432
  %802 = lshr i32 %788, 30
  %803 = trunc i32 %802 to i8
  %804 = and i8 %803, 1
  store i8 %804, i8* %37, align 1, !tbaa !2432
  %805 = zext i1 %792 to i8
  store i8 %805, i8* %43, align 1, !tbaa !2432
  %806 = sext i32 %789 to i64
  store i64 %806, i64* %RDX, align 8, !tbaa !2428
  %807 = shl nsw i64 %806, 3
  %808 = add i64 %807, %786
  %809 = add i64 %1123, 18
  store i64 %809, i64* %PC, align 8
  %810 = inttoptr i64 %808 to i64*
  %811 = load i64, i64* %810, align 8
  store i64 %811, i64* %70, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %812 = add i64 %1095, -112
  %813 = add i64 %1123, 23
  store i64 %813, i64* %PC, align 8
  %814 = inttoptr i64 %812 to i64*
  store i64 %811, i64* %814, align 8
  %815 = load i64, i64* %RBP, align 8
  %816 = add i64 %815, -32
  %817 = load i64, i64* %PC, align 8
  %818 = add i64 %817, 4
  store i64 %818, i64* %PC, align 8
  %819 = inttoptr i64 %816 to i64*
  %820 = load i64, i64* %819, align 8
  store i64 %820, i64* %RAX, align 8, !tbaa !2428
  %821 = add i64 %815, -100
  %822 = add i64 %817, 7
  store i64 %822, i64* %PC, align 8
  %823 = inttoptr i64 %821 to i32*
  %824 = load i32, i32* %823, align 4
  %825 = shl i32 %824, 1
  %826 = icmp slt i32 %824, 0
  %827 = icmp slt i32 %825, 0
  %828 = xor i1 %826, %827
  %829 = zext i32 %825 to i64
  store i64 %829, i64* %RCX, align 8, !tbaa !2428
  %.lobit31 = lshr i32 %824, 31
  %830 = trunc i32 %.lobit31 to i8
  store i8 %830, i8* %19, align 1, !tbaa !2432
  %831 = and i32 %825, 254
  %832 = tail call i32 @llvm.ctpop.i32(i32 %831) #10
  %833 = trunc i32 %832 to i8
  %834 = and i8 %833, 1
  %835 = xor i8 %834, 1
  store i8 %835, i8* %26, align 1, !tbaa !2432
  store i8 0, i8* %31, align 1, !tbaa !2432
  %836 = icmp eq i32 %825, 0
  %837 = zext i1 %836 to i8
  store i8 %837, i8* %34, align 1, !tbaa !2432
  %838 = lshr i32 %824, 30
  %839 = trunc i32 %838 to i8
  %840 = and i8 %839, 1
  store i8 %840, i8* %37, align 1, !tbaa !2432
  %841 = zext i1 %828 to i8
  store i8 %841, i8* %43, align 1, !tbaa !2432
  %842 = sext i32 %825 to i64
  store i64 %842, i64* %RDX, align 8, !tbaa !2428
  %843 = shl nsw i64 %842, 3
  %844 = add i64 %843, %820
  %845 = add i64 %817, 18
  store i64 %845, i64* %PC, align 8
  %846 = inttoptr i64 %844 to i64*
  %847 = load i64, i64* %846, align 8
  store i64 %847, i64* %70, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %848 = add i64 %815, -120
  %849 = add i64 %817, 23
  store i64 %849, i64* %PC, align 8
  %850 = inttoptr i64 %848 to i64*
  store i64 %847, i64* %850, align 8
  %851 = load i64, i64* %RBP, align 8
  %852 = add i64 %851, -40
  %853 = load i64, i64* %PC, align 8
  %854 = add i64 %853, 4
  store i64 %854, i64* %PC, align 8
  %855 = inttoptr i64 %852 to i64*
  %856 = load i64, i64* %855, align 8
  store i64 %856, i64* %RAX, align 8, !tbaa !2428
  %857 = add i64 %851, -100
  %858 = add i64 %853, 7
  store i64 %858, i64* %PC, align 8
  %859 = inttoptr i64 %857 to i32*
  %860 = load i32, i32* %859, align 4
  %861 = shl i32 %860, 1
  %862 = lshr i32 %860, 30
  %863 = and i32 %862, 1
  %864 = or i32 %861, 1
  %865 = zext i32 %864 to i64
  store i64 %865, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %19, align 1, !tbaa !2433
  %866 = and i32 %864, 255
  %867 = tail call i32 @llvm.ctpop.i32(i32 %866) #10
  %868 = trunc i32 %867 to i8
  %869 = and i8 %868, 1
  %870 = xor i8 %869, 1
  store i8 %870, i8* %26, align 1, !tbaa !2447
  store i8 0, i8* %31, align 1, !tbaa !2451
  store i8 0, i8* %34, align 1, !tbaa !2448
  %871 = trunc i32 %863 to i8
  store i8 %871, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  %872 = sext i32 %864 to i64
  store i64 %872, i64* %RDX, align 8, !tbaa !2428
  %873 = shl nsw i64 %872, 3
  %874 = add i64 %873, %856
  %875 = add i64 %853, 21
  store i64 %875, i64* %PC, align 8
  %876 = inttoptr i64 %874 to i64*
  %877 = load i64, i64* %876, align 8
  store i64 %877, i64* %70, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %878 = add i64 %851, -128
  %879 = add i64 %853, 26
  store i64 %879, i64* %PC, align 8
  %880 = inttoptr i64 %878 to i64*
  store i64 %877, i64* %880, align 8
  %881 = load i64, i64* %RBP, align 8
  %882 = add i64 %881, -32
  %883 = load i64, i64* %PC, align 8
  %884 = add i64 %883, 4
  store i64 %884, i64* %PC, align 8
  %885 = inttoptr i64 %882 to i64*
  %886 = load i64, i64* %885, align 8
  store i64 %886, i64* %RAX, align 8, !tbaa !2428
  %887 = add i64 %881, -100
  %888 = add i64 %883, 7
  store i64 %888, i64* %PC, align 8
  %889 = inttoptr i64 %887 to i32*
  %890 = load i32, i32* %889, align 4
  %891 = shl i32 %890, 1
  %892 = lshr i32 %890, 30
  %893 = and i32 %892, 1
  %894 = or i32 %891, 1
  %895 = zext i32 %894 to i64
  store i64 %895, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %19, align 1, !tbaa !2433
  %896 = and i32 %894, 255
  %897 = tail call i32 @llvm.ctpop.i32(i32 %896) #10
  %898 = trunc i32 %897 to i8
  %899 = and i8 %898, 1
  %900 = xor i8 %899, 1
  store i8 %900, i8* %26, align 1, !tbaa !2447
  store i8 0, i8* %31, align 1, !tbaa !2451
  store i8 0, i8* %34, align 1, !tbaa !2448
  %901 = trunc i32 %893 to i8
  store i8 %901, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  %902 = sext i32 %894 to i64
  store i64 %902, i64* %RDX, align 8, !tbaa !2428
  %903 = shl nsw i64 %902, 3
  %904 = add i64 %903, %886
  %905 = add i64 %883, 21
  store i64 %905, i64* %PC, align 8
  %906 = inttoptr i64 %904 to i64*
  %907 = load i64, i64* %906, align 8
  store i64 %907, i64* %70, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %908 = add i64 %881, -136
  %909 = add i64 %883, 29
  store i64 %909, i64* %PC, align 8
  %910 = inttoptr i64 %908 to i64*
  store i64 %907, i64* %910, align 8
  %911 = load i64, i64* %RBP, align 8
  %912 = add i64 %911, -112
  %913 = load i64, i64* %PC, align 8
  %914 = add i64 %913, 5
  store i64 %914, i64* %PC, align 8
  %915 = inttoptr i64 %912 to double*
  %916 = load double, double* %915, align 8
  store double %916, double* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %917 = add i64 %911, -120
  %918 = add i64 %913, 10
  store i64 %918, i64* %PC, align 8
  %919 = inttoptr i64 %917 to double*
  %920 = load double, double* %919, align 8
  %921 = fmul double %916, %920
  store double %921, double* %69, align 1, !tbaa !2452
  store i64 0, i64* %93, align 1, !tbaa !2452
  %922 = add i64 %911, -128
  %923 = add i64 %913, 15
  store i64 %923, i64* %PC, align 8
  %924 = inttoptr i64 %922 to double*
  %925 = load double, double* %924, align 8
  store double %925, double* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %926 = add i64 %911, -136
  %927 = add i64 %913, 23
  store i64 %927, i64* %PC, align 8
  %928 = inttoptr i64 %926 to double*
  %929 = load double, double* %928, align 8
  %930 = fmul double %925, %929
  store double %930, double* %100, align 1, !tbaa !2452
  store i64 0, i64* %101, align 1, !tbaa !2452
  %931 = fsub double %921, %930
  store double %931, double* %69, align 1, !tbaa !2452
  store i64 0, i64* %93, align 1, !tbaa !2452
  %932 = add i64 %911, -40
  %933 = add i64 %913, 31
  store i64 %933, i64* %PC, align 8
  %934 = inttoptr i64 %932 to i64*
  %935 = load i64, i64* %934, align 8
  store i64 %935, i64* %RAX, align 8, !tbaa !2428
  %936 = add i64 %911, -100
  %937 = add i64 %913, 34
  store i64 %937, i64* %PC, align 8
  %938 = inttoptr i64 %936 to i32*
  %939 = load i32, i32* %938, align 4
  %940 = shl i32 %939, 1
  %941 = icmp slt i32 %939, 0
  %942 = icmp slt i32 %940, 0
  %943 = xor i1 %941, %942
  %944 = zext i32 %940 to i64
  store i64 %944, i64* %RCX, align 8, !tbaa !2428
  %.lobit32 = lshr i32 %939, 31
  %945 = trunc i32 %.lobit32 to i8
  store i8 %945, i8* %19, align 1, !tbaa !2432
  %946 = and i32 %940, 254
  %947 = tail call i32 @llvm.ctpop.i32(i32 %946) #10
  %948 = trunc i32 %947 to i8
  %949 = and i8 %948, 1
  %950 = xor i8 %949, 1
  store i8 %950, i8* %26, align 1, !tbaa !2432
  store i8 0, i8* %31, align 1, !tbaa !2432
  %951 = icmp eq i32 %940, 0
  %952 = zext i1 %951 to i8
  store i8 %952, i8* %34, align 1, !tbaa !2432
  %953 = lshr i32 %939, 30
  %954 = trunc i32 %953 to i8
  %955 = and i8 %954, 1
  store i8 %955, i8* %37, align 1, !tbaa !2432
  %956 = zext i1 %943 to i8
  store i8 %956, i8* %43, align 1, !tbaa !2432
  %957 = sext i32 %940 to i64
  store i64 %957, i64* %RDX, align 8, !tbaa !2428
  %958 = shl nsw i64 %957, 3
  %959 = add i64 %958, %935
  %960 = add i64 %913, 45
  store i64 %960, i64* %PC, align 8
  %961 = inttoptr i64 %959 to double*
  store double %931, double* %961, align 8
  %962 = load i64, i64* %RBP, align 8
  %963 = add i64 %962, -112
  %964 = load i64, i64* %PC, align 8
  %965 = add i64 %964, 5
  store i64 %965, i64* %PC, align 8
  %966 = inttoptr i64 %963 to double*
  %967 = load double, double* %966, align 8
  store double %967, double* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %968 = add i64 %962, -136
  %969 = add i64 %964, 13
  store i64 %969, i64* %PC, align 8
  %970 = inttoptr i64 %968 to double*
  %971 = load double, double* %970, align 8
  %972 = fmul double %967, %971
  store double %972, double* %69, align 1, !tbaa !2452
  store i64 0, i64* %93, align 1, !tbaa !2452
  %973 = add i64 %962, -128
  %974 = add i64 %964, 18
  store i64 %974, i64* %PC, align 8
  %975 = inttoptr i64 %973 to double*
  %976 = load double, double* %975, align 8
  store double %976, double* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %977 = add i64 %962, -120
  %978 = add i64 %964, 23
  store i64 %978, i64* %PC, align 8
  %979 = inttoptr i64 %977 to double*
  %980 = load double, double* %979, align 8
  %981 = fmul double %976, %980
  store double %981, double* %100, align 1, !tbaa !2452
  store i64 0, i64* %101, align 1, !tbaa !2452
  %982 = fadd double %972, %981
  store double %982, double* %69, align 1, !tbaa !2452
  store i64 0, i64* %93, align 1, !tbaa !2452
  %983 = add i64 %962, -40
  %984 = add i64 %964, 31
  store i64 %984, i64* %PC, align 8
  %985 = inttoptr i64 %983 to i64*
  %986 = load i64, i64* %985, align 8
  store i64 %986, i64* %RAX, align 8, !tbaa !2428
  %987 = add i64 %962, -100
  %988 = add i64 %964, 34
  store i64 %988, i64* %PC, align 8
  %989 = inttoptr i64 %987 to i32*
  %990 = load i32, i32* %989, align 4
  %991 = shl i32 %990, 1
  %992 = lshr i32 %990, 30
  %993 = and i32 %992, 1
  %994 = or i32 %991, 1
  %995 = zext i32 %994 to i64
  store i64 %995, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %19, align 1, !tbaa !2433
  %996 = and i32 %994, 255
  %997 = tail call i32 @llvm.ctpop.i32(i32 %996) #10
  %998 = trunc i32 %997 to i8
  %999 = and i8 %998, 1
  %1000 = xor i8 %999, 1
  store i8 %1000, i8* %26, align 1, !tbaa !2447
  store i8 0, i8* %31, align 1, !tbaa !2451
  store i8 0, i8* %34, align 1, !tbaa !2448
  %1001 = trunc i32 %993 to i8
  store i8 %1001, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  %1002 = sext i32 %994 to i64
  store i64 %1002, i64* %RDX, align 8, !tbaa !2428
  %1003 = shl nsw i64 %1002, 3
  %1004 = add i64 %1003, %986
  %1005 = add i64 %964, 48
  store i64 %1005, i64* %PC, align 8
  %1006 = inttoptr i64 %1004 to double*
  store double %982, double* %1006, align 8
  %1007 = load i64, i64* %RBP, align 8
  %1008 = add i64 %1007, -100
  %1009 = load i64, i64* %PC, align 8
  %1010 = add i64 %1009, 3
  store i64 %1010, i64* %PC, align 8
  %1011 = inttoptr i64 %1008 to i32*
  %1012 = load i32, i32* %1011, align 4
  %1013 = add i32 %1012, 1
  %1014 = zext i32 %1013 to i64
  store i64 %1014, i64* %RAX, align 8, !tbaa !2428
  %1015 = icmp eq i32 %1012, -1
  %1016 = icmp eq i32 %1013, 0
  %1017 = or i1 %1015, %1016
  %1018 = zext i1 %1017 to i8
  store i8 %1018, i8* %19, align 1, !tbaa !2433
  %1019 = and i32 %1013, 255
  %1020 = tail call i32 @llvm.ctpop.i32(i32 %1019) #10
  %1021 = trunc i32 %1020 to i8
  %1022 = and i8 %1021, 1
  %1023 = xor i8 %1022, 1
  store i8 %1023, i8* %26, align 1, !tbaa !2447
  %1024 = xor i32 %1012, %1013
  %1025 = lshr i32 %1024, 4
  %1026 = trunc i32 %1025 to i8
  %1027 = and i8 %1026, 1
  store i8 %1027, i8* %31, align 1, !tbaa !2451
  %1028 = zext i1 %1016 to i8
  store i8 %1028, i8* %34, align 1, !tbaa !2448
  %1029 = lshr i32 %1013, 31
  %1030 = trunc i32 %1029 to i8
  store i8 %1030, i8* %37, align 1, !tbaa !2449
  %1031 = lshr i32 %1012, 31
  %1032 = xor i32 %1029, %1031
  %1033 = add nuw nsw i32 %1032, %1029
  %1034 = icmp eq i32 %1033, 2
  %1035 = zext i1 %1034 to i8
  store i8 %1035, i8* %43, align 1, !tbaa !2450
  %1036 = add i64 %1009, 9
  store i64 %1036, i64* %PC, align 8
  store i32 %1013, i32* %1011, align 4
  %1037 = load i64, i64* %PC, align 8
  %1038 = add i64 %1037, -216
  store i64 %1038, i64* %PC, align 8, !tbaa !2428
  br label %block_400b37

block_400cc2:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1
  store i32 0, i32* %375, align 1, !tbaa !2459
  store i32 0, i32* %377, align 1, !tbaa !2459
  store i32 0, i32* %378, align 1, !tbaa !2459
  store i32 0, i32* %380, align 1, !tbaa !2459
  %1039 = load i64, i64* %RBP, align 8
  %1040 = add i64 %595, 11
  store i64 %1040, i64* %PC, align 8
  %1041 = load double, double* %69, align 1
  br label %block_400cd2

block_400c3d:                                     ; preds = %block_400ad6
  %1042 = add i64 %626, 419
  %1043 = add i64 %626, 5
  %1044 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1045 = add i64 %1044, -8
  %1046 = inttoptr i64 %1045 to i64*
  store i64 %1043, i64* %1046, align 8
  store i64 %1045, i64* %RSP, align 8, !tbaa !2428
  store i64 %1042, i64* %PC, align 8, !tbaa !2428
  %1047 = tail call %struct.Memory* @sub_400de0_get_time_renamed_(%struct.State* nonnull %0, i64 %1042, %struct.Memory* %MEMORY.0)
  %1048 = load i64, i64* %RBP, align 8
  %1049 = add i64 %1048, -72
  %1050 = load i64, i64* %PC, align 8
  %1051 = add i64 %1050, 5
  store i64 %1051, i64* %PC, align 8
  %1052 = load i64, i64* %70, align 1
  %1053 = inttoptr i64 %1049 to i64*
  store i64 %1052, i64* %1053, align 8
  %1054 = load i64, i64* %RBP, align 8
  %1055 = add i64 %1054, -72
  %1056 = load i64, i64* %PC, align 8
  %1057 = add i64 %1056, 5
  store i64 %1057, i64* %PC, align 8
  %1058 = inttoptr i64 %1055 to double*
  %1059 = load double, double* %1058, align 8
  store double %1059, double* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %1060 = add i64 %1054, -64
  %1061 = add i64 %1056, 10
  store i64 %1061, i64* %PC, align 8
  %1062 = inttoptr i64 %1060 to double*
  %1063 = load double, double* %1062, align 8
  %1064 = fsub double %1059, %1063
  store double %1064, double* %69, align 1, !tbaa !2452
  store i64 0, i64* %93, align 1, !tbaa !2452
  %1065 = add i64 %1054, -80
  %1066 = add i64 %1056, 15
  store i64 %1066, i64* %PC, align 8
  %1067 = inttoptr i64 %1065 to double*
  %1068 = load double, double* %1067, align 8
  %1069 = fsub double %1064, %1068
  store double %1069, double* %69, align 1, !tbaa !2452
  store i64 0, i64* %93, align 1, !tbaa !2452
  %1070 = add i64 %1054, -88
  %1071 = add i64 %1056, 20
  store i64 %1071, i64* %PC, align 8
  %1072 = inttoptr i64 %1070 to double*
  %1073 = load double, double* %1072, align 8
  %1074 = fadd double %1069, %1073
  store double %1074, double* %69, align 1, !tbaa !2452
  store i64 0, i64* %93, align 1, !tbaa !2452
  %1075 = add i64 %1056, 25
  store i64 %1075, i64* %PC, align 8
  store double %1074, double* %1072, align 8
  %1076 = load i64, i64* %RBP, align 8
  %1077 = add i64 %1076, -12
  %1078 = load i64, i64* %PC, align 8
  %1079 = add i64 %1078, 7
  store i64 %1079, i64* %PC, align 8
  %1080 = inttoptr i64 %1077 to i32*
  store i32 0, i32* %1080, align 4
  %1081 = bitcast %union.VectorReg* %7 to i32*
  %1082 = getelementptr inbounds i8, i8* %95, i64 4
  %1083 = bitcast i8* %1082 to i32*
  %1084 = bitcast i64* %101 to i32*
  %1085 = getelementptr inbounds i8, i8* %95, i64 12
  %1086 = bitcast i8* %1085 to i32*
  %1087 = bitcast %union.VectorReg* %9 to i8*
  %1088 = getelementptr inbounds i8, i8* %1087, i64 4
  %1089 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3, i32 0, i32 0, i32 0, i64 1
  %1090 = getelementptr inbounds i8, i8* %1087, i64 12
  %1091 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %9, i64 0, i32 0, i32 0, i32 0, i64 0
  %1092 = bitcast %union.VectorReg* %7 to <2 x i32>*
  %1093 = bitcast i64* %101 to <2 x i32>*
  %.pre8 = load i64, i64* %PC, align 8
  br label %block_400c67

block_400b37:                                     ; preds = %block_400b44, %block_400ae3
  %1094 = phi i64 [ %1038, %block_400b44 ], [ %.pre7, %block_400ae3 ]
  %1095 = load i64, i64* %RBP, align 8
  %1096 = add i64 %1095, -100
  %1097 = add i64 %1094, 7
  store i64 %1097, i64* %PC, align 8
  %1098 = inttoptr i64 %1096 to i32*
  %1099 = load i32, i32* %1098, align 4
  %1100 = add i32 %1099, -1024
  %1101 = icmp ult i32 %1099, 1024
  %1102 = zext i1 %1101 to i8
  store i8 %1102, i8* %19, align 1, !tbaa !2433
  %1103 = and i32 %1100, 255
  %1104 = tail call i32 @llvm.ctpop.i32(i32 %1103) #10
  %1105 = trunc i32 %1104 to i8
  %1106 = and i8 %1105, 1
  %1107 = xor i8 %1106, 1
  store i8 %1107, i8* %26, align 1, !tbaa !2447
  %1108 = xor i32 %1099, %1100
  %1109 = lshr i32 %1108, 4
  %1110 = trunc i32 %1109 to i8
  %1111 = and i8 %1110, 1
  store i8 %1111, i8* %31, align 1, !tbaa !2451
  %1112 = icmp eq i32 %1100, 0
  %1113 = zext i1 %1112 to i8
  store i8 %1113, i8* %34, align 1, !tbaa !2448
  %1114 = lshr i32 %1100, 31
  %1115 = trunc i32 %1114 to i8
  store i8 %1115, i8* %37, align 1, !tbaa !2449
  %1116 = lshr i32 %1099, 31
  %1117 = xor i32 %1114, %1116
  %1118 = add nuw nsw i32 %1117, %1116
  %1119 = icmp eq i32 %1118, 2
  %1120 = zext i1 %1119 to i8
  store i8 %1120, i8* %43, align 1, !tbaa !2450
  %1121 = icmp ne i8 %1115, 0
  %1122 = xor i1 %1121, %1119
  %.v30 = select i1 %1122, i64 13, i64 221
  %1123 = add i64 %1094, %.v30
  store i64 %1123, i64* %PC, align 8, !tbaa !2428
  br i1 %1122, label %block_400b44, label %block_400c14

block_400a3c:                                     ; preds = %block_400a2f
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %1124 = add i64 %1461, -32
  %1125 = add i64 %1489, 14
  store i64 %1125, i64* %PC, align 8
  %1126 = inttoptr i64 %1124 to i64*
  %1127 = load i64, i64* %1126, align 8
  store i64 %1127, i64* %RCX, align 8, !tbaa !2428
  %1128 = add i64 %1489, 17
  store i64 %1128, i64* %PC, align 8
  %1129 = load i32, i32* %1464, align 4
  %1130 = shl i32 %1129, 1
  %1131 = lshr i32 %1129, 30
  %1132 = and i32 %1131, 1
  %1133 = or i32 %1130, 1
  %1134 = zext i32 %1133 to i64
  store i64 %1134, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %19, align 1, !tbaa !2433
  %1135 = and i32 %1133, 255
  %1136 = tail call i32 @llvm.ctpop.i32(i32 %1135) #10
  %1137 = trunc i32 %1136 to i8
  %1138 = and i8 %1137, 1
  %1139 = xor i8 %1138, 1
  store i8 %1139, i8* %26, align 1, !tbaa !2447
  store i8 0, i8* %31, align 1, !tbaa !2451
  store i8 0, i8* %34, align 1, !tbaa !2448
  %1140 = trunc i32 %1132 to i8
  store i8 %1140, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  %1141 = sext i32 %1133 to i64
  store i64 %1141, i64* %RSI, align 8, !tbaa !2428
  %1142 = shl nsw i64 %1141, 3
  %1143 = add i64 %1142, %1127
  %1144 = add i64 %1489, 31
  store i64 %1144, i64* %PC, align 8
  %1145 = inttoptr i64 %1143 to i64*
  %1146 = load i64, i64* %1145, align 8
  %1147 = xor i64 %1146, -9223372036854775808
  store i64 %1147, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %19, align 1, !tbaa !2433
  %1148 = trunc i64 %1146 to i32
  %1149 = and i32 %1148, 255
  %1150 = tail call i32 @llvm.ctpop.i32(i32 %1149) #10
  %1151 = trunc i32 %1150 to i8
  %1152 = and i8 %1151, 1
  %1153 = xor i8 %1152, 1
  store i8 %1153, i8* %26, align 1, !tbaa !2447
  %1154 = icmp eq i64 %1147, 0
  %1155 = zext i1 %1154 to i8
  store i8 %1155, i8* %34, align 1, !tbaa !2448
  %1156 = lshr i64 %1147, 63
  %1157 = trunc i64 %1156 to i8
  store i8 %1157, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  store i8 0, i8* %31, align 1, !tbaa !2451
  store i64 %1147, i64* %70, align 1, !tbaa !2428
  store i64 0, i64* %93, align 1, !tbaa !2428
  %1158 = load i64, i64* %RBP, align 8
  %1159 = add i64 %1158, -32
  %1160 = add i64 %1489, 48
  store i64 %1160, i64* %PC, align 8
  %1161 = inttoptr i64 %1159 to i64*
  %1162 = load i64, i64* %1161, align 8
  store i64 %1162, i64* %RAX, align 8, !tbaa !2428
  %1163 = add i64 %1158, -12
  %1164 = add i64 %1489, 51
  store i64 %1164, i64* %PC, align 8
  %1165 = inttoptr i64 %1163 to i32*
  %1166 = load i32, i32* %1165, align 4
  %1167 = shl i32 %1166, 1
  %1168 = lshr i32 %1166, 30
  %1169 = and i32 %1168, 1
  %1170 = or i32 %1167, 1
  %1171 = zext i32 %1170 to i64
  store i64 %1171, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %19, align 1, !tbaa !2433
  %1172 = and i32 %1170, 255
  %1173 = tail call i32 @llvm.ctpop.i32(i32 %1172) #10
  %1174 = trunc i32 %1173 to i8
  %1175 = and i8 %1174, 1
  %1176 = xor i8 %1175, 1
  store i8 %1176, i8* %26, align 1, !tbaa !2447
  store i8 0, i8* %31, align 1, !tbaa !2451
  store i8 0, i8* %34, align 1, !tbaa !2448
  %1177 = trunc i32 %1169 to i8
  store i8 %1177, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  %1178 = sext i32 %1170 to i64
  store i64 %1178, i64* %RCX, align 8, !tbaa !2428
  %1179 = shl nsw i64 %1178, 3
  %1180 = add i64 %1179, %1162
  %1181 = add i64 %1489, 65
  store i64 %1181, i64* %PC, align 8
  %1182 = inttoptr i64 %1180 to i64*
  store i64 %1147, i64* %1182, align 8
  %1183 = load i64, i64* %RBP, align 8
  %1184 = add i64 %1183, -12
  %1185 = load i64, i64* %PC, align 8
  %1186 = add i64 %1185, 3
  store i64 %1186, i64* %PC, align 8
  %1187 = inttoptr i64 %1184 to i32*
  %1188 = load i32, i32* %1187, align 4
  %1189 = add i32 %1188, 1
  %1190 = zext i32 %1189 to i64
  store i64 %1190, i64* %RAX, align 8, !tbaa !2428
  %1191 = icmp eq i32 %1188, -1
  %1192 = icmp eq i32 %1189, 0
  %1193 = or i1 %1191, %1192
  %1194 = zext i1 %1193 to i8
  store i8 %1194, i8* %19, align 1, !tbaa !2433
  %1195 = and i32 %1189, 255
  %1196 = tail call i32 @llvm.ctpop.i32(i32 %1195) #10
  %1197 = trunc i32 %1196 to i8
  %1198 = and i8 %1197, 1
  %1199 = xor i8 %1198, 1
  store i8 %1199, i8* %26, align 1, !tbaa !2447
  %1200 = xor i32 %1188, %1189
  %1201 = lshr i32 %1200, 4
  %1202 = trunc i32 %1201 to i8
  %1203 = and i8 %1202, 1
  store i8 %1203, i8* %31, align 1, !tbaa !2451
  %1204 = zext i1 %1192 to i8
  store i8 %1204, i8* %34, align 1, !tbaa !2448
  %1205 = lshr i32 %1189, 31
  %1206 = trunc i32 %1205 to i8
  store i8 %1206, i8* %37, align 1, !tbaa !2449
  %1207 = lshr i32 %1188, 31
  %1208 = xor i32 %1205, %1207
  %1209 = add nuw nsw i32 %1208, %1205
  %1210 = icmp eq i32 %1209, 2
  %1211 = zext i1 %1210 to i8
  store i8 %1211, i8* %43, align 1, !tbaa !2450
  %1212 = add i64 %1185, 9
  store i64 %1212, i64* %PC, align 8
  store i32 %1189, i32* %1187, align 4
  %1213 = load i64, i64* %PC, align 8
  %1214 = add i64 %1213, -87
  store i64 %1214, i64* %PC, align 8, !tbaa !2428
  br label %block_400a2f

block_4009b2:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2
  store i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 112), i64* %RDI, align 8, !tbaa !2428
  %1215 = load i64, i64* %RBP, align 8
  %1216 = add i64 %1215, -96
  %1217 = add i64 %412, 15
  store i64 %1217, i64* %PC, align 8
  %1218 = inttoptr i64 %1216 to i64*
  %1219 = load i64, i64* %1218, align 8
  store i64 %1219, i64* %70, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  store i8 1, i8* %AL, align 1, !tbaa !2432
  %1220 = add i64 %412, -802
  %1221 = add i64 %412, 22
  %1222 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1223 = add i64 %1222, -8
  %1224 = inttoptr i64 %1223 to i64*
  store i64 %1221, i64* %1224, align 8
  store i64 %1223, i64* %RSP, align 8, !tbaa !2428
  store i64 %1220, i64* %PC, align 8, !tbaa !2428
  %1225 = tail call fastcc %struct.Memory* @ext_6050a0_printf(%struct.State* nonnull %0, %struct.Memory* %407)
  %1226 = load i64, i64* %RBP, align 8
  %1227 = add i64 %1226, -156
  %1228 = load i32, i32* %EAX, align 4
  %1229 = load i64, i64* %PC, align 8
  %1230 = add i64 %1229, 6
  store i64 %1230, i64* %PC, align 8
  %1231 = inttoptr i64 %1227 to i32*
  store i32 %1228, i32* %1231, align 4
  %1232 = load i64, i64* %PC, align 8
  %1233 = add i64 %1232, -862
  %1234 = add i64 %1232, 5
  %1235 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1236 = add i64 %1235, -8
  %1237 = inttoptr i64 %1236 to i64*
  store i64 %1234, i64* %1237, align 8
  store i64 %1236, i64* %RSP, align 8, !tbaa !2428
  store i64 %1233, i64* %PC, align 8, !tbaa !2428
  %1238 = tail call fastcc %struct.Memory* @ext_400670_abort(%struct.State* nonnull %0, %struct.Memory* %1225)
  %1239 = load i64, i64* %PC, align 8
  %1240 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull %0, i64 %1239, %struct.Memory* %1238)
  ret %struct.Memory* %1240

block_400ca3:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1
  %1241 = load i64, i64* %RBP, align 8
  %1242 = add i64 %1241, -40
  %1243 = add i64 %595, 4
  store i64 %1243, i64* %PC, align 8
  %1244 = inttoptr i64 %1242 to i64*
  %1245 = load i64, i64* %1244, align 8
  store i64 %1245, i64* %RAX, align 8, !tbaa !2428
  %1246 = add i64 %1241, -12
  %1247 = add i64 %595, 7
  store i64 %1247, i64* %PC, align 8
  %1248 = inttoptr i64 %1246 to i32*
  %1249 = load i32, i32* %1248, align 4
  %1250 = shl i32 %1249, 1
  %1251 = icmp slt i32 %1249, 0
  %1252 = icmp slt i32 %1250, 0
  %1253 = xor i1 %1251, %1252
  %1254 = zext i32 %1250 to i64
  store i64 %1254, i64* %RCX, align 8, !tbaa !2428
  %.lobit36 = lshr i32 %1249, 31
  %1255 = trunc i32 %.lobit36 to i8
  store i8 %1255, i8* %19, align 1, !tbaa !2432
  %1256 = and i32 %1250, 254
  %1257 = tail call i32 @llvm.ctpop.i32(i32 %1256) #10
  %1258 = trunc i32 %1257 to i8
  %1259 = and i8 %1258, 1
  %1260 = xor i8 %1259, 1
  store i8 %1260, i8* %26, align 1, !tbaa !2432
  store i8 0, i8* %31, align 1, !tbaa !2432
  %1261 = icmp eq i32 %1250, 0
  %1262 = zext i1 %1261 to i8
  store i8 %1262, i8* %34, align 1, !tbaa !2432
  %1263 = lshr i32 %1249, 30
  %1264 = trunc i32 %1263 to i8
  %1265 = and i8 %1264, 1
  store i8 %1265, i8* %37, align 1, !tbaa !2432
  %1266 = zext i1 %1253 to i8
  store i8 %1266, i8* %43, align 1, !tbaa !2432
  %1267 = sext i32 %1250 to i64
  store i64 %1267, i64* %RDX, align 8, !tbaa !2428
  %1268 = shl nsw i64 %1267, 3
  %1269 = add i64 %1268, %1245
  %1270 = add i64 %595, 18
  store i64 %1270, i64* %PC, align 8
  %1271 = inttoptr i64 %1269 to double*
  %1272 = load double, double* %1271, align 8
  store double %1272, double* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %1273 = add i64 %595, 26
  store i64 %1273, i64* %PC, align 8
  br label %block_400cd2

block_400d14:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %1274 = load i64, i64* %RBP, align 8
  %1275 = add i64 %1274, -40
  %1276 = add i64 %711, 4
  store i64 %1276, i64* %PC, align 8
  %1277 = inttoptr i64 %1275 to i64*
  %1278 = load i64, i64* %1277, align 8
  store i64 %1278, i64* %RAX, align 8, !tbaa !2428
  %1279 = add i64 %1274, -12
  %1280 = add i64 %711, 7
  store i64 %1280, i64* %PC, align 8
  %1281 = inttoptr i64 %1279 to i32*
  %1282 = load i32, i32* %1281, align 4
  %1283 = shl i32 %1282, 1
  %1284 = lshr i32 %1282, 30
  %1285 = and i32 %1284, 1
  %1286 = or i32 %1283, 1
  %1287 = zext i32 %1286 to i64
  store i64 %1287, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %19, align 1, !tbaa !2433
  %1288 = and i32 %1286, 255
  %1289 = tail call i32 @llvm.ctpop.i32(i32 %1288) #10
  %1290 = trunc i32 %1289 to i8
  %1291 = and i8 %1290, 1
  %1292 = xor i8 %1291, 1
  store i8 %1292, i8* %26, align 1, !tbaa !2447
  store i8 0, i8* %31, align 1, !tbaa !2451
  store i8 0, i8* %34, align 1, !tbaa !2448
  %1293 = trunc i32 %1285 to i8
  store i8 %1293, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  %1294 = sext i32 %1286 to i64
  store i64 %1294, i64* %RDX, align 8, !tbaa !2428
  %1295 = shl nsw i64 %1294, 3
  %1296 = add i64 %1295, %1278
  %1297 = add i64 %711, 21
  store i64 %1297, i64* %PC, align 8
  %1298 = inttoptr i64 %1296 to double*
  %1299 = load double, double* %1298, align 8
  store double %1299, double* %69, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %1300 = add i64 %711, 29
  store i64 %1300, i64* %PC, align 8
  br label %block_400d46

block_400d8e:                                     ; preds = %block_400c67
  %1301 = add i64 %1552, -32
  %1302 = add i64 %1580, 4
  store i64 %1302, i64* %PC, align 8
  %1303 = inttoptr i64 %1301 to i64*
  %1304 = load i64, i64* %1303, align 8
  store i64 %1304, i64* %RAX, align 8, !tbaa !2428
  store i64 %1304, i64* %RDI, align 8, !tbaa !2428
  %1305 = add i64 %1580, -1838
  %1306 = add i64 %1580, 12
  %1307 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1308 = add i64 %1307, -8
  %1309 = inttoptr i64 %1308 to i64*
  store i64 %1306, i64* %1309, align 8
  store i64 %1308, i64* %RSP, align 8, !tbaa !2428
  store i64 %1305, i64* %PC, align 8, !tbaa !2428
  %1310 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %MEMORY.5)
  %1311 = load i64, i64* %RBP, align 8
  %1312 = add i64 %1311, -56
  %1313 = load i64, i64* %PC, align 8
  %1314 = add i64 %1313, 4
  store i64 %1314, i64* %PC, align 8
  %1315 = inttoptr i64 %1312 to i64*
  %1316 = load i64, i64* %1315, align 8
  store i64 %1316, i64* %RAX, align 8, !tbaa !2428
  store i64 %1316, i64* %RDI, align 8, !tbaa !2428
  %1317 = add i64 %1313, -1850
  %1318 = add i64 %1313, 12
  %1319 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1320 = add i64 %1319, -8
  %1321 = inttoptr i64 %1320 to i64*
  store i64 %1318, i64* %1321, align 8
  store i64 %1320, i64* %RSP, align 8, !tbaa !2428
  store i64 %1317, i64* %PC, align 8, !tbaa !2428
  %1322 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %1310)
  %1323 = load i64, i64* %RBP, align 8
  %1324 = add i64 %1323, -24
  %1325 = load i64, i64* %PC, align 8
  %1326 = add i64 %1325, 4
  store i64 %1326, i64* %PC, align 8
  %1327 = inttoptr i64 %1324 to i64*
  %1328 = load i64, i64* %1327, align 8
  store i64 %1328, i64* %RAX, align 8, !tbaa !2428
  store i64 %1328, i64* %RDI, align 8, !tbaa !2428
  %1329 = add i64 %1325, -1862
  %1330 = add i64 %1325, 12
  %1331 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1332 = add i64 %1331, -8
  %1333 = inttoptr i64 %1332 to i64*
  store i64 %1330, i64* %1333, align 8
  store i64 %1332, i64* %RSP, align 8, !tbaa !2428
  store i64 %1329, i64* %PC, align 8, !tbaa !2428
  %1334 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %1322)
  %1335 = load i64, i64* %RBP, align 8
  %1336 = add i64 %1335, -40
  %1337 = load i64, i64* %PC, align 8
  %1338 = add i64 %1337, 4
  store i64 %1338, i64* %PC, align 8
  %1339 = inttoptr i64 %1336 to i64*
  %1340 = load i64, i64* %1339, align 8
  store i64 %1340, i64* %RAX, align 8, !tbaa !2428
  store i64 %1340, i64* %RDI, align 8, !tbaa !2428
  %1341 = add i64 %1337, -1874
  %1342 = add i64 %1337, 12
  %1343 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1344 = add i64 %1343, -8
  %1345 = inttoptr i64 %1344 to i64*
  store i64 %1342, i64* %1345, align 8
  store i64 %1344, i64* %RSP, align 8, !tbaa !2428
  store i64 %1341, i64* %PC, align 8, !tbaa !2428
  %1346 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %1334)
  %1347 = load i64, i64* %RBP, align 8
  %1348 = add i64 %1347, -48
  %1349 = load i64, i64* %PC, align 8
  %1350 = add i64 %1349, 4
  store i64 %1350, i64* %PC, align 8
  %1351 = inttoptr i64 %1348 to i64*
  %1352 = load i64, i64* %1351, align 8
  store i64 %1352, i64* %RAX, align 8, !tbaa !2428
  store i64 %1352, i64* %RDI, align 8, !tbaa !2428
  %1353 = add i64 %1349, -1886
  %1354 = add i64 %1349, 12
  %1355 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1356 = add i64 %1355, -8
  %1357 = inttoptr i64 %1356 to i64*
  store i64 %1354, i64* %1357, align 8
  store i64 %1356, i64* %RSP, align 8, !tbaa !2428
  store i64 %1353, i64* %PC, align 8, !tbaa !2428
  %1358 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %1346)
  %1359 = load i64, i64* %PC, align 8
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  %1360 = load i64, i64* %RSP, align 8
  %1361 = add i64 %1360, 224
  store i64 %1361, i64* %RSP, align 8, !tbaa !2428
  %1362 = icmp ugt i64 %1360, -225
  %1363 = zext i1 %1362 to i8
  store i8 %1363, i8* %19, align 1, !tbaa !2433
  %1364 = trunc i64 %1361 to i32
  %1365 = and i32 %1364, 255
  %1366 = tail call i32 @llvm.ctpop.i32(i32 %1365) #10
  %1367 = trunc i32 %1366 to i8
  %1368 = and i8 %1367, 1
  %1369 = xor i8 %1368, 1
  store i8 %1369, i8* %26, align 1, !tbaa !2447
  %1370 = xor i64 %1360, %1361
  %1371 = lshr i64 %1370, 4
  %1372 = trunc i64 %1371 to i8
  %1373 = and i8 %1372, 1
  store i8 %1373, i8* %31, align 1, !tbaa !2451
  %1374 = icmp eq i64 %1361, 0
  %1375 = zext i1 %1374 to i8
  store i8 %1375, i8* %34, align 1, !tbaa !2448
  %1376 = lshr i64 %1361, 63
  %1377 = trunc i64 %1376 to i8
  store i8 %1377, i8* %37, align 1, !tbaa !2449
  %1378 = lshr i64 %1360, 63
  %1379 = xor i64 %1376, %1378
  %1380 = add nuw nsw i64 %1379, %1376
  %1381 = icmp eq i64 %1380, 2
  %1382 = zext i1 %1381 to i8
  store i8 %1382, i8* %43, align 1, !tbaa !2450
  %1383 = add i64 %1359, 10
  store i64 %1383, i64* %PC, align 8
  %1384 = add i64 %1360, 232
  %1385 = inttoptr i64 %1361 to i64*
  %1386 = load i64, i64* %1385, align 8
  store i64 %1386, i64* %RBP, align 8, !tbaa !2428
  store i64 %1384, i64* %RSP, align 8, !tbaa !2428
  %1387 = add i64 %1359, 11
  store i64 %1387, i64* %PC, align 8
  %1388 = inttoptr i64 %1384 to i64*
  %1389 = load i64, i64* %1388, align 8
  store i64 %1389, i64* %PC, align 8, !tbaa !2428
  %1390 = add i64 %1360, 240
  store i64 %1390, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %1358

block_4009d3:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %19, align 1, !tbaa !2433
  store i8 1, i8* %26, align 1, !tbaa !2447
  store i8 1, i8* %34, align 1, !tbaa !2448
  store i8 0, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  store i8 0, i8* %31, align 1, !tbaa !2451
  store i64 1023, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RCX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %1391 = load i64, i64* %RBP, align 8
  %1392 = add i64 %1391, -32
  %1393 = add i64 %412, 18
  store i64 %1393, i64* %PC, align 8
  %1394 = inttoptr i64 %1392 to i64*
  %1395 = load i64, i64* %1394, align 8
  store i64 %1395, i64* %RDI, align 8, !tbaa !2428
  %1396 = add i64 %1391, -160
  %1397 = add i64 %412, 24
  store i64 %1397, i64* %PC, align 8
  %1398 = inttoptr i64 %1396 to i32*
  store i32 1023, i32* %1398, align 4
  %1399 = load i32, i32* %EAX, align 4
  %1400 = zext i32 %1399 to i64
  %1401 = load i64, i64* %PC, align 8
  store i64 %1400, i64* %RSI, align 8, !tbaa !2428
  %1402 = load i64, i64* %RBP, align 8
  %1403 = add i64 %1402, -164
  %1404 = add i64 %1401, 8
  store i64 %1404, i64* %PC, align 8
  %1405 = inttoptr i64 %1403 to i32*
  store i32 %1399, i32* %1405, align 4
  %1406 = load i64, i64* %PC, align 8
  %1407 = add i64 %1406, -835
  %1408 = add i64 %1406, 5
  %1409 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1410 = add i64 %1409, -8
  %1411 = inttoptr i64 %1410 to i64*
  store i64 %1408, i64* %1411, align 8
  store i64 %1410, i64* %RSP, align 8, !tbaa !2428
  store i64 %1407, i64* %PC, align 8, !tbaa !2428
  %1412 = tail call fastcc %struct.Memory* @ext_605110_memset(%struct.State* nonnull %0, %struct.Memory* %407)
  %1413 = load i64, i64* %RBP, align 8
  %1414 = add i64 %1413, -32
  %1415 = load i64, i64* %PC, align 8
  %1416 = add i64 %1415, 4
  store i64 %1416, i64* %PC, align 8
  %1417 = inttoptr i64 %1414 to i64*
  %1418 = load i64, i64* %1417, align 8
  store i64 %1418, i64* %RDX, align 8, !tbaa !2428
  %1419 = add i64 %1413, -164
  %1420 = add i64 %1415, 10
  store i64 %1420, i64* %PC, align 8
  %1421 = inttoptr i64 %1419 to i32*
  %1422 = load i32, i32* %1421, align 4
  %1423 = zext i32 %1422 to i64
  store i64 %1423, i64* %RDI, align 8, !tbaa !2428
  %1424 = add i64 %1413, -160
  %1425 = add i64 %1415, 16
  store i64 %1425, i64* %PC, align 8
  %1426 = inttoptr i64 %1424 to i32*
  %1427 = load i32, i32* %1426, align 4
  %1428 = zext i32 %1427 to i64
  store i64 %1428, i64* %RSI, align 8, !tbaa !2428
  %1429 = add i64 %1415, 1464
  %1430 = add i64 %1415, 21
  %1431 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1432 = add i64 %1431, -8
  %1433 = inttoptr i64 %1432 to i64*
  store i64 %1430, i64* %1433, align 8
  store i64 %1432, i64* %RSP, align 8, !tbaa !2428
  store i64 %1429, i64* %PC, align 8, !tbaa !2428
  %1434 = tail call %struct.Memory* @sub_400fb0_putdata_renamed_(%struct.State* nonnull %0, i64 %1429, %struct.Memory* %1412)
  %1435 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  %1436 = load i64, i64* %RBP, align 8
  %1437 = add i64 %1436, -32
  %1438 = add i64 %1435, 14
  store i64 %1438, i64* %PC, align 8
  %1439 = inttoptr i64 %1437 to i64*
  %1440 = load i64, i64* %1439, align 8
  store i64 %1440, i64* %RDX, align 8, !tbaa !2428
  %1441 = add i64 %1436, -24
  %1442 = add i64 %1435, 18
  store i64 %1442, i64* %PC, align 8
  %1443 = inttoptr i64 %1441 to i64*
  %1444 = load i64, i64* %1443, align 8
  store i64 %1444, i64* %RCX, align 8, !tbaa !2428
  %1445 = add i64 %1436, -56
  %1446 = add i64 %1435, 22
  store i64 %1446, i64* %PC, align 8
  %1447 = inttoptr i64 %1445 to i64*
  %1448 = load i64, i64* %1447, align 8
  store i64 %1448, i64* %R8, align 8, !tbaa !2428
  %1449 = add i64 %1435, 1571
  %1450 = add i64 %1435, 27
  %1451 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1452 = add i64 %1451, -8
  %1453 = inttoptr i64 %1452 to i64*
  store i64 %1450, i64* %1453, align 8
  store i64 %1452, i64* %RSP, align 8, !tbaa !2428
  store i64 %1449, i64* %PC, align 8, !tbaa !2428
  %1454 = tail call %struct.Memory* @sub_401030_cdft_renamed_(%struct.State* nonnull %0, i64 %1449, %struct.Memory* %1434)
  %1455 = load i64, i64* %RBP, align 8
  %1456 = add i64 %1455, -12
  %1457 = load i64, i64* %PC, align 8
  %1458 = add i64 %1457, 7
  store i64 %1458, i64* %PC, align 8
  %1459 = inttoptr i64 %1456 to i32*
  store i32 0, i32* %1459, align 4
  %.pre5 = load i64, i64* %PC, align 8
  br label %block_400a2f

block_400a2f:                                     ; preds = %block_4009d3, %block_400a3c
  %1460 = phi i64 [ %.pre5, %block_4009d3 ], [ %1214, %block_400a3c ]
  %1461 = load i64, i64* %RBP, align 8
  %1462 = add i64 %1461, -12
  %1463 = add i64 %1460, 7
  store i64 %1463, i64* %PC, align 8
  %1464 = inttoptr i64 %1462 to i32*
  %1465 = load i32, i32* %1464, align 4
  %1466 = add i32 %1465, -1024
  %1467 = icmp ult i32 %1465, 1024
  %1468 = zext i1 %1467 to i8
  store i8 %1468, i8* %19, align 1, !tbaa !2433
  %1469 = and i32 %1466, 255
  %1470 = tail call i32 @llvm.ctpop.i32(i32 %1469) #10
  %1471 = trunc i32 %1470 to i8
  %1472 = and i8 %1471, 1
  %1473 = xor i8 %1472, 1
  store i8 %1473, i8* %26, align 1, !tbaa !2447
  %1474 = xor i32 %1465, %1466
  %1475 = lshr i32 %1474, 4
  %1476 = trunc i32 %1475 to i8
  %1477 = and i8 %1476, 1
  store i8 %1477, i8* %31, align 1, !tbaa !2451
  %1478 = icmp eq i32 %1466, 0
  %1479 = zext i1 %1478 to i8
  store i8 %1479, i8* %34, align 1, !tbaa !2448
  %1480 = lshr i32 %1466, 31
  %1481 = trunc i32 %1480 to i8
  store i8 %1481, i8* %37, align 1, !tbaa !2449
  %1482 = lshr i32 %1465, 31
  %1483 = xor i32 %1480, %1482
  %1484 = add nuw nsw i32 %1483, %1482
  %1485 = icmp eq i32 %1484, 2
  %1486 = zext i1 %1485 to i8
  store i8 %1486, i8* %43, align 1, !tbaa !2450
  %1487 = icmp ne i8 %1481, 0
  %1488 = xor i1 %1487, %1485
  %.v28 = select i1 %1488, i64 13, i64 92
  %1489 = add i64 %1460, %.v28
  store i64 %1489, i64* %PC, align 8, !tbaa !2428
  br i1 %1488, label %block_400a3c, label %block_400a8b

block_400a8b:                                     ; preds = %block_400a2f
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %19, align 1, !tbaa !2433
  store i8 1, i8* %26, align 1, !tbaa !2447
  store i8 1, i8* %34, align 1, !tbaa !2448
  store i8 0, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  store i8 0, i8* %31, align 1, !tbaa !2451
  store i64 1023, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RCX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %1490 = add i64 %1461, -48
  %1491 = add i64 %1489, 18
  store i64 %1491, i64* %PC, align 8
  %1492 = inttoptr i64 %1490 to i64*
  %1493 = load i64, i64* %1492, align 8
  store i64 %1493, i64* %RDI, align 8, !tbaa !2428
  %1494 = add i64 %1461, -168
  %1495 = add i64 %1489, 24
  store i64 %1495, i64* %PC, align 8
  %1496 = inttoptr i64 %1494 to i32*
  store i32 1023, i32* %1496, align 4
  %1497 = load i32, i32* %EAX, align 4
  %1498 = zext i32 %1497 to i64
  %1499 = load i64, i64* %PC, align 8
  store i64 %1498, i64* %RSI, align 8, !tbaa !2428
  %1500 = load i64, i64* %RBP, align 8
  %1501 = add i64 %1500, -172
  %1502 = add i64 %1499, 8
  store i64 %1502, i64* %PC, align 8
  %1503 = inttoptr i64 %1501 to i32*
  store i32 %1497, i32* %1503, align 4
  %1504 = load i64, i64* %PC, align 8
  %1505 = add i64 %1504, -1019
  %1506 = add i64 %1504, 5
  %1507 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1508 = add i64 %1507, -8
  %1509 = inttoptr i64 %1508 to i64*
  store i64 %1506, i64* %1509, align 8
  store i64 %1508, i64* %RSP, align 8, !tbaa !2428
  store i64 %1505, i64* %PC, align 8, !tbaa !2428
  %1510 = tail call fastcc %struct.Memory* @ext_605110_memset(%struct.State* nonnull %0, %struct.Memory* %1454)
  %1511 = load i64, i64* %RBP, align 8
  %1512 = add i64 %1511, -48
  %1513 = load i64, i64* %PC, align 8
  %1514 = add i64 %1513, 4
  store i64 %1514, i64* %PC, align 8
  %1515 = inttoptr i64 %1512 to i64*
  %1516 = load i64, i64* %1515, align 8
  store i64 %1516, i64* %RDX, align 8, !tbaa !2428
  %1517 = add i64 %1511, -172
  %1518 = add i64 %1513, 10
  store i64 %1518, i64* %PC, align 8
  %1519 = inttoptr i64 %1517 to i32*
  %1520 = load i32, i32* %1519, align 4
  %1521 = zext i32 %1520 to i64
  store i64 %1521, i64* %RDI, align 8, !tbaa !2428
  %1522 = add i64 %1511, -168
  %1523 = add i64 %1513, 16
  store i64 %1523, i64* %PC, align 8
  %1524 = inttoptr i64 %1522 to i32*
  %1525 = load i32, i32* %1524, align 4
  %1526 = zext i32 %1525 to i64
  store i64 %1526, i64* %RSI, align 8, !tbaa !2428
  %1527 = add i64 %1513, 1280
  %1528 = add i64 %1513, 21
  %1529 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1530 = add i64 %1529, -8
  %1531 = inttoptr i64 %1530 to i64*
  store i64 %1528, i64* %1531, align 8
  store i64 %1530, i64* %RSP, align 8, !tbaa !2428
  store i64 %1527, i64* %PC, align 8, !tbaa !2428
  %1532 = tail call %struct.Memory* @sub_400fb0_putdata_renamed_(%struct.State* nonnull %0, i64 %1527, %struct.Memory* %1510)
  %1533 = load i64, i64* %PC, align 8
  %1534 = add i64 %1533, 795
  %1535 = add i64 %1533, 5
  %1536 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1537 = add i64 %1536, -8
  %1538 = inttoptr i64 %1537 to i64*
  store i64 %1535, i64* %1538, align 8
  store i64 %1537, i64* %RSP, align 8, !tbaa !2428
  store i64 %1534, i64* %PC, align 8, !tbaa !2428
  %1539 = tail call %struct.Memory* @sub_400de0_get_time_renamed_(%struct.State* nonnull %0, i64 %1534, %struct.Memory* %1532)
  %1540 = load i64, i64* %RBP, align 8
  %1541 = add i64 %1540, -64
  %1542 = load i64, i64* %PC, align 8
  %1543 = add i64 %1542, 5
  store i64 %1543, i64* %PC, align 8
  %1544 = load i64, i64* %70, align 1
  %1545 = inttoptr i64 %1541 to i64*
  store i64 %1544, i64* %1545, align 8
  %1546 = load i64, i64* %RBP, align 8
  %1547 = add i64 %1546, -8
  %1548 = load i64, i64* %PC, align 8
  %1549 = add i64 %1548, 7
  store i64 %1549, i64* %PC, align 8
  %1550 = inttoptr i64 %1547 to i32*
  store i32 0, i32* %1550, align 4
  %.pre6 = load i64, i64* %PC, align 8
  br label %block_400ad6

block_400c67:                                     ; preds = %block_400c3d, %block_400d46
  %1551 = phi i64 [ %.pre8, %block_400c3d ], [ %782, %block_400d46 ]
  %MEMORY.5 = phi %struct.Memory* [ %1047, %block_400c3d ], [ %744, %block_400d46 ]
  %1552 = load i64, i64* %RBP, align 8
  %1553 = add i64 %1552, -12
  %1554 = add i64 %1551, 7
  store i64 %1554, i64* %PC, align 8
  %1555 = inttoptr i64 %1553 to i32*
  %1556 = load i32, i32* %1555, align 4
  %1557 = add i32 %1556, -1024
  %1558 = icmp ult i32 %1556, 1024
  %1559 = zext i1 %1558 to i8
  store i8 %1559, i8* %19, align 1, !tbaa !2433
  %1560 = and i32 %1557, 255
  %1561 = tail call i32 @llvm.ctpop.i32(i32 %1560) #10
  %1562 = trunc i32 %1561 to i8
  %1563 = and i8 %1562, 1
  %1564 = xor i8 %1563, 1
  store i8 %1564, i8* %26, align 1, !tbaa !2447
  %1565 = xor i32 %1556, %1557
  %1566 = lshr i32 %1565, 4
  %1567 = trunc i32 %1566 to i8
  %1568 = and i8 %1567, 1
  store i8 %1568, i8* %31, align 1, !tbaa !2451
  %1569 = icmp eq i32 %1557, 0
  %1570 = zext i1 %1569 to i8
  store i8 %1570, i8* %34, align 1, !tbaa !2448
  %1571 = lshr i32 %1557, 31
  %1572 = trunc i32 %1571 to i8
  store i8 %1572, i8* %37, align 1, !tbaa !2449
  %1573 = lshr i32 %1556, 31
  %1574 = xor i32 %1571, %1573
  %1575 = add nuw nsw i32 %1574, %1573
  %1576 = icmp eq i32 %1575, 2
  %1577 = zext i1 %1576 to i8
  store i8 %1577, i8* %43, align 1, !tbaa !2450
  %1578 = icmp ne i8 %1572, 0
  %1579 = xor i1 %1578, %1576
  %.v33 = select i1 %1579, i64 13, i64 295
  %1580 = add i64 %1551, %.v33
  store i64 %1580, i64* %PC, align 8, !tbaa !2428
  br i1 %1579, label %block_400c74, label %block_400d8e

block_400d36:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  store i32 0, i32* %375, align 1, !tbaa !2459
  store i32 0, i32* %377, align 1, !tbaa !2459
  store i32 0, i32* %378, align 1, !tbaa !2459
  store i32 0, i32* %380, align 1, !tbaa !2459
  %1581 = load i64, i64* %RBP, align 8
  %1582 = add i64 %711, 11
  store i64 %1582, i64* %PC, align 8
  %1583 = load double, double* %69, align 1
  br label %block_400d46
}

; Function Attrs: noinline
define %struct.Memory* @sub_400de0_get_time(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400de0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %7 = load i64, i64* %RBP, align 8
  %8 = add i64 %1, 1
  store i64 %8, i64* %PC, align 8
  %9 = load i64, i64* %RSP, align 8, !tbaa !2428
  %10 = add i64 %9, -8
  %11 = inttoptr i64 %10 to i64*
  store i64 %7, i64* %11, align 8
  %12 = load i64, i64* %PC, align 8
  store i64 %10, i64* %RBP, align 8, !tbaa !2428
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %19 = add i64 %9, -24
  store i64 %19, i64* %RDI, align 8, !tbaa !2428
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %13, align 1, !tbaa !2433
  store i8 1, i8* %14, align 1, !tbaa !2447
  store i8 1, i8* %16, align 1, !tbaa !2448
  store i8 0, i8* %17, align 1, !tbaa !2449
  store i8 0, i8* %18, align 1, !tbaa !2450
  store i8 0, i8* %15, align 1, !tbaa !2451
  store i64 0, i64* %RSI, align 8, !tbaa !2428
  %20 = add i64 %12, -1857
  %21 = add i64 %12, 20
  %22 = add i64 %9, -48
  %23 = inttoptr i64 %22 to i64*
  store i64 %21, i64* %23, align 8
  store i64 %22, i64* %RSP, align 8, !tbaa !2428
  store i64 %20, i64* %PC, align 8, !tbaa !2428
  %24 = tail call fastcc %struct.Memory* @ext_4006a0_gettimeofday(%struct.State* nonnull %0, %struct.Memory* %2)
  %25 = bitcast [32 x %union.VectorReg]* %4 to i8*
  %26 = load i64, i64* %PC, align 8
  %27 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 56) to double*), align 8
  %28 = bitcast [32 x %union.VectorReg]* %4 to double*
  store double %27, double* %28, align 1, !tbaa !2452
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %30 = bitcast i64* %29 to double*
  store double 0.000000e+00, double* %30, align 1, !tbaa !2452
  %31 = load i64, i64* %RBP, align 8
  %32 = add i64 %31, -16
  %33 = add i64 %26, 12
  store i64 %33, i64* %PC, align 8
  %34 = inttoptr i64 %32 to i64*
  %35 = load i64, i64* %34, align 8
  store i64 %35, i64* %RSI, align 8, !tbaa !2428
  %36 = sitofp i64 %35 to double
  %37 = bitcast %union.VectorReg* %5 to double*
  store double %36, double* %37, align 1, !tbaa !2452
  %38 = add i64 %31, -8
  %39 = add i64 %26, 21
  store i64 %39, i64* %PC, align 8
  %40 = inttoptr i64 %38 to i64*
  %41 = load i64, i64* %40, align 8
  store i64 %41, i64* %RSI, align 8, !tbaa !2428
  %42 = sitofp i64 %41 to double
  %43 = bitcast %union.VectorReg* %6 to double*
  %44 = fmul double %42, %27
  store double %44, double* %43, align 1, !tbaa !2452
  %45 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %46 = bitcast i64* %45 to <2 x i32>*
  %47 = load <2 x i32>, <2 x i32>* %46, align 1
  %48 = fadd double %36, %44
  store double %48, double* %37, align 1, !tbaa !2452
  %49 = bitcast double %48 to <2 x i32>
  %50 = extractelement <2 x i32> %49, i32 0
  %51 = bitcast [32 x %union.VectorReg]* %4 to i32*
  store i32 %50, i32* %51, align 1, !tbaa !2475
  %52 = extractelement <2 x i32> %49, i32 1
  %53 = getelementptr inbounds i8, i8* %25, i64 4
  %54 = bitcast i8* %53 to i32*
  store i32 %52, i32* %54, align 1, !tbaa !2475
  %55 = extractelement <2 x i32> %47, i32 0
  %56 = bitcast i64* %29 to i32*
  store i32 %55, i32* %56, align 1, !tbaa !2475
  %57 = extractelement <2 x i32> %47, i32 1
  %58 = getelementptr inbounds i8, i8* %25, i64 12
  %59 = bitcast i8* %58 to i32*
  store i32 %57, i32* %59, align 1, !tbaa !2475
  %60 = add i64 %31, -20
  %61 = load i32, i32* %EAX, align 4
  %62 = add i64 %26, 40
  store i64 %62, i64* %PC, align 8
  %63 = inttoptr i64 %60 to i32*
  store i32 %61, i32* %63, align 4
  %64 = load i64, i64* %RSP, align 8
  %65 = load i64, i64* %PC, align 8
  %66 = add i64 %64, 32
  store i64 %66, i64* %RSP, align 8, !tbaa !2428
  %67 = icmp ugt i64 %64, -33
  %68 = zext i1 %67 to i8
  store i8 %68, i8* %13, align 1, !tbaa !2433
  %69 = trunc i64 %66 to i32
  %70 = and i32 %69, 255
  %71 = tail call i32 @llvm.ctpop.i32(i32 %70) #10
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  %74 = xor i8 %73, 1
  store i8 %74, i8* %14, align 1, !tbaa !2447
  %75 = xor i64 %64, %66
  %76 = lshr i64 %75, 4
  %77 = trunc i64 %76 to i8
  %78 = and i8 %77, 1
  store i8 %78, i8* %15, align 1, !tbaa !2451
  %79 = icmp eq i64 %66, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %16, align 1, !tbaa !2448
  %81 = lshr i64 %66, 63
  %82 = trunc i64 %81 to i8
  store i8 %82, i8* %17, align 1, !tbaa !2449
  %83 = lshr i64 %64, 63
  %84 = xor i64 %81, %83
  %85 = add nuw nsw i64 %84, %81
  %86 = icmp eq i64 %85, 2
  %87 = zext i1 %86 to i8
  store i8 %87, i8* %18, align 1, !tbaa !2450
  %88 = add i64 %65, 5
  store i64 %88, i64* %PC, align 8
  %89 = add i64 %64, 40
  %90 = inttoptr i64 %66 to i64*
  %91 = load i64, i64* %90, align 8
  store i64 %91, i64* %RBP, align 8, !tbaa !2428
  store i64 %89, i64* %RSP, align 8, !tbaa !2428
  %92 = add i64 %65, 6
  store i64 %92, i64* %PC, align 8
  %93 = inttoptr i64 %89 to i64*
  %94 = load i64, i64* %93, align 8
  store i64 %94, i64* %PC, align 8, !tbaa !2428
  %95 = add i64 %64, 48
  store i64 %95, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %24
}

; Function Attrs: noinline
define %struct.Memory* @sub_401be0_bitrv2conj(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_401be0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %8 = load i64, i64* %7, align 8, !tbaa !2428
  %9 = add i64 %8, -8
  %10 = inttoptr i64 %9 to i64*
  store i64 %5, i64* %10, align 8
  store i64 %9, i64* %7, align 8, !tbaa !2428
  %11 = load i64, i64* %PC, align 8
  store i64 %9, i64* %RBP, align 8, !tbaa !2428
  %12 = add i64 %8, -12
  %13 = load i32, i32* %EDI, align 4
  %14 = add i64 %11, 6
  store i64 %14, i64* %PC, align 8
  %15 = inttoptr i64 %12 to i32*
  store i32 %13, i32* %15, align 4
  %16 = load i64, i64* %RBP, align 8
  %17 = add i64 %16, -16
  %18 = load i64, i64* %RSI, align 8
  %19 = load i64, i64* %PC, align 8
  %20 = add i64 %19, 4
  store i64 %20, i64* %PC, align 8
  %21 = inttoptr i64 %17 to i64*
  store i64 %18, i64* %21, align 8
  %22 = load i64, i64* %RBP, align 8
  %23 = add i64 %22, -24
  %24 = load i64, i64* %RDX, align 8
  %25 = load i64, i64* %PC, align 8
  %26 = add i64 %25, 4
  store i64 %26, i64* %PC, align 8
  %27 = inttoptr i64 %23 to i64*
  store i64 %24, i64* %27, align 8
  %28 = load i64, i64* %RBP, align 8
  %29 = add i64 %28, -16
  %30 = load i64, i64* %PC, align 8
  %31 = add i64 %30, 4
  store i64 %31, i64* %PC, align 8
  %32 = inttoptr i64 %29 to i64*
  %33 = load i64, i64* %32, align 8
  store i64 %33, i64* %RDX, align 8, !tbaa !2428
  %34 = add i64 %30, 10
  store i64 %34, i64* %PC, align 8
  %35 = inttoptr i64 %33 to i32*
  store i32 0, i32* %35, align 4
  %36 = load i64, i64* %RBP, align 8
  %37 = add i64 %36, -4
  %38 = load i64, i64* %PC, align 8
  %39 = add i64 %38, 3
  store i64 %39, i64* %PC, align 8
  %40 = inttoptr i64 %37 to i32*
  %41 = load i32, i32* %40, align 4
  %42 = zext i32 %41 to i64
  store i64 %42, i64* %RDI, align 8, !tbaa !2428
  %43 = add i64 %36, -44
  %44 = add i64 %38, 6
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %43 to i32*
  store i32 %41, i32* %45, align 4
  %46 = load i64, i64* %RBP, align 8
  %47 = add i64 %46, -48
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 7
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %47 to i32*
  store i32 1, i32* %50, align 4
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %53 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %56 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %.pre = load i64, i64* %PC, align 8
  br label %block_401c06

block_4021ff:                                     ; preds = %block_40220b, %block_4021f8
  %57 = phi i64 [ %3679, %block_40220b ], [ %.pre8, %block_4021f8 ]
  %58 = load i64, i64* %RBP, align 8
  %59 = add i64 %58, -28
  %60 = add i64 %57, 3
  store i64 %60, i64* %PC, align 8
  %61 = inttoptr i64 %59 to i32*
  %62 = load i32, i32* %61, align 4
  %63 = zext i32 %62 to i64
  store i64 %63, i64* %RAX, align 8, !tbaa !2428
  %64 = add i64 %58, -36
  %65 = add i64 %57, 6
  store i64 %65, i64* %PC, align 8
  %66 = inttoptr i64 %64 to i32*
  %67 = load i32, i32* %66, align 4
  %68 = sub i32 %62, %67
  %69 = icmp ult i32 %62, %67
  %70 = zext i1 %69 to i8
  store i8 %70, i8* %51, align 1, !tbaa !2433
  %71 = and i32 %68, 255
  %72 = tail call i32 @llvm.ctpop.i32(i32 %71) #10
  %73 = trunc i32 %72 to i8
  %74 = and i8 %73, 1
  %75 = xor i8 %74, 1
  store i8 %75, i8* %52, align 1, !tbaa !2447
  %76 = xor i32 %67, %62
  %77 = xor i32 %76, %68
  %78 = lshr i32 %77, 4
  %79 = trunc i32 %78 to i8
  %80 = and i8 %79, 1
  store i8 %80, i8* %53, align 1, !tbaa !2451
  %81 = icmp eq i32 %68, 0
  %82 = zext i1 %81 to i8
  store i8 %82, i8* %54, align 1, !tbaa !2448
  %83 = lshr i32 %68, 31
  %84 = trunc i32 %83 to i8
  store i8 %84, i8* %55, align 1, !tbaa !2449
  %85 = lshr i32 %62, 31
  %86 = lshr i32 %67, 31
  %87 = xor i32 %86, %85
  %88 = xor i32 %83, %85
  %89 = add nuw nsw i32 %88, %87
  %90 = icmp eq i32 %89, 2
  %91 = zext i1 %90 to i8
  store i8 %91, i8* %56, align 1, !tbaa !2450
  %92 = icmp ne i8 %84, 0
  %93 = xor i1 %92, %90
  %.v22 = select i1 %93, i64 12, i64 474
  %94 = add i64 %57, %.v22
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %95 = add i64 %94, 13
  store i64 %95, i64* %PC, align 8
  br i1 %93, label %block_40220b, label %block_4023d9

block_4021f8:                                     ; preds = %block_4021ec
  %96 = add i64 %2801, -28
  %97 = add i64 %2837, 7
  store i64 %97, i64* %PC, align 8
  %98 = inttoptr i64 %96 to i32*
  store i32 0, i32* %98, align 4
  %.pre8 = load i64, i64* %PC, align 8
  br label %block_4021ff

block_40246d:                                     ; preds = %block_4021ec
  %99 = add i64 %2837, 5
  br label %block_402472

block_401c6b:                                     ; preds = %block_401c06
  %100 = load i32, i32* %3684, align 4
  %101 = shl i32 %100, 1
  %102 = icmp slt i32 %100, 0
  %103 = icmp slt i32 %101, 0
  %104 = xor i1 %102, %103
  %105 = zext i32 %101 to i64
  store i64 %105, i64* %RAX, align 8, !tbaa !2428
  %.lobit11 = lshr i32 %100, 31
  %106 = trunc i32 %.lobit11 to i8
  store i8 %106, i8* %51, align 1, !tbaa !2432
  %107 = and i32 %101, 254
  %108 = tail call i32 @llvm.ctpop.i32(i32 %107) #10
  %109 = trunc i32 %108 to i8
  %110 = and i8 %109, 1
  %111 = xor i8 %110, 1
  store i8 %111, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %112 = icmp eq i32 %101, 0
  %113 = zext i1 %112 to i8
  store i8 %113, i8* %54, align 1, !tbaa !2432
  %114 = lshr i32 %100, 30
  %115 = trunc i32 %114 to i8
  %116 = and i8 %115, 1
  store i8 %116, i8* %55, align 1, !tbaa !2432
  %117 = zext i1 %104 to i8
  store i8 %117, i8* %56, align 1, !tbaa !2432
  %118 = add i64 %3681, -52
  %119 = add i64 %3730, 9
  store i64 %119, i64* %PC, align 8
  %120 = inttoptr i64 %118 to i32*
  store i32 %101, i32* %120, align 4
  %121 = load i64, i64* %RBP, align 8
  %122 = add i64 %121, -48
  %123 = load i64, i64* %PC, align 8
  %124 = add i64 %123, 3
  store i64 %124, i64* %PC, align 8
  %125 = inttoptr i64 %122 to i32*
  %126 = load i32, i32* %125, align 4
  %127 = shl i32 %126, 3
  %128 = zext i32 %127 to i64
  store i64 %128, i64* %RAX, align 8, !tbaa !2428
  %129 = lshr i32 %126, 29
  %130 = trunc i32 %129 to i8
  %131 = and i8 %130, 1
  store i8 %131, i8* %51, align 1, !tbaa !2432
  %132 = and i32 %127, 248
  %133 = tail call i32 @llvm.ctpop.i32(i32 %132) #10
  %134 = trunc i32 %133 to i8
  %135 = and i8 %134, 1
  %136 = xor i8 %135, 1
  store i8 %136, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %137 = icmp eq i32 %127, 0
  %138 = zext i1 %137 to i8
  store i8 %138, i8* %54, align 1, !tbaa !2432
  %139 = lshr i32 %126, 28
  %140 = and i32 %139, 1
  %141 = trunc i32 %140 to i8
  store i8 %141, i8* %55, align 1, !tbaa !2432
  store i8 0, i8* %56, align 1, !tbaa !2432
  %142 = add i64 %121, -44
  %143 = add i64 %123, 9
  store i64 %143, i64* %PC, align 8
  %144 = inttoptr i64 %142 to i32*
  %145 = load i32, i32* %144, align 4
  %146 = sub i32 %127, %145
  %147 = icmp ult i32 %127, %145
  %148 = zext i1 %147 to i8
  store i8 %148, i8* %51, align 1, !tbaa !2433
  %149 = and i32 %146, 255
  %150 = tail call i32 @llvm.ctpop.i32(i32 %149) #10
  %151 = trunc i32 %150 to i8
  %152 = and i8 %151, 1
  %153 = xor i8 %152, 1
  store i8 %153, i8* %52, align 1, !tbaa !2447
  %154 = xor i32 %145, %127
  %155 = xor i32 %154, %146
  %156 = lshr i32 %155, 4
  %157 = trunc i32 %156 to i8
  %158 = and i8 %157, 1
  store i8 %158, i8* %53, align 1, !tbaa !2451
  %159 = icmp eq i32 %146, 0
  %160 = zext i1 %159 to i8
  store i8 %160, i8* %54, align 1, !tbaa !2448
  %161 = lshr i32 %146, 31
  %162 = trunc i32 %161 to i8
  store i8 %162, i8* %55, align 1, !tbaa !2449
  %163 = lshr i32 %145, 31
  %164 = xor i32 %163, %140
  %165 = xor i32 %161, %140
  %166 = add nuw nsw i32 %165, %164
  %167 = icmp eq i32 %166, 2
  %168 = zext i1 %167 to i8
  store i8 %168, i8* %56, align 1, !tbaa !2450
  %.v13 = select i1 %159, i64 15, i64 1303
  %169 = add i64 %123, %.v13
  store i64 %169, i64* %PC, align 8, !tbaa !2428
  br i1 %159, label %block_401c83, label %block_40218b

block_401c5d:                                     ; preds = %block_401c25
  %170 = add i64 %2111, 3
  store i64 %170, i64* %PC, align 8
  %171 = load i32, i32* %2083, align 4
  %172 = shl i32 %171, 1
  %173 = icmp slt i32 %171, 0
  %174 = icmp slt i32 %172, 0
  %175 = xor i1 %173, %174
  %176 = zext i32 %172 to i64
  store i64 %176, i64* %RAX, align 8, !tbaa !2428
  %.lobit = lshr i32 %171, 31
  %177 = trunc i32 %.lobit to i8
  store i8 %177, i8* %51, align 1, !tbaa !2432
  %178 = and i32 %172, 254
  %179 = tail call i32 @llvm.ctpop.i32(i32 %178) #10
  %180 = trunc i32 %179 to i8
  %181 = and i8 %180, 1
  %182 = xor i8 %181, 1
  store i8 %182, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %183 = icmp eq i32 %172, 0
  %184 = zext i1 %183 to i8
  store i8 %184, i8* %54, align 1, !tbaa !2432
  %185 = lshr i32 %171, 30
  %186 = trunc i32 %185 to i8
  %187 = and i8 %186, 1
  store i8 %187, i8* %55, align 1, !tbaa !2432
  %188 = zext i1 %175 to i8
  store i8 %188, i8* %56, align 1, !tbaa !2432
  %189 = add i64 %2111, 9
  store i64 %189, i64* %PC, align 8
  store i32 %172, i32* %2083, align 4
  %190 = load i64, i64* %PC, align 8
  %191 = add i64 %190, -96
  store i64 %191, i64* %PC, align 8, !tbaa !2428
  br label %block_401c06

block_402186:                                     ; preds = %block_401c8a
  %192 = add i64 %2908, 748
  br label %block_402472

block_401c31:                                     ; preds = %block_401c25
  %193 = add i64 %2075, -16
  %194 = add i64 %2111, 4
  store i64 %194, i64* %PC, align 8
  %195 = inttoptr i64 %193 to i64*
  %196 = load i64, i64* %195, align 8
  store i64 %196, i64* %RAX, align 8, !tbaa !2428
  %197 = add i64 %2111, 8
  store i64 %197, i64* %PC, align 8
  %198 = load i32, i32* %2078, align 4
  %199 = sext i32 %198 to i64
  store i64 %199, i64* %RCX, align 8, !tbaa !2428
  %200 = shl nsw i64 %199, 2
  %201 = add i64 %200, %196
  %202 = add i64 %2111, 11
  store i64 %202, i64* %PC, align 8
  %203 = inttoptr i64 %201 to i32*
  %204 = load i32, i32* %203, align 4
  %205 = zext i32 %204 to i64
  store i64 %205, i64* %RDX, align 8, !tbaa !2428
  %206 = add i64 %2075, -44
  %207 = add i64 %2111, 14
  store i64 %207, i64* %PC, align 8
  %208 = inttoptr i64 %206 to i32*
  %209 = load i32, i32* %208, align 4
  %210 = add i32 %209, %204
  %211 = zext i32 %210 to i64
  store i64 %211, i64* %RDX, align 8, !tbaa !2428
  %212 = icmp ult i32 %210, %204
  %213 = icmp ult i32 %210, %209
  %214 = or i1 %212, %213
  %215 = zext i1 %214 to i8
  store i8 %215, i8* %51, align 1, !tbaa !2433
  %216 = and i32 %210, 255
  %217 = tail call i32 @llvm.ctpop.i32(i32 %216) #10
  %218 = trunc i32 %217 to i8
  %219 = and i8 %218, 1
  %220 = xor i8 %219, 1
  store i8 %220, i8* %52, align 1, !tbaa !2447
  %221 = xor i32 %209, %204
  %222 = xor i32 %221, %210
  %223 = lshr i32 %222, 4
  %224 = trunc i32 %223 to i8
  %225 = and i8 %224, 1
  store i8 %225, i8* %53, align 1, !tbaa !2451
  %226 = icmp eq i32 %210, 0
  %227 = zext i1 %226 to i8
  store i8 %227, i8* %54, align 1, !tbaa !2448
  %228 = lshr i32 %210, 31
  %229 = trunc i32 %228 to i8
  store i8 %229, i8* %55, align 1, !tbaa !2449
  %230 = lshr i32 %204, 31
  %231 = lshr i32 %209, 31
  %232 = xor i32 %228, %230
  %233 = xor i32 %228, %231
  %234 = add nuw nsw i32 %232, %233
  %235 = icmp eq i32 %234, 2
  %236 = zext i1 %235 to i8
  store i8 %236, i8* %56, align 1, !tbaa !2450
  %237 = add i64 %2111, 18
  store i64 %237, i64* %PC, align 8
  %238 = load i64, i64* %195, align 8
  store i64 %238, i64* %RAX, align 8, !tbaa !2428
  %239 = add i64 %2111, 21
  store i64 %239, i64* %PC, align 8
  %240 = load i32, i32* %2083, align 4
  %241 = zext i32 %240 to i64
  store i64 %241, i64* %RSI, align 8, !tbaa !2428
  %242 = add i64 %2111, 24
  store i64 %242, i64* %PC, align 8
  %243 = load i32, i32* %2078, align 4
  %244 = add i32 %243, %240
  %245 = zext i32 %244 to i64
  store i64 %245, i64* %RSI, align 8, !tbaa !2428
  %246 = icmp ult i32 %244, %240
  %247 = icmp ult i32 %244, %243
  %248 = or i1 %246, %247
  %249 = zext i1 %248 to i8
  store i8 %249, i8* %51, align 1, !tbaa !2433
  %250 = and i32 %244, 255
  %251 = tail call i32 @llvm.ctpop.i32(i32 %250) #10
  %252 = trunc i32 %251 to i8
  %253 = and i8 %252, 1
  %254 = xor i8 %253, 1
  store i8 %254, i8* %52, align 1, !tbaa !2447
  %255 = xor i32 %243, %240
  %256 = xor i32 %255, %244
  %257 = lshr i32 %256, 4
  %258 = trunc i32 %257 to i8
  %259 = and i8 %258, 1
  store i8 %259, i8* %53, align 1, !tbaa !2451
  %260 = icmp eq i32 %244, 0
  %261 = zext i1 %260 to i8
  store i8 %261, i8* %54, align 1, !tbaa !2448
  %262 = lshr i32 %244, 31
  %263 = trunc i32 %262 to i8
  store i8 %263, i8* %55, align 1, !tbaa !2449
  %264 = lshr i32 %240, 31
  %265 = lshr i32 %243, 31
  %266 = xor i32 %262, %264
  %267 = xor i32 %262, %265
  %268 = add nuw nsw i32 %266, %267
  %269 = icmp eq i32 %268, 2
  %270 = zext i1 %269 to i8
  store i8 %270, i8* %56, align 1, !tbaa !2450
  %271 = sext i32 %244 to i64
  store i64 %271, i64* %RCX, align 8, !tbaa !2428
  %272 = shl nsw i64 %271, 2
  %273 = add i64 %272, %238
  %274 = add i64 %2111, 30
  store i64 %274, i64* %PC, align 8
  %275 = inttoptr i64 %273 to i32*
  store i32 %210, i32* %275, align 4
  %276 = load i64, i64* %RBP, align 8
  %277 = add i64 %276, -28
  %278 = load i64, i64* %PC, align 8
  %279 = add i64 %278, 3
  store i64 %279, i64* %PC, align 8
  %280 = inttoptr i64 %277 to i32*
  %281 = load i32, i32* %280, align 4
  %282 = add i32 %281, 1
  %283 = zext i32 %282 to i64
  store i64 %283, i64* %RAX, align 8, !tbaa !2428
  %284 = icmp eq i32 %281, -1
  %285 = icmp eq i32 %282, 0
  %286 = or i1 %284, %285
  %287 = zext i1 %286 to i8
  store i8 %287, i8* %51, align 1, !tbaa !2433
  %288 = and i32 %282, 255
  %289 = tail call i32 @llvm.ctpop.i32(i32 %288) #10
  %290 = trunc i32 %289 to i8
  %291 = and i8 %290, 1
  %292 = xor i8 %291, 1
  store i8 %292, i8* %52, align 1, !tbaa !2447
  %293 = xor i32 %281, %282
  %294 = lshr i32 %293, 4
  %295 = trunc i32 %294 to i8
  %296 = and i8 %295, 1
  store i8 %296, i8* %53, align 1, !tbaa !2451
  %297 = zext i1 %285 to i8
  store i8 %297, i8* %54, align 1, !tbaa !2448
  %298 = lshr i32 %282, 31
  %299 = trunc i32 %298 to i8
  store i8 %299, i8* %55, align 1, !tbaa !2449
  %300 = lshr i32 %281, 31
  %301 = xor i32 %298, %300
  %302 = add nuw nsw i32 %301, %298
  %303 = icmp eq i32 %302, 2
  %304 = zext i1 %303 to i8
  store i8 %304, i8* %56, align 1, !tbaa !2450
  %305 = add i64 %278, 9
  store i64 %305, i64* %PC, align 8
  store i32 %282, i32* %280, align 4
  %306 = load i64, i64* %PC, align 8
  %307 = add i64 %306, -51
  store i64 %307, i64* %PC, align 8, !tbaa !2428
  br label %block_401c25

block_4023d9:                                     ; preds = %block_4021ff
  %308 = load i32, i32* %66, align 4
  %309 = shl i32 %308, 1
  %310 = icmp slt i32 %308, 0
  %311 = icmp slt i32 %309, 0
  %312 = xor i1 %310, %311
  %313 = zext i32 %309 to i64
  store i64 %313, i64* %RCX, align 8, !tbaa !2428
  %.lobit25 = lshr i32 %308, 31
  %314 = trunc i32 %.lobit25 to i8
  store i8 %314, i8* %51, align 1, !tbaa !2432
  %315 = and i32 %309, 254
  %316 = tail call i32 @llvm.ctpop.i32(i32 %315) #10
  %317 = trunc i32 %316 to i8
  %318 = and i8 %317, 1
  %319 = xor i8 %318, 1
  store i8 %319, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %320 = icmp eq i32 %309, 0
  %321 = zext i1 %320 to i8
  store i8 %321, i8* %54, align 1, !tbaa !2432
  %322 = lshr i32 %308, 30
  %323 = and i32 %322, 1
  %324 = trunc i32 %323 to i8
  store i8 %324, i8* %55, align 1, !tbaa !2432
  %325 = zext i1 %312 to i8
  store i8 %325, i8* %56, align 1, !tbaa !2432
  %326 = add i64 %58, -16
  %327 = add i64 %94, 20
  store i64 %327, i64* %PC, align 8
  %328 = inttoptr i64 %326 to i64*
  %329 = load i64, i64* %328, align 8
  store i64 %329, i64* %RDX, align 8, !tbaa !2428
  %330 = add i64 %94, 24
  store i64 %330, i64* %PC, align 8
  %331 = load i32, i32* %66, align 4
  %332 = sext i32 %331 to i64
  store i64 %332, i64* %RSI, align 8, !tbaa !2428
  %333 = shl nsw i64 %332, 2
  %334 = add i64 %333, %329
  %335 = add i64 %94, 27
  store i64 %335, i64* %PC, align 8
  %336 = inttoptr i64 %334 to i32*
  %337 = load i32, i32* %336, align 4
  %338 = add i32 %337, %309
  %339 = zext i32 %338 to i64
  store i64 %339, i64* %RCX, align 8, !tbaa !2428
  %340 = icmp ult i32 %338, %309
  %341 = icmp ult i32 %338, %337
  %342 = or i1 %340, %341
  %343 = zext i1 %342 to i8
  store i8 %343, i8* %51, align 1, !tbaa !2433
  %344 = and i32 %338, 255
  %345 = tail call i32 @llvm.ctpop.i32(i32 %344) #10
  %346 = trunc i32 %345 to i8
  %347 = and i8 %346, 1
  %348 = xor i8 %347, 1
  store i8 %348, i8* %52, align 1, !tbaa !2447
  %349 = xor i32 %337, %309
  %350 = xor i32 %349, %338
  %351 = lshr i32 %350, 4
  %352 = trunc i32 %351 to i8
  %353 = and i8 %352, 1
  store i8 %353, i8* %53, align 1, !tbaa !2451
  %354 = icmp eq i32 %338, 0
  %355 = zext i1 %354 to i8
  store i8 %355, i8* %54, align 1, !tbaa !2448
  %356 = lshr i32 %338, 31
  %357 = trunc i32 %356 to i8
  store i8 %357, i8* %55, align 1, !tbaa !2449
  %358 = lshr i32 %337, 31
  %359 = xor i32 %356, %323
  %360 = xor i32 %356, %358
  %361 = add nuw nsw i32 %359, %360
  %362 = icmp eq i32 %361, 2
  %363 = zext i1 %362 to i8
  store i8 %363, i8* %56, align 1, !tbaa !2450
  %364 = add i64 %58, -40
  %365 = add i64 %94, 30
  store i64 %365, i64* %PC, align 8
  %366 = inttoptr i64 %364 to i32*
  store i32 %338, i32* %366, align 4
  %367 = load i64, i64* %RBP, align 8
  %368 = add i64 %367, -24
  %369 = load i64, i64* %PC, align 8
  %370 = add i64 %369, 4
  store i64 %370, i64* %PC, align 8
  %371 = inttoptr i64 %368 to i64*
  %372 = load i64, i64* %371, align 8
  store i64 %372, i64* %RDX, align 8, !tbaa !2428
  %373 = add i64 %367, -40
  %374 = add i64 %369, 7
  store i64 %374, i64* %PC, align 8
  %375 = inttoptr i64 %373 to i32*
  %376 = load i32, i32* %375, align 4
  %377 = add i32 %376, 1
  %378 = zext i32 %377 to i64
  store i64 %378, i64* %RCX, align 8, !tbaa !2428
  %379 = icmp eq i32 %376, -1
  %380 = icmp eq i32 %377, 0
  %381 = or i1 %379, %380
  %382 = zext i1 %381 to i8
  store i8 %382, i8* %51, align 1, !tbaa !2433
  %383 = and i32 %377, 255
  %384 = tail call i32 @llvm.ctpop.i32(i32 %383) #10
  %385 = trunc i32 %384 to i8
  %386 = and i8 %385, 1
  %387 = xor i8 %386, 1
  store i8 %387, i8* %52, align 1, !tbaa !2447
  %388 = xor i32 %376, %377
  %389 = lshr i32 %388, 4
  %390 = trunc i32 %389 to i8
  %391 = and i8 %390, 1
  store i8 %391, i8* %53, align 1, !tbaa !2451
  %392 = zext i1 %380 to i8
  store i8 %392, i8* %54, align 1, !tbaa !2448
  %393 = lshr i32 %377, 31
  %394 = trunc i32 %393 to i8
  store i8 %394, i8* %55, align 1, !tbaa !2449
  %395 = lshr i32 %376, 31
  %396 = xor i32 %393, %395
  %397 = add nuw nsw i32 %396, %393
  %398 = icmp eq i32 %397, 2
  %399 = zext i1 %398 to i8
  store i8 %399, i8* %56, align 1, !tbaa !2450
  %400 = sext i32 %377 to i64
  store i64 %400, i64* %RSI, align 8, !tbaa !2428
  %401 = shl nsw i64 %400, 3
  %402 = add i64 %401, %372
  %403 = add i64 %369, 18
  store i64 %403, i64* %PC, align 8
  %404 = inttoptr i64 %402 to i64*
  %405 = load i64, i64* %404, align 8
  %406 = load i64, i64* %RAX, align 8
  %407 = xor i64 %406, %405
  store i64 %407, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %408 = trunc i64 %407 to i32
  %409 = and i32 %408, 255
  %410 = tail call i32 @llvm.ctpop.i32(i32 %409) #10
  %411 = trunc i32 %410 to i8
  %412 = and i8 %411, 1
  %413 = xor i8 %412, 1
  store i8 %413, i8* %52, align 1, !tbaa !2447
  %414 = icmp eq i64 %407, 0
  %415 = zext i1 %414 to i8
  store i8 %415, i8* %54, align 1, !tbaa !2448
  %416 = lshr i64 %407, 63
  %417 = trunc i64 %416 to i8
  store i8 %417, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %407, i64* %3753, align 1, !tbaa !2428
  store i64 0, i64* %3740, align 1, !tbaa !2428
  %418 = add i64 %369, 35
  store i64 %418, i64* %PC, align 8
  %419 = load i64, i64* %371, align 8
  store i64 %419, i64* %RDX, align 8, !tbaa !2428
  %420 = add i64 %369, 38
  store i64 %420, i64* %PC, align 8
  %421 = load i32, i32* %375, align 4
  %422 = add i32 %421, 1
  %423 = zext i32 %422 to i64
  store i64 %423, i64* %RCX, align 8, !tbaa !2428
  %424 = icmp eq i32 %421, -1
  %425 = icmp eq i32 %422, 0
  %426 = or i1 %424, %425
  %427 = zext i1 %426 to i8
  store i8 %427, i8* %51, align 1, !tbaa !2433
  %428 = and i32 %422, 255
  %429 = tail call i32 @llvm.ctpop.i32(i32 %428) #10
  %430 = trunc i32 %429 to i8
  %431 = and i8 %430, 1
  %432 = xor i8 %431, 1
  store i8 %432, i8* %52, align 1, !tbaa !2447
  %433 = xor i32 %421, %422
  %434 = lshr i32 %433, 4
  %435 = trunc i32 %434 to i8
  %436 = and i8 %435, 1
  store i8 %436, i8* %53, align 1, !tbaa !2451
  %437 = zext i1 %425 to i8
  store i8 %437, i8* %54, align 1, !tbaa !2448
  %438 = lshr i32 %422, 31
  %439 = trunc i32 %438 to i8
  store i8 %439, i8* %55, align 1, !tbaa !2449
  %440 = lshr i32 %421, 31
  %441 = xor i32 %438, %440
  %442 = add nuw nsw i32 %441, %438
  %443 = icmp eq i32 %442, 2
  %444 = zext i1 %443 to i8
  store i8 %444, i8* %56, align 1, !tbaa !2450
  %445 = sext i32 %422 to i64
  store i64 %445, i64* %RSI, align 8, !tbaa !2428
  %446 = shl nsw i64 %445, 3
  %447 = add i64 %446, %419
  %448 = add i64 %369, 49
  store i64 %448, i64* %PC, align 8
  %449 = inttoptr i64 %447 to i64*
  store i64 %407, i64* %449, align 8
  %450 = load i64, i64* %RBP, align 8
  %451 = add i64 %450, -24
  %452 = load i64, i64* %PC, align 8
  %453 = add i64 %452, 4
  store i64 %453, i64* %PC, align 8
  %454 = inttoptr i64 %451 to i64*
  %455 = load i64, i64* %454, align 8
  store i64 %455, i64* %RDX, align 8, !tbaa !2428
  %456 = add i64 %450, -40
  %457 = add i64 %452, 7
  store i64 %457, i64* %PC, align 8
  %458 = inttoptr i64 %456 to i32*
  %459 = load i32, i32* %458, align 4
  %460 = zext i32 %459 to i64
  store i64 %460, i64* %RCX, align 8, !tbaa !2428
  %461 = add i64 %450, -52
  %462 = add i64 %452, 10
  store i64 %462, i64* %PC, align 8
  %463 = inttoptr i64 %461 to i32*
  %464 = load i32, i32* %463, align 4
  %465 = add i32 %464, %459
  %466 = lshr i32 %465, 31
  %467 = add i32 %465, 1
  %468 = zext i32 %467 to i64
  store i64 %468, i64* %RCX, align 8, !tbaa !2428
  %469 = icmp eq i32 %465, -1
  %470 = icmp eq i32 %467, 0
  %471 = or i1 %469, %470
  %472 = zext i1 %471 to i8
  store i8 %472, i8* %51, align 1, !tbaa !2433
  %473 = and i32 %467, 255
  %474 = tail call i32 @llvm.ctpop.i32(i32 %473) #10
  %475 = trunc i32 %474 to i8
  %476 = and i8 %475, 1
  %477 = xor i8 %476, 1
  store i8 %477, i8* %52, align 1, !tbaa !2447
  %478 = xor i32 %465, %467
  %479 = lshr i32 %478, 4
  %480 = trunc i32 %479 to i8
  %481 = and i8 %480, 1
  store i8 %481, i8* %53, align 1, !tbaa !2451
  %482 = zext i1 %470 to i8
  store i8 %482, i8* %54, align 1, !tbaa !2448
  %483 = lshr i32 %467, 31
  %484 = trunc i32 %483 to i8
  store i8 %484, i8* %55, align 1, !tbaa !2449
  %485 = xor i32 %483, %466
  %486 = add nuw nsw i32 %485, %483
  %487 = icmp eq i32 %486, 2
  %488 = zext i1 %487 to i8
  store i8 %488, i8* %56, align 1, !tbaa !2450
  %489 = sext i32 %467 to i64
  store i64 %489, i64* %RSI, align 8, !tbaa !2428
  %490 = shl nsw i64 %489, 3
  %491 = add i64 %490, %455
  %492 = add i64 %452, 21
  store i64 %492, i64* %PC, align 8
  %493 = inttoptr i64 %491 to i64*
  %494 = load i64, i64* %493, align 8
  %495 = load i64, i64* %RAX, align 8
  %496 = xor i64 %495, %494
  store i64 %496, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %497 = trunc i64 %496 to i32
  %498 = and i32 %497, 255
  %499 = tail call i32 @llvm.ctpop.i32(i32 %498) #10
  %500 = trunc i32 %499 to i8
  %501 = and i8 %500, 1
  %502 = xor i8 %501, 1
  store i8 %502, i8* %52, align 1, !tbaa !2447
  %503 = icmp eq i64 %496, 0
  %504 = zext i1 %503 to i8
  store i8 %504, i8* %54, align 1, !tbaa !2448
  %505 = lshr i64 %496, 63
  %506 = trunc i64 %505 to i8
  store i8 %506, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %496, i64* %3753, align 1, !tbaa !2428
  store i64 0, i64* %3740, align 1, !tbaa !2428
  %507 = load i64, i64* %RBP, align 8
  %508 = add i64 %507, -24
  %509 = add i64 %452, 38
  store i64 %509, i64* %PC, align 8
  %510 = inttoptr i64 %508 to i64*
  %511 = load i64, i64* %510, align 8
  store i64 %511, i64* %RAX, align 8, !tbaa !2428
  %512 = add i64 %507, -40
  %513 = add i64 %452, 41
  store i64 %513, i64* %PC, align 8
  %514 = inttoptr i64 %512 to i32*
  %515 = load i32, i32* %514, align 4
  %516 = zext i32 %515 to i64
  store i64 %516, i64* %RCX, align 8, !tbaa !2428
  %517 = add i64 %507, -52
  %518 = add i64 %452, 44
  store i64 %518, i64* %PC, align 8
  %519 = inttoptr i64 %517 to i32*
  %520 = load i32, i32* %519, align 4
  %521 = add i32 %520, %515
  %522 = lshr i32 %521, 31
  %523 = add i32 %521, 1
  %524 = zext i32 %523 to i64
  store i64 %524, i64* %RCX, align 8, !tbaa !2428
  %525 = icmp eq i32 %521, -1
  %526 = icmp eq i32 %523, 0
  %527 = or i1 %525, %526
  %528 = zext i1 %527 to i8
  store i8 %528, i8* %51, align 1, !tbaa !2433
  %529 = and i32 %523, 255
  %530 = tail call i32 @llvm.ctpop.i32(i32 %529) #10
  %531 = trunc i32 %530 to i8
  %532 = and i8 %531, 1
  %533 = xor i8 %532, 1
  store i8 %533, i8* %52, align 1, !tbaa !2447
  %534 = xor i32 %521, %523
  %535 = lshr i32 %534, 4
  %536 = trunc i32 %535 to i8
  %537 = and i8 %536, 1
  store i8 %537, i8* %53, align 1, !tbaa !2451
  %538 = zext i1 %526 to i8
  store i8 %538, i8* %54, align 1, !tbaa !2448
  %539 = lshr i32 %523, 31
  %540 = trunc i32 %539 to i8
  store i8 %540, i8* %55, align 1, !tbaa !2449
  %541 = xor i32 %539, %522
  %542 = add nuw nsw i32 %541, %539
  %543 = icmp eq i32 %542, 2
  %544 = zext i1 %543 to i8
  store i8 %544, i8* %56, align 1, !tbaa !2450
  %545 = sext i32 %523 to i64
  store i64 %545, i64* %RDX, align 8, !tbaa !2428
  %546 = shl nsw i64 %545, 3
  %547 = add i64 %546, %511
  %548 = add i64 %452, 55
  store i64 %548, i64* %PC, align 8
  %549 = load i64, i64* %3753, align 1
  %550 = inttoptr i64 %547 to i64*
  store i64 %549, i64* %550, align 8
  %551 = load i64, i64* %RBP, align 8
  %552 = add i64 %551, -36
  %553 = load i64, i64* %PC, align 8
  %554 = add i64 %553, 3
  store i64 %554, i64* %PC, align 8
  %555 = inttoptr i64 %552 to i32*
  %556 = load i32, i32* %555, align 4
  %557 = add i32 %556, 1
  %558 = zext i32 %557 to i64
  store i64 %558, i64* %RAX, align 8, !tbaa !2428
  %559 = icmp eq i32 %556, -1
  %560 = icmp eq i32 %557, 0
  %561 = or i1 %559, %560
  %562 = zext i1 %561 to i8
  store i8 %562, i8* %51, align 1, !tbaa !2433
  %563 = and i32 %557, 255
  %564 = tail call i32 @llvm.ctpop.i32(i32 %563) #10
  %565 = trunc i32 %564 to i8
  %566 = and i8 %565, 1
  %567 = xor i8 %566, 1
  store i8 %567, i8* %52, align 1, !tbaa !2447
  %568 = xor i32 %556, %557
  %569 = lshr i32 %568, 4
  %570 = trunc i32 %569 to i8
  %571 = and i8 %570, 1
  store i8 %571, i8* %53, align 1, !tbaa !2451
  %572 = zext i1 %560 to i8
  store i8 %572, i8* %54, align 1, !tbaa !2448
  %573 = lshr i32 %557, 31
  %574 = trunc i32 %573 to i8
  store i8 %574, i8* %55, align 1, !tbaa !2449
  %575 = lshr i32 %556, 31
  %576 = xor i32 %573, %575
  %577 = add nuw nsw i32 %576, %573
  %578 = icmp eq i32 %577, 2
  %579 = zext i1 %578 to i8
  store i8 %579, i8* %56, align 1, !tbaa !2450
  %580 = add i64 %553, 9
  store i64 %580, i64* %PC, align 8
  store i32 %557, i32* %555, align 4
  %581 = load i64, i64* %PC, align 8
  %582 = add i64 %581, -636
  store i64 %582, i64* %PC, align 8, !tbaa !2428
  br label %block_4021ec

block_401ca9:                                     ; preds = %block_401c9d
  %583 = load i32, i32* %2762, align 4
  %584 = shl i32 %583, 1
  %585 = icmp slt i32 %583, 0
  %586 = icmp slt i32 %584, 0
  %587 = xor i1 %585, %586
  %588 = zext i32 %584 to i64
  store i64 %588, i64* %RCX, align 8, !tbaa !2428
  %.lobit16 = lshr i32 %583, 31
  %589 = trunc i32 %.lobit16 to i8
  store i8 %589, i8* %51, align 1, !tbaa !2432
  %590 = and i32 %584, 254
  %591 = tail call i32 @llvm.ctpop.i32(i32 %590) #10
  %592 = trunc i32 %591 to i8
  %593 = and i8 %592, 1
  %594 = xor i8 %593, 1
  store i8 %594, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %595 = icmp eq i32 %584, 0
  %596 = zext i1 %595 to i8
  store i8 %596, i8* %54, align 1, !tbaa !2432
  %597 = lshr i32 %583, 30
  %598 = and i32 %597, 1
  %599 = trunc i32 %598 to i8
  store i8 %599, i8* %55, align 1, !tbaa !2432
  %600 = zext i1 %587 to i8
  store i8 %600, i8* %56, align 1, !tbaa !2432
  %601 = add i64 %2759, -16
  %602 = add i64 %2795, 20
  store i64 %602, i64* %PC, align 8
  %603 = inttoptr i64 %601 to i64*
  %604 = load i64, i64* %603, align 8
  store i64 %604, i64* %RDX, align 8, !tbaa !2428
  %605 = add i64 %2795, 24
  store i64 %605, i64* %PC, align 8
  %606 = load i32, i32* %2767, align 4
  %607 = sext i32 %606 to i64
  store i64 %607, i64* %RSI, align 8, !tbaa !2428
  %608 = shl nsw i64 %607, 2
  %609 = add i64 %608, %604
  %610 = add i64 %2795, 27
  store i64 %610, i64* %PC, align 8
  %611 = inttoptr i64 %609 to i32*
  %612 = load i32, i32* %611, align 4
  %613 = add i32 %612, %584
  %614 = zext i32 %613 to i64
  store i64 %614, i64* %RCX, align 8, !tbaa !2428
  %615 = icmp ult i32 %613, %584
  %616 = icmp ult i32 %613, %612
  %617 = or i1 %615, %616
  %618 = zext i1 %617 to i8
  store i8 %618, i8* %51, align 1, !tbaa !2433
  %619 = and i32 %613, 255
  %620 = tail call i32 @llvm.ctpop.i32(i32 %619) #10
  %621 = trunc i32 %620 to i8
  %622 = and i8 %621, 1
  %623 = xor i8 %622, 1
  store i8 %623, i8* %52, align 1, !tbaa !2447
  %624 = xor i32 %612, %584
  %625 = xor i32 %624, %613
  %626 = lshr i32 %625, 4
  %627 = trunc i32 %626 to i8
  %628 = and i8 %627, 1
  store i8 %628, i8* %53, align 1, !tbaa !2451
  %629 = icmp eq i32 %613, 0
  %630 = zext i1 %629 to i8
  store i8 %630, i8* %54, align 1, !tbaa !2448
  %631 = lshr i32 %613, 31
  %632 = trunc i32 %631 to i8
  store i8 %632, i8* %55, align 1, !tbaa !2449
  %633 = lshr i32 %612, 31
  %634 = xor i32 %631, %598
  %635 = xor i32 %631, %633
  %636 = add nuw nsw i32 %634, %635
  %637 = icmp eq i32 %636, 2
  %638 = zext i1 %637 to i8
  store i8 %638, i8* %56, align 1, !tbaa !2450
  %639 = add i64 %2759, -32
  %640 = add i64 %2795, 30
  store i64 %640, i64* %PC, align 8
  %641 = inttoptr i64 %639 to i32*
  store i32 %613, i32* %641, align 4
  %642 = load i64, i64* %RBP, align 8
  %643 = add i64 %642, -36
  %644 = load i64, i64* %PC, align 8
  %645 = add i64 %644, 3
  store i64 %645, i64* %PC, align 8
  %646 = inttoptr i64 %643 to i32*
  %647 = load i32, i32* %646, align 4
  %648 = shl i32 %647, 1
  %649 = icmp slt i32 %647, 0
  %650 = icmp slt i32 %648, 0
  %651 = xor i1 %649, %650
  %652 = zext i32 %648 to i64
  store i64 %652, i64* %RCX, align 8, !tbaa !2428
  %.lobit17 = lshr i32 %647, 31
  %653 = trunc i32 %.lobit17 to i8
  store i8 %653, i8* %51, align 1, !tbaa !2432
  %654 = and i32 %648, 254
  %655 = tail call i32 @llvm.ctpop.i32(i32 %654) #10
  %656 = trunc i32 %655 to i8
  %657 = and i8 %656, 1
  %658 = xor i8 %657, 1
  store i8 %658, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %659 = icmp eq i32 %648, 0
  %660 = zext i1 %659 to i8
  store i8 %660, i8* %54, align 1, !tbaa !2432
  %661 = lshr i32 %647, 30
  %662 = and i32 %661, 1
  %663 = trunc i32 %662 to i8
  store i8 %663, i8* %55, align 1, !tbaa !2432
  %664 = zext i1 %651 to i8
  store i8 %664, i8* %56, align 1, !tbaa !2432
  %665 = add i64 %642, -16
  %666 = add i64 %644, 10
  store i64 %666, i64* %PC, align 8
  %667 = inttoptr i64 %665 to i64*
  %668 = load i64, i64* %667, align 8
  store i64 %668, i64* %RDX, align 8, !tbaa !2428
  %669 = add i64 %642, -28
  %670 = add i64 %644, 14
  store i64 %670, i64* %PC, align 8
  %671 = inttoptr i64 %669 to i32*
  %672 = load i32, i32* %671, align 4
  %673 = sext i32 %672 to i64
  store i64 %673, i64* %RSI, align 8, !tbaa !2428
  %674 = shl nsw i64 %673, 2
  %675 = add i64 %674, %668
  %676 = add i64 %644, 17
  store i64 %676, i64* %PC, align 8
  %677 = inttoptr i64 %675 to i32*
  %678 = load i32, i32* %677, align 4
  %679 = add i32 %678, %648
  %680 = zext i32 %679 to i64
  store i64 %680, i64* %RCX, align 8, !tbaa !2428
  %681 = icmp ult i32 %679, %648
  %682 = icmp ult i32 %679, %678
  %683 = or i1 %681, %682
  %684 = zext i1 %683 to i8
  store i8 %684, i8* %51, align 1, !tbaa !2433
  %685 = and i32 %679, 255
  %686 = tail call i32 @llvm.ctpop.i32(i32 %685) #10
  %687 = trunc i32 %686 to i8
  %688 = and i8 %687, 1
  %689 = xor i8 %688, 1
  store i8 %689, i8* %52, align 1, !tbaa !2447
  %690 = xor i32 %678, %648
  %691 = xor i32 %690, %679
  %692 = lshr i32 %691, 4
  %693 = trunc i32 %692 to i8
  %694 = and i8 %693, 1
  store i8 %694, i8* %53, align 1, !tbaa !2451
  %695 = icmp eq i32 %679, 0
  %696 = zext i1 %695 to i8
  store i8 %696, i8* %54, align 1, !tbaa !2448
  %697 = lshr i32 %679, 31
  %698 = trunc i32 %697 to i8
  store i8 %698, i8* %55, align 1, !tbaa !2449
  %699 = lshr i32 %678, 31
  %700 = xor i32 %697, %662
  %701 = xor i32 %697, %699
  %702 = add nuw nsw i32 %700, %701
  %703 = icmp eq i32 %702, 2
  %704 = zext i1 %703 to i8
  store i8 %704, i8* %56, align 1, !tbaa !2450
  %705 = add i64 %642, -40
  %706 = add i64 %644, 20
  store i64 %706, i64* %PC, align 8
  %707 = inttoptr i64 %705 to i32*
  store i32 %679, i32* %707, align 4
  %708 = load i64, i64* %RBP, align 8
  %709 = add i64 %708, -24
  %710 = load i64, i64* %PC, align 8
  %711 = add i64 %710, 4
  store i64 %711, i64* %PC, align 8
  %712 = inttoptr i64 %709 to i64*
  %713 = load i64, i64* %712, align 8
  store i64 %713, i64* %RDX, align 8, !tbaa !2428
  %714 = add i64 %708, -32
  %715 = add i64 %710, 8
  store i64 %715, i64* %PC, align 8
  %716 = inttoptr i64 %714 to i32*
  %717 = load i32, i32* %716, align 4
  %718 = sext i32 %717 to i64
  store i64 %718, i64* %RSI, align 8, !tbaa !2428
  %719 = shl nsw i64 %718, 3
  %720 = add i64 %719, %713
  %721 = add i64 %710, 13
  store i64 %721, i64* %PC, align 8
  %722 = inttoptr i64 %720 to i64*
  %723 = load i64, i64* %722, align 8
  store i64 %723, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %724 = add i64 %708, -64
  %725 = add i64 %710, 18
  store i64 %725, i64* %PC, align 8
  %726 = inttoptr i64 %724 to i64*
  store i64 %723, i64* %726, align 8
  %727 = load i64, i64* %RBP, align 8
  %728 = add i64 %727, -24
  %729 = load i64, i64* %PC, align 8
  %730 = add i64 %729, 4
  store i64 %730, i64* %PC, align 8
  %731 = inttoptr i64 %728 to i64*
  %732 = load i64, i64* %731, align 8
  store i64 %732, i64* %RDX, align 8, !tbaa !2428
  %733 = add i64 %727, -32
  %734 = add i64 %729, 7
  store i64 %734, i64* %PC, align 8
  %735 = inttoptr i64 %733 to i32*
  %736 = load i32, i32* %735, align 4
  %737 = add i32 %736, 1
  %738 = zext i32 %737 to i64
  store i64 %738, i64* %RCX, align 8, !tbaa !2428
  %739 = icmp eq i32 %736, -1
  %740 = icmp eq i32 %737, 0
  %741 = or i1 %739, %740
  %742 = zext i1 %741 to i8
  store i8 %742, i8* %51, align 1, !tbaa !2433
  %743 = and i32 %737, 255
  %744 = tail call i32 @llvm.ctpop.i32(i32 %743) #10
  %745 = trunc i32 %744 to i8
  %746 = and i8 %745, 1
  %747 = xor i8 %746, 1
  store i8 %747, i8* %52, align 1, !tbaa !2447
  %748 = xor i32 %736, %737
  %749 = lshr i32 %748, 4
  %750 = trunc i32 %749 to i8
  %751 = and i8 %750, 1
  store i8 %751, i8* %53, align 1, !tbaa !2451
  %752 = zext i1 %740 to i8
  store i8 %752, i8* %54, align 1, !tbaa !2448
  %753 = lshr i32 %737, 31
  %754 = trunc i32 %753 to i8
  store i8 %754, i8* %55, align 1, !tbaa !2449
  %755 = lshr i32 %736, 31
  %756 = xor i32 %753, %755
  %757 = add nuw nsw i32 %756, %753
  %758 = icmp eq i32 %757, 2
  %759 = zext i1 %758 to i8
  store i8 %759, i8* %56, align 1, !tbaa !2450
  %760 = sext i32 %737 to i64
  store i64 %760, i64* %RSI, align 8, !tbaa !2428
  %761 = shl nsw i64 %760, 3
  %762 = add i64 %761, %732
  %763 = add i64 %729, 18
  store i64 %763, i64* %PC, align 8
  %764 = inttoptr i64 %762 to i64*
  %765 = load i64, i64* %764, align 8
  %766 = load i64, i64* %RAX, align 8
  %767 = xor i64 %766, %765
  store i64 %767, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %768 = trunc i64 %767 to i32
  %769 = and i32 %768, 255
  %770 = tail call i32 @llvm.ctpop.i32(i32 %769) #10
  %771 = trunc i32 %770 to i8
  %772 = and i8 %771, 1
  %773 = xor i8 %772, 1
  store i8 %773, i8* %52, align 1, !tbaa !2447
  %774 = icmp eq i64 %767, 0
  %775 = zext i1 %774 to i8
  store i8 %775, i8* %54, align 1, !tbaa !2448
  %776 = lshr i64 %767, 63
  %777 = trunc i64 %776 to i8
  store i8 %777, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %767, i64* %3852, align 1, !tbaa !2428
  store i64 0, i64* %3850, align 1, !tbaa !2428
  %778 = add i64 %727, -72
  %779 = add i64 %729, 36
  store i64 %779, i64* %PC, align 8
  %780 = inttoptr i64 %778 to i64*
  store i64 %767, i64* %780, align 8
  %781 = load i64, i64* %RBP, align 8
  %782 = add i64 %781, -24
  %783 = load i64, i64* %PC, align 8
  %784 = add i64 %783, 4
  store i64 %784, i64* %PC, align 8
  %785 = inttoptr i64 %782 to i64*
  %786 = load i64, i64* %785, align 8
  store i64 %786, i64* %RDX, align 8, !tbaa !2428
  %787 = add i64 %781, -40
  %788 = add i64 %783, 8
  store i64 %788, i64* %PC, align 8
  %789 = inttoptr i64 %787 to i32*
  %790 = load i32, i32* %789, align 4
  %791 = sext i32 %790 to i64
  store i64 %791, i64* %RSI, align 8, !tbaa !2428
  %792 = shl nsw i64 %791, 3
  %793 = add i64 %792, %786
  %794 = add i64 %783, 13
  store i64 %794, i64* %PC, align 8
  %795 = inttoptr i64 %793 to i64*
  %796 = load i64, i64* %795, align 8
  store i64 %796, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %797 = add i64 %781, -80
  %798 = add i64 %783, 18
  store i64 %798, i64* %PC, align 8
  %799 = inttoptr i64 %797 to i64*
  store i64 %796, i64* %799, align 8
  %800 = load i64, i64* %RBP, align 8
  %801 = add i64 %800, -24
  %802 = load i64, i64* %PC, align 8
  %803 = add i64 %802, 4
  store i64 %803, i64* %PC, align 8
  %804 = inttoptr i64 %801 to i64*
  %805 = load i64, i64* %804, align 8
  store i64 %805, i64* %RDX, align 8, !tbaa !2428
  %806 = add i64 %800, -40
  %807 = add i64 %802, 7
  store i64 %807, i64* %PC, align 8
  %808 = inttoptr i64 %806 to i32*
  %809 = load i32, i32* %808, align 4
  %810 = add i32 %809, 1
  %811 = zext i32 %810 to i64
  store i64 %811, i64* %RCX, align 8, !tbaa !2428
  %812 = icmp eq i32 %809, -1
  %813 = icmp eq i32 %810, 0
  %814 = or i1 %812, %813
  %815 = zext i1 %814 to i8
  store i8 %815, i8* %51, align 1, !tbaa !2433
  %816 = and i32 %810, 255
  %817 = tail call i32 @llvm.ctpop.i32(i32 %816) #10
  %818 = trunc i32 %817 to i8
  %819 = and i8 %818, 1
  %820 = xor i8 %819, 1
  store i8 %820, i8* %52, align 1, !tbaa !2447
  %821 = xor i32 %809, %810
  %822 = lshr i32 %821, 4
  %823 = trunc i32 %822 to i8
  %824 = and i8 %823, 1
  store i8 %824, i8* %53, align 1, !tbaa !2451
  %825 = zext i1 %813 to i8
  store i8 %825, i8* %54, align 1, !tbaa !2448
  %826 = lshr i32 %810, 31
  %827 = trunc i32 %826 to i8
  store i8 %827, i8* %55, align 1, !tbaa !2449
  %828 = lshr i32 %809, 31
  %829 = xor i32 %826, %828
  %830 = add nuw nsw i32 %829, %826
  %831 = icmp eq i32 %830, 2
  %832 = zext i1 %831 to i8
  store i8 %832, i8* %56, align 1, !tbaa !2450
  %833 = sext i32 %810 to i64
  store i64 %833, i64* %RSI, align 8, !tbaa !2428
  %834 = shl nsw i64 %833, 3
  %835 = add i64 %834, %805
  %836 = add i64 %802, 18
  store i64 %836, i64* %PC, align 8
  %837 = inttoptr i64 %835 to i64*
  %838 = load i64, i64* %837, align 8
  %839 = load i64, i64* %RAX, align 8
  %840 = xor i64 %839, %838
  store i64 %840, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %841 = trunc i64 %840 to i32
  %842 = and i32 %841, 255
  %843 = tail call i32 @llvm.ctpop.i32(i32 %842) #10
  %844 = trunc i32 %843 to i8
  %845 = and i8 %844, 1
  %846 = xor i8 %845, 1
  store i8 %846, i8* %52, align 1, !tbaa !2447
  %847 = icmp eq i64 %840, 0
  %848 = zext i1 %847 to i8
  store i8 %848, i8* %54, align 1, !tbaa !2448
  %849 = lshr i64 %840, 63
  %850 = trunc i64 %849 to i8
  store i8 %850, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %840, i64* %3852, align 1, !tbaa !2428
  store i64 0, i64* %3850, align 1, !tbaa !2428
  %851 = add i64 %800, -88
  %852 = add i64 %802, 36
  store i64 %852, i64* %PC, align 8
  %853 = inttoptr i64 %851 to i64*
  store i64 %840, i64* %853, align 8
  %854 = load i64, i64* %RBP, align 8
  %855 = add i64 %854, -80
  %856 = load i64, i64* %PC, align 8
  %857 = add i64 %856, 5
  store i64 %857, i64* %PC, align 8
  %858 = inttoptr i64 %855 to i64*
  %859 = load i64, i64* %858, align 8
  store i64 %859, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %860 = add i64 %854, -24
  %861 = add i64 %856, 9
  store i64 %861, i64* %PC, align 8
  %862 = inttoptr i64 %860 to i64*
  %863 = load i64, i64* %862, align 8
  store i64 %863, i64* %RDX, align 8, !tbaa !2428
  %864 = add i64 %854, -32
  %865 = add i64 %856, 13
  store i64 %865, i64* %PC, align 8
  %866 = inttoptr i64 %864 to i32*
  %867 = load i32, i32* %866, align 4
  %868 = sext i32 %867 to i64
  store i64 %868, i64* %RSI, align 8, !tbaa !2428
  %869 = shl nsw i64 %868, 3
  %870 = add i64 %869, %863
  %871 = add i64 %856, 18
  store i64 %871, i64* %PC, align 8
  %872 = inttoptr i64 %870 to i64*
  store i64 %859, i64* %872, align 8
  %873 = load i64, i64* %RBP, align 8
  %874 = add i64 %873, -88
  %875 = load i64, i64* %PC, align 8
  %876 = add i64 %875, 5
  store i64 %876, i64* %PC, align 8
  %877 = inttoptr i64 %874 to i64*
  %878 = load i64, i64* %877, align 8
  store i64 %878, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %879 = add i64 %873, -24
  %880 = add i64 %875, 9
  store i64 %880, i64* %PC, align 8
  %881 = inttoptr i64 %879 to i64*
  %882 = load i64, i64* %881, align 8
  store i64 %882, i64* %RDX, align 8, !tbaa !2428
  %883 = add i64 %873, -32
  %884 = add i64 %875, 12
  store i64 %884, i64* %PC, align 8
  %885 = inttoptr i64 %883 to i32*
  %886 = load i32, i32* %885, align 4
  %887 = add i32 %886, 1
  %888 = zext i32 %887 to i64
  store i64 %888, i64* %RCX, align 8, !tbaa !2428
  %889 = icmp eq i32 %886, -1
  %890 = icmp eq i32 %887, 0
  %891 = or i1 %889, %890
  %892 = zext i1 %891 to i8
  store i8 %892, i8* %51, align 1, !tbaa !2433
  %893 = and i32 %887, 255
  %894 = tail call i32 @llvm.ctpop.i32(i32 %893) #10
  %895 = trunc i32 %894 to i8
  %896 = and i8 %895, 1
  %897 = xor i8 %896, 1
  store i8 %897, i8* %52, align 1, !tbaa !2447
  %898 = xor i32 %886, %887
  %899 = lshr i32 %898, 4
  %900 = trunc i32 %899 to i8
  %901 = and i8 %900, 1
  store i8 %901, i8* %53, align 1, !tbaa !2451
  %902 = zext i1 %890 to i8
  store i8 %902, i8* %54, align 1, !tbaa !2448
  %903 = lshr i32 %887, 31
  %904 = trunc i32 %903 to i8
  store i8 %904, i8* %55, align 1, !tbaa !2449
  %905 = lshr i32 %886, 31
  %906 = xor i32 %903, %905
  %907 = add nuw nsw i32 %906, %903
  %908 = icmp eq i32 %907, 2
  %909 = zext i1 %908 to i8
  store i8 %909, i8* %56, align 1, !tbaa !2450
  %910 = sext i32 %887 to i64
  store i64 %910, i64* %RSI, align 8, !tbaa !2428
  %911 = shl nsw i64 %910, 3
  %912 = add i64 %911, %882
  %913 = add i64 %875, 23
  store i64 %913, i64* %PC, align 8
  %914 = inttoptr i64 %912 to i64*
  store i64 %878, i64* %914, align 8
  %915 = load i64, i64* %RBP, align 8
  %916 = add i64 %915, -64
  %917 = load i64, i64* %PC, align 8
  %918 = add i64 %917, 5
  store i64 %918, i64* %PC, align 8
  %919 = inttoptr i64 %916 to i64*
  %920 = load i64, i64* %919, align 8
  store i64 %920, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %921 = add i64 %915, -24
  %922 = add i64 %917, 9
  store i64 %922, i64* %PC, align 8
  %923 = inttoptr i64 %921 to i64*
  %924 = load i64, i64* %923, align 8
  store i64 %924, i64* %RDX, align 8, !tbaa !2428
  %925 = add i64 %915, -40
  %926 = add i64 %917, 13
  store i64 %926, i64* %PC, align 8
  %927 = inttoptr i64 %925 to i32*
  %928 = load i32, i32* %927, align 4
  %929 = sext i32 %928 to i64
  store i64 %929, i64* %RSI, align 8, !tbaa !2428
  %930 = shl nsw i64 %929, 3
  %931 = add i64 %930, %924
  %932 = add i64 %917, 18
  store i64 %932, i64* %PC, align 8
  %933 = inttoptr i64 %931 to i64*
  store i64 %920, i64* %933, align 8
  %934 = load i64, i64* %RBP, align 8
  %935 = add i64 %934, -72
  %936 = load i64, i64* %PC, align 8
  %937 = add i64 %936, 5
  store i64 %937, i64* %PC, align 8
  %938 = inttoptr i64 %935 to i64*
  %939 = load i64, i64* %938, align 8
  store i64 %939, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %940 = add i64 %934, -24
  %941 = add i64 %936, 9
  store i64 %941, i64* %PC, align 8
  %942 = inttoptr i64 %940 to i64*
  %943 = load i64, i64* %942, align 8
  store i64 %943, i64* %RDX, align 8, !tbaa !2428
  %944 = add i64 %934, -40
  %945 = add i64 %936, 12
  store i64 %945, i64* %PC, align 8
  %946 = inttoptr i64 %944 to i32*
  %947 = load i32, i32* %946, align 4
  %948 = add i32 %947, 1
  %949 = zext i32 %948 to i64
  store i64 %949, i64* %RCX, align 8, !tbaa !2428
  %950 = icmp eq i32 %947, -1
  %951 = icmp eq i32 %948, 0
  %952 = or i1 %950, %951
  %953 = zext i1 %952 to i8
  store i8 %953, i8* %51, align 1, !tbaa !2433
  %954 = and i32 %948, 255
  %955 = tail call i32 @llvm.ctpop.i32(i32 %954) #10
  %956 = trunc i32 %955 to i8
  %957 = and i8 %956, 1
  %958 = xor i8 %957, 1
  store i8 %958, i8* %52, align 1, !tbaa !2447
  %959 = xor i32 %947, %948
  %960 = lshr i32 %959, 4
  %961 = trunc i32 %960 to i8
  %962 = and i8 %961, 1
  store i8 %962, i8* %53, align 1, !tbaa !2451
  %963 = zext i1 %951 to i8
  store i8 %963, i8* %54, align 1, !tbaa !2448
  %964 = lshr i32 %948, 31
  %965 = trunc i32 %964 to i8
  store i8 %965, i8* %55, align 1, !tbaa !2449
  %966 = lshr i32 %947, 31
  %967 = xor i32 %964, %966
  %968 = add nuw nsw i32 %967, %964
  %969 = icmp eq i32 %968, 2
  %970 = zext i1 %969 to i8
  store i8 %970, i8* %56, align 1, !tbaa !2450
  %971 = sext i32 %948 to i64
  store i64 %971, i64* %RSI, align 8, !tbaa !2428
  %972 = shl nsw i64 %971, 3
  %973 = add i64 %972, %943
  %974 = add i64 %936, 23
  store i64 %974, i64* %PC, align 8
  %975 = inttoptr i64 %973 to i64*
  store i64 %939, i64* %975, align 8
  %976 = load i64, i64* %RBP, align 8
  %977 = add i64 %976, -52
  %978 = load i64, i64* %PC, align 8
  %979 = add i64 %978, 3
  store i64 %979, i64* %PC, align 8
  %980 = inttoptr i64 %977 to i32*
  %981 = load i32, i32* %980, align 4
  %982 = zext i32 %981 to i64
  store i64 %982, i64* %RCX, align 8, !tbaa !2428
  %983 = add i64 %976, -32
  %984 = add i64 %978, 6
  store i64 %984, i64* %PC, align 8
  %985 = inttoptr i64 %983 to i32*
  %986 = load i32, i32* %985, align 4
  %987 = add i32 %986, %981
  %988 = zext i32 %987 to i64
  store i64 %988, i64* %RCX, align 8, !tbaa !2428
  %989 = icmp ult i32 %987, %981
  %990 = icmp ult i32 %987, %986
  %991 = or i1 %989, %990
  %992 = zext i1 %991 to i8
  store i8 %992, i8* %51, align 1, !tbaa !2433
  %993 = and i32 %987, 255
  %994 = tail call i32 @llvm.ctpop.i32(i32 %993) #10
  %995 = trunc i32 %994 to i8
  %996 = and i8 %995, 1
  %997 = xor i8 %996, 1
  store i8 %997, i8* %52, align 1, !tbaa !2447
  %998 = xor i32 %986, %981
  %999 = xor i32 %998, %987
  %1000 = lshr i32 %999, 4
  %1001 = trunc i32 %1000 to i8
  %1002 = and i8 %1001, 1
  store i8 %1002, i8* %53, align 1, !tbaa !2451
  %1003 = icmp eq i32 %987, 0
  %1004 = zext i1 %1003 to i8
  store i8 %1004, i8* %54, align 1, !tbaa !2448
  %1005 = lshr i32 %987, 31
  %1006 = trunc i32 %1005 to i8
  store i8 %1006, i8* %55, align 1, !tbaa !2449
  %1007 = lshr i32 %981, 31
  %1008 = lshr i32 %986, 31
  %1009 = xor i32 %1005, %1007
  %1010 = xor i32 %1005, %1008
  %1011 = add nuw nsw i32 %1009, %1010
  %1012 = icmp eq i32 %1011, 2
  %1013 = zext i1 %1012 to i8
  store i8 %1013, i8* %56, align 1, !tbaa !2450
  %1014 = add i64 %978, 9
  store i64 %1014, i64* %PC, align 8
  store i32 %987, i32* %985, align 4
  %1015 = load i64, i64* %RBP, align 8
  %1016 = add i64 %1015, -52
  %1017 = load i64, i64* %PC, align 8
  %1018 = add i64 %1017, 3
  store i64 %1018, i64* %PC, align 8
  %1019 = inttoptr i64 %1016 to i32*
  %1020 = load i32, i32* %1019, align 4
  %1021 = shl i32 %1020, 1
  %1022 = icmp slt i32 %1020, 0
  %1023 = icmp slt i32 %1021, 0
  %1024 = xor i1 %1022, %1023
  %1025 = zext i32 %1021 to i64
  store i64 %1025, i64* %RCX, align 8, !tbaa !2428
  %.lobit18 = lshr i32 %1020, 31
  %1026 = trunc i32 %.lobit18 to i8
  store i8 %1026, i8* %51, align 1, !tbaa !2432
  %1027 = and i32 %1021, 254
  %1028 = tail call i32 @llvm.ctpop.i32(i32 %1027) #10
  %1029 = trunc i32 %1028 to i8
  %1030 = and i8 %1029, 1
  %1031 = xor i8 %1030, 1
  store i8 %1031, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %1032 = icmp eq i32 %1021, 0
  %1033 = zext i1 %1032 to i8
  store i8 %1033, i8* %54, align 1, !tbaa !2432
  %1034 = lshr i32 %1020, 30
  %1035 = and i32 %1034, 1
  %1036 = trunc i32 %1035 to i8
  store i8 %1036, i8* %55, align 1, !tbaa !2432
  %1037 = zext i1 %1024 to i8
  store i8 %1037, i8* %56, align 1, !tbaa !2432
  %1038 = add i64 %1015, -40
  %1039 = add i64 %1017, 9
  store i64 %1039, i64* %PC, align 8
  %1040 = inttoptr i64 %1038 to i32*
  %1041 = load i32, i32* %1040, align 4
  %1042 = add i32 %1041, %1021
  %1043 = zext i32 %1042 to i64
  store i64 %1043, i64* %RCX, align 8, !tbaa !2428
  %1044 = icmp ult i32 %1042, %1021
  %1045 = icmp ult i32 %1042, %1041
  %1046 = or i1 %1044, %1045
  %1047 = zext i1 %1046 to i8
  store i8 %1047, i8* %51, align 1, !tbaa !2433
  %1048 = and i32 %1042, 255
  %1049 = tail call i32 @llvm.ctpop.i32(i32 %1048) #10
  %1050 = trunc i32 %1049 to i8
  %1051 = and i8 %1050, 1
  %1052 = xor i8 %1051, 1
  store i8 %1052, i8* %52, align 1, !tbaa !2447
  %1053 = xor i32 %1041, %1021
  %1054 = xor i32 %1053, %1042
  %1055 = lshr i32 %1054, 4
  %1056 = trunc i32 %1055 to i8
  %1057 = and i8 %1056, 1
  store i8 %1057, i8* %53, align 1, !tbaa !2451
  %1058 = icmp eq i32 %1042, 0
  %1059 = zext i1 %1058 to i8
  store i8 %1059, i8* %54, align 1, !tbaa !2448
  %1060 = lshr i32 %1042, 31
  %1061 = trunc i32 %1060 to i8
  store i8 %1061, i8* %55, align 1, !tbaa !2449
  %1062 = lshr i32 %1041, 31
  %1063 = xor i32 %1060, %1035
  %1064 = xor i32 %1060, %1062
  %1065 = add nuw nsw i32 %1063, %1064
  %1066 = icmp eq i32 %1065, 2
  %1067 = zext i1 %1066 to i8
  store i8 %1067, i8* %56, align 1, !tbaa !2450
  %1068 = add i64 %1017, 12
  store i64 %1068, i64* %PC, align 8
  store i32 %1042, i32* %1040, align 4
  %1069 = load i64, i64* %RBP, align 8
  %1070 = add i64 %1069, -24
  %1071 = load i64, i64* %PC, align 8
  %1072 = add i64 %1071, 4
  store i64 %1072, i64* %PC, align 8
  %1073 = inttoptr i64 %1070 to i64*
  %1074 = load i64, i64* %1073, align 8
  store i64 %1074, i64* %RDX, align 8, !tbaa !2428
  %1075 = add i64 %1069, -32
  %1076 = add i64 %1071, 8
  store i64 %1076, i64* %PC, align 8
  %1077 = inttoptr i64 %1075 to i32*
  %1078 = load i32, i32* %1077, align 4
  %1079 = sext i32 %1078 to i64
  store i64 %1079, i64* %RSI, align 8, !tbaa !2428
  %1080 = shl nsw i64 %1079, 3
  %1081 = add i64 %1080, %1074
  %1082 = add i64 %1071, 13
  store i64 %1082, i64* %PC, align 8
  %1083 = inttoptr i64 %1081 to i64*
  %1084 = load i64, i64* %1083, align 8
  store i64 %1084, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1085 = add i64 %1069, -64
  %1086 = add i64 %1071, 18
  store i64 %1086, i64* %PC, align 8
  %1087 = inttoptr i64 %1085 to i64*
  store i64 %1084, i64* %1087, align 8
  %1088 = load i64, i64* %RBP, align 8
  %1089 = add i64 %1088, -24
  %1090 = load i64, i64* %PC, align 8
  %1091 = add i64 %1090, 4
  store i64 %1091, i64* %PC, align 8
  %1092 = inttoptr i64 %1089 to i64*
  %1093 = load i64, i64* %1092, align 8
  store i64 %1093, i64* %RDX, align 8, !tbaa !2428
  %1094 = add i64 %1088, -32
  %1095 = add i64 %1090, 7
  store i64 %1095, i64* %PC, align 8
  %1096 = inttoptr i64 %1094 to i32*
  %1097 = load i32, i32* %1096, align 4
  %1098 = add i32 %1097, 1
  %1099 = zext i32 %1098 to i64
  store i64 %1099, i64* %RCX, align 8, !tbaa !2428
  %1100 = icmp eq i32 %1097, -1
  %1101 = icmp eq i32 %1098, 0
  %1102 = or i1 %1100, %1101
  %1103 = zext i1 %1102 to i8
  store i8 %1103, i8* %51, align 1, !tbaa !2433
  %1104 = and i32 %1098, 255
  %1105 = tail call i32 @llvm.ctpop.i32(i32 %1104) #10
  %1106 = trunc i32 %1105 to i8
  %1107 = and i8 %1106, 1
  %1108 = xor i8 %1107, 1
  store i8 %1108, i8* %52, align 1, !tbaa !2447
  %1109 = xor i32 %1097, %1098
  %1110 = lshr i32 %1109, 4
  %1111 = trunc i32 %1110 to i8
  %1112 = and i8 %1111, 1
  store i8 %1112, i8* %53, align 1, !tbaa !2451
  %1113 = zext i1 %1101 to i8
  store i8 %1113, i8* %54, align 1, !tbaa !2448
  %1114 = lshr i32 %1098, 31
  %1115 = trunc i32 %1114 to i8
  store i8 %1115, i8* %55, align 1, !tbaa !2449
  %1116 = lshr i32 %1097, 31
  %1117 = xor i32 %1114, %1116
  %1118 = add nuw nsw i32 %1117, %1114
  %1119 = icmp eq i32 %1118, 2
  %1120 = zext i1 %1119 to i8
  store i8 %1120, i8* %56, align 1, !tbaa !2450
  %1121 = sext i32 %1098 to i64
  store i64 %1121, i64* %RSI, align 8, !tbaa !2428
  %1122 = shl nsw i64 %1121, 3
  %1123 = add i64 %1122, %1093
  %1124 = add i64 %1090, 18
  store i64 %1124, i64* %PC, align 8
  %1125 = inttoptr i64 %1123 to i64*
  %1126 = load i64, i64* %1125, align 8
  %1127 = load i64, i64* %RAX, align 8
  %1128 = xor i64 %1127, %1126
  store i64 %1128, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %1129 = trunc i64 %1128 to i32
  %1130 = and i32 %1129, 255
  %1131 = tail call i32 @llvm.ctpop.i32(i32 %1130) #10
  %1132 = trunc i32 %1131 to i8
  %1133 = and i8 %1132, 1
  %1134 = xor i8 %1133, 1
  store i8 %1134, i8* %52, align 1, !tbaa !2447
  %1135 = icmp eq i64 %1128, 0
  %1136 = zext i1 %1135 to i8
  store i8 %1136, i8* %54, align 1, !tbaa !2448
  %1137 = lshr i64 %1128, 63
  %1138 = trunc i64 %1137 to i8
  store i8 %1138, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %1128, i64* %3852, align 1, !tbaa !2428
  store i64 0, i64* %3850, align 1, !tbaa !2428
  %1139 = add i64 %1088, -72
  %1140 = add i64 %1090, 36
  store i64 %1140, i64* %PC, align 8
  %1141 = inttoptr i64 %1139 to i64*
  store i64 %1128, i64* %1141, align 8
  %1142 = load i64, i64* %RBP, align 8
  %1143 = add i64 %1142, -24
  %1144 = load i64, i64* %PC, align 8
  %1145 = add i64 %1144, 4
  store i64 %1145, i64* %PC, align 8
  %1146 = inttoptr i64 %1143 to i64*
  %1147 = load i64, i64* %1146, align 8
  store i64 %1147, i64* %RDX, align 8, !tbaa !2428
  %1148 = add i64 %1142, -40
  %1149 = add i64 %1144, 8
  store i64 %1149, i64* %PC, align 8
  %1150 = inttoptr i64 %1148 to i32*
  %1151 = load i32, i32* %1150, align 4
  %1152 = sext i32 %1151 to i64
  store i64 %1152, i64* %RSI, align 8, !tbaa !2428
  %1153 = shl nsw i64 %1152, 3
  %1154 = add i64 %1153, %1147
  %1155 = add i64 %1144, 13
  store i64 %1155, i64* %PC, align 8
  %1156 = inttoptr i64 %1154 to i64*
  %1157 = load i64, i64* %1156, align 8
  store i64 %1157, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1158 = add i64 %1142, -80
  %1159 = add i64 %1144, 18
  store i64 %1159, i64* %PC, align 8
  %1160 = inttoptr i64 %1158 to i64*
  store i64 %1157, i64* %1160, align 8
  %1161 = load i64, i64* %RBP, align 8
  %1162 = add i64 %1161, -24
  %1163 = load i64, i64* %PC, align 8
  %1164 = add i64 %1163, 4
  store i64 %1164, i64* %PC, align 8
  %1165 = inttoptr i64 %1162 to i64*
  %1166 = load i64, i64* %1165, align 8
  store i64 %1166, i64* %RDX, align 8, !tbaa !2428
  %1167 = add i64 %1161, -40
  %1168 = add i64 %1163, 7
  store i64 %1168, i64* %PC, align 8
  %1169 = inttoptr i64 %1167 to i32*
  %1170 = load i32, i32* %1169, align 4
  %1171 = add i32 %1170, 1
  %1172 = zext i32 %1171 to i64
  store i64 %1172, i64* %RCX, align 8, !tbaa !2428
  %1173 = icmp eq i32 %1170, -1
  %1174 = icmp eq i32 %1171, 0
  %1175 = or i1 %1173, %1174
  %1176 = zext i1 %1175 to i8
  store i8 %1176, i8* %51, align 1, !tbaa !2433
  %1177 = and i32 %1171, 255
  %1178 = tail call i32 @llvm.ctpop.i32(i32 %1177) #10
  %1179 = trunc i32 %1178 to i8
  %1180 = and i8 %1179, 1
  %1181 = xor i8 %1180, 1
  store i8 %1181, i8* %52, align 1, !tbaa !2447
  %1182 = xor i32 %1170, %1171
  %1183 = lshr i32 %1182, 4
  %1184 = trunc i32 %1183 to i8
  %1185 = and i8 %1184, 1
  store i8 %1185, i8* %53, align 1, !tbaa !2451
  %1186 = zext i1 %1174 to i8
  store i8 %1186, i8* %54, align 1, !tbaa !2448
  %1187 = lshr i32 %1171, 31
  %1188 = trunc i32 %1187 to i8
  store i8 %1188, i8* %55, align 1, !tbaa !2449
  %1189 = lshr i32 %1170, 31
  %1190 = xor i32 %1187, %1189
  %1191 = add nuw nsw i32 %1190, %1187
  %1192 = icmp eq i32 %1191, 2
  %1193 = zext i1 %1192 to i8
  store i8 %1193, i8* %56, align 1, !tbaa !2450
  %1194 = sext i32 %1171 to i64
  store i64 %1194, i64* %RSI, align 8, !tbaa !2428
  %1195 = shl nsw i64 %1194, 3
  %1196 = add i64 %1195, %1166
  %1197 = add i64 %1163, 18
  store i64 %1197, i64* %PC, align 8
  %1198 = inttoptr i64 %1196 to i64*
  %1199 = load i64, i64* %1198, align 8
  %1200 = load i64, i64* %RAX, align 8
  %1201 = xor i64 %1200, %1199
  store i64 %1201, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %1202 = trunc i64 %1201 to i32
  %1203 = and i32 %1202, 255
  %1204 = tail call i32 @llvm.ctpop.i32(i32 %1203) #10
  %1205 = trunc i32 %1204 to i8
  %1206 = and i8 %1205, 1
  %1207 = xor i8 %1206, 1
  store i8 %1207, i8* %52, align 1, !tbaa !2447
  %1208 = icmp eq i64 %1201, 0
  %1209 = zext i1 %1208 to i8
  store i8 %1209, i8* %54, align 1, !tbaa !2448
  %1210 = lshr i64 %1201, 63
  %1211 = trunc i64 %1210 to i8
  store i8 %1211, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %1201, i64* %3852, align 1, !tbaa !2428
  store i64 0, i64* %3850, align 1, !tbaa !2428
  %1212 = add i64 %1161, -88
  %1213 = add i64 %1163, 36
  store i64 %1213, i64* %PC, align 8
  %1214 = inttoptr i64 %1212 to i64*
  store i64 %1201, i64* %1214, align 8
  %1215 = load i64, i64* %RBP, align 8
  %1216 = add i64 %1215, -80
  %1217 = load i64, i64* %PC, align 8
  %1218 = add i64 %1217, 5
  store i64 %1218, i64* %PC, align 8
  %1219 = inttoptr i64 %1216 to i64*
  %1220 = load i64, i64* %1219, align 8
  store i64 %1220, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1221 = add i64 %1215, -24
  %1222 = add i64 %1217, 9
  store i64 %1222, i64* %PC, align 8
  %1223 = inttoptr i64 %1221 to i64*
  %1224 = load i64, i64* %1223, align 8
  store i64 %1224, i64* %RDX, align 8, !tbaa !2428
  %1225 = add i64 %1215, -32
  %1226 = add i64 %1217, 13
  store i64 %1226, i64* %PC, align 8
  %1227 = inttoptr i64 %1225 to i32*
  %1228 = load i32, i32* %1227, align 4
  %1229 = sext i32 %1228 to i64
  store i64 %1229, i64* %RSI, align 8, !tbaa !2428
  %1230 = shl nsw i64 %1229, 3
  %1231 = add i64 %1230, %1224
  %1232 = add i64 %1217, 18
  store i64 %1232, i64* %PC, align 8
  %1233 = inttoptr i64 %1231 to i64*
  store i64 %1220, i64* %1233, align 8
  %1234 = load i64, i64* %RBP, align 8
  %1235 = add i64 %1234, -88
  %1236 = load i64, i64* %PC, align 8
  %1237 = add i64 %1236, 5
  store i64 %1237, i64* %PC, align 8
  %1238 = inttoptr i64 %1235 to i64*
  %1239 = load i64, i64* %1238, align 8
  store i64 %1239, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1240 = add i64 %1234, -24
  %1241 = add i64 %1236, 9
  store i64 %1241, i64* %PC, align 8
  %1242 = inttoptr i64 %1240 to i64*
  %1243 = load i64, i64* %1242, align 8
  store i64 %1243, i64* %RDX, align 8, !tbaa !2428
  %1244 = add i64 %1234, -32
  %1245 = add i64 %1236, 12
  store i64 %1245, i64* %PC, align 8
  %1246 = inttoptr i64 %1244 to i32*
  %1247 = load i32, i32* %1246, align 4
  %1248 = add i32 %1247, 1
  %1249 = zext i32 %1248 to i64
  store i64 %1249, i64* %RCX, align 8, !tbaa !2428
  %1250 = icmp eq i32 %1247, -1
  %1251 = icmp eq i32 %1248, 0
  %1252 = or i1 %1250, %1251
  %1253 = zext i1 %1252 to i8
  store i8 %1253, i8* %51, align 1, !tbaa !2433
  %1254 = and i32 %1248, 255
  %1255 = tail call i32 @llvm.ctpop.i32(i32 %1254) #10
  %1256 = trunc i32 %1255 to i8
  %1257 = and i8 %1256, 1
  %1258 = xor i8 %1257, 1
  store i8 %1258, i8* %52, align 1, !tbaa !2447
  %1259 = xor i32 %1247, %1248
  %1260 = lshr i32 %1259, 4
  %1261 = trunc i32 %1260 to i8
  %1262 = and i8 %1261, 1
  store i8 %1262, i8* %53, align 1, !tbaa !2451
  %1263 = zext i1 %1251 to i8
  store i8 %1263, i8* %54, align 1, !tbaa !2448
  %1264 = lshr i32 %1248, 31
  %1265 = trunc i32 %1264 to i8
  store i8 %1265, i8* %55, align 1, !tbaa !2449
  %1266 = lshr i32 %1247, 31
  %1267 = xor i32 %1264, %1266
  %1268 = add nuw nsw i32 %1267, %1264
  %1269 = icmp eq i32 %1268, 2
  %1270 = zext i1 %1269 to i8
  store i8 %1270, i8* %56, align 1, !tbaa !2450
  %1271 = sext i32 %1248 to i64
  store i64 %1271, i64* %RSI, align 8, !tbaa !2428
  %1272 = shl nsw i64 %1271, 3
  %1273 = add i64 %1272, %1243
  %1274 = add i64 %1236, 23
  store i64 %1274, i64* %PC, align 8
  %1275 = inttoptr i64 %1273 to i64*
  store i64 %1239, i64* %1275, align 8
  %1276 = load i64, i64* %RBP, align 8
  %1277 = add i64 %1276, -64
  %1278 = load i64, i64* %PC, align 8
  %1279 = add i64 %1278, 5
  store i64 %1279, i64* %PC, align 8
  %1280 = inttoptr i64 %1277 to i64*
  %1281 = load i64, i64* %1280, align 8
  store i64 %1281, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1282 = add i64 %1276, -24
  %1283 = add i64 %1278, 9
  store i64 %1283, i64* %PC, align 8
  %1284 = inttoptr i64 %1282 to i64*
  %1285 = load i64, i64* %1284, align 8
  store i64 %1285, i64* %RDX, align 8, !tbaa !2428
  %1286 = add i64 %1276, -40
  %1287 = add i64 %1278, 13
  store i64 %1287, i64* %PC, align 8
  %1288 = inttoptr i64 %1286 to i32*
  %1289 = load i32, i32* %1288, align 4
  %1290 = sext i32 %1289 to i64
  store i64 %1290, i64* %RSI, align 8, !tbaa !2428
  %1291 = shl nsw i64 %1290, 3
  %1292 = add i64 %1291, %1285
  %1293 = add i64 %1278, 18
  store i64 %1293, i64* %PC, align 8
  %1294 = inttoptr i64 %1292 to i64*
  store i64 %1281, i64* %1294, align 8
  %1295 = load i64, i64* %RBP, align 8
  %1296 = add i64 %1295, -72
  %1297 = load i64, i64* %PC, align 8
  %1298 = add i64 %1297, 5
  store i64 %1298, i64* %PC, align 8
  %1299 = inttoptr i64 %1296 to i64*
  %1300 = load i64, i64* %1299, align 8
  store i64 %1300, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1301 = add i64 %1295, -24
  %1302 = add i64 %1297, 9
  store i64 %1302, i64* %PC, align 8
  %1303 = inttoptr i64 %1301 to i64*
  %1304 = load i64, i64* %1303, align 8
  store i64 %1304, i64* %RDX, align 8, !tbaa !2428
  %1305 = add i64 %1295, -40
  %1306 = add i64 %1297, 12
  store i64 %1306, i64* %PC, align 8
  %1307 = inttoptr i64 %1305 to i32*
  %1308 = load i32, i32* %1307, align 4
  %1309 = add i32 %1308, 1
  %1310 = zext i32 %1309 to i64
  store i64 %1310, i64* %RCX, align 8, !tbaa !2428
  %1311 = icmp eq i32 %1308, -1
  %1312 = icmp eq i32 %1309, 0
  %1313 = or i1 %1311, %1312
  %1314 = zext i1 %1313 to i8
  store i8 %1314, i8* %51, align 1, !tbaa !2433
  %1315 = and i32 %1309, 255
  %1316 = tail call i32 @llvm.ctpop.i32(i32 %1315) #10
  %1317 = trunc i32 %1316 to i8
  %1318 = and i8 %1317, 1
  %1319 = xor i8 %1318, 1
  store i8 %1319, i8* %52, align 1, !tbaa !2447
  %1320 = xor i32 %1308, %1309
  %1321 = lshr i32 %1320, 4
  %1322 = trunc i32 %1321 to i8
  %1323 = and i8 %1322, 1
  store i8 %1323, i8* %53, align 1, !tbaa !2451
  %1324 = zext i1 %1312 to i8
  store i8 %1324, i8* %54, align 1, !tbaa !2448
  %1325 = lshr i32 %1309, 31
  %1326 = trunc i32 %1325 to i8
  store i8 %1326, i8* %55, align 1, !tbaa !2449
  %1327 = lshr i32 %1308, 31
  %1328 = xor i32 %1325, %1327
  %1329 = add nuw nsw i32 %1328, %1325
  %1330 = icmp eq i32 %1329, 2
  %1331 = zext i1 %1330 to i8
  store i8 %1331, i8* %56, align 1, !tbaa !2450
  %1332 = sext i32 %1309 to i64
  store i64 %1332, i64* %RSI, align 8, !tbaa !2428
  %1333 = shl nsw i64 %1332, 3
  %1334 = add i64 %1333, %1304
  %1335 = add i64 %1297, 23
  store i64 %1335, i64* %PC, align 8
  %1336 = inttoptr i64 %1334 to i64*
  store i64 %1300, i64* %1336, align 8
  %1337 = load i64, i64* %RBP, align 8
  %1338 = add i64 %1337, -52
  %1339 = load i64, i64* %PC, align 8
  %1340 = add i64 %1339, 3
  store i64 %1340, i64* %PC, align 8
  %1341 = inttoptr i64 %1338 to i32*
  %1342 = load i32, i32* %1341, align 4
  %1343 = zext i32 %1342 to i64
  store i64 %1343, i64* %RCX, align 8, !tbaa !2428
  %1344 = add i64 %1337, -32
  %1345 = add i64 %1339, 6
  store i64 %1345, i64* %PC, align 8
  %1346 = inttoptr i64 %1344 to i32*
  %1347 = load i32, i32* %1346, align 4
  %1348 = add i32 %1347, %1342
  %1349 = zext i32 %1348 to i64
  store i64 %1349, i64* %RCX, align 8, !tbaa !2428
  %1350 = icmp ult i32 %1348, %1342
  %1351 = icmp ult i32 %1348, %1347
  %1352 = or i1 %1350, %1351
  %1353 = zext i1 %1352 to i8
  store i8 %1353, i8* %51, align 1, !tbaa !2433
  %1354 = and i32 %1348, 255
  %1355 = tail call i32 @llvm.ctpop.i32(i32 %1354) #10
  %1356 = trunc i32 %1355 to i8
  %1357 = and i8 %1356, 1
  %1358 = xor i8 %1357, 1
  store i8 %1358, i8* %52, align 1, !tbaa !2447
  %1359 = xor i32 %1347, %1342
  %1360 = xor i32 %1359, %1348
  %1361 = lshr i32 %1360, 4
  %1362 = trunc i32 %1361 to i8
  %1363 = and i8 %1362, 1
  store i8 %1363, i8* %53, align 1, !tbaa !2451
  %1364 = icmp eq i32 %1348, 0
  %1365 = zext i1 %1364 to i8
  store i8 %1365, i8* %54, align 1, !tbaa !2448
  %1366 = lshr i32 %1348, 31
  %1367 = trunc i32 %1366 to i8
  store i8 %1367, i8* %55, align 1, !tbaa !2449
  %1368 = lshr i32 %1342, 31
  %1369 = lshr i32 %1347, 31
  %1370 = xor i32 %1366, %1368
  %1371 = xor i32 %1366, %1369
  %1372 = add nuw nsw i32 %1370, %1371
  %1373 = icmp eq i32 %1372, 2
  %1374 = zext i1 %1373 to i8
  store i8 %1374, i8* %56, align 1, !tbaa !2450
  %1375 = add i64 %1339, 9
  store i64 %1375, i64* %PC, align 8
  store i32 %1348, i32* %1346, align 4
  %1376 = load i64, i64* %RBP, align 8
  %1377 = add i64 %1376, -52
  %1378 = load i64, i64* %PC, align 8
  %1379 = add i64 %1378, 3
  store i64 %1379, i64* %PC, align 8
  %1380 = inttoptr i64 %1377 to i32*
  %1381 = load i32, i32* %1380, align 4
  %1382 = zext i32 %1381 to i64
  store i64 %1382, i64* %RCX, align 8, !tbaa !2428
  %1383 = add i64 %1376, -40
  %1384 = add i64 %1378, 6
  store i64 %1384, i64* %PC, align 8
  %1385 = inttoptr i64 %1383 to i32*
  %1386 = load i32, i32* %1385, align 4
  %1387 = sub i32 %1386, %1381
  %1388 = zext i32 %1387 to i64
  store i64 %1388, i64* %RDI, align 8, !tbaa !2428
  %1389 = icmp ult i32 %1386, %1381
  %1390 = zext i1 %1389 to i8
  store i8 %1390, i8* %51, align 1, !tbaa !2433
  %1391 = and i32 %1387, 255
  %1392 = tail call i32 @llvm.ctpop.i32(i32 %1391) #10
  %1393 = trunc i32 %1392 to i8
  %1394 = and i8 %1393, 1
  %1395 = xor i8 %1394, 1
  store i8 %1395, i8* %52, align 1, !tbaa !2447
  %1396 = xor i32 %1381, %1386
  %1397 = xor i32 %1396, %1387
  %1398 = lshr i32 %1397, 4
  %1399 = trunc i32 %1398 to i8
  %1400 = and i8 %1399, 1
  store i8 %1400, i8* %53, align 1, !tbaa !2451
  %1401 = icmp eq i32 %1387, 0
  %1402 = zext i1 %1401 to i8
  store i8 %1402, i8* %54, align 1, !tbaa !2448
  %1403 = lshr i32 %1387, 31
  %1404 = trunc i32 %1403 to i8
  store i8 %1404, i8* %55, align 1, !tbaa !2449
  %1405 = lshr i32 %1386, 31
  %1406 = lshr i32 %1381, 31
  %1407 = xor i32 %1406, %1405
  %1408 = xor i32 %1403, %1405
  %1409 = add nuw nsw i32 %1408, %1407
  %1410 = icmp eq i32 %1409, 2
  %1411 = zext i1 %1410 to i8
  store i8 %1411, i8* %56, align 1, !tbaa !2450
  %1412 = add i64 %1378, 11
  store i64 %1412, i64* %PC, align 8
  store i32 %1387, i32* %1385, align 4
  %1413 = load i64, i64* %RBP, align 8
  %1414 = add i64 %1413, -24
  %1415 = load i64, i64* %PC, align 8
  %1416 = add i64 %1415, 4
  store i64 %1416, i64* %PC, align 8
  %1417 = inttoptr i64 %1414 to i64*
  %1418 = load i64, i64* %1417, align 8
  store i64 %1418, i64* %RDX, align 8, !tbaa !2428
  %1419 = add i64 %1413, -32
  %1420 = add i64 %1415, 8
  store i64 %1420, i64* %PC, align 8
  %1421 = inttoptr i64 %1419 to i32*
  %1422 = load i32, i32* %1421, align 4
  %1423 = sext i32 %1422 to i64
  store i64 %1423, i64* %RSI, align 8, !tbaa !2428
  %1424 = shl nsw i64 %1423, 3
  %1425 = add i64 %1424, %1418
  %1426 = add i64 %1415, 13
  store i64 %1426, i64* %PC, align 8
  %1427 = inttoptr i64 %1425 to i64*
  %1428 = load i64, i64* %1427, align 8
  store i64 %1428, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1429 = add i64 %1413, -64
  %1430 = add i64 %1415, 18
  store i64 %1430, i64* %PC, align 8
  %1431 = inttoptr i64 %1429 to i64*
  store i64 %1428, i64* %1431, align 8
  %1432 = load i64, i64* %RBP, align 8
  %1433 = add i64 %1432, -24
  %1434 = load i64, i64* %PC, align 8
  %1435 = add i64 %1434, 4
  store i64 %1435, i64* %PC, align 8
  %1436 = inttoptr i64 %1433 to i64*
  %1437 = load i64, i64* %1436, align 8
  store i64 %1437, i64* %RDX, align 8, !tbaa !2428
  %1438 = add i64 %1432, -32
  %1439 = add i64 %1434, 7
  store i64 %1439, i64* %PC, align 8
  %1440 = inttoptr i64 %1438 to i32*
  %1441 = load i32, i32* %1440, align 4
  %1442 = add i32 %1441, 1
  %1443 = zext i32 %1442 to i64
  store i64 %1443, i64* %RCX, align 8, !tbaa !2428
  %1444 = icmp eq i32 %1441, -1
  %1445 = icmp eq i32 %1442, 0
  %1446 = or i1 %1444, %1445
  %1447 = zext i1 %1446 to i8
  store i8 %1447, i8* %51, align 1, !tbaa !2433
  %1448 = and i32 %1442, 255
  %1449 = tail call i32 @llvm.ctpop.i32(i32 %1448) #10
  %1450 = trunc i32 %1449 to i8
  %1451 = and i8 %1450, 1
  %1452 = xor i8 %1451, 1
  store i8 %1452, i8* %52, align 1, !tbaa !2447
  %1453 = xor i32 %1441, %1442
  %1454 = lshr i32 %1453, 4
  %1455 = trunc i32 %1454 to i8
  %1456 = and i8 %1455, 1
  store i8 %1456, i8* %53, align 1, !tbaa !2451
  %1457 = zext i1 %1445 to i8
  store i8 %1457, i8* %54, align 1, !tbaa !2448
  %1458 = lshr i32 %1442, 31
  %1459 = trunc i32 %1458 to i8
  store i8 %1459, i8* %55, align 1, !tbaa !2449
  %1460 = lshr i32 %1441, 31
  %1461 = xor i32 %1458, %1460
  %1462 = add nuw nsw i32 %1461, %1458
  %1463 = icmp eq i32 %1462, 2
  %1464 = zext i1 %1463 to i8
  store i8 %1464, i8* %56, align 1, !tbaa !2450
  %1465 = sext i32 %1442 to i64
  store i64 %1465, i64* %RSI, align 8, !tbaa !2428
  %1466 = shl nsw i64 %1465, 3
  %1467 = add i64 %1466, %1437
  %1468 = add i64 %1434, 18
  store i64 %1468, i64* %PC, align 8
  %1469 = inttoptr i64 %1467 to i64*
  %1470 = load i64, i64* %1469, align 8
  %1471 = load i64, i64* %RAX, align 8
  %1472 = xor i64 %1471, %1470
  store i64 %1472, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %1473 = trunc i64 %1472 to i32
  %1474 = and i32 %1473, 255
  %1475 = tail call i32 @llvm.ctpop.i32(i32 %1474) #10
  %1476 = trunc i32 %1475 to i8
  %1477 = and i8 %1476, 1
  %1478 = xor i8 %1477, 1
  store i8 %1478, i8* %52, align 1, !tbaa !2447
  %1479 = icmp eq i64 %1472, 0
  %1480 = zext i1 %1479 to i8
  store i8 %1480, i8* %54, align 1, !tbaa !2448
  %1481 = lshr i64 %1472, 63
  %1482 = trunc i64 %1481 to i8
  store i8 %1482, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %1472, i64* %3852, align 1, !tbaa !2428
  store i64 0, i64* %3850, align 1, !tbaa !2428
  %1483 = add i64 %1432, -72
  %1484 = add i64 %1434, 36
  store i64 %1484, i64* %PC, align 8
  %1485 = inttoptr i64 %1483 to i64*
  store i64 %1472, i64* %1485, align 8
  %1486 = load i64, i64* %RBP, align 8
  %1487 = add i64 %1486, -24
  %1488 = load i64, i64* %PC, align 8
  %1489 = add i64 %1488, 4
  store i64 %1489, i64* %PC, align 8
  %1490 = inttoptr i64 %1487 to i64*
  %1491 = load i64, i64* %1490, align 8
  store i64 %1491, i64* %RDX, align 8, !tbaa !2428
  %1492 = add i64 %1486, -40
  %1493 = add i64 %1488, 8
  store i64 %1493, i64* %PC, align 8
  %1494 = inttoptr i64 %1492 to i32*
  %1495 = load i32, i32* %1494, align 4
  %1496 = sext i32 %1495 to i64
  store i64 %1496, i64* %RSI, align 8, !tbaa !2428
  %1497 = shl nsw i64 %1496, 3
  %1498 = add i64 %1497, %1491
  %1499 = add i64 %1488, 13
  store i64 %1499, i64* %PC, align 8
  %1500 = inttoptr i64 %1498 to i64*
  %1501 = load i64, i64* %1500, align 8
  store i64 %1501, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1502 = add i64 %1486, -80
  %1503 = add i64 %1488, 18
  store i64 %1503, i64* %PC, align 8
  %1504 = inttoptr i64 %1502 to i64*
  store i64 %1501, i64* %1504, align 8
  %1505 = load i64, i64* %RBP, align 8
  %1506 = add i64 %1505, -24
  %1507 = load i64, i64* %PC, align 8
  %1508 = add i64 %1507, 4
  store i64 %1508, i64* %PC, align 8
  %1509 = inttoptr i64 %1506 to i64*
  %1510 = load i64, i64* %1509, align 8
  store i64 %1510, i64* %RDX, align 8, !tbaa !2428
  %1511 = add i64 %1505, -40
  %1512 = add i64 %1507, 7
  store i64 %1512, i64* %PC, align 8
  %1513 = inttoptr i64 %1511 to i32*
  %1514 = load i32, i32* %1513, align 4
  %1515 = add i32 %1514, 1
  %1516 = zext i32 %1515 to i64
  store i64 %1516, i64* %RCX, align 8, !tbaa !2428
  %1517 = icmp eq i32 %1514, -1
  %1518 = icmp eq i32 %1515, 0
  %1519 = or i1 %1517, %1518
  %1520 = zext i1 %1519 to i8
  store i8 %1520, i8* %51, align 1, !tbaa !2433
  %1521 = and i32 %1515, 255
  %1522 = tail call i32 @llvm.ctpop.i32(i32 %1521) #10
  %1523 = trunc i32 %1522 to i8
  %1524 = and i8 %1523, 1
  %1525 = xor i8 %1524, 1
  store i8 %1525, i8* %52, align 1, !tbaa !2447
  %1526 = xor i32 %1514, %1515
  %1527 = lshr i32 %1526, 4
  %1528 = trunc i32 %1527 to i8
  %1529 = and i8 %1528, 1
  store i8 %1529, i8* %53, align 1, !tbaa !2451
  %1530 = zext i1 %1518 to i8
  store i8 %1530, i8* %54, align 1, !tbaa !2448
  %1531 = lshr i32 %1515, 31
  %1532 = trunc i32 %1531 to i8
  store i8 %1532, i8* %55, align 1, !tbaa !2449
  %1533 = lshr i32 %1514, 31
  %1534 = xor i32 %1531, %1533
  %1535 = add nuw nsw i32 %1534, %1531
  %1536 = icmp eq i32 %1535, 2
  %1537 = zext i1 %1536 to i8
  store i8 %1537, i8* %56, align 1, !tbaa !2450
  %1538 = sext i32 %1515 to i64
  store i64 %1538, i64* %RSI, align 8, !tbaa !2428
  %1539 = shl nsw i64 %1538, 3
  %1540 = add i64 %1539, %1510
  %1541 = add i64 %1507, 18
  store i64 %1541, i64* %PC, align 8
  %1542 = inttoptr i64 %1540 to i64*
  %1543 = load i64, i64* %1542, align 8
  %1544 = load i64, i64* %RAX, align 8
  %1545 = xor i64 %1544, %1543
  store i64 %1545, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %1546 = trunc i64 %1545 to i32
  %1547 = and i32 %1546, 255
  %1548 = tail call i32 @llvm.ctpop.i32(i32 %1547) #10
  %1549 = trunc i32 %1548 to i8
  %1550 = and i8 %1549, 1
  %1551 = xor i8 %1550, 1
  store i8 %1551, i8* %52, align 1, !tbaa !2447
  %1552 = icmp eq i64 %1545, 0
  %1553 = zext i1 %1552 to i8
  store i8 %1553, i8* %54, align 1, !tbaa !2448
  %1554 = lshr i64 %1545, 63
  %1555 = trunc i64 %1554 to i8
  store i8 %1555, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %1545, i64* %3852, align 1, !tbaa !2428
  store i64 0, i64* %3850, align 1, !tbaa !2428
  %1556 = add i64 %1505, -88
  %1557 = add i64 %1507, 36
  store i64 %1557, i64* %PC, align 8
  %1558 = inttoptr i64 %1556 to i64*
  store i64 %1545, i64* %1558, align 8
  %1559 = load i64, i64* %RBP, align 8
  %1560 = add i64 %1559, -80
  %1561 = load i64, i64* %PC, align 8
  %1562 = add i64 %1561, 5
  store i64 %1562, i64* %PC, align 8
  %1563 = inttoptr i64 %1560 to i64*
  %1564 = load i64, i64* %1563, align 8
  store i64 %1564, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1565 = add i64 %1559, -24
  %1566 = add i64 %1561, 9
  store i64 %1566, i64* %PC, align 8
  %1567 = inttoptr i64 %1565 to i64*
  %1568 = load i64, i64* %1567, align 8
  store i64 %1568, i64* %RDX, align 8, !tbaa !2428
  %1569 = add i64 %1559, -32
  %1570 = add i64 %1561, 13
  store i64 %1570, i64* %PC, align 8
  %1571 = inttoptr i64 %1569 to i32*
  %1572 = load i32, i32* %1571, align 4
  %1573 = sext i32 %1572 to i64
  store i64 %1573, i64* %RSI, align 8, !tbaa !2428
  %1574 = shl nsw i64 %1573, 3
  %1575 = add i64 %1574, %1568
  %1576 = add i64 %1561, 18
  store i64 %1576, i64* %PC, align 8
  %1577 = inttoptr i64 %1575 to i64*
  store i64 %1564, i64* %1577, align 8
  %1578 = load i64, i64* %RBP, align 8
  %1579 = add i64 %1578, -88
  %1580 = load i64, i64* %PC, align 8
  %1581 = add i64 %1580, 5
  store i64 %1581, i64* %PC, align 8
  %1582 = inttoptr i64 %1579 to i64*
  %1583 = load i64, i64* %1582, align 8
  store i64 %1583, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1584 = add i64 %1578, -24
  %1585 = add i64 %1580, 9
  store i64 %1585, i64* %PC, align 8
  %1586 = inttoptr i64 %1584 to i64*
  %1587 = load i64, i64* %1586, align 8
  store i64 %1587, i64* %RDX, align 8, !tbaa !2428
  %1588 = add i64 %1578, -32
  %1589 = add i64 %1580, 12
  store i64 %1589, i64* %PC, align 8
  %1590 = inttoptr i64 %1588 to i32*
  %1591 = load i32, i32* %1590, align 4
  %1592 = add i32 %1591, 1
  %1593 = zext i32 %1592 to i64
  store i64 %1593, i64* %RCX, align 8, !tbaa !2428
  %1594 = icmp eq i32 %1591, -1
  %1595 = icmp eq i32 %1592, 0
  %1596 = or i1 %1594, %1595
  %1597 = zext i1 %1596 to i8
  store i8 %1597, i8* %51, align 1, !tbaa !2433
  %1598 = and i32 %1592, 255
  %1599 = tail call i32 @llvm.ctpop.i32(i32 %1598) #10
  %1600 = trunc i32 %1599 to i8
  %1601 = and i8 %1600, 1
  %1602 = xor i8 %1601, 1
  store i8 %1602, i8* %52, align 1, !tbaa !2447
  %1603 = xor i32 %1591, %1592
  %1604 = lshr i32 %1603, 4
  %1605 = trunc i32 %1604 to i8
  %1606 = and i8 %1605, 1
  store i8 %1606, i8* %53, align 1, !tbaa !2451
  %1607 = zext i1 %1595 to i8
  store i8 %1607, i8* %54, align 1, !tbaa !2448
  %1608 = lshr i32 %1592, 31
  %1609 = trunc i32 %1608 to i8
  store i8 %1609, i8* %55, align 1, !tbaa !2449
  %1610 = lshr i32 %1591, 31
  %1611 = xor i32 %1608, %1610
  %1612 = add nuw nsw i32 %1611, %1608
  %1613 = icmp eq i32 %1612, 2
  %1614 = zext i1 %1613 to i8
  store i8 %1614, i8* %56, align 1, !tbaa !2450
  %1615 = sext i32 %1592 to i64
  store i64 %1615, i64* %RSI, align 8, !tbaa !2428
  %1616 = shl nsw i64 %1615, 3
  %1617 = add i64 %1616, %1587
  %1618 = add i64 %1580, 23
  store i64 %1618, i64* %PC, align 8
  %1619 = inttoptr i64 %1617 to i64*
  store i64 %1583, i64* %1619, align 8
  %1620 = load i64, i64* %RBP, align 8
  %1621 = add i64 %1620, -64
  %1622 = load i64, i64* %PC, align 8
  %1623 = add i64 %1622, 5
  store i64 %1623, i64* %PC, align 8
  %1624 = inttoptr i64 %1621 to i64*
  %1625 = load i64, i64* %1624, align 8
  store i64 %1625, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1626 = add i64 %1620, -24
  %1627 = add i64 %1622, 9
  store i64 %1627, i64* %PC, align 8
  %1628 = inttoptr i64 %1626 to i64*
  %1629 = load i64, i64* %1628, align 8
  store i64 %1629, i64* %RDX, align 8, !tbaa !2428
  %1630 = add i64 %1620, -40
  %1631 = add i64 %1622, 13
  store i64 %1631, i64* %PC, align 8
  %1632 = inttoptr i64 %1630 to i32*
  %1633 = load i32, i32* %1632, align 4
  %1634 = sext i32 %1633 to i64
  store i64 %1634, i64* %RSI, align 8, !tbaa !2428
  %1635 = shl nsw i64 %1634, 3
  %1636 = add i64 %1635, %1629
  %1637 = add i64 %1622, 18
  store i64 %1637, i64* %PC, align 8
  %1638 = inttoptr i64 %1636 to i64*
  store i64 %1625, i64* %1638, align 8
  %1639 = load i64, i64* %RBP, align 8
  %1640 = add i64 %1639, -72
  %1641 = load i64, i64* %PC, align 8
  %1642 = add i64 %1641, 5
  store i64 %1642, i64* %PC, align 8
  %1643 = inttoptr i64 %1640 to i64*
  %1644 = load i64, i64* %1643, align 8
  store i64 %1644, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1645 = add i64 %1639, -24
  %1646 = add i64 %1641, 9
  store i64 %1646, i64* %PC, align 8
  %1647 = inttoptr i64 %1645 to i64*
  %1648 = load i64, i64* %1647, align 8
  store i64 %1648, i64* %RDX, align 8, !tbaa !2428
  %1649 = add i64 %1639, -40
  %1650 = add i64 %1641, 12
  store i64 %1650, i64* %PC, align 8
  %1651 = inttoptr i64 %1649 to i32*
  %1652 = load i32, i32* %1651, align 4
  %1653 = add i32 %1652, 1
  %1654 = zext i32 %1653 to i64
  store i64 %1654, i64* %RCX, align 8, !tbaa !2428
  %1655 = icmp eq i32 %1652, -1
  %1656 = icmp eq i32 %1653, 0
  %1657 = or i1 %1655, %1656
  %1658 = zext i1 %1657 to i8
  store i8 %1658, i8* %51, align 1, !tbaa !2433
  %1659 = and i32 %1653, 255
  %1660 = tail call i32 @llvm.ctpop.i32(i32 %1659) #10
  %1661 = trunc i32 %1660 to i8
  %1662 = and i8 %1661, 1
  %1663 = xor i8 %1662, 1
  store i8 %1663, i8* %52, align 1, !tbaa !2447
  %1664 = xor i32 %1652, %1653
  %1665 = lshr i32 %1664, 4
  %1666 = trunc i32 %1665 to i8
  %1667 = and i8 %1666, 1
  store i8 %1667, i8* %53, align 1, !tbaa !2451
  %1668 = zext i1 %1656 to i8
  store i8 %1668, i8* %54, align 1, !tbaa !2448
  %1669 = lshr i32 %1653, 31
  %1670 = trunc i32 %1669 to i8
  store i8 %1670, i8* %55, align 1, !tbaa !2449
  %1671 = lshr i32 %1652, 31
  %1672 = xor i32 %1669, %1671
  %1673 = add nuw nsw i32 %1672, %1669
  %1674 = icmp eq i32 %1673, 2
  %1675 = zext i1 %1674 to i8
  store i8 %1675, i8* %56, align 1, !tbaa !2450
  %1676 = sext i32 %1653 to i64
  store i64 %1676, i64* %RSI, align 8, !tbaa !2428
  %1677 = shl nsw i64 %1676, 3
  %1678 = add i64 %1677, %1648
  %1679 = add i64 %1641, 23
  store i64 %1679, i64* %PC, align 8
  %1680 = inttoptr i64 %1678 to i64*
  store i64 %1644, i64* %1680, align 8
  %1681 = load i64, i64* %RBP, align 8
  %1682 = add i64 %1681, -52
  %1683 = load i64, i64* %PC, align 8
  %1684 = add i64 %1683, 3
  store i64 %1684, i64* %PC, align 8
  %1685 = inttoptr i64 %1682 to i32*
  %1686 = load i32, i32* %1685, align 4
  %1687 = zext i32 %1686 to i64
  store i64 %1687, i64* %RCX, align 8, !tbaa !2428
  %1688 = add i64 %1681, -32
  %1689 = add i64 %1683, 6
  store i64 %1689, i64* %PC, align 8
  %1690 = inttoptr i64 %1688 to i32*
  %1691 = load i32, i32* %1690, align 4
  %1692 = add i32 %1691, %1686
  %1693 = zext i32 %1692 to i64
  store i64 %1693, i64* %RCX, align 8, !tbaa !2428
  %1694 = icmp ult i32 %1692, %1686
  %1695 = icmp ult i32 %1692, %1691
  %1696 = or i1 %1694, %1695
  %1697 = zext i1 %1696 to i8
  store i8 %1697, i8* %51, align 1, !tbaa !2433
  %1698 = and i32 %1692, 255
  %1699 = tail call i32 @llvm.ctpop.i32(i32 %1698) #10
  %1700 = trunc i32 %1699 to i8
  %1701 = and i8 %1700, 1
  %1702 = xor i8 %1701, 1
  store i8 %1702, i8* %52, align 1, !tbaa !2447
  %1703 = xor i32 %1691, %1686
  %1704 = xor i32 %1703, %1692
  %1705 = lshr i32 %1704, 4
  %1706 = trunc i32 %1705 to i8
  %1707 = and i8 %1706, 1
  store i8 %1707, i8* %53, align 1, !tbaa !2451
  %1708 = icmp eq i32 %1692, 0
  %1709 = zext i1 %1708 to i8
  store i8 %1709, i8* %54, align 1, !tbaa !2448
  %1710 = lshr i32 %1692, 31
  %1711 = trunc i32 %1710 to i8
  store i8 %1711, i8* %55, align 1, !tbaa !2449
  %1712 = lshr i32 %1686, 31
  %1713 = lshr i32 %1691, 31
  %1714 = xor i32 %1710, %1712
  %1715 = xor i32 %1710, %1713
  %1716 = add nuw nsw i32 %1714, %1715
  %1717 = icmp eq i32 %1716, 2
  %1718 = zext i1 %1717 to i8
  store i8 %1718, i8* %56, align 1, !tbaa !2450
  %1719 = add i64 %1683, 9
  store i64 %1719, i64* %PC, align 8
  store i32 %1692, i32* %1690, align 4
  %1720 = load i64, i64* %RBP, align 8
  %1721 = add i64 %1720, -52
  %1722 = load i64, i64* %PC, align 8
  %1723 = add i64 %1722, 3
  store i64 %1723, i64* %PC, align 8
  %1724 = inttoptr i64 %1721 to i32*
  %1725 = load i32, i32* %1724, align 4
  %1726 = shl i32 %1725, 1
  %1727 = icmp slt i32 %1725, 0
  %1728 = icmp slt i32 %1726, 0
  %1729 = xor i1 %1727, %1728
  %1730 = zext i32 %1726 to i64
  store i64 %1730, i64* %RCX, align 8, !tbaa !2428
  %.lobit19 = lshr i32 %1725, 31
  %1731 = trunc i32 %.lobit19 to i8
  store i8 %1731, i8* %51, align 1, !tbaa !2432
  %1732 = and i32 %1726, 254
  %1733 = tail call i32 @llvm.ctpop.i32(i32 %1732) #10
  %1734 = trunc i32 %1733 to i8
  %1735 = and i8 %1734, 1
  %1736 = xor i8 %1735, 1
  store i8 %1736, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %1737 = icmp eq i32 %1726, 0
  %1738 = zext i1 %1737 to i8
  store i8 %1738, i8* %54, align 1, !tbaa !2432
  %1739 = lshr i32 %1725, 30
  %1740 = and i32 %1739, 1
  %1741 = trunc i32 %1740 to i8
  store i8 %1741, i8* %55, align 1, !tbaa !2432
  %1742 = zext i1 %1729 to i8
  store i8 %1742, i8* %56, align 1, !tbaa !2432
  %1743 = add i64 %1720, -40
  %1744 = add i64 %1722, 9
  store i64 %1744, i64* %PC, align 8
  %1745 = inttoptr i64 %1743 to i32*
  %1746 = load i32, i32* %1745, align 4
  %1747 = add i32 %1746, %1726
  %1748 = zext i32 %1747 to i64
  store i64 %1748, i64* %RCX, align 8, !tbaa !2428
  %1749 = icmp ult i32 %1747, %1726
  %1750 = icmp ult i32 %1747, %1746
  %1751 = or i1 %1749, %1750
  %1752 = zext i1 %1751 to i8
  store i8 %1752, i8* %51, align 1, !tbaa !2433
  %1753 = and i32 %1747, 255
  %1754 = tail call i32 @llvm.ctpop.i32(i32 %1753) #10
  %1755 = trunc i32 %1754 to i8
  %1756 = and i8 %1755, 1
  %1757 = xor i8 %1756, 1
  store i8 %1757, i8* %52, align 1, !tbaa !2447
  %1758 = xor i32 %1746, %1726
  %1759 = xor i32 %1758, %1747
  %1760 = lshr i32 %1759, 4
  %1761 = trunc i32 %1760 to i8
  %1762 = and i8 %1761, 1
  store i8 %1762, i8* %53, align 1, !tbaa !2451
  %1763 = icmp eq i32 %1747, 0
  %1764 = zext i1 %1763 to i8
  store i8 %1764, i8* %54, align 1, !tbaa !2448
  %1765 = lshr i32 %1747, 31
  %1766 = trunc i32 %1765 to i8
  store i8 %1766, i8* %55, align 1, !tbaa !2449
  %1767 = lshr i32 %1746, 31
  %1768 = xor i32 %1765, %1740
  %1769 = xor i32 %1765, %1767
  %1770 = add nuw nsw i32 %1768, %1769
  %1771 = icmp eq i32 %1770, 2
  %1772 = zext i1 %1771 to i8
  store i8 %1772, i8* %56, align 1, !tbaa !2450
  %1773 = add i64 %1722, 12
  store i64 %1773, i64* %PC, align 8
  store i32 %1747, i32* %1745, align 4
  %1774 = load i64, i64* %RBP, align 8
  %1775 = add i64 %1774, -24
  %1776 = load i64, i64* %PC, align 8
  %1777 = add i64 %1776, 4
  store i64 %1777, i64* %PC, align 8
  %1778 = inttoptr i64 %1775 to i64*
  %1779 = load i64, i64* %1778, align 8
  store i64 %1779, i64* %RDX, align 8, !tbaa !2428
  %1780 = add i64 %1774, -32
  %1781 = add i64 %1776, 8
  store i64 %1781, i64* %PC, align 8
  %1782 = inttoptr i64 %1780 to i32*
  %1783 = load i32, i32* %1782, align 4
  %1784 = sext i32 %1783 to i64
  store i64 %1784, i64* %RSI, align 8, !tbaa !2428
  %1785 = shl nsw i64 %1784, 3
  %1786 = add i64 %1785, %1779
  %1787 = add i64 %1776, 13
  store i64 %1787, i64* %PC, align 8
  %1788 = inttoptr i64 %1786 to i64*
  %1789 = load i64, i64* %1788, align 8
  store i64 %1789, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1790 = add i64 %1774, -64
  %1791 = add i64 %1776, 18
  store i64 %1791, i64* %PC, align 8
  %1792 = inttoptr i64 %1790 to i64*
  store i64 %1789, i64* %1792, align 8
  %1793 = load i64, i64* %RBP, align 8
  %1794 = add i64 %1793, -24
  %1795 = load i64, i64* %PC, align 8
  %1796 = add i64 %1795, 4
  store i64 %1796, i64* %PC, align 8
  %1797 = inttoptr i64 %1794 to i64*
  %1798 = load i64, i64* %1797, align 8
  store i64 %1798, i64* %RDX, align 8, !tbaa !2428
  %1799 = add i64 %1793, -32
  %1800 = add i64 %1795, 7
  store i64 %1800, i64* %PC, align 8
  %1801 = inttoptr i64 %1799 to i32*
  %1802 = load i32, i32* %1801, align 4
  %1803 = add i32 %1802, 1
  %1804 = zext i32 %1803 to i64
  store i64 %1804, i64* %RCX, align 8, !tbaa !2428
  %1805 = icmp eq i32 %1802, -1
  %1806 = icmp eq i32 %1803, 0
  %1807 = or i1 %1805, %1806
  %1808 = zext i1 %1807 to i8
  store i8 %1808, i8* %51, align 1, !tbaa !2433
  %1809 = and i32 %1803, 255
  %1810 = tail call i32 @llvm.ctpop.i32(i32 %1809) #10
  %1811 = trunc i32 %1810 to i8
  %1812 = and i8 %1811, 1
  %1813 = xor i8 %1812, 1
  store i8 %1813, i8* %52, align 1, !tbaa !2447
  %1814 = xor i32 %1802, %1803
  %1815 = lshr i32 %1814, 4
  %1816 = trunc i32 %1815 to i8
  %1817 = and i8 %1816, 1
  store i8 %1817, i8* %53, align 1, !tbaa !2451
  %1818 = zext i1 %1806 to i8
  store i8 %1818, i8* %54, align 1, !tbaa !2448
  %1819 = lshr i32 %1803, 31
  %1820 = trunc i32 %1819 to i8
  store i8 %1820, i8* %55, align 1, !tbaa !2449
  %1821 = lshr i32 %1802, 31
  %1822 = xor i32 %1819, %1821
  %1823 = add nuw nsw i32 %1822, %1819
  %1824 = icmp eq i32 %1823, 2
  %1825 = zext i1 %1824 to i8
  store i8 %1825, i8* %56, align 1, !tbaa !2450
  %1826 = sext i32 %1803 to i64
  store i64 %1826, i64* %RSI, align 8, !tbaa !2428
  %1827 = shl nsw i64 %1826, 3
  %1828 = add i64 %1827, %1798
  %1829 = add i64 %1795, 18
  store i64 %1829, i64* %PC, align 8
  %1830 = inttoptr i64 %1828 to i64*
  %1831 = load i64, i64* %1830, align 8
  %1832 = load i64, i64* %RAX, align 8
  %1833 = xor i64 %1832, %1831
  store i64 %1833, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %1834 = trunc i64 %1833 to i32
  %1835 = and i32 %1834, 255
  %1836 = tail call i32 @llvm.ctpop.i32(i32 %1835) #10
  %1837 = trunc i32 %1836 to i8
  %1838 = and i8 %1837, 1
  %1839 = xor i8 %1838, 1
  store i8 %1839, i8* %52, align 1, !tbaa !2447
  %1840 = icmp eq i64 %1833, 0
  %1841 = zext i1 %1840 to i8
  store i8 %1841, i8* %54, align 1, !tbaa !2448
  %1842 = lshr i64 %1833, 63
  %1843 = trunc i64 %1842 to i8
  store i8 %1843, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %1833, i64* %3852, align 1, !tbaa !2428
  store i64 0, i64* %3850, align 1, !tbaa !2428
  %1844 = add i64 %1793, -72
  %1845 = add i64 %1795, 36
  store i64 %1845, i64* %PC, align 8
  %1846 = inttoptr i64 %1844 to i64*
  store i64 %1833, i64* %1846, align 8
  %1847 = load i64, i64* %RBP, align 8
  %1848 = add i64 %1847, -24
  %1849 = load i64, i64* %PC, align 8
  %1850 = add i64 %1849, 4
  store i64 %1850, i64* %PC, align 8
  %1851 = inttoptr i64 %1848 to i64*
  %1852 = load i64, i64* %1851, align 8
  store i64 %1852, i64* %RDX, align 8, !tbaa !2428
  %1853 = add i64 %1847, -40
  %1854 = add i64 %1849, 8
  store i64 %1854, i64* %PC, align 8
  %1855 = inttoptr i64 %1853 to i32*
  %1856 = load i32, i32* %1855, align 4
  %1857 = sext i32 %1856 to i64
  store i64 %1857, i64* %RSI, align 8, !tbaa !2428
  %1858 = shl nsw i64 %1857, 3
  %1859 = add i64 %1858, %1852
  %1860 = add i64 %1849, 13
  store i64 %1860, i64* %PC, align 8
  %1861 = inttoptr i64 %1859 to i64*
  %1862 = load i64, i64* %1861, align 8
  store i64 %1862, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1863 = add i64 %1847, -80
  %1864 = add i64 %1849, 18
  store i64 %1864, i64* %PC, align 8
  %1865 = inttoptr i64 %1863 to i64*
  store i64 %1862, i64* %1865, align 8
  %1866 = load i64, i64* %RBP, align 8
  %1867 = add i64 %1866, -24
  %1868 = load i64, i64* %PC, align 8
  %1869 = add i64 %1868, 4
  store i64 %1869, i64* %PC, align 8
  %1870 = inttoptr i64 %1867 to i64*
  %1871 = load i64, i64* %1870, align 8
  store i64 %1871, i64* %RDX, align 8, !tbaa !2428
  %1872 = add i64 %1866, -40
  %1873 = add i64 %1868, 7
  store i64 %1873, i64* %PC, align 8
  %1874 = inttoptr i64 %1872 to i32*
  %1875 = load i32, i32* %1874, align 4
  %1876 = add i32 %1875, 1
  %1877 = zext i32 %1876 to i64
  store i64 %1877, i64* %RCX, align 8, !tbaa !2428
  %1878 = icmp eq i32 %1875, -1
  %1879 = icmp eq i32 %1876, 0
  %1880 = or i1 %1878, %1879
  %1881 = zext i1 %1880 to i8
  store i8 %1881, i8* %51, align 1, !tbaa !2433
  %1882 = and i32 %1876, 255
  %1883 = tail call i32 @llvm.ctpop.i32(i32 %1882) #10
  %1884 = trunc i32 %1883 to i8
  %1885 = and i8 %1884, 1
  %1886 = xor i8 %1885, 1
  store i8 %1886, i8* %52, align 1, !tbaa !2447
  %1887 = xor i32 %1875, %1876
  %1888 = lshr i32 %1887, 4
  %1889 = trunc i32 %1888 to i8
  %1890 = and i8 %1889, 1
  store i8 %1890, i8* %53, align 1, !tbaa !2451
  %1891 = zext i1 %1879 to i8
  store i8 %1891, i8* %54, align 1, !tbaa !2448
  %1892 = lshr i32 %1876, 31
  %1893 = trunc i32 %1892 to i8
  store i8 %1893, i8* %55, align 1, !tbaa !2449
  %1894 = lshr i32 %1875, 31
  %1895 = xor i32 %1892, %1894
  %1896 = add nuw nsw i32 %1895, %1892
  %1897 = icmp eq i32 %1896, 2
  %1898 = zext i1 %1897 to i8
  store i8 %1898, i8* %56, align 1, !tbaa !2450
  %1899 = sext i32 %1876 to i64
  store i64 %1899, i64* %RSI, align 8, !tbaa !2428
  %1900 = shl nsw i64 %1899, 3
  %1901 = add i64 %1900, %1871
  %1902 = add i64 %1868, 18
  store i64 %1902, i64* %PC, align 8
  %1903 = inttoptr i64 %1901 to i64*
  %1904 = load i64, i64* %1903, align 8
  %1905 = load i64, i64* %RAX, align 8
  %1906 = xor i64 %1905, %1904
  store i64 %1906, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %1907 = trunc i64 %1906 to i32
  %1908 = and i32 %1907, 255
  %1909 = tail call i32 @llvm.ctpop.i32(i32 %1908) #10
  %1910 = trunc i32 %1909 to i8
  %1911 = and i8 %1910, 1
  %1912 = xor i8 %1911, 1
  store i8 %1912, i8* %52, align 1, !tbaa !2447
  %1913 = icmp eq i64 %1906, 0
  %1914 = zext i1 %1913 to i8
  store i8 %1914, i8* %54, align 1, !tbaa !2448
  %1915 = lshr i64 %1906, 63
  %1916 = trunc i64 %1915 to i8
  store i8 %1916, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %1906, i64* %3852, align 1, !tbaa !2428
  store i64 0, i64* %3850, align 1, !tbaa !2428
  %1917 = add i64 %1866, -88
  %1918 = add i64 %1868, 36
  store i64 %1918, i64* %PC, align 8
  %1919 = inttoptr i64 %1917 to i64*
  store i64 %1906, i64* %1919, align 8
  %1920 = load i64, i64* %RBP, align 8
  %1921 = add i64 %1920, -80
  %1922 = load i64, i64* %PC, align 8
  %1923 = add i64 %1922, 5
  store i64 %1923, i64* %PC, align 8
  %1924 = inttoptr i64 %1921 to i64*
  %1925 = load i64, i64* %1924, align 8
  store i64 %1925, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1926 = add i64 %1920, -24
  %1927 = add i64 %1922, 9
  store i64 %1927, i64* %PC, align 8
  %1928 = inttoptr i64 %1926 to i64*
  %1929 = load i64, i64* %1928, align 8
  store i64 %1929, i64* %RAX, align 8, !tbaa !2428
  %1930 = add i64 %1920, -32
  %1931 = add i64 %1922, 13
  store i64 %1931, i64* %PC, align 8
  %1932 = inttoptr i64 %1930 to i32*
  %1933 = load i32, i32* %1932, align 4
  %1934 = sext i32 %1933 to i64
  store i64 %1934, i64* %RDX, align 8, !tbaa !2428
  %1935 = shl nsw i64 %1934, 3
  %1936 = add i64 %1935, %1929
  %1937 = add i64 %1922, 18
  store i64 %1937, i64* %PC, align 8
  %1938 = inttoptr i64 %1936 to i64*
  store i64 %1925, i64* %1938, align 8
  %1939 = load i64, i64* %RBP, align 8
  %1940 = add i64 %1939, -88
  %1941 = load i64, i64* %PC, align 8
  %1942 = add i64 %1941, 5
  store i64 %1942, i64* %PC, align 8
  %1943 = inttoptr i64 %1940 to i64*
  %1944 = load i64, i64* %1943, align 8
  store i64 %1944, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1945 = add i64 %1939, -24
  %1946 = add i64 %1941, 9
  store i64 %1946, i64* %PC, align 8
  %1947 = inttoptr i64 %1945 to i64*
  %1948 = load i64, i64* %1947, align 8
  store i64 %1948, i64* %RAX, align 8, !tbaa !2428
  %1949 = add i64 %1939, -32
  %1950 = add i64 %1941, 12
  store i64 %1950, i64* %PC, align 8
  %1951 = inttoptr i64 %1949 to i32*
  %1952 = load i32, i32* %1951, align 4
  %1953 = add i32 %1952, 1
  %1954 = zext i32 %1953 to i64
  store i64 %1954, i64* %RCX, align 8, !tbaa !2428
  %1955 = icmp eq i32 %1952, -1
  %1956 = icmp eq i32 %1953, 0
  %1957 = or i1 %1955, %1956
  %1958 = zext i1 %1957 to i8
  store i8 %1958, i8* %51, align 1, !tbaa !2433
  %1959 = and i32 %1953, 255
  %1960 = tail call i32 @llvm.ctpop.i32(i32 %1959) #10
  %1961 = trunc i32 %1960 to i8
  %1962 = and i8 %1961, 1
  %1963 = xor i8 %1962, 1
  store i8 %1963, i8* %52, align 1, !tbaa !2447
  %1964 = xor i32 %1952, %1953
  %1965 = lshr i32 %1964, 4
  %1966 = trunc i32 %1965 to i8
  %1967 = and i8 %1966, 1
  store i8 %1967, i8* %53, align 1, !tbaa !2451
  %1968 = zext i1 %1956 to i8
  store i8 %1968, i8* %54, align 1, !tbaa !2448
  %1969 = lshr i32 %1953, 31
  %1970 = trunc i32 %1969 to i8
  store i8 %1970, i8* %55, align 1, !tbaa !2449
  %1971 = lshr i32 %1952, 31
  %1972 = xor i32 %1969, %1971
  %1973 = add nuw nsw i32 %1972, %1969
  %1974 = icmp eq i32 %1973, 2
  %1975 = zext i1 %1974 to i8
  store i8 %1975, i8* %56, align 1, !tbaa !2450
  %1976 = sext i32 %1953 to i64
  store i64 %1976, i64* %RDX, align 8, !tbaa !2428
  %1977 = shl nsw i64 %1976, 3
  %1978 = add i64 %1977, %1948
  %1979 = add i64 %1941, 23
  store i64 %1979, i64* %PC, align 8
  %1980 = inttoptr i64 %1978 to i64*
  store i64 %1944, i64* %1980, align 8
  %1981 = load i64, i64* %RBP, align 8
  %1982 = add i64 %1981, -64
  %1983 = load i64, i64* %PC, align 8
  %1984 = add i64 %1983, 5
  store i64 %1984, i64* %PC, align 8
  %1985 = inttoptr i64 %1982 to i64*
  %1986 = load i64, i64* %1985, align 8
  store i64 %1986, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %1987 = add i64 %1981, -24
  %1988 = add i64 %1983, 9
  store i64 %1988, i64* %PC, align 8
  %1989 = inttoptr i64 %1987 to i64*
  %1990 = load i64, i64* %1989, align 8
  store i64 %1990, i64* %RAX, align 8, !tbaa !2428
  %1991 = add i64 %1981, -40
  %1992 = add i64 %1983, 13
  store i64 %1992, i64* %PC, align 8
  %1993 = inttoptr i64 %1991 to i32*
  %1994 = load i32, i32* %1993, align 4
  %1995 = sext i32 %1994 to i64
  store i64 %1995, i64* %RDX, align 8, !tbaa !2428
  %1996 = shl nsw i64 %1995, 3
  %1997 = add i64 %1996, %1990
  %1998 = add i64 %1983, 18
  store i64 %1998, i64* %PC, align 8
  %1999 = inttoptr i64 %1997 to i64*
  store i64 %1986, i64* %1999, align 8
  %2000 = load i64, i64* %RBP, align 8
  %2001 = add i64 %2000, -72
  %2002 = load i64, i64* %PC, align 8
  %2003 = add i64 %2002, 5
  store i64 %2003, i64* %PC, align 8
  %2004 = inttoptr i64 %2001 to i64*
  %2005 = load i64, i64* %2004, align 8
  store i64 %2005, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %2006 = add i64 %2000, -24
  %2007 = add i64 %2002, 9
  store i64 %2007, i64* %PC, align 8
  %2008 = inttoptr i64 %2006 to i64*
  %2009 = load i64, i64* %2008, align 8
  store i64 %2009, i64* %RAX, align 8, !tbaa !2428
  %2010 = add i64 %2000, -40
  %2011 = add i64 %2002, 12
  store i64 %2011, i64* %PC, align 8
  %2012 = inttoptr i64 %2010 to i32*
  %2013 = load i32, i32* %2012, align 4
  %2014 = add i32 %2013, 1
  %2015 = zext i32 %2014 to i64
  store i64 %2015, i64* %RCX, align 8, !tbaa !2428
  %2016 = icmp eq i32 %2013, -1
  %2017 = icmp eq i32 %2014, 0
  %2018 = or i1 %2016, %2017
  %2019 = zext i1 %2018 to i8
  store i8 %2019, i8* %51, align 1, !tbaa !2433
  %2020 = and i32 %2014, 255
  %2021 = tail call i32 @llvm.ctpop.i32(i32 %2020) #10
  %2022 = trunc i32 %2021 to i8
  %2023 = and i8 %2022, 1
  %2024 = xor i8 %2023, 1
  store i8 %2024, i8* %52, align 1, !tbaa !2447
  %2025 = xor i32 %2013, %2014
  %2026 = lshr i32 %2025, 4
  %2027 = trunc i32 %2026 to i8
  %2028 = and i8 %2027, 1
  store i8 %2028, i8* %53, align 1, !tbaa !2451
  %2029 = zext i1 %2017 to i8
  store i8 %2029, i8* %54, align 1, !tbaa !2448
  %2030 = lshr i32 %2014, 31
  %2031 = trunc i32 %2030 to i8
  store i8 %2031, i8* %55, align 1, !tbaa !2449
  %2032 = lshr i32 %2013, 31
  %2033 = xor i32 %2030, %2032
  %2034 = add nuw nsw i32 %2033, %2030
  %2035 = icmp eq i32 %2034, 2
  %2036 = zext i1 %2035 to i8
  store i8 %2036, i8* %56, align 1, !tbaa !2450
  %2037 = sext i32 %2014 to i64
  store i64 %2037, i64* %RDX, align 8, !tbaa !2428
  %2038 = shl nsw i64 %2037, 3
  %2039 = add i64 %2038, %2009
  %2040 = add i64 %2002, 23
  store i64 %2040, i64* %PC, align 8
  %2041 = inttoptr i64 %2039 to i64*
  store i64 %2005, i64* %2041, align 8
  %2042 = load i64, i64* %RBP, align 8
  %2043 = add i64 %2042, -28
  %2044 = load i64, i64* %PC, align 8
  %2045 = add i64 %2044, 3
  store i64 %2045, i64* %PC, align 8
  %2046 = inttoptr i64 %2043 to i32*
  %2047 = load i32, i32* %2046, align 4
  %2048 = add i32 %2047, 1
  %2049 = zext i32 %2048 to i64
  store i64 %2049, i64* %RAX, align 8, !tbaa !2428
  %2050 = icmp eq i32 %2047, -1
  %2051 = icmp eq i32 %2048, 0
  %2052 = or i1 %2050, %2051
  %2053 = zext i1 %2052 to i8
  store i8 %2053, i8* %51, align 1, !tbaa !2433
  %2054 = and i32 %2048, 255
  %2055 = tail call i32 @llvm.ctpop.i32(i32 %2054) #10
  %2056 = trunc i32 %2055 to i8
  %2057 = and i8 %2056, 1
  %2058 = xor i8 %2057, 1
  store i8 %2058, i8* %52, align 1, !tbaa !2447
  %2059 = xor i32 %2047, %2048
  %2060 = lshr i32 %2059, 4
  %2061 = trunc i32 %2060 to i8
  %2062 = and i8 %2061, 1
  store i8 %2062, i8* %53, align 1, !tbaa !2451
  %2063 = zext i1 %2051 to i8
  store i8 %2063, i8* %54, align 1, !tbaa !2448
  %2064 = lshr i32 %2048, 31
  %2065 = trunc i32 %2064 to i8
  store i8 %2065, i8* %55, align 1, !tbaa !2449
  %2066 = lshr i32 %2047, 31
  %2067 = xor i32 %2064, %2066
  %2068 = add nuw nsw i32 %2067, %2064
  %2069 = icmp eq i32 %2068, 2
  %2070 = zext i1 %2069 to i8
  store i8 %2070, i8* %56, align 1, !tbaa !2450
  %2071 = add i64 %2044, 9
  store i64 %2071, i64* %PC, align 8
  store i32 %2048, i32* %2046, align 4
  %2072 = load i64, i64* %PC, align 8
  %2073 = add i64 %2072, -893
  store i64 %2073, i64* %PC, align 8, !tbaa !2428
  br label %block_401c9d

block_401c25:                                     ; preds = %block_401c15, %block_401c31
  %2074 = phi i64 [ %.pre4, %block_401c15 ], [ %307, %block_401c31 ]
  %2075 = load i64, i64* %RBP, align 8
  %2076 = add i64 %2075, -28
  %2077 = add i64 %2074, 3
  store i64 %2077, i64* %PC, align 8
  %2078 = inttoptr i64 %2076 to i32*
  %2079 = load i32, i32* %2078, align 4
  %2080 = zext i32 %2079 to i64
  store i64 %2080, i64* %RAX, align 8, !tbaa !2428
  %2081 = add i64 %2075, -48
  %2082 = add i64 %2074, 6
  store i64 %2082, i64* %PC, align 8
  %2083 = inttoptr i64 %2081 to i32*
  %2084 = load i32, i32* %2083, align 4
  %2085 = sub i32 %2079, %2084
  %2086 = icmp ult i32 %2079, %2084
  %2087 = zext i1 %2086 to i8
  store i8 %2087, i8* %51, align 1, !tbaa !2433
  %2088 = and i32 %2085, 255
  %2089 = tail call i32 @llvm.ctpop.i32(i32 %2088) #10
  %2090 = trunc i32 %2089 to i8
  %2091 = and i8 %2090, 1
  %2092 = xor i8 %2091, 1
  store i8 %2092, i8* %52, align 1, !tbaa !2447
  %2093 = xor i32 %2084, %2079
  %2094 = xor i32 %2093, %2085
  %2095 = lshr i32 %2094, 4
  %2096 = trunc i32 %2095 to i8
  %2097 = and i8 %2096, 1
  store i8 %2097, i8* %53, align 1, !tbaa !2451
  %2098 = icmp eq i32 %2085, 0
  %2099 = zext i1 %2098 to i8
  store i8 %2099, i8* %54, align 1, !tbaa !2448
  %2100 = lshr i32 %2085, 31
  %2101 = trunc i32 %2100 to i8
  store i8 %2101, i8* %55, align 1, !tbaa !2449
  %2102 = lshr i32 %2079, 31
  %2103 = lshr i32 %2084, 31
  %2104 = xor i32 %2103, %2102
  %2105 = xor i32 %2100, %2102
  %2106 = add nuw nsw i32 %2105, %2104
  %2107 = icmp eq i32 %2106, 2
  %2108 = zext i1 %2107 to i8
  store i8 %2108, i8* %56, align 1, !tbaa !2450
  %2109 = icmp ne i8 %2101, 0
  %2110 = xor i1 %2109, %2107
  %.v10 = select i1 %2110, i64 12, i64 56
  %2111 = add i64 %2074, %.v10
  store i64 %2111, i64* %PC, align 8, !tbaa !2428
  br i1 %2110, label %block_401c31, label %block_401c5d

block_40201f:                                     ; preds = %block_401c9d
  %2112 = load i32, i32* %2767, align 4
  %2113 = shl i32 %2112, 1
  %2114 = icmp slt i32 %2112, 0
  %2115 = icmp slt i32 %2113, 0
  %2116 = xor i1 %2114, %2115
  %2117 = zext i32 %2113 to i64
  store i64 %2117, i64* %RCX, align 8, !tbaa !2428
  %.lobit20 = lshr i32 %2112, 31
  %2118 = trunc i32 %.lobit20 to i8
  store i8 %2118, i8* %51, align 1, !tbaa !2432
  %2119 = and i32 %2113, 254
  %2120 = tail call i32 @llvm.ctpop.i32(i32 %2119) #10
  %2121 = trunc i32 %2120 to i8
  %2122 = and i8 %2121, 1
  %2123 = xor i8 %2122, 1
  store i8 %2123, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %2124 = icmp eq i32 %2113, 0
  %2125 = zext i1 %2124 to i8
  store i8 %2125, i8* %54, align 1, !tbaa !2432
  %2126 = lshr i32 %2112, 30
  %2127 = and i32 %2126, 1
  %2128 = trunc i32 %2127 to i8
  store i8 %2128, i8* %55, align 1, !tbaa !2432
  %2129 = zext i1 %2116 to i8
  store i8 %2129, i8* %56, align 1, !tbaa !2432
  %2130 = add i64 %2759, -16
  %2131 = add i64 %2795, 20
  store i64 %2131, i64* %PC, align 8
  %2132 = inttoptr i64 %2130 to i64*
  %2133 = load i64, i64* %2132, align 8
  store i64 %2133, i64* %RDX, align 8, !tbaa !2428
  %2134 = add i64 %2795, 24
  store i64 %2134, i64* %PC, align 8
  %2135 = load i32, i32* %2767, align 4
  %2136 = sext i32 %2135 to i64
  store i64 %2136, i64* %RSI, align 8, !tbaa !2428
  %2137 = shl nsw i64 %2136, 2
  %2138 = add i64 %2137, %2133
  %2139 = add i64 %2795, 27
  store i64 %2139, i64* %PC, align 8
  %2140 = inttoptr i64 %2138 to i32*
  %2141 = load i32, i32* %2140, align 4
  %2142 = add i32 %2141, %2113
  %2143 = zext i32 %2142 to i64
  store i64 %2143, i64* %RCX, align 8, !tbaa !2428
  %2144 = icmp ult i32 %2142, %2113
  %2145 = icmp ult i32 %2142, %2141
  %2146 = or i1 %2144, %2145
  %2147 = zext i1 %2146 to i8
  store i8 %2147, i8* %51, align 1, !tbaa !2433
  %2148 = and i32 %2142, 255
  %2149 = tail call i32 @llvm.ctpop.i32(i32 %2148) #10
  %2150 = trunc i32 %2149 to i8
  %2151 = and i8 %2150, 1
  %2152 = xor i8 %2151, 1
  store i8 %2152, i8* %52, align 1, !tbaa !2447
  %2153 = xor i32 %2141, %2113
  %2154 = xor i32 %2153, %2142
  %2155 = lshr i32 %2154, 4
  %2156 = trunc i32 %2155 to i8
  %2157 = and i8 %2156, 1
  store i8 %2157, i8* %53, align 1, !tbaa !2451
  %2158 = icmp eq i32 %2142, 0
  %2159 = zext i1 %2158 to i8
  store i8 %2159, i8* %54, align 1, !tbaa !2448
  %2160 = lshr i32 %2142, 31
  %2161 = trunc i32 %2160 to i8
  store i8 %2161, i8* %55, align 1, !tbaa !2449
  %2162 = lshr i32 %2141, 31
  %2163 = xor i32 %2160, %2127
  %2164 = xor i32 %2160, %2162
  %2165 = add nuw nsw i32 %2163, %2164
  %2166 = icmp eq i32 %2165, 2
  %2167 = zext i1 %2166 to i8
  store i8 %2167, i8* %56, align 1, !tbaa !2450
  %2168 = add i64 %2759, -40
  %2169 = add i64 %2795, 30
  store i64 %2169, i64* %PC, align 8
  %2170 = inttoptr i64 %2168 to i32*
  store i32 %2142, i32* %2170, align 4
  %2171 = load i64, i64* %RBP, align 8
  %2172 = add i64 %2171, -24
  %2173 = load i64, i64* %PC, align 8
  %2174 = add i64 %2173, 4
  store i64 %2174, i64* %PC, align 8
  %2175 = inttoptr i64 %2172 to i64*
  %2176 = load i64, i64* %2175, align 8
  store i64 %2176, i64* %RDX, align 8, !tbaa !2428
  %2177 = add i64 %2171, -40
  %2178 = add i64 %2173, 7
  store i64 %2178, i64* %PC, align 8
  %2179 = inttoptr i64 %2177 to i32*
  %2180 = load i32, i32* %2179, align 4
  %2181 = add i32 %2180, 1
  %2182 = zext i32 %2181 to i64
  store i64 %2182, i64* %RCX, align 8, !tbaa !2428
  %2183 = icmp eq i32 %2180, -1
  %2184 = icmp eq i32 %2181, 0
  %2185 = or i1 %2183, %2184
  %2186 = zext i1 %2185 to i8
  store i8 %2186, i8* %51, align 1, !tbaa !2433
  %2187 = and i32 %2181, 255
  %2188 = tail call i32 @llvm.ctpop.i32(i32 %2187) #10
  %2189 = trunc i32 %2188 to i8
  %2190 = and i8 %2189, 1
  %2191 = xor i8 %2190, 1
  store i8 %2191, i8* %52, align 1, !tbaa !2447
  %2192 = xor i32 %2180, %2181
  %2193 = lshr i32 %2192, 4
  %2194 = trunc i32 %2193 to i8
  %2195 = and i8 %2194, 1
  store i8 %2195, i8* %53, align 1, !tbaa !2451
  %2196 = zext i1 %2184 to i8
  store i8 %2196, i8* %54, align 1, !tbaa !2448
  %2197 = lshr i32 %2181, 31
  %2198 = trunc i32 %2197 to i8
  store i8 %2198, i8* %55, align 1, !tbaa !2449
  %2199 = lshr i32 %2180, 31
  %2200 = xor i32 %2197, %2199
  %2201 = add nuw nsw i32 %2200, %2197
  %2202 = icmp eq i32 %2201, 2
  %2203 = zext i1 %2202 to i8
  store i8 %2203, i8* %56, align 1, !tbaa !2450
  %2204 = sext i32 %2181 to i64
  store i64 %2204, i64* %RSI, align 8, !tbaa !2428
  %2205 = shl nsw i64 %2204, 3
  %2206 = add i64 %2205, %2176
  %2207 = add i64 %2173, 18
  store i64 %2207, i64* %PC, align 8
  %2208 = inttoptr i64 %2206 to i64*
  %2209 = load i64, i64* %2208, align 8
  %2210 = load i64, i64* %RAX, align 8
  %2211 = xor i64 %2210, %2209
  store i64 %2211, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %2212 = trunc i64 %2211 to i32
  %2213 = and i32 %2212, 255
  %2214 = tail call i32 @llvm.ctpop.i32(i32 %2213) #10
  %2215 = trunc i32 %2214 to i8
  %2216 = and i8 %2215, 1
  %2217 = xor i8 %2216, 1
  store i8 %2217, i8* %52, align 1, !tbaa !2447
  %2218 = icmp eq i64 %2211, 0
  %2219 = zext i1 %2218 to i8
  store i8 %2219, i8* %54, align 1, !tbaa !2448
  %2220 = lshr i64 %2211, 63
  %2221 = trunc i64 %2220 to i8
  store i8 %2221, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %2211, i64* %3852, align 1, !tbaa !2428
  store i64 0, i64* %3850, align 1, !tbaa !2428
  %2222 = add i64 %2173, 35
  store i64 %2222, i64* %PC, align 8
  %2223 = load i64, i64* %2175, align 8
  store i64 %2223, i64* %RDX, align 8, !tbaa !2428
  %2224 = add i64 %2173, 38
  store i64 %2224, i64* %PC, align 8
  %2225 = load i32, i32* %2179, align 4
  %2226 = add i32 %2225, 1
  %2227 = zext i32 %2226 to i64
  store i64 %2227, i64* %RCX, align 8, !tbaa !2428
  %2228 = icmp eq i32 %2225, -1
  %2229 = icmp eq i32 %2226, 0
  %2230 = or i1 %2228, %2229
  %2231 = zext i1 %2230 to i8
  store i8 %2231, i8* %51, align 1, !tbaa !2433
  %2232 = and i32 %2226, 255
  %2233 = tail call i32 @llvm.ctpop.i32(i32 %2232) #10
  %2234 = trunc i32 %2233 to i8
  %2235 = and i8 %2234, 1
  %2236 = xor i8 %2235, 1
  store i8 %2236, i8* %52, align 1, !tbaa !2447
  %2237 = xor i32 %2225, %2226
  %2238 = lshr i32 %2237, 4
  %2239 = trunc i32 %2238 to i8
  %2240 = and i8 %2239, 1
  store i8 %2240, i8* %53, align 1, !tbaa !2451
  %2241 = zext i1 %2229 to i8
  store i8 %2241, i8* %54, align 1, !tbaa !2448
  %2242 = lshr i32 %2226, 31
  %2243 = trunc i32 %2242 to i8
  store i8 %2243, i8* %55, align 1, !tbaa !2449
  %2244 = lshr i32 %2225, 31
  %2245 = xor i32 %2242, %2244
  %2246 = add nuw nsw i32 %2245, %2242
  %2247 = icmp eq i32 %2246, 2
  %2248 = zext i1 %2247 to i8
  store i8 %2248, i8* %56, align 1, !tbaa !2450
  %2249 = sext i32 %2226 to i64
  store i64 %2249, i64* %RSI, align 8, !tbaa !2428
  %2250 = shl nsw i64 %2249, 3
  %2251 = add i64 %2250, %2223
  %2252 = add i64 %2173, 49
  store i64 %2252, i64* %PC, align 8
  %2253 = inttoptr i64 %2251 to i64*
  store i64 %2211, i64* %2253, align 8
  %2254 = load i64, i64* %RBP, align 8
  %2255 = add i64 %2254, -40
  %2256 = load i64, i64* %PC, align 8
  %2257 = add i64 %2256, 3
  store i64 %2257, i64* %PC, align 8
  %2258 = inttoptr i64 %2255 to i32*
  %2259 = load i32, i32* %2258, align 4
  %2260 = zext i32 %2259 to i64
  store i64 %2260, i64* %RCX, align 8, !tbaa !2428
  %2261 = add i64 %2254, -52
  %2262 = add i64 %2256, 6
  store i64 %2262, i64* %PC, align 8
  %2263 = inttoptr i64 %2261 to i32*
  %2264 = load i32, i32* %2263, align 4
  %2265 = add i32 %2264, %2259
  %2266 = zext i32 %2265 to i64
  store i64 %2266, i64* %RCX, align 8, !tbaa !2428
  %2267 = icmp ult i32 %2265, %2259
  %2268 = icmp ult i32 %2265, %2264
  %2269 = or i1 %2267, %2268
  %2270 = zext i1 %2269 to i8
  store i8 %2270, i8* %51, align 1, !tbaa !2433
  %2271 = and i32 %2265, 255
  %2272 = tail call i32 @llvm.ctpop.i32(i32 %2271) #10
  %2273 = trunc i32 %2272 to i8
  %2274 = and i8 %2273, 1
  %2275 = xor i8 %2274, 1
  store i8 %2275, i8* %52, align 1, !tbaa !2447
  %2276 = xor i32 %2264, %2259
  %2277 = xor i32 %2276, %2265
  %2278 = lshr i32 %2277, 4
  %2279 = trunc i32 %2278 to i8
  %2280 = and i8 %2279, 1
  store i8 %2280, i8* %53, align 1, !tbaa !2451
  %2281 = icmp eq i32 %2265, 0
  %2282 = zext i1 %2281 to i8
  store i8 %2282, i8* %54, align 1, !tbaa !2448
  %2283 = lshr i32 %2265, 31
  %2284 = trunc i32 %2283 to i8
  store i8 %2284, i8* %55, align 1, !tbaa !2449
  %2285 = lshr i32 %2259, 31
  %2286 = lshr i32 %2264, 31
  %2287 = xor i32 %2283, %2285
  %2288 = xor i32 %2283, %2286
  %2289 = add nuw nsw i32 %2287, %2288
  %2290 = icmp eq i32 %2289, 2
  %2291 = zext i1 %2290 to i8
  store i8 %2291, i8* %56, align 1, !tbaa !2450
  %2292 = add i64 %2254, -32
  %2293 = add i64 %2256, 9
  store i64 %2293, i64* %PC, align 8
  %2294 = inttoptr i64 %2292 to i32*
  store i32 %2265, i32* %2294, align 4
  %2295 = load i64, i64* %RBP, align 8
  %2296 = add i64 %2295, -32
  %2297 = load i64, i64* %PC, align 8
  %2298 = add i64 %2297, 3
  store i64 %2298, i64* %PC, align 8
  %2299 = inttoptr i64 %2296 to i32*
  %2300 = load i32, i32* %2299, align 4
  %2301 = zext i32 %2300 to i64
  store i64 %2301, i64* %RCX, align 8, !tbaa !2428
  %2302 = add i64 %2295, -52
  %2303 = add i64 %2297, 6
  store i64 %2303, i64* %PC, align 8
  %2304 = inttoptr i64 %2302 to i32*
  %2305 = load i32, i32* %2304, align 4
  %2306 = add i32 %2305, %2300
  %2307 = zext i32 %2306 to i64
  store i64 %2307, i64* %RCX, align 8, !tbaa !2428
  %2308 = icmp ult i32 %2306, %2300
  %2309 = icmp ult i32 %2306, %2305
  %2310 = or i1 %2308, %2309
  %2311 = zext i1 %2310 to i8
  store i8 %2311, i8* %51, align 1, !tbaa !2433
  %2312 = and i32 %2306, 255
  %2313 = tail call i32 @llvm.ctpop.i32(i32 %2312) #10
  %2314 = trunc i32 %2313 to i8
  %2315 = and i8 %2314, 1
  %2316 = xor i8 %2315, 1
  store i8 %2316, i8* %52, align 1, !tbaa !2447
  %2317 = xor i32 %2305, %2300
  %2318 = xor i32 %2317, %2306
  %2319 = lshr i32 %2318, 4
  %2320 = trunc i32 %2319 to i8
  %2321 = and i8 %2320, 1
  store i8 %2321, i8* %53, align 1, !tbaa !2451
  %2322 = icmp eq i32 %2306, 0
  %2323 = zext i1 %2322 to i8
  store i8 %2323, i8* %54, align 1, !tbaa !2448
  %2324 = lshr i32 %2306, 31
  %2325 = trunc i32 %2324 to i8
  store i8 %2325, i8* %55, align 1, !tbaa !2449
  %2326 = lshr i32 %2300, 31
  %2327 = lshr i32 %2305, 31
  %2328 = xor i32 %2324, %2326
  %2329 = xor i32 %2324, %2327
  %2330 = add nuw nsw i32 %2328, %2329
  %2331 = icmp eq i32 %2330, 2
  %2332 = zext i1 %2331 to i8
  store i8 %2332, i8* %56, align 1, !tbaa !2450
  %2333 = add i64 %2295, -40
  %2334 = add i64 %2297, 9
  store i64 %2334, i64* %PC, align 8
  %2335 = inttoptr i64 %2333 to i32*
  store i32 %2306, i32* %2335, align 4
  %2336 = load i64, i64* %RBP, align 8
  %2337 = add i64 %2336, -24
  %2338 = load i64, i64* %PC, align 8
  %2339 = add i64 %2338, 4
  store i64 %2339, i64* %PC, align 8
  %2340 = inttoptr i64 %2337 to i64*
  %2341 = load i64, i64* %2340, align 8
  store i64 %2341, i64* %RDX, align 8, !tbaa !2428
  %2342 = add i64 %2336, -32
  %2343 = add i64 %2338, 8
  store i64 %2343, i64* %PC, align 8
  %2344 = inttoptr i64 %2342 to i32*
  %2345 = load i32, i32* %2344, align 4
  %2346 = sext i32 %2345 to i64
  store i64 %2346, i64* %RSI, align 8, !tbaa !2428
  %2347 = shl nsw i64 %2346, 3
  %2348 = add i64 %2347, %2341
  %2349 = add i64 %2338, 13
  store i64 %2349, i64* %PC, align 8
  %2350 = inttoptr i64 %2348 to i64*
  %2351 = load i64, i64* %2350, align 8
  store i64 %2351, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %2352 = add i64 %2336, -64
  %2353 = add i64 %2338, 18
  store i64 %2353, i64* %PC, align 8
  %2354 = inttoptr i64 %2352 to i64*
  store i64 %2351, i64* %2354, align 8
  %2355 = load i64, i64* %RBP, align 8
  %2356 = add i64 %2355, -24
  %2357 = load i64, i64* %PC, align 8
  %2358 = add i64 %2357, 4
  store i64 %2358, i64* %PC, align 8
  %2359 = inttoptr i64 %2356 to i64*
  %2360 = load i64, i64* %2359, align 8
  store i64 %2360, i64* %RDX, align 8, !tbaa !2428
  %2361 = add i64 %2355, -32
  %2362 = add i64 %2357, 7
  store i64 %2362, i64* %PC, align 8
  %2363 = inttoptr i64 %2361 to i32*
  %2364 = load i32, i32* %2363, align 4
  %2365 = add i32 %2364, 1
  %2366 = zext i32 %2365 to i64
  store i64 %2366, i64* %RCX, align 8, !tbaa !2428
  %2367 = icmp eq i32 %2364, -1
  %2368 = icmp eq i32 %2365, 0
  %2369 = or i1 %2367, %2368
  %2370 = zext i1 %2369 to i8
  store i8 %2370, i8* %51, align 1, !tbaa !2433
  %2371 = and i32 %2365, 255
  %2372 = tail call i32 @llvm.ctpop.i32(i32 %2371) #10
  %2373 = trunc i32 %2372 to i8
  %2374 = and i8 %2373, 1
  %2375 = xor i8 %2374, 1
  store i8 %2375, i8* %52, align 1, !tbaa !2447
  %2376 = xor i32 %2364, %2365
  %2377 = lshr i32 %2376, 4
  %2378 = trunc i32 %2377 to i8
  %2379 = and i8 %2378, 1
  store i8 %2379, i8* %53, align 1, !tbaa !2451
  %2380 = zext i1 %2368 to i8
  store i8 %2380, i8* %54, align 1, !tbaa !2448
  %2381 = lshr i32 %2365, 31
  %2382 = trunc i32 %2381 to i8
  store i8 %2382, i8* %55, align 1, !tbaa !2449
  %2383 = lshr i32 %2364, 31
  %2384 = xor i32 %2381, %2383
  %2385 = add nuw nsw i32 %2384, %2381
  %2386 = icmp eq i32 %2385, 2
  %2387 = zext i1 %2386 to i8
  store i8 %2387, i8* %56, align 1, !tbaa !2450
  %2388 = sext i32 %2365 to i64
  store i64 %2388, i64* %RSI, align 8, !tbaa !2428
  %2389 = shl nsw i64 %2388, 3
  %2390 = add i64 %2389, %2360
  %2391 = add i64 %2357, 18
  store i64 %2391, i64* %PC, align 8
  %2392 = inttoptr i64 %2390 to i64*
  %2393 = load i64, i64* %2392, align 8
  %2394 = load i64, i64* %RAX, align 8
  %2395 = xor i64 %2394, %2393
  store i64 %2395, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %2396 = trunc i64 %2395 to i32
  %2397 = and i32 %2396, 255
  %2398 = tail call i32 @llvm.ctpop.i32(i32 %2397) #10
  %2399 = trunc i32 %2398 to i8
  %2400 = and i8 %2399, 1
  %2401 = xor i8 %2400, 1
  store i8 %2401, i8* %52, align 1, !tbaa !2447
  %2402 = icmp eq i64 %2395, 0
  %2403 = zext i1 %2402 to i8
  store i8 %2403, i8* %54, align 1, !tbaa !2448
  %2404 = lshr i64 %2395, 63
  %2405 = trunc i64 %2404 to i8
  store i8 %2405, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %2395, i64* %3852, align 1, !tbaa !2428
  store i64 0, i64* %3850, align 1, !tbaa !2428
  %2406 = add i64 %2355, -72
  %2407 = add i64 %2357, 36
  store i64 %2407, i64* %PC, align 8
  %2408 = inttoptr i64 %2406 to i64*
  store i64 %2395, i64* %2408, align 8
  %2409 = load i64, i64* %RBP, align 8
  %2410 = add i64 %2409, -24
  %2411 = load i64, i64* %PC, align 8
  %2412 = add i64 %2411, 4
  store i64 %2412, i64* %PC, align 8
  %2413 = inttoptr i64 %2410 to i64*
  %2414 = load i64, i64* %2413, align 8
  store i64 %2414, i64* %RDX, align 8, !tbaa !2428
  %2415 = add i64 %2409, -40
  %2416 = add i64 %2411, 8
  store i64 %2416, i64* %PC, align 8
  %2417 = inttoptr i64 %2415 to i32*
  %2418 = load i32, i32* %2417, align 4
  %2419 = sext i32 %2418 to i64
  store i64 %2419, i64* %RSI, align 8, !tbaa !2428
  %2420 = shl nsw i64 %2419, 3
  %2421 = add i64 %2420, %2414
  %2422 = add i64 %2411, 13
  store i64 %2422, i64* %PC, align 8
  %2423 = inttoptr i64 %2421 to i64*
  %2424 = load i64, i64* %2423, align 8
  store i64 %2424, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %2425 = add i64 %2409, -80
  %2426 = add i64 %2411, 18
  store i64 %2426, i64* %PC, align 8
  %2427 = inttoptr i64 %2425 to i64*
  store i64 %2424, i64* %2427, align 8
  %2428 = load i64, i64* %RBP, align 8
  %2429 = add i64 %2428, -24
  %2430 = load i64, i64* %PC, align 8
  %2431 = add i64 %2430, 4
  store i64 %2431, i64* %PC, align 8
  %2432 = inttoptr i64 %2429 to i64*
  %2433 = load i64, i64* %2432, align 8
  store i64 %2433, i64* %RDX, align 8, !tbaa !2428
  %2434 = add i64 %2428, -40
  %2435 = add i64 %2430, 7
  store i64 %2435, i64* %PC, align 8
  %2436 = inttoptr i64 %2434 to i32*
  %2437 = load i32, i32* %2436, align 4
  %2438 = add i32 %2437, 1
  %2439 = zext i32 %2438 to i64
  store i64 %2439, i64* %RCX, align 8, !tbaa !2428
  %2440 = icmp eq i32 %2437, -1
  %2441 = icmp eq i32 %2438, 0
  %2442 = or i1 %2440, %2441
  %2443 = zext i1 %2442 to i8
  store i8 %2443, i8* %51, align 1, !tbaa !2433
  %2444 = and i32 %2438, 255
  %2445 = tail call i32 @llvm.ctpop.i32(i32 %2444) #10
  %2446 = trunc i32 %2445 to i8
  %2447 = and i8 %2446, 1
  %2448 = xor i8 %2447, 1
  store i8 %2448, i8* %52, align 1, !tbaa !2447
  %2449 = xor i32 %2437, %2438
  %2450 = lshr i32 %2449, 4
  %2451 = trunc i32 %2450 to i8
  %2452 = and i8 %2451, 1
  store i8 %2452, i8* %53, align 1, !tbaa !2451
  %2453 = zext i1 %2441 to i8
  store i8 %2453, i8* %54, align 1, !tbaa !2448
  %2454 = lshr i32 %2438, 31
  %2455 = trunc i32 %2454 to i8
  store i8 %2455, i8* %55, align 1, !tbaa !2449
  %2456 = lshr i32 %2437, 31
  %2457 = xor i32 %2454, %2456
  %2458 = add nuw nsw i32 %2457, %2454
  %2459 = icmp eq i32 %2458, 2
  %2460 = zext i1 %2459 to i8
  store i8 %2460, i8* %56, align 1, !tbaa !2450
  %2461 = sext i32 %2438 to i64
  store i64 %2461, i64* %RSI, align 8, !tbaa !2428
  %2462 = shl nsw i64 %2461, 3
  %2463 = add i64 %2462, %2433
  %2464 = add i64 %2430, 18
  store i64 %2464, i64* %PC, align 8
  %2465 = inttoptr i64 %2463 to i64*
  %2466 = load i64, i64* %2465, align 8
  %2467 = load i64, i64* %RAX, align 8
  %2468 = xor i64 %2467, %2466
  store i64 %2468, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %2469 = trunc i64 %2468 to i32
  %2470 = and i32 %2469, 255
  %2471 = tail call i32 @llvm.ctpop.i32(i32 %2470) #10
  %2472 = trunc i32 %2471 to i8
  %2473 = and i8 %2472, 1
  %2474 = xor i8 %2473, 1
  store i8 %2474, i8* %52, align 1, !tbaa !2447
  %2475 = icmp eq i64 %2468, 0
  %2476 = zext i1 %2475 to i8
  store i8 %2476, i8* %54, align 1, !tbaa !2448
  %2477 = lshr i64 %2468, 63
  %2478 = trunc i64 %2477 to i8
  store i8 %2478, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %2468, i64* %3852, align 1, !tbaa !2428
  store i64 0, i64* %3850, align 1, !tbaa !2428
  %2479 = add i64 %2428, -88
  %2480 = add i64 %2430, 36
  store i64 %2480, i64* %PC, align 8
  %2481 = inttoptr i64 %2479 to i64*
  store i64 %2468, i64* %2481, align 8
  %2482 = load i64, i64* %RBP, align 8
  %2483 = add i64 %2482, -80
  %2484 = load i64, i64* %PC, align 8
  %2485 = add i64 %2484, 5
  store i64 %2485, i64* %PC, align 8
  %2486 = inttoptr i64 %2483 to i64*
  %2487 = load i64, i64* %2486, align 8
  store i64 %2487, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %2488 = add i64 %2482, -24
  %2489 = add i64 %2484, 9
  store i64 %2489, i64* %PC, align 8
  %2490 = inttoptr i64 %2488 to i64*
  %2491 = load i64, i64* %2490, align 8
  store i64 %2491, i64* %RDX, align 8, !tbaa !2428
  %2492 = add i64 %2482, -32
  %2493 = add i64 %2484, 13
  store i64 %2493, i64* %PC, align 8
  %2494 = inttoptr i64 %2492 to i32*
  %2495 = load i32, i32* %2494, align 4
  %2496 = sext i32 %2495 to i64
  store i64 %2496, i64* %RSI, align 8, !tbaa !2428
  %2497 = shl nsw i64 %2496, 3
  %2498 = add i64 %2497, %2491
  %2499 = add i64 %2484, 18
  store i64 %2499, i64* %PC, align 8
  %2500 = inttoptr i64 %2498 to i64*
  store i64 %2487, i64* %2500, align 8
  %2501 = load i64, i64* %RBP, align 8
  %2502 = add i64 %2501, -88
  %2503 = load i64, i64* %PC, align 8
  %2504 = add i64 %2503, 5
  store i64 %2504, i64* %PC, align 8
  %2505 = inttoptr i64 %2502 to i64*
  %2506 = load i64, i64* %2505, align 8
  store i64 %2506, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %2507 = add i64 %2501, -24
  %2508 = add i64 %2503, 9
  store i64 %2508, i64* %PC, align 8
  %2509 = inttoptr i64 %2507 to i64*
  %2510 = load i64, i64* %2509, align 8
  store i64 %2510, i64* %RDX, align 8, !tbaa !2428
  %2511 = add i64 %2501, -32
  %2512 = add i64 %2503, 12
  store i64 %2512, i64* %PC, align 8
  %2513 = inttoptr i64 %2511 to i32*
  %2514 = load i32, i32* %2513, align 4
  %2515 = add i32 %2514, 1
  %2516 = zext i32 %2515 to i64
  store i64 %2516, i64* %RCX, align 8, !tbaa !2428
  %2517 = icmp eq i32 %2514, -1
  %2518 = icmp eq i32 %2515, 0
  %2519 = or i1 %2517, %2518
  %2520 = zext i1 %2519 to i8
  store i8 %2520, i8* %51, align 1, !tbaa !2433
  %2521 = and i32 %2515, 255
  %2522 = tail call i32 @llvm.ctpop.i32(i32 %2521) #10
  %2523 = trunc i32 %2522 to i8
  %2524 = and i8 %2523, 1
  %2525 = xor i8 %2524, 1
  store i8 %2525, i8* %52, align 1, !tbaa !2447
  %2526 = xor i32 %2514, %2515
  %2527 = lshr i32 %2526, 4
  %2528 = trunc i32 %2527 to i8
  %2529 = and i8 %2528, 1
  store i8 %2529, i8* %53, align 1, !tbaa !2451
  %2530 = zext i1 %2518 to i8
  store i8 %2530, i8* %54, align 1, !tbaa !2448
  %2531 = lshr i32 %2515, 31
  %2532 = trunc i32 %2531 to i8
  store i8 %2532, i8* %55, align 1, !tbaa !2449
  %2533 = lshr i32 %2514, 31
  %2534 = xor i32 %2531, %2533
  %2535 = add nuw nsw i32 %2534, %2531
  %2536 = icmp eq i32 %2535, 2
  %2537 = zext i1 %2536 to i8
  store i8 %2537, i8* %56, align 1, !tbaa !2450
  %2538 = sext i32 %2515 to i64
  store i64 %2538, i64* %RSI, align 8, !tbaa !2428
  %2539 = shl nsw i64 %2538, 3
  %2540 = add i64 %2539, %2510
  %2541 = add i64 %2503, 23
  store i64 %2541, i64* %PC, align 8
  %2542 = inttoptr i64 %2540 to i64*
  store i64 %2506, i64* %2542, align 8
  %2543 = load i64, i64* %RBP, align 8
  %2544 = add i64 %2543, -64
  %2545 = load i64, i64* %PC, align 8
  %2546 = add i64 %2545, 5
  store i64 %2546, i64* %PC, align 8
  %2547 = inttoptr i64 %2544 to i64*
  %2548 = load i64, i64* %2547, align 8
  store i64 %2548, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %2549 = add i64 %2543, -24
  %2550 = add i64 %2545, 9
  store i64 %2550, i64* %PC, align 8
  %2551 = inttoptr i64 %2549 to i64*
  %2552 = load i64, i64* %2551, align 8
  store i64 %2552, i64* %RDX, align 8, !tbaa !2428
  %2553 = add i64 %2543, -40
  %2554 = add i64 %2545, 13
  store i64 %2554, i64* %PC, align 8
  %2555 = inttoptr i64 %2553 to i32*
  %2556 = load i32, i32* %2555, align 4
  %2557 = sext i32 %2556 to i64
  store i64 %2557, i64* %RSI, align 8, !tbaa !2428
  %2558 = shl nsw i64 %2557, 3
  %2559 = add i64 %2558, %2552
  %2560 = add i64 %2545, 18
  store i64 %2560, i64* %PC, align 8
  %2561 = inttoptr i64 %2559 to i64*
  store i64 %2548, i64* %2561, align 8
  %2562 = load i64, i64* %RBP, align 8
  %2563 = add i64 %2562, -72
  %2564 = load i64, i64* %PC, align 8
  %2565 = add i64 %2564, 5
  store i64 %2565, i64* %PC, align 8
  %2566 = inttoptr i64 %2563 to i64*
  %2567 = load i64, i64* %2566, align 8
  store i64 %2567, i64* %3852, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3851, align 1, !tbaa !2452
  %2568 = add i64 %2562, -24
  %2569 = add i64 %2564, 9
  store i64 %2569, i64* %PC, align 8
  %2570 = inttoptr i64 %2568 to i64*
  %2571 = load i64, i64* %2570, align 8
  store i64 %2571, i64* %RDX, align 8, !tbaa !2428
  %2572 = add i64 %2562, -40
  %2573 = add i64 %2564, 12
  store i64 %2573, i64* %PC, align 8
  %2574 = inttoptr i64 %2572 to i32*
  %2575 = load i32, i32* %2574, align 4
  %2576 = add i32 %2575, 1
  %2577 = zext i32 %2576 to i64
  store i64 %2577, i64* %RCX, align 8, !tbaa !2428
  %2578 = icmp eq i32 %2575, -1
  %2579 = icmp eq i32 %2576, 0
  %2580 = or i1 %2578, %2579
  %2581 = zext i1 %2580 to i8
  store i8 %2581, i8* %51, align 1, !tbaa !2433
  %2582 = and i32 %2576, 255
  %2583 = tail call i32 @llvm.ctpop.i32(i32 %2582) #10
  %2584 = trunc i32 %2583 to i8
  %2585 = and i8 %2584, 1
  %2586 = xor i8 %2585, 1
  store i8 %2586, i8* %52, align 1, !tbaa !2447
  %2587 = xor i32 %2575, %2576
  %2588 = lshr i32 %2587, 4
  %2589 = trunc i32 %2588 to i8
  %2590 = and i8 %2589, 1
  store i8 %2590, i8* %53, align 1, !tbaa !2451
  %2591 = zext i1 %2579 to i8
  store i8 %2591, i8* %54, align 1, !tbaa !2448
  %2592 = lshr i32 %2576, 31
  %2593 = trunc i32 %2592 to i8
  store i8 %2593, i8* %55, align 1, !tbaa !2449
  %2594 = lshr i32 %2575, 31
  %2595 = xor i32 %2592, %2594
  %2596 = add nuw nsw i32 %2595, %2592
  %2597 = icmp eq i32 %2596, 2
  %2598 = zext i1 %2597 to i8
  store i8 %2598, i8* %56, align 1, !tbaa !2450
  %2599 = sext i32 %2576 to i64
  store i64 %2599, i64* %RSI, align 8, !tbaa !2428
  %2600 = shl nsw i64 %2599, 3
  %2601 = add i64 %2600, %2571
  %2602 = add i64 %2564, 23
  store i64 %2602, i64* %PC, align 8
  %2603 = inttoptr i64 %2601 to i64*
  store i64 %2567, i64* %2603, align 8
  %2604 = load i64, i64* %RBP, align 8
  %2605 = add i64 %2604, -52
  %2606 = load i64, i64* %PC, align 8
  %2607 = add i64 %2606, 3
  store i64 %2607, i64* %PC, align 8
  %2608 = inttoptr i64 %2605 to i32*
  %2609 = load i32, i32* %2608, align 4
  %2610 = zext i32 %2609 to i64
  store i64 %2610, i64* %RCX, align 8, !tbaa !2428
  %2611 = add i64 %2604, -40
  %2612 = add i64 %2606, 6
  store i64 %2612, i64* %PC, align 8
  %2613 = inttoptr i64 %2611 to i32*
  %2614 = load i32, i32* %2613, align 4
  %2615 = add i32 %2614, %2609
  %2616 = zext i32 %2615 to i64
  store i64 %2616, i64* %RCX, align 8, !tbaa !2428
  %2617 = icmp ult i32 %2615, %2609
  %2618 = icmp ult i32 %2615, %2614
  %2619 = or i1 %2617, %2618
  %2620 = zext i1 %2619 to i8
  store i8 %2620, i8* %51, align 1, !tbaa !2433
  %2621 = and i32 %2615, 255
  %2622 = tail call i32 @llvm.ctpop.i32(i32 %2621) #10
  %2623 = trunc i32 %2622 to i8
  %2624 = and i8 %2623, 1
  %2625 = xor i8 %2624, 1
  store i8 %2625, i8* %52, align 1, !tbaa !2447
  %2626 = xor i32 %2614, %2609
  %2627 = xor i32 %2626, %2615
  %2628 = lshr i32 %2627, 4
  %2629 = trunc i32 %2628 to i8
  %2630 = and i8 %2629, 1
  store i8 %2630, i8* %53, align 1, !tbaa !2451
  %2631 = icmp eq i32 %2615, 0
  %2632 = zext i1 %2631 to i8
  store i8 %2632, i8* %54, align 1, !tbaa !2448
  %2633 = lshr i32 %2615, 31
  %2634 = trunc i32 %2633 to i8
  store i8 %2634, i8* %55, align 1, !tbaa !2449
  %2635 = lshr i32 %2609, 31
  %2636 = lshr i32 %2614, 31
  %2637 = xor i32 %2633, %2635
  %2638 = xor i32 %2633, %2636
  %2639 = add nuw nsw i32 %2637, %2638
  %2640 = icmp eq i32 %2639, 2
  %2641 = zext i1 %2640 to i8
  store i8 %2641, i8* %56, align 1, !tbaa !2450
  %2642 = add i64 %2606, 9
  store i64 %2642, i64* %PC, align 8
  store i32 %2615, i32* %2613, align 4
  %2643 = load i64, i64* %RBP, align 8
  %2644 = add i64 %2643, -24
  %2645 = load i64, i64* %PC, align 8
  %2646 = add i64 %2645, 4
  store i64 %2646, i64* %PC, align 8
  %2647 = inttoptr i64 %2644 to i64*
  %2648 = load i64, i64* %2647, align 8
  store i64 %2648, i64* %RDX, align 8, !tbaa !2428
  %2649 = add i64 %2643, -40
  %2650 = add i64 %2645, 7
  store i64 %2650, i64* %PC, align 8
  %2651 = inttoptr i64 %2649 to i32*
  %2652 = load i32, i32* %2651, align 4
  %2653 = add i32 %2652, 1
  %2654 = zext i32 %2653 to i64
  store i64 %2654, i64* %RCX, align 8, !tbaa !2428
  %2655 = icmp eq i32 %2652, -1
  %2656 = icmp eq i32 %2653, 0
  %2657 = or i1 %2655, %2656
  %2658 = zext i1 %2657 to i8
  store i8 %2658, i8* %51, align 1, !tbaa !2433
  %2659 = and i32 %2653, 255
  %2660 = tail call i32 @llvm.ctpop.i32(i32 %2659) #10
  %2661 = trunc i32 %2660 to i8
  %2662 = and i8 %2661, 1
  %2663 = xor i8 %2662, 1
  store i8 %2663, i8* %52, align 1, !tbaa !2447
  %2664 = xor i32 %2652, %2653
  %2665 = lshr i32 %2664, 4
  %2666 = trunc i32 %2665 to i8
  %2667 = and i8 %2666, 1
  store i8 %2667, i8* %53, align 1, !tbaa !2451
  %2668 = zext i1 %2656 to i8
  store i8 %2668, i8* %54, align 1, !tbaa !2448
  %2669 = lshr i32 %2653, 31
  %2670 = trunc i32 %2669 to i8
  store i8 %2670, i8* %55, align 1, !tbaa !2449
  %2671 = lshr i32 %2652, 31
  %2672 = xor i32 %2669, %2671
  %2673 = add nuw nsw i32 %2672, %2669
  %2674 = icmp eq i32 %2673, 2
  %2675 = zext i1 %2674 to i8
  store i8 %2675, i8* %56, align 1, !tbaa !2450
  %2676 = sext i32 %2653 to i64
  store i64 %2676, i64* %RSI, align 8, !tbaa !2428
  %2677 = shl nsw i64 %2676, 3
  %2678 = add i64 %2677, %2648
  %2679 = add i64 %2645, 18
  store i64 %2679, i64* %PC, align 8
  %2680 = inttoptr i64 %2678 to i64*
  %2681 = load i64, i64* %2680, align 8
  %2682 = load i64, i64* %RAX, align 8
  %2683 = xor i64 %2682, %2681
  store i64 %2683, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %2684 = trunc i64 %2683 to i32
  %2685 = and i32 %2684, 255
  %2686 = tail call i32 @llvm.ctpop.i32(i32 %2685) #10
  %2687 = trunc i32 %2686 to i8
  %2688 = and i8 %2687, 1
  %2689 = xor i8 %2688, 1
  store i8 %2689, i8* %52, align 1, !tbaa !2447
  %2690 = icmp eq i64 %2683, 0
  %2691 = zext i1 %2690 to i8
  store i8 %2691, i8* %54, align 1, !tbaa !2448
  %2692 = lshr i64 %2683, 63
  %2693 = trunc i64 %2692 to i8
  store i8 %2693, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %2683, i64* %3852, align 1, !tbaa !2428
  store i64 0, i64* %3850, align 1, !tbaa !2428
  %2694 = add i64 %2645, 35
  store i64 %2694, i64* %PC, align 8
  %2695 = load i64, i64* %2647, align 8
  store i64 %2695, i64* %RAX, align 8, !tbaa !2428
  %2696 = add i64 %2645, 38
  store i64 %2696, i64* %PC, align 8
  %2697 = load i32, i32* %2651, align 4
  %2698 = add i32 %2697, 1
  %2699 = zext i32 %2698 to i64
  store i64 %2699, i64* %RCX, align 8, !tbaa !2428
  %2700 = icmp eq i32 %2697, -1
  %2701 = icmp eq i32 %2698, 0
  %2702 = or i1 %2700, %2701
  %2703 = zext i1 %2702 to i8
  store i8 %2703, i8* %51, align 1, !tbaa !2433
  %2704 = and i32 %2698, 255
  %2705 = tail call i32 @llvm.ctpop.i32(i32 %2704) #10
  %2706 = trunc i32 %2705 to i8
  %2707 = and i8 %2706, 1
  %2708 = xor i8 %2707, 1
  store i8 %2708, i8* %52, align 1, !tbaa !2447
  %2709 = xor i32 %2697, %2698
  %2710 = lshr i32 %2709, 4
  %2711 = trunc i32 %2710 to i8
  %2712 = and i8 %2711, 1
  store i8 %2712, i8* %53, align 1, !tbaa !2451
  %2713 = zext i1 %2701 to i8
  store i8 %2713, i8* %54, align 1, !tbaa !2448
  %2714 = lshr i32 %2698, 31
  %2715 = trunc i32 %2714 to i8
  store i8 %2715, i8* %55, align 1, !tbaa !2449
  %2716 = lshr i32 %2697, 31
  %2717 = xor i32 %2714, %2716
  %2718 = add nuw nsw i32 %2717, %2714
  %2719 = icmp eq i32 %2718, 2
  %2720 = zext i1 %2719 to i8
  store i8 %2720, i8* %56, align 1, !tbaa !2450
  %2721 = sext i32 %2698 to i64
  store i64 %2721, i64* %RDX, align 8, !tbaa !2428
  %2722 = shl nsw i64 %2721, 3
  %2723 = add i64 %2722, %2695
  %2724 = add i64 %2645, 49
  store i64 %2724, i64* %PC, align 8
  %2725 = inttoptr i64 %2723 to i64*
  store i64 %2683, i64* %2725, align 8
  %2726 = load i64, i64* %RBP, align 8
  %2727 = add i64 %2726, -36
  %2728 = load i64, i64* %PC, align 8
  %2729 = add i64 %2728, 3
  store i64 %2729, i64* %PC, align 8
  %2730 = inttoptr i64 %2727 to i32*
  %2731 = load i32, i32* %2730, align 4
  %2732 = add i32 %2731, 1
  %2733 = zext i32 %2732 to i64
  store i64 %2733, i64* %RAX, align 8, !tbaa !2428
  %2734 = icmp eq i32 %2731, -1
  %2735 = icmp eq i32 %2732, 0
  %2736 = or i1 %2734, %2735
  %2737 = zext i1 %2736 to i8
  store i8 %2737, i8* %51, align 1, !tbaa !2433
  %2738 = and i32 %2732, 255
  %2739 = tail call i32 @llvm.ctpop.i32(i32 %2738) #10
  %2740 = trunc i32 %2739 to i8
  %2741 = and i8 %2740, 1
  %2742 = xor i8 %2741, 1
  store i8 %2742, i8* %52, align 1, !tbaa !2447
  %2743 = xor i32 %2731, %2732
  %2744 = lshr i32 %2743, 4
  %2745 = trunc i32 %2744 to i8
  %2746 = and i8 %2745, 1
  store i8 %2746, i8* %53, align 1, !tbaa !2451
  %2747 = zext i1 %2735 to i8
  store i8 %2747, i8* %54, align 1, !tbaa !2448
  %2748 = lshr i32 %2732, 31
  %2749 = trunc i32 %2748 to i8
  store i8 %2749, i8* %55, align 1, !tbaa !2449
  %2750 = lshr i32 %2731, 31
  %2751 = xor i32 %2748, %2750
  %2752 = add nuw nsw i32 %2751, %2748
  %2753 = icmp eq i32 %2752, 2
  %2754 = zext i1 %2753 to i8
  store i8 %2754, i8* %56, align 1, !tbaa !2450
  %2755 = add i64 %2728, 9
  store i64 %2755, i64* %PC, align 8
  store i32 %2732, i32* %2730, align 4
  %2756 = load i64, i64* %PC, align 8
  %2757 = add i64 %2756, -1271
  store i64 %2757, i64* %PC, align 8, !tbaa !2428
  br label %block_401c8a

block_401c9d:                                     ; preds = %block_401c96, %block_401ca9
  %2758 = phi i64 [ %.pre6, %block_401c96 ], [ %2073, %block_401ca9 ]
  %2759 = load i64, i64* %RBP, align 8
  %2760 = add i64 %2759, -28
  %2761 = add i64 %2758, 3
  store i64 %2761, i64* %PC, align 8
  %2762 = inttoptr i64 %2760 to i32*
  %2763 = load i32, i32* %2762, align 4
  %2764 = zext i32 %2763 to i64
  store i64 %2764, i64* %RAX, align 8, !tbaa !2428
  %2765 = add i64 %2759, -36
  %2766 = add i64 %2758, 6
  store i64 %2766, i64* %PC, align 8
  %2767 = inttoptr i64 %2765 to i32*
  %2768 = load i32, i32* %2767, align 4
  %2769 = sub i32 %2763, %2768
  %2770 = icmp ult i32 %2763, %2768
  %2771 = zext i1 %2770 to i8
  store i8 %2771, i8* %51, align 1, !tbaa !2433
  %2772 = and i32 %2769, 255
  %2773 = tail call i32 @llvm.ctpop.i32(i32 %2772) #10
  %2774 = trunc i32 %2773 to i8
  %2775 = and i8 %2774, 1
  %2776 = xor i8 %2775, 1
  store i8 %2776, i8* %52, align 1, !tbaa !2447
  %2777 = xor i32 %2768, %2763
  %2778 = xor i32 %2777, %2769
  %2779 = lshr i32 %2778, 4
  %2780 = trunc i32 %2779 to i8
  %2781 = and i8 %2780, 1
  store i8 %2781, i8* %53, align 1, !tbaa !2451
  %2782 = icmp eq i32 %2769, 0
  %2783 = zext i1 %2782 to i8
  store i8 %2783, i8* %54, align 1, !tbaa !2448
  %2784 = lshr i32 %2769, 31
  %2785 = trunc i32 %2784 to i8
  store i8 %2785, i8* %55, align 1, !tbaa !2449
  %2786 = lshr i32 %2763, 31
  %2787 = lshr i32 %2768, 31
  %2788 = xor i32 %2787, %2786
  %2789 = xor i32 %2784, %2786
  %2790 = add nuw nsw i32 %2789, %2788
  %2791 = icmp eq i32 %2790, 2
  %2792 = zext i1 %2791 to i8
  store i8 %2792, i8* %56, align 1, !tbaa !2450
  %2793 = icmp ne i8 %2785, 0
  %2794 = xor i1 %2793, %2791
  %.v15 = select i1 %2794, i64 12, i64 898
  %2795 = add i64 %2758, %.v15
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %2796 = add i64 %2795, 13
  store i64 %2796, i64* %PC, align 8
  br i1 %2794, label %block_401ca9, label %block_40201f

block_401c96:                                     ; preds = %block_401c8a
  %2797 = add i64 %2872, -28
  %2798 = add i64 %2908, 7
  store i64 %2798, i64* %PC, align 8
  %2799 = inttoptr i64 %2797 to i32*
  store i32 0, i32* %2799, align 4
  %.pre6 = load i64, i64* %PC, align 8
  br label %block_401c9d

block_4021ec:                                     ; preds = %block_40218b, %block_4023d9
  %2800 = phi i64 [ %.pre7, %block_40218b ], [ %582, %block_4023d9 ]
  %2801 = load i64, i64* %RBP, align 8
  %2802 = add i64 %2801, -36
  %2803 = add i64 %2800, 3
  store i64 %2803, i64* %PC, align 8
  %2804 = inttoptr i64 %2802 to i32*
  %2805 = load i32, i32* %2804, align 4
  %2806 = zext i32 %2805 to i64
  store i64 %2806, i64* %RAX, align 8, !tbaa !2428
  %2807 = add i64 %2801, -48
  %2808 = add i64 %2800, 6
  store i64 %2808, i64* %PC, align 8
  %2809 = inttoptr i64 %2807 to i32*
  %2810 = load i32, i32* %2809, align 4
  %2811 = sub i32 %2805, %2810
  %2812 = icmp ult i32 %2805, %2810
  %2813 = zext i1 %2812 to i8
  store i8 %2813, i8* %51, align 1, !tbaa !2433
  %2814 = and i32 %2811, 255
  %2815 = tail call i32 @llvm.ctpop.i32(i32 %2814) #10
  %2816 = trunc i32 %2815 to i8
  %2817 = and i8 %2816, 1
  %2818 = xor i8 %2817, 1
  store i8 %2818, i8* %52, align 1, !tbaa !2447
  %2819 = xor i32 %2810, %2805
  %2820 = xor i32 %2819, %2811
  %2821 = lshr i32 %2820, 4
  %2822 = trunc i32 %2821 to i8
  %2823 = and i8 %2822, 1
  store i8 %2823, i8* %53, align 1, !tbaa !2451
  %2824 = icmp eq i32 %2811, 0
  %2825 = zext i1 %2824 to i8
  store i8 %2825, i8* %54, align 1, !tbaa !2448
  %2826 = lshr i32 %2811, 31
  %2827 = trunc i32 %2826 to i8
  store i8 %2827, i8* %55, align 1, !tbaa !2449
  %2828 = lshr i32 %2805, 31
  %2829 = lshr i32 %2810, 31
  %2830 = xor i32 %2829, %2828
  %2831 = xor i32 %2826, %2828
  %2832 = add nuw nsw i32 %2831, %2830
  %2833 = icmp eq i32 %2832, 2
  %2834 = zext i1 %2833 to i8
  store i8 %2834, i8* %56, align 1, !tbaa !2450
  %2835 = icmp ne i8 %2827, 0
  %2836 = xor i1 %2835, %2833
  %.v21 = select i1 %2836, i64 12, i64 641
  %2837 = add i64 %2800, %.v21
  store i64 %2837, i64* %PC, align 8, !tbaa !2428
  br i1 %2836, label %block_4021f8, label %block_40246d

block_401c15:                                     ; preds = %block_401c06
  %2838 = load i32, i32* %3703, align 4
  %2839 = zext i32 %2838 to i64
  %2840 = shl nuw i64 %2839, 32
  %2841 = ashr i64 %2840, 33
  %2842 = trunc i32 %2838 to i8
  %2843 = and i8 %2842, 1
  %2844 = trunc i64 %2841 to i32
  %2845 = and i64 %2841, 4294967295
  store i64 %2845, i64* %RAX, align 8, !tbaa !2428
  store i8 %2843, i8* %51, align 1, !tbaa !2432
  %2846 = and i32 %2844, 255
  %2847 = tail call i32 @llvm.ctpop.i32(i32 %2846) #10
  %2848 = trunc i32 %2847 to i8
  %2849 = and i8 %2848, 1
  %2850 = xor i8 %2849, 1
  store i8 %2850, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %2851 = icmp eq i32 %2844, 0
  %2852 = zext i1 %2851 to i8
  store i8 %2852, i8* %54, align 1, !tbaa !2432
  %2853 = lshr i64 %2841, 31
  %2854 = trunc i64 %2853 to i8
  %2855 = and i8 %2854, 1
  store i8 %2855, i8* %55, align 1, !tbaa !2432
  store i8 0, i8* %56, align 1, !tbaa !2432
  %2856 = add i64 %3730, 9
  store i64 %2856, i64* %PC, align 8
  store i32 %2844, i32* %3703, align 4
  %2857 = load i64, i64* %RBP, align 8
  %2858 = add i64 %2857, -28
  %2859 = load i64, i64* %PC, align 8
  %2860 = add i64 %2859, 7
  store i64 %2860, i64* %PC, align 8
  %2861 = inttoptr i64 %2858 to i32*
  store i32 0, i32* %2861, align 4
  %.pre4 = load i64, i64* %PC, align 8
  br label %block_401c25

block_402472:                                     ; preds = %block_402186, %block_40246d
  %.sink = phi i64 [ %192, %block_402186 ], [ %99, %block_40246d ]
  %2862 = add i64 %.sink, 1
  store i64 %2862, i64* %PC, align 8
  %2863 = load i64, i64* %7, align 8, !tbaa !2428
  %2864 = add i64 %2863, 8
  %2865 = inttoptr i64 %2863 to i64*
  %2866 = load i64, i64* %2865, align 8
  store i64 %2866, i64* %RBP, align 8, !tbaa !2428
  store i64 %2864, i64* %7, align 8, !tbaa !2428
  %2867 = add i64 %.sink, 2
  store i64 %2867, i64* %PC, align 8
  %2868 = inttoptr i64 %2864 to i64*
  %2869 = load i64, i64* %2868, align 8
  store i64 %2869, i64* %PC, align 8, !tbaa !2428
  %2870 = add i64 %2863, 16
  store i64 %2870, i64* %7, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_401c8a:                                     ; preds = %block_401c83, %block_40201f
  %2871 = phi i64 [ %.pre5, %block_401c83 ], [ %2757, %block_40201f ]
  %2872 = load i64, i64* %RBP, align 8
  %2873 = add i64 %2872, -36
  %2874 = add i64 %2871, 3
  store i64 %2874, i64* %PC, align 8
  %2875 = inttoptr i64 %2873 to i32*
  %2876 = load i32, i32* %2875, align 4
  %2877 = zext i32 %2876 to i64
  store i64 %2877, i64* %RAX, align 8, !tbaa !2428
  %2878 = add i64 %2872, -48
  %2879 = add i64 %2871, 6
  store i64 %2879, i64* %PC, align 8
  %2880 = inttoptr i64 %2878 to i32*
  %2881 = load i32, i32* %2880, align 4
  %2882 = sub i32 %2876, %2881
  %2883 = icmp ult i32 %2876, %2881
  %2884 = zext i1 %2883 to i8
  store i8 %2884, i8* %51, align 1, !tbaa !2433
  %2885 = and i32 %2882, 255
  %2886 = tail call i32 @llvm.ctpop.i32(i32 %2885) #10
  %2887 = trunc i32 %2886 to i8
  %2888 = and i8 %2887, 1
  %2889 = xor i8 %2888, 1
  store i8 %2889, i8* %52, align 1, !tbaa !2447
  %2890 = xor i32 %2881, %2876
  %2891 = xor i32 %2890, %2882
  %2892 = lshr i32 %2891, 4
  %2893 = trunc i32 %2892 to i8
  %2894 = and i8 %2893, 1
  store i8 %2894, i8* %53, align 1, !tbaa !2451
  %2895 = icmp eq i32 %2882, 0
  %2896 = zext i1 %2895 to i8
  store i8 %2896, i8* %54, align 1, !tbaa !2448
  %2897 = lshr i32 %2882, 31
  %2898 = trunc i32 %2897 to i8
  store i8 %2898, i8* %55, align 1, !tbaa !2449
  %2899 = lshr i32 %2876, 31
  %2900 = lshr i32 %2881, 31
  %2901 = xor i32 %2900, %2899
  %2902 = xor i32 %2897, %2899
  %2903 = add nuw nsw i32 %2902, %2901
  %2904 = icmp eq i32 %2903, 2
  %2905 = zext i1 %2904 to i8
  store i8 %2905, i8* %56, align 1, !tbaa !2450
  %2906 = icmp ne i8 %2898, 0
  %2907 = xor i1 %2906, %2904
  %.v14 = select i1 %2907, i64 12, i64 1276
  %2908 = add i64 %2871, %.v14
  store i64 %2908, i64* %PC, align 8, !tbaa !2428
  br i1 %2907, label %block_401c96, label %block_402186

block_40220b:                                     ; preds = %block_4021ff
  %2909 = load i32, i32* %61, align 4
  %2910 = shl i32 %2909, 1
  %2911 = icmp slt i32 %2909, 0
  %2912 = icmp slt i32 %2910, 0
  %2913 = xor i1 %2911, %2912
  %2914 = zext i32 %2910 to i64
  store i64 %2914, i64* %RCX, align 8, !tbaa !2428
  %.lobit23 = lshr i32 %2909, 31
  %2915 = trunc i32 %.lobit23 to i8
  store i8 %2915, i8* %51, align 1, !tbaa !2432
  %2916 = and i32 %2910, 254
  %2917 = tail call i32 @llvm.ctpop.i32(i32 %2916) #10
  %2918 = trunc i32 %2917 to i8
  %2919 = and i8 %2918, 1
  %2920 = xor i8 %2919, 1
  store i8 %2920, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %2921 = icmp eq i32 %2910, 0
  %2922 = zext i1 %2921 to i8
  store i8 %2922, i8* %54, align 1, !tbaa !2432
  %2923 = lshr i32 %2909, 30
  %2924 = and i32 %2923, 1
  %2925 = trunc i32 %2924 to i8
  store i8 %2925, i8* %55, align 1, !tbaa !2432
  %2926 = zext i1 %2913 to i8
  store i8 %2926, i8* %56, align 1, !tbaa !2432
  %2927 = add i64 %58, -16
  %2928 = add i64 %94, 20
  store i64 %2928, i64* %PC, align 8
  %2929 = inttoptr i64 %2927 to i64*
  %2930 = load i64, i64* %2929, align 8
  store i64 %2930, i64* %RDX, align 8, !tbaa !2428
  %2931 = add i64 %94, 24
  store i64 %2931, i64* %PC, align 8
  %2932 = load i32, i32* %66, align 4
  %2933 = sext i32 %2932 to i64
  store i64 %2933, i64* %RSI, align 8, !tbaa !2428
  %2934 = shl nsw i64 %2933, 2
  %2935 = add i64 %2934, %2930
  %2936 = add i64 %94, 27
  store i64 %2936, i64* %PC, align 8
  %2937 = inttoptr i64 %2935 to i32*
  %2938 = load i32, i32* %2937, align 4
  %2939 = add i32 %2938, %2910
  %2940 = zext i32 %2939 to i64
  store i64 %2940, i64* %RCX, align 8, !tbaa !2428
  %2941 = icmp ult i32 %2939, %2910
  %2942 = icmp ult i32 %2939, %2938
  %2943 = or i1 %2941, %2942
  %2944 = zext i1 %2943 to i8
  store i8 %2944, i8* %51, align 1, !tbaa !2433
  %2945 = and i32 %2939, 255
  %2946 = tail call i32 @llvm.ctpop.i32(i32 %2945) #10
  %2947 = trunc i32 %2946 to i8
  %2948 = and i8 %2947, 1
  %2949 = xor i8 %2948, 1
  store i8 %2949, i8* %52, align 1, !tbaa !2447
  %2950 = xor i32 %2938, %2910
  %2951 = xor i32 %2950, %2939
  %2952 = lshr i32 %2951, 4
  %2953 = trunc i32 %2952 to i8
  %2954 = and i8 %2953, 1
  store i8 %2954, i8* %53, align 1, !tbaa !2451
  %2955 = icmp eq i32 %2939, 0
  %2956 = zext i1 %2955 to i8
  store i8 %2956, i8* %54, align 1, !tbaa !2448
  %2957 = lshr i32 %2939, 31
  %2958 = trunc i32 %2957 to i8
  store i8 %2958, i8* %55, align 1, !tbaa !2449
  %2959 = lshr i32 %2938, 31
  %2960 = xor i32 %2957, %2924
  %2961 = xor i32 %2957, %2959
  %2962 = add nuw nsw i32 %2960, %2961
  %2963 = icmp eq i32 %2962, 2
  %2964 = zext i1 %2963 to i8
  store i8 %2964, i8* %56, align 1, !tbaa !2450
  %2965 = add i64 %58, -32
  %2966 = add i64 %94, 30
  store i64 %2966, i64* %PC, align 8
  %2967 = inttoptr i64 %2965 to i32*
  store i32 %2939, i32* %2967, align 4
  %2968 = load i64, i64* %RBP, align 8
  %2969 = add i64 %2968, -36
  %2970 = load i64, i64* %PC, align 8
  %2971 = add i64 %2970, 3
  store i64 %2971, i64* %PC, align 8
  %2972 = inttoptr i64 %2969 to i32*
  %2973 = load i32, i32* %2972, align 4
  %2974 = shl i32 %2973, 1
  %2975 = icmp slt i32 %2973, 0
  %2976 = icmp slt i32 %2974, 0
  %2977 = xor i1 %2975, %2976
  %2978 = zext i32 %2974 to i64
  store i64 %2978, i64* %RCX, align 8, !tbaa !2428
  %.lobit24 = lshr i32 %2973, 31
  %2979 = trunc i32 %.lobit24 to i8
  store i8 %2979, i8* %51, align 1, !tbaa !2432
  %2980 = and i32 %2974, 254
  %2981 = tail call i32 @llvm.ctpop.i32(i32 %2980) #10
  %2982 = trunc i32 %2981 to i8
  %2983 = and i8 %2982, 1
  %2984 = xor i8 %2983, 1
  store i8 %2984, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %2985 = icmp eq i32 %2974, 0
  %2986 = zext i1 %2985 to i8
  store i8 %2986, i8* %54, align 1, !tbaa !2432
  %2987 = lshr i32 %2973, 30
  %2988 = and i32 %2987, 1
  %2989 = trunc i32 %2988 to i8
  store i8 %2989, i8* %55, align 1, !tbaa !2432
  %2990 = zext i1 %2977 to i8
  store i8 %2990, i8* %56, align 1, !tbaa !2432
  %2991 = add i64 %2968, -16
  %2992 = add i64 %2970, 10
  store i64 %2992, i64* %PC, align 8
  %2993 = inttoptr i64 %2991 to i64*
  %2994 = load i64, i64* %2993, align 8
  store i64 %2994, i64* %RDX, align 8, !tbaa !2428
  %2995 = add i64 %2968, -28
  %2996 = add i64 %2970, 14
  store i64 %2996, i64* %PC, align 8
  %2997 = inttoptr i64 %2995 to i32*
  %2998 = load i32, i32* %2997, align 4
  %2999 = sext i32 %2998 to i64
  store i64 %2999, i64* %RSI, align 8, !tbaa !2428
  %3000 = shl nsw i64 %2999, 2
  %3001 = add i64 %3000, %2994
  %3002 = add i64 %2970, 17
  store i64 %3002, i64* %PC, align 8
  %3003 = inttoptr i64 %3001 to i32*
  %3004 = load i32, i32* %3003, align 4
  %3005 = add i32 %3004, %2974
  %3006 = zext i32 %3005 to i64
  store i64 %3006, i64* %RCX, align 8, !tbaa !2428
  %3007 = icmp ult i32 %3005, %2974
  %3008 = icmp ult i32 %3005, %3004
  %3009 = or i1 %3007, %3008
  %3010 = zext i1 %3009 to i8
  store i8 %3010, i8* %51, align 1, !tbaa !2433
  %3011 = and i32 %3005, 255
  %3012 = tail call i32 @llvm.ctpop.i32(i32 %3011) #10
  %3013 = trunc i32 %3012 to i8
  %3014 = and i8 %3013, 1
  %3015 = xor i8 %3014, 1
  store i8 %3015, i8* %52, align 1, !tbaa !2447
  %3016 = xor i32 %3004, %2974
  %3017 = xor i32 %3016, %3005
  %3018 = lshr i32 %3017, 4
  %3019 = trunc i32 %3018 to i8
  %3020 = and i8 %3019, 1
  store i8 %3020, i8* %53, align 1, !tbaa !2451
  %3021 = icmp eq i32 %3005, 0
  %3022 = zext i1 %3021 to i8
  store i8 %3022, i8* %54, align 1, !tbaa !2448
  %3023 = lshr i32 %3005, 31
  %3024 = trunc i32 %3023 to i8
  store i8 %3024, i8* %55, align 1, !tbaa !2449
  %3025 = lshr i32 %3004, 31
  %3026 = xor i32 %3023, %2988
  %3027 = xor i32 %3023, %3025
  %3028 = add nuw nsw i32 %3026, %3027
  %3029 = icmp eq i32 %3028, 2
  %3030 = zext i1 %3029 to i8
  store i8 %3030, i8* %56, align 1, !tbaa !2450
  %3031 = add i64 %2968, -40
  %3032 = add i64 %2970, 20
  store i64 %3032, i64* %PC, align 8
  %3033 = inttoptr i64 %3031 to i32*
  store i32 %3005, i32* %3033, align 4
  %3034 = load i64, i64* %RBP, align 8
  %3035 = add i64 %3034, -24
  %3036 = load i64, i64* %PC, align 8
  %3037 = add i64 %3036, 4
  store i64 %3037, i64* %PC, align 8
  %3038 = inttoptr i64 %3035 to i64*
  %3039 = load i64, i64* %3038, align 8
  store i64 %3039, i64* %RDX, align 8, !tbaa !2428
  %3040 = add i64 %3034, -32
  %3041 = add i64 %3036, 8
  store i64 %3041, i64* %PC, align 8
  %3042 = inttoptr i64 %3040 to i32*
  %3043 = load i32, i32* %3042, align 4
  %3044 = sext i32 %3043 to i64
  store i64 %3044, i64* %RSI, align 8, !tbaa !2428
  %3045 = shl nsw i64 %3044, 3
  %3046 = add i64 %3045, %3039
  %3047 = add i64 %3036, 13
  store i64 %3047, i64* %PC, align 8
  %3048 = inttoptr i64 %3046 to i64*
  %3049 = load i64, i64* %3048, align 8
  store i64 %3049, i64* %3753, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3741, align 1, !tbaa !2452
  %3050 = add i64 %3034, -64
  %3051 = add i64 %3036, 18
  store i64 %3051, i64* %PC, align 8
  %3052 = inttoptr i64 %3050 to i64*
  store i64 %3049, i64* %3052, align 8
  %3053 = load i64, i64* %RBP, align 8
  %3054 = add i64 %3053, -24
  %3055 = load i64, i64* %PC, align 8
  %3056 = add i64 %3055, 4
  store i64 %3056, i64* %PC, align 8
  %3057 = inttoptr i64 %3054 to i64*
  %3058 = load i64, i64* %3057, align 8
  store i64 %3058, i64* %RDX, align 8, !tbaa !2428
  %3059 = add i64 %3053, -32
  %3060 = add i64 %3055, 7
  store i64 %3060, i64* %PC, align 8
  %3061 = inttoptr i64 %3059 to i32*
  %3062 = load i32, i32* %3061, align 4
  %3063 = add i32 %3062, 1
  %3064 = zext i32 %3063 to i64
  store i64 %3064, i64* %RCX, align 8, !tbaa !2428
  %3065 = icmp eq i32 %3062, -1
  %3066 = icmp eq i32 %3063, 0
  %3067 = or i1 %3065, %3066
  %3068 = zext i1 %3067 to i8
  store i8 %3068, i8* %51, align 1, !tbaa !2433
  %3069 = and i32 %3063, 255
  %3070 = tail call i32 @llvm.ctpop.i32(i32 %3069) #10
  %3071 = trunc i32 %3070 to i8
  %3072 = and i8 %3071, 1
  %3073 = xor i8 %3072, 1
  store i8 %3073, i8* %52, align 1, !tbaa !2447
  %3074 = xor i32 %3062, %3063
  %3075 = lshr i32 %3074, 4
  %3076 = trunc i32 %3075 to i8
  %3077 = and i8 %3076, 1
  store i8 %3077, i8* %53, align 1, !tbaa !2451
  %3078 = zext i1 %3066 to i8
  store i8 %3078, i8* %54, align 1, !tbaa !2448
  %3079 = lshr i32 %3063, 31
  %3080 = trunc i32 %3079 to i8
  store i8 %3080, i8* %55, align 1, !tbaa !2449
  %3081 = lshr i32 %3062, 31
  %3082 = xor i32 %3079, %3081
  %3083 = add nuw nsw i32 %3082, %3079
  %3084 = icmp eq i32 %3083, 2
  %3085 = zext i1 %3084 to i8
  store i8 %3085, i8* %56, align 1, !tbaa !2450
  %3086 = sext i32 %3063 to i64
  store i64 %3086, i64* %RSI, align 8, !tbaa !2428
  %3087 = shl nsw i64 %3086, 3
  %3088 = add i64 %3087, %3058
  %3089 = add i64 %3055, 18
  store i64 %3089, i64* %PC, align 8
  %3090 = inttoptr i64 %3088 to i64*
  %3091 = load i64, i64* %3090, align 8
  %3092 = load i64, i64* %RAX, align 8
  %3093 = xor i64 %3092, %3091
  store i64 %3093, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %3094 = trunc i64 %3093 to i32
  %3095 = and i32 %3094, 255
  %3096 = tail call i32 @llvm.ctpop.i32(i32 %3095) #10
  %3097 = trunc i32 %3096 to i8
  %3098 = and i8 %3097, 1
  %3099 = xor i8 %3098, 1
  store i8 %3099, i8* %52, align 1, !tbaa !2447
  %3100 = icmp eq i64 %3093, 0
  %3101 = zext i1 %3100 to i8
  store i8 %3101, i8* %54, align 1, !tbaa !2448
  %3102 = lshr i64 %3093, 63
  %3103 = trunc i64 %3102 to i8
  store i8 %3103, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %3093, i64* %3753, align 1, !tbaa !2428
  store i64 0, i64* %3740, align 1, !tbaa !2428
  %3104 = add i64 %3053, -72
  %3105 = add i64 %3055, 36
  store i64 %3105, i64* %PC, align 8
  %3106 = inttoptr i64 %3104 to i64*
  store i64 %3093, i64* %3106, align 8
  %3107 = load i64, i64* %RBP, align 8
  %3108 = add i64 %3107, -24
  %3109 = load i64, i64* %PC, align 8
  %3110 = add i64 %3109, 4
  store i64 %3110, i64* %PC, align 8
  %3111 = inttoptr i64 %3108 to i64*
  %3112 = load i64, i64* %3111, align 8
  store i64 %3112, i64* %RDX, align 8, !tbaa !2428
  %3113 = add i64 %3107, -40
  %3114 = add i64 %3109, 8
  store i64 %3114, i64* %PC, align 8
  %3115 = inttoptr i64 %3113 to i32*
  %3116 = load i32, i32* %3115, align 4
  %3117 = sext i32 %3116 to i64
  store i64 %3117, i64* %RSI, align 8, !tbaa !2428
  %3118 = shl nsw i64 %3117, 3
  %3119 = add i64 %3118, %3112
  %3120 = add i64 %3109, 13
  store i64 %3120, i64* %PC, align 8
  %3121 = inttoptr i64 %3119 to i64*
  %3122 = load i64, i64* %3121, align 8
  store i64 %3122, i64* %3753, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3741, align 1, !tbaa !2452
  %3123 = add i64 %3107, -80
  %3124 = add i64 %3109, 18
  store i64 %3124, i64* %PC, align 8
  %3125 = inttoptr i64 %3123 to i64*
  store i64 %3122, i64* %3125, align 8
  %3126 = load i64, i64* %RBP, align 8
  %3127 = add i64 %3126, -24
  %3128 = load i64, i64* %PC, align 8
  %3129 = add i64 %3128, 4
  store i64 %3129, i64* %PC, align 8
  %3130 = inttoptr i64 %3127 to i64*
  %3131 = load i64, i64* %3130, align 8
  store i64 %3131, i64* %RDX, align 8, !tbaa !2428
  %3132 = add i64 %3126, -40
  %3133 = add i64 %3128, 7
  store i64 %3133, i64* %PC, align 8
  %3134 = inttoptr i64 %3132 to i32*
  %3135 = load i32, i32* %3134, align 4
  %3136 = add i32 %3135, 1
  %3137 = zext i32 %3136 to i64
  store i64 %3137, i64* %RCX, align 8, !tbaa !2428
  %3138 = icmp eq i32 %3135, -1
  %3139 = icmp eq i32 %3136, 0
  %3140 = or i1 %3138, %3139
  %3141 = zext i1 %3140 to i8
  store i8 %3141, i8* %51, align 1, !tbaa !2433
  %3142 = and i32 %3136, 255
  %3143 = tail call i32 @llvm.ctpop.i32(i32 %3142) #10
  %3144 = trunc i32 %3143 to i8
  %3145 = and i8 %3144, 1
  %3146 = xor i8 %3145, 1
  store i8 %3146, i8* %52, align 1, !tbaa !2447
  %3147 = xor i32 %3135, %3136
  %3148 = lshr i32 %3147, 4
  %3149 = trunc i32 %3148 to i8
  %3150 = and i8 %3149, 1
  store i8 %3150, i8* %53, align 1, !tbaa !2451
  %3151 = zext i1 %3139 to i8
  store i8 %3151, i8* %54, align 1, !tbaa !2448
  %3152 = lshr i32 %3136, 31
  %3153 = trunc i32 %3152 to i8
  store i8 %3153, i8* %55, align 1, !tbaa !2449
  %3154 = lshr i32 %3135, 31
  %3155 = xor i32 %3152, %3154
  %3156 = add nuw nsw i32 %3155, %3152
  %3157 = icmp eq i32 %3156, 2
  %3158 = zext i1 %3157 to i8
  store i8 %3158, i8* %56, align 1, !tbaa !2450
  %3159 = sext i32 %3136 to i64
  store i64 %3159, i64* %RSI, align 8, !tbaa !2428
  %3160 = shl nsw i64 %3159, 3
  %3161 = add i64 %3160, %3131
  %3162 = add i64 %3128, 18
  store i64 %3162, i64* %PC, align 8
  %3163 = inttoptr i64 %3161 to i64*
  %3164 = load i64, i64* %3163, align 8
  %3165 = load i64, i64* %RAX, align 8
  %3166 = xor i64 %3165, %3164
  store i64 %3166, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %3167 = trunc i64 %3166 to i32
  %3168 = and i32 %3167, 255
  %3169 = tail call i32 @llvm.ctpop.i32(i32 %3168) #10
  %3170 = trunc i32 %3169 to i8
  %3171 = and i8 %3170, 1
  %3172 = xor i8 %3171, 1
  store i8 %3172, i8* %52, align 1, !tbaa !2447
  %3173 = icmp eq i64 %3166, 0
  %3174 = zext i1 %3173 to i8
  store i8 %3174, i8* %54, align 1, !tbaa !2448
  %3175 = lshr i64 %3166, 63
  %3176 = trunc i64 %3175 to i8
  store i8 %3176, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %3166, i64* %3753, align 1, !tbaa !2428
  store i64 0, i64* %3740, align 1, !tbaa !2428
  %3177 = add i64 %3126, -88
  %3178 = add i64 %3128, 36
  store i64 %3178, i64* %PC, align 8
  %3179 = inttoptr i64 %3177 to i64*
  store i64 %3166, i64* %3179, align 8
  %3180 = load i64, i64* %RBP, align 8
  %3181 = add i64 %3180, -80
  %3182 = load i64, i64* %PC, align 8
  %3183 = add i64 %3182, 5
  store i64 %3183, i64* %PC, align 8
  %3184 = inttoptr i64 %3181 to i64*
  %3185 = load i64, i64* %3184, align 8
  store i64 %3185, i64* %3753, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3741, align 1, !tbaa !2452
  %3186 = add i64 %3180, -24
  %3187 = add i64 %3182, 9
  store i64 %3187, i64* %PC, align 8
  %3188 = inttoptr i64 %3186 to i64*
  %3189 = load i64, i64* %3188, align 8
  store i64 %3189, i64* %RDX, align 8, !tbaa !2428
  %3190 = add i64 %3180, -32
  %3191 = add i64 %3182, 13
  store i64 %3191, i64* %PC, align 8
  %3192 = inttoptr i64 %3190 to i32*
  %3193 = load i32, i32* %3192, align 4
  %3194 = sext i32 %3193 to i64
  store i64 %3194, i64* %RSI, align 8, !tbaa !2428
  %3195 = shl nsw i64 %3194, 3
  %3196 = add i64 %3195, %3189
  %3197 = add i64 %3182, 18
  store i64 %3197, i64* %PC, align 8
  %3198 = inttoptr i64 %3196 to i64*
  store i64 %3185, i64* %3198, align 8
  %3199 = load i64, i64* %RBP, align 8
  %3200 = add i64 %3199, -88
  %3201 = load i64, i64* %PC, align 8
  %3202 = add i64 %3201, 5
  store i64 %3202, i64* %PC, align 8
  %3203 = inttoptr i64 %3200 to i64*
  %3204 = load i64, i64* %3203, align 8
  store i64 %3204, i64* %3753, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3741, align 1, !tbaa !2452
  %3205 = add i64 %3199, -24
  %3206 = add i64 %3201, 9
  store i64 %3206, i64* %PC, align 8
  %3207 = inttoptr i64 %3205 to i64*
  %3208 = load i64, i64* %3207, align 8
  store i64 %3208, i64* %RDX, align 8, !tbaa !2428
  %3209 = add i64 %3199, -32
  %3210 = add i64 %3201, 12
  store i64 %3210, i64* %PC, align 8
  %3211 = inttoptr i64 %3209 to i32*
  %3212 = load i32, i32* %3211, align 4
  %3213 = add i32 %3212, 1
  %3214 = zext i32 %3213 to i64
  store i64 %3214, i64* %RCX, align 8, !tbaa !2428
  %3215 = icmp eq i32 %3212, -1
  %3216 = icmp eq i32 %3213, 0
  %3217 = or i1 %3215, %3216
  %3218 = zext i1 %3217 to i8
  store i8 %3218, i8* %51, align 1, !tbaa !2433
  %3219 = and i32 %3213, 255
  %3220 = tail call i32 @llvm.ctpop.i32(i32 %3219) #10
  %3221 = trunc i32 %3220 to i8
  %3222 = and i8 %3221, 1
  %3223 = xor i8 %3222, 1
  store i8 %3223, i8* %52, align 1, !tbaa !2447
  %3224 = xor i32 %3212, %3213
  %3225 = lshr i32 %3224, 4
  %3226 = trunc i32 %3225 to i8
  %3227 = and i8 %3226, 1
  store i8 %3227, i8* %53, align 1, !tbaa !2451
  %3228 = zext i1 %3216 to i8
  store i8 %3228, i8* %54, align 1, !tbaa !2448
  %3229 = lshr i32 %3213, 31
  %3230 = trunc i32 %3229 to i8
  store i8 %3230, i8* %55, align 1, !tbaa !2449
  %3231 = lshr i32 %3212, 31
  %3232 = xor i32 %3229, %3231
  %3233 = add nuw nsw i32 %3232, %3229
  %3234 = icmp eq i32 %3233, 2
  %3235 = zext i1 %3234 to i8
  store i8 %3235, i8* %56, align 1, !tbaa !2450
  %3236 = sext i32 %3213 to i64
  store i64 %3236, i64* %RSI, align 8, !tbaa !2428
  %3237 = shl nsw i64 %3236, 3
  %3238 = add i64 %3237, %3208
  %3239 = add i64 %3201, 23
  store i64 %3239, i64* %PC, align 8
  %3240 = inttoptr i64 %3238 to i64*
  store i64 %3204, i64* %3240, align 8
  %3241 = load i64, i64* %RBP, align 8
  %3242 = add i64 %3241, -64
  %3243 = load i64, i64* %PC, align 8
  %3244 = add i64 %3243, 5
  store i64 %3244, i64* %PC, align 8
  %3245 = inttoptr i64 %3242 to i64*
  %3246 = load i64, i64* %3245, align 8
  store i64 %3246, i64* %3753, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3741, align 1, !tbaa !2452
  %3247 = add i64 %3241, -24
  %3248 = add i64 %3243, 9
  store i64 %3248, i64* %PC, align 8
  %3249 = inttoptr i64 %3247 to i64*
  %3250 = load i64, i64* %3249, align 8
  store i64 %3250, i64* %RDX, align 8, !tbaa !2428
  %3251 = add i64 %3241, -40
  %3252 = add i64 %3243, 13
  store i64 %3252, i64* %PC, align 8
  %3253 = inttoptr i64 %3251 to i32*
  %3254 = load i32, i32* %3253, align 4
  %3255 = sext i32 %3254 to i64
  store i64 %3255, i64* %RSI, align 8, !tbaa !2428
  %3256 = shl nsw i64 %3255, 3
  %3257 = add i64 %3256, %3250
  %3258 = add i64 %3243, 18
  store i64 %3258, i64* %PC, align 8
  %3259 = inttoptr i64 %3257 to i64*
  store i64 %3246, i64* %3259, align 8
  %3260 = load i64, i64* %RBP, align 8
  %3261 = add i64 %3260, -72
  %3262 = load i64, i64* %PC, align 8
  %3263 = add i64 %3262, 5
  store i64 %3263, i64* %PC, align 8
  %3264 = inttoptr i64 %3261 to i64*
  %3265 = load i64, i64* %3264, align 8
  store i64 %3265, i64* %3753, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3741, align 1, !tbaa !2452
  %3266 = add i64 %3260, -24
  %3267 = add i64 %3262, 9
  store i64 %3267, i64* %PC, align 8
  %3268 = inttoptr i64 %3266 to i64*
  %3269 = load i64, i64* %3268, align 8
  store i64 %3269, i64* %RDX, align 8, !tbaa !2428
  %3270 = add i64 %3260, -40
  %3271 = add i64 %3262, 12
  store i64 %3271, i64* %PC, align 8
  %3272 = inttoptr i64 %3270 to i32*
  %3273 = load i32, i32* %3272, align 4
  %3274 = add i32 %3273, 1
  %3275 = zext i32 %3274 to i64
  store i64 %3275, i64* %RCX, align 8, !tbaa !2428
  %3276 = icmp eq i32 %3273, -1
  %3277 = icmp eq i32 %3274, 0
  %3278 = or i1 %3276, %3277
  %3279 = zext i1 %3278 to i8
  store i8 %3279, i8* %51, align 1, !tbaa !2433
  %3280 = and i32 %3274, 255
  %3281 = tail call i32 @llvm.ctpop.i32(i32 %3280) #10
  %3282 = trunc i32 %3281 to i8
  %3283 = and i8 %3282, 1
  %3284 = xor i8 %3283, 1
  store i8 %3284, i8* %52, align 1, !tbaa !2447
  %3285 = xor i32 %3273, %3274
  %3286 = lshr i32 %3285, 4
  %3287 = trunc i32 %3286 to i8
  %3288 = and i8 %3287, 1
  store i8 %3288, i8* %53, align 1, !tbaa !2451
  %3289 = zext i1 %3277 to i8
  store i8 %3289, i8* %54, align 1, !tbaa !2448
  %3290 = lshr i32 %3274, 31
  %3291 = trunc i32 %3290 to i8
  store i8 %3291, i8* %55, align 1, !tbaa !2449
  %3292 = lshr i32 %3273, 31
  %3293 = xor i32 %3290, %3292
  %3294 = add nuw nsw i32 %3293, %3290
  %3295 = icmp eq i32 %3294, 2
  %3296 = zext i1 %3295 to i8
  store i8 %3296, i8* %56, align 1, !tbaa !2450
  %3297 = sext i32 %3274 to i64
  store i64 %3297, i64* %RSI, align 8, !tbaa !2428
  %3298 = shl nsw i64 %3297, 3
  %3299 = add i64 %3298, %3269
  %3300 = add i64 %3262, 23
  store i64 %3300, i64* %PC, align 8
  %3301 = inttoptr i64 %3299 to i64*
  store i64 %3265, i64* %3301, align 8
  %3302 = load i64, i64* %RBP, align 8
  %3303 = add i64 %3302, -52
  %3304 = load i64, i64* %PC, align 8
  %3305 = add i64 %3304, 3
  store i64 %3305, i64* %PC, align 8
  %3306 = inttoptr i64 %3303 to i32*
  %3307 = load i32, i32* %3306, align 4
  %3308 = zext i32 %3307 to i64
  store i64 %3308, i64* %RCX, align 8, !tbaa !2428
  %3309 = add i64 %3302, -32
  %3310 = add i64 %3304, 6
  store i64 %3310, i64* %PC, align 8
  %3311 = inttoptr i64 %3309 to i32*
  %3312 = load i32, i32* %3311, align 4
  %3313 = add i32 %3312, %3307
  %3314 = zext i32 %3313 to i64
  store i64 %3314, i64* %RCX, align 8, !tbaa !2428
  %3315 = icmp ult i32 %3313, %3307
  %3316 = icmp ult i32 %3313, %3312
  %3317 = or i1 %3315, %3316
  %3318 = zext i1 %3317 to i8
  store i8 %3318, i8* %51, align 1, !tbaa !2433
  %3319 = and i32 %3313, 255
  %3320 = tail call i32 @llvm.ctpop.i32(i32 %3319) #10
  %3321 = trunc i32 %3320 to i8
  %3322 = and i8 %3321, 1
  %3323 = xor i8 %3322, 1
  store i8 %3323, i8* %52, align 1, !tbaa !2447
  %3324 = xor i32 %3312, %3307
  %3325 = xor i32 %3324, %3313
  %3326 = lshr i32 %3325, 4
  %3327 = trunc i32 %3326 to i8
  %3328 = and i8 %3327, 1
  store i8 %3328, i8* %53, align 1, !tbaa !2451
  %3329 = icmp eq i32 %3313, 0
  %3330 = zext i1 %3329 to i8
  store i8 %3330, i8* %54, align 1, !tbaa !2448
  %3331 = lshr i32 %3313, 31
  %3332 = trunc i32 %3331 to i8
  store i8 %3332, i8* %55, align 1, !tbaa !2449
  %3333 = lshr i32 %3307, 31
  %3334 = lshr i32 %3312, 31
  %3335 = xor i32 %3331, %3333
  %3336 = xor i32 %3331, %3334
  %3337 = add nuw nsw i32 %3335, %3336
  %3338 = icmp eq i32 %3337, 2
  %3339 = zext i1 %3338 to i8
  store i8 %3339, i8* %56, align 1, !tbaa !2450
  %3340 = add i64 %3304, 9
  store i64 %3340, i64* %PC, align 8
  store i32 %3313, i32* %3311, align 4
  %3341 = load i64, i64* %RBP, align 8
  %3342 = add i64 %3341, -52
  %3343 = load i64, i64* %PC, align 8
  %3344 = add i64 %3343, 3
  store i64 %3344, i64* %PC, align 8
  %3345 = inttoptr i64 %3342 to i32*
  %3346 = load i32, i32* %3345, align 4
  %3347 = zext i32 %3346 to i64
  store i64 %3347, i64* %RCX, align 8, !tbaa !2428
  %3348 = add i64 %3341, -40
  %3349 = add i64 %3343, 6
  store i64 %3349, i64* %PC, align 8
  %3350 = inttoptr i64 %3348 to i32*
  %3351 = load i32, i32* %3350, align 4
  %3352 = add i32 %3351, %3346
  %3353 = zext i32 %3352 to i64
  store i64 %3353, i64* %RCX, align 8, !tbaa !2428
  %3354 = icmp ult i32 %3352, %3346
  %3355 = icmp ult i32 %3352, %3351
  %3356 = or i1 %3354, %3355
  %3357 = zext i1 %3356 to i8
  store i8 %3357, i8* %51, align 1, !tbaa !2433
  %3358 = and i32 %3352, 255
  %3359 = tail call i32 @llvm.ctpop.i32(i32 %3358) #10
  %3360 = trunc i32 %3359 to i8
  %3361 = and i8 %3360, 1
  %3362 = xor i8 %3361, 1
  store i8 %3362, i8* %52, align 1, !tbaa !2447
  %3363 = xor i32 %3351, %3346
  %3364 = xor i32 %3363, %3352
  %3365 = lshr i32 %3364, 4
  %3366 = trunc i32 %3365 to i8
  %3367 = and i8 %3366, 1
  store i8 %3367, i8* %53, align 1, !tbaa !2451
  %3368 = icmp eq i32 %3352, 0
  %3369 = zext i1 %3368 to i8
  store i8 %3369, i8* %54, align 1, !tbaa !2448
  %3370 = lshr i32 %3352, 31
  %3371 = trunc i32 %3370 to i8
  store i8 %3371, i8* %55, align 1, !tbaa !2449
  %3372 = lshr i32 %3346, 31
  %3373 = lshr i32 %3351, 31
  %3374 = xor i32 %3370, %3372
  %3375 = xor i32 %3370, %3373
  %3376 = add nuw nsw i32 %3374, %3375
  %3377 = icmp eq i32 %3376, 2
  %3378 = zext i1 %3377 to i8
  store i8 %3378, i8* %56, align 1, !tbaa !2450
  %3379 = add i64 %3343, 9
  store i64 %3379, i64* %PC, align 8
  store i32 %3352, i32* %3350, align 4
  %3380 = load i64, i64* %RBP, align 8
  %3381 = add i64 %3380, -24
  %3382 = load i64, i64* %PC, align 8
  %3383 = add i64 %3382, 4
  store i64 %3383, i64* %PC, align 8
  %3384 = inttoptr i64 %3381 to i64*
  %3385 = load i64, i64* %3384, align 8
  store i64 %3385, i64* %RDX, align 8, !tbaa !2428
  %3386 = add i64 %3380, -32
  %3387 = add i64 %3382, 8
  store i64 %3387, i64* %PC, align 8
  %3388 = inttoptr i64 %3386 to i32*
  %3389 = load i32, i32* %3388, align 4
  %3390 = sext i32 %3389 to i64
  store i64 %3390, i64* %RSI, align 8, !tbaa !2428
  %3391 = shl nsw i64 %3390, 3
  %3392 = add i64 %3391, %3385
  %3393 = add i64 %3382, 13
  store i64 %3393, i64* %PC, align 8
  %3394 = inttoptr i64 %3392 to i64*
  %3395 = load i64, i64* %3394, align 8
  store i64 %3395, i64* %3753, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3741, align 1, !tbaa !2452
  %3396 = add i64 %3380, -64
  %3397 = add i64 %3382, 18
  store i64 %3397, i64* %PC, align 8
  %3398 = inttoptr i64 %3396 to i64*
  store i64 %3395, i64* %3398, align 8
  %3399 = load i64, i64* %RBP, align 8
  %3400 = add i64 %3399, -24
  %3401 = load i64, i64* %PC, align 8
  %3402 = add i64 %3401, 4
  store i64 %3402, i64* %PC, align 8
  %3403 = inttoptr i64 %3400 to i64*
  %3404 = load i64, i64* %3403, align 8
  store i64 %3404, i64* %RDX, align 8, !tbaa !2428
  %3405 = add i64 %3399, -32
  %3406 = add i64 %3401, 7
  store i64 %3406, i64* %PC, align 8
  %3407 = inttoptr i64 %3405 to i32*
  %3408 = load i32, i32* %3407, align 4
  %3409 = add i32 %3408, 1
  %3410 = zext i32 %3409 to i64
  store i64 %3410, i64* %RCX, align 8, !tbaa !2428
  %3411 = icmp eq i32 %3408, -1
  %3412 = icmp eq i32 %3409, 0
  %3413 = or i1 %3411, %3412
  %3414 = zext i1 %3413 to i8
  store i8 %3414, i8* %51, align 1, !tbaa !2433
  %3415 = and i32 %3409, 255
  %3416 = tail call i32 @llvm.ctpop.i32(i32 %3415) #10
  %3417 = trunc i32 %3416 to i8
  %3418 = and i8 %3417, 1
  %3419 = xor i8 %3418, 1
  store i8 %3419, i8* %52, align 1, !tbaa !2447
  %3420 = xor i32 %3408, %3409
  %3421 = lshr i32 %3420, 4
  %3422 = trunc i32 %3421 to i8
  %3423 = and i8 %3422, 1
  store i8 %3423, i8* %53, align 1, !tbaa !2451
  %3424 = zext i1 %3412 to i8
  store i8 %3424, i8* %54, align 1, !tbaa !2448
  %3425 = lshr i32 %3409, 31
  %3426 = trunc i32 %3425 to i8
  store i8 %3426, i8* %55, align 1, !tbaa !2449
  %3427 = lshr i32 %3408, 31
  %3428 = xor i32 %3425, %3427
  %3429 = add nuw nsw i32 %3428, %3425
  %3430 = icmp eq i32 %3429, 2
  %3431 = zext i1 %3430 to i8
  store i8 %3431, i8* %56, align 1, !tbaa !2450
  %3432 = sext i32 %3409 to i64
  store i64 %3432, i64* %RSI, align 8, !tbaa !2428
  %3433 = shl nsw i64 %3432, 3
  %3434 = add i64 %3433, %3404
  %3435 = add i64 %3401, 18
  store i64 %3435, i64* %PC, align 8
  %3436 = inttoptr i64 %3434 to i64*
  %3437 = load i64, i64* %3436, align 8
  %3438 = load i64, i64* %RAX, align 8
  %3439 = xor i64 %3438, %3437
  store i64 %3439, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %3440 = trunc i64 %3439 to i32
  %3441 = and i32 %3440, 255
  %3442 = tail call i32 @llvm.ctpop.i32(i32 %3441) #10
  %3443 = trunc i32 %3442 to i8
  %3444 = and i8 %3443, 1
  %3445 = xor i8 %3444, 1
  store i8 %3445, i8* %52, align 1, !tbaa !2447
  %3446 = icmp eq i64 %3439, 0
  %3447 = zext i1 %3446 to i8
  store i8 %3447, i8* %54, align 1, !tbaa !2448
  %3448 = lshr i64 %3439, 63
  %3449 = trunc i64 %3448 to i8
  store i8 %3449, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %3439, i64* %3753, align 1, !tbaa !2428
  store i64 0, i64* %3740, align 1, !tbaa !2428
  %3450 = add i64 %3399, -72
  %3451 = add i64 %3401, 36
  store i64 %3451, i64* %PC, align 8
  %3452 = inttoptr i64 %3450 to i64*
  store i64 %3439, i64* %3452, align 8
  %3453 = load i64, i64* %RBP, align 8
  %3454 = add i64 %3453, -24
  %3455 = load i64, i64* %PC, align 8
  %3456 = add i64 %3455, 4
  store i64 %3456, i64* %PC, align 8
  %3457 = inttoptr i64 %3454 to i64*
  %3458 = load i64, i64* %3457, align 8
  store i64 %3458, i64* %RDX, align 8, !tbaa !2428
  %3459 = add i64 %3453, -40
  %3460 = add i64 %3455, 8
  store i64 %3460, i64* %PC, align 8
  %3461 = inttoptr i64 %3459 to i32*
  %3462 = load i32, i32* %3461, align 4
  %3463 = sext i32 %3462 to i64
  store i64 %3463, i64* %RSI, align 8, !tbaa !2428
  %3464 = shl nsw i64 %3463, 3
  %3465 = add i64 %3464, %3458
  %3466 = add i64 %3455, 13
  store i64 %3466, i64* %PC, align 8
  %3467 = inttoptr i64 %3465 to i64*
  %3468 = load i64, i64* %3467, align 8
  store i64 %3468, i64* %3753, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3741, align 1, !tbaa !2452
  %3469 = add i64 %3453, -80
  %3470 = add i64 %3455, 18
  store i64 %3470, i64* %PC, align 8
  %3471 = inttoptr i64 %3469 to i64*
  store i64 %3468, i64* %3471, align 8
  %3472 = load i64, i64* %RBP, align 8
  %3473 = add i64 %3472, -24
  %3474 = load i64, i64* %PC, align 8
  %3475 = add i64 %3474, 4
  store i64 %3475, i64* %PC, align 8
  %3476 = inttoptr i64 %3473 to i64*
  %3477 = load i64, i64* %3476, align 8
  store i64 %3477, i64* %RDX, align 8, !tbaa !2428
  %3478 = add i64 %3472, -40
  %3479 = add i64 %3474, 7
  store i64 %3479, i64* %PC, align 8
  %3480 = inttoptr i64 %3478 to i32*
  %3481 = load i32, i32* %3480, align 4
  %3482 = add i32 %3481, 1
  %3483 = zext i32 %3482 to i64
  store i64 %3483, i64* %RCX, align 8, !tbaa !2428
  %3484 = icmp eq i32 %3481, -1
  %3485 = icmp eq i32 %3482, 0
  %3486 = or i1 %3484, %3485
  %3487 = zext i1 %3486 to i8
  store i8 %3487, i8* %51, align 1, !tbaa !2433
  %3488 = and i32 %3482, 255
  %3489 = tail call i32 @llvm.ctpop.i32(i32 %3488) #10
  %3490 = trunc i32 %3489 to i8
  %3491 = and i8 %3490, 1
  %3492 = xor i8 %3491, 1
  store i8 %3492, i8* %52, align 1, !tbaa !2447
  %3493 = xor i32 %3481, %3482
  %3494 = lshr i32 %3493, 4
  %3495 = trunc i32 %3494 to i8
  %3496 = and i8 %3495, 1
  store i8 %3496, i8* %53, align 1, !tbaa !2451
  %3497 = zext i1 %3485 to i8
  store i8 %3497, i8* %54, align 1, !tbaa !2448
  %3498 = lshr i32 %3482, 31
  %3499 = trunc i32 %3498 to i8
  store i8 %3499, i8* %55, align 1, !tbaa !2449
  %3500 = lshr i32 %3481, 31
  %3501 = xor i32 %3498, %3500
  %3502 = add nuw nsw i32 %3501, %3498
  %3503 = icmp eq i32 %3502, 2
  %3504 = zext i1 %3503 to i8
  store i8 %3504, i8* %56, align 1, !tbaa !2450
  %3505 = sext i32 %3482 to i64
  store i64 %3505, i64* %RSI, align 8, !tbaa !2428
  %3506 = shl nsw i64 %3505, 3
  %3507 = add i64 %3506, %3477
  %3508 = add i64 %3474, 18
  store i64 %3508, i64* %PC, align 8
  %3509 = inttoptr i64 %3507 to i64*
  %3510 = load i64, i64* %3509, align 8
  %3511 = load i64, i64* %RAX, align 8
  %3512 = xor i64 %3511, %3510
  store i64 %3512, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %3513 = trunc i64 %3512 to i32
  %3514 = and i32 %3513, 255
  %3515 = tail call i32 @llvm.ctpop.i32(i32 %3514) #10
  %3516 = trunc i32 %3515 to i8
  %3517 = and i8 %3516, 1
  %3518 = xor i8 %3517, 1
  store i8 %3518, i8* %52, align 1, !tbaa !2447
  %3519 = icmp eq i64 %3512, 0
  %3520 = zext i1 %3519 to i8
  store i8 %3520, i8* %54, align 1, !tbaa !2448
  %3521 = lshr i64 %3512, 63
  %3522 = trunc i64 %3521 to i8
  store i8 %3522, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %3512, i64* %3753, align 1, !tbaa !2428
  store i64 0, i64* %3740, align 1, !tbaa !2428
  %3523 = add i64 %3472, -88
  %3524 = add i64 %3474, 36
  store i64 %3524, i64* %PC, align 8
  %3525 = inttoptr i64 %3523 to i64*
  store i64 %3512, i64* %3525, align 8
  %3526 = load i64, i64* %RBP, align 8
  %3527 = add i64 %3526, -80
  %3528 = load i64, i64* %PC, align 8
  %3529 = add i64 %3528, 5
  store i64 %3529, i64* %PC, align 8
  %3530 = inttoptr i64 %3527 to i64*
  %3531 = load i64, i64* %3530, align 8
  store i64 %3531, i64* %3753, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3741, align 1, !tbaa !2452
  %3532 = add i64 %3526, -24
  %3533 = add i64 %3528, 9
  store i64 %3533, i64* %PC, align 8
  %3534 = inttoptr i64 %3532 to i64*
  %3535 = load i64, i64* %3534, align 8
  store i64 %3535, i64* %RAX, align 8, !tbaa !2428
  %3536 = add i64 %3526, -32
  %3537 = add i64 %3528, 13
  store i64 %3537, i64* %PC, align 8
  %3538 = inttoptr i64 %3536 to i32*
  %3539 = load i32, i32* %3538, align 4
  %3540 = sext i32 %3539 to i64
  store i64 %3540, i64* %RDX, align 8, !tbaa !2428
  %3541 = shl nsw i64 %3540, 3
  %3542 = add i64 %3541, %3535
  %3543 = add i64 %3528, 18
  store i64 %3543, i64* %PC, align 8
  %3544 = inttoptr i64 %3542 to i64*
  store i64 %3531, i64* %3544, align 8
  %3545 = load i64, i64* %RBP, align 8
  %3546 = add i64 %3545, -88
  %3547 = load i64, i64* %PC, align 8
  %3548 = add i64 %3547, 5
  store i64 %3548, i64* %PC, align 8
  %3549 = inttoptr i64 %3546 to i64*
  %3550 = load i64, i64* %3549, align 8
  store i64 %3550, i64* %3753, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3741, align 1, !tbaa !2452
  %3551 = add i64 %3545, -24
  %3552 = add i64 %3547, 9
  store i64 %3552, i64* %PC, align 8
  %3553 = inttoptr i64 %3551 to i64*
  %3554 = load i64, i64* %3553, align 8
  store i64 %3554, i64* %RAX, align 8, !tbaa !2428
  %3555 = add i64 %3545, -32
  %3556 = add i64 %3547, 12
  store i64 %3556, i64* %PC, align 8
  %3557 = inttoptr i64 %3555 to i32*
  %3558 = load i32, i32* %3557, align 4
  %3559 = add i32 %3558, 1
  %3560 = zext i32 %3559 to i64
  store i64 %3560, i64* %RCX, align 8, !tbaa !2428
  %3561 = icmp eq i32 %3558, -1
  %3562 = icmp eq i32 %3559, 0
  %3563 = or i1 %3561, %3562
  %3564 = zext i1 %3563 to i8
  store i8 %3564, i8* %51, align 1, !tbaa !2433
  %3565 = and i32 %3559, 255
  %3566 = tail call i32 @llvm.ctpop.i32(i32 %3565) #10
  %3567 = trunc i32 %3566 to i8
  %3568 = and i8 %3567, 1
  %3569 = xor i8 %3568, 1
  store i8 %3569, i8* %52, align 1, !tbaa !2447
  %3570 = xor i32 %3558, %3559
  %3571 = lshr i32 %3570, 4
  %3572 = trunc i32 %3571 to i8
  %3573 = and i8 %3572, 1
  store i8 %3573, i8* %53, align 1, !tbaa !2451
  %3574 = zext i1 %3562 to i8
  store i8 %3574, i8* %54, align 1, !tbaa !2448
  %3575 = lshr i32 %3559, 31
  %3576 = trunc i32 %3575 to i8
  store i8 %3576, i8* %55, align 1, !tbaa !2449
  %3577 = lshr i32 %3558, 31
  %3578 = xor i32 %3575, %3577
  %3579 = add nuw nsw i32 %3578, %3575
  %3580 = icmp eq i32 %3579, 2
  %3581 = zext i1 %3580 to i8
  store i8 %3581, i8* %56, align 1, !tbaa !2450
  %3582 = sext i32 %3559 to i64
  store i64 %3582, i64* %RDX, align 8, !tbaa !2428
  %3583 = shl nsw i64 %3582, 3
  %3584 = add i64 %3583, %3554
  %3585 = add i64 %3547, 23
  store i64 %3585, i64* %PC, align 8
  %3586 = inttoptr i64 %3584 to i64*
  store i64 %3550, i64* %3586, align 8
  %3587 = load i64, i64* %RBP, align 8
  %3588 = add i64 %3587, -64
  %3589 = load i64, i64* %PC, align 8
  %3590 = add i64 %3589, 5
  store i64 %3590, i64* %PC, align 8
  %3591 = inttoptr i64 %3588 to i64*
  %3592 = load i64, i64* %3591, align 8
  store i64 %3592, i64* %3753, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3741, align 1, !tbaa !2452
  %3593 = add i64 %3587, -24
  %3594 = add i64 %3589, 9
  store i64 %3594, i64* %PC, align 8
  %3595 = inttoptr i64 %3593 to i64*
  %3596 = load i64, i64* %3595, align 8
  store i64 %3596, i64* %RAX, align 8, !tbaa !2428
  %3597 = add i64 %3587, -40
  %3598 = add i64 %3589, 13
  store i64 %3598, i64* %PC, align 8
  %3599 = inttoptr i64 %3597 to i32*
  %3600 = load i32, i32* %3599, align 4
  %3601 = sext i32 %3600 to i64
  store i64 %3601, i64* %RDX, align 8, !tbaa !2428
  %3602 = shl nsw i64 %3601, 3
  %3603 = add i64 %3602, %3596
  %3604 = add i64 %3589, 18
  store i64 %3604, i64* %PC, align 8
  %3605 = inttoptr i64 %3603 to i64*
  store i64 %3592, i64* %3605, align 8
  %3606 = load i64, i64* %RBP, align 8
  %3607 = add i64 %3606, -72
  %3608 = load i64, i64* %PC, align 8
  %3609 = add i64 %3608, 5
  store i64 %3609, i64* %PC, align 8
  %3610 = inttoptr i64 %3607 to i64*
  %3611 = load i64, i64* %3610, align 8
  store i64 %3611, i64* %3753, align 1, !tbaa !2452
  store double 0.000000e+00, double* %3741, align 1, !tbaa !2452
  %3612 = add i64 %3606, -24
  %3613 = add i64 %3608, 9
  store i64 %3613, i64* %PC, align 8
  %3614 = inttoptr i64 %3612 to i64*
  %3615 = load i64, i64* %3614, align 8
  store i64 %3615, i64* %RAX, align 8, !tbaa !2428
  %3616 = add i64 %3606, -40
  %3617 = add i64 %3608, 12
  store i64 %3617, i64* %PC, align 8
  %3618 = inttoptr i64 %3616 to i32*
  %3619 = load i32, i32* %3618, align 4
  %3620 = add i32 %3619, 1
  %3621 = zext i32 %3620 to i64
  store i64 %3621, i64* %RCX, align 8, !tbaa !2428
  %3622 = icmp eq i32 %3619, -1
  %3623 = icmp eq i32 %3620, 0
  %3624 = or i1 %3622, %3623
  %3625 = zext i1 %3624 to i8
  store i8 %3625, i8* %51, align 1, !tbaa !2433
  %3626 = and i32 %3620, 255
  %3627 = tail call i32 @llvm.ctpop.i32(i32 %3626) #10
  %3628 = trunc i32 %3627 to i8
  %3629 = and i8 %3628, 1
  %3630 = xor i8 %3629, 1
  store i8 %3630, i8* %52, align 1, !tbaa !2447
  %3631 = xor i32 %3619, %3620
  %3632 = lshr i32 %3631, 4
  %3633 = trunc i32 %3632 to i8
  %3634 = and i8 %3633, 1
  store i8 %3634, i8* %53, align 1, !tbaa !2451
  %3635 = zext i1 %3623 to i8
  store i8 %3635, i8* %54, align 1, !tbaa !2448
  %3636 = lshr i32 %3620, 31
  %3637 = trunc i32 %3636 to i8
  store i8 %3637, i8* %55, align 1, !tbaa !2449
  %3638 = lshr i32 %3619, 31
  %3639 = xor i32 %3636, %3638
  %3640 = add nuw nsw i32 %3639, %3636
  %3641 = icmp eq i32 %3640, 2
  %3642 = zext i1 %3641 to i8
  store i8 %3642, i8* %56, align 1, !tbaa !2450
  %3643 = sext i32 %3620 to i64
  store i64 %3643, i64* %RDX, align 8, !tbaa !2428
  %3644 = shl nsw i64 %3643, 3
  %3645 = add i64 %3644, %3615
  %3646 = add i64 %3608, 23
  store i64 %3646, i64* %PC, align 8
  %3647 = inttoptr i64 %3645 to i64*
  store i64 %3611, i64* %3647, align 8
  %3648 = load i64, i64* %RBP, align 8
  %3649 = add i64 %3648, -28
  %3650 = load i64, i64* %PC, align 8
  %3651 = add i64 %3650, 3
  store i64 %3651, i64* %PC, align 8
  %3652 = inttoptr i64 %3649 to i32*
  %3653 = load i32, i32* %3652, align 4
  %3654 = add i32 %3653, 1
  %3655 = zext i32 %3654 to i64
  store i64 %3655, i64* %RAX, align 8, !tbaa !2428
  %3656 = icmp eq i32 %3653, -1
  %3657 = icmp eq i32 %3654, 0
  %3658 = or i1 %3656, %3657
  %3659 = zext i1 %3658 to i8
  store i8 %3659, i8* %51, align 1, !tbaa !2433
  %3660 = and i32 %3654, 255
  %3661 = tail call i32 @llvm.ctpop.i32(i32 %3660) #10
  %3662 = trunc i32 %3661 to i8
  %3663 = and i8 %3662, 1
  %3664 = xor i8 %3663, 1
  store i8 %3664, i8* %52, align 1, !tbaa !2447
  %3665 = xor i32 %3653, %3654
  %3666 = lshr i32 %3665, 4
  %3667 = trunc i32 %3666 to i8
  %3668 = and i8 %3667, 1
  store i8 %3668, i8* %53, align 1, !tbaa !2451
  %3669 = zext i1 %3657 to i8
  store i8 %3669, i8* %54, align 1, !tbaa !2448
  %3670 = lshr i32 %3654, 31
  %3671 = trunc i32 %3670 to i8
  store i8 %3671, i8* %55, align 1, !tbaa !2449
  %3672 = lshr i32 %3653, 31
  %3673 = xor i32 %3670, %3672
  %3674 = add nuw nsw i32 %3673, %3670
  %3675 = icmp eq i32 %3674, 2
  %3676 = zext i1 %3675 to i8
  store i8 %3676, i8* %56, align 1, !tbaa !2450
  %3677 = add i64 %3650, 9
  store i64 %3677, i64* %PC, align 8
  store i32 %3654, i32* %3652, align 4
  %3678 = load i64, i64* %PC, align 8
  %3679 = add i64 %3678, -469
  store i64 %3679, i64* %PC, align 8, !tbaa !2428
  br label %block_4021ff

block_401c06:                                     ; preds = %block_401c5d, %block_401be0
  %3680 = phi i64 [ %191, %block_401c5d ], [ %.pre, %block_401be0 ]
  %3681 = load i64, i64* %RBP, align 8
  %3682 = add i64 %3681, -48
  %3683 = add i64 %3680, 3
  store i64 %3683, i64* %PC, align 8
  %3684 = inttoptr i64 %3682 to i32*
  %3685 = load i32, i32* %3684, align 4
  %3686 = shl i32 %3685, 3
  %3687 = zext i32 %3686 to i64
  store i64 %3687, i64* %RAX, align 8, !tbaa !2428
  %3688 = lshr i32 %3685, 29
  %3689 = trunc i32 %3688 to i8
  %3690 = and i8 %3689, 1
  store i8 %3690, i8* %51, align 1, !tbaa !2432
  %3691 = and i32 %3686, 248
  %3692 = tail call i32 @llvm.ctpop.i32(i32 %3691) #10
  %3693 = trunc i32 %3692 to i8
  %3694 = and i8 %3693, 1
  %3695 = xor i8 %3694, 1
  store i8 %3695, i8* %52, align 1, !tbaa !2432
  store i8 0, i8* %53, align 1, !tbaa !2432
  %3696 = icmp eq i32 %3686, 0
  %3697 = zext i1 %3696 to i8
  store i8 %3697, i8* %54, align 1, !tbaa !2432
  %3698 = lshr i32 %3685, 28
  %3699 = and i32 %3698, 1
  %3700 = trunc i32 %3699 to i8
  store i8 %3700, i8* %55, align 1, !tbaa !2432
  store i8 0, i8* %56, align 1, !tbaa !2432
  %3701 = add i64 %3681, -44
  %3702 = add i64 %3680, 9
  store i64 %3702, i64* %PC, align 8
  %3703 = inttoptr i64 %3701 to i32*
  %3704 = load i32, i32* %3703, align 4
  %3705 = sub i32 %3686, %3704
  %3706 = icmp ult i32 %3686, %3704
  %3707 = zext i1 %3706 to i8
  store i8 %3707, i8* %51, align 1, !tbaa !2433
  %3708 = and i32 %3705, 255
  %3709 = tail call i32 @llvm.ctpop.i32(i32 %3708) #10
  %3710 = trunc i32 %3709 to i8
  %3711 = and i8 %3710, 1
  %3712 = xor i8 %3711, 1
  store i8 %3712, i8* %52, align 1, !tbaa !2447
  %3713 = xor i32 %3704, %3686
  %3714 = xor i32 %3713, %3705
  %3715 = lshr i32 %3714, 4
  %3716 = trunc i32 %3715 to i8
  %3717 = and i8 %3716, 1
  store i8 %3717, i8* %53, align 1, !tbaa !2451
  %3718 = icmp eq i32 %3705, 0
  %3719 = zext i1 %3718 to i8
  store i8 %3719, i8* %54, align 1, !tbaa !2448
  %3720 = lshr i32 %3705, 31
  %3721 = trunc i32 %3720 to i8
  store i8 %3721, i8* %55, align 1, !tbaa !2449
  %3722 = lshr i32 %3704, 31
  %3723 = xor i32 %3722, %3699
  %3724 = xor i32 %3720, %3699
  %3725 = add nuw nsw i32 %3724, %3723
  %3726 = icmp eq i32 %3725, 2
  %3727 = zext i1 %3726 to i8
  store i8 %3727, i8* %56, align 1, !tbaa !2450
  %3728 = icmp ne i8 %3721, 0
  %3729 = xor i1 %3728, %3726
  %.v = select i1 %3729, i64 15, i64 101
  %3730 = add i64 %3680, %.v
  %3731 = add i64 %3730, 3
  store i64 %3731, i64* %PC, align 8
  br i1 %3729, label %block_401c15, label %block_401c6b

block_40218b:                                     ; preds = %block_401c6b
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %3732 = add i64 %121, -24
  %3733 = add i64 %169, 14
  store i64 %3733, i64* %PC, align 8
  %3734 = inttoptr i64 %3732 to i64*
  %3735 = load i64, i64* %3734, align 8
  store i64 %3735, i64* %RCX, align 8, !tbaa !2428
  %3736 = add i64 %3735, 8
  %3737 = add i64 %169, 19
  store i64 %3737, i64* %PC, align 8
  %3738 = inttoptr i64 %3736 to i64*
  %3739 = load i64, i64* %3738, align 8
  %3740 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %3741 = bitcast i64* %3740 to double*
  %3742 = xor i64 %3739, -9223372036854775808
  store i64 %3742, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %3743 = trunc i64 %3739 to i32
  %3744 = and i32 %3743, 255
  %3745 = tail call i32 @llvm.ctpop.i32(i32 %3744) #10
  %3746 = trunc i32 %3745 to i8
  %3747 = and i8 %3746, 1
  %3748 = xor i8 %3747, 1
  store i8 %3748, i8* %52, align 1, !tbaa !2447
  %3749 = icmp eq i64 %3742, 0
  %3750 = zext i1 %3749 to i8
  store i8 %3750, i8* %54, align 1, !tbaa !2448
  %3751 = lshr i64 %3742, 63
  %3752 = trunc i64 %3751 to i8
  store i8 %3752, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  %3753 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %3742, i64* %3753, align 1, !tbaa !2428
  store i64 0, i64* %3740, align 1, !tbaa !2428
  %3754 = add i64 %169, 36
  store i64 %3754, i64* %PC, align 8
  %3755 = load i64, i64* %3734, align 8
  store i64 %3755, i64* %RCX, align 8, !tbaa !2428
  %3756 = add i64 %3755, 8
  %3757 = add i64 %169, 41
  store i64 %3757, i64* %PC, align 8
  %3758 = inttoptr i64 %3756 to i64*
  store i64 %3742, i64* %3758, align 8
  %3759 = load i64, i64* %RBP, align 8
  %3760 = add i64 %3759, -24
  %3761 = load i64, i64* %PC, align 8
  %3762 = add i64 %3761, 4
  store i64 %3762, i64* %PC, align 8
  %3763 = inttoptr i64 %3760 to i64*
  %3764 = load i64, i64* %3763, align 8
  store i64 %3764, i64* %RCX, align 8, !tbaa !2428
  %3765 = add i64 %3759, -52
  %3766 = add i64 %3761, 7
  store i64 %3766, i64* %PC, align 8
  %3767 = inttoptr i64 %3765 to i32*
  %3768 = load i32, i32* %3767, align 4
  %3769 = add i32 %3768, 1
  %3770 = zext i32 %3769 to i64
  store i64 %3770, i64* %RDX, align 8, !tbaa !2428
  %3771 = icmp eq i32 %3768, -1
  %3772 = icmp eq i32 %3769, 0
  %3773 = or i1 %3771, %3772
  %3774 = zext i1 %3773 to i8
  store i8 %3774, i8* %51, align 1, !tbaa !2433
  %3775 = and i32 %3769, 255
  %3776 = tail call i32 @llvm.ctpop.i32(i32 %3775) #10
  %3777 = trunc i32 %3776 to i8
  %3778 = and i8 %3777, 1
  %3779 = xor i8 %3778, 1
  store i8 %3779, i8* %52, align 1, !tbaa !2447
  %3780 = xor i32 %3768, %3769
  %3781 = lshr i32 %3780, 4
  %3782 = trunc i32 %3781 to i8
  %3783 = and i8 %3782, 1
  store i8 %3783, i8* %53, align 1, !tbaa !2451
  %3784 = zext i1 %3772 to i8
  store i8 %3784, i8* %54, align 1, !tbaa !2448
  %3785 = lshr i32 %3769, 31
  %3786 = trunc i32 %3785 to i8
  store i8 %3786, i8* %55, align 1, !tbaa !2449
  %3787 = lshr i32 %3768, 31
  %3788 = xor i32 %3785, %3787
  %3789 = add nuw nsw i32 %3788, %3785
  %3790 = icmp eq i32 %3789, 2
  %3791 = zext i1 %3790 to i8
  store i8 %3791, i8* %56, align 1, !tbaa !2450
  %3792 = sext i32 %3769 to i64
  store i64 %3792, i64* %RSI, align 8, !tbaa !2428
  %3793 = shl nsw i64 %3792, 3
  %3794 = add i64 %3793, %3764
  %3795 = add i64 %3761, 18
  store i64 %3795, i64* %PC, align 8
  %3796 = inttoptr i64 %3794 to i64*
  %3797 = load i64, i64* %3796, align 8
  %3798 = load i64, i64* %RAX, align 8
  %3799 = xor i64 %3798, %3797
  store i64 %3799, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %51, align 1, !tbaa !2433
  %3800 = trunc i64 %3799 to i32
  %3801 = and i32 %3800, 255
  %3802 = tail call i32 @llvm.ctpop.i32(i32 %3801) #10
  %3803 = trunc i32 %3802 to i8
  %3804 = and i8 %3803, 1
  %3805 = xor i8 %3804, 1
  store i8 %3805, i8* %52, align 1, !tbaa !2447
  %3806 = icmp eq i64 %3799, 0
  %3807 = zext i1 %3806 to i8
  store i8 %3807, i8* %54, align 1, !tbaa !2448
  %3808 = lshr i64 %3799, 63
  %3809 = trunc i64 %3808 to i8
  store i8 %3809, i8* %55, align 1, !tbaa !2449
  store i8 0, i8* %56, align 1, !tbaa !2450
  store i8 0, i8* %53, align 1, !tbaa !2451
  store i64 %3799, i64* %3753, align 1, !tbaa !2428
  store i64 0, i64* %3740, align 1, !tbaa !2428
  %3810 = add i64 %3761, 35
  store i64 %3810, i64* %PC, align 8
  %3811 = load i64, i64* %3763, align 8
  store i64 %3811, i64* %RAX, align 8, !tbaa !2428
  %3812 = add i64 %3761, 38
  store i64 %3812, i64* %PC, align 8
  %3813 = load i32, i32* %3767, align 4
  %3814 = add i32 %3813, 1
  %3815 = zext i32 %3814 to i64
  store i64 %3815, i64* %RDX, align 8, !tbaa !2428
  %3816 = icmp eq i32 %3813, -1
  %3817 = icmp eq i32 %3814, 0
  %3818 = or i1 %3816, %3817
  %3819 = zext i1 %3818 to i8
  store i8 %3819, i8* %51, align 1, !tbaa !2433
  %3820 = and i32 %3814, 255
  %3821 = tail call i32 @llvm.ctpop.i32(i32 %3820) #10
  %3822 = trunc i32 %3821 to i8
  %3823 = and i8 %3822, 1
  %3824 = xor i8 %3823, 1
  store i8 %3824, i8* %52, align 1, !tbaa !2447
  %3825 = xor i32 %3813, %3814
  %3826 = lshr i32 %3825, 4
  %3827 = trunc i32 %3826 to i8
  %3828 = and i8 %3827, 1
  store i8 %3828, i8* %53, align 1, !tbaa !2451
  %3829 = zext i1 %3817 to i8
  store i8 %3829, i8* %54, align 1, !tbaa !2448
  %3830 = lshr i32 %3814, 31
  %3831 = trunc i32 %3830 to i8
  store i8 %3831, i8* %55, align 1, !tbaa !2449
  %3832 = lshr i32 %3813, 31
  %3833 = xor i32 %3830, %3832
  %3834 = add nuw nsw i32 %3833, %3830
  %3835 = icmp eq i32 %3834, 2
  %3836 = zext i1 %3835 to i8
  store i8 %3836, i8* %56, align 1, !tbaa !2450
  %3837 = sext i32 %3814 to i64
  store i64 %3837, i64* %RCX, align 8, !tbaa !2428
  %3838 = shl nsw i64 %3837, 3
  %3839 = add i64 %3838, %3811
  %3840 = add i64 %3761, 49
  store i64 %3840, i64* %PC, align 8
  %3841 = inttoptr i64 %3839 to i64*
  store i64 %3799, i64* %3841, align 8
  %3842 = load i64, i64* %RBP, align 8
  %3843 = add i64 %3842, -36
  %3844 = load i64, i64* %PC, align 8
  %3845 = add i64 %3844, 7
  store i64 %3845, i64* %PC, align 8
  %3846 = inttoptr i64 %3843 to i32*
  store i32 1, i32* %3846, align 4
  %.pre7 = load i64, i64* %PC, align 8
  br label %block_4021ec

block_401c83:                                     ; preds = %block_401c6b
  %3847 = add i64 %121, -36
  %3848 = add i64 %169, 7
  store i64 %3848, i64* %PC, align 8
  %3849 = inttoptr i64 %3847 to i32*
  store i32 0, i32* %3849, align 4
  %3850 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %3851 = bitcast i64* %3850 to double*
  %3852 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  %.pre5 = load i64, i64* %PC, align 8
  br label %block_401c8a
}

; Function Attrs: noinline
define %struct.Memory* @sub_4010d0_errorcheck(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_4010d0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %5 to i32*
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %6 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %6, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %10 = load i64, i64* %RBP, align 8
  %11 = add i64 %1, 1
  store i64 %11, i64* %PC, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %13 = load i64, i64* %12, align 8, !tbaa !2428
  %14 = add i64 %13, -8
  %15 = inttoptr i64 %14 to i64*
  store i64 %10, i64* %15, align 8
  store i64 %14, i64* %12, align 8, !tbaa !2428
  %16 = load i64, i64* %PC, align 8
  store i64 %14, i64* %RBP, align 8, !tbaa !2428
  %17 = bitcast %union.VectorReg* %8 to i8*
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %19 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %8, i64 0, i32 0, i32 0, i32 0, i64 0
  %20 = bitcast %union.VectorReg* %8 to i32*
  store i32 0, i32* %20, align 1, !tbaa !2459
  %21 = getelementptr inbounds i8, i8* %17, i64 4
  %22 = bitcast i8* %21 to i32*
  store i32 0, i32* %22, align 1, !tbaa !2459
  %23 = bitcast i64* %18 to i32*
  store i32 0, i32* %23, align 1, !tbaa !2459
  %24 = getelementptr inbounds i8, i8* %17, i64 12
  %25 = bitcast i8* %24 to i32*
  store i32 0, i32* %25, align 1, !tbaa !2459
  %26 = add i64 %13, -12
  %27 = load i32, i32* %EDI, align 4
  %28 = add i64 %16, 9
  store i64 %28, i64* %PC, align 8
  %29 = inttoptr i64 %26 to i32*
  store i32 %27, i32* %29, align 4
  %30 = load i64, i64* %RBP, align 8
  %31 = add i64 %30, -8
  %32 = load i32, i32* %ESI, align 4
  %33 = load i64, i64* %PC, align 8
  %34 = add i64 %33, 3
  store i64 %34, i64* %PC, align 8
  %35 = inttoptr i64 %31 to i32*
  store i32 %32, i32* %35, align 4
  %36 = load i64, i64* %RBP, align 8
  %37 = add i64 %36, -16
  %38 = load i64, i64* %PC, align 8
  %39 = add i64 %38, 5
  store i64 %39, i64* %PC, align 8
  %40 = bitcast [32 x %union.VectorReg]* %7 to double*
  %41 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %42 = load i64, i64* %41, align 1
  %43 = inttoptr i64 %37 to i64*
  store i64 %42, i64* %43, align 8
  %44 = load i64, i64* %RBP, align 8
  %45 = add i64 %44, -24
  %46 = load i64, i64* %RDX, align 8
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 4
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %45 to i64*
  store i64 %46, i64* %49, align 8
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -32
  %52 = load i64, i64* %PC, align 8
  %53 = add i64 %52, 7
  store i64 %53, i64* %PC, align 8
  %54 = inttoptr i64 %51 to i32*
  store i32 0, i32* %54, align 4
  %55 = load i64, i64* %RBP, align 8
  %56 = add i64 %55, -40
  %57 = load i64, i64* %PC, align 8
  %58 = add i64 %57, 5
  store i64 %58, i64* %PC, align 8
  %59 = bitcast %union.VectorReg* %8 to double*
  %60 = load i64, i64* %19, align 1
  %61 = inttoptr i64 %56 to i64*
  store i64 %60, i64* %61, align 8
  %62 = load i64, i64* %RBP, align 8
  %63 = add i64 %62, -4
  %64 = load i64, i64* %PC, align 8
  %65 = add i64 %64, 3
  store i64 %65, i64* %PC, align 8
  %66 = inttoptr i64 %63 to i32*
  %67 = load i32, i32* %66, align 4
  %68 = zext i32 %67 to i64
  store i64 %68, i64* %RSI, align 8, !tbaa !2428
  %69 = add i64 %62, -28
  %70 = add i64 %64, 6
  store i64 %70, i64* %PC, align 8
  %71 = inttoptr i64 %69 to i32*
  store i32 %67, i32* %71, align 4
  %72 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %73 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %74 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %75 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %76 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %77 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %78 = bitcast [32 x %union.VectorReg]* %7 to i8*
  %79 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %80 = bitcast i64* %79 to double*
  %81 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %82 = bitcast %union.VectorReg* %9 to i8*
  %83 = getelementptr inbounds i8, i8* %82, i64 4
  %84 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %85 = getelementptr inbounds i8, i8* %82, i64 12
  %86 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %9, i64 0, i32 0, i32 0, i32 0, i64 0
  %87 = bitcast [32 x %union.VectorReg]* %7 to i32*
  %88 = getelementptr inbounds i8, i8* %78, i64 4
  %89 = bitcast i8* %88 to i32*
  %90 = bitcast i64* %79 to i32*
  %91 = getelementptr inbounds i8, i8* %78, i64 12
  %92 = bitcast i8* %91 to i32*
  %.pre = load i64, i64* %PC, align 8
  br label %block_4010f8

block_4010f8:                                     ; preds = %block_401192, %block_4010d0
  %93 = phi i64 [ %.pre, %block_4010d0 ], [ %171, %block_401192 ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_4010d0 ], [ %356, %block_401192 ]
  %94 = load i64, i64* %RBP, align 8
  %95 = add i64 %94, -28
  %96 = add i64 %93, 3
  store i64 %96, i64* %PC, align 8
  %97 = inttoptr i64 %95 to i32*
  %98 = load i32, i32* %97, align 4
  %99 = zext i32 %98 to i64
  store i64 %99, i64* %RAX, align 8, !tbaa !2428
  %100 = add i64 %94, -8
  %101 = add i64 %93, 6
  store i64 %101, i64* %PC, align 8
  %102 = inttoptr i64 %100 to i32*
  %103 = load i32, i32* %102, align 4
  %104 = sub i32 %98, %103
  %105 = icmp ult i32 %98, %103
  %106 = zext i1 %105 to i8
  store i8 %106, i8* %72, align 1, !tbaa !2433
  %107 = and i32 %104, 255
  %108 = tail call i32 @llvm.ctpop.i32(i32 %107) #10
  %109 = trunc i32 %108 to i8
  %110 = and i8 %109, 1
  %111 = xor i8 %110, 1
  store i8 %111, i8* %73, align 1, !tbaa !2447
  %112 = xor i32 %103, %98
  %113 = xor i32 %112, %104
  %114 = lshr i32 %113, 4
  %115 = trunc i32 %114 to i8
  %116 = and i8 %115, 1
  store i8 %116, i8* %74, align 1, !tbaa !2451
  %117 = icmp eq i32 %104, 0
  %118 = zext i1 %117 to i8
  store i8 %118, i8* %75, align 1, !tbaa !2448
  %119 = lshr i32 %104, 31
  %120 = trunc i32 %119 to i8
  store i8 %120, i8* %76, align 1, !tbaa !2449
  %121 = lshr i32 %98, 31
  %122 = lshr i32 %103, 31
  %123 = xor i32 %122, %121
  %124 = xor i32 %119, %121
  %125 = add nuw nsw i32 %124, %123
  %126 = icmp eq i32 %125, 2
  %127 = zext i1 %126 to i8
  store i8 %127, i8* %77, align 1, !tbaa !2450
  %128 = icmp ne i8 %120, 0
  %129 = xor i1 %128, %126
  %.demorgan = or i1 %117, %129
  %.v = select i1 %.demorgan, i64 12, i64 178
  %130 = add i64 %93, %.v
  store i64 %130, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan, label %block_401104, label %block_4011aa

block_401192:                                     ; preds = %block_40117d, %block_40116e
  %131 = phi i64 [ %.pre6, %block_40117d ], [ %180, %block_40116e ]
  %132 = load i64, i64* %RBP, align 8
  %133 = add i64 %132, -64
  %134 = add i64 %131, 5
  store i64 %134, i64* %PC, align 8
  %135 = inttoptr i64 %133 to i64*
  %136 = load i64, i64* %135, align 8
  store i64 %136, i64* %41, align 1, !tbaa !2452
  store double 0.000000e+00, double* %80, align 1, !tbaa !2452
  %137 = add i64 %132, -40
  %138 = add i64 %131, 10
  store i64 %138, i64* %PC, align 8
  %139 = inttoptr i64 %137 to i64*
  store i64 %136, i64* %139, align 8
  %140 = load i64, i64* %RBP, align 8
  %141 = add i64 %140, -28
  %142 = load i64, i64* %PC, align 8
  %143 = add i64 %142, 3
  store i64 %143, i64* %PC, align 8
  %144 = inttoptr i64 %141 to i32*
  %145 = load i32, i32* %144, align 4
  %146 = add i32 %145, 1
  %147 = zext i32 %146 to i64
  store i64 %147, i64* %RAX, align 8, !tbaa !2428
  %148 = icmp eq i32 %145, -1
  %149 = icmp eq i32 %146, 0
  %150 = or i1 %148, %149
  %151 = zext i1 %150 to i8
  store i8 %151, i8* %72, align 1, !tbaa !2433
  %152 = and i32 %146, 255
  %153 = tail call i32 @llvm.ctpop.i32(i32 %152) #10
  %154 = trunc i32 %153 to i8
  %155 = and i8 %154, 1
  %156 = xor i8 %155, 1
  store i8 %156, i8* %73, align 1, !tbaa !2447
  %157 = xor i32 %145, %146
  %158 = lshr i32 %157, 4
  %159 = trunc i32 %158 to i8
  %160 = and i8 %159, 1
  store i8 %160, i8* %74, align 1, !tbaa !2451
  %161 = zext i1 %149 to i8
  store i8 %161, i8* %75, align 1, !tbaa !2448
  %162 = lshr i32 %146, 31
  %163 = trunc i32 %162 to i8
  store i8 %163, i8* %76, align 1, !tbaa !2449
  %164 = lshr i32 %145, 31
  %165 = xor i32 %162, %164
  %166 = add nuw nsw i32 %165, %162
  %167 = icmp eq i32 %166, 2
  %168 = zext i1 %167 to i8
  store i8 %168, i8* %77, align 1, !tbaa !2450
  %169 = add i64 %142, 9
  store i64 %169, i64* %PC, align 8
  store i32 %146, i32* %144, align 4
  %170 = load i64, i64* %PC, align 8
  %171 = add i64 %170, -173
  store i64 %171, i64* %PC, align 8, !tbaa !2428
  br label %block_4010f8

block_40116e:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %172 = add i64 %354, -40
  %173 = add i64 %361, 5
  store i64 %173, i64* %PC, align 8
  %174 = inttoptr i64 %172 to i64*
  %175 = load i64, i64* %174, align 8
  store i64 %175, i64* %41, align 1, !tbaa !2452
  store double 0.000000e+00, double* %80, align 1, !tbaa !2452
  %176 = add i64 %354, -64
  %177 = add i64 %361, 10
  store i64 %177, i64* %PC, align 8
  %178 = inttoptr i64 %176 to i64*
  store i64 %175, i64* %178, align 8
  %179 = load i64, i64* %PC, align 8
  %180 = add i64 %179, 26
  store i64 %180, i64* %PC, align 8, !tbaa !2428
  br label %block_401192

block_4011aa:                                     ; preds = %block_4010f8
  %181 = add i64 %94, -40
  %182 = add i64 %130, 5
  store i64 %182, i64* %PC, align 8
  %183 = inttoptr i64 %181 to i64*
  %184 = load i64, i64* %183, align 8
  store i64 %184, i64* %41, align 1, !tbaa !2452
  store double 0.000000e+00, double* %80, align 1, !tbaa !2452
  %185 = add i64 %130, 6
  store i64 %185, i64* %PC, align 8
  %186 = load i64, i64* %12, align 8, !tbaa !2428
  %187 = add i64 %186, 8
  %188 = inttoptr i64 %186 to i64*
  %189 = load i64, i64* %188, align 8
  store i64 %189, i64* %RBP, align 8, !tbaa !2428
  store i64 %187, i64* %12, align 8, !tbaa !2428
  %190 = add i64 %130, 7
  store i64 %190, i64* %PC, align 8
  %191 = inttoptr i64 %187 to i64*
  %192 = load i64, i64* %191, align 8
  store i64 %192, i64* %PC, align 8, !tbaa !2428
  %193 = add i64 %186, 16
  store i64 %193, i64* %12, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_40117d:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %194 = add i64 %354, -48
  %195 = add i64 %361, 5
  store i64 %195, i64* %PC, align 8
  %196 = inttoptr i64 %194 to i64*
  %197 = load i64, i64* %196, align 8
  %198 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 96) to i32*), align 16
  %199 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 100) to i32*), align 4
  %200 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 104) to i32*), align 8
  %201 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 108) to i32*), align 4
  store i32 %198, i32* %20, align 1, !tbaa !2475
  store i32 %199, i32* %22, align 1, !tbaa !2475
  store i32 %200, i32* %23, align 1, !tbaa !2475
  store i32 %201, i32* %25, align 1, !tbaa !2475
  %202 = load i64, i64* %19, align 1
  %203 = and i64 %202, %197
  %204 = trunc i64 %203 to i32
  %205 = lshr i64 %203, 32
  %206 = trunc i64 %205 to i32
  store i32 %204, i32* %87, align 1, !tbaa !2459
  store i32 %206, i32* %89, align 1, !tbaa !2459
  store i32 0, i32* %90, align 1, !tbaa !2459
  store i32 0, i32* %92, align 1, !tbaa !2459
  %207 = add i64 %354, -64
  %208 = add i64 %361, 21
  store i64 %208, i64* %PC, align 8
  %209 = load i64, i64* %41, align 1
  %210 = inttoptr i64 %207 to i64*
  store i64 %209, i64* %210, align 8
  %.pre6 = load i64, i64* %PC, align 8
  br label %block_401192

block_401104:                                     ; preds = %block_4010f8
  %211 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 72) to i64*), align 8
  store i64 %211, i64* %41, align 1, !tbaa !2452
  store double 0.000000e+00, double* %80, align 1, !tbaa !2452
  store i64 259200, i64* %RAX, align 8, !tbaa !2428
  %212 = add i64 %94, -32
  %213 = add i64 %130, 20
  store i64 %213, i64* %PC, align 8
  %214 = inttoptr i64 %212 to i32*
  %215 = load i32, i32* %214, align 4
  %216 = sext i32 %215 to i64
  %217 = mul nsw i64 %216, 7141
  %218 = trunc i64 %217 to i32
  %219 = add i32 %218, 54773
  %220 = zext i32 %219 to i64
  store i64 %220, i64* %RCX, align 8, !tbaa !2428
  %221 = icmp ugt i32 %218, -54774
  %222 = zext i1 %221 to i8
  store i8 %222, i8* %72, align 1, !tbaa !2433
  %223 = and i32 %219, 255
  %224 = tail call i32 @llvm.ctpop.i32(i32 %223) #10
  %225 = trunc i32 %224 to i8
  %226 = and i8 %225, 1
  %227 = xor i8 %226, 1
  store i8 %227, i8* %73, align 1, !tbaa !2447
  %228 = xor i32 %218, 16
  %229 = xor i32 %228, %219
  %230 = lshr i32 %229, 4
  %231 = trunc i32 %230 to i8
  %232 = and i8 %231, 1
  store i8 %232, i8* %74, align 1, !tbaa !2451
  %233 = icmp eq i32 %219, 0
  %234 = zext i1 %233 to i8
  store i8 %234, i8* %75, align 1, !tbaa !2448
  %235 = lshr i32 %219, 31
  %236 = trunc i32 %235 to i8
  store i8 %236, i8* %76, align 1, !tbaa !2449
  %237 = lshr i32 %218, 31
  %238 = xor i32 %235, %237
  %239 = add nuw nsw i32 %238, %235
  %240 = icmp eq i32 %239, 2
  %241 = zext i1 %240 to i8
  store i8 %241, i8* %77, align 1, !tbaa !2450
  %242 = add i64 %94, -52
  %243 = add i64 %130, 29
  store i64 %243, i64* %PC, align 8
  %244 = inttoptr i64 %242 to i32*
  store i32 259200, i32* %244, align 4
  %245 = load i32, i32* %ECX, align 4
  %246 = zext i32 %245 to i64
  %247 = load i64, i64* %PC, align 8
  store i64 %246, i64* %RAX, align 8, !tbaa !2428
  %248 = sext i32 %245 to i64
  %249 = lshr i64 %248, 32
  store i64 %249, i64* %81, align 8, !tbaa !2428
  %250 = load i64, i64* %RBP, align 8
  %251 = add i64 %250, -52
  %252 = add i64 %247, 6
  store i64 %252, i64* %PC, align 8
  %253 = inttoptr i64 %251 to i32*
  %254 = load i32, i32* %253, align 4
  %255 = zext i32 %254 to i64
  store i64 %255, i64* %RCX, align 8, !tbaa !2428
  %256 = add i64 %247, 8
  store i64 %256, i64* %PC, align 8
  %257 = sext i32 %254 to i64
  %258 = shl nuw i64 %249, 32
  %259 = or i64 %258, %246
  %260 = sdiv i64 %259, %257
  %261 = shl i64 %260, 32
  %262 = ashr exact i64 %261, 32
  %263 = icmp eq i64 %260, %262
  br i1 %263, label %266, label %264

; <label>:264:                                    ; preds = %block_401104
  %265 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %256, %struct.Memory* %MEMORY.0) #11
  %.pre1 = load i64, i64* %RBP, align 8
  %.pre2 = load i32, i32* %EDX, align 4
  %.pre3 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:266:                                    ; preds = %block_401104
  %267 = srem i64 %259, %257
  %268 = and i64 %260, 4294967295
  store i64 %268, i64* %RAX, align 8, !tbaa !2428
  %269 = and i64 %267, 4294967295
  store i64 %269, i64* %81, align 8, !tbaa !2428
  store i8 0, i8* %72, align 1, !tbaa !2433
  store i8 0, i8* %73, align 1, !tbaa !2447
  store i8 0, i8* %74, align 1, !tbaa !2451
  store i8 0, i8* %75, align 1, !tbaa !2448
  store i8 0, i8* %76, align 1, !tbaa !2449
  store i8 0, i8* %77, align 1, !tbaa !2450
  %270 = trunc i64 %267 to i32
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %266, %264
  %271 = phi i64 [ %.pre3, %264 ], [ %256, %266 ]
  %272 = phi i32 [ %.pre2, %264 ], [ %270, %266 ]
  %273 = phi i64 [ %.pre1, %264 ], [ %250, %266 ]
  %274 = phi %struct.Memory* [ %265, %264 ], [ %MEMORY.0, %266 ]
  %275 = add i64 %273, -32
  %276 = add i64 %271, 3
  store i64 %276, i64* %PC, align 8
  %277 = inttoptr i64 %275 to i32*
  store i32 %272, i32* %277, align 4
  %278 = load i32, i32* %EDX, align 4
  %279 = load i64, i64* %PC, align 8
  %280 = sitofp i32 %278 to double
  %281 = load double, double* %40, align 1
  %282 = fmul double %280, %281
  store double %282, double* %59, align 1, !tbaa !2452
  %283 = load i64, i64* %RBP, align 8
  %284 = add i64 %283, -24
  %285 = add i64 %279, 12
  store i64 %285, i64* %PC, align 8
  %286 = inttoptr i64 %284 to i64*
  %287 = load i64, i64* %286, align 8
  store i64 %287, i64* %RSI, align 8, !tbaa !2428
  %288 = add i64 %283, -28
  %289 = add i64 %279, 16
  store i64 %289, i64* %PC, align 8
  %290 = inttoptr i64 %288 to i32*
  %291 = load i32, i32* %290, align 4
  %292 = sext i32 %291 to i64
  store i64 %292, i64* %RDI, align 8, !tbaa !2428
  %293 = shl nsw i64 %292, 3
  %294 = add i64 %293, %287
  %295 = add i64 %279, 21
  store i64 %295, i64* %PC, align 8
  %296 = inttoptr i64 %294 to double*
  %297 = load double, double* %296, align 8
  store double %297, double* %40, align 1, !tbaa !2452
  store double 0.000000e+00, double* %80, align 1, !tbaa !2452
  %298 = add i64 %283, -16
  %299 = add i64 %279, 26
  store i64 %299, i64* %PC, align 8
  %300 = inttoptr i64 %298 to double*
  %301 = load double, double* %300, align 8
  %302 = fmul double %297, %301
  store double %302, double* %40, align 1, !tbaa !2452
  store i64 0, i64* %79, align 1, !tbaa !2452
  %303 = fsub double %282, %302
  store double %303, double* %59, align 1, !tbaa !2452
  %304 = add i64 %283, -48
  %305 = add i64 %279, 35
  store i64 %305, i64* %PC, align 8
  %306 = inttoptr i64 %304 to double*
  store double %303, double* %306, align 8
  %307 = load i64, i64* %RBP, align 8
  %308 = add i64 %307, -40
  %309 = load i64, i64* %PC, align 8
  %310 = add i64 %309, 5
  store i64 %310, i64* %PC, align 8
  %311 = inttoptr i64 %308 to double*
  %312 = load double, double* %311, align 8
  store double %312, double* %40, align 1, !tbaa !2452
  store double 0.000000e+00, double* %80, align 1, !tbaa !2452
  %313 = add i64 %307, -48
  %314 = add i64 %309, 10
  store i64 %314, i64* %PC, align 8
  %315 = inttoptr i64 %313 to i64*
  %316 = load i64, i64* %315, align 8
  %317 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 96) to i32*), align 16
  %318 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 100) to i32*), align 4
  %319 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 104) to i32*), align 8
  %320 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_404070__rodata_type* @seg_404070__rodata to i64), i64 108) to i32*), align 4
  %321 = bitcast %union.VectorReg* %9 to i32*
  store i32 %317, i32* %321, align 1, !tbaa !2475
  %322 = bitcast i8* %83 to i32*
  store i32 %318, i32* %322, align 1, !tbaa !2475
  %323 = bitcast i64* %84 to i32*
  store i32 %319, i32* %323, align 1, !tbaa !2475
  %324 = bitcast i8* %85 to i32*
  store i32 %320, i32* %324, align 1, !tbaa !2475
  %325 = load i64, i64* %86, align 1
  %326 = and i64 %325, %316
  %327 = trunc i64 %326 to i32
  %328 = lshr i64 %326, 32
  %329 = trunc i64 %328 to i32
  store i32 %327, i32* %20, align 1, !tbaa !2459
  store i32 %329, i32* %22, align 1, !tbaa !2459
  store i32 0, i32* %23, align 1, !tbaa !2459
  store i32 0, i32* %25, align 1, !tbaa !2459
  %330 = add i64 %309, 25
  store i64 %330, i64* %PC, align 8
  %331 = load double, double* %59, align 1
  %332 = fcmp uno double %312, %331
  br i1 %332, label %333, label %343

; <label>:333:                                    ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit
  %334 = fadd double %312, %331
  %335 = bitcast double %334 to i64
  %336 = and i64 %335, 9221120237041090560
  %337 = icmp eq i64 %336, 9218868437227405312
  %338 = and i64 %335, 2251799813685247
  %339 = icmp ne i64 %338, 0
  %340 = and i1 %337, %339
  br i1 %340, label %341, label %349

; <label>:341:                                    ; preds = %333
  %342 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %330, %struct.Memory* %274) #11
  %.pre4 = load i64, i64* %PC, align 8
  %.pre5 = load i64, i64* %RBP, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

; <label>:343:                                    ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit
  %344 = fcmp ogt double %312, %331
  br i1 %344, label %349, label %345

; <label>:345:                                    ; preds = %343
  %346 = fcmp olt double %312, %331
  br i1 %346, label %349, label %347

; <label>:347:                                    ; preds = %345
  %348 = fcmp oeq double %312, %331
  br i1 %348, label %349, label %353

; <label>:349:                                    ; preds = %347, %345, %343, %333
  %350 = phi i8 [ 0, %343 ], [ 0, %345 ], [ 1, %347 ], [ 1, %333 ]
  %351 = phi i8 [ 0, %343 ], [ 0, %345 ], [ 0, %347 ], [ 1, %333 ]
  %352 = phi i8 [ 0, %343 ], [ 1, %345 ], [ 0, %347 ], [ 1, %333 ]
  store i8 %350, i8* %75, align 1, !tbaa !2432
  store i8 %351, i8* %73, align 1, !tbaa !2432
  store i8 %352, i8* %72, align 1, !tbaa !2432
  br label %353

; <label>:353:                                    ; preds = %349, %347
  store i8 0, i8* %77, align 1, !tbaa !2432
  store i8 0, i8* %76, align 1, !tbaa !2432
  store i8 0, i8* %74, align 1, !tbaa !2432
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit: ; preds = %353, %341
  %354 = phi i64 [ %.pre5, %341 ], [ %307, %353 ]
  %355 = phi i64 [ %.pre4, %341 ], [ %330, %353 ]
  %356 = phi %struct.Memory* [ %342, %341 ], [ %274, %353 ]
  %357 = load i8, i8* %72, align 1, !tbaa !2433
  %358 = load i8, i8* %75, align 1, !tbaa !2448
  %359 = or i8 %358, %357
  %360 = icmp ne i8 %359, 0
  %.v7 = select i1 %360, i64 21, i64 6
  %361 = add i64 %355, %.v7
  store i64 %361, i64* %PC, align 8, !tbaa !2428
  br i1 %360, label %block_40117d, label %block_40116e
}

; Function Attrs: noinline
define %struct.Memory* @sub_400710__start(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400710:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  store i64 0, i64* %RBP, align 8, !tbaa !2428
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %3, align 1, !tbaa !2433
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %4, align 1, !tbaa !2447
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %5, align 1, !tbaa !2448
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %6, align 1, !tbaa !2449
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %7, align 1, !tbaa !2450
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %8, align 1, !tbaa !2451
  %9 = load i64, i64* %RDX, align 8
  store i64 %9, i64* %R9, align 8, !tbaa !2428
  %10 = add i64 %1, 6
  store i64 %10, i64* %PC, align 8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %12 = load i64, i64* %11, align 8, !tbaa !2428
  %13 = add i64 %12, 8
  %14 = inttoptr i64 %12 to i64*
  %15 = load i64, i64* %14, align 8
  store i64 %15, i64* %RSI, align 8, !tbaa !2428
  store i64 %13, i64* %RDX, align 8, !tbaa !2428
  %16 = and i64 %13, -16
  store i8 0, i8* %3, align 1, !tbaa !2433
  %17 = trunc i64 %13 to i32
  %18 = and i32 %17, 240
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18) #10
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  store i8 %22, i8* %4, align 1, !tbaa !2447
  %23 = icmp eq i64 %16, 0
  %24 = zext i1 %23 to i8
  store i8 %24, i8* %5, align 1, !tbaa !2448
  %25 = lshr i64 %13, 63
  %26 = trunc i64 %25 to i8
  store i8 %26, i8* %6, align 1, !tbaa !2449
  store i8 0, i8* %7, align 1, !tbaa !2450
  store i8 0, i8* %8, align 1, !tbaa !2451
  %27 = load i64, i64* %RAX, align 8
  %28 = add i64 %1, 14
  store i64 %28, i64* %PC, align 8
  %29 = add i64 %16, -8
  %30 = inttoptr i64 %29 to i64*
  store i64 %27, i64* %30, align 8
  %31 = load i64, i64* %PC, align 8
  %32 = add i64 %31, 1
  store i64 %32, i64* %PC, align 8
  %33 = add i64 %16, -16
  %34 = inttoptr i64 %33 to i64*
  store i64 %29, i64* %34, align 16
  %35 = load i64, i64* %PC, align 8
  store i64 ptrtoint (void ()* @callback_sub_404060___libc_csu_fini to i64), i64* %R8, align 8, !tbaa !2428
  store i64 ptrtoint (void ()* @callback_sub_403ff0___libc_csu_init to i64), i64* %RCX, align 8, !tbaa !2428
  store i64 ptrtoint (void ()* @main to i64), i64* %RDI, align 8, !tbaa !2428
  %36 = add i64 %35, 27
  %37 = add i64 %16, -24
  %38 = inttoptr i64 %37 to i64*
  store i64 %36, i64* %38, align 8
  store i64 %37, i64* %11, align 8, !tbaa !2428
  %39 = load i64, i64* getelementptr inbounds (%seg_604ff0__got_type, %seg_604ff0__got_type* @seg_604ff0__got, i64 0, i32 0), align 8
  store i64 %39, i64* %PC, align 8, !tbaa !2428
  %40 = tail call fastcc %struct.Memory* @ext_605120___libc_start_main(%struct.State* nonnull %0, %struct.Memory* %2)
  %41 = load i64, i64* %PC, align 8
  %42 = add i64 %41, 1
  store i64 %42, i64* %PC, align 8
  %43 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull %0, i64 %42, %struct.Memory* %40)
  ret %struct.Memory* %43
}

; Function Attrs: noinline
define %struct.Memory* @sub_4007f0_frame_dummy(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_4007f0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  store i64 %7, i64* %5, align 8, !tbaa !2428
  %9 = load i64, i64* %PC, align 8
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = load i64, i64* %8, align 8
  store i64 %11, i64* %RBP, align 8, !tbaa !2428
  store i64 %6, i64* %5, align 8, !tbaa !2428
  %12 = add i64 %9, -113
  store i64 %12, i64* %PC, align 8, !tbaa !2428
  %13 = tail call %struct.Memory* @sub_400780_register_tm_clones(%struct.State* nonnull %0, i64 %12, %struct.Memory* %2)
  ret %struct.Memory* %13
}

; Function Attrs: noinline
declare void @__mcsema_attach_call() #6

; Function Attrs: naked nobuiltin noinline
define internal void @callback_sub_4007f0_frame_dummy() #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x4007f0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @1, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @callback_sub_4007f0_frame_dummy_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_4007f0_frame_dummy(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define internal void @callback_sub_4007c0___do_global_dtors_aux() #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x4007c0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @3, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @callback_sub_4007c0___do_global_dtors_aux_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_4007c0___do_global_dtors_aux(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: alwaysinline inlinehint
define %struct.Memory* @ext_6050f8_atan(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #9 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @atan(double %6)
  %.repack = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 0, i64* %.repack, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  store i64 0, i64* %12, align 8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %13, align 8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %14, align 8
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: alwaysinline inlinehint
define %struct.Memory* @ext_6050b8_cos(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #9 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @cos(double %6)
  %.repack = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 0, i64* %.repack, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  store i64 0, i64* %12, align 8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %13, align 8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %14, align 8
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: alwaysinline inlinehint
define %struct.Memory* @ext_4006f0_sin(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #9 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @sin(double %6)
  %.repack = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 0, i64* %.repack, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  store i64 0, i64* %12, align 8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %13, align 8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %14, align 8
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_605128_memcpy(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64)* @memcpy to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_6050a0_printf(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64)* @printf to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_400670_abort(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 ()* @abort to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_6050e8_free(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64)* @free to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_605110_memset(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64)* @memset to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: alwaysinline inlinehint
define %struct.Memory* @ext_605140_sqrt(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #9 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @sqrt(double %6)
  %.repack = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 0, i64* %.repack, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  store i64 0, i64* %12, align 8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  store i64 0, i64* %13, align 8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 3
  store i64 0, i64* %14, align 8
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_4006e0_memalign(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64)* @memalign to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_4006a0_gettimeofday(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64)* @gettimeofday to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: naked nobuiltin noinline
define internal void @callback_sub_404060___libc_csu_fini() #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x404060;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @4, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @callback_sub_404060___libc_csu_fini_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_404060___libc_csu_fini(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define internal void @callback_sub_403ff0___libc_csu_init() #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x403ff0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @5, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @callback_sub_403ff0___libc_csu_init_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_403ff0___libc_csu_init(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @main() #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400800;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @6, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @main_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400800_main(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_605120___libc_start_main(%struct.State*, %struct.Memory*) unnamed_addr #6 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64)* @__libc_start_main to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @errorcheck() local_unnamed_addr #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x4010d0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @7, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @errorcheck_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_4010d0_errorcheck(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @.term_proc() local_unnamed_addr #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x404064;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @8, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @.term_proc_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_404064__term_proc(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @get_time() local_unnamed_addr #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400de0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @9, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @get_time_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400de0_get_time(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @makewt() local_unnamed_addr #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400e30;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @10, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @makewt_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400e30_makewt(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @.init_proc() local_unnamed_addr #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400638;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @11, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @.init_proc_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400638__init_proc(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @cdft() local_unnamed_addr #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x401030;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @12, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @cdft_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_401030_cdft(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @putdata() local_unnamed_addr #8 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400fb0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @13, void ()** nonnull @2) #10
  ret void
}

define internal %struct.Memory* @putdata_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400fb0_putdata(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

define internal void @__mcsema_constructor() {
  %1 = load volatile i1, i1* @0, align 1
  br i1 %1, label %__mcsema_early_init.exit, label %2

; <label>:2:                                      ; preds = %0
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %0, %2
  tail call void @callback_sub_403ff0___libc_csu_init()
  ret void
}

define internal void @__mcsema_destructor() {
  tail call void @callback_sub_404060___libc_csu_fini()
  ret void
}

attributes #0 = { nounwind readnone }
attributes #1 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind readnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { noinline }
attributes #7 = { noinline "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { naked nobuiltin noinline }
attributes #9 = { alwaysinline inlinehint "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #10 = { nounwind }
attributes #11 = { alwaysinline nobuiltin nounwind }

!llvm.ident = !{!0, !0}
!llvm.dbg.cu = !{!1}
!llvm.module.flags = !{!1259, !1260}

!0 = !{!"clang version 4.0.1 (tags/RELEASE_401/final)"}
!1 = distinct !DICompileUnit(language: DW_LANG_C_plus_plus, file: !2, producer: "clang version 4.0.1 (tags/RELEASE_401/final)", isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug, enums: !3, retainedTypes: !67, imports: !70)
!2 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/X86/Runtime/BasicBlock.cpp", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!3 = !{!4, !26, !35, !39, !45, !51, !55, !61}
!4 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "Name", scope: !6, file: !5, line: 70, baseType: !8, size: 32, elements: !11, identifier: "_ZTSN14AsyncHyperCall4NameE")
!5 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/HyperCall.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!6 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "AsyncHyperCall", file: !5, line: 68, size: 8, elements: !7, identifier: "_ZTS14AsyncHyperCall")
!7 = !{}
!8 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint32_t", file: !9, line: 183, baseType: !10)
!9 = !DIFile(filename: "/home/ubuntu/Github/remill/remill-build/libraries/llvm/bin/../lib/clang/4.0.1/include/stdint.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!10 = !DIBasicType(name: "unsigned int", size: 32, encoding: DW_ATE_unsigned)
!11 = !{!12, !13, !14, !15, !16, !17, !18, !19, !20, !21, !22, !23, !24, !25}
!12 = !DIEnumerator(name: "kInvalid", value: 0)
!13 = !DIEnumerator(name: "kX86Int1", value: 1)
!14 = !DIEnumerator(name: "kX86Int3", value: 2)
!15 = !DIEnumerator(name: "kX86IntO", value: 3)
!16 = !DIEnumerator(name: "kX86IntN", value: 4)
!17 = !DIEnumerator(name: "kX86Bound", value: 5)
!18 = !DIEnumerator(name: "kX86IRet", value: 6)
!19 = !DIEnumerator(name: "kX86SysCall", value: 7)
!20 = !DIEnumerator(name: "kX86SysRet", value: 8)
!21 = !DIEnumerator(name: "kX86SysEnter", value: 9)
!22 = !DIEnumerator(name: "kX86SysExit", value: 10)
!23 = !DIEnumerator(name: "kX86JmpFar", value: 11)
!24 = !DIEnumerator(name: "kAArch64SupervisorCall", value: 12)
!25 = !DIEnumerator(name: "kInvalidInstruction", value: 13)
!26 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "RequestPrivilegeLevel", file: !27, line: 64, baseType: !28, size: 16, elements: !30, identifier: "_ZTS21RequestPrivilegeLevel")
!27 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/X86/Runtime/State.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!28 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint16_t", file: !9, line: 218, baseType: !29)
!29 = !DIBasicType(name: "unsigned short", size: 16, encoding: DW_ATE_unsigned)
!30 = !{!31, !32, !33, !34}
!31 = !DIEnumerator(name: "kRPLRingZero", value: 0)
!32 = !DIEnumerator(name: "kRPLRingOne", value: 1)
!33 = !DIEnumerator(name: "kRPLRingTwo", value: 2)
!34 = !DIEnumerator(name: "kRPLRingThree", value: 3)
!35 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "TableIndicator", file: !27, line: 71, baseType: !28, size: 16, elements: !36, identifier: "_ZTS14TableIndicator")
!36 = !{!37, !38}
!37 = !DIEnumerator(name: "kGlobalDescriptorTable", value: 0)
!38 = !DIEnumerator(name: "kLocalDescriptorTable", value: 1)
!39 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUPrecisionControl", file: !27, line: 123, baseType: !28, size: 16, elements: !40, identifier: "_ZTS19FPUPrecisionControl")
!40 = !{!41, !42, !43, !44}
!41 = !DIEnumerator(name: "kPrecisionSingle", value: 0)
!42 = !DIEnumerator(name: "kPrecisionReserved", value: 1)
!43 = !DIEnumerator(name: "kPrecisionDouble", value: 2)
!44 = !DIEnumerator(name: "kPrecisionExtended", value: 3)
!45 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPURoundingControl", file: !27, line: 130, baseType: !28, size: 16, elements: !46, identifier: "_ZTS18FPURoundingControl")
!46 = !{!47, !48, !49, !50}
!47 = !DIEnumerator(name: "kFPURoundToNearestEven", value: 0)
!48 = !DIEnumerator(name: "kFPURoundDownNegInf", value: 1)
!49 = !DIEnumerator(name: "kFPURoundUpInf", value: 2)
!50 = !DIEnumerator(name: "kFPURoundToZero", value: 3)
!51 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUInfinityControl", file: !27, line: 137, baseType: !28, size: 16, elements: !52, identifier: "_ZTS18FPUInfinityControl")
!52 = !{!53, !54}
!53 = !DIEnumerator(name: "kInfinityProjective", value: 0)
!54 = !DIEnumerator(name: "kInfinityAffine", value: 1)
!55 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUTag", file: !27, line: 214, baseType: !28, size: 16, elements: !56, identifier: "_ZTS6FPUTag")
!56 = !{!57, !58, !59, !60}
!57 = !DIEnumerator(name: "kFPUTagNonZero", value: 0)
!58 = !DIEnumerator(name: "kFPUTagZero", value: 1)
!59 = !DIEnumerator(name: "kFPUTagSpecial", value: 2)
!60 = !DIEnumerator(name: "kFPUTagEmpty", value: 3)
!61 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUAbridgedTag", file: !27, line: 221, baseType: !62, size: 8, elements: !64, identifier: "_ZTS14FPUAbridgedTag")
!62 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint8_t", file: !9, line: 237, baseType: !63)
!63 = !DIBasicType(name: "unsigned char", size: 8, encoding: DW_ATE_unsigned_char)
!64 = !{!65, !66}
!65 = !DIEnumerator(name: "kFPUAbridgedTagEmpty", value: 0)
!66 = !DIEnumerator(name: "kFPUAbridgedTagValid", value: 1)
!67 = !{!68}
!68 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !69, size: 64)
!69 = !DIDerivedType(tag: DW_TAG_const_type, baseType: null)
!70 = !{!71, !77, !83, !86, !93, !97, !102, !104, !112, !116, !120, !132, !136, !140, !144, !148, !153, !157, !161, !165, !169, !177, !181, !185, !187, !191, !195, !199, !205, !209, !213, !215, !223, !227, !235, !237, !241, !245, !249, !253, !258, !263, !268, !269, !270, !271, !274, !275, !276, !277, !278, !279, !280, !335, !339, !355, !358, !363, !371, !376, !380, !384, !388, !392, !394, !396, !400, !406, !410, !416, !422, !424, !428, !432, !436, !440, !451, !453, !457, !461, !465, !467, !471, !475, !479, !481, !483, !487, !495, !499, !503, !507, !509, !515, !517, !523, !527, !531, !535, !539, !543, !547, !549, !551, !555, !559, !563, !565, !569, !573, !575, !577, !581, !585, !589, !593, !594, !595, !596, !597, !598, !599, !600, !601, !602, !603, !606, !609, !611, !613, !615, !617, !619, !621, !623, !625, !627, !629, !631, !633, !634, !635, !636, !638, !640, !642, !644, !646, !648, !650, !652, !654, !656, !658, !660, !662, !665, !669, !674, !677, !679, !681, !683, !685, !687, !689, !691, !693, !695, !697, !699, !701, !703, !706, !712, !717, !721, !723, !725, !727, !729, !736, !740, !744, !748, !752, !756, !761, !765, !767, !771, !777, !781, !786, !788, !790, !794, !798, !802, !804, !806, !808, !810, !814, !816, !818, !822, !826, !830, !834, !838, !840, !842, !846, !850, !854, !858, !860, !862, !866, !870, !871, !872, !873, !874, !875, !880, !882, !884, !888, !890, !892, !894, !896, !898, !900, !902, !907, !911, !913, !915, !920, !922, !924, !926, !928, !930, !932, !935, !937, !939, !943, !947, !949, !951, !953, !955, !957, !959, !961, !963, !965, !967, !971, !975, !977, !979, !981, !983, !985, !987, !989, !991, !993, !995, !997, !999, !1001, !1003, !1005, !1009, !1013, !1017, !1019, !1021, !1023, !1025, !1027, !1029, !1031, !1033, !1035, !1039, !1043, !1047, !1049, !1051, !1053, !1057, !1061, !1065, !1067, !1069, !1071, !1073, !1075, !1077, !1079, !1081, !1083, !1085, !1087, !1089, !1093, !1097, !1101, !1103, !1105, !1107, !1109, !1113, !1117, !1119, !1121, !1123, !1125, !1127, !1129, !1133, !1137, !1139, !1141, !1143, !1145, !1149, !1153, !1157, !1159, !1161, !1163, !1165, !1167, !1169, !1173, !1177, !1181, !1183, !1187, !1191, !1193, !1195, !1197, !1199, !1201, !1203, !1207, !1209, !1212, !1217, !1219, !1225, !1227, !1229, !1231, !1236, !1238, !1244, !1246, !1247, !1248, !1249, !1250, !1251, !1252, !1253, !1254, !1255, !1256, !1257, !1258}
!71 = !DIImportedEntity(tag: DW_TAG_imported_module, scope: !72, entity: !74, line: 58)
!72 = !DINamespace(name: "__gnu_debug", scope: null, file: !73, line: 56)
!73 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/debug/debug.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!74 = !DINamespace(name: "__debug", scope: !75, file: !73, line: 50)
!75 = !DINamespace(name: "std", scope: null, file: !76, line: 229)
!76 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/x86_64-linux-gnu/c++/7.4.0/bits/c++config.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!77 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !78, line: 52)
!78 = !DISubprogram(name: "abs", scope: !79, file: !79, line: 837, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!79 = !DIFile(filename: "/usr/include/stdlib.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!80 = !DISubroutineType(types: !81)
!81 = !{!82, !82}
!82 = !DIBasicType(name: "int", size: 32, encoding: DW_ATE_signed)
!83 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !84, line: 127)
!84 = !DIDerivedType(tag: DW_TAG_typedef, name: "div_t", file: !79, line: 62, baseType: !85)
!85 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 58, flags: DIFlagFwdDecl, identifier: "_ZTS5div_t")
!86 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !87, line: 128)
!87 = !DIDerivedType(tag: DW_TAG_typedef, name: "ldiv_t", file: !79, line: 70, baseType: !88)
!88 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 66, size: 128, elements: !89, identifier: "_ZTS6ldiv_t")
!89 = !{!90, !92}
!90 = !DIDerivedType(tag: DW_TAG_member, name: "quot", scope: !88, file: !79, line: 68, baseType: !91, size: 64)
!91 = !DIBasicType(name: "long int", size: 64, encoding: DW_ATE_signed)
!92 = !DIDerivedType(tag: DW_TAG_member, name: "rem", scope: !88, file: !79, line: 69, baseType: !91, size: 64, offset: 64)
!93 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !94, line: 130)
!94 = !DISubprogram(name: "abort", scope: !79, file: !79, line: 588, type: !95, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!95 = !DISubroutineType(types: !96)
!96 = !{null}
!97 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !98, line: 134)
!98 = !DISubprogram(name: "atexit", scope: !79, file: !79, line: 592, type: !99, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!99 = !DISubroutineType(types: !100)
!100 = !{!82, !101}
!101 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !95, size: 64)
!102 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !103, line: 137)
!103 = !DISubprogram(name: "at_quick_exit", scope: !79, file: !79, line: 597, type: !99, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!104 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !105, line: 140)
!105 = !DISubprogram(name: "atof", scope: !79, file: !79, line: 101, type: !106, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!106 = !DISubroutineType(types: !107)
!107 = !{!108, !109}
!108 = !DIBasicType(name: "double", size: 64, encoding: DW_ATE_float)
!109 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !110, size: 64)
!110 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !111)
!111 = !DIBasicType(name: "char", size: 8, encoding: DW_ATE_signed_char)
!112 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !113, line: 141)
!113 = !DISubprogram(name: "atoi", scope: !79, file: !79, line: 104, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!114 = !DISubroutineType(types: !115)
!115 = !{!82, !109}
!116 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !117, line: 142)
!117 = !DISubprogram(name: "atol", scope: !79, file: !79, line: 107, type: !118, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!118 = !DISubroutineType(types: !119)
!119 = !{!91, !109}
!120 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !121, line: 143)
!121 = !DISubprogram(name: "bsearch", scope: !79, file: !79, line: 817, type: !122, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!122 = !DISubroutineType(types: !123)
!123 = !{!124, !68, !68, !125, !125, !128}
!124 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: null, size: 64)
!125 = !DIDerivedType(tag: DW_TAG_typedef, name: "size_t", file: !126, line: 62, baseType: !127)
!126 = !DIFile(filename: "/home/ubuntu/Github/remill/remill-build/libraries/llvm/bin/../lib/clang/4.0.1/include/stddef.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!127 = !DIBasicType(name: "long unsigned int", size: 64, encoding: DW_ATE_unsigned)
!128 = !DIDerivedType(tag: DW_TAG_typedef, name: "__compar_fn_t", file: !79, line: 805, baseType: !129)
!129 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !130, size: 64)
!130 = !DISubroutineType(types: !131)
!131 = !{!82, !68, !68}
!132 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !133, line: 144)
!133 = !DISubprogram(name: "calloc", scope: !79, file: !79, line: 541, type: !134, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!134 = !DISubroutineType(types: !135)
!135 = !{!124, !125, !125}
!136 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !137, line: 145)
!137 = !DISubprogram(name: "div", scope: !79, file: !79, line: 849, type: !138, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!138 = !DISubroutineType(types: !139)
!139 = !{!84, !82, !82}
!140 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !141, line: 146)
!141 = !DISubprogram(name: "exit", scope: !79, file: !79, line: 614, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!142 = !DISubroutineType(types: !143)
!143 = !{null, !82}
!144 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !145, line: 147)
!145 = !DISubprogram(name: "free", scope: !79, file: !79, line: 563, type: !146, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!146 = !DISubroutineType(types: !147)
!147 = !{null, !124}
!148 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !149, line: 148)
!149 = !DISubprogram(name: "getenv", scope: !79, file: !79, line: 631, type: !150, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!150 = !DISubroutineType(types: !151)
!151 = !{!152, !109}
!152 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !111, size: 64)
!153 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !154, line: 149)
!154 = !DISubprogram(name: "labs", scope: !79, file: !79, line: 838, type: !155, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!155 = !DISubroutineType(types: !156)
!156 = !{!91, !91}
!157 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !158, line: 150)
!158 = !DISubprogram(name: "ldiv", scope: !79, file: !79, line: 851, type: !159, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!159 = !DISubroutineType(types: !160)
!160 = !{!87, !91, !91}
!161 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !162, line: 151)
!162 = !DISubprogram(name: "malloc", scope: !79, file: !79, line: 539, type: !163, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!163 = !DISubroutineType(types: !164)
!164 = !{!124, !125}
!165 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !166, line: 153)
!166 = !DISubprogram(name: "mblen", scope: !79, file: !79, line: 919, type: !167, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!167 = !DISubroutineType(types: !168)
!168 = !{!82, !109, !125}
!169 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !170, line: 154)
!170 = !DISubprogram(name: "mbstowcs", scope: !79, file: !79, line: 930, type: !171, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!171 = !DISubroutineType(types: !172)
!172 = !{!125, !173, !176, !125}
!173 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !174)
!174 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !175, size: 64)
!175 = !DIBasicType(name: "wchar_t", size: 32, encoding: DW_ATE_signed)
!176 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !109)
!177 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !178, line: 155)
!178 = !DISubprogram(name: "mbtowc", scope: !79, file: !79, line: 922, type: !179, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!179 = !DISubroutineType(types: !180)
!180 = !{!82, !173, !176, !125}
!181 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !182, line: 157)
!182 = !DISubprogram(name: "qsort", scope: !79, file: !79, line: 827, type: !183, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!183 = !DISubroutineType(types: !184)
!184 = !{null, !124, !125, !125, !128}
!185 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !186, line: 160)
!186 = !DISubprogram(name: "quick_exit", scope: !79, file: !79, line: 620, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!187 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !188, line: 163)
!188 = !DISubprogram(name: "rand", scope: !79, file: !79, line: 453, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!189 = !DISubroutineType(types: !190)
!190 = !{!82}
!191 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !192, line: 164)
!192 = !DISubprogram(name: "realloc", scope: !79, file: !79, line: 549, type: !193, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!193 = !DISubroutineType(types: !194)
!194 = !{!124, !124, !125}
!195 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !196, line: 165)
!196 = !DISubprogram(name: "srand", scope: !79, file: !79, line: 455, type: !197, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!197 = !DISubroutineType(types: !198)
!198 = !{null, !10}
!199 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !200, line: 166)
!200 = !DISubprogram(name: "strtod", scope: !79, file: !79, line: 117, type: !201, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!201 = !DISubroutineType(types: !202)
!202 = !{!108, !176, !203}
!203 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !204)
!204 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !152, size: 64)
!205 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !206, line: 167)
!206 = !DISubprogram(name: "strtol", scope: !79, file: !79, line: 176, type: !207, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!207 = !DISubroutineType(types: !208)
!208 = !{!91, !176, !203, !82}
!209 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !210, line: 168)
!210 = !DISubprogram(name: "strtoul", scope: !79, file: !79, line: 180, type: !211, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!211 = !DISubroutineType(types: !212)
!212 = !{!127, !176, !203, !82}
!213 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !214, line: 169)
!214 = !DISubprogram(name: "system", scope: !79, file: !79, line: 781, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!215 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !216, line: 171)
!216 = !DISubprogram(name: "wcstombs", scope: !79, file: !79, line: 933, type: !217, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!217 = !DISubroutineType(types: !218)
!218 = !{!125, !219, !220, !125}
!219 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !152)
!220 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !221)
!221 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !222, size: 64)
!222 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !175)
!223 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !224, line: 172)
!224 = !DISubprogram(name: "wctomb", scope: !79, file: !79, line: 926, type: !225, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!225 = !DISubroutineType(types: !226)
!226 = !{!82, !152, !175}
!227 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !229, line: 200)
!228 = !DINamespace(name: "__gnu_cxx", scope: null, file: !76, line: 255)
!229 = !DIDerivedType(tag: DW_TAG_typedef, name: "lldiv_t", file: !79, line: 80, baseType: !230)
!230 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 76, size: 128, elements: !231, identifier: "_ZTS7lldiv_t")
!231 = !{!232, !234}
!232 = !DIDerivedType(tag: DW_TAG_member, name: "quot", scope: !230, file: !79, line: 78, baseType: !233, size: 64)
!233 = !DIBasicType(name: "long long int", size: 64, encoding: DW_ATE_signed)
!234 = !DIDerivedType(tag: DW_TAG_member, name: "rem", scope: !230, file: !79, line: 79, baseType: !233, size: 64, offset: 64)
!235 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !236, line: 206)
!236 = !DISubprogram(name: "_Exit", scope: !79, file: !79, line: 626, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!237 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !238, line: 210)
!238 = !DISubprogram(name: "llabs", scope: !79, file: !79, line: 841, type: !239, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!239 = !DISubroutineType(types: !240)
!240 = !{!233, !233}
!241 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !242, line: 216)
!242 = !DISubprogram(name: "lldiv", scope: !79, file: !79, line: 855, type: !243, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!243 = !DISubroutineType(types: !244)
!244 = !{!229, !233, !233}
!245 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !246, line: 227)
!246 = !DISubprogram(name: "atoll", scope: !79, file: !79, line: 112, type: !247, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!247 = !DISubroutineType(types: !248)
!248 = !{!233, !109}
!249 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !250, line: 228)
!250 = !DISubprogram(name: "strtoll", scope: !79, file: !79, line: 200, type: !251, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!251 = !DISubroutineType(types: !252)
!252 = !{!233, !176, !203, !82}
!253 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !254, line: 229)
!254 = !DISubprogram(name: "strtoull", scope: !79, file: !79, line: 205, type: !255, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!255 = !DISubroutineType(types: !256)
!256 = !{!257, !176, !203, !82}
!257 = !DIBasicType(name: "long long unsigned int", size: 64, encoding: DW_ATE_unsigned)
!258 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !259, line: 231)
!259 = !DISubprogram(name: "strtof", scope: !79, file: !79, line: 123, type: !260, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!260 = !DISubroutineType(types: !261)
!261 = !{!262, !176, !203}
!262 = !DIBasicType(name: "float", size: 32, encoding: DW_ATE_float)
!263 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !264, line: 232)
!264 = !DISubprogram(name: "strtold", scope: !79, file: !79, line: 126, type: !265, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!265 = !DISubroutineType(types: !266)
!266 = !{!267, !176, !203}
!267 = !DIBasicType(name: "long double", size: 128, encoding: DW_ATE_float)
!268 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !229, line: 240)
!269 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !236, line: 242)
!270 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !238, line: 244)
!271 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !272, line: 245)
!272 = !DISubprogram(name: "div", linkageName: "_ZN9__gnu_cxx3divExx", scope: !228, file: !273, line: 213, type: !243, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!273 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/cstdlib", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!274 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !242, line: 246)
!275 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !246, line: 248)
!276 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !259, line: 249)
!277 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !250, line: 250)
!278 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !254, line: 251)
!279 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !264, line: 252)
!280 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !281, line: 57)
!281 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "exception_ptr", scope: !283, file: !282, line: 79, size: 64, elements: !284, identifier: "_ZTSNSt15__exception_ptr13exception_ptrE")
!282 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/bits/exception_ptr.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!283 = !DINamespace(name: "__exception_ptr", scope: !75, file: !282, line: 52)
!284 = !{!285, !286, !290, !293, !294, !299, !300, !304, !309, !313, !317, !320, !321, !324, !328}
!285 = !DIDerivedType(tag: DW_TAG_member, name: "_M_exception_object", scope: !281, file: !282, line: 81, baseType: !124, size: 64)
!286 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 83, type: !287, isLocal: false, isDefinition: false, scopeLine: 83, flags: DIFlagExplicit | DIFlagPrototyped, isOptimized: false)
!287 = !DISubroutineType(types: !288)
!288 = !{null, !289, !124}
!289 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !281, size: 64, flags: DIFlagArtificial | DIFlagObjectPointer)
!290 = !DISubprogram(name: "_M_addref", linkageName: "_ZNSt15__exception_ptr13exception_ptr9_M_addrefEv", scope: !281, file: !282, line: 85, type: !291, isLocal: false, isDefinition: false, scopeLine: 85, flags: DIFlagPrototyped, isOptimized: false)
!291 = !DISubroutineType(types: !292)
!292 = !{null, !289}
!293 = !DISubprogram(name: "_M_release", linkageName: "_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv", scope: !281, file: !282, line: 86, type: !291, isLocal: false, isDefinition: false, scopeLine: 86, flags: DIFlagPrototyped, isOptimized: false)
!294 = !DISubprogram(name: "_M_get", linkageName: "_ZNKSt15__exception_ptr13exception_ptr6_M_getEv", scope: !281, file: !282, line: 88, type: !295, isLocal: false, isDefinition: false, scopeLine: 88, flags: DIFlagPrototyped, isOptimized: false)
!295 = !DISubroutineType(types: !296)
!296 = !{!124, !297}
!297 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !298, size: 64, flags: DIFlagArtificial | DIFlagObjectPointer)
!298 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !281)
!299 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 96, type: !291, isLocal: false, isDefinition: false, scopeLine: 96, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!300 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 98, type: !301, isLocal: false, isDefinition: false, scopeLine: 98, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!301 = !DISubroutineType(types: !302)
!302 = !{null, !289, !303}
!303 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !298, size: 64)
!304 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 101, type: !305, isLocal: false, isDefinition: false, scopeLine: 101, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!305 = !DISubroutineType(types: !306)
!306 = !{null, !289, !307}
!307 = !DIDerivedType(tag: DW_TAG_typedef, name: "nullptr_t", scope: !75, file: !76, line: 235, baseType: !308)
!308 = !DIBasicType(tag: DW_TAG_unspecified_type, name: "decltype(nullptr)")
!309 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 105, type: !310, isLocal: false, isDefinition: false, scopeLine: 105, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!310 = !DISubroutineType(types: !311)
!311 = !{null, !289, !312}
!312 = !DIDerivedType(tag: DW_TAG_rvalue_reference_type, baseType: !281, size: 64)
!313 = !DISubprogram(name: "operator=", linkageName: "_ZNSt15__exception_ptr13exception_ptraSERKS0_", scope: !281, file: !282, line: 118, type: !314, isLocal: false, isDefinition: false, scopeLine: 118, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!314 = !DISubroutineType(types: !315)
!315 = !{!316, !289, !303}
!316 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !281, size: 64)
!317 = !DISubprogram(name: "operator=", linkageName: "_ZNSt15__exception_ptr13exception_ptraSEOS0_", scope: !281, file: !282, line: 122, type: !318, isLocal: false, isDefinition: false, scopeLine: 122, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!318 = !DISubroutineType(types: !319)
!319 = !{!316, !289, !312}
!320 = !DISubprogram(name: "~exception_ptr", scope: !281, file: !282, line: 129, type: !291, isLocal: false, isDefinition: false, scopeLine: 129, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!321 = !DISubprogram(name: "swap", linkageName: "_ZNSt15__exception_ptr13exception_ptr4swapERS0_", scope: !281, file: !282, line: 132, type: !322, isLocal: false, isDefinition: false, scopeLine: 132, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!322 = !DISubroutineType(types: !323)
!323 = !{null, !289, !316}
!324 = !DISubprogram(name: "operator bool", linkageName: "_ZNKSt15__exception_ptr13exception_ptrcvbEv", scope: !281, file: !282, line: 144, type: !325, isLocal: false, isDefinition: false, scopeLine: 144, flags: DIFlagPublic | DIFlagExplicit | DIFlagPrototyped, isOptimized: false)
!325 = !DISubroutineType(types: !326)
!326 = !{!327, !297}
!327 = !DIBasicType(name: "bool", size: 8, encoding: DW_ATE_boolean)
!328 = !DISubprogram(name: "__cxa_exception_type", linkageName: "_ZNKSt15__exception_ptr13exception_ptr20__cxa_exception_typeEv", scope: !281, file: !282, line: 153, type: !329, isLocal: false, isDefinition: false, scopeLine: 153, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!329 = !DISubroutineType(types: !330)
!330 = !{!331, !297}
!331 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !332, size: 64)
!332 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !333)
!333 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "type_info", scope: !75, file: !334, line: 88, flags: DIFlagFwdDecl, identifier: "_ZTSSt9type_info")
!334 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/typeinfo", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!335 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !283, entity: !336, line: 73)
!336 = !DISubprogram(name: "rethrow_exception", linkageName: "_ZSt17rethrow_exceptionNSt15__exception_ptr13exception_ptrE", scope: !75, file: !282, line: 69, type: !337, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!337 = !DISubroutineType(types: !338)
!338 = !{null, !281}
!339 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !340, line: 64)
!340 = !DIDerivedType(tag: DW_TAG_typedef, name: "mbstate_t", file: !341, line: 6, baseType: !342)
!341 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/mbstate_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!342 = !DIDerivedType(tag: DW_TAG_typedef, name: "__mbstate_t", file: !343, line: 21, baseType: !344)
!343 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/__mbstate_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!344 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !343, line: 13, size: 64, elements: !345, identifier: "_ZTS11__mbstate_t")
!345 = !{!346, !347}
!346 = !DIDerivedType(tag: DW_TAG_member, name: "__count", scope: !344, file: !343, line: 15, baseType: !82, size: 32)
!347 = !DIDerivedType(tag: DW_TAG_member, name: "__value", scope: !344, file: !343, line: 20, baseType: !348, size: 32, offset: 32)
!348 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !344, file: !343, line: 16, size: 32, elements: !349, identifier: "_ZTSN11__mbstate_tUt_E")
!349 = !{!350, !351}
!350 = !DIDerivedType(tag: DW_TAG_member, name: "__wch", scope: !348, file: !343, line: 18, baseType: !10, size: 32)
!351 = !DIDerivedType(tag: DW_TAG_member, name: "__wchb", scope: !348, file: !343, line: 19, baseType: !352, size: 32)
!352 = !DICompositeType(tag: DW_TAG_array_type, baseType: !111, size: 32, elements: !353)
!353 = !{!354}
!354 = !DISubrange(count: 4)
!355 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !356, line: 139)
!356 = !DIDerivedType(tag: DW_TAG_typedef, name: "wint_t", file: !357, line: 20, baseType: !10)
!357 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/wint_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!358 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !359, line: 141)
!359 = !DISubprogram(name: "btowc", scope: !360, file: !360, line: 284, type: !361, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!360 = !DIFile(filename: "/usr/include/wchar.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!361 = !DISubroutineType(types: !362)
!362 = !{!356, !82}
!363 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !364, line: 142)
!364 = !DISubprogram(name: "fgetwc", scope: !360, file: !360, line: 727, type: !365, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!365 = !DISubroutineType(types: !366)
!366 = !{!356, !367}
!367 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !368, size: 64)
!368 = !DIDerivedType(tag: DW_TAG_typedef, name: "__FILE", file: !369, line: 5, baseType: !370)
!369 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/__FILE.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!370 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "_IO_FILE", file: !369, line: 4, flags: DIFlagFwdDecl, identifier: "_ZTS8_IO_FILE")
!371 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !372, line: 143)
!372 = !DISubprogram(name: "fgetws", scope: !360, file: !360, line: 756, type: !373, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!373 = !DISubroutineType(types: !374)
!374 = !{!174, !173, !82, !375}
!375 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !367)
!376 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !377, line: 144)
!377 = !DISubprogram(name: "fputwc", scope: !360, file: !360, line: 741, type: !378, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!378 = !DISubroutineType(types: !379)
!379 = !{!356, !175, !367}
!380 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !381, line: 145)
!381 = !DISubprogram(name: "fputws", scope: !360, file: !360, line: 763, type: !382, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!382 = !DISubroutineType(types: !383)
!383 = !{!82, !220, !375}
!384 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !385, line: 146)
!385 = !DISubprogram(name: "fwide", scope: !360, file: !360, line: 573, type: !386, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!386 = !DISubroutineType(types: !387)
!387 = !{!82, !367, !82}
!388 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !389, line: 147)
!389 = !DISubprogram(name: "fwprintf", scope: !360, file: !360, line: 580, type: !390, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!390 = !DISubroutineType(types: !391)
!391 = !{!82, !375, !220, null}
!392 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !393, line: 148)
!393 = !DISubprogram(name: "fwscanf", scope: !360, file: !360, line: 621, type: !390, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!394 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !395, line: 149)
!395 = !DISubprogram(name: "getwc", scope: !360, file: !360, line: 728, type: !365, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!396 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !397, line: 150)
!397 = !DISubprogram(name: "getwchar", scope: !360, file: !360, line: 734, type: !398, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!398 = !DISubroutineType(types: !399)
!399 = !{!356}
!400 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !401, line: 151)
!401 = !DISubprogram(name: "mbrlen", scope: !360, file: !360, line: 307, type: !402, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!402 = !DISubroutineType(types: !403)
!403 = !{!125, !176, !125, !404}
!404 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !405)
!405 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !340, size: 64)
!406 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !407, line: 152)
!407 = !DISubprogram(name: "mbrtowc", scope: !360, file: !360, line: 296, type: !408, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!408 = !DISubroutineType(types: !409)
!409 = !{!125, !173, !176, !125, !404}
!410 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !411, line: 153)
!411 = !DISubprogram(name: "mbsinit", scope: !360, file: !360, line: 292, type: !412, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!412 = !DISubroutineType(types: !413)
!413 = !{!82, !414}
!414 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !415, size: 64)
!415 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !340)
!416 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !417, line: 154)
!417 = !DISubprogram(name: "mbsrtowcs", scope: !360, file: !360, line: 337, type: !418, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!418 = !DISubroutineType(types: !419)
!419 = !{!125, !173, !420, !125, !404}
!420 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !421)
!421 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !109, size: 64)
!422 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !423, line: 155)
!423 = !DISubprogram(name: "putwc", scope: !360, file: !360, line: 742, type: !378, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!424 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !425, line: 156)
!425 = !DISubprogram(name: "putwchar", scope: !360, file: !360, line: 748, type: !426, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!426 = !DISubroutineType(types: !427)
!427 = !{!356, !175}
!428 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !429, line: 158)
!429 = !DISubprogram(name: "swprintf", scope: !360, file: !360, line: 590, type: !430, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!430 = !DISubroutineType(types: !431)
!431 = !{!82, !173, !125, !220, null}
!432 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !433, line: 160)
!433 = !DISubprogram(name: "swscanf", scope: !360, file: !360, line: 631, type: !434, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!434 = !DISubroutineType(types: !435)
!435 = !{!82, !220, !220, null}
!436 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !437, line: 161)
!437 = !DISubprogram(name: "ungetwc", scope: !360, file: !360, line: 771, type: !438, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!438 = !DISubroutineType(types: !439)
!439 = !{!356, !356, !367}
!440 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !441, line: 162)
!441 = !DISubprogram(name: "vfwprintf", scope: !360, file: !360, line: 598, type: !442, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!442 = !DISubroutineType(types: !443)
!443 = !{!82, !375, !220, !444}
!444 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !445, size: 64)
!445 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "__va_list_tag", file: !2, size: 192, elements: !446, identifier: "_ZTS13__va_list_tag")
!446 = !{!447, !448, !449, !450}
!447 = !DIDerivedType(tag: DW_TAG_member, name: "gp_offset", scope: !445, file: !2, baseType: !10, size: 32)
!448 = !DIDerivedType(tag: DW_TAG_member, name: "fp_offset", scope: !445, file: !2, baseType: !10, size: 32, offset: 32)
!449 = !DIDerivedType(tag: DW_TAG_member, name: "overflow_arg_area", scope: !445, file: !2, baseType: !124, size: 64, offset: 64)
!450 = !DIDerivedType(tag: DW_TAG_member, name: "reg_save_area", scope: !445, file: !2, baseType: !124, size: 64, offset: 128)
!451 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !452, line: 164)
!452 = !DISubprogram(name: "vfwscanf", scope: !360, file: !360, line: 673, type: !442, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!453 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !454, line: 167)
!454 = !DISubprogram(name: "vswprintf", scope: !360, file: !360, line: 611, type: !455, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!455 = !DISubroutineType(types: !456)
!456 = !{!82, !173, !125, !220, !444}
!457 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !458, line: 170)
!458 = !DISubprogram(name: "vswscanf", scope: !360, file: !360, line: 685, type: !459, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!459 = !DISubroutineType(types: !460)
!460 = !{!82, !220, !220, !444}
!461 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !462, line: 172)
!462 = !DISubprogram(name: "vwprintf", scope: !360, file: !360, line: 606, type: !463, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!463 = !DISubroutineType(types: !464)
!464 = !{!82, !220, !444}
!465 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !466, line: 174)
!466 = !DISubprogram(name: "vwscanf", scope: !360, file: !360, line: 681, type: !463, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!467 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !468, line: 176)
!468 = !DISubprogram(name: "wcrtomb", scope: !360, file: !360, line: 301, type: !469, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!469 = !DISubroutineType(types: !470)
!470 = !{!125, !219, !175, !404}
!471 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !472, line: 177)
!472 = !DISubprogram(name: "wcscat", scope: !360, file: !360, line: 97, type: !473, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!473 = !DISubroutineType(types: !474)
!474 = !{!174, !173, !220}
!475 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !476, line: 178)
!476 = !DISubprogram(name: "wcscmp", scope: !360, file: !360, line: 106, type: !477, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!477 = !DISubroutineType(types: !478)
!478 = !{!82, !221, !221}
!479 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !480, line: 179)
!480 = !DISubprogram(name: "wcscoll", scope: !360, file: !360, line: 131, type: !477, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!481 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !482, line: 180)
!482 = !DISubprogram(name: "wcscpy", scope: !360, file: !360, line: 87, type: !473, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!483 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !484, line: 181)
!484 = !DISubprogram(name: "wcscspn", scope: !360, file: !360, line: 187, type: !485, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!485 = !DISubroutineType(types: !486)
!486 = !{!125, !221, !221}
!487 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !488, line: 182)
!488 = !DISubprogram(name: "wcsftime", scope: !360, file: !360, line: 835, type: !489, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!489 = !DISubroutineType(types: !490)
!490 = !{!125, !173, !125, !220, !491}
!491 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !492)
!492 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !493, size: 64)
!493 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !494)
!494 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "tm", file: !360, line: 83, flags: DIFlagFwdDecl, identifier: "_ZTS2tm")
!495 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !496, line: 183)
!496 = !DISubprogram(name: "wcslen", scope: !360, file: !360, line: 222, type: !497, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!497 = !DISubroutineType(types: !498)
!498 = !{!125, !221}
!499 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !500, line: 184)
!500 = !DISubprogram(name: "wcsncat", scope: !360, file: !360, line: 101, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!501 = !DISubroutineType(types: !502)
!502 = !{!174, !173, !220, !125}
!503 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !504, line: 185)
!504 = !DISubprogram(name: "wcsncmp", scope: !360, file: !360, line: 109, type: !505, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!505 = !DISubroutineType(types: !506)
!506 = !{!82, !221, !221, !125}
!507 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !508, line: 186)
!508 = !DISubprogram(name: "wcsncpy", scope: !360, file: !360, line: 92, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!509 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !510, line: 187)
!510 = !DISubprogram(name: "wcsrtombs", scope: !360, file: !360, line: 343, type: !511, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!511 = !DISubroutineType(types: !512)
!512 = !{!125, !219, !513, !125, !404}
!513 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !514)
!514 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !221, size: 64)
!515 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !516, line: 188)
!516 = !DISubprogram(name: "wcsspn", scope: !360, file: !360, line: 191, type: !485, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!517 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !518, line: 189)
!518 = !DISubprogram(name: "wcstod", scope: !360, file: !360, line: 377, type: !519, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!519 = !DISubroutineType(types: !520)
!520 = !{!108, !220, !521}
!521 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !522)
!522 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !174, size: 64)
!523 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !524, line: 191)
!524 = !DISubprogram(name: "wcstof", scope: !360, file: !360, line: 382, type: !525, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!525 = !DISubroutineType(types: !526)
!526 = !{!262, !220, !521}
!527 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !528, line: 193)
!528 = !DISubprogram(name: "wcstok", scope: !360, file: !360, line: 217, type: !529, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!529 = !DISubroutineType(types: !530)
!530 = !{!174, !173, !220, !521}
!531 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !532, line: 194)
!532 = !DISubprogram(name: "wcstol", scope: !360, file: !360, line: 428, type: !533, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!533 = !DISubroutineType(types: !534)
!534 = !{!91, !220, !521, !82}
!535 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !536, line: 195)
!536 = !DISubprogram(name: "wcstoul", scope: !360, file: !360, line: 433, type: !537, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!537 = !DISubroutineType(types: !538)
!538 = !{!127, !220, !521, !82}
!539 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !540, line: 196)
!540 = !DISubprogram(name: "wcsxfrm", scope: !360, file: !360, line: 135, type: !541, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!541 = !DISubroutineType(types: !542)
!542 = !{!125, !173, !220, !125}
!543 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !544, line: 197)
!544 = !DISubprogram(name: "wctob", scope: !360, file: !360, line: 288, type: !545, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!545 = !DISubroutineType(types: !546)
!546 = !{!82, !356}
!547 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !548, line: 198)
!548 = !DISubprogram(name: "wmemcmp", scope: !360, file: !360, line: 258, type: !505, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!549 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !550, line: 199)
!550 = !DISubprogram(name: "wmemcpy", scope: !360, file: !360, line: 262, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!551 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !552, line: 200)
!552 = !DISubprogram(name: "wmemmove", scope: !360, file: !360, line: 267, type: !553, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!553 = !DISubroutineType(types: !554)
!554 = !{!174, !174, !221, !125}
!555 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !556, line: 201)
!556 = !DISubprogram(name: "wmemset", scope: !360, file: !360, line: 271, type: !557, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!557 = !DISubroutineType(types: !558)
!558 = !{!174, !174, !175, !125}
!559 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !560, line: 202)
!560 = !DISubprogram(name: "wprintf", scope: !360, file: !360, line: 587, type: !561, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!561 = !DISubroutineType(types: !562)
!562 = !{!82, !220, null}
!563 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !564, line: 203)
!564 = !DISubprogram(name: "wscanf", scope: !360, file: !360, line: 628, type: !561, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!565 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !566, line: 204)
!566 = !DISubprogram(name: "wcschr", scope: !360, file: !360, line: 164, type: !567, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!567 = !DISubroutineType(types: !568)
!568 = !{!174, !221, !175}
!569 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !570, line: 205)
!570 = !DISubprogram(name: "wcspbrk", scope: !360, file: !360, line: 201, type: !571, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!571 = !DISubroutineType(types: !572)
!572 = !{!174, !221, !221}
!573 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !574, line: 206)
!574 = !DISubprogram(name: "wcsrchr", scope: !360, file: !360, line: 174, type: !567, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!575 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !576, line: 207)
!576 = !DISubprogram(name: "wcsstr", scope: !360, file: !360, line: 212, type: !571, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!577 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !578, line: 208)
!578 = !DISubprogram(name: "wmemchr", scope: !360, file: !360, line: 253, type: !579, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!579 = !DISubroutineType(types: !580)
!580 = !{!174, !221, !175, !125}
!581 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !582, line: 248)
!582 = !DISubprogram(name: "wcstold", scope: !360, file: !360, line: 384, type: !583, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!583 = !DISubroutineType(types: !584)
!584 = !{!267, !220, !521}
!585 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !586, line: 257)
!586 = !DISubprogram(name: "wcstoll", scope: !360, file: !360, line: 441, type: !587, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!587 = !DISubroutineType(types: !588)
!588 = !{!233, !220, !521, !82}
!589 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !590, line: 258)
!590 = !DISubprogram(name: "wcstoull", scope: !360, file: !360, line: 448, type: !591, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!591 = !DISubroutineType(types: !592)
!592 = !{!257, !220, !521, !82}
!593 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !582, line: 264)
!594 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !586, line: 265)
!595 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !590, line: 266)
!596 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !524, line: 280)
!597 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !452, line: 283)
!598 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !458, line: 286)
!599 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !466, line: 289)
!600 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !582, line: 293)
!601 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !586, line: 294)
!602 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !590, line: 295)
!603 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !604, line: 48)
!604 = !DIDerivedType(tag: DW_TAG_typedef, name: "int8_t", file: !9, line: 235, baseType: !605)
!605 = !DIBasicType(name: "signed char", size: 8, encoding: DW_ATE_signed_char)
!606 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !607, line: 49)
!607 = !DIDerivedType(tag: DW_TAG_typedef, name: "int16_t", file: !9, line: 216, baseType: !608)
!608 = !DIBasicType(name: "short", size: 16, encoding: DW_ATE_signed)
!609 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !610, line: 50)
!610 = !DIDerivedType(tag: DW_TAG_typedef, name: "int32_t", file: !9, line: 178, baseType: !82)
!611 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !612, line: 51)
!612 = !DIDerivedType(tag: DW_TAG_typedef, name: "int64_t", file: !9, line: 107, baseType: !91)
!613 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !614, line: 53)
!614 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast8_t", file: !9, line: 245, baseType: !604)
!615 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !616, line: 54)
!616 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast16_t", file: !9, line: 228, baseType: !607)
!617 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !618, line: 55)
!618 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast32_t", file: !9, line: 197, baseType: !610)
!619 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !620, line: 56)
!620 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast64_t", file: !9, line: 123, baseType: !612)
!621 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !622, line: 58)
!622 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least8_t", file: !9, line: 243, baseType: !604)
!623 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !624, line: 59)
!624 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least16_t", file: !9, line: 226, baseType: !607)
!625 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !626, line: 60)
!626 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least32_t", file: !9, line: 195, baseType: !610)
!627 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !628, line: 61)
!628 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least64_t", file: !9, line: 121, baseType: !612)
!629 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !630, line: 63)
!630 = !DIDerivedType(tag: DW_TAG_typedef, name: "intmax_t", file: !9, line: 276, baseType: !91)
!631 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !632, line: 64)
!632 = !DIDerivedType(tag: DW_TAG_typedef, name: "intptr_t", file: !9, line: 263, baseType: !612)
!633 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !62, line: 66)
!634 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !28, line: 67)
!635 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !8, line: 68)
!636 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !637, line: 69)
!637 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint64_t", file: !9, line: 109, baseType: !127)
!638 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !639, line: 71)
!639 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast8_t", file: !9, line: 246, baseType: !62)
!640 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !641, line: 72)
!641 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast16_t", file: !9, line: 229, baseType: !28)
!642 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !643, line: 73)
!643 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast32_t", file: !9, line: 198, baseType: !8)
!644 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !645, line: 74)
!645 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast64_t", file: !9, line: 124, baseType: !637)
!646 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !647, line: 76)
!647 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least8_t", file: !9, line: 244, baseType: !62)
!648 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !649, line: 77)
!649 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least16_t", file: !9, line: 227, baseType: !28)
!650 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !651, line: 78)
!651 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least32_t", file: !9, line: 196, baseType: !8)
!652 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !653, line: 79)
!653 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least64_t", file: !9, line: 122, baseType: !637)
!654 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !655, line: 81)
!655 = !DIDerivedType(tag: DW_TAG_typedef, name: "uintmax_t", file: !9, line: 277, baseType: !127)
!656 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !657, line: 82)
!657 = !DIDerivedType(tag: DW_TAG_typedef, name: "uintptr_t", file: !9, line: 270, baseType: !637)
!658 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !659, line: 44)
!659 = !DIDerivedType(tag: DW_TAG_typedef, name: "size_t", scope: !75, file: !76, line: 231, baseType: !127)
!660 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !661, line: 45)
!661 = !DIDerivedType(tag: DW_TAG_typedef, name: "ptrdiff_t", scope: !75, file: !76, line: 232, baseType: !91)
!662 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !663, line: 53)
!663 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "lconv", file: !664, line: 51, flags: DIFlagFwdDecl, identifier: "_ZTS5lconv")
!664 = !DIFile(filename: "/usr/include/locale.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!665 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !666, line: 54)
!666 = !DISubprogram(name: "setlocale", scope: !664, file: !664, line: 122, type: !667, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!667 = !DISubroutineType(types: !668)
!668 = !{!152, !82, !109}
!669 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !670, line: 55)
!670 = !DISubprogram(name: "localeconv", scope: !664, file: !664, line: 125, type: !671, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!671 = !DISubroutineType(types: !672)
!672 = !{!673}
!673 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !663, size: 64)
!674 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !675, line: 64)
!675 = !DISubprogram(name: "isalnum", scope: !676, file: !676, line: 108, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!676 = !DIFile(filename: "/usr/include/ctype.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!677 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !678, line: 65)
!678 = !DISubprogram(name: "isalpha", scope: !676, file: !676, line: 109, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!679 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !680, line: 66)
!680 = !DISubprogram(name: "iscntrl", scope: !676, file: !676, line: 110, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!681 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !682, line: 67)
!682 = !DISubprogram(name: "isdigit", scope: !676, file: !676, line: 111, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!683 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !684, line: 68)
!684 = !DISubprogram(name: "isgraph", scope: !676, file: !676, line: 113, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!685 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !686, line: 69)
!686 = !DISubprogram(name: "islower", scope: !676, file: !676, line: 112, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!687 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !688, line: 70)
!688 = !DISubprogram(name: "isprint", scope: !676, file: !676, line: 114, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!689 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !690, line: 71)
!690 = !DISubprogram(name: "ispunct", scope: !676, file: !676, line: 115, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!691 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !692, line: 72)
!692 = !DISubprogram(name: "isspace", scope: !676, file: !676, line: 116, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!693 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !694, line: 73)
!694 = !DISubprogram(name: "isupper", scope: !676, file: !676, line: 117, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!695 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !696, line: 74)
!696 = !DISubprogram(name: "isxdigit", scope: !676, file: !676, line: 118, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!697 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !698, line: 75)
!698 = !DISubprogram(name: "tolower", scope: !676, file: !676, line: 122, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!699 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !700, line: 76)
!700 = !DISubprogram(name: "toupper", scope: !676, file: !676, line: 125, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!701 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !702, line: 87)
!702 = !DISubprogram(name: "isblank", scope: !676, file: !676, line: 130, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!703 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !704, line: 98)
!704 = !DIDerivedType(tag: DW_TAG_typedef, name: "FILE", file: !705, line: 7, baseType: !370)
!705 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/FILE.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!706 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !707, line: 99)
!707 = !DIDerivedType(tag: DW_TAG_typedef, name: "fpos_t", file: !708, line: 78, baseType: !709)
!708 = !DIFile(filename: "/usr/include/stdio.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!709 = !DIDerivedType(tag: DW_TAG_typedef, name: "_G_fpos_t", file: !710, line: 30, baseType: !711)
!710 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/_G_config.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!711 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !710, line: 26, flags: DIFlagFwdDecl, identifier: "_ZTS9_G_fpos_t")
!712 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !713, line: 101)
!713 = !DISubprogram(name: "clearerr", scope: !708, file: !708, line: 757, type: !714, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!714 = !DISubroutineType(types: !715)
!715 = !{null, !716}
!716 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !704, size: 64)
!717 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !718, line: 102)
!718 = !DISubprogram(name: "fclose", scope: !708, file: !708, line: 199, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!719 = !DISubroutineType(types: !720)
!720 = !{!82, !716}
!721 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !722, line: 103)
!722 = !DISubprogram(name: "feof", scope: !708, file: !708, line: 759, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!723 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !724, line: 104)
!724 = !DISubprogram(name: "ferror", scope: !708, file: !708, line: 761, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!725 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !726, line: 105)
!726 = !DISubprogram(name: "fflush", scope: !708, file: !708, line: 204, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!727 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !728, line: 106)
!728 = !DISubprogram(name: "fgetc", scope: !708, file: !708, line: 477, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!729 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !730, line: 107)
!730 = !DISubprogram(name: "fgetpos", scope: !708, file: !708, line: 731, type: !731, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!731 = !DISubroutineType(types: !732)
!732 = !{!82, !733, !734}
!733 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !716)
!734 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !735)
!735 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !707, size: 64)
!736 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !737, line: 108)
!737 = !DISubprogram(name: "fgets", scope: !708, file: !708, line: 564, type: !738, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!738 = !DISubroutineType(types: !739)
!739 = !{!152, !219, !82, !733}
!740 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !741, line: 109)
!741 = !DISubprogram(name: "fopen", scope: !708, file: !708, line: 232, type: !742, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!742 = !DISubroutineType(types: !743)
!743 = !{!716, !176, !176}
!744 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !745, line: 110)
!745 = !DISubprogram(name: "fprintf", scope: !708, file: !708, line: 312, type: !746, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!746 = !DISubroutineType(types: !747)
!747 = !{!82, !733, !176, null}
!748 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !749, line: 111)
!749 = !DISubprogram(name: "fputc", scope: !708, file: !708, line: 517, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!750 = !DISubroutineType(types: !751)
!751 = !{!82, !82, !716}
!752 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !753, line: 112)
!753 = !DISubprogram(name: "fputs", scope: !708, file: !708, line: 626, type: !754, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!754 = !DISubroutineType(types: !755)
!755 = !{!82, !176, !733}
!756 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !757, line: 113)
!757 = !DISubprogram(name: "fread", scope: !708, file: !708, line: 646, type: !758, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!758 = !DISubroutineType(types: !759)
!759 = !{!125, !760, !125, !125, !733}
!760 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !124)
!761 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !762, line: 114)
!762 = !DISubprogram(name: "freopen", scope: !708, file: !708, line: 238, type: !763, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!763 = !DISubroutineType(types: !764)
!764 = !{!716, !176, !176, !733}
!765 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !766, line: 115)
!766 = !DISubprogram(name: "fscanf", scope: !708, file: !708, line: 377, type: !746, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!767 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !768, line: 116)
!768 = !DISubprogram(name: "fseek", scope: !708, file: !708, line: 684, type: !769, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!769 = !DISubroutineType(types: !770)
!770 = !{!82, !716, !91, !82}
!771 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !772, line: 117)
!772 = !DISubprogram(name: "fsetpos", scope: !708, file: !708, line: 736, type: !773, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!773 = !DISubroutineType(types: !774)
!774 = !{!82, !716, !775}
!775 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !776, size: 64)
!776 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !707)
!777 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !778, line: 118)
!778 = !DISubprogram(name: "ftell", scope: !708, file: !708, line: 689, type: !779, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!779 = !DISubroutineType(types: !780)
!780 = !{!91, !716}
!781 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !782, line: 119)
!782 = !DISubprogram(name: "fwrite", scope: !708, file: !708, line: 652, type: !783, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!783 = !DISubroutineType(types: !784)
!784 = !{!125, !785, !125, !125, !733}
!785 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !68)
!786 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !787, line: 120)
!787 = !DISubprogram(name: "getc", scope: !708, file: !708, line: 478, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!788 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !789, line: 121)
!789 = !DISubprogram(name: "getchar", scope: !708, file: !708, line: 484, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!790 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !791, line: 124)
!791 = !DISubprogram(name: "gets", scope: !708, file: !708, line: 577, type: !792, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!792 = !DISubroutineType(types: !793)
!793 = !{!152, !152}
!794 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !795, line: 126)
!795 = !DISubprogram(name: "perror", scope: !708, file: !708, line: 775, type: !796, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!796 = !DISubroutineType(types: !797)
!797 = !{null, !109}
!798 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !799, line: 127)
!799 = !DISubprogram(name: "printf", scope: !708, file: !708, line: 318, type: !800, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!800 = !DISubroutineType(types: !801)
!801 = !{!82, !176, null}
!802 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !803, line: 128)
!803 = !DISubprogram(name: "putc", scope: !708, file: !708, line: 518, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!804 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !805, line: 129)
!805 = !DISubprogram(name: "putchar", scope: !708, file: !708, line: 524, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!806 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !807, line: 130)
!807 = !DISubprogram(name: "puts", scope: !708, file: !708, line: 632, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!808 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !809, line: 131)
!809 = !DISubprogram(name: "remove", scope: !708, file: !708, line: 144, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!810 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !811, line: 132)
!811 = !DISubprogram(name: "rename", scope: !708, file: !708, line: 146, type: !812, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!812 = !DISubroutineType(types: !813)
!813 = !{!82, !109, !109}
!814 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !815, line: 133)
!815 = !DISubprogram(name: "rewind", scope: !708, file: !708, line: 694, type: !714, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!816 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !817, line: 134)
!817 = !DISubprogram(name: "scanf", scope: !708, file: !708, line: 383, type: !800, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!818 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !819, line: 135)
!819 = !DISubprogram(name: "setbuf", scope: !708, file: !708, line: 290, type: !820, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!820 = !DISubroutineType(types: !821)
!821 = !{null, !733, !219}
!822 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !823, line: 136)
!823 = !DISubprogram(name: "setvbuf", scope: !708, file: !708, line: 294, type: !824, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!824 = !DISubroutineType(types: !825)
!825 = !{!82, !733, !219, !82, !125}
!826 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !827, line: 137)
!827 = !DISubprogram(name: "sprintf", scope: !708, file: !708, line: 320, type: !828, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!828 = !DISubroutineType(types: !829)
!829 = !{!82, !219, !176, null}
!830 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !831, line: 138)
!831 = !DISubprogram(name: "sscanf", scope: !708, file: !708, line: 385, type: !832, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!832 = !DISubroutineType(types: !833)
!833 = !{!82, !176, !176, null}
!834 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !835, line: 139)
!835 = !DISubprogram(name: "tmpfile", scope: !708, file: !708, line: 159, type: !836, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!836 = !DISubroutineType(types: !837)
!837 = !{!716}
!838 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !839, line: 141)
!839 = !DISubprogram(name: "tmpnam", scope: !708, file: !708, line: 173, type: !792, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!840 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !841, line: 143)
!841 = !DISubprogram(name: "ungetc", scope: !708, file: !708, line: 639, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!842 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !843, line: 144)
!843 = !DISubprogram(name: "vfprintf", scope: !708, file: !708, line: 327, type: !844, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!844 = !DISubroutineType(types: !845)
!845 = !{!82, !733, !176, !444}
!846 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !847, line: 145)
!847 = !DISubprogram(name: "vprintf", scope: !708, file: !708, line: 333, type: !848, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!848 = !DISubroutineType(types: !849)
!849 = !{!82, !176, !444}
!850 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !851, line: 146)
!851 = !DISubprogram(name: "vsprintf", scope: !708, file: !708, line: 335, type: !852, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!852 = !DISubroutineType(types: !853)
!853 = !{!82, !219, !176, !444}
!854 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !855, line: 175)
!855 = !DISubprogram(name: "snprintf", scope: !708, file: !708, line: 340, type: !856, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!856 = !DISubroutineType(types: !857)
!857 = !{!82, !219, !125, !176, null}
!858 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !859, line: 176)
!859 = !DISubprogram(name: "vfscanf", scope: !708, file: !708, line: 420, type: !844, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!860 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !861, line: 177)
!861 = !DISubprogram(name: "vscanf", scope: !708, file: !708, line: 428, type: !848, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!862 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !863, line: 178)
!863 = !DISubprogram(name: "vsnprintf", scope: !708, file: !708, line: 344, type: !864, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!864 = !DISubroutineType(types: !865)
!865 = !{!82, !219, !125, !176, !444}
!866 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !867, line: 179)
!867 = !DISubprogram(name: "vsscanf", scope: !708, file: !708, line: 432, type: !868, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!868 = !DISubroutineType(types: !869)
!869 = !{!82, !176, !176, !444}
!870 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !855, line: 185)
!871 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !859, line: 186)
!872 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !861, line: 187)
!873 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !863, line: 188)
!874 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !867, line: 189)
!875 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !876, line: 83)
!876 = !DISubprogram(name: "acos", scope: !877, file: !877, line: 53, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!877 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/mathcalls.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!878 = !DISubroutineType(types: !879)
!879 = !{!108, !108}
!880 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !881, line: 102)
!881 = !DISubprogram(name: "asin", scope: !877, file: !877, line: 55, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!882 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !883, line: 121)
!883 = !DISubprogram(name: "atan", scope: !877, file: !877, line: 57, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!884 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !885, line: 140)
!885 = !DISubprogram(name: "atan2", scope: !877, file: !877, line: 59, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!886 = !DISubroutineType(types: !887)
!887 = !{!108, !108, !108}
!888 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !889, line: 161)
!889 = !DISubprogram(name: "ceil", scope: !877, file: !877, line: 159, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!890 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !891, line: 180)
!891 = !DISubprogram(name: "cos", scope: !877, file: !877, line: 62, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!892 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !893, line: 199)
!893 = !DISubprogram(name: "cosh", scope: !877, file: !877, line: 71, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!894 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !895, line: 218)
!895 = !DISubprogram(name: "exp", scope: !877, file: !877, line: 95, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!896 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !897, line: 237)
!897 = !DISubprogram(name: "fabs", scope: !877, file: !877, line: 162, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!898 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !899, line: 256)
!899 = !DISubprogram(name: "floor", scope: !877, file: !877, line: 165, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!900 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !901, line: 275)
!901 = !DISubprogram(name: "fmod", scope: !877, file: !877, line: 168, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!902 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !903, line: 296)
!903 = !DISubprogram(name: "frexp", scope: !877, file: !877, line: 98, type: !904, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!904 = !DISubroutineType(types: !905)
!905 = !{!108, !108, !906}
!906 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !82, size: 64)
!907 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !908, line: 315)
!908 = !DISubprogram(name: "ldexp", scope: !877, file: !877, line: 101, type: !909, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!909 = !DISubroutineType(types: !910)
!910 = !{!108, !108, !82}
!911 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !912, line: 334)
!912 = !DISubprogram(name: "log", scope: !877, file: !877, line: 104, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!913 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !914, line: 353)
!914 = !DISubprogram(name: "log10", scope: !877, file: !877, line: 107, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!915 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !916, line: 372)
!916 = !DISubprogram(name: "modf", scope: !877, file: !877, line: 110, type: !917, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!917 = !DISubroutineType(types: !918)
!918 = !{!108, !108, !919}
!919 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !108, size: 64)
!920 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !921, line: 384)
!921 = !DISubprogram(name: "pow", scope: !877, file: !877, line: 140, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!922 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !923, line: 421)
!923 = !DISubprogram(name: "sin", scope: !877, file: !877, line: 64, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!924 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !925, line: 440)
!925 = !DISubprogram(name: "sinh", scope: !877, file: !877, line: 73, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!926 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !927, line: 459)
!927 = !DISubprogram(name: "sqrt", scope: !877, file: !877, line: 143, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!928 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !929, line: 478)
!929 = !DISubprogram(name: "tan", scope: !877, file: !877, line: 66, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!930 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !931, line: 497)
!931 = !DISubprogram(name: "tanh", scope: !877, file: !877, line: 75, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!932 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !933, line: 1080)
!933 = !DIDerivedType(tag: DW_TAG_typedef, name: "double_t", file: !934, line: 150, baseType: !108)
!934 = !DIFile(filename: "/usr/include/math.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!935 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !936, line: 1081)
!936 = !DIDerivedType(tag: DW_TAG_typedef, name: "float_t", file: !934, line: 149, baseType: !262)
!937 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !938, line: 1084)
!938 = !DISubprogram(name: "acosh", scope: !877, file: !877, line: 85, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!939 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !940, line: 1085)
!940 = !DISubprogram(name: "acoshf", scope: !877, file: !877, line: 85, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!941 = !DISubroutineType(types: !942)
!942 = !{!262, !262}
!943 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !944, line: 1086)
!944 = !DISubprogram(name: "acoshl", scope: !877, file: !877, line: 85, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!945 = !DISubroutineType(types: !946)
!946 = !{!267, !267}
!947 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !948, line: 1088)
!948 = !DISubprogram(name: "asinh", scope: !877, file: !877, line: 87, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!949 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !950, line: 1089)
!950 = !DISubprogram(name: "asinhf", scope: !877, file: !877, line: 87, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!951 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !952, line: 1090)
!952 = !DISubprogram(name: "asinhl", scope: !877, file: !877, line: 87, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!953 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !954, line: 1092)
!954 = !DISubprogram(name: "atanh", scope: !877, file: !877, line: 89, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!955 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !956, line: 1093)
!956 = !DISubprogram(name: "atanhf", scope: !877, file: !877, line: 89, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!957 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !958, line: 1094)
!958 = !DISubprogram(name: "atanhl", scope: !877, file: !877, line: 89, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!959 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !960, line: 1096)
!960 = !DISubprogram(name: "cbrt", scope: !877, file: !877, line: 152, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!961 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !962, line: 1097)
!962 = !DISubprogram(name: "cbrtf", scope: !877, file: !877, line: 152, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!963 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !964, line: 1098)
!964 = !DISubprogram(name: "cbrtl", scope: !877, file: !877, line: 152, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!965 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !966, line: 1100)
!966 = !DISubprogram(name: "copysign", scope: !877, file: !877, line: 196, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!967 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !968, line: 1101)
!968 = !DISubprogram(name: "copysignf", scope: !877, file: !877, line: 196, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!969 = !DISubroutineType(types: !970)
!970 = !{!262, !262, !262}
!971 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !972, line: 1102)
!972 = !DISubprogram(name: "copysignl", scope: !877, file: !877, line: 196, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!973 = !DISubroutineType(types: !974)
!974 = !{!267, !267, !267}
!975 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !976, line: 1104)
!976 = !DISubprogram(name: "erf", scope: !877, file: !877, line: 228, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!977 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !978, line: 1105)
!978 = !DISubprogram(name: "erff", scope: !877, file: !877, line: 228, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!979 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !980, line: 1106)
!980 = !DISubprogram(name: "erfl", scope: !877, file: !877, line: 228, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!981 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !982, line: 1108)
!982 = !DISubprogram(name: "erfc", scope: !877, file: !877, line: 229, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!983 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !984, line: 1109)
!984 = !DISubprogram(name: "erfcf", scope: !877, file: !877, line: 229, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!985 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !986, line: 1110)
!986 = !DISubprogram(name: "erfcl", scope: !877, file: !877, line: 229, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!987 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !988, line: 1112)
!988 = !DISubprogram(name: "exp2", scope: !877, file: !877, line: 130, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!989 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !990, line: 1113)
!990 = !DISubprogram(name: "exp2f", scope: !877, file: !877, line: 130, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!991 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !992, line: 1114)
!992 = !DISubprogram(name: "exp2l", scope: !877, file: !877, line: 130, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!993 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !994, line: 1116)
!994 = !DISubprogram(name: "expm1", scope: !877, file: !877, line: 119, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!995 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !996, line: 1117)
!996 = !DISubprogram(name: "expm1f", scope: !877, file: !877, line: 119, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!997 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !998, line: 1118)
!998 = !DISubprogram(name: "expm1l", scope: !877, file: !877, line: 119, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!999 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1000, line: 1120)
!1000 = !DISubprogram(name: "fdim", scope: !877, file: !877, line: 326, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1001 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1002, line: 1121)
!1002 = !DISubprogram(name: "fdimf", scope: !877, file: !877, line: 326, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1003 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1004, line: 1122)
!1004 = !DISubprogram(name: "fdiml", scope: !877, file: !877, line: 326, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1005 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1006, line: 1124)
!1006 = !DISubprogram(name: "fma", scope: !877, file: !877, line: 335, type: !1007, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1007 = !DISubroutineType(types: !1008)
!1008 = !{!108, !108, !108, !108}
!1009 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1010, line: 1125)
!1010 = !DISubprogram(name: "fmaf", scope: !877, file: !877, line: 335, type: !1011, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1011 = !DISubroutineType(types: !1012)
!1012 = !{!262, !262, !262, !262}
!1013 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1014, line: 1126)
!1014 = !DISubprogram(name: "fmal", scope: !877, file: !877, line: 335, type: !1015, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1015 = !DISubroutineType(types: !1016)
!1016 = !{!267, !267, !267, !267}
!1017 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1018, line: 1128)
!1018 = !DISubprogram(name: "fmax", scope: !877, file: !877, line: 329, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1019 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1020, line: 1129)
!1020 = !DISubprogram(name: "fmaxf", scope: !877, file: !877, line: 329, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1021 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1022, line: 1130)
!1022 = !DISubprogram(name: "fmaxl", scope: !877, file: !877, line: 329, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1023 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1024, line: 1132)
!1024 = !DISubprogram(name: "fmin", scope: !877, file: !877, line: 332, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1025 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1026, line: 1133)
!1026 = !DISubprogram(name: "fminf", scope: !877, file: !877, line: 332, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1027 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1028, line: 1134)
!1028 = !DISubprogram(name: "fminl", scope: !877, file: !877, line: 332, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1029 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1030, line: 1136)
!1030 = !DISubprogram(name: "hypot", scope: !877, file: !877, line: 147, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1031 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1032, line: 1137)
!1032 = !DISubprogram(name: "hypotf", scope: !877, file: !877, line: 147, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1033 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1034, line: 1138)
!1034 = !DISubprogram(name: "hypotl", scope: !877, file: !877, line: 147, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1035 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1036, line: 1140)
!1036 = !DISubprogram(name: "ilogb", scope: !877, file: !877, line: 280, type: !1037, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1037 = !DISubroutineType(types: !1038)
!1038 = !{!82, !108}
!1039 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1040, line: 1141)
!1040 = !DISubprogram(name: "ilogbf", scope: !877, file: !877, line: 280, type: !1041, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1041 = !DISubroutineType(types: !1042)
!1042 = !{!82, !262}
!1043 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1044, line: 1142)
!1044 = !DISubprogram(name: "ilogbl", scope: !877, file: !877, line: 280, type: !1045, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1045 = !DISubroutineType(types: !1046)
!1046 = !{!82, !267}
!1047 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1048, line: 1144)
!1048 = !DISubprogram(name: "lgamma", scope: !877, file: !877, line: 230, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1049 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1050, line: 1145)
!1050 = !DISubprogram(name: "lgammaf", scope: !877, file: !877, line: 230, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1051 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1052, line: 1146)
!1052 = !DISubprogram(name: "lgammal", scope: !877, file: !877, line: 230, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1053 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1054, line: 1149)
!1054 = !DISubprogram(name: "llrint", scope: !877, file: !877, line: 316, type: !1055, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1055 = !DISubroutineType(types: !1056)
!1056 = !{!233, !108}
!1057 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1058, line: 1150)
!1058 = !DISubprogram(name: "llrintf", scope: !877, file: !877, line: 316, type: !1059, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1059 = !DISubroutineType(types: !1060)
!1060 = !{!233, !262}
!1061 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1062, line: 1151)
!1062 = !DISubprogram(name: "llrintl", scope: !877, file: !877, line: 316, type: !1063, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1063 = !DISubroutineType(types: !1064)
!1064 = !{!233, !267}
!1065 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1066, line: 1153)
!1066 = !DISubprogram(name: "llround", scope: !877, file: !877, line: 322, type: !1055, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1067 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1068, line: 1154)
!1068 = !DISubprogram(name: "llroundf", scope: !877, file: !877, line: 322, type: !1059, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1069 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1070, line: 1155)
!1070 = !DISubprogram(name: "llroundl", scope: !877, file: !877, line: 322, type: !1063, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1071 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1072, line: 1158)
!1072 = !DISubprogram(name: "log1p", scope: !877, file: !877, line: 122, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1073 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1074, line: 1159)
!1074 = !DISubprogram(name: "log1pf", scope: !877, file: !877, line: 122, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1075 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1076, line: 1160)
!1076 = !DISubprogram(name: "log1pl", scope: !877, file: !877, line: 122, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1077 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1078, line: 1162)
!1078 = !DISubprogram(name: "log2", scope: !877, file: !877, line: 133, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1079 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1080, line: 1163)
!1080 = !DISubprogram(name: "log2f", scope: !877, file: !877, line: 133, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1081 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1082, line: 1164)
!1082 = !DISubprogram(name: "log2l", scope: !877, file: !877, line: 133, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1083 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1084, line: 1166)
!1084 = !DISubprogram(name: "logb", scope: !877, file: !877, line: 125, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1085 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1086, line: 1167)
!1086 = !DISubprogram(name: "logbf", scope: !877, file: !877, line: 125, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1087 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1088, line: 1168)
!1088 = !DISubprogram(name: "logbl", scope: !877, file: !877, line: 125, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1089 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1090, line: 1170)
!1090 = !DISubprogram(name: "lrint", scope: !877, file: !877, line: 314, type: !1091, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1091 = !DISubroutineType(types: !1092)
!1092 = !{!91, !108}
!1093 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1094, line: 1171)
!1094 = !DISubprogram(name: "lrintf", scope: !877, file: !877, line: 314, type: !1095, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1095 = !DISubroutineType(types: !1096)
!1096 = !{!91, !262}
!1097 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1098, line: 1172)
!1098 = !DISubprogram(name: "lrintl", scope: !877, file: !877, line: 314, type: !1099, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1099 = !DISubroutineType(types: !1100)
!1100 = !{!91, !267}
!1101 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1102, line: 1174)
!1102 = !DISubprogram(name: "lround", scope: !877, file: !877, line: 320, type: !1091, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1103 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1104, line: 1175)
!1104 = !DISubprogram(name: "lroundf", scope: !877, file: !877, line: 320, type: !1095, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1105 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1106, line: 1176)
!1106 = !DISubprogram(name: "lroundl", scope: !877, file: !877, line: 320, type: !1099, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1107 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1108, line: 1178)
!1108 = !DISubprogram(name: "nan", scope: !877, file: !877, line: 201, type: !106, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1109 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1110, line: 1179)
!1110 = !DISubprogram(name: "nanf", scope: !877, file: !877, line: 201, type: !1111, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1111 = !DISubroutineType(types: !1112)
!1112 = !{!262, !109}
!1113 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1114, line: 1180)
!1114 = !DISubprogram(name: "nanl", scope: !877, file: !877, line: 201, type: !1115, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1115 = !DISubroutineType(types: !1116)
!1116 = !{!267, !109}
!1117 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1118, line: 1182)
!1118 = !DISubprogram(name: "nearbyint", scope: !877, file: !877, line: 294, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1119 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1120, line: 1183)
!1120 = !DISubprogram(name: "nearbyintf", scope: !877, file: !877, line: 294, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1121 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1122, line: 1184)
!1122 = !DISubprogram(name: "nearbyintl", scope: !877, file: !877, line: 294, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1123 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1124, line: 1186)
!1124 = !DISubprogram(name: "nextafter", scope: !877, file: !877, line: 259, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1125 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1126, line: 1187)
!1126 = !DISubprogram(name: "nextafterf", scope: !877, file: !877, line: 259, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1127 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1128, line: 1188)
!1128 = !DISubprogram(name: "nextafterl", scope: !877, file: !877, line: 259, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1129 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1130, line: 1190)
!1130 = !DISubprogram(name: "nexttoward", scope: !877, file: !877, line: 261, type: !1131, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1131 = !DISubroutineType(types: !1132)
!1132 = !{!108, !108, !267}
!1133 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1134, line: 1191)
!1134 = !DISubprogram(name: "nexttowardf", scope: !877, file: !877, line: 261, type: !1135, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1135 = !DISubroutineType(types: !1136)
!1136 = !{!262, !262, !267}
!1137 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1138, line: 1192)
!1138 = !DISubprogram(name: "nexttowardl", scope: !877, file: !877, line: 261, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1139 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1140, line: 1194)
!1140 = !DISubprogram(name: "remainder", scope: !877, file: !877, line: 272, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1141 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1142, line: 1195)
!1142 = !DISubprogram(name: "remainderf", scope: !877, file: !877, line: 272, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1143 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1144, line: 1196)
!1144 = !DISubprogram(name: "remainderl", scope: !877, file: !877, line: 272, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1145 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1146, line: 1198)
!1146 = !DISubprogram(name: "remquo", scope: !877, file: !877, line: 307, type: !1147, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1147 = !DISubroutineType(types: !1148)
!1148 = !{!108, !108, !108, !906}
!1149 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1150, line: 1199)
!1150 = !DISubprogram(name: "remquof", scope: !877, file: !877, line: 307, type: !1151, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1151 = !DISubroutineType(types: !1152)
!1152 = !{!262, !262, !262, !906}
!1153 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1154, line: 1200)
!1154 = !DISubprogram(name: "remquol", scope: !877, file: !877, line: 307, type: !1155, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1155 = !DISubroutineType(types: !1156)
!1156 = !{!267, !267, !267, !906}
!1157 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1158, line: 1202)
!1158 = !DISubprogram(name: "rint", scope: !877, file: !877, line: 256, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1159 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1160, line: 1203)
!1160 = !DISubprogram(name: "rintf", scope: !877, file: !877, line: 256, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1161 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1162, line: 1204)
!1162 = !DISubprogram(name: "rintl", scope: !877, file: !877, line: 256, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1163 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1164, line: 1206)
!1164 = !DISubprogram(name: "round", scope: !877, file: !877, line: 298, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1165 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1166, line: 1207)
!1166 = !DISubprogram(name: "roundf", scope: !877, file: !877, line: 298, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1167 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1168, line: 1208)
!1168 = !DISubprogram(name: "roundl", scope: !877, file: !877, line: 298, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1169 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1170, line: 1210)
!1170 = !DISubprogram(name: "scalbln", scope: !877, file: !877, line: 290, type: !1171, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1171 = !DISubroutineType(types: !1172)
!1172 = !{!108, !108, !91}
!1173 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1174, line: 1211)
!1174 = !DISubprogram(name: "scalblnf", scope: !877, file: !877, line: 290, type: !1175, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1175 = !DISubroutineType(types: !1176)
!1176 = !{!262, !262, !91}
!1177 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1178, line: 1212)
!1178 = !DISubprogram(name: "scalblnl", scope: !877, file: !877, line: 290, type: !1179, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1179 = !DISubroutineType(types: !1180)
!1180 = !{!267, !267, !91}
!1181 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1182, line: 1214)
!1182 = !DISubprogram(name: "scalbn", scope: !877, file: !877, line: 276, type: !909, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1183 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1184, line: 1215)
!1184 = !DISubprogram(name: "scalbnf", scope: !877, file: !877, line: 276, type: !1185, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1185 = !DISubroutineType(types: !1186)
!1186 = !{!262, !262, !82}
!1187 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1188, line: 1216)
!1188 = !DISubprogram(name: "scalbnl", scope: !877, file: !877, line: 276, type: !1189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1189 = !DISubroutineType(types: !1190)
!1190 = !{!267, !267, !82}
!1191 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1192, line: 1218)
!1192 = !DISubprogram(name: "tgamma", scope: !877, file: !877, line: 235, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1193 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1194, line: 1219)
!1194 = !DISubprogram(name: "tgammaf", scope: !877, file: !877, line: 235, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1195 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1196, line: 1220)
!1196 = !DISubprogram(name: "tgammal", scope: !877, file: !877, line: 235, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1197 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1198, line: 1222)
!1198 = !DISubprogram(name: "trunc", scope: !877, file: !877, line: 302, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1199 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1200, line: 1223)
!1200 = !DISubprogram(name: "truncf", scope: !877, file: !877, line: 302, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1201 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1202, line: 1224)
!1202 = !DISubprogram(name: "truncl", scope: !877, file: !877, line: 302, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1203 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1204, line: 58)
!1204 = !DIDerivedType(tag: DW_TAG_typedef, name: "fenv_t", file: !1205, line: 94, baseType: !1206)
!1205 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/fenv.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1206 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !1205, line: 75, flags: DIFlagFwdDecl, identifier: "_ZTS6fenv_t")
!1207 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1208, line: 59)
!1208 = !DIDerivedType(tag: DW_TAG_typedef, name: "fexcept_t", file: !1205, line: 68, baseType: !29)
!1209 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1210, line: 62)
!1210 = !DISubprogram(name: "feclearexcept", scope: !1211, file: !1211, line: 71, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1211 = !DIFile(filename: "/usr/include/fenv.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1212 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1213, line: 63)
!1213 = !DISubprogram(name: "fegetexceptflag", scope: !1211, file: !1211, line: 75, type: !1214, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1214 = !DISubroutineType(types: !1215)
!1215 = !{!82, !1216, !82}
!1216 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1208, size: 64)
!1217 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1218, line: 64)
!1218 = !DISubprogram(name: "feraiseexcept", scope: !1211, file: !1211, line: 78, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1219 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1220, line: 65)
!1220 = !DISubprogram(name: "fesetexceptflag", scope: !1211, file: !1211, line: 88, type: !1221, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1221 = !DISubroutineType(types: !1222)
!1222 = !{!82, !1223, !82}
!1223 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1224, size: 64)
!1224 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !1208)
!1225 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1226, line: 66)
!1226 = !DISubprogram(name: "fetestexcept", scope: !1211, file: !1211, line: 92, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1227 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1228, line: 68)
!1228 = !DISubprogram(name: "fegetround", scope: !1211, file: !1211, line: 104, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1229 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1230, line: 69)
!1230 = !DISubprogram(name: "fesetround", scope: !1211, file: !1211, line: 107, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1231 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1232, line: 71)
!1232 = !DISubprogram(name: "fegetenv", scope: !1211, file: !1211, line: 114, type: !1233, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1233 = !DISubroutineType(types: !1234)
!1234 = !{!82, !1235}
!1235 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1204, size: 64)
!1236 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1237, line: 72)
!1237 = !DISubprogram(name: "feholdexcept", scope: !1211, file: !1211, line: 119, type: !1233, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1238 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1239, line: 73)
!1239 = !DISubprogram(name: "fesetenv", scope: !1211, file: !1211, line: 123, type: !1240, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1240 = !DISubroutineType(types: !1241)
!1241 = !{!82, !1242}
!1242 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1243, size: 64)
!1243 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !1204)
!1244 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1245, line: 74)
!1245 = !DISubprogram(name: "feupdateenv", scope: !1211, file: !1211, line: 128, type: !1240, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1246 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1204, line: 61)
!1247 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1208, line: 62)
!1248 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1210, line: 65)
!1249 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1213, line: 66)
!1250 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1218, line: 67)
!1251 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1220, line: 68)
!1252 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1226, line: 69)
!1253 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1228, line: 71)
!1254 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1230, line: 72)
!1255 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1232, line: 74)
!1256 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1237, line: 75)
!1257 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1239, line: 76)
!1258 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1245, line: 77)
!1259 = !{i32 2, !"Dwarf Version", i32 4}
!1260 = !{i32 2, !"Debug Info Version", i32 3}
!1261 = distinct !DISubprogram(name: "__remill_basic_block", scope: !2, file: !2, line: 52, type: !1262, isLocal: false, isDefinition: true, scopeLine: 52, flags: DIFlagPrototyped, isOptimized: false, unit: !1, variables: !7)
!1262 = !DISubroutineType(types: !1263)
!1263 = !{!1264, !1267, !1950, !1264}
!1264 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1265, size: 64)
!1265 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Memory", file: !1266, line: 36, flags: DIFlagFwdDecl, identifier: "_ZTS6Memory")
!1266 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/Types.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1267 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !1268, size: 64)
!1268 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "State", file: !27, line: 742, size: 27008, align: 128, elements: !1269, identifier: "_ZTS5State")
!1269 = !{!1270, !1282, !1491, !1511, !1541, !1566, !1595, !1632, !1642, !1703, !1728, !1752, !1932}
!1270 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1268, baseType: !1271)
!1271 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "ArchState", file: !1272, line: 21, size: 128, elements: !1273, identifier: "_ZTS9ArchState")
!1272 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/State.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1273 = !{!1274, !1275, !1276}
!1274 = !DIDerivedType(tag: DW_TAG_member, name: "hyper_call", scope: !1271, file: !1272, line: 23, baseType: !4, size: 32)
!1275 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1271, file: !1272, line: 25, baseType: !8, size: 32, offset: 32)
!1276 = !DIDerivedType(tag: DW_TAG_member, scope: !1271, file: !1272, line: 31, baseType: !1277, size: 64, offset: 64)
!1277 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1271, file: !1272, line: 31, size: 64, elements: !1278, identifier: "_ZTSN9ArchStateUt_E")
!1278 = !{!1279, !1280, !1281}
!1279 = !DIDerivedType(tag: DW_TAG_member, name: "addr_to_load", scope: !1277, file: !1272, line: 32, baseType: !637, size: 64)
!1280 = !DIDerivedType(tag: DW_TAG_member, name: "addr_to_store", scope: !1277, file: !1272, line: 33, baseType: !637, size: 64)
!1281 = !DIDerivedType(tag: DW_TAG_member, name: "hyper_call_vector", scope: !1277, file: !1272, line: 34, baseType: !8, size: 32)
!1282 = !DIDerivedType(tag: DW_TAG_member, name: "vec", scope: !1268, file: !27, line: 747, baseType: !1283, size: 16384, offset: 128)
!1283 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1284, size: 16384, elements: !1369)
!1284 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "VectorReg", file: !27, line: 636, size: 512, align: 128, elements: !1285, identifier: "_ZTS9VectorReg")
!1285 = !{!1286, !1361, !1426}
!1286 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1284, file: !27, line: 637, baseType: !1287, size: 128, align: 128)
!1287 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec128_t", file: !1266, line: 317, size: 128, elements: !1288, identifier: "_ZTS8vec128_t")
!1288 = !{!1289, !1298, !1305, !1312, !1317, !1324, !1329, !1334, !1339, !1344, !1349, !1354}
!1289 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1287, file: !1266, line: 321, baseType: !1290, size: 128)
!1290 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v1_t", file: !1266, line: 205, size: 128, elements: !1291, identifier: "_ZTS11uint128v1_t")
!1291 = !{!1292}
!1292 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1290, file: !1266, line: 205, baseType: !1293, size: 128)
!1293 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 128, elements: !1296)
!1294 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint128_t", file: !1266, line: 46, baseType: !1295)
!1295 = !DIBasicType(name: "unsigned __int128", size: 128, encoding: DW_ATE_unsigned)
!1296 = !{!1297}
!1297 = !DISubrange(count: 1)
!1298 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1287, file: !1266, line: 323, baseType: !1299, size: 128)
!1299 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v16_t", file: !1266, line: 182, size: 128, elements: !1300, identifier: "_ZTS10uint8v16_t")
!1300 = !{!1301}
!1301 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1299, file: !1266, line: 182, baseType: !1302, size: 128)
!1302 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 128, elements: !1303)
!1303 = !{!1304}
!1304 = !DISubrange(count: 16)
!1305 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1287, file: !1266, line: 324, baseType: !1306, size: 128)
!1306 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v8_t", file: !1266, line: 189, size: 128, elements: !1307, identifier: "_ZTS10uint16v8_t")
!1307 = !{!1308}
!1308 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1306, file: !1266, line: 189, baseType: !1309, size: 128)
!1309 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 128, elements: !1310)
!1310 = !{!1311}
!1311 = !DISubrange(count: 8)
!1312 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1287, file: !1266, line: 325, baseType: !1313, size: 128)
!1313 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v4_t", file: !1266, line: 195, size: 128, elements: !1314, identifier: "_ZTS10uint32v4_t")
!1314 = !{!1315}
!1315 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1313, file: !1266, line: 195, baseType: !1316, size: 128)
!1316 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 128, elements: !353)
!1317 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1287, file: !1266, line: 326, baseType: !1318, size: 128)
!1318 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v2_t", file: !1266, line: 200, size: 128, elements: !1319, identifier: "_ZTS10uint64v2_t")
!1319 = !{!1320}
!1320 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1318, file: !1266, line: 200, baseType: !1321, size: 128)
!1321 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 128, elements: !1322)
!1322 = !{!1323}
!1323 = !DISubrange(count: 2)
!1324 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1287, file: !1266, line: 327, baseType: !1325, size: 128)
!1325 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v4_t", file: !1266, line: 242, size: 128, elements: !1326, identifier: "_ZTS11float32v4_t")
!1326 = !{!1327}
!1327 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1325, file: !1266, line: 242, baseType: !1328, size: 128)
!1328 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 128, elements: !353)
!1329 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1287, file: !1266, line: 328, baseType: !1330, size: 128)
!1330 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v2_t", file: !1266, line: 247, size: 128, elements: !1331, identifier: "_ZTS11float64v2_t")
!1331 = !{!1332}
!1332 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1330, file: !1266, line: 247, baseType: !1333, size: 128)
!1333 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 128, elements: !1322)
!1334 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1287, file: !1266, line: 330, baseType: !1335, size: 128)
!1335 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v16_t", file: !1266, line: 213, size: 128, elements: !1336, identifier: "_ZTS9int8v16_t")
!1336 = !{!1337}
!1337 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1335, file: !1266, line: 213, baseType: !1338, size: 128)
!1338 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 128, elements: !1303)
!1339 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1287, file: !1266, line: 331, baseType: !1340, size: 128)
!1340 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v8_t", file: !1266, line: 220, size: 128, elements: !1341, identifier: "_ZTS9int16v8_t")
!1341 = !{!1342}
!1342 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1340, file: !1266, line: 220, baseType: !1343, size: 128)
!1343 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 128, elements: !1310)
!1344 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1287, file: !1266, line: 332, baseType: !1345, size: 128)
!1345 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v4_t", file: !1266, line: 226, size: 128, elements: !1346, identifier: "_ZTS9int32v4_t")
!1346 = !{!1347}
!1347 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1345, file: !1266, line: 226, baseType: !1348, size: 128)
!1348 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 128, elements: !353)
!1349 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1287, file: !1266, line: 333, baseType: !1350, size: 128)
!1350 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v2_t", file: !1266, line: 231, size: 128, elements: !1351, identifier: "_ZTS9int64v2_t")
!1351 = !{!1352}
!1352 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1350, file: !1266, line: 231, baseType: !1353, size: 128)
!1353 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 128, elements: !1322)
!1354 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1287, file: !1266, line: 334, baseType: !1355, size: 128)
!1355 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v1_t", file: !1266, line: 236, size: 128, elements: !1356, identifier: "_ZTS10int128v1_t")
!1356 = !{!1357}
!1357 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1355, file: !1266, line: 236, baseType: !1358, size: 128)
!1358 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 128, elements: !1296)
!1359 = !DIDerivedType(tag: DW_TAG_typedef, name: "int128_t", file: !1266, line: 47, baseType: !1360)
!1360 = !DIBasicType(name: "__int128", size: 128, encoding: DW_ATE_signed)
!1361 = !DIDerivedType(tag: DW_TAG_member, name: "ymm", scope: !1284, file: !27, line: 638, baseType: !1362, size: 256, align: 128)
!1362 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec256_t", file: !1266, line: 340, size: 256, elements: !1363, identifier: "_ZTS8vec256_t")
!1363 = !{!1364, !1371, !1376, !1381, !1386, !1391, !1396, !1401, !1406, !1411, !1416, !1421}
!1364 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1362, file: !1266, line: 341, baseType: !1365, size: 256)
!1365 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v32_t", file: !1266, line: 183, size: 256, elements: !1366, identifier: "_ZTS10uint8v32_t")
!1366 = !{!1367}
!1367 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1365, file: !1266, line: 183, baseType: !1368, size: 256)
!1368 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 256, elements: !1369)
!1369 = !{!1370}
!1370 = !DISubrange(count: 32)
!1371 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1362, file: !1266, line: 342, baseType: !1372, size: 256)
!1372 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v16_t", file: !1266, line: 190, size: 256, elements: !1373, identifier: "_ZTS11uint16v16_t")
!1373 = !{!1374}
!1374 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1372, file: !1266, line: 190, baseType: !1375, size: 256)
!1375 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 256, elements: !1303)
!1376 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1362, file: !1266, line: 343, baseType: !1377, size: 256)
!1377 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v8_t", file: !1266, line: 196, size: 256, elements: !1378, identifier: "_ZTS10uint32v8_t")
!1378 = !{!1379}
!1379 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1377, file: !1266, line: 196, baseType: !1380, size: 256)
!1380 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 256, elements: !1310)
!1381 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1362, file: !1266, line: 344, baseType: !1382, size: 256)
!1382 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v4_t", file: !1266, line: 201, size: 256, elements: !1383, identifier: "_ZTS10uint64v4_t")
!1383 = !{!1384}
!1384 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1382, file: !1266, line: 201, baseType: !1385, size: 256)
!1385 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 256, elements: !353)
!1386 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1362, file: !1266, line: 345, baseType: !1387, size: 256)
!1387 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v2_t", file: !1266, line: 206, size: 256, elements: !1388, identifier: "_ZTS11uint128v2_t")
!1388 = !{!1389}
!1389 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1387, file: !1266, line: 206, baseType: !1390, size: 256)
!1390 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 256, elements: !1322)
!1391 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1362, file: !1266, line: 346, baseType: !1392, size: 256)
!1392 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v8_t", file: !1266, line: 243, size: 256, elements: !1393, identifier: "_ZTS11float32v8_t")
!1393 = !{!1394}
!1394 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1392, file: !1266, line: 243, baseType: !1395, size: 256)
!1395 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 256, elements: !1310)
!1396 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1362, file: !1266, line: 347, baseType: !1397, size: 256)
!1397 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v4_t", file: !1266, line: 248, size: 256, elements: !1398, identifier: "_ZTS11float64v4_t")
!1398 = !{!1399}
!1399 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1397, file: !1266, line: 248, baseType: !1400, size: 256)
!1400 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 256, elements: !353)
!1401 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1362, file: !1266, line: 349, baseType: !1402, size: 256)
!1402 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v32_t", file: !1266, line: 214, size: 256, elements: !1403, identifier: "_ZTS9int8v32_t")
!1403 = !{!1404}
!1404 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1402, file: !1266, line: 214, baseType: !1405, size: 256)
!1405 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 256, elements: !1369)
!1406 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1362, file: !1266, line: 350, baseType: !1407, size: 256)
!1407 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v16_t", file: !1266, line: 221, size: 256, elements: !1408, identifier: "_ZTS10int16v16_t")
!1408 = !{!1409}
!1409 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1407, file: !1266, line: 221, baseType: !1410, size: 256)
!1410 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 256, elements: !1303)
!1411 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1362, file: !1266, line: 351, baseType: !1412, size: 256)
!1412 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v8_t", file: !1266, line: 227, size: 256, elements: !1413, identifier: "_ZTS9int32v8_t")
!1413 = !{!1414}
!1414 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1412, file: !1266, line: 227, baseType: !1415, size: 256)
!1415 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 256, elements: !1310)
!1416 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1362, file: !1266, line: 352, baseType: !1417, size: 256)
!1417 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v4_t", file: !1266, line: 232, size: 256, elements: !1418, identifier: "_ZTS9int64v4_t")
!1418 = !{!1419}
!1419 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1417, file: !1266, line: 232, baseType: !1420, size: 256)
!1420 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 256, elements: !353)
!1421 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1362, file: !1266, line: 353, baseType: !1422, size: 256)
!1422 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v2_t", file: !1266, line: 237, size: 256, elements: !1423, identifier: "_ZTS10int128v2_t")
!1423 = !{!1424}
!1424 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1422, file: !1266, line: 237, baseType: !1425, size: 256)
!1425 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 256, elements: !1322)
!1426 = !DIDerivedType(tag: DW_TAG_member, name: "zmm", scope: !1284, file: !27, line: 639, baseType: !1427, size: 512, align: 128)
!1427 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec512_t", file: !1266, line: 359, size: 512, elements: !1428, identifier: "_ZTS8vec512_t")
!1428 = !{!1429, !1436, !1441, !1446, !1451, !1456, !1461, !1466, !1471, !1476, !1481, !1486}
!1429 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1427, file: !1266, line: 360, baseType: !1430, size: 512)
!1430 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v64_t", file: !1266, line: 184, size: 512, elements: !1431, identifier: "_ZTS10uint8v64_t")
!1431 = !{!1432}
!1432 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1430, file: !1266, line: 184, baseType: !1433, size: 512)
!1433 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 512, elements: !1434)
!1434 = !{!1435}
!1435 = !DISubrange(count: 64)
!1436 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1427, file: !1266, line: 361, baseType: !1437, size: 512)
!1437 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v32_t", file: !1266, line: 191, size: 512, elements: !1438, identifier: "_ZTS11uint16v32_t")
!1438 = !{!1439}
!1439 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1437, file: !1266, line: 191, baseType: !1440, size: 512)
!1440 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 512, elements: !1369)
!1441 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1427, file: !1266, line: 362, baseType: !1442, size: 512)
!1442 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v16_t", file: !1266, line: 197, size: 512, elements: !1443, identifier: "_ZTS11uint32v16_t")
!1443 = !{!1444}
!1444 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1442, file: !1266, line: 197, baseType: !1445, size: 512)
!1445 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 512, elements: !1303)
!1446 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1427, file: !1266, line: 363, baseType: !1447, size: 512)
!1447 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v8_t", file: !1266, line: 202, size: 512, elements: !1448, identifier: "_ZTS10uint64v8_t")
!1448 = !{!1449}
!1449 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1447, file: !1266, line: 202, baseType: !1450, size: 512)
!1450 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 512, elements: !1310)
!1451 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1427, file: !1266, line: 364, baseType: !1452, size: 512)
!1452 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v4_t", file: !1266, line: 207, size: 512, elements: !1453, identifier: "_ZTS11uint128v4_t")
!1453 = !{!1454}
!1454 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1452, file: !1266, line: 207, baseType: !1455, size: 512)
!1455 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 512, elements: !353)
!1456 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1427, file: !1266, line: 365, baseType: !1457, size: 512)
!1457 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v16_t", file: !1266, line: 244, size: 512, elements: !1458, identifier: "_ZTS12float32v16_t")
!1458 = !{!1459}
!1459 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1457, file: !1266, line: 244, baseType: !1460, size: 512)
!1460 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 512, elements: !1303)
!1461 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1427, file: !1266, line: 366, baseType: !1462, size: 512)
!1462 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v8_t", file: !1266, line: 249, size: 512, elements: !1463, identifier: "_ZTS11float64v8_t")
!1463 = !{!1464}
!1464 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1462, file: !1266, line: 249, baseType: !1465, size: 512)
!1465 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 512, elements: !1310)
!1466 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1427, file: !1266, line: 368, baseType: !1467, size: 512)
!1467 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v64_t", file: !1266, line: 215, size: 512, elements: !1468, identifier: "_ZTS9int8v64_t")
!1468 = !{!1469}
!1469 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1467, file: !1266, line: 215, baseType: !1470, size: 512)
!1470 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 512, elements: !1434)
!1471 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1427, file: !1266, line: 369, baseType: !1472, size: 512)
!1472 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v32_t", file: !1266, line: 222, size: 512, elements: !1473, identifier: "_ZTS10int16v32_t")
!1473 = !{!1474}
!1474 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1472, file: !1266, line: 222, baseType: !1475, size: 512)
!1475 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 512, elements: !1369)
!1476 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1427, file: !1266, line: 370, baseType: !1477, size: 512)
!1477 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v16_t", file: !1266, line: 228, size: 512, elements: !1478, identifier: "_ZTS10int32v16_t")
!1478 = !{!1479}
!1479 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1477, file: !1266, line: 228, baseType: !1480, size: 512)
!1480 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 512, elements: !1303)
!1481 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1427, file: !1266, line: 371, baseType: !1482, size: 512)
!1482 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v8_t", file: !1266, line: 233, size: 512, elements: !1483, identifier: "_ZTS9int64v8_t")
!1483 = !{!1484}
!1484 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1482, file: !1266, line: 233, baseType: !1485, size: 512)
!1485 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 512, elements: !1310)
!1486 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1427, file: !1266, line: 372, baseType: !1487, size: 512)
!1487 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v4_t", file: !1266, line: 238, size: 512, elements: !1488, identifier: "_ZTS10int128v4_t")
!1488 = !{!1489}
!1489 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1487, file: !1266, line: 238, baseType: !1490, size: 512)
!1490 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 512, elements: !353)
!1491 = !DIDerivedType(tag: DW_TAG_member, name: "aflag", scope: !1268, file: !27, line: 751, baseType: !1492, size: 128, align: 64, offset: 16512)
!1492 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "ArithFlags", file: !27, line: 402, size: 128, align: 64, elements: !1493, identifier: "_ZTS10ArithFlags")
!1493 = !{!1494, !1496, !1497, !1498, !1499, !1500, !1501, !1502, !1503, !1504, !1505, !1506, !1507, !1508, !1509, !1510}
!1494 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1492, file: !27, line: 404, baseType: !1495, size: 8)
!1495 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !62)
!1496 = !DIDerivedType(tag: DW_TAG_member, name: "cf", scope: !1492, file: !27, line: 405, baseType: !62, size: 8, offset: 8)
!1497 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1492, file: !27, line: 406, baseType: !1495, size: 8, offset: 16)
!1498 = !DIDerivedType(tag: DW_TAG_member, name: "pf", scope: !1492, file: !27, line: 407, baseType: !62, size: 8, offset: 24)
!1499 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1492, file: !27, line: 408, baseType: !1495, size: 8, offset: 32)
!1500 = !DIDerivedType(tag: DW_TAG_member, name: "af", scope: !1492, file: !27, line: 409, baseType: !62, size: 8, offset: 40)
!1501 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1492, file: !27, line: 410, baseType: !1495, size: 8, offset: 48)
!1502 = !DIDerivedType(tag: DW_TAG_member, name: "zf", scope: !1492, file: !27, line: 411, baseType: !62, size: 8, offset: 56)
!1503 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1492, file: !27, line: 412, baseType: !1495, size: 8, offset: 64)
!1504 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1492, file: !27, line: 413, baseType: !62, size: 8, offset: 72)
!1505 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1492, file: !27, line: 414, baseType: !1495, size: 8, offset: 80)
!1506 = !DIDerivedType(tag: DW_TAG_member, name: "df", scope: !1492, file: !27, line: 415, baseType: !62, size: 8, offset: 88)
!1507 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1492, file: !27, line: 416, baseType: !1495, size: 8, offset: 96)
!1508 = !DIDerivedType(tag: DW_TAG_member, name: "of", scope: !1492, file: !27, line: 417, baseType: !62, size: 8, offset: 104)
!1509 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1492, file: !27, line: 418, baseType: !1495, size: 8, offset: 112)
!1510 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1492, file: !27, line: 419, baseType: !1495, size: 8, offset: 120)
!1511 = !DIDerivedType(tag: DW_TAG_member, name: "rflag", scope: !1268, file: !27, line: 752, baseType: !1512, size: 64, align: 64, offset: 16640)
!1512 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "Flags", file: !27, line: 366, size: 64, align: 64, elements: !1513, identifier: "_ZTS5Flags")
!1513 = !{!1514, !1515}
!1514 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1512, file: !27, line: 367, baseType: !637, size: 64)
!1515 = !DIDerivedType(tag: DW_TAG_member, scope: !1512, file: !27, line: 368, baseType: !1516, size: 64)
!1516 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1512, file: !27, line: 368, size: 64, elements: !1517, identifier: "_ZTSN5FlagsUt_E")
!1517 = !{!1518, !1519, !1520, !1521, !1522, !1523, !1524, !1525, !1526, !1527, !1528, !1529, !1530, !1531, !1532, !1533, !1534, !1535, !1536, !1537, !1538, !1539, !1540}
!1518 = !DIDerivedType(tag: DW_TAG_member, name: "cf", scope: !1516, file: !27, line: 369, baseType: !8, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1519 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_1", scope: !1516, file: !27, line: 370, baseType: !8, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1520 = !DIDerivedType(tag: DW_TAG_member, name: "pf", scope: !1516, file: !27, line: 371, baseType: !8, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1521 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0a", scope: !1516, file: !27, line: 372, baseType: !8, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1522 = !DIDerivedType(tag: DW_TAG_member, name: "af", scope: !1516, file: !27, line: 374, baseType: !8, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1523 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0b", scope: !1516, file: !27, line: 375, baseType: !8, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1524 = !DIDerivedType(tag: DW_TAG_member, name: "zf", scope: !1516, file: !27, line: 376, baseType: !8, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1525 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1516, file: !27, line: 377, baseType: !8, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1526 = !DIDerivedType(tag: DW_TAG_member, name: "tf", scope: !1516, file: !27, line: 379, baseType: !8, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1527 = !DIDerivedType(tag: DW_TAG_member, name: "_if", scope: !1516, file: !27, line: 380, baseType: !8, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1528 = !DIDerivedType(tag: DW_TAG_member, name: "df", scope: !1516, file: !27, line: 381, baseType: !8, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1529 = !DIDerivedType(tag: DW_TAG_member, name: "of", scope: !1516, file: !27, line: 382, baseType: !8, size: 1, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1530 = !DIDerivedType(tag: DW_TAG_member, name: "iopl", scope: !1516, file: !27, line: 384, baseType: !8, size: 2, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1531 = !DIDerivedType(tag: DW_TAG_member, name: "nt", scope: !1516, file: !27, line: 385, baseType: !8, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1532 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0c", scope: !1516, file: !27, line: 386, baseType: !8, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1533 = !DIDerivedType(tag: DW_TAG_member, name: "rf", scope: !1516, file: !27, line: 388, baseType: !8, size: 1, offset: 16, flags: DIFlagBitField, extraData: i64 0)
!1534 = !DIDerivedType(tag: DW_TAG_member, name: "vm", scope: !1516, file: !27, line: 389, baseType: !8, size: 1, offset: 17, flags: DIFlagBitField, extraData: i64 0)
!1535 = !DIDerivedType(tag: DW_TAG_member, name: "ac", scope: !1516, file: !27, line: 390, baseType: !8, size: 1, offset: 18, flags: DIFlagBitField, extraData: i64 0)
!1536 = !DIDerivedType(tag: DW_TAG_member, name: "vif", scope: !1516, file: !27, line: 391, baseType: !8, size: 1, offset: 19, flags: DIFlagBitField, extraData: i64 0)
!1537 = !DIDerivedType(tag: DW_TAG_member, name: "vip", scope: !1516, file: !27, line: 393, baseType: !8, size: 1, offset: 20, flags: DIFlagBitField, extraData: i64 0)
!1538 = !DIDerivedType(tag: DW_TAG_member, name: "id", scope: !1516, file: !27, line: 394, baseType: !8, size: 1, offset: 21, flags: DIFlagBitField, extraData: i64 0)
!1539 = !DIDerivedType(tag: DW_TAG_member, name: "reserved_eflags", scope: !1516, file: !27, line: 395, baseType: !8, size: 10, offset: 22, flags: DIFlagBitField, extraData: i64 0)
!1540 = !DIDerivedType(tag: DW_TAG_member, name: "reserved_rflags", scope: !1516, file: !27, line: 396, baseType: !8, size: 32, offset: 32)
!1541 = !DIDerivedType(tag: DW_TAG_member, name: "seg", scope: !1268, file: !27, line: 753, baseType: !1542, size: 192, align: 64, offset: 16704)
!1542 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Segments", file: !27, line: 451, size: 192, align: 64, elements: !1543, identifier: "_ZTS8Segments")
!1543 = !{!1544, !1546, !1556, !1557, !1558, !1559, !1560, !1561, !1562, !1563, !1564, !1565}
!1544 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1542, file: !27, line: 452, baseType: !1545, size: 16)
!1545 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !28)
!1546 = !DIDerivedType(tag: DW_TAG_member, name: "ss", scope: !1542, file: !27, line: 453, baseType: !1547, size: 16, offset: 16)
!1547 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "SegmentSelector", file: !27, line: 76, size: 16, elements: !1548, identifier: "_ZTS15SegmentSelector")
!1548 = !{!1549, !1550}
!1549 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1547, file: !27, line: 77, baseType: !28, size: 16)
!1550 = !DIDerivedType(tag: DW_TAG_member, scope: !1547, file: !27, line: 78, baseType: !1551, size: 16)
!1551 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1547, file: !27, line: 78, size: 16, elements: !1552, identifier: "_ZTSN15SegmentSelectorUt_E")
!1552 = !{!1553, !1554, !1555}
!1553 = !DIDerivedType(tag: DW_TAG_member, name: "rpi", scope: !1551, file: !27, line: 79, baseType: !26, size: 2, flags: DIFlagBitField, extraData: i64 0)
!1554 = !DIDerivedType(tag: DW_TAG_member, name: "ti", scope: !1551, file: !27, line: 80, baseType: !35, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1555 = !DIDerivedType(tag: DW_TAG_member, name: "index", scope: !1551, file: !27, line: 81, baseType: !28, size: 13, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1556 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1542, file: !27, line: 454, baseType: !1545, size: 16, offset: 32)
!1557 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1542, file: !27, line: 455, baseType: !1547, size: 16, offset: 48)
!1558 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1542, file: !27, line: 456, baseType: !1545, size: 16, offset: 64)
!1559 = !DIDerivedType(tag: DW_TAG_member, name: "gs", scope: !1542, file: !27, line: 457, baseType: !1547, size: 16, offset: 80)
!1560 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1542, file: !27, line: 458, baseType: !1545, size: 16, offset: 96)
!1561 = !DIDerivedType(tag: DW_TAG_member, name: "fs", scope: !1542, file: !27, line: 459, baseType: !1547, size: 16, offset: 112)
!1562 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1542, file: !27, line: 460, baseType: !1545, size: 16, offset: 128)
!1563 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1542, file: !27, line: 461, baseType: !1547, size: 16, offset: 144)
!1564 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1542, file: !27, line: 462, baseType: !1545, size: 16, offset: 160)
!1565 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1542, file: !27, line: 463, baseType: !1547, size: 16, offset: 176)
!1566 = !DIDerivedType(tag: DW_TAG_member, name: "addr", scope: !1268, file: !27, line: 754, baseType: !1567, size: 768, align: 64, offset: 16896)
!1567 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "AddressSpace", file: !27, line: 654, size: 768, align: 64, elements: !1568, identifier: "_ZTS12AddressSpace")
!1568 = !{!1569, !1571, !1585, !1586, !1587, !1588, !1589, !1590, !1591, !1592, !1593, !1594}
!1569 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1567, file: !27, line: 655, baseType: !1570, size: 64)
!1570 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !637)
!1571 = !DIDerivedType(tag: DW_TAG_member, name: "ss_base", scope: !1567, file: !27, line: 656, baseType: !1572, size: 64, offset: 64)
!1572 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Reg", file: !27, line: 610, size: 64, elements: !1573, identifier: "_ZTS3Reg")
!1573 = !{!1574}
!1574 = !DIDerivedType(tag: DW_TAG_member, scope: !1572, file: !27, line: 611, baseType: !1575, size: 64)
!1575 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1572, file: !27, line: 611, size: 64, elements: !1576, identifier: "_ZTSN3RegUt_E")
!1576 = !{!1577, !1582, !1583, !1584}
!1577 = !DIDerivedType(tag: DW_TAG_member, name: "byte", scope: !1575, file: !27, line: 615, baseType: !1578, size: 16, align: 8)
!1578 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1575, file: !27, line: 612, size: 16, elements: !1579, identifier: "_ZTSN3RegUt_Ut_E")
!1579 = !{!1580, !1581}
!1580 = !DIDerivedType(tag: DW_TAG_member, name: "low", scope: !1578, file: !27, line: 613, baseType: !62, size: 8)
!1581 = !DIDerivedType(tag: DW_TAG_member, name: "high", scope: !1578, file: !27, line: 614, baseType: !62, size: 8, offset: 8)
!1582 = !DIDerivedType(tag: DW_TAG_member, name: "word", scope: !1575, file: !27, line: 616, baseType: !28, size: 16, align: 16)
!1583 = !DIDerivedType(tag: DW_TAG_member, name: "dword", scope: !1575, file: !27, line: 617, baseType: !8, size: 32, align: 32)
!1584 = !DIDerivedType(tag: DW_TAG_member, name: "qword", scope: !1575, file: !27, line: 618, baseType: !637, size: 64, align: 64)
!1585 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1567, file: !27, line: 657, baseType: !1570, size: 64, offset: 128)
!1586 = !DIDerivedType(tag: DW_TAG_member, name: "es_base", scope: !1567, file: !27, line: 658, baseType: !1572, size: 64, offset: 192)
!1587 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1567, file: !27, line: 659, baseType: !1570, size: 64, offset: 256)
!1588 = !DIDerivedType(tag: DW_TAG_member, name: "gs_base", scope: !1567, file: !27, line: 660, baseType: !1572, size: 64, offset: 320)
!1589 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1567, file: !27, line: 661, baseType: !1570, size: 64, offset: 384)
!1590 = !DIDerivedType(tag: DW_TAG_member, name: "fs_base", scope: !1567, file: !27, line: 662, baseType: !1572, size: 64, offset: 448)
!1591 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1567, file: !27, line: 663, baseType: !1570, size: 64, offset: 512)
!1592 = !DIDerivedType(tag: DW_TAG_member, name: "ds_base", scope: !1567, file: !27, line: 664, baseType: !1572, size: 64, offset: 576)
!1593 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1567, file: !27, line: 665, baseType: !1570, size: 64, offset: 640)
!1594 = !DIDerivedType(tag: DW_TAG_member, name: "cs_base", scope: !1567, file: !27, line: 666, baseType: !1572, size: 64, offset: 704)
!1595 = !DIDerivedType(tag: DW_TAG_member, name: "gpr", scope: !1268, file: !27, line: 755, baseType: !1596, size: 2176, align: 64, offset: 17664)
!1596 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "GPR", file: !27, line: 677, size: 2176, align: 64, elements: !1597, identifier: "_ZTS3GPR")
!1597 = !{!1598, !1599, !1600, !1601, !1602, !1603, !1604, !1605, !1606, !1607, !1608, !1609, !1610, !1611, !1612, !1613, !1614, !1615, !1616, !1617, !1618, !1619, !1620, !1621, !1622, !1623, !1624, !1625, !1626, !1627, !1628, !1629, !1630, !1631}
!1598 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1596, file: !27, line: 679, baseType: !1570, size: 64)
!1599 = !DIDerivedType(tag: DW_TAG_member, name: "rax", scope: !1596, file: !27, line: 680, baseType: !1572, size: 64, offset: 64)
!1600 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1596, file: !27, line: 681, baseType: !1570, size: 64, offset: 128)
!1601 = !DIDerivedType(tag: DW_TAG_member, name: "rbx", scope: !1596, file: !27, line: 682, baseType: !1572, size: 64, offset: 192)
!1602 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1596, file: !27, line: 683, baseType: !1570, size: 64, offset: 256)
!1603 = !DIDerivedType(tag: DW_TAG_member, name: "rcx", scope: !1596, file: !27, line: 684, baseType: !1572, size: 64, offset: 320)
!1604 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1596, file: !27, line: 685, baseType: !1570, size: 64, offset: 384)
!1605 = !DIDerivedType(tag: DW_TAG_member, name: "rdx", scope: !1596, file: !27, line: 686, baseType: !1572, size: 64, offset: 448)
!1606 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1596, file: !27, line: 687, baseType: !1570, size: 64, offset: 512)
!1607 = !DIDerivedType(tag: DW_TAG_member, name: "rsi", scope: !1596, file: !27, line: 688, baseType: !1572, size: 64, offset: 576)
!1608 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1596, file: !27, line: 689, baseType: !1570, size: 64, offset: 640)
!1609 = !DIDerivedType(tag: DW_TAG_member, name: "rdi", scope: !1596, file: !27, line: 690, baseType: !1572, size: 64, offset: 704)
!1610 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1596, file: !27, line: 691, baseType: !1570, size: 64, offset: 768)
!1611 = !DIDerivedType(tag: DW_TAG_member, name: "rsp", scope: !1596, file: !27, line: 692, baseType: !1572, size: 64, offset: 832)
!1612 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1596, file: !27, line: 693, baseType: !1570, size: 64, offset: 896)
!1613 = !DIDerivedType(tag: DW_TAG_member, name: "rbp", scope: !1596, file: !27, line: 694, baseType: !1572, size: 64, offset: 960)
!1614 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1596, file: !27, line: 695, baseType: !1570, size: 64, offset: 1024)
!1615 = !DIDerivedType(tag: DW_TAG_member, name: "r8", scope: !1596, file: !27, line: 696, baseType: !1572, size: 64, offset: 1088)
!1616 = !DIDerivedType(tag: DW_TAG_member, name: "_9", scope: !1596, file: !27, line: 697, baseType: !1570, size: 64, offset: 1152)
!1617 = !DIDerivedType(tag: DW_TAG_member, name: "r9", scope: !1596, file: !27, line: 698, baseType: !1572, size: 64, offset: 1216)
!1618 = !DIDerivedType(tag: DW_TAG_member, name: "_10", scope: !1596, file: !27, line: 699, baseType: !1570, size: 64, offset: 1280)
!1619 = !DIDerivedType(tag: DW_TAG_member, name: "r10", scope: !1596, file: !27, line: 700, baseType: !1572, size: 64, offset: 1344)
!1620 = !DIDerivedType(tag: DW_TAG_member, name: "_11", scope: !1596, file: !27, line: 701, baseType: !1570, size: 64, offset: 1408)
!1621 = !DIDerivedType(tag: DW_TAG_member, name: "r11", scope: !1596, file: !27, line: 702, baseType: !1572, size: 64, offset: 1472)
!1622 = !DIDerivedType(tag: DW_TAG_member, name: "_12", scope: !1596, file: !27, line: 703, baseType: !1570, size: 64, offset: 1536)
!1623 = !DIDerivedType(tag: DW_TAG_member, name: "r12", scope: !1596, file: !27, line: 704, baseType: !1572, size: 64, offset: 1600)
!1624 = !DIDerivedType(tag: DW_TAG_member, name: "_13", scope: !1596, file: !27, line: 705, baseType: !1570, size: 64, offset: 1664)
!1625 = !DIDerivedType(tag: DW_TAG_member, name: "r13", scope: !1596, file: !27, line: 706, baseType: !1572, size: 64, offset: 1728)
!1626 = !DIDerivedType(tag: DW_TAG_member, name: "_14", scope: !1596, file: !27, line: 707, baseType: !1570, size: 64, offset: 1792)
!1627 = !DIDerivedType(tag: DW_TAG_member, name: "r14", scope: !1596, file: !27, line: 708, baseType: !1572, size: 64, offset: 1856)
!1628 = !DIDerivedType(tag: DW_TAG_member, name: "_15", scope: !1596, file: !27, line: 709, baseType: !1570, size: 64, offset: 1920)
!1629 = !DIDerivedType(tag: DW_TAG_member, name: "r15", scope: !1596, file: !27, line: 710, baseType: !1572, size: 64, offset: 1984)
!1630 = !DIDerivedType(tag: DW_TAG_member, name: "_16", scope: !1596, file: !27, line: 711, baseType: !1570, size: 64, offset: 2048)
!1631 = !DIDerivedType(tag: DW_TAG_member, name: "rip", scope: !1596, file: !27, line: 714, baseType: !1572, size: 64, offset: 2112)
!1632 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1268, file: !27, line: 756, baseType: !1633, size: 1024, align: 64, offset: 19840)
!1633 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "X87Stack", file: !27, line: 719, size: 1024, align: 64, elements: !1634, identifier: "_ZTS8X87Stack")
!1634 = !{!1635}
!1635 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1633, file: !27, line: 723, baseType: !1636, size: 1024)
!1636 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1637, size: 1024, elements: !1310)
!1637 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1633, file: !27, line: 720, size: 128, align: 64, elements: !1638, identifier: "_ZTSN8X87StackUt_E")
!1638 = !{!1639, !1640}
!1639 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1637, file: !27, line: 721, baseType: !637, size: 64)
!1640 = !DIDerivedType(tag: DW_TAG_member, name: "val", scope: !1637, file: !27, line: 722, baseType: !1641, size: 64, offset: 64)
!1641 = !DIDerivedType(tag: DW_TAG_typedef, name: "float64_t", file: !1266, line: 61, baseType: !108)
!1642 = !DIDerivedType(tag: DW_TAG_member, name: "mmx", scope: !1268, file: !27, line: 757, baseType: !1643, size: 1024, align: 64, offset: 20864)
!1643 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "MMX", file: !27, line: 729, size: 1024, align: 64, elements: !1644, identifier: "_ZTS3MMX")
!1644 = !{!1645}
!1645 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1643, file: !27, line: 733, baseType: !1646, size: 1024)
!1646 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1647, size: 1024, elements: !1310)
!1647 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1643, file: !27, line: 730, size: 128, align: 64, elements: !1648, identifier: "_ZTSN3MMXUt_E")
!1648 = !{!1649, !1650}
!1649 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1647, file: !27, line: 731, baseType: !637, size: 64)
!1650 = !DIDerivedType(tag: DW_TAG_member, name: "val", scope: !1647, file: !27, line: 732, baseType: !1651, size: 64, offset: 64)
!1651 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec64_t", file: !1266, line: 294, size: 64, elements: !1652, identifier: "_ZTS7vec64_t")
!1652 = !{!1653, !1658, !1663, !1668, !1673, !1678, !1683, !1688, !1693, !1698}
!1653 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1651, file: !1266, line: 298, baseType: !1654, size: 64)
!1654 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v1_t", file: !1266, line: 199, size: 64, elements: !1655, identifier: "_ZTS10uint64v1_t")
!1655 = !{!1656}
!1656 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1654, file: !1266, line: 199, baseType: !1657, size: 64)
!1657 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 64, elements: !1296)
!1658 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1651, file: !1266, line: 300, baseType: !1659, size: 64)
!1659 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v8_t", file: !1266, line: 181, size: 64, elements: !1660, identifier: "_ZTS9uint8v8_t")
!1660 = !{!1661}
!1661 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1659, file: !1266, line: 181, baseType: !1662, size: 64)
!1662 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 64, elements: !1310)
!1663 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1651, file: !1266, line: 301, baseType: !1664, size: 64)
!1664 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v4_t", file: !1266, line: 188, size: 64, elements: !1665, identifier: "_ZTS10uint16v4_t")
!1665 = !{!1666}
!1666 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1664, file: !1266, line: 188, baseType: !1667, size: 64)
!1667 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 64, elements: !353)
!1668 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1651, file: !1266, line: 302, baseType: !1669, size: 64)
!1669 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v2_t", file: !1266, line: 194, size: 64, elements: !1670, identifier: "_ZTS10uint32v2_t")
!1670 = !{!1671}
!1671 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1669, file: !1266, line: 194, baseType: !1672, size: 64)
!1672 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 64, elements: !1322)
!1673 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1651, file: !1266, line: 303, baseType: !1674, size: 64)
!1674 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v2_t", file: !1266, line: 241, size: 64, elements: !1675, identifier: "_ZTS11float32v2_t")
!1675 = !{!1676}
!1676 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1674, file: !1266, line: 241, baseType: !1677, size: 64)
!1677 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 64, elements: !1322)
!1678 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1651, file: !1266, line: 304, baseType: !1679, size: 64)
!1679 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v1_t", file: !1266, line: 246, size: 64, elements: !1680, identifier: "_ZTS11float64v1_t")
!1680 = !{!1681}
!1681 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1679, file: !1266, line: 246, baseType: !1682, size: 64)
!1682 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 64, elements: !1296)
!1683 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1651, file: !1266, line: 306, baseType: !1684, size: 64)
!1684 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v8_t", file: !1266, line: 212, size: 64, elements: !1685, identifier: "_ZTS8int8v8_t")
!1685 = !{!1686}
!1686 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1684, file: !1266, line: 212, baseType: !1687, size: 64)
!1687 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 64, elements: !1310)
!1688 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1651, file: !1266, line: 307, baseType: !1689, size: 64)
!1689 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v4_t", file: !1266, line: 219, size: 64, elements: !1690, identifier: "_ZTS9int16v4_t")
!1690 = !{!1691}
!1691 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1689, file: !1266, line: 219, baseType: !1692, size: 64)
!1692 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 64, elements: !353)
!1693 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1651, file: !1266, line: 308, baseType: !1694, size: 64)
!1694 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v2_t", file: !1266, line: 225, size: 64, elements: !1695, identifier: "_ZTS9int32v2_t")
!1695 = !{!1696}
!1696 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1694, file: !1266, line: 225, baseType: !1697, size: 64)
!1697 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 64, elements: !1322)
!1698 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1651, file: !1266, line: 309, baseType: !1699, size: 64)
!1699 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v1_t", file: !1266, line: 230, size: 64, elements: !1700, identifier: "_ZTS9int64v1_t")
!1700 = !{!1701}
!1701 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1699, file: !1266, line: 230, baseType: !1702, size: 64)
!1702 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 64, elements: !1296)
!1703 = !DIDerivedType(tag: DW_TAG_member, name: "sw", scope: !1268, file: !27, line: 758, baseType: !1704, size: 192, offset: 21888)
!1704 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FPUStatusFlags", file: !27, line: 332, size: 192, elements: !1705, identifier: "_ZTS14FPUStatusFlags")
!1705 = !{!1706, !1707, !1708, !1709, !1710, !1711, !1712, !1713, !1714, !1715, !1716, !1717, !1718, !1719, !1720, !1721, !1722, !1723, !1724, !1725, !1726}
!1706 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1704, file: !27, line: 333, baseType: !62, size: 8)
!1707 = !DIDerivedType(tag: DW_TAG_member, name: "c0", scope: !1704, file: !27, line: 334, baseType: !62, size: 8, offset: 8)
!1708 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1704, file: !27, line: 335, baseType: !62, size: 8, offset: 16)
!1709 = !DIDerivedType(tag: DW_TAG_member, name: "c1", scope: !1704, file: !27, line: 336, baseType: !62, size: 8, offset: 24)
!1710 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1704, file: !27, line: 337, baseType: !62, size: 8, offset: 32)
!1711 = !DIDerivedType(tag: DW_TAG_member, name: "c2", scope: !1704, file: !27, line: 338, baseType: !62, size: 8, offset: 40)
!1712 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1704, file: !27, line: 339, baseType: !62, size: 8, offset: 48)
!1713 = !DIDerivedType(tag: DW_TAG_member, name: "c3", scope: !1704, file: !27, line: 340, baseType: !62, size: 8, offset: 56)
!1714 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1704, file: !27, line: 342, baseType: !62, size: 8, offset: 64)
!1715 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1704, file: !27, line: 343, baseType: !62, size: 8, offset: 72)
!1716 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1704, file: !27, line: 345, baseType: !62, size: 8, offset: 80)
!1717 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1704, file: !27, line: 346, baseType: !62, size: 8, offset: 88)
!1718 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1704, file: !27, line: 348, baseType: !62, size: 8, offset: 96)
!1719 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1704, file: !27, line: 349, baseType: !62, size: 8, offset: 104)
!1720 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1704, file: !27, line: 351, baseType: !62, size: 8, offset: 112)
!1721 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1704, file: !27, line: 352, baseType: !62, size: 8, offset: 120)
!1722 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1704, file: !27, line: 354, baseType: !62, size: 8, offset: 128)
!1723 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1704, file: !27, line: 355, baseType: !62, size: 8, offset: 136)
!1724 = !DIDerivedType(tag: DW_TAG_member, name: "_9", scope: !1704, file: !27, line: 357, baseType: !62, size: 8, offset: 144)
!1725 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1704, file: !27, line: 358, baseType: !62, size: 8, offset: 152)
!1726 = !DIDerivedType(tag: DW_TAG_member, name: "_padding", scope: !1704, file: !27, line: 360, baseType: !1727, size: 32, offset: 160)
!1727 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 32, elements: !353)
!1728 = !DIDerivedType(tag: DW_TAG_member, name: "xcr0", scope: !1268, file: !27, line: 759, baseType: !1729, size: 64, offset: 22080)
!1729 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "XCR0", file: !27, line: 424, size: 64, elements: !1730, identifier: "_ZTS4XCR0")
!1730 = !{!1731, !1732, !1737}
!1731 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1729, file: !27, line: 425, baseType: !637, size: 64)
!1732 = !DIDerivedType(tag: DW_TAG_member, scope: !1729, file: !27, line: 427, baseType: !1733, size: 64)
!1733 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1729, file: !27, line: 427, size: 64, elements: !1734, identifier: "_ZTSN4XCR0Ut_E")
!1734 = !{!1735, !1736}
!1735 = !DIDerivedType(tag: DW_TAG_member, name: "eax", scope: !1733, file: !27, line: 428, baseType: !8, size: 32)
!1736 = !DIDerivedType(tag: DW_TAG_member, name: "edx", scope: !1733, file: !27, line: 429, baseType: !8, size: 32, offset: 32)
!1737 = !DIDerivedType(tag: DW_TAG_member, scope: !1729, file: !27, line: 433, baseType: !1738, size: 64)
!1738 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1729, file: !27, line: 433, size: 64, elements: !1739, identifier: "_ZTSN4XCR0Ut0_E")
!1739 = !{!1740, !1741, !1742, !1743, !1744, !1745, !1746, !1747, !1748, !1749, !1750, !1751}
!1740 = !DIDerivedType(tag: DW_TAG_member, name: "x87_fpu_mmx", scope: !1738, file: !27, line: 434, baseType: !637, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1741 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1738, file: !27, line: 435, baseType: !637, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1742 = !DIDerivedType(tag: DW_TAG_member, name: "ymm", scope: !1738, file: !27, line: 436, baseType: !637, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1743 = !DIDerivedType(tag: DW_TAG_member, name: "bndreg", scope: !1738, file: !27, line: 437, baseType: !637, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1744 = !DIDerivedType(tag: DW_TAG_member, name: "bndcsr", scope: !1738, file: !27, line: 438, baseType: !637, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1745 = !DIDerivedType(tag: DW_TAG_member, name: "opmask", scope: !1738, file: !27, line: 439, baseType: !637, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1746 = !DIDerivedType(tag: DW_TAG_member, name: "zmm_hi256", scope: !1738, file: !27, line: 440, baseType: !637, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1747 = !DIDerivedType(tag: DW_TAG_member, name: "hi16_zmm", scope: !1738, file: !27, line: 441, baseType: !637, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1748 = !DIDerivedType(tag: DW_TAG_member, name: "pkru", scope: !1738, file: !27, line: 442, baseType: !637, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1749 = !DIDerivedType(tag: DW_TAG_member, name: "_reserved0", scope: !1738, file: !27, line: 443, baseType: !637, size: 53, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1750 = !DIDerivedType(tag: DW_TAG_member, name: "lwp", scope: !1738, file: !27, line: 444, baseType: !637, size: 1, offset: 62, flags: DIFlagBitField, extraData: i64 0)
!1751 = !DIDerivedType(tag: DW_TAG_member, name: "_reserved1", scope: !1738, file: !27, line: 445, baseType: !637, size: 1, offset: 63, flags: DIFlagBitField, extraData: i64 0)
!1752 = !DIDerivedType(tag: DW_TAG_member, name: "x87", scope: !1268, file: !27, line: 760, baseType: !1753, size: 4096, align: 128, offset: 22144)
!1753 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPU", file: !27, line: 314, size: 4096, align: 128, elements: !1754, identifier: "_ZTS3FPU")
!1754 = !{!1755, !1851, !1914}
!1755 = !DIDerivedType(tag: DW_TAG_member, name: "fsave", scope: !1753, file: !27, line: 317, baseType: !1756, size: 4096)
!1756 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 315, size: 4096, elements: !1757, identifier: "_ZTSN3FPUUt_E")
!1757 = !{!1758, !1847}
!1758 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1756, baseType: !1759)
!1759 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFSAVE", file: !27, line: 263, size: 1248, elements: !1760, identifier: "_ZTS8FpuFSAVE")
!1760 = !{!1761, !1779, !1780, !1801, !1802, !1817, !1818, !1819, !1820, !1821, !1822, !1823, !1824}
!1761 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1759, file: !27, line: 264, baseType: !1762, size: 16)
!1762 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUControlWord", file: !27, line: 142, size: 16, elements: !1763, identifier: "_ZTS14FPUControlWord")
!1763 = !{!1764, !1765}
!1764 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1762, file: !27, line: 143, baseType: !28, size: 16)
!1765 = !DIDerivedType(tag: DW_TAG_member, scope: !1762, file: !27, line: 144, baseType: !1766, size: 16)
!1766 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1762, file: !27, line: 144, size: 16, elements: !1767, identifier: "_ZTSN14FPUControlWordUt_E")
!1767 = !{!1768, !1769, !1770, !1771, !1772, !1773, !1774, !1775, !1776, !1777, !1778}
!1768 = !DIDerivedType(tag: DW_TAG_member, name: "im", scope: !1766, file: !27, line: 145, baseType: !28, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1769 = !DIDerivedType(tag: DW_TAG_member, name: "dm", scope: !1766, file: !27, line: 146, baseType: !28, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1770 = !DIDerivedType(tag: DW_TAG_member, name: "zm", scope: !1766, file: !27, line: 147, baseType: !28, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1771 = !DIDerivedType(tag: DW_TAG_member, name: "om", scope: !1766, file: !27, line: 148, baseType: !28, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1772 = !DIDerivedType(tag: DW_TAG_member, name: "um", scope: !1766, file: !27, line: 149, baseType: !28, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1773 = !DIDerivedType(tag: DW_TAG_member, name: "pm", scope: !1766, file: !27, line: 150, baseType: !28, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1774 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1766, file: !27, line: 151, baseType: !28, size: 2, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1775 = !DIDerivedType(tag: DW_TAG_member, name: "pc", scope: !1766, file: !27, line: 152, baseType: !39, size: 2, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1776 = !DIDerivedType(tag: DW_TAG_member, name: "rc", scope: !1766, file: !27, line: 153, baseType: !45, size: 2, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1777 = !DIDerivedType(tag: DW_TAG_member, name: "x", scope: !1766, file: !27, line: 154, baseType: !51, size: 1, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1778 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1766, file: !27, line: 155, baseType: !28, size: 3, offset: 13, flags: DIFlagBitField, extraData: i64 0)
!1779 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1759, file: !27, line: 265, baseType: !28, size: 16, offset: 16)
!1780 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1759, file: !27, line: 266, baseType: !1781, size: 16, offset: 32)
!1781 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUStatusWord", file: !27, line: 100, size: 16, elements: !1782, identifier: "_ZTS13FPUStatusWord")
!1782 = !{!1783, !1784}
!1783 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1781, file: !27, line: 101, baseType: !28, size: 16)
!1784 = !DIDerivedType(tag: DW_TAG_member, scope: !1781, file: !27, line: 102, baseType: !1785, size: 16)
!1785 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1781, file: !27, line: 102, size: 16, elements: !1786, identifier: "_ZTSN13FPUStatusWordUt_E")
!1786 = !{!1787, !1788, !1789, !1790, !1791, !1792, !1793, !1794, !1795, !1796, !1797, !1798, !1799, !1800}
!1787 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1785, file: !27, line: 103, baseType: !28, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1788 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1785, file: !27, line: 104, baseType: !28, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1789 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1785, file: !27, line: 105, baseType: !28, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1790 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1785, file: !27, line: 106, baseType: !28, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1791 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1785, file: !27, line: 107, baseType: !28, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1792 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1785, file: !27, line: 108, baseType: !28, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1793 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1785, file: !27, line: 109, baseType: !28, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1794 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1785, file: !27, line: 110, baseType: !28, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1795 = !DIDerivedType(tag: DW_TAG_member, name: "c0", scope: !1785, file: !27, line: 111, baseType: !28, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1796 = !DIDerivedType(tag: DW_TAG_member, name: "c1", scope: !1785, file: !27, line: 112, baseType: !28, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1797 = !DIDerivedType(tag: DW_TAG_member, name: "c2", scope: !1785, file: !27, line: 113, baseType: !28, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1798 = !DIDerivedType(tag: DW_TAG_member, name: "top", scope: !1785, file: !27, line: 114, baseType: !28, size: 3, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1799 = !DIDerivedType(tag: DW_TAG_member, name: "c3", scope: !1785, file: !27, line: 115, baseType: !28, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1800 = !DIDerivedType(tag: DW_TAG_member, name: "b", scope: !1785, file: !27, line: 116, baseType: !28, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1801 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1759, file: !27, line: 267, baseType: !28, size: 16, offset: 48)
!1802 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1759, file: !27, line: 268, baseType: !1803, size: 16, offset: 64)
!1803 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUTagWord", file: !27, line: 227, size: 16, elements: !1804, identifier: "_ZTS10FPUTagWord")
!1804 = !{!1805, !1806}
!1805 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1803, file: !27, line: 228, baseType: !28, size: 16)
!1806 = !DIDerivedType(tag: DW_TAG_member, scope: !1803, file: !27, line: 229, baseType: !1807, size: 16)
!1807 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1803, file: !27, line: 229, size: 16, elements: !1808, identifier: "_ZTSN10FPUTagWordUt_E")
!1808 = !{!1809, !1810, !1811, !1812, !1813, !1814, !1815, !1816}
!1809 = !DIDerivedType(tag: DW_TAG_member, name: "tag0", scope: !1807, file: !27, line: 230, baseType: !55, size: 2, flags: DIFlagBitField, extraData: i64 0)
!1810 = !DIDerivedType(tag: DW_TAG_member, name: "tag1", scope: !1807, file: !27, line: 231, baseType: !55, size: 2, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1811 = !DIDerivedType(tag: DW_TAG_member, name: "tag2", scope: !1807, file: !27, line: 232, baseType: !55, size: 2, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1812 = !DIDerivedType(tag: DW_TAG_member, name: "tag3", scope: !1807, file: !27, line: 233, baseType: !55, size: 2, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1813 = !DIDerivedType(tag: DW_TAG_member, name: "tag4", scope: !1807, file: !27, line: 234, baseType: !55, size: 2, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1814 = !DIDerivedType(tag: DW_TAG_member, name: "tag5", scope: !1807, file: !27, line: 235, baseType: !55, size: 2, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1815 = !DIDerivedType(tag: DW_TAG_member, name: "tag6", scope: !1807, file: !27, line: 236, baseType: !55, size: 2, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1816 = !DIDerivedType(tag: DW_TAG_member, name: "tag7", scope: !1807, file: !27, line: 237, baseType: !55, size: 2, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1817 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1759, file: !27, line: 269, baseType: !28, size: 16, offset: 80)
!1818 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1759, file: !27, line: 270, baseType: !8, size: 32, offset: 96)
!1819 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1759, file: !27, line: 271, baseType: !1547, size: 16, offset: 128)
!1820 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd2", scope: !1759, file: !27, line: 272, baseType: !28, size: 16, offset: 144)
!1821 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1759, file: !27, line: 273, baseType: !8, size: 32, offset: 160)
!1822 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1759, file: !27, line: 274, baseType: !1547, size: 16, offset: 192)
!1823 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd3", scope: !1759, file: !27, line: 275, baseType: !28, size: 16, offset: 208)
!1824 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1759, file: !27, line: 276, baseType: !1825, size: 1024, offset: 224)
!1825 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1826, size: 1024, elements: !1310)
!1826 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FPUStackElem", file: !27, line: 162, size: 128, elements: !1827, identifier: "_ZTS12FPUStackElem")
!1827 = !{!1828, !1843}
!1828 = !DIDerivedType(tag: DW_TAG_member, scope: !1826, file: !27, line: 163, baseType: !1829, size: 80)
!1829 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1826, file: !27, line: 163, size: 80, elements: !1830, identifier: "_ZTSN12FPUStackElemUt_E")
!1830 = !{!1831, !1838}
!1831 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1829, file: !27, line: 164, baseType: !1832, size: 80)
!1832 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float80_t", file: !1266, line: 65, size: 80, elements: !1833, identifier: "_ZTS9float80_t")
!1833 = !{!1834}
!1834 = !DIDerivedType(tag: DW_TAG_member, name: "data", scope: !1832, file: !1266, line: 66, baseType: !1835, size: 80)
!1835 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 80, elements: !1836)
!1836 = !{!1837}
!1837 = !DISubrange(count: 10)
!1838 = !DIDerivedType(tag: DW_TAG_member, scope: !1829, file: !27, line: 165, baseType: !1839, size: 80)
!1839 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1829, file: !27, line: 165, size: 80, elements: !1840, identifier: "_ZTSN12FPUStackElemUt_Ut_E")
!1840 = !{!1841, !1842}
!1841 = !DIDerivedType(tag: DW_TAG_member, name: "mmx", scope: !1839, file: !27, line: 166, baseType: !637, size: 64)
!1842 = !DIDerivedType(tag: DW_TAG_member, name: "infinity", scope: !1839, file: !27, line: 167, baseType: !28, size: 16, offset: 64)
!1843 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd", scope: !1826, file: !27, line: 170, baseType: !1844, size: 48, offset: 80)
!1844 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 48, elements: !1845)
!1845 = !{!1846}
!1846 = !DISubrange(count: 6)
!1847 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1756, file: !27, line: 316, baseType: !1848, size: 2848, offset: 1248)
!1848 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 2848, elements: !1849)
!1849 = !{!1850}
!1850 = !DISubrange(count: 356)
!1851 = !DIDerivedType(tag: DW_TAG_member, name: "fxsave32", scope: !1753, file: !27, line: 321, baseType: !1852, size: 4096)
!1852 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 319, size: 4096, elements: !1853, identifier: "_ZTSN3FPUUt0_E")
!1853 = !{!1854, !1910}
!1854 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1852, baseType: !1855)
!1855 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFXSAVE", file: !27, line: 280, size: 3328, elements: !1856, identifier: "_ZTS9FpuFXSAVE")
!1856 = !{!1857, !1858, !1859, !1874, !1875, !1876, !1877, !1878, !1879, !1880, !1881, !1882, !1906, !1907, !1908}
!1857 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1855, file: !27, line: 281, baseType: !1762, size: 16)
!1858 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1855, file: !27, line: 282, baseType: !1781, size: 16, offset: 16)
!1859 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1855, file: !27, line: 283, baseType: !1860, size: 8, offset: 32)
!1860 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUAbridgedTagWord", file: !27, line: 245, size: 8, elements: !1861, identifier: "_ZTS18FPUAbridgedTagWord")
!1861 = !{!1862, !1863}
!1862 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1860, file: !27, line: 246, baseType: !62, size: 8)
!1863 = !DIDerivedType(tag: DW_TAG_member, scope: !1860, file: !27, line: 247, baseType: !1864, size: 8)
!1864 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1860, file: !27, line: 247, size: 8, elements: !1865, identifier: "_ZTSN18FPUAbridgedTagWordUt_E")
!1865 = !{!1866, !1867, !1868, !1869, !1870, !1871, !1872, !1873}
!1866 = !DIDerivedType(tag: DW_TAG_member, name: "r0", scope: !1864, file: !27, line: 248, baseType: !61, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1867 = !DIDerivedType(tag: DW_TAG_member, name: "r1", scope: !1864, file: !27, line: 249, baseType: !61, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1868 = !DIDerivedType(tag: DW_TAG_member, name: "r2", scope: !1864, file: !27, line: 250, baseType: !61, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1869 = !DIDerivedType(tag: DW_TAG_member, name: "r3", scope: !1864, file: !27, line: 251, baseType: !61, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1870 = !DIDerivedType(tag: DW_TAG_member, name: "r4", scope: !1864, file: !27, line: 252, baseType: !61, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1871 = !DIDerivedType(tag: DW_TAG_member, name: "r5", scope: !1864, file: !27, line: 253, baseType: !61, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1872 = !DIDerivedType(tag: DW_TAG_member, name: "r6", scope: !1864, file: !27, line: 254, baseType: !61, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1873 = !DIDerivedType(tag: DW_TAG_member, name: "r7", scope: !1864, file: !27, line: 255, baseType: !61, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1874 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1855, file: !27, line: 284, baseType: !62, size: 8, offset: 40)
!1875 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1855, file: !27, line: 285, baseType: !28, size: 16, offset: 48)
!1876 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1855, file: !27, line: 286, baseType: !8, size: 32, offset: 64)
!1877 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1855, file: !27, line: 287, baseType: !1547, size: 16, offset: 96)
!1878 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1855, file: !27, line: 288, baseType: !28, size: 16, offset: 112)
!1879 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1855, file: !27, line: 289, baseType: !8, size: 32, offset: 128)
!1880 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1855, file: !27, line: 290, baseType: !1547, size: 16, offset: 160)
!1881 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd2", scope: !1855, file: !27, line: 291, baseType: !28, size: 16, offset: 176)
!1882 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr", scope: !1855, file: !27, line: 292, baseType: !1883, size: 32, offset: 192)
!1883 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUControlStatus", file: !27, line: 188, size: 32, elements: !1884, identifier: "_ZTS16FPUControlStatus")
!1884 = !{!1885, !1886}
!1885 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1883, file: !27, line: 189, baseType: !8, size: 32)
!1886 = !DIDerivedType(tag: DW_TAG_member, scope: !1883, file: !27, line: 190, baseType: !1887, size: 32)
!1887 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1883, file: !27, line: 190, size: 32, elements: !1888, identifier: "_ZTSN16FPUControlStatusUt_E")
!1888 = !{!1889, !1890, !1891, !1892, !1893, !1894, !1895, !1896, !1897, !1898, !1899, !1900, !1901, !1902, !1903, !1904, !1905}
!1889 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1887, file: !27, line: 191, baseType: !8, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1890 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1887, file: !27, line: 192, baseType: !8, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1891 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1887, file: !27, line: 193, baseType: !8, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1892 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1887, file: !27, line: 194, baseType: !8, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1893 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1887, file: !27, line: 195, baseType: !8, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1894 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1887, file: !27, line: 196, baseType: !8, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1895 = !DIDerivedType(tag: DW_TAG_member, name: "daz", scope: !1887, file: !27, line: 197, baseType: !8, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1896 = !DIDerivedType(tag: DW_TAG_member, name: "im", scope: !1887, file: !27, line: 198, baseType: !8, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1897 = !DIDerivedType(tag: DW_TAG_member, name: "dm", scope: !1887, file: !27, line: 199, baseType: !8, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1898 = !DIDerivedType(tag: DW_TAG_member, name: "zm", scope: !1887, file: !27, line: 200, baseType: !8, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1899 = !DIDerivedType(tag: DW_TAG_member, name: "om", scope: !1887, file: !27, line: 201, baseType: !8, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1900 = !DIDerivedType(tag: DW_TAG_member, name: "um", scope: !1887, file: !27, line: 202, baseType: !8, size: 1, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1901 = !DIDerivedType(tag: DW_TAG_member, name: "pm", scope: !1887, file: !27, line: 203, baseType: !8, size: 1, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1902 = !DIDerivedType(tag: DW_TAG_member, name: "rn", scope: !1887, file: !27, line: 204, baseType: !8, size: 1, offset: 13, flags: DIFlagBitField, extraData: i64 0)
!1903 = !DIDerivedType(tag: DW_TAG_member, name: "rp", scope: !1887, file: !27, line: 205, baseType: !8, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1904 = !DIDerivedType(tag: DW_TAG_member, name: "fz", scope: !1887, file: !27, line: 206, baseType: !8, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1905 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd", scope: !1887, file: !27, line: 207, baseType: !8, size: 16, offset: 16, flags: DIFlagBitField, extraData: i64 0)
!1906 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr_mask", scope: !1855, file: !27, line: 293, baseType: !1883, size: 32, offset: 224)
!1907 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1855, file: !27, line: 294, baseType: !1825, size: 1024, offset: 256)
!1908 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1855, file: !27, line: 295, baseType: !1909, size: 2048, offset: 1280)
!1909 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1287, size: 2048, elements: !1303)
!1910 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1852, file: !27, line: 320, baseType: !1911, size: 768, offset: 3328)
!1911 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 768, elements: !1912)
!1912 = !{!1913}
!1913 = !DISubrange(count: 96)
!1914 = !DIDerivedType(tag: DW_TAG_member, name: "fxsave64", scope: !1753, file: !27, line: 325, baseType: !1915, size: 4096)
!1915 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 323, size: 4096, elements: !1916, identifier: "_ZTSN3FPUUt1_E")
!1916 = !{!1917, !1931}
!1917 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1915, baseType: !1918)
!1918 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFXSAVE64", file: !27, line: 299, size: 3328, elements: !1919, identifier: "_ZTS11FpuFXSAVE64")
!1919 = !{!1920, !1921, !1922, !1923, !1924, !1925, !1926, !1927, !1928, !1929, !1930}
!1920 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1918, file: !27, line: 300, baseType: !1762, size: 16)
!1921 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1918, file: !27, line: 301, baseType: !1781, size: 16, offset: 16)
!1922 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1918, file: !27, line: 302, baseType: !1860, size: 8, offset: 32)
!1923 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1918, file: !27, line: 303, baseType: !62, size: 8, offset: 40)
!1924 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1918, file: !27, line: 304, baseType: !28, size: 16, offset: 48)
!1925 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1918, file: !27, line: 305, baseType: !637, size: 64, offset: 64)
!1926 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1918, file: !27, line: 306, baseType: !637, size: 64, offset: 128)
!1927 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr", scope: !1918, file: !27, line: 307, baseType: !1883, size: 32, offset: 192)
!1928 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr_mask", scope: !1918, file: !27, line: 308, baseType: !1883, size: 32, offset: 224)
!1929 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1918, file: !27, line: 309, baseType: !1825, size: 1024, offset: 256)
!1930 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1918, file: !27, line: 310, baseType: !1909, size: 2048, offset: 1280)
!1931 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1915, file: !27, line: 324, baseType: !1911, size: 768, offset: 3328)
!1932 = !DIDerivedType(tag: DW_TAG_member, name: "seg_caches", scope: !1268, file: !27, line: 761, baseType: !1933, size: 768, align: 64, offset: 26240)
!1933 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "SegmentCaches", file: !27, line: 468, size: 768, align: 64, elements: !1934, identifier: "_ZTS13SegmentCaches")
!1934 = !{!1935, !1945, !1946, !1947, !1948, !1949}
!1935 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1933, file: !27, line: 469, baseType: !1936, size: 128)
!1936 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "SegmentShadow", file: !27, line: 88, size: 128, elements: !1937, identifier: "_ZTS13SegmentShadow")
!1937 = !{!1938, !1943, !1944}
!1938 = !DIDerivedType(tag: DW_TAG_member, name: "base", scope: !1936, file: !27, line: 92, baseType: !1939, size: 64)
!1939 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1936, file: !27, line: 89, size: 64, elements: !1940, identifier: "_ZTSN13SegmentShadowUt_E")
!1940 = !{!1941, !1942}
!1941 = !DIDerivedType(tag: DW_TAG_member, name: "dword", scope: !1939, file: !27, line: 90, baseType: !8, size: 32)
!1942 = !DIDerivedType(tag: DW_TAG_member, name: "qword", scope: !1939, file: !27, line: 91, baseType: !637, size: 64)
!1943 = !DIDerivedType(tag: DW_TAG_member, name: "limit", scope: !1936, file: !27, line: 93, baseType: !8, size: 32, offset: 64)
!1944 = !DIDerivedType(tag: DW_TAG_member, name: "flags", scope: !1936, file: !27, line: 94, baseType: !8, size: 32, offset: 96)
!1945 = !DIDerivedType(tag: DW_TAG_member, name: "ss", scope: !1933, file: !27, line: 470, baseType: !1936, size: 128, offset: 128)
!1946 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1933, file: !27, line: 471, baseType: !1936, size: 128, offset: 256)
!1947 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1933, file: !27, line: 472, baseType: !1936, size: 128, offset: 384)
!1948 = !DIDerivedType(tag: DW_TAG_member, name: "fs", scope: !1933, file: !27, line: 473, baseType: !1936, size: 128, offset: 512)
!1949 = !DIDerivedType(tag: DW_TAG_member, name: "gs", scope: !1933, file: !27, line: 474, baseType: !1936, size: 128, offset: 640)
!1950 = !DIDerivedType(tag: DW_TAG_typedef, name: "addr_t", file: !1266, line: 42, baseType: !1951)
!1951 = !DIDerivedType(tag: DW_TAG_typedef, name: "addr64_t", file: !1266, line: 41, baseType: !637)
!1952 = !DILocation(line: 54, column: 8, scope: !1261)
!1953 = !DILocation(line: 55, column: 10, scope: !1261)
!1954 = !DILocation(line: 56, column: 10, scope: !1261)
!1955 = !DILocation(line: 57, column: 10, scope: !1261)
!1956 = !DILocation(line: 58, column: 10, scope: !1261)
!1957 = !DILocation(line: 61, column: 9, scope: !1261)
!1958 = !DILocation(line: 62, column: 9, scope: !1261)
!1959 = !DILocation(line: 63, column: 20, scope: !1261)
!1960 = !DILocation(line: 63, column: 24, scope: !1261)
!1961 = !DILocation(line: 63, column: 28, scope: !1261)
!1962 = !DILocation(line: 69, column: 6, scope: !1261)
!1963 = !DILocation(line: 74, column: 20, scope: !1261)
!1964 = !DILocation(line: 74, column: 24, scope: !1261)
!1965 = !DILocation(line: 74, column: 28, scope: !1261)
!1966 = !DILocation(line: 74, column: 33, scope: !1261)
!1967 = !DILocation(line: 75, column: 20, scope: !1261)
!1968 = !DILocation(line: 75, column: 24, scope: !1261)
!1969 = !DILocation(line: 75, column: 28, scope: !1261)
!1970 = !DILocation(line: 75, column: 33, scope: !1261)
!1971 = !DILocation(line: 76, column: 20, scope: !1261)
!1972 = !DILocation(line: 76, column: 24, scope: !1261)
!1973 = !DILocation(line: 76, column: 28, scope: !1261)
!1974 = !DILocation(line: 76, column: 33, scope: !1261)
!1975 = !DILocation(line: 77, column: 20, scope: !1261)
!1976 = !DILocation(line: 77, column: 24, scope: !1261)
!1977 = !DILocation(line: 77, column: 28, scope: !1261)
!1978 = !DILocation(line: 77, column: 33, scope: !1261)
!1979 = !DILocation(line: 78, column: 20, scope: !1261)
!1980 = !DILocation(line: 78, column: 24, scope: !1261)
!1981 = !DILocation(line: 78, column: 28, scope: !1261)
!1982 = !DILocation(line: 78, column: 33, scope: !1261)
!1983 = !DILocation(line: 79, column: 20, scope: !1261)
!1984 = !DILocation(line: 79, column: 24, scope: !1261)
!1985 = !DILocation(line: 79, column: 28, scope: !1261)
!1986 = !DILocation(line: 79, column: 33, scope: !1261)
!1987 = !DILocation(line: 80, column: 20, scope: !1261)
!1988 = !DILocation(line: 80, column: 24, scope: !1261)
!1989 = !DILocation(line: 80, column: 28, scope: !1261)
!1990 = !DILocation(line: 80, column: 33, scope: !1261)
!1991 = !DILocation(line: 81, column: 20, scope: !1261)
!1992 = !DILocation(line: 81, column: 24, scope: !1261)
!1993 = !DILocation(line: 81, column: 28, scope: !1261)
!1994 = !DILocation(line: 81, column: 33, scope: !1261)
!1995 = !DILocation(line: 83, column: 21, scope: !1261)
!1996 = !DILocation(line: 83, column: 25, scope: !1261)
!1997 = !DILocation(line: 83, column: 29, scope: !1261)
!1998 = !DILocation(line: 83, column: 34, scope: !1261)
!1999 = !DILocation(line: 84, column: 21, scope: !1261)
!2000 = !DILocation(line: 84, column: 25, scope: !1261)
!2001 = !DILocation(line: 84, column: 29, scope: !1261)
!2002 = !DILocation(line: 84, column: 34, scope: !1261)
!2003 = !DILocation(line: 85, column: 21, scope: !1261)
!2004 = !DILocation(line: 85, column: 25, scope: !1261)
!2005 = !DILocation(line: 85, column: 29, scope: !1261)
!2006 = !DILocation(line: 85, column: 34, scope: !1261)
!2007 = !DILocation(line: 86, column: 21, scope: !1261)
!2008 = !DILocation(line: 86, column: 25, scope: !1261)
!2009 = !DILocation(line: 86, column: 29, scope: !1261)
!2010 = !DILocation(line: 86, column: 34, scope: !1261)
!2011 = !DILocation(line: 87, column: 21, scope: !1261)
!2012 = !DILocation(line: 87, column: 25, scope: !1261)
!2013 = !DILocation(line: 87, column: 28, scope: !1261)
!2014 = !DILocation(line: 87, column: 33, scope: !1261)
!2015 = !DILocation(line: 88, column: 21, scope: !1261)
!2016 = !DILocation(line: 88, column: 25, scope: !1261)
!2017 = !DILocation(line: 88, column: 28, scope: !1261)
!2018 = !DILocation(line: 88, column: 33, scope: !1261)
!2019 = !DILocation(line: 89, column: 22, scope: !1261)
!2020 = !DILocation(line: 89, column: 26, scope: !1261)
!2021 = !DILocation(line: 89, column: 30, scope: !1261)
!2022 = !DILocation(line: 89, column: 35, scope: !1261)
!2023 = !DILocation(line: 90, column: 22, scope: !1261)
!2024 = !DILocation(line: 90, column: 26, scope: !1261)
!2025 = !DILocation(line: 90, column: 30, scope: !1261)
!2026 = !DILocation(line: 90, column: 35, scope: !1261)
!2027 = !DILocation(line: 91, column: 22, scope: !1261)
!2028 = !DILocation(line: 91, column: 26, scope: !1261)
!2029 = !DILocation(line: 91, column: 30, scope: !1261)
!2030 = !DILocation(line: 91, column: 35, scope: !1261)
!2031 = !DILocation(line: 92, column: 22, scope: !1261)
!2032 = !DILocation(line: 92, column: 26, scope: !1261)
!2033 = !DILocation(line: 92, column: 30, scope: !1261)
!2034 = !DILocation(line: 92, column: 35, scope: !1261)
!2035 = !DILocation(line: 93, column: 22, scope: !1261)
!2036 = !DILocation(line: 93, column: 26, scope: !1261)
!2037 = !DILocation(line: 93, column: 30, scope: !1261)
!2038 = !DILocation(line: 93, column: 35, scope: !1261)
!2039 = !DILocation(line: 94, column: 22, scope: !1261)
!2040 = !DILocation(line: 94, column: 26, scope: !1261)
!2041 = !DILocation(line: 94, column: 30, scope: !1261)
!2042 = !DILocation(line: 94, column: 35, scope: !1261)
!2043 = !DILocation(line: 96, column: 20, scope: !1261)
!2044 = !DILocation(line: 96, column: 24, scope: !1261)
!2045 = !DILocation(line: 96, column: 28, scope: !1261)
!2046 = !DILocation(line: 97, column: 20, scope: !1261)
!2047 = !DILocation(line: 97, column: 24, scope: !1261)
!2048 = !DILocation(line: 97, column: 28, scope: !1261)
!2049 = !DILocation(line: 98, column: 20, scope: !1261)
!2050 = !DILocation(line: 98, column: 24, scope: !1261)
!2051 = !DILocation(line: 98, column: 28, scope: !1261)
!2052 = !DILocation(line: 99, column: 20, scope: !1261)
!2053 = !DILocation(line: 99, column: 24, scope: !1261)
!2054 = !DILocation(line: 99, column: 28, scope: !1261)
!2055 = !DILocation(line: 100, column: 20, scope: !1261)
!2056 = !DILocation(line: 100, column: 24, scope: !1261)
!2057 = !DILocation(line: 100, column: 28, scope: !1261)
!2058 = !DILocation(line: 101, column: 20, scope: !1261)
!2059 = !DILocation(line: 101, column: 24, scope: !1261)
!2060 = !DILocation(line: 101, column: 28, scope: !1261)
!2061 = !DILocation(line: 102, column: 20, scope: !1261)
!2062 = !DILocation(line: 102, column: 24, scope: !1261)
!2063 = !DILocation(line: 102, column: 28, scope: !1261)
!2064 = !DILocation(line: 103, column: 20, scope: !1261)
!2065 = !DILocation(line: 103, column: 24, scope: !1261)
!2066 = !DILocation(line: 103, column: 28, scope: !1261)
!2067 = !DILocation(line: 105, column: 21, scope: !1261)
!2068 = !DILocation(line: 105, column: 25, scope: !1261)
!2069 = !DILocation(line: 105, column: 28, scope: !1261)
!2070 = !DILocation(line: 106, column: 21, scope: !1261)
!2071 = !DILocation(line: 106, column: 25, scope: !1261)
!2072 = !DILocation(line: 106, column: 28, scope: !1261)
!2073 = !DILocation(line: 107, column: 22, scope: !1261)
!2074 = !DILocation(line: 107, column: 26, scope: !1261)
!2075 = !DILocation(line: 107, column: 30, scope: !1261)
!2076 = !DILocation(line: 108, column: 22, scope: !1261)
!2077 = !DILocation(line: 108, column: 26, scope: !1261)
!2078 = !DILocation(line: 108, column: 30, scope: !1261)
!2079 = !DILocation(line: 109, column: 22, scope: !1261)
!2080 = !DILocation(line: 109, column: 26, scope: !1261)
!2081 = !DILocation(line: 109, column: 30, scope: !1261)
!2082 = !DILocation(line: 110, column: 22, scope: !1261)
!2083 = !DILocation(line: 110, column: 26, scope: !1261)
!2084 = !DILocation(line: 110, column: 30, scope: !1261)
!2085 = !DILocation(line: 111, column: 22, scope: !1261)
!2086 = !DILocation(line: 111, column: 26, scope: !1261)
!2087 = !DILocation(line: 111, column: 30, scope: !1261)
!2088 = !DILocation(line: 112, column: 22, scope: !1261)
!2089 = !DILocation(line: 112, column: 26, scope: !1261)
!2090 = !DILocation(line: 112, column: 30, scope: !1261)
!2091 = !DILocation(line: 114, column: 20, scope: !1261)
!2092 = !DILocation(line: 114, column: 24, scope: !1261)
!2093 = !DILocation(line: 114, column: 28, scope: !1261)
!2094 = !DILocation(line: 116, column: 21, scope: !1261)
!2095 = !DILocation(line: 116, column: 25, scope: !1261)
!2096 = !DILocation(line: 116, column: 29, scope: !1261)
!2097 = !DILocation(line: 117, column: 21, scope: !1261)
!2098 = !DILocation(line: 117, column: 25, scope: !1261)
!2099 = !DILocation(line: 117, column: 29, scope: !1261)
!2100 = !DILocation(line: 118, column: 21, scope: !1261)
!2101 = !DILocation(line: 118, column: 25, scope: !1261)
!2102 = !DILocation(line: 118, column: 29, scope: !1261)
!2103 = !DILocation(line: 119, column: 21, scope: !1261)
!2104 = !DILocation(line: 119, column: 25, scope: !1261)
!2105 = !DILocation(line: 119, column: 29, scope: !1261)
!2106 = !DILocation(line: 120, column: 21, scope: !1261)
!2107 = !DILocation(line: 120, column: 25, scope: !1261)
!2108 = !DILocation(line: 120, column: 29, scope: !1261)
!2109 = !DILocation(line: 121, column: 21, scope: !1261)
!2110 = !DILocation(line: 121, column: 25, scope: !1261)
!2111 = !DILocation(line: 121, column: 29, scope: !1261)
!2112 = !DILocation(line: 122, column: 21, scope: !1261)
!2113 = !DILocation(line: 122, column: 25, scope: !1261)
!2114 = !DILocation(line: 122, column: 29, scope: !1261)
!2115 = !DILocation(line: 123, column: 21, scope: !1261)
!2116 = !DILocation(line: 123, column: 25, scope: !1261)
!2117 = !DILocation(line: 123, column: 29, scope: !1261)
!2118 = !DILocation(line: 124, column: 21, scope: !1261)
!2119 = !DILocation(line: 124, column: 25, scope: !1261)
!2120 = !DILocation(line: 124, column: 29, scope: !1261)
!2121 = !DILocation(line: 127, column: 21, scope: !1261)
!2122 = !DILocation(line: 127, column: 25, scope: !1261)
!2123 = !DILocation(line: 127, column: 28, scope: !1261)
!2124 = !DILocation(line: 128, column: 21, scope: !1261)
!2125 = !DILocation(line: 128, column: 25, scope: !1261)
!2126 = !DILocation(line: 128, column: 28, scope: !1261)
!2127 = !DILocation(line: 129, column: 22, scope: !1261)
!2128 = !DILocation(line: 129, column: 26, scope: !1261)
!2129 = !DILocation(line: 129, column: 30, scope: !1261)
!2130 = !DILocation(line: 130, column: 22, scope: !1261)
!2131 = !DILocation(line: 130, column: 26, scope: !1261)
!2132 = !DILocation(line: 130, column: 30, scope: !1261)
!2133 = !DILocation(line: 131, column: 22, scope: !1261)
!2134 = !DILocation(line: 131, column: 26, scope: !1261)
!2135 = !DILocation(line: 131, column: 30, scope: !1261)
!2136 = !DILocation(line: 132, column: 22, scope: !1261)
!2137 = !DILocation(line: 132, column: 26, scope: !1261)
!2138 = !DILocation(line: 132, column: 30, scope: !1261)
!2139 = !DILocation(line: 133, column: 22, scope: !1261)
!2140 = !DILocation(line: 133, column: 26, scope: !1261)
!2141 = !DILocation(line: 133, column: 30, scope: !1261)
!2142 = !DILocation(line: 134, column: 22, scope: !1261)
!2143 = !DILocation(line: 134, column: 26, scope: !1261)
!2144 = !DILocation(line: 134, column: 30, scope: !1261)
!2145 = !DILocation(line: 136, column: 21, scope: !1261)
!2146 = !DILocation(line: 136, column: 25, scope: !1261)
!2147 = !DILocation(line: 136, column: 29, scope: !1261)
!2148 = !DILocation(line: 137, column: 21, scope: !1261)
!2149 = !DILocation(line: 137, column: 25, scope: !1261)
!2150 = !DILocation(line: 137, column: 29, scope: !1261)
!2151 = !DILocation(line: 138, column: 21, scope: !1261)
!2152 = !DILocation(line: 138, column: 25, scope: !1261)
!2153 = !DILocation(line: 138, column: 29, scope: !1261)
!2154 = !DILocation(line: 139, column: 21, scope: !1261)
!2155 = !DILocation(line: 139, column: 25, scope: !1261)
!2156 = !DILocation(line: 139, column: 29, scope: !1261)
!2157 = !DILocation(line: 140, column: 21, scope: !1261)
!2158 = !DILocation(line: 140, column: 25, scope: !1261)
!2159 = !DILocation(line: 140, column: 29, scope: !1261)
!2160 = !DILocation(line: 141, column: 21, scope: !1261)
!2161 = !DILocation(line: 141, column: 25, scope: !1261)
!2162 = !DILocation(line: 141, column: 29, scope: !1261)
!2163 = !DILocation(line: 142, column: 21, scope: !1261)
!2164 = !DILocation(line: 142, column: 25, scope: !1261)
!2165 = !DILocation(line: 142, column: 29, scope: !1261)
!2166 = !DILocation(line: 143, column: 21, scope: !1261)
!2167 = !DILocation(line: 143, column: 25, scope: !1261)
!2168 = !DILocation(line: 143, column: 29, scope: !1261)
!2169 = !DILocation(line: 144, column: 20, scope: !1261)
!2170 = !DILocation(line: 144, column: 24, scope: !1261)
!2171 = !DILocation(line: 144, column: 27, scope: !1261)
!2172 = !DILocation(line: 145, column: 20, scope: !1261)
!2173 = !DILocation(line: 145, column: 24, scope: !1261)
!2174 = !DILocation(line: 145, column: 27, scope: !1261)
!2175 = !DILocation(line: 146, column: 21, scope: !1261)
!2176 = !DILocation(line: 146, column: 25, scope: !1261)
!2177 = !DILocation(line: 146, column: 29, scope: !1261)
!2178 = !DILocation(line: 147, column: 21, scope: !1261)
!2179 = !DILocation(line: 147, column: 25, scope: !1261)
!2180 = !DILocation(line: 147, column: 29, scope: !1261)
!2181 = !DILocation(line: 148, column: 21, scope: !1261)
!2182 = !DILocation(line: 148, column: 25, scope: !1261)
!2183 = !DILocation(line: 148, column: 29, scope: !1261)
!2184 = !DILocation(line: 149, column: 21, scope: !1261)
!2185 = !DILocation(line: 149, column: 25, scope: !1261)
!2186 = !DILocation(line: 149, column: 29, scope: !1261)
!2187 = !DILocation(line: 150, column: 21, scope: !1261)
!2188 = !DILocation(line: 150, column: 25, scope: !1261)
!2189 = !DILocation(line: 150, column: 29, scope: !1261)
!2190 = !DILocation(line: 151, column: 21, scope: !1261)
!2191 = !DILocation(line: 151, column: 25, scope: !1261)
!2192 = !DILocation(line: 151, column: 29, scope: !1261)
!2193 = !DILocation(line: 152, column: 21, scope: !1261)
!2194 = !DILocation(line: 152, column: 25, scope: !1261)
!2195 = !DILocation(line: 152, column: 29, scope: !1261)
!2196 = !DILocation(line: 155, column: 20, scope: !1261)
!2197 = !DILocation(line: 155, column: 24, scope: !1261)
!2198 = !DILocation(line: 155, column: 27, scope: !1261)
!2199 = !DILocation(line: 156, column: 20, scope: !1261)
!2200 = !DILocation(line: 156, column: 24, scope: !1261)
!2201 = !DILocation(line: 156, column: 27, scope: !1261)
!2202 = !DILocation(line: 157, column: 20, scope: !1261)
!2203 = !DILocation(line: 157, column: 24, scope: !1261)
!2204 = !DILocation(line: 157, column: 27, scope: !1261)
!2205 = !DILocation(line: 158, column: 20, scope: !1261)
!2206 = !DILocation(line: 158, column: 24, scope: !1261)
!2207 = !DILocation(line: 158, column: 27, scope: !1261)
!2208 = !DILocation(line: 159, column: 20, scope: !1261)
!2209 = !DILocation(line: 159, column: 24, scope: !1261)
!2210 = !DILocation(line: 159, column: 27, scope: !1261)
!2211 = !DILocation(line: 160, column: 20, scope: !1261)
!2212 = !DILocation(line: 160, column: 24, scope: !1261)
!2213 = !DILocation(line: 160, column: 27, scope: !1261)
!2214 = !DILocation(line: 164, column: 25, scope: !1261)
!2215 = !DILocation(line: 164, column: 30, scope: !1261)
!2216 = !DILocation(line: 164, column: 38, scope: !1261)
!2217 = !DILocation(line: 165, column: 25, scope: !1261)
!2218 = !DILocation(line: 165, column: 30, scope: !1261)
!2219 = !DILocation(line: 165, column: 38, scope: !1261)
!2220 = !DILocation(line: 205, column: 22, scope: !1261)
!2221 = !DILocation(line: 205, column: 16, scope: !1261)
!2222 = !DILocation(line: 205, column: 29, scope: !1261)
!2223 = !DILocation(line: 206, column: 22, scope: !1261)
!2224 = !DILocation(line: 206, column: 16, scope: !1261)
!2225 = !DILocation(line: 206, column: 29, scope: !1261)
!2226 = !DILocation(line: 207, column: 22, scope: !1261)
!2227 = !DILocation(line: 207, column: 16, scope: !1261)
!2228 = !DILocation(line: 207, column: 29, scope: !1261)
!2229 = !DILocation(line: 208, column: 22, scope: !1261)
!2230 = !DILocation(line: 208, column: 16, scope: !1261)
!2231 = !DILocation(line: 208, column: 29, scope: !1261)
!2232 = !DILocation(line: 209, column: 22, scope: !1261)
!2233 = !DILocation(line: 209, column: 16, scope: !1261)
!2234 = !DILocation(line: 209, column: 29, scope: !1261)
!2235 = !DILocation(line: 210, column: 22, scope: !1261)
!2236 = !DILocation(line: 210, column: 16, scope: !1261)
!2237 = !DILocation(line: 210, column: 29, scope: !1261)
!2238 = !DILocation(line: 211, column: 22, scope: !1261)
!2239 = !DILocation(line: 211, column: 16, scope: !1261)
!2240 = !DILocation(line: 211, column: 29, scope: !1261)
!2241 = !DILocation(line: 212, column: 22, scope: !1261)
!2242 = !DILocation(line: 212, column: 16, scope: !1261)
!2243 = !DILocation(line: 212, column: 29, scope: !1261)
!2244 = !DILocation(line: 214, column: 22, scope: !1261)
!2245 = !DILocation(line: 214, column: 16, scope: !1261)
!2246 = !DILocation(line: 214, column: 29, scope: !1261)
!2247 = !DILocation(line: 215, column: 22, scope: !1261)
!2248 = !DILocation(line: 215, column: 16, scope: !1261)
!2249 = !DILocation(line: 215, column: 29, scope: !1261)
!2250 = !DILocation(line: 216, column: 23, scope: !1261)
!2251 = !DILocation(line: 216, column: 17, scope: !1261)
!2252 = !DILocation(line: 216, column: 31, scope: !1261)
!2253 = !DILocation(line: 217, column: 23, scope: !1261)
!2254 = !DILocation(line: 217, column: 17, scope: !1261)
!2255 = !DILocation(line: 217, column: 31, scope: !1261)
!2256 = !DILocation(line: 218, column: 23, scope: !1261)
!2257 = !DILocation(line: 218, column: 17, scope: !1261)
!2258 = !DILocation(line: 218, column: 31, scope: !1261)
!2259 = !DILocation(line: 219, column: 23, scope: !1261)
!2260 = !DILocation(line: 219, column: 17, scope: !1261)
!2261 = !DILocation(line: 219, column: 31, scope: !1261)
!2262 = !DILocation(line: 220, column: 23, scope: !1261)
!2263 = !DILocation(line: 220, column: 17, scope: !1261)
!2264 = !DILocation(line: 220, column: 31, scope: !1261)
!2265 = !DILocation(line: 221, column: 23, scope: !1261)
!2266 = !DILocation(line: 221, column: 17, scope: !1261)
!2267 = !DILocation(line: 221, column: 31, scope: !1261)
!2268 = !DILocation(line: 245, column: 22, scope: !1261)
!2269 = !DILocation(line: 245, column: 16, scope: !1261)
!2270 = !DILocation(line: 245, column: 29, scope: !1261)
!2271 = !DILocation(line: 246, column: 22, scope: !1261)
!2272 = !DILocation(line: 246, column: 16, scope: !1261)
!2273 = !DILocation(line: 246, column: 29, scope: !1261)
!2274 = !DILocation(line: 247, column: 22, scope: !1261)
!2275 = !DILocation(line: 247, column: 16, scope: !1261)
!2276 = !DILocation(line: 247, column: 29, scope: !1261)
!2277 = !DILocation(line: 248, column: 22, scope: !1261)
!2278 = !DILocation(line: 248, column: 16, scope: !1261)
!2279 = !DILocation(line: 248, column: 29, scope: !1261)
!2280 = !DILocation(line: 249, column: 22, scope: !1261)
!2281 = !DILocation(line: 249, column: 16, scope: !1261)
!2282 = !DILocation(line: 249, column: 29, scope: !1261)
!2283 = !DILocation(line: 250, column: 22, scope: !1261)
!2284 = !DILocation(line: 250, column: 16, scope: !1261)
!2285 = !DILocation(line: 250, column: 29, scope: !1261)
!2286 = !DILocation(line: 251, column: 22, scope: !1261)
!2287 = !DILocation(line: 251, column: 16, scope: !1261)
!2288 = !DILocation(line: 251, column: 29, scope: !1261)
!2289 = !DILocation(line: 252, column: 22, scope: !1261)
!2290 = !DILocation(line: 252, column: 16, scope: !1261)
!2291 = !DILocation(line: 252, column: 29, scope: !1261)
!2292 = !DILocation(line: 255, column: 22, scope: !1261)
!2293 = !DILocation(line: 255, column: 16, scope: !1261)
!2294 = !DILocation(line: 255, column: 29, scope: !1261)
!2295 = !DILocation(line: 256, column: 22, scope: !1261)
!2296 = !DILocation(line: 256, column: 16, scope: !1261)
!2297 = !DILocation(line: 256, column: 29, scope: !1261)
!2298 = !DILocation(line: 257, column: 23, scope: !1261)
!2299 = !DILocation(line: 257, column: 17, scope: !1261)
!2300 = !DILocation(line: 257, column: 31, scope: !1261)
!2301 = !DILocation(line: 258, column: 23, scope: !1261)
!2302 = !DILocation(line: 258, column: 17, scope: !1261)
!2303 = !DILocation(line: 258, column: 31, scope: !1261)
!2304 = !DILocation(line: 259, column: 23, scope: !1261)
!2305 = !DILocation(line: 259, column: 17, scope: !1261)
!2306 = !DILocation(line: 259, column: 31, scope: !1261)
!2307 = !DILocation(line: 260, column: 23, scope: !1261)
!2308 = !DILocation(line: 260, column: 17, scope: !1261)
!2309 = !DILocation(line: 260, column: 31, scope: !1261)
!2310 = !DILocation(line: 261, column: 23, scope: !1261)
!2311 = !DILocation(line: 261, column: 17, scope: !1261)
!2312 = !DILocation(line: 261, column: 31, scope: !1261)
!2313 = !DILocation(line: 262, column: 23, scope: !1261)
!2314 = !DILocation(line: 262, column: 17, scope: !1261)
!2315 = !DILocation(line: 262, column: 31, scope: !1261)
!2316 = !DILocation(line: 285, column: 21, scope: !1261)
!2317 = !DILocation(line: 285, column: 24, scope: !1261)
!2318 = !DILocation(line: 285, column: 15, scope: !1261)
!2319 = !DILocation(line: 285, column: 33, scope: !1261)
!2320 = !DILocation(line: 286, column: 21, scope: !1261)
!2321 = !DILocation(line: 286, column: 24, scope: !1261)
!2322 = !DILocation(line: 286, column: 15, scope: !1261)
!2323 = !DILocation(line: 286, column: 33, scope: !1261)
!2324 = !DILocation(line: 287, column: 21, scope: !1261)
!2325 = !DILocation(line: 287, column: 24, scope: !1261)
!2326 = !DILocation(line: 287, column: 15, scope: !1261)
!2327 = !DILocation(line: 287, column: 33, scope: !1261)
!2328 = !DILocation(line: 288, column: 21, scope: !1261)
!2329 = !DILocation(line: 288, column: 24, scope: !1261)
!2330 = !DILocation(line: 288, column: 15, scope: !1261)
!2331 = !DILocation(line: 288, column: 33, scope: !1261)
!2332 = !DILocation(line: 289, column: 21, scope: !1261)
!2333 = !DILocation(line: 289, column: 24, scope: !1261)
!2334 = !DILocation(line: 289, column: 15, scope: !1261)
!2335 = !DILocation(line: 289, column: 33, scope: !1261)
!2336 = !DILocation(line: 290, column: 21, scope: !1261)
!2337 = !DILocation(line: 290, column: 24, scope: !1261)
!2338 = !DILocation(line: 290, column: 15, scope: !1261)
!2339 = !DILocation(line: 290, column: 33, scope: !1261)
!2340 = !DILocation(line: 291, column: 21, scope: !1261)
!2341 = !DILocation(line: 291, column: 24, scope: !1261)
!2342 = !DILocation(line: 291, column: 15, scope: !1261)
!2343 = !DILocation(line: 291, column: 33, scope: !1261)
!2344 = !DILocation(line: 292, column: 21, scope: !1261)
!2345 = !DILocation(line: 292, column: 24, scope: !1261)
!2346 = !DILocation(line: 292, column: 15, scope: !1261)
!2347 = !DILocation(line: 292, column: 33, scope: !1261)
!2348 = !DILocation(line: 318, column: 21, scope: !1261)
!2349 = !DILocation(line: 318, column: 25, scope: !1261)
!2350 = !DILocation(line: 318, column: 15, scope: !1261)
!2351 = !DILocation(line: 318, column: 34, scope: !1261)
!2352 = !DILocation(line: 318, column: 38, scope: !1261)
!2353 = !DILocation(line: 318, column: 45, scope: !1261)
!2354 = !DILocation(line: 319, column: 21, scope: !1261)
!2355 = !DILocation(line: 319, column: 25, scope: !1261)
!2356 = !DILocation(line: 319, column: 15, scope: !1261)
!2357 = !DILocation(line: 319, column: 34, scope: !1261)
!2358 = !DILocation(line: 319, column: 38, scope: !1261)
!2359 = !DILocation(line: 319, column: 45, scope: !1261)
!2360 = !DILocation(line: 320, column: 21, scope: !1261)
!2361 = !DILocation(line: 320, column: 25, scope: !1261)
!2362 = !DILocation(line: 320, column: 15, scope: !1261)
!2363 = !DILocation(line: 320, column: 34, scope: !1261)
!2364 = !DILocation(line: 320, column: 38, scope: !1261)
!2365 = !DILocation(line: 320, column: 45, scope: !1261)
!2366 = !DILocation(line: 321, column: 21, scope: !1261)
!2367 = !DILocation(line: 321, column: 25, scope: !1261)
!2368 = !DILocation(line: 321, column: 15, scope: !1261)
!2369 = !DILocation(line: 321, column: 34, scope: !1261)
!2370 = !DILocation(line: 321, column: 38, scope: !1261)
!2371 = !DILocation(line: 321, column: 45, scope: !1261)
!2372 = !DILocation(line: 322, column: 21, scope: !1261)
!2373 = !DILocation(line: 322, column: 25, scope: !1261)
!2374 = !DILocation(line: 322, column: 15, scope: !1261)
!2375 = !DILocation(line: 322, column: 34, scope: !1261)
!2376 = !DILocation(line: 322, column: 38, scope: !1261)
!2377 = !DILocation(line: 322, column: 45, scope: !1261)
!2378 = !DILocation(line: 323, column: 21, scope: !1261)
!2379 = !DILocation(line: 323, column: 25, scope: !1261)
!2380 = !DILocation(line: 323, column: 15, scope: !1261)
!2381 = !DILocation(line: 323, column: 34, scope: !1261)
!2382 = !DILocation(line: 323, column: 38, scope: !1261)
!2383 = !DILocation(line: 323, column: 45, scope: !1261)
!2384 = !DILocation(line: 324, column: 21, scope: !1261)
!2385 = !DILocation(line: 324, column: 25, scope: !1261)
!2386 = !DILocation(line: 324, column: 15, scope: !1261)
!2387 = !DILocation(line: 324, column: 34, scope: !1261)
!2388 = !DILocation(line: 324, column: 38, scope: !1261)
!2389 = !DILocation(line: 324, column: 45, scope: !1261)
!2390 = !DILocation(line: 325, column: 21, scope: !1261)
!2391 = !DILocation(line: 325, column: 25, scope: !1261)
!2392 = !DILocation(line: 325, column: 15, scope: !1261)
!2393 = !DILocation(line: 325, column: 34, scope: !1261)
!2394 = !DILocation(line: 325, column: 38, scope: !1261)
!2395 = !DILocation(line: 325, column: 45, scope: !1261)
!2396 = !DILocation(line: 328, column: 20, scope: !1261)
!2397 = !DILocation(line: 328, column: 26, scope: !1261)
!2398 = !DILocation(line: 329, column: 20, scope: !1261)
!2399 = !DILocation(line: 329, column: 26, scope: !1261)
!2400 = !DILocation(line: 330, column: 20, scope: !1261)
!2401 = !DILocation(line: 330, column: 26, scope: !1261)
!2402 = !DILocation(line: 331, column: 20, scope: !1261)
!2403 = !DILocation(line: 331, column: 26, scope: !1261)
!2404 = !DILocation(line: 332, column: 20, scope: !1261)
!2405 = !DILocation(line: 332, column: 26, scope: !1261)
!2406 = !DILocation(line: 333, column: 20, scope: !1261)
!2407 = !DILocation(line: 333, column: 26, scope: !1261)
!2408 = !DILocation(line: 334, column: 20, scope: !1261)
!2409 = !DILocation(line: 334, column: 26, scope: !1261)
!2410 = !DILocation(line: 337, column: 9, scope: !1261)
!2411 = !DILocation(line: 338, column: 9, scope: !1261)
!2412 = !DILocation(line: 339, column: 9, scope: !1261)
!2413 = !DILocation(line: 340, column: 9, scope: !1261)
!2414 = !DILocation(line: 341, column: 9, scope: !1261)
!2415 = !DILocation(line: 342, column: 9, scope: !1261)
!2416 = !DILocation(line: 343, column: 9, scope: !1261)
!2417 = !DILocation(line: 344, column: 9, scope: !1261)
!2418 = !DILocation(line: 347, column: 9, scope: !1261)
!2419 = !DILocation(line: 348, column: 9, scope: !1261)
!2420 = !DILocation(line: 349, column: 9, scope: !1261)
!2421 = !DILocation(line: 350, column: 9, scope: !1261)
!2422 = !DILocation(line: 351, column: 9, scope: !1261)
!2423 = !DILocation(line: 353, column: 9, scope: !1261)
!2424 = !DILocation(line: 357, column: 3, scope: !1261)
!2425 = distinct !DISubprogram(name: "__remill_intrinsics", scope: !2426, file: !2426, line: 35, type: !95, isLocal: false, isDefinition: true, scopeLine: 35, flags: DIFlagPrototyped, isOptimized: false, unit: !1, variables: !7)
!2426 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/Intrinsics.cpp", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!2427 = !DILocation(line: 116, column: 1, scope: !2425)
!2428 = !{!2429, !2429, i64 0}
!2429 = !{!"long", !2430, i64 0}
!2430 = !{!"omnipotent char", !2431, i64 0}
!2431 = !{!"Simple C++ TBAA"}
!2432 = !{!2430, !2430, i64 0}
!2433 = !{!2434, !2430, i64 2065}
!2434 = !{!"_ZTS5State", !2430, i64 16, !2435, i64 2064, !2430, i64 2080, !2436, i64 2088, !2438, i64 2112, !2440, i64 2208, !2441, i64 2480, !2442, i64 2608, !2443, i64 2736, !2430, i64 2760, !2430, i64 2768, !2444, i64 3280}
!2435 = !{!"_ZTS10ArithFlags", !2430, i64 0, !2430, i64 1, !2430, i64 2, !2430, i64 3, !2430, i64 4, !2430, i64 5, !2430, i64 6, !2430, i64 7, !2430, i64 8, !2430, i64 9, !2430, i64 10, !2430, i64 11, !2430, i64 12, !2430, i64 13, !2430, i64 14, !2430, i64 15}
!2436 = !{!"_ZTS8Segments", !2437, i64 0, !2430, i64 2, !2437, i64 4, !2430, i64 6, !2437, i64 8, !2430, i64 10, !2437, i64 12, !2430, i64 14, !2437, i64 16, !2430, i64 18, !2437, i64 20, !2430, i64 22}
!2437 = !{!"short", !2430, i64 0}
!2438 = !{!"_ZTS12AddressSpace", !2429, i64 0, !2439, i64 8, !2429, i64 16, !2439, i64 24, !2429, i64 32, !2439, i64 40, !2429, i64 48, !2439, i64 56, !2429, i64 64, !2439, i64 72, !2429, i64 80, !2439, i64 88}
!2439 = !{!"_ZTS3Reg", !2430, i64 0}
!2440 = !{!"_ZTS3GPR", !2429, i64 0, !2439, i64 8, !2429, i64 16, !2439, i64 24, !2429, i64 32, !2439, i64 40, !2429, i64 48, !2439, i64 56, !2429, i64 64, !2439, i64 72, !2429, i64 80, !2439, i64 88, !2429, i64 96, !2439, i64 104, !2429, i64 112, !2439, i64 120, !2429, i64 128, !2439, i64 136, !2429, i64 144, !2439, i64 152, !2429, i64 160, !2439, i64 168, !2429, i64 176, !2439, i64 184, !2429, i64 192, !2439, i64 200, !2429, i64 208, !2439, i64 216, !2429, i64 224, !2439, i64 232, !2429, i64 240, !2439, i64 248, !2429, i64 256, !2439, i64 264}
!2441 = !{!"_ZTS8X87Stack", !2430, i64 0}
!2442 = !{!"_ZTS3MMX", !2430, i64 0}
!2443 = !{!"_ZTS14FPUStatusFlags", !2430, i64 0, !2430, i64 1, !2430, i64 2, !2430, i64 3, !2430, i64 4, !2430, i64 5, !2430, i64 6, !2430, i64 7, !2430, i64 8, !2430, i64 9, !2430, i64 10, !2430, i64 11, !2430, i64 12, !2430, i64 13, !2430, i64 14, !2430, i64 15, !2430, i64 16, !2430, i64 17, !2430, i64 18, !2430, i64 19, !2430, i64 20}
!2444 = !{!"_ZTS13SegmentCaches", !2445, i64 0, !2445, i64 16, !2445, i64 32, !2445, i64 48, !2445, i64 64, !2445, i64 80}
!2445 = !{!"_ZTS13SegmentShadow", !2430, i64 0, !2446, i64 8, !2446, i64 12}
!2446 = !{!"int", !2430, i64 0}
!2447 = !{!2434, !2430, i64 2067}
!2448 = !{!2434, !2430, i64 2071}
!2449 = !{!2434, !2430, i64 2073}
!2450 = !{!2434, !2430, i64 2077}
!2451 = !{!2434, !2430, i64 2069}
!2452 = !{!2453, !2453, i64 0}
!2453 = !{!"double", !2430, i64 0}
!2454 = !{!2455}
!2455 = distinct !{!2455, !2456, !"ext_6050f8_atan: argument 0"}
!2456 = distinct !{!2456, !"ext_6050f8_atan"}
!2457 = !{!2458}
!2458 = distinct !{!2458, !2456, !"ext_6050f8_atan: argument 1"}
!2459 = !{!2446, !2446, i64 0}
!2460 = !{!2461}
!2461 = distinct !{!2461, !2462, !"ext_6050b8_cos: argument 0"}
!2462 = distinct !{!2462, !"ext_6050b8_cos"}
!2463 = !{!2464}
!2464 = distinct !{!2464, !2462, !"ext_6050b8_cos: argument 1"}
!2465 = !{!2466}
!2466 = distinct !{!2466, !2467, !"ext_6050b8_cos: argument 0"}
!2467 = distinct !{!2467, !"ext_6050b8_cos"}
!2468 = !{!2469}
!2469 = distinct !{!2469, !2467, !"ext_6050b8_cos: argument 1"}
!2470 = !{!2471}
!2471 = distinct !{!2471, !2472, !"ext_4006f0_sin: argument 0"}
!2472 = distinct !{!2472, !"ext_4006f0_sin"}
!2473 = !{!2474}
!2474 = distinct !{!2474, !2472, !"ext_4006f0_sin: argument 1"}
!2475 = !{!2476, !2476, i64 0}
!2476 = !{!"float", !2430, i64 0}
!2477 = !{!2478}
!2478 = distinct !{!2478, !2479, !"ext_605140_sqrt: argument 0"}
!2479 = distinct !{!2479, !"ext_605140_sqrt"}
!2480 = !{!2481}
!2481 = distinct !{!2481, !2479, !"ext_605140_sqrt: argument 1"}
