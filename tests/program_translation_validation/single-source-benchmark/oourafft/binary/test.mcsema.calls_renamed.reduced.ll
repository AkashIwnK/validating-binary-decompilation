; ModuleID = '/tmp/tmp2sl384ni-target.ll'
source_filename = "llvm-link"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu-elf"

%union.anon = type { i64 }
%seg_4040a0__rodata_type = type <{ [24 x i8], [88 x i8], [45 x i8], [7 x i8] }>
%seg_604de0__init_array_type = type <{ i64, i64 }>
%seg_604ff0__got_type = type <{ i64, i64 }>
%__bss_start_type = type <{ [8 x i8] }>
%struct.State = type { %struct.ArchState, [32 x %union.VectorReg], %struct.ArithFlags, %union.anon, %struct.Segments, %struct.AddressSpace, %struct.GPR, %struct.X87Stack, %struct.MMX, %struct.FPUStatusFlags, %union.anon, %union.FPU, %struct.SegmentCaches }
%struct.ArchState = type { i32, i32, %union.anon }
%union.VectorReg = type { %union.vec512_t }
%union.vec512_t = type { %struct.uint64v8_t }
%struct.uint64v8_t = type { [8 x i64] }
%struct.ArithFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8 }
%struct.Segments = type { i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector }
%union.SegmentSelector = type { i16 }
%struct.AddressSpace = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.Reg = type { %union.anon }
%struct.GPR = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.X87Stack = type { [8 x %struct.anon.3] }
%struct.anon.3 = type { i64, double }
%struct.MMX = type { [8 x %struct.anon.4] }
%struct.anon.4 = type { i64, %union.vec64_t }
%union.vec64_t = type { %struct.uint64v1_t }
%struct.uint64v1_t = type { [1 x i64] }
%struct.FPUStatusFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, [4 x i8] }
%union.FPU = type { %struct.anon.13 }
%struct.anon.13 = type { %struct.FpuFXSAVE, [96 x i8] }
%struct.FpuFXSAVE = type { %union.SegmentSelector, %union.SegmentSelector, %union.FPUAbridgedTagWord, i8, i16, i32, %union.SegmentSelector, i16, i32, %union.SegmentSelector, i16, %union.FPUControlStatus, %union.FPUControlStatus, [8 x %struct.FPUStackElem], [16 x %union.vec128_t] }
%union.FPUAbridgedTagWord = type { i8 }
%union.FPUControlStatus = type { i32 }
%struct.FPUStackElem = type { %union.anon.11, [6 x i8] }
%union.anon.11 = type { %struct.float80_t }
%struct.float80_t = type { [10 x i8] }
%union.vec128_t = type { %struct.uint128v1_t }
%struct.uint128v1_t = type { [1 x i128] }
%struct.SegmentCaches = type { %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow }
%struct.SegmentShadow = type { %union.anon, i32, i32 }
%struct.Memory = type opaque
%struct.anon.2 = type { i8, i8 }
%"class.std::bitset" = type { %struct.uint64v4_t }
%struct.uint64v4_t = type { [4 x i64] }

@DR0 = external global i64, align 8
@DR1 = external global i64, align 8
@DR2 = external global i64, align 8
@DR3 = external global i64, align 8
@DR4 = external global i64, align 8
@DR5 = external global i64, align 8
@DR6 = external global i64, align 8
@DR7 = external global i64, align 8
@gCR0 = external global %union.anon, align 1
@gCR1 = external global %union.anon, align 1
@gCR2 = external global %union.anon, align 1
@gCR3 = external global %union.anon, align 1
@gCR4 = external global %union.anon, align 1
@gCR8 = external global %union.anon, align 1
@seg_4040a0__rodata = internal constant %seg_4040a0__rodata_type <{ [24 x i8] c"\01\00\02\00\00\00\00\00\BB\BD\D7\D9\DF|\DB=\00\00\00\00\00\00P?", [88 x i8] c"\00\00\00\00\00\00\90@\00\00\00\00\00\00\10@\00\00\00\00\00\00\E0C\95\D6&\E8\0B.\11>\8D\ED\B5\A0\F7\C6\B0>\00\00\00\00\00\00\F0?q\8B\89\C0\85.\D0>\00\00\00\00\00\00\00@\00\00\00\00\00\00\00\00\FF\FF\FF\FF\FF\FF\FF\7F\FF\FF\FF\FF\FF\FF\FF\7F", [45 x i8] c"FFT sanity check failed! Difference is: %le\0A\00", [7 x i8] c"%e %e\0A\00" }>
@seg_604de0__init_array = internal global %seg_604de0__init_array_type <{ i64 ptrtoint (void ()* @callback_sub_400840_frame_dummy to i64), i64 ptrtoint (void ()* @callback_sub_400810___do_global_dtors_aux to i64) }>
@seg_604ff0__got = internal global %seg_604ff0__got_type <{ i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64)* @__libc_start_main to i64), i64 ptrtoint (i64 ()* @__gmon_start__ to i64) }>
@__bss_start = global %__bss_start_type zeroinitializer
@0 = internal global i1 false
@1 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_400840_frame_dummy_wrapper
@2 = internal constant void ()* @__mcsema_attach_call
@3 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_400810___do_global_dtors_aux_wrapper
@4 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_404090___libc_csu_fini_wrapper
@5 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_404020___libc_csu_init_wrapper
@6 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @main_wrapper
@7 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @putdata_wrapper
@8 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @cdft_wrapper
@9 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @errorcheck_wrapper
@10 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @.term_proc_wrapper
@11 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @get_time_wrapper
@12 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @.init_proc_wrapper
@13 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @makewt_wrapper
@llvm.global_ctors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 101, void ()* @__mcsema_constructor, i8* null }]
@llvm.global_dtors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 101, void ()* @__mcsema_destructor, i8* null }]

declare %struct.Memory* @sub_400e30_get_time_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4024b0_cftbsub_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401c10_bitrv2conj_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400fe0_putdata_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400e70_makewt_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401100_errorcheck_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401870_cftfsub_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4011f0_bitrv2_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400688__init_proc_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_403330_cftmdl_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401060_cdft_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4028a0_cft1st_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4007a0_deregister_tm_clones_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

; Function Attrs: nounwind readnone
declare i32 @llvm.ctpop.i32(i32) #0

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_error(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #1

; Function Attrs: nounwind readnone
declare double @llvm.fabs.f64(double) #0

; Function Attrs: nounwind readnone
declare double @llvm.trunc.f64(double) #0

; Function Attrs: nounwind readnone
declare double @sqrt(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @cos(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @sin(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @atan(double) local_unnamed_addr #2

; Function Attrs: noinline nounwind optnone
define %struct.Memory* @__remill_basic_block(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #3 !dbg !1261 {
  %state = alloca %struct.State*, align 8
  %curr_pc = alloca i64, align 8
  %memory = alloca %struct.Memory*, align 8
  %BRANCH_TAKEN = alloca i8, align 1
  %SS_BASE = alloca i64, align 8
  %ES_BASE = alloca i64, align 8
  %DS_BASE = alloca i64, align 8
  %CS_BASE = alloca i64, align 8
  %STATE = alloca %struct.State*, align 8
  %MEMORY = alloca %struct.Memory*, align 8
  %_DR0 = alloca i64*, align 8
  %_DR1 = alloca i64*, align 8
  %_DR2 = alloca i64*, align 8
  %_DR3 = alloca i64*, align 8
  %_DR4 = alloca i64*, align 8
  %_DR5 = alloca i64*, align 8
  %_DR6 = alloca i64*, align 8
  %_DR7 = alloca i64*, align 8
  %CR0 = alloca i64*, align 8
  %CR1 = alloca i64*, align 8
  %CR2 = alloca i64*, align 8
  %CR3 = alloca i64*, align 8
  %CR4 = alloca i64*, align 8
  %CR8 = alloca i64*, align 8
  store %struct.State* %0, %struct.State** %state, align 8
  store i64 %1, i64* %curr_pc, align 8
  store %struct.Memory* %2, %struct.Memory** %memory, align 8
  store i8 0, i8* %BRANCH_TAKEN, align 1, !dbg !1952
  store i64 0, i64* %SS_BASE, align 8, !dbg !1953
  store i64 0, i64* %ES_BASE, align 8, !dbg !1954
  store i64 0, i64* %DS_BASE, align 8, !dbg !1955
  store i64 0, i64* %CS_BASE, align 8, !dbg !1956
  store %struct.State* %0, %struct.State** %STATE, align 8, !dbg !1957
  store %struct.Memory* %2, %struct.Memory** %MEMORY, align 8, !dbg !1958
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1959
  %5 = getelementptr inbounds %struct.GPR, %struct.GPR* %4, i32 0, i32 33, !dbg !1960
  %6 = getelementptr inbounds %struct.Reg, %struct.Reg* %5, i32 0, i32 0, !dbg !1961
  %PC = bitcast %union.anon* %6 to i64*, !dbg !1961
  store i64 %1, i64* %PC, align 8, !dbg !1962
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1963
  %8 = getelementptr inbounds %struct.GPR, %struct.GPR* %7, i32 0, i32 1, !dbg !1964
  %9 = getelementptr inbounds %struct.Reg, %struct.Reg* %8, i32 0, i32 0, !dbg !1965
  %10 = bitcast %union.anon* %9 to %struct.anon.2*, !dbg !1965
  %AH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %10, i32 0, i32 1, !dbg !1966
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1967
  %12 = getelementptr inbounds %struct.GPR, %struct.GPR* %11, i32 0, i32 3, !dbg !1968
  %13 = getelementptr inbounds %struct.Reg, %struct.Reg* %12, i32 0, i32 0, !dbg !1969
  %14 = bitcast %union.anon* %13 to %struct.anon.2*, !dbg !1969
  %BH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %14, i32 0, i32 1, !dbg !1970
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1971
  %16 = getelementptr inbounds %struct.GPR, %struct.GPR* %15, i32 0, i32 5, !dbg !1972
  %17 = getelementptr inbounds %struct.Reg, %struct.Reg* %16, i32 0, i32 0, !dbg !1973
  %18 = bitcast %union.anon* %17 to %struct.anon.2*, !dbg !1973
  %CH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %18, i32 0, i32 1, !dbg !1974
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1975
  %20 = getelementptr inbounds %struct.GPR, %struct.GPR* %19, i32 0, i32 7, !dbg !1976
  %21 = getelementptr inbounds %struct.Reg, %struct.Reg* %20, i32 0, i32 0, !dbg !1977
  %22 = bitcast %union.anon* %21 to %struct.anon.2*, !dbg !1977
  %DH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %22, i32 0, i32 1, !dbg !1978
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1979
  %24 = getelementptr inbounds %struct.GPR, %struct.GPR* %23, i32 0, i32 1, !dbg !1980
  %25 = getelementptr inbounds %struct.Reg, %struct.Reg* %24, i32 0, i32 0, !dbg !1981
  %26 = bitcast %union.anon* %25 to %struct.anon.2*, !dbg !1981
  %AL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %26, i32 0, i32 0, !dbg !1982
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1983
  %28 = getelementptr inbounds %struct.GPR, %struct.GPR* %27, i32 0, i32 3, !dbg !1984
  %29 = getelementptr inbounds %struct.Reg, %struct.Reg* %28, i32 0, i32 0, !dbg !1985
  %30 = bitcast %union.anon* %29 to %struct.anon.2*, !dbg !1985
  %BL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %30, i32 0, i32 0, !dbg !1986
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1987
  %32 = getelementptr inbounds %struct.GPR, %struct.GPR* %31, i32 0, i32 5, !dbg !1988
  %33 = getelementptr inbounds %struct.Reg, %struct.Reg* %32, i32 0, i32 0, !dbg !1989
  %34 = bitcast %union.anon* %33 to %struct.anon.2*, !dbg !1989
  %CL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %34, i32 0, i32 0, !dbg !1990
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1991
  %36 = getelementptr inbounds %struct.GPR, %struct.GPR* %35, i32 0, i32 7, !dbg !1992
  %37 = getelementptr inbounds %struct.Reg, %struct.Reg* %36, i32 0, i32 0, !dbg !1993
  %38 = bitcast %union.anon* %37 to %struct.anon.2*, !dbg !1993
  %DL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %38, i32 0, i32 0, !dbg !1994
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1995
  %40 = getelementptr inbounds %struct.GPR, %struct.GPR* %39, i32 0, i32 9, !dbg !1996
  %41 = getelementptr inbounds %struct.Reg, %struct.Reg* %40, i32 0, i32 0, !dbg !1997
  %42 = bitcast %union.anon* %41 to %struct.anon.2*, !dbg !1997
  %SIL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %42, i32 0, i32 0, !dbg !1998
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1999
  %44 = getelementptr inbounds %struct.GPR, %struct.GPR* %43, i32 0, i32 11, !dbg !2000
  %45 = getelementptr inbounds %struct.Reg, %struct.Reg* %44, i32 0, i32 0, !dbg !2001
  %46 = bitcast %union.anon* %45 to %struct.anon.2*, !dbg !2001
  %DIL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %46, i32 0, i32 0, !dbg !2002
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2003
  %48 = getelementptr inbounds %struct.GPR, %struct.GPR* %47, i32 0, i32 13, !dbg !2004
  %49 = getelementptr inbounds %struct.Reg, %struct.Reg* %48, i32 0, i32 0, !dbg !2005
  %50 = bitcast %union.anon* %49 to %struct.anon.2*, !dbg !2005
  %SPL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %50, i32 0, i32 0, !dbg !2006
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2007
  %52 = getelementptr inbounds %struct.GPR, %struct.GPR* %51, i32 0, i32 15, !dbg !2008
  %53 = getelementptr inbounds %struct.Reg, %struct.Reg* %52, i32 0, i32 0, !dbg !2009
  %54 = bitcast %union.anon* %53 to %struct.anon.2*, !dbg !2009
  %BPL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %54, i32 0, i32 0, !dbg !2010
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2011
  %56 = getelementptr inbounds %struct.GPR, %struct.GPR* %55, i32 0, i32 17, !dbg !2012
  %57 = getelementptr inbounds %struct.Reg, %struct.Reg* %56, i32 0, i32 0, !dbg !2013
  %58 = bitcast %union.anon* %57 to %struct.anon.2*, !dbg !2013
  %R8B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %58, i32 0, i32 0, !dbg !2014
  %59 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2015
  %60 = getelementptr inbounds %struct.GPR, %struct.GPR* %59, i32 0, i32 19, !dbg !2016
  %61 = getelementptr inbounds %struct.Reg, %struct.Reg* %60, i32 0, i32 0, !dbg !2017
  %62 = bitcast %union.anon* %61 to %struct.anon.2*, !dbg !2017
  %R9B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %62, i32 0, i32 0, !dbg !2018
  %63 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2019
  %64 = getelementptr inbounds %struct.GPR, %struct.GPR* %63, i32 0, i32 21, !dbg !2020
  %65 = getelementptr inbounds %struct.Reg, %struct.Reg* %64, i32 0, i32 0, !dbg !2021
  %66 = bitcast %union.anon* %65 to %struct.anon.2*, !dbg !2021
  %R10B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %66, i32 0, i32 0, !dbg !2022
  %67 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2023
  %68 = getelementptr inbounds %struct.GPR, %struct.GPR* %67, i32 0, i32 23, !dbg !2024
  %69 = getelementptr inbounds %struct.Reg, %struct.Reg* %68, i32 0, i32 0, !dbg !2025
  %70 = bitcast %union.anon* %69 to %struct.anon.2*, !dbg !2025
  %R11B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %70, i32 0, i32 0, !dbg !2026
  %71 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2027
  %72 = getelementptr inbounds %struct.GPR, %struct.GPR* %71, i32 0, i32 25, !dbg !2028
  %73 = getelementptr inbounds %struct.Reg, %struct.Reg* %72, i32 0, i32 0, !dbg !2029
  %74 = bitcast %union.anon* %73 to %struct.anon.2*, !dbg !2029
  %R12B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %74, i32 0, i32 0, !dbg !2030
  %75 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2031
  %76 = getelementptr inbounds %struct.GPR, %struct.GPR* %75, i32 0, i32 27, !dbg !2032
  %77 = getelementptr inbounds %struct.Reg, %struct.Reg* %76, i32 0, i32 0, !dbg !2033
  %78 = bitcast %union.anon* %77 to %struct.anon.2*, !dbg !2033
  %R13B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %78, i32 0, i32 0, !dbg !2034
  %79 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2035
  %80 = getelementptr inbounds %struct.GPR, %struct.GPR* %79, i32 0, i32 29, !dbg !2036
  %81 = getelementptr inbounds %struct.Reg, %struct.Reg* %80, i32 0, i32 0, !dbg !2037
  %82 = bitcast %union.anon* %81 to %struct.anon.2*, !dbg !2037
  %R14B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %82, i32 0, i32 0, !dbg !2038
  %83 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2039
  %84 = getelementptr inbounds %struct.GPR, %struct.GPR* %83, i32 0, i32 31, !dbg !2040
  %85 = getelementptr inbounds %struct.Reg, %struct.Reg* %84, i32 0, i32 0, !dbg !2041
  %86 = bitcast %union.anon* %85 to %struct.anon.2*, !dbg !2041
  %R15B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %86, i32 0, i32 0, !dbg !2042
  %87 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2043
  %88 = getelementptr inbounds %struct.GPR, %struct.GPR* %87, i32 0, i32 1, !dbg !2044
  %89 = getelementptr inbounds %struct.Reg, %struct.Reg* %88, i32 0, i32 0, !dbg !2045
  %AX = bitcast %union.anon* %89 to i16*, !dbg !2045
  %90 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2046
  %91 = getelementptr inbounds %struct.GPR, %struct.GPR* %90, i32 0, i32 3, !dbg !2047
  %92 = getelementptr inbounds %struct.Reg, %struct.Reg* %91, i32 0, i32 0, !dbg !2048
  %BX = bitcast %union.anon* %92 to i16*, !dbg !2048
  %93 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2049
  %94 = getelementptr inbounds %struct.GPR, %struct.GPR* %93, i32 0, i32 5, !dbg !2050
  %95 = getelementptr inbounds %struct.Reg, %struct.Reg* %94, i32 0, i32 0, !dbg !2051
  %CX = bitcast %union.anon* %95 to i16*, !dbg !2051
  %96 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2052
  %97 = getelementptr inbounds %struct.GPR, %struct.GPR* %96, i32 0, i32 7, !dbg !2053
  %98 = getelementptr inbounds %struct.Reg, %struct.Reg* %97, i32 0, i32 0, !dbg !2054
  %DX = bitcast %union.anon* %98 to i16*, !dbg !2054
  %99 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2055
  %100 = getelementptr inbounds %struct.GPR, %struct.GPR* %99, i32 0, i32 9, !dbg !2056
  %101 = getelementptr inbounds %struct.Reg, %struct.Reg* %100, i32 0, i32 0, !dbg !2057
  %SI = bitcast %union.anon* %101 to i16*, !dbg !2057
  %102 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2058
  %103 = getelementptr inbounds %struct.GPR, %struct.GPR* %102, i32 0, i32 11, !dbg !2059
  %104 = getelementptr inbounds %struct.Reg, %struct.Reg* %103, i32 0, i32 0, !dbg !2060
  %DI = bitcast %union.anon* %104 to i16*, !dbg !2060
  %105 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2061
  %106 = getelementptr inbounds %struct.GPR, %struct.GPR* %105, i32 0, i32 13, !dbg !2062
  %107 = getelementptr inbounds %struct.Reg, %struct.Reg* %106, i32 0, i32 0, !dbg !2063
  %SP = bitcast %union.anon* %107 to i16*, !dbg !2063
  %108 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2064
  %109 = getelementptr inbounds %struct.GPR, %struct.GPR* %108, i32 0, i32 15, !dbg !2065
  %110 = getelementptr inbounds %struct.Reg, %struct.Reg* %109, i32 0, i32 0, !dbg !2066
  %BP = bitcast %union.anon* %110 to i16*, !dbg !2066
  %111 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2067
  %112 = getelementptr inbounds %struct.GPR, %struct.GPR* %111, i32 0, i32 17, !dbg !2068
  %113 = getelementptr inbounds %struct.Reg, %struct.Reg* %112, i32 0, i32 0, !dbg !2069
  %R8W = bitcast %union.anon* %113 to i16*, !dbg !2069
  %114 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2070
  %115 = getelementptr inbounds %struct.GPR, %struct.GPR* %114, i32 0, i32 19, !dbg !2071
  %116 = getelementptr inbounds %struct.Reg, %struct.Reg* %115, i32 0, i32 0, !dbg !2072
  %R9W = bitcast %union.anon* %116 to i16*, !dbg !2072
  %117 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2073
  %118 = getelementptr inbounds %struct.GPR, %struct.GPR* %117, i32 0, i32 21, !dbg !2074
  %119 = getelementptr inbounds %struct.Reg, %struct.Reg* %118, i32 0, i32 0, !dbg !2075
  %R10W = bitcast %union.anon* %119 to i16*, !dbg !2075
  %120 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2076
  %121 = getelementptr inbounds %struct.GPR, %struct.GPR* %120, i32 0, i32 23, !dbg !2077
  %122 = getelementptr inbounds %struct.Reg, %struct.Reg* %121, i32 0, i32 0, !dbg !2078
  %R11W = bitcast %union.anon* %122 to i16*, !dbg !2078
  %123 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2079
  %124 = getelementptr inbounds %struct.GPR, %struct.GPR* %123, i32 0, i32 25, !dbg !2080
  %125 = getelementptr inbounds %struct.Reg, %struct.Reg* %124, i32 0, i32 0, !dbg !2081
  %R12W = bitcast %union.anon* %125 to i16*, !dbg !2081
  %126 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2082
  %127 = getelementptr inbounds %struct.GPR, %struct.GPR* %126, i32 0, i32 27, !dbg !2083
  %128 = getelementptr inbounds %struct.Reg, %struct.Reg* %127, i32 0, i32 0, !dbg !2084
  %R13W = bitcast %union.anon* %128 to i16*, !dbg !2084
  %129 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2085
  %130 = getelementptr inbounds %struct.GPR, %struct.GPR* %129, i32 0, i32 29, !dbg !2086
  %131 = getelementptr inbounds %struct.Reg, %struct.Reg* %130, i32 0, i32 0, !dbg !2087
  %R14W = bitcast %union.anon* %131 to i16*, !dbg !2087
  %132 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2088
  %133 = getelementptr inbounds %struct.GPR, %struct.GPR* %132, i32 0, i32 31, !dbg !2089
  %134 = getelementptr inbounds %struct.Reg, %struct.Reg* %133, i32 0, i32 0, !dbg !2090
  %R15W = bitcast %union.anon* %134 to i16*, !dbg !2090
  %135 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2091
  %136 = getelementptr inbounds %struct.GPR, %struct.GPR* %135, i32 0, i32 33, !dbg !2092
  %137 = getelementptr inbounds %struct.Reg, %struct.Reg* %136, i32 0, i32 0, !dbg !2093
  %IP = bitcast %union.anon* %137 to i16*, !dbg !2093
  %138 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2094
  %139 = getelementptr inbounds %struct.GPR, %struct.GPR* %138, i32 0, i32 1, !dbg !2095
  %140 = getelementptr inbounds %struct.Reg, %struct.Reg* %139, i32 0, i32 0, !dbg !2096
  %EAX = bitcast %union.anon* %140 to i32*, !dbg !2096
  %141 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2097
  %142 = getelementptr inbounds %struct.GPR, %struct.GPR* %141, i32 0, i32 3, !dbg !2098
  %143 = getelementptr inbounds %struct.Reg, %struct.Reg* %142, i32 0, i32 0, !dbg !2099
  %EBX = bitcast %union.anon* %143 to i32*, !dbg !2099
  %144 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2100
  %145 = getelementptr inbounds %struct.GPR, %struct.GPR* %144, i32 0, i32 5, !dbg !2101
  %146 = getelementptr inbounds %struct.Reg, %struct.Reg* %145, i32 0, i32 0, !dbg !2102
  %ECX = bitcast %union.anon* %146 to i32*, !dbg !2102
  %147 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2103
  %148 = getelementptr inbounds %struct.GPR, %struct.GPR* %147, i32 0, i32 7, !dbg !2104
  %149 = getelementptr inbounds %struct.Reg, %struct.Reg* %148, i32 0, i32 0, !dbg !2105
  %EDX = bitcast %union.anon* %149 to i32*, !dbg !2105
  %150 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2106
  %151 = getelementptr inbounds %struct.GPR, %struct.GPR* %150, i32 0, i32 9, !dbg !2107
  %152 = getelementptr inbounds %struct.Reg, %struct.Reg* %151, i32 0, i32 0, !dbg !2108
  %ESI = bitcast %union.anon* %152 to i32*, !dbg !2108
  %153 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2109
  %154 = getelementptr inbounds %struct.GPR, %struct.GPR* %153, i32 0, i32 11, !dbg !2110
  %155 = getelementptr inbounds %struct.Reg, %struct.Reg* %154, i32 0, i32 0, !dbg !2111
  %EDI = bitcast %union.anon* %155 to i32*, !dbg !2111
  %156 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2112
  %157 = getelementptr inbounds %struct.GPR, %struct.GPR* %156, i32 0, i32 13, !dbg !2113
  %158 = getelementptr inbounds %struct.Reg, %struct.Reg* %157, i32 0, i32 0, !dbg !2114
  %ESP = bitcast %union.anon* %158 to i32*, !dbg !2114
  %159 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2115
  %160 = getelementptr inbounds %struct.GPR, %struct.GPR* %159, i32 0, i32 15, !dbg !2116
  %161 = getelementptr inbounds %struct.Reg, %struct.Reg* %160, i32 0, i32 0, !dbg !2117
  %EBP = bitcast %union.anon* %161 to i32*, !dbg !2117
  %162 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2118
  %163 = getelementptr inbounds %struct.GPR, %struct.GPR* %162, i32 0, i32 33, !dbg !2119
  %164 = getelementptr inbounds %struct.Reg, %struct.Reg* %163, i32 0, i32 0, !dbg !2120
  %EIP = bitcast %union.anon* %164 to i32*, !dbg !2120
  %165 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2121
  %166 = getelementptr inbounds %struct.GPR, %struct.GPR* %165, i32 0, i32 17, !dbg !2122
  %167 = getelementptr inbounds %struct.Reg, %struct.Reg* %166, i32 0, i32 0, !dbg !2123
  %R8D = bitcast %union.anon* %167 to i32*, !dbg !2123
  %168 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2124
  %169 = getelementptr inbounds %struct.GPR, %struct.GPR* %168, i32 0, i32 19, !dbg !2125
  %170 = getelementptr inbounds %struct.Reg, %struct.Reg* %169, i32 0, i32 0, !dbg !2126
  %R9D = bitcast %union.anon* %170 to i32*, !dbg !2126
  %171 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2127
  %172 = getelementptr inbounds %struct.GPR, %struct.GPR* %171, i32 0, i32 21, !dbg !2128
  %173 = getelementptr inbounds %struct.Reg, %struct.Reg* %172, i32 0, i32 0, !dbg !2129
  %R10D = bitcast %union.anon* %173 to i32*, !dbg !2129
  %174 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2130
  %175 = getelementptr inbounds %struct.GPR, %struct.GPR* %174, i32 0, i32 23, !dbg !2131
  %176 = getelementptr inbounds %struct.Reg, %struct.Reg* %175, i32 0, i32 0, !dbg !2132
  %R11D = bitcast %union.anon* %176 to i32*, !dbg !2132
  %177 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2133
  %178 = getelementptr inbounds %struct.GPR, %struct.GPR* %177, i32 0, i32 25, !dbg !2134
  %179 = getelementptr inbounds %struct.Reg, %struct.Reg* %178, i32 0, i32 0, !dbg !2135
  %R12D = bitcast %union.anon* %179 to i32*, !dbg !2135
  %180 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2136
  %181 = getelementptr inbounds %struct.GPR, %struct.GPR* %180, i32 0, i32 27, !dbg !2137
  %182 = getelementptr inbounds %struct.Reg, %struct.Reg* %181, i32 0, i32 0, !dbg !2138
  %R13D = bitcast %union.anon* %182 to i32*, !dbg !2138
  %183 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2139
  %184 = getelementptr inbounds %struct.GPR, %struct.GPR* %183, i32 0, i32 29, !dbg !2140
  %185 = getelementptr inbounds %struct.Reg, %struct.Reg* %184, i32 0, i32 0, !dbg !2141
  %R14D = bitcast %union.anon* %185 to i32*, !dbg !2141
  %186 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2142
  %187 = getelementptr inbounds %struct.GPR, %struct.GPR* %186, i32 0, i32 31, !dbg !2143
  %188 = getelementptr inbounds %struct.Reg, %struct.Reg* %187, i32 0, i32 0, !dbg !2144
  %R15D = bitcast %union.anon* %188 to i32*, !dbg !2144
  %189 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2145
  %190 = getelementptr inbounds %struct.GPR, %struct.GPR* %189, i32 0, i32 1, !dbg !2146
  %191 = getelementptr inbounds %struct.Reg, %struct.Reg* %190, i32 0, i32 0, !dbg !2147
  %RAX = bitcast %union.anon* %191 to i64*, !dbg !2147
  %192 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2148
  %193 = getelementptr inbounds %struct.GPR, %struct.GPR* %192, i32 0, i32 3, !dbg !2149
  %194 = getelementptr inbounds %struct.Reg, %struct.Reg* %193, i32 0, i32 0, !dbg !2150
  %RBX = bitcast %union.anon* %194 to i64*, !dbg !2150
  %195 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2151
  %196 = getelementptr inbounds %struct.GPR, %struct.GPR* %195, i32 0, i32 5, !dbg !2152
  %197 = getelementptr inbounds %struct.Reg, %struct.Reg* %196, i32 0, i32 0, !dbg !2153
  %RCX = bitcast %union.anon* %197 to i64*, !dbg !2153
  %198 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2154
  %199 = getelementptr inbounds %struct.GPR, %struct.GPR* %198, i32 0, i32 7, !dbg !2155
  %200 = getelementptr inbounds %struct.Reg, %struct.Reg* %199, i32 0, i32 0, !dbg !2156
  %RDX = bitcast %union.anon* %200 to i64*, !dbg !2156
  %201 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2157
  %202 = getelementptr inbounds %struct.GPR, %struct.GPR* %201, i32 0, i32 9, !dbg !2158
  %203 = getelementptr inbounds %struct.Reg, %struct.Reg* %202, i32 0, i32 0, !dbg !2159
  %RSI = bitcast %union.anon* %203 to i64*, !dbg !2159
  %204 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2160
  %205 = getelementptr inbounds %struct.GPR, %struct.GPR* %204, i32 0, i32 11, !dbg !2161
  %206 = getelementptr inbounds %struct.Reg, %struct.Reg* %205, i32 0, i32 0, !dbg !2162
  %RDI = bitcast %union.anon* %206 to i64*, !dbg !2162
  %207 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2163
  %208 = getelementptr inbounds %struct.GPR, %struct.GPR* %207, i32 0, i32 13, !dbg !2164
  %209 = getelementptr inbounds %struct.Reg, %struct.Reg* %208, i32 0, i32 0, !dbg !2165
  %RSP = bitcast %union.anon* %209 to i64*, !dbg !2165
  %210 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2166
  %211 = getelementptr inbounds %struct.GPR, %struct.GPR* %210, i32 0, i32 15, !dbg !2167
  %212 = getelementptr inbounds %struct.Reg, %struct.Reg* %211, i32 0, i32 0, !dbg !2168
  %RBP = bitcast %union.anon* %212 to i64*, !dbg !2168
  %213 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2169
  %214 = getelementptr inbounds %struct.GPR, %struct.GPR* %213, i32 0, i32 17, !dbg !2170
  %215 = getelementptr inbounds %struct.Reg, %struct.Reg* %214, i32 0, i32 0, !dbg !2171
  %R8 = bitcast %union.anon* %215 to i64*, !dbg !2171
  %216 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2172
  %217 = getelementptr inbounds %struct.GPR, %struct.GPR* %216, i32 0, i32 19, !dbg !2173
  %218 = getelementptr inbounds %struct.Reg, %struct.Reg* %217, i32 0, i32 0, !dbg !2174
  %R9 = bitcast %union.anon* %218 to i64*, !dbg !2174
  %219 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2175
  %220 = getelementptr inbounds %struct.GPR, %struct.GPR* %219, i32 0, i32 21, !dbg !2176
  %221 = getelementptr inbounds %struct.Reg, %struct.Reg* %220, i32 0, i32 0, !dbg !2177
  %R10 = bitcast %union.anon* %221 to i64*, !dbg !2177
  %222 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2178
  %223 = getelementptr inbounds %struct.GPR, %struct.GPR* %222, i32 0, i32 23, !dbg !2179
  %224 = getelementptr inbounds %struct.Reg, %struct.Reg* %223, i32 0, i32 0, !dbg !2180
  %R11 = bitcast %union.anon* %224 to i64*, !dbg !2180
  %225 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2181
  %226 = getelementptr inbounds %struct.GPR, %struct.GPR* %225, i32 0, i32 25, !dbg !2182
  %227 = getelementptr inbounds %struct.Reg, %struct.Reg* %226, i32 0, i32 0, !dbg !2183
  %R12 = bitcast %union.anon* %227 to i64*, !dbg !2183
  %228 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2184
  %229 = getelementptr inbounds %struct.GPR, %struct.GPR* %228, i32 0, i32 27, !dbg !2185
  %230 = getelementptr inbounds %struct.Reg, %struct.Reg* %229, i32 0, i32 0, !dbg !2186
  %R13 = bitcast %union.anon* %230 to i64*, !dbg !2186
  %231 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2187
  %232 = getelementptr inbounds %struct.GPR, %struct.GPR* %231, i32 0, i32 29, !dbg !2188
  %233 = getelementptr inbounds %struct.Reg, %struct.Reg* %232, i32 0, i32 0, !dbg !2189
  %R14 = bitcast %union.anon* %233 to i64*, !dbg !2189
  %234 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2190
  %235 = getelementptr inbounds %struct.GPR, %struct.GPR* %234, i32 0, i32 31, !dbg !2191
  %236 = getelementptr inbounds %struct.Reg, %struct.Reg* %235, i32 0, i32 0, !dbg !2192
  %R15 = bitcast %union.anon* %236 to i64*, !dbg !2192
  %237 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2193
  %238 = getelementptr inbounds %struct.GPR, %struct.GPR* %237, i32 0, i32 33, !dbg !2194
  %239 = getelementptr inbounds %struct.Reg, %struct.Reg* %238, i32 0, i32 0, !dbg !2195
  %RIP = bitcast %union.anon* %239 to i64*, !dbg !2195
  %240 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2196
  %241 = getelementptr inbounds %struct.Segments, %struct.Segments* %240, i32 0, i32 1, !dbg !2197
  %SS = bitcast %union.SegmentSelector* %241 to i16*, !dbg !2198
  %242 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2199
  %243 = getelementptr inbounds %struct.Segments, %struct.Segments* %242, i32 0, i32 3, !dbg !2200
  %ES = bitcast %union.SegmentSelector* %243 to i16*, !dbg !2201
  %244 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2202
  %245 = getelementptr inbounds %struct.Segments, %struct.Segments* %244, i32 0, i32 5, !dbg !2203
  %GS = bitcast %union.SegmentSelector* %245 to i16*, !dbg !2204
  %246 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2205
  %247 = getelementptr inbounds %struct.Segments, %struct.Segments* %246, i32 0, i32 7, !dbg !2206
  %FS = bitcast %union.SegmentSelector* %247 to i16*, !dbg !2207
  %248 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2208
  %249 = getelementptr inbounds %struct.Segments, %struct.Segments* %248, i32 0, i32 9, !dbg !2209
  %DS = bitcast %union.SegmentSelector* %249 to i16*, !dbg !2210
  %250 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2211
  %251 = getelementptr inbounds %struct.Segments, %struct.Segments* %250, i32 0, i32 11, !dbg !2212
  %CS = bitcast %union.SegmentSelector* %251 to i16*, !dbg !2213
  %252 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 5, !dbg !2214
  %253 = getelementptr inbounds %struct.AddressSpace, %struct.AddressSpace* %252, i32 0, i32 5, !dbg !2215
  %254 = getelementptr inbounds %struct.Reg, %struct.Reg* %253, i32 0, i32 0, !dbg !2216
  %GS_BASE = bitcast %union.anon* %254 to i64*, !dbg !2216
  %255 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 5, !dbg !2217
  %256 = getelementptr inbounds %struct.AddressSpace, %struct.AddressSpace* %255, i32 0, i32 7, !dbg !2218
  %257 = getelementptr inbounds %struct.Reg, %struct.Reg* %256, i32 0, i32 0, !dbg !2219
  %FS_BASE = bitcast %union.anon* %257 to i64*, !dbg !2219
  %258 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2220
  %259 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %258, i64 0, i64 0, !dbg !2221
  %YMM0 = bitcast %union.VectorReg* %259 to %"class.std::bitset"*, !dbg !2222
  %260 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2223
  %261 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %260, i64 0, i64 1, !dbg !2224
  %YMM1 = bitcast %union.VectorReg* %261 to %"class.std::bitset"*, !dbg !2225
  %262 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2226
  %263 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %262, i64 0, i64 2, !dbg !2227
  %YMM2 = bitcast %union.VectorReg* %263 to %"class.std::bitset"*, !dbg !2228
  %264 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2229
  %265 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %264, i64 0, i64 3, !dbg !2230
  %YMM3 = bitcast %union.VectorReg* %265 to %"class.std::bitset"*, !dbg !2231
  %266 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2232
  %267 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %266, i64 0, i64 4, !dbg !2233
  %YMM4 = bitcast %union.VectorReg* %267 to %"class.std::bitset"*, !dbg !2234
  %268 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2235
  %269 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %268, i64 0, i64 5, !dbg !2236
  %YMM5 = bitcast %union.VectorReg* %269 to %"class.std::bitset"*, !dbg !2237
  %270 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2238
  %271 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %270, i64 0, i64 6, !dbg !2239
  %YMM6 = bitcast %union.VectorReg* %271 to %"class.std::bitset"*, !dbg !2240
  %272 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2241
  %273 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %272, i64 0, i64 7, !dbg !2242
  %YMM7 = bitcast %union.VectorReg* %273 to %"class.std::bitset"*, !dbg !2243
  %274 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2244
  %275 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %274, i64 0, i64 8, !dbg !2245
  %YMM8 = bitcast %union.VectorReg* %275 to %"class.std::bitset"*, !dbg !2246
  %276 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2247
  %277 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %276, i64 0, i64 9, !dbg !2248
  %YMM9 = bitcast %union.VectorReg* %277 to %"class.std::bitset"*, !dbg !2249
  %278 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2250
  %279 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %278, i64 0, i64 10, !dbg !2251
  %YMM10 = bitcast %union.VectorReg* %279 to %"class.std::bitset"*, !dbg !2252
  %280 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2253
  %281 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %280, i64 0, i64 11, !dbg !2254
  %YMM11 = bitcast %union.VectorReg* %281 to %"class.std::bitset"*, !dbg !2255
  %282 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2256
  %283 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %282, i64 0, i64 12, !dbg !2257
  %YMM12 = bitcast %union.VectorReg* %283 to %"class.std::bitset"*, !dbg !2258
  %284 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2259
  %285 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %284, i64 0, i64 13, !dbg !2260
  %YMM13 = bitcast %union.VectorReg* %285 to %"class.std::bitset"*, !dbg !2261
  %286 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2262
  %287 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %286, i64 0, i64 14, !dbg !2263
  %YMM14 = bitcast %union.VectorReg* %287 to %"class.std::bitset"*, !dbg !2264
  %288 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2265
  %289 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %288, i64 0, i64 15, !dbg !2266
  %YMM15 = bitcast %union.VectorReg* %289 to %"class.std::bitset"*, !dbg !2267
  %290 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2268
  %291 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %290, i64 0, i64 0, !dbg !2269
  %XMM0 = bitcast %union.VectorReg* %291 to %union.vec128_t*, !dbg !2270
  %292 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2271
  %293 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %292, i64 0, i64 1, !dbg !2272
  %XMM1 = bitcast %union.VectorReg* %293 to %union.vec128_t*, !dbg !2273
  %294 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2274
  %295 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %294, i64 0, i64 2, !dbg !2275
  %XMM2 = bitcast %union.VectorReg* %295 to %union.vec128_t*, !dbg !2276
  %296 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2277
  %297 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %296, i64 0, i64 3, !dbg !2278
  %XMM3 = bitcast %union.VectorReg* %297 to %union.vec128_t*, !dbg !2279
  %298 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2280
  %299 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %298, i64 0, i64 4, !dbg !2281
  %XMM4 = bitcast %union.VectorReg* %299 to %union.vec128_t*, !dbg !2282
  %300 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2283
  %301 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %300, i64 0, i64 5, !dbg !2284
  %XMM5 = bitcast %union.VectorReg* %301 to %union.vec128_t*, !dbg !2285
  %302 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2286
  %303 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %302, i64 0, i64 6, !dbg !2287
  %XMM6 = bitcast %union.VectorReg* %303 to %union.vec128_t*, !dbg !2288
  %304 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2289
  %305 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %304, i64 0, i64 7, !dbg !2290
  %XMM7 = bitcast %union.VectorReg* %305 to %union.vec128_t*, !dbg !2291
  %306 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2292
  %307 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %306, i64 0, i64 8, !dbg !2293
  %XMM8 = bitcast %union.VectorReg* %307 to %union.vec128_t*, !dbg !2294
  %308 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2295
  %309 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %308, i64 0, i64 9, !dbg !2296
  %XMM9 = bitcast %union.VectorReg* %309 to %union.vec128_t*, !dbg !2297
  %310 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2298
  %311 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %310, i64 0, i64 10, !dbg !2299
  %XMM10 = bitcast %union.VectorReg* %311 to %union.vec128_t*, !dbg !2300
  %312 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2301
  %313 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %312, i64 0, i64 11, !dbg !2302
  %XMM11 = bitcast %union.VectorReg* %313 to %union.vec128_t*, !dbg !2303
  %314 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2304
  %315 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %314, i64 0, i64 12, !dbg !2305
  %XMM12 = bitcast %union.VectorReg* %315 to %union.vec128_t*, !dbg !2306
  %316 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2307
  %317 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %316, i64 0, i64 13, !dbg !2308
  %XMM13 = bitcast %union.VectorReg* %317 to %union.vec128_t*, !dbg !2309
  %318 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2310
  %319 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %318, i64 0, i64 14, !dbg !2311
  %XMM14 = bitcast %union.VectorReg* %319 to %union.vec128_t*, !dbg !2312
  %320 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2313
  %321 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %320, i64 0, i64 15, !dbg !2314
  %XMM15 = bitcast %union.VectorReg* %321 to %union.vec128_t*, !dbg !2315
  %322 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2316
  %323 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %322, i32 0, i32 0, !dbg !2317
  %324 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %323, i64 0, i64 0, !dbg !2318
  %ST0 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %324, i32 0, i32 1, !dbg !2319
  %325 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2320
  %326 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %325, i32 0, i32 0, !dbg !2321
  %327 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %326, i64 0, i64 1, !dbg !2322
  %ST1 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %327, i32 0, i32 1, !dbg !2323
  %328 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2324
  %329 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %328, i32 0, i32 0, !dbg !2325
  %330 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %329, i64 0, i64 2, !dbg !2326
  %ST2 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %330, i32 0, i32 1, !dbg !2327
  %331 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2328
  %332 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %331, i32 0, i32 0, !dbg !2329
  %333 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %332, i64 0, i64 3, !dbg !2330
  %ST3 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %333, i32 0, i32 1, !dbg !2331
  %334 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2332
  %335 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %334, i32 0, i32 0, !dbg !2333
  %336 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %335, i64 0, i64 4, !dbg !2334
  %ST4 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %336, i32 0, i32 1, !dbg !2335
  %337 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2336
  %338 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %337, i32 0, i32 0, !dbg !2337
  %339 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %338, i64 0, i64 5, !dbg !2338
  %ST5 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %339, i32 0, i32 1, !dbg !2339
  %340 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2340
  %341 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %340, i32 0, i32 0, !dbg !2341
  %342 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %341, i64 0, i64 6, !dbg !2342
  %ST6 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %342, i32 0, i32 1, !dbg !2343
  %343 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2344
  %344 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %343, i32 0, i32 0, !dbg !2345
  %345 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %344, i64 0, i64 7, !dbg !2346
  %ST7 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %345, i32 0, i32 1, !dbg !2347
  %346 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2348
  %347 = getelementptr inbounds %struct.MMX, %struct.MMX* %346, i32 0, i32 0, !dbg !2349
  %348 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %347, i64 0, i64 0, !dbg !2350
  %349 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %348, i32 0, i32 1, !dbg !2351
  %350 = bitcast %union.vec64_t* %349 to %struct.uint64v1_t*, !dbg !2352
  %351 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %350, i32 0, i32 0, !dbg !2353
  %MM0 = getelementptr inbounds [1 x i64], [1 x i64]* %351, i64 0, i64 0, !dbg !2350
  %352 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2354
  %353 = getelementptr inbounds %struct.MMX, %struct.MMX* %352, i32 0, i32 0, !dbg !2355
  %354 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %353, i64 0, i64 1, !dbg !2356
  %355 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %354, i32 0, i32 1, !dbg !2357
  %356 = bitcast %union.vec64_t* %355 to %struct.uint64v1_t*, !dbg !2358
  %357 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %356, i32 0, i32 0, !dbg !2359
  %MM1 = getelementptr inbounds [1 x i64], [1 x i64]* %357, i64 0, i64 0, !dbg !2356
  %358 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2360
  %359 = getelementptr inbounds %struct.MMX, %struct.MMX* %358, i32 0, i32 0, !dbg !2361
  %360 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %359, i64 0, i64 2, !dbg !2362
  %361 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %360, i32 0, i32 1, !dbg !2363
  %362 = bitcast %union.vec64_t* %361 to %struct.uint64v1_t*, !dbg !2364
  %363 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %362, i32 0, i32 0, !dbg !2365
  %MM2 = getelementptr inbounds [1 x i64], [1 x i64]* %363, i64 0, i64 0, !dbg !2362
  %364 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2366
  %365 = getelementptr inbounds %struct.MMX, %struct.MMX* %364, i32 0, i32 0, !dbg !2367
  %366 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %365, i64 0, i64 3, !dbg !2368
  %367 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %366, i32 0, i32 1, !dbg !2369
  %368 = bitcast %union.vec64_t* %367 to %struct.uint64v1_t*, !dbg !2370
  %369 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %368, i32 0, i32 0, !dbg !2371
  %MM3 = getelementptr inbounds [1 x i64], [1 x i64]* %369, i64 0, i64 0, !dbg !2368
  %370 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2372
  %371 = getelementptr inbounds %struct.MMX, %struct.MMX* %370, i32 0, i32 0, !dbg !2373
  %372 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %371, i64 0, i64 4, !dbg !2374
  %373 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %372, i32 0, i32 1, !dbg !2375
  %374 = bitcast %union.vec64_t* %373 to %struct.uint64v1_t*, !dbg !2376
  %375 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %374, i32 0, i32 0, !dbg !2377
  %MM4 = getelementptr inbounds [1 x i64], [1 x i64]* %375, i64 0, i64 0, !dbg !2374
  %376 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2378
  %377 = getelementptr inbounds %struct.MMX, %struct.MMX* %376, i32 0, i32 0, !dbg !2379
  %378 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %377, i64 0, i64 5, !dbg !2380
  %379 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %378, i32 0, i32 1, !dbg !2381
  %380 = bitcast %union.vec64_t* %379 to %struct.uint64v1_t*, !dbg !2382
  %381 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %380, i32 0, i32 0, !dbg !2383
  %MM5 = getelementptr inbounds [1 x i64], [1 x i64]* %381, i64 0, i64 0, !dbg !2380
  %382 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2384
  %383 = getelementptr inbounds %struct.MMX, %struct.MMX* %382, i32 0, i32 0, !dbg !2385
  %384 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %383, i64 0, i64 6, !dbg !2386
  %385 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %384, i32 0, i32 1, !dbg !2387
  %386 = bitcast %union.vec64_t* %385 to %struct.uint64v1_t*, !dbg !2388
  %387 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %386, i32 0, i32 0, !dbg !2389
  %MM6 = getelementptr inbounds [1 x i64], [1 x i64]* %387, i64 0, i64 0, !dbg !2386
  %388 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2390
  %389 = getelementptr inbounds %struct.MMX, %struct.MMX* %388, i32 0, i32 0, !dbg !2391
  %390 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %389, i64 0, i64 7, !dbg !2392
  %391 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %390, i32 0, i32 1, !dbg !2393
  %392 = bitcast %union.vec64_t* %391 to %struct.uint64v1_t*, !dbg !2394
  %393 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %392, i32 0, i32 0, !dbg !2395
  %MM7 = getelementptr inbounds [1 x i64], [1 x i64]* %393, i64 0, i64 0, !dbg !2392
  %394 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2396
  %AF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %394, i32 0, i32 5, !dbg !2397
  %395 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2398
  %CF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %395, i32 0, i32 1, !dbg !2399
  %396 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2400
  %DF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %396, i32 0, i32 11, !dbg !2401
  %397 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2402
  %OF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %397, i32 0, i32 13, !dbg !2403
  %398 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2404
  %PF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %398, i32 0, i32 3, !dbg !2405
  %399 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2406
  %SF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %399, i32 0, i32 9, !dbg !2407
  %400 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2408
  %ZF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %400, i32 0, i32 7, !dbg !2409
  store i64* @DR0, i64** %_DR0, align 8, !dbg !2410
  store i64* @DR1, i64** %_DR1, align 8, !dbg !2411
  store i64* @DR2, i64** %_DR2, align 8, !dbg !2412
  store i64* @DR3, i64** %_DR3, align 8, !dbg !2413
  store i64* @DR4, i64** %_DR4, align 8, !dbg !2414
  store i64* @DR5, i64** %_DR5, align 8, !dbg !2415
  store i64* @DR6, i64** %_DR6, align 8, !dbg !2416
  store i64* @DR7, i64** %_DR7, align 8, !dbg !2417
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR0, i32 0, i32 0), i64** %CR0, align 8, !dbg !2418
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR1, i32 0, i32 0), i64** %CR1, align 8, !dbg !2419
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR2, i32 0, i32 0), i64** %CR2, align 8, !dbg !2420
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR3, i32 0, i32 0), i64** %CR3, align 8, !dbg !2421
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR4, i32 0, i32 0), i64** %CR4, align 8, !dbg !2422
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR8, i32 0, i32 0), i64** %CR8, align 8, !dbg !2423
  ret %struct.Memory* %2, !dbg !2424
}

; Function Attrs: noduplicate noinline nounwind optnone
define void @__remill_intrinsics() local_unnamed_addr #4 !dbg !2425 {
  ret void, !dbg !2427
}

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_function_call(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #5

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memcpy(i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @printf(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @__libc_start_main(i64, i64, i64, i64, i64, i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @free(i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @__gmon_start__() #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memset(i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @abort() #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @gettimeofday(i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memalign(i64, i64) #6

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400fe0_putdata(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400fe0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %5 to i32*
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %6 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %6, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %9 = load i64, i64* %RBP, align 8
  %10 = add i64 %1, 1
  store i64 %10, i64* %PC, align 8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %12 = load i64, i64* %11, align 8, !tbaa !2428
  %13 = add i64 %12, -8
  %14 = inttoptr i64 %13 to i64*
  store i64 %9, i64* %14, align 8
  store i64 %13, i64* %11, align 8, !tbaa !2428
  %15 = load i64, i64* %PC, align 8
  store i64 %13, i64* %RBP, align 8, !tbaa !2428
  %16 = add i64 %12, -12
  %17 = load i32, i32* %EDI, align 4
  %18 = add i64 %15, 6
  store i64 %18, i64* %PC, align 8
  %19 = inttoptr i64 %16 to i32*
  store i32 %17, i32* %19, align 4
  %20 = load i64, i64* %RBP, align 8
  %21 = add i64 %20, -8
  %22 = load i32, i32* %ESI, align 4
  %23 = load i64, i64* %PC, align 8
  %24 = add i64 %23, 3
  store i64 %24, i64* %PC, align 8
  %25 = inttoptr i64 %21 to i32*
  store i32 %22, i32* %25, align 4
  %26 = load i64, i64* %RBP, align 8
  %27 = add i64 %26, -16
  %28 = load i64, i64* %RDX, align 8
  %29 = load i64, i64* %PC, align 8
  %30 = add i64 %29, 4
  store i64 %30, i64* %PC, align 8
  %31 = inttoptr i64 %27 to i64*
  store i64 %28, i64* %31, align 8
  %32 = load i64, i64* %RBP, align 8
  %33 = add i64 %32, -24
  %34 = load i64, i64* %PC, align 8
  %35 = add i64 %34, 7
  store i64 %35, i64* %PC, align 8
  %36 = inttoptr i64 %33 to i32*
  store i32 0, i32* %36, align 4
  %37 = load i64, i64* %RBP, align 8
  %38 = add i64 %37, -4
  %39 = load i64, i64* %PC, align 8
  %40 = add i64 %39, 3
  store i64 %40, i64* %PC, align 8
  %41 = inttoptr i64 %38 to i32*
  %42 = load i32, i32* %41, align 4
  %43 = zext i32 %42 to i64
  store i64 %43, i64* %RSI, align 8, !tbaa !2428
  %44 = add i64 %37, -20
  %45 = add i64 %39, 6
  store i64 %45, i64* %PC, align 8
  %46 = inttoptr i64 %44 to i32*
  store i32 %42, i32* %46, align 4
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %48 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %49 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %50 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %53 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %55 = bitcast i64* %54 to double*
  %56 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %57 = bitcast %union.VectorReg* %8 to double*
  %58 = bitcast [32 x %union.VectorReg]* %7 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_400ffb

block_400ffb:                                     ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit, %block_400fe0
  %59 = phi i64 [ %.pre, %block_400fe0 ], [ %212, %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_400fe0 ], [ %158, %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit ]
  %60 = load i64, i64* %RBP, align 8
  %61 = add i64 %60, -20
  %62 = add i64 %59, 3
  store i64 %62, i64* %PC, align 8
  %63 = inttoptr i64 %61 to i32*
  %64 = load i32, i32* %63, align 4
  %65 = zext i32 %64 to i64
  store i64 %65, i64* %RAX, align 8, !tbaa !2428
  %66 = add i64 %60, -8
  %67 = add i64 %59, 6
  store i64 %67, i64* %PC, align 8
  %68 = inttoptr i64 %66 to i32*
  %69 = load i32, i32* %68, align 4
  %70 = sub i32 %64, %69
  %71 = icmp ult i32 %64, %69
  %72 = zext i1 %71 to i8
  store i8 %72, i8* %47, align 1, !tbaa !2432
  %73 = and i32 %70, 255
  %74 = tail call i32 @llvm.ctpop.i32(i32 %73) #14
  %75 = trunc i32 %74 to i8
  %76 = and i8 %75, 1
  %77 = xor i8 %76, 1
  store i8 %77, i8* %48, align 1, !tbaa !2446
  %78 = xor i32 %69, %64
  %79 = xor i32 %78, %70
  %80 = lshr i32 %79, 4
  %81 = trunc i32 %80 to i8
  %82 = and i8 %81, 1
  store i8 %82, i8* %49, align 1, !tbaa !2447
  %83 = icmp eq i32 %70, 0
  %84 = zext i1 %83 to i8
  store i8 %84, i8* %50, align 1, !tbaa !2448
  %85 = lshr i32 %70, 31
  %86 = trunc i32 %85 to i8
  store i8 %86, i8* %51, align 1, !tbaa !2449
  %87 = lshr i32 %64, 31
  %88 = lshr i32 %69, 31
  %89 = xor i32 %88, %87
  %90 = xor i32 %85, %87
  %91 = add nuw nsw i32 %90, %89
  %92 = icmp eq i32 %91, 2
  %93 = zext i1 %92 to i8
  store i8 %93, i8* %52, align 1, !tbaa !2450
  %94 = icmp ne i8 %86, 0
  %95 = xor i1 %94, %92
  %.demorgan = or i1 %83, %95
  %.v = select i1 %.demorgan, i64 12, i64 87
  %96 = add i64 %59, %.v
  store i64 %96, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan, label %block_401007, label %block_401052

block_401007:                                     ; preds = %block_400ffb
  %97 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 72) to i64*), align 8
  store i64 %97, i64* %53, align 1, !tbaa !2451
  store double 0.000000e+00, double* %55, align 1, !tbaa !2451
  store i64 259200, i64* %RAX, align 8, !tbaa !2428
  %98 = add i64 %60, -24
  %99 = add i64 %96, 20
  store i64 %99, i64* %PC, align 8
  %100 = inttoptr i64 %98 to i32*
  %101 = load i32, i32* %100, align 4
  %102 = mul i32 %101, 7141
  %103 = add i32 %102, 54773
  %104 = zext i32 %103 to i64
  store i64 %104, i64* %RCX, align 8, !tbaa !2428
  %105 = icmp ugt i32 %102, -54774
  %106 = zext i1 %105 to i8
  store i8 %106, i8* %47, align 1, !tbaa !2432
  %107 = and i32 %103, 255
  %108 = tail call i32 @llvm.ctpop.i32(i32 %107) #14
  %109 = trunc i32 %108 to i8
  %110 = and i8 %109, 1
  %111 = xor i8 %110, 1
  store i8 %111, i8* %48, align 1, !tbaa !2446
  %112 = xor i32 %102, 16
  %113 = xor i32 %112, %103
  %114 = lshr i32 %113, 4
  %115 = trunc i32 %114 to i8
  %116 = and i8 %115, 1
  store i8 %116, i8* %49, align 1, !tbaa !2447
  %117 = icmp eq i32 %103, 0
  %118 = zext i1 %117 to i8
  store i8 %118, i8* %50, align 1, !tbaa !2448
  %119 = lshr i32 %103, 31
  %120 = trunc i32 %119 to i8
  store i8 %120, i8* %51, align 1, !tbaa !2449
  %121 = lshr i32 %102, 31
  %122 = xor i32 %119, %121
  %123 = add nuw nsw i32 %122, %119
  %124 = icmp eq i32 %123, 2
  %125 = zext i1 %124 to i8
  store i8 %125, i8* %52, align 1, !tbaa !2450
  %126 = add i64 %60, -28
  %127 = add i64 %96, 29
  store i64 %127, i64* %PC, align 8
  %128 = inttoptr i64 %126 to i32*
  store i32 259200, i32* %128, align 4
  %129 = load i32, i32* %ECX, align 4
  %130 = zext i32 %129 to i64
  %131 = load i64, i64* %PC, align 8
  store i64 %130, i64* %RAX, align 8, !tbaa !2428
  %132 = sext i32 %129 to i64
  %133 = lshr i64 %132, 32
  store i64 %133, i64* %56, align 8, !tbaa !2428
  %134 = load i64, i64* %RBP, align 8
  %135 = add i64 %134, -28
  %136 = add i64 %131, 6
  store i64 %136, i64* %PC, align 8
  %137 = inttoptr i64 %135 to i32*
  %138 = load i32, i32* %137, align 4
  %139 = zext i32 %138 to i64
  store i64 %139, i64* %RCX, align 8, !tbaa !2428
  %140 = add i64 %131, 8
  store i64 %140, i64* %PC, align 8
  %141 = sext i32 %138 to i64
  %142 = shl nuw i64 %133, 32
  %143 = or i64 %142, %130
  %144 = sdiv i64 %143, %141
  %145 = shl i64 %144, 32
  %146 = ashr exact i64 %145, 32
  %147 = icmp eq i64 %144, %146
  br i1 %147, label %150, label %148

; <label>:148:                                    ; preds = %block_401007
  %149 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %140, %struct.Memory* %MEMORY.0) #16
  %.pre1 = load i64, i64* %RBP, align 8
  %.pre2 = load i32, i32* %EDX, align 4
  %.pre3 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:150:                                    ; preds = %block_401007
  %151 = srem i64 %143, %141
  %152 = and i64 %144, 4294967295
  store i64 %152, i64* %RAX, align 8, !tbaa !2428
  %153 = and i64 %151, 4294967295
  store i64 %153, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %47, align 1, !tbaa !2432
  store i8 0, i8* %48, align 1, !tbaa !2446
  store i8 0, i8* %49, align 1, !tbaa !2447
  store i8 0, i8* %50, align 1, !tbaa !2448
  store i8 0, i8* %51, align 1, !tbaa !2449
  store i8 0, i8* %52, align 1, !tbaa !2450
  %154 = trunc i64 %151 to i32
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %150, %148
  %155 = phi i64 [ %.pre3, %148 ], [ %140, %150 ]
  %156 = phi i32 [ %.pre2, %148 ], [ %154, %150 ]
  %157 = phi i64 [ %.pre1, %148 ], [ %134, %150 ]
  %158 = phi %struct.Memory* [ %149, %148 ], [ %MEMORY.0, %150 ]
  %159 = add i64 %157, -24
  %160 = add i64 %155, 3
  store i64 %160, i64* %PC, align 8
  %161 = inttoptr i64 %159 to i32*
  store i32 %156, i32* %161, align 4
  %162 = load i32, i32* %EDX, align 4
  %163 = load i64, i64* %PC, align 8
  %164 = sitofp i32 %162 to double
  %165 = load double, double* %58, align 1
  %166 = fmul double %164, %165
  store double %166, double* %57, align 1, !tbaa !2451
  %167 = load i64, i64* %RBP, align 8
  %168 = add i64 %167, -16
  %169 = add i64 %163, 12
  store i64 %169, i64* %PC, align 8
  %170 = inttoptr i64 %168 to i64*
  %171 = load i64, i64* %170, align 8
  store i64 %171, i64* %RSI, align 8, !tbaa !2428
  %172 = add i64 %167, -20
  %173 = add i64 %163, 16
  store i64 %173, i64* %PC, align 8
  %174 = inttoptr i64 %172 to i32*
  %175 = load i32, i32* %174, align 4
  %176 = sext i32 %175 to i64
  store i64 %176, i64* %RDI, align 8, !tbaa !2428
  %177 = shl nsw i64 %176, 3
  %178 = add i64 %177, %171
  %179 = add i64 %163, 21
  store i64 %179, i64* %PC, align 8
  %180 = inttoptr i64 %178 to double*
  store double %166, double* %180, align 8
  %181 = load i64, i64* %RBP, align 8
  %182 = add i64 %181, -20
  %183 = load i64, i64* %PC, align 8
  %184 = add i64 %183, 3
  store i64 %184, i64* %PC, align 8
  %185 = inttoptr i64 %182 to i32*
  %186 = load i32, i32* %185, align 4
  %187 = add i32 %186, 1
  %188 = zext i32 %187 to i64
  store i64 %188, i64* %RAX, align 8, !tbaa !2428
  %189 = icmp eq i32 %186, -1
  %190 = icmp eq i32 %187, 0
  %191 = or i1 %189, %190
  %192 = zext i1 %191 to i8
  store i8 %192, i8* %47, align 1, !tbaa !2432
  %193 = and i32 %187, 255
  %194 = tail call i32 @llvm.ctpop.i32(i32 %193) #14
  %195 = trunc i32 %194 to i8
  %196 = and i8 %195, 1
  %197 = xor i8 %196, 1
  store i8 %197, i8* %48, align 1, !tbaa !2446
  %198 = xor i32 %187, %186
  %199 = lshr i32 %198, 4
  %200 = trunc i32 %199 to i8
  %201 = and i8 %200, 1
  store i8 %201, i8* %49, align 1, !tbaa !2447
  %202 = zext i1 %190 to i8
  store i8 %202, i8* %50, align 1, !tbaa !2448
  %203 = lshr i32 %187, 31
  %204 = trunc i32 %203 to i8
  store i8 %204, i8* %51, align 1, !tbaa !2449
  %205 = lshr i32 %186, 31
  %206 = xor i32 %203, %205
  %207 = add nuw nsw i32 %206, %203
  %208 = icmp eq i32 %207, 2
  %209 = zext i1 %208 to i8
  store i8 %209, i8* %52, align 1, !tbaa !2450
  %210 = add i64 %183, 9
  store i64 %210, i64* %PC, align 8
  store i32 %187, i32* %185, align 4
  %211 = load i64, i64* %PC, align 8
  %212 = add i64 %211, -82
  store i64 %212, i64* %PC, align 8, !tbaa !2428
  br label %block_400ffb

block_401052:                                     ; preds = %block_400ffb
  %213 = add i64 %96, 1
  store i64 %213, i64* %PC, align 8
  %214 = load i64, i64* %11, align 8, !tbaa !2428
  %215 = add i64 %214, 8
  %216 = inttoptr i64 %214 to i64*
  %217 = load i64, i64* %216, align 8
  store i64 %217, i64* %RBP, align 8, !tbaa !2428
  store i64 %215, i64* %11, align 8, !tbaa !2428
  %218 = add i64 %96, 2
  store i64 %218, i64* %PC, align 8
  %219 = inttoptr i64 %215 to i64*
  %220 = load i64, i64* %219, align 8
  store i64 %220, i64* %PC, align 8, !tbaa !2428
  %221 = add i64 %214, 16
  store i64 %221, i64* %11, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400688__init_proc(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400688:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = add i64 %3, -8
  store i64 %4, i64* %RSP, align 8, !tbaa !2428
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_604ff0__got_type* @seg_604ff0__got to i64), i64 8) to i64*), align 8
  store i64 %11, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %5, align 1, !tbaa !2432
  %12 = trunc i64 %11 to i32
  %13 = and i32 %12, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13) #14
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %6, align 1, !tbaa !2446
  %18 = icmp eq i64 %11, 0
  %19 = zext i1 %18 to i8
  store i8 %19, i8* %8, align 1, !tbaa !2448
  %20 = lshr i64 %11, 63
  %21 = trunc i64 %20 to i8
  store i8 %21, i8* %9, align 1, !tbaa !2449
  store i8 0, i8* %10, align 1, !tbaa !2450
  store i8 0, i8* %7, align 1, !tbaa !2447
  %.v = select i1 %18, i64 18, i64 16
  %22 = add i64 %.v, %1
  store i64 %22, i64* %PC, align 8, !tbaa !2428
  br i1 %18, label %block_40069a, label %block_400698

block_400698:                                     ; preds = %block_400688
  %23 = add i64 %22, 2
  %24 = add i64 %3, -16
  %25 = inttoptr i64 %24 to i64*
  store i64 %23, i64* %25, align 8
  store i64 %24, i64* %RSP, align 8, !tbaa !2428
  store i64 %11, i64* %PC, align 8, !tbaa !2428
  %26 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 %11, %struct.Memory* %2)
  %.pre = load i64, i64* %RSP, align 8
  %.pre1 = load i64, i64* %PC, align 8
  br label %block_40069a

block_40069a:                                     ; preds = %block_400698, %block_400688
  %27 = phi i64 [ %22, %block_400688 ], [ %.pre1, %block_400698 ]
  %28 = phi i64 [ %4, %block_400688 ], [ %.pre, %block_400698 ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_400688 ], [ %26, %block_400698 ]
  %29 = add i64 %28, 8
  store i64 %29, i64* %RSP, align 8, !tbaa !2428
  %30 = icmp ugt i64 %28, -9
  %31 = zext i1 %30 to i8
  store i8 %31, i8* %5, align 1, !tbaa !2432
  %32 = trunc i64 %29 to i32
  %33 = and i32 %32, 255
  %34 = tail call i32 @llvm.ctpop.i32(i32 %33) #14
  %35 = trunc i32 %34 to i8
  %36 = and i8 %35, 1
  %37 = xor i8 %36, 1
  store i8 %37, i8* %6, align 1, !tbaa !2446
  %38 = xor i64 %29, %28
  %39 = lshr i64 %38, 4
  %40 = trunc i64 %39 to i8
  %41 = and i8 %40, 1
  store i8 %41, i8* %7, align 1, !tbaa !2447
  %42 = icmp eq i64 %29, 0
  %43 = zext i1 %42 to i8
  store i8 %43, i8* %8, align 1, !tbaa !2448
  %44 = lshr i64 %29, 63
  %45 = trunc i64 %44 to i8
  store i8 %45, i8* %9, align 1, !tbaa !2449
  %46 = lshr i64 %28, 63
  %47 = xor i64 %44, %46
  %48 = add nuw nsw i64 %47, %44
  %49 = icmp eq i64 %48, 2
  %50 = zext i1 %49 to i8
  store i8 %50, i8* %10, align 1, !tbaa !2450
  %51 = add i64 %27, 5
  store i64 %51, i64* %PC, align 8
  %52 = inttoptr i64 %29 to i64*
  %53 = load i64, i64* %52, align 8
  store i64 %53, i64* %PC, align 8, !tbaa !2428
  %54 = add i64 %28, 16
  store i64 %54, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0
}

; Function Attrs: noinline
define %struct.Memory* @sub_404020___libc_csu_init(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #8 {
block_404020:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 27, i32 0
  %R13D = bitcast %union.anon* %4 to i32*
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 25, i32 0, i32 0
  %R13 = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %R14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 29, i32 0, i32 0
  %R15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 31, i32 0, i32 0
  %5 = load i64, i64* %R15, align 8
  %6 = add i64 %1, 2
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %R14, align 8
  %11 = load i64, i64* %PC, align 8
  %12 = add i64 %11, 2
  store i64 %12, i64* %PC, align 8
  %13 = add i64 %7, -16
  %14 = inttoptr i64 %13 to i64*
  store i64 %10, i64* %14, align 8
  %15 = load i64, i64* %RDX, align 8
  %16 = load i64, i64* %PC, align 8
  store i64 %15, i64* %R15, align 8, !tbaa !2428
  %17 = load i64, i64* %R13, align 8
  %18 = add i64 %16, 5
  store i64 %18, i64* %PC, align 8
  %19 = add i64 %7, -24
  %20 = inttoptr i64 %19 to i64*
  store i64 %17, i64* %20, align 8
  %21 = load i64, i64* %R12, align 8
  %22 = load i64, i64* %PC, align 8
  %23 = add i64 %22, 2
  store i64 %23, i64* %PC, align 8
  %24 = add i64 %7, -32
  %25 = inttoptr i64 %24 to i64*
  store i64 %21, i64* %25, align 8
  %26 = load i64, i64* %PC, align 8
  store i64 ptrtoint (%seg_604de0__init_array_type* @seg_604de0__init_array to i64), i64* %R12, align 8, !tbaa !2428
  %27 = load i64, i64* %RBP, align 8
  %28 = add i64 %26, 8
  store i64 %28, i64* %PC, align 8
  %29 = add i64 %7, -40
  %30 = inttoptr i64 %29 to i64*
  store i64 %27, i64* %30, align 8
  %31 = load i64, i64* %PC, align 8
  store i64 add (i64 ptrtoint (%seg_604de0__init_array_type* @seg_604de0__init_array to i64), i64 8), i64* %RBP, align 8, !tbaa !2428
  %32 = load i64, i64* %RBX, align 8
  %33 = add i64 %31, 8
  store i64 %33, i64* %PC, align 8
  %34 = add i64 %7, -48
  %35 = inttoptr i64 %34 to i64*
  store i64 %32, i64* %35, align 8
  %36 = load i32, i32* %EDI, align 4
  %37 = zext i32 %36 to i64
  %38 = load i64, i64* %PC, align 8
  store i64 %37, i64* %R13, align 8, !tbaa !2428
  %39 = load i64, i64* %RSI, align 8
  store i64 %39, i64* %R14, align 8, !tbaa !2428
  %40 = load i64, i64* %RBP, align 8
  %41 = load i64, i64* %R12, align 8
  %42 = sub i64 %40, %41
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %45 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %48 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %49 = lshr i64 %42, 2
  %50 = trunc i64 %49 to i8
  %51 = and i8 %50, 1
  %52 = ashr i64 %42, 3
  store i64 %52, i64* %RBP, align 8, !tbaa !2428
  store i8 %51, i8* %43, align 1, !tbaa !2453
  %53 = trunc i64 %52 to i32
  %54 = and i32 %53, 255
  %55 = tail call i32 @llvm.ctpop.i32(i32 %54) #14
  %56 = trunc i32 %55 to i8
  %57 = and i8 %56, 1
  %58 = xor i8 %57, 1
  store i8 %58, i8* %44, align 1, !tbaa !2453
  store i8 0, i8* %45, align 1, !tbaa !2453
  %59 = icmp eq i64 %52, 0
  %60 = zext i1 %59 to i8
  store i8 %60, i8* %46, align 1, !tbaa !2453
  %61 = lshr i64 %52, 63
  %62 = trunc i64 %61 to i8
  store i8 %62, i8* %47, align 1, !tbaa !2453
  store i8 0, i8* %48, align 1, !tbaa !2453
  %63 = add i64 %38, -14771
  %64 = add i64 %38, 22
  %65 = add i64 %7, -64
  %66 = inttoptr i64 %65 to i64*
  store i64 %64, i64* %66, align 8
  store i64 %65, i64* %RSP, align 8, !tbaa !2428
  store i64 %63, i64* %PC, align 8, !tbaa !2428
  %67 = tail call %struct.Memory* @sub_400688__init_proc_renamed_(%struct.State* nonnull %0, i64 %63, %struct.Memory* %2)
  %68 = load i64, i64* %RBP, align 8
  %69 = load i64, i64* %PC, align 8
  store i8 0, i8* %43, align 1, !tbaa !2432
  %70 = trunc i64 %68 to i32
  %71 = and i32 %70, 255
  %72 = tail call i32 @llvm.ctpop.i32(i32 %71) #14
  %73 = trunc i32 %72 to i8
  %74 = and i8 %73, 1
  %75 = xor i8 %74, 1
  store i8 %75, i8* %44, align 1, !tbaa !2446
  %76 = icmp eq i64 %68, 0
  %77 = zext i1 %76 to i8
  store i8 %77, i8* %46, align 1, !tbaa !2448
  %78 = lshr i64 %68, 63
  %79 = trunc i64 %78 to i8
  store i8 %79, i8* %47, align 1, !tbaa !2449
  store i8 0, i8* %48, align 1, !tbaa !2450
  store i8 0, i8* %45, align 1, !tbaa !2447
  %.v = select i1 %76, i64 37, i64 5
  %80 = add i64 %69, %.v
  store i64 %80, i64* %PC, align 8, !tbaa !2428
  br i1 %76, label %block_404076, label %block_404056

block_404076.loopexit:                            ; preds = %block_404060
  br label %block_404076

block_404076:                                     ; preds = %block_404076.loopexit, %block_404020
  %81 = phi i64 [ %80, %block_404020 ], [ %179, %block_404076.loopexit ]
  %MEMORY.0 = phi %struct.Memory* [ %67, %block_404020 ], [ %149, %block_404076.loopexit ]
  %82 = load i64, i64* %RSP, align 8
  %83 = add i64 %82, 8
  store i64 %83, i64* %RSP, align 8, !tbaa !2428
  %84 = icmp ugt i64 %82, -9
  %85 = zext i1 %84 to i8
  store i8 %85, i8* %43, align 1, !tbaa !2432
  %86 = trunc i64 %83 to i32
  %87 = and i32 %86, 255
  %88 = tail call i32 @llvm.ctpop.i32(i32 %87) #14
  %89 = trunc i32 %88 to i8
  %90 = and i8 %89, 1
  %91 = xor i8 %90, 1
  store i8 %91, i8* %44, align 1, !tbaa !2446
  %92 = xor i64 %83, %82
  %93 = lshr i64 %92, 4
  %94 = trunc i64 %93 to i8
  %95 = and i8 %94, 1
  store i8 %95, i8* %45, align 1, !tbaa !2447
  %96 = icmp eq i64 %83, 0
  %97 = zext i1 %96 to i8
  store i8 %97, i8* %46, align 1, !tbaa !2448
  %98 = lshr i64 %83, 63
  %99 = trunc i64 %98 to i8
  store i8 %99, i8* %47, align 1, !tbaa !2449
  %100 = lshr i64 %82, 63
  %101 = xor i64 %98, %100
  %102 = add nuw nsw i64 %101, %98
  %103 = icmp eq i64 %102, 2
  %104 = zext i1 %103 to i8
  store i8 %104, i8* %48, align 1, !tbaa !2450
  %105 = add i64 %81, 5
  store i64 %105, i64* %PC, align 8
  %106 = add i64 %82, 16
  %107 = inttoptr i64 %83 to i64*
  %108 = load i64, i64* %107, align 8
  store i64 %108, i64* %RBX, align 8, !tbaa !2428
  store i64 %106, i64* %RSP, align 8, !tbaa !2428
  %109 = add i64 %81, 6
  store i64 %109, i64* %PC, align 8
  %110 = add i64 %82, 24
  %111 = inttoptr i64 %106 to i64*
  %112 = load i64, i64* %111, align 8
  store i64 %112, i64* %RBP, align 8, !tbaa !2428
  store i64 %110, i64* %RSP, align 8, !tbaa !2428
  %113 = add i64 %81, 8
  store i64 %113, i64* %PC, align 8
  %114 = add i64 %82, 32
  %115 = inttoptr i64 %110 to i64*
  %116 = load i64, i64* %115, align 8
  store i64 %116, i64* %R12, align 8, !tbaa !2428
  store i64 %114, i64* %RSP, align 8, !tbaa !2428
  %117 = add i64 %81, 10
  store i64 %117, i64* %PC, align 8
  %118 = add i64 %82, 40
  %119 = inttoptr i64 %114 to i64*
  %120 = load i64, i64* %119, align 8
  store i64 %120, i64* %R13, align 8, !tbaa !2428
  store i64 %118, i64* %RSP, align 8, !tbaa !2428
  %121 = add i64 %81, 12
  store i64 %121, i64* %PC, align 8
  %122 = add i64 %82, 48
  %123 = inttoptr i64 %118 to i64*
  %124 = load i64, i64* %123, align 8
  store i64 %124, i64* %R14, align 8, !tbaa !2428
  store i64 %122, i64* %RSP, align 8, !tbaa !2428
  %125 = add i64 %81, 14
  store i64 %125, i64* %PC, align 8
  %126 = add i64 %82, 56
  %127 = inttoptr i64 %122 to i64*
  %128 = load i64, i64* %127, align 8
  store i64 %128, i64* %R15, align 8, !tbaa !2428
  store i64 %126, i64* %RSP, align 8, !tbaa !2428
  %129 = add i64 %81, 15
  store i64 %129, i64* %PC, align 8
  %130 = inttoptr i64 %126 to i64*
  %131 = load i64, i64* %130, align 8
  store i64 %131, i64* %PC, align 8, !tbaa !2428
  %132 = add i64 %82, 64
  store i64 %132, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_404056:                                     ; preds = %block_404020
  store i64 0, i64* %RBX, align 8, !tbaa !2428
  store i8 0, i8* %43, align 1, !tbaa !2432
  store i8 1, i8* %44, align 1, !tbaa !2446
  store i8 1, i8* %46, align 1, !tbaa !2448
  store i8 0, i8* %47, align 1, !tbaa !2449
  store i8 0, i8* %48, align 1, !tbaa !2450
  store i8 0, i8* %45, align 1, !tbaa !2447
  %133 = add i64 %80, 10
  store i64 %133, i64* %PC, align 8
  br label %block_404060

block_404060:                                     ; preds = %block_404060, %block_404056
  %134 = phi i64 [ 0, %block_404056 ], [ %152, %block_404060 ]
  %135 = phi i64 [ %133, %block_404056 ], [ %179, %block_404060 ]
  %MEMORY.1 = phi %struct.Memory* [ %67, %block_404056 ], [ %149, %block_404060 ]
  %136 = load i64, i64* %R15, align 8
  store i64 %136, i64* %RDX, align 8, !tbaa !2428
  %137 = load i64, i64* %R14, align 8
  store i64 %137, i64* %RSI, align 8, !tbaa !2428
  %138 = load i32, i32* %R13D, align 4
  %139 = zext i32 %138 to i64
  store i64 %139, i64* %RDI, align 8, !tbaa !2428
  %140 = load i64, i64* %R12, align 8
  %141 = shl i64 %134, 3
  %142 = add i64 %141, %140
  %143 = add i64 %135, 13
  store i64 %143, i64* %PC, align 8
  %144 = load i64, i64* %RSP, align 8, !tbaa !2428
  %145 = add i64 %144, -8
  %146 = inttoptr i64 %145 to i64*
  store i64 %143, i64* %146, align 8
  store i64 %145, i64* %RSP, align 8, !tbaa !2428
  %147 = inttoptr i64 %142 to i64*
  %148 = load i64, i64* %147, align 8
  store i64 %148, i64* %PC, align 8, !tbaa !2428
  %149 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 %148, %struct.Memory* %MEMORY.1)
  %150 = load i64, i64* %RBX, align 8
  %151 = load i64, i64* %PC, align 8
  %152 = add i64 %150, 1
  store i64 %152, i64* %RBX, align 8, !tbaa !2428
  %153 = lshr i64 %152, 63
  %154 = load i64, i64* %RBP, align 8
  %155 = sub i64 %154, %152
  %156 = icmp ult i64 %154, %152
  %157 = zext i1 %156 to i8
  store i8 %157, i8* %43, align 1, !tbaa !2432
  %158 = trunc i64 %155 to i32
  %159 = and i32 %158, 255
  %160 = tail call i32 @llvm.ctpop.i32(i32 %159) #14
  %161 = trunc i32 %160 to i8
  %162 = and i8 %161, 1
  %163 = xor i8 %162, 1
  store i8 %163, i8* %44, align 1, !tbaa !2446
  %164 = xor i64 %152, %154
  %165 = xor i64 %164, %155
  %166 = lshr i64 %165, 4
  %167 = trunc i64 %166 to i8
  %168 = and i8 %167, 1
  store i8 %168, i8* %45, align 1, !tbaa !2447
  %169 = icmp eq i64 %155, 0
  %170 = zext i1 %169 to i8
  store i8 %170, i8* %46, align 1, !tbaa !2448
  %171 = lshr i64 %155, 63
  %172 = trunc i64 %171 to i8
  store i8 %172, i8* %47, align 1, !tbaa !2449
  %173 = lshr i64 %154, 63
  %174 = xor i64 %153, %173
  %175 = xor i64 %171, %173
  %176 = add nuw nsw i64 %175, %174
  %177 = icmp eq i64 %176, 2
  %178 = zext i1 %177 to i8
  store i8 %178, i8* %48, align 1, !tbaa !2450
  %.v2 = select i1 %169, i64 9, i64 -13
  %179 = add i64 %151, %.v2
  store i64 %179, i64* %PC, align 8, !tbaa !2428
  br i1 %169, label %block_404076.loopexit, label %block_404060
}

; Function Attrs: noinline
define %struct.Memory* @sub_400e70_makewt(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone) local_unnamed_addr #8 {
block_400e70:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %1, 1
  store i64 %7, i64* %PC, align 8
  %8 = load i64, i64* %RSP, align 8, !tbaa !2428
  %9 = add i64 %8, -8
  %10 = inttoptr i64 %9 to i64*
  store i64 %6, i64* %10, align 8
  %11 = load i64, i64* %PC, align 8
  store i64 %9, i64* %RBP, align 8, !tbaa !2428
  %12 = add i64 %8, -72
  store i64 %12, i64* %RSP, align 8, !tbaa !2428
  %13 = icmp ult i64 %9, 64
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1, !tbaa !2432
  %16 = trunc i64 %12 to i32
  %17 = and i32 %16, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17) #14
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1, !tbaa !2446
  %23 = xor i64 %9, %12
  %24 = lshr i64 %23, 4
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1, !tbaa !2447
  %28 = icmp eq i64 %12, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1, !tbaa !2448
  %31 = lshr i64 %12, 63
  %32 = trunc i64 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1, !tbaa !2449
  %34 = lshr i64 %9, 63
  %35 = xor i64 %31, %34
  %36 = add nuw nsw i64 %35, %34
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1, !tbaa !2450
  %40 = add i64 %8, -12
  %41 = load i32, i32* %EDI, align 4
  %42 = add i64 %11, 10
  store i64 %42, i64* %PC, align 8
  %43 = inttoptr i64 %40 to i32*
  store i32 %41, i32* %43, align 4
  %44 = load i64, i64* %RBP, align 8
  %45 = add i64 %44, -16
  %46 = load i64, i64* %RSI, align 8
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 4
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %45 to i64*
  store i64 %46, i64* %49, align 8
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -24
  %52 = load i64, i64* %RDX, align 8
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 4
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %51 to i64*
  store i64 %52, i64* %55, align 8
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -4
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 4
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %57 to i32*
  %61 = load i32, i32* %60, align 4
  %62 = add i32 %61, -2
  %63 = icmp ult i32 %61, 2
  %64 = zext i1 %63 to i8
  store i8 %64, i8* %15, align 1, !tbaa !2432
  %65 = and i32 %62, 255
  %66 = tail call i32 @llvm.ctpop.i32(i32 %65) #14
  %67 = trunc i32 %66 to i8
  %68 = and i8 %67, 1
  %69 = xor i8 %68, 1
  store i8 %69, i8* %22, align 1, !tbaa !2446
  %70 = xor i32 %62, %61
  %71 = lshr i32 %70, 4
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  store i8 %73, i8* %27, align 1, !tbaa !2447
  %74 = icmp eq i32 %62, 0
  %75 = zext i1 %74 to i8
  store i8 %75, i8* %30, align 1, !tbaa !2448
  %76 = lshr i32 %62, 31
  %77 = trunc i32 %76 to i8
  store i8 %77, i8* %33, align 1, !tbaa !2449
  %78 = lshr i32 %61, 31
  %79 = xor i32 %76, %78
  %80 = add nuw nsw i32 %79, %78
  %81 = icmp eq i32 %80, 2
  %82 = zext i1 %81 to i8
  store i8 %82, i8* %39, align 1, !tbaa !2450
  %83 = icmp ne i8 %77, 0
  %84 = xor i1 %83, %81
  %85 = or i1 %74, %84
  %.v = select i1 %85, i64 339, i64 10
  %86 = add i64 %58, %.v
  store i64 %86, i64* %PC, align 8, !tbaa !2428
  br i1 %85, label %block_400fd6, label %block_400e8d

block_400f1d:                                     ; preds = %block_400f16, %block_400f29
  %87 = phi i64 [ %.pre, %block_400f16 ], [ %391, %block_400f29 ]
  %88 = load i64, i64* %RBP, align 8
  %89 = add i64 %88, -28
  %90 = add i64 %87, 3
  store i64 %90, i64* %PC, align 8
  %91 = inttoptr i64 %89 to i32*
  %92 = load i32, i32* %91, align 4
  %93 = zext i32 %92 to i64
  store i64 %93, i64* %RAX, align 8, !tbaa !2428
  %94 = add i64 %88, -32
  %95 = add i64 %87, 6
  store i64 %95, i64* %PC, align 8
  %96 = inttoptr i64 %94 to i32*
  %97 = load i32, i32* %96, align 4
  %98 = sub i32 %92, %97
  %99 = icmp ult i32 %92, %97
  %100 = zext i1 %99 to i8
  store i8 %100, i8* %15, align 1, !tbaa !2432
  %101 = and i32 %98, 255
  %102 = tail call i32 @llvm.ctpop.i32(i32 %101) #14
  %103 = trunc i32 %102 to i8
  %104 = and i8 %103, 1
  %105 = xor i8 %104, 1
  store i8 %105, i8* %22, align 1, !tbaa !2446
  %106 = xor i32 %97, %92
  %107 = xor i32 %106, %98
  %108 = lshr i32 %107, 4
  %109 = trunc i32 %108 to i8
  %110 = and i8 %109, 1
  store i8 %110, i8* %27, align 1, !tbaa !2447
  %111 = icmp eq i32 %98, 0
  %112 = zext i1 %111 to i8
  store i8 %112, i8* %30, align 1, !tbaa !2448
  %113 = lshr i32 %98, 31
  %114 = trunc i32 %113 to i8
  store i8 %114, i8* %33, align 1, !tbaa !2449
  %115 = lshr i32 %92, 31
  %116 = lshr i32 %97, 31
  %117 = xor i32 %116, %115
  %118 = xor i32 %113, %115
  %119 = add nuw nsw i32 %118, %117
  %120 = icmp eq i32 %119, 2
  %121 = zext i1 %120 to i8
  store i8 %121, i8* %39, align 1, !tbaa !2450
  %122 = icmp ne i8 %114, 0
  %123 = xor i1 %122, %120
  %.v118 = select i1 %123, i64 12, i64 164
  %124 = add i64 %87, %.v118
  store i64 %124, i64* %PC, align 8, !tbaa !2428
  br i1 %123, label %block_400f29, label %block_400fc1

block_400fd6:                                     ; preds = %block_400fd1, %block_400e70
  %125 = phi i64 [ %86, %block_400e70 ], [ %393, %block_400fd1 ]
  %MEMORY.1 = phi %struct.Memory* [ %2, %block_400e70 ], [ %MEMORY.2, %block_400fd1 ]
  %126 = load i64, i64* %RSP, align 8
  %127 = add i64 %126, 64
  store i64 %127, i64* %RSP, align 8, !tbaa !2428
  %128 = icmp ugt i64 %126, -65
  %129 = zext i1 %128 to i8
  store i8 %129, i8* %15, align 1, !tbaa !2432
  %130 = trunc i64 %127 to i32
  %131 = and i32 %130, 255
  %132 = tail call i32 @llvm.ctpop.i32(i32 %131) #14
  %133 = trunc i32 %132 to i8
  %134 = and i8 %133, 1
  %135 = xor i8 %134, 1
  store i8 %135, i8* %22, align 1, !tbaa !2446
  %136 = xor i64 %127, %126
  %137 = lshr i64 %136, 4
  %138 = trunc i64 %137 to i8
  %139 = and i8 %138, 1
  store i8 %139, i8* %27, align 1, !tbaa !2447
  %140 = icmp eq i64 %127, 0
  %141 = zext i1 %140 to i8
  store i8 %141, i8* %30, align 1, !tbaa !2448
  %142 = lshr i64 %127, 63
  %143 = trunc i64 %142 to i8
  store i8 %143, i8* %33, align 1, !tbaa !2449
  %144 = lshr i64 %126, 63
  %145 = xor i64 %142, %144
  %146 = add nuw nsw i64 %145, %142
  %147 = icmp eq i64 %146, 2
  %148 = zext i1 %147 to i8
  store i8 %148, i8* %39, align 1, !tbaa !2450
  %149 = add i64 %125, 5
  store i64 %149, i64* %PC, align 8
  %150 = add i64 %126, 72
  %151 = inttoptr i64 %127 to i64*
  %152 = load i64, i64* %151, align 8
  store i64 %152, i64* %RBP, align 8, !tbaa !2428
  store i64 %150, i64* %RSP, align 8, !tbaa !2428
  %153 = add i64 %125, 6
  store i64 %153, i64* %PC, align 8
  %154 = inttoptr i64 %150 to i64*
  %155 = load i64, i64* %154, align 8
  store i64 %155, i64* %PC, align 8, !tbaa !2428
  %156 = add i64 %126, 80
  store i64 %156, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.1

block_400f29:                                     ; preds = %block_400f1d
  %157 = add i64 %88, -40
  %158 = add i64 %124, 5
  store i64 %158, i64* %PC, align 8
  %159 = inttoptr i64 %157 to i64*
  %160 = load i64, i64* %159, align 8
  store i64 %160, i64* %404, align 1, !tbaa !2451
  store double 0.000000e+00, double* %406, align 1, !tbaa !2451
  %161 = add i64 %124, 10
  store i64 %161, i64* %PC, align 8
  %162 = load i32, i32* %91, align 4
  %163 = sitofp i32 %162 to double
  store double %163, double* %495, align 1, !tbaa !2451
  %164 = bitcast i64 %160 to double
  %165 = fmul double %163, %164
  store double %165, double* %403, align 1, !tbaa !2451
  store i64 0, i64* %405, align 1, !tbaa !2451
  %166 = add i64 %124, -2073
  %167 = add i64 %124, 19
  %168 = load i64, i64* %RSP, align 8, !tbaa !2428
  %169 = add i64 %168, -8
  %170 = inttoptr i64 %169 to i64*
  store i64 %167, i64* %170, align 8
  store i64 %169, i64* %RSP, align 8, !tbaa !2428
  store i64 %166, i64* %PC, align 8, !tbaa !2428
  %171 = load double, double* %403, align 8, !alias.scope !2454, !noalias !2457
  %172 = load i64, i64* %170, align 8
  store i64 %168, i64* %RSP, align 8, !alias.scope !2454, !noalias !2457
  %173 = tail call double @cos(double %171)
  call void @llvm.memset.p0i8.i64(i8* %398, i8 0, i64 24, i32 8, i1 false)
  store double %173, double* %403, align 8, !alias.scope !2454, !noalias !2457
  %174 = load i64, i64* %RBP, align 8
  %175 = add i64 %174, -48
  %176 = add i64 %172, 5
  store i64 %176, i64* %PC, align 8
  %177 = inttoptr i64 %175 to double*
  store double %173, double* %177, align 8
  %178 = load i64, i64* %RBP, align 8
  %179 = add i64 %178, -40
  %180 = load i64, i64* %PC, align 8
  %181 = add i64 %180, 5
  store i64 %181, i64* %PC, align 8
  %182 = inttoptr i64 %179 to i64*
  %183 = load i64, i64* %182, align 8
  store i64 %183, i64* %404, align 1, !tbaa !2451
  store double 0.000000e+00, double* %406, align 1, !tbaa !2451
  %184 = add i64 %178, -28
  %185 = add i64 %180, 10
  store i64 %185, i64* %PC, align 8
  %186 = inttoptr i64 %184 to i32*
  %187 = load i32, i32* %186, align 4
  %188 = sitofp i32 %187 to double
  store double %188, double* %495, align 1, !tbaa !2451
  %189 = bitcast i64 %183 to double
  %190 = fmul double %188, %189
  store double %190, double* %403, align 1, !tbaa !2451
  store i64 0, i64* %405, align 1, !tbaa !2451
  %191 = add i64 %180, -2049
  %192 = add i64 %180, 19
  %193 = load i64, i64* %RSP, align 8, !tbaa !2428
  %194 = add i64 %193, -8
  %195 = inttoptr i64 %194 to i64*
  store i64 %192, i64* %195, align 8
  store i64 %194, i64* %RSP, align 8, !tbaa !2428
  store i64 %191, i64* %PC, align 8, !tbaa !2428
  %196 = load double, double* %403, align 8, !alias.scope !2459, !noalias !2462
  %197 = load i64, i64* %195, align 8
  store i64 %193, i64* %RSP, align 8, !alias.scope !2459, !noalias !2462
  %198 = tail call double @sin(double %196)
  call void @llvm.memset.p0i8.i64(i8* %400, i8 0, i64 24, i32 8, i1 false)
  store double %198, double* %403, align 8, !alias.scope !2459, !noalias !2462
  %199 = load i64, i64* %RBP, align 8
  %200 = add i64 %199, -56
  %201 = add i64 %197, 5
  store i64 %201, i64* %PC, align 8
  %202 = inttoptr i64 %200 to double*
  store double %198, double* %202, align 8
  %203 = load i64, i64* %RBP, align 8
  %204 = add i64 %203, -48
  %205 = load i64, i64* %PC, align 8
  %206 = add i64 %205, 5
  store i64 %206, i64* %PC, align 8
  %207 = inttoptr i64 %204 to i64*
  %208 = load i64, i64* %207, align 8
  store i64 %208, i64* %404, align 1, !tbaa !2451
  store double 0.000000e+00, double* %406, align 1, !tbaa !2451
  %209 = add i64 %203, -24
  %210 = add i64 %205, 9
  store i64 %210, i64* %PC, align 8
  %211 = inttoptr i64 %209 to i64*
  %212 = load i64, i64* %211, align 8
  store i64 %212, i64* %RAX, align 8, !tbaa !2428
  %213 = add i64 %203, -28
  %214 = add i64 %205, 13
  store i64 %214, i64* %PC, align 8
  %215 = inttoptr i64 %213 to i32*
  %216 = load i32, i32* %215, align 4
  %217 = sext i32 %216 to i64
  store i64 %217, i64* %RCX, align 8, !tbaa !2428
  %218 = shl nsw i64 %217, 3
  %219 = add i64 %218, %212
  %220 = add i64 %205, 18
  store i64 %220, i64* %PC, align 8
  %221 = inttoptr i64 %219 to i64*
  store i64 %208, i64* %221, align 8
  %222 = load i64, i64* %RBP, align 8
  %223 = add i64 %222, -56
  %224 = load i64, i64* %PC, align 8
  %225 = add i64 %224, 5
  store i64 %225, i64* %PC, align 8
  %226 = inttoptr i64 %223 to i64*
  %227 = load i64, i64* %226, align 8
  store i64 %227, i64* %404, align 1, !tbaa !2451
  store double 0.000000e+00, double* %406, align 1, !tbaa !2451
  %228 = add i64 %222, -24
  %229 = add i64 %224, 9
  store i64 %229, i64* %PC, align 8
  %230 = inttoptr i64 %228 to i64*
  %231 = load i64, i64* %230, align 8
  store i64 %231, i64* %RAX, align 8, !tbaa !2428
  %232 = add i64 %222, -28
  %233 = add i64 %224, 12
  store i64 %233, i64* %PC, align 8
  %234 = inttoptr i64 %232 to i32*
  %235 = load i32, i32* %234, align 4
  %236 = add i32 %235, 1
  %237 = zext i32 %236 to i64
  store i64 %237, i64* %RDX, align 8, !tbaa !2428
  %238 = icmp eq i32 %235, -1
  %239 = icmp eq i32 %236, 0
  %240 = or i1 %238, %239
  %241 = zext i1 %240 to i8
  store i8 %241, i8* %15, align 1, !tbaa !2432
  %242 = and i32 %236, 255
  %243 = tail call i32 @llvm.ctpop.i32(i32 %242) #14
  %244 = trunc i32 %243 to i8
  %245 = and i8 %244, 1
  %246 = xor i8 %245, 1
  store i8 %246, i8* %22, align 1, !tbaa !2446
  %247 = xor i32 %236, %235
  %248 = lshr i32 %247, 4
  %249 = trunc i32 %248 to i8
  %250 = and i8 %249, 1
  store i8 %250, i8* %27, align 1, !tbaa !2447
  %251 = zext i1 %239 to i8
  store i8 %251, i8* %30, align 1, !tbaa !2448
  %252 = lshr i32 %236, 31
  %253 = trunc i32 %252 to i8
  store i8 %253, i8* %33, align 1, !tbaa !2449
  %254 = lshr i32 %235, 31
  %255 = xor i32 %252, %254
  %256 = add nuw nsw i32 %255, %252
  %257 = icmp eq i32 %256, 2
  %258 = zext i1 %257 to i8
  store i8 %258, i8* %39, align 1, !tbaa !2450
  %259 = sext i32 %236 to i64
  store i64 %259, i64* %RCX, align 8, !tbaa !2428
  %260 = shl nsw i64 %259, 3
  %261 = add i64 %231, %260
  %262 = add i64 %224, 23
  store i64 %262, i64* %PC, align 8
  %263 = inttoptr i64 %261 to i64*
  store i64 %227, i64* %263, align 8
  %264 = load i64, i64* %RBP, align 8
  %265 = add i64 %264, -56
  %266 = load i64, i64* %PC, align 8
  %267 = add i64 %266, 5
  store i64 %267, i64* %PC, align 8
  %268 = inttoptr i64 %265 to i64*
  %269 = load i64, i64* %268, align 8
  store i64 %269, i64* %404, align 1, !tbaa !2451
  store double 0.000000e+00, double* %406, align 1, !tbaa !2451
  %270 = add i64 %264, -24
  %271 = add i64 %266, 9
  store i64 %271, i64* %PC, align 8
  %272 = inttoptr i64 %270 to i64*
  %273 = load i64, i64* %272, align 8
  store i64 %273, i64* %RAX, align 8, !tbaa !2428
  %274 = add i64 %264, -4
  %275 = add i64 %266, 12
  store i64 %275, i64* %PC, align 8
  %276 = inttoptr i64 %274 to i32*
  %277 = load i32, i32* %276, align 4
  %278 = zext i32 %277 to i64
  store i64 %278, i64* %RDX, align 8, !tbaa !2428
  %279 = add i64 %264, -28
  %280 = add i64 %266, 15
  store i64 %280, i64* %PC, align 8
  %281 = inttoptr i64 %279 to i32*
  %282 = load i32, i32* %281, align 4
  %283 = sub i32 %277, %282
  %284 = zext i32 %283 to i64
  store i64 %284, i64* %RDX, align 8, !tbaa !2428
  %285 = icmp ult i32 %277, %282
  %286 = zext i1 %285 to i8
  store i8 %286, i8* %15, align 1, !tbaa !2432
  %287 = and i32 %283, 255
  %288 = tail call i32 @llvm.ctpop.i32(i32 %287) #14
  %289 = trunc i32 %288 to i8
  %290 = and i8 %289, 1
  %291 = xor i8 %290, 1
  store i8 %291, i8* %22, align 1, !tbaa !2446
  %292 = xor i32 %282, %277
  %293 = xor i32 %292, %283
  %294 = lshr i32 %293, 4
  %295 = trunc i32 %294 to i8
  %296 = and i8 %295, 1
  store i8 %296, i8* %27, align 1, !tbaa !2447
  %297 = icmp eq i32 %283, 0
  %298 = zext i1 %297 to i8
  store i8 %298, i8* %30, align 1, !tbaa !2448
  %299 = lshr i32 %283, 31
  %300 = trunc i32 %299 to i8
  store i8 %300, i8* %33, align 1, !tbaa !2449
  %301 = lshr i32 %277, 31
  %302 = lshr i32 %282, 31
  %303 = xor i32 %302, %301
  %304 = xor i32 %299, %301
  %305 = add nuw nsw i32 %304, %303
  %306 = icmp eq i32 %305, 2
  %307 = zext i1 %306 to i8
  store i8 %307, i8* %39, align 1, !tbaa !2450
  %308 = sext i32 %283 to i64
  store i64 %308, i64* %RCX, align 8, !tbaa !2428
  %309 = shl nsw i64 %308, 3
  %310 = add i64 %273, %309
  %311 = add i64 %266, 23
  store i64 %311, i64* %PC, align 8
  %312 = inttoptr i64 %310 to i64*
  store i64 %269, i64* %312, align 8
  %313 = load i64, i64* %RBP, align 8
  %314 = add i64 %313, -48
  %315 = load i64, i64* %PC, align 8
  %316 = add i64 %315, 5
  store i64 %316, i64* %PC, align 8
  %317 = inttoptr i64 %314 to i64*
  %318 = load i64, i64* %317, align 8
  store i64 %318, i64* %404, align 1, !tbaa !2451
  store double 0.000000e+00, double* %406, align 1, !tbaa !2451
  %319 = add i64 %313, -24
  %320 = add i64 %315, 9
  store i64 %320, i64* %PC, align 8
  %321 = inttoptr i64 %319 to i64*
  %322 = load i64, i64* %321, align 8
  store i64 %322, i64* %RAX, align 8, !tbaa !2428
  %323 = add i64 %313, -4
  %324 = add i64 %315, 12
  store i64 %324, i64* %PC, align 8
  %325 = inttoptr i64 %323 to i32*
  %326 = load i32, i32* %325, align 4
  %327 = zext i32 %326 to i64
  store i64 %327, i64* %RDX, align 8, !tbaa !2428
  %328 = add i64 %313, -28
  %329 = add i64 %315, 15
  store i64 %329, i64* %PC, align 8
  %330 = inttoptr i64 %328 to i32*
  %331 = load i32, i32* %330, align 4
  %332 = sub i32 %326, %331
  %333 = lshr i32 %332, 31
  %334 = add i32 %332, 1
  %335 = zext i32 %334 to i64
  store i64 %335, i64* %RDX, align 8, !tbaa !2428
  %336 = icmp eq i32 %332, -1
  %337 = icmp eq i32 %334, 0
  %338 = or i1 %336, %337
  %339 = zext i1 %338 to i8
  store i8 %339, i8* %15, align 1, !tbaa !2432
  %340 = and i32 %334, 255
  %341 = tail call i32 @llvm.ctpop.i32(i32 %340) #14
  %342 = trunc i32 %341 to i8
  %343 = and i8 %342, 1
  %344 = xor i8 %343, 1
  store i8 %344, i8* %22, align 1, !tbaa !2446
  %345 = xor i32 %334, %332
  %346 = lshr i32 %345, 4
  %347 = trunc i32 %346 to i8
  %348 = and i8 %347, 1
  store i8 %348, i8* %27, align 1, !tbaa !2447
  %349 = zext i1 %337 to i8
  store i8 %349, i8* %30, align 1, !tbaa !2448
  %350 = lshr i32 %334, 31
  %351 = trunc i32 %350 to i8
  store i8 %351, i8* %33, align 1, !tbaa !2449
  %352 = xor i32 %350, %333
  %353 = add nuw nsw i32 %352, %350
  %354 = icmp eq i32 %353, 2
  %355 = zext i1 %354 to i8
  store i8 %355, i8* %39, align 1, !tbaa !2450
  %356 = sext i32 %334 to i64
  store i64 %356, i64* %RCX, align 8, !tbaa !2428
  %357 = shl nsw i64 %356, 3
  %358 = add i64 %322, %357
  %359 = add i64 %315, 26
  store i64 %359, i64* %PC, align 8
  %360 = inttoptr i64 %358 to i64*
  store i64 %318, i64* %360, align 8
  %361 = load i64, i64* %RBP, align 8
  %362 = add i64 %361, -28
  %363 = load i64, i64* %PC, align 8
  %364 = add i64 %363, 3
  store i64 %364, i64* %PC, align 8
  %365 = inttoptr i64 %362 to i32*
  %366 = load i32, i32* %365, align 4
  %367 = add i32 %366, 2
  %368 = zext i32 %367 to i64
  store i64 %368, i64* %RAX, align 8, !tbaa !2428
  %369 = icmp ugt i32 %366, -3
  %370 = zext i1 %369 to i8
  store i8 %370, i8* %15, align 1, !tbaa !2432
  %371 = and i32 %367, 255
  %372 = tail call i32 @llvm.ctpop.i32(i32 %371) #14
  %373 = trunc i32 %372 to i8
  %374 = and i8 %373, 1
  %375 = xor i8 %374, 1
  store i8 %375, i8* %22, align 1, !tbaa !2446
  %376 = xor i32 %367, %366
  %377 = lshr i32 %376, 4
  %378 = trunc i32 %377 to i8
  %379 = and i8 %378, 1
  store i8 %379, i8* %27, align 1, !tbaa !2447
  %380 = icmp eq i32 %367, 0
  %381 = zext i1 %380 to i8
  store i8 %381, i8* %30, align 1, !tbaa !2448
  %382 = lshr i32 %367, 31
  %383 = trunc i32 %382 to i8
  store i8 %383, i8* %33, align 1, !tbaa !2449
  %384 = lshr i32 %366, 31
  %385 = xor i32 %382, %384
  %386 = add nuw nsw i32 %385, %382
  %387 = icmp eq i32 %386, 2
  %388 = zext i1 %387 to i8
  store i8 %388, i8* %39, align 1, !tbaa !2450
  %389 = add i64 %363, 9
  store i64 %389, i64* %PC, align 8
  store i32 %367, i32* %365, align 4
  %390 = load i64, i64* %PC, align 8
  %391 = add i64 %390, -159
  store i64 %391, i64* %PC, align 8, !tbaa !2428
  br label %block_400f1d

block_400fd1:                                     ; preds = %block_400fc1, %block_400e8d
  %392 = phi i64 [ %600, %block_400e8d ], [ %.pre116, %block_400fc1 ]
  %MEMORY.2 = phi %struct.Memory* [ %2, %block_400e8d ], [ %619, %block_400fc1 ]
  %393 = add i64 %392, 5
  store i64 %393, i64* %PC, align 8, !tbaa !2428
  br label %block_400fd6

block_400f16:                                     ; preds = %block_400e8d
  %394 = add i64 %570, -28
  %395 = add i64 %600, 7
  store i64 %395, i64* %PC, align 8
  %396 = inttoptr i64 %394 to i32*
  store i32 2, i32* %396, align 4
  %.pre = load i64, i64* %PC, align 8
  %397 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %398 = bitcast i64* %397 to i8*
  %399 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %400 = bitcast i64* %399 to i8*
  br label %block_400f1d

block_400e8d:                                     ; preds = %block_400e70
  %401 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3
  %402 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 64) to i64*), align 16
  %403 = bitcast [32 x %union.VectorReg]* %4 to double*
  %404 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %402, i64* %404, align 1, !tbaa !2451
  %405 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %406 = bitcast i64* %405 to double*
  store double 0.000000e+00, double* %406, align 1, !tbaa !2451
  %407 = add i64 %86, 11
  store i64 %407, i64* %PC, align 8
  %408 = load i32, i32* %60, align 4
  %409 = zext i32 %408 to i64
  %410 = shl nuw i64 %409, 32
  %411 = ashr i64 %410, 33
  %412 = trunc i32 %408 to i8
  %413 = and i8 %412, 1
  %414 = trunc i64 %411 to i32
  %415 = and i64 %411, 4294967295
  store i64 %415, i64* %RAX, align 8, !tbaa !2428
  store i8 %413, i8* %15, align 1, !tbaa !2453
  %416 = and i32 %414, 255
  %417 = tail call i32 @llvm.ctpop.i32(i32 %416) #14
  %418 = trunc i32 %417 to i8
  %419 = and i8 %418, 1
  %420 = xor i8 %419, 1
  store i8 %420, i8* %22, align 1, !tbaa !2453
  store i8 0, i8* %27, align 1, !tbaa !2453
  %421 = icmp eq i32 %414, 0
  %422 = zext i1 %421 to i8
  store i8 %422, i8* %30, align 1, !tbaa !2453
  %423 = lshr i64 %411, 31
  %424 = trunc i64 %423 to i8
  %425 = and i8 %424, 1
  store i8 %425, i8* %33, align 1, !tbaa !2453
  store i8 0, i8* %39, align 1, !tbaa !2453
  %426 = add i64 %56, -32
  %427 = trunc i64 %411 to i32
  %428 = add i64 %86, 17
  store i64 %428, i64* %PC, align 8
  %429 = inttoptr i64 %426 to i32*
  store i32 %427, i32* %429, align 4
  %430 = load i64, i64* %PC, align 8
  %431 = add i64 %430, -1998
  %432 = add i64 %430, 5
  %433 = load i64, i64* %RSP, align 8, !tbaa !2428
  %434 = add i64 %433, -8
  %435 = inttoptr i64 %434 to i64*
  store i64 %432, i64* %435, align 8
  store i64 %434, i64* %RSP, align 8, !tbaa !2428
  store i64 %431, i64* %PC, align 8, !tbaa !2428
  %436 = load double, double* %403, align 8, !alias.scope !2464, !noalias !2467
  %437 = load i64, i64* %435, align 8
  store i64 %433, i64* %RSP, align 8, !alias.scope !2464, !noalias !2467
  %438 = tail call double @atan(double %436)
  %439 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %440 = bitcast i64* %439 to i8*
  call void @llvm.memset.p0i8.i64(i8* %440, i8 0, i64 24, i32 8, i1 false)
  store double %438, double* %403, align 8, !alias.scope !2464, !noalias !2467
  %441 = bitcast %union.VectorReg* %5 to i8*
  %442 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %443 = bitcast %union.VectorReg* %5 to i32*
  store i32 0, i32* %443, align 1, !tbaa !2469
  %444 = getelementptr inbounds i8, i8* %441, i64 4
  %445 = bitcast i8* %444 to i32*
  store i32 0, i32* %445, align 1, !tbaa !2469
  %446 = bitcast i64* %442 to i32*
  store i32 0, i32* %446, align 1, !tbaa !2469
  %447 = getelementptr inbounds i8, i8* %441, i64 12
  %448 = bitcast i8* %447 to i32*
  store i32 0, i32* %448, align 1, !tbaa !2469
  %449 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 64) to i64*), align 16
  %450 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 0
  store i64 %449, i64* %450, align 1, !tbaa !2451
  %451 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %452 = bitcast i64* %451 to double*
  store double 0.000000e+00, double* %452, align 1, !tbaa !2451
  %453 = load i64, i64* %RBP, align 8
  %454 = add i64 %453, -32
  %455 = add i64 %437, 16
  store i64 %455, i64* %PC, align 8
  %456 = inttoptr i64 %454 to i32*
  %457 = load i32, i32* %456, align 4
  %458 = sitofp i32 %457 to double
  %459 = bitcast %union.VectorReg* %401 to double*
  store double %458, double* %459, align 1, !tbaa !2451
  %460 = fdiv double %438, %458
  store double %460, double* %403, align 1, !tbaa !2451
  store i64 0, i64* %405, align 1, !tbaa !2451
  %461 = add i64 %453, -40
  %462 = add i64 %437, 25
  store i64 %462, i64* %PC, align 8
  %463 = inttoptr i64 %461 to double*
  store double %460, double* %463, align 8
  %464 = load i64, i64* %RBP, align 8
  %465 = add i64 %464, -24
  %466 = load i64, i64* %PC, align 8
  %467 = add i64 %466, 4
  store i64 %467, i64* %PC, align 8
  %468 = inttoptr i64 %465 to i64*
  %469 = load i64, i64* %468, align 8
  store i64 %469, i64* %RCX, align 8, !tbaa !2428
  %470 = add i64 %466, 8
  store i64 %470, i64* %PC, align 8
  %471 = load i64, i64* %450, align 1
  %472 = inttoptr i64 %469 to i64*
  store i64 %471, i64* %472, align 8
  %473 = load i64, i64* %RBP, align 8
  %474 = add i64 %473, -24
  %475 = load i64, i64* %PC, align 8
  %476 = add i64 %475, 4
  store i64 %476, i64* %PC, align 8
  %477 = inttoptr i64 %474 to i64*
  %478 = load i64, i64* %477, align 8
  store i64 %478, i64* %RCX, align 8, !tbaa !2428
  %479 = add i64 %478, 8
  %480 = add i64 %475, 9
  store i64 %480, i64* %PC, align 8
  %481 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  %482 = load i64, i64* %481, align 1
  %483 = inttoptr i64 %479 to i64*
  store i64 %482, i64* %483, align 8
  %484 = load i64, i64* %RBP, align 8
  %485 = add i64 %484, -40
  %486 = load i64, i64* %PC, align 8
  %487 = add i64 %486, 5
  store i64 %487, i64* %PC, align 8
  %488 = inttoptr i64 %485 to i64*
  %489 = load i64, i64* %488, align 8
  store i64 %489, i64* %404, align 1, !tbaa !2451
  store double 0.000000e+00, double* %406, align 1, !tbaa !2451
  %490 = add i64 %484, -32
  %491 = add i64 %486, 10
  store i64 %491, i64* %PC, align 8
  %492 = inttoptr i64 %490 to i32*
  %493 = load i32, i32* %492, align 4
  %494 = sitofp i32 %493 to double
  %495 = bitcast %union.VectorReg* %5 to double*
  store double %494, double* %495, align 1, !tbaa !2451
  %496 = bitcast i64 %489 to double
  %497 = fmul double %494, %496
  store double %497, double* %403, align 1, !tbaa !2451
  store i64 0, i64* %405, align 1, !tbaa !2451
  %498 = add i64 %486, -1981
  %499 = add i64 %486, 19
  %500 = load i64, i64* %RSP, align 8, !tbaa !2428
  %501 = add i64 %500, -8
  %502 = inttoptr i64 %501 to i64*
  store i64 %499, i64* %502, align 8
  store i64 %501, i64* %RSP, align 8, !tbaa !2428
  store i64 %498, i64* %PC, align 8, !tbaa !2428
  %503 = load double, double* %403, align 8, !alias.scope !2470, !noalias !2473
  %504 = load i64, i64* %502, align 8
  store i64 %500, i64* %RSP, align 8, !alias.scope !2470, !noalias !2473
  %505 = tail call double @cos(double %503)
  %506 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %507 = bitcast i64* %506 to i8*
  call void @llvm.memset.p0i8.i64(i8* %507, i8 0, i64 24, i32 8, i1 false)
  store double %505, double* %403, align 8, !alias.scope !2470, !noalias !2473
  %508 = load i64, i64* %RBP, align 8
  %509 = add i64 %508, -24
  %510 = add i64 %504, 4
  store i64 %510, i64* %PC, align 8
  %511 = inttoptr i64 %509 to i64*
  %512 = load i64, i64* %511, align 8
  store i64 %512, i64* %RCX, align 8, !tbaa !2428
  %513 = add i64 %508, -32
  %514 = add i64 %504, 8
  store i64 %514, i64* %PC, align 8
  %515 = inttoptr i64 %513 to i32*
  %516 = load i32, i32* %515, align 4
  %517 = sext i32 %516 to i64
  store i64 %517, i64* %RDX, align 8, !tbaa !2428
  %518 = shl nsw i64 %517, 3
  %519 = add i64 %518, %512
  %520 = add i64 %504, 13
  store i64 %520, i64* %PC, align 8
  %521 = inttoptr i64 %519 to double*
  store double %505, double* %521, align 8
  %522 = load i64, i64* %RBP, align 8
  %523 = add i64 %522, -24
  %524 = load i64, i64* %PC, align 8
  %525 = add i64 %524, 4
  store i64 %525, i64* %PC, align 8
  %526 = inttoptr i64 %523 to i64*
  %527 = load i64, i64* %526, align 8
  store i64 %527, i64* %RCX, align 8, !tbaa !2428
  %528 = add i64 %522, -32
  %529 = add i64 %524, 8
  store i64 %529, i64* %PC, align 8
  %530 = inttoptr i64 %528 to i32*
  %531 = load i32, i32* %530, align 4
  %532 = sext i32 %531 to i64
  store i64 %532, i64* %RDX, align 8, !tbaa !2428
  %533 = shl nsw i64 %532, 3
  %534 = add i64 %533, %527
  %535 = add i64 %524, 13
  store i64 %535, i64* %PC, align 8
  %536 = inttoptr i64 %534 to i64*
  %537 = load i64, i64* %536, align 8
  store i64 %537, i64* %404, align 1, !tbaa !2451
  store double 0.000000e+00, double* %406, align 1, !tbaa !2451
  %538 = add i64 %524, 17
  store i64 %538, i64* %PC, align 8
  %539 = load i64, i64* %526, align 8
  store i64 %539, i64* %RCX, align 8, !tbaa !2428
  %540 = add i64 %524, 20
  store i64 %540, i64* %PC, align 8
  %541 = load i32, i32* %530, align 4
  %542 = add i32 %541, 1
  %543 = zext i32 %542 to i64
  store i64 %543, i64* %RAX, align 8, !tbaa !2428
  %544 = icmp eq i32 %541, -1
  %545 = icmp eq i32 %542, 0
  %546 = or i1 %544, %545
  %547 = zext i1 %546 to i8
  store i8 %547, i8* %15, align 1, !tbaa !2432
  %548 = and i32 %542, 255
  %549 = tail call i32 @llvm.ctpop.i32(i32 %548) #14
  %550 = trunc i32 %549 to i8
  %551 = and i8 %550, 1
  %552 = xor i8 %551, 1
  store i8 %552, i8* %22, align 1, !tbaa !2446
  %553 = xor i32 %542, %541
  %554 = lshr i32 %553, 4
  %555 = trunc i32 %554 to i8
  %556 = and i8 %555, 1
  store i8 %556, i8* %27, align 1, !tbaa !2447
  %557 = zext i1 %545 to i8
  store i8 %557, i8* %30, align 1, !tbaa !2448
  %558 = lshr i32 %542, 31
  %559 = trunc i32 %558 to i8
  store i8 %559, i8* %33, align 1, !tbaa !2449
  %560 = lshr i32 %541, 31
  %561 = xor i32 %558, %560
  %562 = add nuw nsw i32 %561, %558
  %563 = icmp eq i32 %562, 2
  %564 = zext i1 %563 to i8
  store i8 %564, i8* %39, align 1, !tbaa !2450
  %565 = sext i32 %542 to i64
  store i64 %565, i64* %RDX, align 8, !tbaa !2428
  %566 = shl nsw i64 %565, 3
  %567 = add i64 %539, %566
  %568 = add i64 %524, 31
  store i64 %568, i64* %PC, align 8
  %569 = inttoptr i64 %567 to i64*
  store i64 %537, i64* %569, align 8
  %570 = load i64, i64* %RBP, align 8
  %571 = add i64 %570, -32
  %572 = load i64, i64* %PC, align 8
  %573 = add i64 %572, 4
  store i64 %573, i64* %PC, align 8
  %574 = inttoptr i64 %571 to i32*
  %575 = load i32, i32* %574, align 4
  %576 = add i32 %575, -2
  %577 = icmp ult i32 %575, 2
  %578 = zext i1 %577 to i8
  store i8 %578, i8* %15, align 1, !tbaa !2432
  %579 = and i32 %576, 255
  %580 = tail call i32 @llvm.ctpop.i32(i32 %579) #14
  %581 = trunc i32 %580 to i8
  %582 = and i8 %581, 1
  %583 = xor i8 %582, 1
  store i8 %583, i8* %22, align 1, !tbaa !2446
  %584 = xor i32 %576, %575
  %585 = lshr i32 %584, 4
  %586 = trunc i32 %585 to i8
  %587 = and i8 %586, 1
  store i8 %587, i8* %27, align 1, !tbaa !2447
  %588 = icmp eq i32 %576, 0
  %589 = zext i1 %588 to i8
  store i8 %589, i8* %30, align 1, !tbaa !2448
  %590 = lshr i32 %576, 31
  %591 = trunc i32 %590 to i8
  store i8 %591, i8* %33, align 1, !tbaa !2449
  %592 = lshr i32 %575, 31
  %593 = xor i32 %590, %592
  %594 = add nuw nsw i32 %593, %592
  %595 = icmp eq i32 %594, 2
  %596 = zext i1 %595 to i8
  store i8 %596, i8* %39, align 1, !tbaa !2450
  %597 = icmp ne i8 %591, 0
  %598 = xor i1 %597, %595
  %599 = or i1 %588, %598
  %.v117 = select i1 %599, i64 197, i64 10
  %600 = add i64 %572, %.v117
  store i64 %600, i64* %PC, align 8, !tbaa !2428
  br i1 %599, label %block_400fd1, label %block_400f16

block_400fc1:                                     ; preds = %block_400f1d
  %601 = add i64 %88, -4
  %602 = add i64 %124, 3
  store i64 %602, i64* %PC, align 8
  %603 = inttoptr i64 %601 to i32*
  %604 = load i32, i32* %603, align 4
  %605 = zext i32 %604 to i64
  store i64 %605, i64* %RDI, align 8, !tbaa !2428
  %606 = add i64 %88, -16
  %607 = add i64 %124, 7
  store i64 %607, i64* %PC, align 8
  %608 = inttoptr i64 %606 to i64*
  %609 = load i64, i64* %608, align 8
  store i64 %609, i64* %RSI, align 8, !tbaa !2428
  %610 = add i64 %88, -24
  %611 = add i64 %124, 11
  store i64 %611, i64* %PC, align 8
  %612 = inttoptr i64 %610 to i64*
  %613 = load i64, i64* %612, align 8
  store i64 %613, i64* %RDX, align 8, !tbaa !2428
  %614 = add i64 %124, 559
  %615 = add i64 %124, 16
  %616 = load i64, i64* %RSP, align 8, !tbaa !2428
  %617 = add i64 %616, -8
  %618 = inttoptr i64 %617 to i64*
  store i64 %615, i64* %618, align 8
  store i64 %617, i64* %RSP, align 8, !tbaa !2428
  store i64 %614, i64* %PC, align 8, !tbaa !2428
  %619 = tail call %struct.Memory* @sub_4011f0_bitrv2_renamed_(%struct.State* nonnull %0, i64 %614, %struct.Memory* %2)
  %.pre116 = load i64, i64* %PC, align 8
  br label %block_400fd1
}

; Function Attrs: noinline
define %struct.Memory* @sub_4024b0_cftbsub(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone) local_unnamed_addr #8 {
block_4024b0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -120
  store i64 %11, i64* %RSP, align 8, !tbaa !2428
  %12 = icmp ult i64 %8, 112
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1, !tbaa !2432
  %15 = trunc i64 %11 to i32
  %16 = and i32 %15, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16) #14
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1, !tbaa !2446
  %22 = xor i64 %8, 16
  %23 = xor i64 %22, %11
  %24 = lshr i64 %23, 4
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1, !tbaa !2447
  %28 = icmp eq i64 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1, !tbaa !2448
  %31 = lshr i64 %11, 63
  %32 = trunc i64 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1, !tbaa !2449
  %34 = lshr i64 %8, 63
  %35 = xor i64 %31, %34
  %36 = add nuw nsw i64 %35, %34
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1, !tbaa !2450
  %40 = add i64 %7, -12
  %41 = load i32, i32* %EDI, align 4
  %42 = add i64 %10, 10
  store i64 %42, i64* %PC, align 8
  %43 = inttoptr i64 %40 to i32*
  store i32 %41, i32* %43, align 4
  %44 = load i64, i64* %RBP, align 8
  %45 = add i64 %44, -16
  %46 = load i64, i64* %RSI, align 8
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 4
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %45 to i64*
  store i64 %46, i64* %49, align 8
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -24
  %52 = load i64, i64* %RDX, align 8
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 4
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %51 to i64*
  store i64 %52, i64* %55, align 8
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -44
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 7
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %57 to i32*
  store i32 2, i32* %60, align 4
  %61 = load i64, i64* %RBP, align 8
  %62 = add i64 %61, -4
  %63 = load i64, i64* %PC, align 8
  %64 = add i64 %63, 4
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %62 to i32*
  %66 = load i32, i32* %65, align 4
  %67 = add i32 %66, -8
  %68 = icmp ult i32 %66, 8
  %69 = zext i1 %68 to i8
  store i8 %69, i8* %14, align 1, !tbaa !2432
  %70 = and i32 %67, 255
  %71 = tail call i32 @llvm.ctpop.i32(i32 %70) #14
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  %74 = xor i8 %73, 1
  store i8 %74, i8* %21, align 1, !tbaa !2446
  %75 = xor i32 %67, %66
  %76 = lshr i32 %75, 4
  %77 = trunc i32 %76 to i8
  %78 = and i8 %77, 1
  store i8 %78, i8* %27, align 1, !tbaa !2447
  %79 = icmp eq i32 %67, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %30, align 1, !tbaa !2448
  %81 = lshr i32 %67, 31
  %82 = trunc i32 %81 to i8
  store i8 %82, i8* %33, align 1, !tbaa !2449
  %83 = lshr i32 %66, 31
  %84 = xor i32 %81, %83
  %85 = add nuw nsw i32 %84, %83
  %86 = icmp eq i32 %85, 2
  %87 = zext i1 %86 to i8
  store i8 %87, i8* %39, align 1, !tbaa !2450
  %88 = icmp ne i8 %82, 0
  %89 = xor i1 %88, %86
  %90 = or i1 %79, %89
  %.v14 = select i1 %90, i64 86, i64 10
  %91 = add i64 %63, %.v14
  store i64 %91, i64* %PC, align 8, !tbaa !2428
  br i1 %90, label %block_402520, label %block_4024d4

block_40277b:                                     ; preds = %block_402536
  %92 = add i64 %162, 286
  br label %block_402899

block_402899:                                     ; preds = %block_402894, %block_40277b
  %.sink = phi i64 [ %730, %block_402894 ], [ %92, %block_40277b ]
  %93 = load i64, i64* %RSP, align 8
  %94 = add i64 %93, 112
  store i64 %94, i64* %RSP, align 8, !tbaa !2428
  %95 = icmp ugt i64 %93, -113
  %96 = zext i1 %95 to i8
  store i8 %96, i8* %14, align 1, !tbaa !2432
  %97 = trunc i64 %94 to i32
  %98 = and i32 %97, 255
  %99 = tail call i32 @llvm.ctpop.i32(i32 %98) #14
  %100 = trunc i32 %99 to i8
  %101 = and i8 %100, 1
  %102 = xor i8 %101, 1
  store i8 %102, i8* %21, align 1, !tbaa !2446
  %103 = xor i64 %93, 16
  %104 = xor i64 %103, %94
  %105 = lshr i64 %104, 4
  %106 = trunc i64 %105 to i8
  %107 = and i8 %106, 1
  store i8 %107, i8* %27, align 1, !tbaa !2447
  %108 = icmp eq i64 %94, 0
  %109 = zext i1 %108 to i8
  store i8 %109, i8* %30, align 1, !tbaa !2448
  %110 = lshr i64 %94, 63
  %111 = trunc i64 %110 to i8
  store i8 %111, i8* %33, align 1, !tbaa !2449
  %112 = lshr i64 %93, 63
  %113 = xor i64 %110, %112
  %114 = add nuw nsw i64 %113, %110
  %115 = icmp eq i64 %114, 2
  %116 = zext i1 %115 to i8
  store i8 %116, i8* %39, align 1, !tbaa !2450
  %117 = add i64 %.sink, 5
  store i64 %117, i64* %PC, align 8
  %118 = add i64 %93, 120
  %119 = inttoptr i64 %94 to i64*
  %120 = load i64, i64* %119, align 8
  store i64 %120, i64* %RBP, align 8, !tbaa !2428
  store i64 %118, i64* %RSP, align 8, !tbaa !2428
  %121 = add i64 %.sink, 6
  store i64 %121, i64* %PC, align 8
  %122 = inttoptr i64 %118 to i64*
  %123 = load i64, i64* %122, align 8
  store i64 %123, i64* %PC, align 8, !tbaa !2428
  %124 = add i64 %93, 128
  store i64 %124, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.4

block_402536:                                     ; preds = %block_402536.preheader, %block_402542
  %125 = phi i64 [ %1646, %block_402542 ], [ %.pre12, %block_402536.preheader ]
  %126 = load i64, i64* %RBP, align 8
  %127 = add i64 %126, -28
  %128 = add i64 %125, 3
  store i64 %128, i64* %PC, align 8
  %129 = inttoptr i64 %127 to i32*
  %130 = load i32, i32* %129, align 4
  %131 = zext i32 %130 to i64
  store i64 %131, i64* %RAX, align 8, !tbaa !2428
  %132 = add i64 %126, -44
  %133 = add i64 %125, 6
  store i64 %133, i64* %PC, align 8
  %134 = inttoptr i64 %132 to i32*
  %135 = load i32, i32* %134, align 4
  %136 = sub i32 %130, %135
  %137 = icmp ult i32 %130, %135
  %138 = zext i1 %137 to i8
  store i8 %138, i8* %14, align 1, !tbaa !2432
  %139 = and i32 %136, 255
  %140 = tail call i32 @llvm.ctpop.i32(i32 %139) #14
  %141 = trunc i32 %140 to i8
  %142 = and i8 %141, 1
  %143 = xor i8 %142, 1
  store i8 %143, i8* %21, align 1, !tbaa !2446
  %144 = xor i32 %135, %130
  %145 = xor i32 %144, %136
  %146 = lshr i32 %145, 4
  %147 = trunc i32 %146 to i8
  %148 = and i8 %147, 1
  store i8 %148, i8* %27, align 1, !tbaa !2447
  %149 = icmp eq i32 %136, 0
  %150 = zext i1 %149 to i8
  store i8 %150, i8* %30, align 1, !tbaa !2448
  %151 = lshr i32 %136, 31
  %152 = trunc i32 %151 to i8
  store i8 %152, i8* %33, align 1, !tbaa !2449
  %153 = lshr i32 %130, 31
  %154 = lshr i32 %135, 31
  %155 = xor i32 %154, %153
  %156 = xor i32 %151, %153
  %157 = add nuw nsw i32 %156, %155
  %158 = icmp eq i32 %157, 2
  %159 = zext i1 %158 to i8
  store i8 %159, i8* %39, align 1, !tbaa !2450
  %160 = icmp ne i8 %152, 0
  %161 = xor i1 %160, %158
  %.v17 = select i1 %161, i64 12, i64 581
  %162 = add i64 %125, %.v17
  store i64 %162, i64* %PC, align 8, !tbaa !2428
  br i1 %161, label %block_402542, label %block_40277b

block_4024d4:                                     ; preds = %block_4024b0
  %163 = add i64 %91, 3
  store i64 %163, i64* %PC, align 8
  %164 = load i32, i32* %65, align 4
  %165 = zext i32 %164 to i64
  store i64 %165, i64* %RDI, align 8, !tbaa !2428
  %166 = add i64 %61, -16
  %167 = add i64 %91, 7
  store i64 %167, i64* %PC, align 8
  %168 = inttoptr i64 %166 to i64*
  %169 = load i64, i64* %168, align 8
  store i64 %169, i64* %RSI, align 8, !tbaa !2428
  %170 = add i64 %61, -24
  %171 = add i64 %91, 11
  store i64 %171, i64* %PC, align 8
  %172 = inttoptr i64 %170 to i64*
  %173 = load i64, i64* %172, align 8
  store i64 %173, i64* %RDX, align 8, !tbaa !2428
  %174 = add i64 %91, 972
  %175 = add i64 %91, 16
  %176 = load i64, i64* %RSP, align 8, !tbaa !2428
  %177 = add i64 %176, -8
  %178 = inttoptr i64 %177 to i64*
  store i64 %175, i64* %178, align 8
  store i64 %177, i64* %RSP, align 8, !tbaa !2428
  store i64 %174, i64* %PC, align 8, !tbaa !2428
  %179 = tail call %struct.Memory* @sub_4028a0_cft1st_renamed_(%struct.State* nonnull %0, i64 %174, %struct.Memory* %2)
  %180 = load i64, i64* %RBP, align 8
  %181 = add i64 %180, -44
  %182 = load i64, i64* %PC, align 8
  %183 = add i64 %182, 7
  store i64 %183, i64* %PC, align 8
  %184 = inttoptr i64 %181 to i32*
  store i32 8, i32* %184, align 4
  %.pre = load i64, i64* %PC, align 8
  br label %block_4024eb

block_402793:                                     ; preds = %block_402787
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %185 = add i64 %684, 13
  store i64 %185, i64* %PC, align 8
  %186 = load i32, i32* %651, align 4
  %187 = zext i32 %186 to i64
  store i64 %187, i64* %RCX, align 8, !tbaa !2428
  %188 = add i64 %684, 16
  store i64 %188, i64* %PC, align 8
  %189 = load i32, i32* %656, align 4
  %190 = add i32 %189, %186
  %191 = zext i32 %190 to i64
  store i64 %191, i64* %RCX, align 8, !tbaa !2428
  %192 = icmp ult i32 %190, %186
  %193 = icmp ult i32 %190, %189
  %194 = or i1 %192, %193
  %195 = zext i1 %194 to i8
  store i8 %195, i8* %14, align 1, !tbaa !2432
  %196 = and i32 %190, 255
  %197 = tail call i32 @llvm.ctpop.i32(i32 %196) #14
  %198 = trunc i32 %197 to i8
  %199 = and i8 %198, 1
  %200 = xor i8 %199, 1
  store i8 %200, i8* %21, align 1, !tbaa !2446
  %201 = xor i32 %189, %186
  %202 = xor i32 %201, %190
  %203 = lshr i32 %202, 4
  %204 = trunc i32 %203 to i8
  %205 = and i8 %204, 1
  store i8 %205, i8* %27, align 1, !tbaa !2447
  %206 = icmp eq i32 %190, 0
  %207 = zext i1 %206 to i8
  store i8 %207, i8* %30, align 1, !tbaa !2448
  %208 = lshr i32 %190, 31
  %209 = trunc i32 %208 to i8
  store i8 %209, i8* %33, align 1, !tbaa !2449
  %210 = lshr i32 %186, 31
  %211 = lshr i32 %189, 31
  %212 = xor i32 %208, %210
  %213 = xor i32 %208, %211
  %214 = add nuw nsw i32 %212, %213
  %215 = icmp eq i32 %214, 2
  %216 = zext i1 %215 to i8
  store i8 %216, i8* %39, align 1, !tbaa !2450
  %217 = add i64 %648, -32
  %218 = add i64 %684, 19
  store i64 %218, i64* %PC, align 8
  %219 = inttoptr i64 %217 to i32*
  store i32 %190, i32* %219, align 4
  %220 = load i64, i64* %RBP, align 8
  %221 = add i64 %220, -16
  %222 = load i64, i64* %PC, align 8
  %223 = add i64 %222, 4
  store i64 %223, i64* %PC, align 8
  %224 = inttoptr i64 %221 to i64*
  %225 = load i64, i64* %224, align 8
  store i64 %225, i64* %RDX, align 8, !tbaa !2428
  %226 = add i64 %220, -28
  %227 = add i64 %222, 8
  store i64 %227, i64* %PC, align 8
  %228 = inttoptr i64 %226 to i32*
  %229 = load i32, i32* %228, align 4
  %230 = sext i32 %229 to i64
  store i64 %230, i64* %RSI, align 8, !tbaa !2428
  %231 = shl nsw i64 %230, 3
  %232 = add i64 %231, %225
  %233 = add i64 %222, 13
  store i64 %233, i64* %PC, align 8
  %234 = inttoptr i64 %232 to i64*
  %235 = load i64, i64* %234, align 8
  store i64 %235, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %236 = add i64 %222, 17
  store i64 %236, i64* %PC, align 8
  %237 = load i64, i64* %224, align 8
  store i64 %237, i64* %RDX, align 8, !tbaa !2428
  %238 = add i64 %220, -32
  %239 = add i64 %222, 21
  store i64 %239, i64* %PC, align 8
  %240 = inttoptr i64 %238 to i32*
  %241 = load i32, i32* %240, align 4
  %242 = sext i32 %241 to i64
  store i64 %242, i64* %RSI, align 8, !tbaa !2428
  %243 = shl nsw i64 %242, 3
  %244 = add i64 %243, %237
  %245 = add i64 %222, 26
  store i64 %245, i64* %PC, align 8
  %246 = bitcast i64 %235 to double
  %247 = inttoptr i64 %244 to double*
  %248 = load double, double* %247, align 8
  %249 = fsub double %246, %248
  store double %249, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %250 = add i64 %220, -56
  %251 = add i64 %222, 31
  store i64 %251, i64* %PC, align 8
  %252 = inttoptr i64 %250 to double*
  store double %249, double* %252, align 8
  %253 = load i64, i64* %RBP, align 8
  %254 = add i64 %253, -16
  %255 = load i64, i64* %PC, align 8
  %256 = add i64 %255, 4
  store i64 %256, i64* %PC, align 8
  %257 = inttoptr i64 %254 to i64*
  %258 = load i64, i64* %257, align 8
  store i64 %258, i64* %RDX, align 8, !tbaa !2428
  %259 = add i64 %253, -28
  %260 = add i64 %255, 7
  store i64 %260, i64* %PC, align 8
  %261 = inttoptr i64 %259 to i32*
  %262 = load i32, i32* %261, align 4
  %263 = add i32 %262, 1
  %264 = zext i32 %263 to i64
  store i64 %264, i64* %RCX, align 8, !tbaa !2428
  %265 = icmp eq i32 %262, -1
  %266 = icmp eq i32 %263, 0
  %267 = or i1 %265, %266
  %268 = zext i1 %267 to i8
  store i8 %268, i8* %14, align 1, !tbaa !2432
  %269 = and i32 %263, 255
  %270 = tail call i32 @llvm.ctpop.i32(i32 %269) #14
  %271 = trunc i32 %270 to i8
  %272 = and i8 %271, 1
  %273 = xor i8 %272, 1
  store i8 %273, i8* %21, align 1, !tbaa !2446
  %274 = xor i32 %263, %262
  %275 = lshr i32 %274, 4
  %276 = trunc i32 %275 to i8
  %277 = and i8 %276, 1
  store i8 %277, i8* %27, align 1, !tbaa !2447
  %278 = zext i1 %266 to i8
  store i8 %278, i8* %30, align 1, !tbaa !2448
  %279 = lshr i32 %263, 31
  %280 = trunc i32 %279 to i8
  store i8 %280, i8* %33, align 1, !tbaa !2449
  %281 = lshr i32 %262, 31
  %282 = xor i32 %279, %281
  %283 = add nuw nsw i32 %282, %279
  %284 = icmp eq i32 %283, 2
  %285 = zext i1 %284 to i8
  store i8 %285, i8* %39, align 1, !tbaa !2450
  %286 = sext i32 %263 to i64
  store i64 %286, i64* %RSI, align 8, !tbaa !2428
  %287 = shl nsw i64 %286, 3
  %288 = add i64 %258, %287
  %289 = add i64 %255, 18
  store i64 %289, i64* %PC, align 8
  %290 = inttoptr i64 %288 to i64*
  %291 = load i64, i64* %290, align 8
  %292 = load i64, i64* %RAX, align 8
  %293 = xor i64 %292, %291
  store i64 %293, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2432
  %294 = trunc i64 %293 to i32
  %295 = and i32 %294, 255
  %296 = tail call i32 @llvm.ctpop.i32(i32 %295) #14
  %297 = trunc i32 %296 to i8
  %298 = and i8 %297, 1
  %299 = xor i8 %298, 1
  store i8 %299, i8* %21, align 1, !tbaa !2446
  %300 = icmp eq i64 %293, 0
  %301 = zext i1 %300 to i8
  store i8 %301, i8* %30, align 1, !tbaa !2448
  %302 = lshr i64 %293, 63
  %303 = trunc i64 %302 to i8
  store i8 %303, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2447
  store i64 %293, i64* %1702, align 1, !tbaa !2428
  store i64 0, i64* %1703, align 1, !tbaa !2428
  %304 = add i64 %255, 35
  store i64 %304, i64* %PC, align 8
  %305 = load i64, i64* %257, align 8
  store i64 %305, i64* %RDX, align 8, !tbaa !2428
  %306 = add i64 %253, -32
  %307 = add i64 %255, 38
  store i64 %307, i64* %PC, align 8
  %308 = inttoptr i64 %306 to i32*
  %309 = load i32, i32* %308, align 4
  %310 = add i32 %309, 1
  %311 = zext i32 %310 to i64
  store i64 %311, i64* %RCX, align 8, !tbaa !2428
  %312 = icmp eq i32 %309, -1
  %313 = icmp eq i32 %310, 0
  %314 = or i1 %312, %313
  %315 = zext i1 %314 to i8
  store i8 %315, i8* %14, align 1, !tbaa !2432
  %316 = and i32 %310, 255
  %317 = tail call i32 @llvm.ctpop.i32(i32 %316) #14
  %318 = trunc i32 %317 to i8
  %319 = and i8 %318, 1
  %320 = xor i8 %319, 1
  store i8 %320, i8* %21, align 1, !tbaa !2446
  %321 = xor i32 %310, %309
  %322 = lshr i32 %321, 4
  %323 = trunc i32 %322 to i8
  %324 = and i8 %323, 1
  store i8 %324, i8* %27, align 1, !tbaa !2447
  %325 = zext i1 %313 to i8
  store i8 %325, i8* %30, align 1, !tbaa !2448
  %326 = lshr i32 %310, 31
  %327 = trunc i32 %326 to i8
  store i8 %327, i8* %33, align 1, !tbaa !2449
  %328 = lshr i32 %309, 31
  %329 = xor i32 %326, %328
  %330 = add nuw nsw i32 %329, %326
  %331 = icmp eq i32 %330, 2
  %332 = zext i1 %331 to i8
  store i8 %332, i8* %39, align 1, !tbaa !2450
  %333 = sext i32 %310 to i64
  store i64 %333, i64* %RSI, align 8, !tbaa !2428
  %334 = shl nsw i64 %333, 3
  %335 = add i64 %305, %334
  %336 = add i64 %255, 49
  store i64 %336, i64* %PC, align 8
  %337 = bitcast i64 %293 to double
  %338 = inttoptr i64 %335 to double*
  %339 = load double, double* %338, align 8
  %340 = fadd double %337, %339
  store double %340, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %341 = load i64, i64* %RBP, align 8
  %342 = add i64 %341, -64
  %343 = add i64 %255, 54
  store i64 %343, i64* %PC, align 8
  %344 = inttoptr i64 %342 to double*
  store double %340, double* %344, align 8
  %345 = load i64, i64* %RBP, align 8
  %346 = add i64 %345, -16
  %347 = load i64, i64* %PC, align 8
  %348 = add i64 %347, 4
  store i64 %348, i64* %PC, align 8
  %349 = inttoptr i64 %346 to i64*
  %350 = load i64, i64* %349, align 8
  store i64 %350, i64* %RDX, align 8, !tbaa !2428
  %351 = add i64 %345, -32
  %352 = add i64 %347, 8
  store i64 %352, i64* %PC, align 8
  %353 = inttoptr i64 %351 to i32*
  %354 = load i32, i32* %353, align 4
  %355 = sext i32 %354 to i64
  store i64 %355, i64* %RSI, align 8, !tbaa !2428
  %356 = shl nsw i64 %355, 3
  %357 = add i64 %356, %350
  %358 = add i64 %347, 13
  store i64 %358, i64* %PC, align 8
  %359 = inttoptr i64 %357 to i64*
  %360 = load i64, i64* %359, align 8
  store i64 %360, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %361 = add i64 %347, 17
  store i64 %361, i64* %PC, align 8
  %362 = load i64, i64* %349, align 8
  store i64 %362, i64* %RDX, align 8, !tbaa !2428
  %363 = add i64 %345, -28
  %364 = add i64 %347, 21
  store i64 %364, i64* %PC, align 8
  %365 = inttoptr i64 %363 to i32*
  %366 = load i32, i32* %365, align 4
  %367 = sext i32 %366 to i64
  store i64 %367, i64* %RSI, align 8, !tbaa !2428
  %368 = shl nsw i64 %367, 3
  %369 = add i64 %368, %362
  %370 = add i64 %347, 26
  store i64 %370, i64* %PC, align 8
  %371 = bitcast i64 %360 to double
  %372 = inttoptr i64 %369 to double*
  %373 = load double, double* %372, align 8
  %374 = fadd double %371, %373
  store double %374, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %375 = add i64 %347, 31
  store i64 %375, i64* %PC, align 8
  %376 = inttoptr i64 %369 to double*
  store double %374, double* %376, align 8
  %377 = load i64, i64* %RBP, align 8
  %378 = add i64 %377, -16
  %379 = load i64, i64* %PC, align 8
  %380 = add i64 %379, 4
  store i64 %380, i64* %PC, align 8
  %381 = inttoptr i64 %378 to i64*
  %382 = load i64, i64* %381, align 8
  store i64 %382, i64* %RDX, align 8, !tbaa !2428
  %383 = add i64 %377, -28
  %384 = add i64 %379, 7
  store i64 %384, i64* %PC, align 8
  %385 = inttoptr i64 %383 to i32*
  %386 = load i32, i32* %385, align 4
  %387 = add i32 %386, 1
  %388 = zext i32 %387 to i64
  store i64 %388, i64* %RCX, align 8, !tbaa !2428
  %389 = icmp eq i32 %386, -1
  %390 = icmp eq i32 %387, 0
  %391 = or i1 %389, %390
  %392 = zext i1 %391 to i8
  store i8 %392, i8* %14, align 1, !tbaa !2432
  %393 = and i32 %387, 255
  %394 = tail call i32 @llvm.ctpop.i32(i32 %393) #14
  %395 = trunc i32 %394 to i8
  %396 = and i8 %395, 1
  %397 = xor i8 %396, 1
  store i8 %397, i8* %21, align 1, !tbaa !2446
  %398 = xor i32 %387, %386
  %399 = lshr i32 %398, 4
  %400 = trunc i32 %399 to i8
  %401 = and i8 %400, 1
  store i8 %401, i8* %27, align 1, !tbaa !2447
  %402 = zext i1 %390 to i8
  store i8 %402, i8* %30, align 1, !tbaa !2448
  %403 = lshr i32 %387, 31
  %404 = trunc i32 %403 to i8
  store i8 %404, i8* %33, align 1, !tbaa !2449
  %405 = lshr i32 %386, 31
  %406 = xor i32 %403, %405
  %407 = add nuw nsw i32 %406, %403
  %408 = icmp eq i32 %407, 2
  %409 = zext i1 %408 to i8
  store i8 %409, i8* %39, align 1, !tbaa !2450
  %410 = sext i32 %387 to i64
  store i64 %410, i64* %RSI, align 8, !tbaa !2428
  %411 = shl nsw i64 %410, 3
  %412 = add i64 %382, %411
  %413 = add i64 %379, 18
  store i64 %413, i64* %PC, align 8
  %414 = inttoptr i64 %412 to i64*
  %415 = load i64, i64* %414, align 8
  %416 = load i64, i64* %RAX, align 8
  %417 = xor i64 %416, %415
  store i64 %417, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2432
  %418 = trunc i64 %417 to i32
  %419 = and i32 %418, 255
  %420 = tail call i32 @llvm.ctpop.i32(i32 %419) #14
  %421 = trunc i32 %420 to i8
  %422 = and i8 %421, 1
  %423 = xor i8 %422, 1
  store i8 %423, i8* %21, align 1, !tbaa !2446
  %424 = icmp eq i64 %417, 0
  %425 = zext i1 %424 to i8
  store i8 %425, i8* %30, align 1, !tbaa !2448
  %426 = lshr i64 %417, 63
  %427 = trunc i64 %426 to i8
  store i8 %427, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2447
  store i64 %417, i64* %1702, align 1, !tbaa !2428
  store i64 0, i64* %1703, align 1, !tbaa !2428
  %428 = add i64 %379, 35
  store i64 %428, i64* %PC, align 8
  %429 = load i64, i64* %381, align 8
  store i64 %429, i64* %RAX, align 8, !tbaa !2428
  %430 = add i64 %377, -32
  %431 = add i64 %379, 38
  store i64 %431, i64* %PC, align 8
  %432 = inttoptr i64 %430 to i32*
  %433 = load i32, i32* %432, align 4
  %434 = add i32 %433, 1
  %435 = zext i32 %434 to i64
  store i64 %435, i64* %RCX, align 8, !tbaa !2428
  %436 = icmp eq i32 %433, -1
  %437 = icmp eq i32 %434, 0
  %438 = or i1 %436, %437
  %439 = zext i1 %438 to i8
  store i8 %439, i8* %14, align 1, !tbaa !2432
  %440 = and i32 %434, 255
  %441 = tail call i32 @llvm.ctpop.i32(i32 %440) #14
  %442 = trunc i32 %441 to i8
  %443 = and i8 %442, 1
  %444 = xor i8 %443, 1
  store i8 %444, i8* %21, align 1, !tbaa !2446
  %445 = xor i32 %434, %433
  %446 = lshr i32 %445, 4
  %447 = trunc i32 %446 to i8
  %448 = and i8 %447, 1
  store i8 %448, i8* %27, align 1, !tbaa !2447
  %449 = zext i1 %437 to i8
  store i8 %449, i8* %30, align 1, !tbaa !2448
  %450 = lshr i32 %434, 31
  %451 = trunc i32 %450 to i8
  store i8 %451, i8* %33, align 1, !tbaa !2449
  %452 = lshr i32 %433, 31
  %453 = xor i32 %450, %452
  %454 = add nuw nsw i32 %453, %450
  %455 = icmp eq i32 %454, 2
  %456 = zext i1 %455 to i8
  store i8 %456, i8* %39, align 1, !tbaa !2450
  %457 = sext i32 %434 to i64
  store i64 %457, i64* %RDX, align 8, !tbaa !2428
  %458 = shl nsw i64 %457, 3
  %459 = add i64 %429, %458
  %460 = add i64 %379, 49
  store i64 %460, i64* %PC, align 8
  %461 = bitcast i64 %417 to double
  %462 = inttoptr i64 %459 to double*
  %463 = load double, double* %462, align 8
  %464 = fsub double %461, %463
  store double %464, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %465 = load i64, i64* %RBP, align 8
  %466 = add i64 %465, -16
  %467 = add i64 %379, 53
  store i64 %467, i64* %PC, align 8
  %468 = inttoptr i64 %466 to i64*
  %469 = load i64, i64* %468, align 8
  store i64 %469, i64* %RAX, align 8, !tbaa !2428
  %470 = add i64 %465, -28
  %471 = add i64 %379, 56
  store i64 %471, i64* %PC, align 8
  %472 = inttoptr i64 %470 to i32*
  %473 = load i32, i32* %472, align 4
  %474 = add i32 %473, 1
  %475 = zext i32 %474 to i64
  store i64 %475, i64* %RCX, align 8, !tbaa !2428
  %476 = icmp eq i32 %473, -1
  %477 = icmp eq i32 %474, 0
  %478 = or i1 %476, %477
  %479 = zext i1 %478 to i8
  store i8 %479, i8* %14, align 1, !tbaa !2432
  %480 = and i32 %474, 255
  %481 = tail call i32 @llvm.ctpop.i32(i32 %480) #14
  %482 = trunc i32 %481 to i8
  %483 = and i8 %482, 1
  %484 = xor i8 %483, 1
  store i8 %484, i8* %21, align 1, !tbaa !2446
  %485 = xor i32 %474, %473
  %486 = lshr i32 %485, 4
  %487 = trunc i32 %486 to i8
  %488 = and i8 %487, 1
  store i8 %488, i8* %27, align 1, !tbaa !2447
  %489 = zext i1 %477 to i8
  store i8 %489, i8* %30, align 1, !tbaa !2448
  %490 = lshr i32 %474, 31
  %491 = trunc i32 %490 to i8
  store i8 %491, i8* %33, align 1, !tbaa !2449
  %492 = lshr i32 %473, 31
  %493 = xor i32 %490, %492
  %494 = add nuw nsw i32 %493, %490
  %495 = icmp eq i32 %494, 2
  %496 = zext i1 %495 to i8
  store i8 %496, i8* %39, align 1, !tbaa !2450
  %497 = sext i32 %474 to i64
  store i64 %497, i64* %RDX, align 8, !tbaa !2428
  %498 = shl nsw i64 %497, 3
  %499 = add i64 %469, %498
  %500 = add i64 %379, 67
  store i64 %500, i64* %PC, align 8
  %501 = inttoptr i64 %499 to double*
  store double %464, double* %501, align 8
  %502 = load i64, i64* %RBP, align 8
  %503 = add i64 %502, -56
  %504 = load i64, i64* %PC, align 8
  %505 = add i64 %504, 5
  store i64 %505, i64* %PC, align 8
  %506 = inttoptr i64 %503 to i64*
  %507 = load i64, i64* %506, align 8
  store i64 %507, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %508 = add i64 %502, -16
  %509 = add i64 %504, 9
  store i64 %509, i64* %PC, align 8
  %510 = inttoptr i64 %508 to i64*
  %511 = load i64, i64* %510, align 8
  store i64 %511, i64* %RAX, align 8, !tbaa !2428
  %512 = add i64 %502, -32
  %513 = add i64 %504, 13
  store i64 %513, i64* %PC, align 8
  %514 = inttoptr i64 %512 to i32*
  %515 = load i32, i32* %514, align 4
  %516 = sext i32 %515 to i64
  store i64 %516, i64* %RDX, align 8, !tbaa !2428
  %517 = shl nsw i64 %516, 3
  %518 = add i64 %517, %511
  %519 = add i64 %504, 18
  store i64 %519, i64* %PC, align 8
  %520 = inttoptr i64 %518 to i64*
  store i64 %507, i64* %520, align 8
  %521 = load i64, i64* %RBP, align 8
  %522 = add i64 %521, -64
  %523 = load i64, i64* %PC, align 8
  %524 = add i64 %523, 5
  store i64 %524, i64* %PC, align 8
  %525 = inttoptr i64 %522 to i64*
  %526 = load i64, i64* %525, align 8
  store i64 %526, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %527 = add i64 %521, -16
  %528 = add i64 %523, 9
  store i64 %528, i64* %PC, align 8
  %529 = inttoptr i64 %527 to i64*
  %530 = load i64, i64* %529, align 8
  store i64 %530, i64* %RAX, align 8, !tbaa !2428
  %531 = add i64 %521, -32
  %532 = add i64 %523, 12
  store i64 %532, i64* %PC, align 8
  %533 = inttoptr i64 %531 to i32*
  %534 = load i32, i32* %533, align 4
  %535 = add i32 %534, 1
  %536 = zext i32 %535 to i64
  store i64 %536, i64* %RCX, align 8, !tbaa !2428
  %537 = icmp eq i32 %534, -1
  %538 = icmp eq i32 %535, 0
  %539 = or i1 %537, %538
  %540 = zext i1 %539 to i8
  store i8 %540, i8* %14, align 1, !tbaa !2432
  %541 = and i32 %535, 255
  %542 = tail call i32 @llvm.ctpop.i32(i32 %541) #14
  %543 = trunc i32 %542 to i8
  %544 = and i8 %543, 1
  %545 = xor i8 %544, 1
  store i8 %545, i8* %21, align 1, !tbaa !2446
  %546 = xor i32 %535, %534
  %547 = lshr i32 %546, 4
  %548 = trunc i32 %547 to i8
  %549 = and i8 %548, 1
  store i8 %549, i8* %27, align 1, !tbaa !2447
  %550 = zext i1 %538 to i8
  store i8 %550, i8* %30, align 1, !tbaa !2448
  %551 = lshr i32 %535, 31
  %552 = trunc i32 %551 to i8
  store i8 %552, i8* %33, align 1, !tbaa !2449
  %553 = lshr i32 %534, 31
  %554 = xor i32 %551, %553
  %555 = add nuw nsw i32 %554, %551
  %556 = icmp eq i32 %555, 2
  %557 = zext i1 %556 to i8
  store i8 %557, i8* %39, align 1, !tbaa !2450
  %558 = sext i32 %535 to i64
  store i64 %558, i64* %RDX, align 8, !tbaa !2428
  %559 = shl nsw i64 %558, 3
  %560 = add i64 %530, %559
  %561 = add i64 %523, 23
  store i64 %561, i64* %PC, align 8
  %562 = inttoptr i64 %560 to i64*
  store i64 %526, i64* %562, align 8
  %563 = load i64, i64* %RBP, align 8
  %564 = add i64 %563, -28
  %565 = load i64, i64* %PC, align 8
  %566 = add i64 %565, 3
  store i64 %566, i64* %PC, align 8
  %567 = inttoptr i64 %564 to i32*
  %568 = load i32, i32* %567, align 4
  %569 = add i32 %568, 2
  %570 = zext i32 %569 to i64
  store i64 %570, i64* %RAX, align 8, !tbaa !2428
  %571 = icmp ugt i32 %568, -3
  %572 = zext i1 %571 to i8
  store i8 %572, i8* %14, align 1, !tbaa !2432
  %573 = and i32 %569, 255
  %574 = tail call i32 @llvm.ctpop.i32(i32 %573) #14
  %575 = trunc i32 %574 to i8
  %576 = and i8 %575, 1
  %577 = xor i8 %576, 1
  store i8 %577, i8* %21, align 1, !tbaa !2446
  %578 = xor i32 %569, %568
  %579 = lshr i32 %578, 4
  %580 = trunc i32 %579 to i8
  %581 = and i8 %580, 1
  store i8 %581, i8* %27, align 1, !tbaa !2447
  %582 = icmp eq i32 %569, 0
  %583 = zext i1 %582 to i8
  store i8 %583, i8* %30, align 1, !tbaa !2448
  %584 = lshr i32 %569, 31
  %585 = trunc i32 %584 to i8
  store i8 %585, i8* %33, align 1, !tbaa !2449
  %586 = lshr i32 %568, 31
  %587 = xor i32 %584, %586
  %588 = add nuw nsw i32 %587, %584
  %589 = icmp eq i32 %588, 2
  %590 = zext i1 %589 to i8
  store i8 %590, i8* %39, align 1, !tbaa !2450
  %591 = add i64 %565, 9
  store i64 %591, i64* %PC, align 8
  store i32 %569, i32* %567, align 4
  %592 = load i64, i64* %PC, align 8
  %593 = add i64 %592, -264
  store i64 %593, i64* %PC, align 8, !tbaa !2428
  br label %block_402787

block_4024eb:                                     ; preds = %block_4024fa, %block_4024d4
  %594 = phi i64 [ %729, %block_4024fa ], [ %.pre, %block_4024d4 ]
  %595 = load i64, i64* %RBP, align 8
  %596 = add i64 %595, -44
  %597 = add i64 %594, 3
  store i64 %597, i64* %PC, align 8
  %598 = inttoptr i64 %596 to i32*
  %599 = load i32, i32* %598, align 4
  %600 = shl i32 %599, 2
  %601 = zext i32 %600 to i64
  store i64 %601, i64* %RAX, align 8, !tbaa !2428
  %602 = lshr i32 %599, 30
  %603 = trunc i32 %602 to i8
  %604 = and i8 %603, 1
  store i8 %604, i8* %14, align 1, !tbaa !2453
  %605 = and i32 %600, 252
  %606 = tail call i32 @llvm.ctpop.i32(i32 %605) #14
  %607 = trunc i32 %606 to i8
  %608 = and i8 %607, 1
  %609 = xor i8 %608, 1
  store i8 %609, i8* %21, align 1, !tbaa !2453
  store i8 0, i8* %27, align 1, !tbaa !2453
  %610 = icmp eq i32 %600, 0
  %611 = zext i1 %610 to i8
  store i8 %611, i8* %30, align 1, !tbaa !2453
  %612 = lshr i32 %599, 29
  %613 = trunc i32 %612 to i8
  %614 = and i8 %613, 1
  store i8 %614, i8* %33, align 1, !tbaa !2453
  store i8 0, i8* %39, align 1, !tbaa !2453
  %615 = add i64 %595, -4
  %616 = add i64 %594, 9
  store i64 %616, i64* %PC, align 8
  %617 = inttoptr i64 %615 to i32*
  %618 = load i32, i32* %617, align 4
  %619 = sub i32 %600, %618
  %620 = icmp ult i32 %600, %618
  %621 = zext i1 %620 to i8
  store i8 %621, i8* %14, align 1, !tbaa !2432
  %622 = and i32 %619, 255
  %623 = tail call i32 @llvm.ctpop.i32(i32 %622) #14
  %624 = trunc i32 %623 to i8
  %625 = and i8 %624, 1
  %626 = xor i8 %625, 1
  store i8 %626, i8* %21, align 1, !tbaa !2446
  %627 = xor i32 %618, %600
  %628 = xor i32 %627, %619
  %629 = lshr i32 %628, 4
  %630 = trunc i32 %629 to i8
  %631 = and i8 %630, 1
  store i8 %631, i8* %27, align 1, !tbaa !2447
  %632 = icmp eq i32 %619, 0
  %633 = zext i1 %632 to i8
  store i8 %633, i8* %30, align 1, !tbaa !2448
  %634 = lshr i32 %619, 31
  %635 = trunc i32 %634 to i8
  store i8 %635, i8* %33, align 1, !tbaa !2449
  %636 = lshr i32 %599, 29
  %637 = and i32 %636, 1
  %638 = lshr i32 %618, 31
  %639 = xor i32 %638, %637
  %640 = xor i32 %634, %637
  %641 = add nuw nsw i32 %640, %639
  %642 = icmp eq i32 %641, 2
  %643 = zext i1 %642 to i8
  store i8 %643, i8* %39, align 1, !tbaa !2450
  %644 = icmp ne i8 %635, 0
  %645 = xor i1 %644, %642
  %.v15 = select i1 %645, i64 15, i64 48
  %646 = add i64 %594, %.v15
  store i64 %646, i64* %PC, align 8, !tbaa !2428
  br i1 %645, label %block_4024fa, label %block_40251b

block_402787:                                     ; preds = %block_402787.preheader, %block_402793
  %647 = phi i64 [ %593, %block_402793 ], [ %.pre12, %block_402787.preheader ]
  %648 = load i64, i64* %RBP, align 8
  %649 = add i64 %648, -28
  %650 = add i64 %647, 3
  store i64 %650, i64* %PC, align 8
  %651 = inttoptr i64 %649 to i32*
  %652 = load i32, i32* %651, align 4
  %653 = zext i32 %652 to i64
  store i64 %653, i64* %RAX, align 8, !tbaa !2428
  %654 = add i64 %648, -44
  %655 = add i64 %647, 6
  store i64 %655, i64* %PC, align 8
  %656 = inttoptr i64 %654 to i32*
  %657 = load i32, i32* %656, align 4
  %658 = sub i32 %652, %657
  %659 = icmp ult i32 %652, %657
  %660 = zext i1 %659 to i8
  store i8 %660, i8* %14, align 1, !tbaa !2432
  %661 = and i32 %658, 255
  %662 = tail call i32 @llvm.ctpop.i32(i32 %661) #14
  %663 = trunc i32 %662 to i8
  %664 = and i8 %663, 1
  %665 = xor i8 %664, 1
  store i8 %665, i8* %21, align 1, !tbaa !2446
  %666 = xor i32 %657, %652
  %667 = xor i32 %666, %658
  %668 = lshr i32 %667, 4
  %669 = trunc i32 %668 to i8
  %670 = and i8 %669, 1
  store i8 %670, i8* %27, align 1, !tbaa !2447
  %671 = icmp eq i32 %658, 0
  %672 = zext i1 %671 to i8
  store i8 %672, i8* %30, align 1, !tbaa !2448
  %673 = lshr i32 %658, 31
  %674 = trunc i32 %673 to i8
  store i8 %674, i8* %33, align 1, !tbaa !2449
  %675 = lshr i32 %652, 31
  %676 = lshr i32 %657, 31
  %677 = xor i32 %676, %675
  %678 = xor i32 %673, %675
  %679 = add nuw nsw i32 %678, %677
  %680 = icmp eq i32 %679, 2
  %681 = zext i1 %680 to i8
  store i8 %681, i8* %39, align 1, !tbaa !2450
  %682 = icmp ne i8 %674, 0
  %683 = xor i1 %682, %680
  %.v16 = select i1 %683, i64 12, i64 269
  %684 = add i64 %647, %.v16
  store i64 %684, i64* %PC, align 8, !tbaa !2428
  br i1 %683, label %block_402793, label %block_402894

block_40251b:                                     ; preds = %block_4024eb
  %685 = add i64 %646, 5
  store i64 %685, i64* %PC, align 8, !tbaa !2428
  br label %block_402520

block_4024fa:                                     ; preds = %block_4024eb
  %686 = add i64 %646, 3
  store i64 %686, i64* %PC, align 8
  %687 = load i32, i32* %617, align 4
  %688 = zext i32 %687 to i64
  store i64 %688, i64* %RDI, align 8, !tbaa !2428
  %689 = add i64 %646, 6
  store i64 %689, i64* %PC, align 8
  %690 = load i32, i32* %598, align 4
  %691 = zext i32 %690 to i64
  store i64 %691, i64* %RSI, align 8, !tbaa !2428
  %692 = add i64 %595, -16
  %693 = add i64 %646, 10
  store i64 %693, i64* %PC, align 8
  %694 = inttoptr i64 %692 to i64*
  %695 = load i64, i64* %694, align 8
  store i64 %695, i64* %RDX, align 8, !tbaa !2428
  %696 = add i64 %595, -24
  %697 = add i64 %646, 14
  store i64 %697, i64* %PC, align 8
  %698 = inttoptr i64 %696 to i64*
  %699 = load i64, i64* %698, align 8
  store i64 %699, i64* %RCX, align 8, !tbaa !2428
  %700 = add i64 %646, 3638
  %701 = add i64 %646, 19
  %702 = load i64, i64* %RSP, align 8, !tbaa !2428
  %703 = add i64 %702, -8
  %704 = inttoptr i64 %703 to i64*
  store i64 %701, i64* %704, align 8
  store i64 %703, i64* %RSP, align 8, !tbaa !2428
  store i64 %700, i64* %PC, align 8, !tbaa !2428
  %705 = tail call %struct.Memory* @sub_403330_cftmdl_renamed_(%struct.State* nonnull %0, i64 %700, %struct.Memory* %179)
  %706 = load i64, i64* %RBP, align 8
  %707 = add i64 %706, -44
  %708 = load i64, i64* %PC, align 8
  %709 = add i64 %708, 3
  store i64 %709, i64* %PC, align 8
  %710 = inttoptr i64 %707 to i32*
  %711 = load i32, i32* %710, align 4
  %712 = shl i32 %711, 2
  %713 = zext i32 %712 to i64
  store i64 %713, i64* %RSI, align 8, !tbaa !2428
  %714 = lshr i32 %711, 30
  %715 = trunc i32 %714 to i8
  %716 = and i8 %715, 1
  store i8 %716, i8* %14, align 1, !tbaa !2453
  %717 = and i32 %712, 252
  %718 = tail call i32 @llvm.ctpop.i32(i32 %717) #14
  %719 = trunc i32 %718 to i8
  %720 = and i8 %719, 1
  %721 = xor i8 %720, 1
  store i8 %721, i8* %21, align 1, !tbaa !2453
  store i8 0, i8* %27, align 1, !tbaa !2453
  %722 = icmp eq i32 %712, 0
  %723 = zext i1 %722 to i8
  store i8 %723, i8* %30, align 1, !tbaa !2453
  %724 = lshr i32 %711, 29
  %725 = trunc i32 %724 to i8
  %726 = and i8 %725, 1
  store i8 %726, i8* %33, align 1, !tbaa !2453
  store i8 0, i8* %39, align 1, !tbaa !2453
  %727 = add i64 %708, 9
  store i64 %727, i64* %PC, align 8
  store i32 %712, i32* %710, align 4
  %728 = load i64, i64* %PC, align 8
  %729 = add i64 %728, -43
  store i64 %729, i64* %PC, align 8, !tbaa !2428
  br label %block_4024eb

block_402894:                                     ; preds = %block_402787
  %730 = add i64 %684, 5
  br label %block_402899

block_402542:                                     ; preds = %block_402536
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %731 = add i64 %162, 13
  store i64 %731, i64* %PC, align 8
  %732 = load i32, i32* %129, align 4
  %733 = zext i32 %732 to i64
  store i64 %733, i64* %RCX, align 8, !tbaa !2428
  %734 = add i64 %162, 16
  store i64 %734, i64* %PC, align 8
  %735 = load i32, i32* %134, align 4
  %736 = add i32 %735, %732
  %737 = zext i32 %736 to i64
  store i64 %737, i64* %RCX, align 8, !tbaa !2428
  %738 = icmp ult i32 %736, %732
  %739 = icmp ult i32 %736, %735
  %740 = or i1 %738, %739
  %741 = zext i1 %740 to i8
  store i8 %741, i8* %14, align 1, !tbaa !2432
  %742 = and i32 %736, 255
  %743 = tail call i32 @llvm.ctpop.i32(i32 %742) #14
  %744 = trunc i32 %743 to i8
  %745 = and i8 %744, 1
  %746 = xor i8 %745, 1
  store i8 %746, i8* %21, align 1, !tbaa !2446
  %747 = xor i32 %735, %732
  %748 = xor i32 %747, %736
  %749 = lshr i32 %748, 4
  %750 = trunc i32 %749 to i8
  %751 = and i8 %750, 1
  store i8 %751, i8* %27, align 1, !tbaa !2447
  %752 = icmp eq i32 %736, 0
  %753 = zext i1 %752 to i8
  store i8 %753, i8* %30, align 1, !tbaa !2448
  %754 = lshr i32 %736, 31
  %755 = trunc i32 %754 to i8
  store i8 %755, i8* %33, align 1, !tbaa !2449
  %756 = lshr i32 %732, 31
  %757 = lshr i32 %735, 31
  %758 = xor i32 %754, %756
  %759 = xor i32 %754, %757
  %760 = add nuw nsw i32 %758, %759
  %761 = icmp eq i32 %760, 2
  %762 = zext i1 %761 to i8
  store i8 %762, i8* %39, align 1, !tbaa !2450
  %763 = add i64 %126, -32
  %764 = add i64 %162, 19
  store i64 %764, i64* %PC, align 8
  %765 = inttoptr i64 %763 to i32*
  store i32 %736, i32* %765, align 4
  %766 = load i64, i64* %RBP, align 8
  %767 = add i64 %766, -32
  %768 = load i64, i64* %PC, align 8
  %769 = add i64 %768, 3
  store i64 %769, i64* %PC, align 8
  %770 = inttoptr i64 %767 to i32*
  %771 = load i32, i32* %770, align 4
  %772 = zext i32 %771 to i64
  store i64 %772, i64* %RCX, align 8, !tbaa !2428
  %773 = add i64 %766, -44
  %774 = add i64 %768, 6
  store i64 %774, i64* %PC, align 8
  %775 = inttoptr i64 %773 to i32*
  %776 = load i32, i32* %775, align 4
  %777 = add i32 %776, %771
  %778 = zext i32 %777 to i64
  store i64 %778, i64* %RCX, align 8, !tbaa !2428
  %779 = icmp ult i32 %777, %771
  %780 = icmp ult i32 %777, %776
  %781 = or i1 %779, %780
  %782 = zext i1 %781 to i8
  store i8 %782, i8* %14, align 1, !tbaa !2432
  %783 = and i32 %777, 255
  %784 = tail call i32 @llvm.ctpop.i32(i32 %783) #14
  %785 = trunc i32 %784 to i8
  %786 = and i8 %785, 1
  %787 = xor i8 %786, 1
  store i8 %787, i8* %21, align 1, !tbaa !2446
  %788 = xor i32 %776, %771
  %789 = xor i32 %788, %777
  %790 = lshr i32 %789, 4
  %791 = trunc i32 %790 to i8
  %792 = and i8 %791, 1
  store i8 %792, i8* %27, align 1, !tbaa !2447
  %793 = icmp eq i32 %777, 0
  %794 = zext i1 %793 to i8
  store i8 %794, i8* %30, align 1, !tbaa !2448
  %795 = lshr i32 %777, 31
  %796 = trunc i32 %795 to i8
  store i8 %796, i8* %33, align 1, !tbaa !2449
  %797 = lshr i32 %771, 31
  %798 = lshr i32 %776, 31
  %799 = xor i32 %795, %797
  %800 = xor i32 %795, %798
  %801 = add nuw nsw i32 %799, %800
  %802 = icmp eq i32 %801, 2
  %803 = zext i1 %802 to i8
  store i8 %803, i8* %39, align 1, !tbaa !2450
  %804 = add i64 %766, -36
  %805 = add i64 %768, 9
  store i64 %805, i64* %PC, align 8
  %806 = inttoptr i64 %804 to i32*
  store i32 %777, i32* %806, align 4
  %807 = load i64, i64* %RBP, align 8
  %808 = add i64 %807, -36
  %809 = load i64, i64* %PC, align 8
  %810 = add i64 %809, 3
  store i64 %810, i64* %PC, align 8
  %811 = inttoptr i64 %808 to i32*
  %812 = load i32, i32* %811, align 4
  %813 = zext i32 %812 to i64
  store i64 %813, i64* %RCX, align 8, !tbaa !2428
  %814 = add i64 %807, -44
  %815 = add i64 %809, 6
  store i64 %815, i64* %PC, align 8
  %816 = inttoptr i64 %814 to i32*
  %817 = load i32, i32* %816, align 4
  %818 = add i32 %817, %812
  %819 = zext i32 %818 to i64
  store i64 %819, i64* %RCX, align 8, !tbaa !2428
  %820 = icmp ult i32 %818, %812
  %821 = icmp ult i32 %818, %817
  %822 = or i1 %820, %821
  %823 = zext i1 %822 to i8
  store i8 %823, i8* %14, align 1, !tbaa !2432
  %824 = and i32 %818, 255
  %825 = tail call i32 @llvm.ctpop.i32(i32 %824) #14
  %826 = trunc i32 %825 to i8
  %827 = and i8 %826, 1
  %828 = xor i8 %827, 1
  store i8 %828, i8* %21, align 1, !tbaa !2446
  %829 = xor i32 %817, %812
  %830 = xor i32 %829, %818
  %831 = lshr i32 %830, 4
  %832 = trunc i32 %831 to i8
  %833 = and i8 %832, 1
  store i8 %833, i8* %27, align 1, !tbaa !2447
  %834 = icmp eq i32 %818, 0
  %835 = zext i1 %834 to i8
  store i8 %835, i8* %30, align 1, !tbaa !2448
  %836 = lshr i32 %818, 31
  %837 = trunc i32 %836 to i8
  store i8 %837, i8* %33, align 1, !tbaa !2449
  %838 = lshr i32 %812, 31
  %839 = lshr i32 %817, 31
  %840 = xor i32 %836, %838
  %841 = xor i32 %836, %839
  %842 = add nuw nsw i32 %840, %841
  %843 = icmp eq i32 %842, 2
  %844 = zext i1 %843 to i8
  store i8 %844, i8* %39, align 1, !tbaa !2450
  %845 = add i64 %807, -40
  %846 = add i64 %809, 9
  store i64 %846, i64* %PC, align 8
  %847 = inttoptr i64 %845 to i32*
  store i32 %818, i32* %847, align 4
  %848 = load i64, i64* %RBP, align 8
  %849 = add i64 %848, -16
  %850 = load i64, i64* %PC, align 8
  %851 = add i64 %850, 4
  store i64 %851, i64* %PC, align 8
  %852 = inttoptr i64 %849 to i64*
  %853 = load i64, i64* %852, align 8
  store i64 %853, i64* %RDX, align 8, !tbaa !2428
  %854 = add i64 %848, -28
  %855 = add i64 %850, 8
  store i64 %855, i64* %PC, align 8
  %856 = inttoptr i64 %854 to i32*
  %857 = load i32, i32* %856, align 4
  %858 = sext i32 %857 to i64
  store i64 %858, i64* %RSI, align 8, !tbaa !2428
  %859 = shl nsw i64 %858, 3
  %860 = add i64 %859, %853
  %861 = add i64 %850, 13
  store i64 %861, i64* %PC, align 8
  %862 = inttoptr i64 %860 to i64*
  %863 = load i64, i64* %862, align 8
  store i64 %863, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %864 = add i64 %850, 17
  store i64 %864, i64* %PC, align 8
  %865 = load i64, i64* %852, align 8
  store i64 %865, i64* %RDX, align 8, !tbaa !2428
  %866 = add i64 %848, -32
  %867 = add i64 %850, 21
  store i64 %867, i64* %PC, align 8
  %868 = inttoptr i64 %866 to i32*
  %869 = load i32, i32* %868, align 4
  %870 = sext i32 %869 to i64
  store i64 %870, i64* %RSI, align 8, !tbaa !2428
  %871 = shl nsw i64 %870, 3
  %872 = add i64 %871, %865
  %873 = add i64 %850, 26
  store i64 %873, i64* %PC, align 8
  %874 = bitcast i64 %863 to double
  %875 = inttoptr i64 %872 to double*
  %876 = load double, double* %875, align 8
  %877 = fadd double %874, %876
  store double %877, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %878 = add i64 %848, -56
  %879 = add i64 %850, 31
  store i64 %879, i64* %PC, align 8
  %880 = inttoptr i64 %878 to double*
  store double %877, double* %880, align 8
  %881 = load i64, i64* %RBP, align 8
  %882 = add i64 %881, -16
  %883 = load i64, i64* %PC, align 8
  %884 = add i64 %883, 4
  store i64 %884, i64* %PC, align 8
  %885 = inttoptr i64 %882 to i64*
  %886 = load i64, i64* %885, align 8
  store i64 %886, i64* %RDX, align 8, !tbaa !2428
  %887 = add i64 %881, -28
  %888 = add i64 %883, 7
  store i64 %888, i64* %PC, align 8
  %889 = inttoptr i64 %887 to i32*
  %890 = load i32, i32* %889, align 4
  %891 = add i32 %890, 1
  %892 = zext i32 %891 to i64
  store i64 %892, i64* %RCX, align 8, !tbaa !2428
  %893 = icmp eq i32 %890, -1
  %894 = icmp eq i32 %891, 0
  %895 = or i1 %893, %894
  %896 = zext i1 %895 to i8
  store i8 %896, i8* %14, align 1, !tbaa !2432
  %897 = and i32 %891, 255
  %898 = tail call i32 @llvm.ctpop.i32(i32 %897) #14
  %899 = trunc i32 %898 to i8
  %900 = and i8 %899, 1
  %901 = xor i8 %900, 1
  store i8 %901, i8* %21, align 1, !tbaa !2446
  %902 = xor i32 %891, %890
  %903 = lshr i32 %902, 4
  %904 = trunc i32 %903 to i8
  %905 = and i8 %904, 1
  store i8 %905, i8* %27, align 1, !tbaa !2447
  %906 = zext i1 %894 to i8
  store i8 %906, i8* %30, align 1, !tbaa !2448
  %907 = lshr i32 %891, 31
  %908 = trunc i32 %907 to i8
  store i8 %908, i8* %33, align 1, !tbaa !2449
  %909 = lshr i32 %890, 31
  %910 = xor i32 %907, %909
  %911 = add nuw nsw i32 %910, %907
  %912 = icmp eq i32 %911, 2
  %913 = zext i1 %912 to i8
  store i8 %913, i8* %39, align 1, !tbaa !2450
  %914 = sext i32 %891 to i64
  store i64 %914, i64* %RSI, align 8, !tbaa !2428
  %915 = shl nsw i64 %914, 3
  %916 = add i64 %886, %915
  %917 = add i64 %883, 18
  store i64 %917, i64* %PC, align 8
  %918 = inttoptr i64 %916 to i64*
  %919 = load i64, i64* %918, align 8
  %920 = load i64, i64* %RAX, align 8
  %921 = xor i64 %920, %919
  store i64 %921, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2432
  %922 = trunc i64 %921 to i32
  %923 = and i32 %922, 255
  %924 = tail call i32 @llvm.ctpop.i32(i32 %923) #14
  %925 = trunc i32 %924 to i8
  %926 = and i8 %925, 1
  %927 = xor i8 %926, 1
  store i8 %927, i8* %21, align 1, !tbaa !2446
  %928 = icmp eq i64 %921, 0
  %929 = zext i1 %928 to i8
  store i8 %929, i8* %30, align 1, !tbaa !2448
  %930 = lshr i64 %921, 63
  %931 = trunc i64 %930 to i8
  store i8 %931, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2447
  store i64 %921, i64* %1702, align 1, !tbaa !2428
  store i64 0, i64* %1703, align 1, !tbaa !2428
  %932 = add i64 %883, 35
  store i64 %932, i64* %PC, align 8
  %933 = load i64, i64* %885, align 8
  store i64 %933, i64* %RDX, align 8, !tbaa !2428
  %934 = add i64 %881, -32
  %935 = add i64 %883, 38
  store i64 %935, i64* %PC, align 8
  %936 = inttoptr i64 %934 to i32*
  %937 = load i32, i32* %936, align 4
  %938 = add i32 %937, 1
  %939 = zext i32 %938 to i64
  store i64 %939, i64* %RCX, align 8, !tbaa !2428
  %940 = icmp eq i32 %937, -1
  %941 = icmp eq i32 %938, 0
  %942 = or i1 %940, %941
  %943 = zext i1 %942 to i8
  store i8 %943, i8* %14, align 1, !tbaa !2432
  %944 = and i32 %938, 255
  %945 = tail call i32 @llvm.ctpop.i32(i32 %944) #14
  %946 = trunc i32 %945 to i8
  %947 = and i8 %946, 1
  %948 = xor i8 %947, 1
  store i8 %948, i8* %21, align 1, !tbaa !2446
  %949 = xor i32 %938, %937
  %950 = lshr i32 %949, 4
  %951 = trunc i32 %950 to i8
  %952 = and i8 %951, 1
  store i8 %952, i8* %27, align 1, !tbaa !2447
  %953 = zext i1 %941 to i8
  store i8 %953, i8* %30, align 1, !tbaa !2448
  %954 = lshr i32 %938, 31
  %955 = trunc i32 %954 to i8
  store i8 %955, i8* %33, align 1, !tbaa !2449
  %956 = lshr i32 %937, 31
  %957 = xor i32 %954, %956
  %958 = add nuw nsw i32 %957, %954
  %959 = icmp eq i32 %958, 2
  %960 = zext i1 %959 to i8
  store i8 %960, i8* %39, align 1, !tbaa !2450
  %961 = sext i32 %938 to i64
  store i64 %961, i64* %RSI, align 8, !tbaa !2428
  %962 = shl nsw i64 %961, 3
  %963 = add i64 %933, %962
  %964 = add i64 %883, 49
  store i64 %964, i64* %PC, align 8
  %965 = bitcast i64 %921 to double
  %966 = inttoptr i64 %963 to double*
  %967 = load double, double* %966, align 8
  %968 = fsub double %965, %967
  store double %968, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %969 = load i64, i64* %RBP, align 8
  %970 = add i64 %969, -64
  %971 = add i64 %883, 54
  store i64 %971, i64* %PC, align 8
  %972 = inttoptr i64 %970 to double*
  store double %968, double* %972, align 8
  %973 = load i64, i64* %RBP, align 8
  %974 = add i64 %973, -16
  %975 = load i64, i64* %PC, align 8
  %976 = add i64 %975, 4
  store i64 %976, i64* %PC, align 8
  %977 = inttoptr i64 %974 to i64*
  %978 = load i64, i64* %977, align 8
  store i64 %978, i64* %RDX, align 8, !tbaa !2428
  %979 = add i64 %973, -28
  %980 = add i64 %975, 8
  store i64 %980, i64* %PC, align 8
  %981 = inttoptr i64 %979 to i32*
  %982 = load i32, i32* %981, align 4
  %983 = sext i32 %982 to i64
  store i64 %983, i64* %RSI, align 8, !tbaa !2428
  %984 = shl nsw i64 %983, 3
  %985 = add i64 %984, %978
  %986 = add i64 %975, 13
  store i64 %986, i64* %PC, align 8
  %987 = inttoptr i64 %985 to i64*
  %988 = load i64, i64* %987, align 8
  store i64 %988, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %989 = add i64 %975, 17
  store i64 %989, i64* %PC, align 8
  %990 = load i64, i64* %977, align 8
  store i64 %990, i64* %RDX, align 8, !tbaa !2428
  %991 = add i64 %973, -32
  %992 = add i64 %975, 21
  store i64 %992, i64* %PC, align 8
  %993 = inttoptr i64 %991 to i32*
  %994 = load i32, i32* %993, align 4
  %995 = sext i32 %994 to i64
  store i64 %995, i64* %RSI, align 8, !tbaa !2428
  %996 = shl nsw i64 %995, 3
  %997 = add i64 %996, %990
  %998 = add i64 %975, 26
  store i64 %998, i64* %PC, align 8
  %999 = bitcast i64 %988 to double
  %1000 = inttoptr i64 %997 to double*
  %1001 = load double, double* %1000, align 8
  %1002 = fsub double %999, %1001
  store double %1002, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %1003 = add i64 %973, -72
  %1004 = add i64 %975, 31
  store i64 %1004, i64* %PC, align 8
  %1005 = inttoptr i64 %1003 to double*
  store double %1002, double* %1005, align 8
  %1006 = load i64, i64* %RBP, align 8
  %1007 = add i64 %1006, -16
  %1008 = load i64, i64* %PC, align 8
  %1009 = add i64 %1008, 4
  store i64 %1009, i64* %PC, align 8
  %1010 = inttoptr i64 %1007 to i64*
  %1011 = load i64, i64* %1010, align 8
  store i64 %1011, i64* %RDX, align 8, !tbaa !2428
  %1012 = add i64 %1006, -28
  %1013 = add i64 %1008, 7
  store i64 %1013, i64* %PC, align 8
  %1014 = inttoptr i64 %1012 to i32*
  %1015 = load i32, i32* %1014, align 4
  %1016 = add i32 %1015, 1
  %1017 = zext i32 %1016 to i64
  store i64 %1017, i64* %RCX, align 8, !tbaa !2428
  %1018 = icmp eq i32 %1015, -1
  %1019 = icmp eq i32 %1016, 0
  %1020 = or i1 %1018, %1019
  %1021 = zext i1 %1020 to i8
  store i8 %1021, i8* %14, align 1, !tbaa !2432
  %1022 = and i32 %1016, 255
  %1023 = tail call i32 @llvm.ctpop.i32(i32 %1022) #14
  %1024 = trunc i32 %1023 to i8
  %1025 = and i8 %1024, 1
  %1026 = xor i8 %1025, 1
  store i8 %1026, i8* %21, align 1, !tbaa !2446
  %1027 = xor i32 %1016, %1015
  %1028 = lshr i32 %1027, 4
  %1029 = trunc i32 %1028 to i8
  %1030 = and i8 %1029, 1
  store i8 %1030, i8* %27, align 1, !tbaa !2447
  %1031 = zext i1 %1019 to i8
  store i8 %1031, i8* %30, align 1, !tbaa !2448
  %1032 = lshr i32 %1016, 31
  %1033 = trunc i32 %1032 to i8
  store i8 %1033, i8* %33, align 1, !tbaa !2449
  %1034 = lshr i32 %1015, 31
  %1035 = xor i32 %1032, %1034
  %1036 = add nuw nsw i32 %1035, %1032
  %1037 = icmp eq i32 %1036, 2
  %1038 = zext i1 %1037 to i8
  store i8 %1038, i8* %39, align 1, !tbaa !2450
  %1039 = sext i32 %1016 to i64
  store i64 %1039, i64* %RSI, align 8, !tbaa !2428
  %1040 = shl nsw i64 %1039, 3
  %1041 = add i64 %1011, %1040
  %1042 = add i64 %1008, 18
  store i64 %1042, i64* %PC, align 8
  %1043 = inttoptr i64 %1041 to i64*
  %1044 = load i64, i64* %1043, align 8
  %1045 = load i64, i64* %RAX, align 8
  %1046 = xor i64 %1045, %1044
  store i64 %1046, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2432
  %1047 = trunc i64 %1046 to i32
  %1048 = and i32 %1047, 255
  %1049 = tail call i32 @llvm.ctpop.i32(i32 %1048) #14
  %1050 = trunc i32 %1049 to i8
  %1051 = and i8 %1050, 1
  %1052 = xor i8 %1051, 1
  store i8 %1052, i8* %21, align 1, !tbaa !2446
  %1053 = icmp eq i64 %1046, 0
  %1054 = zext i1 %1053 to i8
  store i8 %1054, i8* %30, align 1, !tbaa !2448
  %1055 = lshr i64 %1046, 63
  %1056 = trunc i64 %1055 to i8
  store i8 %1056, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2447
  store i64 %1046, i64* %1702, align 1, !tbaa !2428
  store i64 0, i64* %1703, align 1, !tbaa !2428
  %1057 = add i64 %1008, 35
  store i64 %1057, i64* %PC, align 8
  %1058 = load i64, i64* %1010, align 8
  store i64 %1058, i64* %RAX, align 8, !tbaa !2428
  %1059 = add i64 %1006, -32
  %1060 = add i64 %1008, 38
  store i64 %1060, i64* %PC, align 8
  %1061 = inttoptr i64 %1059 to i32*
  %1062 = load i32, i32* %1061, align 4
  %1063 = add i32 %1062, 1
  %1064 = zext i32 %1063 to i64
  store i64 %1064, i64* %RCX, align 8, !tbaa !2428
  %1065 = icmp eq i32 %1062, -1
  %1066 = icmp eq i32 %1063, 0
  %1067 = or i1 %1065, %1066
  %1068 = zext i1 %1067 to i8
  store i8 %1068, i8* %14, align 1, !tbaa !2432
  %1069 = and i32 %1063, 255
  %1070 = tail call i32 @llvm.ctpop.i32(i32 %1069) #14
  %1071 = trunc i32 %1070 to i8
  %1072 = and i8 %1071, 1
  %1073 = xor i8 %1072, 1
  store i8 %1073, i8* %21, align 1, !tbaa !2446
  %1074 = xor i32 %1063, %1062
  %1075 = lshr i32 %1074, 4
  %1076 = trunc i32 %1075 to i8
  %1077 = and i8 %1076, 1
  store i8 %1077, i8* %27, align 1, !tbaa !2447
  %1078 = zext i1 %1066 to i8
  store i8 %1078, i8* %30, align 1, !tbaa !2448
  %1079 = lshr i32 %1063, 31
  %1080 = trunc i32 %1079 to i8
  store i8 %1080, i8* %33, align 1, !tbaa !2449
  %1081 = lshr i32 %1062, 31
  %1082 = xor i32 %1079, %1081
  %1083 = add nuw nsw i32 %1082, %1079
  %1084 = icmp eq i32 %1083, 2
  %1085 = zext i1 %1084 to i8
  store i8 %1085, i8* %39, align 1, !tbaa !2450
  %1086 = sext i32 %1063 to i64
  store i64 %1086, i64* %RDX, align 8, !tbaa !2428
  %1087 = shl nsw i64 %1086, 3
  %1088 = add i64 %1058, %1087
  %1089 = add i64 %1008, 49
  store i64 %1089, i64* %PC, align 8
  %1090 = bitcast i64 %1046 to double
  %1091 = inttoptr i64 %1088 to double*
  %1092 = load double, double* %1091, align 8
  %1093 = fadd double %1090, %1092
  store double %1093, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %1094 = load i64, i64* %RBP, align 8
  %1095 = add i64 %1094, -80
  %1096 = add i64 %1008, 54
  store i64 %1096, i64* %PC, align 8
  %1097 = inttoptr i64 %1095 to double*
  store double %1093, double* %1097, align 8
  %1098 = load i64, i64* %RBP, align 8
  %1099 = add i64 %1098, -16
  %1100 = load i64, i64* %PC, align 8
  %1101 = add i64 %1100, 4
  store i64 %1101, i64* %PC, align 8
  %1102 = inttoptr i64 %1099 to i64*
  %1103 = load i64, i64* %1102, align 8
  store i64 %1103, i64* %RAX, align 8, !tbaa !2428
  %1104 = add i64 %1098, -36
  %1105 = add i64 %1100, 8
  store i64 %1105, i64* %PC, align 8
  %1106 = inttoptr i64 %1104 to i32*
  %1107 = load i32, i32* %1106, align 4
  %1108 = sext i32 %1107 to i64
  store i64 %1108, i64* %RDX, align 8, !tbaa !2428
  %1109 = shl nsw i64 %1108, 3
  %1110 = add i64 %1109, %1103
  %1111 = add i64 %1100, 13
  store i64 %1111, i64* %PC, align 8
  %1112 = inttoptr i64 %1110 to i64*
  %1113 = load i64, i64* %1112, align 8
  store i64 %1113, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %1114 = add i64 %1100, 17
  store i64 %1114, i64* %PC, align 8
  %1115 = load i64, i64* %1102, align 8
  store i64 %1115, i64* %RAX, align 8, !tbaa !2428
  %1116 = add i64 %1098, -40
  %1117 = add i64 %1100, 21
  store i64 %1117, i64* %PC, align 8
  %1118 = inttoptr i64 %1116 to i32*
  %1119 = load i32, i32* %1118, align 4
  %1120 = sext i32 %1119 to i64
  store i64 %1120, i64* %RDX, align 8, !tbaa !2428
  %1121 = shl nsw i64 %1120, 3
  %1122 = add i64 %1121, %1115
  %1123 = add i64 %1100, 26
  store i64 %1123, i64* %PC, align 8
  %1124 = bitcast i64 %1113 to double
  %1125 = inttoptr i64 %1122 to double*
  %1126 = load double, double* %1125, align 8
  %1127 = fadd double %1124, %1126
  store double %1127, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %1128 = add i64 %1098, -88
  %1129 = add i64 %1100, 31
  store i64 %1129, i64* %PC, align 8
  %1130 = inttoptr i64 %1128 to double*
  store double %1127, double* %1130, align 8
  %1131 = load i64, i64* %RBP, align 8
  %1132 = add i64 %1131, -16
  %1133 = load i64, i64* %PC, align 8
  %1134 = add i64 %1133, 4
  store i64 %1134, i64* %PC, align 8
  %1135 = inttoptr i64 %1132 to i64*
  %1136 = load i64, i64* %1135, align 8
  store i64 %1136, i64* %RAX, align 8, !tbaa !2428
  %1137 = add i64 %1131, -36
  %1138 = add i64 %1133, 7
  store i64 %1138, i64* %PC, align 8
  %1139 = inttoptr i64 %1137 to i32*
  %1140 = load i32, i32* %1139, align 4
  %1141 = add i32 %1140, 1
  %1142 = zext i32 %1141 to i64
  store i64 %1142, i64* %RCX, align 8, !tbaa !2428
  %1143 = icmp eq i32 %1140, -1
  %1144 = icmp eq i32 %1141, 0
  %1145 = or i1 %1143, %1144
  %1146 = zext i1 %1145 to i8
  store i8 %1146, i8* %14, align 1, !tbaa !2432
  %1147 = and i32 %1141, 255
  %1148 = tail call i32 @llvm.ctpop.i32(i32 %1147) #14
  %1149 = trunc i32 %1148 to i8
  %1150 = and i8 %1149, 1
  %1151 = xor i8 %1150, 1
  store i8 %1151, i8* %21, align 1, !tbaa !2446
  %1152 = xor i32 %1141, %1140
  %1153 = lshr i32 %1152, 4
  %1154 = trunc i32 %1153 to i8
  %1155 = and i8 %1154, 1
  store i8 %1155, i8* %27, align 1, !tbaa !2447
  %1156 = zext i1 %1144 to i8
  store i8 %1156, i8* %30, align 1, !tbaa !2448
  %1157 = lshr i32 %1141, 31
  %1158 = trunc i32 %1157 to i8
  store i8 %1158, i8* %33, align 1, !tbaa !2449
  %1159 = lshr i32 %1140, 31
  %1160 = xor i32 %1157, %1159
  %1161 = add nuw nsw i32 %1160, %1157
  %1162 = icmp eq i32 %1161, 2
  %1163 = zext i1 %1162 to i8
  store i8 %1163, i8* %39, align 1, !tbaa !2450
  %1164 = sext i32 %1141 to i64
  store i64 %1164, i64* %RDX, align 8, !tbaa !2428
  %1165 = shl nsw i64 %1164, 3
  %1166 = add i64 %1136, %1165
  %1167 = add i64 %1133, 18
  store i64 %1167, i64* %PC, align 8
  %1168 = inttoptr i64 %1166 to i64*
  %1169 = load i64, i64* %1168, align 8
  store i64 %1169, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %1170 = add i64 %1133, 22
  store i64 %1170, i64* %PC, align 8
  %1171 = load i64, i64* %1135, align 8
  store i64 %1171, i64* %RAX, align 8, !tbaa !2428
  %1172 = add i64 %1131, -40
  %1173 = add i64 %1133, 25
  store i64 %1173, i64* %PC, align 8
  %1174 = inttoptr i64 %1172 to i32*
  %1175 = load i32, i32* %1174, align 4
  %1176 = add i32 %1175, 1
  %1177 = zext i32 %1176 to i64
  store i64 %1177, i64* %RCX, align 8, !tbaa !2428
  %1178 = icmp eq i32 %1175, -1
  %1179 = icmp eq i32 %1176, 0
  %1180 = or i1 %1178, %1179
  %1181 = zext i1 %1180 to i8
  store i8 %1181, i8* %14, align 1, !tbaa !2432
  %1182 = and i32 %1176, 255
  %1183 = tail call i32 @llvm.ctpop.i32(i32 %1182) #14
  %1184 = trunc i32 %1183 to i8
  %1185 = and i8 %1184, 1
  %1186 = xor i8 %1185, 1
  store i8 %1186, i8* %21, align 1, !tbaa !2446
  %1187 = xor i32 %1176, %1175
  %1188 = lshr i32 %1187, 4
  %1189 = trunc i32 %1188 to i8
  %1190 = and i8 %1189, 1
  store i8 %1190, i8* %27, align 1, !tbaa !2447
  %1191 = zext i1 %1179 to i8
  store i8 %1191, i8* %30, align 1, !tbaa !2448
  %1192 = lshr i32 %1176, 31
  %1193 = trunc i32 %1192 to i8
  store i8 %1193, i8* %33, align 1, !tbaa !2449
  %1194 = lshr i32 %1175, 31
  %1195 = xor i32 %1192, %1194
  %1196 = add nuw nsw i32 %1195, %1192
  %1197 = icmp eq i32 %1196, 2
  %1198 = zext i1 %1197 to i8
  store i8 %1198, i8* %39, align 1, !tbaa !2450
  %1199 = sext i32 %1176 to i64
  store i64 %1199, i64* %RDX, align 8, !tbaa !2428
  %1200 = shl nsw i64 %1199, 3
  %1201 = add i64 %1171, %1200
  %1202 = add i64 %1133, 36
  store i64 %1202, i64* %PC, align 8
  %1203 = bitcast i64 %1169 to double
  %1204 = inttoptr i64 %1201 to double*
  %1205 = load double, double* %1204, align 8
  %1206 = fadd double %1203, %1205
  store double %1206, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %1207 = load i64, i64* %RBP, align 8
  %1208 = add i64 %1207, -96
  %1209 = add i64 %1133, 41
  store i64 %1209, i64* %PC, align 8
  %1210 = inttoptr i64 %1208 to double*
  store double %1206, double* %1210, align 8
  %1211 = load i64, i64* %RBP, align 8
  %1212 = add i64 %1211, -16
  %1213 = load i64, i64* %PC, align 8
  %1214 = add i64 %1213, 4
  store i64 %1214, i64* %PC, align 8
  %1215 = inttoptr i64 %1212 to i64*
  %1216 = load i64, i64* %1215, align 8
  store i64 %1216, i64* %RAX, align 8, !tbaa !2428
  %1217 = add i64 %1211, -36
  %1218 = add i64 %1213, 8
  store i64 %1218, i64* %PC, align 8
  %1219 = inttoptr i64 %1217 to i32*
  %1220 = load i32, i32* %1219, align 4
  %1221 = sext i32 %1220 to i64
  store i64 %1221, i64* %RDX, align 8, !tbaa !2428
  %1222 = shl nsw i64 %1221, 3
  %1223 = add i64 %1222, %1216
  %1224 = add i64 %1213, 13
  store i64 %1224, i64* %PC, align 8
  %1225 = inttoptr i64 %1223 to i64*
  %1226 = load i64, i64* %1225, align 8
  store i64 %1226, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %1227 = add i64 %1213, 17
  store i64 %1227, i64* %PC, align 8
  %1228 = load i64, i64* %1215, align 8
  store i64 %1228, i64* %RAX, align 8, !tbaa !2428
  %1229 = add i64 %1211, -40
  %1230 = add i64 %1213, 21
  store i64 %1230, i64* %PC, align 8
  %1231 = inttoptr i64 %1229 to i32*
  %1232 = load i32, i32* %1231, align 4
  %1233 = sext i32 %1232 to i64
  store i64 %1233, i64* %RDX, align 8, !tbaa !2428
  %1234 = shl nsw i64 %1233, 3
  %1235 = add i64 %1234, %1228
  %1236 = add i64 %1213, 26
  store i64 %1236, i64* %PC, align 8
  %1237 = bitcast i64 %1226 to double
  %1238 = inttoptr i64 %1235 to double*
  %1239 = load double, double* %1238, align 8
  %1240 = fsub double %1237, %1239
  store double %1240, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %1241 = add i64 %1211, -104
  %1242 = add i64 %1213, 31
  store i64 %1242, i64* %PC, align 8
  %1243 = inttoptr i64 %1241 to double*
  store double %1240, double* %1243, align 8
  %1244 = load i64, i64* %RBP, align 8
  %1245 = add i64 %1244, -16
  %1246 = load i64, i64* %PC, align 8
  %1247 = add i64 %1246, 4
  store i64 %1247, i64* %PC, align 8
  %1248 = inttoptr i64 %1245 to i64*
  %1249 = load i64, i64* %1248, align 8
  store i64 %1249, i64* %RAX, align 8, !tbaa !2428
  %1250 = add i64 %1244, -36
  %1251 = add i64 %1246, 7
  store i64 %1251, i64* %PC, align 8
  %1252 = inttoptr i64 %1250 to i32*
  %1253 = load i32, i32* %1252, align 4
  %1254 = add i32 %1253, 1
  %1255 = zext i32 %1254 to i64
  store i64 %1255, i64* %RCX, align 8, !tbaa !2428
  %1256 = icmp eq i32 %1253, -1
  %1257 = icmp eq i32 %1254, 0
  %1258 = or i1 %1256, %1257
  %1259 = zext i1 %1258 to i8
  store i8 %1259, i8* %14, align 1, !tbaa !2432
  %1260 = and i32 %1254, 255
  %1261 = tail call i32 @llvm.ctpop.i32(i32 %1260) #14
  %1262 = trunc i32 %1261 to i8
  %1263 = and i8 %1262, 1
  %1264 = xor i8 %1263, 1
  store i8 %1264, i8* %21, align 1, !tbaa !2446
  %1265 = xor i32 %1254, %1253
  %1266 = lshr i32 %1265, 4
  %1267 = trunc i32 %1266 to i8
  %1268 = and i8 %1267, 1
  store i8 %1268, i8* %27, align 1, !tbaa !2447
  %1269 = zext i1 %1257 to i8
  store i8 %1269, i8* %30, align 1, !tbaa !2448
  %1270 = lshr i32 %1254, 31
  %1271 = trunc i32 %1270 to i8
  store i8 %1271, i8* %33, align 1, !tbaa !2449
  %1272 = lshr i32 %1253, 31
  %1273 = xor i32 %1270, %1272
  %1274 = add nuw nsw i32 %1273, %1270
  %1275 = icmp eq i32 %1274, 2
  %1276 = zext i1 %1275 to i8
  store i8 %1276, i8* %39, align 1, !tbaa !2450
  %1277 = sext i32 %1254 to i64
  store i64 %1277, i64* %RDX, align 8, !tbaa !2428
  %1278 = shl nsw i64 %1277, 3
  %1279 = add i64 %1249, %1278
  %1280 = add i64 %1246, 18
  store i64 %1280, i64* %PC, align 8
  %1281 = inttoptr i64 %1279 to i64*
  %1282 = load i64, i64* %1281, align 8
  store i64 %1282, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %1283 = add i64 %1246, 22
  store i64 %1283, i64* %PC, align 8
  %1284 = load i64, i64* %1248, align 8
  store i64 %1284, i64* %RAX, align 8, !tbaa !2428
  %1285 = add i64 %1244, -40
  %1286 = add i64 %1246, 25
  store i64 %1286, i64* %PC, align 8
  %1287 = inttoptr i64 %1285 to i32*
  %1288 = load i32, i32* %1287, align 4
  %1289 = add i32 %1288, 1
  %1290 = zext i32 %1289 to i64
  store i64 %1290, i64* %RCX, align 8, !tbaa !2428
  %1291 = icmp eq i32 %1288, -1
  %1292 = icmp eq i32 %1289, 0
  %1293 = or i1 %1291, %1292
  %1294 = zext i1 %1293 to i8
  store i8 %1294, i8* %14, align 1, !tbaa !2432
  %1295 = and i32 %1289, 255
  %1296 = tail call i32 @llvm.ctpop.i32(i32 %1295) #14
  %1297 = trunc i32 %1296 to i8
  %1298 = and i8 %1297, 1
  %1299 = xor i8 %1298, 1
  store i8 %1299, i8* %21, align 1, !tbaa !2446
  %1300 = xor i32 %1289, %1288
  %1301 = lshr i32 %1300, 4
  %1302 = trunc i32 %1301 to i8
  %1303 = and i8 %1302, 1
  store i8 %1303, i8* %27, align 1, !tbaa !2447
  %1304 = zext i1 %1292 to i8
  store i8 %1304, i8* %30, align 1, !tbaa !2448
  %1305 = lshr i32 %1289, 31
  %1306 = trunc i32 %1305 to i8
  store i8 %1306, i8* %33, align 1, !tbaa !2449
  %1307 = lshr i32 %1288, 31
  %1308 = xor i32 %1305, %1307
  %1309 = add nuw nsw i32 %1308, %1305
  %1310 = icmp eq i32 %1309, 2
  %1311 = zext i1 %1310 to i8
  store i8 %1311, i8* %39, align 1, !tbaa !2450
  %1312 = sext i32 %1289 to i64
  store i64 %1312, i64* %RDX, align 8, !tbaa !2428
  %1313 = shl nsw i64 %1312, 3
  %1314 = add i64 %1284, %1313
  %1315 = add i64 %1246, 36
  store i64 %1315, i64* %PC, align 8
  %1316 = bitcast i64 %1282 to double
  %1317 = inttoptr i64 %1314 to double*
  %1318 = load double, double* %1317, align 8
  %1319 = fsub double %1316, %1318
  store double %1319, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %1320 = load i64, i64* %RBP, align 8
  %1321 = add i64 %1320, -112
  %1322 = add i64 %1246, 41
  store i64 %1322, i64* %PC, align 8
  %1323 = inttoptr i64 %1321 to double*
  store double %1319, double* %1323, align 8
  %1324 = load i64, i64* %RBP, align 8
  %1325 = add i64 %1324, -56
  %1326 = load i64, i64* %PC, align 8
  %1327 = add i64 %1326, 5
  store i64 %1327, i64* %PC, align 8
  %1328 = inttoptr i64 %1325 to i64*
  %1329 = load i64, i64* %1328, align 8
  store i64 %1329, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %1330 = add i64 %1324, -88
  %1331 = add i64 %1326, 10
  store i64 %1331, i64* %PC, align 8
  %1332 = bitcast i64 %1329 to double
  %1333 = inttoptr i64 %1330 to double*
  %1334 = load double, double* %1333, align 8
  %1335 = fadd double %1332, %1334
  store double %1335, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %1336 = add i64 %1324, -16
  %1337 = add i64 %1326, 14
  store i64 %1337, i64* %PC, align 8
  %1338 = inttoptr i64 %1336 to i64*
  %1339 = load i64, i64* %1338, align 8
  store i64 %1339, i64* %RAX, align 8, !tbaa !2428
  %1340 = add i64 %1324, -28
  %1341 = add i64 %1326, 18
  store i64 %1341, i64* %PC, align 8
  %1342 = inttoptr i64 %1340 to i32*
  %1343 = load i32, i32* %1342, align 4
  %1344 = sext i32 %1343 to i64
  store i64 %1344, i64* %RDX, align 8, !tbaa !2428
  %1345 = shl nsw i64 %1344, 3
  %1346 = add i64 %1345, %1339
  %1347 = add i64 %1326, 23
  store i64 %1347, i64* %PC, align 8
  %1348 = inttoptr i64 %1346 to double*
  store double %1335, double* %1348, align 8
  %1349 = load i64, i64* %RBP, align 8
  %1350 = add i64 %1349, -64
  %1351 = load i64, i64* %PC, align 8
  %1352 = add i64 %1351, 5
  store i64 %1352, i64* %PC, align 8
  %1353 = inttoptr i64 %1350 to i64*
  %1354 = load i64, i64* %1353, align 8
  store i64 %1354, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %1355 = add i64 %1349, -96
  %1356 = add i64 %1351, 10
  store i64 %1356, i64* %PC, align 8
  %1357 = bitcast i64 %1354 to double
  %1358 = inttoptr i64 %1355 to double*
  %1359 = load double, double* %1358, align 8
  %1360 = fsub double %1357, %1359
  store double %1360, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %1361 = add i64 %1349, -16
  %1362 = add i64 %1351, 14
  store i64 %1362, i64* %PC, align 8
  %1363 = inttoptr i64 %1361 to i64*
  %1364 = load i64, i64* %1363, align 8
  store i64 %1364, i64* %RAX, align 8, !tbaa !2428
  %1365 = add i64 %1349, -28
  %1366 = add i64 %1351, 17
  store i64 %1366, i64* %PC, align 8
  %1367 = inttoptr i64 %1365 to i32*
  %1368 = load i32, i32* %1367, align 4
  %1369 = add i32 %1368, 1
  %1370 = zext i32 %1369 to i64
  store i64 %1370, i64* %RCX, align 8, !tbaa !2428
  %1371 = icmp eq i32 %1368, -1
  %1372 = icmp eq i32 %1369, 0
  %1373 = or i1 %1371, %1372
  %1374 = zext i1 %1373 to i8
  store i8 %1374, i8* %14, align 1, !tbaa !2432
  %1375 = and i32 %1369, 255
  %1376 = tail call i32 @llvm.ctpop.i32(i32 %1375) #14
  %1377 = trunc i32 %1376 to i8
  %1378 = and i8 %1377, 1
  %1379 = xor i8 %1378, 1
  store i8 %1379, i8* %21, align 1, !tbaa !2446
  %1380 = xor i32 %1369, %1368
  %1381 = lshr i32 %1380, 4
  %1382 = trunc i32 %1381 to i8
  %1383 = and i8 %1382, 1
  store i8 %1383, i8* %27, align 1, !tbaa !2447
  %1384 = zext i1 %1372 to i8
  store i8 %1384, i8* %30, align 1, !tbaa !2448
  %1385 = lshr i32 %1369, 31
  %1386 = trunc i32 %1385 to i8
  store i8 %1386, i8* %33, align 1, !tbaa !2449
  %1387 = lshr i32 %1368, 31
  %1388 = xor i32 %1385, %1387
  %1389 = add nuw nsw i32 %1388, %1385
  %1390 = icmp eq i32 %1389, 2
  %1391 = zext i1 %1390 to i8
  store i8 %1391, i8* %39, align 1, !tbaa !2450
  %1392 = sext i32 %1369 to i64
  store i64 %1392, i64* %RDX, align 8, !tbaa !2428
  %1393 = shl nsw i64 %1392, 3
  %1394 = add i64 %1364, %1393
  %1395 = add i64 %1351, 28
  store i64 %1395, i64* %PC, align 8
  %1396 = inttoptr i64 %1394 to double*
  store double %1360, double* %1396, align 8
  %1397 = load i64, i64* %RBP, align 8
  %1398 = add i64 %1397, -56
  %1399 = load i64, i64* %PC, align 8
  %1400 = add i64 %1399, 5
  store i64 %1400, i64* %PC, align 8
  %1401 = inttoptr i64 %1398 to i64*
  %1402 = load i64, i64* %1401, align 8
  store i64 %1402, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %1403 = add i64 %1397, -88
  %1404 = add i64 %1399, 10
  store i64 %1404, i64* %PC, align 8
  %1405 = bitcast i64 %1402 to double
  %1406 = inttoptr i64 %1403 to double*
  %1407 = load double, double* %1406, align 8
  %1408 = fsub double %1405, %1407
  store double %1408, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %1409 = add i64 %1397, -16
  %1410 = add i64 %1399, 14
  store i64 %1410, i64* %PC, align 8
  %1411 = inttoptr i64 %1409 to i64*
  %1412 = load i64, i64* %1411, align 8
  store i64 %1412, i64* %RAX, align 8, !tbaa !2428
  %1413 = add i64 %1397, -36
  %1414 = add i64 %1399, 18
  store i64 %1414, i64* %PC, align 8
  %1415 = inttoptr i64 %1413 to i32*
  %1416 = load i32, i32* %1415, align 4
  %1417 = sext i32 %1416 to i64
  store i64 %1417, i64* %RDX, align 8, !tbaa !2428
  %1418 = shl nsw i64 %1417, 3
  %1419 = add i64 %1418, %1412
  %1420 = add i64 %1399, 23
  store i64 %1420, i64* %PC, align 8
  %1421 = inttoptr i64 %1419 to double*
  store double %1408, double* %1421, align 8
  %1422 = load i64, i64* %RBP, align 8
  %1423 = add i64 %1422, -64
  %1424 = load i64, i64* %PC, align 8
  %1425 = add i64 %1424, 5
  store i64 %1425, i64* %PC, align 8
  %1426 = inttoptr i64 %1423 to i64*
  %1427 = load i64, i64* %1426, align 8
  store i64 %1427, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %1428 = add i64 %1422, -96
  %1429 = add i64 %1424, 10
  store i64 %1429, i64* %PC, align 8
  %1430 = bitcast i64 %1427 to double
  %1431 = inttoptr i64 %1428 to double*
  %1432 = load double, double* %1431, align 8
  %1433 = fadd double %1430, %1432
  store double %1433, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %1434 = add i64 %1422, -16
  %1435 = add i64 %1424, 14
  store i64 %1435, i64* %PC, align 8
  %1436 = inttoptr i64 %1434 to i64*
  %1437 = load i64, i64* %1436, align 8
  store i64 %1437, i64* %RAX, align 8, !tbaa !2428
  %1438 = add i64 %1422, -36
  %1439 = add i64 %1424, 17
  store i64 %1439, i64* %PC, align 8
  %1440 = inttoptr i64 %1438 to i32*
  %1441 = load i32, i32* %1440, align 4
  %1442 = add i32 %1441, 1
  %1443 = zext i32 %1442 to i64
  store i64 %1443, i64* %RCX, align 8, !tbaa !2428
  %1444 = icmp eq i32 %1441, -1
  %1445 = icmp eq i32 %1442, 0
  %1446 = or i1 %1444, %1445
  %1447 = zext i1 %1446 to i8
  store i8 %1447, i8* %14, align 1, !tbaa !2432
  %1448 = and i32 %1442, 255
  %1449 = tail call i32 @llvm.ctpop.i32(i32 %1448) #14
  %1450 = trunc i32 %1449 to i8
  %1451 = and i8 %1450, 1
  %1452 = xor i8 %1451, 1
  store i8 %1452, i8* %21, align 1, !tbaa !2446
  %1453 = xor i32 %1442, %1441
  %1454 = lshr i32 %1453, 4
  %1455 = trunc i32 %1454 to i8
  %1456 = and i8 %1455, 1
  store i8 %1456, i8* %27, align 1, !tbaa !2447
  %1457 = zext i1 %1445 to i8
  store i8 %1457, i8* %30, align 1, !tbaa !2448
  %1458 = lshr i32 %1442, 31
  %1459 = trunc i32 %1458 to i8
  store i8 %1459, i8* %33, align 1, !tbaa !2449
  %1460 = lshr i32 %1441, 31
  %1461 = xor i32 %1458, %1460
  %1462 = add nuw nsw i32 %1461, %1458
  %1463 = icmp eq i32 %1462, 2
  %1464 = zext i1 %1463 to i8
  store i8 %1464, i8* %39, align 1, !tbaa !2450
  %1465 = sext i32 %1442 to i64
  store i64 %1465, i64* %RDX, align 8, !tbaa !2428
  %1466 = shl nsw i64 %1465, 3
  %1467 = add i64 %1437, %1466
  %1468 = add i64 %1424, 28
  store i64 %1468, i64* %PC, align 8
  %1469 = inttoptr i64 %1467 to double*
  store double %1433, double* %1469, align 8
  %1470 = load i64, i64* %RBP, align 8
  %1471 = add i64 %1470, -72
  %1472 = load i64, i64* %PC, align 8
  %1473 = add i64 %1472, 5
  store i64 %1473, i64* %PC, align 8
  %1474 = inttoptr i64 %1471 to i64*
  %1475 = load i64, i64* %1474, align 8
  store i64 %1475, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %1476 = add i64 %1470, -112
  %1477 = add i64 %1472, 10
  store i64 %1477, i64* %PC, align 8
  %1478 = bitcast i64 %1475 to double
  %1479 = inttoptr i64 %1476 to double*
  %1480 = load double, double* %1479, align 8
  %1481 = fsub double %1478, %1480
  store double %1481, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %1482 = add i64 %1470, -16
  %1483 = add i64 %1472, 14
  store i64 %1483, i64* %PC, align 8
  %1484 = inttoptr i64 %1482 to i64*
  %1485 = load i64, i64* %1484, align 8
  store i64 %1485, i64* %RAX, align 8, !tbaa !2428
  %1486 = add i64 %1470, -32
  %1487 = add i64 %1472, 18
  store i64 %1487, i64* %PC, align 8
  %1488 = inttoptr i64 %1486 to i32*
  %1489 = load i32, i32* %1488, align 4
  %1490 = sext i32 %1489 to i64
  store i64 %1490, i64* %RDX, align 8, !tbaa !2428
  %1491 = shl nsw i64 %1490, 3
  %1492 = add i64 %1491, %1485
  %1493 = add i64 %1472, 23
  store i64 %1493, i64* %PC, align 8
  %1494 = inttoptr i64 %1492 to double*
  store double %1481, double* %1494, align 8
  %1495 = load i64, i64* %RBP, align 8
  %1496 = add i64 %1495, -80
  %1497 = load i64, i64* %PC, align 8
  %1498 = add i64 %1497, 5
  store i64 %1498, i64* %PC, align 8
  %1499 = inttoptr i64 %1496 to i64*
  %1500 = load i64, i64* %1499, align 8
  store i64 %1500, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %1501 = add i64 %1495, -104
  %1502 = add i64 %1497, 10
  store i64 %1502, i64* %PC, align 8
  %1503 = bitcast i64 %1500 to double
  %1504 = inttoptr i64 %1501 to double*
  %1505 = load double, double* %1504, align 8
  %1506 = fsub double %1503, %1505
  store double %1506, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %1507 = add i64 %1495, -16
  %1508 = add i64 %1497, 14
  store i64 %1508, i64* %PC, align 8
  %1509 = inttoptr i64 %1507 to i64*
  %1510 = load i64, i64* %1509, align 8
  store i64 %1510, i64* %RAX, align 8, !tbaa !2428
  %1511 = add i64 %1495, -32
  %1512 = add i64 %1497, 17
  store i64 %1512, i64* %PC, align 8
  %1513 = inttoptr i64 %1511 to i32*
  %1514 = load i32, i32* %1513, align 4
  %1515 = add i32 %1514, 1
  %1516 = zext i32 %1515 to i64
  store i64 %1516, i64* %RCX, align 8, !tbaa !2428
  %1517 = icmp eq i32 %1514, -1
  %1518 = icmp eq i32 %1515, 0
  %1519 = or i1 %1517, %1518
  %1520 = zext i1 %1519 to i8
  store i8 %1520, i8* %14, align 1, !tbaa !2432
  %1521 = and i32 %1515, 255
  %1522 = tail call i32 @llvm.ctpop.i32(i32 %1521) #14
  %1523 = trunc i32 %1522 to i8
  %1524 = and i8 %1523, 1
  %1525 = xor i8 %1524, 1
  store i8 %1525, i8* %21, align 1, !tbaa !2446
  %1526 = xor i32 %1515, %1514
  %1527 = lshr i32 %1526, 4
  %1528 = trunc i32 %1527 to i8
  %1529 = and i8 %1528, 1
  store i8 %1529, i8* %27, align 1, !tbaa !2447
  %1530 = zext i1 %1518 to i8
  store i8 %1530, i8* %30, align 1, !tbaa !2448
  %1531 = lshr i32 %1515, 31
  %1532 = trunc i32 %1531 to i8
  store i8 %1532, i8* %33, align 1, !tbaa !2449
  %1533 = lshr i32 %1514, 31
  %1534 = xor i32 %1531, %1533
  %1535 = add nuw nsw i32 %1534, %1531
  %1536 = icmp eq i32 %1535, 2
  %1537 = zext i1 %1536 to i8
  store i8 %1537, i8* %39, align 1, !tbaa !2450
  %1538 = sext i32 %1515 to i64
  store i64 %1538, i64* %RDX, align 8, !tbaa !2428
  %1539 = shl nsw i64 %1538, 3
  %1540 = add i64 %1510, %1539
  %1541 = add i64 %1497, 28
  store i64 %1541, i64* %PC, align 8
  %1542 = inttoptr i64 %1540 to double*
  store double %1506, double* %1542, align 8
  %1543 = load i64, i64* %RBP, align 8
  %1544 = add i64 %1543, -72
  %1545 = load i64, i64* %PC, align 8
  %1546 = add i64 %1545, 5
  store i64 %1546, i64* %PC, align 8
  %1547 = inttoptr i64 %1544 to i64*
  %1548 = load i64, i64* %1547, align 8
  store i64 %1548, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %1549 = add i64 %1543, -112
  %1550 = add i64 %1545, 10
  store i64 %1550, i64* %PC, align 8
  %1551 = bitcast i64 %1548 to double
  %1552 = inttoptr i64 %1549 to double*
  %1553 = load double, double* %1552, align 8
  %1554 = fadd double %1551, %1553
  store double %1554, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %1555 = add i64 %1543, -16
  %1556 = add i64 %1545, 14
  store i64 %1556, i64* %PC, align 8
  %1557 = inttoptr i64 %1555 to i64*
  %1558 = load i64, i64* %1557, align 8
  store i64 %1558, i64* %RAX, align 8, !tbaa !2428
  %1559 = add i64 %1543, -40
  %1560 = add i64 %1545, 18
  store i64 %1560, i64* %PC, align 8
  %1561 = inttoptr i64 %1559 to i32*
  %1562 = load i32, i32* %1561, align 4
  %1563 = sext i32 %1562 to i64
  store i64 %1563, i64* %RDX, align 8, !tbaa !2428
  %1564 = shl nsw i64 %1563, 3
  %1565 = add i64 %1564, %1558
  %1566 = add i64 %1545, 23
  store i64 %1566, i64* %PC, align 8
  %1567 = inttoptr i64 %1565 to double*
  store double %1554, double* %1567, align 8
  %1568 = load i64, i64* %RBP, align 8
  %1569 = add i64 %1568, -80
  %1570 = load i64, i64* %PC, align 8
  %1571 = add i64 %1570, 5
  store i64 %1571, i64* %PC, align 8
  %1572 = inttoptr i64 %1569 to i64*
  %1573 = load i64, i64* %1572, align 8
  store i64 %1573, i64* %1702, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1704, align 1, !tbaa !2451
  %1574 = add i64 %1568, -104
  %1575 = add i64 %1570, 10
  store i64 %1575, i64* %PC, align 8
  %1576 = bitcast i64 %1573 to double
  %1577 = inttoptr i64 %1574 to double*
  %1578 = load double, double* %1577, align 8
  %1579 = fadd double %1576, %1578
  store double %1579, double* %1701, align 1, !tbaa !2451
  store i64 0, i64* %1703, align 1, !tbaa !2451
  %1580 = add i64 %1568, -16
  %1581 = add i64 %1570, 14
  store i64 %1581, i64* %PC, align 8
  %1582 = inttoptr i64 %1580 to i64*
  %1583 = load i64, i64* %1582, align 8
  store i64 %1583, i64* %RAX, align 8, !tbaa !2428
  %1584 = add i64 %1568, -40
  %1585 = add i64 %1570, 17
  store i64 %1585, i64* %PC, align 8
  %1586 = inttoptr i64 %1584 to i32*
  %1587 = load i32, i32* %1586, align 4
  %1588 = add i32 %1587, 1
  %1589 = zext i32 %1588 to i64
  store i64 %1589, i64* %RCX, align 8, !tbaa !2428
  %1590 = icmp eq i32 %1587, -1
  %1591 = icmp eq i32 %1588, 0
  %1592 = or i1 %1590, %1591
  %1593 = zext i1 %1592 to i8
  store i8 %1593, i8* %14, align 1, !tbaa !2432
  %1594 = and i32 %1588, 255
  %1595 = tail call i32 @llvm.ctpop.i32(i32 %1594) #14
  %1596 = trunc i32 %1595 to i8
  %1597 = and i8 %1596, 1
  %1598 = xor i8 %1597, 1
  store i8 %1598, i8* %21, align 1, !tbaa !2446
  %1599 = xor i32 %1588, %1587
  %1600 = lshr i32 %1599, 4
  %1601 = trunc i32 %1600 to i8
  %1602 = and i8 %1601, 1
  store i8 %1602, i8* %27, align 1, !tbaa !2447
  %1603 = zext i1 %1591 to i8
  store i8 %1603, i8* %30, align 1, !tbaa !2448
  %1604 = lshr i32 %1588, 31
  %1605 = trunc i32 %1604 to i8
  store i8 %1605, i8* %33, align 1, !tbaa !2449
  %1606 = lshr i32 %1587, 31
  %1607 = xor i32 %1604, %1606
  %1608 = add nuw nsw i32 %1607, %1604
  %1609 = icmp eq i32 %1608, 2
  %1610 = zext i1 %1609 to i8
  store i8 %1610, i8* %39, align 1, !tbaa !2450
  %1611 = sext i32 %1588 to i64
  store i64 %1611, i64* %RDX, align 8, !tbaa !2428
  %1612 = shl nsw i64 %1611, 3
  %1613 = add i64 %1583, %1612
  %1614 = add i64 %1570, 28
  store i64 %1614, i64* %PC, align 8
  %1615 = inttoptr i64 %1613 to double*
  store double %1579, double* %1615, align 8
  %1616 = load i64, i64* %RBP, align 8
  %1617 = add i64 %1616, -28
  %1618 = load i64, i64* %PC, align 8
  %1619 = add i64 %1618, 3
  store i64 %1619, i64* %PC, align 8
  %1620 = inttoptr i64 %1617 to i32*
  %1621 = load i32, i32* %1620, align 4
  %1622 = add i32 %1621, 2
  %1623 = zext i32 %1622 to i64
  store i64 %1623, i64* %RAX, align 8, !tbaa !2428
  %1624 = icmp ugt i32 %1621, -3
  %1625 = zext i1 %1624 to i8
  store i8 %1625, i8* %14, align 1, !tbaa !2432
  %1626 = and i32 %1622, 255
  %1627 = tail call i32 @llvm.ctpop.i32(i32 %1626) #14
  %1628 = trunc i32 %1627 to i8
  %1629 = and i8 %1628, 1
  %1630 = xor i8 %1629, 1
  store i8 %1630, i8* %21, align 1, !tbaa !2446
  %1631 = xor i32 %1622, %1621
  %1632 = lshr i32 %1631, 4
  %1633 = trunc i32 %1632 to i8
  %1634 = and i8 %1633, 1
  store i8 %1634, i8* %27, align 1, !tbaa !2447
  %1635 = icmp eq i32 %1622, 0
  %1636 = zext i1 %1635 to i8
  store i8 %1636, i8* %30, align 1, !tbaa !2448
  %1637 = lshr i32 %1622, 31
  %1638 = trunc i32 %1637 to i8
  store i8 %1638, i8* %33, align 1, !tbaa !2449
  %1639 = lshr i32 %1621, 31
  %1640 = xor i32 %1637, %1639
  %1641 = add nuw nsw i32 %1640, %1637
  %1642 = icmp eq i32 %1641, 2
  %1643 = zext i1 %1642 to i8
  store i8 %1643, i8* %39, align 1, !tbaa !2450
  %1644 = add i64 %1618, 9
  store i64 %1644, i64* %PC, align 8
  store i32 %1622, i32* %1620, align 4
  %1645 = load i64, i64* %PC, align 8
  %1646 = add i64 %1645, -576
  store i64 %1646, i64* %PC, align 8, !tbaa !2428
  br label %block_402536

block_402520:                                     ; preds = %block_40251b, %block_4024b0
  %1647 = phi i64 [ %91, %block_4024b0 ], [ %685, %block_40251b ]
  %1648 = phi i64 [ %61, %block_4024b0 ], [ %595, %block_40251b ]
  %MEMORY.4 = phi %struct.Memory* [ %2, %block_4024b0 ], [ %179, %block_40251b ]
  %1649 = add i64 %1648, -44
  %1650 = add i64 %1647, 3
  store i64 %1650, i64* %PC, align 8
  %1651 = inttoptr i64 %1649 to i32*
  %1652 = load i32, i32* %1651, align 4
  %1653 = shl i32 %1652, 2
  %1654 = zext i32 %1653 to i64
  store i64 %1654, i64* %RAX, align 8, !tbaa !2428
  %1655 = lshr i32 %1652, 30
  %1656 = trunc i32 %1655 to i8
  %1657 = and i8 %1656, 1
  store i8 %1657, i8* %14, align 1, !tbaa !2453
  %1658 = and i32 %1653, 252
  %1659 = tail call i32 @llvm.ctpop.i32(i32 %1658) #14
  %1660 = trunc i32 %1659 to i8
  %1661 = and i8 %1660, 1
  %1662 = xor i8 %1661, 1
  store i8 %1662, i8* %21, align 1, !tbaa !2453
  store i8 0, i8* %27, align 1, !tbaa !2453
  %1663 = icmp eq i32 %1653, 0
  %1664 = zext i1 %1663 to i8
  store i8 %1664, i8* %30, align 1, !tbaa !2453
  %1665 = lshr i32 %1652, 29
  %1666 = trunc i32 %1665 to i8
  %1667 = and i8 %1666, 1
  store i8 %1667, i8* %33, align 1, !tbaa !2453
  store i8 0, i8* %39, align 1, !tbaa !2453
  %1668 = add i64 %1648, -4
  %1669 = add i64 %1647, 9
  store i64 %1669, i64* %PC, align 8
  %1670 = inttoptr i64 %1668 to i32*
  %1671 = load i32, i32* %1670, align 4
  %1672 = sub i32 %1653, %1671
  %1673 = icmp ult i32 %1653, %1671
  %1674 = zext i1 %1673 to i8
  store i8 %1674, i8* %14, align 1, !tbaa !2432
  %1675 = and i32 %1672, 255
  %1676 = tail call i32 @llvm.ctpop.i32(i32 %1675) #14
  %1677 = trunc i32 %1676 to i8
  %1678 = and i8 %1677, 1
  %1679 = xor i8 %1678, 1
  store i8 %1679, i8* %21, align 1, !tbaa !2446
  %1680 = xor i32 %1671, %1653
  %1681 = xor i32 %1680, %1672
  %1682 = lshr i32 %1681, 4
  %1683 = trunc i32 %1682 to i8
  %1684 = and i8 %1683, 1
  store i8 %1684, i8* %27, align 1, !tbaa !2447
  %1685 = icmp eq i32 %1672, 0
  %1686 = zext i1 %1685 to i8
  store i8 %1686, i8* %30, align 1, !tbaa !2448
  %1687 = lshr i32 %1672, 31
  %1688 = trunc i32 %1687 to i8
  store i8 %1688, i8* %33, align 1, !tbaa !2449
  %1689 = lshr i32 %1652, 29
  %1690 = and i32 %1689, 1
  %1691 = lshr i32 %1671, 31
  %1692 = xor i32 %1691, %1690
  %1693 = xor i32 %1687, %1690
  %1694 = add nuw nsw i32 %1693, %1692
  %1695 = icmp eq i32 %1694, 2
  %1696 = zext i1 %1695 to i8
  store i8 %1696, i8* %39, align 1, !tbaa !2450
  %.v = select i1 %1685, i64 15, i64 608
  %1697 = add i64 %1647, %.v
  %1698 = add i64 %1648, -28
  %1699 = add i64 %1697, 7
  store i64 %1699, i64* %PC, align 8
  %1700 = inttoptr i64 %1698 to i32*
  store i32 0, i32* %1700, align 4
  %1701 = bitcast %union.VectorReg* %4 to double*
  %1702 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  %1703 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1704 = bitcast i64* %1703 to double*
  %.pre12 = load i64, i64* %PC, align 8
  br i1 %1685, label %block_402536.preheader, label %block_402787.preheader

block_402787.preheader:                           ; preds = %block_402520
  br label %block_402787

block_402536.preheader:                           ; preds = %block_402520
  br label %block_402536
}

; Function Attrs: noinline
define %struct.Memory* @sub_400810___do_global_dtors_aux(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #8 {
block_400810:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i8, i8* getelementptr inbounds (%__bss_start_type, %__bss_start_type* @__bss_start, i64 0, i32 0, i64 0), align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %4, align 1, !tbaa !2432
  %5 = zext i8 %3 to i32
  %6 = tail call i32 @llvm.ctpop.i32(i32 %5) #14
  %7 = trunc i32 %6 to i8
  %8 = and i8 %7, 1
  %9 = xor i8 %8, 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %9, i8* %10, align 1, !tbaa !2446
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %11, align 1, !tbaa !2447
  %12 = icmp eq i8 %3, 0
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %13, i8* %14, align 1, !tbaa !2448
  %15 = lshr i8 %3, 7
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %15, i8* %16, align 1, !tbaa !2449
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %17, align 1, !tbaa !2450
  %.v = select i1 %12, i64 9, i64 32
  %18 = add i64 %.v, %1
  store i64 %18, i64* %PC, align 8, !tbaa !2428
  br i1 %12, label %block_400819, label %block_400830

block_400830:                                     ; preds = %block_400810
  %19 = add i64 %18, 2
  store i64 %19, i64* %PC, align 8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %21 = load i64, i64* %20, align 8, !tbaa !2428
  %22 = inttoptr i64 %21 to i64*
  %23 = load i64, i64* %22, align 8
  store i64 %23, i64* %PC, align 8, !tbaa !2428
  %24 = add i64 %21, 8
  store i64 %24, i64* %20, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_400819:                                     ; preds = %block_400810
  %25 = load i64, i64* %RBP, align 8
  %26 = add i64 %18, 1
  store i64 %26, i64* %PC, align 8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %28 = load i64, i64* %27, align 8, !tbaa !2428
  %29 = add i64 %28, -8
  %30 = inttoptr i64 %29 to i64*
  store i64 %25, i64* %30, align 8
  %31 = load i64, i64* %PC, align 8
  store i64 %29, i64* %RBP, align 8, !tbaa !2428
  %32 = add i64 %31, -122
  %33 = add i64 %31, 8
  %34 = add i64 %28, -16
  %35 = inttoptr i64 %34 to i64*
  store i64 %33, i64* %35, align 8
  store i64 %34, i64* %27, align 8, !tbaa !2428
  store i64 %32, i64* %PC, align 8, !tbaa !2428
  %36 = tail call %struct.Memory* @sub_4007a0_deregister_tm_clones_renamed_(%struct.State* nonnull %0, i64 %32, %struct.Memory* %2)
  %37 = load i64, i64* %PC, align 8
  store i8 1, i8* getelementptr inbounds (%__bss_start_type, %__bss_start_type* @__bss_start, i64 0, i32 0, i64 0), align 8
  %38 = add i64 %37, 8
  store i64 %38, i64* %PC, align 8
  %39 = load i64, i64* %27, align 8, !tbaa !2428
  %40 = add i64 %39, 8
  %41 = inttoptr i64 %39 to i64*
  %42 = load i64, i64* %41, align 8
  store i64 %42, i64* %RBP, align 8, !tbaa !2428
  store i64 %40, i64* %27, align 8, !tbaa !2428
  %43 = add i64 %37, 9
  store i64 %43, i64* %PC, align 8
  %44 = inttoptr i64 %40 to i64*
  %45 = load i64, i64* %44, align 8
  store i64 %45, i64* %PC, align 8, !tbaa !2428
  %46 = add i64 %39, 16
  store i64 %46, i64* %27, align 8, !tbaa !2428
  ret %struct.Memory* %36
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_404094__term_proc(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_404094:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = add i64 %3, -8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %7 = xor i64 %4, %3
  %8 = lshr i64 %7, 4
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %13 = lshr i64 %4, 63
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %15 = lshr i64 %3, 63
  %16 = xor i64 %13, %15
  %17 = add nuw nsw i64 %16, %15
  %18 = icmp eq i64 %17, 2
  %19 = zext i1 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i64 %3, i64* %RSP, align 8, !tbaa !2428
  %21 = icmp ult i64 %3, 8
  %22 = zext i1 %21 to i8
  store i8 %22, i8* %5, align 1, !tbaa !2432
  %23 = trunc i64 %3 to i32
  %24 = and i32 %23, 255
  %25 = tail call i32 @llvm.ctpop.i32(i32 %24) #14
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = xor i8 %27, 1
  store i8 %28, i8* %6, align 1, !tbaa !2446
  store i8 %10, i8* %11, align 1, !tbaa !2447
  %29 = icmp eq i64 %3, 0
  %30 = zext i1 %29 to i8
  store i8 %30, i8* %12, align 1, !tbaa !2448
  %31 = trunc i64 %15 to i8
  store i8 %31, i8* %14, align 1, !tbaa !2449
  store i8 %19, i8* %20, align 1, !tbaa !2450
  %32 = add i64 %1, 9
  store i64 %32, i64* %PC, align 8
  %33 = inttoptr i64 %3 to i64*
  %34 = load i64, i64* %33, align 8
  store i64 %34, i64* %PC, align 8, !tbaa !2428
  %35 = add i64 %3, 8
  store i64 %35, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_4011f0_bitrv2(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_4011f0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %1, 1
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %4, i64* %9, align 8
  store i64 %8, i64* %6, align 8, !tbaa !2428
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -12
  %12 = load i32, i32* %EDI, align 4
  %13 = add i64 %10, 6
  store i64 %13, i64* %PC, align 8
  %14 = inttoptr i64 %11 to i32*
  store i32 %12, i32* %14, align 4
  %15 = load i64, i64* %RBP, align 8
  %16 = add i64 %15, -16
  %17 = load i64, i64* %RSI, align 8
  %18 = load i64, i64* %PC, align 8
  %19 = add i64 %18, 4
  store i64 %19, i64* %PC, align 8
  %20 = inttoptr i64 %16 to i64*
  store i64 %17, i64* %20, align 8
  %21 = load i64, i64* %RBP, align 8
  %22 = add i64 %21, -24
  %23 = load i64, i64* %RDX, align 8
  %24 = load i64, i64* %PC, align 8
  %25 = add i64 %24, 4
  store i64 %25, i64* %PC, align 8
  %26 = inttoptr i64 %22 to i64*
  store i64 %23, i64* %26, align 8
  %27 = load i64, i64* %RBP, align 8
  %28 = add i64 %27, -16
  %29 = load i64, i64* %PC, align 8
  %30 = add i64 %29, 4
  store i64 %30, i64* %PC, align 8
  %31 = inttoptr i64 %28 to i64*
  %32 = load i64, i64* %31, align 8
  store i64 %32, i64* %RDX, align 8, !tbaa !2428
  %33 = add i64 %29, 10
  store i64 %33, i64* %PC, align 8
  %34 = inttoptr i64 %32 to i32*
  store i32 0, i32* %34, align 4
  %35 = load i64, i64* %RBP, align 8
  %36 = add i64 %35, -4
  %37 = load i64, i64* %PC, align 8
  %38 = add i64 %37, 3
  store i64 %38, i64* %PC, align 8
  %39 = inttoptr i64 %36 to i32*
  %40 = load i32, i32* %39, align 4
  %41 = zext i32 %40 to i64
  store i64 %41, i64* %RDI, align 8, !tbaa !2428
  %42 = add i64 %35, -44
  %43 = add i64 %37, 6
  store i64 %43, i64* %PC, align 8
  %44 = inttoptr i64 %42 to i32*
  store i32 %40, i32* %44, align 4
  %45 = load i64, i64* %RBP, align 8
  %46 = add i64 %45, -48
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 7
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %46 to i32*
  store i32 1, i32* %49, align 4
  %50 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %53 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %.pre = load i64, i64* %PC, align 8
  br label %block_401216

block_401862.loopexit:                            ; preds = %block_40129a
  br label %block_401862

block_401862.loopexit76:                          ; preds = %block_40169b
  br label %block_401862

block_401862:                                     ; preds = %block_401862.loopexit76, %block_401862.loopexit
  %56 = phi i64 [ %2853, %block_401862.loopexit ], [ %2777, %block_401862.loopexit76 ]
  %.sink5 = phi i64 [ 468, %block_401862.loopexit ], [ 6, %block_401862.loopexit76 ]
  %57 = add i64 %.sink5, %56
  store i64 %57, i64* %PC, align 8
  %58 = load i64, i64* %6, align 8, !tbaa !2428
  %59 = add i64 %58, 8
  %60 = inttoptr i64 %58 to i64*
  %61 = load i64, i64* %60, align 8
  store i64 %61, i64* %RBP, align 8, !tbaa !2428
  store i64 %59, i64* %6, align 8, !tbaa !2428
  %62 = add i64 %57, 1
  store i64 %62, i64* %PC, align 8
  %63 = inttoptr i64 %59 to i64*
  %64 = load i64, i64* %63, align 8
  store i64 %64, i64* %PC, align 8, !tbaa !2428
  %65 = add i64 %58, 16
  store i64 %65, i64* %6, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_40184a:                                     ; preds = %block_4016ae
  %66 = add i64 %2815, 8
  store i64 %66, i64* %PC, align 8
  %67 = load i32, i32* %2787, align 4
  %68 = add i32 %67, 1
  %69 = zext i32 %68 to i64
  store i64 %69, i64* %RAX, align 8, !tbaa !2428
  %70 = icmp eq i32 %67, -1
  %71 = icmp eq i32 %68, 0
  %72 = or i1 %70, %71
  %73 = zext i1 %72 to i8
  store i8 %73, i8* %50, align 1, !tbaa !2432
  %74 = and i32 %68, 255
  %75 = tail call i32 @llvm.ctpop.i32(i32 %74) #14
  %76 = trunc i32 %75 to i8
  %77 = and i8 %76, 1
  %78 = xor i8 %77, 1
  store i8 %78, i8* %51, align 1, !tbaa !2446
  %79 = xor i32 %68, %67
  %80 = lshr i32 %79, 4
  %81 = trunc i32 %80 to i8
  %82 = and i8 %81, 1
  store i8 %82, i8* %52, align 1, !tbaa !2447
  %83 = zext i1 %71 to i8
  store i8 %83, i8* %53, align 1, !tbaa !2448
  %84 = lshr i32 %68, 31
  %85 = trunc i32 %84 to i8
  store i8 %85, i8* %54, align 1, !tbaa !2449
  %86 = lshr i32 %67, 31
  %87 = xor i32 %84, %86
  %88 = add nuw nsw i32 %87, %84
  %89 = icmp eq i32 %88, 2
  %90 = zext i1 %89 to i8
  store i8 %90, i8* %55, align 1, !tbaa !2450
  %91 = add i64 %2815, 14
  store i64 %91, i64* %PC, align 8
  store i32 %68, i32* %2787, align 4
  %92 = load i64, i64* %PC, align 8
  %93 = add i64 %92, -445
  store i64 %93, i64* %PC, align 8, !tbaa !2428
  br label %block_40169b

block_4015bd:                                     ; preds = %block_4012ad
  %94 = load i32, i32* %1953, align 4
  %95 = shl i32 %94, 1
  %96 = icmp slt i32 %94, 0
  %97 = icmp slt i32 %95, 0
  %98 = xor i1 %96, %97
  %99 = zext i32 %95 to i64
  store i64 %99, i64* %RAX, align 8, !tbaa !2428
  %.lobit18 = lshr i32 %94, 31
  %100 = trunc i32 %.lobit18 to i8
  store i8 %100, i8* %50, align 1, !tbaa !2453
  %101 = and i32 %95, 254
  %102 = tail call i32 @llvm.ctpop.i32(i32 %101) #14
  %103 = trunc i32 %102 to i8
  %104 = and i8 %103, 1
  %105 = xor i8 %104, 1
  store i8 %105, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %106 = icmp eq i32 %95, 0
  %107 = zext i1 %106 to i8
  store i8 %107, i8* %53, align 1, !tbaa !2453
  %108 = lshr i32 %94, 30
  %109 = trunc i32 %108 to i8
  %110 = and i8 %109, 1
  store i8 %110, i8* %54, align 1, !tbaa !2453
  %111 = zext i1 %98 to i8
  store i8 %111, i8* %55, align 1, !tbaa !2453
  %112 = add i64 %1945, -52
  %113 = add i64 %1981, 9
  store i64 %113, i64* %PC, align 8
  %114 = inttoptr i64 %112 to i32*
  %115 = load i32, i32* %114, align 4
  %116 = add i32 %115, %95
  %117 = zext i32 %116 to i64
  store i64 %117, i64* %RAX, align 8, !tbaa !2428
  %118 = icmp ult i32 %116, %95
  %119 = icmp ult i32 %116, %115
  %120 = or i1 %118, %119
  %121 = zext i1 %120 to i8
  store i8 %121, i8* %50, align 1, !tbaa !2432
  %122 = and i32 %116, 255
  %123 = tail call i32 @llvm.ctpop.i32(i32 %122) #14
  %124 = trunc i32 %123 to i8
  %125 = and i8 %124, 1
  %126 = xor i8 %125, 1
  store i8 %126, i8* %51, align 1, !tbaa !2446
  %127 = xor i32 %115, %95
  %128 = xor i32 %127, %116
  %129 = lshr i32 %128, 4
  %130 = trunc i32 %129 to i8
  %131 = and i8 %130, 1
  store i8 %131, i8* %52, align 1, !tbaa !2447
  %132 = icmp eq i32 %116, 0
  %133 = zext i1 %132 to i8
  store i8 %133, i8* %53, align 1, !tbaa !2448
  %134 = lshr i32 %116, 31
  %135 = trunc i32 %134 to i8
  store i8 %135, i8* %54, align 1, !tbaa !2449
  %136 = lshr i32 %94, 30
  %137 = and i32 %136, 1
  %138 = lshr i32 %115, 31
  %139 = xor i32 %134, %137
  %140 = xor i32 %134, %138
  %141 = add nuw nsw i32 %139, %140
  %142 = icmp eq i32 %141, 2
  %143 = zext i1 %142 to i8
  store i8 %143, i8* %55, align 1, !tbaa !2450
  %144 = add i64 %1945, -16
  %145 = add i64 %1981, 13
  store i64 %145, i64* %PC, align 8
  %146 = inttoptr i64 %144 to i64*
  %147 = load i64, i64* %146, align 8
  store i64 %147, i64* %RCX, align 8, !tbaa !2428
  %148 = add i64 %1981, 17
  store i64 %148, i64* %PC, align 8
  %149 = load i32, i32* %1953, align 4
  %150 = sext i32 %149 to i64
  store i64 %150, i64* %RDX, align 8, !tbaa !2428
  %151 = shl nsw i64 %150, 2
  %152 = add i64 %147, %151
  %153 = add i64 %1981, 20
  store i64 %153, i64* %PC, align 8
  %154 = inttoptr i64 %152 to i32*
  %155 = load i32, i32* %154, align 4
  %156 = add i32 %155, %116
  %157 = zext i32 %156 to i64
  store i64 %157, i64* %RAX, align 8, !tbaa !2428
  %158 = icmp ult i32 %156, %116
  %159 = icmp ult i32 %156, %155
  %160 = or i1 %158, %159
  %161 = zext i1 %160 to i8
  store i8 %161, i8* %50, align 1, !tbaa !2432
  %162 = and i32 %156, 255
  %163 = tail call i32 @llvm.ctpop.i32(i32 %162) #14
  %164 = trunc i32 %163 to i8
  %165 = and i8 %164, 1
  %166 = xor i8 %165, 1
  store i8 %166, i8* %51, align 1, !tbaa !2446
  %167 = xor i32 %155, %116
  %168 = xor i32 %167, %156
  %169 = lshr i32 %168, 4
  %170 = trunc i32 %169 to i8
  %171 = and i8 %170, 1
  store i8 %171, i8* %52, align 1, !tbaa !2447
  %172 = icmp eq i32 %156, 0
  %173 = zext i1 %172 to i8
  store i8 %173, i8* %53, align 1, !tbaa !2448
  %174 = lshr i32 %156, 31
  %175 = trunc i32 %174 to i8
  store i8 %175, i8* %54, align 1, !tbaa !2449
  %176 = lshr i32 %155, 31
  %177 = xor i32 %174, %134
  %178 = xor i32 %174, %176
  %179 = add nuw nsw i32 %177, %178
  %180 = icmp eq i32 %179, 2
  %181 = zext i1 %180 to i8
  store i8 %181, i8* %55, align 1, !tbaa !2450
  %182 = load i64, i64* %RBP, align 8
  %183 = add i64 %182, -32
  %184 = add i64 %1981, 23
  store i64 %184, i64* %PC, align 8
  %185 = inttoptr i64 %183 to i32*
  store i32 %156, i32* %185, align 4
  %186 = load i64, i64* %RBP, align 8
  %187 = add i64 %186, -32
  %188 = load i64, i64* %PC, align 8
  %189 = add i64 %188, 3
  store i64 %189, i64* %PC, align 8
  %190 = inttoptr i64 %187 to i32*
  %191 = load i32, i32* %190, align 4
  %192 = zext i32 %191 to i64
  store i64 %192, i64* %RAX, align 8, !tbaa !2428
  %193 = add i64 %186, -52
  %194 = add i64 %188, 6
  store i64 %194, i64* %PC, align 8
  %195 = inttoptr i64 %193 to i32*
  %196 = load i32, i32* %195, align 4
  %197 = add i32 %196, %191
  %198 = zext i32 %197 to i64
  store i64 %198, i64* %RAX, align 8, !tbaa !2428
  %199 = icmp ult i32 %197, %191
  %200 = icmp ult i32 %197, %196
  %201 = or i1 %199, %200
  %202 = zext i1 %201 to i8
  store i8 %202, i8* %50, align 1, !tbaa !2432
  %203 = and i32 %197, 255
  %204 = tail call i32 @llvm.ctpop.i32(i32 %203) #14
  %205 = trunc i32 %204 to i8
  %206 = and i8 %205, 1
  %207 = xor i8 %206, 1
  store i8 %207, i8* %51, align 1, !tbaa !2446
  %208 = xor i32 %196, %191
  %209 = xor i32 %208, %197
  %210 = lshr i32 %209, 4
  %211 = trunc i32 %210 to i8
  %212 = and i8 %211, 1
  store i8 %212, i8* %52, align 1, !tbaa !2447
  %213 = icmp eq i32 %197, 0
  %214 = zext i1 %213 to i8
  store i8 %214, i8* %53, align 1, !tbaa !2448
  %215 = lshr i32 %197, 31
  %216 = trunc i32 %215 to i8
  store i8 %216, i8* %54, align 1, !tbaa !2449
  %217 = lshr i32 %191, 31
  %218 = lshr i32 %196, 31
  %219 = xor i32 %215, %217
  %220 = xor i32 %215, %218
  %221 = add nuw nsw i32 %219, %220
  %222 = icmp eq i32 %221, 2
  %223 = zext i1 %222 to i8
  store i8 %223, i8* %55, align 1, !tbaa !2450
  %224 = add i64 %186, -40
  %225 = add i64 %188, 9
  store i64 %225, i64* %PC, align 8
  %226 = inttoptr i64 %224 to i32*
  store i32 %197, i32* %226, align 4
  %227 = load i64, i64* %RBP, align 8
  %228 = add i64 %227, -24
  %229 = load i64, i64* %PC, align 8
  %230 = add i64 %229, 4
  store i64 %230, i64* %PC, align 8
  %231 = inttoptr i64 %228 to i64*
  %232 = load i64, i64* %231, align 8
  store i64 %232, i64* %RCX, align 8, !tbaa !2428
  %233 = add i64 %227, -32
  %234 = add i64 %229, 8
  store i64 %234, i64* %PC, align 8
  %235 = inttoptr i64 %233 to i32*
  %236 = load i32, i32* %235, align 4
  %237 = sext i32 %236 to i64
  store i64 %237, i64* %RDX, align 8, !tbaa !2428
  %238 = shl nsw i64 %237, 3
  %239 = add i64 %238, %232
  %240 = add i64 %229, 13
  store i64 %240, i64* %PC, align 8
  %241 = inttoptr i64 %239 to i64*
  %242 = load i64, i64* %241, align 8
  store i64 %242, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %243 = add i64 %227, -64
  %244 = add i64 %229, 18
  store i64 %244, i64* %PC, align 8
  %245 = inttoptr i64 %243 to i64*
  store i64 %242, i64* %245, align 8
  %246 = load i64, i64* %RBP, align 8
  %247 = add i64 %246, -24
  %248 = load i64, i64* %PC, align 8
  %249 = add i64 %248, 4
  store i64 %249, i64* %PC, align 8
  %250 = inttoptr i64 %247 to i64*
  %251 = load i64, i64* %250, align 8
  store i64 %251, i64* %RCX, align 8, !tbaa !2428
  %252 = add i64 %246, -32
  %253 = add i64 %248, 7
  store i64 %253, i64* %PC, align 8
  %254 = inttoptr i64 %252 to i32*
  %255 = load i32, i32* %254, align 4
  %256 = add i32 %255, 1
  %257 = zext i32 %256 to i64
  store i64 %257, i64* %RAX, align 8, !tbaa !2428
  %258 = icmp eq i32 %255, -1
  %259 = icmp eq i32 %256, 0
  %260 = or i1 %258, %259
  %261 = zext i1 %260 to i8
  store i8 %261, i8* %50, align 1, !tbaa !2432
  %262 = and i32 %256, 255
  %263 = tail call i32 @llvm.ctpop.i32(i32 %262) #14
  %264 = trunc i32 %263 to i8
  %265 = and i8 %264, 1
  %266 = xor i8 %265, 1
  store i8 %266, i8* %51, align 1, !tbaa !2446
  %267 = xor i32 %256, %255
  %268 = lshr i32 %267, 4
  %269 = trunc i32 %268 to i8
  %270 = and i8 %269, 1
  store i8 %270, i8* %52, align 1, !tbaa !2447
  %271 = zext i1 %259 to i8
  store i8 %271, i8* %53, align 1, !tbaa !2448
  %272 = lshr i32 %256, 31
  %273 = trunc i32 %272 to i8
  store i8 %273, i8* %54, align 1, !tbaa !2449
  %274 = lshr i32 %255, 31
  %275 = xor i32 %272, %274
  %276 = add nuw nsw i32 %275, %272
  %277 = icmp eq i32 %276, 2
  %278 = zext i1 %277 to i8
  store i8 %278, i8* %55, align 1, !tbaa !2450
  %279 = sext i32 %256 to i64
  store i64 %279, i64* %RDX, align 8, !tbaa !2428
  %280 = shl nsw i64 %279, 3
  %281 = add i64 %251, %280
  %282 = add i64 %248, 18
  store i64 %282, i64* %PC, align 8
  %283 = inttoptr i64 %281 to i64*
  %284 = load i64, i64* %283, align 8
  store i64 %284, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %285 = add i64 %246, -72
  %286 = add i64 %248, 23
  store i64 %286, i64* %PC, align 8
  %287 = inttoptr i64 %285 to i64*
  store i64 %284, i64* %287, align 8
  %288 = load i64, i64* %RBP, align 8
  %289 = add i64 %288, -24
  %290 = load i64, i64* %PC, align 8
  %291 = add i64 %290, 4
  store i64 %291, i64* %PC, align 8
  %292 = inttoptr i64 %289 to i64*
  %293 = load i64, i64* %292, align 8
  store i64 %293, i64* %RCX, align 8, !tbaa !2428
  %294 = add i64 %288, -40
  %295 = add i64 %290, 8
  store i64 %295, i64* %PC, align 8
  %296 = inttoptr i64 %294 to i32*
  %297 = load i32, i32* %296, align 4
  %298 = sext i32 %297 to i64
  store i64 %298, i64* %RDX, align 8, !tbaa !2428
  %299 = shl nsw i64 %298, 3
  %300 = add i64 %299, %293
  %301 = add i64 %290, 13
  store i64 %301, i64* %PC, align 8
  %302 = inttoptr i64 %300 to i64*
  %303 = load i64, i64* %302, align 8
  store i64 %303, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %304 = add i64 %288, -80
  %305 = add i64 %290, 18
  store i64 %305, i64* %PC, align 8
  %306 = inttoptr i64 %304 to i64*
  store i64 %303, i64* %306, align 8
  %307 = load i64, i64* %RBP, align 8
  %308 = add i64 %307, -24
  %309 = load i64, i64* %PC, align 8
  %310 = add i64 %309, 4
  store i64 %310, i64* %PC, align 8
  %311 = inttoptr i64 %308 to i64*
  %312 = load i64, i64* %311, align 8
  store i64 %312, i64* %RCX, align 8, !tbaa !2428
  %313 = add i64 %307, -40
  %314 = add i64 %309, 7
  store i64 %314, i64* %PC, align 8
  %315 = inttoptr i64 %313 to i32*
  %316 = load i32, i32* %315, align 4
  %317 = add i32 %316, 1
  %318 = zext i32 %317 to i64
  store i64 %318, i64* %RAX, align 8, !tbaa !2428
  %319 = icmp eq i32 %316, -1
  %320 = icmp eq i32 %317, 0
  %321 = or i1 %319, %320
  %322 = zext i1 %321 to i8
  store i8 %322, i8* %50, align 1, !tbaa !2432
  %323 = and i32 %317, 255
  %324 = tail call i32 @llvm.ctpop.i32(i32 %323) #14
  %325 = trunc i32 %324 to i8
  %326 = and i8 %325, 1
  %327 = xor i8 %326, 1
  store i8 %327, i8* %51, align 1, !tbaa !2446
  %328 = xor i32 %317, %316
  %329 = lshr i32 %328, 4
  %330 = trunc i32 %329 to i8
  %331 = and i8 %330, 1
  store i8 %331, i8* %52, align 1, !tbaa !2447
  %332 = zext i1 %320 to i8
  store i8 %332, i8* %53, align 1, !tbaa !2448
  %333 = lshr i32 %317, 31
  %334 = trunc i32 %333 to i8
  store i8 %334, i8* %54, align 1, !tbaa !2449
  %335 = lshr i32 %316, 31
  %336 = xor i32 %333, %335
  %337 = add nuw nsw i32 %336, %333
  %338 = icmp eq i32 %337, 2
  %339 = zext i1 %338 to i8
  store i8 %339, i8* %55, align 1, !tbaa !2450
  %340 = sext i32 %317 to i64
  store i64 %340, i64* %RDX, align 8, !tbaa !2428
  %341 = shl nsw i64 %340, 3
  %342 = add i64 %312, %341
  %343 = add i64 %309, 18
  store i64 %343, i64* %PC, align 8
  %344 = inttoptr i64 %342 to i64*
  %345 = load i64, i64* %344, align 8
  store i64 %345, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %346 = add i64 %307, -88
  %347 = add i64 %309, 23
  store i64 %347, i64* %PC, align 8
  %348 = inttoptr i64 %346 to i64*
  store i64 %345, i64* %348, align 8
  %349 = load i64, i64* %RBP, align 8
  %350 = add i64 %349, -80
  %351 = load i64, i64* %PC, align 8
  %352 = add i64 %351, 5
  store i64 %352, i64* %PC, align 8
  %353 = inttoptr i64 %350 to i64*
  %354 = load i64, i64* %353, align 8
  store i64 %354, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %355 = add i64 %349, -24
  %356 = add i64 %351, 9
  store i64 %356, i64* %PC, align 8
  %357 = inttoptr i64 %355 to i64*
  %358 = load i64, i64* %357, align 8
  store i64 %358, i64* %RCX, align 8, !tbaa !2428
  %359 = add i64 %349, -32
  %360 = add i64 %351, 13
  store i64 %360, i64* %PC, align 8
  %361 = inttoptr i64 %359 to i32*
  %362 = load i32, i32* %361, align 4
  %363 = sext i32 %362 to i64
  store i64 %363, i64* %RDX, align 8, !tbaa !2428
  %364 = shl nsw i64 %363, 3
  %365 = add i64 %364, %358
  %366 = add i64 %351, 18
  store i64 %366, i64* %PC, align 8
  %367 = inttoptr i64 %365 to i64*
  store i64 %354, i64* %367, align 8
  %368 = load i64, i64* %RBP, align 8
  %369 = add i64 %368, -88
  %370 = load i64, i64* %PC, align 8
  %371 = add i64 %370, 5
  store i64 %371, i64* %PC, align 8
  %372 = inttoptr i64 %369 to i64*
  %373 = load i64, i64* %372, align 8
  store i64 %373, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %374 = add i64 %368, -24
  %375 = add i64 %370, 9
  store i64 %375, i64* %PC, align 8
  %376 = inttoptr i64 %374 to i64*
  %377 = load i64, i64* %376, align 8
  store i64 %377, i64* %RCX, align 8, !tbaa !2428
  %378 = add i64 %368, -32
  %379 = add i64 %370, 12
  store i64 %379, i64* %PC, align 8
  %380 = inttoptr i64 %378 to i32*
  %381 = load i32, i32* %380, align 4
  %382 = add i32 %381, 1
  %383 = zext i32 %382 to i64
  store i64 %383, i64* %RAX, align 8, !tbaa !2428
  %384 = icmp eq i32 %381, -1
  %385 = icmp eq i32 %382, 0
  %386 = or i1 %384, %385
  %387 = zext i1 %386 to i8
  store i8 %387, i8* %50, align 1, !tbaa !2432
  %388 = and i32 %382, 255
  %389 = tail call i32 @llvm.ctpop.i32(i32 %388) #14
  %390 = trunc i32 %389 to i8
  %391 = and i8 %390, 1
  %392 = xor i8 %391, 1
  store i8 %392, i8* %51, align 1, !tbaa !2446
  %393 = xor i32 %382, %381
  %394 = lshr i32 %393, 4
  %395 = trunc i32 %394 to i8
  %396 = and i8 %395, 1
  store i8 %396, i8* %52, align 1, !tbaa !2447
  %397 = zext i1 %385 to i8
  store i8 %397, i8* %53, align 1, !tbaa !2448
  %398 = lshr i32 %382, 31
  %399 = trunc i32 %398 to i8
  store i8 %399, i8* %54, align 1, !tbaa !2449
  %400 = lshr i32 %381, 31
  %401 = xor i32 %398, %400
  %402 = add nuw nsw i32 %401, %398
  %403 = icmp eq i32 %402, 2
  %404 = zext i1 %403 to i8
  store i8 %404, i8* %55, align 1, !tbaa !2450
  %405 = sext i32 %382 to i64
  store i64 %405, i64* %RDX, align 8, !tbaa !2428
  %406 = shl nsw i64 %405, 3
  %407 = add i64 %377, %406
  %408 = add i64 %370, 23
  store i64 %408, i64* %PC, align 8
  %409 = inttoptr i64 %407 to i64*
  store i64 %373, i64* %409, align 8
  %410 = load i64, i64* %RBP, align 8
  %411 = add i64 %410, -64
  %412 = load i64, i64* %PC, align 8
  %413 = add i64 %412, 5
  store i64 %413, i64* %PC, align 8
  %414 = inttoptr i64 %411 to i64*
  %415 = load i64, i64* %414, align 8
  store i64 %415, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %416 = add i64 %410, -24
  %417 = add i64 %412, 9
  store i64 %417, i64* %PC, align 8
  %418 = inttoptr i64 %416 to i64*
  %419 = load i64, i64* %418, align 8
  store i64 %419, i64* %RCX, align 8, !tbaa !2428
  %420 = add i64 %410, -40
  %421 = add i64 %412, 13
  store i64 %421, i64* %PC, align 8
  %422 = inttoptr i64 %420 to i32*
  %423 = load i32, i32* %422, align 4
  %424 = sext i32 %423 to i64
  store i64 %424, i64* %RDX, align 8, !tbaa !2428
  %425 = shl nsw i64 %424, 3
  %426 = add i64 %425, %419
  %427 = add i64 %412, 18
  store i64 %427, i64* %PC, align 8
  %428 = inttoptr i64 %426 to i64*
  store i64 %415, i64* %428, align 8
  %429 = load i64, i64* %RBP, align 8
  %430 = add i64 %429, -72
  %431 = load i64, i64* %PC, align 8
  %432 = add i64 %431, 5
  store i64 %432, i64* %PC, align 8
  %433 = inttoptr i64 %430 to i64*
  %434 = load i64, i64* %433, align 8
  store i64 %434, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %435 = add i64 %429, -24
  %436 = add i64 %431, 9
  store i64 %436, i64* %PC, align 8
  %437 = inttoptr i64 %435 to i64*
  %438 = load i64, i64* %437, align 8
  store i64 %438, i64* %RCX, align 8, !tbaa !2428
  %439 = add i64 %429, -40
  %440 = add i64 %431, 12
  store i64 %440, i64* %PC, align 8
  %441 = inttoptr i64 %439 to i32*
  %442 = load i32, i32* %441, align 4
  %443 = add i32 %442, 1
  %444 = zext i32 %443 to i64
  store i64 %444, i64* %RAX, align 8, !tbaa !2428
  %445 = icmp eq i32 %442, -1
  %446 = icmp eq i32 %443, 0
  %447 = or i1 %445, %446
  %448 = zext i1 %447 to i8
  store i8 %448, i8* %50, align 1, !tbaa !2432
  %449 = and i32 %443, 255
  %450 = tail call i32 @llvm.ctpop.i32(i32 %449) #14
  %451 = trunc i32 %450 to i8
  %452 = and i8 %451, 1
  %453 = xor i8 %452, 1
  store i8 %453, i8* %51, align 1, !tbaa !2446
  %454 = xor i32 %443, %442
  %455 = lshr i32 %454, 4
  %456 = trunc i32 %455 to i8
  %457 = and i8 %456, 1
  store i8 %457, i8* %52, align 1, !tbaa !2447
  %458 = zext i1 %446 to i8
  store i8 %458, i8* %53, align 1, !tbaa !2448
  %459 = lshr i32 %443, 31
  %460 = trunc i32 %459 to i8
  store i8 %460, i8* %54, align 1, !tbaa !2449
  %461 = lshr i32 %442, 31
  %462 = xor i32 %459, %461
  %463 = add nuw nsw i32 %462, %459
  %464 = icmp eq i32 %463, 2
  %465 = zext i1 %464 to i8
  store i8 %465, i8* %55, align 1, !tbaa !2450
  %466 = sext i32 %443 to i64
  store i64 %466, i64* %RDX, align 8, !tbaa !2428
  %467 = shl nsw i64 %466, 3
  %468 = add i64 %438, %467
  %469 = add i64 %431, 23
  store i64 %469, i64* %PC, align 8
  %470 = inttoptr i64 %468 to i64*
  store i64 %434, i64* %470, align 8
  %471 = load i64, i64* %RBP, align 8
  %472 = add i64 %471, -36
  %473 = load i64, i64* %PC, align 8
  %474 = add i64 %473, 3
  store i64 %474, i64* %PC, align 8
  %475 = inttoptr i64 %472 to i32*
  %476 = load i32, i32* %475, align 4
  %477 = add i32 %476, 1
  %478 = zext i32 %477 to i64
  store i64 %478, i64* %RAX, align 8, !tbaa !2428
  %479 = icmp eq i32 %476, -1
  %480 = icmp eq i32 %477, 0
  %481 = or i1 %479, %480
  %482 = zext i1 %481 to i8
  store i8 %482, i8* %50, align 1, !tbaa !2432
  %483 = and i32 %477, 255
  %484 = tail call i32 @llvm.ctpop.i32(i32 %483) #14
  %485 = trunc i32 %484 to i8
  %486 = and i8 %485, 1
  %487 = xor i8 %486, 1
  store i8 %487, i8* %51, align 1, !tbaa !2446
  %488 = xor i32 %477, %476
  %489 = lshr i32 %488, 4
  %490 = trunc i32 %489 to i8
  %491 = and i8 %490, 1
  store i8 %491, i8* %52, align 1, !tbaa !2447
  %492 = zext i1 %480 to i8
  store i8 %492, i8* %53, align 1, !tbaa !2448
  %493 = lshr i32 %477, 31
  %494 = trunc i32 %493 to i8
  store i8 %494, i8* %54, align 1, !tbaa !2449
  %495 = lshr i32 %476, 31
  %496 = xor i32 %493, %495
  %497 = add nuw nsw i32 %496, %493
  %498 = icmp eq i32 %497, 2
  %499 = zext i1 %498 to i8
  store i8 %499, i8* %55, align 1, !tbaa !2450
  %500 = add i64 %473, 9
  store i64 %500, i64* %PC, align 8
  store i32 %477, i32* %475, align 4
  %501 = load i64, i64* %PC, align 8
  %502 = add i64 %501, -1008
  store i64 %502, i64* %PC, align 8, !tbaa !2428
  br label %block_40129a

block_4012b9:                                     ; preds = %block_4012ad
  %503 = load i32, i32* %1948, align 4
  %504 = shl i32 %503, 1
  %505 = icmp slt i32 %503, 0
  %506 = icmp slt i32 %504, 0
  %507 = xor i1 %505, %506
  %508 = zext i32 %504 to i64
  store i64 %508, i64* %RAX, align 8, !tbaa !2428
  %.lobit14 = lshr i32 %503, 31
  %509 = trunc i32 %.lobit14 to i8
  store i8 %509, i8* %50, align 1, !tbaa !2453
  %510 = and i32 %504, 254
  %511 = tail call i32 @llvm.ctpop.i32(i32 %510) #14
  %512 = trunc i32 %511 to i8
  %513 = and i8 %512, 1
  %514 = xor i8 %513, 1
  store i8 %514, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %515 = icmp eq i32 %504, 0
  %516 = zext i1 %515 to i8
  store i8 %516, i8* %53, align 1, !tbaa !2453
  %517 = lshr i32 %503, 30
  %518 = trunc i32 %517 to i8
  %519 = and i8 %518, 1
  store i8 %519, i8* %54, align 1, !tbaa !2453
  %520 = zext i1 %507 to i8
  store i8 %520, i8* %55, align 1, !tbaa !2453
  %521 = add i64 %1945, -16
  %522 = add i64 %1981, 10
  store i64 %522, i64* %PC, align 8
  %523 = inttoptr i64 %521 to i64*
  %524 = load i64, i64* %523, align 8
  store i64 %524, i64* %RCX, align 8, !tbaa !2428
  %525 = add i64 %1981, 14
  store i64 %525, i64* %PC, align 8
  %526 = load i32, i32* %1953, align 4
  %527 = sext i32 %526 to i64
  store i64 %527, i64* %RDX, align 8, !tbaa !2428
  %528 = shl nsw i64 %527, 2
  %529 = add i64 %524, %528
  %530 = add i64 %1981, 17
  store i64 %530, i64* %PC, align 8
  %531 = inttoptr i64 %529 to i32*
  %532 = load i32, i32* %531, align 4
  %533 = add i32 %532, %504
  %534 = zext i32 %533 to i64
  store i64 %534, i64* %RAX, align 8, !tbaa !2428
  %535 = icmp ult i32 %533, %504
  %536 = icmp ult i32 %533, %532
  %537 = or i1 %535, %536
  %538 = zext i1 %537 to i8
  store i8 %538, i8* %50, align 1, !tbaa !2432
  %539 = and i32 %533, 255
  %540 = tail call i32 @llvm.ctpop.i32(i32 %539) #14
  %541 = trunc i32 %540 to i8
  %542 = and i8 %541, 1
  %543 = xor i8 %542, 1
  store i8 %543, i8* %51, align 1, !tbaa !2446
  %544 = xor i32 %532, %504
  %545 = xor i32 %544, %533
  %546 = lshr i32 %545, 4
  %547 = trunc i32 %546 to i8
  %548 = and i8 %547, 1
  store i8 %548, i8* %52, align 1, !tbaa !2447
  %549 = icmp eq i32 %533, 0
  %550 = zext i1 %549 to i8
  store i8 %550, i8* %53, align 1, !tbaa !2448
  %551 = lshr i32 %533, 31
  %552 = trunc i32 %551 to i8
  store i8 %552, i8* %54, align 1, !tbaa !2449
  %553 = lshr i32 %503, 30
  %554 = and i32 %553, 1
  %555 = lshr i32 %532, 31
  %556 = xor i32 %551, %554
  %557 = xor i32 %551, %555
  %558 = add nuw nsw i32 %556, %557
  %559 = icmp eq i32 %558, 2
  %560 = zext i1 %559 to i8
  store i8 %560, i8* %55, align 1, !tbaa !2450
  %561 = add i64 %1945, -32
  %562 = add i64 %1981, 20
  store i64 %562, i64* %PC, align 8
  %563 = inttoptr i64 %561 to i32*
  store i32 %533, i32* %563, align 4
  %564 = load i64, i64* %RBP, align 8
  %565 = add i64 %564, -36
  %566 = load i64, i64* %PC, align 8
  %567 = add i64 %566, 3
  store i64 %567, i64* %PC, align 8
  %568 = inttoptr i64 %565 to i32*
  %569 = load i32, i32* %568, align 4
  %570 = shl i32 %569, 1
  %571 = icmp slt i32 %569, 0
  %572 = icmp slt i32 %570, 0
  %573 = xor i1 %571, %572
  %574 = zext i32 %570 to i64
  store i64 %574, i64* %RAX, align 8, !tbaa !2428
  %.lobit15 = lshr i32 %569, 31
  %575 = trunc i32 %.lobit15 to i8
  store i8 %575, i8* %50, align 1, !tbaa !2453
  %576 = and i32 %570, 254
  %577 = tail call i32 @llvm.ctpop.i32(i32 %576) #14
  %578 = trunc i32 %577 to i8
  %579 = and i8 %578, 1
  %580 = xor i8 %579, 1
  store i8 %580, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %581 = icmp eq i32 %570, 0
  %582 = zext i1 %581 to i8
  store i8 %582, i8* %53, align 1, !tbaa !2453
  %583 = lshr i32 %569, 30
  %584 = trunc i32 %583 to i8
  %585 = and i8 %584, 1
  store i8 %585, i8* %54, align 1, !tbaa !2453
  %586 = zext i1 %573 to i8
  store i8 %586, i8* %55, align 1, !tbaa !2453
  %587 = add i64 %564, -16
  %588 = add i64 %566, 10
  store i64 %588, i64* %PC, align 8
  %589 = inttoptr i64 %587 to i64*
  %590 = load i64, i64* %589, align 8
  store i64 %590, i64* %RCX, align 8, !tbaa !2428
  %591 = add i64 %564, -28
  %592 = add i64 %566, 14
  store i64 %592, i64* %PC, align 8
  %593 = inttoptr i64 %591 to i32*
  %594 = load i32, i32* %593, align 4
  %595 = sext i32 %594 to i64
  store i64 %595, i64* %RDX, align 8, !tbaa !2428
  %596 = shl nsw i64 %595, 2
  %597 = add i64 %590, %596
  %598 = add i64 %566, 17
  store i64 %598, i64* %PC, align 8
  %599 = inttoptr i64 %597 to i32*
  %600 = load i32, i32* %599, align 4
  %601 = add i32 %600, %570
  %602 = zext i32 %601 to i64
  store i64 %602, i64* %RAX, align 8, !tbaa !2428
  %603 = icmp ult i32 %601, %570
  %604 = icmp ult i32 %601, %600
  %605 = or i1 %603, %604
  %606 = zext i1 %605 to i8
  store i8 %606, i8* %50, align 1, !tbaa !2432
  %607 = and i32 %601, 255
  %608 = tail call i32 @llvm.ctpop.i32(i32 %607) #14
  %609 = trunc i32 %608 to i8
  %610 = and i8 %609, 1
  %611 = xor i8 %610, 1
  store i8 %611, i8* %51, align 1, !tbaa !2446
  %612 = xor i32 %600, %570
  %613 = xor i32 %612, %601
  %614 = lshr i32 %613, 4
  %615 = trunc i32 %614 to i8
  %616 = and i8 %615, 1
  store i8 %616, i8* %52, align 1, !tbaa !2447
  %617 = icmp eq i32 %601, 0
  %618 = zext i1 %617 to i8
  store i8 %618, i8* %53, align 1, !tbaa !2448
  %619 = lshr i32 %601, 31
  %620 = trunc i32 %619 to i8
  store i8 %620, i8* %54, align 1, !tbaa !2449
  %621 = lshr i32 %569, 30
  %622 = and i32 %621, 1
  %623 = lshr i32 %600, 31
  %624 = xor i32 %619, %622
  %625 = xor i32 %619, %623
  %626 = add nuw nsw i32 %624, %625
  %627 = icmp eq i32 %626, 2
  %628 = zext i1 %627 to i8
  store i8 %628, i8* %55, align 1, !tbaa !2450
  %629 = add i64 %564, -40
  %630 = add i64 %566, 20
  store i64 %630, i64* %PC, align 8
  %631 = inttoptr i64 %629 to i32*
  store i32 %601, i32* %631, align 4
  %632 = load i64, i64* %RBP, align 8
  %633 = add i64 %632, -24
  %634 = load i64, i64* %PC, align 8
  %635 = add i64 %634, 4
  store i64 %635, i64* %PC, align 8
  %636 = inttoptr i64 %633 to i64*
  %637 = load i64, i64* %636, align 8
  store i64 %637, i64* %RCX, align 8, !tbaa !2428
  %638 = add i64 %632, -32
  %639 = add i64 %634, 8
  store i64 %639, i64* %PC, align 8
  %640 = inttoptr i64 %638 to i32*
  %641 = load i32, i32* %640, align 4
  %642 = sext i32 %641 to i64
  store i64 %642, i64* %RDX, align 8, !tbaa !2428
  %643 = shl nsw i64 %642, 3
  %644 = add i64 %643, %637
  %645 = add i64 %634, 13
  store i64 %645, i64* %PC, align 8
  %646 = inttoptr i64 %644 to i64*
  %647 = load i64, i64* %646, align 8
  store i64 %647, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %648 = add i64 %632, -64
  %649 = add i64 %634, 18
  store i64 %649, i64* %PC, align 8
  %650 = inttoptr i64 %648 to i64*
  store i64 %647, i64* %650, align 8
  %651 = load i64, i64* %RBP, align 8
  %652 = add i64 %651, -24
  %653 = load i64, i64* %PC, align 8
  %654 = add i64 %653, 4
  store i64 %654, i64* %PC, align 8
  %655 = inttoptr i64 %652 to i64*
  %656 = load i64, i64* %655, align 8
  store i64 %656, i64* %RCX, align 8, !tbaa !2428
  %657 = add i64 %651, -32
  %658 = add i64 %653, 7
  store i64 %658, i64* %PC, align 8
  %659 = inttoptr i64 %657 to i32*
  %660 = load i32, i32* %659, align 4
  %661 = add i32 %660, 1
  %662 = zext i32 %661 to i64
  store i64 %662, i64* %RAX, align 8, !tbaa !2428
  %663 = icmp eq i32 %660, -1
  %664 = icmp eq i32 %661, 0
  %665 = or i1 %663, %664
  %666 = zext i1 %665 to i8
  store i8 %666, i8* %50, align 1, !tbaa !2432
  %667 = and i32 %661, 255
  %668 = tail call i32 @llvm.ctpop.i32(i32 %667) #14
  %669 = trunc i32 %668 to i8
  %670 = and i8 %669, 1
  %671 = xor i8 %670, 1
  store i8 %671, i8* %51, align 1, !tbaa !2446
  %672 = xor i32 %661, %660
  %673 = lshr i32 %672, 4
  %674 = trunc i32 %673 to i8
  %675 = and i8 %674, 1
  store i8 %675, i8* %52, align 1, !tbaa !2447
  %676 = zext i1 %664 to i8
  store i8 %676, i8* %53, align 1, !tbaa !2448
  %677 = lshr i32 %661, 31
  %678 = trunc i32 %677 to i8
  store i8 %678, i8* %54, align 1, !tbaa !2449
  %679 = lshr i32 %660, 31
  %680 = xor i32 %677, %679
  %681 = add nuw nsw i32 %680, %677
  %682 = icmp eq i32 %681, 2
  %683 = zext i1 %682 to i8
  store i8 %683, i8* %55, align 1, !tbaa !2450
  %684 = sext i32 %661 to i64
  store i64 %684, i64* %RDX, align 8, !tbaa !2428
  %685 = shl nsw i64 %684, 3
  %686 = add i64 %656, %685
  %687 = add i64 %653, 18
  store i64 %687, i64* %PC, align 8
  %688 = inttoptr i64 %686 to i64*
  %689 = load i64, i64* %688, align 8
  store i64 %689, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %690 = add i64 %651, -72
  %691 = add i64 %653, 23
  store i64 %691, i64* %PC, align 8
  %692 = inttoptr i64 %690 to i64*
  store i64 %689, i64* %692, align 8
  %693 = load i64, i64* %RBP, align 8
  %694 = add i64 %693, -24
  %695 = load i64, i64* %PC, align 8
  %696 = add i64 %695, 4
  store i64 %696, i64* %PC, align 8
  %697 = inttoptr i64 %694 to i64*
  %698 = load i64, i64* %697, align 8
  store i64 %698, i64* %RCX, align 8, !tbaa !2428
  %699 = add i64 %693, -40
  %700 = add i64 %695, 8
  store i64 %700, i64* %PC, align 8
  %701 = inttoptr i64 %699 to i32*
  %702 = load i32, i32* %701, align 4
  %703 = sext i32 %702 to i64
  store i64 %703, i64* %RDX, align 8, !tbaa !2428
  %704 = shl nsw i64 %703, 3
  %705 = add i64 %704, %698
  %706 = add i64 %695, 13
  store i64 %706, i64* %PC, align 8
  %707 = inttoptr i64 %705 to i64*
  %708 = load i64, i64* %707, align 8
  store i64 %708, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %709 = add i64 %693, -80
  %710 = add i64 %695, 18
  store i64 %710, i64* %PC, align 8
  %711 = inttoptr i64 %709 to i64*
  store i64 %708, i64* %711, align 8
  %712 = load i64, i64* %RBP, align 8
  %713 = add i64 %712, -24
  %714 = load i64, i64* %PC, align 8
  %715 = add i64 %714, 4
  store i64 %715, i64* %PC, align 8
  %716 = inttoptr i64 %713 to i64*
  %717 = load i64, i64* %716, align 8
  store i64 %717, i64* %RCX, align 8, !tbaa !2428
  %718 = add i64 %712, -40
  %719 = add i64 %714, 7
  store i64 %719, i64* %PC, align 8
  %720 = inttoptr i64 %718 to i32*
  %721 = load i32, i32* %720, align 4
  %722 = add i32 %721, 1
  %723 = zext i32 %722 to i64
  store i64 %723, i64* %RAX, align 8, !tbaa !2428
  %724 = icmp eq i32 %721, -1
  %725 = icmp eq i32 %722, 0
  %726 = or i1 %724, %725
  %727 = zext i1 %726 to i8
  store i8 %727, i8* %50, align 1, !tbaa !2432
  %728 = and i32 %722, 255
  %729 = tail call i32 @llvm.ctpop.i32(i32 %728) #14
  %730 = trunc i32 %729 to i8
  %731 = and i8 %730, 1
  %732 = xor i8 %731, 1
  store i8 %732, i8* %51, align 1, !tbaa !2446
  %733 = xor i32 %722, %721
  %734 = lshr i32 %733, 4
  %735 = trunc i32 %734 to i8
  %736 = and i8 %735, 1
  store i8 %736, i8* %52, align 1, !tbaa !2447
  %737 = zext i1 %725 to i8
  store i8 %737, i8* %53, align 1, !tbaa !2448
  %738 = lshr i32 %722, 31
  %739 = trunc i32 %738 to i8
  store i8 %739, i8* %54, align 1, !tbaa !2449
  %740 = lshr i32 %721, 31
  %741 = xor i32 %738, %740
  %742 = add nuw nsw i32 %741, %738
  %743 = icmp eq i32 %742, 2
  %744 = zext i1 %743 to i8
  store i8 %744, i8* %55, align 1, !tbaa !2450
  %745 = sext i32 %722 to i64
  store i64 %745, i64* %RDX, align 8, !tbaa !2428
  %746 = shl nsw i64 %745, 3
  %747 = add i64 %717, %746
  %748 = add i64 %714, 18
  store i64 %748, i64* %PC, align 8
  %749 = inttoptr i64 %747 to i64*
  %750 = load i64, i64* %749, align 8
  store i64 %750, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %751 = add i64 %712, -88
  %752 = add i64 %714, 23
  store i64 %752, i64* %PC, align 8
  %753 = inttoptr i64 %751 to i64*
  store i64 %750, i64* %753, align 8
  %754 = load i64, i64* %RBP, align 8
  %755 = add i64 %754, -80
  %756 = load i64, i64* %PC, align 8
  %757 = add i64 %756, 5
  store i64 %757, i64* %PC, align 8
  %758 = inttoptr i64 %755 to i64*
  %759 = load i64, i64* %758, align 8
  store i64 %759, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %760 = add i64 %754, -24
  %761 = add i64 %756, 9
  store i64 %761, i64* %PC, align 8
  %762 = inttoptr i64 %760 to i64*
  %763 = load i64, i64* %762, align 8
  store i64 %763, i64* %RCX, align 8, !tbaa !2428
  %764 = add i64 %754, -32
  %765 = add i64 %756, 13
  store i64 %765, i64* %PC, align 8
  %766 = inttoptr i64 %764 to i32*
  %767 = load i32, i32* %766, align 4
  %768 = sext i32 %767 to i64
  store i64 %768, i64* %RDX, align 8, !tbaa !2428
  %769 = shl nsw i64 %768, 3
  %770 = add i64 %769, %763
  %771 = add i64 %756, 18
  store i64 %771, i64* %PC, align 8
  %772 = inttoptr i64 %770 to i64*
  store i64 %759, i64* %772, align 8
  %773 = load i64, i64* %RBP, align 8
  %774 = add i64 %773, -88
  %775 = load i64, i64* %PC, align 8
  %776 = add i64 %775, 5
  store i64 %776, i64* %PC, align 8
  %777 = inttoptr i64 %774 to i64*
  %778 = load i64, i64* %777, align 8
  store i64 %778, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %779 = add i64 %773, -24
  %780 = add i64 %775, 9
  store i64 %780, i64* %PC, align 8
  %781 = inttoptr i64 %779 to i64*
  %782 = load i64, i64* %781, align 8
  store i64 %782, i64* %RCX, align 8, !tbaa !2428
  %783 = add i64 %773, -32
  %784 = add i64 %775, 12
  store i64 %784, i64* %PC, align 8
  %785 = inttoptr i64 %783 to i32*
  %786 = load i32, i32* %785, align 4
  %787 = add i32 %786, 1
  %788 = zext i32 %787 to i64
  store i64 %788, i64* %RAX, align 8, !tbaa !2428
  %789 = icmp eq i32 %786, -1
  %790 = icmp eq i32 %787, 0
  %791 = or i1 %789, %790
  %792 = zext i1 %791 to i8
  store i8 %792, i8* %50, align 1, !tbaa !2432
  %793 = and i32 %787, 255
  %794 = tail call i32 @llvm.ctpop.i32(i32 %793) #14
  %795 = trunc i32 %794 to i8
  %796 = and i8 %795, 1
  %797 = xor i8 %796, 1
  store i8 %797, i8* %51, align 1, !tbaa !2446
  %798 = xor i32 %787, %786
  %799 = lshr i32 %798, 4
  %800 = trunc i32 %799 to i8
  %801 = and i8 %800, 1
  store i8 %801, i8* %52, align 1, !tbaa !2447
  %802 = zext i1 %790 to i8
  store i8 %802, i8* %53, align 1, !tbaa !2448
  %803 = lshr i32 %787, 31
  %804 = trunc i32 %803 to i8
  store i8 %804, i8* %54, align 1, !tbaa !2449
  %805 = lshr i32 %786, 31
  %806 = xor i32 %803, %805
  %807 = add nuw nsw i32 %806, %803
  %808 = icmp eq i32 %807, 2
  %809 = zext i1 %808 to i8
  store i8 %809, i8* %55, align 1, !tbaa !2450
  %810 = sext i32 %787 to i64
  store i64 %810, i64* %RDX, align 8, !tbaa !2428
  %811 = shl nsw i64 %810, 3
  %812 = add i64 %782, %811
  %813 = add i64 %775, 23
  store i64 %813, i64* %PC, align 8
  %814 = inttoptr i64 %812 to i64*
  store i64 %778, i64* %814, align 8
  %815 = load i64, i64* %RBP, align 8
  %816 = add i64 %815, -64
  %817 = load i64, i64* %PC, align 8
  %818 = add i64 %817, 5
  store i64 %818, i64* %PC, align 8
  %819 = inttoptr i64 %816 to i64*
  %820 = load i64, i64* %819, align 8
  store i64 %820, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %821 = add i64 %815, -24
  %822 = add i64 %817, 9
  store i64 %822, i64* %PC, align 8
  %823 = inttoptr i64 %821 to i64*
  %824 = load i64, i64* %823, align 8
  store i64 %824, i64* %RCX, align 8, !tbaa !2428
  %825 = add i64 %815, -40
  %826 = add i64 %817, 13
  store i64 %826, i64* %PC, align 8
  %827 = inttoptr i64 %825 to i32*
  %828 = load i32, i32* %827, align 4
  %829 = sext i32 %828 to i64
  store i64 %829, i64* %RDX, align 8, !tbaa !2428
  %830 = shl nsw i64 %829, 3
  %831 = add i64 %830, %824
  %832 = add i64 %817, 18
  store i64 %832, i64* %PC, align 8
  %833 = inttoptr i64 %831 to i64*
  store i64 %820, i64* %833, align 8
  %834 = load i64, i64* %RBP, align 8
  %835 = add i64 %834, -72
  %836 = load i64, i64* %PC, align 8
  %837 = add i64 %836, 5
  store i64 %837, i64* %PC, align 8
  %838 = inttoptr i64 %835 to i64*
  %839 = load i64, i64* %838, align 8
  store i64 %839, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %840 = add i64 %834, -24
  %841 = add i64 %836, 9
  store i64 %841, i64* %PC, align 8
  %842 = inttoptr i64 %840 to i64*
  %843 = load i64, i64* %842, align 8
  store i64 %843, i64* %RCX, align 8, !tbaa !2428
  %844 = add i64 %834, -40
  %845 = add i64 %836, 12
  store i64 %845, i64* %PC, align 8
  %846 = inttoptr i64 %844 to i32*
  %847 = load i32, i32* %846, align 4
  %848 = add i32 %847, 1
  %849 = zext i32 %848 to i64
  store i64 %849, i64* %RAX, align 8, !tbaa !2428
  %850 = icmp eq i32 %847, -1
  %851 = icmp eq i32 %848, 0
  %852 = or i1 %850, %851
  %853 = zext i1 %852 to i8
  store i8 %853, i8* %50, align 1, !tbaa !2432
  %854 = and i32 %848, 255
  %855 = tail call i32 @llvm.ctpop.i32(i32 %854) #14
  %856 = trunc i32 %855 to i8
  %857 = and i8 %856, 1
  %858 = xor i8 %857, 1
  store i8 %858, i8* %51, align 1, !tbaa !2446
  %859 = xor i32 %848, %847
  %860 = lshr i32 %859, 4
  %861 = trunc i32 %860 to i8
  %862 = and i8 %861, 1
  store i8 %862, i8* %52, align 1, !tbaa !2447
  %863 = zext i1 %851 to i8
  store i8 %863, i8* %53, align 1, !tbaa !2448
  %864 = lshr i32 %848, 31
  %865 = trunc i32 %864 to i8
  store i8 %865, i8* %54, align 1, !tbaa !2449
  %866 = lshr i32 %847, 31
  %867 = xor i32 %864, %866
  %868 = add nuw nsw i32 %867, %864
  %869 = icmp eq i32 %868, 2
  %870 = zext i1 %869 to i8
  store i8 %870, i8* %55, align 1, !tbaa !2450
  %871 = sext i32 %848 to i64
  store i64 %871, i64* %RDX, align 8, !tbaa !2428
  %872 = shl nsw i64 %871, 3
  %873 = add i64 %843, %872
  %874 = add i64 %836, 23
  store i64 %874, i64* %PC, align 8
  %875 = inttoptr i64 %873 to i64*
  store i64 %839, i64* %875, align 8
  %876 = load i64, i64* %RBP, align 8
  %877 = add i64 %876, -52
  %878 = load i64, i64* %PC, align 8
  %879 = add i64 %878, 3
  store i64 %879, i64* %PC, align 8
  %880 = inttoptr i64 %877 to i32*
  %881 = load i32, i32* %880, align 4
  %882 = zext i32 %881 to i64
  store i64 %882, i64* %RAX, align 8, !tbaa !2428
  %883 = add i64 %876, -32
  %884 = add i64 %878, 6
  store i64 %884, i64* %PC, align 8
  %885 = inttoptr i64 %883 to i32*
  %886 = load i32, i32* %885, align 4
  %887 = add i32 %886, %881
  %888 = zext i32 %887 to i64
  store i64 %888, i64* %RAX, align 8, !tbaa !2428
  %889 = icmp ult i32 %887, %881
  %890 = icmp ult i32 %887, %886
  %891 = or i1 %889, %890
  %892 = zext i1 %891 to i8
  store i8 %892, i8* %50, align 1, !tbaa !2432
  %893 = and i32 %887, 255
  %894 = tail call i32 @llvm.ctpop.i32(i32 %893) #14
  %895 = trunc i32 %894 to i8
  %896 = and i8 %895, 1
  %897 = xor i8 %896, 1
  store i8 %897, i8* %51, align 1, !tbaa !2446
  %898 = xor i32 %886, %881
  %899 = xor i32 %898, %887
  %900 = lshr i32 %899, 4
  %901 = trunc i32 %900 to i8
  %902 = and i8 %901, 1
  store i8 %902, i8* %52, align 1, !tbaa !2447
  %903 = icmp eq i32 %887, 0
  %904 = zext i1 %903 to i8
  store i8 %904, i8* %53, align 1, !tbaa !2448
  %905 = lshr i32 %887, 31
  %906 = trunc i32 %905 to i8
  store i8 %906, i8* %54, align 1, !tbaa !2449
  %907 = lshr i32 %881, 31
  %908 = lshr i32 %886, 31
  %909 = xor i32 %905, %907
  %910 = xor i32 %905, %908
  %911 = add nuw nsw i32 %909, %910
  %912 = icmp eq i32 %911, 2
  %913 = zext i1 %912 to i8
  store i8 %913, i8* %55, align 1, !tbaa !2450
  %914 = add i64 %878, 9
  store i64 %914, i64* %PC, align 8
  store i32 %887, i32* %885, align 4
  %915 = load i64, i64* %RBP, align 8
  %916 = add i64 %915, -52
  %917 = load i64, i64* %PC, align 8
  %918 = add i64 %917, 3
  store i64 %918, i64* %PC, align 8
  %919 = inttoptr i64 %916 to i32*
  %920 = load i32, i32* %919, align 4
  %921 = shl i32 %920, 1
  %922 = icmp slt i32 %920, 0
  %923 = icmp slt i32 %921, 0
  %924 = xor i1 %922, %923
  %925 = zext i32 %921 to i64
  store i64 %925, i64* %RAX, align 8, !tbaa !2428
  %.lobit16 = lshr i32 %920, 31
  %926 = trunc i32 %.lobit16 to i8
  store i8 %926, i8* %50, align 1, !tbaa !2453
  %927 = and i32 %921, 254
  %928 = tail call i32 @llvm.ctpop.i32(i32 %927) #14
  %929 = trunc i32 %928 to i8
  %930 = and i8 %929, 1
  %931 = xor i8 %930, 1
  store i8 %931, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %932 = icmp eq i32 %921, 0
  %933 = zext i1 %932 to i8
  store i8 %933, i8* %53, align 1, !tbaa !2453
  %934 = lshr i32 %920, 30
  %935 = trunc i32 %934 to i8
  %936 = and i8 %935, 1
  store i8 %936, i8* %54, align 1, !tbaa !2453
  %937 = zext i1 %924 to i8
  store i8 %937, i8* %55, align 1, !tbaa !2453
  %938 = add i64 %915, -40
  %939 = add i64 %917, 9
  store i64 %939, i64* %PC, align 8
  %940 = inttoptr i64 %938 to i32*
  %941 = load i32, i32* %940, align 4
  %942 = add i32 %941, %921
  %943 = zext i32 %942 to i64
  store i64 %943, i64* %RAX, align 8, !tbaa !2428
  %944 = icmp ult i32 %942, %921
  %945 = icmp ult i32 %942, %941
  %946 = or i1 %944, %945
  %947 = zext i1 %946 to i8
  store i8 %947, i8* %50, align 1, !tbaa !2432
  %948 = and i32 %942, 255
  %949 = tail call i32 @llvm.ctpop.i32(i32 %948) #14
  %950 = trunc i32 %949 to i8
  %951 = and i8 %950, 1
  %952 = xor i8 %951, 1
  store i8 %952, i8* %51, align 1, !tbaa !2446
  %953 = xor i32 %941, %921
  %954 = xor i32 %953, %942
  %955 = lshr i32 %954, 4
  %956 = trunc i32 %955 to i8
  %957 = and i8 %956, 1
  store i8 %957, i8* %52, align 1, !tbaa !2447
  %958 = icmp eq i32 %942, 0
  %959 = zext i1 %958 to i8
  store i8 %959, i8* %53, align 1, !tbaa !2448
  %960 = lshr i32 %942, 31
  %961 = trunc i32 %960 to i8
  store i8 %961, i8* %54, align 1, !tbaa !2449
  %962 = lshr i32 %920, 30
  %963 = and i32 %962, 1
  %964 = lshr i32 %941, 31
  %965 = xor i32 %960, %963
  %966 = xor i32 %960, %964
  %967 = add nuw nsw i32 %965, %966
  %968 = icmp eq i32 %967, 2
  %969 = zext i1 %968 to i8
  store i8 %969, i8* %55, align 1, !tbaa !2450
  %970 = add i64 %917, 12
  store i64 %970, i64* %PC, align 8
  store i32 %942, i32* %940, align 4
  %971 = load i64, i64* %RBP, align 8
  %972 = add i64 %971, -24
  %973 = load i64, i64* %PC, align 8
  %974 = add i64 %973, 4
  store i64 %974, i64* %PC, align 8
  %975 = inttoptr i64 %972 to i64*
  %976 = load i64, i64* %975, align 8
  store i64 %976, i64* %RCX, align 8, !tbaa !2428
  %977 = add i64 %971, -32
  %978 = add i64 %973, 8
  store i64 %978, i64* %PC, align 8
  %979 = inttoptr i64 %977 to i32*
  %980 = load i32, i32* %979, align 4
  %981 = sext i32 %980 to i64
  store i64 %981, i64* %RDX, align 8, !tbaa !2428
  %982 = shl nsw i64 %981, 3
  %983 = add i64 %982, %976
  %984 = add i64 %973, 13
  store i64 %984, i64* %PC, align 8
  %985 = inttoptr i64 %983 to i64*
  %986 = load i64, i64* %985, align 8
  store i64 %986, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %987 = add i64 %971, -64
  %988 = add i64 %973, 18
  store i64 %988, i64* %PC, align 8
  %989 = inttoptr i64 %987 to i64*
  store i64 %986, i64* %989, align 8
  %990 = load i64, i64* %RBP, align 8
  %991 = add i64 %990, -24
  %992 = load i64, i64* %PC, align 8
  %993 = add i64 %992, 4
  store i64 %993, i64* %PC, align 8
  %994 = inttoptr i64 %991 to i64*
  %995 = load i64, i64* %994, align 8
  store i64 %995, i64* %RCX, align 8, !tbaa !2428
  %996 = add i64 %990, -32
  %997 = add i64 %992, 7
  store i64 %997, i64* %PC, align 8
  %998 = inttoptr i64 %996 to i32*
  %999 = load i32, i32* %998, align 4
  %1000 = add i32 %999, 1
  %1001 = zext i32 %1000 to i64
  store i64 %1001, i64* %RAX, align 8, !tbaa !2428
  %1002 = icmp eq i32 %999, -1
  %1003 = icmp eq i32 %1000, 0
  %1004 = or i1 %1002, %1003
  %1005 = zext i1 %1004 to i8
  store i8 %1005, i8* %50, align 1, !tbaa !2432
  %1006 = and i32 %1000, 255
  %1007 = tail call i32 @llvm.ctpop.i32(i32 %1006) #14
  %1008 = trunc i32 %1007 to i8
  %1009 = and i8 %1008, 1
  %1010 = xor i8 %1009, 1
  store i8 %1010, i8* %51, align 1, !tbaa !2446
  %1011 = xor i32 %1000, %999
  %1012 = lshr i32 %1011, 4
  %1013 = trunc i32 %1012 to i8
  %1014 = and i8 %1013, 1
  store i8 %1014, i8* %52, align 1, !tbaa !2447
  %1015 = zext i1 %1003 to i8
  store i8 %1015, i8* %53, align 1, !tbaa !2448
  %1016 = lshr i32 %1000, 31
  %1017 = trunc i32 %1016 to i8
  store i8 %1017, i8* %54, align 1, !tbaa !2449
  %1018 = lshr i32 %999, 31
  %1019 = xor i32 %1016, %1018
  %1020 = add nuw nsw i32 %1019, %1016
  %1021 = icmp eq i32 %1020, 2
  %1022 = zext i1 %1021 to i8
  store i8 %1022, i8* %55, align 1, !tbaa !2450
  %1023 = sext i32 %1000 to i64
  store i64 %1023, i64* %RDX, align 8, !tbaa !2428
  %1024 = shl nsw i64 %1023, 3
  %1025 = add i64 %995, %1024
  %1026 = add i64 %992, 18
  store i64 %1026, i64* %PC, align 8
  %1027 = inttoptr i64 %1025 to i64*
  %1028 = load i64, i64* %1027, align 8
  store i64 %1028, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1029 = add i64 %990, -72
  %1030 = add i64 %992, 23
  store i64 %1030, i64* %PC, align 8
  %1031 = inttoptr i64 %1029 to i64*
  store i64 %1028, i64* %1031, align 8
  %1032 = load i64, i64* %RBP, align 8
  %1033 = add i64 %1032, -24
  %1034 = load i64, i64* %PC, align 8
  %1035 = add i64 %1034, 4
  store i64 %1035, i64* %PC, align 8
  %1036 = inttoptr i64 %1033 to i64*
  %1037 = load i64, i64* %1036, align 8
  store i64 %1037, i64* %RCX, align 8, !tbaa !2428
  %1038 = add i64 %1032, -40
  %1039 = add i64 %1034, 8
  store i64 %1039, i64* %PC, align 8
  %1040 = inttoptr i64 %1038 to i32*
  %1041 = load i32, i32* %1040, align 4
  %1042 = sext i32 %1041 to i64
  store i64 %1042, i64* %RDX, align 8, !tbaa !2428
  %1043 = shl nsw i64 %1042, 3
  %1044 = add i64 %1043, %1037
  %1045 = add i64 %1034, 13
  store i64 %1045, i64* %PC, align 8
  %1046 = inttoptr i64 %1044 to i64*
  %1047 = load i64, i64* %1046, align 8
  store i64 %1047, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1048 = add i64 %1032, -80
  %1049 = add i64 %1034, 18
  store i64 %1049, i64* %PC, align 8
  %1050 = inttoptr i64 %1048 to i64*
  store i64 %1047, i64* %1050, align 8
  %1051 = load i64, i64* %RBP, align 8
  %1052 = add i64 %1051, -24
  %1053 = load i64, i64* %PC, align 8
  %1054 = add i64 %1053, 4
  store i64 %1054, i64* %PC, align 8
  %1055 = inttoptr i64 %1052 to i64*
  %1056 = load i64, i64* %1055, align 8
  store i64 %1056, i64* %RCX, align 8, !tbaa !2428
  %1057 = add i64 %1051, -40
  %1058 = add i64 %1053, 7
  store i64 %1058, i64* %PC, align 8
  %1059 = inttoptr i64 %1057 to i32*
  %1060 = load i32, i32* %1059, align 4
  %1061 = add i32 %1060, 1
  %1062 = zext i32 %1061 to i64
  store i64 %1062, i64* %RAX, align 8, !tbaa !2428
  %1063 = icmp eq i32 %1060, -1
  %1064 = icmp eq i32 %1061, 0
  %1065 = or i1 %1063, %1064
  %1066 = zext i1 %1065 to i8
  store i8 %1066, i8* %50, align 1, !tbaa !2432
  %1067 = and i32 %1061, 255
  %1068 = tail call i32 @llvm.ctpop.i32(i32 %1067) #14
  %1069 = trunc i32 %1068 to i8
  %1070 = and i8 %1069, 1
  %1071 = xor i8 %1070, 1
  store i8 %1071, i8* %51, align 1, !tbaa !2446
  %1072 = xor i32 %1061, %1060
  %1073 = lshr i32 %1072, 4
  %1074 = trunc i32 %1073 to i8
  %1075 = and i8 %1074, 1
  store i8 %1075, i8* %52, align 1, !tbaa !2447
  %1076 = zext i1 %1064 to i8
  store i8 %1076, i8* %53, align 1, !tbaa !2448
  %1077 = lshr i32 %1061, 31
  %1078 = trunc i32 %1077 to i8
  store i8 %1078, i8* %54, align 1, !tbaa !2449
  %1079 = lshr i32 %1060, 31
  %1080 = xor i32 %1077, %1079
  %1081 = add nuw nsw i32 %1080, %1077
  %1082 = icmp eq i32 %1081, 2
  %1083 = zext i1 %1082 to i8
  store i8 %1083, i8* %55, align 1, !tbaa !2450
  %1084 = sext i32 %1061 to i64
  store i64 %1084, i64* %RDX, align 8, !tbaa !2428
  %1085 = shl nsw i64 %1084, 3
  %1086 = add i64 %1056, %1085
  %1087 = add i64 %1053, 18
  store i64 %1087, i64* %PC, align 8
  %1088 = inttoptr i64 %1086 to i64*
  %1089 = load i64, i64* %1088, align 8
  store i64 %1089, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1090 = add i64 %1051, -88
  %1091 = add i64 %1053, 23
  store i64 %1091, i64* %PC, align 8
  %1092 = inttoptr i64 %1090 to i64*
  store i64 %1089, i64* %1092, align 8
  %1093 = load i64, i64* %RBP, align 8
  %1094 = add i64 %1093, -80
  %1095 = load i64, i64* %PC, align 8
  %1096 = add i64 %1095, 5
  store i64 %1096, i64* %PC, align 8
  %1097 = inttoptr i64 %1094 to i64*
  %1098 = load i64, i64* %1097, align 8
  store i64 %1098, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1099 = add i64 %1093, -24
  %1100 = add i64 %1095, 9
  store i64 %1100, i64* %PC, align 8
  %1101 = inttoptr i64 %1099 to i64*
  %1102 = load i64, i64* %1101, align 8
  store i64 %1102, i64* %RCX, align 8, !tbaa !2428
  %1103 = add i64 %1093, -32
  %1104 = add i64 %1095, 13
  store i64 %1104, i64* %PC, align 8
  %1105 = inttoptr i64 %1103 to i32*
  %1106 = load i32, i32* %1105, align 4
  %1107 = sext i32 %1106 to i64
  store i64 %1107, i64* %RDX, align 8, !tbaa !2428
  %1108 = shl nsw i64 %1107, 3
  %1109 = add i64 %1108, %1102
  %1110 = add i64 %1095, 18
  store i64 %1110, i64* %PC, align 8
  %1111 = inttoptr i64 %1109 to i64*
  store i64 %1098, i64* %1111, align 8
  %1112 = load i64, i64* %RBP, align 8
  %1113 = add i64 %1112, -88
  %1114 = load i64, i64* %PC, align 8
  %1115 = add i64 %1114, 5
  store i64 %1115, i64* %PC, align 8
  %1116 = inttoptr i64 %1113 to i64*
  %1117 = load i64, i64* %1116, align 8
  store i64 %1117, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1118 = add i64 %1112, -24
  %1119 = add i64 %1114, 9
  store i64 %1119, i64* %PC, align 8
  %1120 = inttoptr i64 %1118 to i64*
  %1121 = load i64, i64* %1120, align 8
  store i64 %1121, i64* %RCX, align 8, !tbaa !2428
  %1122 = add i64 %1112, -32
  %1123 = add i64 %1114, 12
  store i64 %1123, i64* %PC, align 8
  %1124 = inttoptr i64 %1122 to i32*
  %1125 = load i32, i32* %1124, align 4
  %1126 = add i32 %1125, 1
  %1127 = zext i32 %1126 to i64
  store i64 %1127, i64* %RAX, align 8, !tbaa !2428
  %1128 = icmp eq i32 %1125, -1
  %1129 = icmp eq i32 %1126, 0
  %1130 = or i1 %1128, %1129
  %1131 = zext i1 %1130 to i8
  store i8 %1131, i8* %50, align 1, !tbaa !2432
  %1132 = and i32 %1126, 255
  %1133 = tail call i32 @llvm.ctpop.i32(i32 %1132) #14
  %1134 = trunc i32 %1133 to i8
  %1135 = and i8 %1134, 1
  %1136 = xor i8 %1135, 1
  store i8 %1136, i8* %51, align 1, !tbaa !2446
  %1137 = xor i32 %1126, %1125
  %1138 = lshr i32 %1137, 4
  %1139 = trunc i32 %1138 to i8
  %1140 = and i8 %1139, 1
  store i8 %1140, i8* %52, align 1, !tbaa !2447
  %1141 = zext i1 %1129 to i8
  store i8 %1141, i8* %53, align 1, !tbaa !2448
  %1142 = lshr i32 %1126, 31
  %1143 = trunc i32 %1142 to i8
  store i8 %1143, i8* %54, align 1, !tbaa !2449
  %1144 = lshr i32 %1125, 31
  %1145 = xor i32 %1142, %1144
  %1146 = add nuw nsw i32 %1145, %1142
  %1147 = icmp eq i32 %1146, 2
  %1148 = zext i1 %1147 to i8
  store i8 %1148, i8* %55, align 1, !tbaa !2450
  %1149 = sext i32 %1126 to i64
  store i64 %1149, i64* %RDX, align 8, !tbaa !2428
  %1150 = shl nsw i64 %1149, 3
  %1151 = add i64 %1121, %1150
  %1152 = add i64 %1114, 23
  store i64 %1152, i64* %PC, align 8
  %1153 = inttoptr i64 %1151 to i64*
  store i64 %1117, i64* %1153, align 8
  %1154 = load i64, i64* %RBP, align 8
  %1155 = add i64 %1154, -64
  %1156 = load i64, i64* %PC, align 8
  %1157 = add i64 %1156, 5
  store i64 %1157, i64* %PC, align 8
  %1158 = inttoptr i64 %1155 to i64*
  %1159 = load i64, i64* %1158, align 8
  store i64 %1159, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1160 = add i64 %1154, -24
  %1161 = add i64 %1156, 9
  store i64 %1161, i64* %PC, align 8
  %1162 = inttoptr i64 %1160 to i64*
  %1163 = load i64, i64* %1162, align 8
  store i64 %1163, i64* %RCX, align 8, !tbaa !2428
  %1164 = add i64 %1154, -40
  %1165 = add i64 %1156, 13
  store i64 %1165, i64* %PC, align 8
  %1166 = inttoptr i64 %1164 to i32*
  %1167 = load i32, i32* %1166, align 4
  %1168 = sext i32 %1167 to i64
  store i64 %1168, i64* %RDX, align 8, !tbaa !2428
  %1169 = shl nsw i64 %1168, 3
  %1170 = add i64 %1169, %1163
  %1171 = add i64 %1156, 18
  store i64 %1171, i64* %PC, align 8
  %1172 = inttoptr i64 %1170 to i64*
  store i64 %1159, i64* %1172, align 8
  %1173 = load i64, i64* %RBP, align 8
  %1174 = add i64 %1173, -72
  %1175 = load i64, i64* %PC, align 8
  %1176 = add i64 %1175, 5
  store i64 %1176, i64* %PC, align 8
  %1177 = inttoptr i64 %1174 to i64*
  %1178 = load i64, i64* %1177, align 8
  store i64 %1178, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1179 = add i64 %1173, -24
  %1180 = add i64 %1175, 9
  store i64 %1180, i64* %PC, align 8
  %1181 = inttoptr i64 %1179 to i64*
  %1182 = load i64, i64* %1181, align 8
  store i64 %1182, i64* %RCX, align 8, !tbaa !2428
  %1183 = add i64 %1173, -40
  %1184 = add i64 %1175, 12
  store i64 %1184, i64* %PC, align 8
  %1185 = inttoptr i64 %1183 to i32*
  %1186 = load i32, i32* %1185, align 4
  %1187 = add i32 %1186, 1
  %1188 = zext i32 %1187 to i64
  store i64 %1188, i64* %RAX, align 8, !tbaa !2428
  %1189 = icmp eq i32 %1186, -1
  %1190 = icmp eq i32 %1187, 0
  %1191 = or i1 %1189, %1190
  %1192 = zext i1 %1191 to i8
  store i8 %1192, i8* %50, align 1, !tbaa !2432
  %1193 = and i32 %1187, 255
  %1194 = tail call i32 @llvm.ctpop.i32(i32 %1193) #14
  %1195 = trunc i32 %1194 to i8
  %1196 = and i8 %1195, 1
  %1197 = xor i8 %1196, 1
  store i8 %1197, i8* %51, align 1, !tbaa !2446
  %1198 = xor i32 %1187, %1186
  %1199 = lshr i32 %1198, 4
  %1200 = trunc i32 %1199 to i8
  %1201 = and i8 %1200, 1
  store i8 %1201, i8* %52, align 1, !tbaa !2447
  %1202 = zext i1 %1190 to i8
  store i8 %1202, i8* %53, align 1, !tbaa !2448
  %1203 = lshr i32 %1187, 31
  %1204 = trunc i32 %1203 to i8
  store i8 %1204, i8* %54, align 1, !tbaa !2449
  %1205 = lshr i32 %1186, 31
  %1206 = xor i32 %1203, %1205
  %1207 = add nuw nsw i32 %1206, %1203
  %1208 = icmp eq i32 %1207, 2
  %1209 = zext i1 %1208 to i8
  store i8 %1209, i8* %55, align 1, !tbaa !2450
  %1210 = sext i32 %1187 to i64
  store i64 %1210, i64* %RDX, align 8, !tbaa !2428
  %1211 = shl nsw i64 %1210, 3
  %1212 = add i64 %1182, %1211
  %1213 = add i64 %1175, 23
  store i64 %1213, i64* %PC, align 8
  %1214 = inttoptr i64 %1212 to i64*
  store i64 %1178, i64* %1214, align 8
  %1215 = load i64, i64* %RBP, align 8
  %1216 = add i64 %1215, -52
  %1217 = load i64, i64* %PC, align 8
  %1218 = add i64 %1217, 3
  store i64 %1218, i64* %PC, align 8
  %1219 = inttoptr i64 %1216 to i32*
  %1220 = load i32, i32* %1219, align 4
  %1221 = zext i32 %1220 to i64
  store i64 %1221, i64* %RAX, align 8, !tbaa !2428
  %1222 = add i64 %1215, -32
  %1223 = add i64 %1217, 6
  store i64 %1223, i64* %PC, align 8
  %1224 = inttoptr i64 %1222 to i32*
  %1225 = load i32, i32* %1224, align 4
  %1226 = add i32 %1225, %1220
  %1227 = zext i32 %1226 to i64
  store i64 %1227, i64* %RAX, align 8, !tbaa !2428
  %1228 = icmp ult i32 %1226, %1220
  %1229 = icmp ult i32 %1226, %1225
  %1230 = or i1 %1228, %1229
  %1231 = zext i1 %1230 to i8
  store i8 %1231, i8* %50, align 1, !tbaa !2432
  %1232 = and i32 %1226, 255
  %1233 = tail call i32 @llvm.ctpop.i32(i32 %1232) #14
  %1234 = trunc i32 %1233 to i8
  %1235 = and i8 %1234, 1
  %1236 = xor i8 %1235, 1
  store i8 %1236, i8* %51, align 1, !tbaa !2446
  %1237 = xor i32 %1225, %1220
  %1238 = xor i32 %1237, %1226
  %1239 = lshr i32 %1238, 4
  %1240 = trunc i32 %1239 to i8
  %1241 = and i8 %1240, 1
  store i8 %1241, i8* %52, align 1, !tbaa !2447
  %1242 = icmp eq i32 %1226, 0
  %1243 = zext i1 %1242 to i8
  store i8 %1243, i8* %53, align 1, !tbaa !2448
  %1244 = lshr i32 %1226, 31
  %1245 = trunc i32 %1244 to i8
  store i8 %1245, i8* %54, align 1, !tbaa !2449
  %1246 = lshr i32 %1220, 31
  %1247 = lshr i32 %1225, 31
  %1248 = xor i32 %1244, %1246
  %1249 = xor i32 %1244, %1247
  %1250 = add nuw nsw i32 %1248, %1249
  %1251 = icmp eq i32 %1250, 2
  %1252 = zext i1 %1251 to i8
  store i8 %1252, i8* %55, align 1, !tbaa !2450
  %1253 = add i64 %1217, 9
  store i64 %1253, i64* %PC, align 8
  store i32 %1226, i32* %1224, align 4
  %1254 = load i64, i64* %RBP, align 8
  %1255 = add i64 %1254, -52
  %1256 = load i64, i64* %PC, align 8
  %1257 = add i64 %1256, 3
  store i64 %1257, i64* %PC, align 8
  %1258 = inttoptr i64 %1255 to i32*
  %1259 = load i32, i32* %1258, align 4
  %1260 = zext i32 %1259 to i64
  store i64 %1260, i64* %RAX, align 8, !tbaa !2428
  %1261 = add i64 %1254, -40
  %1262 = add i64 %1256, 6
  store i64 %1262, i64* %PC, align 8
  %1263 = inttoptr i64 %1261 to i32*
  %1264 = load i32, i32* %1263, align 4
  %1265 = sub i32 %1264, %1259
  %1266 = zext i32 %1265 to i64
  store i64 %1266, i64* %RSI, align 8, !tbaa !2428
  %1267 = icmp ult i32 %1264, %1259
  %1268 = zext i1 %1267 to i8
  store i8 %1268, i8* %50, align 1, !tbaa !2432
  %1269 = and i32 %1265, 255
  %1270 = tail call i32 @llvm.ctpop.i32(i32 %1269) #14
  %1271 = trunc i32 %1270 to i8
  %1272 = and i8 %1271, 1
  %1273 = xor i8 %1272, 1
  store i8 %1273, i8* %51, align 1, !tbaa !2446
  %1274 = xor i32 %1259, %1264
  %1275 = xor i32 %1274, %1265
  %1276 = lshr i32 %1275, 4
  %1277 = trunc i32 %1276 to i8
  %1278 = and i8 %1277, 1
  store i8 %1278, i8* %52, align 1, !tbaa !2447
  %1279 = icmp eq i32 %1265, 0
  %1280 = zext i1 %1279 to i8
  store i8 %1280, i8* %53, align 1, !tbaa !2448
  %1281 = lshr i32 %1265, 31
  %1282 = trunc i32 %1281 to i8
  store i8 %1282, i8* %54, align 1, !tbaa !2449
  %1283 = lshr i32 %1264, 31
  %1284 = lshr i32 %1259, 31
  %1285 = xor i32 %1284, %1283
  %1286 = xor i32 %1281, %1283
  %1287 = add nuw nsw i32 %1286, %1285
  %1288 = icmp eq i32 %1287, 2
  %1289 = zext i1 %1288 to i8
  store i8 %1289, i8* %55, align 1, !tbaa !2450
  %1290 = add i64 %1256, 11
  store i64 %1290, i64* %PC, align 8
  store i32 %1265, i32* %1263, align 4
  %1291 = load i64, i64* %RBP, align 8
  %1292 = add i64 %1291, -24
  %1293 = load i64, i64* %PC, align 8
  %1294 = add i64 %1293, 4
  store i64 %1294, i64* %PC, align 8
  %1295 = inttoptr i64 %1292 to i64*
  %1296 = load i64, i64* %1295, align 8
  store i64 %1296, i64* %RCX, align 8, !tbaa !2428
  %1297 = add i64 %1291, -32
  %1298 = add i64 %1293, 8
  store i64 %1298, i64* %PC, align 8
  %1299 = inttoptr i64 %1297 to i32*
  %1300 = load i32, i32* %1299, align 4
  %1301 = sext i32 %1300 to i64
  store i64 %1301, i64* %RDX, align 8, !tbaa !2428
  %1302 = shl nsw i64 %1301, 3
  %1303 = add i64 %1302, %1296
  %1304 = add i64 %1293, 13
  store i64 %1304, i64* %PC, align 8
  %1305 = inttoptr i64 %1303 to i64*
  %1306 = load i64, i64* %1305, align 8
  store i64 %1306, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1307 = add i64 %1291, -64
  %1308 = add i64 %1293, 18
  store i64 %1308, i64* %PC, align 8
  %1309 = inttoptr i64 %1307 to i64*
  store i64 %1306, i64* %1309, align 8
  %1310 = load i64, i64* %RBP, align 8
  %1311 = add i64 %1310, -24
  %1312 = load i64, i64* %PC, align 8
  %1313 = add i64 %1312, 4
  store i64 %1313, i64* %PC, align 8
  %1314 = inttoptr i64 %1311 to i64*
  %1315 = load i64, i64* %1314, align 8
  store i64 %1315, i64* %RCX, align 8, !tbaa !2428
  %1316 = add i64 %1310, -32
  %1317 = add i64 %1312, 7
  store i64 %1317, i64* %PC, align 8
  %1318 = inttoptr i64 %1316 to i32*
  %1319 = load i32, i32* %1318, align 4
  %1320 = add i32 %1319, 1
  %1321 = zext i32 %1320 to i64
  store i64 %1321, i64* %RAX, align 8, !tbaa !2428
  %1322 = icmp eq i32 %1319, -1
  %1323 = icmp eq i32 %1320, 0
  %1324 = or i1 %1322, %1323
  %1325 = zext i1 %1324 to i8
  store i8 %1325, i8* %50, align 1, !tbaa !2432
  %1326 = and i32 %1320, 255
  %1327 = tail call i32 @llvm.ctpop.i32(i32 %1326) #14
  %1328 = trunc i32 %1327 to i8
  %1329 = and i8 %1328, 1
  %1330 = xor i8 %1329, 1
  store i8 %1330, i8* %51, align 1, !tbaa !2446
  %1331 = xor i32 %1320, %1319
  %1332 = lshr i32 %1331, 4
  %1333 = trunc i32 %1332 to i8
  %1334 = and i8 %1333, 1
  store i8 %1334, i8* %52, align 1, !tbaa !2447
  %1335 = zext i1 %1323 to i8
  store i8 %1335, i8* %53, align 1, !tbaa !2448
  %1336 = lshr i32 %1320, 31
  %1337 = trunc i32 %1336 to i8
  store i8 %1337, i8* %54, align 1, !tbaa !2449
  %1338 = lshr i32 %1319, 31
  %1339 = xor i32 %1336, %1338
  %1340 = add nuw nsw i32 %1339, %1336
  %1341 = icmp eq i32 %1340, 2
  %1342 = zext i1 %1341 to i8
  store i8 %1342, i8* %55, align 1, !tbaa !2450
  %1343 = sext i32 %1320 to i64
  store i64 %1343, i64* %RDX, align 8, !tbaa !2428
  %1344 = shl nsw i64 %1343, 3
  %1345 = add i64 %1315, %1344
  %1346 = add i64 %1312, 18
  store i64 %1346, i64* %PC, align 8
  %1347 = inttoptr i64 %1345 to i64*
  %1348 = load i64, i64* %1347, align 8
  store i64 %1348, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1349 = add i64 %1310, -72
  %1350 = add i64 %1312, 23
  store i64 %1350, i64* %PC, align 8
  %1351 = inttoptr i64 %1349 to i64*
  store i64 %1348, i64* %1351, align 8
  %1352 = load i64, i64* %RBP, align 8
  %1353 = add i64 %1352, -24
  %1354 = load i64, i64* %PC, align 8
  %1355 = add i64 %1354, 4
  store i64 %1355, i64* %PC, align 8
  %1356 = inttoptr i64 %1353 to i64*
  %1357 = load i64, i64* %1356, align 8
  store i64 %1357, i64* %RCX, align 8, !tbaa !2428
  %1358 = add i64 %1352, -40
  %1359 = add i64 %1354, 8
  store i64 %1359, i64* %PC, align 8
  %1360 = inttoptr i64 %1358 to i32*
  %1361 = load i32, i32* %1360, align 4
  %1362 = sext i32 %1361 to i64
  store i64 %1362, i64* %RDX, align 8, !tbaa !2428
  %1363 = shl nsw i64 %1362, 3
  %1364 = add i64 %1363, %1357
  %1365 = add i64 %1354, 13
  store i64 %1365, i64* %PC, align 8
  %1366 = inttoptr i64 %1364 to i64*
  %1367 = load i64, i64* %1366, align 8
  store i64 %1367, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1368 = add i64 %1352, -80
  %1369 = add i64 %1354, 18
  store i64 %1369, i64* %PC, align 8
  %1370 = inttoptr i64 %1368 to i64*
  store i64 %1367, i64* %1370, align 8
  %1371 = load i64, i64* %RBP, align 8
  %1372 = add i64 %1371, -24
  %1373 = load i64, i64* %PC, align 8
  %1374 = add i64 %1373, 4
  store i64 %1374, i64* %PC, align 8
  %1375 = inttoptr i64 %1372 to i64*
  %1376 = load i64, i64* %1375, align 8
  store i64 %1376, i64* %RCX, align 8, !tbaa !2428
  %1377 = add i64 %1371, -40
  %1378 = add i64 %1373, 7
  store i64 %1378, i64* %PC, align 8
  %1379 = inttoptr i64 %1377 to i32*
  %1380 = load i32, i32* %1379, align 4
  %1381 = add i32 %1380, 1
  %1382 = zext i32 %1381 to i64
  store i64 %1382, i64* %RAX, align 8, !tbaa !2428
  %1383 = icmp eq i32 %1380, -1
  %1384 = icmp eq i32 %1381, 0
  %1385 = or i1 %1383, %1384
  %1386 = zext i1 %1385 to i8
  store i8 %1386, i8* %50, align 1, !tbaa !2432
  %1387 = and i32 %1381, 255
  %1388 = tail call i32 @llvm.ctpop.i32(i32 %1387) #14
  %1389 = trunc i32 %1388 to i8
  %1390 = and i8 %1389, 1
  %1391 = xor i8 %1390, 1
  store i8 %1391, i8* %51, align 1, !tbaa !2446
  %1392 = xor i32 %1381, %1380
  %1393 = lshr i32 %1392, 4
  %1394 = trunc i32 %1393 to i8
  %1395 = and i8 %1394, 1
  store i8 %1395, i8* %52, align 1, !tbaa !2447
  %1396 = zext i1 %1384 to i8
  store i8 %1396, i8* %53, align 1, !tbaa !2448
  %1397 = lshr i32 %1381, 31
  %1398 = trunc i32 %1397 to i8
  store i8 %1398, i8* %54, align 1, !tbaa !2449
  %1399 = lshr i32 %1380, 31
  %1400 = xor i32 %1397, %1399
  %1401 = add nuw nsw i32 %1400, %1397
  %1402 = icmp eq i32 %1401, 2
  %1403 = zext i1 %1402 to i8
  store i8 %1403, i8* %55, align 1, !tbaa !2450
  %1404 = sext i32 %1381 to i64
  store i64 %1404, i64* %RDX, align 8, !tbaa !2428
  %1405 = shl nsw i64 %1404, 3
  %1406 = add i64 %1376, %1405
  %1407 = add i64 %1373, 18
  store i64 %1407, i64* %PC, align 8
  %1408 = inttoptr i64 %1406 to i64*
  %1409 = load i64, i64* %1408, align 8
  store i64 %1409, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1410 = add i64 %1371, -88
  %1411 = add i64 %1373, 23
  store i64 %1411, i64* %PC, align 8
  %1412 = inttoptr i64 %1410 to i64*
  store i64 %1409, i64* %1412, align 8
  %1413 = load i64, i64* %RBP, align 8
  %1414 = add i64 %1413, -80
  %1415 = load i64, i64* %PC, align 8
  %1416 = add i64 %1415, 5
  store i64 %1416, i64* %PC, align 8
  %1417 = inttoptr i64 %1414 to i64*
  %1418 = load i64, i64* %1417, align 8
  store i64 %1418, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1419 = add i64 %1413, -24
  %1420 = add i64 %1415, 9
  store i64 %1420, i64* %PC, align 8
  %1421 = inttoptr i64 %1419 to i64*
  %1422 = load i64, i64* %1421, align 8
  store i64 %1422, i64* %RCX, align 8, !tbaa !2428
  %1423 = add i64 %1413, -32
  %1424 = add i64 %1415, 13
  store i64 %1424, i64* %PC, align 8
  %1425 = inttoptr i64 %1423 to i32*
  %1426 = load i32, i32* %1425, align 4
  %1427 = sext i32 %1426 to i64
  store i64 %1427, i64* %RDX, align 8, !tbaa !2428
  %1428 = shl nsw i64 %1427, 3
  %1429 = add i64 %1428, %1422
  %1430 = add i64 %1415, 18
  store i64 %1430, i64* %PC, align 8
  %1431 = inttoptr i64 %1429 to i64*
  store i64 %1418, i64* %1431, align 8
  %1432 = load i64, i64* %RBP, align 8
  %1433 = add i64 %1432, -88
  %1434 = load i64, i64* %PC, align 8
  %1435 = add i64 %1434, 5
  store i64 %1435, i64* %PC, align 8
  %1436 = inttoptr i64 %1433 to i64*
  %1437 = load i64, i64* %1436, align 8
  store i64 %1437, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1438 = add i64 %1432, -24
  %1439 = add i64 %1434, 9
  store i64 %1439, i64* %PC, align 8
  %1440 = inttoptr i64 %1438 to i64*
  %1441 = load i64, i64* %1440, align 8
  store i64 %1441, i64* %RCX, align 8, !tbaa !2428
  %1442 = add i64 %1432, -32
  %1443 = add i64 %1434, 12
  store i64 %1443, i64* %PC, align 8
  %1444 = inttoptr i64 %1442 to i32*
  %1445 = load i32, i32* %1444, align 4
  %1446 = add i32 %1445, 1
  %1447 = zext i32 %1446 to i64
  store i64 %1447, i64* %RAX, align 8, !tbaa !2428
  %1448 = icmp eq i32 %1445, -1
  %1449 = icmp eq i32 %1446, 0
  %1450 = or i1 %1448, %1449
  %1451 = zext i1 %1450 to i8
  store i8 %1451, i8* %50, align 1, !tbaa !2432
  %1452 = and i32 %1446, 255
  %1453 = tail call i32 @llvm.ctpop.i32(i32 %1452) #14
  %1454 = trunc i32 %1453 to i8
  %1455 = and i8 %1454, 1
  %1456 = xor i8 %1455, 1
  store i8 %1456, i8* %51, align 1, !tbaa !2446
  %1457 = xor i32 %1446, %1445
  %1458 = lshr i32 %1457, 4
  %1459 = trunc i32 %1458 to i8
  %1460 = and i8 %1459, 1
  store i8 %1460, i8* %52, align 1, !tbaa !2447
  %1461 = zext i1 %1449 to i8
  store i8 %1461, i8* %53, align 1, !tbaa !2448
  %1462 = lshr i32 %1446, 31
  %1463 = trunc i32 %1462 to i8
  store i8 %1463, i8* %54, align 1, !tbaa !2449
  %1464 = lshr i32 %1445, 31
  %1465 = xor i32 %1462, %1464
  %1466 = add nuw nsw i32 %1465, %1462
  %1467 = icmp eq i32 %1466, 2
  %1468 = zext i1 %1467 to i8
  store i8 %1468, i8* %55, align 1, !tbaa !2450
  %1469 = sext i32 %1446 to i64
  store i64 %1469, i64* %RDX, align 8, !tbaa !2428
  %1470 = shl nsw i64 %1469, 3
  %1471 = add i64 %1441, %1470
  %1472 = add i64 %1434, 23
  store i64 %1472, i64* %PC, align 8
  %1473 = inttoptr i64 %1471 to i64*
  store i64 %1437, i64* %1473, align 8
  %1474 = load i64, i64* %RBP, align 8
  %1475 = add i64 %1474, -64
  %1476 = load i64, i64* %PC, align 8
  %1477 = add i64 %1476, 5
  store i64 %1477, i64* %PC, align 8
  %1478 = inttoptr i64 %1475 to i64*
  %1479 = load i64, i64* %1478, align 8
  store i64 %1479, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1480 = add i64 %1474, -24
  %1481 = add i64 %1476, 9
  store i64 %1481, i64* %PC, align 8
  %1482 = inttoptr i64 %1480 to i64*
  %1483 = load i64, i64* %1482, align 8
  store i64 %1483, i64* %RCX, align 8, !tbaa !2428
  %1484 = add i64 %1474, -40
  %1485 = add i64 %1476, 13
  store i64 %1485, i64* %PC, align 8
  %1486 = inttoptr i64 %1484 to i32*
  %1487 = load i32, i32* %1486, align 4
  %1488 = sext i32 %1487 to i64
  store i64 %1488, i64* %RDX, align 8, !tbaa !2428
  %1489 = shl nsw i64 %1488, 3
  %1490 = add i64 %1489, %1483
  %1491 = add i64 %1476, 18
  store i64 %1491, i64* %PC, align 8
  %1492 = inttoptr i64 %1490 to i64*
  store i64 %1479, i64* %1492, align 8
  %1493 = load i64, i64* %RBP, align 8
  %1494 = add i64 %1493, -72
  %1495 = load i64, i64* %PC, align 8
  %1496 = add i64 %1495, 5
  store i64 %1496, i64* %PC, align 8
  %1497 = inttoptr i64 %1494 to i64*
  %1498 = load i64, i64* %1497, align 8
  store i64 %1498, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1499 = add i64 %1493, -24
  %1500 = add i64 %1495, 9
  store i64 %1500, i64* %PC, align 8
  %1501 = inttoptr i64 %1499 to i64*
  %1502 = load i64, i64* %1501, align 8
  store i64 %1502, i64* %RCX, align 8, !tbaa !2428
  %1503 = add i64 %1493, -40
  %1504 = add i64 %1495, 12
  store i64 %1504, i64* %PC, align 8
  %1505 = inttoptr i64 %1503 to i32*
  %1506 = load i32, i32* %1505, align 4
  %1507 = add i32 %1506, 1
  %1508 = zext i32 %1507 to i64
  store i64 %1508, i64* %RAX, align 8, !tbaa !2428
  %1509 = icmp eq i32 %1506, -1
  %1510 = icmp eq i32 %1507, 0
  %1511 = or i1 %1509, %1510
  %1512 = zext i1 %1511 to i8
  store i8 %1512, i8* %50, align 1, !tbaa !2432
  %1513 = and i32 %1507, 255
  %1514 = tail call i32 @llvm.ctpop.i32(i32 %1513) #14
  %1515 = trunc i32 %1514 to i8
  %1516 = and i8 %1515, 1
  %1517 = xor i8 %1516, 1
  store i8 %1517, i8* %51, align 1, !tbaa !2446
  %1518 = xor i32 %1507, %1506
  %1519 = lshr i32 %1518, 4
  %1520 = trunc i32 %1519 to i8
  %1521 = and i8 %1520, 1
  store i8 %1521, i8* %52, align 1, !tbaa !2447
  %1522 = zext i1 %1510 to i8
  store i8 %1522, i8* %53, align 1, !tbaa !2448
  %1523 = lshr i32 %1507, 31
  %1524 = trunc i32 %1523 to i8
  store i8 %1524, i8* %54, align 1, !tbaa !2449
  %1525 = lshr i32 %1506, 31
  %1526 = xor i32 %1523, %1525
  %1527 = add nuw nsw i32 %1526, %1523
  %1528 = icmp eq i32 %1527, 2
  %1529 = zext i1 %1528 to i8
  store i8 %1529, i8* %55, align 1, !tbaa !2450
  %1530 = sext i32 %1507 to i64
  store i64 %1530, i64* %RDX, align 8, !tbaa !2428
  %1531 = shl nsw i64 %1530, 3
  %1532 = add i64 %1502, %1531
  %1533 = add i64 %1495, 23
  store i64 %1533, i64* %PC, align 8
  %1534 = inttoptr i64 %1532 to i64*
  store i64 %1498, i64* %1534, align 8
  %1535 = load i64, i64* %RBP, align 8
  %1536 = add i64 %1535, -52
  %1537 = load i64, i64* %PC, align 8
  %1538 = add i64 %1537, 3
  store i64 %1538, i64* %PC, align 8
  %1539 = inttoptr i64 %1536 to i32*
  %1540 = load i32, i32* %1539, align 4
  %1541 = zext i32 %1540 to i64
  store i64 %1541, i64* %RAX, align 8, !tbaa !2428
  %1542 = add i64 %1535, -32
  %1543 = add i64 %1537, 6
  store i64 %1543, i64* %PC, align 8
  %1544 = inttoptr i64 %1542 to i32*
  %1545 = load i32, i32* %1544, align 4
  %1546 = add i32 %1545, %1540
  %1547 = zext i32 %1546 to i64
  store i64 %1547, i64* %RAX, align 8, !tbaa !2428
  %1548 = icmp ult i32 %1546, %1540
  %1549 = icmp ult i32 %1546, %1545
  %1550 = or i1 %1548, %1549
  %1551 = zext i1 %1550 to i8
  store i8 %1551, i8* %50, align 1, !tbaa !2432
  %1552 = and i32 %1546, 255
  %1553 = tail call i32 @llvm.ctpop.i32(i32 %1552) #14
  %1554 = trunc i32 %1553 to i8
  %1555 = and i8 %1554, 1
  %1556 = xor i8 %1555, 1
  store i8 %1556, i8* %51, align 1, !tbaa !2446
  %1557 = xor i32 %1545, %1540
  %1558 = xor i32 %1557, %1546
  %1559 = lshr i32 %1558, 4
  %1560 = trunc i32 %1559 to i8
  %1561 = and i8 %1560, 1
  store i8 %1561, i8* %52, align 1, !tbaa !2447
  %1562 = icmp eq i32 %1546, 0
  %1563 = zext i1 %1562 to i8
  store i8 %1563, i8* %53, align 1, !tbaa !2448
  %1564 = lshr i32 %1546, 31
  %1565 = trunc i32 %1564 to i8
  store i8 %1565, i8* %54, align 1, !tbaa !2449
  %1566 = lshr i32 %1540, 31
  %1567 = lshr i32 %1545, 31
  %1568 = xor i32 %1564, %1566
  %1569 = xor i32 %1564, %1567
  %1570 = add nuw nsw i32 %1568, %1569
  %1571 = icmp eq i32 %1570, 2
  %1572 = zext i1 %1571 to i8
  store i8 %1572, i8* %55, align 1, !tbaa !2450
  %1573 = add i64 %1537, 9
  store i64 %1573, i64* %PC, align 8
  store i32 %1546, i32* %1544, align 4
  %1574 = load i64, i64* %RBP, align 8
  %1575 = add i64 %1574, -52
  %1576 = load i64, i64* %PC, align 8
  %1577 = add i64 %1576, 3
  store i64 %1577, i64* %PC, align 8
  %1578 = inttoptr i64 %1575 to i32*
  %1579 = load i32, i32* %1578, align 4
  %1580 = shl i32 %1579, 1
  %1581 = icmp slt i32 %1579, 0
  %1582 = icmp slt i32 %1580, 0
  %1583 = xor i1 %1581, %1582
  %1584 = zext i32 %1580 to i64
  store i64 %1584, i64* %RAX, align 8, !tbaa !2428
  %.lobit17 = lshr i32 %1579, 31
  %1585 = trunc i32 %.lobit17 to i8
  store i8 %1585, i8* %50, align 1, !tbaa !2453
  %1586 = and i32 %1580, 254
  %1587 = tail call i32 @llvm.ctpop.i32(i32 %1586) #14
  %1588 = trunc i32 %1587 to i8
  %1589 = and i8 %1588, 1
  %1590 = xor i8 %1589, 1
  store i8 %1590, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %1591 = icmp eq i32 %1580, 0
  %1592 = zext i1 %1591 to i8
  store i8 %1592, i8* %53, align 1, !tbaa !2453
  %1593 = lshr i32 %1579, 30
  %1594 = trunc i32 %1593 to i8
  %1595 = and i8 %1594, 1
  store i8 %1595, i8* %54, align 1, !tbaa !2453
  %1596 = zext i1 %1583 to i8
  store i8 %1596, i8* %55, align 1, !tbaa !2453
  %1597 = add i64 %1574, -40
  %1598 = add i64 %1576, 9
  store i64 %1598, i64* %PC, align 8
  %1599 = inttoptr i64 %1597 to i32*
  %1600 = load i32, i32* %1599, align 4
  %1601 = add i32 %1600, %1580
  %1602 = zext i32 %1601 to i64
  store i64 %1602, i64* %RAX, align 8, !tbaa !2428
  %1603 = icmp ult i32 %1601, %1580
  %1604 = icmp ult i32 %1601, %1600
  %1605 = or i1 %1603, %1604
  %1606 = zext i1 %1605 to i8
  store i8 %1606, i8* %50, align 1, !tbaa !2432
  %1607 = and i32 %1601, 255
  %1608 = tail call i32 @llvm.ctpop.i32(i32 %1607) #14
  %1609 = trunc i32 %1608 to i8
  %1610 = and i8 %1609, 1
  %1611 = xor i8 %1610, 1
  store i8 %1611, i8* %51, align 1, !tbaa !2446
  %1612 = xor i32 %1600, %1580
  %1613 = xor i32 %1612, %1601
  %1614 = lshr i32 %1613, 4
  %1615 = trunc i32 %1614 to i8
  %1616 = and i8 %1615, 1
  store i8 %1616, i8* %52, align 1, !tbaa !2447
  %1617 = icmp eq i32 %1601, 0
  %1618 = zext i1 %1617 to i8
  store i8 %1618, i8* %53, align 1, !tbaa !2448
  %1619 = lshr i32 %1601, 31
  %1620 = trunc i32 %1619 to i8
  store i8 %1620, i8* %54, align 1, !tbaa !2449
  %1621 = lshr i32 %1579, 30
  %1622 = and i32 %1621, 1
  %1623 = lshr i32 %1600, 31
  %1624 = xor i32 %1619, %1622
  %1625 = xor i32 %1619, %1623
  %1626 = add nuw nsw i32 %1624, %1625
  %1627 = icmp eq i32 %1626, 2
  %1628 = zext i1 %1627 to i8
  store i8 %1628, i8* %55, align 1, !tbaa !2450
  %1629 = add i64 %1576, 12
  store i64 %1629, i64* %PC, align 8
  store i32 %1601, i32* %1599, align 4
  %1630 = load i64, i64* %RBP, align 8
  %1631 = add i64 %1630, -24
  %1632 = load i64, i64* %PC, align 8
  %1633 = add i64 %1632, 4
  store i64 %1633, i64* %PC, align 8
  %1634 = inttoptr i64 %1631 to i64*
  %1635 = load i64, i64* %1634, align 8
  store i64 %1635, i64* %RCX, align 8, !tbaa !2428
  %1636 = add i64 %1630, -32
  %1637 = add i64 %1632, 8
  store i64 %1637, i64* %PC, align 8
  %1638 = inttoptr i64 %1636 to i32*
  %1639 = load i32, i32* %1638, align 4
  %1640 = sext i32 %1639 to i64
  store i64 %1640, i64* %RDX, align 8, !tbaa !2428
  %1641 = shl nsw i64 %1640, 3
  %1642 = add i64 %1641, %1635
  %1643 = add i64 %1632, 13
  store i64 %1643, i64* %PC, align 8
  %1644 = inttoptr i64 %1642 to i64*
  %1645 = load i64, i64* %1644, align 8
  store i64 %1645, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1646 = add i64 %1630, -64
  %1647 = add i64 %1632, 18
  store i64 %1647, i64* %PC, align 8
  %1648 = inttoptr i64 %1646 to i64*
  store i64 %1645, i64* %1648, align 8
  %1649 = load i64, i64* %RBP, align 8
  %1650 = add i64 %1649, -24
  %1651 = load i64, i64* %PC, align 8
  %1652 = add i64 %1651, 4
  store i64 %1652, i64* %PC, align 8
  %1653 = inttoptr i64 %1650 to i64*
  %1654 = load i64, i64* %1653, align 8
  store i64 %1654, i64* %RCX, align 8, !tbaa !2428
  %1655 = add i64 %1649, -32
  %1656 = add i64 %1651, 7
  store i64 %1656, i64* %PC, align 8
  %1657 = inttoptr i64 %1655 to i32*
  %1658 = load i32, i32* %1657, align 4
  %1659 = add i32 %1658, 1
  %1660 = zext i32 %1659 to i64
  store i64 %1660, i64* %RAX, align 8, !tbaa !2428
  %1661 = icmp eq i32 %1658, -1
  %1662 = icmp eq i32 %1659, 0
  %1663 = or i1 %1661, %1662
  %1664 = zext i1 %1663 to i8
  store i8 %1664, i8* %50, align 1, !tbaa !2432
  %1665 = and i32 %1659, 255
  %1666 = tail call i32 @llvm.ctpop.i32(i32 %1665) #14
  %1667 = trunc i32 %1666 to i8
  %1668 = and i8 %1667, 1
  %1669 = xor i8 %1668, 1
  store i8 %1669, i8* %51, align 1, !tbaa !2446
  %1670 = xor i32 %1659, %1658
  %1671 = lshr i32 %1670, 4
  %1672 = trunc i32 %1671 to i8
  %1673 = and i8 %1672, 1
  store i8 %1673, i8* %52, align 1, !tbaa !2447
  %1674 = zext i1 %1662 to i8
  store i8 %1674, i8* %53, align 1, !tbaa !2448
  %1675 = lshr i32 %1659, 31
  %1676 = trunc i32 %1675 to i8
  store i8 %1676, i8* %54, align 1, !tbaa !2449
  %1677 = lshr i32 %1658, 31
  %1678 = xor i32 %1675, %1677
  %1679 = add nuw nsw i32 %1678, %1675
  %1680 = icmp eq i32 %1679, 2
  %1681 = zext i1 %1680 to i8
  store i8 %1681, i8* %55, align 1, !tbaa !2450
  %1682 = sext i32 %1659 to i64
  store i64 %1682, i64* %RDX, align 8, !tbaa !2428
  %1683 = shl nsw i64 %1682, 3
  %1684 = add i64 %1654, %1683
  %1685 = add i64 %1651, 18
  store i64 %1685, i64* %PC, align 8
  %1686 = inttoptr i64 %1684 to i64*
  %1687 = load i64, i64* %1686, align 8
  store i64 %1687, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1688 = add i64 %1649, -72
  %1689 = add i64 %1651, 23
  store i64 %1689, i64* %PC, align 8
  %1690 = inttoptr i64 %1688 to i64*
  store i64 %1687, i64* %1690, align 8
  %1691 = load i64, i64* %RBP, align 8
  %1692 = add i64 %1691, -24
  %1693 = load i64, i64* %PC, align 8
  %1694 = add i64 %1693, 4
  store i64 %1694, i64* %PC, align 8
  %1695 = inttoptr i64 %1692 to i64*
  %1696 = load i64, i64* %1695, align 8
  store i64 %1696, i64* %RCX, align 8, !tbaa !2428
  %1697 = add i64 %1691, -40
  %1698 = add i64 %1693, 8
  store i64 %1698, i64* %PC, align 8
  %1699 = inttoptr i64 %1697 to i32*
  %1700 = load i32, i32* %1699, align 4
  %1701 = sext i32 %1700 to i64
  store i64 %1701, i64* %RDX, align 8, !tbaa !2428
  %1702 = shl nsw i64 %1701, 3
  %1703 = add i64 %1702, %1696
  %1704 = add i64 %1693, 13
  store i64 %1704, i64* %PC, align 8
  %1705 = inttoptr i64 %1703 to i64*
  %1706 = load i64, i64* %1705, align 8
  store i64 %1706, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1707 = add i64 %1691, -80
  %1708 = add i64 %1693, 18
  store i64 %1708, i64* %PC, align 8
  %1709 = inttoptr i64 %1707 to i64*
  store i64 %1706, i64* %1709, align 8
  %1710 = load i64, i64* %RBP, align 8
  %1711 = add i64 %1710, -24
  %1712 = load i64, i64* %PC, align 8
  %1713 = add i64 %1712, 4
  store i64 %1713, i64* %PC, align 8
  %1714 = inttoptr i64 %1711 to i64*
  %1715 = load i64, i64* %1714, align 8
  store i64 %1715, i64* %RCX, align 8, !tbaa !2428
  %1716 = add i64 %1710, -40
  %1717 = add i64 %1712, 7
  store i64 %1717, i64* %PC, align 8
  %1718 = inttoptr i64 %1716 to i32*
  %1719 = load i32, i32* %1718, align 4
  %1720 = add i32 %1719, 1
  %1721 = zext i32 %1720 to i64
  store i64 %1721, i64* %RAX, align 8, !tbaa !2428
  %1722 = icmp eq i32 %1719, -1
  %1723 = icmp eq i32 %1720, 0
  %1724 = or i1 %1722, %1723
  %1725 = zext i1 %1724 to i8
  store i8 %1725, i8* %50, align 1, !tbaa !2432
  %1726 = and i32 %1720, 255
  %1727 = tail call i32 @llvm.ctpop.i32(i32 %1726) #14
  %1728 = trunc i32 %1727 to i8
  %1729 = and i8 %1728, 1
  %1730 = xor i8 %1729, 1
  store i8 %1730, i8* %51, align 1, !tbaa !2446
  %1731 = xor i32 %1720, %1719
  %1732 = lshr i32 %1731, 4
  %1733 = trunc i32 %1732 to i8
  %1734 = and i8 %1733, 1
  store i8 %1734, i8* %52, align 1, !tbaa !2447
  %1735 = zext i1 %1723 to i8
  store i8 %1735, i8* %53, align 1, !tbaa !2448
  %1736 = lshr i32 %1720, 31
  %1737 = trunc i32 %1736 to i8
  store i8 %1737, i8* %54, align 1, !tbaa !2449
  %1738 = lshr i32 %1719, 31
  %1739 = xor i32 %1736, %1738
  %1740 = add nuw nsw i32 %1739, %1736
  %1741 = icmp eq i32 %1740, 2
  %1742 = zext i1 %1741 to i8
  store i8 %1742, i8* %55, align 1, !tbaa !2450
  %1743 = sext i32 %1720 to i64
  store i64 %1743, i64* %RDX, align 8, !tbaa !2428
  %1744 = shl nsw i64 %1743, 3
  %1745 = add i64 %1715, %1744
  %1746 = add i64 %1712, 18
  store i64 %1746, i64* %PC, align 8
  %1747 = inttoptr i64 %1745 to i64*
  %1748 = load i64, i64* %1747, align 8
  store i64 %1748, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1749 = add i64 %1710, -88
  %1750 = add i64 %1712, 23
  store i64 %1750, i64* %PC, align 8
  %1751 = inttoptr i64 %1749 to i64*
  store i64 %1748, i64* %1751, align 8
  %1752 = load i64, i64* %RBP, align 8
  %1753 = add i64 %1752, -80
  %1754 = load i64, i64* %PC, align 8
  %1755 = add i64 %1754, 5
  store i64 %1755, i64* %PC, align 8
  %1756 = inttoptr i64 %1753 to i64*
  %1757 = load i64, i64* %1756, align 8
  store i64 %1757, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1758 = add i64 %1752, -24
  %1759 = add i64 %1754, 9
  store i64 %1759, i64* %PC, align 8
  %1760 = inttoptr i64 %1758 to i64*
  %1761 = load i64, i64* %1760, align 8
  store i64 %1761, i64* %RCX, align 8, !tbaa !2428
  %1762 = add i64 %1752, -32
  %1763 = add i64 %1754, 13
  store i64 %1763, i64* %PC, align 8
  %1764 = inttoptr i64 %1762 to i32*
  %1765 = load i32, i32* %1764, align 4
  %1766 = sext i32 %1765 to i64
  store i64 %1766, i64* %RDX, align 8, !tbaa !2428
  %1767 = shl nsw i64 %1766, 3
  %1768 = add i64 %1767, %1761
  %1769 = add i64 %1754, 18
  store i64 %1769, i64* %PC, align 8
  %1770 = inttoptr i64 %1768 to i64*
  store i64 %1757, i64* %1770, align 8
  %1771 = load i64, i64* %RBP, align 8
  %1772 = add i64 %1771, -88
  %1773 = load i64, i64* %PC, align 8
  %1774 = add i64 %1773, 5
  store i64 %1774, i64* %PC, align 8
  %1775 = inttoptr i64 %1772 to i64*
  %1776 = load i64, i64* %1775, align 8
  store i64 %1776, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1777 = add i64 %1771, -24
  %1778 = add i64 %1773, 9
  store i64 %1778, i64* %PC, align 8
  %1779 = inttoptr i64 %1777 to i64*
  %1780 = load i64, i64* %1779, align 8
  store i64 %1780, i64* %RCX, align 8, !tbaa !2428
  %1781 = add i64 %1771, -32
  %1782 = add i64 %1773, 12
  store i64 %1782, i64* %PC, align 8
  %1783 = inttoptr i64 %1781 to i32*
  %1784 = load i32, i32* %1783, align 4
  %1785 = add i32 %1784, 1
  %1786 = zext i32 %1785 to i64
  store i64 %1786, i64* %RAX, align 8, !tbaa !2428
  %1787 = icmp eq i32 %1784, -1
  %1788 = icmp eq i32 %1785, 0
  %1789 = or i1 %1787, %1788
  %1790 = zext i1 %1789 to i8
  store i8 %1790, i8* %50, align 1, !tbaa !2432
  %1791 = and i32 %1785, 255
  %1792 = tail call i32 @llvm.ctpop.i32(i32 %1791) #14
  %1793 = trunc i32 %1792 to i8
  %1794 = and i8 %1793, 1
  %1795 = xor i8 %1794, 1
  store i8 %1795, i8* %51, align 1, !tbaa !2446
  %1796 = xor i32 %1785, %1784
  %1797 = lshr i32 %1796, 4
  %1798 = trunc i32 %1797 to i8
  %1799 = and i8 %1798, 1
  store i8 %1799, i8* %52, align 1, !tbaa !2447
  %1800 = zext i1 %1788 to i8
  store i8 %1800, i8* %53, align 1, !tbaa !2448
  %1801 = lshr i32 %1785, 31
  %1802 = trunc i32 %1801 to i8
  store i8 %1802, i8* %54, align 1, !tbaa !2449
  %1803 = lshr i32 %1784, 31
  %1804 = xor i32 %1801, %1803
  %1805 = add nuw nsw i32 %1804, %1801
  %1806 = icmp eq i32 %1805, 2
  %1807 = zext i1 %1806 to i8
  store i8 %1807, i8* %55, align 1, !tbaa !2450
  %1808 = sext i32 %1785 to i64
  store i64 %1808, i64* %RDX, align 8, !tbaa !2428
  %1809 = shl nsw i64 %1808, 3
  %1810 = add i64 %1780, %1809
  %1811 = add i64 %1773, 23
  store i64 %1811, i64* %PC, align 8
  %1812 = inttoptr i64 %1810 to i64*
  store i64 %1776, i64* %1812, align 8
  %1813 = load i64, i64* %RBP, align 8
  %1814 = add i64 %1813, -64
  %1815 = load i64, i64* %PC, align 8
  %1816 = add i64 %1815, 5
  store i64 %1816, i64* %PC, align 8
  %1817 = inttoptr i64 %1814 to i64*
  %1818 = load i64, i64* %1817, align 8
  store i64 %1818, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1819 = add i64 %1813, -24
  %1820 = add i64 %1815, 9
  store i64 %1820, i64* %PC, align 8
  %1821 = inttoptr i64 %1819 to i64*
  %1822 = load i64, i64* %1821, align 8
  store i64 %1822, i64* %RCX, align 8, !tbaa !2428
  %1823 = add i64 %1813, -40
  %1824 = add i64 %1815, 13
  store i64 %1824, i64* %PC, align 8
  %1825 = inttoptr i64 %1823 to i32*
  %1826 = load i32, i32* %1825, align 4
  %1827 = sext i32 %1826 to i64
  store i64 %1827, i64* %RDX, align 8, !tbaa !2428
  %1828 = shl nsw i64 %1827, 3
  %1829 = add i64 %1828, %1822
  %1830 = add i64 %1815, 18
  store i64 %1830, i64* %PC, align 8
  %1831 = inttoptr i64 %1829 to i64*
  store i64 %1818, i64* %1831, align 8
  %1832 = load i64, i64* %RBP, align 8
  %1833 = add i64 %1832, -72
  %1834 = load i64, i64* %PC, align 8
  %1835 = add i64 %1834, 5
  store i64 %1835, i64* %PC, align 8
  %1836 = inttoptr i64 %1833 to i64*
  %1837 = load i64, i64* %1836, align 8
  store i64 %1837, i64* %2935, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2937, align 1, !tbaa !2451
  %1838 = add i64 %1832, -24
  %1839 = add i64 %1834, 9
  store i64 %1839, i64* %PC, align 8
  %1840 = inttoptr i64 %1838 to i64*
  %1841 = load i64, i64* %1840, align 8
  store i64 %1841, i64* %RCX, align 8, !tbaa !2428
  %1842 = add i64 %1832, -40
  %1843 = add i64 %1834, 12
  store i64 %1843, i64* %PC, align 8
  %1844 = inttoptr i64 %1842 to i32*
  %1845 = load i32, i32* %1844, align 4
  %1846 = add i32 %1845, 1
  %1847 = zext i32 %1846 to i64
  store i64 %1847, i64* %RAX, align 8, !tbaa !2428
  %1848 = icmp eq i32 %1845, -1
  %1849 = icmp eq i32 %1846, 0
  %1850 = or i1 %1848, %1849
  %1851 = zext i1 %1850 to i8
  store i8 %1851, i8* %50, align 1, !tbaa !2432
  %1852 = and i32 %1846, 255
  %1853 = tail call i32 @llvm.ctpop.i32(i32 %1852) #14
  %1854 = trunc i32 %1853 to i8
  %1855 = and i8 %1854, 1
  %1856 = xor i8 %1855, 1
  store i8 %1856, i8* %51, align 1, !tbaa !2446
  %1857 = xor i32 %1846, %1845
  %1858 = lshr i32 %1857, 4
  %1859 = trunc i32 %1858 to i8
  %1860 = and i8 %1859, 1
  store i8 %1860, i8* %52, align 1, !tbaa !2447
  %1861 = zext i1 %1849 to i8
  store i8 %1861, i8* %53, align 1, !tbaa !2448
  %1862 = lshr i32 %1846, 31
  %1863 = trunc i32 %1862 to i8
  store i8 %1863, i8* %54, align 1, !tbaa !2449
  %1864 = lshr i32 %1845, 31
  %1865 = xor i32 %1862, %1864
  %1866 = add nuw nsw i32 %1865, %1862
  %1867 = icmp eq i32 %1866, 2
  %1868 = zext i1 %1867 to i8
  store i8 %1868, i8* %55, align 1, !tbaa !2450
  %1869 = sext i32 %1846 to i64
  store i64 %1869, i64* %RDX, align 8, !tbaa !2428
  %1870 = shl nsw i64 %1869, 3
  %1871 = add i64 %1841, %1870
  %1872 = add i64 %1834, 23
  store i64 %1872, i64* %PC, align 8
  %1873 = inttoptr i64 %1871 to i64*
  store i64 %1837, i64* %1873, align 8
  %1874 = load i64, i64* %RBP, align 8
  %1875 = add i64 %1874, -28
  %1876 = load i64, i64* %PC, align 8
  %1877 = add i64 %1876, 3
  store i64 %1877, i64* %PC, align 8
  %1878 = inttoptr i64 %1875 to i32*
  %1879 = load i32, i32* %1878, align 4
  %1880 = add i32 %1879, 1
  %1881 = zext i32 %1880 to i64
  store i64 %1881, i64* %RAX, align 8, !tbaa !2428
  %1882 = icmp eq i32 %1879, -1
  %1883 = icmp eq i32 %1880, 0
  %1884 = or i1 %1882, %1883
  %1885 = zext i1 %1884 to i8
  store i8 %1885, i8* %50, align 1, !tbaa !2432
  %1886 = and i32 %1880, 255
  %1887 = tail call i32 @llvm.ctpop.i32(i32 %1886) #14
  %1888 = trunc i32 %1887 to i8
  %1889 = and i8 %1888, 1
  %1890 = xor i8 %1889, 1
  store i8 %1890, i8* %51, align 1, !tbaa !2446
  %1891 = xor i32 %1880, %1879
  %1892 = lshr i32 %1891, 4
  %1893 = trunc i32 %1892 to i8
  %1894 = and i8 %1893, 1
  store i8 %1894, i8* %52, align 1, !tbaa !2447
  %1895 = zext i1 %1883 to i8
  store i8 %1895, i8* %53, align 1, !tbaa !2448
  %1896 = lshr i32 %1880, 31
  %1897 = trunc i32 %1896 to i8
  store i8 %1897, i8* %54, align 1, !tbaa !2449
  %1898 = lshr i32 %1879, 31
  %1899 = xor i32 %1896, %1898
  %1900 = add nuw nsw i32 %1899, %1896
  %1901 = icmp eq i32 %1900, 2
  %1902 = zext i1 %1901 to i8
  store i8 %1902, i8* %55, align 1, !tbaa !2450
  %1903 = add i64 %1876, 9
  store i64 %1903, i64* %PC, align 8
  store i32 %1880, i32* %1878, align 4
  %1904 = load i64, i64* %PC, align 8
  %1905 = add i64 %1904, -779
  store i64 %1905, i64* %PC, align 8, !tbaa !2428
  br label %block_4012ad

block_401235:                                     ; preds = %block_401241, %block_401225
  %1906 = phi i64 [ %3129, %block_401241 ], [ %.pre45, %block_401225 ]
  %1907 = load i64, i64* %RBP, align 8
  %1908 = add i64 %1907, -28
  %1909 = add i64 %1906, 3
  store i64 %1909, i64* %PC, align 8
  %1910 = inttoptr i64 %1908 to i32*
  %1911 = load i32, i32* %1910, align 4
  %1912 = zext i32 %1911 to i64
  store i64 %1912, i64* %RAX, align 8, !tbaa !2428
  %1913 = add i64 %1907, -48
  %1914 = add i64 %1906, 6
  store i64 %1914, i64* %PC, align 8
  %1915 = inttoptr i64 %1913 to i32*
  %1916 = load i32, i32* %1915, align 4
  %1917 = sub i32 %1911, %1916
  %1918 = icmp ult i32 %1911, %1916
  %1919 = zext i1 %1918 to i8
  store i8 %1919, i8* %50, align 1, !tbaa !2432
  %1920 = and i32 %1917, 255
  %1921 = tail call i32 @llvm.ctpop.i32(i32 %1920) #14
  %1922 = trunc i32 %1921 to i8
  %1923 = and i8 %1922, 1
  %1924 = xor i8 %1923, 1
  store i8 %1924, i8* %51, align 1, !tbaa !2446
  %1925 = xor i32 %1916, %1911
  %1926 = xor i32 %1925, %1917
  %1927 = lshr i32 %1926, 4
  %1928 = trunc i32 %1927 to i8
  %1929 = and i8 %1928, 1
  store i8 %1929, i8* %52, align 1, !tbaa !2447
  %1930 = icmp eq i32 %1917, 0
  %1931 = zext i1 %1930 to i8
  store i8 %1931, i8* %53, align 1, !tbaa !2448
  %1932 = lshr i32 %1917, 31
  %1933 = trunc i32 %1932 to i8
  store i8 %1933, i8* %54, align 1, !tbaa !2449
  %1934 = lshr i32 %1911, 31
  %1935 = lshr i32 %1916, 31
  %1936 = xor i32 %1935, %1934
  %1937 = xor i32 %1932, %1934
  %1938 = add nuw nsw i32 %1937, %1936
  %1939 = icmp eq i32 %1938, 2
  %1940 = zext i1 %1939 to i8
  store i8 %1940, i8* %55, align 1, !tbaa !2450
  %1941 = icmp ne i8 %1933, 0
  %1942 = xor i1 %1941, %1939
  %.v51 = select i1 %1942, i64 12, i64 56
  %1943 = add i64 %1906, %.v51
  store i64 %1943, i64* %PC, align 8, !tbaa !2428
  br i1 %1942, label %block_401241, label %block_40126d

block_4012ad:                                     ; preds = %block_4012a6, %block_4012b9
  %1944 = phi i64 [ %.pre42, %block_4012a6 ], [ %1905, %block_4012b9 ]
  %1945 = load i64, i64* %RBP, align 8
  %1946 = add i64 %1945, -28
  %1947 = add i64 %1944, 3
  store i64 %1947, i64* %PC, align 8
  %1948 = inttoptr i64 %1946 to i32*
  %1949 = load i32, i32* %1948, align 4
  %1950 = zext i32 %1949 to i64
  store i64 %1950, i64* %RAX, align 8, !tbaa !2428
  %1951 = add i64 %1945, -36
  %1952 = add i64 %1944, 6
  store i64 %1952, i64* %PC, align 8
  %1953 = inttoptr i64 %1951 to i32*
  %1954 = load i32, i32* %1953, align 4
  %1955 = sub i32 %1949, %1954
  %1956 = icmp ult i32 %1949, %1954
  %1957 = zext i1 %1956 to i8
  store i8 %1957, i8* %50, align 1, !tbaa !2432
  %1958 = and i32 %1955, 255
  %1959 = tail call i32 @llvm.ctpop.i32(i32 %1958) #14
  %1960 = trunc i32 %1959 to i8
  %1961 = and i8 %1960, 1
  %1962 = xor i8 %1961, 1
  store i8 %1962, i8* %51, align 1, !tbaa !2446
  %1963 = xor i32 %1954, %1949
  %1964 = xor i32 %1963, %1955
  %1965 = lshr i32 %1964, 4
  %1966 = trunc i32 %1965 to i8
  %1967 = and i8 %1966, 1
  store i8 %1967, i8* %52, align 1, !tbaa !2447
  %1968 = icmp eq i32 %1955, 0
  %1969 = zext i1 %1968 to i8
  store i8 %1969, i8* %53, align 1, !tbaa !2448
  %1970 = lshr i32 %1955, 31
  %1971 = trunc i32 %1970 to i8
  store i8 %1971, i8* %54, align 1, !tbaa !2449
  %1972 = lshr i32 %1949, 31
  %1973 = lshr i32 %1954, 31
  %1974 = xor i32 %1973, %1972
  %1975 = xor i32 %1970, %1972
  %1976 = add nuw nsw i32 %1975, %1974
  %1977 = icmp eq i32 %1976, 2
  %1978 = zext i1 %1977 to i8
  store i8 %1978, i8* %55, align 1, !tbaa !2450
  %1979 = icmp ne i8 %1971, 0
  %1980 = xor i1 %1979, %1977
  %.v50 = select i1 %1980, i64 12, i64 784
  %1981 = add i64 %1944, %.v50
  %1982 = add i64 %1981, 3
  store i64 %1982, i64* %PC, align 8
  br i1 %1980, label %block_4012b9, label %block_4015bd

block_4016ba:                                     ; preds = %block_4016ae
  %1983 = add i64 %2815, 3
  store i64 %1983, i64* %PC, align 8
  %1984 = load i32, i32* %2782, align 4
  %1985 = shl i32 %1984, 1
  %1986 = icmp slt i32 %1984, 0
  %1987 = icmp slt i32 %1985, 0
  %1988 = xor i1 %1986, %1987
  %1989 = zext i32 %1985 to i64
  store i64 %1989, i64* %RAX, align 8, !tbaa !2428
  %.lobit19 = lshr i32 %1984, 31
  %1990 = trunc i32 %.lobit19 to i8
  store i8 %1990, i8* %50, align 1, !tbaa !2453
  %1991 = and i32 %1985, 254
  %1992 = tail call i32 @llvm.ctpop.i32(i32 %1991) #14
  %1993 = trunc i32 %1992 to i8
  %1994 = and i8 %1993, 1
  %1995 = xor i8 %1994, 1
  store i8 %1995, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %1996 = icmp eq i32 %1985, 0
  %1997 = zext i1 %1996 to i8
  store i8 %1997, i8* %53, align 1, !tbaa !2453
  %1998 = lshr i32 %1984, 30
  %1999 = trunc i32 %1998 to i8
  %2000 = and i8 %1999, 1
  store i8 %2000, i8* %54, align 1, !tbaa !2453
  %2001 = zext i1 %1988 to i8
  store i8 %2001, i8* %55, align 1, !tbaa !2453
  %2002 = add i64 %2779, -16
  %2003 = add i64 %2815, 10
  store i64 %2003, i64* %PC, align 8
  %2004 = inttoptr i64 %2002 to i64*
  %2005 = load i64, i64* %2004, align 8
  store i64 %2005, i64* %RCX, align 8, !tbaa !2428
  %2006 = add i64 %2815, 14
  store i64 %2006, i64* %PC, align 8
  %2007 = load i32, i32* %2787, align 4
  %2008 = sext i32 %2007 to i64
  store i64 %2008, i64* %RDX, align 8, !tbaa !2428
  %2009 = shl nsw i64 %2008, 2
  %2010 = add i64 %2005, %2009
  %2011 = add i64 %2815, 17
  store i64 %2011, i64* %PC, align 8
  %2012 = inttoptr i64 %2010 to i32*
  %2013 = load i32, i32* %2012, align 4
  %2014 = add i32 %2013, %1985
  %2015 = zext i32 %2014 to i64
  store i64 %2015, i64* %RAX, align 8, !tbaa !2428
  %2016 = icmp ult i32 %2014, %1985
  %2017 = icmp ult i32 %2014, %2013
  %2018 = or i1 %2016, %2017
  %2019 = zext i1 %2018 to i8
  store i8 %2019, i8* %50, align 1, !tbaa !2432
  %2020 = and i32 %2014, 255
  %2021 = tail call i32 @llvm.ctpop.i32(i32 %2020) #14
  %2022 = trunc i32 %2021 to i8
  %2023 = and i8 %2022, 1
  %2024 = xor i8 %2023, 1
  store i8 %2024, i8* %51, align 1, !tbaa !2446
  %2025 = xor i32 %2013, %1985
  %2026 = xor i32 %2025, %2014
  %2027 = lshr i32 %2026, 4
  %2028 = trunc i32 %2027 to i8
  %2029 = and i8 %2028, 1
  store i8 %2029, i8* %52, align 1, !tbaa !2447
  %2030 = icmp eq i32 %2014, 0
  %2031 = zext i1 %2030 to i8
  store i8 %2031, i8* %53, align 1, !tbaa !2448
  %2032 = lshr i32 %2014, 31
  %2033 = trunc i32 %2032 to i8
  store i8 %2033, i8* %54, align 1, !tbaa !2449
  %2034 = lshr i32 %1984, 30
  %2035 = and i32 %2034, 1
  %2036 = lshr i32 %2013, 31
  %2037 = xor i32 %2032, %2035
  %2038 = xor i32 %2032, %2036
  %2039 = add nuw nsw i32 %2037, %2038
  %2040 = icmp eq i32 %2039, 2
  %2041 = zext i1 %2040 to i8
  store i8 %2041, i8* %55, align 1, !tbaa !2450
  %2042 = add i64 %2779, -32
  %2043 = add i64 %2815, 20
  store i64 %2043, i64* %PC, align 8
  %2044 = inttoptr i64 %2042 to i32*
  store i32 %2014, i32* %2044, align 4
  %2045 = load i64, i64* %RBP, align 8
  %2046 = add i64 %2045, -36
  %2047 = load i64, i64* %PC, align 8
  %2048 = add i64 %2047, 3
  store i64 %2048, i64* %PC, align 8
  %2049 = inttoptr i64 %2046 to i32*
  %2050 = load i32, i32* %2049, align 4
  %2051 = shl i32 %2050, 1
  %2052 = icmp slt i32 %2050, 0
  %2053 = icmp slt i32 %2051, 0
  %2054 = xor i1 %2052, %2053
  %2055 = zext i32 %2051 to i64
  store i64 %2055, i64* %RAX, align 8, !tbaa !2428
  %.lobit20 = lshr i32 %2050, 31
  %2056 = trunc i32 %.lobit20 to i8
  store i8 %2056, i8* %50, align 1, !tbaa !2453
  %2057 = and i32 %2051, 254
  %2058 = tail call i32 @llvm.ctpop.i32(i32 %2057) #14
  %2059 = trunc i32 %2058 to i8
  %2060 = and i8 %2059, 1
  %2061 = xor i8 %2060, 1
  store i8 %2061, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2062 = icmp eq i32 %2051, 0
  %2063 = zext i1 %2062 to i8
  store i8 %2063, i8* %53, align 1, !tbaa !2453
  %2064 = lshr i32 %2050, 30
  %2065 = trunc i32 %2064 to i8
  %2066 = and i8 %2065, 1
  store i8 %2066, i8* %54, align 1, !tbaa !2453
  %2067 = zext i1 %2054 to i8
  store i8 %2067, i8* %55, align 1, !tbaa !2453
  %2068 = add i64 %2045, -16
  %2069 = add i64 %2047, 10
  store i64 %2069, i64* %PC, align 8
  %2070 = inttoptr i64 %2068 to i64*
  %2071 = load i64, i64* %2070, align 8
  store i64 %2071, i64* %RCX, align 8, !tbaa !2428
  %2072 = add i64 %2045, -28
  %2073 = add i64 %2047, 14
  store i64 %2073, i64* %PC, align 8
  %2074 = inttoptr i64 %2072 to i32*
  %2075 = load i32, i32* %2074, align 4
  %2076 = sext i32 %2075 to i64
  store i64 %2076, i64* %RDX, align 8, !tbaa !2428
  %2077 = shl nsw i64 %2076, 2
  %2078 = add i64 %2071, %2077
  %2079 = add i64 %2047, 17
  store i64 %2079, i64* %PC, align 8
  %2080 = inttoptr i64 %2078 to i32*
  %2081 = load i32, i32* %2080, align 4
  %2082 = add i32 %2081, %2051
  %2083 = zext i32 %2082 to i64
  store i64 %2083, i64* %RAX, align 8, !tbaa !2428
  %2084 = icmp ult i32 %2082, %2051
  %2085 = icmp ult i32 %2082, %2081
  %2086 = or i1 %2084, %2085
  %2087 = zext i1 %2086 to i8
  store i8 %2087, i8* %50, align 1, !tbaa !2432
  %2088 = and i32 %2082, 255
  %2089 = tail call i32 @llvm.ctpop.i32(i32 %2088) #14
  %2090 = trunc i32 %2089 to i8
  %2091 = and i8 %2090, 1
  %2092 = xor i8 %2091, 1
  store i8 %2092, i8* %51, align 1, !tbaa !2446
  %2093 = xor i32 %2081, %2051
  %2094 = xor i32 %2093, %2082
  %2095 = lshr i32 %2094, 4
  %2096 = trunc i32 %2095 to i8
  %2097 = and i8 %2096, 1
  store i8 %2097, i8* %52, align 1, !tbaa !2447
  %2098 = icmp eq i32 %2082, 0
  %2099 = zext i1 %2098 to i8
  store i8 %2099, i8* %53, align 1, !tbaa !2448
  %2100 = lshr i32 %2082, 31
  %2101 = trunc i32 %2100 to i8
  store i8 %2101, i8* %54, align 1, !tbaa !2449
  %2102 = lshr i32 %2050, 30
  %2103 = and i32 %2102, 1
  %2104 = lshr i32 %2081, 31
  %2105 = xor i32 %2100, %2103
  %2106 = xor i32 %2100, %2104
  %2107 = add nuw nsw i32 %2105, %2106
  %2108 = icmp eq i32 %2107, 2
  %2109 = zext i1 %2108 to i8
  store i8 %2109, i8* %55, align 1, !tbaa !2450
  %2110 = add i64 %2045, -40
  %2111 = add i64 %2047, 20
  store i64 %2111, i64* %PC, align 8
  %2112 = inttoptr i64 %2110 to i32*
  store i32 %2082, i32* %2112, align 4
  %2113 = load i64, i64* %RBP, align 8
  %2114 = add i64 %2113, -24
  %2115 = load i64, i64* %PC, align 8
  %2116 = add i64 %2115, 4
  store i64 %2116, i64* %PC, align 8
  %2117 = inttoptr i64 %2114 to i64*
  %2118 = load i64, i64* %2117, align 8
  store i64 %2118, i64* %RCX, align 8, !tbaa !2428
  %2119 = add i64 %2113, -32
  %2120 = add i64 %2115, 8
  store i64 %2120, i64* %PC, align 8
  %2121 = inttoptr i64 %2119 to i32*
  %2122 = load i32, i32* %2121, align 4
  %2123 = sext i32 %2122 to i64
  store i64 %2123, i64* %RDX, align 8, !tbaa !2428
  %2124 = shl nsw i64 %2123, 3
  %2125 = add i64 %2124, %2118
  %2126 = add i64 %2115, 13
  store i64 %2126, i64* %PC, align 8
  %2127 = inttoptr i64 %2125 to i64*
  %2128 = load i64, i64* %2127, align 8
  store i64 %2128, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2129 = add i64 %2113, -64
  %2130 = add i64 %2115, 18
  store i64 %2130, i64* %PC, align 8
  %2131 = inttoptr i64 %2129 to i64*
  store i64 %2128, i64* %2131, align 8
  %2132 = load i64, i64* %RBP, align 8
  %2133 = add i64 %2132, -24
  %2134 = load i64, i64* %PC, align 8
  %2135 = add i64 %2134, 4
  store i64 %2135, i64* %PC, align 8
  %2136 = inttoptr i64 %2133 to i64*
  %2137 = load i64, i64* %2136, align 8
  store i64 %2137, i64* %RCX, align 8, !tbaa !2428
  %2138 = add i64 %2132, -32
  %2139 = add i64 %2134, 7
  store i64 %2139, i64* %PC, align 8
  %2140 = inttoptr i64 %2138 to i32*
  %2141 = load i32, i32* %2140, align 4
  %2142 = add i32 %2141, 1
  %2143 = zext i32 %2142 to i64
  store i64 %2143, i64* %RAX, align 8, !tbaa !2428
  %2144 = icmp eq i32 %2141, -1
  %2145 = icmp eq i32 %2142, 0
  %2146 = or i1 %2144, %2145
  %2147 = zext i1 %2146 to i8
  store i8 %2147, i8* %50, align 1, !tbaa !2432
  %2148 = and i32 %2142, 255
  %2149 = tail call i32 @llvm.ctpop.i32(i32 %2148) #14
  %2150 = trunc i32 %2149 to i8
  %2151 = and i8 %2150, 1
  %2152 = xor i8 %2151, 1
  store i8 %2152, i8* %51, align 1, !tbaa !2446
  %2153 = xor i32 %2142, %2141
  %2154 = lshr i32 %2153, 4
  %2155 = trunc i32 %2154 to i8
  %2156 = and i8 %2155, 1
  store i8 %2156, i8* %52, align 1, !tbaa !2447
  %2157 = zext i1 %2145 to i8
  store i8 %2157, i8* %53, align 1, !tbaa !2448
  %2158 = lshr i32 %2142, 31
  %2159 = trunc i32 %2158 to i8
  store i8 %2159, i8* %54, align 1, !tbaa !2449
  %2160 = lshr i32 %2141, 31
  %2161 = xor i32 %2158, %2160
  %2162 = add nuw nsw i32 %2161, %2158
  %2163 = icmp eq i32 %2162, 2
  %2164 = zext i1 %2163 to i8
  store i8 %2164, i8* %55, align 1, !tbaa !2450
  %2165 = sext i32 %2142 to i64
  store i64 %2165, i64* %RDX, align 8, !tbaa !2428
  %2166 = shl nsw i64 %2165, 3
  %2167 = add i64 %2137, %2166
  %2168 = add i64 %2134, 18
  store i64 %2168, i64* %PC, align 8
  %2169 = inttoptr i64 %2167 to i64*
  %2170 = load i64, i64* %2169, align 8
  store i64 %2170, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2171 = add i64 %2132, -72
  %2172 = add i64 %2134, 23
  store i64 %2172, i64* %PC, align 8
  %2173 = inttoptr i64 %2171 to i64*
  store i64 %2170, i64* %2173, align 8
  %2174 = load i64, i64* %RBP, align 8
  %2175 = add i64 %2174, -24
  %2176 = load i64, i64* %PC, align 8
  %2177 = add i64 %2176, 4
  store i64 %2177, i64* %PC, align 8
  %2178 = inttoptr i64 %2175 to i64*
  %2179 = load i64, i64* %2178, align 8
  store i64 %2179, i64* %RCX, align 8, !tbaa !2428
  %2180 = add i64 %2174, -40
  %2181 = add i64 %2176, 8
  store i64 %2181, i64* %PC, align 8
  %2182 = inttoptr i64 %2180 to i32*
  %2183 = load i32, i32* %2182, align 4
  %2184 = sext i32 %2183 to i64
  store i64 %2184, i64* %RDX, align 8, !tbaa !2428
  %2185 = shl nsw i64 %2184, 3
  %2186 = add i64 %2185, %2179
  %2187 = add i64 %2176, 13
  store i64 %2187, i64* %PC, align 8
  %2188 = inttoptr i64 %2186 to i64*
  %2189 = load i64, i64* %2188, align 8
  store i64 %2189, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2190 = add i64 %2174, -80
  %2191 = add i64 %2176, 18
  store i64 %2191, i64* %PC, align 8
  %2192 = inttoptr i64 %2190 to i64*
  store i64 %2189, i64* %2192, align 8
  %2193 = load i64, i64* %RBP, align 8
  %2194 = add i64 %2193, -24
  %2195 = load i64, i64* %PC, align 8
  %2196 = add i64 %2195, 4
  store i64 %2196, i64* %PC, align 8
  %2197 = inttoptr i64 %2194 to i64*
  %2198 = load i64, i64* %2197, align 8
  store i64 %2198, i64* %RCX, align 8, !tbaa !2428
  %2199 = add i64 %2193, -40
  %2200 = add i64 %2195, 7
  store i64 %2200, i64* %PC, align 8
  %2201 = inttoptr i64 %2199 to i32*
  %2202 = load i32, i32* %2201, align 4
  %2203 = add i32 %2202, 1
  %2204 = zext i32 %2203 to i64
  store i64 %2204, i64* %RAX, align 8, !tbaa !2428
  %2205 = icmp eq i32 %2202, -1
  %2206 = icmp eq i32 %2203, 0
  %2207 = or i1 %2205, %2206
  %2208 = zext i1 %2207 to i8
  store i8 %2208, i8* %50, align 1, !tbaa !2432
  %2209 = and i32 %2203, 255
  %2210 = tail call i32 @llvm.ctpop.i32(i32 %2209) #14
  %2211 = trunc i32 %2210 to i8
  %2212 = and i8 %2211, 1
  %2213 = xor i8 %2212, 1
  store i8 %2213, i8* %51, align 1, !tbaa !2446
  %2214 = xor i32 %2203, %2202
  %2215 = lshr i32 %2214, 4
  %2216 = trunc i32 %2215 to i8
  %2217 = and i8 %2216, 1
  store i8 %2217, i8* %52, align 1, !tbaa !2447
  %2218 = zext i1 %2206 to i8
  store i8 %2218, i8* %53, align 1, !tbaa !2448
  %2219 = lshr i32 %2203, 31
  %2220 = trunc i32 %2219 to i8
  store i8 %2220, i8* %54, align 1, !tbaa !2449
  %2221 = lshr i32 %2202, 31
  %2222 = xor i32 %2219, %2221
  %2223 = add nuw nsw i32 %2222, %2219
  %2224 = icmp eq i32 %2223, 2
  %2225 = zext i1 %2224 to i8
  store i8 %2225, i8* %55, align 1, !tbaa !2450
  %2226 = sext i32 %2203 to i64
  store i64 %2226, i64* %RDX, align 8, !tbaa !2428
  %2227 = shl nsw i64 %2226, 3
  %2228 = add i64 %2198, %2227
  %2229 = add i64 %2195, 18
  store i64 %2229, i64* %PC, align 8
  %2230 = inttoptr i64 %2228 to i64*
  %2231 = load i64, i64* %2230, align 8
  store i64 %2231, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2232 = add i64 %2193, -88
  %2233 = add i64 %2195, 23
  store i64 %2233, i64* %PC, align 8
  %2234 = inttoptr i64 %2232 to i64*
  store i64 %2231, i64* %2234, align 8
  %2235 = load i64, i64* %RBP, align 8
  %2236 = add i64 %2235, -80
  %2237 = load i64, i64* %PC, align 8
  %2238 = add i64 %2237, 5
  store i64 %2238, i64* %PC, align 8
  %2239 = inttoptr i64 %2236 to i64*
  %2240 = load i64, i64* %2239, align 8
  store i64 %2240, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2241 = add i64 %2235, -24
  %2242 = add i64 %2237, 9
  store i64 %2242, i64* %PC, align 8
  %2243 = inttoptr i64 %2241 to i64*
  %2244 = load i64, i64* %2243, align 8
  store i64 %2244, i64* %RCX, align 8, !tbaa !2428
  %2245 = add i64 %2235, -32
  %2246 = add i64 %2237, 13
  store i64 %2246, i64* %PC, align 8
  %2247 = inttoptr i64 %2245 to i32*
  %2248 = load i32, i32* %2247, align 4
  %2249 = sext i32 %2248 to i64
  store i64 %2249, i64* %RDX, align 8, !tbaa !2428
  %2250 = shl nsw i64 %2249, 3
  %2251 = add i64 %2250, %2244
  %2252 = add i64 %2237, 18
  store i64 %2252, i64* %PC, align 8
  %2253 = inttoptr i64 %2251 to i64*
  store i64 %2240, i64* %2253, align 8
  %2254 = load i64, i64* %RBP, align 8
  %2255 = add i64 %2254, -88
  %2256 = load i64, i64* %PC, align 8
  %2257 = add i64 %2256, 5
  store i64 %2257, i64* %PC, align 8
  %2258 = inttoptr i64 %2255 to i64*
  %2259 = load i64, i64* %2258, align 8
  store i64 %2259, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2260 = add i64 %2254, -24
  %2261 = add i64 %2256, 9
  store i64 %2261, i64* %PC, align 8
  %2262 = inttoptr i64 %2260 to i64*
  %2263 = load i64, i64* %2262, align 8
  store i64 %2263, i64* %RCX, align 8, !tbaa !2428
  %2264 = add i64 %2254, -32
  %2265 = add i64 %2256, 12
  store i64 %2265, i64* %PC, align 8
  %2266 = inttoptr i64 %2264 to i32*
  %2267 = load i32, i32* %2266, align 4
  %2268 = add i32 %2267, 1
  %2269 = zext i32 %2268 to i64
  store i64 %2269, i64* %RAX, align 8, !tbaa !2428
  %2270 = icmp eq i32 %2267, -1
  %2271 = icmp eq i32 %2268, 0
  %2272 = or i1 %2270, %2271
  %2273 = zext i1 %2272 to i8
  store i8 %2273, i8* %50, align 1, !tbaa !2432
  %2274 = and i32 %2268, 255
  %2275 = tail call i32 @llvm.ctpop.i32(i32 %2274) #14
  %2276 = trunc i32 %2275 to i8
  %2277 = and i8 %2276, 1
  %2278 = xor i8 %2277, 1
  store i8 %2278, i8* %51, align 1, !tbaa !2446
  %2279 = xor i32 %2268, %2267
  %2280 = lshr i32 %2279, 4
  %2281 = trunc i32 %2280 to i8
  %2282 = and i8 %2281, 1
  store i8 %2282, i8* %52, align 1, !tbaa !2447
  %2283 = zext i1 %2271 to i8
  store i8 %2283, i8* %53, align 1, !tbaa !2448
  %2284 = lshr i32 %2268, 31
  %2285 = trunc i32 %2284 to i8
  store i8 %2285, i8* %54, align 1, !tbaa !2449
  %2286 = lshr i32 %2267, 31
  %2287 = xor i32 %2284, %2286
  %2288 = add nuw nsw i32 %2287, %2284
  %2289 = icmp eq i32 %2288, 2
  %2290 = zext i1 %2289 to i8
  store i8 %2290, i8* %55, align 1, !tbaa !2450
  %2291 = sext i32 %2268 to i64
  store i64 %2291, i64* %RDX, align 8, !tbaa !2428
  %2292 = shl nsw i64 %2291, 3
  %2293 = add i64 %2263, %2292
  %2294 = add i64 %2256, 23
  store i64 %2294, i64* %PC, align 8
  %2295 = inttoptr i64 %2293 to i64*
  store i64 %2259, i64* %2295, align 8
  %2296 = load i64, i64* %RBP, align 8
  %2297 = add i64 %2296, -64
  %2298 = load i64, i64* %PC, align 8
  %2299 = add i64 %2298, 5
  store i64 %2299, i64* %PC, align 8
  %2300 = inttoptr i64 %2297 to i64*
  %2301 = load i64, i64* %2300, align 8
  store i64 %2301, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2302 = add i64 %2296, -24
  %2303 = add i64 %2298, 9
  store i64 %2303, i64* %PC, align 8
  %2304 = inttoptr i64 %2302 to i64*
  %2305 = load i64, i64* %2304, align 8
  store i64 %2305, i64* %RCX, align 8, !tbaa !2428
  %2306 = add i64 %2296, -40
  %2307 = add i64 %2298, 13
  store i64 %2307, i64* %PC, align 8
  %2308 = inttoptr i64 %2306 to i32*
  %2309 = load i32, i32* %2308, align 4
  %2310 = sext i32 %2309 to i64
  store i64 %2310, i64* %RDX, align 8, !tbaa !2428
  %2311 = shl nsw i64 %2310, 3
  %2312 = add i64 %2311, %2305
  %2313 = add i64 %2298, 18
  store i64 %2313, i64* %PC, align 8
  %2314 = inttoptr i64 %2312 to i64*
  store i64 %2301, i64* %2314, align 8
  %2315 = load i64, i64* %RBP, align 8
  %2316 = add i64 %2315, -72
  %2317 = load i64, i64* %PC, align 8
  %2318 = add i64 %2317, 5
  store i64 %2318, i64* %PC, align 8
  %2319 = inttoptr i64 %2316 to i64*
  %2320 = load i64, i64* %2319, align 8
  store i64 %2320, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2321 = add i64 %2315, -24
  %2322 = add i64 %2317, 9
  store i64 %2322, i64* %PC, align 8
  %2323 = inttoptr i64 %2321 to i64*
  %2324 = load i64, i64* %2323, align 8
  store i64 %2324, i64* %RCX, align 8, !tbaa !2428
  %2325 = add i64 %2315, -40
  %2326 = add i64 %2317, 12
  store i64 %2326, i64* %PC, align 8
  %2327 = inttoptr i64 %2325 to i32*
  %2328 = load i32, i32* %2327, align 4
  %2329 = add i32 %2328, 1
  %2330 = zext i32 %2329 to i64
  store i64 %2330, i64* %RAX, align 8, !tbaa !2428
  %2331 = icmp eq i32 %2328, -1
  %2332 = icmp eq i32 %2329, 0
  %2333 = or i1 %2331, %2332
  %2334 = zext i1 %2333 to i8
  store i8 %2334, i8* %50, align 1, !tbaa !2432
  %2335 = and i32 %2329, 255
  %2336 = tail call i32 @llvm.ctpop.i32(i32 %2335) #14
  %2337 = trunc i32 %2336 to i8
  %2338 = and i8 %2337, 1
  %2339 = xor i8 %2338, 1
  store i8 %2339, i8* %51, align 1, !tbaa !2446
  %2340 = xor i32 %2329, %2328
  %2341 = lshr i32 %2340, 4
  %2342 = trunc i32 %2341 to i8
  %2343 = and i8 %2342, 1
  store i8 %2343, i8* %52, align 1, !tbaa !2447
  %2344 = zext i1 %2332 to i8
  store i8 %2344, i8* %53, align 1, !tbaa !2448
  %2345 = lshr i32 %2329, 31
  %2346 = trunc i32 %2345 to i8
  store i8 %2346, i8* %54, align 1, !tbaa !2449
  %2347 = lshr i32 %2328, 31
  %2348 = xor i32 %2345, %2347
  %2349 = add nuw nsw i32 %2348, %2345
  %2350 = icmp eq i32 %2349, 2
  %2351 = zext i1 %2350 to i8
  store i8 %2351, i8* %55, align 1, !tbaa !2450
  %2352 = sext i32 %2329 to i64
  store i64 %2352, i64* %RDX, align 8, !tbaa !2428
  %2353 = shl nsw i64 %2352, 3
  %2354 = add i64 %2324, %2353
  %2355 = add i64 %2317, 23
  store i64 %2355, i64* %PC, align 8
  %2356 = inttoptr i64 %2354 to i64*
  store i64 %2320, i64* %2356, align 8
  %2357 = load i64, i64* %RBP, align 8
  %2358 = add i64 %2357, -52
  %2359 = load i64, i64* %PC, align 8
  %2360 = add i64 %2359, 3
  store i64 %2360, i64* %PC, align 8
  %2361 = inttoptr i64 %2358 to i32*
  %2362 = load i32, i32* %2361, align 4
  %2363 = zext i32 %2362 to i64
  store i64 %2363, i64* %RAX, align 8, !tbaa !2428
  %2364 = add i64 %2357, -32
  %2365 = add i64 %2359, 6
  store i64 %2365, i64* %PC, align 8
  %2366 = inttoptr i64 %2364 to i32*
  %2367 = load i32, i32* %2366, align 4
  %2368 = add i32 %2367, %2362
  %2369 = zext i32 %2368 to i64
  store i64 %2369, i64* %RAX, align 8, !tbaa !2428
  %2370 = icmp ult i32 %2368, %2362
  %2371 = icmp ult i32 %2368, %2367
  %2372 = or i1 %2370, %2371
  %2373 = zext i1 %2372 to i8
  store i8 %2373, i8* %50, align 1, !tbaa !2432
  %2374 = and i32 %2368, 255
  %2375 = tail call i32 @llvm.ctpop.i32(i32 %2374) #14
  %2376 = trunc i32 %2375 to i8
  %2377 = and i8 %2376, 1
  %2378 = xor i8 %2377, 1
  store i8 %2378, i8* %51, align 1, !tbaa !2446
  %2379 = xor i32 %2367, %2362
  %2380 = xor i32 %2379, %2368
  %2381 = lshr i32 %2380, 4
  %2382 = trunc i32 %2381 to i8
  %2383 = and i8 %2382, 1
  store i8 %2383, i8* %52, align 1, !tbaa !2447
  %2384 = icmp eq i32 %2368, 0
  %2385 = zext i1 %2384 to i8
  store i8 %2385, i8* %53, align 1, !tbaa !2448
  %2386 = lshr i32 %2368, 31
  %2387 = trunc i32 %2386 to i8
  store i8 %2387, i8* %54, align 1, !tbaa !2449
  %2388 = lshr i32 %2362, 31
  %2389 = lshr i32 %2367, 31
  %2390 = xor i32 %2386, %2388
  %2391 = xor i32 %2386, %2389
  %2392 = add nuw nsw i32 %2390, %2391
  %2393 = icmp eq i32 %2392, 2
  %2394 = zext i1 %2393 to i8
  store i8 %2394, i8* %55, align 1, !tbaa !2450
  %2395 = add i64 %2359, 9
  store i64 %2395, i64* %PC, align 8
  store i32 %2368, i32* %2366, align 4
  %2396 = load i64, i64* %RBP, align 8
  %2397 = add i64 %2396, -52
  %2398 = load i64, i64* %PC, align 8
  %2399 = add i64 %2398, 3
  store i64 %2399, i64* %PC, align 8
  %2400 = inttoptr i64 %2397 to i32*
  %2401 = load i32, i32* %2400, align 4
  %2402 = zext i32 %2401 to i64
  store i64 %2402, i64* %RAX, align 8, !tbaa !2428
  %2403 = add i64 %2396, -40
  %2404 = add i64 %2398, 6
  store i64 %2404, i64* %PC, align 8
  %2405 = inttoptr i64 %2403 to i32*
  %2406 = load i32, i32* %2405, align 4
  %2407 = add i32 %2406, %2401
  %2408 = zext i32 %2407 to i64
  store i64 %2408, i64* %RAX, align 8, !tbaa !2428
  %2409 = icmp ult i32 %2407, %2401
  %2410 = icmp ult i32 %2407, %2406
  %2411 = or i1 %2409, %2410
  %2412 = zext i1 %2411 to i8
  store i8 %2412, i8* %50, align 1, !tbaa !2432
  %2413 = and i32 %2407, 255
  %2414 = tail call i32 @llvm.ctpop.i32(i32 %2413) #14
  %2415 = trunc i32 %2414 to i8
  %2416 = and i8 %2415, 1
  %2417 = xor i8 %2416, 1
  store i8 %2417, i8* %51, align 1, !tbaa !2446
  %2418 = xor i32 %2406, %2401
  %2419 = xor i32 %2418, %2407
  %2420 = lshr i32 %2419, 4
  %2421 = trunc i32 %2420 to i8
  %2422 = and i8 %2421, 1
  store i8 %2422, i8* %52, align 1, !tbaa !2447
  %2423 = icmp eq i32 %2407, 0
  %2424 = zext i1 %2423 to i8
  store i8 %2424, i8* %53, align 1, !tbaa !2448
  %2425 = lshr i32 %2407, 31
  %2426 = trunc i32 %2425 to i8
  store i8 %2426, i8* %54, align 1, !tbaa !2449
  %2427 = lshr i32 %2401, 31
  %2428 = lshr i32 %2406, 31
  %2429 = xor i32 %2425, %2427
  %2430 = xor i32 %2425, %2428
  %2431 = add nuw nsw i32 %2429, %2430
  %2432 = icmp eq i32 %2431, 2
  %2433 = zext i1 %2432 to i8
  store i8 %2433, i8* %55, align 1, !tbaa !2450
  %2434 = add i64 %2398, 9
  store i64 %2434, i64* %PC, align 8
  store i32 %2407, i32* %2405, align 4
  %2435 = load i64, i64* %RBP, align 8
  %2436 = add i64 %2435, -24
  %2437 = load i64, i64* %PC, align 8
  %2438 = add i64 %2437, 4
  store i64 %2438, i64* %PC, align 8
  %2439 = inttoptr i64 %2436 to i64*
  %2440 = load i64, i64* %2439, align 8
  store i64 %2440, i64* %RCX, align 8, !tbaa !2428
  %2441 = add i64 %2435, -32
  %2442 = add i64 %2437, 8
  store i64 %2442, i64* %PC, align 8
  %2443 = inttoptr i64 %2441 to i32*
  %2444 = load i32, i32* %2443, align 4
  %2445 = sext i32 %2444 to i64
  store i64 %2445, i64* %RDX, align 8, !tbaa !2428
  %2446 = shl nsw i64 %2445, 3
  %2447 = add i64 %2446, %2440
  %2448 = add i64 %2437, 13
  store i64 %2448, i64* %PC, align 8
  %2449 = inttoptr i64 %2447 to i64*
  %2450 = load i64, i64* %2449, align 8
  store i64 %2450, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2451 = add i64 %2435, -64
  %2452 = add i64 %2437, 18
  store i64 %2452, i64* %PC, align 8
  %2453 = inttoptr i64 %2451 to i64*
  store i64 %2450, i64* %2453, align 8
  %2454 = load i64, i64* %RBP, align 8
  %2455 = add i64 %2454, -24
  %2456 = load i64, i64* %PC, align 8
  %2457 = add i64 %2456, 4
  store i64 %2457, i64* %PC, align 8
  %2458 = inttoptr i64 %2455 to i64*
  %2459 = load i64, i64* %2458, align 8
  store i64 %2459, i64* %RCX, align 8, !tbaa !2428
  %2460 = add i64 %2454, -32
  %2461 = add i64 %2456, 7
  store i64 %2461, i64* %PC, align 8
  %2462 = inttoptr i64 %2460 to i32*
  %2463 = load i32, i32* %2462, align 4
  %2464 = add i32 %2463, 1
  %2465 = zext i32 %2464 to i64
  store i64 %2465, i64* %RAX, align 8, !tbaa !2428
  %2466 = icmp eq i32 %2463, -1
  %2467 = icmp eq i32 %2464, 0
  %2468 = or i1 %2466, %2467
  %2469 = zext i1 %2468 to i8
  store i8 %2469, i8* %50, align 1, !tbaa !2432
  %2470 = and i32 %2464, 255
  %2471 = tail call i32 @llvm.ctpop.i32(i32 %2470) #14
  %2472 = trunc i32 %2471 to i8
  %2473 = and i8 %2472, 1
  %2474 = xor i8 %2473, 1
  store i8 %2474, i8* %51, align 1, !tbaa !2446
  %2475 = xor i32 %2464, %2463
  %2476 = lshr i32 %2475, 4
  %2477 = trunc i32 %2476 to i8
  %2478 = and i8 %2477, 1
  store i8 %2478, i8* %52, align 1, !tbaa !2447
  %2479 = zext i1 %2467 to i8
  store i8 %2479, i8* %53, align 1, !tbaa !2448
  %2480 = lshr i32 %2464, 31
  %2481 = trunc i32 %2480 to i8
  store i8 %2481, i8* %54, align 1, !tbaa !2449
  %2482 = lshr i32 %2463, 31
  %2483 = xor i32 %2480, %2482
  %2484 = add nuw nsw i32 %2483, %2480
  %2485 = icmp eq i32 %2484, 2
  %2486 = zext i1 %2485 to i8
  store i8 %2486, i8* %55, align 1, !tbaa !2450
  %2487 = sext i32 %2464 to i64
  store i64 %2487, i64* %RDX, align 8, !tbaa !2428
  %2488 = shl nsw i64 %2487, 3
  %2489 = add i64 %2459, %2488
  %2490 = add i64 %2456, 18
  store i64 %2490, i64* %PC, align 8
  %2491 = inttoptr i64 %2489 to i64*
  %2492 = load i64, i64* %2491, align 8
  store i64 %2492, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2493 = add i64 %2454, -72
  %2494 = add i64 %2456, 23
  store i64 %2494, i64* %PC, align 8
  %2495 = inttoptr i64 %2493 to i64*
  store i64 %2492, i64* %2495, align 8
  %2496 = load i64, i64* %RBP, align 8
  %2497 = add i64 %2496, -24
  %2498 = load i64, i64* %PC, align 8
  %2499 = add i64 %2498, 4
  store i64 %2499, i64* %PC, align 8
  %2500 = inttoptr i64 %2497 to i64*
  %2501 = load i64, i64* %2500, align 8
  store i64 %2501, i64* %RCX, align 8, !tbaa !2428
  %2502 = add i64 %2496, -40
  %2503 = add i64 %2498, 8
  store i64 %2503, i64* %PC, align 8
  %2504 = inttoptr i64 %2502 to i32*
  %2505 = load i32, i32* %2504, align 4
  %2506 = sext i32 %2505 to i64
  store i64 %2506, i64* %RDX, align 8, !tbaa !2428
  %2507 = shl nsw i64 %2506, 3
  %2508 = add i64 %2507, %2501
  %2509 = add i64 %2498, 13
  store i64 %2509, i64* %PC, align 8
  %2510 = inttoptr i64 %2508 to i64*
  %2511 = load i64, i64* %2510, align 8
  store i64 %2511, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2512 = add i64 %2496, -80
  %2513 = add i64 %2498, 18
  store i64 %2513, i64* %PC, align 8
  %2514 = inttoptr i64 %2512 to i64*
  store i64 %2511, i64* %2514, align 8
  %2515 = load i64, i64* %RBP, align 8
  %2516 = add i64 %2515, -24
  %2517 = load i64, i64* %PC, align 8
  %2518 = add i64 %2517, 4
  store i64 %2518, i64* %PC, align 8
  %2519 = inttoptr i64 %2516 to i64*
  %2520 = load i64, i64* %2519, align 8
  store i64 %2520, i64* %RCX, align 8, !tbaa !2428
  %2521 = add i64 %2515, -40
  %2522 = add i64 %2517, 7
  store i64 %2522, i64* %PC, align 8
  %2523 = inttoptr i64 %2521 to i32*
  %2524 = load i32, i32* %2523, align 4
  %2525 = add i32 %2524, 1
  %2526 = zext i32 %2525 to i64
  store i64 %2526, i64* %RAX, align 8, !tbaa !2428
  %2527 = icmp eq i32 %2524, -1
  %2528 = icmp eq i32 %2525, 0
  %2529 = or i1 %2527, %2528
  %2530 = zext i1 %2529 to i8
  store i8 %2530, i8* %50, align 1, !tbaa !2432
  %2531 = and i32 %2525, 255
  %2532 = tail call i32 @llvm.ctpop.i32(i32 %2531) #14
  %2533 = trunc i32 %2532 to i8
  %2534 = and i8 %2533, 1
  %2535 = xor i8 %2534, 1
  store i8 %2535, i8* %51, align 1, !tbaa !2446
  %2536 = xor i32 %2525, %2524
  %2537 = lshr i32 %2536, 4
  %2538 = trunc i32 %2537 to i8
  %2539 = and i8 %2538, 1
  store i8 %2539, i8* %52, align 1, !tbaa !2447
  %2540 = zext i1 %2528 to i8
  store i8 %2540, i8* %53, align 1, !tbaa !2448
  %2541 = lshr i32 %2525, 31
  %2542 = trunc i32 %2541 to i8
  store i8 %2542, i8* %54, align 1, !tbaa !2449
  %2543 = lshr i32 %2524, 31
  %2544 = xor i32 %2541, %2543
  %2545 = add nuw nsw i32 %2544, %2541
  %2546 = icmp eq i32 %2545, 2
  %2547 = zext i1 %2546 to i8
  store i8 %2547, i8* %55, align 1, !tbaa !2450
  %2548 = sext i32 %2525 to i64
  store i64 %2548, i64* %RDX, align 8, !tbaa !2428
  %2549 = shl nsw i64 %2548, 3
  %2550 = add i64 %2520, %2549
  %2551 = add i64 %2517, 18
  store i64 %2551, i64* %PC, align 8
  %2552 = inttoptr i64 %2550 to i64*
  %2553 = load i64, i64* %2552, align 8
  store i64 %2553, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2554 = add i64 %2515, -88
  %2555 = add i64 %2517, 23
  store i64 %2555, i64* %PC, align 8
  %2556 = inttoptr i64 %2554 to i64*
  store i64 %2553, i64* %2556, align 8
  %2557 = load i64, i64* %RBP, align 8
  %2558 = add i64 %2557, -80
  %2559 = load i64, i64* %PC, align 8
  %2560 = add i64 %2559, 5
  store i64 %2560, i64* %PC, align 8
  %2561 = inttoptr i64 %2558 to i64*
  %2562 = load i64, i64* %2561, align 8
  store i64 %2562, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2563 = add i64 %2557, -24
  %2564 = add i64 %2559, 9
  store i64 %2564, i64* %PC, align 8
  %2565 = inttoptr i64 %2563 to i64*
  %2566 = load i64, i64* %2565, align 8
  store i64 %2566, i64* %RCX, align 8, !tbaa !2428
  %2567 = add i64 %2557, -32
  %2568 = add i64 %2559, 13
  store i64 %2568, i64* %PC, align 8
  %2569 = inttoptr i64 %2567 to i32*
  %2570 = load i32, i32* %2569, align 4
  %2571 = sext i32 %2570 to i64
  store i64 %2571, i64* %RDX, align 8, !tbaa !2428
  %2572 = shl nsw i64 %2571, 3
  %2573 = add i64 %2572, %2566
  %2574 = add i64 %2559, 18
  store i64 %2574, i64* %PC, align 8
  %2575 = inttoptr i64 %2573 to i64*
  store i64 %2562, i64* %2575, align 8
  %2576 = load i64, i64* %RBP, align 8
  %2577 = add i64 %2576, -88
  %2578 = load i64, i64* %PC, align 8
  %2579 = add i64 %2578, 5
  store i64 %2579, i64* %PC, align 8
  %2580 = inttoptr i64 %2577 to i64*
  %2581 = load i64, i64* %2580, align 8
  store i64 %2581, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2582 = add i64 %2576, -24
  %2583 = add i64 %2578, 9
  store i64 %2583, i64* %PC, align 8
  %2584 = inttoptr i64 %2582 to i64*
  %2585 = load i64, i64* %2584, align 8
  store i64 %2585, i64* %RCX, align 8, !tbaa !2428
  %2586 = add i64 %2576, -32
  %2587 = add i64 %2578, 12
  store i64 %2587, i64* %PC, align 8
  %2588 = inttoptr i64 %2586 to i32*
  %2589 = load i32, i32* %2588, align 4
  %2590 = add i32 %2589, 1
  %2591 = zext i32 %2590 to i64
  store i64 %2591, i64* %RAX, align 8, !tbaa !2428
  %2592 = icmp eq i32 %2589, -1
  %2593 = icmp eq i32 %2590, 0
  %2594 = or i1 %2592, %2593
  %2595 = zext i1 %2594 to i8
  store i8 %2595, i8* %50, align 1, !tbaa !2432
  %2596 = and i32 %2590, 255
  %2597 = tail call i32 @llvm.ctpop.i32(i32 %2596) #14
  %2598 = trunc i32 %2597 to i8
  %2599 = and i8 %2598, 1
  %2600 = xor i8 %2599, 1
  store i8 %2600, i8* %51, align 1, !tbaa !2446
  %2601 = xor i32 %2590, %2589
  %2602 = lshr i32 %2601, 4
  %2603 = trunc i32 %2602 to i8
  %2604 = and i8 %2603, 1
  store i8 %2604, i8* %52, align 1, !tbaa !2447
  %2605 = zext i1 %2593 to i8
  store i8 %2605, i8* %53, align 1, !tbaa !2448
  %2606 = lshr i32 %2590, 31
  %2607 = trunc i32 %2606 to i8
  store i8 %2607, i8* %54, align 1, !tbaa !2449
  %2608 = lshr i32 %2589, 31
  %2609 = xor i32 %2606, %2608
  %2610 = add nuw nsw i32 %2609, %2606
  %2611 = icmp eq i32 %2610, 2
  %2612 = zext i1 %2611 to i8
  store i8 %2612, i8* %55, align 1, !tbaa !2450
  %2613 = sext i32 %2590 to i64
  store i64 %2613, i64* %RDX, align 8, !tbaa !2428
  %2614 = shl nsw i64 %2613, 3
  %2615 = add i64 %2585, %2614
  %2616 = add i64 %2578, 23
  store i64 %2616, i64* %PC, align 8
  %2617 = inttoptr i64 %2615 to i64*
  store i64 %2581, i64* %2617, align 8
  %2618 = load i64, i64* %RBP, align 8
  %2619 = add i64 %2618, -64
  %2620 = load i64, i64* %PC, align 8
  %2621 = add i64 %2620, 5
  store i64 %2621, i64* %PC, align 8
  %2622 = inttoptr i64 %2619 to i64*
  %2623 = load i64, i64* %2622, align 8
  store i64 %2623, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2624 = add i64 %2618, -24
  %2625 = add i64 %2620, 9
  store i64 %2625, i64* %PC, align 8
  %2626 = inttoptr i64 %2624 to i64*
  %2627 = load i64, i64* %2626, align 8
  store i64 %2627, i64* %RCX, align 8, !tbaa !2428
  %2628 = add i64 %2618, -40
  %2629 = add i64 %2620, 13
  store i64 %2629, i64* %PC, align 8
  %2630 = inttoptr i64 %2628 to i32*
  %2631 = load i32, i32* %2630, align 4
  %2632 = sext i32 %2631 to i64
  store i64 %2632, i64* %RDX, align 8, !tbaa !2428
  %2633 = shl nsw i64 %2632, 3
  %2634 = add i64 %2633, %2627
  %2635 = add i64 %2620, 18
  store i64 %2635, i64* %PC, align 8
  %2636 = inttoptr i64 %2634 to i64*
  store i64 %2623, i64* %2636, align 8
  %2637 = load i64, i64* %RBP, align 8
  %2638 = add i64 %2637, -72
  %2639 = load i64, i64* %PC, align 8
  %2640 = add i64 %2639, 5
  store i64 %2640, i64* %PC, align 8
  %2641 = inttoptr i64 %2638 to i64*
  %2642 = load i64, i64* %2641, align 8
  store i64 %2642, i64* %2929, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2931, align 1, !tbaa !2451
  %2643 = add i64 %2637, -24
  %2644 = add i64 %2639, 9
  store i64 %2644, i64* %PC, align 8
  %2645 = inttoptr i64 %2643 to i64*
  %2646 = load i64, i64* %2645, align 8
  store i64 %2646, i64* %RCX, align 8, !tbaa !2428
  %2647 = add i64 %2637, -40
  %2648 = add i64 %2639, 12
  store i64 %2648, i64* %PC, align 8
  %2649 = inttoptr i64 %2647 to i32*
  %2650 = load i32, i32* %2649, align 4
  %2651 = add i32 %2650, 1
  %2652 = zext i32 %2651 to i64
  store i64 %2652, i64* %RAX, align 8, !tbaa !2428
  %2653 = icmp eq i32 %2650, -1
  %2654 = icmp eq i32 %2651, 0
  %2655 = or i1 %2653, %2654
  %2656 = zext i1 %2655 to i8
  store i8 %2656, i8* %50, align 1, !tbaa !2432
  %2657 = and i32 %2651, 255
  %2658 = tail call i32 @llvm.ctpop.i32(i32 %2657) #14
  %2659 = trunc i32 %2658 to i8
  %2660 = and i8 %2659, 1
  %2661 = xor i8 %2660, 1
  store i8 %2661, i8* %51, align 1, !tbaa !2446
  %2662 = xor i32 %2651, %2650
  %2663 = lshr i32 %2662, 4
  %2664 = trunc i32 %2663 to i8
  %2665 = and i8 %2664, 1
  store i8 %2665, i8* %52, align 1, !tbaa !2447
  %2666 = zext i1 %2654 to i8
  store i8 %2666, i8* %53, align 1, !tbaa !2448
  %2667 = lshr i32 %2651, 31
  %2668 = trunc i32 %2667 to i8
  store i8 %2668, i8* %54, align 1, !tbaa !2449
  %2669 = lshr i32 %2650, 31
  %2670 = xor i32 %2667, %2669
  %2671 = add nuw nsw i32 %2670, %2667
  %2672 = icmp eq i32 %2671, 2
  %2673 = zext i1 %2672 to i8
  store i8 %2673, i8* %55, align 1, !tbaa !2450
  %2674 = sext i32 %2651 to i64
  store i64 %2674, i64* %RDX, align 8, !tbaa !2428
  %2675 = shl nsw i64 %2674, 3
  %2676 = add i64 %2646, %2675
  %2677 = add i64 %2639, 23
  store i64 %2677, i64* %PC, align 8
  %2678 = inttoptr i64 %2676 to i64*
  store i64 %2642, i64* %2678, align 8
  %2679 = load i64, i64* %RBP, align 8
  %2680 = add i64 %2679, -28
  %2681 = load i64, i64* %PC, align 8
  %2682 = add i64 %2681, 3
  store i64 %2682, i64* %PC, align 8
  %2683 = inttoptr i64 %2680 to i32*
  %2684 = load i32, i32* %2683, align 4
  %2685 = add i32 %2684, 1
  %2686 = zext i32 %2685 to i64
  store i64 %2686, i64* %RAX, align 8, !tbaa !2428
  %2687 = icmp eq i32 %2684, -1
  %2688 = icmp eq i32 %2685, 0
  %2689 = or i1 %2687, %2688
  %2690 = zext i1 %2689 to i8
  store i8 %2690, i8* %50, align 1, !tbaa !2432
  %2691 = and i32 %2685, 255
  %2692 = tail call i32 @llvm.ctpop.i32(i32 %2691) #14
  %2693 = trunc i32 %2692 to i8
  %2694 = and i8 %2693, 1
  %2695 = xor i8 %2694, 1
  store i8 %2695, i8* %51, align 1, !tbaa !2446
  %2696 = xor i32 %2685, %2684
  %2697 = lshr i32 %2696, 4
  %2698 = trunc i32 %2697 to i8
  %2699 = and i8 %2698, 1
  store i8 %2699, i8* %52, align 1, !tbaa !2447
  %2700 = zext i1 %2688 to i8
  store i8 %2700, i8* %53, align 1, !tbaa !2448
  %2701 = lshr i32 %2685, 31
  %2702 = trunc i32 %2701 to i8
  store i8 %2702, i8* %54, align 1, !tbaa !2449
  %2703 = lshr i32 %2684, 31
  %2704 = xor i32 %2701, %2703
  %2705 = add nuw nsw i32 %2704, %2701
  %2706 = icmp eq i32 %2705, 2
  %2707 = zext i1 %2706 to i8
  store i8 %2707, i8* %55, align 1, !tbaa !2450
  %2708 = add i64 %2681, 9
  store i64 %2708, i64* %PC, align 8
  store i32 %2685, i32* %2683, align 4
  %2709 = load i64, i64* %PC, align 8
  %2710 = add i64 %2709, -407
  store i64 %2710, i64* %PC, align 8, !tbaa !2428
  br label %block_4016ae

block_4012a6:                                     ; preds = %block_40129a
  %2711 = add i64 %2817, -28
  %2712 = add i64 %2853, 7
  store i64 %2712, i64* %PC, align 8
  %2713 = inttoptr i64 %2711 to i32*
  store i32 0, i32* %2713, align 4
  %.pre42 = load i64, i64* %PC, align 8
  br label %block_4012ad

block_401225:                                     ; preds = %block_401216
  %2714 = add i64 %2928, 3
  store i64 %2714, i64* %PC, align 8
  %2715 = load i32, i32* %2899, align 4
  %2716 = zext i32 %2715 to i64
  %2717 = shl nuw i64 %2716, 32
  %2718 = ashr i64 %2717, 33
  %2719 = trunc i32 %2715 to i8
  %2720 = and i8 %2719, 1
  %2721 = trunc i64 %2718 to i32
  %2722 = and i64 %2718, 4294967295
  store i64 %2722, i64* %RAX, align 8, !tbaa !2428
  store i8 %2720, i8* %50, align 1, !tbaa !2453
  %2723 = and i32 %2721, 255
  %2724 = tail call i32 @llvm.ctpop.i32(i32 %2723) #14
  %2725 = trunc i32 %2724 to i8
  %2726 = and i8 %2725, 1
  %2727 = xor i8 %2726, 1
  store i8 %2727, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2728 = icmp eq i32 %2721, 0
  %2729 = zext i1 %2728 to i8
  store i8 %2729, i8* %53, align 1, !tbaa !2453
  %2730 = lshr i64 %2718, 31
  %2731 = trunc i64 %2730 to i8
  %2732 = and i8 %2731, 1
  store i8 %2732, i8* %54, align 1, !tbaa !2453
  store i8 0, i8* %55, align 1, !tbaa !2453
  %2733 = trunc i64 %2718 to i32
  %2734 = add i64 %2928, 9
  store i64 %2734, i64* %PC, align 8
  store i32 %2733, i32* %2899, align 4
  %2735 = load i64, i64* %RBP, align 8
  %2736 = add i64 %2735, -28
  %2737 = load i64, i64* %PC, align 8
  %2738 = add i64 %2737, 7
  store i64 %2738, i64* %PC, align 8
  %2739 = inttoptr i64 %2736 to i32*
  store i32 0, i32* %2739, align 4
  %.pre45 = load i64, i64* %PC, align 8
  br label %block_401235

block_40169b:                                     ; preds = %block_401694, %block_40184a
  %2740 = phi i64 [ %.pre43, %block_401694 ], [ %93, %block_40184a ]
  %2741 = load i64, i64* %RBP, align 8
  %2742 = add i64 %2741, -36
  %2743 = add i64 %2740, 3
  store i64 %2743, i64* %PC, align 8
  %2744 = inttoptr i64 %2742 to i32*
  %2745 = load i32, i32* %2744, align 4
  %2746 = zext i32 %2745 to i64
  store i64 %2746, i64* %RAX, align 8, !tbaa !2428
  %2747 = add i64 %2741, -48
  %2748 = add i64 %2740, 6
  store i64 %2748, i64* %PC, align 8
  %2749 = inttoptr i64 %2747 to i32*
  %2750 = load i32, i32* %2749, align 4
  %2751 = sub i32 %2745, %2750
  %2752 = icmp ult i32 %2745, %2750
  %2753 = zext i1 %2752 to i8
  store i8 %2753, i8* %50, align 1, !tbaa !2432
  %2754 = and i32 %2751, 255
  %2755 = tail call i32 @llvm.ctpop.i32(i32 %2754) #14
  %2756 = trunc i32 %2755 to i8
  %2757 = and i8 %2756, 1
  %2758 = xor i8 %2757, 1
  store i8 %2758, i8* %51, align 1, !tbaa !2446
  %2759 = xor i32 %2750, %2745
  %2760 = xor i32 %2759, %2751
  %2761 = lshr i32 %2760, 4
  %2762 = trunc i32 %2761 to i8
  %2763 = and i8 %2762, 1
  store i8 %2763, i8* %52, align 1, !tbaa !2447
  %2764 = icmp eq i32 %2751, 0
  %2765 = zext i1 %2764 to i8
  store i8 %2765, i8* %53, align 1, !tbaa !2448
  %2766 = lshr i32 %2751, 31
  %2767 = trunc i32 %2766 to i8
  store i8 %2767, i8* %54, align 1, !tbaa !2449
  %2768 = lshr i32 %2745, 31
  %2769 = lshr i32 %2750, 31
  %2770 = xor i32 %2769, %2768
  %2771 = xor i32 %2766, %2768
  %2772 = add nuw nsw i32 %2771, %2770
  %2773 = icmp eq i32 %2772, 2
  %2774 = zext i1 %2773 to i8
  store i8 %2774, i8* %55, align 1, !tbaa !2450
  %2775 = icmp ne i8 %2767, 0
  %2776 = xor i1 %2775, %2773
  %.v48 = select i1 %2776, i64 12, i64 450
  %2777 = add i64 %2740, %.v48
  store i64 %2777, i64* %PC, align 8, !tbaa !2428
  br i1 %2776, label %block_4016a7, label %block_401862.loopexit76

block_4016ae:                                     ; preds = %block_4016a7, %block_4016ba
  %2778 = phi i64 [ %.pre44, %block_4016a7 ], [ %2710, %block_4016ba ]
  %2779 = load i64, i64* %RBP, align 8
  %2780 = add i64 %2779, -28
  %2781 = add i64 %2778, 3
  store i64 %2781, i64* %PC, align 8
  %2782 = inttoptr i64 %2780 to i32*
  %2783 = load i32, i32* %2782, align 4
  %2784 = zext i32 %2783 to i64
  store i64 %2784, i64* %RAX, align 8, !tbaa !2428
  %2785 = add i64 %2779, -36
  %2786 = add i64 %2778, 6
  store i64 %2786, i64* %PC, align 8
  %2787 = inttoptr i64 %2785 to i32*
  %2788 = load i32, i32* %2787, align 4
  %2789 = sub i32 %2783, %2788
  %2790 = icmp ult i32 %2783, %2788
  %2791 = zext i1 %2790 to i8
  store i8 %2791, i8* %50, align 1, !tbaa !2432
  %2792 = and i32 %2789, 255
  %2793 = tail call i32 @llvm.ctpop.i32(i32 %2792) #14
  %2794 = trunc i32 %2793 to i8
  %2795 = and i8 %2794, 1
  %2796 = xor i8 %2795, 1
  store i8 %2796, i8* %51, align 1, !tbaa !2446
  %2797 = xor i32 %2788, %2783
  %2798 = xor i32 %2797, %2789
  %2799 = lshr i32 %2798, 4
  %2800 = trunc i32 %2799 to i8
  %2801 = and i8 %2800, 1
  store i8 %2801, i8* %52, align 1, !tbaa !2447
  %2802 = icmp eq i32 %2789, 0
  %2803 = zext i1 %2802 to i8
  store i8 %2803, i8* %53, align 1, !tbaa !2448
  %2804 = lshr i32 %2789, 31
  %2805 = trunc i32 %2804 to i8
  store i8 %2805, i8* %54, align 1, !tbaa !2449
  %2806 = lshr i32 %2783, 31
  %2807 = lshr i32 %2788, 31
  %2808 = xor i32 %2807, %2806
  %2809 = xor i32 %2804, %2806
  %2810 = add nuw nsw i32 %2809, %2808
  %2811 = icmp eq i32 %2810, 2
  %2812 = zext i1 %2811 to i8
  store i8 %2812, i8* %55, align 1, !tbaa !2450
  %2813 = icmp ne i8 %2805, 0
  %2814 = xor i1 %2813, %2811
  %.v46 = select i1 %2814, i64 12, i64 412
  %2815 = add i64 %2778, %.v46
  store i64 %2815, i64* %PC, align 8, !tbaa !2428
  br i1 %2814, label %block_4016ba, label %block_40184a

block_40129a:                                     ; preds = %block_401293, %block_4015bd
  %2816 = phi i64 [ %.pre41, %block_401293 ], [ %502, %block_4015bd ]
  %2817 = load i64, i64* %RBP, align 8
  %2818 = add i64 %2817, -36
  %2819 = add i64 %2816, 3
  store i64 %2819, i64* %PC, align 8
  %2820 = inttoptr i64 %2818 to i32*
  %2821 = load i32, i32* %2820, align 4
  %2822 = zext i32 %2821 to i64
  store i64 %2822, i64* %RAX, align 8, !tbaa !2428
  %2823 = add i64 %2817, -48
  %2824 = add i64 %2816, 6
  store i64 %2824, i64* %PC, align 8
  %2825 = inttoptr i64 %2823 to i32*
  %2826 = load i32, i32* %2825, align 4
  %2827 = sub i32 %2821, %2826
  %2828 = icmp ult i32 %2821, %2826
  %2829 = zext i1 %2828 to i8
  store i8 %2829, i8* %50, align 1, !tbaa !2432
  %2830 = and i32 %2827, 255
  %2831 = tail call i32 @llvm.ctpop.i32(i32 %2830) #14
  %2832 = trunc i32 %2831 to i8
  %2833 = and i8 %2832, 1
  %2834 = xor i8 %2833, 1
  store i8 %2834, i8* %51, align 1, !tbaa !2446
  %2835 = xor i32 %2826, %2821
  %2836 = xor i32 %2835, %2827
  %2837 = lshr i32 %2836, 4
  %2838 = trunc i32 %2837 to i8
  %2839 = and i8 %2838, 1
  store i8 %2839, i8* %52, align 1, !tbaa !2447
  %2840 = icmp eq i32 %2827, 0
  %2841 = zext i1 %2840 to i8
  store i8 %2841, i8* %53, align 1, !tbaa !2448
  %2842 = lshr i32 %2827, 31
  %2843 = trunc i32 %2842 to i8
  store i8 %2843, i8* %54, align 1, !tbaa !2449
  %2844 = lshr i32 %2821, 31
  %2845 = lshr i32 %2826, 31
  %2846 = xor i32 %2845, %2844
  %2847 = xor i32 %2842, %2844
  %2848 = add nuw nsw i32 %2847, %2846
  %2849 = icmp eq i32 %2848, 2
  %2850 = zext i1 %2849 to i8
  store i8 %2850, i8* %55, align 1, !tbaa !2450
  %2851 = icmp ne i8 %2843, 0
  %2852 = xor i1 %2851, %2849
  %.v49 = select i1 %2852, i64 12, i64 1013
  %2853 = add i64 %2816, %.v49
  store i64 %2853, i64* %PC, align 8, !tbaa !2428
  br i1 %2852, label %block_4012a6, label %block_401862.loopexit

block_40126d:                                     ; preds = %block_401235
  %2854 = add i64 %1943, 3
  store i64 %2854, i64* %PC, align 8
  %2855 = load i32, i32* %1915, align 4
  %2856 = shl i32 %2855, 1
  %2857 = icmp slt i32 %2855, 0
  %2858 = icmp slt i32 %2856, 0
  %2859 = xor i1 %2857, %2858
  %2860 = zext i32 %2856 to i64
  store i64 %2860, i64* %RAX, align 8, !tbaa !2428
  %.lobit = lshr i32 %2855, 31
  %2861 = trunc i32 %.lobit to i8
  store i8 %2861, i8* %50, align 1, !tbaa !2453
  %2862 = and i32 %2856, 254
  %2863 = tail call i32 @llvm.ctpop.i32(i32 %2862) #14
  %2864 = trunc i32 %2863 to i8
  %2865 = and i8 %2864, 1
  %2866 = xor i8 %2865, 1
  store i8 %2866, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2867 = icmp eq i32 %2856, 0
  %2868 = zext i1 %2867 to i8
  store i8 %2868, i8* %53, align 1, !tbaa !2453
  %2869 = lshr i32 %2855, 30
  %2870 = trunc i32 %2869 to i8
  %2871 = and i8 %2870, 1
  store i8 %2871, i8* %54, align 1, !tbaa !2453
  %2872 = zext i1 %2859 to i8
  store i8 %2872, i8* %55, align 1, !tbaa !2453
  %2873 = add i64 %1943, 9
  store i64 %2873, i64* %PC, align 8
  store i32 %2856, i32* %1915, align 4
  %2874 = load i64, i64* %PC, align 8
  %2875 = add i64 %2874, -96
  store i64 %2875, i64* %PC, align 8, !tbaa !2428
  br label %block_401216

block_401216:                                     ; preds = %block_40126d, %block_4011f0
  %2876 = phi i64 [ %2875, %block_40126d ], [ %.pre, %block_4011f0 ]
  %2877 = load i64, i64* %RBP, align 8
  %2878 = add i64 %2877, -48
  %2879 = add i64 %2876, 3
  store i64 %2879, i64* %PC, align 8
  %2880 = inttoptr i64 %2878 to i32*
  %2881 = load i32, i32* %2880, align 4
  %2882 = shl i32 %2881, 3
  %2883 = zext i32 %2882 to i64
  store i64 %2883, i64* %RAX, align 8, !tbaa !2428
  %2884 = lshr i32 %2881, 29
  %2885 = trunc i32 %2884 to i8
  %2886 = and i8 %2885, 1
  store i8 %2886, i8* %50, align 1, !tbaa !2453
  %2887 = and i32 %2882, 248
  %2888 = tail call i32 @llvm.ctpop.i32(i32 %2887) #14
  %2889 = trunc i32 %2888 to i8
  %2890 = and i8 %2889, 1
  %2891 = xor i8 %2890, 1
  store i8 %2891, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2892 = icmp eq i32 %2882, 0
  %2893 = zext i1 %2892 to i8
  store i8 %2893, i8* %53, align 1, !tbaa !2453
  %2894 = lshr i32 %2881, 28
  %2895 = trunc i32 %2894 to i8
  %2896 = and i8 %2895, 1
  store i8 %2896, i8* %54, align 1, !tbaa !2453
  store i8 0, i8* %55, align 1, !tbaa !2453
  %2897 = add i64 %2877, -44
  %2898 = add i64 %2876, 9
  store i64 %2898, i64* %PC, align 8
  %2899 = inttoptr i64 %2897 to i32*
  %2900 = load i32, i32* %2899, align 4
  %2901 = sub i32 %2882, %2900
  %2902 = icmp ult i32 %2882, %2900
  %2903 = zext i1 %2902 to i8
  store i8 %2903, i8* %50, align 1, !tbaa !2432
  %2904 = and i32 %2901, 255
  %2905 = tail call i32 @llvm.ctpop.i32(i32 %2904) #14
  %2906 = trunc i32 %2905 to i8
  %2907 = and i8 %2906, 1
  %2908 = xor i8 %2907, 1
  store i8 %2908, i8* %51, align 1, !tbaa !2446
  %2909 = xor i32 %2900, %2882
  %2910 = xor i32 %2909, %2901
  %2911 = lshr i32 %2910, 4
  %2912 = trunc i32 %2911 to i8
  %2913 = and i8 %2912, 1
  store i8 %2913, i8* %52, align 1, !tbaa !2447
  %2914 = icmp eq i32 %2901, 0
  %2915 = zext i1 %2914 to i8
  store i8 %2915, i8* %53, align 1, !tbaa !2448
  %2916 = lshr i32 %2901, 31
  %2917 = trunc i32 %2916 to i8
  store i8 %2917, i8* %54, align 1, !tbaa !2449
  %2918 = lshr i32 %2881, 28
  %2919 = and i32 %2918, 1
  %2920 = lshr i32 %2900, 31
  %2921 = xor i32 %2920, %2919
  %2922 = xor i32 %2916, %2919
  %2923 = add nuw nsw i32 %2922, %2921
  %2924 = icmp eq i32 %2923, 2
  %2925 = zext i1 %2924 to i8
  store i8 %2925, i8* %55, align 1, !tbaa !2450
  %2926 = icmp ne i8 %2917, 0
  %2927 = xor i1 %2926, %2924
  %.v47 = select i1 %2927, i64 15, i64 101
  %2928 = add i64 %2876, %.v47
  store i64 %2928, i64* %PC, align 8, !tbaa !2428
  br i1 %2927, label %block_401225, label %block_40127b

block_401694:                                     ; preds = %block_40127b
  store i32 1, i32* %3014, align 4
  %2929 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %2938, i64 0, i32 0, i32 0, i32 0, i64 0
  %2930 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %2931 = bitcast i64* %2930 to double*
  %.pre43 = load i64, i64* %PC, align 8
  br label %block_40169b

block_4016a7:                                     ; preds = %block_40169b
  %2932 = add i64 %2741, -28
  %2933 = add i64 %2777, 7
  store i64 %2933, i64* %PC, align 8
  %2934 = inttoptr i64 %2932 to i32*
  store i32 0, i32* %2934, align 4
  %.pre44 = load i64, i64* %PC, align 8
  br label %block_4016ae

block_401293:                                     ; preds = %block_40127b
  store i32 0, i32* %3014, align 4
  %2935 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %2938, i64 0, i32 0, i32 0, i32 0, i64 0
  %2936 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %2937 = bitcast i64* %2936 to double*
  %.pre41 = load i64, i64* %PC, align 8
  br label %block_40129a

block_40127b:                                     ; preds = %block_401216
  %2938 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %2939 = add i64 %2928, 3
  store i64 %2939, i64* %PC, align 8
  %2940 = load i32, i32* %2880, align 4
  %2941 = shl i32 %2940, 1
  %2942 = icmp slt i32 %2940, 0
  %2943 = icmp slt i32 %2941, 0
  %2944 = xor i1 %2942, %2943
  %2945 = zext i32 %2941 to i64
  store i64 %2945, i64* %RAX, align 8, !tbaa !2428
  %.lobit12 = lshr i32 %2940, 31
  %2946 = trunc i32 %.lobit12 to i8
  store i8 %2946, i8* %50, align 1, !tbaa !2453
  %2947 = and i32 %2941, 254
  %2948 = tail call i32 @llvm.ctpop.i32(i32 %2947) #14
  %2949 = trunc i32 %2948 to i8
  %2950 = and i8 %2949, 1
  %2951 = xor i8 %2950, 1
  store i8 %2951, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2952 = icmp eq i32 %2941, 0
  %2953 = zext i1 %2952 to i8
  store i8 %2953, i8* %53, align 1, !tbaa !2453
  %2954 = lshr i32 %2940, 30
  %2955 = trunc i32 %2954 to i8
  %2956 = and i8 %2955, 1
  store i8 %2956, i8* %54, align 1, !tbaa !2453
  %2957 = zext i1 %2944 to i8
  store i8 %2957, i8* %55, align 1, !tbaa !2453
  %2958 = add i64 %2877, -52
  %2959 = add i64 %2928, 9
  store i64 %2959, i64* %PC, align 8
  %2960 = inttoptr i64 %2958 to i32*
  store i32 %2941, i32* %2960, align 4
  %2961 = load i64, i64* %RBP, align 8
  %2962 = add i64 %2961, -48
  %2963 = load i64, i64* %PC, align 8
  %2964 = add i64 %2963, 3
  store i64 %2964, i64* %PC, align 8
  %2965 = inttoptr i64 %2962 to i32*
  %2966 = load i32, i32* %2965, align 4
  %2967 = shl i32 %2966, 3
  %2968 = zext i32 %2967 to i64
  store i64 %2968, i64* %RAX, align 8, !tbaa !2428
  %2969 = lshr i32 %2966, 29
  %2970 = trunc i32 %2969 to i8
  %2971 = and i8 %2970, 1
  store i8 %2971, i8* %50, align 1, !tbaa !2453
  %2972 = and i32 %2967, 248
  %2973 = tail call i32 @llvm.ctpop.i32(i32 %2972) #14
  %2974 = trunc i32 %2973 to i8
  %2975 = and i8 %2974, 1
  %2976 = xor i8 %2975, 1
  store i8 %2976, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2977 = icmp eq i32 %2967, 0
  %2978 = zext i1 %2977 to i8
  store i8 %2978, i8* %53, align 1, !tbaa !2453
  %2979 = lshr i32 %2966, 28
  %2980 = trunc i32 %2979 to i8
  %2981 = and i8 %2980, 1
  store i8 %2981, i8* %54, align 1, !tbaa !2453
  store i8 0, i8* %55, align 1, !tbaa !2453
  %2982 = add i64 %2961, -44
  %2983 = add i64 %2963, 9
  store i64 %2983, i64* %PC, align 8
  %2984 = inttoptr i64 %2982 to i32*
  %2985 = load i32, i32* %2984, align 4
  %2986 = sub i32 %2967, %2985
  %2987 = icmp ult i32 %2967, %2985
  %2988 = zext i1 %2987 to i8
  store i8 %2988, i8* %50, align 1, !tbaa !2432
  %2989 = and i32 %2986, 255
  %2990 = tail call i32 @llvm.ctpop.i32(i32 %2989) #14
  %2991 = trunc i32 %2990 to i8
  %2992 = and i8 %2991, 1
  %2993 = xor i8 %2992, 1
  store i8 %2993, i8* %51, align 1, !tbaa !2446
  %2994 = xor i32 %2985, %2967
  %2995 = xor i32 %2994, %2986
  %2996 = lshr i32 %2995, 4
  %2997 = trunc i32 %2996 to i8
  %2998 = and i8 %2997, 1
  store i8 %2998, i8* %52, align 1, !tbaa !2447
  %2999 = icmp eq i32 %2986, 0
  %3000 = zext i1 %2999 to i8
  store i8 %3000, i8* %53, align 1, !tbaa !2448
  %3001 = lshr i32 %2986, 31
  %3002 = trunc i32 %3001 to i8
  store i8 %3002, i8* %54, align 1, !tbaa !2449
  %3003 = lshr i32 %2966, 28
  %3004 = and i32 %3003, 1
  %3005 = lshr i32 %2985, 31
  %3006 = xor i32 %3005, %3004
  %3007 = xor i32 %3001, %3004
  %3008 = add nuw nsw i32 %3007, %3006
  %3009 = icmp eq i32 %3008, 2
  %3010 = zext i1 %3009 to i8
  store i8 %3010, i8* %55, align 1, !tbaa !2450
  %.v = select i1 %2999, i64 15, i64 1040
  %3011 = add i64 %2963, %.v
  %3012 = add i64 %2961, -36
  %3013 = add i64 %3011, 7
  store i64 %3013, i64* %PC, align 8
  %3014 = inttoptr i64 %3012 to i32*
  br i1 %2999, label %block_401293, label %block_401694

block_401241:                                     ; preds = %block_401235
  %3015 = add i64 %1907, -16
  %3016 = add i64 %1943, 4
  store i64 %3016, i64* %PC, align 8
  %3017 = inttoptr i64 %3015 to i64*
  %3018 = load i64, i64* %3017, align 8
  store i64 %3018, i64* %RAX, align 8, !tbaa !2428
  %3019 = add i64 %1943, 8
  store i64 %3019, i64* %PC, align 8
  %3020 = load i32, i32* %1910, align 4
  %3021 = sext i32 %3020 to i64
  store i64 %3021, i64* %RCX, align 8, !tbaa !2428
  %3022 = shl nsw i64 %3021, 2
  %3023 = add i64 %3022, %3018
  %3024 = add i64 %1943, 11
  store i64 %3024, i64* %PC, align 8
  %3025 = inttoptr i64 %3023 to i32*
  %3026 = load i32, i32* %3025, align 4
  %3027 = zext i32 %3026 to i64
  store i64 %3027, i64* %RDX, align 8, !tbaa !2428
  %3028 = add i64 %1907, -44
  %3029 = add i64 %1943, 14
  store i64 %3029, i64* %PC, align 8
  %3030 = inttoptr i64 %3028 to i32*
  %3031 = load i32, i32* %3030, align 4
  %3032 = add i32 %3031, %3026
  %3033 = zext i32 %3032 to i64
  store i64 %3033, i64* %RDX, align 8, !tbaa !2428
  %3034 = icmp ult i32 %3032, %3026
  %3035 = icmp ult i32 %3032, %3031
  %3036 = or i1 %3034, %3035
  %3037 = zext i1 %3036 to i8
  store i8 %3037, i8* %50, align 1, !tbaa !2432
  %3038 = and i32 %3032, 255
  %3039 = tail call i32 @llvm.ctpop.i32(i32 %3038) #14
  %3040 = trunc i32 %3039 to i8
  %3041 = and i8 %3040, 1
  %3042 = xor i8 %3041, 1
  store i8 %3042, i8* %51, align 1, !tbaa !2446
  %3043 = xor i32 %3031, %3026
  %3044 = xor i32 %3043, %3032
  %3045 = lshr i32 %3044, 4
  %3046 = trunc i32 %3045 to i8
  %3047 = and i8 %3046, 1
  store i8 %3047, i8* %52, align 1, !tbaa !2447
  %3048 = icmp eq i32 %3032, 0
  %3049 = zext i1 %3048 to i8
  store i8 %3049, i8* %53, align 1, !tbaa !2448
  %3050 = lshr i32 %3032, 31
  %3051 = trunc i32 %3050 to i8
  store i8 %3051, i8* %54, align 1, !tbaa !2449
  %3052 = lshr i32 %3026, 31
  %3053 = lshr i32 %3031, 31
  %3054 = xor i32 %3050, %3052
  %3055 = xor i32 %3050, %3053
  %3056 = add nuw nsw i32 %3054, %3055
  %3057 = icmp eq i32 %3056, 2
  %3058 = zext i1 %3057 to i8
  store i8 %3058, i8* %55, align 1, !tbaa !2450
  %3059 = add i64 %1943, 18
  store i64 %3059, i64* %PC, align 8
  %3060 = load i64, i64* %3017, align 8
  store i64 %3060, i64* %RAX, align 8, !tbaa !2428
  %3061 = add i64 %1943, 21
  store i64 %3061, i64* %PC, align 8
  %3062 = load i32, i32* %1915, align 4
  %3063 = zext i32 %3062 to i64
  store i64 %3063, i64* %RSI, align 8, !tbaa !2428
  %3064 = add i64 %1943, 24
  store i64 %3064, i64* %PC, align 8
  %3065 = load i32, i32* %1910, align 4
  %3066 = add i32 %3065, %3062
  %3067 = zext i32 %3066 to i64
  store i64 %3067, i64* %RSI, align 8, !tbaa !2428
  %3068 = icmp ult i32 %3066, %3062
  %3069 = icmp ult i32 %3066, %3065
  %3070 = or i1 %3068, %3069
  %3071 = zext i1 %3070 to i8
  store i8 %3071, i8* %50, align 1, !tbaa !2432
  %3072 = and i32 %3066, 255
  %3073 = tail call i32 @llvm.ctpop.i32(i32 %3072) #14
  %3074 = trunc i32 %3073 to i8
  %3075 = and i8 %3074, 1
  %3076 = xor i8 %3075, 1
  store i8 %3076, i8* %51, align 1, !tbaa !2446
  %3077 = xor i32 %3065, %3062
  %3078 = xor i32 %3077, %3066
  %3079 = lshr i32 %3078, 4
  %3080 = trunc i32 %3079 to i8
  %3081 = and i8 %3080, 1
  store i8 %3081, i8* %52, align 1, !tbaa !2447
  %3082 = icmp eq i32 %3066, 0
  %3083 = zext i1 %3082 to i8
  store i8 %3083, i8* %53, align 1, !tbaa !2448
  %3084 = lshr i32 %3066, 31
  %3085 = trunc i32 %3084 to i8
  store i8 %3085, i8* %54, align 1, !tbaa !2449
  %3086 = lshr i32 %3062, 31
  %3087 = lshr i32 %3065, 31
  %3088 = xor i32 %3084, %3086
  %3089 = xor i32 %3084, %3087
  %3090 = add nuw nsw i32 %3088, %3089
  %3091 = icmp eq i32 %3090, 2
  %3092 = zext i1 %3091 to i8
  store i8 %3092, i8* %55, align 1, !tbaa !2450
  %3093 = sext i32 %3066 to i64
  store i64 %3093, i64* %RCX, align 8, !tbaa !2428
  %3094 = shl nsw i64 %3093, 2
  %3095 = add i64 %3060, %3094
  %3096 = add i64 %1943, 30
  store i64 %3096, i64* %PC, align 8
  %3097 = inttoptr i64 %3095 to i32*
  store i32 %3032, i32* %3097, align 4
  %3098 = load i64, i64* %RBP, align 8
  %3099 = add i64 %3098, -28
  %3100 = load i64, i64* %PC, align 8
  %3101 = add i64 %3100, 3
  store i64 %3101, i64* %PC, align 8
  %3102 = inttoptr i64 %3099 to i32*
  %3103 = load i32, i32* %3102, align 4
  %3104 = add i32 %3103, 1
  %3105 = zext i32 %3104 to i64
  store i64 %3105, i64* %RAX, align 8, !tbaa !2428
  %3106 = icmp eq i32 %3103, -1
  %3107 = icmp eq i32 %3104, 0
  %3108 = or i1 %3106, %3107
  %3109 = zext i1 %3108 to i8
  store i8 %3109, i8* %50, align 1, !tbaa !2432
  %3110 = and i32 %3104, 255
  %3111 = tail call i32 @llvm.ctpop.i32(i32 %3110) #14
  %3112 = trunc i32 %3111 to i8
  %3113 = and i8 %3112, 1
  %3114 = xor i8 %3113, 1
  store i8 %3114, i8* %51, align 1, !tbaa !2446
  %3115 = xor i32 %3104, %3103
  %3116 = lshr i32 %3115, 4
  %3117 = trunc i32 %3116 to i8
  %3118 = and i8 %3117, 1
  store i8 %3118, i8* %52, align 1, !tbaa !2447
  %3119 = zext i1 %3107 to i8
  store i8 %3119, i8* %53, align 1, !tbaa !2448
  %3120 = lshr i32 %3104, 31
  %3121 = trunc i32 %3120 to i8
  store i8 %3121, i8* %54, align 1, !tbaa !2449
  %3122 = lshr i32 %3103, 31
  %3123 = xor i32 %3120, %3122
  %3124 = add nuw nsw i32 %3123, %3120
  %3125 = icmp eq i32 %3124, 2
  %3126 = zext i1 %3125 to i8
  store i8 %3126, i8* %55, align 1, !tbaa !2450
  %3127 = add i64 %3100, 9
  store i64 %3127, i64* %PC, align 8
  store i32 %3104, i32* %3102, align 4
  %3128 = load i64, i64* %PC, align 8
  %3129 = add i64 %3128, -51
  store i64 %3129, i64* %PC, align 8, !tbaa !2428
  br label %block_401235
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400760__start(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400760:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  store i64 0, i64* %RBP, align 8, !tbaa !2428
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %3, align 1, !tbaa !2432
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %4, align 1, !tbaa !2446
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %5, align 1, !tbaa !2448
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %6, align 1, !tbaa !2449
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %7, align 1, !tbaa !2450
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %8, align 1, !tbaa !2447
  %9 = load i64, i64* %RDX, align 8
  store i64 %9, i64* %R9, align 8, !tbaa !2428
  %10 = add i64 %1, 6
  store i64 %10, i64* %PC, align 8
  %11 = load i64, i64* %RSP, align 8, !tbaa !2428
  %12 = add i64 %11, 8
  %13 = inttoptr i64 %11 to i64*
  %14 = load i64, i64* %13, align 8
  store i64 %14, i64* %RSI, align 8, !tbaa !2428
  store i64 %12, i64* %RDX, align 8, !tbaa !2428
  %15 = and i64 %12, -16
  store i8 0, i8* %3, align 1, !tbaa !2432
  %16 = trunc i64 %12 to i32
  %17 = and i32 %16, 240
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17) #14
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  store i8 %21, i8* %4, align 1, !tbaa !2446
  %22 = icmp eq i64 %15, 0
  %23 = zext i1 %22 to i8
  store i8 %23, i8* %5, align 1, !tbaa !2448
  %24 = lshr i64 %12, 63
  %25 = trunc i64 %24 to i8
  store i8 %25, i8* %6, align 1, !tbaa !2449
  store i8 0, i8* %7, align 1, !tbaa !2450
  store i8 0, i8* %8, align 1, !tbaa !2447
  %26 = load i64, i64* %RAX, align 8
  %27 = add i64 %1, 14
  store i64 %27, i64* %PC, align 8
  %28 = add i64 %15, -8
  %29 = inttoptr i64 %28 to i64*
  store i64 %26, i64* %29, align 8
  %30 = load i64, i64* %PC, align 8
  %31 = add i64 %30, 1
  store i64 %31, i64* %PC, align 8
  %32 = add i64 %15, -16
  %33 = inttoptr i64 %32 to i64*
  store i64 %28, i64* %33, align 16
  %34 = load i64, i64* %PC, align 8
  store i64 ptrtoint (void ()* @callback_sub_404090___libc_csu_fini to i64), i64* %R8, align 8, !tbaa !2428
  store i64 ptrtoint (void ()* @callback_sub_404020___libc_csu_init to i64), i64* %RCX, align 8, !tbaa !2428
  store i64 ptrtoint (void ()* @main to i64), i64* %RDI, align 8, !tbaa !2428
  %35 = add i64 %34, 27
  %36 = add i64 %15, -24
  %37 = inttoptr i64 %36 to i64*
  store i64 %35, i64* %37, align 8
  store i64 %36, i64* %RSP, align 8, !tbaa !2428
  %38 = load i64, i64* getelementptr inbounds (%seg_604ff0__got_type, %seg_604ff0__got_type* @seg_604ff0__got, i64 0, i32 0), align 8
  store i64 %38, i64* %PC, align 8, !tbaa !2428
  %39 = tail call fastcc %struct.Memory* @ext_605120___libc_start_main(%struct.State* nonnull %0, %struct.Memory* %2)
  %40 = load i64, i64* %PC, align 8
  %41 = add i64 %40, 1
  store i64 %41, i64* %PC, align 8
  %42 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull %0, i64 %41, %struct.Memory* %39)
  ret %struct.Memory* %42
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_401100_errorcheck(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_401100:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %5 to i32*
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %6 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %6, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %10 = load i64, i64* %RBP, align 8
  %11 = add i64 %1, 1
  store i64 %11, i64* %PC, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %13 = load i64, i64* %12, align 8, !tbaa !2428
  %14 = add i64 %13, -8
  %15 = inttoptr i64 %14 to i64*
  store i64 %10, i64* %15, align 8
  store i64 %14, i64* %12, align 8, !tbaa !2428
  %16 = load i64, i64* %PC, align 8
  store i64 %14, i64* %RBP, align 8, !tbaa !2428
  %17 = bitcast %union.VectorReg* %8 to i8*
  %18 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %8, i64 0, i32 0, i32 0, i32 0, i64 0
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %20 = bitcast %union.VectorReg* %8 to i32*
  %21 = getelementptr inbounds i8, i8* %17, i64 4
  %22 = bitcast i8* %21 to i32*
  %23 = bitcast i64* %19 to i32*
  %24 = getelementptr inbounds i8, i8* %17, i64 12
  %25 = bitcast i8* %24 to i32*
  %26 = bitcast %union.VectorReg* %8 to <4 x i32>*
  store <4 x i32> zeroinitializer, <4 x i32>* %26, align 1, !tbaa !2469
  %27 = add i64 %13, -12
  %28 = load i32, i32* %EDI, align 4
  %29 = add i64 %16, 9
  store i64 %29, i64* %PC, align 8
  %30 = inttoptr i64 %27 to i32*
  store i32 %28, i32* %30, align 4
  %31 = load i64, i64* %RBP, align 8
  %32 = add i64 %31, -8
  %33 = load i32, i32* %ESI, align 4
  %34 = load i64, i64* %PC, align 8
  %35 = add i64 %34, 3
  store i64 %35, i64* %PC, align 8
  %36 = inttoptr i64 %32 to i32*
  store i32 %33, i32* %36, align 4
  %37 = load i64, i64* %RBP, align 8
  %38 = add i64 %37, -16
  %39 = load i64, i64* %PC, align 8
  %40 = add i64 %39, 5
  store i64 %40, i64* %PC, align 8
  %41 = bitcast [32 x %union.VectorReg]* %7 to double*
  %42 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %43 = load i64, i64* %42, align 1
  %44 = inttoptr i64 %38 to i64*
  store i64 %43, i64* %44, align 8
  %45 = load i64, i64* %RBP, align 8
  %46 = add i64 %45, -24
  %47 = load i64, i64* %RDX, align 8
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 4
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %46 to i64*
  store i64 %47, i64* %50, align 8
  %51 = load i64, i64* %RBP, align 8
  %52 = add i64 %51, -32
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 7
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %52 to i32*
  store i32 0, i32* %55, align 4
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -40
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 5
  store i64 %59, i64* %PC, align 8
  %60 = bitcast %union.VectorReg* %8 to double*
  %61 = load i64, i64* %18, align 1
  %62 = inttoptr i64 %57 to i64*
  store i64 %61, i64* %62, align 8
  %63 = load i64, i64* %RBP, align 8
  %64 = add i64 %63, -4
  %65 = load i64, i64* %PC, align 8
  %66 = add i64 %65, 3
  store i64 %66, i64* %PC, align 8
  %67 = inttoptr i64 %64 to i32*
  %68 = load i32, i32* %67, align 4
  %69 = zext i32 %68 to i64
  store i64 %69, i64* %RSI, align 8, !tbaa !2428
  %70 = add i64 %63, -28
  %71 = add i64 %65, 6
  store i64 %71, i64* %PC, align 8
  %72 = inttoptr i64 %70 to i32*
  store i32 %68, i32* %72, align 4
  %73 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %74 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %75 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %76 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %77 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %78 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %79 = bitcast [32 x %union.VectorReg]* %7 to i8*
  %80 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %81 = bitcast i64* %80 to double*
  %82 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %83 = bitcast %union.VectorReg* %9 to i8*
  %84 = bitcast %union.VectorReg* %9 to i32*
  %85 = getelementptr inbounds i8, i8* %83, i64 4
  %86 = bitcast i8* %85 to i32*
  %87 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %88 = bitcast i64* %87 to i32*
  %89 = getelementptr inbounds i8, i8* %83, i64 12
  %90 = bitcast i8* %89 to i32*
  %91 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %9, i64 0, i32 0, i32 0, i32 0, i64 0
  %92 = bitcast [32 x %union.VectorReg]* %7 to i32*
  %93 = getelementptr inbounds i8, i8* %79, i64 4
  %94 = bitcast i8* %93 to i32*
  %95 = bitcast i64* %80 to i32*
  %96 = getelementptr inbounds i8, i8* %79, i64 12
  %97 = bitcast i8* %96 to i32*
  %.pre = load i64, i64* %PC, align 8
  br label %block_401128

block_40119e:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %98 = add i64 %259, -40
  %99 = add i64 %266, 5
  store i64 %99, i64* %PC, align 8
  %100 = inttoptr i64 %98 to i64*
  %101 = load i64, i64* %100, align 8
  store i64 %101, i64* %42, align 1, !tbaa !2451
  store double 0.000000e+00, double* %81, align 1, !tbaa !2451
  %102 = add i64 %259, -64
  %103 = add i64 %266, 10
  store i64 %103, i64* %PC, align 8
  %104 = inttoptr i64 %102 to i64*
  store i64 %101, i64* %104, align 8
  %105 = load i64, i64* %PC, align 8
  %106 = add i64 %105, 26
  store i64 %106, i64* %PC, align 8, !tbaa !2428
  br label %block_4011c2

block_4011da:                                     ; preds = %block_401128
  %107 = add i64 %285, -40
  %108 = add i64 %321, 5
  store i64 %108, i64* %PC, align 8
  %109 = inttoptr i64 %107 to i64*
  %110 = load i64, i64* %109, align 8
  store i64 %110, i64* %42, align 1, !tbaa !2451
  store double 0.000000e+00, double* %81, align 1, !tbaa !2451
  %111 = add i64 %321, 6
  store i64 %111, i64* %PC, align 8
  %112 = load i64, i64* %12, align 8, !tbaa !2428
  %113 = add i64 %112, 8
  %114 = inttoptr i64 %112 to i64*
  %115 = load i64, i64* %114, align 8
  store i64 %115, i64* %RBP, align 8, !tbaa !2428
  store i64 %113, i64* %12, align 8, !tbaa !2428
  %116 = add i64 %321, 7
  store i64 %116, i64* %PC, align 8
  %117 = inttoptr i64 %113 to i64*
  %118 = load i64, i64* %117, align 8
  store i64 %118, i64* %PC, align 8, !tbaa !2428
  %119 = add i64 %112, 16
  store i64 %119, i64* %12, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_401134:                                     ; preds = %block_401128
  %120 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 72) to i64*), align 8
  store i64 %120, i64* %42, align 1, !tbaa !2451
  store double 0.000000e+00, double* %81, align 1, !tbaa !2451
  store i64 259200, i64* %RAX, align 8, !tbaa !2428
  %121 = add i64 %285, -32
  %122 = add i64 %321, 20
  store i64 %122, i64* %PC, align 8
  %123 = inttoptr i64 %121 to i32*
  %124 = load i32, i32* %123, align 4
  %125 = mul i32 %124, 7141
  %126 = add i32 %125, 54773
  %127 = zext i32 %126 to i64
  store i64 %127, i64* %RCX, align 8, !tbaa !2428
  %128 = icmp ugt i32 %125, -54774
  %129 = zext i1 %128 to i8
  store i8 %129, i8* %73, align 1, !tbaa !2432
  %130 = and i32 %126, 255
  %131 = tail call i32 @llvm.ctpop.i32(i32 %130) #14
  %132 = trunc i32 %131 to i8
  %133 = and i8 %132, 1
  %134 = xor i8 %133, 1
  store i8 %134, i8* %74, align 1, !tbaa !2446
  %135 = xor i32 %125, 16
  %136 = xor i32 %135, %126
  %137 = lshr i32 %136, 4
  %138 = trunc i32 %137 to i8
  %139 = and i8 %138, 1
  store i8 %139, i8* %75, align 1, !tbaa !2447
  %140 = icmp eq i32 %126, 0
  %141 = zext i1 %140 to i8
  store i8 %141, i8* %76, align 1, !tbaa !2448
  %142 = lshr i32 %126, 31
  %143 = trunc i32 %142 to i8
  store i8 %143, i8* %77, align 1, !tbaa !2449
  %144 = lshr i32 %125, 31
  %145 = xor i32 %142, %144
  %146 = add nuw nsw i32 %145, %142
  %147 = icmp eq i32 %146, 2
  %148 = zext i1 %147 to i8
  store i8 %148, i8* %78, align 1, !tbaa !2450
  %149 = add i64 %285, -52
  %150 = add i64 %321, 29
  store i64 %150, i64* %PC, align 8
  %151 = inttoptr i64 %149 to i32*
  store i32 259200, i32* %151, align 4
  %152 = load i32, i32* %ECX, align 4
  %153 = zext i32 %152 to i64
  %154 = load i64, i64* %PC, align 8
  store i64 %153, i64* %RAX, align 8, !tbaa !2428
  %155 = sext i32 %152 to i64
  %156 = lshr i64 %155, 32
  store i64 %156, i64* %82, align 8, !tbaa !2428
  %157 = load i64, i64* %RBP, align 8
  %158 = add i64 %157, -52
  %159 = add i64 %154, 6
  store i64 %159, i64* %PC, align 8
  %160 = inttoptr i64 %158 to i32*
  %161 = load i32, i32* %160, align 4
  %162 = zext i32 %161 to i64
  store i64 %162, i64* %RCX, align 8, !tbaa !2428
  %163 = add i64 %154, 8
  store i64 %163, i64* %PC, align 8
  %164 = sext i32 %161 to i64
  %165 = shl nuw i64 %156, 32
  %166 = or i64 %165, %153
  %167 = sdiv i64 %166, %164
  %168 = shl i64 %167, 32
  %169 = ashr exact i64 %168, 32
  %170 = icmp eq i64 %167, %169
  br i1 %170, label %173, label %171

; <label>:171:                                    ; preds = %block_401134
  %172 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %163, %struct.Memory* %MEMORY.0) #16
  %.pre2 = load i64, i64* %RBP, align 8
  %.pre3 = load i32, i32* %EDX, align 4
  %.pre4 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:173:                                    ; preds = %block_401134
  %174 = srem i64 %166, %164
  %175 = and i64 %167, 4294967295
  store i64 %175, i64* %RAX, align 8, !tbaa !2428
  %176 = and i64 %174, 4294967295
  store i64 %176, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %73, align 1, !tbaa !2432
  store i8 0, i8* %74, align 1, !tbaa !2446
  store i8 0, i8* %75, align 1, !tbaa !2447
  store i8 0, i8* %76, align 1, !tbaa !2448
  store i8 0, i8* %77, align 1, !tbaa !2449
  store i8 0, i8* %78, align 1, !tbaa !2450
  %177 = trunc i64 %174 to i32
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %173, %171
  %178 = phi i64 [ %.pre4, %171 ], [ %163, %173 ]
  %179 = phi i32 [ %.pre3, %171 ], [ %177, %173 ]
  %180 = phi i64 [ %.pre2, %171 ], [ %157, %173 ]
  %181 = phi %struct.Memory* [ %172, %171 ], [ %MEMORY.0, %173 ]
  %182 = add i64 %180, -32
  %183 = add i64 %178, 3
  store i64 %183, i64* %PC, align 8
  %184 = inttoptr i64 %182 to i32*
  store i32 %179, i32* %184, align 4
  %185 = load i32, i32* %EDX, align 4
  %186 = load i64, i64* %PC, align 8
  %187 = sitofp i32 %185 to double
  %188 = load double, double* %41, align 1
  %189 = fmul double %187, %188
  store double %189, double* %60, align 1, !tbaa !2451
  %190 = load i64, i64* %RBP, align 8
  %191 = add i64 %190, -24
  %192 = add i64 %186, 12
  store i64 %192, i64* %PC, align 8
  %193 = inttoptr i64 %191 to i64*
  %194 = load i64, i64* %193, align 8
  store i64 %194, i64* %RSI, align 8, !tbaa !2428
  %195 = add i64 %190, -28
  %196 = add i64 %186, 16
  store i64 %196, i64* %PC, align 8
  %197 = inttoptr i64 %195 to i32*
  %198 = load i32, i32* %197, align 4
  %199 = sext i32 %198 to i64
  store i64 %199, i64* %RDI, align 8, !tbaa !2428
  %200 = shl nsw i64 %199, 3
  %201 = add i64 %200, %194
  %202 = add i64 %186, 21
  store i64 %202, i64* %PC, align 8
  %203 = inttoptr i64 %201 to i64*
  %204 = load i64, i64* %203, align 8
  store i64 %204, i64* %42, align 1, !tbaa !2451
  store double 0.000000e+00, double* %81, align 1, !tbaa !2451
  %205 = add i64 %190, -16
  %206 = add i64 %186, 26
  store i64 %206, i64* %PC, align 8
  %207 = bitcast i64 %204 to double
  %208 = inttoptr i64 %205 to double*
  %209 = load double, double* %208, align 8
  %210 = fmul double %207, %209
  store double %210, double* %41, align 1, !tbaa !2451
  store i64 0, i64* %80, align 1, !tbaa !2451
  %211 = fsub double %189, %210
  store double %211, double* %60, align 1, !tbaa !2451
  %212 = add i64 %190, -48
  %213 = add i64 %186, 35
  store i64 %213, i64* %PC, align 8
  %214 = inttoptr i64 %212 to double*
  store double %211, double* %214, align 8
  %215 = load i64, i64* %RBP, align 8
  %216 = add i64 %215, -40
  %217 = load i64, i64* %PC, align 8
  %218 = add i64 %217, 5
  store i64 %218, i64* %PC, align 8
  %219 = inttoptr i64 %216 to i64*
  %220 = load i64, i64* %219, align 8
  store i64 %220, i64* %42, align 1, !tbaa !2451
  store double 0.000000e+00, double* %81, align 1, !tbaa !2451
  %221 = add i64 %215, -48
  %222 = add i64 %217, 10
  store i64 %222, i64* %PC, align 8
  %223 = inttoptr i64 %221 to i64*
  %224 = load i64, i64* %223, align 8
  %225 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 96) to i32*), align 16
  %226 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 100) to i32*), align 4
  %227 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 104) to i32*), align 8
  %228 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 108) to i32*), align 4
  store i32 %225, i32* %84, align 1, !tbaa !2475
  store i32 %226, i32* %86, align 1, !tbaa !2475
  store i32 %227, i32* %88, align 1, !tbaa !2475
  store i32 %228, i32* %90, align 1, !tbaa !2475
  %229 = load i64, i64* %91, align 1
  %230 = and i64 %229, %224
  %231 = trunc i64 %230 to i32
  %232 = lshr i64 %230, 32
  %233 = trunc i64 %232 to i32
  store i32 %231, i32* %20, align 1, !tbaa !2469
  store i32 %233, i32* %22, align 1, !tbaa !2469
  store i32 0, i32* %23, align 1, !tbaa !2469
  store i32 0, i32* %25, align 1, !tbaa !2469
  %234 = add i64 %217, 25
  store i64 %234, i64* %PC, align 8
  %235 = bitcast i64 %220 to double
  %236 = load double, double* %60, align 1
  %237 = fcmp uno double %235, %236
  br i1 %237, label %238, label %248

; <label>:238:                                    ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit
  %239 = fadd double %235, %236
  %240 = bitcast double %239 to i64
  %241 = and i64 %240, 9221120237041090560
  %242 = icmp eq i64 %241, 9218868437227405312
  %243 = and i64 %240, 2251799813685247
  %244 = icmp ne i64 %243, 0
  %245 = and i1 %242, %244
  br i1 %245, label %246, label %254

; <label>:246:                                    ; preds = %238
  %247 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %234, %struct.Memory* %181) #16
  %.pre5 = load i64, i64* %PC, align 8
  %.pre6 = load i64, i64* %RBP, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

; <label>:248:                                    ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit
  %249 = fcmp ogt double %235, %236
  br i1 %249, label %254, label %250

; <label>:250:                                    ; preds = %248
  %251 = fcmp olt double %235, %236
  br i1 %251, label %254, label %252

; <label>:252:                                    ; preds = %250
  %253 = fcmp oeq double %235, %236
  br i1 %253, label %254, label %258

; <label>:254:                                    ; preds = %252, %250, %248, %238
  %255 = phi i8 [ 0, %248 ], [ 0, %250 ], [ 1, %252 ], [ 1, %238 ]
  %256 = phi i8 [ 0, %248 ], [ 0, %250 ], [ 0, %252 ], [ 1, %238 ]
  %257 = phi i8 [ 0, %248 ], [ 1, %250 ], [ 0, %252 ], [ 1, %238 ]
  store i8 %255, i8* %76, align 1, !tbaa !2453
  store i8 %256, i8* %74, align 1, !tbaa !2453
  store i8 %257, i8* %73, align 1, !tbaa !2453
  br label %258

; <label>:258:                                    ; preds = %254, %252
  store i8 0, i8* %78, align 1, !tbaa !2453
  store i8 0, i8* %77, align 1, !tbaa !2453
  store i8 0, i8* %75, align 1, !tbaa !2453
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit: ; preds = %258, %246
  %259 = phi i64 [ %.pre6, %246 ], [ %215, %258 ]
  %260 = phi i64 [ %.pre5, %246 ], [ %234, %258 ]
  %261 = phi %struct.Memory* [ %247, %246 ], [ %181, %258 ]
  %262 = load i8, i8* %73, align 1, !tbaa !2432
  %263 = load i8, i8* %76, align 1, !tbaa !2448
  %264 = or i8 %263, %262
  %265 = icmp ne i8 %264, 0
  %.v9 = select i1 %265, i64 21, i64 6
  %266 = add i64 %260, %.v9
  store i64 %266, i64* %PC, align 8, !tbaa !2428
  br i1 %265, label %block_4011ad, label %block_40119e

block_4011ad:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %267 = add i64 %259, -48
  %268 = add i64 %266, 5
  store i64 %268, i64* %PC, align 8
  %269 = inttoptr i64 %267 to i64*
  %270 = load i64, i64* %269, align 8
  %271 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 96) to i32*), align 16
  %272 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 100) to i32*), align 4
  %273 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 104) to i32*), align 8
  %274 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 108) to i32*), align 4
  store i32 %271, i32* %20, align 1, !tbaa !2475
  store i32 %272, i32* %22, align 1, !tbaa !2475
  store i32 %273, i32* %23, align 1, !tbaa !2475
  store i32 %274, i32* %25, align 1, !tbaa !2475
  %275 = load i64, i64* %18, align 1
  %276 = and i64 %275, %270
  %277 = trunc i64 %276 to i32
  %278 = lshr i64 %276, 32
  %279 = trunc i64 %278 to i32
  store i32 %277, i32* %92, align 1, !tbaa !2469
  store i32 %279, i32* %94, align 1, !tbaa !2469
  store i32 0, i32* %95, align 1, !tbaa !2469
  store i32 0, i32* %97, align 1, !tbaa !2469
  %280 = add i64 %259, -64
  %281 = add i64 %266, 21
  store i64 %281, i64* %PC, align 8
  %282 = load i64, i64* %42, align 1
  %283 = inttoptr i64 %280 to i64*
  store i64 %282, i64* %283, align 8
  %.pre7 = load i64, i64* %PC, align 8
  br label %block_4011c2

block_401128:                                     ; preds = %block_4011c2, %block_401100
  %284 = phi i64 [ %.pre, %block_401100 ], [ %362, %block_4011c2 ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_401100 ], [ %261, %block_4011c2 ]
  %285 = load i64, i64* %RBP, align 8
  %286 = add i64 %285, -28
  %287 = add i64 %284, 3
  store i64 %287, i64* %PC, align 8
  %288 = inttoptr i64 %286 to i32*
  %289 = load i32, i32* %288, align 4
  %290 = zext i32 %289 to i64
  store i64 %290, i64* %RAX, align 8, !tbaa !2428
  %291 = add i64 %285, -8
  %292 = add i64 %284, 6
  store i64 %292, i64* %PC, align 8
  %293 = inttoptr i64 %291 to i32*
  %294 = load i32, i32* %293, align 4
  %295 = sub i32 %289, %294
  %296 = icmp ult i32 %289, %294
  %297 = zext i1 %296 to i8
  store i8 %297, i8* %73, align 1, !tbaa !2432
  %298 = and i32 %295, 255
  %299 = tail call i32 @llvm.ctpop.i32(i32 %298) #14
  %300 = trunc i32 %299 to i8
  %301 = and i8 %300, 1
  %302 = xor i8 %301, 1
  store i8 %302, i8* %74, align 1, !tbaa !2446
  %303 = xor i32 %294, %289
  %304 = xor i32 %303, %295
  %305 = lshr i32 %304, 4
  %306 = trunc i32 %305 to i8
  %307 = and i8 %306, 1
  store i8 %307, i8* %75, align 1, !tbaa !2447
  %308 = icmp eq i32 %295, 0
  %309 = zext i1 %308 to i8
  store i8 %309, i8* %76, align 1, !tbaa !2448
  %310 = lshr i32 %295, 31
  %311 = trunc i32 %310 to i8
  store i8 %311, i8* %77, align 1, !tbaa !2449
  %312 = lshr i32 %289, 31
  %313 = lshr i32 %294, 31
  %314 = xor i32 %313, %312
  %315 = xor i32 %310, %312
  %316 = add nuw nsw i32 %315, %314
  %317 = icmp eq i32 %316, 2
  %318 = zext i1 %317 to i8
  store i8 %318, i8* %78, align 1, !tbaa !2450
  %319 = icmp ne i8 %311, 0
  %320 = xor i1 %319, %317
  %.demorgan = or i1 %308, %320
  %.v = select i1 %.demorgan, i64 12, i64 178
  %321 = add i64 %284, %.v
  store i64 %321, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan, label %block_401134, label %block_4011da

block_4011c2:                                     ; preds = %block_4011ad, %block_40119e
  %322 = phi i64 [ %.pre7, %block_4011ad ], [ %106, %block_40119e ]
  %323 = load i64, i64* %RBP, align 8
  %324 = add i64 %323, -64
  %325 = add i64 %322, 5
  store i64 %325, i64* %PC, align 8
  %326 = inttoptr i64 %324 to i64*
  %327 = load i64, i64* %326, align 8
  store i64 %327, i64* %42, align 1, !tbaa !2451
  store double 0.000000e+00, double* %81, align 1, !tbaa !2451
  %328 = add i64 %323, -40
  %329 = add i64 %322, 10
  store i64 %329, i64* %PC, align 8
  %330 = inttoptr i64 %328 to i64*
  store i64 %327, i64* %330, align 8
  %331 = load i64, i64* %RBP, align 8
  %332 = add i64 %331, -28
  %333 = load i64, i64* %PC, align 8
  %334 = add i64 %333, 3
  store i64 %334, i64* %PC, align 8
  %335 = inttoptr i64 %332 to i32*
  %336 = load i32, i32* %335, align 4
  %337 = add i32 %336, 1
  %338 = zext i32 %337 to i64
  store i64 %338, i64* %RAX, align 8, !tbaa !2428
  %339 = icmp eq i32 %336, -1
  %340 = icmp eq i32 %337, 0
  %341 = or i1 %339, %340
  %342 = zext i1 %341 to i8
  store i8 %342, i8* %73, align 1, !tbaa !2432
  %343 = and i32 %337, 255
  %344 = tail call i32 @llvm.ctpop.i32(i32 %343) #14
  %345 = trunc i32 %344 to i8
  %346 = and i8 %345, 1
  %347 = xor i8 %346, 1
  store i8 %347, i8* %74, align 1, !tbaa !2446
  %348 = xor i32 %337, %336
  %349 = lshr i32 %348, 4
  %350 = trunc i32 %349 to i8
  %351 = and i8 %350, 1
  store i8 %351, i8* %75, align 1, !tbaa !2447
  %352 = zext i1 %340 to i8
  store i8 %352, i8* %76, align 1, !tbaa !2448
  %353 = lshr i32 %337, 31
  %354 = trunc i32 %353 to i8
  store i8 %354, i8* %77, align 1, !tbaa !2449
  %355 = lshr i32 %336, 31
  %356 = xor i32 %353, %355
  %357 = add nuw nsw i32 %356, %353
  %358 = icmp eq i32 %357, 2
  %359 = zext i1 %358 to i8
  store i8 %359, i8* %78, align 1, !tbaa !2450
  %360 = add i64 %333, 9
  store i64 %360, i64* %PC, align 8
  store i32 %337, i32* %335, align 4
  %361 = load i64, i64* %PC, align 8
  %362 = add i64 %361, -173
  store i64 %362, i64* %PC, align 8, !tbaa !2428
  br label %block_401128
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_401c10_bitrv2conj(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_401c10:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %1, 1
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %4, i64* %9, align 8
  store i64 %8, i64* %6, align 8, !tbaa !2428
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -12
  %12 = load i32, i32* %EDI, align 4
  %13 = add i64 %10, 6
  store i64 %13, i64* %PC, align 8
  %14 = inttoptr i64 %11 to i32*
  store i32 %12, i32* %14, align 4
  %15 = load i64, i64* %RBP, align 8
  %16 = add i64 %15, -16
  %17 = load i64, i64* %RSI, align 8
  %18 = load i64, i64* %PC, align 8
  %19 = add i64 %18, 4
  store i64 %19, i64* %PC, align 8
  %20 = inttoptr i64 %16 to i64*
  store i64 %17, i64* %20, align 8
  %21 = load i64, i64* %RBP, align 8
  %22 = add i64 %21, -24
  %23 = load i64, i64* %RDX, align 8
  %24 = load i64, i64* %PC, align 8
  %25 = add i64 %24, 4
  store i64 %25, i64* %PC, align 8
  %26 = inttoptr i64 %22 to i64*
  store i64 %23, i64* %26, align 8
  %27 = load i64, i64* %RBP, align 8
  %28 = add i64 %27, -16
  %29 = load i64, i64* %PC, align 8
  %30 = add i64 %29, 4
  store i64 %30, i64* %PC, align 8
  %31 = inttoptr i64 %28 to i64*
  %32 = load i64, i64* %31, align 8
  store i64 %32, i64* %RDX, align 8, !tbaa !2428
  %33 = add i64 %29, 10
  store i64 %33, i64* %PC, align 8
  %34 = inttoptr i64 %32 to i32*
  store i32 0, i32* %34, align 4
  %35 = load i64, i64* %RBP, align 8
  %36 = add i64 %35, -4
  %37 = load i64, i64* %PC, align 8
  %38 = add i64 %37, 3
  store i64 %38, i64* %PC, align 8
  %39 = inttoptr i64 %36 to i32*
  %40 = load i32, i32* %39, align 4
  %41 = zext i32 %40 to i64
  store i64 %41, i64* %RDI, align 8, !tbaa !2428
  %42 = add i64 %35, -44
  %43 = add i64 %37, 6
  store i64 %43, i64* %PC, align 8
  %44 = inttoptr i64 %42 to i32*
  store i32 %40, i32* %44, align 4
  %45 = load i64, i64* %RBP, align 8
  %46 = add i64 %45, -48
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 7
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %46 to i32*
  store i32 1, i32* %49, align 4
  %50 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %53 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %.pre = load i64, i64* %PC, align 8
  br label %block_401c36

block_401c61:                                     ; preds = %block_401c55
  %56 = add i64 %2041, -16
  %57 = add i64 %2077, 4
  store i64 %57, i64* %PC, align 8
  %58 = inttoptr i64 %56 to i64*
  %59 = load i64, i64* %58, align 8
  store i64 %59, i64* %RAX, align 8, !tbaa !2428
  %60 = add i64 %2077, 8
  store i64 %60, i64* %PC, align 8
  %61 = load i32, i32* %2044, align 4
  %62 = sext i32 %61 to i64
  store i64 %62, i64* %RCX, align 8, !tbaa !2428
  %63 = shl nsw i64 %62, 2
  %64 = add i64 %63, %59
  %65 = add i64 %2077, 11
  store i64 %65, i64* %PC, align 8
  %66 = inttoptr i64 %64 to i32*
  %67 = load i32, i32* %66, align 4
  %68 = zext i32 %67 to i64
  store i64 %68, i64* %RDX, align 8, !tbaa !2428
  %69 = add i64 %2041, -44
  %70 = add i64 %2077, 14
  store i64 %70, i64* %PC, align 8
  %71 = inttoptr i64 %69 to i32*
  %72 = load i32, i32* %71, align 4
  %73 = add i32 %72, %67
  %74 = zext i32 %73 to i64
  store i64 %74, i64* %RDX, align 8, !tbaa !2428
  %75 = icmp ult i32 %73, %67
  %76 = icmp ult i32 %73, %72
  %77 = or i1 %75, %76
  %78 = zext i1 %77 to i8
  store i8 %78, i8* %50, align 1, !tbaa !2432
  %79 = and i32 %73, 255
  %80 = tail call i32 @llvm.ctpop.i32(i32 %79) #14
  %81 = trunc i32 %80 to i8
  %82 = and i8 %81, 1
  %83 = xor i8 %82, 1
  store i8 %83, i8* %51, align 1, !tbaa !2446
  %84 = xor i32 %72, %67
  %85 = xor i32 %84, %73
  %86 = lshr i32 %85, 4
  %87 = trunc i32 %86 to i8
  %88 = and i8 %87, 1
  store i8 %88, i8* %52, align 1, !tbaa !2447
  %89 = icmp eq i32 %73, 0
  %90 = zext i1 %89 to i8
  store i8 %90, i8* %53, align 1, !tbaa !2448
  %91 = lshr i32 %73, 31
  %92 = trunc i32 %91 to i8
  store i8 %92, i8* %54, align 1, !tbaa !2449
  %93 = lshr i32 %67, 31
  %94 = lshr i32 %72, 31
  %95 = xor i32 %91, %93
  %96 = xor i32 %91, %94
  %97 = add nuw nsw i32 %95, %96
  %98 = icmp eq i32 %97, 2
  %99 = zext i1 %98 to i8
  store i8 %99, i8* %55, align 1, !tbaa !2450
  %100 = add i64 %2077, 18
  store i64 %100, i64* %PC, align 8
  %101 = load i64, i64* %58, align 8
  store i64 %101, i64* %RAX, align 8, !tbaa !2428
  %102 = add i64 %2077, 21
  store i64 %102, i64* %PC, align 8
  %103 = load i32, i32* %2049, align 4
  %104 = zext i32 %103 to i64
  store i64 %104, i64* %RSI, align 8, !tbaa !2428
  %105 = add i64 %2077, 24
  store i64 %105, i64* %PC, align 8
  %106 = load i32, i32* %2044, align 4
  %107 = add i32 %106, %103
  %108 = zext i32 %107 to i64
  store i64 %108, i64* %RSI, align 8, !tbaa !2428
  %109 = icmp ult i32 %107, %103
  %110 = icmp ult i32 %107, %106
  %111 = or i1 %109, %110
  %112 = zext i1 %111 to i8
  store i8 %112, i8* %50, align 1, !tbaa !2432
  %113 = and i32 %107, 255
  %114 = tail call i32 @llvm.ctpop.i32(i32 %113) #14
  %115 = trunc i32 %114 to i8
  %116 = and i8 %115, 1
  %117 = xor i8 %116, 1
  store i8 %117, i8* %51, align 1, !tbaa !2446
  %118 = xor i32 %106, %103
  %119 = xor i32 %118, %107
  %120 = lshr i32 %119, 4
  %121 = trunc i32 %120 to i8
  %122 = and i8 %121, 1
  store i8 %122, i8* %52, align 1, !tbaa !2447
  %123 = icmp eq i32 %107, 0
  %124 = zext i1 %123 to i8
  store i8 %124, i8* %53, align 1, !tbaa !2448
  %125 = lshr i32 %107, 31
  %126 = trunc i32 %125 to i8
  store i8 %126, i8* %54, align 1, !tbaa !2449
  %127 = lshr i32 %103, 31
  %128 = lshr i32 %106, 31
  %129 = xor i32 %125, %127
  %130 = xor i32 %125, %128
  %131 = add nuw nsw i32 %129, %130
  %132 = icmp eq i32 %131, 2
  %133 = zext i1 %132 to i8
  store i8 %133, i8* %55, align 1, !tbaa !2450
  %134 = sext i32 %107 to i64
  store i64 %134, i64* %RCX, align 8, !tbaa !2428
  %135 = shl nsw i64 %134, 2
  %136 = add i64 %101, %135
  %137 = add i64 %2077, 30
  store i64 %137, i64* %PC, align 8
  %138 = inttoptr i64 %136 to i32*
  store i32 %73, i32* %138, align 4
  %139 = load i64, i64* %RBP, align 8
  %140 = add i64 %139, -28
  %141 = load i64, i64* %PC, align 8
  %142 = add i64 %141, 3
  store i64 %142, i64* %PC, align 8
  %143 = inttoptr i64 %140 to i32*
  %144 = load i32, i32* %143, align 4
  %145 = add i32 %144, 1
  %146 = zext i32 %145 to i64
  store i64 %146, i64* %RAX, align 8, !tbaa !2428
  %147 = icmp eq i32 %144, -1
  %148 = icmp eq i32 %145, 0
  %149 = or i1 %147, %148
  %150 = zext i1 %149 to i8
  store i8 %150, i8* %50, align 1, !tbaa !2432
  %151 = and i32 %145, 255
  %152 = tail call i32 @llvm.ctpop.i32(i32 %151) #14
  %153 = trunc i32 %152 to i8
  %154 = and i8 %153, 1
  %155 = xor i8 %154, 1
  store i8 %155, i8* %51, align 1, !tbaa !2446
  %156 = xor i32 %145, %144
  %157 = lshr i32 %156, 4
  %158 = trunc i32 %157 to i8
  %159 = and i8 %158, 1
  store i8 %159, i8* %52, align 1, !tbaa !2447
  %160 = zext i1 %148 to i8
  store i8 %160, i8* %53, align 1, !tbaa !2448
  %161 = lshr i32 %145, 31
  %162 = trunc i32 %161 to i8
  store i8 %162, i8* %54, align 1, !tbaa !2449
  %163 = lshr i32 %144, 31
  %164 = xor i32 %161, %163
  %165 = add nuw nsw i32 %164, %161
  %166 = icmp eq i32 %165, 2
  %167 = zext i1 %166 to i8
  store i8 %167, i8* %55, align 1, !tbaa !2450
  %168 = add i64 %141, 9
  store i64 %168, i64* %PC, align 8
  store i32 %145, i32* %143, align 4
  %169 = load i64, i64* %PC, align 8
  %170 = add i64 %169, -51
  store i64 %170, i64* %PC, align 8, !tbaa !2428
  br label %block_401c55

block_40204f:                                     ; preds = %block_401ccd
  %171 = load i32, i32* %828, align 4
  %172 = shl i32 %171, 1
  %173 = icmp slt i32 %171, 0
  %174 = icmp slt i32 %172, 0
  %175 = xor i1 %173, %174
  %176 = zext i32 %172 to i64
  store i64 %176, i64* %RCX, align 8, !tbaa !2428
  %.lobit18 = lshr i32 %171, 31
  %177 = trunc i32 %.lobit18 to i8
  store i8 %177, i8* %50, align 1, !tbaa !2453
  %178 = and i32 %172, 254
  %179 = tail call i32 @llvm.ctpop.i32(i32 %178) #14
  %180 = trunc i32 %179 to i8
  %181 = and i8 %180, 1
  %182 = xor i8 %181, 1
  store i8 %182, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %183 = icmp eq i32 %172, 0
  %184 = zext i1 %183 to i8
  store i8 %184, i8* %53, align 1, !tbaa !2453
  %185 = lshr i32 %171, 30
  %186 = trunc i32 %185 to i8
  %187 = and i8 %186, 1
  store i8 %187, i8* %54, align 1, !tbaa !2453
  %188 = zext i1 %175 to i8
  store i8 %188, i8* %55, align 1, !tbaa !2453
  %189 = add i64 %820, -16
  %190 = add i64 %856, 20
  store i64 %190, i64* %PC, align 8
  %191 = inttoptr i64 %189 to i64*
  %192 = load i64, i64* %191, align 8
  store i64 %192, i64* %RDX, align 8, !tbaa !2428
  %193 = add i64 %856, 24
  store i64 %193, i64* %PC, align 8
  %194 = load i32, i32* %828, align 4
  %195 = sext i32 %194 to i64
  store i64 %195, i64* %RSI, align 8, !tbaa !2428
  %196 = shl nsw i64 %195, 2
  %197 = add i64 %192, %196
  %198 = add i64 %856, 27
  store i64 %198, i64* %PC, align 8
  %199 = inttoptr i64 %197 to i32*
  %200 = load i32, i32* %199, align 4
  %201 = add i32 %200, %172
  %202 = zext i32 %201 to i64
  store i64 %202, i64* %RCX, align 8, !tbaa !2428
  %203 = icmp ult i32 %201, %172
  %204 = icmp ult i32 %201, %200
  %205 = or i1 %203, %204
  %206 = zext i1 %205 to i8
  store i8 %206, i8* %50, align 1, !tbaa !2432
  %207 = and i32 %201, 255
  %208 = tail call i32 @llvm.ctpop.i32(i32 %207) #14
  %209 = trunc i32 %208 to i8
  %210 = and i8 %209, 1
  %211 = xor i8 %210, 1
  store i8 %211, i8* %51, align 1, !tbaa !2446
  %212 = xor i32 %200, %172
  %213 = xor i32 %212, %201
  %214 = lshr i32 %213, 4
  %215 = trunc i32 %214 to i8
  %216 = and i8 %215, 1
  store i8 %216, i8* %52, align 1, !tbaa !2447
  %217 = icmp eq i32 %201, 0
  %218 = zext i1 %217 to i8
  store i8 %218, i8* %53, align 1, !tbaa !2448
  %219 = lshr i32 %201, 31
  %220 = trunc i32 %219 to i8
  store i8 %220, i8* %54, align 1, !tbaa !2449
  %221 = lshr i32 %171, 30
  %222 = and i32 %221, 1
  %223 = lshr i32 %200, 31
  %224 = xor i32 %219, %222
  %225 = xor i32 %219, %223
  %226 = add nuw nsw i32 %224, %225
  %227 = icmp eq i32 %226, 2
  %228 = zext i1 %227 to i8
  store i8 %228, i8* %55, align 1, !tbaa !2450
  %229 = add i64 %820, -40
  %230 = add i64 %856, 30
  store i64 %230, i64* %PC, align 8
  %231 = inttoptr i64 %229 to i32*
  store i32 %201, i32* %231, align 4
  %232 = load i64, i64* %RBP, align 8
  %233 = add i64 %232, -24
  %234 = load i64, i64* %PC, align 8
  %235 = add i64 %234, 4
  store i64 %235, i64* %PC, align 8
  %236 = inttoptr i64 %233 to i64*
  %237 = load i64, i64* %236, align 8
  store i64 %237, i64* %RDX, align 8, !tbaa !2428
  %238 = add i64 %232, -40
  %239 = add i64 %234, 7
  store i64 %239, i64* %PC, align 8
  %240 = inttoptr i64 %238 to i32*
  %241 = load i32, i32* %240, align 4
  %242 = add i32 %241, 1
  %243 = zext i32 %242 to i64
  store i64 %243, i64* %RCX, align 8, !tbaa !2428
  %244 = icmp eq i32 %241, -1
  %245 = icmp eq i32 %242, 0
  %246 = or i1 %244, %245
  %247 = zext i1 %246 to i8
  store i8 %247, i8* %50, align 1, !tbaa !2432
  %248 = and i32 %242, 255
  %249 = tail call i32 @llvm.ctpop.i32(i32 %248) #14
  %250 = trunc i32 %249 to i8
  %251 = and i8 %250, 1
  %252 = xor i8 %251, 1
  store i8 %252, i8* %51, align 1, !tbaa !2446
  %253 = xor i32 %242, %241
  %254 = lshr i32 %253, 4
  %255 = trunc i32 %254 to i8
  %256 = and i8 %255, 1
  store i8 %256, i8* %52, align 1, !tbaa !2447
  %257 = zext i1 %245 to i8
  store i8 %257, i8* %53, align 1, !tbaa !2448
  %258 = lshr i32 %242, 31
  %259 = trunc i32 %258 to i8
  store i8 %259, i8* %54, align 1, !tbaa !2449
  %260 = lshr i32 %241, 31
  %261 = xor i32 %258, %260
  %262 = add nuw nsw i32 %261, %258
  %263 = icmp eq i32 %262, 2
  %264 = zext i1 %263 to i8
  store i8 %264, i8* %55, align 1, !tbaa !2450
  %265 = sext i32 %242 to i64
  store i64 %265, i64* %RSI, align 8, !tbaa !2428
  %266 = shl nsw i64 %265, 3
  %267 = add i64 %237, %266
  %268 = add i64 %234, 18
  store i64 %268, i64* %PC, align 8
  %269 = inttoptr i64 %267 to i64*
  %270 = load i64, i64* %269, align 8
  %271 = load i64, i64* %RAX, align 8
  %272 = xor i64 %271, %270
  store i64 %272, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %273 = trunc i64 %272 to i32
  %274 = and i32 %273, 255
  %275 = tail call i32 @llvm.ctpop.i32(i32 %274) #14
  %276 = trunc i32 %275 to i8
  %277 = and i8 %276, 1
  %278 = xor i8 %277, 1
  store i8 %278, i8* %51, align 1, !tbaa !2446
  %279 = icmp eq i64 %272, 0
  %280 = zext i1 %279 to i8
  store i8 %280, i8* %53, align 1, !tbaa !2448
  %281 = lshr i64 %272, 63
  %282 = trunc i64 %281 to i8
  store i8 %282, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %272, i64* %1808, align 1, !tbaa !2428
  store i64 0, i64* %1809, align 1, !tbaa !2428
  %283 = add i64 %234, 35
  store i64 %283, i64* %PC, align 8
  %284 = load i64, i64* %236, align 8
  store i64 %284, i64* %RDX, align 8, !tbaa !2428
  %285 = add i64 %234, 38
  store i64 %285, i64* %PC, align 8
  %286 = load i32, i32* %240, align 4
  %287 = add i32 %286, 1
  %288 = zext i32 %287 to i64
  store i64 %288, i64* %RCX, align 8, !tbaa !2428
  %289 = icmp eq i32 %286, -1
  %290 = icmp eq i32 %287, 0
  %291 = or i1 %289, %290
  %292 = zext i1 %291 to i8
  store i8 %292, i8* %50, align 1, !tbaa !2432
  %293 = and i32 %287, 255
  %294 = tail call i32 @llvm.ctpop.i32(i32 %293) #14
  %295 = trunc i32 %294 to i8
  %296 = and i8 %295, 1
  %297 = xor i8 %296, 1
  store i8 %297, i8* %51, align 1, !tbaa !2446
  %298 = xor i32 %287, %286
  %299 = lshr i32 %298, 4
  %300 = trunc i32 %299 to i8
  %301 = and i8 %300, 1
  store i8 %301, i8* %52, align 1, !tbaa !2447
  %302 = zext i1 %290 to i8
  store i8 %302, i8* %53, align 1, !tbaa !2448
  %303 = lshr i32 %287, 31
  %304 = trunc i32 %303 to i8
  store i8 %304, i8* %54, align 1, !tbaa !2449
  %305 = lshr i32 %286, 31
  %306 = xor i32 %303, %305
  %307 = add nuw nsw i32 %306, %303
  %308 = icmp eq i32 %307, 2
  %309 = zext i1 %308 to i8
  store i8 %309, i8* %55, align 1, !tbaa !2450
  %310 = sext i32 %287 to i64
  store i64 %310, i64* %RSI, align 8, !tbaa !2428
  %311 = shl nsw i64 %310, 3
  %312 = add i64 %284, %311
  %313 = add i64 %234, 49
  store i64 %313, i64* %PC, align 8
  %314 = inttoptr i64 %312 to i64*
  store i64 %272, i64* %314, align 8
  %315 = load i64, i64* %RBP, align 8
  %316 = add i64 %315, -40
  %317 = load i64, i64* %PC, align 8
  %318 = add i64 %317, 3
  store i64 %318, i64* %PC, align 8
  %319 = inttoptr i64 %316 to i32*
  %320 = load i32, i32* %319, align 4
  %321 = zext i32 %320 to i64
  store i64 %321, i64* %RCX, align 8, !tbaa !2428
  %322 = add i64 %315, -52
  %323 = add i64 %317, 6
  store i64 %323, i64* %PC, align 8
  %324 = inttoptr i64 %322 to i32*
  %325 = load i32, i32* %324, align 4
  %326 = add i32 %325, %320
  %327 = zext i32 %326 to i64
  store i64 %327, i64* %RCX, align 8, !tbaa !2428
  %328 = icmp ult i32 %326, %320
  %329 = icmp ult i32 %326, %325
  %330 = or i1 %328, %329
  %331 = zext i1 %330 to i8
  store i8 %331, i8* %50, align 1, !tbaa !2432
  %332 = and i32 %326, 255
  %333 = tail call i32 @llvm.ctpop.i32(i32 %332) #14
  %334 = trunc i32 %333 to i8
  %335 = and i8 %334, 1
  %336 = xor i8 %335, 1
  store i8 %336, i8* %51, align 1, !tbaa !2446
  %337 = xor i32 %325, %320
  %338 = xor i32 %337, %326
  %339 = lshr i32 %338, 4
  %340 = trunc i32 %339 to i8
  %341 = and i8 %340, 1
  store i8 %341, i8* %52, align 1, !tbaa !2447
  %342 = icmp eq i32 %326, 0
  %343 = zext i1 %342 to i8
  store i8 %343, i8* %53, align 1, !tbaa !2448
  %344 = lshr i32 %326, 31
  %345 = trunc i32 %344 to i8
  store i8 %345, i8* %54, align 1, !tbaa !2449
  %346 = lshr i32 %320, 31
  %347 = lshr i32 %325, 31
  %348 = xor i32 %344, %346
  %349 = xor i32 %344, %347
  %350 = add nuw nsw i32 %348, %349
  %351 = icmp eq i32 %350, 2
  %352 = zext i1 %351 to i8
  store i8 %352, i8* %55, align 1, !tbaa !2450
  %353 = add i64 %315, -32
  %354 = add i64 %317, 9
  store i64 %354, i64* %PC, align 8
  %355 = inttoptr i64 %353 to i32*
  store i32 %326, i32* %355, align 4
  %356 = load i64, i64* %RBP, align 8
  %357 = add i64 %356, -32
  %358 = load i64, i64* %PC, align 8
  %359 = add i64 %358, 3
  store i64 %359, i64* %PC, align 8
  %360 = inttoptr i64 %357 to i32*
  %361 = load i32, i32* %360, align 4
  %362 = zext i32 %361 to i64
  store i64 %362, i64* %RCX, align 8, !tbaa !2428
  %363 = add i64 %356, -52
  %364 = add i64 %358, 6
  store i64 %364, i64* %PC, align 8
  %365 = inttoptr i64 %363 to i32*
  %366 = load i32, i32* %365, align 4
  %367 = add i32 %366, %361
  %368 = zext i32 %367 to i64
  store i64 %368, i64* %RCX, align 8, !tbaa !2428
  %369 = icmp ult i32 %367, %361
  %370 = icmp ult i32 %367, %366
  %371 = or i1 %369, %370
  %372 = zext i1 %371 to i8
  store i8 %372, i8* %50, align 1, !tbaa !2432
  %373 = and i32 %367, 255
  %374 = tail call i32 @llvm.ctpop.i32(i32 %373) #14
  %375 = trunc i32 %374 to i8
  %376 = and i8 %375, 1
  %377 = xor i8 %376, 1
  store i8 %377, i8* %51, align 1, !tbaa !2446
  %378 = xor i32 %366, %361
  %379 = xor i32 %378, %367
  %380 = lshr i32 %379, 4
  %381 = trunc i32 %380 to i8
  %382 = and i8 %381, 1
  store i8 %382, i8* %52, align 1, !tbaa !2447
  %383 = icmp eq i32 %367, 0
  %384 = zext i1 %383 to i8
  store i8 %384, i8* %53, align 1, !tbaa !2448
  %385 = lshr i32 %367, 31
  %386 = trunc i32 %385 to i8
  store i8 %386, i8* %54, align 1, !tbaa !2449
  %387 = lshr i32 %361, 31
  %388 = lshr i32 %366, 31
  %389 = xor i32 %385, %387
  %390 = xor i32 %385, %388
  %391 = add nuw nsw i32 %389, %390
  %392 = icmp eq i32 %391, 2
  %393 = zext i1 %392 to i8
  store i8 %393, i8* %55, align 1, !tbaa !2450
  %394 = add i64 %356, -40
  %395 = add i64 %358, 9
  store i64 %395, i64* %PC, align 8
  %396 = inttoptr i64 %394 to i32*
  store i32 %367, i32* %396, align 4
  %397 = load i64, i64* %RBP, align 8
  %398 = add i64 %397, -24
  %399 = load i64, i64* %PC, align 8
  %400 = add i64 %399, 4
  store i64 %400, i64* %PC, align 8
  %401 = inttoptr i64 %398 to i64*
  %402 = load i64, i64* %401, align 8
  store i64 %402, i64* %RDX, align 8, !tbaa !2428
  %403 = add i64 %397, -32
  %404 = add i64 %399, 8
  store i64 %404, i64* %PC, align 8
  %405 = inttoptr i64 %403 to i32*
  %406 = load i32, i32* %405, align 4
  %407 = sext i32 %406 to i64
  store i64 %407, i64* %RSI, align 8, !tbaa !2428
  %408 = shl nsw i64 %407, 3
  %409 = add i64 %408, %402
  %410 = add i64 %399, 13
  store i64 %410, i64* %PC, align 8
  %411 = inttoptr i64 %409 to i64*
  %412 = load i64, i64* %411, align 8
  store i64 %412, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %413 = add i64 %397, -64
  %414 = add i64 %399, 18
  store i64 %414, i64* %PC, align 8
  %415 = inttoptr i64 %413 to i64*
  store i64 %412, i64* %415, align 8
  %416 = load i64, i64* %RBP, align 8
  %417 = add i64 %416, -24
  %418 = load i64, i64* %PC, align 8
  %419 = add i64 %418, 4
  store i64 %419, i64* %PC, align 8
  %420 = inttoptr i64 %417 to i64*
  %421 = load i64, i64* %420, align 8
  store i64 %421, i64* %RDX, align 8, !tbaa !2428
  %422 = add i64 %416, -32
  %423 = add i64 %418, 7
  store i64 %423, i64* %PC, align 8
  %424 = inttoptr i64 %422 to i32*
  %425 = load i32, i32* %424, align 4
  %426 = add i32 %425, 1
  %427 = zext i32 %426 to i64
  store i64 %427, i64* %RCX, align 8, !tbaa !2428
  %428 = icmp eq i32 %425, -1
  %429 = icmp eq i32 %426, 0
  %430 = or i1 %428, %429
  %431 = zext i1 %430 to i8
  store i8 %431, i8* %50, align 1, !tbaa !2432
  %432 = and i32 %426, 255
  %433 = tail call i32 @llvm.ctpop.i32(i32 %432) #14
  %434 = trunc i32 %433 to i8
  %435 = and i8 %434, 1
  %436 = xor i8 %435, 1
  store i8 %436, i8* %51, align 1, !tbaa !2446
  %437 = xor i32 %426, %425
  %438 = lshr i32 %437, 4
  %439 = trunc i32 %438 to i8
  %440 = and i8 %439, 1
  store i8 %440, i8* %52, align 1, !tbaa !2447
  %441 = zext i1 %429 to i8
  store i8 %441, i8* %53, align 1, !tbaa !2448
  %442 = lshr i32 %426, 31
  %443 = trunc i32 %442 to i8
  store i8 %443, i8* %54, align 1, !tbaa !2449
  %444 = lshr i32 %425, 31
  %445 = xor i32 %442, %444
  %446 = add nuw nsw i32 %445, %442
  %447 = icmp eq i32 %446, 2
  %448 = zext i1 %447 to i8
  store i8 %448, i8* %55, align 1, !tbaa !2450
  %449 = sext i32 %426 to i64
  store i64 %449, i64* %RSI, align 8, !tbaa !2428
  %450 = shl nsw i64 %449, 3
  %451 = add i64 %421, %450
  %452 = add i64 %418, 18
  store i64 %452, i64* %PC, align 8
  %453 = inttoptr i64 %451 to i64*
  %454 = load i64, i64* %453, align 8
  %455 = load i64, i64* %RAX, align 8
  %456 = xor i64 %455, %454
  store i64 %456, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %457 = trunc i64 %456 to i32
  %458 = and i32 %457, 255
  %459 = tail call i32 @llvm.ctpop.i32(i32 %458) #14
  %460 = trunc i32 %459 to i8
  %461 = and i8 %460, 1
  %462 = xor i8 %461, 1
  store i8 %462, i8* %51, align 1, !tbaa !2446
  %463 = icmp eq i64 %456, 0
  %464 = zext i1 %463 to i8
  store i8 %464, i8* %53, align 1, !tbaa !2448
  %465 = lshr i64 %456, 63
  %466 = trunc i64 %465 to i8
  store i8 %466, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %456, i64* %1808, align 1, !tbaa !2428
  store i64 0, i64* %1809, align 1, !tbaa !2428
  %467 = add i64 %416, -72
  %468 = add i64 %418, 36
  store i64 %468, i64* %PC, align 8
  %469 = inttoptr i64 %467 to i64*
  store i64 %456, i64* %469, align 8
  %470 = load i64, i64* %RBP, align 8
  %471 = add i64 %470, -24
  %472 = load i64, i64* %PC, align 8
  %473 = add i64 %472, 4
  store i64 %473, i64* %PC, align 8
  %474 = inttoptr i64 %471 to i64*
  %475 = load i64, i64* %474, align 8
  store i64 %475, i64* %RDX, align 8, !tbaa !2428
  %476 = add i64 %470, -40
  %477 = add i64 %472, 8
  store i64 %477, i64* %PC, align 8
  %478 = inttoptr i64 %476 to i32*
  %479 = load i32, i32* %478, align 4
  %480 = sext i32 %479 to i64
  store i64 %480, i64* %RSI, align 8, !tbaa !2428
  %481 = shl nsw i64 %480, 3
  %482 = add i64 %481, %475
  %483 = add i64 %472, 13
  store i64 %483, i64* %PC, align 8
  %484 = inttoptr i64 %482 to i64*
  %485 = load i64, i64* %484, align 8
  store i64 %485, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %486 = add i64 %470, -80
  %487 = add i64 %472, 18
  store i64 %487, i64* %PC, align 8
  %488 = inttoptr i64 %486 to i64*
  store i64 %485, i64* %488, align 8
  %489 = load i64, i64* %RBP, align 8
  %490 = add i64 %489, -24
  %491 = load i64, i64* %PC, align 8
  %492 = add i64 %491, 4
  store i64 %492, i64* %PC, align 8
  %493 = inttoptr i64 %490 to i64*
  %494 = load i64, i64* %493, align 8
  store i64 %494, i64* %RDX, align 8, !tbaa !2428
  %495 = add i64 %489, -40
  %496 = add i64 %491, 7
  store i64 %496, i64* %PC, align 8
  %497 = inttoptr i64 %495 to i32*
  %498 = load i32, i32* %497, align 4
  %499 = add i32 %498, 1
  %500 = zext i32 %499 to i64
  store i64 %500, i64* %RCX, align 8, !tbaa !2428
  %501 = icmp eq i32 %498, -1
  %502 = icmp eq i32 %499, 0
  %503 = or i1 %501, %502
  %504 = zext i1 %503 to i8
  store i8 %504, i8* %50, align 1, !tbaa !2432
  %505 = and i32 %499, 255
  %506 = tail call i32 @llvm.ctpop.i32(i32 %505) #14
  %507 = trunc i32 %506 to i8
  %508 = and i8 %507, 1
  %509 = xor i8 %508, 1
  store i8 %509, i8* %51, align 1, !tbaa !2446
  %510 = xor i32 %499, %498
  %511 = lshr i32 %510, 4
  %512 = trunc i32 %511 to i8
  %513 = and i8 %512, 1
  store i8 %513, i8* %52, align 1, !tbaa !2447
  %514 = zext i1 %502 to i8
  store i8 %514, i8* %53, align 1, !tbaa !2448
  %515 = lshr i32 %499, 31
  %516 = trunc i32 %515 to i8
  store i8 %516, i8* %54, align 1, !tbaa !2449
  %517 = lshr i32 %498, 31
  %518 = xor i32 %515, %517
  %519 = add nuw nsw i32 %518, %515
  %520 = icmp eq i32 %519, 2
  %521 = zext i1 %520 to i8
  store i8 %521, i8* %55, align 1, !tbaa !2450
  %522 = sext i32 %499 to i64
  store i64 %522, i64* %RSI, align 8, !tbaa !2428
  %523 = shl nsw i64 %522, 3
  %524 = add i64 %494, %523
  %525 = add i64 %491, 18
  store i64 %525, i64* %PC, align 8
  %526 = inttoptr i64 %524 to i64*
  %527 = load i64, i64* %526, align 8
  %528 = load i64, i64* %RAX, align 8
  %529 = xor i64 %528, %527
  store i64 %529, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %530 = trunc i64 %529 to i32
  %531 = and i32 %530, 255
  %532 = tail call i32 @llvm.ctpop.i32(i32 %531) #14
  %533 = trunc i32 %532 to i8
  %534 = and i8 %533, 1
  %535 = xor i8 %534, 1
  store i8 %535, i8* %51, align 1, !tbaa !2446
  %536 = icmp eq i64 %529, 0
  %537 = zext i1 %536 to i8
  store i8 %537, i8* %53, align 1, !tbaa !2448
  %538 = lshr i64 %529, 63
  %539 = trunc i64 %538 to i8
  store i8 %539, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %529, i64* %1808, align 1, !tbaa !2428
  store i64 0, i64* %1809, align 1, !tbaa !2428
  %540 = add i64 %489, -88
  %541 = add i64 %491, 36
  store i64 %541, i64* %PC, align 8
  %542 = inttoptr i64 %540 to i64*
  store i64 %529, i64* %542, align 8
  %543 = load i64, i64* %RBP, align 8
  %544 = add i64 %543, -80
  %545 = load i64, i64* %PC, align 8
  %546 = add i64 %545, 5
  store i64 %546, i64* %PC, align 8
  %547 = inttoptr i64 %544 to i64*
  %548 = load i64, i64* %547, align 8
  store i64 %548, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %549 = add i64 %543, -24
  %550 = add i64 %545, 9
  store i64 %550, i64* %PC, align 8
  %551 = inttoptr i64 %549 to i64*
  %552 = load i64, i64* %551, align 8
  store i64 %552, i64* %RDX, align 8, !tbaa !2428
  %553 = add i64 %543, -32
  %554 = add i64 %545, 13
  store i64 %554, i64* %PC, align 8
  %555 = inttoptr i64 %553 to i32*
  %556 = load i32, i32* %555, align 4
  %557 = sext i32 %556 to i64
  store i64 %557, i64* %RSI, align 8, !tbaa !2428
  %558 = shl nsw i64 %557, 3
  %559 = add i64 %558, %552
  %560 = add i64 %545, 18
  store i64 %560, i64* %PC, align 8
  %561 = inttoptr i64 %559 to i64*
  store i64 %548, i64* %561, align 8
  %562 = load i64, i64* %RBP, align 8
  %563 = add i64 %562, -88
  %564 = load i64, i64* %PC, align 8
  %565 = add i64 %564, 5
  store i64 %565, i64* %PC, align 8
  %566 = inttoptr i64 %563 to i64*
  %567 = load i64, i64* %566, align 8
  store i64 %567, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %568 = add i64 %562, -24
  %569 = add i64 %564, 9
  store i64 %569, i64* %PC, align 8
  %570 = inttoptr i64 %568 to i64*
  %571 = load i64, i64* %570, align 8
  store i64 %571, i64* %RDX, align 8, !tbaa !2428
  %572 = add i64 %562, -32
  %573 = add i64 %564, 12
  store i64 %573, i64* %PC, align 8
  %574 = inttoptr i64 %572 to i32*
  %575 = load i32, i32* %574, align 4
  %576 = add i32 %575, 1
  %577 = zext i32 %576 to i64
  store i64 %577, i64* %RCX, align 8, !tbaa !2428
  %578 = icmp eq i32 %575, -1
  %579 = icmp eq i32 %576, 0
  %580 = or i1 %578, %579
  %581 = zext i1 %580 to i8
  store i8 %581, i8* %50, align 1, !tbaa !2432
  %582 = and i32 %576, 255
  %583 = tail call i32 @llvm.ctpop.i32(i32 %582) #14
  %584 = trunc i32 %583 to i8
  %585 = and i8 %584, 1
  %586 = xor i8 %585, 1
  store i8 %586, i8* %51, align 1, !tbaa !2446
  %587 = xor i32 %576, %575
  %588 = lshr i32 %587, 4
  %589 = trunc i32 %588 to i8
  %590 = and i8 %589, 1
  store i8 %590, i8* %52, align 1, !tbaa !2447
  %591 = zext i1 %579 to i8
  store i8 %591, i8* %53, align 1, !tbaa !2448
  %592 = lshr i32 %576, 31
  %593 = trunc i32 %592 to i8
  store i8 %593, i8* %54, align 1, !tbaa !2449
  %594 = lshr i32 %575, 31
  %595 = xor i32 %592, %594
  %596 = add nuw nsw i32 %595, %592
  %597 = icmp eq i32 %596, 2
  %598 = zext i1 %597 to i8
  store i8 %598, i8* %55, align 1, !tbaa !2450
  %599 = sext i32 %576 to i64
  store i64 %599, i64* %RSI, align 8, !tbaa !2428
  %600 = shl nsw i64 %599, 3
  %601 = add i64 %571, %600
  %602 = add i64 %564, 23
  store i64 %602, i64* %PC, align 8
  %603 = inttoptr i64 %601 to i64*
  store i64 %567, i64* %603, align 8
  %604 = load i64, i64* %RBP, align 8
  %605 = add i64 %604, -64
  %606 = load i64, i64* %PC, align 8
  %607 = add i64 %606, 5
  store i64 %607, i64* %PC, align 8
  %608 = inttoptr i64 %605 to i64*
  %609 = load i64, i64* %608, align 8
  store i64 %609, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %610 = add i64 %604, -24
  %611 = add i64 %606, 9
  store i64 %611, i64* %PC, align 8
  %612 = inttoptr i64 %610 to i64*
  %613 = load i64, i64* %612, align 8
  store i64 %613, i64* %RDX, align 8, !tbaa !2428
  %614 = add i64 %604, -40
  %615 = add i64 %606, 13
  store i64 %615, i64* %PC, align 8
  %616 = inttoptr i64 %614 to i32*
  %617 = load i32, i32* %616, align 4
  %618 = sext i32 %617 to i64
  store i64 %618, i64* %RSI, align 8, !tbaa !2428
  %619 = shl nsw i64 %618, 3
  %620 = add i64 %619, %613
  %621 = add i64 %606, 18
  store i64 %621, i64* %PC, align 8
  %622 = inttoptr i64 %620 to i64*
  store i64 %609, i64* %622, align 8
  %623 = load i64, i64* %RBP, align 8
  %624 = add i64 %623, -72
  %625 = load i64, i64* %PC, align 8
  %626 = add i64 %625, 5
  store i64 %626, i64* %PC, align 8
  %627 = inttoptr i64 %624 to i64*
  %628 = load i64, i64* %627, align 8
  store i64 %628, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %629 = add i64 %623, -24
  %630 = add i64 %625, 9
  store i64 %630, i64* %PC, align 8
  %631 = inttoptr i64 %629 to i64*
  %632 = load i64, i64* %631, align 8
  store i64 %632, i64* %RDX, align 8, !tbaa !2428
  %633 = add i64 %623, -40
  %634 = add i64 %625, 12
  store i64 %634, i64* %PC, align 8
  %635 = inttoptr i64 %633 to i32*
  %636 = load i32, i32* %635, align 4
  %637 = add i32 %636, 1
  %638 = zext i32 %637 to i64
  store i64 %638, i64* %RCX, align 8, !tbaa !2428
  %639 = icmp eq i32 %636, -1
  %640 = icmp eq i32 %637, 0
  %641 = or i1 %639, %640
  %642 = zext i1 %641 to i8
  store i8 %642, i8* %50, align 1, !tbaa !2432
  %643 = and i32 %637, 255
  %644 = tail call i32 @llvm.ctpop.i32(i32 %643) #14
  %645 = trunc i32 %644 to i8
  %646 = and i8 %645, 1
  %647 = xor i8 %646, 1
  store i8 %647, i8* %51, align 1, !tbaa !2446
  %648 = xor i32 %637, %636
  %649 = lshr i32 %648, 4
  %650 = trunc i32 %649 to i8
  %651 = and i8 %650, 1
  store i8 %651, i8* %52, align 1, !tbaa !2447
  %652 = zext i1 %640 to i8
  store i8 %652, i8* %53, align 1, !tbaa !2448
  %653 = lshr i32 %637, 31
  %654 = trunc i32 %653 to i8
  store i8 %654, i8* %54, align 1, !tbaa !2449
  %655 = lshr i32 %636, 31
  %656 = xor i32 %653, %655
  %657 = add nuw nsw i32 %656, %653
  %658 = icmp eq i32 %657, 2
  %659 = zext i1 %658 to i8
  store i8 %659, i8* %55, align 1, !tbaa !2450
  %660 = sext i32 %637 to i64
  store i64 %660, i64* %RSI, align 8, !tbaa !2428
  %661 = shl nsw i64 %660, 3
  %662 = add i64 %632, %661
  %663 = add i64 %625, 23
  store i64 %663, i64* %PC, align 8
  %664 = inttoptr i64 %662 to i64*
  store i64 %628, i64* %664, align 8
  %665 = load i64, i64* %RBP, align 8
  %666 = add i64 %665, -52
  %667 = load i64, i64* %PC, align 8
  %668 = add i64 %667, 3
  store i64 %668, i64* %PC, align 8
  %669 = inttoptr i64 %666 to i32*
  %670 = load i32, i32* %669, align 4
  %671 = zext i32 %670 to i64
  store i64 %671, i64* %RCX, align 8, !tbaa !2428
  %672 = add i64 %665, -40
  %673 = add i64 %667, 6
  store i64 %673, i64* %PC, align 8
  %674 = inttoptr i64 %672 to i32*
  %675 = load i32, i32* %674, align 4
  %676 = add i32 %675, %670
  %677 = zext i32 %676 to i64
  store i64 %677, i64* %RCX, align 8, !tbaa !2428
  %678 = icmp ult i32 %676, %670
  %679 = icmp ult i32 %676, %675
  %680 = or i1 %678, %679
  %681 = zext i1 %680 to i8
  store i8 %681, i8* %50, align 1, !tbaa !2432
  %682 = and i32 %676, 255
  %683 = tail call i32 @llvm.ctpop.i32(i32 %682) #14
  %684 = trunc i32 %683 to i8
  %685 = and i8 %684, 1
  %686 = xor i8 %685, 1
  store i8 %686, i8* %51, align 1, !tbaa !2446
  %687 = xor i32 %675, %670
  %688 = xor i32 %687, %676
  %689 = lshr i32 %688, 4
  %690 = trunc i32 %689 to i8
  %691 = and i8 %690, 1
  store i8 %691, i8* %52, align 1, !tbaa !2447
  %692 = icmp eq i32 %676, 0
  %693 = zext i1 %692 to i8
  store i8 %693, i8* %53, align 1, !tbaa !2448
  %694 = lshr i32 %676, 31
  %695 = trunc i32 %694 to i8
  store i8 %695, i8* %54, align 1, !tbaa !2449
  %696 = lshr i32 %670, 31
  %697 = lshr i32 %675, 31
  %698 = xor i32 %694, %696
  %699 = xor i32 %694, %697
  %700 = add nuw nsw i32 %698, %699
  %701 = icmp eq i32 %700, 2
  %702 = zext i1 %701 to i8
  store i8 %702, i8* %55, align 1, !tbaa !2450
  %703 = add i64 %667, 9
  store i64 %703, i64* %PC, align 8
  store i32 %676, i32* %674, align 4
  %704 = load i64, i64* %RBP, align 8
  %705 = add i64 %704, -24
  %706 = load i64, i64* %PC, align 8
  %707 = add i64 %706, 4
  store i64 %707, i64* %PC, align 8
  %708 = inttoptr i64 %705 to i64*
  %709 = load i64, i64* %708, align 8
  store i64 %709, i64* %RDX, align 8, !tbaa !2428
  %710 = add i64 %704, -40
  %711 = add i64 %706, 7
  store i64 %711, i64* %PC, align 8
  %712 = inttoptr i64 %710 to i32*
  %713 = load i32, i32* %712, align 4
  %714 = add i32 %713, 1
  %715 = zext i32 %714 to i64
  store i64 %715, i64* %RCX, align 8, !tbaa !2428
  %716 = icmp eq i32 %713, -1
  %717 = icmp eq i32 %714, 0
  %718 = or i1 %716, %717
  %719 = zext i1 %718 to i8
  store i8 %719, i8* %50, align 1, !tbaa !2432
  %720 = and i32 %714, 255
  %721 = tail call i32 @llvm.ctpop.i32(i32 %720) #14
  %722 = trunc i32 %721 to i8
  %723 = and i8 %722, 1
  %724 = xor i8 %723, 1
  store i8 %724, i8* %51, align 1, !tbaa !2446
  %725 = xor i32 %714, %713
  %726 = lshr i32 %725, 4
  %727 = trunc i32 %726 to i8
  %728 = and i8 %727, 1
  store i8 %728, i8* %52, align 1, !tbaa !2447
  %729 = zext i1 %717 to i8
  store i8 %729, i8* %53, align 1, !tbaa !2448
  %730 = lshr i32 %714, 31
  %731 = trunc i32 %730 to i8
  store i8 %731, i8* %54, align 1, !tbaa !2449
  %732 = lshr i32 %713, 31
  %733 = xor i32 %730, %732
  %734 = add nuw nsw i32 %733, %730
  %735 = icmp eq i32 %734, 2
  %736 = zext i1 %735 to i8
  store i8 %736, i8* %55, align 1, !tbaa !2450
  %737 = sext i32 %714 to i64
  store i64 %737, i64* %RSI, align 8, !tbaa !2428
  %738 = shl nsw i64 %737, 3
  %739 = add i64 %709, %738
  %740 = add i64 %706, 18
  store i64 %740, i64* %PC, align 8
  %741 = inttoptr i64 %739 to i64*
  %742 = load i64, i64* %741, align 8
  %743 = load i64, i64* %RAX, align 8
  %744 = xor i64 %743, %742
  store i64 %744, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %745 = trunc i64 %744 to i32
  %746 = and i32 %745, 255
  %747 = tail call i32 @llvm.ctpop.i32(i32 %746) #14
  %748 = trunc i32 %747 to i8
  %749 = and i8 %748, 1
  %750 = xor i8 %749, 1
  store i8 %750, i8* %51, align 1, !tbaa !2446
  %751 = icmp eq i64 %744, 0
  %752 = zext i1 %751 to i8
  store i8 %752, i8* %53, align 1, !tbaa !2448
  %753 = lshr i64 %744, 63
  %754 = trunc i64 %753 to i8
  store i8 %754, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %744, i64* %1808, align 1, !tbaa !2428
  store i64 0, i64* %1809, align 1, !tbaa !2428
  %755 = add i64 %706, 35
  store i64 %755, i64* %PC, align 8
  %756 = load i64, i64* %708, align 8
  store i64 %756, i64* %RAX, align 8, !tbaa !2428
  %757 = add i64 %706, 38
  store i64 %757, i64* %PC, align 8
  %758 = load i32, i32* %712, align 4
  %759 = add i32 %758, 1
  %760 = zext i32 %759 to i64
  store i64 %760, i64* %RCX, align 8, !tbaa !2428
  %761 = icmp eq i32 %758, -1
  %762 = icmp eq i32 %759, 0
  %763 = or i1 %761, %762
  %764 = zext i1 %763 to i8
  store i8 %764, i8* %50, align 1, !tbaa !2432
  %765 = and i32 %759, 255
  %766 = tail call i32 @llvm.ctpop.i32(i32 %765) #14
  %767 = trunc i32 %766 to i8
  %768 = and i8 %767, 1
  %769 = xor i8 %768, 1
  store i8 %769, i8* %51, align 1, !tbaa !2446
  %770 = xor i32 %759, %758
  %771 = lshr i32 %770, 4
  %772 = trunc i32 %771 to i8
  %773 = and i8 %772, 1
  store i8 %773, i8* %52, align 1, !tbaa !2447
  %774 = zext i1 %762 to i8
  store i8 %774, i8* %53, align 1, !tbaa !2448
  %775 = lshr i32 %759, 31
  %776 = trunc i32 %775 to i8
  store i8 %776, i8* %54, align 1, !tbaa !2449
  %777 = lshr i32 %758, 31
  %778 = xor i32 %775, %777
  %779 = add nuw nsw i32 %778, %775
  %780 = icmp eq i32 %779, 2
  %781 = zext i1 %780 to i8
  store i8 %781, i8* %55, align 1, !tbaa !2450
  %782 = sext i32 %759 to i64
  store i64 %782, i64* %RDX, align 8, !tbaa !2428
  %783 = shl nsw i64 %782, 3
  %784 = add i64 %756, %783
  %785 = add i64 %706, 49
  store i64 %785, i64* %PC, align 8
  %786 = inttoptr i64 %784 to i64*
  store i64 %744, i64* %786, align 8
  %787 = load i64, i64* %RBP, align 8
  %788 = add i64 %787, -36
  %789 = load i64, i64* %PC, align 8
  %790 = add i64 %789, 3
  store i64 %790, i64* %PC, align 8
  %791 = inttoptr i64 %788 to i32*
  %792 = load i32, i32* %791, align 4
  %793 = add i32 %792, 1
  %794 = zext i32 %793 to i64
  store i64 %794, i64* %RAX, align 8, !tbaa !2428
  %795 = icmp eq i32 %792, -1
  %796 = icmp eq i32 %793, 0
  %797 = or i1 %795, %796
  %798 = zext i1 %797 to i8
  store i8 %798, i8* %50, align 1, !tbaa !2432
  %799 = and i32 %793, 255
  %800 = tail call i32 @llvm.ctpop.i32(i32 %799) #14
  %801 = trunc i32 %800 to i8
  %802 = and i8 %801, 1
  %803 = xor i8 %802, 1
  store i8 %803, i8* %51, align 1, !tbaa !2446
  %804 = xor i32 %793, %792
  %805 = lshr i32 %804, 4
  %806 = trunc i32 %805 to i8
  %807 = and i8 %806, 1
  store i8 %807, i8* %52, align 1, !tbaa !2447
  %808 = zext i1 %796 to i8
  store i8 %808, i8* %53, align 1, !tbaa !2448
  %809 = lshr i32 %793, 31
  %810 = trunc i32 %809 to i8
  store i8 %810, i8* %54, align 1, !tbaa !2449
  %811 = lshr i32 %792, 31
  %812 = xor i32 %809, %811
  %813 = add nuw nsw i32 %812, %809
  %814 = icmp eq i32 %813, 2
  %815 = zext i1 %814 to i8
  store i8 %815, i8* %55, align 1, !tbaa !2450
  %816 = add i64 %789, 9
  store i64 %816, i64* %PC, align 8
  store i32 %793, i32* %791, align 4
  %817 = load i64, i64* %PC, align 8
  %818 = add i64 %817, -1271
  store i64 %818, i64* %PC, align 8, !tbaa !2428
  br label %block_401cba

block_401ccd:                                     ; preds = %block_401cd9, %block_401cc6
  %819 = phi i64 [ %3598, %block_401cd9 ], [ %.pre41, %block_401cc6 ]
  %820 = load i64, i64* %RBP, align 8
  %821 = add i64 %820, -28
  %822 = add i64 %819, 3
  store i64 %822, i64* %PC, align 8
  %823 = inttoptr i64 %821 to i32*
  %824 = load i32, i32* %823, align 4
  %825 = zext i32 %824 to i64
  store i64 %825, i64* %RAX, align 8, !tbaa !2428
  %826 = add i64 %820, -36
  %827 = add i64 %819, 6
  store i64 %827, i64* %PC, align 8
  %828 = inttoptr i64 %826 to i32*
  %829 = load i32, i32* %828, align 4
  %830 = sub i32 %824, %829
  %831 = icmp ult i32 %824, %829
  %832 = zext i1 %831 to i8
  store i8 %832, i8* %50, align 1, !tbaa !2432
  %833 = and i32 %830, 255
  %834 = tail call i32 @llvm.ctpop.i32(i32 %833) #14
  %835 = trunc i32 %834 to i8
  %836 = and i8 %835, 1
  %837 = xor i8 %836, 1
  store i8 %837, i8* %51, align 1, !tbaa !2446
  %838 = xor i32 %829, %824
  %839 = xor i32 %838, %830
  %840 = lshr i32 %839, 4
  %841 = trunc i32 %840 to i8
  %842 = and i8 %841, 1
  store i8 %842, i8* %52, align 1, !tbaa !2447
  %843 = icmp eq i32 %830, 0
  %844 = zext i1 %843 to i8
  store i8 %844, i8* %53, align 1, !tbaa !2448
  %845 = lshr i32 %830, 31
  %846 = trunc i32 %845 to i8
  store i8 %846, i8* %54, align 1, !tbaa !2449
  %847 = lshr i32 %824, 31
  %848 = lshr i32 %829, 31
  %849 = xor i32 %848, %847
  %850 = xor i32 %845, %847
  %851 = add nuw nsw i32 %850, %849
  %852 = icmp eq i32 %851, 2
  %853 = zext i1 %852 to i8
  store i8 %853, i8* %55, align 1, !tbaa !2450
  %854 = icmp ne i8 %846, 0
  %855 = xor i1 %854, %852
  %.v49 = select i1 %855, i64 12, i64 898
  %856 = add i64 %819, %.v49
  %857 = add i64 %856, 10
  store i64 %857, i64* %PC, align 8
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %858 = add i64 %856, 13
  store i64 %858, i64* %PC, align 8
  br i1 %855, label %block_401cd9, label %block_40204f

block_401cc6:                                     ; preds = %block_401cba
  %859 = add i64 %1855, -28
  %860 = add i64 %1891, 7
  store i64 %860, i64* %PC, align 8
  %861 = inttoptr i64 %859 to i32*
  store i32 0, i32* %861, align 4
  %.pre41 = load i64, i64* %PC, align 8
  br label %block_401ccd

block_40223b:                                     ; preds = %block_40222f
  %862 = load i32, i32* %1815, align 4
  %863 = shl i32 %862, 1
  %864 = icmp slt i32 %862, 0
  %865 = icmp slt i32 %863, 0
  %866 = xor i1 %864, %865
  %867 = zext i32 %863 to i64
  store i64 %867, i64* %RCX, align 8, !tbaa !2428
  %.lobit19 = lshr i32 %862, 31
  %868 = trunc i32 %.lobit19 to i8
  store i8 %868, i8* %50, align 1, !tbaa !2453
  %869 = and i32 %863, 254
  %870 = tail call i32 @llvm.ctpop.i32(i32 %869) #14
  %871 = trunc i32 %870 to i8
  %872 = and i8 %871, 1
  %873 = xor i8 %872, 1
  store i8 %873, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %874 = icmp eq i32 %863, 0
  %875 = zext i1 %874 to i8
  store i8 %875, i8* %53, align 1, !tbaa !2453
  %876 = lshr i32 %862, 30
  %877 = trunc i32 %876 to i8
  %878 = and i8 %877, 1
  store i8 %878, i8* %54, align 1, !tbaa !2453
  %879 = zext i1 %866 to i8
  store i8 %879, i8* %55, align 1, !tbaa !2453
  %880 = add i64 %1812, -16
  %881 = add i64 %1848, 20
  store i64 %881, i64* %PC, align 8
  %882 = inttoptr i64 %880 to i64*
  %883 = load i64, i64* %882, align 8
  store i64 %883, i64* %RDX, align 8, !tbaa !2428
  %884 = add i64 %1848, 24
  store i64 %884, i64* %PC, align 8
  %885 = load i32, i32* %1820, align 4
  %886 = sext i32 %885 to i64
  store i64 %886, i64* %RSI, align 8, !tbaa !2428
  %887 = shl nsw i64 %886, 2
  %888 = add i64 %883, %887
  %889 = add i64 %1848, 27
  store i64 %889, i64* %PC, align 8
  %890 = inttoptr i64 %888 to i32*
  %891 = load i32, i32* %890, align 4
  %892 = add i32 %891, %863
  %893 = zext i32 %892 to i64
  store i64 %893, i64* %RCX, align 8, !tbaa !2428
  %894 = icmp ult i32 %892, %863
  %895 = icmp ult i32 %892, %891
  %896 = or i1 %894, %895
  %897 = zext i1 %896 to i8
  store i8 %897, i8* %50, align 1, !tbaa !2432
  %898 = and i32 %892, 255
  %899 = tail call i32 @llvm.ctpop.i32(i32 %898) #14
  %900 = trunc i32 %899 to i8
  %901 = and i8 %900, 1
  %902 = xor i8 %901, 1
  store i8 %902, i8* %51, align 1, !tbaa !2446
  %903 = xor i32 %891, %863
  %904 = xor i32 %903, %892
  %905 = lshr i32 %904, 4
  %906 = trunc i32 %905 to i8
  %907 = and i8 %906, 1
  store i8 %907, i8* %52, align 1, !tbaa !2447
  %908 = icmp eq i32 %892, 0
  %909 = zext i1 %908 to i8
  store i8 %909, i8* %53, align 1, !tbaa !2448
  %910 = lshr i32 %892, 31
  %911 = trunc i32 %910 to i8
  store i8 %911, i8* %54, align 1, !tbaa !2449
  %912 = lshr i32 %862, 30
  %913 = and i32 %912, 1
  %914 = lshr i32 %891, 31
  %915 = xor i32 %910, %913
  %916 = xor i32 %910, %914
  %917 = add nuw nsw i32 %915, %916
  %918 = icmp eq i32 %917, 2
  %919 = zext i1 %918 to i8
  store i8 %919, i8* %55, align 1, !tbaa !2450
  %920 = add i64 %1812, -32
  %921 = add i64 %1848, 30
  store i64 %921, i64* %PC, align 8
  %922 = inttoptr i64 %920 to i32*
  store i32 %892, i32* %922, align 4
  %923 = load i64, i64* %RBP, align 8
  %924 = add i64 %923, -36
  %925 = load i64, i64* %PC, align 8
  %926 = add i64 %925, 3
  store i64 %926, i64* %PC, align 8
  %927 = inttoptr i64 %924 to i32*
  %928 = load i32, i32* %927, align 4
  %929 = shl i32 %928, 1
  %930 = icmp slt i32 %928, 0
  %931 = icmp slt i32 %929, 0
  %932 = xor i1 %930, %931
  %933 = zext i32 %929 to i64
  store i64 %933, i64* %RCX, align 8, !tbaa !2428
  %.lobit20 = lshr i32 %928, 31
  %934 = trunc i32 %.lobit20 to i8
  store i8 %934, i8* %50, align 1, !tbaa !2453
  %935 = and i32 %929, 254
  %936 = tail call i32 @llvm.ctpop.i32(i32 %935) #14
  %937 = trunc i32 %936 to i8
  %938 = and i8 %937, 1
  %939 = xor i8 %938, 1
  store i8 %939, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %940 = icmp eq i32 %929, 0
  %941 = zext i1 %940 to i8
  store i8 %941, i8* %53, align 1, !tbaa !2453
  %942 = lshr i32 %928, 30
  %943 = trunc i32 %942 to i8
  %944 = and i8 %943, 1
  store i8 %944, i8* %54, align 1, !tbaa !2453
  %945 = zext i1 %932 to i8
  store i8 %945, i8* %55, align 1, !tbaa !2453
  %946 = add i64 %923, -16
  %947 = add i64 %925, 10
  store i64 %947, i64* %PC, align 8
  %948 = inttoptr i64 %946 to i64*
  %949 = load i64, i64* %948, align 8
  store i64 %949, i64* %RDX, align 8, !tbaa !2428
  %950 = add i64 %923, -28
  %951 = add i64 %925, 14
  store i64 %951, i64* %PC, align 8
  %952 = inttoptr i64 %950 to i32*
  %953 = load i32, i32* %952, align 4
  %954 = sext i32 %953 to i64
  store i64 %954, i64* %RSI, align 8, !tbaa !2428
  %955 = shl nsw i64 %954, 2
  %956 = add i64 %949, %955
  %957 = add i64 %925, 17
  store i64 %957, i64* %PC, align 8
  %958 = inttoptr i64 %956 to i32*
  %959 = load i32, i32* %958, align 4
  %960 = add i32 %959, %929
  %961 = zext i32 %960 to i64
  store i64 %961, i64* %RCX, align 8, !tbaa !2428
  %962 = icmp ult i32 %960, %929
  %963 = icmp ult i32 %960, %959
  %964 = or i1 %962, %963
  %965 = zext i1 %964 to i8
  store i8 %965, i8* %50, align 1, !tbaa !2432
  %966 = and i32 %960, 255
  %967 = tail call i32 @llvm.ctpop.i32(i32 %966) #14
  %968 = trunc i32 %967 to i8
  %969 = and i8 %968, 1
  %970 = xor i8 %969, 1
  store i8 %970, i8* %51, align 1, !tbaa !2446
  %971 = xor i32 %959, %929
  %972 = xor i32 %971, %960
  %973 = lshr i32 %972, 4
  %974 = trunc i32 %973 to i8
  %975 = and i8 %974, 1
  store i8 %975, i8* %52, align 1, !tbaa !2447
  %976 = icmp eq i32 %960, 0
  %977 = zext i1 %976 to i8
  store i8 %977, i8* %53, align 1, !tbaa !2448
  %978 = lshr i32 %960, 31
  %979 = trunc i32 %978 to i8
  store i8 %979, i8* %54, align 1, !tbaa !2449
  %980 = lshr i32 %928, 30
  %981 = and i32 %980, 1
  %982 = lshr i32 %959, 31
  %983 = xor i32 %978, %981
  %984 = xor i32 %978, %982
  %985 = add nuw nsw i32 %983, %984
  %986 = icmp eq i32 %985, 2
  %987 = zext i1 %986 to i8
  store i8 %987, i8* %55, align 1, !tbaa !2450
  %988 = add i64 %923, -40
  %989 = add i64 %925, 20
  store i64 %989, i64* %PC, align 8
  %990 = inttoptr i64 %988 to i32*
  store i32 %960, i32* %990, align 4
  %991 = load i64, i64* %RBP, align 8
  %992 = add i64 %991, -24
  %993 = load i64, i64* %PC, align 8
  %994 = add i64 %993, 4
  store i64 %994, i64* %PC, align 8
  %995 = inttoptr i64 %992 to i64*
  %996 = load i64, i64* %995, align 8
  store i64 %996, i64* %RDX, align 8, !tbaa !2428
  %997 = add i64 %991, -32
  %998 = add i64 %993, 8
  store i64 %998, i64* %PC, align 8
  %999 = inttoptr i64 %997 to i32*
  %1000 = load i32, i32* %999, align 4
  %1001 = sext i32 %1000 to i64
  store i64 %1001, i64* %RSI, align 8, !tbaa !2428
  %1002 = shl nsw i64 %1001, 3
  %1003 = add i64 %1002, %996
  %1004 = add i64 %993, 13
  store i64 %1004, i64* %PC, align 8
  %1005 = inttoptr i64 %1003 to i64*
  %1006 = load i64, i64* %1005, align 8
  store i64 %1006, i64* %1698, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1700, align 1, !tbaa !2451
  %1007 = add i64 %991, -64
  %1008 = add i64 %993, 18
  store i64 %1008, i64* %PC, align 8
  %1009 = inttoptr i64 %1007 to i64*
  store i64 %1006, i64* %1009, align 8
  %1010 = load i64, i64* %RBP, align 8
  %1011 = add i64 %1010, -24
  %1012 = load i64, i64* %PC, align 8
  %1013 = add i64 %1012, 4
  store i64 %1013, i64* %PC, align 8
  %1014 = inttoptr i64 %1011 to i64*
  %1015 = load i64, i64* %1014, align 8
  store i64 %1015, i64* %RDX, align 8, !tbaa !2428
  %1016 = add i64 %1010, -32
  %1017 = add i64 %1012, 7
  store i64 %1017, i64* %PC, align 8
  %1018 = inttoptr i64 %1016 to i32*
  %1019 = load i32, i32* %1018, align 4
  %1020 = add i32 %1019, 1
  %1021 = zext i32 %1020 to i64
  store i64 %1021, i64* %RCX, align 8, !tbaa !2428
  %1022 = icmp eq i32 %1019, -1
  %1023 = icmp eq i32 %1020, 0
  %1024 = or i1 %1022, %1023
  %1025 = zext i1 %1024 to i8
  store i8 %1025, i8* %50, align 1, !tbaa !2432
  %1026 = and i32 %1020, 255
  %1027 = tail call i32 @llvm.ctpop.i32(i32 %1026) #14
  %1028 = trunc i32 %1027 to i8
  %1029 = and i8 %1028, 1
  %1030 = xor i8 %1029, 1
  store i8 %1030, i8* %51, align 1, !tbaa !2446
  %1031 = xor i32 %1020, %1019
  %1032 = lshr i32 %1031, 4
  %1033 = trunc i32 %1032 to i8
  %1034 = and i8 %1033, 1
  store i8 %1034, i8* %52, align 1, !tbaa !2447
  %1035 = zext i1 %1023 to i8
  store i8 %1035, i8* %53, align 1, !tbaa !2448
  %1036 = lshr i32 %1020, 31
  %1037 = trunc i32 %1036 to i8
  store i8 %1037, i8* %54, align 1, !tbaa !2449
  %1038 = lshr i32 %1019, 31
  %1039 = xor i32 %1036, %1038
  %1040 = add nuw nsw i32 %1039, %1036
  %1041 = icmp eq i32 %1040, 2
  %1042 = zext i1 %1041 to i8
  store i8 %1042, i8* %55, align 1, !tbaa !2450
  %1043 = sext i32 %1020 to i64
  store i64 %1043, i64* %RSI, align 8, !tbaa !2428
  %1044 = shl nsw i64 %1043, 3
  %1045 = add i64 %1015, %1044
  %1046 = add i64 %1012, 18
  store i64 %1046, i64* %PC, align 8
  %1047 = inttoptr i64 %1045 to i64*
  %1048 = load i64, i64* %1047, align 8
  %1049 = load i64, i64* %RAX, align 8
  %1050 = xor i64 %1049, %1048
  store i64 %1050, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %1051 = trunc i64 %1050 to i32
  %1052 = and i32 %1051, 255
  %1053 = tail call i32 @llvm.ctpop.i32(i32 %1052) #14
  %1054 = trunc i32 %1053 to i8
  %1055 = and i8 %1054, 1
  %1056 = xor i8 %1055, 1
  store i8 %1056, i8* %51, align 1, !tbaa !2446
  %1057 = icmp eq i64 %1050, 0
  %1058 = zext i1 %1057 to i8
  store i8 %1058, i8* %53, align 1, !tbaa !2448
  %1059 = lshr i64 %1050, 63
  %1060 = trunc i64 %1059 to i8
  store i8 %1060, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %1050, i64* %1698, align 1, !tbaa !2428
  store i64 0, i64* %1699, align 1, !tbaa !2428
  %1061 = add i64 %1010, -72
  %1062 = add i64 %1012, 36
  store i64 %1062, i64* %PC, align 8
  %1063 = inttoptr i64 %1061 to i64*
  store i64 %1050, i64* %1063, align 8
  %1064 = load i64, i64* %RBP, align 8
  %1065 = add i64 %1064, -24
  %1066 = load i64, i64* %PC, align 8
  %1067 = add i64 %1066, 4
  store i64 %1067, i64* %PC, align 8
  %1068 = inttoptr i64 %1065 to i64*
  %1069 = load i64, i64* %1068, align 8
  store i64 %1069, i64* %RDX, align 8, !tbaa !2428
  %1070 = add i64 %1064, -40
  %1071 = add i64 %1066, 8
  store i64 %1071, i64* %PC, align 8
  %1072 = inttoptr i64 %1070 to i32*
  %1073 = load i32, i32* %1072, align 4
  %1074 = sext i32 %1073 to i64
  store i64 %1074, i64* %RSI, align 8, !tbaa !2428
  %1075 = shl nsw i64 %1074, 3
  %1076 = add i64 %1075, %1069
  %1077 = add i64 %1066, 13
  store i64 %1077, i64* %PC, align 8
  %1078 = inttoptr i64 %1076 to i64*
  %1079 = load i64, i64* %1078, align 8
  store i64 %1079, i64* %1698, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1700, align 1, !tbaa !2451
  %1080 = add i64 %1064, -80
  %1081 = add i64 %1066, 18
  store i64 %1081, i64* %PC, align 8
  %1082 = inttoptr i64 %1080 to i64*
  store i64 %1079, i64* %1082, align 8
  %1083 = load i64, i64* %RBP, align 8
  %1084 = add i64 %1083, -24
  %1085 = load i64, i64* %PC, align 8
  %1086 = add i64 %1085, 4
  store i64 %1086, i64* %PC, align 8
  %1087 = inttoptr i64 %1084 to i64*
  %1088 = load i64, i64* %1087, align 8
  store i64 %1088, i64* %RDX, align 8, !tbaa !2428
  %1089 = add i64 %1083, -40
  %1090 = add i64 %1085, 7
  store i64 %1090, i64* %PC, align 8
  %1091 = inttoptr i64 %1089 to i32*
  %1092 = load i32, i32* %1091, align 4
  %1093 = add i32 %1092, 1
  %1094 = zext i32 %1093 to i64
  store i64 %1094, i64* %RCX, align 8, !tbaa !2428
  %1095 = icmp eq i32 %1092, -1
  %1096 = icmp eq i32 %1093, 0
  %1097 = or i1 %1095, %1096
  %1098 = zext i1 %1097 to i8
  store i8 %1098, i8* %50, align 1, !tbaa !2432
  %1099 = and i32 %1093, 255
  %1100 = tail call i32 @llvm.ctpop.i32(i32 %1099) #14
  %1101 = trunc i32 %1100 to i8
  %1102 = and i8 %1101, 1
  %1103 = xor i8 %1102, 1
  store i8 %1103, i8* %51, align 1, !tbaa !2446
  %1104 = xor i32 %1093, %1092
  %1105 = lshr i32 %1104, 4
  %1106 = trunc i32 %1105 to i8
  %1107 = and i8 %1106, 1
  store i8 %1107, i8* %52, align 1, !tbaa !2447
  %1108 = zext i1 %1096 to i8
  store i8 %1108, i8* %53, align 1, !tbaa !2448
  %1109 = lshr i32 %1093, 31
  %1110 = trunc i32 %1109 to i8
  store i8 %1110, i8* %54, align 1, !tbaa !2449
  %1111 = lshr i32 %1092, 31
  %1112 = xor i32 %1109, %1111
  %1113 = add nuw nsw i32 %1112, %1109
  %1114 = icmp eq i32 %1113, 2
  %1115 = zext i1 %1114 to i8
  store i8 %1115, i8* %55, align 1, !tbaa !2450
  %1116 = sext i32 %1093 to i64
  store i64 %1116, i64* %RSI, align 8, !tbaa !2428
  %1117 = shl nsw i64 %1116, 3
  %1118 = add i64 %1088, %1117
  %1119 = add i64 %1085, 18
  store i64 %1119, i64* %PC, align 8
  %1120 = inttoptr i64 %1118 to i64*
  %1121 = load i64, i64* %1120, align 8
  %1122 = load i64, i64* %RAX, align 8
  %1123 = xor i64 %1122, %1121
  store i64 %1123, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %1124 = trunc i64 %1123 to i32
  %1125 = and i32 %1124, 255
  %1126 = tail call i32 @llvm.ctpop.i32(i32 %1125) #14
  %1127 = trunc i32 %1126 to i8
  %1128 = and i8 %1127, 1
  %1129 = xor i8 %1128, 1
  store i8 %1129, i8* %51, align 1, !tbaa !2446
  %1130 = icmp eq i64 %1123, 0
  %1131 = zext i1 %1130 to i8
  store i8 %1131, i8* %53, align 1, !tbaa !2448
  %1132 = lshr i64 %1123, 63
  %1133 = trunc i64 %1132 to i8
  store i8 %1133, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %1123, i64* %1698, align 1, !tbaa !2428
  store i64 0, i64* %1699, align 1, !tbaa !2428
  %1134 = add i64 %1083, -88
  %1135 = add i64 %1085, 36
  store i64 %1135, i64* %PC, align 8
  %1136 = inttoptr i64 %1134 to i64*
  store i64 %1123, i64* %1136, align 8
  %1137 = load i64, i64* %RBP, align 8
  %1138 = add i64 %1137, -80
  %1139 = load i64, i64* %PC, align 8
  %1140 = add i64 %1139, 5
  store i64 %1140, i64* %PC, align 8
  %1141 = inttoptr i64 %1138 to i64*
  %1142 = load i64, i64* %1141, align 8
  store i64 %1142, i64* %1698, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1700, align 1, !tbaa !2451
  %1143 = add i64 %1137, -24
  %1144 = add i64 %1139, 9
  store i64 %1144, i64* %PC, align 8
  %1145 = inttoptr i64 %1143 to i64*
  %1146 = load i64, i64* %1145, align 8
  store i64 %1146, i64* %RDX, align 8, !tbaa !2428
  %1147 = add i64 %1137, -32
  %1148 = add i64 %1139, 13
  store i64 %1148, i64* %PC, align 8
  %1149 = inttoptr i64 %1147 to i32*
  %1150 = load i32, i32* %1149, align 4
  %1151 = sext i32 %1150 to i64
  store i64 %1151, i64* %RSI, align 8, !tbaa !2428
  %1152 = shl nsw i64 %1151, 3
  %1153 = add i64 %1152, %1146
  %1154 = add i64 %1139, 18
  store i64 %1154, i64* %PC, align 8
  %1155 = inttoptr i64 %1153 to i64*
  store i64 %1142, i64* %1155, align 8
  %1156 = load i64, i64* %RBP, align 8
  %1157 = add i64 %1156, -88
  %1158 = load i64, i64* %PC, align 8
  %1159 = add i64 %1158, 5
  store i64 %1159, i64* %PC, align 8
  %1160 = inttoptr i64 %1157 to i64*
  %1161 = load i64, i64* %1160, align 8
  store i64 %1161, i64* %1698, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1700, align 1, !tbaa !2451
  %1162 = add i64 %1156, -24
  %1163 = add i64 %1158, 9
  store i64 %1163, i64* %PC, align 8
  %1164 = inttoptr i64 %1162 to i64*
  %1165 = load i64, i64* %1164, align 8
  store i64 %1165, i64* %RDX, align 8, !tbaa !2428
  %1166 = add i64 %1156, -32
  %1167 = add i64 %1158, 12
  store i64 %1167, i64* %PC, align 8
  %1168 = inttoptr i64 %1166 to i32*
  %1169 = load i32, i32* %1168, align 4
  %1170 = add i32 %1169, 1
  %1171 = zext i32 %1170 to i64
  store i64 %1171, i64* %RCX, align 8, !tbaa !2428
  %1172 = icmp eq i32 %1169, -1
  %1173 = icmp eq i32 %1170, 0
  %1174 = or i1 %1172, %1173
  %1175 = zext i1 %1174 to i8
  store i8 %1175, i8* %50, align 1, !tbaa !2432
  %1176 = and i32 %1170, 255
  %1177 = tail call i32 @llvm.ctpop.i32(i32 %1176) #14
  %1178 = trunc i32 %1177 to i8
  %1179 = and i8 %1178, 1
  %1180 = xor i8 %1179, 1
  store i8 %1180, i8* %51, align 1, !tbaa !2446
  %1181 = xor i32 %1170, %1169
  %1182 = lshr i32 %1181, 4
  %1183 = trunc i32 %1182 to i8
  %1184 = and i8 %1183, 1
  store i8 %1184, i8* %52, align 1, !tbaa !2447
  %1185 = zext i1 %1173 to i8
  store i8 %1185, i8* %53, align 1, !tbaa !2448
  %1186 = lshr i32 %1170, 31
  %1187 = trunc i32 %1186 to i8
  store i8 %1187, i8* %54, align 1, !tbaa !2449
  %1188 = lshr i32 %1169, 31
  %1189 = xor i32 %1186, %1188
  %1190 = add nuw nsw i32 %1189, %1186
  %1191 = icmp eq i32 %1190, 2
  %1192 = zext i1 %1191 to i8
  store i8 %1192, i8* %55, align 1, !tbaa !2450
  %1193 = sext i32 %1170 to i64
  store i64 %1193, i64* %RSI, align 8, !tbaa !2428
  %1194 = shl nsw i64 %1193, 3
  %1195 = add i64 %1165, %1194
  %1196 = add i64 %1158, 23
  store i64 %1196, i64* %PC, align 8
  %1197 = inttoptr i64 %1195 to i64*
  store i64 %1161, i64* %1197, align 8
  %1198 = load i64, i64* %RBP, align 8
  %1199 = add i64 %1198, -64
  %1200 = load i64, i64* %PC, align 8
  %1201 = add i64 %1200, 5
  store i64 %1201, i64* %PC, align 8
  %1202 = inttoptr i64 %1199 to i64*
  %1203 = load i64, i64* %1202, align 8
  store i64 %1203, i64* %1698, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1700, align 1, !tbaa !2451
  %1204 = add i64 %1198, -24
  %1205 = add i64 %1200, 9
  store i64 %1205, i64* %PC, align 8
  %1206 = inttoptr i64 %1204 to i64*
  %1207 = load i64, i64* %1206, align 8
  store i64 %1207, i64* %RDX, align 8, !tbaa !2428
  %1208 = add i64 %1198, -40
  %1209 = add i64 %1200, 13
  store i64 %1209, i64* %PC, align 8
  %1210 = inttoptr i64 %1208 to i32*
  %1211 = load i32, i32* %1210, align 4
  %1212 = sext i32 %1211 to i64
  store i64 %1212, i64* %RSI, align 8, !tbaa !2428
  %1213 = shl nsw i64 %1212, 3
  %1214 = add i64 %1213, %1207
  %1215 = add i64 %1200, 18
  store i64 %1215, i64* %PC, align 8
  %1216 = inttoptr i64 %1214 to i64*
  store i64 %1203, i64* %1216, align 8
  %1217 = load i64, i64* %RBP, align 8
  %1218 = add i64 %1217, -72
  %1219 = load i64, i64* %PC, align 8
  %1220 = add i64 %1219, 5
  store i64 %1220, i64* %PC, align 8
  %1221 = inttoptr i64 %1218 to i64*
  %1222 = load i64, i64* %1221, align 8
  store i64 %1222, i64* %1698, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1700, align 1, !tbaa !2451
  %1223 = add i64 %1217, -24
  %1224 = add i64 %1219, 9
  store i64 %1224, i64* %PC, align 8
  %1225 = inttoptr i64 %1223 to i64*
  %1226 = load i64, i64* %1225, align 8
  store i64 %1226, i64* %RDX, align 8, !tbaa !2428
  %1227 = add i64 %1217, -40
  %1228 = add i64 %1219, 12
  store i64 %1228, i64* %PC, align 8
  %1229 = inttoptr i64 %1227 to i32*
  %1230 = load i32, i32* %1229, align 4
  %1231 = add i32 %1230, 1
  %1232 = zext i32 %1231 to i64
  store i64 %1232, i64* %RCX, align 8, !tbaa !2428
  %1233 = icmp eq i32 %1230, -1
  %1234 = icmp eq i32 %1231, 0
  %1235 = or i1 %1233, %1234
  %1236 = zext i1 %1235 to i8
  store i8 %1236, i8* %50, align 1, !tbaa !2432
  %1237 = and i32 %1231, 255
  %1238 = tail call i32 @llvm.ctpop.i32(i32 %1237) #14
  %1239 = trunc i32 %1238 to i8
  %1240 = and i8 %1239, 1
  %1241 = xor i8 %1240, 1
  store i8 %1241, i8* %51, align 1, !tbaa !2446
  %1242 = xor i32 %1231, %1230
  %1243 = lshr i32 %1242, 4
  %1244 = trunc i32 %1243 to i8
  %1245 = and i8 %1244, 1
  store i8 %1245, i8* %52, align 1, !tbaa !2447
  %1246 = zext i1 %1234 to i8
  store i8 %1246, i8* %53, align 1, !tbaa !2448
  %1247 = lshr i32 %1231, 31
  %1248 = trunc i32 %1247 to i8
  store i8 %1248, i8* %54, align 1, !tbaa !2449
  %1249 = lshr i32 %1230, 31
  %1250 = xor i32 %1247, %1249
  %1251 = add nuw nsw i32 %1250, %1247
  %1252 = icmp eq i32 %1251, 2
  %1253 = zext i1 %1252 to i8
  store i8 %1253, i8* %55, align 1, !tbaa !2450
  %1254 = sext i32 %1231 to i64
  store i64 %1254, i64* %RSI, align 8, !tbaa !2428
  %1255 = shl nsw i64 %1254, 3
  %1256 = add i64 %1226, %1255
  %1257 = add i64 %1219, 23
  store i64 %1257, i64* %PC, align 8
  %1258 = inttoptr i64 %1256 to i64*
  store i64 %1222, i64* %1258, align 8
  %1259 = load i64, i64* %RBP, align 8
  %1260 = add i64 %1259, -52
  %1261 = load i64, i64* %PC, align 8
  %1262 = add i64 %1261, 3
  store i64 %1262, i64* %PC, align 8
  %1263 = inttoptr i64 %1260 to i32*
  %1264 = load i32, i32* %1263, align 4
  %1265 = zext i32 %1264 to i64
  store i64 %1265, i64* %RCX, align 8, !tbaa !2428
  %1266 = add i64 %1259, -32
  %1267 = add i64 %1261, 6
  store i64 %1267, i64* %PC, align 8
  %1268 = inttoptr i64 %1266 to i32*
  %1269 = load i32, i32* %1268, align 4
  %1270 = add i32 %1269, %1264
  %1271 = zext i32 %1270 to i64
  store i64 %1271, i64* %RCX, align 8, !tbaa !2428
  %1272 = icmp ult i32 %1270, %1264
  %1273 = icmp ult i32 %1270, %1269
  %1274 = or i1 %1272, %1273
  %1275 = zext i1 %1274 to i8
  store i8 %1275, i8* %50, align 1, !tbaa !2432
  %1276 = and i32 %1270, 255
  %1277 = tail call i32 @llvm.ctpop.i32(i32 %1276) #14
  %1278 = trunc i32 %1277 to i8
  %1279 = and i8 %1278, 1
  %1280 = xor i8 %1279, 1
  store i8 %1280, i8* %51, align 1, !tbaa !2446
  %1281 = xor i32 %1269, %1264
  %1282 = xor i32 %1281, %1270
  %1283 = lshr i32 %1282, 4
  %1284 = trunc i32 %1283 to i8
  %1285 = and i8 %1284, 1
  store i8 %1285, i8* %52, align 1, !tbaa !2447
  %1286 = icmp eq i32 %1270, 0
  %1287 = zext i1 %1286 to i8
  store i8 %1287, i8* %53, align 1, !tbaa !2448
  %1288 = lshr i32 %1270, 31
  %1289 = trunc i32 %1288 to i8
  store i8 %1289, i8* %54, align 1, !tbaa !2449
  %1290 = lshr i32 %1264, 31
  %1291 = lshr i32 %1269, 31
  %1292 = xor i32 %1288, %1290
  %1293 = xor i32 %1288, %1291
  %1294 = add nuw nsw i32 %1292, %1293
  %1295 = icmp eq i32 %1294, 2
  %1296 = zext i1 %1295 to i8
  store i8 %1296, i8* %55, align 1, !tbaa !2450
  %1297 = add i64 %1261, 9
  store i64 %1297, i64* %PC, align 8
  store i32 %1270, i32* %1268, align 4
  %1298 = load i64, i64* %RBP, align 8
  %1299 = add i64 %1298, -52
  %1300 = load i64, i64* %PC, align 8
  %1301 = add i64 %1300, 3
  store i64 %1301, i64* %PC, align 8
  %1302 = inttoptr i64 %1299 to i32*
  %1303 = load i32, i32* %1302, align 4
  %1304 = zext i32 %1303 to i64
  store i64 %1304, i64* %RCX, align 8, !tbaa !2428
  %1305 = add i64 %1298, -40
  %1306 = add i64 %1300, 6
  store i64 %1306, i64* %PC, align 8
  %1307 = inttoptr i64 %1305 to i32*
  %1308 = load i32, i32* %1307, align 4
  %1309 = add i32 %1308, %1303
  %1310 = zext i32 %1309 to i64
  store i64 %1310, i64* %RCX, align 8, !tbaa !2428
  %1311 = icmp ult i32 %1309, %1303
  %1312 = icmp ult i32 %1309, %1308
  %1313 = or i1 %1311, %1312
  %1314 = zext i1 %1313 to i8
  store i8 %1314, i8* %50, align 1, !tbaa !2432
  %1315 = and i32 %1309, 255
  %1316 = tail call i32 @llvm.ctpop.i32(i32 %1315) #14
  %1317 = trunc i32 %1316 to i8
  %1318 = and i8 %1317, 1
  %1319 = xor i8 %1318, 1
  store i8 %1319, i8* %51, align 1, !tbaa !2446
  %1320 = xor i32 %1308, %1303
  %1321 = xor i32 %1320, %1309
  %1322 = lshr i32 %1321, 4
  %1323 = trunc i32 %1322 to i8
  %1324 = and i8 %1323, 1
  store i8 %1324, i8* %52, align 1, !tbaa !2447
  %1325 = icmp eq i32 %1309, 0
  %1326 = zext i1 %1325 to i8
  store i8 %1326, i8* %53, align 1, !tbaa !2448
  %1327 = lshr i32 %1309, 31
  %1328 = trunc i32 %1327 to i8
  store i8 %1328, i8* %54, align 1, !tbaa !2449
  %1329 = lshr i32 %1303, 31
  %1330 = lshr i32 %1308, 31
  %1331 = xor i32 %1327, %1329
  %1332 = xor i32 %1327, %1330
  %1333 = add nuw nsw i32 %1331, %1332
  %1334 = icmp eq i32 %1333, 2
  %1335 = zext i1 %1334 to i8
  store i8 %1335, i8* %55, align 1, !tbaa !2450
  %1336 = add i64 %1300, 9
  store i64 %1336, i64* %PC, align 8
  store i32 %1309, i32* %1307, align 4
  %1337 = load i64, i64* %RBP, align 8
  %1338 = add i64 %1337, -24
  %1339 = load i64, i64* %PC, align 8
  %1340 = add i64 %1339, 4
  store i64 %1340, i64* %PC, align 8
  %1341 = inttoptr i64 %1338 to i64*
  %1342 = load i64, i64* %1341, align 8
  store i64 %1342, i64* %RDX, align 8, !tbaa !2428
  %1343 = add i64 %1337, -32
  %1344 = add i64 %1339, 8
  store i64 %1344, i64* %PC, align 8
  %1345 = inttoptr i64 %1343 to i32*
  %1346 = load i32, i32* %1345, align 4
  %1347 = sext i32 %1346 to i64
  store i64 %1347, i64* %RSI, align 8, !tbaa !2428
  %1348 = shl nsw i64 %1347, 3
  %1349 = add i64 %1348, %1342
  %1350 = add i64 %1339, 13
  store i64 %1350, i64* %PC, align 8
  %1351 = inttoptr i64 %1349 to i64*
  %1352 = load i64, i64* %1351, align 8
  store i64 %1352, i64* %1698, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1700, align 1, !tbaa !2451
  %1353 = add i64 %1337, -64
  %1354 = add i64 %1339, 18
  store i64 %1354, i64* %PC, align 8
  %1355 = inttoptr i64 %1353 to i64*
  store i64 %1352, i64* %1355, align 8
  %1356 = load i64, i64* %RBP, align 8
  %1357 = add i64 %1356, -24
  %1358 = load i64, i64* %PC, align 8
  %1359 = add i64 %1358, 4
  store i64 %1359, i64* %PC, align 8
  %1360 = inttoptr i64 %1357 to i64*
  %1361 = load i64, i64* %1360, align 8
  store i64 %1361, i64* %RDX, align 8, !tbaa !2428
  %1362 = add i64 %1356, -32
  %1363 = add i64 %1358, 7
  store i64 %1363, i64* %PC, align 8
  %1364 = inttoptr i64 %1362 to i32*
  %1365 = load i32, i32* %1364, align 4
  %1366 = add i32 %1365, 1
  %1367 = zext i32 %1366 to i64
  store i64 %1367, i64* %RCX, align 8, !tbaa !2428
  %1368 = icmp eq i32 %1365, -1
  %1369 = icmp eq i32 %1366, 0
  %1370 = or i1 %1368, %1369
  %1371 = zext i1 %1370 to i8
  store i8 %1371, i8* %50, align 1, !tbaa !2432
  %1372 = and i32 %1366, 255
  %1373 = tail call i32 @llvm.ctpop.i32(i32 %1372) #14
  %1374 = trunc i32 %1373 to i8
  %1375 = and i8 %1374, 1
  %1376 = xor i8 %1375, 1
  store i8 %1376, i8* %51, align 1, !tbaa !2446
  %1377 = xor i32 %1366, %1365
  %1378 = lshr i32 %1377, 4
  %1379 = trunc i32 %1378 to i8
  %1380 = and i8 %1379, 1
  store i8 %1380, i8* %52, align 1, !tbaa !2447
  %1381 = zext i1 %1369 to i8
  store i8 %1381, i8* %53, align 1, !tbaa !2448
  %1382 = lshr i32 %1366, 31
  %1383 = trunc i32 %1382 to i8
  store i8 %1383, i8* %54, align 1, !tbaa !2449
  %1384 = lshr i32 %1365, 31
  %1385 = xor i32 %1382, %1384
  %1386 = add nuw nsw i32 %1385, %1382
  %1387 = icmp eq i32 %1386, 2
  %1388 = zext i1 %1387 to i8
  store i8 %1388, i8* %55, align 1, !tbaa !2450
  %1389 = sext i32 %1366 to i64
  store i64 %1389, i64* %RSI, align 8, !tbaa !2428
  %1390 = shl nsw i64 %1389, 3
  %1391 = add i64 %1361, %1390
  %1392 = add i64 %1358, 18
  store i64 %1392, i64* %PC, align 8
  %1393 = inttoptr i64 %1391 to i64*
  %1394 = load i64, i64* %1393, align 8
  %1395 = load i64, i64* %RAX, align 8
  %1396 = xor i64 %1395, %1394
  store i64 %1396, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %1397 = trunc i64 %1396 to i32
  %1398 = and i32 %1397, 255
  %1399 = tail call i32 @llvm.ctpop.i32(i32 %1398) #14
  %1400 = trunc i32 %1399 to i8
  %1401 = and i8 %1400, 1
  %1402 = xor i8 %1401, 1
  store i8 %1402, i8* %51, align 1, !tbaa !2446
  %1403 = icmp eq i64 %1396, 0
  %1404 = zext i1 %1403 to i8
  store i8 %1404, i8* %53, align 1, !tbaa !2448
  %1405 = lshr i64 %1396, 63
  %1406 = trunc i64 %1405 to i8
  store i8 %1406, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %1396, i64* %1698, align 1, !tbaa !2428
  store i64 0, i64* %1699, align 1, !tbaa !2428
  %1407 = add i64 %1356, -72
  %1408 = add i64 %1358, 36
  store i64 %1408, i64* %PC, align 8
  %1409 = inttoptr i64 %1407 to i64*
  store i64 %1396, i64* %1409, align 8
  %1410 = load i64, i64* %RBP, align 8
  %1411 = add i64 %1410, -24
  %1412 = load i64, i64* %PC, align 8
  %1413 = add i64 %1412, 4
  store i64 %1413, i64* %PC, align 8
  %1414 = inttoptr i64 %1411 to i64*
  %1415 = load i64, i64* %1414, align 8
  store i64 %1415, i64* %RDX, align 8, !tbaa !2428
  %1416 = add i64 %1410, -40
  %1417 = add i64 %1412, 8
  store i64 %1417, i64* %PC, align 8
  %1418 = inttoptr i64 %1416 to i32*
  %1419 = load i32, i32* %1418, align 4
  %1420 = sext i32 %1419 to i64
  store i64 %1420, i64* %RSI, align 8, !tbaa !2428
  %1421 = shl nsw i64 %1420, 3
  %1422 = add i64 %1421, %1415
  %1423 = add i64 %1412, 13
  store i64 %1423, i64* %PC, align 8
  %1424 = inttoptr i64 %1422 to i64*
  %1425 = load i64, i64* %1424, align 8
  store i64 %1425, i64* %1698, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1700, align 1, !tbaa !2451
  %1426 = add i64 %1410, -80
  %1427 = add i64 %1412, 18
  store i64 %1427, i64* %PC, align 8
  %1428 = inttoptr i64 %1426 to i64*
  store i64 %1425, i64* %1428, align 8
  %1429 = load i64, i64* %RBP, align 8
  %1430 = add i64 %1429, -24
  %1431 = load i64, i64* %PC, align 8
  %1432 = add i64 %1431, 4
  store i64 %1432, i64* %PC, align 8
  %1433 = inttoptr i64 %1430 to i64*
  %1434 = load i64, i64* %1433, align 8
  store i64 %1434, i64* %RDX, align 8, !tbaa !2428
  %1435 = add i64 %1429, -40
  %1436 = add i64 %1431, 7
  store i64 %1436, i64* %PC, align 8
  %1437 = inttoptr i64 %1435 to i32*
  %1438 = load i32, i32* %1437, align 4
  %1439 = add i32 %1438, 1
  %1440 = zext i32 %1439 to i64
  store i64 %1440, i64* %RCX, align 8, !tbaa !2428
  %1441 = icmp eq i32 %1438, -1
  %1442 = icmp eq i32 %1439, 0
  %1443 = or i1 %1441, %1442
  %1444 = zext i1 %1443 to i8
  store i8 %1444, i8* %50, align 1, !tbaa !2432
  %1445 = and i32 %1439, 255
  %1446 = tail call i32 @llvm.ctpop.i32(i32 %1445) #14
  %1447 = trunc i32 %1446 to i8
  %1448 = and i8 %1447, 1
  %1449 = xor i8 %1448, 1
  store i8 %1449, i8* %51, align 1, !tbaa !2446
  %1450 = xor i32 %1439, %1438
  %1451 = lshr i32 %1450, 4
  %1452 = trunc i32 %1451 to i8
  %1453 = and i8 %1452, 1
  store i8 %1453, i8* %52, align 1, !tbaa !2447
  %1454 = zext i1 %1442 to i8
  store i8 %1454, i8* %53, align 1, !tbaa !2448
  %1455 = lshr i32 %1439, 31
  %1456 = trunc i32 %1455 to i8
  store i8 %1456, i8* %54, align 1, !tbaa !2449
  %1457 = lshr i32 %1438, 31
  %1458 = xor i32 %1455, %1457
  %1459 = add nuw nsw i32 %1458, %1455
  %1460 = icmp eq i32 %1459, 2
  %1461 = zext i1 %1460 to i8
  store i8 %1461, i8* %55, align 1, !tbaa !2450
  %1462 = sext i32 %1439 to i64
  store i64 %1462, i64* %RSI, align 8, !tbaa !2428
  %1463 = shl nsw i64 %1462, 3
  %1464 = add i64 %1434, %1463
  %1465 = add i64 %1431, 18
  store i64 %1465, i64* %PC, align 8
  %1466 = inttoptr i64 %1464 to i64*
  %1467 = load i64, i64* %1466, align 8
  %1468 = load i64, i64* %RAX, align 8
  %1469 = xor i64 %1468, %1467
  store i64 %1469, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %1470 = trunc i64 %1469 to i32
  %1471 = and i32 %1470, 255
  %1472 = tail call i32 @llvm.ctpop.i32(i32 %1471) #14
  %1473 = trunc i32 %1472 to i8
  %1474 = and i8 %1473, 1
  %1475 = xor i8 %1474, 1
  store i8 %1475, i8* %51, align 1, !tbaa !2446
  %1476 = icmp eq i64 %1469, 0
  %1477 = zext i1 %1476 to i8
  store i8 %1477, i8* %53, align 1, !tbaa !2448
  %1478 = lshr i64 %1469, 63
  %1479 = trunc i64 %1478 to i8
  store i8 %1479, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %1469, i64* %1698, align 1, !tbaa !2428
  store i64 0, i64* %1699, align 1, !tbaa !2428
  %1480 = add i64 %1429, -88
  %1481 = add i64 %1431, 36
  store i64 %1481, i64* %PC, align 8
  %1482 = inttoptr i64 %1480 to i64*
  store i64 %1469, i64* %1482, align 8
  %1483 = load i64, i64* %RBP, align 8
  %1484 = add i64 %1483, -80
  %1485 = load i64, i64* %PC, align 8
  %1486 = add i64 %1485, 5
  store i64 %1486, i64* %PC, align 8
  %1487 = inttoptr i64 %1484 to i64*
  %1488 = load i64, i64* %1487, align 8
  store i64 %1488, i64* %1698, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1700, align 1, !tbaa !2451
  %1489 = add i64 %1483, -24
  %1490 = add i64 %1485, 9
  store i64 %1490, i64* %PC, align 8
  %1491 = inttoptr i64 %1489 to i64*
  %1492 = load i64, i64* %1491, align 8
  store i64 %1492, i64* %RAX, align 8, !tbaa !2428
  %1493 = add i64 %1483, -32
  %1494 = add i64 %1485, 13
  store i64 %1494, i64* %PC, align 8
  %1495 = inttoptr i64 %1493 to i32*
  %1496 = load i32, i32* %1495, align 4
  %1497 = sext i32 %1496 to i64
  store i64 %1497, i64* %RDX, align 8, !tbaa !2428
  %1498 = shl nsw i64 %1497, 3
  %1499 = add i64 %1498, %1492
  %1500 = add i64 %1485, 18
  store i64 %1500, i64* %PC, align 8
  %1501 = inttoptr i64 %1499 to i64*
  store i64 %1488, i64* %1501, align 8
  %1502 = load i64, i64* %RBP, align 8
  %1503 = add i64 %1502, -88
  %1504 = load i64, i64* %PC, align 8
  %1505 = add i64 %1504, 5
  store i64 %1505, i64* %PC, align 8
  %1506 = inttoptr i64 %1503 to i64*
  %1507 = load i64, i64* %1506, align 8
  store i64 %1507, i64* %1698, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1700, align 1, !tbaa !2451
  %1508 = add i64 %1502, -24
  %1509 = add i64 %1504, 9
  store i64 %1509, i64* %PC, align 8
  %1510 = inttoptr i64 %1508 to i64*
  %1511 = load i64, i64* %1510, align 8
  store i64 %1511, i64* %RAX, align 8, !tbaa !2428
  %1512 = add i64 %1502, -32
  %1513 = add i64 %1504, 12
  store i64 %1513, i64* %PC, align 8
  %1514 = inttoptr i64 %1512 to i32*
  %1515 = load i32, i32* %1514, align 4
  %1516 = add i32 %1515, 1
  %1517 = zext i32 %1516 to i64
  store i64 %1517, i64* %RCX, align 8, !tbaa !2428
  %1518 = icmp eq i32 %1515, -1
  %1519 = icmp eq i32 %1516, 0
  %1520 = or i1 %1518, %1519
  %1521 = zext i1 %1520 to i8
  store i8 %1521, i8* %50, align 1, !tbaa !2432
  %1522 = and i32 %1516, 255
  %1523 = tail call i32 @llvm.ctpop.i32(i32 %1522) #14
  %1524 = trunc i32 %1523 to i8
  %1525 = and i8 %1524, 1
  %1526 = xor i8 %1525, 1
  store i8 %1526, i8* %51, align 1, !tbaa !2446
  %1527 = xor i32 %1516, %1515
  %1528 = lshr i32 %1527, 4
  %1529 = trunc i32 %1528 to i8
  %1530 = and i8 %1529, 1
  store i8 %1530, i8* %52, align 1, !tbaa !2447
  %1531 = zext i1 %1519 to i8
  store i8 %1531, i8* %53, align 1, !tbaa !2448
  %1532 = lshr i32 %1516, 31
  %1533 = trunc i32 %1532 to i8
  store i8 %1533, i8* %54, align 1, !tbaa !2449
  %1534 = lshr i32 %1515, 31
  %1535 = xor i32 %1532, %1534
  %1536 = add nuw nsw i32 %1535, %1532
  %1537 = icmp eq i32 %1536, 2
  %1538 = zext i1 %1537 to i8
  store i8 %1538, i8* %55, align 1, !tbaa !2450
  %1539 = sext i32 %1516 to i64
  store i64 %1539, i64* %RDX, align 8, !tbaa !2428
  %1540 = shl nsw i64 %1539, 3
  %1541 = add i64 %1511, %1540
  %1542 = add i64 %1504, 23
  store i64 %1542, i64* %PC, align 8
  %1543 = inttoptr i64 %1541 to i64*
  store i64 %1507, i64* %1543, align 8
  %1544 = load i64, i64* %RBP, align 8
  %1545 = add i64 %1544, -64
  %1546 = load i64, i64* %PC, align 8
  %1547 = add i64 %1546, 5
  store i64 %1547, i64* %PC, align 8
  %1548 = inttoptr i64 %1545 to i64*
  %1549 = load i64, i64* %1548, align 8
  store i64 %1549, i64* %1698, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1700, align 1, !tbaa !2451
  %1550 = add i64 %1544, -24
  %1551 = add i64 %1546, 9
  store i64 %1551, i64* %PC, align 8
  %1552 = inttoptr i64 %1550 to i64*
  %1553 = load i64, i64* %1552, align 8
  store i64 %1553, i64* %RAX, align 8, !tbaa !2428
  %1554 = add i64 %1544, -40
  %1555 = add i64 %1546, 13
  store i64 %1555, i64* %PC, align 8
  %1556 = inttoptr i64 %1554 to i32*
  %1557 = load i32, i32* %1556, align 4
  %1558 = sext i32 %1557 to i64
  store i64 %1558, i64* %RDX, align 8, !tbaa !2428
  %1559 = shl nsw i64 %1558, 3
  %1560 = add i64 %1559, %1553
  %1561 = add i64 %1546, 18
  store i64 %1561, i64* %PC, align 8
  %1562 = inttoptr i64 %1560 to i64*
  store i64 %1549, i64* %1562, align 8
  %1563 = load i64, i64* %RBP, align 8
  %1564 = add i64 %1563, -72
  %1565 = load i64, i64* %PC, align 8
  %1566 = add i64 %1565, 5
  store i64 %1566, i64* %PC, align 8
  %1567 = inttoptr i64 %1564 to i64*
  %1568 = load i64, i64* %1567, align 8
  store i64 %1568, i64* %1698, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1700, align 1, !tbaa !2451
  %1569 = add i64 %1563, -24
  %1570 = add i64 %1565, 9
  store i64 %1570, i64* %PC, align 8
  %1571 = inttoptr i64 %1569 to i64*
  %1572 = load i64, i64* %1571, align 8
  store i64 %1572, i64* %RAX, align 8, !tbaa !2428
  %1573 = add i64 %1563, -40
  %1574 = add i64 %1565, 12
  store i64 %1574, i64* %PC, align 8
  %1575 = inttoptr i64 %1573 to i32*
  %1576 = load i32, i32* %1575, align 4
  %1577 = add i32 %1576, 1
  %1578 = zext i32 %1577 to i64
  store i64 %1578, i64* %RCX, align 8, !tbaa !2428
  %1579 = icmp eq i32 %1576, -1
  %1580 = icmp eq i32 %1577, 0
  %1581 = or i1 %1579, %1580
  %1582 = zext i1 %1581 to i8
  store i8 %1582, i8* %50, align 1, !tbaa !2432
  %1583 = and i32 %1577, 255
  %1584 = tail call i32 @llvm.ctpop.i32(i32 %1583) #14
  %1585 = trunc i32 %1584 to i8
  %1586 = and i8 %1585, 1
  %1587 = xor i8 %1586, 1
  store i8 %1587, i8* %51, align 1, !tbaa !2446
  %1588 = xor i32 %1577, %1576
  %1589 = lshr i32 %1588, 4
  %1590 = trunc i32 %1589 to i8
  %1591 = and i8 %1590, 1
  store i8 %1591, i8* %52, align 1, !tbaa !2447
  %1592 = zext i1 %1580 to i8
  store i8 %1592, i8* %53, align 1, !tbaa !2448
  %1593 = lshr i32 %1577, 31
  %1594 = trunc i32 %1593 to i8
  store i8 %1594, i8* %54, align 1, !tbaa !2449
  %1595 = lshr i32 %1576, 31
  %1596 = xor i32 %1593, %1595
  %1597 = add nuw nsw i32 %1596, %1593
  %1598 = icmp eq i32 %1597, 2
  %1599 = zext i1 %1598 to i8
  store i8 %1599, i8* %55, align 1, !tbaa !2450
  %1600 = sext i32 %1577 to i64
  store i64 %1600, i64* %RDX, align 8, !tbaa !2428
  %1601 = shl nsw i64 %1600, 3
  %1602 = add i64 %1572, %1601
  %1603 = add i64 %1565, 23
  store i64 %1603, i64* %PC, align 8
  %1604 = inttoptr i64 %1602 to i64*
  store i64 %1568, i64* %1604, align 8
  %1605 = load i64, i64* %RBP, align 8
  %1606 = add i64 %1605, -28
  %1607 = load i64, i64* %PC, align 8
  %1608 = add i64 %1607, 3
  store i64 %1608, i64* %PC, align 8
  %1609 = inttoptr i64 %1606 to i32*
  %1610 = load i32, i32* %1609, align 4
  %1611 = add i32 %1610, 1
  %1612 = zext i32 %1611 to i64
  store i64 %1612, i64* %RAX, align 8, !tbaa !2428
  %1613 = icmp eq i32 %1610, -1
  %1614 = icmp eq i32 %1611, 0
  %1615 = or i1 %1613, %1614
  %1616 = zext i1 %1615 to i8
  store i8 %1616, i8* %50, align 1, !tbaa !2432
  %1617 = and i32 %1611, 255
  %1618 = tail call i32 @llvm.ctpop.i32(i32 %1617) #14
  %1619 = trunc i32 %1618 to i8
  %1620 = and i8 %1619, 1
  %1621 = xor i8 %1620, 1
  store i8 %1621, i8* %51, align 1, !tbaa !2446
  %1622 = xor i32 %1611, %1610
  %1623 = lshr i32 %1622, 4
  %1624 = trunc i32 %1623 to i8
  %1625 = and i8 %1624, 1
  store i8 %1625, i8* %52, align 1, !tbaa !2447
  %1626 = zext i1 %1614 to i8
  store i8 %1626, i8* %53, align 1, !tbaa !2448
  %1627 = lshr i32 %1611, 31
  %1628 = trunc i32 %1627 to i8
  store i8 %1628, i8* %54, align 1, !tbaa !2449
  %1629 = lshr i32 %1610, 31
  %1630 = xor i32 %1627, %1629
  %1631 = add nuw nsw i32 %1630, %1627
  %1632 = icmp eq i32 %1631, 2
  %1633 = zext i1 %1632 to i8
  store i8 %1633, i8* %55, align 1, !tbaa !2450
  %1634 = add i64 %1607, 9
  store i64 %1634, i64* %PC, align 8
  store i32 %1611, i32* %1609, align 4
  %1635 = load i64, i64* %PC, align 8
  %1636 = add i64 %1635, -469
  store i64 %1636, i64* %PC, align 8, !tbaa !2428
  br label %block_40222f

block_401c36:                                     ; preds = %block_401c8d, %block_401c10
  %1637 = phi i64 [ %2099, %block_401c8d ], [ %.pre, %block_401c10 ]
  %1638 = load i64, i64* %RBP, align 8
  %1639 = add i64 %1638, -48
  %1640 = add i64 %1637, 3
  store i64 %1640, i64* %PC, align 8
  %1641 = inttoptr i64 %1639 to i32*
  %1642 = load i32, i32* %1641, align 4
  %1643 = shl i32 %1642, 3
  %1644 = zext i32 %1643 to i64
  store i64 %1644, i64* %RAX, align 8, !tbaa !2428
  %1645 = lshr i32 %1642, 29
  %1646 = trunc i32 %1645 to i8
  %1647 = and i8 %1646, 1
  store i8 %1647, i8* %50, align 1, !tbaa !2453
  %1648 = and i32 %1643, 248
  %1649 = tail call i32 @llvm.ctpop.i32(i32 %1648) #14
  %1650 = trunc i32 %1649 to i8
  %1651 = and i8 %1650, 1
  %1652 = xor i8 %1651, 1
  store i8 %1652, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %1653 = icmp eq i32 %1643, 0
  %1654 = zext i1 %1653 to i8
  store i8 %1654, i8* %53, align 1, !tbaa !2453
  %1655 = lshr i32 %1642, 28
  %1656 = trunc i32 %1655 to i8
  %1657 = and i8 %1656, 1
  store i8 %1657, i8* %54, align 1, !tbaa !2453
  store i8 0, i8* %55, align 1, !tbaa !2453
  %1658 = add i64 %1638, -44
  %1659 = add i64 %1637, 9
  store i64 %1659, i64* %PC, align 8
  %1660 = inttoptr i64 %1658 to i32*
  %1661 = load i32, i32* %1660, align 4
  %1662 = sub i32 %1643, %1661
  %1663 = icmp ult i32 %1643, %1661
  %1664 = zext i1 %1663 to i8
  store i8 %1664, i8* %50, align 1, !tbaa !2432
  %1665 = and i32 %1662, 255
  %1666 = tail call i32 @llvm.ctpop.i32(i32 %1665) #14
  %1667 = trunc i32 %1666 to i8
  %1668 = and i8 %1667, 1
  %1669 = xor i8 %1668, 1
  store i8 %1669, i8* %51, align 1, !tbaa !2446
  %1670 = xor i32 %1661, %1643
  %1671 = xor i32 %1670, %1662
  %1672 = lshr i32 %1671, 4
  %1673 = trunc i32 %1672 to i8
  %1674 = and i8 %1673, 1
  store i8 %1674, i8* %52, align 1, !tbaa !2447
  %1675 = icmp eq i32 %1662, 0
  %1676 = zext i1 %1675 to i8
  store i8 %1676, i8* %53, align 1, !tbaa !2448
  %1677 = lshr i32 %1662, 31
  %1678 = trunc i32 %1677 to i8
  store i8 %1678, i8* %54, align 1, !tbaa !2449
  %1679 = lshr i32 %1642, 28
  %1680 = and i32 %1679, 1
  %1681 = lshr i32 %1661, 31
  %1682 = xor i32 %1681, %1680
  %1683 = xor i32 %1677, %1680
  %1684 = add nuw nsw i32 %1683, %1682
  %1685 = icmp eq i32 %1684, 2
  %1686 = zext i1 %1685 to i8
  store i8 %1686, i8* %55, align 1, !tbaa !2450
  %1687 = icmp ne i8 %1678, 0
  %1688 = xor i1 %1687, %1685
  %.v = select i1 %1688, i64 15, i64 101
  %1689 = add i64 %1637, %.v
  store i64 %1689, i64* %PC, align 8, !tbaa !2428
  br i1 %1688, label %block_401c45, label %block_401c9b

block_4021bb:                                     ; preds = %block_401c9b
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %1690 = add i64 %1989, -24
  %1691 = add i64 %2039, 14
  store i64 %1691, i64* %PC, align 8
  %1692 = inttoptr i64 %1690 to i64*
  %1693 = load i64, i64* %1692, align 8
  store i64 %1693, i64* %RCX, align 8, !tbaa !2428
  %1694 = add i64 %1693, 8
  %1695 = add i64 %2039, 19
  store i64 %1695, i64* %PC, align 8
  %1696 = inttoptr i64 %1694 to i64*
  %1697 = load i64, i64* %1696, align 8
  %1698 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %1966, i64 0, i32 0, i32 0, i32 0, i64 0
  %1699 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1700 = bitcast i64* %1699 to double*
  %1701 = xor i64 %1697, -9223372036854775808
  store i64 %1701, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %1702 = trunc i64 %1697 to i32
  %1703 = and i32 %1702, 255
  %1704 = tail call i32 @llvm.ctpop.i32(i32 %1703) #14
  %1705 = trunc i32 %1704 to i8
  %1706 = and i8 %1705, 1
  %1707 = xor i8 %1706, 1
  store i8 %1707, i8* %51, align 1, !tbaa !2446
  %1708 = icmp eq i64 %1701, 0
  %1709 = zext i1 %1708 to i8
  store i8 %1709, i8* %53, align 1, !tbaa !2448
  %1710 = lshr i64 %1701, 63
  %1711 = trunc i64 %1710 to i8
  store i8 %1711, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %1701, i64* %1698, align 1, !tbaa !2428
  store i64 0, i64* %1699, align 1, !tbaa !2428
  %1712 = add i64 %2039, 36
  store i64 %1712, i64* %PC, align 8
  %1713 = load i64, i64* %1692, align 8
  store i64 %1713, i64* %RCX, align 8, !tbaa !2428
  %1714 = add i64 %1713, 8
  %1715 = add i64 %2039, 41
  store i64 %1715, i64* %PC, align 8
  %1716 = inttoptr i64 %1714 to i64*
  store i64 %1701, i64* %1716, align 8
  %1717 = load i64, i64* %RBP, align 8
  %1718 = add i64 %1717, -24
  %1719 = load i64, i64* %PC, align 8
  %1720 = add i64 %1719, 4
  store i64 %1720, i64* %PC, align 8
  %1721 = inttoptr i64 %1718 to i64*
  %1722 = load i64, i64* %1721, align 8
  store i64 %1722, i64* %RCX, align 8, !tbaa !2428
  %1723 = add i64 %1717, -52
  %1724 = add i64 %1719, 7
  store i64 %1724, i64* %PC, align 8
  %1725 = inttoptr i64 %1723 to i32*
  %1726 = load i32, i32* %1725, align 4
  %1727 = add i32 %1726, 1
  %1728 = zext i32 %1727 to i64
  store i64 %1728, i64* %RDX, align 8, !tbaa !2428
  %1729 = icmp eq i32 %1726, -1
  %1730 = icmp eq i32 %1727, 0
  %1731 = or i1 %1729, %1730
  %1732 = zext i1 %1731 to i8
  store i8 %1732, i8* %50, align 1, !tbaa !2432
  %1733 = and i32 %1727, 255
  %1734 = tail call i32 @llvm.ctpop.i32(i32 %1733) #14
  %1735 = trunc i32 %1734 to i8
  %1736 = and i8 %1735, 1
  %1737 = xor i8 %1736, 1
  store i8 %1737, i8* %51, align 1, !tbaa !2446
  %1738 = xor i32 %1727, %1726
  %1739 = lshr i32 %1738, 4
  %1740 = trunc i32 %1739 to i8
  %1741 = and i8 %1740, 1
  store i8 %1741, i8* %52, align 1, !tbaa !2447
  %1742 = zext i1 %1730 to i8
  store i8 %1742, i8* %53, align 1, !tbaa !2448
  %1743 = lshr i32 %1727, 31
  %1744 = trunc i32 %1743 to i8
  store i8 %1744, i8* %54, align 1, !tbaa !2449
  %1745 = lshr i32 %1726, 31
  %1746 = xor i32 %1743, %1745
  %1747 = add nuw nsw i32 %1746, %1743
  %1748 = icmp eq i32 %1747, 2
  %1749 = zext i1 %1748 to i8
  store i8 %1749, i8* %55, align 1, !tbaa !2450
  %1750 = sext i32 %1727 to i64
  store i64 %1750, i64* %RSI, align 8, !tbaa !2428
  %1751 = shl nsw i64 %1750, 3
  %1752 = add i64 %1722, %1751
  %1753 = add i64 %1719, 18
  store i64 %1753, i64* %PC, align 8
  %1754 = inttoptr i64 %1752 to i64*
  %1755 = load i64, i64* %1754, align 8
  %1756 = load i64, i64* %RAX, align 8
  %1757 = xor i64 %1756, %1755
  store i64 %1757, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %1758 = trunc i64 %1757 to i32
  %1759 = and i32 %1758, 255
  %1760 = tail call i32 @llvm.ctpop.i32(i32 %1759) #14
  %1761 = trunc i32 %1760 to i8
  %1762 = and i8 %1761, 1
  %1763 = xor i8 %1762, 1
  store i8 %1763, i8* %51, align 1, !tbaa !2446
  %1764 = icmp eq i64 %1757, 0
  %1765 = zext i1 %1764 to i8
  store i8 %1765, i8* %53, align 1, !tbaa !2448
  %1766 = lshr i64 %1757, 63
  %1767 = trunc i64 %1766 to i8
  store i8 %1767, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %1757, i64* %1698, align 1, !tbaa !2428
  store i64 0, i64* %1699, align 1, !tbaa !2428
  %1768 = add i64 %1719, 35
  store i64 %1768, i64* %PC, align 8
  %1769 = load i64, i64* %1721, align 8
  store i64 %1769, i64* %RAX, align 8, !tbaa !2428
  %1770 = add i64 %1719, 38
  store i64 %1770, i64* %PC, align 8
  %1771 = load i32, i32* %1725, align 4
  %1772 = add i32 %1771, 1
  %1773 = zext i32 %1772 to i64
  store i64 %1773, i64* %RDX, align 8, !tbaa !2428
  %1774 = icmp eq i32 %1771, -1
  %1775 = icmp eq i32 %1772, 0
  %1776 = or i1 %1774, %1775
  %1777 = zext i1 %1776 to i8
  store i8 %1777, i8* %50, align 1, !tbaa !2432
  %1778 = and i32 %1772, 255
  %1779 = tail call i32 @llvm.ctpop.i32(i32 %1778) #14
  %1780 = trunc i32 %1779 to i8
  %1781 = and i8 %1780, 1
  %1782 = xor i8 %1781, 1
  store i8 %1782, i8* %51, align 1, !tbaa !2446
  %1783 = xor i32 %1772, %1771
  %1784 = lshr i32 %1783, 4
  %1785 = trunc i32 %1784 to i8
  %1786 = and i8 %1785, 1
  store i8 %1786, i8* %52, align 1, !tbaa !2447
  %1787 = zext i1 %1775 to i8
  store i8 %1787, i8* %53, align 1, !tbaa !2448
  %1788 = lshr i32 %1772, 31
  %1789 = trunc i32 %1788 to i8
  store i8 %1789, i8* %54, align 1, !tbaa !2449
  %1790 = lshr i32 %1771, 31
  %1791 = xor i32 %1788, %1790
  %1792 = add nuw nsw i32 %1791, %1788
  %1793 = icmp eq i32 %1792, 2
  %1794 = zext i1 %1793 to i8
  store i8 %1794, i8* %55, align 1, !tbaa !2450
  %1795 = sext i32 %1772 to i64
  store i64 %1795, i64* %RCX, align 8, !tbaa !2428
  %1796 = shl nsw i64 %1795, 3
  %1797 = add i64 %1769, %1796
  %1798 = add i64 %1719, 49
  store i64 %1798, i64* %PC, align 8
  %1799 = inttoptr i64 %1797 to i64*
  store i64 %1757, i64* %1799, align 8
  %1800 = load i64, i64* %RBP, align 8
  %1801 = add i64 %1800, -36
  %1802 = load i64, i64* %PC, align 8
  %1803 = add i64 %1802, 7
  store i64 %1803, i64* %PC, align 8
  %1804 = inttoptr i64 %1801 to i32*
  store i32 1, i32* %1804, align 4
  %.pre42 = load i64, i64* %PC, align 8
  br label %block_40221c

block_401cb3:                                     ; preds = %block_401c9b
  %1805 = add i64 %1989, -36
  %1806 = add i64 %2039, 7
  store i64 %1806, i64* %PC, align 8
  %1807 = inttoptr i64 %1805 to i32*
  store i32 0, i32* %1807, align 4
  %1808 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %1966, i64 0, i32 0, i32 0, i32 0, i64 0
  %1809 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1810 = bitcast i64* %1809 to double*
  %.pre40 = load i64, i64* %PC, align 8
  br label %block_401cba

block_40222f:                                     ; preds = %block_402228, %block_40223b
  %1811 = phi i64 [ %.pre43, %block_402228 ], [ %1636, %block_40223b ]
  %1812 = load i64, i64* %RBP, align 8
  %1813 = add i64 %1812, -28
  %1814 = add i64 %1811, 3
  store i64 %1814, i64* %PC, align 8
  %1815 = inttoptr i64 %1813 to i32*
  %1816 = load i32, i32* %1815, align 4
  %1817 = zext i32 %1816 to i64
  store i64 %1817, i64* %RAX, align 8, !tbaa !2428
  %1818 = add i64 %1812, -36
  %1819 = add i64 %1811, 6
  store i64 %1819, i64* %PC, align 8
  %1820 = inttoptr i64 %1818 to i32*
  %1821 = load i32, i32* %1820, align 4
  %1822 = sub i32 %1816, %1821
  %1823 = icmp ult i32 %1816, %1821
  %1824 = zext i1 %1823 to i8
  store i8 %1824, i8* %50, align 1, !tbaa !2432
  %1825 = and i32 %1822, 255
  %1826 = tail call i32 @llvm.ctpop.i32(i32 %1825) #14
  %1827 = trunc i32 %1826 to i8
  %1828 = and i8 %1827, 1
  %1829 = xor i8 %1828, 1
  store i8 %1829, i8* %51, align 1, !tbaa !2446
  %1830 = xor i32 %1821, %1816
  %1831 = xor i32 %1830, %1822
  %1832 = lshr i32 %1831, 4
  %1833 = trunc i32 %1832 to i8
  %1834 = and i8 %1833, 1
  store i8 %1834, i8* %52, align 1, !tbaa !2447
  %1835 = icmp eq i32 %1822, 0
  %1836 = zext i1 %1835 to i8
  store i8 %1836, i8* %53, align 1, !tbaa !2448
  %1837 = lshr i32 %1822, 31
  %1838 = trunc i32 %1837 to i8
  store i8 %1838, i8* %54, align 1, !tbaa !2449
  %1839 = lshr i32 %1816, 31
  %1840 = lshr i32 %1821, 31
  %1841 = xor i32 %1840, %1839
  %1842 = xor i32 %1837, %1839
  %1843 = add nuw nsw i32 %1842, %1841
  %1844 = icmp eq i32 %1843, 2
  %1845 = zext i1 %1844 to i8
  store i8 %1845, i8* %55, align 1, !tbaa !2450
  %1846 = icmp ne i8 %1838, 0
  %1847 = xor i1 %1846, %1844
  %.v47 = select i1 %1847, i64 12, i64 474
  %1848 = add i64 %1811, %.v47
  %1849 = add i64 %1848, 10
  store i64 %1849, i64* %PC, align 8
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %1850 = add i64 %1848, 13
  store i64 %1850, i64* %PC, align 8
  br i1 %1847, label %block_40223b, label %block_402409

block_402228:                                     ; preds = %block_40221c
  %1851 = add i64 %1929, -28
  %1852 = add i64 %1965, 7
  store i64 %1852, i64* %PC, align 8
  %1853 = inttoptr i64 %1851 to i32*
  store i32 0, i32* %1853, align 4
  %.pre43 = load i64, i64* %PC, align 8
  br label %block_40222f

block_401cba:                                     ; preds = %block_401cb3, %block_40204f
  %1854 = phi i64 [ %.pre40, %block_401cb3 ], [ %818, %block_40204f ]
  %1855 = load i64, i64* %RBP, align 8
  %1856 = add i64 %1855, -36
  %1857 = add i64 %1854, 3
  store i64 %1857, i64* %PC, align 8
  %1858 = inttoptr i64 %1856 to i32*
  %1859 = load i32, i32* %1858, align 4
  %1860 = zext i32 %1859 to i64
  store i64 %1860, i64* %RAX, align 8, !tbaa !2428
  %1861 = add i64 %1855, -48
  %1862 = add i64 %1854, 6
  store i64 %1862, i64* %PC, align 8
  %1863 = inttoptr i64 %1861 to i32*
  %1864 = load i32, i32* %1863, align 4
  %1865 = sub i32 %1859, %1864
  %1866 = icmp ult i32 %1859, %1864
  %1867 = zext i1 %1866 to i8
  store i8 %1867, i8* %50, align 1, !tbaa !2432
  %1868 = and i32 %1865, 255
  %1869 = tail call i32 @llvm.ctpop.i32(i32 %1868) #14
  %1870 = trunc i32 %1869 to i8
  %1871 = and i8 %1870, 1
  %1872 = xor i8 %1871, 1
  store i8 %1872, i8* %51, align 1, !tbaa !2446
  %1873 = xor i32 %1864, %1859
  %1874 = xor i32 %1873, %1865
  %1875 = lshr i32 %1874, 4
  %1876 = trunc i32 %1875 to i8
  %1877 = and i8 %1876, 1
  store i8 %1877, i8* %52, align 1, !tbaa !2447
  %1878 = icmp eq i32 %1865, 0
  %1879 = zext i1 %1878 to i8
  store i8 %1879, i8* %53, align 1, !tbaa !2448
  %1880 = lshr i32 %1865, 31
  %1881 = trunc i32 %1880 to i8
  store i8 %1881, i8* %54, align 1, !tbaa !2449
  %1882 = lshr i32 %1859, 31
  %1883 = lshr i32 %1864, 31
  %1884 = xor i32 %1883, %1882
  %1885 = xor i32 %1880, %1882
  %1886 = add nuw nsw i32 %1885, %1884
  %1887 = icmp eq i32 %1886, 2
  %1888 = zext i1 %1887 to i8
  store i8 %1888, i8* %55, align 1, !tbaa !2450
  %1889 = icmp ne i8 %1881, 0
  %1890 = xor i1 %1889, %1887
  %.v48 = select i1 %1890, i64 12, i64 1276
  %1891 = add i64 %1854, %.v48
  store i64 %1891, i64* %PC, align 8, !tbaa !2428
  br i1 %1890, label %block_401cc6, label %block_4024a2.loopexit

block_4024a2.loopexit:                            ; preds = %block_401cba
  br label %block_4024a2

block_4024a2.loopexit77:                          ; preds = %block_40221c
  br label %block_4024a2

block_4024a2:                                     ; preds = %block_4024a2.loopexit77, %block_4024a2.loopexit
  %1892 = phi i64 [ %1891, %block_4024a2.loopexit ], [ %1965, %block_4024a2.loopexit77 ]
  %.sink5 = phi i64 [ 749, %block_4024a2.loopexit ], [ 6, %block_4024a2.loopexit77 ]
  %1893 = add i64 %.sink5, %1892
  store i64 %1893, i64* %PC, align 8
  %1894 = load i64, i64* %6, align 8, !tbaa !2428
  %1895 = add i64 %1894, 8
  %1896 = inttoptr i64 %1894 to i64*
  %1897 = load i64, i64* %1896, align 8
  store i64 %1897, i64* %RBP, align 8, !tbaa !2428
  store i64 %1895, i64* %6, align 8, !tbaa !2428
  %1898 = add i64 %1893, 1
  store i64 %1898, i64* %PC, align 8
  %1899 = inttoptr i64 %1895 to i64*
  %1900 = load i64, i64* %1899, align 8
  store i64 %1900, i64* %PC, align 8, !tbaa !2428
  %1901 = add i64 %1894, 16
  store i64 %1901, i64* %6, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_401c45:                                     ; preds = %block_401c36
  %1902 = add i64 %1689, 3
  store i64 %1902, i64* %PC, align 8
  %1903 = load i32, i32* %1660, align 4
  %1904 = zext i32 %1903 to i64
  %1905 = shl nuw i64 %1904, 32
  %1906 = ashr i64 %1905, 33
  %1907 = trunc i32 %1903 to i8
  %1908 = and i8 %1907, 1
  %1909 = trunc i64 %1906 to i32
  %1910 = and i64 %1906, 4294967295
  store i64 %1910, i64* %RAX, align 8, !tbaa !2428
  store i8 %1908, i8* %50, align 1, !tbaa !2453
  %1911 = and i32 %1909, 255
  %1912 = tail call i32 @llvm.ctpop.i32(i32 %1911) #14
  %1913 = trunc i32 %1912 to i8
  %1914 = and i8 %1913, 1
  %1915 = xor i8 %1914, 1
  store i8 %1915, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %1916 = icmp eq i32 %1909, 0
  %1917 = zext i1 %1916 to i8
  store i8 %1917, i8* %53, align 1, !tbaa !2453
  %1918 = lshr i64 %1906, 31
  %1919 = trunc i64 %1918 to i8
  %1920 = and i8 %1919, 1
  store i8 %1920, i8* %54, align 1, !tbaa !2453
  store i8 0, i8* %55, align 1, !tbaa !2453
  %1921 = trunc i64 %1906 to i32
  %1922 = add i64 %1689, 9
  store i64 %1922, i64* %PC, align 8
  store i32 %1921, i32* %1660, align 4
  %1923 = load i64, i64* %RBP, align 8
  %1924 = add i64 %1923, -28
  %1925 = load i64, i64* %PC, align 8
  %1926 = add i64 %1925, 7
  store i64 %1926, i64* %PC, align 8
  %1927 = inttoptr i64 %1924 to i32*
  store i32 0, i32* %1927, align 4
  %.pre44 = load i64, i64* %PC, align 8
  br label %block_401c55

block_40221c:                                     ; preds = %block_402409, %block_4021bb
  %1928 = phi i64 [ %3874, %block_402409 ], [ %.pre42, %block_4021bb ]
  %1929 = load i64, i64* %RBP, align 8
  %1930 = add i64 %1929, -36
  %1931 = add i64 %1928, 3
  store i64 %1931, i64* %PC, align 8
  %1932 = inttoptr i64 %1930 to i32*
  %1933 = load i32, i32* %1932, align 4
  %1934 = zext i32 %1933 to i64
  store i64 %1934, i64* %RAX, align 8, !tbaa !2428
  %1935 = add i64 %1929, -48
  %1936 = add i64 %1928, 6
  store i64 %1936, i64* %PC, align 8
  %1937 = inttoptr i64 %1935 to i32*
  %1938 = load i32, i32* %1937, align 4
  %1939 = sub i32 %1933, %1938
  %1940 = icmp ult i32 %1933, %1938
  %1941 = zext i1 %1940 to i8
  store i8 %1941, i8* %50, align 1, !tbaa !2432
  %1942 = and i32 %1939, 255
  %1943 = tail call i32 @llvm.ctpop.i32(i32 %1942) #14
  %1944 = trunc i32 %1943 to i8
  %1945 = and i8 %1944, 1
  %1946 = xor i8 %1945, 1
  store i8 %1946, i8* %51, align 1, !tbaa !2446
  %1947 = xor i32 %1938, %1933
  %1948 = xor i32 %1947, %1939
  %1949 = lshr i32 %1948, 4
  %1950 = trunc i32 %1949 to i8
  %1951 = and i8 %1950, 1
  store i8 %1951, i8* %52, align 1, !tbaa !2447
  %1952 = icmp eq i32 %1939, 0
  %1953 = zext i1 %1952 to i8
  store i8 %1953, i8* %53, align 1, !tbaa !2448
  %1954 = lshr i32 %1939, 31
  %1955 = trunc i32 %1954 to i8
  store i8 %1955, i8* %54, align 1, !tbaa !2449
  %1956 = lshr i32 %1933, 31
  %1957 = lshr i32 %1938, 31
  %1958 = xor i32 %1957, %1956
  %1959 = xor i32 %1954, %1956
  %1960 = add nuw nsw i32 %1959, %1958
  %1961 = icmp eq i32 %1960, 2
  %1962 = zext i1 %1961 to i8
  store i8 %1962, i8* %55, align 1, !tbaa !2450
  %1963 = icmp ne i8 %1955, 0
  %1964 = xor i1 %1963, %1961
  %.v46 = select i1 %1964, i64 12, i64 641
  %1965 = add i64 %1928, %.v46
  store i64 %1965, i64* %PC, align 8, !tbaa !2428
  br i1 %1964, label %block_402228, label %block_4024a2.loopexit77

block_401c9b:                                     ; preds = %block_401c36
  %1966 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %1967 = add i64 %1689, 3
  store i64 %1967, i64* %PC, align 8
  %1968 = load i32, i32* %1641, align 4
  %1969 = shl i32 %1968, 1
  %1970 = icmp slt i32 %1968, 0
  %1971 = icmp slt i32 %1969, 0
  %1972 = xor i1 %1970, %1971
  %1973 = zext i32 %1969 to i64
  store i64 %1973, i64* %RAX, align 8, !tbaa !2428
  %.lobit12 = lshr i32 %1968, 31
  %1974 = trunc i32 %.lobit12 to i8
  store i8 %1974, i8* %50, align 1, !tbaa !2453
  %1975 = and i32 %1969, 254
  %1976 = tail call i32 @llvm.ctpop.i32(i32 %1975) #14
  %1977 = trunc i32 %1976 to i8
  %1978 = and i8 %1977, 1
  %1979 = xor i8 %1978, 1
  store i8 %1979, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %1980 = icmp eq i32 %1969, 0
  %1981 = zext i1 %1980 to i8
  store i8 %1981, i8* %53, align 1, !tbaa !2453
  %1982 = lshr i32 %1968, 30
  %1983 = trunc i32 %1982 to i8
  %1984 = and i8 %1983, 1
  store i8 %1984, i8* %54, align 1, !tbaa !2453
  %1985 = zext i1 %1972 to i8
  store i8 %1985, i8* %55, align 1, !tbaa !2453
  %1986 = add i64 %1638, -52
  %1987 = add i64 %1689, 9
  store i64 %1987, i64* %PC, align 8
  %1988 = inttoptr i64 %1986 to i32*
  store i32 %1969, i32* %1988, align 4
  %1989 = load i64, i64* %RBP, align 8
  %1990 = add i64 %1989, -48
  %1991 = load i64, i64* %PC, align 8
  %1992 = add i64 %1991, 3
  store i64 %1992, i64* %PC, align 8
  %1993 = inttoptr i64 %1990 to i32*
  %1994 = load i32, i32* %1993, align 4
  %1995 = shl i32 %1994, 3
  %1996 = zext i32 %1995 to i64
  store i64 %1996, i64* %RAX, align 8, !tbaa !2428
  %1997 = lshr i32 %1994, 29
  %1998 = trunc i32 %1997 to i8
  %1999 = and i8 %1998, 1
  store i8 %1999, i8* %50, align 1, !tbaa !2453
  %2000 = and i32 %1995, 248
  %2001 = tail call i32 @llvm.ctpop.i32(i32 %2000) #14
  %2002 = trunc i32 %2001 to i8
  %2003 = and i8 %2002, 1
  %2004 = xor i8 %2003, 1
  store i8 %2004, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2005 = icmp eq i32 %1995, 0
  %2006 = zext i1 %2005 to i8
  store i8 %2006, i8* %53, align 1, !tbaa !2453
  %2007 = lshr i32 %1994, 28
  %2008 = trunc i32 %2007 to i8
  %2009 = and i8 %2008, 1
  store i8 %2009, i8* %54, align 1, !tbaa !2453
  store i8 0, i8* %55, align 1, !tbaa !2453
  %2010 = add i64 %1989, -44
  %2011 = add i64 %1991, 9
  store i64 %2011, i64* %PC, align 8
  %2012 = inttoptr i64 %2010 to i32*
  %2013 = load i32, i32* %2012, align 4
  %2014 = sub i32 %1995, %2013
  %2015 = icmp ult i32 %1995, %2013
  %2016 = zext i1 %2015 to i8
  store i8 %2016, i8* %50, align 1, !tbaa !2432
  %2017 = and i32 %2014, 255
  %2018 = tail call i32 @llvm.ctpop.i32(i32 %2017) #14
  %2019 = trunc i32 %2018 to i8
  %2020 = and i8 %2019, 1
  %2021 = xor i8 %2020, 1
  store i8 %2021, i8* %51, align 1, !tbaa !2446
  %2022 = xor i32 %2013, %1995
  %2023 = xor i32 %2022, %2014
  %2024 = lshr i32 %2023, 4
  %2025 = trunc i32 %2024 to i8
  %2026 = and i8 %2025, 1
  store i8 %2026, i8* %52, align 1, !tbaa !2447
  %2027 = icmp eq i32 %2014, 0
  %2028 = zext i1 %2027 to i8
  store i8 %2028, i8* %53, align 1, !tbaa !2448
  %2029 = lshr i32 %2014, 31
  %2030 = trunc i32 %2029 to i8
  store i8 %2030, i8* %54, align 1, !tbaa !2449
  %2031 = lshr i32 %1994, 28
  %2032 = and i32 %2031, 1
  %2033 = lshr i32 %2013, 31
  %2034 = xor i32 %2033, %2032
  %2035 = xor i32 %2029, %2032
  %2036 = add nuw nsw i32 %2035, %2034
  %2037 = icmp eq i32 %2036, 2
  %2038 = zext i1 %2037 to i8
  store i8 %2038, i8* %55, align 1, !tbaa !2450
  %.v45 = select i1 %2027, i64 15, i64 1303
  %2039 = add i64 %1991, %.v45
  store i64 %2039, i64* %PC, align 8, !tbaa !2428
  br i1 %2027, label %block_401cb3, label %block_4021bb

block_401c55:                                     ; preds = %block_401c45, %block_401c61
  %2040 = phi i64 [ %.pre44, %block_401c45 ], [ %170, %block_401c61 ]
  %2041 = load i64, i64* %RBP, align 8
  %2042 = add i64 %2041, -28
  %2043 = add i64 %2040, 3
  store i64 %2043, i64* %PC, align 8
  %2044 = inttoptr i64 %2042 to i32*
  %2045 = load i32, i32* %2044, align 4
  %2046 = zext i32 %2045 to i64
  store i64 %2046, i64* %RAX, align 8, !tbaa !2428
  %2047 = add i64 %2041, -48
  %2048 = add i64 %2040, 6
  store i64 %2048, i64* %PC, align 8
  %2049 = inttoptr i64 %2047 to i32*
  %2050 = load i32, i32* %2049, align 4
  %2051 = sub i32 %2045, %2050
  %2052 = icmp ult i32 %2045, %2050
  %2053 = zext i1 %2052 to i8
  store i8 %2053, i8* %50, align 1, !tbaa !2432
  %2054 = and i32 %2051, 255
  %2055 = tail call i32 @llvm.ctpop.i32(i32 %2054) #14
  %2056 = trunc i32 %2055 to i8
  %2057 = and i8 %2056, 1
  %2058 = xor i8 %2057, 1
  store i8 %2058, i8* %51, align 1, !tbaa !2446
  %2059 = xor i32 %2050, %2045
  %2060 = xor i32 %2059, %2051
  %2061 = lshr i32 %2060, 4
  %2062 = trunc i32 %2061 to i8
  %2063 = and i8 %2062, 1
  store i8 %2063, i8* %52, align 1, !tbaa !2447
  %2064 = icmp eq i32 %2051, 0
  %2065 = zext i1 %2064 to i8
  store i8 %2065, i8* %53, align 1, !tbaa !2448
  %2066 = lshr i32 %2051, 31
  %2067 = trunc i32 %2066 to i8
  store i8 %2067, i8* %54, align 1, !tbaa !2449
  %2068 = lshr i32 %2045, 31
  %2069 = lshr i32 %2050, 31
  %2070 = xor i32 %2069, %2068
  %2071 = xor i32 %2066, %2068
  %2072 = add nuw nsw i32 %2071, %2070
  %2073 = icmp eq i32 %2072, 2
  %2074 = zext i1 %2073 to i8
  store i8 %2074, i8* %55, align 1, !tbaa !2450
  %2075 = icmp ne i8 %2067, 0
  %2076 = xor i1 %2075, %2073
  %.v50 = select i1 %2076, i64 12, i64 56
  %2077 = add i64 %2040, %.v50
  store i64 %2077, i64* %PC, align 8, !tbaa !2428
  br i1 %2076, label %block_401c61, label %block_401c8d

block_401c8d:                                     ; preds = %block_401c55
  %2078 = add i64 %2077, 3
  store i64 %2078, i64* %PC, align 8
  %2079 = load i32, i32* %2049, align 4
  %2080 = shl i32 %2079, 1
  %2081 = icmp slt i32 %2079, 0
  %2082 = icmp slt i32 %2080, 0
  %2083 = xor i1 %2081, %2082
  %2084 = zext i32 %2080 to i64
  store i64 %2084, i64* %RAX, align 8, !tbaa !2428
  %.lobit = lshr i32 %2079, 31
  %2085 = trunc i32 %.lobit to i8
  store i8 %2085, i8* %50, align 1, !tbaa !2453
  %2086 = and i32 %2080, 254
  %2087 = tail call i32 @llvm.ctpop.i32(i32 %2086) #14
  %2088 = trunc i32 %2087 to i8
  %2089 = and i8 %2088, 1
  %2090 = xor i8 %2089, 1
  store i8 %2090, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2091 = icmp eq i32 %2080, 0
  %2092 = zext i1 %2091 to i8
  store i8 %2092, i8* %53, align 1, !tbaa !2453
  %2093 = lshr i32 %2079, 30
  %2094 = trunc i32 %2093 to i8
  %2095 = and i8 %2094, 1
  store i8 %2095, i8* %54, align 1, !tbaa !2453
  %2096 = zext i1 %2083 to i8
  store i8 %2096, i8* %55, align 1, !tbaa !2453
  %2097 = add i64 %2077, 9
  store i64 %2097, i64* %PC, align 8
  store i32 %2080, i32* %2049, align 4
  %2098 = load i64, i64* %PC, align 8
  %2099 = add i64 %2098, -96
  store i64 %2099, i64* %PC, align 8, !tbaa !2428
  br label %block_401c36

block_401cd9:                                     ; preds = %block_401ccd
  %2100 = load i32, i32* %823, align 4
  %2101 = shl i32 %2100, 1
  %2102 = icmp slt i32 %2100, 0
  %2103 = icmp slt i32 %2101, 0
  %2104 = xor i1 %2102, %2103
  %2105 = zext i32 %2101 to i64
  store i64 %2105, i64* %RCX, align 8, !tbaa !2428
  %.lobit14 = lshr i32 %2100, 31
  %2106 = trunc i32 %.lobit14 to i8
  store i8 %2106, i8* %50, align 1, !tbaa !2453
  %2107 = and i32 %2101, 254
  %2108 = tail call i32 @llvm.ctpop.i32(i32 %2107) #14
  %2109 = trunc i32 %2108 to i8
  %2110 = and i8 %2109, 1
  %2111 = xor i8 %2110, 1
  store i8 %2111, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2112 = icmp eq i32 %2101, 0
  %2113 = zext i1 %2112 to i8
  store i8 %2113, i8* %53, align 1, !tbaa !2453
  %2114 = lshr i32 %2100, 30
  %2115 = trunc i32 %2114 to i8
  %2116 = and i8 %2115, 1
  store i8 %2116, i8* %54, align 1, !tbaa !2453
  %2117 = zext i1 %2104 to i8
  store i8 %2117, i8* %55, align 1, !tbaa !2453
  %2118 = add i64 %820, -16
  %2119 = add i64 %856, 20
  store i64 %2119, i64* %PC, align 8
  %2120 = inttoptr i64 %2118 to i64*
  %2121 = load i64, i64* %2120, align 8
  store i64 %2121, i64* %RDX, align 8, !tbaa !2428
  %2122 = add i64 %856, 24
  store i64 %2122, i64* %PC, align 8
  %2123 = load i32, i32* %828, align 4
  %2124 = sext i32 %2123 to i64
  store i64 %2124, i64* %RSI, align 8, !tbaa !2428
  %2125 = shl nsw i64 %2124, 2
  %2126 = add i64 %2121, %2125
  %2127 = add i64 %856, 27
  store i64 %2127, i64* %PC, align 8
  %2128 = inttoptr i64 %2126 to i32*
  %2129 = load i32, i32* %2128, align 4
  %2130 = add i32 %2129, %2101
  %2131 = zext i32 %2130 to i64
  store i64 %2131, i64* %RCX, align 8, !tbaa !2428
  %2132 = icmp ult i32 %2130, %2101
  %2133 = icmp ult i32 %2130, %2129
  %2134 = or i1 %2132, %2133
  %2135 = zext i1 %2134 to i8
  store i8 %2135, i8* %50, align 1, !tbaa !2432
  %2136 = and i32 %2130, 255
  %2137 = tail call i32 @llvm.ctpop.i32(i32 %2136) #14
  %2138 = trunc i32 %2137 to i8
  %2139 = and i8 %2138, 1
  %2140 = xor i8 %2139, 1
  store i8 %2140, i8* %51, align 1, !tbaa !2446
  %2141 = xor i32 %2129, %2101
  %2142 = xor i32 %2141, %2130
  %2143 = lshr i32 %2142, 4
  %2144 = trunc i32 %2143 to i8
  %2145 = and i8 %2144, 1
  store i8 %2145, i8* %52, align 1, !tbaa !2447
  %2146 = icmp eq i32 %2130, 0
  %2147 = zext i1 %2146 to i8
  store i8 %2147, i8* %53, align 1, !tbaa !2448
  %2148 = lshr i32 %2130, 31
  %2149 = trunc i32 %2148 to i8
  store i8 %2149, i8* %54, align 1, !tbaa !2449
  %2150 = lshr i32 %2100, 30
  %2151 = and i32 %2150, 1
  %2152 = lshr i32 %2129, 31
  %2153 = xor i32 %2148, %2151
  %2154 = xor i32 %2148, %2152
  %2155 = add nuw nsw i32 %2153, %2154
  %2156 = icmp eq i32 %2155, 2
  %2157 = zext i1 %2156 to i8
  store i8 %2157, i8* %55, align 1, !tbaa !2450
  %2158 = add i64 %820, -32
  %2159 = add i64 %856, 30
  store i64 %2159, i64* %PC, align 8
  %2160 = inttoptr i64 %2158 to i32*
  store i32 %2130, i32* %2160, align 4
  %2161 = load i64, i64* %RBP, align 8
  %2162 = add i64 %2161, -36
  %2163 = load i64, i64* %PC, align 8
  %2164 = add i64 %2163, 3
  store i64 %2164, i64* %PC, align 8
  %2165 = inttoptr i64 %2162 to i32*
  %2166 = load i32, i32* %2165, align 4
  %2167 = shl i32 %2166, 1
  %2168 = icmp slt i32 %2166, 0
  %2169 = icmp slt i32 %2167, 0
  %2170 = xor i1 %2168, %2169
  %2171 = zext i32 %2167 to i64
  store i64 %2171, i64* %RCX, align 8, !tbaa !2428
  %.lobit15 = lshr i32 %2166, 31
  %2172 = trunc i32 %.lobit15 to i8
  store i8 %2172, i8* %50, align 1, !tbaa !2453
  %2173 = and i32 %2167, 254
  %2174 = tail call i32 @llvm.ctpop.i32(i32 %2173) #14
  %2175 = trunc i32 %2174 to i8
  %2176 = and i8 %2175, 1
  %2177 = xor i8 %2176, 1
  store i8 %2177, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2178 = icmp eq i32 %2167, 0
  %2179 = zext i1 %2178 to i8
  store i8 %2179, i8* %53, align 1, !tbaa !2453
  %2180 = lshr i32 %2166, 30
  %2181 = trunc i32 %2180 to i8
  %2182 = and i8 %2181, 1
  store i8 %2182, i8* %54, align 1, !tbaa !2453
  %2183 = zext i1 %2170 to i8
  store i8 %2183, i8* %55, align 1, !tbaa !2453
  %2184 = add i64 %2161, -16
  %2185 = add i64 %2163, 10
  store i64 %2185, i64* %PC, align 8
  %2186 = inttoptr i64 %2184 to i64*
  %2187 = load i64, i64* %2186, align 8
  store i64 %2187, i64* %RDX, align 8, !tbaa !2428
  %2188 = add i64 %2161, -28
  %2189 = add i64 %2163, 14
  store i64 %2189, i64* %PC, align 8
  %2190 = inttoptr i64 %2188 to i32*
  %2191 = load i32, i32* %2190, align 4
  %2192 = sext i32 %2191 to i64
  store i64 %2192, i64* %RSI, align 8, !tbaa !2428
  %2193 = shl nsw i64 %2192, 2
  %2194 = add i64 %2187, %2193
  %2195 = add i64 %2163, 17
  store i64 %2195, i64* %PC, align 8
  %2196 = inttoptr i64 %2194 to i32*
  %2197 = load i32, i32* %2196, align 4
  %2198 = add i32 %2197, %2167
  %2199 = zext i32 %2198 to i64
  store i64 %2199, i64* %RCX, align 8, !tbaa !2428
  %2200 = icmp ult i32 %2198, %2167
  %2201 = icmp ult i32 %2198, %2197
  %2202 = or i1 %2200, %2201
  %2203 = zext i1 %2202 to i8
  store i8 %2203, i8* %50, align 1, !tbaa !2432
  %2204 = and i32 %2198, 255
  %2205 = tail call i32 @llvm.ctpop.i32(i32 %2204) #14
  %2206 = trunc i32 %2205 to i8
  %2207 = and i8 %2206, 1
  %2208 = xor i8 %2207, 1
  store i8 %2208, i8* %51, align 1, !tbaa !2446
  %2209 = xor i32 %2197, %2167
  %2210 = xor i32 %2209, %2198
  %2211 = lshr i32 %2210, 4
  %2212 = trunc i32 %2211 to i8
  %2213 = and i8 %2212, 1
  store i8 %2213, i8* %52, align 1, !tbaa !2447
  %2214 = icmp eq i32 %2198, 0
  %2215 = zext i1 %2214 to i8
  store i8 %2215, i8* %53, align 1, !tbaa !2448
  %2216 = lshr i32 %2198, 31
  %2217 = trunc i32 %2216 to i8
  store i8 %2217, i8* %54, align 1, !tbaa !2449
  %2218 = lshr i32 %2166, 30
  %2219 = and i32 %2218, 1
  %2220 = lshr i32 %2197, 31
  %2221 = xor i32 %2216, %2219
  %2222 = xor i32 %2216, %2220
  %2223 = add nuw nsw i32 %2221, %2222
  %2224 = icmp eq i32 %2223, 2
  %2225 = zext i1 %2224 to i8
  store i8 %2225, i8* %55, align 1, !tbaa !2450
  %2226 = add i64 %2161, -40
  %2227 = add i64 %2163, 20
  store i64 %2227, i64* %PC, align 8
  %2228 = inttoptr i64 %2226 to i32*
  store i32 %2198, i32* %2228, align 4
  %2229 = load i64, i64* %RBP, align 8
  %2230 = add i64 %2229, -24
  %2231 = load i64, i64* %PC, align 8
  %2232 = add i64 %2231, 4
  store i64 %2232, i64* %PC, align 8
  %2233 = inttoptr i64 %2230 to i64*
  %2234 = load i64, i64* %2233, align 8
  store i64 %2234, i64* %RDX, align 8, !tbaa !2428
  %2235 = add i64 %2229, -32
  %2236 = add i64 %2231, 8
  store i64 %2236, i64* %PC, align 8
  %2237 = inttoptr i64 %2235 to i32*
  %2238 = load i32, i32* %2237, align 4
  %2239 = sext i32 %2238 to i64
  store i64 %2239, i64* %RSI, align 8, !tbaa !2428
  %2240 = shl nsw i64 %2239, 3
  %2241 = add i64 %2240, %2234
  %2242 = add i64 %2231, 13
  store i64 %2242, i64* %PC, align 8
  %2243 = inttoptr i64 %2241 to i64*
  %2244 = load i64, i64* %2243, align 8
  store i64 %2244, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %2245 = add i64 %2229, -64
  %2246 = add i64 %2231, 18
  store i64 %2246, i64* %PC, align 8
  %2247 = inttoptr i64 %2245 to i64*
  store i64 %2244, i64* %2247, align 8
  %2248 = load i64, i64* %RBP, align 8
  %2249 = add i64 %2248, -24
  %2250 = load i64, i64* %PC, align 8
  %2251 = add i64 %2250, 4
  store i64 %2251, i64* %PC, align 8
  %2252 = inttoptr i64 %2249 to i64*
  %2253 = load i64, i64* %2252, align 8
  store i64 %2253, i64* %RDX, align 8, !tbaa !2428
  %2254 = add i64 %2248, -32
  %2255 = add i64 %2250, 7
  store i64 %2255, i64* %PC, align 8
  %2256 = inttoptr i64 %2254 to i32*
  %2257 = load i32, i32* %2256, align 4
  %2258 = add i32 %2257, 1
  %2259 = zext i32 %2258 to i64
  store i64 %2259, i64* %RCX, align 8, !tbaa !2428
  %2260 = icmp eq i32 %2257, -1
  %2261 = icmp eq i32 %2258, 0
  %2262 = or i1 %2260, %2261
  %2263 = zext i1 %2262 to i8
  store i8 %2263, i8* %50, align 1, !tbaa !2432
  %2264 = and i32 %2258, 255
  %2265 = tail call i32 @llvm.ctpop.i32(i32 %2264) #14
  %2266 = trunc i32 %2265 to i8
  %2267 = and i8 %2266, 1
  %2268 = xor i8 %2267, 1
  store i8 %2268, i8* %51, align 1, !tbaa !2446
  %2269 = xor i32 %2258, %2257
  %2270 = lshr i32 %2269, 4
  %2271 = trunc i32 %2270 to i8
  %2272 = and i8 %2271, 1
  store i8 %2272, i8* %52, align 1, !tbaa !2447
  %2273 = zext i1 %2261 to i8
  store i8 %2273, i8* %53, align 1, !tbaa !2448
  %2274 = lshr i32 %2258, 31
  %2275 = trunc i32 %2274 to i8
  store i8 %2275, i8* %54, align 1, !tbaa !2449
  %2276 = lshr i32 %2257, 31
  %2277 = xor i32 %2274, %2276
  %2278 = add nuw nsw i32 %2277, %2274
  %2279 = icmp eq i32 %2278, 2
  %2280 = zext i1 %2279 to i8
  store i8 %2280, i8* %55, align 1, !tbaa !2450
  %2281 = sext i32 %2258 to i64
  store i64 %2281, i64* %RSI, align 8, !tbaa !2428
  %2282 = shl nsw i64 %2281, 3
  %2283 = add i64 %2253, %2282
  %2284 = add i64 %2250, 18
  store i64 %2284, i64* %PC, align 8
  %2285 = inttoptr i64 %2283 to i64*
  %2286 = load i64, i64* %2285, align 8
  %2287 = load i64, i64* %RAX, align 8
  %2288 = xor i64 %2287, %2286
  store i64 %2288, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %2289 = trunc i64 %2288 to i32
  %2290 = and i32 %2289, 255
  %2291 = tail call i32 @llvm.ctpop.i32(i32 %2290) #14
  %2292 = trunc i32 %2291 to i8
  %2293 = and i8 %2292, 1
  %2294 = xor i8 %2293, 1
  store i8 %2294, i8* %51, align 1, !tbaa !2446
  %2295 = icmp eq i64 %2288, 0
  %2296 = zext i1 %2295 to i8
  store i8 %2296, i8* %53, align 1, !tbaa !2448
  %2297 = lshr i64 %2288, 63
  %2298 = trunc i64 %2297 to i8
  store i8 %2298, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %2288, i64* %1808, align 1, !tbaa !2428
  store i64 0, i64* %1809, align 1, !tbaa !2428
  %2299 = add i64 %2248, -72
  %2300 = add i64 %2250, 36
  store i64 %2300, i64* %PC, align 8
  %2301 = inttoptr i64 %2299 to i64*
  store i64 %2288, i64* %2301, align 8
  %2302 = load i64, i64* %RBP, align 8
  %2303 = add i64 %2302, -24
  %2304 = load i64, i64* %PC, align 8
  %2305 = add i64 %2304, 4
  store i64 %2305, i64* %PC, align 8
  %2306 = inttoptr i64 %2303 to i64*
  %2307 = load i64, i64* %2306, align 8
  store i64 %2307, i64* %RDX, align 8, !tbaa !2428
  %2308 = add i64 %2302, -40
  %2309 = add i64 %2304, 8
  store i64 %2309, i64* %PC, align 8
  %2310 = inttoptr i64 %2308 to i32*
  %2311 = load i32, i32* %2310, align 4
  %2312 = sext i32 %2311 to i64
  store i64 %2312, i64* %RSI, align 8, !tbaa !2428
  %2313 = shl nsw i64 %2312, 3
  %2314 = add i64 %2313, %2307
  %2315 = add i64 %2304, 13
  store i64 %2315, i64* %PC, align 8
  %2316 = inttoptr i64 %2314 to i64*
  %2317 = load i64, i64* %2316, align 8
  store i64 %2317, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %2318 = add i64 %2302, -80
  %2319 = add i64 %2304, 18
  store i64 %2319, i64* %PC, align 8
  %2320 = inttoptr i64 %2318 to i64*
  store i64 %2317, i64* %2320, align 8
  %2321 = load i64, i64* %RBP, align 8
  %2322 = add i64 %2321, -24
  %2323 = load i64, i64* %PC, align 8
  %2324 = add i64 %2323, 4
  store i64 %2324, i64* %PC, align 8
  %2325 = inttoptr i64 %2322 to i64*
  %2326 = load i64, i64* %2325, align 8
  store i64 %2326, i64* %RDX, align 8, !tbaa !2428
  %2327 = add i64 %2321, -40
  %2328 = add i64 %2323, 7
  store i64 %2328, i64* %PC, align 8
  %2329 = inttoptr i64 %2327 to i32*
  %2330 = load i32, i32* %2329, align 4
  %2331 = add i32 %2330, 1
  %2332 = zext i32 %2331 to i64
  store i64 %2332, i64* %RCX, align 8, !tbaa !2428
  %2333 = icmp eq i32 %2330, -1
  %2334 = icmp eq i32 %2331, 0
  %2335 = or i1 %2333, %2334
  %2336 = zext i1 %2335 to i8
  store i8 %2336, i8* %50, align 1, !tbaa !2432
  %2337 = and i32 %2331, 255
  %2338 = tail call i32 @llvm.ctpop.i32(i32 %2337) #14
  %2339 = trunc i32 %2338 to i8
  %2340 = and i8 %2339, 1
  %2341 = xor i8 %2340, 1
  store i8 %2341, i8* %51, align 1, !tbaa !2446
  %2342 = xor i32 %2331, %2330
  %2343 = lshr i32 %2342, 4
  %2344 = trunc i32 %2343 to i8
  %2345 = and i8 %2344, 1
  store i8 %2345, i8* %52, align 1, !tbaa !2447
  %2346 = zext i1 %2334 to i8
  store i8 %2346, i8* %53, align 1, !tbaa !2448
  %2347 = lshr i32 %2331, 31
  %2348 = trunc i32 %2347 to i8
  store i8 %2348, i8* %54, align 1, !tbaa !2449
  %2349 = lshr i32 %2330, 31
  %2350 = xor i32 %2347, %2349
  %2351 = add nuw nsw i32 %2350, %2347
  %2352 = icmp eq i32 %2351, 2
  %2353 = zext i1 %2352 to i8
  store i8 %2353, i8* %55, align 1, !tbaa !2450
  %2354 = sext i32 %2331 to i64
  store i64 %2354, i64* %RSI, align 8, !tbaa !2428
  %2355 = shl nsw i64 %2354, 3
  %2356 = add i64 %2326, %2355
  %2357 = add i64 %2323, 18
  store i64 %2357, i64* %PC, align 8
  %2358 = inttoptr i64 %2356 to i64*
  %2359 = load i64, i64* %2358, align 8
  %2360 = load i64, i64* %RAX, align 8
  %2361 = xor i64 %2360, %2359
  store i64 %2361, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %2362 = trunc i64 %2361 to i32
  %2363 = and i32 %2362, 255
  %2364 = tail call i32 @llvm.ctpop.i32(i32 %2363) #14
  %2365 = trunc i32 %2364 to i8
  %2366 = and i8 %2365, 1
  %2367 = xor i8 %2366, 1
  store i8 %2367, i8* %51, align 1, !tbaa !2446
  %2368 = icmp eq i64 %2361, 0
  %2369 = zext i1 %2368 to i8
  store i8 %2369, i8* %53, align 1, !tbaa !2448
  %2370 = lshr i64 %2361, 63
  %2371 = trunc i64 %2370 to i8
  store i8 %2371, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %2361, i64* %1808, align 1, !tbaa !2428
  store i64 0, i64* %1809, align 1, !tbaa !2428
  %2372 = add i64 %2321, -88
  %2373 = add i64 %2323, 36
  store i64 %2373, i64* %PC, align 8
  %2374 = inttoptr i64 %2372 to i64*
  store i64 %2361, i64* %2374, align 8
  %2375 = load i64, i64* %RBP, align 8
  %2376 = add i64 %2375, -80
  %2377 = load i64, i64* %PC, align 8
  %2378 = add i64 %2377, 5
  store i64 %2378, i64* %PC, align 8
  %2379 = inttoptr i64 %2376 to i64*
  %2380 = load i64, i64* %2379, align 8
  store i64 %2380, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %2381 = add i64 %2375, -24
  %2382 = add i64 %2377, 9
  store i64 %2382, i64* %PC, align 8
  %2383 = inttoptr i64 %2381 to i64*
  %2384 = load i64, i64* %2383, align 8
  store i64 %2384, i64* %RDX, align 8, !tbaa !2428
  %2385 = add i64 %2375, -32
  %2386 = add i64 %2377, 13
  store i64 %2386, i64* %PC, align 8
  %2387 = inttoptr i64 %2385 to i32*
  %2388 = load i32, i32* %2387, align 4
  %2389 = sext i32 %2388 to i64
  store i64 %2389, i64* %RSI, align 8, !tbaa !2428
  %2390 = shl nsw i64 %2389, 3
  %2391 = add i64 %2390, %2384
  %2392 = add i64 %2377, 18
  store i64 %2392, i64* %PC, align 8
  %2393 = inttoptr i64 %2391 to i64*
  store i64 %2380, i64* %2393, align 8
  %2394 = load i64, i64* %RBP, align 8
  %2395 = add i64 %2394, -88
  %2396 = load i64, i64* %PC, align 8
  %2397 = add i64 %2396, 5
  store i64 %2397, i64* %PC, align 8
  %2398 = inttoptr i64 %2395 to i64*
  %2399 = load i64, i64* %2398, align 8
  store i64 %2399, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %2400 = add i64 %2394, -24
  %2401 = add i64 %2396, 9
  store i64 %2401, i64* %PC, align 8
  %2402 = inttoptr i64 %2400 to i64*
  %2403 = load i64, i64* %2402, align 8
  store i64 %2403, i64* %RDX, align 8, !tbaa !2428
  %2404 = add i64 %2394, -32
  %2405 = add i64 %2396, 12
  store i64 %2405, i64* %PC, align 8
  %2406 = inttoptr i64 %2404 to i32*
  %2407 = load i32, i32* %2406, align 4
  %2408 = add i32 %2407, 1
  %2409 = zext i32 %2408 to i64
  store i64 %2409, i64* %RCX, align 8, !tbaa !2428
  %2410 = icmp eq i32 %2407, -1
  %2411 = icmp eq i32 %2408, 0
  %2412 = or i1 %2410, %2411
  %2413 = zext i1 %2412 to i8
  store i8 %2413, i8* %50, align 1, !tbaa !2432
  %2414 = and i32 %2408, 255
  %2415 = tail call i32 @llvm.ctpop.i32(i32 %2414) #14
  %2416 = trunc i32 %2415 to i8
  %2417 = and i8 %2416, 1
  %2418 = xor i8 %2417, 1
  store i8 %2418, i8* %51, align 1, !tbaa !2446
  %2419 = xor i32 %2408, %2407
  %2420 = lshr i32 %2419, 4
  %2421 = trunc i32 %2420 to i8
  %2422 = and i8 %2421, 1
  store i8 %2422, i8* %52, align 1, !tbaa !2447
  %2423 = zext i1 %2411 to i8
  store i8 %2423, i8* %53, align 1, !tbaa !2448
  %2424 = lshr i32 %2408, 31
  %2425 = trunc i32 %2424 to i8
  store i8 %2425, i8* %54, align 1, !tbaa !2449
  %2426 = lshr i32 %2407, 31
  %2427 = xor i32 %2424, %2426
  %2428 = add nuw nsw i32 %2427, %2424
  %2429 = icmp eq i32 %2428, 2
  %2430 = zext i1 %2429 to i8
  store i8 %2430, i8* %55, align 1, !tbaa !2450
  %2431 = sext i32 %2408 to i64
  store i64 %2431, i64* %RSI, align 8, !tbaa !2428
  %2432 = shl nsw i64 %2431, 3
  %2433 = add i64 %2403, %2432
  %2434 = add i64 %2396, 23
  store i64 %2434, i64* %PC, align 8
  %2435 = inttoptr i64 %2433 to i64*
  store i64 %2399, i64* %2435, align 8
  %2436 = load i64, i64* %RBP, align 8
  %2437 = add i64 %2436, -64
  %2438 = load i64, i64* %PC, align 8
  %2439 = add i64 %2438, 5
  store i64 %2439, i64* %PC, align 8
  %2440 = inttoptr i64 %2437 to i64*
  %2441 = load i64, i64* %2440, align 8
  store i64 %2441, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %2442 = add i64 %2436, -24
  %2443 = add i64 %2438, 9
  store i64 %2443, i64* %PC, align 8
  %2444 = inttoptr i64 %2442 to i64*
  %2445 = load i64, i64* %2444, align 8
  store i64 %2445, i64* %RDX, align 8, !tbaa !2428
  %2446 = add i64 %2436, -40
  %2447 = add i64 %2438, 13
  store i64 %2447, i64* %PC, align 8
  %2448 = inttoptr i64 %2446 to i32*
  %2449 = load i32, i32* %2448, align 4
  %2450 = sext i32 %2449 to i64
  store i64 %2450, i64* %RSI, align 8, !tbaa !2428
  %2451 = shl nsw i64 %2450, 3
  %2452 = add i64 %2451, %2445
  %2453 = add i64 %2438, 18
  store i64 %2453, i64* %PC, align 8
  %2454 = inttoptr i64 %2452 to i64*
  store i64 %2441, i64* %2454, align 8
  %2455 = load i64, i64* %RBP, align 8
  %2456 = add i64 %2455, -72
  %2457 = load i64, i64* %PC, align 8
  %2458 = add i64 %2457, 5
  store i64 %2458, i64* %PC, align 8
  %2459 = inttoptr i64 %2456 to i64*
  %2460 = load i64, i64* %2459, align 8
  store i64 %2460, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %2461 = add i64 %2455, -24
  %2462 = add i64 %2457, 9
  store i64 %2462, i64* %PC, align 8
  %2463 = inttoptr i64 %2461 to i64*
  %2464 = load i64, i64* %2463, align 8
  store i64 %2464, i64* %RDX, align 8, !tbaa !2428
  %2465 = add i64 %2455, -40
  %2466 = add i64 %2457, 12
  store i64 %2466, i64* %PC, align 8
  %2467 = inttoptr i64 %2465 to i32*
  %2468 = load i32, i32* %2467, align 4
  %2469 = add i32 %2468, 1
  %2470 = zext i32 %2469 to i64
  store i64 %2470, i64* %RCX, align 8, !tbaa !2428
  %2471 = icmp eq i32 %2468, -1
  %2472 = icmp eq i32 %2469, 0
  %2473 = or i1 %2471, %2472
  %2474 = zext i1 %2473 to i8
  store i8 %2474, i8* %50, align 1, !tbaa !2432
  %2475 = and i32 %2469, 255
  %2476 = tail call i32 @llvm.ctpop.i32(i32 %2475) #14
  %2477 = trunc i32 %2476 to i8
  %2478 = and i8 %2477, 1
  %2479 = xor i8 %2478, 1
  store i8 %2479, i8* %51, align 1, !tbaa !2446
  %2480 = xor i32 %2469, %2468
  %2481 = lshr i32 %2480, 4
  %2482 = trunc i32 %2481 to i8
  %2483 = and i8 %2482, 1
  store i8 %2483, i8* %52, align 1, !tbaa !2447
  %2484 = zext i1 %2472 to i8
  store i8 %2484, i8* %53, align 1, !tbaa !2448
  %2485 = lshr i32 %2469, 31
  %2486 = trunc i32 %2485 to i8
  store i8 %2486, i8* %54, align 1, !tbaa !2449
  %2487 = lshr i32 %2468, 31
  %2488 = xor i32 %2485, %2487
  %2489 = add nuw nsw i32 %2488, %2485
  %2490 = icmp eq i32 %2489, 2
  %2491 = zext i1 %2490 to i8
  store i8 %2491, i8* %55, align 1, !tbaa !2450
  %2492 = sext i32 %2469 to i64
  store i64 %2492, i64* %RSI, align 8, !tbaa !2428
  %2493 = shl nsw i64 %2492, 3
  %2494 = add i64 %2464, %2493
  %2495 = add i64 %2457, 23
  store i64 %2495, i64* %PC, align 8
  %2496 = inttoptr i64 %2494 to i64*
  store i64 %2460, i64* %2496, align 8
  %2497 = load i64, i64* %RBP, align 8
  %2498 = add i64 %2497, -52
  %2499 = load i64, i64* %PC, align 8
  %2500 = add i64 %2499, 3
  store i64 %2500, i64* %PC, align 8
  %2501 = inttoptr i64 %2498 to i32*
  %2502 = load i32, i32* %2501, align 4
  %2503 = zext i32 %2502 to i64
  store i64 %2503, i64* %RCX, align 8, !tbaa !2428
  %2504 = add i64 %2497, -32
  %2505 = add i64 %2499, 6
  store i64 %2505, i64* %PC, align 8
  %2506 = inttoptr i64 %2504 to i32*
  %2507 = load i32, i32* %2506, align 4
  %2508 = add i32 %2507, %2502
  %2509 = zext i32 %2508 to i64
  store i64 %2509, i64* %RCX, align 8, !tbaa !2428
  %2510 = icmp ult i32 %2508, %2502
  %2511 = icmp ult i32 %2508, %2507
  %2512 = or i1 %2510, %2511
  %2513 = zext i1 %2512 to i8
  store i8 %2513, i8* %50, align 1, !tbaa !2432
  %2514 = and i32 %2508, 255
  %2515 = tail call i32 @llvm.ctpop.i32(i32 %2514) #14
  %2516 = trunc i32 %2515 to i8
  %2517 = and i8 %2516, 1
  %2518 = xor i8 %2517, 1
  store i8 %2518, i8* %51, align 1, !tbaa !2446
  %2519 = xor i32 %2507, %2502
  %2520 = xor i32 %2519, %2508
  %2521 = lshr i32 %2520, 4
  %2522 = trunc i32 %2521 to i8
  %2523 = and i8 %2522, 1
  store i8 %2523, i8* %52, align 1, !tbaa !2447
  %2524 = icmp eq i32 %2508, 0
  %2525 = zext i1 %2524 to i8
  store i8 %2525, i8* %53, align 1, !tbaa !2448
  %2526 = lshr i32 %2508, 31
  %2527 = trunc i32 %2526 to i8
  store i8 %2527, i8* %54, align 1, !tbaa !2449
  %2528 = lshr i32 %2502, 31
  %2529 = lshr i32 %2507, 31
  %2530 = xor i32 %2526, %2528
  %2531 = xor i32 %2526, %2529
  %2532 = add nuw nsw i32 %2530, %2531
  %2533 = icmp eq i32 %2532, 2
  %2534 = zext i1 %2533 to i8
  store i8 %2534, i8* %55, align 1, !tbaa !2450
  %2535 = add i64 %2499, 9
  store i64 %2535, i64* %PC, align 8
  store i32 %2508, i32* %2506, align 4
  %2536 = load i64, i64* %RBP, align 8
  %2537 = add i64 %2536, -52
  %2538 = load i64, i64* %PC, align 8
  %2539 = add i64 %2538, 3
  store i64 %2539, i64* %PC, align 8
  %2540 = inttoptr i64 %2537 to i32*
  %2541 = load i32, i32* %2540, align 4
  %2542 = shl i32 %2541, 1
  %2543 = icmp slt i32 %2541, 0
  %2544 = icmp slt i32 %2542, 0
  %2545 = xor i1 %2543, %2544
  %2546 = zext i32 %2542 to i64
  store i64 %2546, i64* %RCX, align 8, !tbaa !2428
  %.lobit16 = lshr i32 %2541, 31
  %2547 = trunc i32 %.lobit16 to i8
  store i8 %2547, i8* %50, align 1, !tbaa !2453
  %2548 = and i32 %2542, 254
  %2549 = tail call i32 @llvm.ctpop.i32(i32 %2548) #14
  %2550 = trunc i32 %2549 to i8
  %2551 = and i8 %2550, 1
  %2552 = xor i8 %2551, 1
  store i8 %2552, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2553 = icmp eq i32 %2542, 0
  %2554 = zext i1 %2553 to i8
  store i8 %2554, i8* %53, align 1, !tbaa !2453
  %2555 = lshr i32 %2541, 30
  %2556 = trunc i32 %2555 to i8
  %2557 = and i8 %2556, 1
  store i8 %2557, i8* %54, align 1, !tbaa !2453
  %2558 = zext i1 %2545 to i8
  store i8 %2558, i8* %55, align 1, !tbaa !2453
  %2559 = add i64 %2536, -40
  %2560 = add i64 %2538, 9
  store i64 %2560, i64* %PC, align 8
  %2561 = inttoptr i64 %2559 to i32*
  %2562 = load i32, i32* %2561, align 4
  %2563 = add i32 %2562, %2542
  %2564 = zext i32 %2563 to i64
  store i64 %2564, i64* %RCX, align 8, !tbaa !2428
  %2565 = icmp ult i32 %2563, %2542
  %2566 = icmp ult i32 %2563, %2562
  %2567 = or i1 %2565, %2566
  %2568 = zext i1 %2567 to i8
  store i8 %2568, i8* %50, align 1, !tbaa !2432
  %2569 = and i32 %2563, 255
  %2570 = tail call i32 @llvm.ctpop.i32(i32 %2569) #14
  %2571 = trunc i32 %2570 to i8
  %2572 = and i8 %2571, 1
  %2573 = xor i8 %2572, 1
  store i8 %2573, i8* %51, align 1, !tbaa !2446
  %2574 = xor i32 %2562, %2542
  %2575 = xor i32 %2574, %2563
  %2576 = lshr i32 %2575, 4
  %2577 = trunc i32 %2576 to i8
  %2578 = and i8 %2577, 1
  store i8 %2578, i8* %52, align 1, !tbaa !2447
  %2579 = icmp eq i32 %2563, 0
  %2580 = zext i1 %2579 to i8
  store i8 %2580, i8* %53, align 1, !tbaa !2448
  %2581 = lshr i32 %2563, 31
  %2582 = trunc i32 %2581 to i8
  store i8 %2582, i8* %54, align 1, !tbaa !2449
  %2583 = lshr i32 %2541, 30
  %2584 = and i32 %2583, 1
  %2585 = lshr i32 %2562, 31
  %2586 = xor i32 %2581, %2584
  %2587 = xor i32 %2581, %2585
  %2588 = add nuw nsw i32 %2586, %2587
  %2589 = icmp eq i32 %2588, 2
  %2590 = zext i1 %2589 to i8
  store i8 %2590, i8* %55, align 1, !tbaa !2450
  %2591 = add i64 %2538, 12
  store i64 %2591, i64* %PC, align 8
  store i32 %2563, i32* %2561, align 4
  %2592 = load i64, i64* %RBP, align 8
  %2593 = add i64 %2592, -24
  %2594 = load i64, i64* %PC, align 8
  %2595 = add i64 %2594, 4
  store i64 %2595, i64* %PC, align 8
  %2596 = inttoptr i64 %2593 to i64*
  %2597 = load i64, i64* %2596, align 8
  store i64 %2597, i64* %RDX, align 8, !tbaa !2428
  %2598 = add i64 %2592, -32
  %2599 = add i64 %2594, 8
  store i64 %2599, i64* %PC, align 8
  %2600 = inttoptr i64 %2598 to i32*
  %2601 = load i32, i32* %2600, align 4
  %2602 = sext i32 %2601 to i64
  store i64 %2602, i64* %RSI, align 8, !tbaa !2428
  %2603 = shl nsw i64 %2602, 3
  %2604 = add i64 %2603, %2597
  %2605 = add i64 %2594, 13
  store i64 %2605, i64* %PC, align 8
  %2606 = inttoptr i64 %2604 to i64*
  %2607 = load i64, i64* %2606, align 8
  store i64 %2607, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %2608 = add i64 %2592, -64
  %2609 = add i64 %2594, 18
  store i64 %2609, i64* %PC, align 8
  %2610 = inttoptr i64 %2608 to i64*
  store i64 %2607, i64* %2610, align 8
  %2611 = load i64, i64* %RBP, align 8
  %2612 = add i64 %2611, -24
  %2613 = load i64, i64* %PC, align 8
  %2614 = add i64 %2613, 4
  store i64 %2614, i64* %PC, align 8
  %2615 = inttoptr i64 %2612 to i64*
  %2616 = load i64, i64* %2615, align 8
  store i64 %2616, i64* %RDX, align 8, !tbaa !2428
  %2617 = add i64 %2611, -32
  %2618 = add i64 %2613, 7
  store i64 %2618, i64* %PC, align 8
  %2619 = inttoptr i64 %2617 to i32*
  %2620 = load i32, i32* %2619, align 4
  %2621 = add i32 %2620, 1
  %2622 = zext i32 %2621 to i64
  store i64 %2622, i64* %RCX, align 8, !tbaa !2428
  %2623 = icmp eq i32 %2620, -1
  %2624 = icmp eq i32 %2621, 0
  %2625 = or i1 %2623, %2624
  %2626 = zext i1 %2625 to i8
  store i8 %2626, i8* %50, align 1, !tbaa !2432
  %2627 = and i32 %2621, 255
  %2628 = tail call i32 @llvm.ctpop.i32(i32 %2627) #14
  %2629 = trunc i32 %2628 to i8
  %2630 = and i8 %2629, 1
  %2631 = xor i8 %2630, 1
  store i8 %2631, i8* %51, align 1, !tbaa !2446
  %2632 = xor i32 %2621, %2620
  %2633 = lshr i32 %2632, 4
  %2634 = trunc i32 %2633 to i8
  %2635 = and i8 %2634, 1
  store i8 %2635, i8* %52, align 1, !tbaa !2447
  %2636 = zext i1 %2624 to i8
  store i8 %2636, i8* %53, align 1, !tbaa !2448
  %2637 = lshr i32 %2621, 31
  %2638 = trunc i32 %2637 to i8
  store i8 %2638, i8* %54, align 1, !tbaa !2449
  %2639 = lshr i32 %2620, 31
  %2640 = xor i32 %2637, %2639
  %2641 = add nuw nsw i32 %2640, %2637
  %2642 = icmp eq i32 %2641, 2
  %2643 = zext i1 %2642 to i8
  store i8 %2643, i8* %55, align 1, !tbaa !2450
  %2644 = sext i32 %2621 to i64
  store i64 %2644, i64* %RSI, align 8, !tbaa !2428
  %2645 = shl nsw i64 %2644, 3
  %2646 = add i64 %2616, %2645
  %2647 = add i64 %2613, 18
  store i64 %2647, i64* %PC, align 8
  %2648 = inttoptr i64 %2646 to i64*
  %2649 = load i64, i64* %2648, align 8
  %2650 = load i64, i64* %RAX, align 8
  %2651 = xor i64 %2650, %2649
  store i64 %2651, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %2652 = trunc i64 %2651 to i32
  %2653 = and i32 %2652, 255
  %2654 = tail call i32 @llvm.ctpop.i32(i32 %2653) #14
  %2655 = trunc i32 %2654 to i8
  %2656 = and i8 %2655, 1
  %2657 = xor i8 %2656, 1
  store i8 %2657, i8* %51, align 1, !tbaa !2446
  %2658 = icmp eq i64 %2651, 0
  %2659 = zext i1 %2658 to i8
  store i8 %2659, i8* %53, align 1, !tbaa !2448
  %2660 = lshr i64 %2651, 63
  %2661 = trunc i64 %2660 to i8
  store i8 %2661, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %2651, i64* %1808, align 1, !tbaa !2428
  store i64 0, i64* %1809, align 1, !tbaa !2428
  %2662 = add i64 %2611, -72
  %2663 = add i64 %2613, 36
  store i64 %2663, i64* %PC, align 8
  %2664 = inttoptr i64 %2662 to i64*
  store i64 %2651, i64* %2664, align 8
  %2665 = load i64, i64* %RBP, align 8
  %2666 = add i64 %2665, -24
  %2667 = load i64, i64* %PC, align 8
  %2668 = add i64 %2667, 4
  store i64 %2668, i64* %PC, align 8
  %2669 = inttoptr i64 %2666 to i64*
  %2670 = load i64, i64* %2669, align 8
  store i64 %2670, i64* %RDX, align 8, !tbaa !2428
  %2671 = add i64 %2665, -40
  %2672 = add i64 %2667, 8
  store i64 %2672, i64* %PC, align 8
  %2673 = inttoptr i64 %2671 to i32*
  %2674 = load i32, i32* %2673, align 4
  %2675 = sext i32 %2674 to i64
  store i64 %2675, i64* %RSI, align 8, !tbaa !2428
  %2676 = shl nsw i64 %2675, 3
  %2677 = add i64 %2676, %2670
  %2678 = add i64 %2667, 13
  store i64 %2678, i64* %PC, align 8
  %2679 = inttoptr i64 %2677 to i64*
  %2680 = load i64, i64* %2679, align 8
  store i64 %2680, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %2681 = add i64 %2665, -80
  %2682 = add i64 %2667, 18
  store i64 %2682, i64* %PC, align 8
  %2683 = inttoptr i64 %2681 to i64*
  store i64 %2680, i64* %2683, align 8
  %2684 = load i64, i64* %RBP, align 8
  %2685 = add i64 %2684, -24
  %2686 = load i64, i64* %PC, align 8
  %2687 = add i64 %2686, 4
  store i64 %2687, i64* %PC, align 8
  %2688 = inttoptr i64 %2685 to i64*
  %2689 = load i64, i64* %2688, align 8
  store i64 %2689, i64* %RDX, align 8, !tbaa !2428
  %2690 = add i64 %2684, -40
  %2691 = add i64 %2686, 7
  store i64 %2691, i64* %PC, align 8
  %2692 = inttoptr i64 %2690 to i32*
  %2693 = load i32, i32* %2692, align 4
  %2694 = add i32 %2693, 1
  %2695 = zext i32 %2694 to i64
  store i64 %2695, i64* %RCX, align 8, !tbaa !2428
  %2696 = icmp eq i32 %2693, -1
  %2697 = icmp eq i32 %2694, 0
  %2698 = or i1 %2696, %2697
  %2699 = zext i1 %2698 to i8
  store i8 %2699, i8* %50, align 1, !tbaa !2432
  %2700 = and i32 %2694, 255
  %2701 = tail call i32 @llvm.ctpop.i32(i32 %2700) #14
  %2702 = trunc i32 %2701 to i8
  %2703 = and i8 %2702, 1
  %2704 = xor i8 %2703, 1
  store i8 %2704, i8* %51, align 1, !tbaa !2446
  %2705 = xor i32 %2694, %2693
  %2706 = lshr i32 %2705, 4
  %2707 = trunc i32 %2706 to i8
  %2708 = and i8 %2707, 1
  store i8 %2708, i8* %52, align 1, !tbaa !2447
  %2709 = zext i1 %2697 to i8
  store i8 %2709, i8* %53, align 1, !tbaa !2448
  %2710 = lshr i32 %2694, 31
  %2711 = trunc i32 %2710 to i8
  store i8 %2711, i8* %54, align 1, !tbaa !2449
  %2712 = lshr i32 %2693, 31
  %2713 = xor i32 %2710, %2712
  %2714 = add nuw nsw i32 %2713, %2710
  %2715 = icmp eq i32 %2714, 2
  %2716 = zext i1 %2715 to i8
  store i8 %2716, i8* %55, align 1, !tbaa !2450
  %2717 = sext i32 %2694 to i64
  store i64 %2717, i64* %RSI, align 8, !tbaa !2428
  %2718 = shl nsw i64 %2717, 3
  %2719 = add i64 %2689, %2718
  %2720 = add i64 %2686, 18
  store i64 %2720, i64* %PC, align 8
  %2721 = inttoptr i64 %2719 to i64*
  %2722 = load i64, i64* %2721, align 8
  %2723 = load i64, i64* %RAX, align 8
  %2724 = xor i64 %2723, %2722
  store i64 %2724, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %2725 = trunc i64 %2724 to i32
  %2726 = and i32 %2725, 255
  %2727 = tail call i32 @llvm.ctpop.i32(i32 %2726) #14
  %2728 = trunc i32 %2727 to i8
  %2729 = and i8 %2728, 1
  %2730 = xor i8 %2729, 1
  store i8 %2730, i8* %51, align 1, !tbaa !2446
  %2731 = icmp eq i64 %2724, 0
  %2732 = zext i1 %2731 to i8
  store i8 %2732, i8* %53, align 1, !tbaa !2448
  %2733 = lshr i64 %2724, 63
  %2734 = trunc i64 %2733 to i8
  store i8 %2734, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %2724, i64* %1808, align 1, !tbaa !2428
  store i64 0, i64* %1809, align 1, !tbaa !2428
  %2735 = add i64 %2684, -88
  %2736 = add i64 %2686, 36
  store i64 %2736, i64* %PC, align 8
  %2737 = inttoptr i64 %2735 to i64*
  store i64 %2724, i64* %2737, align 8
  %2738 = load i64, i64* %RBP, align 8
  %2739 = add i64 %2738, -80
  %2740 = load i64, i64* %PC, align 8
  %2741 = add i64 %2740, 5
  store i64 %2741, i64* %PC, align 8
  %2742 = inttoptr i64 %2739 to i64*
  %2743 = load i64, i64* %2742, align 8
  store i64 %2743, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %2744 = add i64 %2738, -24
  %2745 = add i64 %2740, 9
  store i64 %2745, i64* %PC, align 8
  %2746 = inttoptr i64 %2744 to i64*
  %2747 = load i64, i64* %2746, align 8
  store i64 %2747, i64* %RDX, align 8, !tbaa !2428
  %2748 = add i64 %2738, -32
  %2749 = add i64 %2740, 13
  store i64 %2749, i64* %PC, align 8
  %2750 = inttoptr i64 %2748 to i32*
  %2751 = load i32, i32* %2750, align 4
  %2752 = sext i32 %2751 to i64
  store i64 %2752, i64* %RSI, align 8, !tbaa !2428
  %2753 = shl nsw i64 %2752, 3
  %2754 = add i64 %2753, %2747
  %2755 = add i64 %2740, 18
  store i64 %2755, i64* %PC, align 8
  %2756 = inttoptr i64 %2754 to i64*
  store i64 %2743, i64* %2756, align 8
  %2757 = load i64, i64* %RBP, align 8
  %2758 = add i64 %2757, -88
  %2759 = load i64, i64* %PC, align 8
  %2760 = add i64 %2759, 5
  store i64 %2760, i64* %PC, align 8
  %2761 = inttoptr i64 %2758 to i64*
  %2762 = load i64, i64* %2761, align 8
  store i64 %2762, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %2763 = add i64 %2757, -24
  %2764 = add i64 %2759, 9
  store i64 %2764, i64* %PC, align 8
  %2765 = inttoptr i64 %2763 to i64*
  %2766 = load i64, i64* %2765, align 8
  store i64 %2766, i64* %RDX, align 8, !tbaa !2428
  %2767 = add i64 %2757, -32
  %2768 = add i64 %2759, 12
  store i64 %2768, i64* %PC, align 8
  %2769 = inttoptr i64 %2767 to i32*
  %2770 = load i32, i32* %2769, align 4
  %2771 = add i32 %2770, 1
  %2772 = zext i32 %2771 to i64
  store i64 %2772, i64* %RCX, align 8, !tbaa !2428
  %2773 = icmp eq i32 %2770, -1
  %2774 = icmp eq i32 %2771, 0
  %2775 = or i1 %2773, %2774
  %2776 = zext i1 %2775 to i8
  store i8 %2776, i8* %50, align 1, !tbaa !2432
  %2777 = and i32 %2771, 255
  %2778 = tail call i32 @llvm.ctpop.i32(i32 %2777) #14
  %2779 = trunc i32 %2778 to i8
  %2780 = and i8 %2779, 1
  %2781 = xor i8 %2780, 1
  store i8 %2781, i8* %51, align 1, !tbaa !2446
  %2782 = xor i32 %2771, %2770
  %2783 = lshr i32 %2782, 4
  %2784 = trunc i32 %2783 to i8
  %2785 = and i8 %2784, 1
  store i8 %2785, i8* %52, align 1, !tbaa !2447
  %2786 = zext i1 %2774 to i8
  store i8 %2786, i8* %53, align 1, !tbaa !2448
  %2787 = lshr i32 %2771, 31
  %2788 = trunc i32 %2787 to i8
  store i8 %2788, i8* %54, align 1, !tbaa !2449
  %2789 = lshr i32 %2770, 31
  %2790 = xor i32 %2787, %2789
  %2791 = add nuw nsw i32 %2790, %2787
  %2792 = icmp eq i32 %2791, 2
  %2793 = zext i1 %2792 to i8
  store i8 %2793, i8* %55, align 1, !tbaa !2450
  %2794 = sext i32 %2771 to i64
  store i64 %2794, i64* %RSI, align 8, !tbaa !2428
  %2795 = shl nsw i64 %2794, 3
  %2796 = add i64 %2766, %2795
  %2797 = add i64 %2759, 23
  store i64 %2797, i64* %PC, align 8
  %2798 = inttoptr i64 %2796 to i64*
  store i64 %2762, i64* %2798, align 8
  %2799 = load i64, i64* %RBP, align 8
  %2800 = add i64 %2799, -64
  %2801 = load i64, i64* %PC, align 8
  %2802 = add i64 %2801, 5
  store i64 %2802, i64* %PC, align 8
  %2803 = inttoptr i64 %2800 to i64*
  %2804 = load i64, i64* %2803, align 8
  store i64 %2804, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %2805 = add i64 %2799, -24
  %2806 = add i64 %2801, 9
  store i64 %2806, i64* %PC, align 8
  %2807 = inttoptr i64 %2805 to i64*
  %2808 = load i64, i64* %2807, align 8
  store i64 %2808, i64* %RDX, align 8, !tbaa !2428
  %2809 = add i64 %2799, -40
  %2810 = add i64 %2801, 13
  store i64 %2810, i64* %PC, align 8
  %2811 = inttoptr i64 %2809 to i32*
  %2812 = load i32, i32* %2811, align 4
  %2813 = sext i32 %2812 to i64
  store i64 %2813, i64* %RSI, align 8, !tbaa !2428
  %2814 = shl nsw i64 %2813, 3
  %2815 = add i64 %2814, %2808
  %2816 = add i64 %2801, 18
  store i64 %2816, i64* %PC, align 8
  %2817 = inttoptr i64 %2815 to i64*
  store i64 %2804, i64* %2817, align 8
  %2818 = load i64, i64* %RBP, align 8
  %2819 = add i64 %2818, -72
  %2820 = load i64, i64* %PC, align 8
  %2821 = add i64 %2820, 5
  store i64 %2821, i64* %PC, align 8
  %2822 = inttoptr i64 %2819 to i64*
  %2823 = load i64, i64* %2822, align 8
  store i64 %2823, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %2824 = add i64 %2818, -24
  %2825 = add i64 %2820, 9
  store i64 %2825, i64* %PC, align 8
  %2826 = inttoptr i64 %2824 to i64*
  %2827 = load i64, i64* %2826, align 8
  store i64 %2827, i64* %RDX, align 8, !tbaa !2428
  %2828 = add i64 %2818, -40
  %2829 = add i64 %2820, 12
  store i64 %2829, i64* %PC, align 8
  %2830 = inttoptr i64 %2828 to i32*
  %2831 = load i32, i32* %2830, align 4
  %2832 = add i32 %2831, 1
  %2833 = zext i32 %2832 to i64
  store i64 %2833, i64* %RCX, align 8, !tbaa !2428
  %2834 = icmp eq i32 %2831, -1
  %2835 = icmp eq i32 %2832, 0
  %2836 = or i1 %2834, %2835
  %2837 = zext i1 %2836 to i8
  store i8 %2837, i8* %50, align 1, !tbaa !2432
  %2838 = and i32 %2832, 255
  %2839 = tail call i32 @llvm.ctpop.i32(i32 %2838) #14
  %2840 = trunc i32 %2839 to i8
  %2841 = and i8 %2840, 1
  %2842 = xor i8 %2841, 1
  store i8 %2842, i8* %51, align 1, !tbaa !2446
  %2843 = xor i32 %2832, %2831
  %2844 = lshr i32 %2843, 4
  %2845 = trunc i32 %2844 to i8
  %2846 = and i8 %2845, 1
  store i8 %2846, i8* %52, align 1, !tbaa !2447
  %2847 = zext i1 %2835 to i8
  store i8 %2847, i8* %53, align 1, !tbaa !2448
  %2848 = lshr i32 %2832, 31
  %2849 = trunc i32 %2848 to i8
  store i8 %2849, i8* %54, align 1, !tbaa !2449
  %2850 = lshr i32 %2831, 31
  %2851 = xor i32 %2848, %2850
  %2852 = add nuw nsw i32 %2851, %2848
  %2853 = icmp eq i32 %2852, 2
  %2854 = zext i1 %2853 to i8
  store i8 %2854, i8* %55, align 1, !tbaa !2450
  %2855 = sext i32 %2832 to i64
  store i64 %2855, i64* %RSI, align 8, !tbaa !2428
  %2856 = shl nsw i64 %2855, 3
  %2857 = add i64 %2827, %2856
  %2858 = add i64 %2820, 23
  store i64 %2858, i64* %PC, align 8
  %2859 = inttoptr i64 %2857 to i64*
  store i64 %2823, i64* %2859, align 8
  %2860 = load i64, i64* %RBP, align 8
  %2861 = add i64 %2860, -52
  %2862 = load i64, i64* %PC, align 8
  %2863 = add i64 %2862, 3
  store i64 %2863, i64* %PC, align 8
  %2864 = inttoptr i64 %2861 to i32*
  %2865 = load i32, i32* %2864, align 4
  %2866 = zext i32 %2865 to i64
  store i64 %2866, i64* %RCX, align 8, !tbaa !2428
  %2867 = add i64 %2860, -32
  %2868 = add i64 %2862, 6
  store i64 %2868, i64* %PC, align 8
  %2869 = inttoptr i64 %2867 to i32*
  %2870 = load i32, i32* %2869, align 4
  %2871 = add i32 %2870, %2865
  %2872 = zext i32 %2871 to i64
  store i64 %2872, i64* %RCX, align 8, !tbaa !2428
  %2873 = icmp ult i32 %2871, %2865
  %2874 = icmp ult i32 %2871, %2870
  %2875 = or i1 %2873, %2874
  %2876 = zext i1 %2875 to i8
  store i8 %2876, i8* %50, align 1, !tbaa !2432
  %2877 = and i32 %2871, 255
  %2878 = tail call i32 @llvm.ctpop.i32(i32 %2877) #14
  %2879 = trunc i32 %2878 to i8
  %2880 = and i8 %2879, 1
  %2881 = xor i8 %2880, 1
  store i8 %2881, i8* %51, align 1, !tbaa !2446
  %2882 = xor i32 %2870, %2865
  %2883 = xor i32 %2882, %2871
  %2884 = lshr i32 %2883, 4
  %2885 = trunc i32 %2884 to i8
  %2886 = and i8 %2885, 1
  store i8 %2886, i8* %52, align 1, !tbaa !2447
  %2887 = icmp eq i32 %2871, 0
  %2888 = zext i1 %2887 to i8
  store i8 %2888, i8* %53, align 1, !tbaa !2448
  %2889 = lshr i32 %2871, 31
  %2890 = trunc i32 %2889 to i8
  store i8 %2890, i8* %54, align 1, !tbaa !2449
  %2891 = lshr i32 %2865, 31
  %2892 = lshr i32 %2870, 31
  %2893 = xor i32 %2889, %2891
  %2894 = xor i32 %2889, %2892
  %2895 = add nuw nsw i32 %2893, %2894
  %2896 = icmp eq i32 %2895, 2
  %2897 = zext i1 %2896 to i8
  store i8 %2897, i8* %55, align 1, !tbaa !2450
  %2898 = add i64 %2862, 9
  store i64 %2898, i64* %PC, align 8
  store i32 %2871, i32* %2869, align 4
  %2899 = load i64, i64* %RBP, align 8
  %2900 = add i64 %2899, -52
  %2901 = load i64, i64* %PC, align 8
  %2902 = add i64 %2901, 3
  store i64 %2902, i64* %PC, align 8
  %2903 = inttoptr i64 %2900 to i32*
  %2904 = load i32, i32* %2903, align 4
  %2905 = zext i32 %2904 to i64
  store i64 %2905, i64* %RCX, align 8, !tbaa !2428
  %2906 = add i64 %2899, -40
  %2907 = add i64 %2901, 6
  store i64 %2907, i64* %PC, align 8
  %2908 = inttoptr i64 %2906 to i32*
  %2909 = load i32, i32* %2908, align 4
  %2910 = sub i32 %2909, %2904
  %2911 = zext i32 %2910 to i64
  store i64 %2911, i64* %RDI, align 8, !tbaa !2428
  %2912 = icmp ult i32 %2909, %2904
  %2913 = zext i1 %2912 to i8
  store i8 %2913, i8* %50, align 1, !tbaa !2432
  %2914 = and i32 %2910, 255
  %2915 = tail call i32 @llvm.ctpop.i32(i32 %2914) #14
  %2916 = trunc i32 %2915 to i8
  %2917 = and i8 %2916, 1
  %2918 = xor i8 %2917, 1
  store i8 %2918, i8* %51, align 1, !tbaa !2446
  %2919 = xor i32 %2904, %2909
  %2920 = xor i32 %2919, %2910
  %2921 = lshr i32 %2920, 4
  %2922 = trunc i32 %2921 to i8
  %2923 = and i8 %2922, 1
  store i8 %2923, i8* %52, align 1, !tbaa !2447
  %2924 = icmp eq i32 %2910, 0
  %2925 = zext i1 %2924 to i8
  store i8 %2925, i8* %53, align 1, !tbaa !2448
  %2926 = lshr i32 %2910, 31
  %2927 = trunc i32 %2926 to i8
  store i8 %2927, i8* %54, align 1, !tbaa !2449
  %2928 = lshr i32 %2909, 31
  %2929 = lshr i32 %2904, 31
  %2930 = xor i32 %2929, %2928
  %2931 = xor i32 %2926, %2928
  %2932 = add nuw nsw i32 %2931, %2930
  %2933 = icmp eq i32 %2932, 2
  %2934 = zext i1 %2933 to i8
  store i8 %2934, i8* %55, align 1, !tbaa !2450
  %2935 = add i64 %2901, 11
  store i64 %2935, i64* %PC, align 8
  store i32 %2910, i32* %2908, align 4
  %2936 = load i64, i64* %RBP, align 8
  %2937 = add i64 %2936, -24
  %2938 = load i64, i64* %PC, align 8
  %2939 = add i64 %2938, 4
  store i64 %2939, i64* %PC, align 8
  %2940 = inttoptr i64 %2937 to i64*
  %2941 = load i64, i64* %2940, align 8
  store i64 %2941, i64* %RDX, align 8, !tbaa !2428
  %2942 = add i64 %2936, -32
  %2943 = add i64 %2938, 8
  store i64 %2943, i64* %PC, align 8
  %2944 = inttoptr i64 %2942 to i32*
  %2945 = load i32, i32* %2944, align 4
  %2946 = sext i32 %2945 to i64
  store i64 %2946, i64* %RSI, align 8, !tbaa !2428
  %2947 = shl nsw i64 %2946, 3
  %2948 = add i64 %2947, %2941
  %2949 = add i64 %2938, 13
  store i64 %2949, i64* %PC, align 8
  %2950 = inttoptr i64 %2948 to i64*
  %2951 = load i64, i64* %2950, align 8
  store i64 %2951, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %2952 = add i64 %2936, -64
  %2953 = add i64 %2938, 18
  store i64 %2953, i64* %PC, align 8
  %2954 = inttoptr i64 %2952 to i64*
  store i64 %2951, i64* %2954, align 8
  %2955 = load i64, i64* %RBP, align 8
  %2956 = add i64 %2955, -24
  %2957 = load i64, i64* %PC, align 8
  %2958 = add i64 %2957, 4
  store i64 %2958, i64* %PC, align 8
  %2959 = inttoptr i64 %2956 to i64*
  %2960 = load i64, i64* %2959, align 8
  store i64 %2960, i64* %RDX, align 8, !tbaa !2428
  %2961 = add i64 %2955, -32
  %2962 = add i64 %2957, 7
  store i64 %2962, i64* %PC, align 8
  %2963 = inttoptr i64 %2961 to i32*
  %2964 = load i32, i32* %2963, align 4
  %2965 = add i32 %2964, 1
  %2966 = zext i32 %2965 to i64
  store i64 %2966, i64* %RCX, align 8, !tbaa !2428
  %2967 = icmp eq i32 %2964, -1
  %2968 = icmp eq i32 %2965, 0
  %2969 = or i1 %2967, %2968
  %2970 = zext i1 %2969 to i8
  store i8 %2970, i8* %50, align 1, !tbaa !2432
  %2971 = and i32 %2965, 255
  %2972 = tail call i32 @llvm.ctpop.i32(i32 %2971) #14
  %2973 = trunc i32 %2972 to i8
  %2974 = and i8 %2973, 1
  %2975 = xor i8 %2974, 1
  store i8 %2975, i8* %51, align 1, !tbaa !2446
  %2976 = xor i32 %2965, %2964
  %2977 = lshr i32 %2976, 4
  %2978 = trunc i32 %2977 to i8
  %2979 = and i8 %2978, 1
  store i8 %2979, i8* %52, align 1, !tbaa !2447
  %2980 = zext i1 %2968 to i8
  store i8 %2980, i8* %53, align 1, !tbaa !2448
  %2981 = lshr i32 %2965, 31
  %2982 = trunc i32 %2981 to i8
  store i8 %2982, i8* %54, align 1, !tbaa !2449
  %2983 = lshr i32 %2964, 31
  %2984 = xor i32 %2981, %2983
  %2985 = add nuw nsw i32 %2984, %2981
  %2986 = icmp eq i32 %2985, 2
  %2987 = zext i1 %2986 to i8
  store i8 %2987, i8* %55, align 1, !tbaa !2450
  %2988 = sext i32 %2965 to i64
  store i64 %2988, i64* %RSI, align 8, !tbaa !2428
  %2989 = shl nsw i64 %2988, 3
  %2990 = add i64 %2960, %2989
  %2991 = add i64 %2957, 18
  store i64 %2991, i64* %PC, align 8
  %2992 = inttoptr i64 %2990 to i64*
  %2993 = load i64, i64* %2992, align 8
  %2994 = load i64, i64* %RAX, align 8
  %2995 = xor i64 %2994, %2993
  store i64 %2995, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %2996 = trunc i64 %2995 to i32
  %2997 = and i32 %2996, 255
  %2998 = tail call i32 @llvm.ctpop.i32(i32 %2997) #14
  %2999 = trunc i32 %2998 to i8
  %3000 = and i8 %2999, 1
  %3001 = xor i8 %3000, 1
  store i8 %3001, i8* %51, align 1, !tbaa !2446
  %3002 = icmp eq i64 %2995, 0
  %3003 = zext i1 %3002 to i8
  store i8 %3003, i8* %53, align 1, !tbaa !2448
  %3004 = lshr i64 %2995, 63
  %3005 = trunc i64 %3004 to i8
  store i8 %3005, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %2995, i64* %1808, align 1, !tbaa !2428
  store i64 0, i64* %1809, align 1, !tbaa !2428
  %3006 = add i64 %2955, -72
  %3007 = add i64 %2957, 36
  store i64 %3007, i64* %PC, align 8
  %3008 = inttoptr i64 %3006 to i64*
  store i64 %2995, i64* %3008, align 8
  %3009 = load i64, i64* %RBP, align 8
  %3010 = add i64 %3009, -24
  %3011 = load i64, i64* %PC, align 8
  %3012 = add i64 %3011, 4
  store i64 %3012, i64* %PC, align 8
  %3013 = inttoptr i64 %3010 to i64*
  %3014 = load i64, i64* %3013, align 8
  store i64 %3014, i64* %RDX, align 8, !tbaa !2428
  %3015 = add i64 %3009, -40
  %3016 = add i64 %3011, 8
  store i64 %3016, i64* %PC, align 8
  %3017 = inttoptr i64 %3015 to i32*
  %3018 = load i32, i32* %3017, align 4
  %3019 = sext i32 %3018 to i64
  store i64 %3019, i64* %RSI, align 8, !tbaa !2428
  %3020 = shl nsw i64 %3019, 3
  %3021 = add i64 %3020, %3014
  %3022 = add i64 %3011, 13
  store i64 %3022, i64* %PC, align 8
  %3023 = inttoptr i64 %3021 to i64*
  %3024 = load i64, i64* %3023, align 8
  store i64 %3024, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %3025 = add i64 %3009, -80
  %3026 = add i64 %3011, 18
  store i64 %3026, i64* %PC, align 8
  %3027 = inttoptr i64 %3025 to i64*
  store i64 %3024, i64* %3027, align 8
  %3028 = load i64, i64* %RBP, align 8
  %3029 = add i64 %3028, -24
  %3030 = load i64, i64* %PC, align 8
  %3031 = add i64 %3030, 4
  store i64 %3031, i64* %PC, align 8
  %3032 = inttoptr i64 %3029 to i64*
  %3033 = load i64, i64* %3032, align 8
  store i64 %3033, i64* %RDX, align 8, !tbaa !2428
  %3034 = add i64 %3028, -40
  %3035 = add i64 %3030, 7
  store i64 %3035, i64* %PC, align 8
  %3036 = inttoptr i64 %3034 to i32*
  %3037 = load i32, i32* %3036, align 4
  %3038 = add i32 %3037, 1
  %3039 = zext i32 %3038 to i64
  store i64 %3039, i64* %RCX, align 8, !tbaa !2428
  %3040 = icmp eq i32 %3037, -1
  %3041 = icmp eq i32 %3038, 0
  %3042 = or i1 %3040, %3041
  %3043 = zext i1 %3042 to i8
  store i8 %3043, i8* %50, align 1, !tbaa !2432
  %3044 = and i32 %3038, 255
  %3045 = tail call i32 @llvm.ctpop.i32(i32 %3044) #14
  %3046 = trunc i32 %3045 to i8
  %3047 = and i8 %3046, 1
  %3048 = xor i8 %3047, 1
  store i8 %3048, i8* %51, align 1, !tbaa !2446
  %3049 = xor i32 %3038, %3037
  %3050 = lshr i32 %3049, 4
  %3051 = trunc i32 %3050 to i8
  %3052 = and i8 %3051, 1
  store i8 %3052, i8* %52, align 1, !tbaa !2447
  %3053 = zext i1 %3041 to i8
  store i8 %3053, i8* %53, align 1, !tbaa !2448
  %3054 = lshr i32 %3038, 31
  %3055 = trunc i32 %3054 to i8
  store i8 %3055, i8* %54, align 1, !tbaa !2449
  %3056 = lshr i32 %3037, 31
  %3057 = xor i32 %3054, %3056
  %3058 = add nuw nsw i32 %3057, %3054
  %3059 = icmp eq i32 %3058, 2
  %3060 = zext i1 %3059 to i8
  store i8 %3060, i8* %55, align 1, !tbaa !2450
  %3061 = sext i32 %3038 to i64
  store i64 %3061, i64* %RSI, align 8, !tbaa !2428
  %3062 = shl nsw i64 %3061, 3
  %3063 = add i64 %3033, %3062
  %3064 = add i64 %3030, 18
  store i64 %3064, i64* %PC, align 8
  %3065 = inttoptr i64 %3063 to i64*
  %3066 = load i64, i64* %3065, align 8
  %3067 = load i64, i64* %RAX, align 8
  %3068 = xor i64 %3067, %3066
  store i64 %3068, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %3069 = trunc i64 %3068 to i32
  %3070 = and i32 %3069, 255
  %3071 = tail call i32 @llvm.ctpop.i32(i32 %3070) #14
  %3072 = trunc i32 %3071 to i8
  %3073 = and i8 %3072, 1
  %3074 = xor i8 %3073, 1
  store i8 %3074, i8* %51, align 1, !tbaa !2446
  %3075 = icmp eq i64 %3068, 0
  %3076 = zext i1 %3075 to i8
  store i8 %3076, i8* %53, align 1, !tbaa !2448
  %3077 = lshr i64 %3068, 63
  %3078 = trunc i64 %3077 to i8
  store i8 %3078, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %3068, i64* %1808, align 1, !tbaa !2428
  store i64 0, i64* %1809, align 1, !tbaa !2428
  %3079 = add i64 %3028, -88
  %3080 = add i64 %3030, 36
  store i64 %3080, i64* %PC, align 8
  %3081 = inttoptr i64 %3079 to i64*
  store i64 %3068, i64* %3081, align 8
  %3082 = load i64, i64* %RBP, align 8
  %3083 = add i64 %3082, -80
  %3084 = load i64, i64* %PC, align 8
  %3085 = add i64 %3084, 5
  store i64 %3085, i64* %PC, align 8
  %3086 = inttoptr i64 %3083 to i64*
  %3087 = load i64, i64* %3086, align 8
  store i64 %3087, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %3088 = add i64 %3082, -24
  %3089 = add i64 %3084, 9
  store i64 %3089, i64* %PC, align 8
  %3090 = inttoptr i64 %3088 to i64*
  %3091 = load i64, i64* %3090, align 8
  store i64 %3091, i64* %RDX, align 8, !tbaa !2428
  %3092 = add i64 %3082, -32
  %3093 = add i64 %3084, 13
  store i64 %3093, i64* %PC, align 8
  %3094 = inttoptr i64 %3092 to i32*
  %3095 = load i32, i32* %3094, align 4
  %3096 = sext i32 %3095 to i64
  store i64 %3096, i64* %RSI, align 8, !tbaa !2428
  %3097 = shl nsw i64 %3096, 3
  %3098 = add i64 %3097, %3091
  %3099 = add i64 %3084, 18
  store i64 %3099, i64* %PC, align 8
  %3100 = inttoptr i64 %3098 to i64*
  store i64 %3087, i64* %3100, align 8
  %3101 = load i64, i64* %RBP, align 8
  %3102 = add i64 %3101, -88
  %3103 = load i64, i64* %PC, align 8
  %3104 = add i64 %3103, 5
  store i64 %3104, i64* %PC, align 8
  %3105 = inttoptr i64 %3102 to i64*
  %3106 = load i64, i64* %3105, align 8
  store i64 %3106, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %3107 = add i64 %3101, -24
  %3108 = add i64 %3103, 9
  store i64 %3108, i64* %PC, align 8
  %3109 = inttoptr i64 %3107 to i64*
  %3110 = load i64, i64* %3109, align 8
  store i64 %3110, i64* %RDX, align 8, !tbaa !2428
  %3111 = add i64 %3101, -32
  %3112 = add i64 %3103, 12
  store i64 %3112, i64* %PC, align 8
  %3113 = inttoptr i64 %3111 to i32*
  %3114 = load i32, i32* %3113, align 4
  %3115 = add i32 %3114, 1
  %3116 = zext i32 %3115 to i64
  store i64 %3116, i64* %RCX, align 8, !tbaa !2428
  %3117 = icmp eq i32 %3114, -1
  %3118 = icmp eq i32 %3115, 0
  %3119 = or i1 %3117, %3118
  %3120 = zext i1 %3119 to i8
  store i8 %3120, i8* %50, align 1, !tbaa !2432
  %3121 = and i32 %3115, 255
  %3122 = tail call i32 @llvm.ctpop.i32(i32 %3121) #14
  %3123 = trunc i32 %3122 to i8
  %3124 = and i8 %3123, 1
  %3125 = xor i8 %3124, 1
  store i8 %3125, i8* %51, align 1, !tbaa !2446
  %3126 = xor i32 %3115, %3114
  %3127 = lshr i32 %3126, 4
  %3128 = trunc i32 %3127 to i8
  %3129 = and i8 %3128, 1
  store i8 %3129, i8* %52, align 1, !tbaa !2447
  %3130 = zext i1 %3118 to i8
  store i8 %3130, i8* %53, align 1, !tbaa !2448
  %3131 = lshr i32 %3115, 31
  %3132 = trunc i32 %3131 to i8
  store i8 %3132, i8* %54, align 1, !tbaa !2449
  %3133 = lshr i32 %3114, 31
  %3134 = xor i32 %3131, %3133
  %3135 = add nuw nsw i32 %3134, %3131
  %3136 = icmp eq i32 %3135, 2
  %3137 = zext i1 %3136 to i8
  store i8 %3137, i8* %55, align 1, !tbaa !2450
  %3138 = sext i32 %3115 to i64
  store i64 %3138, i64* %RSI, align 8, !tbaa !2428
  %3139 = shl nsw i64 %3138, 3
  %3140 = add i64 %3110, %3139
  %3141 = add i64 %3103, 23
  store i64 %3141, i64* %PC, align 8
  %3142 = inttoptr i64 %3140 to i64*
  store i64 %3106, i64* %3142, align 8
  %3143 = load i64, i64* %RBP, align 8
  %3144 = add i64 %3143, -64
  %3145 = load i64, i64* %PC, align 8
  %3146 = add i64 %3145, 5
  store i64 %3146, i64* %PC, align 8
  %3147 = inttoptr i64 %3144 to i64*
  %3148 = load i64, i64* %3147, align 8
  store i64 %3148, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %3149 = add i64 %3143, -24
  %3150 = add i64 %3145, 9
  store i64 %3150, i64* %PC, align 8
  %3151 = inttoptr i64 %3149 to i64*
  %3152 = load i64, i64* %3151, align 8
  store i64 %3152, i64* %RDX, align 8, !tbaa !2428
  %3153 = add i64 %3143, -40
  %3154 = add i64 %3145, 13
  store i64 %3154, i64* %PC, align 8
  %3155 = inttoptr i64 %3153 to i32*
  %3156 = load i32, i32* %3155, align 4
  %3157 = sext i32 %3156 to i64
  store i64 %3157, i64* %RSI, align 8, !tbaa !2428
  %3158 = shl nsw i64 %3157, 3
  %3159 = add i64 %3158, %3152
  %3160 = add i64 %3145, 18
  store i64 %3160, i64* %PC, align 8
  %3161 = inttoptr i64 %3159 to i64*
  store i64 %3148, i64* %3161, align 8
  %3162 = load i64, i64* %RBP, align 8
  %3163 = add i64 %3162, -72
  %3164 = load i64, i64* %PC, align 8
  %3165 = add i64 %3164, 5
  store i64 %3165, i64* %PC, align 8
  %3166 = inttoptr i64 %3163 to i64*
  %3167 = load i64, i64* %3166, align 8
  store i64 %3167, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %3168 = add i64 %3162, -24
  %3169 = add i64 %3164, 9
  store i64 %3169, i64* %PC, align 8
  %3170 = inttoptr i64 %3168 to i64*
  %3171 = load i64, i64* %3170, align 8
  store i64 %3171, i64* %RDX, align 8, !tbaa !2428
  %3172 = add i64 %3162, -40
  %3173 = add i64 %3164, 12
  store i64 %3173, i64* %PC, align 8
  %3174 = inttoptr i64 %3172 to i32*
  %3175 = load i32, i32* %3174, align 4
  %3176 = add i32 %3175, 1
  %3177 = zext i32 %3176 to i64
  store i64 %3177, i64* %RCX, align 8, !tbaa !2428
  %3178 = icmp eq i32 %3175, -1
  %3179 = icmp eq i32 %3176, 0
  %3180 = or i1 %3178, %3179
  %3181 = zext i1 %3180 to i8
  store i8 %3181, i8* %50, align 1, !tbaa !2432
  %3182 = and i32 %3176, 255
  %3183 = tail call i32 @llvm.ctpop.i32(i32 %3182) #14
  %3184 = trunc i32 %3183 to i8
  %3185 = and i8 %3184, 1
  %3186 = xor i8 %3185, 1
  store i8 %3186, i8* %51, align 1, !tbaa !2446
  %3187 = xor i32 %3176, %3175
  %3188 = lshr i32 %3187, 4
  %3189 = trunc i32 %3188 to i8
  %3190 = and i8 %3189, 1
  store i8 %3190, i8* %52, align 1, !tbaa !2447
  %3191 = zext i1 %3179 to i8
  store i8 %3191, i8* %53, align 1, !tbaa !2448
  %3192 = lshr i32 %3176, 31
  %3193 = trunc i32 %3192 to i8
  store i8 %3193, i8* %54, align 1, !tbaa !2449
  %3194 = lshr i32 %3175, 31
  %3195 = xor i32 %3192, %3194
  %3196 = add nuw nsw i32 %3195, %3192
  %3197 = icmp eq i32 %3196, 2
  %3198 = zext i1 %3197 to i8
  store i8 %3198, i8* %55, align 1, !tbaa !2450
  %3199 = sext i32 %3176 to i64
  store i64 %3199, i64* %RSI, align 8, !tbaa !2428
  %3200 = shl nsw i64 %3199, 3
  %3201 = add i64 %3171, %3200
  %3202 = add i64 %3164, 23
  store i64 %3202, i64* %PC, align 8
  %3203 = inttoptr i64 %3201 to i64*
  store i64 %3167, i64* %3203, align 8
  %3204 = load i64, i64* %RBP, align 8
  %3205 = add i64 %3204, -52
  %3206 = load i64, i64* %PC, align 8
  %3207 = add i64 %3206, 3
  store i64 %3207, i64* %PC, align 8
  %3208 = inttoptr i64 %3205 to i32*
  %3209 = load i32, i32* %3208, align 4
  %3210 = zext i32 %3209 to i64
  store i64 %3210, i64* %RCX, align 8, !tbaa !2428
  %3211 = add i64 %3204, -32
  %3212 = add i64 %3206, 6
  store i64 %3212, i64* %PC, align 8
  %3213 = inttoptr i64 %3211 to i32*
  %3214 = load i32, i32* %3213, align 4
  %3215 = add i32 %3214, %3209
  %3216 = zext i32 %3215 to i64
  store i64 %3216, i64* %RCX, align 8, !tbaa !2428
  %3217 = icmp ult i32 %3215, %3209
  %3218 = icmp ult i32 %3215, %3214
  %3219 = or i1 %3217, %3218
  %3220 = zext i1 %3219 to i8
  store i8 %3220, i8* %50, align 1, !tbaa !2432
  %3221 = and i32 %3215, 255
  %3222 = tail call i32 @llvm.ctpop.i32(i32 %3221) #14
  %3223 = trunc i32 %3222 to i8
  %3224 = and i8 %3223, 1
  %3225 = xor i8 %3224, 1
  store i8 %3225, i8* %51, align 1, !tbaa !2446
  %3226 = xor i32 %3214, %3209
  %3227 = xor i32 %3226, %3215
  %3228 = lshr i32 %3227, 4
  %3229 = trunc i32 %3228 to i8
  %3230 = and i8 %3229, 1
  store i8 %3230, i8* %52, align 1, !tbaa !2447
  %3231 = icmp eq i32 %3215, 0
  %3232 = zext i1 %3231 to i8
  store i8 %3232, i8* %53, align 1, !tbaa !2448
  %3233 = lshr i32 %3215, 31
  %3234 = trunc i32 %3233 to i8
  store i8 %3234, i8* %54, align 1, !tbaa !2449
  %3235 = lshr i32 %3209, 31
  %3236 = lshr i32 %3214, 31
  %3237 = xor i32 %3233, %3235
  %3238 = xor i32 %3233, %3236
  %3239 = add nuw nsw i32 %3237, %3238
  %3240 = icmp eq i32 %3239, 2
  %3241 = zext i1 %3240 to i8
  store i8 %3241, i8* %55, align 1, !tbaa !2450
  %3242 = add i64 %3206, 9
  store i64 %3242, i64* %PC, align 8
  store i32 %3215, i32* %3213, align 4
  %3243 = load i64, i64* %RBP, align 8
  %3244 = add i64 %3243, -52
  %3245 = load i64, i64* %PC, align 8
  %3246 = add i64 %3245, 3
  store i64 %3246, i64* %PC, align 8
  %3247 = inttoptr i64 %3244 to i32*
  %3248 = load i32, i32* %3247, align 4
  %3249 = shl i32 %3248, 1
  %3250 = icmp slt i32 %3248, 0
  %3251 = icmp slt i32 %3249, 0
  %3252 = xor i1 %3250, %3251
  %3253 = zext i32 %3249 to i64
  store i64 %3253, i64* %RCX, align 8, !tbaa !2428
  %.lobit17 = lshr i32 %3248, 31
  %3254 = trunc i32 %.lobit17 to i8
  store i8 %3254, i8* %50, align 1, !tbaa !2453
  %3255 = and i32 %3249, 254
  %3256 = tail call i32 @llvm.ctpop.i32(i32 %3255) #14
  %3257 = trunc i32 %3256 to i8
  %3258 = and i8 %3257, 1
  %3259 = xor i8 %3258, 1
  store i8 %3259, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %3260 = icmp eq i32 %3249, 0
  %3261 = zext i1 %3260 to i8
  store i8 %3261, i8* %53, align 1, !tbaa !2453
  %3262 = lshr i32 %3248, 30
  %3263 = trunc i32 %3262 to i8
  %3264 = and i8 %3263, 1
  store i8 %3264, i8* %54, align 1, !tbaa !2453
  %3265 = zext i1 %3252 to i8
  store i8 %3265, i8* %55, align 1, !tbaa !2453
  %3266 = add i64 %3243, -40
  %3267 = add i64 %3245, 9
  store i64 %3267, i64* %PC, align 8
  %3268 = inttoptr i64 %3266 to i32*
  %3269 = load i32, i32* %3268, align 4
  %3270 = add i32 %3269, %3249
  %3271 = zext i32 %3270 to i64
  store i64 %3271, i64* %RCX, align 8, !tbaa !2428
  %3272 = icmp ult i32 %3270, %3249
  %3273 = icmp ult i32 %3270, %3269
  %3274 = or i1 %3272, %3273
  %3275 = zext i1 %3274 to i8
  store i8 %3275, i8* %50, align 1, !tbaa !2432
  %3276 = and i32 %3270, 255
  %3277 = tail call i32 @llvm.ctpop.i32(i32 %3276) #14
  %3278 = trunc i32 %3277 to i8
  %3279 = and i8 %3278, 1
  %3280 = xor i8 %3279, 1
  store i8 %3280, i8* %51, align 1, !tbaa !2446
  %3281 = xor i32 %3269, %3249
  %3282 = xor i32 %3281, %3270
  %3283 = lshr i32 %3282, 4
  %3284 = trunc i32 %3283 to i8
  %3285 = and i8 %3284, 1
  store i8 %3285, i8* %52, align 1, !tbaa !2447
  %3286 = icmp eq i32 %3270, 0
  %3287 = zext i1 %3286 to i8
  store i8 %3287, i8* %53, align 1, !tbaa !2448
  %3288 = lshr i32 %3270, 31
  %3289 = trunc i32 %3288 to i8
  store i8 %3289, i8* %54, align 1, !tbaa !2449
  %3290 = lshr i32 %3248, 30
  %3291 = and i32 %3290, 1
  %3292 = lshr i32 %3269, 31
  %3293 = xor i32 %3288, %3291
  %3294 = xor i32 %3288, %3292
  %3295 = add nuw nsw i32 %3293, %3294
  %3296 = icmp eq i32 %3295, 2
  %3297 = zext i1 %3296 to i8
  store i8 %3297, i8* %55, align 1, !tbaa !2450
  %3298 = add i64 %3245, 12
  store i64 %3298, i64* %PC, align 8
  store i32 %3270, i32* %3268, align 4
  %3299 = load i64, i64* %RBP, align 8
  %3300 = add i64 %3299, -24
  %3301 = load i64, i64* %PC, align 8
  %3302 = add i64 %3301, 4
  store i64 %3302, i64* %PC, align 8
  %3303 = inttoptr i64 %3300 to i64*
  %3304 = load i64, i64* %3303, align 8
  store i64 %3304, i64* %RDX, align 8, !tbaa !2428
  %3305 = add i64 %3299, -32
  %3306 = add i64 %3301, 8
  store i64 %3306, i64* %PC, align 8
  %3307 = inttoptr i64 %3305 to i32*
  %3308 = load i32, i32* %3307, align 4
  %3309 = sext i32 %3308 to i64
  store i64 %3309, i64* %RSI, align 8, !tbaa !2428
  %3310 = shl nsw i64 %3309, 3
  %3311 = add i64 %3310, %3304
  %3312 = add i64 %3301, 13
  store i64 %3312, i64* %PC, align 8
  %3313 = inttoptr i64 %3311 to i64*
  %3314 = load i64, i64* %3313, align 8
  store i64 %3314, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %3315 = add i64 %3299, -64
  %3316 = add i64 %3301, 18
  store i64 %3316, i64* %PC, align 8
  %3317 = inttoptr i64 %3315 to i64*
  store i64 %3314, i64* %3317, align 8
  %3318 = load i64, i64* %RBP, align 8
  %3319 = add i64 %3318, -24
  %3320 = load i64, i64* %PC, align 8
  %3321 = add i64 %3320, 4
  store i64 %3321, i64* %PC, align 8
  %3322 = inttoptr i64 %3319 to i64*
  %3323 = load i64, i64* %3322, align 8
  store i64 %3323, i64* %RDX, align 8, !tbaa !2428
  %3324 = add i64 %3318, -32
  %3325 = add i64 %3320, 7
  store i64 %3325, i64* %PC, align 8
  %3326 = inttoptr i64 %3324 to i32*
  %3327 = load i32, i32* %3326, align 4
  %3328 = add i32 %3327, 1
  %3329 = zext i32 %3328 to i64
  store i64 %3329, i64* %RCX, align 8, !tbaa !2428
  %3330 = icmp eq i32 %3327, -1
  %3331 = icmp eq i32 %3328, 0
  %3332 = or i1 %3330, %3331
  %3333 = zext i1 %3332 to i8
  store i8 %3333, i8* %50, align 1, !tbaa !2432
  %3334 = and i32 %3328, 255
  %3335 = tail call i32 @llvm.ctpop.i32(i32 %3334) #14
  %3336 = trunc i32 %3335 to i8
  %3337 = and i8 %3336, 1
  %3338 = xor i8 %3337, 1
  store i8 %3338, i8* %51, align 1, !tbaa !2446
  %3339 = xor i32 %3328, %3327
  %3340 = lshr i32 %3339, 4
  %3341 = trunc i32 %3340 to i8
  %3342 = and i8 %3341, 1
  store i8 %3342, i8* %52, align 1, !tbaa !2447
  %3343 = zext i1 %3331 to i8
  store i8 %3343, i8* %53, align 1, !tbaa !2448
  %3344 = lshr i32 %3328, 31
  %3345 = trunc i32 %3344 to i8
  store i8 %3345, i8* %54, align 1, !tbaa !2449
  %3346 = lshr i32 %3327, 31
  %3347 = xor i32 %3344, %3346
  %3348 = add nuw nsw i32 %3347, %3344
  %3349 = icmp eq i32 %3348, 2
  %3350 = zext i1 %3349 to i8
  store i8 %3350, i8* %55, align 1, !tbaa !2450
  %3351 = sext i32 %3328 to i64
  store i64 %3351, i64* %RSI, align 8, !tbaa !2428
  %3352 = shl nsw i64 %3351, 3
  %3353 = add i64 %3323, %3352
  %3354 = add i64 %3320, 18
  store i64 %3354, i64* %PC, align 8
  %3355 = inttoptr i64 %3353 to i64*
  %3356 = load i64, i64* %3355, align 8
  %3357 = load i64, i64* %RAX, align 8
  %3358 = xor i64 %3357, %3356
  store i64 %3358, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %3359 = trunc i64 %3358 to i32
  %3360 = and i32 %3359, 255
  %3361 = tail call i32 @llvm.ctpop.i32(i32 %3360) #14
  %3362 = trunc i32 %3361 to i8
  %3363 = and i8 %3362, 1
  %3364 = xor i8 %3363, 1
  store i8 %3364, i8* %51, align 1, !tbaa !2446
  %3365 = icmp eq i64 %3358, 0
  %3366 = zext i1 %3365 to i8
  store i8 %3366, i8* %53, align 1, !tbaa !2448
  %3367 = lshr i64 %3358, 63
  %3368 = trunc i64 %3367 to i8
  store i8 %3368, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %3358, i64* %1808, align 1, !tbaa !2428
  store i64 0, i64* %1809, align 1, !tbaa !2428
  %3369 = add i64 %3318, -72
  %3370 = add i64 %3320, 36
  store i64 %3370, i64* %PC, align 8
  %3371 = inttoptr i64 %3369 to i64*
  store i64 %3358, i64* %3371, align 8
  %3372 = load i64, i64* %RBP, align 8
  %3373 = add i64 %3372, -24
  %3374 = load i64, i64* %PC, align 8
  %3375 = add i64 %3374, 4
  store i64 %3375, i64* %PC, align 8
  %3376 = inttoptr i64 %3373 to i64*
  %3377 = load i64, i64* %3376, align 8
  store i64 %3377, i64* %RDX, align 8, !tbaa !2428
  %3378 = add i64 %3372, -40
  %3379 = add i64 %3374, 8
  store i64 %3379, i64* %PC, align 8
  %3380 = inttoptr i64 %3378 to i32*
  %3381 = load i32, i32* %3380, align 4
  %3382 = sext i32 %3381 to i64
  store i64 %3382, i64* %RSI, align 8, !tbaa !2428
  %3383 = shl nsw i64 %3382, 3
  %3384 = add i64 %3383, %3377
  %3385 = add i64 %3374, 13
  store i64 %3385, i64* %PC, align 8
  %3386 = inttoptr i64 %3384 to i64*
  %3387 = load i64, i64* %3386, align 8
  store i64 %3387, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %3388 = add i64 %3372, -80
  %3389 = add i64 %3374, 18
  store i64 %3389, i64* %PC, align 8
  %3390 = inttoptr i64 %3388 to i64*
  store i64 %3387, i64* %3390, align 8
  %3391 = load i64, i64* %RBP, align 8
  %3392 = add i64 %3391, -24
  %3393 = load i64, i64* %PC, align 8
  %3394 = add i64 %3393, 4
  store i64 %3394, i64* %PC, align 8
  %3395 = inttoptr i64 %3392 to i64*
  %3396 = load i64, i64* %3395, align 8
  store i64 %3396, i64* %RDX, align 8, !tbaa !2428
  %3397 = add i64 %3391, -40
  %3398 = add i64 %3393, 7
  store i64 %3398, i64* %PC, align 8
  %3399 = inttoptr i64 %3397 to i32*
  %3400 = load i32, i32* %3399, align 4
  %3401 = add i32 %3400, 1
  %3402 = zext i32 %3401 to i64
  store i64 %3402, i64* %RCX, align 8, !tbaa !2428
  %3403 = icmp eq i32 %3400, -1
  %3404 = icmp eq i32 %3401, 0
  %3405 = or i1 %3403, %3404
  %3406 = zext i1 %3405 to i8
  store i8 %3406, i8* %50, align 1, !tbaa !2432
  %3407 = and i32 %3401, 255
  %3408 = tail call i32 @llvm.ctpop.i32(i32 %3407) #14
  %3409 = trunc i32 %3408 to i8
  %3410 = and i8 %3409, 1
  %3411 = xor i8 %3410, 1
  store i8 %3411, i8* %51, align 1, !tbaa !2446
  %3412 = xor i32 %3401, %3400
  %3413 = lshr i32 %3412, 4
  %3414 = trunc i32 %3413 to i8
  %3415 = and i8 %3414, 1
  store i8 %3415, i8* %52, align 1, !tbaa !2447
  %3416 = zext i1 %3404 to i8
  store i8 %3416, i8* %53, align 1, !tbaa !2448
  %3417 = lshr i32 %3401, 31
  %3418 = trunc i32 %3417 to i8
  store i8 %3418, i8* %54, align 1, !tbaa !2449
  %3419 = lshr i32 %3400, 31
  %3420 = xor i32 %3417, %3419
  %3421 = add nuw nsw i32 %3420, %3417
  %3422 = icmp eq i32 %3421, 2
  %3423 = zext i1 %3422 to i8
  store i8 %3423, i8* %55, align 1, !tbaa !2450
  %3424 = sext i32 %3401 to i64
  store i64 %3424, i64* %RSI, align 8, !tbaa !2428
  %3425 = shl nsw i64 %3424, 3
  %3426 = add i64 %3396, %3425
  %3427 = add i64 %3393, 18
  store i64 %3427, i64* %PC, align 8
  %3428 = inttoptr i64 %3426 to i64*
  %3429 = load i64, i64* %3428, align 8
  %3430 = load i64, i64* %RAX, align 8
  %3431 = xor i64 %3430, %3429
  store i64 %3431, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %3432 = trunc i64 %3431 to i32
  %3433 = and i32 %3432, 255
  %3434 = tail call i32 @llvm.ctpop.i32(i32 %3433) #14
  %3435 = trunc i32 %3434 to i8
  %3436 = and i8 %3435, 1
  %3437 = xor i8 %3436, 1
  store i8 %3437, i8* %51, align 1, !tbaa !2446
  %3438 = icmp eq i64 %3431, 0
  %3439 = zext i1 %3438 to i8
  store i8 %3439, i8* %53, align 1, !tbaa !2448
  %3440 = lshr i64 %3431, 63
  %3441 = trunc i64 %3440 to i8
  store i8 %3441, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %3431, i64* %1808, align 1, !tbaa !2428
  store i64 0, i64* %1809, align 1, !tbaa !2428
  %3442 = add i64 %3391, -88
  %3443 = add i64 %3393, 36
  store i64 %3443, i64* %PC, align 8
  %3444 = inttoptr i64 %3442 to i64*
  store i64 %3431, i64* %3444, align 8
  %3445 = load i64, i64* %RBP, align 8
  %3446 = add i64 %3445, -80
  %3447 = load i64, i64* %PC, align 8
  %3448 = add i64 %3447, 5
  store i64 %3448, i64* %PC, align 8
  %3449 = inttoptr i64 %3446 to i64*
  %3450 = load i64, i64* %3449, align 8
  store i64 %3450, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %3451 = add i64 %3445, -24
  %3452 = add i64 %3447, 9
  store i64 %3452, i64* %PC, align 8
  %3453 = inttoptr i64 %3451 to i64*
  %3454 = load i64, i64* %3453, align 8
  store i64 %3454, i64* %RAX, align 8, !tbaa !2428
  %3455 = add i64 %3445, -32
  %3456 = add i64 %3447, 13
  store i64 %3456, i64* %PC, align 8
  %3457 = inttoptr i64 %3455 to i32*
  %3458 = load i32, i32* %3457, align 4
  %3459 = sext i32 %3458 to i64
  store i64 %3459, i64* %RDX, align 8, !tbaa !2428
  %3460 = shl nsw i64 %3459, 3
  %3461 = add i64 %3460, %3454
  %3462 = add i64 %3447, 18
  store i64 %3462, i64* %PC, align 8
  %3463 = inttoptr i64 %3461 to i64*
  store i64 %3450, i64* %3463, align 8
  %3464 = load i64, i64* %RBP, align 8
  %3465 = add i64 %3464, -88
  %3466 = load i64, i64* %PC, align 8
  %3467 = add i64 %3466, 5
  store i64 %3467, i64* %PC, align 8
  %3468 = inttoptr i64 %3465 to i64*
  %3469 = load i64, i64* %3468, align 8
  store i64 %3469, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %3470 = add i64 %3464, -24
  %3471 = add i64 %3466, 9
  store i64 %3471, i64* %PC, align 8
  %3472 = inttoptr i64 %3470 to i64*
  %3473 = load i64, i64* %3472, align 8
  store i64 %3473, i64* %RAX, align 8, !tbaa !2428
  %3474 = add i64 %3464, -32
  %3475 = add i64 %3466, 12
  store i64 %3475, i64* %PC, align 8
  %3476 = inttoptr i64 %3474 to i32*
  %3477 = load i32, i32* %3476, align 4
  %3478 = add i32 %3477, 1
  %3479 = zext i32 %3478 to i64
  store i64 %3479, i64* %RCX, align 8, !tbaa !2428
  %3480 = icmp eq i32 %3477, -1
  %3481 = icmp eq i32 %3478, 0
  %3482 = or i1 %3480, %3481
  %3483 = zext i1 %3482 to i8
  store i8 %3483, i8* %50, align 1, !tbaa !2432
  %3484 = and i32 %3478, 255
  %3485 = tail call i32 @llvm.ctpop.i32(i32 %3484) #14
  %3486 = trunc i32 %3485 to i8
  %3487 = and i8 %3486, 1
  %3488 = xor i8 %3487, 1
  store i8 %3488, i8* %51, align 1, !tbaa !2446
  %3489 = xor i32 %3478, %3477
  %3490 = lshr i32 %3489, 4
  %3491 = trunc i32 %3490 to i8
  %3492 = and i8 %3491, 1
  store i8 %3492, i8* %52, align 1, !tbaa !2447
  %3493 = zext i1 %3481 to i8
  store i8 %3493, i8* %53, align 1, !tbaa !2448
  %3494 = lshr i32 %3478, 31
  %3495 = trunc i32 %3494 to i8
  store i8 %3495, i8* %54, align 1, !tbaa !2449
  %3496 = lshr i32 %3477, 31
  %3497 = xor i32 %3494, %3496
  %3498 = add nuw nsw i32 %3497, %3494
  %3499 = icmp eq i32 %3498, 2
  %3500 = zext i1 %3499 to i8
  store i8 %3500, i8* %55, align 1, !tbaa !2450
  %3501 = sext i32 %3478 to i64
  store i64 %3501, i64* %RDX, align 8, !tbaa !2428
  %3502 = shl nsw i64 %3501, 3
  %3503 = add i64 %3473, %3502
  %3504 = add i64 %3466, 23
  store i64 %3504, i64* %PC, align 8
  %3505 = inttoptr i64 %3503 to i64*
  store i64 %3469, i64* %3505, align 8
  %3506 = load i64, i64* %RBP, align 8
  %3507 = add i64 %3506, -64
  %3508 = load i64, i64* %PC, align 8
  %3509 = add i64 %3508, 5
  store i64 %3509, i64* %PC, align 8
  %3510 = inttoptr i64 %3507 to i64*
  %3511 = load i64, i64* %3510, align 8
  store i64 %3511, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %3512 = add i64 %3506, -24
  %3513 = add i64 %3508, 9
  store i64 %3513, i64* %PC, align 8
  %3514 = inttoptr i64 %3512 to i64*
  %3515 = load i64, i64* %3514, align 8
  store i64 %3515, i64* %RAX, align 8, !tbaa !2428
  %3516 = add i64 %3506, -40
  %3517 = add i64 %3508, 13
  store i64 %3517, i64* %PC, align 8
  %3518 = inttoptr i64 %3516 to i32*
  %3519 = load i32, i32* %3518, align 4
  %3520 = sext i32 %3519 to i64
  store i64 %3520, i64* %RDX, align 8, !tbaa !2428
  %3521 = shl nsw i64 %3520, 3
  %3522 = add i64 %3521, %3515
  %3523 = add i64 %3508, 18
  store i64 %3523, i64* %PC, align 8
  %3524 = inttoptr i64 %3522 to i64*
  store i64 %3511, i64* %3524, align 8
  %3525 = load i64, i64* %RBP, align 8
  %3526 = add i64 %3525, -72
  %3527 = load i64, i64* %PC, align 8
  %3528 = add i64 %3527, 5
  store i64 %3528, i64* %PC, align 8
  %3529 = inttoptr i64 %3526 to i64*
  %3530 = load i64, i64* %3529, align 8
  store i64 %3530, i64* %1808, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1810, align 1, !tbaa !2451
  %3531 = add i64 %3525, -24
  %3532 = add i64 %3527, 9
  store i64 %3532, i64* %PC, align 8
  %3533 = inttoptr i64 %3531 to i64*
  %3534 = load i64, i64* %3533, align 8
  store i64 %3534, i64* %RAX, align 8, !tbaa !2428
  %3535 = add i64 %3525, -40
  %3536 = add i64 %3527, 12
  store i64 %3536, i64* %PC, align 8
  %3537 = inttoptr i64 %3535 to i32*
  %3538 = load i32, i32* %3537, align 4
  %3539 = add i32 %3538, 1
  %3540 = zext i32 %3539 to i64
  store i64 %3540, i64* %RCX, align 8, !tbaa !2428
  %3541 = icmp eq i32 %3538, -1
  %3542 = icmp eq i32 %3539, 0
  %3543 = or i1 %3541, %3542
  %3544 = zext i1 %3543 to i8
  store i8 %3544, i8* %50, align 1, !tbaa !2432
  %3545 = and i32 %3539, 255
  %3546 = tail call i32 @llvm.ctpop.i32(i32 %3545) #14
  %3547 = trunc i32 %3546 to i8
  %3548 = and i8 %3547, 1
  %3549 = xor i8 %3548, 1
  store i8 %3549, i8* %51, align 1, !tbaa !2446
  %3550 = xor i32 %3539, %3538
  %3551 = lshr i32 %3550, 4
  %3552 = trunc i32 %3551 to i8
  %3553 = and i8 %3552, 1
  store i8 %3553, i8* %52, align 1, !tbaa !2447
  %3554 = zext i1 %3542 to i8
  store i8 %3554, i8* %53, align 1, !tbaa !2448
  %3555 = lshr i32 %3539, 31
  %3556 = trunc i32 %3555 to i8
  store i8 %3556, i8* %54, align 1, !tbaa !2449
  %3557 = lshr i32 %3538, 31
  %3558 = xor i32 %3555, %3557
  %3559 = add nuw nsw i32 %3558, %3555
  %3560 = icmp eq i32 %3559, 2
  %3561 = zext i1 %3560 to i8
  store i8 %3561, i8* %55, align 1, !tbaa !2450
  %3562 = sext i32 %3539 to i64
  store i64 %3562, i64* %RDX, align 8, !tbaa !2428
  %3563 = shl nsw i64 %3562, 3
  %3564 = add i64 %3534, %3563
  %3565 = add i64 %3527, 23
  store i64 %3565, i64* %PC, align 8
  %3566 = inttoptr i64 %3564 to i64*
  store i64 %3530, i64* %3566, align 8
  %3567 = load i64, i64* %RBP, align 8
  %3568 = add i64 %3567, -28
  %3569 = load i64, i64* %PC, align 8
  %3570 = add i64 %3569, 3
  store i64 %3570, i64* %PC, align 8
  %3571 = inttoptr i64 %3568 to i32*
  %3572 = load i32, i32* %3571, align 4
  %3573 = add i32 %3572, 1
  %3574 = zext i32 %3573 to i64
  store i64 %3574, i64* %RAX, align 8, !tbaa !2428
  %3575 = icmp eq i32 %3572, -1
  %3576 = icmp eq i32 %3573, 0
  %3577 = or i1 %3575, %3576
  %3578 = zext i1 %3577 to i8
  store i8 %3578, i8* %50, align 1, !tbaa !2432
  %3579 = and i32 %3573, 255
  %3580 = tail call i32 @llvm.ctpop.i32(i32 %3579) #14
  %3581 = trunc i32 %3580 to i8
  %3582 = and i8 %3581, 1
  %3583 = xor i8 %3582, 1
  store i8 %3583, i8* %51, align 1, !tbaa !2446
  %3584 = xor i32 %3573, %3572
  %3585 = lshr i32 %3584, 4
  %3586 = trunc i32 %3585 to i8
  %3587 = and i8 %3586, 1
  store i8 %3587, i8* %52, align 1, !tbaa !2447
  %3588 = zext i1 %3576 to i8
  store i8 %3588, i8* %53, align 1, !tbaa !2448
  %3589 = lshr i32 %3573, 31
  %3590 = trunc i32 %3589 to i8
  store i8 %3590, i8* %54, align 1, !tbaa !2449
  %3591 = lshr i32 %3572, 31
  %3592 = xor i32 %3589, %3591
  %3593 = add nuw nsw i32 %3592, %3589
  %3594 = icmp eq i32 %3593, 2
  %3595 = zext i1 %3594 to i8
  store i8 %3595, i8* %55, align 1, !tbaa !2450
  %3596 = add i64 %3569, 9
  store i64 %3596, i64* %PC, align 8
  store i32 %3573, i32* %3571, align 4
  %3597 = load i64, i64* %PC, align 8
  %3598 = add i64 %3597, -893
  store i64 %3598, i64* %PC, align 8, !tbaa !2428
  br label %block_401ccd

block_402409:                                     ; preds = %block_40222f
  %3599 = load i32, i32* %1820, align 4
  %3600 = shl i32 %3599, 1
  %3601 = icmp slt i32 %3599, 0
  %3602 = icmp slt i32 %3600, 0
  %3603 = xor i1 %3601, %3602
  %3604 = zext i32 %3600 to i64
  store i64 %3604, i64* %RCX, align 8, !tbaa !2428
  %.lobit21 = lshr i32 %3599, 31
  %3605 = trunc i32 %.lobit21 to i8
  store i8 %3605, i8* %50, align 1, !tbaa !2453
  %3606 = and i32 %3600, 254
  %3607 = tail call i32 @llvm.ctpop.i32(i32 %3606) #14
  %3608 = trunc i32 %3607 to i8
  %3609 = and i8 %3608, 1
  %3610 = xor i8 %3609, 1
  store i8 %3610, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %3611 = icmp eq i32 %3600, 0
  %3612 = zext i1 %3611 to i8
  store i8 %3612, i8* %53, align 1, !tbaa !2453
  %3613 = lshr i32 %3599, 30
  %3614 = trunc i32 %3613 to i8
  %3615 = and i8 %3614, 1
  store i8 %3615, i8* %54, align 1, !tbaa !2453
  %3616 = zext i1 %3603 to i8
  store i8 %3616, i8* %55, align 1, !tbaa !2453
  %3617 = add i64 %1812, -16
  %3618 = add i64 %1848, 20
  store i64 %3618, i64* %PC, align 8
  %3619 = inttoptr i64 %3617 to i64*
  %3620 = load i64, i64* %3619, align 8
  store i64 %3620, i64* %RDX, align 8, !tbaa !2428
  %3621 = add i64 %1848, 24
  store i64 %3621, i64* %PC, align 8
  %3622 = load i32, i32* %1820, align 4
  %3623 = sext i32 %3622 to i64
  store i64 %3623, i64* %RSI, align 8, !tbaa !2428
  %3624 = shl nsw i64 %3623, 2
  %3625 = add i64 %3620, %3624
  %3626 = add i64 %1848, 27
  store i64 %3626, i64* %PC, align 8
  %3627 = inttoptr i64 %3625 to i32*
  %3628 = load i32, i32* %3627, align 4
  %3629 = add i32 %3628, %3600
  %3630 = zext i32 %3629 to i64
  store i64 %3630, i64* %RCX, align 8, !tbaa !2428
  %3631 = icmp ult i32 %3629, %3600
  %3632 = icmp ult i32 %3629, %3628
  %3633 = or i1 %3631, %3632
  %3634 = zext i1 %3633 to i8
  store i8 %3634, i8* %50, align 1, !tbaa !2432
  %3635 = and i32 %3629, 255
  %3636 = tail call i32 @llvm.ctpop.i32(i32 %3635) #14
  %3637 = trunc i32 %3636 to i8
  %3638 = and i8 %3637, 1
  %3639 = xor i8 %3638, 1
  store i8 %3639, i8* %51, align 1, !tbaa !2446
  %3640 = xor i32 %3628, %3600
  %3641 = xor i32 %3640, %3629
  %3642 = lshr i32 %3641, 4
  %3643 = trunc i32 %3642 to i8
  %3644 = and i8 %3643, 1
  store i8 %3644, i8* %52, align 1, !tbaa !2447
  %3645 = icmp eq i32 %3629, 0
  %3646 = zext i1 %3645 to i8
  store i8 %3646, i8* %53, align 1, !tbaa !2448
  %3647 = lshr i32 %3629, 31
  %3648 = trunc i32 %3647 to i8
  store i8 %3648, i8* %54, align 1, !tbaa !2449
  %3649 = lshr i32 %3599, 30
  %3650 = and i32 %3649, 1
  %3651 = lshr i32 %3628, 31
  %3652 = xor i32 %3647, %3650
  %3653 = xor i32 %3647, %3651
  %3654 = add nuw nsw i32 %3652, %3653
  %3655 = icmp eq i32 %3654, 2
  %3656 = zext i1 %3655 to i8
  store i8 %3656, i8* %55, align 1, !tbaa !2450
  %3657 = add i64 %1812, -40
  %3658 = add i64 %1848, 30
  store i64 %3658, i64* %PC, align 8
  %3659 = inttoptr i64 %3657 to i32*
  store i32 %3629, i32* %3659, align 4
  %3660 = load i64, i64* %RBP, align 8
  %3661 = add i64 %3660, -24
  %3662 = load i64, i64* %PC, align 8
  %3663 = add i64 %3662, 4
  store i64 %3663, i64* %PC, align 8
  %3664 = inttoptr i64 %3661 to i64*
  %3665 = load i64, i64* %3664, align 8
  store i64 %3665, i64* %RDX, align 8, !tbaa !2428
  %3666 = add i64 %3660, -40
  %3667 = add i64 %3662, 7
  store i64 %3667, i64* %PC, align 8
  %3668 = inttoptr i64 %3666 to i32*
  %3669 = load i32, i32* %3668, align 4
  %3670 = add i32 %3669, 1
  %3671 = zext i32 %3670 to i64
  store i64 %3671, i64* %RCX, align 8, !tbaa !2428
  %3672 = icmp eq i32 %3669, -1
  %3673 = icmp eq i32 %3670, 0
  %3674 = or i1 %3672, %3673
  %3675 = zext i1 %3674 to i8
  store i8 %3675, i8* %50, align 1, !tbaa !2432
  %3676 = and i32 %3670, 255
  %3677 = tail call i32 @llvm.ctpop.i32(i32 %3676) #14
  %3678 = trunc i32 %3677 to i8
  %3679 = and i8 %3678, 1
  %3680 = xor i8 %3679, 1
  store i8 %3680, i8* %51, align 1, !tbaa !2446
  %3681 = xor i32 %3670, %3669
  %3682 = lshr i32 %3681, 4
  %3683 = trunc i32 %3682 to i8
  %3684 = and i8 %3683, 1
  store i8 %3684, i8* %52, align 1, !tbaa !2447
  %3685 = zext i1 %3673 to i8
  store i8 %3685, i8* %53, align 1, !tbaa !2448
  %3686 = lshr i32 %3670, 31
  %3687 = trunc i32 %3686 to i8
  store i8 %3687, i8* %54, align 1, !tbaa !2449
  %3688 = lshr i32 %3669, 31
  %3689 = xor i32 %3686, %3688
  %3690 = add nuw nsw i32 %3689, %3686
  %3691 = icmp eq i32 %3690, 2
  %3692 = zext i1 %3691 to i8
  store i8 %3692, i8* %55, align 1, !tbaa !2450
  %3693 = sext i32 %3670 to i64
  store i64 %3693, i64* %RSI, align 8, !tbaa !2428
  %3694 = shl nsw i64 %3693, 3
  %3695 = add i64 %3665, %3694
  %3696 = add i64 %3662, 18
  store i64 %3696, i64* %PC, align 8
  %3697 = inttoptr i64 %3695 to i64*
  %3698 = load i64, i64* %3697, align 8
  %3699 = load i64, i64* %RAX, align 8
  %3700 = xor i64 %3699, %3698
  store i64 %3700, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %3701 = trunc i64 %3700 to i32
  %3702 = and i32 %3701, 255
  %3703 = tail call i32 @llvm.ctpop.i32(i32 %3702) #14
  %3704 = trunc i32 %3703 to i8
  %3705 = and i8 %3704, 1
  %3706 = xor i8 %3705, 1
  store i8 %3706, i8* %51, align 1, !tbaa !2446
  %3707 = icmp eq i64 %3700, 0
  %3708 = zext i1 %3707 to i8
  store i8 %3708, i8* %53, align 1, !tbaa !2448
  %3709 = lshr i64 %3700, 63
  %3710 = trunc i64 %3709 to i8
  store i8 %3710, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %3700, i64* %1698, align 1, !tbaa !2428
  store i64 0, i64* %1699, align 1, !tbaa !2428
  %3711 = add i64 %3662, 35
  store i64 %3711, i64* %PC, align 8
  %3712 = load i64, i64* %3664, align 8
  store i64 %3712, i64* %RDX, align 8, !tbaa !2428
  %3713 = add i64 %3662, 38
  store i64 %3713, i64* %PC, align 8
  %3714 = load i32, i32* %3668, align 4
  %3715 = add i32 %3714, 1
  %3716 = zext i32 %3715 to i64
  store i64 %3716, i64* %RCX, align 8, !tbaa !2428
  %3717 = icmp eq i32 %3714, -1
  %3718 = icmp eq i32 %3715, 0
  %3719 = or i1 %3717, %3718
  %3720 = zext i1 %3719 to i8
  store i8 %3720, i8* %50, align 1, !tbaa !2432
  %3721 = and i32 %3715, 255
  %3722 = tail call i32 @llvm.ctpop.i32(i32 %3721) #14
  %3723 = trunc i32 %3722 to i8
  %3724 = and i8 %3723, 1
  %3725 = xor i8 %3724, 1
  store i8 %3725, i8* %51, align 1, !tbaa !2446
  %3726 = xor i32 %3715, %3714
  %3727 = lshr i32 %3726, 4
  %3728 = trunc i32 %3727 to i8
  %3729 = and i8 %3728, 1
  store i8 %3729, i8* %52, align 1, !tbaa !2447
  %3730 = zext i1 %3718 to i8
  store i8 %3730, i8* %53, align 1, !tbaa !2448
  %3731 = lshr i32 %3715, 31
  %3732 = trunc i32 %3731 to i8
  store i8 %3732, i8* %54, align 1, !tbaa !2449
  %3733 = lshr i32 %3714, 31
  %3734 = xor i32 %3731, %3733
  %3735 = add nuw nsw i32 %3734, %3731
  %3736 = icmp eq i32 %3735, 2
  %3737 = zext i1 %3736 to i8
  store i8 %3737, i8* %55, align 1, !tbaa !2450
  %3738 = sext i32 %3715 to i64
  store i64 %3738, i64* %RSI, align 8, !tbaa !2428
  %3739 = shl nsw i64 %3738, 3
  %3740 = add i64 %3712, %3739
  %3741 = add i64 %3662, 49
  store i64 %3741, i64* %PC, align 8
  %3742 = inttoptr i64 %3740 to i64*
  store i64 %3700, i64* %3742, align 8
  %3743 = load i64, i64* %RBP, align 8
  %3744 = add i64 %3743, -24
  %3745 = load i64, i64* %PC, align 8
  %3746 = add i64 %3745, 4
  store i64 %3746, i64* %PC, align 8
  %3747 = inttoptr i64 %3744 to i64*
  %3748 = load i64, i64* %3747, align 8
  store i64 %3748, i64* %RDX, align 8, !tbaa !2428
  %3749 = add i64 %3743, -40
  %3750 = add i64 %3745, 7
  store i64 %3750, i64* %PC, align 8
  %3751 = inttoptr i64 %3749 to i32*
  %3752 = load i32, i32* %3751, align 4
  %3753 = zext i32 %3752 to i64
  store i64 %3753, i64* %RCX, align 8, !tbaa !2428
  %3754 = add i64 %3743, -52
  %3755 = add i64 %3745, 10
  store i64 %3755, i64* %PC, align 8
  %3756 = inttoptr i64 %3754 to i32*
  %3757 = load i32, i32* %3756, align 4
  %3758 = add i32 %3757, %3752
  %3759 = lshr i32 %3758, 31
  %3760 = add i32 %3758, 1
  %3761 = zext i32 %3760 to i64
  store i64 %3761, i64* %RCX, align 8, !tbaa !2428
  %3762 = icmp eq i32 %3758, -1
  %3763 = icmp eq i32 %3760, 0
  %3764 = or i1 %3762, %3763
  %3765 = zext i1 %3764 to i8
  store i8 %3765, i8* %50, align 1, !tbaa !2432
  %3766 = and i32 %3760, 255
  %3767 = tail call i32 @llvm.ctpop.i32(i32 %3766) #14
  %3768 = trunc i32 %3767 to i8
  %3769 = and i8 %3768, 1
  %3770 = xor i8 %3769, 1
  store i8 %3770, i8* %51, align 1, !tbaa !2446
  %3771 = xor i32 %3760, %3758
  %3772 = lshr i32 %3771, 4
  %3773 = trunc i32 %3772 to i8
  %3774 = and i8 %3773, 1
  store i8 %3774, i8* %52, align 1, !tbaa !2447
  %3775 = zext i1 %3763 to i8
  store i8 %3775, i8* %53, align 1, !tbaa !2448
  %3776 = lshr i32 %3760, 31
  %3777 = trunc i32 %3776 to i8
  store i8 %3777, i8* %54, align 1, !tbaa !2449
  %3778 = xor i32 %3776, %3759
  %3779 = add nuw nsw i32 %3778, %3776
  %3780 = icmp eq i32 %3779, 2
  %3781 = zext i1 %3780 to i8
  store i8 %3781, i8* %55, align 1, !tbaa !2450
  %3782 = sext i32 %3760 to i64
  store i64 %3782, i64* %RSI, align 8, !tbaa !2428
  %3783 = shl nsw i64 %3782, 3
  %3784 = add i64 %3748, %3783
  %3785 = add i64 %3745, 21
  store i64 %3785, i64* %PC, align 8
  %3786 = inttoptr i64 %3784 to i64*
  %3787 = load i64, i64* %3786, align 8
  %3788 = load i64, i64* %RAX, align 8
  %3789 = xor i64 %3788, %3787
  store i64 %3789, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %50, align 1, !tbaa !2432
  %3790 = trunc i64 %3789 to i32
  %3791 = and i32 %3790, 255
  %3792 = tail call i32 @llvm.ctpop.i32(i32 %3791) #14
  %3793 = trunc i32 %3792 to i8
  %3794 = and i8 %3793, 1
  %3795 = xor i8 %3794, 1
  store i8 %3795, i8* %51, align 1, !tbaa !2446
  %3796 = icmp eq i64 %3789, 0
  %3797 = zext i1 %3796 to i8
  store i8 %3797, i8* %53, align 1, !tbaa !2448
  %3798 = lshr i64 %3789, 63
  %3799 = trunc i64 %3798 to i8
  store i8 %3799, i8* %54, align 1, !tbaa !2449
  store i8 0, i8* %55, align 1, !tbaa !2450
  store i8 0, i8* %52, align 1, !tbaa !2447
  store i64 %3789, i64* %1698, align 1, !tbaa !2428
  store i64 0, i64* %1699, align 1, !tbaa !2428
  %3800 = load i64, i64* %RBP, align 8
  %3801 = add i64 %3800, -24
  %3802 = add i64 %3745, 38
  store i64 %3802, i64* %PC, align 8
  %3803 = inttoptr i64 %3801 to i64*
  %3804 = load i64, i64* %3803, align 8
  store i64 %3804, i64* %RAX, align 8, !tbaa !2428
  %3805 = add i64 %3800, -40
  %3806 = add i64 %3745, 41
  store i64 %3806, i64* %PC, align 8
  %3807 = inttoptr i64 %3805 to i32*
  %3808 = load i32, i32* %3807, align 4
  %3809 = zext i32 %3808 to i64
  store i64 %3809, i64* %RCX, align 8, !tbaa !2428
  %3810 = add i64 %3800, -52
  %3811 = add i64 %3745, 44
  store i64 %3811, i64* %PC, align 8
  %3812 = inttoptr i64 %3810 to i32*
  %3813 = load i32, i32* %3812, align 4
  %3814 = add i32 %3813, %3808
  %3815 = lshr i32 %3814, 31
  %3816 = add i32 %3814, 1
  %3817 = zext i32 %3816 to i64
  store i64 %3817, i64* %RCX, align 8, !tbaa !2428
  %3818 = icmp eq i32 %3814, -1
  %3819 = icmp eq i32 %3816, 0
  %3820 = or i1 %3818, %3819
  %3821 = zext i1 %3820 to i8
  store i8 %3821, i8* %50, align 1, !tbaa !2432
  %3822 = and i32 %3816, 255
  %3823 = tail call i32 @llvm.ctpop.i32(i32 %3822) #14
  %3824 = trunc i32 %3823 to i8
  %3825 = and i8 %3824, 1
  %3826 = xor i8 %3825, 1
  store i8 %3826, i8* %51, align 1, !tbaa !2446
  %3827 = xor i32 %3816, %3814
  %3828 = lshr i32 %3827, 4
  %3829 = trunc i32 %3828 to i8
  %3830 = and i8 %3829, 1
  store i8 %3830, i8* %52, align 1, !tbaa !2447
  %3831 = zext i1 %3819 to i8
  store i8 %3831, i8* %53, align 1, !tbaa !2448
  %3832 = lshr i32 %3816, 31
  %3833 = trunc i32 %3832 to i8
  store i8 %3833, i8* %54, align 1, !tbaa !2449
  %3834 = xor i32 %3832, %3815
  %3835 = add nuw nsw i32 %3834, %3832
  %3836 = icmp eq i32 %3835, 2
  %3837 = zext i1 %3836 to i8
  store i8 %3837, i8* %55, align 1, !tbaa !2450
  %3838 = sext i32 %3816 to i64
  store i64 %3838, i64* %RDX, align 8, !tbaa !2428
  %3839 = shl nsw i64 %3838, 3
  %3840 = add i64 %3804, %3839
  %3841 = add i64 %3745, 55
  store i64 %3841, i64* %PC, align 8
  %3842 = inttoptr i64 %3840 to i64*
  store i64 %3789, i64* %3842, align 8
  %3843 = load i64, i64* %RBP, align 8
  %3844 = add i64 %3843, -36
  %3845 = load i64, i64* %PC, align 8
  %3846 = add i64 %3845, 3
  store i64 %3846, i64* %PC, align 8
  %3847 = inttoptr i64 %3844 to i32*
  %3848 = load i32, i32* %3847, align 4
  %3849 = add i32 %3848, 1
  %3850 = zext i32 %3849 to i64
  store i64 %3850, i64* %RAX, align 8, !tbaa !2428
  %3851 = icmp eq i32 %3848, -1
  %3852 = icmp eq i32 %3849, 0
  %3853 = or i1 %3851, %3852
  %3854 = zext i1 %3853 to i8
  store i8 %3854, i8* %50, align 1, !tbaa !2432
  %3855 = and i32 %3849, 255
  %3856 = tail call i32 @llvm.ctpop.i32(i32 %3855) #14
  %3857 = trunc i32 %3856 to i8
  %3858 = and i8 %3857, 1
  %3859 = xor i8 %3858, 1
  store i8 %3859, i8* %51, align 1, !tbaa !2446
  %3860 = xor i32 %3849, %3848
  %3861 = lshr i32 %3860, 4
  %3862 = trunc i32 %3861 to i8
  %3863 = and i8 %3862, 1
  store i8 %3863, i8* %52, align 1, !tbaa !2447
  %3864 = zext i1 %3852 to i8
  store i8 %3864, i8* %53, align 1, !tbaa !2448
  %3865 = lshr i32 %3849, 31
  %3866 = trunc i32 %3865 to i8
  store i8 %3866, i8* %54, align 1, !tbaa !2449
  %3867 = lshr i32 %3848, 31
  %3868 = xor i32 %3865, %3867
  %3869 = add nuw nsw i32 %3868, %3865
  %3870 = icmp eq i32 %3869, 2
  %3871 = zext i1 %3870 to i8
  store i8 %3871, i8* %55, align 1, !tbaa !2450
  %3872 = add i64 %3845, 9
  store i64 %3872, i64* %PC, align 8
  store i32 %3849, i32* %3847, align 4
  %3873 = load i64, i64* %PC, align 8
  %3874 = add i64 %3873, -636
  store i64 %3874, i64* %PC, align 8, !tbaa !2428
  br label %block_40221c
}

; Function Attrs: noinline
define %struct.Memory* @sub_400840_frame_dummy(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #8 {
block_400840:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  store i64 %7, i64* %5, align 8, !tbaa !2428
  %9 = load i64, i64* %PC, align 8
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = load i64, i64* %8, align 8
  store i64 %11, i64* %RBP, align 8, !tbaa !2428
  store i64 %6, i64* %5, align 8, !tbaa !2428
  %12 = add i64 %9, -113
  store i64 %12, i64* %PC, align 8, !tbaa !2428
  %13 = tail call %struct.Memory* @sub_4007d0_register_tm_clones(%struct.State* nonnull %0, i64 %12, %struct.Memory* %2)
  ret %struct.Memory* %13
}

; Function Attrs: noinline norecurse nounwind
define %struct.Memory* @sub_400790__dl_relocate_static_pie(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #9 {
block_400790:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = add i64 %1, 2
  store i64 %3, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !2428
  %6 = inttoptr i64 %5 to i64*
  %7 = load i64, i64* %6, align 8
  store i64 %7, i64* %PC, align 8, !tbaa !2428
  %8 = add i64 %5, 8
  store i64 %8, i64* %4, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_401060_cdft(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone) local_unnamed_addr #8 {
block_401060:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %4 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -40
  store i64 %11, i64* %RSP, align 8, !tbaa !2428
  %12 = icmp ult i64 %8, 32
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1, !tbaa !2432
  %15 = trunc i64 %11 to i32
  %16 = and i32 %15, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16) #14
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1, !tbaa !2446
  %22 = xor i64 %8, %11
  %23 = lshr i64 %22, 4
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1, !tbaa !2447
  %27 = icmp eq i64 %11, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1, !tbaa !2448
  %30 = lshr i64 %11, 63
  %31 = trunc i64 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1, !tbaa !2449
  %33 = lshr i64 %8, 63
  %34 = xor i64 %30, %33
  %35 = add nuw nsw i64 %34, %33
  %36 = icmp eq i64 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1, !tbaa !2450
  %39 = add i64 %7, -12
  %40 = load i32, i32* %EDI, align 4
  %41 = add i64 %10, 10
  store i64 %41, i64* %PC, align 8
  %42 = inttoptr i64 %39 to i32*
  store i32 %40, i32* %42, align 4
  %43 = load i64, i64* %RBP, align 8
  %44 = add i64 %43, -8
  %45 = load i32, i32* %ESI, align 4
  %46 = load i64, i64* %PC, align 8
  %47 = add i64 %46, 3
  store i64 %47, i64* %PC, align 8
  %48 = inttoptr i64 %44 to i32*
  store i32 %45, i32* %48, align 4
  %49 = load i64, i64* %RBP, align 8
  %50 = add i64 %49, -16
  %51 = load i64, i64* %RDX, align 8
  %52 = load i64, i64* %PC, align 8
  %53 = add i64 %52, 4
  store i64 %53, i64* %PC, align 8
  %54 = inttoptr i64 %50 to i64*
  store i64 %51, i64* %54, align 8
  %55 = load i64, i64* %RBP, align 8
  %56 = add i64 %55, -24
  %57 = load i64, i64* %RCX, align 8
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 4
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %56 to i64*
  store i64 %57, i64* %60, align 8
  %61 = load i64, i64* %RBP, align 8
  %62 = add i64 %61, -32
  %63 = load i64, i64* %R8, align 8
  %64 = load i64, i64* %PC, align 8
  %65 = add i64 %64, 4
  store i64 %65, i64* %PC, align 8
  %66 = inttoptr i64 %62 to i64*
  store i64 %63, i64* %66, align 8
  %67 = load i64, i64* %RBP, align 8
  %68 = add i64 %67, -4
  %69 = load i64, i64* %PC, align 8
  %70 = add i64 %69, 4
  store i64 %70, i64* %PC, align 8
  %71 = inttoptr i64 %68 to i32*
  %72 = load i32, i32* %71, align 4
  %73 = add i32 %72, -4
  %74 = icmp ult i32 %72, 4
  %75 = zext i1 %74 to i8
  store i8 %75, i8* %14, align 1, !tbaa !2432
  %76 = and i32 %73, 255
  %77 = tail call i32 @llvm.ctpop.i32(i32 %76) #14
  %78 = trunc i32 %77 to i8
  %79 = and i8 %78, 1
  %80 = xor i8 %79, 1
  store i8 %80, i8* %21, align 1, !tbaa !2446
  %81 = xor i32 %73, %72
  %82 = lshr i32 %81, 4
  %83 = trunc i32 %82 to i8
  %84 = and i8 %83, 1
  store i8 %84, i8* %26, align 1, !tbaa !2447
  %85 = icmp eq i32 %73, 0
  %86 = zext i1 %85 to i8
  store i8 %86, i8* %29, align 1, !tbaa !2448
  %87 = lshr i32 %73, 31
  %88 = trunc i32 %87 to i8
  store i8 %88, i8* %32, align 1, !tbaa !2449
  %89 = lshr i32 %72, 31
  %90 = xor i32 %87, %89
  %91 = add nuw nsw i32 %90, %89
  %92 = icmp eq i32 %91, 2
  %93 = zext i1 %92 to i8
  store i8 %93, i8* %38, align 1, !tbaa !2450
  %94 = icmp ne i8 %88, 0
  %95 = xor i1 %94, %92
  %96 = or i1 %85, %95
  %.v8 = select i1 %96, i64 94, i64 10
  %97 = add i64 %69, %.v8
  store i64 %97, i64* %PC, align 8, !tbaa !2428
  br i1 %96, label %block_4010d8, label %block_401084

block_4010d8:                                     ; preds = %block_401060
  %98 = add i64 %97, 4
  store i64 %98, i64* %PC, align 8
  %99 = load i32, i32* %71, align 4
  %100 = add i32 %99, -4
  %101 = icmp ult i32 %99, 4
  %102 = zext i1 %101 to i8
  store i8 %102, i8* %14, align 1, !tbaa !2432
  %103 = and i32 %100, 255
  %104 = tail call i32 @llvm.ctpop.i32(i32 %103) #14
  %105 = trunc i32 %104 to i8
  %106 = and i8 %105, 1
  %107 = xor i8 %106, 1
  store i8 %107, i8* %21, align 1, !tbaa !2446
  %108 = xor i32 %100, %99
  %109 = lshr i32 %108, 4
  %110 = trunc i32 %109 to i8
  %111 = and i8 %110, 1
  store i8 %111, i8* %26, align 1, !tbaa !2447
  %112 = icmp eq i32 %100, 0
  %113 = zext i1 %112 to i8
  store i8 %113, i8* %29, align 1, !tbaa !2448
  %114 = lshr i32 %100, 31
  %115 = trunc i32 %114 to i8
  store i8 %115, i8* %32, align 1, !tbaa !2449
  %116 = lshr i32 %99, 31
  %117 = xor i32 %114, %116
  %118 = add nuw nsw i32 %117, %116
  %119 = icmp eq i32 %118, 2
  %120 = zext i1 %119 to i8
  store i8 %120, i8* %38, align 1, !tbaa !2450
  %.v9 = select i1 %112, i64 10, i64 26
  %121 = add i64 %97, %.v9
  store i64 %121, i64* %PC, align 8, !tbaa !2428
  br i1 %112, label %block_4010e2, label %block_4010f7

block_4010f7:                                     ; preds = %block_4010d8, %block_40108e, %block_4010b3, %block_4010e2
  %.sink5 = phi i64 [ 5, %block_4010e2 ], [ 5, %block_4010d8 ], [ 36, %block_4010b3 ], [ 36, %block_40108e ]
  %MEMORY.0 = phi %struct.Memory* [ %253, %block_4010e2 ], [ %2, %block_4010d8 ], [ %210, %block_4010b3 ], [ %181, %block_40108e ]
  %122 = load i64, i64* %PC, align 8
  %123 = add i64 %122, %.sink5
  %124 = load i64, i64* %RSP, align 8
  %125 = add i64 %124, 32
  store i64 %125, i64* %RSP, align 8, !tbaa !2428
  %126 = icmp ugt i64 %124, -33
  %127 = zext i1 %126 to i8
  store i8 %127, i8* %14, align 1, !tbaa !2432
  %128 = trunc i64 %125 to i32
  %129 = and i32 %128, 255
  %130 = tail call i32 @llvm.ctpop.i32(i32 %129) #14
  %131 = trunc i32 %130 to i8
  %132 = and i8 %131, 1
  %133 = xor i8 %132, 1
  store i8 %133, i8* %21, align 1, !tbaa !2446
  %134 = xor i64 %125, %124
  %135 = lshr i64 %134, 4
  %136 = trunc i64 %135 to i8
  %137 = and i8 %136, 1
  store i8 %137, i8* %26, align 1, !tbaa !2447
  %138 = icmp eq i64 %125, 0
  %139 = zext i1 %138 to i8
  store i8 %139, i8* %29, align 1, !tbaa !2448
  %140 = lshr i64 %125, 63
  %141 = trunc i64 %140 to i8
  store i8 %141, i8* %32, align 1, !tbaa !2449
  %142 = lshr i64 %124, 63
  %143 = xor i64 %140, %142
  %144 = add nuw nsw i64 %143, %140
  %145 = icmp eq i64 %144, 2
  %146 = zext i1 %145 to i8
  store i8 %146, i8* %38, align 1, !tbaa !2450
  %147 = add i64 %123, 5
  store i64 %147, i64* %PC, align 8
  %148 = add i64 %124, 40
  %149 = inttoptr i64 %125 to i64*
  %150 = load i64, i64* %149, align 8
  store i64 %150, i64* %RBP, align 8, !tbaa !2428
  store i64 %148, i64* %RSP, align 8, !tbaa !2428
  %151 = add i64 %123, 6
  store i64 %151, i64* %PC, align 8
  %152 = inttoptr i64 %148 to i64*
  %153 = load i64, i64* %152, align 8
  store i64 %153, i64* %PC, align 8, !tbaa !2428
  %154 = add i64 %124, 48
  store i64 %154, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_40108e:                                     ; preds = %block_401084
  %155 = add i64 %225, 354
  %156 = add i64 %225, 16
  %157 = load i64, i64* %RSP, align 8, !tbaa !2428
  %158 = add i64 %157, -8
  %159 = inttoptr i64 %158 to i64*
  store i64 %156, i64* %159, align 8
  store i64 %158, i64* %RSP, align 8, !tbaa !2428
  store i64 %155, i64* %PC, align 8, !tbaa !2428
  %160 = tail call %struct.Memory* @sub_4011f0_bitrv2_renamed_(%struct.State* nonnull %0, i64 %155, %struct.Memory* %2)
  %161 = load i64, i64* %RBP, align 8
  %162 = add i64 %161, -4
  %163 = load i64, i64* %PC, align 8
  %164 = add i64 %163, 3
  store i64 %164, i64* %PC, align 8
  %165 = inttoptr i64 %162 to i32*
  %166 = load i32, i32* %165, align 4
  %167 = zext i32 %166 to i64
  store i64 %167, i64* %RDI, align 8, !tbaa !2428
  %168 = add i64 %161, -16
  %169 = add i64 %163, 7
  store i64 %169, i64* %PC, align 8
  %170 = inttoptr i64 %168 to i64*
  %171 = load i64, i64* %170, align 8
  store i64 %171, i64* %RSI, align 8, !tbaa !2428
  %172 = add i64 %161, -32
  %173 = add i64 %163, 11
  store i64 %173, i64* %PC, align 8
  %174 = inttoptr i64 %172 to i64*
  %175 = load i64, i64* %174, align 8
  store i64 %175, i64* %RDX, align 8, !tbaa !2428
  %176 = add i64 %163, 2002
  %177 = add i64 %163, 16
  %178 = load i64, i64* %RSP, align 8, !tbaa !2428
  %179 = add i64 %178, -8
  %180 = inttoptr i64 %179 to i64*
  store i64 %177, i64* %180, align 8
  store i64 %179, i64* %RSP, align 8, !tbaa !2428
  store i64 %176, i64* %PC, align 8, !tbaa !2428
  %181 = tail call %struct.Memory* @sub_401870_cftfsub_renamed_(%struct.State* nonnull %0, i64 %176, %struct.Memory* %160)
  %182 = load i64, i64* %PC, align 8
  %183 = add i64 %182, 37
  store i64 %183, i64* %PC, align 8, !tbaa !2428
  br label %block_4010f7

block_4010b3:                                     ; preds = %block_401084
  %184 = add i64 %225, 2909
  %185 = add i64 %225, 16
  %186 = load i64, i64* %RSP, align 8, !tbaa !2428
  %187 = add i64 %186, -8
  %188 = inttoptr i64 %187 to i64*
  store i64 %185, i64* %188, align 8
  store i64 %187, i64* %RSP, align 8, !tbaa !2428
  store i64 %184, i64* %PC, align 8, !tbaa !2428
  %189 = tail call %struct.Memory* @sub_401c10_bitrv2conj_renamed_(%struct.State* nonnull %0, i64 %184, %struct.Memory* %2)
  %190 = load i64, i64* %RBP, align 8
  %191 = add i64 %190, -4
  %192 = load i64, i64* %PC, align 8
  %193 = add i64 %192, 3
  store i64 %193, i64* %PC, align 8
  %194 = inttoptr i64 %191 to i32*
  %195 = load i32, i32* %194, align 4
  %196 = zext i32 %195 to i64
  store i64 %196, i64* %RDI, align 8, !tbaa !2428
  %197 = add i64 %190, -16
  %198 = add i64 %192, 7
  store i64 %198, i64* %PC, align 8
  %199 = inttoptr i64 %197 to i64*
  %200 = load i64, i64* %199, align 8
  store i64 %200, i64* %RSI, align 8, !tbaa !2428
  %201 = add i64 %190, -32
  %202 = add i64 %192, 11
  store i64 %202, i64* %PC, align 8
  %203 = inttoptr i64 %201 to i64*
  %204 = load i64, i64* %203, align 8
  store i64 %204, i64* %RDX, align 8, !tbaa !2428
  %205 = add i64 %192, 5101
  %206 = add i64 %192, 16
  %207 = load i64, i64* %RSP, align 8, !tbaa !2428
  %208 = add i64 %207, -8
  %209 = inttoptr i64 %208 to i64*
  store i64 %206, i64* %209, align 8
  store i64 %208, i64* %RSP, align 8, !tbaa !2428
  store i64 %205, i64* %PC, align 8, !tbaa !2428
  %210 = tail call %struct.Memory* @sub_4024b0_cftbsub_renamed_(%struct.State* nonnull %0, i64 %205, %struct.Memory* %189)
  br label %block_4010f7

block_401084:                                     ; preds = %block_401060
  %211 = add i64 %67, -8
  %212 = add i64 %97, 4
  store i64 %212, i64* %PC, align 8
  %213 = inttoptr i64 %211 to i32*
  %214 = load i32, i32* %213, align 4
  store i8 0, i8* %14, align 1, !tbaa !2432
  %215 = and i32 %214, 255
  %216 = tail call i32 @llvm.ctpop.i32(i32 %215) #14
  %217 = trunc i32 %216 to i8
  %218 = and i8 %217, 1
  %219 = xor i8 %218, 1
  store i8 %219, i8* %21, align 1, !tbaa !2446
  store i8 0, i8* %26, align 1, !tbaa !2447
  %220 = icmp eq i32 %214, 0
  %221 = zext i1 %220 to i8
  store i8 %221, i8* %29, align 1, !tbaa !2448
  %222 = lshr i32 %214, 31
  %223 = trunc i32 %222 to i8
  store i8 %223, i8* %32, align 1, !tbaa !2449
  store i8 0, i8* %38, align 1, !tbaa !2450
  %224 = icmp ne i8 %223, 0
  %.v = select i1 %224, i64 43, i64 6
  %225 = add i64 %212, %.v
  %226 = add i64 %225, 3
  store i64 %226, i64* %PC, align 8
  %227 = load i32, i32* %71, align 4
  %228 = zext i32 %227 to i64
  store i64 %228, i64* %RDI, align 8, !tbaa !2428
  %229 = add i64 %67, -24
  %230 = add i64 %225, 7
  store i64 %230, i64* %PC, align 8
  %231 = inttoptr i64 %229 to i64*
  %232 = load i64, i64* %231, align 8
  store i64 %232, i64* %RSI, align 8, !tbaa !2428
  %233 = add i64 %67, -16
  %234 = add i64 %225, 11
  store i64 %234, i64* %PC, align 8
  %235 = inttoptr i64 %233 to i64*
  %236 = load i64, i64* %235, align 8
  store i64 %236, i64* %RDX, align 8, !tbaa !2428
  br i1 %224, label %block_4010b3, label %block_40108e

block_4010e2:                                     ; preds = %block_4010d8
  %237 = add i64 %121, 3
  store i64 %237, i64* %PC, align 8
  %238 = load i32, i32* %71, align 4
  %239 = zext i32 %238 to i64
  store i64 %239, i64* %RDI, align 8, !tbaa !2428
  %240 = add i64 %67, -16
  %241 = add i64 %121, 7
  store i64 %241, i64* %PC, align 8
  %242 = inttoptr i64 %240 to i64*
  %243 = load i64, i64* %242, align 8
  store i64 %243, i64* %RSI, align 8, !tbaa !2428
  %244 = add i64 %67, -32
  %245 = add i64 %121, 11
  store i64 %245, i64* %PC, align 8
  %246 = inttoptr i64 %244 to i64*
  %247 = load i64, i64* %246, align 8
  store i64 %247, i64* %RDX, align 8, !tbaa !2428
  %248 = add i64 %121, 1934
  %249 = add i64 %121, 16
  %250 = load i64, i64* %RSP, align 8, !tbaa !2428
  %251 = add i64 %250, -8
  %252 = inttoptr i64 %251 to i64*
  store i64 %249, i64* %252, align 8
  store i64 %251, i64* %RSP, align 8, !tbaa !2428
  store i64 %248, i64* %PC, align 8, !tbaa !2428
  %253 = tail call %struct.Memory* @sub_401870_cftfsub_renamed_(%struct.State* nonnull %0, i64 %248, %struct.Memory* %2)
  br label %block_4010f7
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_4028a0_cft1st(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_4028a0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %7 = load i64, i64* %RBP, align 8
  %8 = add i64 %1, 1
  store i64 %8, i64* %PC, align 8
  %9 = load i64, i64* %RSP, align 8, !tbaa !2428
  %10 = add i64 %9, -8
  %11 = inttoptr i64 %10 to i64*
  store i64 %7, i64* %11, align 8
  %12 = load i64, i64* %PC, align 8
  store i64 %10, i64* %RBP, align 8, !tbaa !2428
  %13 = add i64 %9, -32
  store i64 %13, i64* %RSP, align 8, !tbaa !2428
  %14 = icmp ult i64 %10, 24
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1, !tbaa !2432
  %17 = trunc i64 %13 to i32
  %18 = and i32 %17, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18) #14
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1, !tbaa !2446
  %24 = xor i64 %10, 16
  %25 = xor i64 %24, %13
  %26 = lshr i64 %25, 4
  %27 = trunc i64 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1, !tbaa !2447
  %30 = icmp eq i64 %13, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1, !tbaa !2448
  %33 = lshr i64 %13, 63
  %34 = trunc i64 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1, !tbaa !2449
  %36 = lshr i64 %10, 63
  %37 = xor i64 %33, %36
  %38 = add nuw nsw i64 %37, %36
  %39 = icmp eq i64 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1, !tbaa !2450
  %42 = add i64 %9, -12
  %43 = load i32, i32* %EDI, align 4
  %44 = add i64 %12, 10
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %42 to i32*
  store i32 %43, i32* %45, align 4
  %46 = load i64, i64* %RBP, align 8
  %47 = add i64 %46, -16
  %48 = load i64, i64* %RSI, align 8
  %49 = load i64, i64* %PC, align 8
  %50 = add i64 %49, 4
  store i64 %50, i64* %PC, align 8
  %51 = inttoptr i64 %47 to i64*
  store i64 %48, i64* %51, align 8
  %52 = load i64, i64* %RBP, align 8
  %53 = add i64 %52, -24
  %54 = load i64, i64* %RDX, align 8
  %55 = load i64, i64* %PC, align 8
  %56 = add i64 %55, 4
  store i64 %56, i64* %PC, align 8
  %57 = inttoptr i64 %53 to i64*
  store i64 %54, i64* %57, align 8
  %58 = load i64, i64* %RBP, align 8
  %59 = add i64 %58, -16
  %60 = load i64, i64* %PC, align 8
  %61 = add i64 %60, 4
  store i64 %61, i64* %PC, align 8
  %62 = inttoptr i64 %59 to i64*
  %63 = load i64, i64* %62, align 8
  store i64 %63, i64* %RDX, align 8, !tbaa !2428
  %64 = add i64 %60, 8
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %63 to i64*
  %66 = load i64, i64* %65, align 8
  %67 = bitcast [32 x %union.VectorReg]* %4 to double*
  %68 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %66, i64* %68, align 1, !tbaa !2451
  %69 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %70 = bitcast i64* %69 to double*
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %71 = add i64 %60, 12
  store i64 %71, i64* %PC, align 8
  %72 = load i64, i64* %62, align 8
  store i64 %72, i64* %RDX, align 8, !tbaa !2428
  %73 = add i64 %72, 16
  %74 = add i64 %60, 17
  store i64 %74, i64* %PC, align 8
  %75 = bitcast i64 %66 to double
  %76 = inttoptr i64 %73 to double*
  %77 = load double, double* %76, align 8
  %78 = fadd double %75, %77
  store double %78, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %79 = add i64 %58, -96
  %80 = add i64 %60, 22
  store i64 %80, i64* %PC, align 8
  %81 = inttoptr i64 %79 to double*
  store double %78, double* %81, align 8
  %82 = load i64, i64* %RBP, align 8
  %83 = add i64 %82, -16
  %84 = load i64, i64* %PC, align 8
  %85 = add i64 %84, 4
  store i64 %85, i64* %PC, align 8
  %86 = inttoptr i64 %83 to i64*
  %87 = load i64, i64* %86, align 8
  store i64 %87, i64* %RDX, align 8, !tbaa !2428
  %88 = add i64 %87, 8
  %89 = add i64 %84, 9
  store i64 %89, i64* %PC, align 8
  %90 = inttoptr i64 %88 to i64*
  %91 = load i64, i64* %90, align 8
  store i64 %91, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %92 = add i64 %84, 13
  store i64 %92, i64* %PC, align 8
  %93 = load i64, i64* %86, align 8
  store i64 %93, i64* %RDX, align 8, !tbaa !2428
  %94 = add i64 %93, 24
  %95 = add i64 %84, 18
  store i64 %95, i64* %PC, align 8
  %96 = bitcast i64 %91 to double
  %97 = inttoptr i64 %94 to double*
  %98 = load double, double* %97, align 8
  %99 = fadd double %96, %98
  store double %99, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %100 = add i64 %82, -104
  %101 = add i64 %84, 23
  store i64 %101, i64* %PC, align 8
  %102 = inttoptr i64 %100 to double*
  store double %99, double* %102, align 8
  %103 = load i64, i64* %RBP, align 8
  %104 = add i64 %103, -16
  %105 = load i64, i64* %PC, align 8
  %106 = add i64 %105, 4
  store i64 %106, i64* %PC, align 8
  %107 = inttoptr i64 %104 to i64*
  %108 = load i64, i64* %107, align 8
  store i64 %108, i64* %RDX, align 8, !tbaa !2428
  %109 = add i64 %105, 8
  store i64 %109, i64* %PC, align 8
  %110 = inttoptr i64 %108 to i64*
  %111 = load i64, i64* %110, align 8
  store i64 %111, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %112 = add i64 %105, 12
  store i64 %112, i64* %PC, align 8
  %113 = load i64, i64* %107, align 8
  store i64 %113, i64* %RDX, align 8, !tbaa !2428
  %114 = add i64 %113, 16
  %115 = add i64 %105, 17
  store i64 %115, i64* %PC, align 8
  %116 = bitcast i64 %111 to double
  %117 = inttoptr i64 %114 to double*
  %118 = load double, double* %117, align 8
  %119 = fsub double %116, %118
  store double %119, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %120 = add i64 %103, -112
  %121 = add i64 %105, 22
  store i64 %121, i64* %PC, align 8
  %122 = inttoptr i64 %120 to double*
  store double %119, double* %122, align 8
  %123 = load i64, i64* %RBP, align 8
  %124 = add i64 %123, -16
  %125 = load i64, i64* %PC, align 8
  %126 = add i64 %125, 4
  store i64 %126, i64* %PC, align 8
  %127 = inttoptr i64 %124 to i64*
  %128 = load i64, i64* %127, align 8
  store i64 %128, i64* %RDX, align 8, !tbaa !2428
  %129 = add i64 %128, 8
  %130 = add i64 %125, 9
  store i64 %130, i64* %PC, align 8
  %131 = inttoptr i64 %129 to i64*
  %132 = load i64, i64* %131, align 8
  store i64 %132, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %133 = add i64 %125, 13
  store i64 %133, i64* %PC, align 8
  %134 = load i64, i64* %127, align 8
  store i64 %134, i64* %RDX, align 8, !tbaa !2428
  %135 = add i64 %134, 24
  %136 = add i64 %125, 18
  store i64 %136, i64* %PC, align 8
  %137 = bitcast i64 %132 to double
  %138 = inttoptr i64 %135 to double*
  %139 = load double, double* %138, align 8
  %140 = fsub double %137, %139
  store double %140, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %141 = add i64 %123, -120
  %142 = add i64 %125, 23
  store i64 %142, i64* %PC, align 8
  %143 = inttoptr i64 %141 to double*
  store double %140, double* %143, align 8
  %144 = load i64, i64* %RBP, align 8
  %145 = add i64 %144, -16
  %146 = load i64, i64* %PC, align 8
  %147 = add i64 %146, 4
  store i64 %147, i64* %PC, align 8
  %148 = inttoptr i64 %145 to i64*
  %149 = load i64, i64* %148, align 8
  store i64 %149, i64* %RDX, align 8, !tbaa !2428
  %150 = add i64 %149, 32
  %151 = add i64 %146, 9
  store i64 %151, i64* %PC, align 8
  %152 = inttoptr i64 %150 to i64*
  %153 = load i64, i64* %152, align 8
  store i64 %153, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %154 = add i64 %146, 13
  store i64 %154, i64* %PC, align 8
  %155 = load i64, i64* %148, align 8
  store i64 %155, i64* %RDX, align 8, !tbaa !2428
  %156 = add i64 %155, 48
  %157 = add i64 %146, 18
  store i64 %157, i64* %PC, align 8
  %158 = bitcast i64 %153 to double
  %159 = inttoptr i64 %156 to double*
  %160 = load double, double* %159, align 8
  %161 = fadd double %158, %160
  store double %161, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %162 = add i64 %144, -128
  %163 = add i64 %146, 23
  store i64 %163, i64* %PC, align 8
  %164 = inttoptr i64 %162 to double*
  store double %161, double* %164, align 8
  %165 = load i64, i64* %RBP, align 8
  %166 = add i64 %165, -16
  %167 = load i64, i64* %PC, align 8
  %168 = add i64 %167, 4
  store i64 %168, i64* %PC, align 8
  %169 = inttoptr i64 %166 to i64*
  %170 = load i64, i64* %169, align 8
  store i64 %170, i64* %RDX, align 8, !tbaa !2428
  %171 = add i64 %170, 40
  %172 = add i64 %167, 9
  store i64 %172, i64* %PC, align 8
  %173 = inttoptr i64 %171 to i64*
  %174 = load i64, i64* %173, align 8
  store i64 %174, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %175 = add i64 %167, 13
  store i64 %175, i64* %PC, align 8
  %176 = load i64, i64* %169, align 8
  store i64 %176, i64* %RDX, align 8, !tbaa !2428
  %177 = add i64 %176, 56
  %178 = add i64 %167, 18
  store i64 %178, i64* %PC, align 8
  %179 = bitcast i64 %174 to double
  %180 = inttoptr i64 %177 to double*
  %181 = load double, double* %180, align 8
  %182 = fadd double %179, %181
  store double %182, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %183 = add i64 %165, -136
  %184 = add i64 %167, 26
  store i64 %184, i64* %PC, align 8
  %185 = inttoptr i64 %183 to double*
  store double %182, double* %185, align 8
  %186 = load i64, i64* %RBP, align 8
  %187 = add i64 %186, -16
  %188 = load i64, i64* %PC, align 8
  %189 = add i64 %188, 4
  store i64 %189, i64* %PC, align 8
  %190 = inttoptr i64 %187 to i64*
  %191 = load i64, i64* %190, align 8
  store i64 %191, i64* %RDX, align 8, !tbaa !2428
  %192 = add i64 %191, 32
  %193 = add i64 %188, 9
  store i64 %193, i64* %PC, align 8
  %194 = inttoptr i64 %192 to i64*
  %195 = load i64, i64* %194, align 8
  store i64 %195, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %196 = add i64 %188, 13
  store i64 %196, i64* %PC, align 8
  %197 = load i64, i64* %190, align 8
  store i64 %197, i64* %RDX, align 8, !tbaa !2428
  %198 = add i64 %197, 48
  %199 = add i64 %188, 18
  store i64 %199, i64* %PC, align 8
  %200 = bitcast i64 %195 to double
  %201 = inttoptr i64 %198 to double*
  %202 = load double, double* %201, align 8
  %203 = fsub double %200, %202
  store double %203, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %204 = add i64 %186, -144
  %205 = add i64 %188, 26
  store i64 %205, i64* %PC, align 8
  %206 = inttoptr i64 %204 to double*
  store double %203, double* %206, align 8
  %207 = load i64, i64* %RBP, align 8
  %208 = add i64 %207, -16
  %209 = load i64, i64* %PC, align 8
  %210 = add i64 %209, 4
  store i64 %210, i64* %PC, align 8
  %211 = inttoptr i64 %208 to i64*
  %212 = load i64, i64* %211, align 8
  store i64 %212, i64* %RDX, align 8, !tbaa !2428
  %213 = add i64 %212, 40
  %214 = add i64 %209, 9
  store i64 %214, i64* %PC, align 8
  %215 = inttoptr i64 %213 to i64*
  %216 = load i64, i64* %215, align 8
  store i64 %216, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %217 = add i64 %209, 13
  store i64 %217, i64* %PC, align 8
  %218 = load i64, i64* %211, align 8
  store i64 %218, i64* %RDX, align 8, !tbaa !2428
  %219 = add i64 %218, 56
  %220 = add i64 %209, 18
  store i64 %220, i64* %PC, align 8
  %221 = bitcast i64 %216 to double
  %222 = inttoptr i64 %219 to double*
  %223 = load double, double* %222, align 8
  %224 = fsub double %221, %223
  store double %224, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %225 = add i64 %207, -152
  %226 = add i64 %209, 26
  store i64 %226, i64* %PC, align 8
  %227 = inttoptr i64 %225 to double*
  store double %224, double* %227, align 8
  %228 = load i64, i64* %RBP, align 8
  %229 = add i64 %228, -96
  %230 = load i64, i64* %PC, align 8
  %231 = add i64 %230, 5
  store i64 %231, i64* %PC, align 8
  %232 = inttoptr i64 %229 to i64*
  %233 = load i64, i64* %232, align 8
  store i64 %233, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %234 = add i64 %228, -128
  %235 = add i64 %230, 10
  store i64 %235, i64* %PC, align 8
  %236 = bitcast i64 %233 to double
  %237 = inttoptr i64 %234 to double*
  %238 = load double, double* %237, align 8
  %239 = fadd double %236, %238
  store double %239, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %240 = add i64 %228, -16
  %241 = add i64 %230, 14
  store i64 %241, i64* %PC, align 8
  %242 = inttoptr i64 %240 to i64*
  %243 = load i64, i64* %242, align 8
  store i64 %243, i64* %RDX, align 8, !tbaa !2428
  %244 = add i64 %230, 18
  store i64 %244, i64* %PC, align 8
  %245 = inttoptr i64 %243 to double*
  store double %239, double* %245, align 8
  %246 = load i64, i64* %RBP, align 8
  %247 = add i64 %246, -104
  %248 = load i64, i64* %PC, align 8
  %249 = add i64 %248, 5
  store i64 %249, i64* %PC, align 8
  %250 = inttoptr i64 %247 to i64*
  %251 = load i64, i64* %250, align 8
  store i64 %251, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %252 = add i64 %246, -136
  %253 = add i64 %248, 13
  store i64 %253, i64* %PC, align 8
  %254 = bitcast i64 %251 to double
  %255 = inttoptr i64 %252 to double*
  %256 = load double, double* %255, align 8
  %257 = fadd double %254, %256
  store double %257, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %258 = add i64 %246, -16
  %259 = add i64 %248, 17
  store i64 %259, i64* %PC, align 8
  %260 = inttoptr i64 %258 to i64*
  %261 = load i64, i64* %260, align 8
  store i64 %261, i64* %RDX, align 8, !tbaa !2428
  %262 = add i64 %261, 8
  %263 = add i64 %248, 22
  store i64 %263, i64* %PC, align 8
  %264 = inttoptr i64 %262 to double*
  store double %257, double* %264, align 8
  %265 = load i64, i64* %RBP, align 8
  %266 = add i64 %265, -96
  %267 = load i64, i64* %PC, align 8
  %268 = add i64 %267, 5
  store i64 %268, i64* %PC, align 8
  %269 = inttoptr i64 %266 to i64*
  %270 = load i64, i64* %269, align 8
  store i64 %270, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %271 = add i64 %265, -128
  %272 = add i64 %267, 10
  store i64 %272, i64* %PC, align 8
  %273 = bitcast i64 %270 to double
  %274 = inttoptr i64 %271 to double*
  %275 = load double, double* %274, align 8
  %276 = fsub double %273, %275
  store double %276, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %277 = add i64 %265, -16
  %278 = add i64 %267, 14
  store i64 %278, i64* %PC, align 8
  %279 = inttoptr i64 %277 to i64*
  %280 = load i64, i64* %279, align 8
  store i64 %280, i64* %RDX, align 8, !tbaa !2428
  %281 = add i64 %280, 32
  %282 = add i64 %267, 19
  store i64 %282, i64* %PC, align 8
  %283 = inttoptr i64 %281 to double*
  store double %276, double* %283, align 8
  %284 = load i64, i64* %RBP, align 8
  %285 = add i64 %284, -104
  %286 = load i64, i64* %PC, align 8
  %287 = add i64 %286, 5
  store i64 %287, i64* %PC, align 8
  %288 = inttoptr i64 %285 to i64*
  %289 = load i64, i64* %288, align 8
  store i64 %289, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %290 = add i64 %284, -136
  %291 = add i64 %286, 13
  store i64 %291, i64* %PC, align 8
  %292 = bitcast i64 %289 to double
  %293 = inttoptr i64 %290 to double*
  %294 = load double, double* %293, align 8
  %295 = fsub double %292, %294
  store double %295, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %296 = add i64 %284, -16
  %297 = add i64 %286, 17
  store i64 %297, i64* %PC, align 8
  %298 = inttoptr i64 %296 to i64*
  %299 = load i64, i64* %298, align 8
  store i64 %299, i64* %RDX, align 8, !tbaa !2428
  %300 = add i64 %299, 40
  %301 = add i64 %286, 22
  store i64 %301, i64* %PC, align 8
  %302 = inttoptr i64 %300 to double*
  store double %295, double* %302, align 8
  %303 = load i64, i64* %RBP, align 8
  %304 = add i64 %303, -112
  %305 = load i64, i64* %PC, align 8
  %306 = add i64 %305, 5
  store i64 %306, i64* %PC, align 8
  %307 = inttoptr i64 %304 to i64*
  %308 = load i64, i64* %307, align 8
  store i64 %308, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %309 = add i64 %303, -152
  %310 = add i64 %305, 13
  store i64 %310, i64* %PC, align 8
  %311 = bitcast i64 %308 to double
  %312 = inttoptr i64 %309 to double*
  %313 = load double, double* %312, align 8
  %314 = fsub double %311, %313
  store double %314, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %315 = add i64 %303, -16
  %316 = add i64 %305, 17
  store i64 %316, i64* %PC, align 8
  %317 = inttoptr i64 %315 to i64*
  %318 = load i64, i64* %317, align 8
  store i64 %318, i64* %RDX, align 8, !tbaa !2428
  %319 = add i64 %318, 16
  %320 = add i64 %305, 22
  store i64 %320, i64* %PC, align 8
  %321 = inttoptr i64 %319 to double*
  store double %314, double* %321, align 8
  %322 = load i64, i64* %RBP, align 8
  %323 = add i64 %322, -120
  %324 = load i64, i64* %PC, align 8
  %325 = add i64 %324, 5
  store i64 %325, i64* %PC, align 8
  %326 = inttoptr i64 %323 to i64*
  %327 = load i64, i64* %326, align 8
  store i64 %327, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %328 = add i64 %322, -144
  %329 = add i64 %324, 13
  store i64 %329, i64* %PC, align 8
  %330 = bitcast i64 %327 to double
  %331 = inttoptr i64 %328 to double*
  %332 = load double, double* %331, align 8
  %333 = fadd double %330, %332
  store double %333, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %334 = add i64 %322, -16
  %335 = add i64 %324, 17
  store i64 %335, i64* %PC, align 8
  %336 = inttoptr i64 %334 to i64*
  %337 = load i64, i64* %336, align 8
  store i64 %337, i64* %RDX, align 8, !tbaa !2428
  %338 = add i64 %337, 24
  %339 = add i64 %324, 22
  store i64 %339, i64* %PC, align 8
  %340 = inttoptr i64 %338 to double*
  store double %333, double* %340, align 8
  %341 = load i64, i64* %RBP, align 8
  %342 = add i64 %341, -112
  %343 = load i64, i64* %PC, align 8
  %344 = add i64 %343, 5
  store i64 %344, i64* %PC, align 8
  %345 = inttoptr i64 %342 to i64*
  %346 = load i64, i64* %345, align 8
  store i64 %346, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %347 = add i64 %341, -152
  %348 = add i64 %343, 13
  store i64 %348, i64* %PC, align 8
  %349 = bitcast i64 %346 to double
  %350 = inttoptr i64 %347 to double*
  %351 = load double, double* %350, align 8
  %352 = fadd double %349, %351
  store double %352, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %353 = add i64 %341, -16
  %354 = add i64 %343, 17
  store i64 %354, i64* %PC, align 8
  %355 = inttoptr i64 %353 to i64*
  %356 = load i64, i64* %355, align 8
  store i64 %356, i64* %RDX, align 8, !tbaa !2428
  %357 = add i64 %356, 48
  %358 = add i64 %343, 22
  store i64 %358, i64* %PC, align 8
  %359 = inttoptr i64 %357 to double*
  store double %352, double* %359, align 8
  %360 = load i64, i64* %RBP, align 8
  %361 = add i64 %360, -120
  %362 = load i64, i64* %PC, align 8
  %363 = add i64 %362, 5
  store i64 %363, i64* %PC, align 8
  %364 = inttoptr i64 %361 to i64*
  %365 = load i64, i64* %364, align 8
  store i64 %365, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %366 = add i64 %360, -144
  %367 = add i64 %362, 13
  store i64 %367, i64* %PC, align 8
  %368 = bitcast i64 %365 to double
  %369 = inttoptr i64 %366 to double*
  %370 = load double, double* %369, align 8
  %371 = fsub double %368, %370
  store double %371, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %372 = add i64 %360, -16
  %373 = add i64 %362, 17
  store i64 %373, i64* %PC, align 8
  %374 = inttoptr i64 %372 to i64*
  %375 = load i64, i64* %374, align 8
  store i64 %375, i64* %RDX, align 8, !tbaa !2428
  %376 = add i64 %375, 56
  %377 = add i64 %362, 22
  store i64 %377, i64* %PC, align 8
  %378 = inttoptr i64 %376 to double*
  store double %371, double* %378, align 8
  %379 = load i64, i64* %RBP, align 8
  %380 = add i64 %379, -24
  %381 = load i64, i64* %PC, align 8
  %382 = add i64 %381, 4
  store i64 %382, i64* %PC, align 8
  %383 = inttoptr i64 %380 to i64*
  %384 = load i64, i64* %383, align 8
  store i64 %384, i64* %RDX, align 8, !tbaa !2428
  %385 = add i64 %384, 16
  %386 = add i64 %381, 9
  store i64 %386, i64* %PC, align 8
  %387 = inttoptr i64 %385 to i64*
  %388 = load i64, i64* %387, align 8
  store i64 %388, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %389 = add i64 %379, -48
  %390 = add i64 %381, 14
  store i64 %390, i64* %PC, align 8
  %391 = inttoptr i64 %389 to i64*
  store i64 %388, i64* %391, align 8
  %392 = load i64, i64* %RBP, align 8
  %393 = add i64 %392, -16
  %394 = load i64, i64* %PC, align 8
  %395 = add i64 %394, 4
  store i64 %395, i64* %PC, align 8
  %396 = inttoptr i64 %393 to i64*
  %397 = load i64, i64* %396, align 8
  store i64 %397, i64* %RDX, align 8, !tbaa !2428
  %398 = add i64 %397, 64
  %399 = add i64 %394, 9
  store i64 %399, i64* %PC, align 8
  %400 = inttoptr i64 %398 to i64*
  %401 = load i64, i64* %400, align 8
  store i64 %401, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %402 = add i64 %394, 13
  store i64 %402, i64* %PC, align 8
  %403 = load i64, i64* %396, align 8
  store i64 %403, i64* %RDX, align 8, !tbaa !2428
  %404 = add i64 %403, 80
  %405 = add i64 %394, 18
  store i64 %405, i64* %PC, align 8
  %406 = bitcast i64 %401 to double
  %407 = inttoptr i64 %404 to double*
  %408 = load double, double* %407, align 8
  %409 = fadd double %406, %408
  store double %409, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %410 = add i64 %392, -96
  %411 = add i64 %394, 23
  store i64 %411, i64* %PC, align 8
  %412 = inttoptr i64 %410 to double*
  store double %409, double* %412, align 8
  %413 = load i64, i64* %RBP, align 8
  %414 = add i64 %413, -16
  %415 = load i64, i64* %PC, align 8
  %416 = add i64 %415, 4
  store i64 %416, i64* %PC, align 8
  %417 = inttoptr i64 %414 to i64*
  %418 = load i64, i64* %417, align 8
  store i64 %418, i64* %RDX, align 8, !tbaa !2428
  %419 = add i64 %418, 72
  %420 = add i64 %415, 9
  store i64 %420, i64* %PC, align 8
  %421 = inttoptr i64 %419 to i64*
  %422 = load i64, i64* %421, align 8
  store i64 %422, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %423 = add i64 %415, 13
  store i64 %423, i64* %PC, align 8
  %424 = load i64, i64* %417, align 8
  store i64 %424, i64* %RDX, align 8, !tbaa !2428
  %425 = add i64 %424, 88
  %426 = add i64 %415, 18
  store i64 %426, i64* %PC, align 8
  %427 = bitcast i64 %422 to double
  %428 = inttoptr i64 %425 to double*
  %429 = load double, double* %428, align 8
  %430 = fadd double %427, %429
  store double %430, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %431 = add i64 %413, -104
  %432 = add i64 %415, 23
  store i64 %432, i64* %PC, align 8
  %433 = inttoptr i64 %431 to double*
  store double %430, double* %433, align 8
  %434 = load i64, i64* %RBP, align 8
  %435 = add i64 %434, -16
  %436 = load i64, i64* %PC, align 8
  %437 = add i64 %436, 4
  store i64 %437, i64* %PC, align 8
  %438 = inttoptr i64 %435 to i64*
  %439 = load i64, i64* %438, align 8
  store i64 %439, i64* %RDX, align 8, !tbaa !2428
  %440 = add i64 %439, 64
  %441 = add i64 %436, 9
  store i64 %441, i64* %PC, align 8
  %442 = inttoptr i64 %440 to i64*
  %443 = load i64, i64* %442, align 8
  store i64 %443, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %444 = add i64 %436, 13
  store i64 %444, i64* %PC, align 8
  %445 = load i64, i64* %438, align 8
  store i64 %445, i64* %RDX, align 8, !tbaa !2428
  %446 = add i64 %445, 80
  %447 = add i64 %436, 18
  store i64 %447, i64* %PC, align 8
  %448 = bitcast i64 %443 to double
  %449 = inttoptr i64 %446 to double*
  %450 = load double, double* %449, align 8
  %451 = fsub double %448, %450
  store double %451, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %452 = add i64 %434, -112
  %453 = add i64 %436, 23
  store i64 %453, i64* %PC, align 8
  %454 = inttoptr i64 %452 to double*
  store double %451, double* %454, align 8
  %455 = load i64, i64* %RBP, align 8
  %456 = add i64 %455, -16
  %457 = load i64, i64* %PC, align 8
  %458 = add i64 %457, 4
  store i64 %458, i64* %PC, align 8
  %459 = inttoptr i64 %456 to i64*
  %460 = load i64, i64* %459, align 8
  store i64 %460, i64* %RDX, align 8, !tbaa !2428
  %461 = add i64 %460, 72
  %462 = add i64 %457, 9
  store i64 %462, i64* %PC, align 8
  %463 = inttoptr i64 %461 to i64*
  %464 = load i64, i64* %463, align 8
  store i64 %464, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %465 = add i64 %457, 13
  store i64 %465, i64* %PC, align 8
  %466 = load i64, i64* %459, align 8
  store i64 %466, i64* %RDX, align 8, !tbaa !2428
  %467 = add i64 %466, 88
  %468 = add i64 %457, 18
  store i64 %468, i64* %PC, align 8
  %469 = bitcast i64 %464 to double
  %470 = inttoptr i64 %467 to double*
  %471 = load double, double* %470, align 8
  %472 = fsub double %469, %471
  store double %472, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %473 = add i64 %455, -120
  %474 = add i64 %457, 23
  store i64 %474, i64* %PC, align 8
  %475 = inttoptr i64 %473 to double*
  store double %472, double* %475, align 8
  %476 = load i64, i64* %RBP, align 8
  %477 = add i64 %476, -16
  %478 = load i64, i64* %PC, align 8
  %479 = add i64 %478, 4
  store i64 %479, i64* %PC, align 8
  %480 = inttoptr i64 %477 to i64*
  %481 = load i64, i64* %480, align 8
  store i64 %481, i64* %RDX, align 8, !tbaa !2428
  %482 = add i64 %481, 96
  %483 = add i64 %478, 9
  store i64 %483, i64* %PC, align 8
  %484 = inttoptr i64 %482 to i64*
  %485 = load i64, i64* %484, align 8
  store i64 %485, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %486 = add i64 %478, 13
  store i64 %486, i64* %PC, align 8
  %487 = load i64, i64* %480, align 8
  store i64 %487, i64* %RDX, align 8, !tbaa !2428
  %488 = add i64 %487, 112
  %489 = add i64 %478, 18
  store i64 %489, i64* %PC, align 8
  %490 = bitcast i64 %485 to double
  %491 = inttoptr i64 %488 to double*
  %492 = load double, double* %491, align 8
  %493 = fadd double %490, %492
  store double %493, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %494 = add i64 %476, -128
  %495 = add i64 %478, 23
  store i64 %495, i64* %PC, align 8
  %496 = inttoptr i64 %494 to double*
  store double %493, double* %496, align 8
  %497 = load i64, i64* %RBP, align 8
  %498 = add i64 %497, -16
  %499 = load i64, i64* %PC, align 8
  %500 = add i64 %499, 4
  store i64 %500, i64* %PC, align 8
  %501 = inttoptr i64 %498 to i64*
  %502 = load i64, i64* %501, align 8
  store i64 %502, i64* %RDX, align 8, !tbaa !2428
  %503 = add i64 %502, 104
  %504 = add i64 %499, 9
  store i64 %504, i64* %PC, align 8
  %505 = inttoptr i64 %503 to i64*
  %506 = load i64, i64* %505, align 8
  store i64 %506, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %507 = add i64 %499, 13
  store i64 %507, i64* %PC, align 8
  %508 = load i64, i64* %501, align 8
  store i64 %508, i64* %RDX, align 8, !tbaa !2428
  %509 = add i64 %508, 120
  %510 = add i64 %499, 18
  store i64 %510, i64* %PC, align 8
  %511 = bitcast i64 %506 to double
  %512 = inttoptr i64 %509 to double*
  %513 = load double, double* %512, align 8
  %514 = fadd double %511, %513
  store double %514, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %515 = add i64 %497, -136
  %516 = add i64 %499, 26
  store i64 %516, i64* %PC, align 8
  %517 = inttoptr i64 %515 to double*
  store double %514, double* %517, align 8
  %518 = load i64, i64* %RBP, align 8
  %519 = add i64 %518, -16
  %520 = load i64, i64* %PC, align 8
  %521 = add i64 %520, 4
  store i64 %521, i64* %PC, align 8
  %522 = inttoptr i64 %519 to i64*
  %523 = load i64, i64* %522, align 8
  store i64 %523, i64* %RDX, align 8, !tbaa !2428
  %524 = add i64 %523, 96
  %525 = add i64 %520, 9
  store i64 %525, i64* %PC, align 8
  %526 = inttoptr i64 %524 to i64*
  %527 = load i64, i64* %526, align 8
  store i64 %527, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %528 = add i64 %520, 13
  store i64 %528, i64* %PC, align 8
  %529 = load i64, i64* %522, align 8
  store i64 %529, i64* %RDX, align 8, !tbaa !2428
  %530 = add i64 %529, 112
  %531 = add i64 %520, 18
  store i64 %531, i64* %PC, align 8
  %532 = bitcast i64 %527 to double
  %533 = inttoptr i64 %530 to double*
  %534 = load double, double* %533, align 8
  %535 = fsub double %532, %534
  store double %535, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %536 = add i64 %518, -144
  %537 = add i64 %520, 26
  store i64 %537, i64* %PC, align 8
  %538 = inttoptr i64 %536 to double*
  store double %535, double* %538, align 8
  %539 = load i64, i64* %RBP, align 8
  %540 = add i64 %539, -16
  %541 = load i64, i64* %PC, align 8
  %542 = add i64 %541, 4
  store i64 %542, i64* %PC, align 8
  %543 = inttoptr i64 %540 to i64*
  %544 = load i64, i64* %543, align 8
  store i64 %544, i64* %RDX, align 8, !tbaa !2428
  %545 = add i64 %544, 104
  %546 = add i64 %541, 9
  store i64 %546, i64* %PC, align 8
  %547 = inttoptr i64 %545 to i64*
  %548 = load i64, i64* %547, align 8
  store i64 %548, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %549 = add i64 %541, 13
  store i64 %549, i64* %PC, align 8
  %550 = load i64, i64* %543, align 8
  store i64 %550, i64* %RDX, align 8, !tbaa !2428
  %551 = add i64 %550, 120
  %552 = add i64 %541, 18
  store i64 %552, i64* %PC, align 8
  %553 = bitcast i64 %548 to double
  %554 = inttoptr i64 %551 to double*
  %555 = load double, double* %554, align 8
  %556 = fsub double %553, %555
  store double %556, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %557 = add i64 %539, -152
  %558 = add i64 %541, 26
  store i64 %558, i64* %PC, align 8
  %559 = inttoptr i64 %557 to double*
  store double %556, double* %559, align 8
  %560 = load i64, i64* %RBP, align 8
  %561 = add i64 %560, -96
  %562 = load i64, i64* %PC, align 8
  %563 = add i64 %562, 5
  store i64 %563, i64* %PC, align 8
  %564 = inttoptr i64 %561 to i64*
  %565 = load i64, i64* %564, align 8
  store i64 %565, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %566 = add i64 %560, -128
  %567 = add i64 %562, 10
  store i64 %567, i64* %PC, align 8
  %568 = bitcast i64 %565 to double
  %569 = inttoptr i64 %566 to double*
  %570 = load double, double* %569, align 8
  %571 = fadd double %568, %570
  store double %571, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %572 = add i64 %560, -16
  %573 = add i64 %562, 14
  store i64 %573, i64* %PC, align 8
  %574 = inttoptr i64 %572 to i64*
  %575 = load i64, i64* %574, align 8
  store i64 %575, i64* %RDX, align 8, !tbaa !2428
  %576 = add i64 %575, 64
  %577 = add i64 %562, 19
  store i64 %577, i64* %PC, align 8
  %578 = inttoptr i64 %576 to double*
  store double %571, double* %578, align 8
  %579 = load i64, i64* %RBP, align 8
  %580 = add i64 %579, -104
  %581 = load i64, i64* %PC, align 8
  %582 = add i64 %581, 5
  store i64 %582, i64* %PC, align 8
  %583 = inttoptr i64 %580 to i64*
  %584 = load i64, i64* %583, align 8
  store i64 %584, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %585 = add i64 %579, -136
  %586 = add i64 %581, 13
  store i64 %586, i64* %PC, align 8
  %587 = bitcast i64 %584 to double
  %588 = inttoptr i64 %585 to double*
  %589 = load double, double* %588, align 8
  %590 = fadd double %587, %589
  store double %590, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %591 = add i64 %579, -16
  %592 = add i64 %581, 17
  store i64 %592, i64* %PC, align 8
  %593 = inttoptr i64 %591 to i64*
  %594 = load i64, i64* %593, align 8
  store i64 %594, i64* %RDX, align 8, !tbaa !2428
  %595 = add i64 %594, 72
  %596 = add i64 %581, 22
  store i64 %596, i64* %PC, align 8
  %597 = inttoptr i64 %595 to double*
  store double %590, double* %597, align 8
  %598 = load i64, i64* %RBP, align 8
  %599 = add i64 %598, -136
  %600 = load i64, i64* %PC, align 8
  %601 = add i64 %600, 8
  store i64 %601, i64* %PC, align 8
  %602 = inttoptr i64 %599 to i64*
  %603 = load i64, i64* %602, align 8
  store i64 %603, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %604 = add i64 %598, -104
  %605 = add i64 %600, 13
  store i64 %605, i64* %PC, align 8
  %606 = bitcast i64 %603 to double
  %607 = inttoptr i64 %604 to double*
  %608 = load double, double* %607, align 8
  %609 = fsub double %606, %608
  store double %609, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %610 = add i64 %598, -16
  %611 = add i64 %600, 17
  store i64 %611, i64* %PC, align 8
  %612 = inttoptr i64 %610 to i64*
  %613 = load i64, i64* %612, align 8
  store i64 %613, i64* %RDX, align 8, !tbaa !2428
  %614 = add i64 %613, 96
  %615 = add i64 %600, 22
  store i64 %615, i64* %PC, align 8
  %616 = inttoptr i64 %614 to double*
  store double %609, double* %616, align 8
  %617 = load i64, i64* %RBP, align 8
  %618 = add i64 %617, -96
  %619 = load i64, i64* %PC, align 8
  %620 = add i64 %619, 5
  store i64 %620, i64* %PC, align 8
  %621 = inttoptr i64 %618 to i64*
  %622 = load i64, i64* %621, align 8
  store i64 %622, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %623 = add i64 %617, -128
  %624 = add i64 %619, 10
  store i64 %624, i64* %PC, align 8
  %625 = bitcast i64 %622 to double
  %626 = inttoptr i64 %623 to double*
  %627 = load double, double* %626, align 8
  %628 = fsub double %625, %627
  store double %628, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %629 = add i64 %617, -16
  %630 = add i64 %619, 14
  store i64 %630, i64* %PC, align 8
  %631 = inttoptr i64 %629 to i64*
  %632 = load i64, i64* %631, align 8
  store i64 %632, i64* %RDX, align 8, !tbaa !2428
  %633 = add i64 %632, 104
  %634 = add i64 %619, 19
  store i64 %634, i64* %PC, align 8
  %635 = inttoptr i64 %633 to double*
  store double %628, double* %635, align 8
  %636 = load i64, i64* %RBP, align 8
  %637 = add i64 %636, -112
  %638 = load i64, i64* %PC, align 8
  %639 = add i64 %638, 5
  store i64 %639, i64* %PC, align 8
  %640 = inttoptr i64 %637 to i64*
  %641 = load i64, i64* %640, align 8
  store i64 %641, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %642 = add i64 %636, -152
  %643 = add i64 %638, 13
  store i64 %643, i64* %PC, align 8
  %644 = bitcast i64 %641 to double
  %645 = inttoptr i64 %642 to double*
  %646 = load double, double* %645, align 8
  %647 = fsub double %644, %646
  store double %647, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %648 = add i64 %636, -96
  %649 = add i64 %638, 18
  store i64 %649, i64* %PC, align 8
  %650 = inttoptr i64 %648 to double*
  store double %647, double* %650, align 8
  %651 = load i64, i64* %RBP, align 8
  %652 = add i64 %651, -120
  %653 = load i64, i64* %PC, align 8
  %654 = add i64 %653, 5
  store i64 %654, i64* %PC, align 8
  %655 = inttoptr i64 %652 to i64*
  %656 = load i64, i64* %655, align 8
  store i64 %656, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %657 = add i64 %651, -144
  %658 = add i64 %653, 13
  store i64 %658, i64* %PC, align 8
  %659 = bitcast i64 %656 to double
  %660 = inttoptr i64 %657 to double*
  %661 = load double, double* %660, align 8
  %662 = fadd double %659, %661
  store double %662, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %663 = add i64 %651, -104
  %664 = add i64 %653, 18
  store i64 %664, i64* %PC, align 8
  %665 = inttoptr i64 %663 to double*
  store double %662, double* %665, align 8
  %666 = load i64, i64* %RBP, align 8
  %667 = add i64 %666, -48
  %668 = load i64, i64* %PC, align 8
  %669 = add i64 %668, 5
  store i64 %669, i64* %PC, align 8
  %670 = inttoptr i64 %667 to i64*
  %671 = load i64, i64* %670, align 8
  store i64 %671, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %672 = bitcast %union.VectorReg* %5 to i8*
  %673 = add i64 %666, -96
  %674 = add i64 %668, 10
  store i64 %674, i64* %PC, align 8
  %675 = inttoptr i64 %673 to i64*
  %676 = load i64, i64* %675, align 8
  %677 = bitcast %union.VectorReg* %5 to double*
  %678 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %676, i64* %678, align 1, !tbaa !2451
  %679 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %680 = bitcast i64* %679 to double*
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %681 = add i64 %666, -104
  %682 = add i64 %668, 15
  store i64 %682, i64* %PC, align 8
  %683 = bitcast i64 %676 to double
  %684 = inttoptr i64 %681 to double*
  %685 = load double, double* %684, align 8
  %686 = fsub double %683, %685
  store double %686, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %687 = bitcast i64 %671 to double
  %688 = fmul double %687, %686
  store double %688, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %689 = add i64 %666, -16
  %690 = add i64 %668, 23
  store i64 %690, i64* %PC, align 8
  %691 = inttoptr i64 %689 to i64*
  %692 = load i64, i64* %691, align 8
  store i64 %692, i64* %RDX, align 8, !tbaa !2428
  %693 = add i64 %692, 80
  %694 = add i64 %668, 28
  store i64 %694, i64* %PC, align 8
  %695 = inttoptr i64 %693 to double*
  store double %688, double* %695, align 8
  %696 = load i64, i64* %RBP, align 8
  %697 = add i64 %696, -48
  %698 = load i64, i64* %PC, align 8
  %699 = add i64 %698, 5
  store i64 %699, i64* %PC, align 8
  %700 = inttoptr i64 %697 to i64*
  %701 = load i64, i64* %700, align 8
  store i64 %701, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %702 = add i64 %696, -96
  %703 = add i64 %698, 10
  store i64 %703, i64* %PC, align 8
  %704 = inttoptr i64 %702 to i64*
  %705 = load i64, i64* %704, align 8
  store i64 %705, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %706 = add i64 %696, -104
  %707 = add i64 %698, 15
  store i64 %707, i64* %PC, align 8
  %708 = bitcast i64 %705 to double
  %709 = inttoptr i64 %706 to double*
  %710 = load double, double* %709, align 8
  %711 = fadd double %708, %710
  store double %711, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %712 = bitcast i64 %701 to double
  %713 = fmul double %712, %711
  store double %713, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %714 = add i64 %696, -16
  %715 = add i64 %698, 23
  store i64 %715, i64* %PC, align 8
  %716 = inttoptr i64 %714 to i64*
  %717 = load i64, i64* %716, align 8
  store i64 %717, i64* %RDX, align 8, !tbaa !2428
  %718 = add i64 %717, 88
  %719 = add i64 %698, 28
  store i64 %719, i64* %PC, align 8
  %720 = inttoptr i64 %718 to double*
  store double %713, double* %720, align 8
  %721 = load i64, i64* %RBP, align 8
  %722 = add i64 %721, -152
  %723 = load i64, i64* %PC, align 8
  %724 = add i64 %723, 8
  store i64 %724, i64* %PC, align 8
  %725 = inttoptr i64 %722 to i64*
  %726 = load i64, i64* %725, align 8
  store i64 %726, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %727 = add i64 %721, -112
  %728 = add i64 %723, 13
  store i64 %728, i64* %PC, align 8
  %729 = bitcast i64 %726 to double
  %730 = inttoptr i64 %727 to double*
  %731 = load double, double* %730, align 8
  %732 = fadd double %729, %731
  store double %732, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %733 = add i64 %721, -96
  %734 = add i64 %723, 18
  store i64 %734, i64* %PC, align 8
  %735 = inttoptr i64 %733 to double*
  store double %732, double* %735, align 8
  %736 = load i64, i64* %RBP, align 8
  %737 = add i64 %736, -144
  %738 = load i64, i64* %PC, align 8
  %739 = add i64 %738, 8
  store i64 %739, i64* %PC, align 8
  %740 = inttoptr i64 %737 to i64*
  %741 = load i64, i64* %740, align 8
  store i64 %741, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %742 = add i64 %736, -120
  %743 = add i64 %738, 13
  store i64 %743, i64* %PC, align 8
  %744 = bitcast i64 %741 to double
  %745 = inttoptr i64 %742 to double*
  %746 = load double, double* %745, align 8
  %747 = fsub double %744, %746
  store double %747, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %748 = add i64 %736, -104
  %749 = add i64 %738, 18
  store i64 %749, i64* %PC, align 8
  %750 = inttoptr i64 %748 to double*
  store double %747, double* %750, align 8
  %751 = load i64, i64* %RBP, align 8
  %752 = add i64 %751, -48
  %753 = load i64, i64* %PC, align 8
  %754 = add i64 %753, 5
  store i64 %754, i64* %PC, align 8
  %755 = inttoptr i64 %752 to i64*
  %756 = load i64, i64* %755, align 8
  store i64 %756, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %757 = add i64 %751, -104
  %758 = add i64 %753, 10
  store i64 %758, i64* %PC, align 8
  %759 = inttoptr i64 %757 to i64*
  %760 = load i64, i64* %759, align 8
  store i64 %760, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %761 = add i64 %751, -96
  %762 = add i64 %753, 15
  store i64 %762, i64* %PC, align 8
  %763 = bitcast i64 %760 to double
  %764 = inttoptr i64 %761 to double*
  %765 = load double, double* %764, align 8
  %766 = fsub double %763, %765
  store double %766, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %767 = bitcast i64 %756 to double
  %768 = fmul double %767, %766
  store double %768, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %769 = add i64 %751, -16
  %770 = add i64 %753, 23
  store i64 %770, i64* %PC, align 8
  %771 = inttoptr i64 %769 to i64*
  %772 = load i64, i64* %771, align 8
  store i64 %772, i64* %RDX, align 8, !tbaa !2428
  %773 = add i64 %772, 112
  %774 = add i64 %753, 28
  store i64 %774, i64* %PC, align 8
  %775 = inttoptr i64 %773 to double*
  store double %768, double* %775, align 8
  %776 = load i64, i64* %RBP, align 8
  %777 = add i64 %776, -48
  %778 = load i64, i64* %PC, align 8
  %779 = add i64 %778, 5
  store i64 %779, i64* %PC, align 8
  %780 = inttoptr i64 %777 to i64*
  %781 = load i64, i64* %780, align 8
  store i64 %781, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %782 = add i64 %776, -104
  %783 = add i64 %778, 10
  store i64 %783, i64* %PC, align 8
  %784 = inttoptr i64 %782 to i64*
  %785 = load i64, i64* %784, align 8
  store i64 %785, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %786 = add i64 %776, -96
  %787 = add i64 %778, 15
  store i64 %787, i64* %PC, align 8
  %788 = bitcast i64 %785 to double
  %789 = inttoptr i64 %786 to double*
  %790 = load double, double* %789, align 8
  %791 = fadd double %788, %790
  store double %791, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %792 = bitcast i64 %781 to double
  %793 = fmul double %792, %791
  store double %793, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %794 = add i64 %776, -16
  %795 = add i64 %778, 23
  store i64 %795, i64* %PC, align 8
  %796 = inttoptr i64 %794 to i64*
  %797 = load i64, i64* %796, align 8
  store i64 %797, i64* %RDX, align 8, !tbaa !2428
  %798 = add i64 %797, 120
  %799 = add i64 %778, 28
  store i64 %799, i64* %PC, align 8
  %800 = inttoptr i64 %798 to double*
  store double %793, double* %800, align 8
  %801 = load i64, i64* %RBP, align 8
  %802 = add i64 %801, -32
  %803 = load i64, i64* %PC, align 8
  %804 = add i64 %803, 7
  store i64 %804, i64* %PC, align 8
  %805 = inttoptr i64 %802 to i32*
  store i32 0, i32* %805, align 4
  %806 = load i64, i64* %RBP, align 8
  %807 = add i64 %806, -28
  %808 = load i64, i64* %PC, align 8
  %809 = add i64 %808, 7
  store i64 %809, i64* %PC, align 8
  %810 = inttoptr i64 %807 to i32*
  store i32 16, i32* %810, align 4
  %811 = bitcast %union.VectorReg* %6 to i8*
  %812 = bitcast [32 x %union.VectorReg]* %4 to <2 x i32>*
  %813 = bitcast i64* %69 to <2 x i32>*
  %814 = bitcast %union.VectorReg* %6 to i32*
  %815 = getelementptr inbounds i8, i8* %811, i64 4
  %816 = bitcast i8* %815 to i32*
  %817 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %818 = bitcast i64* %817 to i32*
  %819 = getelementptr inbounds i8, i8* %811, i64 12
  %820 = bitcast i8* %819 to i32*
  %821 = bitcast %union.VectorReg* %6 to double*
  %822 = bitcast %union.VectorReg* %5 to i32*
  %823 = getelementptr inbounds i8, i8* %672, i64 4
  %824 = bitcast i8* %823 to i32*
  %825 = bitcast i64* %679 to i32*
  %826 = getelementptr inbounds i8, i8* %672, i64 12
  %827 = bitcast i8* %826 to i32*
  %828 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  %829 = bitcast i64* %817 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_402c02

block_402c0e:                                     ; preds = %block_402c02
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %830 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 80) to i64*), align 16
  store i64 %830, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %831 = add i64 %3490, -32
  %832 = add i64 %3526, 21
  store i64 %832, i64* %PC, align 8
  %833 = inttoptr i64 %831 to i32*
  %834 = load i32, i32* %833, align 4
  %835 = add i32 %834, 2
  %836 = zext i32 %835 to i64
  store i64 %836, i64* %RCX, align 8, !tbaa !2428
  %837 = icmp ugt i32 %834, -3
  %838 = zext i1 %837 to i8
  store i8 %838, i8* %16, align 1, !tbaa !2432
  %839 = and i32 %835, 255
  %840 = tail call i32 @llvm.ctpop.i32(i32 %839) #14
  %841 = trunc i32 %840 to i8
  %842 = and i8 %841, 1
  %843 = xor i8 %842, 1
  store i8 %843, i8* %23, align 1, !tbaa !2446
  %844 = xor i32 %835, %834
  %845 = lshr i32 %844, 4
  %846 = trunc i32 %845 to i8
  %847 = and i8 %846, 1
  store i8 %847, i8* %29, align 1, !tbaa !2447
  %848 = icmp eq i32 %835, 0
  %849 = zext i1 %848 to i8
  store i8 %849, i8* %32, align 1, !tbaa !2448
  %850 = lshr i32 %835, 31
  %851 = trunc i32 %850 to i8
  store i8 %851, i8* %35, align 1, !tbaa !2449
  %852 = lshr i32 %834, 31
  %853 = xor i32 %850, %852
  %854 = add nuw nsw i32 %853, %850
  %855 = icmp eq i32 %854, 2
  %856 = zext i1 %855 to i8
  store i8 %856, i8* %41, align 1, !tbaa !2450
  %857 = add i64 %3526, 27
  store i64 %857, i64* %PC, align 8
  store i32 %835, i32* %833, align 4
  %858 = load i64, i64* %RBP, align 8
  %859 = add i64 %858, -32
  %860 = load i64, i64* %PC, align 8
  %861 = add i64 %860, 3
  store i64 %861, i64* %PC, align 8
  %862 = inttoptr i64 %859 to i32*
  %863 = load i32, i32* %862, align 4
  %864 = shl i32 %863, 1
  %865 = icmp slt i32 %863, 0
  %866 = icmp slt i32 %864, 0
  %867 = xor i1 %865, %866
  %868 = zext i32 %864 to i64
  store i64 %868, i64* %RCX, align 8, !tbaa !2428
  %.lobit = lshr i32 %863, 31
  %869 = trunc i32 %.lobit to i8
  store i8 %869, i8* %16, align 1, !tbaa !2453
  %870 = and i32 %864, 254
  %871 = tail call i32 @llvm.ctpop.i32(i32 %870) #14
  %872 = trunc i32 %871 to i8
  %873 = and i8 %872, 1
  %874 = xor i8 %873, 1
  store i8 %874, i8* %23, align 1, !tbaa !2453
  store i8 0, i8* %29, align 1, !tbaa !2453
  %875 = icmp eq i32 %864, 0
  %876 = zext i1 %875 to i8
  store i8 %876, i8* %32, align 1, !tbaa !2453
  %877 = lshr i32 %863, 30
  %878 = trunc i32 %877 to i8
  %879 = and i8 %878, 1
  store i8 %879, i8* %35, align 1, !tbaa !2453
  %880 = zext i1 %867 to i8
  store i8 %880, i8* %41, align 1, !tbaa !2453
  %881 = add i64 %858, -36
  %882 = add i64 %860, 9
  store i64 %882, i64* %PC, align 8
  %883 = inttoptr i64 %881 to i32*
  store i32 %864, i32* %883, align 4
  %884 = load i64, i64* %RBP, align 8
  %885 = add i64 %884, -24
  %886 = load i64, i64* %PC, align 8
  %887 = add i64 %886, 4
  store i64 %887, i64* %PC, align 8
  %888 = inttoptr i64 %885 to i64*
  %889 = load i64, i64* %888, align 8
  store i64 %889, i64* %RDX, align 8, !tbaa !2428
  %890 = add i64 %884, -32
  %891 = add i64 %886, 8
  store i64 %891, i64* %PC, align 8
  %892 = inttoptr i64 %890 to i32*
  %893 = load i32, i32* %892, align 4
  %894 = sext i32 %893 to i64
  store i64 %894, i64* %RSI, align 8, !tbaa !2428
  %895 = shl nsw i64 %894, 3
  %896 = add i64 %895, %889
  %897 = add i64 %886, 13
  store i64 %897, i64* %PC, align 8
  %898 = inttoptr i64 %896 to i64*
  %899 = load i64, i64* %898, align 8
  store i64 %899, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %900 = add i64 %884, -64
  %901 = add i64 %886, 18
  store i64 %901, i64* %PC, align 8
  %902 = inttoptr i64 %900 to i64*
  store i64 %899, i64* %902, align 8
  %903 = load i64, i64* %RBP, align 8
  %904 = add i64 %903, -24
  %905 = load i64, i64* %PC, align 8
  %906 = add i64 %905, 4
  store i64 %906, i64* %PC, align 8
  %907 = inttoptr i64 %904 to i64*
  %908 = load i64, i64* %907, align 8
  store i64 %908, i64* %RDX, align 8, !tbaa !2428
  %909 = add i64 %903, -32
  %910 = add i64 %905, 7
  store i64 %910, i64* %PC, align 8
  %911 = inttoptr i64 %909 to i32*
  %912 = load i32, i32* %911, align 4
  %913 = add i32 %912, 1
  %914 = zext i32 %913 to i64
  store i64 %914, i64* %RCX, align 8, !tbaa !2428
  %915 = icmp eq i32 %912, -1
  %916 = icmp eq i32 %913, 0
  %917 = or i1 %915, %916
  %918 = zext i1 %917 to i8
  store i8 %918, i8* %16, align 1, !tbaa !2432
  %919 = and i32 %913, 255
  %920 = tail call i32 @llvm.ctpop.i32(i32 %919) #14
  %921 = trunc i32 %920 to i8
  %922 = and i8 %921, 1
  %923 = xor i8 %922, 1
  store i8 %923, i8* %23, align 1, !tbaa !2446
  %924 = xor i32 %913, %912
  %925 = lshr i32 %924, 4
  %926 = trunc i32 %925 to i8
  %927 = and i8 %926, 1
  store i8 %927, i8* %29, align 1, !tbaa !2447
  %928 = zext i1 %916 to i8
  store i8 %928, i8* %32, align 1, !tbaa !2448
  %929 = lshr i32 %913, 31
  %930 = trunc i32 %929 to i8
  store i8 %930, i8* %35, align 1, !tbaa !2449
  %931 = lshr i32 %912, 31
  %932 = xor i32 %929, %931
  %933 = add nuw nsw i32 %932, %929
  %934 = icmp eq i32 %933, 2
  %935 = zext i1 %934 to i8
  store i8 %935, i8* %41, align 1, !tbaa !2450
  %936 = sext i32 %913 to i64
  store i64 %936, i64* %RSI, align 8, !tbaa !2428
  %937 = shl nsw i64 %936, 3
  %938 = add i64 %908, %937
  %939 = add i64 %905, 18
  store i64 %939, i64* %PC, align 8
  %940 = inttoptr i64 %938 to i64*
  %941 = load i64, i64* %940, align 8
  store i64 %941, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %942 = add i64 %903, -72
  %943 = add i64 %905, 23
  store i64 %943, i64* %PC, align 8
  %944 = inttoptr i64 %942 to i64*
  store i64 %941, i64* %944, align 8
  %945 = load i64, i64* %RBP, align 8
  %946 = add i64 %945, -24
  %947 = load i64, i64* %PC, align 8
  %948 = add i64 %947, 4
  store i64 %948, i64* %PC, align 8
  %949 = inttoptr i64 %946 to i64*
  %950 = load i64, i64* %949, align 8
  store i64 %950, i64* %RDX, align 8, !tbaa !2428
  %951 = add i64 %945, -36
  %952 = add i64 %947, 8
  store i64 %952, i64* %PC, align 8
  %953 = inttoptr i64 %951 to i32*
  %954 = load i32, i32* %953, align 4
  %955 = sext i32 %954 to i64
  store i64 %955, i64* %RSI, align 8, !tbaa !2428
  %956 = shl nsw i64 %955, 3
  %957 = add i64 %956, %950
  %958 = add i64 %947, 13
  store i64 %958, i64* %PC, align 8
  %959 = inttoptr i64 %957 to i64*
  %960 = load i64, i64* %959, align 8
  store i64 %960, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %961 = add i64 %945, -48
  %962 = add i64 %947, 18
  store i64 %962, i64* %PC, align 8
  %963 = inttoptr i64 %961 to i64*
  store i64 %960, i64* %963, align 8
  %964 = load i64, i64* %RBP, align 8
  %965 = add i64 %964, -24
  %966 = load i64, i64* %PC, align 8
  %967 = add i64 %966, 4
  store i64 %967, i64* %PC, align 8
  %968 = inttoptr i64 %965 to i64*
  %969 = load i64, i64* %968, align 8
  store i64 %969, i64* %RDX, align 8, !tbaa !2428
  %970 = add i64 %964, -36
  %971 = add i64 %966, 7
  store i64 %971, i64* %PC, align 8
  %972 = inttoptr i64 %970 to i32*
  %973 = load i32, i32* %972, align 4
  %974 = add i32 %973, 1
  %975 = zext i32 %974 to i64
  store i64 %975, i64* %RCX, align 8, !tbaa !2428
  %976 = icmp eq i32 %973, -1
  %977 = icmp eq i32 %974, 0
  %978 = or i1 %976, %977
  %979 = zext i1 %978 to i8
  store i8 %979, i8* %16, align 1, !tbaa !2432
  %980 = and i32 %974, 255
  %981 = tail call i32 @llvm.ctpop.i32(i32 %980) #14
  %982 = trunc i32 %981 to i8
  %983 = and i8 %982, 1
  %984 = xor i8 %983, 1
  store i8 %984, i8* %23, align 1, !tbaa !2446
  %985 = xor i32 %974, %973
  %986 = lshr i32 %985, 4
  %987 = trunc i32 %986 to i8
  %988 = and i8 %987, 1
  store i8 %988, i8* %29, align 1, !tbaa !2447
  %989 = zext i1 %977 to i8
  store i8 %989, i8* %32, align 1, !tbaa !2448
  %990 = lshr i32 %974, 31
  %991 = trunc i32 %990 to i8
  store i8 %991, i8* %35, align 1, !tbaa !2449
  %992 = lshr i32 %973, 31
  %993 = xor i32 %990, %992
  %994 = add nuw nsw i32 %993, %990
  %995 = icmp eq i32 %994, 2
  %996 = zext i1 %995 to i8
  store i8 %996, i8* %41, align 1, !tbaa !2450
  %997 = sext i32 %974 to i64
  store i64 %997, i64* %RSI, align 8, !tbaa !2428
  %998 = shl nsw i64 %997, 3
  %999 = add i64 %969, %998
  %1000 = add i64 %966, 18
  store i64 %1000, i64* %PC, align 8
  %1001 = inttoptr i64 %999 to i64*
  %1002 = load i64, i64* %1001, align 8
  store i64 %1002, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1003 = add i64 %964, -56
  %1004 = add i64 %966, 23
  store i64 %1004, i64* %PC, align 8
  %1005 = inttoptr i64 %1003 to i64*
  store i64 %1002, i64* %1005, align 8
  %1006 = load i64, i64* %RBP, align 8
  %1007 = add i64 %1006, -48
  %1008 = load i64, i64* %PC, align 8
  %1009 = add i64 %1008, 5
  store i64 %1009, i64* %PC, align 8
  %1010 = inttoptr i64 %1007 to i64*
  %1011 = load i64, i64* %1010, align 8
  store i64 %1011, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1012 = load <2 x i32>, <2 x i32>* %812, align 1
  %1013 = load <2 x i32>, <2 x i32>* %813, align 1
  %1014 = extractelement <2 x i32> %1012, i32 0
  store i32 %1014, i32* %814, align 1, !tbaa !2475
  %1015 = extractelement <2 x i32> %1012, i32 1
  store i32 %1015, i32* %816, align 1, !tbaa !2475
  %1016 = extractelement <2 x i32> %1013, i32 0
  store i32 %1016, i32* %818, align 1, !tbaa !2475
  %1017 = extractelement <2 x i32> %1013, i32 1
  store i32 %1017, i32* %820, align 1, !tbaa !2475
  %1018 = add i64 %1006, -72
  %1019 = add i64 %1008, 13
  store i64 %1019, i64* %PC, align 8
  %1020 = load double, double* %821, align 1
  %1021 = inttoptr i64 %1018 to double*
  %1022 = load double, double* %1021, align 8
  %1023 = fmul double %1020, %1022
  store double %1023, double* %821, align 1, !tbaa !2451
  %1024 = add i64 %1006, -56
  %1025 = add i64 %1008, 18
  store i64 %1025, i64* %PC, align 8
  %1026 = inttoptr i64 %1024 to double*
  %1027 = load double, double* %1026, align 8
  %1028 = fmul double %1023, %1027
  store double %1028, double* %821, align 1, !tbaa !2451
  %1029 = bitcast i64 %1011 to double
  %1030 = fsub double %1029, %1028
  %1031 = add i64 %1006, -80
  %1032 = add i64 %1008, 27
  store i64 %1032, i64* %PC, align 8
  %1033 = inttoptr i64 %1031 to double*
  store double %1030, double* %1033, align 8
  %1034 = load i64, i64* %PC, align 8
  %1035 = load <2 x i32>, <2 x i32>* %812, align 1
  %1036 = load <2 x i32>, <2 x i32>* %813, align 1
  %1037 = extractelement <2 x i32> %1035, i32 0
  store i32 %1037, i32* %822, align 1, !tbaa !2475
  %1038 = extractelement <2 x i32> %1035, i32 1
  store i32 %1038, i32* %824, align 1, !tbaa !2475
  %1039 = extractelement <2 x i32> %1036, i32 0
  store i32 %1039, i32* %825, align 1, !tbaa !2475
  %1040 = extractelement <2 x i32> %1036, i32 1
  store i32 %1040, i32* %827, align 1, !tbaa !2475
  %1041 = load i64, i64* %RBP, align 8
  %1042 = add i64 %1041, -72
  %1043 = add i64 %1034, 8
  store i64 %1043, i64* %PC, align 8
  %1044 = load double, double* %677, align 1
  %1045 = inttoptr i64 %1042 to double*
  %1046 = load double, double* %1045, align 8
  %1047 = fmul double %1044, %1046
  store double %1047, double* %677, align 1, !tbaa !2451
  %1048 = add i64 %1041, -48
  %1049 = add i64 %1034, 13
  store i64 %1049, i64* %PC, align 8
  %1050 = inttoptr i64 %1048 to double*
  %1051 = load double, double* %1050, align 8
  %1052 = fmul double %1047, %1051
  store double %1052, double* %677, align 1, !tbaa !2451
  %1053 = add i64 %1041, -56
  %1054 = add i64 %1034, 18
  store i64 %1054, i64* %PC, align 8
  %1055 = inttoptr i64 %1053 to double*
  %1056 = load double, double* %1055, align 8
  %1057 = fsub double %1052, %1056
  store double %1057, double* %677, align 1, !tbaa !2451
  %1058 = add i64 %1041, -88
  %1059 = add i64 %1034, 23
  store i64 %1059, i64* %PC, align 8
  %1060 = inttoptr i64 %1058 to double*
  store double %1057, double* %1060, align 8
  %1061 = load i64, i64* %RBP, align 8
  %1062 = add i64 %1061, -16
  %1063 = load i64, i64* %PC, align 8
  %1064 = add i64 %1063, 4
  store i64 %1064, i64* %PC, align 8
  %1065 = inttoptr i64 %1062 to i64*
  %1066 = load i64, i64* %1065, align 8
  store i64 %1066, i64* %RDX, align 8, !tbaa !2428
  %1067 = add i64 %1061, -28
  %1068 = add i64 %1063, 8
  store i64 %1068, i64* %PC, align 8
  %1069 = inttoptr i64 %1067 to i32*
  %1070 = load i32, i32* %1069, align 4
  %1071 = sext i32 %1070 to i64
  store i64 %1071, i64* %RSI, align 8, !tbaa !2428
  %1072 = shl nsw i64 %1071, 3
  %1073 = add i64 %1072, %1066
  %1074 = add i64 %1063, 13
  store i64 %1074, i64* %PC, align 8
  %1075 = inttoptr i64 %1073 to i64*
  %1076 = load i64, i64* %1075, align 8
  store i64 %1076, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1077 = add i64 %1063, 17
  store i64 %1077, i64* %PC, align 8
  %1078 = load i64, i64* %1065, align 8
  store i64 %1078, i64* %RDX, align 8, !tbaa !2428
  %1079 = add i64 %1063, 20
  store i64 %1079, i64* %PC, align 8
  %1080 = load i32, i32* %1069, align 4
  %1081 = add i32 %1080, 2
  %1082 = zext i32 %1081 to i64
  store i64 %1082, i64* %RCX, align 8, !tbaa !2428
  %1083 = icmp ugt i32 %1080, -3
  %1084 = zext i1 %1083 to i8
  store i8 %1084, i8* %16, align 1, !tbaa !2432
  %1085 = and i32 %1081, 255
  %1086 = tail call i32 @llvm.ctpop.i32(i32 %1085) #14
  %1087 = trunc i32 %1086 to i8
  %1088 = and i8 %1087, 1
  %1089 = xor i8 %1088, 1
  store i8 %1089, i8* %23, align 1, !tbaa !2446
  %1090 = xor i32 %1081, %1080
  %1091 = lshr i32 %1090, 4
  %1092 = trunc i32 %1091 to i8
  %1093 = and i8 %1092, 1
  store i8 %1093, i8* %29, align 1, !tbaa !2447
  %1094 = icmp eq i32 %1081, 0
  %1095 = zext i1 %1094 to i8
  store i8 %1095, i8* %32, align 1, !tbaa !2448
  %1096 = lshr i32 %1081, 31
  %1097 = trunc i32 %1096 to i8
  store i8 %1097, i8* %35, align 1, !tbaa !2449
  %1098 = lshr i32 %1080, 31
  %1099 = xor i32 %1096, %1098
  %1100 = add nuw nsw i32 %1099, %1096
  %1101 = icmp eq i32 %1100, 2
  %1102 = zext i1 %1101 to i8
  store i8 %1102, i8* %41, align 1, !tbaa !2450
  %1103 = sext i32 %1081 to i64
  store i64 %1103, i64* %RSI, align 8, !tbaa !2428
  %1104 = shl nsw i64 %1103, 3
  %1105 = add i64 %1078, %1104
  %1106 = add i64 %1063, 31
  store i64 %1106, i64* %PC, align 8
  %1107 = bitcast i64 %1076 to double
  %1108 = inttoptr i64 %1105 to double*
  %1109 = load double, double* %1108, align 8
  %1110 = fadd double %1107, %1109
  store double %1110, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1111 = add i64 %1061, -96
  %1112 = add i64 %1063, 36
  store i64 %1112, i64* %PC, align 8
  %1113 = inttoptr i64 %1111 to double*
  store double %1110, double* %1113, align 8
  %1114 = load i64, i64* %RBP, align 8
  %1115 = add i64 %1114, -16
  %1116 = load i64, i64* %PC, align 8
  %1117 = add i64 %1116, 4
  store i64 %1117, i64* %PC, align 8
  %1118 = inttoptr i64 %1115 to i64*
  %1119 = load i64, i64* %1118, align 8
  store i64 %1119, i64* %RDX, align 8, !tbaa !2428
  %1120 = add i64 %1114, -28
  %1121 = add i64 %1116, 7
  store i64 %1121, i64* %PC, align 8
  %1122 = inttoptr i64 %1120 to i32*
  %1123 = load i32, i32* %1122, align 4
  %1124 = add i32 %1123, 1
  %1125 = zext i32 %1124 to i64
  store i64 %1125, i64* %RCX, align 8, !tbaa !2428
  %1126 = icmp eq i32 %1123, -1
  %1127 = icmp eq i32 %1124, 0
  %1128 = or i1 %1126, %1127
  %1129 = zext i1 %1128 to i8
  store i8 %1129, i8* %16, align 1, !tbaa !2432
  %1130 = and i32 %1124, 255
  %1131 = tail call i32 @llvm.ctpop.i32(i32 %1130) #14
  %1132 = trunc i32 %1131 to i8
  %1133 = and i8 %1132, 1
  %1134 = xor i8 %1133, 1
  store i8 %1134, i8* %23, align 1, !tbaa !2446
  %1135 = xor i32 %1124, %1123
  %1136 = lshr i32 %1135, 4
  %1137 = trunc i32 %1136 to i8
  %1138 = and i8 %1137, 1
  store i8 %1138, i8* %29, align 1, !tbaa !2447
  %1139 = zext i1 %1127 to i8
  store i8 %1139, i8* %32, align 1, !tbaa !2448
  %1140 = lshr i32 %1124, 31
  %1141 = trunc i32 %1140 to i8
  store i8 %1141, i8* %35, align 1, !tbaa !2449
  %1142 = lshr i32 %1123, 31
  %1143 = xor i32 %1140, %1142
  %1144 = add nuw nsw i32 %1143, %1140
  %1145 = icmp eq i32 %1144, 2
  %1146 = zext i1 %1145 to i8
  store i8 %1146, i8* %41, align 1, !tbaa !2450
  %1147 = sext i32 %1124 to i64
  store i64 %1147, i64* %RSI, align 8, !tbaa !2428
  %1148 = shl nsw i64 %1147, 3
  %1149 = add i64 %1119, %1148
  %1150 = add i64 %1116, 18
  store i64 %1150, i64* %PC, align 8
  %1151 = inttoptr i64 %1149 to i64*
  %1152 = load i64, i64* %1151, align 8
  store i64 %1152, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1153 = add i64 %1116, 22
  store i64 %1153, i64* %PC, align 8
  %1154 = load i64, i64* %1118, align 8
  store i64 %1154, i64* %RDX, align 8, !tbaa !2428
  %1155 = add i64 %1116, 25
  store i64 %1155, i64* %PC, align 8
  %1156 = load i32, i32* %1122, align 4
  %1157 = add i32 %1156, 3
  %1158 = zext i32 %1157 to i64
  store i64 %1158, i64* %RCX, align 8, !tbaa !2428
  %1159 = icmp ugt i32 %1156, -4
  %1160 = zext i1 %1159 to i8
  store i8 %1160, i8* %16, align 1, !tbaa !2432
  %1161 = and i32 %1157, 255
  %1162 = tail call i32 @llvm.ctpop.i32(i32 %1161) #14
  %1163 = trunc i32 %1162 to i8
  %1164 = and i8 %1163, 1
  %1165 = xor i8 %1164, 1
  store i8 %1165, i8* %23, align 1, !tbaa !2446
  %1166 = xor i32 %1157, %1156
  %1167 = lshr i32 %1166, 4
  %1168 = trunc i32 %1167 to i8
  %1169 = and i8 %1168, 1
  store i8 %1169, i8* %29, align 1, !tbaa !2447
  %1170 = icmp eq i32 %1157, 0
  %1171 = zext i1 %1170 to i8
  store i8 %1171, i8* %32, align 1, !tbaa !2448
  %1172 = lshr i32 %1157, 31
  %1173 = trunc i32 %1172 to i8
  store i8 %1173, i8* %35, align 1, !tbaa !2449
  %1174 = lshr i32 %1156, 31
  %1175 = xor i32 %1172, %1174
  %1176 = add nuw nsw i32 %1175, %1172
  %1177 = icmp eq i32 %1176, 2
  %1178 = zext i1 %1177 to i8
  store i8 %1178, i8* %41, align 1, !tbaa !2450
  %1179 = sext i32 %1157 to i64
  store i64 %1179, i64* %RSI, align 8, !tbaa !2428
  %1180 = shl nsw i64 %1179, 3
  %1181 = add i64 %1154, %1180
  %1182 = add i64 %1116, 36
  store i64 %1182, i64* %PC, align 8
  %1183 = bitcast i64 %1152 to double
  %1184 = inttoptr i64 %1181 to double*
  %1185 = load double, double* %1184, align 8
  %1186 = fadd double %1183, %1185
  store double %1186, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1187 = load i64, i64* %RBP, align 8
  %1188 = add i64 %1187, -104
  %1189 = add i64 %1116, 41
  store i64 %1189, i64* %PC, align 8
  %1190 = inttoptr i64 %1188 to double*
  store double %1186, double* %1190, align 8
  %1191 = load i64, i64* %RBP, align 8
  %1192 = add i64 %1191, -16
  %1193 = load i64, i64* %PC, align 8
  %1194 = add i64 %1193, 4
  store i64 %1194, i64* %PC, align 8
  %1195 = inttoptr i64 %1192 to i64*
  %1196 = load i64, i64* %1195, align 8
  store i64 %1196, i64* %RDX, align 8, !tbaa !2428
  %1197 = add i64 %1191, -28
  %1198 = add i64 %1193, 8
  store i64 %1198, i64* %PC, align 8
  %1199 = inttoptr i64 %1197 to i32*
  %1200 = load i32, i32* %1199, align 4
  %1201 = sext i32 %1200 to i64
  store i64 %1201, i64* %RSI, align 8, !tbaa !2428
  %1202 = shl nsw i64 %1201, 3
  %1203 = add i64 %1202, %1196
  %1204 = add i64 %1193, 13
  store i64 %1204, i64* %PC, align 8
  %1205 = inttoptr i64 %1203 to i64*
  %1206 = load i64, i64* %1205, align 8
  store i64 %1206, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1207 = add i64 %1193, 17
  store i64 %1207, i64* %PC, align 8
  %1208 = load i64, i64* %1195, align 8
  store i64 %1208, i64* %RDX, align 8, !tbaa !2428
  %1209 = add i64 %1193, 20
  store i64 %1209, i64* %PC, align 8
  %1210 = load i32, i32* %1199, align 4
  %1211 = add i32 %1210, 2
  %1212 = zext i32 %1211 to i64
  store i64 %1212, i64* %RCX, align 8, !tbaa !2428
  %1213 = icmp ugt i32 %1210, -3
  %1214 = zext i1 %1213 to i8
  store i8 %1214, i8* %16, align 1, !tbaa !2432
  %1215 = and i32 %1211, 255
  %1216 = tail call i32 @llvm.ctpop.i32(i32 %1215) #14
  %1217 = trunc i32 %1216 to i8
  %1218 = and i8 %1217, 1
  %1219 = xor i8 %1218, 1
  store i8 %1219, i8* %23, align 1, !tbaa !2446
  %1220 = xor i32 %1211, %1210
  %1221 = lshr i32 %1220, 4
  %1222 = trunc i32 %1221 to i8
  %1223 = and i8 %1222, 1
  store i8 %1223, i8* %29, align 1, !tbaa !2447
  %1224 = icmp eq i32 %1211, 0
  %1225 = zext i1 %1224 to i8
  store i8 %1225, i8* %32, align 1, !tbaa !2448
  %1226 = lshr i32 %1211, 31
  %1227 = trunc i32 %1226 to i8
  store i8 %1227, i8* %35, align 1, !tbaa !2449
  %1228 = lshr i32 %1210, 31
  %1229 = xor i32 %1226, %1228
  %1230 = add nuw nsw i32 %1229, %1226
  %1231 = icmp eq i32 %1230, 2
  %1232 = zext i1 %1231 to i8
  store i8 %1232, i8* %41, align 1, !tbaa !2450
  %1233 = sext i32 %1211 to i64
  store i64 %1233, i64* %RSI, align 8, !tbaa !2428
  %1234 = shl nsw i64 %1233, 3
  %1235 = add i64 %1208, %1234
  %1236 = add i64 %1193, 31
  store i64 %1236, i64* %PC, align 8
  %1237 = bitcast i64 %1206 to double
  %1238 = inttoptr i64 %1235 to double*
  %1239 = load double, double* %1238, align 8
  %1240 = fsub double %1237, %1239
  store double %1240, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1241 = add i64 %1191, -112
  %1242 = add i64 %1193, 36
  store i64 %1242, i64* %PC, align 8
  %1243 = inttoptr i64 %1241 to double*
  store double %1240, double* %1243, align 8
  %1244 = load i64, i64* %RBP, align 8
  %1245 = add i64 %1244, -16
  %1246 = load i64, i64* %PC, align 8
  %1247 = add i64 %1246, 4
  store i64 %1247, i64* %PC, align 8
  %1248 = inttoptr i64 %1245 to i64*
  %1249 = load i64, i64* %1248, align 8
  store i64 %1249, i64* %RDX, align 8, !tbaa !2428
  %1250 = add i64 %1244, -28
  %1251 = add i64 %1246, 7
  store i64 %1251, i64* %PC, align 8
  %1252 = inttoptr i64 %1250 to i32*
  %1253 = load i32, i32* %1252, align 4
  %1254 = add i32 %1253, 1
  %1255 = zext i32 %1254 to i64
  store i64 %1255, i64* %RCX, align 8, !tbaa !2428
  %1256 = icmp eq i32 %1253, -1
  %1257 = icmp eq i32 %1254, 0
  %1258 = or i1 %1256, %1257
  %1259 = zext i1 %1258 to i8
  store i8 %1259, i8* %16, align 1, !tbaa !2432
  %1260 = and i32 %1254, 255
  %1261 = tail call i32 @llvm.ctpop.i32(i32 %1260) #14
  %1262 = trunc i32 %1261 to i8
  %1263 = and i8 %1262, 1
  %1264 = xor i8 %1263, 1
  store i8 %1264, i8* %23, align 1, !tbaa !2446
  %1265 = xor i32 %1254, %1253
  %1266 = lshr i32 %1265, 4
  %1267 = trunc i32 %1266 to i8
  %1268 = and i8 %1267, 1
  store i8 %1268, i8* %29, align 1, !tbaa !2447
  %1269 = zext i1 %1257 to i8
  store i8 %1269, i8* %32, align 1, !tbaa !2448
  %1270 = lshr i32 %1254, 31
  %1271 = trunc i32 %1270 to i8
  store i8 %1271, i8* %35, align 1, !tbaa !2449
  %1272 = lshr i32 %1253, 31
  %1273 = xor i32 %1270, %1272
  %1274 = add nuw nsw i32 %1273, %1270
  %1275 = icmp eq i32 %1274, 2
  %1276 = zext i1 %1275 to i8
  store i8 %1276, i8* %41, align 1, !tbaa !2450
  %1277 = sext i32 %1254 to i64
  store i64 %1277, i64* %RSI, align 8, !tbaa !2428
  %1278 = shl nsw i64 %1277, 3
  %1279 = add i64 %1249, %1278
  %1280 = add i64 %1246, 18
  store i64 %1280, i64* %PC, align 8
  %1281 = inttoptr i64 %1279 to i64*
  %1282 = load i64, i64* %1281, align 8
  store i64 %1282, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1283 = add i64 %1246, 22
  store i64 %1283, i64* %PC, align 8
  %1284 = load i64, i64* %1248, align 8
  store i64 %1284, i64* %RDX, align 8, !tbaa !2428
  %1285 = add i64 %1246, 25
  store i64 %1285, i64* %PC, align 8
  %1286 = load i32, i32* %1252, align 4
  %1287 = add i32 %1286, 3
  %1288 = zext i32 %1287 to i64
  store i64 %1288, i64* %RCX, align 8, !tbaa !2428
  %1289 = icmp ugt i32 %1286, -4
  %1290 = zext i1 %1289 to i8
  store i8 %1290, i8* %16, align 1, !tbaa !2432
  %1291 = and i32 %1287, 255
  %1292 = tail call i32 @llvm.ctpop.i32(i32 %1291) #14
  %1293 = trunc i32 %1292 to i8
  %1294 = and i8 %1293, 1
  %1295 = xor i8 %1294, 1
  store i8 %1295, i8* %23, align 1, !tbaa !2446
  %1296 = xor i32 %1287, %1286
  %1297 = lshr i32 %1296, 4
  %1298 = trunc i32 %1297 to i8
  %1299 = and i8 %1298, 1
  store i8 %1299, i8* %29, align 1, !tbaa !2447
  %1300 = icmp eq i32 %1287, 0
  %1301 = zext i1 %1300 to i8
  store i8 %1301, i8* %32, align 1, !tbaa !2448
  %1302 = lshr i32 %1287, 31
  %1303 = trunc i32 %1302 to i8
  store i8 %1303, i8* %35, align 1, !tbaa !2449
  %1304 = lshr i32 %1286, 31
  %1305 = xor i32 %1302, %1304
  %1306 = add nuw nsw i32 %1305, %1302
  %1307 = icmp eq i32 %1306, 2
  %1308 = zext i1 %1307 to i8
  store i8 %1308, i8* %41, align 1, !tbaa !2450
  %1309 = sext i32 %1287 to i64
  store i64 %1309, i64* %RSI, align 8, !tbaa !2428
  %1310 = shl nsw i64 %1309, 3
  %1311 = add i64 %1284, %1310
  %1312 = add i64 %1246, 36
  store i64 %1312, i64* %PC, align 8
  %1313 = bitcast i64 %1282 to double
  %1314 = inttoptr i64 %1311 to double*
  %1315 = load double, double* %1314, align 8
  %1316 = fsub double %1313, %1315
  store double %1316, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1317 = load i64, i64* %RBP, align 8
  %1318 = add i64 %1317, -120
  %1319 = add i64 %1246, 41
  store i64 %1319, i64* %PC, align 8
  %1320 = inttoptr i64 %1318 to double*
  store double %1316, double* %1320, align 8
  %1321 = load i64, i64* %RBP, align 8
  %1322 = add i64 %1321, -16
  %1323 = load i64, i64* %PC, align 8
  %1324 = add i64 %1323, 4
  store i64 %1324, i64* %PC, align 8
  %1325 = inttoptr i64 %1322 to i64*
  %1326 = load i64, i64* %1325, align 8
  store i64 %1326, i64* %RDX, align 8, !tbaa !2428
  %1327 = add i64 %1321, -28
  %1328 = add i64 %1323, 7
  store i64 %1328, i64* %PC, align 8
  %1329 = inttoptr i64 %1327 to i32*
  %1330 = load i32, i32* %1329, align 4
  %1331 = add i32 %1330, 4
  %1332 = zext i32 %1331 to i64
  store i64 %1332, i64* %RCX, align 8, !tbaa !2428
  %1333 = icmp ugt i32 %1330, -5
  %1334 = zext i1 %1333 to i8
  store i8 %1334, i8* %16, align 1, !tbaa !2432
  %1335 = and i32 %1331, 255
  %1336 = tail call i32 @llvm.ctpop.i32(i32 %1335) #14
  %1337 = trunc i32 %1336 to i8
  %1338 = and i8 %1337, 1
  %1339 = xor i8 %1338, 1
  store i8 %1339, i8* %23, align 1, !tbaa !2446
  %1340 = xor i32 %1331, %1330
  %1341 = lshr i32 %1340, 4
  %1342 = trunc i32 %1341 to i8
  %1343 = and i8 %1342, 1
  store i8 %1343, i8* %29, align 1, !tbaa !2447
  %1344 = icmp eq i32 %1331, 0
  %1345 = zext i1 %1344 to i8
  store i8 %1345, i8* %32, align 1, !tbaa !2448
  %1346 = lshr i32 %1331, 31
  %1347 = trunc i32 %1346 to i8
  store i8 %1347, i8* %35, align 1, !tbaa !2449
  %1348 = lshr i32 %1330, 31
  %1349 = xor i32 %1346, %1348
  %1350 = add nuw nsw i32 %1349, %1346
  %1351 = icmp eq i32 %1350, 2
  %1352 = zext i1 %1351 to i8
  store i8 %1352, i8* %41, align 1, !tbaa !2450
  %1353 = sext i32 %1331 to i64
  store i64 %1353, i64* %RSI, align 8, !tbaa !2428
  %1354 = shl nsw i64 %1353, 3
  %1355 = add i64 %1326, %1354
  %1356 = add i64 %1323, 18
  store i64 %1356, i64* %PC, align 8
  %1357 = inttoptr i64 %1355 to i64*
  %1358 = load i64, i64* %1357, align 8
  store i64 %1358, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1359 = add i64 %1323, 22
  store i64 %1359, i64* %PC, align 8
  %1360 = load i64, i64* %1325, align 8
  store i64 %1360, i64* %RDX, align 8, !tbaa !2428
  %1361 = add i64 %1323, 25
  store i64 %1361, i64* %PC, align 8
  %1362 = load i32, i32* %1329, align 4
  %1363 = add i32 %1362, 6
  %1364 = zext i32 %1363 to i64
  store i64 %1364, i64* %RCX, align 8, !tbaa !2428
  %1365 = icmp ugt i32 %1362, -7
  %1366 = zext i1 %1365 to i8
  store i8 %1366, i8* %16, align 1, !tbaa !2432
  %1367 = and i32 %1363, 255
  %1368 = tail call i32 @llvm.ctpop.i32(i32 %1367) #14
  %1369 = trunc i32 %1368 to i8
  %1370 = and i8 %1369, 1
  %1371 = xor i8 %1370, 1
  store i8 %1371, i8* %23, align 1, !tbaa !2446
  %1372 = xor i32 %1363, %1362
  %1373 = lshr i32 %1372, 4
  %1374 = trunc i32 %1373 to i8
  %1375 = and i8 %1374, 1
  store i8 %1375, i8* %29, align 1, !tbaa !2447
  %1376 = icmp eq i32 %1363, 0
  %1377 = zext i1 %1376 to i8
  store i8 %1377, i8* %32, align 1, !tbaa !2448
  %1378 = lshr i32 %1363, 31
  %1379 = trunc i32 %1378 to i8
  store i8 %1379, i8* %35, align 1, !tbaa !2449
  %1380 = lshr i32 %1362, 31
  %1381 = xor i32 %1378, %1380
  %1382 = add nuw nsw i32 %1381, %1378
  %1383 = icmp eq i32 %1382, 2
  %1384 = zext i1 %1383 to i8
  store i8 %1384, i8* %41, align 1, !tbaa !2450
  %1385 = sext i32 %1363 to i64
  store i64 %1385, i64* %RSI, align 8, !tbaa !2428
  %1386 = shl nsw i64 %1385, 3
  %1387 = add i64 %1360, %1386
  %1388 = add i64 %1323, 36
  store i64 %1388, i64* %PC, align 8
  %1389 = bitcast i64 %1358 to double
  %1390 = inttoptr i64 %1387 to double*
  %1391 = load double, double* %1390, align 8
  %1392 = fadd double %1389, %1391
  store double %1392, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1393 = load i64, i64* %RBP, align 8
  %1394 = add i64 %1393, -128
  %1395 = add i64 %1323, 41
  store i64 %1395, i64* %PC, align 8
  %1396 = inttoptr i64 %1394 to double*
  store double %1392, double* %1396, align 8
  %1397 = load i64, i64* %RBP, align 8
  %1398 = add i64 %1397, -16
  %1399 = load i64, i64* %PC, align 8
  %1400 = add i64 %1399, 4
  store i64 %1400, i64* %PC, align 8
  %1401 = inttoptr i64 %1398 to i64*
  %1402 = load i64, i64* %1401, align 8
  store i64 %1402, i64* %RDX, align 8, !tbaa !2428
  %1403 = add i64 %1397, -28
  %1404 = add i64 %1399, 7
  store i64 %1404, i64* %PC, align 8
  %1405 = inttoptr i64 %1403 to i32*
  %1406 = load i32, i32* %1405, align 4
  %1407 = add i32 %1406, 5
  %1408 = zext i32 %1407 to i64
  store i64 %1408, i64* %RCX, align 8, !tbaa !2428
  %1409 = icmp ugt i32 %1406, -6
  %1410 = zext i1 %1409 to i8
  store i8 %1410, i8* %16, align 1, !tbaa !2432
  %1411 = and i32 %1407, 255
  %1412 = tail call i32 @llvm.ctpop.i32(i32 %1411) #14
  %1413 = trunc i32 %1412 to i8
  %1414 = and i8 %1413, 1
  %1415 = xor i8 %1414, 1
  store i8 %1415, i8* %23, align 1, !tbaa !2446
  %1416 = xor i32 %1407, %1406
  %1417 = lshr i32 %1416, 4
  %1418 = trunc i32 %1417 to i8
  %1419 = and i8 %1418, 1
  store i8 %1419, i8* %29, align 1, !tbaa !2447
  %1420 = icmp eq i32 %1407, 0
  %1421 = zext i1 %1420 to i8
  store i8 %1421, i8* %32, align 1, !tbaa !2448
  %1422 = lshr i32 %1407, 31
  %1423 = trunc i32 %1422 to i8
  store i8 %1423, i8* %35, align 1, !tbaa !2449
  %1424 = lshr i32 %1406, 31
  %1425 = xor i32 %1422, %1424
  %1426 = add nuw nsw i32 %1425, %1422
  %1427 = icmp eq i32 %1426, 2
  %1428 = zext i1 %1427 to i8
  store i8 %1428, i8* %41, align 1, !tbaa !2450
  %1429 = sext i32 %1407 to i64
  store i64 %1429, i64* %RSI, align 8, !tbaa !2428
  %1430 = shl nsw i64 %1429, 3
  %1431 = add i64 %1402, %1430
  %1432 = add i64 %1399, 18
  store i64 %1432, i64* %PC, align 8
  %1433 = inttoptr i64 %1431 to i64*
  %1434 = load i64, i64* %1433, align 8
  store i64 %1434, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1435 = add i64 %1399, 22
  store i64 %1435, i64* %PC, align 8
  %1436 = load i64, i64* %1401, align 8
  store i64 %1436, i64* %RDX, align 8, !tbaa !2428
  %1437 = add i64 %1399, 25
  store i64 %1437, i64* %PC, align 8
  %1438 = load i32, i32* %1405, align 4
  %1439 = add i32 %1438, 7
  %1440 = zext i32 %1439 to i64
  store i64 %1440, i64* %RCX, align 8, !tbaa !2428
  %1441 = icmp ugt i32 %1438, -8
  %1442 = zext i1 %1441 to i8
  store i8 %1442, i8* %16, align 1, !tbaa !2432
  %1443 = and i32 %1439, 255
  %1444 = tail call i32 @llvm.ctpop.i32(i32 %1443) #14
  %1445 = trunc i32 %1444 to i8
  %1446 = and i8 %1445, 1
  %1447 = xor i8 %1446, 1
  store i8 %1447, i8* %23, align 1, !tbaa !2446
  %1448 = xor i32 %1439, %1438
  %1449 = lshr i32 %1448, 4
  %1450 = trunc i32 %1449 to i8
  %1451 = and i8 %1450, 1
  store i8 %1451, i8* %29, align 1, !tbaa !2447
  %1452 = icmp eq i32 %1439, 0
  %1453 = zext i1 %1452 to i8
  store i8 %1453, i8* %32, align 1, !tbaa !2448
  %1454 = lshr i32 %1439, 31
  %1455 = trunc i32 %1454 to i8
  store i8 %1455, i8* %35, align 1, !tbaa !2449
  %1456 = lshr i32 %1438, 31
  %1457 = xor i32 %1454, %1456
  %1458 = add nuw nsw i32 %1457, %1454
  %1459 = icmp eq i32 %1458, 2
  %1460 = zext i1 %1459 to i8
  store i8 %1460, i8* %41, align 1, !tbaa !2450
  %1461 = sext i32 %1439 to i64
  store i64 %1461, i64* %RSI, align 8, !tbaa !2428
  %1462 = shl nsw i64 %1461, 3
  %1463 = add i64 %1436, %1462
  %1464 = add i64 %1399, 36
  store i64 %1464, i64* %PC, align 8
  %1465 = bitcast i64 %1434 to double
  %1466 = inttoptr i64 %1463 to double*
  %1467 = load double, double* %1466, align 8
  %1468 = fadd double %1465, %1467
  store double %1468, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1469 = load i64, i64* %RBP, align 8
  %1470 = add i64 %1469, -136
  %1471 = add i64 %1399, 44
  store i64 %1471, i64* %PC, align 8
  %1472 = inttoptr i64 %1470 to double*
  store double %1468, double* %1472, align 8
  %1473 = load i64, i64* %RBP, align 8
  %1474 = add i64 %1473, -16
  %1475 = load i64, i64* %PC, align 8
  %1476 = add i64 %1475, 4
  store i64 %1476, i64* %PC, align 8
  %1477 = inttoptr i64 %1474 to i64*
  %1478 = load i64, i64* %1477, align 8
  store i64 %1478, i64* %RDX, align 8, !tbaa !2428
  %1479 = add i64 %1473, -28
  %1480 = add i64 %1475, 7
  store i64 %1480, i64* %PC, align 8
  %1481 = inttoptr i64 %1479 to i32*
  %1482 = load i32, i32* %1481, align 4
  %1483 = add i32 %1482, 4
  %1484 = zext i32 %1483 to i64
  store i64 %1484, i64* %RCX, align 8, !tbaa !2428
  %1485 = icmp ugt i32 %1482, -5
  %1486 = zext i1 %1485 to i8
  store i8 %1486, i8* %16, align 1, !tbaa !2432
  %1487 = and i32 %1483, 255
  %1488 = tail call i32 @llvm.ctpop.i32(i32 %1487) #14
  %1489 = trunc i32 %1488 to i8
  %1490 = and i8 %1489, 1
  %1491 = xor i8 %1490, 1
  store i8 %1491, i8* %23, align 1, !tbaa !2446
  %1492 = xor i32 %1483, %1482
  %1493 = lshr i32 %1492, 4
  %1494 = trunc i32 %1493 to i8
  %1495 = and i8 %1494, 1
  store i8 %1495, i8* %29, align 1, !tbaa !2447
  %1496 = icmp eq i32 %1483, 0
  %1497 = zext i1 %1496 to i8
  store i8 %1497, i8* %32, align 1, !tbaa !2448
  %1498 = lshr i32 %1483, 31
  %1499 = trunc i32 %1498 to i8
  store i8 %1499, i8* %35, align 1, !tbaa !2449
  %1500 = lshr i32 %1482, 31
  %1501 = xor i32 %1498, %1500
  %1502 = add nuw nsw i32 %1501, %1498
  %1503 = icmp eq i32 %1502, 2
  %1504 = zext i1 %1503 to i8
  store i8 %1504, i8* %41, align 1, !tbaa !2450
  %1505 = sext i32 %1483 to i64
  store i64 %1505, i64* %RSI, align 8, !tbaa !2428
  %1506 = shl nsw i64 %1505, 3
  %1507 = add i64 %1478, %1506
  %1508 = add i64 %1475, 18
  store i64 %1508, i64* %PC, align 8
  %1509 = inttoptr i64 %1507 to i64*
  %1510 = load i64, i64* %1509, align 8
  store i64 %1510, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1511 = add i64 %1475, 22
  store i64 %1511, i64* %PC, align 8
  %1512 = load i64, i64* %1477, align 8
  store i64 %1512, i64* %RDX, align 8, !tbaa !2428
  %1513 = add i64 %1475, 25
  store i64 %1513, i64* %PC, align 8
  %1514 = load i32, i32* %1481, align 4
  %1515 = add i32 %1514, 6
  %1516 = zext i32 %1515 to i64
  store i64 %1516, i64* %RCX, align 8, !tbaa !2428
  %1517 = icmp ugt i32 %1514, -7
  %1518 = zext i1 %1517 to i8
  store i8 %1518, i8* %16, align 1, !tbaa !2432
  %1519 = and i32 %1515, 255
  %1520 = tail call i32 @llvm.ctpop.i32(i32 %1519) #14
  %1521 = trunc i32 %1520 to i8
  %1522 = and i8 %1521, 1
  %1523 = xor i8 %1522, 1
  store i8 %1523, i8* %23, align 1, !tbaa !2446
  %1524 = xor i32 %1515, %1514
  %1525 = lshr i32 %1524, 4
  %1526 = trunc i32 %1525 to i8
  %1527 = and i8 %1526, 1
  store i8 %1527, i8* %29, align 1, !tbaa !2447
  %1528 = icmp eq i32 %1515, 0
  %1529 = zext i1 %1528 to i8
  store i8 %1529, i8* %32, align 1, !tbaa !2448
  %1530 = lshr i32 %1515, 31
  %1531 = trunc i32 %1530 to i8
  store i8 %1531, i8* %35, align 1, !tbaa !2449
  %1532 = lshr i32 %1514, 31
  %1533 = xor i32 %1530, %1532
  %1534 = add nuw nsw i32 %1533, %1530
  %1535 = icmp eq i32 %1534, 2
  %1536 = zext i1 %1535 to i8
  store i8 %1536, i8* %41, align 1, !tbaa !2450
  %1537 = sext i32 %1515 to i64
  store i64 %1537, i64* %RSI, align 8, !tbaa !2428
  %1538 = shl nsw i64 %1537, 3
  %1539 = add i64 %1512, %1538
  %1540 = add i64 %1475, 36
  store i64 %1540, i64* %PC, align 8
  %1541 = bitcast i64 %1510 to double
  %1542 = inttoptr i64 %1539 to double*
  %1543 = load double, double* %1542, align 8
  %1544 = fsub double %1541, %1543
  store double %1544, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1545 = load i64, i64* %RBP, align 8
  %1546 = add i64 %1545, -144
  %1547 = add i64 %1475, 44
  store i64 %1547, i64* %PC, align 8
  %1548 = inttoptr i64 %1546 to double*
  store double %1544, double* %1548, align 8
  %1549 = load i64, i64* %RBP, align 8
  %1550 = add i64 %1549, -16
  %1551 = load i64, i64* %PC, align 8
  %1552 = add i64 %1551, 4
  store i64 %1552, i64* %PC, align 8
  %1553 = inttoptr i64 %1550 to i64*
  %1554 = load i64, i64* %1553, align 8
  store i64 %1554, i64* %RDX, align 8, !tbaa !2428
  %1555 = add i64 %1549, -28
  %1556 = add i64 %1551, 7
  store i64 %1556, i64* %PC, align 8
  %1557 = inttoptr i64 %1555 to i32*
  %1558 = load i32, i32* %1557, align 4
  %1559 = add i32 %1558, 5
  %1560 = zext i32 %1559 to i64
  store i64 %1560, i64* %RCX, align 8, !tbaa !2428
  %1561 = icmp ugt i32 %1558, -6
  %1562 = zext i1 %1561 to i8
  store i8 %1562, i8* %16, align 1, !tbaa !2432
  %1563 = and i32 %1559, 255
  %1564 = tail call i32 @llvm.ctpop.i32(i32 %1563) #14
  %1565 = trunc i32 %1564 to i8
  %1566 = and i8 %1565, 1
  %1567 = xor i8 %1566, 1
  store i8 %1567, i8* %23, align 1, !tbaa !2446
  %1568 = xor i32 %1559, %1558
  %1569 = lshr i32 %1568, 4
  %1570 = trunc i32 %1569 to i8
  %1571 = and i8 %1570, 1
  store i8 %1571, i8* %29, align 1, !tbaa !2447
  %1572 = icmp eq i32 %1559, 0
  %1573 = zext i1 %1572 to i8
  store i8 %1573, i8* %32, align 1, !tbaa !2448
  %1574 = lshr i32 %1559, 31
  %1575 = trunc i32 %1574 to i8
  store i8 %1575, i8* %35, align 1, !tbaa !2449
  %1576 = lshr i32 %1558, 31
  %1577 = xor i32 %1574, %1576
  %1578 = add nuw nsw i32 %1577, %1574
  %1579 = icmp eq i32 %1578, 2
  %1580 = zext i1 %1579 to i8
  store i8 %1580, i8* %41, align 1, !tbaa !2450
  %1581 = sext i32 %1559 to i64
  store i64 %1581, i64* %RSI, align 8, !tbaa !2428
  %1582 = shl nsw i64 %1581, 3
  %1583 = add i64 %1554, %1582
  %1584 = add i64 %1551, 18
  store i64 %1584, i64* %PC, align 8
  %1585 = inttoptr i64 %1583 to i64*
  %1586 = load i64, i64* %1585, align 8
  store i64 %1586, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1587 = add i64 %1551, 22
  store i64 %1587, i64* %PC, align 8
  %1588 = load i64, i64* %1553, align 8
  store i64 %1588, i64* %RDX, align 8, !tbaa !2428
  %1589 = add i64 %1551, 25
  store i64 %1589, i64* %PC, align 8
  %1590 = load i32, i32* %1557, align 4
  %1591 = add i32 %1590, 7
  %1592 = zext i32 %1591 to i64
  store i64 %1592, i64* %RCX, align 8, !tbaa !2428
  %1593 = icmp ugt i32 %1590, -8
  %1594 = zext i1 %1593 to i8
  store i8 %1594, i8* %16, align 1, !tbaa !2432
  %1595 = and i32 %1591, 255
  %1596 = tail call i32 @llvm.ctpop.i32(i32 %1595) #14
  %1597 = trunc i32 %1596 to i8
  %1598 = and i8 %1597, 1
  %1599 = xor i8 %1598, 1
  store i8 %1599, i8* %23, align 1, !tbaa !2446
  %1600 = xor i32 %1591, %1590
  %1601 = lshr i32 %1600, 4
  %1602 = trunc i32 %1601 to i8
  %1603 = and i8 %1602, 1
  store i8 %1603, i8* %29, align 1, !tbaa !2447
  %1604 = icmp eq i32 %1591, 0
  %1605 = zext i1 %1604 to i8
  store i8 %1605, i8* %32, align 1, !tbaa !2448
  %1606 = lshr i32 %1591, 31
  %1607 = trunc i32 %1606 to i8
  store i8 %1607, i8* %35, align 1, !tbaa !2449
  %1608 = lshr i32 %1590, 31
  %1609 = xor i32 %1606, %1608
  %1610 = add nuw nsw i32 %1609, %1606
  %1611 = icmp eq i32 %1610, 2
  %1612 = zext i1 %1611 to i8
  store i8 %1612, i8* %41, align 1, !tbaa !2450
  %1613 = sext i32 %1591 to i64
  store i64 %1613, i64* %RSI, align 8, !tbaa !2428
  %1614 = shl nsw i64 %1613, 3
  %1615 = add i64 %1588, %1614
  %1616 = add i64 %1551, 36
  store i64 %1616, i64* %PC, align 8
  %1617 = bitcast i64 %1586 to double
  %1618 = inttoptr i64 %1615 to double*
  %1619 = load double, double* %1618, align 8
  %1620 = fsub double %1617, %1619
  store double %1620, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1621 = load i64, i64* %RBP, align 8
  %1622 = add i64 %1621, -152
  %1623 = add i64 %1551, 44
  store i64 %1623, i64* %PC, align 8
  %1624 = inttoptr i64 %1622 to double*
  store double %1620, double* %1624, align 8
  %1625 = load i64, i64* %RBP, align 8
  %1626 = add i64 %1625, -96
  %1627 = load i64, i64* %PC, align 8
  %1628 = add i64 %1627, 5
  store i64 %1628, i64* %PC, align 8
  %1629 = inttoptr i64 %1626 to i64*
  %1630 = load i64, i64* %1629, align 8
  store i64 %1630, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1631 = add i64 %1625, -128
  %1632 = add i64 %1627, 10
  store i64 %1632, i64* %PC, align 8
  %1633 = bitcast i64 %1630 to double
  %1634 = inttoptr i64 %1631 to double*
  %1635 = load double, double* %1634, align 8
  %1636 = fadd double %1633, %1635
  store double %1636, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1637 = add i64 %1625, -16
  %1638 = add i64 %1627, 14
  store i64 %1638, i64* %PC, align 8
  %1639 = inttoptr i64 %1637 to i64*
  %1640 = load i64, i64* %1639, align 8
  store i64 %1640, i64* %RDX, align 8, !tbaa !2428
  %1641 = add i64 %1625, -28
  %1642 = add i64 %1627, 18
  store i64 %1642, i64* %PC, align 8
  %1643 = inttoptr i64 %1641 to i32*
  %1644 = load i32, i32* %1643, align 4
  %1645 = sext i32 %1644 to i64
  store i64 %1645, i64* %RSI, align 8, !tbaa !2428
  %1646 = shl nsw i64 %1645, 3
  %1647 = add i64 %1646, %1640
  %1648 = add i64 %1627, 23
  store i64 %1648, i64* %PC, align 8
  %1649 = inttoptr i64 %1647 to double*
  store double %1636, double* %1649, align 8
  %1650 = load i64, i64* %RBP, align 8
  %1651 = add i64 %1650, -104
  %1652 = load i64, i64* %PC, align 8
  %1653 = add i64 %1652, 5
  store i64 %1653, i64* %PC, align 8
  %1654 = inttoptr i64 %1651 to i64*
  %1655 = load i64, i64* %1654, align 8
  store i64 %1655, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1656 = add i64 %1650, -136
  %1657 = add i64 %1652, 13
  store i64 %1657, i64* %PC, align 8
  %1658 = bitcast i64 %1655 to double
  %1659 = inttoptr i64 %1656 to double*
  %1660 = load double, double* %1659, align 8
  %1661 = fadd double %1658, %1660
  store double %1661, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1662 = add i64 %1650, -16
  %1663 = add i64 %1652, 17
  store i64 %1663, i64* %PC, align 8
  %1664 = inttoptr i64 %1662 to i64*
  %1665 = load i64, i64* %1664, align 8
  store i64 %1665, i64* %RDX, align 8, !tbaa !2428
  %1666 = add i64 %1650, -28
  %1667 = add i64 %1652, 20
  store i64 %1667, i64* %PC, align 8
  %1668 = inttoptr i64 %1666 to i32*
  %1669 = load i32, i32* %1668, align 4
  %1670 = add i32 %1669, 1
  %1671 = zext i32 %1670 to i64
  store i64 %1671, i64* %RCX, align 8, !tbaa !2428
  %1672 = icmp eq i32 %1669, -1
  %1673 = icmp eq i32 %1670, 0
  %1674 = or i1 %1672, %1673
  %1675 = zext i1 %1674 to i8
  store i8 %1675, i8* %16, align 1, !tbaa !2432
  %1676 = and i32 %1670, 255
  %1677 = tail call i32 @llvm.ctpop.i32(i32 %1676) #14
  %1678 = trunc i32 %1677 to i8
  %1679 = and i8 %1678, 1
  %1680 = xor i8 %1679, 1
  store i8 %1680, i8* %23, align 1, !tbaa !2446
  %1681 = xor i32 %1670, %1669
  %1682 = lshr i32 %1681, 4
  %1683 = trunc i32 %1682 to i8
  %1684 = and i8 %1683, 1
  store i8 %1684, i8* %29, align 1, !tbaa !2447
  %1685 = zext i1 %1673 to i8
  store i8 %1685, i8* %32, align 1, !tbaa !2448
  %1686 = lshr i32 %1670, 31
  %1687 = trunc i32 %1686 to i8
  store i8 %1687, i8* %35, align 1, !tbaa !2449
  %1688 = lshr i32 %1669, 31
  %1689 = xor i32 %1686, %1688
  %1690 = add nuw nsw i32 %1689, %1686
  %1691 = icmp eq i32 %1690, 2
  %1692 = zext i1 %1691 to i8
  store i8 %1692, i8* %41, align 1, !tbaa !2450
  %1693 = sext i32 %1670 to i64
  store i64 %1693, i64* %RSI, align 8, !tbaa !2428
  %1694 = shl nsw i64 %1693, 3
  %1695 = add i64 %1665, %1694
  %1696 = add i64 %1652, 31
  store i64 %1696, i64* %PC, align 8
  %1697 = inttoptr i64 %1695 to double*
  store double %1661, double* %1697, align 8
  %1698 = load i64, i64* %RBP, align 8
  %1699 = add i64 %1698, -128
  %1700 = load i64, i64* %PC, align 8
  %1701 = add i64 %1700, 5
  store i64 %1701, i64* %PC, align 8
  %1702 = inttoptr i64 %1699 to i64*
  %1703 = load i64, i64* %1702, align 8
  store i64 %1703, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1704 = add i64 %1698, -96
  %1705 = add i64 %1700, 10
  store i64 %1705, i64* %PC, align 8
  %1706 = inttoptr i64 %1704 to double*
  %1707 = load double, double* %1706, align 8
  %1708 = bitcast i64 %1703 to double
  %1709 = fsub double %1707, %1708
  store double %1709, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %1710 = add i64 %1700, 19
  store i64 %1710, i64* %PC, align 8
  %1711 = inttoptr i64 %1704 to double*
  store double %1709, double* %1711, align 8
  %1712 = load i64, i64* %RBP, align 8
  %1713 = add i64 %1712, -136
  %1714 = load i64, i64* %PC, align 8
  %1715 = add i64 %1714, 8
  store i64 %1715, i64* %PC, align 8
  %1716 = inttoptr i64 %1713 to i64*
  %1717 = load i64, i64* %1716, align 8
  store i64 %1717, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1718 = add i64 %1712, -104
  %1719 = add i64 %1714, 13
  store i64 %1719, i64* %PC, align 8
  %1720 = inttoptr i64 %1718 to double*
  %1721 = load double, double* %1720, align 8
  %1722 = bitcast i64 %1717 to double
  %1723 = fsub double %1721, %1722
  store double %1723, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %1724 = add i64 %1714, 22
  store i64 %1724, i64* %PC, align 8
  %1725 = inttoptr i64 %1718 to double*
  store double %1723, double* %1725, align 8
  %1726 = load i64, i64* %RBP, align 8
  %1727 = add i64 %1726, -64
  %1728 = load i64, i64* %PC, align 8
  %1729 = add i64 %1728, 5
  store i64 %1729, i64* %PC, align 8
  %1730 = inttoptr i64 %1727 to i64*
  %1731 = load i64, i64* %1730, align 8
  store i64 %1731, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1732 = add i64 %1726, -96
  %1733 = add i64 %1728, 10
  store i64 %1733, i64* %PC, align 8
  %1734 = bitcast i64 %1731 to double
  %1735 = inttoptr i64 %1732 to double*
  %1736 = load double, double* %1735, align 8
  %1737 = fmul double %1734, %1736
  store double %1737, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1738 = add i64 %1726, -72
  %1739 = add i64 %1728, 15
  store i64 %1739, i64* %PC, align 8
  %1740 = inttoptr i64 %1738 to i64*
  %1741 = load i64, i64* %1740, align 8
  store i64 %1741, i64* %828, align 1, !tbaa !2451
  store double 0.000000e+00, double* %829, align 1, !tbaa !2451
  %1742 = add i64 %1726, -104
  %1743 = add i64 %1728, 20
  store i64 %1743, i64* %PC, align 8
  %1744 = bitcast i64 %1741 to double
  %1745 = inttoptr i64 %1742 to double*
  %1746 = load double, double* %1745, align 8
  %1747 = fmul double %1744, %1746
  store double %1747, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %1748 = fsub double %1737, %1747
  store double %1748, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1749 = add i64 %1726, -16
  %1750 = add i64 %1728, 28
  store i64 %1750, i64* %PC, align 8
  %1751 = inttoptr i64 %1749 to i64*
  %1752 = load i64, i64* %1751, align 8
  store i64 %1752, i64* %RDX, align 8, !tbaa !2428
  %1753 = add i64 %1726, -28
  %1754 = add i64 %1728, 31
  store i64 %1754, i64* %PC, align 8
  %1755 = inttoptr i64 %1753 to i32*
  %1756 = load i32, i32* %1755, align 4
  %1757 = add i32 %1756, 4
  %1758 = zext i32 %1757 to i64
  store i64 %1758, i64* %RCX, align 8, !tbaa !2428
  %1759 = icmp ugt i32 %1756, -5
  %1760 = zext i1 %1759 to i8
  store i8 %1760, i8* %16, align 1, !tbaa !2432
  %1761 = and i32 %1757, 255
  %1762 = tail call i32 @llvm.ctpop.i32(i32 %1761) #14
  %1763 = trunc i32 %1762 to i8
  %1764 = and i8 %1763, 1
  %1765 = xor i8 %1764, 1
  store i8 %1765, i8* %23, align 1, !tbaa !2446
  %1766 = xor i32 %1757, %1756
  %1767 = lshr i32 %1766, 4
  %1768 = trunc i32 %1767 to i8
  %1769 = and i8 %1768, 1
  store i8 %1769, i8* %29, align 1, !tbaa !2447
  %1770 = icmp eq i32 %1757, 0
  %1771 = zext i1 %1770 to i8
  store i8 %1771, i8* %32, align 1, !tbaa !2448
  %1772 = lshr i32 %1757, 31
  %1773 = trunc i32 %1772 to i8
  store i8 %1773, i8* %35, align 1, !tbaa !2449
  %1774 = lshr i32 %1756, 31
  %1775 = xor i32 %1772, %1774
  %1776 = add nuw nsw i32 %1775, %1772
  %1777 = icmp eq i32 %1776, 2
  %1778 = zext i1 %1777 to i8
  store i8 %1778, i8* %41, align 1, !tbaa !2450
  %1779 = sext i32 %1757 to i64
  store i64 %1779, i64* %RSI, align 8, !tbaa !2428
  %1780 = shl nsw i64 %1779, 3
  %1781 = add i64 %1752, %1780
  %1782 = add i64 %1728, 42
  store i64 %1782, i64* %PC, align 8
  %1783 = inttoptr i64 %1781 to double*
  store double %1748, double* %1783, align 8
  %1784 = load i64, i64* %RBP, align 8
  %1785 = add i64 %1784, -64
  %1786 = load i64, i64* %PC, align 8
  %1787 = add i64 %1786, 5
  store i64 %1787, i64* %PC, align 8
  %1788 = inttoptr i64 %1785 to i64*
  %1789 = load i64, i64* %1788, align 8
  store i64 %1789, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1790 = add i64 %1784, -104
  %1791 = add i64 %1786, 10
  store i64 %1791, i64* %PC, align 8
  %1792 = bitcast i64 %1789 to double
  %1793 = inttoptr i64 %1790 to double*
  %1794 = load double, double* %1793, align 8
  %1795 = fmul double %1792, %1794
  store double %1795, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1796 = add i64 %1784, -72
  %1797 = add i64 %1786, 15
  store i64 %1797, i64* %PC, align 8
  %1798 = inttoptr i64 %1796 to i64*
  %1799 = load i64, i64* %1798, align 8
  store i64 %1799, i64* %828, align 1, !tbaa !2451
  store double 0.000000e+00, double* %829, align 1, !tbaa !2451
  %1800 = add i64 %1784, -96
  %1801 = add i64 %1786, 20
  store i64 %1801, i64* %PC, align 8
  %1802 = bitcast i64 %1799 to double
  %1803 = inttoptr i64 %1800 to double*
  %1804 = load double, double* %1803, align 8
  %1805 = fmul double %1802, %1804
  store double %1805, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %1806 = fadd double %1795, %1805
  store double %1806, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1807 = add i64 %1784, -16
  %1808 = add i64 %1786, 28
  store i64 %1808, i64* %PC, align 8
  %1809 = inttoptr i64 %1807 to i64*
  %1810 = load i64, i64* %1809, align 8
  store i64 %1810, i64* %RDX, align 8, !tbaa !2428
  %1811 = add i64 %1784, -28
  %1812 = add i64 %1786, 31
  store i64 %1812, i64* %PC, align 8
  %1813 = inttoptr i64 %1811 to i32*
  %1814 = load i32, i32* %1813, align 4
  %1815 = add i32 %1814, 5
  %1816 = zext i32 %1815 to i64
  store i64 %1816, i64* %RCX, align 8, !tbaa !2428
  %1817 = icmp ugt i32 %1814, -6
  %1818 = zext i1 %1817 to i8
  store i8 %1818, i8* %16, align 1, !tbaa !2432
  %1819 = and i32 %1815, 255
  %1820 = tail call i32 @llvm.ctpop.i32(i32 %1819) #14
  %1821 = trunc i32 %1820 to i8
  %1822 = and i8 %1821, 1
  %1823 = xor i8 %1822, 1
  store i8 %1823, i8* %23, align 1, !tbaa !2446
  %1824 = xor i32 %1815, %1814
  %1825 = lshr i32 %1824, 4
  %1826 = trunc i32 %1825 to i8
  %1827 = and i8 %1826, 1
  store i8 %1827, i8* %29, align 1, !tbaa !2447
  %1828 = icmp eq i32 %1815, 0
  %1829 = zext i1 %1828 to i8
  store i8 %1829, i8* %32, align 1, !tbaa !2448
  %1830 = lshr i32 %1815, 31
  %1831 = trunc i32 %1830 to i8
  store i8 %1831, i8* %35, align 1, !tbaa !2449
  %1832 = lshr i32 %1814, 31
  %1833 = xor i32 %1830, %1832
  %1834 = add nuw nsw i32 %1833, %1830
  %1835 = icmp eq i32 %1834, 2
  %1836 = zext i1 %1835 to i8
  store i8 %1836, i8* %41, align 1, !tbaa !2450
  %1837 = sext i32 %1815 to i64
  store i64 %1837, i64* %RSI, align 8, !tbaa !2428
  %1838 = shl nsw i64 %1837, 3
  %1839 = add i64 %1810, %1838
  %1840 = add i64 %1786, 42
  store i64 %1840, i64* %PC, align 8
  %1841 = inttoptr i64 %1839 to double*
  store double %1806, double* %1841, align 8
  %1842 = load i64, i64* %RBP, align 8
  %1843 = add i64 %1842, -112
  %1844 = load i64, i64* %PC, align 8
  %1845 = add i64 %1844, 5
  store i64 %1845, i64* %PC, align 8
  %1846 = inttoptr i64 %1843 to i64*
  %1847 = load i64, i64* %1846, align 8
  store i64 %1847, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1848 = add i64 %1842, -152
  %1849 = add i64 %1844, 13
  store i64 %1849, i64* %PC, align 8
  %1850 = bitcast i64 %1847 to double
  %1851 = inttoptr i64 %1848 to double*
  %1852 = load double, double* %1851, align 8
  %1853 = fsub double %1850, %1852
  store double %1853, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1854 = add i64 %1842, -96
  %1855 = add i64 %1844, 18
  store i64 %1855, i64* %PC, align 8
  %1856 = inttoptr i64 %1854 to double*
  store double %1853, double* %1856, align 8
  %1857 = load i64, i64* %RBP, align 8
  %1858 = add i64 %1857, -120
  %1859 = load i64, i64* %PC, align 8
  %1860 = add i64 %1859, 5
  store i64 %1860, i64* %PC, align 8
  %1861 = inttoptr i64 %1858 to i64*
  %1862 = load i64, i64* %1861, align 8
  store i64 %1862, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1863 = add i64 %1857, -144
  %1864 = add i64 %1859, 13
  store i64 %1864, i64* %PC, align 8
  %1865 = bitcast i64 %1862 to double
  %1866 = inttoptr i64 %1863 to double*
  %1867 = load double, double* %1866, align 8
  %1868 = fadd double %1865, %1867
  store double %1868, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1869 = add i64 %1857, -104
  %1870 = add i64 %1859, 18
  store i64 %1870, i64* %PC, align 8
  %1871 = inttoptr i64 %1869 to double*
  store double %1868, double* %1871, align 8
  %1872 = load i64, i64* %RBP, align 8
  %1873 = add i64 %1872, -48
  %1874 = load i64, i64* %PC, align 8
  %1875 = add i64 %1874, 5
  store i64 %1875, i64* %PC, align 8
  %1876 = inttoptr i64 %1873 to i64*
  %1877 = load i64, i64* %1876, align 8
  store i64 %1877, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1878 = add i64 %1872, -96
  %1879 = add i64 %1874, 10
  store i64 %1879, i64* %PC, align 8
  %1880 = bitcast i64 %1877 to double
  %1881 = inttoptr i64 %1878 to double*
  %1882 = load double, double* %1881, align 8
  %1883 = fmul double %1880, %1882
  store double %1883, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1884 = add i64 %1872, -56
  %1885 = add i64 %1874, 15
  store i64 %1885, i64* %PC, align 8
  %1886 = inttoptr i64 %1884 to i64*
  %1887 = load i64, i64* %1886, align 8
  store i64 %1887, i64* %828, align 1, !tbaa !2451
  store double 0.000000e+00, double* %829, align 1, !tbaa !2451
  %1888 = add i64 %1872, -104
  %1889 = add i64 %1874, 20
  store i64 %1889, i64* %PC, align 8
  %1890 = bitcast i64 %1887 to double
  %1891 = inttoptr i64 %1888 to double*
  %1892 = load double, double* %1891, align 8
  %1893 = fmul double %1890, %1892
  store double %1893, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %1894 = fsub double %1883, %1893
  store double %1894, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1895 = add i64 %1872, -16
  %1896 = add i64 %1874, 28
  store i64 %1896, i64* %PC, align 8
  %1897 = inttoptr i64 %1895 to i64*
  %1898 = load i64, i64* %1897, align 8
  store i64 %1898, i64* %RDX, align 8, !tbaa !2428
  %1899 = add i64 %1872, -28
  %1900 = add i64 %1874, 31
  store i64 %1900, i64* %PC, align 8
  %1901 = inttoptr i64 %1899 to i32*
  %1902 = load i32, i32* %1901, align 4
  %1903 = add i32 %1902, 2
  %1904 = zext i32 %1903 to i64
  store i64 %1904, i64* %RCX, align 8, !tbaa !2428
  %1905 = icmp ugt i32 %1902, -3
  %1906 = zext i1 %1905 to i8
  store i8 %1906, i8* %16, align 1, !tbaa !2432
  %1907 = and i32 %1903, 255
  %1908 = tail call i32 @llvm.ctpop.i32(i32 %1907) #14
  %1909 = trunc i32 %1908 to i8
  %1910 = and i8 %1909, 1
  %1911 = xor i8 %1910, 1
  store i8 %1911, i8* %23, align 1, !tbaa !2446
  %1912 = xor i32 %1903, %1902
  %1913 = lshr i32 %1912, 4
  %1914 = trunc i32 %1913 to i8
  %1915 = and i8 %1914, 1
  store i8 %1915, i8* %29, align 1, !tbaa !2447
  %1916 = icmp eq i32 %1903, 0
  %1917 = zext i1 %1916 to i8
  store i8 %1917, i8* %32, align 1, !tbaa !2448
  %1918 = lshr i32 %1903, 31
  %1919 = trunc i32 %1918 to i8
  store i8 %1919, i8* %35, align 1, !tbaa !2449
  %1920 = lshr i32 %1902, 31
  %1921 = xor i32 %1918, %1920
  %1922 = add nuw nsw i32 %1921, %1918
  %1923 = icmp eq i32 %1922, 2
  %1924 = zext i1 %1923 to i8
  store i8 %1924, i8* %41, align 1, !tbaa !2450
  %1925 = sext i32 %1903 to i64
  store i64 %1925, i64* %RSI, align 8, !tbaa !2428
  %1926 = shl nsw i64 %1925, 3
  %1927 = add i64 %1898, %1926
  %1928 = add i64 %1874, 42
  store i64 %1928, i64* %PC, align 8
  %1929 = inttoptr i64 %1927 to double*
  store double %1894, double* %1929, align 8
  %1930 = load i64, i64* %RBP, align 8
  %1931 = add i64 %1930, -48
  %1932 = load i64, i64* %PC, align 8
  %1933 = add i64 %1932, 5
  store i64 %1933, i64* %PC, align 8
  %1934 = inttoptr i64 %1931 to i64*
  %1935 = load i64, i64* %1934, align 8
  store i64 %1935, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1936 = add i64 %1930, -104
  %1937 = add i64 %1932, 10
  store i64 %1937, i64* %PC, align 8
  %1938 = bitcast i64 %1935 to double
  %1939 = inttoptr i64 %1936 to double*
  %1940 = load double, double* %1939, align 8
  %1941 = fmul double %1938, %1940
  store double %1941, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1942 = add i64 %1930, -56
  %1943 = add i64 %1932, 15
  store i64 %1943, i64* %PC, align 8
  %1944 = inttoptr i64 %1942 to i64*
  %1945 = load i64, i64* %1944, align 8
  store i64 %1945, i64* %828, align 1, !tbaa !2451
  store double 0.000000e+00, double* %829, align 1, !tbaa !2451
  %1946 = add i64 %1930, -96
  %1947 = add i64 %1932, 20
  store i64 %1947, i64* %PC, align 8
  %1948 = bitcast i64 %1945 to double
  %1949 = inttoptr i64 %1946 to double*
  %1950 = load double, double* %1949, align 8
  %1951 = fmul double %1948, %1950
  store double %1951, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %1952 = fadd double %1941, %1951
  store double %1952, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1953 = add i64 %1930, -16
  %1954 = add i64 %1932, 28
  store i64 %1954, i64* %PC, align 8
  %1955 = inttoptr i64 %1953 to i64*
  %1956 = load i64, i64* %1955, align 8
  store i64 %1956, i64* %RDX, align 8, !tbaa !2428
  %1957 = add i64 %1930, -28
  %1958 = add i64 %1932, 31
  store i64 %1958, i64* %PC, align 8
  %1959 = inttoptr i64 %1957 to i32*
  %1960 = load i32, i32* %1959, align 4
  %1961 = add i32 %1960, 3
  %1962 = zext i32 %1961 to i64
  store i64 %1962, i64* %RCX, align 8, !tbaa !2428
  %1963 = icmp ugt i32 %1960, -4
  %1964 = zext i1 %1963 to i8
  store i8 %1964, i8* %16, align 1, !tbaa !2432
  %1965 = and i32 %1961, 255
  %1966 = tail call i32 @llvm.ctpop.i32(i32 %1965) #14
  %1967 = trunc i32 %1966 to i8
  %1968 = and i8 %1967, 1
  %1969 = xor i8 %1968, 1
  store i8 %1969, i8* %23, align 1, !tbaa !2446
  %1970 = xor i32 %1961, %1960
  %1971 = lshr i32 %1970, 4
  %1972 = trunc i32 %1971 to i8
  %1973 = and i8 %1972, 1
  store i8 %1973, i8* %29, align 1, !tbaa !2447
  %1974 = icmp eq i32 %1961, 0
  %1975 = zext i1 %1974 to i8
  store i8 %1975, i8* %32, align 1, !tbaa !2448
  %1976 = lshr i32 %1961, 31
  %1977 = trunc i32 %1976 to i8
  store i8 %1977, i8* %35, align 1, !tbaa !2449
  %1978 = lshr i32 %1960, 31
  %1979 = xor i32 %1976, %1978
  %1980 = add nuw nsw i32 %1979, %1976
  %1981 = icmp eq i32 %1980, 2
  %1982 = zext i1 %1981 to i8
  store i8 %1982, i8* %41, align 1, !tbaa !2450
  %1983 = sext i32 %1961 to i64
  store i64 %1983, i64* %RSI, align 8, !tbaa !2428
  %1984 = shl nsw i64 %1983, 3
  %1985 = add i64 %1956, %1984
  %1986 = add i64 %1932, 42
  store i64 %1986, i64* %PC, align 8
  %1987 = inttoptr i64 %1985 to double*
  store double %1952, double* %1987, align 8
  %1988 = load i64, i64* %RBP, align 8
  %1989 = add i64 %1988, -112
  %1990 = load i64, i64* %PC, align 8
  %1991 = add i64 %1990, 5
  store i64 %1991, i64* %PC, align 8
  %1992 = inttoptr i64 %1989 to i64*
  %1993 = load i64, i64* %1992, align 8
  store i64 %1993, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1994 = add i64 %1988, -152
  %1995 = add i64 %1990, 13
  store i64 %1995, i64* %PC, align 8
  %1996 = bitcast i64 %1993 to double
  %1997 = inttoptr i64 %1994 to double*
  %1998 = load double, double* %1997, align 8
  %1999 = fadd double %1996, %1998
  store double %1999, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2000 = add i64 %1988, -96
  %2001 = add i64 %1990, 18
  store i64 %2001, i64* %PC, align 8
  %2002 = inttoptr i64 %2000 to double*
  store double %1999, double* %2002, align 8
  %2003 = load i64, i64* %RBP, align 8
  %2004 = add i64 %2003, -120
  %2005 = load i64, i64* %PC, align 8
  %2006 = add i64 %2005, 5
  store i64 %2006, i64* %PC, align 8
  %2007 = inttoptr i64 %2004 to i64*
  %2008 = load i64, i64* %2007, align 8
  store i64 %2008, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %2009 = add i64 %2003, -144
  %2010 = add i64 %2005, 13
  store i64 %2010, i64* %PC, align 8
  %2011 = bitcast i64 %2008 to double
  %2012 = inttoptr i64 %2009 to double*
  %2013 = load double, double* %2012, align 8
  %2014 = fsub double %2011, %2013
  store double %2014, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2015 = add i64 %2003, -104
  %2016 = add i64 %2005, 18
  store i64 %2016, i64* %PC, align 8
  %2017 = inttoptr i64 %2015 to double*
  store double %2014, double* %2017, align 8
  %2018 = load i64, i64* %RBP, align 8
  %2019 = add i64 %2018, -80
  %2020 = load i64, i64* %PC, align 8
  %2021 = add i64 %2020, 5
  store i64 %2021, i64* %PC, align 8
  %2022 = inttoptr i64 %2019 to i64*
  %2023 = load i64, i64* %2022, align 8
  store i64 %2023, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %2024 = add i64 %2018, -96
  %2025 = add i64 %2020, 10
  store i64 %2025, i64* %PC, align 8
  %2026 = bitcast i64 %2023 to double
  %2027 = inttoptr i64 %2024 to double*
  %2028 = load double, double* %2027, align 8
  %2029 = fmul double %2026, %2028
  store double %2029, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2030 = add i64 %2018, -88
  %2031 = add i64 %2020, 15
  store i64 %2031, i64* %PC, align 8
  %2032 = inttoptr i64 %2030 to i64*
  %2033 = load i64, i64* %2032, align 8
  store i64 %2033, i64* %828, align 1, !tbaa !2451
  store double 0.000000e+00, double* %829, align 1, !tbaa !2451
  %2034 = add i64 %2018, -104
  %2035 = add i64 %2020, 20
  store i64 %2035, i64* %PC, align 8
  %2036 = bitcast i64 %2033 to double
  %2037 = inttoptr i64 %2034 to double*
  %2038 = load double, double* %2037, align 8
  %2039 = fmul double %2036, %2038
  store double %2039, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %2040 = fsub double %2029, %2039
  store double %2040, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2041 = add i64 %2018, -16
  %2042 = add i64 %2020, 28
  store i64 %2042, i64* %PC, align 8
  %2043 = inttoptr i64 %2041 to i64*
  %2044 = load i64, i64* %2043, align 8
  store i64 %2044, i64* %RDX, align 8, !tbaa !2428
  %2045 = add i64 %2018, -28
  %2046 = add i64 %2020, 31
  store i64 %2046, i64* %PC, align 8
  %2047 = inttoptr i64 %2045 to i32*
  %2048 = load i32, i32* %2047, align 4
  %2049 = add i32 %2048, 6
  %2050 = zext i32 %2049 to i64
  store i64 %2050, i64* %RCX, align 8, !tbaa !2428
  %2051 = icmp ugt i32 %2048, -7
  %2052 = zext i1 %2051 to i8
  store i8 %2052, i8* %16, align 1, !tbaa !2432
  %2053 = and i32 %2049, 255
  %2054 = tail call i32 @llvm.ctpop.i32(i32 %2053) #14
  %2055 = trunc i32 %2054 to i8
  %2056 = and i8 %2055, 1
  %2057 = xor i8 %2056, 1
  store i8 %2057, i8* %23, align 1, !tbaa !2446
  %2058 = xor i32 %2049, %2048
  %2059 = lshr i32 %2058, 4
  %2060 = trunc i32 %2059 to i8
  %2061 = and i8 %2060, 1
  store i8 %2061, i8* %29, align 1, !tbaa !2447
  %2062 = icmp eq i32 %2049, 0
  %2063 = zext i1 %2062 to i8
  store i8 %2063, i8* %32, align 1, !tbaa !2448
  %2064 = lshr i32 %2049, 31
  %2065 = trunc i32 %2064 to i8
  store i8 %2065, i8* %35, align 1, !tbaa !2449
  %2066 = lshr i32 %2048, 31
  %2067 = xor i32 %2064, %2066
  %2068 = add nuw nsw i32 %2067, %2064
  %2069 = icmp eq i32 %2068, 2
  %2070 = zext i1 %2069 to i8
  store i8 %2070, i8* %41, align 1, !tbaa !2450
  %2071 = sext i32 %2049 to i64
  store i64 %2071, i64* %RSI, align 8, !tbaa !2428
  %2072 = shl nsw i64 %2071, 3
  %2073 = add i64 %2044, %2072
  %2074 = add i64 %2020, 42
  store i64 %2074, i64* %PC, align 8
  %2075 = inttoptr i64 %2073 to double*
  store double %2040, double* %2075, align 8
  %2076 = load i64, i64* %RBP, align 8
  %2077 = add i64 %2076, -80
  %2078 = load i64, i64* %PC, align 8
  %2079 = add i64 %2078, 5
  store i64 %2079, i64* %PC, align 8
  %2080 = inttoptr i64 %2077 to i64*
  %2081 = load i64, i64* %2080, align 8
  store i64 %2081, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %2082 = add i64 %2076, -104
  %2083 = add i64 %2078, 10
  store i64 %2083, i64* %PC, align 8
  %2084 = bitcast i64 %2081 to double
  %2085 = inttoptr i64 %2082 to double*
  %2086 = load double, double* %2085, align 8
  %2087 = fmul double %2084, %2086
  store double %2087, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2088 = add i64 %2076, -88
  %2089 = add i64 %2078, 15
  store i64 %2089, i64* %PC, align 8
  %2090 = inttoptr i64 %2088 to i64*
  %2091 = load i64, i64* %2090, align 8
  store i64 %2091, i64* %828, align 1, !tbaa !2451
  store double 0.000000e+00, double* %829, align 1, !tbaa !2451
  %2092 = add i64 %2076, -96
  %2093 = add i64 %2078, 20
  store i64 %2093, i64* %PC, align 8
  %2094 = bitcast i64 %2091 to double
  %2095 = inttoptr i64 %2092 to double*
  %2096 = load double, double* %2095, align 8
  %2097 = fmul double %2094, %2096
  store double %2097, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %2098 = fadd double %2087, %2097
  store double %2098, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2099 = add i64 %2076, -16
  %2100 = add i64 %2078, 28
  store i64 %2100, i64* %PC, align 8
  %2101 = inttoptr i64 %2099 to i64*
  %2102 = load i64, i64* %2101, align 8
  store i64 %2102, i64* %RDX, align 8, !tbaa !2428
  %2103 = add i64 %2076, -28
  %2104 = add i64 %2078, 31
  store i64 %2104, i64* %PC, align 8
  %2105 = inttoptr i64 %2103 to i32*
  %2106 = load i32, i32* %2105, align 4
  %2107 = add i32 %2106, 7
  %2108 = zext i32 %2107 to i64
  store i64 %2108, i64* %RCX, align 8, !tbaa !2428
  %2109 = icmp ugt i32 %2106, -8
  %2110 = zext i1 %2109 to i8
  store i8 %2110, i8* %16, align 1, !tbaa !2432
  %2111 = and i32 %2107, 255
  %2112 = tail call i32 @llvm.ctpop.i32(i32 %2111) #14
  %2113 = trunc i32 %2112 to i8
  %2114 = and i8 %2113, 1
  %2115 = xor i8 %2114, 1
  store i8 %2115, i8* %23, align 1, !tbaa !2446
  %2116 = xor i32 %2107, %2106
  %2117 = lshr i32 %2116, 4
  %2118 = trunc i32 %2117 to i8
  %2119 = and i8 %2118, 1
  store i8 %2119, i8* %29, align 1, !tbaa !2447
  %2120 = icmp eq i32 %2107, 0
  %2121 = zext i1 %2120 to i8
  store i8 %2121, i8* %32, align 1, !tbaa !2448
  %2122 = lshr i32 %2107, 31
  %2123 = trunc i32 %2122 to i8
  store i8 %2123, i8* %35, align 1, !tbaa !2449
  %2124 = lshr i32 %2106, 31
  %2125 = xor i32 %2122, %2124
  %2126 = add nuw nsw i32 %2125, %2122
  %2127 = icmp eq i32 %2126, 2
  %2128 = zext i1 %2127 to i8
  store i8 %2128, i8* %41, align 1, !tbaa !2450
  %2129 = sext i32 %2107 to i64
  store i64 %2129, i64* %RSI, align 8, !tbaa !2428
  %2130 = shl nsw i64 %2129, 3
  %2131 = add i64 %2102, %2130
  %2132 = add i64 %2078, 42
  store i64 %2132, i64* %PC, align 8
  %2133 = inttoptr i64 %2131 to double*
  store double %2098, double* %2133, align 8
  %2134 = load i64, i64* %RBP, align 8
  %2135 = add i64 %2134, -24
  %2136 = load i64, i64* %PC, align 8
  %2137 = add i64 %2136, 4
  store i64 %2137, i64* %PC, align 8
  %2138 = inttoptr i64 %2135 to i64*
  %2139 = load i64, i64* %2138, align 8
  store i64 %2139, i64* %RDX, align 8, !tbaa !2428
  %2140 = add i64 %2134, -36
  %2141 = add i64 %2136, 7
  store i64 %2141, i64* %PC, align 8
  %2142 = inttoptr i64 %2140 to i32*
  %2143 = load i32, i32* %2142, align 4
  %2144 = add i32 %2143, 2
  %2145 = zext i32 %2144 to i64
  store i64 %2145, i64* %RCX, align 8, !tbaa !2428
  %2146 = icmp ugt i32 %2143, -3
  %2147 = zext i1 %2146 to i8
  store i8 %2147, i8* %16, align 1, !tbaa !2432
  %2148 = and i32 %2144, 255
  %2149 = tail call i32 @llvm.ctpop.i32(i32 %2148) #14
  %2150 = trunc i32 %2149 to i8
  %2151 = and i8 %2150, 1
  %2152 = xor i8 %2151, 1
  store i8 %2152, i8* %23, align 1, !tbaa !2446
  %2153 = xor i32 %2144, %2143
  %2154 = lshr i32 %2153, 4
  %2155 = trunc i32 %2154 to i8
  %2156 = and i8 %2155, 1
  store i8 %2156, i8* %29, align 1, !tbaa !2447
  %2157 = icmp eq i32 %2144, 0
  %2158 = zext i1 %2157 to i8
  store i8 %2158, i8* %32, align 1, !tbaa !2448
  %2159 = lshr i32 %2144, 31
  %2160 = trunc i32 %2159 to i8
  store i8 %2160, i8* %35, align 1, !tbaa !2449
  %2161 = lshr i32 %2143, 31
  %2162 = xor i32 %2159, %2161
  %2163 = add nuw nsw i32 %2162, %2159
  %2164 = icmp eq i32 %2163, 2
  %2165 = zext i1 %2164 to i8
  store i8 %2165, i8* %41, align 1, !tbaa !2450
  %2166 = sext i32 %2144 to i64
  store i64 %2166, i64* %RSI, align 8, !tbaa !2428
  %2167 = shl nsw i64 %2166, 3
  %2168 = add i64 %2139, %2167
  %2169 = add i64 %2136, 18
  store i64 %2169, i64* %PC, align 8
  %2170 = inttoptr i64 %2168 to i64*
  %2171 = load i64, i64* %2170, align 8
  store i64 %2171, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %2172 = add i64 %2134, -48
  %2173 = add i64 %2136, 23
  store i64 %2173, i64* %PC, align 8
  %2174 = inttoptr i64 %2172 to i64*
  store i64 %2171, i64* %2174, align 8
  %2175 = load i64, i64* %RBP, align 8
  %2176 = add i64 %2175, -24
  %2177 = load i64, i64* %PC, align 8
  %2178 = add i64 %2177, 4
  store i64 %2178, i64* %PC, align 8
  %2179 = inttoptr i64 %2176 to i64*
  %2180 = load i64, i64* %2179, align 8
  store i64 %2180, i64* %RDX, align 8, !tbaa !2428
  %2181 = add i64 %2175, -36
  %2182 = add i64 %2177, 7
  store i64 %2182, i64* %PC, align 8
  %2183 = inttoptr i64 %2181 to i32*
  %2184 = load i32, i32* %2183, align 4
  %2185 = add i32 %2184, 3
  %2186 = zext i32 %2185 to i64
  store i64 %2186, i64* %RCX, align 8, !tbaa !2428
  %2187 = icmp ugt i32 %2184, -4
  %2188 = zext i1 %2187 to i8
  store i8 %2188, i8* %16, align 1, !tbaa !2432
  %2189 = and i32 %2185, 255
  %2190 = tail call i32 @llvm.ctpop.i32(i32 %2189) #14
  %2191 = trunc i32 %2190 to i8
  %2192 = and i8 %2191, 1
  %2193 = xor i8 %2192, 1
  store i8 %2193, i8* %23, align 1, !tbaa !2446
  %2194 = xor i32 %2185, %2184
  %2195 = lshr i32 %2194, 4
  %2196 = trunc i32 %2195 to i8
  %2197 = and i8 %2196, 1
  store i8 %2197, i8* %29, align 1, !tbaa !2447
  %2198 = icmp eq i32 %2185, 0
  %2199 = zext i1 %2198 to i8
  store i8 %2199, i8* %32, align 1, !tbaa !2448
  %2200 = lshr i32 %2185, 31
  %2201 = trunc i32 %2200 to i8
  store i8 %2201, i8* %35, align 1, !tbaa !2449
  %2202 = lshr i32 %2184, 31
  %2203 = xor i32 %2200, %2202
  %2204 = add nuw nsw i32 %2203, %2200
  %2205 = icmp eq i32 %2204, 2
  %2206 = zext i1 %2205 to i8
  store i8 %2206, i8* %41, align 1, !tbaa !2450
  %2207 = sext i32 %2185 to i64
  store i64 %2207, i64* %RSI, align 8, !tbaa !2428
  %2208 = shl nsw i64 %2207, 3
  %2209 = add i64 %2180, %2208
  %2210 = add i64 %2177, 18
  store i64 %2210, i64* %PC, align 8
  %2211 = inttoptr i64 %2209 to i64*
  %2212 = load i64, i64* %2211, align 8
  store i64 %2212, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %2213 = add i64 %2175, -56
  %2214 = add i64 %2177, 23
  store i64 %2214, i64* %PC, align 8
  %2215 = inttoptr i64 %2213 to i64*
  store i64 %2212, i64* %2215, align 8
  %2216 = load i64, i64* %RBP, align 8
  %2217 = add i64 %2216, -48
  %2218 = load i64, i64* %PC, align 8
  %2219 = add i64 %2218, 5
  store i64 %2219, i64* %PC, align 8
  %2220 = inttoptr i64 %2217 to i64*
  %2221 = load i64, i64* %2220, align 8
  store i64 %2221, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %2222 = load <2 x i32>, <2 x i32>* %812, align 1
  %2223 = load <2 x i32>, <2 x i32>* %813, align 1
  %2224 = extractelement <2 x i32> %2222, i32 0
  store i32 %2224, i32* %814, align 1, !tbaa !2475
  %2225 = extractelement <2 x i32> %2222, i32 1
  store i32 %2225, i32* %816, align 1, !tbaa !2475
  %2226 = extractelement <2 x i32> %2223, i32 0
  store i32 %2226, i32* %818, align 1, !tbaa !2475
  %2227 = extractelement <2 x i32> %2223, i32 1
  store i32 %2227, i32* %820, align 1, !tbaa !2475
  %2228 = add i64 %2216, -64
  %2229 = add i64 %2218, 13
  store i64 %2229, i64* %PC, align 8
  %2230 = load double, double* %821, align 1
  %2231 = inttoptr i64 %2228 to double*
  %2232 = load double, double* %2231, align 8
  %2233 = fmul double %2230, %2232
  store double %2233, double* %821, align 1, !tbaa !2451
  %2234 = add i64 %2216, -56
  %2235 = add i64 %2218, 18
  store i64 %2235, i64* %PC, align 8
  %2236 = inttoptr i64 %2234 to double*
  %2237 = load double, double* %2236, align 8
  %2238 = fmul double %2233, %2237
  store double %2238, double* %821, align 1, !tbaa !2451
  %2239 = bitcast i64 %2221 to double
  %2240 = fsub double %2239, %2238
  store double %2240, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2241 = add i64 %2216, -80
  %2242 = add i64 %2218, 27
  store i64 %2242, i64* %PC, align 8
  %2243 = inttoptr i64 %2241 to double*
  store double %2240, double* %2243, align 8
  %2244 = load i64, i64* %RBP, align 8
  %2245 = add i64 %2244, -64
  %2246 = load i64, i64* %PC, align 8
  %2247 = add i64 %2246, 5
  store i64 %2247, i64* %PC, align 8
  %2248 = load double, double* %67, align 1
  %2249 = inttoptr i64 %2245 to double*
  %2250 = load double, double* %2249, align 8
  %2251 = fmul double %2248, %2250
  store double %2251, double* %67, align 1, !tbaa !2451
  %2252 = add i64 %2244, -48
  %2253 = add i64 %2246, 10
  store i64 %2253, i64* %PC, align 8
  %2254 = inttoptr i64 %2252 to double*
  %2255 = load double, double* %2254, align 8
  %2256 = fmul double %2251, %2255
  store double %2256, double* %67, align 1, !tbaa !2451
  %2257 = add i64 %2244, -56
  %2258 = add i64 %2246, 15
  store i64 %2258, i64* %PC, align 8
  %2259 = inttoptr i64 %2257 to double*
  %2260 = load double, double* %2259, align 8
  %2261 = fsub double %2256, %2260
  store double %2261, double* %67, align 1, !tbaa !2451
  %2262 = add i64 %2244, -88
  %2263 = add i64 %2246, 20
  store i64 %2263, i64* %PC, align 8
  %2264 = inttoptr i64 %2262 to double*
  store double %2261, double* %2264, align 8
  %2265 = load i64, i64* %RBP, align 8
  %2266 = add i64 %2265, -16
  %2267 = load i64, i64* %PC, align 8
  %2268 = add i64 %2267, 4
  store i64 %2268, i64* %PC, align 8
  %2269 = inttoptr i64 %2266 to i64*
  %2270 = load i64, i64* %2269, align 8
  store i64 %2270, i64* %RDX, align 8, !tbaa !2428
  %2271 = add i64 %2265, -28
  %2272 = add i64 %2267, 7
  store i64 %2272, i64* %PC, align 8
  %2273 = inttoptr i64 %2271 to i32*
  %2274 = load i32, i32* %2273, align 4
  %2275 = add i32 %2274, 8
  %2276 = zext i32 %2275 to i64
  store i64 %2276, i64* %RCX, align 8, !tbaa !2428
  %2277 = icmp ugt i32 %2274, -9
  %2278 = zext i1 %2277 to i8
  store i8 %2278, i8* %16, align 1, !tbaa !2432
  %2279 = and i32 %2275, 255
  %2280 = tail call i32 @llvm.ctpop.i32(i32 %2279) #14
  %2281 = trunc i32 %2280 to i8
  %2282 = and i8 %2281, 1
  %2283 = xor i8 %2282, 1
  store i8 %2283, i8* %23, align 1, !tbaa !2446
  %2284 = xor i32 %2275, %2274
  %2285 = lshr i32 %2284, 4
  %2286 = trunc i32 %2285 to i8
  %2287 = and i8 %2286, 1
  store i8 %2287, i8* %29, align 1, !tbaa !2447
  %2288 = icmp eq i32 %2275, 0
  %2289 = zext i1 %2288 to i8
  store i8 %2289, i8* %32, align 1, !tbaa !2448
  %2290 = lshr i32 %2275, 31
  %2291 = trunc i32 %2290 to i8
  store i8 %2291, i8* %35, align 1, !tbaa !2449
  %2292 = lshr i32 %2274, 31
  %2293 = xor i32 %2290, %2292
  %2294 = add nuw nsw i32 %2293, %2290
  %2295 = icmp eq i32 %2294, 2
  %2296 = zext i1 %2295 to i8
  store i8 %2296, i8* %41, align 1, !tbaa !2450
  %2297 = sext i32 %2275 to i64
  store i64 %2297, i64* %RSI, align 8, !tbaa !2428
  %2298 = shl nsw i64 %2297, 3
  %2299 = add i64 %2270, %2298
  %2300 = add i64 %2267, 18
  store i64 %2300, i64* %PC, align 8
  %2301 = inttoptr i64 %2299 to i64*
  %2302 = load i64, i64* %2301, align 8
  store i64 %2302, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2303 = add i64 %2267, 22
  store i64 %2303, i64* %PC, align 8
  %2304 = load i64, i64* %2269, align 8
  store i64 %2304, i64* %RDX, align 8, !tbaa !2428
  %2305 = add i64 %2267, 25
  store i64 %2305, i64* %PC, align 8
  %2306 = load i32, i32* %2273, align 4
  %2307 = add i32 %2306, 10
  %2308 = zext i32 %2307 to i64
  store i64 %2308, i64* %RCX, align 8, !tbaa !2428
  %2309 = icmp ugt i32 %2306, -11
  %2310 = zext i1 %2309 to i8
  store i8 %2310, i8* %16, align 1, !tbaa !2432
  %2311 = and i32 %2307, 255
  %2312 = tail call i32 @llvm.ctpop.i32(i32 %2311) #14
  %2313 = trunc i32 %2312 to i8
  %2314 = and i8 %2313, 1
  %2315 = xor i8 %2314, 1
  store i8 %2315, i8* %23, align 1, !tbaa !2446
  %2316 = xor i32 %2307, %2306
  %2317 = lshr i32 %2316, 4
  %2318 = trunc i32 %2317 to i8
  %2319 = and i8 %2318, 1
  store i8 %2319, i8* %29, align 1, !tbaa !2447
  %2320 = icmp eq i32 %2307, 0
  %2321 = zext i1 %2320 to i8
  store i8 %2321, i8* %32, align 1, !tbaa !2448
  %2322 = lshr i32 %2307, 31
  %2323 = trunc i32 %2322 to i8
  store i8 %2323, i8* %35, align 1, !tbaa !2449
  %2324 = lshr i32 %2306, 31
  %2325 = xor i32 %2322, %2324
  %2326 = add nuw nsw i32 %2325, %2322
  %2327 = icmp eq i32 %2326, 2
  %2328 = zext i1 %2327 to i8
  store i8 %2328, i8* %41, align 1, !tbaa !2450
  %2329 = sext i32 %2307 to i64
  store i64 %2329, i64* %RSI, align 8, !tbaa !2428
  %2330 = shl nsw i64 %2329, 3
  %2331 = add i64 %2304, %2330
  %2332 = add i64 %2267, 36
  store i64 %2332, i64* %PC, align 8
  %2333 = bitcast i64 %2302 to double
  %2334 = inttoptr i64 %2331 to double*
  %2335 = load double, double* %2334, align 8
  %2336 = fadd double %2333, %2335
  store double %2336, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2337 = load i64, i64* %RBP, align 8
  %2338 = add i64 %2337, -96
  %2339 = add i64 %2267, 41
  store i64 %2339, i64* %PC, align 8
  %2340 = inttoptr i64 %2338 to double*
  store double %2336, double* %2340, align 8
  %2341 = load i64, i64* %RBP, align 8
  %2342 = add i64 %2341, -16
  %2343 = load i64, i64* %PC, align 8
  %2344 = add i64 %2343, 4
  store i64 %2344, i64* %PC, align 8
  %2345 = inttoptr i64 %2342 to i64*
  %2346 = load i64, i64* %2345, align 8
  store i64 %2346, i64* %RDX, align 8, !tbaa !2428
  %2347 = add i64 %2341, -28
  %2348 = add i64 %2343, 7
  store i64 %2348, i64* %PC, align 8
  %2349 = inttoptr i64 %2347 to i32*
  %2350 = load i32, i32* %2349, align 4
  %2351 = add i32 %2350, 9
  %2352 = zext i32 %2351 to i64
  store i64 %2352, i64* %RCX, align 8, !tbaa !2428
  %2353 = icmp ugt i32 %2350, -10
  %2354 = zext i1 %2353 to i8
  store i8 %2354, i8* %16, align 1, !tbaa !2432
  %2355 = and i32 %2351, 255
  %2356 = tail call i32 @llvm.ctpop.i32(i32 %2355) #14
  %2357 = trunc i32 %2356 to i8
  %2358 = and i8 %2357, 1
  %2359 = xor i8 %2358, 1
  store i8 %2359, i8* %23, align 1, !tbaa !2446
  %2360 = xor i32 %2351, %2350
  %2361 = lshr i32 %2360, 4
  %2362 = trunc i32 %2361 to i8
  %2363 = and i8 %2362, 1
  store i8 %2363, i8* %29, align 1, !tbaa !2447
  %2364 = icmp eq i32 %2351, 0
  %2365 = zext i1 %2364 to i8
  store i8 %2365, i8* %32, align 1, !tbaa !2448
  %2366 = lshr i32 %2351, 31
  %2367 = trunc i32 %2366 to i8
  store i8 %2367, i8* %35, align 1, !tbaa !2449
  %2368 = lshr i32 %2350, 31
  %2369 = xor i32 %2366, %2368
  %2370 = add nuw nsw i32 %2369, %2366
  %2371 = icmp eq i32 %2370, 2
  %2372 = zext i1 %2371 to i8
  store i8 %2372, i8* %41, align 1, !tbaa !2450
  %2373 = sext i32 %2351 to i64
  store i64 %2373, i64* %RSI, align 8, !tbaa !2428
  %2374 = shl nsw i64 %2373, 3
  %2375 = add i64 %2346, %2374
  %2376 = add i64 %2343, 18
  store i64 %2376, i64* %PC, align 8
  %2377 = inttoptr i64 %2375 to i64*
  %2378 = load i64, i64* %2377, align 8
  store i64 %2378, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2379 = add i64 %2343, 22
  store i64 %2379, i64* %PC, align 8
  %2380 = load i64, i64* %2345, align 8
  store i64 %2380, i64* %RDX, align 8, !tbaa !2428
  %2381 = add i64 %2343, 25
  store i64 %2381, i64* %PC, align 8
  %2382 = load i32, i32* %2349, align 4
  %2383 = add i32 %2382, 11
  %2384 = zext i32 %2383 to i64
  store i64 %2384, i64* %RCX, align 8, !tbaa !2428
  %2385 = icmp ugt i32 %2382, -12
  %2386 = zext i1 %2385 to i8
  store i8 %2386, i8* %16, align 1, !tbaa !2432
  %2387 = and i32 %2383, 255
  %2388 = tail call i32 @llvm.ctpop.i32(i32 %2387) #14
  %2389 = trunc i32 %2388 to i8
  %2390 = and i8 %2389, 1
  %2391 = xor i8 %2390, 1
  store i8 %2391, i8* %23, align 1, !tbaa !2446
  %2392 = xor i32 %2383, %2382
  %2393 = lshr i32 %2392, 4
  %2394 = trunc i32 %2393 to i8
  %2395 = and i8 %2394, 1
  store i8 %2395, i8* %29, align 1, !tbaa !2447
  %2396 = icmp eq i32 %2383, 0
  %2397 = zext i1 %2396 to i8
  store i8 %2397, i8* %32, align 1, !tbaa !2448
  %2398 = lshr i32 %2383, 31
  %2399 = trunc i32 %2398 to i8
  store i8 %2399, i8* %35, align 1, !tbaa !2449
  %2400 = lshr i32 %2382, 31
  %2401 = xor i32 %2398, %2400
  %2402 = add nuw nsw i32 %2401, %2398
  %2403 = icmp eq i32 %2402, 2
  %2404 = zext i1 %2403 to i8
  store i8 %2404, i8* %41, align 1, !tbaa !2450
  %2405 = sext i32 %2383 to i64
  store i64 %2405, i64* %RSI, align 8, !tbaa !2428
  %2406 = shl nsw i64 %2405, 3
  %2407 = add i64 %2380, %2406
  %2408 = add i64 %2343, 36
  store i64 %2408, i64* %PC, align 8
  %2409 = bitcast i64 %2378 to double
  %2410 = inttoptr i64 %2407 to double*
  %2411 = load double, double* %2410, align 8
  %2412 = fadd double %2409, %2411
  store double %2412, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2413 = load i64, i64* %RBP, align 8
  %2414 = add i64 %2413, -104
  %2415 = add i64 %2343, 41
  store i64 %2415, i64* %PC, align 8
  %2416 = inttoptr i64 %2414 to double*
  store double %2412, double* %2416, align 8
  %2417 = load i64, i64* %RBP, align 8
  %2418 = add i64 %2417, -16
  %2419 = load i64, i64* %PC, align 8
  %2420 = add i64 %2419, 4
  store i64 %2420, i64* %PC, align 8
  %2421 = inttoptr i64 %2418 to i64*
  %2422 = load i64, i64* %2421, align 8
  store i64 %2422, i64* %RDX, align 8, !tbaa !2428
  %2423 = add i64 %2417, -28
  %2424 = add i64 %2419, 7
  store i64 %2424, i64* %PC, align 8
  %2425 = inttoptr i64 %2423 to i32*
  %2426 = load i32, i32* %2425, align 4
  %2427 = add i32 %2426, 8
  %2428 = zext i32 %2427 to i64
  store i64 %2428, i64* %RCX, align 8, !tbaa !2428
  %2429 = icmp ugt i32 %2426, -9
  %2430 = zext i1 %2429 to i8
  store i8 %2430, i8* %16, align 1, !tbaa !2432
  %2431 = and i32 %2427, 255
  %2432 = tail call i32 @llvm.ctpop.i32(i32 %2431) #14
  %2433 = trunc i32 %2432 to i8
  %2434 = and i8 %2433, 1
  %2435 = xor i8 %2434, 1
  store i8 %2435, i8* %23, align 1, !tbaa !2446
  %2436 = xor i32 %2427, %2426
  %2437 = lshr i32 %2436, 4
  %2438 = trunc i32 %2437 to i8
  %2439 = and i8 %2438, 1
  store i8 %2439, i8* %29, align 1, !tbaa !2447
  %2440 = icmp eq i32 %2427, 0
  %2441 = zext i1 %2440 to i8
  store i8 %2441, i8* %32, align 1, !tbaa !2448
  %2442 = lshr i32 %2427, 31
  %2443 = trunc i32 %2442 to i8
  store i8 %2443, i8* %35, align 1, !tbaa !2449
  %2444 = lshr i32 %2426, 31
  %2445 = xor i32 %2442, %2444
  %2446 = add nuw nsw i32 %2445, %2442
  %2447 = icmp eq i32 %2446, 2
  %2448 = zext i1 %2447 to i8
  store i8 %2448, i8* %41, align 1, !tbaa !2450
  %2449 = sext i32 %2427 to i64
  store i64 %2449, i64* %RSI, align 8, !tbaa !2428
  %2450 = shl nsw i64 %2449, 3
  %2451 = add i64 %2422, %2450
  %2452 = add i64 %2419, 18
  store i64 %2452, i64* %PC, align 8
  %2453 = inttoptr i64 %2451 to i64*
  %2454 = load i64, i64* %2453, align 8
  store i64 %2454, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2455 = add i64 %2419, 22
  store i64 %2455, i64* %PC, align 8
  %2456 = load i64, i64* %2421, align 8
  store i64 %2456, i64* %RDX, align 8, !tbaa !2428
  %2457 = add i64 %2419, 25
  store i64 %2457, i64* %PC, align 8
  %2458 = load i32, i32* %2425, align 4
  %2459 = add i32 %2458, 10
  %2460 = zext i32 %2459 to i64
  store i64 %2460, i64* %RCX, align 8, !tbaa !2428
  %2461 = icmp ugt i32 %2458, -11
  %2462 = zext i1 %2461 to i8
  store i8 %2462, i8* %16, align 1, !tbaa !2432
  %2463 = and i32 %2459, 255
  %2464 = tail call i32 @llvm.ctpop.i32(i32 %2463) #14
  %2465 = trunc i32 %2464 to i8
  %2466 = and i8 %2465, 1
  %2467 = xor i8 %2466, 1
  store i8 %2467, i8* %23, align 1, !tbaa !2446
  %2468 = xor i32 %2459, %2458
  %2469 = lshr i32 %2468, 4
  %2470 = trunc i32 %2469 to i8
  %2471 = and i8 %2470, 1
  store i8 %2471, i8* %29, align 1, !tbaa !2447
  %2472 = icmp eq i32 %2459, 0
  %2473 = zext i1 %2472 to i8
  store i8 %2473, i8* %32, align 1, !tbaa !2448
  %2474 = lshr i32 %2459, 31
  %2475 = trunc i32 %2474 to i8
  store i8 %2475, i8* %35, align 1, !tbaa !2449
  %2476 = lshr i32 %2458, 31
  %2477 = xor i32 %2474, %2476
  %2478 = add nuw nsw i32 %2477, %2474
  %2479 = icmp eq i32 %2478, 2
  %2480 = zext i1 %2479 to i8
  store i8 %2480, i8* %41, align 1, !tbaa !2450
  %2481 = sext i32 %2459 to i64
  store i64 %2481, i64* %RSI, align 8, !tbaa !2428
  %2482 = shl nsw i64 %2481, 3
  %2483 = add i64 %2456, %2482
  %2484 = add i64 %2419, 36
  store i64 %2484, i64* %PC, align 8
  %2485 = bitcast i64 %2454 to double
  %2486 = inttoptr i64 %2483 to double*
  %2487 = load double, double* %2486, align 8
  %2488 = fsub double %2485, %2487
  store double %2488, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2489 = load i64, i64* %RBP, align 8
  %2490 = add i64 %2489, -112
  %2491 = add i64 %2419, 41
  store i64 %2491, i64* %PC, align 8
  %2492 = inttoptr i64 %2490 to double*
  store double %2488, double* %2492, align 8
  %2493 = load i64, i64* %RBP, align 8
  %2494 = add i64 %2493, -16
  %2495 = load i64, i64* %PC, align 8
  %2496 = add i64 %2495, 4
  store i64 %2496, i64* %PC, align 8
  %2497 = inttoptr i64 %2494 to i64*
  %2498 = load i64, i64* %2497, align 8
  store i64 %2498, i64* %RDX, align 8, !tbaa !2428
  %2499 = add i64 %2493, -28
  %2500 = add i64 %2495, 7
  store i64 %2500, i64* %PC, align 8
  %2501 = inttoptr i64 %2499 to i32*
  %2502 = load i32, i32* %2501, align 4
  %2503 = add i32 %2502, 9
  %2504 = zext i32 %2503 to i64
  store i64 %2504, i64* %RCX, align 8, !tbaa !2428
  %2505 = icmp ugt i32 %2502, -10
  %2506 = zext i1 %2505 to i8
  store i8 %2506, i8* %16, align 1, !tbaa !2432
  %2507 = and i32 %2503, 255
  %2508 = tail call i32 @llvm.ctpop.i32(i32 %2507) #14
  %2509 = trunc i32 %2508 to i8
  %2510 = and i8 %2509, 1
  %2511 = xor i8 %2510, 1
  store i8 %2511, i8* %23, align 1, !tbaa !2446
  %2512 = xor i32 %2503, %2502
  %2513 = lshr i32 %2512, 4
  %2514 = trunc i32 %2513 to i8
  %2515 = and i8 %2514, 1
  store i8 %2515, i8* %29, align 1, !tbaa !2447
  %2516 = icmp eq i32 %2503, 0
  %2517 = zext i1 %2516 to i8
  store i8 %2517, i8* %32, align 1, !tbaa !2448
  %2518 = lshr i32 %2503, 31
  %2519 = trunc i32 %2518 to i8
  store i8 %2519, i8* %35, align 1, !tbaa !2449
  %2520 = lshr i32 %2502, 31
  %2521 = xor i32 %2518, %2520
  %2522 = add nuw nsw i32 %2521, %2518
  %2523 = icmp eq i32 %2522, 2
  %2524 = zext i1 %2523 to i8
  store i8 %2524, i8* %41, align 1, !tbaa !2450
  %2525 = sext i32 %2503 to i64
  store i64 %2525, i64* %RSI, align 8, !tbaa !2428
  %2526 = shl nsw i64 %2525, 3
  %2527 = add i64 %2498, %2526
  %2528 = add i64 %2495, 18
  store i64 %2528, i64* %PC, align 8
  %2529 = inttoptr i64 %2527 to i64*
  %2530 = load i64, i64* %2529, align 8
  store i64 %2530, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2531 = add i64 %2495, 22
  store i64 %2531, i64* %PC, align 8
  %2532 = load i64, i64* %2497, align 8
  store i64 %2532, i64* %RDX, align 8, !tbaa !2428
  %2533 = add i64 %2495, 25
  store i64 %2533, i64* %PC, align 8
  %2534 = load i32, i32* %2501, align 4
  %2535 = add i32 %2534, 11
  %2536 = zext i32 %2535 to i64
  store i64 %2536, i64* %RCX, align 8, !tbaa !2428
  %2537 = icmp ugt i32 %2534, -12
  %2538 = zext i1 %2537 to i8
  store i8 %2538, i8* %16, align 1, !tbaa !2432
  %2539 = and i32 %2535, 255
  %2540 = tail call i32 @llvm.ctpop.i32(i32 %2539) #14
  %2541 = trunc i32 %2540 to i8
  %2542 = and i8 %2541, 1
  %2543 = xor i8 %2542, 1
  store i8 %2543, i8* %23, align 1, !tbaa !2446
  %2544 = xor i32 %2535, %2534
  %2545 = lshr i32 %2544, 4
  %2546 = trunc i32 %2545 to i8
  %2547 = and i8 %2546, 1
  store i8 %2547, i8* %29, align 1, !tbaa !2447
  %2548 = icmp eq i32 %2535, 0
  %2549 = zext i1 %2548 to i8
  store i8 %2549, i8* %32, align 1, !tbaa !2448
  %2550 = lshr i32 %2535, 31
  %2551 = trunc i32 %2550 to i8
  store i8 %2551, i8* %35, align 1, !tbaa !2449
  %2552 = lshr i32 %2534, 31
  %2553 = xor i32 %2550, %2552
  %2554 = add nuw nsw i32 %2553, %2550
  %2555 = icmp eq i32 %2554, 2
  %2556 = zext i1 %2555 to i8
  store i8 %2556, i8* %41, align 1, !tbaa !2450
  %2557 = sext i32 %2535 to i64
  store i64 %2557, i64* %RSI, align 8, !tbaa !2428
  %2558 = shl nsw i64 %2557, 3
  %2559 = add i64 %2532, %2558
  %2560 = add i64 %2495, 36
  store i64 %2560, i64* %PC, align 8
  %2561 = bitcast i64 %2530 to double
  %2562 = inttoptr i64 %2559 to double*
  %2563 = load double, double* %2562, align 8
  %2564 = fsub double %2561, %2563
  store double %2564, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2565 = load i64, i64* %RBP, align 8
  %2566 = add i64 %2565, -120
  %2567 = add i64 %2495, 41
  store i64 %2567, i64* %PC, align 8
  %2568 = inttoptr i64 %2566 to double*
  store double %2564, double* %2568, align 8
  %2569 = load i64, i64* %RBP, align 8
  %2570 = add i64 %2569, -16
  %2571 = load i64, i64* %PC, align 8
  %2572 = add i64 %2571, 4
  store i64 %2572, i64* %PC, align 8
  %2573 = inttoptr i64 %2570 to i64*
  %2574 = load i64, i64* %2573, align 8
  store i64 %2574, i64* %RDX, align 8, !tbaa !2428
  %2575 = add i64 %2569, -28
  %2576 = add i64 %2571, 7
  store i64 %2576, i64* %PC, align 8
  %2577 = inttoptr i64 %2575 to i32*
  %2578 = load i32, i32* %2577, align 4
  %2579 = add i32 %2578, 12
  %2580 = zext i32 %2579 to i64
  store i64 %2580, i64* %RCX, align 8, !tbaa !2428
  %2581 = icmp ugt i32 %2578, -13
  %2582 = zext i1 %2581 to i8
  store i8 %2582, i8* %16, align 1, !tbaa !2432
  %2583 = and i32 %2579, 255
  %2584 = tail call i32 @llvm.ctpop.i32(i32 %2583) #14
  %2585 = trunc i32 %2584 to i8
  %2586 = and i8 %2585, 1
  %2587 = xor i8 %2586, 1
  store i8 %2587, i8* %23, align 1, !tbaa !2446
  %2588 = xor i32 %2579, %2578
  %2589 = lshr i32 %2588, 4
  %2590 = trunc i32 %2589 to i8
  %2591 = and i8 %2590, 1
  store i8 %2591, i8* %29, align 1, !tbaa !2447
  %2592 = icmp eq i32 %2579, 0
  %2593 = zext i1 %2592 to i8
  store i8 %2593, i8* %32, align 1, !tbaa !2448
  %2594 = lshr i32 %2579, 31
  %2595 = trunc i32 %2594 to i8
  store i8 %2595, i8* %35, align 1, !tbaa !2449
  %2596 = lshr i32 %2578, 31
  %2597 = xor i32 %2594, %2596
  %2598 = add nuw nsw i32 %2597, %2594
  %2599 = icmp eq i32 %2598, 2
  %2600 = zext i1 %2599 to i8
  store i8 %2600, i8* %41, align 1, !tbaa !2450
  %2601 = sext i32 %2579 to i64
  store i64 %2601, i64* %RSI, align 8, !tbaa !2428
  %2602 = shl nsw i64 %2601, 3
  %2603 = add i64 %2574, %2602
  %2604 = add i64 %2571, 18
  store i64 %2604, i64* %PC, align 8
  %2605 = inttoptr i64 %2603 to i64*
  %2606 = load i64, i64* %2605, align 8
  store i64 %2606, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2607 = add i64 %2571, 22
  store i64 %2607, i64* %PC, align 8
  %2608 = load i64, i64* %2573, align 8
  store i64 %2608, i64* %RDX, align 8, !tbaa !2428
  %2609 = add i64 %2571, 25
  store i64 %2609, i64* %PC, align 8
  %2610 = load i32, i32* %2577, align 4
  %2611 = add i32 %2610, 14
  %2612 = zext i32 %2611 to i64
  store i64 %2612, i64* %RCX, align 8, !tbaa !2428
  %2613 = icmp ugt i32 %2610, -15
  %2614 = zext i1 %2613 to i8
  store i8 %2614, i8* %16, align 1, !tbaa !2432
  %2615 = and i32 %2611, 255
  %2616 = tail call i32 @llvm.ctpop.i32(i32 %2615) #14
  %2617 = trunc i32 %2616 to i8
  %2618 = and i8 %2617, 1
  %2619 = xor i8 %2618, 1
  store i8 %2619, i8* %23, align 1, !tbaa !2446
  %2620 = xor i32 %2611, %2610
  %2621 = lshr i32 %2620, 4
  %2622 = trunc i32 %2621 to i8
  %2623 = and i8 %2622, 1
  store i8 %2623, i8* %29, align 1, !tbaa !2447
  %2624 = icmp eq i32 %2611, 0
  %2625 = zext i1 %2624 to i8
  store i8 %2625, i8* %32, align 1, !tbaa !2448
  %2626 = lshr i32 %2611, 31
  %2627 = trunc i32 %2626 to i8
  store i8 %2627, i8* %35, align 1, !tbaa !2449
  %2628 = lshr i32 %2610, 31
  %2629 = xor i32 %2626, %2628
  %2630 = add nuw nsw i32 %2629, %2626
  %2631 = icmp eq i32 %2630, 2
  %2632 = zext i1 %2631 to i8
  store i8 %2632, i8* %41, align 1, !tbaa !2450
  %2633 = sext i32 %2611 to i64
  store i64 %2633, i64* %RSI, align 8, !tbaa !2428
  %2634 = shl nsw i64 %2633, 3
  %2635 = add i64 %2608, %2634
  %2636 = add i64 %2571, 36
  store i64 %2636, i64* %PC, align 8
  %2637 = bitcast i64 %2606 to double
  %2638 = inttoptr i64 %2635 to double*
  %2639 = load double, double* %2638, align 8
  %2640 = fadd double %2637, %2639
  store double %2640, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2641 = load i64, i64* %RBP, align 8
  %2642 = add i64 %2641, -128
  %2643 = add i64 %2571, 41
  store i64 %2643, i64* %PC, align 8
  %2644 = inttoptr i64 %2642 to double*
  store double %2640, double* %2644, align 8
  %2645 = load i64, i64* %RBP, align 8
  %2646 = add i64 %2645, -16
  %2647 = load i64, i64* %PC, align 8
  %2648 = add i64 %2647, 4
  store i64 %2648, i64* %PC, align 8
  %2649 = inttoptr i64 %2646 to i64*
  %2650 = load i64, i64* %2649, align 8
  store i64 %2650, i64* %RDX, align 8, !tbaa !2428
  %2651 = add i64 %2645, -28
  %2652 = add i64 %2647, 7
  store i64 %2652, i64* %PC, align 8
  %2653 = inttoptr i64 %2651 to i32*
  %2654 = load i32, i32* %2653, align 4
  %2655 = add i32 %2654, 13
  %2656 = zext i32 %2655 to i64
  store i64 %2656, i64* %RCX, align 8, !tbaa !2428
  %2657 = icmp ugt i32 %2654, -14
  %2658 = zext i1 %2657 to i8
  store i8 %2658, i8* %16, align 1, !tbaa !2432
  %2659 = and i32 %2655, 255
  %2660 = tail call i32 @llvm.ctpop.i32(i32 %2659) #14
  %2661 = trunc i32 %2660 to i8
  %2662 = and i8 %2661, 1
  %2663 = xor i8 %2662, 1
  store i8 %2663, i8* %23, align 1, !tbaa !2446
  %2664 = xor i32 %2655, %2654
  %2665 = lshr i32 %2664, 4
  %2666 = trunc i32 %2665 to i8
  %2667 = and i8 %2666, 1
  store i8 %2667, i8* %29, align 1, !tbaa !2447
  %2668 = icmp eq i32 %2655, 0
  %2669 = zext i1 %2668 to i8
  store i8 %2669, i8* %32, align 1, !tbaa !2448
  %2670 = lshr i32 %2655, 31
  %2671 = trunc i32 %2670 to i8
  store i8 %2671, i8* %35, align 1, !tbaa !2449
  %2672 = lshr i32 %2654, 31
  %2673 = xor i32 %2670, %2672
  %2674 = add nuw nsw i32 %2673, %2670
  %2675 = icmp eq i32 %2674, 2
  %2676 = zext i1 %2675 to i8
  store i8 %2676, i8* %41, align 1, !tbaa !2450
  %2677 = sext i32 %2655 to i64
  store i64 %2677, i64* %RSI, align 8, !tbaa !2428
  %2678 = shl nsw i64 %2677, 3
  %2679 = add i64 %2650, %2678
  %2680 = add i64 %2647, 18
  store i64 %2680, i64* %PC, align 8
  %2681 = inttoptr i64 %2679 to i64*
  %2682 = load i64, i64* %2681, align 8
  store i64 %2682, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2683 = add i64 %2647, 22
  store i64 %2683, i64* %PC, align 8
  %2684 = load i64, i64* %2649, align 8
  store i64 %2684, i64* %RDX, align 8, !tbaa !2428
  %2685 = add i64 %2647, 25
  store i64 %2685, i64* %PC, align 8
  %2686 = load i32, i32* %2653, align 4
  %2687 = add i32 %2686, 15
  %2688 = zext i32 %2687 to i64
  store i64 %2688, i64* %RCX, align 8, !tbaa !2428
  %2689 = icmp ugt i32 %2686, -16
  %2690 = zext i1 %2689 to i8
  store i8 %2690, i8* %16, align 1, !tbaa !2432
  %2691 = and i32 %2687, 255
  %2692 = tail call i32 @llvm.ctpop.i32(i32 %2691) #14
  %2693 = trunc i32 %2692 to i8
  %2694 = and i8 %2693, 1
  %2695 = xor i8 %2694, 1
  store i8 %2695, i8* %23, align 1, !tbaa !2446
  %2696 = xor i32 %2687, %2686
  %2697 = lshr i32 %2696, 4
  %2698 = trunc i32 %2697 to i8
  %2699 = and i8 %2698, 1
  store i8 %2699, i8* %29, align 1, !tbaa !2447
  %2700 = icmp eq i32 %2687, 0
  %2701 = zext i1 %2700 to i8
  store i8 %2701, i8* %32, align 1, !tbaa !2448
  %2702 = lshr i32 %2687, 31
  %2703 = trunc i32 %2702 to i8
  store i8 %2703, i8* %35, align 1, !tbaa !2449
  %2704 = lshr i32 %2686, 31
  %2705 = xor i32 %2702, %2704
  %2706 = add nuw nsw i32 %2705, %2702
  %2707 = icmp eq i32 %2706, 2
  %2708 = zext i1 %2707 to i8
  store i8 %2708, i8* %41, align 1, !tbaa !2450
  %2709 = sext i32 %2687 to i64
  store i64 %2709, i64* %RSI, align 8, !tbaa !2428
  %2710 = shl nsw i64 %2709, 3
  %2711 = add i64 %2684, %2710
  %2712 = add i64 %2647, 36
  store i64 %2712, i64* %PC, align 8
  %2713 = bitcast i64 %2682 to double
  %2714 = inttoptr i64 %2711 to double*
  %2715 = load double, double* %2714, align 8
  %2716 = fadd double %2713, %2715
  store double %2716, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2717 = load i64, i64* %RBP, align 8
  %2718 = add i64 %2717, -136
  %2719 = add i64 %2647, 44
  store i64 %2719, i64* %PC, align 8
  %2720 = inttoptr i64 %2718 to double*
  store double %2716, double* %2720, align 8
  %2721 = load i64, i64* %RBP, align 8
  %2722 = add i64 %2721, -16
  %2723 = load i64, i64* %PC, align 8
  %2724 = add i64 %2723, 4
  store i64 %2724, i64* %PC, align 8
  %2725 = inttoptr i64 %2722 to i64*
  %2726 = load i64, i64* %2725, align 8
  store i64 %2726, i64* %RDX, align 8, !tbaa !2428
  %2727 = add i64 %2721, -28
  %2728 = add i64 %2723, 7
  store i64 %2728, i64* %PC, align 8
  %2729 = inttoptr i64 %2727 to i32*
  %2730 = load i32, i32* %2729, align 4
  %2731 = add i32 %2730, 12
  %2732 = zext i32 %2731 to i64
  store i64 %2732, i64* %RCX, align 8, !tbaa !2428
  %2733 = icmp ugt i32 %2730, -13
  %2734 = zext i1 %2733 to i8
  store i8 %2734, i8* %16, align 1, !tbaa !2432
  %2735 = and i32 %2731, 255
  %2736 = tail call i32 @llvm.ctpop.i32(i32 %2735) #14
  %2737 = trunc i32 %2736 to i8
  %2738 = and i8 %2737, 1
  %2739 = xor i8 %2738, 1
  store i8 %2739, i8* %23, align 1, !tbaa !2446
  %2740 = xor i32 %2731, %2730
  %2741 = lshr i32 %2740, 4
  %2742 = trunc i32 %2741 to i8
  %2743 = and i8 %2742, 1
  store i8 %2743, i8* %29, align 1, !tbaa !2447
  %2744 = icmp eq i32 %2731, 0
  %2745 = zext i1 %2744 to i8
  store i8 %2745, i8* %32, align 1, !tbaa !2448
  %2746 = lshr i32 %2731, 31
  %2747 = trunc i32 %2746 to i8
  store i8 %2747, i8* %35, align 1, !tbaa !2449
  %2748 = lshr i32 %2730, 31
  %2749 = xor i32 %2746, %2748
  %2750 = add nuw nsw i32 %2749, %2746
  %2751 = icmp eq i32 %2750, 2
  %2752 = zext i1 %2751 to i8
  store i8 %2752, i8* %41, align 1, !tbaa !2450
  %2753 = sext i32 %2731 to i64
  store i64 %2753, i64* %RSI, align 8, !tbaa !2428
  %2754 = shl nsw i64 %2753, 3
  %2755 = add i64 %2726, %2754
  %2756 = add i64 %2723, 18
  store i64 %2756, i64* %PC, align 8
  %2757 = inttoptr i64 %2755 to i64*
  %2758 = load i64, i64* %2757, align 8
  store i64 %2758, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2759 = add i64 %2723, 22
  store i64 %2759, i64* %PC, align 8
  %2760 = load i64, i64* %2725, align 8
  store i64 %2760, i64* %RDX, align 8, !tbaa !2428
  %2761 = add i64 %2723, 25
  store i64 %2761, i64* %PC, align 8
  %2762 = load i32, i32* %2729, align 4
  %2763 = add i32 %2762, 14
  %2764 = zext i32 %2763 to i64
  store i64 %2764, i64* %RCX, align 8, !tbaa !2428
  %2765 = icmp ugt i32 %2762, -15
  %2766 = zext i1 %2765 to i8
  store i8 %2766, i8* %16, align 1, !tbaa !2432
  %2767 = and i32 %2763, 255
  %2768 = tail call i32 @llvm.ctpop.i32(i32 %2767) #14
  %2769 = trunc i32 %2768 to i8
  %2770 = and i8 %2769, 1
  %2771 = xor i8 %2770, 1
  store i8 %2771, i8* %23, align 1, !tbaa !2446
  %2772 = xor i32 %2763, %2762
  %2773 = lshr i32 %2772, 4
  %2774 = trunc i32 %2773 to i8
  %2775 = and i8 %2774, 1
  store i8 %2775, i8* %29, align 1, !tbaa !2447
  %2776 = icmp eq i32 %2763, 0
  %2777 = zext i1 %2776 to i8
  store i8 %2777, i8* %32, align 1, !tbaa !2448
  %2778 = lshr i32 %2763, 31
  %2779 = trunc i32 %2778 to i8
  store i8 %2779, i8* %35, align 1, !tbaa !2449
  %2780 = lshr i32 %2762, 31
  %2781 = xor i32 %2778, %2780
  %2782 = add nuw nsw i32 %2781, %2778
  %2783 = icmp eq i32 %2782, 2
  %2784 = zext i1 %2783 to i8
  store i8 %2784, i8* %41, align 1, !tbaa !2450
  %2785 = sext i32 %2763 to i64
  store i64 %2785, i64* %RSI, align 8, !tbaa !2428
  %2786 = shl nsw i64 %2785, 3
  %2787 = add i64 %2760, %2786
  %2788 = add i64 %2723, 36
  store i64 %2788, i64* %PC, align 8
  %2789 = bitcast i64 %2758 to double
  %2790 = inttoptr i64 %2787 to double*
  %2791 = load double, double* %2790, align 8
  %2792 = fsub double %2789, %2791
  store double %2792, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2793 = load i64, i64* %RBP, align 8
  %2794 = add i64 %2793, -144
  %2795 = add i64 %2723, 44
  store i64 %2795, i64* %PC, align 8
  %2796 = inttoptr i64 %2794 to double*
  store double %2792, double* %2796, align 8
  %2797 = load i64, i64* %RBP, align 8
  %2798 = add i64 %2797, -16
  %2799 = load i64, i64* %PC, align 8
  %2800 = add i64 %2799, 4
  store i64 %2800, i64* %PC, align 8
  %2801 = inttoptr i64 %2798 to i64*
  %2802 = load i64, i64* %2801, align 8
  store i64 %2802, i64* %RDX, align 8, !tbaa !2428
  %2803 = add i64 %2797, -28
  %2804 = add i64 %2799, 7
  store i64 %2804, i64* %PC, align 8
  %2805 = inttoptr i64 %2803 to i32*
  %2806 = load i32, i32* %2805, align 4
  %2807 = add i32 %2806, 13
  %2808 = zext i32 %2807 to i64
  store i64 %2808, i64* %RCX, align 8, !tbaa !2428
  %2809 = icmp ugt i32 %2806, -14
  %2810 = zext i1 %2809 to i8
  store i8 %2810, i8* %16, align 1, !tbaa !2432
  %2811 = and i32 %2807, 255
  %2812 = tail call i32 @llvm.ctpop.i32(i32 %2811) #14
  %2813 = trunc i32 %2812 to i8
  %2814 = and i8 %2813, 1
  %2815 = xor i8 %2814, 1
  store i8 %2815, i8* %23, align 1, !tbaa !2446
  %2816 = xor i32 %2807, %2806
  %2817 = lshr i32 %2816, 4
  %2818 = trunc i32 %2817 to i8
  %2819 = and i8 %2818, 1
  store i8 %2819, i8* %29, align 1, !tbaa !2447
  %2820 = icmp eq i32 %2807, 0
  %2821 = zext i1 %2820 to i8
  store i8 %2821, i8* %32, align 1, !tbaa !2448
  %2822 = lshr i32 %2807, 31
  %2823 = trunc i32 %2822 to i8
  store i8 %2823, i8* %35, align 1, !tbaa !2449
  %2824 = lshr i32 %2806, 31
  %2825 = xor i32 %2822, %2824
  %2826 = add nuw nsw i32 %2825, %2822
  %2827 = icmp eq i32 %2826, 2
  %2828 = zext i1 %2827 to i8
  store i8 %2828, i8* %41, align 1, !tbaa !2450
  %2829 = sext i32 %2807 to i64
  store i64 %2829, i64* %RSI, align 8, !tbaa !2428
  %2830 = shl nsw i64 %2829, 3
  %2831 = add i64 %2802, %2830
  %2832 = add i64 %2799, 18
  store i64 %2832, i64* %PC, align 8
  %2833 = inttoptr i64 %2831 to i64*
  %2834 = load i64, i64* %2833, align 8
  store i64 %2834, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2835 = add i64 %2799, 22
  store i64 %2835, i64* %PC, align 8
  %2836 = load i64, i64* %2801, align 8
  store i64 %2836, i64* %RDX, align 8, !tbaa !2428
  %2837 = add i64 %2799, 25
  store i64 %2837, i64* %PC, align 8
  %2838 = load i32, i32* %2805, align 4
  %2839 = add i32 %2838, 15
  %2840 = zext i32 %2839 to i64
  store i64 %2840, i64* %RCX, align 8, !tbaa !2428
  %2841 = icmp ugt i32 %2838, -16
  %2842 = zext i1 %2841 to i8
  store i8 %2842, i8* %16, align 1, !tbaa !2432
  %2843 = and i32 %2839, 255
  %2844 = tail call i32 @llvm.ctpop.i32(i32 %2843) #14
  %2845 = trunc i32 %2844 to i8
  %2846 = and i8 %2845, 1
  %2847 = xor i8 %2846, 1
  store i8 %2847, i8* %23, align 1, !tbaa !2446
  %2848 = xor i32 %2839, %2838
  %2849 = lshr i32 %2848, 4
  %2850 = trunc i32 %2849 to i8
  %2851 = and i8 %2850, 1
  store i8 %2851, i8* %29, align 1, !tbaa !2447
  %2852 = icmp eq i32 %2839, 0
  %2853 = zext i1 %2852 to i8
  store i8 %2853, i8* %32, align 1, !tbaa !2448
  %2854 = lshr i32 %2839, 31
  %2855 = trunc i32 %2854 to i8
  store i8 %2855, i8* %35, align 1, !tbaa !2449
  %2856 = lshr i32 %2838, 31
  %2857 = xor i32 %2854, %2856
  %2858 = add nuw nsw i32 %2857, %2854
  %2859 = icmp eq i32 %2858, 2
  %2860 = zext i1 %2859 to i8
  store i8 %2860, i8* %41, align 1, !tbaa !2450
  %2861 = sext i32 %2839 to i64
  store i64 %2861, i64* %RSI, align 8, !tbaa !2428
  %2862 = shl nsw i64 %2861, 3
  %2863 = add i64 %2836, %2862
  %2864 = add i64 %2799, 36
  store i64 %2864, i64* %PC, align 8
  %2865 = bitcast i64 %2834 to double
  %2866 = inttoptr i64 %2863 to double*
  %2867 = load double, double* %2866, align 8
  %2868 = fsub double %2865, %2867
  store double %2868, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2869 = load i64, i64* %RBP, align 8
  %2870 = add i64 %2869, -152
  %2871 = add i64 %2799, 44
  store i64 %2871, i64* %PC, align 8
  %2872 = inttoptr i64 %2870 to double*
  store double %2868, double* %2872, align 8
  %2873 = load i64, i64* %RBP, align 8
  %2874 = add i64 %2873, -96
  %2875 = load i64, i64* %PC, align 8
  %2876 = add i64 %2875, 5
  store i64 %2876, i64* %PC, align 8
  %2877 = inttoptr i64 %2874 to i64*
  %2878 = load i64, i64* %2877, align 8
  store i64 %2878, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2879 = add i64 %2873, -128
  %2880 = add i64 %2875, 10
  store i64 %2880, i64* %PC, align 8
  %2881 = bitcast i64 %2878 to double
  %2882 = inttoptr i64 %2879 to double*
  %2883 = load double, double* %2882, align 8
  %2884 = fadd double %2881, %2883
  store double %2884, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2885 = add i64 %2873, -16
  %2886 = add i64 %2875, 14
  store i64 %2886, i64* %PC, align 8
  %2887 = inttoptr i64 %2885 to i64*
  %2888 = load i64, i64* %2887, align 8
  store i64 %2888, i64* %RDX, align 8, !tbaa !2428
  %2889 = add i64 %2873, -28
  %2890 = add i64 %2875, 17
  store i64 %2890, i64* %PC, align 8
  %2891 = inttoptr i64 %2889 to i32*
  %2892 = load i32, i32* %2891, align 4
  %2893 = add i32 %2892, 8
  %2894 = zext i32 %2893 to i64
  store i64 %2894, i64* %RCX, align 8, !tbaa !2428
  %2895 = icmp ugt i32 %2892, -9
  %2896 = zext i1 %2895 to i8
  store i8 %2896, i8* %16, align 1, !tbaa !2432
  %2897 = and i32 %2893, 255
  %2898 = tail call i32 @llvm.ctpop.i32(i32 %2897) #14
  %2899 = trunc i32 %2898 to i8
  %2900 = and i8 %2899, 1
  %2901 = xor i8 %2900, 1
  store i8 %2901, i8* %23, align 1, !tbaa !2446
  %2902 = xor i32 %2893, %2892
  %2903 = lshr i32 %2902, 4
  %2904 = trunc i32 %2903 to i8
  %2905 = and i8 %2904, 1
  store i8 %2905, i8* %29, align 1, !tbaa !2447
  %2906 = icmp eq i32 %2893, 0
  %2907 = zext i1 %2906 to i8
  store i8 %2907, i8* %32, align 1, !tbaa !2448
  %2908 = lshr i32 %2893, 31
  %2909 = trunc i32 %2908 to i8
  store i8 %2909, i8* %35, align 1, !tbaa !2449
  %2910 = lshr i32 %2892, 31
  %2911 = xor i32 %2908, %2910
  %2912 = add nuw nsw i32 %2911, %2908
  %2913 = icmp eq i32 %2912, 2
  %2914 = zext i1 %2913 to i8
  store i8 %2914, i8* %41, align 1, !tbaa !2450
  %2915 = sext i32 %2893 to i64
  store i64 %2915, i64* %RSI, align 8, !tbaa !2428
  %2916 = shl nsw i64 %2915, 3
  %2917 = add i64 %2888, %2916
  %2918 = add i64 %2875, 28
  store i64 %2918, i64* %PC, align 8
  %2919 = inttoptr i64 %2917 to double*
  store double %2884, double* %2919, align 8
  %2920 = load i64, i64* %RBP, align 8
  %2921 = add i64 %2920, -104
  %2922 = load i64, i64* %PC, align 8
  %2923 = add i64 %2922, 5
  store i64 %2923, i64* %PC, align 8
  %2924 = inttoptr i64 %2921 to i64*
  %2925 = load i64, i64* %2924, align 8
  store i64 %2925, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2926 = add i64 %2920, -136
  %2927 = add i64 %2922, 13
  store i64 %2927, i64* %PC, align 8
  %2928 = bitcast i64 %2925 to double
  %2929 = inttoptr i64 %2926 to double*
  %2930 = load double, double* %2929, align 8
  %2931 = fadd double %2928, %2930
  store double %2931, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2932 = add i64 %2920, -16
  %2933 = add i64 %2922, 17
  store i64 %2933, i64* %PC, align 8
  %2934 = inttoptr i64 %2932 to i64*
  %2935 = load i64, i64* %2934, align 8
  store i64 %2935, i64* %RDX, align 8, !tbaa !2428
  %2936 = add i64 %2920, -28
  %2937 = add i64 %2922, 20
  store i64 %2937, i64* %PC, align 8
  %2938 = inttoptr i64 %2936 to i32*
  %2939 = load i32, i32* %2938, align 4
  %2940 = add i32 %2939, 9
  %2941 = zext i32 %2940 to i64
  store i64 %2941, i64* %RCX, align 8, !tbaa !2428
  %2942 = icmp ugt i32 %2939, -10
  %2943 = zext i1 %2942 to i8
  store i8 %2943, i8* %16, align 1, !tbaa !2432
  %2944 = and i32 %2940, 255
  %2945 = tail call i32 @llvm.ctpop.i32(i32 %2944) #14
  %2946 = trunc i32 %2945 to i8
  %2947 = and i8 %2946, 1
  %2948 = xor i8 %2947, 1
  store i8 %2948, i8* %23, align 1, !tbaa !2446
  %2949 = xor i32 %2940, %2939
  %2950 = lshr i32 %2949, 4
  %2951 = trunc i32 %2950 to i8
  %2952 = and i8 %2951, 1
  store i8 %2952, i8* %29, align 1, !tbaa !2447
  %2953 = icmp eq i32 %2940, 0
  %2954 = zext i1 %2953 to i8
  store i8 %2954, i8* %32, align 1, !tbaa !2448
  %2955 = lshr i32 %2940, 31
  %2956 = trunc i32 %2955 to i8
  store i8 %2956, i8* %35, align 1, !tbaa !2449
  %2957 = lshr i32 %2939, 31
  %2958 = xor i32 %2955, %2957
  %2959 = add nuw nsw i32 %2958, %2955
  %2960 = icmp eq i32 %2959, 2
  %2961 = zext i1 %2960 to i8
  store i8 %2961, i8* %41, align 1, !tbaa !2450
  %2962 = sext i32 %2940 to i64
  store i64 %2962, i64* %RSI, align 8, !tbaa !2428
  %2963 = shl nsw i64 %2962, 3
  %2964 = add i64 %2935, %2963
  %2965 = add i64 %2922, 31
  store i64 %2965, i64* %PC, align 8
  %2966 = inttoptr i64 %2964 to double*
  store double %2931, double* %2966, align 8
  %2967 = load i64, i64* %RBP, align 8
  %2968 = add i64 %2967, -128
  %2969 = load i64, i64* %PC, align 8
  %2970 = add i64 %2969, 5
  store i64 %2970, i64* %PC, align 8
  %2971 = inttoptr i64 %2968 to i64*
  %2972 = load i64, i64* %2971, align 8
  store i64 %2972, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2973 = add i64 %2967, -96
  %2974 = add i64 %2969, 10
  store i64 %2974, i64* %PC, align 8
  %2975 = inttoptr i64 %2973 to double*
  %2976 = load double, double* %2975, align 8
  %2977 = bitcast i64 %2972 to double
  %2978 = fsub double %2976, %2977
  store double %2978, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2979 = add i64 %2969, 19
  store i64 %2979, i64* %PC, align 8
  %2980 = inttoptr i64 %2973 to double*
  store double %2978, double* %2980, align 8
  %2981 = load i64, i64* %RBP, align 8
  %2982 = add i64 %2981, -136
  %2983 = load i64, i64* %PC, align 8
  %2984 = add i64 %2983, 8
  store i64 %2984, i64* %PC, align 8
  %2985 = inttoptr i64 %2982 to i64*
  %2986 = load i64, i64* %2985, align 8
  store i64 %2986, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2987 = add i64 %2981, -104
  %2988 = add i64 %2983, 13
  store i64 %2988, i64* %PC, align 8
  %2989 = inttoptr i64 %2987 to double*
  %2990 = load double, double* %2989, align 8
  %2991 = bitcast i64 %2986 to double
  %2992 = fsub double %2990, %2991
  store double %2992, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2993 = add i64 %2983, 22
  store i64 %2993, i64* %PC, align 8
  %2994 = inttoptr i64 %2987 to double*
  store double %2992, double* %2994, align 8
  %2995 = load i64, i64* %RBP, align 8
  %2996 = add i64 %2995, -72
  %2997 = load i64, i64* %PC, align 8
  %2998 = add i64 %2997, 5
  store i64 %2998, i64* %PC, align 8
  %2999 = inttoptr i64 %2996 to i64*
  %3000 = load i64, i64* %2999, align 8
  %3001 = load i64, i64* %RAX, align 8
  %3002 = xor i64 %3001, %3000
  store i64 %3002, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %16, align 1, !tbaa !2432
  %3003 = trunc i64 %3002 to i32
  %3004 = and i32 %3003, 255
  %3005 = tail call i32 @llvm.ctpop.i32(i32 %3004) #14
  %3006 = trunc i32 %3005 to i8
  %3007 = and i8 %3006, 1
  %3008 = xor i8 %3007, 1
  store i8 %3008, i8* %23, align 1, !tbaa !2446
  %3009 = icmp eq i64 %3002, 0
  %3010 = zext i1 %3009 to i8
  store i8 %3010, i8* %32, align 1, !tbaa !2448
  %3011 = lshr i64 %3002, 63
  %3012 = trunc i64 %3011 to i8
  store i8 %3012, i8* %35, align 1, !tbaa !2449
  store i8 0, i8* %41, align 1, !tbaa !2450
  store i8 0, i8* %29, align 1, !tbaa !2447
  store i64 %3002, i64* %68, align 1, !tbaa !2428
  store i64 0, i64* %69, align 1, !tbaa !2428
  %3013 = add i64 %2995, -96
  %3014 = add i64 %2997, 23
  store i64 %3014, i64* %PC, align 8
  %.cast4 = bitcast i64 %3002 to double
  %3015 = inttoptr i64 %3013 to double*
  %3016 = load double, double* %3015, align 8
  %3017 = fmul double %.cast4, %3016
  store double %3017, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3018 = add i64 %2995, -64
  %3019 = add i64 %2997, 28
  store i64 %3019, i64* %PC, align 8
  %3020 = inttoptr i64 %3018 to i64*
  %3021 = load i64, i64* %3020, align 8
  store i64 %3021, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %3022 = add i64 %2995, -104
  %3023 = add i64 %2997, 33
  store i64 %3023, i64* %PC, align 8
  %3024 = bitcast i64 %3021 to double
  %3025 = inttoptr i64 %3022 to double*
  %3026 = load double, double* %3025, align 8
  %3027 = fmul double %3024, %3026
  store double %3027, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %3028 = fsub double %3017, %3027
  store double %3028, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3029 = add i64 %2995, -16
  %3030 = add i64 %2997, 41
  store i64 %3030, i64* %PC, align 8
  %3031 = inttoptr i64 %3029 to i64*
  %3032 = load i64, i64* %3031, align 8
  store i64 %3032, i64* %RDX, align 8, !tbaa !2428
  %3033 = add i64 %2995, -28
  %3034 = add i64 %2997, 44
  store i64 %3034, i64* %PC, align 8
  %3035 = inttoptr i64 %3033 to i32*
  %3036 = load i32, i32* %3035, align 4
  %3037 = add i32 %3036, 12
  %3038 = zext i32 %3037 to i64
  store i64 %3038, i64* %RCX, align 8, !tbaa !2428
  %3039 = icmp ugt i32 %3036, -13
  %3040 = zext i1 %3039 to i8
  store i8 %3040, i8* %16, align 1, !tbaa !2432
  %3041 = and i32 %3037, 255
  %3042 = tail call i32 @llvm.ctpop.i32(i32 %3041) #14
  %3043 = trunc i32 %3042 to i8
  %3044 = and i8 %3043, 1
  %3045 = xor i8 %3044, 1
  store i8 %3045, i8* %23, align 1, !tbaa !2446
  %3046 = xor i32 %3037, %3036
  %3047 = lshr i32 %3046, 4
  %3048 = trunc i32 %3047 to i8
  %3049 = and i8 %3048, 1
  store i8 %3049, i8* %29, align 1, !tbaa !2447
  %3050 = icmp eq i32 %3037, 0
  %3051 = zext i1 %3050 to i8
  store i8 %3051, i8* %32, align 1, !tbaa !2448
  %3052 = lshr i32 %3037, 31
  %3053 = trunc i32 %3052 to i8
  store i8 %3053, i8* %35, align 1, !tbaa !2449
  %3054 = lshr i32 %3036, 31
  %3055 = xor i32 %3052, %3054
  %3056 = add nuw nsw i32 %3055, %3052
  %3057 = icmp eq i32 %3056, 2
  %3058 = zext i1 %3057 to i8
  store i8 %3058, i8* %41, align 1, !tbaa !2450
  %3059 = sext i32 %3037 to i64
  store i64 %3059, i64* %RSI, align 8, !tbaa !2428
  %3060 = shl nsw i64 %3059, 3
  %3061 = add i64 %3032, %3060
  %3062 = add i64 %2997, 55
  store i64 %3062, i64* %PC, align 8
  %3063 = inttoptr i64 %3061 to double*
  store double %3028, double* %3063, align 8
  %3064 = load i64, i64* %RBP, align 8
  %3065 = add i64 %3064, -72
  %3066 = load i64, i64* %PC, align 8
  %3067 = add i64 %3066, 5
  store i64 %3067, i64* %PC, align 8
  %3068 = inttoptr i64 %3065 to i64*
  %3069 = load i64, i64* %3068, align 8
  %3070 = load i64, i64* %RAX, align 8
  %3071 = xor i64 %3070, %3069
  store i64 %3071, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %16, align 1, !tbaa !2432
  %3072 = trunc i64 %3071 to i32
  %3073 = and i32 %3072, 255
  %3074 = tail call i32 @llvm.ctpop.i32(i32 %3073) #14
  %3075 = trunc i32 %3074 to i8
  %3076 = and i8 %3075, 1
  %3077 = xor i8 %3076, 1
  store i8 %3077, i8* %23, align 1, !tbaa !2446
  %3078 = icmp eq i64 %3071, 0
  %3079 = zext i1 %3078 to i8
  store i8 %3079, i8* %32, align 1, !tbaa !2448
  %3080 = lshr i64 %3071, 63
  %3081 = trunc i64 %3080 to i8
  store i8 %3081, i8* %35, align 1, !tbaa !2449
  store i8 0, i8* %41, align 1, !tbaa !2450
  store i8 0, i8* %29, align 1, !tbaa !2447
  store i64 %3071, i64* %68, align 1, !tbaa !2428
  store i64 0, i64* %69, align 1, !tbaa !2428
  %3082 = add i64 %3064, -104
  %3083 = add i64 %3066, 23
  store i64 %3083, i64* %PC, align 8
  %.cast5 = bitcast i64 %3071 to double
  %3084 = inttoptr i64 %3082 to double*
  %3085 = load double, double* %3084, align 8
  %3086 = fmul double %.cast5, %3085
  store double %3086, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3087 = add i64 %3064, -64
  %3088 = add i64 %3066, 28
  store i64 %3088, i64* %PC, align 8
  %3089 = inttoptr i64 %3087 to i64*
  %3090 = load i64, i64* %3089, align 8
  store i64 %3090, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %3091 = add i64 %3064, -96
  %3092 = add i64 %3066, 33
  store i64 %3092, i64* %PC, align 8
  %3093 = bitcast i64 %3090 to double
  %3094 = inttoptr i64 %3091 to double*
  %3095 = load double, double* %3094, align 8
  %3096 = fmul double %3093, %3095
  store double %3096, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %3097 = fadd double %3086, %3096
  store double %3097, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3098 = add i64 %3064, -16
  %3099 = add i64 %3066, 41
  store i64 %3099, i64* %PC, align 8
  %3100 = inttoptr i64 %3098 to i64*
  %3101 = load i64, i64* %3100, align 8
  store i64 %3101, i64* %RAX, align 8, !tbaa !2428
  %3102 = add i64 %3064, -28
  %3103 = add i64 %3066, 44
  store i64 %3103, i64* %PC, align 8
  %3104 = inttoptr i64 %3102 to i32*
  %3105 = load i32, i32* %3104, align 4
  %3106 = add i32 %3105, 13
  %3107 = zext i32 %3106 to i64
  store i64 %3107, i64* %RCX, align 8, !tbaa !2428
  %3108 = icmp ugt i32 %3105, -14
  %3109 = zext i1 %3108 to i8
  store i8 %3109, i8* %16, align 1, !tbaa !2432
  %3110 = and i32 %3106, 255
  %3111 = tail call i32 @llvm.ctpop.i32(i32 %3110) #14
  %3112 = trunc i32 %3111 to i8
  %3113 = and i8 %3112, 1
  %3114 = xor i8 %3113, 1
  store i8 %3114, i8* %23, align 1, !tbaa !2446
  %3115 = xor i32 %3106, %3105
  %3116 = lshr i32 %3115, 4
  %3117 = trunc i32 %3116 to i8
  %3118 = and i8 %3117, 1
  store i8 %3118, i8* %29, align 1, !tbaa !2447
  %3119 = icmp eq i32 %3106, 0
  %3120 = zext i1 %3119 to i8
  store i8 %3120, i8* %32, align 1, !tbaa !2448
  %3121 = lshr i32 %3106, 31
  %3122 = trunc i32 %3121 to i8
  store i8 %3122, i8* %35, align 1, !tbaa !2449
  %3123 = lshr i32 %3105, 31
  %3124 = xor i32 %3121, %3123
  %3125 = add nuw nsw i32 %3124, %3121
  %3126 = icmp eq i32 %3125, 2
  %3127 = zext i1 %3126 to i8
  store i8 %3127, i8* %41, align 1, !tbaa !2450
  %3128 = sext i32 %3106 to i64
  store i64 %3128, i64* %RDX, align 8, !tbaa !2428
  %3129 = shl nsw i64 %3128, 3
  %3130 = add i64 %3101, %3129
  %3131 = add i64 %3066, 55
  store i64 %3131, i64* %PC, align 8
  %3132 = inttoptr i64 %3130 to double*
  store double %3097, double* %3132, align 8
  %3133 = load i64, i64* %RBP, align 8
  %3134 = add i64 %3133, -112
  %3135 = load i64, i64* %PC, align 8
  %3136 = add i64 %3135, 5
  store i64 %3136, i64* %PC, align 8
  %3137 = inttoptr i64 %3134 to i64*
  %3138 = load i64, i64* %3137, align 8
  store i64 %3138, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3139 = add i64 %3133, -152
  %3140 = add i64 %3135, 13
  store i64 %3140, i64* %PC, align 8
  %3141 = bitcast i64 %3138 to double
  %3142 = inttoptr i64 %3139 to double*
  %3143 = load double, double* %3142, align 8
  %3144 = fsub double %3141, %3143
  store double %3144, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3145 = add i64 %3133, -96
  %3146 = add i64 %3135, 18
  store i64 %3146, i64* %PC, align 8
  %3147 = inttoptr i64 %3145 to double*
  store double %3144, double* %3147, align 8
  %3148 = load i64, i64* %RBP, align 8
  %3149 = add i64 %3148, -120
  %3150 = load i64, i64* %PC, align 8
  %3151 = add i64 %3150, 5
  store i64 %3151, i64* %PC, align 8
  %3152 = inttoptr i64 %3149 to i64*
  %3153 = load i64, i64* %3152, align 8
  store i64 %3153, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3154 = add i64 %3148, -144
  %3155 = add i64 %3150, 13
  store i64 %3155, i64* %PC, align 8
  %3156 = bitcast i64 %3153 to double
  %3157 = inttoptr i64 %3154 to double*
  %3158 = load double, double* %3157, align 8
  %3159 = fadd double %3156, %3158
  store double %3159, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3160 = add i64 %3148, -104
  %3161 = add i64 %3150, 18
  store i64 %3161, i64* %PC, align 8
  %3162 = inttoptr i64 %3160 to double*
  store double %3159, double* %3162, align 8
  %3163 = load i64, i64* %RBP, align 8
  %3164 = add i64 %3163, -48
  %3165 = load i64, i64* %PC, align 8
  %3166 = add i64 %3165, 5
  store i64 %3166, i64* %PC, align 8
  %3167 = inttoptr i64 %3164 to i64*
  %3168 = load i64, i64* %3167, align 8
  store i64 %3168, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3169 = add i64 %3163, -96
  %3170 = add i64 %3165, 10
  store i64 %3170, i64* %PC, align 8
  %3171 = bitcast i64 %3168 to double
  %3172 = inttoptr i64 %3169 to double*
  %3173 = load double, double* %3172, align 8
  %3174 = fmul double %3171, %3173
  store double %3174, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3175 = add i64 %3163, -56
  %3176 = add i64 %3165, 15
  store i64 %3176, i64* %PC, align 8
  %3177 = inttoptr i64 %3175 to i64*
  %3178 = load i64, i64* %3177, align 8
  store i64 %3178, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %3179 = add i64 %3163, -104
  %3180 = add i64 %3165, 20
  store i64 %3180, i64* %PC, align 8
  %3181 = bitcast i64 %3178 to double
  %3182 = inttoptr i64 %3179 to double*
  %3183 = load double, double* %3182, align 8
  %3184 = fmul double %3181, %3183
  store double %3184, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %3185 = fsub double %3174, %3184
  store double %3185, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3186 = add i64 %3163, -16
  %3187 = add i64 %3165, 28
  store i64 %3187, i64* %PC, align 8
  %3188 = inttoptr i64 %3186 to i64*
  %3189 = load i64, i64* %3188, align 8
  store i64 %3189, i64* %RAX, align 8, !tbaa !2428
  %3190 = add i64 %3163, -28
  %3191 = add i64 %3165, 31
  store i64 %3191, i64* %PC, align 8
  %3192 = inttoptr i64 %3190 to i32*
  %3193 = load i32, i32* %3192, align 4
  %3194 = add i32 %3193, 10
  %3195 = zext i32 %3194 to i64
  store i64 %3195, i64* %RCX, align 8, !tbaa !2428
  %3196 = icmp ugt i32 %3193, -11
  %3197 = zext i1 %3196 to i8
  store i8 %3197, i8* %16, align 1, !tbaa !2432
  %3198 = and i32 %3194, 255
  %3199 = tail call i32 @llvm.ctpop.i32(i32 %3198) #14
  %3200 = trunc i32 %3199 to i8
  %3201 = and i8 %3200, 1
  %3202 = xor i8 %3201, 1
  store i8 %3202, i8* %23, align 1, !tbaa !2446
  %3203 = xor i32 %3194, %3193
  %3204 = lshr i32 %3203, 4
  %3205 = trunc i32 %3204 to i8
  %3206 = and i8 %3205, 1
  store i8 %3206, i8* %29, align 1, !tbaa !2447
  %3207 = icmp eq i32 %3194, 0
  %3208 = zext i1 %3207 to i8
  store i8 %3208, i8* %32, align 1, !tbaa !2448
  %3209 = lshr i32 %3194, 31
  %3210 = trunc i32 %3209 to i8
  store i8 %3210, i8* %35, align 1, !tbaa !2449
  %3211 = lshr i32 %3193, 31
  %3212 = xor i32 %3209, %3211
  %3213 = add nuw nsw i32 %3212, %3209
  %3214 = icmp eq i32 %3213, 2
  %3215 = zext i1 %3214 to i8
  store i8 %3215, i8* %41, align 1, !tbaa !2450
  %3216 = sext i32 %3194 to i64
  store i64 %3216, i64* %RDX, align 8, !tbaa !2428
  %3217 = shl nsw i64 %3216, 3
  %3218 = add i64 %3189, %3217
  %3219 = add i64 %3165, 42
  store i64 %3219, i64* %PC, align 8
  %3220 = inttoptr i64 %3218 to double*
  store double %3185, double* %3220, align 8
  %3221 = load i64, i64* %RBP, align 8
  %3222 = add i64 %3221, -48
  %3223 = load i64, i64* %PC, align 8
  %3224 = add i64 %3223, 5
  store i64 %3224, i64* %PC, align 8
  %3225 = inttoptr i64 %3222 to i64*
  %3226 = load i64, i64* %3225, align 8
  store i64 %3226, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3227 = add i64 %3221, -104
  %3228 = add i64 %3223, 10
  store i64 %3228, i64* %PC, align 8
  %3229 = bitcast i64 %3226 to double
  %3230 = inttoptr i64 %3227 to double*
  %3231 = load double, double* %3230, align 8
  %3232 = fmul double %3229, %3231
  store double %3232, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3233 = add i64 %3221, -56
  %3234 = add i64 %3223, 15
  store i64 %3234, i64* %PC, align 8
  %3235 = inttoptr i64 %3233 to i64*
  %3236 = load i64, i64* %3235, align 8
  store i64 %3236, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %3237 = add i64 %3221, -96
  %3238 = add i64 %3223, 20
  store i64 %3238, i64* %PC, align 8
  %3239 = bitcast i64 %3236 to double
  %3240 = inttoptr i64 %3237 to double*
  %3241 = load double, double* %3240, align 8
  %3242 = fmul double %3239, %3241
  store double %3242, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %3243 = fadd double %3232, %3242
  store double %3243, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3244 = add i64 %3221, -16
  %3245 = add i64 %3223, 28
  store i64 %3245, i64* %PC, align 8
  %3246 = inttoptr i64 %3244 to i64*
  %3247 = load i64, i64* %3246, align 8
  store i64 %3247, i64* %RAX, align 8, !tbaa !2428
  %3248 = add i64 %3221, -28
  %3249 = add i64 %3223, 31
  store i64 %3249, i64* %PC, align 8
  %3250 = inttoptr i64 %3248 to i32*
  %3251 = load i32, i32* %3250, align 4
  %3252 = add i32 %3251, 11
  %3253 = zext i32 %3252 to i64
  store i64 %3253, i64* %RCX, align 8, !tbaa !2428
  %3254 = icmp ugt i32 %3251, -12
  %3255 = zext i1 %3254 to i8
  store i8 %3255, i8* %16, align 1, !tbaa !2432
  %3256 = and i32 %3252, 255
  %3257 = tail call i32 @llvm.ctpop.i32(i32 %3256) #14
  %3258 = trunc i32 %3257 to i8
  %3259 = and i8 %3258, 1
  %3260 = xor i8 %3259, 1
  store i8 %3260, i8* %23, align 1, !tbaa !2446
  %3261 = xor i32 %3252, %3251
  %3262 = lshr i32 %3261, 4
  %3263 = trunc i32 %3262 to i8
  %3264 = and i8 %3263, 1
  store i8 %3264, i8* %29, align 1, !tbaa !2447
  %3265 = icmp eq i32 %3252, 0
  %3266 = zext i1 %3265 to i8
  store i8 %3266, i8* %32, align 1, !tbaa !2448
  %3267 = lshr i32 %3252, 31
  %3268 = trunc i32 %3267 to i8
  store i8 %3268, i8* %35, align 1, !tbaa !2449
  %3269 = lshr i32 %3251, 31
  %3270 = xor i32 %3267, %3269
  %3271 = add nuw nsw i32 %3270, %3267
  %3272 = icmp eq i32 %3271, 2
  %3273 = zext i1 %3272 to i8
  store i8 %3273, i8* %41, align 1, !tbaa !2450
  %3274 = sext i32 %3252 to i64
  store i64 %3274, i64* %RDX, align 8, !tbaa !2428
  %3275 = shl nsw i64 %3274, 3
  %3276 = add i64 %3247, %3275
  %3277 = add i64 %3223, 42
  store i64 %3277, i64* %PC, align 8
  %3278 = inttoptr i64 %3276 to double*
  store double %3243, double* %3278, align 8
  %3279 = load i64, i64* %RBP, align 8
  %3280 = add i64 %3279, -112
  %3281 = load i64, i64* %PC, align 8
  %3282 = add i64 %3281, 5
  store i64 %3282, i64* %PC, align 8
  %3283 = inttoptr i64 %3280 to i64*
  %3284 = load i64, i64* %3283, align 8
  store i64 %3284, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3285 = add i64 %3279, -152
  %3286 = add i64 %3281, 13
  store i64 %3286, i64* %PC, align 8
  %3287 = bitcast i64 %3284 to double
  %3288 = inttoptr i64 %3285 to double*
  %3289 = load double, double* %3288, align 8
  %3290 = fadd double %3287, %3289
  store double %3290, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3291 = add i64 %3279, -96
  %3292 = add i64 %3281, 18
  store i64 %3292, i64* %PC, align 8
  %3293 = inttoptr i64 %3291 to double*
  store double %3290, double* %3293, align 8
  %3294 = load i64, i64* %RBP, align 8
  %3295 = add i64 %3294, -120
  %3296 = load i64, i64* %PC, align 8
  %3297 = add i64 %3296, 5
  store i64 %3297, i64* %PC, align 8
  %3298 = inttoptr i64 %3295 to i64*
  %3299 = load i64, i64* %3298, align 8
  store i64 %3299, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3300 = add i64 %3294, -144
  %3301 = add i64 %3296, 13
  store i64 %3301, i64* %PC, align 8
  %3302 = bitcast i64 %3299 to double
  %3303 = inttoptr i64 %3300 to double*
  %3304 = load double, double* %3303, align 8
  %3305 = fsub double %3302, %3304
  store double %3305, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3306 = add i64 %3294, -104
  %3307 = add i64 %3296, 18
  store i64 %3307, i64* %PC, align 8
  %3308 = inttoptr i64 %3306 to double*
  store double %3305, double* %3308, align 8
  %3309 = load i64, i64* %RBP, align 8
  %3310 = add i64 %3309, -80
  %3311 = load i64, i64* %PC, align 8
  %3312 = add i64 %3311, 5
  store i64 %3312, i64* %PC, align 8
  %3313 = inttoptr i64 %3310 to i64*
  %3314 = load i64, i64* %3313, align 8
  store i64 %3314, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3315 = add i64 %3309, -96
  %3316 = add i64 %3311, 10
  store i64 %3316, i64* %PC, align 8
  %3317 = bitcast i64 %3314 to double
  %3318 = inttoptr i64 %3315 to double*
  %3319 = load double, double* %3318, align 8
  %3320 = fmul double %3317, %3319
  store double %3320, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3321 = add i64 %3309, -88
  %3322 = add i64 %3311, 15
  store i64 %3322, i64* %PC, align 8
  %3323 = inttoptr i64 %3321 to i64*
  %3324 = load i64, i64* %3323, align 8
  store i64 %3324, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %3325 = add i64 %3309, -104
  %3326 = add i64 %3311, 20
  store i64 %3326, i64* %PC, align 8
  %3327 = bitcast i64 %3324 to double
  %3328 = inttoptr i64 %3325 to double*
  %3329 = load double, double* %3328, align 8
  %3330 = fmul double %3327, %3329
  store double %3330, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %3331 = fsub double %3320, %3330
  store double %3331, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3332 = add i64 %3309, -16
  %3333 = add i64 %3311, 28
  store i64 %3333, i64* %PC, align 8
  %3334 = inttoptr i64 %3332 to i64*
  %3335 = load i64, i64* %3334, align 8
  store i64 %3335, i64* %RAX, align 8, !tbaa !2428
  %3336 = add i64 %3309, -28
  %3337 = add i64 %3311, 31
  store i64 %3337, i64* %PC, align 8
  %3338 = inttoptr i64 %3336 to i32*
  %3339 = load i32, i32* %3338, align 4
  %3340 = add i32 %3339, 14
  %3341 = zext i32 %3340 to i64
  store i64 %3341, i64* %RCX, align 8, !tbaa !2428
  %3342 = icmp ugt i32 %3339, -15
  %3343 = zext i1 %3342 to i8
  store i8 %3343, i8* %16, align 1, !tbaa !2432
  %3344 = and i32 %3340, 255
  %3345 = tail call i32 @llvm.ctpop.i32(i32 %3344) #14
  %3346 = trunc i32 %3345 to i8
  %3347 = and i8 %3346, 1
  %3348 = xor i8 %3347, 1
  store i8 %3348, i8* %23, align 1, !tbaa !2446
  %3349 = xor i32 %3340, %3339
  %3350 = lshr i32 %3349, 4
  %3351 = trunc i32 %3350 to i8
  %3352 = and i8 %3351, 1
  store i8 %3352, i8* %29, align 1, !tbaa !2447
  %3353 = icmp eq i32 %3340, 0
  %3354 = zext i1 %3353 to i8
  store i8 %3354, i8* %32, align 1, !tbaa !2448
  %3355 = lshr i32 %3340, 31
  %3356 = trunc i32 %3355 to i8
  store i8 %3356, i8* %35, align 1, !tbaa !2449
  %3357 = lshr i32 %3339, 31
  %3358 = xor i32 %3355, %3357
  %3359 = add nuw nsw i32 %3358, %3355
  %3360 = icmp eq i32 %3359, 2
  %3361 = zext i1 %3360 to i8
  store i8 %3361, i8* %41, align 1, !tbaa !2450
  %3362 = sext i32 %3340 to i64
  store i64 %3362, i64* %RDX, align 8, !tbaa !2428
  %3363 = shl nsw i64 %3362, 3
  %3364 = add i64 %3335, %3363
  %3365 = add i64 %3311, 42
  store i64 %3365, i64* %PC, align 8
  %3366 = inttoptr i64 %3364 to double*
  store double %3331, double* %3366, align 8
  %3367 = load i64, i64* %RBP, align 8
  %3368 = add i64 %3367, -80
  %3369 = load i64, i64* %PC, align 8
  %3370 = add i64 %3369, 5
  store i64 %3370, i64* %PC, align 8
  %3371 = inttoptr i64 %3368 to i64*
  %3372 = load i64, i64* %3371, align 8
  store i64 %3372, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3373 = add i64 %3367, -104
  %3374 = add i64 %3369, 10
  store i64 %3374, i64* %PC, align 8
  %3375 = bitcast i64 %3372 to double
  %3376 = inttoptr i64 %3373 to double*
  %3377 = load double, double* %3376, align 8
  %3378 = fmul double %3375, %3377
  store double %3378, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3379 = add i64 %3367, -88
  %3380 = add i64 %3369, 15
  store i64 %3380, i64* %PC, align 8
  %3381 = inttoptr i64 %3379 to i64*
  %3382 = load i64, i64* %3381, align 8
  store i64 %3382, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %3383 = add i64 %3367, -96
  %3384 = add i64 %3369, 20
  store i64 %3384, i64* %PC, align 8
  %3385 = bitcast i64 %3382 to double
  %3386 = inttoptr i64 %3383 to double*
  %3387 = load double, double* %3386, align 8
  %3388 = fmul double %3385, %3387
  store double %3388, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %3389 = fadd double %3378, %3388
  store double %3389, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3390 = add i64 %3367, -16
  %3391 = add i64 %3369, 28
  store i64 %3391, i64* %PC, align 8
  %3392 = inttoptr i64 %3390 to i64*
  %3393 = load i64, i64* %3392, align 8
  store i64 %3393, i64* %RAX, align 8, !tbaa !2428
  %3394 = add i64 %3367, -28
  %3395 = add i64 %3369, 31
  store i64 %3395, i64* %PC, align 8
  %3396 = inttoptr i64 %3394 to i32*
  %3397 = load i32, i32* %3396, align 4
  %3398 = add i32 %3397, 15
  %3399 = zext i32 %3398 to i64
  store i64 %3399, i64* %RCX, align 8, !tbaa !2428
  %3400 = icmp ugt i32 %3397, -16
  %3401 = zext i1 %3400 to i8
  store i8 %3401, i8* %16, align 1, !tbaa !2432
  %3402 = and i32 %3398, 255
  %3403 = tail call i32 @llvm.ctpop.i32(i32 %3402) #14
  %3404 = trunc i32 %3403 to i8
  %3405 = and i8 %3404, 1
  %3406 = xor i8 %3405, 1
  store i8 %3406, i8* %23, align 1, !tbaa !2446
  %3407 = xor i32 %3398, %3397
  %3408 = lshr i32 %3407, 4
  %3409 = trunc i32 %3408 to i8
  %3410 = and i8 %3409, 1
  store i8 %3410, i8* %29, align 1, !tbaa !2447
  %3411 = icmp eq i32 %3398, 0
  %3412 = zext i1 %3411 to i8
  store i8 %3412, i8* %32, align 1, !tbaa !2448
  %3413 = lshr i32 %3398, 31
  %3414 = trunc i32 %3413 to i8
  store i8 %3414, i8* %35, align 1, !tbaa !2449
  %3415 = lshr i32 %3397, 31
  %3416 = xor i32 %3413, %3415
  %3417 = add nuw nsw i32 %3416, %3413
  %3418 = icmp eq i32 %3417, 2
  %3419 = zext i1 %3418 to i8
  store i8 %3419, i8* %41, align 1, !tbaa !2450
  %3420 = sext i32 %3398 to i64
  store i64 %3420, i64* %RDX, align 8, !tbaa !2428
  %3421 = shl nsw i64 %3420, 3
  %3422 = add i64 %3393, %3421
  %3423 = add i64 %3369, 42
  store i64 %3423, i64* %PC, align 8
  %3424 = inttoptr i64 %3422 to double*
  store double %3389, double* %3424, align 8
  %3425 = load i64, i64* %RBP, align 8
  %3426 = add i64 %3425, -28
  %3427 = load i64, i64* %PC, align 8
  %3428 = add i64 %3427, 3
  store i64 %3428, i64* %PC, align 8
  %3429 = inttoptr i64 %3426 to i32*
  %3430 = load i32, i32* %3429, align 4
  %3431 = add i32 %3430, 16
  %3432 = zext i32 %3431 to i64
  store i64 %3432, i64* %RAX, align 8, !tbaa !2428
  %3433 = icmp ugt i32 %3430, -17
  %3434 = zext i1 %3433 to i8
  store i8 %3434, i8* %16, align 1, !tbaa !2432
  %3435 = and i32 %3431, 255
  %3436 = tail call i32 @llvm.ctpop.i32(i32 %3435) #14
  %3437 = trunc i32 %3436 to i8
  %3438 = and i8 %3437, 1
  %3439 = xor i8 %3438, 1
  store i8 %3439, i8* %23, align 1, !tbaa !2446
  %3440 = xor i32 %3430, 16
  %3441 = xor i32 %3440, %3431
  %3442 = lshr i32 %3441, 4
  %3443 = trunc i32 %3442 to i8
  %3444 = and i8 %3443, 1
  store i8 %3444, i8* %29, align 1, !tbaa !2447
  %3445 = icmp eq i32 %3431, 0
  %3446 = zext i1 %3445 to i8
  store i8 %3446, i8* %32, align 1, !tbaa !2448
  %3447 = lshr i32 %3431, 31
  %3448 = trunc i32 %3447 to i8
  store i8 %3448, i8* %35, align 1, !tbaa !2449
  %3449 = lshr i32 %3430, 31
  %3450 = xor i32 %3447, %3449
  %3451 = add nuw nsw i32 %3450, %3447
  %3452 = icmp eq i32 %3451, 2
  %3453 = zext i1 %3452 to i8
  store i8 %3453, i8* %41, align 1, !tbaa !2450
  %3454 = add i64 %3427, 9
  store i64 %3454, i64* %PC, align 8
  store i32 %3431, i32* %3429, align 4
  %3455 = load i64, i64* %PC, align 8
  %3456 = add i64 %3455, -1815
  store i64 %3456, i64* %PC, align 8, !tbaa !2428
  br label %block_402c02

block_40331e:                                     ; preds = %block_402c02
  %3457 = load i64, i64* %RSP, align 8
  %3458 = add i64 %3457, 24
  store i64 %3458, i64* %RSP, align 8, !tbaa !2428
  %3459 = icmp ugt i64 %3457, -25
  %3460 = zext i1 %3459 to i8
  store i8 %3460, i8* %16, align 1, !tbaa !2432
  %3461 = trunc i64 %3458 to i32
  %3462 = and i32 %3461, 255
  %3463 = tail call i32 @llvm.ctpop.i32(i32 %3462) #14
  %3464 = trunc i32 %3463 to i8
  %3465 = and i8 %3464, 1
  %3466 = xor i8 %3465, 1
  store i8 %3466, i8* %23, align 1, !tbaa !2446
  %3467 = xor i64 %3457, 16
  %3468 = xor i64 %3467, %3458
  %3469 = lshr i64 %3468, 4
  %3470 = trunc i64 %3469 to i8
  %3471 = and i8 %3470, 1
  store i8 %3471, i8* %29, align 1, !tbaa !2447
  %3472 = icmp eq i64 %3458, 0
  %3473 = zext i1 %3472 to i8
  store i8 %3473, i8* %32, align 1, !tbaa !2448
  %3474 = lshr i64 %3458, 63
  %3475 = trunc i64 %3474 to i8
  store i8 %3475, i8* %35, align 1, !tbaa !2449
  %3476 = lshr i64 %3457, 63
  %3477 = xor i64 %3474, %3476
  %3478 = add nuw nsw i64 %3477, %3474
  %3479 = icmp eq i64 %3478, 2
  %3480 = zext i1 %3479 to i8
  store i8 %3480, i8* %41, align 1, !tbaa !2450
  %3481 = add i64 %3526, 5
  store i64 %3481, i64* %PC, align 8
  %3482 = add i64 %3457, 32
  %3483 = inttoptr i64 %3458 to i64*
  %3484 = load i64, i64* %3483, align 8
  store i64 %3484, i64* %RBP, align 8, !tbaa !2428
  store i64 %3482, i64* %RSP, align 8, !tbaa !2428
  %3485 = add i64 %3526, 6
  store i64 %3485, i64* %PC, align 8
  %3486 = inttoptr i64 %3482 to i64*
  %3487 = load i64, i64* %3486, align 8
  store i64 %3487, i64* %PC, align 8, !tbaa !2428
  %3488 = add i64 %3457, 40
  store i64 %3488, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_402c02:                                     ; preds = %block_402c0e, %block_4028a0
  %3489 = phi i64 [ %3456, %block_402c0e ], [ %.pre, %block_4028a0 ]
  %3490 = load i64, i64* %RBP, align 8
  %3491 = add i64 %3490, -28
  %3492 = add i64 %3489, 3
  store i64 %3492, i64* %PC, align 8
  %3493 = inttoptr i64 %3491 to i32*
  %3494 = load i32, i32* %3493, align 4
  %3495 = zext i32 %3494 to i64
  store i64 %3495, i64* %RAX, align 8, !tbaa !2428
  %3496 = add i64 %3490, -4
  %3497 = add i64 %3489, 6
  store i64 %3497, i64* %PC, align 8
  %3498 = inttoptr i64 %3496 to i32*
  %3499 = load i32, i32* %3498, align 4
  %3500 = sub i32 %3494, %3499
  %3501 = icmp ult i32 %3494, %3499
  %3502 = zext i1 %3501 to i8
  store i8 %3502, i8* %16, align 1, !tbaa !2432
  %3503 = and i32 %3500, 255
  %3504 = tail call i32 @llvm.ctpop.i32(i32 %3503) #14
  %3505 = trunc i32 %3504 to i8
  %3506 = and i8 %3505, 1
  %3507 = xor i8 %3506, 1
  store i8 %3507, i8* %23, align 1, !tbaa !2446
  %3508 = xor i32 %3499, %3494
  %3509 = xor i32 %3508, %3500
  %3510 = lshr i32 %3509, 4
  %3511 = trunc i32 %3510 to i8
  %3512 = and i8 %3511, 1
  store i8 %3512, i8* %29, align 1, !tbaa !2447
  %3513 = icmp eq i32 %3500, 0
  %3514 = zext i1 %3513 to i8
  store i8 %3514, i8* %32, align 1, !tbaa !2448
  %3515 = lshr i32 %3500, 31
  %3516 = trunc i32 %3515 to i8
  store i8 %3516, i8* %35, align 1, !tbaa !2449
  %3517 = lshr i32 %3494, 31
  %3518 = lshr i32 %3499, 31
  %3519 = xor i32 %3518, %3517
  %3520 = xor i32 %3515, %3517
  %3521 = add nuw nsw i32 %3520, %3519
  %3522 = icmp eq i32 %3521, 2
  %3523 = zext i1 %3522 to i8
  store i8 %3523, i8* %41, align 1, !tbaa !2450
  %3524 = icmp ne i8 %3516, 0
  %3525 = xor i1 %3524, %3522
  %.v = select i1 %3525, i64 12, i64 1820
  %3526 = add i64 %3489, %.v
  store i64 %3526, i64* %PC, align 8, !tbaa !2428
  br i1 %3525, label %block_402c0e, label %block_40331e
}

; Function Attrs: noinline
define %struct.Memory* @sub_4007d0_register_tm_clones(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #8 {
block_4007d0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  store i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64* %RSI, align 8, !tbaa !2428
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 6
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* %RSP, align 8, !tbaa !2428
  %6 = add i64 %5, -8
  %7 = inttoptr i64 %6 to i64*
  store i64 %3, i64* %7, align 8
  store i64 %6, i64* %RSP, align 8, !tbaa !2428
  %8 = load i64, i64* %RSI, align 8
  %9 = load i64, i64* %PC, align 8
  %10 = sub i64 %8, ptrtoint (%__bss_start_type* @__bss_start to i64)
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i64 %6, i64* %RBP, align 8, !tbaa !2428
  %17 = ashr i64 %10, 3
  %18 = lshr i64 %17, 63
  store i64 %18, i64* %RAX, align 8, !tbaa !2428
  %19 = add nsw i64 %18, %17
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = ashr i64 %19, 1
  store i64 %22, i64* %RSI, align 8, !tbaa !2428
  store i8 %21, i8* %11, align 1, !tbaa !2453
  %23 = trunc i64 %22 to i32
  %24 = and i32 %23, 255
  %25 = tail call i32 @llvm.ctpop.i32(i32 %24) #14
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = xor i8 %27, 1
  store i8 %28, i8* %12, align 1, !tbaa !2453
  store i8 0, i8* %13, align 1, !tbaa !2453
  %29 = icmp eq i64 %22, 0
  %30 = zext i1 %29 to i8
  store i8 %30, i8* %14, align 1, !tbaa !2453
  %31 = lshr i64 %22, 63
  %32 = trunc i64 %31 to i8
  store i8 %32, i8* %15, align 1, !tbaa !2453
  store i8 0, i8* %16, align 1, !tbaa !2453
  %.v = select i1 %29, i64 50, i64 29
  %33 = add i64 %9, %.v
  store i64 %33, i64* %PC, align 8, !tbaa !2428
  br i1 %29, label %block_400808, label %block_4007f3

block_4007f3:                                     ; preds = %block_4007d0
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %11, align 1, !tbaa !2432
  store i8 1, i8* %12, align 1, !tbaa !2446
  store i8 1, i8* %14, align 1, !tbaa !2448
  store i8 0, i8* %15, align 1, !tbaa !2449
  store i8 0, i8* %16, align 1, !tbaa !2450
  store i8 0, i8* %13, align 1, !tbaa !2447
  %34 = add i64 %33, 21
  store i64 %34, i64* %PC, align 8, !tbaa !2428
  br label %block_400808

block_400808:                                     ; preds = %block_4007f3, %block_4007d0
  %35 = phi i64 [ %34, %block_4007f3 ], [ %33, %block_4007d0 ]
  %36 = add i64 %35, 1
  store i64 %36, i64* %PC, align 8
  %37 = load i64, i64* %RSP, align 8, !tbaa !2428
  %38 = add i64 %37, 8
  %39 = inttoptr i64 %37 to i64*
  %40 = load i64, i64* %39, align 8
  store i64 %40, i64* %RBP, align 8, !tbaa !2428
  store i64 %38, i64* %RSP, align 8, !tbaa !2428
  %41 = add i64 %35, 2
  store i64 %41, i64* %PC, align 8
  %42 = inttoptr i64 %38 to i64*
  %43 = load i64, i64* %42, align 8
  store i64 %43, i64* %PC, align 8, !tbaa !2428
  %44 = add i64 %37, 16
  store i64 %44, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400e30_get_time(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400e30:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %7 = load i64, i64* %RBP, align 8
  %8 = add i64 %1, 1
  store i64 %8, i64* %PC, align 8
  %9 = load i64, i64* %RSP, align 8, !tbaa !2428
  %10 = add i64 %9, -8
  %11 = inttoptr i64 %10 to i64*
  store i64 %7, i64* %11, align 8
  %12 = load i64, i64* %PC, align 8
  store i64 %10, i64* %RBP, align 8, !tbaa !2428
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %19 = add i64 %9, -24
  store i64 %19, i64* %RDI, align 8, !tbaa !2428
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %13, align 1, !tbaa !2432
  store i8 1, i8* %14, align 1, !tbaa !2446
  store i8 1, i8* %16, align 1, !tbaa !2448
  store i8 0, i8* %17, align 1, !tbaa !2449
  store i8 0, i8* %18, align 1, !tbaa !2450
  store i8 0, i8* %15, align 1, !tbaa !2447
  store i64 0, i64* %RSI, align 8, !tbaa !2428
  %20 = add i64 %12, -1857
  %21 = add i64 %12, 20
  %22 = add i64 %9, -48
  %23 = inttoptr i64 %22 to i64*
  store i64 %21, i64* %23, align 8
  store i64 %22, i64* %RSP, align 8, !tbaa !2428
  store i64 %20, i64* %PC, align 8, !tbaa !2428
  %24 = tail call fastcc %struct.Memory* @ext_4006f0_gettimeofday(%struct.State* nonnull %0, %struct.Memory* %2)
  %25 = bitcast [32 x %union.VectorReg]* %4 to i8*
  %26 = load i64, i64* %PC, align 8
  %27 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 56) to i64*), align 8
  %28 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %27, i64* %28, align 1, !tbaa !2451
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %30 = bitcast i64* %29 to double*
  store double 0.000000e+00, double* %30, align 1, !tbaa !2451
  %31 = load i64, i64* %RBP, align 8
  %32 = add i64 %31, -16
  %33 = add i64 %26, 14
  store i64 %33, i64* %PC, align 8
  %34 = inttoptr i64 %32 to i64*
  %35 = load i64, i64* %34, align 8
  %36 = sitofp i64 %35 to double
  %37 = bitcast %union.VectorReg* %5 to double*
  store double %36, double* %37, align 1, !tbaa !2451
  %38 = add i64 %31, -8
  %39 = add i64 %26, 20
  store i64 %39, i64* %PC, align 8
  %40 = inttoptr i64 %38 to i64*
  %41 = load i64, i64* %40, align 8
  %42 = sitofp i64 %41 to double
  %43 = bitcast %union.VectorReg* %6 to double*
  %44 = bitcast i64 %27 to double
  %45 = fmul double %42, %44
  store double %45, double* %43, align 1, !tbaa !2451
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %47 = bitcast i64* %46 to <2 x i32>*
  %48 = load <2 x i32>, <2 x i32>* %47, align 1
  %49 = fadd double %36, %45
  store double %49, double* %37, align 1, !tbaa !2451
  %.cast = bitcast double %49 to <2 x i32>
  %50 = extractelement <2 x i32> %.cast, i32 0
  %51 = bitcast [32 x %union.VectorReg]* %4 to i32*
  store i32 %50, i32* %51, align 1, !tbaa !2475
  %52 = extractelement <2 x i32> %.cast, i32 1
  %53 = getelementptr inbounds i8, i8* %25, i64 4
  %54 = bitcast i8* %53 to i32*
  store i32 %52, i32* %54, align 1, !tbaa !2475
  %55 = extractelement <2 x i32> %48, i32 0
  %56 = bitcast i64* %29 to i32*
  store i32 %55, i32* %56, align 1, !tbaa !2475
  %57 = extractelement <2 x i32> %48, i32 1
  %58 = getelementptr inbounds i8, i8* %25, i64 12
  %59 = bitcast i8* %58 to i32*
  store i32 %57, i32* %59, align 1, !tbaa !2475
  %60 = add i64 %31, -20
  %61 = load i32, i32* %EAX, align 4
  %62 = add i64 %26, 34
  store i64 %62, i64* %PC, align 8
  %63 = inttoptr i64 %60 to i32*
  store i32 %61, i32* %63, align 4
  %64 = load i64, i64* %RSP, align 8
  %65 = load i64, i64* %PC, align 8
  %66 = add i64 %64, 32
  store i64 %66, i64* %RSP, align 8, !tbaa !2428
  %67 = icmp ugt i64 %64, -33
  %68 = zext i1 %67 to i8
  store i8 %68, i8* %13, align 1, !tbaa !2432
  %69 = trunc i64 %66 to i32
  %70 = and i32 %69, 255
  %71 = tail call i32 @llvm.ctpop.i32(i32 %70) #14
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  %74 = xor i8 %73, 1
  store i8 %74, i8* %14, align 1, !tbaa !2446
  %75 = xor i64 %66, %64
  %76 = lshr i64 %75, 4
  %77 = trunc i64 %76 to i8
  %78 = and i8 %77, 1
  store i8 %78, i8* %15, align 1, !tbaa !2447
  %79 = icmp eq i64 %66, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %16, align 1, !tbaa !2448
  %81 = lshr i64 %66, 63
  %82 = trunc i64 %81 to i8
  store i8 %82, i8* %17, align 1, !tbaa !2449
  %83 = lshr i64 %64, 63
  %84 = xor i64 %81, %83
  %85 = add nuw nsw i64 %84, %81
  %86 = icmp eq i64 %85, 2
  %87 = zext i1 %86 to i8
  store i8 %87, i8* %18, align 1, !tbaa !2450
  %88 = add i64 %65, 5
  store i64 %88, i64* %PC, align 8
  %89 = add i64 %64, 40
  %90 = inttoptr i64 %66 to i64*
  %91 = load i64, i64* %90, align 8
  store i64 %91, i64* %RBP, align 8, !tbaa !2428
  store i64 %89, i64* %RSP, align 8, !tbaa !2428
  %92 = add i64 %65, 6
  store i64 %92, i64* %PC, align 8
  %93 = inttoptr i64 %89 to i64*
  %94 = load i64, i64* %93, align 8
  store i64 %94, i64* %PC, align 8, !tbaa !2428
  %95 = add i64 %64, 48
  store i64 %95, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %24
}

; Function Attrs: noinline
define %struct.Memory* @sub_400850_main(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #8 {
block_400850:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %4 to i32*
  %RAX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3
  %9 = load i64, i64* %RBP, align 8
  %10 = add i64 %1, 1
  store i64 %10, i64* %PC, align 8
  %11 = load i64, i64* %RSP, align 8, !tbaa !2428
  %12 = add i64 %11, -8
  %13 = inttoptr i64 %12 to i64*
  store i64 %9, i64* %13, align 8
  %14 = load i64, i64* %PC, align 8
  store i64 %12, i64* %RBP, align 8, !tbaa !2428
  %15 = add i64 %11, -232
  store i64 %15, i64* %RSP, align 8, !tbaa !2428
  %16 = icmp ult i64 %12, 224
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1, !tbaa !2432
  %19 = trunc i64 %15 to i32
  %20 = and i32 %19, 255
  %21 = tail call i32 @llvm.ctpop.i32(i32 %20) #14
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = xor i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %24, i8* %25, align 1, !tbaa !2446
  %26 = xor i64 %12, %15
  %27 = lshr i64 %26, 4
  %28 = trunc i64 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1, !tbaa !2447
  %31 = icmp eq i64 %15, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1, !tbaa !2448
  %34 = lshr i64 %15, 63
  %35 = trunc i64 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1, !tbaa !2449
  %37 = lshr i64 %12, 63
  %38 = xor i64 %34, %37
  %39 = add nuw nsw i64 %38, %37
  %40 = icmp eq i64 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1, !tbaa !2450
  store i64 16, i64* %RAX, align 8, !tbaa !2428
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  %43 = add i64 %11, -12
  %44 = add i64 %14, 24
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %43 to i32*
  store i32 0, i32* %45, align 4
  %46 = load i64, i64* %RBP, align 8
  %47 = add i64 %46, -88
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 8
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %47 to i64*
  store i64 0, i64* %50, align 8
  %51 = load i64, i64* %RBP, align 8
  %52 = add i64 %51, -144
  %53 = load i64, i64* %RDI, align 8
  %54 = load i64, i64* %PC, align 8
  %55 = add i64 %54, 7
  store i64 %55, i64* %PC, align 8
  %56 = inttoptr i64 %52 to i64*
  store i64 %53, i64* %56, align 8
  %57 = load i64, i64* %PC, align 8
  %58 = add i64 %57, 1464
  %59 = add i64 %57, 5
  %60 = load i64, i64* %RSP, align 8, !tbaa !2428
  %61 = add i64 %60, -8
  %62 = inttoptr i64 %61 to i64*
  store i64 %59, i64* %62, align 8
  store i64 %61, i64* %RSP, align 8, !tbaa !2428
  store i64 %58, i64* %PC, align 8, !tbaa !2428
  %63 = tail call %struct.Memory* @sub_400e30_get_time_renamed_(%struct.State* nonnull %0, i64 %58, %struct.Memory* %2)
  %64 = load i64, i64* %RBP, align 8
  %65 = add i64 %64, -64
  %66 = load i64, i64* %PC, align 8
  %67 = add i64 %66, 5
  store i64 %67, i64* %PC, align 8
  %68 = bitcast [32 x %union.VectorReg]* %5 to double*
  %69 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %5, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %70 = load i64, i64* %69, align 1
  %71 = inttoptr i64 %65 to i64*
  store i64 %70, i64* %71, align 8
  %72 = load i64, i64* %PC, align 8
  %73 = add i64 %72, 1454
  %74 = add i64 %72, 5
  %75 = load i64, i64* %RSP, align 8, !tbaa !2428
  %76 = add i64 %75, -8
  %77 = inttoptr i64 %76 to i64*
  store i64 %74, i64* %77, align 8
  store i64 %76, i64* %RSP, align 8, !tbaa !2428
  store i64 %73, i64* %PC, align 8, !tbaa !2428
  %78 = tail call %struct.Memory* @sub_400e30_get_time_renamed_(%struct.State* nonnull %0, i64 %73, %struct.Memory* %63)
  %79 = load i64, i64* %RBP, align 8
  %80 = add i64 %79, -72
  %81 = load i64, i64* %PC, align 8
  %82 = add i64 %81, 5
  store i64 %82, i64* %PC, align 8
  %83 = load i64, i64* %69, align 1
  %84 = inttoptr i64 %80 to i64*
  store i64 %83, i64* %84, align 8
  %85 = bitcast [32 x %union.VectorReg]* %5 to i8*
  %86 = load i64, i64* %RBP, align 8
  %87 = add i64 %86, -72
  %88 = load i64, i64* %PC, align 8
  %89 = add i64 %88, 5
  store i64 %89, i64* %PC, align 8
  %90 = inttoptr i64 %87 to i64*
  %91 = load i64, i64* %90, align 8
  store i64 %91, i64* %69, align 1, !tbaa !2451
  %92 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %93 = bitcast i64* %92 to double*
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %94 = bitcast %union.VectorReg* %6 to i8*
  %95 = add i64 %86, -64
  %96 = add i64 %88, 10
  store i64 %96, i64* %PC, align 8
  %97 = inttoptr i64 %95 to i64*
  %98 = load i64, i64* %97, align 8
  %99 = bitcast %union.VectorReg* %6 to double*
  %100 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %98, i64* %100, align 1, !tbaa !2451
  %101 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %102 = bitcast i64* %101 to double*
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  %103 = bitcast i64 %91 to double
  %104 = bitcast i64 %98 to double
  %105 = fsub double %103, %104
  %106 = add i64 %86, -80
  %107 = add i64 %88, 19
  store i64 %107, i64* %PC, align 8
  %108 = inttoptr i64 %106 to double*
  store double %105, double* %108, align 8
  %109 = load i64, i64* %PC, align 8
  %110 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 24) to i64*), align 8
  store i64 %110, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %111 = add i64 %109, -335
  %112 = add i64 %109, 13
  %113 = load i64, i64* %RSP, align 8, !tbaa !2428
  %114 = add i64 %113, -8
  %115 = inttoptr i64 %114 to i64*
  store i64 %112, i64* %115, align 8
  store i64 %114, i64* %RSP, align 8, !tbaa !2428
  store i64 %111, i64* %PC, align 8, !tbaa !2428
  %116 = load double, double* %68, align 8, !alias.scope !2477, !noalias !2480
  %117 = load i64, i64* %115, align 8
  store i64 %113, i64* %RSP, align 8, !alias.scope !2477, !noalias !2480
  %118 = tail call double @sqrt(double %116)
  %119 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  %120 = bitcast i64* %119 to i8*
  call void @llvm.memset.p0i8.i64(i8* %120, i8 0, i64 16, i32 8, i1 false)
  %121 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 32) to double*), align 16
  %122 = fmul double %121, %118
  store double %122, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %123 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 40) to i64*), align 8
  store i64 %123, i64* %100, align 1, !tbaa !2451
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  %124 = bitcast %union.VectorReg* %7 to i8*
  %125 = bitcast double %122 to <2 x i32>
  %126 = extractelement <2 x i32> %125, i32 0
  %127 = bitcast %union.VectorReg* %7 to i32*
  store i32 %126, i32* %127, align 1, !tbaa !2475
  %128 = extractelement <2 x i32> %125, i32 1
  %129 = getelementptr inbounds i8, i8* %124, i64 4
  %130 = bitcast i8* %129 to i32*
  store i32 %128, i32* %130, align 1, !tbaa !2475
  %131 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %132 = bitcast i64* %131 to i32*
  store i32 0, i32* %132, align 1, !tbaa !2475
  %133 = getelementptr inbounds i8, i8* %124, i64 12
  %134 = bitcast i8* %133 to i32*
  store i32 0, i32* %134, align 1, !tbaa !2475
  %135 = bitcast %union.VectorReg* %7 to double*
  %136 = load double, double* %135, align 1
  %137 = bitcast i64 %123 to double
  %138 = fsub double %136, %137
  store double %138, double* %135, align 1, !tbaa !2451
  %139 = tail call double @llvm.trunc.f64(double %138) #14
  %140 = tail call double @llvm.fabs.f64(double %139) #14
  %141 = fcmp ogt double %140, 0x43E0000000000000
  %142 = fptosi double %139 to i64
  %143 = select i1 %141, i64 -9223372036854775808, i64 %142
  %144 = xor i64 %143, -9223372036854775808
  store i64 %144, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %145 = trunc i64 %143 to i32
  %146 = and i32 %145, 255
  %147 = tail call i32 @llvm.ctpop.i32(i32 %146) #14
  %148 = trunc i32 %147 to i8
  %149 = and i8 %148, 1
  %150 = xor i8 %149, 1
  store i8 %150, i8* %25, align 1, !tbaa !2446
  %151 = icmp eq i64 %144, 0
  %152 = zext i1 %151 to i8
  store i8 %152, i8* %33, align 1, !tbaa !2448
  %153 = lshr i64 %144, 63
  %154 = trunc i64 %153 to i8
  store i8 %154, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2447
  %155 = tail call double @llvm.trunc.f64(double %122) #14
  %156 = tail call double @llvm.fabs.f64(double %155) #14
  %157 = fcmp ogt double %156, 0x43E0000000000000
  %158 = fptosi double %155 to i64
  %159 = select i1 %157, i64 -9223372036854775808, i64 %158
  store i64 %159, i64* %RCX, align 8, !tbaa !2428
  %160 = add i64 %117, 54
  store i64 %160, i64* %PC, align 8
  %161 = fcmp uno double %122, %137
  br i1 %161, label %162, label %172

; <label>:162:                                    ; preds = %block_400850
  %163 = fadd double %122, %137
  %164 = bitcast double %163 to i64
  %165 = and i64 %164, 9221120237041090560
  %166 = icmp eq i64 %165, 9218868437227405312
  %167 = and i64 %164, 2251799813685247
  %168 = icmp ne i64 %167, 0
  %169 = and i1 %166, %168
  br i1 %169, label %170, label %178

; <label>:170:                                    ; preds = %162
  %171 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %160, %struct.Memory* %78) #16
  %.pre = load i64, i64* %RCX, align 8
  %.pre71 = load i64, i64* %PC, align 8
  %.pre72 = load i8, i8* %18, align 1, !tbaa !2432
  %.pre73 = load i64, i64* %RDI, align 8, !tbaa !2428
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3

; <label>:172:                                    ; preds = %block_400850
  %173 = fcmp ogt double %122, %137
  br i1 %173, label %178, label %174

; <label>:174:                                    ; preds = %172
  %175 = fcmp olt double %122, %137
  br i1 %175, label %178, label %176

; <label>:176:                                    ; preds = %174
  %177 = fcmp oeq double %122, %137
  br i1 %177, label %178, label %182

; <label>:178:                                    ; preds = %176, %174, %172, %162
  %179 = phi i8 [ 0, %172 ], [ 0, %174 ], [ 1, %176 ], [ 1, %162 ]
  %180 = phi i8 [ 0, %172 ], [ 0, %174 ], [ 0, %176 ], [ 1, %162 ]
  %181 = phi i8 [ 0, %172 ], [ 1, %174 ], [ 0, %176 ], [ 1, %162 ]
  store i8 %179, i8* %33, align 1, !tbaa !2453
  store i8 %180, i8* %25, align 1, !tbaa !2453
  store i8 %181, i8* %18, align 1, !tbaa !2453
  br label %182

; <label>:182:                                    ; preds = %178, %176
  %183 = phi i8 [ %181, %178 ], [ 0, %176 ]
  store i8 0, i8* %42, align 1, !tbaa !2453
  store i8 0, i8* %36, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3: ; preds = %182, %170
  %184 = phi i64 [ %.pre73, %170 ], [ %144, %182 ]
  %185 = phi i8 [ %.pre72, %170 ], [ %183, %182 ]
  %186 = phi i64 [ %.pre71, %170 ], [ %160, %182 ]
  %187 = phi i64 [ %.pre, %170 ], [ %159, %182 ]
  %188 = phi %struct.Memory* [ %171, %170 ], [ %78, %182 ]
  %189 = icmp ne i8 %185, 0
  %190 = select i1 %189, i64 %187, i64 %184
  store i64 %190, i64* %RDI, align 8, !tbaa !2428
  %191 = load i64, i64* %RBP, align 8
  %192 = add i64 %191, -144
  %193 = add i64 %186, 11
  store i64 %193, i64* %PC, align 8
  %194 = inttoptr i64 %192 to i64*
  %195 = load i64, i64* %194, align 8
  store i64 %195, i64* %RCX, align 8, !tbaa !2428
  %196 = add i64 %191, -152
  %197 = add i64 %186, 18
  store i64 %197, i64* %PC, align 8
  %198 = inttoptr i64 %196 to i64*
  store i64 %190, i64* %198, align 8
  %199 = load i64, i64* %RCX, align 8
  %200 = load i64, i64* %PC, align 8
  store i64 %199, i64* %RDI, align 8, !tbaa !2428
  %201 = load i64, i64* %RBP, align 8
  %202 = add i64 %201, -152
  %203 = add i64 %200, 10
  store i64 %203, i64* %PC, align 8
  %204 = inttoptr i64 %202 to i64*
  %205 = load i64, i64* %204, align 8
  store i64 %205, i64* %RSI, align 8, !tbaa !2428
  %206 = add i64 %200, -452
  %207 = add i64 %200, 15
  %208 = load i64, i64* %RSP, align 8, !tbaa !2428
  %209 = add i64 %208, -8
  %210 = inttoptr i64 %209 to i64*
  store i64 %207, i64* %210, align 8
  store i64 %209, i64* %RSP, align 8, !tbaa !2428
  store i64 %206, i64* %PC, align 8, !tbaa !2428
  %211 = tail call fastcc %struct.Memory* @ext_6050d0_memalign(%struct.State* nonnull %0, %struct.Memory* %188)
  %212 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 20480, i64* %RDX, align 8, !tbaa !2428
  store i64 20480, i64* %RSI, align 8, !tbaa !2428
  %213 = load i64, i64* %RBP, align 8
  %214 = add i64 %213, -24
  %215 = load i64, i64* %RAX, align 8
  %216 = add i64 %212, 18
  store i64 %216, i64* %PC, align 8
  %217 = inttoptr i64 %214 to i64*
  store i64 %215, i64* %217, align 8
  %218 = load i64, i64* %PC, align 8
  %219 = add i64 %218, -485
  %220 = add i64 %218, 5
  %221 = load i64, i64* %RSP, align 8, !tbaa !2428
  %222 = add i64 %221, -8
  %223 = inttoptr i64 %222 to i64*
  store i64 %220, i64* %223, align 8
  store i64 %222, i64* %RSP, align 8, !tbaa !2428
  store i64 %219, i64* %PC, align 8, !tbaa !2428
  %224 = tail call fastcc %struct.Memory* @ext_6050d0_memalign(%struct.State* nonnull %0, %struct.Memory* %211)
  %225 = load i64, i64* %PC, align 8
  store i64 512, i64* %RDI, align 8, !tbaa !2428
  %226 = load i64, i64* %RBP, align 8
  %227 = add i64 %226, -56
  %228 = load i64, i64* %RAX, align 8
  %229 = add i64 %225, 9
  store i64 %229, i64* %PC, align 8
  %230 = inttoptr i64 %227 to i64*
  store i64 %228, i64* %230, align 8
  %231 = load i64, i64* %RBP, align 8
  %232 = add i64 %231, -24
  %233 = load i64, i64* %PC, align 8
  %234 = add i64 %233, 4
  store i64 %234, i64* %PC, align 8
  %235 = inttoptr i64 %232 to i64*
  %236 = load i64, i64* %235, align 8
  store i64 %236, i64* %RSI, align 8, !tbaa !2428
  %237 = add i64 %231, -56
  %238 = add i64 %233, 8
  store i64 %238, i64* %PC, align 8
  %239 = inttoptr i64 %237 to i64*
  %240 = load i64, i64* %239, align 8
  store i64 %240, i64* %RDX, align 8, !tbaa !2428
  %241 = add i64 %233, 1357
  %242 = add i64 %233, 13
  %243 = load i64, i64* %RSP, align 8, !tbaa !2428
  %244 = add i64 %243, -8
  %245 = inttoptr i64 %244 to i64*
  store i64 %242, i64* %245, align 8
  store i64 %244, i64* %RSP, align 8, !tbaa !2428
  store i64 %241, i64* %PC, align 8, !tbaa !2428
  %246 = tail call %struct.Memory* @sub_400e70_makewt_renamed_(%struct.State* nonnull %0, i64 %241, %struct.Memory* %224)
  %247 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 16384, i64* %R8, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %248 = add i64 %247, -512
  %249 = add i64 %247, 19
  %250 = load i64, i64* %RSP, align 8, !tbaa !2428
  %251 = add i64 %250, -8
  %252 = inttoptr i64 %251 to i64*
  store i64 %249, i64* %252, align 8
  store i64 %251, i64* %RSP, align 8, !tbaa !2428
  store i64 %248, i64* %PC, align 8, !tbaa !2428
  %253 = tail call fastcc %struct.Memory* @ext_6050d0_memalign(%struct.State* nonnull %0, %struct.Memory* %246)
  %254 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 16384, i64* %R8, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %255 = load i64, i64* %RBP, align 8
  %256 = add i64 %255, -32
  %257 = load i64, i64* %RAX, align 8
  %258 = add i64 %254, 22
  store i64 %258, i64* %PC, align 8
  %259 = inttoptr i64 %256 to i64*
  store i64 %257, i64* %259, align 8
  %260 = load i64, i64* %PC, align 8
  %261 = add i64 %260, -553
  %262 = add i64 %260, 5
  %263 = load i64, i64* %RSP, align 8, !tbaa !2428
  %264 = add i64 %263, -8
  %265 = inttoptr i64 %264 to i64*
  store i64 %262, i64* %265, align 8
  store i64 %264, i64* %RSP, align 8, !tbaa !2428
  store i64 %261, i64* %PC, align 8, !tbaa !2428
  %266 = tail call fastcc %struct.Memory* @ext_6050d0_memalign(%struct.State* nonnull %0, %struct.Memory* %253)
  %267 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 16384, i64* %R8, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %268 = load i64, i64* %RBP, align 8
  %269 = add i64 %268, -40
  %270 = load i64, i64* %RAX, align 8
  %271 = add i64 %267, 22
  store i64 %271, i64* %PC, align 8
  %272 = inttoptr i64 %269 to i64*
  store i64 %270, i64* %272, align 8
  %273 = load i64, i64* %PC, align 8
  %274 = add i64 %273, -580
  %275 = add i64 %273, 5
  %276 = load i64, i64* %RSP, align 8, !tbaa !2428
  %277 = add i64 %276, -8
  %278 = inttoptr i64 %277 to i64*
  store i64 %275, i64* %278, align 8
  store i64 %277, i64* %RSP, align 8, !tbaa !2428
  store i64 %274, i64* %PC, align 8, !tbaa !2428
  %279 = tail call fastcc %struct.Memory* @ext_6050d0_memalign(%struct.State* nonnull %0, %struct.Memory* %266)
  %280 = load i64, i64* %PC, align 8
  store i64 0, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  store i8 1, i8* %25, align 1, !tbaa !2446
  store i8 1, i8* %33, align 1, !tbaa !2448
  store i8 0, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i64 2047, i64* %RSI, align 8, !tbaa !2428
  %281 = load i64, i64* %RBP, align 8
  %282 = add i64 %281, -48
  %283 = load i64, i64* %RAX, align 8
  %284 = add i64 %280, 11
  store i64 %284, i64* %PC, align 8
  %285 = inttoptr i64 %282 to i64*
  store i64 %283, i64* %285, align 8
  %286 = load i64, i64* %RBP, align 8
  %287 = add i64 %286, -32
  %288 = load i64, i64* %PC, align 8
  %289 = add i64 %288, 4
  store i64 %289, i64* %PC, align 8
  %290 = inttoptr i64 %287 to i64*
  %291 = load i64, i64* %290, align 8
  store i64 %291, i64* %RDX, align 8, !tbaa !2428
  %292 = add i64 %288, 1628
  %293 = add i64 %288, 9
  %294 = load i64, i64* %RSP, align 8, !tbaa !2428
  %295 = add i64 %294, -8
  %296 = inttoptr i64 %295 to i64*
  store i64 %293, i64* %296, align 8
  store i64 %295, i64* %RSP, align 8, !tbaa !2428
  store i64 %292, i64* %PC, align 8, !tbaa !2428
  %297 = tail call %struct.Memory* @sub_400fe0_putdata_renamed_(%struct.State* nonnull %0, i64 %292, %struct.Memory* %279)
  %298 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  %299 = load i64, i64* %RBP, align 8
  %300 = add i64 %299, -32
  %301 = add i64 %298, 14
  store i64 %301, i64* %PC, align 8
  %302 = inttoptr i64 %300 to i64*
  %303 = load i64, i64* %302, align 8
  store i64 %303, i64* %RDX, align 8, !tbaa !2428
  %304 = add i64 %299, -24
  %305 = add i64 %298, 18
  store i64 %305, i64* %PC, align 8
  %306 = inttoptr i64 %304 to i64*
  %307 = load i64, i64* %306, align 8
  store i64 %307, i64* %RCX, align 8, !tbaa !2428
  %308 = add i64 %299, -56
  %309 = add i64 %298, 22
  store i64 %309, i64* %PC, align 8
  %310 = inttoptr i64 %308 to i64*
  %311 = load i64, i64* %310, align 8
  store i64 %311, i64* %R8, align 8, !tbaa !2428
  %312 = add i64 %298, 1747
  %313 = add i64 %298, 27
  %314 = load i64, i64* %RSP, align 8, !tbaa !2428
  %315 = add i64 %314, -8
  %316 = inttoptr i64 %315 to i64*
  store i64 %313, i64* %316, align 8
  store i64 %315, i64* %RSP, align 8, !tbaa !2428
  store i64 %312, i64* %PC, align 8, !tbaa !2428
  %317 = tail call %struct.Memory* @sub_401060_cdft_renamed_(%struct.State* nonnull %0, i64 %312, %struct.Memory* %297)
  %318 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 4294967295, i64* %RSI, align 8, !tbaa !2428
  %319 = load i64, i64* %RBP, align 8
  %320 = add i64 %319, -32
  %321 = add i64 %318, 14
  store i64 %321, i64* %PC, align 8
  %322 = inttoptr i64 %320 to i64*
  %323 = load i64, i64* %322, align 8
  store i64 %323, i64* %RDX, align 8, !tbaa !2428
  %324 = add i64 %319, -24
  %325 = add i64 %318, 18
  store i64 %325, i64* %PC, align 8
  %326 = inttoptr i64 %324 to i64*
  %327 = load i64, i64* %326, align 8
  store i64 %327, i64* %RCX, align 8, !tbaa !2428
  %328 = add i64 %319, -56
  %329 = add i64 %318, 22
  store i64 %329, i64* %PC, align 8
  %330 = inttoptr i64 %328 to i64*
  %331 = load i64, i64* %330, align 8
  store i64 %331, i64* %R8, align 8, !tbaa !2428
  %332 = add i64 %318, 1720
  %333 = add i64 %318, 27
  %334 = load i64, i64* %RSP, align 8, !tbaa !2428
  %335 = add i64 %334, -8
  %336 = inttoptr i64 %335 to i64*
  store i64 %333, i64* %336, align 8
  store i64 %335, i64* %RSP, align 8, !tbaa !2428
  store i64 %332, i64* %PC, align 8, !tbaa !2428
  %337 = tail call %struct.Memory* @sub_401060_cdft_renamed_(%struct.State* nonnull %0, i64 %332, %struct.Memory* %317)
  %338 = load i64, i64* %PC, align 8
  store i64 0, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  store i8 1, i8* %25, align 1, !tbaa !2446
  store i8 1, i8* %33, align 1, !tbaa !2448
  store i8 0, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i64 2047, i64* %RSI, align 8, !tbaa !2428
  %339 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 16) to i64*), align 16
  store i64 %339, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %340 = load i64, i64* %RBP, align 8
  %341 = add i64 %340, -32
  %342 = add i64 %338, 19
  store i64 %342, i64* %PC, align 8
  %343 = inttoptr i64 %341 to i64*
  %344 = load i64, i64* %343, align 8
  store i64 %344, i64* %RDX, align 8, !tbaa !2428
  %345 = add i64 %338, 1853
  %346 = add i64 %338, 24
  %347 = load i64, i64* %RSP, align 8, !tbaa !2428
  %348 = add i64 %347, -8
  %349 = inttoptr i64 %348 to i64*
  store i64 %346, i64* %349, align 8
  store i64 %348, i64* %RSP, align 8, !tbaa !2428
  store i64 %345, i64* %PC, align 8, !tbaa !2428
  %350 = tail call %struct.Memory* @sub_401100_errorcheck_renamed_(%struct.State* nonnull %0, i64 %345, %struct.Memory* %337)
  %351 = load i64, i64* %PC, align 8
  %352 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 8) to i64*), align 8
  store i64 %352, i64* %100, align 1, !tbaa !2451
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  %353 = load i64, i64* %RBP, align 8
  %354 = add i64 %353, -96
  %355 = add i64 %351, 13
  store i64 %355, i64* %PC, align 8
  %356 = load i64, i64* %69, align 1
  %357 = inttoptr i64 %354 to i64*
  store i64 %356, i64* %357, align 8
  %358 = load i64, i64* %RBP, align 8
  %359 = add i64 %358, -96
  %360 = load i64, i64* %PC, align 8
  %361 = add i64 %360, 5
  store i64 %361, i64* %PC, align 8
  %362 = inttoptr i64 %359 to i64*
  %363 = load i64, i64* %362, align 8
  %364 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 96) to i32*), align 16
  %365 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 100) to i32*), align 4
  %366 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 104) to i32*), align 8
  %367 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 108) to i32*), align 4
  store i32 %364, i32* %127, align 1, !tbaa !2475
  store i32 %365, i32* %130, align 1, !tbaa !2475
  store i32 %366, i32* %132, align 1, !tbaa !2475
  store i32 %367, i32* %134, align 1, !tbaa !2475
  %368 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %7, i64 0, i32 0, i32 0, i32 0, i64 0
  %369 = load i64, i64* %368, align 1
  %370 = and i64 %369, %363
  %371 = trunc i64 %370 to i32
  %372 = lshr i64 %370, 32
  %373 = trunc i64 %372 to i32
  %374 = bitcast [32 x %union.VectorReg]* %5 to i32*
  store i32 %371, i32* %374, align 1, !tbaa !2469
  %375 = getelementptr inbounds i8, i8* %85, i64 4
  %376 = bitcast i8* %375 to i32*
  store i32 %373, i32* %376, align 1, !tbaa !2469
  %377 = bitcast i64* %92 to i32*
  store i32 0, i32* %377, align 1, !tbaa !2469
  %378 = getelementptr inbounds i8, i8* %85, i64 12
  %379 = bitcast i8* %378 to i32*
  store i32 0, i32* %379, align 1, !tbaa !2469
  %380 = add i64 %360, 20
  store i64 %380, i64* %PC, align 8
  %381 = load double, double* %68, align 1
  %382 = load double, double* %99, align 1
  %383 = fcmp uno double %381, %382
  br i1 %383, label %384, label %394

; <label>:384:                                    ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3
  %385 = fadd double %381, %382
  %386 = bitcast double %385 to i64
  %387 = and i64 %386, 9221120237041090560
  %388 = icmp eq i64 %387, 9218868437227405312
  %389 = and i64 %386, 2251799813685247
  %390 = icmp ne i64 %389, 0
  %391 = and i1 %388, %390
  br i1 %391, label %392, label %400

; <label>:392:                                    ; preds = %384
  %393 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %380, %struct.Memory* %350) #16
  %.pre74 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2

; <label>:394:                                    ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3
  %395 = fcmp ogt double %381, %382
  br i1 %395, label %400, label %396

; <label>:396:                                    ; preds = %394
  %397 = fcmp olt double %381, %382
  br i1 %397, label %400, label %398

; <label>:398:                                    ; preds = %396
  %399 = fcmp oeq double %381, %382
  br i1 %399, label %400, label %404

; <label>:400:                                    ; preds = %398, %396, %394, %384
  %401 = phi i8 [ 0, %394 ], [ 0, %396 ], [ 1, %398 ], [ 1, %384 ]
  %402 = phi i8 [ 0, %394 ], [ 0, %396 ], [ 0, %398 ], [ 1, %384 ]
  %403 = phi i8 [ 0, %394 ], [ 1, %396 ], [ 0, %398 ], [ 1, %384 ]
  store i8 %401, i8* %33, align 1, !tbaa !2453
  store i8 %402, i8* %25, align 1, !tbaa !2453
  store i8 %403, i8* %18, align 1, !tbaa !2453
  br label %404

; <label>:404:                                    ; preds = %400, %398
  store i8 0, i8* %42, align 1, !tbaa !2453
  store i8 0, i8* %36, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2: ; preds = %404, %392
  %405 = phi i64 [ %.pre74, %392 ], [ %380, %404 ]
  %406 = phi %struct.Memory* [ %393, %392 ], [ %350, %404 ]
  %407 = load i8, i8* %18, align 1, !tbaa !2432
  %408 = load i8, i8* %33, align 1, !tbaa !2448
  %409 = or i8 %408, %407
  %410 = icmp ne i8 %409, 0
  %.v97 = select i1 %410, i64 39, i64 6
  %411 = add i64 %405, %.v97
  store i64 %411, i64* %PC, align 8, !tbaa !2428
  br i1 %410, label %block_400a23, label %block_400a02

block_400cf3:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1
  %412 = load i64, i64* %RBP, align 8
  %413 = add i64 %412, -40
  %414 = add i64 %749, 4
  store i64 %414, i64* %PC, align 8
  %415 = inttoptr i64 %413 to i64*
  %416 = load i64, i64* %415, align 8
  store i64 %416, i64* %RAX, align 8, !tbaa !2428
  %417 = add i64 %412, -12
  %418 = add i64 %749, 7
  store i64 %418, i64* %PC, align 8
  %419 = inttoptr i64 %417 to i32*
  %420 = load i32, i32* %419, align 4
  %421 = shl i32 %420, 1
  %422 = icmp slt i32 %420, 0
  %423 = icmp slt i32 %421, 0
  %424 = xor i1 %422, %423
  %425 = zext i32 %421 to i64
  store i64 %425, i64* %RCX, align 8, !tbaa !2428
  %.lobit62 = lshr i32 %420, 31
  %426 = trunc i32 %.lobit62 to i8
  store i8 %426, i8* %18, align 1, !tbaa !2453
  %427 = and i32 %421, 254
  %428 = tail call i32 @llvm.ctpop.i32(i32 %427) #14
  %429 = trunc i32 %428 to i8
  %430 = and i8 %429, 1
  %431 = xor i8 %430, 1
  store i8 %431, i8* %25, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  %432 = icmp eq i32 %421, 0
  %433 = zext i1 %432 to i8
  store i8 %433, i8* %33, align 1, !tbaa !2453
  %434 = lshr i32 %420, 30
  %435 = trunc i32 %434 to i8
  %436 = and i8 %435, 1
  store i8 %436, i8* %36, align 1, !tbaa !2453
  %437 = zext i1 %424 to i8
  store i8 %437, i8* %42, align 1, !tbaa !2453
  %438 = sext i32 %421 to i64
  store i64 %438, i64* %RDX, align 8, !tbaa !2428
  %439 = shl nsw i64 %438, 3
  %440 = add i64 %416, %439
  %441 = add i64 %749, 18
  store i64 %441, i64* %PC, align 8
  %442 = inttoptr i64 %440 to i64*
  %443 = load i64, i64* %442, align 8
  store i64 %443, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  br label %block_400d22

block_400c64:                                     ; preds = %block_400b87
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 4294967295, i64* %RSI, align 8, !tbaa !2428
  %444 = add i64 %1449, -40
  %445 = add i64 %1477, 14
  store i64 %445, i64* %PC, align 8
  %446 = inttoptr i64 %444 to i64*
  %447 = load i64, i64* %446, align 8
  store i64 %447, i64* %RDX, align 8, !tbaa !2428
  %448 = add i64 %1449, -24
  %449 = add i64 %1477, 18
  store i64 %449, i64* %PC, align 8
  %450 = inttoptr i64 %448 to i64*
  %451 = load i64, i64* %450, align 8
  store i64 %451, i64* %RCX, align 8, !tbaa !2428
  %452 = add i64 %1449, -56
  %453 = add i64 %1477, 22
  store i64 %453, i64* %PC, align 8
  %454 = inttoptr i64 %452 to i64*
  %455 = load i64, i64* %454, align 8
  store i64 %455, i64* %R8, align 8, !tbaa !2428
  %456 = add i64 %1477, 1020
  %457 = add i64 %1477, 27
  %458 = load i64, i64* %RSP, align 8, !tbaa !2428
  %459 = add i64 %458, -8
  %460 = inttoptr i64 %459 to i64*
  store i64 %457, i64* %460, align 8
  store i64 %459, i64* %RSP, align 8, !tbaa !2428
  store i64 %456, i64* %PC, align 8, !tbaa !2428
  %461 = tail call %struct.Memory* @sub_401060_cdft_renamed_(%struct.State* nonnull %0, i64 %456, %struct.Memory* %671)
  %462 = load i64, i64* %RBP, align 8
  %463 = add i64 %462, -8
  %464 = load i64, i64* %PC, align 8
  %465 = add i64 %464, 3
  store i64 %465, i64* %PC, align 8
  %466 = inttoptr i64 %463 to i32*
  %467 = load i32, i32* %466, align 4
  %468 = add i32 %467, 1
  %469 = zext i32 %468 to i64
  store i64 %469, i64* %RAX, align 8, !tbaa !2428
  %470 = icmp eq i32 %467, -1
  %471 = icmp eq i32 %468, 0
  %472 = or i1 %470, %471
  %473 = zext i1 %472 to i8
  store i8 %473, i8* %18, align 1, !tbaa !2432
  %474 = and i32 %468, 255
  %475 = tail call i32 @llvm.ctpop.i32(i32 %474) #14
  %476 = trunc i32 %475 to i8
  %477 = and i8 %476, 1
  %478 = xor i8 %477, 1
  store i8 %478, i8* %25, align 1, !tbaa !2446
  %479 = xor i32 %468, %467
  %480 = lshr i32 %479, 4
  %481 = trunc i32 %480 to i8
  %482 = and i8 %481, 1
  store i8 %482, i8* %30, align 1, !tbaa !2447
  %483 = zext i1 %471 to i8
  store i8 %483, i8* %33, align 1, !tbaa !2448
  %484 = lshr i32 %468, 31
  %485 = trunc i32 %484 to i8
  store i8 %485, i8* %36, align 1, !tbaa !2449
  %486 = lshr i32 %467, 31
  %487 = xor i32 %484, %486
  %488 = add nuw nsw i32 %487, %484
  %489 = icmp eq i32 %488, 2
  %490 = zext i1 %489 to i8
  store i8 %490, i8* %42, align 1, !tbaa !2450
  %491 = add i64 %464, 9
  store i64 %491, i64* %PC, align 8
  store i32 %468, i32* %466, align 4
  %492 = load i64, i64* %PC, align 8
  %493 = add i64 %492, -354
  store i64 %493, i64* %PC, align 8, !tbaa !2428
  br label %block_400b26

block_400dde:                                     ; preds = %block_400cb7
  %494 = add i64 %1479, -32
  %495 = add i64 %1507, 4
  store i64 %495, i64* %PC, align 8
  %496 = inttoptr i64 %494 to i64*
  %497 = load i64, i64* %496, align 8
  store i64 %497, i64* %RAX, align 8, !tbaa !2428
  store i64 %497, i64* %RDI, align 8, !tbaa !2428
  %498 = add i64 %1507, -1838
  %499 = add i64 %1507, 12
  %500 = load i64, i64* %RSP, align 8, !tbaa !2428
  %501 = add i64 %500, -8
  %502 = inttoptr i64 %501 to i64*
  store i64 %499, i64* %502, align 8
  store i64 %501, i64* %RSP, align 8, !tbaa !2428
  store i64 %498, i64* %PC, align 8, !tbaa !2428
  %503 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %MEMORY.5)
  %504 = load i64, i64* %RBP, align 8
  %505 = add i64 %504, -56
  %506 = load i64, i64* %PC, align 8
  %507 = add i64 %506, 4
  store i64 %507, i64* %PC, align 8
  %508 = inttoptr i64 %505 to i64*
  %509 = load i64, i64* %508, align 8
  store i64 %509, i64* %RAX, align 8, !tbaa !2428
  store i64 %509, i64* %RDI, align 8, !tbaa !2428
  %510 = add i64 %506, -1850
  %511 = add i64 %506, 12
  %512 = load i64, i64* %RSP, align 8, !tbaa !2428
  %513 = add i64 %512, -8
  %514 = inttoptr i64 %513 to i64*
  store i64 %511, i64* %514, align 8
  store i64 %513, i64* %RSP, align 8, !tbaa !2428
  store i64 %510, i64* %PC, align 8, !tbaa !2428
  %515 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %503)
  %516 = load i64, i64* %RBP, align 8
  %517 = add i64 %516, -24
  %518 = load i64, i64* %PC, align 8
  %519 = add i64 %518, 4
  store i64 %519, i64* %PC, align 8
  %520 = inttoptr i64 %517 to i64*
  %521 = load i64, i64* %520, align 8
  store i64 %521, i64* %RAX, align 8, !tbaa !2428
  store i64 %521, i64* %RDI, align 8, !tbaa !2428
  %522 = add i64 %518, -1862
  %523 = add i64 %518, 12
  %524 = load i64, i64* %RSP, align 8, !tbaa !2428
  %525 = add i64 %524, -8
  %526 = inttoptr i64 %525 to i64*
  store i64 %523, i64* %526, align 8
  store i64 %525, i64* %RSP, align 8, !tbaa !2428
  store i64 %522, i64* %PC, align 8, !tbaa !2428
  %527 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %515)
  %528 = load i64, i64* %RBP, align 8
  %529 = add i64 %528, -40
  %530 = load i64, i64* %PC, align 8
  %531 = add i64 %530, 4
  store i64 %531, i64* %PC, align 8
  %532 = inttoptr i64 %529 to i64*
  %533 = load i64, i64* %532, align 8
  store i64 %533, i64* %RAX, align 8, !tbaa !2428
  store i64 %533, i64* %RDI, align 8, !tbaa !2428
  %534 = add i64 %530, -1874
  %535 = add i64 %530, 12
  %536 = load i64, i64* %RSP, align 8, !tbaa !2428
  %537 = add i64 %536, -8
  %538 = inttoptr i64 %537 to i64*
  store i64 %535, i64* %538, align 8
  store i64 %537, i64* %RSP, align 8, !tbaa !2428
  store i64 %534, i64* %PC, align 8, !tbaa !2428
  %539 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %527)
  %540 = load i64, i64* %RBP, align 8
  %541 = add i64 %540, -48
  %542 = load i64, i64* %PC, align 8
  %543 = add i64 %542, 4
  store i64 %543, i64* %PC, align 8
  %544 = inttoptr i64 %541 to i64*
  %545 = load i64, i64* %544, align 8
  store i64 %545, i64* %RAX, align 8, !tbaa !2428
  store i64 %545, i64* %RDI, align 8, !tbaa !2428
  %546 = add i64 %542, -1886
  %547 = add i64 %542, 12
  %548 = load i64, i64* %RSP, align 8, !tbaa !2428
  %549 = add i64 %548, -8
  %550 = inttoptr i64 %549 to i64*
  store i64 %547, i64* %550, align 8
  store i64 %549, i64* %RSP, align 8, !tbaa !2428
  store i64 %546, i64* %PC, align 8, !tbaa !2428
  %551 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %539)
  %552 = load i64, i64* %PC, align 8
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  %553 = load i64, i64* %RSP, align 8
  %554 = add i64 %553, 224
  store i64 %554, i64* %RSP, align 8, !tbaa !2428
  %555 = icmp ugt i64 %553, -225
  %556 = zext i1 %555 to i8
  store i8 %556, i8* %18, align 1, !tbaa !2432
  %557 = trunc i64 %554 to i32
  %558 = and i32 %557, 255
  %559 = tail call i32 @llvm.ctpop.i32(i32 %558) #14
  %560 = trunc i32 %559 to i8
  %561 = and i8 %560, 1
  %562 = xor i8 %561, 1
  store i8 %562, i8* %25, align 1, !tbaa !2446
  %563 = xor i64 %554, %553
  %564 = lshr i64 %563, 4
  %565 = trunc i64 %564 to i8
  %566 = and i8 %565, 1
  store i8 %566, i8* %30, align 1, !tbaa !2447
  %567 = icmp eq i64 %554, 0
  %568 = zext i1 %567 to i8
  store i8 %568, i8* %33, align 1, !tbaa !2448
  %569 = lshr i64 %554, 63
  %570 = trunc i64 %569 to i8
  store i8 %570, i8* %36, align 1, !tbaa !2449
  %571 = lshr i64 %553, 63
  %572 = xor i64 %569, %571
  %573 = add nuw nsw i64 %572, %569
  %574 = icmp eq i64 %573, 2
  %575 = zext i1 %574 to i8
  store i8 %575, i8* %42, align 1, !tbaa !2450
  %576 = add i64 %552, 10
  store i64 %576, i64* %PC, align 8
  %577 = add i64 %553, 232
  %578 = inttoptr i64 %554 to i64*
  %579 = load i64, i64* %578, align 8
  store i64 %579, i64* %RBP, align 8, !tbaa !2428
  store i64 %577, i64* %RSP, align 8, !tbaa !2428
  %580 = add i64 %552, 11
  store i64 %580, i64* %PC, align 8
  %581 = inttoptr i64 %577 to i64*
  %582 = load i64, i64* %581, align 8
  store i64 %582, i64* %PC, align 8, !tbaa !2428
  %583 = add i64 %553, 240
  store i64 %583, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %551

block_400d64:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %584 = load i64, i64* %RBP, align 8
  %585 = add i64 %584, -40
  %586 = add i64 %1032, 4
  store i64 %586, i64* %PC, align 8
  %587 = inttoptr i64 %585 to i64*
  %588 = load i64, i64* %587, align 8
  store i64 %588, i64* %RAX, align 8, !tbaa !2428
  %589 = add i64 %584, -12
  %590 = add i64 %1032, 7
  store i64 %590, i64* %PC, align 8
  %591 = inttoptr i64 %589 to i32*
  %592 = load i32, i32* %591, align 4
  %593 = shl i32 %592, 1
  %594 = or i32 %593, 1
  %595 = zext i32 %594 to i64
  store i64 %595, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %596 = and i32 %594, 255
  %597 = tail call i32 @llvm.ctpop.i32(i32 %596) #14
  %598 = trunc i32 %597 to i8
  %599 = and i8 %598, 1
  %600 = xor i8 %599, 1
  store i8 %600, i8* %25, align 1, !tbaa !2446
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i8 0, i8* %33, align 1, !tbaa !2448
  %601 = lshr i32 %592, 30
  %602 = and i32 %601, 1
  %603 = trunc i32 %602 to i8
  store i8 %603, i8* %36, align 1, !tbaa !2449
  %604 = lshr i32 %592, 30
  %605 = and i32 %604, 1
  %606 = xor i32 %602, %605
  %607 = add nuw nsw i32 %606, %602
  %608 = icmp eq i32 %607, 2
  %609 = zext i1 %608 to i8
  store i8 %609, i8* %42, align 1, !tbaa !2450
  %610 = sext i32 %594 to i64
  store i64 %610, i64* %RDX, align 8, !tbaa !2428
  %611 = shl nsw i64 %610, 3
  %612 = add i64 %588, %611
  %613 = add i64 %1032, 21
  store i64 %613, i64* %PC, align 8
  %614 = inttoptr i64 %612 to i64*
  %615 = load i64, i64* %614, align 8
  store i64 %615, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  br label %block_400d96

block_400b33:                                     ; preds = %block_400b26
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RAX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %616 = add i64 %751, -40
  %617 = add i64 %780, 21
  store i64 %617, i64* %PC, align 8
  %618 = inttoptr i64 %616 to i64*
  %619 = load i64, i64* %618, align 8
  store i64 %619, i64* %RCX, align 8, !tbaa !2428
  %620 = add i64 %751, -48
  %621 = add i64 %780, 25
  store i64 %621, i64* %PC, align 8
  %622 = inttoptr i64 %620 to i64*
  %623 = load i64, i64* %622, align 8
  store i64 %623, i64* %R8, align 8, !tbaa !2428
  %624 = add i64 %751, -176
  %625 = add i64 %780, 31
  store i64 %625, i64* %PC, align 8
  %626 = inttoptr i64 %624 to i32*
  store i32 2048, i32* %626, align 4
  %627 = load i64, i64* %RCX, align 8
  %628 = load i64, i64* %PC, align 8
  store i64 %627, i64* %RDI, align 8, !tbaa !2428
  %629 = load i64, i64* %RBP, align 8
  %630 = add i64 %629, -180
  %631 = load i32, i32* %ESI, align 4
  %632 = add i64 %628, 9
  store i64 %632, i64* %PC, align 8
  %633 = inttoptr i64 %630 to i32*
  store i32 %631, i32* %633, align 4
  %634 = load i64, i64* %R8, align 8
  %635 = load i64, i64* %PC, align 8
  store i64 %634, i64* %RSI, align 8, !tbaa !2428
  %636 = add i64 %635, -1083
  %637 = add i64 %635, 8
  %638 = load i64, i64* %RSP, align 8, !tbaa !2428
  %639 = add i64 %638, -8
  %640 = inttoptr i64 %639 to i64*
  store i64 %637, i64* %640, align 8
  store i64 %639, i64* %RSP, align 8, !tbaa !2428
  store i64 %636, i64* %PC, align 8, !tbaa !2428
  %641 = tail call fastcc %struct.Memory* @ext_605128_memcpy(%struct.State* nonnull %0, %struct.Memory* %MEMORY.0)
  %642 = load i64, i64* %RBP, align 8
  %643 = add i64 %642, -40
  %644 = load i64, i64* %PC, align 8
  %645 = add i64 %644, 4
  store i64 %645, i64* %PC, align 8
  %646 = inttoptr i64 %643 to i64*
  %647 = load i64, i64* %646, align 8
  store i64 %647, i64* %RDX, align 8, !tbaa !2428
  %648 = add i64 %642, -24
  %649 = add i64 %644, 8
  store i64 %649, i64* %PC, align 8
  %650 = inttoptr i64 %648 to i64*
  %651 = load i64, i64* %650, align 8
  store i64 %651, i64* %RCX, align 8, !tbaa !2428
  %652 = add i64 %642, -56
  %653 = add i64 %644, 12
  store i64 %653, i64* %PC, align 8
  %654 = inttoptr i64 %652 to i64*
  %655 = load i64, i64* %654, align 8
  store i64 %655, i64* %R8, align 8, !tbaa !2428
  %656 = add i64 %642, -176
  %657 = add i64 %644, 18
  store i64 %657, i64* %PC, align 8
  %658 = inttoptr i64 %656 to i32*
  %659 = load i32, i32* %658, align 4
  %660 = zext i32 %659 to i64
  store i64 %660, i64* %RDI, align 8, !tbaa !2428
  %661 = add i64 %642, -180
  %662 = add i64 %644, 24
  store i64 %662, i64* %PC, align 8
  %663 = inttoptr i64 %661 to i32*
  %664 = load i32, i32* %663, align 4
  %665 = zext i32 %664 to i64
  store i64 %665, i64* %RSI, align 8, !tbaa !2428
  %666 = add i64 %644, 1277
  %667 = add i64 %644, 29
  %668 = load i64, i64* %RSP, align 8, !tbaa !2428
  %669 = add i64 %668, -8
  %670 = inttoptr i64 %669 to i64*
  store i64 %667, i64* %670, align 8
  store i64 %669, i64* %RSP, align 8, !tbaa !2428
  store i64 %666, i64* %PC, align 8, !tbaa !2428
  %671 = tail call %struct.Memory* @sub_401060_cdft_renamed_(%struct.State* nonnull %0, i64 %666, %struct.Memory* %641)
  %672 = load i64, i64* %RBP, align 8
  %673 = add i64 %672, -100
  %674 = load i64, i64* %PC, align 8
  %675 = add i64 %674, 7
  store i64 %675, i64* %PC, align 8
  %676 = inttoptr i64 %673 to i32*
  store i32 0, i32* %676, align 4
  %.pre86 = load i64, i64* %PC, align 8
  br label %block_400b87

block_400cc4:                                     ; preds = %block_400cb7
  %677 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 48) to i64*), align 16
  store i64 %677, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %678 = add i64 %1479, -40
  %679 = add i64 %1507, 12
  store i64 %679, i64* %PC, align 8
  %680 = inttoptr i64 %678 to i64*
  %681 = load i64, i64* %680, align 8
  store i64 %681, i64* %RAX, align 8, !tbaa !2428
  %682 = add i64 %1507, 15
  store i64 %682, i64* %PC, align 8
  %683 = load i32, i32* %1482, align 4
  %684 = shl i32 %683, 1
  %685 = icmp slt i32 %683, 0
  %686 = icmp slt i32 %684, 0
  %687 = xor i1 %685, %686
  %688 = zext i32 %684 to i64
  store i64 %688, i64* %RCX, align 8, !tbaa !2428
  %.lobit61 = lshr i32 %683, 31
  %689 = trunc i32 %.lobit61 to i8
  store i8 %689, i8* %18, align 1, !tbaa !2453
  %690 = and i32 %684, 254
  %691 = tail call i32 @llvm.ctpop.i32(i32 %690) #14
  %692 = trunc i32 %691 to i8
  %693 = and i8 %692, 1
  %694 = xor i8 %693, 1
  store i8 %694, i8* %25, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  %695 = icmp eq i32 %684, 0
  %696 = zext i1 %695 to i8
  store i8 %696, i8* %33, align 1, !tbaa !2453
  %697 = lshr i32 %683, 30
  %698 = trunc i32 %697 to i8
  %699 = and i8 %698, 1
  store i8 %699, i8* %36, align 1, !tbaa !2453
  %700 = zext i1 %687 to i8
  store i8 %700, i8* %42, align 1, !tbaa !2453
  %701 = sext i32 %684 to i64
  store i64 %701, i64* %RDX, align 8, !tbaa !2428
  %702 = shl nsw i64 %701, 3
  %703 = add i64 %681, %702
  %704 = add i64 %1507, 26
  store i64 %704, i64* %PC, align 8
  %705 = inttoptr i64 %703 to i64*
  %706 = load i64, i64* %705, align 8
  %707 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 96) to i32*), align 16
  %708 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 100) to i32*), align 4
  %709 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 104) to i32*), align 8
  %710 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 108) to i32*), align 4
  store i32 %707, i32* %127, align 1, !tbaa !2475
  store i32 %708, i32* %130, align 1, !tbaa !2475
  store i32 %709, i32* %132, align 1, !tbaa !2475
  store i32 %710, i32* %134, align 1, !tbaa !2475
  %711 = load i64, i64* %368, align 1
  %712 = and i64 %711, %706
  %713 = trunc i64 %712 to i32
  %714 = lshr i64 %712, 32
  %715 = trunc i64 %714 to i32
  store i32 %713, i32* %1429, align 1, !tbaa !2469
  store i32 %715, i32* %1431, align 1, !tbaa !2469
  store i32 0, i32* %1432, align 1, !tbaa !2469
  store i32 0, i32* %1434, align 1, !tbaa !2469
  %716 = add i64 %1507, 41
  store i64 %716, i64* %PC, align 8
  %717 = load double, double* %99, align 1
  %718 = bitcast i64 %677 to double
  %719 = fcmp uno double %717, %718
  br i1 %719, label %720, label %730

; <label>:720:                                    ; preds = %block_400cc4
  %721 = fadd double %717, %718
  %722 = bitcast double %721 to i64
  %723 = and i64 %722, 9221120237041090560
  %724 = icmp eq i64 %723, 9218868437227405312
  %725 = and i64 %722, 2251799813685247
  %726 = icmp ne i64 %725, 0
  %727 = and i1 %724, %726
  br i1 %727, label %728, label %736

; <label>:728:                                    ; preds = %720
  %729 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %716, %struct.Memory* %MEMORY.5) #16
  %.pre78 = load i64, i64* %PC, align 8
  %.pre79 = load i8, i8* %18, align 1, !tbaa !2432
  %.pre80 = load i8, i8* %33, align 1, !tbaa !2448
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1

; <label>:730:                                    ; preds = %block_400cc4
  %731 = fcmp ogt double %717, %718
  br i1 %731, label %736, label %732

; <label>:732:                                    ; preds = %730
  %733 = fcmp olt double %717, %718
  br i1 %733, label %736, label %734

; <label>:734:                                    ; preds = %732
  %735 = fcmp oeq double %717, %718
  br i1 %735, label %736, label %740

; <label>:736:                                    ; preds = %734, %732, %730, %720
  %737 = phi i8 [ 0, %730 ], [ 0, %732 ], [ 1, %734 ], [ 1, %720 ]
  %738 = phi i8 [ 0, %730 ], [ 0, %732 ], [ 0, %734 ], [ 1, %720 ]
  %739 = phi i8 [ 0, %730 ], [ 1, %732 ], [ 0, %734 ], [ 1, %720 ]
  store i8 %737, i8* %33, align 1, !tbaa !2453
  store i8 %738, i8* %25, align 1, !tbaa !2453
  store i8 %739, i8* %18, align 1, !tbaa !2453
  br label %740

; <label>:740:                                    ; preds = %736, %734
  %741 = phi i8 [ %737, %736 ], [ %696, %734 ]
  %742 = phi i8 [ %739, %736 ], [ %689, %734 ]
  store i8 0, i8* %42, align 1, !tbaa !2453
  store i8 0, i8* %36, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1: ; preds = %740, %728
  %743 = phi i8 [ %.pre80, %728 ], [ %741, %740 ]
  %744 = phi i8 [ %.pre79, %728 ], [ %742, %740 ]
  %745 = phi i64 [ %.pre78, %728 ], [ %716, %740 ]
  %746 = phi %struct.Memory* [ %729, %728 ], [ %MEMORY.5, %740 ]
  %747 = or i8 %743, %744
  %748 = icmp ne i8 %747, 0
  %.v89 = select i1 %748, i64 37, i64 6
  %749 = add i64 %745, %.v89
  store i64 %749, i64* %PC, align 8, !tbaa !2428
  br i1 %748, label %block_400d12, label %block_400cf3

block_400b26:                                     ; preds = %block_400adb, %block_400c64
  %750 = phi i64 [ %.pre76, %block_400adb ], [ %493, %block_400c64 ]
  %MEMORY.0 = phi %struct.Memory* [ %860, %block_400adb ], [ %461, %block_400c64 ]
  %751 = load i64, i64* %RBP, align 8
  %752 = add i64 %751, -8
  %753 = add i64 %750, 7
  store i64 %753, i64* %PC, align 8
  %754 = inttoptr i64 %752 to i32*
  %755 = load i32, i32* %754, align 4
  %756 = add i32 %755, -150000
  %757 = icmp ult i32 %755, 150000
  %758 = zext i1 %757 to i8
  store i8 %758, i8* %18, align 1, !tbaa !2432
  %759 = and i32 %756, 255
  %760 = tail call i32 @llvm.ctpop.i32(i32 %759) #14
  %761 = trunc i32 %760 to i8
  %762 = and i8 %761, 1
  %763 = xor i8 %762, 1
  store i8 %763, i8* %25, align 1, !tbaa !2446
  %764 = xor i32 %755, 16
  %765 = xor i32 %764, %756
  %766 = lshr i32 %765, 4
  %767 = trunc i32 %766 to i8
  %768 = and i8 %767, 1
  store i8 %768, i8* %30, align 1, !tbaa !2447
  %769 = icmp eq i32 %756, 0
  %770 = zext i1 %769 to i8
  store i8 %770, i8* %33, align 1, !tbaa !2448
  %771 = lshr i32 %756, 31
  %772 = trunc i32 %771 to i8
  store i8 %772, i8* %36, align 1, !tbaa !2449
  %773 = lshr i32 %755, 31
  %774 = xor i32 %771, %773
  %775 = add nuw nsw i32 %774, %773
  %776 = icmp eq i32 %775, 2
  %777 = zext i1 %776 to i8
  store i8 %777, i8* %42, align 1, !tbaa !2450
  %778 = icmp ne i8 %772, 0
  %779 = xor i1 %778, %776
  %.v87 = select i1 %779, i64 13, i64 359
  %780 = add i64 %750, %.v87
  store i64 %780, i64* %PC, align 8, !tbaa !2428
  br i1 %779, label %block_400b33, label %block_400c8d

block_400a7f:                                     ; preds = %block_400a8c, %block_400a23
  %781 = phi i64 [ %1611, %block_400a8c ], [ %.pre75, %block_400a23 ]
  %782 = load i64, i64* %RBP, align 8
  %783 = add i64 %782, -12
  %784 = add i64 %781, 7
  store i64 %784, i64* %PC, align 8
  %785 = inttoptr i64 %783 to i32*
  %786 = load i32, i32* %785, align 4
  %787 = add i32 %786, -1024
  %788 = icmp ult i32 %786, 1024
  %789 = zext i1 %788 to i8
  store i8 %789, i8* %18, align 1, !tbaa !2432
  %790 = and i32 %787, 255
  %791 = tail call i32 @llvm.ctpop.i32(i32 %790) #14
  %792 = trunc i32 %791 to i8
  %793 = and i8 %792, 1
  %794 = xor i8 %793, 1
  store i8 %794, i8* %25, align 1, !tbaa !2446
  %795 = xor i32 %787, %786
  %796 = lshr i32 %795, 4
  %797 = trunc i32 %796 to i8
  %798 = and i8 %797, 1
  store i8 %798, i8* %30, align 1, !tbaa !2447
  %799 = icmp eq i32 %787, 0
  %800 = zext i1 %799 to i8
  store i8 %800, i8* %33, align 1, !tbaa !2448
  %801 = lshr i32 %787, 31
  %802 = trunc i32 %801 to i8
  store i8 %802, i8* %36, align 1, !tbaa !2449
  %803 = lshr i32 %786, 31
  %804 = xor i32 %801, %803
  %805 = add nuw nsw i32 %804, %803
  %806 = icmp eq i32 %805, 2
  %807 = zext i1 %806 to i8
  store i8 %807, i8* %42, align 1, !tbaa !2450
  %808 = icmp ne i8 %802, 0
  %809 = xor i1 %808, %806
  %.v = select i1 %809, i64 13, i64 92
  %810 = add i64 %781, %.v
  store i64 %810, i64* %PC, align 8, !tbaa !2428
  br i1 %809, label %block_400a8c, label %block_400adb

block_400adb:                                     ; preds = %block_400a7f
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  store i8 1, i8* %25, align 1, !tbaa !2446
  store i8 1, i8* %33, align 1, !tbaa !2448
  store i8 0, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i64 1023, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RCX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %811 = add i64 %782, -48
  %812 = add i64 %810, 18
  store i64 %812, i64* %PC, align 8
  %813 = inttoptr i64 %811 to i64*
  %814 = load i64, i64* %813, align 8
  store i64 %814, i64* %RDI, align 8, !tbaa !2428
  %815 = add i64 %782, -168
  %816 = add i64 %810, 24
  store i64 %816, i64* %PC, align 8
  %817 = inttoptr i64 %815 to i32*
  store i32 1023, i32* %817, align 4
  %818 = load i32, i32* %EAX, align 4
  %819 = zext i32 %818 to i64
  %820 = load i64, i64* %PC, align 8
  store i64 %819, i64* %RSI, align 8, !tbaa !2428
  %821 = load i64, i64* %RBP, align 8
  %822 = add i64 %821, -172
  %823 = add i64 %820, 8
  store i64 %823, i64* %PC, align 8
  %824 = inttoptr i64 %822 to i32*
  store i32 %818, i32* %824, align 4
  %825 = load i64, i64* %PC, align 8
  %826 = add i64 %825, -1019
  %827 = add i64 %825, 5
  %828 = load i64, i64* %RSP, align 8, !tbaa !2428
  %829 = add i64 %828, -8
  %830 = inttoptr i64 %829 to i64*
  store i64 %827, i64* %830, align 8
  store i64 %829, i64* %RSP, align 8, !tbaa !2428
  store i64 %826, i64* %PC, align 8, !tbaa !2428
  %831 = tail call fastcc %struct.Memory* @ext_605110_memset(%struct.State* nonnull %0, %struct.Memory* %935)
  %832 = load i64, i64* %RBP, align 8
  %833 = add i64 %832, -48
  %834 = load i64, i64* %PC, align 8
  %835 = add i64 %834, 4
  store i64 %835, i64* %PC, align 8
  %836 = inttoptr i64 %833 to i64*
  %837 = load i64, i64* %836, align 8
  store i64 %837, i64* %RDX, align 8, !tbaa !2428
  %838 = add i64 %832, -172
  %839 = add i64 %834, 10
  store i64 %839, i64* %PC, align 8
  %840 = inttoptr i64 %838 to i32*
  %841 = load i32, i32* %840, align 4
  %842 = zext i32 %841 to i64
  store i64 %842, i64* %RDI, align 8, !tbaa !2428
  %843 = add i64 %832, -168
  %844 = add i64 %834, 16
  store i64 %844, i64* %PC, align 8
  %845 = inttoptr i64 %843 to i32*
  %846 = load i32, i32* %845, align 4
  %847 = zext i32 %846 to i64
  store i64 %847, i64* %RSI, align 8, !tbaa !2428
  %848 = add i64 %834, 1248
  %849 = add i64 %834, 21
  %850 = load i64, i64* %RSP, align 8, !tbaa !2428
  %851 = add i64 %850, -8
  %852 = inttoptr i64 %851 to i64*
  store i64 %849, i64* %852, align 8
  store i64 %851, i64* %RSP, align 8, !tbaa !2428
  store i64 %848, i64* %PC, align 8, !tbaa !2428
  %853 = tail call %struct.Memory* @sub_400fe0_putdata_renamed_(%struct.State* nonnull %0, i64 %848, %struct.Memory* %831)
  %854 = load i64, i64* %PC, align 8
  %855 = add i64 %854, 795
  %856 = add i64 %854, 5
  %857 = load i64, i64* %RSP, align 8, !tbaa !2428
  %858 = add i64 %857, -8
  %859 = inttoptr i64 %858 to i64*
  store i64 %856, i64* %859, align 8
  store i64 %858, i64* %RSP, align 8, !tbaa !2428
  store i64 %855, i64* %PC, align 8, !tbaa !2428
  %860 = tail call %struct.Memory* @sub_400e30_get_time_renamed_(%struct.State* nonnull %0, i64 %855, %struct.Memory* %853)
  %861 = load i64, i64* %RBP, align 8
  %862 = add i64 %861, -64
  %863 = load i64, i64* %PC, align 8
  %864 = add i64 %863, 5
  store i64 %864, i64* %PC, align 8
  %865 = load i64, i64* %69, align 1
  %866 = inttoptr i64 %862 to i64*
  store i64 %865, i64* %866, align 8
  %867 = load i64, i64* %RBP, align 8
  %868 = add i64 %867, -8
  %869 = load i64, i64* %PC, align 8
  %870 = add i64 %869, 7
  store i64 %870, i64* %PC, align 8
  %871 = inttoptr i64 %868 to i32*
  store i32 0, i32* %871, align 4
  %.pre76 = load i64, i64* %PC, align 8
  br label %block_400b26

block_400a23:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  store i8 1, i8* %25, align 1, !tbaa !2446
  store i8 1, i8* %33, align 1, !tbaa !2448
  store i8 0, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i64 1023, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RCX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %872 = load i64, i64* %RBP, align 8
  %873 = add i64 %872, -32
  %874 = add i64 %411, 18
  store i64 %874, i64* %PC, align 8
  %875 = inttoptr i64 %873 to i64*
  %876 = load i64, i64* %875, align 8
  store i64 %876, i64* %RDI, align 8, !tbaa !2428
  %877 = add i64 %872, -160
  %878 = add i64 %411, 24
  store i64 %878, i64* %PC, align 8
  %879 = inttoptr i64 %877 to i32*
  store i32 1023, i32* %879, align 4
  %880 = load i32, i32* %EAX, align 4
  %881 = zext i32 %880 to i64
  %882 = load i64, i64* %PC, align 8
  store i64 %881, i64* %RSI, align 8, !tbaa !2428
  %883 = load i64, i64* %RBP, align 8
  %884 = add i64 %883, -164
  %885 = add i64 %882, 8
  store i64 %885, i64* %PC, align 8
  %886 = inttoptr i64 %884 to i32*
  store i32 %880, i32* %886, align 4
  %887 = load i64, i64* %PC, align 8
  %888 = add i64 %887, -835
  %889 = add i64 %887, 5
  %890 = load i64, i64* %RSP, align 8, !tbaa !2428
  %891 = add i64 %890, -8
  %892 = inttoptr i64 %891 to i64*
  store i64 %889, i64* %892, align 8
  store i64 %891, i64* %RSP, align 8, !tbaa !2428
  store i64 %888, i64* %PC, align 8, !tbaa !2428
  %893 = tail call fastcc %struct.Memory* @ext_605110_memset(%struct.State* nonnull %0, %struct.Memory* %406)
  %894 = load i64, i64* %RBP, align 8
  %895 = add i64 %894, -32
  %896 = load i64, i64* %PC, align 8
  %897 = add i64 %896, 4
  store i64 %897, i64* %PC, align 8
  %898 = inttoptr i64 %895 to i64*
  %899 = load i64, i64* %898, align 8
  store i64 %899, i64* %RDX, align 8, !tbaa !2428
  %900 = add i64 %894, -164
  %901 = add i64 %896, 10
  store i64 %901, i64* %PC, align 8
  %902 = inttoptr i64 %900 to i32*
  %903 = load i32, i32* %902, align 4
  %904 = zext i32 %903 to i64
  store i64 %904, i64* %RDI, align 8, !tbaa !2428
  %905 = add i64 %894, -160
  %906 = add i64 %896, 16
  store i64 %906, i64* %PC, align 8
  %907 = inttoptr i64 %905 to i32*
  %908 = load i32, i32* %907, align 4
  %909 = zext i32 %908 to i64
  store i64 %909, i64* %RSI, align 8, !tbaa !2428
  %910 = add i64 %896, 1432
  %911 = add i64 %896, 21
  %912 = load i64, i64* %RSP, align 8, !tbaa !2428
  %913 = add i64 %912, -8
  %914 = inttoptr i64 %913 to i64*
  store i64 %911, i64* %914, align 8
  store i64 %913, i64* %RSP, align 8, !tbaa !2428
  store i64 %910, i64* %PC, align 8, !tbaa !2428
  %915 = tail call %struct.Memory* @sub_400fe0_putdata_renamed_(%struct.State* nonnull %0, i64 %910, %struct.Memory* %893)
  %916 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  %917 = load i64, i64* %RBP, align 8
  %918 = add i64 %917, -32
  %919 = add i64 %916, 14
  store i64 %919, i64* %PC, align 8
  %920 = inttoptr i64 %918 to i64*
  %921 = load i64, i64* %920, align 8
  store i64 %921, i64* %RDX, align 8, !tbaa !2428
  %922 = add i64 %917, -24
  %923 = add i64 %916, 18
  store i64 %923, i64* %PC, align 8
  %924 = inttoptr i64 %922 to i64*
  %925 = load i64, i64* %924, align 8
  store i64 %925, i64* %RCX, align 8, !tbaa !2428
  %926 = add i64 %917, -56
  %927 = add i64 %916, 22
  store i64 %927, i64* %PC, align 8
  %928 = inttoptr i64 %926 to i64*
  %929 = load i64, i64* %928, align 8
  store i64 %929, i64* %R8, align 8, !tbaa !2428
  %930 = add i64 %916, 1539
  %931 = add i64 %916, 27
  %932 = load i64, i64* %RSP, align 8, !tbaa !2428
  %933 = add i64 %932, -8
  %934 = inttoptr i64 %933 to i64*
  store i64 %931, i64* %934, align 8
  store i64 %933, i64* %RSP, align 8, !tbaa !2428
  store i64 %930, i64* %PC, align 8, !tbaa !2428
  %935 = tail call %struct.Memory* @sub_401060_cdft_renamed_(%struct.State* nonnull %0, i64 %930, %struct.Memory* %915)
  %936 = load i64, i64* %RBP, align 8
  %937 = add i64 %936, -12
  %938 = load i64, i64* %PC, align 8
  %939 = add i64 %938, 7
  store i64 %939, i64* %PC, align 8
  %940 = inttoptr i64 %937 to i32*
  store i32 0, i32* %940, align 4
  %.pre75 = load i64, i64* %PC, align 8
  br label %block_400a7f

block_400d22:                                     ; preds = %block_400d12, %block_400cf3
  %941 = phi i64 [ %.pre82, %block_400d12 ], [ %443, %block_400cf3 ]
  %942 = phi i64 [ %1387, %block_400d12 ], [ %441, %block_400cf3 ]
  %943 = phi i64 [ %.pre81, %block_400d12 ], [ %412, %block_400cf3 ]
  %.sink5 = phi i64 [ 5, %block_400d12 ], [ 21, %block_400cf3 ]
  %944 = add i64 %943, -192
  %945 = add i64 %942, 8
  store i64 %945, i64* %PC, align 8
  %946 = inttoptr i64 %944 to i64*
  store i64 %941, i64* %946, align 8
  %947 = load i64, i64* %PC, align 8
  %948 = add i64 %947, %.sink5
  %949 = load i64, i64* %RBP, align 8
  %950 = add i64 %949, -192
  %951 = add i64 %948, 8
  store i64 %951, i64* %PC, align 8
  %952 = inttoptr i64 %950 to i64*
  %953 = load i64, i64* %952, align 8
  store i64 %953, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %954 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 48) to i64*), align 16
  store i64 %954, i64* %100, align 1, !tbaa !2451
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  %955 = add i64 %949, -40
  %956 = add i64 %948, 20
  store i64 %956, i64* %PC, align 8
  %957 = inttoptr i64 %955 to i64*
  %958 = load i64, i64* %957, align 8
  store i64 %958, i64* %RAX, align 8, !tbaa !2428
  %959 = add i64 %949, -12
  %960 = add i64 %948, 23
  store i64 %960, i64* %PC, align 8
  %961 = inttoptr i64 %959 to i32*
  %962 = load i32, i32* %961, align 4
  %963 = shl i32 %962, 1
  %964 = or i32 %963, 1
  %965 = zext i32 %964 to i64
  store i64 %965, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %966 = and i32 %964, 255
  %967 = tail call i32 @llvm.ctpop.i32(i32 %966) #14
  %968 = trunc i32 %967 to i8
  %969 = and i8 %968, 1
  %970 = xor i8 %969, 1
  store i8 %970, i8* %25, align 1, !tbaa !2446
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i8 0, i8* %33, align 1, !tbaa !2448
  %971 = lshr i32 %962, 30
  %972 = and i32 %971, 1
  %973 = trunc i32 %972 to i8
  store i8 %973, i8* %36, align 1, !tbaa !2449
  %974 = lshr i32 %962, 30
  %975 = and i32 %974, 1
  %976 = xor i32 %972, %975
  %977 = add nuw nsw i32 %976, %972
  %978 = icmp eq i32 %977, 2
  %979 = zext i1 %978 to i8
  store i8 %979, i8* %42, align 1, !tbaa !2450
  %980 = sext i32 %964 to i64
  store i64 %980, i64* %RDX, align 8, !tbaa !2428
  %981 = shl nsw i64 %980, 3
  %982 = add i64 %958, %981
  %983 = add i64 %948, 37
  store i64 %983, i64* %PC, align 8
  %984 = inttoptr i64 %982 to i64*
  %985 = load i64, i64* %984, align 8
  %986 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 96) to i32*), align 16
  %987 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 100) to i32*), align 4
  %988 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 104) to i32*), align 8
  %989 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 108) to i32*), align 4
  store i32 %986, i32* %1436, align 1, !tbaa !2475
  store i32 %987, i32* %1438, align 1, !tbaa !2475
  store i32 %988, i32* %1440, align 1, !tbaa !2475
  store i32 %989, i32* %1442, align 1, !tbaa !2475
  %990 = load i64, i64* %1443, align 1
  %991 = and i64 %990, %985
  %992 = trunc i64 %991 to i32
  %993 = lshr i64 %991, 32
  %994 = trunc i64 %993 to i32
  store i32 %992, i32* %127, align 1, !tbaa !2469
  store i32 %994, i32* %130, align 1, !tbaa !2469
  store i32 0, i32* %132, align 1, !tbaa !2469
  store i32 0, i32* %134, align 1, !tbaa !2469
  %995 = add i64 %948, 52
  store i64 %995, i64* %PC, align 8
  %996 = load double, double* %135, align 1
  %997 = load double, double* %99, align 1
  %998 = fcmp uno double %996, %997
  br i1 %998, label %999, label %1009

; <label>:999:                                    ; preds = %block_400d22
  %1000 = fadd double %996, %997
  %1001 = bitcast double %1000 to i64
  %1002 = and i64 %1001, 9221120237041090560
  %1003 = icmp eq i64 %1002, 9218868437227405312
  %1004 = and i64 %1001, 2251799813685247
  %1005 = icmp ne i64 %1004, 0
  %1006 = and i1 %1003, %1005
  br i1 %1006, label %1007, label %1015

; <label>:1007:                                   ; preds = %999
  %1008 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %995, %struct.Memory* %746) #16
  %.pre83 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

; <label>:1009:                                   ; preds = %block_400d22
  %1010 = fcmp ogt double %996, %997
  br i1 %1010, label %1015, label %1011

; <label>:1011:                                   ; preds = %1009
  %1012 = fcmp olt double %996, %997
  br i1 %1012, label %1015, label %1013

; <label>:1013:                                   ; preds = %1011
  %1014 = fcmp oeq double %996, %997
  br i1 %1014, label %1015, label %1019

; <label>:1015:                                   ; preds = %1013, %1011, %1009, %999
  %1016 = phi i8 [ 0, %1009 ], [ 0, %1011 ], [ 1, %1013 ], [ 1, %999 ]
  %1017 = phi i8 [ 0, %1009 ], [ 0, %1011 ], [ 0, %1013 ], [ 1, %999 ]
  %1018 = phi i8 [ 0, %1009 ], [ 1, %1011 ], [ 0, %1013 ], [ 1, %999 ]
  store i8 %1016, i8* %33, align 1, !tbaa !2453
  store i8 %1017, i8* %25, align 1, !tbaa !2453
  store i8 %1018, i8* %18, align 1, !tbaa !2453
  br label %1019

; <label>:1019:                                   ; preds = %1015, %1013
  store i8 0, i8* %42, align 1, !tbaa !2453
  store i8 0, i8* %36, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit: ; preds = %1019, %1007
  %1020 = phi i64 [ %.pre83, %1007 ], [ %995, %1019 ]
  %1021 = phi %struct.Memory* [ %1008, %1007 ], [ %746, %1019 ]
  %1022 = load i64, i64* %RBP, align 8
  %1023 = add i64 %1022, -200
  %1024 = add i64 %1020, 8
  store i64 %1024, i64* %PC, align 8
  %1025 = load i64, i64* %69, align 1
  %1026 = inttoptr i64 %1023 to i64*
  store i64 %1025, i64* %1026, align 8
  %1027 = load i64, i64* %PC, align 8
  %1028 = load i8, i8* %18, align 1, !tbaa !2432
  %1029 = load i8, i8* %33, align 1, !tbaa !2448
  %1030 = or i8 %1029, %1028
  %1031 = icmp ne i8 %1030, 0
  %.v98 = select i1 %1031, i64 40, i64 6
  %1032 = add i64 %1027, %.v98
  store i64 %1032, i64* %PC, align 8, !tbaa !2428
  br i1 %1031, label %block_400d86, label %block_400d64

block_400d96:                                     ; preds = %block_400d86, %block_400d64
  %1033 = phi i64 [ %.pre85, %block_400d86 ], [ %615, %block_400d64 ]
  %1034 = phi i64 [ %1508, %block_400d86 ], [ %613, %block_400d64 ]
  %1035 = phi i64 [ %.pre84, %block_400d86 ], [ %584, %block_400d64 ]
  %.sink15 = phi i64 [ 5, %block_400d86 ], [ 21, %block_400d64 ]
  %1036 = add i64 %1035, -208
  %1037 = add i64 %1034, 8
  store i64 %1037, i64* %PC, align 8
  %1038 = inttoptr i64 %1036 to i64*
  store i64 %1033, i64* %1038, align 8
  %1039 = load i64, i64* %PC, align 8
  %1040 = add i64 %1039, %.sink15
  %1041 = load i64, i64* %RBP, align 8
  %1042 = add i64 %1041, -208
  %1043 = add i64 %1040, 8
  store i64 %1043, i64* %PC, align 8
  %1044 = inttoptr i64 %1042 to i64*
  %1045 = load i64, i64* %1044, align 8
  store i64 %1045, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  store i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 157), i64* %RDI, align 8, !tbaa !2428
  %1046 = add i64 %1041, -200
  %1047 = add i64 %1040, 26
  store i64 %1047, i64* %PC, align 8
  %1048 = inttoptr i64 %1046 to i64*
  %1049 = load i64, i64* %1048, align 8
  store i64 %1049, i64* %100, align 1, !tbaa !2451
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  %1050 = add i64 %1041, -216
  %1051 = add i64 %1040, 34
  store i64 %1051, i64* %PC, align 8
  %1052 = inttoptr i64 %1050 to i64*
  store i64 %1045, i64* %1052, align 8
  %1053 = load i64, i64* %PC, align 8
  %1054 = load <2 x i32>, <2 x i32>* %1444, align 1
  %1055 = load <2 x i32>, <2 x i32>* %1445, align 1
  %1056 = extractelement <2 x i32> %1054, i32 0
  store i32 %1056, i32* %374, align 1, !tbaa !2475
  %1057 = extractelement <2 x i32> %1054, i32 1
  store i32 %1057, i32* %376, align 1, !tbaa !2475
  %1058 = extractelement <2 x i32> %1055, i32 0
  store i32 %1058, i32* %377, align 1, !tbaa !2475
  %1059 = extractelement <2 x i32> %1055, i32 1
  store i32 %1059, i32* %379, align 1, !tbaa !2475
  %1060 = load i64, i64* %RBP, align 8
  %1061 = add i64 %1060, -216
  %1062 = add i64 %1053, 11
  store i64 %1062, i64* %PC, align 8
  %1063 = inttoptr i64 %1061 to i64*
  %1064 = load i64, i64* %1063, align 8
  store i64 %1064, i64* %100, align 1, !tbaa !2451
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  store i8 2, i8* %AL, align 1, !tbaa !2453
  %1065 = add i64 %1053, -1752
  %1066 = add i64 %1053, 18
  %1067 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1068 = add i64 %1067, -8
  %1069 = inttoptr i64 %1068 to i64*
  store i64 %1066, i64* %1069, align 8
  store i64 %1068, i64* %RSP, align 8, !tbaa !2428
  store i64 %1065, i64* %PC, align 8, !tbaa !2428
  %1070 = tail call fastcc %struct.Memory* @ext_4006e0_printf(%struct.State* nonnull %0, %struct.Memory* %1021)
  %1071 = load i64, i64* %RBP, align 8
  %1072 = add i64 %1071, -220
  %1073 = load i32, i32* %EAX, align 4
  %1074 = load i64, i64* %PC, align 8
  %1075 = add i64 %1074, 6
  store i64 %1075, i64* %PC, align 8
  %1076 = inttoptr i64 %1072 to i32*
  store i32 %1073, i32* %1076, align 4
  %1077 = load i64, i64* %RBP, align 8
  %1078 = add i64 %1077, -12
  %1079 = load i64, i64* %PC, align 8
  %1080 = add i64 %1079, 3
  store i64 %1080, i64* %PC, align 8
  %1081 = inttoptr i64 %1078 to i32*
  %1082 = load i32, i32* %1081, align 4
  %1083 = add i32 %1082, 1
  %1084 = zext i32 %1083 to i64
  store i64 %1084, i64* %RAX, align 8, !tbaa !2428
  %1085 = icmp eq i32 %1082, -1
  %1086 = icmp eq i32 %1083, 0
  %1087 = or i1 %1085, %1086
  %1088 = zext i1 %1087 to i8
  store i8 %1088, i8* %18, align 1, !tbaa !2432
  %1089 = and i32 %1083, 255
  %1090 = tail call i32 @llvm.ctpop.i32(i32 %1089) #14
  %1091 = trunc i32 %1090 to i8
  %1092 = and i8 %1091, 1
  %1093 = xor i8 %1092, 1
  store i8 %1093, i8* %25, align 1, !tbaa !2446
  %1094 = xor i32 %1083, %1082
  %1095 = lshr i32 %1094, 4
  %1096 = trunc i32 %1095 to i8
  %1097 = and i8 %1096, 1
  store i8 %1097, i8* %30, align 1, !tbaa !2447
  %1098 = zext i1 %1086 to i8
  store i8 %1098, i8* %33, align 1, !tbaa !2448
  %1099 = lshr i32 %1083, 31
  %1100 = trunc i32 %1099 to i8
  store i8 %1100, i8* %36, align 1, !tbaa !2449
  %1101 = lshr i32 %1082, 31
  %1102 = xor i32 %1099, %1101
  %1103 = add nuw nsw i32 %1102, %1099
  %1104 = icmp eq i32 %1103, 2
  %1105 = zext i1 %1104 to i8
  store i8 %1105, i8* %42, align 1, !tbaa !2450
  %1106 = add i64 %1079, 9
  store i64 %1106, i64* %PC, align 8
  store i32 %1083, i32* %1081, align 4
  %1107 = load i64, i64* %PC, align 8
  %1108 = add i64 %1107, -290
  store i64 %1108, i64* %PC, align 8, !tbaa !2428
  br label %block_400cb7

block_400b94:                                     ; preds = %block_400b87
  %1109 = add i64 %1449, -40
  %1110 = add i64 %1477, 4
  store i64 %1110, i64* %PC, align 8
  %1111 = inttoptr i64 %1109 to i64*
  %1112 = load i64, i64* %1111, align 8
  store i64 %1112, i64* %RAX, align 8, !tbaa !2428
  %1113 = add i64 %1477, 7
  store i64 %1113, i64* %PC, align 8
  %1114 = load i32, i32* %1452, align 4
  %1115 = shl i32 %1114, 1
  %1116 = icmp slt i32 %1114, 0
  %1117 = icmp slt i32 %1115, 0
  %1118 = xor i1 %1116, %1117
  %1119 = zext i32 %1115 to i64
  store i64 %1119, i64* %RCX, align 8, !tbaa !2428
  %.lobit55 = lshr i32 %1114, 31
  %1120 = trunc i32 %.lobit55 to i8
  store i8 %1120, i8* %18, align 1, !tbaa !2453
  %1121 = and i32 %1115, 254
  %1122 = tail call i32 @llvm.ctpop.i32(i32 %1121) #14
  %1123 = trunc i32 %1122 to i8
  %1124 = and i8 %1123, 1
  %1125 = xor i8 %1124, 1
  store i8 %1125, i8* %25, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  %1126 = icmp eq i32 %1115, 0
  %1127 = zext i1 %1126 to i8
  store i8 %1127, i8* %33, align 1, !tbaa !2453
  %1128 = lshr i32 %1114, 30
  %1129 = trunc i32 %1128 to i8
  %1130 = and i8 %1129, 1
  store i8 %1130, i8* %36, align 1, !tbaa !2453
  %1131 = zext i1 %1118 to i8
  store i8 %1131, i8* %42, align 1, !tbaa !2453
  %1132 = sext i32 %1115 to i64
  store i64 %1132, i64* %RDX, align 8, !tbaa !2428
  %1133 = shl nsw i64 %1132, 3
  %1134 = add i64 %1112, %1133
  %1135 = add i64 %1477, 18
  store i64 %1135, i64* %PC, align 8
  %1136 = inttoptr i64 %1134 to i64*
  %1137 = load i64, i64* %1136, align 8
  store i64 %1137, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %1138 = add i64 %1449, -112
  %1139 = add i64 %1477, 23
  store i64 %1139, i64* %PC, align 8
  %1140 = inttoptr i64 %1138 to i64*
  store i64 %1137, i64* %1140, align 8
  %1141 = load i64, i64* %RBP, align 8
  %1142 = add i64 %1141, -32
  %1143 = load i64, i64* %PC, align 8
  %1144 = add i64 %1143, 4
  store i64 %1144, i64* %PC, align 8
  %1145 = inttoptr i64 %1142 to i64*
  %1146 = load i64, i64* %1145, align 8
  store i64 %1146, i64* %RAX, align 8, !tbaa !2428
  %1147 = add i64 %1141, -100
  %1148 = add i64 %1143, 7
  store i64 %1148, i64* %PC, align 8
  %1149 = inttoptr i64 %1147 to i32*
  %1150 = load i32, i32* %1149, align 4
  %1151 = shl i32 %1150, 1
  %1152 = icmp slt i32 %1150, 0
  %1153 = icmp slt i32 %1151, 0
  %1154 = xor i1 %1152, %1153
  %1155 = zext i32 %1151 to i64
  store i64 %1155, i64* %RCX, align 8, !tbaa !2428
  %.lobit56 = lshr i32 %1150, 31
  %1156 = trunc i32 %.lobit56 to i8
  store i8 %1156, i8* %18, align 1, !tbaa !2453
  %1157 = and i32 %1151, 254
  %1158 = tail call i32 @llvm.ctpop.i32(i32 %1157) #14
  %1159 = trunc i32 %1158 to i8
  %1160 = and i8 %1159, 1
  %1161 = xor i8 %1160, 1
  store i8 %1161, i8* %25, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  %1162 = icmp eq i32 %1151, 0
  %1163 = zext i1 %1162 to i8
  store i8 %1163, i8* %33, align 1, !tbaa !2453
  %1164 = lshr i32 %1150, 30
  %1165 = trunc i32 %1164 to i8
  %1166 = and i8 %1165, 1
  store i8 %1166, i8* %36, align 1, !tbaa !2453
  %1167 = zext i1 %1154 to i8
  store i8 %1167, i8* %42, align 1, !tbaa !2453
  %1168 = sext i32 %1151 to i64
  store i64 %1168, i64* %RDX, align 8, !tbaa !2428
  %1169 = shl nsw i64 %1168, 3
  %1170 = add i64 %1146, %1169
  %1171 = add i64 %1143, 18
  store i64 %1171, i64* %PC, align 8
  %1172 = inttoptr i64 %1170 to i64*
  %1173 = load i64, i64* %1172, align 8
  store i64 %1173, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %1174 = add i64 %1141, -120
  %1175 = add i64 %1143, 23
  store i64 %1175, i64* %PC, align 8
  %1176 = inttoptr i64 %1174 to i64*
  store i64 %1173, i64* %1176, align 8
  %1177 = load i64, i64* %RBP, align 8
  %1178 = add i64 %1177, -40
  %1179 = load i64, i64* %PC, align 8
  %1180 = add i64 %1179, 4
  store i64 %1180, i64* %PC, align 8
  %1181 = inttoptr i64 %1178 to i64*
  %1182 = load i64, i64* %1181, align 8
  store i64 %1182, i64* %RAX, align 8, !tbaa !2428
  %1183 = add i64 %1177, -100
  %1184 = add i64 %1179, 7
  store i64 %1184, i64* %PC, align 8
  %1185 = inttoptr i64 %1183 to i32*
  %1186 = load i32, i32* %1185, align 4
  %1187 = shl i32 %1186, 1
  %1188 = or i32 %1187, 1
  %1189 = zext i32 %1188 to i64
  store i64 %1189, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %1190 = and i32 %1188, 255
  %1191 = tail call i32 @llvm.ctpop.i32(i32 %1190) #14
  %1192 = trunc i32 %1191 to i8
  %1193 = and i8 %1192, 1
  %1194 = xor i8 %1193, 1
  store i8 %1194, i8* %25, align 1, !tbaa !2446
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i8 0, i8* %33, align 1, !tbaa !2448
  %1195 = lshr i32 %1186, 30
  %1196 = and i32 %1195, 1
  %1197 = trunc i32 %1196 to i8
  store i8 %1197, i8* %36, align 1, !tbaa !2449
  %1198 = lshr i32 %1186, 30
  %1199 = and i32 %1198, 1
  %1200 = xor i32 %1196, %1199
  %1201 = add nuw nsw i32 %1200, %1196
  %1202 = icmp eq i32 %1201, 2
  %1203 = zext i1 %1202 to i8
  store i8 %1203, i8* %42, align 1, !tbaa !2450
  %1204 = sext i32 %1188 to i64
  store i64 %1204, i64* %RDX, align 8, !tbaa !2428
  %1205 = shl nsw i64 %1204, 3
  %1206 = add i64 %1182, %1205
  %1207 = add i64 %1179, 21
  store i64 %1207, i64* %PC, align 8
  %1208 = inttoptr i64 %1206 to i64*
  %1209 = load i64, i64* %1208, align 8
  store i64 %1209, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %1210 = add i64 %1177, -128
  %1211 = add i64 %1179, 26
  store i64 %1211, i64* %PC, align 8
  %1212 = inttoptr i64 %1210 to i64*
  store i64 %1209, i64* %1212, align 8
  %1213 = load i64, i64* %RBP, align 8
  %1214 = add i64 %1213, -32
  %1215 = load i64, i64* %PC, align 8
  %1216 = add i64 %1215, 4
  store i64 %1216, i64* %PC, align 8
  %1217 = inttoptr i64 %1214 to i64*
  %1218 = load i64, i64* %1217, align 8
  store i64 %1218, i64* %RAX, align 8, !tbaa !2428
  %1219 = add i64 %1213, -100
  %1220 = add i64 %1215, 7
  store i64 %1220, i64* %PC, align 8
  %1221 = inttoptr i64 %1219 to i32*
  %1222 = load i32, i32* %1221, align 4
  %1223 = shl i32 %1222, 1
  %1224 = or i32 %1223, 1
  %1225 = zext i32 %1224 to i64
  store i64 %1225, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %1226 = and i32 %1224, 255
  %1227 = tail call i32 @llvm.ctpop.i32(i32 %1226) #14
  %1228 = trunc i32 %1227 to i8
  %1229 = and i8 %1228, 1
  %1230 = xor i8 %1229, 1
  store i8 %1230, i8* %25, align 1, !tbaa !2446
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i8 0, i8* %33, align 1, !tbaa !2448
  %1231 = lshr i32 %1222, 30
  %1232 = and i32 %1231, 1
  %1233 = trunc i32 %1232 to i8
  store i8 %1233, i8* %36, align 1, !tbaa !2449
  %1234 = lshr i32 %1222, 30
  %1235 = and i32 %1234, 1
  %1236 = xor i32 %1232, %1235
  %1237 = add nuw nsw i32 %1236, %1232
  %1238 = icmp eq i32 %1237, 2
  %1239 = zext i1 %1238 to i8
  store i8 %1239, i8* %42, align 1, !tbaa !2450
  %1240 = sext i32 %1224 to i64
  store i64 %1240, i64* %RDX, align 8, !tbaa !2428
  %1241 = shl nsw i64 %1240, 3
  %1242 = add i64 %1218, %1241
  %1243 = add i64 %1215, 21
  store i64 %1243, i64* %PC, align 8
  %1244 = inttoptr i64 %1242 to i64*
  %1245 = load i64, i64* %1244, align 8
  store i64 %1245, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %1246 = add i64 %1213, -136
  %1247 = add i64 %1215, 29
  store i64 %1247, i64* %PC, align 8
  %1248 = inttoptr i64 %1246 to i64*
  store i64 %1245, i64* %1248, align 8
  %1249 = load i64, i64* %RBP, align 8
  %1250 = add i64 %1249, -112
  %1251 = load i64, i64* %PC, align 8
  %1252 = add i64 %1251, 5
  store i64 %1252, i64* %PC, align 8
  %1253 = inttoptr i64 %1250 to i64*
  %1254 = load i64, i64* %1253, align 8
  store i64 %1254, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %1255 = add i64 %1249, -120
  %1256 = add i64 %1251, 10
  store i64 %1256, i64* %PC, align 8
  %1257 = bitcast i64 %1254 to double
  %1258 = inttoptr i64 %1255 to double*
  %1259 = load double, double* %1258, align 8
  %1260 = fmul double %1257, %1259
  store double %1260, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %1261 = add i64 %1249, -128
  %1262 = add i64 %1251, 15
  store i64 %1262, i64* %PC, align 8
  %1263 = inttoptr i64 %1261 to i64*
  %1264 = load i64, i64* %1263, align 8
  store i64 %1264, i64* %100, align 1, !tbaa !2451
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  %1265 = add i64 %1249, -136
  %1266 = add i64 %1251, 23
  store i64 %1266, i64* %PC, align 8
  %1267 = bitcast i64 %1264 to double
  %1268 = inttoptr i64 %1265 to double*
  %1269 = load double, double* %1268, align 8
  %1270 = fmul double %1267, %1269
  store double %1270, double* %99, align 1, !tbaa !2451
  store i64 0, i64* %101, align 1, !tbaa !2451
  %1271 = fsub double %1260, %1270
  store double %1271, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %1272 = add i64 %1249, -40
  %1273 = add i64 %1251, 31
  store i64 %1273, i64* %PC, align 8
  %1274 = inttoptr i64 %1272 to i64*
  %1275 = load i64, i64* %1274, align 8
  store i64 %1275, i64* %RAX, align 8, !tbaa !2428
  %1276 = add i64 %1249, -100
  %1277 = add i64 %1251, 34
  store i64 %1277, i64* %PC, align 8
  %1278 = inttoptr i64 %1276 to i32*
  %1279 = load i32, i32* %1278, align 4
  %1280 = shl i32 %1279, 1
  %1281 = icmp slt i32 %1279, 0
  %1282 = icmp slt i32 %1280, 0
  %1283 = xor i1 %1281, %1282
  %1284 = zext i32 %1280 to i64
  store i64 %1284, i64* %RCX, align 8, !tbaa !2428
  %.lobit59 = lshr i32 %1279, 31
  %1285 = trunc i32 %.lobit59 to i8
  store i8 %1285, i8* %18, align 1, !tbaa !2453
  %1286 = and i32 %1280, 254
  %1287 = tail call i32 @llvm.ctpop.i32(i32 %1286) #14
  %1288 = trunc i32 %1287 to i8
  %1289 = and i8 %1288, 1
  %1290 = xor i8 %1289, 1
  store i8 %1290, i8* %25, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  %1291 = icmp eq i32 %1280, 0
  %1292 = zext i1 %1291 to i8
  store i8 %1292, i8* %33, align 1, !tbaa !2453
  %1293 = lshr i32 %1279, 30
  %1294 = trunc i32 %1293 to i8
  %1295 = and i8 %1294, 1
  store i8 %1295, i8* %36, align 1, !tbaa !2453
  %1296 = zext i1 %1283 to i8
  store i8 %1296, i8* %42, align 1, !tbaa !2453
  %1297 = sext i32 %1280 to i64
  store i64 %1297, i64* %RDX, align 8, !tbaa !2428
  %1298 = shl nsw i64 %1297, 3
  %1299 = add i64 %1275, %1298
  %1300 = add i64 %1251, 45
  store i64 %1300, i64* %PC, align 8
  %1301 = inttoptr i64 %1299 to double*
  store double %1271, double* %1301, align 8
  %1302 = load i64, i64* %RBP, align 8
  %1303 = add i64 %1302, -112
  %1304 = load i64, i64* %PC, align 8
  %1305 = add i64 %1304, 5
  store i64 %1305, i64* %PC, align 8
  %1306 = inttoptr i64 %1303 to i64*
  %1307 = load i64, i64* %1306, align 8
  store i64 %1307, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %1308 = add i64 %1302, -136
  %1309 = add i64 %1304, 13
  store i64 %1309, i64* %PC, align 8
  %1310 = bitcast i64 %1307 to double
  %1311 = inttoptr i64 %1308 to double*
  %1312 = load double, double* %1311, align 8
  %1313 = fmul double %1310, %1312
  store double %1313, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %1314 = add i64 %1302, -128
  %1315 = add i64 %1304, 18
  store i64 %1315, i64* %PC, align 8
  %1316 = inttoptr i64 %1314 to i64*
  %1317 = load i64, i64* %1316, align 8
  store i64 %1317, i64* %100, align 1, !tbaa !2451
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  %1318 = add i64 %1302, -120
  %1319 = add i64 %1304, 23
  store i64 %1319, i64* %PC, align 8
  %1320 = bitcast i64 %1317 to double
  %1321 = inttoptr i64 %1318 to double*
  %1322 = load double, double* %1321, align 8
  %1323 = fmul double %1320, %1322
  store double %1323, double* %99, align 1, !tbaa !2451
  store i64 0, i64* %101, align 1, !tbaa !2451
  %1324 = fadd double %1313, %1323
  store double %1324, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %1325 = add i64 %1302, -40
  %1326 = add i64 %1304, 31
  store i64 %1326, i64* %PC, align 8
  %1327 = inttoptr i64 %1325 to i64*
  %1328 = load i64, i64* %1327, align 8
  store i64 %1328, i64* %RAX, align 8, !tbaa !2428
  %1329 = add i64 %1302, -100
  %1330 = add i64 %1304, 34
  store i64 %1330, i64* %PC, align 8
  %1331 = inttoptr i64 %1329 to i32*
  %1332 = load i32, i32* %1331, align 4
  %1333 = shl i32 %1332, 1
  %1334 = or i32 %1333, 1
  %1335 = zext i32 %1334 to i64
  store i64 %1335, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %1336 = and i32 %1334, 255
  %1337 = tail call i32 @llvm.ctpop.i32(i32 %1336) #14
  %1338 = trunc i32 %1337 to i8
  %1339 = and i8 %1338, 1
  %1340 = xor i8 %1339, 1
  store i8 %1340, i8* %25, align 1, !tbaa !2446
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i8 0, i8* %33, align 1, !tbaa !2448
  %1341 = lshr i32 %1332, 30
  %1342 = and i32 %1341, 1
  %1343 = trunc i32 %1342 to i8
  store i8 %1343, i8* %36, align 1, !tbaa !2449
  %1344 = lshr i32 %1332, 30
  %1345 = and i32 %1344, 1
  %1346 = xor i32 %1342, %1345
  %1347 = add nuw nsw i32 %1346, %1342
  %1348 = icmp eq i32 %1347, 2
  %1349 = zext i1 %1348 to i8
  store i8 %1349, i8* %42, align 1, !tbaa !2450
  %1350 = sext i32 %1334 to i64
  store i64 %1350, i64* %RDX, align 8, !tbaa !2428
  %1351 = shl nsw i64 %1350, 3
  %1352 = add i64 %1328, %1351
  %1353 = add i64 %1304, 48
  store i64 %1353, i64* %PC, align 8
  %1354 = inttoptr i64 %1352 to double*
  store double %1324, double* %1354, align 8
  %1355 = load i64, i64* %RBP, align 8
  %1356 = add i64 %1355, -100
  %1357 = load i64, i64* %PC, align 8
  %1358 = add i64 %1357, 3
  store i64 %1358, i64* %PC, align 8
  %1359 = inttoptr i64 %1356 to i32*
  %1360 = load i32, i32* %1359, align 4
  %1361 = add i32 %1360, 1
  %1362 = zext i32 %1361 to i64
  store i64 %1362, i64* %RAX, align 8, !tbaa !2428
  %1363 = icmp eq i32 %1360, -1
  %1364 = icmp eq i32 %1361, 0
  %1365 = or i1 %1363, %1364
  %1366 = zext i1 %1365 to i8
  store i8 %1366, i8* %18, align 1, !tbaa !2432
  %1367 = and i32 %1361, 255
  %1368 = tail call i32 @llvm.ctpop.i32(i32 %1367) #14
  %1369 = trunc i32 %1368 to i8
  %1370 = and i8 %1369, 1
  %1371 = xor i8 %1370, 1
  store i8 %1371, i8* %25, align 1, !tbaa !2446
  %1372 = xor i32 %1361, %1360
  %1373 = lshr i32 %1372, 4
  %1374 = trunc i32 %1373 to i8
  %1375 = and i8 %1374, 1
  store i8 %1375, i8* %30, align 1, !tbaa !2447
  %1376 = zext i1 %1364 to i8
  store i8 %1376, i8* %33, align 1, !tbaa !2448
  %1377 = lshr i32 %1361, 31
  %1378 = trunc i32 %1377 to i8
  store i8 %1378, i8* %36, align 1, !tbaa !2449
  %1379 = lshr i32 %1360, 31
  %1380 = xor i32 %1377, %1379
  %1381 = add nuw nsw i32 %1380, %1377
  %1382 = icmp eq i32 %1381, 2
  %1383 = zext i1 %1382 to i8
  store i8 %1383, i8* %42, align 1, !tbaa !2450
  %1384 = add i64 %1357, 9
  store i64 %1384, i64* %PC, align 8
  store i32 %1361, i32* %1359, align 4
  %1385 = load i64, i64* %PC, align 8
  %1386 = add i64 %1385, -216
  store i64 %1386, i64* %PC, align 8, !tbaa !2428
  br label %block_400b87

block_400d12:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1
  %1387 = add i64 %749, 3
  store i64 %1387, i64* %PC, align 8
  store <4 x i32> zeroinitializer, <4 x i32>* %1446, align 1, !tbaa !2469
  %.pre81 = load i64, i64* %RBP, align 8
  %.pre82 = load i64, i64* %69, align 1
  br label %block_400d22

block_400c8d:                                     ; preds = %block_400b26
  %1388 = add i64 %780, 419
  %1389 = add i64 %780, 5
  %1390 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1391 = add i64 %1390, -8
  %1392 = inttoptr i64 %1391 to i64*
  store i64 %1389, i64* %1392, align 8
  store i64 %1391, i64* %RSP, align 8, !tbaa !2428
  store i64 %1388, i64* %PC, align 8, !tbaa !2428
  %1393 = tail call %struct.Memory* @sub_400e30_get_time_renamed_(%struct.State* nonnull %0, i64 %1388, %struct.Memory* %MEMORY.0)
  %1394 = load i64, i64* %RBP, align 8
  %1395 = add i64 %1394, -72
  %1396 = load i64, i64* %PC, align 8
  %1397 = add i64 %1396, 5
  store i64 %1397, i64* %PC, align 8
  %1398 = load i64, i64* %69, align 1
  %1399 = inttoptr i64 %1395 to i64*
  store i64 %1398, i64* %1399, align 8
  %1400 = load i64, i64* %RBP, align 8
  %1401 = add i64 %1400, -72
  %1402 = load i64, i64* %PC, align 8
  %1403 = add i64 %1402, 5
  store i64 %1403, i64* %PC, align 8
  %1404 = inttoptr i64 %1401 to i64*
  %1405 = load i64, i64* %1404, align 8
  store i64 %1405, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %1406 = add i64 %1400, -64
  %1407 = add i64 %1402, 10
  store i64 %1407, i64* %PC, align 8
  %1408 = bitcast i64 %1405 to double
  %1409 = inttoptr i64 %1406 to double*
  %1410 = load double, double* %1409, align 8
  %1411 = fsub double %1408, %1410
  store double %1411, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %1412 = add i64 %1400, -80
  %1413 = add i64 %1402, 15
  store i64 %1413, i64* %PC, align 8
  %1414 = inttoptr i64 %1412 to double*
  %1415 = load double, double* %1414, align 8
  %1416 = fsub double %1411, %1415
  store double %1416, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %1417 = add i64 %1400, -88
  %1418 = add i64 %1402, 20
  store i64 %1418, i64* %PC, align 8
  %1419 = inttoptr i64 %1417 to double*
  %1420 = load double, double* %1419, align 8
  %1421 = fadd double %1416, %1420
  store double %1421, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %1422 = add i64 %1402, 25
  store i64 %1422, i64* %PC, align 8
  %1423 = inttoptr i64 %1417 to double*
  store double %1421, double* %1423, align 8
  %1424 = load i64, i64* %RBP, align 8
  %1425 = add i64 %1424, -12
  %1426 = load i64, i64* %PC, align 8
  %1427 = add i64 %1426, 7
  store i64 %1427, i64* %PC, align 8
  %1428 = inttoptr i64 %1425 to i32*
  store i32 0, i32* %1428, align 4
  %1429 = bitcast %union.VectorReg* %6 to i32*
  %1430 = getelementptr inbounds i8, i8* %94, i64 4
  %1431 = bitcast i8* %1430 to i32*
  %1432 = bitcast i64* %101 to i32*
  %1433 = getelementptr inbounds i8, i8* %94, i64 12
  %1434 = bitcast i8* %1433 to i32*
  %1435 = bitcast %union.VectorReg* %8 to i8*
  %1436 = bitcast %union.VectorReg* %8 to i32*
  %1437 = getelementptr inbounds i8, i8* %1435, i64 4
  %1438 = bitcast i8* %1437 to i32*
  %1439 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3, i32 0, i32 0, i32 0, i64 1
  %1440 = bitcast i64* %1439 to i32*
  %1441 = getelementptr inbounds i8, i8* %1435, i64 12
  %1442 = bitcast i8* %1441 to i32*
  %1443 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %8, i64 0, i32 0, i32 0, i32 0, i64 0
  %1444 = bitcast %union.VectorReg* %6 to <2 x i32>*
  %1445 = bitcast i64* %101 to <2 x i32>*
  %.pre77 = load i64, i64* %PC, align 8
  %1446 = bitcast [32 x %union.VectorReg]* %5 to <4 x i32>*
  %1447 = bitcast [32 x %union.VectorReg]* %5 to <4 x i32>*
  br label %block_400cb7

block_400b87:                                     ; preds = %block_400b94, %block_400b33
  %1448 = phi i64 [ %1386, %block_400b94 ], [ %.pre86, %block_400b33 ]
  %1449 = load i64, i64* %RBP, align 8
  %1450 = add i64 %1449, -100
  %1451 = add i64 %1448, 7
  store i64 %1451, i64* %PC, align 8
  %1452 = inttoptr i64 %1450 to i32*
  %1453 = load i32, i32* %1452, align 4
  %1454 = add i32 %1453, -1024
  %1455 = icmp ult i32 %1453, 1024
  %1456 = zext i1 %1455 to i8
  store i8 %1456, i8* %18, align 1, !tbaa !2432
  %1457 = and i32 %1454, 255
  %1458 = tail call i32 @llvm.ctpop.i32(i32 %1457) #14
  %1459 = trunc i32 %1458 to i8
  %1460 = and i8 %1459, 1
  %1461 = xor i8 %1460, 1
  store i8 %1461, i8* %25, align 1, !tbaa !2446
  %1462 = xor i32 %1454, %1453
  %1463 = lshr i32 %1462, 4
  %1464 = trunc i32 %1463 to i8
  %1465 = and i8 %1464, 1
  store i8 %1465, i8* %30, align 1, !tbaa !2447
  %1466 = icmp eq i32 %1454, 0
  %1467 = zext i1 %1466 to i8
  store i8 %1467, i8* %33, align 1, !tbaa !2448
  %1468 = lshr i32 %1454, 31
  %1469 = trunc i32 %1468 to i8
  store i8 %1469, i8* %36, align 1, !tbaa !2449
  %1470 = lshr i32 %1453, 31
  %1471 = xor i32 %1468, %1470
  %1472 = add nuw nsw i32 %1471, %1470
  %1473 = icmp eq i32 %1472, 2
  %1474 = zext i1 %1473 to i8
  store i8 %1474, i8* %42, align 1, !tbaa !2450
  %1475 = icmp ne i8 %1469, 0
  %1476 = xor i1 %1475, %1473
  %.v90 = select i1 %1476, i64 13, i64 221
  %1477 = add i64 %1448, %.v90
  store i64 %1477, i64* %PC, align 8, !tbaa !2428
  br i1 %1476, label %block_400b94, label %block_400c64

block_400cb7:                                     ; preds = %block_400c8d, %block_400d96
  %1478 = phi i64 [ %.pre77, %block_400c8d ], [ %1108, %block_400d96 ]
  %MEMORY.5 = phi %struct.Memory* [ %1393, %block_400c8d ], [ %1070, %block_400d96 ]
  %1479 = load i64, i64* %RBP, align 8
  %1480 = add i64 %1479, -12
  %1481 = add i64 %1478, 7
  store i64 %1481, i64* %PC, align 8
  %1482 = inttoptr i64 %1480 to i32*
  %1483 = load i32, i32* %1482, align 4
  %1484 = add i32 %1483, -1024
  %1485 = icmp ult i32 %1483, 1024
  %1486 = zext i1 %1485 to i8
  store i8 %1486, i8* %18, align 1, !tbaa !2432
  %1487 = and i32 %1484, 255
  %1488 = tail call i32 @llvm.ctpop.i32(i32 %1487) #14
  %1489 = trunc i32 %1488 to i8
  %1490 = and i8 %1489, 1
  %1491 = xor i8 %1490, 1
  store i8 %1491, i8* %25, align 1, !tbaa !2446
  %1492 = xor i32 %1484, %1483
  %1493 = lshr i32 %1492, 4
  %1494 = trunc i32 %1493 to i8
  %1495 = and i8 %1494, 1
  store i8 %1495, i8* %30, align 1, !tbaa !2447
  %1496 = icmp eq i32 %1484, 0
  %1497 = zext i1 %1496 to i8
  store i8 %1497, i8* %33, align 1, !tbaa !2448
  %1498 = lshr i32 %1484, 31
  %1499 = trunc i32 %1498 to i8
  store i8 %1499, i8* %36, align 1, !tbaa !2449
  %1500 = lshr i32 %1483, 31
  %1501 = xor i32 %1498, %1500
  %1502 = add nuw nsw i32 %1501, %1500
  %1503 = icmp eq i32 %1502, 2
  %1504 = zext i1 %1503 to i8
  store i8 %1504, i8* %42, align 1, !tbaa !2450
  %1505 = icmp ne i8 %1499, 0
  %1506 = xor i1 %1505, %1503
  %.v88 = select i1 %1506, i64 13, i64 295
  %1507 = add i64 %1478, %.v88
  store i64 %1507, i64* %PC, align 8, !tbaa !2428
  br i1 %1506, label %block_400cc4, label %block_400dde

block_400d86:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %1508 = add i64 %1032, 3
  store i64 %1508, i64* %PC, align 8
  store <4 x i32> zeroinitializer, <4 x i32>* %1447, align 1, !tbaa !2469
  %.pre84 = load i64, i64* %RBP, align 8
  %.pre85 = load i64, i64* %69, align 1
  br label %block_400d96

block_400a8c:                                     ; preds = %block_400a7f
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %1509 = add i64 %782, -32
  %1510 = add i64 %810, 14
  store i64 %1510, i64* %PC, align 8
  %1511 = inttoptr i64 %1509 to i64*
  %1512 = load i64, i64* %1511, align 8
  store i64 %1512, i64* %RCX, align 8, !tbaa !2428
  %1513 = add i64 %810, 17
  store i64 %1513, i64* %PC, align 8
  %1514 = load i32, i32* %785, align 4
  %1515 = shl i32 %1514, 1
  %1516 = or i32 %1515, 1
  %1517 = zext i32 %1516 to i64
  store i64 %1517, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %1518 = and i32 %1516, 255
  %1519 = tail call i32 @llvm.ctpop.i32(i32 %1518) #14
  %1520 = trunc i32 %1519 to i8
  %1521 = and i8 %1520, 1
  %1522 = xor i8 %1521, 1
  store i8 %1522, i8* %25, align 1, !tbaa !2446
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i8 0, i8* %33, align 1, !tbaa !2448
  %1523 = lshr i32 %1514, 30
  %1524 = and i32 %1523, 1
  %1525 = trunc i32 %1524 to i8
  store i8 %1525, i8* %36, align 1, !tbaa !2449
  %1526 = lshr i32 %1514, 30
  %1527 = and i32 %1526, 1
  %1528 = xor i32 %1524, %1527
  %1529 = add nuw nsw i32 %1528, %1524
  %1530 = icmp eq i32 %1529, 2
  %1531 = zext i1 %1530 to i8
  store i8 %1531, i8* %42, align 1, !tbaa !2450
  %1532 = sext i32 %1516 to i64
  store i64 %1532, i64* %RSI, align 8, !tbaa !2428
  %1533 = shl nsw i64 %1532, 3
  %1534 = add i64 %1512, %1533
  %1535 = add i64 %810, 31
  store i64 %1535, i64* %PC, align 8
  %1536 = inttoptr i64 %1534 to i64*
  %1537 = load i64, i64* %1536, align 8
  %1538 = xor i64 %1537, -9223372036854775808
  store i64 %1538, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %1539 = trunc i64 %1537 to i32
  %1540 = and i32 %1539, 255
  %1541 = tail call i32 @llvm.ctpop.i32(i32 %1540) #14
  %1542 = trunc i32 %1541 to i8
  %1543 = and i8 %1542, 1
  %1544 = xor i8 %1543, 1
  store i8 %1544, i8* %25, align 1, !tbaa !2446
  %1545 = icmp eq i64 %1538, 0
  %1546 = zext i1 %1545 to i8
  store i8 %1546, i8* %33, align 1, !tbaa !2448
  %1547 = lshr i64 %1538, 63
  %1548 = trunc i64 %1547 to i8
  store i8 %1548, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i64 %1538, i64* %69, align 1, !tbaa !2428
  store i64 0, i64* %92, align 1, !tbaa !2428
  %1549 = load i64, i64* %RBP, align 8
  %1550 = add i64 %1549, -32
  %1551 = add i64 %810, 48
  store i64 %1551, i64* %PC, align 8
  %1552 = inttoptr i64 %1550 to i64*
  %1553 = load i64, i64* %1552, align 8
  store i64 %1553, i64* %RAX, align 8, !tbaa !2428
  %1554 = add i64 %1549, -12
  %1555 = add i64 %810, 51
  store i64 %1555, i64* %PC, align 8
  %1556 = inttoptr i64 %1554 to i32*
  %1557 = load i32, i32* %1556, align 4
  %1558 = shl i32 %1557, 1
  %1559 = or i32 %1558, 1
  %1560 = zext i32 %1559 to i64
  store i64 %1560, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %1561 = and i32 %1559, 255
  %1562 = tail call i32 @llvm.ctpop.i32(i32 %1561) #14
  %1563 = trunc i32 %1562 to i8
  %1564 = and i8 %1563, 1
  %1565 = xor i8 %1564, 1
  store i8 %1565, i8* %25, align 1, !tbaa !2446
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i8 0, i8* %33, align 1, !tbaa !2448
  %1566 = lshr i32 %1557, 30
  %1567 = and i32 %1566, 1
  %1568 = trunc i32 %1567 to i8
  store i8 %1568, i8* %36, align 1, !tbaa !2449
  %1569 = lshr i32 %1557, 30
  %1570 = and i32 %1569, 1
  %1571 = xor i32 %1567, %1570
  %1572 = add nuw nsw i32 %1571, %1567
  %1573 = icmp eq i32 %1572, 2
  %1574 = zext i1 %1573 to i8
  store i8 %1574, i8* %42, align 1, !tbaa !2450
  %1575 = sext i32 %1559 to i64
  store i64 %1575, i64* %RCX, align 8, !tbaa !2428
  %1576 = shl nsw i64 %1575, 3
  %1577 = add i64 %1553, %1576
  %1578 = add i64 %810, 65
  store i64 %1578, i64* %PC, align 8
  %1579 = inttoptr i64 %1577 to i64*
  store i64 %1538, i64* %1579, align 8
  %1580 = load i64, i64* %RBP, align 8
  %1581 = add i64 %1580, -12
  %1582 = load i64, i64* %PC, align 8
  %1583 = add i64 %1582, 3
  store i64 %1583, i64* %PC, align 8
  %1584 = inttoptr i64 %1581 to i32*
  %1585 = load i32, i32* %1584, align 4
  %1586 = add i32 %1585, 1
  %1587 = zext i32 %1586 to i64
  store i64 %1587, i64* %RAX, align 8, !tbaa !2428
  %1588 = icmp eq i32 %1585, -1
  %1589 = icmp eq i32 %1586, 0
  %1590 = or i1 %1588, %1589
  %1591 = zext i1 %1590 to i8
  store i8 %1591, i8* %18, align 1, !tbaa !2432
  %1592 = and i32 %1586, 255
  %1593 = tail call i32 @llvm.ctpop.i32(i32 %1592) #14
  %1594 = trunc i32 %1593 to i8
  %1595 = and i8 %1594, 1
  %1596 = xor i8 %1595, 1
  store i8 %1596, i8* %25, align 1, !tbaa !2446
  %1597 = xor i32 %1586, %1585
  %1598 = lshr i32 %1597, 4
  %1599 = trunc i32 %1598 to i8
  %1600 = and i8 %1599, 1
  store i8 %1600, i8* %30, align 1, !tbaa !2447
  %1601 = zext i1 %1589 to i8
  store i8 %1601, i8* %33, align 1, !tbaa !2448
  %1602 = lshr i32 %1586, 31
  %1603 = trunc i32 %1602 to i8
  store i8 %1603, i8* %36, align 1, !tbaa !2449
  %1604 = lshr i32 %1585, 31
  %1605 = xor i32 %1602, %1604
  %1606 = add nuw nsw i32 %1605, %1602
  %1607 = icmp eq i32 %1606, 2
  %1608 = zext i1 %1607 to i8
  store i8 %1608, i8* %42, align 1, !tbaa !2450
  %1609 = add i64 %1582, 9
  store i64 %1609, i64* %PC, align 8
  store i32 %1586, i32* %1584, align 4
  %1610 = load i64, i64* %PC, align 8
  %1611 = add i64 %1610, -87
  store i64 %1611, i64* %PC, align 8, !tbaa !2428
  br label %block_400a7f

block_400a02:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2
  store i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 112), i64* %RDI, align 8, !tbaa !2428
  %1612 = load i64, i64* %RBP, align 8
  %1613 = add i64 %1612, -96
  %1614 = add i64 %411, 15
  store i64 %1614, i64* %PC, align 8
  %1615 = inttoptr i64 %1613 to i64*
  %1616 = load i64, i64* %1615, align 8
  store i64 %1616, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  store i8 1, i8* %AL, align 1, !tbaa !2453
  %1617 = add i64 %411, -802
  %1618 = add i64 %411, 22
  %1619 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1620 = add i64 %1619, -8
  %1621 = inttoptr i64 %1620 to i64*
  store i64 %1618, i64* %1621, align 8
  store i64 %1620, i64* %RSP, align 8, !tbaa !2428
  store i64 %1617, i64* %PC, align 8, !tbaa !2428
  %1622 = tail call fastcc %struct.Memory* @ext_4006e0_printf(%struct.State* nonnull %0, %struct.Memory* %406)
  %1623 = load i64, i64* %RBP, align 8
  %1624 = add i64 %1623, -156
  %1625 = load i32, i32* %EAX, align 4
  %1626 = load i64, i64* %PC, align 8
  %1627 = add i64 %1626, 6
  store i64 %1627, i64* %PC, align 8
  %1628 = inttoptr i64 %1624 to i32*
  store i32 %1625, i32* %1628, align 4
  %1629 = load i64, i64* %PC, align 8
  %1630 = add i64 %1629, -862
  %1631 = add i64 %1629, 5
  %1632 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1633 = add i64 %1632, -8
  %1634 = inttoptr i64 %1633 to i64*
  store i64 %1631, i64* %1634, align 8
  store i64 %1633, i64* %RSP, align 8, !tbaa !2428
  store i64 %1630, i64* %PC, align 8, !tbaa !2428
  %1635 = tail call fastcc %struct.Memory* @ext_4006c0_abort(%struct.State* nonnull %0, %struct.Memory* %1622)
  %1636 = load i64, i64* %PC, align 8
  %1637 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull %0, i64 %1636, %struct.Memory* %1635)
  ret %struct.Memory* %1637
}

; Function Attrs: noinline norecurse nounwind
define %struct.Memory* @sub_404090___libc_csu_fini(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #9 {
block_404090:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = add i64 %1, 2
  store i64 %3, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !2428
  %6 = inttoptr i64 %5 to i64*
  %7 = load i64, i64* %6, align 8
  store i64 %7, i64* %PC, align 8, !tbaa !2428
  %8 = add i64 %5, 8
  store i64 %8, i64* %4, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_401870_cftfsub(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone) local_unnamed_addr #8 {
block_401870:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -120
  store i64 %11, i64* %RSP, align 8, !tbaa !2428
  %12 = icmp ult i64 %8, 112
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1, !tbaa !2432
  %15 = trunc i64 %11 to i32
  %16 = and i32 %15, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16) #14
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1, !tbaa !2446
  %22 = xor i64 %8, 16
  %23 = xor i64 %22, %11
  %24 = lshr i64 %23, 4
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1, !tbaa !2447
  %28 = icmp eq i64 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1, !tbaa !2448
  %31 = lshr i64 %11, 63
  %32 = trunc i64 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1, !tbaa !2449
  %34 = lshr i64 %8, 63
  %35 = xor i64 %31, %34
  %36 = add nuw nsw i64 %35, %34
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1, !tbaa !2450
  %40 = add i64 %7, -12
  %41 = load i32, i32* %EDI, align 4
  %42 = add i64 %10, 10
  store i64 %42, i64* %PC, align 8
  %43 = inttoptr i64 %40 to i32*
  store i32 %41, i32* %43, align 4
  %44 = load i64, i64* %RBP, align 8
  %45 = add i64 %44, -16
  %46 = load i64, i64* %RSI, align 8
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 4
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %45 to i64*
  store i64 %46, i64* %49, align 8
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -24
  %52 = load i64, i64* %RDX, align 8
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 4
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %51 to i64*
  store i64 %52, i64* %55, align 8
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -44
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 7
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %57 to i32*
  store i32 2, i32* %60, align 4
  %61 = load i64, i64* %RBP, align 8
  %62 = add i64 %61, -4
  %63 = load i64, i64* %PC, align 8
  %64 = add i64 %63, 4
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %62 to i32*
  %66 = load i32, i32* %65, align 4
  %67 = add i32 %66, -8
  %68 = icmp ult i32 %66, 8
  %69 = zext i1 %68 to i8
  store i8 %69, i8* %14, align 1, !tbaa !2432
  %70 = and i32 %67, 255
  %71 = tail call i32 @llvm.ctpop.i32(i32 %70) #14
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  %74 = xor i8 %73, 1
  store i8 %74, i8* %21, align 1, !tbaa !2446
  %75 = xor i32 %67, %66
  %76 = lshr i32 %75, 4
  %77 = trunc i32 %76 to i8
  %78 = and i8 %77, 1
  store i8 %78, i8* %27, align 1, !tbaa !2447
  %79 = icmp eq i32 %67, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %30, align 1, !tbaa !2448
  %81 = lshr i32 %67, 31
  %82 = trunc i32 %81 to i8
  store i8 %82, i8* %33, align 1, !tbaa !2449
  %83 = lshr i32 %66, 31
  %84 = xor i32 %81, %83
  %85 = add nuw nsw i32 %84, %83
  %86 = icmp eq i32 %85, 2
  %87 = zext i1 %86 to i8
  store i8 %87, i8* %39, align 1, !tbaa !2450
  %88 = icmp ne i8 %82, 0
  %89 = xor i1 %88, %86
  %90 = or i1 %79, %89
  %.v14 = select i1 %90, i64 86, i64 10
  %91 = add i64 %63, %.v14
  store i64 %91, i64* %PC, align 8, !tbaa !2428
  br i1 %90, label %block_4018e0, label %block_401894

block_4018db:                                     ; preds = %block_4018ab
  %92 = add i64 %561, 5
  store i64 %92, i64* %PC, align 8, !tbaa !2428
  br label %block_4018e0

block_401894:                                     ; preds = %block_401870
  %93 = add i64 %91, 3
  store i64 %93, i64* %PC, align 8
  %94 = load i32, i32* %65, align 4
  %95 = zext i32 %94 to i64
  store i64 %95, i64* %RDI, align 8, !tbaa !2428
  %96 = add i64 %61, -16
  %97 = add i64 %91, 7
  store i64 %97, i64* %PC, align 8
  %98 = inttoptr i64 %96 to i64*
  %99 = load i64, i64* %98, align 8
  store i64 %99, i64* %RSI, align 8, !tbaa !2428
  %100 = add i64 %61, -24
  %101 = add i64 %91, 11
  store i64 %101, i64* %PC, align 8
  %102 = inttoptr i64 %100 to i64*
  %103 = load i64, i64* %102, align 8
  store i64 %103, i64* %RDX, align 8, !tbaa !2428
  %104 = add i64 %91, 4108
  %105 = add i64 %91, 16
  %106 = load i64, i64* %RSP, align 8, !tbaa !2428
  %107 = add i64 %106, -8
  %108 = inttoptr i64 %107 to i64*
  store i64 %105, i64* %108, align 8
  store i64 %107, i64* %RSP, align 8, !tbaa !2428
  store i64 %104, i64* %PC, align 8, !tbaa !2428
  %109 = tail call %struct.Memory* @sub_4028a0_cft1st_renamed_(%struct.State* nonnull %0, i64 %104, %struct.Memory* %2)
  %110 = load i64, i64* %RBP, align 8
  %111 = add i64 %110, -44
  %112 = load i64, i64* %PC, align 8
  %113 = add i64 %112, 7
  store i64 %113, i64* %PC, align 8
  %114 = inttoptr i64 %111 to i32*
  store i32 8, i32* %114, align 4
  %.pre = load i64, i64* %PC, align 8
  br label %block_4018ab

block_4018ba:                                     ; preds = %block_4018ab
  %115 = add i64 %561, 3
  store i64 %115, i64* %PC, align 8
  %116 = load i32, i32* %532, align 4
  %117 = zext i32 %116 to i64
  store i64 %117, i64* %RDI, align 8, !tbaa !2428
  %118 = add i64 %561, 6
  store i64 %118, i64* %PC, align 8
  %119 = load i32, i32* %513, align 4
  %120 = zext i32 %119 to i64
  store i64 %120, i64* %RSI, align 8, !tbaa !2428
  %121 = add i64 %510, -16
  %122 = add i64 %561, 10
  store i64 %122, i64* %PC, align 8
  %123 = inttoptr i64 %121 to i64*
  %124 = load i64, i64* %123, align 8
  store i64 %124, i64* %RDX, align 8, !tbaa !2428
  %125 = add i64 %510, -24
  %126 = add i64 %561, 14
  store i64 %126, i64* %PC, align 8
  %127 = inttoptr i64 %125 to i64*
  %128 = load i64, i64* %127, align 8
  store i64 %128, i64* %RCX, align 8, !tbaa !2428
  %129 = add i64 %561, 6774
  %130 = add i64 %561, 19
  %131 = load i64, i64* %RSP, align 8, !tbaa !2428
  %132 = add i64 %131, -8
  %133 = inttoptr i64 %132 to i64*
  store i64 %130, i64* %133, align 8
  store i64 %132, i64* %RSP, align 8, !tbaa !2428
  store i64 %129, i64* %PC, align 8, !tbaa !2428
  %134 = tail call %struct.Memory* @sub_403330_cftmdl_renamed_(%struct.State* nonnull %0, i64 %129, %struct.Memory* %109)
  %135 = load i64, i64* %RBP, align 8
  %136 = add i64 %135, -44
  %137 = load i64, i64* %PC, align 8
  %138 = add i64 %137, 3
  store i64 %138, i64* %PC, align 8
  %139 = inttoptr i64 %136 to i32*
  %140 = load i32, i32* %139, align 4
  %141 = shl i32 %140, 2
  %142 = zext i32 %141 to i64
  store i64 %142, i64* %RSI, align 8, !tbaa !2428
  %143 = lshr i32 %140, 30
  %144 = trunc i32 %143 to i8
  %145 = and i8 %144, 1
  store i8 %145, i8* %14, align 1, !tbaa !2453
  %146 = and i32 %141, 252
  %147 = tail call i32 @llvm.ctpop.i32(i32 %146) #14
  %148 = trunc i32 %147 to i8
  %149 = and i8 %148, 1
  %150 = xor i8 %149, 1
  store i8 %150, i8* %21, align 1, !tbaa !2453
  store i8 0, i8* %27, align 1, !tbaa !2453
  %151 = icmp eq i32 %141, 0
  %152 = zext i1 %151 to i8
  store i8 %152, i8* %30, align 1, !tbaa !2453
  %153 = lshr i32 %140, 29
  %154 = trunc i32 %153 to i8
  %155 = and i8 %154, 1
  store i8 %155, i8* %33, align 1, !tbaa !2453
  store i8 0, i8* %39, align 1, !tbaa !2453
  %156 = add i64 %137, 9
  store i64 %156, i64* %PC, align 8
  store i32 %141, i32* %139, align 4
  %157 = load i64, i64* %PC, align 8
  %158 = add i64 %157, -43
  store i64 %158, i64* %PC, align 8, !tbaa !2428
  br label %block_4018ab

block_401b2f:                                     ; preds = %block_401b23
  %159 = add i64 %671, 3
  store i64 %159, i64* %PC, align 8
  %160 = load i32, i32* %638, align 4
  %161 = zext i32 %160 to i64
  store i64 %161, i64* %RAX, align 8, !tbaa !2428
  %162 = add i64 %671, 6
  store i64 %162, i64* %PC, align 8
  %163 = load i32, i32* %643, align 4
  %164 = add i32 %163, %160
  %165 = zext i32 %164 to i64
  store i64 %165, i64* %RAX, align 8, !tbaa !2428
  %166 = icmp ult i32 %164, %160
  %167 = icmp ult i32 %164, %163
  %168 = or i1 %166, %167
  %169 = zext i1 %168 to i8
  store i8 %169, i8* %14, align 1, !tbaa !2432
  %170 = and i32 %164, 255
  %171 = tail call i32 @llvm.ctpop.i32(i32 %170) #14
  %172 = trunc i32 %171 to i8
  %173 = and i8 %172, 1
  %174 = xor i8 %173, 1
  store i8 %174, i8* %21, align 1, !tbaa !2446
  %175 = xor i32 %163, %160
  %176 = xor i32 %175, %164
  %177 = lshr i32 %176, 4
  %178 = trunc i32 %177 to i8
  %179 = and i8 %178, 1
  store i8 %179, i8* %27, align 1, !tbaa !2447
  %180 = icmp eq i32 %164, 0
  %181 = zext i1 %180 to i8
  store i8 %181, i8* %30, align 1, !tbaa !2448
  %182 = lshr i32 %164, 31
  %183 = trunc i32 %182 to i8
  store i8 %183, i8* %33, align 1, !tbaa !2449
  %184 = lshr i32 %160, 31
  %185 = lshr i32 %163, 31
  %186 = xor i32 %182, %184
  %187 = xor i32 %182, %185
  %188 = add nuw nsw i32 %186, %187
  %189 = icmp eq i32 %188, 2
  %190 = zext i1 %189 to i8
  store i8 %190, i8* %39, align 1, !tbaa !2450
  %191 = add i64 %635, -32
  %192 = add i64 %671, 9
  store i64 %192, i64* %PC, align 8
  %193 = inttoptr i64 %191 to i32*
  store i32 %164, i32* %193, align 4
  %194 = load i64, i64* %RBP, align 8
  %195 = add i64 %194, -16
  %196 = load i64, i64* %PC, align 8
  %197 = add i64 %196, 4
  store i64 %197, i64* %PC, align 8
  %198 = inttoptr i64 %195 to i64*
  %199 = load i64, i64* %198, align 8
  store i64 %199, i64* %RCX, align 8, !tbaa !2428
  %200 = add i64 %194, -28
  %201 = add i64 %196, 8
  store i64 %201, i64* %PC, align 8
  %202 = inttoptr i64 %200 to i32*
  %203 = load i32, i32* %202, align 4
  %204 = sext i32 %203 to i64
  store i64 %204, i64* %RDX, align 8, !tbaa !2428
  %205 = shl nsw i64 %204, 3
  %206 = add i64 %205, %199
  %207 = add i64 %196, 13
  store i64 %207, i64* %PC, align 8
  %208 = inttoptr i64 %206 to i64*
  %209 = load i64, i64* %208, align 8
  store i64 %209, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %210 = add i64 %196, 17
  store i64 %210, i64* %PC, align 8
  %211 = load i64, i64* %198, align 8
  store i64 %211, i64* %RCX, align 8, !tbaa !2428
  %212 = add i64 %194, -32
  %213 = add i64 %196, 21
  store i64 %213, i64* %PC, align 8
  %214 = inttoptr i64 %212 to i32*
  %215 = load i32, i32* %214, align 4
  %216 = sext i32 %215 to i64
  store i64 %216, i64* %RDX, align 8, !tbaa !2428
  %217 = shl nsw i64 %216, 3
  %218 = add i64 %217, %211
  %219 = add i64 %196, 26
  store i64 %219, i64* %PC, align 8
  %220 = bitcast i64 %209 to double
  %221 = inttoptr i64 %218 to double*
  %222 = load double, double* %221, align 8
  %223 = fsub double %220, %222
  store double %223, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %224 = add i64 %194, -56
  %225 = add i64 %196, 31
  store i64 %225, i64* %PC, align 8
  %226 = inttoptr i64 %224 to double*
  store double %223, double* %226, align 8
  %227 = load i64, i64* %RBP, align 8
  %228 = add i64 %227, -16
  %229 = load i64, i64* %PC, align 8
  %230 = add i64 %229, 4
  store i64 %230, i64* %PC, align 8
  %231 = inttoptr i64 %228 to i64*
  %232 = load i64, i64* %231, align 8
  store i64 %232, i64* %RCX, align 8, !tbaa !2428
  %233 = add i64 %227, -28
  %234 = add i64 %229, 7
  store i64 %234, i64* %PC, align 8
  %235 = inttoptr i64 %233 to i32*
  %236 = load i32, i32* %235, align 4
  %237 = add i32 %236, 1
  %238 = zext i32 %237 to i64
  store i64 %238, i64* %RAX, align 8, !tbaa !2428
  %239 = icmp eq i32 %236, -1
  %240 = icmp eq i32 %237, 0
  %241 = or i1 %239, %240
  %242 = zext i1 %241 to i8
  store i8 %242, i8* %14, align 1, !tbaa !2432
  %243 = and i32 %237, 255
  %244 = tail call i32 @llvm.ctpop.i32(i32 %243) #14
  %245 = trunc i32 %244 to i8
  %246 = and i8 %245, 1
  %247 = xor i8 %246, 1
  store i8 %247, i8* %21, align 1, !tbaa !2446
  %248 = xor i32 %237, %236
  %249 = lshr i32 %248, 4
  %250 = trunc i32 %249 to i8
  %251 = and i8 %250, 1
  store i8 %251, i8* %27, align 1, !tbaa !2447
  %252 = zext i1 %240 to i8
  store i8 %252, i8* %30, align 1, !tbaa !2448
  %253 = lshr i32 %237, 31
  %254 = trunc i32 %253 to i8
  store i8 %254, i8* %33, align 1, !tbaa !2449
  %255 = lshr i32 %236, 31
  %256 = xor i32 %253, %255
  %257 = add nuw nsw i32 %256, %253
  %258 = icmp eq i32 %257, 2
  %259 = zext i1 %258 to i8
  store i8 %259, i8* %39, align 1, !tbaa !2450
  %260 = sext i32 %237 to i64
  store i64 %260, i64* %RDX, align 8, !tbaa !2428
  %261 = shl nsw i64 %260, 3
  %262 = add i64 %232, %261
  %263 = add i64 %229, 18
  store i64 %263, i64* %PC, align 8
  %264 = inttoptr i64 %262 to i64*
  %265 = load i64, i64* %264, align 8
  store i64 %265, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %266 = add i64 %229, 22
  store i64 %266, i64* %PC, align 8
  %267 = load i64, i64* %231, align 8
  store i64 %267, i64* %RCX, align 8, !tbaa !2428
  %268 = add i64 %227, -32
  %269 = add i64 %229, 25
  store i64 %269, i64* %PC, align 8
  %270 = inttoptr i64 %268 to i32*
  %271 = load i32, i32* %270, align 4
  %272 = add i32 %271, 1
  %273 = zext i32 %272 to i64
  store i64 %273, i64* %RAX, align 8, !tbaa !2428
  %274 = icmp eq i32 %271, -1
  %275 = icmp eq i32 %272, 0
  %276 = or i1 %274, %275
  %277 = zext i1 %276 to i8
  store i8 %277, i8* %14, align 1, !tbaa !2432
  %278 = and i32 %272, 255
  %279 = tail call i32 @llvm.ctpop.i32(i32 %278) #14
  %280 = trunc i32 %279 to i8
  %281 = and i8 %280, 1
  %282 = xor i8 %281, 1
  store i8 %282, i8* %21, align 1, !tbaa !2446
  %283 = xor i32 %272, %271
  %284 = lshr i32 %283, 4
  %285 = trunc i32 %284 to i8
  %286 = and i8 %285, 1
  store i8 %286, i8* %27, align 1, !tbaa !2447
  %287 = zext i1 %275 to i8
  store i8 %287, i8* %30, align 1, !tbaa !2448
  %288 = lshr i32 %272, 31
  %289 = trunc i32 %288 to i8
  store i8 %289, i8* %33, align 1, !tbaa !2449
  %290 = lshr i32 %271, 31
  %291 = xor i32 %288, %290
  %292 = add nuw nsw i32 %291, %288
  %293 = icmp eq i32 %292, 2
  %294 = zext i1 %293 to i8
  store i8 %294, i8* %39, align 1, !tbaa !2450
  %295 = sext i32 %272 to i64
  store i64 %295, i64* %RDX, align 8, !tbaa !2428
  %296 = shl nsw i64 %295, 3
  %297 = add i64 %267, %296
  %298 = add i64 %229, 36
  store i64 %298, i64* %PC, align 8
  %299 = bitcast i64 %265 to double
  %300 = inttoptr i64 %297 to double*
  %301 = load double, double* %300, align 8
  %302 = fsub double %299, %301
  store double %302, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %303 = load i64, i64* %RBP, align 8
  %304 = add i64 %303, -64
  %305 = add i64 %229, 41
  store i64 %305, i64* %PC, align 8
  %306 = inttoptr i64 %304 to double*
  store double %302, double* %306, align 8
  %307 = load i64, i64* %RBP, align 8
  %308 = add i64 %307, -16
  %309 = load i64, i64* %PC, align 8
  %310 = add i64 %309, 4
  store i64 %310, i64* %PC, align 8
  %311 = inttoptr i64 %308 to i64*
  %312 = load i64, i64* %311, align 8
  store i64 %312, i64* %RCX, align 8, !tbaa !2428
  %313 = add i64 %307, -32
  %314 = add i64 %309, 8
  store i64 %314, i64* %PC, align 8
  %315 = inttoptr i64 %313 to i32*
  %316 = load i32, i32* %315, align 4
  %317 = sext i32 %316 to i64
  store i64 %317, i64* %RDX, align 8, !tbaa !2428
  %318 = shl nsw i64 %317, 3
  %319 = add i64 %318, %312
  %320 = add i64 %309, 13
  store i64 %320, i64* %PC, align 8
  %321 = inttoptr i64 %319 to i64*
  %322 = load i64, i64* %321, align 8
  store i64 %322, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %323 = add i64 %309, 17
  store i64 %323, i64* %PC, align 8
  %324 = load i64, i64* %311, align 8
  store i64 %324, i64* %RCX, align 8, !tbaa !2428
  %325 = add i64 %307, -28
  %326 = add i64 %309, 21
  store i64 %326, i64* %PC, align 8
  %327 = inttoptr i64 %325 to i32*
  %328 = load i32, i32* %327, align 4
  %329 = sext i32 %328 to i64
  store i64 %329, i64* %RDX, align 8, !tbaa !2428
  %330 = shl nsw i64 %329, 3
  %331 = add i64 %330, %324
  %332 = add i64 %309, 26
  store i64 %332, i64* %PC, align 8
  %333 = bitcast i64 %322 to double
  %334 = inttoptr i64 %331 to double*
  %335 = load double, double* %334, align 8
  %336 = fadd double %333, %335
  store double %336, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %337 = add i64 %309, 31
  store i64 %337, i64* %PC, align 8
  %338 = inttoptr i64 %331 to double*
  store double %336, double* %338, align 8
  %339 = load i64, i64* %RBP, align 8
  %340 = add i64 %339, -16
  %341 = load i64, i64* %PC, align 8
  %342 = add i64 %341, 4
  store i64 %342, i64* %PC, align 8
  %343 = inttoptr i64 %340 to i64*
  %344 = load i64, i64* %343, align 8
  store i64 %344, i64* %RCX, align 8, !tbaa !2428
  %345 = add i64 %339, -32
  %346 = add i64 %341, 7
  store i64 %346, i64* %PC, align 8
  %347 = inttoptr i64 %345 to i32*
  %348 = load i32, i32* %347, align 4
  %349 = add i32 %348, 1
  %350 = zext i32 %349 to i64
  store i64 %350, i64* %RAX, align 8, !tbaa !2428
  %351 = icmp eq i32 %348, -1
  %352 = icmp eq i32 %349, 0
  %353 = or i1 %351, %352
  %354 = zext i1 %353 to i8
  store i8 %354, i8* %14, align 1, !tbaa !2432
  %355 = and i32 %349, 255
  %356 = tail call i32 @llvm.ctpop.i32(i32 %355) #14
  %357 = trunc i32 %356 to i8
  %358 = and i8 %357, 1
  %359 = xor i8 %358, 1
  store i8 %359, i8* %21, align 1, !tbaa !2446
  %360 = xor i32 %349, %348
  %361 = lshr i32 %360, 4
  %362 = trunc i32 %361 to i8
  %363 = and i8 %362, 1
  store i8 %363, i8* %27, align 1, !tbaa !2447
  %364 = zext i1 %352 to i8
  store i8 %364, i8* %30, align 1, !tbaa !2448
  %365 = lshr i32 %349, 31
  %366 = trunc i32 %365 to i8
  store i8 %366, i8* %33, align 1, !tbaa !2449
  %367 = lshr i32 %348, 31
  %368 = xor i32 %365, %367
  %369 = add nuw nsw i32 %368, %365
  %370 = icmp eq i32 %369, 2
  %371 = zext i1 %370 to i8
  store i8 %371, i8* %39, align 1, !tbaa !2450
  %372 = sext i32 %349 to i64
  store i64 %372, i64* %RDX, align 8, !tbaa !2428
  %373 = shl nsw i64 %372, 3
  %374 = add i64 %344, %373
  %375 = add i64 %341, 18
  store i64 %375, i64* %PC, align 8
  %376 = inttoptr i64 %374 to i64*
  %377 = load i64, i64* %376, align 8
  store i64 %377, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %378 = add i64 %341, 22
  store i64 %378, i64* %PC, align 8
  %379 = load i64, i64* %343, align 8
  store i64 %379, i64* %RCX, align 8, !tbaa !2428
  %380 = add i64 %339, -28
  %381 = add i64 %341, 25
  store i64 %381, i64* %PC, align 8
  %382 = inttoptr i64 %380 to i32*
  %383 = load i32, i32* %382, align 4
  %384 = add i32 %383, 1
  %385 = zext i32 %384 to i64
  store i64 %385, i64* %RAX, align 8, !tbaa !2428
  %386 = icmp eq i32 %383, -1
  %387 = icmp eq i32 %384, 0
  %388 = or i1 %386, %387
  %389 = zext i1 %388 to i8
  store i8 %389, i8* %14, align 1, !tbaa !2432
  %390 = and i32 %384, 255
  %391 = tail call i32 @llvm.ctpop.i32(i32 %390) #14
  %392 = trunc i32 %391 to i8
  %393 = and i8 %392, 1
  %394 = xor i8 %393, 1
  store i8 %394, i8* %21, align 1, !tbaa !2446
  %395 = xor i32 %384, %383
  %396 = lshr i32 %395, 4
  %397 = trunc i32 %396 to i8
  %398 = and i8 %397, 1
  store i8 %398, i8* %27, align 1, !tbaa !2447
  %399 = zext i1 %387 to i8
  store i8 %399, i8* %30, align 1, !tbaa !2448
  %400 = lshr i32 %384, 31
  %401 = trunc i32 %400 to i8
  store i8 %401, i8* %33, align 1, !tbaa !2449
  %402 = lshr i32 %383, 31
  %403 = xor i32 %400, %402
  %404 = add nuw nsw i32 %403, %400
  %405 = icmp eq i32 %404, 2
  %406 = zext i1 %405 to i8
  store i8 %406, i8* %39, align 1, !tbaa !2450
  %407 = sext i32 %384 to i64
  store i64 %407, i64* %RDX, align 8, !tbaa !2428
  %408 = shl nsw i64 %407, 3
  %409 = add i64 %379, %408
  %410 = add i64 %341, 36
  store i64 %410, i64* %PC, align 8
  %411 = bitcast i64 %377 to double
  %412 = inttoptr i64 %409 to double*
  %413 = load double, double* %412, align 8
  %414 = fadd double %411, %413
  store double %414, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %415 = add i64 %341, 41
  store i64 %415, i64* %PC, align 8
  %416 = inttoptr i64 %409 to double*
  store double %414, double* %416, align 8
  %417 = load i64, i64* %RBP, align 8
  %418 = add i64 %417, -56
  %419 = load i64, i64* %PC, align 8
  %420 = add i64 %419, 5
  store i64 %420, i64* %PC, align 8
  %421 = inttoptr i64 %418 to i64*
  %422 = load i64, i64* %421, align 8
  store i64 %422, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %423 = add i64 %417, -16
  %424 = add i64 %419, 9
  store i64 %424, i64* %PC, align 8
  %425 = inttoptr i64 %423 to i64*
  %426 = load i64, i64* %425, align 8
  store i64 %426, i64* %RCX, align 8, !tbaa !2428
  %427 = add i64 %417, -32
  %428 = add i64 %419, 13
  store i64 %428, i64* %PC, align 8
  %429 = inttoptr i64 %427 to i32*
  %430 = load i32, i32* %429, align 4
  %431 = sext i32 %430 to i64
  store i64 %431, i64* %RDX, align 8, !tbaa !2428
  %432 = shl nsw i64 %431, 3
  %433 = add i64 %432, %426
  %434 = add i64 %419, 18
  store i64 %434, i64* %PC, align 8
  %435 = inttoptr i64 %433 to i64*
  store i64 %422, i64* %435, align 8
  %436 = load i64, i64* %RBP, align 8
  %437 = add i64 %436, -64
  %438 = load i64, i64* %PC, align 8
  %439 = add i64 %438, 5
  store i64 %439, i64* %PC, align 8
  %440 = inttoptr i64 %437 to i64*
  %441 = load i64, i64* %440, align 8
  store i64 %441, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %442 = add i64 %436, -16
  %443 = add i64 %438, 9
  store i64 %443, i64* %PC, align 8
  %444 = inttoptr i64 %442 to i64*
  %445 = load i64, i64* %444, align 8
  store i64 %445, i64* %RCX, align 8, !tbaa !2428
  %446 = add i64 %436, -32
  %447 = add i64 %438, 12
  store i64 %447, i64* %PC, align 8
  %448 = inttoptr i64 %446 to i32*
  %449 = load i32, i32* %448, align 4
  %450 = add i32 %449, 1
  %451 = zext i32 %450 to i64
  store i64 %451, i64* %RAX, align 8, !tbaa !2428
  %452 = icmp eq i32 %449, -1
  %453 = icmp eq i32 %450, 0
  %454 = or i1 %452, %453
  %455 = zext i1 %454 to i8
  store i8 %455, i8* %14, align 1, !tbaa !2432
  %456 = and i32 %450, 255
  %457 = tail call i32 @llvm.ctpop.i32(i32 %456) #14
  %458 = trunc i32 %457 to i8
  %459 = and i8 %458, 1
  %460 = xor i8 %459, 1
  store i8 %460, i8* %21, align 1, !tbaa !2446
  %461 = xor i32 %450, %449
  %462 = lshr i32 %461, 4
  %463 = trunc i32 %462 to i8
  %464 = and i8 %463, 1
  store i8 %464, i8* %27, align 1, !tbaa !2447
  %465 = zext i1 %453 to i8
  store i8 %465, i8* %30, align 1, !tbaa !2448
  %466 = lshr i32 %450, 31
  %467 = trunc i32 %466 to i8
  store i8 %467, i8* %33, align 1, !tbaa !2449
  %468 = lshr i32 %449, 31
  %469 = xor i32 %466, %468
  %470 = add nuw nsw i32 %469, %466
  %471 = icmp eq i32 %470, 2
  %472 = zext i1 %471 to i8
  store i8 %472, i8* %39, align 1, !tbaa !2450
  %473 = sext i32 %450 to i64
  store i64 %473, i64* %RDX, align 8, !tbaa !2428
  %474 = shl nsw i64 %473, 3
  %475 = add i64 %445, %474
  %476 = add i64 %438, 23
  store i64 %476, i64* %PC, align 8
  %477 = inttoptr i64 %475 to i64*
  store i64 %441, i64* %477, align 8
  %478 = load i64, i64* %RBP, align 8
  %479 = add i64 %478, -28
  %480 = load i64, i64* %PC, align 8
  %481 = add i64 %480, 3
  store i64 %481, i64* %PC, align 8
  %482 = inttoptr i64 %479 to i32*
  %483 = load i32, i32* %482, align 4
  %484 = add i32 %483, 2
  %485 = zext i32 %484 to i64
  store i64 %485, i64* %RAX, align 8, !tbaa !2428
  %486 = icmp ugt i32 %483, -3
  %487 = zext i1 %486 to i8
  store i8 %487, i8* %14, align 1, !tbaa !2432
  %488 = and i32 %484, 255
  %489 = tail call i32 @llvm.ctpop.i32(i32 %488) #14
  %490 = trunc i32 %489 to i8
  %491 = and i8 %490, 1
  %492 = xor i8 %491, 1
  store i8 %492, i8* %21, align 1, !tbaa !2446
  %493 = xor i32 %484, %483
  %494 = lshr i32 %493, 4
  %495 = trunc i32 %494 to i8
  %496 = and i8 %495, 1
  store i8 %496, i8* %27, align 1, !tbaa !2447
  %497 = icmp eq i32 %484, 0
  %498 = zext i1 %497 to i8
  store i8 %498, i8* %30, align 1, !tbaa !2448
  %499 = lshr i32 %484, 31
  %500 = trunc i32 %499 to i8
  store i8 %500, i8* %33, align 1, !tbaa !2449
  %501 = lshr i32 %483, 31
  %502 = xor i32 %499, %501
  %503 = add nuw nsw i32 %502, %499
  %504 = icmp eq i32 %503, 2
  %505 = zext i1 %504 to i8
  store i8 %505, i8* %39, align 1, !tbaa !2450
  %506 = add i64 %480, 9
  store i64 %506, i64* %PC, align 8
  store i32 %484, i32* %482, align 4
  %507 = load i64, i64* %PC, align 8
  %508 = add i64 %507, -215
  store i64 %508, i64* %PC, align 8, !tbaa !2428
  br label %block_401b23

block_4018ab:                                     ; preds = %block_4018ba, %block_401894
  %509 = phi i64 [ %158, %block_4018ba ], [ %.pre, %block_401894 ]
  %510 = load i64, i64* %RBP, align 8
  %511 = add i64 %510, -44
  %512 = add i64 %509, 3
  store i64 %512, i64* %PC, align 8
  %513 = inttoptr i64 %511 to i32*
  %514 = load i32, i32* %513, align 4
  %515 = shl i32 %514, 2
  %516 = zext i32 %515 to i64
  store i64 %516, i64* %RAX, align 8, !tbaa !2428
  %517 = lshr i32 %514, 30
  %518 = trunc i32 %517 to i8
  %519 = and i8 %518, 1
  store i8 %519, i8* %14, align 1, !tbaa !2453
  %520 = and i32 %515, 252
  %521 = tail call i32 @llvm.ctpop.i32(i32 %520) #14
  %522 = trunc i32 %521 to i8
  %523 = and i8 %522, 1
  %524 = xor i8 %523, 1
  store i8 %524, i8* %21, align 1, !tbaa !2453
  store i8 0, i8* %27, align 1, !tbaa !2453
  %525 = icmp eq i32 %515, 0
  %526 = zext i1 %525 to i8
  store i8 %526, i8* %30, align 1, !tbaa !2453
  %527 = lshr i32 %514, 29
  %528 = trunc i32 %527 to i8
  %529 = and i8 %528, 1
  store i8 %529, i8* %33, align 1, !tbaa !2453
  store i8 0, i8* %39, align 1, !tbaa !2453
  %530 = add i64 %510, -4
  %531 = add i64 %509, 9
  store i64 %531, i64* %PC, align 8
  %532 = inttoptr i64 %530 to i32*
  %533 = load i32, i32* %532, align 4
  %534 = sub i32 %515, %533
  %535 = icmp ult i32 %515, %533
  %536 = zext i1 %535 to i8
  store i8 %536, i8* %14, align 1, !tbaa !2432
  %537 = and i32 %534, 255
  %538 = tail call i32 @llvm.ctpop.i32(i32 %537) #14
  %539 = trunc i32 %538 to i8
  %540 = and i8 %539, 1
  %541 = xor i8 %540, 1
  store i8 %541, i8* %21, align 1, !tbaa !2446
  %542 = xor i32 %533, %515
  %543 = xor i32 %542, %534
  %544 = lshr i32 %543, 4
  %545 = trunc i32 %544 to i8
  %546 = and i8 %545, 1
  store i8 %546, i8* %27, align 1, !tbaa !2447
  %547 = icmp eq i32 %534, 0
  %548 = zext i1 %547 to i8
  store i8 %548, i8* %30, align 1, !tbaa !2448
  %549 = lshr i32 %534, 31
  %550 = trunc i32 %549 to i8
  store i8 %550, i8* %33, align 1, !tbaa !2449
  %551 = lshr i32 %514, 29
  %552 = and i32 %551, 1
  %553 = lshr i32 %533, 31
  %554 = xor i32 %553, %552
  %555 = xor i32 %549, %552
  %556 = add nuw nsw i32 %555, %554
  %557 = icmp eq i32 %556, 2
  %558 = zext i1 %557 to i8
  store i8 %558, i8* %39, align 1, !tbaa !2450
  %559 = icmp ne i8 %550, 0
  %560 = xor i1 %559, %557
  %.v15 = select i1 %560, i64 15, i64 48
  %561 = add i64 %509, %.v15
  store i64 %561, i64* %PC, align 8, !tbaa !2428
  br i1 %560, label %block_4018ba, label %block_4018db

block_4018f6:                                     ; preds = %block_4018f6.preheader, %block_401902
  %562 = phi i64 [ %1563, %block_401902 ], [ %.pre12, %block_4018f6.preheader ]
  %563 = load i64, i64* %RBP, align 8
  %564 = add i64 %563, -28
  %565 = add i64 %562, 3
  store i64 %565, i64* %PC, align 8
  %566 = inttoptr i64 %564 to i32*
  %567 = load i32, i32* %566, align 4
  %568 = zext i32 %567 to i64
  store i64 %568, i64* %RAX, align 8, !tbaa !2428
  %569 = add i64 %563, -44
  %570 = add i64 %562, 6
  store i64 %570, i64* %PC, align 8
  %571 = inttoptr i64 %569 to i32*
  %572 = load i32, i32* %571, align 4
  %573 = sub i32 %567, %572
  %574 = icmp ult i32 %567, %572
  %575 = zext i1 %574 to i8
  store i8 %575, i8* %14, align 1, !tbaa !2432
  %576 = and i32 %573, 255
  %577 = tail call i32 @llvm.ctpop.i32(i32 %576) #14
  %578 = trunc i32 %577 to i8
  %579 = and i8 %578, 1
  %580 = xor i8 %579, 1
  store i8 %580, i8* %21, align 1, !tbaa !2446
  %581 = xor i32 %572, %567
  %582 = xor i32 %581, %573
  %583 = lshr i32 %582, 4
  %584 = trunc i32 %583 to i8
  %585 = and i8 %584, 1
  store i8 %585, i8* %27, align 1, !tbaa !2447
  %586 = icmp eq i32 %573, 0
  %587 = zext i1 %586 to i8
  store i8 %587, i8* %30, align 1, !tbaa !2448
  %588 = lshr i32 %573, 31
  %589 = trunc i32 %588 to i8
  store i8 %589, i8* %33, align 1, !tbaa !2449
  %590 = lshr i32 %567, 31
  %591 = lshr i32 %572, 31
  %592 = xor i32 %591, %590
  %593 = xor i32 %588, %590
  %594 = add nuw nsw i32 %593, %592
  %595 = icmp eq i32 %594, 2
  %596 = zext i1 %595 to i8
  store i8 %596, i8* %39, align 1, !tbaa !2450
  %597 = icmp ne i8 %589, 0
  %598 = xor i1 %597, %595
  %.v17 = select i1 %598, i64 12, i64 545
  %599 = add i64 %562, %.v17
  store i64 %599, i64* %PC, align 8, !tbaa !2428
  br i1 %598, label %block_401902, label %block_401c04.loopexit

block_401c04.loopexit:                            ; preds = %block_4018f6
  br label %block_401c04

block_401c04.loopexit26:                          ; preds = %block_401b23
  br label %block_401c04

block_401c04:                                     ; preds = %block_401c04.loopexit26, %block_401c04.loopexit
  %600 = phi i64 [ %599, %block_401c04.loopexit ], [ %671, %block_401c04.loopexit26 ]
  %.sink5 = phi i64 [ 237, %block_401c04.loopexit ], [ 5, %block_401c04.loopexit26 ]
  %601 = add i64 %600, %.sink5
  %602 = load i64, i64* %RSP, align 8
  %603 = add i64 %602, 112
  store i64 %603, i64* %RSP, align 8, !tbaa !2428
  %604 = icmp ugt i64 %602, -113
  %605 = zext i1 %604 to i8
  store i8 %605, i8* %14, align 1, !tbaa !2432
  %606 = trunc i64 %603 to i32
  %607 = and i32 %606, 255
  %608 = tail call i32 @llvm.ctpop.i32(i32 %607) #14
  %609 = trunc i32 %608 to i8
  %610 = and i8 %609, 1
  %611 = xor i8 %610, 1
  store i8 %611, i8* %21, align 1, !tbaa !2446
  %612 = xor i64 %602, 16
  %613 = xor i64 %612, %603
  %614 = lshr i64 %613, 4
  %615 = trunc i64 %614 to i8
  %616 = and i8 %615, 1
  store i8 %616, i8* %27, align 1, !tbaa !2447
  %617 = icmp eq i64 %603, 0
  %618 = zext i1 %617 to i8
  store i8 %618, i8* %30, align 1, !tbaa !2448
  %619 = lshr i64 %603, 63
  %620 = trunc i64 %619 to i8
  store i8 %620, i8* %33, align 1, !tbaa !2449
  %621 = lshr i64 %602, 63
  %622 = xor i64 %619, %621
  %623 = add nuw nsw i64 %622, %619
  %624 = icmp eq i64 %623, 2
  %625 = zext i1 %624 to i8
  store i8 %625, i8* %39, align 1, !tbaa !2450
  %626 = add i64 %601, 5
  store i64 %626, i64* %PC, align 8
  %627 = add i64 %602, 120
  %628 = inttoptr i64 %603 to i64*
  %629 = load i64, i64* %628, align 8
  store i64 %629, i64* %RBP, align 8, !tbaa !2428
  store i64 %627, i64* %RSP, align 8, !tbaa !2428
  %630 = add i64 %601, 6
  store i64 %630, i64* %PC, align 8
  %631 = inttoptr i64 %627 to i64*
  %632 = load i64, i64* %631, align 8
  store i64 %632, i64* %PC, align 8, !tbaa !2428
  %633 = add i64 %602, 128
  store i64 %633, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.4

block_401b23:                                     ; preds = %block_401b23.preheader, %block_401b2f
  %634 = phi i64 [ %508, %block_401b2f ], [ %.pre12, %block_401b23.preheader ]
  %635 = load i64, i64* %RBP, align 8
  %636 = add i64 %635, -28
  %637 = add i64 %634, 3
  store i64 %637, i64* %PC, align 8
  %638 = inttoptr i64 %636 to i32*
  %639 = load i32, i32* %638, align 4
  %640 = zext i32 %639 to i64
  store i64 %640, i64* %RAX, align 8, !tbaa !2428
  %641 = add i64 %635, -44
  %642 = add i64 %634, 6
  store i64 %642, i64* %PC, align 8
  %643 = inttoptr i64 %641 to i32*
  %644 = load i32, i32* %643, align 4
  %645 = sub i32 %639, %644
  %646 = icmp ult i32 %639, %644
  %647 = zext i1 %646 to i8
  store i8 %647, i8* %14, align 1, !tbaa !2432
  %648 = and i32 %645, 255
  %649 = tail call i32 @llvm.ctpop.i32(i32 %648) #14
  %650 = trunc i32 %649 to i8
  %651 = and i8 %650, 1
  %652 = xor i8 %651, 1
  store i8 %652, i8* %21, align 1, !tbaa !2446
  %653 = xor i32 %644, %639
  %654 = xor i32 %653, %645
  %655 = lshr i32 %654, 4
  %656 = trunc i32 %655 to i8
  %657 = and i8 %656, 1
  store i8 %657, i8* %27, align 1, !tbaa !2447
  %658 = icmp eq i32 %645, 0
  %659 = zext i1 %658 to i8
  store i8 %659, i8* %30, align 1, !tbaa !2448
  %660 = lshr i32 %645, 31
  %661 = trunc i32 %660 to i8
  store i8 %661, i8* %33, align 1, !tbaa !2449
  %662 = lshr i32 %639, 31
  %663 = lshr i32 %644, 31
  %664 = xor i32 %663, %662
  %665 = xor i32 %660, %662
  %666 = add nuw nsw i32 %665, %664
  %667 = icmp eq i32 %666, 2
  %668 = zext i1 %667 to i8
  store i8 %668, i8* %39, align 1, !tbaa !2450
  %669 = icmp ne i8 %661, 0
  %670 = xor i1 %669, %667
  %.v16 = select i1 %670, i64 12, i64 220
  %671 = add i64 %634, %.v16
  store i64 %671, i64* %PC, align 8, !tbaa !2428
  br i1 %670, label %block_401b2f, label %block_401c04.loopexit26

block_401902:                                     ; preds = %block_4018f6
  %672 = add i64 %599, 3
  store i64 %672, i64* %PC, align 8
  %673 = load i32, i32* %566, align 4
  %674 = zext i32 %673 to i64
  store i64 %674, i64* %RAX, align 8, !tbaa !2428
  %675 = add i64 %599, 6
  store i64 %675, i64* %PC, align 8
  %676 = load i32, i32* %571, align 4
  %677 = add i32 %676, %673
  %678 = zext i32 %677 to i64
  store i64 %678, i64* %RAX, align 8, !tbaa !2428
  %679 = icmp ult i32 %677, %673
  %680 = icmp ult i32 %677, %676
  %681 = or i1 %679, %680
  %682 = zext i1 %681 to i8
  store i8 %682, i8* %14, align 1, !tbaa !2432
  %683 = and i32 %677, 255
  %684 = tail call i32 @llvm.ctpop.i32(i32 %683) #14
  %685 = trunc i32 %684 to i8
  %686 = and i8 %685, 1
  %687 = xor i8 %686, 1
  store i8 %687, i8* %21, align 1, !tbaa !2446
  %688 = xor i32 %676, %673
  %689 = xor i32 %688, %677
  %690 = lshr i32 %689, 4
  %691 = trunc i32 %690 to i8
  %692 = and i8 %691, 1
  store i8 %692, i8* %27, align 1, !tbaa !2447
  %693 = icmp eq i32 %677, 0
  %694 = zext i1 %693 to i8
  store i8 %694, i8* %30, align 1, !tbaa !2448
  %695 = lshr i32 %677, 31
  %696 = trunc i32 %695 to i8
  store i8 %696, i8* %33, align 1, !tbaa !2449
  %697 = lshr i32 %673, 31
  %698 = lshr i32 %676, 31
  %699 = xor i32 %695, %697
  %700 = xor i32 %695, %698
  %701 = add nuw nsw i32 %699, %700
  %702 = icmp eq i32 %701, 2
  %703 = zext i1 %702 to i8
  store i8 %703, i8* %39, align 1, !tbaa !2450
  %704 = add i64 %563, -32
  %705 = add i64 %599, 9
  store i64 %705, i64* %PC, align 8
  %706 = inttoptr i64 %704 to i32*
  store i32 %677, i32* %706, align 4
  %707 = load i64, i64* %RBP, align 8
  %708 = add i64 %707, -32
  %709 = load i64, i64* %PC, align 8
  %710 = add i64 %709, 3
  store i64 %710, i64* %PC, align 8
  %711 = inttoptr i64 %708 to i32*
  %712 = load i32, i32* %711, align 4
  %713 = zext i32 %712 to i64
  store i64 %713, i64* %RAX, align 8, !tbaa !2428
  %714 = add i64 %707, -44
  %715 = add i64 %709, 6
  store i64 %715, i64* %PC, align 8
  %716 = inttoptr i64 %714 to i32*
  %717 = load i32, i32* %716, align 4
  %718 = add i32 %717, %712
  %719 = zext i32 %718 to i64
  store i64 %719, i64* %RAX, align 8, !tbaa !2428
  %720 = icmp ult i32 %718, %712
  %721 = icmp ult i32 %718, %717
  %722 = or i1 %720, %721
  %723 = zext i1 %722 to i8
  store i8 %723, i8* %14, align 1, !tbaa !2432
  %724 = and i32 %718, 255
  %725 = tail call i32 @llvm.ctpop.i32(i32 %724) #14
  %726 = trunc i32 %725 to i8
  %727 = and i8 %726, 1
  %728 = xor i8 %727, 1
  store i8 %728, i8* %21, align 1, !tbaa !2446
  %729 = xor i32 %717, %712
  %730 = xor i32 %729, %718
  %731 = lshr i32 %730, 4
  %732 = trunc i32 %731 to i8
  %733 = and i8 %732, 1
  store i8 %733, i8* %27, align 1, !tbaa !2447
  %734 = icmp eq i32 %718, 0
  %735 = zext i1 %734 to i8
  store i8 %735, i8* %30, align 1, !tbaa !2448
  %736 = lshr i32 %718, 31
  %737 = trunc i32 %736 to i8
  store i8 %737, i8* %33, align 1, !tbaa !2449
  %738 = lshr i32 %712, 31
  %739 = lshr i32 %717, 31
  %740 = xor i32 %736, %738
  %741 = xor i32 %736, %739
  %742 = add nuw nsw i32 %740, %741
  %743 = icmp eq i32 %742, 2
  %744 = zext i1 %743 to i8
  store i8 %744, i8* %39, align 1, !tbaa !2450
  %745 = add i64 %707, -36
  %746 = add i64 %709, 9
  store i64 %746, i64* %PC, align 8
  %747 = inttoptr i64 %745 to i32*
  store i32 %718, i32* %747, align 4
  %748 = load i64, i64* %RBP, align 8
  %749 = add i64 %748, -36
  %750 = load i64, i64* %PC, align 8
  %751 = add i64 %750, 3
  store i64 %751, i64* %PC, align 8
  %752 = inttoptr i64 %749 to i32*
  %753 = load i32, i32* %752, align 4
  %754 = zext i32 %753 to i64
  store i64 %754, i64* %RAX, align 8, !tbaa !2428
  %755 = add i64 %748, -44
  %756 = add i64 %750, 6
  store i64 %756, i64* %PC, align 8
  %757 = inttoptr i64 %755 to i32*
  %758 = load i32, i32* %757, align 4
  %759 = add i32 %758, %753
  %760 = zext i32 %759 to i64
  store i64 %760, i64* %RAX, align 8, !tbaa !2428
  %761 = icmp ult i32 %759, %753
  %762 = icmp ult i32 %759, %758
  %763 = or i1 %761, %762
  %764 = zext i1 %763 to i8
  store i8 %764, i8* %14, align 1, !tbaa !2432
  %765 = and i32 %759, 255
  %766 = tail call i32 @llvm.ctpop.i32(i32 %765) #14
  %767 = trunc i32 %766 to i8
  %768 = and i8 %767, 1
  %769 = xor i8 %768, 1
  store i8 %769, i8* %21, align 1, !tbaa !2446
  %770 = xor i32 %758, %753
  %771 = xor i32 %770, %759
  %772 = lshr i32 %771, 4
  %773 = trunc i32 %772 to i8
  %774 = and i8 %773, 1
  store i8 %774, i8* %27, align 1, !tbaa !2447
  %775 = icmp eq i32 %759, 0
  %776 = zext i1 %775 to i8
  store i8 %776, i8* %30, align 1, !tbaa !2448
  %777 = lshr i32 %759, 31
  %778 = trunc i32 %777 to i8
  store i8 %778, i8* %33, align 1, !tbaa !2449
  %779 = lshr i32 %753, 31
  %780 = lshr i32 %758, 31
  %781 = xor i32 %777, %779
  %782 = xor i32 %777, %780
  %783 = add nuw nsw i32 %781, %782
  %784 = icmp eq i32 %783, 2
  %785 = zext i1 %784 to i8
  store i8 %785, i8* %39, align 1, !tbaa !2450
  %786 = add i64 %748, -40
  %787 = add i64 %750, 9
  store i64 %787, i64* %PC, align 8
  %788 = inttoptr i64 %786 to i32*
  store i32 %759, i32* %788, align 4
  %789 = load i64, i64* %RBP, align 8
  %790 = add i64 %789, -16
  %791 = load i64, i64* %PC, align 8
  %792 = add i64 %791, 4
  store i64 %792, i64* %PC, align 8
  %793 = inttoptr i64 %790 to i64*
  %794 = load i64, i64* %793, align 8
  store i64 %794, i64* %RCX, align 8, !tbaa !2428
  %795 = add i64 %789, -28
  %796 = add i64 %791, 8
  store i64 %796, i64* %PC, align 8
  %797 = inttoptr i64 %795 to i32*
  %798 = load i32, i32* %797, align 4
  %799 = sext i32 %798 to i64
  store i64 %799, i64* %RDX, align 8, !tbaa !2428
  %800 = shl nsw i64 %799, 3
  %801 = add i64 %800, %794
  %802 = add i64 %791, 13
  store i64 %802, i64* %PC, align 8
  %803 = inttoptr i64 %801 to i64*
  %804 = load i64, i64* %803, align 8
  store i64 %804, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %805 = add i64 %791, 17
  store i64 %805, i64* %PC, align 8
  %806 = load i64, i64* %793, align 8
  store i64 %806, i64* %RCX, align 8, !tbaa !2428
  %807 = add i64 %789, -32
  %808 = add i64 %791, 21
  store i64 %808, i64* %PC, align 8
  %809 = inttoptr i64 %807 to i32*
  %810 = load i32, i32* %809, align 4
  %811 = sext i32 %810 to i64
  store i64 %811, i64* %RDX, align 8, !tbaa !2428
  %812 = shl nsw i64 %811, 3
  %813 = add i64 %812, %806
  %814 = add i64 %791, 26
  store i64 %814, i64* %PC, align 8
  %815 = bitcast i64 %804 to double
  %816 = inttoptr i64 %813 to double*
  %817 = load double, double* %816, align 8
  %818 = fadd double %815, %817
  store double %818, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %819 = add i64 %789, -56
  %820 = add i64 %791, 31
  store i64 %820, i64* %PC, align 8
  %821 = inttoptr i64 %819 to double*
  store double %818, double* %821, align 8
  %822 = load i64, i64* %RBP, align 8
  %823 = add i64 %822, -16
  %824 = load i64, i64* %PC, align 8
  %825 = add i64 %824, 4
  store i64 %825, i64* %PC, align 8
  %826 = inttoptr i64 %823 to i64*
  %827 = load i64, i64* %826, align 8
  store i64 %827, i64* %RCX, align 8, !tbaa !2428
  %828 = add i64 %822, -28
  %829 = add i64 %824, 7
  store i64 %829, i64* %PC, align 8
  %830 = inttoptr i64 %828 to i32*
  %831 = load i32, i32* %830, align 4
  %832 = add i32 %831, 1
  %833 = zext i32 %832 to i64
  store i64 %833, i64* %RAX, align 8, !tbaa !2428
  %834 = icmp eq i32 %831, -1
  %835 = icmp eq i32 %832, 0
  %836 = or i1 %834, %835
  %837 = zext i1 %836 to i8
  store i8 %837, i8* %14, align 1, !tbaa !2432
  %838 = and i32 %832, 255
  %839 = tail call i32 @llvm.ctpop.i32(i32 %838) #14
  %840 = trunc i32 %839 to i8
  %841 = and i8 %840, 1
  %842 = xor i8 %841, 1
  store i8 %842, i8* %21, align 1, !tbaa !2446
  %843 = xor i32 %832, %831
  %844 = lshr i32 %843, 4
  %845 = trunc i32 %844 to i8
  %846 = and i8 %845, 1
  store i8 %846, i8* %27, align 1, !tbaa !2447
  %847 = zext i1 %835 to i8
  store i8 %847, i8* %30, align 1, !tbaa !2448
  %848 = lshr i32 %832, 31
  %849 = trunc i32 %848 to i8
  store i8 %849, i8* %33, align 1, !tbaa !2449
  %850 = lshr i32 %831, 31
  %851 = xor i32 %848, %850
  %852 = add nuw nsw i32 %851, %848
  %853 = icmp eq i32 %852, 2
  %854 = zext i1 %853 to i8
  store i8 %854, i8* %39, align 1, !tbaa !2450
  %855 = sext i32 %832 to i64
  store i64 %855, i64* %RDX, align 8, !tbaa !2428
  %856 = shl nsw i64 %855, 3
  %857 = add i64 %827, %856
  %858 = add i64 %824, 18
  store i64 %858, i64* %PC, align 8
  %859 = inttoptr i64 %857 to i64*
  %860 = load i64, i64* %859, align 8
  store i64 %860, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %861 = add i64 %824, 22
  store i64 %861, i64* %PC, align 8
  %862 = load i64, i64* %826, align 8
  store i64 %862, i64* %RCX, align 8, !tbaa !2428
  %863 = add i64 %822, -32
  %864 = add i64 %824, 25
  store i64 %864, i64* %PC, align 8
  %865 = inttoptr i64 %863 to i32*
  %866 = load i32, i32* %865, align 4
  %867 = add i32 %866, 1
  %868 = zext i32 %867 to i64
  store i64 %868, i64* %RAX, align 8, !tbaa !2428
  %869 = icmp eq i32 %866, -1
  %870 = icmp eq i32 %867, 0
  %871 = or i1 %869, %870
  %872 = zext i1 %871 to i8
  store i8 %872, i8* %14, align 1, !tbaa !2432
  %873 = and i32 %867, 255
  %874 = tail call i32 @llvm.ctpop.i32(i32 %873) #14
  %875 = trunc i32 %874 to i8
  %876 = and i8 %875, 1
  %877 = xor i8 %876, 1
  store i8 %877, i8* %21, align 1, !tbaa !2446
  %878 = xor i32 %867, %866
  %879 = lshr i32 %878, 4
  %880 = trunc i32 %879 to i8
  %881 = and i8 %880, 1
  store i8 %881, i8* %27, align 1, !tbaa !2447
  %882 = zext i1 %870 to i8
  store i8 %882, i8* %30, align 1, !tbaa !2448
  %883 = lshr i32 %867, 31
  %884 = trunc i32 %883 to i8
  store i8 %884, i8* %33, align 1, !tbaa !2449
  %885 = lshr i32 %866, 31
  %886 = xor i32 %883, %885
  %887 = add nuw nsw i32 %886, %883
  %888 = icmp eq i32 %887, 2
  %889 = zext i1 %888 to i8
  store i8 %889, i8* %39, align 1, !tbaa !2450
  %890 = sext i32 %867 to i64
  store i64 %890, i64* %RDX, align 8, !tbaa !2428
  %891 = shl nsw i64 %890, 3
  %892 = add i64 %862, %891
  %893 = add i64 %824, 36
  store i64 %893, i64* %PC, align 8
  %894 = bitcast i64 %860 to double
  %895 = inttoptr i64 %892 to double*
  %896 = load double, double* %895, align 8
  %897 = fadd double %894, %896
  store double %897, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %898 = load i64, i64* %RBP, align 8
  %899 = add i64 %898, -64
  %900 = add i64 %824, 41
  store i64 %900, i64* %PC, align 8
  %901 = inttoptr i64 %899 to double*
  store double %897, double* %901, align 8
  %902 = load i64, i64* %RBP, align 8
  %903 = add i64 %902, -16
  %904 = load i64, i64* %PC, align 8
  %905 = add i64 %904, 4
  store i64 %905, i64* %PC, align 8
  %906 = inttoptr i64 %903 to i64*
  %907 = load i64, i64* %906, align 8
  store i64 %907, i64* %RCX, align 8, !tbaa !2428
  %908 = add i64 %902, -28
  %909 = add i64 %904, 8
  store i64 %909, i64* %PC, align 8
  %910 = inttoptr i64 %908 to i32*
  %911 = load i32, i32* %910, align 4
  %912 = sext i32 %911 to i64
  store i64 %912, i64* %RDX, align 8, !tbaa !2428
  %913 = shl nsw i64 %912, 3
  %914 = add i64 %913, %907
  %915 = add i64 %904, 13
  store i64 %915, i64* %PC, align 8
  %916 = inttoptr i64 %914 to i64*
  %917 = load i64, i64* %916, align 8
  store i64 %917, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %918 = add i64 %904, 17
  store i64 %918, i64* %PC, align 8
  %919 = load i64, i64* %906, align 8
  store i64 %919, i64* %RCX, align 8, !tbaa !2428
  %920 = add i64 %902, -32
  %921 = add i64 %904, 21
  store i64 %921, i64* %PC, align 8
  %922 = inttoptr i64 %920 to i32*
  %923 = load i32, i32* %922, align 4
  %924 = sext i32 %923 to i64
  store i64 %924, i64* %RDX, align 8, !tbaa !2428
  %925 = shl nsw i64 %924, 3
  %926 = add i64 %925, %919
  %927 = add i64 %904, 26
  store i64 %927, i64* %PC, align 8
  %928 = bitcast i64 %917 to double
  %929 = inttoptr i64 %926 to double*
  %930 = load double, double* %929, align 8
  %931 = fsub double %928, %930
  store double %931, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %932 = add i64 %902, -72
  %933 = add i64 %904, 31
  store i64 %933, i64* %PC, align 8
  %934 = inttoptr i64 %932 to double*
  store double %931, double* %934, align 8
  %935 = load i64, i64* %RBP, align 8
  %936 = add i64 %935, -16
  %937 = load i64, i64* %PC, align 8
  %938 = add i64 %937, 4
  store i64 %938, i64* %PC, align 8
  %939 = inttoptr i64 %936 to i64*
  %940 = load i64, i64* %939, align 8
  store i64 %940, i64* %RCX, align 8, !tbaa !2428
  %941 = add i64 %935, -28
  %942 = add i64 %937, 7
  store i64 %942, i64* %PC, align 8
  %943 = inttoptr i64 %941 to i32*
  %944 = load i32, i32* %943, align 4
  %945 = add i32 %944, 1
  %946 = zext i32 %945 to i64
  store i64 %946, i64* %RAX, align 8, !tbaa !2428
  %947 = icmp eq i32 %944, -1
  %948 = icmp eq i32 %945, 0
  %949 = or i1 %947, %948
  %950 = zext i1 %949 to i8
  store i8 %950, i8* %14, align 1, !tbaa !2432
  %951 = and i32 %945, 255
  %952 = tail call i32 @llvm.ctpop.i32(i32 %951) #14
  %953 = trunc i32 %952 to i8
  %954 = and i8 %953, 1
  %955 = xor i8 %954, 1
  store i8 %955, i8* %21, align 1, !tbaa !2446
  %956 = xor i32 %945, %944
  %957 = lshr i32 %956, 4
  %958 = trunc i32 %957 to i8
  %959 = and i8 %958, 1
  store i8 %959, i8* %27, align 1, !tbaa !2447
  %960 = zext i1 %948 to i8
  store i8 %960, i8* %30, align 1, !tbaa !2448
  %961 = lshr i32 %945, 31
  %962 = trunc i32 %961 to i8
  store i8 %962, i8* %33, align 1, !tbaa !2449
  %963 = lshr i32 %944, 31
  %964 = xor i32 %961, %963
  %965 = add nuw nsw i32 %964, %961
  %966 = icmp eq i32 %965, 2
  %967 = zext i1 %966 to i8
  store i8 %967, i8* %39, align 1, !tbaa !2450
  %968 = sext i32 %945 to i64
  store i64 %968, i64* %RDX, align 8, !tbaa !2428
  %969 = shl nsw i64 %968, 3
  %970 = add i64 %940, %969
  %971 = add i64 %937, 18
  store i64 %971, i64* %PC, align 8
  %972 = inttoptr i64 %970 to i64*
  %973 = load i64, i64* %972, align 8
  store i64 %973, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %974 = add i64 %937, 22
  store i64 %974, i64* %PC, align 8
  %975 = load i64, i64* %939, align 8
  store i64 %975, i64* %RCX, align 8, !tbaa !2428
  %976 = add i64 %935, -32
  %977 = add i64 %937, 25
  store i64 %977, i64* %PC, align 8
  %978 = inttoptr i64 %976 to i32*
  %979 = load i32, i32* %978, align 4
  %980 = add i32 %979, 1
  %981 = zext i32 %980 to i64
  store i64 %981, i64* %RAX, align 8, !tbaa !2428
  %982 = icmp eq i32 %979, -1
  %983 = icmp eq i32 %980, 0
  %984 = or i1 %982, %983
  %985 = zext i1 %984 to i8
  store i8 %985, i8* %14, align 1, !tbaa !2432
  %986 = and i32 %980, 255
  %987 = tail call i32 @llvm.ctpop.i32(i32 %986) #14
  %988 = trunc i32 %987 to i8
  %989 = and i8 %988, 1
  %990 = xor i8 %989, 1
  store i8 %990, i8* %21, align 1, !tbaa !2446
  %991 = xor i32 %980, %979
  %992 = lshr i32 %991, 4
  %993 = trunc i32 %992 to i8
  %994 = and i8 %993, 1
  store i8 %994, i8* %27, align 1, !tbaa !2447
  %995 = zext i1 %983 to i8
  store i8 %995, i8* %30, align 1, !tbaa !2448
  %996 = lshr i32 %980, 31
  %997 = trunc i32 %996 to i8
  store i8 %997, i8* %33, align 1, !tbaa !2449
  %998 = lshr i32 %979, 31
  %999 = xor i32 %996, %998
  %1000 = add nuw nsw i32 %999, %996
  %1001 = icmp eq i32 %1000, 2
  %1002 = zext i1 %1001 to i8
  store i8 %1002, i8* %39, align 1, !tbaa !2450
  %1003 = sext i32 %980 to i64
  store i64 %1003, i64* %RDX, align 8, !tbaa !2428
  %1004 = shl nsw i64 %1003, 3
  %1005 = add i64 %975, %1004
  %1006 = add i64 %937, 36
  store i64 %1006, i64* %PC, align 8
  %1007 = bitcast i64 %973 to double
  %1008 = inttoptr i64 %1005 to double*
  %1009 = load double, double* %1008, align 8
  %1010 = fsub double %1007, %1009
  store double %1010, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %1011 = load i64, i64* %RBP, align 8
  %1012 = add i64 %1011, -80
  %1013 = add i64 %937, 41
  store i64 %1013, i64* %PC, align 8
  %1014 = inttoptr i64 %1012 to double*
  store double %1010, double* %1014, align 8
  %1015 = load i64, i64* %RBP, align 8
  %1016 = add i64 %1015, -16
  %1017 = load i64, i64* %PC, align 8
  %1018 = add i64 %1017, 4
  store i64 %1018, i64* %PC, align 8
  %1019 = inttoptr i64 %1016 to i64*
  %1020 = load i64, i64* %1019, align 8
  store i64 %1020, i64* %RCX, align 8, !tbaa !2428
  %1021 = add i64 %1015, -36
  %1022 = add i64 %1017, 8
  store i64 %1022, i64* %PC, align 8
  %1023 = inttoptr i64 %1021 to i32*
  %1024 = load i32, i32* %1023, align 4
  %1025 = sext i32 %1024 to i64
  store i64 %1025, i64* %RDX, align 8, !tbaa !2428
  %1026 = shl nsw i64 %1025, 3
  %1027 = add i64 %1026, %1020
  %1028 = add i64 %1017, 13
  store i64 %1028, i64* %PC, align 8
  %1029 = inttoptr i64 %1027 to i64*
  %1030 = load i64, i64* %1029, align 8
  store i64 %1030, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %1031 = add i64 %1017, 17
  store i64 %1031, i64* %PC, align 8
  %1032 = load i64, i64* %1019, align 8
  store i64 %1032, i64* %RCX, align 8, !tbaa !2428
  %1033 = add i64 %1015, -40
  %1034 = add i64 %1017, 21
  store i64 %1034, i64* %PC, align 8
  %1035 = inttoptr i64 %1033 to i32*
  %1036 = load i32, i32* %1035, align 4
  %1037 = sext i32 %1036 to i64
  store i64 %1037, i64* %RDX, align 8, !tbaa !2428
  %1038 = shl nsw i64 %1037, 3
  %1039 = add i64 %1038, %1032
  %1040 = add i64 %1017, 26
  store i64 %1040, i64* %PC, align 8
  %1041 = bitcast i64 %1030 to double
  %1042 = inttoptr i64 %1039 to double*
  %1043 = load double, double* %1042, align 8
  %1044 = fadd double %1041, %1043
  store double %1044, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %1045 = add i64 %1015, -88
  %1046 = add i64 %1017, 31
  store i64 %1046, i64* %PC, align 8
  %1047 = inttoptr i64 %1045 to double*
  store double %1044, double* %1047, align 8
  %1048 = load i64, i64* %RBP, align 8
  %1049 = add i64 %1048, -16
  %1050 = load i64, i64* %PC, align 8
  %1051 = add i64 %1050, 4
  store i64 %1051, i64* %PC, align 8
  %1052 = inttoptr i64 %1049 to i64*
  %1053 = load i64, i64* %1052, align 8
  store i64 %1053, i64* %RCX, align 8, !tbaa !2428
  %1054 = add i64 %1048, -36
  %1055 = add i64 %1050, 7
  store i64 %1055, i64* %PC, align 8
  %1056 = inttoptr i64 %1054 to i32*
  %1057 = load i32, i32* %1056, align 4
  %1058 = add i32 %1057, 1
  %1059 = zext i32 %1058 to i64
  store i64 %1059, i64* %RAX, align 8, !tbaa !2428
  %1060 = icmp eq i32 %1057, -1
  %1061 = icmp eq i32 %1058, 0
  %1062 = or i1 %1060, %1061
  %1063 = zext i1 %1062 to i8
  store i8 %1063, i8* %14, align 1, !tbaa !2432
  %1064 = and i32 %1058, 255
  %1065 = tail call i32 @llvm.ctpop.i32(i32 %1064) #14
  %1066 = trunc i32 %1065 to i8
  %1067 = and i8 %1066, 1
  %1068 = xor i8 %1067, 1
  store i8 %1068, i8* %21, align 1, !tbaa !2446
  %1069 = xor i32 %1058, %1057
  %1070 = lshr i32 %1069, 4
  %1071 = trunc i32 %1070 to i8
  %1072 = and i8 %1071, 1
  store i8 %1072, i8* %27, align 1, !tbaa !2447
  %1073 = zext i1 %1061 to i8
  store i8 %1073, i8* %30, align 1, !tbaa !2448
  %1074 = lshr i32 %1058, 31
  %1075 = trunc i32 %1074 to i8
  store i8 %1075, i8* %33, align 1, !tbaa !2449
  %1076 = lshr i32 %1057, 31
  %1077 = xor i32 %1074, %1076
  %1078 = add nuw nsw i32 %1077, %1074
  %1079 = icmp eq i32 %1078, 2
  %1080 = zext i1 %1079 to i8
  store i8 %1080, i8* %39, align 1, !tbaa !2450
  %1081 = sext i32 %1058 to i64
  store i64 %1081, i64* %RDX, align 8, !tbaa !2428
  %1082 = shl nsw i64 %1081, 3
  %1083 = add i64 %1053, %1082
  %1084 = add i64 %1050, 18
  store i64 %1084, i64* %PC, align 8
  %1085 = inttoptr i64 %1083 to i64*
  %1086 = load i64, i64* %1085, align 8
  store i64 %1086, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %1087 = add i64 %1050, 22
  store i64 %1087, i64* %PC, align 8
  %1088 = load i64, i64* %1052, align 8
  store i64 %1088, i64* %RCX, align 8, !tbaa !2428
  %1089 = add i64 %1048, -40
  %1090 = add i64 %1050, 25
  store i64 %1090, i64* %PC, align 8
  %1091 = inttoptr i64 %1089 to i32*
  %1092 = load i32, i32* %1091, align 4
  %1093 = add i32 %1092, 1
  %1094 = zext i32 %1093 to i64
  store i64 %1094, i64* %RAX, align 8, !tbaa !2428
  %1095 = icmp eq i32 %1092, -1
  %1096 = icmp eq i32 %1093, 0
  %1097 = or i1 %1095, %1096
  %1098 = zext i1 %1097 to i8
  store i8 %1098, i8* %14, align 1, !tbaa !2432
  %1099 = and i32 %1093, 255
  %1100 = tail call i32 @llvm.ctpop.i32(i32 %1099) #14
  %1101 = trunc i32 %1100 to i8
  %1102 = and i8 %1101, 1
  %1103 = xor i8 %1102, 1
  store i8 %1103, i8* %21, align 1, !tbaa !2446
  %1104 = xor i32 %1093, %1092
  %1105 = lshr i32 %1104, 4
  %1106 = trunc i32 %1105 to i8
  %1107 = and i8 %1106, 1
  store i8 %1107, i8* %27, align 1, !tbaa !2447
  %1108 = zext i1 %1096 to i8
  store i8 %1108, i8* %30, align 1, !tbaa !2448
  %1109 = lshr i32 %1093, 31
  %1110 = trunc i32 %1109 to i8
  store i8 %1110, i8* %33, align 1, !tbaa !2449
  %1111 = lshr i32 %1092, 31
  %1112 = xor i32 %1109, %1111
  %1113 = add nuw nsw i32 %1112, %1109
  %1114 = icmp eq i32 %1113, 2
  %1115 = zext i1 %1114 to i8
  store i8 %1115, i8* %39, align 1, !tbaa !2450
  %1116 = sext i32 %1093 to i64
  store i64 %1116, i64* %RDX, align 8, !tbaa !2428
  %1117 = shl nsw i64 %1116, 3
  %1118 = add i64 %1088, %1117
  %1119 = add i64 %1050, 36
  store i64 %1119, i64* %PC, align 8
  %1120 = bitcast i64 %1086 to double
  %1121 = inttoptr i64 %1118 to double*
  %1122 = load double, double* %1121, align 8
  %1123 = fadd double %1120, %1122
  store double %1123, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %1124 = load i64, i64* %RBP, align 8
  %1125 = add i64 %1124, -96
  %1126 = add i64 %1050, 41
  store i64 %1126, i64* %PC, align 8
  %1127 = inttoptr i64 %1125 to double*
  store double %1123, double* %1127, align 8
  %1128 = load i64, i64* %RBP, align 8
  %1129 = add i64 %1128, -16
  %1130 = load i64, i64* %PC, align 8
  %1131 = add i64 %1130, 4
  store i64 %1131, i64* %PC, align 8
  %1132 = inttoptr i64 %1129 to i64*
  %1133 = load i64, i64* %1132, align 8
  store i64 %1133, i64* %RCX, align 8, !tbaa !2428
  %1134 = add i64 %1128, -36
  %1135 = add i64 %1130, 8
  store i64 %1135, i64* %PC, align 8
  %1136 = inttoptr i64 %1134 to i32*
  %1137 = load i32, i32* %1136, align 4
  %1138 = sext i32 %1137 to i64
  store i64 %1138, i64* %RDX, align 8, !tbaa !2428
  %1139 = shl nsw i64 %1138, 3
  %1140 = add i64 %1139, %1133
  %1141 = add i64 %1130, 13
  store i64 %1141, i64* %PC, align 8
  %1142 = inttoptr i64 %1140 to i64*
  %1143 = load i64, i64* %1142, align 8
  store i64 %1143, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %1144 = add i64 %1130, 17
  store i64 %1144, i64* %PC, align 8
  %1145 = load i64, i64* %1132, align 8
  store i64 %1145, i64* %RCX, align 8, !tbaa !2428
  %1146 = add i64 %1128, -40
  %1147 = add i64 %1130, 21
  store i64 %1147, i64* %PC, align 8
  %1148 = inttoptr i64 %1146 to i32*
  %1149 = load i32, i32* %1148, align 4
  %1150 = sext i32 %1149 to i64
  store i64 %1150, i64* %RDX, align 8, !tbaa !2428
  %1151 = shl nsw i64 %1150, 3
  %1152 = add i64 %1151, %1145
  %1153 = add i64 %1130, 26
  store i64 %1153, i64* %PC, align 8
  %1154 = bitcast i64 %1143 to double
  %1155 = inttoptr i64 %1152 to double*
  %1156 = load double, double* %1155, align 8
  %1157 = fsub double %1154, %1156
  store double %1157, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %1158 = add i64 %1128, -104
  %1159 = add i64 %1130, 31
  store i64 %1159, i64* %PC, align 8
  %1160 = inttoptr i64 %1158 to double*
  store double %1157, double* %1160, align 8
  %1161 = load i64, i64* %RBP, align 8
  %1162 = add i64 %1161, -16
  %1163 = load i64, i64* %PC, align 8
  %1164 = add i64 %1163, 4
  store i64 %1164, i64* %PC, align 8
  %1165 = inttoptr i64 %1162 to i64*
  %1166 = load i64, i64* %1165, align 8
  store i64 %1166, i64* %RCX, align 8, !tbaa !2428
  %1167 = add i64 %1161, -36
  %1168 = add i64 %1163, 7
  store i64 %1168, i64* %PC, align 8
  %1169 = inttoptr i64 %1167 to i32*
  %1170 = load i32, i32* %1169, align 4
  %1171 = add i32 %1170, 1
  %1172 = zext i32 %1171 to i64
  store i64 %1172, i64* %RAX, align 8, !tbaa !2428
  %1173 = icmp eq i32 %1170, -1
  %1174 = icmp eq i32 %1171, 0
  %1175 = or i1 %1173, %1174
  %1176 = zext i1 %1175 to i8
  store i8 %1176, i8* %14, align 1, !tbaa !2432
  %1177 = and i32 %1171, 255
  %1178 = tail call i32 @llvm.ctpop.i32(i32 %1177) #14
  %1179 = trunc i32 %1178 to i8
  %1180 = and i8 %1179, 1
  %1181 = xor i8 %1180, 1
  store i8 %1181, i8* %21, align 1, !tbaa !2446
  %1182 = xor i32 %1171, %1170
  %1183 = lshr i32 %1182, 4
  %1184 = trunc i32 %1183 to i8
  %1185 = and i8 %1184, 1
  store i8 %1185, i8* %27, align 1, !tbaa !2447
  %1186 = zext i1 %1174 to i8
  store i8 %1186, i8* %30, align 1, !tbaa !2448
  %1187 = lshr i32 %1171, 31
  %1188 = trunc i32 %1187 to i8
  store i8 %1188, i8* %33, align 1, !tbaa !2449
  %1189 = lshr i32 %1170, 31
  %1190 = xor i32 %1187, %1189
  %1191 = add nuw nsw i32 %1190, %1187
  %1192 = icmp eq i32 %1191, 2
  %1193 = zext i1 %1192 to i8
  store i8 %1193, i8* %39, align 1, !tbaa !2450
  %1194 = sext i32 %1171 to i64
  store i64 %1194, i64* %RDX, align 8, !tbaa !2428
  %1195 = shl nsw i64 %1194, 3
  %1196 = add i64 %1166, %1195
  %1197 = add i64 %1163, 18
  store i64 %1197, i64* %PC, align 8
  %1198 = inttoptr i64 %1196 to i64*
  %1199 = load i64, i64* %1198, align 8
  store i64 %1199, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %1200 = add i64 %1163, 22
  store i64 %1200, i64* %PC, align 8
  %1201 = load i64, i64* %1165, align 8
  store i64 %1201, i64* %RCX, align 8, !tbaa !2428
  %1202 = add i64 %1161, -40
  %1203 = add i64 %1163, 25
  store i64 %1203, i64* %PC, align 8
  %1204 = inttoptr i64 %1202 to i32*
  %1205 = load i32, i32* %1204, align 4
  %1206 = add i32 %1205, 1
  %1207 = zext i32 %1206 to i64
  store i64 %1207, i64* %RAX, align 8, !tbaa !2428
  %1208 = icmp eq i32 %1205, -1
  %1209 = icmp eq i32 %1206, 0
  %1210 = or i1 %1208, %1209
  %1211 = zext i1 %1210 to i8
  store i8 %1211, i8* %14, align 1, !tbaa !2432
  %1212 = and i32 %1206, 255
  %1213 = tail call i32 @llvm.ctpop.i32(i32 %1212) #14
  %1214 = trunc i32 %1213 to i8
  %1215 = and i8 %1214, 1
  %1216 = xor i8 %1215, 1
  store i8 %1216, i8* %21, align 1, !tbaa !2446
  %1217 = xor i32 %1206, %1205
  %1218 = lshr i32 %1217, 4
  %1219 = trunc i32 %1218 to i8
  %1220 = and i8 %1219, 1
  store i8 %1220, i8* %27, align 1, !tbaa !2447
  %1221 = zext i1 %1209 to i8
  store i8 %1221, i8* %30, align 1, !tbaa !2448
  %1222 = lshr i32 %1206, 31
  %1223 = trunc i32 %1222 to i8
  store i8 %1223, i8* %33, align 1, !tbaa !2449
  %1224 = lshr i32 %1205, 31
  %1225 = xor i32 %1222, %1224
  %1226 = add nuw nsw i32 %1225, %1222
  %1227 = icmp eq i32 %1226, 2
  %1228 = zext i1 %1227 to i8
  store i8 %1228, i8* %39, align 1, !tbaa !2450
  %1229 = sext i32 %1206 to i64
  store i64 %1229, i64* %RDX, align 8, !tbaa !2428
  %1230 = shl nsw i64 %1229, 3
  %1231 = add i64 %1201, %1230
  %1232 = add i64 %1163, 36
  store i64 %1232, i64* %PC, align 8
  %1233 = bitcast i64 %1199 to double
  %1234 = inttoptr i64 %1231 to double*
  %1235 = load double, double* %1234, align 8
  %1236 = fsub double %1233, %1235
  store double %1236, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %1237 = load i64, i64* %RBP, align 8
  %1238 = add i64 %1237, -112
  %1239 = add i64 %1163, 41
  store i64 %1239, i64* %PC, align 8
  %1240 = inttoptr i64 %1238 to double*
  store double %1236, double* %1240, align 8
  %1241 = load i64, i64* %RBP, align 8
  %1242 = add i64 %1241, -56
  %1243 = load i64, i64* %PC, align 8
  %1244 = add i64 %1243, 5
  store i64 %1244, i64* %PC, align 8
  %1245 = inttoptr i64 %1242 to i64*
  %1246 = load i64, i64* %1245, align 8
  store i64 %1246, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %1247 = add i64 %1241, -88
  %1248 = add i64 %1243, 10
  store i64 %1248, i64* %PC, align 8
  %1249 = bitcast i64 %1246 to double
  %1250 = inttoptr i64 %1247 to double*
  %1251 = load double, double* %1250, align 8
  %1252 = fadd double %1249, %1251
  store double %1252, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %1253 = add i64 %1241, -16
  %1254 = add i64 %1243, 14
  store i64 %1254, i64* %PC, align 8
  %1255 = inttoptr i64 %1253 to i64*
  %1256 = load i64, i64* %1255, align 8
  store i64 %1256, i64* %RCX, align 8, !tbaa !2428
  %1257 = add i64 %1241, -28
  %1258 = add i64 %1243, 18
  store i64 %1258, i64* %PC, align 8
  %1259 = inttoptr i64 %1257 to i32*
  %1260 = load i32, i32* %1259, align 4
  %1261 = sext i32 %1260 to i64
  store i64 %1261, i64* %RDX, align 8, !tbaa !2428
  %1262 = shl nsw i64 %1261, 3
  %1263 = add i64 %1262, %1256
  %1264 = add i64 %1243, 23
  store i64 %1264, i64* %PC, align 8
  %1265 = inttoptr i64 %1263 to double*
  store double %1252, double* %1265, align 8
  %1266 = load i64, i64* %RBP, align 8
  %1267 = add i64 %1266, -64
  %1268 = load i64, i64* %PC, align 8
  %1269 = add i64 %1268, 5
  store i64 %1269, i64* %PC, align 8
  %1270 = inttoptr i64 %1267 to i64*
  %1271 = load i64, i64* %1270, align 8
  store i64 %1271, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %1272 = add i64 %1266, -96
  %1273 = add i64 %1268, 10
  store i64 %1273, i64* %PC, align 8
  %1274 = bitcast i64 %1271 to double
  %1275 = inttoptr i64 %1272 to double*
  %1276 = load double, double* %1275, align 8
  %1277 = fadd double %1274, %1276
  store double %1277, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %1278 = add i64 %1266, -16
  %1279 = add i64 %1268, 14
  store i64 %1279, i64* %PC, align 8
  %1280 = inttoptr i64 %1278 to i64*
  %1281 = load i64, i64* %1280, align 8
  store i64 %1281, i64* %RCX, align 8, !tbaa !2428
  %1282 = add i64 %1266, -28
  %1283 = add i64 %1268, 17
  store i64 %1283, i64* %PC, align 8
  %1284 = inttoptr i64 %1282 to i32*
  %1285 = load i32, i32* %1284, align 4
  %1286 = add i32 %1285, 1
  %1287 = zext i32 %1286 to i64
  store i64 %1287, i64* %RAX, align 8, !tbaa !2428
  %1288 = icmp eq i32 %1285, -1
  %1289 = icmp eq i32 %1286, 0
  %1290 = or i1 %1288, %1289
  %1291 = zext i1 %1290 to i8
  store i8 %1291, i8* %14, align 1, !tbaa !2432
  %1292 = and i32 %1286, 255
  %1293 = tail call i32 @llvm.ctpop.i32(i32 %1292) #14
  %1294 = trunc i32 %1293 to i8
  %1295 = and i8 %1294, 1
  %1296 = xor i8 %1295, 1
  store i8 %1296, i8* %21, align 1, !tbaa !2446
  %1297 = xor i32 %1286, %1285
  %1298 = lshr i32 %1297, 4
  %1299 = trunc i32 %1298 to i8
  %1300 = and i8 %1299, 1
  store i8 %1300, i8* %27, align 1, !tbaa !2447
  %1301 = zext i1 %1289 to i8
  store i8 %1301, i8* %30, align 1, !tbaa !2448
  %1302 = lshr i32 %1286, 31
  %1303 = trunc i32 %1302 to i8
  store i8 %1303, i8* %33, align 1, !tbaa !2449
  %1304 = lshr i32 %1285, 31
  %1305 = xor i32 %1302, %1304
  %1306 = add nuw nsw i32 %1305, %1302
  %1307 = icmp eq i32 %1306, 2
  %1308 = zext i1 %1307 to i8
  store i8 %1308, i8* %39, align 1, !tbaa !2450
  %1309 = sext i32 %1286 to i64
  store i64 %1309, i64* %RDX, align 8, !tbaa !2428
  %1310 = shl nsw i64 %1309, 3
  %1311 = add i64 %1281, %1310
  %1312 = add i64 %1268, 28
  store i64 %1312, i64* %PC, align 8
  %1313 = inttoptr i64 %1311 to double*
  store double %1277, double* %1313, align 8
  %1314 = load i64, i64* %RBP, align 8
  %1315 = add i64 %1314, -56
  %1316 = load i64, i64* %PC, align 8
  %1317 = add i64 %1316, 5
  store i64 %1317, i64* %PC, align 8
  %1318 = inttoptr i64 %1315 to i64*
  %1319 = load i64, i64* %1318, align 8
  store i64 %1319, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %1320 = add i64 %1314, -88
  %1321 = add i64 %1316, 10
  store i64 %1321, i64* %PC, align 8
  %1322 = bitcast i64 %1319 to double
  %1323 = inttoptr i64 %1320 to double*
  %1324 = load double, double* %1323, align 8
  %1325 = fsub double %1322, %1324
  store double %1325, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %1326 = add i64 %1314, -16
  %1327 = add i64 %1316, 14
  store i64 %1327, i64* %PC, align 8
  %1328 = inttoptr i64 %1326 to i64*
  %1329 = load i64, i64* %1328, align 8
  store i64 %1329, i64* %RCX, align 8, !tbaa !2428
  %1330 = add i64 %1314, -36
  %1331 = add i64 %1316, 18
  store i64 %1331, i64* %PC, align 8
  %1332 = inttoptr i64 %1330 to i32*
  %1333 = load i32, i32* %1332, align 4
  %1334 = sext i32 %1333 to i64
  store i64 %1334, i64* %RDX, align 8, !tbaa !2428
  %1335 = shl nsw i64 %1334, 3
  %1336 = add i64 %1335, %1329
  %1337 = add i64 %1316, 23
  store i64 %1337, i64* %PC, align 8
  %1338 = inttoptr i64 %1336 to double*
  store double %1325, double* %1338, align 8
  %1339 = load i64, i64* %RBP, align 8
  %1340 = add i64 %1339, -64
  %1341 = load i64, i64* %PC, align 8
  %1342 = add i64 %1341, 5
  store i64 %1342, i64* %PC, align 8
  %1343 = inttoptr i64 %1340 to i64*
  %1344 = load i64, i64* %1343, align 8
  store i64 %1344, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %1345 = add i64 %1339, -96
  %1346 = add i64 %1341, 10
  store i64 %1346, i64* %PC, align 8
  %1347 = bitcast i64 %1344 to double
  %1348 = inttoptr i64 %1345 to double*
  %1349 = load double, double* %1348, align 8
  %1350 = fsub double %1347, %1349
  store double %1350, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %1351 = add i64 %1339, -16
  %1352 = add i64 %1341, 14
  store i64 %1352, i64* %PC, align 8
  %1353 = inttoptr i64 %1351 to i64*
  %1354 = load i64, i64* %1353, align 8
  store i64 %1354, i64* %RCX, align 8, !tbaa !2428
  %1355 = add i64 %1339, -36
  %1356 = add i64 %1341, 17
  store i64 %1356, i64* %PC, align 8
  %1357 = inttoptr i64 %1355 to i32*
  %1358 = load i32, i32* %1357, align 4
  %1359 = add i32 %1358, 1
  %1360 = zext i32 %1359 to i64
  store i64 %1360, i64* %RAX, align 8, !tbaa !2428
  %1361 = icmp eq i32 %1358, -1
  %1362 = icmp eq i32 %1359, 0
  %1363 = or i1 %1361, %1362
  %1364 = zext i1 %1363 to i8
  store i8 %1364, i8* %14, align 1, !tbaa !2432
  %1365 = and i32 %1359, 255
  %1366 = tail call i32 @llvm.ctpop.i32(i32 %1365) #14
  %1367 = trunc i32 %1366 to i8
  %1368 = and i8 %1367, 1
  %1369 = xor i8 %1368, 1
  store i8 %1369, i8* %21, align 1, !tbaa !2446
  %1370 = xor i32 %1359, %1358
  %1371 = lshr i32 %1370, 4
  %1372 = trunc i32 %1371 to i8
  %1373 = and i8 %1372, 1
  store i8 %1373, i8* %27, align 1, !tbaa !2447
  %1374 = zext i1 %1362 to i8
  store i8 %1374, i8* %30, align 1, !tbaa !2448
  %1375 = lshr i32 %1359, 31
  %1376 = trunc i32 %1375 to i8
  store i8 %1376, i8* %33, align 1, !tbaa !2449
  %1377 = lshr i32 %1358, 31
  %1378 = xor i32 %1375, %1377
  %1379 = add nuw nsw i32 %1378, %1375
  %1380 = icmp eq i32 %1379, 2
  %1381 = zext i1 %1380 to i8
  store i8 %1381, i8* %39, align 1, !tbaa !2450
  %1382 = sext i32 %1359 to i64
  store i64 %1382, i64* %RDX, align 8, !tbaa !2428
  %1383 = shl nsw i64 %1382, 3
  %1384 = add i64 %1354, %1383
  %1385 = add i64 %1341, 28
  store i64 %1385, i64* %PC, align 8
  %1386 = inttoptr i64 %1384 to double*
  store double %1350, double* %1386, align 8
  %1387 = load i64, i64* %RBP, align 8
  %1388 = add i64 %1387, -72
  %1389 = load i64, i64* %PC, align 8
  %1390 = add i64 %1389, 5
  store i64 %1390, i64* %PC, align 8
  %1391 = inttoptr i64 %1388 to i64*
  %1392 = load i64, i64* %1391, align 8
  store i64 %1392, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %1393 = add i64 %1387, -112
  %1394 = add i64 %1389, 10
  store i64 %1394, i64* %PC, align 8
  %1395 = bitcast i64 %1392 to double
  %1396 = inttoptr i64 %1393 to double*
  %1397 = load double, double* %1396, align 8
  %1398 = fsub double %1395, %1397
  store double %1398, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %1399 = add i64 %1387, -16
  %1400 = add i64 %1389, 14
  store i64 %1400, i64* %PC, align 8
  %1401 = inttoptr i64 %1399 to i64*
  %1402 = load i64, i64* %1401, align 8
  store i64 %1402, i64* %RCX, align 8, !tbaa !2428
  %1403 = add i64 %1387, -32
  %1404 = add i64 %1389, 18
  store i64 %1404, i64* %PC, align 8
  %1405 = inttoptr i64 %1403 to i32*
  %1406 = load i32, i32* %1405, align 4
  %1407 = sext i32 %1406 to i64
  store i64 %1407, i64* %RDX, align 8, !tbaa !2428
  %1408 = shl nsw i64 %1407, 3
  %1409 = add i64 %1408, %1402
  %1410 = add i64 %1389, 23
  store i64 %1410, i64* %PC, align 8
  %1411 = inttoptr i64 %1409 to double*
  store double %1398, double* %1411, align 8
  %1412 = load i64, i64* %RBP, align 8
  %1413 = add i64 %1412, -80
  %1414 = load i64, i64* %PC, align 8
  %1415 = add i64 %1414, 5
  store i64 %1415, i64* %PC, align 8
  %1416 = inttoptr i64 %1413 to i64*
  %1417 = load i64, i64* %1416, align 8
  store i64 %1417, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %1418 = add i64 %1412, -104
  %1419 = add i64 %1414, 10
  store i64 %1419, i64* %PC, align 8
  %1420 = bitcast i64 %1417 to double
  %1421 = inttoptr i64 %1418 to double*
  %1422 = load double, double* %1421, align 8
  %1423 = fadd double %1420, %1422
  store double %1423, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %1424 = add i64 %1412, -16
  %1425 = add i64 %1414, 14
  store i64 %1425, i64* %PC, align 8
  %1426 = inttoptr i64 %1424 to i64*
  %1427 = load i64, i64* %1426, align 8
  store i64 %1427, i64* %RCX, align 8, !tbaa !2428
  %1428 = add i64 %1412, -32
  %1429 = add i64 %1414, 17
  store i64 %1429, i64* %PC, align 8
  %1430 = inttoptr i64 %1428 to i32*
  %1431 = load i32, i32* %1430, align 4
  %1432 = add i32 %1431, 1
  %1433 = zext i32 %1432 to i64
  store i64 %1433, i64* %RAX, align 8, !tbaa !2428
  %1434 = icmp eq i32 %1431, -1
  %1435 = icmp eq i32 %1432, 0
  %1436 = or i1 %1434, %1435
  %1437 = zext i1 %1436 to i8
  store i8 %1437, i8* %14, align 1, !tbaa !2432
  %1438 = and i32 %1432, 255
  %1439 = tail call i32 @llvm.ctpop.i32(i32 %1438) #14
  %1440 = trunc i32 %1439 to i8
  %1441 = and i8 %1440, 1
  %1442 = xor i8 %1441, 1
  store i8 %1442, i8* %21, align 1, !tbaa !2446
  %1443 = xor i32 %1432, %1431
  %1444 = lshr i32 %1443, 4
  %1445 = trunc i32 %1444 to i8
  %1446 = and i8 %1445, 1
  store i8 %1446, i8* %27, align 1, !tbaa !2447
  %1447 = zext i1 %1435 to i8
  store i8 %1447, i8* %30, align 1, !tbaa !2448
  %1448 = lshr i32 %1432, 31
  %1449 = trunc i32 %1448 to i8
  store i8 %1449, i8* %33, align 1, !tbaa !2449
  %1450 = lshr i32 %1431, 31
  %1451 = xor i32 %1448, %1450
  %1452 = add nuw nsw i32 %1451, %1448
  %1453 = icmp eq i32 %1452, 2
  %1454 = zext i1 %1453 to i8
  store i8 %1454, i8* %39, align 1, !tbaa !2450
  %1455 = sext i32 %1432 to i64
  store i64 %1455, i64* %RDX, align 8, !tbaa !2428
  %1456 = shl nsw i64 %1455, 3
  %1457 = add i64 %1427, %1456
  %1458 = add i64 %1414, 28
  store i64 %1458, i64* %PC, align 8
  %1459 = inttoptr i64 %1457 to double*
  store double %1423, double* %1459, align 8
  %1460 = load i64, i64* %RBP, align 8
  %1461 = add i64 %1460, -72
  %1462 = load i64, i64* %PC, align 8
  %1463 = add i64 %1462, 5
  store i64 %1463, i64* %PC, align 8
  %1464 = inttoptr i64 %1461 to i64*
  %1465 = load i64, i64* %1464, align 8
  store i64 %1465, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %1466 = add i64 %1460, -112
  %1467 = add i64 %1462, 10
  store i64 %1467, i64* %PC, align 8
  %1468 = bitcast i64 %1465 to double
  %1469 = inttoptr i64 %1466 to double*
  %1470 = load double, double* %1469, align 8
  %1471 = fadd double %1468, %1470
  store double %1471, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %1472 = add i64 %1460, -16
  %1473 = add i64 %1462, 14
  store i64 %1473, i64* %PC, align 8
  %1474 = inttoptr i64 %1472 to i64*
  %1475 = load i64, i64* %1474, align 8
  store i64 %1475, i64* %RCX, align 8, !tbaa !2428
  %1476 = add i64 %1460, -40
  %1477 = add i64 %1462, 18
  store i64 %1477, i64* %PC, align 8
  %1478 = inttoptr i64 %1476 to i32*
  %1479 = load i32, i32* %1478, align 4
  %1480 = sext i32 %1479 to i64
  store i64 %1480, i64* %RDX, align 8, !tbaa !2428
  %1481 = shl nsw i64 %1480, 3
  %1482 = add i64 %1481, %1475
  %1483 = add i64 %1462, 23
  store i64 %1483, i64* %PC, align 8
  %1484 = inttoptr i64 %1482 to double*
  store double %1471, double* %1484, align 8
  %1485 = load i64, i64* %RBP, align 8
  %1486 = add i64 %1485, -80
  %1487 = load i64, i64* %PC, align 8
  %1488 = add i64 %1487, 5
  store i64 %1488, i64* %PC, align 8
  %1489 = inttoptr i64 %1486 to i64*
  %1490 = load i64, i64* %1489, align 8
  store i64 %1490, i64* %1619, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1621, align 1, !tbaa !2451
  %1491 = add i64 %1485, -104
  %1492 = add i64 %1487, 10
  store i64 %1492, i64* %PC, align 8
  %1493 = bitcast i64 %1490 to double
  %1494 = inttoptr i64 %1491 to double*
  %1495 = load double, double* %1494, align 8
  %1496 = fsub double %1493, %1495
  store double %1496, double* %1618, align 1, !tbaa !2451
  store i64 0, i64* %1620, align 1, !tbaa !2451
  %1497 = add i64 %1485, -16
  %1498 = add i64 %1487, 14
  store i64 %1498, i64* %PC, align 8
  %1499 = inttoptr i64 %1497 to i64*
  %1500 = load i64, i64* %1499, align 8
  store i64 %1500, i64* %RCX, align 8, !tbaa !2428
  %1501 = add i64 %1485, -40
  %1502 = add i64 %1487, 17
  store i64 %1502, i64* %PC, align 8
  %1503 = inttoptr i64 %1501 to i32*
  %1504 = load i32, i32* %1503, align 4
  %1505 = add i32 %1504, 1
  %1506 = zext i32 %1505 to i64
  store i64 %1506, i64* %RAX, align 8, !tbaa !2428
  %1507 = icmp eq i32 %1504, -1
  %1508 = icmp eq i32 %1505, 0
  %1509 = or i1 %1507, %1508
  %1510 = zext i1 %1509 to i8
  store i8 %1510, i8* %14, align 1, !tbaa !2432
  %1511 = and i32 %1505, 255
  %1512 = tail call i32 @llvm.ctpop.i32(i32 %1511) #14
  %1513 = trunc i32 %1512 to i8
  %1514 = and i8 %1513, 1
  %1515 = xor i8 %1514, 1
  store i8 %1515, i8* %21, align 1, !tbaa !2446
  %1516 = xor i32 %1505, %1504
  %1517 = lshr i32 %1516, 4
  %1518 = trunc i32 %1517 to i8
  %1519 = and i8 %1518, 1
  store i8 %1519, i8* %27, align 1, !tbaa !2447
  %1520 = zext i1 %1508 to i8
  store i8 %1520, i8* %30, align 1, !tbaa !2448
  %1521 = lshr i32 %1505, 31
  %1522 = trunc i32 %1521 to i8
  store i8 %1522, i8* %33, align 1, !tbaa !2449
  %1523 = lshr i32 %1504, 31
  %1524 = xor i32 %1521, %1523
  %1525 = add nuw nsw i32 %1524, %1521
  %1526 = icmp eq i32 %1525, 2
  %1527 = zext i1 %1526 to i8
  store i8 %1527, i8* %39, align 1, !tbaa !2450
  %1528 = sext i32 %1505 to i64
  store i64 %1528, i64* %RDX, align 8, !tbaa !2428
  %1529 = shl nsw i64 %1528, 3
  %1530 = add i64 %1500, %1529
  %1531 = add i64 %1487, 28
  store i64 %1531, i64* %PC, align 8
  %1532 = inttoptr i64 %1530 to double*
  store double %1496, double* %1532, align 8
  %1533 = load i64, i64* %RBP, align 8
  %1534 = add i64 %1533, -28
  %1535 = load i64, i64* %PC, align 8
  %1536 = add i64 %1535, 3
  store i64 %1536, i64* %PC, align 8
  %1537 = inttoptr i64 %1534 to i32*
  %1538 = load i32, i32* %1537, align 4
  %1539 = add i32 %1538, 2
  %1540 = zext i32 %1539 to i64
  store i64 %1540, i64* %RAX, align 8, !tbaa !2428
  %1541 = icmp ugt i32 %1538, -3
  %1542 = zext i1 %1541 to i8
  store i8 %1542, i8* %14, align 1, !tbaa !2432
  %1543 = and i32 %1539, 255
  %1544 = tail call i32 @llvm.ctpop.i32(i32 %1543) #14
  %1545 = trunc i32 %1544 to i8
  %1546 = and i8 %1545, 1
  %1547 = xor i8 %1546, 1
  store i8 %1547, i8* %21, align 1, !tbaa !2446
  %1548 = xor i32 %1539, %1538
  %1549 = lshr i32 %1548, 4
  %1550 = trunc i32 %1549 to i8
  %1551 = and i8 %1550, 1
  store i8 %1551, i8* %27, align 1, !tbaa !2447
  %1552 = icmp eq i32 %1539, 0
  %1553 = zext i1 %1552 to i8
  store i8 %1553, i8* %30, align 1, !tbaa !2448
  %1554 = lshr i32 %1539, 31
  %1555 = trunc i32 %1554 to i8
  store i8 %1555, i8* %33, align 1, !tbaa !2449
  %1556 = lshr i32 %1538, 31
  %1557 = xor i32 %1554, %1556
  %1558 = add nuw nsw i32 %1557, %1554
  %1559 = icmp eq i32 %1558, 2
  %1560 = zext i1 %1559 to i8
  store i8 %1560, i8* %39, align 1, !tbaa !2450
  %1561 = add i64 %1535, 9
  store i64 %1561, i64* %PC, align 8
  store i32 %1539, i32* %1537, align 4
  %1562 = load i64, i64* %PC, align 8
  %1563 = add i64 %1562, -540
  store i64 %1563, i64* %PC, align 8, !tbaa !2428
  br label %block_4018f6

block_4018e0:                                     ; preds = %block_4018db, %block_401870
  %1564 = phi i64 [ %91, %block_401870 ], [ %92, %block_4018db ]
  %1565 = phi i64 [ %61, %block_401870 ], [ %510, %block_4018db ]
  %MEMORY.4 = phi %struct.Memory* [ %2, %block_401870 ], [ %109, %block_4018db ]
  %1566 = add i64 %1565, -44
  %1567 = add i64 %1564, 3
  store i64 %1567, i64* %PC, align 8
  %1568 = inttoptr i64 %1566 to i32*
  %1569 = load i32, i32* %1568, align 4
  %1570 = shl i32 %1569, 2
  %1571 = zext i32 %1570 to i64
  store i64 %1571, i64* %RAX, align 8, !tbaa !2428
  %1572 = lshr i32 %1569, 30
  %1573 = trunc i32 %1572 to i8
  %1574 = and i8 %1573, 1
  store i8 %1574, i8* %14, align 1, !tbaa !2453
  %1575 = and i32 %1570, 252
  %1576 = tail call i32 @llvm.ctpop.i32(i32 %1575) #14
  %1577 = trunc i32 %1576 to i8
  %1578 = and i8 %1577, 1
  %1579 = xor i8 %1578, 1
  store i8 %1579, i8* %21, align 1, !tbaa !2453
  store i8 0, i8* %27, align 1, !tbaa !2453
  %1580 = icmp eq i32 %1570, 0
  %1581 = zext i1 %1580 to i8
  store i8 %1581, i8* %30, align 1, !tbaa !2453
  %1582 = lshr i32 %1569, 29
  %1583 = trunc i32 %1582 to i8
  %1584 = and i8 %1583, 1
  store i8 %1584, i8* %33, align 1, !tbaa !2453
  store i8 0, i8* %39, align 1, !tbaa !2453
  %1585 = add i64 %1565, -4
  %1586 = add i64 %1564, 9
  store i64 %1586, i64* %PC, align 8
  %1587 = inttoptr i64 %1585 to i32*
  %1588 = load i32, i32* %1587, align 4
  %1589 = sub i32 %1570, %1588
  %1590 = icmp ult i32 %1570, %1588
  %1591 = zext i1 %1590 to i8
  store i8 %1591, i8* %14, align 1, !tbaa !2432
  %1592 = and i32 %1589, 255
  %1593 = tail call i32 @llvm.ctpop.i32(i32 %1592) #14
  %1594 = trunc i32 %1593 to i8
  %1595 = and i8 %1594, 1
  %1596 = xor i8 %1595, 1
  store i8 %1596, i8* %21, align 1, !tbaa !2446
  %1597 = xor i32 %1588, %1570
  %1598 = xor i32 %1597, %1589
  %1599 = lshr i32 %1598, 4
  %1600 = trunc i32 %1599 to i8
  %1601 = and i8 %1600, 1
  store i8 %1601, i8* %27, align 1, !tbaa !2447
  %1602 = icmp eq i32 %1589, 0
  %1603 = zext i1 %1602 to i8
  store i8 %1603, i8* %30, align 1, !tbaa !2448
  %1604 = lshr i32 %1589, 31
  %1605 = trunc i32 %1604 to i8
  store i8 %1605, i8* %33, align 1, !tbaa !2449
  %1606 = lshr i32 %1569, 29
  %1607 = and i32 %1606, 1
  %1608 = lshr i32 %1588, 31
  %1609 = xor i32 %1608, %1607
  %1610 = xor i32 %1604, %1607
  %1611 = add nuw nsw i32 %1610, %1609
  %1612 = icmp eq i32 %1611, 2
  %1613 = zext i1 %1612 to i8
  store i8 %1613, i8* %39, align 1, !tbaa !2450
  %.v = select i1 %1602, i64 15, i64 572
  %1614 = add i64 %1564, %.v
  %1615 = add i64 %1565, -28
  %1616 = add i64 %1614, 7
  store i64 %1616, i64* %PC, align 8
  %1617 = inttoptr i64 %1615 to i32*
  store i32 0, i32* %1617, align 4
  %1618 = bitcast %union.VectorReg* %4 to double*
  %1619 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  %1620 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1621 = bitcast i64* %1620 to double*
  %.pre12 = load i64, i64* %PC, align 8
  br i1 %1602, label %block_4018f6.preheader, label %block_401b23.preheader

block_401b23.preheader:                           ; preds = %block_4018e0
  br label %block_401b23

block_4018f6.preheader:                           ; preds = %block_4018e0
  br label %block_4018f6
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_403330_cftmdl(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_403330:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
; Matched:%var_2_45:  %var_2_45 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
; %var_2_3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
; Matched:  %ESI.i2242 = bitcast %union.anon* %var_2_45 to i32*
; %ESI = bitcast %union.anon* %var_2_3 to i32*
; Matched:%var_2_40:  %var_2_40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
; %var_2_4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
; Matched:  %EDI.i = bitcast %union.anon* %var_2_40 to i32*
; %EDI = bitcast %union.anon* %var_2_4 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
; Matched:  %RCX.i2236 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
; %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
; Matched:  %RDX.i2239 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
; %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
; Matched:  %RSI.i2233 = getelementptr inbounds %union.anon, %union.anon* %var_2_45, i64 0, i32 0
; %RSI = getelementptr inbounds %union.anon, %union.anon* %var_2_3, i64 0, i32 0
; Matched:%var_2_6:  %var_2_6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
; %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
%var_2_5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
; Matched:%var_2_1052:  %var_2_1052 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
; %var_2_6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
; Matched:%var_2_4:  %var_2_4 = load i64, i64* %RBP.i, align 8
; %var_2_7 = load i64, i64* %RBP, align 8
; Matched:%var_2_5:  %var_2_5 = add i64 %1, 1
; %var_2_8 = add i64 %1, 1
; Matched:\<badref\>:  store i64 %var_2_5, i64* %var_2_3, align 8
; store i64 %var_2_8, i64* %PC, align 8
; Matched:%var_2_7:  %var_2_7 = load i64, i64* %var_2_6, align 8
; %var_2_9 = load i64, i64* %RSP, align 8
; Matched:%var_2_8:  %var_2_8 = add i64 %var_2_7, -8
; %var_2_10 = add i64 %var_2_9, -8
; Matched:%var_2_9:  %var_2_9 = inttoptr i64 %var_2_8 to i64*
; %var_2_11 = inttoptr i64 %var_2_10 to i64*
; Matched:\<badref\>:  store i64 %var_2_4, i64* %var_2_9, align 8
; store i64 %var_2_7, i64* %var_2_11, align 8
%var_2_12 = load i64, i64* %PC, align 8
; Matched:\<badref\>:  store i64 %var_2_8, i64* %RBP.i, align 8
; store i64 %var_2_10, i64* %RBP, align 8
; Matched:%var_2_11:  %var_2_11 = add i64 %var_2_7, -56
; %var_2_13 = add i64 %var_2_9, -56
; Matched:\<badref\>:  store i64 %var_2_11, i64* %var_2_6, align 8
; store i64 %var_2_13, i64* %RSP, align 8
; Matched:%var_2_12:  %var_2_12 = icmp ult i64 %var_2_8, 48
; %var_2_14 = icmp ult i64 %var_2_10, 48
; Matched:%var_2_13:  %var_2_13 = zext i1 %var_2_12 to i8
; %var_2_15 = zext i1 %var_2_14 to i8
%var_2_16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
; Matched:\<badref\>:  store i8 %var_2_13, i8* %var_2_14, align 1
; store i8 %var_2_15, i8* %var_2_16, align 1
; Matched:%var_2_15:  %var_2_15 = trunc i64 %var_2_11 to i32
; %var_2_17 = trunc i64 %var_2_13 to i32
; Matched:%var_2_16:  %var_2_16 = and i32 %var_2_15, 255
; %var_2_18 = and i32 %var_2_17, 255
; Matched:%var_2_17:  %var_2_17 = tail call i32 @llvm.ctpop.i32(i32 %var_2_16)
; %var_2_19 = tail call i32 @llvm.ctpop.i32(i32 %var_2_18) #14
; Matched:%var_2_18:  %var_2_18 = trunc i32 %var_2_17 to i8
; %var_2_20 = trunc i32 %var_2_19 to i8
; Matched:%var_2_19:  %var_2_19 = and i8 %var_2_18, 1
; %var_2_21 = and i8 %var_2_20, 1
; Matched:%var_2_20:  %var_2_20 = xor i8 %var_2_19, 1
; %var_2_22 = xor i8 %var_2_21, 1
; Matched:%var_2_21:  %var_2_21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
; %var_2_23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
; Matched:\<badref\>:  store i8 %var_2_20, i8* %var_2_21, align 1
; store i8 %var_2_22, i8* %var_2_23, align 1
; Matched:%var_2_22:  %var_2_22 = xor i64 %var_2_8, 16
; %var_2_24 = xor i64 %var_2_10, 16
; Matched:%var_2_23:  %var_2_23 = xor i64 %var_2_22, %var_2_11
; %var_2_25 = xor i64 %var_2_24, %var_2_13
; Matched:%var_2_24:  %var_2_24 = lshr i64 %var_2_23, 4
; %var_2_26 = lshr i64 %var_2_25, 4
; Matched:%var_2_25:  %var_2_25 = trunc i64 %var_2_24 to i8
; %var_2_27 = trunc i64 %var_2_26 to i8
; Matched:%var_2_26:  %var_2_26 = and i8 %var_2_25, 1
; %var_2_28 = and i8 %var_2_27, 1
%var_2_29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
; Matched:\<badref\>:  store i8 %var_2_26, i8* %var_2_27, align 1
; store i8 %var_2_28, i8* %var_2_29, align 1
; Matched:%var_2_28:  %var_2_28 = icmp eq i64 %var_2_11, 0
; %var_2_30 = icmp eq i64 %var_2_13, 0
; Matched:%var_2_29:  %var_2_29 = zext i1 %var_2_28 to i8
; %var_2_31 = zext i1 %var_2_30 to i8
; Matched:%var_2_30:  %var_2_30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
; %var_2_32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
; Matched:\<badref\>:  store i8 %var_2_29, i8* %var_2_30, align 1
; store i8 %var_2_31, i8* %var_2_32, align 1
; Matched:%var_2_31:  %var_2_31 = lshr i64 %var_2_11, 63
; %var_2_33 = lshr i64 %var_2_13, 63
; Matched:%var_2_32:  %var_2_32 = trunc i64 %var_2_31 to i8
; %var_2_34 = trunc i64 %var_2_33 to i8
; Matched:%var_2_33:  %var_2_33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
; %var_2_35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
; Matched:\<badref\>:  store i8 %var_2_32, i8* %var_2_33, align 1
; store i8 %var_2_34, i8* %var_2_35, align 1
; Matched:%var_2_34:  %var_2_34 = lshr i64 %var_2_8, 63
; %var_2_36 = lshr i64 %var_2_10, 63
; Matched:%var_2_35:  %var_2_35 = xor i64 %var_2_31, %var_2_34
; %var_2_37 = xor i64 %var_2_33, %var_2_36
; Matched:%var_2_36:  %var_2_36 = add nuw nsw i64 %var_2_35, %var_2_34
; %var_2_38 = add nuw nsw i64 %var_2_37, %var_2_36
; Matched:%var_2_37:  %var_2_37 = icmp eq i64 %var_2_36, 2
; %var_2_39 = icmp eq i64 %var_2_38, 2
; Matched:%var_2_38:  %var_2_38 = zext i1 %var_2_37 to i8
; %var_2_40 = zext i1 %var_2_39 to i8
%var_2_41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
; Matched:\<badref\>:  store i8 %var_2_38, i8* %var_2_39, align 1
; store i8 %var_2_40, i8* %var_2_41, align 1
; Matched:%var_2_41:  %var_2_41 = add i64 %var_2_7, -12
; %var_2_42 = add i64 %var_2_9, -12
; Matched:%var_2_42:  %var_2_42 = load i32, i32* %EDI.i, align 4
; %var_2_43 = load i32, i32* %EDI, align 4
; Matched:%var_2_43:  %var_2_43 = add i64 %var_2_10, 10
; %var_2_44 = add i64 %var_2_12, 10
; Matched:\<badref\>:  store i64 %var_2_3617, i64* %var_2_3, align 8
; store i64 %var_2_44, i64* %PC, align 8
; Matched:%var_2_44:  %var_2_44 = inttoptr i64 %var_2_41 to i32*
; %var_2_45 = inttoptr i64 %var_2_42 to i32*
; Matched:\<badref\>:  store i32 %var_2_42, i32* %var_2_44, align 4
; store i32 %var_2_43, i32* %var_2_45, align 4
; Matched:%var_2_46:  %var_2_46 = load i64, i64* %RBP.i, align 8
; %var_2_46 = load i64, i64* %RBP, align 8
; Matched:%var_2_47:  %var_2_47 = add i64 %var_2_46, -8
; %var_2_47 = add i64 %var_2_46, -8
; Matched:%var_2_48:  %var_2_48 = load i32, i32* %ESI.i2242, align 4
; %var_2_48 = load i32, i32* %ESI, align 4
%var_2_49 = load i64, i64* %PC, align 8
; Matched:%var_2_2110:  %var_2_2110 = add i64 %var_2_2109, 3
; %var_2_50 = add i64 %var_2_49, 3
; Matched:\<badref\>:  store i64 %var_2_2050, i64* %var_2_3, align 8
; store i64 %var_2_50, i64* %PC, align 8
; Matched:%var_2_51:  %var_2_51 = inttoptr i64 %var_2_47 to i32*
; %var_2_51 = inttoptr i64 %var_2_47 to i32*
; Matched:\<badref\>:  store i32 %var_2_48, i32* %var_2_51, align 4
; store i32 %var_2_48, i32* %var_2_51, align 4
; Matched:%var_2_52:  %var_2_52 = load i64, i64* %RBP.i, align 8
; %var_2_52 = load i64, i64* %RBP, align 8
; Matched:%var_2_53:  %var_2_53 = add i64 %var_2_52, -16
; %var_2_53 = add i64 %var_2_52, -16
; Matched:%var_2_54:  %var_2_54 = load i64, i64* %RDX.i2239, align 8
; %var_2_54 = load i64, i64* %RDX, align 8
%var_2_55 = load i64, i64* %PC, align 8
; Matched:%var_2_515:  %var_2_515 = add i64 %var_2_514, 4
; %var_2_56 = add i64 %var_2_55, 4
; Matched:\<badref\>:  store i64 %var_2_515, i64* %var_2_3, align 8
; store i64 %var_2_56, i64* %PC, align 8
; Matched:%var_2_57:  %var_2_57 = inttoptr i64 %var_2_53 to i64*
; %var_2_57 = inttoptr i64 %var_2_53 to i64*
; Matched:\<badref\>:  store i64 %var_2_54, i64* %var_2_57, align 8
; store i64 %var_2_54, i64* %var_2_57, align 8
; Matched:%var_2_58:  %var_2_58 = load i64, i64* %RBP.i, align 8
; %var_2_58 = load i64, i64* %RBP, align 8
; Matched:%var_2_59:  %var_2_59 = add i64 %var_2_58, -24
; %var_2_59 = add i64 %var_2_58, -24
; Matched:%var_2_60:  %var_2_60 = load i64, i64* %RCX.i2236, align 8
; %var_2_60 = load i64, i64* %RCX, align 8
%var_2_61 = load i64, i64* %PC, align 8
; Matched:%var_2_1255:  %var_2_1255 = add i64 %var_2_1254, 4
; %var_2_62 = add i64 %var_2_61, 4
; Matched:\<badref\>:  store i64 %var_2_1255, i64* %var_2_3, align 8
; store i64 %var_2_62, i64* %PC, align 8
; Matched:%var_2_63:  %var_2_63 = inttoptr i64 %var_2_59 to i64*
; %var_2_63 = inttoptr i64 %var_2_59 to i64*
; Matched:\<badref\>:  store i64 %var_2_60, i64* %var_2_63, align 8
; store i64 %var_2_60, i64* %var_2_63, align 8
; Matched:%var_2_64:  %var_2_64 = load i64, i64* %RBP.i, align 8
; %var_2_64 = load i64, i64* %RBP, align 8
; Matched:%var_2_65:  %var_2_65 = add i64 %var_2_64, -8
; %var_2_65 = add i64 %var_2_64, -8
%var_2_66 = load i64, i64* %PC, align 8
; Matched:%var_2_3765:  %var_2_3765 = add i64 %var_2_3764, 3
; %var_2_67 = add i64 %var_2_66, 3
; Matched:\<badref\>:  store i64 %var_2_3765, i64* %var_2_3, align 8
; store i64 %var_2_67, i64* %PC, align 8
; Matched:%var_2_68:  %var_2_68 = inttoptr i64 %var_2_65 to i32*
; %var_2_68 = inttoptr i64 %var_2_65 to i32*
; Matched:%var_2_69:  %var_2_69 = load i32, i32* %var_2_68, align 4
; %var_2_69 = load i32, i32* %var_2_68, align 4
; Matched:%var_2_70:  %var_2_70 = shl i32 %var_2_69, 2
; %var_2_70 = shl i32 %var_2_69, 2
; Matched:%var_2_71:  %var_2_71 = zext i32 %var_2_70 to i64
; %var_2_71 = zext i32 %var_2_70 to i64
; Matched:\<badref\>:  store i64 %var_2_71, i64* %RSI.i2233, align 8
; store i64 %var_2_71, i64* %RSI, align 8
; Matched:%var_2_72:  %var_2_72 = lshr i32 %var_2_69, 30
; %var_2_72 = lshr i32 %var_2_69, 30
; Matched:%var_2_73:  %var_2_73 = trunc i32 %var_2_72 to i8
; %var_2_73 = trunc i32 %var_2_72 to i8
; Matched:%var_2_74:  %var_2_74 = and i8 %var_2_73, 1
; %var_2_74 = and i8 %var_2_73, 1
; Matched:\<badref\>:  store i8 %var_2_74, i8* %var_2_14, align 1
; store i8 %var_2_74, i8* %var_2_16, align 1
; Matched:%var_2_75:  %var_2_75 = and i32 %var_2_70, 252
; %var_2_75 = and i32 %var_2_70, 252
; Matched:%var_2_76:  %var_2_76 = tail call i32 @llvm.ctpop.i32(i32 %var_2_75)
; %var_2_76 = tail call i32 @llvm.ctpop.i32(i32 %var_2_75) #14
; Matched:%var_2_77:  %var_2_77 = trunc i32 %var_2_76 to i8
; %var_2_77 = trunc i32 %var_2_76 to i8
; Matched:%var_2_78:  %var_2_78 = and i8 %var_2_77, 1
; %var_2_78 = and i8 %var_2_77, 1
; Matched:%var_2_79:  %var_2_79 = xor i8 %var_2_78, 1
; %var_2_79 = xor i8 %var_2_78, 1
; Matched:\<badref\>:  store i8 %var_2_79, i8* %var_2_21, align 1
; store i8 %var_2_79, i8* %var_2_23, align 1
store i8 0, i8* %var_2_29, align 1
; Matched:%var_2_80:  %var_2_80 = icmp eq i32 %var_2_70, 0
; %var_2_80 = icmp eq i32 %var_2_70, 0
; Matched:%var_2_81:  %var_2_81 = zext i1 %var_2_80 to i8
; %var_2_81 = zext i1 %var_2_80 to i8
; Matched:\<badref\>:  store i8 %var_2_81, i8* %var_2_30, align 1
; store i8 %var_2_81, i8* %var_2_32, align 1
; Matched:%var_2_82:  %var_2_82 = lshr i32 %var_2_69, 29
; %var_2_82 = lshr i32 %var_2_69, 29
; Matched:%var_2_83:  %var_2_83 = trunc i32 %var_2_82 to i8
; %var_2_83 = trunc i32 %var_2_82 to i8
; Matched:%var_2_84:  %var_2_84 = and i8 %var_2_83, 1
; %var_2_84 = and i8 %var_2_83, 1
; Matched:\<badref\>:  store i8 %var_2_84, i8* %var_2_33, align 1
; store i8 %var_2_84, i8* %var_2_35, align 1
store i8 0, i8* %var_2_41, align 1
; Matched:%var_2_85:  %var_2_85 = add i64 %var_2_64, -56
; %var_2_85 = add i64 %var_2_64, -56
%var_2_86 = add i64 %var_2_66, 9
store i64 %var_2_86, i64* %PC, align 8
; Matched:%var_2_87:  %var_2_87 = inttoptr i64 %var_2_85 to i32*
; %var_2_87 = inttoptr i64 %var_2_85 to i32*
; Matched:\<badref\>:  store i32 %var_2_70, i32* %var_2_87, align 4
; store i32 %var_2_70, i32* %var_2_87, align 4
%var_2_88 = load i64, i64* %RBP, align 8
%var_2_89 = add i64 %var_2_88, -28
%var_2_90 = load i64, i64* %PC, align 8
; Matched:%var_2_91:  %var_2_91 = add i64 %var_2_90, 7
; %var_2_91 = add i64 %var_2_90, 7
; Matched:\<badref\>:  store i64 %var_2_4223, i64* %var_2_3, align 8
; store i64 %var_2_91, i64* %PC, align 8
%var_2_92 = inttoptr i64 %var_2_89 to i32*
store i32 0, i32* %var_2_92, align 4
%var_2_93 = bitcast [32 x %union.VectorReg]* %var_2_5 to double*
%var_2_94 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %var_2_5, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
; Matched:%var_2_96:  %var_2_96 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
; %var_2_95 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
; Matched:%var_2_97:  %var_2_97 = bitcast i64* %var_2_96 to double*
; %var_2_96 = bitcast i64* %var_2_95 to double*
; Matched:  %.pre = load i64, i64* %var_2_3, align 8
; %.pre = load i64, i64* %PC, align 8
  br label %block_403356

block_40389f:                                     ; preds = %block_403893
%var_2_97 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 80) to i64*), align 16
store i64 %var_2_97, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_2171:  %var_2_2171 = add i64 %var_2_2130, -48
; %var_2_98 = add i64 %var_2_3683, -48
; Matched:%var_2_2172:  %var_2_2172 = add i64 %var_2_2166, 11
; %var_2_99 = add i64 %var_2_3719, 11
; Matched:\<badref\>:  store i64 %var_2_2172, i64* %var_2_3, align 8
; store i64 %var_2_99, i64* %PC, align 8
; Matched:%var_2_2173:  %var_2_2173 = inttoptr i64 %var_2_2171 to i32*
; %var_2_100 = inttoptr i64 %var_2_98 to i32*
; Matched:%var_2_2174:  %var_2_2174 = load i32, i32* %var_2_2173, align 4
; %var_2_101 = load i32, i32* %var_2_100, align 4
; Matched:%var_2_2175:  %var_2_2175 = add i32 %var_2_2174, 2
; %var_2_102 = add i32 %var_2_101, 2
; Matched:%var_2_2176:  %var_2_2176 = zext i32 %var_2_2175 to i64
; %var_2_103 = zext i32 %var_2_102 to i64
; Matched:\<badref\>:  store i64 %var_2_2176, i64* %RAX.i2224, align 8
; store i64 %var_2_103, i64* %RAX, align 8
; Matched:%var_2_2177:  %var_2_2177 = icmp ugt i32 %var_2_2174, -3
; %var_2_104 = icmp ugt i32 %var_2_101, -3
; Matched:%var_2_2178:  %var_2_2178 = zext i1 %var_2_2177 to i8
; %var_2_105 = zext i1 %var_2_104 to i8
; Matched:\<badref\>:  store i8 %var_2_2178, i8* %var_2_14, align 1
; store i8 %var_2_105, i8* %var_2_16, align 1
; Matched:%var_2_2179:  %var_2_2179 = and i32 %var_2_2175, 255
; %var_2_106 = and i32 %var_2_102, 255
; Matched:%var_2_2180:  %var_2_2180 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2179)
; %var_2_107 = tail call i32 @llvm.ctpop.i32(i32 %var_2_106) #14
; Matched:%var_2_2181:  %var_2_2181 = trunc i32 %var_2_2180 to i8
; %var_2_108 = trunc i32 %var_2_107 to i8
; Matched:%var_2_2182:  %var_2_2182 = and i8 %var_2_2181, 1
; %var_2_109 = and i8 %var_2_108, 1
; Matched:%var_2_2183:  %var_2_2183 = xor i8 %var_2_2182, 1
; %var_2_110 = xor i8 %var_2_109, 1
; Matched:\<badref\>:  store i8 %var_2_2183, i8* %var_2_21, align 1
; store i8 %var_2_110, i8* %var_2_23, align 1
; Matched:%var_2_2184:  %var_2_2184 = xor i32 %var_2_2175, %var_2_2174
; %var_2_111 = xor i32 %var_2_102, %var_2_101
; Matched:%var_2_2185:  %var_2_2185 = lshr i32 %var_2_2184, 4
; %var_2_112 = lshr i32 %var_2_111, 4
; Matched:%var_2_2186:  %var_2_2186 = trunc i32 %var_2_2185 to i8
; %var_2_113 = trunc i32 %var_2_112 to i8
; Matched:%var_2_2187:  %var_2_2187 = and i8 %var_2_2186, 1
; %var_2_114 = and i8 %var_2_113, 1
; Matched:\<badref\>:  store i8 %var_2_2187, i8* %var_2_27, align 1
; store i8 %var_2_114, i8* %var_2_29, align 1
; Matched:%var_2_2188:  %var_2_2188 = icmp eq i32 %var_2_2175, 0
; %var_2_115 = icmp eq i32 %var_2_102, 0
; Matched:%var_2_2189:  %var_2_2189 = zext i1 %var_2_2188 to i8
; %var_2_116 = zext i1 %var_2_115 to i8
; Matched:\<badref\>:  store i8 %var_2_2189, i8* %var_2_30, align 1
; store i8 %var_2_116, i8* %var_2_32, align 1
; Matched:%var_2_2190:  %var_2_2190 = lshr i32 %var_2_2175, 31
; %var_2_117 = lshr i32 %var_2_102, 31
; Matched:%var_2_2191:  %var_2_2191 = trunc i32 %var_2_2190 to i8
; %var_2_118 = trunc i32 %var_2_117 to i8
; Matched:\<badref\>:  store i8 %var_2_2191, i8* %var_2_33, align 1
; store i8 %var_2_118, i8* %var_2_35, align 1
; Matched:%var_2_2192:  %var_2_2192 = lshr i32 %var_2_2174, 31
; %var_2_119 = lshr i32 %var_2_101, 31
; Matched:%var_2_2193:  %var_2_2193 = xor i32 %var_2_2190, %var_2_2192
; %var_2_120 = xor i32 %var_2_117, %var_2_119
; Matched:%var_2_2194:  %var_2_2194 = add nuw nsw i32 %var_2_2193, %var_2_2190
; %var_2_121 = add nuw nsw i32 %var_2_120, %var_2_117
; Matched:%var_2_2195:  %var_2_2195 = icmp eq i32 %var_2_2194, 2
; %var_2_122 = icmp eq i32 %var_2_121, 2
; Matched:%var_2_2196:  %var_2_2196 = zext i1 %var_2_2195 to i8
; %var_2_123 = zext i1 %var_2_122 to i8
; Matched:\<badref\>:  store i8 %var_2_2196, i8* %var_2_39, align 1
; store i8 %var_2_123, i8* %var_2_41, align 1
; Matched:%var_2_2197:  %var_2_2197 = add i64 %var_2_2166, 17
; %var_2_124 = add i64 %var_2_3719, 17
; Matched:\<badref\>:  store i64 %var_2_2197, i64* %var_2_3, align 8
; store i64 %var_2_124, i64* %PC, align 8
; Matched:\<badref\>:  store i32 %var_2_2175, i32* %var_2_2173, align 4
; store i32 %var_2_102, i32* %var_2_100, align 4
; Matched:%var_2_2198:  %var_2_2198 = load i64, i64* %RBP.i, align 8
; %var_2_125 = load i64, i64* %RBP, align 8
; Matched:%var_2_2199:  %var_2_2199 = add i64 %var_2_2198, -48
; %var_2_126 = add i64 %var_2_125, -48
%var_2_127 = load i64, i64* %PC, align 8
; Matched:%var_2_2084:  %var_2_2084 = add i64 %var_2_2083, 3
; %var_2_128 = add i64 %var_2_127, 3
; Matched:\<badref\>:  store i64 %var_2_2084, i64* %var_2_3, align 8
; store i64 %var_2_128, i64* %PC, align 8
; Matched:%var_2_2202:  %var_2_2202 = inttoptr i64 %var_2_2199 to i32*
; %var_2_129 = inttoptr i64 %var_2_126 to i32*
; Matched:%var_2_2203:  %var_2_2203 = load i32, i32* %var_2_2202, align 4
; %var_2_130 = load i32, i32* %var_2_129, align 4
; Matched:%var_2_2204:  %var_2_2204 = shl i32 %var_2_2203, 1
; %var_2_131 = shl i32 %var_2_130, 1
; Matched:%var_2_2205:  %var_2_2205 = icmp slt i32 %var_2_2203, 0
; %var_2_132 = icmp slt i32 %var_2_130, 0
; Matched:%var_2_2206:  %var_2_2206 = icmp slt i32 %var_2_2204, 0
; %var_2_133 = icmp slt i32 %var_2_131, 0
; Matched:%var_2_2207:  %var_2_2207 = xor i1 %var_2_2205, %var_2_2206
; %var_2_134 = xor i1 %var_2_132, %var_2_133
; Matched:%var_2_2208:  %var_2_2208 = zext i32 %var_2_2204 to i64
; %var_2_135 = zext i32 %var_2_131 to i64
; Matched:\<badref\>:  store i64 %var_2_2208, i64* %RAX.i2224, align 8
; store i64 %var_2_135, i64* %RAX, align 8
; Matched:  %.lobit5 = lshr i32 %var_2_2203, 31
; %.lobit5 = lshr i32 %var_2_130, 31
; Matched:%var_2_2209:  %var_2_2209 = trunc i32 %.lobit5 to i8
; %var_2_136 = trunc i32 %.lobit5 to i8
; Matched:\<badref\>:  store i8 %var_2_2209, i8* %var_2_14, align 1
; store i8 %var_2_136, i8* %var_2_16, align 1
; Matched:%var_2_2210:  %var_2_2210 = and i32 %var_2_2204, 254
; %var_2_137 = and i32 %var_2_131, 254
; Matched:%var_2_2211:  %var_2_2211 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2210)
; %var_2_138 = tail call i32 @llvm.ctpop.i32(i32 %var_2_137) #14
; Matched:%var_2_2212:  %var_2_2212 = trunc i32 %var_2_2211 to i8
; %var_2_139 = trunc i32 %var_2_138 to i8
; Matched:%var_2_2213:  %var_2_2213 = and i8 %var_2_2212, 1
; %var_2_140 = and i8 %var_2_139, 1
; Matched:%var_2_2214:  %var_2_2214 = xor i8 %var_2_2213, 1
; %var_2_141 = xor i8 %var_2_140, 1
; Matched:\<badref\>:  store i8 %var_2_2214, i8* %var_2_21, align 1
; store i8 %var_2_141, i8* %var_2_23, align 1
store i8 0, i8* %var_2_29, align 1
; Matched:%var_2_2215:  %var_2_2215 = icmp eq i32 %var_2_2204, 0
; %var_2_142 = icmp eq i32 %var_2_131, 0
; Matched:%var_2_2216:  %var_2_2216 = zext i1 %var_2_2215 to i8
; %var_2_143 = zext i1 %var_2_142 to i8
; Matched:\<badref\>:  store i8 %var_2_2216, i8* %var_2_30, align 1
; store i8 %var_2_143, i8* %var_2_32, align 1
; Matched:%var_2_2217:  %var_2_2217 = lshr i32 %var_2_2203, 30
; %var_2_144 = lshr i32 %var_2_130, 30
; Matched:%var_2_2218:  %var_2_2218 = trunc i32 %var_2_2217 to i8
; %var_2_145 = trunc i32 %var_2_144 to i8
; Matched:%var_2_2219:  %var_2_2219 = and i8 %var_2_2218, 1
; %var_2_146 = and i8 %var_2_145, 1
; Matched:\<badref\>:  store i8 %var_2_2219, i8* %var_2_33, align 1
; store i8 %var_2_146, i8* %var_2_35, align 1
; Matched:%var_2_2220:  %var_2_2220 = zext i1 %var_2_2207 to i8
; %var_2_147 = zext i1 %var_2_134 to i8
; Matched:\<badref\>:  store i8 %var_2_2220, i8* %var_2_39, align 1
; store i8 %var_2_147, i8* %var_2_41, align 1
; Matched:%var_2_2221:  %var_2_2221 = add i64 %var_2_2198, -52
; %var_2_148 = add i64 %var_2_125, -52
%var_2_149 = add i64 %var_2_127, 9
store i64 %var_2_149, i64* %PC, align 8
; Matched:%var_2_2223:  %var_2_2223 = inttoptr i64 %var_2_2221 to i32*
; %var_2_150 = inttoptr i64 %var_2_148 to i32*
; Matched:\<badref\>:  store i32 %var_2_2204, i32* %var_2_2223, align 4
; store i32 %var_2_131, i32* %var_2_150, align 4
; Matched:%var_2_2285:  %var_2_2285 = load i64, i64* %RBP.i, align 8
; %var_2_151 = load i64, i64* %RBP, align 8
; Matched:%var_2_2244:  %var_2_2244 = add i64 %var_2_2243, -24
; %var_2_152 = add i64 %var_2_151, -24
%var_2_153 = load i64, i64* %PC, align 8
; Matched:%var_2_2246:  %var_2_2246 = add i64 %var_2_2245, 4
; %var_2_154 = add i64 %var_2_153, 4
; Matched:\<badref\>:  store i64 %var_2_2246, i64* %var_2_3, align 8
; store i64 %var_2_154, i64* %PC, align 8
; Matched:%var_2_2247:  %var_2_2247 = inttoptr i64 %var_2_2244 to i64*
; %var_2_155 = inttoptr i64 %var_2_152 to i64*
; Matched:%var_2_2290:  %var_2_2290 = load i64, i64* %var_2_2289, align 8
; %var_2_156 = load i64, i64* %var_2_155, align 8
; Matched:\<badref\>:  store i64 %var_2_2248, i64* %RCX.i2236, align 8
; store i64 %var_2_156, i64* %RCX, align 8
; Matched:%var_2_2230:  %var_2_2230 = add i64 %var_2_2224, -48
; %var_2_157 = add i64 %var_2_151, -48
%var_2_158 = add i64 %var_2_153, 8
store i64 %var_2_158, i64* %PC, align 8
; Matched:%var_2_2232:  %var_2_2232 = inttoptr i64 %var_2_2230 to i32*
; %var_2_159 = inttoptr i64 %var_2_157 to i32*
; Matched:%var_2_2233:  %var_2_2233 = load i32, i32* %var_2_2232, align 4
; %var_2_160 = load i32, i32* %var_2_159, align 4
; Matched:%var_2_2234:  %var_2_2234 = sext i32 %var_2_2233 to i64
; %var_2_161 = sext i32 %var_2_160 to i64
; Matched:\<badref\>:  store i64 %var_2_2234, i64* %RDX.i2239, align 8
; store i64 %var_2_161, i64* %RDX, align 8
; Matched:%var_2_2235:  %var_2_2235 = shl nsw i64 %var_2_2234, 3
; %var_2_162 = shl nsw i64 %var_2_161, 3
; Matched:%var_2_2236:  %var_2_2236 = add i64 %var_2_2235, %var_2_2229
; %var_2_163 = add i64 %var_2_162, %var_2_156
; Matched:%var_2_810:  %var_2_810 = add i64 %var_2_805, 13
; %var_2_164 = add i64 %var_2_153, 13
; Matched:\<badref\>:  store i64 %var_2_266, i64* %var_2_3, align 8
; store i64 %var_2_164, i64* %PC, align 8
; Matched:%var_2_2238:  %var_2_2238 = inttoptr i64 %var_2_2236 to i64*
; %var_2_165 = inttoptr i64 %var_2_163 to i64*
; Matched:%var_2_2239:  %var_2_2239 = load i64, i64* %var_2_2238, align 8
; %var_2_166 = load i64, i64* %var_2_165, align 8
; Matched:\<badref\>:  store i64 %var_2_2239, i64* %var_2_1054, align 1
; store i64 %var_2_166, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_2240:  %var_2_2240 = add i64 %var_2_2224, -88
; %var_2_167 = add i64 %var_2_151, -88
; Matched:%var_2_322:  %var_2_322 = add i64 %var_2_288, 18
; %var_2_168 = add i64 %var_2_153, 18
; Matched:\<badref\>:  store i64 %var_2_322, i64* %var_2_3, align 8
; store i64 %var_2_168, i64* %PC, align 8
; Matched:%var_2_2242:  %var_2_2242 = inttoptr i64 %var_2_2240 to i64*
; %var_2_169 = inttoptr i64 %var_2_167 to i64*
; Matched:\<badref\>:  store i64 %var_2_2239, i64* %var_2_2242, align 8
; store i64 %var_2_166, i64* %var_2_169, align 8
; Matched:%var_2_2304:  %var_2_2304 = load i64, i64* %RBP.i, align 8
; %var_2_170 = load i64, i64* %RBP, align 8
; Matched:%var_2_2225:  %var_2_2225 = add i64 %var_2_2224, -24
; %var_2_171 = add i64 %var_2_170, -24
%var_2_172 = load i64, i64* %PC, align 8
; Matched:%var_2_2909:  %var_2_2909 = add i64 %var_2_2908, 4
; %var_2_173 = add i64 %var_2_172, 4
; Matched:\<badref\>:  store i64 %var_2_2909, i64* %var_2_3, align 8
; store i64 %var_2_173, i64* %PC, align 8
; Matched:%var_2_2228:  %var_2_2228 = inttoptr i64 %var_2_2225 to i64*
; %var_2_174 = inttoptr i64 %var_2_171 to i64*
; Matched:%var_2_2309:  %var_2_2309 = load i64, i64* %var_2_2308, align 8
; %var_2_175 = load i64, i64* %var_2_174, align 8
; Matched:\<badref\>:  store i64 %var_2_2229, i64* %RCX.i2236, align 8
; store i64 %var_2_175, i64* %RCX, align 8
; Matched:%var_2_2249:  %var_2_2249 = add i64 %var_2_2243, -48
; %var_2_176 = add i64 %var_2_170, -48
; Matched:%var_2_1372:  %var_2_1372 = add i64 %var_2_1367, 7
; %var_2_177 = add i64 %var_2_172, 7
; Matched:\<badref\>:  store i64 %var_2_91, i64* %var_2_3, align 8
; store i64 %var_2_177, i64* %PC, align 8
; Matched:%var_2_2251:  %var_2_2251 = inttoptr i64 %var_2_2249 to i32*
; %var_2_178 = inttoptr i64 %var_2_176 to i32*
; Matched:%var_2_2252:  %var_2_2252 = load i32, i32* %var_2_2251, align 4
; %var_2_179 = load i32, i32* %var_2_178, align 4
; Matched:%var_2_2253:  %var_2_2253 = add i32 %var_2_2252, 1
; %var_2_180 = add i32 %var_2_179, 1
; Matched:%var_2_2254:  %var_2_2254 = zext i32 %var_2_2253 to i64
; %var_2_181 = zext i32 %var_2_180 to i64
; Matched:\<badref\>:  store i64 %var_2_2254, i64* %RAX.i2224, align 8
; store i64 %var_2_181, i64* %RAX, align 8
; Matched:%var_2_2255:  %var_2_2255 = icmp eq i32 %var_2_2252, -1
; %var_2_182 = icmp eq i32 %var_2_179, -1
; Matched:%var_2_2256:  %var_2_2256 = icmp eq i32 %var_2_2253, 0
; %var_2_183 = icmp eq i32 %var_2_180, 0
; Matched:%var_2_2257:  %var_2_2257 = or i1 %var_2_2255, %var_2_2256
; %var_2_184 = or i1 %var_2_182, %var_2_183
; Matched:%var_2_2258:  %var_2_2258 = zext i1 %var_2_2257 to i8
; %var_2_185 = zext i1 %var_2_184 to i8
; Matched:\<badref\>:  store i8 %var_2_2258, i8* %var_2_14, align 1
; store i8 %var_2_185, i8* %var_2_16, align 1
; Matched:%var_2_2259:  %var_2_2259 = and i32 %var_2_2253, 255
; %var_2_186 = and i32 %var_2_180, 255
; Matched:%var_2_2260:  %var_2_2260 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2259)
; %var_2_187 = tail call i32 @llvm.ctpop.i32(i32 %var_2_186) #14
; Matched:%var_2_2261:  %var_2_2261 = trunc i32 %var_2_2260 to i8
; %var_2_188 = trunc i32 %var_2_187 to i8
; Matched:%var_2_2262:  %var_2_2262 = and i8 %var_2_2261, 1
; %var_2_189 = and i8 %var_2_188, 1
; Matched:%var_2_2263:  %var_2_2263 = xor i8 %var_2_2262, 1
; %var_2_190 = xor i8 %var_2_189, 1
; Matched:\<badref\>:  store i8 %var_2_2263, i8* %var_2_21, align 1
; store i8 %var_2_190, i8* %var_2_23, align 1
; Matched:%var_2_2264:  %var_2_2264 = xor i32 %var_2_2253, %var_2_2252
; %var_2_191 = xor i32 %var_2_180, %var_2_179
; Matched:%var_2_2265:  %var_2_2265 = lshr i32 %var_2_2264, 4
; %var_2_192 = lshr i32 %var_2_191, 4
; Matched:%var_2_2266:  %var_2_2266 = trunc i32 %var_2_2265 to i8
; %var_2_193 = trunc i32 %var_2_192 to i8
; Matched:%var_2_2267:  %var_2_2267 = and i8 %var_2_2266, 1
; %var_2_194 = and i8 %var_2_193, 1
; Matched:\<badref\>:  store i8 %var_2_2267, i8* %var_2_27, align 1
; store i8 %var_2_194, i8* %var_2_29, align 1
; Matched:%var_2_2268:  %var_2_2268 = zext i1 %var_2_2256 to i8
; %var_2_195 = zext i1 %var_2_183 to i8
; Matched:\<badref\>:  store i8 %var_2_2268, i8* %var_2_30, align 1
; store i8 %var_2_195, i8* %var_2_32, align 1
; Matched:%var_2_2269:  %var_2_2269 = lshr i32 %var_2_2253, 31
; %var_2_196 = lshr i32 %var_2_180, 31
; Matched:%var_2_2270:  %var_2_2270 = trunc i32 %var_2_2269 to i8
; %var_2_197 = trunc i32 %var_2_196 to i8
; Matched:\<badref\>:  store i8 %var_2_2270, i8* %var_2_33, align 1
; store i8 %var_2_197, i8* %var_2_35, align 1
; Matched:%var_2_2271:  %var_2_2271 = lshr i32 %var_2_2252, 31
; %var_2_198 = lshr i32 %var_2_179, 31
; Matched:%var_2_2272:  %var_2_2272 = xor i32 %var_2_2269, %var_2_2271
; %var_2_199 = xor i32 %var_2_196, %var_2_198
; Matched:%var_2_2273:  %var_2_2273 = add nuw nsw i32 %var_2_2272, %var_2_2269
; %var_2_200 = add nuw nsw i32 %var_2_199, %var_2_196
; Matched:%var_2_2274:  %var_2_2274 = icmp eq i32 %var_2_2273, 2
; %var_2_201 = icmp eq i32 %var_2_200, 2
; Matched:%var_2_2275:  %var_2_2275 = zext i1 %var_2_2274 to i8
; %var_2_202 = zext i1 %var_2_201 to i8
; Matched:\<badref\>:  store i8 %var_2_2275, i8* %var_2_39, align 1
; store i8 %var_2_202, i8* %var_2_41, align 1
; Matched:%var_2_2276:  %var_2_2276 = sext i32 %var_2_2253 to i64
; %var_2_203 = sext i32 %var_2_180 to i64
; Matched:\<badref\>:  store i64 %var_2_2276, i64* %RDX.i2239, align 8
; store i64 %var_2_203, i64* %RDX, align 8
; Matched:%var_2_2277:  %var_2_2277 = shl nsw i64 %var_2_2276, 3
; %var_2_204 = shl nsw i64 %var_2_203, 3
; Matched:%var_2_2278:  %var_2_2278 = add i64 %var_2_2248, %var_2_2277
; %var_2_205 = add i64 %var_2_175, %var_2_204
; Matched:%var_2_661:  %var_2_661 = add i64 %var_2_627, 18
; %var_2_206 = add i64 %var_2_172, 18
; Matched:\<badref\>:  store i64 %var_2_661, i64* %var_2_3, align 8
; store i64 %var_2_206, i64* %PC, align 8
; Matched:%var_2_2280:  %var_2_2280 = inttoptr i64 %var_2_2278 to i64*
; %var_2_207 = inttoptr i64 %var_2_205 to i64*
; Matched:%var_2_2281:  %var_2_2281 = load i64, i64* %var_2_2280, align 8
; %var_2_208 = load i64, i64* %var_2_207, align 8
; Matched:\<badref\>:  store i64 %var_2_2281, i64* %var_2_1054, align 1
; store i64 %var_2_208, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_2282:  %var_2_2282 = add i64 %var_2_2243, -96
; %var_2_209 = add i64 %var_2_170, -96
; Matched:%var_2_2012:  %var_2_2012 = add i64 %var_2_1995, 23
; %var_2_210 = add i64 %var_2_172, 23
; Matched:\<badref\>:  store i64 %var_2_2012, i64* %var_2_3, align 8
; store i64 %var_2_210, i64* %PC, align 8
; Matched:%var_2_2284:  %var_2_2284 = inttoptr i64 %var_2_2282 to i64*
; %var_2_211 = inttoptr i64 %var_2_209 to i64*
; Matched:\<badref\>:  store i64 %var_2_2281, i64* %var_2_2284, align 8
; store i64 %var_2_208, i64* %var_2_211, align 8
; Matched:%var_2_2243:  %var_2_2243 = load i64, i64* %RBP.i, align 8
; %var_2_212 = load i64, i64* %RBP, align 8
; Matched:%var_2_2305:  %var_2_2305 = add i64 %var_2_2304, -24
; %var_2_213 = add i64 %var_2_212, -24
%var_2_214 = load i64, i64* %PC, align 8
; Matched:%var_2_402:  %var_2_402 = add i64 %var_2_401, 4
; %var_2_215 = add i64 %var_2_214, 4
; Matched:\<badref\>:  store i64 %var_2_402, i64* %var_2_3, align 8
; store i64 %var_2_215, i64* %PC, align 8
; Matched:%var_2_2308:  %var_2_2308 = inttoptr i64 %var_2_2305 to i64*
; %var_2_216 = inttoptr i64 %var_2_213 to i64*
; Matched:%var_2_2248:  %var_2_2248 = load i64, i64* %var_2_2247, align 8
; %var_2_217 = load i64, i64* %var_2_216, align 8
; Matched:\<badref\>:  store i64 %var_2_2309, i64* %RCX.i2236, align 8
; store i64 %var_2_217, i64* %RCX, align 8
; Matched:%var_2_2291:  %var_2_2291 = add i64 %var_2_2285, -52
; %var_2_218 = add i64 %var_2_212, -52
%var_2_219 = add i64 %var_2_214, 8
store i64 %var_2_219, i64* %PC, align 8
; Matched:%var_2_2293:  %var_2_2293 = inttoptr i64 %var_2_2291 to i32*
; %var_2_220 = inttoptr i64 %var_2_218 to i32*
; Matched:%var_2_2294:  %var_2_2294 = load i32, i32* %var_2_2293, align 4
; %var_2_221 = load i32, i32* %var_2_220, align 4
; Matched:%var_2_2295:  %var_2_2295 = sext i32 %var_2_2294 to i64
; %var_2_222 = sext i32 %var_2_221 to i64
; Matched:\<badref\>:  store i64 %var_2_2295, i64* %RDX.i2239, align 8
; store i64 %var_2_222, i64* %RDX, align 8
; Matched:%var_2_2296:  %var_2_2296 = shl nsw i64 %var_2_2295, 3
; %var_2_223 = shl nsw i64 %var_2_222, 3
; Matched:%var_2_2297:  %var_2_2297 = add i64 %var_2_2296, %var_2_2290
; %var_2_224 = add i64 %var_2_223, %var_2_217
; Matched:%var_2_785:  %var_2_785 = add i64 %var_2_780, 13
; %var_2_225 = add i64 %var_2_214, 13
; Matched:\<badref\>:  store i64 %var_2_785, i64* %var_2_3, align 8
; store i64 %var_2_225, i64* %PC, align 8
; Matched:%var_2_2299:  %var_2_2299 = inttoptr i64 %var_2_2297 to i64*
; %var_2_226 = inttoptr i64 %var_2_224 to i64*
; Matched:%var_2_2300:  %var_2_2300 = load i64, i64* %var_2_2299, align 8
; %var_2_227 = load i64, i64* %var_2_226, align 8
; Matched:\<badref\>:  store i64 %var_2_2300, i64* %var_2_1054, align 1
; store i64 %var_2_227, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_2301:  %var_2_2301 = add i64 %var_2_2285, -72
; %var_2_228 = add i64 %var_2_212, -72
; Matched:%var_2_3599:  %var_2_3599 = add i64 %var_2_3582, 18
; %var_2_229 = add i64 %var_2_214, 18
; Matched:\<badref\>:  store i64 %var_2_3599, i64* %var_2_3, align 8
; store i64 %var_2_229, i64* %PC, align 8
; Matched:%var_2_2303:  %var_2_2303 = inttoptr i64 %var_2_2301 to i64*
; %var_2_230 = inttoptr i64 %var_2_228 to i64*
; Matched:\<badref\>:  store i64 %var_2_2300, i64* %var_2_2303, align 8
; store i64 %var_2_227, i64* %var_2_230, align 8
; Matched:%var_2_2224:  %var_2_2224 = load i64, i64* %RBP.i, align 8
; %var_2_231 = load i64, i64* %RBP, align 8
; Matched:%var_2_2286:  %var_2_2286 = add i64 %var_2_2285, -24
; %var_2_232 = add i64 %var_2_231, -24
%var_2_233 = load i64, i64* %PC, align 8
; Matched:%var_2_2603:  %var_2_2603 = add i64 %var_2_2602, 4
; %var_2_234 = add i64 %var_2_233, 4
; Matched:\<badref\>:  store i64 %var_2_2603, i64* %var_2_3, align 8
; store i64 %var_2_234, i64* %PC, align 8
; Matched:%var_2_2289:  %var_2_2289 = inttoptr i64 %var_2_2286 to i64*
; %var_2_235 = inttoptr i64 %var_2_232 to i64*
; Matched:%var_2_2229:  %var_2_2229 = load i64, i64* %var_2_2228, align 8
; %var_2_236 = load i64, i64* %var_2_235, align 8
; Matched:\<badref\>:  store i64 %var_2_2290, i64* %RCX.i2236, align 8
; store i64 %var_2_236, i64* %RCX, align 8
; Matched:%var_2_2310:  %var_2_2310 = add i64 %var_2_2304, -52
; %var_2_237 = add i64 %var_2_231, -52
; Matched:%var_2_2720:  %var_2_2720 = add i64 %var_2_2715, 7
; %var_2_238 = add i64 %var_2_233, 7
; Matched:\<badref\>:  store i64 %var_2_632, i64* %var_2_3, align 8
; store i64 %var_2_238, i64* %PC, align 8
; Matched:%var_2_2312:  %var_2_2312 = inttoptr i64 %var_2_2310 to i32*
; %var_2_239 = inttoptr i64 %var_2_237 to i32*
; Matched:%var_2_2313:  %var_2_2313 = load i32, i32* %var_2_2312, align 4
; %var_2_240 = load i32, i32* %var_2_239, align 4
; Matched:%var_2_2314:  %var_2_2314 = add i32 %var_2_2313, 1
; %var_2_241 = add i32 %var_2_240, 1
; Matched:%var_2_2315:  %var_2_2315 = zext i32 %var_2_2314 to i64
; %var_2_242 = zext i32 %var_2_241 to i64
; Matched:\<badref\>:  store i64 %var_2_2315, i64* %RAX.i2224, align 8
; store i64 %var_2_242, i64* %RAX, align 8
; Matched:%var_2_2316:  %var_2_2316 = icmp eq i32 %var_2_2313, -1
; %var_2_243 = icmp eq i32 %var_2_240, -1
; Matched:%var_2_2317:  %var_2_2317 = icmp eq i32 %var_2_2314, 0
; %var_2_244 = icmp eq i32 %var_2_241, 0
; Matched:%var_2_2318:  %var_2_2318 = or i1 %var_2_2316, %var_2_2317
; %var_2_245 = or i1 %var_2_243, %var_2_244
; Matched:%var_2_2319:  %var_2_2319 = zext i1 %var_2_2318 to i8
; %var_2_246 = zext i1 %var_2_245 to i8
; Matched:\<badref\>:  store i8 %var_2_2319, i8* %var_2_14, align 1
; store i8 %var_2_246, i8* %var_2_16, align 1
; Matched:%var_2_2320:  %var_2_2320 = and i32 %var_2_2314, 255
; %var_2_247 = and i32 %var_2_241, 255
; Matched:%var_2_2321:  %var_2_2321 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2320)
; %var_2_248 = tail call i32 @llvm.ctpop.i32(i32 %var_2_247) #14
; Matched:%var_2_2322:  %var_2_2322 = trunc i32 %var_2_2321 to i8
; %var_2_249 = trunc i32 %var_2_248 to i8
; Matched:%var_2_2323:  %var_2_2323 = and i8 %var_2_2322, 1
; %var_2_250 = and i8 %var_2_249, 1
; Matched:%var_2_2324:  %var_2_2324 = xor i8 %var_2_2323, 1
; %var_2_251 = xor i8 %var_2_250, 1
; Matched:\<badref\>:  store i8 %var_2_2324, i8* %var_2_21, align 1
; store i8 %var_2_251, i8* %var_2_23, align 1
; Matched:%var_2_2325:  %var_2_2325 = xor i32 %var_2_2314, %var_2_2313
; %var_2_252 = xor i32 %var_2_241, %var_2_240
; Matched:%var_2_2326:  %var_2_2326 = lshr i32 %var_2_2325, 4
; %var_2_253 = lshr i32 %var_2_252, 4
; Matched:%var_2_2327:  %var_2_2327 = trunc i32 %var_2_2326 to i8
; %var_2_254 = trunc i32 %var_2_253 to i8
; Matched:%var_2_2328:  %var_2_2328 = and i8 %var_2_2327, 1
; %var_2_255 = and i8 %var_2_254, 1
; Matched:\<badref\>:  store i8 %var_2_2328, i8* %var_2_27, align 1
; store i8 %var_2_255, i8* %var_2_29, align 1
; Matched:%var_2_2329:  %var_2_2329 = zext i1 %var_2_2317 to i8
; %var_2_256 = zext i1 %var_2_244 to i8
; Matched:\<badref\>:  store i8 %var_2_2329, i8* %var_2_30, align 1
; store i8 %var_2_256, i8* %var_2_32, align 1
; Matched:%var_2_2330:  %var_2_2330 = lshr i32 %var_2_2314, 31
; %var_2_257 = lshr i32 %var_2_241, 31
; Matched:%var_2_2331:  %var_2_2331 = trunc i32 %var_2_2330 to i8
; %var_2_258 = trunc i32 %var_2_257 to i8
; Matched:\<badref\>:  store i8 %var_2_2331, i8* %var_2_33, align 1
; store i8 %var_2_258, i8* %var_2_35, align 1
; Matched:%var_2_2332:  %var_2_2332 = lshr i32 %var_2_2313, 31
; %var_2_259 = lshr i32 %var_2_240, 31
; Matched:%var_2_2333:  %var_2_2333 = xor i32 %var_2_2330, %var_2_2332
; %var_2_260 = xor i32 %var_2_257, %var_2_259
; Matched:%var_2_2334:  %var_2_2334 = add nuw nsw i32 %var_2_2333, %var_2_2330
; %var_2_261 = add nuw nsw i32 %var_2_260, %var_2_257
; Matched:%var_2_2335:  %var_2_2335 = icmp eq i32 %var_2_2334, 2
; %var_2_262 = icmp eq i32 %var_2_261, 2
; Matched:%var_2_2336:  %var_2_2336 = zext i1 %var_2_2335 to i8
; %var_2_263 = zext i1 %var_2_262 to i8
; Matched:\<badref\>:  store i8 %var_2_2336, i8* %var_2_39, align 1
; store i8 %var_2_263, i8* %var_2_41, align 1
; Matched:%var_2_2337:  %var_2_2337 = sext i32 %var_2_2314 to i64
; %var_2_264 = sext i32 %var_2_241 to i64
; Matched:\<badref\>:  store i64 %var_2_2337, i64* %RDX.i2239, align 8
; store i64 %var_2_264, i64* %RDX, align 8
; Matched:%var_2_2338:  %var_2_2338 = shl nsw i64 %var_2_2337, 3
; %var_2_265 = shl nsw i64 %var_2_264, 3
; Matched:%var_2_2339:  %var_2_2339 = add i64 %var_2_2309, %var_2_2338
; %var_2_266 = add i64 %var_2_236, %var_2_265
; Matched:%var_2_2365:  %var_2_2365 = add i64 %var_2_2348, 18
; %var_2_267 = add i64 %var_2_233, 18
; Matched:\<badref\>:  store i64 %var_2_1288, i64* %var_2_3, align 8
; store i64 %var_2_267, i64* %PC, align 8
; Matched:%var_2_2341:  %var_2_2341 = inttoptr i64 %var_2_2339 to i64*
; %var_2_268 = inttoptr i64 %var_2_266 to i64*
; Matched:%var_2_2342:  %var_2_2342 = load i64, i64* %var_2_2341, align 8
; %var_2_269 = load i64, i64* %var_2_268, align 8
; Matched:\<badref\>:  store i64 %var_2_2342, i64* %var_2_1054, align 1
; store i64 %var_2_269, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_2343:  %var_2_2343 = add i64 %var_2_2304, -80
; %var_2_270 = add i64 %var_2_231, -80
; Matched:%var_2_1981:  %var_2_1981 = add i64 %var_2_1964, 23
; %var_2_271 = add i64 %var_2_233, 23
; Matched:\<badref\>:  store i64 %var_2_3578, i64* %var_2_3, align 8
; store i64 %var_2_271, i64* %PC, align 8
; Matched:%var_2_2345:  %var_2_2345 = inttoptr i64 %var_2_2343 to i64*
; %var_2_272 = inttoptr i64 %var_2_270 to i64*
; Matched:\<badref\>:  store i64 %var_2_2342, i64* %var_2_2345, align 8
; store i64 %var_2_269, i64* %var_2_272, align 8
; Matched:%var_2_3580:  %var_2_3580 = load i64, i64* %RBP.i, align 8
; %var_2_273 = load i64, i64* %RBP, align 8
; Matched:%var_2_3581:  %var_2_3581 = add i64 %var_2_3580, -72
; %var_2_274 = add i64 %var_2_273, -72
%var_2_275 = load i64, i64* %PC, align 8
; Matched:%var_2_4447:  %var_2_4447 = add i64 %var_2_4446, 5
; %var_2_276 = add i64 %var_2_275, 5
; Matched:\<badref\>:  store i64 %var_2_4447, i64* %var_2_3, align 8
; store i64 %var_2_276, i64* %PC, align 8
; Matched:%var_2_3584:  %var_2_3584 = inttoptr i64 %var_2_3581 to i64*
; %var_2_277 = inttoptr i64 %var_2_274 to i64*
; Matched:%var_2_3585:  %var_2_3585 = load i64, i64* %var_2_3584, align 8
; %var_2_278 = load i64, i64* %var_2_277, align 8
; Matched:\<badref\>:  store i64 %var_2_3585, i64* %var_2_1054, align 1
; store i64 %var_2_278, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
%var_2_279 = load <2 x i32>, <2 x i32>* %var_2_1348, align 1
%var_2_280 = load <2 x i32>, <2 x i32>* %var_2_1349, align 1
%var_2_281 = extractelement <2 x i32> %var_2_279, i32 0
; Matched:\<badref\>:  store i32 %var_2_3588, i32* %var_2_2121, align 1
; store i32 %var_2_281, i32* %var_2_1350, align 1
%var_2_282 = extractelement <2 x i32> %var_2_279, i32 1
; Matched:\<badref\>:  store i32 %var_2_2355, i32* %var_2_2123, align 1
; store i32 %var_2_282, i32* %var_2_1352, align 1
%var_2_283 = extractelement <2 x i32> %var_2_280, i32 0
; Matched:\<badref\>:  store i32 %var_2_3590, i32* %var_2_2125, align 1
; store i32 %var_2_283, i32* %var_2_1354, align 1
%var_2_284 = extractelement <2 x i32> %var_2_280, i32 1
; Matched:\<badref\>:  store i32 %var_2_3591, i32* %var_2_2127, align 1
; store i32 %var_2_284, i32* %var_2_1356, align 1
; Matched:%var_2_2358:  %var_2_2358 = add i64 %var_2_2346, -96
; %var_2_285 = add i64 %var_2_273, -96
; Matched:%var_2_4376:  %var_2_4376 = add i64 %var_2_4371, 13
; %var_2_286 = add i64 %var_2_275, 13
; Matched:\<badref\>:  store i64 %var_2_4376, i64* %var_2_3, align 8
; store i64 %var_2_286, i64* %PC, align 8
; Matched:%var_2_2360:  %var_2_2360 = load double, double* %var_2_2128, align 1
; %var_2_287 = load double, double* %var_2_1357, align 1
; Matched:%var_2_2361:  %var_2_2361 = inttoptr i64 %var_2_2358 to double*
; %var_2_288 = inttoptr i64 %var_2_285 to double*
; Matched:%var_2_2362:  %var_2_2362 = load double, double* %var_2_2361, align 8
; %var_2_289 = load double, double* %var_2_288, align 8
; Matched:%var_2_2363:  %var_2_2363 = fmul double %var_2_2360, %var_2_2362
; %var_2_290 = fmul double %var_2_287, %var_2_289
; Matched:\<badref\>:  store double %var_2_2363, double* %var_2_2128, align 1
; store double %var_2_290, double* %var_2_1357, align 1
; Matched:%var_2_2364:  %var_2_2364 = add i64 %var_2_2346, -80
; %var_2_291 = add i64 %var_2_273, -80
; Matched:%var_2_1288:  %var_2_1288 = add i64 %var_2_1254, 18
; %var_2_292 = add i64 %var_2_275, 18
; Matched:\<badref\>:  store i64 %var_2_2241, i64* %var_2_3, align 8
; store i64 %var_2_292, i64* %PC, align 8
; Matched:%var_2_2366:  %var_2_2366 = inttoptr i64 %var_2_2364 to double*
; %var_2_293 = inttoptr i64 %var_2_291 to double*
; Matched:%var_2_2367:  %var_2_2367 = load double, double* %var_2_2366, align 8
; %var_2_294 = load double, double* %var_2_293, align 8
; Matched:%var_2_2368:  %var_2_2368 = fmul double %var_2_2363, %var_2_2367
; %var_2_295 = fmul double %var_2_290, %var_2_294
; Matched:\<badref\>:  store double %var_2_2368, double* %var_2_2128, align 1
; store double %var_2_295, double* %var_2_1357, align 1
; Matched:%var_2_2369:  %var_2_2369 = bitcast i64 %var_2_2351 to double
; %var_2_296 = bitcast i64 %var_2_278 to double
; Matched:%var_2_2370:  %var_2_2370 = fsub double %var_2_2369, %var_2_2368
; %var_2_297 = fsub double %var_2_296, %var_2_295
; Matched:\<badref\>:  store double %var_2_2370, double* %var_2_1053, align 1
; store double %var_2_297, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_2371:  %var_2_2371 = add i64 %var_2_2346, -104
; %var_2_298 = add i64 %var_2_273, -104
; Matched:%var_2_3606:  %var_2_3606 = add i64 %var_2_3582, 27
; %var_2_299 = add i64 %var_2_275, 27
; Matched:\<badref\>:  store i64 %var_2_3606, i64* %var_2_3, align 8
; store i64 %var_2_299, i64* %PC, align 8
; Matched:%var_2_2373:  %var_2_2373 = inttoptr i64 %var_2_2371 to double*
; %var_2_300 = inttoptr i64 %var_2_298 to double*
; Matched:\<badref\>:  store double %var_2_2370, double* %var_2_2373, align 8
; store double %var_2_297, double* %var_2_300, align 8
; Matched:%var_2_2374:  %var_2_2374 = load i64, i64* %RBP.i, align 8
; %var_2_301 = load i64, i64* %RBP, align 8
; Matched:%var_2_2375:  %var_2_2375 = add i64 %var_2_2374, -96
; %var_2_302 = add i64 %var_2_301, -96
%var_2_303 = load i64, i64* %PC, align 8
; Matched:%var_2_1850:  %var_2_1850 = add i64 %var_2_1849, 5
; %var_2_304 = add i64 %var_2_303, 5
; Matched:\<badref\>:  store i64 %var_2_3373, i64* %var_2_3, align 8
; store i64 %var_2_304, i64* %PC, align 8
; Matched:%var_2_2378:  %var_2_2378 = load double, double* %var_2_1037, align 1
; %var_2_305 = load double, double* %var_2_93, align 1
; Matched:%var_2_2379:  %var_2_2379 = inttoptr i64 %var_2_2375 to double*
; %var_2_306 = inttoptr i64 %var_2_302 to double*
; Matched:%var_2_2380:  %var_2_2380 = load double, double* %var_2_2379, align 8
; %var_2_307 = load double, double* %var_2_306, align 8
; Matched:%var_2_2381:  %var_2_2381 = fmul double %var_2_2378, %var_2_2380
; %var_2_308 = fmul double %var_2_305, %var_2_307
; Matched:\<badref\>:  store double %var_2_2381, double* %var_2_1037, align 1
; store double %var_2_308, double* %var_2_93, align 1
; Matched:%var_2_2382:  %var_2_2382 = add i64 %var_2_2374, -72
; %var_2_309 = add i64 %var_2_301, -72
; Matched:%var_2_1854:  %var_2_1854 = add i64 %var_2_1849, 10
; %var_2_310 = add i64 %var_2_303, 10
; Matched:\<badref\>:  store i64 %var_2_1854, i64* %var_2_3, align 8
; store i64 %var_2_310, i64* %PC, align 8
; Matched:%var_2_2384:  %var_2_2384 = inttoptr i64 %var_2_2382 to double*
; %var_2_311 = inttoptr i64 %var_2_309 to double*
; Matched:%var_2_2385:  %var_2_2385 = load double, double* %var_2_2384, align 8
; %var_2_312 = load double, double* %var_2_311, align 8
; Matched:%var_2_2386:  %var_2_2386 = fmul double %var_2_2381, %var_2_2385
; %var_2_313 = fmul double %var_2_308, %var_2_312
; Matched:\<badref\>:  store double %var_2_2386, double* %var_2_1037, align 1
; store double %var_2_313, double* %var_2_93, align 1
; Matched:%var_2_2387:  %var_2_2387 = add i64 %var_2_2374, -80
; %var_2_314 = add i64 %var_2_301, -80
; Matched:%var_2_3622:  %var_2_3622 = add i64 %var_2_3610, 15
; %var_2_315 = add i64 %var_2_303, 15
; Matched:\<badref\>:  store i64 %var_2_3622, i64* %var_2_3, align 8
; store i64 %var_2_315, i64* %PC, align 8
; Matched:%var_2_2389:  %var_2_2389 = inttoptr i64 %var_2_2387 to double*
; %var_2_316 = inttoptr i64 %var_2_314 to double*
; Matched:%var_2_2390:  %var_2_2390 = load double, double* %var_2_2389, align 8
; %var_2_317 = load double, double* %var_2_316, align 8
; Matched:%var_2_2391:  %var_2_2391 = fsub double %var_2_2386, %var_2_2390
; %var_2_318 = fsub double %var_2_313, %var_2_317
; Matched:\<badref\>:  store double %var_2_2391, double* %var_2_1037, align 1
; store double %var_2_318, double* %var_2_93, align 1
; Matched:%var_2_2392:  %var_2_2392 = add i64 %var_2_2374, -112
; %var_2_319 = add i64 %var_2_301, -112
; Matched:%var_2_3387:  %var_2_3387 = add i64 %var_2_3372, 20
; %var_2_320 = add i64 %var_2_303, 20
; Matched:\<badref\>:  store i64 %var_2_3387, i64* %var_2_3, align 8
; store i64 %var_2_320, i64* %PC, align 8
; Matched:%var_2_2394:  %var_2_2394 = inttoptr i64 %var_2_2392 to double*
; %var_2_321 = inttoptr i64 %var_2_319 to double*
; Matched:\<badref\>:  store double %var_2_2391, double* %var_2_2394, align 8
; store double %var_2_318, double* %var_2_321, align 8
%var_2_322 = load i64, i64* %RBP, align 8
; Matched:%var_2_2396:  %var_2_2396 = add i64 %var_2_2395, -44
; %var_2_323 = add i64 %var_2_322, -44
%var_2_324 = load i64, i64* %PC, align 8
; Matched:%var_2_1181:  %var_2_1181 = add i64 %var_2_1180, 3
; %var_2_325 = add i64 %var_2_324, 3
; Matched:\<badref\>:  store i64 %var_2_1181, i64* %var_2_3, align 8
; store i64 %var_2_325, i64* %PC, align 8
; Matched:%var_2_2399:  %var_2_2399 = inttoptr i64 %var_2_2396 to i32*
; %var_2_326 = inttoptr i64 %var_2_323 to i32*
; Matched:%var_2_2134:  %var_2_2134 = load i32, i32* %var_2_2133, align 4
; %var_2_327 = load i32, i32* %var_2_326, align 4
; Matched:%var_2_2135:  %var_2_2135 = zext i32 %var_2_2134 to i64
; %var_2_328 = zext i32 %var_2_327 to i64
; Matched:\<badref\>:  store i64 %var_2_2401, i64* %RAX.i2224, align 8
; store i64 %var_2_328, i64* %RAX, align 8
; Matched:%var_2_2402:  %var_2_2402 = add i64 %var_2_2395, -28
; %var_2_329 = add i64 %var_2_322, -28
; Matched:%var_2_3637:  %var_2_3637 = add i64 %var_2_3631, 6
; %var_2_330 = add i64 %var_2_324, 6
; Matched:\<badref\>:  store i64 %var_2_3637, i64* %var_2_3, align 8
; store i64 %var_2_330, i64* %PC, align 8
; Matched:%var_2_2404:  %var_2_2404 = inttoptr i64 %var_2_2402 to i32*
; %var_2_331 = inttoptr i64 %var_2_329 to i32*
; Matched:\<badref\>:  store i32 %var_2_2400, i32* %var_2_2404, align 4
; store i32 %var_2_327, i32* %var_2_331, align 4
; Matched:  %.pre25 = load i64, i64* %var_2_3, align 8
; %.pre25 = load i64, i64* %PC, align 8
  br label %block_403940

block_4035d2:                                     ; preds = %block_4035c1
; Matched:%var_2_1102:  %var_2_1102 = add i64 %var_2_1101, 3
; %var_2_332 = add i64 %var_2_4810, 3
; Matched:\<badref\>:  store i64 %var_2_1102, i64* %var_2_3, align 8
; store i64 %var_2_332, i64* %PC, align 8
%var_2_333 = load i32, i32* %var_2_4770, align 4
; Matched:%var_2_104:  %var_2_104 = zext i32 %var_2_103 to i64
; %var_2_334 = zext i32 %var_2_333 to i64
; Matched:\<badref\>:  store i64 %var_2_104, i64* %RAX.i2224, align 8
; store i64 %var_2_334, i64* %RAX, align 8
; Matched:%var_2_1105:  %var_2_1105 = add i64 %var_2_1101, 6
; %var_2_335 = add i64 %var_2_4810, 6
; Matched:\<badref\>:  store i64 %var_2_1105, i64* %var_2_3, align 8
; store i64 %var_2_335, i64* %PC, align 8
%var_2_336 = load i32, i32* %var_2_4775, align 4
%var_2_337 = add i32 %var_2_336, %var_2_333
; Matched:%var_2_2456:  %var_2_2456 = zext i32 %var_2_2455 to i64
; %var_2_338 = zext i32 %var_2_337 to i64
; Matched:\<badref\>:  store i64 %var_2_1108, i64* %RAX.i2224, align 8
; store i64 %var_2_338, i64* %RAX, align 8
; Matched:%var_2_2457:  %var_2_2457 = icmp ult i32 %var_2_2455, %var_2_2451
; %var_2_339 = icmp ult i32 %var_2_337, %var_2_333
; Matched:%var_2_144:  %var_2_144 = icmp ult i32 %var_2_141, %var_2_140
; %var_2_340 = icmp ult i32 %var_2_337, %var_2_336
; Matched:%var_2_1111:  %var_2_1111 = or i1 %var_2_1109, %var_2_1110
; %var_2_341 = or i1 %var_2_339, %var_2_340
; Matched:%var_2_146:  %var_2_146 = zext i1 %var_2_145 to i8
; %var_2_342 = zext i1 %var_2_341 to i8
; Matched:\<badref\>:  store i8 %var_2_146, i8* %var_2_14, align 1
; store i8 %var_2_342, i8* %var_2_16, align 1
; Matched:%var_2_147:  %var_2_147 = and i32 %var_2_141, 255
; %var_2_343 = and i32 %var_2_337, 255
; Matched:%var_2_2462:  %var_2_2462 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2461)
; %var_2_344 = tail call i32 @llvm.ctpop.i32(i32 %var_2_343) #14
; Matched:%var_2_2463:  %var_2_2463 = trunc i32 %var_2_2462 to i8
; %var_2_345 = trunc i32 %var_2_344 to i8
; Matched:%var_2_2464:  %var_2_2464 = and i8 %var_2_2463, 1
; %var_2_346 = and i8 %var_2_345, 1
; Matched:%var_2_151:  %var_2_151 = xor i8 %var_2_150, 1
; %var_2_347 = xor i8 %var_2_346, 1
; Matched:\<badref\>:  store i8 %var_2_1117, i8* %var_2_21, align 1
; store i8 %var_2_347, i8* %var_2_23, align 1
; Matched:%var_2_152:  %var_2_152 = xor i32 %var_2_140, %var_2_137
; %var_2_348 = xor i32 %var_2_336, %var_2_333
; Matched:%var_2_153:  %var_2_153 = xor i32 %var_2_152, %var_2_141
; %var_2_349 = xor i32 %var_2_348, %var_2_337
; Matched:%var_2_154:  %var_2_154 = lshr i32 %var_2_153, 4
; %var_2_350 = lshr i32 %var_2_349, 4
; Matched:%var_2_2469:  %var_2_2469 = trunc i32 %var_2_2468 to i8
; %var_2_351 = trunc i32 %var_2_350 to i8
; Matched:%var_2_2470:  %var_2_2470 = and i8 %var_2_2469, 1
; %var_2_352 = and i8 %var_2_351, 1
; Matched:\<badref\>:  store i8 %var_2_2470, i8* %var_2_27, align 1
; store i8 %var_2_352, i8* %var_2_29, align 1
; Matched:%var_2_157:  %var_2_157 = icmp eq i32 %var_2_141, 0
; %var_2_353 = icmp eq i32 %var_2_337, 0
; Matched:%var_2_1124:  %var_2_1124 = zext i1 %var_2_1123 to i8
; %var_2_354 = zext i1 %var_2_353 to i8
; Matched:\<badref\>:  store i8 %var_2_158, i8* %var_2_30, align 1
; store i8 %var_2_354, i8* %var_2_32, align 1
; Matched:%var_2_159:  %var_2_159 = lshr i32 %var_2_141, 31
; %var_2_355 = lshr i32 %var_2_337, 31
; Matched:%var_2_160:  %var_2_160 = trunc i32 %var_2_159 to i8
; %var_2_356 = trunc i32 %var_2_355 to i8
; Matched:\<badref\>:  store i8 %var_2_2474, i8* %var_2_33, align 1
; store i8 %var_2_356, i8* %var_2_35, align 1
; Matched:%var_2_161:  %var_2_161 = lshr i32 %var_2_137, 31
; %var_2_357 = lshr i32 %var_2_333, 31
; Matched:%var_2_2476:  %var_2_2476 = lshr i32 %var_2_2454, 31
; %var_2_358 = lshr i32 %var_2_336, 31
; Matched:%var_2_163:  %var_2_163 = xor i32 %var_2_159, %var_2_161
; %var_2_359 = xor i32 %var_2_355, %var_2_357
; Matched:%var_2_2478:  %var_2_2478 = xor i32 %var_2_2473, %var_2_2476
; %var_2_360 = xor i32 %var_2_355, %var_2_358
; Matched:%var_2_165:  %var_2_165 = add nuw nsw i32 %var_2_163, %var_2_164
; %var_2_361 = add nuw nsw i32 %var_2_359, %var_2_360
; Matched:%var_2_166:  %var_2_166 = icmp eq i32 %var_2_165, 2
; %var_2_362 = icmp eq i32 %var_2_361, 2
; Matched:%var_2_167:  %var_2_167 = zext i1 %var_2_166 to i8
; %var_2_363 = zext i1 %var_2_362 to i8
; Matched:\<badref\>:  store i8 %var_2_2481, i8* %var_2_39, align 1
; store i8 %var_2_363, i8* %var_2_41, align 1
; Matched:%var_2_168:  %var_2_168 = add i64 %var_2_99, -32
; %var_2_364 = add i64 %var_2_4767, -32
; Matched:%var_2_1135:  %var_2_1135 = add i64 %var_2_1101, 9
; %var_2_365 = add i64 %var_2_4810, 9
; Matched:\<badref\>:  store i64 %var_2_1135, i64* %var_2_3, align 8
; store i64 %var_2_365, i64* %PC, align 8
; Matched:%var_2_2484:  %var_2_2484 = inttoptr i64 %var_2_2482 to i32*
; %var_2_366 = inttoptr i64 %var_2_364 to i32*
; Matched:\<badref\>:  store i32 %var_2_2455, i32* %var_2_2484, align 4
; store i32 %var_2_337, i32* %var_2_366, align 4
%var_2_367 = load i64, i64* %RBP, align 8
%var_2_368 = add i64 %var_2_367, -32
%var_2_369 = load i64, i64* %PC, align 8
; Matched:%var_2_4767:  %var_2_4767 = add i64 %var_2_4766, 3
; %var_2_370 = add i64 %var_2_369, 3
; Matched:\<badref\>:  store i64 %var_2_4767, i64* %var_2_3, align 8
; store i64 %var_2_370, i64* %PC, align 8
%var_2_371 = inttoptr i64 %var_2_368 to i32*
%var_2_372 = load i32, i32* %var_2_371, align 4
; Matched:%var_2_177:  %var_2_177 = zext i32 %var_2_176 to i64
; %var_2_373 = zext i32 %var_2_372 to i64
; Matched:\<badref\>:  store i64 %var_2_177, i64* %RAX.i2224, align 8
; store i64 %var_2_373, i64* %RAX, align 8
%var_2_374 = add i64 %var_2_367, -8
; Matched:%var_2_179:  %var_2_179 = add i64 %var_2_173, 6
; %var_2_375 = add i64 %var_2_369, 6
; Matched:\<badref\>:  store i64 %var_2_179, i64* %var_2_3, align 8
; store i64 %var_2_375, i64* %PC, align 8
%var_2_376 = inttoptr i64 %var_2_374 to i32*
%var_2_377 = load i32, i32* %var_2_376, align 4
%var_2_378 = add i32 %var_2_377, %var_2_372
; Matched:%var_2_183:  %var_2_183 = zext i32 %var_2_182 to i64
; %var_2_379 = zext i32 %var_2_378 to i64
; Matched:\<badref\>:  store i64 %var_2_183, i64* %RAX.i2224, align 8
; store i64 %var_2_379, i64* %RAX, align 8
; Matched:%var_2_184:  %var_2_184 = icmp ult i32 %var_2_182, %var_2_176
; %var_2_380 = icmp ult i32 %var_2_378, %var_2_372
; Matched:%var_2_2499:  %var_2_2499 = icmp ult i32 %var_2_2496, %var_2_2495
; %var_2_381 = icmp ult i32 %var_2_378, %var_2_377
; Matched:%var_2_186:  %var_2_186 = or i1 %var_2_184, %var_2_185
; %var_2_382 = or i1 %var_2_380, %var_2_381
; Matched:%var_2_2501:  %var_2_2501 = zext i1 %var_2_2500 to i8
; %var_2_383 = zext i1 %var_2_382 to i8
; Matched:\<badref\>:  store i8 %var_2_187, i8* %var_2_14, align 1
; store i8 %var_2_383, i8* %var_2_16, align 1
; Matched:%var_2_2502:  %var_2_2502 = and i32 %var_2_2496, 255
; %var_2_384 = and i32 %var_2_378, 255
; Matched:%var_2_189:  %var_2_189 = tail call i32 @llvm.ctpop.i32(i32 %var_2_188)
; %var_2_385 = tail call i32 @llvm.ctpop.i32(i32 %var_2_384) #14
; Matched:%var_2_190:  %var_2_190 = trunc i32 %var_2_189 to i8
; %var_2_386 = trunc i32 %var_2_385 to i8
; Matched:%var_2_191:  %var_2_191 = and i8 %var_2_190, 1
; %var_2_387 = and i8 %var_2_386, 1
; Matched:%var_2_2506:  %var_2_2506 = xor i8 %var_2_2505, 1
; %var_2_388 = xor i8 %var_2_387, 1
; Matched:\<badref\>:  store i8 %var_2_192, i8* %var_2_21, align 1
; store i8 %var_2_388, i8* %var_2_23, align 1
; Matched:%var_2_2507:  %var_2_2507 = xor i32 %var_2_2495, %var_2_2490
; %var_2_389 = xor i32 %var_2_377, %var_2_372
; Matched:%var_2_194:  %var_2_194 = xor i32 %var_2_193, %var_2_182
; %var_2_390 = xor i32 %var_2_389, %var_2_378
; Matched:%var_2_2509:  %var_2_2509 = lshr i32 %var_2_2508, 4
; %var_2_391 = lshr i32 %var_2_390, 4
; Matched:%var_2_196:  %var_2_196 = trunc i32 %var_2_195 to i8
; %var_2_392 = trunc i32 %var_2_391 to i8
; Matched:%var_2_197:  %var_2_197 = and i8 %var_2_196, 1
; %var_2_393 = and i8 %var_2_392, 1
; Matched:\<badref\>:  store i8 %var_2_197, i8* %var_2_27, align 1
; store i8 %var_2_393, i8* %var_2_29, align 1
; Matched:%var_2_2512:  %var_2_2512 = icmp eq i32 %var_2_2496, 0
; %var_2_394 = icmp eq i32 %var_2_378, 0
; Matched:%var_2_199:  %var_2_199 = zext i1 %var_2_198 to i8
; %var_2_395 = zext i1 %var_2_394 to i8
; Matched:\<badref\>:  store i8 %var_2_2513, i8* %var_2_30, align 1
; store i8 %var_2_395, i8* %var_2_32, align 1
; Matched:%var_2_200:  %var_2_200 = lshr i32 %var_2_182, 31
; %var_2_396 = lshr i32 %var_2_378, 31
; Matched:%var_2_2515:  %var_2_2515 = trunc i32 %var_2_2514 to i8
; %var_2_397 = trunc i32 %var_2_396 to i8
; Matched:\<badref\>:  store i8 %var_2_201, i8* %var_2_33, align 1
; store i8 %var_2_397, i8* %var_2_35, align 1
; Matched:%var_2_202:  %var_2_202 = lshr i32 %var_2_176, 31
; %var_2_398 = lshr i32 %var_2_372, 31
; Matched:%var_2_203:  %var_2_203 = lshr i32 %var_2_181, 31
; %var_2_399 = lshr i32 %var_2_377, 31
; Matched:%var_2_2518:  %var_2_2518 = xor i32 %var_2_2514, %var_2_2516
; %var_2_400 = xor i32 %var_2_396, %var_2_398
; Matched:%var_2_205:  %var_2_205 = xor i32 %var_2_200, %var_2_203
; %var_2_401 = xor i32 %var_2_396, %var_2_399
; Matched:%var_2_2520:  %var_2_2520 = add nuw nsw i32 %var_2_2518, %var_2_2519
; %var_2_402 = add nuw nsw i32 %var_2_400, %var_2_401
; Matched:%var_2_207:  %var_2_207 = icmp eq i32 %var_2_206, 2
; %var_2_403 = icmp eq i32 %var_2_402, 2
; Matched:%var_2_2522:  %var_2_2522 = zext i1 %var_2_2521 to i8
; %var_2_404 = zext i1 %var_2_403 to i8
; Matched:\<badref\>:  store i8 %var_2_208, i8* %var_2_39, align 1
; store i8 %var_2_404, i8* %var_2_41, align 1
; Matched:%var_2_209:  %var_2_209 = add i64 %var_2_171, -36
; %var_2_405 = add i64 %var_2_367, -36
%var_2_406 = add i64 %var_2_369, 9
store i64 %var_2_406, i64* %PC, align 8
; Matched:%var_2_2525:  %var_2_2525 = inttoptr i64 %var_2_2523 to i32*
; %var_2_407 = inttoptr i64 %var_2_405 to i32*
; Matched:\<badref\>:  store i32 %var_2_2496, i32* %var_2_2525, align 4
; store i32 %var_2_378, i32* %var_2_407, align 4
%var_2_408 = load i64, i64* %RBP, align 8
%var_2_409 = add i64 %var_2_408, -36
%var_2_410 = load i64, i64* %PC, align 8
; Matched:%var_2_2050:  %var_2_2050 = add i64 %var_2_2049, 3
; %var_2_411 = add i64 %var_2_410, 3
; Matched:\<badref\>:  store i64 %var_2_3632, i64* %var_2_3, align 8
; store i64 %var_2_411, i64* %PC, align 8
%var_2_412 = inttoptr i64 %var_2_409 to i32*
%var_2_413 = load i32, i32* %var_2_412, align 4
; Matched:%var_2_1184:  %var_2_1184 = zext i32 %var_2_1183 to i64
; %var_2_414 = zext i32 %var_2_413 to i64
; Matched:\<badref\>:  store i64 %var_2_2532, i64* %RAX.i2224, align 8
; store i64 %var_2_414, i64* %RAX, align 8
%var_2_415 = add i64 %var_2_408, -8
; Matched:%var_2_1145:  %var_2_1145 = add i64 %var_2_1139, 6
; %var_2_416 = add i64 %var_2_410, 6
; Matched:\<badref\>:  store i64 %var_2_220, i64* %var_2_3, align 8
; store i64 %var_2_416, i64* %PC, align 8
%var_2_417 = inttoptr i64 %var_2_415 to i32*
%var_2_418 = load i32, i32* %var_2_417, align 4
%var_2_419 = add i32 %var_2_418, %var_2_413
; Matched:%var_2_1190:  %var_2_1190 = zext i32 %var_2_1189 to i64
; %var_2_420 = zext i32 %var_2_419 to i64
; Matched:\<badref\>:  store i64 %var_2_2538, i64* %RAX.i2224, align 8
; store i64 %var_2_420, i64* %RAX, align 8
; Matched:%var_2_2539:  %var_2_2539 = icmp ult i32 %var_2_2537, %var_2_2531
; %var_2_421 = icmp ult i32 %var_2_419, %var_2_413
; Matched:%var_2_226:  %var_2_226 = icmp ult i32 %var_2_223, %var_2_222
; %var_2_422 = icmp ult i32 %var_2_419, %var_2_418
; Matched:%var_2_227:  %var_2_227 = or i1 %var_2_225, %var_2_226
; %var_2_423 = or i1 %var_2_421, %var_2_422
; Matched:%var_2_228:  %var_2_228 = zext i1 %var_2_227 to i8
; %var_2_424 = zext i1 %var_2_423 to i8
; Matched:\<badref\>:  store i8 %var_2_2542, i8* %var_2_14, align 1
; store i8 %var_2_424, i8* %var_2_16, align 1
; Matched:%var_2_2543:  %var_2_2543 = and i32 %var_2_2537, 255
; %var_2_425 = and i32 %var_2_419, 255
; Matched:%var_2_2544:  %var_2_2544 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2543)
; %var_2_426 = tail call i32 @llvm.ctpop.i32(i32 %var_2_425) #14
; Matched:%var_2_231:  %var_2_231 = trunc i32 %var_2_230 to i8
; %var_2_427 = trunc i32 %var_2_426 to i8
; Matched:%var_2_2546:  %var_2_2546 = and i8 %var_2_2545, 1
; %var_2_428 = and i8 %var_2_427, 1
; Matched:%var_2_233:  %var_2_233 = xor i8 %var_2_232, 1
; %var_2_429 = xor i8 %var_2_428, 1
; Matched:\<badref\>:  store i8 %var_2_233, i8* %var_2_21, align 1
; store i8 %var_2_429, i8* %var_2_23, align 1
; Matched:%var_2_234:  %var_2_234 = xor i32 %var_2_222, %var_2_217
; %var_2_430 = xor i32 %var_2_418, %var_2_413
; Matched:%var_2_2549:  %var_2_2549 = xor i32 %var_2_2548, %var_2_2537
; %var_2_431 = xor i32 %var_2_430, %var_2_419
; Matched:%var_2_2550:  %var_2_2550 = lshr i32 %var_2_2549, 4
; %var_2_432 = lshr i32 %var_2_431, 4
; Matched:%var_2_237:  %var_2_237 = trunc i32 %var_2_236 to i8
; %var_2_433 = trunc i32 %var_2_432 to i8
; Matched:%var_2_2552:  %var_2_2552 = and i8 %var_2_2551, 1
; %var_2_434 = and i8 %var_2_433, 1
; Matched:\<badref\>:  store i8 %var_2_2552, i8* %var_2_27, align 1
; store i8 %var_2_434, i8* %var_2_29, align 1
; Matched:%var_2_2553:  %var_2_2553 = icmp eq i32 %var_2_2537, 0
; %var_2_435 = icmp eq i32 %var_2_419, 0
; Matched:%var_2_240:  %var_2_240 = zext i1 %var_2_239 to i8
; %var_2_436 = zext i1 %var_2_435 to i8
; Matched:\<badref\>:  store i8 %var_2_240, i8* %var_2_30, align 1
; store i8 %var_2_436, i8* %var_2_32, align 1
; Matched:%var_2_2555:  %var_2_2555 = lshr i32 %var_2_2537, 31
; %var_2_437 = lshr i32 %var_2_419, 31
; Matched:%var_2_2556:  %var_2_2556 = trunc i32 %var_2_2555 to i8
; %var_2_438 = trunc i32 %var_2_437 to i8
; Matched:\<badref\>:  store i8 %var_2_242, i8* %var_2_33, align 1
; store i8 %var_2_438, i8* %var_2_35, align 1
; Matched:%var_2_2557:  %var_2_2557 = lshr i32 %var_2_2531, 31
; %var_2_439 = lshr i32 %var_2_413, 31
; Matched:%var_2_2558:  %var_2_2558 = lshr i32 %var_2_2536, 31
; %var_2_440 = lshr i32 %var_2_418, 31
; Matched:%var_2_2559:  %var_2_2559 = xor i32 %var_2_2555, %var_2_2557
; %var_2_441 = xor i32 %var_2_437, %var_2_439
; Matched:%var_2_246:  %var_2_246 = xor i32 %var_2_241, %var_2_244
; %var_2_442 = xor i32 %var_2_437, %var_2_440
; Matched:%var_2_247:  %var_2_247 = add nuw nsw i32 %var_2_245, %var_2_246
; %var_2_443 = add nuw nsw i32 %var_2_441, %var_2_442
; Matched:%var_2_2562:  %var_2_2562 = icmp eq i32 %var_2_2561, 2
; %var_2_444 = icmp eq i32 %var_2_443, 2
; Matched:%var_2_2563:  %var_2_2563 = zext i1 %var_2_2562 to i8
; %var_2_445 = zext i1 %var_2_444 to i8
; Matched:\<badref\>:  store i8 %var_2_249, i8* %var_2_39, align 1
; store i8 %var_2_445, i8* %var_2_41, align 1
; Matched:%var_2_2564:  %var_2_2564 = add i64 %var_2_2526, -40
; %var_2_446 = add i64 %var_2_408, -40
%var_2_447 = add i64 %var_2_410, 9
store i64 %var_2_447, i64* %PC, align 8
; Matched:%var_2_252:  %var_2_252 = inttoptr i64 %var_2_250 to i32*
; %var_2_448 = inttoptr i64 %var_2_446 to i32*
; Matched:\<badref\>:  store i32 %var_2_223, i32* %var_2_252, align 4
; store i32 %var_2_419, i32* %var_2_448, align 4
%var_2_449 = load i64, i64* %RBP, align 8
%var_2_450 = add i64 %var_2_449, -16
%var_2_451 = load i64, i64* %PC, align 8
; Matched:%var_2_1368:  %var_2_1368 = add i64 %var_2_1367, 4
; %var_2_452 = add i64 %var_2_451, 4
; Matched:\<badref\>:  store i64 %var_2_1368, i64* %var_2_3, align 8
; store i64 %var_2_452, i64* %PC, align 8
%var_2_453 = inttoptr i64 %var_2_450 to i64*
%var_2_454 = load i64, i64* %var_2_453, align 8
; Matched:\<badref\>:  store i64 %var_2_371, i64* %RCX.i2236, align 8
; store i64 %var_2_454, i64* %RCX, align 8
%var_2_455 = add i64 %var_2_449, -28
%var_2_456 = add i64 %var_2_451, 8
store i64 %var_2_456, i64* %PC, align 8
%var_2_457 = inttoptr i64 %var_2_455 to i32*
%var_2_458 = load i32, i32* %var_2_457, align 4
%var_2_459 = sext i32 %var_2_458 to i64
; Matched:\<badref\>:  store i64 %var_2_263, i64* %RDX.i2239, align 8
; store i64 %var_2_459, i64* %RDX, align 8
%var_2_460 = shl nsw i64 %var_2_459, 3
%var_2_461 = add i64 %var_2_460, %var_2_454
; Matched:%var_2_379:  %var_2_379 = add i64 %var_2_368, 13
; %var_2_462 = add i64 %var_2_451, 13
; Matched:\<badref\>:  store i64 %var_2_379, i64* %var_2_3, align 8
; store i64 %var_2_462, i64* %PC, align 8
%var_2_463 = inttoptr i64 %var_2_461 to i64*
%var_2_464 = load i64, i64* %var_2_463, align 8
store i64 %var_2_464, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_382:  %var_2_382 = add i64 %var_2_368, 17
; %var_2_465 = add i64 %var_2_451, 17
; Matched:\<badref\>:  store i64 %var_2_382, i64* %var_2_3, align 8
; store i64 %var_2_465, i64* %PC, align 8
%var_2_466 = load i64, i64* %var_2_453, align 8
; Matched:\<badref\>:  store i64 %var_2_2572, i64* %RCX.i2236, align 8
; store i64 %var_2_466, i64* %RCX, align 8
%var_2_467 = add i64 %var_2_449, -32
; Matched:%var_2_385:  %var_2_385 = add i64 %var_2_368, 21
; %var_2_468 = add i64 %var_2_451, 21
; Matched:\<badref\>:  store i64 %var_2_1845, i64* %var_2_3, align 8
; store i64 %var_2_468, i64* %PC, align 8
%var_2_469 = inttoptr i64 %var_2_467 to i32*
%var_2_470 = load i32, i32* %var_2_469, align 4
%var_2_471 = sext i32 %var_2_470 to i64
; Matched:\<badref\>:  store i64 %var_2_1354, i64* %RDX.i2239, align 8
; store i64 %var_2_471, i64* %RDX, align 8
%var_2_472 = shl nsw i64 %var_2_471, 3
%var_2_473 = add i64 %var_2_472, %var_2_466
; Matched:%var_2_2705:  %var_2_2705 = add i64 %var_2_2682, 26
; %var_2_474 = add i64 %var_2_451, 26
; Matched:\<badref\>:  store i64 %var_2_2705, i64* %var_2_3, align 8
; store i64 %var_2_474, i64* %PC, align 8
%var_2_475 = bitcast i64 %var_2_464 to double
%var_2_476 = inttoptr i64 %var_2_473 to double*
%var_2_477 = load double, double* %var_2_476, align 8
%var_2_478 = fadd double %var_2_475, %var_2_477
store double %var_2_478, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_2597:  %var_2_2597 = add i64 %var_2_2567, -120
; %var_2_479 = add i64 %var_2_449, -120
; Matched:%var_2_284:  %var_2_284 = add i64 %var_2_255, 31
; %var_2_480 = add i64 %var_2_451, 31
; Matched:\<badref\>:  store i64 %var_2_284, i64* %var_2_3, align 8
; store i64 %var_2_480, i64* %PC, align 8
; Matched:%var_2_285:  %var_2_285 = inttoptr i64 %var_2_283 to double*
; %var_2_481 = inttoptr i64 %var_2_479 to double*
; Matched:\<badref\>:  store double %var_2_282, double* %var_2_285, align 8
; store double %var_2_478, double* %var_2_481, align 8
%var_2_482 = load i64, i64* %RBP, align 8
%var_2_483 = add i64 %var_2_482, -16
%var_2_484 = load i64, i64* %PC, align 8
; Matched:%var_2_1561:  %var_2_1561 = add i64 %var_2_1560, 4
; %var_2_485 = add i64 %var_2_484, 4
; Matched:\<badref\>:  store i64 %var_2_2942, i64* %var_2_3, align 8
; store i64 %var_2_485, i64* %PC, align 8
%var_2_486 = inttoptr i64 %var_2_483 to i64*
%var_2_487 = load i64, i64* %var_2_486, align 8
; Matched:\<badref\>:  store i64 %var_2_1711, i64* %RCX.i2236, align 8
; store i64 %var_2_487, i64* %RCX, align 8
%var_2_488 = add i64 %var_2_482, -28
; Matched:%var_2_3884:  %var_2_3884 = add i64 %var_2_3879, 7
; %var_2_489 = add i64 %var_2_484, 7
; Matched:\<badref\>:  store i64 %var_2_2946, i64* %var_2_3, align 8
; store i64 %var_2_489, i64* %PC, align 8
%var_2_490 = inttoptr i64 %var_2_488 to i32*
%var_2_491 = load i32, i32* %var_2_490, align 4
%var_2_492 = add i32 %var_2_491, 1
; Matched:%var_2_297:  %var_2_297 = zext i32 %var_2_296 to i64
; %var_2_493 = zext i32 %var_2_492 to i64
; Matched:\<badref\>:  store i64 %var_2_297, i64* %RAX.i2224, align 8
; store i64 %var_2_493, i64* %RAX, align 8
; Matched:%var_2_298:  %var_2_298 = icmp eq i32 %var_2_295, -1
; %var_2_494 = icmp eq i32 %var_2_491, -1
; Matched:%var_2_299:  %var_2_299 = icmp eq i32 %var_2_296, 0
; %var_2_495 = icmp eq i32 %var_2_492, 0
; Matched:%var_2_754:  %var_2_754 = or i1 %var_2_752, %var_2_753
; %var_2_496 = or i1 %var_2_494, %var_2_495
; Matched:%var_2_1380:  %var_2_1380 = zext i1 %var_2_1379 to i8
; %var_2_497 = zext i1 %var_2_496 to i8
; Matched:\<badref\>:  store i8 %var_2_1721, i8* %var_2_14, align 1
; store i8 %var_2_497, i8* %var_2_16, align 1
; Matched:%var_2_302:  %var_2_302 = and i32 %var_2_296, 255
; %var_2_498 = and i32 %var_2_492, 255
; Matched:%var_2_1382:  %var_2_1382 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1381)
; %var_2_499 = tail call i32 @llvm.ctpop.i32(i32 %var_2_498) #14
; Matched:%var_2_1270:  %var_2_1270 = trunc i32 %var_2_1269 to i8
; %var_2_500 = trunc i32 %var_2_499 to i8
; Matched:%var_2_1384:  %var_2_1384 = and i8 %var_2_1383, 1
; %var_2_501 = and i8 %var_2_500, 1
; Matched:%var_2_306:  %var_2_306 = xor i8 %var_2_305, 1
; %var_2_502 = xor i8 %var_2_501, 1
; Matched:\<badref\>:  store i8 %var_2_306, i8* %var_2_21, align 1
; store i8 %var_2_502, i8* %var_2_23, align 1
; Matched:%var_2_4011:  %var_2_4011 = xor i32 %var_2_4000, %var_2_3999
; %var_2_503 = xor i32 %var_2_492, %var_2_491
; Matched:%var_2_4012:  %var_2_4012 = lshr i32 %var_2_4011, 4
; %var_2_504 = lshr i32 %var_2_503, 4
; Matched:%var_2_4013:  %var_2_4013 = trunc i32 %var_2_4012 to i8
; %var_2_505 = trunc i32 %var_2_504 to i8
; Matched:%var_2_764:  %var_2_764 = and i8 %var_2_763, 1
; %var_2_506 = and i8 %var_2_505, 1
; Matched:\<badref\>:  store i8 %var_2_764, i8* %var_2_27, align 1
; store i8 %var_2_506, i8* %var_2_29, align 1
; Matched:%var_2_311:  %var_2_311 = zext i1 %var_2_299 to i8
; %var_2_507 = zext i1 %var_2_495 to i8
; Matched:\<badref\>:  store i8 %var_2_765, i8* %var_2_30, align 1
; store i8 %var_2_507, i8* %var_2_32, align 1
; Matched:%var_2_312:  %var_2_312 = lshr i32 %var_2_296, 31
; %var_2_508 = lshr i32 %var_2_492, 31
; Matched:%var_2_767:  %var_2_767 = trunc i32 %var_2_766 to i8
; %var_2_509 = trunc i32 %var_2_508 to i8
; Matched:\<badref\>:  store i8 %var_2_1392, i8* %var_2_33, align 1
; store i8 %var_2_509, i8* %var_2_35, align 1
; Matched:%var_2_1393:  %var_2_1393 = lshr i32 %var_2_1374, 31
; %var_2_510 = lshr i32 %var_2_491, 31
; Matched:%var_2_1394:  %var_2_1394 = xor i32 %var_2_1391, %var_2_1393
; %var_2_511 = xor i32 %var_2_508, %var_2_510
; Matched:%var_2_4361:  %var_2_4361 = add nuw nsw i32 %var_2_4360, %var_2_4357
; %var_2_512 = add nuw nsw i32 %var_2_511, %var_2_508
; Matched:%var_2_1396:  %var_2_1396 = icmp eq i32 %var_2_1395, 2
; %var_2_513 = icmp eq i32 %var_2_512, 2
; Matched:%var_2_1284:  %var_2_1284 = zext i1 %var_2_1283 to i8
; %var_2_514 = zext i1 %var_2_513 to i8
; Matched:\<badref\>:  store i8 %var_2_1284, i8* %var_2_39, align 1
; store i8 %var_2_514, i8* %var_2_41, align 1
%var_2_515 = sext i32 %var_2_492 to i64
; Matched:\<badref\>:  store i64 %var_2_773, i64* %RDX.i2239, align 8
; store i64 %var_2_515, i64* %RDX, align 8
%var_2_516 = shl nsw i64 %var_2_515, 3
%var_2_517 = add i64 %var_2_487, %var_2_516
; Matched:%var_2_4026:  %var_2_4026 = add i64 %var_2_3992, 18
; %var_2_518 = add i64 %var_2_484, 18
; Matched:\<badref\>:  store i64 %var_2_4026, i64* %var_2_3, align 8
; store i64 %var_2_518, i64* %PC, align 8
%var_2_519 = inttoptr i64 %var_2_517 to i64*
%var_2_520 = load i64, i64* %var_2_519, align 8
store i64 %var_2_520, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_4395:  %var_2_4395 = add i64 %var_2_4385, 22
; %var_2_521 = add i64 %var_2_484, 22
; Matched:\<badref\>:  store i64 %var_2_551, i64* %var_2_3, align 8
; store i64 %var_2_521, i64* %PC, align 8
%var_2_522 = load i64, i64* %var_2_486, align 8
; Matched:\<badref\>:  store i64 %var_2_866, i64* %RCX.i2236, align 8
; store i64 %var_2_522, i64* %RCX, align 8
%var_2_523 = add i64 %var_2_482, -32
; Matched:%var_2_328:  %var_2_328 = add i64 %var_2_288, 25
; %var_2_524 = add i64 %var_2_484, 25
; Matched:\<badref\>:  store i64 %var_2_328, i64* %var_2_3, align 8
; store i64 %var_2_524, i64* %PC, align 8
%var_2_525 = inttoptr i64 %var_2_523 to i32*
%var_2_526 = load i32, i32* %var_2_525, align 4
%var_2_527 = add i32 %var_2_526, 1
; Matched:%var_2_332:  %var_2_332 = zext i32 %var_2_331 to i64
; %var_2_528 = zext i32 %var_2_527 to i64
; Matched:\<badref\>:  store i64 %var_2_332, i64* %RAX.i2224, align 8
; store i64 %var_2_528, i64* %RAX, align 8
; Matched:%var_2_898:  %var_2_898 = icmp eq i32 %var_2_895, -1
; %var_2_529 = icmp eq i32 %var_2_526, -1
; Matched:%var_2_4614:  %var_2_4614 = icmp eq i32 %var_2_4611, 0
; %var_2_530 = icmp eq i32 %var_2_527, 0
; Matched:%var_2_4615:  %var_2_4615 = or i1 %var_2_4613, %var_2_4614
; %var_2_531 = or i1 %var_2_529, %var_2_530
; Matched:%var_2_901:  %var_2_901 = zext i1 %var_2_900 to i8
; %var_2_532 = zext i1 %var_2_531 to i8
; Matched:\<badref\>:  store i8 %var_2_449, i8* %var_2_14, align 1
; store i8 %var_2_532, i8* %var_2_16, align 1
; Matched:%var_2_337:  %var_2_337 = and i32 %var_2_331, 255
; %var_2_533 = and i32 %var_2_527, 255
; Matched:%var_2_903:  %var_2_903 = tail call i32 @llvm.ctpop.i32(i32 %var_2_902)
; %var_2_534 = tail call i32 @llvm.ctpop.i32(i32 %var_2_533) #14
; Matched:%var_2_452:  %var_2_452 = trunc i32 %var_2_451 to i8
; %var_2_535 = trunc i32 %var_2_534 to i8
; Matched:%var_2_453:  %var_2_453 = and i8 %var_2_452, 1
; %var_2_536 = and i8 %var_2_535, 1
; Matched:%var_2_906:  %var_2_906 = xor i8 %var_2_905, 1
; %var_2_537 = xor i8 %var_2_536, 1
; Matched:\<badref\>:  store i8 %var_2_906, i8* %var_2_21, align 1
; store i8 %var_2_537, i8* %var_2_23, align 1
; Matched:%var_2_4622:  %var_2_4622 = xor i32 %var_2_4611, %var_2_4610
; %var_2_538 = xor i32 %var_2_527, %var_2_526
; Matched:%var_2_4623:  %var_2_4623 = lshr i32 %var_2_4622, 4
; %var_2_539 = lshr i32 %var_2_538, 4
; Matched:%var_2_4624:  %var_2_4624 = trunc i32 %var_2_4623 to i8
; %var_2_540 = trunc i32 %var_2_539 to i8
; Matched:%var_2_4625:  %var_2_4625 = and i8 %var_2_4624, 1
; %var_2_541 = and i8 %var_2_540, 1
; Matched:\<badref\>:  store i8 %var_2_4625, i8* %var_2_27, align 1
; store i8 %var_2_541, i8* %var_2_29, align 1
; Matched:%var_2_459:  %var_2_459 = zext i1 %var_2_447 to i8
; %var_2_542 = zext i1 %var_2_530 to i8
; Matched:\<badref\>:  store i8 %var_2_459, i8* %var_2_30, align 1
; store i8 %var_2_542, i8* %var_2_32, align 1
; Matched:%var_2_912:  %var_2_912 = lshr i32 %var_2_896, 31
; %var_2_543 = lshr i32 %var_2_527, 31
; Matched:%var_2_913:  %var_2_913 = trunc i32 %var_2_912 to i8
; %var_2_544 = trunc i32 %var_2_543 to i8
; Matched:\<badref\>:  store i8 %var_2_4628, i8* %var_2_33, align 1
; store i8 %var_2_544, i8* %var_2_35, align 1
; Matched:%var_2_349:  %var_2_349 = lshr i32 %var_2_330, 31
; %var_2_545 = lshr i32 %var_2_526, 31
; Matched:%var_2_350:  %var_2_350 = xor i32 %var_2_347, %var_2_349
; %var_2_546 = xor i32 %var_2_543, %var_2_545
; Matched:%var_2_916:  %var_2_916 = add nuw nsw i32 %var_2_915, %var_2_912
; %var_2_547 = add nuw nsw i32 %var_2_546, %var_2_543
; Matched:%var_2_4632:  %var_2_4632 = icmp eq i32 %var_2_4631, 2
; %var_2_548 = icmp eq i32 %var_2_547, 2
; Matched:%var_2_4633:  %var_2_4633 = zext i1 %var_2_4632 to i8
; %var_2_549 = zext i1 %var_2_548 to i8
; Matched:\<badref\>:  store i8 %var_2_918, i8* %var_2_39, align 1
; store i8 %var_2_549, i8* %var_2_41, align 1
%var_2_550 = sext i32 %var_2_527 to i64
; Matched:\<badref\>:  store i64 %var_2_354, i64* %RDX.i2239, align 8
; store i64 %var_2_550, i64* %RDX, align 8
%var_2_551 = shl nsw i64 %var_2_550, 3
%var_2_552 = add i64 %var_2_522, %var_2_551
; Matched:%var_2_1436:  %var_2_1436 = add i64 %var_2_1367, 36
; %var_2_553 = add i64 %var_2_484, 36
; Matched:\<badref\>:  store i64 %var_2_1436, i64* %var_2_3, align 8
; store i64 %var_2_553, i64* %PC, align 8
%var_2_554 = bitcast i64 %var_2_520 to double
%var_2_555 = inttoptr i64 %var_2_552 to double*
%var_2_556 = load double, double* %var_2_555, align 8
%var_2_557 = fadd double %var_2_554, %var_2_556
store double %var_2_557, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_2676:  %var_2_2676 = load i64, i64* %RBP.i, align 8
; %var_2_558 = load i64, i64* %RBP, align 8
; Matched:%var_2_363:  %var_2_363 = add i64 %var_2_362, -128
; %var_2_559 = add i64 %var_2_558, -128
; Matched:%var_2_4479:  %var_2_4479 = add i64 %var_2_4446, 41
; %var_2_560 = add i64 %var_2_484, 41
; Matched:\<badref\>:  store i64 %var_2_2678, i64* %var_2_3, align 8
; store i64 %var_2_560, i64* %PC, align 8
; Matched:%var_2_365:  %var_2_365 = inttoptr i64 %var_2_363 to double*
; %var_2_561 = inttoptr i64 %var_2_559 to double*
; Matched:\<badref\>:  store double %var_2_361, double* %var_2_365, align 8
; store double %var_2_557, double* %var_2_561, align 8
%var_2_562 = load i64, i64* %RBP, align 8
%var_2_563 = add i64 %var_2_562, -16
%var_2_564 = load i64, i64* %PC, align 8
; Matched:%var_2_3542:  %var_2_3542 = add i64 %var_2_3541, 4
; %var_2_565 = add i64 %var_2_564, 4
; Matched:\<badref\>:  store i64 %var_2_3542, i64* %var_2_3, align 8
; store i64 %var_2_565, i64* %PC, align 8
%var_2_566 = inttoptr i64 %var_2_563 to i64*
%var_2_567 = load i64, i64* %var_2_566, align 8
; Matched:\<badref\>:  store i64 %var_2_1337, i64* %RCX.i2236, align 8
; store i64 %var_2_567, i64* %RCX, align 8
%var_2_568 = add i64 %var_2_562, -28
%var_2_569 = add i64 %var_2_564, 8
store i64 %var_2_569, i64* %PC, align 8
%var_2_570 = inttoptr i64 %var_2_568 to i32*
%var_2_571 = load i32, i32* %var_2_570, align 4
%var_2_572 = sext i32 %var_2_571 to i64
; Matched:\<badref\>:  store i64 %var_2_376, i64* %RDX.i2239, align 8
; store i64 %var_2_572, i64* %RDX, align 8
%var_2_573 = shl nsw i64 %var_2_572, 3
%var_2_574 = add i64 %var_2_573, %var_2_567
; Matched:%var_2_1232:  %var_2_1232 = add i64 %var_2_1221, 13
; %var_2_575 = add i64 %var_2_564, 13
; Matched:\<badref\>:  store i64 %var_2_1232, i64* %var_2_3, align 8
; store i64 %var_2_575, i64* %PC, align 8
%var_2_576 = inttoptr i64 %var_2_574 to i64*
%var_2_577 = load i64, i64* %var_2_576, align 8
store i64 %var_2_577, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_4334:  %var_2_4334 = add i64 %var_2_4323, 17
; %var_2_578 = add i64 %var_2_564, 17
; Matched:\<badref\>:  store i64 %var_2_4334, i64* %var_2_3, align 8
; store i64 %var_2_578, i64* %PC, align 8
%var_2_579 = load i64, i64* %var_2_566, align 8
; Matched:\<badref\>:  store i64 %var_2_1349, i64* %RCX.i2236, align 8
; store i64 %var_2_579, i64* %RCX, align 8
%var_2_580 = add i64 %var_2_562, -32
; Matched:%var_2_1688:  %var_2_1688 = add i64 %var_2_1673, 21
; %var_2_581 = add i64 %var_2_564, 21
; Matched:\<badref\>:  store i64 %var_2_1688, i64* %var_2_3, align 8
; store i64 %var_2_581, i64* %PC, align 8
%var_2_582 = inttoptr i64 %var_2_580 to i32*
%var_2_583 = load i32, i32* %var_2_582, align 4
%var_2_584 = sext i32 %var_2_583 to i64
; Matched:\<badref\>:  store i64 %var_2_275, i64* %RDX.i2239, align 8
; store i64 %var_2_584, i64* %RDX, align 8
%var_2_585 = shl nsw i64 %var_2_584, 3
%var_2_586 = add i64 %var_2_585, %var_2_579
; Matched:%var_2_1583:  %var_2_1583 = add i64 %var_2_1560, 26
; %var_2_587 = add i64 %var_2_564, 26
; Matched:\<badref\>:  store i64 %var_2_1583, i64* %var_2_3, align 8
; store i64 %var_2_587, i64* %PC, align 8
%var_2_588 = bitcast i64 %var_2_577 to double
%var_2_589 = inttoptr i64 %var_2_586 to double*
%var_2_590 = load double, double* %var_2_589, align 8
%var_2_591 = fsub double %var_2_588, %var_2_590
store double %var_2_591, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_396:  %var_2_396 = add i64 %var_2_366, -136
; %var_2_592 = add i64 %var_2_562, -136
; Matched:%var_2_397:  %var_2_397 = add i64 %var_2_368, 34
; %var_2_593 = add i64 %var_2_564, 34
; Matched:\<badref\>:  store i64 %var_2_397, i64* %var_2_3, align 8
; store i64 %var_2_593, i64* %PC, align 8
; Matched:%var_2_398:  %var_2_398 = inttoptr i64 %var_2_396 to double*
; %var_2_594 = inttoptr i64 %var_2_592 to double*
; Matched:\<badref\>:  store double %var_2_395, double* %var_2_398, align 8
; store double %var_2_591, double* %var_2_594, align 8
%var_2_595 = load i64, i64* %RBP, align 8
%var_2_596 = add i64 %var_2_595, -16
%var_2_597 = load i64, i64* %PC, align 8
; Matched:%var_2_4219:  %var_2_4219 = add i64 %var_2_4218, 4
; %var_2_598 = add i64 %var_2_597, 4
; Matched:\<badref\>:  store i64 %var_2_4219, i64* %var_2_3, align 8
; store i64 %var_2_598, i64* %PC, align 8
%var_2_599 = inttoptr i64 %var_2_596 to i64*
%var_2_600 = load i64, i64* %var_2_599, align 8
; Matched:\<badref\>:  store i64 %var_2_665, i64* %RCX.i2236, align 8
; store i64 %var_2_600, i64* %RCX, align 8
%var_2_601 = add i64 %var_2_595, -28
; Matched:%var_2_4110:  %var_2_4110 = add i64 %var_2_4105, 7
; %var_2_602 = add i64 %var_2_597, 7
; Matched:\<badref\>:  store i64 %var_2_3884, i64* %var_2_3, align 8
; store i64 %var_2_602, i64* %PC, align 8
%var_2_603 = inttoptr i64 %var_2_601 to i32*
%var_2_604 = load i32, i32* %var_2_603, align 4
%var_2_605 = add i32 %var_2_604, 1
; Matched:%var_2_410:  %var_2_410 = zext i32 %var_2_409 to i64
; %var_2_606 = zext i32 %var_2_605 to i64
; Matched:\<badref\>:  store i64 %var_2_410, i64* %RAX.i2224, align 8
; store i64 %var_2_606, i64* %RAX, align 8
; Matched:%var_2_411:  %var_2_411 = icmp eq i32 %var_2_408, -1
; %var_2_607 = icmp eq i32 %var_2_604, -1
; Matched:%var_2_3067:  %var_2_3067 = icmp eq i32 %var_2_3064, 0
; %var_2_608 = icmp eq i32 %var_2_605, 0
; Matched:%var_2_300:  %var_2_300 = or i1 %var_2_298, %var_2_299
; %var_2_609 = or i1 %var_2_607, %var_2_608
; Matched:%var_2_301:  %var_2_301 = zext i1 %var_2_300 to i8
; %var_2_610 = zext i1 %var_2_609 to i8
; Matched:\<badref\>:  store i8 %var_2_301, i8* %var_2_14, align 1
; store i8 %var_2_610, i8* %var_2_16, align 1
; Matched:%var_2_415:  %var_2_415 = and i32 %var_2_409, 255
; %var_2_611 = and i32 %var_2_605, 255
; Matched:%var_2_757:  %var_2_757 = tail call i32 @llvm.ctpop.i32(i32 %var_2_756)
; %var_2_612 = tail call i32 @llvm.ctpop.i32(i32 %var_2_611) #14
; Matched:%var_2_1383:  %var_2_1383 = trunc i32 %var_2_1382 to i8
; %var_2_613 = trunc i32 %var_2_612 to i8
; Matched:%var_2_305:  %var_2_305 = and i8 %var_2_304, 1
; %var_2_614 = and i8 %var_2_613, 1
; Matched:%var_2_2620:  %var_2_2620 = xor i8 %var_2_2619, 1
; %var_2_615 = xor i8 %var_2_614, 1
; Matched:\<badref\>:  store i8 %var_2_419, i8* %var_2_21, align 1
; store i8 %var_2_615, i8* %var_2_23, align 1
; Matched:%var_2_761:  %var_2_761 = xor i32 %var_2_750, %var_2_749
; %var_2_616 = xor i32 %var_2_605, %var_2_604
; Matched:%var_2_421:  %var_2_421 = lshr i32 %var_2_420, 4
; %var_2_617 = lshr i32 %var_2_616, 4
; Matched:%var_2_422:  %var_2_422 = trunc i32 %var_2_421 to i8
; %var_2_618 = trunc i32 %var_2_617 to i8
; Matched:%var_2_423:  %var_2_423 = and i8 %var_2_422, 1
; %var_2_619 = and i8 %var_2_618, 1
; Matched:\<badref\>:  store i8 %var_2_423, i8* %var_2_27, align 1
; store i8 %var_2_619, i8* %var_2_29, align 1
; Matched:%var_2_424:  %var_2_424 = zext i1 %var_2_412 to i8
; %var_2_620 = zext i1 %var_2_608 to i8
; Matched:\<badref\>:  store i8 %var_2_424, i8* %var_2_30, align 1
; store i8 %var_2_620, i8* %var_2_32, align 1
; Matched:%var_2_425:  %var_2_425 = lshr i32 %var_2_409, 31
; %var_2_621 = lshr i32 %var_2_605, 31
; Matched:%var_2_426:  %var_2_426 = trunc i32 %var_2_425 to i8
; %var_2_622 = trunc i32 %var_2_621 to i8
; Matched:\<badref\>:  store i8 %var_2_313, i8* %var_2_33, align 1
; store i8 %var_2_622, i8* %var_2_35, align 1
; Matched:%var_2_314:  %var_2_314 = lshr i32 %var_2_295, 31
; %var_2_623 = lshr i32 %var_2_604, 31
; Matched:%var_2_4360:  %var_2_4360 = xor i32 %var_2_4357, %var_2_4359
; %var_2_624 = xor i32 %var_2_621, %var_2_623
; Matched:%var_2_770:  %var_2_770 = add nuw nsw i32 %var_2_769, %var_2_766
; %var_2_625 = add nuw nsw i32 %var_2_624, %var_2_621
; Matched:%var_2_317:  %var_2_317 = icmp eq i32 %var_2_316, 2
; %var_2_626 = icmp eq i32 %var_2_625, 2
; Matched:%var_2_1397:  %var_2_1397 = zext i1 %var_2_1396 to i8
; %var_2_627 = zext i1 %var_2_626 to i8
; Matched:\<badref\>:  store i8 %var_2_1397, i8* %var_2_39, align 1
; store i8 %var_2_627, i8* %var_2_41, align 1
%var_2_628 = sext i32 %var_2_605 to i64
; Matched:\<badref\>:  store i64 %var_2_432, i64* %RDX.i2239, align 8
; store i64 %var_2_628, i64* %RDX, align 8
%var_2_629 = shl nsw i64 %var_2_628, 3
%var_2_630 = add i64 %var_2_600, %var_2_629
; Matched:%var_2_3574:  %var_2_3574 = add i64 %var_2_3541, 18
; %var_2_631 = add i64 %var_2_597, 18
; Matched:\<badref\>:  store i64 %var_2_3574, i64* %var_2_3, align 8
; store i64 %var_2_631, i64* %PC, align 8
%var_2_632 = inttoptr i64 %var_2_630 to i64*
%var_2_633 = load i64, i64* %var_2_632, align 8
store i64 %var_2_633, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_2639:  %var_2_2639 = add i64 %var_2_2602, 22
; %var_2_634 = add i64 %var_2_597, 22
; Matched:\<badref\>:  store i64 %var_2_4395, i64* %var_2_3, align 8
; store i64 %var_2_634, i64* %PC, align 8
%var_2_635 = load i64, i64* %var_2_599, align 8
; Matched:\<badref\>:  store i64 %var_2_552, i64* %RCX.i2236, align 8
; store i64 %var_2_635, i64* %RCX, align 8
%var_2_636 = add i64 %var_2_595, -32
; Matched:%var_2_554:  %var_2_554 = add i64 %var_2_514, 25
; %var_2_637 = add i64 %var_2_597, 25
; Matched:\<badref\>:  store i64 %var_2_554, i64* %var_2_3, align 8
; store i64 %var_2_637, i64* %PC, align 8
%var_2_638 = inttoptr i64 %var_2_636 to i32*
%var_2_639 = load i32, i32* %var_2_638, align 4
%var_2_640 = add i32 %var_2_639, 1
; Matched:%var_2_897:  %var_2_897 = zext i32 %var_2_896 to i64
; %var_2_641 = zext i32 %var_2_640 to i64
; Matched:\<badref\>:  store i64 %var_2_897, i64* %RAX.i2224, align 8
; store i64 %var_2_641, i64* %RAX, align 8
; Matched:%var_2_4613:  %var_2_4613 = icmp eq i32 %var_2_4610, -1
; %var_2_642 = icmp eq i32 %var_2_639, -1
; Matched:%var_2_3315:  %var_2_3315 = icmp eq i32 %var_2_3312, 0
; %var_2_643 = icmp eq i32 %var_2_640, 0
; Matched:%var_2_3316:  %var_2_3316 = or i1 %var_2_3314, %var_2_3315
; %var_2_644 = or i1 %var_2_642, %var_2_643
; Matched:%var_2_4616:  %var_2_4616 = zext i1 %var_2_4615 to i8
; %var_2_645 = zext i1 %var_2_644 to i8
; Matched:\<badref\>:  store i8 %var_2_901, i8* %var_2_14, align 1
; store i8 %var_2_645, i8* %var_2_16, align 1
; Matched:%var_2_450:  %var_2_450 = and i32 %var_2_444, 255
; %var_2_646 = and i32 %var_2_640, 255
; Matched:%var_2_4618:  %var_2_4618 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4617)
; %var_2_647 = tail call i32 @llvm.ctpop.i32(i32 %var_2_646) #14
; Matched:%var_2_4619:  %var_2_4619 = trunc i32 %var_2_4618 to i8
; %var_2_648 = trunc i32 %var_2_647 to i8
; Matched:%var_2_905:  %var_2_905 = and i8 %var_2_904, 1
; %var_2_649 = and i8 %var_2_648, 1
; Matched:%var_2_454:  %var_2_454 = xor i8 %var_2_453, 1
; %var_2_650 = xor i8 %var_2_649, 1
; Matched:\<badref\>:  store i8 %var_2_4621, i8* %var_2_21, align 1
; store i8 %var_2_650, i8* %var_2_23, align 1
; Matched:%var_2_3323:  %var_2_3323 = xor i32 %var_2_3312, %var_2_3311
; %var_2_651 = xor i32 %var_2_640, %var_2_639
; Matched:%var_2_3324:  %var_2_3324 = lshr i32 %var_2_3323, 4
; %var_2_652 = lshr i32 %var_2_651, 4
; Matched:%var_2_3325:  %var_2_3325 = trunc i32 %var_2_3324 to i8
; %var_2_653 = trunc i32 %var_2_652 to i8
; Matched:%var_2_3326:  %var_2_3326 = and i8 %var_2_3325, 1
; %var_2_654 = and i8 %var_2_653, 1
; Matched:\<badref\>:  store i8 %var_2_3326, i8* %var_2_27, align 1
; store i8 %var_2_654, i8* %var_2_29, align 1
; Matched:%var_2_4626:  %var_2_4626 = zext i1 %var_2_4614 to i8
; %var_2_655 = zext i1 %var_2_643 to i8
; Matched:\<badref\>:  store i8 %var_2_4626, i8* %var_2_30, align 1
; store i8 %var_2_655, i8* %var_2_32, align 1
; Matched:%var_2_4627:  %var_2_4627 = lshr i32 %var_2_4611, 31
; %var_2_656 = lshr i32 %var_2_640, 31
; Matched:%var_2_4628:  %var_2_4628 = trunc i32 %var_2_4627 to i8
; %var_2_657 = trunc i32 %var_2_656 to i8
; Matched:\<badref\>:  store i8 %var_2_3329, i8* %var_2_33, align 1
; store i8 %var_2_657, i8* %var_2_35, align 1
; Matched:%var_2_462:  %var_2_462 = lshr i32 %var_2_443, 31
; %var_2_658 = lshr i32 %var_2_639, 31
; Matched:%var_2_915:  %var_2_915 = xor i32 %var_2_912, %var_2_914
; %var_2_659 = xor i32 %var_2_656, %var_2_658
; Matched:%var_2_4631:  %var_2_4631 = add nuw nsw i32 %var_2_4630, %var_2_4627
; %var_2_660 = add nuw nsw i32 %var_2_659, %var_2_656
; Matched:%var_2_3333:  %var_2_3333 = icmp eq i32 %var_2_3332, 2
; %var_2_661 = icmp eq i32 %var_2_660, 2
; Matched:%var_2_3334:  %var_2_3334 = zext i1 %var_2_3333 to i8
; %var_2_662 = zext i1 %var_2_661 to i8
; Matched:\<badref\>:  store i8 %var_2_4633, i8* %var_2_39, align 1
; store i8 %var_2_662, i8* %var_2_41, align 1
%var_2_663 = sext i32 %var_2_640 to i64
; Matched:\<badref\>:  store i64 %var_2_467, i64* %RDX.i2239, align 8
; store i64 %var_2_663, i64* %RDX, align 8
%var_2_664 = shl nsw i64 %var_2_663, 3
%var_2_665 = add i64 %var_2_635, %var_2_664
; Matched:%var_2_1662:  %var_2_1662 = add i64 %var_2_1593, 36
; %var_2_666 = add i64 %var_2_597, 36
; Matched:\<badref\>:  store i64 %var_2_1662, i64* %var_2_3, align 8
; store i64 %var_2_666, i64* %PC, align 8
%var_2_667 = bitcast i64 %var_2_633 to double
%var_2_668 = inttoptr i64 %var_2_665 to double*
%var_2_669 = load double, double* %var_2_668, align 8
%var_2_670 = fsub double %var_2_667, %var_2_669
store double %var_2_670, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_475:  %var_2_475 = load i64, i64* %RBP.i, align 8
; %var_2_671 = load i64, i64* %RBP, align 8
; Matched:%var_2_2790:  %var_2_2790 = add i64 %var_2_2789, -144
; %var_2_672 = add i64 %var_2_671, -144
; Matched:%var_2_1443:  %var_2_1443 = add i64 %var_2_1367, 44
; %var_2_673 = add i64 %var_2_597, 44
; Matched:\<badref\>:  store i64 %var_2_1443, i64* %var_2_3, align 8
; store i64 %var_2_673, i64* %PC, align 8
; Matched:%var_2_2792:  %var_2_2792 = inttoptr i64 %var_2_2790 to double*
; %var_2_674 = inttoptr i64 %var_2_672 to double*
; Matched:\<badref\>:  store double %var_2_474, double* %var_2_478, align 8
; store double %var_2_670, double* %var_2_674, align 8
%var_2_675 = load i64, i64* %RBP, align 8
%var_2_676 = add i64 %var_2_675, -16
%var_2_677 = load i64, i64* %PC, align 8
; Matched:%var_2_3847:  %var_2_3847 = add i64 %var_2_3846, 4
; %var_2_678 = add i64 %var_2_677, 4
; Matched:\<badref\>:  store i64 %var_2_3847, i64* %var_2_3, align 8
; store i64 %var_2_678, i64* %PC, align 8
%var_2_679 = inttoptr i64 %var_2_676 to i64*
%var_2_680 = load i64, i64* %var_2_679, align 8
; Matched:\<badref\>:  store i64 %var_2_1370, i64* %RCX.i2236, align 8
; store i64 %var_2_680, i64* %RCX, align 8
%var_2_681 = add i64 %var_2_675, -36
%var_2_682 = add i64 %var_2_677, 8
store i64 %var_2_682, i64* %PC, align 8
%var_2_683 = inttoptr i64 %var_2_681 to i32*
%var_2_684 = load i32, i32* %var_2_683, align 4
%var_2_685 = sext i32 %var_2_684 to i64
; Matched:\<badref\>:  store i64 %var_2_489, i64* %RDX.i2239, align 8
; store i64 %var_2_685, i64* %RDX, align 8
%var_2_686 = shl nsw i64 %var_2_685, 3
%var_2_687 = add i64 %var_2_686, %var_2_680
; Matched:%var_2_605:  %var_2_605 = add i64 %var_2_594, 13
; %var_2_688 = add i64 %var_2_677, 13
; Matched:\<badref\>:  store i64 %var_2_605, i64* %var_2_3, align 8
; store i64 %var_2_688, i64* %PC, align 8
%var_2_689 = inttoptr i64 %var_2_687 to i64*
%var_2_690 = load i64, i64* %var_2_689, align 8
store i64 %var_2_690, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_269:  %var_2_269 = add i64 %var_2_255, 17
; %var_2_691 = add i64 %var_2_677, 17
; Matched:\<badref\>:  store i64 %var_2_269, i64* %var_2_3, align 8
; store i64 %var_2_691, i64* %PC, align 8
%var_2_692 = load i64, i64* %var_2_679, align 8
; Matched:\<badref\>:  store i64 %var_2_3034, i64* %RCX.i2236, align 8
; store i64 %var_2_692, i64* %RCX, align 8
%var_2_693 = add i64 %var_2_675, -40
; Matched:%var_2_611:  %var_2_611 = add i64 %var_2_594, 21
; %var_2_694 = add i64 %var_2_677, 21
; Matched:\<badref\>:  store i64 %var_2_611, i64* %var_2_3, align 8
; store i64 %var_2_694, i64* %PC, align 8
%var_2_695 = inttoptr i64 %var_2_693 to i32*
%var_2_696 = load i32, i32* %var_2_695, align 4
%var_2_697 = sext i32 %var_2_696 to i64
; Matched:\<badref\>:  store i64 %var_2_501, i64* %RDX.i2239, align 8
; store i64 %var_2_697, i64* %RDX, align 8
%var_2_698 = shl nsw i64 %var_2_697, 3
%var_2_699 = add i64 %var_2_698, %var_2_692
; Matched:%var_2_2818:  %var_2_2818 = add i64 %var_2_2795, 26
; %var_2_700 = add i64 %var_2_677, 26
; Matched:\<badref\>:  store i64 %var_2_2818, i64* %var_2_3, align 8
; store i64 %var_2_700, i64* %PC, align 8
%var_2_701 = bitcast i64 %var_2_690 to double
%var_2_702 = inttoptr i64 %var_2_699 to double*
%var_2_703 = load double, double* %var_2_702, align 8
%var_2_704 = fadd double %var_2_701, %var_2_703
store double %var_2_704, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_2823:  %var_2_2823 = add i64 %var_2_2793, -152
; %var_2_705 = add i64 %var_2_675, -152
; Matched:%var_2_510:  %var_2_510 = add i64 %var_2_481, 34
; %var_2_706 = add i64 %var_2_677, 34
; Matched:\<badref\>:  store i64 %var_2_510, i64* %var_2_3, align 8
; store i64 %var_2_706, i64* %PC, align 8
; Matched:%var_2_511:  %var_2_511 = inttoptr i64 %var_2_509 to double*
; %var_2_707 = inttoptr i64 %var_2_705 to double*
; Matched:\<badref\>:  store double %var_2_508, double* %var_2_511, align 8
; store double %var_2_704, double* %var_2_707, align 8
%var_2_708 = load i64, i64* %RBP, align 8
%var_2_709 = add i64 %var_2_708, -16
%var_2_710 = load i64, i64* %PC, align 8
; Matched:%var_2_1448:  %var_2_1448 = add i64 %var_2_1447, 4
; %var_2_711 = add i64 %var_2_710, 4
; Matched:\<badref\>:  store i64 %var_2_1448, i64* %var_2_3, align 8
; store i64 %var_2_711, i64* %PC, align 8
%var_2_712 = inttoptr i64 %var_2_709 to i64*
%var_2_713 = load i64, i64* %var_2_712, align 8
; Matched:\<badref\>:  store i64 %var_2_891, i64* %RCX.i2236, align 8
; store i64 %var_2_713, i64* %RCX, align 8
%var_2_714 = add i64 %var_2_708, -36
; Matched:%var_2_2250:  %var_2_2250 = add i64 %var_2_2245, 7
; %var_2_715 = add i64 %var_2_710, 7
; Matched:\<badref\>:  store i64 %var_2_4110, i64* %var_2_3, align 8
; store i64 %var_2_715, i64* %PC, align 8
%var_2_716 = inttoptr i64 %var_2_714 to i32*
%var_2_717 = load i32, i32* %var_2_716, align 4
%var_2_718 = add i32 %var_2_717, 1
; Matched:%var_2_1602:  %var_2_1602 = zext i32 %var_2_1601 to i64
; %var_2_719 = zext i32 %var_2_718 to i64
; Matched:\<badref\>:  store i64 %var_2_1602, i64* %RAX.i2224, align 8
; store i64 %var_2_719, i64* %RAX, align 8
; Matched:%var_2_524:  %var_2_524 = icmp eq i32 %var_2_521, -1
; %var_2_720 = icmp eq i32 %var_2_717, -1
; Matched:%var_2_525:  %var_2_525 = icmp eq i32 %var_2_522, 0
; %var_2_721 = icmp eq i32 %var_2_718, 0
; Matched:%var_2_526:  %var_2_526 = or i1 %var_2_524, %var_2_525
; %var_2_722 = or i1 %var_2_720, %var_2_721
; Matched:%var_2_527:  %var_2_527 = zext i1 %var_2_526 to i8
; %var_2_723 = zext i1 %var_2_722 to i8
; Matched:\<badref\>:  store i8 %var_2_527, i8* %var_2_14, align 1
; store i8 %var_2_723, i8* %var_2_16, align 1
; Matched:%var_2_528:  %var_2_528 = and i32 %var_2_522, 255
; %var_2_724 = and i32 %var_2_718, 255
; Matched:%var_2_529:  %var_2_529 = tail call i32 @llvm.ctpop.i32(i32 %var_2_528)
; %var_2_725 = tail call i32 @llvm.ctpop.i32(i32 %var_2_724) #14
; Matched:%var_2_530:  %var_2_530 = trunc i32 %var_2_529 to i8
; %var_2_726 = trunc i32 %var_2_725 to i8
; Matched:%var_2_1610:  %var_2_1610 = and i8 %var_2_1609, 1
; %var_2_727 = and i8 %var_2_726, 1
; Matched:%var_2_1498:  %var_2_1498 = xor i8 %var_2_1497, 1
; %var_2_728 = xor i8 %var_2_727, 1
; Matched:\<badref\>:  store i8 %var_2_1611, i8* %var_2_21, align 1
; store i8 %var_2_728, i8* %var_2_23, align 1
; Matched:%var_2_533:  %var_2_533 = xor i32 %var_2_522, %var_2_521
; %var_2_729 = xor i32 %var_2_718, %var_2_717
; Matched:%var_2_534:  %var_2_534 = lshr i32 %var_2_533, 4
; %var_2_730 = lshr i32 %var_2_729, 4
; Matched:%var_2_535:  %var_2_535 = trunc i32 %var_2_534 to i8
; %var_2_731 = trunc i32 %var_2_730 to i8
; Matched:%var_2_536:  %var_2_536 = and i8 %var_2_535, 1
; %var_2_732 = and i8 %var_2_731, 1
; Matched:\<badref\>:  store i8 %var_2_536, i8* %var_2_27, align 1
; store i8 %var_2_732, i8* %var_2_29, align 1
; Matched:%var_2_537:  %var_2_537 = zext i1 %var_2_525 to i8
; %var_2_733 = zext i1 %var_2_721 to i8
; Matched:\<badref\>:  store i8 %var_2_537, i8* %var_2_30, align 1
; store i8 %var_2_733, i8* %var_2_32, align 1
; Matched:%var_2_538:  %var_2_538 = lshr i32 %var_2_522, 31
; %var_2_734 = lshr i32 %var_2_718, 31
; Matched:%var_2_539:  %var_2_539 = trunc i32 %var_2_538 to i8
; %var_2_735 = trunc i32 %var_2_734 to i8
; Matched:\<badref\>:  store i8 %var_2_652, i8* %var_2_33, align 1
; store i8 %var_2_735, i8* %var_2_35, align 1
; Matched:%var_2_540:  %var_2_540 = lshr i32 %var_2_521, 31
; %var_2_736 = lshr i32 %var_2_717, 31
; Matched:%var_2_3206:  %var_2_3206 = xor i32 %var_2_3203, %var_2_3205
; %var_2_737 = xor i32 %var_2_734, %var_2_736
; Matched:%var_2_1508:  %var_2_1508 = add nuw nsw i32 %var_2_1507, %var_2_1504
; %var_2_738 = add nuw nsw i32 %var_2_737, %var_2_734
; Matched:%var_2_844:  %var_2_844 = icmp eq i32 %var_2_843, 2
; %var_2_739 = icmp eq i32 %var_2_738, 2
; Matched:%var_2_1510:  %var_2_1510 = zext i1 %var_2_1509 to i8
; %var_2_740 = zext i1 %var_2_739 to i8
; Matched:\<badref\>:  store i8 %var_2_845, i8* %var_2_39, align 1
; store i8 %var_2_740, i8* %var_2_41, align 1
%var_2_741 = sext i32 %var_2_718 to i64
; Matched:\<badref\>:  store i64 %var_2_1624, i64* %RDX.i2239, align 8
; store i64 %var_2_741, i64* %RDX, align 8
%var_2_742 = shl nsw i64 %var_2_741, 3
%var_2_743 = add i64 %var_2_713, %var_2_742
; Matched:%var_2_2975:  %var_2_2975 = add i64 %var_2_2941, 18
; %var_2_744 = add i64 %var_2_710, 18
; Matched:\<badref\>:  store i64 %var_2_3913, i64* %var_2_3, align 8
; store i64 %var_2_744, i64* %PC, align 8
%var_2_745 = inttoptr i64 %var_2_743 to i64*
%var_2_746 = load i64, i64* %var_2_745, align 8
store i64 %var_2_746, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_2865:  %var_2_2865 = add i64 %var_2_2828, 22
; %var_2_747 = add i64 %var_2_710, 22
; Matched:\<badref\>:  store i64 %var_2_2639, i64* %var_2_3, align 8
; store i64 %var_2_747, i64* %PC, align 8
%var_2_748 = load i64, i64* %var_2_712, align 8
; Matched:\<badref\>:  store i64 %var_2_1518, i64* %RCX.i2236, align 8
; store i64 %var_2_748, i64* %RCX, align 8
%var_2_749 = add i64 %var_2_708, -40
; Matched:%var_2_2642:  %var_2_2642 = add i64 %var_2_2602, 25
; %var_2_750 = add i64 %var_2_710, 25
; Matched:\<badref\>:  store i64 %var_2_2642, i64* %var_2_3, align 8
; store i64 %var_2_750, i64* %PC, align 8
%var_2_751 = inttoptr i64 %var_2_749 to i32*
%var_2_752 = load i32, i32* %var_2_751, align 4
%var_2_753 = add i32 %var_2_752, 1
; Matched:%var_2_558:  %var_2_558 = zext i32 %var_2_557 to i64
; %var_2_754 = zext i32 %var_2_753 to i64
; Matched:\<badref\>:  store i64 %var_2_558, i64* %RAX.i2224, align 8
; store i64 %var_2_754, i64* %RAX, align 8
; Matched:%var_2_559:  %var_2_559 = icmp eq i32 %var_2_556, -1
; %var_2_755 = icmp eq i32 %var_2_752, -1
; Matched:%var_2_560:  %var_2_560 = icmp eq i32 %var_2_557, 0
; %var_2_756 = icmp eq i32 %var_2_753, 0
; Matched:%var_2_1640:  %var_2_1640 = or i1 %var_2_1638, %var_2_1639
; %var_2_757 = or i1 %var_2_755, %var_2_756
; Matched:%var_2_562:  %var_2_562 = zext i1 %var_2_561 to i8
; %var_2_758 = zext i1 %var_2_757 to i8
; Matched:\<badref\>:  store i8 %var_2_562, i8* %var_2_14, align 1
; store i8 %var_2_758, i8* %var_2_16, align 1
; Matched:%var_2_563:  %var_2_563 = and i32 %var_2_557, 255
; %var_2_759 = and i32 %var_2_753, 255
; Matched:%var_2_1643:  %var_2_1643 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1642)
; %var_2_760 = tail call i32 @llvm.ctpop.i32(i32 %var_2_759) #14
; Matched:%var_2_1644:  %var_2_1644 = trunc i32 %var_2_1643 to i8
; %var_2_761 = trunc i32 %var_2_760 to i8
; Matched:%var_2_566:  %var_2_566 = and i8 %var_2_565, 1
; %var_2_762 = and i8 %var_2_761, 1
; Matched:%var_2_567:  %var_2_567 = xor i8 %var_2_566, 1
; %var_2_763 = xor i8 %var_2_762, 1
; Matched:\<badref\>:  store i8 %var_2_567, i8* %var_2_21, align 1
; store i8 %var_2_763, i8* %var_2_23, align 1
; Matched:%var_2_568:  %var_2_568 = xor i32 %var_2_557, %var_2_556
; %var_2_764 = xor i32 %var_2_753, %var_2_752
; Matched:%var_2_682:  %var_2_682 = lshr i32 %var_2_681, 4
; %var_2_765 = lshr i32 %var_2_764, 4
; Matched:%var_2_4749:  %var_2_4749 = trunc i32 %var_2_4748 to i8
; %var_2_766 = trunc i32 %var_2_765 to i8
; Matched:%var_2_571:  %var_2_571 = and i8 %var_2_570, 1
; %var_2_767 = and i8 %var_2_766, 1
; Matched:\<badref\>:  store i8 %var_2_571, i8* %var_2_27, align 1
; store i8 %var_2_767, i8* %var_2_29, align 1
; Matched:%var_2_572:  %var_2_572 = zext i1 %var_2_560 to i8
; %var_2_768 = zext i1 %var_2_756 to i8
; Matched:\<badref\>:  store i8 %var_2_572, i8* %var_2_30, align 1
; store i8 %var_2_768, i8* %var_2_32, align 1
; Matched:%var_2_573:  %var_2_573 = lshr i32 %var_2_557, 31
; %var_2_769 = lshr i32 %var_2_753, 31
; Matched:%var_2_574:  %var_2_574 = trunc i32 %var_2_573 to i8
; %var_2_770 = trunc i32 %var_2_769 to i8
; Matched:\<badref\>:  store i8 %var_2_574, i8* %var_2_33, align 1
; store i8 %var_2_770, i8* %var_2_35, align 1
; Matched:%var_2_575:  %var_2_575 = lshr i32 %var_2_556, 31
; %var_2_771 = lshr i32 %var_2_752, 31
; Matched:%var_2_689:  %var_2_689 = xor i32 %var_2_686, %var_2_688
; %var_2_772 = xor i32 %var_2_769, %var_2_771
; Matched:%var_2_1656:  %var_2_1656 = add nuw nsw i32 %var_2_1655, %var_2_1652
; %var_2_773 = add nuw nsw i32 %var_2_772, %var_2_769
; Matched:%var_2_1544:  %var_2_1544 = icmp eq i32 %var_2_1543, 2
; %var_2_774 = icmp eq i32 %var_2_773, 2
; Matched:%var_2_1658:  %var_2_1658 = zext i1 %var_2_1657 to i8
; %var_2_775 = zext i1 %var_2_774 to i8
; Matched:\<badref\>:  store i8 %var_2_579, i8* %var_2_39, align 1
; store i8 %var_2_775, i8* %var_2_41, align 1
%var_2_776 = sext i32 %var_2_753 to i64
; Matched:\<badref\>:  store i64 %var_2_580, i64* %RDX.i2239, align 8
; store i64 %var_2_776, i64* %RDX, align 8
%var_2_777 = shl nsw i64 %var_2_776, 3
%var_2_778 = add i64 %var_2_748, %var_2_777
; Matched:%var_2_470:  %var_2_470 = add i64 %var_2_401, 36
; %var_2_779 = add i64 %var_2_710, 36
; Matched:\<badref\>:  store i64 %var_2_470, i64* %var_2_3, align 8
; store i64 %var_2_779, i64* %PC, align 8
%var_2_780 = bitcast i64 %var_2_746 to double
%var_2_781 = inttoptr i64 %var_2_778 to double*
%var_2_782 = load double, double* %var_2_781, align 8
%var_2_783 = fadd double %var_2_780, %var_2_782
store double %var_2_783, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_588:  %var_2_588 = load i64, i64* %RBP.i, align 8
; %var_2_784 = load i64, i64* %RBP, align 8
; Matched:%var_2_2903:  %var_2_2903 = add i64 %var_2_2902, -160
; %var_2_785 = add i64 %var_2_784, -160
; Matched:%var_2_1556:  %var_2_1556 = add i64 %var_2_1480, 44
; %var_2_786 = add i64 %var_2_710, 44
; Matched:\<badref\>:  store i64 %var_2_1556, i64* %var_2_3, align 8
; store i64 %var_2_786, i64* %PC, align 8
; Matched:%var_2_591:  %var_2_591 = inttoptr i64 %var_2_589 to double*
; %var_2_787 = inttoptr i64 %var_2_785 to double*
; Matched:\<badref\>:  store double %var_2_2901, double* %var_2_2905, align 8
; store double %var_2_783, double* %var_2_787, align 8
%var_2_788 = load i64, i64* %RBP, align 8
%var_2_789 = add i64 %var_2_788, -16
%var_2_790 = load i64, i64* %PC, align 8
; Matched:%var_2_2796:  %var_2_2796 = add i64 %var_2_2795, 4
; %var_2_791 = add i64 %var_2_790, 4
; Matched:\<badref\>:  store i64 %var_2_2796, i64* %var_2_3, align 8
; store i64 %var_2_791, i64* %PC, align 8
%var_2_792 = inttoptr i64 %var_2_789 to i64*
%var_2_793 = load i64, i64* %var_2_792, align 8
; Matched:\<badref\>:  store i64 %var_2_2685, i64* %RCX.i2236, align 8
; store i64 %var_2_793, i64* %RCX, align 8
%var_2_794 = add i64 %var_2_788, -36
%var_2_795 = add i64 %var_2_790, 8
store i64 %var_2_795, i64* %PC, align 8
%var_2_796 = inttoptr i64 %var_2_794 to i32*
%var_2_797 = load i32, i32* %var_2_796, align 4
%var_2_798 = sext i32 %var_2_797 to i64
; Matched:\<badref\>:  store i64 %var_2_602, i64* %RDX.i2239, align 8
; store i64 %var_2_798, i64* %RDX, align 8
%var_2_799 = shl nsw i64 %var_2_798, 3
%var_2_800 = add i64 %var_2_799, %var_2_793
; Matched:%var_2_266:  %var_2_266 = add i64 %var_2_255, 13
; %var_2_801 = add i64 %var_2_790, 13
; Matched:\<badref\>:  store i64 %var_2_2806, i64* %var_2_3, align 8
; store i64 %var_2_801, i64* %PC, align 8
%var_2_802 = inttoptr i64 %var_2_800 to i64*
%var_2_803 = load i64, i64* %var_2_802, align 8
store i64 %var_2_803, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_4309:  %var_2_4309 = add i64 %var_2_4298, 17
; %var_2_804 = add i64 %var_2_790, 17
; Matched:\<badref\>:  store i64 %var_2_4309, i64* %var_2_3, align 8
; store i64 %var_2_804, i64* %PC, align 8
%var_2_805 = load i64, i64* %var_2_792, align 8
; Matched:\<badref\>:  store i64 %var_2_1450, i64* %RCX.i2236, align 8
; store i64 %var_2_805, i64* %RCX, align 8
%var_2_806 = add i64 %var_2_788, -40
; Matched:%var_2_272:  %var_2_272 = add i64 %var_2_255, 21
; %var_2_807 = add i64 %var_2_790, 21
; Matched:\<badref\>:  store i64 %var_2_272, i64* %var_2_3, align 8
; store i64 %var_2_807, i64* %PC, align 8
%var_2_808 = inttoptr i64 %var_2_806 to i32*
%var_2_809 = load i32, i32* %var_2_808, align 4
%var_2_810 = sext i32 %var_2_809 to i64
; Matched:\<badref\>:  store i64 %var_2_614, i64* %RDX.i2239, align 8
; store i64 %var_2_810, i64* %RDX, align 8
%var_2_811 = shl nsw i64 %var_2_810, 3
%var_2_812 = add i64 %var_2_811, %var_2_805
; Matched:%var_2_278:  %var_2_278 = add i64 %var_2_255, 26
; %var_2_813 = add i64 %var_2_790, 26
; Matched:\<badref\>:  store i64 %var_2_278, i64* %var_2_3, align 8
; store i64 %var_2_813, i64* %PC, align 8
%var_2_814 = bitcast i64 %var_2_803 to double
%var_2_815 = inttoptr i64 %var_2_812 to double*
%var_2_816 = load double, double* %var_2_815, align 8
%var_2_817 = fsub double %var_2_814, %var_2_816
store double %var_2_817, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_2936:  %var_2_2936 = add i64 %var_2_2906, -168
; %var_2_818 = add i64 %var_2_788, -168
; Matched:%var_2_623:  %var_2_623 = add i64 %var_2_594, 34
; %var_2_819 = add i64 %var_2_790, 34
; Matched:\<badref\>:  store i64 %var_2_623, i64* %var_2_3, align 8
; store i64 %var_2_819, i64* %PC, align 8
; Matched:%var_2_2938:  %var_2_2938 = inttoptr i64 %var_2_2936 to double*
; %var_2_820 = inttoptr i64 %var_2_818 to double*
; Matched:\<badref\>:  store double %var_2_621, double* %var_2_624, align 8
; store double %var_2_817, double* %var_2_820, align 8
%var_2_821 = load i64, i64* %RBP, align 8
%var_2_822 = add i64 %var_2_821, -16
%var_2_823 = load i64, i64* %PC, align 8
; Matched:%var_2_4186:  %var_2_4186 = add i64 %var_2_4185, 4
; %var_2_824 = add i64 %var_2_823, 4
; Matched:\<badref\>:  store i64 %var_2_4186, i64* %var_2_3, align 8
; store i64 %var_2_824, i64* %PC, align 8
%var_2_825 = inttoptr i64 %var_2_822 to i64*
%var_2_826 = load i64, i64* %var_2_825, align 8
; Matched:\<badref\>:  store i64 %var_2_2014, i64* %RCX.i2236, align 8
; store i64 %var_2_826, i64* %RCX, align 8
%var_2_827 = add i64 %var_2_821, -36
; Matched:%var_2_1259:  %var_2_1259 = add i64 %var_2_1254, 7
; %var_2_828 = add i64 %var_2_823, 7
; Matched:\<badref\>:  store i64 %var_2_2250, i64* %var_2_3, align 8
; store i64 %var_2_828, i64* %PC, align 8
%var_2_829 = inttoptr i64 %var_2_827 to i32*
%var_2_830 = load i32, i32* %var_2_829, align 4
%var_2_831 = add i32 %var_2_830, 1
; Matched:%var_2_523:  %var_2_523 = zext i32 %var_2_522 to i64
; %var_2_832 = zext i32 %var_2_831 to i64
; Matched:\<badref\>:  store i64 %var_2_523, i64* %RAX.i2224, align 8
; store i64 %var_2_832, i64* %RAX, align 8
; Matched:%var_2_637:  %var_2_637 = icmp eq i32 %var_2_634, -1
; %var_2_833 = icmp eq i32 %var_2_830, -1
; Matched:%var_2_638:  %var_2_638 = icmp eq i32 %var_2_635, 0
; %var_2_834 = icmp eq i32 %var_2_831, 0
; Matched:%var_2_639:  %var_2_639 = or i1 %var_2_637, %var_2_638
; %var_2_835 = or i1 %var_2_833, %var_2_834
; Matched:%var_2_640:  %var_2_640 = zext i1 %var_2_639 to i8
; %var_2_836 = zext i1 %var_2_835 to i8
; Matched:\<badref\>:  store i8 %var_2_640, i8* %var_2_14, align 1
; store i8 %var_2_836, i8* %var_2_16, align 1
; Matched:%var_2_641:  %var_2_641 = and i32 %var_2_635, 255
; %var_2_837 = and i32 %var_2_831, 255
; Matched:%var_2_642:  %var_2_642 = tail call i32 @llvm.ctpop.i32(i32 %var_2_641)
; %var_2_838 = tail call i32 @llvm.ctpop.i32(i32 %var_2_837) #14
; Matched:%var_2_643:  %var_2_643 = trunc i32 %var_2_642 to i8
; %var_2_839 = trunc i32 %var_2_838 to i8
; Matched:%var_2_531:  %var_2_531 = and i8 %var_2_530, 1
; %var_2_840 = and i8 %var_2_839, 1
; Matched:%var_2_1611:  %var_2_1611 = xor i8 %var_2_1610, 1
; %var_2_841 = xor i8 %var_2_840, 1
; Matched:\<badref\>:  store i8 %var_2_532, i8* %var_2_21, align 1
; store i8 %var_2_841, i8* %var_2_23, align 1
; Matched:%var_2_646:  %var_2_646 = xor i32 %var_2_635, %var_2_634
; %var_2_842 = xor i32 %var_2_831, %var_2_830
; Matched:%var_2_647:  %var_2_647 = lshr i32 %var_2_646, 4
; %var_2_843 = lshr i32 %var_2_842, 4
; Matched:%var_2_648:  %var_2_648 = trunc i32 %var_2_647 to i8
; %var_2_844 = trunc i32 %var_2_843 to i8
; Matched:%var_2_649:  %var_2_649 = and i8 %var_2_648, 1
; %var_2_845 = and i8 %var_2_844, 1
; Matched:\<badref\>:  store i8 %var_2_649, i8* %var_2_27, align 1
; store i8 %var_2_845, i8* %var_2_29, align 1
; Matched:%var_2_650:  %var_2_650 = zext i1 %var_2_638 to i8
; %var_2_846 = zext i1 %var_2_834 to i8
; Matched:\<badref\>:  store i8 %var_2_650, i8* %var_2_30, align 1
; store i8 %var_2_846, i8* %var_2_32, align 1
; Matched:%var_2_651:  %var_2_651 = lshr i32 %var_2_635, 31
; %var_2_847 = lshr i32 %var_2_831, 31
; Matched:%var_2_652:  %var_2_652 = trunc i32 %var_2_651 to i8
; %var_2_848 = trunc i32 %var_2_847 to i8
; Matched:\<badref\>:  store i8 %var_2_3204, i8* %var_2_33, align 1
; store i8 %var_2_848, i8* %var_2_35, align 1
; Matched:%var_2_653:  %var_2_653 = lshr i32 %var_2_634, 31
; %var_2_849 = lshr i32 %var_2_830, 31
; Matched:%var_2_541:  %var_2_541 = xor i32 %var_2_538, %var_2_540
; %var_2_850 = xor i32 %var_2_847, %var_2_849
; Matched:%var_2_1621:  %var_2_1621 = add nuw nsw i32 %var_2_1620, %var_2_1617
; %var_2_851 = add nuw nsw i32 %var_2_850, %var_2_847
; Matched:%var_2_1509:  %var_2_1509 = icmp eq i32 %var_2_1508, 2
; %var_2_852 = icmp eq i32 %var_2_851, 2
; Matched:%var_2_1623:  %var_2_1623 = zext i1 %var_2_1622 to i8
; %var_2_853 = zext i1 %var_2_852 to i8
; Matched:\<badref\>:  store i8 %var_2_1510, i8* %var_2_39, align 1
; store i8 %var_2_853, i8* %var_2_41, align 1
%var_2_854 = sext i32 %var_2_831 to i64
; Matched:\<badref\>:  store i64 %var_2_545, i64* %RDX.i2239, align 8
; store i64 %var_2_854, i64* %RDX, align 8
%var_2_855 = shl nsw i64 %var_2_854, 3
%var_2_856 = add i64 %var_2_826, %var_2_855
; Matched:%var_2_1627:  %var_2_1627 = add i64 %var_2_1593, 18
; %var_2_857 = add i64 %var_2_823, 18
; Matched:\<badref\>:  store i64 %var_2_1627, i64* %var_2_3, align 8
; store i64 %var_2_857, i64* %PC, align 8
%var_2_858 = inttoptr i64 %var_2_856 to i64*
%var_2_859 = load i64, i64* %var_2_858, align 8
store i64 %var_2_859, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_4029:  %var_2_4029 = add i64 %var_2_3992, 22
; %var_2_860 = add i64 %var_2_823, 22
; Matched:\<badref\>:  store i64 %var_2_2865, i64* %var_2_3, align 8
; store i64 %var_2_860, i64* %PC, align 8
%var_2_861 = load i64, i64* %var_2_825, align 8
; Matched:\<badref\>:  store i64 %var_2_2640, i64* %RCX.i2236, align 8
; store i64 %var_2_861, i64* %RCX, align 8
%var_2_862 = add i64 %var_2_821, -40
; Matched:%var_2_2868:  %var_2_2868 = add i64 %var_2_2828, 25
; %var_2_863 = add i64 %var_2_823, 25
; Matched:\<badref\>:  store i64 %var_2_2868, i64* %var_2_3, align 8
; store i64 %var_2_863, i64* %PC, align 8
%var_2_864 = inttoptr i64 %var_2_862 to i32*
%var_2_865 = load i32, i32* %var_2_864, align 4
%var_2_866 = add i32 %var_2_865, 1
; Matched:%var_2_671:  %var_2_671 = zext i32 %var_2_670 to i64
; %var_2_867 = zext i32 %var_2_866 to i64
; Matched:\<badref\>:  store i64 %var_2_671, i64* %RAX.i2224, align 8
; store i64 %var_2_867, i64* %RAX, align 8
; Matched:%var_2_672:  %var_2_672 = icmp eq i32 %var_2_669, -1
; %var_2_868 = icmp eq i32 %var_2_865, -1
; Matched:%var_2_673:  %var_2_673 = icmp eq i32 %var_2_670, 0
; %var_2_869 = icmp eq i32 %var_2_866, 0
; Matched:%var_2_561:  %var_2_561 = or i1 %var_2_559, %var_2_560
; %var_2_870 = or i1 %var_2_868, %var_2_869
; Matched:%var_2_675:  %var_2_675 = zext i1 %var_2_674 to i8
; %var_2_871 = zext i1 %var_2_870 to i8
; Matched:\<badref\>:  store i8 %var_2_675, i8* %var_2_14, align 1
; store i8 %var_2_871, i8* %var_2_16, align 1
; Matched:%var_2_676:  %var_2_676 = and i32 %var_2_670, 255
; %var_2_872 = and i32 %var_2_866, 255
; Matched:%var_2_564:  %var_2_564 = tail call i32 @llvm.ctpop.i32(i32 %var_2_563)
; %var_2_873 = tail call i32 @llvm.ctpop.i32(i32 %var_2_872) #14
; Matched:%var_2_565:  %var_2_565 = trunc i32 %var_2_564 to i8
; %var_2_874 = trunc i32 %var_2_873 to i8
; Matched:%var_2_679:  %var_2_679 = and i8 %var_2_678, 1
; %var_2_875 = and i8 %var_2_874, 1
; Matched:%var_2_680:  %var_2_680 = xor i8 %var_2_679, 1
; %var_2_876 = xor i8 %var_2_875, 1
; Matched:\<badref\>:  store i8 %var_2_680, i8* %var_2_21, align 1
; store i8 %var_2_876, i8* %var_2_23, align 1
; Matched:%var_2_681:  %var_2_681 = xor i32 %var_2_670, %var_2_669
; %var_2_877 = xor i32 %var_2_866, %var_2_865
; Matched:%var_2_4748:  %var_2_4748 = lshr i32 %var_2_4747, 4
; %var_2_878 = lshr i32 %var_2_877, 4
; Matched:%var_2_3450:  %var_2_3450 = trunc i32 %var_2_3449 to i8
; %var_2_879 = trunc i32 %var_2_878 to i8
; Matched:%var_2_684:  %var_2_684 = and i8 %var_2_683, 1
; %var_2_880 = and i8 %var_2_879, 1
; Matched:\<badref\>:  store i8 %var_2_684, i8* %var_2_27, align 1
; store i8 %var_2_880, i8* %var_2_29, align 1
; Matched:%var_2_685:  %var_2_685 = zext i1 %var_2_673 to i8
; %var_2_881 = zext i1 %var_2_869 to i8
; Matched:\<badref\>:  store i8 %var_2_685, i8* %var_2_30, align 1
; store i8 %var_2_881, i8* %var_2_32, align 1
; Matched:%var_2_686:  %var_2_686 = lshr i32 %var_2_670, 31
; %var_2_882 = lshr i32 %var_2_866, 31
; Matched:%var_2_687:  %var_2_687 = trunc i32 %var_2_686 to i8
; %var_2_883 = trunc i32 %var_2_882 to i8
; Matched:\<badref\>:  store i8 %var_2_687, i8* %var_2_33, align 1
; store i8 %var_2_883, i8* %var_2_35, align 1
; Matched:%var_2_688:  %var_2_688 = lshr i32 %var_2_669, 31
; %var_2_884 = lshr i32 %var_2_865, 31
; Matched:%var_2_4755:  %var_2_4755 = xor i32 %var_2_4752, %var_2_4754
; %var_2_885 = xor i32 %var_2_882, %var_2_884
; Matched:%var_2_577:  %var_2_577 = add nuw nsw i32 %var_2_576, %var_2_573
; %var_2_886 = add nuw nsw i32 %var_2_885, %var_2_882
; Matched:%var_2_1657:  %var_2_1657 = icmp eq i32 %var_2_1656, 2
; %var_2_887 = icmp eq i32 %var_2_886, 2
; Matched:%var_2_579:  %var_2_579 = zext i1 %var_2_578 to i8
; %var_2_888 = zext i1 %var_2_887 to i8
; Matched:\<badref\>:  store i8 %var_2_692, i8* %var_2_39, align 1
; store i8 %var_2_888, i8* %var_2_41, align 1
%var_2_889 = sext i32 %var_2_866 to i64
; Matched:\<badref\>:  store i64 %var_2_2042, i64* %RDX.i2239, align 8
; store i64 %var_2_889, i64* %RDX, align 8
%var_2_890 = shl nsw i64 %var_2_889, 3
%var_2_891 = add i64 %var_2_861, %var_2_890
; Matched:%var_2_696:  %var_2_696 = add i64 %var_2_627, 36
; %var_2_892 = add i64 %var_2_823, 36
; Matched:\<badref\>:  store i64 %var_2_696, i64* %var_2_3, align 8
; store i64 %var_2_892, i64* %PC, align 8
%var_2_893 = bitcast i64 %var_2_859 to double
%var_2_894 = inttoptr i64 %var_2_891 to double*
%var_2_895 = load double, double* %var_2_894, align 8
%var_2_896 = fsub double %var_2_893, %var_2_895
store double %var_2_896, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_701:  %var_2_701 = load i64, i64* %RBP.i, align 8
; %var_2_897 = load i64, i64* %RBP, align 8
; Matched:%var_2_702:  %var_2_702 = add i64 %var_2_701, -176
; %var_2_898 = add i64 %var_2_897, -176
; Matched:%var_2_1669:  %var_2_1669 = add i64 %var_2_1593, 44
; %var_2_899 = add i64 %var_2_823, 44
; Matched:\<badref\>:  store i64 %var_2_1669, i64* %var_2_3, align 8
; store i64 %var_2_899, i64* %PC, align 8
; Matched:%var_2_3018:  %var_2_3018 = inttoptr i64 %var_2_3016 to double*
; %var_2_900 = inttoptr i64 %var_2_898 to double*
; Matched:\<badref\>:  store double %var_2_700, double* %var_2_704, align 8
; store double %var_2_896, double* %var_2_900, align 8
%var_2_901 = load i64, i64* %RBP, align 8
%var_2_902 = add i64 %var_2_901, -120
%var_2_903 = load i64, i64* %PC, align 8
; Matched:%var_2_1996:  %var_2_1996 = add i64 %var_2_1995, 5
; %var_2_904 = add i64 %var_2_903, 5
; Matched:\<badref\>:  store i64 %var_2_1996, i64* %var_2_3, align 8
; store i64 %var_2_904, i64* %PC, align 8
%var_2_905 = inttoptr i64 %var_2_902 to i64*
%var_2_906 = load i64, i64* %var_2_905, align 8
store i64 %var_2_906, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_907 = add i64 %var_2_901, -152
; Matched:%var_2_2919:  %var_2_2919 = add i64 %var_2_2908, 13
; %var_2_908 = add i64 %var_2_903, 13
; Matched:\<badref\>:  store i64 %var_2_4083, i64* %var_2_3, align 8
; store i64 %var_2_908, i64* %PC, align 8
%var_2_909 = bitcast i64 %var_2_906 to double
%var_2_910 = inttoptr i64 %var_2_907 to double*
%var_2_911 = load double, double* %var_2_910, align 8
%var_2_912 = fadd double %var_2_909, %var_2_911
store double %var_2_912, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_913 = add i64 %var_2_901, -16
; Matched:%var_2_743:  %var_2_743 = add i64 %var_2_732, 17
; %var_2_914 = add i64 %var_2_903, 17
; Matched:\<badref\>:  store i64 %var_2_743, i64* %var_2_3, align 8
; store i64 %var_2_914, i64* %PC, align 8
%var_2_915 = inttoptr i64 %var_2_913 to i64*
%var_2_916 = load i64, i64* %var_2_915, align 8
; Matched:\<badref\>:  store i64 %var_2_383, i64* %RCX.i2236, align 8
; store i64 %var_2_916, i64* %RCX, align 8
%var_2_917 = add i64 %var_2_901, -28
; Matched:%var_2_1845:  %var_2_1845 = add i64 %var_2_1834, 21
; %var_2_918 = add i64 %var_2_903, 21
; Matched:\<badref\>:  store i64 %var_2_3368, i64* %var_2_3, align 8
; store i64 %var_2_918, i64* %PC, align 8
%var_2_919 = inttoptr i64 %var_2_917 to i32*
%var_2_920 = load i32, i32* %var_2_919, align 4
%var_2_921 = sext i32 %var_2_920 to i64
; Matched:\<badref\>:  store i64 %var_2_725, i64* %RDX.i2239, align 8
; store i64 %var_2_921, i64* %RDX, align 8
; Matched:%var_2_3040:  %var_2_3040 = shl nsw i64 %var_2_3039, 3
; %var_2_922 = shl nsw i64 %var_2_921, 3
; Matched:%var_2_3041:  %var_2_3041 = add i64 %var_2_3040, %var_2_3034
; %var_2_923 = add i64 %var_2_922, %var_2_916
; Matched:%var_2_2931:  %var_2_2931 = add i64 %var_2_2908, 26
; %var_2_924 = add i64 %var_2_903, 26
; Matched:\<badref\>:  store i64 %var_2_2931, i64* %var_2_3, align 8
; store i64 %var_2_924, i64* %PC, align 8
; Matched:%var_2_729:  %var_2_729 = inttoptr i64 %var_2_727 to double*
; %var_2_925 = inttoptr i64 %var_2_923 to double*
; Matched:\<badref\>:  store double %var_2_3030, double* %var_2_3043, align 8
; store double %var_2_912, double* %var_2_925, align 8
%var_2_926 = load i64, i64* %RBP, align 8
%var_2_927 = add i64 %var_2_926, -128
%var_2_928 = load i64, i64* %PC, align 8
; Matched:%var_2_3022:  %var_2_3022 = add i64 %var_2_3021, 5
; %var_2_929 = add i64 %var_2_928, 5
; Matched:\<badref\>:  store i64 %var_2_3022, i64* %var_2_3, align 8
; store i64 %var_2_929, i64* %PC, align 8
%var_2_930 = inttoptr i64 %var_2_927 to i64*
%var_2_931 = load i64, i64* %var_2_930, align 8
store i64 %var_2_931, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_932 = add i64 %var_2_926, -160
; Matched:%var_2_492:  %var_2_492 = add i64 %var_2_481, 13
; %var_2_933 = add i64 %var_2_928, 13
; Matched:\<badref\>:  store i64 %var_2_492, i64* %var_2_3, align 8
; store i64 %var_2_933, i64* %PC, align 8
%var_2_934 = bitcast i64 %var_2_931 to double
%var_2_935 = inttoptr i64 %var_2_932 to double*
%var_2_936 = load double, double* %var_2_935, align 8
%var_2_937 = fadd double %var_2_934, %var_2_936
store double %var_2_937, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_938 = add i64 %var_2_926, -16
; Matched:%var_2_4199:  %var_2_4199 = add i64 %var_2_4185, 17
; %var_2_939 = add i64 %var_2_928, 17
; Matched:\<badref\>:  store i64 %var_2_4199, i64* %var_2_3, align 8
; store i64 %var_2_939, i64* %PC, align 8
%var_2_940 = inttoptr i64 %var_2_938 to i64*
%var_2_941 = load i64, i64* %var_2_940, align 8
; Matched:\<badref\>:  store i64 %var_2_258, i64* %RCX.i2236, align 8
; store i64 %var_2_941, i64* %RCX, align 8
%var_2_942 = add i64 %var_2_926, -28
; Matched:%var_2_2393:  %var_2_2393 = add i64 %var_2_2376, 20
; %var_2_943 = add i64 %var_2_928, 20
; Matched:\<badref\>:  store i64 %var_2_2393, i64* %var_2_3, align 8
; store i64 %var_2_943, i64* %PC, align 8
%var_2_944 = inttoptr i64 %var_2_942 to i32*
%var_2_945 = load i32, i32* %var_2_944, align 4
%var_2_946 = add i32 %var_2_945, 1
; Matched:%var_2_751:  %var_2_751 = zext i32 %var_2_750 to i64
; %var_2_947 = zext i32 %var_2_946 to i64
; Matched:\<badref\>:  store i64 %var_2_751, i64* %RAX.i2224, align 8
; store i64 %var_2_947, i64* %RAX, align 8
; Matched:%var_2_752:  %var_2_752 = icmp eq i32 %var_2_749, -1
; %var_2_948 = icmp eq i32 %var_2_945, -1
; Matched:%var_2_412:  %var_2_412 = icmp eq i32 %var_2_409, 0
; %var_2_949 = icmp eq i32 %var_2_946, 0
; Matched:%var_2_1379:  %var_2_1379 = or i1 %var_2_1377, %var_2_1378
; %var_2_950 = or i1 %var_2_948, %var_2_949
; Matched:%var_2_755:  %var_2_755 = zext i1 %var_2_754 to i8
; %var_2_951 = zext i1 %var_2_950 to i8
; Matched:\<badref\>:  store i8 %var_2_755, i8* %var_2_14, align 1
; store i8 %var_2_951, i8* %var_2_16, align 1
; Matched:%var_2_756:  %var_2_756 = and i32 %var_2_750, 255
; %var_2_952 = and i32 %var_2_946, 255
; Matched:%var_2_3894:  %var_2_3894 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3893)
; %var_2_953 = tail call i32 @llvm.ctpop.i32(i32 %var_2_952) #14
; Matched:%var_2_3895:  %var_2_3895 = trunc i32 %var_2_3894 to i8
; %var_2_954 = trunc i32 %var_2_953 to i8
; Matched:%var_2_4009:  %var_2_4009 = and i8 %var_2_4008, 1
; %var_2_955 = and i8 %var_2_954, 1
; Matched:%var_2_419:  %var_2_419 = xor i8 %var_2_418, 1
; %var_2_956 = xor i8 %var_2_955, 1
; Matched:\<badref\>:  store i8 %var_2_2733, i8* %var_2_21, align 1
; store i8 %var_2_956, i8* %var_2_23, align 1
; Matched:%var_2_307:  %var_2_307 = xor i32 %var_2_296, %var_2_295
; %var_2_957 = xor i32 %var_2_946, %var_2_945
; Matched:%var_2_308:  %var_2_308 = lshr i32 %var_2_307, 4
; %var_2_958 = lshr i32 %var_2_957, 4
; Matched:%var_2_309:  %var_2_309 = trunc i32 %var_2_308 to i8
; %var_2_959 = trunc i32 %var_2_958 to i8
; Matched:%var_2_310:  %var_2_310 = and i8 %var_2_309, 1
; %var_2_960 = and i8 %var_2_959, 1
; Matched:\<badref\>:  store i8 %var_2_310, i8* %var_2_27, align 1
; store i8 %var_2_960, i8* %var_2_29, align 1
; Matched:%var_2_765:  %var_2_765 = zext i1 %var_2_753 to i8
; %var_2_961 = zext i1 %var_2_949 to i8
; Matched:\<badref\>:  store i8 %var_2_311, i8* %var_2_30, align 1
; store i8 %var_2_961, i8* %var_2_32, align 1
; Matched:%var_2_766:  %var_2_766 = lshr i32 %var_2_750, 31
; %var_2_962 = lshr i32 %var_2_946, 31
; Matched:%var_2_313:  %var_2_313 = trunc i32 %var_2_312 to i8
; %var_2_963 = trunc i32 %var_2_962 to i8
; Matched:\<badref\>:  store i8 %var_2_3904, i8* %var_2_33, align 1
; store i8 %var_2_963, i8* %var_2_35, align 1
; Matched:%var_2_2628:  %var_2_2628 = lshr i32 %var_2_2609, 31
; %var_2_964 = lshr i32 %var_2_945, 31
; Matched:%var_2_1281:  %var_2_1281 = xor i32 %var_2_1278, %var_2_1280
; %var_2_965 = xor i32 %var_2_962, %var_2_964
; Matched:%var_2_1395:  %var_2_1395 = add nuw nsw i32 %var_2_1394, %var_2_1391
; %var_2_966 = add nuw nsw i32 %var_2_965, %var_2_962
; Matched:%var_2_1283:  %var_2_1283 = icmp eq i32 %var_2_1282, 2
; %var_2_967 = icmp eq i32 %var_2_966, 2
; Matched:%var_2_1738:  %var_2_1738 = zext i1 %var_2_1737 to i8
; %var_2_968 = zext i1 %var_2_967 to i8
; Matched:\<badref\>:  store i8 %var_2_1738, i8* %var_2_39, align 1
; store i8 %var_2_968, i8* %var_2_41, align 1
%var_2_969 = sext i32 %var_2_946 to i64
; Matched:\<badref\>:  store i64 %var_2_319, i64* %RDX.i2239, align 8
; store i64 %var_2_969, i64* %RDX, align 8
; Matched:%var_2_774:  %var_2_774 = shl nsw i64 %var_2_773, 3
; %var_2_970 = shl nsw i64 %var_2_969, 3
; Matched:%var_2_775:  %var_2_775 = add i64 %var_2_745, %var_2_774
; %var_2_971 = add i64 %var_2_941, %var_2_970
; Matched:%var_2_776:  %var_2_776 = add i64 %var_2_732, 31
; %var_2_972 = add i64 %var_2_928, 31
; Matched:\<badref\>:  store i64 %var_2_2598, i64* %var_2_3, align 8
; store i64 %var_2_972, i64* %PC, align 8
; Matched:%var_2_3091:  %var_2_3091 = inttoptr i64 %var_2_3089 to double*
; %var_2_973 = inttoptr i64 %var_2_971 to double*
; Matched:\<badref\>:  store double %var_2_741, double* %var_2_777, align 8
; store double %var_2_937, double* %var_2_973, align 8
%var_2_974 = load i64, i64* %RBP, align 8
%var_2_975 = add i64 %var_2_974, -160
%var_2_976 = load i64, i64* %PC, align 8
%var_2_977 = add i64 %var_2_976, 8
store i64 %var_2_977, i64* %PC, align 8
%var_2_978 = inttoptr i64 %var_2_975 to i64*
%var_2_979 = load i64, i64* %var_2_978, align 8
; Matched:\<badref\>:  store i64 %var_2_1749, i64* %var_2_1038, align 1
; store i64 %var_2_979, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1750:  %var_2_1750 = add i64 %var_2_1744, -128
; %var_2_980 = add i64 %var_2_974, -128
; Matched:%var_2_712:  %var_2_712 = add i64 %var_2_707, 13
; %var_2_981 = add i64 %var_2_976, 13
; Matched:\<badref\>:  store i64 %var_2_712, i64* %var_2_3, align 8
; store i64 %var_2_981, i64* %PC, align 8
; Matched:%var_2_1752:  %var_2_1752 = bitcast i64 %var_2_1749 to double
; %var_2_982 = bitcast i64 %var_2_979 to double
; Matched:%var_2_1753:  %var_2_1753 = inttoptr i64 %var_2_1750 to double*
; %var_2_983 = inttoptr i64 %var_2_980 to double*
; Matched:%var_2_1754:  %var_2_1754 = load double, double* %var_2_1753, align 8
; %var_2_984 = load double, double* %var_2_983, align 8
; Matched:%var_2_1755:  %var_2_1755 = fsub double %var_2_1752, %var_2_1754
; %var_2_985 = fsub double %var_2_982, %var_2_984
; Matched:\<badref\>:  store double %var_2_1755, double* %var_2_1037, align 1
; store double %var_2_985, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_986 = add i64 %var_2_974, -16
; Matched:%var_2_4086:  %var_2_4086 = add i64 %var_2_4072, 17
; %var_2_987 = add i64 %var_2_976, 17
; Matched:\<badref\>:  store i64 %var_2_4086, i64* %var_2_3, align 8
; store i64 %var_2_987, i64* %PC, align 8
%var_2_988 = inttoptr i64 %var_2_986 to i64*
%var_2_989 = load i64, i64* %var_2_988, align 8
; Matched:\<badref\>:  store i64 %var_2_1983, i64* %RCX.i2236, align 8
; store i64 %var_2_989, i64* %RCX, align 8
%var_2_990 = add i64 %var_2_974, -36
; Matched:%var_2_1464:  %var_2_1464 = add i64 %var_2_1447, 21
; %var_2_991 = add i64 %var_2_976, 21
; Matched:\<badref\>:  store i64 %var_2_1464, i64* %var_2_3, align 8
; store i64 %var_2_991, i64* %PC, align 8
%var_2_992 = inttoptr i64 %var_2_990 to i32*
%var_2_993 = load i32, i32* %var_2_992, align 4
%var_2_994 = sext i32 %var_2_993 to i64
; Matched:\<badref\>:  store i64 %var_2_798, i64* %RDX.i2239, align 8
; store i64 %var_2_994, i64* %RDX, align 8
; Matched:%var_2_1765:  %var_2_1765 = shl nsw i64 %var_2_1764, 3
; %var_2_995 = shl nsw i64 %var_2_994, 3
; Matched:%var_2_1766:  %var_2_1766 = add i64 %var_2_1765, %var_2_1759
; %var_2_996 = add i64 %var_2_995, %var_2_989
; Matched:%var_2_1470:  %var_2_1470 = add i64 %var_2_1447, 26
; %var_2_997 = add i64 %var_2_976, 26
; Matched:\<badref\>:  store i64 %var_2_1470, i64* %var_2_3, align 8
; store i64 %var_2_997, i64* %PC, align 8
; Matched:%var_2_1768:  %var_2_1768 = inttoptr i64 %var_2_1766 to double*
; %var_2_998 = inttoptr i64 %var_2_996 to double*
; Matched:\<badref\>:  store double %var_2_1755, double* %var_2_1768, align 8
; store double %var_2_985, double* %var_2_998, align 8
%var_2_999 = load i64, i64* %RBP, align 8
%var_2_1000 = add i64 %var_2_999, -120
%var_2_1001 = load i64, i64* %PC, align 8
; Matched:%var_2_1699:  %var_2_1699 = add i64 %var_2_1698, 5
; %var_2_1002 = add i64 %var_2_1001, 5
; Matched:\<badref\>:  store i64 %var_2_1699, i64* %var_2_3, align 8
; store i64 %var_2_1002, i64* %PC, align 8
%var_2_1003 = inttoptr i64 %var_2_1000 to i64*
%var_2_1004 = load i64, i64* %var_2_1003, align 8
store i64 %var_2_1004, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1775:  %var_2_1775 = add i64 %var_2_1769, -152
; %var_2_1005 = add i64 %var_2_999, -152
; Matched:%var_2_1571:  %var_2_1571 = add i64 %var_2_1560, 13
; %var_2_1006 = add i64 %var_2_1001, 13
; Matched:\<badref\>:  store i64 %var_2_1571, i64* %var_2_3, align 8
; store i64 %var_2_1006, i64* %PC, align 8
; Matched:%var_2_1777:  %var_2_1777 = bitcast i64 %var_2_1774 to double
; %var_2_1007 = bitcast i64 %var_2_1004 to double
; Matched:%var_2_1778:  %var_2_1778 = inttoptr i64 %var_2_1775 to double*
; %var_2_1008 = inttoptr i64 %var_2_1005 to double*
; Matched:%var_2_1779:  %var_2_1779 = load double, double* %var_2_1778, align 8
; %var_2_1009 = load double, double* %var_2_1008, align 8
; Matched:%var_2_1780:  %var_2_1780 = fsub double %var_2_1777, %var_2_1779
; %var_2_1010 = fsub double %var_2_1007, %var_2_1009
; Matched:\<badref\>:  store double %var_2_1780, double* %var_2_1037, align 1
; store double %var_2_1010, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_1011 = add i64 %var_2_999, -16
; Matched:%var_2_791:  %var_2_791 = add i64 %var_2_780, 17
; %var_2_1012 = add i64 %var_2_1001, 17
; Matched:\<badref\>:  store i64 %var_2_791, i64* %var_2_3, align 8
; store i64 %var_2_1012, i64* %PC, align 8
%var_2_1013 = inttoptr i64 %var_2_1011 to i64*
%var_2_1014 = load i64, i64* %var_2_1013, align 8
; Matched:\<badref\>:  store i64 %var_2_404, i64* %RCX.i2236, align 8
; store i64 %var_2_1014, i64* %RCX, align 8
%var_2_1015 = add i64 %var_2_999, -36
; Matched:%var_2_889:  %var_2_889 = add i64 %var_2_878, 20
; %var_2_1016 = add i64 %var_2_1001, 20
; Matched:\<badref\>:  store i64 %var_2_889, i64* %var_2_3, align 8
; store i64 %var_2_1016, i64* %PC, align 8
%var_2_1017 = inttoptr i64 %var_2_1015 to i32*
%var_2_1018 = load i32, i32* %var_2_1017, align 4
%var_2_1019 = add i32 %var_2_1018, 1
; Matched:%var_2_1790:  %var_2_1790 = zext i32 %var_2_1789 to i64
; %var_2_1020 = zext i32 %var_2_1019 to i64
; Matched:\<badref\>:  store i64 %var_2_1790, i64* %RAX.i2224, align 8
; store i64 %var_2_1020, i64* %RAX, align 8
; Matched:%var_2_825:  %var_2_825 = icmp eq i32 %var_2_822, -1
; %var_2_1021 = icmp eq i32 %var_2_1018, -1
; Matched:%var_2_826:  %var_2_826 = icmp eq i32 %var_2_823, 0
; %var_2_1022 = icmp eq i32 %var_2_1019, 0
; Matched:%var_2_827:  %var_2_827 = or i1 %var_2_825, %var_2_826
; %var_2_1023 = or i1 %var_2_1021, %var_2_1022
; Matched:%var_2_828:  %var_2_828 = zext i1 %var_2_827 to i8
; %var_2_1024 = zext i1 %var_2_1023 to i8
; Matched:\<badref\>:  store i8 %var_2_828, i8* %var_2_14, align 1
; store i8 %var_2_1024, i8* %var_2_16, align 1
; Matched:%var_2_829:  %var_2_829 = and i32 %var_2_823, 255
; %var_2_1025 = and i32 %var_2_1019, 255
; Matched:%var_2_830:  %var_2_830 = tail call i32 @llvm.ctpop.i32(i32 %var_2_829)
; %var_2_1026 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1025) #14
; Matched:%var_2_831:  %var_2_831 = trunc i32 %var_2_830 to i8
; %var_2_1027 = trunc i32 %var_2_1026 to i8
; Matched:%var_2_1798:  %var_2_1798 = and i8 %var_2_1797, 1
; %var_2_1028 = and i8 %var_2_1027, 1
; Matched:%var_2_4236:  %var_2_4236 = xor i8 %var_2_4235, 1
; %var_2_1029 = xor i8 %var_2_1028, 1
; Matched:\<badref\>:  store i8 %var_2_1799, i8* %var_2_21, align 1
; store i8 %var_2_1029, i8* %var_2_23, align 1
; Matched:%var_2_834:  %var_2_834 = xor i32 %var_2_823, %var_2_822
; %var_2_1030 = xor i32 %var_2_1019, %var_2_1018
; Matched:%var_2_835:  %var_2_835 = lshr i32 %var_2_834, 4
; %var_2_1031 = lshr i32 %var_2_1030, 4
; Matched:%var_2_836:  %var_2_836 = trunc i32 %var_2_835 to i8
; %var_2_1032 = trunc i32 %var_2_1031 to i8
; Matched:%var_2_837:  %var_2_837 = and i8 %var_2_836, 1
; %var_2_1033 = and i8 %var_2_1032, 1
; Matched:\<badref\>:  store i8 %var_2_837, i8* %var_2_27, align 1
; store i8 %var_2_1033, i8* %var_2_29, align 1
; Matched:%var_2_838:  %var_2_838 = zext i1 %var_2_826 to i8
; %var_2_1034 = zext i1 %var_2_1022 to i8
; Matched:\<badref\>:  store i8 %var_2_1804, i8* %var_2_30, align 1
; store i8 %var_2_1034, i8* %var_2_32, align 1
; Matched:%var_2_839:  %var_2_839 = lshr i32 %var_2_823, 31
; %var_2_1035 = lshr i32 %var_2_1019, 31
; Matched:%var_2_1806:  %var_2_1806 = trunc i32 %var_2_1805 to i8
; %var_2_1036 = trunc i32 %var_2_1035 to i8
; Matched:\<badref\>:  store i8 %var_2_840, i8* %var_2_33, align 1
; store i8 %var_2_1036, i8* %var_2_35, align 1
; Matched:%var_2_841:  %var_2_841 = lshr i32 %var_2_822, 31
; %var_2_1037 = lshr i32 %var_2_1018, 31
; Matched:%var_2_842:  %var_2_842 = xor i32 %var_2_839, %var_2_841
; %var_2_1038 = xor i32 %var_2_1035, %var_2_1037
; Matched:%var_2_1809:  %var_2_1809 = add nuw nsw i32 %var_2_1808, %var_2_1805
; %var_2_1039 = add nuw nsw i32 %var_2_1038, %var_2_1035
; Matched:%var_2_3208:  %var_2_3208 = icmp eq i32 %var_2_3207, 2
; %var_2_1040 = icmp eq i32 %var_2_1039, 2
; Matched:%var_2_4248:  %var_2_4248 = zext i1 %var_2_4247 to i8
; %var_2_1041 = zext i1 %var_2_1040 to i8
; Matched:\<badref\>:  store i8 %var_2_4135, i8* %var_2_39, align 1
; store i8 %var_2_1041, i8* %var_2_41, align 1
%var_2_1042 = sext i32 %var_2_1019 to i64
; Matched:\<badref\>:  store i64 %var_2_1812, i64* %RDX.i2239, align 8
; store i64 %var_2_1042, i64* %RDX, align 8
; Matched:%var_2_1813:  %var_2_1813 = shl nsw i64 %var_2_1812, 3
; %var_2_1043 = shl nsw i64 %var_2_1042, 3
; Matched:%var_2_1814:  %var_2_1814 = add i64 %var_2_1784, %var_2_1813
; %var_2_1044 = add i64 %var_2_1014, %var_2_1043
; Matched:%var_2_849:  %var_2_849 = add i64 %var_2_805, 31
; %var_2_1045 = add i64 %var_2_1001, 31
; Matched:\<badref\>:  store i64 %var_2_849, i64* %var_2_3, align 8
; store i64 %var_2_1045, i64* %PC, align 8
; Matched:%var_2_1816:  %var_2_1816 = inttoptr i64 %var_2_1814 to double*
; %var_2_1046 = inttoptr i64 %var_2_1044 to double*
; Matched:\<badref\>:  store double %var_2_1780, double* %var_2_1816, align 8
; store double %var_2_1010, double* %var_2_1046, align 8
%var_2_1047 = load i64, i64* %RBP, align 8
%var_2_1048 = add i64 %var_2_1047, -136
%var_2_1049 = load i64, i64* %PC, align 8
%var_2_1050 = add i64 %var_2_1049, 8
store i64 %var_2_1050, i64* %PC, align 8
%var_2_1051 = inttoptr i64 %var_2_1048 to i64*
%var_2_1052 = load i64, i64* %var_2_1051, align 8
store i64 %var_2_1052, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_1053 = add i64 %var_2_1047, -176
; Matched:%var_2_1839:  %var_2_1839 = add i64 %var_2_1834, 16
; %var_2_1054 = add i64 %var_2_1049, 16
; Matched:\<badref\>:  store i64 %var_2_1839, i64* %var_2_3, align 8
; store i64 %var_2_1054, i64* %PC, align 8
%var_2_1055 = bitcast i64 %var_2_1052 to double
%var_2_1056 = inttoptr i64 %var_2_1053 to double*
%var_2_1057 = load double, double* %var_2_1056, align 8
%var_2_1058 = fsub double %var_2_1055, %var_2_1057
store double %var_2_1058, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_1829:  %var_2_1829 = add i64 %var_2_1817, -120
; %var_2_1059 = add i64 %var_2_1047, -120
; Matched:%var_2_795:  %var_2_795 = add i64 %var_2_780, 21
; %var_2_1060 = add i64 %var_2_1049, 21
; Matched:\<badref\>:  store i64 %var_2_795, i64* %var_2_3, align 8
; store i64 %var_2_1060, i64* %PC, align 8
; Matched:%var_2_3229:  %var_2_3229 = inttoptr i64 %var_2_3227 to double*
; %var_2_1061 = inttoptr i64 %var_2_1059 to double*
; Matched:\<badref\>:  store double %var_2_3226, double* %var_2_3229, align 8
; store double %var_2_1058, double* %var_2_1061, align 8
%var_2_1062 = load i64, i64* %RBP, align 8
%var_2_1063 = add i64 %var_2_1062, -144
%var_2_1064 = load i64, i64* %PC, align 8
%var_2_1065 = add i64 %var_2_1064, 8
store i64 %var_2_1065, i64* %PC, align 8
%var_2_1066 = inttoptr i64 %var_2_1063 to i64*
%var_2_1067 = load i64, i64* %var_2_1066, align 8
store i64 %var_2_1067, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_1068 = add i64 %var_2_1062, -168
; Matched:%var_2_956:  %var_2_956 = add i64 %var_2_951, 16
; %var_2_1069 = add i64 %var_2_1064, 16
; Matched:\<badref\>:  store i64 %var_2_956, i64* %var_2_3, align 8
; store i64 %var_2_1069, i64* %PC, align 8
%var_2_1070 = bitcast i64 %var_2_1067 to double
%var_2_1071 = inttoptr i64 %var_2_1068 to double*
%var_2_1072 = load double, double* %var_2_1071, align 8
%var_2_1073 = fadd double %var_2_1070, %var_2_1072
store double %var_2_1073, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_3242:  %var_2_3242 = add i64 %var_2_3230, -128
; %var_2_1074 = add i64 %var_2_1062, -128
; Matched:%var_2_722:  %var_2_722 = add i64 %var_2_707, 21
; %var_2_1075 = add i64 %var_2_1064, 21
; Matched:\<badref\>:  store i64 %var_2_722, i64* %var_2_3, align 8
; store i64 %var_2_1075, i64* %PC, align 8
; Matched:%var_2_3244:  %var_2_3244 = inttoptr i64 %var_2_3242 to double*
; %var_2_1076 = inttoptr i64 %var_2_1074 to double*
; Matched:\<badref\>:  store double %var_2_3241, double* %var_2_3244, align 8
; store double %var_2_1073, double* %var_2_1076, align 8
%var_2_1077 = load i64, i64* %RBP, align 8
%var_2_1078 = add i64 %var_2_1077, -72
%var_2_1079 = load i64, i64* %PC, align 8
; Matched:%var_2_3047:  %var_2_3047 = add i64 %var_2_3046, 5
; %var_2_1080 = add i64 %var_2_1079, 5
; Matched:\<badref\>:  store i64 %var_2_3047, i64* %var_2_3, align 8
; store i64 %var_2_1080, i64* %PC, align 8
%var_2_1081 = inttoptr i64 %var_2_1078 to i64*
%var_2_1082 = load i64, i64* %var_2_1081, align 8
; Matched:\<badref\>:  store i64 %var_2_1998, i64* %var_2_1038, align 1
; store i64 %var_2_1082, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1853:  %var_2_1853 = add i64 %var_2_1847, -120
; %var_2_1083 = add i64 %var_2_1077, -120
; Matched:%var_2_3163:  %var_2_3163 = add i64 %var_2_3158, 10
; %var_2_1084 = add i64 %var_2_1079, 10
; Matched:\<badref\>:  store i64 %var_2_4676, i64* %var_2_3, align 8
; store i64 %var_2_1084, i64* %PC, align 8
; Matched:%var_2_1886:  %var_2_1886 = inttoptr i64 %var_2_1884 to i64*
; %var_2_1085 = inttoptr i64 %var_2_1083 to i64*
; Matched:%var_2_1887:  %var_2_1887 = load i64, i64* %var_2_1886, align 8
; %var_2_1086 = load i64, i64* %var_2_1085, align 8
; Matched:\<badref\>:  store i64 %var_2_1887, i64* %var_2_1054, align 1
; store i64 %var_2_1086, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_1857:  %var_2_1857 = add i64 %var_2_1847, -128
; %var_2_1087 = add i64 %var_2_1077, -128
; Matched:%var_2_3133:  %var_2_3133 = add i64 %var_2_3122, 15
; %var_2_1088 = add i64 %var_2_1079, 15
; Matched:\<badref\>:  store i64 %var_2_3133, i64* %var_2_3, align 8
; store i64 %var_2_1088, i64* %PC, align 8
; Matched:%var_2_1859:  %var_2_1859 = bitcast i64 %var_2_1856 to double
; %var_2_1089 = bitcast i64 %var_2_1086 to double
; Matched:%var_2_1860:  %var_2_1860 = inttoptr i64 %var_2_1857 to double*
; %var_2_1090 = inttoptr i64 %var_2_1087 to double*
; Matched:%var_2_1861:  %var_2_1861 = load double, double* %var_2_1860, align 8
; %var_2_1091 = load double, double* %var_2_1090, align 8
; Matched:%var_2_1862:  %var_2_1862 = fsub double %var_2_1859, %var_2_1861
; %var_2_1092 = fsub double %var_2_1089, %var_2_1091
; Matched:\<badref\>:  store double %var_2_1862, double* %var_2_1053, align 1
; store double %var_2_1092, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_1863:  %var_2_1863 = bitcast i64 %var_2_1852 to double
; %var_2_1093 = bitcast i64 %var_2_1082 to double
; Matched:%var_2_1864:  %var_2_1864 = fmul double %var_2_1863, %var_2_1862
; %var_2_1094 = fmul double %var_2_1093, %var_2_1092
; Matched:\<badref\>:  store double %var_2_1864, double* %var_2_1037, align 1
; store double %var_2_1094, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_1095 = add i64 %var_2_1077, -16
; Matched:%var_2_1866:  %var_2_1866 = add i64 %var_2_1849, 23
; %var_2_1096 = add i64 %var_2_1079, 23
; Matched:\<badref\>:  store i64 %var_2_1866, i64* %var_2_3, align 8
; store i64 %var_2_1096, i64* %PC, align 8
%var_2_1097 = inttoptr i64 %var_2_1095 to i64*
%var_2_1098 = load i64, i64* %var_2_1097, align 8
; Matched:\<badref\>:  store i64 %var_2_939, i64* %RCX.i2236, align 8
; store i64 %var_2_1098, i64* %RCX, align 8
%var_2_1099 = add i64 %var_2_1077, -32
; Matched:%var_2_2372:  %var_2_2372 = add i64 %var_2_2348, 27
; %var_2_1100 = add i64 %var_2_1079, 27
; Matched:\<badref\>:  store i64 %var_2_1985, i64* %var_2_3, align 8
; store i64 %var_2_1100, i64* %PC, align 8
%var_2_1101 = inttoptr i64 %var_2_1099 to i32*
%var_2_1102 = load i32, i32* %var_2_1101, align 4
%var_2_1103 = sext i32 %var_2_1102 to i64
; Matched:\<badref\>:  store i64 %var_2_1241, i64* %RDX.i2239, align 8
; store i64 %var_2_1103, i64* %RDX, align 8
; Matched:%var_2_1874:  %var_2_1874 = shl nsw i64 %var_2_1873, 3
; %var_2_1104 = shl nsw i64 %var_2_1103, 3
; Matched:%var_2_1875:  %var_2_1875 = add i64 %var_2_1874, %var_2_1868
; %var_2_1105 = add i64 %var_2_1104, %var_2_1098
; Matched:%var_2_1876:  %var_2_1876 = add i64 %var_2_1849, 32
; %var_2_1106 = add i64 %var_2_1079, 32
; Matched:\<badref\>:  store i64 %var_2_4697, i64* %var_2_3, align 8
; store i64 %var_2_1106, i64* %PC, align 8
; Matched:%var_2_1877:  %var_2_1877 = inttoptr i64 %var_2_1875 to double*
; %var_2_1107 = inttoptr i64 %var_2_1105 to double*
; Matched:\<badref\>:  store double %var_2_1864, double* %var_2_1877, align 8
; store double %var_2_1094, double* %var_2_1107, align 8
%var_2_1108 = load i64, i64* %RBP, align 8
%var_2_1109 = add i64 %var_2_1108, -72
%var_2_1110 = load i64, i64* %PC, align 8
; Matched:%var_2_4708:  %var_2_4708 = add i64 %var_2_4707, 5
; %var_2_1111 = add i64 %var_2_1110, 5
; Matched:\<badref\>:  store i64 %var_2_4708, i64* %var_2_3, align 8
; store i64 %var_2_1111, i64* %PC, align 8
%var_2_1112 = inttoptr i64 %var_2_1109 to i64*
%var_2_1113 = load i64, i64* %var_2_1112, align 8
; Matched:\<badref\>:  store i64 %var_2_1883, i64* %var_2_1038, align 1
; store i64 %var_2_1113, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1884:  %var_2_1884 = add i64 %var_2_1878, -120
; %var_2_1114 = add i64 %var_2_1108, -120
; Matched:%var_2_4712:  %var_2_4712 = add i64 %var_2_4707, 10
; %var_2_1115 = add i64 %var_2_1110, 10
; Matched:\<badref\>:  store i64 %var_2_3288, i64* %var_2_3, align 8
; store i64 %var_2_1115, i64* %PC, align 8
; Matched:%var_2_1855:  %var_2_1855 = inttoptr i64 %var_2_1853 to i64*
; %var_2_1116 = inttoptr i64 %var_2_1114 to i64*
; Matched:%var_2_1856:  %var_2_1856 = load i64, i64* %var_2_1855, align 8
; %var_2_1117 = load i64, i64* %var_2_1116, align 8
; Matched:\<badref\>:  store i64 %var_2_1856, i64* %var_2_1054, align 1
; store i64 %var_2_1117, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_1888:  %var_2_1888 = add i64 %var_2_1878, -128
; %var_2_1118 = add i64 %var_2_1108, -128
; Matched:%var_2_3383:  %var_2_3383 = add i64 %var_2_3372, 15
; %var_2_1119 = add i64 %var_2_1110, 15
; Matched:\<badref\>:  store i64 %var_2_3383, i64* %var_2_3, align 8
; store i64 %var_2_1119, i64* %PC, align 8
; Matched:%var_2_1890:  %var_2_1890 = bitcast i64 %var_2_1887 to double
; %var_2_1120 = bitcast i64 %var_2_1117 to double
; Matched:%var_2_1891:  %var_2_1891 = inttoptr i64 %var_2_1888 to double*
; %var_2_1121 = inttoptr i64 %var_2_1118 to double*
; Matched:%var_2_1892:  %var_2_1892 = load double, double* %var_2_1891, align 8
; %var_2_1122 = load double, double* %var_2_1121, align 8
; Matched:%var_2_1893:  %var_2_1893 = fadd double %var_2_1890, %var_2_1892
; %var_2_1123 = fadd double %var_2_1120, %var_2_1122
; Matched:\<badref\>:  store double %var_2_1893, double* %var_2_1053, align 1
; store double %var_2_1123, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_1894:  %var_2_1894 = bitcast i64 %var_2_1883 to double
; %var_2_1124 = bitcast i64 %var_2_1113 to double
; Matched:%var_2_1895:  %var_2_1895 = fmul double %var_2_1894, %var_2_1893
; %var_2_1125 = fmul double %var_2_1124, %var_2_1123
; Matched:\<badref\>:  store double %var_2_1895, double* %var_2_1037, align 1
; store double %var_2_1125, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_1126 = add i64 %var_2_1108, -16
; Matched:%var_2_3578:  %var_2_3578 = add i64 %var_2_3541, 23
; %var_2_1127 = add i64 %var_2_1110, 23
; Matched:\<badref\>:  store i64 %var_2_1981, i64* %var_2_3, align 8
; store i64 %var_2_1127, i64* %PC, align 8
%var_2_1128 = inttoptr i64 %var_2_1126 to i64*
%var_2_1129 = load i64, i64* %var_2_1128, align 8
; Matched:\<badref\>:  store i64 %var_2_1563, i64* %RCX.i2236, align 8
; store i64 %var_2_1129, i64* %RCX, align 8
%var_2_1130 = add i64 %var_2_1108, -32
; Matched:%var_2_4208:  %var_2_4208 = add i64 %var_2_4185, 26
; %var_2_1131 = add i64 %var_2_1110, 26
; Matched:\<badref\>:  store i64 %var_2_4208, i64* %var_2_3, align 8
; store i64 %var_2_1131, i64* %PC, align 8
%var_2_1132 = inttoptr i64 %var_2_1130 to i32*
%var_2_1133 = load i32, i32* %var_2_1132, align 4
%var_2_1134 = add i32 %var_2_1133, 1
; Matched:%var_2_1411:  %var_2_1411 = zext i32 %var_2_1410 to i64
; %var_2_1135 = zext i32 %var_2_1134 to i64
; Matched:\<badref\>:  store i64 %var_2_1411, i64* %RAX.i2224, align 8
; store i64 %var_2_1135, i64* %RAX, align 8
; Matched:%var_2_1412:  %var_2_1412 = icmp eq i32 %var_2_1409, -1
; %var_2_1136 = icmp eq i32 %var_2_1133, -1
; Matched:%var_2_334:  %var_2_334 = icmp eq i32 %var_2_331, 0
; %var_2_1137 = icmp eq i32 %var_2_1134, 0
; Matched:%var_2_900:  %var_2_900 = or i1 %var_2_898, %var_2_899
; %var_2_1138 = or i1 %var_2_1136, %var_2_1137
; Matched:%var_2_1415:  %var_2_1415 = zext i1 %var_2_1414 to i8
; %var_2_1139 = zext i1 %var_2_1138 to i8
; Matched:\<badref\>:  store i8 %var_2_1302, i8* %var_2_14, align 1
; store i8 %var_2_1139, i8* %var_2_16, align 1
; Matched:%var_2_1303:  %var_2_1303 = and i32 %var_2_1297, 255
; %var_2_1140 = and i32 %var_2_1134, 255
; Matched:%var_2_1417:  %var_2_1417 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1416)
; %var_2_1141 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1140) #14
; Matched:%var_2_1418:  %var_2_1418 = trunc i32 %var_2_1417 to i8
; %var_2_1142 = trunc i32 %var_2_1141 to i8
; Matched:%var_2_1306:  %var_2_1306 = and i8 %var_2_1305, 1
; %var_2_1143 = and i8 %var_2_1142, 1
; Matched:%var_2_1307:  %var_2_1307 = xor i8 %var_2_1306, 1
; %var_2_1144 = xor i8 %var_2_1143, 1
; Matched:\<badref\>:  store i8 %var_2_1420, i8* %var_2_21, align 1
; store i8 %var_2_1144, i8* %var_2_23, align 1
; Matched:%var_2_455:  %var_2_455 = xor i32 %var_2_444, %var_2_443
; %var_2_1145 = xor i32 %var_2_1134, %var_2_1133
; Matched:%var_2_456:  %var_2_456 = lshr i32 %var_2_455, 4
; %var_2_1146 = lshr i32 %var_2_1145, 4
; Matched:%var_2_457:  %var_2_457 = trunc i32 %var_2_456 to i8
; %var_2_1147 = trunc i32 %var_2_1146 to i8
; Matched:%var_2_458:  %var_2_458 = and i8 %var_2_457, 1
; %var_2_1148 = and i8 %var_2_1147, 1
; Matched:\<badref\>:  store i8 %var_2_458, i8* %var_2_27, align 1
; store i8 %var_2_1148, i8* %var_2_29, align 1
; Matched:%var_2_1425:  %var_2_1425 = zext i1 %var_2_1413 to i8
; %var_2_1149 = zext i1 %var_2_1137 to i8
; Matched:\<badref\>:  store i8 %var_2_1425, i8* %var_2_30, align 1
; store i8 %var_2_1149, i8* %var_2_32, align 1
; Matched:%var_2_1426:  %var_2_1426 = lshr i32 %var_2_1410, 31
; %var_2_1150 = lshr i32 %var_2_1134, 31
; Matched:%var_2_1427:  %var_2_1427 = trunc i32 %var_2_1426 to i8
; %var_2_1151 = trunc i32 %var_2_1150 to i8
; Matched:\<badref\>:  store i8 %var_2_461, i8* %var_2_33, align 1
; store i8 %var_2_1151, i8* %var_2_35, align 1
; Matched:%var_2_1428:  %var_2_1428 = lshr i32 %var_2_1409, 31
; %var_2_1152 = lshr i32 %var_2_1133, 31
; Matched:%var_2_1316:  %var_2_1316 = xor i32 %var_2_1313, %var_2_1315
; %var_2_1153 = xor i32 %var_2_1150, %var_2_1152
; Matched:%var_2_1430:  %var_2_1430 = add nuw nsw i32 %var_2_1429, %var_2_1426
; %var_2_1154 = add nuw nsw i32 %var_2_1153, %var_2_1150
; Matched:%var_2_352:  %var_2_352 = icmp eq i32 %var_2_351, 2
; %var_2_1155 = icmp eq i32 %var_2_1154, 2
; Matched:%var_2_353:  %var_2_353 = zext i1 %var_2_352 to i8
; %var_2_1156 = zext i1 %var_2_1155 to i8
; Matched:\<badref\>:  store i8 %var_2_466, i8* %var_2_39, align 1
; store i8 %var_2_1156, i8* %var_2_41, align 1
%var_2_1157 = sext i32 %var_2_1134 to i64
; Matched:\<badref\>:  store i64 %var_2_1320, i64* %RDX.i2239, align 8
; store i64 %var_2_1157, i64* %RDX, align 8
; Matched:%var_2_1928:  %var_2_1928 = shl nsw i64 %var_2_1927, 3
; %var_2_1158 = shl nsw i64 %var_2_1157, 3
; Matched:%var_2_1929:  %var_2_1929 = add i64 %var_2_1899, %var_2_1928
; %var_2_1159 = add i64 %var_2_1129, %var_2_1158
; Matched:%var_2_3404:  %var_2_3404 = add i64 %var_2_3372, 37
; %var_2_1160 = add i64 %var_2_1110, 37
; Matched:\<badref\>:  store i64 %var_2_3404, i64* %var_2_3, align 8
; store i64 %var_2_1160, i64* %PC, align 8
; Matched:%var_2_1931:  %var_2_1931 = inttoptr i64 %var_2_1929 to double*
; %var_2_1161 = inttoptr i64 %var_2_1159 to double*
; Matched:\<badref\>:  store double %var_2_1895, double* %var_2_1931, align 8
; store double %var_2_1125, double* %var_2_1161, align 8
; Matched:%var_2_1932:  %var_2_1932 = load i64, i64* %RBP.i, align 8
; %var_2_1162 = load i64, i64* %RBP, align 8
; Matched:%var_2_1933:  %var_2_1933 = add i64 %var_2_1932, -176
; %var_2_1163 = add i64 %var_2_1162, -176
%var_2_1164 = load i64, i64* %PC, align 8
%var_2_1165 = add i64 %var_2_1164, 8
store i64 %var_2_1165, i64* %PC, align 8
; Matched:%var_2_1936:  %var_2_1936 = inttoptr i64 %var_2_1933 to i64*
; %var_2_1166 = inttoptr i64 %var_2_1163 to i64*
; Matched:%var_2_1937:  %var_2_1937 = load i64, i64* %var_2_1936, align 8
; %var_2_1167 = load i64, i64* %var_2_1166, align 8
; Matched:\<badref\>:  store i64 %var_2_1937, i64* %var_2_1038, align 1
; store i64 %var_2_1167, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1938:  %var_2_1938 = add i64 %var_2_1932, -136
; %var_2_1168 = add i64 %var_2_1162, -136
; Matched:%var_2_3347:  %var_2_3347 = add i64 %var_2_3342, 16
; %var_2_1169 = add i64 %var_2_1164, 16
; Matched:\<badref\>:  store i64 %var_2_3347, i64* %var_2_3, align 8
; store i64 %var_2_1169, i64* %PC, align 8
; Matched:%var_2_1940:  %var_2_1940 = bitcast i64 %var_2_1937 to double
; %var_2_1170 = bitcast i64 %var_2_1167 to double
; Matched:%var_2_1941:  %var_2_1941 = inttoptr i64 %var_2_1938 to double*
; %var_2_1171 = inttoptr i64 %var_2_1168 to double*
; Matched:%var_2_1942:  %var_2_1942 = load double, double* %var_2_1941, align 8
; %var_2_1172 = load double, double* %var_2_1171, align 8
; Matched:%var_2_1943:  %var_2_1943 = fadd double %var_2_1940, %var_2_1942
; %var_2_1173 = fadd double %var_2_1170, %var_2_1172
; Matched:\<badref\>:  store double %var_2_1943, double* %var_2_1037, align 1
; store double %var_2_1173, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_1944:  %var_2_1944 = add i64 %var_2_1932, -120
; %var_2_1174 = add i64 %var_2_1162, -120
; Matched:%var_2_1945:  %var_2_1945 = add i64 %var_2_1934, 21
; %var_2_1175 = add i64 %var_2_1164, 21
; Matched:\<badref\>:  store i64 %var_2_2586, i64* %var_2_3, align 8
; store i64 %var_2_1175, i64* %PC, align 8
; Matched:%var_2_1946:  %var_2_1946 = inttoptr i64 %var_2_1944 to double*
; %var_2_1176 = inttoptr i64 %var_2_1174 to double*
; Matched:\<badref\>:  store double %var_2_1943, double* %var_2_1946, align 8
; store double %var_2_1173, double* %var_2_1176, align 8
; Matched:%var_2_1947:  %var_2_1947 = load i64, i64* %RBP.i, align 8
; %var_2_1177 = load i64, i64* %RBP, align 8
; Matched:%var_2_1948:  %var_2_1948 = add i64 %var_2_1947, -168
; %var_2_1178 = add i64 %var_2_1177, -168
%var_2_1179 = load i64, i64* %PC, align 8
%var_2_1180 = add i64 %var_2_1179, 8
store i64 %var_2_1180, i64* %PC, align 8
; Matched:%var_2_1951:  %var_2_1951 = inttoptr i64 %var_2_1948 to i64*
; %var_2_1181 = inttoptr i64 %var_2_1178 to i64*
; Matched:%var_2_1952:  %var_2_1952 = load i64, i64* %var_2_1951, align 8
; %var_2_1182 = load i64, i64* %var_2_1181, align 8
; Matched:\<badref\>:  store i64 %var_2_1952, i64* %var_2_1038, align 1
; store i64 %var_2_1182, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1953:  %var_2_1953 = add i64 %var_2_1947, -144
; %var_2_1183 = add i64 %var_2_1177, -144
; Matched:%var_2_3237:  %var_2_3237 = add i64 %var_2_3232, 16
; %var_2_1184 = add i64 %var_2_1179, 16
; Matched:\<badref\>:  store i64 %var_2_3237, i64* %var_2_3, align 8
; store i64 %var_2_1184, i64* %PC, align 8
; Matched:%var_2_1955:  %var_2_1955 = bitcast i64 %var_2_1952 to double
; %var_2_1185 = bitcast i64 %var_2_1182 to double
; Matched:%var_2_1956:  %var_2_1956 = inttoptr i64 %var_2_1953 to double*
; %var_2_1186 = inttoptr i64 %var_2_1183 to double*
; Matched:%var_2_1957:  %var_2_1957 = load double, double* %var_2_1956, align 8
; %var_2_1187 = load double, double* %var_2_1186, align 8
; Matched:%var_2_1958:  %var_2_1958 = fsub double %var_2_1955, %var_2_1957
; %var_2_1188 = fsub double %var_2_1185, %var_2_1187
; Matched:\<badref\>:  store double %var_2_1958, double* %var_2_1037, align 1
; store double %var_2_1188, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_1959:  %var_2_1959 = add i64 %var_2_1947, -128
; %var_2_1189 = add i64 %var_2_1177, -128
; Matched:%var_2_1761:  %var_2_1761 = add i64 %var_2_1746, 21
; %var_2_1190 = add i64 %var_2_1179, 21
; Matched:\<badref\>:  store i64 %var_2_1761, i64* %var_2_3, align 8
; store i64 %var_2_1190, i64* %PC, align 8
; Matched:%var_2_1961:  %var_2_1961 = inttoptr i64 %var_2_1959 to double*
; %var_2_1191 = inttoptr i64 %var_2_1189 to double*
; Matched:\<badref\>:  store double %var_2_1958, double* %var_2_1961, align 8
; store double %var_2_1188, double* %var_2_1191, align 8
%var_2_1192 = load i64, i64* %RBP, align 8
%var_2_1193 = add i64 %var_2_1192, -72
%var_2_1194 = load i64, i64* %PC, align 8
; Matched:%var_2_3409:  %var_2_3409 = add i64 %var_2_3408, 5
; %var_2_1195 = add i64 %var_2_1194, 5
; Matched:\<badref\>:  store i64 %var_2_3409, i64* %var_2_3, align 8
; store i64 %var_2_1195, i64* %PC, align 8
%var_2_1196 = inttoptr i64 %var_2_1193 to i64*
%var_2_1197 = load i64, i64* %var_2_1196, align 8
; Matched:\<badref\>:  store i64 %var_2_4549, i64* %var_2_1038, align 1
; store i64 %var_2_1197, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1968:  %var_2_1968 = add i64 %var_2_1962, -128
; %var_2_1198 = add i64 %var_2_1192, -128
; Matched:%var_2_1969:  %var_2_1969 = add i64 %var_2_1964, 10
; %var_2_1199 = add i64 %var_2_1194, 10
; Matched:\<badref\>:  store i64 %var_2_1885, i64* %var_2_3, align 8
; store i64 %var_2_1199, i64* %PC, align 8
; Matched:%var_2_1970:  %var_2_1970 = inttoptr i64 %var_2_1968 to i64*
; %var_2_1200 = inttoptr i64 %var_2_1198 to i64*
; Matched:%var_2_2002:  %var_2_2002 = load i64, i64* %var_2_2001, align 8
; %var_2_1201 = load i64, i64* %var_2_1200, align 8
; Matched:\<badref\>:  store i64 %var_2_2002, i64* %var_2_1054, align 1
; store i64 %var_2_1201, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_1972:  %var_2_1972 = add i64 %var_2_1962, -120
; %var_2_1202 = add i64 %var_2_1192, -120
; Matched:%var_2_3294:  %var_2_3294 = add i64 %var_2_3283, 15
; %var_2_1203 = add i64 %var_2_1194, 15
; Matched:\<badref\>:  store i64 %var_2_3294, i64* %var_2_3, align 8
; store i64 %var_2_1203, i64* %PC, align 8
; Matched:%var_2_1974:  %var_2_1974 = bitcast i64 %var_2_1971 to double
; %var_2_1204 = bitcast i64 %var_2_1201 to double
; Matched:%var_2_1975:  %var_2_1975 = inttoptr i64 %var_2_1972 to double*
; %var_2_1205 = inttoptr i64 %var_2_1202 to double*
; Matched:%var_2_1976:  %var_2_1976 = load double, double* %var_2_1975, align 8
; %var_2_1206 = load double, double* %var_2_1205, align 8
; Matched:%var_2_1977:  %var_2_1977 = fsub double %var_2_1974, %var_2_1976
; %var_2_1207 = fsub double %var_2_1204, %var_2_1206
; Matched:\<badref\>:  store double %var_2_1977, double* %var_2_1053, align 1
; store double %var_2_1207, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_1978:  %var_2_1978 = bitcast i64 %var_2_1967 to double
; %var_2_1208 = bitcast i64 %var_2_1197 to double
; Matched:%var_2_1979:  %var_2_1979 = fmul double %var_2_1978, %var_2_1977
; %var_2_1209 = fmul double %var_2_1208, %var_2_1207
; Matched:\<badref\>:  store double %var_2_1979, double* %var_2_1037, align 1
; store double %var_2_1209, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_1210 = add i64 %var_2_1192, -16
; Matched:%var_2_2344:  %var_2_2344 = add i64 %var_2_2306, 23
; %var_2_1211 = add i64 %var_2_1194, 23
; Matched:\<badref\>:  store i64 %var_2_4463, i64* %var_2_3, align 8
; store i64 %var_2_1211, i64* %PC, align 8
%var_2_1212 = inttoptr i64 %var_2_1210 to i64*
%var_2_1213 = load i64, i64* %var_2_1212, align 8
; Matched:\<badref\>:  store i64 %var_2_818, i64* %RCX.i2236, align 8
; store i64 %var_2_1213, i64* %RCX, align 8
%var_2_1214 = add i64 %var_2_1192, -40
; Matched:%var_2_1985:  %var_2_1985 = add i64 %var_2_1964, 27
; %var_2_1215 = add i64 %var_2_1194, 27
; Matched:\<badref\>:  store i64 %var_2_1870, i64* %var_2_3, align 8
; store i64 %var_2_1215, i64* %PC, align 8
%var_2_1216 = inttoptr i64 %var_2_1214 to i32*
%var_2_1217 = load i32, i32* %var_2_1216, align 4
%var_2_1218 = sext i32 %var_2_1217 to i64
; Matched:\<badref\>:  store i64 %var_2_3401, i64* %RDX.i2239, align 8
; store i64 %var_2_1218, i64* %RDX, align 8
; Matched:%var_2_1989:  %var_2_1989 = shl nsw i64 %var_2_1988, 3
; %var_2_1219 = shl nsw i64 %var_2_1218, 3
; Matched:%var_2_1990:  %var_2_1990 = add i64 %var_2_1989, %var_2_1983
; %var_2_1220 = add i64 %var_2_1219, %var_2_1213
; Matched:%var_2_4572:  %var_2_4572 = add i64 %var_2_4546, 32
; %var_2_1221 = add i64 %var_2_1194, 32
; Matched:\<badref\>:  store i64 %var_2_3148, i64* %var_2_3, align 8
; store i64 %var_2_1221, i64* %PC, align 8
; Matched:%var_2_1992:  %var_2_1992 = inttoptr i64 %var_2_1990 to double*
; %var_2_1222 = inttoptr i64 %var_2_1220 to double*
; Matched:\<badref\>:  store double %var_2_1979, double* %var_2_1992, align 8
; store double %var_2_1209, double* %var_2_1222, align 8
%var_2_1223 = load i64, i64* %RBP, align 8
%var_2_1224 = add i64 %var_2_1223, -72
%var_2_1225 = load i64, i64* %PC, align 8
; Matched:%var_2_3123:  %var_2_3123 = add i64 %var_2_3122, 5
; %var_2_1226 = add i64 %var_2_1225, 5
; Matched:\<badref\>:  store i64 %var_2_3123, i64* %var_2_3, align 8
; store i64 %var_2_1226, i64* %PC, align 8
%var_2_1227 = inttoptr i64 %var_2_1224 to i64*
%var_2_1228 = load i64, i64* %var_2_1227, align 8
; Matched:\<badref\>:  store i64 %var_2_3286, i64* %var_2_1038, align 1
; store i64 %var_2_1228, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1999:  %var_2_1999 = add i64 %var_2_1993, -128
; %var_2_1229 = add i64 %var_2_1223, -128
; Matched:%var_2_3377:  %var_2_3377 = add i64 %var_2_3372, 10
; %var_2_1230 = add i64 %var_2_1225, 10
; Matched:\<badref\>:  store i64 %var_2_3377, i64* %var_2_3, align 8
; store i64 %var_2_1230, i64* %PC, align 8
; Matched:%var_2_2001:  %var_2_2001 = inttoptr i64 %var_2_1999 to i64*
; %var_2_1231 = inttoptr i64 %var_2_1229 to i64*
; Matched:%var_2_1971:  %var_2_1971 = load i64, i64* %var_2_1970, align 8
; %var_2_1232 = load i64, i64* %var_2_1231, align 8
; Matched:\<badref\>:  store i64 %var_2_1971, i64* %var_2_1054, align 1
; store i64 %var_2_1232, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_2003:  %var_2_2003 = add i64 %var_2_1993, -120
; %var_2_1233 = add i64 %var_2_1223, -120
; Matched:%var_2_4557:  %var_2_4557 = add i64 %var_2_4546, 15
; %var_2_1234 = add i64 %var_2_1225, 15
; Matched:\<badref\>:  store i64 %var_2_4557, i64* %var_2_3, align 8
; store i64 %var_2_1234, i64* %PC, align 8
; Matched:%var_2_2005:  %var_2_2005 = bitcast i64 %var_2_2002 to double
; %var_2_1235 = bitcast i64 %var_2_1232 to double
; Matched:%var_2_2006:  %var_2_2006 = inttoptr i64 %var_2_2003 to double*
; %var_2_1236 = inttoptr i64 %var_2_1233 to double*
; Matched:%var_2_2007:  %var_2_2007 = load double, double* %var_2_2006, align 8
; %var_2_1237 = load double, double* %var_2_1236, align 8
; Matched:%var_2_2008:  %var_2_2008 = fadd double %var_2_2005, %var_2_2007
; %var_2_1238 = fadd double %var_2_1235, %var_2_1237
; Matched:\<badref\>:  store double %var_2_2008, double* %var_2_1053, align 1
; store double %var_2_1238, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_2009:  %var_2_2009 = bitcast i64 %var_2_1998 to double
; %var_2_1239 = bitcast i64 %var_2_1228 to double
; Matched:%var_2_2010:  %var_2_2010 = fmul double %var_2_2009, %var_2_2008
; %var_2_1240 = fmul double %var_2_1239, %var_2_1238
; Matched:\<badref\>:  store double %var_2_2010, double* %var_2_1037, align 1
; store double %var_2_1240, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_1241 = add i64 %var_2_1223, -16
; Matched:%var_2_966:  %var_2_966 = add i64 %var_2_951, 23
; %var_2_1242 = add i64 %var_2_1225, 23
; Matched:\<badref\>:  store i64 %var_2_966, i64* %var_2_3, align 8
; store i64 %var_2_1242, i64* %PC, align 8
%var_2_1243 = inttoptr i64 %var_2_1241 to i64*
%var_2_1244 = load i64, i64* %var_2_1243, align 8
; Matched:\<badref\>:  store i64 %var_2_1631, i64* %RCX.i2236, align 8
; store i64 %var_2_1244, i64* %RCX, align 8
%var_2_1245 = add i64 %var_2_1223, -40
; Matched:%var_2_504:  %var_2_504 = add i64 %var_2_481, 26
; %var_2_1246 = add i64 %var_2_1225, 26
; Matched:\<badref\>:  store i64 %var_2_504, i64* %var_2_3, align 8
; store i64 %var_2_1246, i64* %PC, align 8
%var_2_1247 = inttoptr i64 %var_2_1245 to i32*
%var_2_1248 = load i32, i32* %var_2_1247, align 4
%var_2_1249 = add i32 %var_2_1248, 1
; Matched:%var_2_970:  %var_2_970 = zext i32 %var_2_969 to i64
; %var_2_1250 = zext i32 %var_2_1249 to i64
; Matched:\<badref\>:  store i64 %var_2_970, i64* %RAX.i2224, align 8
; store i64 %var_2_1250, i64* %RAX, align 8
; Matched:%var_2_2021:  %var_2_2021 = icmp eq i32 %var_2_2018, -1
; %var_2_1251 = icmp eq i32 %var_2_1248, -1
; Matched:%var_2_4264:  %var_2_4264 = icmp eq i32 %var_2_4261, 0
; %var_2_1252 = icmp eq i32 %var_2_1249, 0
; Matched:%var_2_4152:  %var_2_4152 = or i1 %var_2_4150, %var_2_4151
; %var_2_1253 = or i1 %var_2_1251, %var_2_1252
; Matched:%var_2_974:  %var_2_974 = zext i1 %var_2_973 to i8
; %var_2_1254 = zext i1 %var_2_1253 to i8
; Matched:\<badref\>:  store i8 %var_2_974, i8* %var_2_14, align 1
; store i8 %var_2_1254, i8* %var_2_16, align 1
; Matched:%var_2_4267:  %var_2_4267 = and i32 %var_2_4261, 255
; %var_2_1255 = and i32 %var_2_1249, 255
; Matched:%var_2_4268:  %var_2_4268 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4267)
; %var_2_1256 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1255) #14
; Matched:%var_2_4269:  %var_2_4269 = trunc i32 %var_2_4268 to i8
; %var_2_1257 = trunc i32 %var_2_1256 to i8
; Matched:%var_2_4270:  %var_2_4270 = and i8 %var_2_4269, 1
; %var_2_1258 = and i8 %var_2_1257, 1
; Matched:%var_2_4271:  %var_2_4271 = xor i8 %var_2_4270, 1
; %var_2_1259 = xor i8 %var_2_1258, 1
; Matched:\<badref\>:  store i8 %var_2_4158, i8* %var_2_21, align 1
; store i8 %var_2_1259, i8* %var_2_23, align 1
; Matched:%var_2_4159:  %var_2_4159 = xor i32 %var_2_4148, %var_2_4147
; %var_2_1260 = xor i32 %var_2_1249, %var_2_1248
; Matched:%var_2_4273:  %var_2_4273 = lshr i32 %var_2_4272, 4
; %var_2_1261 = lshr i32 %var_2_1260, 4
; Matched:%var_2_982:  %var_2_982 = trunc i32 %var_2_981 to i8
; %var_2_1262 = trunc i32 %var_2_1261 to i8
; Matched:%var_2_4275:  %var_2_4275 = and i8 %var_2_4274, 1
; %var_2_1263 = and i8 %var_2_1262, 1
; Matched:\<badref\>:  store i8 %var_2_4275, i8* %var_2_27, align 1
; store i8 %var_2_1263, i8* %var_2_29, align 1
; Matched:%var_2_4276:  %var_2_4276 = zext i1 %var_2_4264 to i8
; %var_2_1264 = zext i1 %var_2_1252 to i8
; Matched:\<badref\>:  store i8 %var_2_4276, i8* %var_2_30, align 1
; store i8 %var_2_1264, i8* %var_2_32, align 1
; Matched:%var_2_4277:  %var_2_4277 = lshr i32 %var_2_4261, 31
; %var_2_1265 = lshr i32 %var_2_1249, 31
; Matched:%var_2_4278:  %var_2_4278 = trunc i32 %var_2_4277 to i8
; %var_2_1266 = trunc i32 %var_2_1265 to i8
; Matched:\<badref\>:  store i8 %var_2_4278, i8* %var_2_33, align 1
; store i8 %var_2_1266, i8* %var_2_35, align 1
; Matched:%var_2_4279:  %var_2_4279 = lshr i32 %var_2_4260, 31
; %var_2_1267 = lshr i32 %var_2_1248, 31
; Matched:%var_2_988:  %var_2_988 = xor i32 %var_2_985, %var_2_987
; %var_2_1268 = xor i32 %var_2_1265, %var_2_1267
; Matched:%var_2_4281:  %var_2_4281 = add nuw nsw i32 %var_2_4280, %var_2_4277
; %var_2_1269 = add nuw nsw i32 %var_2_1268, %var_2_1265
; Matched:%var_2_4169:  %var_2_4169 = icmp eq i32 %var_2_4168, 2
; %var_2_1270 = icmp eq i32 %var_2_1269, 2
; Matched:%var_2_4283:  %var_2_4283 = zext i1 %var_2_4282 to i8
; %var_2_1271 = zext i1 %var_2_1270 to i8
; Matched:\<badref\>:  store i8 %var_2_4283, i8* %var_2_39, align 1
; store i8 %var_2_1271, i8* %var_2_41, align 1
%var_2_1272 = sext i32 %var_2_1249 to i64
; Matched:\<badref\>:  store i64 %var_2_992, i64* %RDX.i2239, align 8
; store i64 %var_2_1272, i64* %RDX, align 8
; Matched:%var_2_2043:  %var_2_2043 = shl nsw i64 %var_2_2042, 3
; %var_2_1273 = shl nsw i64 %var_2_1272, 3
; Matched:%var_2_2044:  %var_2_2044 = add i64 %var_2_2014, %var_2_2043
; %var_2_1274 = add i64 %var_2_1244, %var_2_1273
; Matched:%var_2_3154:  %var_2_3154 = add i64 %var_2_3122, 37
; %var_2_1275 = add i64 %var_2_1225, 37
; Matched:\<badref\>:  store i64 %var_2_3154, i64* %var_2_3, align 8
; store i64 %var_2_1275, i64* %PC, align 8
; Matched:%var_2_2046:  %var_2_2046 = inttoptr i64 %var_2_2044 to double*
; %var_2_1276 = inttoptr i64 %var_2_1274 to double*
; Matched:\<badref\>:  store double %var_2_2010, double* %var_2_2046, align 8
; store double %var_2_1240, double* %var_2_1276, align 8
; Matched:%var_2_3465:  %var_2_3465 = load i64, i64* %RBP.i, align 8
; %var_2_1277 = load i64, i64* %RBP, align 8
; Matched:%var_2_3466:  %var_2_3466 = add i64 %var_2_3465, -28
; %var_2_1278 = add i64 %var_2_1277, -28
%var_2_1279 = load i64, i64* %PC, align 8
; Matched:%var_2_3806:  %var_2_3806 = add i64 %var_2_3805, 3
; %var_2_1280 = add i64 %var_2_1279, 3
; Matched:\<badref\>:  store i64 %var_2_3806, i64* %var_2_3, align 8
; store i64 %var_2_1280, i64* %PC, align 8
; Matched:%var_2_1001:  %var_2_1001 = inttoptr i64 %var_2_998 to i32*
; %var_2_1281 = inttoptr i64 %var_2_1278 to i32*
; Matched:%var_2_3470:  %var_2_3470 = load i32, i32* %var_2_3469, align 4
; %var_2_1282 = load i32, i32* %var_2_1281, align 4
; Matched:%var_2_3471:  %var_2_3471 = add i32 %var_2_3470, 2
; %var_2_1283 = add i32 %var_2_1282, 2
; Matched:%var_2_3472:  %var_2_3472 = zext i32 %var_2_3471 to i64
; %var_2_1284 = zext i32 %var_2_1283 to i64
; Matched:\<badref\>:  store i64 %var_2_3472, i64* %RAX.i2224, align 8
; store i64 %var_2_1284, i64* %RAX, align 8
; Matched:%var_2_1005:  %var_2_1005 = icmp ugt i32 %var_2_1002, -3
; %var_2_1285 = icmp ugt i32 %var_2_1282, -3
; Matched:%var_2_1006:  %var_2_1006 = zext i1 %var_2_1005 to i8
; %var_2_1286 = zext i1 %var_2_1285 to i8
; Matched:\<badref\>:  store i8 %var_2_3474, i8* %var_2_14, align 1
; store i8 %var_2_1286, i8* %var_2_16, align 1
; Matched:%var_2_1007:  %var_2_1007 = and i32 %var_2_1003, 255
; %var_2_1287 = and i32 %var_2_1283, 255
; Matched:%var_2_3476:  %var_2_3476 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3475)
; %var_2_1288 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1287) #14
; Matched:%var_2_3477:  %var_2_3477 = trunc i32 %var_2_3476 to i8
; %var_2_1289 = trunc i32 %var_2_1288 to i8
; Matched:%var_2_3478:  %var_2_3478 = and i8 %var_2_3477, 1
; %var_2_1290 = and i8 %var_2_1289, 1
; Matched:%var_2_3479:  %var_2_3479 = xor i8 %var_2_3478, 1
; %var_2_1291 = xor i8 %var_2_1290, 1
; Matched:\<badref\>:  store i8 %var_2_1011, i8* %var_2_21, align 1
; store i8 %var_2_1291, i8* %var_2_23, align 1
; Matched:%var_2_1012:  %var_2_1012 = xor i32 %var_2_1003, %var_2_1002
; %var_2_1292 = xor i32 %var_2_1283, %var_2_1282
; Matched:%var_2_3481:  %var_2_3481 = lshr i32 %var_2_3480, 4
; %var_2_1293 = lshr i32 %var_2_1292, 4
; Matched:%var_2_1014:  %var_2_1014 = trunc i32 %var_2_1013 to i8
; %var_2_1294 = trunc i32 %var_2_1293 to i8
; Matched:%var_2_3483:  %var_2_3483 = and i8 %var_2_3482, 1
; %var_2_1295 = and i8 %var_2_1294, 1
; Matched:\<badref\>:  store i8 %var_2_3483, i8* %var_2_27, align 1
; store i8 %var_2_1295, i8* %var_2_29, align 1
; Matched:%var_2_3484:  %var_2_3484 = icmp eq i32 %var_2_3471, 0
; %var_2_1296 = icmp eq i32 %var_2_1283, 0
; Matched:%var_2_3485:  %var_2_3485 = zext i1 %var_2_3484 to i8
; %var_2_1297 = zext i1 %var_2_1296 to i8
; Matched:\<badref\>:  store i8 %var_2_1017, i8* %var_2_30, align 1
; store i8 %var_2_1297, i8* %var_2_32, align 1
; Matched:%var_2_1018:  %var_2_1018 = lshr i32 %var_2_1003, 31
; %var_2_1298 = lshr i32 %var_2_1283, 31
; Matched:%var_2_3487:  %var_2_3487 = trunc i32 %var_2_3486 to i8
; %var_2_1299 = trunc i32 %var_2_1298 to i8
; Matched:\<badref\>:  store i8 %var_2_1019, i8* %var_2_33, align 1
; store i8 %var_2_1299, i8* %var_2_35, align 1
; Matched:%var_2_3488:  %var_2_3488 = lshr i32 %var_2_3470, 31
; %var_2_1300 = lshr i32 %var_2_1282, 31
; Matched:%var_2_3489:  %var_2_3489 = xor i32 %var_2_3486, %var_2_3488
; %var_2_1301 = xor i32 %var_2_1298, %var_2_1300
; Matched:%var_2_3490:  %var_2_3490 = add nuw nsw i32 %var_2_3489, %var_2_3486
; %var_2_1302 = add nuw nsw i32 %var_2_1301, %var_2_1298
; Matched:%var_2_3491:  %var_2_3491 = icmp eq i32 %var_2_3490, 2
; %var_2_1303 = icmp eq i32 %var_2_1302, 2
; Matched:%var_2_1024:  %var_2_1024 = zext i1 %var_2_1023 to i8
; %var_2_1304 = zext i1 %var_2_1303 to i8
; Matched:\<badref\>:  store i8 %var_2_1024, i8* %var_2_39, align 1
; store i8 %var_2_1304, i8* %var_2_41, align 1
%var_2_1305 = add i64 %var_2_1279, 9
store i64 %var_2_1305, i64* %PC, align 8
; Matched:\<badref\>:  store i32 %var_2_3471, i32* %var_2_3469, align 4
; store i32 %var_2_1283, i32* %var_2_1281, align 4
; Matched:%var_2_2076:  %var_2_2076 = load i64, i64* %var_2_3, align 8
; %var_2_1306 = load i64, i64* %PC, align 8
; Matched:%var_2_2077:  %var_2_2077 = add i64 %var_2_2076, -695
; %var_2_1307 = add i64 %var_2_1306, -695
; Matched:\<badref\>:  store i64 %var_2_2077, i64* %var_2_3, align 8
; store i64 %var_2_1307, i64* %PC, align 8
  br label %block_4035c1

block_40387d:                                     ; preds = %block_4035c1
%var_2_1308 = add i64 %var_2_4767, -48
; Matched:%var_2_2079:  %var_2_2079 = add i64 %var_2_1101, 7
; %var_2_1309 = add i64 %var_2_4810, 7
; Matched:\<badref\>:  store i64 %var_2_2079, i64* %var_2_3, align 8
; store i64 %var_2_1309, i64* %PC, align 8
%var_2_1310 = inttoptr i64 %var_2_1308 to i32*
store i32 0, i32* %var_2_1310, align 4
; Matched:%var_2_2081:  %var_2_2081 = load i64, i64* %RBP.i, align 8
; %var_2_1311 = load i64, i64* %RBP, align 8
; Matched:%var_2_2082:  %var_2_2082 = add i64 %var_2_2081, -56
; %var_2_1312 = add i64 %var_2_1311, -56
%var_2_1313 = load i64, i64* %PC, align 8
; Matched:%var_2_3468:  %var_2_3468 = add i64 %var_2_3467, 3
; %var_2_1314 = add i64 %var_2_1313, 3
; Matched:\<badref\>:  store i64 %var_2_3468, i64* %var_2_3, align 8
; store i64 %var_2_1314, i64* %PC, align 8
; Matched:%var_2_2085:  %var_2_2085 = inttoptr i64 %var_2_2082 to i32*
; %var_2_1315 = inttoptr i64 %var_2_1312 to i32*
; Matched:%var_2_2086:  %var_2_2086 = load i32, i32* %var_2_2085, align 4
; %var_2_1316 = load i32, i32* %var_2_1315, align 4
; Matched:%var_2_2087:  %var_2_2087 = shl i32 %var_2_2086, 1
; %var_2_1317 = shl i32 %var_2_1316, 1
; Matched:%var_2_2088:  %var_2_2088 = icmp slt i32 %var_2_2086, 0
; %var_2_1318 = icmp slt i32 %var_2_1316, 0
; Matched:%var_2_2089:  %var_2_2089 = icmp slt i32 %var_2_2087, 0
; %var_2_1319 = icmp slt i32 %var_2_1317, 0
; Matched:%var_2_2090:  %var_2_2090 = xor i1 %var_2_2088, %var_2_2089
; %var_2_1320 = xor i1 %var_2_1318, %var_2_1319
; Matched:%var_2_2091:  %var_2_2091 = zext i32 %var_2_2087 to i64
; %var_2_1321 = zext i32 %var_2_1317 to i64
; Matched:\<badref\>:  store i64 %var_2_2091, i64* %RAX.i2224, align 8
; store i64 %var_2_1321, i64* %RAX, align 8
; Matched:  %.lobit = lshr i32 %var_2_2086, 31
; %.lobit = lshr i32 %var_2_1316, 31
; Matched:%var_2_2092:  %var_2_2092 = trunc i32 %.lobit to i8
; %var_2_1322 = trunc i32 %.lobit to i8
; Matched:\<badref\>:  store i8 %var_2_2092, i8* %var_2_14, align 1
; store i8 %var_2_1322, i8* %var_2_16, align 1
; Matched:%var_2_2093:  %var_2_2093 = and i32 %var_2_2087, 254
; %var_2_1323 = and i32 %var_2_1317, 254
; Matched:%var_2_2094:  %var_2_2094 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2093)
; %var_2_1324 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1323) #14
; Matched:%var_2_2095:  %var_2_2095 = trunc i32 %var_2_2094 to i8
; %var_2_1325 = trunc i32 %var_2_1324 to i8
; Matched:%var_2_2096:  %var_2_2096 = and i8 %var_2_2095, 1
; %var_2_1326 = and i8 %var_2_1325, 1
; Matched:%var_2_2097:  %var_2_2097 = xor i8 %var_2_2096, 1
; %var_2_1327 = xor i8 %var_2_1326, 1
; Matched:\<badref\>:  store i8 %var_2_2097, i8* %var_2_21, align 1
; store i8 %var_2_1327, i8* %var_2_23, align 1
store i8 0, i8* %var_2_29, align 1
; Matched:%var_2_2098:  %var_2_2098 = icmp eq i32 %var_2_2087, 0
; %var_2_1328 = icmp eq i32 %var_2_1317, 0
; Matched:%var_2_2099:  %var_2_2099 = zext i1 %var_2_2098 to i8
; %var_2_1329 = zext i1 %var_2_1328 to i8
; Matched:\<badref\>:  store i8 %var_2_2099, i8* %var_2_30, align 1
; store i8 %var_2_1329, i8* %var_2_32, align 1
; Matched:%var_2_2100:  %var_2_2100 = lshr i32 %var_2_2086, 30
; %var_2_1330 = lshr i32 %var_2_1316, 30
; Matched:%var_2_2101:  %var_2_2101 = trunc i32 %var_2_2100 to i8
; %var_2_1331 = trunc i32 %var_2_1330 to i8
; Matched:%var_2_2102:  %var_2_2102 = and i8 %var_2_2101, 1
; %var_2_1332 = and i8 %var_2_1331, 1
; Matched:\<badref\>:  store i8 %var_2_2102, i8* %var_2_33, align 1
; store i8 %var_2_1332, i8* %var_2_35, align 1
; Matched:%var_2_2103:  %var_2_2103 = zext i1 %var_2_2090 to i8
; %var_2_1333 = zext i1 %var_2_1320 to i8
; Matched:\<badref\>:  store i8 %var_2_2103, i8* %var_2_39, align 1
; store i8 %var_2_1333, i8* %var_2_41, align 1
; Matched:%var_2_2104:  %var_2_2104 = add i64 %var_2_2081, -60
; %var_2_1334 = add i64 %var_2_1311, -60
%var_2_1335 = add i64 %var_2_1313, 9
store i64 %var_2_1335, i64* %PC, align 8
; Matched:%var_2_2106:  %var_2_2106 = inttoptr i64 %var_2_2104 to i32*
; %var_2_1336 = inttoptr i64 %var_2_1334 to i32*
; Matched:\<badref\>:  store i32 %var_2_2087, i32* %var_2_2106, align 4
; store i32 %var_2_1317, i32* %var_2_1336, align 4
; Matched:%var_2_2107:  %var_2_2107 = load i64, i64* %RBP.i, align 8
; %var_2_1337 = load i64, i64* %RBP, align 8
; Matched:%var_2_4796:  %var_2_4796 = add i64 %var_2_4795, -60
; %var_2_1338 = add i64 %var_2_1337, -60
%var_2_1339 = load i64, i64* %PC, align 8
; Matched:%var_2_2398:  %var_2_2398 = add i64 %var_2_2397, 3
; %var_2_1340 = add i64 %var_2_1339, 3
; Matched:\<badref\>:  store i64 %var_2_2398, i64* %var_2_3, align 8
; store i64 %var_2_1340, i64* %PC, align 8
; Matched:%var_2_4798:  %var_2_4798 = inttoptr i64 %var_2_4796 to i32*
; %var_2_1341 = inttoptr i64 %var_2_1338 to i32*
; Matched:%var_2_4799:  %var_2_4799 = load i32, i32* %var_2_4798, align 4
; %var_2_1342 = load i32, i32* %var_2_1341, align 4
; Matched:%var_2_4800:  %var_2_4800 = zext i32 %var_2_4799 to i64
; %var_2_1343 = zext i32 %var_2_1342 to i64
; Matched:\<badref\>:  store i64 %var_2_2113, i64* %RAX.i2224, align 8
; store i64 %var_2_1343, i64* %RAX, align 8
; Matched:%var_2_2114:  %var_2_2114 = add i64 %var_2_2107, -44
; %var_2_1344 = add i64 %var_2_1337, -44
; Matched:%var_2_1050:  %var_2_1050 = add i64 %var_2_1044, 6
; %var_2_1345 = add i64 %var_2_1339, 6
; Matched:\<badref\>:  store i64 %var_2_1050, i64* %var_2_3, align 8
; store i64 %var_2_1345, i64* %PC, align 8
; Matched:%var_2_2116:  %var_2_2116 = inttoptr i64 %var_2_2114 to i32*
; %var_2_1346 = inttoptr i64 %var_2_1344 to i32*
; Matched:\<badref\>:  store i32 %var_2_2112, i32* %var_2_2116, align 4
; store i32 %var_2_1342, i32* %var_2_1346, align 4
; Matched:%var_2_2118:  %var_2_2118 = bitcast %union.VectorReg* %var_2_2117 to i8*
; %var_2_1347 = bitcast %union.VectorReg* %var_2_1601 to i8*
%var_2_1348 = bitcast [32 x %union.VectorReg]* %var_2_5 to <2 x i32>*
%var_2_1349 = bitcast i64* %var_2_95 to <2 x i32>*
; Matched:%var_2_2121:  %var_2_2121 = bitcast %union.VectorReg* %var_2_2117 to i32*
; %var_2_1350 = bitcast %union.VectorReg* %var_2_1601 to i32*
; Matched:%var_2_2122:  %var_2_2122 = getelementptr inbounds i8, i8* %var_2_2118, i64 4
; %var_2_1351 = getelementptr inbounds i8, i8* %var_2_1347, i64 4
; Matched:%var_2_2123:  %var_2_2123 = bitcast i8* %var_2_2122 to i32*
; %var_2_1352 = bitcast i8* %var_2_1351 to i32*
; Matched:%var_2_2124:  %var_2_2124 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
; %var_2_1353 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
; Matched:%var_2_2125:  %var_2_2125 = bitcast i64* %var_2_2124 to i32*
; %var_2_1354 = bitcast i64* %var_2_1353 to i32*
; Matched:%var_2_2126:  %var_2_2126 = getelementptr inbounds i8, i8* %var_2_2118, i64 12
; %var_2_1355 = getelementptr inbounds i8, i8* %var_2_1347, i64 12
; Matched:%var_2_2127:  %var_2_2127 = bitcast i8* %var_2_2126 to i32*
; %var_2_1356 = bitcast i8* %var_2_1355 to i32*
; Matched:%var_2_2128:  %var_2_2128 = bitcast %union.VectorReg* %var_2_2117 to double*
; %var_2_1357 = bitcast %union.VectorReg* %var_2_1601 to double*
; Matched:  %.pre24 = load i64, i64* %var_2_3, align 8
; %.pre24 = load i64, i64* %PC, align 8
  br label %block_403893

block_403c52:                                     ; preds = %block_403940
%var_2_1358 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 80) to i64*), align 16
store i64 %var_2_1358, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_3500:  %var_2_3500 = add i64 %var_2_2406, -24
; %var_2_1359 = add i64 %var_2_4812, -24
; Matched:%var_2_3501:  %var_2_3501 = add i64 %var_2_2449, 12
; %var_2_1360 = add i64 %var_2_4855, 12
; Matched:\<badref\>:  store i64 %var_2_3501, i64* %var_2_3, align 8
; store i64 %var_2_1360, i64* %PC, align 8
; Matched:%var_2_3502:  %var_2_3502 = inttoptr i64 %var_2_3500 to i64*
; %var_2_1361 = inttoptr i64 %var_2_1359 to i64*
; Matched:%var_2_3544:  %var_2_3544 = load i64, i64* %var_2_3543, align 8
; %var_2_1362 = load i64, i64* %var_2_1361, align 8
; Matched:\<badref\>:  store i64 %var_2_3503, i64* %RAX.i2224, align 8
; store i64 %var_2_1362, i64* %RAX, align 8
; Matched:%var_2_3504:  %var_2_3504 = add i64 %var_2_2406, -52
; %var_2_1363 = add i64 %var_2_4812, -52
; Matched:%var_2_3505:  %var_2_3505 = add i64 %var_2_2449, 15
; %var_2_1364 = add i64 %var_2_4855, 15
; Matched:\<badref\>:  store i64 %var_2_3505, i64* %var_2_3, align 8
; store i64 %var_2_1364, i64* %PC, align 8
; Matched:%var_2_3506:  %var_2_3506 = inttoptr i64 %var_2_3504 to i32*
; %var_2_1365 = inttoptr i64 %var_2_1363 to i32*
; Matched:%var_2_3507:  %var_2_3507 = load i32, i32* %var_2_3506, align 4
; %var_2_1366 = load i32, i32* %var_2_1365, align 4
; Matched:%var_2_3508:  %var_2_3508 = add i32 %var_2_3507, 2
; %var_2_1367 = add i32 %var_2_1366, 2
; Matched:%var_2_3509:  %var_2_3509 = zext i32 %var_2_3508 to i64
; %var_2_1368 = zext i32 %var_2_1367 to i64
; Matched:\<badref\>:  store i64 %var_2_3509, i64* %RCX.i2236, align 8
; store i64 %var_2_1368, i64* %RCX, align 8
; Matched:%var_2_3510:  %var_2_3510 = icmp ugt i32 %var_2_3507, -3
; %var_2_1369 = icmp ugt i32 %var_2_1366, -3
; Matched:%var_2_3511:  %var_2_3511 = zext i1 %var_2_3510 to i8
; %var_2_1370 = zext i1 %var_2_1369 to i8
; Matched:\<badref\>:  store i8 %var_2_3511, i8* %var_2_14, align 1
; store i8 %var_2_1370, i8* %var_2_16, align 1
; Matched:%var_2_3512:  %var_2_3512 = and i32 %var_2_3508, 255
; %var_2_1371 = and i32 %var_2_1367, 255
; Matched:%var_2_3513:  %var_2_3513 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3512)
; %var_2_1372 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1371) #14
; Matched:%var_2_3514:  %var_2_3514 = trunc i32 %var_2_3513 to i8
; %var_2_1373 = trunc i32 %var_2_1372 to i8
; Matched:%var_2_3515:  %var_2_3515 = and i8 %var_2_3514, 1
; %var_2_1374 = and i8 %var_2_1373, 1
; Matched:%var_2_3516:  %var_2_3516 = xor i8 %var_2_3515, 1
; %var_2_1375 = xor i8 %var_2_1374, 1
; Matched:\<badref\>:  store i8 %var_2_3516, i8* %var_2_21, align 1
; store i8 %var_2_1375, i8* %var_2_23, align 1
; Matched:%var_2_3517:  %var_2_3517 = xor i32 %var_2_3508, %var_2_3507
; %var_2_1376 = xor i32 %var_2_1367, %var_2_1366
; Matched:%var_2_3518:  %var_2_3518 = lshr i32 %var_2_3517, 4
; %var_2_1377 = lshr i32 %var_2_1376, 4
; Matched:%var_2_3519:  %var_2_3519 = trunc i32 %var_2_3518 to i8
; %var_2_1378 = trunc i32 %var_2_1377 to i8
; Matched:%var_2_3520:  %var_2_3520 = and i8 %var_2_3519, 1
; %var_2_1379 = and i8 %var_2_1378, 1
; Matched:\<badref\>:  store i8 %var_2_3520, i8* %var_2_27, align 1
; store i8 %var_2_1379, i8* %var_2_29, align 1
; Matched:%var_2_3521:  %var_2_3521 = icmp eq i32 %var_2_3508, 0
; %var_2_1380 = icmp eq i32 %var_2_1367, 0
; Matched:%var_2_3522:  %var_2_3522 = zext i1 %var_2_3521 to i8
; %var_2_1381 = zext i1 %var_2_1380 to i8
; Matched:\<badref\>:  store i8 %var_2_3522, i8* %var_2_30, align 1
; store i8 %var_2_1381, i8* %var_2_32, align 1
; Matched:%var_2_3523:  %var_2_3523 = lshr i32 %var_2_3508, 31
; %var_2_1382 = lshr i32 %var_2_1367, 31
; Matched:%var_2_3524:  %var_2_3524 = trunc i32 %var_2_3523 to i8
; %var_2_1383 = trunc i32 %var_2_1382 to i8
; Matched:\<badref\>:  store i8 %var_2_3524, i8* %var_2_33, align 1
; store i8 %var_2_1383, i8* %var_2_35, align 1
; Matched:%var_2_3525:  %var_2_3525 = lshr i32 %var_2_3507, 31
; %var_2_1384 = lshr i32 %var_2_1366, 31
; Matched:%var_2_3526:  %var_2_3526 = xor i32 %var_2_3523, %var_2_3525
; %var_2_1385 = xor i32 %var_2_1382, %var_2_1384
; Matched:%var_2_3527:  %var_2_3527 = add nuw nsw i32 %var_2_3526, %var_2_3523
; %var_2_1386 = add nuw nsw i32 %var_2_1385, %var_2_1382
; Matched:%var_2_3528:  %var_2_3528 = icmp eq i32 %var_2_3527, 2
; %var_2_1387 = icmp eq i32 %var_2_1386, 2
; Matched:%var_2_3529:  %var_2_3529 = zext i1 %var_2_3528 to i8
; %var_2_1388 = zext i1 %var_2_1387 to i8
; Matched:\<badref\>:  store i8 %var_2_3529, i8* %var_2_39, align 1
; store i8 %var_2_1388, i8* %var_2_41, align 1
; Matched:%var_2_3530:  %var_2_3530 = sext i32 %var_2_3508 to i64
; %var_2_1389 = sext i32 %var_2_1367 to i64
; Matched:\<badref\>:  store i64 %var_2_3530, i64* %RDX.i2239, align 8
; store i64 %var_2_1389, i64* %RDX, align 8
; Matched:%var_2_3531:  %var_2_3531 = shl nsw i64 %var_2_3530, 3
; %var_2_1390 = shl nsw i64 %var_2_1389, 3
; Matched:%var_2_3532:  %var_2_3532 = add i64 %var_2_3503, %var_2_3531
; %var_2_1391 = add i64 %var_2_1362, %var_2_1390
; Matched:%var_2_3533:  %var_2_3533 = add i64 %var_2_2449, 26
; %var_2_1392 = add i64 %var_2_4855, 26
; Matched:\<badref\>:  store i64 %var_2_3533, i64* %var_2_3, align 8
; store i64 %var_2_1392, i64* %PC, align 8
; Matched:%var_2_3534:  %var_2_3534 = inttoptr i64 %var_2_3532 to i64*
; %var_2_1393 = inttoptr i64 %var_2_1391 to i64*
; Matched:%var_2_3535:  %var_2_3535 = load i64, i64* %var_2_3534, align 8
; %var_2_1394 = load i64, i64* %var_2_1393, align 8
; Matched:\<badref\>:  store i64 %var_2_3535, i64* %var_2_1054, align 1
; store i64 %var_2_1394, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_3536:  %var_2_3536 = add i64 %var_2_2406, -72
; %var_2_1395 = add i64 %var_2_4812, -72
; Matched:%var_2_3537:  %var_2_3537 = add i64 %var_2_2449, 31
; %var_2_1396 = add i64 %var_2_4855, 31
; Matched:\<badref\>:  store i64 %var_2_3537, i64* %var_2_3, align 8
; store i64 %var_2_1396, i64* %PC, align 8
; Matched:%var_2_3538:  %var_2_3538 = inttoptr i64 %var_2_3536 to i64*
; %var_2_1397 = inttoptr i64 %var_2_1395 to i64*
; Matched:\<badref\>:  store i64 %var_2_3535, i64* %var_2_3538, align 8
; store i64 %var_2_1394, i64* %var_2_1397, align 8
%var_2_1398 = load i64, i64* %RBP, align 8
; Matched:%var_2_3540:  %var_2_3540 = add i64 %var_2_3539, -24
; %var_2_1399 = add i64 %var_2_1398, -24
%var_2_1400 = load i64, i64* %PC, align 8
; Matched:%var_2_2227:  %var_2_2227 = add i64 %var_2_2226, 4
; %var_2_1401 = add i64 %var_2_1400, 4
; Matched:\<badref\>:  store i64 %var_2_2227, i64* %var_2_3, align 8
; store i64 %var_2_1401, i64* %PC, align 8
; Matched:%var_2_3543:  %var_2_3543 = inttoptr i64 %var_2_3540 to i64*
; %var_2_1402 = inttoptr i64 %var_2_1399 to i64*
; Matched:%var_2_3503:  %var_2_3503 = load i64, i64* %var_2_3502, align 8
; %var_2_1403 = load i64, i64* %var_2_1402, align 8
; Matched:\<badref\>:  store i64 %var_2_1031, i64* %RAX.i2224, align 8
; store i64 %var_2_1403, i64* %RAX, align 8
; Matched:%var_2_3545:  %var_2_3545 = add i64 %var_2_3539, -52
; %var_2_1404 = add i64 %var_2_1398, -52
; Matched:%var_2_2946:  %var_2_2946 = add i64 %var_2_2941, 7
; %var_2_1405 = add i64 %var_2_1400, 7
; Matched:\<badref\>:  store i64 %var_2_2720, i64* %var_2_3, align 8
; store i64 %var_2_1405, i64* %PC, align 8
; Matched:%var_2_3547:  %var_2_3547 = inttoptr i64 %var_2_3545 to i32*
; %var_2_1406 = inttoptr i64 %var_2_1404 to i32*
; Matched:%var_2_3548:  %var_2_3548 = load i32, i32* %var_2_3547, align 4
; %var_2_1407 = load i32, i32* %var_2_1406, align 4
; Matched:%var_2_3549:  %var_2_3549 = add i32 %var_2_3548, 3
; %var_2_1408 = add i32 %var_2_1407, 3
; Matched:%var_2_3550:  %var_2_3550 = zext i32 %var_2_3549 to i64
; %var_2_1409 = zext i32 %var_2_1408 to i64
; Matched:\<badref\>:  store i64 %var_2_3550, i64* %RCX.i2236, align 8
; store i64 %var_2_1409, i64* %RCX, align 8
; Matched:%var_2_3551:  %var_2_3551 = icmp ugt i32 %var_2_3548, -4
; %var_2_1410 = icmp ugt i32 %var_2_1407, -4
; Matched:%var_2_3552:  %var_2_3552 = zext i1 %var_2_3551 to i8
; %var_2_1411 = zext i1 %var_2_1410 to i8
; Matched:\<badref\>:  store i8 %var_2_3552, i8* %var_2_14, align 1
; store i8 %var_2_1411, i8* %var_2_16, align 1
; Matched:%var_2_3553:  %var_2_3553 = and i32 %var_2_3549, 255
; %var_2_1412 = and i32 %var_2_1408, 255
; Matched:%var_2_3554:  %var_2_3554 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3553)
; %var_2_1413 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1412) #14
; Matched:%var_2_3555:  %var_2_3555 = trunc i32 %var_2_3554 to i8
; %var_2_1414 = trunc i32 %var_2_1413 to i8
; Matched:%var_2_3556:  %var_2_3556 = and i8 %var_2_3555, 1
; %var_2_1415 = and i8 %var_2_1414, 1
; Matched:%var_2_3557:  %var_2_3557 = xor i8 %var_2_3556, 1
; %var_2_1416 = xor i8 %var_2_1415, 1
; Matched:\<badref\>:  store i8 %var_2_3557, i8* %var_2_21, align 1
; store i8 %var_2_1416, i8* %var_2_23, align 1
; Matched:%var_2_3558:  %var_2_3558 = xor i32 %var_2_3549, %var_2_3548
; %var_2_1417 = xor i32 %var_2_1408, %var_2_1407
; Matched:%var_2_3559:  %var_2_3559 = lshr i32 %var_2_3558, 4
; %var_2_1418 = lshr i32 %var_2_1417, 4
; Matched:%var_2_3560:  %var_2_3560 = trunc i32 %var_2_3559 to i8
; %var_2_1419 = trunc i32 %var_2_1418 to i8
; Matched:%var_2_3561:  %var_2_3561 = and i8 %var_2_3560, 1
; %var_2_1420 = and i8 %var_2_1419, 1
; Matched:\<badref\>:  store i8 %var_2_3561, i8* %var_2_27, align 1
; store i8 %var_2_1420, i8* %var_2_29, align 1
; Matched:%var_2_3562:  %var_2_3562 = icmp eq i32 %var_2_3549, 0
; %var_2_1421 = icmp eq i32 %var_2_1408, 0
; Matched:%var_2_3563:  %var_2_3563 = zext i1 %var_2_3562 to i8
; %var_2_1422 = zext i1 %var_2_1421 to i8
; Matched:\<badref\>:  store i8 %var_2_3563, i8* %var_2_30, align 1
; store i8 %var_2_1422, i8* %var_2_32, align 1
; Matched:%var_2_3564:  %var_2_3564 = lshr i32 %var_2_3549, 31
; %var_2_1423 = lshr i32 %var_2_1408, 31
; Matched:%var_2_3565:  %var_2_3565 = trunc i32 %var_2_3564 to i8
; %var_2_1424 = trunc i32 %var_2_1423 to i8
; Matched:\<badref\>:  store i8 %var_2_3565, i8* %var_2_33, align 1
; store i8 %var_2_1424, i8* %var_2_35, align 1
; Matched:%var_2_3566:  %var_2_3566 = lshr i32 %var_2_3548, 31
; %var_2_1425 = lshr i32 %var_2_1407, 31
; Matched:%var_2_3567:  %var_2_3567 = xor i32 %var_2_3564, %var_2_3566
; %var_2_1426 = xor i32 %var_2_1423, %var_2_1425
; Matched:%var_2_3568:  %var_2_3568 = add nuw nsw i32 %var_2_3567, %var_2_3564
; %var_2_1427 = add nuw nsw i32 %var_2_1426, %var_2_1423
; Matched:%var_2_3569:  %var_2_3569 = icmp eq i32 %var_2_3568, 2
; %var_2_1428 = icmp eq i32 %var_2_1427, 2
; Matched:%var_2_3570:  %var_2_3570 = zext i1 %var_2_3569 to i8
; %var_2_1429 = zext i1 %var_2_1428 to i8
; Matched:\<badref\>:  store i8 %var_2_3570, i8* %var_2_39, align 1
; store i8 %var_2_1429, i8* %var_2_41, align 1
; Matched:%var_2_3571:  %var_2_3571 = sext i32 %var_2_3549 to i64
; %var_2_1430 = sext i32 %var_2_1408 to i64
; Matched:\<badref\>:  store i64 %var_2_3571, i64* %RDX.i2239, align 8
; store i64 %var_2_1430, i64* %RDX, align 8
; Matched:%var_2_3572:  %var_2_3572 = shl nsw i64 %var_2_3571, 3
; %var_2_1431 = shl nsw i64 %var_2_1430, 3
; Matched:%var_2_3573:  %var_2_3573 = add i64 %var_2_3544, %var_2_3572
; %var_2_1432 = add i64 %var_2_1403, %var_2_1431
; Matched:%var_2_1514:  %var_2_1514 = add i64 %var_2_1480, 18
; %var_2_1433 = add i64 %var_2_1400, 18
; Matched:\<badref\>:  store i64 %var_2_1514, i64* %var_2_3, align 8
; store i64 %var_2_1433, i64* %PC, align 8
; Matched:%var_2_3575:  %var_2_3575 = inttoptr i64 %var_2_3573 to i64*
; %var_2_1434 = inttoptr i64 %var_2_1432 to i64*
; Matched:%var_2_3576:  %var_2_3576 = load i64, i64* %var_2_3575, align 8
; %var_2_1435 = load i64, i64* %var_2_1434, align 8
; Matched:\<badref\>:  store i64 %var_2_3576, i64* %var_2_1054, align 1
; store i64 %var_2_1435, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_3577:  %var_2_3577 = add i64 %var_2_3539, -80
; %var_2_1436 = add i64 %var_2_1398, -80
; Matched:%var_2_4463:  %var_2_4463 = add i64 %var_2_4446, 23
; %var_2_1437 = add i64 %var_2_1400, 23
; Matched:\<badref\>:  store i64 %var_2_893, i64* %var_2_3, align 8
; store i64 %var_2_1437, i64* %PC, align 8
; Matched:%var_2_3579:  %var_2_3579 = inttoptr i64 %var_2_3577 to i64*
; %var_2_1438 = inttoptr i64 %var_2_1436 to i64*
; Matched:\<badref\>:  store i64 %var_2_3576, i64* %var_2_3579, align 8
; store i64 %var_2_1435, i64* %var_2_1438, align 8
; Matched:%var_2_2346:  %var_2_2346 = load i64, i64* %RBP.i, align 8
; %var_2_1439 = load i64, i64* %RBP, align 8
; Matched:%var_2_2347:  %var_2_2347 = add i64 %var_2_2346, -72
; %var_2_1440 = add i64 %var_2_1439, -72
%var_2_1441 = load i64, i64* %PC, align 8
; Matched:%var_2_781:  %var_2_781 = add i64 %var_2_780, 5
; %var_2_1442 = add i64 %var_2_1441, 5
; Matched:\<badref\>:  store i64 %var_2_781, i64* %var_2_3, align 8
; store i64 %var_2_1442, i64* %PC, align 8
; Matched:%var_2_2350:  %var_2_2350 = inttoptr i64 %var_2_2347 to i64*
; %var_2_1443 = inttoptr i64 %var_2_1440 to i64*
; Matched:%var_2_2351:  %var_2_2351 = load i64, i64* %var_2_2350, align 8
; %var_2_1444 = load i64, i64* %var_2_1443, align 8
; Matched:\<badref\>:  store i64 %var_2_2351, i64* %var_2_1054, align 1
; store i64 %var_2_1444, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
%var_2_1445 = load <2 x i32>, <2 x i32>* %var_2_1348, align 1
%var_2_1446 = load <2 x i32>, <2 x i32>* %var_2_1349, align 1
%var_2_1447 = extractelement <2 x i32> %var_2_1445, i32 0
; Matched:\<badref\>:  store i32 %var_2_2354, i32* %var_2_2121, align 1
; store i32 %var_2_1447, i32* %var_2_1350, align 1
%var_2_1448 = extractelement <2 x i32> %var_2_1445, i32 1
; Matched:\<badref\>:  store i32 %var_2_3589, i32* %var_2_2123, align 1
; store i32 %var_2_1448, i32* %var_2_1352, align 1
%var_2_1449 = extractelement <2 x i32> %var_2_1446, i32 0
; Matched:\<badref\>:  store i32 %var_2_2356, i32* %var_2_2125, align 1
; store i32 %var_2_1449, i32* %var_2_1354, align 1
%var_2_1450 = extractelement <2 x i32> %var_2_1446, i32 1
; Matched:\<badref\>:  store i32 %var_2_2357, i32* %var_2_2127, align 1
; store i32 %var_2_1450, i32* %var_2_1356, align 1
; Matched:%var_2_3592:  %var_2_3592 = add i64 %var_2_3580, -88
; %var_2_1451 = add i64 %var_2_1439, -88
; Matched:%var_2_3026:  %var_2_3026 = add i64 %var_2_3021, 13
; %var_2_1452 = add i64 %var_2_1441, 13
; Matched:\<badref\>:  store i64 %var_2_3026, i64* %var_2_3, align 8
; store i64 %var_2_1452, i64* %PC, align 8
; Matched:%var_2_3594:  %var_2_3594 = load double, double* %var_2_2128, align 1
; %var_2_1453 = load double, double* %var_2_1357, align 1
; Matched:%var_2_3595:  %var_2_3595 = inttoptr i64 %var_2_3592 to double*
; %var_2_1454 = inttoptr i64 %var_2_1451 to double*
; Matched:%var_2_3596:  %var_2_3596 = load double, double* %var_2_3595, align 8
; %var_2_1455 = load double, double* %var_2_1454, align 8
; Matched:%var_2_3597:  %var_2_3597 = fmul double %var_2_3594, %var_2_3596
; %var_2_1456 = fmul double %var_2_1453, %var_2_1455
; Matched:\<badref\>:  store double %var_2_3597, double* %var_2_2128, align 1
; store double %var_2_1456, double* %var_2_1357, align 1
; Matched:%var_2_3598:  %var_2_3598 = add i64 %var_2_3580, -80
; %var_2_1457 = add i64 %var_2_1439, -80
; Matched:%var_2_2749:  %var_2_2749 = add i64 %var_2_2715, 18
; %var_2_1458 = add i64 %var_2_1441, 18
; Matched:\<badref\>:  store i64 %var_2_2975, i64* %var_2_3, align 8
; store i64 %var_2_1458, i64* %PC, align 8
; Matched:%var_2_3600:  %var_2_3600 = inttoptr i64 %var_2_3598 to double*
; %var_2_1459 = inttoptr i64 %var_2_1457 to double*
; Matched:%var_2_3601:  %var_2_3601 = load double, double* %var_2_3600, align 8
; %var_2_1460 = load double, double* %var_2_1459, align 8
; Matched:%var_2_3602:  %var_2_3602 = fmul double %var_2_3597, %var_2_3601
; %var_2_1461 = fmul double %var_2_1456, %var_2_1460
; Matched:\<badref\>:  store double %var_2_3602, double* %var_2_2128, align 1
; store double %var_2_1461, double* %var_2_1357, align 1
; Matched:%var_2_3603:  %var_2_3603 = bitcast i64 %var_2_3585 to double
; %var_2_1462 = bitcast i64 %var_2_1444 to double
; Matched:%var_2_3604:  %var_2_3604 = fsub double %var_2_3603, %var_2_3602
; %var_2_1463 = fsub double %var_2_1462, %var_2_1461
; Matched:\<badref\>:  store double %var_2_3604, double* %var_2_1053, align 1
; store double %var_2_1463, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_3605:  %var_2_3605 = add i64 %var_2_3580, -104
; %var_2_1464 = add i64 %var_2_1439, -104
; Matched:%var_2_1870:  %var_2_1870 = add i64 %var_2_1849, 27
; %var_2_1465 = add i64 %var_2_1441, 27
; Matched:\<badref\>:  store i64 %var_2_2372, i64* %var_2_3, align 8
; store i64 %var_2_1465, i64* %PC, align 8
; Matched:%var_2_3607:  %var_2_3607 = inttoptr i64 %var_2_3605 to double*
; %var_2_1466 = inttoptr i64 %var_2_1464 to double*
; Matched:\<badref\>:  store double %var_2_3604, double* %var_2_3607, align 8
; store double %var_2_1463, double* %var_2_1466, align 8
; Matched:%var_2_3608:  %var_2_3608 = load i64, i64* %RBP.i, align 8
; %var_2_1467 = load i64, i64* %RBP, align 8
; Matched:%var_2_3609:  %var_2_3609 = add i64 %var_2_3608, -88
; %var_2_1468 = add i64 %var_2_1467, -88
%var_2_1469 = load i64, i64* %PC, align 8
; Matched:%var_2_708:  %var_2_708 = add i64 %var_2_707, 5
; %var_2_1470 = add i64 %var_2_1469, 5
; Matched:\<badref\>:  store i64 %var_2_708, i64* %var_2_3, align 8
; store i64 %var_2_1470, i64* %PC, align 8
; Matched:%var_2_3612:  %var_2_3612 = load double, double* %var_2_1037, align 1
; %var_2_1471 = load double, double* %var_2_93, align 1
; Matched:%var_2_3613:  %var_2_3613 = inttoptr i64 %var_2_3609 to double*
; %var_2_1472 = inttoptr i64 %var_2_1468 to double*
; Matched:%var_2_3614:  %var_2_3614 = load double, double* %var_2_3613, align 8
; %var_2_1473 = load double, double* %var_2_1472, align 8
; Matched:%var_2_3615:  %var_2_3615 = fmul double %var_2_3612, %var_2_3614
; %var_2_1474 = fmul double %var_2_1471, %var_2_1473
; Matched:\<badref\>:  store double %var_2_3615, double* %var_2_1037, align 1
; store double %var_2_1474, double* %var_2_93, align 1
; Matched:%var_2_3616:  %var_2_3616 = add i64 %var_2_3608, -72
; %var_2_1475 = add i64 %var_2_1467, -72
; Matched:%var_2_4587:  %var_2_4587 = add i64 %var_2_4582, 10
; %var_2_1476 = add i64 %var_2_1469, 10
; Matched:\<badref\>:  store i64 %var_2_3163, i64* %var_2_3, align 8
; store i64 %var_2_1476, i64* %PC, align 8
; Matched:%var_2_3618:  %var_2_3618 = inttoptr i64 %var_2_3616 to double*
; %var_2_1477 = inttoptr i64 %var_2_1475 to double*
; Matched:%var_2_3619:  %var_2_3619 = load double, double* %var_2_3618, align 8
; %var_2_1478 = load double, double* %var_2_1477, align 8
; Matched:%var_2_3620:  %var_2_3620 = fmul double %var_2_3615, %var_2_3619
; %var_2_1479 = fmul double %var_2_1474, %var_2_1478
; Matched:\<badref\>:  store double %var_2_3620, double* %var_2_1037, align 1
; store double %var_2_1479, double* %var_2_93, align 1
; Matched:%var_2_3621:  %var_2_3621 = add i64 %var_2_3608, -80
; %var_2_1480 = add i64 %var_2_1467, -80
; Matched:%var_2_3258:  %var_2_3258 = add i64 %var_2_3247, 15
; %var_2_1481 = add i64 %var_2_1469, 15
; Matched:\<badref\>:  store i64 %var_2_3258, i64* %var_2_3, align 8
; store i64 %var_2_1481, i64* %PC, align 8
; Matched:%var_2_3623:  %var_2_3623 = inttoptr i64 %var_2_3621 to double*
; %var_2_1482 = inttoptr i64 %var_2_1480 to double*
; Matched:%var_2_3624:  %var_2_3624 = load double, double* %var_2_3623, align 8
; %var_2_1483 = load double, double* %var_2_1482, align 8
; Matched:%var_2_3625:  %var_2_3625 = fsub double %var_2_3620, %var_2_3624
; %var_2_1484 = fsub double %var_2_1479, %var_2_1483
; Matched:\<badref\>:  store double %var_2_3625, double* %var_2_1037, align 1
; store double %var_2_1484, double* %var_2_93, align 1
; Matched:%var_2_3626:  %var_2_3626 = add i64 %var_2_3608, -112
; %var_2_1485 = add i64 %var_2_1467, -112
; Matched:%var_2_4597:  %var_2_4597 = add i64 %var_2_4582, 20
; %var_2_1486 = add i64 %var_2_1469, 20
; Matched:\<badref\>:  store i64 %var_2_4597, i64* %var_2_3, align 8
; store i64 %var_2_1486, i64* %PC, align 8
; Matched:%var_2_3628:  %var_2_3628 = inttoptr i64 %var_2_3626 to double*
; %var_2_1487 = inttoptr i64 %var_2_1485 to double*
; Matched:\<badref\>:  store double %var_2_3625, double* %var_2_3628, align 8
; store double %var_2_1484, double* %var_2_1487, align 8
; Matched:%var_2_3629:  %var_2_3629 = load i64, i64* %RBP.i, align 8
; %var_2_1488 = load i64, i64* %RBP, align 8
; Matched:%var_2_3630:  %var_2_3630 = add i64 %var_2_3629, -44
; %var_2_1489 = add i64 %var_2_1488, -44
%var_2_1490 = load i64, i64* %PC, align 8
; Matched:%var_2_2201:  %var_2_2201 = add i64 %var_2_2200, 3
; %var_2_1491 = add i64 %var_2_1490, 3
; Matched:\<badref\>:  store i64 %var_2_2110, i64* %var_2_3, align 8
; store i64 %var_2_1491, i64* %PC, align 8
; Matched:%var_2_3633:  %var_2_3633 = inttoptr i64 %var_2_3630 to i32*
; %var_2_1492 = inttoptr i64 %var_2_1489 to i32*
; Matched:%var_2_3634:  %var_2_3634 = load i32, i32* %var_2_3633, align 4
; %var_2_1493 = load i32, i32* %var_2_1492, align 4
; Matched:%var_2_3635:  %var_2_3635 = zext i32 %var_2_3634 to i64
; %var_2_1494 = zext i32 %var_2_1493 to i64
; Matched:\<badref\>:  store i64 %var_2_3635, i64* %RCX.i2236, align 8
; store i64 %var_2_1494, i64* %RCX, align 8
; Matched:%var_2_3636:  %var_2_3636 = add i64 %var_2_3629, -56
; %var_2_1495 = add i64 %var_2_1488, -56
; Matched:%var_2_2493:  %var_2_2493 = add i64 %var_2_2487, 6
; %var_2_1496 = add i64 %var_2_1490, 6
; Matched:\<badref\>:  store i64 %var_2_1145, i64* %var_2_3, align 8
; store i64 %var_2_1496, i64* %PC, align 8
; Matched:%var_2_3638:  %var_2_3638 = inttoptr i64 %var_2_3636 to i32*
; %var_2_1497 = inttoptr i64 %var_2_1495 to i32*
; Matched:%var_2_3639:  %var_2_3639 = load i32, i32* %var_2_3638, align 4
; %var_2_1498 = load i32, i32* %var_2_1497, align 4
; Matched:%var_2_3640:  %var_2_3640 = add i32 %var_2_3639, %var_2_3634
; %var_2_1499 = add i32 %var_2_1498, %var_2_1493
; Matched:%var_2_3641:  %var_2_3641 = zext i32 %var_2_3640 to i64
; %var_2_1500 = zext i32 %var_2_1499 to i64
; Matched:\<badref\>:  store i64 %var_2_3641, i64* %RCX.i2236, align 8
; store i64 %var_2_1500, i64* %RCX, align 8
; Matched:%var_2_3642:  %var_2_3642 = icmp ult i32 %var_2_3640, %var_2_3634
; %var_2_1501 = icmp ult i32 %var_2_1499, %var_2_1493
; Matched:%var_2_3643:  %var_2_3643 = icmp ult i32 %var_2_3640, %var_2_3639
; %var_2_1502 = icmp ult i32 %var_2_1499, %var_2_1498
; Matched:%var_2_3644:  %var_2_3644 = or i1 %var_2_3642, %var_2_3643
; %var_2_1503 = or i1 %var_2_1501, %var_2_1502
; Matched:%var_2_3645:  %var_2_3645 = zext i1 %var_2_3644 to i8
; %var_2_1504 = zext i1 %var_2_1503 to i8
; Matched:\<badref\>:  store i8 %var_2_3645, i8* %var_2_14, align 1
; store i8 %var_2_1504, i8* %var_2_16, align 1
; Matched:%var_2_3646:  %var_2_3646 = and i32 %var_2_3640, 255
; %var_2_1505 = and i32 %var_2_1499, 255
; Matched:%var_2_3647:  %var_2_3647 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3646)
; %var_2_1506 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1505) #14
; Matched:%var_2_3648:  %var_2_3648 = trunc i32 %var_2_3647 to i8
; %var_2_1507 = trunc i32 %var_2_1506 to i8
; Matched:%var_2_3649:  %var_2_3649 = and i8 %var_2_3648, 1
; %var_2_1508 = and i8 %var_2_1507, 1
; Matched:%var_2_3650:  %var_2_3650 = xor i8 %var_2_3649, 1
; %var_2_1509 = xor i8 %var_2_1508, 1
; Matched:\<badref\>:  store i8 %var_2_3650, i8* %var_2_21, align 1
; store i8 %var_2_1509, i8* %var_2_23, align 1
; Matched:%var_2_3651:  %var_2_3651 = xor i32 %var_2_3639, %var_2_3634
; %var_2_1510 = xor i32 %var_2_1498, %var_2_1493
; Matched:%var_2_3652:  %var_2_3652 = xor i32 %var_2_3651, %var_2_3640
; %var_2_1511 = xor i32 %var_2_1510, %var_2_1499
; Matched:%var_2_3653:  %var_2_3653 = lshr i32 %var_2_3652, 4
; %var_2_1512 = lshr i32 %var_2_1511, 4
; Matched:%var_2_3654:  %var_2_3654 = trunc i32 %var_2_3653 to i8
; %var_2_1513 = trunc i32 %var_2_1512 to i8
; Matched:%var_2_3655:  %var_2_3655 = and i8 %var_2_3654, 1
; %var_2_1514 = and i8 %var_2_1513, 1
; Matched:\<badref\>:  store i8 %var_2_3655, i8* %var_2_27, align 1
; store i8 %var_2_1514, i8* %var_2_29, align 1
; Matched:%var_2_3656:  %var_2_3656 = icmp eq i32 %var_2_3640, 0
; %var_2_1515 = icmp eq i32 %var_2_1499, 0
; Matched:%var_2_3657:  %var_2_3657 = zext i1 %var_2_3656 to i8
; %var_2_1516 = zext i1 %var_2_1515 to i8
; Matched:\<badref\>:  store i8 %var_2_3657, i8* %var_2_30, align 1
; store i8 %var_2_1516, i8* %var_2_32, align 1
; Matched:%var_2_3658:  %var_2_3658 = lshr i32 %var_2_3640, 31
; %var_2_1517 = lshr i32 %var_2_1499, 31
; Matched:%var_2_3659:  %var_2_3659 = trunc i32 %var_2_3658 to i8
; %var_2_1518 = trunc i32 %var_2_1517 to i8
; Matched:\<badref\>:  store i8 %var_2_3659, i8* %var_2_33, align 1
; store i8 %var_2_1518, i8* %var_2_35, align 1
; Matched:%var_2_3660:  %var_2_3660 = lshr i32 %var_2_3634, 31
; %var_2_1519 = lshr i32 %var_2_1493, 31
; Matched:%var_2_3661:  %var_2_3661 = lshr i32 %var_2_3639, 31
; %var_2_1520 = lshr i32 %var_2_1498, 31
; Matched:%var_2_3662:  %var_2_3662 = xor i32 %var_2_3658, %var_2_3660
; %var_2_1521 = xor i32 %var_2_1517, %var_2_1519
; Matched:%var_2_3663:  %var_2_3663 = xor i32 %var_2_3658, %var_2_3661
; %var_2_1522 = xor i32 %var_2_1517, %var_2_1520
; Matched:%var_2_3664:  %var_2_3664 = add nuw nsw i32 %var_2_3662, %var_2_3663
; %var_2_1523 = add nuw nsw i32 %var_2_1521, %var_2_1522
; Matched:%var_2_3665:  %var_2_3665 = icmp eq i32 %var_2_3664, 2
; %var_2_1524 = icmp eq i32 %var_2_1523, 2
; Matched:%var_2_3666:  %var_2_3666 = zext i1 %var_2_3665 to i8
; %var_2_1525 = zext i1 %var_2_1524 to i8
; Matched:\<badref\>:  store i8 %var_2_3666, i8* %var_2_39, align 1
; store i8 %var_2_1525, i8* %var_2_41, align 1
; Matched:%var_2_3667:  %var_2_3667 = add i64 %var_2_3629, -28
; %var_2_1526 = add i64 %var_2_1488, -28
%var_2_1527 = add i64 %var_2_1490, 9
store i64 %var_2_1527, i64* %PC, align 8
; Matched:%var_2_3669:  %var_2_3669 = inttoptr i64 %var_2_3667 to i32*
; %var_2_1528 = inttoptr i64 %var_2_1526 to i32*
; Matched:\<badref\>:  store i32 %var_2_3640, i32* %var_2_3669, align 4
; store i32 %var_2_1499, i32* %var_2_1528, align 4
; Matched:  %.pre26 = load i64, i64* %var_2_3, align 8
; %.pre26 = load i64, i64* %PC, align 8
  br label %block_403cc0

block_403ffb:                                     ; preds = %block_403cc0
; Matched:%var_2_4795:  %var_2_4795 = load i64, i64* %RBP.i, align 8
; %var_2_1529 = load i64, i64* %RBP, align 8
; Matched:%var_2_2108:  %var_2_2108 = add i64 %var_2_2107, -60
; %var_2_1530 = add i64 %var_2_1529, -60
; Matched:%var_2_4797:  %var_2_4797 = add i64 %var_2_3721, 8
; %var_2_1531 = add i64 %var_2_1678, 8
; Matched:\<badref\>:  store i64 %var_2_4797, i64* %var_2_3, align 8
; store i64 %var_2_1531, i64* %PC, align 8
; Matched:%var_2_2111:  %var_2_2111 = inttoptr i64 %var_2_2108 to i32*
; %var_2_1532 = inttoptr i64 %var_2_1530 to i32*
; Matched:%var_2_2112:  %var_2_2112 = load i32, i32* %var_2_2111, align 4
; %var_2_1533 = load i32, i32* %var_2_1532, align 4
; Matched:%var_2_2113:  %var_2_2113 = zext i32 %var_2_2112 to i64
; %var_2_1534 = zext i32 %var_2_1533 to i64
; Matched:\<badref\>:  store i64 %var_2_4800, i64* %RAX.i2224, align 8
; store i64 %var_2_1534, i64* %RAX, align 8
; Matched:%var_2_4801:  %var_2_4801 = add i64 %var_2_4795, -44
; %var_2_1535 = add i64 %var_2_1529, -44
; Matched:%var_2_4802:  %var_2_4802 = add i64 %var_2_3721, 11
; %var_2_1536 = add i64 %var_2_1678, 11
; Matched:\<badref\>:  store i64 %var_2_4802, i64* %var_2_3, align 8
; store i64 %var_2_1536, i64* %PC, align 8
; Matched:%var_2_4803:  %var_2_4803 = inttoptr i64 %var_2_4801 to i32*
; %var_2_1537 = inttoptr i64 %var_2_1535 to i32*
; Matched:%var_2_4804:  %var_2_4804 = load i32, i32* %var_2_4803, align 4
; %var_2_1538 = load i32, i32* %var_2_1537, align 4
; Matched:%var_2_4805:  %var_2_4805 = add i32 %var_2_4804, %var_2_4799
; %var_2_1539 = add i32 %var_2_1538, %var_2_1533
; Matched:%var_2_4806:  %var_2_4806 = zext i32 %var_2_4805 to i64
; %var_2_1540 = zext i32 %var_2_1539 to i64
; Matched:\<badref\>:  store i64 %var_2_4806, i64* %RAX.i2224, align 8
; store i64 %var_2_1540, i64* %RAX, align 8
; Matched:%var_2_4807:  %var_2_4807 = icmp ult i32 %var_2_4805, %var_2_4799
; %var_2_1541 = icmp ult i32 %var_2_1539, %var_2_1533
; Matched:%var_2_4808:  %var_2_4808 = icmp ult i32 %var_2_4805, %var_2_4804
; %var_2_1542 = icmp ult i32 %var_2_1539, %var_2_1538
; Matched:%var_2_4809:  %var_2_4809 = or i1 %var_2_4807, %var_2_4808
; %var_2_1543 = or i1 %var_2_1541, %var_2_1542
; Matched:%var_2_4810:  %var_2_4810 = zext i1 %var_2_4809 to i8
; %var_2_1544 = zext i1 %var_2_1543 to i8
; Matched:\<badref\>:  store i8 %var_2_4810, i8* %var_2_14, align 1
; store i8 %var_2_1544, i8* %var_2_16, align 1
; Matched:%var_2_4811:  %var_2_4811 = and i32 %var_2_4805, 255
; %var_2_1545 = and i32 %var_2_1539, 255
; Matched:%var_2_4812:  %var_2_4812 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4811)
; %var_2_1546 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1545) #14
; Matched:%var_2_4813:  %var_2_4813 = trunc i32 %var_2_4812 to i8
; %var_2_1547 = trunc i32 %var_2_1546 to i8
; Matched:%var_2_4814:  %var_2_4814 = and i8 %var_2_4813, 1
; %var_2_1548 = and i8 %var_2_1547, 1
; Matched:%var_2_4815:  %var_2_4815 = xor i8 %var_2_4814, 1
; %var_2_1549 = xor i8 %var_2_1548, 1
; Matched:\<badref\>:  store i8 %var_2_4815, i8* %var_2_21, align 1
; store i8 %var_2_1549, i8* %var_2_23, align 1
; Matched:%var_2_4816:  %var_2_4816 = xor i32 %var_2_4804, %var_2_4799
; %var_2_1550 = xor i32 %var_2_1538, %var_2_1533
; Matched:%var_2_4817:  %var_2_4817 = xor i32 %var_2_4816, %var_2_4805
; %var_2_1551 = xor i32 %var_2_1550, %var_2_1539
; Matched:%var_2_4818:  %var_2_4818 = lshr i32 %var_2_4817, 4
; %var_2_1552 = lshr i32 %var_2_1551, 4
; Matched:%var_2_4819:  %var_2_4819 = trunc i32 %var_2_4818 to i8
; %var_2_1553 = trunc i32 %var_2_1552 to i8
; Matched:%var_2_4820:  %var_2_4820 = and i8 %var_2_4819, 1
; %var_2_1554 = and i8 %var_2_1553, 1
; Matched:\<badref\>:  store i8 %var_2_4820, i8* %var_2_27, align 1
; store i8 %var_2_1554, i8* %var_2_29, align 1
; Matched:%var_2_4821:  %var_2_4821 = icmp eq i32 %var_2_4805, 0
; %var_2_1555 = icmp eq i32 %var_2_1539, 0
; Matched:%var_2_4822:  %var_2_4822 = zext i1 %var_2_4821 to i8
; %var_2_1556 = zext i1 %var_2_1555 to i8
; Matched:\<badref\>:  store i8 %var_2_4822, i8* %var_2_30, align 1
; store i8 %var_2_1556, i8* %var_2_32, align 1
; Matched:%var_2_4823:  %var_2_4823 = lshr i32 %var_2_4805, 31
; %var_2_1557 = lshr i32 %var_2_1539, 31
; Matched:%var_2_4824:  %var_2_4824 = trunc i32 %var_2_4823 to i8
; %var_2_1558 = trunc i32 %var_2_1557 to i8
; Matched:\<badref\>:  store i8 %var_2_4824, i8* %var_2_33, align 1
; store i8 %var_2_1558, i8* %var_2_35, align 1
; Matched:%var_2_4825:  %var_2_4825 = lshr i32 %var_2_4799, 31
; %var_2_1559 = lshr i32 %var_2_1533, 31
; Matched:%var_2_4826:  %var_2_4826 = lshr i32 %var_2_4804, 31
; %var_2_1560 = lshr i32 %var_2_1538, 31
; Matched:%var_2_4827:  %var_2_4827 = xor i32 %var_2_4823, %var_2_4825
; %var_2_1561 = xor i32 %var_2_1557, %var_2_1559
; Matched:%var_2_4828:  %var_2_4828 = xor i32 %var_2_4823, %var_2_4826
; %var_2_1562 = xor i32 %var_2_1557, %var_2_1560
; Matched:%var_2_4829:  %var_2_4829 = add nuw nsw i32 %var_2_4827, %var_2_4828
; %var_2_1563 = add nuw nsw i32 %var_2_1561, %var_2_1562
; Matched:%var_2_4830:  %var_2_4830 = icmp eq i32 %var_2_4829, 2
; %var_2_1564 = icmp eq i32 %var_2_1563, 2
; Matched:%var_2_4831:  %var_2_4831 = zext i1 %var_2_4830 to i8
; %var_2_1565 = zext i1 %var_2_1564 to i8
; Matched:\<badref\>:  store i8 %var_2_4831, i8* %var_2_39, align 1
; store i8 %var_2_1565, i8* %var_2_41, align 1
; Matched:%var_2_4832:  %var_2_4832 = add i64 %var_2_3721, 14
; %var_2_1566 = add i64 %var_2_1678, 14
; Matched:\<badref\>:  store i64 %var_2_4832, i64* %var_2_3, align 8
; store i64 %var_2_1566, i64* %PC, align 8
; Matched:\<badref\>:  store i32 %var_2_4805, i32* %var_2_4803, align 4
; store i32 %var_2_1539, i32* %var_2_1537, align 4
; Matched:%var_2_4833:  %var_2_4833 = load i64, i64* %var_2_3, align 8
; %var_2_1567 = load i64, i64* %PC, align 8
; Matched:%var_2_4834:  %var_2_4834 = add i64 %var_2_4833, -1910
; %var_2_1568 = add i64 %var_2_1567, -1910
; Matched:\<badref\>:  store i64 %var_2_4834, i64* %var_2_3, align 8
; store i64 %var_2_1568, i64* %PC, align 8
  br label %block_403893

block_40400e:                                     ; preds = %block_403893
; Matched:%var_2_4835:  %var_2_4835 = load i64, i64* %var_2_6, align 8
; %var_2_1569 = load i64, i64* %RSP, align 8
; Matched:%var_2_4836:  %var_2_4836 = add i64 %var_2_4835, 48
; %var_2_1570 = add i64 %var_2_1569, 48
; Matched:\<badref\>:  store i64 %var_2_4836, i64* %var_2_6, align 8
; store i64 %var_2_1570, i64* %RSP, align 8
; Matched:%var_2_4837:  %var_2_4837 = icmp ugt i64 %var_2_4835, -49
; %var_2_1571 = icmp ugt i64 %var_2_1569, -49
; Matched:%var_2_4838:  %var_2_4838 = zext i1 %var_2_4837 to i8
; %var_2_1572 = zext i1 %var_2_1571 to i8
; Matched:\<badref\>:  store i8 %var_2_4838, i8* %var_2_14, align 1
; store i8 %var_2_1572, i8* %var_2_16, align 1
; Matched:%var_2_4839:  %var_2_4839 = trunc i64 %var_2_4836 to i32
; %var_2_1573 = trunc i64 %var_2_1570 to i32
; Matched:%var_2_4840:  %var_2_4840 = and i32 %var_2_4839, 255
; %var_2_1574 = and i32 %var_2_1573, 255
; Matched:%var_2_4841:  %var_2_4841 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4840)
; %var_2_1575 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1574) #14
; Matched:%var_2_4842:  %var_2_4842 = trunc i32 %var_2_4841 to i8
; %var_2_1576 = trunc i32 %var_2_1575 to i8
; Matched:%var_2_4843:  %var_2_4843 = and i8 %var_2_4842, 1
; %var_2_1577 = and i8 %var_2_1576, 1
; Matched:%var_2_4844:  %var_2_4844 = xor i8 %var_2_4843, 1
; %var_2_1578 = xor i8 %var_2_1577, 1
; Matched:\<badref\>:  store i8 %var_2_4844, i8* %var_2_21, align 1
; store i8 %var_2_1578, i8* %var_2_23, align 1
; Matched:%var_2_4845:  %var_2_4845 = xor i64 %var_2_4835, 16
; %var_2_1579 = xor i64 %var_2_1569, 16
; Matched:%var_2_4846:  %var_2_4846 = xor i64 %var_2_4845, %var_2_4836
; %var_2_1580 = xor i64 %var_2_1579, %var_2_1570
; Matched:%var_2_4847:  %var_2_4847 = lshr i64 %var_2_4846, 4
; %var_2_1581 = lshr i64 %var_2_1580, 4
; Matched:%var_2_4848:  %var_2_4848 = trunc i64 %var_2_4847 to i8
; %var_2_1582 = trunc i64 %var_2_1581 to i8
; Matched:%var_2_4849:  %var_2_4849 = and i8 %var_2_4848, 1
; %var_2_1583 = and i8 %var_2_1582, 1
; Matched:\<badref\>:  store i8 %var_2_4849, i8* %var_2_27, align 1
; store i8 %var_2_1583, i8* %var_2_29, align 1
; Matched:%var_2_4850:  %var_2_4850 = icmp eq i64 %var_2_4836, 0
; %var_2_1584 = icmp eq i64 %var_2_1570, 0
; Matched:%var_2_4851:  %var_2_4851 = zext i1 %var_2_4850 to i8
; %var_2_1585 = zext i1 %var_2_1584 to i8
; Matched:\<badref\>:  store i8 %var_2_4851, i8* %var_2_30, align 1
; store i8 %var_2_1585, i8* %var_2_32, align 1
; Matched:%var_2_4852:  %var_2_4852 = lshr i64 %var_2_4836, 63
; %var_2_1586 = lshr i64 %var_2_1570, 63
; Matched:%var_2_4853:  %var_2_4853 = trunc i64 %var_2_4852 to i8
; %var_2_1587 = trunc i64 %var_2_1586 to i8
; Matched:\<badref\>:  store i8 %var_2_4853, i8* %var_2_33, align 1
; store i8 %var_2_1587, i8* %var_2_35, align 1
; Matched:%var_2_4854:  %var_2_4854 = lshr i64 %var_2_4835, 63
; %var_2_1588 = lshr i64 %var_2_1569, 63
; Matched:%var_2_4855:  %var_2_4855 = xor i64 %var_2_4852, %var_2_4854
; %var_2_1589 = xor i64 %var_2_1586, %var_2_1588
; Matched:%var_2_4856:  %var_2_4856 = add nuw nsw i64 %var_2_4855, %var_2_4852
; %var_2_1590 = add nuw nsw i64 %var_2_1589, %var_2_1586
; Matched:%var_2_4857:  %var_2_4857 = icmp eq i64 %var_2_4856, 2
; %var_2_1591 = icmp eq i64 %var_2_1590, 2
; Matched:%var_2_4858:  %var_2_4858 = zext i1 %var_2_4857 to i8
; %var_2_1592 = zext i1 %var_2_1591 to i8
; Matched:\<badref\>:  store i8 %var_2_4858, i8* %var_2_39, align 1
; store i8 %var_2_1592, i8* %var_2_41, align 1
; Matched:%var_2_4859:  %var_2_4859 = add i64 %var_2_2166, 5
; %var_2_1593 = add i64 %var_2_3719, 5
; Matched:\<badref\>:  store i64 %var_2_4859, i64* %var_2_3, align 8
; store i64 %var_2_1593, i64* %PC, align 8
; Matched:%var_2_4860:  %var_2_4860 = add i64 %var_2_4835, 56
; %var_2_1594 = add i64 %var_2_1569, 56
; Matched:%var_2_4861:  %var_2_4861 = inttoptr i64 %var_2_4836 to i64*
; %var_2_1595 = inttoptr i64 %var_2_1570 to i64*
; Matched:%var_2_4862:  %var_2_4862 = load i64, i64* %var_2_4861, align 8
; %var_2_1596 = load i64, i64* %var_2_1595, align 8
; Matched:\<badref\>:  store i64 %var_2_4862, i64* %RBP.i, align 8
; store i64 %var_2_1596, i64* %RBP, align 8
; Matched:\<badref\>:  store i64 %var_2_4860, i64* %var_2_6, align 8
; store i64 %var_2_1594, i64* %RSP, align 8
; Matched:%var_2_4863:  %var_2_4863 = add i64 %var_2_2166, 6
; %var_2_1597 = add i64 %var_2_3719, 6
; Matched:\<badref\>:  store i64 %var_2_4863, i64* %var_2_3, align 8
; store i64 %var_2_1597, i64* %PC, align 8
; Matched:%var_2_4864:  %var_2_4864 = inttoptr i64 %var_2_4860 to i64*
; %var_2_1598 = inttoptr i64 %var_2_1594 to i64*
; Matched:%var_2_4865:  %var_2_4865 = load i64, i64* %var_2_4864, align 8
; %var_2_1599 = load i64, i64* %var_2_1598, align 8
; Matched:\<badref\>:  store i64 %var_2_4865, i64* %var_2_3, align 8
; store i64 %var_2_1599, i64* %PC, align 8
; Matched:%var_2_4866:  %var_2_4866 = add i64 %var_2_4835, 64
; %var_2_1600 = add i64 %var_2_1569, 64
; Matched:\<badref\>:  store i64 %var_2_4866, i64* %var_2_6, align 8
; store i64 %var_2_1600, i64* %RSP, align 8
  ret %struct.Memory* %2

block_4035ad:                                     ; preds = %block_403356
; Matched:%var_2_2117:  %var_2_2117 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
; %var_2_1601 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
; Matched:%var_2_1028:  %var_2_1028 = add i64 %var_2_99, -24
; %var_2_1602 = add i64 %var_2_2753, -24
; Matched:%var_2_1029:  %var_2_1029 = add i64 %var_2_135, 4
; %var_2_1603 = add i64 %var_2_2789, 4
; Matched:\<badref\>:  store i64 %var_2_1029, i64* %var_2_3, align 8
; store i64 %var_2_1603, i64* %PC, align 8
; Matched:%var_2_1030:  %var_2_1030 = inttoptr i64 %var_2_1028 to i64*
; %var_2_1604 = inttoptr i64 %var_2_1602 to i64*
; Matched:%var_2_1031:  %var_2_1031 = load i64, i64* %var_2_1030, align 8
; %var_2_1605 = load i64, i64* %var_2_1604, align 8
; Matched:\<badref\>:  store i64 %var_2_3544, i64* %RAX.i2224, align 8
; store i64 %var_2_1605, i64* %RAX, align 8
; Matched:%var_2_1033:  %var_2_1033 = add i64 %var_2_1031, 16
; %var_2_1606 = add i64 %var_2_1605, 16
; Matched:%var_2_1034:  %var_2_1034 = add i64 %var_2_135, 9
; %var_2_1607 = add i64 %var_2_2789, 9
; Matched:\<badref\>:  store i64 %var_2_169, i64* %var_2_3, align 8
; store i64 %var_2_1607, i64* %PC, align 8
; Matched:%var_2_1035:  %var_2_1035 = inttoptr i64 %var_2_1033 to i64*
; %var_2_1608 = inttoptr i64 %var_2_1606 to i64*
; Matched:%var_2_1036:  %var_2_1036 = load i64, i64* %var_2_1035, align 8
; %var_2_1609 = load i64, i64* %var_2_1608, align 8
; Matched:\<badref\>:  store i64 %var_2_1036, i64* %var_2_1038, align 1
; store i64 %var_2_1609, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1039:  %var_2_1039 = add i64 %var_2_99, -72
; %var_2_1610 = add i64 %var_2_2753, -72
; Matched:%var_2_1040:  %var_2_1040 = add i64 %var_2_135, 14
; %var_2_1611 = add i64 %var_2_2789, 14
; Matched:\<badref\>:  store i64 %var_2_1040, i64* %var_2_3, align 8
; store i64 %var_2_1611, i64* %PC, align 8
; Matched:%var_2_1041:  %var_2_1041 = inttoptr i64 %var_2_1039 to i64*
; %var_2_1612 = inttoptr i64 %var_2_1610 to i64*
; Matched:\<badref\>:  store i64 %var_2_1036, i64* %var_2_1041, align 8
; store i64 %var_2_1609, i64* %var_2_1612, align 8
; Matched:%var_2_1042:  %var_2_1042 = load i64, i64* %RBP.i, align 8
; %var_2_1613 = load i64, i64* %RBP, align 8
; Matched:%var_2_1043:  %var_2_1043 = add i64 %var_2_1042, -56
; %var_2_1614 = add i64 %var_2_1613, -56
%var_2_1615 = load i64, i64* %PC, align 8
; Matched:%var_2_174:  %var_2_174 = add i64 %var_2_173, 3
; %var_2_1616 = add i64 %var_2_1615, 3
; Matched:\<badref\>:  store i64 %var_2_174, i64* %var_2_3, align 8
; store i64 %var_2_1616, i64* %PC, align 8
; Matched:%var_2_1046:  %var_2_1046 = inttoptr i64 %var_2_1043 to i32*
; %var_2_1617 = inttoptr i64 %var_2_1614 to i32*
; Matched:%var_2_1047:  %var_2_1047 = load i32, i32* %var_2_1046, align 4
; %var_2_1618 = load i32, i32* %var_2_1617, align 4
; Matched:%var_2_1048:  %var_2_1048 = zext i32 %var_2_1047 to i64
; %var_2_1619 = zext i32 %var_2_1618 to i64
; Matched:\<badref\>:  store i64 %var_2_1048, i64* %RCX.i2236, align 8
; store i64 %var_2_1619, i64* %RCX, align 8
; Matched:%var_2_1049:  %var_2_1049 = add i64 %var_2_1042, -28
; %var_2_1620 = add i64 %var_2_1613, -28
; Matched:%var_2_3811:  %var_2_3811 = add i64 %var_2_3805, 6
; %var_2_1621 = add i64 %var_2_1615, 6
; Matched:\<badref\>:  store i64 %var_2_3811, i64* %var_2_3, align 8
; store i64 %var_2_1621, i64* %PC, align 8
; Matched:%var_2_1051:  %var_2_1051 = inttoptr i64 %var_2_1049 to i32*
; %var_2_1622 = inttoptr i64 %var_2_1620 to i32*
; Matched:\<badref\>:  store i32 %var_2_1047, i32* %var_2_1051, align 4
; store i32 %var_2_1618, i32* %var_2_1622, align 4
; Matched:%var_2_1053:  %var_2_1053 = bitcast %union.VectorReg* %var_2_1052 to double*
; %var_2_1623 = bitcast %union.VectorReg* %var_2_6 to double*
; Matched:%var_2_1054:  %var_2_1054 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %var_2_1052, i64 0, i32 0, i32 0, i32 0, i64 0
; %var_2_1624 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %var_2_6, i64 0, i32 0, i32 0, i32 0, i64 0
; Matched:%var_2_1055:  %var_2_1055 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
; %var_2_1625 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
; Matched:%var_2_1056:  %var_2_1056 = bitcast i64* %var_2_1055 to double*
; %var_2_1626 = bitcast i64* %var_2_1625 to double*
; Matched:  %.pre23 = load i64, i64* %var_2_3, align 8
; %.pre23 = load i64, i64* %PC, align 8
  br label %block_4035c1

block_403cc0:                                     ; preds = %block_403cd6, %block_403c52
; Matched:%var_2_3670:  %var_2_3670 = phi i64 [ %var_2_4794, %block_403cd6 ], [ %.pre26, %block_.L_403c52 ]
; %var_2_1627 = phi i64 [ %var_2_2751, %block_403cd6 ], [ %.pre26, %block_403c52 ]
%var_2_1628 = load i64, i64* %RBP, align 8
%var_2_1629 = add i64 %var_2_1628, -28
; Matched:%var_2_3673:  %var_2_3673 = add i64 %var_2_3670, 3
; %var_2_1630 = add i64 %var_2_1627, 3
; Matched:\<badref\>:  store i64 %var_2_3673, i64* %var_2_3, align 8
; store i64 %var_2_1630, i64* %PC, align 8
%var_2_1631 = inttoptr i64 %var_2_1629 to i32*
%var_2_1632 = load i32, i32* %var_2_1631, align 4
; Matched:%var_2_2452:  %var_2_2452 = zext i32 %var_2_2451 to i64
; %var_2_1633 = zext i32 %var_2_1632 to i64
; Matched:\<badref\>:  store i64 %var_2_2452, i64* %RAX.i2224, align 8
; store i64 %var_2_1633, i64* %RAX, align 8
%var_2_1634 = add i64 %var_2_1628, -8
; Matched:%var_2_3678:  %var_2_3678 = add i64 %var_2_3670, 6
; %var_2_1635 = add i64 %var_2_1627, 6
; Matched:\<badref\>:  store i64 %var_2_3678, i64* %var_2_3, align 8
; store i64 %var_2_1635, i64* %PC, align 8
%var_2_1636 = inttoptr i64 %var_2_1634 to i32*
%var_2_1637 = load i32, i32* %var_2_1636, align 4
; Matched:%var_2_1068:  %var_2_1068 = zext i32 %var_2_1067 to i64
; %var_2_1638 = zext i32 %var_2_1637 to i64
; Matched:\<badref\>:  store i64 %var_2_1068, i64* %RCX.i2236, align 8
; store i64 %var_2_1638, i64* %RCX, align 8
%var_2_1639 = add i64 %var_2_1628, -44
; Matched:%var_2_3683:  %var_2_3683 = add i64 %var_2_3670, 9
; %var_2_1640 = add i64 %var_2_1627, 9
; Matched:\<badref\>:  store i64 %var_2_3683, i64* %var_2_3, align 8
; store i64 %var_2_1640, i64* %PC, align 8
%var_2_1641 = inttoptr i64 %var_2_1639 to i32*
%var_2_1642 = load i32, i32* %var_2_1641, align 4
; Matched:%var_2_3686:  %var_2_3686 = zext i32 %var_2_3685 to i64
; %var_2_1643 = zext i32 %var_2_1642 to i64
; Matched:\<badref\>:  store i64 %var_2_3686, i64* %RDX.i2239, align 8
; store i64 %var_2_1643, i64* %RDX, align 8
%var_2_1644 = add i64 %var_2_1628, -56
; Matched:%var_2_3688:  %var_2_3688 = add i64 %var_2_3670, 12
; %var_2_1645 = add i64 %var_2_1627, 12
; Matched:\<badref\>:  store i64 %var_2_3688, i64* %var_2_3, align 8
; store i64 %var_2_1645, i64* %PC, align 8
%var_2_1646 = inttoptr i64 %var_2_1644 to i32*
%var_2_1647 = load i32, i32* %var_2_1646, align 4
%var_2_1648 = add i32 %var_2_1647, %var_2_1642
; Matched:%var_2_3692:  %var_2_3692 = zext i32 %var_2_3691 to i64
; %var_2_1649 = zext i32 %var_2_1648 to i64
; Matched:\<badref\>:  store i64 %var_2_3692, i64* %RDX.i2239, align 8
; store i64 %var_2_1649, i64* %RDX, align 8
%var_2_1650 = add i32 %var_2_1648, %var_2_1637
; Matched:%var_2_3694:  %var_2_3694 = zext i32 %var_2_3693 to i64
; %var_2_1651 = zext i32 %var_2_1650 to i64
; Matched:\<badref\>:  store i64 %var_2_3694, i64* %RCX.i2236, align 8
; store i64 %var_2_1651, i64* %RCX, align 8
%var_2_1652 = lshr i32 %var_2_1650, 31
%var_2_1653 = sub i32 %var_2_1632, %var_2_1650
; Matched:%var_2_3697:  %var_2_3697 = icmp ult i32 %var_2_3675, %var_2_3693
; %var_2_1654 = icmp ult i32 %var_2_1632, %var_2_1650
; Matched:%var_2_3698:  %var_2_3698 = zext i1 %var_2_3697 to i8
; %var_2_1655 = zext i1 %var_2_1654 to i8
; Matched:\<badref\>:  store i8 %var_2_3698, i8* %var_2_14, align 1
; store i8 %var_2_1655, i8* %var_2_16, align 1
; Matched:%var_2_3699:  %var_2_3699 = and i32 %var_2_3696, 255
; %var_2_1656 = and i32 %var_2_1653, 255
; Matched:%var_2_3700:  %var_2_3700 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3699)
; %var_2_1657 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1656) #14
; Matched:%var_2_3701:  %var_2_3701 = trunc i32 %var_2_3700 to i8
; %var_2_1658 = trunc i32 %var_2_1657 to i8
; Matched:%var_2_3702:  %var_2_3702 = and i8 %var_2_3701, 1
; %var_2_1659 = and i8 %var_2_1658, 1
; Matched:%var_2_3703:  %var_2_3703 = xor i8 %var_2_3702, 1
; %var_2_1660 = xor i8 %var_2_1659, 1
; Matched:\<badref\>:  store i8 %var_2_3703, i8* %var_2_21, align 1
; store i8 %var_2_1660, i8* %var_2_23, align 1
; Matched:%var_2_3704:  %var_2_3704 = xor i32 %var_2_3693, %var_2_3675
; %var_2_1661 = xor i32 %var_2_1650, %var_2_1632
; Matched:%var_2_3705:  %var_2_3705 = xor i32 %var_2_3704, %var_2_3696
; %var_2_1662 = xor i32 %var_2_1661, %var_2_1653
; Matched:%var_2_3706:  %var_2_3706 = lshr i32 %var_2_3705, 4
; %var_2_1663 = lshr i32 %var_2_1662, 4
; Matched:%var_2_3707:  %var_2_3707 = trunc i32 %var_2_3706 to i8
; %var_2_1664 = trunc i32 %var_2_1663 to i8
; Matched:%var_2_3708:  %var_2_3708 = and i8 %var_2_3707, 1
; %var_2_1665 = and i8 %var_2_1664, 1
; Matched:\<badref\>:  store i8 %var_2_3708, i8* %var_2_27, align 1
; store i8 %var_2_1665, i8* %var_2_29, align 1
; Matched:%var_2_3709:  %var_2_3709 = icmp eq i32 %var_2_3696, 0
; %var_2_1666 = icmp eq i32 %var_2_1653, 0
; Matched:%var_2_3710:  %var_2_3710 = zext i1 %var_2_3709 to i8
; %var_2_1667 = zext i1 %var_2_1666 to i8
; Matched:\<badref\>:  store i8 %var_2_3710, i8* %var_2_30, align 1
; store i8 %var_2_1667, i8* %var_2_32, align 1
%var_2_1668 = lshr i32 %var_2_1653, 31
%var_2_1669 = trunc i32 %var_2_1668 to i8
; Matched:\<badref\>:  store i8 %var_2_3712, i8* %var_2_33, align 1
; store i8 %var_2_1669, i8* %var_2_35, align 1
%var_2_1670 = lshr i32 %var_2_1632, 31
%var_2_1671 = xor i32 %var_2_1652, %var_2_1670
%var_2_1672 = xor i32 %var_2_1668, %var_2_1670
%var_2_1673 = add nuw nsw i32 %var_2_1672, %var_2_1671
%var_2_1674 = icmp eq i32 %var_2_1673, 2
; Matched:%var_2_3718:  %var_2_3718 = zext i1 %var_2_3717 to i8
; %var_2_1675 = zext i1 %var_2_1674 to i8
; Matched:\<badref\>:  store i8 %var_2_3718, i8* %var_2_39, align 1
; store i8 %var_2_1675, i8* %var_2_41, align 1
%var_2_1676 = icmp ne i8 %var_2_1669, 0
%var_2_1677 = xor i1 %var_2_1676, %var_2_1674
; Matched:  %.v30 = select i1 %var_2_3720, i64 22, i64 827
; %.v30 = select i1 %var_2_1677, i64 22, i64 827
; Matched:%var_2_3721:  %var_2_3721 = add i64 %var_2_3670, %.v30
; %var_2_1678 = add i64 %var_2_1627, %.v30
; Matched:\<badref\>:  store i64 %var_2_3721, i64* %var_2_3, align 8
; store i64 %var_2_1678, i64* %PC, align 8
br i1 %var_2_1677, label %block_403cd6, label %block_403ffb

block_403cd6:                                     ; preds = %block_403cc0
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
%var_2_1679 = load i64, i64* %RBP, align 8
%var_2_1680 = add i64 %var_2_1679, -28
; Matched:%var_2_3724:  %var_2_3724 = add i64 %var_2_3721, 13
; %var_2_1681 = add i64 %var_2_1678, 13
; Matched:\<badref\>:  store i64 %var_2_3724, i64* %var_2_3, align 8
; store i64 %var_2_1681, i64* %PC, align 8
%var_2_1682 = inttoptr i64 %var_2_1680 to i32*
%var_2_1683 = load i32, i32* %var_2_1682, align 4
; Matched:%var_2_3727:  %var_2_3727 = zext i32 %var_2_3726 to i64
; %var_2_1684 = zext i32 %var_2_1683 to i64
; Matched:\<badref\>:  store i64 %var_2_3727, i64* %RCX.i2236, align 8
; store i64 %var_2_1684, i64* %RCX, align 8
%var_2_1685 = add i64 %var_2_1679, -8
; Matched:%var_2_3729:  %var_2_3729 = add i64 %var_2_3721, 16
; %var_2_1686 = add i64 %var_2_1678, 16
; Matched:\<badref\>:  store i64 %var_2_3729, i64* %var_2_3, align 8
; store i64 %var_2_1686, i64* %PC, align 8
%var_2_1687 = inttoptr i64 %var_2_1685 to i32*
%var_2_1688 = load i32, i32* %var_2_1687, align 4
%var_2_1689 = add i32 %var_2_1688, %var_2_1683
; Matched:%var_2_3733:  %var_2_3733 = zext i32 %var_2_3732 to i64
; %var_2_1690 = zext i32 %var_2_1689 to i64
; Matched:\<badref\>:  store i64 %var_2_3733, i64* %RCX.i2236, align 8
; store i64 %var_2_1690, i64* %RCX, align 8
; Matched:%var_2_1109:  %var_2_1109 = icmp ult i32 %var_2_1107, %var_2_1103
; %var_2_1691 = icmp ult i32 %var_2_1689, %var_2_1683
; Matched:%var_2_2458:  %var_2_2458 = icmp ult i32 %var_2_2455, %var_2_2454
; %var_2_1692 = icmp ult i32 %var_2_1689, %var_2_1688
; Matched:%var_2_3736:  %var_2_3736 = or i1 %var_2_3734, %var_2_3735
; %var_2_1693 = or i1 %var_2_1691, %var_2_1692
; Matched:%var_2_2460:  %var_2_2460 = zext i1 %var_2_2459 to i8
; %var_2_1694 = zext i1 %var_2_1693 to i8
; Matched:\<badref\>:  store i8 %var_2_2460, i8* %var_2_14, align 1
; store i8 %var_2_1694, i8* %var_2_16, align 1
; Matched:%var_2_2461:  %var_2_2461 = and i32 %var_2_2455, 255
; %var_2_1695 = and i32 %var_2_1689, 255
; Matched:%var_2_1114:  %var_2_1114 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1113)
; %var_2_1696 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1695) #14
; Matched:%var_2_1115:  %var_2_1115 = trunc i32 %var_2_1114 to i8
; %var_2_1697 = trunc i32 %var_2_1696 to i8
; Matched:%var_2_1116:  %var_2_1116 = and i8 %var_2_1115, 1
; %var_2_1698 = and i8 %var_2_1697, 1
; Matched:%var_2_2465:  %var_2_2465 = xor i8 %var_2_2464, 1
; %var_2_1699 = xor i8 %var_2_1698, 1
; Matched:\<badref\>:  store i8 %var_2_3742, i8* %var_2_21, align 1
; store i8 %var_2_1699, i8* %var_2_23, align 1
; Matched:%var_2_2466:  %var_2_2466 = xor i32 %var_2_2454, %var_2_2451
; %var_2_1700 = xor i32 %var_2_1688, %var_2_1683
; Matched:%var_2_2467:  %var_2_2467 = xor i32 %var_2_2466, %var_2_2455
; %var_2_1701 = xor i32 %var_2_1700, %var_2_1689
; Matched:%var_2_2468:  %var_2_2468 = lshr i32 %var_2_2467, 4
; %var_2_1702 = lshr i32 %var_2_1701, 4
; Matched:%var_2_1121:  %var_2_1121 = trunc i32 %var_2_1120 to i8
; %var_2_1703 = trunc i32 %var_2_1702 to i8
; Matched:%var_2_1122:  %var_2_1122 = and i8 %var_2_1121, 1
; %var_2_1704 = and i8 %var_2_1703, 1
; Matched:\<badref\>:  store i8 %var_2_1122, i8* %var_2_27, align 1
; store i8 %var_2_1704, i8* %var_2_29, align 1
; Matched:%var_2_2471:  %var_2_2471 = icmp eq i32 %var_2_2455, 0
; %var_2_1705 = icmp eq i32 %var_2_1689, 0
; Matched:%var_2_3749:  %var_2_3749 = zext i1 %var_2_3748 to i8
; %var_2_1706 = zext i1 %var_2_1705 to i8
; Matched:\<badref\>:  store i8 %var_2_2472, i8* %var_2_30, align 1
; store i8 %var_2_1706, i8* %var_2_32, align 1
; Matched:%var_2_2473:  %var_2_2473 = lshr i32 %var_2_2455, 31
; %var_2_1707 = lshr i32 %var_2_1689, 31
; Matched:%var_2_1126:  %var_2_1126 = trunc i32 %var_2_1125 to i8
; %var_2_1708 = trunc i32 %var_2_1707 to i8
; Matched:\<badref\>:  store i8 %var_2_1126, i8* %var_2_33, align 1
; store i8 %var_2_1708, i8* %var_2_35, align 1
; Matched:%var_2_1127:  %var_2_1127 = lshr i32 %var_2_1103, 31
; %var_2_1709 = lshr i32 %var_2_1683, 31
; Matched:%var_2_1128:  %var_2_1128 = lshr i32 %var_2_1106, 31
; %var_2_1710 = lshr i32 %var_2_1688, 31
; Matched:%var_2_1129:  %var_2_1129 = xor i32 %var_2_1125, %var_2_1127
; %var_2_1711 = xor i32 %var_2_1707, %var_2_1709
; Matched:%var_2_1130:  %var_2_1130 = xor i32 %var_2_1125, %var_2_1128
; %var_2_1712 = xor i32 %var_2_1707, %var_2_1710
; Matched:%var_2_1131:  %var_2_1131 = add nuw nsw i32 %var_2_1129, %var_2_1130
; %var_2_1713 = add nuw nsw i32 %var_2_1711, %var_2_1712
; Matched:%var_2_2480:  %var_2_2480 = icmp eq i32 %var_2_2479, 2
; %var_2_1714 = icmp eq i32 %var_2_1713, 2
; Matched:%var_2_1133:  %var_2_1133 = zext i1 %var_2_1132 to i8
; %var_2_1715 = zext i1 %var_2_1714 to i8
; Matched:\<badref\>:  store i8 %var_2_1133, i8* %var_2_39, align 1
; store i8 %var_2_1715, i8* %var_2_41, align 1
; Matched:%var_2_1134:  %var_2_1134 = add i64 %var_2_1058, -32
; %var_2_1716 = add i64 %var_2_1679, -32
; Matched:%var_2_3760:  %var_2_3760 = add i64 %var_2_3721, 19
; %var_2_1717 = add i64 %var_2_1678, 19
; Matched:\<badref\>:  store i64 %var_2_3760, i64* %var_2_3, align 8
; store i64 %var_2_1717, i64* %PC, align 8
; Matched:%var_2_1136:  %var_2_1136 = inttoptr i64 %var_2_1134 to i32*
; %var_2_1718 = inttoptr i64 %var_2_1716 to i32*
; Matched:\<badref\>:  store i32 %var_2_1107, i32* %var_2_1136, align 4
; store i32 %var_2_1689, i32* %var_2_1718, align 4
%var_2_1719 = load i64, i64* %RBP, align 8
%var_2_1720 = add i64 %var_2_1719, -32
%var_2_1721 = load i64, i64* %PC, align 8
; Matched:%var_2_3632:  %var_2_3632 = add i64 %var_2_3631, 3
; %var_2_1722 = add i64 %var_2_1721, 3
; Matched:\<badref\>:  store i64 %var_2_2201, i64* %var_2_3, align 8
; store i64 %var_2_1722, i64* %PC, align 8
%var_2_1723 = inttoptr i64 %var_2_1720 to i32*
%var_2_1724 = load i32, i32* %var_2_1723, align 4
; Matched:%var_2_3768:  %var_2_3768 = zext i32 %var_2_3767 to i64
; %var_2_1725 = zext i32 %var_2_1724 to i64
; Matched:\<badref\>:  store i64 %var_2_3768, i64* %RCX.i2236, align 8
; store i64 %var_2_1725, i64* %RCX, align 8
%var_2_1726 = add i64 %var_2_1719, -8
; Matched:%var_2_220:  %var_2_220 = add i64 %var_2_214, 6
; %var_2_1727 = add i64 %var_2_1721, 6
; Matched:\<badref\>:  store i64 %var_2_2493, i64* %var_2_3, align 8
; store i64 %var_2_1727, i64* %PC, align 8
%var_2_1728 = inttoptr i64 %var_2_1726 to i32*
%var_2_1729 = load i32, i32* %var_2_1728, align 4
%var_2_1730 = add i32 %var_2_1729, %var_2_1724
; Matched:%var_2_3774:  %var_2_3774 = zext i32 %var_2_3773 to i64
; %var_2_1731 = zext i32 %var_2_1730 to i64
; Matched:\<badref\>:  store i64 %var_2_3774, i64* %RCX.i2236, align 8
; store i64 %var_2_1731, i64* %RCX, align 8
; Matched:%var_2_1150:  %var_2_1150 = icmp ult i32 %var_2_1148, %var_2_1142
; %var_2_1732 = icmp ult i32 %var_2_1730, %var_2_1724
; Matched:%var_2_1151:  %var_2_1151 = icmp ult i32 %var_2_1148, %var_2_1147
; %var_2_1733 = icmp ult i32 %var_2_1730, %var_2_1729
; Matched:%var_2_1152:  %var_2_1152 = or i1 %var_2_1150, %var_2_1151
; %var_2_1734 = or i1 %var_2_1732, %var_2_1733
; Matched:%var_2_1153:  %var_2_1153 = zext i1 %var_2_1152 to i8
; %var_2_1735 = zext i1 %var_2_1734 to i8
; Matched:\<badref\>:  store i8 %var_2_1153, i8* %var_2_14, align 1
; store i8 %var_2_1735, i8* %var_2_16, align 1
; Matched:%var_2_1154:  %var_2_1154 = and i32 %var_2_1148, 255
; %var_2_1736 = and i32 %var_2_1730, 255
; Matched:%var_2_1155:  %var_2_1155 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1154)
; %var_2_1737 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1736) #14
; Matched:%var_2_2504:  %var_2_2504 = trunc i32 %var_2_2503 to i8
; %var_2_1738 = trunc i32 %var_2_1737 to i8
; Matched:%var_2_1157:  %var_2_1157 = and i8 %var_2_1156, 1
; %var_2_1739 = and i8 %var_2_1738, 1
; Matched:%var_2_1158:  %var_2_1158 = xor i8 %var_2_1157, 1
; %var_2_1740 = xor i8 %var_2_1739, 1
; Matched:\<badref\>:  store i8 %var_2_1158, i8* %var_2_21, align 1
; store i8 %var_2_1740, i8* %var_2_23, align 1
; Matched:%var_2_1159:  %var_2_1159 = xor i32 %var_2_1147, %var_2_1142
; %var_2_1741 = xor i32 %var_2_1729, %var_2_1724
; Matched:%var_2_1160:  %var_2_1160 = xor i32 %var_2_1159, %var_2_1148
; %var_2_1742 = xor i32 %var_2_1741, %var_2_1730
; Matched:%var_2_1161:  %var_2_1161 = lshr i32 %var_2_1160, 4
; %var_2_1743 = lshr i32 %var_2_1742, 4
; Matched:%var_2_1162:  %var_2_1162 = trunc i32 %var_2_1161 to i8
; %var_2_1744 = trunc i32 %var_2_1743 to i8
; Matched:%var_2_2511:  %var_2_2511 = and i8 %var_2_2510, 1
; %var_2_1745 = and i8 %var_2_1744, 1
; Matched:\<badref\>:  store i8 %var_2_1163, i8* %var_2_27, align 1
; store i8 %var_2_1745, i8* %var_2_29, align 1
; Matched:%var_2_1164:  %var_2_1164 = icmp eq i32 %var_2_1148, 0
; %var_2_1746 = icmp eq i32 %var_2_1730, 0
; Matched:%var_2_1165:  %var_2_1165 = zext i1 %var_2_1164 to i8
; %var_2_1747 = zext i1 %var_2_1746 to i8
; Matched:\<badref\>:  store i8 %var_2_1165, i8* %var_2_30, align 1
; store i8 %var_2_1747, i8* %var_2_32, align 1
; Matched:%var_2_1166:  %var_2_1166 = lshr i32 %var_2_1148, 31
; %var_2_1748 = lshr i32 %var_2_1730, 31
; Matched:%var_2_1167:  %var_2_1167 = trunc i32 %var_2_1166 to i8
; %var_2_1749 = trunc i32 %var_2_1748 to i8
; Matched:\<badref\>:  store i8 %var_2_1167, i8* %var_2_33, align 1
; store i8 %var_2_1749, i8* %var_2_35, align 1
; Matched:%var_2_2516:  %var_2_2516 = lshr i32 %var_2_2490, 31
; %var_2_1750 = lshr i32 %var_2_1724, 31
; Matched:%var_2_1169:  %var_2_1169 = lshr i32 %var_2_1147, 31
; %var_2_1751 = lshr i32 %var_2_1729, 31
; Matched:%var_2_1170:  %var_2_1170 = xor i32 %var_2_1166, %var_2_1168
; %var_2_1752 = xor i32 %var_2_1748, %var_2_1750
; Matched:%var_2_1171:  %var_2_1171 = xor i32 %var_2_1166, %var_2_1169
; %var_2_1753 = xor i32 %var_2_1748, %var_2_1751
; Matched:%var_2_1172:  %var_2_1172 = add nuw nsw i32 %var_2_1170, %var_2_1171
; %var_2_1754 = add nuw nsw i32 %var_2_1752, %var_2_1753
; Matched:%var_2_1173:  %var_2_1173 = icmp eq i32 %var_2_1172, 2
; %var_2_1755 = icmp eq i32 %var_2_1754, 2
; Matched:%var_2_1174:  %var_2_1174 = zext i1 %var_2_1173 to i8
; %var_2_1756 = zext i1 %var_2_1755 to i8
; Matched:\<badref\>:  store i8 %var_2_1174, i8* %var_2_39, align 1
; store i8 %var_2_1756, i8* %var_2_41, align 1
; Matched:%var_2_2523:  %var_2_2523 = add i64 %var_2_2485, -36
; %var_2_1757 = add i64 %var_2_1719, -36
%var_2_1758 = add i64 %var_2_1721, 9
store i64 %var_2_1758, i64* %PC, align 8
; Matched:%var_2_1177:  %var_2_1177 = inttoptr i64 %var_2_1175 to i32*
; %var_2_1759 = inttoptr i64 %var_2_1757 to i32*
; Matched:\<badref\>:  store i32 %var_2_1148, i32* %var_2_1177, align 4
; store i32 %var_2_1730, i32* %var_2_1759, align 4
%var_2_1760 = load i64, i64* %RBP, align 8
%var_2_1761 = add i64 %var_2_1760, -36
%var_2_1762 = load i64, i64* %PC, align 8
; Matched:%var_2_1000:  %var_2_1000 = add i64 %var_2_999, 3
; %var_2_1763 = add i64 %var_2_1762, 3
; Matched:\<badref\>:  store i64 %var_2_1000, i64* %var_2_3, align 8
; store i64 %var_2_1763, i64* %PC, align 8
%var_2_1764 = inttoptr i64 %var_2_1761 to i32*
%var_2_1765 = load i32, i32* %var_2_1764, align 4
; Matched:%var_2_3809:  %var_2_3809 = zext i32 %var_2_3808 to i64
; %var_2_1766 = zext i32 %var_2_1765 to i64
; Matched:\<badref\>:  store i64 %var_2_3809, i64* %RCX.i2236, align 8
; store i64 %var_2_1766, i64* %RCX, align 8
%var_2_1767 = add i64 %var_2_1760, -8
; Matched:%var_2_2534:  %var_2_2534 = add i64 %var_2_2528, 6
; %var_2_1768 = add i64 %var_2_1762, 6
; Matched:\<badref\>:  store i64 %var_2_2534, i64* %var_2_3, align 8
; store i64 %var_2_1768, i64* %PC, align 8
%var_2_1769 = inttoptr i64 %var_2_1767 to i32*
%var_2_1770 = load i32, i32* %var_2_1769, align 4
%var_2_1771 = add i32 %var_2_1770, %var_2_1765
; Matched:%var_2_3815:  %var_2_3815 = zext i32 %var_2_3814 to i64
; %var_2_1772 = zext i32 %var_2_1771 to i64
; Matched:\<badref\>:  store i64 %var_2_3815, i64* %RCX.i2236, align 8
; store i64 %var_2_1772, i64* %RCX, align 8
; Matched:%var_2_1191:  %var_2_1191 = icmp ult i32 %var_2_1189, %var_2_1183
; %var_2_1773 = icmp ult i32 %var_2_1771, %var_2_1765
; Matched:%var_2_2540:  %var_2_2540 = icmp ult i32 %var_2_2537, %var_2_2536
; %var_2_1774 = icmp ult i32 %var_2_1771, %var_2_1770
; Matched:%var_2_2541:  %var_2_2541 = or i1 %var_2_2539, %var_2_2540
; %var_2_1775 = or i1 %var_2_1773, %var_2_1774
; Matched:%var_2_2542:  %var_2_2542 = zext i1 %var_2_2541 to i8
; %var_2_1776 = zext i1 %var_2_1775 to i8
; Matched:\<badref\>:  store i8 %var_2_1194, i8* %var_2_14, align 1
; store i8 %var_2_1776, i8* %var_2_16, align 1
; Matched:%var_2_1195:  %var_2_1195 = and i32 %var_2_1189, 255
; %var_2_1777 = and i32 %var_2_1771, 255
; Matched:%var_2_1196:  %var_2_1196 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1195)
; %var_2_1778 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1777) #14
; Matched:%var_2_2545:  %var_2_2545 = trunc i32 %var_2_2544 to i8
; %var_2_1779 = trunc i32 %var_2_1778 to i8
; Matched:%var_2_1198:  %var_2_1198 = and i8 %var_2_1197, 1
; %var_2_1780 = and i8 %var_2_1779, 1
; Matched:%var_2_2547:  %var_2_2547 = xor i8 %var_2_2546, 1
; %var_2_1781 = xor i8 %var_2_1780, 1
; Matched:\<badref\>:  store i8 %var_2_2547, i8* %var_2_21, align 1
; store i8 %var_2_1781, i8* %var_2_23, align 1
; Matched:%var_2_2548:  %var_2_2548 = xor i32 %var_2_2536, %var_2_2531
; %var_2_1782 = xor i32 %var_2_1770, %var_2_1765
; Matched:%var_2_1201:  %var_2_1201 = xor i32 %var_2_1200, %var_2_1189
; %var_2_1783 = xor i32 %var_2_1782, %var_2_1771
; Matched:%var_2_1202:  %var_2_1202 = lshr i32 %var_2_1201, 4
; %var_2_1784 = lshr i32 %var_2_1783, 4
; Matched:%var_2_2551:  %var_2_2551 = trunc i32 %var_2_2550 to i8
; %var_2_1785 = trunc i32 %var_2_1784 to i8
; Matched:%var_2_1204:  %var_2_1204 = and i8 %var_2_1203, 1
; %var_2_1786 = and i8 %var_2_1785, 1
; Matched:\<badref\>:  store i8 %var_2_1204, i8* %var_2_27, align 1
; store i8 %var_2_1786, i8* %var_2_29, align 1
; Matched:%var_2_1205:  %var_2_1205 = icmp eq i32 %var_2_1189, 0
; %var_2_1787 = icmp eq i32 %var_2_1771, 0
; Matched:%var_2_2554:  %var_2_2554 = zext i1 %var_2_2553 to i8
; %var_2_1788 = zext i1 %var_2_1787 to i8
; Matched:\<badref\>:  store i8 %var_2_2554, i8* %var_2_30, align 1
; store i8 %var_2_1788, i8* %var_2_32, align 1
; Matched:%var_2_1207:  %var_2_1207 = lshr i32 %var_2_1189, 31
; %var_2_1789 = lshr i32 %var_2_1771, 31
; Matched:%var_2_1208:  %var_2_1208 = trunc i32 %var_2_1207 to i8
; %var_2_1790 = trunc i32 %var_2_1789 to i8
; Matched:\<badref\>:  store i8 %var_2_2556, i8* %var_2_33, align 1
; store i8 %var_2_1790, i8* %var_2_35, align 1
; Matched:%var_2_1209:  %var_2_1209 = lshr i32 %var_2_1183, 31
; %var_2_1791 = lshr i32 %var_2_1765, 31
; Matched:%var_2_1210:  %var_2_1210 = lshr i32 %var_2_1188, 31
; %var_2_1792 = lshr i32 %var_2_1770, 31
; Matched:%var_2_1211:  %var_2_1211 = xor i32 %var_2_1207, %var_2_1209
; %var_2_1793 = xor i32 %var_2_1789, %var_2_1791
; Matched:%var_2_2560:  %var_2_2560 = xor i32 %var_2_2555, %var_2_2558
; %var_2_1794 = xor i32 %var_2_1789, %var_2_1792
; Matched:%var_2_2561:  %var_2_2561 = add nuw nsw i32 %var_2_2559, %var_2_2560
; %var_2_1795 = add nuw nsw i32 %var_2_1793, %var_2_1794
; Matched:%var_2_1214:  %var_2_1214 = icmp eq i32 %var_2_1213, 2
; %var_2_1796 = icmp eq i32 %var_2_1795, 2
; Matched:%var_2_1215:  %var_2_1215 = zext i1 %var_2_1214 to i8
; %var_2_1797 = zext i1 %var_2_1796 to i8
; Matched:\<badref\>:  store i8 %var_2_2563, i8* %var_2_39, align 1
; store i8 %var_2_1797, i8* %var_2_41, align 1
; Matched:%var_2_1216:  %var_2_1216 = add i64 %var_2_1178, -40
; %var_2_1798 = add i64 %var_2_1760, -40
%var_2_1799 = add i64 %var_2_1762, 9
store i64 %var_2_1799, i64* %PC, align 8
; Matched:%var_2_2566:  %var_2_2566 = inttoptr i64 %var_2_2564 to i32*
; %var_2_1800 = inttoptr i64 %var_2_1798 to i32*
; Matched:\<badref\>:  store i32 %var_2_2537, i32* %var_2_2566, align 4
; store i32 %var_2_1771, i32* %var_2_1800, align 4
%var_2_1801 = load i64, i64* %RBP, align 8
%var_2_1802 = add i64 %var_2_1801, -16
%var_2_1803 = load i64, i64* %PC, align 8
; Matched:%var_2_2716:  %var_2_2716 = add i64 %var_2_2715, 4
; %var_2_1804 = add i64 %var_2_1803, 4
; Matched:\<badref\>:  store i64 %var_2_2716, i64* %var_2_3, align 8
; store i64 %var_2_1804, i64* %PC, align 8
%var_2_1805 = inttoptr i64 %var_2_1802 to i64*
%var_2_1806 = load i64, i64* %var_2_1805, align 8
; Matched:\<badref\>:  store i64 %var_2_3882, i64* %RDX.i2239, align 8
; store i64 %var_2_1806, i64* %RDX, align 8
%var_2_1807 = add i64 %var_2_1801, -28
%var_2_1808 = add i64 %var_2_1803, 8
store i64 %var_2_1808, i64* %PC, align 8
%var_2_1809 = inttoptr i64 %var_2_1807 to i32*
%var_2_1810 = load i32, i32* %var_2_1809, align 4
%var_2_1811 = sext i32 %var_2_1810 to i64
; Matched:\<badref\>:  store i64 %var_2_4316, i64* %RSI.i2233, align 8
; store i64 %var_2_1811, i64* %RSI, align 8
%var_2_1812 = shl nsw i64 %var_2_1811, 3
%var_2_1813 = add i64 %var_2_1812, %var_2_1806
; Matched:%var_2_3099:  %var_2_3099 = add i64 %var_2_3094, 13
; %var_2_1814 = add i64 %var_2_1803, 13
; Matched:\<badref\>:  store i64 %var_2_3099, i64* %var_2_3, align 8
; store i64 %var_2_1814, i64* %PC, align 8
%var_2_1815 = inttoptr i64 %var_2_1813 to i64*
%var_2_1816 = load i64, i64* %var_2_1815, align 8
store i64 %var_2_1816, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_2696:  %var_2_2696 = add i64 %var_2_2682, 17
; %var_2_1817 = add i64 %var_2_1803, 17
; Matched:\<badref\>:  store i64 %var_2_2696, i64* %var_2_3, align 8
; store i64 %var_2_1817, i64* %PC, align 8
%var_2_1818 = load i64, i64* %var_2_1805, align 8
; Matched:\<badref\>:  store i64 %var_2_3962, i64* %RDX.i2239, align 8
; store i64 %var_2_1818, i64* %RDX, align 8
%var_2_1819 = add i64 %var_2_1801, -32
; Matched:%var_2_2925:  %var_2_2925 = add i64 %var_2_2908, 21
; %var_2_1820 = add i64 %var_2_1803, 21
; Matched:\<badref\>:  store i64 %var_2_2925, i64* %var_2_3, align 8
; store i64 %var_2_1820, i64* %PC, align 8
%var_2_1821 = inttoptr i64 %var_2_1819 to i32*
%var_2_1822 = load i32, i32* %var_2_1821, align 4
%var_2_1823 = sext i32 %var_2_1822 to i64
; Matched:\<badref\>:  store i64 %var_2_3979, i64* %RSI.i2233, align 8
; store i64 %var_2_1823, i64* %RSI, align 8
%var_2_1824 = shl nsw i64 %var_2_1823, 3
%var_2_1825 = add i64 %var_2_1824, %var_2_1818
; Matched:%var_2_4095:  %var_2_4095 = add i64 %var_2_4072, 26
; %var_2_1826 = add i64 %var_2_1803, 26
; Matched:\<badref\>:  store i64 %var_2_4095, i64* %var_2_3, align 8
; store i64 %var_2_1826, i64* %PC, align 8
%var_2_1827 = bitcast i64 %var_2_1816 to double
%var_2_1828 = inttoptr i64 %var_2_1825 to double*
%var_2_1829 = load double, double* %var_2_1828, align 8
%var_2_1830 = fadd double %var_2_1827, %var_2_1829
store double %var_2_1830, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_3874:  %var_2_3874 = add i64 %var_2_3844, -120
; %var_2_1831 = add i64 %var_2_1801, -120
; Matched:%var_2_3434:  %var_2_3434 = add i64 %var_2_3408, 31
; %var_2_1832 = add i64 %var_2_1803, 31
; Matched:\<badref\>:  store i64 %var_2_4733, i64* %var_2_3, align 8
; store i64 %var_2_1832, i64* %PC, align 8
; Matched:%var_2_2599:  %var_2_2599 = inttoptr i64 %var_2_2597 to double*
; %var_2_1833 = inttoptr i64 %var_2_1831 to double*
; Matched:\<badref\>:  store double %var_2_1248, double* %var_2_1251, align 8
; store double %var_2_1830, double* %var_2_1833, align 8
%var_2_1834 = load i64, i64* %RBP, align 8
%var_2_1835 = add i64 %var_2_1834, -16
%var_2_1836 = load i64, i64* %PC, align 8
; Matched:%var_2_2570:  %var_2_2570 = add i64 %var_2_2569, 4
; %var_2_1837 = add i64 %var_2_1836, 4
; Matched:\<badref\>:  store i64 %var_2_2570, i64* %var_2_3, align 8
; store i64 %var_2_1837, i64* %PC, align 8
%var_2_1838 = inttoptr i64 %var_2_1835 to i64*
%var_2_1839 = load i64, i64* %var_2_1838, align 8
; Matched:\<badref\>:  store i64 %var_2_3861, i64* %RDX.i2239, align 8
; store i64 %var_2_1839, i64* %RDX, align 8
%var_2_1840 = add i64 %var_2_1834, -28
; Matched:%var_2_2607:  %var_2_2607 = add i64 %var_2_2602, 7
; %var_2_1841 = add i64 %var_2_1836, 7
; Matched:\<badref\>:  store i64 %var_2_519, i64* %var_2_3, align 8
; store i64 %var_2_1841, i64* %PC, align 8
%var_2_1842 = inttoptr i64 %var_2_1840 to i32*
%var_2_1843 = load i32, i32* %var_2_1842, align 4
%var_2_1844 = add i32 %var_2_1843, 1
; Matched:%var_2_3888:  %var_2_3888 = zext i32 %var_2_3887 to i64
; %var_2_1845 = zext i32 %var_2_1844 to i64
; Matched:\<badref\>:  store i64 %var_2_3888, i64* %RCX.i2236, align 8
; store i64 %var_2_1845, i64* %RCX, align 8
; Matched:%var_2_4343:  %var_2_4343 = icmp eq i32 %var_2_4340, -1
; %var_2_1846 = icmp eq i32 %var_2_1843, -1
; Matched:%var_2_4344:  %var_2_4344 = icmp eq i32 %var_2_4341, 0
; %var_2_1847 = icmp eq i32 %var_2_1844, 0
; Matched:%var_2_4345:  %var_2_4345 = or i1 %var_2_4343, %var_2_4344
; %var_2_1848 = or i1 %var_2_1846, %var_2_1847
; Matched:%var_2_4346:  %var_2_4346 = zext i1 %var_2_4345 to i8
; %var_2_1849 = zext i1 %var_2_1848 to i8
; Matched:\<badref\>:  store i8 %var_2_3892, i8* %var_2_14, align 1
; store i8 %var_2_1849, i8* %var_2_16, align 1
; Matched:%var_2_4347:  %var_2_4347 = and i32 %var_2_4341, 255
; %var_2_1850 = and i32 %var_2_1844, 255
; Matched:%var_2_2730:  %var_2_2730 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2729)
; %var_2_1851 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1850) #14
; Matched:%var_2_3072:  %var_2_3072 = trunc i32 %var_2_3071 to i8
; %var_2_1852 = trunc i32 %var_2_1851 to i8
; Matched:%var_2_3896:  %var_2_3896 = and i8 %var_2_3895, 1
; %var_2_1853 = and i8 %var_2_1852, 1
; Matched:%var_2_4010:  %var_2_4010 = xor i8 %var_2_4009, 1
; %var_2_1854 = xor i8 %var_2_1853, 1
; Matched:\<badref\>:  store i8 %var_2_4010, i8* %var_2_21, align 1
; store i8 %var_2_1854, i8* %var_2_23, align 1
; Matched:%var_2_3898:  %var_2_3898 = xor i32 %var_2_3887, %var_2_3886
; %var_2_1855 = xor i32 %var_2_1844, %var_2_1843
; Matched:%var_2_3899:  %var_2_3899 = lshr i32 %var_2_3898, 4
; %var_2_1856 = lshr i32 %var_2_1855, 4
; Matched:%var_2_3900:  %var_2_3900 = trunc i32 %var_2_3899 to i8
; %var_2_1857 = trunc i32 %var_2_1856 to i8
; Matched:%var_2_3901:  %var_2_3901 = and i8 %var_2_3900, 1
; %var_2_1858 = and i8 %var_2_1857, 1
; Matched:\<badref\>:  store i8 %var_2_3901, i8* %var_2_27, align 1
; store i8 %var_2_1858, i8* %var_2_29, align 1
; Matched:%var_2_4356:  %var_2_4356 = zext i1 %var_2_4344 to i8
; %var_2_1859 = zext i1 %var_2_1847 to i8
; Matched:\<badref\>:  store i8 %var_2_3902, i8* %var_2_30, align 1
; store i8 %var_2_1859, i8* %var_2_32, align 1
; Matched:%var_2_2739:  %var_2_2739 = lshr i32 %var_2_2723, 31
; %var_2_1860 = lshr i32 %var_2_1844, 31
; Matched:%var_2_3081:  %var_2_3081 = trunc i32 %var_2_3080 to i8
; %var_2_1861 = trunc i32 %var_2_1860 to i8
; Matched:\<badref\>:  store i8 %var_2_2740, i8* %var_2_33, align 1
; store i8 %var_2_1861, i8* %var_2_35, align 1
; Matched:%var_2_3082:  %var_2_3082 = lshr i32 %var_2_3063, 31
; %var_2_1862 = lshr i32 %var_2_1843, 31
; Matched:%var_2_3083:  %var_2_3083 = xor i32 %var_2_3080, %var_2_3082
; %var_2_1863 = xor i32 %var_2_1860, %var_2_1862
; Matched:%var_2_2743:  %var_2_2743 = add nuw nsw i32 %var_2_2742, %var_2_2739
; %var_2_1864 = add nuw nsw i32 %var_2_1863, %var_2_1860
; Matched:%var_2_2744:  %var_2_2744 = icmp eq i32 %var_2_2743, 2
; %var_2_1865 = icmp eq i32 %var_2_1864, 2
; Matched:%var_2_2632:  %var_2_2632 = zext i1 %var_2_2631 to i8
; %var_2_1866 = zext i1 %var_2_1865 to i8
; Matched:\<badref\>:  store i8 %var_2_2632, i8* %var_2_39, align 1
; store i8 %var_2_1866, i8* %var_2_41, align 1
%var_2_1867 = sext i32 %var_2_1844 to i64
; Matched:\<badref\>:  store i64 %var_2_3910, i64* %RSI.i2233, align 8
; store i64 %var_2_1867, i64* %RSI, align 8
%var_2_1868 = shl nsw i64 %var_2_1867, 3
%var_2_1869 = add i64 %var_2_1839, %var_2_1868
; Matched:%var_2_2302:  %var_2_2302 = add i64 %var_2_2287, 18
; %var_2_1870 = add i64 %var_2_1836, 18
; Matched:\<badref\>:  store i64 %var_2_2302, i64* %var_2_3, align 8
; store i64 %var_2_1870, i64* %PC, align 8
%var_2_1871 = inttoptr i64 %var_2_1869 to i64*
%var_2_1872 = load i64, i64* %var_2_1871, align 8
store i64 %var_2_1872, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_664:  %var_2_664 = add i64 %var_2_627, 22
; %var_2_1873 = add i64 %var_2_1836, 22
; Matched:\<badref\>:  store i64 %var_2_438, i64* %var_2_3, align 8
; store i64 %var_2_1873, i64* %PC, align 8
%var_2_1874 = load i64, i64* %var_2_1838, align 8
; Matched:\<badref\>:  store i64 %var_2_3974, i64* %RDX.i2239, align 8
; store i64 %var_2_1874, i64* %RDX, align 8
%var_2_1875 = add i64 %var_2_1834, -32
; Matched:%var_2_441:  %var_2_441 = add i64 %var_2_401, 25
; %var_2_1876 = add i64 %var_2_1836, 25
; Matched:\<badref\>:  store i64 %var_2_441, i64* %var_2_3, align 8
; store i64 %var_2_1876, i64* %PC, align 8
%var_2_1877 = inttoptr i64 %var_2_1875 to i32*
%var_2_1878 = load i32, i32* %var_2_1877, align 4
%var_2_1879 = add i32 %var_2_1878, 1
; Matched:%var_2_4612:  %var_2_4612 = zext i32 %var_2_4611 to i64
; %var_2_1880 = zext i32 %var_2_1879 to i64
; Matched:\<badref\>:  store i64 %var_2_4612, i64* %RCX.i2236, align 8
; store i64 %var_2_1880, i64* %RCX, align 8
; Matched:%var_2_2760:  %var_2_2760 = icmp eq i32 %var_2_2757, -1
; %var_2_1881 = icmp eq i32 %var_2_1878, -1
; Matched:%var_2_3925:  %var_2_3925 = icmp eq i32 %var_2_3922, 0
; %var_2_1882 = icmp eq i32 %var_2_1879, 0
; Matched:%var_2_3926:  %var_2_3926 = or i1 %var_2_3924, %var_2_3925
; %var_2_1883 = or i1 %var_2_1881, %var_2_1882
; Matched:%var_2_2763:  %var_2_2763 = zext i1 %var_2_2762 to i8
; %var_2_1884 = zext i1 %var_2_1883 to i8
; Matched:\<badref\>:  store i8 %var_2_2650, i8* %var_2_14, align 1
; store i8 %var_2_1884, i8* %var_2_16, align 1
; Matched:%var_2_2651:  %var_2_2651 = and i32 %var_2_2645, 255
; %var_2_1885 = and i32 %var_2_1879, 255
; Matched:%var_2_2765:  %var_2_2765 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2764)
; %var_2_1886 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1885) #14
; Matched:%var_2_2766:  %var_2_2766 = trunc i32 %var_2_2765 to i8
; %var_2_1887 = trunc i32 %var_2_1886 to i8
; Matched:%var_2_2654:  %var_2_2654 = and i8 %var_2_2653, 1
; %var_2_1888 = and i8 %var_2_1887, 1
; Matched:%var_2_2655:  %var_2_2655 = xor i8 %var_2_2654, 1
; %var_2_1889 = xor i8 %var_2_1888, 1
; Matched:\<badref\>:  store i8 %var_2_2768, i8* %var_2_21, align 1
; store i8 %var_2_1889, i8* %var_2_23, align 1
; Matched:%var_2_3933:  %var_2_3933 = xor i32 %var_2_3922, %var_2_3921
; %var_2_1890 = xor i32 %var_2_1879, %var_2_1878
; Matched:%var_2_3934:  %var_2_3934 = lshr i32 %var_2_3933, 4
; %var_2_1891 = lshr i32 %var_2_1890, 4
; Matched:%var_2_3935:  %var_2_3935 = trunc i32 %var_2_3934 to i8
; %var_2_1892 = trunc i32 %var_2_1891 to i8
; Matched:%var_2_3936:  %var_2_3936 = and i8 %var_2_3935, 1
; %var_2_1893 = and i8 %var_2_1892, 1
; Matched:\<badref\>:  store i8 %var_2_3936, i8* %var_2_27, align 1
; store i8 %var_2_1893, i8* %var_2_29, align 1
; Matched:%var_2_2773:  %var_2_2773 = zext i1 %var_2_2761 to i8
; %var_2_1894 = zext i1 %var_2_1882 to i8
; Matched:\<badref\>:  store i8 %var_2_2773, i8* %var_2_30, align 1
; store i8 %var_2_1894, i8* %var_2_32, align 1
; Matched:%var_2_3938:  %var_2_3938 = lshr i32 %var_2_3922, 31
; %var_2_1895 = lshr i32 %var_2_1879, 31
; Matched:%var_2_3939:  %var_2_3939 = trunc i32 %var_2_3938 to i8
; %var_2_1896 = trunc i32 %var_2_1895 to i8
; Matched:\<badref\>:  store i8 %var_2_4052, i8* %var_2_33, align 1
; store i8 %var_2_1896, i8* %var_2_35, align 1
; Matched:%var_2_2663:  %var_2_2663 = lshr i32 %var_2_2644, 31
; %var_2_1897 = lshr i32 %var_2_1878, 31
; Matched:%var_2_2664:  %var_2_2664 = xor i32 %var_2_2661, %var_2_2663
; %var_2_1898 = xor i32 %var_2_1895, %var_2_1897
; Matched:%var_2_2665:  %var_2_2665 = add nuw nsw i32 %var_2_2664, %var_2_2661
; %var_2_1899 = add nuw nsw i32 %var_2_1898, %var_2_1895
; Matched:%var_2_2779:  %var_2_2779 = icmp eq i32 %var_2_2778, 2
; %var_2_1900 = icmp eq i32 %var_2_1899, 2
; Matched:%var_2_4057:  %var_2_4057 = zext i1 %var_2_4056 to i8
; %var_2_1901 = zext i1 %var_2_1900 to i8
; Matched:\<badref\>:  store i8 %var_2_3944, i8* %var_2_39, align 1
; store i8 %var_2_1901, i8* %var_2_41, align 1
%var_2_1902 = sext i32 %var_2_1879 to i64
; Matched:\<badref\>:  store i64 %var_2_3945, i64* %RSI.i2233, align 8
; store i64 %var_2_1902, i64* %RSI, align 8
%var_2_1903 = shl nsw i64 %var_2_1902, 3
%var_2_1904 = add i64 %var_2_1874, %var_2_1903
; Matched:%var_2_1323:  %var_2_1323 = add i64 %var_2_1254, 36
; %var_2_1905 = add i64 %var_2_1836, 36
; Matched:\<badref\>:  store i64 %var_2_1323, i64* %var_2_3, align 8
; store i64 %var_2_1905, i64* %PC, align 8
%var_2_1906 = bitcast i64 %var_2_1872 to double
%var_2_1907 = inttoptr i64 %var_2_1904 to double*
%var_2_1908 = load double, double* %var_2_1907, align 8
%var_2_1909 = fadd double %var_2_1906, %var_2_1908
store double %var_2_1909, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_1328:  %var_2_1328 = load i64, i64* %RBP.i, align 8
; %var_2_1910 = load i64, i64* %RBP, align 8
; Matched:%var_2_2677:  %var_2_2677 = add i64 %var_2_2676, -128
; %var_2_1911 = add i64 %var_2_1910, -128
; Matched:%var_2_1330:  %var_2_1330 = add i64 %var_2_1254, 41
; %var_2_1912 = add i64 %var_2_1836, 41
; Matched:\<badref\>:  store i64 %var_2_3955, i64* %var_2_3, align 8
; store i64 %var_2_1912, i64* %PC, align 8
; Matched:%var_2_2679:  %var_2_2679 = inttoptr i64 %var_2_2677 to double*
; %var_2_1913 = inttoptr i64 %var_2_1911 to double*
; Matched:\<badref\>:  store double %var_2_2675, double* %var_2_2679, align 8
; store double %var_2_1909, double* %var_2_1913, align 8
%var_2_1914 = load i64, i64* %RBP, align 8
%var_2_1915 = add i64 %var_2_1914, -16
%var_2_1916 = load i64, i64* %PC, align 8
; Matched:%var_2_289:  %var_2_289 = add i64 %var_2_288, 4
; %var_2_1917 = add i64 %var_2_1916, 4
; Matched:\<badref\>:  store i64 %var_2_289, i64* %var_2_3, align 8
; store i64 %var_2_1917, i64* %PC, align 8
%var_2_1918 = inttoptr i64 %var_2_1915 to i64*
%var_2_1919 = load i64, i64* %var_2_1918, align 8
; Matched:\<badref\>:  store i64 %var_2_4200, i64* %RDX.i2239, align 8
; store i64 %var_2_1919, i64* %RDX, align 8
%var_2_1920 = add i64 %var_2_1914, -28
%var_2_1921 = add i64 %var_2_1916, 8
store i64 %var_2_1921, i64* %PC, align 8
%var_2_1922 = inttoptr i64 %var_2_1920 to i32*
%var_2_1923 = load i32, i32* %var_2_1922, align 4
%var_2_1924 = sext i32 %var_2_1923 to i64
; Matched:\<badref\>:  store i64 %var_2_3854, i64* %RSI.i2233, align 8
; store i64 %var_2_1924, i64* %RSI, align 8
%var_2_1925 = shl nsw i64 %var_2_1924, 3
%var_2_1926 = add i64 %var_2_1925, %var_2_1919
; Matched:%var_2_2298:  %var_2_2298 = add i64 %var_2_2287, 13
; %var_2_1927 = add i64 %var_2_1916, 13
; Matched:\<badref\>:  store i64 %var_2_2298, i64* %var_2_3, align 8
; store i64 %var_2_1927, i64* %PC, align 8
%var_2_1928 = inttoptr i64 %var_2_1926 to i64*
%var_2_1929 = load i64, i64* %var_2_1928, align 8
store i64 %var_2_1929, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1757:  %var_2_1757 = add i64 %var_2_1746, 17
; %var_2_1930 = add i64 %var_2_1916, 17
; Matched:\<badref\>:  store i64 %var_2_1757, i64* %var_2_3, align 8
; store i64 %var_2_1930, i64* %PC, align 8
%var_2_1931 = load i64, i64* %var_2_1918, align 8
; Matched:\<badref\>:  store i64 %var_2_4188, i64* %RDX.i2239, align 8
; store i64 %var_2_1931, i64* %RDX, align 8
%var_2_1932 = add i64 %var_2_1914, -32
; Matched:%var_2_2586:  %var_2_2586 = add i64 %var_2_2569, 21
; %var_2_1933 = add i64 %var_2_1916, 21
; Matched:\<badref\>:  store i64 %var_2_1945, i64* %var_2_3, align 8
; store i64 %var_2_1933, i64* %PC, align 8
%var_2_1934 = inttoptr i64 %var_2_1932 to i32*
%var_2_1935 = load i32, i32* %var_2_1934, align 4
%var_2_1936 = sext i32 %var_2_1935 to i64
; Matched:\<badref\>:  store i64 %var_2_3866, i64* %RSI.i2233, align 8
; store i64 %var_2_1936, i64* %RSI, align 8
%var_2_1937 = shl nsw i64 %var_2_1936, 3
%var_2_1938 = add i64 %var_2_1937, %var_2_1931
; Matched:%var_2_391:  %var_2_391 = add i64 %var_2_368, 26
; %var_2_1939 = add i64 %var_2_1916, 26
; Matched:\<badref\>:  store i64 %var_2_391, i64* %var_2_3, align 8
; store i64 %var_2_1939, i64* %PC, align 8
%var_2_1940 = bitcast i64 %var_2_1929 to double
%var_2_1941 = inttoptr i64 %var_2_1938 to double*
%var_2_1942 = load double, double* %var_2_1941, align 8
%var_2_1943 = fsub double %var_2_1940, %var_2_1942
store double %var_2_1943, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_2710:  %var_2_2710 = add i64 %var_2_2680, -136
; %var_2_1944 = add i64 %var_2_1914, -136
; Matched:%var_2_4101:  %var_2_4101 = add i64 %var_2_4072, 34
; %var_2_1945 = add i64 %var_2_1916, 34
; Matched:\<badref\>:  store i64 %var_2_4101, i64* %var_2_3, align 8
; store i64 %var_2_1945, i64* %PC, align 8
; Matched:%var_2_2712:  %var_2_2712 = inttoptr i64 %var_2_2710 to double*
; %var_2_1946 = inttoptr i64 %var_2_1944 to double*
; Matched:\<badref\>:  store double %var_2_2709, double* %var_2_2712, align 8
; store double %var_2_1943, double* %var_2_1946, align 8
%var_2_1947 = load i64, i64* %RBP, align 8
%var_2_1948 = add i64 %var_2_1947, -16
%var_2_1949 = load i64, i64* %PC, align 8
; Matched:%var_2_1594:  %var_2_1594 = add i64 %var_2_1593, 4
; %var_2_1950 = add i64 %var_2_1949, 4
; Matched:\<badref\>:  store i64 %var_2_1594, i64* %var_2_3, align 8
; store i64 %var_2_1950, i64* %PC, align 8
%var_2_1951 = inttoptr i64 %var_2_1948 to i64*
%var_2_1952 = load i64, i64* %var_2_1951, align 8
; Matched:\<badref\>:  store i64 %var_2_4087, i64* %RDX.i2239, align 8
; store i64 %var_2_1952, i64* %RDX, align 8
%var_2_1953 = add i64 %var_2_1947, -28
; Matched:%var_2_2833:  %var_2_2833 = add i64 %var_2_2828, 7
; %var_2_1954 = add i64 %var_2_1949, 7
; Matched:\<badref\>:  store i64 %var_2_2607, i64* %var_2_3, align 8
; store i64 %var_2_1954, i64* %PC, align 8
%var_2_1955 = inttoptr i64 %var_2_1953 to i32*
%var_2_1956 = load i32, i32* %var_2_1955, align 4
%var_2_1957 = add i32 %var_2_1956, 1
; Matched:%var_2_4342:  %var_2_4342 = zext i32 %var_2_4341 to i64
; %var_2_1958 = zext i32 %var_2_1957 to i64
; Matched:\<badref\>:  store i64 %var_2_4001, i64* %RCX.i2236, align 8
; store i64 %var_2_1958, i64* %RCX, align 8
; Matched:%var_2_4002:  %var_2_4002 = icmp eq i32 %var_2_3999, -1
; %var_2_1959 = icmp eq i32 %var_2_1956, -1
; Matched:%var_2_4003:  %var_2_4003 = icmp eq i32 %var_2_4000, 0
; %var_2_1960 = icmp eq i32 %var_2_1957, 0
; Matched:%var_2_3891:  %var_2_3891 = or i1 %var_2_3889, %var_2_3890
; %var_2_1961 = or i1 %var_2_1959, %var_2_1960
; Matched:%var_2_3892:  %var_2_3892 = zext i1 %var_2_3891 to i8
; %var_2_1962 = zext i1 %var_2_1961 to i8
; Matched:\<badref\>:  store i8 %var_2_4005, i8* %var_2_14, align 1
; store i8 %var_2_1962, i8* %var_2_16, align 1
; Matched:%var_2_4006:  %var_2_4006 = and i32 %var_2_4000, 255
; %var_2_1963 = and i32 %var_2_1957, 255
; Matched:%var_2_4348:  %var_2_4348 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4347)
; %var_2_1964 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1963) #14
; Matched:%var_2_2731:  %var_2_2731 = trunc i32 %var_2_2730 to i8
; %var_2_1965 = trunc i32 %var_2_1964 to i8
; Matched:%var_2_4350:  %var_2_4350 = and i8 %var_2_4349, 1
; %var_2_1966 = and i8 %var_2_1965, 1
; Matched:%var_2_760:  %var_2_760 = xor i8 %var_2_759, 1
; %var_2_1967 = xor i8 %var_2_1966, 1
; Matched:\<badref\>:  store i8 %var_2_760, i8* %var_2_21, align 1
; store i8 %var_2_1967, i8* %var_2_23, align 1
; Matched:%var_2_4352:  %var_2_4352 = xor i32 %var_2_4341, %var_2_4340
; %var_2_1968 = xor i32 %var_2_1957, %var_2_1956
; Matched:%var_2_4353:  %var_2_4353 = lshr i32 %var_2_4352, 4
; %var_2_1969 = lshr i32 %var_2_1968, 4
; Matched:%var_2_4354:  %var_2_4354 = trunc i32 %var_2_4353 to i8
; %var_2_1970 = trunc i32 %var_2_1969 to i8
; Matched:%var_2_4355:  %var_2_4355 = and i8 %var_2_4354, 1
; %var_2_1971 = and i8 %var_2_1970, 1
; Matched:\<badref\>:  store i8 %var_2_4355, i8* %var_2_27, align 1
; store i8 %var_2_1971, i8* %var_2_29, align 1
; Matched:%var_2_4015:  %var_2_4015 = zext i1 %var_2_4003 to i8
; %var_2_1972 = zext i1 %var_2_1960 to i8
; Matched:\<badref\>:  store i8 %var_2_4356, i8* %var_2_30, align 1
; store i8 %var_2_1972, i8* %var_2_32, align 1
; Matched:%var_2_4357:  %var_2_4357 = lshr i32 %var_2_4341, 31
; %var_2_1973 = lshr i32 %var_2_1957, 31
; Matched:%var_2_2740:  %var_2_2740 = trunc i32 %var_2_2739 to i8
; %var_2_1974 = trunc i32 %var_2_1973 to i8
; Matched:\<badref\>:  store i8 %var_2_4358, i8* %var_2_33, align 1
; store i8 %var_2_1974, i8* %var_2_35, align 1
; Matched:%var_2_2741:  %var_2_2741 = lshr i32 %var_2_2722, 31
; %var_2_1975 = lshr i32 %var_2_1956, 31
; Matched:%var_2_2742:  %var_2_2742 = xor i32 %var_2_2739, %var_2_2741
; %var_2_1976 = xor i32 %var_2_1973, %var_2_1975
; Matched:%var_2_3907:  %var_2_3907 = add nuw nsw i32 %var_2_3906, %var_2_3903
; %var_2_1977 = add nuw nsw i32 %var_2_1976, %var_2_1973
; Matched:%var_2_3908:  %var_2_3908 = icmp eq i32 %var_2_3907, 2
; %var_2_1978 = icmp eq i32 %var_2_1977, 2
; Matched:%var_2_2745:  %var_2_2745 = zext i1 %var_2_2744 to i8
; %var_2_1979 = zext i1 %var_2_1978 to i8
; Matched:\<badref\>:  store i8 %var_2_2745, i8* %var_2_39, align 1
; store i8 %var_2_1979, i8* %var_2_41, align 1
%var_2_1980 = sext i32 %var_2_1957 to i64
; Matched:\<badref\>:  store i64 %var_2_4364, i64* %RSI.i2233, align 8
; store i64 %var_2_1980, i64* %RSI, align 8
%var_2_1981 = shl nsw i64 %var_2_1980, 3
%var_2_1982 = add i64 %var_2_1952, %var_2_1981
; Matched:%var_2_2636:  %var_2_2636 = add i64 %var_2_2602, 18
; %var_2_1983 = add i64 %var_2_1949, 18
; Matched:\<badref\>:  store i64 %var_2_2636, i64* %var_2_3, align 8
; store i64 %var_2_1983, i64* %PC, align 8
%var_2_1984 = inttoptr i64 %var_2_1982 to i64*
%var_2_1985 = load i64, i64* %var_2_1984, align 8
store i64 %var_2_1985, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_3118:  %var_2_3118 = add i64 %var_2_3108, 22
; %var_2_1986 = add i64 %var_2_1949, 22
; Matched:\<badref\>:  store i64 %var_2_664, i64* %var_2_3, align 8
; store i64 %var_2_1986, i64* %PC, align 8
%var_2_1987 = load i64, i64* %var_2_1951, align 8
; Matched:\<badref\>:  store i64 %var_2_4336, i64* %RDX.i2239, align 8
; store i64 %var_2_1987, i64* %RDX, align 8
%var_2_1988 = add i64 %var_2_1947, -32
; Matched:%var_2_667:  %var_2_667 = add i64 %var_2_627, 25
; %var_2_1989 = add i64 %var_2_1949, 25
; Matched:\<badref\>:  store i64 %var_2_667, i64* %var_2_3, align 8
; store i64 %var_2_1989, i64* %PC, align 8
%var_2_1990 = inttoptr i64 %var_2_1988 to i32*
%var_2_1991 = load i32, i32* %var_2_1990, align 4
%var_2_1992 = add i32 %var_2_1991, 1
; Matched:%var_2_3923:  %var_2_3923 = zext i32 %var_2_3922 to i64
; %var_2_1993 = zext i32 %var_2_1992 to i64
; Matched:\<badref\>:  store i64 %var_2_3923, i64* %RCX.i2236, align 8
; store i64 %var_2_1993, i64* %RCX, align 8
; Matched:%var_2_3924:  %var_2_3924 = icmp eq i32 %var_2_3921, -1
; %var_2_1994 = icmp eq i32 %var_2_1991, -1
; Matched:%var_2_4038:  %var_2_4038 = icmp eq i32 %var_2_4035, 0
; %var_2_1995 = icmp eq i32 %var_2_1992, 0
; Matched:%var_2_4039:  %var_2_4039 = or i1 %var_2_4037, %var_2_4038
; %var_2_1996 = or i1 %var_2_1994, %var_2_1995
; Matched:%var_2_3927:  %var_2_3927 = zext i1 %var_2_3926 to i8
; %var_2_1997 = zext i1 %var_2_1996 to i8
; Matched:\<badref\>:  store i8 %var_2_2763, i8* %var_2_14, align 1
; store i8 %var_2_1997, i8* %var_2_16, align 1
; Matched:%var_2_2764:  %var_2_2764 = and i32 %var_2_2758, 255
; %var_2_1998 = and i32 %var_2_1992, 255
; Matched:%var_2_3929:  %var_2_3929 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3928)
; %var_2_1999 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1998) #14
; Matched:%var_2_3930:  %var_2_3930 = trunc i32 %var_2_3929 to i8
; %var_2_2000 = trunc i32 %var_2_1999 to i8
; Matched:%var_2_2767:  %var_2_2767 = and i8 %var_2_2766, 1
; %var_2_2001 = and i8 %var_2_2000, 1
; Matched:%var_2_2768:  %var_2_2768 = xor i8 %var_2_2767, 1
; %var_2_2002 = xor i8 %var_2_2001, 1
; Matched:\<badref\>:  store i8 %var_2_3932, i8* %var_2_21, align 1
; store i8 %var_2_2002, i8* %var_2_23, align 1
; Matched:%var_2_4046:  %var_2_4046 = xor i32 %var_2_4035, %var_2_4034
; %var_2_2003 = xor i32 %var_2_1992, %var_2_1991
; Matched:%var_2_4047:  %var_2_4047 = lshr i32 %var_2_4046, 4
; %var_2_2004 = lshr i32 %var_2_2003, 4
; Matched:%var_2_4048:  %var_2_4048 = trunc i32 %var_2_4047 to i8
; %var_2_2005 = trunc i32 %var_2_2004 to i8
; Matched:%var_2_4049:  %var_2_4049 = and i8 %var_2_4048, 1
; %var_2_2006 = and i8 %var_2_2005, 1
; Matched:\<badref\>:  store i8 %var_2_4049, i8* %var_2_27, align 1
; store i8 %var_2_2006, i8* %var_2_29, align 1
; Matched:%var_2_3937:  %var_2_3937 = zext i1 %var_2_3925 to i8
; %var_2_2007 = zext i1 %var_2_1995 to i8
; Matched:\<badref\>:  store i8 %var_2_3937, i8* %var_2_30, align 1
; store i8 %var_2_2007, i8* %var_2_32, align 1
; Matched:%var_2_4051:  %var_2_4051 = lshr i32 %var_2_4035, 31
; %var_2_2008 = lshr i32 %var_2_1992, 31
; Matched:%var_2_4052:  %var_2_4052 = trunc i32 %var_2_4051 to i8
; %var_2_2009 = trunc i32 %var_2_2008 to i8
; Matched:\<badref\>:  store i8 %var_2_1921, i8* %var_2_33, align 1
; store i8 %var_2_2009, i8* %var_2_35, align 1
; Matched:%var_2_2776:  %var_2_2776 = lshr i32 %var_2_2757, 31
; %var_2_2010 = lshr i32 %var_2_1991, 31
; Matched:%var_2_2777:  %var_2_2777 = xor i32 %var_2_2774, %var_2_2776
; %var_2_2011 = xor i32 %var_2_2008, %var_2_2010
; Matched:%var_2_2778:  %var_2_2778 = add nuw nsw i32 %var_2_2777, %var_2_2774
; %var_2_2012 = add nuw nsw i32 %var_2_2011, %var_2_2008
; Matched:%var_2_3943:  %var_2_3943 = icmp eq i32 %var_2_3942, 2
; %var_2_2013 = icmp eq i32 %var_2_2012, 2
; Matched:%var_2_466:  %var_2_466 = zext i1 %var_2_465 to i8
; %var_2_2014 = zext i1 %var_2_2013 to i8
; Matched:\<badref\>:  store i8 %var_2_4057, i8* %var_2_39, align 1
; store i8 %var_2_2014, i8* %var_2_41, align 1
%var_2_2015 = sext i32 %var_2_1992 to i64
; Matched:\<badref\>:  store i64 %var_2_4058, i64* %RSI.i2233, align 8
; store i64 %var_2_2015, i64* %RSI, align 8
%var_2_2016 = shl nsw i64 %var_2_2015, 3
%var_2_2017 = add i64 %var_2_1987, %var_2_2016
; Matched:%var_2_1549:  %var_2_1549 = add i64 %var_2_1480, 36
; %var_2_2018 = add i64 %var_2_1949, 36
; Matched:\<badref\>:  store i64 %var_2_1549, i64* %var_2_3, align 8
; store i64 %var_2_2018, i64* %PC, align 8
%var_2_2019 = bitcast i64 %var_2_1985 to double
%var_2_2020 = inttoptr i64 %var_2_2017 to double*
%var_2_2021 = load double, double* %var_2_2020, align 8
%var_2_2022 = fsub double %var_2_2019, %var_2_2021
store double %var_2_2022, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_1441:  %var_2_1441 = load i64, i64* %RBP.i, align 8
; %var_2_2023 = load i64, i64* %RBP, align 8
; Matched:%var_2_1442:  %var_2_1442 = add i64 %var_2_1441, -144
; %var_2_2024 = add i64 %var_2_2023, -144
; Matched:%var_2_2904:  %var_2_2904 = add i64 %var_2_2828, 44
; %var_2_2025 = add i64 %var_2_1949, 44
; Matched:\<badref\>:  store i64 %var_2_2791, i64* %var_2_3, align 8
; store i64 %var_2_2025, i64* %PC, align 8
; Matched:%var_2_4069:  %var_2_4069 = inttoptr i64 %var_2_4067 to double*
; %var_2_2026 = inttoptr i64 %var_2_2024 to double*
; Matched:\<badref\>:  store double %var_2_2788, double* %var_2_2792, align 8
; store double %var_2_2022, double* %var_2_2026, align 8
%var_2_2027 = load i64, i64* %RBP, align 8
%var_2_2028 = add i64 %var_2_2027, -16
%var_2_2029 = load i64, i64* %PC, align 8
; Matched:%var_2_2942:  %var_2_2942 = add i64 %var_2_2941, 4
; %var_2_2030 = add i64 %var_2_2029, 4
; Matched:\<badref\>:  store i64 %var_2_1222, i64* %var_2_3, align 8
; store i64 %var_2_2030, i64* %PC, align 8
%var_2_2031 = inttoptr i64 %var_2_2028 to i64*
%var_2_2032 = load i64, i64* %var_2_2031, align 8
; Matched:\<badref\>:  store i64 %var_2_4108, i64* %RDX.i2239, align 8
; store i64 %var_2_2032, i64* %RDX, align 8
%var_2_2033 = add i64 %var_2_2027, -36
%var_2_2034 = add i64 %var_2_2029, 8
store i64 %var_2_2034, i64* %PC, align 8
%var_2_2035 = inttoptr i64 %var_2_2033 to i32*
%var_2_2036 = load i32, i32* %var_2_2035, align 4
%var_2_2037 = sext i32 %var_2_2036 to i64
; Matched:\<badref\>:  store i64 %var_2_4193, i64* %RSI.i2233, align 8
; store i64 %var_2_2037, i64* %RSI, align 8
%var_2_2038 = shl nsw i64 %var_2_2037, 3
%var_2_2039 = add i64 %var_2_2038, %var_2_2032
; Matched:%var_2_2693:  %var_2_2693 = add i64 %var_2_2682, 13
; %var_2_2040 = add i64 %var_2_2029, 13
; Matched:\<badref\>:  store i64 %var_2_2693, i64* %var_2_3, align 8
; store i64 %var_2_2040, i64* %PC, align 8
%var_2_2041 = inttoptr i64 %var_2_2039 to i64*
%var_2_2042 = load i64, i64* %var_2_2041, align 8
store i64 %var_2_2042, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1684:  %var_2_1684 = add i64 %var_2_1673, 17
; %var_2_2043 = add i64 %var_2_2029, 17
; Matched:\<badref\>:  store i64 %var_2_1684, i64* %var_2_3, align 8
; store i64 %var_2_2043, i64* %PC, align 8
%var_2_2044 = load i64, i64* %var_2_2031, align 8
; Matched:\<badref\>:  store i64 %var_2_4030, i64* %RDX.i2239, align 8
; store i64 %var_2_2044, i64* %RDX, align 8
%var_2_2045 = add i64 %var_2_2027, -40
; Matched:%var_2_3863:  %var_2_3863 = add i64 %var_2_3846, 21
; %var_2_2046 = add i64 %var_2_2029, 21
; Matched:\<badref\>:  store i64 %var_2_3863, i64* %var_2_3, align 8
; store i64 %var_2_2046, i64* %PC, align 8
%var_2_2047 = inttoptr i64 %var_2_2045 to i32*
%var_2_2048 = load i32, i32* %var_2_2047, align 4
%var_2_2049 = sext i32 %var_2_2048 to i64
; Matched:\<badref\>:  store i64 %var_2_4092, i64* %RSI.i2233, align 8
; store i64 %var_2_2049, i64* %RSI, align 8
%var_2_2050 = shl nsw i64 %var_2_2049, 3
%var_2_2051 = add i64 %var_2_2050, %var_2_2044
; Matched:%var_2_1901:  %var_2_1901 = add i64 %var_2_1880, 26
; %var_2_2052 = add i64 %var_2_2029, 26
; Matched:\<badref\>:  store i64 %var_2_1901, i64* %var_2_3, align 8
; store i64 %var_2_2052, i64* %PC, align 8
%var_2_2053 = bitcast i64 %var_2_2042 to double
%var_2_2054 = inttoptr i64 %var_2_2051 to double*
%var_2_2055 = load double, double* %var_2_2054, align 8
%var_2_2056 = fadd double %var_2_2053, %var_2_2055
store double %var_2_2056, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_1475:  %var_2_1475 = add i64 %var_2_1445, -152
; %var_2_2057 = add i64 %var_2_2027, -152
; Matched:%var_2_4214:  %var_2_4214 = add i64 %var_2_4185, 34
; %var_2_2058 = add i64 %var_2_2029, 34
; Matched:\<badref\>:  store i64 %var_2_4214, i64* %var_2_3, align 8
; store i64 %var_2_2058, i64* %PC, align 8
; Matched:%var_2_2825:  %var_2_2825 = inttoptr i64 %var_2_2823 to double*
; %var_2_2059 = inttoptr i64 %var_2_2057 to double*
; Matched:\<badref\>:  store double %var_2_2822, double* %var_2_2825, align 8
; store double %var_2_2056, double* %var_2_2059, align 8
%var_2_2060 = load i64, i64* %RBP, align 8
%var_2_2061 = add i64 %var_2_2060, -16
%var_2_2062 = load i64, i64* %PC, align 8
; Matched:%var_2_62:  %var_2_62 = add i64 %var_2_61, 4
; %var_2_2063 = add i64 %var_2_2062, 4
; Matched:\<badref\>:  store i64 %var_2_62, i64* %var_2_3, align 8
; store i64 %var_2_2063, i64* %PC, align 8
%var_2_2064 = inttoptr i64 %var_2_2061 to i64*
%var_2_2065 = load i64, i64* %var_2_2064, align 8
; Matched:\<badref\>:  store i64 %var_2_3995, i64* %RDX.i2239, align 8
; store i64 %var_2_2065, i64* %RDX, align 8
%var_2_2066 = add i64 %var_2_2060, -36
; Matched:%var_2_3997:  %var_2_3997 = add i64 %var_2_3992, 7
; %var_2_2067 = add i64 %var_2_2062, 7
; Matched:\<badref\>:  store i64 %var_2_2833, i64* %var_2_3, align 8
; store i64 %var_2_2067, i64* %PC, align 8
%var_2_2068 = inttoptr i64 %var_2_2066 to i32*
%var_2_2069 = load i32, i32* %var_2_2068, align 4
%var_2_2070 = add i32 %var_2_2069, 1
; Matched:%var_2_4114:  %var_2_4114 = zext i32 %var_2_4113 to i64
; %var_2_2071 = zext i32 %var_2_2070 to i64
; Matched:\<badref\>:  store i64 %var_2_4114, i64* %RCX.i2236, align 8
; store i64 %var_2_2071, i64* %RCX, align 8
; Matched:%var_2_3189:  %var_2_3189 = icmp eq i32 %var_2_3186, -1
; %var_2_2072 = icmp eq i32 %var_2_2069, -1
; Matched:%var_2_3190:  %var_2_3190 = icmp eq i32 %var_2_3187, 0
; %var_2_2073 = icmp eq i32 %var_2_2070, 0
; Matched:%var_2_3191:  %var_2_3191 = or i1 %var_2_3189, %var_2_3190
; %var_2_2074 = or i1 %var_2_2072, %var_2_2073
; Matched:%var_2_3192:  %var_2_3192 = zext i1 %var_2_3191 to i8
; %var_2_2075 = zext i1 %var_2_2074 to i8
; Matched:\<badref\>:  store i8 %var_2_4118, i8* %var_2_14, align 1
; store i8 %var_2_2075, i8* %var_2_16, align 1
; Matched:%var_2_3193:  %var_2_3193 = and i32 %var_2_3187, 255
; %var_2_2076 = and i32 %var_2_2070, 255
; Matched:%var_2_4120:  %var_2_4120 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4119)
; %var_2_2077 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2076) #14
; Matched:%var_2_4121:  %var_2_4121 = trunc i32 %var_2_4120 to i8
; %var_2_2078 = trunc i32 %var_2_2077 to i8
; Matched:%var_2_4122:  %var_2_4122 = and i8 %var_2_4121, 1
; %var_2_2079 = and i8 %var_2_2078, 1
; Matched:%var_2_4496:  %var_2_4496 = xor i8 %var_2_4495, 1
; %var_2_2080 = xor i8 %var_2_2079, 1
; Matched:\<badref\>:  store i8 %var_2_3197, i8* %var_2_21, align 1
; store i8 %var_2_2080, i8* %var_2_23, align 1
; Matched:%var_2_3198:  %var_2_3198 = xor i32 %var_2_3187, %var_2_3186
; %var_2_2081 = xor i32 %var_2_2070, %var_2_2069
; Matched:%var_2_4125:  %var_2_4125 = lshr i32 %var_2_4124, 4
; %var_2_2082 = lshr i32 %var_2_2081, 4
; Matched:%var_2_4126:  %var_2_4126 = trunc i32 %var_2_4125 to i8
; %var_2_2083 = trunc i32 %var_2_2082 to i8
; Matched:%var_2_4127:  %var_2_4127 = and i8 %var_2_4126, 1
; %var_2_2084 = and i8 %var_2_2083, 1
; Matched:\<badref\>:  store i8 %var_2_4127, i8* %var_2_27, align 1
; store i8 %var_2_2084, i8* %var_2_29, align 1
; Matched:%var_2_3202:  %var_2_3202 = zext i1 %var_2_3190 to i8
; %var_2_2085 = zext i1 %var_2_2073 to i8
; Matched:\<badref\>:  store i8 %var_2_4128, i8* %var_2_30, align 1
; store i8 %var_2_2085, i8* %var_2_32, align 1
; Matched:%var_2_3203:  %var_2_3203 = lshr i32 %var_2_3187, 31
; %var_2_2086 = lshr i32 %var_2_2070, 31
; Matched:%var_2_4130:  %var_2_4130 = trunc i32 %var_2_4129 to i8
; %var_2_2087 = trunc i32 %var_2_2086 to i8
; Matched:\<badref\>:  store i8 %var_2_4130, i8* %var_2_33, align 1
; store i8 %var_2_2087, i8* %var_2_35, align 1
; Matched:%var_2_4131:  %var_2_4131 = lshr i32 %var_2_4112, 31
; %var_2_2088 = lshr i32 %var_2_2069, 31
; Matched:%var_2_4505:  %var_2_4505 = xor i32 %var_2_4502, %var_2_4504
; %var_2_2089 = xor i32 %var_2_2086, %var_2_2088
; Matched:%var_2_2969:  %var_2_2969 = add nuw nsw i32 %var_2_2968, %var_2_2965
; %var_2_2090 = add nuw nsw i32 %var_2_2089, %var_2_2086
; Matched:%var_2_2857:  %var_2_2857 = icmp eq i32 %var_2_2856, 2
; %var_2_2091 = icmp eq i32 %var_2_2090, 2
; Matched:%var_2_2971:  %var_2_2971 = zext i1 %var_2_2970 to i8
; %var_2_2092 = zext i1 %var_2_2091 to i8
; Matched:\<badref\>:  store i8 %var_2_2971, i8* %var_2_39, align 1
; store i8 %var_2_2092, i8* %var_2_41, align 1
%var_2_2093 = sext i32 %var_2_2070 to i64
; Matched:\<badref\>:  store i64 %var_2_4136, i64* %RSI.i2233, align 8
; store i64 %var_2_2093, i64* %RSI, align 8
%var_2_2094 = shl nsw i64 %var_2_2093, 3
%var_2_2095 = add i64 %var_2_2065, %var_2_2094
; Matched:%var_2_4139:  %var_2_4139 = add i64 %var_2_4105, 18
; %var_2_2096 = add i64 %var_2_2062, 18
; Matched:\<badref\>:  store i64 %var_2_2365, i64* %var_2_3, align 8
; store i64 %var_2_2096, i64* %PC, align 8
%var_2_2097 = inttoptr i64 %var_2_2095 to i64*
%var_2_2098 = load i64, i64* %var_2_2097, align 8
store i64 %var_2_2098, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_2752:  %var_2_2752 = add i64 %var_2_2715, 22
; %var_2_2099 = add i64 %var_2_2062, 22
; Matched:\<badref\>:  store i64 %var_2_3118, i64* %var_2_3, align 8
; store i64 %var_2_2099, i64* %PC, align 8
%var_2_2100 = load i64, i64* %var_2_2064, align 8
; Matched:\<badref\>:  store i64 %var_2_4075, i64* %RDX.i2239, align 8
; store i64 %var_2_2100, i64* %RDX, align 8
%var_2_2101 = add i64 %var_2_2060, -40
; Matched:%var_2_2755:  %var_2_2755 = add i64 %var_2_2715, 25
; %var_2_2102 = add i64 %var_2_2062, 25
; Matched:\<badref\>:  store i64 %var_2_2755, i64* %var_2_3, align 8
; store i64 %var_2_2102, i64* %PC, align 8
%var_2_2103 = inttoptr i64 %var_2_2101 to i32*
%var_2_2104 = load i32, i32* %var_2_2103, align 4
%var_2_2105 = add i32 %var_2_2104, 1
; Matched:%var_2_4149:  %var_2_4149 = zext i32 %var_2_4148 to i64
; %var_2_2106 = zext i32 %var_2_2105 to i64
; Matched:\<badref\>:  store i64 %var_2_4149, i64* %RCX.i2236, align 8
; store i64 %var_2_2106, i64* %RCX, align 8
; Matched:%var_2_2986:  %var_2_2986 = icmp eq i32 %var_2_2983, -1
; %var_2_2107 = icmp eq i32 %var_2_2104, -1
; Matched:%var_2_2022:  %var_2_2022 = icmp eq i32 %var_2_2019, 0
; %var_2_2108 = icmp eq i32 %var_2_2105, 0
; Matched:%var_2_2023:  %var_2_2023 = or i1 %var_2_2021, %var_2_2022
; %var_2_2109 = or i1 %var_2_2107, %var_2_2108
; Matched:%var_2_2989:  %var_2_2989 = zext i1 %var_2_2988 to i8
; %var_2_2110 = zext i1 %var_2_2109 to i8
; Matched:\<badref\>:  store i8 %var_2_2989, i8* %var_2_14, align 1
; store i8 %var_2_2110, i8* %var_2_16, align 1
; Matched:%var_2_2990:  %var_2_2990 = and i32 %var_2_2984, 255
; %var_2_2111 = and i32 %var_2_2105, 255
; Matched:%var_2_2026:  %var_2_2026 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2025)
; %var_2_2112 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2111) #14
; Matched:%var_2_2027:  %var_2_2027 = trunc i32 %var_2_2026 to i8
; %var_2_2113 = trunc i32 %var_2_2112 to i8
; Matched:%var_2_2993:  %var_2_2993 = and i8 %var_2_2992, 1
; %var_2_2114 = and i8 %var_2_2113, 1
; Matched:%var_2_2994:  %var_2_2994 = xor i8 %var_2_2993, 1
; %var_2_2115 = xor i8 %var_2_2114, 1
; Matched:\<badref\>:  store i8 %var_2_2881, i8* %var_2_21, align 1
; store i8 %var_2_2115, i8* %var_2_23, align 1
; Matched:%var_2_2030:  %var_2_2030 = xor i32 %var_2_2019, %var_2_2018
; %var_2_2116 = xor i32 %var_2_2105, %var_2_2104
; Matched:%var_2_2996:  %var_2_2996 = lshr i32 %var_2_2995, 4
; %var_2_2117 = lshr i32 %var_2_2116, 4
; Matched:%var_2_4161:  %var_2_4161 = trunc i32 %var_2_4160 to i8
; %var_2_2118 = trunc i32 %var_2_2117 to i8
; Matched:%var_2_2033:  %var_2_2033 = and i8 %var_2_2032, 1
; %var_2_2119 = and i8 %var_2_2118, 1
; Matched:\<badref\>:  store i8 %var_2_2033, i8* %var_2_27, align 1
; store i8 %var_2_2119, i8* %var_2_29, align 1
; Matched:%var_2_2034:  %var_2_2034 = zext i1 %var_2_2022 to i8
; %var_2_2120 = zext i1 %var_2_2108 to i8
; Matched:\<badref\>:  store i8 %var_2_2034, i8* %var_2_30, align 1
; store i8 %var_2_2120, i8* %var_2_32, align 1
; Matched:%var_2_2887:  %var_2_2887 = lshr i32 %var_2_2871, 31
; %var_2_2121 = lshr i32 %var_2_2105, 31
; Matched:%var_2_2888:  %var_2_2888 = trunc i32 %var_2_2887 to i8
; %var_2_2122 = trunc i32 %var_2_2121 to i8
; Matched:\<badref\>:  store i8 %var_2_2888, i8* %var_2_33, align 1
; store i8 %var_2_2122, i8* %var_2_35, align 1
; Matched:%var_2_2037:  %var_2_2037 = lshr i32 %var_2_2018, 31
; %var_2_2123 = lshr i32 %var_2_2104, 31
; Matched:%var_2_3003:  %var_2_3003 = xor i32 %var_2_3000, %var_2_3002
; %var_2_2124 = xor i32 %var_2_2121, %var_2_2123
; Matched:%var_2_2891:  %var_2_2891 = add nuw nsw i32 %var_2_2890, %var_2_2887
; %var_2_2125 = add nuw nsw i32 %var_2_2124, %var_2_2121
; Matched:%var_2_2892:  %var_2_2892 = icmp eq i32 %var_2_2891, 2
; %var_2_2126 = icmp eq i32 %var_2_2125, 2
; Matched:%var_2_2041:  %var_2_2041 = zext i1 %var_2_2040 to i8
; %var_2_2127 = zext i1 %var_2_2126 to i8
; Matched:\<badref\>:  store i8 %var_2_2041, i8* %var_2_39, align 1
; store i8 %var_2_2127, i8* %var_2_41, align 1
%var_2_2128 = sext i32 %var_2_2105 to i64
; Matched:\<badref\>:  store i64 %var_2_4284, i64* %RSI.i2233, align 8
; store i64 %var_2_2128, i64* %RSI, align 8
%var_2_2129 = shl nsw i64 %var_2_2128, 3
%var_2_2130 = add i64 %var_2_2100, %var_2_2129
; Matched:%var_2_357:  %var_2_357 = add i64 %var_2_288, 36
; %var_2_2131 = add i64 %var_2_2062, 36
; Matched:\<badref\>:  store i64 %var_2_357, i64* %var_2_3, align 8
; store i64 %var_2_2131, i64* %PC, align 8
%var_2_2132 = bitcast i64 %var_2_2098 to double
%var_2_2133 = inttoptr i64 %var_2_2130 to double*
%var_2_2134 = load double, double* %var_2_2133, align 8
%var_2_2135 = fadd double %var_2_2132, %var_2_2134
store double %var_2_2135, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_2902:  %var_2_2902 = load i64, i64* %RBP.i, align 8
; %var_2_2136 = load i64, i64* %RBP, align 8
; Matched:%var_2_1555:  %var_2_1555 = add i64 %var_2_1554, -160
; %var_2_2137 = add i64 %var_2_2136, -160
; Matched:%var_2_3017:  %var_2_3017 = add i64 %var_2_2941, 44
; %var_2_2138 = add i64 %var_2_2062, 44
; Matched:\<badref\>:  store i64 %var_2_2904, i64* %var_2_3, align 8
; store i64 %var_2_2138, i64* %PC, align 8
; Matched:%var_2_2905:  %var_2_2905 = inttoptr i64 %var_2_2903 to double*
; %var_2_2139 = inttoptr i64 %var_2_2137 to double*
; Matched:\<badref\>:  store double %var_2_1553, double* %var_2_1557, align 8
; store double %var_2_2135, double* %var_2_2139, align 8
%var_2_2140 = load i64, i64* %RBP, align 8
%var_2_2141 = add i64 %var_2_2140, -16
%var_2_2142 = load i64, i64* %PC, align 8
; Matched:%var_2_1335:  %var_2_1335 = add i64 %var_2_1334, 4
; %var_2_2143 = add i64 %var_2_2142, 4
; Matched:\<badref\>:  store i64 %var_2_1335, i64* %var_2_3, align 8
; store i64 %var_2_2143, i64* %PC, align 8
%var_2_2144 = inttoptr i64 %var_2_2141 to i64*
%var_2_2145 = load i64, i64* %var_2_2144, align 8
; Matched:\<badref\>:  store i64 %var_2_3917, i64* %RDX.i2239, align 8
; store i64 %var_2_2145, i64* %RDX, align 8
%var_2_2146 = add i64 %var_2_2140, -36
%var_2_2147 = add i64 %var_2_2142, 8
store i64 %var_2_2147, i64* %PC, align 8
%var_2_2148 = inttoptr i64 %var_2_2146 to i32*
%var_2_2149 = load i32, i32* %var_2_2148, align 4
%var_2_2150 = sext i32 %var_2_2149 to i64
; Matched:\<badref\>:  store i64 %var_2_4439, i64* %RSI.i2233, align 8
; store i64 %var_2_2150, i64* %RSI, align 8
%var_2_2151 = shl nsw i64 %var_2_2150, 3
%var_2_2152 = add i64 %var_2_2151, %var_2_2145
; Matched:%var_2_4328:  %var_2_4328 = add i64 %var_2_4323, 13
; %var_2_2153 = add i64 %var_2_2142, 13
; Matched:\<badref\>:  store i64 %var_2_4328, i64* %var_2_3, align 8
; store i64 %var_2_2153, i64* %PC, align 8
%var_2_2154 = inttoptr i64 %var_2_2152 to i64*
%var_2_2155 = load i64, i64* %var_2_2154, align 8
store i64 %var_2_2155, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1235:  %var_2_1235 = add i64 %var_2_1221, 17
; %var_2_2156 = add i64 %var_2_2142, 17
; Matched:\<badref\>:  store i64 %var_2_1235, i64* %var_2_3, align 8
; store i64 %var_2_2156, i64* %PC, align 8
%var_2_2157 = load i64, i64* %var_2_2144, align 8
; Matched:\<badref\>:  store i64 %var_2_4434, i64* %RDX.i2239, align 8
; store i64 %var_2_2157, i64* %RDX, align 8
%var_2_2158 = add i64 %var_2_2140, -40
; Matched:%var_2_3976:  %var_2_3976 = add i64 %var_2_3959, 21
; %var_2_2159 = add i64 %var_2_2142, 21
; Matched:\<badref\>:  store i64 %var_2_3976, i64* %var_2_3, align 8
; store i64 %var_2_2159, i64* %PC, align 8
%var_2_2160 = inttoptr i64 %var_2_2158 to i32*
%var_2_2161 = load i32, i32* %var_2_2160, align 4
%var_2_2162 = sext i32 %var_2_2161 to i64
; Matched:\<badref\>:  store i64 %var_2_4205, i64* %RSI.i2233, align 8
; store i64 %var_2_2162, i64* %RSI, align 8
%var_2_2163 = shl nsw i64 %var_2_2162, 3
%var_2_2164 = add i64 %var_2_2163, %var_2_2157
; Matched:%var_2_728:  %var_2_728 = add i64 %var_2_707, 26
; %var_2_2165 = add i64 %var_2_2142, 26
; Matched:\<badref\>:  store i64 %var_2_728, i64* %var_2_3, align 8
; store i64 %var_2_2165, i64* %PC, align 8
%var_2_2166 = bitcast i64 %var_2_2155 to double
%var_2_2167 = inttoptr i64 %var_2_2164 to double*
%var_2_2168 = load double, double* %var_2_2167, align 8
%var_2_2169 = fsub double %var_2_2166, %var_2_2168
store double %var_2_2169, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_1588:  %var_2_1588 = add i64 %var_2_1558, -168
; %var_2_2170 = add i64 %var_2_2140, -168
; Matched:%var_2_995:  %var_2_995 = add i64 %var_2_951, 34
; %var_2_2171 = add i64 %var_2_2142, 34
; Matched:\<badref\>:  store i64 %var_2_995, i64* %var_2_3, align 8
; store i64 %var_2_2171, i64* %PC, align 8
; Matched:%var_2_4215:  %var_2_4215 = inttoptr i64 %var_2_4213 to double*
; %var_2_2172 = inttoptr i64 %var_2_2170 to double*
; Matched:\<badref\>:  store double %var_2_2935, double* %var_2_2938, align 8
; store double %var_2_2169, double* %var_2_2172, align 8
%var_2_2173 = load i64, i64* %RBP, align 8
%var_2_2174 = add i64 %var_2_2173, -16
%var_2_2175 = load i64, i64* %PC, align 8
; Matched:%var_2_369:  %var_2_369 = add i64 %var_2_368, 4
; %var_2_2176 = add i64 %var_2_2175, 4
; Matched:\<badref\>:  store i64 %var_2_369, i64* %var_2_3, align 8
; store i64 %var_2_2176, i64* %PC, align 8
%var_2_2177 = inttoptr i64 %var_2_2174 to i64*
%var_2_2178 = load i64, i64* %var_2_2177, align 8
; Matched:\<badref\>:  store i64 %var_2_4221, i64* %RDX.i2239, align 8
; store i64 %var_2_2178, i64* %RDX, align 8
%var_2_2179 = add i64 %var_2_2173, -36
; Matched:%var_2_4223:  %var_2_4223 = add i64 %var_2_4218, 7
; %var_2_2180 = add i64 %var_2_2175, 7
; Matched:\<badref\>:  store i64 %var_2_3997, i64* %var_2_3, align 8
; store i64 %var_2_2180, i64* %PC, align 8
%var_2_2181 = inttoptr i64 %var_2_2179 to i32*
%var_2_2182 = load i32, i32* %var_2_2181, align 4
%var_2_2183 = add i32 %var_2_2182, 1
; Matched:%var_2_4227:  %var_2_4227 = zext i32 %var_2_4226 to i64
; %var_2_2184 = zext i32 %var_2_2183 to i64
; Matched:\<badref\>:  store i64 %var_2_4227, i64* %RCX.i2236, align 8
; store i64 %var_2_2184, i64* %RCX, align 8
; Matched:%var_2_4228:  %var_2_4228 = icmp eq i32 %var_2_4225, -1
; %var_2_2185 = icmp eq i32 %var_2_2182, -1
; Matched:%var_2_4229:  %var_2_4229 = icmp eq i32 %var_2_4226, 0
; %var_2_2186 = icmp eq i32 %var_2_2183, 0
; Matched:%var_2_4230:  %var_2_4230 = or i1 %var_2_4228, %var_2_4229
; %var_2_2187 = or i1 %var_2_2185, %var_2_2186
; Matched:%var_2_4231:  %var_2_4231 = zext i1 %var_2_4230 to i8
; %var_2_2188 = zext i1 %var_2_2187 to i8
; Matched:\<badref\>:  store i8 %var_2_4231, i8* %var_2_14, align 1
; store i8 %var_2_2188, i8* %var_2_16, align 1
; Matched:%var_2_4232:  %var_2_4232 = and i32 %var_2_4226, 255
; %var_2_2189 = and i32 %var_2_2183, 255
; Matched:%var_2_4233:  %var_2_4233 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4232)
; %var_2_2190 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2189) #14
; Matched:%var_2_4234:  %var_2_4234 = trunc i32 %var_2_4233 to i8
; %var_2_2191 = trunc i32 %var_2_2190 to i8
; Matched:%var_2_3196:  %var_2_3196 = and i8 %var_2_3195, 1
; %var_2_2192 = and i8 %var_2_2191, 1
; Matched:%var_2_4123:  %var_2_4123 = xor i8 %var_2_4122, 1
; %var_2_2193 = xor i8 %var_2_2192, 1
; Matched:\<badref\>:  store i8 %var_2_4123, i8* %var_2_21, align 1
; store i8 %var_2_2193, i8* %var_2_23, align 1
; Matched:%var_2_4237:  %var_2_4237 = xor i32 %var_2_4226, %var_2_4225
; %var_2_2194 = xor i32 %var_2_2183, %var_2_2182
; Matched:%var_2_4238:  %var_2_4238 = lshr i32 %var_2_4237, 4
; %var_2_2195 = lshr i32 %var_2_2194, 4
; Matched:%var_2_4239:  %var_2_4239 = trunc i32 %var_2_4238 to i8
; %var_2_2196 = trunc i32 %var_2_2195 to i8
; Matched:%var_2_4240:  %var_2_4240 = and i8 %var_2_4239, 1
; %var_2_2197 = and i8 %var_2_2196, 1
; Matched:\<badref\>:  store i8 %var_2_4240, i8* %var_2_27, align 1
; store i8 %var_2_2197, i8* %var_2_29, align 1
; Matched:%var_2_4241:  %var_2_4241 = zext i1 %var_2_4229 to i8
; %var_2_2198 = zext i1 %var_2_2186 to i8
; Matched:\<badref\>:  store i8 %var_2_3202, i8* %var_2_30, align 1
; store i8 %var_2_2198, i8* %var_2_32, align 1
; Matched:%var_2_4242:  %var_2_4242 = lshr i32 %var_2_4226, 31
; %var_2_2199 = lshr i32 %var_2_2183, 31
; Matched:%var_2_3204:  %var_2_3204 = trunc i32 %var_2_3203 to i8
; %var_2_2200 = trunc i32 %var_2_2199 to i8
; Matched:\<badref\>:  store i8 %var_2_4243, i8* %var_2_33, align 1
; store i8 %var_2_2200, i8* %var_2_35, align 1
; Matched:%var_2_4244:  %var_2_4244 = lshr i32 %var_2_4225, 31
; %var_2_2201 = lshr i32 %var_2_2182, 31
; Matched:%var_2_4132:  %var_2_4132 = xor i32 %var_2_4129, %var_2_4131
; %var_2_2202 = xor i32 %var_2_2199, %var_2_2201
; Matched:%var_2_4506:  %var_2_4506 = add nuw nsw i32 %var_2_4505, %var_2_4502
; %var_2_2203 = add nuw nsw i32 %var_2_2202, %var_2_2199
; Matched:%var_2_2970:  %var_2_2970 = icmp eq i32 %var_2_2969, 2
; %var_2_2204 = icmp eq i32 %var_2_2203, 2
; Matched:%var_2_4508:  %var_2_4508 = zext i1 %var_2_4507 to i8
; %var_2_2205 = zext i1 %var_2_2204 to i8
; Matched:\<badref\>:  store i8 %var_2_4508, i8* %var_2_39, align 1
; store i8 %var_2_2205, i8* %var_2_41, align 1
%var_2_2206 = sext i32 %var_2_2183 to i64
; Matched:\<badref\>:  store i64 %var_2_4249, i64* %RSI.i2233, align 8
; store i64 %var_2_2206, i64* %RSI, align 8
%var_2_2207 = shl nsw i64 %var_2_2206, 3
%var_2_2208 = add i64 %var_2_2178, %var_2_2207
; Matched:%var_2_435:  %var_2_435 = add i64 %var_2_401, 18
; %var_2_2209 = add i64 %var_2_2175, 18
; Matched:\<badref\>:  store i64 %var_2_435, i64* %var_2_3, align 8
; store i64 %var_2_2209, i64* %PC, align 8
%var_2_2210 = inttoptr i64 %var_2_2208 to i64*
%var_2_2211 = load i64, i64* %var_2_2210, align 8
store i64 %var_2_2211, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_2978:  %var_2_2978 = add i64 %var_2_2941, 22
; %var_2_2212 = add i64 %var_2_2175, 22
; Matched:\<badref\>:  store i64 %var_2_2752, i64* %var_2_3, align 8
; store i64 %var_2_2212, i64* %PC, align 8
%var_2_2213 = load i64, i64* %var_2_2177, align 8
; Matched:\<badref\>:  store i64 %var_2_4256, i64* %RDX.i2239, align 8
; store i64 %var_2_2213, i64* %RDX, align 8
%var_2_2214 = add i64 %var_2_2173, -40
; Matched:%var_2_2981:  %var_2_2981 = add i64 %var_2_2941, 25
; %var_2_2215 = add i64 %var_2_2175, 25
; Matched:\<badref\>:  store i64 %var_2_2981, i64* %var_2_3, align 8
; store i64 %var_2_2215, i64* %PC, align 8
%var_2_2216 = inttoptr i64 %var_2_2214 to i32*
%var_2_2217 = load i32, i32* %var_2_2216, align 4
%var_2_2218 = add i32 %var_2_2217, 1
; Matched:%var_2_4262:  %var_2_4262 = zext i32 %var_2_4261 to i64
; %var_2_2219 = zext i32 %var_2_2218 to i64
; Matched:\<badref\>:  store i64 %var_2_4262, i64* %RCX.i2236, align 8
; store i64 %var_2_2219, i64* %RCX, align 8
; Matched:%var_2_4150:  %var_2_4150 = icmp eq i32 %var_2_4147, -1
; %var_2_2220 = icmp eq i32 %var_2_2217, -1
; Matched:%var_2_2987:  %var_2_2987 = icmp eq i32 %var_2_2984, 0
; %var_2_2221 = icmp eq i32 %var_2_2218, 0
; Matched:%var_2_2875:  %var_2_2875 = or i1 %var_2_2873, %var_2_2874
; %var_2_2222 = or i1 %var_2_2220, %var_2_2221
; Matched:%var_2_4153:  %var_2_4153 = zext i1 %var_2_4152 to i8
; %var_2_2223 = zext i1 %var_2_2222 to i8
; Matched:\<badref\>:  store i8 %var_2_4153, i8* %var_2_14, align 1
; store i8 %var_2_2223, i8* %var_2_16, align 1
; Matched:%var_2_4154:  %var_2_4154 = and i32 %var_2_4148, 255
; %var_2_2224 = and i32 %var_2_2218, 255
; Matched:%var_2_2991:  %var_2_2991 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2990)
; %var_2_2225 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2224) #14
; Matched:%var_2_2992:  %var_2_2992 = trunc i32 %var_2_2991 to i8
; %var_2_2226 = trunc i32 %var_2_2225 to i8
; Matched:%var_2_4157:  %var_2_4157 = and i8 %var_2_4156, 1
; %var_2_2227 = and i8 %var_2_2226, 1
; Matched:%var_2_4158:  %var_2_4158 = xor i8 %var_2_4157, 1
; %var_2_2228 = xor i8 %var_2_2227, 1
; Matched:\<badref\>:  store i8 %var_2_2994, i8* %var_2_21, align 1
; store i8 %var_2_2228, i8* %var_2_23, align 1
; Matched:%var_2_2995:  %var_2_2995 = xor i32 %var_2_2984, %var_2_2983
; %var_2_2229 = xor i32 %var_2_2218, %var_2_2217
; Matched:%var_2_4160:  %var_2_4160 = lshr i32 %var_2_4159, 4
; %var_2_2230 = lshr i32 %var_2_2229, 4
; Matched:%var_2_4274:  %var_2_4274 = trunc i32 %var_2_4273 to i8
; %var_2_2231 = trunc i32 %var_2_2230 to i8
; Matched:%var_2_2998:  %var_2_2998 = and i8 %var_2_2997, 1
; %var_2_2232 = and i8 %var_2_2231, 1
; Matched:\<badref\>:  store i8 %var_2_2998, i8* %var_2_27, align 1
; store i8 %var_2_2232, i8* %var_2_29, align 1
; Matched:%var_2_2999:  %var_2_2999 = zext i1 %var_2_2987 to i8
; %var_2_2233 = zext i1 %var_2_2221 to i8
; Matched:\<badref\>:  store i8 %var_2_2999, i8* %var_2_30, align 1
; store i8 %var_2_2233, i8* %var_2_32, align 1
; Matched:%var_2_3000:  %var_2_3000 = lshr i32 %var_2_2984, 31
; %var_2_2234 = lshr i32 %var_2_2218, 31
; Matched:%var_2_3001:  %var_2_3001 = trunc i32 %var_2_3000 to i8
; %var_2_2235 = trunc i32 %var_2_2234 to i8
; Matched:\<badref\>:  store i8 %var_2_3001, i8* %var_2_33, align 1
; store i8 %var_2_2235, i8* %var_2_35, align 1
; Matched:%var_2_3002:  %var_2_3002 = lshr i32 %var_2_2983, 31
; %var_2_2236 = lshr i32 %var_2_2217, 31
; Matched:%var_2_4167:  %var_2_4167 = xor i32 %var_2_4164, %var_2_4166
; %var_2_2237 = xor i32 %var_2_2234, %var_2_2236
; Matched:%var_2_2039:  %var_2_2039 = add nuw nsw i32 %var_2_2038, %var_2_2035
; %var_2_2238 = add nuw nsw i32 %var_2_2237, %var_2_2234
; Matched:%var_2_2040:  %var_2_2040 = icmp eq i32 %var_2_2039, 2
; %var_2_2239 = icmp eq i32 %var_2_2238, 2
; Matched:%var_2_3006:  %var_2_3006 = zext i1 %var_2_3005 to i8
; %var_2_2240 = zext i1 %var_2_2239 to i8
; Matched:\<badref\>:  store i8 %var_2_3006, i8* %var_2_39, align 1
; store i8 %var_2_2240, i8* %var_2_41, align 1
%var_2_2241 = sext i32 %var_2_2218 to i64
; Matched:\<badref\>:  store i64 %var_2_4171, i64* %RSI.i2233, align 8
; store i64 %var_2_2241, i64* %RSI, align 8
%var_2_2242 = shl nsw i64 %var_2_2241, 3
%var_2_2243 = add i64 %var_2_2213, %var_2_2242
; Matched:%var_2_583:  %var_2_583 = add i64 %var_2_514, 36
; %var_2_2244 = add i64 %var_2_2175, 36
; Matched:\<badref\>:  store i64 %var_2_583, i64* %var_2_3, align 8
; store i64 %var_2_2244, i64* %PC, align 8
%var_2_2245 = bitcast i64 %var_2_2211 to double
%var_2_2246 = inttoptr i64 %var_2_2243 to double*
%var_2_2247 = load double, double* %var_2_2246, align 8
%var_2_2248 = fsub double %var_2_2245, %var_2_2247
store double %var_2_2248, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_3015:  %var_2_3015 = load i64, i64* %RBP.i, align 8
; %var_2_2249 = load i64, i64* %RBP, align 8
; Matched:%var_2_3016:  %var_2_3016 = add i64 %var_2_3015, -176
; %var_2_2250 = add i64 %var_2_2249, -176
; Matched:%var_2_4068:  %var_2_4068 = add i64 %var_2_3992, 44
; %var_2_2251 = add i64 %var_2_2175, 44
; Matched:\<badref\>:  store i64 %var_2_3017, i64* %var_2_3, align 8
; store i64 %var_2_2251, i64* %PC, align 8
; Matched:%var_2_1670:  %var_2_1670 = inttoptr i64 %var_2_1668 to double*
; %var_2_2252 = inttoptr i64 %var_2_2250 to double*
; Matched:\<badref\>:  store double %var_2_3014, double* %var_2_3018, align 8
; store double %var_2_2248, double* %var_2_2252, align 8
%var_2_2253 = load i64, i64* %RBP, align 8
%var_2_2254 = add i64 %var_2_2253, -120
%var_2_2255 = load i64, i64* %PC, align 8
; Matched:%var_2_4299:  %var_2_4299 = add i64 %var_2_4298, 5
; %var_2_2256 = add i64 %var_2_2255, 5
; Matched:\<badref\>:  store i64 %var_2_4299, i64* %var_2_3, align 8
; store i64 %var_2_2256, i64* %PC, align 8
%var_2_2257 = inttoptr i64 %var_2_2254 to i64*
%var_2_2258 = load i64, i64* %var_2_2257, align 8
store i64 %var_2_2258, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_2259 = add i64 %var_2_2253, -152
; Matched:%var_2_4083:  %var_2_4083 = add i64 %var_2_4072, 13
; %var_2_2260 = add i64 %var_2_2255, 13
; Matched:\<badref\>:  store i64 %var_2_2359, i64* %var_2_3, align 8
; store i64 %var_2_2260, i64* %PC, align 8
%var_2_2261 = bitcast i64 %var_2_2258 to double
%var_2_2262 = inttoptr i64 %var_2_2259 to double*
%var_2_2263 = load double, double* %var_2_2262, align 8
%var_2_2264 = fadd double %var_2_2261, %var_2_2263
store double %var_2_2264, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_2265 = add i64 %var_2_2253, -16
; Matched:%var_2_3057:  %var_2_3057 = add i64 %var_2_3046, 17
; %var_2_2266 = add i64 %var_2_2255, 17
; Matched:\<badref\>:  store i64 %var_2_3057, i64* %var_2_3, align 8
; store i64 %var_2_2266, i64* %PC, align 8
%var_2_2267 = inttoptr i64 %var_2_2265 to i64*
%var_2_2268 = load i64, i64* %var_2_2267, align 8
; Matched:\<badref\>:  store i64 %var_2_4311, i64* %RDX.i2239, align 8
; store i64 %var_2_2268, i64* %RDX, align 8
%var_2_2269 = add i64 %var_2_2253, -28
; Matched:%var_2_4089:  %var_2_4089 = add i64 %var_2_4072, 21
; %var_2_2270 = add i64 %var_2_2255, 21
; Matched:\<badref\>:  store i64 %var_2_4089, i64* %var_2_3, align 8
; store i64 %var_2_2270, i64* %PC, align 8
%var_2_2271 = inttoptr i64 %var_2_2269 to i32*
%var_2_2272 = load i32, i32* %var_2_2271, align 4
%var_2_2273 = sext i32 %var_2_2272 to i64
; Matched:\<badref\>:  store i64 %var_2_3967, i64* %RSI.i2233, align 8
; store i64 %var_2_2273, i64* %RSI, align 8
; Matched:%var_2_1692:  %var_2_1692 = shl nsw i64 %var_2_1691, 3
; %var_2_2274 = shl nsw i64 %var_2_2273, 3
; Matched:%var_2_1693:  %var_2_1693 = add i64 %var_2_1692, %var_2_1686
; %var_2_2275 = add i64 %var_2_2274, %var_2_2268
; Matched:%var_2_4319:  %var_2_4319 = add i64 %var_2_4298, 26
; %var_2_2276 = add i64 %var_2_2255, 26
; Matched:\<badref\>:  store i64 %var_2_4319, i64* %var_2_3, align 8
; store i64 %var_2_2276, i64* %PC, align 8
; Matched:%var_2_3043:  %var_2_3043 = inttoptr i64 %var_2_3041 to double*
; %var_2_2277 = inttoptr i64 %var_2_2275 to double*
; Matched:\<badref\>:  store double %var_2_1682, double* %var_2_1695, align 8
; store double %var_2_2264, double* %var_2_2277, align 8
%var_2_2278 = load i64, i64* %RBP, align 8
%var_2_2279 = add i64 %var_2_2278, -128
%var_2_2280 = load i64, i64* %PC, align 8
; Matched:%var_2_3583:  %var_2_3583 = add i64 %var_2_3582, 5
; %var_2_2281 = add i64 %var_2_2280, 5
; Matched:\<badref\>:  store i64 %var_2_3583, i64* %var_2_3, align 8
; store i64 %var_2_2281, i64* %PC, align 8
%var_2_2282 = inttoptr i64 %var_2_2279 to i64*
%var_2_2283 = load i64, i64* %var_2_2282, align 8
store i64 %var_2_2283, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_2284 = add i64 %var_2_2278, -160
; Matched:%var_2_4196:  %var_2_4196 = add i64 %var_2_4185, 13
; %var_2_2285 = add i64 %var_2_2280, 13
; Matched:\<badref\>:  store i64 %var_2_4196, i64* %var_2_3, align 8
; store i64 %var_2_2285, i64* %PC, align 8
%var_2_2286 = bitcast i64 %var_2_2283 to double
%var_2_2287 = inttoptr i64 %var_2_2284 to double*
%var_2_2288 = load double, double* %var_2_2287, align 8
%var_2_2289 = fadd double %var_2_2286, %var_2_2288
store double %var_2_2289, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_2290 = add i64 %var_2_2278, -16
; Matched:%var_2_1348:  %var_2_1348 = add i64 %var_2_1334, 17
; %var_2_2291 = add i64 %var_2_2280, 17
; Matched:\<badref\>:  store i64 %var_2_1348, i64* %var_2_3, align 8
; store i64 %var_2_2291, i64* %PC, align 8
%var_2_2292 = inttoptr i64 %var_2_2290 to i64*
%var_2_2293 = load i64, i64* %var_2_2292, align 8
; Matched:\<badref\>:  store i64 %var_2_4143, i64* %RDX.i2239, align 8
; store i64 %var_2_2293, i64* %RDX, align 8
%var_2_2294 = add i64 %var_2_2278, -28
; Matched:%var_2_4338:  %var_2_4338 = add i64 %var_2_4323, 20
; %var_2_2295 = add i64 %var_2_2280, 20
; Matched:\<badref\>:  store i64 %var_2_4338, i64* %var_2_3, align 8
; store i64 %var_2_2295, i64* %PC, align 8
%var_2_2296 = inttoptr i64 %var_2_2294 to i32*
%var_2_2297 = load i32, i32* %var_2_2296, align 4
%var_2_2298 = add i32 %var_2_2297, 1
; Matched:%var_2_4001:  %var_2_4001 = zext i32 %var_2_4000 to i64
; %var_2_2299 = zext i32 %var_2_2298 to i64
; Matched:\<badref\>:  store i64 %var_2_4342, i64* %RCX.i2236, align 8
; store i64 %var_2_2299, i64* %RCX, align 8
; Matched:%var_2_3889:  %var_2_3889 = icmp eq i32 %var_2_3886, -1
; %var_2_2300 = icmp eq i32 %var_2_2297, -1
; Matched:%var_2_3890:  %var_2_3890 = icmp eq i32 %var_2_3887, 0
; %var_2_2301 = icmp eq i32 %var_2_2298, 0
; Matched:%var_2_2727:  %var_2_2727 = or i1 %var_2_2725, %var_2_2726
; %var_2_2302 = or i1 %var_2_2300, %var_2_2301
; Matched:%var_2_2728:  %var_2_2728 = zext i1 %var_2_2727 to i8
; %var_2_2303 = zext i1 %var_2_2302 to i8
; Matched:\<badref\>:  store i8 %var_2_4346, i8* %var_2_14, align 1
; store i8 %var_2_2303, i8* %var_2_16, align 1
; Matched:%var_2_3893:  %var_2_3893 = and i32 %var_2_3887, 255
; %var_2_2304 = and i32 %var_2_2298, 255
; Matched:%var_2_3071:  %var_2_3071 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3070)
; %var_2_2305 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2304) #14
; Matched:%var_2_2618:  %var_2_2618 = trunc i32 %var_2_2617 to i8
; %var_2_2306 = trunc i32 %var_2_2305 to i8
; Matched:%var_2_2732:  %var_2_2732 = and i8 %var_2_2731, 1
; %var_2_2307 = and i8 %var_2_2306, 1
; Matched:%var_2_3897:  %var_2_3897 = xor i8 %var_2_3896, 1
; %var_2_2308 = xor i8 %var_2_2307, 1
; Matched:\<badref\>:  store i8 %var_2_4351, i8* %var_2_21, align 1
; store i8 %var_2_2308, i8* %var_2_23, align 1
; Matched:%var_2_2734:  %var_2_2734 = xor i32 %var_2_2723, %var_2_2722
; %var_2_2309 = xor i32 %var_2_2298, %var_2_2297
; Matched:%var_2_2735:  %var_2_2735 = lshr i32 %var_2_2734, 4
; %var_2_2310 = lshr i32 %var_2_2309, 4
; Matched:%var_2_2736:  %var_2_2736 = trunc i32 %var_2_2735 to i8
; %var_2_2311 = trunc i32 %var_2_2310 to i8
; Matched:%var_2_2737:  %var_2_2737 = and i8 %var_2_2736, 1
; %var_2_2312 = and i8 %var_2_2311, 1
; Matched:\<badref\>:  store i8 %var_2_2737, i8* %var_2_27, align 1
; store i8 %var_2_2312, i8* %var_2_29, align 1
; Matched:%var_2_2625:  %var_2_2625 = zext i1 %var_2_2613 to i8
; %var_2_2313 = zext i1 %var_2_2301 to i8
; Matched:\<badref\>:  store i8 %var_2_1390, i8* %var_2_30, align 1
; store i8 %var_2_2313, i8* %var_2_32, align 1
; Matched:%var_2_2626:  %var_2_2626 = lshr i32 %var_2_2610, 31
; %var_2_2314 = lshr i32 %var_2_2298, 31
; Matched:%var_2_1733:  %var_2_1733 = trunc i32 %var_2_1732 to i8
; %var_2_2315 = trunc i32 %var_2_2314 to i8
; Matched:\<badref\>:  store i8 %var_2_4017, i8* %var_2_33, align 1
; store i8 %var_2_2315, i8* %var_2_35, align 1
; Matched:%var_2_3905:  %var_2_3905 = lshr i32 %var_2_3886, 31
; %var_2_2316 = lshr i32 %var_2_2297, 31
; Matched:%var_2_3906:  %var_2_3906 = xor i32 %var_2_3903, %var_2_3905
; %var_2_2317 = xor i32 %var_2_2314, %var_2_2316
; Matched:%var_2_2630:  %var_2_2630 = add nuw nsw i32 %var_2_2629, %var_2_2626
; %var_2_2318 = add nuw nsw i32 %var_2_2317, %var_2_2314
; Matched:%var_2_2631:  %var_2_2631 = icmp eq i32 %var_2_2630, 2
; %var_2_2319 = icmp eq i32 %var_2_2318, 2
; Matched:%var_2_3086:  %var_2_3086 = zext i1 %var_2_3085 to i8
; %var_2_2320 = zext i1 %var_2_2319 to i8
; Matched:\<badref\>:  store i8 %var_2_3086, i8* %var_2_39, align 1
; store i8 %var_2_2320, i8* %var_2_41, align 1
%var_2_2321 = sext i32 %var_2_2298 to i64
; Matched:\<badref\>:  store i64 %var_2_4023, i64* %RSI.i2233, align 8
; store i64 %var_2_2321, i64* %RSI, align 8
; Matched:%var_2_3088:  %var_2_3088 = shl nsw i64 %var_2_3087, 3
; %var_2_2322 = shl nsw i64 %var_2_2321, 3
; Matched:%var_2_3089:  %var_2_3089 = add i64 %var_2_3059, %var_2_3088
; %var_2_2323 = add i64 %var_2_2293, %var_2_2322
; Matched:%var_2_3090:  %var_2_3090 = add i64 %var_2_3046, 31
; %var_2_2324 = add i64 %var_2_2280, 31
; Matched:\<badref\>:  store i64 %var_2_3875, i64* %var_2_3, align 8
; store i64 %var_2_2324, i64* %PC, align 8
; Matched:%var_2_1743:  %var_2_1743 = inttoptr i64 %var_2_1741 to double*
; %var_2_2325 = inttoptr i64 %var_2_2323 to double*
; Matched:\<badref\>:  store double %var_2_3055, double* %var_2_3091, align 8
; store double %var_2_2289, double* %var_2_2325, align 8
; Matched:%var_2_4369:  %var_2_4369 = load i64, i64* %RBP.i, align 8
; %var_2_2326 = load i64, i64* %RBP, align 8
; Matched:%var_2_3093:  %var_2_3093 = add i64 %var_2_3092, -152
; %var_2_2327 = add i64 %var_2_2326, -152
%var_2_2328 = load i64, i64* %PC, align 8
%var_2_2329 = add i64 %var_2_2328, 8
store i64 %var_2_2329, i64* %PC, align 8
; Matched:%var_2_3096:  %var_2_3096 = inttoptr i64 %var_2_3093 to i64*
; %var_2_2330 = inttoptr i64 %var_2_2327 to i64*
; Matched:%var_2_3097:  %var_2_3097 = load i64, i64* %var_2_3096, align 8
; %var_2_2331 = load i64, i64* %var_2_2330, align 8
; Matched:\<badref\>:  store i64 %var_2_3097, i64* %var_2_1038, align 1
; store i64 %var_2_2331, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_3098:  %var_2_3098 = add i64 %var_2_3092, -120
; %var_2_2332 = add i64 %var_2_2326, -120
; Matched:%var_2_3593:  %var_2_3593 = add i64 %var_2_3582, 13
; %var_2_2333 = add i64 %var_2_2328, 13
; Matched:\<badref\>:  store i64 %var_2_2919, i64* %var_2_3, align 8
; store i64 %var_2_2333, i64* %PC, align 8
; Matched:%var_2_4377:  %var_2_4377 = inttoptr i64 %var_2_4375 to double*
; %var_2_2334 = inttoptr i64 %var_2_2332 to double*
; Matched:%var_2_3101:  %var_2_3101 = load double, double* %var_2_3100, align 8
; %var_2_2335 = load double, double* %var_2_2334, align 8
; Matched:%var_2_3102:  %var_2_3102 = bitcast i64 %var_2_3097 to double
; %var_2_2336 = bitcast i64 %var_2_2331 to double
; Matched:%var_2_3103:  %var_2_3103 = fsub double %var_2_3101, %var_2_3102
; %var_2_2337 = fsub double %var_2_2335, %var_2_2336
; Matched:\<badref\>:  store double %var_2_4380, double* %var_2_1053, align 1
; store double %var_2_2337, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_1517:  %var_2_1517 = add i64 %var_2_1480, 22
; %var_2_2338 = add i64 %var_2_2328, 22
; Matched:\<badref\>:  store i64 %var_2_1291, i64* %var_2_3, align 8
; store i64 %var_2_2338, i64* %PC, align 8
; Matched:%var_2_4382:  %var_2_4382 = inttoptr i64 %var_2_4375 to double*
; %var_2_2339 = inttoptr i64 %var_2_2332 to double*
; Matched:\<badref\>:  store double %var_2_3103, double* %var_2_3105, align 8
; store double %var_2_2337, double* %var_2_2339, align 8
%var_2_2340 = load i64, i64* %RBP, align 8
%var_2_2341 = add i64 %var_2_2340, -160
%var_2_2342 = load i64, i64* %PC, align 8
%var_2_2343 = add i64 %var_2_2342, 8
store i64 %var_2_2343, i64* %PC, align 8
%var_2_2344 = inttoptr i64 %var_2_2341 to i64*
%var_2_2345 = load i64, i64* %var_2_2344, align 8
; Matched:\<badref\>:  store i64 %var_2_3111, i64* %var_2_1038, align 1
; store i64 %var_2_2345, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_3112:  %var_2_3112 = add i64 %var_2_3106, -128
; %var_2_2346 = add i64 %var_2_2340, -128
; Matched:%var_2_2359:  %var_2_2359 = add i64 %var_2_2348, 13
; %var_2_2347 = add i64 %var_2_2342, 13
; Matched:\<badref\>:  store i64 %var_2_1458, i64* %var_2_3, align 8
; store i64 %var_2_2347, i64* %PC, align 8
; Matched:%var_2_3114:  %var_2_3114 = inttoptr i64 %var_2_3112 to double*
; %var_2_2348 = inttoptr i64 %var_2_2346 to double*
; Matched:%var_2_3115:  %var_2_3115 = load double, double* %var_2_3114, align 8
; %var_2_2349 = load double, double* %var_2_2348, align 8
; Matched:%var_2_4393:  %var_2_4393 = bitcast i64 %var_2_4388 to double
; %var_2_2350 = bitcast i64 %var_2_2345 to double
; Matched:%var_2_3117:  %var_2_3117 = fsub double %var_2_3115, %var_2_3116
; %var_2_2351 = fsub double %var_2_2349, %var_2_2350
; Matched:\<badref\>:  store double %var_2_3117, double* %var_2_1053, align 1
; store double %var_2_2351, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_4255:  %var_2_4255 = add i64 %var_2_4218, 22
; %var_2_2352 = add i64 %var_2_2342, 22
; Matched:\<badref\>:  store i64 %var_2_4029, i64* %var_2_3, align 8
; store i64 %var_2_2352, i64* %PC, align 8
; Matched:%var_2_3119:  %var_2_3119 = inttoptr i64 %var_2_3112 to double*
; %var_2_2353 = inttoptr i64 %var_2_2346 to double*
; Matched:\<badref\>:  store double %var_2_3117, double* %var_2_3119, align 8
; store double %var_2_2351, double* %var_2_2353, align 8
%var_2_2354 = load i64, i64* %RBP, align 8
; Matched:%var_2_4445:  %var_2_4445 = add i64 %var_2_4444, -96
; %var_2_2355 = add i64 %var_2_2354, -96
%var_2_2356 = load i64, i64* %PC, align 8
; Matched:%var_2_4400:  %var_2_4400 = add i64 %var_2_4399, 5
; %var_2_2357 = add i64 %var_2_2356, 5
; Matched:\<badref\>:  store i64 %var_2_4400, i64* %var_2_3, align 8
; store i64 %var_2_2357, i64* %PC, align 8
; Matched:%var_2_4401:  %var_2_4401 = inttoptr i64 %var_2_4398 to i64*
; %var_2_2358 = inttoptr i64 %var_2_2355 to i64*
; Matched:%var_2_4449:  %var_2_4449 = load i64, i64* %var_2_4448, align 8
; %var_2_2359 = load i64, i64* %var_2_2358, align 8
; Matched:%var_2_4450:  %var_2_4450 = load i64, i64* %RAX.i2224, align 8
; %var_2_2360 = load i64, i64* %RAX, align 8
; Matched:%var_2_4451:  %var_2_4451 = xor i64 %var_2_4450, %var_2_4449
; %var_2_2361 = xor i64 %var_2_2360, %var_2_2359
; Matched:\<badref\>:  store i64 %var_2_4451, i64* %RDX.i2239, align 8
; store i64 %var_2_2361, i64* %RDX, align 8
store i8 0, i8* %var_2_16, align 1
; Matched:%var_2_4452:  %var_2_4452 = trunc i64 %var_2_4451 to i32
; %var_2_2362 = trunc i64 %var_2_2361 to i32
; Matched:%var_2_4406:  %var_2_4406 = and i32 %var_2_4405, 255
; %var_2_2363 = and i32 %var_2_2362, 255
; Matched:%var_2_4407:  %var_2_4407 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4406)
; %var_2_2364 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2363) #14
; Matched:%var_2_4455:  %var_2_4455 = trunc i32 %var_2_4454 to i8
; %var_2_2365 = trunc i32 %var_2_2364 to i8
; Matched:%var_2_4456:  %var_2_4456 = and i8 %var_2_4455, 1
; %var_2_2366 = and i8 %var_2_2365, 1
; Matched:%var_2_4457:  %var_2_4457 = xor i8 %var_2_4456, 1
; %var_2_2367 = xor i8 %var_2_2366, 1
; Matched:\<badref\>:  store i8 %var_2_4457, i8* %var_2_21, align 1
; store i8 %var_2_2367, i8* %var_2_23, align 1
; Matched:%var_2_4458:  %var_2_4458 = icmp eq i64 %var_2_4451, 0
; %var_2_2368 = icmp eq i64 %var_2_2361, 0
; Matched:%var_2_4459:  %var_2_4459 = zext i1 %var_2_4458 to i8
; %var_2_2369 = zext i1 %var_2_2368 to i8
; Matched:\<badref\>:  store i8 %var_2_4412, i8* %var_2_30, align 1
; store i8 %var_2_2369, i8* %var_2_32, align 1
; Matched:%var_2_4413:  %var_2_4413 = lshr i64 %var_2_4404, 63
; %var_2_2370 = lshr i64 %var_2_2361, 63
; Matched:%var_2_4461:  %var_2_4461 = trunc i64 %var_2_4460 to i8
; %var_2_2371 = trunc i64 %var_2_2370 to i8
; Matched:\<badref\>:  store i8 %var_2_4461, i8* %var_2_33, align 1
; store i8 %var_2_2371, i8* %var_2_35, align 1
store i8 0, i8* %var_2_41, align 1
store i8 0, i8* %var_2_29, align 1
; Matched:\<badref\>:  store i64 %var_2_4451, i64* %var_2_1038, align 1
; store i64 %var_2_2361, i64* %var_2_94, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_4415:  %var_2_4415 = add i64 %var_2_4397, -120
; %var_2_2372 = add i64 %var_2_2354, -120
; Matched:%var_2_893:  %var_2_893 = add i64 %var_2_878, 23
; %var_2_2373 = add i64 %var_2_2356, 23
; Matched:\<badref\>:  store i64 %var_2_2344, i64* %var_2_3, align 8
; store i64 %var_2_2373, i64* %PC, align 8
; Matched:  %.cast9 = bitcast i64 %var_2_4404 to double
; %.cast9 = bitcast i64 %var_2_2361 to double
; Matched:%var_2_4417:  %var_2_4417 = inttoptr i64 %var_2_4415 to double*
; %var_2_2374 = inttoptr i64 %var_2_2372 to double*
; Matched:%var_2_4418:  %var_2_4418 = load double, double* %var_2_4417, align 8
; %var_2_2375 = load double, double* %var_2_2374, align 8
; Matched:%var_2_4419:  %var_2_4419 = fmul double %.cast9, %var_2_4418
; %var_2_2376 = fmul double %.cast9, %var_2_2375
; Matched:\<badref\>:  store double %var_2_4419, double* %var_2_1037, align 1
; store double %var_2_2376, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_4420:  %var_2_4420 = add i64 %var_2_4397, -88
; %var_2_2377 = add i64 %var_2_2354, -88
; Matched:%var_2_4568:  %var_2_4568 = add i64 %var_2_4546, 28
; %var_2_2378 = add i64 %var_2_2356, 28
; Matched:\<badref\>:  store i64 %var_2_4568, i64* %var_2_3, align 8
; store i64 %var_2_2378, i64* %PC, align 8
; Matched:%var_2_4469:  %var_2_4469 = inttoptr i64 %var_2_4467 to i64*
; %var_2_2379 = inttoptr i64 %var_2_2377 to i64*
; Matched:%var_2_4470:  %var_2_4470 = load i64, i64* %var_2_4469, align 8
; %var_2_2380 = load i64, i64* %var_2_2379, align 8
; Matched:\<badref\>:  store i64 %var_2_4470, i64* %var_2_1054, align 1
; store i64 %var_2_2380, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_4424:  %var_2_4424 = add i64 %var_2_4397, -128
; %var_2_2381 = add i64 %var_2_2354, -128
; Matched:%var_2_4425:  %var_2_4425 = add i64 %var_2_4399, 33
; %var_2_2382 = add i64 %var_2_2356, 33
; Matched:\<badref\>:  store i64 %var_2_4472, i64* %var_2_3, align 8
; store i64 %var_2_2382, i64* %PC, align 8
; Matched:%var_2_4426:  %var_2_4426 = bitcast i64 %var_2_4423 to double
; %var_2_2383 = bitcast i64 %var_2_2380 to double
; Matched:%var_2_4427:  %var_2_4427 = inttoptr i64 %var_2_4424 to double*
; %var_2_2384 = inttoptr i64 %var_2_2381 to double*
; Matched:%var_2_4428:  %var_2_4428 = load double, double* %var_2_4427, align 8
; %var_2_2385 = load double, double* %var_2_2384, align 8
; Matched:%var_2_4429:  %var_2_4429 = fmul double %var_2_4426, %var_2_4428
; %var_2_2386 = fmul double %var_2_2383, %var_2_2385
; Matched:\<badref\>:  store double %var_2_4429, double* %var_2_1053, align 1
; store double %var_2_2386, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_4430:  %var_2_4430 = fsub double %var_2_4419, %var_2_4429
; %var_2_2387 = fsub double %var_2_2376, %var_2_2386
; Matched:\<badref\>:  store double %var_2_4430, double* %var_2_1037, align 1
; store double %var_2_2387, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_2388 = add i64 %var_2_2354, -16
; Matched:%var_2_364:  %var_2_364 = add i64 %var_2_288, 41
; %var_2_2389 = add i64 %var_2_2356, 41
; Matched:\<badref\>:  store i64 %var_2_4479, i64* %var_2_3, align 8
; store i64 %var_2_2389, i64* %PC, align 8
%var_2_2390 = inttoptr i64 %var_2_2388 to i64*
%var_2_2391 = load i64, i64* %var_2_2390, align 8
; Matched:\<badref\>:  store i64 %var_2_3849, i64* %RDX.i2239, align 8
; store i64 %var_2_2391, i64* %RDX, align 8
%var_2_2392 = add i64 %var_2_2354, -36
; Matched:%var_2_4436:  %var_2_4436 = add i64 %var_2_4399, 45
; %var_2_2393 = add i64 %var_2_2356, 45
; Matched:\<badref\>:  store i64 %var_2_4436, i64* %var_2_3, align 8
; store i64 %var_2_2393, i64* %PC, align 8
%var_2_2394 = inttoptr i64 %var_2_2392 to i32*
%var_2_2395 = load i32, i32* %var_2_2394, align 4
%var_2_2396 = sext i32 %var_2_2395 to i64
; Matched:\<badref\>:  store i64 %var_2_4080, i64* %RSI.i2233, align 8
; store i64 %var_2_2396, i64* %RSI, align 8
; Matched:%var_2_4440:  %var_2_4440 = shl nsw i64 %var_2_4439, 3
; %var_2_2397 = shl nsw i64 %var_2_2396, 3
; Matched:%var_2_4441:  %var_2_4441 = add i64 %var_2_4440, %var_2_4434
; %var_2_2398 = add i64 %var_2_2397, %var_2_2391
; Matched:%var_2_4442:  %var_2_4442 = add i64 %var_2_4399, 50
; %var_2_2399 = add i64 %var_2_2356, 50
; Matched:\<badref\>:  store i64 %var_2_4442, i64* %var_2_3, align 8
; store i64 %var_2_2399, i64* %PC, align 8
; Matched:%var_2_4443:  %var_2_4443 = inttoptr i64 %var_2_4441 to double*
; %var_2_2400 = inttoptr i64 %var_2_2398 to double*
; Matched:\<badref\>:  store double %var_2_4430, double* %var_2_4443, align 8
; store double %var_2_2387, double* %var_2_2400, align 8
%var_2_2401 = load i64, i64* %RBP, align 8
; Matched:%var_2_4398:  %var_2_4398 = add i64 %var_2_4397, -96
; %var_2_2402 = add i64 %var_2_2401, -96
%var_2_2403 = load i64, i64* %PC, align 8
; Matched:%var_2_4547:  %var_2_4547 = add i64 %var_2_4546, 5
; %var_2_2404 = add i64 %var_2_2403, 5
; Matched:\<badref\>:  store i64 %var_2_4547, i64* %var_2_3, align 8
; store i64 %var_2_2404, i64* %PC, align 8
; Matched:%var_2_4448:  %var_2_4448 = inttoptr i64 %var_2_4445 to i64*
; %var_2_2405 = inttoptr i64 %var_2_2402 to i64*
; Matched:%var_2_4402:  %var_2_4402 = load i64, i64* %var_2_4401, align 8
; %var_2_2406 = load i64, i64* %var_2_2405, align 8
; Matched:%var_2_4403:  %var_2_4403 = load i64, i64* %RAX.i2224, align 8
; %var_2_2407 = load i64, i64* %RAX, align 8
; Matched:%var_2_4404:  %var_2_4404 = xor i64 %var_2_4403, %var_2_4402
; %var_2_2408 = xor i64 %var_2_2407, %var_2_2406
; Matched:\<badref\>:  store i64 %var_2_4404, i64* %RDX.i2239, align 8
; store i64 %var_2_2408, i64* %RDX, align 8
store i8 0, i8* %var_2_16, align 1
; Matched:%var_2_4405:  %var_2_4405 = trunc i64 %var_2_4404 to i32
; %var_2_2409 = trunc i64 %var_2_2408 to i32
; Matched:%var_2_4453:  %var_2_4453 = and i32 %var_2_4452, 255
; %var_2_2410 = and i32 %var_2_2409, 255
; Matched:%var_2_4454:  %var_2_4454 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4453)
; %var_2_2411 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2410) #14
; Matched:%var_2_4408:  %var_2_4408 = trunc i32 %var_2_4407 to i8
; %var_2_2412 = trunc i32 %var_2_2411 to i8
; Matched:%var_2_4409:  %var_2_4409 = and i8 %var_2_4408, 1
; %var_2_2413 = and i8 %var_2_2412, 1
; Matched:%var_2_4410:  %var_2_4410 = xor i8 %var_2_4409, 1
; %var_2_2414 = xor i8 %var_2_2413, 1
; Matched:\<badref\>:  store i8 %var_2_4410, i8* %var_2_21, align 1
; store i8 %var_2_2414, i8* %var_2_23, align 1
; Matched:%var_2_4411:  %var_2_4411 = icmp eq i64 %var_2_4404, 0
; %var_2_2415 = icmp eq i64 %var_2_2408, 0
; Matched:%var_2_4412:  %var_2_4412 = zext i1 %var_2_4411 to i8
; %var_2_2416 = zext i1 %var_2_2415 to i8
; Matched:\<badref\>:  store i8 %var_2_4459, i8* %var_2_30, align 1
; store i8 %var_2_2416, i8* %var_2_32, align 1
; Matched:%var_2_4460:  %var_2_4460 = lshr i64 %var_2_4451, 63
; %var_2_2417 = lshr i64 %var_2_2408, 63
; Matched:%var_2_4414:  %var_2_4414 = trunc i64 %var_2_4413 to i8
; %var_2_2418 = trunc i64 %var_2_2417 to i8
; Matched:\<badref\>:  store i8 %var_2_4414, i8* %var_2_33, align 1
; store i8 %var_2_2418, i8* %var_2_35, align 1
store i8 0, i8* %var_2_41, align 1
store i8 0, i8* %var_2_29, align 1
; Matched:\<badref\>:  store i64 %var_2_4404, i64* %var_2_1038, align 1
; store i64 %var_2_2408, i64* %var_2_94, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_4462:  %var_2_4462 = add i64 %var_2_4444, -128
; %var_2_2419 = add i64 %var_2_2401, -128
; Matched:%var_2_1897:  %var_2_1897 = add i64 %var_2_1880, 23
; %var_2_2420 = add i64 %var_2_2403, 23
; Matched:\<badref\>:  store i64 %var_2_1897, i64* %var_2_3, align 8
; store i64 %var_2_2420, i64* %PC, align 8
; Matched:  %.cast10 = bitcast i64 %var_2_4451 to double
; %.cast10 = bitcast i64 %var_2_2408 to double
; Matched:%var_2_4464:  %var_2_4464 = inttoptr i64 %var_2_4462 to double*
; %var_2_2421 = inttoptr i64 %var_2_2419 to double*
; Matched:%var_2_4465:  %var_2_4465 = load double, double* %var_2_4464, align 8
; %var_2_2422 = load double, double* %var_2_2421, align 8
; Matched:%var_2_4466:  %var_2_4466 = fmul double %.cast10, %var_2_4465
; %var_2_2423 = fmul double %.cast10, %var_2_2422
; Matched:\<badref\>:  store double %var_2_4466, double* %var_2_1037, align 1
; store double %var_2_2423, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_4467:  %var_2_4467 = add i64 %var_2_4444, -88
; %var_2_2424 = add i64 %var_2_2401, -88
; Matched:%var_2_4421:  %var_2_4421 = add i64 %var_2_4399, 28
; %var_2_2425 = add i64 %var_2_2403, 28
; Matched:\<badref\>:  store i64 %var_2_4421, i64* %var_2_3, align 8
; store i64 %var_2_2425, i64* %PC, align 8
; Matched:%var_2_4422:  %var_2_4422 = inttoptr i64 %var_2_4420 to i64*
; %var_2_2426 = inttoptr i64 %var_2_2424 to i64*
; Matched:%var_2_4423:  %var_2_4423 = load i64, i64* %var_2_4422, align 8
; %var_2_2427 = load i64, i64* %var_2_2426, align 8
; Matched:\<badref\>:  store i64 %var_2_4423, i64* %var_2_1054, align 1
; store i64 %var_2_2427, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_4471:  %var_2_4471 = add i64 %var_2_4444, -120
; %var_2_2428 = add i64 %var_2_2401, -120
; Matched:%var_2_4472:  %var_2_4472 = add i64 %var_2_4446, 33
; %var_2_2429 = add i64 %var_2_2403, 33
; Matched:\<badref\>:  store i64 %var_2_4425, i64* %var_2_3, align 8
; store i64 %var_2_2429, i64* %PC, align 8
; Matched:%var_2_4473:  %var_2_4473 = bitcast i64 %var_2_4470 to double
; %var_2_2430 = bitcast i64 %var_2_2427 to double
; Matched:%var_2_4474:  %var_2_4474 = inttoptr i64 %var_2_4471 to double*
; %var_2_2431 = inttoptr i64 %var_2_2428 to double*
; Matched:%var_2_4475:  %var_2_4475 = load double, double* %var_2_4474, align 8
; %var_2_2432 = load double, double* %var_2_2431, align 8
; Matched:%var_2_4476:  %var_2_4476 = fmul double %var_2_4473, %var_2_4475
; %var_2_2433 = fmul double %var_2_2430, %var_2_2432
; Matched:\<badref\>:  store double %var_2_4476, double* %var_2_1053, align 1
; store double %var_2_2433, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_4477:  %var_2_4477 = fadd double %var_2_4466, %var_2_4476
; %var_2_2434 = fadd double %var_2_2423, %var_2_2433
; Matched:\<badref\>:  store double %var_2_4477, double* %var_2_1037, align 1
; store double %var_2_2434, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_2435 = add i64 %var_2_2401, -16
; Matched:%var_2_3955:  %var_2_3955 = add i64 %var_2_3879, 41
; %var_2_2436 = add i64 %var_2_2403, 41
; Matched:\<badref\>:  store i64 %var_2_4432, i64* %var_2_3, align 8
; store i64 %var_2_2436, i64* %PC, align 8
%var_2_2437 = inttoptr i64 %var_2_2435 to i64*
%var_2_2438 = load i64, i64* %var_2_2437, align 8
; Matched:\<badref\>:  store i64 %var_2_4481, i64* %RAX.i2224, align 8
; store i64 %var_2_2438, i64* %RAX, align 8
%var_2_2439 = add i64 %var_2_2401, -36
; Matched:%var_2_2791:  %var_2_2791 = add i64 %var_2_2715, 44
; %var_2_2440 = add i64 %var_2_2403, 44
; Matched:\<badref\>:  store i64 %var_2_4483, i64* %var_2_3, align 8
; store i64 %var_2_2440, i64* %PC, align 8
%var_2_2441 = inttoptr i64 %var_2_2439 to i32*
%var_2_2442 = load i32, i32* %var_2_2441, align 4
%var_2_2443 = add i32 %var_2_2442, 1
; Matched:%var_2_4487:  %var_2_4487 = zext i32 %var_2_4486 to i64
; %var_2_2444 = zext i32 %var_2_2443 to i64
; Matched:\<badref\>:  store i64 %var_2_4487, i64* %RCX.i2236, align 8
; store i64 %var_2_2444, i64* %RCX, align 8
; Matched:%var_2_4488:  %var_2_4488 = icmp eq i32 %var_2_4485, -1
; %var_2_2445 = icmp eq i32 %var_2_2442, -1
; Matched:%var_2_4489:  %var_2_4489 = icmp eq i32 %var_2_4486, 0
; %var_2_2446 = icmp eq i32 %var_2_2443, 0
; Matched:%var_2_4490:  %var_2_4490 = or i1 %var_2_4488, %var_2_4489
; %var_2_2447 = or i1 %var_2_2445, %var_2_2446
; Matched:%var_2_4491:  %var_2_4491 = zext i1 %var_2_4490 to i8
; %var_2_2448 = zext i1 %var_2_2447 to i8
; Matched:\<badref\>:  store i8 %var_2_4491, i8* %var_2_14, align 1
; store i8 %var_2_2448, i8* %var_2_16, align 1
; Matched:%var_2_4492:  %var_2_4492 = and i32 %var_2_4486, 255
; %var_2_2449 = and i32 %var_2_2443, 255
; Matched:%var_2_4493:  %var_2_4493 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4492)
; %var_2_2450 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2449) #14
; Matched:%var_2_4494:  %var_2_4494 = trunc i32 %var_2_4493 to i8
; %var_2_2451 = trunc i32 %var_2_2450 to i8
; Matched:%var_2_2958:  %var_2_2958 = and i8 %var_2_2957, 1
; %var_2_2452 = and i8 %var_2_2451, 1
; Matched:%var_2_2846:  %var_2_2846 = xor i8 %var_2_2845, 1
; %var_2_2453 = xor i8 %var_2_2452, 1
; Matched:\<badref\>:  store i8 %var_2_2959, i8* %var_2_21, align 1
; store i8 %var_2_2453, i8* %var_2_23, align 1
; Matched:%var_2_4497:  %var_2_4497 = xor i32 %var_2_4486, %var_2_4485
; %var_2_2454 = xor i32 %var_2_2443, %var_2_2442
; Matched:%var_2_4498:  %var_2_4498 = lshr i32 %var_2_4497, 4
; %var_2_2455 = lshr i32 %var_2_2454, 4
; Matched:%var_2_4499:  %var_2_4499 = trunc i32 %var_2_4498 to i8
; %var_2_2456 = trunc i32 %var_2_2455 to i8
; Matched:%var_2_4500:  %var_2_4500 = and i8 %var_2_4499, 1
; %var_2_2457 = and i8 %var_2_2456, 1
; Matched:\<badref\>:  store i8 %var_2_4500, i8* %var_2_27, align 1
; store i8 %var_2_2457, i8* %var_2_29, align 1
; Matched:%var_2_4501:  %var_2_4501 = zext i1 %var_2_4489 to i8
; %var_2_2458 = zext i1 %var_2_2446 to i8
; Matched:\<badref\>:  store i8 %var_2_4501, i8* %var_2_30, align 1
; store i8 %var_2_2458, i8* %var_2_32, align 1
; Matched:%var_2_4129:  %var_2_4129 = lshr i32 %var_2_4113, 31
; %var_2_2459 = lshr i32 %var_2_2443, 31
; Matched:%var_2_4503:  %var_2_4503 = trunc i32 %var_2_4502 to i8
; %var_2_2460 = trunc i32 %var_2_2459 to i8
; Matched:\<badref\>:  store i8 %var_2_4503, i8* %var_2_33, align 1
; store i8 %var_2_2460, i8* %var_2_35, align 1
; Matched:%var_2_4504:  %var_2_4504 = lshr i32 %var_2_4485, 31
; %var_2_2461 = lshr i32 %var_2_2442, 31
; Matched:%var_2_2968:  %var_2_2968 = xor i32 %var_2_2965, %var_2_2967
; %var_2_2462 = xor i32 %var_2_2459, %var_2_2461
; Matched:%var_2_2856:  %var_2_2856 = add nuw nsw i32 %var_2_2855, %var_2_2852
; %var_2_2463 = add nuw nsw i32 %var_2_2462, %var_2_2459
; Matched:%var_2_656:  %var_2_656 = icmp eq i32 %var_2_655, 2
; %var_2_2464 = icmp eq i32 %var_2_2463, 2
; Matched:%var_2_2858:  %var_2_2858 = zext i1 %var_2_2857 to i8
; %var_2_2465 = zext i1 %var_2_2464 to i8
; Matched:\<badref\>:  store i8 %var_2_657, i8* %var_2_39, align 1
; store i8 %var_2_2465, i8* %var_2_41, align 1
%var_2_2466 = sext i32 %var_2_2443 to i64
; Matched:\<badref\>:  store i64 %var_2_2972, i64* %RDX.i2239, align 8
; store i64 %var_2_2466, i64* %RDX, align 8
; Matched:%var_2_4510:  %var_2_4510 = shl nsw i64 %var_2_4509, 3
; %var_2_2467 = shl nsw i64 %var_2_2466, 3
; Matched:%var_2_4511:  %var_2_4511 = add i64 %var_2_4481, %var_2_4510
; %var_2_2468 = add i64 %var_2_2438, %var_2_2467
; Matched:%var_2_4512:  %var_2_4512 = add i64 %var_2_4446, 55
; %var_2_2469 = add i64 %var_2_2403, 55
; Matched:\<badref\>:  store i64 %var_2_4512, i64* %var_2_3, align 8
; store i64 %var_2_2469, i64* %PC, align 8
; Matched:%var_2_4513:  %var_2_4513 = inttoptr i64 %var_2_4511 to double*
; %var_2_2470 = inttoptr i64 %var_2_2468 to double*
; Matched:\<badref\>:  store double %var_2_4477, double* %var_2_4513, align 8
; store double %var_2_2434, double* %var_2_2470, align 8
%var_2_2471 = load i64, i64* %RBP, align 8
%var_2_2472 = add i64 %var_2_2471, -136
%var_2_2473 = load i64, i64* %PC, align 8
%var_2_2474 = add i64 %var_2_2473, 8
store i64 %var_2_2474, i64* %PC, align 8
%var_2_2475 = inttoptr i64 %var_2_2472 to i64*
%var_2_2476 = load i64, i64* %var_2_2475, align 8
store i64 %var_2_2476, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_2477 = add i64 %var_2_2471, -176
; Matched:%var_2_4646:  %var_2_4646 = add i64 %var_2_4641, 16
; %var_2_2478 = add i64 %var_2_2473, 16
; Matched:\<badref\>:  store i64 %var_2_4646, i64* %var_2_3, align 8
; store i64 %var_2_2478, i64* %PC, align 8
%var_2_2479 = bitcast i64 %var_2_2476 to double
%var_2_2480 = inttoptr i64 %var_2_2477 to double*
%var_2_2481 = load double, double* %var_2_2480, align 8
%var_2_2482 = fsub double %var_2_2479, %var_2_2481
store double %var_2_2482, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_4526:  %var_2_4526 = add i64 %var_2_4514, -120
; %var_2_2483 = add i64 %var_2_2471, -120
; Matched:%var_2_3228:  %var_2_3228 = add i64 %var_2_3217, 21
; %var_2_2484 = add i64 %var_2_2473, 21
; Matched:\<badref\>:  store i64 %var_2_4313, i64* %var_2_3, align 8
; store i64 %var_2_2484, i64* %PC, align 8
; Matched:%var_2_1831:  %var_2_1831 = inttoptr i64 %var_2_1829 to double*
; %var_2_2485 = inttoptr i64 %var_2_2483 to double*
; Matched:\<badref\>:  store double %var_2_1828, double* %var_2_1831, align 8
; store double %var_2_2482, double* %var_2_2485, align 8
%var_2_2486 = load i64, i64* %RBP, align 8
%var_2_2487 = add i64 %var_2_2486, -144
%var_2_2488 = load i64, i64* %PC, align 8
%var_2_2489 = add i64 %var_2_2488, 8
store i64 %var_2_2489, i64* %PC, align 8
%var_2_2490 = inttoptr i64 %var_2_2487 to i64*
%var_2_2491 = load i64, i64* %var_2_2490, align 8
store i64 %var_2_2491, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_2492 = add i64 %var_2_2486, -168
; Matched:%var_2_883:  %var_2_883 = add i64 %var_2_878, 16
; %var_2_2493 = add i64 %var_2_2488, 16
; Matched:\<badref\>:  store i64 %var_2_883, i64* %var_2_3, align 8
; store i64 %var_2_2493, i64* %PC, align 8
%var_2_2494 = bitcast i64 %var_2_2491 to double
%var_2_2495 = inttoptr i64 %var_2_2492 to double*
%var_2_2496 = load double, double* %var_2_2495, align 8
%var_2_2497 = fadd double %var_2_2494, %var_2_2496
store double %var_2_2497, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_1844:  %var_2_1844 = add i64 %var_2_1832, -128
; %var_2_2498 = add i64 %var_2_2486, -128
; Matched:%var_2_3243:  %var_2_3243 = add i64 %var_2_3232, 21
; %var_2_2499 = add i64 %var_2_2488, 21
; Matched:\<badref\>:  store i64 %var_2_3243, i64* %var_2_3, align 8
; store i64 %var_2_2499, i64* %PC, align 8
; Matched:%var_2_1846:  %var_2_1846 = inttoptr i64 %var_2_1844 to double*
; %var_2_2500 = inttoptr i64 %var_2_2498 to double*
; Matched:\<badref\>:  store double %var_2_1843, double* %var_2_1846, align 8
; store double %var_2_2497, double* %var_2_2500, align 8
%var_2_2501 = load i64, i64* %RBP, align 8
%var_2_2502 = add i64 %var_2_2501, -72
%var_2_2503 = load i64, i64* %PC, align 8
; Matched:%var_2_1772:  %var_2_1772 = add i64 %var_2_1771, 5
; %var_2_2504 = add i64 %var_2_2503, 5
; Matched:\<badref\>:  store i64 %var_2_1772, i64* %var_2_3, align 8
; store i64 %var_2_2504, i64* %PC, align 8
%var_2_2505 = inttoptr i64 %var_2_2502 to i64*
%var_2_2506 = load i64, i64* %var_2_2505, align 8
; Matched:\<badref\>:  store i64 %var_2_1967, i64* %var_2_1038, align 1
; store i64 %var_2_2506, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_4550:  %var_2_4550 = add i64 %var_2_4544, -120
; %var_2_2507 = add i64 %var_2_2501, -120
; Matched:%var_2_2383:  %var_2_2383 = add i64 %var_2_2376, 10
; %var_2_2508 = add i64 %var_2_2503, 10
; Matched:\<badref\>:  store i64 %var_2_3413, i64* %var_2_3, align 8
; store i64 %var_2_2508, i64* %PC, align 8
; Matched:%var_2_4552:  %var_2_4552 = bitcast i64 %var_2_4549 to double
; %var_2_2509 = bitcast i64 %var_2_2506 to double
; Matched:%var_2_4553:  %var_2_4553 = inttoptr i64 %var_2_4550 to double*
; %var_2_2510 = inttoptr i64 %var_2_2507 to double*
; Matched:%var_2_4554:  %var_2_4554 = load double, double* %var_2_4553, align 8
; %var_2_2511 = load double, double* %var_2_2510, align 8
; Matched:%var_2_3256:  %var_2_3256 = fmul double %var_2_3253, %var_2_3255
; %var_2_2512 = fmul double %var_2_2509, %var_2_2511
; Matched:\<badref\>:  store double %var_2_3256, double* %var_2_1037, align 1
; store double %var_2_2512, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_2513 = add i64 %var_2_2501, -80
; Matched:%var_2_3169:  %var_2_3169 = add i64 %var_2_3158, 15
; %var_2_2514 = add i64 %var_2_2503, 15
; Matched:\<badref\>:  store i64 %var_2_3169, i64* %var_2_3, align 8
; store i64 %var_2_2514, i64* %PC, align 8
%var_2_2515 = inttoptr i64 %var_2_2513 to i64*
%var_2_2516 = load i64, i64* %var_2_2515, align 8
; Matched:\<badref\>:  store i64 %var_2_3296, i64* %var_2_1054, align 1
; store i64 %var_2_2516, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_4560:  %var_2_4560 = add i64 %var_2_4544, -128
; %var_2_2517 = add i64 %var_2_2501, -128
; Matched:%var_2_1786:  %var_2_1786 = add i64 %var_2_1771, 20
; %var_2_2518 = add i64 %var_2_2503, 20
; Matched:\<badref\>:  store i64 %var_2_1786, i64* %var_2_3, align 8
; store i64 %var_2_2518, i64* %PC, align 8
; Matched:%var_2_4562:  %var_2_4562 = bitcast i64 %var_2_4559 to double
; %var_2_2519 = bitcast i64 %var_2_2516 to double
; Matched:%var_2_4563:  %var_2_4563 = inttoptr i64 %var_2_4560 to double*
; %var_2_2520 = inttoptr i64 %var_2_2517 to double*
; Matched:%var_2_4564:  %var_2_4564 = load double, double* %var_2_4563, align 8
; %var_2_2521 = load double, double* %var_2_2520, align 8
; Matched:%var_2_3266:  %var_2_3266 = fmul double %var_2_3263, %var_2_3265
; %var_2_2522 = fmul double %var_2_2519, %var_2_2521
; Matched:\<badref\>:  store double %var_2_3266, double* %var_2_1053, align 1
; store double %var_2_2522, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_3267:  %var_2_3267 = fsub double %var_2_3256, %var_2_3266
; %var_2_2523 = fsub double %var_2_2512, %var_2_2522
; Matched:\<badref\>:  store double %var_2_3267, double* %var_2_1037, align 1
; store double %var_2_2523, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_2524 = add i64 %var_2_2501, -16
; Matched:%var_2_3144:  %var_2_3144 = add i64 %var_2_3122, 28
; %var_2_2525 = add i64 %var_2_2503, 28
; Matched:\<badref\>:  store i64 %var_2_3144, i64* %var_2_3, align 8
; store i64 %var_2_2525, i64* %PC, align 8
%var_2_2526 = inttoptr i64 %var_2_2524 to i64*
%var_2_2527 = load i64, i64* %var_2_2526, align 8
; Matched:\<badref\>:  store i64 %var_2_4570, i64* %RAX.i2224, align 8
; store i64 %var_2_2527, i64* %RAX, align 8
%var_2_2528 = add i64 %var_2_2501, -32
; Matched:%var_2_1991:  %var_2_1991 = add i64 %var_2_1964, 32
; %var_2_2529 = add i64 %var_2_2503, 32
; Matched:\<badref\>:  store i64 %var_2_3398, i64* %var_2_3, align 8
; store i64 %var_2_2529, i64* %PC, align 8
%var_2_2530 = inttoptr i64 %var_2_2528 to i32*
%var_2_2531 = load i32, i32* %var_2_2530, align 4
%var_2_2532 = sext i32 %var_2_2531 to i64
; Matched:\<badref\>:  store i64 %var_2_2702, i64* %RDX.i2239, align 8
; store i64 %var_2_2532, i64* %RDX, align 8
; Matched:%var_2_3277:  %var_2_3277 = shl nsw i64 %var_2_3276, 3
; %var_2_2533 = shl nsw i64 %var_2_2532, 3
; Matched:%var_2_3278:  %var_2_3278 = add i64 %var_2_3277, %var_2_3271
; %var_2_2534 = add i64 %var_2_2533, %var_2_2527
; Matched:%var_2_4578:  %var_2_4578 = add i64 %var_2_4546, 37
; %var_2_2535 = add i64 %var_2_2503, 37
; Matched:\<badref\>:  store i64 %var_2_4578, i64* %var_2_3, align 8
; store i64 %var_2_2535, i64* %PC, align 8
; Matched:%var_2_4579:  %var_2_4579 = inttoptr i64 %var_2_4577 to double*
; %var_2_2536 = inttoptr i64 %var_2_2534 to double*
; Matched:\<badref\>:  store double %var_2_3267, double* %var_2_3280, align 8
; store double %var_2_2523, double* %var_2_2536, align 8
%var_2_2537 = load i64, i64* %RBP, align 8
%var_2_2538 = add i64 %var_2_2537, -72
%var_2_2539 = load i64, i64* %PC, align 8
; Matched:%var_2_1881:  %var_2_1881 = add i64 %var_2_1880, 5
; %var_2_2540 = add i64 %var_2_2539, 5
; Matched:\<badref\>:  store i64 %var_2_1881, i64* %var_2_3, align 8
; store i64 %var_2_2540, i64* %PC, align 8
%var_2_2541 = inttoptr i64 %var_2_2538 to i64*
%var_2_2542 = load i64, i64* %var_2_2541, align 8
; Matched:\<badref\>:  store i64 %var_2_1852, i64* %var_2_1038, align 1
; store i64 %var_2_2542, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_4586:  %var_2_4586 = add i64 %var_2_4580, -128
; %var_2_2543 = add i64 %var_2_2537, -128
; Matched:%var_2_3127:  %var_2_3127 = add i64 %var_2_3122, 10
; %var_2_2544 = add i64 %var_2_2539, 10
; Matched:\<badref\>:  store i64 %var_2_43, i64* %var_2_3, align 8
; store i64 %var_2_2544, i64* %PC, align 8
; Matched:%var_2_4588:  %var_2_4588 = bitcast i64 %var_2_4585 to double
; %var_2_2545 = bitcast i64 %var_2_2542 to double
; Matched:%var_2_4589:  %var_2_4589 = inttoptr i64 %var_2_4586 to double*
; %var_2_2546 = inttoptr i64 %var_2_2543 to double*
; Matched:%var_2_4590:  %var_2_4590 = load double, double* %var_2_4589, align 8
; %var_2_2547 = load double, double* %var_2_2546, align 8
; Matched:%var_2_3292:  %var_2_3292 = fmul double %var_2_3289, %var_2_3291
; %var_2_2548 = fmul double %var_2_2545, %var_2_2547
; Matched:\<badref\>:  store double %var_2_3292, double* %var_2_1037, align 1
; store double %var_2_2548, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_2549 = add i64 %var_2_2537, -80
; Matched:%var_2_2388:  %var_2_2388 = add i64 %var_2_2376, 15
; %var_2_2550 = add i64 %var_2_2539, 15
; Matched:\<badref\>:  store i64 %var_2_2388, i64* %var_2_3, align 8
; store i64 %var_2_2550, i64* %PC, align 8
%var_2_2551 = inttoptr i64 %var_2_2549 to i64*
%var_2_2552 = load i64, i64* %var_2_2551, align 8
; Matched:\<badref\>:  store i64 %var_2_4559, i64* %var_2_1054, align 1
; store i64 %var_2_2552, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_4596:  %var_2_4596 = add i64 %var_2_4580, -120
; %var_2_2553 = add i64 %var_2_2537, -120
; Matched:%var_2_3423:  %var_2_3423 = add i64 %var_2_3408, 20
; %var_2_2554 = add i64 %var_2_2539, 20
; Matched:\<badref\>:  store i64 %var_2_3423, i64* %var_2_3, align 8
; store i64 %var_2_2554, i64* %PC, align 8
; Matched:%var_2_4598:  %var_2_4598 = bitcast i64 %var_2_4595 to double
; %var_2_2555 = bitcast i64 %var_2_2552 to double
; Matched:%var_2_4599:  %var_2_4599 = inttoptr i64 %var_2_4596 to double*
; %var_2_2556 = inttoptr i64 %var_2_2553 to double*
; Matched:%var_2_4600:  %var_2_4600 = load double, double* %var_2_4599, align 8
; %var_2_2557 = load double, double* %var_2_2556, align 8
; Matched:%var_2_3302:  %var_2_3302 = fmul double %var_2_3299, %var_2_3301
; %var_2_2558 = fmul double %var_2_2555, %var_2_2557
; Matched:\<badref\>:  store double %var_2_3302, double* %var_2_1053, align 1
; store double %var_2_2558, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_3303:  %var_2_3303 = fadd double %var_2_3292, %var_2_3302
; %var_2_2559 = fadd double %var_2_2548, %var_2_2558
; Matched:\<badref\>:  store double %var_2_3303, double* %var_2_1037, align 1
; store double %var_2_2559, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_2560 = add i64 %var_2_2537, -16
; Matched:%var_2_3394:  %var_2_3394 = add i64 %var_2_3372, 28
; %var_2_2561 = add i64 %var_2_2539, 28
; Matched:\<badref\>:  store i64 %var_2_3394, i64* %var_2_3, align 8
; store i64 %var_2_2561, i64* %PC, align 8
%var_2_2562 = inttoptr i64 %var_2_2560 to i64*
%var_2_2563 = load i64, i64* %var_2_2562, align 8
; Matched:\<badref\>:  store i64 %var_2_4606, i64* %RAX.i2224, align 8
; store i64 %var_2_2563, i64* %RAX, align 8
%var_2_2564 = add i64 %var_2_2537, -32
; Matched:%var_2_3184:  %var_2_3184 = add i64 %var_2_3158, 31
; %var_2_2565 = add i64 %var_2_2539, 31
; Matched:\<badref\>:  store i64 %var_2_3184, i64* %var_2_3, align 8
; store i64 %var_2_2565, i64* %PC, align 8
%var_2_2566 = inttoptr i64 %var_2_2564 to i32*
%var_2_2567 = load i32, i32* %var_2_2566, align 4
%var_2_2568 = add i32 %var_2_2567, 1
; Matched:%var_2_4036:  %var_2_4036 = zext i32 %var_2_4035 to i64
; %var_2_2569 = zext i32 %var_2_2568 to i64
; Matched:\<badref\>:  store i64 %var_2_4036, i64* %RCX.i2236, align 8
; store i64 %var_2_2569, i64* %RCX, align 8
; Matched:%var_2_333:  %var_2_333 = icmp eq i32 %var_2_330, -1
; %var_2_2570 = icmp eq i32 %var_2_2567, -1
; Matched:%var_2_447:  %var_2_447 = icmp eq i32 %var_2_444, 0
; %var_2_2571 = icmp eq i32 %var_2_2568, 0
; Matched:%var_2_448:  %var_2_448 = or i1 %var_2_446, %var_2_447
; %var_2_2572 = or i1 %var_2_2570, %var_2_2571
; Matched:%var_2_449:  %var_2_449 = zext i1 %var_2_448 to i8
; %var_2_2573 = zext i1 %var_2_2572 to i8
; Matched:\<badref\>:  store i8 %var_2_336, i8* %var_2_14, align 1
; store i8 %var_2_2573, i8* %var_2_16, align 1
; Matched:%var_2_902:  %var_2_902 = and i32 %var_2_896, 255
; %var_2_2574 = and i32 %var_2_2568, 255
; Matched:%var_2_451:  %var_2_451 = tail call i32 @llvm.ctpop.i32(i32 %var_2_450)
; %var_2_2575 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2574) #14
; Matched:%var_2_904:  %var_2_904 = trunc i32 %var_2_903 to i8
; %var_2_2576 = trunc i32 %var_2_2575 to i8
; Matched:%var_2_340:  %var_2_340 = and i8 %var_2_339, 1
; %var_2_2577 = and i8 %var_2_2576, 1
; Matched:%var_2_341:  %var_2_341 = xor i8 %var_2_340, 1
; %var_2_2578 = xor i8 %var_2_2577, 1
; Matched:\<badref\>:  store i8 %var_2_454, i8* %var_2_21, align 1
; store i8 %var_2_2578, i8* %var_2_23, align 1
; Matched:%var_2_907:  %var_2_907 = xor i32 %var_2_896, %var_2_895
; %var_2_2579 = xor i32 %var_2_2568, %var_2_2567
; Matched:%var_2_908:  %var_2_908 = lshr i32 %var_2_907, 4
; %var_2_2580 = lshr i32 %var_2_2579, 4
; Matched:%var_2_909:  %var_2_909 = trunc i32 %var_2_908 to i8
; %var_2_2581 = trunc i32 %var_2_2580 to i8
; Matched:%var_2_910:  %var_2_910 = and i8 %var_2_909, 1
; %var_2_2582 = and i8 %var_2_2581, 1
; Matched:\<badref\>:  store i8 %var_2_910, i8* %var_2_27, align 1
; store i8 %var_2_2582, i8* %var_2_29, align 1
; Matched:%var_2_911:  %var_2_911 = zext i1 %var_2_899 to i8
; %var_2_2583 = zext i1 %var_2_2571 to i8
; Matched:\<badref\>:  store i8 %var_2_911, i8* %var_2_30, align 1
; store i8 %var_2_2583, i8* %var_2_32, align 1
; Matched:%var_2_347:  %var_2_347 = lshr i32 %var_2_331, 31
; %var_2_2584 = lshr i32 %var_2_2568, 31
; Matched:%var_2_348:  %var_2_348 = trunc i32 %var_2_347 to i8
; %var_2_2585 = trunc i32 %var_2_2584 to i8
; Matched:\<badref\>:  store i8 %var_2_913, i8* %var_2_33, align 1
; store i8 %var_2_2585, i8* %var_2_35, align 1
; Matched:%var_2_914:  %var_2_914 = lshr i32 %var_2_895, 31
; %var_2_2586 = lshr i32 %var_2_2567, 31
; Matched:%var_2_1429:  %var_2_1429 = xor i32 %var_2_1426, %var_2_1428
; %var_2_2587 = xor i32 %var_2_2584, %var_2_2586
; Matched:%var_2_351:  %var_2_351 = add nuw nsw i32 %var_2_350, %var_2_347
; %var_2_2588 = add nuw nsw i32 %var_2_2587, %var_2_2584
; Matched:%var_2_917:  %var_2_917 = icmp eq i32 %var_2_916, 2
; %var_2_2589 = icmp eq i32 %var_2_2588, 2
; Matched:%var_2_918:  %var_2_918 = zext i1 %var_2_917 to i8
; %var_2_2590 = zext i1 %var_2_2589 to i8
; Matched:\<badref\>:  store i8 %var_2_353, i8* %var_2_39, align 1
; store i8 %var_2_2590, i8* %var_2_41, align 1
%var_2_2591 = sext i32 %var_2_2568 to i64
; Matched:\<badref\>:  store i64 %var_2_1433, i64* %RDX.i2239, align 8
; store i64 %var_2_2591, i64* %RDX, align 8
; Matched:%var_2_3336:  %var_2_3336 = shl nsw i64 %var_2_3335, 3
; %var_2_2592 = shl nsw i64 %var_2_2591, 3
; Matched:%var_2_4636:  %var_2_4636 = add i64 %var_2_4606, %var_2_4635
; %var_2_2593 = add i64 %var_2_2563, %var_2_2592
; Matched:%var_2_3213:  %var_2_3213 = add i64 %var_2_3158, 42
; %var_2_2594 = add i64 %var_2_2539, 42
; Matched:\<badref\>:  store i64 %var_2_3463, i64* %var_2_3, align 8
; store i64 %var_2_2594, i64* %PC, align 8
; Matched:%var_2_4638:  %var_2_4638 = inttoptr i64 %var_2_4636 to double*
; %var_2_2595 = inttoptr i64 %var_2_2593 to double*
; Matched:\<badref\>:  store double %var_2_4602, double* %var_2_4638, align 8
; store double %var_2_2559, double* %var_2_2595, align 8
%var_2_2596 = load i64, i64* %RBP, align 8
%var_2_2597 = add i64 %var_2_2596, -136
%var_2_2598 = load i64, i64* %PC, align 8
%var_2_2599 = add i64 %var_2_2598, 8
store i64 %var_2_2599, i64* %PC, align 8
%var_2_2600 = inttoptr i64 %var_2_2597 to i64*
%var_2_2601 = load i64, i64* %var_2_2600, align 8
store i64 %var_2_2601, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_2602 = add i64 %var_2_2596, -176
; Matched:%var_2_858:  %var_2_858 = add i64 %var_2_853, 16
; %var_2_2603 = add i64 %var_2_2598, 16
; Matched:\<badref\>:  store i64 %var_2_858, i64* %var_2_3, align 8
; store i64 %var_2_2603, i64* %PC, align 8
%var_2_2604 = bitcast i64 %var_2_2601 to double
%var_2_2605 = inttoptr i64 %var_2_2602 to double*
%var_2_2606 = load double, double* %var_2_2605, align 8
%var_2_2607 = fadd double %var_2_2604, %var_2_2606
store double %var_2_2607, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_3352:  %var_2_3352 = add i64 %var_2_3340, -120
; %var_2_2608 = add i64 %var_2_2596, -120
; Matched:%var_2_4527:  %var_2_4527 = add i64 %var_2_4516, 21
; %var_2_2609 = add i64 %var_2_2598, 21
; Matched:\<badref\>:  store i64 %var_2_4527, i64* %var_2_3, align 8
; store i64 %var_2_2609, i64* %PC, align 8
; Matched:%var_2_3354:  %var_2_3354 = inttoptr i64 %var_2_3352 to double*
; %var_2_2610 = inttoptr i64 %var_2_2608 to double*
; Matched:\<badref\>:  store double %var_2_4650, double* %var_2_4653, align 8
; store double %var_2_2607, double* %var_2_2610, align 8
%var_2_2611 = load i64, i64* %RBP, align 8
%var_2_2612 = add i64 %var_2_2611, -144
%var_2_2613 = load i64, i64* %PC, align 8
%var_2_2614 = add i64 %var_2_2613, 8
store i64 %var_2_2614, i64* %PC, align 8
%var_2_2615 = inttoptr i64 %var_2_2612 to i64*
%var_2_2616 = load i64, i64* %var_2_2615, align 8
store i64 %var_2_2616, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_2617 = add i64 %var_2_2611, -168
; Matched:%var_2_4661:  %var_2_4661 = add i64 %var_2_4656, 16
; %var_2_2618 = add i64 %var_2_2613, 16
; Matched:\<badref\>:  store i64 %var_2_4661, i64* %var_2_3, align 8
; store i64 %var_2_2618, i64* %PC, align 8
%var_2_2619 = bitcast i64 %var_2_2616 to double
%var_2_2620 = inttoptr i64 %var_2_2617 to double*
%var_2_2621 = load double, double* %var_2_2620, align 8
%var_2_2622 = fsub double %var_2_2619, %var_2_2621
store double %var_2_2622, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_3367:  %var_2_3367 = add i64 %var_2_3355, -128
; %var_2_2623 = add i64 %var_2_2611, -128
; Matched:%var_2_1577:  %var_2_1577 = add i64 %var_2_1560, 21
; %var_2_2624 = add i64 %var_2_2613, 21
; Matched:\<badref\>:  store i64 %var_2_1577, i64* %var_2_3, align 8
; store i64 %var_2_2624, i64* %PC, align 8
; Matched:%var_2_3369:  %var_2_3369 = inttoptr i64 %var_2_3367 to double*
; %var_2_2625 = inttoptr i64 %var_2_2623 to double*
; Matched:\<badref\>:  store double %var_2_3366, double* %var_2_3369, align 8
; store double %var_2_2622, double* %var_2_2625, align 8
%var_2_2626 = load i64, i64* %RBP, align 8
%var_2_2627 = add i64 %var_2_2626, -104
%var_2_2628 = load i64, i64* %PC, align 8
; Matched:%var_2_2377:  %var_2_2377 = add i64 %var_2_2376, 5
; %var_2_2629 = add i64 %var_2_2628, 5
; Matched:\<badref\>:  store i64 %var_2_2377, i64* %var_2_3, align 8
; store i64 %var_2_2629, i64* %PC, align 8
%var_2_2630 = inttoptr i64 %var_2_2627 to i64*
%var_2_2631 = load i64, i64* %var_2_2630, align 8
; Matched:\<badref\>:  store i64 %var_2_3375, i64* %var_2_1038, align 1
; store i64 %var_2_2631, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_4675:  %var_2_4675 = add i64 %var_2_4669, -120
; %var_2_2632 = add i64 %var_2_2626, -120
; Matched:%var_2_2000:  %var_2_2000 = add i64 %var_2_1995, 10
; %var_2_2633 = add i64 %var_2_2628, 10
; Matched:\<badref\>:  store i64 %var_2_1969, i64* %var_2_3, align 8
; store i64 %var_2_2633, i64* %PC, align 8
; Matched:%var_2_3378:  %var_2_3378 = bitcast i64 %var_2_3375 to double
; %var_2_2634 = bitcast i64 %var_2_2631 to double
; Matched:%var_2_4678:  %var_2_4678 = inttoptr i64 %var_2_4675 to double*
; %var_2_2635 = inttoptr i64 %var_2_2632 to double*
; Matched:%var_2_3380:  %var_2_3380 = load double, double* %var_2_3379, align 8
; %var_2_2636 = load double, double* %var_2_2635, align 8
; Matched:%var_2_3381:  %var_2_3381 = fmul double %var_2_3378, %var_2_3380
; %var_2_2637 = fmul double %var_2_2634, %var_2_2636
; Matched:\<badref\>:  store double %var_2_4680, double* %var_2_1037, align 1
; store double %var_2_2637, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_2638 = add i64 %var_2_2626, -112
; Matched:%var_2_4593:  %var_2_4593 = add i64 %var_2_4582, 15
; %var_2_2639 = add i64 %var_2_2628, 15
; Matched:\<badref\>:  store i64 %var_2_4593, i64* %var_2_3, align 8
; store i64 %var_2_2639, i64* %PC, align 8
%var_2_2640 = inttoptr i64 %var_2_2638 to i64*
%var_2_2641 = load i64, i64* %var_2_2640, align 8
; Matched:\<badref\>:  store i64 %var_2_3421, i64* %var_2_1054, align 1
; store i64 %var_2_2641, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_4685:  %var_2_4685 = add i64 %var_2_4669, -128
; %var_2_2642 = add i64 %var_2_2626, -128
; Matched:%var_2_4722:  %var_2_4722 = add i64 %var_2_4707, 20
; %var_2_2643 = add i64 %var_2_2628, 20
; Matched:\<badref\>:  store i64 %var_2_4722, i64* %var_2_3, align 8
; store i64 %var_2_2643, i64* %PC, align 8
; Matched:%var_2_3388:  %var_2_3388 = bitcast i64 %var_2_3385 to double
; %var_2_2644 = bitcast i64 %var_2_2641 to double
; Matched:%var_2_4688:  %var_2_4688 = inttoptr i64 %var_2_4685 to double*
; %var_2_2645 = inttoptr i64 %var_2_2642 to double*
; Matched:%var_2_3390:  %var_2_3390 = load double, double* %var_2_3389, align 8
; %var_2_2646 = load double, double* %var_2_2645, align 8
; Matched:%var_2_3391:  %var_2_3391 = fmul double %var_2_3388, %var_2_3390
; %var_2_2647 = fmul double %var_2_2644, %var_2_2646
; Matched:\<badref\>:  store double %var_2_4690, double* %var_2_1053, align 1
; store double %var_2_2647, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_4691:  %var_2_4691 = fsub double %var_2_4680, %var_2_4690
; %var_2_2648 = fsub double %var_2_2637, %var_2_2647
; Matched:\<badref\>:  store double %var_2_3392, double* %var_2_1037, align 1
; store double %var_2_2648, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_2649 = add i64 %var_2_2626, -16
; Matched:%var_2_3269:  %var_2_3269 = add i64 %var_2_3247, 28
; %var_2_2650 = add i64 %var_2_2628, 28
; Matched:\<badref\>:  store i64 %var_2_3269, i64* %var_2_3, align 8
; store i64 %var_2_2650, i64* %PC, align 8
%var_2_2651 = inttoptr i64 %var_2_2649 to i64*
%var_2_2652 = load i64, i64* %var_2_2651, align 8
; Matched:\<badref\>:  store i64 %var_2_4695, i64* %RAX.i2224, align 8
; store i64 %var_2_2652, i64* %RAX, align 8
%var_2_2653 = add i64 %var_2_2626, -40
; Matched:%var_2_3273:  %var_2_3273 = add i64 %var_2_3247, 32
; %var_2_2654 = add i64 %var_2_2628, 32
; Matched:\<badref\>:  store i64 %var_2_4572, i64* %var_2_3, align 8
; store i64 %var_2_2654, i64* %PC, align 8
%var_2_2655 = inttoptr i64 %var_2_2653 to i32*
%var_2_2656 = load i32, i32* %var_2_2655, align 4
%var_2_2657 = sext i32 %var_2_2656 to i64
; Matched:\<badref\>:  store i64 %var_2_944, i64* %RDX.i2239, align 8
; store i64 %var_2_2657, i64* %RDX, align 8
; Matched:%var_2_4701:  %var_2_4701 = shl nsw i64 %var_2_4700, 3
; %var_2_2658 = shl nsw i64 %var_2_2657, 3
; Matched:%var_2_3403:  %var_2_3403 = add i64 %var_2_3402, %var_2_3396
; %var_2_2659 = add i64 %var_2_2658, %var_2_2652
; Matched:%var_2_2045:  %var_2_2045 = add i64 %var_2_1995, 37
; %var_2_2660 = add i64 %var_2_2628, 37
; Matched:\<badref\>:  store i64 %var_2_2045, i64* %var_2_3, align 8
; store i64 %var_2_2660, i64* %PC, align 8
; Matched:%var_2_3405:  %var_2_3405 = inttoptr i64 %var_2_3403 to double*
; %var_2_2661 = inttoptr i64 %var_2_2659 to double*
; Matched:\<badref\>:  store double %var_2_3392, double* %var_2_3405, align 8
; store double %var_2_2648, double* %var_2_2661, align 8
%var_2_2662 = load i64, i64* %RBP, align 8
%var_2_2663 = add i64 %var_2_2662, -104
%var_2_2664 = load i64, i64* %PC, align 8
; Matched:%var_2_2349:  %var_2_2349 = add i64 %var_2_2348, 5
; %var_2_2665 = add i64 %var_2_2664, 5
; Matched:\<badref\>:  store i64 %var_2_2349, i64* %var_2_3, align 8
; store i64 %var_2_2665, i64* %PC, align 8
%var_2_2666 = inttoptr i64 %var_2_2663 to i64*
%var_2_2667 = load i64, i64* %var_2_2666, align 8
; Matched:\<badref\>:  store i64 %var_2_4674, i64* %var_2_1038, align 1
; store i64 %var_2_2667, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_4711:  %var_2_4711 = add i64 %var_2_4705, -128
; %var_2_2668 = add i64 %var_2_2662, -128
; Matched:%var_2_4676:  %var_2_4676 = add i64 %var_2_4671, 10
; %var_2_2669 = add i64 %var_2_2664, 10
; Matched:\<badref\>:  store i64 %var_2_3252, i64* %var_2_3, align 8
; store i64 %var_2_2669, i64* %PC, align 8
; Matched:%var_2_3414:  %var_2_3414 = bitcast i64 %var_2_3411 to double
; %var_2_2670 = bitcast i64 %var_2_2667 to double
; Matched:%var_2_4714:  %var_2_4714 = inttoptr i64 %var_2_4711 to double*
; %var_2_2671 = inttoptr i64 %var_2_2668 to double*
; Matched:%var_2_3416:  %var_2_3416 = load double, double* %var_2_3415, align 8
; %var_2_2672 = load double, double* %var_2_2671, align 8
; Matched:%var_2_3417:  %var_2_3417 = fmul double %var_2_3414, %var_2_3416
; %var_2_2673 = fmul double %var_2_2670, %var_2_2672
; Matched:\<badref\>:  store double %var_2_4716, double* %var_2_1037, align 1
; store double %var_2_2673, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_2674 = add i64 %var_2_2662, -112
; Matched:%var_2_1973:  %var_2_1973 = add i64 %var_2_1964, 15
; %var_2_2675 = add i64 %var_2_2664, 15
; Matched:\<badref\>:  store i64 %var_2_1973, i64* %var_2_3, align 8
; store i64 %var_2_2675, i64* %PC, align 8
%var_2_2676 = inttoptr i64 %var_2_2674 to i64*
%var_2_2677 = load i64, i64* %var_2_2676, align 8
; Matched:\<badref\>:  store i64 %var_2_4720, i64* %var_2_1054, align 1
; store i64 %var_2_2677, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_4721:  %var_2_4721 = add i64 %var_2_4705, -120
; %var_2_2678 = add i64 %var_2_2662, -120
; Matched:%var_2_820:  %var_2_820 = add i64 %var_2_805, 20
; %var_2_2679 = add i64 %var_2_2664, 20
; Matched:\<badref\>:  store i64 %var_2_820, i64* %var_2_3, align 8
; store i64 %var_2_2679, i64* %PC, align 8
; Matched:%var_2_3424:  %var_2_3424 = bitcast i64 %var_2_3421 to double
; %var_2_2680 = bitcast i64 %var_2_2677 to double
; Matched:%var_2_4724:  %var_2_4724 = inttoptr i64 %var_2_4721 to double*
; %var_2_2681 = inttoptr i64 %var_2_2678 to double*
; Matched:%var_2_3426:  %var_2_3426 = load double, double* %var_2_3425, align 8
; %var_2_2682 = load double, double* %var_2_2681, align 8
; Matched:%var_2_3427:  %var_2_3427 = fmul double %var_2_3424, %var_2_3426
; %var_2_2683 = fmul double %var_2_2680, %var_2_2682
; Matched:\<badref\>:  store double %var_2_4726, double* %var_2_1053, align 1
; store double %var_2_2683, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_4727:  %var_2_4727 = fadd double %var_2_4716, %var_2_4726
; %var_2_2684 = fadd double %var_2_2673, %var_2_2683
; Matched:\<badref\>:  store double %var_2_3428, double* %var_2_1037, align 1
; store double %var_2_2684, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_2685 = add i64 %var_2_2662, -16
; Matched:%var_2_3305:  %var_2_3305 = add i64 %var_2_3283, 28
; %var_2_2686 = add i64 %var_2_2664, 28
; Matched:\<badref\>:  store i64 %var_2_3305, i64* %var_2_3, align 8
; store i64 %var_2_2686, i64* %PC, align 8
%var_2_2687 = inttoptr i64 %var_2_2685 to i64*
%var_2_2688 = load i64, i64* %var_2_2687, align 8
; Matched:\<badref\>:  store i64 %var_2_4731, i64* %RAX.i2224, align 8
; store i64 %var_2_2688, i64* %RAX, align 8
%var_2_2689 = add i64 %var_2_2662, -40
; Matched:%var_2_2598:  %var_2_2598 = add i64 %var_2_2569, 31
; %var_2_2690 = add i64 %var_2_2664, 31
; Matched:\<badref\>:  store i64 %var_2_4367, i64* %var_2_3, align 8
; store i64 %var_2_2690, i64* %PC, align 8
%var_2_2691 = inttoptr i64 %var_2_2689 to i32*
%var_2_2692 = load i32, i32* %var_2_2691, align 4
%var_2_2693 = add i32 %var_2_2692, 1
; Matched:%var_2_4737:  %var_2_4737 = zext i32 %var_2_4736 to i64
; %var_2_2694 = zext i32 %var_2_2693 to i64
; Matched:\<badref\>:  store i64 %var_2_4737, i64* %RCX.i2236, align 8
; store i64 %var_2_2694, i64* %RCX, align 8
; Matched:%var_2_1638:  %var_2_1638 = icmp eq i32 %var_2_1635, -1
; %var_2_2695 = icmp eq i32 %var_2_2692, -1
; Matched:%var_2_1639:  %var_2_1639 = icmp eq i32 %var_2_1636, 0
; %var_2_2696 = icmp eq i32 %var_2_2693, 0
; Matched:%var_2_1527:  %var_2_1527 = or i1 %var_2_1525, %var_2_1526
; %var_2_2697 = or i1 %var_2_2695, %var_2_2696
; Matched:%var_2_2876:  %var_2_2876 = zext i1 %var_2_2875 to i8
; %var_2_2698 = zext i1 %var_2_2697 to i8
; Matched:\<badref\>:  store i8 %var_2_1641, i8* %var_2_14, align 1
; store i8 %var_2_2698, i8* %var_2_16, align 1
; Matched:%var_2_1642:  %var_2_1642 = and i32 %var_2_1636, 255
; %var_2_2699 = and i32 %var_2_2693, 255
; Matched:%var_2_1530:  %var_2_1530 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1529)
; %var_2_2700 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2699) #14
; Matched:%var_2_1531:  %var_2_1531 = trunc i32 %var_2_1530 to i8
; %var_2_2701 = trunc i32 %var_2_2700 to i8
; Matched:%var_2_1645:  %var_2_1645 = and i8 %var_2_1644, 1
; %var_2_2702 = and i8 %var_2_2701, 1
; Matched:%var_2_1646:  %var_2_1646 = xor i8 %var_2_1645, 1
; %var_2_2703 = xor i8 %var_2_2702, 1
; Matched:\<badref\>:  store i8 %var_2_1646, i8* %var_2_21, align 1
; store i8 %var_2_2703, i8* %var_2_23, align 1
; Matched:%var_2_1647:  %var_2_1647 = xor i32 %var_2_1636, %var_2_1635
; %var_2_2704 = xor i32 %var_2_2693, %var_2_2692
; Matched:%var_2_569:  %var_2_569 = lshr i32 %var_2_568, 4
; %var_2_2705 = lshr i32 %var_2_2704, 4
; Matched:%var_2_683:  %var_2_683 = trunc i32 %var_2_682 to i8
; %var_2_2706 = trunc i32 %var_2_2705 to i8
; Matched:%var_2_1650:  %var_2_1650 = and i8 %var_2_1649, 1
; %var_2_2707 = and i8 %var_2_2706, 1
; Matched:\<badref\>:  store i8 %var_2_1650, i8* %var_2_27, align 1
; store i8 %var_2_2707, i8* %var_2_29, align 1
; Matched:%var_2_1651:  %var_2_1651 = zext i1 %var_2_1639 to i8
; %var_2_2708 = zext i1 %var_2_2696 to i8
; Matched:\<badref\>:  store i8 %var_2_1651, i8* %var_2_30, align 1
; store i8 %var_2_2708, i8* %var_2_32, align 1
; Matched:%var_2_1652:  %var_2_1652 = lshr i32 %var_2_1636, 31
; %var_2_2709 = lshr i32 %var_2_2693, 31
; Matched:%var_2_1653:  %var_2_1653 = trunc i32 %var_2_1652 to i8
; %var_2_2710 = trunc i32 %var_2_2709 to i8
; Matched:\<badref\>:  store i8 %var_2_1653, i8* %var_2_33, align 1
; store i8 %var_2_2710, i8* %var_2_35, align 1
; Matched:%var_2_1654:  %var_2_1654 = lshr i32 %var_2_1635, 31
; %var_2_2711 = lshr i32 %var_2_2692, 31
; Matched:%var_2_576:  %var_2_576 = xor i32 %var_2_573, %var_2_575
; %var_2_2712 = xor i32 %var_2_2709, %var_2_2711
; Matched:%var_2_3004:  %var_2_3004 = add nuw nsw i32 %var_2_3003, %var_2_3000
; %var_2_2713 = add nuw nsw i32 %var_2_2712, %var_2_2709
; Matched:%var_2_3458:  %var_2_3458 = icmp eq i32 %var_2_3457, 2
; %var_2_2714 = icmp eq i32 %var_2_2713, 2
; Matched:%var_2_4758:  %var_2_4758 = zext i1 %var_2_4757 to i8
; %var_2_2715 = zext i1 %var_2_2714 to i8
; Matched:\<badref\>:  store i8 %var_2_991, i8* %var_2_39, align 1
; store i8 %var_2_2715, i8* %var_2_41, align 1
%var_2_2716 = sext i32 %var_2_2693 to i64
; Matched:\<badref\>:  store i64 %var_2_693, i64* %RDX.i2239, align 8
; store i64 %var_2_2716, i64* %RDX, align 8
; Matched:%var_2_4760:  %var_2_4760 = shl nsw i64 %var_2_4759, 3
; %var_2_2717 = shl nsw i64 %var_2_2716, 3
; Matched:%var_2_4761:  %var_2_4761 = add i64 %var_2_4731, %var_2_4760
; %var_2_2718 = add i64 %var_2_2688, %var_2_2717
; Matched:%var_2_3338:  %var_2_3338 = add i64 %var_2_3283, 42
; %var_2_2719 = add i64 %var_2_2664, 42
; Matched:\<badref\>:  store i64 %var_2_4637, i64* %var_2_3, align 8
; store i64 %var_2_2719, i64* %PC, align 8
; Matched:%var_2_3464:  %var_2_3464 = inttoptr i64 %var_2_3462 to double*
; %var_2_2720 = inttoptr i64 %var_2_2718 to double*
; Matched:\<badref\>:  store double %var_2_4727, double* %var_2_4763, align 8
; store double %var_2_2684, double* %var_2_2720, align 8
; Matched:%var_2_997:  %var_2_997 = load i64, i64* %RBP.i, align 8
; %var_2_2721 = load i64, i64* %RBP, align 8
; Matched:%var_2_998:  %var_2_998 = add i64 %var_2_997, -28
; %var_2_2722 = add i64 %var_2_2721, -28
%var_2_2723 = load i64, i64* %PC, align 8
; Matched:%var_2_67:  %var_2_67 = add i64 %var_2_66, 3
; %var_2_2724 = add i64 %var_2_2723, 3
; Matched:\<badref\>:  store i64 %var_2_67, i64* %var_2_3, align 8
; store i64 %var_2_2724, i64* %PC, align 8
; Matched:%var_2_2051:  %var_2_2051 = inttoptr i64 %var_2_2048 to i32*
; %var_2_2725 = inttoptr i64 %var_2_2722 to i32*
; Matched:%var_2_1002:  %var_2_1002 = load i32, i32* %var_2_1001, align 4
; %var_2_2726 = load i32, i32* %var_2_2725, align 4
; Matched:%var_2_1003:  %var_2_1003 = add i32 %var_2_1002, 2
; %var_2_2727 = add i32 %var_2_2726, 2
; Matched:%var_2_1004:  %var_2_1004 = zext i32 %var_2_1003 to i64
; %var_2_2728 = zext i32 %var_2_2727 to i64
; Matched:\<badref\>:  store i64 %var_2_1004, i64* %RAX.i2224, align 8
; store i64 %var_2_2728, i64* %RAX, align 8
; Matched:%var_2_2055:  %var_2_2055 = icmp ugt i32 %var_2_2052, -3
; %var_2_2729 = icmp ugt i32 %var_2_2726, -3
; Matched:%var_2_2056:  %var_2_2056 = zext i1 %var_2_2055 to i8
; %var_2_2730 = zext i1 %var_2_2729 to i8
; Matched:\<badref\>:  store i8 %var_2_2056, i8* %var_2_14, align 1
; store i8 %var_2_2730, i8* %var_2_16, align 1
; Matched:%var_2_2057:  %var_2_2057 = and i32 %var_2_2053, 255
; %var_2_2731 = and i32 %var_2_2727, 255
; Matched:%var_2_2058:  %var_2_2058 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2057)
; %var_2_2732 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2731) #14
; Matched:%var_2_1009:  %var_2_1009 = trunc i32 %var_2_1008 to i8
; %var_2_2733 = trunc i32 %var_2_2732 to i8
; Matched:%var_2_2060:  %var_2_2060 = and i8 %var_2_2059, 1
; %var_2_2734 = and i8 %var_2_2733, 1
; Matched:%var_2_1011:  %var_2_1011 = xor i8 %var_2_1010, 1
; %var_2_2735 = xor i8 %var_2_2734, 1
; Matched:\<badref\>:  store i8 %var_2_4778, i8* %var_2_21, align 1
; store i8 %var_2_2735, i8* %var_2_23, align 1
; Matched:%var_2_2062:  %var_2_2062 = xor i32 %var_2_2053, %var_2_2052
; %var_2_2736 = xor i32 %var_2_2727, %var_2_2726
; Matched:%var_2_2063:  %var_2_2063 = lshr i32 %var_2_2062, 4
; %var_2_2737 = lshr i32 %var_2_2736, 4
; Matched:%var_2_2064:  %var_2_2064 = trunc i32 %var_2_2063 to i8
; %var_2_2738 = trunc i32 %var_2_2737 to i8
; Matched:%var_2_2065:  %var_2_2065 = and i8 %var_2_2064, 1
; %var_2_2739 = and i8 %var_2_2738, 1
; Matched:\<badref\>:  store i8 %var_2_1015, i8* %var_2_27, align 1
; store i8 %var_2_2739, i8* %var_2_29, align 1
; Matched:%var_2_2066:  %var_2_2066 = icmp eq i32 %var_2_2053, 0
; %var_2_2740 = icmp eq i32 %var_2_2727, 0
; Matched:%var_2_1017:  %var_2_1017 = zext i1 %var_2_1016 to i8
; %var_2_2741 = zext i1 %var_2_2740 to i8
; Matched:\<badref\>:  store i8 %var_2_4784, i8* %var_2_30, align 1
; store i8 %var_2_2741, i8* %var_2_32, align 1
; Matched:%var_2_2068:  %var_2_2068 = lshr i32 %var_2_2053, 31
; %var_2_2742 = lshr i32 %var_2_2727, 31
; Matched:%var_2_2069:  %var_2_2069 = trunc i32 %var_2_2068 to i8
; %var_2_2743 = trunc i32 %var_2_2742 to i8
; Matched:\<badref\>:  store i8 %var_2_2069, i8* %var_2_33, align 1
; store i8 %var_2_2743, i8* %var_2_35, align 1
; Matched:%var_2_2070:  %var_2_2070 = lshr i32 %var_2_2052, 31
; %var_2_2744 = lshr i32 %var_2_2726, 31
; Matched:%var_2_1021:  %var_2_1021 = xor i32 %var_2_1018, %var_2_1020
; %var_2_2745 = xor i32 %var_2_2742, %var_2_2744
; Matched:%var_2_2072:  %var_2_2072 = add nuw nsw i32 %var_2_2071, %var_2_2068
; %var_2_2746 = add nuw nsw i32 %var_2_2745, %var_2_2742
; Matched:%var_2_1023:  %var_2_1023 = icmp eq i32 %var_2_1022, 2
; %var_2_2747 = icmp eq i32 %var_2_2746, 2
; Matched:%var_2_4791:  %var_2_4791 = zext i1 %var_2_4790 to i8
; %var_2_2748 = zext i1 %var_2_2747 to i8
; Matched:\<badref\>:  store i8 %var_2_2074, i8* %var_2_39, align 1
; store i8 %var_2_2748, i8* %var_2_41, align 1
%var_2_2749 = add i64 %var_2_2723, 9
store i64 %var_2_2749, i64* %PC, align 8
; Matched:\<badref\>:  store i32 %var_2_2053, i32* %var_2_2051, align 4
; store i32 %var_2_2727, i32* %var_2_2725, align 4
; Matched:%var_2_4793:  %var_2_4793 = load i64, i64* %var_2_3, align 8
; %var_2_2750 = load i64, i64* %PC, align 8
; Matched:%var_2_4794:  %var_2_4794 = add i64 %var_2_4793, -822
; %var_2_2751 = add i64 %var_2_2750, -822
; Matched:\<badref\>:  store i64 %var_2_4794, i64* %var_2_3, align 8
; store i64 %var_2_2751, i64* %PC, align 8
  br label %block_403cc0

block_403356:                                     ; preds = %block_403362, %block_403330
; Matched:%var_2_98:  %var_2_98 = phi i64 [ %var_2_1027, %block_403362 ], [ %.pre, %entry ]
; %var_2_2752 = phi i64 [ %var_2_3681, %block_403362 ], [ %.pre, %block_403330 ]
%var_2_2753 = load i64, i64* %RBP, align 8
%var_2_2754 = add i64 %var_2_2753, -28
; Matched:%var_2_101:  %var_2_101 = add i64 %var_2_98, 3
; %var_2_2755 = add i64 %var_2_2752, 3
; Matched:\<badref\>:  store i64 %var_2_101, i64* %var_2_3, align 8
; store i64 %var_2_2755, i64* %PC, align 8
%var_2_2756 = inttoptr i64 %var_2_2754 to i32*
%var_2_2757 = load i32, i32* %var_2_2756, align 4
; Matched:%var_2_2411:  %var_2_2411 = zext i32 %var_2_2410 to i64
; %var_2_2758 = zext i32 %var_2_2757 to i64
; Matched:\<badref\>:  store i64 %var_2_138, i64* %RAX.i2224, align 8
; store i64 %var_2_2758, i64* %RAX, align 8
%var_2_2759 = add i64 %var_2_2753, -8
; Matched:%var_2_106:  %var_2_106 = add i64 %var_2_98, 6
; %var_2_2760 = add i64 %var_2_2752, 6
; Matched:\<badref\>:  store i64 %var_2_106, i64* %var_2_3, align 8
; store i64 %var_2_2760, i64* %PC, align 8
%var_2_2761 = inttoptr i64 %var_2_2759 to i32*
%var_2_2762 = load i32, i32* %var_2_2761, align 4
%var_2_2763 = sub i32 %var_2_2757, %var_2_2762
; Matched:%var_2_110:  %var_2_110 = icmp ult i32 %var_2_103, %var_2_108
; %var_2_2764 = icmp ult i32 %var_2_2757, %var_2_2762
; Matched:%var_2_111:  %var_2_111 = zext i1 %var_2_110 to i8
; %var_2_2765 = zext i1 %var_2_2764 to i8
; Matched:\<badref\>:  store i8 %var_2_111, i8* %var_2_14, align 1
; store i8 %var_2_2765, i8* %var_2_16, align 1
; Matched:%var_2_112:  %var_2_112 = and i32 %var_2_109, 255
; %var_2_2766 = and i32 %var_2_2763, 255
; Matched:%var_2_113:  %var_2_113 = tail call i32 @llvm.ctpop.i32(i32 %var_2_112)
; %var_2_2767 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2766) #14
; Matched:%var_2_114:  %var_2_114 = trunc i32 %var_2_113 to i8
; %var_2_2768 = trunc i32 %var_2_2767 to i8
; Matched:%var_2_115:  %var_2_115 = and i8 %var_2_114, 1
; %var_2_2769 = and i8 %var_2_2768, 1
; Matched:%var_2_116:  %var_2_116 = xor i8 %var_2_115, 1
; %var_2_2770 = xor i8 %var_2_2769, 1
; Matched:\<badref\>:  store i8 %var_2_116, i8* %var_2_21, align 1
; store i8 %var_2_2770, i8* %var_2_23, align 1
; Matched:%var_2_117:  %var_2_117 = xor i32 %var_2_108, %var_2_103
; %var_2_2771 = xor i32 %var_2_2762, %var_2_2757
; Matched:%var_2_118:  %var_2_118 = xor i32 %var_2_117, %var_2_109
; %var_2_2772 = xor i32 %var_2_2771, %var_2_2763
; Matched:%var_2_119:  %var_2_119 = lshr i32 %var_2_118, 4
; %var_2_2773 = lshr i32 %var_2_2772, 4
; Matched:%var_2_120:  %var_2_120 = trunc i32 %var_2_119 to i8
; %var_2_2774 = trunc i32 %var_2_2773 to i8
; Matched:%var_2_121:  %var_2_121 = and i8 %var_2_120, 1
; %var_2_2775 = and i8 %var_2_2774, 1
; Matched:\<badref\>:  store i8 %var_2_121, i8* %var_2_27, align 1
; store i8 %var_2_2775, i8* %var_2_29, align 1
; Matched:%var_2_122:  %var_2_122 = icmp eq i32 %var_2_109, 0
; %var_2_2776 = icmp eq i32 %var_2_2763, 0
; Matched:%var_2_123:  %var_2_123 = zext i1 %var_2_122 to i8
; %var_2_2777 = zext i1 %var_2_2776 to i8
; Matched:\<badref\>:  store i8 %var_2_123, i8* %var_2_30, align 1
; store i8 %var_2_2777, i8* %var_2_32, align 1
%var_2_2778 = lshr i32 %var_2_2763, 31
%var_2_2779 = trunc i32 %var_2_2778 to i8
; Matched:\<badref\>:  store i8 %var_2_125, i8* %var_2_33, align 1
; store i8 %var_2_2779, i8* %var_2_35, align 1
%var_2_2780 = lshr i32 %var_2_2757, 31
%var_2_2781 = lshr i32 %var_2_2762, 31
%var_2_2782 = xor i32 %var_2_2781, %var_2_2780
%var_2_2783 = xor i32 %var_2_2778, %var_2_2780
%var_2_2784 = add nuw nsw i32 %var_2_2783, %var_2_2782
%var_2_2785 = icmp eq i32 %var_2_2784, 2
; Matched:%var_2_132:  %var_2_132 = zext i1 %var_2_131 to i8
; %var_2_2786 = zext i1 %var_2_2785 to i8
; Matched:\<badref\>:  store i8 %var_2_132, i8* %var_2_39, align 1
; store i8 %var_2_2786, i8* %var_2_41, align 1
%var_2_2787 = icmp ne i8 %var_2_2779, 0
%var_2_2788 = xor i1 %var_2_2787, %var_2_2785
; Matched:  %.v = select i1 %var_2_134, i64 12, i64 599
; %.v = select i1 %var_2_2788, i64 12, i64 599
; Matched:%var_2_135:  %var_2_135 = add i64 %var_2_98, %.v
; %var_2_2789 = add i64 %var_2_2752, %.v
; Matched:\<badref\>:  store i64 %var_2_135, i64* %var_2_3, align 8
; store i64 %var_2_2789, i64* %PC, align 8
br i1 %var_2_2788, label %block_403362, label %block_4035ad

block_403362:                                     ; preds = %block_403356
; Matched:%var_2_136:  %var_2_136 = add i64 %var_2_135, 3
; %var_2_2790 = add i64 %var_2_2789, 3
; Matched:\<badref\>:  store i64 %var_2_136, i64* %var_2_3, align 8
; store i64 %var_2_2790, i64* %PC, align 8
%var_2_2791 = load i32, i32* %var_2_2756, align 4
; Matched:%var_2_1104:  %var_2_1104 = zext i32 %var_2_1103 to i64
; %var_2_2792 = zext i32 %var_2_2791 to i64
; Matched:\<badref\>:  store i64 %var_2_1104, i64* %RAX.i2224, align 8
; store i64 %var_2_2792, i64* %RAX, align 8
; Matched:%var_2_139:  %var_2_139 = add i64 %var_2_135, 6
; %var_2_2793 = add i64 %var_2_2789, 6
; Matched:\<badref\>:  store i64 %var_2_139, i64* %var_2_3, align 8
; store i64 %var_2_2793, i64* %PC, align 8
%var_2_2794 = load i32, i32* %var_2_2761, align 4
%var_2_2795 = add i32 %var_2_2794, %var_2_2791
; Matched:%var_2_142:  %var_2_142 = zext i32 %var_2_141 to i64
; %var_2_2796 = zext i32 %var_2_2795 to i64
; Matched:\<badref\>:  store i64 %var_2_142, i64* %RAX.i2224, align 8
; store i64 %var_2_2796, i64* %RAX, align 8
; Matched:%var_2_143:  %var_2_143 = icmp ult i32 %var_2_141, %var_2_137
; %var_2_2797 = icmp ult i32 %var_2_2795, %var_2_2791
; Matched:%var_2_1110:  %var_2_1110 = icmp ult i32 %var_2_1107, %var_2_1106
; %var_2_2798 = icmp ult i32 %var_2_2795, %var_2_2794
; Matched:%var_2_2459:  %var_2_2459 = or i1 %var_2_2457, %var_2_2458
; %var_2_2799 = or i1 %var_2_2797, %var_2_2798
; Matched:%var_2_1112:  %var_2_1112 = zext i1 %var_2_1111 to i8
; %var_2_2800 = zext i1 %var_2_2799 to i8
; Matched:\<badref\>:  store i8 %var_2_3737, i8* %var_2_14, align 1
; store i8 %var_2_2800, i8* %var_2_16, align 1
; Matched:%var_2_1113:  %var_2_1113 = and i32 %var_2_1107, 255
; %var_2_2801 = and i32 %var_2_2795, 255
; Matched:%var_2_148:  %var_2_148 = tail call i32 @llvm.ctpop.i32(i32 %var_2_147)
; %var_2_2802 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2801) #14
; Matched:%var_2_3740:  %var_2_3740 = trunc i32 %var_2_3739 to i8
; %var_2_2803 = trunc i32 %var_2_2802 to i8
; Matched:%var_2_150:  %var_2_150 = and i8 %var_2_149, 1
; %var_2_2804 = and i8 %var_2_2803, 1
; Matched:%var_2_1117:  %var_2_1117 = xor i8 %var_2_1116, 1
; %var_2_2805 = xor i8 %var_2_2804, 1
; Matched:\<badref\>:  store i8 %var_2_2465, i8* %var_2_21, align 1
; store i8 %var_2_2805, i8* %var_2_23, align 1
; Matched:%var_2_1118:  %var_2_1118 = xor i32 %var_2_1106, %var_2_1103
; %var_2_2806 = xor i32 %var_2_2794, %var_2_2791
; Matched:%var_2_3744:  %var_2_3744 = xor i32 %var_2_3743, %var_2_3732
; %var_2_2807 = xor i32 %var_2_2806, %var_2_2795
; Matched:%var_2_1120:  %var_2_1120 = lshr i32 %var_2_1119, 4
; %var_2_2808 = lshr i32 %var_2_2807, 4
; Matched:%var_2_155:  %var_2_155 = trunc i32 %var_2_154 to i8
; %var_2_2809 = trunc i32 %var_2_2808 to i8
; Matched:%var_2_3747:  %var_2_3747 = and i8 %var_2_3746, 1
; %var_2_2810 = and i8 %var_2_2809, 1
; Matched:\<badref\>:  store i8 %var_2_156, i8* %var_2_27, align 1
; store i8 %var_2_2810, i8* %var_2_29, align 1
; Matched:%var_2_1123:  %var_2_1123 = icmp eq i32 %var_2_1107, 0
; %var_2_2811 = icmp eq i32 %var_2_2795, 0
; Matched:%var_2_2472:  %var_2_2472 = zext i1 %var_2_2471 to i8
; %var_2_2812 = zext i1 %var_2_2811 to i8
; Matched:\<badref\>:  store i8 %var_2_1124, i8* %var_2_30, align 1
; store i8 %var_2_2812, i8* %var_2_32, align 1
; Matched:%var_2_3750:  %var_2_3750 = lshr i32 %var_2_3732, 31
; %var_2_2813 = lshr i32 %var_2_2795, 31
; Matched:%var_2_3751:  %var_2_3751 = trunc i32 %var_2_3750 to i8
; %var_2_2814 = trunc i32 %var_2_2813 to i8
; Matched:\<badref\>:  store i8 %var_2_160, i8* %var_2_33, align 1
; store i8 %var_2_2814, i8* %var_2_35, align 1
; Matched:%var_2_3752:  %var_2_3752 = lshr i32 %var_2_3726, 31
; %var_2_2815 = lshr i32 %var_2_2791, 31
; Matched:%var_2_162:  %var_2_162 = lshr i32 %var_2_140, 31
; %var_2_2816 = lshr i32 %var_2_2794, 31
; Matched:%var_2_3754:  %var_2_3754 = xor i32 %var_2_3750, %var_2_3752
; %var_2_2817 = xor i32 %var_2_2813, %var_2_2815
; Matched:%var_2_164:  %var_2_164 = xor i32 %var_2_159, %var_2_162
; %var_2_2818 = xor i32 %var_2_2813, %var_2_2816
; Matched:%var_2_3756:  %var_2_3756 = add nuw nsw i32 %var_2_3754, %var_2_3755
; %var_2_2819 = add nuw nsw i32 %var_2_2817, %var_2_2818
; Matched:%var_2_3757:  %var_2_3757 = icmp eq i32 %var_2_3756, 2
; %var_2_2820 = icmp eq i32 %var_2_2819, 2
; Matched:%var_2_3758:  %var_2_3758 = zext i1 %var_2_3757 to i8
; %var_2_2821 = zext i1 %var_2_2820 to i8
; Matched:\<badref\>:  store i8 %var_2_167, i8* %var_2_39, align 1
; store i8 %var_2_2821, i8* %var_2_41, align 1
; Matched:%var_2_3759:  %var_2_3759 = add i64 %var_2_3722, -32
; %var_2_2822 = add i64 %var_2_2753, -32
; Matched:%var_2_169:  %var_2_169 = add i64 %var_2_135, 9
; %var_2_2823 = add i64 %var_2_2789, 9
; Matched:\<badref\>:  store i64 %var_2_1034, i64* %var_2_3, align 8
; store i64 %var_2_2823, i64* %PC, align 8
; Matched:%var_2_170:  %var_2_170 = inttoptr i64 %var_2_168 to i32*
; %var_2_2824 = inttoptr i64 %var_2_2822 to i32*
; Matched:\<badref\>:  store i32 %var_2_3732, i32* %var_2_3761, align 4
; store i32 %var_2_2795, i32* %var_2_2824, align 4
%var_2_2825 = load i64, i64* %RBP, align 8
%var_2_2826 = add i64 %var_2_2825, -32
%var_2_2827 = load i64, i64* %PC, align 8
; Matched:%var_2_1140:  %var_2_1140 = add i64 %var_2_1139, 3
; %var_2_2828 = add i64 %var_2_2827, 3
; Matched:\<badref\>:  store i64 %var_2_1140, i64* %var_2_3, align 8
; store i64 %var_2_2828, i64* %PC, align 8
%var_2_2829 = inttoptr i64 %var_2_2826 to i32*
%var_2_2830 = load i32, i32* %var_2_2829, align 4
; Matched:%var_2_2491:  %var_2_2491 = zext i32 %var_2_2490 to i64
; %var_2_2831 = zext i32 %var_2_2830 to i64
; Matched:\<badref\>:  store i64 %var_2_1143, i64* %RAX.i2224, align 8
; store i64 %var_2_2831, i64* %RAX, align 8
%var_2_2832 = add i64 %var_2_2825, -8
; Matched:%var_2_2115:  %var_2_2115 = add i64 %var_2_2109, 6
; %var_2_2833 = add i64 %var_2_2827, 6
; Matched:\<badref\>:  store i64 %var_2_2115, i64* %var_2_3, align 8
; store i64 %var_2_2833, i64* %PC, align 8
%var_2_2834 = inttoptr i64 %var_2_2832 to i32*
%var_2_2835 = load i32, i32* %var_2_2834, align 4
%var_2_2836 = add i32 %var_2_2835, %var_2_2830
; Matched:%var_2_2497:  %var_2_2497 = zext i32 %var_2_2496 to i64
; %var_2_2837 = zext i32 %var_2_2836 to i64
; Matched:\<badref\>:  store i64 %var_2_1149, i64* %RAX.i2224, align 8
; store i64 %var_2_2837, i64* %RAX, align 8
; Matched:%var_2_2498:  %var_2_2498 = icmp ult i32 %var_2_2496, %var_2_2490
; %var_2_2838 = icmp ult i32 %var_2_2836, %var_2_2830
; Matched:%var_2_3776:  %var_2_3776 = icmp ult i32 %var_2_3773, %var_2_3772
; %var_2_2839 = icmp ult i32 %var_2_2836, %var_2_2835
; Matched:%var_2_2500:  %var_2_2500 = or i1 %var_2_2498, %var_2_2499
; %var_2_2840 = or i1 %var_2_2838, %var_2_2839
; Matched:%var_2_3778:  %var_2_3778 = zext i1 %var_2_3777 to i8
; %var_2_2841 = zext i1 %var_2_2840 to i8
; Matched:\<badref\>:  store i8 %var_2_2501, i8* %var_2_14, align 1
; store i8 %var_2_2841, i8* %var_2_16, align 1
; Matched:%var_2_3779:  %var_2_3779 = and i32 %var_2_3773, 255
; %var_2_2842 = and i32 %var_2_2836, 255
; Matched:%var_2_2503:  %var_2_2503 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2502)
; %var_2_2843 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2842) #14
; Matched:%var_2_1156:  %var_2_1156 = trunc i32 %var_2_1155 to i8
; %var_2_2844 = trunc i32 %var_2_2843 to i8
; Matched:%var_2_2505:  %var_2_2505 = and i8 %var_2_2504, 1
; %var_2_2845 = and i8 %var_2_2844, 1
; Matched:%var_2_3783:  %var_2_3783 = xor i8 %var_2_3782, 1
; %var_2_2846 = xor i8 %var_2_2845, 1
; Matched:\<badref\>:  store i8 %var_2_2506, i8* %var_2_21, align 1
; store i8 %var_2_2846, i8* %var_2_23, align 1
; Matched:%var_2_3784:  %var_2_3784 = xor i32 %var_2_3772, %var_2_3767
; %var_2_2847 = xor i32 %var_2_2835, %var_2_2830
; Matched:%var_2_2508:  %var_2_2508 = xor i32 %var_2_2507, %var_2_2496
; %var_2_2848 = xor i32 %var_2_2847, %var_2_2836
; Matched:%var_2_3786:  %var_2_3786 = lshr i32 %var_2_3785, 4
; %var_2_2849 = lshr i32 %var_2_2848, 4
; Matched:%var_2_2510:  %var_2_2510 = trunc i32 %var_2_2509 to i8
; %var_2_2850 = trunc i32 %var_2_2849 to i8
; Matched:%var_2_1163:  %var_2_1163 = and i8 %var_2_1162, 1
; %var_2_2851 = and i8 %var_2_2850, 1
; Matched:\<badref\>:  store i8 %var_2_2511, i8* %var_2_27, align 1
; store i8 %var_2_2851, i8* %var_2_29, align 1
; Matched:%var_2_3789:  %var_2_3789 = icmp eq i32 %var_2_3773, 0
; %var_2_2852 = icmp eq i32 %var_2_2836, 0
; Matched:%var_2_2513:  %var_2_2513 = zext i1 %var_2_2512 to i8
; %var_2_2853 = zext i1 %var_2_2852 to i8
; Matched:\<badref\>:  store i8 %var_2_3790, i8* %var_2_30, align 1
; store i8 %var_2_2853, i8* %var_2_32, align 1
; Matched:%var_2_2514:  %var_2_2514 = lshr i32 %var_2_2496, 31
; %var_2_2854 = lshr i32 %var_2_2836, 31
; Matched:%var_2_3792:  %var_2_3792 = trunc i32 %var_2_3791 to i8
; %var_2_2855 = trunc i32 %var_2_2854 to i8
; Matched:\<badref\>:  store i8 %var_2_2515, i8* %var_2_33, align 1
; store i8 %var_2_2855, i8* %var_2_35, align 1
; Matched:%var_2_1168:  %var_2_1168 = lshr i32 %var_2_1142, 31
; %var_2_2856 = lshr i32 %var_2_2830, 31
; Matched:%var_2_2517:  %var_2_2517 = lshr i32 %var_2_2495, 31
; %var_2_2857 = lshr i32 %var_2_2835, 31
; Matched:%var_2_3795:  %var_2_3795 = xor i32 %var_2_3791, %var_2_3793
; %var_2_2858 = xor i32 %var_2_2854, %var_2_2856
; Matched:%var_2_2519:  %var_2_2519 = xor i32 %var_2_2514, %var_2_2517
; %var_2_2859 = xor i32 %var_2_2854, %var_2_2857
; Matched:%var_2_3797:  %var_2_3797 = add nuw nsw i32 %var_2_3795, %var_2_3796
; %var_2_2860 = add nuw nsw i32 %var_2_2858, %var_2_2859
; Matched:%var_2_2521:  %var_2_2521 = icmp eq i32 %var_2_2520, 2
; %var_2_2861 = icmp eq i32 %var_2_2860, 2
; Matched:%var_2_3799:  %var_2_3799 = zext i1 %var_2_3798 to i8
; %var_2_2862 = zext i1 %var_2_2861 to i8
; Matched:\<badref\>:  store i8 %var_2_2522, i8* %var_2_39, align 1
; store i8 %var_2_2862, i8* %var_2_41, align 1
; Matched:%var_2_1175:  %var_2_1175 = add i64 %var_2_1137, -36
; %var_2_2863 = add i64 %var_2_2825, -36
%var_2_2864 = add i64 %var_2_2827, 9
store i64 %var_2_2864, i64* %PC, align 8
; Matched:%var_2_3802:  %var_2_3802 = inttoptr i64 %var_2_3800 to i32*
; %var_2_2865 = inttoptr i64 %var_2_2863 to i32*
; Matched:\<badref\>:  store i32 %var_2_3773, i32* %var_2_3802, align 4
; store i32 %var_2_2836, i32* %var_2_2865, align 4
%var_2_2866 = load i64, i64* %RBP, align 8
%var_2_2867 = add i64 %var_2_2866, -36
%var_2_2868 = load i64, i64* %PC, align 8
; Matched:%var_2_215:  %var_2_215 = add i64 %var_2_214, 3
; %var_2_2869 = add i64 %var_2_2868, 3
; Matched:\<badref\>:  store i64 %var_2_215, i64* %var_2_3, align 8
; store i64 %var_2_2869, i64* %PC, align 8
%var_2_2870 = inttoptr i64 %var_2_2867 to i32*
%var_2_2871 = load i32, i32* %var_2_2870, align 4
; Matched:%var_2_218:  %var_2_218 = zext i32 %var_2_217 to i64
; %var_2_2872 = zext i32 %var_2_2871 to i64
; Matched:\<badref\>:  store i64 %var_2_1184, i64* %RAX.i2224, align 8
; store i64 %var_2_2872, i64* %RAX, align 8
%var_2_2873 = add i64 %var_2_2866, -8
; Matched:%var_2_2403:  %var_2_2403 = add i64 %var_2_2397, 6
; %var_2_2874 = add i64 %var_2_2868, 6
; Matched:\<badref\>:  store i64 %var_2_2403, i64* %var_2_3, align 8
; store i64 %var_2_2874, i64* %PC, align 8
%var_2_2875 = inttoptr i64 %var_2_2873 to i32*
%var_2_2876 = load i32, i32* %var_2_2875, align 4
%var_2_2877 = add i32 %var_2_2876, %var_2_2871
; Matched:%var_2_224:  %var_2_224 = zext i32 %var_2_223 to i64
; %var_2_2878 = zext i32 %var_2_2877 to i64
; Matched:\<badref\>:  store i64 %var_2_1190, i64* %RAX.i2224, align 8
; store i64 %var_2_2878, i64* %RAX, align 8
; Matched:%var_2_3816:  %var_2_3816 = icmp ult i32 %var_2_3814, %var_2_3808
; %var_2_2879 = icmp ult i32 %var_2_2877, %var_2_2871
; Matched:%var_2_1192:  %var_2_1192 = icmp ult i32 %var_2_1189, %var_2_1188
; %var_2_2880 = icmp ult i32 %var_2_2877, %var_2_2876
; Matched:%var_2_1193:  %var_2_1193 = or i1 %var_2_1191, %var_2_1192
; %var_2_2881 = or i1 %var_2_2879, %var_2_2880
; Matched:%var_2_1194:  %var_2_1194 = zext i1 %var_2_1193 to i8
; %var_2_2882 = zext i1 %var_2_2881 to i8
; Matched:\<badref\>:  store i8 %var_2_3819, i8* %var_2_14, align 1
; store i8 %var_2_2882, i8* %var_2_16, align 1
; Matched:%var_2_3820:  %var_2_3820 = and i32 %var_2_3814, 255
; %var_2_2883 = and i32 %var_2_2877, 255
; Matched:%var_2_3821:  %var_2_3821 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3820)
; %var_2_2884 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2883) #14
; Matched:%var_2_1197:  %var_2_1197 = trunc i32 %var_2_1196 to i8
; %var_2_2885 = trunc i32 %var_2_2884 to i8
; Matched:%var_2_3823:  %var_2_3823 = and i8 %var_2_3822, 1
; %var_2_2886 = and i8 %var_2_2885, 1
; Matched:%var_2_1199:  %var_2_1199 = xor i8 %var_2_1198, 1
; %var_2_2887 = xor i8 %var_2_2886, 1
; Matched:\<badref\>:  store i8 %var_2_1199, i8* %var_2_21, align 1
; store i8 %var_2_2887, i8* %var_2_23, align 1
; Matched:%var_2_3825:  %var_2_3825 = xor i32 %var_2_3813, %var_2_3808
; %var_2_2888 = xor i32 %var_2_2876, %var_2_2871
; Matched:%var_2_3826:  %var_2_3826 = xor i32 %var_2_3825, %var_2_3814
; %var_2_2889 = xor i32 %var_2_2888, %var_2_2877
; Matched:%var_2_236:  %var_2_236 = lshr i32 %var_2_235, 4
; %var_2_2890 = lshr i32 %var_2_2889, 4
; Matched:%var_2_1203:  %var_2_1203 = trunc i32 %var_2_1202 to i8
; %var_2_2891 = trunc i32 %var_2_2890 to i8
; Matched:%var_2_238:  %var_2_238 = and i8 %var_2_237, 1
; %var_2_2892 = and i8 %var_2_2891, 1
; Matched:\<badref\>:  store i8 %var_2_3829, i8* %var_2_27, align 1
; store i8 %var_2_2892, i8* %var_2_29, align 1
; Matched:%var_2_239:  %var_2_239 = icmp eq i32 %var_2_223, 0
; %var_2_2893 = icmp eq i32 %var_2_2877, 0
; Matched:%var_2_1206:  %var_2_1206 = zext i1 %var_2_1205 to i8
; %var_2_2894 = zext i1 %var_2_2893 to i8
; Matched:\<badref\>:  store i8 %var_2_3831, i8* %var_2_30, align 1
; store i8 %var_2_2894, i8* %var_2_32, align 1
; Matched:%var_2_3832:  %var_2_3832 = lshr i32 %var_2_3814, 31
; %var_2_2895 = lshr i32 %var_2_2877, 31
; Matched:%var_2_242:  %var_2_242 = trunc i32 %var_2_241 to i8
; %var_2_2896 = trunc i32 %var_2_2895 to i8
; Matched:\<badref\>:  store i8 %var_2_1208, i8* %var_2_33, align 1
; store i8 %var_2_2896, i8* %var_2_35, align 1
; Matched:%var_2_243:  %var_2_243 = lshr i32 %var_2_217, 31
; %var_2_2897 = lshr i32 %var_2_2871, 31
; Matched:%var_2_3835:  %var_2_3835 = lshr i32 %var_2_3813, 31
; %var_2_2898 = lshr i32 %var_2_2876, 31
; Matched:%var_2_245:  %var_2_245 = xor i32 %var_2_241, %var_2_243
; %var_2_2899 = xor i32 %var_2_2895, %var_2_2897
; Matched:%var_2_1212:  %var_2_1212 = xor i32 %var_2_1207, %var_2_1210
; %var_2_2900 = xor i32 %var_2_2895, %var_2_2898
; Matched:%var_2_3838:  %var_2_3838 = add nuw nsw i32 %var_2_3836, %var_2_3837
; %var_2_2901 = add nuw nsw i32 %var_2_2899, %var_2_2900
; Matched:%var_2_3839:  %var_2_3839 = icmp eq i32 %var_2_3838, 2
; %var_2_2902 = icmp eq i32 %var_2_2901, 2
; Matched:%var_2_249:  %var_2_249 = zext i1 %var_2_248 to i8
; %var_2_2903 = zext i1 %var_2_2902 to i8
; Matched:\<badref\>:  store i8 %var_2_1215, i8* %var_2_39, align 1
; store i8 %var_2_2903, i8* %var_2_41, align 1
; Matched:%var_2_250:  %var_2_250 = add i64 %var_2_212, -40
; %var_2_2904 = add i64 %var_2_2866, -40
%var_2_2905 = add i64 %var_2_2868, 9
store i64 %var_2_2905, i64* %PC, align 8
; Matched:%var_2_1218:  %var_2_1218 = inttoptr i64 %var_2_1216 to i32*
; %var_2_2906 = inttoptr i64 %var_2_2904 to i32*
; Matched:\<badref\>:  store i32 %var_2_3814, i32* %var_2_3843, align 4
; store i32 %var_2_2877, i32* %var_2_2906, align 4
%var_2_2907 = load i64, i64* %RBP, align 8
%var_2_2908 = add i64 %var_2_2907, -16
%var_2_2909 = load i64, i64* %PC, align 8
; Matched:%var_2_482:  %var_2_482 = add i64 %var_2_481, 4
; %var_2_2910 = add i64 %var_2_2909, 4
; Matched:\<badref\>:  store i64 %var_2_482, i64* %var_2_3, align 8
; store i64 %var_2_2910, i64* %PC, align 8
%var_2_2911 = inttoptr i64 %var_2_2908 to i64*
%var_2_2912 = load i64, i64* %var_2_2911, align 8
; Matched:\<badref\>:  store i64 %var_2_964, i64* %RCX.i2236, align 8
; store i64 %var_2_2912, i64* %RCX, align 8
%var_2_2913 = add i64 %var_2_2907, -28
%var_2_2914 = add i64 %var_2_2909, 8
store i64 %var_2_2914, i64* %PC, align 8
%var_2_2915 = inttoptr i64 %var_2_2913 to i32*
%var_2_2916 = load i32, i32* %var_2_2915, align 4
%var_2_2917 = sext i32 %var_2_2916 to i64
; Matched:\<badref\>:  store i64 %var_2_1229, i64* %RDX.i2239, align 8
; store i64 %var_2_2917, i64* %RDX, align 8
%var_2_2918 = shl nsw i64 %var_2_2917, 3
%var_2_2919 = add i64 %var_2_2918, %var_2_2912
; Matched:%var_2_1776:  %var_2_1776 = add i64 %var_2_1771, 13
; %var_2_2920 = add i64 %var_2_2909, 13
; Matched:\<badref\>:  store i64 %var_2_1776, i64* %var_2_3, align 8
; store i64 %var_2_2920, i64* %PC, align 8
%var_2_2921 = inttoptr i64 %var_2_2919 to i64*
%var_2_2922 = load i64, i64* %var_2_2921, align 8
store i64 %var_2_2922, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_2809:  %var_2_2809 = add i64 %var_2_2795, 17
; %var_2_2923 = add i64 %var_2_2909, 17
; Matched:\<badref\>:  store i64 %var_2_2809, i64* %var_2_3, align 8
; store i64 %var_2_2923, i64* %PC, align 8
%var_2_2924 = load i64, i64* %var_2_2911, align 8
; Matched:\<badref\>:  store i64 %var_2_630, i64* %RCX.i2236, align 8
; store i64 %var_2_2924, i64* %RCX, align 8
%var_2_2925 = add i64 %var_2_2907, -32
; Matched:%var_2_1960:  %var_2_1960 = add i64 %var_2_1949, 21
; %var_2_2926 = add i64 %var_2_2909, 21
; Matched:\<badref\>:  store i64 %var_2_3228, i64* %var_2_3, align 8
; store i64 %var_2_2926, i64* %PC, align 8
%var_2_2927 = inttoptr i64 %var_2_2925 to i32*
%var_2_2928 = load i32, i32* %var_2_2927, align 4
%var_2_2929 = sext i32 %var_2_2928 to i64
; Matched:\<badref\>:  store i64 %var_2_871, i64* %RDX.i2239, align 8
; store i64 %var_2_2929, i64* %RDX, align 8
%var_2_2930 = shl nsw i64 %var_2_2929, 3
%var_2_2931 = add i64 %var_2_2930, %var_2_2924
; Matched:%var_2_1767:  %var_2_1767 = add i64 %var_2_1746, 26
; %var_2_2932 = add i64 %var_2_2909, 26
; Matched:\<badref\>:  store i64 %var_2_1767, i64* %var_2_3, align 8
; store i64 %var_2_2932, i64* %PC, align 8
%var_2_2933 = bitcast i64 %var_2_2922 to double
%var_2_2934 = inttoptr i64 %var_2_2931 to double*
%var_2_2935 = load double, double* %var_2_2934, align 8
%var_2_2936 = fadd double %var_2_2933, %var_2_2935
store double %var_2_2936, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_1249:  %var_2_1249 = add i64 %var_2_1219, -120
; %var_2_2937 = add i64 %var_2_2907, -120
; Matched:%var_2_4367:  %var_2_4367 = add i64 %var_2_4323, 31
; %var_2_2938 = add i64 %var_2_2909, 31
; Matched:\<badref\>:  store i64 %var_2_3090, i64* %var_2_3, align 8
; store i64 %var_2_2938, i64* %PC, align 8
; Matched:%var_2_1251:  %var_2_1251 = inttoptr i64 %var_2_1249 to double*
; %var_2_2939 = inttoptr i64 %var_2_2937 to double*
; Matched:\<badref\>:  store double %var_2_2596, double* %var_2_2599, align 8
; store double %var_2_2936, double* %var_2_2939, align 8
%var_2_2940 = load i64, i64* %RBP, align 8
%var_2_2941 = add i64 %var_2_2940, -16
%var_2_2942 = load i64, i64* %PC, align 8
; Matched:%var_2_3960:  %var_2_3960 = add i64 %var_2_3959, 4
; %var_2_2943 = add i64 %var_2_2942, 4
; Matched:\<badref\>:  store i64 %var_2_3960, i64* %var_2_3, align 8
; store i64 %var_2_2943, i64* %PC, align 8
%var_2_2944 = inttoptr i64 %var_2_2941 to i64*
%var_2_2945 = load i64, i64* %var_2_2944, align 8
; Matched:\<badref\>:  store i64 %var_2_1224, i64* %RCX.i2236, align 8
; store i64 %var_2_2945, i64* %RCX, align 8
%var_2_2946 = add i64 %var_2_2940, -28
; Matched:%var_2_1598:  %var_2_1598 = add i64 %var_2_1593, 7
; %var_2_2947 = add i64 %var_2_2942, 7
; Matched:\<badref\>:  store i64 %var_2_1372, i64* %var_2_3, align 8
; store i64 %var_2_2947, i64* %PC, align 8
%var_2_2948 = inttoptr i64 %var_2_2946 to i32*
%var_2_2949 = load i32, i32* %var_2_2948, align 4
%var_2_2950 = add i32 %var_2_2949, 1
; Matched:%var_2_1263:  %var_2_1263 = zext i32 %var_2_1262 to i64
; %var_2_2951 = zext i32 %var_2_2950 to i64
; Matched:\<badref\>:  store i64 %var_2_1717, i64* %RAX.i2224, align 8
; store i64 %var_2_2951, i64* %RAX, align 8
; Matched:%var_2_1264:  %var_2_1264 = icmp eq i32 %var_2_1261, -1
; %var_2_2952 = icmp eq i32 %var_2_2949, -1
; Matched:%var_2_1378:  %var_2_1378 = icmp eq i32 %var_2_1375, 0
; %var_2_2953 = icmp eq i32 %var_2_2950, 0
; Matched:%var_2_1266:  %var_2_1266 = or i1 %var_2_1264, %var_2_1265
; %var_2_2954 = or i1 %var_2_2952, %var_2_2953
; Matched:%var_2_1267:  %var_2_1267 = zext i1 %var_2_1266 to i8
; %var_2_2955 = zext i1 %var_2_2954 to i8
; Matched:\<badref\>:  store i8 %var_2_1267, i8* %var_2_14, align 1
; store i8 %var_2_2955, i8* %var_2_16, align 1
; Matched:%var_2_1268:  %var_2_1268 = and i32 %var_2_1262, 255
; %var_2_2956 = and i32 %var_2_2950, 255
; Matched:%var_2_1723:  %var_2_1723 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1722)
; %var_2_2957 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2956) #14
; Matched:%var_2_4008:  %var_2_4008 = trunc i32 %var_2_4007 to i8
; %var_2_2958 = trunc i32 %var_2_2957 to i8
; Matched:%var_2_1271:  %var_2_1271 = and i8 %var_2_1270, 1
; %var_2_2959 = and i8 %var_2_2958, 1
; Matched:%var_2_1726:  %var_2_1726 = xor i8 %var_2_1725, 1
; %var_2_2960 = xor i8 %var_2_2959, 1
; Matched:\<badref\>:  store i8 %var_2_1726, i8* %var_2_21, align 1
; store i8 %var_2_2960, i8* %var_2_23, align 1
; Matched:%var_2_1727:  %var_2_1727 = xor i32 %var_2_1716, %var_2_1715
; %var_2_2961 = xor i32 %var_2_2950, %var_2_2949
; Matched:%var_2_1728:  %var_2_1728 = lshr i32 %var_2_1727, 4
; %var_2_2962 = lshr i32 %var_2_2961, 4
; Matched:%var_2_1729:  %var_2_1729 = trunc i32 %var_2_1728 to i8
; %var_2_2963 = trunc i32 %var_2_2962 to i8
; Matched:%var_2_1730:  %var_2_1730 = and i8 %var_2_1729, 1
; %var_2_2964 = and i8 %var_2_2963, 1
; Matched:\<badref\>:  store i8 %var_2_1730, i8* %var_2_27, align 1
; store i8 %var_2_2964, i8* %var_2_29, align 1
; Matched:%var_2_1390:  %var_2_1390 = zext i1 %var_2_1378 to i8
; %var_2_2965 = zext i1 %var_2_2953 to i8
; Matched:\<badref\>:  store i8 %var_2_1731, i8* %var_2_30, align 1
; store i8 %var_2_2965, i8* %var_2_32, align 1
; Matched:%var_2_1732:  %var_2_1732 = lshr i32 %var_2_1716, 31
; %var_2_2966 = lshr i32 %var_2_2950, 31
; Matched:%var_2_1279:  %var_2_1279 = trunc i32 %var_2_1278 to i8
; %var_2_2967 = trunc i32 %var_2_2966 to i8
; Matched:\<badref\>:  store i8 %var_2_1733, i8* %var_2_33, align 1
; store i8 %var_2_2967, i8* %var_2_35, align 1
; Matched:%var_2_1280:  %var_2_1280 = lshr i32 %var_2_1261, 31
; %var_2_2968 = lshr i32 %var_2_2949, 31
; Matched:%var_2_2629:  %var_2_2629 = xor i32 %var_2_2626, %var_2_2628
; %var_2_2969 = xor i32 %var_2_2966, %var_2_2968
; Matched:%var_2_1736:  %var_2_1736 = add nuw nsw i32 %var_2_1735, %var_2_1732
; %var_2_2970 = add nuw nsw i32 %var_2_2969, %var_2_2966
; Matched:%var_2_4362:  %var_2_4362 = icmp eq i32 %var_2_4361, 2
; %var_2_2971 = icmp eq i32 %var_2_2970, 2
; Matched:%var_2_4022:  %var_2_4022 = zext i1 %var_2_4021 to i8
; %var_2_2972 = zext i1 %var_2_2971 to i8
; Matched:\<badref\>:  store i8 %var_2_4022, i8* %var_2_39, align 1
; store i8 %var_2_2972, i8* %var_2_41, align 1
%var_2_2973 = sext i32 %var_2_2950 to i64
; Matched:\<badref\>:  store i64 %var_2_1739, i64* %RDX.i2239, align 8
; store i64 %var_2_2973, i64* %RDX, align 8
%var_2_2974 = shl nsw i64 %var_2_2973, 3
%var_2_2975 = add i64 %var_2_2945, %var_2_2974
; Matched:%var_2_2279:  %var_2_2279 = add i64 %var_2_2245, 18
; %var_2_2976 = add i64 %var_2_2942, 18
; Matched:\<badref\>:  store i64 %var_2_2279, i64* %var_2_3, align 8
; store i64 %var_2_2976, i64* %PC, align 8
%var_2_2977 = inttoptr i64 %var_2_2975 to i64*
%var_2_2978 = load i64, i64* %var_2_2977, align 8
store i64 %var_2_2978, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_3104:  %var_2_3104 = add i64 %var_2_3094, 22
; %var_2_2979 = add i64 %var_2_2942, 22
; Matched:\<badref\>:  store i64 %var_2_4142, i64* %var_2_3, align 8
; store i64 %var_2_2979, i64* %PC, align 8
%var_2_2980 = load i64, i64* %var_2_2944, align 8
; Matched:\<badref\>:  store i64 %var_2_1292, i64* %RCX.i2236, align 8
; store i64 %var_2_2980, i64* %RCX, align 8
%var_2_2981 = add i64 %var_2_2940, -32
; Matched:%var_2_3919:  %var_2_3919 = add i64 %var_2_3879, 25
; %var_2_2982 = add i64 %var_2_2942, 25
; Matched:\<badref\>:  store i64 %var_2_3919, i64* %var_2_3, align 8
; store i64 %var_2_2982, i64* %PC, align 8
%var_2_2983 = inttoptr i64 %var_2_2981 to i32*
%var_2_2984 = load i32, i32* %var_2_2983, align 4
%var_2_2985 = add i32 %var_2_2984, 1
; Matched:%var_2_1905:  %var_2_1905 = zext i32 %var_2_1904 to i64
; %var_2_2986 = zext i32 %var_2_2985 to i64
; Matched:\<badref\>:  store i64 %var_2_1905, i64* %RAX.i2224, align 8
; store i64 %var_2_2986, i64* %RAX, align 8
; Matched:%var_2_1906:  %var_2_1906 = icmp eq i32 %var_2_1903, -1
; %var_2_2987 = icmp eq i32 %var_2_2984, -1
; Matched:%var_2_1300:  %var_2_1300 = icmp eq i32 %var_2_1297, 0
; %var_2_2988 = icmp eq i32 %var_2_2985, 0
; Matched:%var_2_1301:  %var_2_1301 = or i1 %var_2_1299, %var_2_1300
; %var_2_2989 = or i1 %var_2_2987, %var_2_2988
; Matched:%var_2_1909:  %var_2_1909 = zext i1 %var_2_1908 to i8
; %var_2_2990 = zext i1 %var_2_2989 to i8
; Matched:\<badref\>:  store i8 %var_2_4040, i8* %var_2_14, align 1
; store i8 %var_2_2990, i8* %var_2_16, align 1
; Matched:%var_2_4041:  %var_2_4041 = and i32 %var_2_4035, 255
; %var_2_2991 = and i32 %var_2_2985, 255
; Matched:%var_2_1911:  %var_2_1911 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1910)
; %var_2_2992 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2991) #14
; Matched:%var_2_1912:  %var_2_1912 = trunc i32 %var_2_1911 to i8
; %var_2_2993 = trunc i32 %var_2_2992 to i8
; Matched:%var_2_4044:  %var_2_4044 = and i8 %var_2_4043, 1
; %var_2_2994 = and i8 %var_2_2993, 1
; Matched:%var_2_4045:  %var_2_4045 = xor i8 %var_2_4044, 1
; %var_2_2995 = xor i8 %var_2_2994, 1
; Matched:\<badref\>:  store i8 %var_2_1914, i8* %var_2_21, align 1
; store i8 %var_2_2995, i8* %var_2_23, align 1
; Matched:%var_2_1308:  %var_2_1308 = xor i32 %var_2_1297, %var_2_1296
; %var_2_2996 = xor i32 %var_2_2985, %var_2_2984
; Matched:%var_2_1309:  %var_2_1309 = lshr i32 %var_2_1308, 4
; %var_2_2997 = lshr i32 %var_2_2996, 4
; Matched:%var_2_1917:  %var_2_1917 = trunc i32 %var_2_1916 to i8
; %var_2_2998 = trunc i32 %var_2_2997 to i8
; Matched:%var_2_1918:  %var_2_1918 = and i8 %var_2_1917, 1
; %var_2_2999 = and i8 %var_2_2998, 1
; Matched:\<badref\>:  store i8 %var_2_1311, i8* %var_2_27, align 1
; store i8 %var_2_2999, i8* %var_2_29, align 1
; Matched:%var_2_1919:  %var_2_1919 = zext i1 %var_2_1907 to i8
; %var_2_3000 = zext i1 %var_2_2988 to i8
; Matched:\<badref\>:  store i8 %var_2_1919, i8* %var_2_30, align 1
; store i8 %var_2_3000, i8* %var_2_32, align 1
; Matched:%var_2_1920:  %var_2_1920 = lshr i32 %var_2_1904, 31
; %var_2_3001 = lshr i32 %var_2_2985, 31
; Matched:%var_2_1921:  %var_2_1921 = trunc i32 %var_2_1920 to i8
; %var_2_3002 = trunc i32 %var_2_3001 to i8
; Matched:\<badref\>:  store i8 %var_2_1314, i8* %var_2_33, align 1
; store i8 %var_2_3002, i8* %var_2_35, align 1
; Matched:%var_2_1922:  %var_2_1922 = lshr i32 %var_2_1903, 31
; %var_2_3003 = lshr i32 %var_2_2984, 31
; Matched:%var_2_4054:  %var_2_4054 = xor i32 %var_2_4051, %var_2_4053
; %var_2_3004 = xor i32 %var_2_3001, %var_2_3003
; Matched:%var_2_1924:  %var_2_1924 = add nuw nsw i32 %var_2_1923, %var_2_1920
; %var_2_3005 = add nuw nsw i32 %var_2_3004, %var_2_3001
; Matched:%var_2_1318:  %var_2_1318 = icmp eq i32 %var_2_1317, 2
; %var_2_3006 = icmp eq i32 %var_2_3005, 2
; Matched:%var_2_1319:  %var_2_1319 = zext i1 %var_2_1318 to i8
; %var_2_3007 = zext i1 %var_2_3006 to i8
; Matched:\<badref\>:  store i8 %var_2_1319, i8* %var_2_39, align 1
; store i8 %var_2_3007, i8* %var_2_41, align 1
%var_2_3008 = sext i32 %var_2_2985 to i64
; Matched:\<badref\>:  store i64 %var_2_2668, i64* %RDX.i2239, align 8
; store i64 %var_2_3008, i64* %RDX, align 8
%var_2_3009 = shl nsw i64 %var_2_3008, 3
%var_2_3010 = add i64 %var_2_2980, %var_2_3009
; Matched:%var_2_2671:  %var_2_2671 = add i64 %var_2_2602, 36
; %var_2_3011 = add i64 %var_2_2942, 36
; Matched:\<badref\>:  store i64 %var_2_2671, i64* %var_2_3, align 8
; store i64 %var_2_3011, i64* %PC, align 8
%var_2_3012 = bitcast i64 %var_2_2978 to double
%var_2_3013 = inttoptr i64 %var_2_3010 to double*
%var_2_3014 = load double, double* %var_2_3013, align 8
%var_2_3015 = fadd double %var_2_3012, %var_2_3014
store double %var_2_3015, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_3953:  %var_2_3953 = load i64, i64* %RBP.i, align 8
; %var_2_3016 = load i64, i64* %RBP, align 8
; Matched:%var_2_3954:  %var_2_3954 = add i64 %var_2_3953, -128
; %var_2_3017 = add i64 %var_2_3016, -128
; Matched:%var_2_4432:  %var_2_4432 = add i64 %var_2_4399, 41
; %var_2_3018 = add i64 %var_2_2942, 41
; Matched:\<badref\>:  store i64 %var_2_364, i64* %var_2_3, align 8
; store i64 %var_2_3018, i64* %PC, align 8
; Matched:%var_2_1331:  %var_2_1331 = inttoptr i64 %var_2_1329 to double*
; %var_2_3019 = inttoptr i64 %var_2_3017 to double*
; Matched:\<badref\>:  store double %var_2_3952, double* %var_2_3956, align 8
; store double %var_2_3015, double* %var_2_3019, align 8
%var_2_3020 = load i64, i64* %RBP, align 8
%var_2_3021 = add i64 %var_2_3020, -16
%var_2_3022 = load i64, i64* %PC, align 8
; Matched:%var_2_2683:  %var_2_2683 = add i64 %var_2_2682, 4
; %var_2_3023 = add i64 %var_2_3022, 4
; Matched:\<badref\>:  store i64 %var_2_2683, i64* %var_2_3, align 8
; store i64 %var_2_3023, i64* %PC, align 8
%var_2_3024 = inttoptr i64 %var_2_3021 to i64*
%var_2_3025 = load i64, i64* %var_2_3024, align 8
; Matched:\<badref\>:  store i64 %var_2_291, i64* %RCX.i2236, align 8
; store i64 %var_2_3025, i64* %RCX, align 8
%var_2_3026 = add i64 %var_2_3020, -28
%var_2_3027 = add i64 %var_2_3022, 8
store i64 %var_2_3027, i64* %PC, align 8
%var_2_3028 = inttoptr i64 %var_2_3026 to i32*
%var_2_3029 = load i32, i32* %var_2_3028, align 4
%var_2_3030 = sext i32 %var_2_3029 to i64
; Matched:\<badref\>:  store i64 %var_2_1342, i64* %RDX.i2239, align 8
; store i64 %var_2_3030, i64* %RDX, align 8
%var_2_3031 = shl nsw i64 %var_2_3030, 3
%var_2_3032 = add i64 %var_2_3031, %var_2_3025
; Matched:%var_2_1345:  %var_2_1345 = add i64 %var_2_1334, 13
; %var_2_3033 = add i64 %var_2_3022, 13
; Matched:\<badref\>:  store i64 %var_2_1345, i64* %var_2_3, align 8
; store i64 %var_2_3033, i64* %PC, align 8
%var_2_3034 = inttoptr i64 %var_2_3032 to i64*
%var_2_3035 = load i64, i64* %var_2_3034, align 8
store i64 %var_2_3035, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_816:  %var_2_816 = add i64 %var_2_805, 17
; %var_2_3036 = add i64 %var_2_3022, 17
; Matched:\<badref\>:  store i64 %var_2_816, i64* %var_2_3, align 8
; store i64 %var_2_3036, i64* %PC, align 8
%var_2_3037 = load i64, i64* %var_2_3024, align 8
; Matched:\<badref\>:  store i64 %var_2_1405, i64* %RCX.i2236, align 8
; store i64 %var_2_3037, i64* %RCX, align 8
%var_2_3038 = add i64 %var_2_3020, -32
; Matched:%var_2_4667:  %var_2_4667 = add i64 %var_2_4656, 21
; %var_2_3039 = add i64 %var_2_3022, 21
; Matched:\<badref\>:  store i64 %var_2_4667, i64* %var_2_3, align 8
; store i64 %var_2_3039, i64* %PC, align 8
%var_2_3040 = inttoptr i64 %var_2_3038 to i32*
%var_2_3041 = load i32, i32* %var_2_3040, align 4
%var_2_3042 = sext i32 %var_2_3041 to i64
; Matched:\<badref\>:  store i64 %var_2_1873, i64* %RDX.i2239, align 8
; store i64 %var_2_3042, i64* %RDX, align 8
%var_2_3043 = shl nsw i64 %var_2_3042, 3
%var_2_3044 = add i64 %var_2_3043, %var_2_3037
; Matched:%var_2_2592:  %var_2_2592 = add i64 %var_2_2569, 26
; %var_2_3045 = add i64 %var_2_3022, 26
; Matched:\<badref\>:  store i64 %var_2_2592, i64* %var_2_3, align 8
; store i64 %var_2_3045, i64* %PC, align 8
%var_2_3046 = bitcast i64 %var_2_3035 to double
%var_2_3047 = inttoptr i64 %var_2_3044 to double*
%var_2_3048 = load double, double* %var_2_3047, align 8
%var_2_3049 = fsub double %var_2_3046, %var_2_3048
store double %var_2_3049, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_1362:  %var_2_1362 = add i64 %var_2_1332, -136
; %var_2_3050 = add i64 %var_2_3020, -136
; Matched:%var_2_1363:  %var_2_1363 = add i64 %var_2_1334, 34
; %var_2_3051 = add i64 %var_2_3022, 34
; Matched:\<badref\>:  store i64 %var_2_1476, i64* %var_2_3, align 8
; store i64 %var_2_3051, i64* %PC, align 8
; Matched:%var_2_1364:  %var_2_1364 = inttoptr i64 %var_2_1362 to double*
; %var_2_3052 = inttoptr i64 %var_2_3050 to double*
; Matched:\<badref\>:  store double %var_2_1361, double* %var_2_1364, align 8
; store double %var_2_3049, double* %var_2_3052, align 8
%var_2_3053 = load i64, i64* %RBP, align 8
%var_2_3054 = add i64 %var_2_3053, -16
%var_2_3055 = load i64, i64* %PC, align 8
; Matched:%var_2_628:  %var_2_628 = add i64 %var_2_627, 4
; %var_2_3056 = add i64 %var_2_3055, 4
; Matched:\<badref\>:  store i64 %var_2_628, i64* %var_2_3, align 8
; store i64 %var_2_3056, i64* %PC, align 8
%var_2_3057 = inttoptr i64 %var_2_3054 to i64*
%var_2_3058 = load i64, i64* %var_2_3057, align 8
; Matched:\<badref\>:  store i64 %var_2_720, i64* %RCX.i2236, align 8
; store i64 %var_2_3058, i64* %RCX, align 8
%var_2_3059 = add i64 %var_2_3053, -28
; Matched:%var_2_2311:  %var_2_2311 = add i64 %var_2_2306, 7
; %var_2_3060 = add i64 %var_2_3055, 7
; Matched:\<badref\>:  store i64 %var_2_1598, i64* %var_2_3, align 8
; store i64 %var_2_3060, i64* %PC, align 8
%var_2_3061 = inttoptr i64 %var_2_3059 to i32*
%var_2_3062 = load i32, i32* %var_2_3061, align 4
%var_2_3063 = add i32 %var_2_3062, 1
; Matched:%var_2_1717:  %var_2_1717 = zext i32 %var_2_1716 to i64
; %var_2_3064 = zext i32 %var_2_3063 to i64
; Matched:\<badref\>:  store i64 %var_2_1263, i64* %RAX.i2224, align 8
; store i64 %var_2_3064, i64* %RAX, align 8
; Matched:%var_2_1377:  %var_2_1377 = icmp eq i32 %var_2_1374, -1
; %var_2_3065 = icmp eq i32 %var_2_3062, -1
; Matched:%var_2_753:  %var_2_753 = icmp eq i32 %var_2_750, 0
; %var_2_3066 = icmp eq i32 %var_2_3063, 0
; Matched:%var_2_1720:  %var_2_1720 = or i1 %var_2_1718, %var_2_1719
; %var_2_3067 = or i1 %var_2_3065, %var_2_3066
; Matched:%var_2_1721:  %var_2_1721 = zext i1 %var_2_1720 to i8
; %var_2_3068 = zext i1 %var_2_3067 to i8
; Matched:\<badref\>:  store i8 %var_2_1380, i8* %var_2_14, align 1
; store i8 %var_2_3068, i8* %var_2_16, align 1
; Matched:%var_2_1381:  %var_2_1381 = and i32 %var_2_1375, 255
; %var_2_3069 = and i32 %var_2_3063, 255
; Matched:%var_2_1269:  %var_2_1269 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1268)
; %var_2_3070 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3069) #14
; Matched:%var_2_1724:  %var_2_1724 = trunc i32 %var_2_1723 to i8
; %var_2_3071 = trunc i32 %var_2_3070 to i8
; Matched:%var_2_1725:  %var_2_1725 = and i8 %var_2_1724, 1
; %var_2_3072 = and i8 %var_2_3071, 1
; Matched:%var_2_1385:  %var_2_1385 = xor i8 %var_2_1384, 1
; %var_2_3073 = xor i8 %var_2_3072, 1
; Matched:\<badref\>:  store i8 %var_2_1385, i8* %var_2_21, align 1
; store i8 %var_2_3073, i8* %var_2_23, align 1
; Matched:%var_2_1386:  %var_2_1386 = xor i32 %var_2_1375, %var_2_1374
; %var_2_3074 = xor i32 %var_2_3063, %var_2_3062
; Matched:%var_2_1387:  %var_2_1387 = lshr i32 %var_2_1386, 4
; %var_2_3075 = lshr i32 %var_2_3074, 4
; Matched:%var_2_1388:  %var_2_1388 = trunc i32 %var_2_1387 to i8
; %var_2_3076 = trunc i32 %var_2_3075 to i8
; Matched:%var_2_1276:  %var_2_1276 = and i8 %var_2_1275, 1
; %var_2_3077 = and i8 %var_2_3076, 1
; Matched:\<badref\>:  store i8 %var_2_1276, i8* %var_2_27, align 1
; store i8 %var_2_3077, i8* %var_2_29, align 1
; Matched:%var_2_3079:  %var_2_3079 = zext i1 %var_2_3067 to i8
; %var_2_3078 = zext i1 %var_2_3066 to i8
; Matched:\<badref\>:  store i8 %var_2_1277, i8* %var_2_30, align 1
; store i8 %var_2_3078, i8* %var_2_32, align 1
; Matched:%var_2_1391:  %var_2_1391 = lshr i32 %var_2_1375, 31
; %var_2_3079 = lshr i32 %var_2_3063, 31
; Matched:%var_2_1392:  %var_2_1392 = trunc i32 %var_2_1391 to i8
; %var_2_3080 = trunc i32 %var_2_3079 to i8
; Matched:\<badref\>:  store i8 %var_2_1279, i8* %var_2_33, align 1
; store i8 %var_2_3080, i8* %var_2_35, align 1
; Matched:%var_2_1734:  %var_2_1734 = lshr i32 %var_2_1715, 31
; %var_2_3081 = lshr i32 %var_2_3062, 31
; Matched:%var_2_1735:  %var_2_1735 = xor i32 %var_2_1732, %var_2_1734
; %var_2_3082 = xor i32 %var_2_3079, %var_2_3081
; Matched:%var_2_1282:  %var_2_1282 = add nuw nsw i32 %var_2_1281, %var_2_1278
; %var_2_3083 = add nuw nsw i32 %var_2_3082, %var_2_3079
; Matched:%var_2_1737:  %var_2_1737 = icmp eq i32 %var_2_1736, 2
; %var_2_3084 = icmp eq i32 %var_2_3083, 2
; Matched:%var_2_4363:  %var_2_4363 = zext i1 %var_2_4362 to i8
; %var_2_3085 = zext i1 %var_2_3084 to i8
; Matched:\<badref\>:  store i8 %var_2_4363, i8* %var_2_39, align 1
; store i8 %var_2_3085, i8* %var_2_41, align 1
%var_2_3086 = sext i32 %var_2_3063 to i64
; Matched:\<badref\>:  store i64 %var_2_1398, i64* %RDX.i2239, align 8
; store i64 %var_2_3086, i64* %RDX, align 8
%var_2_3087 = shl nsw i64 %var_2_3086, 3
%var_2_3088 = add i64 %var_2_3058, %var_2_3087
; Matched:%var_2_2241:  %var_2_2241 = add i64 %var_2_2226, 18
; %var_2_3089 = add i64 %var_2_3055, 18
; Matched:\<badref\>:  store i64 %var_2_2749, i64* %var_2_3, align 8
; store i64 %var_2_3089, i64* %PC, align 8
%var_2_3090 = inttoptr i64 %var_2_3088 to i64*
%var_2_3091 = load i64, i64* %var_2_3090, align 8
store i64 %var_2_3091, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1291:  %var_2_1291 = add i64 %var_2_1254, 22
; %var_2_3092 = add i64 %var_2_3055, 22
; Matched:\<badref\>:  store i64 %var_2_3104, i64* %var_2_3, align 8
; store i64 %var_2_3092, i64* %PC, align 8
%var_2_3093 = load i64, i64* %var_2_3057, align 8
; Matched:\<badref\>:  store i64 %var_2_3146, i64* %RCX.i2236, align 8
; store i64 %var_2_3093, i64* %RCX, align 8
%var_2_3094 = add i64 %var_2_3053, -32
; Matched:%var_2_4145:  %var_2_4145 = add i64 %var_2_4105, 25
; %var_2_3095 = add i64 %var_2_3055, 25
; Matched:\<badref\>:  store i64 %var_2_4145, i64* %var_2_3, align 8
; store i64 %var_2_3095, i64* %PC, align 8
%var_2_3096 = inttoptr i64 %var_2_3094 to i32*
%var_2_3097 = load i32, i32* %var_2_3096, align 4
%var_2_3098 = add i32 %var_2_3097, 1
; Matched:%var_2_1298:  %var_2_1298 = zext i32 %var_2_1297 to i64
; %var_2_3099 = zext i32 %var_2_3098 to i64
; Matched:\<badref\>:  store i64 %var_2_1298, i64* %RAX.i2224, align 8
; store i64 %var_2_3099, i64* %RAX, align 8
; Matched:%var_2_1299:  %var_2_1299 = icmp eq i32 %var_2_1296, -1
; %var_2_3100 = icmp eq i32 %var_2_3097, -1
; Matched:%var_2_1413:  %var_2_1413 = icmp eq i32 %var_2_1410, 0
; %var_2_3101 = icmp eq i32 %var_2_3098, 0
; Matched:%var_2_1414:  %var_2_1414 = or i1 %var_2_1412, %var_2_1413
; %var_2_3102 = or i1 %var_2_3100, %var_2_3101
; Matched:%var_2_1302:  %var_2_1302 = zext i1 %var_2_1301 to i8
; %var_2_3103 = zext i1 %var_2_3102 to i8
; Matched:\<badref\>:  store i8 %var_2_1909, i8* %var_2_14, align 1
; store i8 %var_2_3103, i8* %var_2_16, align 1
; Matched:%var_2_1910:  %var_2_1910 = and i32 %var_2_1904, 255
; %var_2_3104 = and i32 %var_2_3098, 255
; Matched:%var_2_1304:  %var_2_1304 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1303)
; %var_2_3105 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3104) #14
; Matched:%var_2_1305:  %var_2_1305 = trunc i32 %var_2_1304 to i8
; %var_2_3106 = trunc i32 %var_2_3105 to i8
; Matched:%var_2_1913:  %var_2_1913 = and i8 %var_2_1912, 1
; %var_2_3107 = and i8 %var_2_3106, 1
; Matched:%var_2_1914:  %var_2_1914 = xor i8 %var_2_1913, 1
; %var_2_3108 = xor i8 %var_2_3107, 1
; Matched:\<badref\>:  store i8 %var_2_1307, i8* %var_2_21, align 1
; store i8 %var_2_3108, i8* %var_2_23, align 1
; Matched:%var_2_1421:  %var_2_1421 = xor i32 %var_2_1410, %var_2_1409
; %var_2_3109 = xor i32 %var_2_3098, %var_2_3097
; Matched:%var_2_1422:  %var_2_1422 = lshr i32 %var_2_1421, 4
; %var_2_3110 = lshr i32 %var_2_3109, 4
; Matched:%var_2_1310:  %var_2_1310 = trunc i32 %var_2_1309 to i8
; %var_2_3111 = trunc i32 %var_2_3110 to i8
; Matched:%var_2_1311:  %var_2_1311 = and i8 %var_2_1310, 1
; %var_2_3112 = and i8 %var_2_3111, 1
; Matched:\<badref\>:  store i8 %var_2_1424, i8* %var_2_27, align 1
; store i8 %var_2_3112, i8* %var_2_29, align 1
; Matched:%var_2_1312:  %var_2_1312 = zext i1 %var_2_1300 to i8
; %var_2_3113 = zext i1 %var_2_3101 to i8
; Matched:\<badref\>:  store i8 %var_2_1312, i8* %var_2_30, align 1
; store i8 %var_2_3113, i8* %var_2_32, align 1
; Matched:%var_2_1313:  %var_2_1313 = lshr i32 %var_2_1297, 31
; %var_2_3114 = lshr i32 %var_2_3098, 31
; Matched:%var_2_1314:  %var_2_1314 = trunc i32 %var_2_1313 to i8
; %var_2_3115 = trunc i32 %var_2_3114 to i8
; Matched:\<badref\>:  store i8 %var_2_1427, i8* %var_2_33, align 1
; store i8 %var_2_3115, i8* %var_2_35, align 1
; Matched:%var_2_1315:  %var_2_1315 = lshr i32 %var_2_1296, 31
; %var_2_3116 = lshr i32 %var_2_3097, 31
; Matched:%var_2_1923:  %var_2_1923 = xor i32 %var_2_1920, %var_2_1922
; %var_2_3117 = xor i32 %var_2_3114, %var_2_3116
; Matched:%var_2_1317:  %var_2_1317 = add nuw nsw i32 %var_2_1316, %var_2_1313
; %var_2_3118 = add nuw nsw i32 %var_2_3117, %var_2_3114
; Matched:%var_2_1431:  %var_2_1431 = icmp eq i32 %var_2_1430, 2
; %var_2_3119 = icmp eq i32 %var_2_3118, 2
; Matched:%var_2_1432:  %var_2_1432 = zext i1 %var_2_1431 to i8
; %var_2_3120 = zext i1 %var_2_3119 to i8
; Matched:\<badref\>:  store i8 %var_2_1432, i8* %var_2_39, align 1
; store i8 %var_2_3120, i8* %var_2_41, align 1
%var_2_3121 = sext i32 %var_2_3098 to i64
; Matched:\<badref\>:  store i64 %var_2_2781, i64* %RDX.i2239, align 8
; store i64 %var_2_3121, i64* %RDX, align 8
%var_2_3122 = shl nsw i64 %var_2_3121, 3
%var_2_3123 = add i64 %var_2_3093, %var_2_3122
; Matched:%var_2_2897:  %var_2_2897 = add i64 %var_2_2828, 36
; %var_2_3124 = add i64 %var_2_3055, 36
; Matched:\<badref\>:  store i64 %var_2_2897, i64* %var_2_3, align 8
; store i64 %var_2_3124, i64* %PC, align 8
%var_2_3125 = bitcast i64 %var_2_3091 to double
%var_2_3126 = inttoptr i64 %var_2_3123 to double*
%var_2_3127 = load double, double* %var_2_3126, align 8
%var_2_3128 = fsub double %var_2_3125, %var_2_3127
store double %var_2_3128, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_2789:  %var_2_2789 = load i64, i64* %RBP.i, align 8
; %var_2_3129 = load i64, i64* %RBP, align 8
; Matched:%var_2_4067:  %var_2_4067 = add i64 %var_2_4066, -144
; %var_2_3130 = add i64 %var_2_3129, -144
; Matched:%var_2_4181:  %var_2_4181 = add i64 %var_2_4105, 44
; %var_2_3131 = add i64 %var_2_3055, 44
; Matched:\<badref\>:  store i64 %var_2_4068, i64* %var_2_3, align 8
; store i64 %var_2_3131, i64* %PC, align 8
; Matched:%var_2_1444:  %var_2_1444 = inttoptr i64 %var_2_1442 to double*
; %var_2_3132 = inttoptr i64 %var_2_3130 to double*
; Matched:\<badref\>:  store double %var_2_1440, double* %var_2_1444, align 8
; store double %var_2_3128, double* %var_2_3132, align 8
%var_2_3133 = load i64, i64* %RBP, align 8
%var_2_3134 = add i64 %var_2_3133, -16
%var_2_3135 = load i64, i64* %PC, align 8
; Matched:%var_2_256:  %var_2_256 = add i64 %var_2_255, 4
; %var_2_3136 = add i64 %var_2_3135, 4
; Matched:\<badref\>:  store i64 %var_2_256, i64* %var_2_3, align 8
; store i64 %var_2_3136, i64* %PC, align 8
%var_2_3137 = inttoptr i64 %var_2_3134 to i64*
%var_2_3138 = load i64, i64* %var_2_3137, align 8
; Matched:\<badref\>:  store i64 %var_2_3396, i64* %RCX.i2236, align 8
; store i64 %var_2_3138, i64* %RCX, align 8
%var_2_3139 = add i64 %var_2_3133, -36
%var_2_3140 = add i64 %var_2_3135, 8
store i64 %var_2_3140, i64* %PC, align 8
%var_2_3141 = inttoptr i64 %var_2_3139 to i32*
%var_2_3142 = load i32, i32* %var_2_3141, align 4
%var_2_3143 = sext i32 %var_2_3142 to i64
; Matched:\<badref\>:  store i64 %var_2_1455, i64* %RDX.i2239, align 8
; store i64 %var_2_3143, i64* %RDX, align 8
%var_2_3144 = shl nsw i64 %var_2_3143, 3
%var_2_3145 = add i64 %var_2_3144, %var_2_3138
; Matched:%var_2_1458:  %var_2_1458 = add i64 %var_2_1447, 13
; %var_2_3146 = add i64 %var_2_3135, 13
; Matched:\<badref\>:  store i64 %var_2_810, i64* %var_2_3, align 8
; store i64 %var_2_3146, i64* %PC, align 8
%var_2_3147 = inttoptr i64 %var_2_3145 to i64*
%var_2_3148 = load i64, i64* %var_2_3147, align 8
store i64 %var_2_3148, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_3860:  %var_2_3860 = add i64 %var_2_3846, 17
; %var_2_3149 = add i64 %var_2_3135, 17
; Matched:\<badref\>:  store i64 %var_2_3860, i64* %var_2_3, align 8
; store i64 %var_2_3149, i64* %PC, align 8
%var_2_3150 = load i64, i64* %var_2_3137, align 8
; Matched:\<badref\>:  store i64 %var_2_2911, i64* %RCX.i2236, align 8
; store i64 %var_2_3150, i64* %RCX, align 8
%var_2_3151 = add i64 %var_2_3133, -40
; Matched:%var_2_3353:  %var_2_3353 = add i64 %var_2_3342, 21
; %var_2_3152 = add i64 %var_2_3135, 21
; Matched:\<badref\>:  store i64 %var_2_3353, i64* %var_2_3, align 8
; store i64 %var_2_3152, i64* %PC, align 8
%var_2_3153 = inttoptr i64 %var_2_3151 to i32*
%var_2_3154 = load i32, i32* %var_2_3153, align 4
%var_2_3155 = sext i32 %var_2_3154 to i64
; Matched:\<badref\>:  store i64 %var_2_1467, i64* %RDX.i2239, align 8
; store i64 %var_2_3155, i64* %RDX, align 8
%var_2_3156 = shl nsw i64 %var_2_3155, 3
%var_2_3157 = add i64 %var_2_3156, %var_2_3150
; Matched:%var_2_1244:  %var_2_1244 = add i64 %var_2_1221, 26
; %var_2_3158 = add i64 %var_2_3135, 26
; Matched:\<badref\>:  store i64 %var_2_1244, i64* %var_2_3, align 8
; store i64 %var_2_3158, i64* %PC, align 8
%var_2_3159 = bitcast i64 %var_2_3148 to double
%var_2_3160 = inttoptr i64 %var_2_3157 to double*
%var_2_3161 = load double, double* %var_2_3160, align 8
%var_2_3162 = fadd double %var_2_3159, %var_2_3161
store double %var_2_3162, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_509:  %var_2_509 = add i64 %var_2_479, -152
; %var_2_3163 = add i64 %var_2_3133, -152
; Matched:%var_2_1476:  %var_2_1476 = add i64 %var_2_1447, 34
; %var_2_3164 = add i64 %var_2_3135, 34
; Matched:\<badref\>:  store i64 %var_2_922, i64* %var_2_3, align 8
; store i64 %var_2_3164, i64* %PC, align 8
; Matched:%var_2_1477:  %var_2_1477 = inttoptr i64 %var_2_1475 to double*
; %var_2_3165 = inttoptr i64 %var_2_3163 to double*
; Matched:\<badref\>:  store double %var_2_4099, double* %var_2_4102, align 8
; store double %var_2_3162, double* %var_2_3165, align 8
%var_2_3166 = load i64, i64* %RBP, align 8
%var_2_3167 = add i64 %var_2_3166, -16
%var_2_3168 = load i64, i64* %PC, align 8
; Matched:%var_2_2288:  %var_2_2288 = add i64 %var_2_2287, 4
; %var_2_3169 = add i64 %var_2_3168, 4
; Matched:\<badref\>:  store i64 %var_2_2288, i64* %var_2_3, align 8
; store i64 %var_2_3169, i64* %PC, align 8
%var_2_3170 = inttoptr i64 %var_2_3167 to i64*
%var_2_3171 = load i64, i64* %var_2_3170, align 8
; Matched:\<badref\>:  store i64 %var_2_2944, i64* %RCX.i2236, align 8
; store i64 %var_2_3171, i64* %RCX, align 8
%var_2_3172 = add i64 %var_2_3166, -36
; Matched:%var_2_406:  %var_2_406 = add i64 %var_2_401, 7
; %var_2_3173 = add i64 %var_2_3168, 7
; Matched:\<badref\>:  store i64 %var_2_2311, i64* %var_2_3, align 8
; store i64 %var_2_3173, i64* %PC, align 8
%var_2_3174 = inttoptr i64 %var_2_3172 to i32*
%var_2_3175 = load i32, i32* %var_2_3174, align 4
%var_2_3176 = add i32 %var_2_3175, 1
; Matched:%var_2_824:  %var_2_824 = zext i32 %var_2_823 to i64
; %var_2_3177 = zext i32 %var_2_3176 to i64
; Matched:\<badref\>:  store i64 %var_2_824, i64* %RAX.i2224, align 8
; store i64 %var_2_3177, i64* %RAX, align 8
; Matched:%var_2_1490:  %var_2_1490 = icmp eq i32 %var_2_1487, -1
; %var_2_3178 = icmp eq i32 %var_2_3175, -1
; Matched:%var_2_1491:  %var_2_1491 = icmp eq i32 %var_2_1488, 0
; %var_2_3179 = icmp eq i32 %var_2_3176, 0
; Matched:%var_2_1492:  %var_2_1492 = or i1 %var_2_1490, %var_2_1491
; %var_2_3180 = or i1 %var_2_3178, %var_2_3179
; Matched:%var_2_1493:  %var_2_1493 = zext i1 %var_2_1492 to i8
; %var_2_3181 = zext i1 %var_2_3180 to i8
; Matched:\<badref\>:  store i8 %var_2_1493, i8* %var_2_14, align 1
; store i8 %var_2_3181, i8* %var_2_16, align 1
; Matched:%var_2_1494:  %var_2_1494 = and i32 %var_2_1488, 255
; %var_2_3182 = and i32 %var_2_3176, 255
; Matched:%var_2_1495:  %var_2_1495 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1494)
; %var_2_3183 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3182) #14
; Matched:%var_2_1496:  %var_2_1496 = trunc i32 %var_2_1495 to i8
; %var_2_3184 = trunc i32 %var_2_3183 to i8
; Matched:%var_2_832:  %var_2_832 = and i8 %var_2_831, 1
; %var_2_3185 = and i8 %var_2_3184, 1
; Matched:%var_2_1799:  %var_2_1799 = xor i8 %var_2_1798, 1
; %var_2_3186 = xor i8 %var_2_3185, 1
; Matched:\<badref\>:  store i8 %var_2_833, i8* %var_2_21, align 1
; store i8 %var_2_3186, i8* %var_2_23, align 1
; Matched:%var_2_1499:  %var_2_1499 = xor i32 %var_2_1488, %var_2_1487
; %var_2_3187 = xor i32 %var_2_3176, %var_2_3175
; Matched:%var_2_1500:  %var_2_1500 = lshr i32 %var_2_1499, 4
; %var_2_3188 = lshr i32 %var_2_3187, 4
; Matched:%var_2_1501:  %var_2_1501 = trunc i32 %var_2_1500 to i8
; %var_2_3189 = trunc i32 %var_2_3188 to i8
; Matched:%var_2_1502:  %var_2_1502 = and i8 %var_2_1501, 1
; %var_2_3190 = and i8 %var_2_3189, 1
; Matched:\<badref\>:  store i8 %var_2_1502, i8* %var_2_27, align 1
; store i8 %var_2_3190, i8* %var_2_29, align 1
; Matched:%var_2_1503:  %var_2_1503 = zext i1 %var_2_1491 to i8
; %var_2_3191 = zext i1 %var_2_3179 to i8
; Matched:\<badref\>:  store i8 %var_2_838, i8* %var_2_30, align 1
; store i8 %var_2_3191, i8* %var_2_32, align 1
; Matched:%var_2_1504:  %var_2_1504 = lshr i32 %var_2_1488, 31
; %var_2_3192 = lshr i32 %var_2_3176, 31
; Matched:%var_2_840:  %var_2_840 = trunc i32 %var_2_839 to i8
; %var_2_3193 = trunc i32 %var_2_3192 to i8
; Matched:\<badref\>:  store i8 %var_2_1505, i8* %var_2_33, align 1
; store i8 %var_2_3193, i8* %var_2_35, align 1
; Matched:%var_2_1619:  %var_2_1619 = lshr i32 %var_2_1600, 31
; %var_2_3194 = lshr i32 %var_2_3175, 31
; Matched:%var_2_1507:  %var_2_1507 = xor i32 %var_2_1504, %var_2_1506
; %var_2_3195 = xor i32 %var_2_3192, %var_2_3194
; Matched:%var_2_843:  %var_2_843 = add nuw nsw i32 %var_2_842, %var_2_839
; %var_2_3196 = add nuw nsw i32 %var_2_3195, %var_2_3192
; Matched:%var_2_4247:  %var_2_4247 = icmp eq i32 %var_2_4246, 2
; %var_2_3197 = icmp eq i32 %var_2_3196, 2
; Matched:%var_2_1811:  %var_2_1811 = zext i1 %var_2_1810 to i8
; %var_2_3198 = zext i1 %var_2_3197 to i8
; Matched:\<badref\>:  store i8 %var_2_4248, i8* %var_2_39, align 1
; store i8 %var_2_3198, i8* %var_2_41, align 1
%var_2_3199 = sext i32 %var_2_3176 to i64
; Matched:\<badref\>:  store i64 %var_2_846, i64* %RDX.i2239, align 8
; store i64 %var_2_3199, i64* %RDX, align 8
%var_2_3200 = shl nsw i64 %var_2_3199, 3
%var_2_3201 = add i64 %var_2_3171, %var_2_3200
; Matched:%var_2_1401:  %var_2_1401 = add i64 %var_2_1367, 18
; %var_2_3202 = add i64 %var_2_3168, 18
; Matched:\<badref\>:  store i64 %var_2_1401, i64* %var_2_3, align 8
; store i64 %var_2_3202, i64* %PC, align 8
%var_2_3203 = inttoptr i64 %var_2_3201 to i64*
%var_2_3204 = load i64, i64* %var_2_3203, align 8
store i64 %var_2_3204, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_4142:  %var_2_4142 = add i64 %var_2_4105, 22
; %var_2_3205 = add i64 %var_2_3168, 22
; Matched:\<badref\>:  store i64 %var_2_2978, i64* %var_2_3, align 8
; store i64 %var_2_3205, i64* %PC, align 8
%var_2_3206 = load i64, i64* %var_2_3170, align 8
; Matched:\<badref\>:  store i64 %var_2_1575, i64* %RCX.i2236, align 8
; store i64 %var_2_3206, i64* %RCX, align 8
%var_2_3207 = add i64 %var_2_3166, -40
; Matched:%var_2_1294:  %var_2_1294 = add i64 %var_2_1254, 25
; %var_2_3208 = add i64 %var_2_3168, 25
; Matched:\<badref\>:  store i64 %var_2_1294, i64* %var_2_3, align 8
; store i64 %var_2_3208, i64* %PC, align 8
%var_2_3209 = inttoptr i64 %var_2_3207 to i32*
%var_2_3210 = load i32, i32* %var_2_3209, align 4
%var_2_3211 = add i32 %var_2_3210, 1
; Matched:%var_2_1524:  %var_2_1524 = zext i32 %var_2_1523 to i64
; %var_2_3212 = zext i32 %var_2_3211 to i64
; Matched:\<badref\>:  store i64 %var_2_1524, i64* %RAX.i2224, align 8
; store i64 %var_2_3212, i64* %RAX, align 8
; Matched:%var_2_971:  %var_2_971 = icmp eq i32 %var_2_968, -1
; %var_2_3213 = icmp eq i32 %var_2_3210, -1
; Matched:%var_2_972:  %var_2_972 = icmp eq i32 %var_2_969, 0
; %var_2_3214 = icmp eq i32 %var_2_3211, 0
; Matched:%var_2_4265:  %var_2_4265 = or i1 %var_2_4263, %var_2_4264
; %var_2_3215 = or i1 %var_2_3213, %var_2_3214
; Matched:%var_2_1528:  %var_2_1528 = zext i1 %var_2_1527 to i8
; %var_2_3216 = zext i1 %var_2_3215 to i8
; Matched:\<badref\>:  store i8 %var_2_2876, i8* %var_2_14, align 1
; store i8 %var_2_3216, i8* %var_2_16, align 1
; Matched:%var_2_975:  %var_2_975 = and i32 %var_2_969, 255
; %var_2_3217 = and i32 %var_2_3211, 255
; Matched:%var_2_2878:  %var_2_2878 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2877)
; %var_2_3218 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3217) #14
; Matched:%var_2_2879:  %var_2_2879 = trunc i32 %var_2_2878 to i8
; %var_2_3219 = trunc i32 %var_2_3218 to i8
; Matched:%var_2_978:  %var_2_978 = and i8 %var_2_977, 1
; %var_2_3220 = and i8 %var_2_3219, 1
; Matched:%var_2_979:  %var_2_979 = xor i8 %var_2_978, 1
; %var_2_3221 = xor i8 %var_2_3220, 1
; Matched:\<badref\>:  store i8 %var_2_4271, i8* %var_2_21, align 1
; store i8 %var_2_3221, i8* %var_2_23, align 1
; Matched:%var_2_4272:  %var_2_4272 = xor i32 %var_2_4261, %var_2_4260
; %var_2_3222 = xor i32 %var_2_3211, %var_2_3210
; Matched:%var_2_1535:  %var_2_1535 = lshr i32 %var_2_1534, 4
; %var_2_3223 = lshr i32 %var_2_3222, 4
; Matched:%var_2_1649:  %var_2_1649 = trunc i32 %var_2_1648 to i8
; %var_2_3224 = trunc i32 %var_2_3223 to i8
; Matched:%var_2_983:  %var_2_983 = and i8 %var_2_982, 1
; %var_2_3225 = and i8 %var_2_3224, 1
; Matched:\<badref\>:  store i8 %var_2_983, i8* %var_2_27, align 1
; store i8 %var_2_3225, i8* %var_2_29, align 1
; Matched:%var_2_984:  %var_2_984 = zext i1 %var_2_972 to i8
; %var_2_3226 = zext i1 %var_2_3214 to i8
; Matched:\<badref\>:  store i8 %var_2_984, i8* %var_2_30, align 1
; store i8 %var_2_3226, i8* %var_2_32, align 1
; Matched:%var_2_985:  %var_2_985 = lshr i32 %var_2_969, 31
; %var_2_3227 = lshr i32 %var_2_3211, 31
; Matched:%var_2_986:  %var_2_986 = trunc i32 %var_2_985 to i8
; %var_2_3228 = trunc i32 %var_2_3227 to i8
; Matched:\<badref\>:  store i8 %var_2_986, i8* %var_2_33, align 1
; store i8 %var_2_3228, i8* %var_2_35, align 1
; Matched:%var_2_987:  %var_2_987 = lshr i32 %var_2_968, 31
; %var_2_3229 = lshr i32 %var_2_3210, 31
; Matched:%var_2_1542:  %var_2_1542 = xor i32 %var_2_1539, %var_2_1541
; %var_2_3230 = xor i32 %var_2_3227, %var_2_3229
; Matched:%var_2_989:  %var_2_989 = add nuw nsw i32 %var_2_988, %var_2_985
; %var_2_3231 = add nuw nsw i32 %var_2_3230, %var_2_3227
; Matched:%var_2_4282:  %var_2_4282 = icmp eq i32 %var_2_4281, 2
; %var_2_3232 = icmp eq i32 %var_2_3231, 2
; Matched:%var_2_991:  %var_2_991 = zext i1 %var_2_990 to i8
; %var_2_3233 = zext i1 %var_2_3232 to i8
; Matched:\<badref\>:  store i8 %var_2_1545, i8* %var_2_39, align 1
; store i8 %var_2_3233, i8* %var_2_41, align 1
%var_2_3234 = sext i32 %var_2_3211 to i64
; Matched:\<badref\>:  store i64 %var_2_1546, i64* %RDX.i2239, align 8
; store i64 %var_2_3234, i64* %RDX, align 8
%var_2_3235 = shl nsw i64 %var_2_3234, 3
%var_2_3236 = add i64 %var_2_3206, %var_2_3235
; Matched:%var_2_4061:  %var_2_4061 = add i64 %var_2_3992, 36
; %var_2_3237 = add i64 %var_2_3168, 36
; Matched:\<badref\>:  store i64 %var_2_4061, i64* %var_2_3, align 8
; store i64 %var_2_3237, i64* %PC, align 8
%var_2_3238 = bitcast i64 %var_2_3204 to double
%var_2_3239 = inttoptr i64 %var_2_3236 to double*
%var_2_3240 = load double, double* %var_2_3239, align 8
%var_2_3241 = fadd double %var_2_3238, %var_2_3240
store double %var_2_3241, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_1554:  %var_2_1554 = load i64, i64* %RBP.i, align 8
; %var_2_3242 = load i64, i64* %RBP, align 8
; Matched:%var_2_4180:  %var_2_4180 = add i64 %var_2_4179, -160
; %var_2_3243 = add i64 %var_2_3242, -160
; Matched:%var_2_4294:  %var_2_4294 = add i64 %var_2_4218, 44
; %var_2_3244 = add i64 %var_2_3168, 44
; Matched:\<badref\>:  store i64 %var_2_4181, i64* %var_2_3, align 8
; store i64 %var_2_3244, i64* %PC, align 8
; Matched:%var_2_1557:  %var_2_1557 = inttoptr i64 %var_2_1555 to double*
; %var_2_3245 = inttoptr i64 %var_2_3243 to double*
; Matched:\<badref\>:  store double %var_2_4178, double* %var_2_4182, align 8
; store double %var_2_3241, double* %var_2_3245, align 8
%var_2_3246 = load i64, i64* %RBP, align 8
%var_2_3247 = add i64 %var_2_3246, -16
%var_2_3248 = load i64, i64* %PC, align 8
; Matched:%var_2_3993:  %var_2_3993 = add i64 %var_2_3992, 4
; %var_2_3249 = add i64 %var_2_3248, 4
; Matched:\<badref\>:  store i64 %var_2_3993, i64* %var_2_3, align 8
; store i64 %var_2_3249, i64* %PC, align 8
%var_2_3250 = inttoptr i64 %var_2_3247 to i64*
%var_2_3251 = load i64, i64* %var_2_3250, align 8
; Matched:\<badref\>:  store i64 %var_2_2923, i64* %RCX.i2236, align 8
; store i64 %var_2_3251, i64* %RCX, align 8
%var_2_3252 = add i64 %var_2_3246, -36
%var_2_3253 = add i64 %var_2_3248, 8
store i64 %var_2_3253, i64* %PC, align 8
%var_2_3254 = inttoptr i64 %var_2_3252 to i32*
%var_2_3255 = load i32, i32* %var_2_3254, align 4
%var_2_3256 = sext i32 %var_2_3255 to i64
; Matched:\<badref\>:  store i64 %var_2_1568, i64* %RDX.i2239, align 8
; store i64 %var_2_3256, i64* %RDX, align 8
%var_2_3257 = shl nsw i64 %var_2_3256, 3
%var_2_3258 = add i64 %var_2_3257, %var_2_3251
; Matched:%var_2_1751:  %var_2_1751 = add i64 %var_2_1746, 13
; %var_2_3259 = add i64 %var_2_3248, 13
; Matched:\<badref\>:  store i64 %var_2_1751, i64* %var_2_3, align 8
; store i64 %var_2_3259, i64* %PC, align 8
%var_2_3260 = inttoptr i64 %var_2_3258 to i64*
%var_2_3261 = load i64, i64* %var_2_3260, align 8
store i64 %var_2_3261, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1574:  %var_2_1574 = add i64 %var_2_1560, 17
; %var_2_3262 = add i64 %var_2_3248, 17
; Matched:\<badref\>:  store i64 %var_2_1574, i64* %var_2_3, align 8
; store i64 %var_2_3262, i64* %PC, align 8
%var_2_3263 = load i64, i64* %var_2_3250, align 8
; Matched:\<badref\>:  store i64 %var_2_2584, i64* %RCX.i2236, align 8
; store i64 %var_2_3263, i64* %RCX, align 8
%var_2_3264 = add i64 %var_2_3246, -40
; Matched:%var_2_4542:  %var_2_4542 = add i64 %var_2_4531, 21
; %var_2_3265 = add i64 %var_2_3248, 21
; Matched:\<badref\>:  store i64 %var_2_4542, i64* %var_2_3, align 8
; store i64 %var_2_3265, i64* %PC, align 8
%var_2_3266 = inttoptr i64 %var_2_3264 to i32*
%var_2_3267 = load i32, i32* %var_2_3266, align 4
%var_2_3268 = sext i32 %var_2_3267 to i64
; Matched:\<badref\>:  store i64 %var_2_1580, i64* %RDX.i2239, align 8
; store i64 %var_2_3268, i64* %RDX, align 8
%var_2_3269 = shl nsw i64 %var_2_3268, 3
%var_2_3270 = add i64 %var_2_3269, %var_2_3263
; Matched:%var_2_2016:  %var_2_2016 = add i64 %var_2_1995, 26
; %var_2_3271 = add i64 %var_2_3248, 26
; Matched:\<badref\>:  store i64 %var_2_2016, i64* %var_2_3, align 8
; store i64 %var_2_3271, i64* %PC, align 8
%var_2_3272 = bitcast i64 %var_2_3261 to double
%var_2_3273 = inttoptr i64 %var_2_3270 to double*
%var_2_3274 = load double, double* %var_2_3273, align 8
%var_2_3275 = fsub double %var_2_3272, %var_2_3274
store double %var_2_3275, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_622:  %var_2_622 = add i64 %var_2_592, -168
; %var_2_3276 = add i64 %var_2_3246, -168
; Matched:%var_2_1589:  %var_2_1589 = add i64 %var_2_1560, 34
; %var_2_3277 = add i64 %var_2_3248, 34
; Matched:\<badref\>:  store i64 %var_2_1589, i64* %var_2_3, align 8
; store i64 %var_2_3277, i64* %PC, align 8
; Matched:%var_2_1590:  %var_2_1590 = inttoptr i64 %var_2_1588 to double*
; %var_2_3278 = inttoptr i64 %var_2_3276 to double*
; Matched:\<badref\>:  store double %var_2_4212, double* %var_2_4215, align 8
; store double %var_2_3275, double* %var_2_3278, align 8
%var_2_3279 = load i64, i64* %RBP, align 8
%var_2_3280 = add i64 %var_2_3279, -16
%var_2_3281 = load i64, i64* %PC, align 8
; Matched:%var_2_1222:  %var_2_1222 = add i64 %var_2_1221, 4
; %var_2_3282 = add i64 %var_2_3281, 4
; Matched:\<badref\>:  store i64 %var_2_1561, i64* %var_2_3, align 8
; store i64 %var_2_3282, i64* %PC, align 8
%var_2_3283 = inttoptr i64 %var_2_3280 to i64*
%var_2_3284 = load i64, i64* %var_2_3283, align 8
; Matched:\<badref\>:  store i64 %var_2_2810, i64* %RCX.i2236, align 8
; store i64 %var_2_3284, i64* %RCX, align 8
%var_2_3285 = add i64 %var_2_3279, -36
; Matched:%var_2_632:  %var_2_632 = add i64 %var_2_627, 7
; %var_2_3286 = add i64 %var_2_3281, 7
; Matched:\<badref\>:  store i64 %var_2_406, i64* %var_2_3, align 8
; store i64 %var_2_3286, i64* %PC, align 8
%var_2_3287 = inttoptr i64 %var_2_3285 to i32*
%var_2_3288 = load i32, i32* %var_2_3287, align 4
%var_2_3289 = add i32 %var_2_3288, 1
; Matched:%var_2_1489:  %var_2_1489 = zext i32 %var_2_1488 to i64
; %var_2_3290 = zext i32 %var_2_3289 to i64
; Matched:\<badref\>:  store i64 %var_2_1489, i64* %RAX.i2224, align 8
; store i64 %var_2_3290, i64* %RAX, align 8
; Matched:%var_2_1603:  %var_2_1603 = icmp eq i32 %var_2_1600, -1
; %var_2_3291 = icmp eq i32 %var_2_3288, -1
; Matched:%var_2_1604:  %var_2_1604 = icmp eq i32 %var_2_1601, 0
; %var_2_3292 = icmp eq i32 %var_2_3289, 0
; Matched:%var_2_1605:  %var_2_1605 = or i1 %var_2_1603, %var_2_1604
; %var_2_3293 = or i1 %var_2_3291, %var_2_3292
; Matched:%var_2_1606:  %var_2_1606 = zext i1 %var_2_1605 to i8
; %var_2_3294 = zext i1 %var_2_3293 to i8
; Matched:\<badref\>:  store i8 %var_2_1606, i8* %var_2_14, align 1
; store i8 %var_2_3294, i8* %var_2_16, align 1
; Matched:%var_2_1607:  %var_2_1607 = and i32 %var_2_1601, 255
; %var_2_3295 = and i32 %var_2_3289, 255
; Matched:%var_2_1608:  %var_2_1608 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1607)
; %var_2_3296 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3295) #14
; Matched:%var_2_1609:  %var_2_1609 = trunc i32 %var_2_1608 to i8
; %var_2_3297 = trunc i32 %var_2_3296 to i8
; Matched:%var_2_1497:  %var_2_1497 = and i8 %var_2_1496, 1
; %var_2_3298 = and i8 %var_2_3297, 1
; Matched:%var_2_833:  %var_2_833 = xor i8 %var_2_832, 1
; %var_2_3299 = xor i8 %var_2_3298, 1
; Matched:\<badref\>:  store i8 %var_2_1498, i8* %var_2_21, align 1
; store i8 %var_2_3299, i8* %var_2_23, align 1
; Matched:%var_2_1612:  %var_2_1612 = xor i32 %var_2_1601, %var_2_1600
; %var_2_3300 = xor i32 %var_2_3289, %var_2_3288
; Matched:%var_2_1613:  %var_2_1613 = lshr i32 %var_2_1612, 4
; %var_2_3301 = lshr i32 %var_2_3300, 4
; Matched:%var_2_1614:  %var_2_1614 = trunc i32 %var_2_1613 to i8
; %var_2_3302 = trunc i32 %var_2_3301 to i8
; Matched:%var_2_1615:  %var_2_1615 = and i8 %var_2_1614, 1
; %var_2_3303 = and i8 %var_2_3302, 1
; Matched:\<badref\>:  store i8 %var_2_1615, i8* %var_2_27, align 1
; store i8 %var_2_3303, i8* %var_2_29, align 1
; Matched:%var_2_1616:  %var_2_1616 = zext i1 %var_2_1604 to i8
; %var_2_3304 = zext i1 %var_2_3292 to i8
; Matched:\<badref\>:  store i8 %var_2_1503, i8* %var_2_30, align 1
; store i8 %var_2_3304, i8* %var_2_32, align 1
; Matched:%var_2_1617:  %var_2_1617 = lshr i32 %var_2_1601, 31
; %var_2_3305 = lshr i32 %var_2_3289, 31
; Matched:%var_2_1505:  %var_2_1505 = trunc i32 %var_2_1504 to i8
; %var_2_3306 = trunc i32 %var_2_3305 to i8
; Matched:\<badref\>:  store i8 %var_2_1618, i8* %var_2_33, align 1
; store i8 %var_2_3306, i8* %var_2_35, align 1
; Matched:%var_2_3205:  %var_2_3205 = lshr i32 %var_2_3186, 31
; %var_2_3307 = lshr i32 %var_2_3288, 31
; Matched:%var_2_1620:  %var_2_1620 = xor i32 %var_2_1617, %var_2_1619
; %var_2_3308 = xor i32 %var_2_3305, %var_2_3307
; Matched:%var_2_3207:  %var_2_3207 = add nuw nsw i32 %var_2_3206, %var_2_3203
; %var_2_3309 = add nuw nsw i32 %var_2_3308, %var_2_3305
; Matched:%var_2_1810:  %var_2_1810 = icmp eq i32 %var_2_1809, 2
; %var_2_3310 = icmp eq i32 %var_2_3309, 2
; Matched:%var_2_845:  %var_2_845 = zext i1 %var_2_844 to i8
; %var_2_3311 = zext i1 %var_2_3310 to i8
; Matched:\<badref\>:  store i8 %var_2_1811, i8* %var_2_39, align 1
; store i8 %var_2_3311, i8* %var_2_41, align 1
%var_2_3312 = sext i32 %var_2_3289 to i64
; Matched:\<badref\>:  store i64 %var_2_1511, i64* %RDX.i2239, align 8
; store i64 %var_2_3312, i64* %RDX, align 8
%var_2_3313 = shl nsw i64 %var_2_3312, 3
%var_2_3314 = add i64 %var_2_3284, %var_2_3313
; Matched:%var_2_2862:  %var_2_2862 = add i64 %var_2_2828, 18
; %var_2_3315 = add i64 %var_2_3281, 18
; Matched:\<badref\>:  store i64 %var_2_2862, i64* %var_2_3, align 8
; store i64 %var_2_3315, i64* %PC, align 8
%var_2_3316 = inttoptr i64 %var_2_3314 to i64*
%var_2_3317 = load i64, i64* %var_2_3316, align 8
store i64 %var_2_3317, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_325:  %var_2_325 = add i64 %var_2_288, 22
; %var_2_3318 = add i64 %var_2_3281, 22
; Matched:\<badref\>:  store i64 %var_2_1517, i64* %var_2_3, align 8
; store i64 %var_2_3318, i64* %PC, align 8
%var_2_3319 = load i64, i64* %var_2_3283, align 8
; Matched:\<badref\>:  store i64 %var_2_326, i64* %RCX.i2236, align 8
; store i64 %var_2_3319, i64* %RCX, align 8
%var_2_3320 = add i64 %var_2_3279, -40
; Matched:%var_2_1520:  %var_2_1520 = add i64 %var_2_1480, 25
; %var_2_3321 = add i64 %var_2_3281, 25
; Matched:\<badref\>:  store i64 %var_2_1520, i64* %var_2_3, align 8
; store i64 %var_2_3321, i64* %PC, align 8
%var_2_3322 = inttoptr i64 %var_2_3320 to i32*
%var_2_3323 = load i32, i32* %var_2_3322, align 4
%var_2_3324 = add i32 %var_2_3323, 1
; Matched:%var_2_1637:  %var_2_1637 = zext i32 %var_2_1636 to i64
; %var_2_3325 = zext i32 %var_2_3324 to i64
; Matched:\<badref\>:  store i64 %var_2_1637, i64* %RAX.i2224, align 8
; store i64 %var_2_3325, i64* %RAX, align 8
; Matched:%var_2_1525:  %var_2_1525 = icmp eq i32 %var_2_1522, -1
; %var_2_3326 = icmp eq i32 %var_2_3323, -1
; Matched:%var_2_1526:  %var_2_1526 = icmp eq i32 %var_2_1523, 0
; %var_2_3327 = icmp eq i32 %var_2_3324, 0
; Matched:%var_2_973:  %var_2_973 = or i1 %var_2_971, %var_2_972
; %var_2_3328 = or i1 %var_2_3326, %var_2_3327
; Matched:%var_2_1641:  %var_2_1641 = zext i1 %var_2_1640 to i8
; %var_2_3329 = zext i1 %var_2_3328 to i8
; Matched:\<badref\>:  store i8 %var_2_1528, i8* %var_2_14, align 1
; store i8 %var_2_3329, i8* %var_2_16, align 1
; Matched:%var_2_1529:  %var_2_1529 = and i32 %var_2_1523, 255
; %var_2_3330 = and i32 %var_2_3324, 255
; Matched:%var_2_976:  %var_2_976 = tail call i32 @llvm.ctpop.i32(i32 %var_2_975)
; %var_2_3331 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3330) #14
; Matched:%var_2_977:  %var_2_977 = trunc i32 %var_2_976 to i8
; %var_2_3332 = trunc i32 %var_2_3331 to i8
; Matched:%var_2_1532:  %var_2_1532 = and i8 %var_2_1531, 1
; %var_2_3333 = and i8 %var_2_3332, 1
; Matched:%var_2_1533:  %var_2_1533 = xor i8 %var_2_1532, 1
; %var_2_3334 = xor i8 %var_2_3333, 1
; Matched:\<badref\>:  store i8 %var_2_979, i8* %var_2_21, align 1
; store i8 %var_2_3334, i8* %var_2_23, align 1
; Matched:%var_2_980:  %var_2_980 = xor i32 %var_2_969, %var_2_968
; %var_2_3335 = xor i32 %var_2_3324, %var_2_3323
; Matched:%var_2_1648:  %var_2_1648 = lshr i32 %var_2_1647, 4
; %var_2_3336 = lshr i32 %var_2_3335, 4
; Matched:%var_2_570:  %var_2_570 = trunc i32 %var_2_569 to i8
; %var_2_3337 = trunc i32 %var_2_3336 to i8
; Matched:%var_2_1537:  %var_2_1537 = and i8 %var_2_1536, 1
; %var_2_3338 = and i8 %var_2_3337, 1
; Matched:\<badref\>:  store i8 %var_2_1537, i8* %var_2_27, align 1
; store i8 %var_2_3338, i8* %var_2_29, align 1
; Matched:%var_2_1538:  %var_2_1538 = zext i1 %var_2_1526 to i8
; %var_2_3339 = zext i1 %var_2_3327 to i8
; Matched:\<badref\>:  store i8 %var_2_1538, i8* %var_2_30, align 1
; store i8 %var_2_3339, i8* %var_2_32, align 1
; Matched:%var_2_1539:  %var_2_1539 = lshr i32 %var_2_1523, 31
; %var_2_3340 = lshr i32 %var_2_3324, 31
; Matched:%var_2_1540:  %var_2_1540 = trunc i32 %var_2_1539 to i8
; %var_2_3341 = trunc i32 %var_2_3340 to i8
; Matched:\<badref\>:  store i8 %var_2_1540, i8* %var_2_33, align 1
; store i8 %var_2_3341, i8* %var_2_35, align 1
; Matched:%var_2_1541:  %var_2_1541 = lshr i32 %var_2_1522, 31
; %var_2_3342 = lshr i32 %var_2_3323, 31
; Matched:%var_2_1655:  %var_2_1655 = xor i32 %var_2_1652, %var_2_1654
; %var_2_3343 = xor i32 %var_2_3340, %var_2_3342
; Matched:%var_2_1543:  %var_2_1543 = add nuw nsw i32 %var_2_1542, %var_2_1539
; %var_2_3344 = add nuw nsw i32 %var_2_3343, %var_2_3340
; Matched:%var_2_990:  %var_2_990 = icmp eq i32 %var_2_989, 2
; %var_2_3345 = icmp eq i32 %var_2_3344, 2
; Matched:%var_2_1545:  %var_2_1545 = zext i1 %var_2_1544 to i8
; %var_2_3346 = zext i1 %var_2_3345 to i8
; Matched:\<badref\>:  store i8 %var_2_1658, i8* %var_2_39, align 1
; store i8 %var_2_3346, i8* %var_2_41, align 1
%var_2_3347 = sext i32 %var_2_3324 to i64
; Matched:\<badref\>:  store i64 %var_2_1659, i64* %RDX.i2239, align 8
; store i64 %var_2_3347, i64* %RDX, align 8
%var_2_3348 = shl nsw i64 %var_2_3347, 3
%var_2_3349 = add i64 %var_2_3319, %var_2_3348
; Matched:%var_2_4287:  %var_2_4287 = add i64 %var_2_4218, 36
; %var_2_3350 = add i64 %var_2_3281, 36
; Matched:\<badref\>:  store i64 %var_2_4287, i64* %var_2_3, align 8
; store i64 %var_2_3350, i64* %PC, align 8
%var_2_3351 = bitcast i64 %var_2_3317 to double
%var_2_3352 = inttoptr i64 %var_2_3349 to double*
%var_2_3353 = load double, double* %var_2_3352, align 8
%var_2_3354 = fsub double %var_2_3351, %var_2_3353
store double %var_2_3354, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_4292:  %var_2_4292 = load i64, i64* %RBP.i, align 8
; %var_2_3355 = load i64, i64* %RBP, align 8
; Matched:%var_2_1668:  %var_2_1668 = add i64 %var_2_1667, -176
; %var_2_3356 = add i64 %var_2_3355, -176
; Matched:%var_2_4483:  %var_2_4483 = add i64 %var_2_4446, 44
; %var_2_3357 = add i64 %var_2_3281, 44
; Matched:\<badref\>:  store i64 %var_2_4294, i64* %var_2_3, align 8
; store i64 %var_2_3357, i64* %PC, align 8
; Matched:%var_2_704:  %var_2_704 = inttoptr i64 %var_2_702 to double*
; %var_2_3358 = inttoptr i64 %var_2_3356 to double*
; Matched:\<badref\>:  store double %var_2_1666, double* %var_2_1670, align 8
; store double %var_2_3354, double* %var_2_3358, align 8
%var_2_3359 = load i64, i64* %RBP, align 8
%var_2_3360 = add i64 %var_2_3359, -120
%var_2_3361 = load i64, i64* %PC, align 8
; Matched:%var_2_4324:  %var_2_4324 = add i64 %var_2_4323, 5
; %var_2_3362 = add i64 %var_2_3361, 5
; Matched:\<badref\>:  store i64 %var_2_4324, i64* %var_2_3, align 8
; store i64 %var_2_3362, i64* %PC, align 8
%var_2_3363 = inttoptr i64 %var_2_3360 to i64*
%var_2_3364 = load i64, i64* %var_2_3363, align 8
store i64 %var_2_3364, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_3365 = add i64 %var_2_3359, -152
; Matched:%var_2_4390:  %var_2_4390 = add i64 %var_2_4385, 13
; %var_2_3366 = add i64 %var_2_3361, 13
; Matched:\<badref\>:  store i64 %var_2_4390, i64* %var_2_3, align 8
; store i64 %var_2_3366, i64* %PC, align 8
%var_2_3367 = bitcast i64 %var_2_3364 to double
%var_2_3368 = inttoptr i64 %var_2_3365 to double*
%var_2_3369 = load double, double* %var_2_3368, align 8
%var_2_3370 = fadd double %var_2_3367, %var_2_3369
store double %var_2_3370, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_3371 = add i64 %var_2_3359, -16
; Matched:%var_2_3973:  %var_2_3973 = add i64 %var_2_3959, 17
; %var_2_3372 = add i64 %var_2_3361, 17
; Matched:\<badref\>:  store i64 %var_2_3973, i64* %var_2_3, align 8
; store i64 %var_2_3372, i64* %PC, align 8
%var_2_3373 = inttoptr i64 %var_2_3371 to i64*
%var_2_3374 = load i64, i64* %var_2_3373, align 8
; Matched:\<badref\>:  store i64 %var_2_439, i64* %RCX.i2236, align 8
; store i64 %var_2_3374, i64* %RCX, align 8
%var_2_3375 = add i64 %var_2_3359, -28
; Matched:%var_2_1238:  %var_2_1238 = add i64 %var_2_1221, 21
; %var_2_3376 = add i64 %var_2_3361, 21
; Matched:\<badref\>:  store i64 %var_2_1238, i64* %var_2_3, align 8
; store i64 %var_2_3376, i64* %PC, align 8
%var_2_3377 = inttoptr i64 %var_2_3375 to i32*
%var_2_3378 = load i32, i32* %var_2_3377, align 4
%var_2_3379 = sext i32 %var_2_3378 to i64
; Matched:\<badref\>:  store i64 %var_2_1691, i64* %RDX.i2239, align 8
; store i64 %var_2_3379, i64* %RDX, align 8
; Matched:%var_2_4317:  %var_2_4317 = shl nsw i64 %var_2_4316, 3
; %var_2_3380 = shl nsw i64 %var_2_3379, 3
; Matched:%var_2_727:  %var_2_727 = add i64 %var_2_726, %var_2_720
; %var_2_3381 = add i64 %var_2_3380, %var_2_3374
; Matched:%var_2_1357:  %var_2_1357 = add i64 %var_2_1334, 26
; %var_2_3382 = add i64 %var_2_3361, 26
; Matched:\<badref\>:  store i64 %var_2_1357, i64* %var_2_3, align 8
; store i64 %var_2_3382, i64* %PC, align 8
; Matched:%var_2_1695:  %var_2_1695 = inttoptr i64 %var_2_1693 to double*
; %var_2_3383 = inttoptr i64 %var_2_3381 to double*
; Matched:\<badref\>:  store double %var_2_716, double* %var_2_729, align 8
; store double %var_2_3370, double* %var_2_3383, align 8
%var_2_3384 = load i64, i64* %RBP, align 8
%var_2_3385 = add i64 %var_2_3384, -128
%var_2_3386 = load i64, i64* %PC, align 8
; Matched:%var_2_4672:  %var_2_4672 = add i64 %var_2_4671, 5
; %var_2_3387 = add i64 %var_2_3386, 5
; Matched:\<badref\>:  store i64 %var_2_4672, i64* %var_2_3, align 8
; store i64 %var_2_3387, i64* %PC, align 8
%var_2_3388 = inttoptr i64 %var_2_3385 to i64*
%var_2_3389 = load i64, i64* %var_2_3388, align 8
store i64 %var_2_3389, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_3390 = add i64 %var_2_3384, -160
; Matched:%var_2_1703:  %var_2_1703 = add i64 %var_2_1698, 13
; %var_2_3391 = add i64 %var_2_3386, 13
; Matched:\<badref\>:  store i64 %var_2_1703, i64* %var_2_3, align 8
; store i64 %var_2_3391, i64* %PC, align 8
%var_2_3392 = bitcast i64 %var_2_3389 to double
%var_2_3393 = inttoptr i64 %var_2_3390 to double*
%var_2_3394 = load double, double* %var_2_3393, align 8
%var_2_3395 = fadd double %var_2_3392, %var_2_3394
store double %var_2_3395, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_3396 = add i64 %var_2_3384, -16
; Matched:%var_2_1461:  %var_2_1461 = add i64 %var_2_1447, 17
; %var_2_3397 = add i64 %var_2_3386, 17
; Matched:\<badref\>:  store i64 %var_2_1461, i64* %var_2_3, align 8
; store i64 %var_2_3397, i64* %PC, align 8
%var_2_3398 = inttoptr i64 %var_2_3396 to i64*
%var_2_3399 = load i64, i64* %var_2_3398, align 8
; Matched:\<badref\>:  store i64 %var_2_496, i64* %RCX.i2236, align 8
; store i64 %var_2_3399, i64* %RCX, align 8
%var_2_3400 = add i64 %var_2_3384, -28
; Matched:%var_2_3262:  %var_2_3262 = add i64 %var_2_3247, 20
; %var_2_3401 = add i64 %var_2_3386, 20
; Matched:\<badref\>:  store i64 %var_2_3262, i64* %var_2_3, align 8
; store i64 %var_2_3401, i64* %PC, align 8
%var_2_3402 = inttoptr i64 %var_2_3400 to i32*
%var_2_3403 = load i32, i32* %var_2_3402, align 4
%var_2_3404 = add i32 %var_2_3403, 1
; Matched:%var_2_1376:  %var_2_1376 = zext i32 %var_2_1375 to i64
; %var_2_3405 = zext i32 %var_2_3404 to i64
; Matched:\<badref\>:  store i64 %var_2_1376, i64* %RAX.i2224, align 8
; store i64 %var_2_3405, i64* %RAX, align 8
; Matched:%var_2_1718:  %var_2_1718 = icmp eq i32 %var_2_1715, -1
; %var_2_3406 = icmp eq i32 %var_2_3403, -1
; Matched:%var_2_1265:  %var_2_1265 = icmp eq i32 %var_2_1262, 0
; %var_2_3407 = icmp eq i32 %var_2_3404, 0
; Matched:%var_2_4004:  %var_2_4004 = or i1 %var_2_4002, %var_2_4003
; %var_2_3408 = or i1 %var_2_3406, %var_2_3407
; Matched:%var_2_4005:  %var_2_4005 = zext i1 %var_2_4004 to i8
; %var_2_3409 = zext i1 %var_2_3408 to i8
; Matched:\<badref\>:  store i8 %var_2_2728, i8* %var_2_14, align 1
; store i8 %var_2_3409, i8* %var_2_16, align 1
; Matched:%var_2_3070:  %var_2_3070 = and i32 %var_2_3064, 255
; %var_2_3410 = and i32 %var_2_3404, 255
; Matched:%var_2_4007:  %var_2_4007 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4006)
; %var_2_3411 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3410) #14
; Matched:%var_2_4349:  %var_2_4349 = trunc i32 %var_2_4348 to i8
; %var_2_3412 = trunc i32 %var_2_3411 to i8
; Matched:%var_2_759:  %var_2_759 = and i8 %var_2_758, 1
; %var_2_3413 = and i8 %var_2_3412, 1
; Matched:%var_2_1272:  %var_2_1272 = xor i8 %var_2_1271, 1
; %var_2_3414 = xor i8 %var_2_3413, 1
; Matched:\<badref\>:  store i8 %var_2_1272, i8* %var_2_21, align 1
; store i8 %var_2_3414, i8* %var_2_23, align 1
; Matched:%var_2_1273:  %var_2_1273 = xor i32 %var_2_1262, %var_2_1261
; %var_2_3415 = xor i32 %var_2_3404, %var_2_3403
; Matched:%var_2_1274:  %var_2_1274 = lshr i32 %var_2_1273, 4
; %var_2_3416 = lshr i32 %var_2_3415, 4
; Matched:%var_2_1275:  %var_2_1275 = trunc i32 %var_2_1274 to i8
; %var_2_3417 = trunc i32 %var_2_3416 to i8
; Matched:%var_2_4014:  %var_2_4014 = and i8 %var_2_4013, 1
; %var_2_3418 = and i8 %var_2_3417, 1
; Matched:\<badref\>:  store i8 %var_2_4014, i8* %var_2_27, align 1
; store i8 %var_2_3418, i8* %var_2_29, align 1
; Matched:%var_2_1731:  %var_2_1731 = zext i1 %var_2_1719 to i8
; %var_2_3419 = zext i1 %var_2_3407 to i8
; Matched:\<badref\>:  store i8 %var_2_3079, i8* %var_2_30, align 1
; store i8 %var_2_3419, i8* %var_2_32, align 1
; Matched:%var_2_1278:  %var_2_1278 = lshr i32 %var_2_1262, 31
; %var_2_3420 = lshr i32 %var_2_3404, 31
; Matched:%var_2_4017:  %var_2_4017 = trunc i32 %var_2_4016 to i8
; %var_2_3421 = trunc i32 %var_2_3420 to i8
; Matched:\<badref\>:  store i8 %var_2_3081, i8* %var_2_33, align 1
; store i8 %var_2_3421, i8* %var_2_35, align 1
; Matched:%var_2_4018:  %var_2_4018 = lshr i32 %var_2_3999, 31
; %var_2_3422 = lshr i32 %var_2_3403, 31
; Matched:%var_2_4019:  %var_2_4019 = xor i32 %var_2_4016, %var_2_4018
; %var_2_3423 = xor i32 %var_2_3420, %var_2_3422
; Matched:%var_2_4020:  %var_2_4020 = add nuw nsw i32 %var_2_4019, %var_2_4016
; %var_2_3424 = add nuw nsw i32 %var_2_3423, %var_2_3420
; Matched:%var_2_4021:  %var_2_4021 = icmp eq i32 %var_2_4020, 2
; %var_2_3425 = icmp eq i32 %var_2_3424, 2
; Matched:%var_2_3909:  %var_2_3909 = zext i1 %var_2_3908 to i8
; %var_2_3426 = zext i1 %var_2_3425 to i8
; Matched:\<badref\>:  store i8 %var_2_3909, i8* %var_2_39, align 1
; store i8 %var_2_3426, i8* %var_2_41, align 1
%var_2_3427 = sext i32 %var_2_3404 to i64
; Matched:\<badref\>:  store i64 %var_2_1285, i64* %RDX.i2239, align 8
; store i64 %var_2_3427, i64* %RDX, align 8
; Matched:%var_2_1740:  %var_2_1740 = shl nsw i64 %var_2_1739, 3
; %var_2_3428 = shl nsw i64 %var_2_3427, 3
; Matched:%var_2_1741:  %var_2_1741 = add i64 %var_2_1711, %var_2_1740
; %var_2_3429 = add i64 %var_2_3399, %var_2_3428
; Matched:%var_2_4733:  %var_2_4733 = add i64 %var_2_4707, 31
; %var_2_3430 = add i64 %var_2_3386, 31
; Matched:\<badref\>:  store i64 %var_2_776, i64* %var_2_3, align 8
; store i64 %var_2_3430, i64* %PC, align 8
; Matched:%var_2_4368:  %var_2_4368 = inttoptr i64 %var_2_4366 to double*
; %var_2_3431 = inttoptr i64 %var_2_3429 to double*
; Matched:\<badref\>:  store double %var_2_1707, double* %var_2_1743, align 8
; store double %var_2_3395, double* %var_2_3431, align 8
%var_2_3432 = load i64, i64* %RBP, align 8
%var_2_3433 = add i64 %var_2_3432, -120
%var_2_3434 = load i64, i64* %PC, align 8
; Matched:%var_2_1965:  %var_2_1965 = add i64 %var_2_1964, 5
; %var_2_3435 = add i64 %var_2_3434, 5
; Matched:\<badref\>:  store i64 %var_2_1965, i64* %var_2_3, align 8
; store i64 %var_2_3435, i64* %PC, align 8
%var_2_3436 = inttoptr i64 %var_2_3433 to i64*
%var_2_3437 = load i64, i64* %var_2_3436, align 8
store i64 %var_2_3437, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_3438 = add i64 %var_2_3432, -152
; Matched:%var_2_3113:  %var_2_3113 = add i64 %var_2_3108, 13
; %var_2_3439 = add i64 %var_2_3434, 13
; Matched:\<badref\>:  store i64 %var_2_3113, i64* %var_2_3, align 8
; store i64 %var_2_3439, i64* %PC, align 8
%var_2_3440 = bitcast i64 %var_2_3437 to double
%var_2_3441 = inttoptr i64 %var_2_3438 to double*
%var_2_3442 = load double, double* %var_2_3441, align 8
%var_2_3443 = fsub double %var_2_3440, %var_2_3442
; Matched:\<badref\>:  store double %var_2_1780, double* %var_2_1037, align 1
; store double %var_2_3443, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_3444 = add i64 %var_2_3432, -16
; Matched:%var_2_1709:  %var_2_1709 = add i64 %var_2_1698, 17
; %var_2_3445 = add i64 %var_2_3434, 17
; Matched:\<badref\>:  store i64 %var_2_1709, i64* %var_2_3, align 8
; store i64 %var_2_3445, i64* %PC, align 8
%var_2_3446 = inttoptr i64 %var_2_3444 to i64*
%var_2_3447 = load i64, i64* %var_2_3446, align 8
; Matched:\<badref\>:  store i64 %var_2_1868, i64* %RCX.i2236, align 8
; store i64 %var_2_3447, i64* %RCX, align 8
%var_2_3448 = add i64 %var_2_3432, -36
; Matched:%var_2_4202:  %var_2_4202 = add i64 %var_2_4185, 21
; %var_2_3449 = add i64 %var_2_3434, 21
; Matched:\<badref\>:  store i64 %var_2_4202, i64* %var_2_3, align 8
; store i64 %var_2_3449, i64* %PC, align 8
%var_2_3450 = inttoptr i64 %var_2_3448 to i32*
%var_2_3451 = load i32, i32* %var_2_3450, align 4
%var_2_3452 = sext i32 %var_2_3451 to i64
; Matched:\<badref\>:  store i64 %var_2_1764, i64* %RDX.i2239, align 8
; store i64 %var_2_3452, i64* %RDX, align 8
; Matched:%var_2_799:  %var_2_799 = shl nsw i64 %var_2_798, 3
; %var_2_3453 = shl nsw i64 %var_2_3452, 3
; Matched:%var_2_800:  %var_2_800 = add i64 %var_2_799, %var_2_793
; %var_2_3454 = add i64 %var_2_3453, %var_2_3447
; Matched:%var_2_617:  %var_2_617 = add i64 %var_2_594, 26
; %var_2_3455 = add i64 %var_2_3434, 26
; Matched:\<badref\>:  store i64 %var_2_617, i64* %var_2_3, align 8
; store i64 %var_2_3455, i64* %PC, align 8
; Matched:%var_2_802:  %var_2_802 = inttoptr i64 %var_2_800 to double*
; %var_2_3456 = inttoptr i64 %var_2_3454 to double*
; Matched:\<badref\>:  store double %var_2_789, double* %var_2_802, align 8
; store double %var_2_3443, double* %var_2_3456, align 8
%var_2_3457 = load i64, i64* %RBP, align 8
%var_2_3458 = add i64 %var_2_3457, -128
%var_2_3459 = load i64, i64* %PC, align 8
; Matched:%var_2_3284:  %var_2_3284 = add i64 %var_2_3283, 5
; %var_2_3460 = add i64 %var_2_3459, 5
; Matched:\<badref\>:  store i64 %var_2_3284, i64* %var_2_3, align 8
; store i64 %var_2_3460, i64* %PC, align 8
%var_2_3461 = inttoptr i64 %var_2_3458 to i64*
%var_2_3462 = load i64, i64* %var_2_3461, align 8
store i64 %var_2_3462, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_3463 = add i64 %var_2_3457, -160
; Matched:%var_2_4303:  %var_2_4303 = add i64 %var_2_4298, 13
; %var_2_3464 = add i64 %var_2_3459, 13
; Matched:\<badref\>:  store i64 %var_2_4303, i64* %var_2_3, align 8
; store i64 %var_2_3464, i64* %PC, align 8
%var_2_3465 = bitcast i64 %var_2_3462 to double
%var_2_3466 = inttoptr i64 %var_2_3463 to double*
%var_2_3467 = load double, double* %var_2_3466, align 8
%var_2_3468 = fsub double %var_2_3465, %var_2_3467
store double %var_2_3468, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_3469 = add i64 %var_2_3457, -16
; Matched:%var_2_2583:  %var_2_2583 = add i64 %var_2_2569, 17
; %var_2_3470 = add i64 %var_2_3459, 17
; Matched:\<badref\>:  store i64 %var_2_2583, i64* %var_2_3, align 8
; store i64 %var_2_3470, i64* %PC, align 8
%var_2_3471 = inttoptr i64 %var_2_3469 to i64*
%var_2_3472 = load i64, i64* %var_2_3471, align 8
; Matched:\<badref\>:  store i64 %var_2_3182, i64* %RCX.i2236, align 8
; store i64 %var_2_3472, i64* %RCX, align 8
%var_2_3473 = add i64 %var_2_3457, -36
; Matched:%var_2_3298:  %var_2_3298 = add i64 %var_2_3283, 20
; %var_2_3474 = add i64 %var_2_3459, 20
; Matched:\<badref\>:  store i64 %var_2_3298, i64* %var_2_3, align 8
; store i64 %var_2_3474, i64* %PC, align 8
%var_2_3475 = inttoptr i64 %var_2_3473 to i32*
%var_2_3476 = load i32, i32* %var_2_3475, align 4
%var_2_3477 = add i32 %var_2_3476, 1
; Matched:%var_2_3188:  %var_2_3188 = zext i32 %var_2_3187 to i64
; %var_2_3478 = zext i32 %var_2_3477 to i64
; Matched:\<badref\>:  store i64 %var_2_3188, i64* %RAX.i2224, align 8
; store i64 %var_2_3478, i64* %RAX, align 8
; Matched:%var_2_1791:  %var_2_1791 = icmp eq i32 %var_2_1788, -1
; %var_2_3479 = icmp eq i32 %var_2_3476, -1
; Matched:%var_2_1792:  %var_2_1792 = icmp eq i32 %var_2_1789, 0
; %var_2_3480 = icmp eq i32 %var_2_3477, 0
; Matched:%var_2_1793:  %var_2_1793 = or i1 %var_2_1791, %var_2_1792
; %var_2_3481 = or i1 %var_2_3479, %var_2_3480
; Matched:%var_2_1794:  %var_2_1794 = zext i1 %var_2_1793 to i8
; %var_2_3482 = zext i1 %var_2_3481 to i8
; Matched:\<badref\>:  store i8 %var_2_1794, i8* %var_2_14, align 1
; store i8 %var_2_3482, i8* %var_2_16, align 1
; Matched:%var_2_1795:  %var_2_1795 = and i32 %var_2_1789, 255
; %var_2_3483 = and i32 %var_2_3477, 255
; Matched:%var_2_1796:  %var_2_1796 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1795)
; %var_2_3484 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3483) #14
; Matched:%var_2_1797:  %var_2_1797 = trunc i32 %var_2_1796 to i8
; %var_2_3485 = trunc i32 %var_2_3484 to i8
; Matched:%var_2_4235:  %var_2_4235 = and i8 %var_2_4234, 1
; %var_2_3486 = and i8 %var_2_3485, 1
; Matched:%var_2_3197:  %var_2_3197 = xor i8 %var_2_3196, 1
; %var_2_3487 = xor i8 %var_2_3486, 1
; Matched:\<badref\>:  store i8 %var_2_4236, i8* %var_2_21, align 1
; store i8 %var_2_3487, i8* %var_2_23, align 1
; Matched:%var_2_1800:  %var_2_1800 = xor i32 %var_2_1789, %var_2_1788
; %var_2_3488 = xor i32 %var_2_3477, %var_2_3476
; Matched:%var_2_1801:  %var_2_1801 = lshr i32 %var_2_1800, 4
; %var_2_3489 = lshr i32 %var_2_3488, 4
; Matched:%var_2_1802:  %var_2_1802 = trunc i32 %var_2_1801 to i8
; %var_2_3490 = trunc i32 %var_2_3489 to i8
; Matched:%var_2_1803:  %var_2_1803 = and i8 %var_2_1802, 1
; %var_2_3491 = and i8 %var_2_3490, 1
; Matched:\<badref\>:  store i8 %var_2_1803, i8* %var_2_27, align 1
; store i8 %var_2_3491, i8* %var_2_29, align 1
; Matched:%var_2_1804:  %var_2_1804 = zext i1 %var_2_1792 to i8
; %var_2_3492 = zext i1 %var_2_3480 to i8
; Matched:\<badref\>:  store i8 %var_2_4241, i8* %var_2_30, align 1
; store i8 %var_2_3492, i8* %var_2_32, align 1
; Matched:%var_2_1805:  %var_2_1805 = lshr i32 %var_2_1789, 31
; %var_2_3493 = lshr i32 %var_2_3477, 31
; Matched:%var_2_4243:  %var_2_4243 = trunc i32 %var_2_4242 to i8
; %var_2_3494 = trunc i32 %var_2_3493 to i8
; Matched:\<badref\>:  store i8 %var_2_1806, i8* %var_2_33, align 1
; store i8 %var_2_3494, i8* %var_2_35, align 1
; Matched:%var_2_1807:  %var_2_1807 = lshr i32 %var_2_1788, 31
; %var_2_3495 = lshr i32 %var_2_3476, 31
; Matched:%var_2_4245:  %var_2_4245 = xor i32 %var_2_4242, %var_2_4244
; %var_2_3496 = xor i32 %var_2_3493, %var_2_3495
; Matched:%var_2_4133:  %var_2_4133 = add nuw nsw i32 %var_2_4132, %var_2_4129
; %var_2_3497 = add nuw nsw i32 %var_2_3496, %var_2_3493
; Matched:%var_2_4507:  %var_2_4507 = icmp eq i32 %var_2_4506, 2
; %var_2_3498 = icmp eq i32 %var_2_3497, 2
; Matched:%var_2_4135:  %var_2_4135 = zext i1 %var_2_4134 to i8
; %var_2_3499 = zext i1 %var_2_3498 to i8
; Matched:\<badref\>:  store i8 %var_2_3209, i8* %var_2_39, align 1
; store i8 %var_2_3499, i8* %var_2_41, align 1
%var_2_3500 = sext i32 %var_2_3477 to i64
; Matched:\<badref\>:  store i64 %var_2_3210, i64* %RDX.i2239, align 8
; store i64 %var_2_3500, i64* %RDX, align 8
; Matched:%var_2_847:  %var_2_847 = shl nsw i64 %var_2_846, 3
; %var_2_3501 = shl nsw i64 %var_2_3500, 3
; Matched:%var_2_848:  %var_2_848 = add i64 %var_2_818, %var_2_847
; %var_2_3502 = add i64 %var_2_3472, %var_2_3501
; Matched:%var_2_1250:  %var_2_1250 = add i64 %var_2_1221, 31
; %var_2_3503 = add i64 %var_2_3459, 31
; Matched:\<badref\>:  store i64 %var_2_1250, i64* %var_2_3, align 8
; store i64 %var_2_3503, i64* %PC, align 8
; Matched:%var_2_850:  %var_2_850 = inttoptr i64 %var_2_848 to double*
; %var_2_3504 = inttoptr i64 %var_2_3502 to double*
; Matched:\<badref\>:  store double %var_2_814, double* %var_2_850, align 8
; store double %var_2_3468, double* %var_2_3504, align 8
%var_2_3505 = load i64, i64* %RBP, align 8
%var_2_3506 = add i64 %var_2_3505, -136
%var_2_3507 = load i64, i64* %PC, align 8
%var_2_3508 = add i64 %var_2_3507, 8
store i64 %var_2_3508, i64* %PC, align 8
%var_2_3509 = inttoptr i64 %var_2_3506 to i64*
%var_2_3510 = load i64, i64* %var_2_3509, align 8
store i64 %var_2_3510, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_3511 = add i64 %var_2_3505, -176
; Matched:%var_2_931:  %var_2_931 = add i64 %var_2_926, 16
; %var_2_3512 = add i64 %var_2_3507, 16
; Matched:\<badref\>:  store i64 %var_2_931, i64* %var_2_3, align 8
; store i64 %var_2_3512, i64* %PC, align 8
%var_2_3513 = bitcast i64 %var_2_3510 to double
%var_2_3514 = inttoptr i64 %var_2_3511 to double*
%var_2_3515 = load double, double* %var_2_3514, align 8
%var_2_3516 = fsub double %var_2_3513, %var_2_3515
store double %var_2_3516, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_3517 = add i64 %var_2_3505, -16
; Matched:%var_2_962:  %var_2_962 = add i64 %var_2_951, 20
; %var_2_3518 = add i64 %var_2_3507, 20
; Matched:\<badref\>:  store i64 %var_2_962, i64* %var_2_3, align 8
; store i64 %var_2_3518, i64* %PC, align 8
%var_2_3519 = inttoptr i64 %var_2_3517 to i64*
%var_2_3520 = load i64, i64* %var_2_3519, align 8
; Matched:\<badref\>:  store i64 %var_2_3271, i64* %RCX.i2236, align 8
; store i64 %var_2_3520, i64* %RCX, align 8
%var_2_3521 = add i64 %var_2_3505, -32
; Matched:%var_2_941:  %var_2_941 = add i64 %var_2_926, 24
; %var_2_3522 = add i64 %var_2_3507, 24
; Matched:\<badref\>:  store i64 %var_2_941, i64* %var_2_3, align 8
; store i64 %var_2_3522, i64* %PC, align 8
%var_2_3523 = inttoptr i64 %var_2_3521 to i32*
%var_2_3524 = load i32, i32* %var_2_3523, align 4
%var_2_3525 = sext i32 %var_2_3524 to i64
; Matched:\<badref\>:  store i64 %var_2_3276, i64* %RDX.i2239, align 8
; store i64 %var_2_3525, i64* %RDX, align 8
; Matched:%var_2_872:  %var_2_872 = shl nsw i64 %var_2_871, 3
; %var_2_3526 = shl nsw i64 %var_2_3525, 3
; Matched:%var_2_873:  %var_2_873 = add i64 %var_2_872, %var_2_866
; %var_2_3527 = add i64 %var_2_3526, %var_2_3520
; Matched:%var_2_874:  %var_2_874 = add i64 %var_2_853, 29
; %var_2_3528 = add i64 %var_2_3507, 29
; Matched:\<badref\>:  store i64 %var_2_874, i64* %var_2_3, align 8
; store i64 %var_2_3528, i64* %PC, align 8
; Matched:%var_2_875:  %var_2_875 = inttoptr i64 %var_2_873 to double*
; %var_2_3529 = inttoptr i64 %var_2_3527 to double*
; Matched:\<badref\>:  store double %var_2_862, double* %var_2_875, align 8
; store double %var_2_3516, double* %var_2_3529, align 8
%var_2_3530 = load i64, i64* %RBP, align 8
%var_2_3531 = add i64 %var_2_3530, -144
%var_2_3532 = load i64, i64* %PC, align 8
%var_2_3533 = add i64 %var_2_3532, 8
store i64 %var_2_3533, i64* %PC, align 8
%var_2_3534 = inttoptr i64 %var_2_3531 to i64*
%var_2_3535 = load i64, i64* %var_2_3534, align 8
store i64 %var_2_3535, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_3536 = add i64 %var_2_3530, -168
; Matched:%var_2_1824:  %var_2_1824 = add i64 %var_2_1819, 16
; %var_2_3537 = add i64 %var_2_3532, 16
; Matched:\<badref\>:  store i64 %var_2_1824, i64* %var_2_3, align 8
; store i64 %var_2_3537, i64* %PC, align 8
%var_2_3538 = bitcast i64 %var_2_3535 to double
%var_2_3539 = inttoptr i64 %var_2_3536 to double*
%var_2_3540 = load double, double* %var_2_3539, align 8
%var_2_3541 = fadd double %var_2_3538, %var_2_3540
store double %var_2_3541, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_3542 = add i64 %var_2_3530, -16
; Matched:%var_2_937:  %var_2_937 = add i64 %var_2_926, 20
; %var_2_3543 = add i64 %var_2_3532, 20
; Matched:\<badref\>:  store i64 %var_2_937, i64* %var_2_3, align 8
; store i64 %var_2_3543, i64* %PC, align 8
%var_2_3544 = inttoptr i64 %var_2_3542 to i64*
%var_2_3545 = load i64, i64* %var_2_3544, align 8
; Matched:\<badref\>:  store i64 %var_2_609, i64* %RCX.i2236, align 8
; store i64 %var_2_3545, i64* %RCX, align 8
%var_2_3546 = add i64 %var_2_3530, -32
; Matched:%var_2_2283:  %var_2_2283 = add i64 %var_2_2245, 23
; %var_2_3547 = add i64 %var_2_3532, 23
; Matched:\<badref\>:  store i64 %var_2_2283, i64* %var_2_3, align 8
; store i64 %var_2_3547, i64* %PC, align 8
%var_2_3548 = inttoptr i64 %var_2_3546 to i32*
%var_2_3549 = load i32, i32* %var_2_3548, align 4
%var_2_3550 = add i32 %var_2_3549, 1
; Matched:%var_2_2759:  %var_2_2759 = zext i32 %var_2_2758 to i64
; %var_2_3551 = zext i32 %var_2_3550 to i64
; Matched:\<badref\>:  store i64 %var_2_2759, i64* %RAX.i2224, align 8
; store i64 %var_2_3551, i64* %RAX, align 8
; Matched:%var_2_4037:  %var_2_4037 = icmp eq i32 %var_2_4034, -1
; %var_2_3552 = icmp eq i32 %var_2_3549, -1
; Matched:%var_2_1907:  %var_2_1907 = icmp eq i32 %var_2_1904, 0
; %var_2_3553 = icmp eq i32 %var_2_3550, 0
; Matched:%var_2_1908:  %var_2_1908 = or i1 %var_2_1906, %var_2_1907
; %var_2_3554 = or i1 %var_2_3552, %var_2_3553
; Matched:%var_2_4040:  %var_2_4040 = zext i1 %var_2_4039 to i8
; %var_2_3555 = zext i1 %var_2_3554 to i8
; Matched:\<badref\>:  store i8 %var_2_3927, i8* %var_2_14, align 1
; store i8 %var_2_3555, i8* %var_2_16, align 1
; Matched:%var_2_3928:  %var_2_3928 = and i32 %var_2_3922, 255
; %var_2_3556 = and i32 %var_2_3550, 255
; Matched:%var_2_4042:  %var_2_4042 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4041)
; %var_2_3557 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3556) #14
; Matched:%var_2_4043:  %var_2_4043 = trunc i32 %var_2_4042 to i8
; %var_2_3558 = trunc i32 %var_2_3557 to i8
; Matched:%var_2_3931:  %var_2_3931 = and i8 %var_2_3930, 1
; %var_2_3559 = and i8 %var_2_3558, 1
; Matched:%var_2_3932:  %var_2_3932 = xor i8 %var_2_3931, 1
; %var_2_3560 = xor i8 %var_2_3559, 1
; Matched:\<badref\>:  store i8 %var_2_4045, i8* %var_2_21, align 1
; store i8 %var_2_3560, i8* %var_2_23, align 1
; Matched:%var_2_1915:  %var_2_1915 = xor i32 %var_2_1904, %var_2_1903
; %var_2_3561 = xor i32 %var_2_3550, %var_2_3549
; Matched:%var_2_1916:  %var_2_1916 = lshr i32 %var_2_1915, 4
; %var_2_3562 = lshr i32 %var_2_3561, 4
; Matched:%var_2_344:  %var_2_344 = trunc i32 %var_2_343 to i8
; %var_2_3563 = trunc i32 %var_2_3562 to i8
; Matched:%var_2_1424:  %var_2_1424 = and i8 %var_2_1423, 1
; %var_2_3564 = and i8 %var_2_3563, 1
; Matched:\<badref\>:  store i8 %var_2_1918, i8* %var_2_27, align 1
; store i8 %var_2_3564, i8* %var_2_29, align 1
; Matched:%var_2_4050:  %var_2_4050 = zext i1 %var_2_4038 to i8
; %var_2_3565 = zext i1 %var_2_3553 to i8
; Matched:\<badref\>:  store i8 %var_2_4050, i8* %var_2_30, align 1
; store i8 %var_2_3565, i8* %var_2_32, align 1
; Matched:%var_2_2774:  %var_2_2774 = lshr i32 %var_2_2758, 31
; %var_2_3566 = lshr i32 %var_2_3550, 31
; Matched:%var_2_2775:  %var_2_2775 = trunc i32 %var_2_2774 to i8
; %var_2_3567 = trunc i32 %var_2_3566 to i8
; Matched:\<badref\>:  store i8 %var_2_2662, i8* %var_2_33, align 1
; store i8 %var_2_3567, i8* %var_2_35, align 1
; Matched:%var_2_4053:  %var_2_4053 = lshr i32 %var_2_4034, 31
; %var_2_3568 = lshr i32 %var_2_3549, 31
; Matched:%var_2_3941:  %var_2_3941 = xor i32 %var_2_3938, %var_2_3940
; %var_2_3569 = xor i32 %var_2_3566, %var_2_3568
; Matched:%var_2_4055:  %var_2_4055 = add nuw nsw i32 %var_2_4054, %var_2_4051
; %var_2_3570 = add nuw nsw i32 %var_2_3569, %var_2_3566
; Matched:%var_2_1925:  %var_2_1925 = icmp eq i32 %var_2_1924, 2
; %var_2_3571 = icmp eq i32 %var_2_3570, 2
; Matched:%var_2_1926:  %var_2_1926 = zext i1 %var_2_1925 to i8
; %var_2_3572 = zext i1 %var_2_3571 to i8
; Matched:\<badref\>:  store i8 %var_2_1926, i8* %var_2_39, align 1
; store i8 %var_2_3572, i8* %var_2_41, align 1
%var_2_3573 = sext i32 %var_2_3550 to i64
; Matched:\<badref\>:  store i64 %var_2_919, i64* %RDX.i2239, align 8
; store i64 %var_2_3573, i64* %RDX, align 8
; Matched:%var_2_920:  %var_2_920 = shl nsw i64 %var_2_919, 3
; %var_2_3574 = shl nsw i64 %var_2_3573, 3
; Matched:%var_2_921:  %var_2_921 = add i64 %var_2_891, %var_2_920
; %var_2_3575 = add i64 %var_2_3545, %var_2_3574
; Matched:%var_2_922:  %var_2_922 = add i64 %var_2_878, 34
; %var_2_3576 = add i64 %var_2_3532, 34
; Matched:\<badref\>:  store i64 %var_2_1363, i64* %var_2_3, align 8
; store i64 %var_2_3576, i64* %PC, align 8
; Matched:%var_2_923:  %var_2_923 = inttoptr i64 %var_2_921 to double*
; %var_2_3577 = inttoptr i64 %var_2_3575 to double*
; Matched:\<badref\>:  store double %var_2_887, double* %var_2_923, align 8
; store double %var_2_3541, double* %var_2_3577, align 8
%var_2_3578 = load i64, i64* %RBP, align 8
%var_2_3579 = add i64 %var_2_3578, -136
%var_2_3580 = load i64, i64* %PC, align 8
%var_2_3581 = add i64 %var_2_3580, 8
store i64 %var_2_3581, i64* %PC, align 8
%var_2_3582 = inttoptr i64 %var_2_3579 to i64*
%var_2_3583 = load i64, i64* %var_2_3582, align 8
store i64 %var_2_3583, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_3584 = add i64 %var_2_3578, -176
; Matched:%var_2_3222:  %var_2_3222 = add i64 %var_2_3217, 16
; %var_2_3585 = add i64 %var_2_3580, 16
; Matched:\<badref\>:  store i64 %var_2_3222, i64* %var_2_3, align 8
; store i64 %var_2_3585, i64* %PC, align 8
%var_2_3586 = bitcast i64 %var_2_3583 to double
%var_2_3587 = inttoptr i64 %var_2_3584 to double*
%var_2_3588 = load double, double* %var_2_3587, align 8
%var_2_3589 = fadd double %var_2_3586, %var_2_3588
store double %var_2_3589, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_3590 = add i64 %var_2_3578, -16
; Matched:%var_2_864:  %var_2_864 = add i64 %var_2_853, 20
; %var_2_3591 = add i64 %var_2_3580, 20
; Matched:\<badref\>:  store i64 %var_2_864, i64* %var_2_3, align 8
; store i64 %var_2_3591, i64* %PC, align 8
%var_2_3592 = inttoptr i64 %var_2_3590 to i64*
%var_2_3593 = load i64, i64* %var_2_3592, align 8
; Matched:\<badref\>:  store i64 %var_2_2697, i64* %RCX.i2236, align 8
; store i64 %var_2_3593, i64* %RCX, align 8
%var_2_3594 = add i64 %var_2_3578, -40
; Matched:%var_2_868:  %var_2_868 = add i64 %var_2_853, 24
; %var_2_3595 = add i64 %var_2_3580, 24
; Matched:\<badref\>:  store i64 %var_2_868, i64* %var_2_3, align 8
; store i64 %var_2_3595, i64* %PC, align 8
%var_2_3596 = inttoptr i64 %var_2_3594 to i32*
%var_2_3597 = load i32, i32* %var_2_3596, align 4
%var_2_3598 = sext i32 %var_2_3597 to i64
; Matched:\<badref\>:  store i64 %var_2_2815, i64* %RDX.i2239, align 8
; store i64 %var_2_3598, i64* %RDX, align 8
; Matched:%var_2_945:  %var_2_945 = shl nsw i64 %var_2_944, 3
; %var_2_3599 = shl nsw i64 %var_2_3598, 3
; Matched:%var_2_946:  %var_2_946 = add i64 %var_2_945, %var_2_939
; %var_2_3600 = add i64 %var_2_3599, %var_2_3593
; Matched:%var_2_947:  %var_2_947 = add i64 %var_2_926, 29
; %var_2_3601 = add i64 %var_2_3580, 29
; Matched:\<badref\>:  store i64 %var_2_947, i64* %var_2_3, align 8
; store i64 %var_2_3601, i64* %PC, align 8
; Matched:%var_2_948:  %var_2_948 = inttoptr i64 %var_2_946 to double*
; %var_2_3602 = inttoptr i64 %var_2_3600 to double*
; Matched:\<badref\>:  store double %var_2_935, double* %var_2_948, align 8
; store double %var_2_3589, double* %var_2_3602, align 8
%var_2_3603 = load i64, i64* %RBP, align 8
%var_2_3604 = add i64 %var_2_3603, -144
%var_2_3605 = load i64, i64* %PC, align 8
%var_2_3606 = add i64 %var_2_3605, 8
store i64 %var_2_3606, i64* %PC, align 8
%var_2_3607 = inttoptr i64 %var_2_3604 to i64*
%var_2_3608 = load i64, i64* %var_2_3607, align 8
store i64 %var_2_3608, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_3609 = add i64 %var_2_3603, -168
; Matched:%var_2_4521:  %var_2_4521 = add i64 %var_2_4516, 16
; %var_2_3610 = add i64 %var_2_3605, 16
; Matched:\<badref\>:  store i64 %var_2_4521, i64* %var_2_3, align 8
; store i64 %var_2_3610, i64* %PC, align 8
%var_2_3611 = bitcast i64 %var_2_3608 to double
%var_2_3612 = inttoptr i64 %var_2_3609 to double*
%var_2_3613 = load double, double* %var_2_3612, align 8
%var_2_3614 = fsub double %var_2_3611, %var_2_3613
store double %var_2_3614, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_3615 = add i64 %var_2_3603, -16
; Matched:%var_2_3061:  %var_2_3061 = add i64 %var_2_3046, 20
; %var_2_3616 = add i64 %var_2_3605, 20
; Matched:\<badref\>:  store i64 %var_2_3061, i64* %var_2_3, align 8
; store i64 %var_2_3616, i64* %PC, align 8
%var_2_3617 = inttoptr i64 %var_2_3615 to i64*
%var_2_3618 = load i64, i64* %var_2_3617, align 8
; Matched:\<badref\>:  store i64 %var_2_2753, i64* %RCX.i2236, align 8
; store i64 %var_2_3618, i64* %RCX, align 8
%var_2_3619 = add i64 %var_2_3603, -40
; Matched:%var_2_4416:  %var_2_4416 = add i64 %var_2_4399, 23
; %var_2_3620 = add i64 %var_2_3605, 23
; Matched:\<badref\>:  store i64 %var_2_4416, i64* %var_2_3, align 8
; store i64 %var_2_3620, i64* %PC, align 8
%var_2_3621 = inttoptr i64 %var_2_3619 to i32*
%var_2_3622 = load i32, i32* %var_2_3621, align 4
%var_2_3623 = add i32 %var_2_3622, 1
; Matched:%var_2_2985:  %var_2_2985 = zext i32 %var_2_2984 to i64
; %var_2_3624 = zext i32 %var_2_3623 to i64
; Matched:\<badref\>:  store i64 %var_2_2872, i64* %RAX.i2224, align 8
; store i64 %var_2_3624, i64* %RAX, align 8
; Matched:%var_2_4263:  %var_2_4263 = icmp eq i32 %var_2_4260, -1
; %var_2_3625 = icmp eq i32 %var_2_3622, -1
; Matched:%var_2_4151:  %var_2_4151 = icmp eq i32 %var_2_4148, 0
; %var_2_3626 = icmp eq i32 %var_2_3623, 0
; Matched:%var_2_2988:  %var_2_2988 = or i1 %var_2_2986, %var_2_2987
; %var_2_3627 = or i1 %var_2_3625, %var_2_3626
; Matched:%var_2_4266:  %var_2_4266 = zext i1 %var_2_4265 to i8
; %var_2_3628 = zext i1 %var_2_3627 to i8
; Matched:\<badref\>:  store i8 %var_2_4266, i8* %var_2_14, align 1
; store i8 %var_2_3628, i8* %var_2_16, align 1
; Matched:%var_2_2877:  %var_2_2877 = and i32 %var_2_2871, 255
; %var_2_3629 = and i32 %var_2_3623, 255
; Matched:%var_2_4155:  %var_2_4155 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4154)
; %var_2_3630 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3629) #14
; Matched:%var_2_4156:  %var_2_4156 = trunc i32 %var_2_4155 to i8
; %var_2_3631 = trunc i32 %var_2_3630 to i8
; Matched:%var_2_2028:  %var_2_2028 = and i8 %var_2_2027, 1
; %var_2_3632 = and i8 %var_2_3631, 1
; Matched:%var_2_4746:  %var_2_4746 = xor i8 %var_2_4745, 1
; %var_2_3633 = xor i8 %var_2_3632, 1
; Matched:\<badref\>:  store i8 %var_2_1533, i8* %var_2_21, align 1
; store i8 %var_2_3633, i8* %var_2_23, align 1
; Matched:%var_2_1534:  %var_2_1534 = xor i32 %var_2_1523, %var_2_1522
; %var_2_3634 = xor i32 %var_2_3623, %var_2_3622
; Matched:%var_2_981:  %var_2_981 = lshr i32 %var_2_980, 4
; %var_2_3635 = lshr i32 %var_2_3634, 4
; Matched:%var_2_1536:  %var_2_1536 = trunc i32 %var_2_1535 to i8
; %var_2_3636 = trunc i32 %var_2_3635 to i8
; Matched:%var_2_4162:  %var_2_4162 = and i8 %var_2_4161, 1
; %var_2_3637 = and i8 %var_2_3636, 1
; Matched:\<badref\>:  store i8 %var_2_4162, i8* %var_2_27, align 1
; store i8 %var_2_3637, i8* %var_2_29, align 1
; Matched:%var_2_4163:  %var_2_4163 = zext i1 %var_2_4151 to i8
; %var_2_3638 = zext i1 %var_2_3626 to i8
; Matched:\<badref\>:  store i8 %var_2_4163, i8* %var_2_30, align 1
; store i8 %var_2_3638, i8* %var_2_32, align 1
; Matched:%var_2_4164:  %var_2_4164 = lshr i32 %var_2_4148, 31
; %var_2_3639 = lshr i32 %var_2_3623, 31
; Matched:%var_2_4165:  %var_2_4165 = trunc i32 %var_2_4164 to i8
; %var_2_3640 = trunc i32 %var_2_3639 to i8
; Matched:\<badref\>:  store i8 %var_2_4165, i8* %var_2_33, align 1
; store i8 %var_2_3640, i8* %var_2_35, align 1
; Matched:%var_2_4166:  %var_2_4166 = lshr i32 %var_2_4147, 31
; %var_2_3641 = lshr i32 %var_2_3622, 31
; Matched:%var_2_4280:  %var_2_4280 = xor i32 %var_2_4277, %var_2_4279
; %var_2_3642 = xor i32 %var_2_3639, %var_2_3641
; Matched:%var_2_4168:  %var_2_4168 = add nuw nsw i32 %var_2_4167, %var_2_4164
; %var_2_3643 = add nuw nsw i32 %var_2_3642, %var_2_3639
; Matched:%var_2_3005:  %var_2_3005 = icmp eq i32 %var_2_3004, 2
; %var_2_3644 = icmp eq i32 %var_2_3643, 2
; Matched:%var_2_4170:  %var_2_4170 = zext i1 %var_2_4169 to i8
; %var_2_3645 = zext i1 %var_2_3644 to i8
; Matched:\<badref\>:  store i8 %var_2_4170, i8* %var_2_39, align 1
; store i8 %var_2_3645, i8* %var_2_41, align 1
%var_2_3646 = sext i32 %var_2_3623 to i64
; Matched:\<badref\>:  store i64 %var_2_3007, i64* %RDX.i2239, align 8
; store i64 %var_2_3646, i64* %RDX, align 8
; Matched:%var_2_993:  %var_2_993 = shl nsw i64 %var_2_992, 3
; %var_2_3647 = shl nsw i64 %var_2_3646, 3
; Matched:%var_2_994:  %var_2_994 = add i64 %var_2_964, %var_2_993
; %var_2_3648 = add i64 %var_2_3618, %var_2_3647
; Matched:%var_2_3988:  %var_2_3988 = add i64 %var_2_3959, 34
; %var_2_3649 = add i64 %var_2_3605, 34
; Matched:\<badref\>:  store i64 %var_2_3988, i64* %var_2_3, align 8
; store i64 %var_2_3649, i64* %PC, align 8
; Matched:%var_2_996:  %var_2_996 = inttoptr i64 %var_2_994 to double*
; %var_2_3650 = inttoptr i64 %var_2_3648 to double*
; Matched:\<badref\>:  store double %var_2_960, double* %var_2_996, align 8
; store double %var_2_3614, double* %var_2_3650, align 8
; Matched:%var_2_2047:  %var_2_2047 = load i64, i64* %RBP.i, align 8
; %var_2_3651 = load i64, i64* %RBP, align 8
; Matched:%var_2_4765:  %var_2_4765 = add i64 %var_2_4764, -28
; %var_2_3652 = add i64 %var_2_3651, -28
%var_2_3653 = load i64, i64* %PC, align 8
; Matched:%var_2_50:  %var_2_50 = add i64 %var_2_49, 3
; %var_2_3654 = add i64 %var_2_3653, 3
; Matched:\<badref\>:  store i64 %var_2_50, i64* %var_2_3, align 8
; store i64 %var_2_3654, i64* %PC, align 8
; Matched:%var_2_3469:  %var_2_3469 = inttoptr i64 %var_2_3466 to i32*
; %var_2_3655 = inttoptr i64 %var_2_3652 to i32*
; Matched:%var_2_2052:  %var_2_2052 = load i32, i32* %var_2_2051, align 4
; %var_2_3656 = load i32, i32* %var_2_3655, align 4
; Matched:%var_2_4770:  %var_2_4770 = add i32 %var_2_4769, 2
; %var_2_3657 = add i32 %var_2_3656, 2
; Matched:%var_2_2054:  %var_2_2054 = zext i32 %var_2_2053 to i64
; %var_2_3658 = zext i32 %var_2_3657 to i64
; Matched:\<badref\>:  store i64 %var_2_4771, i64* %RAX.i2224, align 8
; store i64 %var_2_3658, i64* %RAX, align 8
; Matched:%var_2_4772:  %var_2_4772 = icmp ugt i32 %var_2_4769, -3
; %var_2_3659 = icmp ugt i32 %var_2_3656, -3
; Matched:%var_2_3474:  %var_2_3474 = zext i1 %var_2_3473 to i8
; %var_2_3660 = zext i1 %var_2_3659 to i8
; Matched:\<badref\>:  store i8 %var_2_1006, i8* %var_2_14, align 1
; store i8 %var_2_3660, i8* %var_2_16, align 1
; Matched:%var_2_3475:  %var_2_3475 = and i32 %var_2_3471, 255
; %var_2_3661 = and i32 %var_2_3657, 255
; Matched:%var_2_1008:  %var_2_1008 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1007)
; %var_2_3662 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3661) #14
; Matched:%var_2_4776:  %var_2_4776 = trunc i32 %var_2_4775 to i8
; %var_2_3663 = trunc i32 %var_2_3662 to i8
; Matched:%var_2_1010:  %var_2_1010 = and i8 %var_2_1009, 1
; %var_2_3664 = and i8 %var_2_3663, 1
; Matched:%var_2_4778:  %var_2_4778 = xor i8 %var_2_4777, 1
; %var_2_3665 = xor i8 %var_2_3664, 1
; Matched:\<badref\>:  store i8 %var_2_2061, i8* %var_2_21, align 1
; store i8 %var_2_3665, i8* %var_2_23, align 1
; Matched:%var_2_3480:  %var_2_3480 = xor i32 %var_2_3471, %var_2_3470
; %var_2_3666 = xor i32 %var_2_3657, %var_2_3656
; Matched:%var_2_1013:  %var_2_1013 = lshr i32 %var_2_1012, 4
; %var_2_3667 = lshr i32 %var_2_3666, 4
; Matched:%var_2_3482:  %var_2_3482 = trunc i32 %var_2_3481 to i8
; %var_2_3668 = trunc i32 %var_2_3667 to i8
; Matched:%var_2_1015:  %var_2_1015 = and i8 %var_2_1014, 1
; %var_2_3669 = and i8 %var_2_3668, 1
; Matched:\<badref\>:  store i8 %var_2_4782, i8* %var_2_27, align 1
; store i8 %var_2_3669, i8* %var_2_29, align 1
; Matched:%var_2_1016:  %var_2_1016 = icmp eq i32 %var_2_1003, 0
; %var_2_3670 = icmp eq i32 %var_2_3657, 0
; Matched:%var_2_4784:  %var_2_4784 = zext i1 %var_2_4783 to i8
; %var_2_3671 = zext i1 %var_2_3670 to i8
; Matched:\<badref\>:  store i8 %var_2_2067, i8* %var_2_30, align 1
; store i8 %var_2_3671, i8* %var_2_32, align 1
; Matched:%var_2_3486:  %var_2_3486 = lshr i32 %var_2_3471, 31
; %var_2_3672 = lshr i32 %var_2_3657, 31
; Matched:%var_2_1019:  %var_2_1019 = trunc i32 %var_2_1018 to i8
; %var_2_3673 = trunc i32 %var_2_3672 to i8
; Matched:\<badref\>:  store i8 %var_2_3487, i8* %var_2_33, align 1
; store i8 %var_2_3673, i8* %var_2_35, align 1
; Matched:%var_2_1020:  %var_2_1020 = lshr i32 %var_2_1002, 31
; %var_2_3674 = lshr i32 %var_2_3656, 31
; Matched:%var_2_4788:  %var_2_4788 = xor i32 %var_2_4785, %var_2_4787
; %var_2_3675 = xor i32 %var_2_3672, %var_2_3674
; Matched:%var_2_1022:  %var_2_1022 = add nuw nsw i32 %var_2_1021, %var_2_1018
; %var_2_3676 = add nuw nsw i32 %var_2_3675, %var_2_3672
; Matched:%var_2_4790:  %var_2_4790 = icmp eq i32 %var_2_4789, 2
; %var_2_3677 = icmp eq i32 %var_2_3676, 2
; Matched:%var_2_2074:  %var_2_2074 = zext i1 %var_2_2073 to i8
; %var_2_3678 = zext i1 %var_2_3677 to i8
; Matched:\<badref\>:  store i8 %var_2_3492, i8* %var_2_39, align 1
; store i8 %var_2_3678, i8* %var_2_41, align 1
%var_2_3679 = add i64 %var_2_3653, 9
store i64 %var_2_3679, i64* %PC, align 8
; Matched:\<badref\>:  store i32 %var_2_1003, i32* %var_2_1001, align 4
; store i32 %var_2_3657, i32* %var_2_3655, align 4
; Matched:%var_2_1026:  %var_2_1026 = load i64, i64* %var_2_3, align 8
; %var_2_3680 = load i64, i64* %PC, align 8
; Matched:%var_2_1027:  %var_2_1027 = add i64 %var_2_1026, -594
; %var_2_3681 = add i64 %var_2_3680, -594
; Matched:\<badref\>:  store i64 %var_2_1027, i64* %var_2_3, align 8
; store i64 %var_2_3681, i64* %PC, align 8
  br label %block_403356

block_403893:                                     ; preds = %block_403ffb, %block_40387d
; Matched:%var_2_2129:  %var_2_2129 = phi i64 [ %var_2_4834, %block_.L_403ffb ], [ %.pre24, %block_.L_40387d ]
; %var_2_3682 = phi i64 [ %var_2_1568, %block_403ffb ], [ %.pre24, %block_40387d ]
%var_2_3683 = load i64, i64* %RBP, align 8
%var_2_3684 = add i64 %var_2_3683, -44
; Matched:%var_2_2132:  %var_2_2132 = add i64 %var_2_2129, 3
; %var_2_3685 = add i64 %var_2_3682, 3
; Matched:\<badref\>:  store i64 %var_2_2132, i64* %var_2_3, align 8
; store i64 %var_2_3685, i64* %PC, align 8
%var_2_3686 = inttoptr i64 %var_2_3684 to i32*
%var_2_3687 = load i32, i32* %var_2_3686, align 4
; Matched:%var_2_2401:  %var_2_2401 = zext i32 %var_2_2400 to i64
; %var_2_3688 = zext i32 %var_2_3687 to i64
; Matched:\<badref\>:  store i64 %var_2_2135, i64* %RAX.i2224, align 8
; store i64 %var_2_3688, i64* %RAX, align 8
%var_2_3689 = add i64 %var_2_3683, -4
; Matched:%var_2_2137:  %var_2_2137 = add i64 %var_2_2129, 6
; %var_2_3690 = add i64 %var_2_3682, 6
; Matched:\<badref\>:  store i64 %var_2_2137, i64* %var_2_3, align 8
; store i64 %var_2_3690, i64* %PC, align 8
%var_2_3691 = inttoptr i64 %var_2_3689 to i32*
%var_2_3692 = load i32, i32* %var_2_3691, align 4
%var_2_3693 = sub i32 %var_2_3687, %var_2_3692
; Matched:%var_2_2141:  %var_2_2141 = icmp ult i32 %var_2_2134, %var_2_2139
; %var_2_3694 = icmp ult i32 %var_2_3687, %var_2_3692
; Matched:%var_2_2142:  %var_2_2142 = zext i1 %var_2_2141 to i8
; %var_2_3695 = zext i1 %var_2_3694 to i8
; Matched:\<badref\>:  store i8 %var_2_2142, i8* %var_2_14, align 1
; store i8 %var_2_3695, i8* %var_2_16, align 1
; Matched:%var_2_2143:  %var_2_2143 = and i32 %var_2_2140, 255
; %var_2_3696 = and i32 %var_2_3693, 255
; Matched:%var_2_2144:  %var_2_2144 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2143)
; %var_2_3697 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3696) #14
; Matched:%var_2_2145:  %var_2_2145 = trunc i32 %var_2_2144 to i8
; %var_2_3698 = trunc i32 %var_2_3697 to i8
; Matched:%var_2_2146:  %var_2_2146 = and i8 %var_2_2145, 1
; %var_2_3699 = and i8 %var_2_3698, 1
; Matched:%var_2_2147:  %var_2_2147 = xor i8 %var_2_2146, 1
; %var_2_3700 = xor i8 %var_2_3699, 1
; Matched:\<badref\>:  store i8 %var_2_2147, i8* %var_2_21, align 1
; store i8 %var_2_3700, i8* %var_2_23, align 1
; Matched:%var_2_2148:  %var_2_2148 = xor i32 %var_2_2139, %var_2_2134
; %var_2_3701 = xor i32 %var_2_3692, %var_2_3687
; Matched:%var_2_2149:  %var_2_2149 = xor i32 %var_2_2148, %var_2_2140
; %var_2_3702 = xor i32 %var_2_3701, %var_2_3693
; Matched:%var_2_2150:  %var_2_2150 = lshr i32 %var_2_2149, 4
; %var_2_3703 = lshr i32 %var_2_3702, 4
; Matched:%var_2_2151:  %var_2_2151 = trunc i32 %var_2_2150 to i8
; %var_2_3704 = trunc i32 %var_2_3703 to i8
; Matched:%var_2_2152:  %var_2_2152 = and i8 %var_2_2151, 1
; %var_2_3705 = and i8 %var_2_3704, 1
; Matched:\<badref\>:  store i8 %var_2_2152, i8* %var_2_27, align 1
; store i8 %var_2_3705, i8* %var_2_29, align 1
; Matched:%var_2_2153:  %var_2_2153 = icmp eq i32 %var_2_2140, 0
; %var_2_3706 = icmp eq i32 %var_2_3693, 0
; Matched:%var_2_2154:  %var_2_2154 = zext i1 %var_2_2153 to i8
; %var_2_3707 = zext i1 %var_2_3706 to i8
; Matched:\<badref\>:  store i8 %var_2_2154, i8* %var_2_30, align 1
; store i8 %var_2_3707, i8* %var_2_32, align 1
%var_2_3708 = lshr i32 %var_2_3693, 31
%var_2_3709 = trunc i32 %var_2_3708 to i8
; Matched:\<badref\>:  store i8 %var_2_2156, i8* %var_2_33, align 1
; store i8 %var_2_3709, i8* %var_2_35, align 1
%var_2_3710 = lshr i32 %var_2_3687, 31
%var_2_3711 = lshr i32 %var_2_3692, 31
%var_2_3712 = xor i32 %var_2_3711, %var_2_3710
%var_2_3713 = xor i32 %var_2_3708, %var_2_3710
%var_2_3714 = add nuw nsw i32 %var_2_3713, %var_2_3712
%var_2_3715 = icmp eq i32 %var_2_3714, 2
; Matched:%var_2_2163:  %var_2_2163 = zext i1 %var_2_2162 to i8
; %var_2_3716 = zext i1 %var_2_3715 to i8
; Matched:\<badref\>:  store i8 %var_2_2163, i8* %var_2_39, align 1
; store i8 %var_2_3716, i8* %var_2_41, align 1
%var_2_3717 = icmp ne i8 %var_2_3709, 0
%var_2_3718 = xor i1 %var_2_3717, %var_2_3715
; Matched:  %.v28 = select i1 %var_2_2165, i64 12, i64 1915
; %.v28 = select i1 %var_2_3718, i64 12, i64 1915
; Matched:%var_2_2166:  %var_2_2166 = add i64 %var_2_2129, %.v28
; %var_2_3719 = add i64 %var_2_3682, %.v28
; Matched:\<badref\>:  store i64 %var_2_2166, i64* %var_2_3, align 8
; store i64 %var_2_3719, i64* %PC, align 8
br i1 %var_2_3718, label %block_40389f, label %block_40400e

block_403951:                                     ; preds = %block_403940
; Matched:%var_2_2450:  %var_2_2450 = add i64 %var_2_2449, 3
; %var_2_3720 = add i64 %var_2_4855, 3
; Matched:\<badref\>:  store i64 %var_2_2450, i64* %var_2_3, align 8
; store i64 %var_2_3720, i64* %PC, align 8
%var_2_3721 = load i32, i32* %var_2_4815, align 4
; Matched:%var_2_138:  %var_2_138 = zext i32 %var_2_137 to i64
; %var_2_3722 = zext i32 %var_2_3721 to i64
; Matched:\<badref\>:  store i64 %var_2_2411, i64* %RAX.i2224, align 8
; store i64 %var_2_3722, i64* %RAX, align 8
; Matched:%var_2_2453:  %var_2_2453 = add i64 %var_2_2449, 6
; %var_2_3723 = add i64 %var_2_4855, 6
; Matched:\<badref\>:  store i64 %var_2_2453, i64* %var_2_3, align 8
; store i64 %var_2_3723, i64* %PC, align 8
%var_2_3724 = load i32, i32* %var_2_4820, align 4
%var_2_3725 = add i32 %var_2_3724, %var_2_3721
; Matched:%var_2_1108:  %var_2_1108 = zext i32 %var_2_1107 to i64
; %var_2_3726 = zext i32 %var_2_3725 to i64
; Matched:\<badref\>:  store i64 %var_2_2456, i64* %RAX.i2224, align 8
; store i64 %var_2_3726, i64* %RAX, align 8
; Matched:%var_2_3734:  %var_2_3734 = icmp ult i32 %var_2_3732, %var_2_3726
; %var_2_3727 = icmp ult i32 %var_2_3725, %var_2_3721
; Matched:%var_2_3735:  %var_2_3735 = icmp ult i32 %var_2_3732, %var_2_3731
; %var_2_3728 = icmp ult i32 %var_2_3725, %var_2_3724
; Matched:%var_2_145:  %var_2_145 = or i1 %var_2_143, %var_2_144
; %var_2_3729 = or i1 %var_2_3727, %var_2_3728
; Matched:%var_2_3737:  %var_2_3737 = zext i1 %var_2_3736 to i8
; %var_2_3730 = zext i1 %var_2_3729 to i8
; Matched:\<badref\>:  store i8 %var_2_1112, i8* %var_2_14, align 1
; store i8 %var_2_3730, i8* %var_2_16, align 1
; Matched:%var_2_3738:  %var_2_3738 = and i32 %var_2_3732, 255
; %var_2_3731 = and i32 %var_2_3725, 255
; Matched:%var_2_3739:  %var_2_3739 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3738)
; %var_2_3732 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3731) #14
; Matched:%var_2_149:  %var_2_149 = trunc i32 %var_2_148 to i8
; %var_2_3733 = trunc i32 %var_2_3732 to i8
; Matched:%var_2_3741:  %var_2_3741 = and i8 %var_2_3740, 1
; %var_2_3734 = and i8 %var_2_3733, 1
; Matched:%var_2_3742:  %var_2_3742 = xor i8 %var_2_3741, 1
; %var_2_3735 = xor i8 %var_2_3734, 1
; Matched:\<badref\>:  store i8 %var_2_151, i8* %var_2_21, align 1
; store i8 %var_2_3735, i8* %var_2_23, align 1
; Matched:%var_2_3743:  %var_2_3743 = xor i32 %var_2_3731, %var_2_3726
; %var_2_3736 = xor i32 %var_2_3724, %var_2_3721
; Matched:%var_2_1119:  %var_2_1119 = xor i32 %var_2_1118, %var_2_1107
; %var_2_3737 = xor i32 %var_2_3736, %var_2_3725
; Matched:%var_2_3745:  %var_2_3745 = lshr i32 %var_2_3744, 4
; %var_2_3738 = lshr i32 %var_2_3737, 4
; Matched:%var_2_3746:  %var_2_3746 = trunc i32 %var_2_3745 to i8
; %var_2_3739 = trunc i32 %var_2_3738 to i8
; Matched:%var_2_156:  %var_2_156 = and i8 %var_2_155, 1
; %var_2_3740 = and i8 %var_2_3739, 1
; Matched:\<badref\>:  store i8 %var_2_3747, i8* %var_2_27, align 1
; store i8 %var_2_3740, i8* %var_2_29, align 1
; Matched:%var_2_3748:  %var_2_3748 = icmp eq i32 %var_2_3732, 0
; %var_2_3741 = icmp eq i32 %var_2_3725, 0
; Matched:%var_2_158:  %var_2_158 = zext i1 %var_2_157 to i8
; %var_2_3742 = zext i1 %var_2_3741 to i8
; Matched:\<badref\>:  store i8 %var_2_3749, i8* %var_2_30, align 1
; store i8 %var_2_3742, i8* %var_2_32, align 1
; Matched:%var_2_1125:  %var_2_1125 = lshr i32 %var_2_1107, 31
; %var_2_3743 = lshr i32 %var_2_3725, 31
; Matched:%var_2_2474:  %var_2_2474 = trunc i32 %var_2_2473 to i8
; %var_2_3744 = trunc i32 %var_2_3743 to i8
; Matched:\<badref\>:  store i8 %var_2_3751, i8* %var_2_33, align 1
; store i8 %var_2_3744, i8* %var_2_35, align 1
; Matched:%var_2_2475:  %var_2_2475 = lshr i32 %var_2_2451, 31
; %var_2_3745 = lshr i32 %var_2_3721, 31
; Matched:%var_2_3753:  %var_2_3753 = lshr i32 %var_2_3731, 31
; %var_2_3746 = lshr i32 %var_2_3724, 31
; Matched:%var_2_2477:  %var_2_2477 = xor i32 %var_2_2473, %var_2_2475
; %var_2_3747 = xor i32 %var_2_3743, %var_2_3745
; Matched:%var_2_3755:  %var_2_3755 = xor i32 %var_2_3750, %var_2_3753
; %var_2_3748 = xor i32 %var_2_3743, %var_2_3746
; Matched:%var_2_2479:  %var_2_2479 = add nuw nsw i32 %var_2_2477, %var_2_2478
; %var_2_3749 = add nuw nsw i32 %var_2_3747, %var_2_3748
; Matched:%var_2_1132:  %var_2_1132 = icmp eq i32 %var_2_1131, 2
; %var_2_3750 = icmp eq i32 %var_2_3749, 2
; Matched:%var_2_2481:  %var_2_2481 = zext i1 %var_2_2480 to i8
; %var_2_3751 = zext i1 %var_2_3750 to i8
; Matched:\<badref\>:  store i8 %var_2_3758, i8* %var_2_39, align 1
; store i8 %var_2_3751, i8* %var_2_41, align 1
; Matched:%var_2_2482:  %var_2_2482 = add i64 %var_2_2406, -32
; %var_2_3752 = add i64 %var_2_4812, -32
; Matched:%var_2_2483:  %var_2_2483 = add i64 %var_2_2449, 9
; %var_2_3753 = add i64 %var_2_4855, 9
; Matched:\<badref\>:  store i64 %var_2_2483, i64* %var_2_3, align 8
; store i64 %var_2_3753, i64* %PC, align 8
; Matched:%var_2_3761:  %var_2_3761 = inttoptr i64 %var_2_3759 to i32*
; %var_2_3754 = inttoptr i64 %var_2_3752 to i32*
; Matched:\<badref\>:  store i32 %var_2_141, i32* %var_2_170, align 4
; store i32 %var_2_3725, i32* %var_2_3754, align 4
%var_2_3755 = load i64, i64* %RBP, align 8
%var_2_3756 = add i64 %var_2_3755, -32
%var_2_3757 = load i64, i64* %PC, align 8
; Matched:%var_2_2529:  %var_2_2529 = add i64 %var_2_2528, 3
; %var_2_3758 = add i64 %var_2_3757, 3
; Matched:\<badref\>:  store i64 %var_2_2529, i64* %var_2_3, align 8
; store i64 %var_2_3758, i64* %PC, align 8
%var_2_3759 = inttoptr i64 %var_2_3756 to i32*
%var_2_3760 = load i32, i32* %var_2_3759, align 4
; Matched:%var_2_1143:  %var_2_1143 = zext i32 %var_2_1142 to i64
; %var_2_3761 = zext i32 %var_2_3760 to i64
; Matched:\<badref\>:  store i64 %var_2_2491, i64* %RAX.i2224, align 8
; store i64 %var_2_3761, i64* %RAX, align 8
%var_2_3762 = add i64 %var_2_3755, -8
; Matched:%var_2_1186:  %var_2_1186 = add i64 %var_2_1180, 6
; %var_2_3763 = add i64 %var_2_3757, 6
; Matched:\<badref\>:  store i64 %var_2_1186, i64* %var_2_3, align 8
; store i64 %var_2_3763, i64* %PC, align 8
%var_2_3764 = inttoptr i64 %var_2_3762 to i32*
%var_2_3765 = load i32, i32* %var_2_3764, align 4
%var_2_3766 = add i32 %var_2_3765, %var_2_3760
; Matched:%var_2_1149:  %var_2_1149 = zext i32 %var_2_1148 to i64
; %var_2_3767 = zext i32 %var_2_3766 to i64
; Matched:\<badref\>:  store i64 %var_2_2497, i64* %RAX.i2224, align 8
; store i64 %var_2_3767, i64* %RAX, align 8
; Matched:%var_2_3775:  %var_2_3775 = icmp ult i32 %var_2_3773, %var_2_3767
; %var_2_3768 = icmp ult i32 %var_2_3766, %var_2_3760
; Matched:%var_2_185:  %var_2_185 = icmp ult i32 %var_2_182, %var_2_181
; %var_2_3769 = icmp ult i32 %var_2_3766, %var_2_3765
; Matched:%var_2_3777:  %var_2_3777 = or i1 %var_2_3775, %var_2_3776
; %var_2_3770 = or i1 %var_2_3768, %var_2_3769
; Matched:%var_2_187:  %var_2_187 = zext i1 %var_2_186 to i8
; %var_2_3771 = zext i1 %var_2_3770 to i8
; Matched:\<badref\>:  store i8 %var_2_3778, i8* %var_2_14, align 1
; store i8 %var_2_3771, i8* %var_2_16, align 1
; Matched:%var_2_188:  %var_2_188 = and i32 %var_2_182, 255
; %var_2_3772 = and i32 %var_2_3766, 255
; Matched:%var_2_3780:  %var_2_3780 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3779)
; %var_2_3773 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3772) #14
; Matched:%var_2_3781:  %var_2_3781 = trunc i32 %var_2_3780 to i8
; %var_2_3774 = trunc i32 %var_2_3773 to i8
; Matched:%var_2_3782:  %var_2_3782 = and i8 %var_2_3781, 1
; %var_2_3775 = and i8 %var_2_3774, 1
; Matched:%var_2_192:  %var_2_192 = xor i8 %var_2_191, 1
; %var_2_3776 = xor i8 %var_2_3775, 1
; Matched:\<badref\>:  store i8 %var_2_3783, i8* %var_2_21, align 1
; store i8 %var_2_3776, i8* %var_2_23, align 1
; Matched:%var_2_193:  %var_2_193 = xor i32 %var_2_181, %var_2_176
; %var_2_3777 = xor i32 %var_2_3765, %var_2_3760
; Matched:%var_2_3785:  %var_2_3785 = xor i32 %var_2_3784, %var_2_3773
; %var_2_3778 = xor i32 %var_2_3777, %var_2_3766
; Matched:%var_2_195:  %var_2_195 = lshr i32 %var_2_194, 4
; %var_2_3779 = lshr i32 %var_2_3778, 4
; Matched:%var_2_3787:  %var_2_3787 = trunc i32 %var_2_3786 to i8
; %var_2_3780 = trunc i32 %var_2_3779 to i8
; Matched:%var_2_3788:  %var_2_3788 = and i8 %var_2_3787, 1
; %var_2_3781 = and i8 %var_2_3780, 1
; Matched:\<badref\>:  store i8 %var_2_3788, i8* %var_2_27, align 1
; store i8 %var_2_3781, i8* %var_2_29, align 1
; Matched:%var_2_198:  %var_2_198 = icmp eq i32 %var_2_182, 0
; %var_2_3782 = icmp eq i32 %var_2_3766, 0
; Matched:%var_2_3790:  %var_2_3790 = zext i1 %var_2_3789 to i8
; %var_2_3783 = zext i1 %var_2_3782 to i8
; Matched:\<badref\>:  store i8 %var_2_199, i8* %var_2_30, align 1
; store i8 %var_2_3783, i8* %var_2_32, align 1
; Matched:%var_2_3791:  %var_2_3791 = lshr i32 %var_2_3773, 31
; %var_2_3784 = lshr i32 %var_2_3766, 31
; Matched:%var_2_201:  %var_2_201 = trunc i32 %var_2_200 to i8
; %var_2_3785 = trunc i32 %var_2_3784 to i8
; Matched:\<badref\>:  store i8 %var_2_3792, i8* %var_2_33, align 1
; store i8 %var_2_3785, i8* %var_2_35, align 1
; Matched:%var_2_3793:  %var_2_3793 = lshr i32 %var_2_3767, 31
; %var_2_3786 = lshr i32 %var_2_3760, 31
; Matched:%var_2_3794:  %var_2_3794 = lshr i32 %var_2_3772, 31
; %var_2_3787 = lshr i32 %var_2_3765, 31
; Matched:%var_2_204:  %var_2_204 = xor i32 %var_2_200, %var_2_202
; %var_2_3788 = xor i32 %var_2_3784, %var_2_3786
; Matched:%var_2_3796:  %var_2_3796 = xor i32 %var_2_3791, %var_2_3794
; %var_2_3789 = xor i32 %var_2_3784, %var_2_3787
; Matched:%var_2_206:  %var_2_206 = add nuw nsw i32 %var_2_204, %var_2_205
; %var_2_3790 = add nuw nsw i32 %var_2_3788, %var_2_3789
; Matched:%var_2_3798:  %var_2_3798 = icmp eq i32 %var_2_3797, 2
; %var_2_3791 = icmp eq i32 %var_2_3790, 2
; Matched:%var_2_208:  %var_2_208 = zext i1 %var_2_207 to i8
; %var_2_3792 = zext i1 %var_2_3791 to i8
; Matched:\<badref\>:  store i8 %var_2_3799, i8* %var_2_39, align 1
; store i8 %var_2_3792, i8* %var_2_41, align 1
; Matched:%var_2_3800:  %var_2_3800 = add i64 %var_2_3762, -36
; %var_2_3793 = add i64 %var_2_3755, -36
%var_2_3794 = add i64 %var_2_3757, 9
store i64 %var_2_3794, i64* %PC, align 8
; Matched:%var_2_211:  %var_2_211 = inttoptr i64 %var_2_209 to i32*
; %var_2_3795 = inttoptr i64 %var_2_3793 to i32*
; Matched:\<badref\>:  store i32 %var_2_182, i32* %var_2_211, align 4
; store i32 %var_2_3766, i32* %var_2_3795, align 4
%var_2_3796 = load i64, i64* %RBP, align 8
%var_2_3797 = add i64 %var_2_3796, -36
%var_2_3798 = load i64, i64* %PC, align 8
; Matched:%var_2_1045:  %var_2_1045 = add i64 %var_2_1044, 3
; %var_2_3799 = add i64 %var_2_3798, 3
; Matched:\<badref\>:  store i64 %var_2_1045, i64* %var_2_3, align 8
; store i64 %var_2_3799, i64* %PC, align 8
%var_2_3800 = inttoptr i64 %var_2_3797 to i32*
%var_2_3801 = load i32, i32* %var_2_3800, align 4
; Matched:%var_2_2532:  %var_2_2532 = zext i32 %var_2_2531 to i64
; %var_2_3802 = zext i32 %var_2_3801 to i64
; Matched:\<badref\>:  store i64 %var_2_218, i64* %RAX.i2224, align 8
; store i64 %var_2_3802, i64* %RAX, align 8
%var_2_3803 = add i64 %var_2_3796, -8
; Matched:%var_2_3770:  %var_2_3770 = add i64 %var_2_3764, 6
; %var_2_3804 = add i64 %var_2_3798, 6
; Matched:\<badref\>:  store i64 %var_2_3770, i64* %var_2_3, align 8
; store i64 %var_2_3804, i64* %PC, align 8
%var_2_3805 = inttoptr i64 %var_2_3803 to i32*
%var_2_3806 = load i32, i32* %var_2_3805, align 4
%var_2_3807 = add i32 %var_2_3806, %var_2_3801
; Matched:%var_2_2538:  %var_2_2538 = zext i32 %var_2_2537 to i64
; %var_2_3808 = zext i32 %var_2_3807 to i64
; Matched:\<badref\>:  store i64 %var_2_224, i64* %RAX.i2224, align 8
; store i64 %var_2_3808, i64* %RAX, align 8
; Matched:%var_2_225:  %var_2_225 = icmp ult i32 %var_2_223, %var_2_217
; %var_2_3809 = icmp ult i32 %var_2_3807, %var_2_3801
; Matched:%var_2_3817:  %var_2_3817 = icmp ult i32 %var_2_3814, %var_2_3813
; %var_2_3810 = icmp ult i32 %var_2_3807, %var_2_3806
; Matched:%var_2_3818:  %var_2_3818 = or i1 %var_2_3816, %var_2_3817
; %var_2_3811 = or i1 %var_2_3809, %var_2_3810
; Matched:%var_2_3819:  %var_2_3819 = zext i1 %var_2_3818 to i8
; %var_2_3812 = zext i1 %var_2_3811 to i8
; Matched:\<badref\>:  store i8 %var_2_228, i8* %var_2_14, align 1
; store i8 %var_2_3812, i8* %var_2_16, align 1
; Matched:%var_2_229:  %var_2_229 = and i32 %var_2_223, 255
; %var_2_3813 = and i32 %var_2_3807, 255
; Matched:%var_2_230:  %var_2_230 = tail call i32 @llvm.ctpop.i32(i32 %var_2_229)
; %var_2_3814 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3813) #14
; Matched:%var_2_3822:  %var_2_3822 = trunc i32 %var_2_3821 to i8
; %var_2_3815 = trunc i32 %var_2_3814 to i8
; Matched:%var_2_232:  %var_2_232 = and i8 %var_2_231, 1
; %var_2_3816 = and i8 %var_2_3815, 1
; Matched:%var_2_3824:  %var_2_3824 = xor i8 %var_2_3823, 1
; %var_2_3817 = xor i8 %var_2_3816, 1
; Matched:\<badref\>:  store i8 %var_2_3824, i8* %var_2_21, align 1
; store i8 %var_2_3817, i8* %var_2_23, align 1
; Matched:%var_2_1200:  %var_2_1200 = xor i32 %var_2_1188, %var_2_1183
; %var_2_3818 = xor i32 %var_2_3806, %var_2_3801
; Matched:%var_2_235:  %var_2_235 = xor i32 %var_2_234, %var_2_223
; %var_2_3819 = xor i32 %var_2_3818, %var_2_3807
; Matched:%var_2_3827:  %var_2_3827 = lshr i32 %var_2_3826, 4
; %var_2_3820 = lshr i32 %var_2_3819, 4
; Matched:%var_2_3828:  %var_2_3828 = trunc i32 %var_2_3827 to i8
; %var_2_3821 = trunc i32 %var_2_3820 to i8
; Matched:%var_2_3829:  %var_2_3829 = and i8 %var_2_3828, 1
; %var_2_3822 = and i8 %var_2_3821, 1
; Matched:\<badref\>:  store i8 %var_2_238, i8* %var_2_27, align 1
; store i8 %var_2_3822, i8* %var_2_29, align 1
; Matched:%var_2_3830:  %var_2_3830 = icmp eq i32 %var_2_3814, 0
; %var_2_3823 = icmp eq i32 %var_2_3807, 0
; Matched:%var_2_3831:  %var_2_3831 = zext i1 %var_2_3830 to i8
; %var_2_3824 = zext i1 %var_2_3823 to i8
; Matched:\<badref\>:  store i8 %var_2_1206, i8* %var_2_30, align 1
; store i8 %var_2_3824, i8* %var_2_32, align 1
; Matched:%var_2_241:  %var_2_241 = lshr i32 %var_2_223, 31
; %var_2_3825 = lshr i32 %var_2_3807, 31
; Matched:%var_2_3833:  %var_2_3833 = trunc i32 %var_2_3832 to i8
; %var_2_3826 = trunc i32 %var_2_3825 to i8
; Matched:\<badref\>:  store i8 %var_2_3833, i8* %var_2_33, align 1
; store i8 %var_2_3826, i8* %var_2_35, align 1
; Matched:%var_2_3834:  %var_2_3834 = lshr i32 %var_2_3808, 31
; %var_2_3827 = lshr i32 %var_2_3801, 31
; Matched:%var_2_244:  %var_2_244 = lshr i32 %var_2_222, 31
; %var_2_3828 = lshr i32 %var_2_3806, 31
; Matched:%var_2_3836:  %var_2_3836 = xor i32 %var_2_3832, %var_2_3834
; %var_2_3829 = xor i32 %var_2_3825, %var_2_3827
; Matched:%var_2_3837:  %var_2_3837 = xor i32 %var_2_3832, %var_2_3835
; %var_2_3830 = xor i32 %var_2_3825, %var_2_3828
; Matched:%var_2_1213:  %var_2_1213 = add nuw nsw i32 %var_2_1211, %var_2_1212
; %var_2_3831 = add nuw nsw i32 %var_2_3829, %var_2_3830
; Matched:%var_2_248:  %var_2_248 = icmp eq i32 %var_2_247, 2
; %var_2_3832 = icmp eq i32 %var_2_3831, 2
; Matched:%var_2_3840:  %var_2_3840 = zext i1 %var_2_3839 to i8
; %var_2_3833 = zext i1 %var_2_3832 to i8
; Matched:\<badref\>:  store i8 %var_2_3840, i8* %var_2_39, align 1
; store i8 %var_2_3833, i8* %var_2_41, align 1
; Matched:%var_2_3841:  %var_2_3841 = add i64 %var_2_3803, -40
; %var_2_3834 = add i64 %var_2_3796, -40
%var_2_3835 = add i64 %var_2_3798, 9
store i64 %var_2_3835, i64* %PC, align 8
; Matched:%var_2_3843:  %var_2_3843 = inttoptr i64 %var_2_3841 to i32*
; %var_2_3836 = inttoptr i64 %var_2_3834 to i32*
; Matched:\<badref\>:  store i32 %var_2_1189, i32* %var_2_1218, align 4
; store i32 %var_2_3807, i32* %var_2_3836, align 4
%var_2_3837 = load i64, i64* %RBP, align 8
%var_2_3838 = add i64 %var_2_3837, -16
%var_2_3839 = load i64, i64* %PC, align 8
; Matched:%var_2_2307:  %var_2_2307 = add i64 %var_2_2306, 4
; %var_2_3840 = add i64 %var_2_3839, 4
; Matched:\<badref\>:  store i64 %var_2_2307, i64* %var_2_3, align 8
; store i64 %var_2_3840, i64* %PC, align 8
%var_2_3841 = inttoptr i64 %var_2_3838 to i64*
%var_2_3842 = load i64, i64* %var_2_3841, align 8
; Matched:\<badref\>:  store i64 %var_2_1899, i64* %RCX.i2236, align 8
; store i64 %var_2_3842, i64* %RCX, align 8
%var_2_3843 = add i64 %var_2_3837, -28
%var_2_3844 = add i64 %var_2_3839, 8
store i64 %var_2_3844, i64* %PC, align 8
%var_2_3845 = inttoptr i64 %var_2_3843 to i32*
%var_2_3846 = load i32, i32* %var_2_3845, align 4
%var_2_3847 = sext i32 %var_2_3846 to i64
; Matched:\<badref\>:  store i64 %var_2_2577, i64* %RDX.i2239, align 8
; store i64 %var_2_3847, i64* %RDX, align 8
%var_2_3848 = shl nsw i64 %var_2_3847, 3
%var_2_3849 = add i64 %var_2_3848, %var_2_3842
; Matched:%var_2_2237:  %var_2_2237 = add i64 %var_2_2226, 13
; %var_2_3850 = add i64 %var_2_3839, 13
; Matched:\<badref\>:  store i64 %var_2_2237, i64* %var_2_3, align 8
; store i64 %var_2_3850, i64* %PC, align 8
%var_2_3851 = inttoptr i64 %var_2_3849 to i64*
%var_2_3852 = load i64, i64* %var_2_3851, align 8
store i64 %var_2_3852, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_495:  %var_2_495 = add i64 %var_2_481, 17
; %var_2_3853 = add i64 %var_2_3839, 17
; Matched:\<badref\>:  store i64 %var_2_495, i64* %var_2_3, align 8
; store i64 %var_2_3853, i64* %PC, align 8
%var_2_3854 = load i64, i64* %var_2_3841, align 8
; Matched:\<badref\>:  store i64 %var_2_484, i64* %RCX.i2236, align 8
; store i64 %var_2_3854, i64* %RCX, align 8
%var_2_3855 = add i64 %var_2_3837, -32
; Matched:%var_2_2699:  %var_2_2699 = add i64 %var_2_2682, 21
; %var_2_3856 = add i64 %var_2_3839, 21
; Matched:\<badref\>:  store i64 %var_2_2699, i64* %var_2_3, align 8
; store i64 %var_2_3856, i64* %PC, align 8
%var_2_3857 = inttoptr i64 %var_2_3855 to i32*
%var_2_3858 = load i32, i32* %var_2_3857, align 4
%var_2_3859 = sext i32 %var_2_3858 to i64
; Matched:\<badref\>:  store i64 %var_2_388, i64* %RDX.i2239, align 8
; store i64 %var_2_3859, i64* %RDX, align 8
%var_2_3860 = shl nsw i64 %var_2_3859, 3
%var_2_3861 = add i64 %var_2_3860, %var_2_3854
; Matched:%var_2_3982:  %var_2_3982 = add i64 %var_2_3959, 26
; %var_2_3862 = add i64 %var_2_3839, 26
; Matched:\<badref\>:  store i64 %var_2_3982, i64* %var_2_3, align 8
; store i64 %var_2_3862, i64* %PC, align 8
%var_2_3863 = bitcast i64 %var_2_3852 to double
%var_2_3864 = inttoptr i64 %var_2_3861 to double*
%var_2_3865 = load double, double* %var_2_3864, align 8
%var_2_3866 = fadd double %var_2_3863, %var_2_3865
store double %var_2_3866, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_283:  %var_2_283 = add i64 %var_2_253, -120
; %var_2_3867 = add i64 %var_2_3837, -120
; Matched:%var_2_3309:  %var_2_3309 = add i64 %var_2_3283, 31
; %var_2_3868 = add i64 %var_2_3839, 31
; Matched:\<badref\>:  store i64 %var_2_3309, i64* %var_2_3, align 8
; store i64 %var_2_3868, i64* %PC, align 8
; Matched:%var_2_3876:  %var_2_3876 = inttoptr i64 %var_2_3874 to double*
; %var_2_3869 = inttoptr i64 %var_2_3867 to double*
; Matched:\<badref\>:  store double %var_2_3873, double* %var_2_3876, align 8
; store double %var_2_3866, double* %var_2_3869, align 8
%var_2_3870 = load i64, i64* %RBP, align 8
%var_2_3871 = add i64 %var_2_3870, -16
%var_2_3872 = load i64, i64* %PC, align 8
; Matched:%var_2_3880:  %var_2_3880 = add i64 %var_2_3879, 4
; %var_2_3873 = add i64 %var_2_3872, 4
; Matched:\<badref\>:  store i64 %var_2_3880, i64* %var_2_3, align 8
; store i64 %var_2_3873, i64* %PC, align 8
%var_2_3874 = inttoptr i64 %var_2_3871 to i64*
%var_2_3875 = load i64, i64* %var_2_3874, align 8
; Matched:\<badref\>:  store i64 %var_2_3059, i64* %RCX.i2236, align 8
; store i64 %var_2_3875, i64* %RCX, align 8
%var_2_3876 = add i64 %var_2_3870, -28
; Matched:%var_2_3546:  %var_2_3546 = add i64 %var_2_3541, 7
; %var_2_3877 = add i64 %var_2_3872, 7
; Matched:\<badref\>:  store i64 %var_2_1259, i64* %var_2_3, align 8
; store i64 %var_2_3877, i64* %PC, align 8
%var_2_3878 = inttoptr i64 %var_2_3876 to i32*
%var_2_3879 = load i32, i32* %var_2_3878, align 4
%var_2_3880 = add i32 %var_2_3879, 1
; Matched:%var_2_3065:  %var_2_3065 = zext i32 %var_2_3064 to i64
; %var_2_3881 = zext i32 %var_2_3880 to i64
; Matched:\<badref\>:  store i64 %var_2_3065, i64* %RAX.i2224, align 8
; store i64 %var_2_3881, i64* %RAX, align 8
; Matched:%var_2_2612:  %var_2_2612 = icmp eq i32 %var_2_2609, -1
; %var_2_3882 = icmp eq i32 %var_2_3879, -1
; Matched:%var_2_2726:  %var_2_2726 = icmp eq i32 %var_2_2723, 0
; %var_2_3883 = icmp eq i32 %var_2_3880, 0
; Matched:%var_2_3068:  %var_2_3068 = or i1 %var_2_3066, %var_2_3067
; %var_2_3884 = or i1 %var_2_3882, %var_2_3883
; Matched:%var_2_2615:  %var_2_2615 = zext i1 %var_2_2614 to i8
; %var_2_3885 = zext i1 %var_2_3884 to i8
; Matched:\<badref\>:  store i8 %var_2_2615, i8* %var_2_14, align 1
; store i8 %var_2_3885, i8* %var_2_16, align 1
; Matched:%var_2_2616:  %var_2_2616 = and i32 %var_2_2610, 255
; %var_2_3886 = and i32 %var_2_3880, 255
; Matched:%var_2_416:  %var_2_416 = tail call i32 @llvm.ctpop.i32(i32 %var_2_415)
; %var_2_3887 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3886) #14
; Matched:%var_2_417:  %var_2_417 = trunc i32 %var_2_416 to i8
; %var_2_3888 = trunc i32 %var_2_3887 to i8
; Matched:%var_2_2619:  %var_2_2619 = and i8 %var_2_2618, 1
; %var_2_3889 = and i8 %var_2_3888, 1
; Matched:%var_2_2733:  %var_2_2733 = xor i8 %var_2_2732, 1
; %var_2_3890 = xor i8 %var_2_3889, 1
; Matched:\<badref\>:  store i8 %var_2_3074, i8* %var_2_21, align 1
; store i8 %var_2_3890, i8* %var_2_23, align 1
; Matched:%var_2_420:  %var_2_420 = xor i32 %var_2_409, %var_2_408
; %var_2_3891 = xor i32 %var_2_3880, %var_2_3879
; Matched:%var_2_762:  %var_2_762 = lshr i32 %var_2_761, 4
; %var_2_3892 = lshr i32 %var_2_3891, 4
; Matched:%var_2_2623:  %var_2_2623 = trunc i32 %var_2_2622 to i8
; %var_2_3893 = trunc i32 %var_2_3892 to i8
; Matched:%var_2_3078:  %var_2_3078 = and i8 %var_2_3077, 1
; %var_2_3894 = and i8 %var_2_3893, 1
; Matched:\<badref\>:  store i8 %var_2_3078, i8* %var_2_27, align 1
; store i8 %var_2_3894, i8* %var_2_29, align 1
; Matched:%var_2_2738:  %var_2_2738 = zext i1 %var_2_2726 to i8
; %var_2_3895 = zext i1 %var_2_3883 to i8
; Matched:\<badref\>:  store i8 %var_2_2625, i8* %var_2_30, align 1
; store i8 %var_2_3895, i8* %var_2_32, align 1
; Matched:%var_2_3903:  %var_2_3903 = lshr i32 %var_2_3887, 31
; %var_2_3896 = lshr i32 %var_2_3880, 31
; Matched:%var_2_2627:  %var_2_2627 = trunc i32 %var_2_2626 to i8
; %var_2_3897 = trunc i32 %var_2_3896 to i8
; Matched:\<badref\>:  store i8 %var_2_426, i8* %var_2_33, align 1
; store i8 %var_2_3897, i8* %var_2_35, align 1
; Matched:%var_2_427:  %var_2_427 = lshr i32 %var_2_408, 31
; %var_2_3898 = lshr i32 %var_2_3879, 31
; Matched:%var_2_315:  %var_2_315 = xor i32 %var_2_312, %var_2_314
; %var_2_3899 = xor i32 %var_2_3896, %var_2_3898
; Matched:%var_2_429:  %var_2_429 = add nuw nsw i32 %var_2_428, %var_2_425
; %var_2_3900 = add nuw nsw i32 %var_2_3899, %var_2_3896
; Matched:%var_2_430:  %var_2_430 = icmp eq i32 %var_2_429, 2
; %var_2_3901 = icmp eq i32 %var_2_3900, 2
; Matched:%var_2_318:  %var_2_318 = zext i1 %var_2_317 to i8
; %var_2_3902 = zext i1 %var_2_3901 to i8
; Matched:\<badref\>:  store i8 %var_2_318, i8* %var_2_39, align 1
; store i8 %var_2_3902, i8* %var_2_41, align 1
%var_2_3903 = sext i32 %var_2_3880 to i64
; Matched:\<badref\>:  store i64 %var_2_3087, i64* %RDX.i2239, align 8
; store i64 %var_2_3903, i64* %RDX, align 8
%var_2_3904 = shl nsw i64 %var_2_3903, 3
%var_2_3905 = add i64 %var_2_3875, %var_2_3904
; Matched:%var_2_3913:  %var_2_3913 = add i64 %var_2_3879, 18
; %var_2_3906 = add i64 %var_2_3872, 18
; Matched:\<badref\>:  store i64 %var_2_4139, i64* %var_2_3, align 8
; store i64 %var_2_3906, i64* %PC, align 8
%var_2_3907 = inttoptr i64 %var_2_3905 to i64*
%var_2_3908 = load i64, i64* %var_2_3907, align 8
store i64 %var_2_3908, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1404:  %var_2_1404 = add i64 %var_2_1367, 22
; %var_2_3909 = add i64 %var_2_3872, 22
; Matched:\<badref\>:  store i64 %var_2_4255, i64* %var_2_3, align 8
; store i64 %var_2_3909, i64* %PC, align 8
%var_2_3910 = load i64, i64* %var_2_3874, align 8
; Matched:\<badref\>:  store i64 %var_2_597, i64* %RCX.i2236, align 8
; store i64 %var_2_3910, i64* %RCX, align 8
%var_2_3911 = add i64 %var_2_3870, -32
; Matched:%var_2_4032:  %var_2_4032 = add i64 %var_2_3992, 25
; %var_2_3912 = add i64 %var_2_3872, 25
; Matched:\<badref\>:  store i64 %var_2_4032, i64* %var_2_3, align 8
; store i64 %var_2_3912, i64* %PC, align 8
%var_2_3913 = inttoptr i64 %var_2_3911 to i32*
%var_2_3914 = load i32, i32* %var_2_3913, align 4
%var_2_3915 = add i32 %var_2_3914, 1
; Matched:%var_2_3313:  %var_2_3313 = zext i32 %var_2_3312 to i64
; %var_2_3916 = zext i32 %var_2_3915 to i64
; Matched:\<badref\>:  store i64 %var_2_3313, i64* %RAX.i2224, align 8
; store i64 %var_2_3916, i64* %RAX, align 8
; Matched:%var_2_3314:  %var_2_3314 = icmp eq i32 %var_2_3311, -1
; %var_2_3917 = icmp eq i32 %var_2_3914, -1
; Matched:%var_2_2648:  %var_2_2648 = icmp eq i32 %var_2_2645, 0
; %var_2_3918 = icmp eq i32 %var_2_3915, 0
; Matched:%var_2_2649:  %var_2_2649 = or i1 %var_2_2647, %var_2_2648
; %var_2_3919 = or i1 %var_2_3917, %var_2_3918
; Matched:%var_2_3317:  %var_2_3317 = zext i1 %var_2_3316 to i8
; %var_2_3920 = zext i1 %var_2_3919 to i8
; Matched:\<badref\>:  store i8 %var_2_4616, i8* %var_2_14, align 1
; store i8 %var_2_3920, i8* %var_2_16, align 1
; Matched:%var_2_4617:  %var_2_4617 = and i32 %var_2_4611, 255
; %var_2_3921 = and i32 %var_2_3915, 255
; Matched:%var_2_3319:  %var_2_3319 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3318)
; %var_2_3922 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3921) #14
; Matched:%var_2_3320:  %var_2_3320 = trunc i32 %var_2_3319 to i8
; %var_2_3923 = trunc i32 %var_2_3922 to i8
; Matched:%var_2_4620:  %var_2_4620 = and i8 %var_2_4619, 1
; %var_2_3924 = and i8 %var_2_3923, 1
; Matched:%var_2_4621:  %var_2_4621 = xor i8 %var_2_4620, 1
; %var_2_3925 = xor i8 %var_2_3924, 1
; Matched:\<badref\>:  store i8 %var_2_3322, i8* %var_2_21, align 1
; store i8 %var_2_3925, i8* %var_2_23, align 1
; Matched:%var_2_2656:  %var_2_2656 = xor i32 %var_2_2645, %var_2_2644
; %var_2_3926 = xor i32 %var_2_3915, %var_2_3914
; Matched:%var_2_2657:  %var_2_2657 = lshr i32 %var_2_2656, 4
; %var_2_3927 = lshr i32 %var_2_3926, 4
; Matched:%var_2_2658:  %var_2_2658 = trunc i32 %var_2_2657 to i8
; %var_2_3928 = trunc i32 %var_2_3927 to i8
; Matched:%var_2_2659:  %var_2_2659 = and i8 %var_2_2658, 1
; %var_2_3929 = and i8 %var_2_3928, 1
; Matched:\<badref\>:  store i8 %var_2_2659, i8* %var_2_27, align 1
; store i8 %var_2_3929, i8* %var_2_29, align 1
; Matched:%var_2_3327:  %var_2_3327 = zext i1 %var_2_3315 to i8
; %var_2_3930 = zext i1 %var_2_3918 to i8
; Matched:\<badref\>:  store i8 %var_2_3327, i8* %var_2_30, align 1
; store i8 %var_2_3930, i8* %var_2_32, align 1
; Matched:%var_2_3328:  %var_2_3328 = lshr i32 %var_2_3312, 31
; %var_2_3931 = lshr i32 %var_2_3915, 31
; Matched:%var_2_2662:  %var_2_2662 = trunc i32 %var_2_2661 to i8
; %var_2_3932 = trunc i32 %var_2_3931 to i8
; Matched:\<badref\>:  store i8 %var_2_2775, i8* %var_2_33, align 1
; store i8 %var_2_3932, i8* %var_2_35, align 1
; Matched:%var_2_4629:  %var_2_4629 = lshr i32 %var_2_4610, 31
; %var_2_3933 = lshr i32 %var_2_3914, 31
; Matched:%var_2_4630:  %var_2_4630 = xor i32 %var_2_4627, %var_2_4629
; %var_2_3934 = xor i32 %var_2_3931, %var_2_3933
; Matched:%var_2_3332:  %var_2_3332 = add nuw nsw i32 %var_2_3331, %var_2_3328
; %var_2_3935 = add nuw nsw i32 %var_2_3934, %var_2_3931
; Matched:%var_2_465:  %var_2_465 = icmp eq i32 %var_2_464, 2
; %var_2_3936 = icmp eq i32 %var_2_3935, 2
; Matched:%var_2_2667:  %var_2_2667 = zext i1 %var_2_2666 to i8
; %var_2_3937 = zext i1 %var_2_3936 to i8
; Matched:\<badref\>:  store i8 %var_2_2667, i8* %var_2_39, align 1
; store i8 %var_2_3937, i8* %var_2_41, align 1
%var_2_3938 = sext i32 %var_2_3915 to i64
; Matched:\<badref\>:  store i64 %var_2_4634, i64* %RDX.i2239, align 8
; store i64 %var_2_3938, i64* %RDX, align 8
%var_2_3939 = shl nsw i64 %var_2_3938, 3
%var_2_3940 = add i64 %var_2_3910, %var_2_3939
; Matched:%var_2_2784:  %var_2_2784 = add i64 %var_2_2715, 36
; %var_2_3941 = add i64 %var_2_3872, 36
; Matched:\<badref\>:  store i64 %var_2_2784, i64* %var_2_3, align 8
; store i64 %var_2_3941, i64* %PC, align 8
%var_2_3942 = bitcast i64 %var_2_3908 to double
%var_2_3943 = inttoptr i64 %var_2_3940 to double*
%var_2_3944 = load double, double* %var_2_3943, align 8
%var_2_3945 = fadd double %var_2_3942, %var_2_3944
store double %var_2_3945, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_362:  %var_2_362 = load i64, i64* %RBP.i, align 8
; %var_2_3946 = load i64, i64* %RBP, align 8
; Matched:%var_2_1329:  %var_2_1329 = add i64 %var_2_1328, -128
; %var_2_3947 = add i64 %var_2_3946, -128
; Matched:%var_2_2678:  %var_2_2678 = add i64 %var_2_2602, 41
; %var_2_3948 = add i64 %var_2_3872, 41
; Matched:\<badref\>:  store i64 %var_2_1330, i64* %var_2_3, align 8
; store i64 %var_2_3948, i64* %PC, align 8
; Matched:%var_2_3956:  %var_2_3956 = inttoptr i64 %var_2_3954 to double*
; %var_2_3949 = inttoptr i64 %var_2_3947 to double*
; Matched:\<badref\>:  store double %var_2_1327, double* %var_2_1331, align 8
; store double %var_2_3945, double* %var_2_3949, align 8
%var_2_3950 = load i64, i64* %RBP, align 8
%var_2_3951 = add i64 %var_2_3950, -16
%var_2_3952 = load i64, i64* %PC, align 8
; Matched:%var_2_56:  %var_2_56 = add i64 %var_2_55, 4
; %var_2_3953 = add i64 %var_2_3952, 4
; Matched:\<badref\>:  store i64 %var_2_56, i64* %var_2_3, align 8
; store i64 %var_2_3953, i64* %PC, align 8
%var_2_3954 = inttoptr i64 %var_2_3951 to i64*
%var_2_3955 = load i64, i64* %var_2_3954, align 8
; Matched:\<badref\>:  store i64 %var_2_1596, i64* %RCX.i2236, align 8
; store i64 %var_2_3955, i64* %RCX, align 8
%var_2_3956 = add i64 %var_2_3950, -28
%var_2_3957 = add i64 %var_2_3952, 8
store i64 %var_2_3957, i64* %PC, align 8
%var_2_3958 = inttoptr i64 %var_2_3956 to i32*
%var_2_3959 = load i32, i32* %var_2_3958, align 4
%var_2_3960 = sext i32 %var_2_3959 to i64
; Matched:\<badref\>:  store i64 %var_2_2690, i64* %RDX.i2239, align 8
; store i64 %var_2_3960, i64* %RDX, align 8
%var_2_3961 = shl nsw i64 %var_2_3960, 3
%var_2_3962 = add i64 %var_2_3961, %var_2_3955
; Matched:%var_2_2806:  %var_2_2806 = add i64 %var_2_2795, 13
; %var_2_3963 = add i64 %var_2_3952, 13
; Matched:\<badref\>:  store i64 %var_2_3970, i64* %var_2_3, align 8
; store i64 %var_2_3963, i64* %PC, align 8
%var_2_3964 = inttoptr i64 %var_2_3962 to i64*
%var_2_3965 = load i64, i64* %var_2_3964, align 8
store i64 %var_2_3965, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1782:  %var_2_1782 = add i64 %var_2_1771, 17
; %var_2_3966 = add i64 %var_2_3952, 17
; Matched:\<badref\>:  store i64 %var_2_1782, i64* %var_2_3, align 8
; store i64 %var_2_3966, i64* %PC, align 8
%var_2_3967 = load i64, i64* %var_2_3954, align 8
; Matched:\<badref\>:  store i64 %var_2_517, i64* %RCX.i2236, align 8
; store i64 %var_2_3967, i64* %RCX, align 8
%var_2_3968 = add i64 %var_2_3950, -32
; Matched:%var_2_2812:  %var_2_2812 = add i64 %var_2_2795, 21
; %var_2_3969 = add i64 %var_2_3952, 21
; Matched:\<badref\>:  store i64 %var_2_2812, i64* %var_2_3, align 8
; store i64 %var_2_3969, i64* %PC, align 8
%var_2_3970 = inttoptr i64 %var_2_3968 to i32*
%var_2_3971 = load i32, i32* %var_2_3970, align 4
%var_2_3972 = sext i32 %var_2_3971 to i64
; Matched:\<badref\>:  store i64 %var_2_2589, i64* %RDX.i2239, align 8
; store i64 %var_2_3972, i64* %RDX, align 8
%var_2_3973 = shl nsw i64 %var_2_3972, 3
%var_2_3974 = add i64 %var_2_3973, %var_2_3967
; Matched:%var_2_1694:  %var_2_1694 = add i64 %var_2_1673, 26
; %var_2_3975 = add i64 %var_2_3952, 26
; Matched:\<badref\>:  store i64 %var_2_1694, i64* %var_2_3, align 8
; store i64 %var_2_3975, i64* %PC, align 8
%var_2_3976 = bitcast i64 %var_2_3965 to double
%var_2_3977 = inttoptr i64 %var_2_3974 to double*
%var_2_3978 = load double, double* %var_2_3977, align 8
%var_2_3979 = fsub double %var_2_3976, %var_2_3978
store double %var_2_3979, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_3987:  %var_2_3987 = add i64 %var_2_3957, -136
; %var_2_3980 = add i64 %var_2_3950, -136
; Matched:%var_2_2711:  %var_2_2711 = add i64 %var_2_2682, 34
; %var_2_3981 = add i64 %var_2_3952, 34
; Matched:\<badref\>:  store i64 %var_2_2711, i64* %var_2_3, align 8
; store i64 %var_2_3981, i64* %PC, align 8
; Matched:%var_2_3989:  %var_2_3989 = inttoptr i64 %var_2_3987 to double*
; %var_2_3982 = inttoptr i64 %var_2_3980 to double*
; Matched:\<badref\>:  store double %var_2_3986, double* %var_2_3989, align 8
; store double %var_2_3979, double* %var_2_3982, align 8
%var_2_3983 = load i64, i64* %RBP, align 8
%var_2_3984 = add i64 %var_2_3983, -16
%var_2_3985 = load i64, i64* %PC, align 8
; Matched:%var_2_2829:  %var_2_2829 = add i64 %var_2_2828, 4
; %var_2_3986 = add i64 %var_2_3985, 4
; Matched:\<badref\>:  store i64 %var_2_2829, i64* %var_2_3, align 8
; store i64 %var_2_3986, i64* %PC, align 8
%var_2_3987 = inttoptr i64 %var_2_3984 to i64*
%var_2_3988 = load i64, i64* %var_2_3987, align 8
; Matched:\<badref\>:  store i64 %var_2_745, i64* %RCX.i2236, align 8
; store i64 %var_2_3988, i64* %RCX, align 8
%var_2_3989 = add i64 %var_2_3983, -28
; Matched:%var_2_1485:  %var_2_1485 = add i64 %var_2_1480, 7
; %var_2_3990 = add i64 %var_2_3985, 7
; Matched:\<badref\>:  store i64 %var_2_3546, i64* %var_2_3, align 8
; store i64 %var_2_3990, i64* %PC, align 8
%var_2_3991 = inttoptr i64 %var_2_3989 to i32*
%var_2_3992 = load i32, i32* %var_2_3991, align 4
%var_2_3993 = add i32 %var_2_3992, 1
; Matched:%var_2_2724:  %var_2_2724 = zext i32 %var_2_2723 to i64
; %var_2_3994 = zext i32 %var_2_3993 to i64
; Matched:\<badref\>:  store i64 %var_2_2724, i64* %RAX.i2224, align 8
; store i64 %var_2_3994, i64* %RAX, align 8
; Matched:%var_2_2725:  %var_2_2725 = icmp eq i32 %var_2_2722, -1
; %var_2_3995 = icmp eq i32 %var_2_3992, -1
; Matched:%var_2_1719:  %var_2_1719 = icmp eq i32 %var_2_1716, 0
; %var_2_3996 = icmp eq i32 %var_2_3993, 0
; Matched:%var_2_2614:  %var_2_2614 = or i1 %var_2_2612, %var_2_2613
; %var_2_3997 = or i1 %var_2_3995, %var_2_3996
; Matched:%var_2_3069:  %var_2_3069 = zext i1 %var_2_3068 to i8
; %var_2_3998 = zext i1 %var_2_3997 to i8
; Matched:\<badref\>:  store i8 %var_2_3069, i8* %var_2_14, align 1
; store i8 %var_2_3998, i8* %var_2_16, align 1
; Matched:%var_2_2729:  %var_2_2729 = and i32 %var_2_2723, 255
; %var_2_3999 = and i32 %var_2_3993, 255
; Matched:%var_2_2617:  %var_2_2617 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2616)
; %var_2_4000 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3999) #14
; Matched:%var_2_758:  %var_2_758 = trunc i32 %var_2_757 to i8
; %var_2_4001 = trunc i32 %var_2_4000 to i8
; Matched:%var_2_3073:  %var_2_3073 = and i8 %var_2_3072, 1
; %var_2_4002 = and i8 %var_2_4001, 1
; Matched:%var_2_4351:  %var_2_4351 = xor i8 %var_2_4350, 1
; %var_2_4003 = xor i8 %var_2_4002, 1
; Matched:\<badref\>:  store i8 %var_2_3897, i8* %var_2_21, align 1
; store i8 %var_2_4003, i8* %var_2_23, align 1
; Matched:%var_2_2621:  %var_2_2621 = xor i32 %var_2_2610, %var_2_2609
; %var_2_4004 = xor i32 %var_2_3993, %var_2_3992
; Matched:%var_2_2622:  %var_2_2622 = lshr i32 %var_2_2621, 4
; %var_2_4005 = lshr i32 %var_2_4004, 4
; Matched:%var_2_3077:  %var_2_3077 = trunc i32 %var_2_3076 to i8
; %var_2_4006 = trunc i32 %var_2_4005 to i8
; Matched:%var_2_2624:  %var_2_2624 = and i8 %var_2_2623, 1
; %var_2_4007 = and i8 %var_2_4006, 1
; Matched:\<badref\>:  store i8 %var_2_2624, i8* %var_2_27, align 1
; store i8 %var_2_4007, i8* %var_2_29, align 1
; Matched:%var_2_3902:  %var_2_3902 = zext i1 %var_2_3890 to i8
; %var_2_4008 = zext i1 %var_2_3996 to i8
; Matched:\<badref\>:  store i8 %var_2_2738, i8* %var_2_30, align 1
; store i8 %var_2_4008, i8* %var_2_32, align 1
; Matched:%var_2_3080:  %var_2_3080 = lshr i32 %var_2_3064, 31
; %var_2_4009 = lshr i32 %var_2_3993, 31
; Matched:%var_2_4358:  %var_2_4358 = trunc i32 %var_2_4357 to i8
; %var_2_4010 = trunc i32 %var_2_4009 to i8
; Matched:\<badref\>:  store i8 %var_2_2627, i8* %var_2_33, align 1
; store i8 %var_2_4010, i8* %var_2_35, align 1
; Matched:%var_2_4359:  %var_2_4359 = lshr i32 %var_2_4340, 31
; %var_2_4011 = lshr i32 %var_2_3992, 31
; Matched:%var_2_428:  %var_2_428 = xor i32 %var_2_425, %var_2_427
; %var_2_4012 = xor i32 %var_2_4009, %var_2_4011
; Matched:%var_2_3084:  %var_2_3084 = add nuw nsw i32 %var_2_3083, %var_2_3080
; %var_2_4013 = add nuw nsw i32 %var_2_4012, %var_2_4009
; Matched:%var_2_3085:  %var_2_3085 = icmp eq i32 %var_2_3084, 2
; %var_2_4014 = icmp eq i32 %var_2_4013, 2
; Matched:%var_2_431:  %var_2_431 = zext i1 %var_2_430 to i8
; %var_2_4015 = zext i1 %var_2_4014 to i8
; Matched:\<badref\>:  store i8 %var_2_431, i8* %var_2_39, align 1
; store i8 %var_2_4015, i8* %var_2_41, align 1
%var_2_4016 = sext i32 %var_2_3993 to i64
; Matched:\<badref\>:  store i64 %var_2_2746, i64* %RDX.i2239, align 8
; store i64 %var_2_4016, i64* %RDX, align 8
%var_2_4017 = shl nsw i64 %var_2_4016, 3
%var_2_4018 = add i64 %var_2_3988, %var_2_4017
; Matched:%var_2_2340:  %var_2_2340 = add i64 %var_2_2306, 18
; %var_2_4019 = add i64 %var_2_3985, 18
; Matched:\<badref\>:  store i64 %var_2_2340, i64* %var_2_3, align 8
; store i64 %var_2_4019, i64* %PC, align 8
%var_2_4020 = inttoptr i64 %var_2_4018 to i64*
%var_2_4021 = load i64, i64* %var_2_4020, align 8
store i64 %var_2_4021, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_1630:  %var_2_1630 = add i64 %var_2_1593, 22
; %var_2_4022 = add i64 %var_2_3985, 22
; Matched:\<badref\>:  store i64 %var_2_1404, i64* %var_2_3, align 8
; store i64 %var_2_4022, i64* %PC, align 8
%var_2_4023 = load i64, i64* %var_2_3987, align 8
; Matched:\<badref\>:  store i64 %var_2_270, i64* %RCX.i2236, align 8
; store i64 %var_2_4023, i64* %RCX, align 8
%var_2_4024 = add i64 %var_2_3983, -32
; Matched:%var_2_4258:  %var_2_4258 = add i64 %var_2_4218, 25
; %var_2_4025 = add i64 %var_2_3985, 25
; Matched:\<badref\>:  store i64 %var_2_4258, i64* %var_2_3, align 8
; store i64 %var_2_4025, i64* %PC, align 8
%var_2_4026 = inttoptr i64 %var_2_4024 to i32*
%var_2_4027 = load i32, i32* %var_2_4026, align 4
%var_2_4028 = add i32 %var_2_4027, 1
; Matched:%var_2_2646:  %var_2_2646 = zext i32 %var_2_2645 to i64
; %var_2_4029 = zext i32 %var_2_4028 to i64
; Matched:\<badref\>:  store i64 %var_2_2646, i64* %RAX.i2224, align 8
; store i64 %var_2_4029, i64* %RAX, align 8
; Matched:%var_2_2647:  %var_2_2647 = icmp eq i32 %var_2_2644, -1
; %var_2_4030 = icmp eq i32 %var_2_4027, -1
; Matched:%var_2_2761:  %var_2_2761 = icmp eq i32 %var_2_2758, 0
; %var_2_4031 = icmp eq i32 %var_2_4028, 0
; Matched:%var_2_2762:  %var_2_2762 = or i1 %var_2_2760, %var_2_2761
; %var_2_4032 = or i1 %var_2_4030, %var_2_4031
; Matched:%var_2_2650:  %var_2_2650 = zext i1 %var_2_2649 to i8
; %var_2_4033 = zext i1 %var_2_4032 to i8
; Matched:\<badref\>:  store i8 %var_2_3317, i8* %var_2_14, align 1
; store i8 %var_2_4033, i8* %var_2_16, align 1
; Matched:%var_2_3318:  %var_2_3318 = and i32 %var_2_3312, 255
; %var_2_4034 = and i32 %var_2_4028, 255
; Matched:%var_2_2652:  %var_2_2652 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2651)
; %var_2_4035 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4034) #14
; Matched:%var_2_2653:  %var_2_2653 = trunc i32 %var_2_2652 to i8
; %var_2_4036 = trunc i32 %var_2_4035 to i8
; Matched:%var_2_3321:  %var_2_3321 = and i8 %var_2_3320, 1
; %var_2_4037 = and i8 %var_2_4036, 1
; Matched:%var_2_3322:  %var_2_3322 = xor i8 %var_2_3321, 1
; %var_2_4038 = xor i8 %var_2_4037, 1
; Matched:\<badref\>:  store i8 %var_2_2655, i8* %var_2_21, align 1
; store i8 %var_2_4038, i8* %var_2_23, align 1
; Matched:%var_2_2769:  %var_2_2769 = xor i32 %var_2_2758, %var_2_2757
; %var_2_4039 = xor i32 %var_2_4028, %var_2_4027
; Matched:%var_2_2770:  %var_2_2770 = lshr i32 %var_2_2769, 4
; %var_2_4040 = lshr i32 %var_2_4039, 4
; Matched:%var_2_2771:  %var_2_2771 = trunc i32 %var_2_2770 to i8
; %var_2_4041 = trunc i32 %var_2_4040 to i8
; Matched:%var_2_2772:  %var_2_2772 = and i8 %var_2_2771, 1
; %var_2_4042 = and i8 %var_2_4041, 1
; Matched:\<badref\>:  store i8 %var_2_2772, i8* %var_2_27, align 1
; store i8 %var_2_4042, i8* %var_2_29, align 1
; Matched:%var_2_2660:  %var_2_2660 = zext i1 %var_2_2648 to i8
; %var_2_4043 = zext i1 %var_2_4031 to i8
; Matched:\<badref\>:  store i8 %var_2_2660, i8* %var_2_30, align 1
; store i8 %var_2_4043, i8* %var_2_32, align 1
; Matched:%var_2_2661:  %var_2_2661 = lshr i32 %var_2_2645, 31
; %var_2_4044 = lshr i32 %var_2_4028, 31
; Matched:%var_2_3329:  %var_2_3329 = trunc i32 %var_2_3328 to i8
; %var_2_4045 = trunc i32 %var_2_4044 to i8
; Matched:\<badref\>:  store i8 %var_2_3939, i8* %var_2_33, align 1
; store i8 %var_2_4045, i8* %var_2_35, align 1
; Matched:%var_2_3330:  %var_2_3330 = lshr i32 %var_2_3311, 31
; %var_2_4046 = lshr i32 %var_2_4027, 31
; Matched:%var_2_3331:  %var_2_3331 = xor i32 %var_2_3328, %var_2_3330
; %var_2_4047 = xor i32 %var_2_4044, %var_2_4046
; Matched:%var_2_464:  %var_2_464 = add nuw nsw i32 %var_2_463, %var_2_460
; %var_2_4048 = add nuw nsw i32 %var_2_4047, %var_2_4044
; Matched:%var_2_2666:  %var_2_2666 = icmp eq i32 %var_2_2665, 2
; %var_2_4049 = icmp eq i32 %var_2_4048, 2
; Matched:%var_2_2780:  %var_2_2780 = zext i1 %var_2_2779 to i8
; %var_2_4050 = zext i1 %var_2_4049 to i8
; Matched:\<badref\>:  store i8 %var_2_2780, i8* %var_2_39, align 1
; store i8 %var_2_4050, i8* %var_2_41, align 1
%var_2_4051 = sext i32 %var_2_4028 to i64
; Matched:\<badref\>:  store i64 %var_2_3335, i64* %RDX.i2239, align 8
; store i64 %var_2_4051, i64* %RDX, align 8
%var_2_4052 = shl nsw i64 %var_2_4051, 3
%var_2_4053 = add i64 %var_2_4023, %var_2_4052
; Matched:%var_2_3010:  %var_2_3010 = add i64 %var_2_2941, 36
; %var_2_4054 = add i64 %var_2_3985, 36
; Matched:\<badref\>:  store i64 %var_2_3010, i64* %var_2_3, align 8
; store i64 %var_2_4054, i64* %PC, align 8
%var_2_4055 = bitcast i64 %var_2_4021 to double
%var_2_4056 = inttoptr i64 %var_2_4053 to double*
%var_2_4057 = load double, double* %var_2_4056, align 8
%var_2_4058 = fsub double %var_2_4055, %var_2_4057
store double %var_2_4058, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_4066:  %var_2_4066 = load i64, i64* %RBP.i, align 8
; %var_2_4059 = load i64, i64* %RBP, align 8
; Matched:%var_2_476:  %var_2_476 = add i64 %var_2_475, -144
; %var_2_4060 = add i64 %var_2_4059, -144
; Matched:%var_2_477:  %var_2_477 = add i64 %var_2_401, 44
; %var_2_4061 = add i64 %var_2_3985, 44
; Matched:\<badref\>:  store i64 %var_2_477, i64* %var_2_3, align 8
; store i64 %var_2_4061, i64* %PC, align 8
; Matched:%var_2_478:  %var_2_478 = inttoptr i64 %var_2_476 to double*
; %var_2_4062 = inttoptr i64 %var_2_4060 to double*
; Matched:\<badref\>:  store double %var_2_4065, double* %var_2_4069, align 8
; store double %var_2_4058, double* %var_2_4062, align 8
%var_2_4063 = load i64, i64* %RBP, align 8
%var_2_4064 = add i64 %var_2_4063, -16
%var_2_4065 = load i64, i64* %PC, align 8
; Matched:%var_2_4073:  %var_2_4073 = add i64 %var_2_4072, 4
; %var_2_4066 = add i64 %var_2_4065, 4
; Matched:\<badref\>:  store i64 %var_2_4073, i64* %var_2_3, align 8
; store i64 %var_2_4066, i64* %PC, align 8
%var_2_4067 = inttoptr i64 %var_2_4064 to i64*
%var_2_4068 = load i64, i64* %var_2_4067, align 8
; Matched:\<badref\>:  store i64 %var_2_1462, i64* %RCX.i2236, align 8
; store i64 %var_2_4068, i64* %RCX, align 8
%var_2_4069 = add i64 %var_2_4063, -36
%var_2_4070 = add i64 %var_2_4065, 8
store i64 %var_2_4070, i64* %PC, align 8
%var_2_4071 = inttoptr i64 %var_2_4069 to i32*
%var_2_4072 = load i32, i32* %var_2_4071, align 4
%var_2_4073 = sext i32 %var_2_4072 to i64
; Matched:\<badref\>:  store i64 %var_2_2916, i64* %RDX.i2239, align 8
; store i64 %var_2_4073, i64* %RDX, align 8
%var_2_4074 = shl nsw i64 %var_2_4073, 3
%var_2_4075 = add i64 %var_2_4074, %var_2_4068
; Matched:%var_2_737:  %var_2_737 = add i64 %var_2_732, 13
; %var_2_4076 = add i64 %var_2_4065, 13
; Matched:\<badref\>:  store i64 %var_2_737, i64* %var_2_3, align 8
; store i64 %var_2_4076, i64* %PC, align 8
%var_2_4077 = inttoptr i64 %var_2_4075 to i64*
%var_2_4078 = load i64, i64* %var_2_4077, align 8
store i64 %var_2_4078, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_608:  %var_2_608 = add i64 %var_2_594, 17
; %var_2_4079 = add i64 %var_2_4065, 17
; Matched:\<badref\>:  store i64 %var_2_608, i64* %var_2_3, align 8
; store i64 %var_2_4079, i64* %PC, align 8
%var_2_4080 = load i64, i64* %var_2_4067, align 8
; Matched:\<badref\>:  store i64 %var_2_1483, i64* %RCX.i2236, align 8
; store i64 %var_2_4080, i64* %RCX, align 8
%var_2_4081 = add i64 %var_2_4063, -40
; Matched:%var_2_3368:  %var_2_3368 = add i64 %var_2_3357, 21
; %var_2_4082 = add i64 %var_2_4065, 21
; Matched:\<badref\>:  store i64 %var_2_385, i64* %var_2_3, align 8
; store i64 %var_2_4082, i64* %PC, align 8
%var_2_4083 = inttoptr i64 %var_2_4081 to i32*
%var_2_4084 = load i32, i32* %var_2_4083, align 4
%var_2_4085 = sext i32 %var_2_4084 to i64
; Matched:\<badref\>:  store i64 %var_2_2928, i64* %RDX.i2239, align 8
; store i64 %var_2_4085, i64* %RDX, align 8
%var_2_4086 = shl nsw i64 %var_2_4085, 3
%var_2_4087 = add i64 %var_2_4086, %var_2_4080
; Matched:%var_2_3869:  %var_2_3869 = add i64 %var_2_3846, 26
; %var_2_4088 = add i64 %var_2_4065, 26
; Matched:\<badref\>:  store i64 %var_2_3869, i64* %var_2_3, align 8
; store i64 %var_2_4088, i64* %PC, align 8
%var_2_4089 = bitcast i64 %var_2_4078 to double
%var_2_4090 = inttoptr i64 %var_2_4087 to double*
%var_2_4091 = load double, double* %var_2_4090, align 8
%var_2_4092 = fadd double %var_2_4089, %var_2_4091
store double %var_2_4092, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_4100:  %var_2_4100 = add i64 %var_2_4070, -152
; %var_2_4093 = add i64 %var_2_4063, -152
; Matched:%var_2_2824:  %var_2_2824 = add i64 %var_2_2795, 34
; %var_2_4094 = add i64 %var_2_4065, 34
; Matched:\<badref\>:  store i64 %var_2_2824, i64* %var_2_3, align 8
; store i64 %var_2_4094, i64* %PC, align 8
; Matched:%var_2_4102:  %var_2_4102 = inttoptr i64 %var_2_4100 to double*
; %var_2_4095 = inttoptr i64 %var_2_4093 to double*
; Matched:\<badref\>:  store double %var_2_1474, double* %var_2_1477, align 8
; store double %var_2_4092, double* %var_2_4095, align 8
%var_2_4096 = load i64, i64* %RBP, align 8
%var_2_4097 = add i64 %var_2_4096, -16
%var_2_4098 = load i64, i64* %PC, align 8
; Matched:%var_2_4106:  %var_2_4106 = add i64 %var_2_4105, 4
; %var_2_4099 = add i64 %var_2_4098, 4
; Matched:\<badref\>:  store i64 %var_2_4106, i64* %var_2_3, align 8
; store i64 %var_2_4099, i64* %PC, align 8
%var_2_4100 = inttoptr i64 %var_2_4097 to i64*
%var_2_4101 = load i64, i64* %var_2_4100, align 8
; Matched:\<badref\>:  store i64 %var_2_793, i64* %RCX.i2236, align 8
; store i64 %var_2_4101, i64* %RCX, align 8
%var_2_4102 = add i64 %var_2_4096, -36
; Matched:%var_2_293:  %var_2_293 = add i64 %var_2_288, 7
; %var_2_4103 = add i64 %var_2_4098, 7
; Matched:\<badref\>:  store i64 %var_2_1485, i64* %var_2_3, align 8
; store i64 %var_2_4103, i64* %PC, align 8
%var_2_4104 = inttoptr i64 %var_2_4102 to i32*
%var_2_4105 = load i32, i32* %var_2_4104, align 4
%var_2_4106 = add i32 %var_2_4105, 1
; Matched:%var_2_636:  %var_2_636 = zext i32 %var_2_635 to i64
; %var_2_4107 = zext i32 %var_2_4106 to i64
; Matched:\<badref\>:  store i64 %var_2_636, i64* %RAX.i2224, align 8
; store i64 %var_2_4107, i64* %RAX, align 8
; Matched:%var_2_2838:  %var_2_2838 = icmp eq i32 %var_2_2835, -1
; %var_2_4108 = icmp eq i32 %var_2_4105, -1
; Matched:%var_2_2839:  %var_2_2839 = icmp eq i32 %var_2_2836, 0
; %var_2_4109 = icmp eq i32 %var_2_4106, 0
; Matched:%var_2_2840:  %var_2_2840 = or i1 %var_2_2838, %var_2_2839
; %var_2_4110 = or i1 %var_2_4108, %var_2_4109
; Matched:%var_2_2841:  %var_2_2841 = zext i1 %var_2_2840 to i8
; %var_2_4111 = zext i1 %var_2_4110 to i8
; Matched:\<badref\>:  store i8 %var_2_2841, i8* %var_2_14, align 1
; store i8 %var_2_4111, i8* %var_2_16, align 1
; Matched:%var_2_2842:  %var_2_2842 = and i32 %var_2_2836, 255
; %var_2_4112 = and i32 %var_2_4106, 255
; Matched:%var_2_2843:  %var_2_2843 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2842)
; %var_2_4113 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4112) #14
; Matched:%var_2_2844:  %var_2_2844 = trunc i32 %var_2_2843 to i8
; %var_2_4114 = trunc i32 %var_2_4113 to i8
; Matched:%var_2_644:  %var_2_644 = and i8 %var_2_643, 1
; %var_2_4115 = and i8 %var_2_4114, 1
; Matched:%var_2_532:  %var_2_532 = xor i8 %var_2_531, 1
; %var_2_4116 = xor i8 %var_2_4115, 1
; Matched:\<badref\>:  store i8 %var_2_645, i8* %var_2_21, align 1
; store i8 %var_2_4116, i8* %var_2_23, align 1
; Matched:%var_2_2847:  %var_2_2847 = xor i32 %var_2_2836, %var_2_2835
; %var_2_4117 = xor i32 %var_2_4106, %var_2_4105
; Matched:%var_2_2848:  %var_2_2848 = lshr i32 %var_2_2847, 4
; %var_2_4118 = lshr i32 %var_2_4117, 4
; Matched:%var_2_2849:  %var_2_2849 = trunc i32 %var_2_2848 to i8
; %var_2_4119 = trunc i32 %var_2_4118 to i8
; Matched:%var_2_2850:  %var_2_2850 = and i8 %var_2_2849, 1
; %var_2_4120 = and i8 %var_2_4119, 1
; Matched:\<badref\>:  store i8 %var_2_2850, i8* %var_2_27, align 1
; store i8 %var_2_4120, i8* %var_2_29, align 1
; Matched:%var_2_2851:  %var_2_2851 = zext i1 %var_2_2839 to i8
; %var_2_4121 = zext i1 %var_2_4109 to i8
; Matched:\<badref\>:  store i8 %var_2_2851, i8* %var_2_30, align 1
; store i8 %var_2_4121, i8* %var_2_32, align 1
; Matched:%var_2_2965:  %var_2_2965 = lshr i32 %var_2_2949, 31
; %var_2_4122 = lshr i32 %var_2_4106, 31
; Matched:%var_2_2853:  %var_2_2853 = trunc i32 %var_2_2852 to i8
; %var_2_4123 = trunc i32 %var_2_4122 to i8
; Matched:\<badref\>:  store i8 %var_2_2853, i8* %var_2_33, align 1
; store i8 %var_2_4123, i8* %var_2_35, align 1
; Matched:%var_2_2854:  %var_2_2854 = lshr i32 %var_2_2835, 31
; %var_2_4124 = lshr i32 %var_2_4105, 31
; Matched:%var_2_654:  %var_2_654 = xor i32 %var_2_651, %var_2_653
; %var_2_4125 = xor i32 %var_2_4122, %var_2_4124
; Matched:%var_2_542:  %var_2_542 = add nuw nsw i32 %var_2_541, %var_2_538
; %var_2_4126 = add nuw nsw i32 %var_2_4125, %var_2_4122
; Matched:%var_2_1622:  %var_2_1622 = icmp eq i32 %var_2_1621, 2
; %var_2_4127 = icmp eq i32 %var_2_4126, 2
; Matched:%var_2_657:  %var_2_657 = zext i1 %var_2_656 to i8
; %var_2_4128 = zext i1 %var_2_4127 to i8
; Matched:\<badref\>:  store i8 %var_2_1623, i8* %var_2_39, align 1
; store i8 %var_2_4128, i8* %var_2_41, align 1
%var_2_4129 = sext i32 %var_2_4106 to i64
; Matched:\<badref\>:  store i64 %var_2_658, i64* %RDX.i2239, align 8
; store i64 %var_2_4129, i64* %RDX, align 8
%var_2_4130 = shl nsw i64 %var_2_4129, 3
%var_2_4131 = add i64 %var_2_4101, %var_2_4130
; Matched:%var_2_4252:  %var_2_4252 = add i64 %var_2_4218, 18
; %var_2_4132 = add i64 %var_2_4098, 18
; Matched:\<badref\>:  store i64 %var_2_4252, i64* %var_2_3, align 8
; store i64 %var_2_4132, i64* %PC, align 8
%var_2_4133 = inttoptr i64 %var_2_4131 to i64*
%var_2_4134 = load i64, i64* %var_2_4133, align 8
store i64 %var_2_4134, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_4381:  %var_2_4381 = add i64 %var_2_4371, 22
; %var_2_4135 = add i64 %var_2_4098, 22
; Matched:\<badref\>:  store i64 %var_2_1630, i64* %var_2_3, align 8
; store i64 %var_2_4135, i64* %PC, align 8
%var_2_4136 = load i64, i64* %var_2_4100, align 8
; Matched:\<badref\>:  store i64 %var_2_2866, i64* %RCX.i2236, align 8
; store i64 %var_2_4136, i64* %RCX, align 8
%var_2_4137 = add i64 %var_2_4096, -40
; Matched:%var_2_1407:  %var_2_1407 = add i64 %var_2_1367, 25
; %var_2_4138 = add i64 %var_2_4098, 25
; Matched:\<badref\>:  store i64 %var_2_1407, i64* %var_2_3, align 8
; store i64 %var_2_4138, i64* %PC, align 8
%var_2_4139 = inttoptr i64 %var_2_4137 to i32*
%var_2_4140 = load i32, i32* %var_2_4139, align 4
%var_2_4141 = add i32 %var_2_4140, 1
; Matched:%var_2_2872:  %var_2_2872 = zext i32 %var_2_2871 to i64
; %var_2_4142 = zext i32 %var_2_4141 to i64
; Matched:\<badref\>:  store i64 %var_2_2020, i64* %RAX.i2224, align 8
; store i64 %var_2_4142, i64* %RAX, align 8
; Matched:%var_2_3439:  %var_2_3439 = icmp eq i32 %var_2_3436, -1
; %var_2_4143 = icmp eq i32 %var_2_4140, -1
; Matched:%var_2_3440:  %var_2_3440 = icmp eq i32 %var_2_3437, 0
; %var_2_4144 = icmp eq i32 %var_2_4141, 0
; Matched:%var_2_4740:  %var_2_4740 = or i1 %var_2_4738, %var_2_4739
; %var_2_4145 = or i1 %var_2_4143, %var_2_4144
; Matched:%var_2_3442:  %var_2_3442 = zext i1 %var_2_3441 to i8
; %var_2_4146 = zext i1 %var_2_4145 to i8
; Matched:\<badref\>:  store i8 %var_2_3442, i8* %var_2_14, align 1
; store i8 %var_2_4146, i8* %var_2_16, align 1
; Matched:%var_2_3443:  %var_2_3443 = and i32 %var_2_3437, 255
; %var_2_4147 = and i32 %var_2_4141, 255
; Matched:%var_2_4743:  %var_2_4743 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4742)
; %var_2_4148 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4147) #14
; Matched:%var_2_4744:  %var_2_4744 = trunc i32 %var_2_4743 to i8
; %var_2_4149 = trunc i32 %var_2_4148 to i8
; Matched:%var_2_3446:  %var_2_3446 = and i8 %var_2_3445, 1
; %var_2_4150 = and i8 %var_2_4149, 1
; Matched:%var_2_2029:  %var_2_2029 = xor i8 %var_2_2028, 1
; %var_2_4151 = xor i8 %var_2_4150, 1
; Matched:\<badref\>:  store i8 %var_2_3447, i8* %var_2_21, align 1
; store i8 %var_2_4151, i8* %var_2_23, align 1
; Matched:%var_2_3448:  %var_2_3448 = xor i32 %var_2_3437, %var_2_3436
; %var_2_4152 = xor i32 %var_2_4141, %var_2_4140
; Matched:%var_2_2031:  %var_2_2031 = lshr i32 %var_2_2030, 4
; %var_2_4153 = lshr i32 %var_2_4152, 4
; Matched:%var_2_2884:  %var_2_2884 = trunc i32 %var_2_2883 to i8
; %var_2_4154 = trunc i32 %var_2_4153 to i8
; Matched:%var_2_3451:  %var_2_3451 = and i8 %var_2_3450, 1
; %var_2_4155 = and i8 %var_2_4154, 1
; Matched:\<badref\>:  store i8 %var_2_3451, i8* %var_2_27, align 1
; store i8 %var_2_4155, i8* %var_2_29, align 1
; Matched:%var_2_3452:  %var_2_3452 = zext i1 %var_2_3440 to i8
; %var_2_4156 = zext i1 %var_2_4144 to i8
; Matched:\<badref\>:  store i8 %var_2_3452, i8* %var_2_30, align 1
; store i8 %var_2_4156, i8* %var_2_32, align 1
; Matched:%var_2_3453:  %var_2_3453 = lshr i32 %var_2_3437, 31
; %var_2_4157 = lshr i32 %var_2_4141, 31
; Matched:%var_2_3454:  %var_2_3454 = trunc i32 %var_2_3453 to i8
; %var_2_4158 = trunc i32 %var_2_4157 to i8
; Matched:\<badref\>:  store i8 %var_2_3454, i8* %var_2_33, align 1
; store i8 %var_2_4158, i8* %var_2_35, align 1
; Matched:%var_2_3455:  %var_2_3455 = lshr i32 %var_2_3436, 31
; %var_2_4159 = lshr i32 %var_2_4140, 31
; Matched:%var_2_2038:  %var_2_2038 = xor i32 %var_2_2035, %var_2_2037
; %var_2_4160 = xor i32 %var_2_4157, %var_2_4159
; Matched:%var_2_4756:  %var_2_4756 = add nuw nsw i32 %var_2_4755, %var_2_4752
; %var_2_4161 = add nuw nsw i32 %var_2_4160, %var_2_4157
; Matched:%var_2_691:  %var_2_691 = icmp eq i32 %var_2_690, 2
; %var_2_4162 = icmp eq i32 %var_2_4161, 2
; Matched:%var_2_3459:  %var_2_3459 = zext i1 %var_2_3458 to i8
; %var_2_4163 = zext i1 %var_2_4162 to i8
; Matched:\<badref\>:  store i8 %var_2_3459, i8* %var_2_39, align 1
; store i8 %var_2_4163, i8* %var_2_41, align 1
%var_2_4164 = sext i32 %var_2_4141 to i64
; Matched:\<badref\>:  store i64 %var_2_3460, i64* %RDX.i2239, align 8
; store i64 %var_2_4164, i64* %RDX, align 8
%var_2_4165 = shl nsw i64 %var_2_4164, 3
%var_2_4166 = add i64 %var_2_4136, %var_2_4165
; Matched:%var_2_3948:  %var_2_3948 = add i64 %var_2_3879, 36
; %var_2_4167 = add i64 %var_2_4098, 36
; Matched:\<badref\>:  store i64 %var_2_3948, i64* %var_2_3, align 8
; store i64 %var_2_4167, i64* %PC, align 8
%var_2_4168 = bitcast i64 %var_2_4134 to double
%var_2_4169 = inttoptr i64 %var_2_4166 to double*
%var_2_4170 = load double, double* %var_2_4169, align 8
%var_2_4171 = fadd double %var_2_4168, %var_2_4170
store double %var_2_4171, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_4179:  %var_2_4179 = load i64, i64* %RBP.i, align 8
; %var_2_4172 = load i64, i64* %RBP, align 8
; Matched:%var_2_589:  %var_2_589 = add i64 %var_2_588, -160
; %var_2_4173 = add i64 %var_2_4172, -160
; Matched:%var_2_590:  %var_2_590 = add i64 %var_2_514, 44
; %var_2_4174 = add i64 %var_2_4098, 44
; Matched:\<badref\>:  store i64 %var_2_590, i64* %var_2_3, align 8
; store i64 %var_2_4174, i64* %PC, align 8
; Matched:%var_2_4182:  %var_2_4182 = inttoptr i64 %var_2_4180 to double*
; %var_2_4175 = inttoptr i64 %var_2_4173 to double*
; Matched:\<badref\>:  store double %var_2_587, double* %var_2_591, align 8
; store double %var_2_4171, double* %var_2_4175, align 8
%var_2_4176 = load i64, i64* %RBP, align 8
%var_2_4177 = add i64 %var_2_4176, -16
%var_2_4178 = load i64, i64* %PC, align 8
; Matched:%var_2_1481:  %var_2_1481 = add i64 %var_2_1480, 4
; %var_2_4179 = add i64 %var_2_4178, 4
; Matched:\<badref\>:  store i64 %var_2_1481, i64* %var_2_3, align 8
; store i64 %var_2_4179, i64* %PC, align 8
%var_2_4180 = inttoptr i64 %var_2_4177 to i64*
%var_2_4181 = load i64, i64* %var_2_4180, align 8
; Matched:\<badref\>:  store i64 %var_2_1686, i64* %RCX.i2236, align 8
; store i64 %var_2_4181, i64* %RCX, align 8
%var_2_4182 = add i64 %var_2_4176, -36
%var_2_4183 = add i64 %var_2_4178, 8
store i64 %var_2_4183, i64* %PC, align 8
%var_2_4184 = inttoptr i64 %var_2_4182 to i32*
%var_2_4185 = load i32, i32* %var_2_4184, align 4
%var_2_4186 = sext i32 %var_2_4185 to i64
; Matched:\<badref\>:  store i64 %var_2_2803, i64* %RDX.i2239, align 8
; store i64 %var_2_4186, i64* %RDX, align 8
%var_2_4187 = shl nsw i64 %var_2_4186, 3
%var_2_4188 = add i64 %var_2_4187, %var_2_4181
; Matched:%var_2_2580:  %var_2_2580 = add i64 %var_2_2569, 13
; %var_2_4189 = add i64 %var_2_4178, 13
; Matched:\<badref\>:  store i64 %var_2_2580, i64* %var_2_3, align 8
; store i64 %var_2_4189, i64* %PC, align 8
%var_2_4190 = inttoptr i64 %var_2_4188 to i64*
%var_2_4191 = load i64, i64* %var_2_4190, align 8
store i64 %var_2_4191, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_3032:  %var_2_3032 = add i64 %var_2_3021, 17
; %var_2_4192 = add i64 %var_2_4178, 17
; Matched:\<badref\>:  store i64 %var_2_3032, i64* %var_2_3, align 8
; store i64 %var_2_4192, i64* %PC, align 8
%var_2_4193 = load i64, i64* %var_2_4180, align 8
; Matched:\<badref\>:  store i64 %var_2_2798, i64* %RCX.i2236, align 8
; store i64 %var_2_4193, i64* %RCX, align 8
%var_2_4194 = add i64 %var_2_4176, -40
; Matched:%var_2_498:  %var_2_498 = add i64 %var_2_481, 21
; %var_2_4195 = add i64 %var_2_4178, 21
; Matched:\<badref\>:  store i64 %var_2_498, i64* %var_2_3, align 8
; store i64 %var_2_4195, i64* %PC, align 8
%var_2_4196 = inttoptr i64 %var_2_4194 to i32*
%var_2_4197 = load i32, i32* %var_2_4196, align 4
%var_2_4198 = sext i32 %var_2_4197 to i64
; Matched:\<badref\>:  store i64 %var_2_1988, i64* %RDX.i2239, align 8
; store i64 %var_2_4198, i64* %RDX, align 8
%var_2_4199 = shl nsw i64 %var_2_4198, 3
%var_2_4200 = add i64 %var_2_4199, %var_2_4193
; Matched:%var_2_801:  %var_2_801 = add i64 %var_2_780, 26
; %var_2_4201 = add i64 %var_2_4178, 26
; Matched:\<badref\>:  store i64 %var_2_801, i64* %var_2_3, align 8
; store i64 %var_2_4201, i64* %PC, align 8
%var_2_4202 = bitcast i64 %var_2_4191 to double
%var_2_4203 = inttoptr i64 %var_2_4200 to double*
%var_2_4204 = load double, double* %var_2_4203, align 8
%var_2_4205 = fsub double %var_2_4202, %var_2_4204
store double %var_2_4205, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_4213:  %var_2_4213 = add i64 %var_2_4183, -168
; %var_2_4206 = add i64 %var_2_4176, -168
; Matched:%var_2_2937:  %var_2_2937 = add i64 %var_2_2908, 34
; %var_2_4207 = add i64 %var_2_4178, 34
; Matched:\<badref\>:  store i64 %var_2_2937, i64* %var_2_3, align 8
; store i64 %var_2_4207, i64* %PC, align 8
; Matched:%var_2_624:  %var_2_624 = inttoptr i64 %var_2_622 to double*
; %var_2_4208 = inttoptr i64 %var_2_4206 to double*
; Matched:\<badref\>:  store double %var_2_1587, double* %var_2_1590, align 8
; store double %var_2_4205, double* %var_2_4208, align 8
%var_2_4209 = load i64, i64* %RBP, align 8
%var_2_4210 = add i64 %var_2_4209, -16
%var_2_4211 = load i64, i64* %PC, align 8
; Matched:%var_2_595:  %var_2_595 = add i64 %var_2_594, 4
; %var_2_4212 = add i64 %var_2_4211, 4
; Matched:\<badref\>:  store i64 %var_2_595, i64* %var_2_3, align 8
; store i64 %var_2_4212, i64* %PC, align 8
%var_2_4213 = inttoptr i64 %var_2_4210 to i64*
%var_2_4214 = load i64, i64* %var_2_4213, align 8
; Matched:\<badref\>:  store i64 %var_2_1759, i64* %RCX.i2236, align 8
; store i64 %var_2_4214, i64* %RCX, align 8
%var_2_4215 = add i64 %var_2_4209, -36
; Matched:%var_2_519:  %var_2_519 = add i64 %var_2_514, 7
; %var_2_4216 = add i64 %var_2_4211, 7
; Matched:\<badref\>:  store i64 %var_2_293, i64* %var_2_3, align 8
; store i64 %var_2_4216, i64* %PC, align 8
%var_2_4217 = inttoptr i64 %var_2_4215 to i32*
%var_2_4218 = load i32, i32* %var_2_4217, align 4
%var_2_4219 = add i32 %var_2_4218, 1
; Matched:%var_2_2837:  %var_2_2837 = zext i32 %var_2_2836 to i64
; %var_2_4220 = zext i32 %var_2_4219 to i64
; Matched:\<badref\>:  store i64 %var_2_2837, i64* %RAX.i2224, align 8
; store i64 %var_2_4220, i64* %RAX, align 8
; Matched:%var_2_2951:  %var_2_2951 = icmp eq i32 %var_2_2948, -1
; %var_2_4221 = icmp eq i32 %var_2_4218, -1
; Matched:%var_2_2952:  %var_2_2952 = icmp eq i32 %var_2_2949, 0
; %var_2_4222 = icmp eq i32 %var_2_4219, 0
; Matched:%var_2_2953:  %var_2_2953 = or i1 %var_2_2951, %var_2_2952
; %var_2_4223 = or i1 %var_2_4221, %var_2_4222
; Matched:%var_2_2954:  %var_2_2954 = zext i1 %var_2_2953 to i8
; %var_2_4224 = zext i1 %var_2_4223 to i8
; Matched:\<badref\>:  store i8 %var_2_2954, i8* %var_2_14, align 1
; store i8 %var_2_4224, i8* %var_2_16, align 1
; Matched:%var_2_2955:  %var_2_2955 = and i32 %var_2_2949, 255
; %var_2_4225 = and i32 %var_2_4219, 255
; Matched:%var_2_2956:  %var_2_2956 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2955)
; %var_2_4226 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4225) #14
; Matched:%var_2_2957:  %var_2_2957 = trunc i32 %var_2_2956 to i8
; %var_2_4227 = trunc i32 %var_2_4226 to i8
; Matched:%var_2_2845:  %var_2_2845 = and i8 %var_2_2844, 1
; %var_2_4228 = and i8 %var_2_4227, 1
; Matched:%var_2_645:  %var_2_645 = xor i8 %var_2_644, 1
; %var_2_4229 = xor i8 %var_2_4228, 1
; Matched:\<badref\>:  store i8 %var_2_2846, i8* %var_2_21, align 1
; store i8 %var_2_4229, i8* %var_2_23, align 1
; Matched:%var_2_2960:  %var_2_2960 = xor i32 %var_2_2949, %var_2_2948
; %var_2_4230 = xor i32 %var_2_4219, %var_2_4218
; Matched:%var_2_2961:  %var_2_2961 = lshr i32 %var_2_2960, 4
; %var_2_4231 = lshr i32 %var_2_4230, 4
; Matched:%var_2_2962:  %var_2_2962 = trunc i32 %var_2_2961 to i8
; %var_2_4232 = trunc i32 %var_2_4231 to i8
; Matched:%var_2_2963:  %var_2_2963 = and i8 %var_2_2962, 1
; %var_2_4233 = and i8 %var_2_4232, 1
; Matched:\<badref\>:  store i8 %var_2_2963, i8* %var_2_27, align 1
; store i8 %var_2_4233, i8* %var_2_29, align 1
; Matched:%var_2_2964:  %var_2_2964 = zext i1 %var_2_2952 to i8
; %var_2_4234 = zext i1 %var_2_4222 to i8
; Matched:\<badref\>:  store i8 %var_2_2964, i8* %var_2_30, align 1
; store i8 %var_2_4234, i8* %var_2_32, align 1
; Matched:%var_2_4502:  %var_2_4502 = lshr i32 %var_2_4486, 31
; %var_2_4235 = lshr i32 %var_2_4219, 31
; Matched:%var_2_2966:  %var_2_2966 = trunc i32 %var_2_2965 to i8
; %var_2_4236 = trunc i32 %var_2_4235 to i8
; Matched:\<badref\>:  store i8 %var_2_2966, i8* %var_2_33, align 1
; store i8 %var_2_4236, i8* %var_2_35, align 1
; Matched:%var_2_2967:  %var_2_2967 = lshr i32 %var_2_2948, 31
; %var_2_4237 = lshr i32 %var_2_4218, 31
; Matched:%var_2_2855:  %var_2_2855 = xor i32 %var_2_2852, %var_2_2854
; %var_2_4238 = xor i32 %var_2_4235, %var_2_4237
; Matched:%var_2_655:  %var_2_655 = add nuw nsw i32 %var_2_654, %var_2_651
; %var_2_4239 = add nuw nsw i32 %var_2_4238, %var_2_4235
; Matched:%var_2_543:  %var_2_543 = icmp eq i32 %var_2_542, 2
; %var_2_4240 = icmp eq i32 %var_2_4239, 2
; Matched:%var_2_3209:  %var_2_3209 = zext i1 %var_2_3208 to i8
; %var_2_4241 = zext i1 %var_2_4240 to i8
; Matched:\<badref\>:  store i8 %var_2_544, i8* %var_2_39, align 1
; store i8 %var_2_4241, i8* %var_2_41, align 1
%var_2_4242 = sext i32 %var_2_4219 to i64
; Matched:\<badref\>:  store i64 %var_2_2859, i64* %RDX.i2239, align 8
; store i64 %var_2_4242, i64* %RDX, align 8
%var_2_4243 = shl nsw i64 %var_2_4242, 3
%var_2_4244 = add i64 %var_2_4214, %var_2_4243
; Matched:%var_2_548:  %var_2_548 = add i64 %var_2_514, 18
; %var_2_4245 = add i64 %var_2_4211, 18
; Matched:\<badref\>:  store i64 %var_2_548, i64* %var_2_3, align 8
; store i64 %var_2_4245, i64* %PC, align 8
%var_2_4246 = inttoptr i64 %var_2_4244 to i64*
%var_2_4247 = load i64, i64* %var_2_4246, align 8
store i64 %var_2_4247, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_438:  %var_2_438 = add i64 %var_2_401, 22
; %var_2_4248 = add i64 %var_2_4211, 22
; Matched:\<badref\>:  store i64 %var_2_4381, i64* %var_2_3, align 8
; store i64 %var_2_4248, i64* %PC, align 8
%var_2_4249 = load i64, i64* %var_2_4213, align 8
; Matched:\<badref\>:  store i64 %var_2_3432, i64* %RCX.i2236, align 8
; store i64 %var_2_4249, i64* %RCX, align 8
%var_2_4250 = add i64 %var_2_4209, -40
; Matched:%var_2_1633:  %var_2_1633 = add i64 %var_2_1593, 25
; %var_2_4251 = add i64 %var_2_4211, 25
; Matched:\<badref\>:  store i64 %var_2_1633, i64* %var_2_3, align 8
; store i64 %var_2_4251, i64* %PC, align 8
%var_2_4252 = inttoptr i64 %var_2_4250 to i32*
%var_2_4253 = load i32, i32* %var_2_4252, align 4
%var_2_4254 = add i32 %var_2_4253, 1
; Matched:%var_2_2020:  %var_2_2020 = zext i32 %var_2_2019 to i64
; %var_2_4255 = zext i32 %var_2_4254 to i64
; Matched:\<badref\>:  store i64 %var_2_2985, i64* %RAX.i2224, align 8
; store i64 %var_2_4255, i64* %RAX, align 8
; Matched:%var_2_2873:  %var_2_2873 = icmp eq i32 %var_2_2870, -1
; %var_2_4256 = icmp eq i32 %var_2_4253, -1
; Matched:%var_2_2874:  %var_2_2874 = icmp eq i32 %var_2_2871, 0
; %var_2_4257 = icmp eq i32 %var_2_4254, 0
; Matched:%var_2_3441:  %var_2_3441 = or i1 %var_2_3439, %var_2_3440
; %var_2_4258 = or i1 %var_2_4256, %var_2_4257
; Matched:%var_2_2024:  %var_2_2024 = zext i1 %var_2_2023 to i8
; %var_2_4259 = zext i1 %var_2_4258 to i8
; Matched:\<badref\>:  store i8 %var_2_2024, i8* %var_2_14, align 1
; store i8 %var_2_4259, i8* %var_2_16, align 1
; Matched:%var_2_2025:  %var_2_2025 = and i32 %var_2_2019, 255
; %var_2_4260 = and i32 %var_2_4254, 255
; Matched:%var_2_3444:  %var_2_3444 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3443)
; %var_2_4261 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4260) #14
; Matched:%var_2_3445:  %var_2_3445 = trunc i32 %var_2_3444 to i8
; %var_2_4262 = trunc i32 %var_2_4261 to i8
; Matched:%var_2_2880:  %var_2_2880 = and i8 %var_2_2879, 1
; %var_2_4263 = and i8 %var_2_4262, 1
; Matched:%var_2_2881:  %var_2_2881 = xor i8 %var_2_2880, 1
; %var_2_4264 = xor i8 %var_2_4263, 1
; Matched:\<badref\>:  store i8 %var_2_2029, i8* %var_2_21, align 1
; store i8 %var_2_4264, i8* %var_2_23, align 1
; Matched:%var_2_2882:  %var_2_2882 = xor i32 %var_2_2871, %var_2_2870
; %var_2_4265 = xor i32 %var_2_4254, %var_2_4253
; Matched:%var_2_2883:  %var_2_2883 = lshr i32 %var_2_2882, 4
; %var_2_4266 = lshr i32 %var_2_4265, 4
; Matched:%var_2_2997:  %var_2_2997 = trunc i32 %var_2_2996 to i8
; %var_2_4267 = trunc i32 %var_2_4266 to i8
; Matched:%var_2_2885:  %var_2_2885 = and i8 %var_2_2884, 1
; %var_2_4268 = and i8 %var_2_4267, 1
; Matched:\<badref\>:  store i8 %var_2_2885, i8* %var_2_27, align 1
; store i8 %var_2_4268, i8* %var_2_29, align 1
; Matched:%var_2_2886:  %var_2_2886 = zext i1 %var_2_2874 to i8
; %var_2_4269 = zext i1 %var_2_4257 to i8
; Matched:\<badref\>:  store i8 %var_2_2886, i8* %var_2_30, align 1
; store i8 %var_2_4269, i8* %var_2_32, align 1
; Matched:%var_2_2035:  %var_2_2035 = lshr i32 %var_2_2019, 31
; %var_2_4270 = lshr i32 %var_2_4254, 31
; Matched:%var_2_2036:  %var_2_2036 = trunc i32 %var_2_2035 to i8
; %var_2_4271 = trunc i32 %var_2_4270 to i8
; Matched:\<badref\>:  store i8 %var_2_2036, i8* %var_2_33, align 1
; store i8 %var_2_4271, i8* %var_2_35, align 1
; Matched:%var_2_2889:  %var_2_2889 = lshr i32 %var_2_2870, 31
; %var_2_4272 = lshr i32 %var_2_4253, 31
; Matched:%var_2_2890:  %var_2_2890 = xor i32 %var_2_2887, %var_2_2889
; %var_2_4273 = xor i32 %var_2_4270, %var_2_4272
; Matched:%var_2_3457:  %var_2_3457 = add nuw nsw i32 %var_2_3456, %var_2_3453
; %var_2_4274 = add nuw nsw i32 %var_2_4273, %var_2_4270
; Matched:%var_2_4757:  %var_2_4757 = icmp eq i32 %var_2_4756, 2
; %var_2_4275 = icmp eq i32 %var_2_4274, 2
; Matched:%var_2_2893:  %var_2_2893 = zext i1 %var_2_2892 to i8
; %var_2_4276 = zext i1 %var_2_4275 to i8
; Matched:\<badref\>:  store i8 %var_2_2893, i8* %var_2_39, align 1
; store i8 %var_2_4276, i8* %var_2_41, align 1
%var_2_4277 = sext i32 %var_2_4254 to i64
; Matched:\<badref\>:  store i64 %var_2_2894, i64* %RDX.i2239, align 8
; store i64 %var_2_4277, i64* %RDX, align 8
%var_2_4278 = shl nsw i64 %var_2_4277, 3
%var_2_4279 = add i64 %var_2_4249, %var_2_4278
; Matched:%var_2_4174:  %var_2_4174 = add i64 %var_2_4105, 36
; %var_2_4280 = add i64 %var_2_4211, 36
; Matched:\<badref\>:  store i64 %var_2_4174, i64* %var_2_3, align 8
; store i64 %var_2_4280, i64* %PC, align 8
%var_2_4281 = bitcast i64 %var_2_4247 to double
%var_2_4282 = inttoptr i64 %var_2_4279 to double*
%var_2_4283 = load double, double* %var_2_4282, align 8
%var_2_4284 = fsub double %var_2_4281, %var_2_4283
store double %var_2_4284, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_1667:  %var_2_1667 = load i64, i64* %RBP.i, align 8
; %var_2_4285 = load i64, i64* %RBP, align 8
; Matched:%var_2_4293:  %var_2_4293 = add i64 %var_2_4292, -176
; %var_2_4286 = add i64 %var_2_4285, -176
; Matched:%var_2_703:  %var_2_703 = add i64 %var_2_627, 44
; %var_2_4287 = add i64 %var_2_4211, 44
; Matched:\<badref\>:  store i64 %var_2_703, i64* %var_2_3, align 8
; store i64 %var_2_4287, i64* %PC, align 8
; Matched:%var_2_4295:  %var_2_4295 = inttoptr i64 %var_2_4293 to double*
; %var_2_4288 = inttoptr i64 %var_2_4286 to double*
; Matched:\<badref\>:  store double %var_2_4291, double* %var_2_4295, align 8
; store double %var_2_4284, double* %var_2_4288, align 8
%var_2_4289 = load i64, i64* %RBP, align 8
%var_2_4290 = add i64 %var_2_4289, -120
%var_2_4291 = load i64, i64* %PC, align 8
; Matched:%var_2_4583:  %var_2_4583 = add i64 %var_2_4582, 5
; %var_2_4292 = add i64 %var_2_4291, 5
; Matched:\<badref\>:  store i64 %var_2_4583, i64* %var_2_3, align 8
; store i64 %var_2_4292, i64* %PC, align 8
%var_2_4293 = inttoptr i64 %var_2_4290 to i64*
%var_2_4294 = load i64, i64* %var_2_4293, align 8
store i64 %var_2_4294, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_4295 = add i64 %var_2_4289, -152
; Matched:%var_2_3857:  %var_2_3857 = add i64 %var_2_3846, 13
; %var_2_4296 = add i64 %var_2_4291, 13
; Matched:\<badref\>:  store i64 %var_2_3857, i64* %var_2_3, align 8
; store i64 %var_2_4296, i64* %PC, align 8
%var_2_4297 = bitcast i64 %var_2_4294 to double
%var_2_4298 = inttoptr i64 %var_2_4295 to double*
%var_2_4299 = load double, double* %var_2_4298, align 8
%var_2_4300 = fadd double %var_2_4297, %var_2_4299
store double %var_2_4300, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_4301 = add i64 %var_2_4289, -16
; Matched:%var_2_718:  %var_2_718 = add i64 %var_2_707, 17
; %var_2_4302 = add i64 %var_2_4291, 17
; Matched:\<badref\>:  store i64 %var_2_718, i64* %var_2_3, align 8
; store i64 %var_2_4302, i64* %PC, align 8
%var_2_4303 = inttoptr i64 %var_2_4301 to i64*
%var_2_4304 = load i64, i64* %var_2_4303, align 8
; Matched:\<badref\>:  store i64 %var_2_2831, i64* %RCX.i2236, align 8
; store i64 %var_2_4304, i64* %RCX, align 8
%var_2_4305 = add i64 %var_2_4289, -28
; Matched:%var_2_4313:  %var_2_4313 = add i64 %var_2_4298, 21
; %var_2_4306 = add i64 %var_2_4291, 21
; Matched:\<badref\>:  store i64 %var_2_1960, i64* %var_2_3, align 8
; store i64 %var_2_4306, i64* %PC, align 8
%var_2_4307 = inttoptr i64 %var_2_4305 to i32*
%var_2_4308 = load i32, i32* %var_2_4307, align 4
%var_2_4309 = sext i32 %var_2_4308 to i64
; Matched:\<badref\>:  store i64 %var_2_3039, i64* %RDX.i2239, align 8
; store i64 %var_2_4309, i64* %RDX, align 8
; Matched:%var_2_726:  %var_2_726 = shl nsw i64 %var_2_725, 3
; %var_2_4310 = shl nsw i64 %var_2_4309, 3
; Matched:%var_2_4318:  %var_2_4318 = add i64 %var_2_4317, %var_2_4311
; %var_2_4311 = add i64 %var_2_4310, %var_2_4304
; Matched:%var_2_3042:  %var_2_3042 = add i64 %var_2_3021, 26
; %var_2_4312 = add i64 %var_2_4291, 26
; Matched:\<badref\>:  store i64 %var_2_3042, i64* %var_2_3, align 8
; store i64 %var_2_4312, i64* %PC, align 8
; Matched:%var_2_4320:  %var_2_4320 = inttoptr i64 %var_2_4318 to double*
; %var_2_4313 = inttoptr i64 %var_2_4311 to double*
; Matched:\<badref\>:  store double %var_2_4307, double* %var_2_4320, align 8
; store double %var_2_4300, double* %var_2_4313, align 8
%var_2_4314 = load i64, i64* %RBP, align 8
%var_2_4315 = add i64 %var_2_4314, -128
%var_2_4316 = load i64, i64* %PC, align 8
; Matched:%var_2_806:  %var_2_806 = add i64 %var_2_805, 5
; %var_2_4317 = add i64 %var_2_4316, 5
; Matched:\<badref\>:  store i64 %var_2_806, i64* %var_2_3, align 8
; store i64 %var_2_4317, i64* %PC, align 8
%var_2_4318 = inttoptr i64 %var_2_4315 to i64*
%var_2_4319 = load i64, i64* %var_2_4318, align 8
store i64 %var_2_4319, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_4320 = add i64 %var_2_4314, -160
; Matched:%var_2_3970:  %var_2_3970 = add i64 %var_2_3959, 13
; %var_2_4321 = add i64 %var_2_4316, 13
; Matched:\<badref\>:  store i64 %var_2_3593, i64* %var_2_3, align 8
; store i64 %var_2_4321, i64* %PC, align 8
%var_2_4322 = bitcast i64 %var_2_4319 to double
%var_2_4323 = inttoptr i64 %var_2_4320 to double*
%var_2_4324 = load double, double* %var_2_4323, align 8
%var_2_4325 = fadd double %var_2_4322, %var_2_4324
store double %var_2_4325, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_4326 = add i64 %var_2_4314, -16
; Matched:%var_2_2922:  %var_2_2922 = add i64 %var_2_2908, 17
; %var_2_4327 = add i64 %var_2_4316, 17
; Matched:\<badref\>:  store i64 %var_2_2922, i64* %var_2_3, align 8
; store i64 %var_2_4327, i64* %PC, align 8
%var_2_4328 = inttoptr i64 %var_2_4326 to i64*
%var_2_4329 = load i64, i64* %var_2_4328, align 8
; Matched:\<badref\>:  store i64 %var_2_1257, i64* %RCX.i2236, align 8
; store i64 %var_2_4329, i64* %RCX, align 8
%var_2_4330 = add i64 %var_2_4314, -28
; Matched:%var_2_3137:  %var_2_3137 = add i64 %var_2_3122, 20
; %var_2_4331 = add i64 %var_2_4316, 20
; Matched:\<badref\>:  store i64 %var_2_3137, i64* %var_2_3, align 8
; store i64 %var_2_4331, i64* %PC, align 8
%var_2_4332 = inttoptr i64 %var_2_4330 to i32*
%var_2_4333 = load i32, i32* %var_2_4332, align 4
%var_2_4334 = add i32 %var_2_4333, 1
; Matched:%var_2_2611:  %var_2_2611 = zext i32 %var_2_2610 to i64
; %var_2_4335 = zext i32 %var_2_4334 to i64
; Matched:\<badref\>:  store i64 %var_2_2611, i64* %RAX.i2224, align 8
; store i64 %var_2_4335, i64* %RAX, align 8
; Matched:%var_2_3066:  %var_2_3066 = icmp eq i32 %var_2_3063, -1
; %var_2_4336 = icmp eq i32 %var_2_4333, -1
; Matched:%var_2_2613:  %var_2_2613 = icmp eq i32 %var_2_2610, 0
; %var_2_4337 = icmp eq i32 %var_2_4334, 0
; Matched:%var_2_413:  %var_2_413 = or i1 %var_2_411, %var_2_412
; %var_2_4338 = or i1 %var_2_4336, %var_2_4337
; Matched:%var_2_414:  %var_2_414 = zext i1 %var_2_413 to i8
; %var_2_4339 = zext i1 %var_2_4338 to i8
; Matched:\<badref\>:  store i8 %var_2_414, i8* %var_2_14, align 1
; store i8 %var_2_4339, i8* %var_2_16, align 1
; Matched:%var_2_1722:  %var_2_1722 = and i32 %var_2_1716, 255
; %var_2_4340 = and i32 %var_2_4334, 255
; Matched:%var_2_303:  %var_2_303 = tail call i32 @llvm.ctpop.i32(i32 %var_2_302)
; %var_2_4341 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4340) #14
; Matched:%var_2_304:  %var_2_304 = trunc i32 %var_2_303 to i8
; %var_2_4342 = trunc i32 %var_2_4341 to i8
; Matched:%var_2_418:  %var_2_418 = and i8 %var_2_417, 1
; %var_2_4343 = and i8 %var_2_4342, 1
; Matched:%var_2_3074:  %var_2_3074 = xor i8 %var_2_3073, 1
; %var_2_4344 = xor i8 %var_2_4343, 1
; Matched:\<badref\>:  store i8 %var_2_2620, i8* %var_2_21, align 1
; store i8 %var_2_4344, i8* %var_2_23, align 1
; Matched:%var_2_3075:  %var_2_3075 = xor i32 %var_2_3064, %var_2_3063
; %var_2_4345 = xor i32 %var_2_4334, %var_2_4333
; Matched:%var_2_3076:  %var_2_3076 = lshr i32 %var_2_3075, 4
; %var_2_4346 = lshr i32 %var_2_4345, 4
; Matched:%var_2_763:  %var_2_763 = trunc i32 %var_2_762 to i8
; %var_2_4347 = trunc i32 %var_2_4346 to i8
; Matched:%var_2_1389:  %var_2_1389 = and i8 %var_2_1388, 1
; %var_2_4348 = and i8 %var_2_4347, 1
; Matched:\<badref\>:  store i8 %var_2_1389, i8* %var_2_27, align 1
; store i8 %var_2_4348, i8* %var_2_29, align 1
; Matched:%var_2_1277:  %var_2_1277 = zext i1 %var_2_1265 to i8
; %var_2_4349 = zext i1 %var_2_4337 to i8
; Matched:\<badref\>:  store i8 %var_2_4015, i8* %var_2_30, align 1
; store i8 %var_2_4349, i8* %var_2_32, align 1
; Matched:%var_2_4016:  %var_2_4016 = lshr i32 %var_2_4000, 31
; %var_2_4350 = lshr i32 %var_2_4334, 31
; Matched:%var_2_3904:  %var_2_3904 = trunc i32 %var_2_3903 to i8
; %var_2_4351 = trunc i32 %var_2_4350 to i8
; Matched:\<badref\>:  store i8 %var_2_767, i8* %var_2_33, align 1
; store i8 %var_2_4351, i8* %var_2_35, align 1
; Matched:%var_2_768:  %var_2_768 = lshr i32 %var_2_749, 31
; %var_2_4352 = lshr i32 %var_2_4333, 31
; Matched:%var_2_769:  %var_2_769 = xor i32 %var_2_766, %var_2_768
; %var_2_4353 = xor i32 %var_2_4350, %var_2_4352
; Matched:%var_2_316:  %var_2_316 = add nuw nsw i32 %var_2_315, %var_2_312
; %var_2_4354 = add nuw nsw i32 %var_2_4353, %var_2_4350
; Matched:%var_2_771:  %var_2_771 = icmp eq i32 %var_2_770, 2
; %var_2_4355 = icmp eq i32 %var_2_4354, 2
; Matched:%var_2_772:  %var_2_772 = zext i1 %var_2_771 to i8
; %var_2_4356 = zext i1 %var_2_4355 to i8
; Matched:\<badref\>:  store i8 %var_2_772, i8* %var_2_39, align 1
; store i8 %var_2_4356, i8* %var_2_41, align 1
%var_2_4357 = sext i32 %var_2_4334 to i64
; Matched:\<badref\>:  store i64 %var_2_2633, i64* %RDX.i2239, align 8
; store i64 %var_2_4357, i64* %RDX, align 8
; Matched:%var_2_4365:  %var_2_4365 = shl nsw i64 %var_2_4364, 3
; %var_2_4358 = shl nsw i64 %var_2_4357, 3
; Matched:%var_2_4366:  %var_2_4366 = add i64 %var_2_4336, %var_2_4365
; %var_2_4359 = add i64 %var_2_4329, %var_2_4358
; Matched:%var_2_3875:  %var_2_3875 = add i64 %var_2_3846, 31
; %var_2_4360 = add i64 %var_2_4316, 31
; Matched:\<badref\>:  store i64 %var_2_3434, i64* %var_2_3, align 8
; store i64 %var_2_4360, i64* %PC, align 8
; Matched:%var_2_777:  %var_2_777 = inttoptr i64 %var_2_775 to double*
; %var_2_4361 = inttoptr i64 %var_2_4359 to double*
; Matched:\<badref\>:  store double %var_2_4332, double* %var_2_4368, align 8
; store double %var_2_4325, double* %var_2_4361, align 8
; Matched:%var_2_3092:  %var_2_3092 = load i64, i64* %RBP.i, align 8
; %var_2_4362 = load i64, i64* %RBP, align 8
; Matched:%var_2_4370:  %var_2_4370 = add i64 %var_2_4369, -152
; %var_2_4363 = add i64 %var_2_4362, -152
%var_2_4364 = load i64, i64* %PC, align 8
%var_2_4365 = add i64 %var_2_4364, 8
store i64 %var_2_4365, i64* %PC, align 8
; Matched:%var_2_4373:  %var_2_4373 = inttoptr i64 %var_2_4370 to i64*
; %var_2_4366 = inttoptr i64 %var_2_4363 to i64*
; Matched:%var_2_4374:  %var_2_4374 = load i64, i64* %var_2_4373, align 8
; %var_2_4367 = load i64, i64* %var_2_4366, align 8
; Matched:\<badref\>:  store i64 %var_2_4374, i64* %var_2_1038, align 1
; store i64 %var_2_4367, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_4375:  %var_2_4375 = add i64 %var_2_4369, -120
; %var_2_4368 = add i64 %var_2_4362, -120
; Matched:%var_2_1678:  %var_2_1678 = add i64 %var_2_1673, 13
; %var_2_4369 = add i64 %var_2_4364, 13
; Matched:\<badref\>:  store i64 %var_2_1678, i64* %var_2_3, align 8
; store i64 %var_2_4369, i64* %PC, align 8
; Matched:%var_2_3100:  %var_2_3100 = inttoptr i64 %var_2_3098 to double*
; %var_2_4370 = inttoptr i64 %var_2_4368 to double*
; Matched:%var_2_4378:  %var_2_4378 = load double, double* %var_2_4377, align 8
; %var_2_4371 = load double, double* %var_2_4370, align 8
; Matched:%var_2_4379:  %var_2_4379 = bitcast i64 %var_2_4374 to double
; %var_2_4372 = bitcast i64 %var_2_4367 to double
; Matched:%var_2_4380:  %var_2_4380 = fsub double %var_2_4378, %var_2_4379
; %var_2_4373 = fsub double %var_2_4371, %var_2_4372
; Matched:\<badref\>:  store double %var_2_3103, double* %var_2_1053, align 1
; store double %var_2_4373, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_3916:  %var_2_3916 = add i64 %var_2_3879, 22
; %var_2_4374 = add i64 %var_2_4364, 22
; Matched:\<badref\>:  store i64 %var_2_3916, i64* %var_2_3, align 8
; store i64 %var_2_4374, i64* %PC, align 8
; Matched:%var_2_3105:  %var_2_3105 = inttoptr i64 %var_2_3098 to double*
; %var_2_4375 = inttoptr i64 %var_2_4368 to double*
; Matched:\<badref\>:  store double %var_2_4380, double* %var_2_4382, align 8
; store double %var_2_4373, double* %var_2_4375, align 8
%var_2_4376 = load i64, i64* %RBP, align 8
%var_2_4377 = add i64 %var_2_4376, -160
%var_2_4378 = load i64, i64* %PC, align 8
%var_2_4379 = add i64 %var_2_4378, 8
store i64 %var_2_4379, i64* %PC, align 8
%var_2_4380 = inttoptr i64 %var_2_4377 to i64*
%var_2_4381 = load i64, i64* %var_2_4380, align 8
; Matched:\<badref\>:  store i64 %var_2_4388, i64* %var_2_1038, align 1
; store i64 %var_2_4381, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_4389:  %var_2_4389 = add i64 %var_2_4383, -128
; %var_2_4382 = add i64 %var_2_4376, -128
; Matched:%var_2_3051:  %var_2_3051 = add i64 %var_2_3046, 13
; %var_2_4383 = add i64 %var_2_4378, 13
; Matched:\<badref\>:  store i64 %var_2_3051, i64* %var_2_3, align 8
; store i64 %var_2_4383, i64* %PC, align 8
; Matched:%var_2_4391:  %var_2_4391 = inttoptr i64 %var_2_4389 to double*
; %var_2_4384 = inttoptr i64 %var_2_4382 to double*
; Matched:%var_2_4392:  %var_2_4392 = load double, double* %var_2_4391, align 8
; %var_2_4385 = load double, double* %var_2_4384, align 8
; Matched:%var_2_3116:  %var_2_3116 = bitcast i64 %var_2_3111 to double
; %var_2_4386 = bitcast i64 %var_2_4381 to double
; Matched:%var_2_4394:  %var_2_4394 = fsub double %var_2_4392, %var_2_4393
; %var_2_4387 = fsub double %var_2_4385, %var_2_4386
; Matched:\<badref\>:  store double %var_2_4394, double* %var_2_1053, align 1
; store double %var_2_4387, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_551:  %var_2_551 = add i64 %var_2_514, 22
; %var_2_4388 = add i64 %var_2_4378, 22
; Matched:\<badref\>:  store i64 %var_2_325, i64* %var_2_3, align 8
; store i64 %var_2_4388, i64* %PC, align 8
; Matched:%var_2_4396:  %var_2_4396 = inttoptr i64 %var_2_4389 to double*
; %var_2_4389 = inttoptr i64 %var_2_4382 to double*
; Matched:\<badref\>:  store double %var_2_4394, double* %var_2_4396, align 8
; store double %var_2_4387, double* %var_2_4389, align 8
%var_2_4390 = load i64, i64* %RBP, align 8
; Matched:%var_2_3121:  %var_2_3121 = add i64 %var_2_3120, -88
; %var_2_4391 = add i64 %var_2_4390, -88
%var_2_4392 = load i64, i64* %PC, align 8
; Matched:%var_2_3248:  %var_2_3248 = add i64 %var_2_3247, 5
; %var_2_4393 = add i64 %var_2_4392, 5
; Matched:\<badref\>:  store i64 %var_2_3248, i64* %var_2_3, align 8
; store i64 %var_2_4393, i64* %PC, align 8
; Matched:%var_2_3160:  %var_2_3160 = inttoptr i64 %var_2_3157 to i64*
; %var_2_4394 = inttoptr i64 %var_2_4391 to i64*
; Matched:%var_2_3161:  %var_2_3161 = load i64, i64* %var_2_3160, align 8
; %var_2_4395 = load i64, i64* %var_2_4394, align 8
; Matched:\<badref\>:  store i64 %var_2_3161, i64* %var_2_1038, align 1
; store i64 %var_2_4395, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_3126:  %var_2_3126 = add i64 %var_2_3120, -120
; %var_2_4396 = add i64 %var_2_4390, -120
; Matched:%var_2_3288:  %var_2_3288 = add i64 %var_2_3283, 10
; %var_2_4397 = add i64 %var_2_4392, 10
; Matched:\<badref\>:  store i64 %var_2_4587, i64* %var_2_3, align 8
; store i64 %var_2_4397, i64* %PC, align 8
; Matched:%var_2_3128:  %var_2_3128 = bitcast i64 %var_2_3125 to double
; %var_2_4398 = bitcast i64 %var_2_4395 to double
; Matched:%var_2_3129:  %var_2_3129 = inttoptr i64 %var_2_3126 to double*
; %var_2_4399 = inttoptr i64 %var_2_4396 to double*
; Matched:%var_2_3130:  %var_2_3130 = load double, double* %var_2_3129, align 8
; %var_2_4400 = load double, double* %var_2_4399, align 8
; Matched:%var_2_3131:  %var_2_3131 = fmul double %var_2_3128, %var_2_3130
; %var_2_4401 = fmul double %var_2_4398, %var_2_4400
; Matched:\<badref\>:  store double %var_2_3131, double* %var_2_1037, align 1
; store double %var_2_4401, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_3132:  %var_2_3132 = add i64 %var_2_3120, -96
; %var_2_4402 = add i64 %var_2_4390, -96
; Matched:%var_2_4682:  %var_2_4682 = add i64 %var_2_4671, 15
; %var_2_4403 = add i64 %var_2_4392, 15
; Matched:\<badref\>:  store i64 %var_2_4682, i64* %var_2_3, align 8
; store i64 %var_2_4403, i64* %PC, align 8
; Matched:%var_2_3134:  %var_2_3134 = inttoptr i64 %var_2_3132 to i64*
; %var_2_4404 = inttoptr i64 %var_2_4402 to i64*
; Matched:%var_2_3135:  %var_2_3135 = load i64, i64* %var_2_3134, align 8
; %var_2_4405 = load i64, i64* %var_2_4404, align 8
; Matched:\<badref\>:  store i64 %var_2_3135, i64* %var_2_1054, align 1
; store i64 %var_2_4405, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_3136:  %var_2_3136 = add i64 %var_2_3120, -128
; %var_2_4406 = add i64 %var_2_4390, -128
; Matched:%var_2_4561:  %var_2_4561 = add i64 %var_2_4546, 20
; %var_2_4407 = add i64 %var_2_4392, 20
; Matched:\<badref\>:  store i64 %var_2_4561, i64* %var_2_3, align 8
; store i64 %var_2_4407, i64* %PC, align 8
; Matched:%var_2_3138:  %var_2_3138 = bitcast i64 %var_2_3135 to double
; %var_2_4408 = bitcast i64 %var_2_4405 to double
; Matched:%var_2_3139:  %var_2_3139 = inttoptr i64 %var_2_3136 to double*
; %var_2_4409 = inttoptr i64 %var_2_4406 to double*
; Matched:%var_2_3140:  %var_2_3140 = load double, double* %var_2_3139, align 8
; %var_2_4410 = load double, double* %var_2_4409, align 8
; Matched:%var_2_3141:  %var_2_3141 = fmul double %var_2_3138, %var_2_3140
; %var_2_4411 = fmul double %var_2_4408, %var_2_4410
; Matched:\<badref\>:  store double %var_2_3141, double* %var_2_1053, align 1
; store double %var_2_4411, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_3142:  %var_2_3142 = fsub double %var_2_3131, %var_2_3141
; %var_2_4412 = fsub double %var_2_4401, %var_2_4411
; Matched:\<badref\>:  store double %var_2_3142, double* %var_2_1037, align 1
; store double %var_2_4412, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_4413 = add i64 %var_2_4390, -16
; Matched:%var_2_4468:  %var_2_4468 = add i64 %var_2_4446, 28
; %var_2_4414 = add i64 %var_2_4392, 28
; Matched:\<badref\>:  store i64 %var_2_4468, i64* %var_2_3, align 8
; store i64 %var_2_4414, i64* %PC, align 8
%var_2_4415 = inttoptr i64 %var_2_4413 to i64*
%var_2_4416 = load i64, i64* %var_2_4415, align 8
; Matched:\<badref\>:  store i64 %var_2_2718, i64* %RCX.i2236, align 8
; store i64 %var_2_4416, i64* %RCX, align 8
%var_2_4417 = add i64 %var_2_4390, -36
; Matched:%var_2_3398:  %var_2_3398 = add i64 %var_2_3372, 32
; %var_2_4418 = add i64 %var_2_4392, 32
; Matched:\<badref\>:  store i64 %var_2_1876, i64* %var_2_3, align 8
; store i64 %var_2_4418, i64* %PC, align 8
%var_2_4419 = inttoptr i64 %var_2_4417 to i32*
%var_2_4420 = load i32, i32* %var_2_4419, align 4
%var_2_4421 = sext i32 %var_2_4420 to i64
; Matched:\<badref\>:  store i64 %var_2_3151, i64* %RDX.i2239, align 8
; store i64 %var_2_4421, i64* %RDX, align 8
; Matched:%var_2_3152:  %var_2_3152 = shl nsw i64 %var_2_3151, 3
; %var_2_4422 = shl nsw i64 %var_2_4421, 3
; Matched:%var_2_3153:  %var_2_3153 = add i64 %var_2_3152, %var_2_3146
; %var_2_4423 = add i64 %var_2_4422, %var_2_4416
; Matched:%var_2_1930:  %var_2_1930 = add i64 %var_2_1880, 37
; %var_2_4424 = add i64 %var_2_4392, 37
; Matched:\<badref\>:  store i64 %var_2_1930, i64* %var_2_3, align 8
; store i64 %var_2_4424, i64* %PC, align 8
; Matched:%var_2_3155:  %var_2_3155 = inttoptr i64 %var_2_3153 to double*
; %var_2_4425 = inttoptr i64 %var_2_4423 to double*
; Matched:\<badref\>:  store double %var_2_3142, double* %var_2_3155, align 8
; store double %var_2_4412, double* %var_2_4425, align 8
%var_2_4426 = load i64, i64* %RBP, align 8
; Matched:%var_2_3157:  %var_2_3157 = add i64 %var_2_3156, -88
; %var_2_4427 = add i64 %var_2_4426, -88
%var_2_4428 = load i64, i64* %PC, align 8
; Matched:%var_2_733:  %var_2_733 = add i64 %var_2_732, 5
; %var_2_4429 = add i64 %var_2_4428, 5
; Matched:\<badref\>:  store i64 %var_2_733, i64* %var_2_3, align 8
; store i64 %var_2_4429, i64* %PC, align 8
; Matched:%var_2_3124:  %var_2_3124 = inttoptr i64 %var_2_3121 to i64*
; %var_2_4430 = inttoptr i64 %var_2_4427 to i64*
; Matched:%var_2_3125:  %var_2_3125 = load i64, i64* %var_2_3124, align 8
; %var_2_4431 = load i64, i64* %var_2_4430, align 8
; Matched:\<badref\>:  store i64 %var_2_3125, i64* %var_2_1038, align 1
; store i64 %var_2_4431, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_3162:  %var_2_3162 = add i64 %var_2_3156, -128
; %var_2_4432 = add i64 %var_2_4426, -128
; Matched:%var_2_3617:  %var_2_3617 = add i64 %var_2_3610, 10
; %var_2_4433 = add i64 %var_2_4428, 10
; Matched:\<badref\>:  store i64 %var_2_2000, i64* %var_2_3, align 8
; store i64 %var_2_4433, i64* %PC, align 8
; Matched:%var_2_3164:  %var_2_3164 = bitcast i64 %var_2_3161 to double
; %var_2_4434 = bitcast i64 %var_2_4431 to double
; Matched:%var_2_3165:  %var_2_3165 = inttoptr i64 %var_2_3162 to double*
; %var_2_4435 = inttoptr i64 %var_2_4432 to double*
; Matched:%var_2_3166:  %var_2_3166 = load double, double* %var_2_3165, align 8
; %var_2_4436 = load double, double* %var_2_4435, align 8
; Matched:%var_2_3167:  %var_2_3167 = fmul double %var_2_3164, %var_2_3166
; %var_2_4437 = fmul double %var_2_4434, %var_2_4436
; Matched:\<badref\>:  store double %var_2_3167, double* %var_2_1037, align 1
; store double %var_2_4437, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_3168:  %var_2_3168 = add i64 %var_2_3156, -96
; %var_2_4438 = add i64 %var_2_4426, -96
; Matched:%var_2_3419:  %var_2_3419 = add i64 %var_2_3408, 15
; %var_2_4439 = add i64 %var_2_4428, 15
; Matched:\<badref\>:  store i64 %var_2_3419, i64* %var_2_3, align 8
; store i64 %var_2_4439, i64* %PC, align 8
; Matched:%var_2_3170:  %var_2_3170 = inttoptr i64 %var_2_3168 to i64*
; %var_2_4440 = inttoptr i64 %var_2_4438 to i64*
; Matched:%var_2_3171:  %var_2_3171 = load i64, i64* %var_2_3170, align 8
; %var_2_4441 = load i64, i64* %var_2_4440, align 8
; Matched:\<badref\>:  store i64 %var_2_3171, i64* %var_2_1054, align 1
; store i64 %var_2_4441, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_3172:  %var_2_3172 = add i64 %var_2_3156, -120
; %var_2_4442 = add i64 %var_2_4426, -120
; Matched:%var_2_747:  %var_2_747 = add i64 %var_2_732, 20
; %var_2_4443 = add i64 %var_2_4428, 20
; Matched:\<badref\>:  store i64 %var_2_747, i64* %var_2_3, align 8
; store i64 %var_2_4443, i64* %PC, align 8
; Matched:%var_2_3174:  %var_2_3174 = bitcast i64 %var_2_3171 to double
; %var_2_4444 = bitcast i64 %var_2_4441 to double
; Matched:%var_2_3175:  %var_2_3175 = inttoptr i64 %var_2_3172 to double*
; %var_2_4445 = inttoptr i64 %var_2_4442 to double*
; Matched:%var_2_3176:  %var_2_3176 = load double, double* %var_2_3175, align 8
; %var_2_4446 = load double, double* %var_2_4445, align 8
; Matched:%var_2_3177:  %var_2_3177 = fmul double %var_2_3174, %var_2_3176
; %var_2_4447 = fmul double %var_2_4444, %var_2_4446
; Matched:\<badref\>:  store double %var_2_3177, double* %var_2_1053, align 1
; store double %var_2_4447, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_3178:  %var_2_3178 = fadd double %var_2_3167, %var_2_3177
; %var_2_4448 = fadd double %var_2_4437, %var_2_4447
; Matched:\<badref\>:  store double %var_2_3178, double* %var_2_1037, align 1
; store double %var_2_4448, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_4449 = add i64 %var_2_4426, -16
; Matched:%var_2_3180:  %var_2_3180 = add i64 %var_2_3158, 28
; %var_2_4450 = add i64 %var_2_4428, 28
; Matched:\<badref\>:  store i64 %var_2_4693, i64* %var_2_3, align 8
; store i64 %var_2_4450, i64* %PC, align 8
%var_2_4451 = inttoptr i64 %var_2_4449 to i64*
%var_2_4452 = load i64, i64* %var_2_4451, align 8
; Matched:\<badref\>:  store i64 %var_2_2605, i64* %RCX.i2236, align 8
; store i64 %var_2_4452, i64* %RCX, align 8
%var_2_4453 = add i64 %var_2_4426, -36
; Matched:%var_2_1815:  %var_2_1815 = add i64 %var_2_1771, 31
; %var_2_4454 = add i64 %var_2_4428, 31
; Matched:\<badref\>:  store i64 %var_2_1815, i64* %var_2_3, align 8
; store i64 %var_2_4454, i64* %PC, align 8
%var_2_4455 = inttoptr i64 %var_2_4453 to i32*
%var_2_4456 = load i32, i32* %var_2_4455, align 4
%var_2_4457 = add i32 %var_2_4456, 1
; Matched:%var_2_2950:  %var_2_2950 = zext i32 %var_2_2949 to i64
; %var_2_4458 = zext i32 %var_2_4457 to i64
; Matched:\<badref\>:  store i64 %var_2_2950, i64* %RAX.i2224, align 8
; store i64 %var_2_4458, i64* %RAX, align 8
; Matched:%var_2_4115:  %var_2_4115 = icmp eq i32 %var_2_4112, -1
; %var_2_4459 = icmp eq i32 %var_2_4456, -1
; Matched:%var_2_4116:  %var_2_4116 = icmp eq i32 %var_2_4113, 0
; %var_2_4460 = icmp eq i32 %var_2_4457, 0
; Matched:%var_2_4117:  %var_2_4117 = or i1 %var_2_4115, %var_2_4116
; %var_2_4461 = or i1 %var_2_4459, %var_2_4460
; Matched:%var_2_4118:  %var_2_4118 = zext i1 %var_2_4117 to i8
; %var_2_4462 = zext i1 %var_2_4461 to i8
; Matched:\<badref\>:  store i8 %var_2_3192, i8* %var_2_14, align 1
; store i8 %var_2_4462, i8* %var_2_16, align 1
; Matched:%var_2_4119:  %var_2_4119 = and i32 %var_2_4113, 255
; %var_2_4463 = and i32 %var_2_4457, 255
; Matched:%var_2_3194:  %var_2_3194 = tail call i32 @llvm.ctpop.i32(i32 %var_2_3193)
; %var_2_4464 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4463) #14
; Matched:%var_2_3195:  %var_2_3195 = trunc i32 %var_2_3194 to i8
; %var_2_4465 = trunc i32 %var_2_4464 to i8
; Matched:%var_2_4495:  %var_2_4495 = and i8 %var_2_4494, 1
; %var_2_4466 = and i8 %var_2_4465, 1
; Matched:%var_2_2959:  %var_2_2959 = xor i8 %var_2_2958, 1
; %var_2_4467 = xor i8 %var_2_4466, 1
; Matched:\<badref\>:  store i8 %var_2_4496, i8* %var_2_21, align 1
; store i8 %var_2_4467, i8* %var_2_23, align 1
; Matched:%var_2_4124:  %var_2_4124 = xor i32 %var_2_4113, %var_2_4112
; %var_2_4468 = xor i32 %var_2_4457, %var_2_4456
; Matched:%var_2_3199:  %var_2_3199 = lshr i32 %var_2_3198, 4
; %var_2_4469 = lshr i32 %var_2_4468, 4
; Matched:%var_2_3200:  %var_2_3200 = trunc i32 %var_2_3199 to i8
; %var_2_4470 = trunc i32 %var_2_4469 to i8
; Matched:%var_2_3201:  %var_2_3201 = and i8 %var_2_3200, 1
; %var_2_4471 = and i8 %var_2_4470, 1
; Matched:\<badref\>:  store i8 %var_2_3201, i8* %var_2_27, align 1
; store i8 %var_2_4471, i8* %var_2_29, align 1
; Matched:%var_2_4128:  %var_2_4128 = zext i1 %var_2_4116 to i8
; %var_2_4472 = zext i1 %var_2_4460 to i8
; Matched:\<badref\>:  store i8 %var_2_1616, i8* %var_2_30, align 1
; store i8 %var_2_4472, i8* %var_2_32, align 1
; Matched:%var_2_2852:  %var_2_2852 = lshr i32 %var_2_2836, 31
; %var_2_4473 = lshr i32 %var_2_4457, 31
; Matched:%var_2_1618:  %var_2_1618 = trunc i32 %var_2_1617 to i8
; %var_2_4474 = trunc i32 %var_2_4473 to i8
; Matched:\<badref\>:  store i8 %var_2_539, i8* %var_2_33, align 1
; store i8 %var_2_4474, i8* %var_2_35, align 1
; Matched:%var_2_1506:  %var_2_1506 = lshr i32 %var_2_1487, 31
; %var_2_4475 = lshr i32 %var_2_4456, 31
; Matched:%var_2_1808:  %var_2_1808 = xor i32 %var_2_1805, %var_2_1807
; %var_2_4476 = xor i32 %var_2_4473, %var_2_4475
; Matched:%var_2_4246:  %var_2_4246 = add nuw nsw i32 %var_2_4245, %var_2_4242
; %var_2_4477 = add nuw nsw i32 %var_2_4476, %var_2_4473
; Matched:%var_2_4134:  %var_2_4134 = icmp eq i32 %var_2_4133, 2
; %var_2_4478 = icmp eq i32 %var_2_4477, 2
; Matched:%var_2_544:  %var_2_544 = zext i1 %var_2_543 to i8
; %var_2_4479 = zext i1 %var_2_4478 to i8
; Matched:\<badref\>:  store i8 %var_2_2858, i8* %var_2_39, align 1
; store i8 %var_2_4479, i8* %var_2_41, align 1
%var_2_4480 = sext i32 %var_2_4457 to i64
; Matched:\<badref\>:  store i64 %var_2_4509, i64* %RDX.i2239, align 8
; store i64 %var_2_4480, i64* %RDX, align 8
; Matched:%var_2_3211:  %var_2_3211 = shl nsw i64 %var_2_3210, 3
; %var_2_4481 = shl nsw i64 %var_2_4480, 3
; Matched:%var_2_3212:  %var_2_3212 = add i64 %var_2_3182, %var_2_3211
; %var_2_4482 = add i64 %var_2_4452, %var_2_4481
; Matched:%var_2_3463:  %var_2_3463 = add i64 %var_2_3408, 42
; %var_2_4483 = add i64 %var_2_4428, 42
; Matched:\<badref\>:  store i64 %var_2_4762, i64* %var_2_3, align 8
; store i64 %var_2_4483, i64* %PC, align 8
; Matched:%var_2_3214:  %var_2_3214 = inttoptr i64 %var_2_3212 to double*
; %var_2_4484 = inttoptr i64 %var_2_4482 to double*
; Matched:\<badref\>:  store double %var_2_3178, double* %var_2_3214, align 8
; store double %var_2_4448, double* %var_2_4484, align 8
%var_2_4485 = load i64, i64* %RBP, align 8
%var_2_4486 = add i64 %var_2_4485, -136
%var_2_4487 = load i64, i64* %PC, align 8
%var_2_4488 = add i64 %var_2_4487, 8
store i64 %var_2_4488, i64* %PC, align 8
%var_2_4489 = inttoptr i64 %var_2_4486 to i64*
%var_2_4490 = load i64, i64* %var_2_4489, align 8
store i64 %var_2_4490, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_4491 = add i64 %var_2_4485, -176
; Matched:%var_2_1954:  %var_2_1954 = add i64 %var_2_1949, 16
; %var_2_4492 = add i64 %var_2_4487, 16
; Matched:\<badref\>:  store i64 %var_2_1954, i64* %var_2_3, align 8
; store i64 %var_2_4492, i64* %PC, align 8
%var_2_4493 = bitcast i64 %var_2_4490 to double
%var_2_4494 = inttoptr i64 %var_2_4491 to double*
%var_2_4495 = load double, double* %var_2_4494, align 8
%var_2_4496 = fsub double %var_2_4493, %var_2_4495
store double %var_2_4496, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_3227:  %var_2_3227 = add i64 %var_2_3215, -120
; %var_2_4497 = add i64 %var_2_4485, -120
; Matched:%var_2_1351:  %var_2_1351 = add i64 %var_2_1334, 21
; %var_2_4498 = add i64 %var_2_4487, 21
; Matched:\<badref\>:  store i64 %var_2_1351, i64* %var_2_3, align 8
; store i64 %var_2_4498, i64* %PC, align 8
; Matched:%var_2_4528:  %var_2_4528 = inttoptr i64 %var_2_4526 to double*
; %var_2_4499 = inttoptr i64 %var_2_4497 to double*
; Matched:\<badref\>:  store double %var_2_4525, double* %var_2_4528, align 8
; store double %var_2_4496, double* %var_2_4499, align 8
%var_2_4500 = load i64, i64* %RBP, align 8
%var_2_4501 = add i64 %var_2_4500, -144
%var_2_4502 = load i64, i64* %PC, align 8
%var_2_4503 = add i64 %var_2_4502, 8
store i64 %var_2_4503, i64* %PC, align 8
%var_2_4504 = inttoptr i64 %var_2_4501 to i64*
%var_2_4505 = load i64, i64* %var_2_4504, align 8
store i64 %var_2_4505, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_4506 = add i64 %var_2_4500, -168
; Matched:%var_2_4536:  %var_2_4536 = add i64 %var_2_4531, 16
; %var_2_4507 = add i64 %var_2_4502, 16
; Matched:\<badref\>:  store i64 %var_2_4536, i64* %var_2_3, align 8
; store i64 %var_2_4507, i64* %PC, align 8
%var_2_4508 = bitcast i64 %var_2_4505 to double
%var_2_4509 = inttoptr i64 %var_2_4506 to double*
%var_2_4510 = load double, double* %var_2_4509, align 8
%var_2_4511 = fadd double %var_2_4508, %var_2_4510
store double %var_2_4511, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_4541:  %var_2_4541 = add i64 %var_2_4529, -128
; %var_2_4512 = add i64 %var_2_4500, -128
; Matched:%var_2_1830:  %var_2_1830 = add i64 %var_2_1819, 21
; %var_2_4513 = add i64 %var_2_4502, 21
; Matched:\<badref\>:  store i64 %var_2_1830, i64* %var_2_3, align 8
; store i64 %var_2_4513, i64* %PC, align 8
; Matched:%var_2_4543:  %var_2_4543 = inttoptr i64 %var_2_4541 to double*
; %var_2_4514 = inttoptr i64 %var_2_4512 to double*
; Matched:\<badref\>:  store double %var_2_4540, double* %var_2_4543, align 8
; store double %var_2_4511, double* %var_2_4514, align 8
%var_2_4515 = load i64, i64* %RBP, align 8
%var_2_4516 = add i64 %var_2_4515, -72
%var_2_4517 = load i64, i64* %PC, align 8
; Matched:%var_2_3373:  %var_2_3373 = add i64 %var_2_3372, 5
; %var_2_4518 = add i64 %var_2_4517, 5
; Matched:\<badref\>:  store i64 %var_2_1850, i64* %var_2_3, align 8
; store i64 %var_2_4518, i64* %PC, align 8
%var_2_4519 = inttoptr i64 %var_2_4516 to i64*
%var_2_4520 = load i64, i64* %var_2_4519, align 8
; Matched:\<badref\>:  store i64 %var_2_3250, i64* %var_2_1038, align 1
; store i64 %var_2_4520, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_3251:  %var_2_3251 = add i64 %var_2_3245, -120
; %var_2_4521 = add i64 %var_2_4515, -120
; Matched:%var_2_1885:  %var_2_1885 = add i64 %var_2_1880, 10
; %var_2_4522 = add i64 %var_2_4517, 10
; Matched:\<badref\>:  store i64 %var_2_2383, i64* %var_2_3, align 8
; store i64 %var_2_4522, i64* %PC, align 8
; Matched:%var_2_3253:  %var_2_3253 = bitcast i64 %var_2_3250 to double
; %var_2_4523 = bitcast i64 %var_2_4520 to double
; Matched:%var_2_3254:  %var_2_3254 = inttoptr i64 %var_2_3251 to double*
; %var_2_4524 = inttoptr i64 %var_2_4521 to double*
; Matched:%var_2_3255:  %var_2_3255 = load double, double* %var_2_3254, align 8
; %var_2_4525 = load double, double* %var_2_4524, align 8
; Matched:%var_2_4555:  %var_2_4555 = fmul double %var_2_4552, %var_2_4554
; %var_2_4526 = fmul double %var_2_4523, %var_2_4525
; Matched:\<badref\>:  store double %var_2_4555, double* %var_2_1037, align 1
; store double %var_2_4526, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_4527 = add i64 %var_2_4515, -80
; Matched:%var_2_1858:  %var_2_1858 = add i64 %var_2_1849, 15
; %var_2_4528 = add i64 %var_2_4517, 15
; Matched:\<badref\>:  store i64 %var_2_1858, i64* %var_2_3, align 8
; store i64 %var_2_4528, i64* %PC, align 8
%var_2_4529 = inttoptr i64 %var_2_4527 to i64*
%var_2_4530 = load i64, i64* %var_2_4529, align 8
; Matched:\<badref\>:  store i64 %var_2_3260, i64* %var_2_1054, align 1
; store i64 %var_2_4530, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_3261:  %var_2_3261 = add i64 %var_2_3245, -128
; %var_2_4531 = add i64 %var_2_4515, -128
; Matched:%var_2_1713:  %var_2_1713 = add i64 %var_2_1698, 20
; %var_2_4532 = add i64 %var_2_4517, 20
; Matched:\<badref\>:  store i64 %var_2_1713, i64* %var_2_3, align 8
; store i64 %var_2_4532, i64* %PC, align 8
; Matched:%var_2_3263:  %var_2_3263 = bitcast i64 %var_2_3260 to double
; %var_2_4533 = bitcast i64 %var_2_4530 to double
; Matched:%var_2_3264:  %var_2_3264 = inttoptr i64 %var_2_3261 to double*
; %var_2_4534 = inttoptr i64 %var_2_4531 to double*
; Matched:%var_2_3265:  %var_2_3265 = load double, double* %var_2_3264, align 8
; %var_2_4535 = load double, double* %var_2_4534, align 8
; Matched:%var_2_4565:  %var_2_4565 = fmul double %var_2_4562, %var_2_4564
; %var_2_4536 = fmul double %var_2_4533, %var_2_4535
; Matched:\<badref\>:  store double %var_2_4565, double* %var_2_1053, align 1
; store double %var_2_4536, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_4566:  %var_2_4566 = fsub double %var_2_4555, %var_2_4565
; %var_2_4537 = fsub double %var_2_4526, %var_2_4536
; Matched:\<badref\>:  store double %var_2_4566, double* %var_2_1037, align 1
; store double %var_2_4537, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_4538 = add i64 %var_2_4515, -16
; Matched:%var_2_4693:  %var_2_4693 = add i64 %var_2_4671, 28
; %var_2_4539 = add i64 %var_2_4517, 28
; Matched:\<badref\>:  store i64 %var_2_3180, i64* %var_2_3, align 8
; store i64 %var_2_4539, i64* %PC, align 8
%var_2_4540 = inttoptr i64 %var_2_4538 to i64*
%var_2_4541 = load i64, i64* %var_2_4540, align 8
; Matched:\<badref\>:  store i64 %var_2_2979, i64* %RCX.i2236, align 8
; store i64 %var_2_4541, i64* %RCX, align 8
%var_2_4542 = add i64 %var_2_4515, -32
; Matched:%var_2_3148:  %var_2_3148 = add i64 %var_2_3122, 32
; %var_2_4543 = add i64 %var_2_4517, 32
; Matched:\<badref\>:  store i64 %var_2_1991, i64* %var_2_3, align 8
; store i64 %var_2_4543, i64* %PC, align 8
%var_2_4544 = inttoptr i64 %var_2_4542 to i32*
%var_2_4545 = load i32, i32* %var_2_4544, align 4
%var_2_4546 = sext i32 %var_2_4545 to i64
; Matched:\<badref\>:  store i64 %var_2_4575, i64* %RDX.i2239, align 8
; store i64 %var_2_4546, i64* %RDX, align 8
; Matched:%var_2_4576:  %var_2_4576 = shl nsw i64 %var_2_4575, 3
; %var_2_4547 = shl nsw i64 %var_2_4546, 3
; Matched:%var_2_4577:  %var_2_4577 = add i64 %var_2_4576, %var_2_4570
; %var_2_4548 = add i64 %var_2_4547, %var_2_4541
; Matched:%var_2_3279:  %var_2_3279 = add i64 %var_2_3247, 37
; %var_2_4549 = add i64 %var_2_4517, 37
; Matched:\<badref\>:  store i64 %var_2_3279, i64* %var_2_3, align 8
; store i64 %var_2_4549, i64* %PC, align 8
; Matched:%var_2_3280:  %var_2_3280 = inttoptr i64 %var_2_3278 to double*
; %var_2_4550 = inttoptr i64 %var_2_4548 to double*
; Matched:\<badref\>:  store double %var_2_4566, double* %var_2_4579, align 8
; store double %var_2_4537, double* %var_2_4550, align 8
%var_2_4551 = load i64, i64* %RBP, align 8
%var_2_4552 = add i64 %var_2_4551, -72
%var_2_4553 = load i64, i64* %PC, align 8
; Matched:%var_2_3159:  %var_2_3159 = add i64 %var_2_3158, 5
; %var_2_4554 = add i64 %var_2_4553, 5
; Matched:\<badref\>:  store i64 %var_2_3159, i64* %var_2_3, align 8
; store i64 %var_2_4554, i64* %PC, align 8
%var_2_4555 = inttoptr i64 %var_2_4552 to i64*
%var_2_4556 = load i64, i64* %var_2_4555, align 8
; Matched:\<badref\>:  store i64 %var_2_4585, i64* %var_2_1038, align 1
; store i64 %var_2_4556, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_3287:  %var_2_3287 = add i64 %var_2_3281, -128
; %var_2_4557 = add i64 %var_2_4551, -128
; Matched:%var_2_4551:  %var_2_4551 = add i64 %var_2_4546, 10
; %var_2_4558 = add i64 %var_2_4553, 10
; Matched:\<badref\>:  store i64 %var_2_3127, i64* %var_2_3, align 8
; store i64 %var_2_4558, i64* %PC, align 8
; Matched:%var_2_3289:  %var_2_3289 = bitcast i64 %var_2_3286 to double
; %var_2_4559 = bitcast i64 %var_2_4556 to double
; Matched:%var_2_3290:  %var_2_3290 = inttoptr i64 %var_2_3287 to double*
; %var_2_4560 = inttoptr i64 %var_2_4557 to double*
; Matched:%var_2_3291:  %var_2_3291 = load double, double* %var_2_3290, align 8
; %var_2_4561 = load double, double* %var_2_4560, align 8
; Matched:%var_2_4591:  %var_2_4591 = fmul double %var_2_4588, %var_2_4590
; %var_2_4562 = fmul double %var_2_4559, %var_2_4561
; Matched:\<badref\>:  store double %var_2_4591, double* %var_2_1037, align 1
; store double %var_2_4562, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_4563 = add i64 %var_2_4551, -80
; Matched:%var_2_1889:  %var_2_1889 = add i64 %var_2_1880, 15
; %var_2_4564 = add i64 %var_2_4553, 15
; Matched:\<badref\>:  store i64 %var_2_1889, i64* %var_2_3, align 8
; store i64 %var_2_4564, i64* %PC, align 8
%var_2_4565 = inttoptr i64 %var_2_4563 to i64*
%var_2_4566 = load i64, i64* %var_2_4565, align 8
; Matched:\<badref\>:  store i64 %var_2_4595, i64* %var_2_1054, align 1
; store i64 %var_2_4566, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_3297:  %var_2_3297 = add i64 %var_2_3281, -120
; %var_2_4567 = add i64 %var_2_4551, -120
; Matched:%var_2_3173:  %var_2_3173 = add i64 %var_2_3158, 20
; %var_2_4568 = add i64 %var_2_4553, 20
; Matched:\<badref\>:  store i64 %var_2_3173, i64* %var_2_3, align 8
; store i64 %var_2_4568, i64* %PC, align 8
; Matched:%var_2_3299:  %var_2_3299 = bitcast i64 %var_2_3296 to double
; %var_2_4569 = bitcast i64 %var_2_4566 to double
; Matched:%var_2_3300:  %var_2_3300 = inttoptr i64 %var_2_3297 to double*
; %var_2_4570 = inttoptr i64 %var_2_4567 to double*
; Matched:%var_2_3301:  %var_2_3301 = load double, double* %var_2_3300, align 8
; %var_2_4571 = load double, double* %var_2_4570, align 8
; Matched:%var_2_4601:  %var_2_4601 = fmul double %var_2_4598, %var_2_4600
; %var_2_4572 = fmul double %var_2_4569, %var_2_4571
; Matched:\<badref\>:  store double %var_2_4601, double* %var_2_1053, align 1
; store double %var_2_4572, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_4602:  %var_2_4602 = fadd double %var_2_4591, %var_2_4601
; %var_2_4573 = fadd double %var_2_4562, %var_2_4572
; Matched:\<badref\>:  store double %var_2_4602, double* %var_2_1037, align 1
; store double %var_2_4573, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_4574 = add i64 %var_2_4551, -16
; Matched:%var_2_4604:  %var_2_4604 = add i64 %var_2_4582, 28
; %var_2_4575 = add i64 %var_2_4553, 28
; Matched:\<badref\>:  store i64 %var_2_4604, i64* %var_2_3, align 8
; store i64 %var_2_4575, i64* %PC, align 8
%var_2_4576 = inttoptr i64 %var_2_4574 to i64*
%var_2_4577 = load i64, i64* %var_2_4576, align 8
; Matched:\<badref\>:  store i64 %var_2_1236, i64* %RCX.i2236, align 8
; store i64 %var_2_4577, i64* %RCX, align 8
%var_2_4578 = add i64 %var_2_4551, -32
; Matched:%var_2_4608:  %var_2_4608 = add i64 %var_2_4582, 31
; %var_2_4579 = add i64 %var_2_4553, 31
; Matched:\<badref\>:  store i64 %var_2_4608, i64* %var_2_3, align 8
; store i64 %var_2_4579, i64* %PC, align 8
%var_2_4580 = inttoptr i64 %var_2_4578 to i32*
%var_2_4581 = load i32, i32* %var_2_4580, align 4
%var_2_4582 = add i32 %var_2_4581, 1
; Matched:%var_2_445:  %var_2_445 = zext i32 %var_2_444 to i64
; %var_2_4583 = zext i32 %var_2_4582 to i64
; Matched:\<badref\>:  store i64 %var_2_445, i64* %RAX.i2224, align 8
; store i64 %var_2_4583, i64* %RAX, align 8
; Matched:%var_2_446:  %var_2_446 = icmp eq i32 %var_2_443, -1
; %var_2_4584 = icmp eq i32 %var_2_4581, -1
; Matched:%var_2_899:  %var_2_899 = icmp eq i32 %var_2_896, 0
; %var_2_4585 = icmp eq i32 %var_2_4582, 0
; Matched:%var_2_335:  %var_2_335 = or i1 %var_2_333, %var_2_334
; %var_2_4586 = or i1 %var_2_4584, %var_2_4585
; Matched:%var_2_336:  %var_2_336 = zext i1 %var_2_335 to i8
; %var_2_4587 = zext i1 %var_2_4586 to i8
; Matched:\<badref\>:  store i8 %var_2_1415, i8* %var_2_14, align 1
; store i8 %var_2_4587, i8* %var_2_16, align 1
; Matched:%var_2_1416:  %var_2_1416 = and i32 %var_2_1410, 255
; %var_2_4588 = and i32 %var_2_4582, 255
; Matched:%var_2_338:  %var_2_338 = tail call i32 @llvm.ctpop.i32(i32 %var_2_337)
; %var_2_4589 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4588) #14
; Matched:%var_2_339:  %var_2_339 = trunc i32 %var_2_338 to i8
; %var_2_4590 = trunc i32 %var_2_4589 to i8
; Matched:%var_2_1419:  %var_2_1419 = and i8 %var_2_1418, 1
; %var_2_4591 = and i8 %var_2_4590, 1
; Matched:%var_2_1420:  %var_2_1420 = xor i8 %var_2_1419, 1
; %var_2_4592 = xor i8 %var_2_4591, 1
; Matched:\<badref\>:  store i8 %var_2_341, i8* %var_2_21, align 1
; store i8 %var_2_4592, i8* %var_2_23, align 1
; Matched:%var_2_342:  %var_2_342 = xor i32 %var_2_331, %var_2_330
; %var_2_4593 = xor i32 %var_2_4582, %var_2_4581
; Matched:%var_2_343:  %var_2_343 = lshr i32 %var_2_342, 4
; %var_2_4594 = lshr i32 %var_2_4593, 4
; Matched:%var_2_1423:  %var_2_1423 = trunc i32 %var_2_1422 to i8
; %var_2_4595 = trunc i32 %var_2_4594 to i8
; Matched:%var_2_345:  %var_2_345 = and i8 %var_2_344, 1
; %var_2_4596 = and i8 %var_2_4595, 1
; Matched:\<badref\>:  store i8 %var_2_345, i8* %var_2_27, align 1
; store i8 %var_2_4596, i8* %var_2_29, align 1
; Matched:%var_2_346:  %var_2_346 = zext i1 %var_2_334 to i8
; %var_2_4597 = zext i1 %var_2_4585 to i8
; Matched:\<badref\>:  store i8 %var_2_346, i8* %var_2_30, align 1
; store i8 %var_2_4597, i8* %var_2_32, align 1
; Matched:%var_2_460:  %var_2_460 = lshr i32 %var_2_444, 31
; %var_2_4598 = lshr i32 %var_2_4582, 31
; Matched:%var_2_461:  %var_2_461 = trunc i32 %var_2_460 to i8
; %var_2_4599 = trunc i32 %var_2_4598 to i8
; Matched:\<badref\>:  store i8 %var_2_348, i8* %var_2_33, align 1
; store i8 %var_2_4599, i8* %var_2_35, align 1
; Matched:%var_2_3940:  %var_2_3940 = lshr i32 %var_2_3921, 31
; %var_2_4600 = lshr i32 %var_2_4581, 31
; Matched:%var_2_463:  %var_2_463 = xor i32 %var_2_460, %var_2_462
; %var_2_4601 = xor i32 %var_2_4598, %var_2_4600
; Matched:%var_2_3942:  %var_2_3942 = add nuw nsw i32 %var_2_3941, %var_2_3938
; %var_2_4602 = add nuw nsw i32 %var_2_4601, %var_2_4598
; Matched:%var_2_4056:  %var_2_4056 = icmp eq i32 %var_2_4055, 2
; %var_2_4603 = icmp eq i32 %var_2_4602, 2
; Matched:%var_2_3944:  %var_2_3944 = zext i1 %var_2_3943 to i8
; %var_2_4604 = zext i1 %var_2_4603 to i8
; Matched:\<badref\>:  store i8 %var_2_3334, i8* %var_2_39, align 1
; store i8 %var_2_4604, i8* %var_2_41, align 1
%var_2_4605 = sext i32 %var_2_4582 to i64
; Matched:\<badref\>:  store i64 %var_2_1927, i64* %RDX.i2239, align 8
; store i64 %var_2_4605, i64* %RDX, align 8
; Matched:%var_2_4635:  %var_2_4635 = shl nsw i64 %var_2_4634, 3
; %var_2_4606 = shl nsw i64 %var_2_4605, 3
; Matched:%var_2_3337:  %var_2_3337 = add i64 %var_2_3307, %var_2_3336
; %var_2_4607 = add i64 %var_2_4577, %var_2_4606
; Matched:%var_2_4637:  %var_2_4637 = add i64 %var_2_4582, 42
; %var_2_4608 = add i64 %var_2_4553, 42
; Matched:\<badref\>:  store i64 %var_2_3213, i64* %var_2_3, align 8
; store i64 %var_2_4608, i64* %PC, align 8
; Matched:%var_2_3339:  %var_2_3339 = inttoptr i64 %var_2_3337 to double*
; %var_2_4609 = inttoptr i64 %var_2_4607 to double*
; Matched:\<badref\>:  store double %var_2_3303, double* %var_2_3339, align 8
; store double %var_2_4573, double* %var_2_4609, align 8
%var_2_4610 = load i64, i64* %RBP, align 8
%var_2_4611 = add i64 %var_2_4610, -136
%var_2_4612 = load i64, i64* %PC, align 8
%var_2_4613 = add i64 %var_2_4612, 8
store i64 %var_2_4613, i64* %PC, align 8
%var_2_4614 = inttoptr i64 %var_2_4611 to i64*
%var_2_4615 = load i64, i64* %var_2_4614, align 8
store i64 %var_2_4615, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_4616 = add i64 %var_2_4610, -176
; Matched:%var_2_1939:  %var_2_1939 = add i64 %var_2_1934, 16
; %var_2_4617 = add i64 %var_2_4612, 16
; Matched:\<badref\>:  store i64 %var_2_1939, i64* %var_2_3, align 8
; store i64 %var_2_4617, i64* %PC, align 8
%var_2_4618 = bitcast i64 %var_2_4615 to double
%var_2_4619 = inttoptr i64 %var_2_4616 to double*
%var_2_4620 = load double, double* %var_2_4619, align 8
%var_2_4621 = fadd double %var_2_4618, %var_2_4620
store double %var_2_4621, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_4651:  %var_2_4651 = add i64 %var_2_4639, -120
; %var_2_4622 = add i64 %var_2_4610, -120
; Matched:%var_2_3036:  %var_2_3036 = add i64 %var_2_3021, 21
; %var_2_4623 = add i64 %var_2_4612, 21
; Matched:\<badref\>:  store i64 %var_2_3036, i64* %var_2_3, align 8
; store i64 %var_2_4623, i64* %PC, align 8
; Matched:%var_2_4653:  %var_2_4653 = inttoptr i64 %var_2_4651 to double*
; %var_2_4624 = inttoptr i64 %var_2_4622 to double*
; Matched:\<badref\>:  store double %var_2_3351, double* %var_2_3354, align 8
; store double %var_2_4621, double* %var_2_4624, align 8
%var_2_4625 = load i64, i64* %RBP, align 8
%var_2_4626 = add i64 %var_2_4625, -144
%var_2_4627 = load i64, i64* %PC, align 8
%var_2_4628 = add i64 %var_2_4627, 8
store i64 %var_2_4628, i64* %PC, align 8
%var_2_4629 = inttoptr i64 %var_2_4626 to i64*
%var_2_4630 = load i64, i64* %var_2_4629, align 8
store i64 %var_2_4630, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
%var_2_4631 = add i64 %var_2_4625, -168
; Matched:%var_2_3362:  %var_2_3362 = add i64 %var_2_3357, 16
; %var_2_4632 = add i64 %var_2_4627, 16
; Matched:\<badref\>:  store i64 %var_2_3362, i64* %var_2_3, align 8
; store i64 %var_2_4632, i64* %PC, align 8
%var_2_4633 = bitcast i64 %var_2_4630 to double
%var_2_4634 = inttoptr i64 %var_2_4631 to double*
%var_2_4635 = load double, double* %var_2_4634, align 8
%var_2_4636 = fsub double %var_2_4633, %var_2_4635
store double %var_2_4636, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
; Matched:%var_2_4666:  %var_2_4666 = add i64 %var_2_4654, -128
; %var_2_4637 = add i64 %var_2_4625, -128
; Matched:%var_2_4652:  %var_2_4652 = add i64 %var_2_4641, 21
; %var_2_4638 = add i64 %var_2_4627, 21
; Matched:\<badref\>:  store i64 %var_2_4652, i64* %var_2_3, align 8
; store i64 %var_2_4638, i64* %PC, align 8
; Matched:%var_2_4668:  %var_2_4668 = inttoptr i64 %var_2_4666 to double*
; %var_2_4639 = inttoptr i64 %var_2_4637 to double*
; Matched:\<badref\>:  store double %var_2_4665, double* %var_2_4668, align 8
; store double %var_2_4636, double* %var_2_4639, align 8
%var_2_4640 = load i64, i64* %RBP, align 8
%var_2_4641 = add i64 %var_2_4640, -104
%var_2_4642 = load i64, i64* %PC, align 8
; Matched:%var_2_1674:  %var_2_1674 = add i64 %var_2_1673, 5
; %var_2_4643 = add i64 %var_2_4642, 5
; Matched:\<badref\>:  store i64 %var_2_1674, i64* %var_2_3, align 8
; store i64 %var_2_4643, i64* %PC, align 8
%var_2_4644 = inttoptr i64 %var_2_4641 to i64*
%var_2_4645 = load i64, i64* %var_2_4644, align 8
; Matched:\<badref\>:  store i64 %var_2_3411, i64* %var_2_1038, align 1
; store i64 %var_2_4645, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_3376:  %var_2_3376 = add i64 %var_2_3370, -120
; %var_2_4646 = add i64 %var_2_4640, -120
; Matched:%var_2_3413:  %var_2_3413 = add i64 %var_2_3408, 10
; %var_2_4647 = add i64 %var_2_4642, 10
; Matched:\<badref\>:  store i64 %var_2_4712, i64* %var_2_3, align 8
; store i64 %var_2_4647, i64* %PC, align 8
; Matched:%var_2_4677:  %var_2_4677 = bitcast i64 %var_2_4674 to double
; %var_2_4648 = bitcast i64 %var_2_4645 to double
; Matched:%var_2_3379:  %var_2_3379 = inttoptr i64 %var_2_3376 to double*
; %var_2_4649 = inttoptr i64 %var_2_4646 to double*
; Matched:%var_2_4679:  %var_2_4679 = load double, double* %var_2_4678, align 8
; %var_2_4650 = load double, double* %var_2_4649, align 8
; Matched:%var_2_4680:  %var_2_4680 = fmul double %var_2_4677, %var_2_4679
; %var_2_4651 = fmul double %var_2_4648, %var_2_4650
; Matched:\<badref\>:  store double %var_2_3381, double* %var_2_1037, align 1
; store double %var_2_4651, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_4652 = add i64 %var_2_4640, -112
; Matched:%var_2_4718:  %var_2_4718 = add i64 %var_2_4707, 15
; %var_2_4653 = add i64 %var_2_4642, 15
; Matched:\<badref\>:  store i64 %var_2_4718, i64* %var_2_3, align 8
; store i64 %var_2_4653, i64* %PC, align 8
%var_2_4654 = inttoptr i64 %var_2_4652 to i64*
%var_2_4655 = load i64, i64* %var_2_4654, align 8
; Matched:\<badref\>:  store i64 %var_2_3385, i64* %var_2_1054, align 1
; store i64 %var_2_4655, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_3386:  %var_2_3386 = add i64 %var_2_3370, -128
; %var_2_4656 = add i64 %var_2_4640, -128
; Matched:%var_2_4686:  %var_2_4686 = add i64 %var_2_4671, 20
; %var_2_4657 = add i64 %var_2_4642, 20
; Matched:\<badref\>:  store i64 %var_2_4686, i64* %var_2_3, align 8
; store i64 %var_2_4657, i64* %PC, align 8
; Matched:%var_2_4687:  %var_2_4687 = bitcast i64 %var_2_4684 to double
; %var_2_4658 = bitcast i64 %var_2_4655 to double
; Matched:%var_2_3389:  %var_2_3389 = inttoptr i64 %var_2_3386 to double*
; %var_2_4659 = inttoptr i64 %var_2_4656 to double*
; Matched:%var_2_4689:  %var_2_4689 = load double, double* %var_2_4688, align 8
; %var_2_4660 = load double, double* %var_2_4659, align 8
; Matched:%var_2_4690:  %var_2_4690 = fmul double %var_2_4687, %var_2_4689
; %var_2_4661 = fmul double %var_2_4658, %var_2_4660
; Matched:\<badref\>:  store double %var_2_3391, double* %var_2_1053, align 1
; store double %var_2_4661, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_3392:  %var_2_3392 = fsub double %var_2_3381, %var_2_3391
; %var_2_4662 = fsub double %var_2_4651, %var_2_4661
; Matched:\<badref\>:  store double %var_2_4691, double* %var_2_1037, align 1
; store double %var_2_4662, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_4663 = add i64 %var_2_4640, -16
; Matched:%var_2_3430:  %var_2_3430 = add i64 %var_2_3408, 28
; %var_2_4664 = add i64 %var_2_4642, 28
; Matched:\<badref\>:  store i64 %var_2_3430, i64* %var_2_3, align 8
; store i64 %var_2_4664, i64* %PC, align 8
%var_2_4665 = inttoptr i64 %var_2_4663 to i64*
%var_2_4666 = load i64, i64* %var_2_4665, align 8
; Matched:\<badref\>:  store i64 %var_2_1784, i64* %RCX.i2236, align 8
; store i64 %var_2_4666, i64* %RCX, align 8
%var_2_4667 = add i64 %var_2_4640, -40
; Matched:%var_2_4697:  %var_2_4697 = add i64 %var_2_4671, 32
; %var_2_4668 = add i64 %var_2_4642, 32
; Matched:\<badref\>:  store i64 %var_2_3273, i64* %var_2_3, align 8
; store i64 %var_2_4668, i64* %PC, align 8
%var_2_4669 = inttoptr i64 %var_2_4667 to i32*
%var_2_4670 = load i32, i32* %var_2_4669, align 4
%var_2_4671 = sext i32 %var_2_4670 to i64
; Matched:\<badref\>:  store i64 %var_2_4700, i64* %RDX.i2239, align 8
; store i64 %var_2_4671, i64* %RDX, align 8
; Matched:%var_2_3402:  %var_2_3402 = shl nsw i64 %var_2_3401, 3
; %var_2_4672 = shl nsw i64 %var_2_4671, 3
; Matched:%var_2_4702:  %var_2_4702 = add i64 %var_2_4701, %var_2_4695
; %var_2_4673 = add i64 %var_2_4672, %var_2_4666
; Matched:%var_2_4703:  %var_2_4703 = add i64 %var_2_4671, 37
; %var_2_4674 = add i64 %var_2_4642, 37
; Matched:\<badref\>:  store i64 %var_2_4703, i64* %var_2_3, align 8
; store i64 %var_2_4674, i64* %PC, align 8
; Matched:%var_2_4704:  %var_2_4704 = inttoptr i64 %var_2_4702 to double*
; %var_2_4675 = inttoptr i64 %var_2_4673 to double*
; Matched:\<badref\>:  store double %var_2_4691, double* %var_2_4704, align 8
; store double %var_2_4662, double* %var_2_4675, align 8
%var_2_4676 = load i64, i64* %RBP, align 8
%var_2_4677 = add i64 %var_2_4676, -104
%var_2_4678 = load i64, i64* %PC, align 8
; Matched:%var_2_3611:  %var_2_3611 = add i64 %var_2_3610, 5
; %var_2_4679 = add i64 %var_2_4678, 5
; Matched:\<badref\>:  store i64 %var_2_3611, i64* %var_2_3, align 8
; store i64 %var_2_4679, i64* %PC, align 8
%var_2_4680 = inttoptr i64 %var_2_4677 to i64*
%var_2_4681 = load i64, i64* %var_2_4680, align 8
; Matched:\<badref\>:  store i64 %var_2_4710, i64* %var_2_1038, align 1
; store i64 %var_2_4681, i64* %var_2_94, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_97, align 1
; store double 0.000000e+00, double* %var_2_96, align 1
; Matched:%var_2_3412:  %var_2_3412 = add i64 %var_2_3406, -128
; %var_2_4682 = add i64 %var_2_4676, -128
; Matched:%var_2_3252:  %var_2_3252 = add i64 %var_2_3247, 10
; %var_2_4683 = add i64 %var_2_4678, 10
; Matched:\<badref\>:  store i64 %var_2_4551, i64* %var_2_3, align 8
; store i64 %var_2_4683, i64* %PC, align 8
; Matched:%var_2_4713:  %var_2_4713 = bitcast i64 %var_2_4710 to double
; %var_2_4684 = bitcast i64 %var_2_4681 to double
; Matched:%var_2_3415:  %var_2_3415 = inttoptr i64 %var_2_3412 to double*
; %var_2_4685 = inttoptr i64 %var_2_4682 to double*
; Matched:%var_2_4715:  %var_2_4715 = load double, double* %var_2_4714, align 8
; %var_2_4686 = load double, double* %var_2_4685, align 8
; Matched:%var_2_4716:  %var_2_4716 = fmul double %var_2_4713, %var_2_4715
; %var_2_4687 = fmul double %var_2_4684, %var_2_4686
; Matched:\<badref\>:  store double %var_2_3417, double* %var_2_1037, align 1
; store double %var_2_4687, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_4688 = add i64 %var_2_4676, -112
; Matched:%var_2_2004:  %var_2_2004 = add i64 %var_2_1995, 15
; %var_2_4689 = add i64 %var_2_4678, 15
; Matched:\<badref\>:  store i64 %var_2_2004, i64* %var_2_3, align 8
; store i64 %var_2_4689, i64* %PC, align 8
%var_2_4690 = inttoptr i64 %var_2_4688 to i64*
%var_2_4691 = load i64, i64* %var_2_4690, align 8
; Matched:\<badref\>:  store i64 %var_2_4684, i64* %var_2_1054, align 1
; store i64 %var_2_4691, i64* %var_2_1624, align 1
; Matched:\<badref\>:  store double 0.000000e+00, double* %var_2_1056, align 1
; store double 0.000000e+00, double* %var_2_1626, align 1
; Matched:%var_2_3422:  %var_2_3422 = add i64 %var_2_3406, -120
; %var_2_4692 = add i64 %var_2_4676, -120
; Matched:%var_2_3627:  %var_2_3627 = add i64 %var_2_3610, 20
; %var_2_4693 = add i64 %var_2_4678, 20
; Matched:\<badref\>:  store i64 %var_2_3627, i64* %var_2_3, align 8
; store i64 %var_2_4693, i64* %PC, align 8
; Matched:%var_2_4723:  %var_2_4723 = bitcast i64 %var_2_4720 to double
; %var_2_4694 = bitcast i64 %var_2_4691 to double
; Matched:%var_2_3425:  %var_2_3425 = inttoptr i64 %var_2_3422 to double*
; %var_2_4695 = inttoptr i64 %var_2_4692 to double*
; Matched:%var_2_4725:  %var_2_4725 = load double, double* %var_2_4724, align 8
; %var_2_4696 = load double, double* %var_2_4695, align 8
; Matched:%var_2_4726:  %var_2_4726 = fmul double %var_2_4723, %var_2_4725
; %var_2_4697 = fmul double %var_2_4694, %var_2_4696
; Matched:\<badref\>:  store double %var_2_3427, double* %var_2_1053, align 1
; store double %var_2_4697, double* %var_2_1623, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_1055, align 1
; store i64 0, i64* %var_2_1625, align 1
; Matched:%var_2_3428:  %var_2_3428 = fadd double %var_2_3417, %var_2_3427
; %var_2_4698 = fadd double %var_2_4687, %var_2_4697
; Matched:\<badref\>:  store double %var_2_4727, double* %var_2_1037, align 1
; store double %var_2_4698, double* %var_2_93, align 1
; Matched:\<badref\>:  store i64 0, i64* %var_2_96, align 1
; store i64 0, i64* %var_2_95, align 1
%var_2_4699 = add i64 %var_2_4676, -16
; Matched:%var_2_4729:  %var_2_4729 = add i64 %var_2_4707, 28
; %var_2_4700 = add i64 %var_2_4678, 28
; Matched:\<badref\>:  store i64 %var_2_4729, i64* %var_2_3, align 8
; store i64 %var_2_4700, i64* %PC, align 8
%var_2_4701 = inttoptr i64 %var_2_4699 to i64*
%var_2_4702 = load i64, i64* %var_2_4701, align 8
; Matched:\<badref\>:  store i64 %var_2_3307, i64* %RCX.i2236, align 8
; store i64 %var_2_4702, i64* %RCX, align 8
%var_2_4703 = add i64 %var_2_4676, -40
; Matched:%var_2_1742:  %var_2_1742 = add i64 %var_2_1698, 31
; %var_2_4704 = add i64 %var_2_4678, 31
; Matched:\<badref\>:  store i64 %var_2_1742, i64* %var_2_3, align 8
; store i64 %var_2_4704, i64* %PC, align 8
%var_2_4705 = inttoptr i64 %var_2_4703 to i32*
%var_2_4706 = load i32, i32* %var_2_4705, align 4
%var_2_4707 = add i32 %var_2_4706, 1
; Matched:%var_2_3438:  %var_2_3438 = zext i32 %var_2_3437 to i64
; %var_2_4708 = zext i32 %var_2_4707 to i64
; Matched:\<badref\>:  store i64 %var_2_3438, i64* %RAX.i2224, align 8
; store i64 %var_2_4708, i64* %RAX, align 8
; Matched:%var_2_4738:  %var_2_4738 = icmp eq i32 %var_2_4735, -1
; %var_2_4709 = icmp eq i32 %var_2_4706, -1
; Matched:%var_2_4739:  %var_2_4739 = icmp eq i32 %var_2_4736, 0
; %var_2_4710 = icmp eq i32 %var_2_4707, 0
; Matched:%var_2_674:  %var_2_674 = or i1 %var_2_672, %var_2_673
; %var_2_4711 = or i1 %var_2_4709, %var_2_4710
; Matched:%var_2_4741:  %var_2_4741 = zext i1 %var_2_4740 to i8
; %var_2_4712 = zext i1 %var_2_4711 to i8
; Matched:\<badref\>:  store i8 %var_2_4741, i8* %var_2_14, align 1
; store i8 %var_2_4712, i8* %var_2_16, align 1
; Matched:%var_2_4742:  %var_2_4742 = and i32 %var_2_4736, 255
; %var_2_4713 = and i32 %var_2_4707, 255
; Matched:%var_2_677:  %var_2_677 = tail call i32 @llvm.ctpop.i32(i32 %var_2_676)
; %var_2_4714 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4713) #14
; Matched:%var_2_678:  %var_2_678 = trunc i32 %var_2_677 to i8
; %var_2_4715 = trunc i32 %var_2_4714 to i8
; Matched:%var_2_4745:  %var_2_4745 = and i8 %var_2_4744, 1
; %var_2_4716 = and i8 %var_2_4715, 1
; Matched:%var_2_3447:  %var_2_3447 = xor i8 %var_2_3446, 1
; %var_2_4717 = xor i8 %var_2_4716, 1
; Matched:\<badref\>:  store i8 %var_2_4746, i8* %var_2_21, align 1
; store i8 %var_2_4717, i8* %var_2_23, align 1
; Matched:%var_2_4747:  %var_2_4747 = xor i32 %var_2_4736, %var_2_4735
; %var_2_4718 = xor i32 %var_2_4707, %var_2_4706
; Matched:%var_2_3449:  %var_2_3449 = lshr i32 %var_2_3448, 4
; %var_2_4719 = lshr i32 %var_2_4718, 4
; Matched:%var_2_2032:  %var_2_2032 = trunc i32 %var_2_2031 to i8
; %var_2_4720 = trunc i32 %var_2_4719 to i8
; Matched:%var_2_4750:  %var_2_4750 = and i8 %var_2_4749, 1
; %var_2_4721 = and i8 %var_2_4720, 1
; Matched:\<badref\>:  store i8 %var_2_4750, i8* %var_2_27, align 1
; store i8 %var_2_4721, i8* %var_2_29, align 1
; Matched:%var_2_4751:  %var_2_4751 = zext i1 %var_2_4739 to i8
; %var_2_4722 = zext i1 %var_2_4710 to i8
; Matched:\<badref\>:  store i8 %var_2_4751, i8* %var_2_30, align 1
; store i8 %var_2_4722, i8* %var_2_32, align 1
; Matched:%var_2_4752:  %var_2_4752 = lshr i32 %var_2_4736, 31
; %var_2_4723 = lshr i32 %var_2_4707, 31
; Matched:%var_2_4753:  %var_2_4753 = trunc i32 %var_2_4752 to i8
; %var_2_4724 = trunc i32 %var_2_4723 to i8
; Matched:\<badref\>:  store i8 %var_2_4753, i8* %var_2_33, align 1
; store i8 %var_2_4724, i8* %var_2_35, align 1
; Matched:%var_2_4754:  %var_2_4754 = lshr i32 %var_2_4735, 31
; %var_2_4725 = lshr i32 %var_2_4706, 31
; Matched:%var_2_3456:  %var_2_3456 = xor i32 %var_2_3453, %var_2_3455
; %var_2_4726 = xor i32 %var_2_4723, %var_2_4725
; Matched:%var_2_690:  %var_2_690 = add nuw nsw i32 %var_2_689, %var_2_686
; %var_2_4727 = add nuw nsw i32 %var_2_4726, %var_2_4723
; Matched:%var_2_578:  %var_2_578 = icmp eq i32 %var_2_577, 2
; %var_2_4728 = icmp eq i32 %var_2_4727, 2
; Matched:%var_2_692:  %var_2_692 = zext i1 %var_2_691 to i8
; %var_2_4729 = zext i1 %var_2_4728 to i8
; Matched:\<badref\>:  store i8 %var_2_4758, i8* %var_2_39, align 1
; store i8 %var_2_4729, i8* %var_2_41, align 1
%var_2_4730 = sext i32 %var_2_4707 to i64
; Matched:\<badref\>:  store i64 %var_2_4759, i64* %RDX.i2239, align 8
; store i64 %var_2_4730, i64* %RDX, align 8
; Matched:%var_2_3461:  %var_2_3461 = shl nsw i64 %var_2_3460, 3
; %var_2_4731 = shl nsw i64 %var_2_4730, 3
; Matched:%var_2_3462:  %var_2_3462 = add i64 %var_2_3432, %var_2_3461
; %var_2_4732 = add i64 %var_2_4702, %var_2_4731
; Matched:%var_2_4762:  %var_2_4762 = add i64 %var_2_4707, 42
; %var_2_4733 = add i64 %var_2_4678, 42
; Matched:\<badref\>:  store i64 %var_2_3338, i64* %var_2_3, align 8
; store i64 %var_2_4733, i64* %PC, align 8
; Matched:%var_2_4763:  %var_2_4763 = inttoptr i64 %var_2_4761 to double*
; %var_2_4734 = inttoptr i64 %var_2_4732 to double*
; Matched:\<badref\>:  store double %var_2_3428, double* %var_2_3464, align 8
; store double %var_2_4698, double* %var_2_4734, align 8
; Matched:%var_2_4764:  %var_2_4764 = load i64, i64* %RBP.i, align 8
; %var_2_4735 = load i64, i64* %RBP, align 8
; Matched:%var_2_2048:  %var_2_2048 = add i64 %var_2_2047, -28
; %var_2_4736 = add i64 %var_2_4735, -28
%var_2_4737 = load i64, i64* %PC, align 8
; Matched:%var_2_2488:  %var_2_2488 = add i64 %var_2_2487, 3
; %var_2_4738 = add i64 %var_2_4737, 3
; Matched:\<badref\>:  store i64 %var_2_2488, i64* %var_2_3, align 8
; store i64 %var_2_4738, i64* %PC, align 8
; Matched:%var_2_4768:  %var_2_4768 = inttoptr i64 %var_2_4765 to i32*
; %var_2_4739 = inttoptr i64 %var_2_4736 to i32*
; Matched:%var_2_4769:  %var_2_4769 = load i32, i32* %var_2_4768, align 4
; %var_2_4740 = load i32, i32* %var_2_4739, align 4
; Matched:%var_2_2053:  %var_2_2053 = add i32 %var_2_2052, 2
; %var_2_4741 = add i32 %var_2_4740, 2
; Matched:%var_2_4771:  %var_2_4771 = zext i32 %var_2_4770 to i64
; %var_2_4742 = zext i32 %var_2_4741 to i64
; Matched:\<badref\>:  store i64 %var_2_2054, i64* %RAX.i2224, align 8
; store i64 %var_2_4742, i64* %RAX, align 8
; Matched:%var_2_3473:  %var_2_3473 = icmp ugt i32 %var_2_3470, -3
; %var_2_4743 = icmp ugt i32 %var_2_4740, -3
; Matched:%var_2_4773:  %var_2_4773 = zext i1 %var_2_4772 to i8
; %var_2_4744 = zext i1 %var_2_4743 to i8
; Matched:\<badref\>:  store i8 %var_2_4773, i8* %var_2_14, align 1
; store i8 %var_2_4744, i8* %var_2_16, align 1
; Matched:%var_2_4774:  %var_2_4774 = and i32 %var_2_4770, 255
; %var_2_4745 = and i32 %var_2_4741, 255
; Matched:%var_2_4775:  %var_2_4775 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4774)
; %var_2_4746 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4745) #14
; Matched:%var_2_2059:  %var_2_2059 = trunc i32 %var_2_2058 to i8
; %var_2_4747 = trunc i32 %var_2_4746 to i8
; Matched:%var_2_4777:  %var_2_4777 = and i8 %var_2_4776, 1
; %var_2_4748 = and i8 %var_2_4747, 1
; Matched:%var_2_2061:  %var_2_2061 = xor i8 %var_2_2060, 1
; %var_2_4749 = xor i8 %var_2_4748, 1
; Matched:\<badref\>:  store i8 %var_2_3479, i8* %var_2_21, align 1
; store i8 %var_2_4749, i8* %var_2_23, align 1
; Matched:%var_2_4779:  %var_2_4779 = xor i32 %var_2_4770, %var_2_4769
; %var_2_4750 = xor i32 %var_2_4741, %var_2_4740
; Matched:%var_2_4780:  %var_2_4780 = lshr i32 %var_2_4779, 4
; %var_2_4751 = lshr i32 %var_2_4750, 4
; Matched:%var_2_4781:  %var_2_4781 = trunc i32 %var_2_4780 to i8
; %var_2_4752 = trunc i32 %var_2_4751 to i8
; Matched:%var_2_4782:  %var_2_4782 = and i8 %var_2_4781, 1
; %var_2_4753 = and i8 %var_2_4752, 1
; Matched:\<badref\>:  store i8 %var_2_2065, i8* %var_2_27, align 1
; store i8 %var_2_4753, i8* %var_2_29, align 1
; Matched:%var_2_4783:  %var_2_4783 = icmp eq i32 %var_2_4770, 0
; %var_2_4754 = icmp eq i32 %var_2_4741, 0
; Matched:%var_2_2067:  %var_2_2067 = zext i1 %var_2_2066 to i8
; %var_2_4755 = zext i1 %var_2_4754 to i8
; Matched:\<badref\>:  store i8 %var_2_3485, i8* %var_2_30, align 1
; store i8 %var_2_4755, i8* %var_2_32, align 1
; Matched:%var_2_4785:  %var_2_4785 = lshr i32 %var_2_4770, 31
; %var_2_4756 = lshr i32 %var_2_4741, 31
; Matched:%var_2_4786:  %var_2_4786 = trunc i32 %var_2_4785 to i8
; %var_2_4757 = trunc i32 %var_2_4756 to i8
; Matched:\<badref\>:  store i8 %var_2_4786, i8* %var_2_33, align 1
; store i8 %var_2_4757, i8* %var_2_35, align 1
; Matched:%var_2_4787:  %var_2_4787 = lshr i32 %var_2_4769, 31
; %var_2_4758 = lshr i32 %var_2_4740, 31
; Matched:%var_2_2071:  %var_2_2071 = xor i32 %var_2_2068, %var_2_2070
; %var_2_4759 = xor i32 %var_2_4756, %var_2_4758
; Matched:%var_2_4789:  %var_2_4789 = add nuw nsw i32 %var_2_4788, %var_2_4785
; %var_2_4760 = add nuw nsw i32 %var_2_4759, %var_2_4756
; Matched:%var_2_2073:  %var_2_2073 = icmp eq i32 %var_2_2072, 2
; %var_2_4761 = icmp eq i32 %var_2_4760, 2
; Matched:%var_2_3492:  %var_2_3492 = zext i1 %var_2_3491 to i8
; %var_2_4762 = zext i1 %var_2_4761 to i8
; Matched:\<badref\>:  store i8 %var_2_4791, i8* %var_2_39, align 1
; store i8 %var_2_4762, i8* %var_2_41, align 1
%var_2_4763 = add i64 %var_2_4737, 9
store i64 %var_2_4763, i64* %PC, align 8
; Matched:\<badref\>:  store i32 %var_2_4770, i32* %var_2_4768, align 4
; store i32 %var_2_4741, i32* %var_2_4739, align 4
; Matched:%var_2_3494:  %var_2_3494 = load i64, i64* %var_2_3, align 8
; %var_2_4764 = load i64, i64* %PC, align 8
; Matched:%var_2_3495:  %var_2_3495 = add i64 %var_2_3494, -781
; %var_2_4765 = add i64 %var_2_4764, -781
; Matched:\<badref\>:  store i64 %var_2_3495, i64* %var_2_3, align 8
; store i64 %var_2_4765, i64* %PC, align 8
  br label %block_403940

block_4035c1:                                     ; preds = %block_4035ad, %block_4035d2
; Matched:%var_2_1057:  %var_2_1057 = phi i64 [ %var_2_2077, %block_4035d2 ], [ %.pre23, %block_.L_4035ad ]
; %var_2_4766 = phi i64 [ %.pre23, %block_4035ad ], [ %var_2_1307, %block_4035d2 ]
%var_2_4767 = load i64, i64* %RBP, align 8
%var_2_4768 = add i64 %var_2_4767, -28
; Matched:%var_2_1060:  %var_2_1060 = add i64 %var_2_1057, 3
; %var_2_4769 = add i64 %var_2_4766, 3
; Matched:\<badref\>:  store i64 %var_2_1060, i64* %var_2_3, align 8
; store i64 %var_2_4769, i64* %PC, align 8
%var_2_4770 = inttoptr i64 %var_2_4768 to i32*
%var_2_4771 = load i32, i32* %var_2_4770, align 4
; Matched:%var_2_1063:  %var_2_1063 = zext i32 %var_2_1062 to i64
; %var_2_4772 = zext i32 %var_2_4771 to i64
; Matched:\<badref\>:  store i64 %var_2_1063, i64* %RAX.i2224, align 8
; store i64 %var_2_4772, i64* %RAX, align 8
%var_2_4773 = add i64 %var_2_4767, -8
; Matched:%var_2_1065:  %var_2_1065 = add i64 %var_2_1057, 6
; %var_2_4774 = add i64 %var_2_4766, 6
; Matched:\<badref\>:  store i64 %var_2_1065, i64* %var_2_3, align 8
; store i64 %var_2_4774, i64* %PC, align 8
%var_2_4775 = inttoptr i64 %var_2_4773 to i32*
%var_2_4776 = load i32, i32* %var_2_4775, align 4
; Matched:%var_2_2416:  %var_2_2416 = zext i32 %var_2_2415 to i64
; %var_2_4777 = zext i32 %var_2_4776 to i64
; Matched:\<badref\>:  store i64 %var_2_2416, i64* %RCX.i2236, align 8
; store i64 %var_2_4777, i64* %RCX, align 8
%var_2_4778 = add i64 %var_2_4767, -56
; Matched:%var_2_1070:  %var_2_1070 = add i64 %var_2_1057, 9
; %var_2_4779 = add i64 %var_2_4766, 9
; Matched:\<badref\>:  store i64 %var_2_1070, i64* %var_2_3, align 8
; store i64 %var_2_4779, i64* %PC, align 8
%var_2_4780 = inttoptr i64 %var_2_4778 to i32*
%var_2_4781 = load i32, i32* %var_2_4780, align 4
%var_2_4782 = add i32 %var_2_4781, %var_2_4776
; Matched:%var_2_1074:  %var_2_1074 = zext i32 %var_2_1073 to i64
; %var_2_4783 = zext i32 %var_2_4782 to i64
; Matched:\<badref\>:  store i64 %var_2_1074, i64* %RCX.i2236, align 8
; store i64 %var_2_4783, i64* %RCX, align 8
%var_2_4784 = lshr i32 %var_2_4782, 31
%var_2_4785 = sub i32 %var_2_4771, %var_2_4782
; Matched:%var_2_1077:  %var_2_1077 = icmp ult i32 %var_2_1062, %var_2_1073
; %var_2_4786 = icmp ult i32 %var_2_4771, %var_2_4782
; Matched:%var_2_1078:  %var_2_1078 = zext i1 %var_2_1077 to i8
; %var_2_4787 = zext i1 %var_2_4786 to i8
; Matched:\<badref\>:  store i8 %var_2_1078, i8* %var_2_14, align 1
; store i8 %var_2_4787, i8* %var_2_16, align 1
; Matched:%var_2_1079:  %var_2_1079 = and i32 %var_2_1076, 255
; %var_2_4788 = and i32 %var_2_4785, 255
; Matched:%var_2_1080:  %var_2_1080 = tail call i32 @llvm.ctpop.i32(i32 %var_2_1079)
; %var_2_4789 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4788) #14
; Matched:%var_2_1081:  %var_2_1081 = trunc i32 %var_2_1080 to i8
; %var_2_4790 = trunc i32 %var_2_4789 to i8
; Matched:%var_2_1082:  %var_2_1082 = and i8 %var_2_1081, 1
; %var_2_4791 = and i8 %var_2_4790, 1
; Matched:%var_2_1083:  %var_2_1083 = xor i8 %var_2_1082, 1
; %var_2_4792 = xor i8 %var_2_4791, 1
; Matched:\<badref\>:  store i8 %var_2_1083, i8* %var_2_21, align 1
; store i8 %var_2_4792, i8* %var_2_23, align 1
; Matched:%var_2_1084:  %var_2_1084 = xor i32 %var_2_1073, %var_2_1062
; %var_2_4793 = xor i32 %var_2_4782, %var_2_4771
; Matched:%var_2_1085:  %var_2_1085 = xor i32 %var_2_1084, %var_2_1076
; %var_2_4794 = xor i32 %var_2_4793, %var_2_4785
; Matched:%var_2_1086:  %var_2_1086 = lshr i32 %var_2_1085, 4
; %var_2_4795 = lshr i32 %var_2_4794, 4
; Matched:%var_2_1087:  %var_2_1087 = trunc i32 %var_2_1086 to i8
; %var_2_4796 = trunc i32 %var_2_4795 to i8
; Matched:%var_2_1088:  %var_2_1088 = and i8 %var_2_1087, 1
; %var_2_4797 = and i8 %var_2_4796, 1
; Matched:\<badref\>:  store i8 %var_2_1088, i8* %var_2_27, align 1
; store i8 %var_2_4797, i8* %var_2_29, align 1
; Matched:%var_2_1089:  %var_2_1089 = icmp eq i32 %var_2_1076, 0
; %var_2_4798 = icmp eq i32 %var_2_4785, 0
; Matched:%var_2_1090:  %var_2_1090 = zext i1 %var_2_1089 to i8
; %var_2_4799 = zext i1 %var_2_4798 to i8
; Matched:\<badref\>:  store i8 %var_2_1090, i8* %var_2_30, align 1
; store i8 %var_2_4799, i8* %var_2_32, align 1
%var_2_4800 = lshr i32 %var_2_4785, 31
%var_2_4801 = trunc i32 %var_2_4800 to i8
; Matched:\<badref\>:  store i8 %var_2_1092, i8* %var_2_33, align 1
; store i8 %var_2_4801, i8* %var_2_35, align 1
%var_2_4802 = lshr i32 %var_2_4771, 31
%var_2_4803 = xor i32 %var_2_4784, %var_2_4802
%var_2_4804 = xor i32 %var_2_4800, %var_2_4802
%var_2_4805 = add nuw nsw i32 %var_2_4804, %var_2_4803
%var_2_4806 = icmp eq i32 %var_2_4805, 2
; Matched:%var_2_1098:  %var_2_1098 = zext i1 %var_2_1097 to i8
; %var_2_4807 = zext i1 %var_2_4806 to i8
; Matched:\<badref\>:  store i8 %var_2_1098, i8* %var_2_39, align 1
; store i8 %var_2_4807, i8* %var_2_41, align 1
%var_2_4808 = icmp ne i8 %var_2_4801, 0
%var_2_4809 = xor i1 %var_2_4808, %var_2_4806
; Matched:  %.v27 = select i1 %var_2_1100, i64 17, i64 700
; %.v27 = select i1 %var_2_4809, i64 17, i64 700
; Matched:%var_2_1101:  %var_2_1101 = add i64 %var_2_1057, %.v27
; %var_2_4810 = add i64 %var_2_4766, %.v27
; Matched:\<badref\>:  store i64 %var_2_1101, i64* %var_2_3, align 8
; store i64 %var_2_4810, i64* %PC, align 8
br i1 %var_2_4809, label %block_4035d2, label %block_40387d

block_403940:                                     ; preds = %block_403951, %block_40389f
; Matched:%var_2_2405:  %var_2_2405 = phi i64 [ %var_2_3495, %block_403951 ], [ %.pre25, %block_40389f ]
; %var_2_4811 = phi i64 [ %var_2_4765, %block_403951 ], [ %.pre25, %block_40389f ]
%var_2_4812 = load i64, i64* %RBP, align 8
%var_2_4813 = add i64 %var_2_4812, -28
; Matched:%var_2_2408:  %var_2_2408 = add i64 %var_2_2405, 3
; %var_2_4814 = add i64 %var_2_4811, 3
; Matched:\<badref\>:  store i64 %var_2_2408, i64* %var_2_3, align 8
; store i64 %var_2_4814, i64* %PC, align 8
%var_2_4815 = inttoptr i64 %var_2_4813 to i32*
%var_2_4816 = load i32, i32* %var_2_4815, align 4
; Matched:%var_2_3676:  %var_2_3676 = zext i32 %var_2_3675 to i64
; %var_2_4817 = zext i32 %var_2_4816 to i64
; Matched:\<badref\>:  store i64 %var_2_3676, i64* %RAX.i2224, align 8
; store i64 %var_2_4817, i64* %RAX, align 8
%var_2_4818 = add i64 %var_2_4812, -8
; Matched:%var_2_2413:  %var_2_2413 = add i64 %var_2_2405, 6
; %var_2_4819 = add i64 %var_2_4811, 6
; Matched:\<badref\>:  store i64 %var_2_2413, i64* %var_2_3, align 8
; store i64 %var_2_4819, i64* %PC, align 8
%var_2_4820 = inttoptr i64 %var_2_4818 to i32*
%var_2_4821 = load i32, i32* %var_2_4820, align 4
; Matched:%var_2_3681:  %var_2_3681 = zext i32 %var_2_3680 to i64
; %var_2_4822 = zext i32 %var_2_4821 to i64
; Matched:\<badref\>:  store i64 %var_2_3681, i64* %RCX.i2236, align 8
; store i64 %var_2_4822, i64* %RCX, align 8
%var_2_4823 = add i64 %var_2_4812, -44
; Matched:%var_2_2418:  %var_2_2418 = add i64 %var_2_2405, 9
; %var_2_4824 = add i64 %var_2_4811, 9
; Matched:\<badref\>:  store i64 %var_2_2418, i64* %var_2_3, align 8
; store i64 %var_2_4824, i64* %PC, align 8
%var_2_4825 = inttoptr i64 %var_2_4823 to i32*
%var_2_4826 = load i32, i32* %var_2_4825, align 4
%var_2_4827 = add i32 %var_2_4826, %var_2_4821
; Matched:%var_2_2422:  %var_2_2422 = zext i32 %var_2_2421 to i64
; %var_2_4828 = zext i32 %var_2_4827 to i64
; Matched:\<badref\>:  store i64 %var_2_2422, i64* %RCX.i2236, align 8
; store i64 %var_2_4828, i64* %RCX, align 8
%var_2_4829 = lshr i32 %var_2_4827, 31
%var_2_4830 = sub i32 %var_2_4816, %var_2_4827
; Matched:%var_2_2425:  %var_2_2425 = icmp ult i32 %var_2_2410, %var_2_2421
; %var_2_4831 = icmp ult i32 %var_2_4816, %var_2_4827
; Matched:%var_2_2426:  %var_2_2426 = zext i1 %var_2_2425 to i8
; %var_2_4832 = zext i1 %var_2_4831 to i8
; Matched:\<badref\>:  store i8 %var_2_2426, i8* %var_2_14, align 1
; store i8 %var_2_4832, i8* %var_2_16, align 1
; Matched:%var_2_2427:  %var_2_2427 = and i32 %var_2_2424, 255
; %var_2_4833 = and i32 %var_2_4830, 255
; Matched:%var_2_2428:  %var_2_2428 = tail call i32 @llvm.ctpop.i32(i32 %var_2_2427)
; %var_2_4834 = tail call i32 @llvm.ctpop.i32(i32 %var_2_4833) #14
; Matched:%var_2_2429:  %var_2_2429 = trunc i32 %var_2_2428 to i8
; %var_2_4835 = trunc i32 %var_2_4834 to i8
; Matched:%var_2_2430:  %var_2_2430 = and i8 %var_2_2429, 1
; %var_2_4836 = and i8 %var_2_4835, 1
; Matched:%var_2_2431:  %var_2_2431 = xor i8 %var_2_2430, 1
; %var_2_4837 = xor i8 %var_2_4836, 1
; Matched:\<badref\>:  store i8 %var_2_2431, i8* %var_2_21, align 1
; store i8 %var_2_4837, i8* %var_2_23, align 1
; Matched:%var_2_2432:  %var_2_2432 = xor i32 %var_2_2421, %var_2_2410
; %var_2_4838 = xor i32 %var_2_4827, %var_2_4816
; Matched:%var_2_2433:  %var_2_2433 = xor i32 %var_2_2432, %var_2_2424
; %var_2_4839 = xor i32 %var_2_4838, %var_2_4830
; Matched:%var_2_2434:  %var_2_2434 = lshr i32 %var_2_2433, 4
; %var_2_4840 = lshr i32 %var_2_4839, 4
; Matched:%var_2_2435:  %var_2_2435 = trunc i32 %var_2_2434 to i8
; %var_2_4841 = trunc i32 %var_2_4840 to i8
; Matched:%var_2_2436:  %var_2_2436 = and i8 %var_2_2435, 1
; %var_2_4842 = and i8 %var_2_4841, 1
; Matched:\<badref\>:  store i8 %var_2_2436, i8* %var_2_27, align 1
; store i8 %var_2_4842, i8* %var_2_29, align 1
; Matched:%var_2_2437:  %var_2_2437 = icmp eq i32 %var_2_2424, 0
; %var_2_4843 = icmp eq i32 %var_2_4830, 0
; Matched:%var_2_2438:  %var_2_2438 = zext i1 %var_2_2437 to i8
; %var_2_4844 = zext i1 %var_2_4843 to i8
; Matched:\<badref\>:  store i8 %var_2_2438, i8* %var_2_30, align 1
; store i8 %var_2_4844, i8* %var_2_32, align 1
%var_2_4845 = lshr i32 %var_2_4830, 31
%var_2_4846 = trunc i32 %var_2_4845 to i8
; Matched:\<badref\>:  store i8 %var_2_2440, i8* %var_2_33, align 1
; store i8 %var_2_4846, i8* %var_2_35, align 1
%var_2_4847 = lshr i32 %var_2_4816, 31
%var_2_4848 = xor i32 %var_2_4829, %var_2_4847
%var_2_4849 = xor i32 %var_2_4845, %var_2_4847
%var_2_4850 = add nuw nsw i32 %var_2_4849, %var_2_4848
%var_2_4851 = icmp eq i32 %var_2_4850, 2
; Matched:%var_2_2446:  %var_2_2446 = zext i1 %var_2_2445 to i8
; %var_2_4852 = zext i1 %var_2_4851 to i8
; Matched:\<badref\>:  store i8 %var_2_2446, i8* %var_2_39, align 1
; store i8 %var_2_4852, i8* %var_2_41, align 1
%var_2_4853 = icmp ne i8 %var_2_4846, 0
%var_2_4854 = xor i1 %var_2_4853, %var_2_4851
; Matched:  %.v29 = select i1 %var_2_2448, i64 17, i64 786
; %.v29 = select i1 %var_2_4854, i64 17, i64 786
; Matched:%var_2_2449:  %var_2_2449 = add i64 %var_2_2405, %.v29
; %var_2_4855 = add i64 %var_2_4811, %.v29
; Matched:\<badref\>:  store i64 %var_2_2449, i64* %var_2_3, align 8
; store i64 %var_2_4855, i64* %PC, align 8
br i1 %var_2_4854, label %block_403951, label %block_403c52
}

; Function Attrs: noinline
define %struct.Memory* @sub_4007a0_deregister_tm_clones(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #8 {
block_4007a0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* %RSP, align 8, !tbaa !2428
  %6 = add i64 %5, -8
  %7 = inttoptr i64 %6 to i64*
  store i64 %3, i64* %7, align 8
  store i64 %6, i64* %RSP, align 8, !tbaa !2428
  %8 = load i64, i64* %PC, align 8
  store i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64* %RAX, align 8, !tbaa !2428
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 zext (i1 icmp ult (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)) to i8), i8* %9, align 1, !tbaa !2432
  %10 = tail call i32 @llvm.ctpop.i32(i32 and (i32 trunc (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)) to i32), i32 255)) #14
  %11 = trunc i32 %10 to i8
  %12 = and i8 %11, 1
  %13 = xor i8 %12, 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %13, i8* %14, align 1, !tbaa !2446
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 and (i8 trunc (i64 lshr (i64 xor (i64 xor (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295)), i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64))), i64 4) to i8), i8 1), i8* %15, align 1, !tbaa !2447
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 zext (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0) to i8), i8* %16, align 1, !tbaa !2448
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 trunc (i64 lshr (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 63) to i8), i8* %17, align 1, !tbaa !2449
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 zext (i1 icmp eq (i64 add (i64 xor (i64 lshr (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 63), i64 lshr (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 63)), i64 xor (i64 lshr (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 63), i64 lshr (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 63))), i64 2) to i8), i8* %18, align 1, !tbaa !2450
  store i64 %6, i64* %RBP, align 8, !tbaa !2428
  %19 = add i64 %8, select (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), i64 39, i64 16)
  store i64 %19, i64* %PC, align 8, !tbaa !2428
  br i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), label %block_4007c8, label %block_4007b1

block_4007b1:                                     ; preds = %block_4007a0
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %9, align 1, !tbaa !2432
  store i8 1, i8* %14, align 1, !tbaa !2446
  store i8 1, i8* %16, align 1, !tbaa !2448
  store i8 0, i8* %17, align 1, !tbaa !2449
  store i8 0, i8* %18, align 1, !tbaa !2450
  store i8 0, i8* %15, align 1, !tbaa !2447
  %20 = add i64 %8, add (i64 select (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), i64 39, i64 16), i64 23)
  store i64 %20, i64* %PC, align 8, !tbaa !2428
  br label %block_4007c8

block_4007c8:                                     ; preds = %block_4007b1, %block_4007a0
  %21 = phi i64 [ %20, %block_4007b1 ], [ %19, %block_4007a0 ]
  %22 = add i64 %21, 1
  store i64 %22, i64* %PC, align 8
  %23 = load i64, i64* %7, align 8
  store i64 %23, i64* %RBP, align 8, !tbaa !2428
  store i64 %5, i64* %RSP, align 8, !tbaa !2428
  %24 = add i64 %21, 2
  store i64 %24, i64* %PC, align 8
  %25 = inttoptr i64 %5 to i64*
  %26 = load i64, i64* %25, align 8
  store i64 %26, i64* %PC, align 8, !tbaa !2428
  %27 = add i64 %5, 8
  store i64 %27, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
declare void @__mcsema_attach_call() #6

; Function Attrs: naked nobuiltin noinline nounwind
define internal void @callback_sub_400840_frame_dummy() #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400840;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @1, void ()** nonnull @2) #14
  ret void
}

define internal %struct.Memory* @callback_sub_400840_frame_dummy_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400840_frame_dummy(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define internal void @callback_sub_400810___do_global_dtors_aux() #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400810;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @3, void ()** nonnull @2) #14
  ret void
}

define internal %struct.Memory* @callback_sub_400810___do_global_dtors_aux_wrapper(%struct.State*, i64, %struct.Memory* readnone returned) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400810___do_global_dtors_aux(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: alwaysinline inlinehint nounwind
define %struct.Memory* @ext_6050b8_cos(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #11 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @cos(double %6)
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %13 = bitcast i64* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* %13, i8 0, i64 24, i32 8, i1 false)
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: alwaysinline inlinehint nounwind
define %struct.Memory* @ext_6050d8_sin(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #11 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @sin(double %6)
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %13 = bitcast i64* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* %13, i8 0, i64 24, i32 8, i1 false)
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: alwaysinline inlinehint nounwind
define %struct.Memory* @ext_6050f8_atan(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #11 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @atan(double %6)
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %13 = bitcast i64* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* %13, i8 0, i64 24, i32 8, i1 false)
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: naked nobuiltin noinline nounwind
define internal void @callback_sub_404090___libc_csu_fini() #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x404090;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @4, void ()** nonnull @2) #14
  ret void
}

; Function Attrs: norecurse nounwind
define internal %struct.Memory* @callback_sub_404090___libc_csu_fini_wrapper(%struct.State* nocapture, i64, %struct.Memory* readnone returned) #12 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_404090___libc_csu_fini(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define internal void @callback_sub_404020___libc_csu_init() #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x404020;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @5, void ()** nonnull @2) #14
  ret void
}

define internal %struct.Memory* @callback_sub_404020___libc_csu_init_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_404020___libc_csu_init(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @main() #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400850;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @6, void ()** nonnull @2) #14
  ret void
}

define internal %struct.Memory* @main_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400850_main(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_605120___libc_start_main(%struct.State*, %struct.Memory*) unnamed_addr #13 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64)* @__libc_start_main to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_4006f0_gettimeofday(%struct.State*, %struct.Memory*) unnamed_addr #13 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64)* @gettimeofday to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_6050e8_free(%struct.State*, %struct.Memory*) unnamed_addr #13 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64)* @free to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_605128_memcpy(%struct.State*, %struct.Memory*) unnamed_addr #13 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64)* @memcpy to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_605110_memset(%struct.State*, %struct.Memory*) unnamed_addr #13 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64)* @memset to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_4006e0_printf(%struct.State*, %struct.Memory*) unnamed_addr #13 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64)* @printf to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: alwaysinline inlinehint nounwind
define %struct.Memory* @ext_605140_sqrt(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #11 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @sqrt(double %6)
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %13 = bitcast i64* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* %13, i8 0, i64 24, i32 8, i1 false)
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_6050d0_memalign(%struct.State*, %struct.Memory*) unnamed_addr #13 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64)* @memalign to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_4006c0_abort(%struct.State*, %struct.Memory*) unnamed_addr #13 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 ()* @abort to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @putdata() local_unnamed_addr #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400fe0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @7, void ()** nonnull @2) #14
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @putdata_wrapper(%struct.State*, i64, %struct.Memory*) #14 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400fe0_putdata(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @cdft() local_unnamed_addr #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x401060;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @8, void ()** nonnull @2) #14
  ret void
}

define internal %struct.Memory* @cdft_wrapper(%struct.State*, i64, %struct.Memory* readnone) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_401060_cdft(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @errorcheck() local_unnamed_addr #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x401100;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @9, void ()** nonnull @2) #14
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @errorcheck_wrapper(%struct.State*, i64, %struct.Memory*) #14 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_401100_errorcheck(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @.term_proc() local_unnamed_addr #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x404094;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @10, void ()** nonnull @2) #14
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @.term_proc_wrapper(%struct.State* nocapture, i64, %struct.Memory* readnone returned) #14 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_404094__term_proc(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @get_time() local_unnamed_addr #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400e30;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @11, void ()** nonnull @2) #14
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @get_time_wrapper(%struct.State*, i64, %struct.Memory*) #14 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400e30_get_time(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @.init_proc() local_unnamed_addr #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400688;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @12, void ()** nonnull @2) #14
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @.init_proc_wrapper(%struct.State*, i64, %struct.Memory*) #14 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400688__init_proc(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @makewt() local_unnamed_addr #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400e70;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @13, void ()** nonnull @2) #14
  ret void
}

define internal %struct.Memory* @makewt_wrapper(%struct.State*, i64, %struct.Memory* readnone) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400e70_makewt(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: nounwind
define internal void @__mcsema_constructor() #14 {
  %1 = load volatile i1, i1* @0, align 1
  br i1 %1, label %__mcsema_early_init.exit, label %2

; <label>:2:                                      ; preds = %0
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %0, %2
  tail call void @callback_sub_404020___libc_csu_init()
  ret void
}

; Function Attrs: nounwind
define internal void @__mcsema_destructor() #14 {
  tail call void @callback_sub_404090___libc_csu_fini()
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i32, i1) #15

attributes #0 = { nounwind readnone }
attributes #1 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind readnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { noinline }
attributes #7 = { noinline nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { noinline "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { noinline norecurse nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #10 = { naked nobuiltin noinline nounwind }
attributes #11 = { alwaysinline inlinehint nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #12 = { norecurse nounwind }
attributes #13 = { noinline nounwind }
attributes #14 = { nounwind }
attributes #15 = { argmemonly nounwind }
attributes #16 = { alwaysinline nobuiltin nounwind }

!llvm.ident = !{!0, !0}
!llvm.dbg.cu = !{!1}
!llvm.module.flags = !{!1259, !1260}

!0 = !{!"clang version 4.0.1 (tags/RELEASE_401/final)"}
!1 = distinct !DICompileUnit(language: DW_LANG_C_plus_plus, file: !2, producer: "clang version 4.0.1 (tags/RELEASE_401/final)", isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug, enums: !3, retainedTypes: !67, imports: !70)
!2 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/X86/Runtime/BasicBlock.cpp", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!3 = !{!4, !26, !35, !39, !45, !51, !55, !61}
!4 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "Name", scope: !6, file: !5, line: 70, baseType: !8, size: 32, elements: !11, identifier: "_ZTSN14AsyncHyperCall4NameE")
!5 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/HyperCall.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!6 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "AsyncHyperCall", file: !5, line: 68, size: 8, elements: !7, identifier: "_ZTS14AsyncHyperCall")
!7 = !{}
!8 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint32_t", file: !9, line: 183, baseType: !10)
!9 = !DIFile(filename: "/home/ubuntu/Github/remill/remill-build/libraries/llvm/bin/../lib/clang/4.0.1/include/stdint.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!10 = !DIBasicType(name: "unsigned int", size: 32, encoding: DW_ATE_unsigned)
!11 = !{!12, !13, !14, !15, !16, !17, !18, !19, !20, !21, !22, !23, !24, !25}
!12 = !DIEnumerator(name: "kInvalid", value: 0)
!13 = !DIEnumerator(name: "kX86Int1", value: 1)
!14 = !DIEnumerator(name: "kX86Int3", value: 2)
!15 = !DIEnumerator(name: "kX86IntO", value: 3)
!16 = !DIEnumerator(name: "kX86IntN", value: 4)
!17 = !DIEnumerator(name: "kX86Bound", value: 5)
!18 = !DIEnumerator(name: "kX86IRet", value: 6)
!19 = !DIEnumerator(name: "kX86SysCall", value: 7)
!20 = !DIEnumerator(name: "kX86SysRet", value: 8)
!21 = !DIEnumerator(name: "kX86SysEnter", value: 9)
!22 = !DIEnumerator(name: "kX86SysExit", value: 10)
!23 = !DIEnumerator(name: "kX86JmpFar", value: 11)
!24 = !DIEnumerator(name: "kAArch64SupervisorCall", value: 12)
!25 = !DIEnumerator(name: "kInvalidInstruction", value: 13)
!26 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "RequestPrivilegeLevel", file: !27, line: 64, baseType: !28, size: 16, elements: !30, identifier: "_ZTS21RequestPrivilegeLevel")
!27 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/X86/Runtime/State.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!28 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint16_t", file: !9, line: 218, baseType: !29)
!29 = !DIBasicType(name: "unsigned short", size: 16, encoding: DW_ATE_unsigned)
!30 = !{!31, !32, !33, !34}
!31 = !DIEnumerator(name: "kRPLRingZero", value: 0)
!32 = !DIEnumerator(name: "kRPLRingOne", value: 1)
!33 = !DIEnumerator(name: "kRPLRingTwo", value: 2)
!34 = !DIEnumerator(name: "kRPLRingThree", value: 3)
!35 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "TableIndicator", file: !27, line: 71, baseType: !28, size: 16, elements: !36, identifier: "_ZTS14TableIndicator")
!36 = !{!37, !38}
!37 = !DIEnumerator(name: "kGlobalDescriptorTable", value: 0)
!38 = !DIEnumerator(name: "kLocalDescriptorTable", value: 1)
!39 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUPrecisionControl", file: !27, line: 123, baseType: !28, size: 16, elements: !40, identifier: "_ZTS19FPUPrecisionControl")
!40 = !{!41, !42, !43, !44}
!41 = !DIEnumerator(name: "kPrecisionSingle", value: 0)
!42 = !DIEnumerator(name: "kPrecisionReserved", value: 1)
!43 = !DIEnumerator(name: "kPrecisionDouble", value: 2)
!44 = !DIEnumerator(name: "kPrecisionExtended", value: 3)
!45 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPURoundingControl", file: !27, line: 130, baseType: !28, size: 16, elements: !46, identifier: "_ZTS18FPURoundingControl")
!46 = !{!47, !48, !49, !50}
!47 = !DIEnumerator(name: "kFPURoundToNearestEven", value: 0)
!48 = !DIEnumerator(name: "kFPURoundDownNegInf", value: 1)
!49 = !DIEnumerator(name: "kFPURoundUpInf", value: 2)
!50 = !DIEnumerator(name: "kFPURoundToZero", value: 3)
!51 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUInfinityControl", file: !27, line: 137, baseType: !28, size: 16, elements: !52, identifier: "_ZTS18FPUInfinityControl")
!52 = !{!53, !54}
!53 = !DIEnumerator(name: "kInfinityProjective", value: 0)
!54 = !DIEnumerator(name: "kInfinityAffine", value: 1)
!55 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUTag", file: !27, line: 214, baseType: !28, size: 16, elements: !56, identifier: "_ZTS6FPUTag")
!56 = !{!57, !58, !59, !60}
!57 = !DIEnumerator(name: "kFPUTagNonZero", value: 0)
!58 = !DIEnumerator(name: "kFPUTagZero", value: 1)
!59 = !DIEnumerator(name: "kFPUTagSpecial", value: 2)
!60 = !DIEnumerator(name: "kFPUTagEmpty", value: 3)
!61 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUAbridgedTag", file: !27, line: 221, baseType: !62, size: 8, elements: !64, identifier: "_ZTS14FPUAbridgedTag")
!62 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint8_t", file: !9, line: 237, baseType: !63)
!63 = !DIBasicType(name: "unsigned char", size: 8, encoding: DW_ATE_unsigned_char)
!64 = !{!65, !66}
!65 = !DIEnumerator(name: "kFPUAbridgedTagEmpty", value: 0)
!66 = !DIEnumerator(name: "kFPUAbridgedTagValid", value: 1)
!67 = !{!68}
!68 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !69, size: 64)
!69 = !DIDerivedType(tag: DW_TAG_const_type, baseType: null)
!70 = !{!71, !77, !83, !86, !93, !97, !102, !104, !112, !116, !120, !132, !136, !140, !144, !148, !153, !157, !161, !165, !169, !177, !181, !185, !187, !191, !195, !199, !205, !209, !213, !215, !223, !227, !235, !237, !241, !245, !249, !253, !258, !263, !268, !269, !270, !271, !274, !275, !276, !277, !278, !279, !280, !335, !339, !355, !358, !363, !371, !376, !380, !384, !388, !392, !394, !396, !400, !406, !410, !416, !422, !424, !428, !432, !436, !440, !451, !453, !457, !461, !465, !467, !471, !475, !479, !481, !483, !487, !495, !499, !503, !507, !509, !515, !517, !523, !527, !531, !535, !539, !543, !547, !549, !551, !555, !559, !563, !565, !569, !573, !575, !577, !581, !585, !589, !593, !594, !595, !596, !597, !598, !599, !600, !601, !602, !603, !606, !609, !611, !613, !615, !617, !619, !621, !623, !625, !627, !629, !631, !633, !634, !635, !636, !638, !640, !642, !644, !646, !648, !650, !652, !654, !656, !658, !660, !662, !665, !669, !674, !677, !679, !681, !683, !685, !687, !689, !691, !693, !695, !697, !699, !701, !703, !706, !712, !717, !721, !723, !725, !727, !729, !736, !740, !744, !748, !752, !756, !761, !765, !767, !771, !777, !781, !786, !788, !790, !794, !798, !802, !804, !806, !808, !810, !814, !816, !818, !822, !826, !830, !834, !838, !840, !842, !846, !850, !854, !858, !860, !862, !866, !870, !871, !872, !873, !874, !875, !880, !882, !884, !888, !890, !892, !894, !896, !898, !900, !902, !907, !911, !913, !915, !920, !922, !924, !926, !928, !930, !932, !935, !937, !939, !943, !947, !949, !951, !953, !955, !957, !959, !961, !963, !965, !967, !971, !975, !977, !979, !981, !983, !985, !987, !989, !991, !993, !995, !997, !999, !1001, !1003, !1005, !1009, !1013, !1017, !1019, !1021, !1023, !1025, !1027, !1029, !1031, !1033, !1035, !1039, !1043, !1047, !1049, !1051, !1053, !1057, !1061, !1065, !1067, !1069, !1071, !1073, !1075, !1077, !1079, !1081, !1083, !1085, !1087, !1089, !1093, !1097, !1101, !1103, !1105, !1107, !1109, !1113, !1117, !1119, !1121, !1123, !1125, !1127, !1129, !1133, !1137, !1139, !1141, !1143, !1145, !1149, !1153, !1157, !1159, !1161, !1163, !1165, !1167, !1169, !1173, !1177, !1181, !1183, !1187, !1191, !1193, !1195, !1197, !1199, !1201, !1203, !1207, !1209, !1212, !1217, !1219, !1225, !1227, !1229, !1231, !1236, !1238, !1244, !1246, !1247, !1248, !1249, !1250, !1251, !1252, !1253, !1254, !1255, !1256, !1257, !1258}
!71 = !DIImportedEntity(tag: DW_TAG_imported_module, scope: !72, entity: !74, line: 58)
!72 = !DINamespace(name: "__gnu_debug", scope: null, file: !73, line: 56)
!73 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/debug/debug.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!74 = !DINamespace(name: "__debug", scope: !75, file: !73, line: 50)
!75 = !DINamespace(name: "std", scope: null, file: !76, line: 229)
!76 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/x86_64-linux-gnu/c++/7.4.0/bits/c++config.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!77 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !78, line: 52)
!78 = !DISubprogram(name: "abs", scope: !79, file: !79, line: 837, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!79 = !DIFile(filename: "/usr/include/stdlib.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!80 = !DISubroutineType(types: !81)
!81 = !{!82, !82}
!82 = !DIBasicType(name: "int", size: 32, encoding: DW_ATE_signed)
!83 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !84, line: 127)
!84 = !DIDerivedType(tag: DW_TAG_typedef, name: "div_t", file: !79, line: 62, baseType: !85)
!85 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 58, flags: DIFlagFwdDecl, identifier: "_ZTS5div_t")
!86 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !87, line: 128)
!87 = !DIDerivedType(tag: DW_TAG_typedef, name: "ldiv_t", file: !79, line: 70, baseType: !88)
!88 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 66, size: 128, elements: !89, identifier: "_ZTS6ldiv_t")
!89 = !{!90, !92}
!90 = !DIDerivedType(tag: DW_TAG_member, name: "quot", scope: !88, file: !79, line: 68, baseType: !91, size: 64)
!91 = !DIBasicType(name: "long int", size: 64, encoding: DW_ATE_signed)
!92 = !DIDerivedType(tag: DW_TAG_member, name: "rem", scope: !88, file: !79, line: 69, baseType: !91, size: 64, offset: 64)
!93 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !94, line: 130)
!94 = !DISubprogram(name: "abort", scope: !79, file: !79, line: 588, type: !95, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!95 = !DISubroutineType(types: !96)
!96 = !{null}
!97 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !98, line: 134)
!98 = !DISubprogram(name: "atexit", scope: !79, file: !79, line: 592, type: !99, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!99 = !DISubroutineType(types: !100)
!100 = !{!82, !101}
!101 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !95, size: 64)
!102 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !103, line: 137)
!103 = !DISubprogram(name: "at_quick_exit", scope: !79, file: !79, line: 597, type: !99, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!104 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !105, line: 140)
!105 = !DISubprogram(name: "atof", scope: !79, file: !79, line: 101, type: !106, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!106 = !DISubroutineType(types: !107)
!107 = !{!108, !109}
!108 = !DIBasicType(name: "double", size: 64, encoding: DW_ATE_float)
!109 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !110, size: 64)
!110 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !111)
!111 = !DIBasicType(name: "char", size: 8, encoding: DW_ATE_signed_char)
!112 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !113, line: 141)
!113 = !DISubprogram(name: "atoi", scope: !79, file: !79, line: 104, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!114 = !DISubroutineType(types: !115)
!115 = !{!82, !109}
!116 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !117, line: 142)
!117 = !DISubprogram(name: "atol", scope: !79, file: !79, line: 107, type: !118, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!118 = !DISubroutineType(types: !119)
!119 = !{!91, !109}
!120 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !121, line: 143)
!121 = !DISubprogram(name: "bsearch", scope: !79, file: !79, line: 817, type: !122, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!122 = !DISubroutineType(types: !123)
!123 = !{!124, !68, !68, !125, !125, !128}
!124 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: null, size: 64)
!125 = !DIDerivedType(tag: DW_TAG_typedef, name: "size_t", file: !126, line: 62, baseType: !127)
!126 = !DIFile(filename: "/home/ubuntu/Github/remill/remill-build/libraries/llvm/bin/../lib/clang/4.0.1/include/stddef.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!127 = !DIBasicType(name: "long unsigned int", size: 64, encoding: DW_ATE_unsigned)
!128 = !DIDerivedType(tag: DW_TAG_typedef, name: "__compar_fn_t", file: !79, line: 805, baseType: !129)
!129 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !130, size: 64)
!130 = !DISubroutineType(types: !131)
!131 = !{!82, !68, !68}
!132 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !133, line: 144)
!133 = !DISubprogram(name: "calloc", scope: !79, file: !79, line: 541, type: !134, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!134 = !DISubroutineType(types: !135)
!135 = !{!124, !125, !125}
!136 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !137, line: 145)
!137 = !DISubprogram(name: "div", scope: !79, file: !79, line: 849, type: !138, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!138 = !DISubroutineType(types: !139)
!139 = !{!84, !82, !82}
!140 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !141, line: 146)
!141 = !DISubprogram(name: "exit", scope: !79, file: !79, line: 614, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!142 = !DISubroutineType(types: !143)
!143 = !{null, !82}
!144 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !145, line: 147)
!145 = !DISubprogram(name: "free", scope: !79, file: !79, line: 563, type: !146, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!146 = !DISubroutineType(types: !147)
!147 = !{null, !124}
!148 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !149, line: 148)
!149 = !DISubprogram(name: "getenv", scope: !79, file: !79, line: 631, type: !150, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!150 = !DISubroutineType(types: !151)
!151 = !{!152, !109}
!152 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !111, size: 64)
!153 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !154, line: 149)
!154 = !DISubprogram(name: "labs", scope: !79, file: !79, line: 838, type: !155, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!155 = !DISubroutineType(types: !156)
!156 = !{!91, !91}
!157 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !158, line: 150)
!158 = !DISubprogram(name: "ldiv", scope: !79, file: !79, line: 851, type: !159, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!159 = !DISubroutineType(types: !160)
!160 = !{!87, !91, !91}
!161 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !162, line: 151)
!162 = !DISubprogram(name: "malloc", scope: !79, file: !79, line: 539, type: !163, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!163 = !DISubroutineType(types: !164)
!164 = !{!124, !125}
!165 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !166, line: 153)
!166 = !DISubprogram(name: "mblen", scope: !79, file: !79, line: 919, type: !167, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!167 = !DISubroutineType(types: !168)
!168 = !{!82, !109, !125}
!169 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !170, line: 154)
!170 = !DISubprogram(name: "mbstowcs", scope: !79, file: !79, line: 930, type: !171, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!171 = !DISubroutineType(types: !172)
!172 = !{!125, !173, !176, !125}
!173 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !174)
!174 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !175, size: 64)
!175 = !DIBasicType(name: "wchar_t", size: 32, encoding: DW_ATE_signed)
!176 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !109)
!177 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !178, line: 155)
!178 = !DISubprogram(name: "mbtowc", scope: !79, file: !79, line: 922, type: !179, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!179 = !DISubroutineType(types: !180)
!180 = !{!82, !173, !176, !125}
!181 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !182, line: 157)
!182 = !DISubprogram(name: "qsort", scope: !79, file: !79, line: 827, type: !183, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!183 = !DISubroutineType(types: !184)
!184 = !{null, !124, !125, !125, !128}
!185 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !186, line: 160)
!186 = !DISubprogram(name: "quick_exit", scope: !79, file: !79, line: 620, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!187 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !188, line: 163)
!188 = !DISubprogram(name: "rand", scope: !79, file: !79, line: 453, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!189 = !DISubroutineType(types: !190)
!190 = !{!82}
!191 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !192, line: 164)
!192 = !DISubprogram(name: "realloc", scope: !79, file: !79, line: 549, type: !193, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!193 = !DISubroutineType(types: !194)
!194 = !{!124, !124, !125}
!195 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !196, line: 165)
!196 = !DISubprogram(name: "srand", scope: !79, file: !79, line: 455, type: !197, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!197 = !DISubroutineType(types: !198)
!198 = !{null, !10}
!199 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !200, line: 166)
!200 = !DISubprogram(name: "strtod", scope: !79, file: !79, line: 117, type: !201, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!201 = !DISubroutineType(types: !202)
!202 = !{!108, !176, !203}
!203 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !204)
!204 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !152, size: 64)
!205 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !206, line: 167)
!206 = !DISubprogram(name: "strtol", scope: !79, file: !79, line: 176, type: !207, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!207 = !DISubroutineType(types: !208)
!208 = !{!91, !176, !203, !82}
!209 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !210, line: 168)
!210 = !DISubprogram(name: "strtoul", scope: !79, file: !79, line: 180, type: !211, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!211 = !DISubroutineType(types: !212)
!212 = !{!127, !176, !203, !82}
!213 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !214, line: 169)
!214 = !DISubprogram(name: "system", scope: !79, file: !79, line: 781, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!215 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !216, line: 171)
!216 = !DISubprogram(name: "wcstombs", scope: !79, file: !79, line: 933, type: !217, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!217 = !DISubroutineType(types: !218)
!218 = !{!125, !219, !220, !125}
!219 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !152)
!220 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !221)
!221 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !222, size: 64)
!222 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !175)
!223 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !224, line: 172)
!224 = !DISubprogram(name: "wctomb", scope: !79, file: !79, line: 926, type: !225, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!225 = !DISubroutineType(types: !226)
!226 = !{!82, !152, !175}
!227 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !229, line: 200)
!228 = !DINamespace(name: "__gnu_cxx", scope: null, file: !76, line: 255)
!229 = !DIDerivedType(tag: DW_TAG_typedef, name: "lldiv_t", file: !79, line: 80, baseType: !230)
!230 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 76, size: 128, elements: !231, identifier: "_ZTS7lldiv_t")
!231 = !{!232, !234}
!232 = !DIDerivedType(tag: DW_TAG_member, name: "quot", scope: !230, file: !79, line: 78, baseType: !233, size: 64)
!233 = !DIBasicType(name: "long long int", size: 64, encoding: DW_ATE_signed)
!234 = !DIDerivedType(tag: DW_TAG_member, name: "rem", scope: !230, file: !79, line: 79, baseType: !233, size: 64, offset: 64)
!235 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !236, line: 206)
!236 = !DISubprogram(name: "_Exit", scope: !79, file: !79, line: 626, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!237 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !238, line: 210)
!238 = !DISubprogram(name: "llabs", scope: !79, file: !79, line: 841, type: !239, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!239 = !DISubroutineType(types: !240)
!240 = !{!233, !233}
!241 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !242, line: 216)
!242 = !DISubprogram(name: "lldiv", scope: !79, file: !79, line: 855, type: !243, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!243 = !DISubroutineType(types: !244)
!244 = !{!229, !233, !233}
!245 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !246, line: 227)
!246 = !DISubprogram(name: "atoll", scope: !79, file: !79, line: 112, type: !247, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!247 = !DISubroutineType(types: !248)
!248 = !{!233, !109}
!249 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !250, line: 228)
!250 = !DISubprogram(name: "strtoll", scope: !79, file: !79, line: 200, type: !251, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!251 = !DISubroutineType(types: !252)
!252 = !{!233, !176, !203, !82}
!253 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !254, line: 229)
!254 = !DISubprogram(name: "strtoull", scope: !79, file: !79, line: 205, type: !255, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!255 = !DISubroutineType(types: !256)
!256 = !{!257, !176, !203, !82}
!257 = !DIBasicType(name: "long long unsigned int", size: 64, encoding: DW_ATE_unsigned)
!258 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !259, line: 231)
!259 = !DISubprogram(name: "strtof", scope: !79, file: !79, line: 123, type: !260, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!260 = !DISubroutineType(types: !261)
!261 = !{!262, !176, !203}
!262 = !DIBasicType(name: "float", size: 32, encoding: DW_ATE_float)
!263 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !264, line: 232)
!264 = !DISubprogram(name: "strtold", scope: !79, file: !79, line: 126, type: !265, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!265 = !DISubroutineType(types: !266)
!266 = !{!267, !176, !203}
!267 = !DIBasicType(name: "long double", size: 128, encoding: DW_ATE_float)
!268 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !229, line: 240)
!269 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !236, line: 242)
!270 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !238, line: 244)
!271 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !272, line: 245)
!272 = !DISubprogram(name: "div", linkageName: "_ZN9__gnu_cxx3divExx", scope: !228, file: !273, line: 213, type: !243, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!273 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/cstdlib", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!274 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !242, line: 246)
!275 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !246, line: 248)
!276 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !259, line: 249)
!277 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !250, line: 250)
!278 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !254, line: 251)
!279 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !264, line: 252)
!280 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !281, line: 57)
!281 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "exception_ptr", scope: !283, file: !282, line: 79, size: 64, elements: !284, identifier: "_ZTSNSt15__exception_ptr13exception_ptrE")
!282 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/bits/exception_ptr.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!283 = !DINamespace(name: "__exception_ptr", scope: !75, file: !282, line: 52)
!284 = !{!285, !286, !290, !293, !294, !299, !300, !304, !309, !313, !317, !320, !321, !324, !328}
!285 = !DIDerivedType(tag: DW_TAG_member, name: "_M_exception_object", scope: !281, file: !282, line: 81, baseType: !124, size: 64)
!286 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 83, type: !287, isLocal: false, isDefinition: false, scopeLine: 83, flags: DIFlagExplicit | DIFlagPrototyped, isOptimized: false)
!287 = !DISubroutineType(types: !288)
!288 = !{null, !289, !124}
!289 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !281, size: 64, flags: DIFlagArtificial | DIFlagObjectPointer)
!290 = !DISubprogram(name: "_M_addref", linkageName: "_ZNSt15__exception_ptr13exception_ptr9_M_addrefEv", scope: !281, file: !282, line: 85, type: !291, isLocal: false, isDefinition: false, scopeLine: 85, flags: DIFlagPrototyped, isOptimized: false)
!291 = !DISubroutineType(types: !292)
!292 = !{null, !289}
!293 = !DISubprogram(name: "_M_release", linkageName: "_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv", scope: !281, file: !282, line: 86, type: !291, isLocal: false, isDefinition: false, scopeLine: 86, flags: DIFlagPrototyped, isOptimized: false)
!294 = !DISubprogram(name: "_M_get", linkageName: "_ZNKSt15__exception_ptr13exception_ptr6_M_getEv", scope: !281, file: !282, line: 88, type: !295, isLocal: false, isDefinition: false, scopeLine: 88, flags: DIFlagPrototyped, isOptimized: false)
!295 = !DISubroutineType(types: !296)
!296 = !{!124, !297}
!297 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !298, size: 64, flags: DIFlagArtificial | DIFlagObjectPointer)
!298 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !281)
!299 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 96, type: !291, isLocal: false, isDefinition: false, scopeLine: 96, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!300 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 98, type: !301, isLocal: false, isDefinition: false, scopeLine: 98, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!301 = !DISubroutineType(types: !302)
!302 = !{null, !289, !303}
!303 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !298, size: 64)
!304 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 101, type: !305, isLocal: false, isDefinition: false, scopeLine: 101, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!305 = !DISubroutineType(types: !306)
!306 = !{null, !289, !307}
!307 = !DIDerivedType(tag: DW_TAG_typedef, name: "nullptr_t", scope: !75, file: !76, line: 235, baseType: !308)
!308 = !DIBasicType(tag: DW_TAG_unspecified_type, name: "decltype(nullptr)")
!309 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 105, type: !310, isLocal: false, isDefinition: false, scopeLine: 105, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!310 = !DISubroutineType(types: !311)
!311 = !{null, !289, !312}
!312 = !DIDerivedType(tag: DW_TAG_rvalue_reference_type, baseType: !281, size: 64)
!313 = !DISubprogram(name: "operator=", linkageName: "_ZNSt15__exception_ptr13exception_ptraSERKS0_", scope: !281, file: !282, line: 118, type: !314, isLocal: false, isDefinition: false, scopeLine: 118, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!314 = !DISubroutineType(types: !315)
!315 = !{!316, !289, !303}
!316 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !281, size: 64)
!317 = !DISubprogram(name: "operator=", linkageName: "_ZNSt15__exception_ptr13exception_ptraSEOS0_", scope: !281, file: !282, line: 122, type: !318, isLocal: false, isDefinition: false, scopeLine: 122, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!318 = !DISubroutineType(types: !319)
!319 = !{!316, !289, !312}
!320 = !DISubprogram(name: "~exception_ptr", scope: !281, file: !282, line: 129, type: !291, isLocal: false, isDefinition: false, scopeLine: 129, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!321 = !DISubprogram(name: "swap", linkageName: "_ZNSt15__exception_ptr13exception_ptr4swapERS0_", scope: !281, file: !282, line: 132, type: !322, isLocal: false, isDefinition: false, scopeLine: 132, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!322 = !DISubroutineType(types: !323)
!323 = !{null, !289, !316}
!324 = !DISubprogram(name: "operator bool", linkageName: "_ZNKSt15__exception_ptr13exception_ptrcvbEv", scope: !281, file: !282, line: 144, type: !325, isLocal: false, isDefinition: false, scopeLine: 144, flags: DIFlagPublic | DIFlagExplicit | DIFlagPrototyped, isOptimized: false)
!325 = !DISubroutineType(types: !326)
!326 = !{!327, !297}
!327 = !DIBasicType(name: "bool", size: 8, encoding: DW_ATE_boolean)
!328 = !DISubprogram(name: "__cxa_exception_type", linkageName: "_ZNKSt15__exception_ptr13exception_ptr20__cxa_exception_typeEv", scope: !281, file: !282, line: 153, type: !329, isLocal: false, isDefinition: false, scopeLine: 153, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!329 = !DISubroutineType(types: !330)
!330 = !{!331, !297}
!331 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !332, size: 64)
!332 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !333)
!333 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "type_info", scope: !75, file: !334, line: 88, flags: DIFlagFwdDecl, identifier: "_ZTSSt9type_info")
!334 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/typeinfo", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!335 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !283, entity: !336, line: 73)
!336 = !DISubprogram(name: "rethrow_exception", linkageName: "_ZSt17rethrow_exceptionNSt15__exception_ptr13exception_ptrE", scope: !75, file: !282, line: 69, type: !337, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!337 = !DISubroutineType(types: !338)
!338 = !{null, !281}
!339 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !340, line: 64)
!340 = !DIDerivedType(tag: DW_TAG_typedef, name: "mbstate_t", file: !341, line: 6, baseType: !342)
!341 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/mbstate_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!342 = !DIDerivedType(tag: DW_TAG_typedef, name: "__mbstate_t", file: !343, line: 21, baseType: !344)
!343 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/__mbstate_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!344 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !343, line: 13, size: 64, elements: !345, identifier: "_ZTS11__mbstate_t")
!345 = !{!346, !347}
!346 = !DIDerivedType(tag: DW_TAG_member, name: "__count", scope: !344, file: !343, line: 15, baseType: !82, size: 32)
!347 = !DIDerivedType(tag: DW_TAG_member, name: "__value", scope: !344, file: !343, line: 20, baseType: !348, size: 32, offset: 32)
!348 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !344, file: !343, line: 16, size: 32, elements: !349, identifier: "_ZTSN11__mbstate_tUt_E")
!349 = !{!350, !351}
!350 = !DIDerivedType(tag: DW_TAG_member, name: "__wch", scope: !348, file: !343, line: 18, baseType: !10, size: 32)
!351 = !DIDerivedType(tag: DW_TAG_member, name: "__wchb", scope: !348, file: !343, line: 19, baseType: !352, size: 32)
!352 = !DICompositeType(tag: DW_TAG_array_type, baseType: !111, size: 32, elements: !353)
!353 = !{!354}
!354 = !DISubrange(count: 4)
!355 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !356, line: 139)
!356 = !DIDerivedType(tag: DW_TAG_typedef, name: "wint_t", file: !357, line: 20, baseType: !10)
!357 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/wint_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!358 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !359, line: 141)
!359 = !DISubprogram(name: "btowc", scope: !360, file: !360, line: 284, type: !361, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!360 = !DIFile(filename: "/usr/include/wchar.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!361 = !DISubroutineType(types: !362)
!362 = !{!356, !82}
!363 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !364, line: 142)
!364 = !DISubprogram(name: "fgetwc", scope: !360, file: !360, line: 727, type: !365, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!365 = !DISubroutineType(types: !366)
!366 = !{!356, !367}
!367 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !368, size: 64)
!368 = !DIDerivedType(tag: DW_TAG_typedef, name: "__FILE", file: !369, line: 5, baseType: !370)
!369 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/__FILE.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!370 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "_IO_FILE", file: !369, line: 4, flags: DIFlagFwdDecl, identifier: "_ZTS8_IO_FILE")
!371 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !372, line: 143)
!372 = !DISubprogram(name: "fgetws", scope: !360, file: !360, line: 756, type: !373, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!373 = !DISubroutineType(types: !374)
!374 = !{!174, !173, !82, !375}
!375 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !367)
!376 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !377, line: 144)
!377 = !DISubprogram(name: "fputwc", scope: !360, file: !360, line: 741, type: !378, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!378 = !DISubroutineType(types: !379)
!379 = !{!356, !175, !367}
!380 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !381, line: 145)
!381 = !DISubprogram(name: "fputws", scope: !360, file: !360, line: 763, type: !382, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!382 = !DISubroutineType(types: !383)
!383 = !{!82, !220, !375}
!384 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !385, line: 146)
!385 = !DISubprogram(name: "fwide", scope: !360, file: !360, line: 573, type: !386, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!386 = !DISubroutineType(types: !387)
!387 = !{!82, !367, !82}
!388 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !389, line: 147)
!389 = !DISubprogram(name: "fwprintf", scope: !360, file: !360, line: 580, type: !390, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!390 = !DISubroutineType(types: !391)
!391 = !{!82, !375, !220, null}
!392 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !393, line: 148)
!393 = !DISubprogram(name: "fwscanf", scope: !360, file: !360, line: 621, type: !390, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!394 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !395, line: 149)
!395 = !DISubprogram(name: "getwc", scope: !360, file: !360, line: 728, type: !365, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!396 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !397, line: 150)
!397 = !DISubprogram(name: "getwchar", scope: !360, file: !360, line: 734, type: !398, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!398 = !DISubroutineType(types: !399)
!399 = !{!356}
!400 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !401, line: 151)
!401 = !DISubprogram(name: "mbrlen", scope: !360, file: !360, line: 307, type: !402, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!402 = !DISubroutineType(types: !403)
!403 = !{!125, !176, !125, !404}
!404 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !405)
!405 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !340, size: 64)
!406 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !407, line: 152)
!407 = !DISubprogram(name: "mbrtowc", scope: !360, file: !360, line: 296, type: !408, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!408 = !DISubroutineType(types: !409)
!409 = !{!125, !173, !176, !125, !404}
!410 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !411, line: 153)
!411 = !DISubprogram(name: "mbsinit", scope: !360, file: !360, line: 292, type: !412, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!412 = !DISubroutineType(types: !413)
!413 = !{!82, !414}
!414 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !415, size: 64)
!415 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !340)
!416 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !417, line: 154)
!417 = !DISubprogram(name: "mbsrtowcs", scope: !360, file: !360, line: 337, type: !418, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!418 = !DISubroutineType(types: !419)
!419 = !{!125, !173, !420, !125, !404}
!420 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !421)
!421 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !109, size: 64)
!422 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !423, line: 155)
!423 = !DISubprogram(name: "putwc", scope: !360, file: !360, line: 742, type: !378, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!424 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !425, line: 156)
!425 = !DISubprogram(name: "putwchar", scope: !360, file: !360, line: 748, type: !426, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!426 = !DISubroutineType(types: !427)
!427 = !{!356, !175}
!428 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !429, line: 158)
!429 = !DISubprogram(name: "swprintf", scope: !360, file: !360, line: 590, type: !430, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!430 = !DISubroutineType(types: !431)
!431 = !{!82, !173, !125, !220, null}
!432 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !433, line: 160)
!433 = !DISubprogram(name: "swscanf", scope: !360, file: !360, line: 631, type: !434, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!434 = !DISubroutineType(types: !435)
!435 = !{!82, !220, !220, null}
!436 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !437, line: 161)
!437 = !DISubprogram(name: "ungetwc", scope: !360, file: !360, line: 771, type: !438, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!438 = !DISubroutineType(types: !439)
!439 = !{!356, !356, !367}
!440 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !441, line: 162)
!441 = !DISubprogram(name: "vfwprintf", scope: !360, file: !360, line: 598, type: !442, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!442 = !DISubroutineType(types: !443)
!443 = !{!82, !375, !220, !444}
!444 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !445, size: 64)
!445 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "__va_list_tag", file: !2, size: 192, elements: !446, identifier: "_ZTS13__va_list_tag")
!446 = !{!447, !448, !449, !450}
!447 = !DIDerivedType(tag: DW_TAG_member, name: "gp_offset", scope: !445, file: !2, baseType: !10, size: 32)
!448 = !DIDerivedType(tag: DW_TAG_member, name: "fp_offset", scope: !445, file: !2, baseType: !10, size: 32, offset: 32)
!449 = !DIDerivedType(tag: DW_TAG_member, name: "overflow_arg_area", scope: !445, file: !2, baseType: !124, size: 64, offset: 64)
!450 = !DIDerivedType(tag: DW_TAG_member, name: "reg_save_area", scope: !445, file: !2, baseType: !124, size: 64, offset: 128)
!451 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !452, line: 164)
!452 = !DISubprogram(name: "vfwscanf", scope: !360, file: !360, line: 673, type: !442, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!453 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !454, line: 167)
!454 = !DISubprogram(name: "vswprintf", scope: !360, file: !360, line: 611, type: !455, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!455 = !DISubroutineType(types: !456)
!456 = !{!82, !173, !125, !220, !444}
!457 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !458, line: 170)
!458 = !DISubprogram(name: "vswscanf", scope: !360, file: !360, line: 685, type: !459, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!459 = !DISubroutineType(types: !460)
!460 = !{!82, !220, !220, !444}
!461 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !462, line: 172)
!462 = !DISubprogram(name: "vwprintf", scope: !360, file: !360, line: 606, type: !463, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!463 = !DISubroutineType(types: !464)
!464 = !{!82, !220, !444}
!465 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !466, line: 174)
!466 = !DISubprogram(name: "vwscanf", scope: !360, file: !360, line: 681, type: !463, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!467 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !468, line: 176)
!468 = !DISubprogram(name: "wcrtomb", scope: !360, file: !360, line: 301, type: !469, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!469 = !DISubroutineType(types: !470)
!470 = !{!125, !219, !175, !404}
!471 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !472, line: 177)
!472 = !DISubprogram(name: "wcscat", scope: !360, file: !360, line: 97, type: !473, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!473 = !DISubroutineType(types: !474)
!474 = !{!174, !173, !220}
!475 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !476, line: 178)
!476 = !DISubprogram(name: "wcscmp", scope: !360, file: !360, line: 106, type: !477, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!477 = !DISubroutineType(types: !478)
!478 = !{!82, !221, !221}
!479 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !480, line: 179)
!480 = !DISubprogram(name: "wcscoll", scope: !360, file: !360, line: 131, type: !477, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!481 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !482, line: 180)
!482 = !DISubprogram(name: "wcscpy", scope: !360, file: !360, line: 87, type: !473, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!483 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !484, line: 181)
!484 = !DISubprogram(name: "wcscspn", scope: !360, file: !360, line: 187, type: !485, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!485 = !DISubroutineType(types: !486)
!486 = !{!125, !221, !221}
!487 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !488, line: 182)
!488 = !DISubprogram(name: "wcsftime", scope: !360, file: !360, line: 835, type: !489, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!489 = !DISubroutineType(types: !490)
!490 = !{!125, !173, !125, !220, !491}
!491 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !492)
!492 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !493, size: 64)
!493 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !494)
!494 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "tm", file: !360, line: 83, flags: DIFlagFwdDecl, identifier: "_ZTS2tm")
!495 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !496, line: 183)
!496 = !DISubprogram(name: "wcslen", scope: !360, file: !360, line: 222, type: !497, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!497 = !DISubroutineType(types: !498)
!498 = !{!125, !221}
!499 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !500, line: 184)
!500 = !DISubprogram(name: "wcsncat", scope: !360, file: !360, line: 101, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!501 = !DISubroutineType(types: !502)
!502 = !{!174, !173, !220, !125}
!503 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !504, line: 185)
!504 = !DISubprogram(name: "wcsncmp", scope: !360, file: !360, line: 109, type: !505, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!505 = !DISubroutineType(types: !506)
!506 = !{!82, !221, !221, !125}
!507 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !508, line: 186)
!508 = !DISubprogram(name: "wcsncpy", scope: !360, file: !360, line: 92, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!509 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !510, line: 187)
!510 = !DISubprogram(name: "wcsrtombs", scope: !360, file: !360, line: 343, type: !511, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!511 = !DISubroutineType(types: !512)
!512 = !{!125, !219, !513, !125, !404}
!513 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !514)
!514 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !221, size: 64)
!515 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !516, line: 188)
!516 = !DISubprogram(name: "wcsspn", scope: !360, file: !360, line: 191, type: !485, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!517 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !518, line: 189)
!518 = !DISubprogram(name: "wcstod", scope: !360, file: !360, line: 377, type: !519, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!519 = !DISubroutineType(types: !520)
!520 = !{!108, !220, !521}
!521 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !522)
!522 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !174, size: 64)
!523 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !524, line: 191)
!524 = !DISubprogram(name: "wcstof", scope: !360, file: !360, line: 382, type: !525, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!525 = !DISubroutineType(types: !526)
!526 = !{!262, !220, !521}
!527 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !528, line: 193)
!528 = !DISubprogram(name: "wcstok", scope: !360, file: !360, line: 217, type: !529, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!529 = !DISubroutineType(types: !530)
!530 = !{!174, !173, !220, !521}
!531 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !532, line: 194)
!532 = !DISubprogram(name: "wcstol", scope: !360, file: !360, line: 428, type: !533, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!533 = !DISubroutineType(types: !534)
!534 = !{!91, !220, !521, !82}
!535 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !536, line: 195)
!536 = !DISubprogram(name: "wcstoul", scope: !360, file: !360, line: 433, type: !537, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!537 = !DISubroutineType(types: !538)
!538 = !{!127, !220, !521, !82}
!539 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !540, line: 196)
!540 = !DISubprogram(name: "wcsxfrm", scope: !360, file: !360, line: 135, type: !541, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!541 = !DISubroutineType(types: !542)
!542 = !{!125, !173, !220, !125}
!543 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !544, line: 197)
!544 = !DISubprogram(name: "wctob", scope: !360, file: !360, line: 288, type: !545, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!545 = !DISubroutineType(types: !546)
!546 = !{!82, !356}
!547 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !548, line: 198)
!548 = !DISubprogram(name: "wmemcmp", scope: !360, file: !360, line: 258, type: !505, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!549 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !550, line: 199)
!550 = !DISubprogram(name: "wmemcpy", scope: !360, file: !360, line: 262, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!551 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !552, line: 200)
!552 = !DISubprogram(name: "wmemmove", scope: !360, file: !360, line: 267, type: !553, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!553 = !DISubroutineType(types: !554)
!554 = !{!174, !174, !221, !125}
!555 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !556, line: 201)
!556 = !DISubprogram(name: "wmemset", scope: !360, file: !360, line: 271, type: !557, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!557 = !DISubroutineType(types: !558)
!558 = !{!174, !174, !175, !125}
!559 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !560, line: 202)
!560 = !DISubprogram(name: "wprintf", scope: !360, file: !360, line: 587, type: !561, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!561 = !DISubroutineType(types: !562)
!562 = !{!82, !220, null}
!563 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !564, line: 203)
!564 = !DISubprogram(name: "wscanf", scope: !360, file: !360, line: 628, type: !561, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!565 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !566, line: 204)
!566 = !DISubprogram(name: "wcschr", scope: !360, file: !360, line: 164, type: !567, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!567 = !DISubroutineType(types: !568)
!568 = !{!174, !221, !175}
!569 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !570, line: 205)
!570 = !DISubprogram(name: "wcspbrk", scope: !360, file: !360, line: 201, type: !571, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!571 = !DISubroutineType(types: !572)
!572 = !{!174, !221, !221}
!573 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !574, line: 206)
!574 = !DISubprogram(name: "wcsrchr", scope: !360, file: !360, line: 174, type: !567, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!575 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !576, line: 207)
!576 = !DISubprogram(name: "wcsstr", scope: !360, file: !360, line: 212, type: !571, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!577 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !578, line: 208)
!578 = !DISubprogram(name: "wmemchr", scope: !360, file: !360, line: 253, type: !579, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!579 = !DISubroutineType(types: !580)
!580 = !{!174, !221, !175, !125}
!581 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !582, line: 248)
!582 = !DISubprogram(name: "wcstold", scope: !360, file: !360, line: 384, type: !583, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!583 = !DISubroutineType(types: !584)
!584 = !{!267, !220, !521}
!585 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !586, line: 257)
!586 = !DISubprogram(name: "wcstoll", scope: !360, file: !360, line: 441, type: !587, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!587 = !DISubroutineType(types: !588)
!588 = !{!233, !220, !521, !82}
!589 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !590, line: 258)
!590 = !DISubprogram(name: "wcstoull", scope: !360, file: !360, line: 448, type: !591, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!591 = !DISubroutineType(types: !592)
!592 = !{!257, !220, !521, !82}
!593 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !582, line: 264)
!594 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !586, line: 265)
!595 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !590, line: 266)
!596 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !524, line: 280)
!597 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !452, line: 283)
!598 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !458, line: 286)
!599 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !466, line: 289)
!600 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !582, line: 293)
!601 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !586, line: 294)
!602 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !590, line: 295)
!603 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !604, line: 48)
!604 = !DIDerivedType(tag: DW_TAG_typedef, name: "int8_t", file: !9, line: 235, baseType: !605)
!605 = !DIBasicType(name: "signed char", size: 8, encoding: DW_ATE_signed_char)
!606 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !607, line: 49)
!607 = !DIDerivedType(tag: DW_TAG_typedef, name: "int16_t", file: !9, line: 216, baseType: !608)
!608 = !DIBasicType(name: "short", size: 16, encoding: DW_ATE_signed)
!609 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !610, line: 50)
!610 = !DIDerivedType(tag: DW_TAG_typedef, name: "int32_t", file: !9, line: 178, baseType: !82)
!611 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !612, line: 51)
!612 = !DIDerivedType(tag: DW_TAG_typedef, name: "int64_t", file: !9, line: 107, baseType: !91)
!613 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !614, line: 53)
!614 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast8_t", file: !9, line: 245, baseType: !604)
!615 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !616, line: 54)
!616 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast16_t", file: !9, line: 228, baseType: !607)
!617 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !618, line: 55)
!618 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast32_t", file: !9, line: 197, baseType: !610)
!619 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !620, line: 56)
!620 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast64_t", file: !9, line: 123, baseType: !612)
!621 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !622, line: 58)
!622 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least8_t", file: !9, line: 243, baseType: !604)
!623 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !624, line: 59)
!624 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least16_t", file: !9, line: 226, baseType: !607)
!625 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !626, line: 60)
!626 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least32_t", file: !9, line: 195, baseType: !610)
!627 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !628, line: 61)
!628 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least64_t", file: !9, line: 121, baseType: !612)
!629 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !630, line: 63)
!630 = !DIDerivedType(tag: DW_TAG_typedef, name: "intmax_t", file: !9, line: 276, baseType: !91)
!631 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !632, line: 64)
!632 = !DIDerivedType(tag: DW_TAG_typedef, name: "intptr_t", file: !9, line: 263, baseType: !612)
!633 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !62, line: 66)
!634 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !28, line: 67)
!635 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !8, line: 68)
!636 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !637, line: 69)
!637 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint64_t", file: !9, line: 109, baseType: !127)
!638 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !639, line: 71)
!639 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast8_t", file: !9, line: 246, baseType: !62)
!640 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !641, line: 72)
!641 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast16_t", file: !9, line: 229, baseType: !28)
!642 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !643, line: 73)
!643 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast32_t", file: !9, line: 198, baseType: !8)
!644 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !645, line: 74)
!645 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast64_t", file: !9, line: 124, baseType: !637)
!646 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !647, line: 76)
!647 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least8_t", file: !9, line: 244, baseType: !62)
!648 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !649, line: 77)
!649 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least16_t", file: !9, line: 227, baseType: !28)
!650 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !651, line: 78)
!651 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least32_t", file: !9, line: 196, baseType: !8)
!652 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !653, line: 79)
!653 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least64_t", file: !9, line: 122, baseType: !637)
!654 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !655, line: 81)
!655 = !DIDerivedType(tag: DW_TAG_typedef, name: "uintmax_t", file: !9, line: 277, baseType: !127)
!656 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !657, line: 82)
!657 = !DIDerivedType(tag: DW_TAG_typedef, name: "uintptr_t", file: !9, line: 270, baseType: !637)
!658 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !659, line: 44)
!659 = !DIDerivedType(tag: DW_TAG_typedef, name: "size_t", scope: !75, file: !76, line: 231, baseType: !127)
!660 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !661, line: 45)
!661 = !DIDerivedType(tag: DW_TAG_typedef, name: "ptrdiff_t", scope: !75, file: !76, line: 232, baseType: !91)
!662 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !663, line: 53)
!663 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "lconv", file: !664, line: 51, flags: DIFlagFwdDecl, identifier: "_ZTS5lconv")
!664 = !DIFile(filename: "/usr/include/locale.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!665 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !666, line: 54)
!666 = !DISubprogram(name: "setlocale", scope: !664, file: !664, line: 122, type: !667, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!667 = !DISubroutineType(types: !668)
!668 = !{!152, !82, !109}
!669 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !670, line: 55)
!670 = !DISubprogram(name: "localeconv", scope: !664, file: !664, line: 125, type: !671, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!671 = !DISubroutineType(types: !672)
!672 = !{!673}
!673 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !663, size: 64)
!674 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !675, line: 64)
!675 = !DISubprogram(name: "isalnum", scope: !676, file: !676, line: 108, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!676 = !DIFile(filename: "/usr/include/ctype.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!677 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !678, line: 65)
!678 = !DISubprogram(name: "isalpha", scope: !676, file: !676, line: 109, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!679 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !680, line: 66)
!680 = !DISubprogram(name: "iscntrl", scope: !676, file: !676, line: 110, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!681 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !682, line: 67)
!682 = !DISubprogram(name: "isdigit", scope: !676, file: !676, line: 111, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!683 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !684, line: 68)
!684 = !DISubprogram(name: "isgraph", scope: !676, file: !676, line: 113, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!685 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !686, line: 69)
!686 = !DISubprogram(name: "islower", scope: !676, file: !676, line: 112, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!687 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !688, line: 70)
!688 = !DISubprogram(name: "isprint", scope: !676, file: !676, line: 114, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!689 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !690, line: 71)
!690 = !DISubprogram(name: "ispunct", scope: !676, file: !676, line: 115, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!691 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !692, line: 72)
!692 = !DISubprogram(name: "isspace", scope: !676, file: !676, line: 116, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!693 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !694, line: 73)
!694 = !DISubprogram(name: "isupper", scope: !676, file: !676, line: 117, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!695 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !696, line: 74)
!696 = !DISubprogram(name: "isxdigit", scope: !676, file: !676, line: 118, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!697 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !698, line: 75)
!698 = !DISubprogram(name: "tolower", scope: !676, file: !676, line: 122, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!699 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !700, line: 76)
!700 = !DISubprogram(name: "toupper", scope: !676, file: !676, line: 125, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!701 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !702, line: 87)
!702 = !DISubprogram(name: "isblank", scope: !676, file: !676, line: 130, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!703 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !704, line: 98)
!704 = !DIDerivedType(tag: DW_TAG_typedef, name: "FILE", file: !705, line: 7, baseType: !370)
!705 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/FILE.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!706 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !707, line: 99)
!707 = !DIDerivedType(tag: DW_TAG_typedef, name: "fpos_t", file: !708, line: 78, baseType: !709)
!708 = !DIFile(filename: "/usr/include/stdio.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!709 = !DIDerivedType(tag: DW_TAG_typedef, name: "_G_fpos_t", file: !710, line: 30, baseType: !711)
!710 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/_G_config.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!711 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !710, line: 26, flags: DIFlagFwdDecl, identifier: "_ZTS9_G_fpos_t")
!712 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !713, line: 101)
!713 = !DISubprogram(name: "clearerr", scope: !708, file: !708, line: 757, type: !714, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!714 = !DISubroutineType(types: !715)
!715 = !{null, !716}
!716 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !704, size: 64)
!717 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !718, line: 102)
!718 = !DISubprogram(name: "fclose", scope: !708, file: !708, line: 199, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!719 = !DISubroutineType(types: !720)
!720 = !{!82, !716}
!721 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !722, line: 103)
!722 = !DISubprogram(name: "feof", scope: !708, file: !708, line: 759, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!723 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !724, line: 104)
!724 = !DISubprogram(name: "ferror", scope: !708, file: !708, line: 761, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!725 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !726, line: 105)
!726 = !DISubprogram(name: "fflush", scope: !708, file: !708, line: 204, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!727 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !728, line: 106)
!728 = !DISubprogram(name: "fgetc", scope: !708, file: !708, line: 477, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!729 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !730, line: 107)
!730 = !DISubprogram(name: "fgetpos", scope: !708, file: !708, line: 731, type: !731, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!731 = !DISubroutineType(types: !732)
!732 = !{!82, !733, !734}
!733 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !716)
!734 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !735)
!735 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !707, size: 64)
!736 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !737, line: 108)
!737 = !DISubprogram(name: "fgets", scope: !708, file: !708, line: 564, type: !738, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!738 = !DISubroutineType(types: !739)
!739 = !{!152, !219, !82, !733}
!740 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !741, line: 109)
!741 = !DISubprogram(name: "fopen", scope: !708, file: !708, line: 232, type: !742, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!742 = !DISubroutineType(types: !743)
!743 = !{!716, !176, !176}
!744 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !745, line: 110)
!745 = !DISubprogram(name: "fprintf", scope: !708, file: !708, line: 312, type: !746, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!746 = !DISubroutineType(types: !747)
!747 = !{!82, !733, !176, null}
!748 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !749, line: 111)
!749 = !DISubprogram(name: "fputc", scope: !708, file: !708, line: 517, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!750 = !DISubroutineType(types: !751)
!751 = !{!82, !82, !716}
!752 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !753, line: 112)
!753 = !DISubprogram(name: "fputs", scope: !708, file: !708, line: 626, type: !754, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!754 = !DISubroutineType(types: !755)
!755 = !{!82, !176, !733}
!756 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !757, line: 113)
!757 = !DISubprogram(name: "fread", scope: !708, file: !708, line: 646, type: !758, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!758 = !DISubroutineType(types: !759)
!759 = !{!125, !760, !125, !125, !733}
!760 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !124)
!761 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !762, line: 114)
!762 = !DISubprogram(name: "freopen", scope: !708, file: !708, line: 238, type: !763, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!763 = !DISubroutineType(types: !764)
!764 = !{!716, !176, !176, !733}
!765 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !766, line: 115)
!766 = !DISubprogram(name: "fscanf", scope: !708, file: !708, line: 377, type: !746, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!767 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !768, line: 116)
!768 = !DISubprogram(name: "fseek", scope: !708, file: !708, line: 684, type: !769, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!769 = !DISubroutineType(types: !770)
!770 = !{!82, !716, !91, !82}
!771 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !772, line: 117)
!772 = !DISubprogram(name: "fsetpos", scope: !708, file: !708, line: 736, type: !773, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!773 = !DISubroutineType(types: !774)
!774 = !{!82, !716, !775}
!775 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !776, size: 64)
!776 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !707)
!777 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !778, line: 118)
!778 = !DISubprogram(name: "ftell", scope: !708, file: !708, line: 689, type: !779, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!779 = !DISubroutineType(types: !780)
!780 = !{!91, !716}
!781 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !782, line: 119)
!782 = !DISubprogram(name: "fwrite", scope: !708, file: !708, line: 652, type: !783, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!783 = !DISubroutineType(types: !784)
!784 = !{!125, !785, !125, !125, !733}
!785 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !68)
!786 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !787, line: 120)
!787 = !DISubprogram(name: "getc", scope: !708, file: !708, line: 478, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!788 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !789, line: 121)
!789 = !DISubprogram(name: "getchar", scope: !708, file: !708, line: 484, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!790 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !791, line: 124)
!791 = !DISubprogram(name: "gets", scope: !708, file: !708, line: 577, type: !792, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!792 = !DISubroutineType(types: !793)
!793 = !{!152, !152}
!794 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !795, line: 126)
!795 = !DISubprogram(name: "perror", scope: !708, file: !708, line: 775, type: !796, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!796 = !DISubroutineType(types: !797)
!797 = !{null, !109}
!798 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !799, line: 127)
!799 = !DISubprogram(name: "printf", scope: !708, file: !708, line: 318, type: !800, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!800 = !DISubroutineType(types: !801)
!801 = !{!82, !176, null}
!802 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !803, line: 128)
!803 = !DISubprogram(name: "putc", scope: !708, file: !708, line: 518, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!804 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !805, line: 129)
!805 = !DISubprogram(name: "putchar", scope: !708, file: !708, line: 524, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!806 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !807, line: 130)
!807 = !DISubprogram(name: "puts", scope: !708, file: !708, line: 632, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!808 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !809, line: 131)
!809 = !DISubprogram(name: "remove", scope: !708, file: !708, line: 144, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!810 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !811, line: 132)
!811 = !DISubprogram(name: "rename", scope: !708, file: !708, line: 146, type: !812, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!812 = !DISubroutineType(types: !813)
!813 = !{!82, !109, !109}
!814 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !815, line: 133)
!815 = !DISubprogram(name: "rewind", scope: !708, file: !708, line: 694, type: !714, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!816 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !817, line: 134)
!817 = !DISubprogram(name: "scanf", scope: !708, file: !708, line: 383, type: !800, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!818 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !819, line: 135)
!819 = !DISubprogram(name: "setbuf", scope: !708, file: !708, line: 290, type: !820, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!820 = !DISubroutineType(types: !821)
!821 = !{null, !733, !219}
!822 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !823, line: 136)
!823 = !DISubprogram(name: "setvbuf", scope: !708, file: !708, line: 294, type: !824, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!824 = !DISubroutineType(types: !825)
!825 = !{!82, !733, !219, !82, !125}
!826 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !827, line: 137)
!827 = !DISubprogram(name: "sprintf", scope: !708, file: !708, line: 320, type: !828, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!828 = !DISubroutineType(types: !829)
!829 = !{!82, !219, !176, null}
!830 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !831, line: 138)
!831 = !DISubprogram(name: "sscanf", scope: !708, file: !708, line: 385, type: !832, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!832 = !DISubroutineType(types: !833)
!833 = !{!82, !176, !176, null}
!834 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !835, line: 139)
!835 = !DISubprogram(name: "tmpfile", scope: !708, file: !708, line: 159, type: !836, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!836 = !DISubroutineType(types: !837)
!837 = !{!716}
!838 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !839, line: 141)
!839 = !DISubprogram(name: "tmpnam", scope: !708, file: !708, line: 173, type: !792, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!840 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !841, line: 143)
!841 = !DISubprogram(name: "ungetc", scope: !708, file: !708, line: 639, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!842 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !843, line: 144)
!843 = !DISubprogram(name: "vfprintf", scope: !708, file: !708, line: 327, type: !844, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!844 = !DISubroutineType(types: !845)
!845 = !{!82, !733, !176, !444}
!846 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !847, line: 145)
!847 = !DISubprogram(name: "vprintf", scope: !708, file: !708, line: 333, type: !848, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!848 = !DISubroutineType(types: !849)
!849 = !{!82, !176, !444}
!850 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !851, line: 146)
!851 = !DISubprogram(name: "vsprintf", scope: !708, file: !708, line: 335, type: !852, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!852 = !DISubroutineType(types: !853)
!853 = !{!82, !219, !176, !444}
!854 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !855, line: 175)
!855 = !DISubprogram(name: "snprintf", scope: !708, file: !708, line: 340, type: !856, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!856 = !DISubroutineType(types: !857)
!857 = !{!82, !219, !125, !176, null}
!858 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !859, line: 176)
!859 = !DISubprogram(name: "vfscanf", scope: !708, file: !708, line: 420, type: !844, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!860 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !861, line: 177)
!861 = !DISubprogram(name: "vscanf", scope: !708, file: !708, line: 428, type: !848, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!862 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !863, line: 178)
!863 = !DISubprogram(name: "vsnprintf", scope: !708, file: !708, line: 344, type: !864, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!864 = !DISubroutineType(types: !865)
!865 = !{!82, !219, !125, !176, !444}
!866 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !867, line: 179)
!867 = !DISubprogram(name: "vsscanf", scope: !708, file: !708, line: 432, type: !868, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!868 = !DISubroutineType(types: !869)
!869 = !{!82, !176, !176, !444}
!870 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !855, line: 185)
!871 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !859, line: 186)
!872 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !861, line: 187)
!873 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !863, line: 188)
!874 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !867, line: 189)
!875 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !876, line: 83)
!876 = !DISubprogram(name: "acos", scope: !877, file: !877, line: 53, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!877 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/mathcalls.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!878 = !DISubroutineType(types: !879)
!879 = !{!108, !108}
!880 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !881, line: 102)
!881 = !DISubprogram(name: "asin", scope: !877, file: !877, line: 55, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!882 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !883, line: 121)
!883 = !DISubprogram(name: "atan", scope: !877, file: !877, line: 57, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!884 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !885, line: 140)
!885 = !DISubprogram(name: "atan2", scope: !877, file: !877, line: 59, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!886 = !DISubroutineType(types: !887)
!887 = !{!108, !108, !108}
!888 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !889, line: 161)
!889 = !DISubprogram(name: "ceil", scope: !877, file: !877, line: 159, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!890 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !891, line: 180)
!891 = !DISubprogram(name: "cos", scope: !877, file: !877, line: 62, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!892 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !893, line: 199)
!893 = !DISubprogram(name: "cosh", scope: !877, file: !877, line: 71, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!894 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !895, line: 218)
!895 = !DISubprogram(name: "exp", scope: !877, file: !877, line: 95, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!896 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !897, line: 237)
!897 = !DISubprogram(name: "fabs", scope: !877, file: !877, line: 162, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!898 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !899, line: 256)
!899 = !DISubprogram(name: "floor", scope: !877, file: !877, line: 165, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!900 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !901, line: 275)
!901 = !DISubprogram(name: "fmod", scope: !877, file: !877, line: 168, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!902 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !903, line: 296)
!903 = !DISubprogram(name: "frexp", scope: !877, file: !877, line: 98, type: !904, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!904 = !DISubroutineType(types: !905)
!905 = !{!108, !108, !906}
!906 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !82, size: 64)
!907 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !908, line: 315)
!908 = !DISubprogram(name: "ldexp", scope: !877, file: !877, line: 101, type: !909, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!909 = !DISubroutineType(types: !910)
!910 = !{!108, !108, !82}
!911 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !912, line: 334)
!912 = !DISubprogram(name: "log", scope: !877, file: !877, line: 104, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!913 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !914, line: 353)
!914 = !DISubprogram(name: "log10", scope: !877, file: !877, line: 107, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!915 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !916, line: 372)
!916 = !DISubprogram(name: "modf", scope: !877, file: !877, line: 110, type: !917, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!917 = !DISubroutineType(types: !918)
!918 = !{!108, !108, !919}
!919 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !108, size: 64)
!920 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !921, line: 384)
!921 = !DISubprogram(name: "pow", scope: !877, file: !877, line: 140, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!922 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !923, line: 421)
!923 = !DISubprogram(name: "sin", scope: !877, file: !877, line: 64, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!924 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !925, line: 440)
!925 = !DISubprogram(name: "sinh", scope: !877, file: !877, line: 73, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!926 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !927, line: 459)
!927 = !DISubprogram(name: "sqrt", scope: !877, file: !877, line: 143, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!928 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !929, line: 478)
!929 = !DISubprogram(name: "tan", scope: !877, file: !877, line: 66, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!930 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !931, line: 497)
!931 = !DISubprogram(name: "tanh", scope: !877, file: !877, line: 75, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!932 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !933, line: 1080)
!933 = !DIDerivedType(tag: DW_TAG_typedef, name: "double_t", file: !934, line: 150, baseType: !108)
!934 = !DIFile(filename: "/usr/include/math.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!935 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !936, line: 1081)
!936 = !DIDerivedType(tag: DW_TAG_typedef, name: "float_t", file: !934, line: 149, baseType: !262)
!937 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !938, line: 1084)
!938 = !DISubprogram(name: "acosh", scope: !877, file: !877, line: 85, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!939 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !940, line: 1085)
!940 = !DISubprogram(name: "acoshf", scope: !877, file: !877, line: 85, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!941 = !DISubroutineType(types: !942)
!942 = !{!262, !262}
!943 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !944, line: 1086)
!944 = !DISubprogram(name: "acoshl", scope: !877, file: !877, line: 85, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!945 = !DISubroutineType(types: !946)
!946 = !{!267, !267}
!947 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !948, line: 1088)
!948 = !DISubprogram(name: "asinh", scope: !877, file: !877, line: 87, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!949 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !950, line: 1089)
!950 = !DISubprogram(name: "asinhf", scope: !877, file: !877, line: 87, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!951 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !952, line: 1090)
!952 = !DISubprogram(name: "asinhl", scope: !877, file: !877, line: 87, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!953 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !954, line: 1092)
!954 = !DISubprogram(name: "atanh", scope: !877, file: !877, line: 89, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!955 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !956, line: 1093)
!956 = !DISubprogram(name: "atanhf", scope: !877, file: !877, line: 89, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!957 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !958, line: 1094)
!958 = !DISubprogram(name: "atanhl", scope: !877, file: !877, line: 89, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!959 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !960, line: 1096)
!960 = !DISubprogram(name: "cbrt", scope: !877, file: !877, line: 152, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!961 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !962, line: 1097)
!962 = !DISubprogram(name: "cbrtf", scope: !877, file: !877, line: 152, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!963 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !964, line: 1098)
!964 = !DISubprogram(name: "cbrtl", scope: !877, file: !877, line: 152, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!965 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !966, line: 1100)
!966 = !DISubprogram(name: "copysign", scope: !877, file: !877, line: 196, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!967 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !968, line: 1101)
!968 = !DISubprogram(name: "copysignf", scope: !877, file: !877, line: 196, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!969 = !DISubroutineType(types: !970)
!970 = !{!262, !262, !262}
!971 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !972, line: 1102)
!972 = !DISubprogram(name: "copysignl", scope: !877, file: !877, line: 196, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!973 = !DISubroutineType(types: !974)
!974 = !{!267, !267, !267}
!975 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !976, line: 1104)
!976 = !DISubprogram(name: "erf", scope: !877, file: !877, line: 228, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!977 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !978, line: 1105)
!978 = !DISubprogram(name: "erff", scope: !877, file: !877, line: 228, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!979 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !980, line: 1106)
!980 = !DISubprogram(name: "erfl", scope: !877, file: !877, line: 228, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!981 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !982, line: 1108)
!982 = !DISubprogram(name: "erfc", scope: !877, file: !877, line: 229, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!983 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !984, line: 1109)
!984 = !DISubprogram(name: "erfcf", scope: !877, file: !877, line: 229, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!985 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !986, line: 1110)
!986 = !DISubprogram(name: "erfcl", scope: !877, file: !877, line: 229, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!987 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !988, line: 1112)
!988 = !DISubprogram(name: "exp2", scope: !877, file: !877, line: 130, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!989 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !990, line: 1113)
!990 = !DISubprogram(name: "exp2f", scope: !877, file: !877, line: 130, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!991 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !992, line: 1114)
!992 = !DISubprogram(name: "exp2l", scope: !877, file: !877, line: 130, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!993 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !994, line: 1116)
!994 = !DISubprogram(name: "expm1", scope: !877, file: !877, line: 119, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!995 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !996, line: 1117)
!996 = !DISubprogram(name: "expm1f", scope: !877, file: !877, line: 119, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!997 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !998, line: 1118)
!998 = !DISubprogram(name: "expm1l", scope: !877, file: !877, line: 119, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!999 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1000, line: 1120)
!1000 = !DISubprogram(name: "fdim", scope: !877, file: !877, line: 326, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1001 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1002, line: 1121)
!1002 = !DISubprogram(name: "fdimf", scope: !877, file: !877, line: 326, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1003 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1004, line: 1122)
!1004 = !DISubprogram(name: "fdiml", scope: !877, file: !877, line: 326, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1005 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1006, line: 1124)
!1006 = !DISubprogram(name: "fma", scope: !877, file: !877, line: 335, type: !1007, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1007 = !DISubroutineType(types: !1008)
!1008 = !{!108, !108, !108, !108}
!1009 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1010, line: 1125)
!1010 = !DISubprogram(name: "fmaf", scope: !877, file: !877, line: 335, type: !1011, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1011 = !DISubroutineType(types: !1012)
!1012 = !{!262, !262, !262, !262}
!1013 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1014, line: 1126)
!1014 = !DISubprogram(name: "fmal", scope: !877, file: !877, line: 335, type: !1015, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1015 = !DISubroutineType(types: !1016)
!1016 = !{!267, !267, !267, !267}
!1017 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1018, line: 1128)
!1018 = !DISubprogram(name: "fmax", scope: !877, file: !877, line: 329, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1019 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1020, line: 1129)
!1020 = !DISubprogram(name: "fmaxf", scope: !877, file: !877, line: 329, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1021 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1022, line: 1130)
!1022 = !DISubprogram(name: "fmaxl", scope: !877, file: !877, line: 329, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1023 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1024, line: 1132)
!1024 = !DISubprogram(name: "fmin", scope: !877, file: !877, line: 332, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1025 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1026, line: 1133)
!1026 = !DISubprogram(name: "fminf", scope: !877, file: !877, line: 332, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1027 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1028, line: 1134)
!1028 = !DISubprogram(name: "fminl", scope: !877, file: !877, line: 332, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1029 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1030, line: 1136)
!1030 = !DISubprogram(name: "hypot", scope: !877, file: !877, line: 147, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1031 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1032, line: 1137)
!1032 = !DISubprogram(name: "hypotf", scope: !877, file: !877, line: 147, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1033 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1034, line: 1138)
!1034 = !DISubprogram(name: "hypotl", scope: !877, file: !877, line: 147, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1035 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1036, line: 1140)
!1036 = !DISubprogram(name: "ilogb", scope: !877, file: !877, line: 280, type: !1037, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1037 = !DISubroutineType(types: !1038)
!1038 = !{!82, !108}
!1039 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1040, line: 1141)
!1040 = !DISubprogram(name: "ilogbf", scope: !877, file: !877, line: 280, type: !1041, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1041 = !DISubroutineType(types: !1042)
!1042 = !{!82, !262}
!1043 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1044, line: 1142)
!1044 = !DISubprogram(name: "ilogbl", scope: !877, file: !877, line: 280, type: !1045, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1045 = !DISubroutineType(types: !1046)
!1046 = !{!82, !267}
!1047 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1048, line: 1144)
!1048 = !DISubprogram(name: "lgamma", scope: !877, file: !877, line: 230, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1049 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1050, line: 1145)
!1050 = !DISubprogram(name: "lgammaf", scope: !877, file: !877, line: 230, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1051 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1052, line: 1146)
!1052 = !DISubprogram(name: "lgammal", scope: !877, file: !877, line: 230, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1053 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1054, line: 1149)
!1054 = !DISubprogram(name: "llrint", scope: !877, file: !877, line: 316, type: !1055, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1055 = !DISubroutineType(types: !1056)
!1056 = !{!233, !108}
!1057 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1058, line: 1150)
!1058 = !DISubprogram(name: "llrintf", scope: !877, file: !877, line: 316, type: !1059, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1059 = !DISubroutineType(types: !1060)
!1060 = !{!233, !262}
!1061 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1062, line: 1151)
!1062 = !DISubprogram(name: "llrintl", scope: !877, file: !877, line: 316, type: !1063, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1063 = !DISubroutineType(types: !1064)
!1064 = !{!233, !267}
!1065 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1066, line: 1153)
!1066 = !DISubprogram(name: "llround", scope: !877, file: !877, line: 322, type: !1055, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1067 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1068, line: 1154)
!1068 = !DISubprogram(name: "llroundf", scope: !877, file: !877, line: 322, type: !1059, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1069 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1070, line: 1155)
!1070 = !DISubprogram(name: "llroundl", scope: !877, file: !877, line: 322, type: !1063, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1071 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1072, line: 1158)
!1072 = !DISubprogram(name: "log1p", scope: !877, file: !877, line: 122, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1073 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1074, line: 1159)
!1074 = !DISubprogram(name: "log1pf", scope: !877, file: !877, line: 122, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1075 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1076, line: 1160)
!1076 = !DISubprogram(name: "log1pl", scope: !877, file: !877, line: 122, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1077 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1078, line: 1162)
!1078 = !DISubprogram(name: "log2", scope: !877, file: !877, line: 133, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1079 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1080, line: 1163)
!1080 = !DISubprogram(name: "log2f", scope: !877, file: !877, line: 133, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1081 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1082, line: 1164)
!1082 = !DISubprogram(name: "log2l", scope: !877, file: !877, line: 133, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1083 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1084, line: 1166)
!1084 = !DISubprogram(name: "logb", scope: !877, file: !877, line: 125, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1085 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1086, line: 1167)
!1086 = !DISubprogram(name: "logbf", scope: !877, file: !877, line: 125, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1087 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1088, line: 1168)
!1088 = !DISubprogram(name: "logbl", scope: !877, file: !877, line: 125, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1089 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1090, line: 1170)
!1090 = !DISubprogram(name: "lrint", scope: !877, file: !877, line: 314, type: !1091, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1091 = !DISubroutineType(types: !1092)
!1092 = !{!91, !108}
!1093 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1094, line: 1171)
!1094 = !DISubprogram(name: "lrintf", scope: !877, file: !877, line: 314, type: !1095, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1095 = !DISubroutineType(types: !1096)
!1096 = !{!91, !262}
!1097 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1098, line: 1172)
!1098 = !DISubprogram(name: "lrintl", scope: !877, file: !877, line: 314, type: !1099, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1099 = !DISubroutineType(types: !1100)
!1100 = !{!91, !267}
!1101 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1102, line: 1174)
!1102 = !DISubprogram(name: "lround", scope: !877, file: !877, line: 320, type: !1091, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1103 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1104, line: 1175)
!1104 = !DISubprogram(name: "lroundf", scope: !877, file: !877, line: 320, type: !1095, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1105 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1106, line: 1176)
!1106 = !DISubprogram(name: "lroundl", scope: !877, file: !877, line: 320, type: !1099, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1107 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1108, line: 1178)
!1108 = !DISubprogram(name: "nan", scope: !877, file: !877, line: 201, type: !106, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1109 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1110, line: 1179)
!1110 = !DISubprogram(name: "nanf", scope: !877, file: !877, line: 201, type: !1111, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1111 = !DISubroutineType(types: !1112)
!1112 = !{!262, !109}
!1113 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1114, line: 1180)
!1114 = !DISubprogram(name: "nanl", scope: !877, file: !877, line: 201, type: !1115, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1115 = !DISubroutineType(types: !1116)
!1116 = !{!267, !109}
!1117 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1118, line: 1182)
!1118 = !DISubprogram(name: "nearbyint", scope: !877, file: !877, line: 294, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1119 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1120, line: 1183)
!1120 = !DISubprogram(name: "nearbyintf", scope: !877, file: !877, line: 294, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1121 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1122, line: 1184)
!1122 = !DISubprogram(name: "nearbyintl", scope: !877, file: !877, line: 294, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1123 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1124, line: 1186)
!1124 = !DISubprogram(name: "nextafter", scope: !877, file: !877, line: 259, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1125 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1126, line: 1187)
!1126 = !DISubprogram(name: "nextafterf", scope: !877, file: !877, line: 259, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1127 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1128, line: 1188)
!1128 = !DISubprogram(name: "nextafterl", scope: !877, file: !877, line: 259, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1129 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1130, line: 1190)
!1130 = !DISubprogram(name: "nexttoward", scope: !877, file: !877, line: 261, type: !1131, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1131 = !DISubroutineType(types: !1132)
!1132 = !{!108, !108, !267}
!1133 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1134, line: 1191)
!1134 = !DISubprogram(name: "nexttowardf", scope: !877, file: !877, line: 261, type: !1135, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1135 = !DISubroutineType(types: !1136)
!1136 = !{!262, !262, !267}
!1137 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1138, line: 1192)
!1138 = !DISubprogram(name: "nexttowardl", scope: !877, file: !877, line: 261, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1139 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1140, line: 1194)
!1140 = !DISubprogram(name: "remainder", scope: !877, file: !877, line: 272, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1141 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1142, line: 1195)
!1142 = !DISubprogram(name: "remainderf", scope: !877, file: !877, line: 272, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1143 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1144, line: 1196)
!1144 = !DISubprogram(name: "remainderl", scope: !877, file: !877, line: 272, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1145 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1146, line: 1198)
!1146 = !DISubprogram(name: "remquo", scope: !877, file: !877, line: 307, type: !1147, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1147 = !DISubroutineType(types: !1148)
!1148 = !{!108, !108, !108, !906}
!1149 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1150, line: 1199)
!1150 = !DISubprogram(name: "remquof", scope: !877, file: !877, line: 307, type: !1151, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1151 = !DISubroutineType(types: !1152)
!1152 = !{!262, !262, !262, !906}
!1153 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1154, line: 1200)
!1154 = !DISubprogram(name: "remquol", scope: !877, file: !877, line: 307, type: !1155, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1155 = !DISubroutineType(types: !1156)
!1156 = !{!267, !267, !267, !906}
!1157 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1158, line: 1202)
!1158 = !DISubprogram(name: "rint", scope: !877, file: !877, line: 256, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1159 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1160, line: 1203)
!1160 = !DISubprogram(name: "rintf", scope: !877, file: !877, line: 256, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1161 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1162, line: 1204)
!1162 = !DISubprogram(name: "rintl", scope: !877, file: !877, line: 256, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1163 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1164, line: 1206)
!1164 = !DISubprogram(name: "round", scope: !877, file: !877, line: 298, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1165 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1166, line: 1207)
!1166 = !DISubprogram(name: "roundf", scope: !877, file: !877, line: 298, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1167 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1168, line: 1208)
!1168 = !DISubprogram(name: "roundl", scope: !877, file: !877, line: 298, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1169 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1170, line: 1210)
!1170 = !DISubprogram(name: "scalbln", scope: !877, file: !877, line: 290, type: !1171, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1171 = !DISubroutineType(types: !1172)
!1172 = !{!108, !108, !91}
!1173 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1174, line: 1211)
!1174 = !DISubprogram(name: "scalblnf", scope: !877, file: !877, line: 290, type: !1175, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1175 = !DISubroutineType(types: !1176)
!1176 = !{!262, !262, !91}
!1177 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1178, line: 1212)
!1178 = !DISubprogram(name: "scalblnl", scope: !877, file: !877, line: 290, type: !1179, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1179 = !DISubroutineType(types: !1180)
!1180 = !{!267, !267, !91}
!1181 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1182, line: 1214)
!1182 = !DISubprogram(name: "scalbn", scope: !877, file: !877, line: 276, type: !909, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1183 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1184, line: 1215)
!1184 = !DISubprogram(name: "scalbnf", scope: !877, file: !877, line: 276, type: !1185, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1185 = !DISubroutineType(types: !1186)
!1186 = !{!262, !262, !82}
!1187 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1188, line: 1216)
!1188 = !DISubprogram(name: "scalbnl", scope: !877, file: !877, line: 276, type: !1189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1189 = !DISubroutineType(types: !1190)
!1190 = !{!267, !267, !82}
!1191 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1192, line: 1218)
!1192 = !DISubprogram(name: "tgamma", scope: !877, file: !877, line: 235, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1193 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1194, line: 1219)
!1194 = !DISubprogram(name: "tgammaf", scope: !877, file: !877, line: 235, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1195 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1196, line: 1220)
!1196 = !DISubprogram(name: "tgammal", scope: !877, file: !877, line: 235, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1197 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1198, line: 1222)
!1198 = !DISubprogram(name: "trunc", scope: !877, file: !877, line: 302, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1199 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1200, line: 1223)
!1200 = !DISubprogram(name: "truncf", scope: !877, file: !877, line: 302, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1201 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1202, line: 1224)
!1202 = !DISubprogram(name: "truncl", scope: !877, file: !877, line: 302, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1203 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1204, line: 58)
!1204 = !DIDerivedType(tag: DW_TAG_typedef, name: "fenv_t", file: !1205, line: 94, baseType: !1206)
!1205 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/fenv.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1206 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !1205, line: 75, flags: DIFlagFwdDecl, identifier: "_ZTS6fenv_t")
!1207 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1208, line: 59)
!1208 = !DIDerivedType(tag: DW_TAG_typedef, name: "fexcept_t", file: !1205, line: 68, baseType: !29)
!1209 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1210, line: 62)
!1210 = !DISubprogram(name: "feclearexcept", scope: !1211, file: !1211, line: 71, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1211 = !DIFile(filename: "/usr/include/fenv.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1212 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1213, line: 63)
!1213 = !DISubprogram(name: "fegetexceptflag", scope: !1211, file: !1211, line: 75, type: !1214, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1214 = !DISubroutineType(types: !1215)
!1215 = !{!82, !1216, !82}
!1216 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1208, size: 64)
!1217 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1218, line: 64)
!1218 = !DISubprogram(name: "feraiseexcept", scope: !1211, file: !1211, line: 78, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1219 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1220, line: 65)
!1220 = !DISubprogram(name: "fesetexceptflag", scope: !1211, file: !1211, line: 88, type: !1221, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1221 = !DISubroutineType(types: !1222)
!1222 = !{!82, !1223, !82}
!1223 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1224, size: 64)
!1224 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !1208)
!1225 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1226, line: 66)
!1226 = !DISubprogram(name: "fetestexcept", scope: !1211, file: !1211, line: 92, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1227 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1228, line: 68)
!1228 = !DISubprogram(name: "fegetround", scope: !1211, file: !1211, line: 104, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1229 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1230, line: 69)
!1230 = !DISubprogram(name: "fesetround", scope: !1211, file: !1211, line: 107, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1231 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1232, line: 71)
!1232 = !DISubprogram(name: "fegetenv", scope: !1211, file: !1211, line: 114, type: !1233, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1233 = !DISubroutineType(types: !1234)
!1234 = !{!82, !1235}
!1235 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1204, size: 64)
!1236 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1237, line: 72)
!1237 = !DISubprogram(name: "feholdexcept", scope: !1211, file: !1211, line: 119, type: !1233, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1238 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1239, line: 73)
!1239 = !DISubprogram(name: "fesetenv", scope: !1211, file: !1211, line: 123, type: !1240, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1240 = !DISubroutineType(types: !1241)
!1241 = !{!82, !1242}
!1242 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1243, size: 64)
!1243 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !1204)
!1244 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1245, line: 74)
!1245 = !DISubprogram(name: "feupdateenv", scope: !1211, file: !1211, line: 128, type: !1240, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1246 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1204, line: 61)
!1247 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1208, line: 62)
!1248 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1210, line: 65)
!1249 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1213, line: 66)
!1250 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1218, line: 67)
!1251 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1220, line: 68)
!1252 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1226, line: 69)
!1253 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1228, line: 71)
!1254 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1230, line: 72)
!1255 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1232, line: 74)
!1256 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1237, line: 75)
!1257 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1239, line: 76)
!1258 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1245, line: 77)
!1259 = !{i32 2, !"Dwarf Version", i32 4}
!1260 = !{i32 2, !"Debug Info Version", i32 3}
!1261 = distinct !DISubprogram(name: "__remill_basic_block", scope: !2, file: !2, line: 52, type: !1262, isLocal: false, isDefinition: true, scopeLine: 52, flags: DIFlagPrototyped, isOptimized: false, unit: !1, variables: !7)
!1262 = !DISubroutineType(types: !1263)
!1263 = !{!1264, !1267, !1950, !1264}
!1264 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1265, size: 64)
!1265 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Memory", file: !1266, line: 36, flags: DIFlagFwdDecl, identifier: "_ZTS6Memory")
!1266 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/Types.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1267 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !1268, size: 64)
!1268 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "State", file: !27, line: 742, size: 27008, align: 128, elements: !1269, identifier: "_ZTS5State")
!1269 = !{!1270, !1282, !1491, !1511, !1541, !1566, !1595, !1632, !1642, !1703, !1728, !1752, !1932}
!1270 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1268, baseType: !1271)
!1271 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "ArchState", file: !1272, line: 21, size: 128, elements: !1273, identifier: "_ZTS9ArchState")
!1272 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/State.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1273 = !{!1274, !1275, !1276}
!1274 = !DIDerivedType(tag: DW_TAG_member, name: "hyper_call", scope: !1271, file: !1272, line: 23, baseType: !4, size: 32)
!1275 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1271, file: !1272, line: 25, baseType: !8, size: 32, offset: 32)
!1276 = !DIDerivedType(tag: DW_TAG_member, scope: !1271, file: !1272, line: 31, baseType: !1277, size: 64, offset: 64)
!1277 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1271, file: !1272, line: 31, size: 64, elements: !1278, identifier: "_ZTSN9ArchStateUt_E")
!1278 = !{!1279, !1280, !1281}
!1279 = !DIDerivedType(tag: DW_TAG_member, name: "addr_to_load", scope: !1277, file: !1272, line: 32, baseType: !637, size: 64)
!1280 = !DIDerivedType(tag: DW_TAG_member, name: "addr_to_store", scope: !1277, file: !1272, line: 33, baseType: !637, size: 64)
!1281 = !DIDerivedType(tag: DW_TAG_member, name: "hyper_call_vector", scope: !1277, file: !1272, line: 34, baseType: !8, size: 32)
!1282 = !DIDerivedType(tag: DW_TAG_member, name: "vec", scope: !1268, file: !27, line: 747, baseType: !1283, size: 16384, offset: 128)
!1283 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1284, size: 16384, elements: !1369)
!1284 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "VectorReg", file: !27, line: 636, size: 512, align: 128, elements: !1285, identifier: "_ZTS9VectorReg")
!1285 = !{!1286, !1361, !1426}
!1286 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1284, file: !27, line: 637, baseType: !1287, size: 128, align: 128)
!1287 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec128_t", file: !1266, line: 317, size: 128, elements: !1288, identifier: "_ZTS8vec128_t")
!1288 = !{!1289, !1298, !1305, !1312, !1317, !1324, !1329, !1334, !1339, !1344, !1349, !1354}
!1289 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1287, file: !1266, line: 321, baseType: !1290, size: 128)
!1290 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v1_t", file: !1266, line: 205, size: 128, elements: !1291, identifier: "_ZTS11uint128v1_t")
!1291 = !{!1292}
!1292 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1290, file: !1266, line: 205, baseType: !1293, size: 128)
!1293 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 128, elements: !1296)
!1294 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint128_t", file: !1266, line: 46, baseType: !1295)
!1295 = !DIBasicType(name: "unsigned __int128", size: 128, encoding: DW_ATE_unsigned)
!1296 = !{!1297}
!1297 = !DISubrange(count: 1)
!1298 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1287, file: !1266, line: 323, baseType: !1299, size: 128)
!1299 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v16_t", file: !1266, line: 182, size: 128, elements: !1300, identifier: "_ZTS10uint8v16_t")
!1300 = !{!1301}
!1301 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1299, file: !1266, line: 182, baseType: !1302, size: 128)
!1302 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 128, elements: !1303)
!1303 = !{!1304}
!1304 = !DISubrange(count: 16)
!1305 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1287, file: !1266, line: 324, baseType: !1306, size: 128)
!1306 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v8_t", file: !1266, line: 189, size: 128, elements: !1307, identifier: "_ZTS10uint16v8_t")
!1307 = !{!1308}
!1308 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1306, file: !1266, line: 189, baseType: !1309, size: 128)
!1309 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 128, elements: !1310)
!1310 = !{!1311}
!1311 = !DISubrange(count: 8)
!1312 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1287, file: !1266, line: 325, baseType: !1313, size: 128)
!1313 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v4_t", file: !1266, line: 195, size: 128, elements: !1314, identifier: "_ZTS10uint32v4_t")
!1314 = !{!1315}
!1315 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1313, file: !1266, line: 195, baseType: !1316, size: 128)
!1316 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 128, elements: !353)
!1317 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1287, file: !1266, line: 326, baseType: !1318, size: 128)
!1318 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v2_t", file: !1266, line: 200, size: 128, elements: !1319, identifier: "_ZTS10uint64v2_t")
!1319 = !{!1320}
!1320 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1318, file: !1266, line: 200, baseType: !1321, size: 128)
!1321 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 128, elements: !1322)
!1322 = !{!1323}
!1323 = !DISubrange(count: 2)
!1324 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1287, file: !1266, line: 327, baseType: !1325, size: 128)
!1325 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v4_t", file: !1266, line: 242, size: 128, elements: !1326, identifier: "_ZTS11float32v4_t")
!1326 = !{!1327}
!1327 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1325, file: !1266, line: 242, baseType: !1328, size: 128)
!1328 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 128, elements: !353)
!1329 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1287, file: !1266, line: 328, baseType: !1330, size: 128)
!1330 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v2_t", file: !1266, line: 247, size: 128, elements: !1331, identifier: "_ZTS11float64v2_t")
!1331 = !{!1332}
!1332 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1330, file: !1266, line: 247, baseType: !1333, size: 128)
!1333 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 128, elements: !1322)
!1334 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1287, file: !1266, line: 330, baseType: !1335, size: 128)
!1335 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v16_t", file: !1266, line: 213, size: 128, elements: !1336, identifier: "_ZTS9int8v16_t")
!1336 = !{!1337}
!1337 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1335, file: !1266, line: 213, baseType: !1338, size: 128)
!1338 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 128, elements: !1303)
!1339 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1287, file: !1266, line: 331, baseType: !1340, size: 128)
!1340 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v8_t", file: !1266, line: 220, size: 128, elements: !1341, identifier: "_ZTS9int16v8_t")
!1341 = !{!1342}
!1342 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1340, file: !1266, line: 220, baseType: !1343, size: 128)
!1343 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 128, elements: !1310)
!1344 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1287, file: !1266, line: 332, baseType: !1345, size: 128)
!1345 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v4_t", file: !1266, line: 226, size: 128, elements: !1346, identifier: "_ZTS9int32v4_t")
!1346 = !{!1347}
!1347 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1345, file: !1266, line: 226, baseType: !1348, size: 128)
!1348 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 128, elements: !353)
!1349 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1287, file: !1266, line: 333, baseType: !1350, size: 128)
!1350 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v2_t", file: !1266, line: 231, size: 128, elements: !1351, identifier: "_ZTS9int64v2_t")
!1351 = !{!1352}
!1352 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1350, file: !1266, line: 231, baseType: !1353, size: 128)
!1353 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 128, elements: !1322)
!1354 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1287, file: !1266, line: 334, baseType: !1355, size: 128)
!1355 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v1_t", file: !1266, line: 236, size: 128, elements: !1356, identifier: "_ZTS10int128v1_t")
!1356 = !{!1357}
!1357 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1355, file: !1266, line: 236, baseType: !1358, size: 128)
!1358 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 128, elements: !1296)
!1359 = !DIDerivedType(tag: DW_TAG_typedef, name: "int128_t", file: !1266, line: 47, baseType: !1360)
!1360 = !DIBasicType(name: "__int128", size: 128, encoding: DW_ATE_signed)
!1361 = !DIDerivedType(tag: DW_TAG_member, name: "ymm", scope: !1284, file: !27, line: 638, baseType: !1362, size: 256, align: 128)
!1362 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec256_t", file: !1266, line: 340, size: 256, elements: !1363, identifier: "_ZTS8vec256_t")
!1363 = !{!1364, !1371, !1376, !1381, !1386, !1391, !1396, !1401, !1406, !1411, !1416, !1421}
!1364 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1362, file: !1266, line: 341, baseType: !1365, size: 256)
!1365 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v32_t", file: !1266, line: 183, size: 256, elements: !1366, identifier: "_ZTS10uint8v32_t")
!1366 = !{!1367}
!1367 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1365, file: !1266, line: 183, baseType: !1368, size: 256)
!1368 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 256, elements: !1369)
!1369 = !{!1370}
!1370 = !DISubrange(count: 32)
!1371 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1362, file: !1266, line: 342, baseType: !1372, size: 256)
!1372 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v16_t", file: !1266, line: 190, size: 256, elements: !1373, identifier: "_ZTS11uint16v16_t")
!1373 = !{!1374}
!1374 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1372, file: !1266, line: 190, baseType: !1375, size: 256)
!1375 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 256, elements: !1303)
!1376 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1362, file: !1266, line: 343, baseType: !1377, size: 256)
!1377 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v8_t", file: !1266, line: 196, size: 256, elements: !1378, identifier: "_ZTS10uint32v8_t")
!1378 = !{!1379}
!1379 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1377, file: !1266, line: 196, baseType: !1380, size: 256)
!1380 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 256, elements: !1310)
!1381 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1362, file: !1266, line: 344, baseType: !1382, size: 256)
!1382 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v4_t", file: !1266, line: 201, size: 256, elements: !1383, identifier: "_ZTS10uint64v4_t")
!1383 = !{!1384}
!1384 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1382, file: !1266, line: 201, baseType: !1385, size: 256)
!1385 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 256, elements: !353)
!1386 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1362, file: !1266, line: 345, baseType: !1387, size: 256)
!1387 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v2_t", file: !1266, line: 206, size: 256, elements: !1388, identifier: "_ZTS11uint128v2_t")
!1388 = !{!1389}
!1389 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1387, file: !1266, line: 206, baseType: !1390, size: 256)
!1390 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 256, elements: !1322)
!1391 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1362, file: !1266, line: 346, baseType: !1392, size: 256)
!1392 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v8_t", file: !1266, line: 243, size: 256, elements: !1393, identifier: "_ZTS11float32v8_t")
!1393 = !{!1394}
!1394 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1392, file: !1266, line: 243, baseType: !1395, size: 256)
!1395 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 256, elements: !1310)
!1396 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1362, file: !1266, line: 347, baseType: !1397, size: 256)
!1397 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v4_t", file: !1266, line: 248, size: 256, elements: !1398, identifier: "_ZTS11float64v4_t")
!1398 = !{!1399}
!1399 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1397, file: !1266, line: 248, baseType: !1400, size: 256)
!1400 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 256, elements: !353)
!1401 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1362, file: !1266, line: 349, baseType: !1402, size: 256)
!1402 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v32_t", file: !1266, line: 214, size: 256, elements: !1403, identifier: "_ZTS9int8v32_t")
!1403 = !{!1404}
!1404 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1402, file: !1266, line: 214, baseType: !1405, size: 256)
!1405 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 256, elements: !1369)
!1406 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1362, file: !1266, line: 350, baseType: !1407, size: 256)
!1407 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v16_t", file: !1266, line: 221, size: 256, elements: !1408, identifier: "_ZTS10int16v16_t")
!1408 = !{!1409}
!1409 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1407, file: !1266, line: 221, baseType: !1410, size: 256)
!1410 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 256, elements: !1303)
!1411 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1362, file: !1266, line: 351, baseType: !1412, size: 256)
!1412 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v8_t", file: !1266, line: 227, size: 256, elements: !1413, identifier: "_ZTS9int32v8_t")
!1413 = !{!1414}
!1414 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1412, file: !1266, line: 227, baseType: !1415, size: 256)
!1415 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 256, elements: !1310)
!1416 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1362, file: !1266, line: 352, baseType: !1417, size: 256)
!1417 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v4_t", file: !1266, line: 232, size: 256, elements: !1418, identifier: "_ZTS9int64v4_t")
!1418 = !{!1419}
!1419 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1417, file: !1266, line: 232, baseType: !1420, size: 256)
!1420 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 256, elements: !353)
!1421 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1362, file: !1266, line: 353, baseType: !1422, size: 256)
!1422 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v2_t", file: !1266, line: 237, size: 256, elements: !1423, identifier: "_ZTS10int128v2_t")
!1423 = !{!1424}
!1424 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1422, file: !1266, line: 237, baseType: !1425, size: 256)
!1425 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 256, elements: !1322)
!1426 = !DIDerivedType(tag: DW_TAG_member, name: "zmm", scope: !1284, file: !27, line: 639, baseType: !1427, size: 512, align: 128)
!1427 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec512_t", file: !1266, line: 359, size: 512, elements: !1428, identifier: "_ZTS8vec512_t")
!1428 = !{!1429, !1436, !1441, !1446, !1451, !1456, !1461, !1466, !1471, !1476, !1481, !1486}
!1429 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1427, file: !1266, line: 360, baseType: !1430, size: 512)
!1430 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v64_t", file: !1266, line: 184, size: 512, elements: !1431, identifier: "_ZTS10uint8v64_t")
!1431 = !{!1432}
!1432 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1430, file: !1266, line: 184, baseType: !1433, size: 512)
!1433 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 512, elements: !1434)
!1434 = !{!1435}
!1435 = !DISubrange(count: 64)
!1436 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1427, file: !1266, line: 361, baseType: !1437, size: 512)
!1437 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v32_t", file: !1266, line: 191, size: 512, elements: !1438, identifier: "_ZTS11uint16v32_t")
!1438 = !{!1439}
!1439 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1437, file: !1266, line: 191, baseType: !1440, size: 512)
!1440 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 512, elements: !1369)
!1441 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1427, file: !1266, line: 362, baseType: !1442, size: 512)
!1442 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v16_t", file: !1266, line: 197, size: 512, elements: !1443, identifier: "_ZTS11uint32v16_t")
!1443 = !{!1444}
!1444 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1442, file: !1266, line: 197, baseType: !1445, size: 512)
!1445 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 512, elements: !1303)
!1446 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1427, file: !1266, line: 363, baseType: !1447, size: 512)
!1447 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v8_t", file: !1266, line: 202, size: 512, elements: !1448, identifier: "_ZTS10uint64v8_t")
!1448 = !{!1449}
!1449 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1447, file: !1266, line: 202, baseType: !1450, size: 512)
!1450 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 512, elements: !1310)
!1451 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1427, file: !1266, line: 364, baseType: !1452, size: 512)
!1452 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v4_t", file: !1266, line: 207, size: 512, elements: !1453, identifier: "_ZTS11uint128v4_t")
!1453 = !{!1454}
!1454 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1452, file: !1266, line: 207, baseType: !1455, size: 512)
!1455 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 512, elements: !353)
!1456 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1427, file: !1266, line: 365, baseType: !1457, size: 512)
!1457 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v16_t", file: !1266, line: 244, size: 512, elements: !1458, identifier: "_ZTS12float32v16_t")
!1458 = !{!1459}
!1459 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1457, file: !1266, line: 244, baseType: !1460, size: 512)
!1460 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 512, elements: !1303)
!1461 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1427, file: !1266, line: 366, baseType: !1462, size: 512)
!1462 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v8_t", file: !1266, line: 249, size: 512, elements: !1463, identifier: "_ZTS11float64v8_t")
!1463 = !{!1464}
!1464 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1462, file: !1266, line: 249, baseType: !1465, size: 512)
!1465 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 512, elements: !1310)
!1466 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1427, file: !1266, line: 368, baseType: !1467, size: 512)
!1467 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v64_t", file: !1266, line: 215, size: 512, elements: !1468, identifier: "_ZTS9int8v64_t")
!1468 = !{!1469}
!1469 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1467, file: !1266, line: 215, baseType: !1470, size: 512)
!1470 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 512, elements: !1434)
!1471 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1427, file: !1266, line: 369, baseType: !1472, size: 512)
!1472 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v32_t", file: !1266, line: 222, size: 512, elements: !1473, identifier: "_ZTS10int16v32_t")
!1473 = !{!1474}
!1474 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1472, file: !1266, line: 222, baseType: !1475, size: 512)
!1475 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 512, elements: !1369)
!1476 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1427, file: !1266, line: 370, baseType: !1477, size: 512)
!1477 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v16_t", file: !1266, line: 228, size: 512, elements: !1478, identifier: "_ZTS10int32v16_t")
!1478 = !{!1479}
!1479 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1477, file: !1266, line: 228, baseType: !1480, size: 512)
!1480 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 512, elements: !1303)
!1481 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1427, file: !1266, line: 371, baseType: !1482, size: 512)
!1482 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v8_t", file: !1266, line: 233, size: 512, elements: !1483, identifier: "_ZTS9int64v8_t")
!1483 = !{!1484}
!1484 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1482, file: !1266, line: 233, baseType: !1485, size: 512)
!1485 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 512, elements: !1310)
!1486 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1427, file: !1266, line: 372, baseType: !1487, size: 512)
!1487 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v4_t", file: !1266, line: 238, size: 512, elements: !1488, identifier: "_ZTS10int128v4_t")
!1488 = !{!1489}
!1489 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1487, file: !1266, line: 238, baseType: !1490, size: 512)
!1490 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 512, elements: !353)
!1491 = !DIDerivedType(tag: DW_TAG_member, name: "aflag", scope: !1268, file: !27, line: 751, baseType: !1492, size: 128, align: 64, offset: 16512)
!1492 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "ArithFlags", file: !27, line: 402, size: 128, align: 64, elements: !1493, identifier: "_ZTS10ArithFlags")
!1493 = !{!1494, !1496, !1497, !1498, !1499, !1500, !1501, !1502, !1503, !1504, !1505, !1506, !1507, !1508, !1509, !1510}
!1494 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1492, file: !27, line: 404, baseType: !1495, size: 8)
!1495 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !62)
!1496 = !DIDerivedType(tag: DW_TAG_member, name: "cf", scope: !1492, file: !27, line: 405, baseType: !62, size: 8, offset: 8)
!1497 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1492, file: !27, line: 406, baseType: !1495, size: 8, offset: 16)
!1498 = !DIDerivedType(tag: DW_TAG_member, name: "pf", scope: !1492, file: !27, line: 407, baseType: !62, size: 8, offset: 24)
!1499 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1492, file: !27, line: 408, baseType: !1495, size: 8, offset: 32)
!1500 = !DIDerivedType(tag: DW_TAG_member, name: "af", scope: !1492, file: !27, line: 409, baseType: !62, size: 8, offset: 40)
!1501 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1492, file: !27, line: 410, baseType: !1495, size: 8, offset: 48)
!1502 = !DIDerivedType(tag: DW_TAG_member, name: "zf", scope: !1492, file: !27, line: 411, baseType: !62, size: 8, offset: 56)
!1503 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1492, file: !27, line: 412, baseType: !1495, size: 8, offset: 64)
!1504 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1492, file: !27, line: 413, baseType: !62, size: 8, offset: 72)
!1505 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1492, file: !27, line: 414, baseType: !1495, size: 8, offset: 80)
!1506 = !DIDerivedType(tag: DW_TAG_member, name: "df", scope: !1492, file: !27, line: 415, baseType: !62, size: 8, offset: 88)
!1507 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1492, file: !27, line: 416, baseType: !1495, size: 8, offset: 96)
!1508 = !DIDerivedType(tag: DW_TAG_member, name: "of", scope: !1492, file: !27, line: 417, baseType: !62, size: 8, offset: 104)
!1509 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1492, file: !27, line: 418, baseType: !1495, size: 8, offset: 112)
!1510 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1492, file: !27, line: 419, baseType: !1495, size: 8, offset: 120)
!1511 = !DIDerivedType(tag: DW_TAG_member, name: "rflag", scope: !1268, file: !27, line: 752, baseType: !1512, size: 64, align: 64, offset: 16640)
!1512 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "Flags", file: !27, line: 366, size: 64, align: 64, elements: !1513, identifier: "_ZTS5Flags")
!1513 = !{!1514, !1515}
!1514 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1512, file: !27, line: 367, baseType: !637, size: 64)
!1515 = !DIDerivedType(tag: DW_TAG_member, scope: !1512, file: !27, line: 368, baseType: !1516, size: 64)
!1516 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1512, file: !27, line: 368, size: 64, elements: !1517, identifier: "_ZTSN5FlagsUt_E")
!1517 = !{!1518, !1519, !1520, !1521, !1522, !1523, !1524, !1525, !1526, !1527, !1528, !1529, !1530, !1531, !1532, !1533, !1534, !1535, !1536, !1537, !1538, !1539, !1540}
!1518 = !DIDerivedType(tag: DW_TAG_member, name: "cf", scope: !1516, file: !27, line: 369, baseType: !8, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1519 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_1", scope: !1516, file: !27, line: 370, baseType: !8, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1520 = !DIDerivedType(tag: DW_TAG_member, name: "pf", scope: !1516, file: !27, line: 371, baseType: !8, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1521 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0a", scope: !1516, file: !27, line: 372, baseType: !8, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1522 = !DIDerivedType(tag: DW_TAG_member, name: "af", scope: !1516, file: !27, line: 374, baseType: !8, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1523 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0b", scope: !1516, file: !27, line: 375, baseType: !8, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1524 = !DIDerivedType(tag: DW_TAG_member, name: "zf", scope: !1516, file: !27, line: 376, baseType: !8, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1525 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1516, file: !27, line: 377, baseType: !8, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1526 = !DIDerivedType(tag: DW_TAG_member, name: "tf", scope: !1516, file: !27, line: 379, baseType: !8, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1527 = !DIDerivedType(tag: DW_TAG_member, name: "_if", scope: !1516, file: !27, line: 380, baseType: !8, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1528 = !DIDerivedType(tag: DW_TAG_member, name: "df", scope: !1516, file: !27, line: 381, baseType: !8, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1529 = !DIDerivedType(tag: DW_TAG_member, name: "of", scope: !1516, file: !27, line: 382, baseType: !8, size: 1, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1530 = !DIDerivedType(tag: DW_TAG_member, name: "iopl", scope: !1516, file: !27, line: 384, baseType: !8, size: 2, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1531 = !DIDerivedType(tag: DW_TAG_member, name: "nt", scope: !1516, file: !27, line: 385, baseType: !8, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1532 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0c", scope: !1516, file: !27, line: 386, baseType: !8, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1533 = !DIDerivedType(tag: DW_TAG_member, name: "rf", scope: !1516, file: !27, line: 388, baseType: !8, size: 1, offset: 16, flags: DIFlagBitField, extraData: i64 0)
!1534 = !DIDerivedType(tag: DW_TAG_member, name: "vm", scope: !1516, file: !27, line: 389, baseType: !8, size: 1, offset: 17, flags: DIFlagBitField, extraData: i64 0)
!1535 = !DIDerivedType(tag: DW_TAG_member, name: "ac", scope: !1516, file: !27, line: 390, baseType: !8, size: 1, offset: 18, flags: DIFlagBitField, extraData: i64 0)
!1536 = !DIDerivedType(tag: DW_TAG_member, name: "vif", scope: !1516, file: !27, line: 391, baseType: !8, size: 1, offset: 19, flags: DIFlagBitField, extraData: i64 0)
!1537 = !DIDerivedType(tag: DW_TAG_member, name: "vip", scope: !1516, file: !27, line: 393, baseType: !8, size: 1, offset: 20, flags: DIFlagBitField, extraData: i64 0)
!1538 = !DIDerivedType(tag: DW_TAG_member, name: "id", scope: !1516, file: !27, line: 394, baseType: !8, size: 1, offset: 21, flags: DIFlagBitField, extraData: i64 0)
!1539 = !DIDerivedType(tag: DW_TAG_member, name: "reserved_eflags", scope: !1516, file: !27, line: 395, baseType: !8, size: 10, offset: 22, flags: DIFlagBitField, extraData: i64 0)
!1540 = !DIDerivedType(tag: DW_TAG_member, name: "reserved_rflags", scope: !1516, file: !27, line: 396, baseType: !8, size: 32, offset: 32)
!1541 = !DIDerivedType(tag: DW_TAG_member, name: "seg", scope: !1268, file: !27, line: 753, baseType: !1542, size: 192, align: 64, offset: 16704)
!1542 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Segments", file: !27, line: 451, size: 192, align: 64, elements: !1543, identifier: "_ZTS8Segments")
!1543 = !{!1544, !1546, !1556, !1557, !1558, !1559, !1560, !1561, !1562, !1563, !1564, !1565}
!1544 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1542, file: !27, line: 452, baseType: !1545, size: 16)
!1545 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !28)
!1546 = !DIDerivedType(tag: DW_TAG_member, name: "ss", scope: !1542, file: !27, line: 453, baseType: !1547, size: 16, offset: 16)
!1547 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "SegmentSelector", file: !27, line: 76, size: 16, elements: !1548, identifier: "_ZTS15SegmentSelector")
!1548 = !{!1549, !1550}
!1549 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1547, file: !27, line: 77, baseType: !28, size: 16)
!1550 = !DIDerivedType(tag: DW_TAG_member, scope: !1547, file: !27, line: 78, baseType: !1551, size: 16)
!1551 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1547, file: !27, line: 78, size: 16, elements: !1552, identifier: "_ZTSN15SegmentSelectorUt_E")
!1552 = !{!1553, !1554, !1555}
!1553 = !DIDerivedType(tag: DW_TAG_member, name: "rpi", scope: !1551, file: !27, line: 79, baseType: !26, size: 2, flags: DIFlagBitField, extraData: i64 0)
!1554 = !DIDerivedType(tag: DW_TAG_member, name: "ti", scope: !1551, file: !27, line: 80, baseType: !35, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1555 = !DIDerivedType(tag: DW_TAG_member, name: "index", scope: !1551, file: !27, line: 81, baseType: !28, size: 13, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1556 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1542, file: !27, line: 454, baseType: !1545, size: 16, offset: 32)
!1557 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1542, file: !27, line: 455, baseType: !1547, size: 16, offset: 48)
!1558 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1542, file: !27, line: 456, baseType: !1545, size: 16, offset: 64)
!1559 = !DIDerivedType(tag: DW_TAG_member, name: "gs", scope: !1542, file: !27, line: 457, baseType: !1547, size: 16, offset: 80)
!1560 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1542, file: !27, line: 458, baseType: !1545, size: 16, offset: 96)
!1561 = !DIDerivedType(tag: DW_TAG_member, name: "fs", scope: !1542, file: !27, line: 459, baseType: !1547, size: 16, offset: 112)
!1562 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1542, file: !27, line: 460, baseType: !1545, size: 16, offset: 128)
!1563 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1542, file: !27, line: 461, baseType: !1547, size: 16, offset: 144)
!1564 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1542, file: !27, line: 462, baseType: !1545, size: 16, offset: 160)
!1565 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1542, file: !27, line: 463, baseType: !1547, size: 16, offset: 176)
!1566 = !DIDerivedType(tag: DW_TAG_member, name: "addr", scope: !1268, file: !27, line: 754, baseType: !1567, size: 768, align: 64, offset: 16896)
!1567 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "AddressSpace", file: !27, line: 654, size: 768, align: 64, elements: !1568, identifier: "_ZTS12AddressSpace")
!1568 = !{!1569, !1571, !1585, !1586, !1587, !1588, !1589, !1590, !1591, !1592, !1593, !1594}
!1569 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1567, file: !27, line: 655, baseType: !1570, size: 64)
!1570 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !637)
!1571 = !DIDerivedType(tag: DW_TAG_member, name: "ss_base", scope: !1567, file: !27, line: 656, baseType: !1572, size: 64, offset: 64)
!1572 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Reg", file: !27, line: 610, size: 64, elements: !1573, identifier: "_ZTS3Reg")
!1573 = !{!1574}
!1574 = !DIDerivedType(tag: DW_TAG_member, scope: !1572, file: !27, line: 611, baseType: !1575, size: 64)
!1575 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1572, file: !27, line: 611, size: 64, elements: !1576, identifier: "_ZTSN3RegUt_E")
!1576 = !{!1577, !1582, !1583, !1584}
!1577 = !DIDerivedType(tag: DW_TAG_member, name: "byte", scope: !1575, file: !27, line: 615, baseType: !1578, size: 16, align: 8)
!1578 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1575, file: !27, line: 612, size: 16, elements: !1579, identifier: "_ZTSN3RegUt_Ut_E")
!1579 = !{!1580, !1581}
!1580 = !DIDerivedType(tag: DW_TAG_member, name: "low", scope: !1578, file: !27, line: 613, baseType: !62, size: 8)
!1581 = !DIDerivedType(tag: DW_TAG_member, name: "high", scope: !1578, file: !27, line: 614, baseType: !62, size: 8, offset: 8)
!1582 = !DIDerivedType(tag: DW_TAG_member, name: "word", scope: !1575, file: !27, line: 616, baseType: !28, size: 16, align: 16)
!1583 = !DIDerivedType(tag: DW_TAG_member, name: "dword", scope: !1575, file: !27, line: 617, baseType: !8, size: 32, align: 32)
!1584 = !DIDerivedType(tag: DW_TAG_member, name: "qword", scope: !1575, file: !27, line: 618, baseType: !637, size: 64, align: 64)
!1585 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1567, file: !27, line: 657, baseType: !1570, size: 64, offset: 128)
!1586 = !DIDerivedType(tag: DW_TAG_member, name: "es_base", scope: !1567, file: !27, line: 658, baseType: !1572, size: 64, offset: 192)
!1587 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1567, file: !27, line: 659, baseType: !1570, size: 64, offset: 256)
!1588 = !DIDerivedType(tag: DW_TAG_member, name: "gs_base", scope: !1567, file: !27, line: 660, baseType: !1572, size: 64, offset: 320)
!1589 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1567, file: !27, line: 661, baseType: !1570, size: 64, offset: 384)
!1590 = !DIDerivedType(tag: DW_TAG_member, name: "fs_base", scope: !1567, file: !27, line: 662, baseType: !1572, size: 64, offset: 448)
!1591 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1567, file: !27, line: 663, baseType: !1570, size: 64, offset: 512)
!1592 = !DIDerivedType(tag: DW_TAG_member, name: "ds_base", scope: !1567, file: !27, line: 664, baseType: !1572, size: 64, offset: 576)
!1593 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1567, file: !27, line: 665, baseType: !1570, size: 64, offset: 640)
!1594 = !DIDerivedType(tag: DW_TAG_member, name: "cs_base", scope: !1567, file: !27, line: 666, baseType: !1572, size: 64, offset: 704)
!1595 = !DIDerivedType(tag: DW_TAG_member, name: "gpr", scope: !1268, file: !27, line: 755, baseType: !1596, size: 2176, align: 64, offset: 17664)
!1596 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "GPR", file: !27, line: 677, size: 2176, align: 64, elements: !1597, identifier: "_ZTS3GPR")
!1597 = !{!1598, !1599, !1600, !1601, !1602, !1603, !1604, !1605, !1606, !1607, !1608, !1609, !1610, !1611, !1612, !1613, !1614, !1615, !1616, !1617, !1618, !1619, !1620, !1621, !1622, !1623, !1624, !1625, !1626, !1627, !1628, !1629, !1630, !1631}
!1598 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1596, file: !27, line: 679, baseType: !1570, size: 64)
!1599 = !DIDerivedType(tag: DW_TAG_member, name: "rax", scope: !1596, file: !27, line: 680, baseType: !1572, size: 64, offset: 64)
!1600 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1596, file: !27, line: 681, baseType: !1570, size: 64, offset: 128)
!1601 = !DIDerivedType(tag: DW_TAG_member, name: "rbx", scope: !1596, file: !27, line: 682, baseType: !1572, size: 64, offset: 192)
!1602 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1596, file: !27, line: 683, baseType: !1570, size: 64, offset: 256)
!1603 = !DIDerivedType(tag: DW_TAG_member, name: "rcx", scope: !1596, file: !27, line: 684, baseType: !1572, size: 64, offset: 320)
!1604 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1596, file: !27, line: 685, baseType: !1570, size: 64, offset: 384)
!1605 = !DIDerivedType(tag: DW_TAG_member, name: "rdx", scope: !1596, file: !27, line: 686, baseType: !1572, size: 64, offset: 448)
!1606 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1596, file: !27, line: 687, baseType: !1570, size: 64, offset: 512)
!1607 = !DIDerivedType(tag: DW_TAG_member, name: "rsi", scope: !1596, file: !27, line: 688, baseType: !1572, size: 64, offset: 576)
!1608 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1596, file: !27, line: 689, baseType: !1570, size: 64, offset: 640)
!1609 = !DIDerivedType(tag: DW_TAG_member, name: "rdi", scope: !1596, file: !27, line: 690, baseType: !1572, size: 64, offset: 704)
!1610 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1596, file: !27, line: 691, baseType: !1570, size: 64, offset: 768)
!1611 = !DIDerivedType(tag: DW_TAG_member, name: "rsp", scope: !1596, file: !27, line: 692, baseType: !1572, size: 64, offset: 832)
!1612 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1596, file: !27, line: 693, baseType: !1570, size: 64, offset: 896)
!1613 = !DIDerivedType(tag: DW_TAG_member, name: "rbp", scope: !1596, file: !27, line: 694, baseType: !1572, size: 64, offset: 960)
!1614 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1596, file: !27, line: 695, baseType: !1570, size: 64, offset: 1024)
!1615 = !DIDerivedType(tag: DW_TAG_member, name: "r8", scope: !1596, file: !27, line: 696, baseType: !1572, size: 64, offset: 1088)
!1616 = !DIDerivedType(tag: DW_TAG_member, name: "_9", scope: !1596, file: !27, line: 697, baseType: !1570, size: 64, offset: 1152)
!1617 = !DIDerivedType(tag: DW_TAG_member, name: "r9", scope: !1596, file: !27, line: 698, baseType: !1572, size: 64, offset: 1216)
!1618 = !DIDerivedType(tag: DW_TAG_member, name: "_10", scope: !1596, file: !27, line: 699, baseType: !1570, size: 64, offset: 1280)
!1619 = !DIDerivedType(tag: DW_TAG_member, name: "r10", scope: !1596, file: !27, line: 700, baseType: !1572, size: 64, offset: 1344)
!1620 = !DIDerivedType(tag: DW_TAG_member, name: "_11", scope: !1596, file: !27, line: 701, baseType: !1570, size: 64, offset: 1408)
!1621 = !DIDerivedType(tag: DW_TAG_member, name: "r11", scope: !1596, file: !27, line: 702, baseType: !1572, size: 64, offset: 1472)
!1622 = !DIDerivedType(tag: DW_TAG_member, name: "_12", scope: !1596, file: !27, line: 703, baseType: !1570, size: 64, offset: 1536)
!1623 = !DIDerivedType(tag: DW_TAG_member, name: "r12", scope: !1596, file: !27, line: 704, baseType: !1572, size: 64, offset: 1600)
!1624 = !DIDerivedType(tag: DW_TAG_member, name: "_13", scope: !1596, file: !27, line: 705, baseType: !1570, size: 64, offset: 1664)
!1625 = !DIDerivedType(tag: DW_TAG_member, name: "r13", scope: !1596, file: !27, line: 706, baseType: !1572, size: 64, offset: 1728)
!1626 = !DIDerivedType(tag: DW_TAG_member, name: "_14", scope: !1596, file: !27, line: 707, baseType: !1570, size: 64, offset: 1792)
!1627 = !DIDerivedType(tag: DW_TAG_member, name: "r14", scope: !1596, file: !27, line: 708, baseType: !1572, size: 64, offset: 1856)
!1628 = !DIDerivedType(tag: DW_TAG_member, name: "_15", scope: !1596, file: !27, line: 709, baseType: !1570, size: 64, offset: 1920)
!1629 = !DIDerivedType(tag: DW_TAG_member, name: "r15", scope: !1596, file: !27, line: 710, baseType: !1572, size: 64, offset: 1984)
!1630 = !DIDerivedType(tag: DW_TAG_member, name: "_16", scope: !1596, file: !27, line: 711, baseType: !1570, size: 64, offset: 2048)
!1631 = !DIDerivedType(tag: DW_TAG_member, name: "rip", scope: !1596, file: !27, line: 714, baseType: !1572, size: 64, offset: 2112)
!1632 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1268, file: !27, line: 756, baseType: !1633, size: 1024, align: 64, offset: 19840)
!1633 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "X87Stack", file: !27, line: 719, size: 1024, align: 64, elements: !1634, identifier: "_ZTS8X87Stack")
!1634 = !{!1635}
!1635 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1633, file: !27, line: 723, baseType: !1636, size: 1024)
!1636 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1637, size: 1024, elements: !1310)
!1637 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1633, file: !27, line: 720, size: 128, align: 64, elements: !1638, identifier: "_ZTSN8X87StackUt_E")
!1638 = !{!1639, !1640}
!1639 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1637, file: !27, line: 721, baseType: !637, size: 64)
!1640 = !DIDerivedType(tag: DW_TAG_member, name: "val", scope: !1637, file: !27, line: 722, baseType: !1641, size: 64, offset: 64)
!1641 = !DIDerivedType(tag: DW_TAG_typedef, name: "float64_t", file: !1266, line: 61, baseType: !108)
!1642 = !DIDerivedType(tag: DW_TAG_member, name: "mmx", scope: !1268, file: !27, line: 757, baseType: !1643, size: 1024, align: 64, offset: 20864)
!1643 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "MMX", file: !27, line: 729, size: 1024, align: 64, elements: !1644, identifier: "_ZTS3MMX")
!1644 = !{!1645}
!1645 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1643, file: !27, line: 733, baseType: !1646, size: 1024)
!1646 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1647, size: 1024, elements: !1310)
!1647 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1643, file: !27, line: 730, size: 128, align: 64, elements: !1648, identifier: "_ZTSN3MMXUt_E")
!1648 = !{!1649, !1650}
!1649 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1647, file: !27, line: 731, baseType: !637, size: 64)
!1650 = !DIDerivedType(tag: DW_TAG_member, name: "val", scope: !1647, file: !27, line: 732, baseType: !1651, size: 64, offset: 64)
!1651 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec64_t", file: !1266, line: 294, size: 64, elements: !1652, identifier: "_ZTS7vec64_t")
!1652 = !{!1653, !1658, !1663, !1668, !1673, !1678, !1683, !1688, !1693, !1698}
!1653 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1651, file: !1266, line: 298, baseType: !1654, size: 64)
!1654 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v1_t", file: !1266, line: 199, size: 64, elements: !1655, identifier: "_ZTS10uint64v1_t")
!1655 = !{!1656}
!1656 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1654, file: !1266, line: 199, baseType: !1657, size: 64)
!1657 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 64, elements: !1296)
!1658 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1651, file: !1266, line: 300, baseType: !1659, size: 64)
!1659 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v8_t", file: !1266, line: 181, size: 64, elements: !1660, identifier: "_ZTS9uint8v8_t")
!1660 = !{!1661}
!1661 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1659, file: !1266, line: 181, baseType: !1662, size: 64)
!1662 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 64, elements: !1310)
!1663 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1651, file: !1266, line: 301, baseType: !1664, size: 64)
!1664 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v4_t", file: !1266, line: 188, size: 64, elements: !1665, identifier: "_ZTS10uint16v4_t")
!1665 = !{!1666}
!1666 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1664, file: !1266, line: 188, baseType: !1667, size: 64)
!1667 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 64, elements: !353)
!1668 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1651, file: !1266, line: 302, baseType: !1669, size: 64)
!1669 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v2_t", file: !1266, line: 194, size: 64, elements: !1670, identifier: "_ZTS10uint32v2_t")
!1670 = !{!1671}
!1671 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1669, file: !1266, line: 194, baseType: !1672, size: 64)
!1672 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 64, elements: !1322)
!1673 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1651, file: !1266, line: 303, baseType: !1674, size: 64)
!1674 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v2_t", file: !1266, line: 241, size: 64, elements: !1675, identifier: "_ZTS11float32v2_t")
!1675 = !{!1676}
!1676 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1674, file: !1266, line: 241, baseType: !1677, size: 64)
!1677 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 64, elements: !1322)
!1678 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1651, file: !1266, line: 304, baseType: !1679, size: 64)
!1679 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v1_t", file: !1266, line: 246, size: 64, elements: !1680, identifier: "_ZTS11float64v1_t")
!1680 = !{!1681}
!1681 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1679, file: !1266, line: 246, baseType: !1682, size: 64)
!1682 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 64, elements: !1296)
!1683 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1651, file: !1266, line: 306, baseType: !1684, size: 64)
!1684 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v8_t", file: !1266, line: 212, size: 64, elements: !1685, identifier: "_ZTS8int8v8_t")
!1685 = !{!1686}
!1686 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1684, file: !1266, line: 212, baseType: !1687, size: 64)
!1687 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 64, elements: !1310)
!1688 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1651, file: !1266, line: 307, baseType: !1689, size: 64)
!1689 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v4_t", file: !1266, line: 219, size: 64, elements: !1690, identifier: "_ZTS9int16v4_t")
!1690 = !{!1691}
!1691 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1689, file: !1266, line: 219, baseType: !1692, size: 64)
!1692 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 64, elements: !353)
!1693 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1651, file: !1266, line: 308, baseType: !1694, size: 64)
!1694 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v2_t", file: !1266, line: 225, size: 64, elements: !1695, identifier: "_ZTS9int32v2_t")
!1695 = !{!1696}
!1696 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1694, file: !1266, line: 225, baseType: !1697, size: 64)
!1697 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 64, elements: !1322)
!1698 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1651, file: !1266, line: 309, baseType: !1699, size: 64)
!1699 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v1_t", file: !1266, line: 230, size: 64, elements: !1700, identifier: "_ZTS9int64v1_t")
!1700 = !{!1701}
!1701 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1699, file: !1266, line: 230, baseType: !1702, size: 64)
!1702 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 64, elements: !1296)
!1703 = !DIDerivedType(tag: DW_TAG_member, name: "sw", scope: !1268, file: !27, line: 758, baseType: !1704, size: 192, offset: 21888)
!1704 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FPUStatusFlags", file: !27, line: 332, size: 192, elements: !1705, identifier: "_ZTS14FPUStatusFlags")
!1705 = !{!1706, !1707, !1708, !1709, !1710, !1711, !1712, !1713, !1714, !1715, !1716, !1717, !1718, !1719, !1720, !1721, !1722, !1723, !1724, !1725, !1726}
!1706 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1704, file: !27, line: 333, baseType: !62, size: 8)
!1707 = !DIDerivedType(tag: DW_TAG_member, name: "c0", scope: !1704, file: !27, line: 334, baseType: !62, size: 8, offset: 8)
!1708 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1704, file: !27, line: 335, baseType: !62, size: 8, offset: 16)
!1709 = !DIDerivedType(tag: DW_TAG_member, name: "c1", scope: !1704, file: !27, line: 336, baseType: !62, size: 8, offset: 24)
!1710 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1704, file: !27, line: 337, baseType: !62, size: 8, offset: 32)
!1711 = !DIDerivedType(tag: DW_TAG_member, name: "c2", scope: !1704, file: !27, line: 338, baseType: !62, size: 8, offset: 40)
!1712 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1704, file: !27, line: 339, baseType: !62, size: 8, offset: 48)
!1713 = !DIDerivedType(tag: DW_TAG_member, name: "c3", scope: !1704, file: !27, line: 340, baseType: !62, size: 8, offset: 56)
!1714 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1704, file: !27, line: 342, baseType: !62, size: 8, offset: 64)
!1715 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1704, file: !27, line: 343, baseType: !62, size: 8, offset: 72)
!1716 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1704, file: !27, line: 345, baseType: !62, size: 8, offset: 80)
!1717 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1704, file: !27, line: 346, baseType: !62, size: 8, offset: 88)
!1718 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1704, file: !27, line: 348, baseType: !62, size: 8, offset: 96)
!1719 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1704, file: !27, line: 349, baseType: !62, size: 8, offset: 104)
!1720 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1704, file: !27, line: 351, baseType: !62, size: 8, offset: 112)
!1721 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1704, file: !27, line: 352, baseType: !62, size: 8, offset: 120)
!1722 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1704, file: !27, line: 354, baseType: !62, size: 8, offset: 128)
!1723 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1704, file: !27, line: 355, baseType: !62, size: 8, offset: 136)
!1724 = !DIDerivedType(tag: DW_TAG_member, name: "_9", scope: !1704, file: !27, line: 357, baseType: !62, size: 8, offset: 144)
!1725 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1704, file: !27, line: 358, baseType: !62, size: 8, offset: 152)
!1726 = !DIDerivedType(tag: DW_TAG_member, name: "_padding", scope: !1704, file: !27, line: 360, baseType: !1727, size: 32, offset: 160)
!1727 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 32, elements: !353)
!1728 = !DIDerivedType(tag: DW_TAG_member, name: "xcr0", scope: !1268, file: !27, line: 759, baseType: !1729, size: 64, offset: 22080)
!1729 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "XCR0", file: !27, line: 424, size: 64, elements: !1730, identifier: "_ZTS4XCR0")
!1730 = !{!1731, !1732, !1737}
!1731 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1729, file: !27, line: 425, baseType: !637, size: 64)
!1732 = !DIDerivedType(tag: DW_TAG_member, scope: !1729, file: !27, line: 427, baseType: !1733, size: 64)
!1733 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1729, file: !27, line: 427, size: 64, elements: !1734, identifier: "_ZTSN4XCR0Ut_E")
!1734 = !{!1735, !1736}
!1735 = !DIDerivedType(tag: DW_TAG_member, name: "eax", scope: !1733, file: !27, line: 428, baseType: !8, size: 32)
!1736 = !DIDerivedType(tag: DW_TAG_member, name: "edx", scope: !1733, file: !27, line: 429, baseType: !8, size: 32, offset: 32)
!1737 = !DIDerivedType(tag: DW_TAG_member, scope: !1729, file: !27, line: 433, baseType: !1738, size: 64)
!1738 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1729, file: !27, line: 433, size: 64, elements: !1739, identifier: "_ZTSN4XCR0Ut0_E")
!1739 = !{!1740, !1741, !1742, !1743, !1744, !1745, !1746, !1747, !1748, !1749, !1750, !1751}
!1740 = !DIDerivedType(tag: DW_TAG_member, name: "x87_fpu_mmx", scope: !1738, file: !27, line: 434, baseType: !637, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1741 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1738, file: !27, line: 435, baseType: !637, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1742 = !DIDerivedType(tag: DW_TAG_member, name: "ymm", scope: !1738, file: !27, line: 436, baseType: !637, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1743 = !DIDerivedType(tag: DW_TAG_member, name: "bndreg", scope: !1738, file: !27, line: 437, baseType: !637, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1744 = !DIDerivedType(tag: DW_TAG_member, name: "bndcsr", scope: !1738, file: !27, line: 438, baseType: !637, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1745 = !DIDerivedType(tag: DW_TAG_member, name: "opmask", scope: !1738, file: !27, line: 439, baseType: !637, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1746 = !DIDerivedType(tag: DW_TAG_member, name: "zmm_hi256", scope: !1738, file: !27, line: 440, baseType: !637, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1747 = !DIDerivedType(tag: DW_TAG_member, name: "hi16_zmm", scope: !1738, file: !27, line: 441, baseType: !637, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1748 = !DIDerivedType(tag: DW_TAG_member, name: "pkru", scope: !1738, file: !27, line: 442, baseType: !637, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1749 = !DIDerivedType(tag: DW_TAG_member, name: "_reserved0", scope: !1738, file: !27, line: 443, baseType: !637, size: 53, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1750 = !DIDerivedType(tag: DW_TAG_member, name: "lwp", scope: !1738, file: !27, line: 444, baseType: !637, size: 1, offset: 62, flags: DIFlagBitField, extraData: i64 0)
!1751 = !DIDerivedType(tag: DW_TAG_member, name: "_reserved1", scope: !1738, file: !27, line: 445, baseType: !637, size: 1, offset: 63, flags: DIFlagBitField, extraData: i64 0)
!1752 = !DIDerivedType(tag: DW_TAG_member, name: "x87", scope: !1268, file: !27, line: 760, baseType: !1753, size: 4096, align: 128, offset: 22144)
!1753 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPU", file: !27, line: 314, size: 4096, align: 128, elements: !1754, identifier: "_ZTS3FPU")
!1754 = !{!1755, !1851, !1914}
!1755 = !DIDerivedType(tag: DW_TAG_member, name: "fsave", scope: !1753, file: !27, line: 317, baseType: !1756, size: 4096)
!1756 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 315, size: 4096, elements: !1757, identifier: "_ZTSN3FPUUt_E")
!1757 = !{!1758, !1847}
!1758 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1756, baseType: !1759)
!1759 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFSAVE", file: !27, line: 263, size: 1248, elements: !1760, identifier: "_ZTS8FpuFSAVE")
!1760 = !{!1761, !1779, !1780, !1801, !1802, !1817, !1818, !1819, !1820, !1821, !1822, !1823, !1824}
!1761 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1759, file: !27, line: 264, baseType: !1762, size: 16)
!1762 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUControlWord", file: !27, line: 142, size: 16, elements: !1763, identifier: "_ZTS14FPUControlWord")
!1763 = !{!1764, !1765}
!1764 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1762, file: !27, line: 143, baseType: !28, size: 16)
!1765 = !DIDerivedType(tag: DW_TAG_member, scope: !1762, file: !27, line: 144, baseType: !1766, size: 16)
!1766 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1762, file: !27, line: 144, size: 16, elements: !1767, identifier: "_ZTSN14FPUControlWordUt_E")
!1767 = !{!1768, !1769, !1770, !1771, !1772, !1773, !1774, !1775, !1776, !1777, !1778}
!1768 = !DIDerivedType(tag: DW_TAG_member, name: "im", scope: !1766, file: !27, line: 145, baseType: !28, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1769 = !DIDerivedType(tag: DW_TAG_member, name: "dm", scope: !1766, file: !27, line: 146, baseType: !28, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1770 = !DIDerivedType(tag: DW_TAG_member, name: "zm", scope: !1766, file: !27, line: 147, baseType: !28, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1771 = !DIDerivedType(tag: DW_TAG_member, name: "om", scope: !1766, file: !27, line: 148, baseType: !28, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1772 = !DIDerivedType(tag: DW_TAG_member, name: "um", scope: !1766, file: !27, line: 149, baseType: !28, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1773 = !DIDerivedType(tag: DW_TAG_member, name: "pm", scope: !1766, file: !27, line: 150, baseType: !28, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1774 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1766, file: !27, line: 151, baseType: !28, size: 2, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1775 = !DIDerivedType(tag: DW_TAG_member, name: "pc", scope: !1766, file: !27, line: 152, baseType: !39, size: 2, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1776 = !DIDerivedType(tag: DW_TAG_member, name: "rc", scope: !1766, file: !27, line: 153, baseType: !45, size: 2, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1777 = !DIDerivedType(tag: DW_TAG_member, name: "x", scope: !1766, file: !27, line: 154, baseType: !51, size: 1, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1778 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1766, file: !27, line: 155, baseType: !28, size: 3, offset: 13, flags: DIFlagBitField, extraData: i64 0)
!1779 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1759, file: !27, line: 265, baseType: !28, size: 16, offset: 16)
!1780 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1759, file: !27, line: 266, baseType: !1781, size: 16, offset: 32)
!1781 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUStatusWord", file: !27, line: 100, size: 16, elements: !1782, identifier: "_ZTS13FPUStatusWord")
!1782 = !{!1783, !1784}
!1783 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1781, file: !27, line: 101, baseType: !28, size: 16)
!1784 = !DIDerivedType(tag: DW_TAG_member, scope: !1781, file: !27, line: 102, baseType: !1785, size: 16)
!1785 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1781, file: !27, line: 102, size: 16, elements: !1786, identifier: "_ZTSN13FPUStatusWordUt_E")
!1786 = !{!1787, !1788, !1789, !1790, !1791, !1792, !1793, !1794, !1795, !1796, !1797, !1798, !1799, !1800}
!1787 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1785, file: !27, line: 103, baseType: !28, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1788 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1785, file: !27, line: 104, baseType: !28, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1789 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1785, file: !27, line: 105, baseType: !28, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1790 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1785, file: !27, line: 106, baseType: !28, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1791 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1785, file: !27, line: 107, baseType: !28, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1792 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1785, file: !27, line: 108, baseType: !28, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1793 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1785, file: !27, line: 109, baseType: !28, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1794 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1785, file: !27, line: 110, baseType: !28, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1795 = !DIDerivedType(tag: DW_TAG_member, name: "c0", scope: !1785, file: !27, line: 111, baseType: !28, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1796 = !DIDerivedType(tag: DW_TAG_member, name: "c1", scope: !1785, file: !27, line: 112, baseType: !28, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1797 = !DIDerivedType(tag: DW_TAG_member, name: "c2", scope: !1785, file: !27, line: 113, baseType: !28, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1798 = !DIDerivedType(tag: DW_TAG_member, name: "top", scope: !1785, file: !27, line: 114, baseType: !28, size: 3, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1799 = !DIDerivedType(tag: DW_TAG_member, name: "c3", scope: !1785, file: !27, line: 115, baseType: !28, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1800 = !DIDerivedType(tag: DW_TAG_member, name: "b", scope: !1785, file: !27, line: 116, baseType: !28, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1801 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1759, file: !27, line: 267, baseType: !28, size: 16, offset: 48)
!1802 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1759, file: !27, line: 268, baseType: !1803, size: 16, offset: 64)
!1803 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUTagWord", file: !27, line: 227, size: 16, elements: !1804, identifier: "_ZTS10FPUTagWord")
!1804 = !{!1805, !1806}
!1805 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1803, file: !27, line: 228, baseType: !28, size: 16)
!1806 = !DIDerivedType(tag: DW_TAG_member, scope: !1803, file: !27, line: 229, baseType: !1807, size: 16)
!1807 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1803, file: !27, line: 229, size: 16, elements: !1808, identifier: "_ZTSN10FPUTagWordUt_E")
!1808 = !{!1809, !1810, !1811, !1812, !1813, !1814, !1815, !1816}
!1809 = !DIDerivedType(tag: DW_TAG_member, name: "tag0", scope: !1807, file: !27, line: 230, baseType: !55, size: 2, flags: DIFlagBitField, extraData: i64 0)
!1810 = !DIDerivedType(tag: DW_TAG_member, name: "tag1", scope: !1807, file: !27, line: 231, baseType: !55, size: 2, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1811 = !DIDerivedType(tag: DW_TAG_member, name: "tag2", scope: !1807, file: !27, line: 232, baseType: !55, size: 2, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1812 = !DIDerivedType(tag: DW_TAG_member, name: "tag3", scope: !1807, file: !27, line: 233, baseType: !55, size: 2, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1813 = !DIDerivedType(tag: DW_TAG_member, name: "tag4", scope: !1807, file: !27, line: 234, baseType: !55, size: 2, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1814 = !DIDerivedType(tag: DW_TAG_member, name: "tag5", scope: !1807, file: !27, line: 235, baseType: !55, size: 2, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1815 = !DIDerivedType(tag: DW_TAG_member, name: "tag6", scope: !1807, file: !27, line: 236, baseType: !55, size: 2, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1816 = !DIDerivedType(tag: DW_TAG_member, name: "tag7", scope: !1807, file: !27, line: 237, baseType: !55, size: 2, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1817 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1759, file: !27, line: 269, baseType: !28, size: 16, offset: 80)
!1818 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1759, file: !27, line: 270, baseType: !8, size: 32, offset: 96)
!1819 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1759, file: !27, line: 271, baseType: !1547, size: 16, offset: 128)
!1820 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd2", scope: !1759, file: !27, line: 272, baseType: !28, size: 16, offset: 144)
!1821 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1759, file: !27, line: 273, baseType: !8, size: 32, offset: 160)
!1822 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1759, file: !27, line: 274, baseType: !1547, size: 16, offset: 192)
!1823 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd3", scope: !1759, file: !27, line: 275, baseType: !28, size: 16, offset: 208)
!1824 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1759, file: !27, line: 276, baseType: !1825, size: 1024, offset: 224)
!1825 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1826, size: 1024, elements: !1310)
!1826 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FPUStackElem", file: !27, line: 162, size: 128, elements: !1827, identifier: "_ZTS12FPUStackElem")
!1827 = !{!1828, !1843}
!1828 = !DIDerivedType(tag: DW_TAG_member, scope: !1826, file: !27, line: 163, baseType: !1829, size: 80)
!1829 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1826, file: !27, line: 163, size: 80, elements: !1830, identifier: "_ZTSN12FPUStackElemUt_E")
!1830 = !{!1831, !1838}
!1831 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1829, file: !27, line: 164, baseType: !1832, size: 80)
!1832 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float80_t", file: !1266, line: 65, size: 80, elements: !1833, identifier: "_ZTS9float80_t")
!1833 = !{!1834}
!1834 = !DIDerivedType(tag: DW_TAG_member, name: "data", scope: !1832, file: !1266, line: 66, baseType: !1835, size: 80)
!1835 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 80, elements: !1836)
!1836 = !{!1837}
!1837 = !DISubrange(count: 10)
!1838 = !DIDerivedType(tag: DW_TAG_member, scope: !1829, file: !27, line: 165, baseType: !1839, size: 80)
!1839 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1829, file: !27, line: 165, size: 80, elements: !1840, identifier: "_ZTSN12FPUStackElemUt_Ut_E")
!1840 = !{!1841, !1842}
!1841 = !DIDerivedType(tag: DW_TAG_member, name: "mmx", scope: !1839, file: !27, line: 166, baseType: !637, size: 64)
!1842 = !DIDerivedType(tag: DW_TAG_member, name: "infinity", scope: !1839, file: !27, line: 167, baseType: !28, size: 16, offset: 64)
!1843 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd", scope: !1826, file: !27, line: 170, baseType: !1844, size: 48, offset: 80)
!1844 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 48, elements: !1845)
!1845 = !{!1846}
!1846 = !DISubrange(count: 6)
!1847 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1756, file: !27, line: 316, baseType: !1848, size: 2848, offset: 1248)
!1848 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 2848, elements: !1849)
!1849 = !{!1850}
!1850 = !DISubrange(count: 356)
!1851 = !DIDerivedType(tag: DW_TAG_member, name: "fxsave32", scope: !1753, file: !27, line: 321, baseType: !1852, size: 4096)
!1852 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 319, size: 4096, elements: !1853, identifier: "_ZTSN3FPUUt0_E")
!1853 = !{!1854, !1910}
!1854 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1852, baseType: !1855)
!1855 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFXSAVE", file: !27, line: 280, size: 3328, elements: !1856, identifier: "_ZTS9FpuFXSAVE")
!1856 = !{!1857, !1858, !1859, !1874, !1875, !1876, !1877, !1878, !1879, !1880, !1881, !1882, !1906, !1907, !1908}
!1857 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1855, file: !27, line: 281, baseType: !1762, size: 16)
!1858 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1855, file: !27, line: 282, baseType: !1781, size: 16, offset: 16)
!1859 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1855, file: !27, line: 283, baseType: !1860, size: 8, offset: 32)
!1860 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUAbridgedTagWord", file: !27, line: 245, size: 8, elements: !1861, identifier: "_ZTS18FPUAbridgedTagWord")
!1861 = !{!1862, !1863}
!1862 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1860, file: !27, line: 246, baseType: !62, size: 8)
!1863 = !DIDerivedType(tag: DW_TAG_member, scope: !1860, file: !27, line: 247, baseType: !1864, size: 8)
!1864 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1860, file: !27, line: 247, size: 8, elements: !1865, identifier: "_ZTSN18FPUAbridgedTagWordUt_E")
!1865 = !{!1866, !1867, !1868, !1869, !1870, !1871, !1872, !1873}
!1866 = !DIDerivedType(tag: DW_TAG_member, name: "r0", scope: !1864, file: !27, line: 248, baseType: !61, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1867 = !DIDerivedType(tag: DW_TAG_member, name: "r1", scope: !1864, file: !27, line: 249, baseType: !61, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1868 = !DIDerivedType(tag: DW_TAG_member, name: "r2", scope: !1864, file: !27, line: 250, baseType: !61, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1869 = !DIDerivedType(tag: DW_TAG_member, name: "r3", scope: !1864, file: !27, line: 251, baseType: !61, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1870 = !DIDerivedType(tag: DW_TAG_member, name: "r4", scope: !1864, file: !27, line: 252, baseType: !61, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1871 = !DIDerivedType(tag: DW_TAG_member, name: "r5", scope: !1864, file: !27, line: 253, baseType: !61, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1872 = !DIDerivedType(tag: DW_TAG_member, name: "r6", scope: !1864, file: !27, line: 254, baseType: !61, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1873 = !DIDerivedType(tag: DW_TAG_member, name: "r7", scope: !1864, file: !27, line: 255, baseType: !61, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1874 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1855, file: !27, line: 284, baseType: !62, size: 8, offset: 40)
!1875 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1855, file: !27, line: 285, baseType: !28, size: 16, offset: 48)
!1876 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1855, file: !27, line: 286, baseType: !8, size: 32, offset: 64)
!1877 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1855, file: !27, line: 287, baseType: !1547, size: 16, offset: 96)
!1878 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1855, file: !27, line: 288, baseType: !28, size: 16, offset: 112)
!1879 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1855, file: !27, line: 289, baseType: !8, size: 32, offset: 128)
!1880 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1855, file: !27, line: 290, baseType: !1547, size: 16, offset: 160)
!1881 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd2", scope: !1855, file: !27, line: 291, baseType: !28, size: 16, offset: 176)
!1882 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr", scope: !1855, file: !27, line: 292, baseType: !1883, size: 32, offset: 192)
!1883 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUControlStatus", file: !27, line: 188, size: 32, elements: !1884, identifier: "_ZTS16FPUControlStatus")
!1884 = !{!1885, !1886}
!1885 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1883, file: !27, line: 189, baseType: !8, size: 32)
!1886 = !DIDerivedType(tag: DW_TAG_member, scope: !1883, file: !27, line: 190, baseType: !1887, size: 32)
!1887 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1883, file: !27, line: 190, size: 32, elements: !1888, identifier: "_ZTSN16FPUControlStatusUt_E")
!1888 = !{!1889, !1890, !1891, !1892, !1893, !1894, !1895, !1896, !1897, !1898, !1899, !1900, !1901, !1902, !1903, !1904, !1905}
!1889 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1887, file: !27, line: 191, baseType: !8, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1890 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1887, file: !27, line: 192, baseType: !8, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1891 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1887, file: !27, line: 193, baseType: !8, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1892 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1887, file: !27, line: 194, baseType: !8, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1893 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1887, file: !27, line: 195, baseType: !8, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1894 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1887, file: !27, line: 196, baseType: !8, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1895 = !DIDerivedType(tag: DW_TAG_member, name: "daz", scope: !1887, file: !27, line: 197, baseType: !8, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1896 = !DIDerivedType(tag: DW_TAG_member, name: "im", scope: !1887, file: !27, line: 198, baseType: !8, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1897 = !DIDerivedType(tag: DW_TAG_member, name: "dm", scope: !1887, file: !27, line: 199, baseType: !8, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1898 = !DIDerivedType(tag: DW_TAG_member, name: "zm", scope: !1887, file: !27, line: 200, baseType: !8, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1899 = !DIDerivedType(tag: DW_TAG_member, name: "om", scope: !1887, file: !27, line: 201, baseType: !8, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1900 = !DIDerivedType(tag: DW_TAG_member, name: "um", scope: !1887, file: !27, line: 202, baseType: !8, size: 1, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1901 = !DIDerivedType(tag: DW_TAG_member, name: "pm", scope: !1887, file: !27, line: 203, baseType: !8, size: 1, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1902 = !DIDerivedType(tag: DW_TAG_member, name: "rn", scope: !1887, file: !27, line: 204, baseType: !8, size: 1, offset: 13, flags: DIFlagBitField, extraData: i64 0)
!1903 = !DIDerivedType(tag: DW_TAG_member, name: "rp", scope: !1887, file: !27, line: 205, baseType: !8, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1904 = !DIDerivedType(tag: DW_TAG_member, name: "fz", scope: !1887, file: !27, line: 206, baseType: !8, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1905 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd", scope: !1887, file: !27, line: 207, baseType: !8, size: 16, offset: 16, flags: DIFlagBitField, extraData: i64 0)
!1906 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr_mask", scope: !1855, file: !27, line: 293, baseType: !1883, size: 32, offset: 224)
!1907 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1855, file: !27, line: 294, baseType: !1825, size: 1024, offset: 256)
!1908 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1855, file: !27, line: 295, baseType: !1909, size: 2048, offset: 1280)
!1909 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1287, size: 2048, elements: !1303)
!1910 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1852, file: !27, line: 320, baseType: !1911, size: 768, offset: 3328)
!1911 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 768, elements: !1912)
!1912 = !{!1913}
!1913 = !DISubrange(count: 96)
!1914 = !DIDerivedType(tag: DW_TAG_member, name: "fxsave64", scope: !1753, file: !27, line: 325, baseType: !1915, size: 4096)
!1915 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 323, size: 4096, elements: !1916, identifier: "_ZTSN3FPUUt1_E")
!1916 = !{!1917, !1931}
!1917 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1915, baseType: !1918)
!1918 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFXSAVE64", file: !27, line: 299, size: 3328, elements: !1919, identifier: "_ZTS11FpuFXSAVE64")
!1919 = !{!1920, !1921, !1922, !1923, !1924, !1925, !1926, !1927, !1928, !1929, !1930}
!1920 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1918, file: !27, line: 300, baseType: !1762, size: 16)
!1921 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1918, file: !27, line: 301, baseType: !1781, size: 16, offset: 16)
!1922 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1918, file: !27, line: 302, baseType: !1860, size: 8, offset: 32)
!1923 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1918, file: !27, line: 303, baseType: !62, size: 8, offset: 40)
!1924 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1918, file: !27, line: 304, baseType: !28, size: 16, offset: 48)
!1925 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1918, file: !27, line: 305, baseType: !637, size: 64, offset: 64)
!1926 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1918, file: !27, line: 306, baseType: !637, size: 64, offset: 128)
!1927 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr", scope: !1918, file: !27, line: 307, baseType: !1883, size: 32, offset: 192)
!1928 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr_mask", scope: !1918, file: !27, line: 308, baseType: !1883, size: 32, offset: 224)
!1929 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1918, file: !27, line: 309, baseType: !1825, size: 1024, offset: 256)
!1930 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1918, file: !27, line: 310, baseType: !1909, size: 2048, offset: 1280)
!1931 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1915, file: !27, line: 324, baseType: !1911, size: 768, offset: 3328)
!1932 = !DIDerivedType(tag: DW_TAG_member, name: "seg_caches", scope: !1268, file: !27, line: 761, baseType: !1933, size: 768, align: 64, offset: 26240)
!1933 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "SegmentCaches", file: !27, line: 468, size: 768, align: 64, elements: !1934, identifier: "_ZTS13SegmentCaches")
!1934 = !{!1935, !1945, !1946, !1947, !1948, !1949}
!1935 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1933, file: !27, line: 469, baseType: !1936, size: 128)
!1936 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "SegmentShadow", file: !27, line: 88, size: 128, elements: !1937, identifier: "_ZTS13SegmentShadow")
!1937 = !{!1938, !1943, !1944}
!1938 = !DIDerivedType(tag: DW_TAG_member, name: "base", scope: !1936, file: !27, line: 92, baseType: !1939, size: 64)
!1939 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1936, file: !27, line: 89, size: 64, elements: !1940, identifier: "_ZTSN13SegmentShadowUt_E")
!1940 = !{!1941, !1942}
!1941 = !DIDerivedType(tag: DW_TAG_member, name: "dword", scope: !1939, file: !27, line: 90, baseType: !8, size: 32)
!1942 = !DIDerivedType(tag: DW_TAG_member, name: "qword", scope: !1939, file: !27, line: 91, baseType: !637, size: 64)
!1943 = !DIDerivedType(tag: DW_TAG_member, name: "limit", scope: !1936, file: !27, line: 93, baseType: !8, size: 32, offset: 64)
!1944 = !DIDerivedType(tag: DW_TAG_member, name: "flags", scope: !1936, file: !27, line: 94, baseType: !8, size: 32, offset: 96)
!1945 = !DIDerivedType(tag: DW_TAG_member, name: "ss", scope: !1933, file: !27, line: 470, baseType: !1936, size: 128, offset: 128)
!1946 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1933, file: !27, line: 471, baseType: !1936, size: 128, offset: 256)
!1947 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1933, file: !27, line: 472, baseType: !1936, size: 128, offset: 384)
!1948 = !DIDerivedType(tag: DW_TAG_member, name: "fs", scope: !1933, file: !27, line: 473, baseType: !1936, size: 128, offset: 512)
!1949 = !DIDerivedType(tag: DW_TAG_member, name: "gs", scope: !1933, file: !27, line: 474, baseType: !1936, size: 128, offset: 640)
!1950 = !DIDerivedType(tag: DW_TAG_typedef, name: "addr_t", file: !1266, line: 42, baseType: !1951)
!1951 = !DIDerivedType(tag: DW_TAG_typedef, name: "addr64_t", file: !1266, line: 41, baseType: !637)
!1952 = !DILocation(line: 54, column: 8, scope: !1261)
!1953 = !DILocation(line: 55, column: 10, scope: !1261)
!1954 = !DILocation(line: 56, column: 10, scope: !1261)
!1955 = !DILocation(line: 57, column: 10, scope: !1261)
!1956 = !DILocation(line: 58, column: 10, scope: !1261)
!1957 = !DILocation(line: 61, column: 9, scope: !1261)
!1958 = !DILocation(line: 62, column: 9, scope: !1261)
!1959 = !DILocation(line: 63, column: 20, scope: !1261)
!1960 = !DILocation(line: 63, column: 24, scope: !1261)
!1961 = !DILocation(line: 63, column: 28, scope: !1261)
!1962 = !DILocation(line: 69, column: 6, scope: !1261)
!1963 = !DILocation(line: 74, column: 20, scope: !1261)
!1964 = !DILocation(line: 74, column: 24, scope: !1261)
!1965 = !DILocation(line: 74, column: 28, scope: !1261)
!1966 = !DILocation(line: 74, column: 33, scope: !1261)
!1967 = !DILocation(line: 75, column: 20, scope: !1261)
!1968 = !DILocation(line: 75, column: 24, scope: !1261)
!1969 = !DILocation(line: 75, column: 28, scope: !1261)
!1970 = !DILocation(line: 75, column: 33, scope: !1261)
!1971 = !DILocation(line: 76, column: 20, scope: !1261)
!1972 = !DILocation(line: 76, column: 24, scope: !1261)
!1973 = !DILocation(line: 76, column: 28, scope: !1261)
!1974 = !DILocation(line: 76, column: 33, scope: !1261)
!1975 = !DILocation(line: 77, column: 20, scope: !1261)
!1976 = !DILocation(line: 77, column: 24, scope: !1261)
!1977 = !DILocation(line: 77, column: 28, scope: !1261)
!1978 = !DILocation(line: 77, column: 33, scope: !1261)
!1979 = !DILocation(line: 78, column: 20, scope: !1261)
!1980 = !DILocation(line: 78, column: 24, scope: !1261)
!1981 = !DILocation(line: 78, column: 28, scope: !1261)
!1982 = !DILocation(line: 78, column: 33, scope: !1261)
!1983 = !DILocation(line: 79, column: 20, scope: !1261)
!1984 = !DILocation(line: 79, column: 24, scope: !1261)
!1985 = !DILocation(line: 79, column: 28, scope: !1261)
!1986 = !DILocation(line: 79, column: 33, scope: !1261)
!1987 = !DILocation(line: 80, column: 20, scope: !1261)
!1988 = !DILocation(line: 80, column: 24, scope: !1261)
!1989 = !DILocation(line: 80, column: 28, scope: !1261)
!1990 = !DILocation(line: 80, column: 33, scope: !1261)
!1991 = !DILocation(line: 81, column: 20, scope: !1261)
!1992 = !DILocation(line: 81, column: 24, scope: !1261)
!1993 = !DILocation(line: 81, column: 28, scope: !1261)
!1994 = !DILocation(line: 81, column: 33, scope: !1261)
!1995 = !DILocation(line: 83, column: 21, scope: !1261)
!1996 = !DILocation(line: 83, column: 25, scope: !1261)
!1997 = !DILocation(line: 83, column: 29, scope: !1261)
!1998 = !DILocation(line: 83, column: 34, scope: !1261)
!1999 = !DILocation(line: 84, column: 21, scope: !1261)
!2000 = !DILocation(line: 84, column: 25, scope: !1261)
!2001 = !DILocation(line: 84, column: 29, scope: !1261)
!2002 = !DILocation(line: 84, column: 34, scope: !1261)
!2003 = !DILocation(line: 85, column: 21, scope: !1261)
!2004 = !DILocation(line: 85, column: 25, scope: !1261)
!2005 = !DILocation(line: 85, column: 29, scope: !1261)
!2006 = !DILocation(line: 85, column: 34, scope: !1261)
!2007 = !DILocation(line: 86, column: 21, scope: !1261)
!2008 = !DILocation(line: 86, column: 25, scope: !1261)
!2009 = !DILocation(line: 86, column: 29, scope: !1261)
!2010 = !DILocation(line: 86, column: 34, scope: !1261)
!2011 = !DILocation(line: 87, column: 21, scope: !1261)
!2012 = !DILocation(line: 87, column: 25, scope: !1261)
!2013 = !DILocation(line: 87, column: 28, scope: !1261)
!2014 = !DILocation(line: 87, column: 33, scope: !1261)
!2015 = !DILocation(line: 88, column: 21, scope: !1261)
!2016 = !DILocation(line: 88, column: 25, scope: !1261)
!2017 = !DILocation(line: 88, column: 28, scope: !1261)
!2018 = !DILocation(line: 88, column: 33, scope: !1261)
!2019 = !DILocation(line: 89, column: 22, scope: !1261)
!2020 = !DILocation(line: 89, column: 26, scope: !1261)
!2021 = !DILocation(line: 89, column: 30, scope: !1261)
!2022 = !DILocation(line: 89, column: 35, scope: !1261)
!2023 = !DILocation(line: 90, column: 22, scope: !1261)
!2024 = !DILocation(line: 90, column: 26, scope: !1261)
!2025 = !DILocation(line: 90, column: 30, scope: !1261)
!2026 = !DILocation(line: 90, column: 35, scope: !1261)
!2027 = !DILocation(line: 91, column: 22, scope: !1261)
!2028 = !DILocation(line: 91, column: 26, scope: !1261)
!2029 = !DILocation(line: 91, column: 30, scope: !1261)
!2030 = !DILocation(line: 91, column: 35, scope: !1261)
!2031 = !DILocation(line: 92, column: 22, scope: !1261)
!2032 = !DILocation(line: 92, column: 26, scope: !1261)
!2033 = !DILocation(line: 92, column: 30, scope: !1261)
!2034 = !DILocation(line: 92, column: 35, scope: !1261)
!2035 = !DILocation(line: 93, column: 22, scope: !1261)
!2036 = !DILocation(line: 93, column: 26, scope: !1261)
!2037 = !DILocation(line: 93, column: 30, scope: !1261)
!2038 = !DILocation(line: 93, column: 35, scope: !1261)
!2039 = !DILocation(line: 94, column: 22, scope: !1261)
!2040 = !DILocation(line: 94, column: 26, scope: !1261)
!2041 = !DILocation(line: 94, column: 30, scope: !1261)
!2042 = !DILocation(line: 94, column: 35, scope: !1261)
!2043 = !DILocation(line: 96, column: 20, scope: !1261)
!2044 = !DILocation(line: 96, column: 24, scope: !1261)
!2045 = !DILocation(line: 96, column: 28, scope: !1261)
!2046 = !DILocation(line: 97, column: 20, scope: !1261)
!2047 = !DILocation(line: 97, column: 24, scope: !1261)
!2048 = !DILocation(line: 97, column: 28, scope: !1261)
!2049 = !DILocation(line: 98, column: 20, scope: !1261)
!2050 = !DILocation(line: 98, column: 24, scope: !1261)
!2051 = !DILocation(line: 98, column: 28, scope: !1261)
!2052 = !DILocation(line: 99, column: 20, scope: !1261)
!2053 = !DILocation(line: 99, column: 24, scope: !1261)
!2054 = !DILocation(line: 99, column: 28, scope: !1261)
!2055 = !DILocation(line: 100, column: 20, scope: !1261)
!2056 = !DILocation(line: 100, column: 24, scope: !1261)
!2057 = !DILocation(line: 100, column: 28, scope: !1261)
!2058 = !DILocation(line: 101, column: 20, scope: !1261)
!2059 = !DILocation(line: 101, column: 24, scope: !1261)
!2060 = !DILocation(line: 101, column: 28, scope: !1261)
!2061 = !DILocation(line: 102, column: 20, scope: !1261)
!2062 = !DILocation(line: 102, column: 24, scope: !1261)
!2063 = !DILocation(line: 102, column: 28, scope: !1261)
!2064 = !DILocation(line: 103, column: 20, scope: !1261)
!2065 = !DILocation(line: 103, column: 24, scope: !1261)
!2066 = !DILocation(line: 103, column: 28, scope: !1261)
!2067 = !DILocation(line: 105, column: 21, scope: !1261)
!2068 = !DILocation(line: 105, column: 25, scope: !1261)
!2069 = !DILocation(line: 105, column: 28, scope: !1261)
!2070 = !DILocation(line: 106, column: 21, scope: !1261)
!2071 = !DILocation(line: 106, column: 25, scope: !1261)
!2072 = !DILocation(line: 106, column: 28, scope: !1261)
!2073 = !DILocation(line: 107, column: 22, scope: !1261)
!2074 = !DILocation(line: 107, column: 26, scope: !1261)
!2075 = !DILocation(line: 107, column: 30, scope: !1261)
!2076 = !DILocation(line: 108, column: 22, scope: !1261)
!2077 = !DILocation(line: 108, column: 26, scope: !1261)
!2078 = !DILocation(line: 108, column: 30, scope: !1261)
!2079 = !DILocation(line: 109, column: 22, scope: !1261)
!2080 = !DILocation(line: 109, column: 26, scope: !1261)
!2081 = !DILocation(line: 109, column: 30, scope: !1261)
!2082 = !DILocation(line: 110, column: 22, scope: !1261)
!2083 = !DILocation(line: 110, column: 26, scope: !1261)
!2084 = !DILocation(line: 110, column: 30, scope: !1261)
!2085 = !DILocation(line: 111, column: 22, scope: !1261)
!2086 = !DILocation(line: 111, column: 26, scope: !1261)
!2087 = !DILocation(line: 111, column: 30, scope: !1261)
!2088 = !DILocation(line: 112, column: 22, scope: !1261)
!2089 = !DILocation(line: 112, column: 26, scope: !1261)
!2090 = !DILocation(line: 112, column: 30, scope: !1261)
!2091 = !DILocation(line: 114, column: 20, scope: !1261)
!2092 = !DILocation(line: 114, column: 24, scope: !1261)
!2093 = !DILocation(line: 114, column: 28, scope: !1261)
!2094 = !DILocation(line: 116, column: 21, scope: !1261)
!2095 = !DILocation(line: 116, column: 25, scope: !1261)
!2096 = !DILocation(line: 116, column: 29, scope: !1261)
!2097 = !DILocation(line: 117, column: 21, scope: !1261)
!2098 = !DILocation(line: 117, column: 25, scope: !1261)
!2099 = !DILocation(line: 117, column: 29, scope: !1261)
!2100 = !DILocation(line: 118, column: 21, scope: !1261)
!2101 = !DILocation(line: 118, column: 25, scope: !1261)
!2102 = !DILocation(line: 118, column: 29, scope: !1261)
!2103 = !DILocation(line: 119, column: 21, scope: !1261)
!2104 = !DILocation(line: 119, column: 25, scope: !1261)
!2105 = !DILocation(line: 119, column: 29, scope: !1261)
!2106 = !DILocation(line: 120, column: 21, scope: !1261)
!2107 = !DILocation(line: 120, column: 25, scope: !1261)
!2108 = !DILocation(line: 120, column: 29, scope: !1261)
!2109 = !DILocation(line: 121, column: 21, scope: !1261)
!2110 = !DILocation(line: 121, column: 25, scope: !1261)
!2111 = !DILocation(line: 121, column: 29, scope: !1261)
!2112 = !DILocation(line: 122, column: 21, scope: !1261)
!2113 = !DILocation(line: 122, column: 25, scope: !1261)
!2114 = !DILocation(line: 122, column: 29, scope: !1261)
!2115 = !DILocation(line: 123, column: 21, scope: !1261)
!2116 = !DILocation(line: 123, column: 25, scope: !1261)
!2117 = !DILocation(line: 123, column: 29, scope: !1261)
!2118 = !DILocation(line: 124, column: 21, scope: !1261)
!2119 = !DILocation(line: 124, column: 25, scope: !1261)
!2120 = !DILocation(line: 124, column: 29, scope: !1261)
!2121 = !DILocation(line: 127, column: 21, scope: !1261)
!2122 = !DILocation(line: 127, column: 25, scope: !1261)
!2123 = !DILocation(line: 127, column: 28, scope: !1261)
!2124 = !DILocation(line: 128, column: 21, scope: !1261)
!2125 = !DILocation(line: 128, column: 25, scope: !1261)
!2126 = !DILocation(line: 128, column: 28, scope: !1261)
!2127 = !DILocation(line: 129, column: 22, scope: !1261)
!2128 = !DILocation(line: 129, column: 26, scope: !1261)
!2129 = !DILocation(line: 129, column: 30, scope: !1261)
!2130 = !DILocation(line: 130, column: 22, scope: !1261)
!2131 = !DILocation(line: 130, column: 26, scope: !1261)
!2132 = !DILocation(line: 130, column: 30, scope: !1261)
!2133 = !DILocation(line: 131, column: 22, scope: !1261)
!2134 = !DILocation(line: 131, column: 26, scope: !1261)
!2135 = !DILocation(line: 131, column: 30, scope: !1261)
!2136 = !DILocation(line: 132, column: 22, scope: !1261)
!2137 = !DILocation(line: 132, column: 26, scope: !1261)
!2138 = !DILocation(line: 132, column: 30, scope: !1261)
!2139 = !DILocation(line: 133, column: 22, scope: !1261)
!2140 = !DILocation(line: 133, column: 26, scope: !1261)
!2141 = !DILocation(line: 133, column: 30, scope: !1261)
!2142 = !DILocation(line: 134, column: 22, scope: !1261)
!2143 = !DILocation(line: 134, column: 26, scope: !1261)
!2144 = !DILocation(line: 134, column: 30, scope: !1261)
!2145 = !DILocation(line: 136, column: 21, scope: !1261)
!2146 = !DILocation(line: 136, column: 25, scope: !1261)
!2147 = !DILocation(line: 136, column: 29, scope: !1261)
!2148 = !DILocation(line: 137, column: 21, scope: !1261)
!2149 = !DILocation(line: 137, column: 25, scope: !1261)
!2150 = !DILocation(line: 137, column: 29, scope: !1261)
!2151 = !DILocation(line: 138, column: 21, scope: !1261)
!2152 = !DILocation(line: 138, column: 25, scope: !1261)
!2153 = !DILocation(line: 138, column: 29, scope: !1261)
!2154 = !DILocation(line: 139, column: 21, scope: !1261)
!2155 = !DILocation(line: 139, column: 25, scope: !1261)
!2156 = !DILocation(line: 139, column: 29, scope: !1261)
!2157 = !DILocation(line: 140, column: 21, scope: !1261)
!2158 = !DILocation(line: 140, column: 25, scope: !1261)
!2159 = !DILocation(line: 140, column: 29, scope: !1261)
!2160 = !DILocation(line: 141, column: 21, scope: !1261)
!2161 = !DILocation(line: 141, column: 25, scope: !1261)
!2162 = !DILocation(line: 141, column: 29, scope: !1261)
!2163 = !DILocation(line: 142, column: 21, scope: !1261)
!2164 = !DILocation(line: 142, column: 25, scope: !1261)
!2165 = !DILocation(line: 142, column: 29, scope: !1261)
!2166 = !DILocation(line: 143, column: 21, scope: !1261)
!2167 = !DILocation(line: 143, column: 25, scope: !1261)
!2168 = !DILocation(line: 143, column: 29, scope: !1261)
!2169 = !DILocation(line: 144, column: 20, scope: !1261)
!2170 = !DILocation(line: 144, column: 24, scope: !1261)
!2171 = !DILocation(line: 144, column: 27, scope: !1261)
!2172 = !DILocation(line: 145, column: 20, scope: !1261)
!2173 = !DILocation(line: 145, column: 24, scope: !1261)
!2174 = !DILocation(line: 145, column: 27, scope: !1261)
!2175 = !DILocation(line: 146, column: 21, scope: !1261)
!2176 = !DILocation(line: 146, column: 25, scope: !1261)
!2177 = !DILocation(line: 146, column: 29, scope: !1261)
!2178 = !DILocation(line: 147, column: 21, scope: !1261)
!2179 = !DILocation(line: 147, column: 25, scope: !1261)
!2180 = !DILocation(line: 147, column: 29, scope: !1261)
!2181 = !DILocation(line: 148, column: 21, scope: !1261)
!2182 = !DILocation(line: 148, column: 25, scope: !1261)
!2183 = !DILocation(line: 148, column: 29, scope: !1261)
!2184 = !DILocation(line: 149, column: 21, scope: !1261)
!2185 = !DILocation(line: 149, column: 25, scope: !1261)
!2186 = !DILocation(line: 149, column: 29, scope: !1261)
!2187 = !DILocation(line: 150, column: 21, scope: !1261)
!2188 = !DILocation(line: 150, column: 25, scope: !1261)
!2189 = !DILocation(line: 150, column: 29, scope: !1261)
!2190 = !DILocation(line: 151, column: 21, scope: !1261)
!2191 = !DILocation(line: 151, column: 25, scope: !1261)
!2192 = !DILocation(line: 151, column: 29, scope: !1261)
!2193 = !DILocation(line: 152, column: 21, scope: !1261)
!2194 = !DILocation(line: 152, column: 25, scope: !1261)
!2195 = !DILocation(line: 152, column: 29, scope: !1261)
!2196 = !DILocation(line: 155, column: 20, scope: !1261)
!2197 = !DILocation(line: 155, column: 24, scope: !1261)
!2198 = !DILocation(line: 155, column: 27, scope: !1261)
!2199 = !DILocation(line: 156, column: 20, scope: !1261)
!2200 = !DILocation(line: 156, column: 24, scope: !1261)
!2201 = !DILocation(line: 156, column: 27, scope: !1261)
!2202 = !DILocation(line: 157, column: 20, scope: !1261)
!2203 = !DILocation(line: 157, column: 24, scope: !1261)
!2204 = !DILocation(line: 157, column: 27, scope: !1261)
!2205 = !DILocation(line: 158, column: 20, scope: !1261)
!2206 = !DILocation(line: 158, column: 24, scope: !1261)
!2207 = !DILocation(line: 158, column: 27, scope: !1261)
!2208 = !DILocation(line: 159, column: 20, scope: !1261)
!2209 = !DILocation(line: 159, column: 24, scope: !1261)
!2210 = !DILocation(line: 159, column: 27, scope: !1261)
!2211 = !DILocation(line: 160, column: 20, scope: !1261)
!2212 = !DILocation(line: 160, column: 24, scope: !1261)
!2213 = !DILocation(line: 160, column: 27, scope: !1261)
!2214 = !DILocation(line: 164, column: 25, scope: !1261)
!2215 = !DILocation(line: 164, column: 30, scope: !1261)
!2216 = !DILocation(line: 164, column: 38, scope: !1261)
!2217 = !DILocation(line: 165, column: 25, scope: !1261)
!2218 = !DILocation(line: 165, column: 30, scope: !1261)
!2219 = !DILocation(line: 165, column: 38, scope: !1261)
!2220 = !DILocation(line: 205, column: 22, scope: !1261)
!2221 = !DILocation(line: 205, column: 16, scope: !1261)
!2222 = !DILocation(line: 205, column: 29, scope: !1261)
!2223 = !DILocation(line: 206, column: 22, scope: !1261)
!2224 = !DILocation(line: 206, column: 16, scope: !1261)
!2225 = !DILocation(line: 206, column: 29, scope: !1261)
!2226 = !DILocation(line: 207, column: 22, scope: !1261)
!2227 = !DILocation(line: 207, column: 16, scope: !1261)
!2228 = !DILocation(line: 207, column: 29, scope: !1261)
!2229 = !DILocation(line: 208, column: 22, scope: !1261)
!2230 = !DILocation(line: 208, column: 16, scope: !1261)
!2231 = !DILocation(line: 208, column: 29, scope: !1261)
!2232 = !DILocation(line: 209, column: 22, scope: !1261)
!2233 = !DILocation(line: 209, column: 16, scope: !1261)
!2234 = !DILocation(line: 209, column: 29, scope: !1261)
!2235 = !DILocation(line: 210, column: 22, scope: !1261)
!2236 = !DILocation(line: 210, column: 16, scope: !1261)
!2237 = !DILocation(line: 210, column: 29, scope: !1261)
!2238 = !DILocation(line: 211, column: 22, scope: !1261)
!2239 = !DILocation(line: 211, column: 16, scope: !1261)
!2240 = !DILocation(line: 211, column: 29, scope: !1261)
!2241 = !DILocation(line: 212, column: 22, scope: !1261)
!2242 = !DILocation(line: 212, column: 16, scope: !1261)
!2243 = !DILocation(line: 212, column: 29, scope: !1261)
!2244 = !DILocation(line: 214, column: 22, scope: !1261)
!2245 = !DILocation(line: 214, column: 16, scope: !1261)
!2246 = !DILocation(line: 214, column: 29, scope: !1261)
!2247 = !DILocation(line: 215, column: 22, scope: !1261)
!2248 = !DILocation(line: 215, column: 16, scope: !1261)
!2249 = !DILocation(line: 215, column: 29, scope: !1261)
!2250 = !DILocation(line: 216, column: 23, scope: !1261)
!2251 = !DILocation(line: 216, column: 17, scope: !1261)
!2252 = !DILocation(line: 216, column: 31, scope: !1261)
!2253 = !DILocation(line: 217, column: 23, scope: !1261)
!2254 = !DILocation(line: 217, column: 17, scope: !1261)
!2255 = !DILocation(line: 217, column: 31, scope: !1261)
!2256 = !DILocation(line: 218, column: 23, scope: !1261)
!2257 = !DILocation(line: 218, column: 17, scope: !1261)
!2258 = !DILocation(line: 218, column: 31, scope: !1261)
!2259 = !DILocation(line: 219, column: 23, scope: !1261)
!2260 = !DILocation(line: 219, column: 17, scope: !1261)
!2261 = !DILocation(line: 219, column: 31, scope: !1261)
!2262 = !DILocation(line: 220, column: 23, scope: !1261)
!2263 = !DILocation(line: 220, column: 17, scope: !1261)
!2264 = !DILocation(line: 220, column: 31, scope: !1261)
!2265 = !DILocation(line: 221, column: 23, scope: !1261)
!2266 = !DILocation(line: 221, column: 17, scope: !1261)
!2267 = !DILocation(line: 221, column: 31, scope: !1261)
!2268 = !DILocation(line: 245, column: 22, scope: !1261)
!2269 = !DILocation(line: 245, column: 16, scope: !1261)
!2270 = !DILocation(line: 245, column: 29, scope: !1261)
!2271 = !DILocation(line: 246, column: 22, scope: !1261)
!2272 = !DILocation(line: 246, column: 16, scope: !1261)
!2273 = !DILocation(line: 246, column: 29, scope: !1261)
!2274 = !DILocation(line: 247, column: 22, scope: !1261)
!2275 = !DILocation(line: 247, column: 16, scope: !1261)
!2276 = !DILocation(line: 247, column: 29, scope: !1261)
!2277 = !DILocation(line: 248, column: 22, scope: !1261)
!2278 = !DILocation(line: 248, column: 16, scope: !1261)
!2279 = !DILocation(line: 248, column: 29, scope: !1261)
!2280 = !DILocation(line: 249, column: 22, scope: !1261)
!2281 = !DILocation(line: 249, column: 16, scope: !1261)
!2282 = !DILocation(line: 249, column: 29, scope: !1261)
!2283 = !DILocation(line: 250, column: 22, scope: !1261)
!2284 = !DILocation(line: 250, column: 16, scope: !1261)
!2285 = !DILocation(line: 250, column: 29, scope: !1261)
!2286 = !DILocation(line: 251, column: 22, scope: !1261)
!2287 = !DILocation(line: 251, column: 16, scope: !1261)
!2288 = !DILocation(line: 251, column: 29, scope: !1261)
!2289 = !DILocation(line: 252, column: 22, scope: !1261)
!2290 = !DILocation(line: 252, column: 16, scope: !1261)
!2291 = !DILocation(line: 252, column: 29, scope: !1261)
!2292 = !DILocation(line: 255, column: 22, scope: !1261)
!2293 = !DILocation(line: 255, column: 16, scope: !1261)
!2294 = !DILocation(line: 255, column: 29, scope: !1261)
!2295 = !DILocation(line: 256, column: 22, scope: !1261)
!2296 = !DILocation(line: 256, column: 16, scope: !1261)
!2297 = !DILocation(line: 256, column: 29, scope: !1261)
!2298 = !DILocation(line: 257, column: 23, scope: !1261)
!2299 = !DILocation(line: 257, column: 17, scope: !1261)
!2300 = !DILocation(line: 257, column: 31, scope: !1261)
!2301 = !DILocation(line: 258, column: 23, scope: !1261)
!2302 = !DILocation(line: 258, column: 17, scope: !1261)
!2303 = !DILocation(line: 258, column: 31, scope: !1261)
!2304 = !DILocation(line: 259, column: 23, scope: !1261)
!2305 = !DILocation(line: 259, column: 17, scope: !1261)
!2306 = !DILocation(line: 259, column: 31, scope: !1261)
!2307 = !DILocation(line: 260, column: 23, scope: !1261)
!2308 = !DILocation(line: 260, column: 17, scope: !1261)
!2309 = !DILocation(line: 260, column: 31, scope: !1261)
!2310 = !DILocation(line: 261, column: 23, scope: !1261)
!2311 = !DILocation(line: 261, column: 17, scope: !1261)
!2312 = !DILocation(line: 261, column: 31, scope: !1261)
!2313 = !DILocation(line: 262, column: 23, scope: !1261)
!2314 = !DILocation(line: 262, column: 17, scope: !1261)
!2315 = !DILocation(line: 262, column: 31, scope: !1261)
!2316 = !DILocation(line: 285, column: 21, scope: !1261)
!2317 = !DILocation(line: 285, column: 24, scope: !1261)
!2318 = !DILocation(line: 285, column: 15, scope: !1261)
!2319 = !DILocation(line: 285, column: 33, scope: !1261)
!2320 = !DILocation(line: 286, column: 21, scope: !1261)
!2321 = !DILocation(line: 286, column: 24, scope: !1261)
!2322 = !DILocation(line: 286, column: 15, scope: !1261)
!2323 = !DILocation(line: 286, column: 33, scope: !1261)
!2324 = !DILocation(line: 287, column: 21, scope: !1261)
!2325 = !DILocation(line: 287, column: 24, scope: !1261)
!2326 = !DILocation(line: 287, column: 15, scope: !1261)
!2327 = !DILocation(line: 287, column: 33, scope: !1261)
!2328 = !DILocation(line: 288, column: 21, scope: !1261)
!2329 = !DILocation(line: 288, column: 24, scope: !1261)
!2330 = !DILocation(line: 288, column: 15, scope: !1261)
!2331 = !DILocation(line: 288, column: 33, scope: !1261)
!2332 = !DILocation(line: 289, column: 21, scope: !1261)
!2333 = !DILocation(line: 289, column: 24, scope: !1261)
!2334 = !DILocation(line: 289, column: 15, scope: !1261)
!2335 = !DILocation(line: 289, column: 33, scope: !1261)
!2336 = !DILocation(line: 290, column: 21, scope: !1261)
!2337 = !DILocation(line: 290, column: 24, scope: !1261)
!2338 = !DILocation(line: 290, column: 15, scope: !1261)
!2339 = !DILocation(line: 290, column: 33, scope: !1261)
!2340 = !DILocation(line: 291, column: 21, scope: !1261)
!2341 = !DILocation(line: 291, column: 24, scope: !1261)
!2342 = !DILocation(line: 291, column: 15, scope: !1261)
!2343 = !DILocation(line: 291, column: 33, scope: !1261)
!2344 = !DILocation(line: 292, column: 21, scope: !1261)
!2345 = !DILocation(line: 292, column: 24, scope: !1261)
!2346 = !DILocation(line: 292, column: 15, scope: !1261)
!2347 = !DILocation(line: 292, column: 33, scope: !1261)
!2348 = !DILocation(line: 318, column: 21, scope: !1261)
!2349 = !DILocation(line: 318, column: 25, scope: !1261)
!2350 = !DILocation(line: 318, column: 15, scope: !1261)
!2351 = !DILocation(line: 318, column: 34, scope: !1261)
!2352 = !DILocation(line: 318, column: 38, scope: !1261)
!2353 = !DILocation(line: 318, column: 45, scope: !1261)
!2354 = !DILocation(line: 319, column: 21, scope: !1261)
!2355 = !DILocation(line: 319, column: 25, scope: !1261)
!2356 = !DILocation(line: 319, column: 15, scope: !1261)
!2357 = !DILocation(line: 319, column: 34, scope: !1261)
!2358 = !DILocation(line: 319, column: 38, scope: !1261)
!2359 = !DILocation(line: 319, column: 45, scope: !1261)
!2360 = !DILocation(line: 320, column: 21, scope: !1261)
!2361 = !DILocation(line: 320, column: 25, scope: !1261)
!2362 = !DILocation(line: 320, column: 15, scope: !1261)
!2363 = !DILocation(line: 320, column: 34, scope: !1261)
!2364 = !DILocation(line: 320, column: 38, scope: !1261)
!2365 = !DILocation(line: 320, column: 45, scope: !1261)
!2366 = !DILocation(line: 321, column: 21, scope: !1261)
!2367 = !DILocation(line: 321, column: 25, scope: !1261)
!2368 = !DILocation(line: 321, column: 15, scope: !1261)
!2369 = !DILocation(line: 321, column: 34, scope: !1261)
!2370 = !DILocation(line: 321, column: 38, scope: !1261)
!2371 = !DILocation(line: 321, column: 45, scope: !1261)
!2372 = !DILocation(line: 322, column: 21, scope: !1261)
!2373 = !DILocation(line: 322, column: 25, scope: !1261)
!2374 = !DILocation(line: 322, column: 15, scope: !1261)
!2375 = !DILocation(line: 322, column: 34, scope: !1261)
!2376 = !DILocation(line: 322, column: 38, scope: !1261)
!2377 = !DILocation(line: 322, column: 45, scope: !1261)
!2378 = !DILocation(line: 323, column: 21, scope: !1261)
!2379 = !DILocation(line: 323, column: 25, scope: !1261)
!2380 = !DILocation(line: 323, column: 15, scope: !1261)
!2381 = !DILocation(line: 323, column: 34, scope: !1261)
!2382 = !DILocation(line: 323, column: 38, scope: !1261)
!2383 = !DILocation(line: 323, column: 45, scope: !1261)
!2384 = !DILocation(line: 324, column: 21, scope: !1261)
!2385 = !DILocation(line: 324, column: 25, scope: !1261)
!2386 = !DILocation(line: 324, column: 15, scope: !1261)
!2387 = !DILocation(line: 324, column: 34, scope: !1261)
!2388 = !DILocation(line: 324, column: 38, scope: !1261)
!2389 = !DILocation(line: 324, column: 45, scope: !1261)
!2390 = !DILocation(line: 325, column: 21, scope: !1261)
!2391 = !DILocation(line: 325, column: 25, scope: !1261)
!2392 = !DILocation(line: 325, column: 15, scope: !1261)
!2393 = !DILocation(line: 325, column: 34, scope: !1261)
!2394 = !DILocation(line: 325, column: 38, scope: !1261)
!2395 = !DILocation(line: 325, column: 45, scope: !1261)
!2396 = !DILocation(line: 328, column: 20, scope: !1261)
!2397 = !DILocation(line: 328, column: 26, scope: !1261)
!2398 = !DILocation(line: 329, column: 20, scope: !1261)
!2399 = !DILocation(line: 329, column: 26, scope: !1261)
!2400 = !DILocation(line: 330, column: 20, scope: !1261)
!2401 = !DILocation(line: 330, column: 26, scope: !1261)
!2402 = !DILocation(line: 331, column: 20, scope: !1261)
!2403 = !DILocation(line: 331, column: 26, scope: !1261)
!2404 = !DILocation(line: 332, column: 20, scope: !1261)
!2405 = !DILocation(line: 332, column: 26, scope: !1261)
!2406 = !DILocation(line: 333, column: 20, scope: !1261)
!2407 = !DILocation(line: 333, column: 26, scope: !1261)
!2408 = !DILocation(line: 334, column: 20, scope: !1261)
!2409 = !DILocation(line: 334, column: 26, scope: !1261)
!2410 = !DILocation(line: 337, column: 9, scope: !1261)
!2411 = !DILocation(line: 338, column: 9, scope: !1261)
!2412 = !DILocation(line: 339, column: 9, scope: !1261)
!2413 = !DILocation(line: 340, column: 9, scope: !1261)
!2414 = !DILocation(line: 341, column: 9, scope: !1261)
!2415 = !DILocation(line: 342, column: 9, scope: !1261)
!2416 = !DILocation(line: 343, column: 9, scope: !1261)
!2417 = !DILocation(line: 344, column: 9, scope: !1261)
!2418 = !DILocation(line: 347, column: 9, scope: !1261)
!2419 = !DILocation(line: 348, column: 9, scope: !1261)
!2420 = !DILocation(line: 349, column: 9, scope: !1261)
!2421 = !DILocation(line: 350, column: 9, scope: !1261)
!2422 = !DILocation(line: 351, column: 9, scope: !1261)
!2423 = !DILocation(line: 353, column: 9, scope: !1261)
!2424 = !DILocation(line: 357, column: 3, scope: !1261)
!2425 = distinct !DISubprogram(name: "__remill_intrinsics", scope: !2426, file: !2426, line: 35, type: !95, isLocal: false, isDefinition: true, scopeLine: 35, flags: DIFlagPrototyped, isOptimized: false, unit: !1, variables: !7)
!2426 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/Intrinsics.cpp", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!2427 = !DILocation(line: 116, column: 1, scope: !2425)
!2428 = !{!2429, !2429, i64 0}
!2429 = !{!"long", !2430, i64 0}
!2430 = !{!"omnipotent char", !2431, i64 0}
!2431 = !{!"Simple C++ TBAA"}
!2432 = !{!2433, !2430, i64 2065}
!2433 = !{!"_ZTS5State", !2430, i64 16, !2434, i64 2064, !2430, i64 2080, !2435, i64 2088, !2437, i64 2112, !2439, i64 2208, !2440, i64 2480, !2441, i64 2608, !2442, i64 2736, !2430, i64 2760, !2430, i64 2768, !2443, i64 3280}
!2434 = !{!"_ZTS10ArithFlags", !2430, i64 0, !2430, i64 1, !2430, i64 2, !2430, i64 3, !2430, i64 4, !2430, i64 5, !2430, i64 6, !2430, i64 7, !2430, i64 8, !2430, i64 9, !2430, i64 10, !2430, i64 11, !2430, i64 12, !2430, i64 13, !2430, i64 14, !2430, i64 15}
!2435 = !{!"_ZTS8Segments", !2436, i64 0, !2430, i64 2, !2436, i64 4, !2430, i64 6, !2436, i64 8, !2430, i64 10, !2436, i64 12, !2430, i64 14, !2436, i64 16, !2430, i64 18, !2436, i64 20, !2430, i64 22}
!2436 = !{!"short", !2430, i64 0}
!2437 = !{!"_ZTS12AddressSpace", !2429, i64 0, !2438, i64 8, !2429, i64 16, !2438, i64 24, !2429, i64 32, !2438, i64 40, !2429, i64 48, !2438, i64 56, !2429, i64 64, !2438, i64 72, !2429, i64 80, !2438, i64 88}
!2438 = !{!"_ZTS3Reg", !2430, i64 0}
!2439 = !{!"_ZTS3GPR", !2429, i64 0, !2438, i64 8, !2429, i64 16, !2438, i64 24, !2429, i64 32, !2438, i64 40, !2429, i64 48, !2438, i64 56, !2429, i64 64, !2438, i64 72, !2429, i64 80, !2438, i64 88, !2429, i64 96, !2438, i64 104, !2429, i64 112, !2438, i64 120, !2429, i64 128, !2438, i64 136, !2429, i64 144, !2438, i64 152, !2429, i64 160, !2438, i64 168, !2429, i64 176, !2438, i64 184, !2429, i64 192, !2438, i64 200, !2429, i64 208, !2438, i64 216, !2429, i64 224, !2438, i64 232, !2429, i64 240, !2438, i64 248, !2429, i64 256, !2438, i64 264}
!2440 = !{!"_ZTS8X87Stack", !2430, i64 0}
!2441 = !{!"_ZTS3MMX", !2430, i64 0}
!2442 = !{!"_ZTS14FPUStatusFlags", !2430, i64 0, !2430, i64 1, !2430, i64 2, !2430, i64 3, !2430, i64 4, !2430, i64 5, !2430, i64 6, !2430, i64 7, !2430, i64 8, !2430, i64 9, !2430, i64 10, !2430, i64 11, !2430, i64 12, !2430, i64 13, !2430, i64 14, !2430, i64 15, !2430, i64 16, !2430, i64 17, !2430, i64 18, !2430, i64 19, !2430, i64 20}
!2443 = !{!"_ZTS13SegmentCaches", !2444, i64 0, !2444, i64 16, !2444, i64 32, !2444, i64 48, !2444, i64 64, !2444, i64 80}
!2444 = !{!"_ZTS13SegmentShadow", !2430, i64 0, !2445, i64 8, !2445, i64 12}
!2445 = !{!"int", !2430, i64 0}
!2446 = !{!2433, !2430, i64 2067}
!2447 = !{!2433, !2430, i64 2069}
!2448 = !{!2433, !2430, i64 2071}
!2449 = !{!2433, !2430, i64 2073}
!2450 = !{!2433, !2430, i64 2077}
!2451 = !{!2452, !2452, i64 0}
!2452 = !{!"double", !2430, i64 0}
!2453 = !{!2430, !2430, i64 0}
!2454 = !{!2455}
!2455 = distinct !{!2455, !2456, !"ext_6050b8_cos: argument 0"}
!2456 = distinct !{!2456, !"ext_6050b8_cos"}
!2457 = !{!2458}
!2458 = distinct !{!2458, !2456, !"ext_6050b8_cos: argument 1"}
!2459 = !{!2460}
!2460 = distinct !{!2460, !2461, !"ext_6050d8_sin: argument 0"}
!2461 = distinct !{!2461, !"ext_6050d8_sin"}
!2462 = !{!2463}
!2463 = distinct !{!2463, !2461, !"ext_6050d8_sin: argument 1"}
!2464 = !{!2465}
!2465 = distinct !{!2465, !2466, !"ext_6050f8_atan: argument 0"}
!2466 = distinct !{!2466, !"ext_6050f8_atan"}
!2467 = !{!2468}
!2468 = distinct !{!2468, !2466, !"ext_6050f8_atan: argument 1"}
!2469 = !{!2445, !2445, i64 0}
!2470 = !{!2471}
!2471 = distinct !{!2471, !2472, !"ext_6050b8_cos: argument 0"}
!2472 = distinct !{!2472, !"ext_6050b8_cos"}
!2473 = !{!2474}
!2474 = distinct !{!2474, !2472, !"ext_6050b8_cos: argument 1"}
!2475 = !{!2476, !2476, i64 0}
!2476 = !{!"float", !2430, i64 0}
!2477 = !{!2478}
!2478 = distinct !{!2478, !2479, !"ext_605140_sqrt: argument 0"}
!2479 = distinct !{!2479, !"ext_605140_sqrt"}
!2480 = !{!2481}
!2481 = distinct !{!2481, !2479, !"ext_605140_sqrt: argument 1"}
