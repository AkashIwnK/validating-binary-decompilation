; ModuleID = '/tmp/tmp2fjoqz4b-target.ll'
source_filename = "llvm-link"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu-elf"

%union.anon = type { i64 }
%seg_4040a0__rodata_type = type <{ [24 x i8], [88 x i8], [45 x i8], [7 x i8] }>
%seg_604de0__init_array_type = type <{ i64, i64 }>
%seg_604ff0__got_type = type <{ i64, i64 }>
%__bss_start_type = type <{ [8 x i8] }>
%struct.State = type { %struct.ArchState, [32 x %union.VectorReg], %struct.ArithFlags, %union.anon, %struct.Segments, %struct.AddressSpace, %struct.GPR, %struct.X87Stack, %struct.MMX, %struct.FPUStatusFlags, %union.anon, %union.FPU, %struct.SegmentCaches }
%struct.ArchState = type { i32, i32, %union.anon }
%union.VectorReg = type { %union.vec512_t }
%union.vec512_t = type { %struct.uint64v8_t }
%struct.uint64v8_t = type { [8 x i64] }
%struct.ArithFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8 }
%struct.Segments = type { i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector }
%union.SegmentSelector = type { i16 }
%struct.AddressSpace = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.Reg = type { %union.anon }
%struct.GPR = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.X87Stack = type { [8 x %struct.anon.3] }
%struct.anon.3 = type { i64, double }
%struct.MMX = type { [8 x %struct.anon.4] }
%struct.anon.4 = type { i64, %union.vec64_t }
%union.vec64_t = type { %struct.uint64v1_t }
%struct.uint64v1_t = type { [1 x i64] }
%struct.FPUStatusFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, [4 x i8] }
%union.FPU = type { %struct.anon.13 }
%struct.anon.13 = type { %struct.FpuFXSAVE, [96 x i8] }
%struct.FpuFXSAVE = type { %union.SegmentSelector, %union.SegmentSelector, %union.FPUAbridgedTagWord, i8, i16, i32, %union.SegmentSelector, i16, i32, %union.SegmentSelector, i16, %union.FPUControlStatus, %union.FPUControlStatus, [8 x %struct.FPUStackElem], [16 x %union.vec128_t] }
%union.FPUAbridgedTagWord = type { i8 }
%union.FPUControlStatus = type { i32 }
%struct.FPUStackElem = type { %union.anon.11, [6 x i8] }
%union.anon.11 = type { %struct.float80_t }
%struct.float80_t = type { [10 x i8] }
%union.vec128_t = type { %struct.uint128v1_t }
%struct.uint128v1_t = type { [1 x i128] }
%struct.SegmentCaches = type { %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow }
%struct.SegmentShadow = type { %union.anon, i32, i32 }
%struct.Memory = type opaque
%struct.anon.2 = type { i8, i8 }
%"class.std::bitset" = type { %struct.uint64v4_t }
%struct.uint64v4_t = type { [4 x i64] }

@DR0 = external global i64, align 8
@DR1 = external global i64, align 8
@DR2 = external global i64, align 8
@DR3 = external global i64, align 8
@DR4 = external global i64, align 8
@DR5 = external global i64, align 8
@DR6 = external global i64, align 8
@DR7 = external global i64, align 8
@gCR0 = external global %union.anon, align 1
@gCR1 = external global %union.anon, align 1
@gCR2 = external global %union.anon, align 1
@gCR3 = external global %union.anon, align 1
@gCR4 = external global %union.anon, align 1
@gCR8 = external global %union.anon, align 1
@seg_4040a0__rodata = internal constant %seg_4040a0__rodata_type <{ [24 x i8] c"\01\00\02\00\00\00\00\00\BB\BD\D7\D9\DF|\DB=\00\00\00\00\00\00P?", [88 x i8] c"\00\00\00\00\00\00\90@\00\00\00\00\00\00\10@\00\00\00\00\00\00\E0C\95\D6&\E8\0B.\11>\8D\ED\B5\A0\F7\C6\B0>\00\00\00\00\00\00\F0?q\8B\89\C0\85.\D0>\00\00\00\00\00\00\00@\00\00\00\00\00\00\00\00\FF\FF\FF\FF\FF\FF\FF\7F\FF\FF\FF\FF\FF\FF\FF\7F", [45 x i8] c"FFT sanity check failed! Difference is: %le\0A\00", [7 x i8] c"%e %e\0A\00" }>
@seg_604de0__init_array = internal global %seg_604de0__init_array_type <{ i64 ptrtoint (void ()* @callback_sub_400840_frame_dummy to i64), i64 ptrtoint (void ()* @callback_sub_400810___do_global_dtors_aux to i64) }>
@seg_604ff0__got = internal global %seg_604ff0__got_type <{ i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64)* @__libc_start_main to i64), i64 ptrtoint (i64 ()* @__gmon_start__ to i64) }>
@__bss_start = global %__bss_start_type zeroinitializer
@0 = internal global i1 false
@1 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_400840_frame_dummy_wrapper
@2 = internal constant void ()* @__mcsema_attach_call
@3 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_400810___do_global_dtors_aux_wrapper
@4 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_404090___libc_csu_fini_wrapper
@5 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_404020___libc_csu_init_wrapper
@6 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @main_wrapper
@7 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @putdata_wrapper
@8 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @cdft_wrapper
@9 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @errorcheck_wrapper
@10 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @.term_proc_wrapper
@11 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @get_time_wrapper
@12 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @.init_proc_wrapper
@13 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @makewt_wrapper
@llvm.global_ctors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 101, void ()* @__mcsema_constructor, i8* null }]
@llvm.global_dtors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 101, void ()* @__mcsema_destructor, i8* null }]

declare %struct.Memory* @sub_400e30_get_time_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4024b0_cftbsub_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401c10_bitrv2conj_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400fe0_putdata_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400e70_makewt_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401100_errorcheck_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401870_cftfsub_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4011f0_bitrv2_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400688__init_proc_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_403330_cftmdl_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401060_cdft_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4028a0_cft1st_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4007a0_deregister_tm_clones_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

; Function Attrs: nounwind readnone
declare i32 @llvm.ctpop.i32(i32) #0

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_error(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #1

; Function Attrs: nounwind readnone
declare double @llvm.fabs.f64(double) #0

; Function Attrs: nounwind readnone
declare double @llvm.trunc.f64(double) #0

; Function Attrs: nounwind readnone
declare double @sqrt(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @cos(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @sin(double) local_unnamed_addr #2

; Function Attrs: nounwind readnone
declare double @atan(double) local_unnamed_addr #2

; Function Attrs: noinline nounwind optnone
define %struct.Memory* @__remill_basic_block(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #3 !dbg !1261 {
  %state = alloca %struct.State*, align 8
  %curr_pc = alloca i64, align 8
  %memory = alloca %struct.Memory*, align 8
  %BRANCH_TAKEN = alloca i8, align 1
  %SS_BASE = alloca i64, align 8
  %ES_BASE = alloca i64, align 8
  %DS_BASE = alloca i64, align 8
  %CS_BASE = alloca i64, align 8
  %STATE = alloca %struct.State*, align 8
  %MEMORY = alloca %struct.Memory*, align 8
  %_DR0 = alloca i64*, align 8
  %_DR1 = alloca i64*, align 8
  %_DR2 = alloca i64*, align 8
  %_DR3 = alloca i64*, align 8
  %_DR4 = alloca i64*, align 8
  %_DR5 = alloca i64*, align 8
  %_DR6 = alloca i64*, align 8
  %_DR7 = alloca i64*, align 8
  %CR0 = alloca i64*, align 8
  %CR1 = alloca i64*, align 8
  %CR2 = alloca i64*, align 8
  %CR3 = alloca i64*, align 8
  %CR4 = alloca i64*, align 8
  %CR8 = alloca i64*, align 8
  store %struct.State* %0, %struct.State** %state, align 8
  store i64 %1, i64* %curr_pc, align 8
  store %struct.Memory* %2, %struct.Memory** %memory, align 8
  store i8 0, i8* %BRANCH_TAKEN, align 1, !dbg !1952
  store i64 0, i64* %SS_BASE, align 8, !dbg !1953
  store i64 0, i64* %ES_BASE, align 8, !dbg !1954
  store i64 0, i64* %DS_BASE, align 8, !dbg !1955
  store i64 0, i64* %CS_BASE, align 8, !dbg !1956
  store %struct.State* %0, %struct.State** %STATE, align 8, !dbg !1957
  store %struct.Memory* %2, %struct.Memory** %MEMORY, align 8, !dbg !1958
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1959
  %5 = getelementptr inbounds %struct.GPR, %struct.GPR* %4, i32 0, i32 33, !dbg !1960
  %6 = getelementptr inbounds %struct.Reg, %struct.Reg* %5, i32 0, i32 0, !dbg !1961
  %PC = bitcast %union.anon* %6 to i64*, !dbg !1961
  store i64 %1, i64* %PC, align 8, !dbg !1962
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1963
  %8 = getelementptr inbounds %struct.GPR, %struct.GPR* %7, i32 0, i32 1, !dbg !1964
  %9 = getelementptr inbounds %struct.Reg, %struct.Reg* %8, i32 0, i32 0, !dbg !1965
  %10 = bitcast %union.anon* %9 to %struct.anon.2*, !dbg !1965
  %AH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %10, i32 0, i32 1, !dbg !1966
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1967
  %12 = getelementptr inbounds %struct.GPR, %struct.GPR* %11, i32 0, i32 3, !dbg !1968
  %13 = getelementptr inbounds %struct.Reg, %struct.Reg* %12, i32 0, i32 0, !dbg !1969
  %14 = bitcast %union.anon* %13 to %struct.anon.2*, !dbg !1969
  %BH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %14, i32 0, i32 1, !dbg !1970
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1971
  %16 = getelementptr inbounds %struct.GPR, %struct.GPR* %15, i32 0, i32 5, !dbg !1972
  %17 = getelementptr inbounds %struct.Reg, %struct.Reg* %16, i32 0, i32 0, !dbg !1973
  %18 = bitcast %union.anon* %17 to %struct.anon.2*, !dbg !1973
  %CH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %18, i32 0, i32 1, !dbg !1974
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1975
  %20 = getelementptr inbounds %struct.GPR, %struct.GPR* %19, i32 0, i32 7, !dbg !1976
  %21 = getelementptr inbounds %struct.Reg, %struct.Reg* %20, i32 0, i32 0, !dbg !1977
  %22 = bitcast %union.anon* %21 to %struct.anon.2*, !dbg !1977
  %DH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %22, i32 0, i32 1, !dbg !1978
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1979
  %24 = getelementptr inbounds %struct.GPR, %struct.GPR* %23, i32 0, i32 1, !dbg !1980
  %25 = getelementptr inbounds %struct.Reg, %struct.Reg* %24, i32 0, i32 0, !dbg !1981
  %26 = bitcast %union.anon* %25 to %struct.anon.2*, !dbg !1981
  %AL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %26, i32 0, i32 0, !dbg !1982
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1983
  %28 = getelementptr inbounds %struct.GPR, %struct.GPR* %27, i32 0, i32 3, !dbg !1984
  %29 = getelementptr inbounds %struct.Reg, %struct.Reg* %28, i32 0, i32 0, !dbg !1985
  %30 = bitcast %union.anon* %29 to %struct.anon.2*, !dbg !1985
  %BL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %30, i32 0, i32 0, !dbg !1986
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1987
  %32 = getelementptr inbounds %struct.GPR, %struct.GPR* %31, i32 0, i32 5, !dbg !1988
  %33 = getelementptr inbounds %struct.Reg, %struct.Reg* %32, i32 0, i32 0, !dbg !1989
  %34 = bitcast %union.anon* %33 to %struct.anon.2*, !dbg !1989
  %CL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %34, i32 0, i32 0, !dbg !1990
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1991
  %36 = getelementptr inbounds %struct.GPR, %struct.GPR* %35, i32 0, i32 7, !dbg !1992
  %37 = getelementptr inbounds %struct.Reg, %struct.Reg* %36, i32 0, i32 0, !dbg !1993
  %38 = bitcast %union.anon* %37 to %struct.anon.2*, !dbg !1993
  %DL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %38, i32 0, i32 0, !dbg !1994
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1995
  %40 = getelementptr inbounds %struct.GPR, %struct.GPR* %39, i32 0, i32 9, !dbg !1996
  %41 = getelementptr inbounds %struct.Reg, %struct.Reg* %40, i32 0, i32 0, !dbg !1997
  %42 = bitcast %union.anon* %41 to %struct.anon.2*, !dbg !1997
  %SIL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %42, i32 0, i32 0, !dbg !1998
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1999
  %44 = getelementptr inbounds %struct.GPR, %struct.GPR* %43, i32 0, i32 11, !dbg !2000
  %45 = getelementptr inbounds %struct.Reg, %struct.Reg* %44, i32 0, i32 0, !dbg !2001
  %46 = bitcast %union.anon* %45 to %struct.anon.2*, !dbg !2001
  %DIL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %46, i32 0, i32 0, !dbg !2002
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2003
  %48 = getelementptr inbounds %struct.GPR, %struct.GPR* %47, i32 0, i32 13, !dbg !2004
  %49 = getelementptr inbounds %struct.Reg, %struct.Reg* %48, i32 0, i32 0, !dbg !2005
  %50 = bitcast %union.anon* %49 to %struct.anon.2*, !dbg !2005
  %SPL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %50, i32 0, i32 0, !dbg !2006
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2007
  %52 = getelementptr inbounds %struct.GPR, %struct.GPR* %51, i32 0, i32 15, !dbg !2008
  %53 = getelementptr inbounds %struct.Reg, %struct.Reg* %52, i32 0, i32 0, !dbg !2009
  %54 = bitcast %union.anon* %53 to %struct.anon.2*, !dbg !2009
  %BPL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %54, i32 0, i32 0, !dbg !2010
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2011
  %56 = getelementptr inbounds %struct.GPR, %struct.GPR* %55, i32 0, i32 17, !dbg !2012
  %57 = getelementptr inbounds %struct.Reg, %struct.Reg* %56, i32 0, i32 0, !dbg !2013
  %58 = bitcast %union.anon* %57 to %struct.anon.2*, !dbg !2013
  %R8B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %58, i32 0, i32 0, !dbg !2014
  %59 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2015
  %60 = getelementptr inbounds %struct.GPR, %struct.GPR* %59, i32 0, i32 19, !dbg !2016
  %61 = getelementptr inbounds %struct.Reg, %struct.Reg* %60, i32 0, i32 0, !dbg !2017
  %62 = bitcast %union.anon* %61 to %struct.anon.2*, !dbg !2017
  %R9B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %62, i32 0, i32 0, !dbg !2018
  %63 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2019
  %64 = getelementptr inbounds %struct.GPR, %struct.GPR* %63, i32 0, i32 21, !dbg !2020
  %65 = getelementptr inbounds %struct.Reg, %struct.Reg* %64, i32 0, i32 0, !dbg !2021
  %66 = bitcast %union.anon* %65 to %struct.anon.2*, !dbg !2021
  %R10B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %66, i32 0, i32 0, !dbg !2022
  %67 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2023
  %68 = getelementptr inbounds %struct.GPR, %struct.GPR* %67, i32 0, i32 23, !dbg !2024
  %69 = getelementptr inbounds %struct.Reg, %struct.Reg* %68, i32 0, i32 0, !dbg !2025
  %70 = bitcast %union.anon* %69 to %struct.anon.2*, !dbg !2025
  %R11B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %70, i32 0, i32 0, !dbg !2026
  %71 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2027
  %72 = getelementptr inbounds %struct.GPR, %struct.GPR* %71, i32 0, i32 25, !dbg !2028
  %73 = getelementptr inbounds %struct.Reg, %struct.Reg* %72, i32 0, i32 0, !dbg !2029
  %74 = bitcast %union.anon* %73 to %struct.anon.2*, !dbg !2029
  %R12B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %74, i32 0, i32 0, !dbg !2030
  %75 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2031
  %76 = getelementptr inbounds %struct.GPR, %struct.GPR* %75, i32 0, i32 27, !dbg !2032
  %77 = getelementptr inbounds %struct.Reg, %struct.Reg* %76, i32 0, i32 0, !dbg !2033
  %78 = bitcast %union.anon* %77 to %struct.anon.2*, !dbg !2033
  %R13B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %78, i32 0, i32 0, !dbg !2034
  %79 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2035
  %80 = getelementptr inbounds %struct.GPR, %struct.GPR* %79, i32 0, i32 29, !dbg !2036
  %81 = getelementptr inbounds %struct.Reg, %struct.Reg* %80, i32 0, i32 0, !dbg !2037
  %82 = bitcast %union.anon* %81 to %struct.anon.2*, !dbg !2037
  %R14B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %82, i32 0, i32 0, !dbg !2038
  %83 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2039
  %84 = getelementptr inbounds %struct.GPR, %struct.GPR* %83, i32 0, i32 31, !dbg !2040
  %85 = getelementptr inbounds %struct.Reg, %struct.Reg* %84, i32 0, i32 0, !dbg !2041
  %86 = bitcast %union.anon* %85 to %struct.anon.2*, !dbg !2041
  %R15B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %86, i32 0, i32 0, !dbg !2042
  %87 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2043
  %88 = getelementptr inbounds %struct.GPR, %struct.GPR* %87, i32 0, i32 1, !dbg !2044
  %89 = getelementptr inbounds %struct.Reg, %struct.Reg* %88, i32 0, i32 0, !dbg !2045
  %AX = bitcast %union.anon* %89 to i16*, !dbg !2045
  %90 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2046
  %91 = getelementptr inbounds %struct.GPR, %struct.GPR* %90, i32 0, i32 3, !dbg !2047
  %92 = getelementptr inbounds %struct.Reg, %struct.Reg* %91, i32 0, i32 0, !dbg !2048
  %BX = bitcast %union.anon* %92 to i16*, !dbg !2048
  %93 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2049
  %94 = getelementptr inbounds %struct.GPR, %struct.GPR* %93, i32 0, i32 5, !dbg !2050
  %95 = getelementptr inbounds %struct.Reg, %struct.Reg* %94, i32 0, i32 0, !dbg !2051
  %CX = bitcast %union.anon* %95 to i16*, !dbg !2051
  %96 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2052
  %97 = getelementptr inbounds %struct.GPR, %struct.GPR* %96, i32 0, i32 7, !dbg !2053
  %98 = getelementptr inbounds %struct.Reg, %struct.Reg* %97, i32 0, i32 0, !dbg !2054
  %DX = bitcast %union.anon* %98 to i16*, !dbg !2054
  %99 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2055
  %100 = getelementptr inbounds %struct.GPR, %struct.GPR* %99, i32 0, i32 9, !dbg !2056
  %101 = getelementptr inbounds %struct.Reg, %struct.Reg* %100, i32 0, i32 0, !dbg !2057
  %SI = bitcast %union.anon* %101 to i16*, !dbg !2057
  %102 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2058
  %103 = getelementptr inbounds %struct.GPR, %struct.GPR* %102, i32 0, i32 11, !dbg !2059
  %104 = getelementptr inbounds %struct.Reg, %struct.Reg* %103, i32 0, i32 0, !dbg !2060
  %DI = bitcast %union.anon* %104 to i16*, !dbg !2060
  %105 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2061
  %106 = getelementptr inbounds %struct.GPR, %struct.GPR* %105, i32 0, i32 13, !dbg !2062
  %107 = getelementptr inbounds %struct.Reg, %struct.Reg* %106, i32 0, i32 0, !dbg !2063
  %SP = bitcast %union.anon* %107 to i16*, !dbg !2063
  %108 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2064
  %109 = getelementptr inbounds %struct.GPR, %struct.GPR* %108, i32 0, i32 15, !dbg !2065
  %110 = getelementptr inbounds %struct.Reg, %struct.Reg* %109, i32 0, i32 0, !dbg !2066
  %BP = bitcast %union.anon* %110 to i16*, !dbg !2066
  %111 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2067
  %112 = getelementptr inbounds %struct.GPR, %struct.GPR* %111, i32 0, i32 17, !dbg !2068
  %113 = getelementptr inbounds %struct.Reg, %struct.Reg* %112, i32 0, i32 0, !dbg !2069
  %R8W = bitcast %union.anon* %113 to i16*, !dbg !2069
  %114 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2070
  %115 = getelementptr inbounds %struct.GPR, %struct.GPR* %114, i32 0, i32 19, !dbg !2071
  %116 = getelementptr inbounds %struct.Reg, %struct.Reg* %115, i32 0, i32 0, !dbg !2072
  %R9W = bitcast %union.anon* %116 to i16*, !dbg !2072
  %117 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2073
  %118 = getelementptr inbounds %struct.GPR, %struct.GPR* %117, i32 0, i32 21, !dbg !2074
  %119 = getelementptr inbounds %struct.Reg, %struct.Reg* %118, i32 0, i32 0, !dbg !2075
  %R10W = bitcast %union.anon* %119 to i16*, !dbg !2075
  %120 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2076
  %121 = getelementptr inbounds %struct.GPR, %struct.GPR* %120, i32 0, i32 23, !dbg !2077
  %122 = getelementptr inbounds %struct.Reg, %struct.Reg* %121, i32 0, i32 0, !dbg !2078
  %R11W = bitcast %union.anon* %122 to i16*, !dbg !2078
  %123 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2079
  %124 = getelementptr inbounds %struct.GPR, %struct.GPR* %123, i32 0, i32 25, !dbg !2080
  %125 = getelementptr inbounds %struct.Reg, %struct.Reg* %124, i32 0, i32 0, !dbg !2081
  %R12W = bitcast %union.anon* %125 to i16*, !dbg !2081
  %126 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2082
  %127 = getelementptr inbounds %struct.GPR, %struct.GPR* %126, i32 0, i32 27, !dbg !2083
  %128 = getelementptr inbounds %struct.Reg, %struct.Reg* %127, i32 0, i32 0, !dbg !2084
  %R13W = bitcast %union.anon* %128 to i16*, !dbg !2084
  %129 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2085
  %130 = getelementptr inbounds %struct.GPR, %struct.GPR* %129, i32 0, i32 29, !dbg !2086
  %131 = getelementptr inbounds %struct.Reg, %struct.Reg* %130, i32 0, i32 0, !dbg !2087
  %R14W = bitcast %union.anon* %131 to i16*, !dbg !2087
  %132 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2088
  %133 = getelementptr inbounds %struct.GPR, %struct.GPR* %132, i32 0, i32 31, !dbg !2089
  %134 = getelementptr inbounds %struct.Reg, %struct.Reg* %133, i32 0, i32 0, !dbg !2090
  %R15W = bitcast %union.anon* %134 to i16*, !dbg !2090
  %135 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2091
  %136 = getelementptr inbounds %struct.GPR, %struct.GPR* %135, i32 0, i32 33, !dbg !2092
  %137 = getelementptr inbounds %struct.Reg, %struct.Reg* %136, i32 0, i32 0, !dbg !2093
  %IP = bitcast %union.anon* %137 to i16*, !dbg !2093
  %138 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2094
  %139 = getelementptr inbounds %struct.GPR, %struct.GPR* %138, i32 0, i32 1, !dbg !2095
  %140 = getelementptr inbounds %struct.Reg, %struct.Reg* %139, i32 0, i32 0, !dbg !2096
  %EAX = bitcast %union.anon* %140 to i32*, !dbg !2096
  %141 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2097
  %142 = getelementptr inbounds %struct.GPR, %struct.GPR* %141, i32 0, i32 3, !dbg !2098
  %143 = getelementptr inbounds %struct.Reg, %struct.Reg* %142, i32 0, i32 0, !dbg !2099
  %EBX = bitcast %union.anon* %143 to i32*, !dbg !2099
  %144 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2100
  %145 = getelementptr inbounds %struct.GPR, %struct.GPR* %144, i32 0, i32 5, !dbg !2101
  %146 = getelementptr inbounds %struct.Reg, %struct.Reg* %145, i32 0, i32 0, !dbg !2102
  %ECX = bitcast %union.anon* %146 to i32*, !dbg !2102
  %147 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2103
  %148 = getelementptr inbounds %struct.GPR, %struct.GPR* %147, i32 0, i32 7, !dbg !2104
  %149 = getelementptr inbounds %struct.Reg, %struct.Reg* %148, i32 0, i32 0, !dbg !2105
  %EDX = bitcast %union.anon* %149 to i32*, !dbg !2105
  %150 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2106
  %151 = getelementptr inbounds %struct.GPR, %struct.GPR* %150, i32 0, i32 9, !dbg !2107
  %152 = getelementptr inbounds %struct.Reg, %struct.Reg* %151, i32 0, i32 0, !dbg !2108
  %ESI = bitcast %union.anon* %152 to i32*, !dbg !2108
  %153 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2109
  %154 = getelementptr inbounds %struct.GPR, %struct.GPR* %153, i32 0, i32 11, !dbg !2110
  %155 = getelementptr inbounds %struct.Reg, %struct.Reg* %154, i32 0, i32 0, !dbg !2111
  %EDI = bitcast %union.anon* %155 to i32*, !dbg !2111
  %156 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2112
  %157 = getelementptr inbounds %struct.GPR, %struct.GPR* %156, i32 0, i32 13, !dbg !2113
  %158 = getelementptr inbounds %struct.Reg, %struct.Reg* %157, i32 0, i32 0, !dbg !2114
  %ESP = bitcast %union.anon* %158 to i32*, !dbg !2114
  %159 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2115
  %160 = getelementptr inbounds %struct.GPR, %struct.GPR* %159, i32 0, i32 15, !dbg !2116
  %161 = getelementptr inbounds %struct.Reg, %struct.Reg* %160, i32 0, i32 0, !dbg !2117
  %EBP = bitcast %union.anon* %161 to i32*, !dbg !2117
  %162 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2118
  %163 = getelementptr inbounds %struct.GPR, %struct.GPR* %162, i32 0, i32 33, !dbg !2119
  %164 = getelementptr inbounds %struct.Reg, %struct.Reg* %163, i32 0, i32 0, !dbg !2120
  %EIP = bitcast %union.anon* %164 to i32*, !dbg !2120
  %165 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2121
  %166 = getelementptr inbounds %struct.GPR, %struct.GPR* %165, i32 0, i32 17, !dbg !2122
  %167 = getelementptr inbounds %struct.Reg, %struct.Reg* %166, i32 0, i32 0, !dbg !2123
  %R8D = bitcast %union.anon* %167 to i32*, !dbg !2123
  %168 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2124
  %169 = getelementptr inbounds %struct.GPR, %struct.GPR* %168, i32 0, i32 19, !dbg !2125
  %170 = getelementptr inbounds %struct.Reg, %struct.Reg* %169, i32 0, i32 0, !dbg !2126
  %R9D = bitcast %union.anon* %170 to i32*, !dbg !2126
  %171 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2127
  %172 = getelementptr inbounds %struct.GPR, %struct.GPR* %171, i32 0, i32 21, !dbg !2128
  %173 = getelementptr inbounds %struct.Reg, %struct.Reg* %172, i32 0, i32 0, !dbg !2129
  %R10D = bitcast %union.anon* %173 to i32*, !dbg !2129
  %174 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2130
  %175 = getelementptr inbounds %struct.GPR, %struct.GPR* %174, i32 0, i32 23, !dbg !2131
  %176 = getelementptr inbounds %struct.Reg, %struct.Reg* %175, i32 0, i32 0, !dbg !2132
  %R11D = bitcast %union.anon* %176 to i32*, !dbg !2132
  %177 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2133
  %178 = getelementptr inbounds %struct.GPR, %struct.GPR* %177, i32 0, i32 25, !dbg !2134
  %179 = getelementptr inbounds %struct.Reg, %struct.Reg* %178, i32 0, i32 0, !dbg !2135
  %R12D = bitcast %union.anon* %179 to i32*, !dbg !2135
  %180 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2136
  %181 = getelementptr inbounds %struct.GPR, %struct.GPR* %180, i32 0, i32 27, !dbg !2137
  %182 = getelementptr inbounds %struct.Reg, %struct.Reg* %181, i32 0, i32 0, !dbg !2138
  %R13D = bitcast %union.anon* %182 to i32*, !dbg !2138
  %183 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2139
  %184 = getelementptr inbounds %struct.GPR, %struct.GPR* %183, i32 0, i32 29, !dbg !2140
  %185 = getelementptr inbounds %struct.Reg, %struct.Reg* %184, i32 0, i32 0, !dbg !2141
  %R14D = bitcast %union.anon* %185 to i32*, !dbg !2141
  %186 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2142
  %187 = getelementptr inbounds %struct.GPR, %struct.GPR* %186, i32 0, i32 31, !dbg !2143
  %188 = getelementptr inbounds %struct.Reg, %struct.Reg* %187, i32 0, i32 0, !dbg !2144
  %R15D = bitcast %union.anon* %188 to i32*, !dbg !2144
  %189 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2145
  %190 = getelementptr inbounds %struct.GPR, %struct.GPR* %189, i32 0, i32 1, !dbg !2146
  %191 = getelementptr inbounds %struct.Reg, %struct.Reg* %190, i32 0, i32 0, !dbg !2147
  %RAX = bitcast %union.anon* %191 to i64*, !dbg !2147
  %192 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2148
  %193 = getelementptr inbounds %struct.GPR, %struct.GPR* %192, i32 0, i32 3, !dbg !2149
  %194 = getelementptr inbounds %struct.Reg, %struct.Reg* %193, i32 0, i32 0, !dbg !2150
  %RBX = bitcast %union.anon* %194 to i64*, !dbg !2150
  %195 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2151
  %196 = getelementptr inbounds %struct.GPR, %struct.GPR* %195, i32 0, i32 5, !dbg !2152
  %197 = getelementptr inbounds %struct.Reg, %struct.Reg* %196, i32 0, i32 0, !dbg !2153
  %RCX = bitcast %union.anon* %197 to i64*, !dbg !2153
  %198 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2154
  %199 = getelementptr inbounds %struct.GPR, %struct.GPR* %198, i32 0, i32 7, !dbg !2155
  %200 = getelementptr inbounds %struct.Reg, %struct.Reg* %199, i32 0, i32 0, !dbg !2156
  %RDX = bitcast %union.anon* %200 to i64*, !dbg !2156
  %201 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2157
  %202 = getelementptr inbounds %struct.GPR, %struct.GPR* %201, i32 0, i32 9, !dbg !2158
  %203 = getelementptr inbounds %struct.Reg, %struct.Reg* %202, i32 0, i32 0, !dbg !2159
  %RSI = bitcast %union.anon* %203 to i64*, !dbg !2159
  %204 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2160
  %205 = getelementptr inbounds %struct.GPR, %struct.GPR* %204, i32 0, i32 11, !dbg !2161
  %206 = getelementptr inbounds %struct.Reg, %struct.Reg* %205, i32 0, i32 0, !dbg !2162
  %RDI = bitcast %union.anon* %206 to i64*, !dbg !2162
  %207 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2163
  %208 = getelementptr inbounds %struct.GPR, %struct.GPR* %207, i32 0, i32 13, !dbg !2164
  %209 = getelementptr inbounds %struct.Reg, %struct.Reg* %208, i32 0, i32 0, !dbg !2165
  %RSP = bitcast %union.anon* %209 to i64*, !dbg !2165
  %210 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2166
  %211 = getelementptr inbounds %struct.GPR, %struct.GPR* %210, i32 0, i32 15, !dbg !2167
  %212 = getelementptr inbounds %struct.Reg, %struct.Reg* %211, i32 0, i32 0, !dbg !2168
  %RBP = bitcast %union.anon* %212 to i64*, !dbg !2168
  %213 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2169
  %214 = getelementptr inbounds %struct.GPR, %struct.GPR* %213, i32 0, i32 17, !dbg !2170
  %215 = getelementptr inbounds %struct.Reg, %struct.Reg* %214, i32 0, i32 0, !dbg !2171
  %R8 = bitcast %union.anon* %215 to i64*, !dbg !2171
  %216 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2172
  %217 = getelementptr inbounds %struct.GPR, %struct.GPR* %216, i32 0, i32 19, !dbg !2173
  %218 = getelementptr inbounds %struct.Reg, %struct.Reg* %217, i32 0, i32 0, !dbg !2174
  %R9 = bitcast %union.anon* %218 to i64*, !dbg !2174
  %219 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2175
  %220 = getelementptr inbounds %struct.GPR, %struct.GPR* %219, i32 0, i32 21, !dbg !2176
  %221 = getelementptr inbounds %struct.Reg, %struct.Reg* %220, i32 0, i32 0, !dbg !2177
  %R10 = bitcast %union.anon* %221 to i64*, !dbg !2177
  %222 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2178
  %223 = getelementptr inbounds %struct.GPR, %struct.GPR* %222, i32 0, i32 23, !dbg !2179
  %224 = getelementptr inbounds %struct.Reg, %struct.Reg* %223, i32 0, i32 0, !dbg !2180
  %R11 = bitcast %union.anon* %224 to i64*, !dbg !2180
  %225 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2181
  %226 = getelementptr inbounds %struct.GPR, %struct.GPR* %225, i32 0, i32 25, !dbg !2182
  %227 = getelementptr inbounds %struct.Reg, %struct.Reg* %226, i32 0, i32 0, !dbg !2183
  %R12 = bitcast %union.anon* %227 to i64*, !dbg !2183
  %228 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2184
  %229 = getelementptr inbounds %struct.GPR, %struct.GPR* %228, i32 0, i32 27, !dbg !2185
  %230 = getelementptr inbounds %struct.Reg, %struct.Reg* %229, i32 0, i32 0, !dbg !2186
  %R13 = bitcast %union.anon* %230 to i64*, !dbg !2186
  %231 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2187
  %232 = getelementptr inbounds %struct.GPR, %struct.GPR* %231, i32 0, i32 29, !dbg !2188
  %233 = getelementptr inbounds %struct.Reg, %struct.Reg* %232, i32 0, i32 0, !dbg !2189
  %R14 = bitcast %union.anon* %233 to i64*, !dbg !2189
  %234 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2190
  %235 = getelementptr inbounds %struct.GPR, %struct.GPR* %234, i32 0, i32 31, !dbg !2191
  %236 = getelementptr inbounds %struct.Reg, %struct.Reg* %235, i32 0, i32 0, !dbg !2192
  %R15 = bitcast %union.anon* %236 to i64*, !dbg !2192
  %237 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2193
  %238 = getelementptr inbounds %struct.GPR, %struct.GPR* %237, i32 0, i32 33, !dbg !2194
  %239 = getelementptr inbounds %struct.Reg, %struct.Reg* %238, i32 0, i32 0, !dbg !2195
  %RIP = bitcast %union.anon* %239 to i64*, !dbg !2195
  %240 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2196
  %241 = getelementptr inbounds %struct.Segments, %struct.Segments* %240, i32 0, i32 1, !dbg !2197
  %SS = bitcast %union.SegmentSelector* %241 to i16*, !dbg !2198
  %242 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2199
  %243 = getelementptr inbounds %struct.Segments, %struct.Segments* %242, i32 0, i32 3, !dbg !2200
  %ES = bitcast %union.SegmentSelector* %243 to i16*, !dbg !2201
  %244 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2202
  %245 = getelementptr inbounds %struct.Segments, %struct.Segments* %244, i32 0, i32 5, !dbg !2203
  %GS = bitcast %union.SegmentSelector* %245 to i16*, !dbg !2204
  %246 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2205
  %247 = getelementptr inbounds %struct.Segments, %struct.Segments* %246, i32 0, i32 7, !dbg !2206
  %FS = bitcast %union.SegmentSelector* %247 to i16*, !dbg !2207
  %248 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2208
  %249 = getelementptr inbounds %struct.Segments, %struct.Segments* %248, i32 0, i32 9, !dbg !2209
  %DS = bitcast %union.SegmentSelector* %249 to i16*, !dbg !2210
  %250 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2211
  %251 = getelementptr inbounds %struct.Segments, %struct.Segments* %250, i32 0, i32 11, !dbg !2212
  %CS = bitcast %union.SegmentSelector* %251 to i16*, !dbg !2213
  %252 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 5, !dbg !2214
  %253 = getelementptr inbounds %struct.AddressSpace, %struct.AddressSpace* %252, i32 0, i32 5, !dbg !2215
  %254 = getelementptr inbounds %struct.Reg, %struct.Reg* %253, i32 0, i32 0, !dbg !2216
  %GS_BASE = bitcast %union.anon* %254 to i64*, !dbg !2216
  %255 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 5, !dbg !2217
  %256 = getelementptr inbounds %struct.AddressSpace, %struct.AddressSpace* %255, i32 0, i32 7, !dbg !2218
  %257 = getelementptr inbounds %struct.Reg, %struct.Reg* %256, i32 0, i32 0, !dbg !2219
  %FS_BASE = bitcast %union.anon* %257 to i64*, !dbg !2219
  %258 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2220
  %259 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %258, i64 0, i64 0, !dbg !2221
  %YMM0 = bitcast %union.VectorReg* %259 to %"class.std::bitset"*, !dbg !2222
  %260 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2223
  %261 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %260, i64 0, i64 1, !dbg !2224
  %YMM1 = bitcast %union.VectorReg* %261 to %"class.std::bitset"*, !dbg !2225
  %262 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2226
  %263 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %262, i64 0, i64 2, !dbg !2227
  %YMM2 = bitcast %union.VectorReg* %263 to %"class.std::bitset"*, !dbg !2228
  %264 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2229
  %265 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %264, i64 0, i64 3, !dbg !2230
  %YMM3 = bitcast %union.VectorReg* %265 to %"class.std::bitset"*, !dbg !2231
  %266 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2232
  %267 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %266, i64 0, i64 4, !dbg !2233
  %YMM4 = bitcast %union.VectorReg* %267 to %"class.std::bitset"*, !dbg !2234
  %268 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2235
  %269 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %268, i64 0, i64 5, !dbg !2236
  %YMM5 = bitcast %union.VectorReg* %269 to %"class.std::bitset"*, !dbg !2237
  %270 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2238
  %271 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %270, i64 0, i64 6, !dbg !2239
  %YMM6 = bitcast %union.VectorReg* %271 to %"class.std::bitset"*, !dbg !2240
  %272 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2241
  %273 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %272, i64 0, i64 7, !dbg !2242
  %YMM7 = bitcast %union.VectorReg* %273 to %"class.std::bitset"*, !dbg !2243
  %274 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2244
  %275 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %274, i64 0, i64 8, !dbg !2245
  %YMM8 = bitcast %union.VectorReg* %275 to %"class.std::bitset"*, !dbg !2246
  %276 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2247
  %277 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %276, i64 0, i64 9, !dbg !2248
  %YMM9 = bitcast %union.VectorReg* %277 to %"class.std::bitset"*, !dbg !2249
  %278 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2250
  %279 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %278, i64 0, i64 10, !dbg !2251
  %YMM10 = bitcast %union.VectorReg* %279 to %"class.std::bitset"*, !dbg !2252
  %280 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2253
  %281 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %280, i64 0, i64 11, !dbg !2254
  %YMM11 = bitcast %union.VectorReg* %281 to %"class.std::bitset"*, !dbg !2255
  %282 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2256
  %283 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %282, i64 0, i64 12, !dbg !2257
  %YMM12 = bitcast %union.VectorReg* %283 to %"class.std::bitset"*, !dbg !2258
  %284 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2259
  %285 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %284, i64 0, i64 13, !dbg !2260
  %YMM13 = bitcast %union.VectorReg* %285 to %"class.std::bitset"*, !dbg !2261
  %286 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2262
  %287 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %286, i64 0, i64 14, !dbg !2263
  %YMM14 = bitcast %union.VectorReg* %287 to %"class.std::bitset"*, !dbg !2264
  %288 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2265
  %289 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %288, i64 0, i64 15, !dbg !2266
  %YMM15 = bitcast %union.VectorReg* %289 to %"class.std::bitset"*, !dbg !2267
  %290 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2268
  %291 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %290, i64 0, i64 0, !dbg !2269
  %XMM0 = bitcast %union.VectorReg* %291 to %union.vec128_t*, !dbg !2270
  %292 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2271
  %293 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %292, i64 0, i64 1, !dbg !2272
  %XMM1 = bitcast %union.VectorReg* %293 to %union.vec128_t*, !dbg !2273
  %294 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2274
  %295 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %294, i64 0, i64 2, !dbg !2275
  %XMM2 = bitcast %union.VectorReg* %295 to %union.vec128_t*, !dbg !2276
  %296 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2277
  %297 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %296, i64 0, i64 3, !dbg !2278
  %XMM3 = bitcast %union.VectorReg* %297 to %union.vec128_t*, !dbg !2279
  %298 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2280
  %299 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %298, i64 0, i64 4, !dbg !2281
  %XMM4 = bitcast %union.VectorReg* %299 to %union.vec128_t*, !dbg !2282
  %300 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2283
  %301 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %300, i64 0, i64 5, !dbg !2284
  %XMM5 = bitcast %union.VectorReg* %301 to %union.vec128_t*, !dbg !2285
  %302 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2286
  %303 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %302, i64 0, i64 6, !dbg !2287
  %XMM6 = bitcast %union.VectorReg* %303 to %union.vec128_t*, !dbg !2288
  %304 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2289
  %305 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %304, i64 0, i64 7, !dbg !2290
  %XMM7 = bitcast %union.VectorReg* %305 to %union.vec128_t*, !dbg !2291
  %306 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2292
  %307 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %306, i64 0, i64 8, !dbg !2293
  %XMM8 = bitcast %union.VectorReg* %307 to %union.vec128_t*, !dbg !2294
  %308 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2295
  %309 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %308, i64 0, i64 9, !dbg !2296
  %XMM9 = bitcast %union.VectorReg* %309 to %union.vec128_t*, !dbg !2297
  %310 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2298
  %311 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %310, i64 0, i64 10, !dbg !2299
  %XMM10 = bitcast %union.VectorReg* %311 to %union.vec128_t*, !dbg !2300
  %312 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2301
  %313 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %312, i64 0, i64 11, !dbg !2302
  %XMM11 = bitcast %union.VectorReg* %313 to %union.vec128_t*, !dbg !2303
  %314 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2304
  %315 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %314, i64 0, i64 12, !dbg !2305
  %XMM12 = bitcast %union.VectorReg* %315 to %union.vec128_t*, !dbg !2306
  %316 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2307
  %317 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %316, i64 0, i64 13, !dbg !2308
  %XMM13 = bitcast %union.VectorReg* %317 to %union.vec128_t*, !dbg !2309
  %318 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2310
  %319 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %318, i64 0, i64 14, !dbg !2311
  %XMM14 = bitcast %union.VectorReg* %319 to %union.vec128_t*, !dbg !2312
  %320 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2313
  %321 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %320, i64 0, i64 15, !dbg !2314
  %XMM15 = bitcast %union.VectorReg* %321 to %union.vec128_t*, !dbg !2315
  %322 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2316
  %323 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %322, i32 0, i32 0, !dbg !2317
  %324 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %323, i64 0, i64 0, !dbg !2318
  %ST0 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %324, i32 0, i32 1, !dbg !2319
  %325 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2320
  %326 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %325, i32 0, i32 0, !dbg !2321
  %327 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %326, i64 0, i64 1, !dbg !2322
  %ST1 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %327, i32 0, i32 1, !dbg !2323
  %328 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2324
  %329 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %328, i32 0, i32 0, !dbg !2325
  %330 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %329, i64 0, i64 2, !dbg !2326
  %ST2 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %330, i32 0, i32 1, !dbg !2327
  %331 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2328
  %332 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %331, i32 0, i32 0, !dbg !2329
  %333 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %332, i64 0, i64 3, !dbg !2330
  %ST3 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %333, i32 0, i32 1, !dbg !2331
  %334 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2332
  %335 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %334, i32 0, i32 0, !dbg !2333
  %336 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %335, i64 0, i64 4, !dbg !2334
  %ST4 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %336, i32 0, i32 1, !dbg !2335
  %337 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2336
  %338 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %337, i32 0, i32 0, !dbg !2337
  %339 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %338, i64 0, i64 5, !dbg !2338
  %ST5 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %339, i32 0, i32 1, !dbg !2339
  %340 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2340
  %341 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %340, i32 0, i32 0, !dbg !2341
  %342 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %341, i64 0, i64 6, !dbg !2342
  %ST6 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %342, i32 0, i32 1, !dbg !2343
  %343 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2344
  %344 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %343, i32 0, i32 0, !dbg !2345
  %345 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %344, i64 0, i64 7, !dbg !2346
  %ST7 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %345, i32 0, i32 1, !dbg !2347
  %346 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2348
  %347 = getelementptr inbounds %struct.MMX, %struct.MMX* %346, i32 0, i32 0, !dbg !2349
  %348 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %347, i64 0, i64 0, !dbg !2350
  %349 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %348, i32 0, i32 1, !dbg !2351
  %350 = bitcast %union.vec64_t* %349 to %struct.uint64v1_t*, !dbg !2352
  %351 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %350, i32 0, i32 0, !dbg !2353
  %MM0 = getelementptr inbounds [1 x i64], [1 x i64]* %351, i64 0, i64 0, !dbg !2350
  %352 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2354
  %353 = getelementptr inbounds %struct.MMX, %struct.MMX* %352, i32 0, i32 0, !dbg !2355
  %354 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %353, i64 0, i64 1, !dbg !2356
  %355 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %354, i32 0, i32 1, !dbg !2357
  %356 = bitcast %union.vec64_t* %355 to %struct.uint64v1_t*, !dbg !2358
  %357 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %356, i32 0, i32 0, !dbg !2359
  %MM1 = getelementptr inbounds [1 x i64], [1 x i64]* %357, i64 0, i64 0, !dbg !2356
  %358 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2360
  %359 = getelementptr inbounds %struct.MMX, %struct.MMX* %358, i32 0, i32 0, !dbg !2361
  %360 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %359, i64 0, i64 2, !dbg !2362
  %361 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %360, i32 0, i32 1, !dbg !2363
  %362 = bitcast %union.vec64_t* %361 to %struct.uint64v1_t*, !dbg !2364
  %363 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %362, i32 0, i32 0, !dbg !2365
  %MM2 = getelementptr inbounds [1 x i64], [1 x i64]* %363, i64 0, i64 0, !dbg !2362
  %364 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2366
  %365 = getelementptr inbounds %struct.MMX, %struct.MMX* %364, i32 0, i32 0, !dbg !2367
  %366 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %365, i64 0, i64 3, !dbg !2368
  %367 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %366, i32 0, i32 1, !dbg !2369
  %368 = bitcast %union.vec64_t* %367 to %struct.uint64v1_t*, !dbg !2370
  %369 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %368, i32 0, i32 0, !dbg !2371
  %MM3 = getelementptr inbounds [1 x i64], [1 x i64]* %369, i64 0, i64 0, !dbg !2368
  %370 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2372
  %371 = getelementptr inbounds %struct.MMX, %struct.MMX* %370, i32 0, i32 0, !dbg !2373
  %372 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %371, i64 0, i64 4, !dbg !2374
  %373 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %372, i32 0, i32 1, !dbg !2375
  %374 = bitcast %union.vec64_t* %373 to %struct.uint64v1_t*, !dbg !2376
  %375 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %374, i32 0, i32 0, !dbg !2377
  %MM4 = getelementptr inbounds [1 x i64], [1 x i64]* %375, i64 0, i64 0, !dbg !2374
  %376 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2378
  %377 = getelementptr inbounds %struct.MMX, %struct.MMX* %376, i32 0, i32 0, !dbg !2379
  %378 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %377, i64 0, i64 5, !dbg !2380
  %379 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %378, i32 0, i32 1, !dbg !2381
  %380 = bitcast %union.vec64_t* %379 to %struct.uint64v1_t*, !dbg !2382
  %381 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %380, i32 0, i32 0, !dbg !2383
  %MM5 = getelementptr inbounds [1 x i64], [1 x i64]* %381, i64 0, i64 0, !dbg !2380
  %382 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2384
  %383 = getelementptr inbounds %struct.MMX, %struct.MMX* %382, i32 0, i32 0, !dbg !2385
  %384 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %383, i64 0, i64 6, !dbg !2386
  %385 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %384, i32 0, i32 1, !dbg !2387
  %386 = bitcast %union.vec64_t* %385 to %struct.uint64v1_t*, !dbg !2388
  %387 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %386, i32 0, i32 0, !dbg !2389
  %MM6 = getelementptr inbounds [1 x i64], [1 x i64]* %387, i64 0, i64 0, !dbg !2386
  %388 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2390
  %389 = getelementptr inbounds %struct.MMX, %struct.MMX* %388, i32 0, i32 0, !dbg !2391
  %390 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %389, i64 0, i64 7, !dbg !2392
  %391 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %390, i32 0, i32 1, !dbg !2393
  %392 = bitcast %union.vec64_t* %391 to %struct.uint64v1_t*, !dbg !2394
  %393 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %392, i32 0, i32 0, !dbg !2395
  %MM7 = getelementptr inbounds [1 x i64], [1 x i64]* %393, i64 0, i64 0, !dbg !2392
  %394 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2396
  %AF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %394, i32 0, i32 5, !dbg !2397
  %395 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2398
  %CF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %395, i32 0, i32 1, !dbg !2399
  %396 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2400
  %DF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %396, i32 0, i32 11, !dbg !2401
  %397 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2402
  %OF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %397, i32 0, i32 13, !dbg !2403
  %398 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2404
  %PF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %398, i32 0, i32 3, !dbg !2405
  %399 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2406
  %SF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %399, i32 0, i32 9, !dbg !2407
  %400 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2408
  %ZF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %400, i32 0, i32 7, !dbg !2409
  store i64* @DR0, i64** %_DR0, align 8, !dbg !2410
  store i64* @DR1, i64** %_DR1, align 8, !dbg !2411
  store i64* @DR2, i64** %_DR2, align 8, !dbg !2412
  store i64* @DR3, i64** %_DR3, align 8, !dbg !2413
  store i64* @DR4, i64** %_DR4, align 8, !dbg !2414
  store i64* @DR5, i64** %_DR5, align 8, !dbg !2415
  store i64* @DR6, i64** %_DR6, align 8, !dbg !2416
  store i64* @DR7, i64** %_DR7, align 8, !dbg !2417
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR0, i32 0, i32 0), i64** %CR0, align 8, !dbg !2418
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR1, i32 0, i32 0), i64** %CR1, align 8, !dbg !2419
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR2, i32 0, i32 0), i64** %CR2, align 8, !dbg !2420
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR3, i32 0, i32 0), i64** %CR3, align 8, !dbg !2421
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR4, i32 0, i32 0), i64** %CR4, align 8, !dbg !2422
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR8, i32 0, i32 0), i64** %CR8, align 8, !dbg !2423
  ret %struct.Memory* %2, !dbg !2424
}

; Function Attrs: noduplicate noinline nounwind optnone
define void @__remill_intrinsics() local_unnamed_addr #4 !dbg !2425 {
  ret void, !dbg !2427
}

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_function_call(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #5

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memcpy(i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @printf(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @__libc_start_main(i64, i64, i64, i64, i64, i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @free(i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @__gmon_start__() #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memset(i64, i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @abort() #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @gettimeofday(i64, i64) #6

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @memalign(i64, i64) #6

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400fe0_putdata(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400fe0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %5 to i32*
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %6 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %6, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %9 = load i64, i64* %RBP, align 8
  %10 = add i64 %1, 1
  store i64 %10, i64* %PC, align 8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %12 = load i64, i64* %11, align 8, !tbaa !2428
  %13 = add i64 %12, -8
  %14 = inttoptr i64 %13 to i64*
  store i64 %9, i64* %14, align 8
  store i64 %13, i64* %11, align 8, !tbaa !2428
  %15 = load i64, i64* %PC, align 8
  store i64 %13, i64* %RBP, align 8, !tbaa !2428
  %16 = add i64 %12, -12
  %17 = load i32, i32* %EDI, align 4
  %18 = add i64 %15, 6
  store i64 %18, i64* %PC, align 8
  %19 = inttoptr i64 %16 to i32*
  store i32 %17, i32* %19, align 4
  %20 = load i64, i64* %RBP, align 8
  %21 = add i64 %20, -8
  %22 = load i32, i32* %ESI, align 4
  %23 = load i64, i64* %PC, align 8
  %24 = add i64 %23, 3
  store i64 %24, i64* %PC, align 8
  %25 = inttoptr i64 %21 to i32*
  store i32 %22, i32* %25, align 4
  %26 = load i64, i64* %RBP, align 8
  %27 = add i64 %26, -16
  %28 = load i64, i64* %RDX, align 8
  %29 = load i64, i64* %PC, align 8
  %30 = add i64 %29, 4
  store i64 %30, i64* %PC, align 8
  %31 = inttoptr i64 %27 to i64*
  store i64 %28, i64* %31, align 8
  %32 = load i64, i64* %RBP, align 8
  %33 = add i64 %32, -24
  %34 = load i64, i64* %PC, align 8
  %35 = add i64 %34, 7
  store i64 %35, i64* %PC, align 8
  %36 = inttoptr i64 %33 to i32*
  store i32 0, i32* %36, align 4
  %37 = load i64, i64* %RBP, align 8
  %38 = add i64 %37, -4
  %39 = load i64, i64* %PC, align 8
  %40 = add i64 %39, 3
  store i64 %40, i64* %PC, align 8
  %41 = inttoptr i64 %38 to i32*
  %42 = load i32, i32* %41, align 4
  %43 = zext i32 %42 to i64
  store i64 %43, i64* %RSI, align 8, !tbaa !2428
  %44 = add i64 %37, -20
  %45 = add i64 %39, 6
  store i64 %45, i64* %PC, align 8
  %46 = inttoptr i64 %44 to i32*
  store i32 %42, i32* %46, align 4
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %48 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %49 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %50 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %53 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %55 = bitcast i64* %54 to double*
  %56 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %57 = bitcast %union.VectorReg* %8 to double*
  %58 = bitcast [32 x %union.VectorReg]* %7 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_400ffb

block_400ffb:                                     ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit, %block_400fe0
  %59 = phi i64 [ %.pre, %block_400fe0 ], [ %212, %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_400fe0 ], [ %158, %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit ]
  %60 = load i64, i64* %RBP, align 8
  %61 = add i64 %60, -20
  %62 = add i64 %59, 3
  store i64 %62, i64* %PC, align 8
  %63 = inttoptr i64 %61 to i32*
  %64 = load i32, i32* %63, align 4
  %65 = zext i32 %64 to i64
  store i64 %65, i64* %RAX, align 8, !tbaa !2428
  %66 = add i64 %60, -8
  %67 = add i64 %59, 6
  store i64 %67, i64* %PC, align 8
  %68 = inttoptr i64 %66 to i32*
  %69 = load i32, i32* %68, align 4
  %70 = sub i32 %64, %69
  %71 = icmp ult i32 %64, %69
  %72 = zext i1 %71 to i8
  store i8 %72, i8* %47, align 1, !tbaa !2432
  %73 = and i32 %70, 255
  %74 = tail call i32 @llvm.ctpop.i32(i32 %73) #11
  %75 = trunc i32 %74 to i8
  %76 = and i8 %75, 1
  %77 = xor i8 %76, 1
  store i8 %77, i8* %48, align 1, !tbaa !2446
  %78 = xor i32 %69, %64
  %79 = xor i32 %78, %70
  %80 = lshr i32 %79, 4
  %81 = trunc i32 %80 to i8
  %82 = and i8 %81, 1
  store i8 %82, i8* %49, align 1, !tbaa !2447
  %83 = icmp eq i32 %70, 0
  %84 = zext i1 %83 to i8
  store i8 %84, i8* %50, align 1, !tbaa !2448
  %85 = lshr i32 %70, 31
  %86 = trunc i32 %85 to i8
  store i8 %86, i8* %51, align 1, !tbaa !2449
  %87 = lshr i32 %64, 31
  %88 = lshr i32 %69, 31
  %89 = xor i32 %88, %87
  %90 = xor i32 %85, %87
  %91 = add nuw nsw i32 %90, %89
  %92 = icmp eq i32 %91, 2
  %93 = zext i1 %92 to i8
  store i8 %93, i8* %52, align 1, !tbaa !2450
  %94 = icmp ne i8 %86, 0
  %95 = xor i1 %94, %92
  %.demorgan = or i1 %83, %95
  %.v = select i1 %.demorgan, i64 12, i64 87
  %96 = add i64 %.v, %59
  store i64 %96, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan, label %block_401007, label %block_401052

block_401007:                                     ; preds = %block_400ffb
  %97 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 72) to i64*), align 8
  store i64 %97, i64* %53, align 1, !tbaa !2451
  store double 0.000000e+00, double* %55, align 1, !tbaa !2451
  store i64 259200, i64* %RAX, align 8, !tbaa !2428
  %98 = add i64 %60, -24
  %99 = add i64 %96, 20
  store i64 %99, i64* %PC, align 8
  %100 = inttoptr i64 %98 to i32*
  %101 = load i32, i32* %100, align 4
  %102 = mul i32 %101, 7141
  %103 = add i32 %102, 54773
  %104 = zext i32 %103 to i64
  store i64 %104, i64* %RCX, align 8, !tbaa !2428
  %105 = icmp ugt i32 %102, -54774
  %106 = zext i1 %105 to i8
  store i8 %106, i8* %47, align 1, !tbaa !2432
  %107 = and i32 %103, 255
  %108 = tail call i32 @llvm.ctpop.i32(i32 %107) #11
  %109 = trunc i32 %108 to i8
  %110 = and i8 %109, 1
  %111 = xor i8 %110, 1
  store i8 %111, i8* %48, align 1, !tbaa !2446
  %112 = xor i32 %102, 16
  %113 = xor i32 %112, %103
  %114 = lshr i32 %113, 4
  %115 = trunc i32 %114 to i8
  %116 = and i8 %115, 1
  store i8 %116, i8* %49, align 1, !tbaa !2447
  %117 = icmp eq i32 %103, 0
  %118 = zext i1 %117 to i8
  store i8 %118, i8* %50, align 1, !tbaa !2448
  %119 = lshr i32 %103, 31
  %120 = trunc i32 %119 to i8
  store i8 %120, i8* %51, align 1, !tbaa !2449
  %121 = lshr i32 %102, 31
  %122 = xor i32 %119, %121
  %123 = add nuw nsw i32 %122, %119
  %124 = icmp eq i32 %123, 2
  %125 = zext i1 %124 to i8
  store i8 %125, i8* %52, align 1, !tbaa !2450
  %126 = add i64 %60, -28
  %127 = add i64 %96, 29
  store i64 %127, i64* %PC, align 8
  %128 = inttoptr i64 %126 to i32*
  store i32 259200, i32* %128, align 4
  %129 = load i32, i32* %ECX, align 4
  %130 = zext i32 %129 to i64
  %131 = load i64, i64* %PC, align 8
  store i64 %130, i64* %RAX, align 8, !tbaa !2428
  %132 = sext i32 %129 to i64
  %133 = lshr i64 %132, 32
  store i64 %133, i64* %56, align 8, !tbaa !2428
  %134 = load i64, i64* %RBP, align 8
  %135 = add i64 %134, -28
  %136 = add i64 %131, 6
  store i64 %136, i64* %PC, align 8
  %137 = inttoptr i64 %135 to i32*
  %138 = load i32, i32* %137, align 4
  %139 = zext i32 %138 to i64
  store i64 %139, i64* %RCX, align 8, !tbaa !2428
  %140 = add i64 %131, 8
  store i64 %140, i64* %PC, align 8
  %141 = sext i32 %138 to i64
  %142 = shl nuw i64 %133, 32
  %143 = or i64 %142, %130
  %144 = sdiv i64 %143, %141
  %145 = shl i64 %144, 32
  %146 = ashr exact i64 %145, 32
  %147 = icmp eq i64 %144, %146
  br i1 %147, label %150, label %148

; <label>:148:                                    ; preds = %block_401007
  %149 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %140, %struct.Memory* %MEMORY.0) #16
  %.pre1 = load i64, i64* %RBP, align 8
  %.pre2 = load i32, i32* %EDX, align 4
  %.pre3 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:150:                                    ; preds = %block_401007
  %151 = srem i64 %143, %141
  %152 = and i64 %144, 4294967295
  store i64 %152, i64* %RAX, align 8, !tbaa !2428
  %153 = and i64 %151, 4294967295
  store i64 %153, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %47, align 1, !tbaa !2432
  store i8 0, i8* %48, align 1, !tbaa !2446
  store i8 0, i8* %49, align 1, !tbaa !2447
  store i8 0, i8* %50, align 1, !tbaa !2448
  store i8 0, i8* %51, align 1, !tbaa !2449
  store i8 0, i8* %52, align 1, !tbaa !2450
  %154 = trunc i64 %151 to i32
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %150, %148
  %155 = phi i64 [ %.pre3, %148 ], [ %140, %150 ]
  %156 = phi i32 [ %.pre2, %148 ], [ %154, %150 ]
  %157 = phi i64 [ %.pre1, %148 ], [ %134, %150 ]
  %158 = phi %struct.Memory* [ %149, %148 ], [ %MEMORY.0, %150 ]
  %159 = add i64 %157, -24
  %160 = add i64 %155, 3
  store i64 %160, i64* %PC, align 8
  %161 = inttoptr i64 %159 to i32*
  store i32 %156, i32* %161, align 4
  %162 = load i32, i32* %EDX, align 4
  %163 = load i64, i64* %PC, align 8
  %164 = sitofp i32 %162 to double
  %165 = load double, double* %58, align 1
  %166 = fmul double %164, %165
  store double %166, double* %57, align 1, !tbaa !2451
  %167 = load i64, i64* %RBP, align 8
  %168 = add i64 %167, -16
  %169 = add i64 %163, 12
  store i64 %169, i64* %PC, align 8
  %170 = inttoptr i64 %168 to i64*
  %171 = load i64, i64* %170, align 8
  store i64 %171, i64* %RSI, align 8, !tbaa !2428
  %172 = add i64 %167, -20
  %173 = add i64 %163, 16
  store i64 %173, i64* %PC, align 8
  %174 = inttoptr i64 %172 to i32*
  %175 = load i32, i32* %174, align 4
  %176 = sext i32 %175 to i64
  store i64 %176, i64* %RDI, align 8, !tbaa !2428
  %177 = shl nsw i64 %176, 3
  %178 = add i64 %177, %171
  %179 = add i64 %163, 21
  store i64 %179, i64* %PC, align 8
  %180 = inttoptr i64 %178 to double*
  store double %166, double* %180, align 8
  %181 = load i64, i64* %RBP, align 8
  %182 = add i64 %181, -20
  %183 = load i64, i64* %PC, align 8
  %184 = add i64 %183, 3
  store i64 %184, i64* %PC, align 8
  %185 = inttoptr i64 %182 to i32*
  %186 = load i32, i32* %185, align 4
  %187 = add i32 %186, 1
  %188 = zext i32 %187 to i64
  store i64 %188, i64* %RAX, align 8, !tbaa !2428
  %189 = icmp eq i32 %186, -1
  %190 = icmp eq i32 %187, 0
  %191 = or i1 %189, %190
  %192 = zext i1 %191 to i8
  store i8 %192, i8* %47, align 1, !tbaa !2432
  %193 = and i32 %187, 255
  %194 = tail call i32 @llvm.ctpop.i32(i32 %193) #11
  %195 = trunc i32 %194 to i8
  %196 = and i8 %195, 1
  %197 = xor i8 %196, 1
  store i8 %197, i8* %48, align 1, !tbaa !2446
  %198 = xor i32 %187, %186
  %199 = lshr i32 %198, 4
  %200 = trunc i32 %199 to i8
  %201 = and i8 %200, 1
  store i8 %201, i8* %49, align 1, !tbaa !2447
  %202 = zext i1 %190 to i8
  store i8 %202, i8* %50, align 1, !tbaa !2448
  %203 = lshr i32 %187, 31
  %204 = trunc i32 %203 to i8
  store i8 %204, i8* %51, align 1, !tbaa !2449
  %205 = lshr i32 %186, 31
  %206 = xor i32 %203, %205
  %207 = add nuw nsw i32 %206, %203
  %208 = icmp eq i32 %207, 2
  %209 = zext i1 %208 to i8
  store i8 %209, i8* %52, align 1, !tbaa !2450
  %210 = add i64 %183, 9
  store i64 %210, i64* %PC, align 8
  store i32 %187, i32* %185, align 4
  %211 = load i64, i64* %PC, align 8
  %212 = add i64 %211, -82
  store i64 %212, i64* %PC, align 8, !tbaa !2428
  br label %block_400ffb

block_401052:                                     ; preds = %block_400ffb
  %213 = add i64 %96, 1
  store i64 %213, i64* %PC, align 8
  %214 = load i64, i64* %11, align 8, !tbaa !2428
  %215 = add i64 %214, 8
  %216 = inttoptr i64 %214 to i64*
  %217 = load i64, i64* %216, align 8
  store i64 %217, i64* %RBP, align 8, !tbaa !2428
  store i64 %215, i64* %11, align 8, !tbaa !2428
  %218 = add i64 %96, 2
  store i64 %218, i64* %PC, align 8
  %219 = inttoptr i64 %215 to i64*
  %220 = load i64, i64* %219, align 8
  store i64 %220, i64* %PC, align 8, !tbaa !2428
  %221 = add i64 %214, 16
  store i64 %221, i64* %11, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400688__init_proc(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400688:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = add i64 %3, -8
  store i64 %4, i64* %RSP, align 8, !tbaa !2428
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_604ff0__got_type* @seg_604ff0__got to i64), i64 8) to i64*), align 8
  store i64 %11, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %5, align 1, !tbaa !2432
  %12 = trunc i64 %11 to i32
  %13 = and i32 %12, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13) #11
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %6, align 1, !tbaa !2446
  %18 = icmp eq i64 %11, 0
  %19 = zext i1 %18 to i8
  store i8 %19, i8* %8, align 1, !tbaa !2448
  %20 = lshr i64 %11, 63
  %21 = trunc i64 %20 to i8
  store i8 %21, i8* %9, align 1, !tbaa !2449
  store i8 0, i8* %10, align 1, !tbaa !2450
  store i8 0, i8* %7, align 1, !tbaa !2447
  %.v = select i1 %18, i64 18, i64 16
  %22 = add i64 %.v, %1
  store i64 %22, i64* %PC, align 8, !tbaa !2428
  br i1 %18, label %block_40069a, label %block_400698

block_400698:                                     ; preds = %block_400688
  %23 = add i64 %22, 2
  %24 = add i64 %3, -16
  %25 = inttoptr i64 %24 to i64*
  store i64 %23, i64* %25, align 8
  store i64 %24, i64* %RSP, align 8, !tbaa !2428
  store i64 %11, i64* %PC, align 8, !tbaa !2428
  %26 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 %11, %struct.Memory* %2)
  %.pre = load i64, i64* %RSP, align 8
  %.pre1 = load i64, i64* %PC, align 8
  br label %block_40069a

block_40069a:                                     ; preds = %block_400698, %block_400688
  %27 = phi i64 [ %22, %block_400688 ], [ %.pre1, %block_400698 ]
  %28 = phi i64 [ %4, %block_400688 ], [ %.pre, %block_400698 ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_400688 ], [ %26, %block_400698 ]
  %29 = add i64 %28, 8
  store i64 %29, i64* %RSP, align 8, !tbaa !2428
  %30 = icmp ugt i64 %28, -9
  %31 = zext i1 %30 to i8
  store i8 %31, i8* %5, align 1, !tbaa !2432
  %32 = trunc i64 %29 to i32
  %33 = and i32 %32, 255
  %34 = tail call i32 @llvm.ctpop.i32(i32 %33) #11
  %35 = trunc i32 %34 to i8
  %36 = and i8 %35, 1
  %37 = xor i8 %36, 1
  store i8 %37, i8* %6, align 1, !tbaa !2446
  %38 = xor i64 %29, %28
  %39 = lshr i64 %38, 4
  %40 = trunc i64 %39 to i8
  %41 = and i8 %40, 1
  store i8 %41, i8* %7, align 1, !tbaa !2447
  %42 = icmp eq i64 %29, 0
  %43 = zext i1 %42 to i8
  store i8 %43, i8* %8, align 1, !tbaa !2448
  %44 = lshr i64 %29, 63
  %45 = trunc i64 %44 to i8
  store i8 %45, i8* %9, align 1, !tbaa !2449
  %46 = lshr i64 %28, 63
  %47 = xor i64 %44, %46
  %48 = add nuw nsw i64 %47, %44
  %49 = icmp eq i64 %48, 2
  %50 = zext i1 %49 to i8
  store i8 %50, i8* %10, align 1, !tbaa !2450
  %51 = add i64 %27, 5
  store i64 %51, i64* %PC, align 8
  %52 = inttoptr i64 %29 to i64*
  %53 = load i64, i64* %52, align 8
  store i64 %53, i64* %PC, align 8, !tbaa !2428
  %54 = add i64 %28, 16
  store i64 %54, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0
}

; Function Attrs: noinline
define %struct.Memory* @sub_404020___libc_csu_init(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #8 {
block_404020:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 27, i32 0
  %R13D = bitcast %union.anon* %4 to i32*
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 25, i32 0, i32 0
  %R13 = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %R14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 29, i32 0, i32 0
  %R15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 31, i32 0, i32 0
  %5 = load i64, i64* %R15, align 8
  %6 = add i64 %1, 2
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %R14, align 8
  %11 = load i64, i64* %PC, align 8
  %12 = add i64 %11, 2
  store i64 %12, i64* %PC, align 8
  %13 = add i64 %7, -16
  %14 = inttoptr i64 %13 to i64*
  store i64 %10, i64* %14, align 8
  %15 = load i64, i64* %RDX, align 8
  %16 = load i64, i64* %PC, align 8
  store i64 %15, i64* %R15, align 8, !tbaa !2428
  %17 = load i64, i64* %R13, align 8
  %18 = add i64 %16, 5
  store i64 %18, i64* %PC, align 8
  %19 = add i64 %7, -24
  %20 = inttoptr i64 %19 to i64*
  store i64 %17, i64* %20, align 8
  %21 = load i64, i64* %R12, align 8
  %22 = load i64, i64* %PC, align 8
  %23 = add i64 %22, 2
  store i64 %23, i64* %PC, align 8
  %24 = add i64 %7, -32
  %25 = inttoptr i64 %24 to i64*
  store i64 %21, i64* %25, align 8
  %26 = load i64, i64* %PC, align 8
  store i64 ptrtoint (%seg_604de0__init_array_type* @seg_604de0__init_array to i64), i64* %R12, align 8, !tbaa !2428
  %27 = load i64, i64* %RBP, align 8
  %28 = add i64 %26, 8
  store i64 %28, i64* %PC, align 8
  %29 = add i64 %7, -40
  %30 = inttoptr i64 %29 to i64*
  store i64 %27, i64* %30, align 8
  %31 = load i64, i64* %PC, align 8
  store i64 add (i64 ptrtoint (%seg_604de0__init_array_type* @seg_604de0__init_array to i64), i64 8), i64* %RBP, align 8, !tbaa !2428
  %32 = load i64, i64* %RBX, align 8
  %33 = add i64 %31, 8
  store i64 %33, i64* %PC, align 8
  %34 = add i64 %7, -48
  %35 = inttoptr i64 %34 to i64*
  store i64 %32, i64* %35, align 8
  %36 = load i32, i32* %EDI, align 4
  %37 = zext i32 %36 to i64
  %38 = load i64, i64* %PC, align 8
  store i64 %37, i64* %R13, align 8, !tbaa !2428
  %39 = load i64, i64* %RSI, align 8
  store i64 %39, i64* %R14, align 8, !tbaa !2428
  %40 = load i64, i64* %RBP, align 8
  %41 = load i64, i64* %R12, align 8
  %42 = sub i64 %40, %41
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %45 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %48 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %49 = lshr i64 %42, 2
  %50 = trunc i64 %49 to i8
  %51 = and i8 %50, 1
  %52 = ashr i64 %42, 3
  store i64 %52, i64* %RBP, align 8, !tbaa !2428
  store i8 %51, i8* %43, align 1, !tbaa !2453
  %53 = trunc i64 %52 to i32
  %54 = and i32 %53, 255
  %55 = tail call i32 @llvm.ctpop.i32(i32 %54) #11
  %56 = trunc i32 %55 to i8
  %57 = and i8 %56, 1
  %58 = xor i8 %57, 1
  store i8 %58, i8* %44, align 1, !tbaa !2453
  store i8 0, i8* %45, align 1, !tbaa !2453
  %59 = icmp eq i64 %52, 0
  %60 = zext i1 %59 to i8
  store i8 %60, i8* %46, align 1, !tbaa !2453
  %61 = lshr i64 %52, 63
  %62 = trunc i64 %61 to i8
  store i8 %62, i8* %47, align 1, !tbaa !2453
  store i8 0, i8* %48, align 1, !tbaa !2453
  %63 = add i64 %38, -14771
  %64 = add i64 %38, 22
  %65 = add i64 %7, -64
  %66 = inttoptr i64 %65 to i64*
  store i64 %64, i64* %66, align 8
  store i64 %65, i64* %RSP, align 8, !tbaa !2428
  store i64 %63, i64* %PC, align 8, !tbaa !2428
  %67 = tail call %struct.Memory* @sub_400688__init_proc_renamed_(%struct.State* nonnull %0, i64 %63, %struct.Memory* %2)
  %68 = load i64, i64* %RBP, align 8
  %69 = load i64, i64* %PC, align 8
  store i8 0, i8* %43, align 1, !tbaa !2432
  %70 = trunc i64 %68 to i32
  %71 = and i32 %70, 255
  %72 = tail call i32 @llvm.ctpop.i32(i32 %71) #11
  %73 = trunc i32 %72 to i8
  %74 = and i8 %73, 1
  %75 = xor i8 %74, 1
  store i8 %75, i8* %44, align 1, !tbaa !2446
  %76 = icmp eq i64 %68, 0
  %77 = zext i1 %76 to i8
  store i8 %77, i8* %46, align 1, !tbaa !2448
  %78 = lshr i64 %68, 63
  %79 = trunc i64 %78 to i8
  store i8 %79, i8* %47, align 1, !tbaa !2449
  store i8 0, i8* %48, align 1, !tbaa !2450
  store i8 0, i8* %45, align 1, !tbaa !2447
  %.v = select i1 %76, i64 37, i64 5
  %80 = add i64 %.v, %69
  store i64 %80, i64* %PC, align 8, !tbaa !2428
  br i1 %76, label %block_404076, label %block_404056

block_404076.loopexit:                            ; preds = %block_404060
  br label %block_404076

block_404076:                                     ; preds = %block_404076.loopexit, %block_404020
  %81 = phi i64 [ %80, %block_404020 ], [ %179, %block_404076.loopexit ]
  %MEMORY.0 = phi %struct.Memory* [ %67, %block_404020 ], [ %149, %block_404076.loopexit ]
  %82 = load i64, i64* %RSP, align 8
  %83 = add i64 %82, 8
  store i64 %83, i64* %RSP, align 8, !tbaa !2428
  %84 = icmp ugt i64 %82, -9
  %85 = zext i1 %84 to i8
  store i8 %85, i8* %43, align 1, !tbaa !2432
  %86 = trunc i64 %83 to i32
  %87 = and i32 %86, 255
  %88 = tail call i32 @llvm.ctpop.i32(i32 %87) #11
  %89 = trunc i32 %88 to i8
  %90 = and i8 %89, 1
  %91 = xor i8 %90, 1
  store i8 %91, i8* %44, align 1, !tbaa !2446
  %92 = xor i64 %83, %82
  %93 = lshr i64 %92, 4
  %94 = trunc i64 %93 to i8
  %95 = and i8 %94, 1
  store i8 %95, i8* %45, align 1, !tbaa !2447
  %96 = icmp eq i64 %83, 0
  %97 = zext i1 %96 to i8
  store i8 %97, i8* %46, align 1, !tbaa !2448
  %98 = lshr i64 %83, 63
  %99 = trunc i64 %98 to i8
  store i8 %99, i8* %47, align 1, !tbaa !2449
  %100 = lshr i64 %82, 63
  %101 = xor i64 %98, %100
  %102 = add nuw nsw i64 %101, %98
  %103 = icmp eq i64 %102, 2
  %104 = zext i1 %103 to i8
  store i8 %104, i8* %48, align 1, !tbaa !2450
  %105 = add i64 %81, 5
  store i64 %105, i64* %PC, align 8
  %106 = add i64 %82, 16
  %107 = inttoptr i64 %83 to i64*
  %108 = load i64, i64* %107, align 8
  store i64 %108, i64* %RBX, align 8, !tbaa !2428
  store i64 %106, i64* %RSP, align 8, !tbaa !2428
  %109 = add i64 %81, 6
  store i64 %109, i64* %PC, align 8
  %110 = add i64 %82, 24
  %111 = inttoptr i64 %106 to i64*
  %112 = load i64, i64* %111, align 8
  store i64 %112, i64* %RBP, align 8, !tbaa !2428
  store i64 %110, i64* %RSP, align 8, !tbaa !2428
  %113 = add i64 %81, 8
  store i64 %113, i64* %PC, align 8
  %114 = add i64 %82, 32
  %115 = inttoptr i64 %110 to i64*
  %116 = load i64, i64* %115, align 8
  store i64 %116, i64* %R12, align 8, !tbaa !2428
  store i64 %114, i64* %RSP, align 8, !tbaa !2428
  %117 = add i64 %81, 10
  store i64 %117, i64* %PC, align 8
  %118 = add i64 %82, 40
  %119 = inttoptr i64 %114 to i64*
  %120 = load i64, i64* %119, align 8
  store i64 %120, i64* %R13, align 8, !tbaa !2428
  store i64 %118, i64* %RSP, align 8, !tbaa !2428
  %121 = add i64 %81, 12
  store i64 %121, i64* %PC, align 8
  %122 = add i64 %82, 48
  %123 = inttoptr i64 %118 to i64*
  %124 = load i64, i64* %123, align 8
  store i64 %124, i64* %R14, align 8, !tbaa !2428
  store i64 %122, i64* %RSP, align 8, !tbaa !2428
  %125 = add i64 %81, 14
  store i64 %125, i64* %PC, align 8
  %126 = add i64 %82, 56
  %127 = inttoptr i64 %122 to i64*
  %128 = load i64, i64* %127, align 8
  store i64 %128, i64* %R15, align 8, !tbaa !2428
  store i64 %126, i64* %RSP, align 8, !tbaa !2428
  %129 = add i64 %81, 15
  store i64 %129, i64* %PC, align 8
  %130 = inttoptr i64 %126 to i64*
  %131 = load i64, i64* %130, align 8
  store i64 %131, i64* %PC, align 8, !tbaa !2428
  %132 = add i64 %82, 64
  store i64 %132, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_404056:                                     ; preds = %block_404020
  store i64 0, i64* %RBX, align 8, !tbaa !2428
  store i8 0, i8* %43, align 1, !tbaa !2432
  store i8 1, i8* %44, align 1, !tbaa !2446
  store i8 1, i8* %46, align 1, !tbaa !2448
  store i8 0, i8* %47, align 1, !tbaa !2449
  store i8 0, i8* %48, align 1, !tbaa !2450
  store i8 0, i8* %45, align 1, !tbaa !2447
  %133 = add i64 %80, 10
  store i64 %133, i64* %PC, align 8
  br label %block_404060

block_404060:                                     ; preds = %block_404060, %block_404056
  %134 = phi i64 [ 0, %block_404056 ], [ %152, %block_404060 ]
  %135 = phi i64 [ %133, %block_404056 ], [ %179, %block_404060 ]
  %MEMORY.1 = phi %struct.Memory* [ %67, %block_404056 ], [ %149, %block_404060 ]
  %136 = load i64, i64* %R15, align 8
  store i64 %136, i64* %RDX, align 8, !tbaa !2428
  %137 = load i64, i64* %R14, align 8
  store i64 %137, i64* %RSI, align 8, !tbaa !2428
  %138 = load i32, i32* %R13D, align 4
  %139 = zext i32 %138 to i64
  store i64 %139, i64* %RDI, align 8, !tbaa !2428
  %140 = load i64, i64* %R12, align 8
  %141 = shl i64 %134, 3
  %142 = add i64 %140, %141
  %143 = add i64 %135, 13
  store i64 %143, i64* %PC, align 8
  %144 = load i64, i64* %RSP, align 8, !tbaa !2428
  %145 = add i64 %144, -8
  %146 = inttoptr i64 %145 to i64*
  store i64 %143, i64* %146, align 8
  store i64 %145, i64* %RSP, align 8, !tbaa !2428
  %147 = inttoptr i64 %142 to i64*
  %148 = load i64, i64* %147, align 8
  store i64 %148, i64* %PC, align 8, !tbaa !2428
  %149 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 %148, %struct.Memory* %MEMORY.1)
  %150 = load i64, i64* %RBX, align 8
  %151 = load i64, i64* %PC, align 8
  %152 = add i64 %150, 1
  store i64 %152, i64* %RBX, align 8, !tbaa !2428
  %153 = lshr i64 %152, 63
  %154 = load i64, i64* %RBP, align 8
  %155 = sub i64 %154, %152
  %156 = icmp ult i64 %154, %152
  %157 = zext i1 %156 to i8
  store i8 %157, i8* %43, align 1, !tbaa !2432
  %158 = trunc i64 %155 to i32
  %159 = and i32 %158, 255
  %160 = tail call i32 @llvm.ctpop.i32(i32 %159) #11
  %161 = trunc i32 %160 to i8
  %162 = and i8 %161, 1
  %163 = xor i8 %162, 1
  store i8 %163, i8* %44, align 1, !tbaa !2446
  %164 = xor i64 %154, %152
  %165 = xor i64 %164, %155
  %166 = lshr i64 %165, 4
  %167 = trunc i64 %166 to i8
  %168 = and i8 %167, 1
  store i8 %168, i8* %45, align 1, !tbaa !2447
  %169 = icmp eq i64 %155, 0
  %170 = zext i1 %169 to i8
  store i8 %170, i8* %46, align 1, !tbaa !2448
  %171 = lshr i64 %155, 63
  %172 = trunc i64 %171 to i8
  store i8 %172, i8* %47, align 1, !tbaa !2449
  %173 = lshr i64 %154, 63
  %174 = xor i64 %173, %153
  %175 = xor i64 %171, %173
  %176 = add nuw nsw i64 %175, %174
  %177 = icmp eq i64 %176, 2
  %178 = zext i1 %177 to i8
  store i8 %178, i8* %48, align 1, !tbaa !2450
  %.v2 = select i1 %169, i64 9, i64 -13
  %179 = add i64 %.v2, %151
  store i64 %179, i64* %PC, align 8, !tbaa !2428
  br i1 %169, label %block_404076.loopexit, label %block_404060
}

; Function Attrs: noinline
define %struct.Memory* @sub_400e70_makewt(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone) local_unnamed_addr #8 {
block_400e70:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %1, 1
  store i64 %7, i64* %PC, align 8
  %8 = load i64, i64* %RSP, align 8, !tbaa !2428
  %9 = add i64 %8, -8
  %10 = inttoptr i64 %9 to i64*
  store i64 %6, i64* %10, align 8
  %11 = load i64, i64* %PC, align 8
  store i64 %9, i64* %RBP, align 8, !tbaa !2428
  %12 = add i64 %8, -72
  store i64 %12, i64* %RSP, align 8, !tbaa !2428
  %13 = icmp ult i64 %9, 64
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1, !tbaa !2432
  %16 = trunc i64 %12 to i32
  %17 = and i32 %16, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17) #11
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1, !tbaa !2446
  %23 = xor i64 %9, %12
  %24 = lshr i64 %23, 4
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1, !tbaa !2447
  %28 = icmp eq i64 %12, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1, !tbaa !2448
  %31 = lshr i64 %12, 63
  %32 = trunc i64 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1, !tbaa !2449
  %34 = lshr i64 %9, 63
  %35 = xor i64 %31, %34
  %36 = add nuw nsw i64 %35, %34
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1, !tbaa !2450
  %40 = add i64 %8, -12
  %41 = load i32, i32* %EDI, align 4
  %42 = add i64 %11, 10
  store i64 %42, i64* %PC, align 8
  %43 = inttoptr i64 %40 to i32*
  store i32 %41, i32* %43, align 4
  %44 = load i64, i64* %RBP, align 8
  %45 = add i64 %44, -16
  %46 = load i64, i64* %RSI, align 8
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 4
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %45 to i64*
  store i64 %46, i64* %49, align 8
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -24
  %52 = load i64, i64* %RDX, align 8
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 4
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %51 to i64*
  store i64 %52, i64* %55, align 8
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -4
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 4
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %57 to i32*
  %61 = load i32, i32* %60, align 4
  %62 = add i32 %61, -2
  %63 = icmp ult i32 %61, 2
  %64 = zext i1 %63 to i8
  store i8 %64, i8* %15, align 1, !tbaa !2432
  %65 = and i32 %62, 255
  %66 = tail call i32 @llvm.ctpop.i32(i32 %65) #11
  %67 = trunc i32 %66 to i8
  %68 = and i8 %67, 1
  %69 = xor i8 %68, 1
  store i8 %69, i8* %22, align 1, !tbaa !2446
  %70 = xor i32 %62, %61
  %71 = lshr i32 %70, 4
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  store i8 %73, i8* %27, align 1, !tbaa !2447
  %74 = icmp eq i32 %62, 0
  %75 = zext i1 %74 to i8
  store i8 %75, i8* %30, align 1, !tbaa !2448
  %76 = lshr i32 %62, 31
  %77 = trunc i32 %76 to i8
  store i8 %77, i8* %33, align 1, !tbaa !2449
  %78 = lshr i32 %61, 31
  %79 = xor i32 %76, %78
  %80 = add nuw nsw i32 %79, %78
  %81 = icmp eq i32 %80, 2
  %82 = zext i1 %81 to i8
  store i8 %82, i8* %39, align 1, !tbaa !2450
  %83 = icmp ne i8 %77, 0
  %84 = xor i1 %83, %81
  %85 = or i1 %74, %84
  %.v = select i1 %85, i64 339, i64 10
  %86 = add i64 %.v, %58
  store i64 %86, i64* %PC, align 8, !tbaa !2428
  br i1 %85, label %block_400fd6, label %block_400e8d

block_400f1d:                                     ; preds = %block_400f16, %block_400f29
  %87 = phi i64 [ %.pre, %block_400f16 ], [ %391, %block_400f29 ]
  %88 = load i64, i64* %RBP, align 8
  %89 = add i64 %88, -28
  %90 = add i64 %87, 3
  store i64 %90, i64* %PC, align 8
  %91 = inttoptr i64 %89 to i32*
  %92 = load i32, i32* %91, align 4
  %93 = zext i32 %92 to i64
  store i64 %93, i64* %RAX, align 8, !tbaa !2428
  %94 = add i64 %88, -32
  %95 = add i64 %87, 6
  store i64 %95, i64* %PC, align 8
  %96 = inttoptr i64 %94 to i32*
  %97 = load i32, i32* %96, align 4
  %98 = sub i32 %92, %97
  %99 = icmp ult i32 %92, %97
  %100 = zext i1 %99 to i8
  store i8 %100, i8* %15, align 1, !tbaa !2432
  %101 = and i32 %98, 255
  %102 = tail call i32 @llvm.ctpop.i32(i32 %101) #11
  %103 = trunc i32 %102 to i8
  %104 = and i8 %103, 1
  %105 = xor i8 %104, 1
  store i8 %105, i8* %22, align 1, !tbaa !2446
  %106 = xor i32 %97, %92
  %107 = xor i32 %106, %98
  %108 = lshr i32 %107, 4
  %109 = trunc i32 %108 to i8
  %110 = and i8 %109, 1
  store i8 %110, i8* %27, align 1, !tbaa !2447
  %111 = icmp eq i32 %98, 0
  %112 = zext i1 %111 to i8
  store i8 %112, i8* %30, align 1, !tbaa !2448
  %113 = lshr i32 %98, 31
  %114 = trunc i32 %113 to i8
  store i8 %114, i8* %33, align 1, !tbaa !2449
  %115 = lshr i32 %92, 31
  %116 = lshr i32 %97, 31
  %117 = xor i32 %116, %115
  %118 = xor i32 %113, %115
  %119 = add nuw nsw i32 %118, %117
  %120 = icmp eq i32 %119, 2
  %121 = zext i1 %120 to i8
  store i8 %121, i8* %39, align 1, !tbaa !2450
  %122 = icmp ne i8 %114, 0
  %123 = xor i1 %122, %120
  %.v118 = select i1 %123, i64 12, i64 164
  %124 = add i64 %.v118, %87
  store i64 %124, i64* %PC, align 8, !tbaa !2428
  br i1 %123, label %block_400f29, label %block_400fc1

block_400fd6:                                     ; preds = %block_400fd1, %block_400e70
  %125 = phi i64 [ %86, %block_400e70 ], [ %393, %block_400fd1 ]
  %MEMORY.1 = phi %struct.Memory* [ %2, %block_400e70 ], [ %MEMORY.2, %block_400fd1 ]
  %126 = load i64, i64* %RSP, align 8
  %127 = add i64 %126, 64
  store i64 %127, i64* %RSP, align 8, !tbaa !2428
  %128 = icmp ugt i64 %126, -65
  %129 = zext i1 %128 to i8
  store i8 %129, i8* %15, align 1, !tbaa !2432
  %130 = trunc i64 %127 to i32
  %131 = and i32 %130, 255
  %132 = tail call i32 @llvm.ctpop.i32(i32 %131) #11
  %133 = trunc i32 %132 to i8
  %134 = and i8 %133, 1
  %135 = xor i8 %134, 1
  store i8 %135, i8* %22, align 1, !tbaa !2446
  %136 = xor i64 %127, %126
  %137 = lshr i64 %136, 4
  %138 = trunc i64 %137 to i8
  %139 = and i8 %138, 1
  store i8 %139, i8* %27, align 1, !tbaa !2447
  %140 = icmp eq i64 %127, 0
  %141 = zext i1 %140 to i8
  store i8 %141, i8* %30, align 1, !tbaa !2448
  %142 = lshr i64 %127, 63
  %143 = trunc i64 %142 to i8
  store i8 %143, i8* %33, align 1, !tbaa !2449
  %144 = lshr i64 %126, 63
  %145 = xor i64 %142, %144
  %146 = add nuw nsw i64 %145, %142
  %147 = icmp eq i64 %146, 2
  %148 = zext i1 %147 to i8
  store i8 %148, i8* %39, align 1, !tbaa !2450
  %149 = add i64 %125, 5
  store i64 %149, i64* %PC, align 8
  %150 = add i64 %126, 72
  %151 = inttoptr i64 %127 to i64*
  %152 = load i64, i64* %151, align 8
  store i64 %152, i64* %RBP, align 8, !tbaa !2428
  store i64 %150, i64* %RSP, align 8, !tbaa !2428
  %153 = add i64 %125, 6
  store i64 %153, i64* %PC, align 8
  %154 = inttoptr i64 %150 to i64*
  %155 = load i64, i64* %154, align 8
  store i64 %155, i64* %PC, align 8, !tbaa !2428
  %156 = add i64 %126, 80
  store i64 %156, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.1

block_400f29:                                     ; preds = %block_400f1d
  %157 = add i64 %88, -40
  %158 = add i64 %124, 5
  store i64 %158, i64* %PC, align 8
  %159 = inttoptr i64 %157 to i64*
  %160 = load i64, i64* %159, align 8
  store i64 %160, i64* %400, align 1, !tbaa !2451
  store double 0.000000e+00, double* %402, align 1, !tbaa !2451
  %161 = add i64 %124, 10
  store i64 %161, i64* %PC, align 8
  %162 = load i32, i32* %91, align 4
  %163 = sitofp i32 %162 to double
  store double %163, double* %489, align 1, !tbaa !2451
  %164 = bitcast i64 %160 to double
  %165 = fmul double %164, %163
  store double %165, double* %399, align 1, !tbaa !2451
  store i64 0, i64* %401, align 1, !tbaa !2451
  %166 = add i64 %124, -2073
  %167 = add i64 %124, 19
  %168 = load i64, i64* %RSP, align 8, !tbaa !2428
  %169 = add i64 %168, -8
  %170 = inttoptr i64 %169 to i64*
  store i64 %167, i64* %170, align 8
  store i64 %169, i64* %RSP, align 8, !tbaa !2428
  store i64 %166, i64* %PC, align 8, !tbaa !2428
  %171 = load double, double* %399, align 8, !alias.scope !2454, !noalias !2457
  %172 = load i64, i64* %170, align 8
  store i64 %168, i64* %RSP, align 8, !alias.scope !2454, !noalias !2457
  %173 = tail call double @cos(double %171)
  tail call void @llvm.memset.p0i8.i64(i8* nonnull %434, i8 0, i64 24, i32 8, i1 false)
  store double %173, double* %399, align 8, !alias.scope !2454, !noalias !2457
  %174 = load i64, i64* %RBP, align 8
  %175 = add i64 %174, -48
  %176 = add i64 %172, 5
  store i64 %176, i64* %PC, align 8
  %177 = inttoptr i64 %175 to double*
  store double %173, double* %177, align 8
  %178 = load i64, i64* %RBP, align 8
  %179 = add i64 %178, -40
  %180 = load i64, i64* %PC, align 8
  %181 = add i64 %180, 5
  store i64 %181, i64* %PC, align 8
  %182 = inttoptr i64 %179 to i64*
  %183 = load i64, i64* %182, align 8
  store i64 %183, i64* %400, align 1, !tbaa !2451
  store double 0.000000e+00, double* %402, align 1, !tbaa !2451
  %184 = add i64 %178, -28
  %185 = add i64 %180, 10
  store i64 %185, i64* %PC, align 8
  %186 = inttoptr i64 %184 to i32*
  %187 = load i32, i32* %186, align 4
  %188 = sitofp i32 %187 to double
  store double %188, double* %489, align 1, !tbaa !2451
  %189 = bitcast i64 %183 to double
  %190 = fmul double %189, %188
  store double %190, double* %399, align 1, !tbaa !2451
  store i64 0, i64* %401, align 1, !tbaa !2451
  %191 = add i64 %180, -2049
  %192 = add i64 %180, 19
  %193 = load i64, i64* %RSP, align 8, !tbaa !2428
  %194 = add i64 %193, -8
  %195 = inttoptr i64 %194 to i64*
  store i64 %192, i64* %195, align 8
  store i64 %194, i64* %RSP, align 8, !tbaa !2428
  store i64 %191, i64* %PC, align 8, !tbaa !2428
  %196 = load double, double* %399, align 8, !alias.scope !2459, !noalias !2462
  %197 = load i64, i64* %195, align 8
  store i64 %193, i64* %RSP, align 8, !alias.scope !2459, !noalias !2462
  %198 = tail call double @sin(double %196)
  tail call void @llvm.memset.p0i8.i64(i8* nonnull %434, i8 0, i64 24, i32 8, i1 false)
  store double %198, double* %399, align 8, !alias.scope !2459, !noalias !2462
  %199 = load i64, i64* %RBP, align 8
  %200 = add i64 %199, -56
  %201 = add i64 %197, 5
  store i64 %201, i64* %PC, align 8
  %202 = inttoptr i64 %200 to double*
  store double %198, double* %202, align 8
  %203 = load i64, i64* %RBP, align 8
  %204 = add i64 %203, -48
  %205 = load i64, i64* %PC, align 8
  %206 = add i64 %205, 5
  store i64 %206, i64* %PC, align 8
  %207 = inttoptr i64 %204 to i64*
  %208 = load i64, i64* %207, align 8
  store i64 %208, i64* %400, align 1, !tbaa !2451
  store double 0.000000e+00, double* %402, align 1, !tbaa !2451
  %209 = add i64 %203, -24
  %210 = add i64 %205, 9
  store i64 %210, i64* %PC, align 8
  %211 = inttoptr i64 %209 to i64*
  %212 = load i64, i64* %211, align 8
  store i64 %212, i64* %RAX, align 8, !tbaa !2428
  %213 = add i64 %203, -28
  %214 = add i64 %205, 13
  store i64 %214, i64* %PC, align 8
  %215 = inttoptr i64 %213 to i32*
  %216 = load i32, i32* %215, align 4
  %217 = sext i32 %216 to i64
  store i64 %217, i64* %RCX, align 8, !tbaa !2428
  %218 = shl nsw i64 %217, 3
  %219 = add i64 %218, %212
  %220 = add i64 %205, 18
  store i64 %220, i64* %PC, align 8
  %221 = inttoptr i64 %219 to i64*
  store i64 %208, i64* %221, align 8
  %222 = load i64, i64* %RBP, align 8
  %223 = add i64 %222, -56
  %224 = load i64, i64* %PC, align 8
  %225 = add i64 %224, 5
  store i64 %225, i64* %PC, align 8
  %226 = inttoptr i64 %223 to i64*
  %227 = load i64, i64* %226, align 8
  store i64 %227, i64* %400, align 1, !tbaa !2451
  store double 0.000000e+00, double* %402, align 1, !tbaa !2451
  %228 = add i64 %222, -24
  %229 = add i64 %224, 9
  store i64 %229, i64* %PC, align 8
  %230 = inttoptr i64 %228 to i64*
  %231 = load i64, i64* %230, align 8
  store i64 %231, i64* %RAX, align 8, !tbaa !2428
  %232 = add i64 %222, -28
  %233 = add i64 %224, 12
  store i64 %233, i64* %PC, align 8
  %234 = inttoptr i64 %232 to i32*
  %235 = load i32, i32* %234, align 4
  %236 = add i32 %235, 1
  %237 = zext i32 %236 to i64
  store i64 %237, i64* %RDX, align 8, !tbaa !2428
  %238 = icmp eq i32 %235, -1
  %239 = icmp eq i32 %236, 0
  %240 = or i1 %238, %239
  %241 = zext i1 %240 to i8
  store i8 %241, i8* %15, align 1, !tbaa !2432
  %242 = and i32 %236, 255
  %243 = tail call i32 @llvm.ctpop.i32(i32 %242) #11
  %244 = trunc i32 %243 to i8
  %245 = and i8 %244, 1
  %246 = xor i8 %245, 1
  store i8 %246, i8* %22, align 1, !tbaa !2446
  %247 = xor i32 %236, %235
  %248 = lshr i32 %247, 4
  %249 = trunc i32 %248 to i8
  %250 = and i8 %249, 1
  store i8 %250, i8* %27, align 1, !tbaa !2447
  %251 = zext i1 %239 to i8
  store i8 %251, i8* %30, align 1, !tbaa !2448
  %252 = lshr i32 %236, 31
  %253 = trunc i32 %252 to i8
  store i8 %253, i8* %33, align 1, !tbaa !2449
  %254 = lshr i32 %235, 31
  %255 = xor i32 %252, %254
  %256 = add nuw nsw i32 %255, %252
  %257 = icmp eq i32 %256, 2
  %258 = zext i1 %257 to i8
  store i8 %258, i8* %39, align 1, !tbaa !2450
  %259 = sext i32 %236 to i64
  store i64 %259, i64* %RCX, align 8, !tbaa !2428
  %260 = shl nsw i64 %259, 3
  %261 = add i64 %260, %231
  %262 = add i64 %224, 23
  store i64 %262, i64* %PC, align 8
  %263 = inttoptr i64 %261 to i64*
  store i64 %227, i64* %263, align 8
  %264 = load i64, i64* %RBP, align 8
  %265 = add i64 %264, -56
  %266 = load i64, i64* %PC, align 8
  %267 = add i64 %266, 5
  store i64 %267, i64* %PC, align 8
  %268 = inttoptr i64 %265 to i64*
  %269 = load i64, i64* %268, align 8
  store i64 %269, i64* %400, align 1, !tbaa !2451
  store double 0.000000e+00, double* %402, align 1, !tbaa !2451
  %270 = add i64 %264, -24
  %271 = add i64 %266, 9
  store i64 %271, i64* %PC, align 8
  %272 = inttoptr i64 %270 to i64*
  %273 = load i64, i64* %272, align 8
  store i64 %273, i64* %RAX, align 8, !tbaa !2428
  %274 = add i64 %264, -4
  %275 = add i64 %266, 12
  store i64 %275, i64* %PC, align 8
  %276 = inttoptr i64 %274 to i32*
  %277 = load i32, i32* %276, align 4
  %278 = zext i32 %277 to i64
  store i64 %278, i64* %RDX, align 8, !tbaa !2428
  %279 = add i64 %264, -28
  %280 = add i64 %266, 15
  store i64 %280, i64* %PC, align 8
  %281 = inttoptr i64 %279 to i32*
  %282 = load i32, i32* %281, align 4
  %283 = sub i32 %277, %282
  %284 = zext i32 %283 to i64
  store i64 %284, i64* %RDX, align 8, !tbaa !2428
  %285 = icmp ult i32 %277, %282
  %286 = zext i1 %285 to i8
  store i8 %286, i8* %15, align 1, !tbaa !2432
  %287 = and i32 %283, 255
  %288 = tail call i32 @llvm.ctpop.i32(i32 %287) #11
  %289 = trunc i32 %288 to i8
  %290 = and i8 %289, 1
  %291 = xor i8 %290, 1
  store i8 %291, i8* %22, align 1, !tbaa !2446
  %292 = xor i32 %282, %277
  %293 = xor i32 %292, %283
  %294 = lshr i32 %293, 4
  %295 = trunc i32 %294 to i8
  %296 = and i8 %295, 1
  store i8 %296, i8* %27, align 1, !tbaa !2447
  %297 = icmp eq i32 %283, 0
  %298 = zext i1 %297 to i8
  store i8 %298, i8* %30, align 1, !tbaa !2448
  %299 = lshr i32 %283, 31
  %300 = trunc i32 %299 to i8
  store i8 %300, i8* %33, align 1, !tbaa !2449
  %301 = lshr i32 %277, 31
  %302 = lshr i32 %282, 31
  %303 = xor i32 %302, %301
  %304 = xor i32 %299, %301
  %305 = add nuw nsw i32 %304, %303
  %306 = icmp eq i32 %305, 2
  %307 = zext i1 %306 to i8
  store i8 %307, i8* %39, align 1, !tbaa !2450
  %308 = sext i32 %283 to i64
  store i64 %308, i64* %RCX, align 8, !tbaa !2428
  %309 = shl nsw i64 %308, 3
  %310 = add i64 %309, %273
  %311 = add i64 %266, 23
  store i64 %311, i64* %PC, align 8
  %312 = inttoptr i64 %310 to i64*
  store i64 %269, i64* %312, align 8
  %313 = load i64, i64* %RBP, align 8
  %314 = add i64 %313, -48
  %315 = load i64, i64* %PC, align 8
  %316 = add i64 %315, 5
  store i64 %316, i64* %PC, align 8
  %317 = inttoptr i64 %314 to i64*
  %318 = load i64, i64* %317, align 8
  store i64 %318, i64* %400, align 1, !tbaa !2451
  store double 0.000000e+00, double* %402, align 1, !tbaa !2451
  %319 = add i64 %313, -24
  %320 = add i64 %315, 9
  store i64 %320, i64* %PC, align 8
  %321 = inttoptr i64 %319 to i64*
  %322 = load i64, i64* %321, align 8
  store i64 %322, i64* %RAX, align 8, !tbaa !2428
  %323 = add i64 %313, -4
  %324 = add i64 %315, 12
  store i64 %324, i64* %PC, align 8
  %325 = inttoptr i64 %323 to i32*
  %326 = load i32, i32* %325, align 4
  %327 = zext i32 %326 to i64
  store i64 %327, i64* %RDX, align 8, !tbaa !2428
  %328 = add i64 %313, -28
  %329 = add i64 %315, 15
  store i64 %329, i64* %PC, align 8
  %330 = inttoptr i64 %328 to i32*
  %331 = load i32, i32* %330, align 4
  %332 = sub i32 %326, %331
  %333 = lshr i32 %332, 31
  %334 = add i32 %332, 1
  %335 = zext i32 %334 to i64
  store i64 %335, i64* %RDX, align 8, !tbaa !2428
  %336 = icmp eq i32 %332, -1
  %337 = icmp eq i32 %334, 0
  %338 = or i1 %336, %337
  %339 = zext i1 %338 to i8
  store i8 %339, i8* %15, align 1, !tbaa !2432
  %340 = and i32 %334, 255
  %341 = tail call i32 @llvm.ctpop.i32(i32 %340) #11
  %342 = trunc i32 %341 to i8
  %343 = and i8 %342, 1
  %344 = xor i8 %343, 1
  store i8 %344, i8* %22, align 1, !tbaa !2446
  %345 = xor i32 %334, %332
  %346 = lshr i32 %345, 4
  %347 = trunc i32 %346 to i8
  %348 = and i8 %347, 1
  store i8 %348, i8* %27, align 1, !tbaa !2447
  %349 = zext i1 %337 to i8
  store i8 %349, i8* %30, align 1, !tbaa !2448
  %350 = lshr i32 %334, 31
  %351 = trunc i32 %350 to i8
  store i8 %351, i8* %33, align 1, !tbaa !2449
  %352 = xor i32 %350, %333
  %353 = add nuw nsw i32 %352, %350
  %354 = icmp eq i32 %353, 2
  %355 = zext i1 %354 to i8
  store i8 %355, i8* %39, align 1, !tbaa !2450
  %356 = sext i32 %334 to i64
  store i64 %356, i64* %RCX, align 8, !tbaa !2428
  %357 = shl nsw i64 %356, 3
  %358 = add i64 %357, %322
  %359 = add i64 %315, 26
  store i64 %359, i64* %PC, align 8
  %360 = inttoptr i64 %358 to i64*
  store i64 %318, i64* %360, align 8
  %361 = load i64, i64* %RBP, align 8
  %362 = add i64 %361, -28
  %363 = load i64, i64* %PC, align 8
  %364 = add i64 %363, 3
  store i64 %364, i64* %PC, align 8
  %365 = inttoptr i64 %362 to i32*
  %366 = load i32, i32* %365, align 4
  %367 = add i32 %366, 2
  %368 = zext i32 %367 to i64
  store i64 %368, i64* %RAX, align 8, !tbaa !2428
  %369 = icmp ugt i32 %366, -3
  %370 = zext i1 %369 to i8
  store i8 %370, i8* %15, align 1, !tbaa !2432
  %371 = and i32 %367, 255
  %372 = tail call i32 @llvm.ctpop.i32(i32 %371) #11
  %373 = trunc i32 %372 to i8
  %374 = and i8 %373, 1
  %375 = xor i8 %374, 1
  store i8 %375, i8* %22, align 1, !tbaa !2446
  %376 = xor i32 %367, %366
  %377 = lshr i32 %376, 4
  %378 = trunc i32 %377 to i8
  %379 = and i8 %378, 1
  store i8 %379, i8* %27, align 1, !tbaa !2447
  %380 = icmp eq i32 %367, 0
  %381 = zext i1 %380 to i8
  store i8 %381, i8* %30, align 1, !tbaa !2448
  %382 = lshr i32 %367, 31
  %383 = trunc i32 %382 to i8
  store i8 %383, i8* %33, align 1, !tbaa !2449
  %384 = lshr i32 %366, 31
  %385 = xor i32 %382, %384
  %386 = add nuw nsw i32 %385, %382
  %387 = icmp eq i32 %386, 2
  %388 = zext i1 %387 to i8
  store i8 %388, i8* %39, align 1, !tbaa !2450
  %389 = add i64 %363, 9
  store i64 %389, i64* %PC, align 8
  store i32 %367, i32* %365, align 4
  %390 = load i64, i64* %PC, align 8
  %391 = add i64 %390, -159
  store i64 %391, i64* %PC, align 8, !tbaa !2428
  br label %block_400f1d

block_400fd1:                                     ; preds = %block_400fc1, %block_400e8d
  %392 = phi i64 [ %592, %block_400e8d ], [ %.pre116, %block_400fc1 ]
  %MEMORY.2 = phi %struct.Memory* [ %2, %block_400e8d ], [ %611, %block_400fc1 ]
  %393 = add i64 %392, 5
  store i64 %393, i64* %PC, align 8, !tbaa !2428
  br label %block_400fd6

block_400f16:                                     ; preds = %block_400e8d
  %394 = add i64 %562, -28
  %395 = add i64 %592, 7
  store i64 %395, i64* %PC, align 8
  %396 = inttoptr i64 %394 to i32*
  store i32 2, i32* %396, align 4
  %.pre = load i64, i64* %PC, align 8
  br label %block_400f1d

block_400e8d:                                     ; preds = %block_400e70
  %397 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3
  %398 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 64) to i64*), align 16
  %399 = bitcast [32 x %union.VectorReg]* %4 to double*
  %400 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %398, i64* %400, align 1, !tbaa !2451
  %401 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %402 = bitcast i64* %401 to double*
  store double 0.000000e+00, double* %402, align 1, !tbaa !2451
  %403 = add i64 %86, 11
  store i64 %403, i64* %PC, align 8
  %404 = load i32, i32* %60, align 4
  %405 = zext i32 %404 to i64
  %406 = shl nuw i64 %405, 32
  %407 = ashr i64 %406, 33
  %408 = trunc i32 %404 to i8
  %409 = and i8 %408, 1
  %410 = trunc i64 %407 to i32
  %411 = and i64 %407, 4294967295
  store i64 %411, i64* %RAX, align 8, !tbaa !2428
  store i8 %409, i8* %15, align 1, !tbaa !2453
  %412 = and i32 %410, 255
  %413 = tail call i32 @llvm.ctpop.i32(i32 %412) #11
  %414 = trunc i32 %413 to i8
  %415 = and i8 %414, 1
  %416 = xor i8 %415, 1
  store i8 %416, i8* %22, align 1, !tbaa !2453
  store i8 0, i8* %27, align 1, !tbaa !2453
  %417 = icmp eq i32 %410, 0
  %418 = zext i1 %417 to i8
  store i8 %418, i8* %30, align 1, !tbaa !2453
  %419 = lshr i64 %407, 31
  %420 = trunc i64 %419 to i8
  %421 = and i8 %420, 1
  store i8 %421, i8* %33, align 1, !tbaa !2453
  store i8 0, i8* %39, align 1, !tbaa !2453
  %422 = add i64 %56, -32
  %423 = add i64 %86, 17
  store i64 %423, i64* %PC, align 8
  %424 = inttoptr i64 %422 to i32*
  store i32 %410, i32* %424, align 4
  %425 = load i64, i64* %PC, align 8
  %426 = add i64 %425, -1998
  %427 = add i64 %425, 5
  %428 = load i64, i64* %RSP, align 8, !tbaa !2428
  %429 = add i64 %428, -8
  %430 = inttoptr i64 %429 to i64*
  store i64 %427, i64* %430, align 8
  store i64 %429, i64* %RSP, align 8, !tbaa !2428
  store i64 %426, i64* %PC, align 8, !tbaa !2428
  %431 = load double, double* %399, align 8, !alias.scope !2464, !noalias !2467
  %432 = load i64, i64* %430, align 8
  store i64 %428, i64* %RSP, align 8, !alias.scope !2464, !noalias !2467
  %433 = tail call double @atan(double %431)
  %434 = bitcast i64* %401 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* %434, i8 0, i64 24, i32 8, i1 false)
  store double %433, double* %399, align 8, !alias.scope !2464, !noalias !2467
  %435 = bitcast %union.VectorReg* %5 to i8*
  %436 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %437 = bitcast %union.VectorReg* %5 to i32*
  store i32 0, i32* %437, align 1, !tbaa !2469
  %438 = getelementptr inbounds i8, i8* %435, i64 4
  %439 = bitcast i8* %438 to i32*
  store i32 0, i32* %439, align 1, !tbaa !2469
  %440 = bitcast i64* %436 to i32*
  store i32 0, i32* %440, align 1, !tbaa !2469
  %441 = getelementptr inbounds i8, i8* %435, i64 12
  %442 = bitcast i8* %441 to i32*
  store i32 0, i32* %442, align 1, !tbaa !2469
  %443 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 64) to i64*), align 16
  %444 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 0
  store i64 %443, i64* %444, align 1, !tbaa !2451
  %445 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %446 = bitcast i64* %445 to double*
  store double 0.000000e+00, double* %446, align 1, !tbaa !2451
  %447 = load i64, i64* %RBP, align 8
  %448 = add i64 %447, -32
  %449 = add i64 %432, 16
  store i64 %449, i64* %PC, align 8
  %450 = inttoptr i64 %448 to i32*
  %451 = load i32, i32* %450, align 4
  %452 = sitofp i32 %451 to double
  %453 = bitcast %union.VectorReg* %397 to double*
  store double %452, double* %453, align 1, !tbaa !2451
  %454 = fdiv double %433, %452
  store double %454, double* %399, align 1, !tbaa !2451
  store i64 0, i64* %401, align 1, !tbaa !2451
  %455 = add i64 %447, -40
  %456 = add i64 %432, 25
  store i64 %456, i64* %PC, align 8
  %457 = inttoptr i64 %455 to double*
  store double %454, double* %457, align 8
  %458 = load i64, i64* %RBP, align 8
  %459 = add i64 %458, -24
  %460 = load i64, i64* %PC, align 8
  %461 = add i64 %460, 4
  store i64 %461, i64* %PC, align 8
  %462 = inttoptr i64 %459 to i64*
  %463 = load i64, i64* %462, align 8
  store i64 %463, i64* %RCX, align 8, !tbaa !2428
  %464 = add i64 %460, 8
  store i64 %464, i64* %PC, align 8
  %465 = load i64, i64* %444, align 1
  %466 = inttoptr i64 %463 to i64*
  store i64 %465, i64* %466, align 8
  %467 = load i64, i64* %RBP, align 8
  %468 = add i64 %467, -24
  %469 = load i64, i64* %PC, align 8
  %470 = add i64 %469, 4
  store i64 %470, i64* %PC, align 8
  %471 = inttoptr i64 %468 to i64*
  %472 = load i64, i64* %471, align 8
  store i64 %472, i64* %RCX, align 8, !tbaa !2428
  %473 = add i64 %472, 8
  %474 = add i64 %469, 9
  store i64 %474, i64* %PC, align 8
  %475 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  %476 = load i64, i64* %475, align 1
  %477 = inttoptr i64 %473 to i64*
  store i64 %476, i64* %477, align 8
  %478 = load i64, i64* %RBP, align 8
  %479 = add i64 %478, -40
  %480 = load i64, i64* %PC, align 8
  %481 = add i64 %480, 5
  store i64 %481, i64* %PC, align 8
  %482 = inttoptr i64 %479 to i64*
  %483 = load i64, i64* %482, align 8
  store i64 %483, i64* %400, align 1, !tbaa !2451
  store double 0.000000e+00, double* %402, align 1, !tbaa !2451
  %484 = add i64 %478, -32
  %485 = add i64 %480, 10
  store i64 %485, i64* %PC, align 8
  %486 = inttoptr i64 %484 to i32*
  %487 = load i32, i32* %486, align 4
  %488 = sitofp i32 %487 to double
  %489 = bitcast %union.VectorReg* %5 to double*
  store double %488, double* %489, align 1, !tbaa !2451
  %490 = bitcast i64 %483 to double
  %491 = fmul double %490, %488
  store double %491, double* %399, align 1, !tbaa !2451
  store i64 0, i64* %401, align 1, !tbaa !2451
  %492 = add i64 %480, -1981
  %493 = add i64 %480, 19
  %494 = load i64, i64* %RSP, align 8, !tbaa !2428
  %495 = add i64 %494, -8
  %496 = inttoptr i64 %495 to i64*
  store i64 %493, i64* %496, align 8
  store i64 %495, i64* %RSP, align 8, !tbaa !2428
  store i64 %492, i64* %PC, align 8, !tbaa !2428
  %497 = load double, double* %399, align 8, !alias.scope !2470, !noalias !2473
  %498 = load i64, i64* %496, align 8
  store i64 %494, i64* %RSP, align 8, !alias.scope !2470, !noalias !2473
  %499 = tail call double @cos(double %497)
  tail call void @llvm.memset.p0i8.i64(i8* %434, i8 0, i64 24, i32 8, i1 false)
  store double %499, double* %399, align 8, !alias.scope !2470, !noalias !2473
  %500 = load i64, i64* %RBP, align 8
  %501 = add i64 %500, -24
  %502 = add i64 %498, 4
  store i64 %502, i64* %PC, align 8
  %503 = inttoptr i64 %501 to i64*
  %504 = load i64, i64* %503, align 8
  store i64 %504, i64* %RCX, align 8, !tbaa !2428
  %505 = add i64 %500, -32
  %506 = add i64 %498, 8
  store i64 %506, i64* %PC, align 8
  %507 = inttoptr i64 %505 to i32*
  %508 = load i32, i32* %507, align 4
  %509 = sext i32 %508 to i64
  store i64 %509, i64* %RDX, align 8, !tbaa !2428
  %510 = shl nsw i64 %509, 3
  %511 = add i64 %510, %504
  %512 = add i64 %498, 13
  store i64 %512, i64* %PC, align 8
  %513 = inttoptr i64 %511 to double*
  store double %499, double* %513, align 8
  %514 = load i64, i64* %RBP, align 8
  %515 = add i64 %514, -24
  %516 = load i64, i64* %PC, align 8
  %517 = add i64 %516, 4
  store i64 %517, i64* %PC, align 8
  %518 = inttoptr i64 %515 to i64*
  %519 = load i64, i64* %518, align 8
  store i64 %519, i64* %RCX, align 8, !tbaa !2428
  %520 = add i64 %514, -32
  %521 = add i64 %516, 8
  store i64 %521, i64* %PC, align 8
  %522 = inttoptr i64 %520 to i32*
  %523 = load i32, i32* %522, align 4
  %524 = sext i32 %523 to i64
  store i64 %524, i64* %RDX, align 8, !tbaa !2428
  %525 = shl nsw i64 %524, 3
  %526 = add i64 %525, %519
  %527 = add i64 %516, 13
  store i64 %527, i64* %PC, align 8
  %528 = inttoptr i64 %526 to i64*
  %529 = load i64, i64* %528, align 8
  store i64 %529, i64* %400, align 1, !tbaa !2451
  store double 0.000000e+00, double* %402, align 1, !tbaa !2451
  %530 = add i64 %516, 17
  store i64 %530, i64* %PC, align 8
  %531 = load i64, i64* %518, align 8
  store i64 %531, i64* %RCX, align 8, !tbaa !2428
  %532 = add i64 %516, 20
  store i64 %532, i64* %PC, align 8
  %533 = load i32, i32* %522, align 4
  %534 = add i32 %533, 1
  %535 = zext i32 %534 to i64
  store i64 %535, i64* %RAX, align 8, !tbaa !2428
  %536 = icmp eq i32 %533, -1
  %537 = icmp eq i32 %534, 0
  %538 = or i1 %536, %537
  %539 = zext i1 %538 to i8
  store i8 %539, i8* %15, align 1, !tbaa !2432
  %540 = and i32 %534, 255
  %541 = tail call i32 @llvm.ctpop.i32(i32 %540) #11
  %542 = trunc i32 %541 to i8
  %543 = and i8 %542, 1
  %544 = xor i8 %543, 1
  store i8 %544, i8* %22, align 1, !tbaa !2446
  %545 = xor i32 %534, %533
  %546 = lshr i32 %545, 4
  %547 = trunc i32 %546 to i8
  %548 = and i8 %547, 1
  store i8 %548, i8* %27, align 1, !tbaa !2447
  %549 = zext i1 %537 to i8
  store i8 %549, i8* %30, align 1, !tbaa !2448
  %550 = lshr i32 %534, 31
  %551 = trunc i32 %550 to i8
  store i8 %551, i8* %33, align 1, !tbaa !2449
  %552 = lshr i32 %533, 31
  %553 = xor i32 %550, %552
  %554 = add nuw nsw i32 %553, %550
  %555 = icmp eq i32 %554, 2
  %556 = zext i1 %555 to i8
  store i8 %556, i8* %39, align 1, !tbaa !2450
  %557 = sext i32 %534 to i64
  store i64 %557, i64* %RDX, align 8, !tbaa !2428
  %558 = shl nsw i64 %557, 3
  %559 = add i64 %558, %531
  %560 = add i64 %516, 31
  store i64 %560, i64* %PC, align 8
  %561 = inttoptr i64 %559 to i64*
  store i64 %529, i64* %561, align 8
  %562 = load i64, i64* %RBP, align 8
  %563 = add i64 %562, -32
  %564 = load i64, i64* %PC, align 8
  %565 = add i64 %564, 4
  store i64 %565, i64* %PC, align 8
  %566 = inttoptr i64 %563 to i32*
  %567 = load i32, i32* %566, align 4
  %568 = add i32 %567, -2
  %569 = icmp ult i32 %567, 2
  %570 = zext i1 %569 to i8
  store i8 %570, i8* %15, align 1, !tbaa !2432
  %571 = and i32 %568, 255
  %572 = tail call i32 @llvm.ctpop.i32(i32 %571) #11
  %573 = trunc i32 %572 to i8
  %574 = and i8 %573, 1
  %575 = xor i8 %574, 1
  store i8 %575, i8* %22, align 1, !tbaa !2446
  %576 = xor i32 %568, %567
  %577 = lshr i32 %576, 4
  %578 = trunc i32 %577 to i8
  %579 = and i8 %578, 1
  store i8 %579, i8* %27, align 1, !tbaa !2447
  %580 = icmp eq i32 %568, 0
  %581 = zext i1 %580 to i8
  store i8 %581, i8* %30, align 1, !tbaa !2448
  %582 = lshr i32 %568, 31
  %583 = trunc i32 %582 to i8
  store i8 %583, i8* %33, align 1, !tbaa !2449
  %584 = lshr i32 %567, 31
  %585 = xor i32 %582, %584
  %586 = add nuw nsw i32 %585, %584
  %587 = icmp eq i32 %586, 2
  %588 = zext i1 %587 to i8
  store i8 %588, i8* %39, align 1, !tbaa !2450
  %589 = icmp ne i8 %583, 0
  %590 = xor i1 %589, %587
  %591 = or i1 %580, %590
  %.v117 = select i1 %591, i64 197, i64 10
  %592 = add i64 %.v117, %564
  store i64 %592, i64* %PC, align 8, !tbaa !2428
  br i1 %591, label %block_400fd1, label %block_400f16

block_400fc1:                                     ; preds = %block_400f1d
  %593 = add i64 %88, -4
  %594 = add i64 %124, 3
  store i64 %594, i64* %PC, align 8
  %595 = inttoptr i64 %593 to i32*
  %596 = load i32, i32* %595, align 4
  %597 = zext i32 %596 to i64
  store i64 %597, i64* %RDI, align 8, !tbaa !2428
  %598 = add i64 %88, -16
  %599 = add i64 %124, 7
  store i64 %599, i64* %PC, align 8
  %600 = inttoptr i64 %598 to i64*
  %601 = load i64, i64* %600, align 8
  store i64 %601, i64* %RSI, align 8, !tbaa !2428
  %602 = add i64 %88, -24
  %603 = add i64 %124, 11
  store i64 %603, i64* %PC, align 8
  %604 = inttoptr i64 %602 to i64*
  %605 = load i64, i64* %604, align 8
  store i64 %605, i64* %RDX, align 8, !tbaa !2428
  %606 = add i64 %124, 559
  %607 = add i64 %124, 16
  %608 = load i64, i64* %RSP, align 8, !tbaa !2428
  %609 = add i64 %608, -8
  %610 = inttoptr i64 %609 to i64*
  store i64 %607, i64* %610, align 8
  store i64 %609, i64* %RSP, align 8, !tbaa !2428
  store i64 %606, i64* %PC, align 8, !tbaa !2428
  %611 = tail call %struct.Memory* @sub_4011f0_bitrv2_renamed_(%struct.State* nonnull %0, i64 %606, %struct.Memory* %2)
  %.pre116 = load i64, i64* %PC, align 8
  br label %block_400fd1
}

; Function Attrs: noinline
define %struct.Memory* @sub_4024b0_cftbsub(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone) local_unnamed_addr #8 {
block_4024b0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -120
  store i64 %11, i64* %RSP, align 8, !tbaa !2428
  %12 = icmp ult i64 %8, 112
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1, !tbaa !2432
  %15 = trunc i64 %11 to i32
  %16 = and i32 %15, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16) #11
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1, !tbaa !2446
  %22 = xor i64 %8, 16
  %23 = xor i64 %22, %11
  %24 = lshr i64 %23, 4
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1, !tbaa !2447
  %28 = icmp eq i64 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1, !tbaa !2448
  %31 = lshr i64 %11, 63
  %32 = trunc i64 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1, !tbaa !2449
  %34 = lshr i64 %8, 63
  %35 = xor i64 %31, %34
  %36 = add nuw nsw i64 %35, %34
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1, !tbaa !2450
  %40 = add i64 %7, -12
  %41 = load i32, i32* %EDI, align 4
  %42 = add i64 %10, 10
  store i64 %42, i64* %PC, align 8
  %43 = inttoptr i64 %40 to i32*
  store i32 %41, i32* %43, align 4
  %44 = load i64, i64* %RBP, align 8
  %45 = add i64 %44, -16
  %46 = load i64, i64* %RSI, align 8
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 4
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %45 to i64*
  store i64 %46, i64* %49, align 8
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -24
  %52 = load i64, i64* %RDX, align 8
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 4
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %51 to i64*
  store i64 %52, i64* %55, align 8
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -44
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 7
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %57 to i32*
  store i32 2, i32* %60, align 4
  %61 = load i64, i64* %RBP, align 8
  %62 = add i64 %61, -4
  %63 = load i64, i64* %PC, align 8
  %64 = add i64 %63, 4
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %62 to i32*
  %66 = load i32, i32* %65, align 4
  %67 = add i32 %66, -8
  %68 = icmp ult i32 %66, 8
  %69 = zext i1 %68 to i8
  store i8 %69, i8* %14, align 1, !tbaa !2432
  %70 = and i32 %67, 255
  %71 = tail call i32 @llvm.ctpop.i32(i32 %70) #11
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  %74 = xor i8 %73, 1
  store i8 %74, i8* %21, align 1, !tbaa !2446
  %75 = xor i32 %67, %66
  %76 = lshr i32 %75, 4
  %77 = trunc i32 %76 to i8
  %78 = and i8 %77, 1
  store i8 %78, i8* %27, align 1, !tbaa !2447
  %79 = icmp eq i32 %67, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %30, align 1, !tbaa !2448
  %81 = lshr i32 %67, 31
  %82 = trunc i32 %81 to i8
  store i8 %82, i8* %33, align 1, !tbaa !2449
  %83 = lshr i32 %66, 31
  %84 = xor i32 %81, %83
  %85 = add nuw nsw i32 %84, %83
  %86 = icmp eq i32 %85, 2
  %87 = zext i1 %86 to i8
  store i8 %87, i8* %39, align 1, !tbaa !2450
  %88 = icmp ne i8 %82, 0
  %89 = xor i1 %88, %86
  %90 = or i1 %79, %89
  %.v14 = select i1 %90, i64 86, i64 10
  %91 = add i64 %.v14, %63
  store i64 %91, i64* %PC, align 8, !tbaa !2428
  br i1 %90, label %block_402520, label %block_4024d4

block_40277b:                                     ; preds = %block_402536
  %92 = add i64 %162, 286
  br label %block_402899

block_402899:                                     ; preds = %block_402894, %block_40277b
  %.sink = phi i64 [ %728, %block_402894 ], [ %92, %block_40277b ]
  %93 = load i64, i64* %RSP, align 8
  %94 = add i64 %93, 112
  store i64 %94, i64* %RSP, align 8, !tbaa !2428
  %95 = icmp ugt i64 %93, -113
  %96 = zext i1 %95 to i8
  store i8 %96, i8* %14, align 1, !tbaa !2432
  %97 = trunc i64 %94 to i32
  %98 = and i32 %97, 255
  %99 = tail call i32 @llvm.ctpop.i32(i32 %98) #11
  %100 = trunc i32 %99 to i8
  %101 = and i8 %100, 1
  %102 = xor i8 %101, 1
  store i8 %102, i8* %21, align 1, !tbaa !2446
  %103 = xor i64 %93, 16
  %104 = xor i64 %103, %94
  %105 = lshr i64 %104, 4
  %106 = trunc i64 %105 to i8
  %107 = and i8 %106, 1
  store i8 %107, i8* %27, align 1, !tbaa !2447
  %108 = icmp eq i64 %94, 0
  %109 = zext i1 %108 to i8
  store i8 %109, i8* %30, align 1, !tbaa !2448
  %110 = lshr i64 %94, 63
  %111 = trunc i64 %110 to i8
  store i8 %111, i8* %33, align 1, !tbaa !2449
  %112 = lshr i64 %93, 63
  %113 = xor i64 %110, %112
  %114 = add nuw nsw i64 %113, %110
  %115 = icmp eq i64 %114, 2
  %116 = zext i1 %115 to i8
  store i8 %116, i8* %39, align 1, !tbaa !2450
  %117 = add i64 %.sink, 5
  store i64 %117, i64* %PC, align 8
  %118 = add i64 %93, 120
  %119 = inttoptr i64 %94 to i64*
  %120 = load i64, i64* %119, align 8
  store i64 %120, i64* %RBP, align 8, !tbaa !2428
  store i64 %118, i64* %RSP, align 8, !tbaa !2428
  %121 = add i64 %.sink, 6
  store i64 %121, i64* %PC, align 8
  %122 = inttoptr i64 %118 to i64*
  %123 = load i64, i64* %122, align 8
  store i64 %123, i64* %PC, align 8, !tbaa !2428
  %124 = add i64 %93, 128
  store i64 %124, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.4

block_402536:                                     ; preds = %block_402536.preheader, %block_402542
  %125 = phi i64 [ %1644, %block_402542 ], [ %.pre12, %block_402536.preheader ]
  %126 = load i64, i64* %RBP, align 8
  %127 = add i64 %126, -28
  %128 = add i64 %125, 3
  store i64 %128, i64* %PC, align 8
  %129 = inttoptr i64 %127 to i32*
  %130 = load i32, i32* %129, align 4
  %131 = zext i32 %130 to i64
  store i64 %131, i64* %RAX, align 8, !tbaa !2428
  %132 = add i64 %126, -44
  %133 = add i64 %125, 6
  store i64 %133, i64* %PC, align 8
  %134 = inttoptr i64 %132 to i32*
  %135 = load i32, i32* %134, align 4
  %136 = sub i32 %130, %135
  %137 = icmp ult i32 %130, %135
  %138 = zext i1 %137 to i8
  store i8 %138, i8* %14, align 1, !tbaa !2432
  %139 = and i32 %136, 255
  %140 = tail call i32 @llvm.ctpop.i32(i32 %139) #11
  %141 = trunc i32 %140 to i8
  %142 = and i8 %141, 1
  %143 = xor i8 %142, 1
  store i8 %143, i8* %21, align 1, !tbaa !2446
  %144 = xor i32 %135, %130
  %145 = xor i32 %144, %136
  %146 = lshr i32 %145, 4
  %147 = trunc i32 %146 to i8
  %148 = and i8 %147, 1
  store i8 %148, i8* %27, align 1, !tbaa !2447
  %149 = icmp eq i32 %136, 0
  %150 = zext i1 %149 to i8
  store i8 %150, i8* %30, align 1, !tbaa !2448
  %151 = lshr i32 %136, 31
  %152 = trunc i32 %151 to i8
  store i8 %152, i8* %33, align 1, !tbaa !2449
  %153 = lshr i32 %130, 31
  %154 = lshr i32 %135, 31
  %155 = xor i32 %154, %153
  %156 = xor i32 %151, %153
  %157 = add nuw nsw i32 %156, %155
  %158 = icmp eq i32 %157, 2
  %159 = zext i1 %158 to i8
  store i8 %159, i8* %39, align 1, !tbaa !2450
  %160 = icmp ne i8 %152, 0
  %161 = xor i1 %160, %158
  %.v17 = select i1 %161, i64 12, i64 581
  %162 = add i64 %.v17, %125
  store i64 %162, i64* %PC, align 8, !tbaa !2428
  br i1 %161, label %block_402542, label %block_40277b

block_4024d4:                                     ; preds = %block_4024b0
  %163 = add i64 %91, 3
  store i64 %163, i64* %PC, align 8
  %164 = load i32, i32* %65, align 4
  %165 = zext i32 %164 to i64
  store i64 %165, i64* %RDI, align 8, !tbaa !2428
  %166 = add i64 %61, -16
  %167 = add i64 %91, 7
  store i64 %167, i64* %PC, align 8
  %168 = inttoptr i64 %166 to i64*
  %169 = load i64, i64* %168, align 8
  store i64 %169, i64* %RSI, align 8, !tbaa !2428
  %170 = add i64 %61, -24
  %171 = add i64 %91, 11
  store i64 %171, i64* %PC, align 8
  %172 = inttoptr i64 %170 to i64*
  %173 = load i64, i64* %172, align 8
  store i64 %173, i64* %RDX, align 8, !tbaa !2428
  %174 = add i64 %91, 972
  %175 = add i64 %91, 16
  %176 = load i64, i64* %RSP, align 8, !tbaa !2428
  %177 = add i64 %176, -8
  %178 = inttoptr i64 %177 to i64*
  store i64 %175, i64* %178, align 8
  store i64 %177, i64* %RSP, align 8, !tbaa !2428
  store i64 %174, i64* %PC, align 8, !tbaa !2428
  %179 = tail call %struct.Memory* @sub_4028a0_cft1st_renamed_(%struct.State* nonnull %0, i64 %174, %struct.Memory* %2)
  %180 = load i64, i64* %RBP, align 8
  %181 = add i64 %180, -44
  %182 = load i64, i64* %PC, align 8
  %183 = add i64 %182, 7
  store i64 %183, i64* %PC, align 8
  %184 = inttoptr i64 %181 to i32*
  store i32 8, i32* %184, align 4
  %.pre = load i64, i64* %PC, align 8
  br label %block_4024eb

block_402793:                                     ; preds = %block_402787
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %185 = add i64 %682, 13
  store i64 %185, i64* %PC, align 8
  %186 = load i32, i32* %649, align 4
  %187 = zext i32 %186 to i64
  store i64 %187, i64* %RCX, align 8, !tbaa !2428
  %188 = add i64 %682, 16
  store i64 %188, i64* %PC, align 8
  %189 = load i32, i32* %654, align 4
  %190 = add i32 %189, %186
  %191 = zext i32 %190 to i64
  store i64 %191, i64* %RCX, align 8, !tbaa !2428
  %192 = icmp ult i32 %190, %186
  %193 = icmp ult i32 %190, %189
  %194 = or i1 %192, %193
  %195 = zext i1 %194 to i8
  store i8 %195, i8* %14, align 1, !tbaa !2432
  %196 = and i32 %190, 255
  %197 = tail call i32 @llvm.ctpop.i32(i32 %196) #11
  %198 = trunc i32 %197 to i8
  %199 = and i8 %198, 1
  %200 = xor i8 %199, 1
  store i8 %200, i8* %21, align 1, !tbaa !2446
  %201 = xor i32 %189, %186
  %202 = xor i32 %201, %190
  %203 = lshr i32 %202, 4
  %204 = trunc i32 %203 to i8
  %205 = and i8 %204, 1
  store i8 %205, i8* %27, align 1, !tbaa !2447
  %206 = icmp eq i32 %190, 0
  %207 = zext i1 %206 to i8
  store i8 %207, i8* %30, align 1, !tbaa !2448
  %208 = lshr i32 %190, 31
  %209 = trunc i32 %208 to i8
  store i8 %209, i8* %33, align 1, !tbaa !2449
  %210 = lshr i32 %186, 31
  %211 = lshr i32 %189, 31
  %212 = xor i32 %208, %210
  %213 = xor i32 %208, %211
  %214 = add nuw nsw i32 %212, %213
  %215 = icmp eq i32 %214, 2
  %216 = zext i1 %215 to i8
  store i8 %216, i8* %39, align 1, !tbaa !2450
  %217 = add i64 %646, -32
  %218 = add i64 %682, 19
  store i64 %218, i64* %PC, align 8
  %219 = inttoptr i64 %217 to i32*
  store i32 %190, i32* %219, align 4
  %220 = load i64, i64* %RBP, align 8
  %221 = add i64 %220, -16
  %222 = load i64, i64* %PC, align 8
  %223 = add i64 %222, 4
  store i64 %223, i64* %PC, align 8
  %224 = inttoptr i64 %221 to i64*
  %225 = load i64, i64* %224, align 8
  store i64 %225, i64* %RDX, align 8, !tbaa !2428
  %226 = add i64 %220, -28
  %227 = add i64 %222, 8
  store i64 %227, i64* %PC, align 8
  %228 = inttoptr i64 %226 to i32*
  %229 = load i32, i32* %228, align 4
  %230 = sext i32 %229 to i64
  store i64 %230, i64* %RSI, align 8, !tbaa !2428
  %231 = shl nsw i64 %230, 3
  %232 = add i64 %231, %225
  %233 = add i64 %222, 13
  store i64 %233, i64* %PC, align 8
  %234 = inttoptr i64 %232 to i64*
  %235 = load i64, i64* %234, align 8
  store i64 %235, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %236 = add i64 %222, 17
  store i64 %236, i64* %PC, align 8
  %237 = load i64, i64* %224, align 8
  store i64 %237, i64* %RDX, align 8, !tbaa !2428
  %238 = add i64 %220, -32
  %239 = add i64 %222, 21
  store i64 %239, i64* %PC, align 8
  %240 = inttoptr i64 %238 to i32*
  %241 = load i32, i32* %240, align 4
  %242 = sext i32 %241 to i64
  store i64 %242, i64* %RSI, align 8, !tbaa !2428
  %243 = shl nsw i64 %242, 3
  %244 = add i64 %243, %237
  %245 = add i64 %222, 26
  store i64 %245, i64* %PC, align 8
  %246 = bitcast i64 %235 to double
  %247 = inttoptr i64 %244 to double*
  %248 = load double, double* %247, align 8
  %249 = fsub double %246, %248
  store double %249, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %250 = add i64 %220, -56
  %251 = add i64 %222, 31
  store i64 %251, i64* %PC, align 8
  %252 = inttoptr i64 %250 to double*
  store double %249, double* %252, align 8
  %253 = load i64, i64* %RBP, align 8
  %254 = add i64 %253, -16
  %255 = load i64, i64* %PC, align 8
  %256 = add i64 %255, 4
  store i64 %256, i64* %PC, align 8
  %257 = inttoptr i64 %254 to i64*
  %258 = load i64, i64* %257, align 8
  store i64 %258, i64* %RDX, align 8, !tbaa !2428
  %259 = add i64 %253, -28
  %260 = add i64 %255, 7
  store i64 %260, i64* %PC, align 8
  %261 = inttoptr i64 %259 to i32*
  %262 = load i32, i32* %261, align 4
  %263 = add i32 %262, 1
  %264 = zext i32 %263 to i64
  store i64 %264, i64* %RCX, align 8, !tbaa !2428
  %265 = icmp eq i32 %262, -1
  %266 = icmp eq i32 %263, 0
  %267 = or i1 %265, %266
  %268 = zext i1 %267 to i8
  store i8 %268, i8* %14, align 1, !tbaa !2432
  %269 = and i32 %263, 255
  %270 = tail call i32 @llvm.ctpop.i32(i32 %269) #11
  %271 = trunc i32 %270 to i8
  %272 = and i8 %271, 1
  %273 = xor i8 %272, 1
  store i8 %273, i8* %21, align 1, !tbaa !2446
  %274 = xor i32 %263, %262
  %275 = lshr i32 %274, 4
  %276 = trunc i32 %275 to i8
  %277 = and i8 %276, 1
  store i8 %277, i8* %27, align 1, !tbaa !2447
  %278 = zext i1 %266 to i8
  store i8 %278, i8* %30, align 1, !tbaa !2448
  %279 = lshr i32 %263, 31
  %280 = trunc i32 %279 to i8
  store i8 %280, i8* %33, align 1, !tbaa !2449
  %281 = lshr i32 %262, 31
  %282 = xor i32 %279, %281
  %283 = add nuw nsw i32 %282, %279
  %284 = icmp eq i32 %283, 2
  %285 = zext i1 %284 to i8
  store i8 %285, i8* %39, align 1, !tbaa !2450
  %286 = sext i32 %263 to i64
  store i64 %286, i64* %RSI, align 8, !tbaa !2428
  %287 = shl nsw i64 %286, 3
  %288 = add i64 %287, %258
  %289 = add i64 %255, 18
  store i64 %289, i64* %PC, align 8
  %290 = inttoptr i64 %288 to i64*
  %291 = load i64, i64* %290, align 8
  %292 = load i64, i64* %RAX, align 8
  %293 = xor i64 %292, %291
  store i64 %293, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2432
  %294 = trunc i64 %293 to i32
  %295 = and i32 %294, 255
  %296 = tail call i32 @llvm.ctpop.i32(i32 %295) #11
  %297 = trunc i32 %296 to i8
  %298 = and i8 %297, 1
  %299 = xor i8 %298, 1
  store i8 %299, i8* %21, align 1, !tbaa !2446
  %300 = icmp eq i64 %293, 0
  %301 = zext i1 %300 to i8
  store i8 %301, i8* %30, align 1, !tbaa !2448
  %302 = lshr i64 %293, 63
  %303 = trunc i64 %302 to i8
  store i8 %303, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2447
  store i64 %293, i64* %1699, align 1, !tbaa !2428
  store i64 0, i64* %1700, align 1, !tbaa !2428
  %304 = add i64 %255, 35
  store i64 %304, i64* %PC, align 8
  %305 = load i64, i64* %257, align 8
  store i64 %305, i64* %RDX, align 8, !tbaa !2428
  %306 = add i64 %253, -32
  %307 = add i64 %255, 38
  store i64 %307, i64* %PC, align 8
  %308 = inttoptr i64 %306 to i32*
  %309 = load i32, i32* %308, align 4
  %310 = add i32 %309, 1
  %311 = zext i32 %310 to i64
  store i64 %311, i64* %RCX, align 8, !tbaa !2428
  %312 = icmp eq i32 %309, -1
  %313 = icmp eq i32 %310, 0
  %314 = or i1 %312, %313
  %315 = zext i1 %314 to i8
  store i8 %315, i8* %14, align 1, !tbaa !2432
  %316 = and i32 %310, 255
  %317 = tail call i32 @llvm.ctpop.i32(i32 %316) #11
  %318 = trunc i32 %317 to i8
  %319 = and i8 %318, 1
  %320 = xor i8 %319, 1
  store i8 %320, i8* %21, align 1, !tbaa !2446
  %321 = xor i32 %310, %309
  %322 = lshr i32 %321, 4
  %323 = trunc i32 %322 to i8
  %324 = and i8 %323, 1
  store i8 %324, i8* %27, align 1, !tbaa !2447
  %325 = zext i1 %313 to i8
  store i8 %325, i8* %30, align 1, !tbaa !2448
  %326 = lshr i32 %310, 31
  %327 = trunc i32 %326 to i8
  store i8 %327, i8* %33, align 1, !tbaa !2449
  %328 = lshr i32 %309, 31
  %329 = xor i32 %326, %328
  %330 = add nuw nsw i32 %329, %326
  %331 = icmp eq i32 %330, 2
  %332 = zext i1 %331 to i8
  store i8 %332, i8* %39, align 1, !tbaa !2450
  %333 = sext i32 %310 to i64
  store i64 %333, i64* %RSI, align 8, !tbaa !2428
  %334 = shl nsw i64 %333, 3
  %335 = add i64 %334, %305
  %336 = add i64 %255, 49
  store i64 %336, i64* %PC, align 8
  %337 = bitcast i64 %293 to double
  %338 = inttoptr i64 %335 to double*
  %339 = load double, double* %338, align 8
  %340 = fadd double %337, %339
  store double %340, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %341 = load i64, i64* %RBP, align 8
  %342 = add i64 %341, -64
  %343 = add i64 %255, 54
  store i64 %343, i64* %PC, align 8
  %344 = inttoptr i64 %342 to double*
  store double %340, double* %344, align 8
  %345 = load i64, i64* %RBP, align 8
  %346 = add i64 %345, -16
  %347 = load i64, i64* %PC, align 8
  %348 = add i64 %347, 4
  store i64 %348, i64* %PC, align 8
  %349 = inttoptr i64 %346 to i64*
  %350 = load i64, i64* %349, align 8
  store i64 %350, i64* %RDX, align 8, !tbaa !2428
  %351 = add i64 %345, -32
  %352 = add i64 %347, 8
  store i64 %352, i64* %PC, align 8
  %353 = inttoptr i64 %351 to i32*
  %354 = load i32, i32* %353, align 4
  %355 = sext i32 %354 to i64
  store i64 %355, i64* %RSI, align 8, !tbaa !2428
  %356 = shl nsw i64 %355, 3
  %357 = add i64 %356, %350
  %358 = add i64 %347, 13
  store i64 %358, i64* %PC, align 8
  %359 = inttoptr i64 %357 to i64*
  %360 = load i64, i64* %359, align 8
  store i64 %360, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %361 = add i64 %347, 17
  store i64 %361, i64* %PC, align 8
  %362 = load i64, i64* %349, align 8
  store i64 %362, i64* %RDX, align 8, !tbaa !2428
  %363 = add i64 %345, -28
  %364 = add i64 %347, 21
  store i64 %364, i64* %PC, align 8
  %365 = inttoptr i64 %363 to i32*
  %366 = load i32, i32* %365, align 4
  %367 = sext i32 %366 to i64
  store i64 %367, i64* %RSI, align 8, !tbaa !2428
  %368 = shl nsw i64 %367, 3
  %369 = add i64 %368, %362
  %370 = add i64 %347, 26
  store i64 %370, i64* %PC, align 8
  %371 = bitcast i64 %360 to double
  %372 = inttoptr i64 %369 to double*
  %373 = load double, double* %372, align 8
  %374 = fadd double %371, %373
  store double %374, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %375 = add i64 %347, 31
  store i64 %375, i64* %PC, align 8
  store double %374, double* %372, align 8
  %376 = load i64, i64* %RBP, align 8
  %377 = add i64 %376, -16
  %378 = load i64, i64* %PC, align 8
  %379 = add i64 %378, 4
  store i64 %379, i64* %PC, align 8
  %380 = inttoptr i64 %377 to i64*
  %381 = load i64, i64* %380, align 8
  store i64 %381, i64* %RDX, align 8, !tbaa !2428
  %382 = add i64 %376, -28
  %383 = add i64 %378, 7
  store i64 %383, i64* %PC, align 8
  %384 = inttoptr i64 %382 to i32*
  %385 = load i32, i32* %384, align 4
  %386 = add i32 %385, 1
  %387 = zext i32 %386 to i64
  store i64 %387, i64* %RCX, align 8, !tbaa !2428
  %388 = icmp eq i32 %385, -1
  %389 = icmp eq i32 %386, 0
  %390 = or i1 %388, %389
  %391 = zext i1 %390 to i8
  store i8 %391, i8* %14, align 1, !tbaa !2432
  %392 = and i32 %386, 255
  %393 = tail call i32 @llvm.ctpop.i32(i32 %392) #11
  %394 = trunc i32 %393 to i8
  %395 = and i8 %394, 1
  %396 = xor i8 %395, 1
  store i8 %396, i8* %21, align 1, !tbaa !2446
  %397 = xor i32 %386, %385
  %398 = lshr i32 %397, 4
  %399 = trunc i32 %398 to i8
  %400 = and i8 %399, 1
  store i8 %400, i8* %27, align 1, !tbaa !2447
  %401 = zext i1 %389 to i8
  store i8 %401, i8* %30, align 1, !tbaa !2448
  %402 = lshr i32 %386, 31
  %403 = trunc i32 %402 to i8
  store i8 %403, i8* %33, align 1, !tbaa !2449
  %404 = lshr i32 %385, 31
  %405 = xor i32 %402, %404
  %406 = add nuw nsw i32 %405, %402
  %407 = icmp eq i32 %406, 2
  %408 = zext i1 %407 to i8
  store i8 %408, i8* %39, align 1, !tbaa !2450
  %409 = sext i32 %386 to i64
  store i64 %409, i64* %RSI, align 8, !tbaa !2428
  %410 = shl nsw i64 %409, 3
  %411 = add i64 %410, %381
  %412 = add i64 %378, 18
  store i64 %412, i64* %PC, align 8
  %413 = inttoptr i64 %411 to i64*
  %414 = load i64, i64* %413, align 8
  %415 = load i64, i64* %RAX, align 8
  %416 = xor i64 %415, %414
  store i64 %416, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2432
  %417 = trunc i64 %416 to i32
  %418 = and i32 %417, 255
  %419 = tail call i32 @llvm.ctpop.i32(i32 %418) #11
  %420 = trunc i32 %419 to i8
  %421 = and i8 %420, 1
  %422 = xor i8 %421, 1
  store i8 %422, i8* %21, align 1, !tbaa !2446
  %423 = icmp eq i64 %416, 0
  %424 = zext i1 %423 to i8
  store i8 %424, i8* %30, align 1, !tbaa !2448
  %425 = lshr i64 %416, 63
  %426 = trunc i64 %425 to i8
  store i8 %426, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2447
  store i64 %416, i64* %1699, align 1, !tbaa !2428
  store i64 0, i64* %1700, align 1, !tbaa !2428
  %427 = add i64 %378, 35
  store i64 %427, i64* %PC, align 8
  %428 = load i64, i64* %380, align 8
  store i64 %428, i64* %RAX, align 8, !tbaa !2428
  %429 = add i64 %376, -32
  %430 = add i64 %378, 38
  store i64 %430, i64* %PC, align 8
  %431 = inttoptr i64 %429 to i32*
  %432 = load i32, i32* %431, align 4
  %433 = add i32 %432, 1
  %434 = zext i32 %433 to i64
  store i64 %434, i64* %RCX, align 8, !tbaa !2428
  %435 = icmp eq i32 %432, -1
  %436 = icmp eq i32 %433, 0
  %437 = or i1 %435, %436
  %438 = zext i1 %437 to i8
  store i8 %438, i8* %14, align 1, !tbaa !2432
  %439 = and i32 %433, 255
  %440 = tail call i32 @llvm.ctpop.i32(i32 %439) #11
  %441 = trunc i32 %440 to i8
  %442 = and i8 %441, 1
  %443 = xor i8 %442, 1
  store i8 %443, i8* %21, align 1, !tbaa !2446
  %444 = xor i32 %433, %432
  %445 = lshr i32 %444, 4
  %446 = trunc i32 %445 to i8
  %447 = and i8 %446, 1
  store i8 %447, i8* %27, align 1, !tbaa !2447
  %448 = zext i1 %436 to i8
  store i8 %448, i8* %30, align 1, !tbaa !2448
  %449 = lshr i32 %433, 31
  %450 = trunc i32 %449 to i8
  store i8 %450, i8* %33, align 1, !tbaa !2449
  %451 = lshr i32 %432, 31
  %452 = xor i32 %449, %451
  %453 = add nuw nsw i32 %452, %449
  %454 = icmp eq i32 %453, 2
  %455 = zext i1 %454 to i8
  store i8 %455, i8* %39, align 1, !tbaa !2450
  %456 = sext i32 %433 to i64
  store i64 %456, i64* %RDX, align 8, !tbaa !2428
  %457 = shl nsw i64 %456, 3
  %458 = add i64 %457, %428
  %459 = add i64 %378, 49
  store i64 %459, i64* %PC, align 8
  %460 = bitcast i64 %416 to double
  %461 = inttoptr i64 %458 to double*
  %462 = load double, double* %461, align 8
  %463 = fsub double %460, %462
  store double %463, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %464 = load i64, i64* %RBP, align 8
  %465 = add i64 %464, -16
  %466 = add i64 %378, 53
  store i64 %466, i64* %PC, align 8
  %467 = inttoptr i64 %465 to i64*
  %468 = load i64, i64* %467, align 8
  store i64 %468, i64* %RAX, align 8, !tbaa !2428
  %469 = add i64 %464, -28
  %470 = add i64 %378, 56
  store i64 %470, i64* %PC, align 8
  %471 = inttoptr i64 %469 to i32*
  %472 = load i32, i32* %471, align 4
  %473 = add i32 %472, 1
  %474 = zext i32 %473 to i64
  store i64 %474, i64* %RCX, align 8, !tbaa !2428
  %475 = icmp eq i32 %472, -1
  %476 = icmp eq i32 %473, 0
  %477 = or i1 %475, %476
  %478 = zext i1 %477 to i8
  store i8 %478, i8* %14, align 1, !tbaa !2432
  %479 = and i32 %473, 255
  %480 = tail call i32 @llvm.ctpop.i32(i32 %479) #11
  %481 = trunc i32 %480 to i8
  %482 = and i8 %481, 1
  %483 = xor i8 %482, 1
  store i8 %483, i8* %21, align 1, !tbaa !2446
  %484 = xor i32 %473, %472
  %485 = lshr i32 %484, 4
  %486 = trunc i32 %485 to i8
  %487 = and i8 %486, 1
  store i8 %487, i8* %27, align 1, !tbaa !2447
  %488 = zext i1 %476 to i8
  store i8 %488, i8* %30, align 1, !tbaa !2448
  %489 = lshr i32 %473, 31
  %490 = trunc i32 %489 to i8
  store i8 %490, i8* %33, align 1, !tbaa !2449
  %491 = lshr i32 %472, 31
  %492 = xor i32 %489, %491
  %493 = add nuw nsw i32 %492, %489
  %494 = icmp eq i32 %493, 2
  %495 = zext i1 %494 to i8
  store i8 %495, i8* %39, align 1, !tbaa !2450
  %496 = sext i32 %473 to i64
  store i64 %496, i64* %RDX, align 8, !tbaa !2428
  %497 = shl nsw i64 %496, 3
  %498 = add i64 %497, %468
  %499 = add i64 %378, 67
  store i64 %499, i64* %PC, align 8
  %500 = inttoptr i64 %498 to double*
  store double %463, double* %500, align 8
  %501 = load i64, i64* %RBP, align 8
  %502 = add i64 %501, -56
  %503 = load i64, i64* %PC, align 8
  %504 = add i64 %503, 5
  store i64 %504, i64* %PC, align 8
  %505 = inttoptr i64 %502 to i64*
  %506 = load i64, i64* %505, align 8
  store i64 %506, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %507 = add i64 %501, -16
  %508 = add i64 %503, 9
  store i64 %508, i64* %PC, align 8
  %509 = inttoptr i64 %507 to i64*
  %510 = load i64, i64* %509, align 8
  store i64 %510, i64* %RAX, align 8, !tbaa !2428
  %511 = add i64 %501, -32
  %512 = add i64 %503, 13
  store i64 %512, i64* %PC, align 8
  %513 = inttoptr i64 %511 to i32*
  %514 = load i32, i32* %513, align 4
  %515 = sext i32 %514 to i64
  store i64 %515, i64* %RDX, align 8, !tbaa !2428
  %516 = shl nsw i64 %515, 3
  %517 = add i64 %516, %510
  %518 = add i64 %503, 18
  store i64 %518, i64* %PC, align 8
  %519 = inttoptr i64 %517 to i64*
  store i64 %506, i64* %519, align 8
  %520 = load i64, i64* %RBP, align 8
  %521 = add i64 %520, -64
  %522 = load i64, i64* %PC, align 8
  %523 = add i64 %522, 5
  store i64 %523, i64* %PC, align 8
  %524 = inttoptr i64 %521 to i64*
  %525 = load i64, i64* %524, align 8
  store i64 %525, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %526 = add i64 %520, -16
  %527 = add i64 %522, 9
  store i64 %527, i64* %PC, align 8
  %528 = inttoptr i64 %526 to i64*
  %529 = load i64, i64* %528, align 8
  store i64 %529, i64* %RAX, align 8, !tbaa !2428
  %530 = add i64 %520, -32
  %531 = add i64 %522, 12
  store i64 %531, i64* %PC, align 8
  %532 = inttoptr i64 %530 to i32*
  %533 = load i32, i32* %532, align 4
  %534 = add i32 %533, 1
  %535 = zext i32 %534 to i64
  store i64 %535, i64* %RCX, align 8, !tbaa !2428
  %536 = icmp eq i32 %533, -1
  %537 = icmp eq i32 %534, 0
  %538 = or i1 %536, %537
  %539 = zext i1 %538 to i8
  store i8 %539, i8* %14, align 1, !tbaa !2432
  %540 = and i32 %534, 255
  %541 = tail call i32 @llvm.ctpop.i32(i32 %540) #11
  %542 = trunc i32 %541 to i8
  %543 = and i8 %542, 1
  %544 = xor i8 %543, 1
  store i8 %544, i8* %21, align 1, !tbaa !2446
  %545 = xor i32 %534, %533
  %546 = lshr i32 %545, 4
  %547 = trunc i32 %546 to i8
  %548 = and i8 %547, 1
  store i8 %548, i8* %27, align 1, !tbaa !2447
  %549 = zext i1 %537 to i8
  store i8 %549, i8* %30, align 1, !tbaa !2448
  %550 = lshr i32 %534, 31
  %551 = trunc i32 %550 to i8
  store i8 %551, i8* %33, align 1, !tbaa !2449
  %552 = lshr i32 %533, 31
  %553 = xor i32 %550, %552
  %554 = add nuw nsw i32 %553, %550
  %555 = icmp eq i32 %554, 2
  %556 = zext i1 %555 to i8
  store i8 %556, i8* %39, align 1, !tbaa !2450
  %557 = sext i32 %534 to i64
  store i64 %557, i64* %RDX, align 8, !tbaa !2428
  %558 = shl nsw i64 %557, 3
  %559 = add i64 %558, %529
  %560 = add i64 %522, 23
  store i64 %560, i64* %PC, align 8
  %561 = inttoptr i64 %559 to i64*
  store i64 %525, i64* %561, align 8
  %562 = load i64, i64* %RBP, align 8
  %563 = add i64 %562, -28
  %564 = load i64, i64* %PC, align 8
  %565 = add i64 %564, 3
  store i64 %565, i64* %PC, align 8
  %566 = inttoptr i64 %563 to i32*
  %567 = load i32, i32* %566, align 4
  %568 = add i32 %567, 2
  %569 = zext i32 %568 to i64
  store i64 %569, i64* %RAX, align 8, !tbaa !2428
  %570 = icmp ugt i32 %567, -3
  %571 = zext i1 %570 to i8
  store i8 %571, i8* %14, align 1, !tbaa !2432
  %572 = and i32 %568, 255
  %573 = tail call i32 @llvm.ctpop.i32(i32 %572) #11
  %574 = trunc i32 %573 to i8
  %575 = and i8 %574, 1
  %576 = xor i8 %575, 1
  store i8 %576, i8* %21, align 1, !tbaa !2446
  %577 = xor i32 %568, %567
  %578 = lshr i32 %577, 4
  %579 = trunc i32 %578 to i8
  %580 = and i8 %579, 1
  store i8 %580, i8* %27, align 1, !tbaa !2447
  %581 = icmp eq i32 %568, 0
  %582 = zext i1 %581 to i8
  store i8 %582, i8* %30, align 1, !tbaa !2448
  %583 = lshr i32 %568, 31
  %584 = trunc i32 %583 to i8
  store i8 %584, i8* %33, align 1, !tbaa !2449
  %585 = lshr i32 %567, 31
  %586 = xor i32 %583, %585
  %587 = add nuw nsw i32 %586, %583
  %588 = icmp eq i32 %587, 2
  %589 = zext i1 %588 to i8
  store i8 %589, i8* %39, align 1, !tbaa !2450
  %590 = add i64 %564, 9
  store i64 %590, i64* %PC, align 8
  store i32 %568, i32* %566, align 4
  %591 = load i64, i64* %PC, align 8
  %592 = add i64 %591, -264
  store i64 %592, i64* %PC, align 8, !tbaa !2428
  br label %block_402787

block_4024eb:                                     ; preds = %block_4024fa, %block_4024d4
  %593 = phi i64 [ %727, %block_4024fa ], [ %.pre, %block_4024d4 ]
  %594 = load i64, i64* %RBP, align 8
  %595 = add i64 %594, -44
  %596 = add i64 %593, 3
  store i64 %596, i64* %PC, align 8
  %597 = inttoptr i64 %595 to i32*
  %598 = load i32, i32* %597, align 4
  %599 = shl i32 %598, 2
  %600 = zext i32 %599 to i64
  store i64 %600, i64* %RAX, align 8, !tbaa !2428
  %601 = lshr i32 %598, 30
  %602 = trunc i32 %601 to i8
  %603 = and i8 %602, 1
  store i8 %603, i8* %14, align 1, !tbaa !2453
  %604 = and i32 %599, 252
  %605 = tail call i32 @llvm.ctpop.i32(i32 %604) #11
  %606 = trunc i32 %605 to i8
  %607 = and i8 %606, 1
  %608 = xor i8 %607, 1
  store i8 %608, i8* %21, align 1, !tbaa !2453
  store i8 0, i8* %27, align 1, !tbaa !2453
  %609 = icmp eq i32 %599, 0
  %610 = zext i1 %609 to i8
  store i8 %610, i8* %30, align 1, !tbaa !2453
  %611 = lshr i32 %598, 29
  %612 = trunc i32 %611 to i8
  %613 = and i8 %612, 1
  store i8 %613, i8* %33, align 1, !tbaa !2453
  store i8 0, i8* %39, align 1, !tbaa !2453
  %614 = add i64 %594, -4
  %615 = add i64 %593, 9
  store i64 %615, i64* %PC, align 8
  %616 = inttoptr i64 %614 to i32*
  %617 = load i32, i32* %616, align 4
  %618 = sub i32 %599, %617
  %619 = icmp ult i32 %599, %617
  %620 = zext i1 %619 to i8
  store i8 %620, i8* %14, align 1, !tbaa !2432
  %621 = and i32 %618, 255
  %622 = tail call i32 @llvm.ctpop.i32(i32 %621) #11
  %623 = trunc i32 %622 to i8
  %624 = and i8 %623, 1
  %625 = xor i8 %624, 1
  store i8 %625, i8* %21, align 1, !tbaa !2446
  %626 = xor i32 %617, %599
  %627 = xor i32 %626, %618
  %628 = lshr i32 %627, 4
  %629 = trunc i32 %628 to i8
  %630 = and i8 %629, 1
  store i8 %630, i8* %27, align 1, !tbaa !2447
  %631 = icmp eq i32 %618, 0
  %632 = zext i1 %631 to i8
  store i8 %632, i8* %30, align 1, !tbaa !2448
  %633 = lshr i32 %618, 31
  %634 = trunc i32 %633 to i8
  store i8 %634, i8* %33, align 1, !tbaa !2449
  %635 = and i32 %611, 1
  %636 = lshr i32 %617, 31
  %637 = xor i32 %636, %635
  %638 = xor i32 %633, %635
  %639 = add nuw nsw i32 %638, %637
  %640 = icmp eq i32 %639, 2
  %641 = zext i1 %640 to i8
  store i8 %641, i8* %39, align 1, !tbaa !2450
  %642 = icmp ne i8 %634, 0
  %643 = xor i1 %642, %640
  %.v15 = select i1 %643, i64 15, i64 48
  %644 = add i64 %.v15, %593
  store i64 %644, i64* %PC, align 8, !tbaa !2428
  br i1 %643, label %block_4024fa, label %block_40251b

block_402787:                                     ; preds = %block_402787.preheader, %block_402793
  %645 = phi i64 [ %592, %block_402793 ], [ %.pre12, %block_402787.preheader ]
  %646 = load i64, i64* %RBP, align 8
  %647 = add i64 %646, -28
  %648 = add i64 %645, 3
  store i64 %648, i64* %PC, align 8
  %649 = inttoptr i64 %647 to i32*
  %650 = load i32, i32* %649, align 4
  %651 = zext i32 %650 to i64
  store i64 %651, i64* %RAX, align 8, !tbaa !2428
  %652 = add i64 %646, -44
  %653 = add i64 %645, 6
  store i64 %653, i64* %PC, align 8
  %654 = inttoptr i64 %652 to i32*
  %655 = load i32, i32* %654, align 4
  %656 = sub i32 %650, %655
  %657 = icmp ult i32 %650, %655
  %658 = zext i1 %657 to i8
  store i8 %658, i8* %14, align 1, !tbaa !2432
  %659 = and i32 %656, 255
  %660 = tail call i32 @llvm.ctpop.i32(i32 %659) #11
  %661 = trunc i32 %660 to i8
  %662 = and i8 %661, 1
  %663 = xor i8 %662, 1
  store i8 %663, i8* %21, align 1, !tbaa !2446
  %664 = xor i32 %655, %650
  %665 = xor i32 %664, %656
  %666 = lshr i32 %665, 4
  %667 = trunc i32 %666 to i8
  %668 = and i8 %667, 1
  store i8 %668, i8* %27, align 1, !tbaa !2447
  %669 = icmp eq i32 %656, 0
  %670 = zext i1 %669 to i8
  store i8 %670, i8* %30, align 1, !tbaa !2448
  %671 = lshr i32 %656, 31
  %672 = trunc i32 %671 to i8
  store i8 %672, i8* %33, align 1, !tbaa !2449
  %673 = lshr i32 %650, 31
  %674 = lshr i32 %655, 31
  %675 = xor i32 %674, %673
  %676 = xor i32 %671, %673
  %677 = add nuw nsw i32 %676, %675
  %678 = icmp eq i32 %677, 2
  %679 = zext i1 %678 to i8
  store i8 %679, i8* %39, align 1, !tbaa !2450
  %680 = icmp ne i8 %672, 0
  %681 = xor i1 %680, %678
  %.v16 = select i1 %681, i64 12, i64 269
  %682 = add i64 %.v16, %645
  store i64 %682, i64* %PC, align 8, !tbaa !2428
  br i1 %681, label %block_402793, label %block_402894

block_40251b:                                     ; preds = %block_4024eb
  %683 = add i64 %644, 5
  store i64 %683, i64* %PC, align 8, !tbaa !2428
  br label %block_402520

block_4024fa:                                     ; preds = %block_4024eb
  %684 = add i64 %644, 3
  store i64 %684, i64* %PC, align 8
  %685 = load i32, i32* %616, align 4
  %686 = zext i32 %685 to i64
  store i64 %686, i64* %RDI, align 8, !tbaa !2428
  %687 = add i64 %644, 6
  store i64 %687, i64* %PC, align 8
  %688 = load i32, i32* %597, align 4
  %689 = zext i32 %688 to i64
  store i64 %689, i64* %RSI, align 8, !tbaa !2428
  %690 = add i64 %594, -16
  %691 = add i64 %644, 10
  store i64 %691, i64* %PC, align 8
  %692 = inttoptr i64 %690 to i64*
  %693 = load i64, i64* %692, align 8
  store i64 %693, i64* %RDX, align 8, !tbaa !2428
  %694 = add i64 %594, -24
  %695 = add i64 %644, 14
  store i64 %695, i64* %PC, align 8
  %696 = inttoptr i64 %694 to i64*
  %697 = load i64, i64* %696, align 8
  store i64 %697, i64* %RCX, align 8, !tbaa !2428
  %698 = add i64 %644, 3638
  %699 = add i64 %644, 19
  %700 = load i64, i64* %RSP, align 8, !tbaa !2428
  %701 = add i64 %700, -8
  %702 = inttoptr i64 %701 to i64*
  store i64 %699, i64* %702, align 8
  store i64 %701, i64* %RSP, align 8, !tbaa !2428
  store i64 %698, i64* %PC, align 8, !tbaa !2428
  %703 = tail call %struct.Memory* @sub_403330_cftmdl_renamed_(%struct.State* nonnull %0, i64 %698, %struct.Memory* %179)
  %704 = load i64, i64* %RBP, align 8
  %705 = add i64 %704, -44
  %706 = load i64, i64* %PC, align 8
  %707 = add i64 %706, 3
  store i64 %707, i64* %PC, align 8
  %708 = inttoptr i64 %705 to i32*
  %709 = load i32, i32* %708, align 4
  %710 = shl i32 %709, 2
  %711 = zext i32 %710 to i64
  store i64 %711, i64* %RSI, align 8, !tbaa !2428
  %712 = lshr i32 %709, 30
  %713 = trunc i32 %712 to i8
  %714 = and i8 %713, 1
  store i8 %714, i8* %14, align 1, !tbaa !2453
  %715 = and i32 %710, 252
  %716 = tail call i32 @llvm.ctpop.i32(i32 %715) #11
  %717 = trunc i32 %716 to i8
  %718 = and i8 %717, 1
  %719 = xor i8 %718, 1
  store i8 %719, i8* %21, align 1, !tbaa !2453
  store i8 0, i8* %27, align 1, !tbaa !2453
  %720 = icmp eq i32 %710, 0
  %721 = zext i1 %720 to i8
  store i8 %721, i8* %30, align 1, !tbaa !2453
  %722 = lshr i32 %709, 29
  %723 = trunc i32 %722 to i8
  %724 = and i8 %723, 1
  store i8 %724, i8* %33, align 1, !tbaa !2453
  store i8 0, i8* %39, align 1, !tbaa !2453
  %725 = add i64 %706, 9
  store i64 %725, i64* %PC, align 8
  store i32 %710, i32* %708, align 4
  %726 = load i64, i64* %PC, align 8
  %727 = add i64 %726, -43
  store i64 %727, i64* %PC, align 8, !tbaa !2428
  br label %block_4024eb

block_402894:                                     ; preds = %block_402787
  %728 = add i64 %682, 5
  br label %block_402899

block_402542:                                     ; preds = %block_402536
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %729 = add i64 %162, 13
  store i64 %729, i64* %PC, align 8
  %730 = load i32, i32* %129, align 4
  %731 = zext i32 %730 to i64
  store i64 %731, i64* %RCX, align 8, !tbaa !2428
  %732 = add i64 %162, 16
  store i64 %732, i64* %PC, align 8
  %733 = load i32, i32* %134, align 4
  %734 = add i32 %733, %730
  %735 = zext i32 %734 to i64
  store i64 %735, i64* %RCX, align 8, !tbaa !2428
  %736 = icmp ult i32 %734, %730
  %737 = icmp ult i32 %734, %733
  %738 = or i1 %736, %737
  %739 = zext i1 %738 to i8
  store i8 %739, i8* %14, align 1, !tbaa !2432
  %740 = and i32 %734, 255
  %741 = tail call i32 @llvm.ctpop.i32(i32 %740) #11
  %742 = trunc i32 %741 to i8
  %743 = and i8 %742, 1
  %744 = xor i8 %743, 1
  store i8 %744, i8* %21, align 1, !tbaa !2446
  %745 = xor i32 %733, %730
  %746 = xor i32 %745, %734
  %747 = lshr i32 %746, 4
  %748 = trunc i32 %747 to i8
  %749 = and i8 %748, 1
  store i8 %749, i8* %27, align 1, !tbaa !2447
  %750 = icmp eq i32 %734, 0
  %751 = zext i1 %750 to i8
  store i8 %751, i8* %30, align 1, !tbaa !2448
  %752 = lshr i32 %734, 31
  %753 = trunc i32 %752 to i8
  store i8 %753, i8* %33, align 1, !tbaa !2449
  %754 = lshr i32 %730, 31
  %755 = lshr i32 %733, 31
  %756 = xor i32 %752, %754
  %757 = xor i32 %752, %755
  %758 = add nuw nsw i32 %756, %757
  %759 = icmp eq i32 %758, 2
  %760 = zext i1 %759 to i8
  store i8 %760, i8* %39, align 1, !tbaa !2450
  %761 = add i64 %126, -32
  %762 = add i64 %162, 19
  store i64 %762, i64* %PC, align 8
  %763 = inttoptr i64 %761 to i32*
  store i32 %734, i32* %763, align 4
  %764 = load i64, i64* %RBP, align 8
  %765 = add i64 %764, -32
  %766 = load i64, i64* %PC, align 8
  %767 = add i64 %766, 3
  store i64 %767, i64* %PC, align 8
  %768 = inttoptr i64 %765 to i32*
  %769 = load i32, i32* %768, align 4
  %770 = zext i32 %769 to i64
  store i64 %770, i64* %RCX, align 8, !tbaa !2428
  %771 = add i64 %764, -44
  %772 = add i64 %766, 6
  store i64 %772, i64* %PC, align 8
  %773 = inttoptr i64 %771 to i32*
  %774 = load i32, i32* %773, align 4
  %775 = add i32 %774, %769
  %776 = zext i32 %775 to i64
  store i64 %776, i64* %RCX, align 8, !tbaa !2428
  %777 = icmp ult i32 %775, %769
  %778 = icmp ult i32 %775, %774
  %779 = or i1 %777, %778
  %780 = zext i1 %779 to i8
  store i8 %780, i8* %14, align 1, !tbaa !2432
  %781 = and i32 %775, 255
  %782 = tail call i32 @llvm.ctpop.i32(i32 %781) #11
  %783 = trunc i32 %782 to i8
  %784 = and i8 %783, 1
  %785 = xor i8 %784, 1
  store i8 %785, i8* %21, align 1, !tbaa !2446
  %786 = xor i32 %774, %769
  %787 = xor i32 %786, %775
  %788 = lshr i32 %787, 4
  %789 = trunc i32 %788 to i8
  %790 = and i8 %789, 1
  store i8 %790, i8* %27, align 1, !tbaa !2447
  %791 = icmp eq i32 %775, 0
  %792 = zext i1 %791 to i8
  store i8 %792, i8* %30, align 1, !tbaa !2448
  %793 = lshr i32 %775, 31
  %794 = trunc i32 %793 to i8
  store i8 %794, i8* %33, align 1, !tbaa !2449
  %795 = lshr i32 %769, 31
  %796 = lshr i32 %774, 31
  %797 = xor i32 %793, %795
  %798 = xor i32 %793, %796
  %799 = add nuw nsw i32 %797, %798
  %800 = icmp eq i32 %799, 2
  %801 = zext i1 %800 to i8
  store i8 %801, i8* %39, align 1, !tbaa !2450
  %802 = add i64 %764, -36
  %803 = add i64 %766, 9
  store i64 %803, i64* %PC, align 8
  %804 = inttoptr i64 %802 to i32*
  store i32 %775, i32* %804, align 4
  %805 = load i64, i64* %RBP, align 8
  %806 = add i64 %805, -36
  %807 = load i64, i64* %PC, align 8
  %808 = add i64 %807, 3
  store i64 %808, i64* %PC, align 8
  %809 = inttoptr i64 %806 to i32*
  %810 = load i32, i32* %809, align 4
  %811 = zext i32 %810 to i64
  store i64 %811, i64* %RCX, align 8, !tbaa !2428
  %812 = add i64 %805, -44
  %813 = add i64 %807, 6
  store i64 %813, i64* %PC, align 8
  %814 = inttoptr i64 %812 to i32*
  %815 = load i32, i32* %814, align 4
  %816 = add i32 %815, %810
  %817 = zext i32 %816 to i64
  store i64 %817, i64* %RCX, align 8, !tbaa !2428
  %818 = icmp ult i32 %816, %810
  %819 = icmp ult i32 %816, %815
  %820 = or i1 %818, %819
  %821 = zext i1 %820 to i8
  store i8 %821, i8* %14, align 1, !tbaa !2432
  %822 = and i32 %816, 255
  %823 = tail call i32 @llvm.ctpop.i32(i32 %822) #11
  %824 = trunc i32 %823 to i8
  %825 = and i8 %824, 1
  %826 = xor i8 %825, 1
  store i8 %826, i8* %21, align 1, !tbaa !2446
  %827 = xor i32 %815, %810
  %828 = xor i32 %827, %816
  %829 = lshr i32 %828, 4
  %830 = trunc i32 %829 to i8
  %831 = and i8 %830, 1
  store i8 %831, i8* %27, align 1, !tbaa !2447
  %832 = icmp eq i32 %816, 0
  %833 = zext i1 %832 to i8
  store i8 %833, i8* %30, align 1, !tbaa !2448
  %834 = lshr i32 %816, 31
  %835 = trunc i32 %834 to i8
  store i8 %835, i8* %33, align 1, !tbaa !2449
  %836 = lshr i32 %810, 31
  %837 = lshr i32 %815, 31
  %838 = xor i32 %834, %836
  %839 = xor i32 %834, %837
  %840 = add nuw nsw i32 %838, %839
  %841 = icmp eq i32 %840, 2
  %842 = zext i1 %841 to i8
  store i8 %842, i8* %39, align 1, !tbaa !2450
  %843 = add i64 %805, -40
  %844 = add i64 %807, 9
  store i64 %844, i64* %PC, align 8
  %845 = inttoptr i64 %843 to i32*
  store i32 %816, i32* %845, align 4
  %846 = load i64, i64* %RBP, align 8
  %847 = add i64 %846, -16
  %848 = load i64, i64* %PC, align 8
  %849 = add i64 %848, 4
  store i64 %849, i64* %PC, align 8
  %850 = inttoptr i64 %847 to i64*
  %851 = load i64, i64* %850, align 8
  store i64 %851, i64* %RDX, align 8, !tbaa !2428
  %852 = add i64 %846, -28
  %853 = add i64 %848, 8
  store i64 %853, i64* %PC, align 8
  %854 = inttoptr i64 %852 to i32*
  %855 = load i32, i32* %854, align 4
  %856 = sext i32 %855 to i64
  store i64 %856, i64* %RSI, align 8, !tbaa !2428
  %857 = shl nsw i64 %856, 3
  %858 = add i64 %857, %851
  %859 = add i64 %848, 13
  store i64 %859, i64* %PC, align 8
  %860 = inttoptr i64 %858 to i64*
  %861 = load i64, i64* %860, align 8
  store i64 %861, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %862 = add i64 %848, 17
  store i64 %862, i64* %PC, align 8
  %863 = load i64, i64* %850, align 8
  store i64 %863, i64* %RDX, align 8, !tbaa !2428
  %864 = add i64 %846, -32
  %865 = add i64 %848, 21
  store i64 %865, i64* %PC, align 8
  %866 = inttoptr i64 %864 to i32*
  %867 = load i32, i32* %866, align 4
  %868 = sext i32 %867 to i64
  store i64 %868, i64* %RSI, align 8, !tbaa !2428
  %869 = shl nsw i64 %868, 3
  %870 = add i64 %869, %863
  %871 = add i64 %848, 26
  store i64 %871, i64* %PC, align 8
  %872 = bitcast i64 %861 to double
  %873 = inttoptr i64 %870 to double*
  %874 = load double, double* %873, align 8
  %875 = fadd double %872, %874
  store double %875, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %876 = add i64 %846, -56
  %877 = add i64 %848, 31
  store i64 %877, i64* %PC, align 8
  %878 = inttoptr i64 %876 to double*
  store double %875, double* %878, align 8
  %879 = load i64, i64* %RBP, align 8
  %880 = add i64 %879, -16
  %881 = load i64, i64* %PC, align 8
  %882 = add i64 %881, 4
  store i64 %882, i64* %PC, align 8
  %883 = inttoptr i64 %880 to i64*
  %884 = load i64, i64* %883, align 8
  store i64 %884, i64* %RDX, align 8, !tbaa !2428
  %885 = add i64 %879, -28
  %886 = add i64 %881, 7
  store i64 %886, i64* %PC, align 8
  %887 = inttoptr i64 %885 to i32*
  %888 = load i32, i32* %887, align 4
  %889 = add i32 %888, 1
  %890 = zext i32 %889 to i64
  store i64 %890, i64* %RCX, align 8, !tbaa !2428
  %891 = icmp eq i32 %888, -1
  %892 = icmp eq i32 %889, 0
  %893 = or i1 %891, %892
  %894 = zext i1 %893 to i8
  store i8 %894, i8* %14, align 1, !tbaa !2432
  %895 = and i32 %889, 255
  %896 = tail call i32 @llvm.ctpop.i32(i32 %895) #11
  %897 = trunc i32 %896 to i8
  %898 = and i8 %897, 1
  %899 = xor i8 %898, 1
  store i8 %899, i8* %21, align 1, !tbaa !2446
  %900 = xor i32 %889, %888
  %901 = lshr i32 %900, 4
  %902 = trunc i32 %901 to i8
  %903 = and i8 %902, 1
  store i8 %903, i8* %27, align 1, !tbaa !2447
  %904 = zext i1 %892 to i8
  store i8 %904, i8* %30, align 1, !tbaa !2448
  %905 = lshr i32 %889, 31
  %906 = trunc i32 %905 to i8
  store i8 %906, i8* %33, align 1, !tbaa !2449
  %907 = lshr i32 %888, 31
  %908 = xor i32 %905, %907
  %909 = add nuw nsw i32 %908, %905
  %910 = icmp eq i32 %909, 2
  %911 = zext i1 %910 to i8
  store i8 %911, i8* %39, align 1, !tbaa !2450
  %912 = sext i32 %889 to i64
  store i64 %912, i64* %RSI, align 8, !tbaa !2428
  %913 = shl nsw i64 %912, 3
  %914 = add i64 %913, %884
  %915 = add i64 %881, 18
  store i64 %915, i64* %PC, align 8
  %916 = inttoptr i64 %914 to i64*
  %917 = load i64, i64* %916, align 8
  %918 = load i64, i64* %RAX, align 8
  %919 = xor i64 %918, %917
  store i64 %919, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2432
  %920 = trunc i64 %919 to i32
  %921 = and i32 %920, 255
  %922 = tail call i32 @llvm.ctpop.i32(i32 %921) #11
  %923 = trunc i32 %922 to i8
  %924 = and i8 %923, 1
  %925 = xor i8 %924, 1
  store i8 %925, i8* %21, align 1, !tbaa !2446
  %926 = icmp eq i64 %919, 0
  %927 = zext i1 %926 to i8
  store i8 %927, i8* %30, align 1, !tbaa !2448
  %928 = lshr i64 %919, 63
  %929 = trunc i64 %928 to i8
  store i8 %929, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2447
  store i64 %919, i64* %1699, align 1, !tbaa !2428
  store i64 0, i64* %1700, align 1, !tbaa !2428
  %930 = add i64 %881, 35
  store i64 %930, i64* %PC, align 8
  %931 = load i64, i64* %883, align 8
  store i64 %931, i64* %RDX, align 8, !tbaa !2428
  %932 = add i64 %879, -32
  %933 = add i64 %881, 38
  store i64 %933, i64* %PC, align 8
  %934 = inttoptr i64 %932 to i32*
  %935 = load i32, i32* %934, align 4
  %936 = add i32 %935, 1
  %937 = zext i32 %936 to i64
  store i64 %937, i64* %RCX, align 8, !tbaa !2428
  %938 = icmp eq i32 %935, -1
  %939 = icmp eq i32 %936, 0
  %940 = or i1 %938, %939
  %941 = zext i1 %940 to i8
  store i8 %941, i8* %14, align 1, !tbaa !2432
  %942 = and i32 %936, 255
  %943 = tail call i32 @llvm.ctpop.i32(i32 %942) #11
  %944 = trunc i32 %943 to i8
  %945 = and i8 %944, 1
  %946 = xor i8 %945, 1
  store i8 %946, i8* %21, align 1, !tbaa !2446
  %947 = xor i32 %936, %935
  %948 = lshr i32 %947, 4
  %949 = trunc i32 %948 to i8
  %950 = and i8 %949, 1
  store i8 %950, i8* %27, align 1, !tbaa !2447
  %951 = zext i1 %939 to i8
  store i8 %951, i8* %30, align 1, !tbaa !2448
  %952 = lshr i32 %936, 31
  %953 = trunc i32 %952 to i8
  store i8 %953, i8* %33, align 1, !tbaa !2449
  %954 = lshr i32 %935, 31
  %955 = xor i32 %952, %954
  %956 = add nuw nsw i32 %955, %952
  %957 = icmp eq i32 %956, 2
  %958 = zext i1 %957 to i8
  store i8 %958, i8* %39, align 1, !tbaa !2450
  %959 = sext i32 %936 to i64
  store i64 %959, i64* %RSI, align 8, !tbaa !2428
  %960 = shl nsw i64 %959, 3
  %961 = add i64 %960, %931
  %962 = add i64 %881, 49
  store i64 %962, i64* %PC, align 8
  %963 = bitcast i64 %919 to double
  %964 = inttoptr i64 %961 to double*
  %965 = load double, double* %964, align 8
  %966 = fsub double %963, %965
  store double %966, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %967 = load i64, i64* %RBP, align 8
  %968 = add i64 %967, -64
  %969 = add i64 %881, 54
  store i64 %969, i64* %PC, align 8
  %970 = inttoptr i64 %968 to double*
  store double %966, double* %970, align 8
  %971 = load i64, i64* %RBP, align 8
  %972 = add i64 %971, -16
  %973 = load i64, i64* %PC, align 8
  %974 = add i64 %973, 4
  store i64 %974, i64* %PC, align 8
  %975 = inttoptr i64 %972 to i64*
  %976 = load i64, i64* %975, align 8
  store i64 %976, i64* %RDX, align 8, !tbaa !2428
  %977 = add i64 %971, -28
  %978 = add i64 %973, 8
  store i64 %978, i64* %PC, align 8
  %979 = inttoptr i64 %977 to i32*
  %980 = load i32, i32* %979, align 4
  %981 = sext i32 %980 to i64
  store i64 %981, i64* %RSI, align 8, !tbaa !2428
  %982 = shl nsw i64 %981, 3
  %983 = add i64 %982, %976
  %984 = add i64 %973, 13
  store i64 %984, i64* %PC, align 8
  %985 = inttoptr i64 %983 to i64*
  %986 = load i64, i64* %985, align 8
  store i64 %986, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %987 = add i64 %973, 17
  store i64 %987, i64* %PC, align 8
  %988 = load i64, i64* %975, align 8
  store i64 %988, i64* %RDX, align 8, !tbaa !2428
  %989 = add i64 %971, -32
  %990 = add i64 %973, 21
  store i64 %990, i64* %PC, align 8
  %991 = inttoptr i64 %989 to i32*
  %992 = load i32, i32* %991, align 4
  %993 = sext i32 %992 to i64
  store i64 %993, i64* %RSI, align 8, !tbaa !2428
  %994 = shl nsw i64 %993, 3
  %995 = add i64 %994, %988
  %996 = add i64 %973, 26
  store i64 %996, i64* %PC, align 8
  %997 = bitcast i64 %986 to double
  %998 = inttoptr i64 %995 to double*
  %999 = load double, double* %998, align 8
  %1000 = fsub double %997, %999
  store double %1000, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %1001 = add i64 %971, -72
  %1002 = add i64 %973, 31
  store i64 %1002, i64* %PC, align 8
  %1003 = inttoptr i64 %1001 to double*
  store double %1000, double* %1003, align 8
  %1004 = load i64, i64* %RBP, align 8
  %1005 = add i64 %1004, -16
  %1006 = load i64, i64* %PC, align 8
  %1007 = add i64 %1006, 4
  store i64 %1007, i64* %PC, align 8
  %1008 = inttoptr i64 %1005 to i64*
  %1009 = load i64, i64* %1008, align 8
  store i64 %1009, i64* %RDX, align 8, !tbaa !2428
  %1010 = add i64 %1004, -28
  %1011 = add i64 %1006, 7
  store i64 %1011, i64* %PC, align 8
  %1012 = inttoptr i64 %1010 to i32*
  %1013 = load i32, i32* %1012, align 4
  %1014 = add i32 %1013, 1
  %1015 = zext i32 %1014 to i64
  store i64 %1015, i64* %RCX, align 8, !tbaa !2428
  %1016 = icmp eq i32 %1013, -1
  %1017 = icmp eq i32 %1014, 0
  %1018 = or i1 %1016, %1017
  %1019 = zext i1 %1018 to i8
  store i8 %1019, i8* %14, align 1, !tbaa !2432
  %1020 = and i32 %1014, 255
  %1021 = tail call i32 @llvm.ctpop.i32(i32 %1020) #11
  %1022 = trunc i32 %1021 to i8
  %1023 = and i8 %1022, 1
  %1024 = xor i8 %1023, 1
  store i8 %1024, i8* %21, align 1, !tbaa !2446
  %1025 = xor i32 %1014, %1013
  %1026 = lshr i32 %1025, 4
  %1027 = trunc i32 %1026 to i8
  %1028 = and i8 %1027, 1
  store i8 %1028, i8* %27, align 1, !tbaa !2447
  %1029 = zext i1 %1017 to i8
  store i8 %1029, i8* %30, align 1, !tbaa !2448
  %1030 = lshr i32 %1014, 31
  %1031 = trunc i32 %1030 to i8
  store i8 %1031, i8* %33, align 1, !tbaa !2449
  %1032 = lshr i32 %1013, 31
  %1033 = xor i32 %1030, %1032
  %1034 = add nuw nsw i32 %1033, %1030
  %1035 = icmp eq i32 %1034, 2
  %1036 = zext i1 %1035 to i8
  store i8 %1036, i8* %39, align 1, !tbaa !2450
  %1037 = sext i32 %1014 to i64
  store i64 %1037, i64* %RSI, align 8, !tbaa !2428
  %1038 = shl nsw i64 %1037, 3
  %1039 = add i64 %1038, %1009
  %1040 = add i64 %1006, 18
  store i64 %1040, i64* %PC, align 8
  %1041 = inttoptr i64 %1039 to i64*
  %1042 = load i64, i64* %1041, align 8
  %1043 = load i64, i64* %RAX, align 8
  %1044 = xor i64 %1043, %1042
  store i64 %1044, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %14, align 1, !tbaa !2432
  %1045 = trunc i64 %1044 to i32
  %1046 = and i32 %1045, 255
  %1047 = tail call i32 @llvm.ctpop.i32(i32 %1046) #11
  %1048 = trunc i32 %1047 to i8
  %1049 = and i8 %1048, 1
  %1050 = xor i8 %1049, 1
  store i8 %1050, i8* %21, align 1, !tbaa !2446
  %1051 = icmp eq i64 %1044, 0
  %1052 = zext i1 %1051 to i8
  store i8 %1052, i8* %30, align 1, !tbaa !2448
  %1053 = lshr i64 %1044, 63
  %1054 = trunc i64 %1053 to i8
  store i8 %1054, i8* %33, align 1, !tbaa !2449
  store i8 0, i8* %39, align 1, !tbaa !2450
  store i8 0, i8* %27, align 1, !tbaa !2447
  store i64 %1044, i64* %1699, align 1, !tbaa !2428
  store i64 0, i64* %1700, align 1, !tbaa !2428
  %1055 = add i64 %1006, 35
  store i64 %1055, i64* %PC, align 8
  %1056 = load i64, i64* %1008, align 8
  store i64 %1056, i64* %RAX, align 8, !tbaa !2428
  %1057 = add i64 %1004, -32
  %1058 = add i64 %1006, 38
  store i64 %1058, i64* %PC, align 8
  %1059 = inttoptr i64 %1057 to i32*
  %1060 = load i32, i32* %1059, align 4
  %1061 = add i32 %1060, 1
  %1062 = zext i32 %1061 to i64
  store i64 %1062, i64* %RCX, align 8, !tbaa !2428
  %1063 = icmp eq i32 %1060, -1
  %1064 = icmp eq i32 %1061, 0
  %1065 = or i1 %1063, %1064
  %1066 = zext i1 %1065 to i8
  store i8 %1066, i8* %14, align 1, !tbaa !2432
  %1067 = and i32 %1061, 255
  %1068 = tail call i32 @llvm.ctpop.i32(i32 %1067) #11
  %1069 = trunc i32 %1068 to i8
  %1070 = and i8 %1069, 1
  %1071 = xor i8 %1070, 1
  store i8 %1071, i8* %21, align 1, !tbaa !2446
  %1072 = xor i32 %1061, %1060
  %1073 = lshr i32 %1072, 4
  %1074 = trunc i32 %1073 to i8
  %1075 = and i8 %1074, 1
  store i8 %1075, i8* %27, align 1, !tbaa !2447
  %1076 = zext i1 %1064 to i8
  store i8 %1076, i8* %30, align 1, !tbaa !2448
  %1077 = lshr i32 %1061, 31
  %1078 = trunc i32 %1077 to i8
  store i8 %1078, i8* %33, align 1, !tbaa !2449
  %1079 = lshr i32 %1060, 31
  %1080 = xor i32 %1077, %1079
  %1081 = add nuw nsw i32 %1080, %1077
  %1082 = icmp eq i32 %1081, 2
  %1083 = zext i1 %1082 to i8
  store i8 %1083, i8* %39, align 1, !tbaa !2450
  %1084 = sext i32 %1061 to i64
  store i64 %1084, i64* %RDX, align 8, !tbaa !2428
  %1085 = shl nsw i64 %1084, 3
  %1086 = add i64 %1085, %1056
  %1087 = add i64 %1006, 49
  store i64 %1087, i64* %PC, align 8
  %1088 = bitcast i64 %1044 to double
  %1089 = inttoptr i64 %1086 to double*
  %1090 = load double, double* %1089, align 8
  %1091 = fadd double %1088, %1090
  store double %1091, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %1092 = load i64, i64* %RBP, align 8
  %1093 = add i64 %1092, -80
  %1094 = add i64 %1006, 54
  store i64 %1094, i64* %PC, align 8
  %1095 = inttoptr i64 %1093 to double*
  store double %1091, double* %1095, align 8
  %1096 = load i64, i64* %RBP, align 8
  %1097 = add i64 %1096, -16
  %1098 = load i64, i64* %PC, align 8
  %1099 = add i64 %1098, 4
  store i64 %1099, i64* %PC, align 8
  %1100 = inttoptr i64 %1097 to i64*
  %1101 = load i64, i64* %1100, align 8
  store i64 %1101, i64* %RAX, align 8, !tbaa !2428
  %1102 = add i64 %1096, -36
  %1103 = add i64 %1098, 8
  store i64 %1103, i64* %PC, align 8
  %1104 = inttoptr i64 %1102 to i32*
  %1105 = load i32, i32* %1104, align 4
  %1106 = sext i32 %1105 to i64
  store i64 %1106, i64* %RDX, align 8, !tbaa !2428
  %1107 = shl nsw i64 %1106, 3
  %1108 = add i64 %1107, %1101
  %1109 = add i64 %1098, 13
  store i64 %1109, i64* %PC, align 8
  %1110 = inttoptr i64 %1108 to i64*
  %1111 = load i64, i64* %1110, align 8
  store i64 %1111, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %1112 = add i64 %1098, 17
  store i64 %1112, i64* %PC, align 8
  %1113 = load i64, i64* %1100, align 8
  store i64 %1113, i64* %RAX, align 8, !tbaa !2428
  %1114 = add i64 %1096, -40
  %1115 = add i64 %1098, 21
  store i64 %1115, i64* %PC, align 8
  %1116 = inttoptr i64 %1114 to i32*
  %1117 = load i32, i32* %1116, align 4
  %1118 = sext i32 %1117 to i64
  store i64 %1118, i64* %RDX, align 8, !tbaa !2428
  %1119 = shl nsw i64 %1118, 3
  %1120 = add i64 %1119, %1113
  %1121 = add i64 %1098, 26
  store i64 %1121, i64* %PC, align 8
  %1122 = bitcast i64 %1111 to double
  %1123 = inttoptr i64 %1120 to double*
  %1124 = load double, double* %1123, align 8
  %1125 = fadd double %1122, %1124
  store double %1125, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %1126 = add i64 %1096, -88
  %1127 = add i64 %1098, 31
  store i64 %1127, i64* %PC, align 8
  %1128 = inttoptr i64 %1126 to double*
  store double %1125, double* %1128, align 8
  %1129 = load i64, i64* %RBP, align 8
  %1130 = add i64 %1129, -16
  %1131 = load i64, i64* %PC, align 8
  %1132 = add i64 %1131, 4
  store i64 %1132, i64* %PC, align 8
  %1133 = inttoptr i64 %1130 to i64*
  %1134 = load i64, i64* %1133, align 8
  store i64 %1134, i64* %RAX, align 8, !tbaa !2428
  %1135 = add i64 %1129, -36
  %1136 = add i64 %1131, 7
  store i64 %1136, i64* %PC, align 8
  %1137 = inttoptr i64 %1135 to i32*
  %1138 = load i32, i32* %1137, align 4
  %1139 = add i32 %1138, 1
  %1140 = zext i32 %1139 to i64
  store i64 %1140, i64* %RCX, align 8, !tbaa !2428
  %1141 = icmp eq i32 %1138, -1
  %1142 = icmp eq i32 %1139, 0
  %1143 = or i1 %1141, %1142
  %1144 = zext i1 %1143 to i8
  store i8 %1144, i8* %14, align 1, !tbaa !2432
  %1145 = and i32 %1139, 255
  %1146 = tail call i32 @llvm.ctpop.i32(i32 %1145) #11
  %1147 = trunc i32 %1146 to i8
  %1148 = and i8 %1147, 1
  %1149 = xor i8 %1148, 1
  store i8 %1149, i8* %21, align 1, !tbaa !2446
  %1150 = xor i32 %1139, %1138
  %1151 = lshr i32 %1150, 4
  %1152 = trunc i32 %1151 to i8
  %1153 = and i8 %1152, 1
  store i8 %1153, i8* %27, align 1, !tbaa !2447
  %1154 = zext i1 %1142 to i8
  store i8 %1154, i8* %30, align 1, !tbaa !2448
  %1155 = lshr i32 %1139, 31
  %1156 = trunc i32 %1155 to i8
  store i8 %1156, i8* %33, align 1, !tbaa !2449
  %1157 = lshr i32 %1138, 31
  %1158 = xor i32 %1155, %1157
  %1159 = add nuw nsw i32 %1158, %1155
  %1160 = icmp eq i32 %1159, 2
  %1161 = zext i1 %1160 to i8
  store i8 %1161, i8* %39, align 1, !tbaa !2450
  %1162 = sext i32 %1139 to i64
  store i64 %1162, i64* %RDX, align 8, !tbaa !2428
  %1163 = shl nsw i64 %1162, 3
  %1164 = add i64 %1163, %1134
  %1165 = add i64 %1131, 18
  store i64 %1165, i64* %PC, align 8
  %1166 = inttoptr i64 %1164 to i64*
  %1167 = load i64, i64* %1166, align 8
  store i64 %1167, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %1168 = add i64 %1131, 22
  store i64 %1168, i64* %PC, align 8
  %1169 = load i64, i64* %1133, align 8
  store i64 %1169, i64* %RAX, align 8, !tbaa !2428
  %1170 = add i64 %1129, -40
  %1171 = add i64 %1131, 25
  store i64 %1171, i64* %PC, align 8
  %1172 = inttoptr i64 %1170 to i32*
  %1173 = load i32, i32* %1172, align 4
  %1174 = add i32 %1173, 1
  %1175 = zext i32 %1174 to i64
  store i64 %1175, i64* %RCX, align 8, !tbaa !2428
  %1176 = icmp eq i32 %1173, -1
  %1177 = icmp eq i32 %1174, 0
  %1178 = or i1 %1176, %1177
  %1179 = zext i1 %1178 to i8
  store i8 %1179, i8* %14, align 1, !tbaa !2432
  %1180 = and i32 %1174, 255
  %1181 = tail call i32 @llvm.ctpop.i32(i32 %1180) #11
  %1182 = trunc i32 %1181 to i8
  %1183 = and i8 %1182, 1
  %1184 = xor i8 %1183, 1
  store i8 %1184, i8* %21, align 1, !tbaa !2446
  %1185 = xor i32 %1174, %1173
  %1186 = lshr i32 %1185, 4
  %1187 = trunc i32 %1186 to i8
  %1188 = and i8 %1187, 1
  store i8 %1188, i8* %27, align 1, !tbaa !2447
  %1189 = zext i1 %1177 to i8
  store i8 %1189, i8* %30, align 1, !tbaa !2448
  %1190 = lshr i32 %1174, 31
  %1191 = trunc i32 %1190 to i8
  store i8 %1191, i8* %33, align 1, !tbaa !2449
  %1192 = lshr i32 %1173, 31
  %1193 = xor i32 %1190, %1192
  %1194 = add nuw nsw i32 %1193, %1190
  %1195 = icmp eq i32 %1194, 2
  %1196 = zext i1 %1195 to i8
  store i8 %1196, i8* %39, align 1, !tbaa !2450
  %1197 = sext i32 %1174 to i64
  store i64 %1197, i64* %RDX, align 8, !tbaa !2428
  %1198 = shl nsw i64 %1197, 3
  %1199 = add i64 %1198, %1169
  %1200 = add i64 %1131, 36
  store i64 %1200, i64* %PC, align 8
  %1201 = bitcast i64 %1167 to double
  %1202 = inttoptr i64 %1199 to double*
  %1203 = load double, double* %1202, align 8
  %1204 = fadd double %1201, %1203
  store double %1204, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %1205 = load i64, i64* %RBP, align 8
  %1206 = add i64 %1205, -96
  %1207 = add i64 %1131, 41
  store i64 %1207, i64* %PC, align 8
  %1208 = inttoptr i64 %1206 to double*
  store double %1204, double* %1208, align 8
  %1209 = load i64, i64* %RBP, align 8
  %1210 = add i64 %1209, -16
  %1211 = load i64, i64* %PC, align 8
  %1212 = add i64 %1211, 4
  store i64 %1212, i64* %PC, align 8
  %1213 = inttoptr i64 %1210 to i64*
  %1214 = load i64, i64* %1213, align 8
  store i64 %1214, i64* %RAX, align 8, !tbaa !2428
  %1215 = add i64 %1209, -36
  %1216 = add i64 %1211, 8
  store i64 %1216, i64* %PC, align 8
  %1217 = inttoptr i64 %1215 to i32*
  %1218 = load i32, i32* %1217, align 4
  %1219 = sext i32 %1218 to i64
  store i64 %1219, i64* %RDX, align 8, !tbaa !2428
  %1220 = shl nsw i64 %1219, 3
  %1221 = add i64 %1220, %1214
  %1222 = add i64 %1211, 13
  store i64 %1222, i64* %PC, align 8
  %1223 = inttoptr i64 %1221 to i64*
  %1224 = load i64, i64* %1223, align 8
  store i64 %1224, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %1225 = add i64 %1211, 17
  store i64 %1225, i64* %PC, align 8
  %1226 = load i64, i64* %1213, align 8
  store i64 %1226, i64* %RAX, align 8, !tbaa !2428
  %1227 = add i64 %1209, -40
  %1228 = add i64 %1211, 21
  store i64 %1228, i64* %PC, align 8
  %1229 = inttoptr i64 %1227 to i32*
  %1230 = load i32, i32* %1229, align 4
  %1231 = sext i32 %1230 to i64
  store i64 %1231, i64* %RDX, align 8, !tbaa !2428
  %1232 = shl nsw i64 %1231, 3
  %1233 = add i64 %1232, %1226
  %1234 = add i64 %1211, 26
  store i64 %1234, i64* %PC, align 8
  %1235 = bitcast i64 %1224 to double
  %1236 = inttoptr i64 %1233 to double*
  %1237 = load double, double* %1236, align 8
  %1238 = fsub double %1235, %1237
  store double %1238, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %1239 = add i64 %1209, -104
  %1240 = add i64 %1211, 31
  store i64 %1240, i64* %PC, align 8
  %1241 = inttoptr i64 %1239 to double*
  store double %1238, double* %1241, align 8
  %1242 = load i64, i64* %RBP, align 8
  %1243 = add i64 %1242, -16
  %1244 = load i64, i64* %PC, align 8
  %1245 = add i64 %1244, 4
  store i64 %1245, i64* %PC, align 8
  %1246 = inttoptr i64 %1243 to i64*
  %1247 = load i64, i64* %1246, align 8
  store i64 %1247, i64* %RAX, align 8, !tbaa !2428
  %1248 = add i64 %1242, -36
  %1249 = add i64 %1244, 7
  store i64 %1249, i64* %PC, align 8
  %1250 = inttoptr i64 %1248 to i32*
  %1251 = load i32, i32* %1250, align 4
  %1252 = add i32 %1251, 1
  %1253 = zext i32 %1252 to i64
  store i64 %1253, i64* %RCX, align 8, !tbaa !2428
  %1254 = icmp eq i32 %1251, -1
  %1255 = icmp eq i32 %1252, 0
  %1256 = or i1 %1254, %1255
  %1257 = zext i1 %1256 to i8
  store i8 %1257, i8* %14, align 1, !tbaa !2432
  %1258 = and i32 %1252, 255
  %1259 = tail call i32 @llvm.ctpop.i32(i32 %1258) #11
  %1260 = trunc i32 %1259 to i8
  %1261 = and i8 %1260, 1
  %1262 = xor i8 %1261, 1
  store i8 %1262, i8* %21, align 1, !tbaa !2446
  %1263 = xor i32 %1252, %1251
  %1264 = lshr i32 %1263, 4
  %1265 = trunc i32 %1264 to i8
  %1266 = and i8 %1265, 1
  store i8 %1266, i8* %27, align 1, !tbaa !2447
  %1267 = zext i1 %1255 to i8
  store i8 %1267, i8* %30, align 1, !tbaa !2448
  %1268 = lshr i32 %1252, 31
  %1269 = trunc i32 %1268 to i8
  store i8 %1269, i8* %33, align 1, !tbaa !2449
  %1270 = lshr i32 %1251, 31
  %1271 = xor i32 %1268, %1270
  %1272 = add nuw nsw i32 %1271, %1268
  %1273 = icmp eq i32 %1272, 2
  %1274 = zext i1 %1273 to i8
  store i8 %1274, i8* %39, align 1, !tbaa !2450
  %1275 = sext i32 %1252 to i64
  store i64 %1275, i64* %RDX, align 8, !tbaa !2428
  %1276 = shl nsw i64 %1275, 3
  %1277 = add i64 %1276, %1247
  %1278 = add i64 %1244, 18
  store i64 %1278, i64* %PC, align 8
  %1279 = inttoptr i64 %1277 to i64*
  %1280 = load i64, i64* %1279, align 8
  store i64 %1280, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %1281 = add i64 %1244, 22
  store i64 %1281, i64* %PC, align 8
  %1282 = load i64, i64* %1246, align 8
  store i64 %1282, i64* %RAX, align 8, !tbaa !2428
  %1283 = add i64 %1242, -40
  %1284 = add i64 %1244, 25
  store i64 %1284, i64* %PC, align 8
  %1285 = inttoptr i64 %1283 to i32*
  %1286 = load i32, i32* %1285, align 4
  %1287 = add i32 %1286, 1
  %1288 = zext i32 %1287 to i64
  store i64 %1288, i64* %RCX, align 8, !tbaa !2428
  %1289 = icmp eq i32 %1286, -1
  %1290 = icmp eq i32 %1287, 0
  %1291 = or i1 %1289, %1290
  %1292 = zext i1 %1291 to i8
  store i8 %1292, i8* %14, align 1, !tbaa !2432
  %1293 = and i32 %1287, 255
  %1294 = tail call i32 @llvm.ctpop.i32(i32 %1293) #11
  %1295 = trunc i32 %1294 to i8
  %1296 = and i8 %1295, 1
  %1297 = xor i8 %1296, 1
  store i8 %1297, i8* %21, align 1, !tbaa !2446
  %1298 = xor i32 %1287, %1286
  %1299 = lshr i32 %1298, 4
  %1300 = trunc i32 %1299 to i8
  %1301 = and i8 %1300, 1
  store i8 %1301, i8* %27, align 1, !tbaa !2447
  %1302 = zext i1 %1290 to i8
  store i8 %1302, i8* %30, align 1, !tbaa !2448
  %1303 = lshr i32 %1287, 31
  %1304 = trunc i32 %1303 to i8
  store i8 %1304, i8* %33, align 1, !tbaa !2449
  %1305 = lshr i32 %1286, 31
  %1306 = xor i32 %1303, %1305
  %1307 = add nuw nsw i32 %1306, %1303
  %1308 = icmp eq i32 %1307, 2
  %1309 = zext i1 %1308 to i8
  store i8 %1309, i8* %39, align 1, !tbaa !2450
  %1310 = sext i32 %1287 to i64
  store i64 %1310, i64* %RDX, align 8, !tbaa !2428
  %1311 = shl nsw i64 %1310, 3
  %1312 = add i64 %1311, %1282
  %1313 = add i64 %1244, 36
  store i64 %1313, i64* %PC, align 8
  %1314 = bitcast i64 %1280 to double
  %1315 = inttoptr i64 %1312 to double*
  %1316 = load double, double* %1315, align 8
  %1317 = fsub double %1314, %1316
  store double %1317, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %1318 = load i64, i64* %RBP, align 8
  %1319 = add i64 %1318, -112
  %1320 = add i64 %1244, 41
  store i64 %1320, i64* %PC, align 8
  %1321 = inttoptr i64 %1319 to double*
  store double %1317, double* %1321, align 8
  %1322 = load i64, i64* %RBP, align 8
  %1323 = add i64 %1322, -56
  %1324 = load i64, i64* %PC, align 8
  %1325 = add i64 %1324, 5
  store i64 %1325, i64* %PC, align 8
  %1326 = inttoptr i64 %1323 to i64*
  %1327 = load i64, i64* %1326, align 8
  store i64 %1327, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %1328 = add i64 %1322, -88
  %1329 = add i64 %1324, 10
  store i64 %1329, i64* %PC, align 8
  %1330 = bitcast i64 %1327 to double
  %1331 = inttoptr i64 %1328 to double*
  %1332 = load double, double* %1331, align 8
  %1333 = fadd double %1330, %1332
  store double %1333, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %1334 = add i64 %1322, -16
  %1335 = add i64 %1324, 14
  store i64 %1335, i64* %PC, align 8
  %1336 = inttoptr i64 %1334 to i64*
  %1337 = load i64, i64* %1336, align 8
  store i64 %1337, i64* %RAX, align 8, !tbaa !2428
  %1338 = add i64 %1322, -28
  %1339 = add i64 %1324, 18
  store i64 %1339, i64* %PC, align 8
  %1340 = inttoptr i64 %1338 to i32*
  %1341 = load i32, i32* %1340, align 4
  %1342 = sext i32 %1341 to i64
  store i64 %1342, i64* %RDX, align 8, !tbaa !2428
  %1343 = shl nsw i64 %1342, 3
  %1344 = add i64 %1343, %1337
  %1345 = add i64 %1324, 23
  store i64 %1345, i64* %PC, align 8
  %1346 = inttoptr i64 %1344 to double*
  store double %1333, double* %1346, align 8
  %1347 = load i64, i64* %RBP, align 8
  %1348 = add i64 %1347, -64
  %1349 = load i64, i64* %PC, align 8
  %1350 = add i64 %1349, 5
  store i64 %1350, i64* %PC, align 8
  %1351 = inttoptr i64 %1348 to i64*
  %1352 = load i64, i64* %1351, align 8
  store i64 %1352, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %1353 = add i64 %1347, -96
  %1354 = add i64 %1349, 10
  store i64 %1354, i64* %PC, align 8
  %1355 = bitcast i64 %1352 to double
  %1356 = inttoptr i64 %1353 to double*
  %1357 = load double, double* %1356, align 8
  %1358 = fsub double %1355, %1357
  store double %1358, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %1359 = add i64 %1347, -16
  %1360 = add i64 %1349, 14
  store i64 %1360, i64* %PC, align 8
  %1361 = inttoptr i64 %1359 to i64*
  %1362 = load i64, i64* %1361, align 8
  store i64 %1362, i64* %RAX, align 8, !tbaa !2428
  %1363 = add i64 %1347, -28
  %1364 = add i64 %1349, 17
  store i64 %1364, i64* %PC, align 8
  %1365 = inttoptr i64 %1363 to i32*
  %1366 = load i32, i32* %1365, align 4
  %1367 = add i32 %1366, 1
  %1368 = zext i32 %1367 to i64
  store i64 %1368, i64* %RCX, align 8, !tbaa !2428
  %1369 = icmp eq i32 %1366, -1
  %1370 = icmp eq i32 %1367, 0
  %1371 = or i1 %1369, %1370
  %1372 = zext i1 %1371 to i8
  store i8 %1372, i8* %14, align 1, !tbaa !2432
  %1373 = and i32 %1367, 255
  %1374 = tail call i32 @llvm.ctpop.i32(i32 %1373) #11
  %1375 = trunc i32 %1374 to i8
  %1376 = and i8 %1375, 1
  %1377 = xor i8 %1376, 1
  store i8 %1377, i8* %21, align 1, !tbaa !2446
  %1378 = xor i32 %1367, %1366
  %1379 = lshr i32 %1378, 4
  %1380 = trunc i32 %1379 to i8
  %1381 = and i8 %1380, 1
  store i8 %1381, i8* %27, align 1, !tbaa !2447
  %1382 = zext i1 %1370 to i8
  store i8 %1382, i8* %30, align 1, !tbaa !2448
  %1383 = lshr i32 %1367, 31
  %1384 = trunc i32 %1383 to i8
  store i8 %1384, i8* %33, align 1, !tbaa !2449
  %1385 = lshr i32 %1366, 31
  %1386 = xor i32 %1383, %1385
  %1387 = add nuw nsw i32 %1386, %1383
  %1388 = icmp eq i32 %1387, 2
  %1389 = zext i1 %1388 to i8
  store i8 %1389, i8* %39, align 1, !tbaa !2450
  %1390 = sext i32 %1367 to i64
  store i64 %1390, i64* %RDX, align 8, !tbaa !2428
  %1391 = shl nsw i64 %1390, 3
  %1392 = add i64 %1391, %1362
  %1393 = add i64 %1349, 28
  store i64 %1393, i64* %PC, align 8
  %1394 = inttoptr i64 %1392 to double*
  store double %1358, double* %1394, align 8
  %1395 = load i64, i64* %RBP, align 8
  %1396 = add i64 %1395, -56
  %1397 = load i64, i64* %PC, align 8
  %1398 = add i64 %1397, 5
  store i64 %1398, i64* %PC, align 8
  %1399 = inttoptr i64 %1396 to i64*
  %1400 = load i64, i64* %1399, align 8
  store i64 %1400, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %1401 = add i64 %1395, -88
  %1402 = add i64 %1397, 10
  store i64 %1402, i64* %PC, align 8
  %1403 = bitcast i64 %1400 to double
  %1404 = inttoptr i64 %1401 to double*
  %1405 = load double, double* %1404, align 8
  %1406 = fsub double %1403, %1405
  store double %1406, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %1407 = add i64 %1395, -16
  %1408 = add i64 %1397, 14
  store i64 %1408, i64* %PC, align 8
  %1409 = inttoptr i64 %1407 to i64*
  %1410 = load i64, i64* %1409, align 8
  store i64 %1410, i64* %RAX, align 8, !tbaa !2428
  %1411 = add i64 %1395, -36
  %1412 = add i64 %1397, 18
  store i64 %1412, i64* %PC, align 8
  %1413 = inttoptr i64 %1411 to i32*
  %1414 = load i32, i32* %1413, align 4
  %1415 = sext i32 %1414 to i64
  store i64 %1415, i64* %RDX, align 8, !tbaa !2428
  %1416 = shl nsw i64 %1415, 3
  %1417 = add i64 %1416, %1410
  %1418 = add i64 %1397, 23
  store i64 %1418, i64* %PC, align 8
  %1419 = inttoptr i64 %1417 to double*
  store double %1406, double* %1419, align 8
  %1420 = load i64, i64* %RBP, align 8
  %1421 = add i64 %1420, -64
  %1422 = load i64, i64* %PC, align 8
  %1423 = add i64 %1422, 5
  store i64 %1423, i64* %PC, align 8
  %1424 = inttoptr i64 %1421 to i64*
  %1425 = load i64, i64* %1424, align 8
  store i64 %1425, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %1426 = add i64 %1420, -96
  %1427 = add i64 %1422, 10
  store i64 %1427, i64* %PC, align 8
  %1428 = bitcast i64 %1425 to double
  %1429 = inttoptr i64 %1426 to double*
  %1430 = load double, double* %1429, align 8
  %1431 = fadd double %1428, %1430
  store double %1431, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %1432 = add i64 %1420, -16
  %1433 = add i64 %1422, 14
  store i64 %1433, i64* %PC, align 8
  %1434 = inttoptr i64 %1432 to i64*
  %1435 = load i64, i64* %1434, align 8
  store i64 %1435, i64* %RAX, align 8, !tbaa !2428
  %1436 = add i64 %1420, -36
  %1437 = add i64 %1422, 17
  store i64 %1437, i64* %PC, align 8
  %1438 = inttoptr i64 %1436 to i32*
  %1439 = load i32, i32* %1438, align 4
  %1440 = add i32 %1439, 1
  %1441 = zext i32 %1440 to i64
  store i64 %1441, i64* %RCX, align 8, !tbaa !2428
  %1442 = icmp eq i32 %1439, -1
  %1443 = icmp eq i32 %1440, 0
  %1444 = or i1 %1442, %1443
  %1445 = zext i1 %1444 to i8
  store i8 %1445, i8* %14, align 1, !tbaa !2432
  %1446 = and i32 %1440, 255
  %1447 = tail call i32 @llvm.ctpop.i32(i32 %1446) #11
  %1448 = trunc i32 %1447 to i8
  %1449 = and i8 %1448, 1
  %1450 = xor i8 %1449, 1
  store i8 %1450, i8* %21, align 1, !tbaa !2446
  %1451 = xor i32 %1440, %1439
  %1452 = lshr i32 %1451, 4
  %1453 = trunc i32 %1452 to i8
  %1454 = and i8 %1453, 1
  store i8 %1454, i8* %27, align 1, !tbaa !2447
  %1455 = zext i1 %1443 to i8
  store i8 %1455, i8* %30, align 1, !tbaa !2448
  %1456 = lshr i32 %1440, 31
  %1457 = trunc i32 %1456 to i8
  store i8 %1457, i8* %33, align 1, !tbaa !2449
  %1458 = lshr i32 %1439, 31
  %1459 = xor i32 %1456, %1458
  %1460 = add nuw nsw i32 %1459, %1456
  %1461 = icmp eq i32 %1460, 2
  %1462 = zext i1 %1461 to i8
  store i8 %1462, i8* %39, align 1, !tbaa !2450
  %1463 = sext i32 %1440 to i64
  store i64 %1463, i64* %RDX, align 8, !tbaa !2428
  %1464 = shl nsw i64 %1463, 3
  %1465 = add i64 %1464, %1435
  %1466 = add i64 %1422, 28
  store i64 %1466, i64* %PC, align 8
  %1467 = inttoptr i64 %1465 to double*
  store double %1431, double* %1467, align 8
  %1468 = load i64, i64* %RBP, align 8
  %1469 = add i64 %1468, -72
  %1470 = load i64, i64* %PC, align 8
  %1471 = add i64 %1470, 5
  store i64 %1471, i64* %PC, align 8
  %1472 = inttoptr i64 %1469 to i64*
  %1473 = load i64, i64* %1472, align 8
  store i64 %1473, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %1474 = add i64 %1468, -112
  %1475 = add i64 %1470, 10
  store i64 %1475, i64* %PC, align 8
  %1476 = bitcast i64 %1473 to double
  %1477 = inttoptr i64 %1474 to double*
  %1478 = load double, double* %1477, align 8
  %1479 = fsub double %1476, %1478
  store double %1479, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %1480 = add i64 %1468, -16
  %1481 = add i64 %1470, 14
  store i64 %1481, i64* %PC, align 8
  %1482 = inttoptr i64 %1480 to i64*
  %1483 = load i64, i64* %1482, align 8
  store i64 %1483, i64* %RAX, align 8, !tbaa !2428
  %1484 = add i64 %1468, -32
  %1485 = add i64 %1470, 18
  store i64 %1485, i64* %PC, align 8
  %1486 = inttoptr i64 %1484 to i32*
  %1487 = load i32, i32* %1486, align 4
  %1488 = sext i32 %1487 to i64
  store i64 %1488, i64* %RDX, align 8, !tbaa !2428
  %1489 = shl nsw i64 %1488, 3
  %1490 = add i64 %1489, %1483
  %1491 = add i64 %1470, 23
  store i64 %1491, i64* %PC, align 8
  %1492 = inttoptr i64 %1490 to double*
  store double %1479, double* %1492, align 8
  %1493 = load i64, i64* %RBP, align 8
  %1494 = add i64 %1493, -80
  %1495 = load i64, i64* %PC, align 8
  %1496 = add i64 %1495, 5
  store i64 %1496, i64* %PC, align 8
  %1497 = inttoptr i64 %1494 to i64*
  %1498 = load i64, i64* %1497, align 8
  store i64 %1498, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %1499 = add i64 %1493, -104
  %1500 = add i64 %1495, 10
  store i64 %1500, i64* %PC, align 8
  %1501 = bitcast i64 %1498 to double
  %1502 = inttoptr i64 %1499 to double*
  %1503 = load double, double* %1502, align 8
  %1504 = fsub double %1501, %1503
  store double %1504, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %1505 = add i64 %1493, -16
  %1506 = add i64 %1495, 14
  store i64 %1506, i64* %PC, align 8
  %1507 = inttoptr i64 %1505 to i64*
  %1508 = load i64, i64* %1507, align 8
  store i64 %1508, i64* %RAX, align 8, !tbaa !2428
  %1509 = add i64 %1493, -32
  %1510 = add i64 %1495, 17
  store i64 %1510, i64* %PC, align 8
  %1511 = inttoptr i64 %1509 to i32*
  %1512 = load i32, i32* %1511, align 4
  %1513 = add i32 %1512, 1
  %1514 = zext i32 %1513 to i64
  store i64 %1514, i64* %RCX, align 8, !tbaa !2428
  %1515 = icmp eq i32 %1512, -1
  %1516 = icmp eq i32 %1513, 0
  %1517 = or i1 %1515, %1516
  %1518 = zext i1 %1517 to i8
  store i8 %1518, i8* %14, align 1, !tbaa !2432
  %1519 = and i32 %1513, 255
  %1520 = tail call i32 @llvm.ctpop.i32(i32 %1519) #11
  %1521 = trunc i32 %1520 to i8
  %1522 = and i8 %1521, 1
  %1523 = xor i8 %1522, 1
  store i8 %1523, i8* %21, align 1, !tbaa !2446
  %1524 = xor i32 %1513, %1512
  %1525 = lshr i32 %1524, 4
  %1526 = trunc i32 %1525 to i8
  %1527 = and i8 %1526, 1
  store i8 %1527, i8* %27, align 1, !tbaa !2447
  %1528 = zext i1 %1516 to i8
  store i8 %1528, i8* %30, align 1, !tbaa !2448
  %1529 = lshr i32 %1513, 31
  %1530 = trunc i32 %1529 to i8
  store i8 %1530, i8* %33, align 1, !tbaa !2449
  %1531 = lshr i32 %1512, 31
  %1532 = xor i32 %1529, %1531
  %1533 = add nuw nsw i32 %1532, %1529
  %1534 = icmp eq i32 %1533, 2
  %1535 = zext i1 %1534 to i8
  store i8 %1535, i8* %39, align 1, !tbaa !2450
  %1536 = sext i32 %1513 to i64
  store i64 %1536, i64* %RDX, align 8, !tbaa !2428
  %1537 = shl nsw i64 %1536, 3
  %1538 = add i64 %1537, %1508
  %1539 = add i64 %1495, 28
  store i64 %1539, i64* %PC, align 8
  %1540 = inttoptr i64 %1538 to double*
  store double %1504, double* %1540, align 8
  %1541 = load i64, i64* %RBP, align 8
  %1542 = add i64 %1541, -72
  %1543 = load i64, i64* %PC, align 8
  %1544 = add i64 %1543, 5
  store i64 %1544, i64* %PC, align 8
  %1545 = inttoptr i64 %1542 to i64*
  %1546 = load i64, i64* %1545, align 8
  store i64 %1546, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %1547 = add i64 %1541, -112
  %1548 = add i64 %1543, 10
  store i64 %1548, i64* %PC, align 8
  %1549 = bitcast i64 %1546 to double
  %1550 = inttoptr i64 %1547 to double*
  %1551 = load double, double* %1550, align 8
  %1552 = fadd double %1549, %1551
  store double %1552, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %1553 = add i64 %1541, -16
  %1554 = add i64 %1543, 14
  store i64 %1554, i64* %PC, align 8
  %1555 = inttoptr i64 %1553 to i64*
  %1556 = load i64, i64* %1555, align 8
  store i64 %1556, i64* %RAX, align 8, !tbaa !2428
  %1557 = add i64 %1541, -40
  %1558 = add i64 %1543, 18
  store i64 %1558, i64* %PC, align 8
  %1559 = inttoptr i64 %1557 to i32*
  %1560 = load i32, i32* %1559, align 4
  %1561 = sext i32 %1560 to i64
  store i64 %1561, i64* %RDX, align 8, !tbaa !2428
  %1562 = shl nsw i64 %1561, 3
  %1563 = add i64 %1562, %1556
  %1564 = add i64 %1543, 23
  store i64 %1564, i64* %PC, align 8
  %1565 = inttoptr i64 %1563 to double*
  store double %1552, double* %1565, align 8
  %1566 = load i64, i64* %RBP, align 8
  %1567 = add i64 %1566, -80
  %1568 = load i64, i64* %PC, align 8
  %1569 = add i64 %1568, 5
  store i64 %1569, i64* %PC, align 8
  %1570 = inttoptr i64 %1567 to i64*
  %1571 = load i64, i64* %1570, align 8
  store i64 %1571, i64* %1699, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1701, align 1, !tbaa !2451
  %1572 = add i64 %1566, -104
  %1573 = add i64 %1568, 10
  store i64 %1573, i64* %PC, align 8
  %1574 = bitcast i64 %1571 to double
  %1575 = inttoptr i64 %1572 to double*
  %1576 = load double, double* %1575, align 8
  %1577 = fadd double %1574, %1576
  store double %1577, double* %1698, align 1, !tbaa !2451
  store i64 0, i64* %1700, align 1, !tbaa !2451
  %1578 = add i64 %1566, -16
  %1579 = add i64 %1568, 14
  store i64 %1579, i64* %PC, align 8
  %1580 = inttoptr i64 %1578 to i64*
  %1581 = load i64, i64* %1580, align 8
  store i64 %1581, i64* %RAX, align 8, !tbaa !2428
  %1582 = add i64 %1566, -40
  %1583 = add i64 %1568, 17
  store i64 %1583, i64* %PC, align 8
  %1584 = inttoptr i64 %1582 to i32*
  %1585 = load i32, i32* %1584, align 4
  %1586 = add i32 %1585, 1
  %1587 = zext i32 %1586 to i64
  store i64 %1587, i64* %RCX, align 8, !tbaa !2428
  %1588 = icmp eq i32 %1585, -1
  %1589 = icmp eq i32 %1586, 0
  %1590 = or i1 %1588, %1589
  %1591 = zext i1 %1590 to i8
  store i8 %1591, i8* %14, align 1, !tbaa !2432
  %1592 = and i32 %1586, 255
  %1593 = tail call i32 @llvm.ctpop.i32(i32 %1592) #11
  %1594 = trunc i32 %1593 to i8
  %1595 = and i8 %1594, 1
  %1596 = xor i8 %1595, 1
  store i8 %1596, i8* %21, align 1, !tbaa !2446
  %1597 = xor i32 %1586, %1585
  %1598 = lshr i32 %1597, 4
  %1599 = trunc i32 %1598 to i8
  %1600 = and i8 %1599, 1
  store i8 %1600, i8* %27, align 1, !tbaa !2447
  %1601 = zext i1 %1589 to i8
  store i8 %1601, i8* %30, align 1, !tbaa !2448
  %1602 = lshr i32 %1586, 31
  %1603 = trunc i32 %1602 to i8
  store i8 %1603, i8* %33, align 1, !tbaa !2449
  %1604 = lshr i32 %1585, 31
  %1605 = xor i32 %1602, %1604
  %1606 = add nuw nsw i32 %1605, %1602
  %1607 = icmp eq i32 %1606, 2
  %1608 = zext i1 %1607 to i8
  store i8 %1608, i8* %39, align 1, !tbaa !2450
  %1609 = sext i32 %1586 to i64
  store i64 %1609, i64* %RDX, align 8, !tbaa !2428
  %1610 = shl nsw i64 %1609, 3
  %1611 = add i64 %1610, %1581
  %1612 = add i64 %1568, 28
  store i64 %1612, i64* %PC, align 8
  %1613 = inttoptr i64 %1611 to double*
  store double %1577, double* %1613, align 8
  %1614 = load i64, i64* %RBP, align 8
  %1615 = add i64 %1614, -28
  %1616 = load i64, i64* %PC, align 8
  %1617 = add i64 %1616, 3
  store i64 %1617, i64* %PC, align 8
  %1618 = inttoptr i64 %1615 to i32*
  %1619 = load i32, i32* %1618, align 4
  %1620 = add i32 %1619, 2
  %1621 = zext i32 %1620 to i64
  store i64 %1621, i64* %RAX, align 8, !tbaa !2428
  %1622 = icmp ugt i32 %1619, -3
  %1623 = zext i1 %1622 to i8
  store i8 %1623, i8* %14, align 1, !tbaa !2432
  %1624 = and i32 %1620, 255
  %1625 = tail call i32 @llvm.ctpop.i32(i32 %1624) #11
  %1626 = trunc i32 %1625 to i8
  %1627 = and i8 %1626, 1
  %1628 = xor i8 %1627, 1
  store i8 %1628, i8* %21, align 1, !tbaa !2446
  %1629 = xor i32 %1620, %1619
  %1630 = lshr i32 %1629, 4
  %1631 = trunc i32 %1630 to i8
  %1632 = and i8 %1631, 1
  store i8 %1632, i8* %27, align 1, !tbaa !2447
  %1633 = icmp eq i32 %1620, 0
  %1634 = zext i1 %1633 to i8
  store i8 %1634, i8* %30, align 1, !tbaa !2448
  %1635 = lshr i32 %1620, 31
  %1636 = trunc i32 %1635 to i8
  store i8 %1636, i8* %33, align 1, !tbaa !2449
  %1637 = lshr i32 %1619, 31
  %1638 = xor i32 %1635, %1637
  %1639 = add nuw nsw i32 %1638, %1635
  %1640 = icmp eq i32 %1639, 2
  %1641 = zext i1 %1640 to i8
  store i8 %1641, i8* %39, align 1, !tbaa !2450
  %1642 = add i64 %1616, 9
  store i64 %1642, i64* %PC, align 8
  store i32 %1620, i32* %1618, align 4
  %1643 = load i64, i64* %PC, align 8
  %1644 = add i64 %1643, -576
  store i64 %1644, i64* %PC, align 8, !tbaa !2428
  br label %block_402536

block_402520:                                     ; preds = %block_40251b, %block_4024b0
  %1645 = phi i64 [ %91, %block_4024b0 ], [ %683, %block_40251b ]
  %1646 = phi i64 [ %61, %block_4024b0 ], [ %594, %block_40251b ]
  %MEMORY.4 = phi %struct.Memory* [ %2, %block_4024b0 ], [ %179, %block_40251b ]
  %1647 = add i64 %1646, -44
  %1648 = add i64 %1645, 3
  store i64 %1648, i64* %PC, align 8
  %1649 = inttoptr i64 %1647 to i32*
  %1650 = load i32, i32* %1649, align 4
  %1651 = shl i32 %1650, 2
  %1652 = zext i32 %1651 to i64
  store i64 %1652, i64* %RAX, align 8, !tbaa !2428
  %1653 = lshr i32 %1650, 30
  %1654 = trunc i32 %1653 to i8
  %1655 = and i8 %1654, 1
  store i8 %1655, i8* %14, align 1, !tbaa !2453
  %1656 = and i32 %1651, 252
  %1657 = tail call i32 @llvm.ctpop.i32(i32 %1656) #11
  %1658 = trunc i32 %1657 to i8
  %1659 = and i8 %1658, 1
  %1660 = xor i8 %1659, 1
  store i8 %1660, i8* %21, align 1, !tbaa !2453
  store i8 0, i8* %27, align 1, !tbaa !2453
  %1661 = icmp eq i32 %1651, 0
  %1662 = zext i1 %1661 to i8
  store i8 %1662, i8* %30, align 1, !tbaa !2453
  %1663 = lshr i32 %1650, 29
  %1664 = trunc i32 %1663 to i8
  %1665 = and i8 %1664, 1
  store i8 %1665, i8* %33, align 1, !tbaa !2453
  store i8 0, i8* %39, align 1, !tbaa !2453
  %1666 = add i64 %1646, -4
  %1667 = add i64 %1645, 9
  store i64 %1667, i64* %PC, align 8
  %1668 = inttoptr i64 %1666 to i32*
  %1669 = load i32, i32* %1668, align 4
  %1670 = sub i32 %1651, %1669
  %1671 = icmp ult i32 %1651, %1669
  %1672 = zext i1 %1671 to i8
  store i8 %1672, i8* %14, align 1, !tbaa !2432
  %1673 = and i32 %1670, 255
  %1674 = tail call i32 @llvm.ctpop.i32(i32 %1673) #11
  %1675 = trunc i32 %1674 to i8
  %1676 = and i8 %1675, 1
  %1677 = xor i8 %1676, 1
  store i8 %1677, i8* %21, align 1, !tbaa !2446
  %1678 = xor i32 %1669, %1651
  %1679 = xor i32 %1678, %1670
  %1680 = lshr i32 %1679, 4
  %1681 = trunc i32 %1680 to i8
  %1682 = and i8 %1681, 1
  store i8 %1682, i8* %27, align 1, !tbaa !2447
  %1683 = icmp eq i32 %1670, 0
  %1684 = zext i1 %1683 to i8
  store i8 %1684, i8* %30, align 1, !tbaa !2448
  %1685 = lshr i32 %1670, 31
  %1686 = trunc i32 %1685 to i8
  store i8 %1686, i8* %33, align 1, !tbaa !2449
  %1687 = and i32 %1663, 1
  %1688 = lshr i32 %1669, 31
  %1689 = xor i32 %1688, %1687
  %1690 = xor i32 %1685, %1687
  %1691 = add nuw nsw i32 %1690, %1689
  %1692 = icmp eq i32 %1691, 2
  %1693 = zext i1 %1692 to i8
  store i8 %1693, i8* %39, align 1, !tbaa !2450
  %.v = select i1 %1683, i64 15, i64 608
  %1694 = add i64 %1646, -28
  %1695 = add i64 %1645, 7
  %1696 = add i64 %1695, %.v
  store i64 %1696, i64* %PC, align 8
  %1697 = inttoptr i64 %1694 to i32*
  store i32 0, i32* %1697, align 4
  %1698 = bitcast %union.VectorReg* %4 to double*
  %1699 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  %1700 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1701 = bitcast i64* %1700 to double*
  %.pre12 = load i64, i64* %PC, align 8
  br i1 %1683, label %block_402536.preheader, label %block_402787.preheader

block_402787.preheader:                           ; preds = %block_402520
  br label %block_402787

block_402536.preheader:                           ; preds = %block_402520
  br label %block_402536
}

; Function Attrs: noinline
define %struct.Memory* @sub_400810___do_global_dtors_aux(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #8 {
block_400810:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i8, i8* getelementptr inbounds (%__bss_start_type, %__bss_start_type* @__bss_start, i64 0, i32 0, i64 0), align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %4, align 1, !tbaa !2432
  %5 = zext i8 %3 to i32
  %6 = tail call i32 @llvm.ctpop.i32(i32 %5) #11
  %7 = trunc i32 %6 to i8
  %8 = and i8 %7, 1
  %9 = xor i8 %8, 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %9, i8* %10, align 1, !tbaa !2446
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %11, align 1, !tbaa !2447
  %12 = icmp eq i8 %3, 0
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %13, i8* %14, align 1, !tbaa !2448
  %15 = lshr i8 %3, 7
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %15, i8* %16, align 1, !tbaa !2449
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %17, align 1, !tbaa !2450
  %.v = select i1 %12, i64 9, i64 32
  %18 = add i64 %.v, %1
  store i64 %18, i64* %PC, align 8, !tbaa !2428
  br i1 %12, label %block_400819, label %block_400830

block_400830:                                     ; preds = %block_400810
  %19 = add i64 %18, 2
  store i64 %19, i64* %PC, align 8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %21 = load i64, i64* %20, align 8, !tbaa !2428
  %22 = inttoptr i64 %21 to i64*
  %23 = load i64, i64* %22, align 8
  store i64 %23, i64* %PC, align 8, !tbaa !2428
  %24 = add i64 %21, 8
  store i64 %24, i64* %20, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_400819:                                     ; preds = %block_400810
  %25 = load i64, i64* %RBP, align 8
  %26 = add i64 %18, 1
  store i64 %26, i64* %PC, align 8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %28 = load i64, i64* %27, align 8, !tbaa !2428
  %29 = add i64 %28, -8
  %30 = inttoptr i64 %29 to i64*
  store i64 %25, i64* %30, align 8
  %31 = load i64, i64* %PC, align 8
  store i64 %29, i64* %RBP, align 8, !tbaa !2428
  %32 = add i64 %31, -122
  %33 = add i64 %31, 8
  %34 = add i64 %28, -16
  %35 = inttoptr i64 %34 to i64*
  store i64 %33, i64* %35, align 8
  store i64 %34, i64* %27, align 8, !tbaa !2428
  store i64 %32, i64* %PC, align 8, !tbaa !2428
  %36 = tail call %struct.Memory* @sub_4007a0_deregister_tm_clones_renamed_(%struct.State* nonnull %0, i64 %32, %struct.Memory* %2)
  %37 = load i64, i64* %PC, align 8
  store i8 1, i8* getelementptr inbounds (%__bss_start_type, %__bss_start_type* @__bss_start, i64 0, i32 0, i64 0), align 8
  %38 = add i64 %37, 8
  store i64 %38, i64* %PC, align 8
  %39 = load i64, i64* %27, align 8, !tbaa !2428
  %40 = add i64 %39, 8
  %41 = inttoptr i64 %39 to i64*
  %42 = load i64, i64* %41, align 8
  store i64 %42, i64* %RBP, align 8, !tbaa !2428
  store i64 %40, i64* %27, align 8, !tbaa !2428
  %43 = add i64 %37, 9
  store i64 %43, i64* %PC, align 8
  %44 = inttoptr i64 %40 to i64*
  %45 = load i64, i64* %44, align 8
  store i64 %45, i64* %PC, align 8, !tbaa !2428
  %46 = add i64 %39, 16
  store i64 %46, i64* %27, align 8, !tbaa !2428
  ret %struct.Memory* %36
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_404094__term_proc(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_404094:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = add i64 %3, -8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %7 = xor i64 %4, %3
  %8 = lshr i64 %7, 4
  %9 = trunc i64 %8 to i8
  %10 = and i8 %9, 1
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %13 = lshr i64 %4, 63
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %15 = lshr i64 %3, 63
  %16 = xor i64 %13, %15
  %17 = add nuw nsw i64 %16, %15
  %18 = icmp eq i64 %17, 2
  %19 = zext i1 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %21 = icmp ult i64 %3, 8
  %22 = zext i1 %21 to i8
  store i8 %22, i8* %5, align 1, !tbaa !2432
  %23 = trunc i64 %3 to i32
  %24 = and i32 %23, 255
  %25 = tail call i32 @llvm.ctpop.i32(i32 %24) #11
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = xor i8 %27, 1
  store i8 %28, i8* %6, align 1, !tbaa !2446
  store i8 %10, i8* %11, align 1, !tbaa !2447
  %29 = icmp eq i64 %3, 0
  %30 = zext i1 %29 to i8
  store i8 %30, i8* %12, align 1, !tbaa !2448
  %31 = trunc i64 %15 to i8
  store i8 %31, i8* %14, align 1, !tbaa !2449
  store i8 %19, i8* %20, align 1, !tbaa !2450
  %32 = add i64 %1, 9
  store i64 %32, i64* %PC, align 8
  %33 = inttoptr i64 %3 to i64*
  %34 = load i64, i64* %33, align 8
  store i64 %34, i64* %PC, align 8, !tbaa !2428
  %35 = add i64 %3, 8
  store i64 %35, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_4011f0_bitrv2(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_4011f0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %1, 1
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %4, i64* %9, align 8
  store i64 %8, i64* %6, align 8, !tbaa !2428
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -12
  %12 = load i32, i32* %EDI, align 4
  %13 = add i64 %10, 6
  store i64 %13, i64* %PC, align 8
  %14 = inttoptr i64 %11 to i32*
  store i32 %12, i32* %14, align 4
  %15 = load i64, i64* %RBP, align 8
  %16 = add i64 %15, -16
  %17 = load i64, i64* %RSI, align 8
  %18 = load i64, i64* %PC, align 8
  %19 = add i64 %18, 4
  store i64 %19, i64* %PC, align 8
  %20 = inttoptr i64 %16 to i64*
  store i64 %17, i64* %20, align 8
  %21 = load i64, i64* %RBP, align 8
  %22 = add i64 %21, -24
  %23 = load i64, i64* %RDX, align 8
  %24 = load i64, i64* %PC, align 8
  %25 = add i64 %24, 4
  store i64 %25, i64* %PC, align 8
  %26 = inttoptr i64 %22 to i64*
  store i64 %23, i64* %26, align 8
  %27 = load i64, i64* %RBP, align 8
  %28 = add i64 %27, -16
  %29 = load i64, i64* %PC, align 8
  %30 = add i64 %29, 4
  store i64 %30, i64* %PC, align 8
  %31 = inttoptr i64 %28 to i64*
  %32 = load i64, i64* %31, align 8
  store i64 %32, i64* %RDX, align 8, !tbaa !2428
  %33 = add i64 %29, 10
  store i64 %33, i64* %PC, align 8
  %34 = inttoptr i64 %32 to i32*
  store i32 0, i32* %34, align 4
  %35 = load i64, i64* %RBP, align 8
  %36 = add i64 %35, -4
  %37 = load i64, i64* %PC, align 8
  %38 = add i64 %37, 3
  store i64 %38, i64* %PC, align 8
  %39 = inttoptr i64 %36 to i32*
  %40 = load i32, i32* %39, align 4
  %41 = zext i32 %40 to i64
  store i64 %41, i64* %RDI, align 8, !tbaa !2428
  %42 = add i64 %35, -44
  %43 = add i64 %37, 6
  store i64 %43, i64* %PC, align 8
  %44 = inttoptr i64 %42 to i32*
  store i32 %40, i32* %44, align 4
  %45 = load i64, i64* %RBP, align 8
  %46 = add i64 %45, -48
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 7
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %46 to i32*
  store i32 1, i32* %49, align 4
  %50 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %53 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %.pre = load i64, i64* %PC, align 8
  br label %block_401216

block_401862.loopexit:                            ; preds = %block_40129a
  br label %block_401862

block_401862.loopexit49:                          ; preds = %block_40169b
  br label %block_401862

block_401862:                                     ; preds = %block_401862.loopexit49, %block_401862.loopexit
  %56 = phi i64 [ %2845, %block_401862.loopexit ], [ %2769, %block_401862.loopexit49 ]
  %.sink5 = phi i64 [ 468, %block_401862.loopexit ], [ 6, %block_401862.loopexit49 ]
  %57 = add i64 %.sink5, %56
  store i64 %57, i64* %PC, align 8
  %58 = load i64, i64* %6, align 8, !tbaa !2428
  %59 = add i64 %58, 8
  %60 = inttoptr i64 %58 to i64*
  %61 = load i64, i64* %60, align 8
  store i64 %61, i64* %RBP, align 8, !tbaa !2428
  store i64 %59, i64* %6, align 8, !tbaa !2428
  %62 = add i64 %57, 1
  store i64 %62, i64* %PC, align 8
  %63 = inttoptr i64 %59 to i64*
  %64 = load i64, i64* %63, align 8
  store i64 %64, i64* %PC, align 8, !tbaa !2428
  %65 = add i64 %58, 16
  store i64 %65, i64* %6, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_40184a:                                     ; preds = %block_4016ae
  %66 = add i64 %2807, 8
  store i64 %66, i64* %PC, align 8
  %67 = load i32, i32* %2779, align 4
  %68 = add i32 %67, 1
  %69 = zext i32 %68 to i64
  store i64 %69, i64* %RAX, align 8, !tbaa !2428
  %70 = icmp eq i32 %67, -1
  %71 = icmp eq i32 %68, 0
  %72 = or i1 %70, %71
  %73 = zext i1 %72 to i8
  store i8 %73, i8* %50, align 1, !tbaa !2432
  %74 = and i32 %68, 255
  %75 = tail call i32 @llvm.ctpop.i32(i32 %74) #11
  %76 = trunc i32 %75 to i8
  %77 = and i8 %76, 1
  %78 = xor i8 %77, 1
  store i8 %78, i8* %51, align 1, !tbaa !2446
  %79 = xor i32 %68, %67
  %80 = lshr i32 %79, 4
  %81 = trunc i32 %80 to i8
  %82 = and i8 %81, 1
  store i8 %82, i8* %52, align 1, !tbaa !2447
  %83 = zext i1 %71 to i8
  store i8 %83, i8* %53, align 1, !tbaa !2448
  %84 = lshr i32 %68, 31
  %85 = trunc i32 %84 to i8
  store i8 %85, i8* %54, align 1, !tbaa !2449
  %86 = lshr i32 %67, 31
  %87 = xor i32 %84, %86
  %88 = add nuw nsw i32 %87, %84
  %89 = icmp eq i32 %88, 2
  %90 = zext i1 %89 to i8
  store i8 %90, i8* %55, align 1, !tbaa !2450
  %91 = add i64 %2807, 14
  store i64 %91, i64* %PC, align 8
  store i32 %68, i32* %2779, align 4
  %92 = load i64, i64* %PC, align 8
  %93 = add i64 %92, -445
  store i64 %93, i64* %PC, align 8, !tbaa !2428
  br label %block_40169b

block_4015bd:                                     ; preds = %block_4012ad
  %94 = load i32, i32* %1948, align 4
  %95 = shl i32 %94, 1
  %96 = icmp slt i32 %94, 0
  %97 = icmp slt i32 %95, 0
  %98 = xor i1 %96, %97
  %99 = zext i32 %95 to i64
  store i64 %99, i64* %RAX, align 8, !tbaa !2428
  %.lobit18 = lshr i32 %94, 31
  %100 = trunc i32 %.lobit18 to i8
  store i8 %100, i8* %50, align 1, !tbaa !2453
  %101 = and i32 %95, 254
  %102 = tail call i32 @llvm.ctpop.i32(i32 %101) #11
  %103 = trunc i32 %102 to i8
  %104 = and i8 %103, 1
  %105 = xor i8 %104, 1
  store i8 %105, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %106 = icmp eq i32 %95, 0
  %107 = zext i1 %106 to i8
  store i8 %107, i8* %53, align 1, !tbaa !2453
  %108 = lshr i32 %94, 30
  %109 = trunc i32 %108 to i8
  %110 = and i8 %109, 1
  store i8 %110, i8* %54, align 1, !tbaa !2453
  %111 = zext i1 %98 to i8
  store i8 %111, i8* %55, align 1, !tbaa !2453
  %112 = add i64 %1940, -52
  %113 = add i64 %1976, 9
  store i64 %113, i64* %PC, align 8
  %114 = inttoptr i64 %112 to i32*
  %115 = load i32, i32* %114, align 4
  %116 = add i32 %115, %95
  %117 = zext i32 %116 to i64
  store i64 %117, i64* %RAX, align 8, !tbaa !2428
  %118 = icmp ult i32 %116, %95
  %119 = icmp ult i32 %116, %115
  %120 = or i1 %118, %119
  %121 = zext i1 %120 to i8
  store i8 %121, i8* %50, align 1, !tbaa !2432
  %122 = and i32 %116, 255
  %123 = tail call i32 @llvm.ctpop.i32(i32 %122) #11
  %124 = trunc i32 %123 to i8
  %125 = and i8 %124, 1
  %126 = xor i8 %125, 1
  store i8 %126, i8* %51, align 1, !tbaa !2446
  %127 = xor i32 %115, %95
  %128 = xor i32 %127, %116
  %129 = lshr i32 %128, 4
  %130 = trunc i32 %129 to i8
  %131 = and i8 %130, 1
  store i8 %131, i8* %52, align 1, !tbaa !2447
  %132 = icmp eq i32 %116, 0
  %133 = zext i1 %132 to i8
  store i8 %133, i8* %53, align 1, !tbaa !2448
  %134 = lshr i32 %116, 31
  %135 = trunc i32 %134 to i8
  store i8 %135, i8* %54, align 1, !tbaa !2449
  %136 = and i32 %108, 1
  %137 = lshr i32 %115, 31
  %138 = xor i32 %134, %136
  %139 = xor i32 %134, %137
  %140 = add nuw nsw i32 %138, %139
  %141 = icmp eq i32 %140, 2
  %142 = zext i1 %141 to i8
  store i8 %142, i8* %55, align 1, !tbaa !2450
  %143 = add i64 %1940, -16
  %144 = add i64 %1976, 13
  store i64 %144, i64* %PC, align 8
  %145 = inttoptr i64 %143 to i64*
  %146 = load i64, i64* %145, align 8
  store i64 %146, i64* %RCX, align 8, !tbaa !2428
  %147 = add i64 %1976, 17
  store i64 %147, i64* %PC, align 8
  %148 = load i32, i32* %1948, align 4
  %149 = sext i32 %148 to i64
  store i64 %149, i64* %RDX, align 8, !tbaa !2428
  %150 = shl nsw i64 %149, 2
  %151 = add i64 %150, %146
  %152 = add i64 %1976, 20
  store i64 %152, i64* %PC, align 8
  %153 = inttoptr i64 %151 to i32*
  %154 = load i32, i32* %153, align 4
  %155 = add i32 %154, %116
  %156 = zext i32 %155 to i64
  store i64 %156, i64* %RAX, align 8, !tbaa !2428
  %157 = icmp ult i32 %155, %116
  %158 = icmp ult i32 %155, %154
  %159 = or i1 %157, %158
  %160 = zext i1 %159 to i8
  store i8 %160, i8* %50, align 1, !tbaa !2432
  %161 = and i32 %155, 255
  %162 = tail call i32 @llvm.ctpop.i32(i32 %161) #11
  %163 = trunc i32 %162 to i8
  %164 = and i8 %163, 1
  %165 = xor i8 %164, 1
  store i8 %165, i8* %51, align 1, !tbaa !2446
  %166 = xor i32 %154, %116
  %167 = xor i32 %166, %155
  %168 = lshr i32 %167, 4
  %169 = trunc i32 %168 to i8
  %170 = and i8 %169, 1
  store i8 %170, i8* %52, align 1, !tbaa !2447
  %171 = icmp eq i32 %155, 0
  %172 = zext i1 %171 to i8
  store i8 %172, i8* %53, align 1, !tbaa !2448
  %173 = lshr i32 %155, 31
  %174 = trunc i32 %173 to i8
  store i8 %174, i8* %54, align 1, !tbaa !2449
  %175 = lshr i32 %154, 31
  %176 = xor i32 %173, %134
  %177 = xor i32 %173, %175
  %178 = add nuw nsw i32 %176, %177
  %179 = icmp eq i32 %178, 2
  %180 = zext i1 %179 to i8
  store i8 %180, i8* %55, align 1, !tbaa !2450
  %181 = load i64, i64* %RBP, align 8
  %182 = add i64 %181, -32
  %183 = add i64 %1976, 23
  store i64 %183, i64* %PC, align 8
  %184 = inttoptr i64 %182 to i32*
  store i32 %155, i32* %184, align 4
  %185 = load i64, i64* %RBP, align 8
  %186 = add i64 %185, -32
  %187 = load i64, i64* %PC, align 8
  %188 = add i64 %187, 3
  store i64 %188, i64* %PC, align 8
  %189 = inttoptr i64 %186 to i32*
  %190 = load i32, i32* %189, align 4
  %191 = zext i32 %190 to i64
  store i64 %191, i64* %RAX, align 8, !tbaa !2428
  %192 = add i64 %185, -52
  %193 = add i64 %187, 6
  store i64 %193, i64* %PC, align 8
  %194 = inttoptr i64 %192 to i32*
  %195 = load i32, i32* %194, align 4
  %196 = add i32 %195, %190
  %197 = zext i32 %196 to i64
  store i64 %197, i64* %RAX, align 8, !tbaa !2428
  %198 = icmp ult i32 %196, %190
  %199 = icmp ult i32 %196, %195
  %200 = or i1 %198, %199
  %201 = zext i1 %200 to i8
  store i8 %201, i8* %50, align 1, !tbaa !2432
  %202 = and i32 %196, 255
  %203 = tail call i32 @llvm.ctpop.i32(i32 %202) #11
  %204 = trunc i32 %203 to i8
  %205 = and i8 %204, 1
  %206 = xor i8 %205, 1
  store i8 %206, i8* %51, align 1, !tbaa !2446
  %207 = xor i32 %195, %190
  %208 = xor i32 %207, %196
  %209 = lshr i32 %208, 4
  %210 = trunc i32 %209 to i8
  %211 = and i8 %210, 1
  store i8 %211, i8* %52, align 1, !tbaa !2447
  %212 = icmp eq i32 %196, 0
  %213 = zext i1 %212 to i8
  store i8 %213, i8* %53, align 1, !tbaa !2448
  %214 = lshr i32 %196, 31
  %215 = trunc i32 %214 to i8
  store i8 %215, i8* %54, align 1, !tbaa !2449
  %216 = lshr i32 %190, 31
  %217 = lshr i32 %195, 31
  %218 = xor i32 %214, %216
  %219 = xor i32 %214, %217
  %220 = add nuw nsw i32 %218, %219
  %221 = icmp eq i32 %220, 2
  %222 = zext i1 %221 to i8
  store i8 %222, i8* %55, align 1, !tbaa !2450
  %223 = add i64 %185, -40
  %224 = add i64 %187, 9
  store i64 %224, i64* %PC, align 8
  %225 = inttoptr i64 %223 to i32*
  store i32 %196, i32* %225, align 4
  %226 = load i64, i64* %RBP, align 8
  %227 = add i64 %226, -24
  %228 = load i64, i64* %PC, align 8
  %229 = add i64 %228, 4
  store i64 %229, i64* %PC, align 8
  %230 = inttoptr i64 %227 to i64*
  %231 = load i64, i64* %230, align 8
  store i64 %231, i64* %RCX, align 8, !tbaa !2428
  %232 = add i64 %226, -32
  %233 = add i64 %228, 8
  store i64 %233, i64* %PC, align 8
  %234 = inttoptr i64 %232 to i32*
  %235 = load i32, i32* %234, align 4
  %236 = sext i32 %235 to i64
  store i64 %236, i64* %RDX, align 8, !tbaa !2428
  %237 = shl nsw i64 %236, 3
  %238 = add i64 %237, %231
  %239 = add i64 %228, 13
  store i64 %239, i64* %PC, align 8
  %240 = inttoptr i64 %238 to i64*
  %241 = load i64, i64* %240, align 8
  store i64 %241, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %242 = add i64 %226, -64
  %243 = add i64 %228, 18
  store i64 %243, i64* %PC, align 8
  %244 = inttoptr i64 %242 to i64*
  store i64 %241, i64* %244, align 8
  %245 = load i64, i64* %RBP, align 8
  %246 = add i64 %245, -24
  %247 = load i64, i64* %PC, align 8
  %248 = add i64 %247, 4
  store i64 %248, i64* %PC, align 8
  %249 = inttoptr i64 %246 to i64*
  %250 = load i64, i64* %249, align 8
  store i64 %250, i64* %RCX, align 8, !tbaa !2428
  %251 = add i64 %245, -32
  %252 = add i64 %247, 7
  store i64 %252, i64* %PC, align 8
  %253 = inttoptr i64 %251 to i32*
  %254 = load i32, i32* %253, align 4
  %255 = add i32 %254, 1
  %256 = zext i32 %255 to i64
  store i64 %256, i64* %RAX, align 8, !tbaa !2428
  %257 = icmp eq i32 %254, -1
  %258 = icmp eq i32 %255, 0
  %259 = or i1 %257, %258
  %260 = zext i1 %259 to i8
  store i8 %260, i8* %50, align 1, !tbaa !2432
  %261 = and i32 %255, 255
  %262 = tail call i32 @llvm.ctpop.i32(i32 %261) #11
  %263 = trunc i32 %262 to i8
  %264 = and i8 %263, 1
  %265 = xor i8 %264, 1
  store i8 %265, i8* %51, align 1, !tbaa !2446
  %266 = xor i32 %255, %254
  %267 = lshr i32 %266, 4
  %268 = trunc i32 %267 to i8
  %269 = and i8 %268, 1
  store i8 %269, i8* %52, align 1, !tbaa !2447
  %270 = zext i1 %258 to i8
  store i8 %270, i8* %53, align 1, !tbaa !2448
  %271 = lshr i32 %255, 31
  %272 = trunc i32 %271 to i8
  store i8 %272, i8* %54, align 1, !tbaa !2449
  %273 = lshr i32 %254, 31
  %274 = xor i32 %271, %273
  %275 = add nuw nsw i32 %274, %271
  %276 = icmp eq i32 %275, 2
  %277 = zext i1 %276 to i8
  store i8 %277, i8* %55, align 1, !tbaa !2450
  %278 = sext i32 %255 to i64
  store i64 %278, i64* %RDX, align 8, !tbaa !2428
  %279 = shl nsw i64 %278, 3
  %280 = add i64 %279, %250
  %281 = add i64 %247, 18
  store i64 %281, i64* %PC, align 8
  %282 = inttoptr i64 %280 to i64*
  %283 = load i64, i64* %282, align 8
  store i64 %283, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %284 = add i64 %245, -72
  %285 = add i64 %247, 23
  store i64 %285, i64* %PC, align 8
  %286 = inttoptr i64 %284 to i64*
  store i64 %283, i64* %286, align 8
  %287 = load i64, i64* %RBP, align 8
  %288 = add i64 %287, -24
  %289 = load i64, i64* %PC, align 8
  %290 = add i64 %289, 4
  store i64 %290, i64* %PC, align 8
  %291 = inttoptr i64 %288 to i64*
  %292 = load i64, i64* %291, align 8
  store i64 %292, i64* %RCX, align 8, !tbaa !2428
  %293 = add i64 %287, -40
  %294 = add i64 %289, 8
  store i64 %294, i64* %PC, align 8
  %295 = inttoptr i64 %293 to i32*
  %296 = load i32, i32* %295, align 4
  %297 = sext i32 %296 to i64
  store i64 %297, i64* %RDX, align 8, !tbaa !2428
  %298 = shl nsw i64 %297, 3
  %299 = add i64 %298, %292
  %300 = add i64 %289, 13
  store i64 %300, i64* %PC, align 8
  %301 = inttoptr i64 %299 to i64*
  %302 = load i64, i64* %301, align 8
  store i64 %302, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %303 = add i64 %287, -80
  %304 = add i64 %289, 18
  store i64 %304, i64* %PC, align 8
  %305 = inttoptr i64 %303 to i64*
  store i64 %302, i64* %305, align 8
  %306 = load i64, i64* %RBP, align 8
  %307 = add i64 %306, -24
  %308 = load i64, i64* %PC, align 8
  %309 = add i64 %308, 4
  store i64 %309, i64* %PC, align 8
  %310 = inttoptr i64 %307 to i64*
  %311 = load i64, i64* %310, align 8
  store i64 %311, i64* %RCX, align 8, !tbaa !2428
  %312 = add i64 %306, -40
  %313 = add i64 %308, 7
  store i64 %313, i64* %PC, align 8
  %314 = inttoptr i64 %312 to i32*
  %315 = load i32, i32* %314, align 4
  %316 = add i32 %315, 1
  %317 = zext i32 %316 to i64
  store i64 %317, i64* %RAX, align 8, !tbaa !2428
  %318 = icmp eq i32 %315, -1
  %319 = icmp eq i32 %316, 0
  %320 = or i1 %318, %319
  %321 = zext i1 %320 to i8
  store i8 %321, i8* %50, align 1, !tbaa !2432
  %322 = and i32 %316, 255
  %323 = tail call i32 @llvm.ctpop.i32(i32 %322) #11
  %324 = trunc i32 %323 to i8
  %325 = and i8 %324, 1
  %326 = xor i8 %325, 1
  store i8 %326, i8* %51, align 1, !tbaa !2446
  %327 = xor i32 %316, %315
  %328 = lshr i32 %327, 4
  %329 = trunc i32 %328 to i8
  %330 = and i8 %329, 1
  store i8 %330, i8* %52, align 1, !tbaa !2447
  %331 = zext i1 %319 to i8
  store i8 %331, i8* %53, align 1, !tbaa !2448
  %332 = lshr i32 %316, 31
  %333 = trunc i32 %332 to i8
  store i8 %333, i8* %54, align 1, !tbaa !2449
  %334 = lshr i32 %315, 31
  %335 = xor i32 %332, %334
  %336 = add nuw nsw i32 %335, %332
  %337 = icmp eq i32 %336, 2
  %338 = zext i1 %337 to i8
  store i8 %338, i8* %55, align 1, !tbaa !2450
  %339 = sext i32 %316 to i64
  store i64 %339, i64* %RDX, align 8, !tbaa !2428
  %340 = shl nsw i64 %339, 3
  %341 = add i64 %340, %311
  %342 = add i64 %308, 18
  store i64 %342, i64* %PC, align 8
  %343 = inttoptr i64 %341 to i64*
  %344 = load i64, i64* %343, align 8
  store i64 %344, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %345 = add i64 %306, -88
  %346 = add i64 %308, 23
  store i64 %346, i64* %PC, align 8
  %347 = inttoptr i64 %345 to i64*
  store i64 %344, i64* %347, align 8
  %348 = load i64, i64* %RBP, align 8
  %349 = add i64 %348, -80
  %350 = load i64, i64* %PC, align 8
  %351 = add i64 %350, 5
  store i64 %351, i64* %PC, align 8
  %352 = inttoptr i64 %349 to i64*
  %353 = load i64, i64* %352, align 8
  store i64 %353, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %354 = add i64 %348, -24
  %355 = add i64 %350, 9
  store i64 %355, i64* %PC, align 8
  %356 = inttoptr i64 %354 to i64*
  %357 = load i64, i64* %356, align 8
  store i64 %357, i64* %RCX, align 8, !tbaa !2428
  %358 = add i64 %348, -32
  %359 = add i64 %350, 13
  store i64 %359, i64* %PC, align 8
  %360 = inttoptr i64 %358 to i32*
  %361 = load i32, i32* %360, align 4
  %362 = sext i32 %361 to i64
  store i64 %362, i64* %RDX, align 8, !tbaa !2428
  %363 = shl nsw i64 %362, 3
  %364 = add i64 %363, %357
  %365 = add i64 %350, 18
  store i64 %365, i64* %PC, align 8
  %366 = inttoptr i64 %364 to i64*
  store i64 %353, i64* %366, align 8
  %367 = load i64, i64* %RBP, align 8
  %368 = add i64 %367, -88
  %369 = load i64, i64* %PC, align 8
  %370 = add i64 %369, 5
  store i64 %370, i64* %PC, align 8
  %371 = inttoptr i64 %368 to i64*
  %372 = load i64, i64* %371, align 8
  store i64 %372, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %373 = add i64 %367, -24
  %374 = add i64 %369, 9
  store i64 %374, i64* %PC, align 8
  %375 = inttoptr i64 %373 to i64*
  %376 = load i64, i64* %375, align 8
  store i64 %376, i64* %RCX, align 8, !tbaa !2428
  %377 = add i64 %367, -32
  %378 = add i64 %369, 12
  store i64 %378, i64* %PC, align 8
  %379 = inttoptr i64 %377 to i32*
  %380 = load i32, i32* %379, align 4
  %381 = add i32 %380, 1
  %382 = zext i32 %381 to i64
  store i64 %382, i64* %RAX, align 8, !tbaa !2428
  %383 = icmp eq i32 %380, -1
  %384 = icmp eq i32 %381, 0
  %385 = or i1 %383, %384
  %386 = zext i1 %385 to i8
  store i8 %386, i8* %50, align 1, !tbaa !2432
  %387 = and i32 %381, 255
  %388 = tail call i32 @llvm.ctpop.i32(i32 %387) #11
  %389 = trunc i32 %388 to i8
  %390 = and i8 %389, 1
  %391 = xor i8 %390, 1
  store i8 %391, i8* %51, align 1, !tbaa !2446
  %392 = xor i32 %381, %380
  %393 = lshr i32 %392, 4
  %394 = trunc i32 %393 to i8
  %395 = and i8 %394, 1
  store i8 %395, i8* %52, align 1, !tbaa !2447
  %396 = zext i1 %384 to i8
  store i8 %396, i8* %53, align 1, !tbaa !2448
  %397 = lshr i32 %381, 31
  %398 = trunc i32 %397 to i8
  store i8 %398, i8* %54, align 1, !tbaa !2449
  %399 = lshr i32 %380, 31
  %400 = xor i32 %397, %399
  %401 = add nuw nsw i32 %400, %397
  %402 = icmp eq i32 %401, 2
  %403 = zext i1 %402 to i8
  store i8 %403, i8* %55, align 1, !tbaa !2450
  %404 = sext i32 %381 to i64
  store i64 %404, i64* %RDX, align 8, !tbaa !2428
  %405 = shl nsw i64 %404, 3
  %406 = add i64 %405, %376
  %407 = add i64 %369, 23
  store i64 %407, i64* %PC, align 8
  %408 = inttoptr i64 %406 to i64*
  store i64 %372, i64* %408, align 8
  %409 = load i64, i64* %RBP, align 8
  %410 = add i64 %409, -64
  %411 = load i64, i64* %PC, align 8
  %412 = add i64 %411, 5
  store i64 %412, i64* %PC, align 8
  %413 = inttoptr i64 %410 to i64*
  %414 = load i64, i64* %413, align 8
  store i64 %414, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %415 = add i64 %409, -24
  %416 = add i64 %411, 9
  store i64 %416, i64* %PC, align 8
  %417 = inttoptr i64 %415 to i64*
  %418 = load i64, i64* %417, align 8
  store i64 %418, i64* %RCX, align 8, !tbaa !2428
  %419 = add i64 %409, -40
  %420 = add i64 %411, 13
  store i64 %420, i64* %PC, align 8
  %421 = inttoptr i64 %419 to i32*
  %422 = load i32, i32* %421, align 4
  %423 = sext i32 %422 to i64
  store i64 %423, i64* %RDX, align 8, !tbaa !2428
  %424 = shl nsw i64 %423, 3
  %425 = add i64 %424, %418
  %426 = add i64 %411, 18
  store i64 %426, i64* %PC, align 8
  %427 = inttoptr i64 %425 to i64*
  store i64 %414, i64* %427, align 8
  %428 = load i64, i64* %RBP, align 8
  %429 = add i64 %428, -72
  %430 = load i64, i64* %PC, align 8
  %431 = add i64 %430, 5
  store i64 %431, i64* %PC, align 8
  %432 = inttoptr i64 %429 to i64*
  %433 = load i64, i64* %432, align 8
  store i64 %433, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %434 = add i64 %428, -24
  %435 = add i64 %430, 9
  store i64 %435, i64* %PC, align 8
  %436 = inttoptr i64 %434 to i64*
  %437 = load i64, i64* %436, align 8
  store i64 %437, i64* %RCX, align 8, !tbaa !2428
  %438 = add i64 %428, -40
  %439 = add i64 %430, 12
  store i64 %439, i64* %PC, align 8
  %440 = inttoptr i64 %438 to i32*
  %441 = load i32, i32* %440, align 4
  %442 = add i32 %441, 1
  %443 = zext i32 %442 to i64
  store i64 %443, i64* %RAX, align 8, !tbaa !2428
  %444 = icmp eq i32 %441, -1
  %445 = icmp eq i32 %442, 0
  %446 = or i1 %444, %445
  %447 = zext i1 %446 to i8
  store i8 %447, i8* %50, align 1, !tbaa !2432
  %448 = and i32 %442, 255
  %449 = tail call i32 @llvm.ctpop.i32(i32 %448) #11
  %450 = trunc i32 %449 to i8
  %451 = and i8 %450, 1
  %452 = xor i8 %451, 1
  store i8 %452, i8* %51, align 1, !tbaa !2446
  %453 = xor i32 %442, %441
  %454 = lshr i32 %453, 4
  %455 = trunc i32 %454 to i8
  %456 = and i8 %455, 1
  store i8 %456, i8* %52, align 1, !tbaa !2447
  %457 = zext i1 %445 to i8
  store i8 %457, i8* %53, align 1, !tbaa !2448
  %458 = lshr i32 %442, 31
  %459 = trunc i32 %458 to i8
  store i8 %459, i8* %54, align 1, !tbaa !2449
  %460 = lshr i32 %441, 31
  %461 = xor i32 %458, %460
  %462 = add nuw nsw i32 %461, %458
  %463 = icmp eq i32 %462, 2
  %464 = zext i1 %463 to i8
  store i8 %464, i8* %55, align 1, !tbaa !2450
  %465 = sext i32 %442 to i64
  store i64 %465, i64* %RDX, align 8, !tbaa !2428
  %466 = shl nsw i64 %465, 3
  %467 = add i64 %466, %437
  %468 = add i64 %430, 23
  store i64 %468, i64* %PC, align 8
  %469 = inttoptr i64 %467 to i64*
  store i64 %433, i64* %469, align 8
  %470 = load i64, i64* %RBP, align 8
  %471 = add i64 %470, -36
  %472 = load i64, i64* %PC, align 8
  %473 = add i64 %472, 3
  store i64 %473, i64* %PC, align 8
  %474 = inttoptr i64 %471 to i32*
  %475 = load i32, i32* %474, align 4
  %476 = add i32 %475, 1
  %477 = zext i32 %476 to i64
  store i64 %477, i64* %RAX, align 8, !tbaa !2428
  %478 = icmp eq i32 %475, -1
  %479 = icmp eq i32 %476, 0
  %480 = or i1 %478, %479
  %481 = zext i1 %480 to i8
  store i8 %481, i8* %50, align 1, !tbaa !2432
  %482 = and i32 %476, 255
  %483 = tail call i32 @llvm.ctpop.i32(i32 %482) #11
  %484 = trunc i32 %483 to i8
  %485 = and i8 %484, 1
  %486 = xor i8 %485, 1
  store i8 %486, i8* %51, align 1, !tbaa !2446
  %487 = xor i32 %476, %475
  %488 = lshr i32 %487, 4
  %489 = trunc i32 %488 to i8
  %490 = and i8 %489, 1
  store i8 %490, i8* %52, align 1, !tbaa !2447
  %491 = zext i1 %479 to i8
  store i8 %491, i8* %53, align 1, !tbaa !2448
  %492 = lshr i32 %476, 31
  %493 = trunc i32 %492 to i8
  store i8 %493, i8* %54, align 1, !tbaa !2449
  %494 = lshr i32 %475, 31
  %495 = xor i32 %492, %494
  %496 = add nuw nsw i32 %495, %492
  %497 = icmp eq i32 %496, 2
  %498 = zext i1 %497 to i8
  store i8 %498, i8* %55, align 1, !tbaa !2450
  %499 = add i64 %472, 9
  store i64 %499, i64* %PC, align 8
  store i32 %476, i32* %474, align 4
  %500 = load i64, i64* %PC, align 8
  %501 = add i64 %500, -1008
  store i64 %501, i64* %PC, align 8, !tbaa !2428
  br label %block_40129a

block_4012b9:                                     ; preds = %block_4012ad
  %502 = load i32, i32* %1943, align 4
  %503 = shl i32 %502, 1
  %504 = icmp slt i32 %502, 0
  %505 = icmp slt i32 %503, 0
  %506 = xor i1 %504, %505
  %507 = zext i32 %503 to i64
  store i64 %507, i64* %RAX, align 8, !tbaa !2428
  %.lobit14 = lshr i32 %502, 31
  %508 = trunc i32 %.lobit14 to i8
  store i8 %508, i8* %50, align 1, !tbaa !2453
  %509 = and i32 %503, 254
  %510 = tail call i32 @llvm.ctpop.i32(i32 %509) #11
  %511 = trunc i32 %510 to i8
  %512 = and i8 %511, 1
  %513 = xor i8 %512, 1
  store i8 %513, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %514 = icmp eq i32 %503, 0
  %515 = zext i1 %514 to i8
  store i8 %515, i8* %53, align 1, !tbaa !2453
  %516 = lshr i32 %502, 30
  %517 = trunc i32 %516 to i8
  %518 = and i8 %517, 1
  store i8 %518, i8* %54, align 1, !tbaa !2453
  %519 = zext i1 %506 to i8
  store i8 %519, i8* %55, align 1, !tbaa !2453
  %520 = add i64 %1940, -16
  %521 = add i64 %1976, 10
  store i64 %521, i64* %PC, align 8
  %522 = inttoptr i64 %520 to i64*
  %523 = load i64, i64* %522, align 8
  store i64 %523, i64* %RCX, align 8, !tbaa !2428
  %524 = add i64 %1976, 14
  store i64 %524, i64* %PC, align 8
  %525 = load i32, i32* %1948, align 4
  %526 = sext i32 %525 to i64
  store i64 %526, i64* %RDX, align 8, !tbaa !2428
  %527 = shl nsw i64 %526, 2
  %528 = add i64 %527, %523
  %529 = add i64 %1976, 17
  store i64 %529, i64* %PC, align 8
  %530 = inttoptr i64 %528 to i32*
  %531 = load i32, i32* %530, align 4
  %532 = add i32 %531, %503
  %533 = zext i32 %532 to i64
  store i64 %533, i64* %RAX, align 8, !tbaa !2428
  %534 = icmp ult i32 %532, %503
  %535 = icmp ult i32 %532, %531
  %536 = or i1 %534, %535
  %537 = zext i1 %536 to i8
  store i8 %537, i8* %50, align 1, !tbaa !2432
  %538 = and i32 %532, 255
  %539 = tail call i32 @llvm.ctpop.i32(i32 %538) #11
  %540 = trunc i32 %539 to i8
  %541 = and i8 %540, 1
  %542 = xor i8 %541, 1
  store i8 %542, i8* %51, align 1, !tbaa !2446
  %543 = xor i32 %531, %503
  %544 = xor i32 %543, %532
  %545 = lshr i32 %544, 4
  %546 = trunc i32 %545 to i8
  %547 = and i8 %546, 1
  store i8 %547, i8* %52, align 1, !tbaa !2447
  %548 = icmp eq i32 %532, 0
  %549 = zext i1 %548 to i8
  store i8 %549, i8* %53, align 1, !tbaa !2448
  %550 = lshr i32 %532, 31
  %551 = trunc i32 %550 to i8
  store i8 %551, i8* %54, align 1, !tbaa !2449
  %552 = and i32 %516, 1
  %553 = lshr i32 %531, 31
  %554 = xor i32 %550, %552
  %555 = xor i32 %550, %553
  %556 = add nuw nsw i32 %554, %555
  %557 = icmp eq i32 %556, 2
  %558 = zext i1 %557 to i8
  store i8 %558, i8* %55, align 1, !tbaa !2450
  %559 = add i64 %1940, -32
  %560 = add i64 %1976, 20
  store i64 %560, i64* %PC, align 8
  %561 = inttoptr i64 %559 to i32*
  store i32 %532, i32* %561, align 4
  %562 = load i64, i64* %RBP, align 8
  %563 = add i64 %562, -36
  %564 = load i64, i64* %PC, align 8
  %565 = add i64 %564, 3
  store i64 %565, i64* %PC, align 8
  %566 = inttoptr i64 %563 to i32*
  %567 = load i32, i32* %566, align 4
  %568 = shl i32 %567, 1
  %569 = icmp slt i32 %567, 0
  %570 = icmp slt i32 %568, 0
  %571 = xor i1 %569, %570
  %572 = zext i32 %568 to i64
  store i64 %572, i64* %RAX, align 8, !tbaa !2428
  %.lobit15 = lshr i32 %567, 31
  %573 = trunc i32 %.lobit15 to i8
  store i8 %573, i8* %50, align 1, !tbaa !2453
  %574 = and i32 %568, 254
  %575 = tail call i32 @llvm.ctpop.i32(i32 %574) #11
  %576 = trunc i32 %575 to i8
  %577 = and i8 %576, 1
  %578 = xor i8 %577, 1
  store i8 %578, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %579 = icmp eq i32 %568, 0
  %580 = zext i1 %579 to i8
  store i8 %580, i8* %53, align 1, !tbaa !2453
  %581 = lshr i32 %567, 30
  %582 = trunc i32 %581 to i8
  %583 = and i8 %582, 1
  store i8 %583, i8* %54, align 1, !tbaa !2453
  %584 = zext i1 %571 to i8
  store i8 %584, i8* %55, align 1, !tbaa !2453
  %585 = add i64 %562, -16
  %586 = add i64 %564, 10
  store i64 %586, i64* %PC, align 8
  %587 = inttoptr i64 %585 to i64*
  %588 = load i64, i64* %587, align 8
  store i64 %588, i64* %RCX, align 8, !tbaa !2428
  %589 = add i64 %562, -28
  %590 = add i64 %564, 14
  store i64 %590, i64* %PC, align 8
  %591 = inttoptr i64 %589 to i32*
  %592 = load i32, i32* %591, align 4
  %593 = sext i32 %592 to i64
  store i64 %593, i64* %RDX, align 8, !tbaa !2428
  %594 = shl nsw i64 %593, 2
  %595 = add i64 %594, %588
  %596 = add i64 %564, 17
  store i64 %596, i64* %PC, align 8
  %597 = inttoptr i64 %595 to i32*
  %598 = load i32, i32* %597, align 4
  %599 = add i32 %598, %568
  %600 = zext i32 %599 to i64
  store i64 %600, i64* %RAX, align 8, !tbaa !2428
  %601 = icmp ult i32 %599, %568
  %602 = icmp ult i32 %599, %598
  %603 = or i1 %601, %602
  %604 = zext i1 %603 to i8
  store i8 %604, i8* %50, align 1, !tbaa !2432
  %605 = and i32 %599, 255
  %606 = tail call i32 @llvm.ctpop.i32(i32 %605) #11
  %607 = trunc i32 %606 to i8
  %608 = and i8 %607, 1
  %609 = xor i8 %608, 1
  store i8 %609, i8* %51, align 1, !tbaa !2446
  %610 = xor i32 %598, %568
  %611 = xor i32 %610, %599
  %612 = lshr i32 %611, 4
  %613 = trunc i32 %612 to i8
  %614 = and i8 %613, 1
  store i8 %614, i8* %52, align 1, !tbaa !2447
  %615 = icmp eq i32 %599, 0
  %616 = zext i1 %615 to i8
  store i8 %616, i8* %53, align 1, !tbaa !2448
  %617 = lshr i32 %599, 31
  %618 = trunc i32 %617 to i8
  store i8 %618, i8* %54, align 1, !tbaa !2449
  %619 = and i32 %581, 1
  %620 = lshr i32 %598, 31
  %621 = xor i32 %617, %619
  %622 = xor i32 %617, %620
  %623 = add nuw nsw i32 %621, %622
  %624 = icmp eq i32 %623, 2
  %625 = zext i1 %624 to i8
  store i8 %625, i8* %55, align 1, !tbaa !2450
  %626 = add i64 %562, -40
  %627 = add i64 %564, 20
  store i64 %627, i64* %PC, align 8
  %628 = inttoptr i64 %626 to i32*
  store i32 %599, i32* %628, align 4
  %629 = load i64, i64* %RBP, align 8
  %630 = add i64 %629, -24
  %631 = load i64, i64* %PC, align 8
  %632 = add i64 %631, 4
  store i64 %632, i64* %PC, align 8
  %633 = inttoptr i64 %630 to i64*
  %634 = load i64, i64* %633, align 8
  store i64 %634, i64* %RCX, align 8, !tbaa !2428
  %635 = add i64 %629, -32
  %636 = add i64 %631, 8
  store i64 %636, i64* %PC, align 8
  %637 = inttoptr i64 %635 to i32*
  %638 = load i32, i32* %637, align 4
  %639 = sext i32 %638 to i64
  store i64 %639, i64* %RDX, align 8, !tbaa !2428
  %640 = shl nsw i64 %639, 3
  %641 = add i64 %640, %634
  %642 = add i64 %631, 13
  store i64 %642, i64* %PC, align 8
  %643 = inttoptr i64 %641 to i64*
  %644 = load i64, i64* %643, align 8
  store i64 %644, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %645 = add i64 %629, -64
  %646 = add i64 %631, 18
  store i64 %646, i64* %PC, align 8
  %647 = inttoptr i64 %645 to i64*
  store i64 %644, i64* %647, align 8
  %648 = load i64, i64* %RBP, align 8
  %649 = add i64 %648, -24
  %650 = load i64, i64* %PC, align 8
  %651 = add i64 %650, 4
  store i64 %651, i64* %PC, align 8
  %652 = inttoptr i64 %649 to i64*
  %653 = load i64, i64* %652, align 8
  store i64 %653, i64* %RCX, align 8, !tbaa !2428
  %654 = add i64 %648, -32
  %655 = add i64 %650, 7
  store i64 %655, i64* %PC, align 8
  %656 = inttoptr i64 %654 to i32*
  %657 = load i32, i32* %656, align 4
  %658 = add i32 %657, 1
  %659 = zext i32 %658 to i64
  store i64 %659, i64* %RAX, align 8, !tbaa !2428
  %660 = icmp eq i32 %657, -1
  %661 = icmp eq i32 %658, 0
  %662 = or i1 %660, %661
  %663 = zext i1 %662 to i8
  store i8 %663, i8* %50, align 1, !tbaa !2432
  %664 = and i32 %658, 255
  %665 = tail call i32 @llvm.ctpop.i32(i32 %664) #11
  %666 = trunc i32 %665 to i8
  %667 = and i8 %666, 1
  %668 = xor i8 %667, 1
  store i8 %668, i8* %51, align 1, !tbaa !2446
  %669 = xor i32 %658, %657
  %670 = lshr i32 %669, 4
  %671 = trunc i32 %670 to i8
  %672 = and i8 %671, 1
  store i8 %672, i8* %52, align 1, !tbaa !2447
  %673 = zext i1 %661 to i8
  store i8 %673, i8* %53, align 1, !tbaa !2448
  %674 = lshr i32 %658, 31
  %675 = trunc i32 %674 to i8
  store i8 %675, i8* %54, align 1, !tbaa !2449
  %676 = lshr i32 %657, 31
  %677 = xor i32 %674, %676
  %678 = add nuw nsw i32 %677, %674
  %679 = icmp eq i32 %678, 2
  %680 = zext i1 %679 to i8
  store i8 %680, i8* %55, align 1, !tbaa !2450
  %681 = sext i32 %658 to i64
  store i64 %681, i64* %RDX, align 8, !tbaa !2428
  %682 = shl nsw i64 %681, 3
  %683 = add i64 %682, %653
  %684 = add i64 %650, 18
  store i64 %684, i64* %PC, align 8
  %685 = inttoptr i64 %683 to i64*
  %686 = load i64, i64* %685, align 8
  store i64 %686, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %687 = add i64 %648, -72
  %688 = add i64 %650, 23
  store i64 %688, i64* %PC, align 8
  %689 = inttoptr i64 %687 to i64*
  store i64 %686, i64* %689, align 8
  %690 = load i64, i64* %RBP, align 8
  %691 = add i64 %690, -24
  %692 = load i64, i64* %PC, align 8
  %693 = add i64 %692, 4
  store i64 %693, i64* %PC, align 8
  %694 = inttoptr i64 %691 to i64*
  %695 = load i64, i64* %694, align 8
  store i64 %695, i64* %RCX, align 8, !tbaa !2428
  %696 = add i64 %690, -40
  %697 = add i64 %692, 8
  store i64 %697, i64* %PC, align 8
  %698 = inttoptr i64 %696 to i32*
  %699 = load i32, i32* %698, align 4
  %700 = sext i32 %699 to i64
  store i64 %700, i64* %RDX, align 8, !tbaa !2428
  %701 = shl nsw i64 %700, 3
  %702 = add i64 %701, %695
  %703 = add i64 %692, 13
  store i64 %703, i64* %PC, align 8
  %704 = inttoptr i64 %702 to i64*
  %705 = load i64, i64* %704, align 8
  store i64 %705, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %706 = add i64 %690, -80
  %707 = add i64 %692, 18
  store i64 %707, i64* %PC, align 8
  %708 = inttoptr i64 %706 to i64*
  store i64 %705, i64* %708, align 8
  %709 = load i64, i64* %RBP, align 8
  %710 = add i64 %709, -24
  %711 = load i64, i64* %PC, align 8
  %712 = add i64 %711, 4
  store i64 %712, i64* %PC, align 8
  %713 = inttoptr i64 %710 to i64*
  %714 = load i64, i64* %713, align 8
  store i64 %714, i64* %RCX, align 8, !tbaa !2428
  %715 = add i64 %709, -40
  %716 = add i64 %711, 7
  store i64 %716, i64* %PC, align 8
  %717 = inttoptr i64 %715 to i32*
  %718 = load i32, i32* %717, align 4
  %719 = add i32 %718, 1
  %720 = zext i32 %719 to i64
  store i64 %720, i64* %RAX, align 8, !tbaa !2428
  %721 = icmp eq i32 %718, -1
  %722 = icmp eq i32 %719, 0
  %723 = or i1 %721, %722
  %724 = zext i1 %723 to i8
  store i8 %724, i8* %50, align 1, !tbaa !2432
  %725 = and i32 %719, 255
  %726 = tail call i32 @llvm.ctpop.i32(i32 %725) #11
  %727 = trunc i32 %726 to i8
  %728 = and i8 %727, 1
  %729 = xor i8 %728, 1
  store i8 %729, i8* %51, align 1, !tbaa !2446
  %730 = xor i32 %719, %718
  %731 = lshr i32 %730, 4
  %732 = trunc i32 %731 to i8
  %733 = and i8 %732, 1
  store i8 %733, i8* %52, align 1, !tbaa !2447
  %734 = zext i1 %722 to i8
  store i8 %734, i8* %53, align 1, !tbaa !2448
  %735 = lshr i32 %719, 31
  %736 = trunc i32 %735 to i8
  store i8 %736, i8* %54, align 1, !tbaa !2449
  %737 = lshr i32 %718, 31
  %738 = xor i32 %735, %737
  %739 = add nuw nsw i32 %738, %735
  %740 = icmp eq i32 %739, 2
  %741 = zext i1 %740 to i8
  store i8 %741, i8* %55, align 1, !tbaa !2450
  %742 = sext i32 %719 to i64
  store i64 %742, i64* %RDX, align 8, !tbaa !2428
  %743 = shl nsw i64 %742, 3
  %744 = add i64 %743, %714
  %745 = add i64 %711, 18
  store i64 %745, i64* %PC, align 8
  %746 = inttoptr i64 %744 to i64*
  %747 = load i64, i64* %746, align 8
  store i64 %747, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %748 = add i64 %709, -88
  %749 = add i64 %711, 23
  store i64 %749, i64* %PC, align 8
  %750 = inttoptr i64 %748 to i64*
  store i64 %747, i64* %750, align 8
  %751 = load i64, i64* %RBP, align 8
  %752 = add i64 %751, -80
  %753 = load i64, i64* %PC, align 8
  %754 = add i64 %753, 5
  store i64 %754, i64* %PC, align 8
  %755 = inttoptr i64 %752 to i64*
  %756 = load i64, i64* %755, align 8
  store i64 %756, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %757 = add i64 %751, -24
  %758 = add i64 %753, 9
  store i64 %758, i64* %PC, align 8
  %759 = inttoptr i64 %757 to i64*
  %760 = load i64, i64* %759, align 8
  store i64 %760, i64* %RCX, align 8, !tbaa !2428
  %761 = add i64 %751, -32
  %762 = add i64 %753, 13
  store i64 %762, i64* %PC, align 8
  %763 = inttoptr i64 %761 to i32*
  %764 = load i32, i32* %763, align 4
  %765 = sext i32 %764 to i64
  store i64 %765, i64* %RDX, align 8, !tbaa !2428
  %766 = shl nsw i64 %765, 3
  %767 = add i64 %766, %760
  %768 = add i64 %753, 18
  store i64 %768, i64* %PC, align 8
  %769 = inttoptr i64 %767 to i64*
  store i64 %756, i64* %769, align 8
  %770 = load i64, i64* %RBP, align 8
  %771 = add i64 %770, -88
  %772 = load i64, i64* %PC, align 8
  %773 = add i64 %772, 5
  store i64 %773, i64* %PC, align 8
  %774 = inttoptr i64 %771 to i64*
  %775 = load i64, i64* %774, align 8
  store i64 %775, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %776 = add i64 %770, -24
  %777 = add i64 %772, 9
  store i64 %777, i64* %PC, align 8
  %778 = inttoptr i64 %776 to i64*
  %779 = load i64, i64* %778, align 8
  store i64 %779, i64* %RCX, align 8, !tbaa !2428
  %780 = add i64 %770, -32
  %781 = add i64 %772, 12
  store i64 %781, i64* %PC, align 8
  %782 = inttoptr i64 %780 to i32*
  %783 = load i32, i32* %782, align 4
  %784 = add i32 %783, 1
  %785 = zext i32 %784 to i64
  store i64 %785, i64* %RAX, align 8, !tbaa !2428
  %786 = icmp eq i32 %783, -1
  %787 = icmp eq i32 %784, 0
  %788 = or i1 %786, %787
  %789 = zext i1 %788 to i8
  store i8 %789, i8* %50, align 1, !tbaa !2432
  %790 = and i32 %784, 255
  %791 = tail call i32 @llvm.ctpop.i32(i32 %790) #11
  %792 = trunc i32 %791 to i8
  %793 = and i8 %792, 1
  %794 = xor i8 %793, 1
  store i8 %794, i8* %51, align 1, !tbaa !2446
  %795 = xor i32 %784, %783
  %796 = lshr i32 %795, 4
  %797 = trunc i32 %796 to i8
  %798 = and i8 %797, 1
  store i8 %798, i8* %52, align 1, !tbaa !2447
  %799 = zext i1 %787 to i8
  store i8 %799, i8* %53, align 1, !tbaa !2448
  %800 = lshr i32 %784, 31
  %801 = trunc i32 %800 to i8
  store i8 %801, i8* %54, align 1, !tbaa !2449
  %802 = lshr i32 %783, 31
  %803 = xor i32 %800, %802
  %804 = add nuw nsw i32 %803, %800
  %805 = icmp eq i32 %804, 2
  %806 = zext i1 %805 to i8
  store i8 %806, i8* %55, align 1, !tbaa !2450
  %807 = sext i32 %784 to i64
  store i64 %807, i64* %RDX, align 8, !tbaa !2428
  %808 = shl nsw i64 %807, 3
  %809 = add i64 %808, %779
  %810 = add i64 %772, 23
  store i64 %810, i64* %PC, align 8
  %811 = inttoptr i64 %809 to i64*
  store i64 %775, i64* %811, align 8
  %812 = load i64, i64* %RBP, align 8
  %813 = add i64 %812, -64
  %814 = load i64, i64* %PC, align 8
  %815 = add i64 %814, 5
  store i64 %815, i64* %PC, align 8
  %816 = inttoptr i64 %813 to i64*
  %817 = load i64, i64* %816, align 8
  store i64 %817, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %818 = add i64 %812, -24
  %819 = add i64 %814, 9
  store i64 %819, i64* %PC, align 8
  %820 = inttoptr i64 %818 to i64*
  %821 = load i64, i64* %820, align 8
  store i64 %821, i64* %RCX, align 8, !tbaa !2428
  %822 = add i64 %812, -40
  %823 = add i64 %814, 13
  store i64 %823, i64* %PC, align 8
  %824 = inttoptr i64 %822 to i32*
  %825 = load i32, i32* %824, align 4
  %826 = sext i32 %825 to i64
  store i64 %826, i64* %RDX, align 8, !tbaa !2428
  %827 = shl nsw i64 %826, 3
  %828 = add i64 %827, %821
  %829 = add i64 %814, 18
  store i64 %829, i64* %PC, align 8
  %830 = inttoptr i64 %828 to i64*
  store i64 %817, i64* %830, align 8
  %831 = load i64, i64* %RBP, align 8
  %832 = add i64 %831, -72
  %833 = load i64, i64* %PC, align 8
  %834 = add i64 %833, 5
  store i64 %834, i64* %PC, align 8
  %835 = inttoptr i64 %832 to i64*
  %836 = load i64, i64* %835, align 8
  store i64 %836, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %837 = add i64 %831, -24
  %838 = add i64 %833, 9
  store i64 %838, i64* %PC, align 8
  %839 = inttoptr i64 %837 to i64*
  %840 = load i64, i64* %839, align 8
  store i64 %840, i64* %RCX, align 8, !tbaa !2428
  %841 = add i64 %831, -40
  %842 = add i64 %833, 12
  store i64 %842, i64* %PC, align 8
  %843 = inttoptr i64 %841 to i32*
  %844 = load i32, i32* %843, align 4
  %845 = add i32 %844, 1
  %846 = zext i32 %845 to i64
  store i64 %846, i64* %RAX, align 8, !tbaa !2428
  %847 = icmp eq i32 %844, -1
  %848 = icmp eq i32 %845, 0
  %849 = or i1 %847, %848
  %850 = zext i1 %849 to i8
  store i8 %850, i8* %50, align 1, !tbaa !2432
  %851 = and i32 %845, 255
  %852 = tail call i32 @llvm.ctpop.i32(i32 %851) #11
  %853 = trunc i32 %852 to i8
  %854 = and i8 %853, 1
  %855 = xor i8 %854, 1
  store i8 %855, i8* %51, align 1, !tbaa !2446
  %856 = xor i32 %845, %844
  %857 = lshr i32 %856, 4
  %858 = trunc i32 %857 to i8
  %859 = and i8 %858, 1
  store i8 %859, i8* %52, align 1, !tbaa !2447
  %860 = zext i1 %848 to i8
  store i8 %860, i8* %53, align 1, !tbaa !2448
  %861 = lshr i32 %845, 31
  %862 = trunc i32 %861 to i8
  store i8 %862, i8* %54, align 1, !tbaa !2449
  %863 = lshr i32 %844, 31
  %864 = xor i32 %861, %863
  %865 = add nuw nsw i32 %864, %861
  %866 = icmp eq i32 %865, 2
  %867 = zext i1 %866 to i8
  store i8 %867, i8* %55, align 1, !tbaa !2450
  %868 = sext i32 %845 to i64
  store i64 %868, i64* %RDX, align 8, !tbaa !2428
  %869 = shl nsw i64 %868, 3
  %870 = add i64 %869, %840
  %871 = add i64 %833, 23
  store i64 %871, i64* %PC, align 8
  %872 = inttoptr i64 %870 to i64*
  store i64 %836, i64* %872, align 8
  %873 = load i64, i64* %RBP, align 8
  %874 = add i64 %873, -52
  %875 = load i64, i64* %PC, align 8
  %876 = add i64 %875, 3
  store i64 %876, i64* %PC, align 8
  %877 = inttoptr i64 %874 to i32*
  %878 = load i32, i32* %877, align 4
  %879 = zext i32 %878 to i64
  store i64 %879, i64* %RAX, align 8, !tbaa !2428
  %880 = add i64 %873, -32
  %881 = add i64 %875, 6
  store i64 %881, i64* %PC, align 8
  %882 = inttoptr i64 %880 to i32*
  %883 = load i32, i32* %882, align 4
  %884 = add i32 %883, %878
  %885 = zext i32 %884 to i64
  store i64 %885, i64* %RAX, align 8, !tbaa !2428
  %886 = icmp ult i32 %884, %878
  %887 = icmp ult i32 %884, %883
  %888 = or i1 %886, %887
  %889 = zext i1 %888 to i8
  store i8 %889, i8* %50, align 1, !tbaa !2432
  %890 = and i32 %884, 255
  %891 = tail call i32 @llvm.ctpop.i32(i32 %890) #11
  %892 = trunc i32 %891 to i8
  %893 = and i8 %892, 1
  %894 = xor i8 %893, 1
  store i8 %894, i8* %51, align 1, !tbaa !2446
  %895 = xor i32 %883, %878
  %896 = xor i32 %895, %884
  %897 = lshr i32 %896, 4
  %898 = trunc i32 %897 to i8
  %899 = and i8 %898, 1
  store i8 %899, i8* %52, align 1, !tbaa !2447
  %900 = icmp eq i32 %884, 0
  %901 = zext i1 %900 to i8
  store i8 %901, i8* %53, align 1, !tbaa !2448
  %902 = lshr i32 %884, 31
  %903 = trunc i32 %902 to i8
  store i8 %903, i8* %54, align 1, !tbaa !2449
  %904 = lshr i32 %878, 31
  %905 = lshr i32 %883, 31
  %906 = xor i32 %902, %904
  %907 = xor i32 %902, %905
  %908 = add nuw nsw i32 %906, %907
  %909 = icmp eq i32 %908, 2
  %910 = zext i1 %909 to i8
  store i8 %910, i8* %55, align 1, !tbaa !2450
  %911 = add i64 %875, 9
  store i64 %911, i64* %PC, align 8
  store i32 %884, i32* %882, align 4
  %912 = load i64, i64* %RBP, align 8
  %913 = add i64 %912, -52
  %914 = load i64, i64* %PC, align 8
  %915 = add i64 %914, 3
  store i64 %915, i64* %PC, align 8
  %916 = inttoptr i64 %913 to i32*
  %917 = load i32, i32* %916, align 4
  %918 = shl i32 %917, 1
  %919 = icmp slt i32 %917, 0
  %920 = icmp slt i32 %918, 0
  %921 = xor i1 %919, %920
  %922 = zext i32 %918 to i64
  store i64 %922, i64* %RAX, align 8, !tbaa !2428
  %.lobit16 = lshr i32 %917, 31
  %923 = trunc i32 %.lobit16 to i8
  store i8 %923, i8* %50, align 1, !tbaa !2453
  %924 = and i32 %918, 254
  %925 = tail call i32 @llvm.ctpop.i32(i32 %924) #11
  %926 = trunc i32 %925 to i8
  %927 = and i8 %926, 1
  %928 = xor i8 %927, 1
  store i8 %928, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %929 = icmp eq i32 %918, 0
  %930 = zext i1 %929 to i8
  store i8 %930, i8* %53, align 1, !tbaa !2453
  %931 = lshr i32 %917, 30
  %932 = trunc i32 %931 to i8
  %933 = and i8 %932, 1
  store i8 %933, i8* %54, align 1, !tbaa !2453
  %934 = zext i1 %921 to i8
  store i8 %934, i8* %55, align 1, !tbaa !2453
  %935 = add i64 %912, -40
  %936 = add i64 %914, 9
  store i64 %936, i64* %PC, align 8
  %937 = inttoptr i64 %935 to i32*
  %938 = load i32, i32* %937, align 4
  %939 = add i32 %938, %918
  %940 = zext i32 %939 to i64
  store i64 %940, i64* %RAX, align 8, !tbaa !2428
  %941 = icmp ult i32 %939, %918
  %942 = icmp ult i32 %939, %938
  %943 = or i1 %941, %942
  %944 = zext i1 %943 to i8
  store i8 %944, i8* %50, align 1, !tbaa !2432
  %945 = and i32 %939, 255
  %946 = tail call i32 @llvm.ctpop.i32(i32 %945) #11
  %947 = trunc i32 %946 to i8
  %948 = and i8 %947, 1
  %949 = xor i8 %948, 1
  store i8 %949, i8* %51, align 1, !tbaa !2446
  %950 = xor i32 %938, %918
  %951 = xor i32 %950, %939
  %952 = lshr i32 %951, 4
  %953 = trunc i32 %952 to i8
  %954 = and i8 %953, 1
  store i8 %954, i8* %52, align 1, !tbaa !2447
  %955 = icmp eq i32 %939, 0
  %956 = zext i1 %955 to i8
  store i8 %956, i8* %53, align 1, !tbaa !2448
  %957 = lshr i32 %939, 31
  %958 = trunc i32 %957 to i8
  store i8 %958, i8* %54, align 1, !tbaa !2449
  %959 = and i32 %931, 1
  %960 = lshr i32 %938, 31
  %961 = xor i32 %957, %959
  %962 = xor i32 %957, %960
  %963 = add nuw nsw i32 %961, %962
  %964 = icmp eq i32 %963, 2
  %965 = zext i1 %964 to i8
  store i8 %965, i8* %55, align 1, !tbaa !2450
  %966 = add i64 %914, 12
  store i64 %966, i64* %PC, align 8
  store i32 %939, i32* %937, align 4
  %967 = load i64, i64* %RBP, align 8
  %968 = add i64 %967, -24
  %969 = load i64, i64* %PC, align 8
  %970 = add i64 %969, 4
  store i64 %970, i64* %PC, align 8
  %971 = inttoptr i64 %968 to i64*
  %972 = load i64, i64* %971, align 8
  store i64 %972, i64* %RCX, align 8, !tbaa !2428
  %973 = add i64 %967, -32
  %974 = add i64 %969, 8
  store i64 %974, i64* %PC, align 8
  %975 = inttoptr i64 %973 to i32*
  %976 = load i32, i32* %975, align 4
  %977 = sext i32 %976 to i64
  store i64 %977, i64* %RDX, align 8, !tbaa !2428
  %978 = shl nsw i64 %977, 3
  %979 = add i64 %978, %972
  %980 = add i64 %969, 13
  store i64 %980, i64* %PC, align 8
  %981 = inttoptr i64 %979 to i64*
  %982 = load i64, i64* %981, align 8
  store i64 %982, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %983 = add i64 %967, -64
  %984 = add i64 %969, 18
  store i64 %984, i64* %PC, align 8
  %985 = inttoptr i64 %983 to i64*
  store i64 %982, i64* %985, align 8
  %986 = load i64, i64* %RBP, align 8
  %987 = add i64 %986, -24
  %988 = load i64, i64* %PC, align 8
  %989 = add i64 %988, 4
  store i64 %989, i64* %PC, align 8
  %990 = inttoptr i64 %987 to i64*
  %991 = load i64, i64* %990, align 8
  store i64 %991, i64* %RCX, align 8, !tbaa !2428
  %992 = add i64 %986, -32
  %993 = add i64 %988, 7
  store i64 %993, i64* %PC, align 8
  %994 = inttoptr i64 %992 to i32*
  %995 = load i32, i32* %994, align 4
  %996 = add i32 %995, 1
  %997 = zext i32 %996 to i64
  store i64 %997, i64* %RAX, align 8, !tbaa !2428
  %998 = icmp eq i32 %995, -1
  %999 = icmp eq i32 %996, 0
  %1000 = or i1 %998, %999
  %1001 = zext i1 %1000 to i8
  store i8 %1001, i8* %50, align 1, !tbaa !2432
  %1002 = and i32 %996, 255
  %1003 = tail call i32 @llvm.ctpop.i32(i32 %1002) #11
  %1004 = trunc i32 %1003 to i8
  %1005 = and i8 %1004, 1
  %1006 = xor i8 %1005, 1
  store i8 %1006, i8* %51, align 1, !tbaa !2446
  %1007 = xor i32 %996, %995
  %1008 = lshr i32 %1007, 4
  %1009 = trunc i32 %1008 to i8
  %1010 = and i8 %1009, 1
  store i8 %1010, i8* %52, align 1, !tbaa !2447
  %1011 = zext i1 %999 to i8
  store i8 %1011, i8* %53, align 1, !tbaa !2448
  %1012 = lshr i32 %996, 31
  %1013 = trunc i32 %1012 to i8
  store i8 %1013, i8* %54, align 1, !tbaa !2449
  %1014 = lshr i32 %995, 31
  %1015 = xor i32 %1012, %1014
  %1016 = add nuw nsw i32 %1015, %1012
  %1017 = icmp eq i32 %1016, 2
  %1018 = zext i1 %1017 to i8
  store i8 %1018, i8* %55, align 1, !tbaa !2450
  %1019 = sext i32 %996 to i64
  store i64 %1019, i64* %RDX, align 8, !tbaa !2428
  %1020 = shl nsw i64 %1019, 3
  %1021 = add i64 %1020, %991
  %1022 = add i64 %988, 18
  store i64 %1022, i64* %PC, align 8
  %1023 = inttoptr i64 %1021 to i64*
  %1024 = load i64, i64* %1023, align 8
  store i64 %1024, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1025 = add i64 %986, -72
  %1026 = add i64 %988, 23
  store i64 %1026, i64* %PC, align 8
  %1027 = inttoptr i64 %1025 to i64*
  store i64 %1024, i64* %1027, align 8
  %1028 = load i64, i64* %RBP, align 8
  %1029 = add i64 %1028, -24
  %1030 = load i64, i64* %PC, align 8
  %1031 = add i64 %1030, 4
  store i64 %1031, i64* %PC, align 8
  %1032 = inttoptr i64 %1029 to i64*
  %1033 = load i64, i64* %1032, align 8
  store i64 %1033, i64* %RCX, align 8, !tbaa !2428
  %1034 = add i64 %1028, -40
  %1035 = add i64 %1030, 8
  store i64 %1035, i64* %PC, align 8
  %1036 = inttoptr i64 %1034 to i32*
  %1037 = load i32, i32* %1036, align 4
  %1038 = sext i32 %1037 to i64
  store i64 %1038, i64* %RDX, align 8, !tbaa !2428
  %1039 = shl nsw i64 %1038, 3
  %1040 = add i64 %1039, %1033
  %1041 = add i64 %1030, 13
  store i64 %1041, i64* %PC, align 8
  %1042 = inttoptr i64 %1040 to i64*
  %1043 = load i64, i64* %1042, align 8
  store i64 %1043, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1044 = add i64 %1028, -80
  %1045 = add i64 %1030, 18
  store i64 %1045, i64* %PC, align 8
  %1046 = inttoptr i64 %1044 to i64*
  store i64 %1043, i64* %1046, align 8
  %1047 = load i64, i64* %RBP, align 8
  %1048 = add i64 %1047, -24
  %1049 = load i64, i64* %PC, align 8
  %1050 = add i64 %1049, 4
  store i64 %1050, i64* %PC, align 8
  %1051 = inttoptr i64 %1048 to i64*
  %1052 = load i64, i64* %1051, align 8
  store i64 %1052, i64* %RCX, align 8, !tbaa !2428
  %1053 = add i64 %1047, -40
  %1054 = add i64 %1049, 7
  store i64 %1054, i64* %PC, align 8
  %1055 = inttoptr i64 %1053 to i32*
  %1056 = load i32, i32* %1055, align 4
  %1057 = add i32 %1056, 1
  %1058 = zext i32 %1057 to i64
  store i64 %1058, i64* %RAX, align 8, !tbaa !2428
  %1059 = icmp eq i32 %1056, -1
  %1060 = icmp eq i32 %1057, 0
  %1061 = or i1 %1059, %1060
  %1062 = zext i1 %1061 to i8
  store i8 %1062, i8* %50, align 1, !tbaa !2432
  %1063 = and i32 %1057, 255
  %1064 = tail call i32 @llvm.ctpop.i32(i32 %1063) #11
  %1065 = trunc i32 %1064 to i8
  %1066 = and i8 %1065, 1
  %1067 = xor i8 %1066, 1
  store i8 %1067, i8* %51, align 1, !tbaa !2446
  %1068 = xor i32 %1057, %1056
  %1069 = lshr i32 %1068, 4
  %1070 = trunc i32 %1069 to i8
  %1071 = and i8 %1070, 1
  store i8 %1071, i8* %52, align 1, !tbaa !2447
  %1072 = zext i1 %1060 to i8
  store i8 %1072, i8* %53, align 1, !tbaa !2448
  %1073 = lshr i32 %1057, 31
  %1074 = trunc i32 %1073 to i8
  store i8 %1074, i8* %54, align 1, !tbaa !2449
  %1075 = lshr i32 %1056, 31
  %1076 = xor i32 %1073, %1075
  %1077 = add nuw nsw i32 %1076, %1073
  %1078 = icmp eq i32 %1077, 2
  %1079 = zext i1 %1078 to i8
  store i8 %1079, i8* %55, align 1, !tbaa !2450
  %1080 = sext i32 %1057 to i64
  store i64 %1080, i64* %RDX, align 8, !tbaa !2428
  %1081 = shl nsw i64 %1080, 3
  %1082 = add i64 %1081, %1052
  %1083 = add i64 %1049, 18
  store i64 %1083, i64* %PC, align 8
  %1084 = inttoptr i64 %1082 to i64*
  %1085 = load i64, i64* %1084, align 8
  store i64 %1085, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1086 = add i64 %1047, -88
  %1087 = add i64 %1049, 23
  store i64 %1087, i64* %PC, align 8
  %1088 = inttoptr i64 %1086 to i64*
  store i64 %1085, i64* %1088, align 8
  %1089 = load i64, i64* %RBP, align 8
  %1090 = add i64 %1089, -80
  %1091 = load i64, i64* %PC, align 8
  %1092 = add i64 %1091, 5
  store i64 %1092, i64* %PC, align 8
  %1093 = inttoptr i64 %1090 to i64*
  %1094 = load i64, i64* %1093, align 8
  store i64 %1094, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1095 = add i64 %1089, -24
  %1096 = add i64 %1091, 9
  store i64 %1096, i64* %PC, align 8
  %1097 = inttoptr i64 %1095 to i64*
  %1098 = load i64, i64* %1097, align 8
  store i64 %1098, i64* %RCX, align 8, !tbaa !2428
  %1099 = add i64 %1089, -32
  %1100 = add i64 %1091, 13
  store i64 %1100, i64* %PC, align 8
  %1101 = inttoptr i64 %1099 to i32*
  %1102 = load i32, i32* %1101, align 4
  %1103 = sext i32 %1102 to i64
  store i64 %1103, i64* %RDX, align 8, !tbaa !2428
  %1104 = shl nsw i64 %1103, 3
  %1105 = add i64 %1104, %1098
  %1106 = add i64 %1091, 18
  store i64 %1106, i64* %PC, align 8
  %1107 = inttoptr i64 %1105 to i64*
  store i64 %1094, i64* %1107, align 8
  %1108 = load i64, i64* %RBP, align 8
  %1109 = add i64 %1108, -88
  %1110 = load i64, i64* %PC, align 8
  %1111 = add i64 %1110, 5
  store i64 %1111, i64* %PC, align 8
  %1112 = inttoptr i64 %1109 to i64*
  %1113 = load i64, i64* %1112, align 8
  store i64 %1113, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1114 = add i64 %1108, -24
  %1115 = add i64 %1110, 9
  store i64 %1115, i64* %PC, align 8
  %1116 = inttoptr i64 %1114 to i64*
  %1117 = load i64, i64* %1116, align 8
  store i64 %1117, i64* %RCX, align 8, !tbaa !2428
  %1118 = add i64 %1108, -32
  %1119 = add i64 %1110, 12
  store i64 %1119, i64* %PC, align 8
  %1120 = inttoptr i64 %1118 to i32*
  %1121 = load i32, i32* %1120, align 4
  %1122 = add i32 %1121, 1
  %1123 = zext i32 %1122 to i64
  store i64 %1123, i64* %RAX, align 8, !tbaa !2428
  %1124 = icmp eq i32 %1121, -1
  %1125 = icmp eq i32 %1122, 0
  %1126 = or i1 %1124, %1125
  %1127 = zext i1 %1126 to i8
  store i8 %1127, i8* %50, align 1, !tbaa !2432
  %1128 = and i32 %1122, 255
  %1129 = tail call i32 @llvm.ctpop.i32(i32 %1128) #11
  %1130 = trunc i32 %1129 to i8
  %1131 = and i8 %1130, 1
  %1132 = xor i8 %1131, 1
  store i8 %1132, i8* %51, align 1, !tbaa !2446
  %1133 = xor i32 %1122, %1121
  %1134 = lshr i32 %1133, 4
  %1135 = trunc i32 %1134 to i8
  %1136 = and i8 %1135, 1
  store i8 %1136, i8* %52, align 1, !tbaa !2447
  %1137 = zext i1 %1125 to i8
  store i8 %1137, i8* %53, align 1, !tbaa !2448
  %1138 = lshr i32 %1122, 31
  %1139 = trunc i32 %1138 to i8
  store i8 %1139, i8* %54, align 1, !tbaa !2449
  %1140 = lshr i32 %1121, 31
  %1141 = xor i32 %1138, %1140
  %1142 = add nuw nsw i32 %1141, %1138
  %1143 = icmp eq i32 %1142, 2
  %1144 = zext i1 %1143 to i8
  store i8 %1144, i8* %55, align 1, !tbaa !2450
  %1145 = sext i32 %1122 to i64
  store i64 %1145, i64* %RDX, align 8, !tbaa !2428
  %1146 = shl nsw i64 %1145, 3
  %1147 = add i64 %1146, %1117
  %1148 = add i64 %1110, 23
  store i64 %1148, i64* %PC, align 8
  %1149 = inttoptr i64 %1147 to i64*
  store i64 %1113, i64* %1149, align 8
  %1150 = load i64, i64* %RBP, align 8
  %1151 = add i64 %1150, -64
  %1152 = load i64, i64* %PC, align 8
  %1153 = add i64 %1152, 5
  store i64 %1153, i64* %PC, align 8
  %1154 = inttoptr i64 %1151 to i64*
  %1155 = load i64, i64* %1154, align 8
  store i64 %1155, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1156 = add i64 %1150, -24
  %1157 = add i64 %1152, 9
  store i64 %1157, i64* %PC, align 8
  %1158 = inttoptr i64 %1156 to i64*
  %1159 = load i64, i64* %1158, align 8
  store i64 %1159, i64* %RCX, align 8, !tbaa !2428
  %1160 = add i64 %1150, -40
  %1161 = add i64 %1152, 13
  store i64 %1161, i64* %PC, align 8
  %1162 = inttoptr i64 %1160 to i32*
  %1163 = load i32, i32* %1162, align 4
  %1164 = sext i32 %1163 to i64
  store i64 %1164, i64* %RDX, align 8, !tbaa !2428
  %1165 = shl nsw i64 %1164, 3
  %1166 = add i64 %1165, %1159
  %1167 = add i64 %1152, 18
  store i64 %1167, i64* %PC, align 8
  %1168 = inttoptr i64 %1166 to i64*
  store i64 %1155, i64* %1168, align 8
  %1169 = load i64, i64* %RBP, align 8
  %1170 = add i64 %1169, -72
  %1171 = load i64, i64* %PC, align 8
  %1172 = add i64 %1171, 5
  store i64 %1172, i64* %PC, align 8
  %1173 = inttoptr i64 %1170 to i64*
  %1174 = load i64, i64* %1173, align 8
  store i64 %1174, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1175 = add i64 %1169, -24
  %1176 = add i64 %1171, 9
  store i64 %1176, i64* %PC, align 8
  %1177 = inttoptr i64 %1175 to i64*
  %1178 = load i64, i64* %1177, align 8
  store i64 %1178, i64* %RCX, align 8, !tbaa !2428
  %1179 = add i64 %1169, -40
  %1180 = add i64 %1171, 12
  store i64 %1180, i64* %PC, align 8
  %1181 = inttoptr i64 %1179 to i32*
  %1182 = load i32, i32* %1181, align 4
  %1183 = add i32 %1182, 1
  %1184 = zext i32 %1183 to i64
  store i64 %1184, i64* %RAX, align 8, !tbaa !2428
  %1185 = icmp eq i32 %1182, -1
  %1186 = icmp eq i32 %1183, 0
  %1187 = or i1 %1185, %1186
  %1188 = zext i1 %1187 to i8
  store i8 %1188, i8* %50, align 1, !tbaa !2432
  %1189 = and i32 %1183, 255
  %1190 = tail call i32 @llvm.ctpop.i32(i32 %1189) #11
  %1191 = trunc i32 %1190 to i8
  %1192 = and i8 %1191, 1
  %1193 = xor i8 %1192, 1
  store i8 %1193, i8* %51, align 1, !tbaa !2446
  %1194 = xor i32 %1183, %1182
  %1195 = lshr i32 %1194, 4
  %1196 = trunc i32 %1195 to i8
  %1197 = and i8 %1196, 1
  store i8 %1197, i8* %52, align 1, !tbaa !2447
  %1198 = zext i1 %1186 to i8
  store i8 %1198, i8* %53, align 1, !tbaa !2448
  %1199 = lshr i32 %1183, 31
  %1200 = trunc i32 %1199 to i8
  store i8 %1200, i8* %54, align 1, !tbaa !2449
  %1201 = lshr i32 %1182, 31
  %1202 = xor i32 %1199, %1201
  %1203 = add nuw nsw i32 %1202, %1199
  %1204 = icmp eq i32 %1203, 2
  %1205 = zext i1 %1204 to i8
  store i8 %1205, i8* %55, align 1, !tbaa !2450
  %1206 = sext i32 %1183 to i64
  store i64 %1206, i64* %RDX, align 8, !tbaa !2428
  %1207 = shl nsw i64 %1206, 3
  %1208 = add i64 %1207, %1178
  %1209 = add i64 %1171, 23
  store i64 %1209, i64* %PC, align 8
  %1210 = inttoptr i64 %1208 to i64*
  store i64 %1174, i64* %1210, align 8
  %1211 = load i64, i64* %RBP, align 8
  %1212 = add i64 %1211, -52
  %1213 = load i64, i64* %PC, align 8
  %1214 = add i64 %1213, 3
  store i64 %1214, i64* %PC, align 8
  %1215 = inttoptr i64 %1212 to i32*
  %1216 = load i32, i32* %1215, align 4
  %1217 = zext i32 %1216 to i64
  store i64 %1217, i64* %RAX, align 8, !tbaa !2428
  %1218 = add i64 %1211, -32
  %1219 = add i64 %1213, 6
  store i64 %1219, i64* %PC, align 8
  %1220 = inttoptr i64 %1218 to i32*
  %1221 = load i32, i32* %1220, align 4
  %1222 = add i32 %1221, %1216
  %1223 = zext i32 %1222 to i64
  store i64 %1223, i64* %RAX, align 8, !tbaa !2428
  %1224 = icmp ult i32 %1222, %1216
  %1225 = icmp ult i32 %1222, %1221
  %1226 = or i1 %1224, %1225
  %1227 = zext i1 %1226 to i8
  store i8 %1227, i8* %50, align 1, !tbaa !2432
  %1228 = and i32 %1222, 255
  %1229 = tail call i32 @llvm.ctpop.i32(i32 %1228) #11
  %1230 = trunc i32 %1229 to i8
  %1231 = and i8 %1230, 1
  %1232 = xor i8 %1231, 1
  store i8 %1232, i8* %51, align 1, !tbaa !2446
  %1233 = xor i32 %1221, %1216
  %1234 = xor i32 %1233, %1222
  %1235 = lshr i32 %1234, 4
  %1236 = trunc i32 %1235 to i8
  %1237 = and i8 %1236, 1
  store i8 %1237, i8* %52, align 1, !tbaa !2447
  %1238 = icmp eq i32 %1222, 0
  %1239 = zext i1 %1238 to i8
  store i8 %1239, i8* %53, align 1, !tbaa !2448
  %1240 = lshr i32 %1222, 31
  %1241 = trunc i32 %1240 to i8
  store i8 %1241, i8* %54, align 1, !tbaa !2449
  %1242 = lshr i32 %1216, 31
  %1243 = lshr i32 %1221, 31
  %1244 = xor i32 %1240, %1242
  %1245 = xor i32 %1240, %1243
  %1246 = add nuw nsw i32 %1244, %1245
  %1247 = icmp eq i32 %1246, 2
  %1248 = zext i1 %1247 to i8
  store i8 %1248, i8* %55, align 1, !tbaa !2450
  %1249 = add i64 %1213, 9
  store i64 %1249, i64* %PC, align 8
  store i32 %1222, i32* %1220, align 4
  %1250 = load i64, i64* %RBP, align 8
  %1251 = add i64 %1250, -52
  %1252 = load i64, i64* %PC, align 8
  %1253 = add i64 %1252, 3
  store i64 %1253, i64* %PC, align 8
  %1254 = inttoptr i64 %1251 to i32*
  %1255 = load i32, i32* %1254, align 4
  %1256 = zext i32 %1255 to i64
  store i64 %1256, i64* %RAX, align 8, !tbaa !2428
  %1257 = add i64 %1250, -40
  %1258 = add i64 %1252, 6
  store i64 %1258, i64* %PC, align 8
  %1259 = inttoptr i64 %1257 to i32*
  %1260 = load i32, i32* %1259, align 4
  %1261 = sub i32 %1260, %1255
  %1262 = zext i32 %1261 to i64
  store i64 %1262, i64* %RSI, align 8, !tbaa !2428
  %1263 = icmp ult i32 %1260, %1255
  %1264 = zext i1 %1263 to i8
  store i8 %1264, i8* %50, align 1, !tbaa !2432
  %1265 = and i32 %1261, 255
  %1266 = tail call i32 @llvm.ctpop.i32(i32 %1265) #11
  %1267 = trunc i32 %1266 to i8
  %1268 = and i8 %1267, 1
  %1269 = xor i8 %1268, 1
  store i8 %1269, i8* %51, align 1, !tbaa !2446
  %1270 = xor i32 %1260, %1255
  %1271 = xor i32 %1270, %1261
  %1272 = lshr i32 %1271, 4
  %1273 = trunc i32 %1272 to i8
  %1274 = and i8 %1273, 1
  store i8 %1274, i8* %52, align 1, !tbaa !2447
  %1275 = icmp eq i32 %1261, 0
  %1276 = zext i1 %1275 to i8
  store i8 %1276, i8* %53, align 1, !tbaa !2448
  %1277 = lshr i32 %1261, 31
  %1278 = trunc i32 %1277 to i8
  store i8 %1278, i8* %54, align 1, !tbaa !2449
  %1279 = lshr i32 %1260, 31
  %1280 = lshr i32 %1255, 31
  %1281 = xor i32 %1279, %1280
  %1282 = xor i32 %1277, %1279
  %1283 = add nuw nsw i32 %1282, %1281
  %1284 = icmp eq i32 %1283, 2
  %1285 = zext i1 %1284 to i8
  store i8 %1285, i8* %55, align 1, !tbaa !2450
  %1286 = add i64 %1252, 11
  store i64 %1286, i64* %PC, align 8
  store i32 %1261, i32* %1259, align 4
  %1287 = load i64, i64* %RBP, align 8
  %1288 = add i64 %1287, -24
  %1289 = load i64, i64* %PC, align 8
  %1290 = add i64 %1289, 4
  store i64 %1290, i64* %PC, align 8
  %1291 = inttoptr i64 %1288 to i64*
  %1292 = load i64, i64* %1291, align 8
  store i64 %1292, i64* %RCX, align 8, !tbaa !2428
  %1293 = add i64 %1287, -32
  %1294 = add i64 %1289, 8
  store i64 %1294, i64* %PC, align 8
  %1295 = inttoptr i64 %1293 to i32*
  %1296 = load i32, i32* %1295, align 4
  %1297 = sext i32 %1296 to i64
  store i64 %1297, i64* %RDX, align 8, !tbaa !2428
  %1298 = shl nsw i64 %1297, 3
  %1299 = add i64 %1298, %1292
  %1300 = add i64 %1289, 13
  store i64 %1300, i64* %PC, align 8
  %1301 = inttoptr i64 %1299 to i64*
  %1302 = load i64, i64* %1301, align 8
  store i64 %1302, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1303 = add i64 %1287, -64
  %1304 = add i64 %1289, 18
  store i64 %1304, i64* %PC, align 8
  %1305 = inttoptr i64 %1303 to i64*
  store i64 %1302, i64* %1305, align 8
  %1306 = load i64, i64* %RBP, align 8
  %1307 = add i64 %1306, -24
  %1308 = load i64, i64* %PC, align 8
  %1309 = add i64 %1308, 4
  store i64 %1309, i64* %PC, align 8
  %1310 = inttoptr i64 %1307 to i64*
  %1311 = load i64, i64* %1310, align 8
  store i64 %1311, i64* %RCX, align 8, !tbaa !2428
  %1312 = add i64 %1306, -32
  %1313 = add i64 %1308, 7
  store i64 %1313, i64* %PC, align 8
  %1314 = inttoptr i64 %1312 to i32*
  %1315 = load i32, i32* %1314, align 4
  %1316 = add i32 %1315, 1
  %1317 = zext i32 %1316 to i64
  store i64 %1317, i64* %RAX, align 8, !tbaa !2428
  %1318 = icmp eq i32 %1315, -1
  %1319 = icmp eq i32 %1316, 0
  %1320 = or i1 %1318, %1319
  %1321 = zext i1 %1320 to i8
  store i8 %1321, i8* %50, align 1, !tbaa !2432
  %1322 = and i32 %1316, 255
  %1323 = tail call i32 @llvm.ctpop.i32(i32 %1322) #11
  %1324 = trunc i32 %1323 to i8
  %1325 = and i8 %1324, 1
  %1326 = xor i8 %1325, 1
  store i8 %1326, i8* %51, align 1, !tbaa !2446
  %1327 = xor i32 %1316, %1315
  %1328 = lshr i32 %1327, 4
  %1329 = trunc i32 %1328 to i8
  %1330 = and i8 %1329, 1
  store i8 %1330, i8* %52, align 1, !tbaa !2447
  %1331 = zext i1 %1319 to i8
  store i8 %1331, i8* %53, align 1, !tbaa !2448
  %1332 = lshr i32 %1316, 31
  %1333 = trunc i32 %1332 to i8
  store i8 %1333, i8* %54, align 1, !tbaa !2449
  %1334 = lshr i32 %1315, 31
  %1335 = xor i32 %1332, %1334
  %1336 = add nuw nsw i32 %1335, %1332
  %1337 = icmp eq i32 %1336, 2
  %1338 = zext i1 %1337 to i8
  store i8 %1338, i8* %55, align 1, !tbaa !2450
  %1339 = sext i32 %1316 to i64
  store i64 %1339, i64* %RDX, align 8, !tbaa !2428
  %1340 = shl nsw i64 %1339, 3
  %1341 = add i64 %1340, %1311
  %1342 = add i64 %1308, 18
  store i64 %1342, i64* %PC, align 8
  %1343 = inttoptr i64 %1341 to i64*
  %1344 = load i64, i64* %1343, align 8
  store i64 %1344, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1345 = add i64 %1306, -72
  %1346 = add i64 %1308, 23
  store i64 %1346, i64* %PC, align 8
  %1347 = inttoptr i64 %1345 to i64*
  store i64 %1344, i64* %1347, align 8
  %1348 = load i64, i64* %RBP, align 8
  %1349 = add i64 %1348, -24
  %1350 = load i64, i64* %PC, align 8
  %1351 = add i64 %1350, 4
  store i64 %1351, i64* %PC, align 8
  %1352 = inttoptr i64 %1349 to i64*
  %1353 = load i64, i64* %1352, align 8
  store i64 %1353, i64* %RCX, align 8, !tbaa !2428
  %1354 = add i64 %1348, -40
  %1355 = add i64 %1350, 8
  store i64 %1355, i64* %PC, align 8
  %1356 = inttoptr i64 %1354 to i32*
  %1357 = load i32, i32* %1356, align 4
  %1358 = sext i32 %1357 to i64
  store i64 %1358, i64* %RDX, align 8, !tbaa !2428
  %1359 = shl nsw i64 %1358, 3
  %1360 = add i64 %1359, %1353
  %1361 = add i64 %1350, 13
  store i64 %1361, i64* %PC, align 8
  %1362 = inttoptr i64 %1360 to i64*
  %1363 = load i64, i64* %1362, align 8
  store i64 %1363, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1364 = add i64 %1348, -80
  %1365 = add i64 %1350, 18
  store i64 %1365, i64* %PC, align 8
  %1366 = inttoptr i64 %1364 to i64*
  store i64 %1363, i64* %1366, align 8
  %1367 = load i64, i64* %RBP, align 8
  %1368 = add i64 %1367, -24
  %1369 = load i64, i64* %PC, align 8
  %1370 = add i64 %1369, 4
  store i64 %1370, i64* %PC, align 8
  %1371 = inttoptr i64 %1368 to i64*
  %1372 = load i64, i64* %1371, align 8
  store i64 %1372, i64* %RCX, align 8, !tbaa !2428
  %1373 = add i64 %1367, -40
  %1374 = add i64 %1369, 7
  store i64 %1374, i64* %PC, align 8
  %1375 = inttoptr i64 %1373 to i32*
  %1376 = load i32, i32* %1375, align 4
  %1377 = add i32 %1376, 1
  %1378 = zext i32 %1377 to i64
  store i64 %1378, i64* %RAX, align 8, !tbaa !2428
  %1379 = icmp eq i32 %1376, -1
  %1380 = icmp eq i32 %1377, 0
  %1381 = or i1 %1379, %1380
  %1382 = zext i1 %1381 to i8
  store i8 %1382, i8* %50, align 1, !tbaa !2432
  %1383 = and i32 %1377, 255
  %1384 = tail call i32 @llvm.ctpop.i32(i32 %1383) #11
  %1385 = trunc i32 %1384 to i8
  %1386 = and i8 %1385, 1
  %1387 = xor i8 %1386, 1
  store i8 %1387, i8* %51, align 1, !tbaa !2446
  %1388 = xor i32 %1377, %1376
  %1389 = lshr i32 %1388, 4
  %1390 = trunc i32 %1389 to i8
  %1391 = and i8 %1390, 1
  store i8 %1391, i8* %52, align 1, !tbaa !2447
  %1392 = zext i1 %1380 to i8
  store i8 %1392, i8* %53, align 1, !tbaa !2448
  %1393 = lshr i32 %1377, 31
  %1394 = trunc i32 %1393 to i8
  store i8 %1394, i8* %54, align 1, !tbaa !2449
  %1395 = lshr i32 %1376, 31
  %1396 = xor i32 %1393, %1395
  %1397 = add nuw nsw i32 %1396, %1393
  %1398 = icmp eq i32 %1397, 2
  %1399 = zext i1 %1398 to i8
  store i8 %1399, i8* %55, align 1, !tbaa !2450
  %1400 = sext i32 %1377 to i64
  store i64 %1400, i64* %RDX, align 8, !tbaa !2428
  %1401 = shl nsw i64 %1400, 3
  %1402 = add i64 %1401, %1372
  %1403 = add i64 %1369, 18
  store i64 %1403, i64* %PC, align 8
  %1404 = inttoptr i64 %1402 to i64*
  %1405 = load i64, i64* %1404, align 8
  store i64 %1405, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1406 = add i64 %1367, -88
  %1407 = add i64 %1369, 23
  store i64 %1407, i64* %PC, align 8
  %1408 = inttoptr i64 %1406 to i64*
  store i64 %1405, i64* %1408, align 8
  %1409 = load i64, i64* %RBP, align 8
  %1410 = add i64 %1409, -80
  %1411 = load i64, i64* %PC, align 8
  %1412 = add i64 %1411, 5
  store i64 %1412, i64* %PC, align 8
  %1413 = inttoptr i64 %1410 to i64*
  %1414 = load i64, i64* %1413, align 8
  store i64 %1414, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1415 = add i64 %1409, -24
  %1416 = add i64 %1411, 9
  store i64 %1416, i64* %PC, align 8
  %1417 = inttoptr i64 %1415 to i64*
  %1418 = load i64, i64* %1417, align 8
  store i64 %1418, i64* %RCX, align 8, !tbaa !2428
  %1419 = add i64 %1409, -32
  %1420 = add i64 %1411, 13
  store i64 %1420, i64* %PC, align 8
  %1421 = inttoptr i64 %1419 to i32*
  %1422 = load i32, i32* %1421, align 4
  %1423 = sext i32 %1422 to i64
  store i64 %1423, i64* %RDX, align 8, !tbaa !2428
  %1424 = shl nsw i64 %1423, 3
  %1425 = add i64 %1424, %1418
  %1426 = add i64 %1411, 18
  store i64 %1426, i64* %PC, align 8
  %1427 = inttoptr i64 %1425 to i64*
  store i64 %1414, i64* %1427, align 8
  %1428 = load i64, i64* %RBP, align 8
  %1429 = add i64 %1428, -88
  %1430 = load i64, i64* %PC, align 8
  %1431 = add i64 %1430, 5
  store i64 %1431, i64* %PC, align 8
  %1432 = inttoptr i64 %1429 to i64*
  %1433 = load i64, i64* %1432, align 8
  store i64 %1433, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1434 = add i64 %1428, -24
  %1435 = add i64 %1430, 9
  store i64 %1435, i64* %PC, align 8
  %1436 = inttoptr i64 %1434 to i64*
  %1437 = load i64, i64* %1436, align 8
  store i64 %1437, i64* %RCX, align 8, !tbaa !2428
  %1438 = add i64 %1428, -32
  %1439 = add i64 %1430, 12
  store i64 %1439, i64* %PC, align 8
  %1440 = inttoptr i64 %1438 to i32*
  %1441 = load i32, i32* %1440, align 4
  %1442 = add i32 %1441, 1
  %1443 = zext i32 %1442 to i64
  store i64 %1443, i64* %RAX, align 8, !tbaa !2428
  %1444 = icmp eq i32 %1441, -1
  %1445 = icmp eq i32 %1442, 0
  %1446 = or i1 %1444, %1445
  %1447 = zext i1 %1446 to i8
  store i8 %1447, i8* %50, align 1, !tbaa !2432
  %1448 = and i32 %1442, 255
  %1449 = tail call i32 @llvm.ctpop.i32(i32 %1448) #11
  %1450 = trunc i32 %1449 to i8
  %1451 = and i8 %1450, 1
  %1452 = xor i8 %1451, 1
  store i8 %1452, i8* %51, align 1, !tbaa !2446
  %1453 = xor i32 %1442, %1441
  %1454 = lshr i32 %1453, 4
  %1455 = trunc i32 %1454 to i8
  %1456 = and i8 %1455, 1
  store i8 %1456, i8* %52, align 1, !tbaa !2447
  %1457 = zext i1 %1445 to i8
  store i8 %1457, i8* %53, align 1, !tbaa !2448
  %1458 = lshr i32 %1442, 31
  %1459 = trunc i32 %1458 to i8
  store i8 %1459, i8* %54, align 1, !tbaa !2449
  %1460 = lshr i32 %1441, 31
  %1461 = xor i32 %1458, %1460
  %1462 = add nuw nsw i32 %1461, %1458
  %1463 = icmp eq i32 %1462, 2
  %1464 = zext i1 %1463 to i8
  store i8 %1464, i8* %55, align 1, !tbaa !2450
  %1465 = sext i32 %1442 to i64
  store i64 %1465, i64* %RDX, align 8, !tbaa !2428
  %1466 = shl nsw i64 %1465, 3
  %1467 = add i64 %1466, %1437
  %1468 = add i64 %1430, 23
  store i64 %1468, i64* %PC, align 8
  %1469 = inttoptr i64 %1467 to i64*
  store i64 %1433, i64* %1469, align 8
  %1470 = load i64, i64* %RBP, align 8
  %1471 = add i64 %1470, -64
  %1472 = load i64, i64* %PC, align 8
  %1473 = add i64 %1472, 5
  store i64 %1473, i64* %PC, align 8
  %1474 = inttoptr i64 %1471 to i64*
  %1475 = load i64, i64* %1474, align 8
  store i64 %1475, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1476 = add i64 %1470, -24
  %1477 = add i64 %1472, 9
  store i64 %1477, i64* %PC, align 8
  %1478 = inttoptr i64 %1476 to i64*
  %1479 = load i64, i64* %1478, align 8
  store i64 %1479, i64* %RCX, align 8, !tbaa !2428
  %1480 = add i64 %1470, -40
  %1481 = add i64 %1472, 13
  store i64 %1481, i64* %PC, align 8
  %1482 = inttoptr i64 %1480 to i32*
  %1483 = load i32, i32* %1482, align 4
  %1484 = sext i32 %1483 to i64
  store i64 %1484, i64* %RDX, align 8, !tbaa !2428
  %1485 = shl nsw i64 %1484, 3
  %1486 = add i64 %1485, %1479
  %1487 = add i64 %1472, 18
  store i64 %1487, i64* %PC, align 8
  %1488 = inttoptr i64 %1486 to i64*
  store i64 %1475, i64* %1488, align 8
  %1489 = load i64, i64* %RBP, align 8
  %1490 = add i64 %1489, -72
  %1491 = load i64, i64* %PC, align 8
  %1492 = add i64 %1491, 5
  store i64 %1492, i64* %PC, align 8
  %1493 = inttoptr i64 %1490 to i64*
  %1494 = load i64, i64* %1493, align 8
  store i64 %1494, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1495 = add i64 %1489, -24
  %1496 = add i64 %1491, 9
  store i64 %1496, i64* %PC, align 8
  %1497 = inttoptr i64 %1495 to i64*
  %1498 = load i64, i64* %1497, align 8
  store i64 %1498, i64* %RCX, align 8, !tbaa !2428
  %1499 = add i64 %1489, -40
  %1500 = add i64 %1491, 12
  store i64 %1500, i64* %PC, align 8
  %1501 = inttoptr i64 %1499 to i32*
  %1502 = load i32, i32* %1501, align 4
  %1503 = add i32 %1502, 1
  %1504 = zext i32 %1503 to i64
  store i64 %1504, i64* %RAX, align 8, !tbaa !2428
  %1505 = icmp eq i32 %1502, -1
  %1506 = icmp eq i32 %1503, 0
  %1507 = or i1 %1505, %1506
  %1508 = zext i1 %1507 to i8
  store i8 %1508, i8* %50, align 1, !tbaa !2432
  %1509 = and i32 %1503, 255
  %1510 = tail call i32 @llvm.ctpop.i32(i32 %1509) #11
  %1511 = trunc i32 %1510 to i8
  %1512 = and i8 %1511, 1
  %1513 = xor i8 %1512, 1
  store i8 %1513, i8* %51, align 1, !tbaa !2446
  %1514 = xor i32 %1503, %1502
  %1515 = lshr i32 %1514, 4
  %1516 = trunc i32 %1515 to i8
  %1517 = and i8 %1516, 1
  store i8 %1517, i8* %52, align 1, !tbaa !2447
  %1518 = zext i1 %1506 to i8
  store i8 %1518, i8* %53, align 1, !tbaa !2448
  %1519 = lshr i32 %1503, 31
  %1520 = trunc i32 %1519 to i8
  store i8 %1520, i8* %54, align 1, !tbaa !2449
  %1521 = lshr i32 %1502, 31
  %1522 = xor i32 %1519, %1521
  %1523 = add nuw nsw i32 %1522, %1519
  %1524 = icmp eq i32 %1523, 2
  %1525 = zext i1 %1524 to i8
  store i8 %1525, i8* %55, align 1, !tbaa !2450
  %1526 = sext i32 %1503 to i64
  store i64 %1526, i64* %RDX, align 8, !tbaa !2428
  %1527 = shl nsw i64 %1526, 3
  %1528 = add i64 %1527, %1498
  %1529 = add i64 %1491, 23
  store i64 %1529, i64* %PC, align 8
  %1530 = inttoptr i64 %1528 to i64*
  store i64 %1494, i64* %1530, align 8
  %1531 = load i64, i64* %RBP, align 8
  %1532 = add i64 %1531, -52
  %1533 = load i64, i64* %PC, align 8
  %1534 = add i64 %1533, 3
  store i64 %1534, i64* %PC, align 8
  %1535 = inttoptr i64 %1532 to i32*
  %1536 = load i32, i32* %1535, align 4
  %1537 = zext i32 %1536 to i64
  store i64 %1537, i64* %RAX, align 8, !tbaa !2428
  %1538 = add i64 %1531, -32
  %1539 = add i64 %1533, 6
  store i64 %1539, i64* %PC, align 8
  %1540 = inttoptr i64 %1538 to i32*
  %1541 = load i32, i32* %1540, align 4
  %1542 = add i32 %1541, %1536
  %1543 = zext i32 %1542 to i64
  store i64 %1543, i64* %RAX, align 8, !tbaa !2428
  %1544 = icmp ult i32 %1542, %1536
  %1545 = icmp ult i32 %1542, %1541
  %1546 = or i1 %1544, %1545
  %1547 = zext i1 %1546 to i8
  store i8 %1547, i8* %50, align 1, !tbaa !2432
  %1548 = and i32 %1542, 255
  %1549 = tail call i32 @llvm.ctpop.i32(i32 %1548) #11
  %1550 = trunc i32 %1549 to i8
  %1551 = and i8 %1550, 1
  %1552 = xor i8 %1551, 1
  store i8 %1552, i8* %51, align 1, !tbaa !2446
  %1553 = xor i32 %1541, %1536
  %1554 = xor i32 %1553, %1542
  %1555 = lshr i32 %1554, 4
  %1556 = trunc i32 %1555 to i8
  %1557 = and i8 %1556, 1
  store i8 %1557, i8* %52, align 1, !tbaa !2447
  %1558 = icmp eq i32 %1542, 0
  %1559 = zext i1 %1558 to i8
  store i8 %1559, i8* %53, align 1, !tbaa !2448
  %1560 = lshr i32 %1542, 31
  %1561 = trunc i32 %1560 to i8
  store i8 %1561, i8* %54, align 1, !tbaa !2449
  %1562 = lshr i32 %1536, 31
  %1563 = lshr i32 %1541, 31
  %1564 = xor i32 %1560, %1562
  %1565 = xor i32 %1560, %1563
  %1566 = add nuw nsw i32 %1564, %1565
  %1567 = icmp eq i32 %1566, 2
  %1568 = zext i1 %1567 to i8
  store i8 %1568, i8* %55, align 1, !tbaa !2450
  %1569 = add i64 %1533, 9
  store i64 %1569, i64* %PC, align 8
  store i32 %1542, i32* %1540, align 4
  %1570 = load i64, i64* %RBP, align 8
  %1571 = add i64 %1570, -52
  %1572 = load i64, i64* %PC, align 8
  %1573 = add i64 %1572, 3
  store i64 %1573, i64* %PC, align 8
  %1574 = inttoptr i64 %1571 to i32*
  %1575 = load i32, i32* %1574, align 4
  %1576 = shl i32 %1575, 1
  %1577 = icmp slt i32 %1575, 0
  %1578 = icmp slt i32 %1576, 0
  %1579 = xor i1 %1577, %1578
  %1580 = zext i32 %1576 to i64
  store i64 %1580, i64* %RAX, align 8, !tbaa !2428
  %.lobit17 = lshr i32 %1575, 31
  %1581 = trunc i32 %.lobit17 to i8
  store i8 %1581, i8* %50, align 1, !tbaa !2453
  %1582 = and i32 %1576, 254
  %1583 = tail call i32 @llvm.ctpop.i32(i32 %1582) #11
  %1584 = trunc i32 %1583 to i8
  %1585 = and i8 %1584, 1
  %1586 = xor i8 %1585, 1
  store i8 %1586, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %1587 = icmp eq i32 %1576, 0
  %1588 = zext i1 %1587 to i8
  store i8 %1588, i8* %53, align 1, !tbaa !2453
  %1589 = lshr i32 %1575, 30
  %1590 = trunc i32 %1589 to i8
  %1591 = and i8 %1590, 1
  store i8 %1591, i8* %54, align 1, !tbaa !2453
  %1592 = zext i1 %1579 to i8
  store i8 %1592, i8* %55, align 1, !tbaa !2453
  %1593 = add i64 %1570, -40
  %1594 = add i64 %1572, 9
  store i64 %1594, i64* %PC, align 8
  %1595 = inttoptr i64 %1593 to i32*
  %1596 = load i32, i32* %1595, align 4
  %1597 = add i32 %1596, %1576
  %1598 = zext i32 %1597 to i64
  store i64 %1598, i64* %RAX, align 8, !tbaa !2428
  %1599 = icmp ult i32 %1597, %1576
  %1600 = icmp ult i32 %1597, %1596
  %1601 = or i1 %1599, %1600
  %1602 = zext i1 %1601 to i8
  store i8 %1602, i8* %50, align 1, !tbaa !2432
  %1603 = and i32 %1597, 255
  %1604 = tail call i32 @llvm.ctpop.i32(i32 %1603) #11
  %1605 = trunc i32 %1604 to i8
  %1606 = and i8 %1605, 1
  %1607 = xor i8 %1606, 1
  store i8 %1607, i8* %51, align 1, !tbaa !2446
  %1608 = xor i32 %1596, %1576
  %1609 = xor i32 %1608, %1597
  %1610 = lshr i32 %1609, 4
  %1611 = trunc i32 %1610 to i8
  %1612 = and i8 %1611, 1
  store i8 %1612, i8* %52, align 1, !tbaa !2447
  %1613 = icmp eq i32 %1597, 0
  %1614 = zext i1 %1613 to i8
  store i8 %1614, i8* %53, align 1, !tbaa !2448
  %1615 = lshr i32 %1597, 31
  %1616 = trunc i32 %1615 to i8
  store i8 %1616, i8* %54, align 1, !tbaa !2449
  %1617 = and i32 %1589, 1
  %1618 = lshr i32 %1596, 31
  %1619 = xor i32 %1615, %1617
  %1620 = xor i32 %1615, %1618
  %1621 = add nuw nsw i32 %1619, %1620
  %1622 = icmp eq i32 %1621, 2
  %1623 = zext i1 %1622 to i8
  store i8 %1623, i8* %55, align 1, !tbaa !2450
  %1624 = add i64 %1572, 12
  store i64 %1624, i64* %PC, align 8
  store i32 %1597, i32* %1595, align 4
  %1625 = load i64, i64* %RBP, align 8
  %1626 = add i64 %1625, -24
  %1627 = load i64, i64* %PC, align 8
  %1628 = add i64 %1627, 4
  store i64 %1628, i64* %PC, align 8
  %1629 = inttoptr i64 %1626 to i64*
  %1630 = load i64, i64* %1629, align 8
  store i64 %1630, i64* %RCX, align 8, !tbaa !2428
  %1631 = add i64 %1625, -32
  %1632 = add i64 %1627, 8
  store i64 %1632, i64* %PC, align 8
  %1633 = inttoptr i64 %1631 to i32*
  %1634 = load i32, i32* %1633, align 4
  %1635 = sext i32 %1634 to i64
  store i64 %1635, i64* %RDX, align 8, !tbaa !2428
  %1636 = shl nsw i64 %1635, 3
  %1637 = add i64 %1636, %1630
  %1638 = add i64 %1627, 13
  store i64 %1638, i64* %PC, align 8
  %1639 = inttoptr i64 %1637 to i64*
  %1640 = load i64, i64* %1639, align 8
  store i64 %1640, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1641 = add i64 %1625, -64
  %1642 = add i64 %1627, 18
  store i64 %1642, i64* %PC, align 8
  %1643 = inttoptr i64 %1641 to i64*
  store i64 %1640, i64* %1643, align 8
  %1644 = load i64, i64* %RBP, align 8
  %1645 = add i64 %1644, -24
  %1646 = load i64, i64* %PC, align 8
  %1647 = add i64 %1646, 4
  store i64 %1647, i64* %PC, align 8
  %1648 = inttoptr i64 %1645 to i64*
  %1649 = load i64, i64* %1648, align 8
  store i64 %1649, i64* %RCX, align 8, !tbaa !2428
  %1650 = add i64 %1644, -32
  %1651 = add i64 %1646, 7
  store i64 %1651, i64* %PC, align 8
  %1652 = inttoptr i64 %1650 to i32*
  %1653 = load i32, i32* %1652, align 4
  %1654 = add i32 %1653, 1
  %1655 = zext i32 %1654 to i64
  store i64 %1655, i64* %RAX, align 8, !tbaa !2428
  %1656 = icmp eq i32 %1653, -1
  %1657 = icmp eq i32 %1654, 0
  %1658 = or i1 %1656, %1657
  %1659 = zext i1 %1658 to i8
  store i8 %1659, i8* %50, align 1, !tbaa !2432
  %1660 = and i32 %1654, 255
  %1661 = tail call i32 @llvm.ctpop.i32(i32 %1660) #11
  %1662 = trunc i32 %1661 to i8
  %1663 = and i8 %1662, 1
  %1664 = xor i8 %1663, 1
  store i8 %1664, i8* %51, align 1, !tbaa !2446
  %1665 = xor i32 %1654, %1653
  %1666 = lshr i32 %1665, 4
  %1667 = trunc i32 %1666 to i8
  %1668 = and i8 %1667, 1
  store i8 %1668, i8* %52, align 1, !tbaa !2447
  %1669 = zext i1 %1657 to i8
  store i8 %1669, i8* %53, align 1, !tbaa !2448
  %1670 = lshr i32 %1654, 31
  %1671 = trunc i32 %1670 to i8
  store i8 %1671, i8* %54, align 1, !tbaa !2449
  %1672 = lshr i32 %1653, 31
  %1673 = xor i32 %1670, %1672
  %1674 = add nuw nsw i32 %1673, %1670
  %1675 = icmp eq i32 %1674, 2
  %1676 = zext i1 %1675 to i8
  store i8 %1676, i8* %55, align 1, !tbaa !2450
  %1677 = sext i32 %1654 to i64
  store i64 %1677, i64* %RDX, align 8, !tbaa !2428
  %1678 = shl nsw i64 %1677, 3
  %1679 = add i64 %1678, %1649
  %1680 = add i64 %1646, 18
  store i64 %1680, i64* %PC, align 8
  %1681 = inttoptr i64 %1679 to i64*
  %1682 = load i64, i64* %1681, align 8
  store i64 %1682, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1683 = add i64 %1644, -72
  %1684 = add i64 %1646, 23
  store i64 %1684, i64* %PC, align 8
  %1685 = inttoptr i64 %1683 to i64*
  store i64 %1682, i64* %1685, align 8
  %1686 = load i64, i64* %RBP, align 8
  %1687 = add i64 %1686, -24
  %1688 = load i64, i64* %PC, align 8
  %1689 = add i64 %1688, 4
  store i64 %1689, i64* %PC, align 8
  %1690 = inttoptr i64 %1687 to i64*
  %1691 = load i64, i64* %1690, align 8
  store i64 %1691, i64* %RCX, align 8, !tbaa !2428
  %1692 = add i64 %1686, -40
  %1693 = add i64 %1688, 8
  store i64 %1693, i64* %PC, align 8
  %1694 = inttoptr i64 %1692 to i32*
  %1695 = load i32, i32* %1694, align 4
  %1696 = sext i32 %1695 to i64
  store i64 %1696, i64* %RDX, align 8, !tbaa !2428
  %1697 = shl nsw i64 %1696, 3
  %1698 = add i64 %1697, %1691
  %1699 = add i64 %1688, 13
  store i64 %1699, i64* %PC, align 8
  %1700 = inttoptr i64 %1698 to i64*
  %1701 = load i64, i64* %1700, align 8
  store i64 %1701, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1702 = add i64 %1686, -80
  %1703 = add i64 %1688, 18
  store i64 %1703, i64* %PC, align 8
  %1704 = inttoptr i64 %1702 to i64*
  store i64 %1701, i64* %1704, align 8
  %1705 = load i64, i64* %RBP, align 8
  %1706 = add i64 %1705, -24
  %1707 = load i64, i64* %PC, align 8
  %1708 = add i64 %1707, 4
  store i64 %1708, i64* %PC, align 8
  %1709 = inttoptr i64 %1706 to i64*
  %1710 = load i64, i64* %1709, align 8
  store i64 %1710, i64* %RCX, align 8, !tbaa !2428
  %1711 = add i64 %1705, -40
  %1712 = add i64 %1707, 7
  store i64 %1712, i64* %PC, align 8
  %1713 = inttoptr i64 %1711 to i32*
  %1714 = load i32, i32* %1713, align 4
  %1715 = add i32 %1714, 1
  %1716 = zext i32 %1715 to i64
  store i64 %1716, i64* %RAX, align 8, !tbaa !2428
  %1717 = icmp eq i32 %1714, -1
  %1718 = icmp eq i32 %1715, 0
  %1719 = or i1 %1717, %1718
  %1720 = zext i1 %1719 to i8
  store i8 %1720, i8* %50, align 1, !tbaa !2432
  %1721 = and i32 %1715, 255
  %1722 = tail call i32 @llvm.ctpop.i32(i32 %1721) #11
  %1723 = trunc i32 %1722 to i8
  %1724 = and i8 %1723, 1
  %1725 = xor i8 %1724, 1
  store i8 %1725, i8* %51, align 1, !tbaa !2446
  %1726 = xor i32 %1715, %1714
  %1727 = lshr i32 %1726, 4
  %1728 = trunc i32 %1727 to i8
  %1729 = and i8 %1728, 1
  store i8 %1729, i8* %52, align 1, !tbaa !2447
  %1730 = zext i1 %1718 to i8
  store i8 %1730, i8* %53, align 1, !tbaa !2448
  %1731 = lshr i32 %1715, 31
  %1732 = trunc i32 %1731 to i8
  store i8 %1732, i8* %54, align 1, !tbaa !2449
  %1733 = lshr i32 %1714, 31
  %1734 = xor i32 %1731, %1733
  %1735 = add nuw nsw i32 %1734, %1731
  %1736 = icmp eq i32 %1735, 2
  %1737 = zext i1 %1736 to i8
  store i8 %1737, i8* %55, align 1, !tbaa !2450
  %1738 = sext i32 %1715 to i64
  store i64 %1738, i64* %RDX, align 8, !tbaa !2428
  %1739 = shl nsw i64 %1738, 3
  %1740 = add i64 %1739, %1710
  %1741 = add i64 %1707, 18
  store i64 %1741, i64* %PC, align 8
  %1742 = inttoptr i64 %1740 to i64*
  %1743 = load i64, i64* %1742, align 8
  store i64 %1743, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1744 = add i64 %1705, -88
  %1745 = add i64 %1707, 23
  store i64 %1745, i64* %PC, align 8
  %1746 = inttoptr i64 %1744 to i64*
  store i64 %1743, i64* %1746, align 8
  %1747 = load i64, i64* %RBP, align 8
  %1748 = add i64 %1747, -80
  %1749 = load i64, i64* %PC, align 8
  %1750 = add i64 %1749, 5
  store i64 %1750, i64* %PC, align 8
  %1751 = inttoptr i64 %1748 to i64*
  %1752 = load i64, i64* %1751, align 8
  store i64 %1752, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1753 = add i64 %1747, -24
  %1754 = add i64 %1749, 9
  store i64 %1754, i64* %PC, align 8
  %1755 = inttoptr i64 %1753 to i64*
  %1756 = load i64, i64* %1755, align 8
  store i64 %1756, i64* %RCX, align 8, !tbaa !2428
  %1757 = add i64 %1747, -32
  %1758 = add i64 %1749, 13
  store i64 %1758, i64* %PC, align 8
  %1759 = inttoptr i64 %1757 to i32*
  %1760 = load i32, i32* %1759, align 4
  %1761 = sext i32 %1760 to i64
  store i64 %1761, i64* %RDX, align 8, !tbaa !2428
  %1762 = shl nsw i64 %1761, 3
  %1763 = add i64 %1762, %1756
  %1764 = add i64 %1749, 18
  store i64 %1764, i64* %PC, align 8
  %1765 = inttoptr i64 %1763 to i64*
  store i64 %1752, i64* %1765, align 8
  %1766 = load i64, i64* %RBP, align 8
  %1767 = add i64 %1766, -88
  %1768 = load i64, i64* %PC, align 8
  %1769 = add i64 %1768, 5
  store i64 %1769, i64* %PC, align 8
  %1770 = inttoptr i64 %1767 to i64*
  %1771 = load i64, i64* %1770, align 8
  store i64 %1771, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1772 = add i64 %1766, -24
  %1773 = add i64 %1768, 9
  store i64 %1773, i64* %PC, align 8
  %1774 = inttoptr i64 %1772 to i64*
  %1775 = load i64, i64* %1774, align 8
  store i64 %1775, i64* %RCX, align 8, !tbaa !2428
  %1776 = add i64 %1766, -32
  %1777 = add i64 %1768, 12
  store i64 %1777, i64* %PC, align 8
  %1778 = inttoptr i64 %1776 to i32*
  %1779 = load i32, i32* %1778, align 4
  %1780 = add i32 %1779, 1
  %1781 = zext i32 %1780 to i64
  store i64 %1781, i64* %RAX, align 8, !tbaa !2428
  %1782 = icmp eq i32 %1779, -1
  %1783 = icmp eq i32 %1780, 0
  %1784 = or i1 %1782, %1783
  %1785 = zext i1 %1784 to i8
  store i8 %1785, i8* %50, align 1, !tbaa !2432
  %1786 = and i32 %1780, 255
  %1787 = tail call i32 @llvm.ctpop.i32(i32 %1786) #11
  %1788 = trunc i32 %1787 to i8
  %1789 = and i8 %1788, 1
  %1790 = xor i8 %1789, 1
  store i8 %1790, i8* %51, align 1, !tbaa !2446
  %1791 = xor i32 %1780, %1779
  %1792 = lshr i32 %1791, 4
  %1793 = trunc i32 %1792 to i8
  %1794 = and i8 %1793, 1
  store i8 %1794, i8* %52, align 1, !tbaa !2447
  %1795 = zext i1 %1783 to i8
  store i8 %1795, i8* %53, align 1, !tbaa !2448
  %1796 = lshr i32 %1780, 31
  %1797 = trunc i32 %1796 to i8
  store i8 %1797, i8* %54, align 1, !tbaa !2449
  %1798 = lshr i32 %1779, 31
  %1799 = xor i32 %1796, %1798
  %1800 = add nuw nsw i32 %1799, %1796
  %1801 = icmp eq i32 %1800, 2
  %1802 = zext i1 %1801 to i8
  store i8 %1802, i8* %55, align 1, !tbaa !2450
  %1803 = sext i32 %1780 to i64
  store i64 %1803, i64* %RDX, align 8, !tbaa !2428
  %1804 = shl nsw i64 %1803, 3
  %1805 = add i64 %1804, %1775
  %1806 = add i64 %1768, 23
  store i64 %1806, i64* %PC, align 8
  %1807 = inttoptr i64 %1805 to i64*
  store i64 %1771, i64* %1807, align 8
  %1808 = load i64, i64* %RBP, align 8
  %1809 = add i64 %1808, -64
  %1810 = load i64, i64* %PC, align 8
  %1811 = add i64 %1810, 5
  store i64 %1811, i64* %PC, align 8
  %1812 = inttoptr i64 %1809 to i64*
  %1813 = load i64, i64* %1812, align 8
  store i64 %1813, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1814 = add i64 %1808, -24
  %1815 = add i64 %1810, 9
  store i64 %1815, i64* %PC, align 8
  %1816 = inttoptr i64 %1814 to i64*
  %1817 = load i64, i64* %1816, align 8
  store i64 %1817, i64* %RCX, align 8, !tbaa !2428
  %1818 = add i64 %1808, -40
  %1819 = add i64 %1810, 13
  store i64 %1819, i64* %PC, align 8
  %1820 = inttoptr i64 %1818 to i32*
  %1821 = load i32, i32* %1820, align 4
  %1822 = sext i32 %1821 to i64
  store i64 %1822, i64* %RDX, align 8, !tbaa !2428
  %1823 = shl nsw i64 %1822, 3
  %1824 = add i64 %1823, %1817
  %1825 = add i64 %1810, 18
  store i64 %1825, i64* %PC, align 8
  %1826 = inttoptr i64 %1824 to i64*
  store i64 %1813, i64* %1826, align 8
  %1827 = load i64, i64* %RBP, align 8
  %1828 = add i64 %1827, -72
  %1829 = load i64, i64* %PC, align 8
  %1830 = add i64 %1829, 5
  store i64 %1830, i64* %PC, align 8
  %1831 = inttoptr i64 %1828 to i64*
  %1832 = load i64, i64* %1831, align 8
  store i64 %1832, i64* %2926, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2928, align 1, !tbaa !2451
  %1833 = add i64 %1827, -24
  %1834 = add i64 %1829, 9
  store i64 %1834, i64* %PC, align 8
  %1835 = inttoptr i64 %1833 to i64*
  %1836 = load i64, i64* %1835, align 8
  store i64 %1836, i64* %RCX, align 8, !tbaa !2428
  %1837 = add i64 %1827, -40
  %1838 = add i64 %1829, 12
  store i64 %1838, i64* %PC, align 8
  %1839 = inttoptr i64 %1837 to i32*
  %1840 = load i32, i32* %1839, align 4
  %1841 = add i32 %1840, 1
  %1842 = zext i32 %1841 to i64
  store i64 %1842, i64* %RAX, align 8, !tbaa !2428
  %1843 = icmp eq i32 %1840, -1
  %1844 = icmp eq i32 %1841, 0
  %1845 = or i1 %1843, %1844
  %1846 = zext i1 %1845 to i8
  store i8 %1846, i8* %50, align 1, !tbaa !2432
  %1847 = and i32 %1841, 255
  %1848 = tail call i32 @llvm.ctpop.i32(i32 %1847) #11
  %1849 = trunc i32 %1848 to i8
  %1850 = and i8 %1849, 1
  %1851 = xor i8 %1850, 1
  store i8 %1851, i8* %51, align 1, !tbaa !2446
  %1852 = xor i32 %1841, %1840
  %1853 = lshr i32 %1852, 4
  %1854 = trunc i32 %1853 to i8
  %1855 = and i8 %1854, 1
  store i8 %1855, i8* %52, align 1, !tbaa !2447
  %1856 = zext i1 %1844 to i8
  store i8 %1856, i8* %53, align 1, !tbaa !2448
  %1857 = lshr i32 %1841, 31
  %1858 = trunc i32 %1857 to i8
  store i8 %1858, i8* %54, align 1, !tbaa !2449
  %1859 = lshr i32 %1840, 31
  %1860 = xor i32 %1857, %1859
  %1861 = add nuw nsw i32 %1860, %1857
  %1862 = icmp eq i32 %1861, 2
  %1863 = zext i1 %1862 to i8
  store i8 %1863, i8* %55, align 1, !tbaa !2450
  %1864 = sext i32 %1841 to i64
  store i64 %1864, i64* %RDX, align 8, !tbaa !2428
  %1865 = shl nsw i64 %1864, 3
  %1866 = add i64 %1865, %1836
  %1867 = add i64 %1829, 23
  store i64 %1867, i64* %PC, align 8
  %1868 = inttoptr i64 %1866 to i64*
  store i64 %1832, i64* %1868, align 8
  %1869 = load i64, i64* %RBP, align 8
  %1870 = add i64 %1869, -28
  %1871 = load i64, i64* %PC, align 8
  %1872 = add i64 %1871, 3
  store i64 %1872, i64* %PC, align 8
  %1873 = inttoptr i64 %1870 to i32*
  %1874 = load i32, i32* %1873, align 4
  %1875 = add i32 %1874, 1
  %1876 = zext i32 %1875 to i64
  store i64 %1876, i64* %RAX, align 8, !tbaa !2428
  %1877 = icmp eq i32 %1874, -1
  %1878 = icmp eq i32 %1875, 0
  %1879 = or i1 %1877, %1878
  %1880 = zext i1 %1879 to i8
  store i8 %1880, i8* %50, align 1, !tbaa !2432
  %1881 = and i32 %1875, 255
  %1882 = tail call i32 @llvm.ctpop.i32(i32 %1881) #11
  %1883 = trunc i32 %1882 to i8
  %1884 = and i8 %1883, 1
  %1885 = xor i8 %1884, 1
  store i8 %1885, i8* %51, align 1, !tbaa !2446
  %1886 = xor i32 %1875, %1874
  %1887 = lshr i32 %1886, 4
  %1888 = trunc i32 %1887 to i8
  %1889 = and i8 %1888, 1
  store i8 %1889, i8* %52, align 1, !tbaa !2447
  %1890 = zext i1 %1878 to i8
  store i8 %1890, i8* %53, align 1, !tbaa !2448
  %1891 = lshr i32 %1875, 31
  %1892 = trunc i32 %1891 to i8
  store i8 %1892, i8* %54, align 1, !tbaa !2449
  %1893 = lshr i32 %1874, 31
  %1894 = xor i32 %1891, %1893
  %1895 = add nuw nsw i32 %1894, %1891
  %1896 = icmp eq i32 %1895, 2
  %1897 = zext i1 %1896 to i8
  store i8 %1897, i8* %55, align 1, !tbaa !2450
  %1898 = add i64 %1871, 9
  store i64 %1898, i64* %PC, align 8
  store i32 %1875, i32* %1873, align 4
  %1899 = load i64, i64* %PC, align 8
  %1900 = add i64 %1899, -779
  store i64 %1900, i64* %PC, align 8, !tbaa !2428
  br label %block_4012ad

block_401235:                                     ; preds = %block_401241, %block_401225
  %1901 = phi i64 [ %3119, %block_401241 ], [ %.pre45, %block_401225 ]
  %1902 = load i64, i64* %RBP, align 8
  %1903 = add i64 %1902, -28
  %1904 = add i64 %1901, 3
  store i64 %1904, i64* %PC, align 8
  %1905 = inttoptr i64 %1903 to i32*
  %1906 = load i32, i32* %1905, align 4
  %1907 = zext i32 %1906 to i64
  store i64 %1907, i64* %RAX, align 8, !tbaa !2428
  %1908 = add i64 %1902, -48
  %1909 = add i64 %1901, 6
  store i64 %1909, i64* %PC, align 8
  %1910 = inttoptr i64 %1908 to i32*
  %1911 = load i32, i32* %1910, align 4
  %1912 = sub i32 %1906, %1911
  %1913 = icmp ult i32 %1906, %1911
  %1914 = zext i1 %1913 to i8
  store i8 %1914, i8* %50, align 1, !tbaa !2432
  %1915 = and i32 %1912, 255
  %1916 = tail call i32 @llvm.ctpop.i32(i32 %1915) #11
  %1917 = trunc i32 %1916 to i8
  %1918 = and i8 %1917, 1
  %1919 = xor i8 %1918, 1
  store i8 %1919, i8* %51, align 1, !tbaa !2446
  %1920 = xor i32 %1911, %1906
  %1921 = xor i32 %1920, %1912
  %1922 = lshr i32 %1921, 4
  %1923 = trunc i32 %1922 to i8
  %1924 = and i8 %1923, 1
  store i8 %1924, i8* %52, align 1, !tbaa !2447
  %1925 = icmp eq i32 %1912, 0
  %1926 = zext i1 %1925 to i8
  store i8 %1926, i8* %53, align 1, !tbaa !2448
  %1927 = lshr i32 %1912, 31
  %1928 = trunc i32 %1927 to i8
  store i8 %1928, i8* %54, align 1, !tbaa !2449
  %1929 = lshr i32 %1906, 31
  %1930 = lshr i32 %1911, 31
  %1931 = xor i32 %1930, %1929
  %1932 = xor i32 %1927, %1929
  %1933 = add nuw nsw i32 %1932, %1931
  %1934 = icmp eq i32 %1933, 2
  %1935 = zext i1 %1934 to i8
  store i8 %1935, i8* %55, align 1, !tbaa !2450
  %1936 = icmp ne i8 %1928, 0
  %1937 = xor i1 %1936, %1934
  %.v51 = select i1 %1937, i64 12, i64 56
  %1938 = add i64 %.v51, %1901
  store i64 %1938, i64* %PC, align 8, !tbaa !2428
  br i1 %1937, label %block_401241, label %block_40126d

block_4012ad:                                     ; preds = %block_4012a6, %block_4012b9
  %1939 = phi i64 [ %.pre42, %block_4012a6 ], [ %1900, %block_4012b9 ]
  %1940 = load i64, i64* %RBP, align 8
  %1941 = add i64 %1940, -28
  %1942 = add i64 %1939, 3
  store i64 %1942, i64* %PC, align 8
  %1943 = inttoptr i64 %1941 to i32*
  %1944 = load i32, i32* %1943, align 4
  %1945 = zext i32 %1944 to i64
  store i64 %1945, i64* %RAX, align 8, !tbaa !2428
  %1946 = add i64 %1940, -36
  %1947 = add i64 %1939, 6
  store i64 %1947, i64* %PC, align 8
  %1948 = inttoptr i64 %1946 to i32*
  %1949 = load i32, i32* %1948, align 4
  %1950 = sub i32 %1944, %1949
  %1951 = icmp ult i32 %1944, %1949
  %1952 = zext i1 %1951 to i8
  store i8 %1952, i8* %50, align 1, !tbaa !2432
  %1953 = and i32 %1950, 255
  %1954 = tail call i32 @llvm.ctpop.i32(i32 %1953) #11
  %1955 = trunc i32 %1954 to i8
  %1956 = and i8 %1955, 1
  %1957 = xor i8 %1956, 1
  store i8 %1957, i8* %51, align 1, !tbaa !2446
  %1958 = xor i32 %1949, %1944
  %1959 = xor i32 %1958, %1950
  %1960 = lshr i32 %1959, 4
  %1961 = trunc i32 %1960 to i8
  %1962 = and i8 %1961, 1
  store i8 %1962, i8* %52, align 1, !tbaa !2447
  %1963 = icmp eq i32 %1950, 0
  %1964 = zext i1 %1963 to i8
  store i8 %1964, i8* %53, align 1, !tbaa !2448
  %1965 = lshr i32 %1950, 31
  %1966 = trunc i32 %1965 to i8
  store i8 %1966, i8* %54, align 1, !tbaa !2449
  %1967 = lshr i32 %1944, 31
  %1968 = lshr i32 %1949, 31
  %1969 = xor i32 %1968, %1967
  %1970 = xor i32 %1965, %1967
  %1971 = add nuw nsw i32 %1970, %1969
  %1972 = icmp eq i32 %1971, 2
  %1973 = zext i1 %1972 to i8
  store i8 %1973, i8* %55, align 1, !tbaa !2450
  %1974 = icmp ne i8 %1966, 0
  %1975 = xor i1 %1974, %1972
  %.v50 = select i1 %1975, i64 12, i64 784
  %1976 = add i64 %.v50, %1939
  %1977 = add i64 %1976, 3
  store i64 %1977, i64* %PC, align 8
  br i1 %1975, label %block_4012b9, label %block_4015bd

block_4016ba:                                     ; preds = %block_4016ae
  %1978 = add i64 %2807, 3
  store i64 %1978, i64* %PC, align 8
  %1979 = load i32, i32* %2774, align 4
  %1980 = shl i32 %1979, 1
  %1981 = icmp slt i32 %1979, 0
  %1982 = icmp slt i32 %1980, 0
  %1983 = xor i1 %1981, %1982
  %1984 = zext i32 %1980 to i64
  store i64 %1984, i64* %RAX, align 8, !tbaa !2428
  %.lobit19 = lshr i32 %1979, 31
  %1985 = trunc i32 %.lobit19 to i8
  store i8 %1985, i8* %50, align 1, !tbaa !2453
  %1986 = and i32 %1980, 254
  %1987 = tail call i32 @llvm.ctpop.i32(i32 %1986) #11
  %1988 = trunc i32 %1987 to i8
  %1989 = and i8 %1988, 1
  %1990 = xor i8 %1989, 1
  store i8 %1990, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %1991 = icmp eq i32 %1980, 0
  %1992 = zext i1 %1991 to i8
  store i8 %1992, i8* %53, align 1, !tbaa !2453
  %1993 = lshr i32 %1979, 30
  %1994 = trunc i32 %1993 to i8
  %1995 = and i8 %1994, 1
  store i8 %1995, i8* %54, align 1, !tbaa !2453
  %1996 = zext i1 %1983 to i8
  store i8 %1996, i8* %55, align 1, !tbaa !2453
  %1997 = add i64 %2771, -16
  %1998 = add i64 %2807, 10
  store i64 %1998, i64* %PC, align 8
  %1999 = inttoptr i64 %1997 to i64*
  %2000 = load i64, i64* %1999, align 8
  store i64 %2000, i64* %RCX, align 8, !tbaa !2428
  %2001 = add i64 %2807, 14
  store i64 %2001, i64* %PC, align 8
  %2002 = load i32, i32* %2779, align 4
  %2003 = sext i32 %2002 to i64
  store i64 %2003, i64* %RDX, align 8, !tbaa !2428
  %2004 = shl nsw i64 %2003, 2
  %2005 = add i64 %2004, %2000
  %2006 = add i64 %2807, 17
  store i64 %2006, i64* %PC, align 8
  %2007 = inttoptr i64 %2005 to i32*
  %2008 = load i32, i32* %2007, align 4
  %2009 = add i32 %2008, %1980
  %2010 = zext i32 %2009 to i64
  store i64 %2010, i64* %RAX, align 8, !tbaa !2428
  %2011 = icmp ult i32 %2009, %1980
  %2012 = icmp ult i32 %2009, %2008
  %2013 = or i1 %2011, %2012
  %2014 = zext i1 %2013 to i8
  store i8 %2014, i8* %50, align 1, !tbaa !2432
  %2015 = and i32 %2009, 255
  %2016 = tail call i32 @llvm.ctpop.i32(i32 %2015) #11
  %2017 = trunc i32 %2016 to i8
  %2018 = and i8 %2017, 1
  %2019 = xor i8 %2018, 1
  store i8 %2019, i8* %51, align 1, !tbaa !2446
  %2020 = xor i32 %2008, %1980
  %2021 = xor i32 %2020, %2009
  %2022 = lshr i32 %2021, 4
  %2023 = trunc i32 %2022 to i8
  %2024 = and i8 %2023, 1
  store i8 %2024, i8* %52, align 1, !tbaa !2447
  %2025 = icmp eq i32 %2009, 0
  %2026 = zext i1 %2025 to i8
  store i8 %2026, i8* %53, align 1, !tbaa !2448
  %2027 = lshr i32 %2009, 31
  %2028 = trunc i32 %2027 to i8
  store i8 %2028, i8* %54, align 1, !tbaa !2449
  %2029 = and i32 %1993, 1
  %2030 = lshr i32 %2008, 31
  %2031 = xor i32 %2027, %2029
  %2032 = xor i32 %2027, %2030
  %2033 = add nuw nsw i32 %2031, %2032
  %2034 = icmp eq i32 %2033, 2
  %2035 = zext i1 %2034 to i8
  store i8 %2035, i8* %55, align 1, !tbaa !2450
  %2036 = add i64 %2771, -32
  %2037 = add i64 %2807, 20
  store i64 %2037, i64* %PC, align 8
  %2038 = inttoptr i64 %2036 to i32*
  store i32 %2009, i32* %2038, align 4
  %2039 = load i64, i64* %RBP, align 8
  %2040 = add i64 %2039, -36
  %2041 = load i64, i64* %PC, align 8
  %2042 = add i64 %2041, 3
  store i64 %2042, i64* %PC, align 8
  %2043 = inttoptr i64 %2040 to i32*
  %2044 = load i32, i32* %2043, align 4
  %2045 = shl i32 %2044, 1
  %2046 = icmp slt i32 %2044, 0
  %2047 = icmp slt i32 %2045, 0
  %2048 = xor i1 %2046, %2047
  %2049 = zext i32 %2045 to i64
  store i64 %2049, i64* %RAX, align 8, !tbaa !2428
  %.lobit20 = lshr i32 %2044, 31
  %2050 = trunc i32 %.lobit20 to i8
  store i8 %2050, i8* %50, align 1, !tbaa !2453
  %2051 = and i32 %2045, 254
  %2052 = tail call i32 @llvm.ctpop.i32(i32 %2051) #11
  %2053 = trunc i32 %2052 to i8
  %2054 = and i8 %2053, 1
  %2055 = xor i8 %2054, 1
  store i8 %2055, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2056 = icmp eq i32 %2045, 0
  %2057 = zext i1 %2056 to i8
  store i8 %2057, i8* %53, align 1, !tbaa !2453
  %2058 = lshr i32 %2044, 30
  %2059 = trunc i32 %2058 to i8
  %2060 = and i8 %2059, 1
  store i8 %2060, i8* %54, align 1, !tbaa !2453
  %2061 = zext i1 %2048 to i8
  store i8 %2061, i8* %55, align 1, !tbaa !2453
  %2062 = add i64 %2039, -16
  %2063 = add i64 %2041, 10
  store i64 %2063, i64* %PC, align 8
  %2064 = inttoptr i64 %2062 to i64*
  %2065 = load i64, i64* %2064, align 8
  store i64 %2065, i64* %RCX, align 8, !tbaa !2428
  %2066 = add i64 %2039, -28
  %2067 = add i64 %2041, 14
  store i64 %2067, i64* %PC, align 8
  %2068 = inttoptr i64 %2066 to i32*
  %2069 = load i32, i32* %2068, align 4
  %2070 = sext i32 %2069 to i64
  store i64 %2070, i64* %RDX, align 8, !tbaa !2428
  %2071 = shl nsw i64 %2070, 2
  %2072 = add i64 %2071, %2065
  %2073 = add i64 %2041, 17
  store i64 %2073, i64* %PC, align 8
  %2074 = inttoptr i64 %2072 to i32*
  %2075 = load i32, i32* %2074, align 4
  %2076 = add i32 %2075, %2045
  %2077 = zext i32 %2076 to i64
  store i64 %2077, i64* %RAX, align 8, !tbaa !2428
  %2078 = icmp ult i32 %2076, %2045
  %2079 = icmp ult i32 %2076, %2075
  %2080 = or i1 %2078, %2079
  %2081 = zext i1 %2080 to i8
  store i8 %2081, i8* %50, align 1, !tbaa !2432
  %2082 = and i32 %2076, 255
  %2083 = tail call i32 @llvm.ctpop.i32(i32 %2082) #11
  %2084 = trunc i32 %2083 to i8
  %2085 = and i8 %2084, 1
  %2086 = xor i8 %2085, 1
  store i8 %2086, i8* %51, align 1, !tbaa !2446
  %2087 = xor i32 %2075, %2045
  %2088 = xor i32 %2087, %2076
  %2089 = lshr i32 %2088, 4
  %2090 = trunc i32 %2089 to i8
  %2091 = and i8 %2090, 1
  store i8 %2091, i8* %52, align 1, !tbaa !2447
  %2092 = icmp eq i32 %2076, 0
  %2093 = zext i1 %2092 to i8
  store i8 %2093, i8* %53, align 1, !tbaa !2448
  %2094 = lshr i32 %2076, 31
  %2095 = trunc i32 %2094 to i8
  store i8 %2095, i8* %54, align 1, !tbaa !2449
  %2096 = and i32 %2058, 1
  %2097 = lshr i32 %2075, 31
  %2098 = xor i32 %2094, %2096
  %2099 = xor i32 %2094, %2097
  %2100 = add nuw nsw i32 %2098, %2099
  %2101 = icmp eq i32 %2100, 2
  %2102 = zext i1 %2101 to i8
  store i8 %2102, i8* %55, align 1, !tbaa !2450
  %2103 = add i64 %2039, -40
  %2104 = add i64 %2041, 20
  store i64 %2104, i64* %PC, align 8
  %2105 = inttoptr i64 %2103 to i32*
  store i32 %2076, i32* %2105, align 4
  %2106 = load i64, i64* %RBP, align 8
  %2107 = add i64 %2106, -24
  %2108 = load i64, i64* %PC, align 8
  %2109 = add i64 %2108, 4
  store i64 %2109, i64* %PC, align 8
  %2110 = inttoptr i64 %2107 to i64*
  %2111 = load i64, i64* %2110, align 8
  store i64 %2111, i64* %RCX, align 8, !tbaa !2428
  %2112 = add i64 %2106, -32
  %2113 = add i64 %2108, 8
  store i64 %2113, i64* %PC, align 8
  %2114 = inttoptr i64 %2112 to i32*
  %2115 = load i32, i32* %2114, align 4
  %2116 = sext i32 %2115 to i64
  store i64 %2116, i64* %RDX, align 8, !tbaa !2428
  %2117 = shl nsw i64 %2116, 3
  %2118 = add i64 %2117, %2111
  %2119 = add i64 %2108, 13
  store i64 %2119, i64* %PC, align 8
  %2120 = inttoptr i64 %2118 to i64*
  %2121 = load i64, i64* %2120, align 8
  store i64 %2121, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2122 = add i64 %2106, -64
  %2123 = add i64 %2108, 18
  store i64 %2123, i64* %PC, align 8
  %2124 = inttoptr i64 %2122 to i64*
  store i64 %2121, i64* %2124, align 8
  %2125 = load i64, i64* %RBP, align 8
  %2126 = add i64 %2125, -24
  %2127 = load i64, i64* %PC, align 8
  %2128 = add i64 %2127, 4
  store i64 %2128, i64* %PC, align 8
  %2129 = inttoptr i64 %2126 to i64*
  %2130 = load i64, i64* %2129, align 8
  store i64 %2130, i64* %RCX, align 8, !tbaa !2428
  %2131 = add i64 %2125, -32
  %2132 = add i64 %2127, 7
  store i64 %2132, i64* %PC, align 8
  %2133 = inttoptr i64 %2131 to i32*
  %2134 = load i32, i32* %2133, align 4
  %2135 = add i32 %2134, 1
  %2136 = zext i32 %2135 to i64
  store i64 %2136, i64* %RAX, align 8, !tbaa !2428
  %2137 = icmp eq i32 %2134, -1
  %2138 = icmp eq i32 %2135, 0
  %2139 = or i1 %2137, %2138
  %2140 = zext i1 %2139 to i8
  store i8 %2140, i8* %50, align 1, !tbaa !2432
  %2141 = and i32 %2135, 255
  %2142 = tail call i32 @llvm.ctpop.i32(i32 %2141) #11
  %2143 = trunc i32 %2142 to i8
  %2144 = and i8 %2143, 1
  %2145 = xor i8 %2144, 1
  store i8 %2145, i8* %51, align 1, !tbaa !2446
  %2146 = xor i32 %2135, %2134
  %2147 = lshr i32 %2146, 4
  %2148 = trunc i32 %2147 to i8
  %2149 = and i8 %2148, 1
  store i8 %2149, i8* %52, align 1, !tbaa !2447
  %2150 = zext i1 %2138 to i8
  store i8 %2150, i8* %53, align 1, !tbaa !2448
  %2151 = lshr i32 %2135, 31
  %2152 = trunc i32 %2151 to i8
  store i8 %2152, i8* %54, align 1, !tbaa !2449
  %2153 = lshr i32 %2134, 31
  %2154 = xor i32 %2151, %2153
  %2155 = add nuw nsw i32 %2154, %2151
  %2156 = icmp eq i32 %2155, 2
  %2157 = zext i1 %2156 to i8
  store i8 %2157, i8* %55, align 1, !tbaa !2450
  %2158 = sext i32 %2135 to i64
  store i64 %2158, i64* %RDX, align 8, !tbaa !2428
  %2159 = shl nsw i64 %2158, 3
  %2160 = add i64 %2159, %2130
  %2161 = add i64 %2127, 18
  store i64 %2161, i64* %PC, align 8
  %2162 = inttoptr i64 %2160 to i64*
  %2163 = load i64, i64* %2162, align 8
  store i64 %2163, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2164 = add i64 %2125, -72
  %2165 = add i64 %2127, 23
  store i64 %2165, i64* %PC, align 8
  %2166 = inttoptr i64 %2164 to i64*
  store i64 %2163, i64* %2166, align 8
  %2167 = load i64, i64* %RBP, align 8
  %2168 = add i64 %2167, -24
  %2169 = load i64, i64* %PC, align 8
  %2170 = add i64 %2169, 4
  store i64 %2170, i64* %PC, align 8
  %2171 = inttoptr i64 %2168 to i64*
  %2172 = load i64, i64* %2171, align 8
  store i64 %2172, i64* %RCX, align 8, !tbaa !2428
  %2173 = add i64 %2167, -40
  %2174 = add i64 %2169, 8
  store i64 %2174, i64* %PC, align 8
  %2175 = inttoptr i64 %2173 to i32*
  %2176 = load i32, i32* %2175, align 4
  %2177 = sext i32 %2176 to i64
  store i64 %2177, i64* %RDX, align 8, !tbaa !2428
  %2178 = shl nsw i64 %2177, 3
  %2179 = add i64 %2178, %2172
  %2180 = add i64 %2169, 13
  store i64 %2180, i64* %PC, align 8
  %2181 = inttoptr i64 %2179 to i64*
  %2182 = load i64, i64* %2181, align 8
  store i64 %2182, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2183 = add i64 %2167, -80
  %2184 = add i64 %2169, 18
  store i64 %2184, i64* %PC, align 8
  %2185 = inttoptr i64 %2183 to i64*
  store i64 %2182, i64* %2185, align 8
  %2186 = load i64, i64* %RBP, align 8
  %2187 = add i64 %2186, -24
  %2188 = load i64, i64* %PC, align 8
  %2189 = add i64 %2188, 4
  store i64 %2189, i64* %PC, align 8
  %2190 = inttoptr i64 %2187 to i64*
  %2191 = load i64, i64* %2190, align 8
  store i64 %2191, i64* %RCX, align 8, !tbaa !2428
  %2192 = add i64 %2186, -40
  %2193 = add i64 %2188, 7
  store i64 %2193, i64* %PC, align 8
  %2194 = inttoptr i64 %2192 to i32*
  %2195 = load i32, i32* %2194, align 4
  %2196 = add i32 %2195, 1
  %2197 = zext i32 %2196 to i64
  store i64 %2197, i64* %RAX, align 8, !tbaa !2428
  %2198 = icmp eq i32 %2195, -1
  %2199 = icmp eq i32 %2196, 0
  %2200 = or i1 %2198, %2199
  %2201 = zext i1 %2200 to i8
  store i8 %2201, i8* %50, align 1, !tbaa !2432
  %2202 = and i32 %2196, 255
  %2203 = tail call i32 @llvm.ctpop.i32(i32 %2202) #11
  %2204 = trunc i32 %2203 to i8
  %2205 = and i8 %2204, 1
  %2206 = xor i8 %2205, 1
  store i8 %2206, i8* %51, align 1, !tbaa !2446
  %2207 = xor i32 %2196, %2195
  %2208 = lshr i32 %2207, 4
  %2209 = trunc i32 %2208 to i8
  %2210 = and i8 %2209, 1
  store i8 %2210, i8* %52, align 1, !tbaa !2447
  %2211 = zext i1 %2199 to i8
  store i8 %2211, i8* %53, align 1, !tbaa !2448
  %2212 = lshr i32 %2196, 31
  %2213 = trunc i32 %2212 to i8
  store i8 %2213, i8* %54, align 1, !tbaa !2449
  %2214 = lshr i32 %2195, 31
  %2215 = xor i32 %2212, %2214
  %2216 = add nuw nsw i32 %2215, %2212
  %2217 = icmp eq i32 %2216, 2
  %2218 = zext i1 %2217 to i8
  store i8 %2218, i8* %55, align 1, !tbaa !2450
  %2219 = sext i32 %2196 to i64
  store i64 %2219, i64* %RDX, align 8, !tbaa !2428
  %2220 = shl nsw i64 %2219, 3
  %2221 = add i64 %2220, %2191
  %2222 = add i64 %2188, 18
  store i64 %2222, i64* %PC, align 8
  %2223 = inttoptr i64 %2221 to i64*
  %2224 = load i64, i64* %2223, align 8
  store i64 %2224, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2225 = add i64 %2186, -88
  %2226 = add i64 %2188, 23
  store i64 %2226, i64* %PC, align 8
  %2227 = inttoptr i64 %2225 to i64*
  store i64 %2224, i64* %2227, align 8
  %2228 = load i64, i64* %RBP, align 8
  %2229 = add i64 %2228, -80
  %2230 = load i64, i64* %PC, align 8
  %2231 = add i64 %2230, 5
  store i64 %2231, i64* %PC, align 8
  %2232 = inttoptr i64 %2229 to i64*
  %2233 = load i64, i64* %2232, align 8
  store i64 %2233, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2234 = add i64 %2228, -24
  %2235 = add i64 %2230, 9
  store i64 %2235, i64* %PC, align 8
  %2236 = inttoptr i64 %2234 to i64*
  %2237 = load i64, i64* %2236, align 8
  store i64 %2237, i64* %RCX, align 8, !tbaa !2428
  %2238 = add i64 %2228, -32
  %2239 = add i64 %2230, 13
  store i64 %2239, i64* %PC, align 8
  %2240 = inttoptr i64 %2238 to i32*
  %2241 = load i32, i32* %2240, align 4
  %2242 = sext i32 %2241 to i64
  store i64 %2242, i64* %RDX, align 8, !tbaa !2428
  %2243 = shl nsw i64 %2242, 3
  %2244 = add i64 %2243, %2237
  %2245 = add i64 %2230, 18
  store i64 %2245, i64* %PC, align 8
  %2246 = inttoptr i64 %2244 to i64*
  store i64 %2233, i64* %2246, align 8
  %2247 = load i64, i64* %RBP, align 8
  %2248 = add i64 %2247, -88
  %2249 = load i64, i64* %PC, align 8
  %2250 = add i64 %2249, 5
  store i64 %2250, i64* %PC, align 8
  %2251 = inttoptr i64 %2248 to i64*
  %2252 = load i64, i64* %2251, align 8
  store i64 %2252, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2253 = add i64 %2247, -24
  %2254 = add i64 %2249, 9
  store i64 %2254, i64* %PC, align 8
  %2255 = inttoptr i64 %2253 to i64*
  %2256 = load i64, i64* %2255, align 8
  store i64 %2256, i64* %RCX, align 8, !tbaa !2428
  %2257 = add i64 %2247, -32
  %2258 = add i64 %2249, 12
  store i64 %2258, i64* %PC, align 8
  %2259 = inttoptr i64 %2257 to i32*
  %2260 = load i32, i32* %2259, align 4
  %2261 = add i32 %2260, 1
  %2262 = zext i32 %2261 to i64
  store i64 %2262, i64* %RAX, align 8, !tbaa !2428
  %2263 = icmp eq i32 %2260, -1
  %2264 = icmp eq i32 %2261, 0
  %2265 = or i1 %2263, %2264
  %2266 = zext i1 %2265 to i8
  store i8 %2266, i8* %50, align 1, !tbaa !2432
  %2267 = and i32 %2261, 255
  %2268 = tail call i32 @llvm.ctpop.i32(i32 %2267) #11
  %2269 = trunc i32 %2268 to i8
  %2270 = and i8 %2269, 1
  %2271 = xor i8 %2270, 1
  store i8 %2271, i8* %51, align 1, !tbaa !2446
  %2272 = xor i32 %2261, %2260
  %2273 = lshr i32 %2272, 4
  %2274 = trunc i32 %2273 to i8
  %2275 = and i8 %2274, 1
  store i8 %2275, i8* %52, align 1, !tbaa !2447
  %2276 = zext i1 %2264 to i8
  store i8 %2276, i8* %53, align 1, !tbaa !2448
  %2277 = lshr i32 %2261, 31
  %2278 = trunc i32 %2277 to i8
  store i8 %2278, i8* %54, align 1, !tbaa !2449
  %2279 = lshr i32 %2260, 31
  %2280 = xor i32 %2277, %2279
  %2281 = add nuw nsw i32 %2280, %2277
  %2282 = icmp eq i32 %2281, 2
  %2283 = zext i1 %2282 to i8
  store i8 %2283, i8* %55, align 1, !tbaa !2450
  %2284 = sext i32 %2261 to i64
  store i64 %2284, i64* %RDX, align 8, !tbaa !2428
  %2285 = shl nsw i64 %2284, 3
  %2286 = add i64 %2285, %2256
  %2287 = add i64 %2249, 23
  store i64 %2287, i64* %PC, align 8
  %2288 = inttoptr i64 %2286 to i64*
  store i64 %2252, i64* %2288, align 8
  %2289 = load i64, i64* %RBP, align 8
  %2290 = add i64 %2289, -64
  %2291 = load i64, i64* %PC, align 8
  %2292 = add i64 %2291, 5
  store i64 %2292, i64* %PC, align 8
  %2293 = inttoptr i64 %2290 to i64*
  %2294 = load i64, i64* %2293, align 8
  store i64 %2294, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2295 = add i64 %2289, -24
  %2296 = add i64 %2291, 9
  store i64 %2296, i64* %PC, align 8
  %2297 = inttoptr i64 %2295 to i64*
  %2298 = load i64, i64* %2297, align 8
  store i64 %2298, i64* %RCX, align 8, !tbaa !2428
  %2299 = add i64 %2289, -40
  %2300 = add i64 %2291, 13
  store i64 %2300, i64* %PC, align 8
  %2301 = inttoptr i64 %2299 to i32*
  %2302 = load i32, i32* %2301, align 4
  %2303 = sext i32 %2302 to i64
  store i64 %2303, i64* %RDX, align 8, !tbaa !2428
  %2304 = shl nsw i64 %2303, 3
  %2305 = add i64 %2304, %2298
  %2306 = add i64 %2291, 18
  store i64 %2306, i64* %PC, align 8
  %2307 = inttoptr i64 %2305 to i64*
  store i64 %2294, i64* %2307, align 8
  %2308 = load i64, i64* %RBP, align 8
  %2309 = add i64 %2308, -72
  %2310 = load i64, i64* %PC, align 8
  %2311 = add i64 %2310, 5
  store i64 %2311, i64* %PC, align 8
  %2312 = inttoptr i64 %2309 to i64*
  %2313 = load i64, i64* %2312, align 8
  store i64 %2313, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2314 = add i64 %2308, -24
  %2315 = add i64 %2310, 9
  store i64 %2315, i64* %PC, align 8
  %2316 = inttoptr i64 %2314 to i64*
  %2317 = load i64, i64* %2316, align 8
  store i64 %2317, i64* %RCX, align 8, !tbaa !2428
  %2318 = add i64 %2308, -40
  %2319 = add i64 %2310, 12
  store i64 %2319, i64* %PC, align 8
  %2320 = inttoptr i64 %2318 to i32*
  %2321 = load i32, i32* %2320, align 4
  %2322 = add i32 %2321, 1
  %2323 = zext i32 %2322 to i64
  store i64 %2323, i64* %RAX, align 8, !tbaa !2428
  %2324 = icmp eq i32 %2321, -1
  %2325 = icmp eq i32 %2322, 0
  %2326 = or i1 %2324, %2325
  %2327 = zext i1 %2326 to i8
  store i8 %2327, i8* %50, align 1, !tbaa !2432
  %2328 = and i32 %2322, 255
  %2329 = tail call i32 @llvm.ctpop.i32(i32 %2328) #11
  %2330 = trunc i32 %2329 to i8
  %2331 = and i8 %2330, 1
  %2332 = xor i8 %2331, 1
  store i8 %2332, i8* %51, align 1, !tbaa !2446
  %2333 = xor i32 %2322, %2321
  %2334 = lshr i32 %2333, 4
  %2335 = trunc i32 %2334 to i8
  %2336 = and i8 %2335, 1
  store i8 %2336, i8* %52, align 1, !tbaa !2447
  %2337 = zext i1 %2325 to i8
  store i8 %2337, i8* %53, align 1, !tbaa !2448
  %2338 = lshr i32 %2322, 31
  %2339 = trunc i32 %2338 to i8
  store i8 %2339, i8* %54, align 1, !tbaa !2449
  %2340 = lshr i32 %2321, 31
  %2341 = xor i32 %2338, %2340
  %2342 = add nuw nsw i32 %2341, %2338
  %2343 = icmp eq i32 %2342, 2
  %2344 = zext i1 %2343 to i8
  store i8 %2344, i8* %55, align 1, !tbaa !2450
  %2345 = sext i32 %2322 to i64
  store i64 %2345, i64* %RDX, align 8, !tbaa !2428
  %2346 = shl nsw i64 %2345, 3
  %2347 = add i64 %2346, %2317
  %2348 = add i64 %2310, 23
  store i64 %2348, i64* %PC, align 8
  %2349 = inttoptr i64 %2347 to i64*
  store i64 %2313, i64* %2349, align 8
  %2350 = load i64, i64* %RBP, align 8
  %2351 = add i64 %2350, -52
  %2352 = load i64, i64* %PC, align 8
  %2353 = add i64 %2352, 3
  store i64 %2353, i64* %PC, align 8
  %2354 = inttoptr i64 %2351 to i32*
  %2355 = load i32, i32* %2354, align 4
  %2356 = zext i32 %2355 to i64
  store i64 %2356, i64* %RAX, align 8, !tbaa !2428
  %2357 = add i64 %2350, -32
  %2358 = add i64 %2352, 6
  store i64 %2358, i64* %PC, align 8
  %2359 = inttoptr i64 %2357 to i32*
  %2360 = load i32, i32* %2359, align 4
  %2361 = add i32 %2360, %2355
  %2362 = zext i32 %2361 to i64
  store i64 %2362, i64* %RAX, align 8, !tbaa !2428
  %2363 = icmp ult i32 %2361, %2355
  %2364 = icmp ult i32 %2361, %2360
  %2365 = or i1 %2363, %2364
  %2366 = zext i1 %2365 to i8
  store i8 %2366, i8* %50, align 1, !tbaa !2432
  %2367 = and i32 %2361, 255
  %2368 = tail call i32 @llvm.ctpop.i32(i32 %2367) #11
  %2369 = trunc i32 %2368 to i8
  %2370 = and i8 %2369, 1
  %2371 = xor i8 %2370, 1
  store i8 %2371, i8* %51, align 1, !tbaa !2446
  %2372 = xor i32 %2360, %2355
  %2373 = xor i32 %2372, %2361
  %2374 = lshr i32 %2373, 4
  %2375 = trunc i32 %2374 to i8
  %2376 = and i8 %2375, 1
  store i8 %2376, i8* %52, align 1, !tbaa !2447
  %2377 = icmp eq i32 %2361, 0
  %2378 = zext i1 %2377 to i8
  store i8 %2378, i8* %53, align 1, !tbaa !2448
  %2379 = lshr i32 %2361, 31
  %2380 = trunc i32 %2379 to i8
  store i8 %2380, i8* %54, align 1, !tbaa !2449
  %2381 = lshr i32 %2355, 31
  %2382 = lshr i32 %2360, 31
  %2383 = xor i32 %2379, %2381
  %2384 = xor i32 %2379, %2382
  %2385 = add nuw nsw i32 %2383, %2384
  %2386 = icmp eq i32 %2385, 2
  %2387 = zext i1 %2386 to i8
  store i8 %2387, i8* %55, align 1, !tbaa !2450
  %2388 = add i64 %2352, 9
  store i64 %2388, i64* %PC, align 8
  store i32 %2361, i32* %2359, align 4
  %2389 = load i64, i64* %RBP, align 8
  %2390 = add i64 %2389, -52
  %2391 = load i64, i64* %PC, align 8
  %2392 = add i64 %2391, 3
  store i64 %2392, i64* %PC, align 8
  %2393 = inttoptr i64 %2390 to i32*
  %2394 = load i32, i32* %2393, align 4
  %2395 = zext i32 %2394 to i64
  store i64 %2395, i64* %RAX, align 8, !tbaa !2428
  %2396 = add i64 %2389, -40
  %2397 = add i64 %2391, 6
  store i64 %2397, i64* %PC, align 8
  %2398 = inttoptr i64 %2396 to i32*
  %2399 = load i32, i32* %2398, align 4
  %2400 = add i32 %2399, %2394
  %2401 = zext i32 %2400 to i64
  store i64 %2401, i64* %RAX, align 8, !tbaa !2428
  %2402 = icmp ult i32 %2400, %2394
  %2403 = icmp ult i32 %2400, %2399
  %2404 = or i1 %2402, %2403
  %2405 = zext i1 %2404 to i8
  store i8 %2405, i8* %50, align 1, !tbaa !2432
  %2406 = and i32 %2400, 255
  %2407 = tail call i32 @llvm.ctpop.i32(i32 %2406) #11
  %2408 = trunc i32 %2407 to i8
  %2409 = and i8 %2408, 1
  %2410 = xor i8 %2409, 1
  store i8 %2410, i8* %51, align 1, !tbaa !2446
  %2411 = xor i32 %2399, %2394
  %2412 = xor i32 %2411, %2400
  %2413 = lshr i32 %2412, 4
  %2414 = trunc i32 %2413 to i8
  %2415 = and i8 %2414, 1
  store i8 %2415, i8* %52, align 1, !tbaa !2447
  %2416 = icmp eq i32 %2400, 0
  %2417 = zext i1 %2416 to i8
  store i8 %2417, i8* %53, align 1, !tbaa !2448
  %2418 = lshr i32 %2400, 31
  %2419 = trunc i32 %2418 to i8
  store i8 %2419, i8* %54, align 1, !tbaa !2449
  %2420 = lshr i32 %2394, 31
  %2421 = lshr i32 %2399, 31
  %2422 = xor i32 %2418, %2420
  %2423 = xor i32 %2418, %2421
  %2424 = add nuw nsw i32 %2422, %2423
  %2425 = icmp eq i32 %2424, 2
  %2426 = zext i1 %2425 to i8
  store i8 %2426, i8* %55, align 1, !tbaa !2450
  %2427 = add i64 %2391, 9
  store i64 %2427, i64* %PC, align 8
  store i32 %2400, i32* %2398, align 4
  %2428 = load i64, i64* %RBP, align 8
  %2429 = add i64 %2428, -24
  %2430 = load i64, i64* %PC, align 8
  %2431 = add i64 %2430, 4
  store i64 %2431, i64* %PC, align 8
  %2432 = inttoptr i64 %2429 to i64*
  %2433 = load i64, i64* %2432, align 8
  store i64 %2433, i64* %RCX, align 8, !tbaa !2428
  %2434 = add i64 %2428, -32
  %2435 = add i64 %2430, 8
  store i64 %2435, i64* %PC, align 8
  %2436 = inttoptr i64 %2434 to i32*
  %2437 = load i32, i32* %2436, align 4
  %2438 = sext i32 %2437 to i64
  store i64 %2438, i64* %RDX, align 8, !tbaa !2428
  %2439 = shl nsw i64 %2438, 3
  %2440 = add i64 %2439, %2433
  %2441 = add i64 %2430, 13
  store i64 %2441, i64* %PC, align 8
  %2442 = inttoptr i64 %2440 to i64*
  %2443 = load i64, i64* %2442, align 8
  store i64 %2443, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2444 = add i64 %2428, -64
  %2445 = add i64 %2430, 18
  store i64 %2445, i64* %PC, align 8
  %2446 = inttoptr i64 %2444 to i64*
  store i64 %2443, i64* %2446, align 8
  %2447 = load i64, i64* %RBP, align 8
  %2448 = add i64 %2447, -24
  %2449 = load i64, i64* %PC, align 8
  %2450 = add i64 %2449, 4
  store i64 %2450, i64* %PC, align 8
  %2451 = inttoptr i64 %2448 to i64*
  %2452 = load i64, i64* %2451, align 8
  store i64 %2452, i64* %RCX, align 8, !tbaa !2428
  %2453 = add i64 %2447, -32
  %2454 = add i64 %2449, 7
  store i64 %2454, i64* %PC, align 8
  %2455 = inttoptr i64 %2453 to i32*
  %2456 = load i32, i32* %2455, align 4
  %2457 = add i32 %2456, 1
  %2458 = zext i32 %2457 to i64
  store i64 %2458, i64* %RAX, align 8, !tbaa !2428
  %2459 = icmp eq i32 %2456, -1
  %2460 = icmp eq i32 %2457, 0
  %2461 = or i1 %2459, %2460
  %2462 = zext i1 %2461 to i8
  store i8 %2462, i8* %50, align 1, !tbaa !2432
  %2463 = and i32 %2457, 255
  %2464 = tail call i32 @llvm.ctpop.i32(i32 %2463) #11
  %2465 = trunc i32 %2464 to i8
  %2466 = and i8 %2465, 1
  %2467 = xor i8 %2466, 1
  store i8 %2467, i8* %51, align 1, !tbaa !2446
  %2468 = xor i32 %2457, %2456
  %2469 = lshr i32 %2468, 4
  %2470 = trunc i32 %2469 to i8
  %2471 = and i8 %2470, 1
  store i8 %2471, i8* %52, align 1, !tbaa !2447
  %2472 = zext i1 %2460 to i8
  store i8 %2472, i8* %53, align 1, !tbaa !2448
  %2473 = lshr i32 %2457, 31
  %2474 = trunc i32 %2473 to i8
  store i8 %2474, i8* %54, align 1, !tbaa !2449
  %2475 = lshr i32 %2456, 31
  %2476 = xor i32 %2473, %2475
  %2477 = add nuw nsw i32 %2476, %2473
  %2478 = icmp eq i32 %2477, 2
  %2479 = zext i1 %2478 to i8
  store i8 %2479, i8* %55, align 1, !tbaa !2450
  %2480 = sext i32 %2457 to i64
  store i64 %2480, i64* %RDX, align 8, !tbaa !2428
  %2481 = shl nsw i64 %2480, 3
  %2482 = add i64 %2481, %2452
  %2483 = add i64 %2449, 18
  store i64 %2483, i64* %PC, align 8
  %2484 = inttoptr i64 %2482 to i64*
  %2485 = load i64, i64* %2484, align 8
  store i64 %2485, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2486 = add i64 %2447, -72
  %2487 = add i64 %2449, 23
  store i64 %2487, i64* %PC, align 8
  %2488 = inttoptr i64 %2486 to i64*
  store i64 %2485, i64* %2488, align 8
  %2489 = load i64, i64* %RBP, align 8
  %2490 = add i64 %2489, -24
  %2491 = load i64, i64* %PC, align 8
  %2492 = add i64 %2491, 4
  store i64 %2492, i64* %PC, align 8
  %2493 = inttoptr i64 %2490 to i64*
  %2494 = load i64, i64* %2493, align 8
  store i64 %2494, i64* %RCX, align 8, !tbaa !2428
  %2495 = add i64 %2489, -40
  %2496 = add i64 %2491, 8
  store i64 %2496, i64* %PC, align 8
  %2497 = inttoptr i64 %2495 to i32*
  %2498 = load i32, i32* %2497, align 4
  %2499 = sext i32 %2498 to i64
  store i64 %2499, i64* %RDX, align 8, !tbaa !2428
  %2500 = shl nsw i64 %2499, 3
  %2501 = add i64 %2500, %2494
  %2502 = add i64 %2491, 13
  store i64 %2502, i64* %PC, align 8
  %2503 = inttoptr i64 %2501 to i64*
  %2504 = load i64, i64* %2503, align 8
  store i64 %2504, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2505 = add i64 %2489, -80
  %2506 = add i64 %2491, 18
  store i64 %2506, i64* %PC, align 8
  %2507 = inttoptr i64 %2505 to i64*
  store i64 %2504, i64* %2507, align 8
  %2508 = load i64, i64* %RBP, align 8
  %2509 = add i64 %2508, -24
  %2510 = load i64, i64* %PC, align 8
  %2511 = add i64 %2510, 4
  store i64 %2511, i64* %PC, align 8
  %2512 = inttoptr i64 %2509 to i64*
  %2513 = load i64, i64* %2512, align 8
  store i64 %2513, i64* %RCX, align 8, !tbaa !2428
  %2514 = add i64 %2508, -40
  %2515 = add i64 %2510, 7
  store i64 %2515, i64* %PC, align 8
  %2516 = inttoptr i64 %2514 to i32*
  %2517 = load i32, i32* %2516, align 4
  %2518 = add i32 %2517, 1
  %2519 = zext i32 %2518 to i64
  store i64 %2519, i64* %RAX, align 8, !tbaa !2428
  %2520 = icmp eq i32 %2517, -1
  %2521 = icmp eq i32 %2518, 0
  %2522 = or i1 %2520, %2521
  %2523 = zext i1 %2522 to i8
  store i8 %2523, i8* %50, align 1, !tbaa !2432
  %2524 = and i32 %2518, 255
  %2525 = tail call i32 @llvm.ctpop.i32(i32 %2524) #11
  %2526 = trunc i32 %2525 to i8
  %2527 = and i8 %2526, 1
  %2528 = xor i8 %2527, 1
  store i8 %2528, i8* %51, align 1, !tbaa !2446
  %2529 = xor i32 %2518, %2517
  %2530 = lshr i32 %2529, 4
  %2531 = trunc i32 %2530 to i8
  %2532 = and i8 %2531, 1
  store i8 %2532, i8* %52, align 1, !tbaa !2447
  %2533 = zext i1 %2521 to i8
  store i8 %2533, i8* %53, align 1, !tbaa !2448
  %2534 = lshr i32 %2518, 31
  %2535 = trunc i32 %2534 to i8
  store i8 %2535, i8* %54, align 1, !tbaa !2449
  %2536 = lshr i32 %2517, 31
  %2537 = xor i32 %2534, %2536
  %2538 = add nuw nsw i32 %2537, %2534
  %2539 = icmp eq i32 %2538, 2
  %2540 = zext i1 %2539 to i8
  store i8 %2540, i8* %55, align 1, !tbaa !2450
  %2541 = sext i32 %2518 to i64
  store i64 %2541, i64* %RDX, align 8, !tbaa !2428
  %2542 = shl nsw i64 %2541, 3
  %2543 = add i64 %2542, %2513
  %2544 = add i64 %2510, 18
  store i64 %2544, i64* %PC, align 8
  %2545 = inttoptr i64 %2543 to i64*
  %2546 = load i64, i64* %2545, align 8
  store i64 %2546, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2547 = add i64 %2508, -88
  %2548 = add i64 %2510, 23
  store i64 %2548, i64* %PC, align 8
  %2549 = inttoptr i64 %2547 to i64*
  store i64 %2546, i64* %2549, align 8
  %2550 = load i64, i64* %RBP, align 8
  %2551 = add i64 %2550, -80
  %2552 = load i64, i64* %PC, align 8
  %2553 = add i64 %2552, 5
  store i64 %2553, i64* %PC, align 8
  %2554 = inttoptr i64 %2551 to i64*
  %2555 = load i64, i64* %2554, align 8
  store i64 %2555, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2556 = add i64 %2550, -24
  %2557 = add i64 %2552, 9
  store i64 %2557, i64* %PC, align 8
  %2558 = inttoptr i64 %2556 to i64*
  %2559 = load i64, i64* %2558, align 8
  store i64 %2559, i64* %RCX, align 8, !tbaa !2428
  %2560 = add i64 %2550, -32
  %2561 = add i64 %2552, 13
  store i64 %2561, i64* %PC, align 8
  %2562 = inttoptr i64 %2560 to i32*
  %2563 = load i32, i32* %2562, align 4
  %2564 = sext i32 %2563 to i64
  store i64 %2564, i64* %RDX, align 8, !tbaa !2428
  %2565 = shl nsw i64 %2564, 3
  %2566 = add i64 %2565, %2559
  %2567 = add i64 %2552, 18
  store i64 %2567, i64* %PC, align 8
  %2568 = inttoptr i64 %2566 to i64*
  store i64 %2555, i64* %2568, align 8
  %2569 = load i64, i64* %RBP, align 8
  %2570 = add i64 %2569, -88
  %2571 = load i64, i64* %PC, align 8
  %2572 = add i64 %2571, 5
  store i64 %2572, i64* %PC, align 8
  %2573 = inttoptr i64 %2570 to i64*
  %2574 = load i64, i64* %2573, align 8
  store i64 %2574, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2575 = add i64 %2569, -24
  %2576 = add i64 %2571, 9
  store i64 %2576, i64* %PC, align 8
  %2577 = inttoptr i64 %2575 to i64*
  %2578 = load i64, i64* %2577, align 8
  store i64 %2578, i64* %RCX, align 8, !tbaa !2428
  %2579 = add i64 %2569, -32
  %2580 = add i64 %2571, 12
  store i64 %2580, i64* %PC, align 8
  %2581 = inttoptr i64 %2579 to i32*
  %2582 = load i32, i32* %2581, align 4
  %2583 = add i32 %2582, 1
  %2584 = zext i32 %2583 to i64
  store i64 %2584, i64* %RAX, align 8, !tbaa !2428
  %2585 = icmp eq i32 %2582, -1
  %2586 = icmp eq i32 %2583, 0
  %2587 = or i1 %2585, %2586
  %2588 = zext i1 %2587 to i8
  store i8 %2588, i8* %50, align 1, !tbaa !2432
  %2589 = and i32 %2583, 255
  %2590 = tail call i32 @llvm.ctpop.i32(i32 %2589) #11
  %2591 = trunc i32 %2590 to i8
  %2592 = and i8 %2591, 1
  %2593 = xor i8 %2592, 1
  store i8 %2593, i8* %51, align 1, !tbaa !2446
  %2594 = xor i32 %2583, %2582
  %2595 = lshr i32 %2594, 4
  %2596 = trunc i32 %2595 to i8
  %2597 = and i8 %2596, 1
  store i8 %2597, i8* %52, align 1, !tbaa !2447
  %2598 = zext i1 %2586 to i8
  store i8 %2598, i8* %53, align 1, !tbaa !2448
  %2599 = lshr i32 %2583, 31
  %2600 = trunc i32 %2599 to i8
  store i8 %2600, i8* %54, align 1, !tbaa !2449
  %2601 = lshr i32 %2582, 31
  %2602 = xor i32 %2599, %2601
  %2603 = add nuw nsw i32 %2602, %2599
  %2604 = icmp eq i32 %2603, 2
  %2605 = zext i1 %2604 to i8
  store i8 %2605, i8* %55, align 1, !tbaa !2450
  %2606 = sext i32 %2583 to i64
  store i64 %2606, i64* %RDX, align 8, !tbaa !2428
  %2607 = shl nsw i64 %2606, 3
  %2608 = add i64 %2607, %2578
  %2609 = add i64 %2571, 23
  store i64 %2609, i64* %PC, align 8
  %2610 = inttoptr i64 %2608 to i64*
  store i64 %2574, i64* %2610, align 8
  %2611 = load i64, i64* %RBP, align 8
  %2612 = add i64 %2611, -64
  %2613 = load i64, i64* %PC, align 8
  %2614 = add i64 %2613, 5
  store i64 %2614, i64* %PC, align 8
  %2615 = inttoptr i64 %2612 to i64*
  %2616 = load i64, i64* %2615, align 8
  store i64 %2616, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2617 = add i64 %2611, -24
  %2618 = add i64 %2613, 9
  store i64 %2618, i64* %PC, align 8
  %2619 = inttoptr i64 %2617 to i64*
  %2620 = load i64, i64* %2619, align 8
  store i64 %2620, i64* %RCX, align 8, !tbaa !2428
  %2621 = add i64 %2611, -40
  %2622 = add i64 %2613, 13
  store i64 %2622, i64* %PC, align 8
  %2623 = inttoptr i64 %2621 to i32*
  %2624 = load i32, i32* %2623, align 4
  %2625 = sext i32 %2624 to i64
  store i64 %2625, i64* %RDX, align 8, !tbaa !2428
  %2626 = shl nsw i64 %2625, 3
  %2627 = add i64 %2626, %2620
  %2628 = add i64 %2613, 18
  store i64 %2628, i64* %PC, align 8
  %2629 = inttoptr i64 %2627 to i64*
  store i64 %2616, i64* %2629, align 8
  %2630 = load i64, i64* %RBP, align 8
  %2631 = add i64 %2630, -72
  %2632 = load i64, i64* %PC, align 8
  %2633 = add i64 %2632, 5
  store i64 %2633, i64* %PC, align 8
  %2634 = inttoptr i64 %2631 to i64*
  %2635 = load i64, i64* %2634, align 8
  store i64 %2635, i64* %2920, align 1, !tbaa !2451
  store double 0.000000e+00, double* %2922, align 1, !tbaa !2451
  %2636 = add i64 %2630, -24
  %2637 = add i64 %2632, 9
  store i64 %2637, i64* %PC, align 8
  %2638 = inttoptr i64 %2636 to i64*
  %2639 = load i64, i64* %2638, align 8
  store i64 %2639, i64* %RCX, align 8, !tbaa !2428
  %2640 = add i64 %2630, -40
  %2641 = add i64 %2632, 12
  store i64 %2641, i64* %PC, align 8
  %2642 = inttoptr i64 %2640 to i32*
  %2643 = load i32, i32* %2642, align 4
  %2644 = add i32 %2643, 1
  %2645 = zext i32 %2644 to i64
  store i64 %2645, i64* %RAX, align 8, !tbaa !2428
  %2646 = icmp eq i32 %2643, -1
  %2647 = icmp eq i32 %2644, 0
  %2648 = or i1 %2646, %2647
  %2649 = zext i1 %2648 to i8
  store i8 %2649, i8* %50, align 1, !tbaa !2432
  %2650 = and i32 %2644, 255
  %2651 = tail call i32 @llvm.ctpop.i32(i32 %2650) #11
  %2652 = trunc i32 %2651 to i8
  %2653 = and i8 %2652, 1
  %2654 = xor i8 %2653, 1
  store i8 %2654, i8* %51, align 1, !tbaa !2446
  %2655 = xor i32 %2644, %2643
  %2656 = lshr i32 %2655, 4
  %2657 = trunc i32 %2656 to i8
  %2658 = and i8 %2657, 1
  store i8 %2658, i8* %52, align 1, !tbaa !2447
  %2659 = zext i1 %2647 to i8
  store i8 %2659, i8* %53, align 1, !tbaa !2448
  %2660 = lshr i32 %2644, 31
  %2661 = trunc i32 %2660 to i8
  store i8 %2661, i8* %54, align 1, !tbaa !2449
  %2662 = lshr i32 %2643, 31
  %2663 = xor i32 %2660, %2662
  %2664 = add nuw nsw i32 %2663, %2660
  %2665 = icmp eq i32 %2664, 2
  %2666 = zext i1 %2665 to i8
  store i8 %2666, i8* %55, align 1, !tbaa !2450
  %2667 = sext i32 %2644 to i64
  store i64 %2667, i64* %RDX, align 8, !tbaa !2428
  %2668 = shl nsw i64 %2667, 3
  %2669 = add i64 %2668, %2639
  %2670 = add i64 %2632, 23
  store i64 %2670, i64* %PC, align 8
  %2671 = inttoptr i64 %2669 to i64*
  store i64 %2635, i64* %2671, align 8
  %2672 = load i64, i64* %RBP, align 8
  %2673 = add i64 %2672, -28
  %2674 = load i64, i64* %PC, align 8
  %2675 = add i64 %2674, 3
  store i64 %2675, i64* %PC, align 8
  %2676 = inttoptr i64 %2673 to i32*
  %2677 = load i32, i32* %2676, align 4
  %2678 = add i32 %2677, 1
  %2679 = zext i32 %2678 to i64
  store i64 %2679, i64* %RAX, align 8, !tbaa !2428
  %2680 = icmp eq i32 %2677, -1
  %2681 = icmp eq i32 %2678, 0
  %2682 = or i1 %2680, %2681
  %2683 = zext i1 %2682 to i8
  store i8 %2683, i8* %50, align 1, !tbaa !2432
  %2684 = and i32 %2678, 255
  %2685 = tail call i32 @llvm.ctpop.i32(i32 %2684) #11
  %2686 = trunc i32 %2685 to i8
  %2687 = and i8 %2686, 1
  %2688 = xor i8 %2687, 1
  store i8 %2688, i8* %51, align 1, !tbaa !2446
  %2689 = xor i32 %2678, %2677
  %2690 = lshr i32 %2689, 4
  %2691 = trunc i32 %2690 to i8
  %2692 = and i8 %2691, 1
  store i8 %2692, i8* %52, align 1, !tbaa !2447
  %2693 = zext i1 %2681 to i8
  store i8 %2693, i8* %53, align 1, !tbaa !2448
  %2694 = lshr i32 %2678, 31
  %2695 = trunc i32 %2694 to i8
  store i8 %2695, i8* %54, align 1, !tbaa !2449
  %2696 = lshr i32 %2677, 31
  %2697 = xor i32 %2694, %2696
  %2698 = add nuw nsw i32 %2697, %2694
  %2699 = icmp eq i32 %2698, 2
  %2700 = zext i1 %2699 to i8
  store i8 %2700, i8* %55, align 1, !tbaa !2450
  %2701 = add i64 %2674, 9
  store i64 %2701, i64* %PC, align 8
  store i32 %2678, i32* %2676, align 4
  %2702 = load i64, i64* %PC, align 8
  %2703 = add i64 %2702, -407
  store i64 %2703, i64* %PC, align 8, !tbaa !2428
  br label %block_4016ae

block_4012a6:                                     ; preds = %block_40129a
  %2704 = add i64 %2809, -28
  %2705 = add i64 %2845, 7
  store i64 %2705, i64* %PC, align 8
  %2706 = inttoptr i64 %2704 to i32*
  store i32 0, i32* %2706, align 4
  %.pre42 = load i64, i64* %PC, align 8
  br label %block_4012ad

block_401225:                                     ; preds = %block_401216
  %2707 = add i64 %2919, 3
  store i64 %2707, i64* %PC, align 8
  %2708 = load i32, i32* %2891, align 4
  %2709 = zext i32 %2708 to i64
  %2710 = shl nuw i64 %2709, 32
  %2711 = ashr i64 %2710, 33
  %2712 = trunc i32 %2708 to i8
  %2713 = and i8 %2712, 1
  %2714 = trunc i64 %2711 to i32
  %2715 = and i64 %2711, 4294967295
  store i64 %2715, i64* %RAX, align 8, !tbaa !2428
  store i8 %2713, i8* %50, align 1, !tbaa !2453
  %2716 = and i32 %2714, 255
  %2717 = tail call i32 @llvm.ctpop.i32(i32 %2716) #11
  %2718 = trunc i32 %2717 to i8
  %2719 = and i8 %2718, 1
  %2720 = xor i8 %2719, 1
  store i8 %2720, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2721 = icmp eq i32 %2714, 0
  %2722 = zext i1 %2721 to i8
  store i8 %2722, i8* %53, align 1, !tbaa !2453
  %2723 = lshr i64 %2711, 31
  %2724 = trunc i64 %2723 to i8
  %2725 = and i8 %2724, 1
  store i8 %2725, i8* %54, align 1, !tbaa !2453
  store i8 0, i8* %55, align 1, !tbaa !2453
  %2726 = add i64 %2919, 9
  store i64 %2726, i64* %PC, align 8
  store i32 %2714, i32* %2891, align 4
  %2727 = load i64, i64* %RBP, align 8
  %2728 = add i64 %2727, -28
  %2729 = load i64, i64* %PC, align 8
  %2730 = add i64 %2729, 7
  store i64 %2730, i64* %PC, align 8
  %2731 = inttoptr i64 %2728 to i32*
  store i32 0, i32* %2731, align 4
  %.pre45 = load i64, i64* %PC, align 8
  br label %block_401235

block_40169b:                                     ; preds = %block_401694, %block_40184a
  %2732 = phi i64 [ %.pre43, %block_401694 ], [ %93, %block_40184a ]
  %2733 = load i64, i64* %RBP, align 8
  %2734 = add i64 %2733, -36
  %2735 = add i64 %2732, 3
  store i64 %2735, i64* %PC, align 8
  %2736 = inttoptr i64 %2734 to i32*
  %2737 = load i32, i32* %2736, align 4
  %2738 = zext i32 %2737 to i64
  store i64 %2738, i64* %RAX, align 8, !tbaa !2428
  %2739 = add i64 %2733, -48
  %2740 = add i64 %2732, 6
  store i64 %2740, i64* %PC, align 8
  %2741 = inttoptr i64 %2739 to i32*
  %2742 = load i32, i32* %2741, align 4
  %2743 = sub i32 %2737, %2742
  %2744 = icmp ult i32 %2737, %2742
  %2745 = zext i1 %2744 to i8
  store i8 %2745, i8* %50, align 1, !tbaa !2432
  %2746 = and i32 %2743, 255
  %2747 = tail call i32 @llvm.ctpop.i32(i32 %2746) #11
  %2748 = trunc i32 %2747 to i8
  %2749 = and i8 %2748, 1
  %2750 = xor i8 %2749, 1
  store i8 %2750, i8* %51, align 1, !tbaa !2446
  %2751 = xor i32 %2742, %2737
  %2752 = xor i32 %2751, %2743
  %2753 = lshr i32 %2752, 4
  %2754 = trunc i32 %2753 to i8
  %2755 = and i8 %2754, 1
  store i8 %2755, i8* %52, align 1, !tbaa !2447
  %2756 = icmp eq i32 %2743, 0
  %2757 = zext i1 %2756 to i8
  store i8 %2757, i8* %53, align 1, !tbaa !2448
  %2758 = lshr i32 %2743, 31
  %2759 = trunc i32 %2758 to i8
  store i8 %2759, i8* %54, align 1, !tbaa !2449
  %2760 = lshr i32 %2737, 31
  %2761 = lshr i32 %2742, 31
  %2762 = xor i32 %2761, %2760
  %2763 = xor i32 %2758, %2760
  %2764 = add nuw nsw i32 %2763, %2762
  %2765 = icmp eq i32 %2764, 2
  %2766 = zext i1 %2765 to i8
  store i8 %2766, i8* %55, align 1, !tbaa !2450
  %2767 = icmp ne i8 %2759, 0
  %2768 = xor i1 %2767, %2765
  %.v48 = select i1 %2768, i64 12, i64 450
  %2769 = add i64 %.v48, %2732
  store i64 %2769, i64* %PC, align 8, !tbaa !2428
  br i1 %2768, label %block_4016a7, label %block_401862.loopexit49

block_4016ae:                                     ; preds = %block_4016a7, %block_4016ba
  %2770 = phi i64 [ %.pre44, %block_4016a7 ], [ %2703, %block_4016ba ]
  %2771 = load i64, i64* %RBP, align 8
  %2772 = add i64 %2771, -28
  %2773 = add i64 %2770, 3
  store i64 %2773, i64* %PC, align 8
  %2774 = inttoptr i64 %2772 to i32*
  %2775 = load i32, i32* %2774, align 4
  %2776 = zext i32 %2775 to i64
  store i64 %2776, i64* %RAX, align 8, !tbaa !2428
  %2777 = add i64 %2771, -36
  %2778 = add i64 %2770, 6
  store i64 %2778, i64* %PC, align 8
  %2779 = inttoptr i64 %2777 to i32*
  %2780 = load i32, i32* %2779, align 4
  %2781 = sub i32 %2775, %2780
  %2782 = icmp ult i32 %2775, %2780
  %2783 = zext i1 %2782 to i8
  store i8 %2783, i8* %50, align 1, !tbaa !2432
  %2784 = and i32 %2781, 255
  %2785 = tail call i32 @llvm.ctpop.i32(i32 %2784) #11
  %2786 = trunc i32 %2785 to i8
  %2787 = and i8 %2786, 1
  %2788 = xor i8 %2787, 1
  store i8 %2788, i8* %51, align 1, !tbaa !2446
  %2789 = xor i32 %2780, %2775
  %2790 = xor i32 %2789, %2781
  %2791 = lshr i32 %2790, 4
  %2792 = trunc i32 %2791 to i8
  %2793 = and i8 %2792, 1
  store i8 %2793, i8* %52, align 1, !tbaa !2447
  %2794 = icmp eq i32 %2781, 0
  %2795 = zext i1 %2794 to i8
  store i8 %2795, i8* %53, align 1, !tbaa !2448
  %2796 = lshr i32 %2781, 31
  %2797 = trunc i32 %2796 to i8
  store i8 %2797, i8* %54, align 1, !tbaa !2449
  %2798 = lshr i32 %2775, 31
  %2799 = lshr i32 %2780, 31
  %2800 = xor i32 %2799, %2798
  %2801 = xor i32 %2796, %2798
  %2802 = add nuw nsw i32 %2801, %2800
  %2803 = icmp eq i32 %2802, 2
  %2804 = zext i1 %2803 to i8
  store i8 %2804, i8* %55, align 1, !tbaa !2450
  %2805 = icmp ne i8 %2797, 0
  %2806 = xor i1 %2805, %2803
  %.v46 = select i1 %2806, i64 12, i64 412
  %2807 = add i64 %.v46, %2770
  store i64 %2807, i64* %PC, align 8, !tbaa !2428
  br i1 %2806, label %block_4016ba, label %block_40184a

block_40129a:                                     ; preds = %block_401293, %block_4015bd
  %2808 = phi i64 [ %.pre41, %block_401293 ], [ %501, %block_4015bd ]
  %2809 = load i64, i64* %RBP, align 8
  %2810 = add i64 %2809, -36
  %2811 = add i64 %2808, 3
  store i64 %2811, i64* %PC, align 8
  %2812 = inttoptr i64 %2810 to i32*
  %2813 = load i32, i32* %2812, align 4
  %2814 = zext i32 %2813 to i64
  store i64 %2814, i64* %RAX, align 8, !tbaa !2428
  %2815 = add i64 %2809, -48
  %2816 = add i64 %2808, 6
  store i64 %2816, i64* %PC, align 8
  %2817 = inttoptr i64 %2815 to i32*
  %2818 = load i32, i32* %2817, align 4
  %2819 = sub i32 %2813, %2818
  %2820 = icmp ult i32 %2813, %2818
  %2821 = zext i1 %2820 to i8
  store i8 %2821, i8* %50, align 1, !tbaa !2432
  %2822 = and i32 %2819, 255
  %2823 = tail call i32 @llvm.ctpop.i32(i32 %2822) #11
  %2824 = trunc i32 %2823 to i8
  %2825 = and i8 %2824, 1
  %2826 = xor i8 %2825, 1
  store i8 %2826, i8* %51, align 1, !tbaa !2446
  %2827 = xor i32 %2818, %2813
  %2828 = xor i32 %2827, %2819
  %2829 = lshr i32 %2828, 4
  %2830 = trunc i32 %2829 to i8
  %2831 = and i8 %2830, 1
  store i8 %2831, i8* %52, align 1, !tbaa !2447
  %2832 = icmp eq i32 %2819, 0
  %2833 = zext i1 %2832 to i8
  store i8 %2833, i8* %53, align 1, !tbaa !2448
  %2834 = lshr i32 %2819, 31
  %2835 = trunc i32 %2834 to i8
  store i8 %2835, i8* %54, align 1, !tbaa !2449
  %2836 = lshr i32 %2813, 31
  %2837 = lshr i32 %2818, 31
  %2838 = xor i32 %2837, %2836
  %2839 = xor i32 %2834, %2836
  %2840 = add nuw nsw i32 %2839, %2838
  %2841 = icmp eq i32 %2840, 2
  %2842 = zext i1 %2841 to i8
  store i8 %2842, i8* %55, align 1, !tbaa !2450
  %2843 = icmp ne i8 %2835, 0
  %2844 = xor i1 %2843, %2841
  %.v49 = select i1 %2844, i64 12, i64 1013
  %2845 = add i64 %.v49, %2808
  store i64 %2845, i64* %PC, align 8, !tbaa !2428
  br i1 %2844, label %block_4012a6, label %block_401862.loopexit

block_40126d:                                     ; preds = %block_401235
  %2846 = add i64 %1938, 3
  store i64 %2846, i64* %PC, align 8
  %2847 = load i32, i32* %1910, align 4
  %2848 = shl i32 %2847, 1
  %2849 = icmp slt i32 %2847, 0
  %2850 = icmp slt i32 %2848, 0
  %2851 = xor i1 %2849, %2850
  %2852 = zext i32 %2848 to i64
  store i64 %2852, i64* %RAX, align 8, !tbaa !2428
  %.lobit = lshr i32 %2847, 31
  %2853 = trunc i32 %.lobit to i8
  store i8 %2853, i8* %50, align 1, !tbaa !2453
  %2854 = and i32 %2848, 254
  %2855 = tail call i32 @llvm.ctpop.i32(i32 %2854) #11
  %2856 = trunc i32 %2855 to i8
  %2857 = and i8 %2856, 1
  %2858 = xor i8 %2857, 1
  store i8 %2858, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2859 = icmp eq i32 %2848, 0
  %2860 = zext i1 %2859 to i8
  store i8 %2860, i8* %53, align 1, !tbaa !2453
  %2861 = lshr i32 %2847, 30
  %2862 = trunc i32 %2861 to i8
  %2863 = and i8 %2862, 1
  store i8 %2863, i8* %54, align 1, !tbaa !2453
  %2864 = zext i1 %2851 to i8
  store i8 %2864, i8* %55, align 1, !tbaa !2453
  %2865 = add i64 %1938, 9
  store i64 %2865, i64* %PC, align 8
  store i32 %2848, i32* %1910, align 4
  %2866 = load i64, i64* %PC, align 8
  %2867 = add i64 %2866, -96
  store i64 %2867, i64* %PC, align 8, !tbaa !2428
  br label %block_401216

block_401216:                                     ; preds = %block_40126d, %block_4011f0
  %2868 = phi i64 [ %2867, %block_40126d ], [ %.pre, %block_4011f0 ]
  %2869 = load i64, i64* %RBP, align 8
  %2870 = add i64 %2869, -48
  %2871 = add i64 %2868, 3
  store i64 %2871, i64* %PC, align 8
  %2872 = inttoptr i64 %2870 to i32*
  %2873 = load i32, i32* %2872, align 4
  %2874 = shl i32 %2873, 3
  %2875 = zext i32 %2874 to i64
  store i64 %2875, i64* %RAX, align 8, !tbaa !2428
  %2876 = lshr i32 %2873, 29
  %2877 = trunc i32 %2876 to i8
  %2878 = and i8 %2877, 1
  store i8 %2878, i8* %50, align 1, !tbaa !2453
  %2879 = and i32 %2874, 248
  %2880 = tail call i32 @llvm.ctpop.i32(i32 %2879) #11
  %2881 = trunc i32 %2880 to i8
  %2882 = and i8 %2881, 1
  %2883 = xor i8 %2882, 1
  store i8 %2883, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2884 = icmp eq i32 %2874, 0
  %2885 = zext i1 %2884 to i8
  store i8 %2885, i8* %53, align 1, !tbaa !2453
  %2886 = lshr i32 %2873, 28
  %2887 = trunc i32 %2886 to i8
  %2888 = and i8 %2887, 1
  store i8 %2888, i8* %54, align 1, !tbaa !2453
  store i8 0, i8* %55, align 1, !tbaa !2453
  %2889 = add i64 %2869, -44
  %2890 = add i64 %2868, 9
  store i64 %2890, i64* %PC, align 8
  %2891 = inttoptr i64 %2889 to i32*
  %2892 = load i32, i32* %2891, align 4
  %2893 = sub i32 %2874, %2892
  %2894 = icmp ult i32 %2874, %2892
  %2895 = zext i1 %2894 to i8
  store i8 %2895, i8* %50, align 1, !tbaa !2432
  %2896 = and i32 %2893, 255
  %2897 = tail call i32 @llvm.ctpop.i32(i32 %2896) #11
  %2898 = trunc i32 %2897 to i8
  %2899 = and i8 %2898, 1
  %2900 = xor i8 %2899, 1
  store i8 %2900, i8* %51, align 1, !tbaa !2446
  %2901 = xor i32 %2892, %2874
  %2902 = xor i32 %2901, %2893
  %2903 = lshr i32 %2902, 4
  %2904 = trunc i32 %2903 to i8
  %2905 = and i8 %2904, 1
  store i8 %2905, i8* %52, align 1, !tbaa !2447
  %2906 = icmp eq i32 %2893, 0
  %2907 = zext i1 %2906 to i8
  store i8 %2907, i8* %53, align 1, !tbaa !2448
  %2908 = lshr i32 %2893, 31
  %2909 = trunc i32 %2908 to i8
  store i8 %2909, i8* %54, align 1, !tbaa !2449
  %2910 = and i32 %2886, 1
  %2911 = lshr i32 %2892, 31
  %2912 = xor i32 %2911, %2910
  %2913 = xor i32 %2908, %2910
  %2914 = add nuw nsw i32 %2913, %2912
  %2915 = icmp eq i32 %2914, 2
  %2916 = zext i1 %2915 to i8
  store i8 %2916, i8* %55, align 1, !tbaa !2450
  %2917 = icmp ne i8 %2909, 0
  %2918 = xor i1 %2917, %2915
  %.v47 = select i1 %2918, i64 15, i64 101
  %2919 = add i64 %.v47, %2868
  store i64 %2919, i64* %PC, align 8, !tbaa !2428
  br i1 %2918, label %block_401225, label %block_40127b

block_401694:                                     ; preds = %block_40127b
  store i32 1, i32* %3004, align 4
  %2920 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %2929, i64 0, i32 0, i32 0, i32 0, i64 0
  %2921 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %2922 = bitcast i64* %2921 to double*
  %.pre43 = load i64, i64* %PC, align 8
  br label %block_40169b

block_4016a7:                                     ; preds = %block_40169b
  %2923 = add i64 %2733, -28
  %2924 = add i64 %2769, 7
  store i64 %2924, i64* %PC, align 8
  %2925 = inttoptr i64 %2923 to i32*
  store i32 0, i32* %2925, align 4
  %.pre44 = load i64, i64* %PC, align 8
  br label %block_4016ae

block_401293:                                     ; preds = %block_40127b
  store i32 0, i32* %3004, align 4
  %2926 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %2929, i64 0, i32 0, i32 0, i32 0, i64 0
  %2927 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %2928 = bitcast i64* %2927 to double*
  %.pre41 = load i64, i64* %PC, align 8
  br label %block_40129a

block_40127b:                                     ; preds = %block_401216
  %2929 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %2930 = add i64 %2919, 3
  store i64 %2930, i64* %PC, align 8
  %2931 = load i32, i32* %2872, align 4
  %2932 = shl i32 %2931, 1
  %2933 = icmp slt i32 %2931, 0
  %2934 = icmp slt i32 %2932, 0
  %2935 = xor i1 %2933, %2934
  %2936 = zext i32 %2932 to i64
  store i64 %2936, i64* %RAX, align 8, !tbaa !2428
  %.lobit12 = lshr i32 %2931, 31
  %2937 = trunc i32 %.lobit12 to i8
  store i8 %2937, i8* %50, align 1, !tbaa !2453
  %2938 = and i32 %2932, 254
  %2939 = tail call i32 @llvm.ctpop.i32(i32 %2938) #11
  %2940 = trunc i32 %2939 to i8
  %2941 = and i8 %2940, 1
  %2942 = xor i8 %2941, 1
  store i8 %2942, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2943 = icmp eq i32 %2932, 0
  %2944 = zext i1 %2943 to i8
  store i8 %2944, i8* %53, align 1, !tbaa !2453
  %2945 = lshr i32 %2931, 30
  %2946 = trunc i32 %2945 to i8
  %2947 = and i8 %2946, 1
  store i8 %2947, i8* %54, align 1, !tbaa !2453
  %2948 = zext i1 %2935 to i8
  store i8 %2948, i8* %55, align 1, !tbaa !2453
  %2949 = add i64 %2869, -52
  %2950 = add i64 %2919, 9
  store i64 %2950, i64* %PC, align 8
  %2951 = inttoptr i64 %2949 to i32*
  store i32 %2932, i32* %2951, align 4
  %2952 = load i64, i64* %RBP, align 8
  %2953 = add i64 %2952, -48
  %2954 = load i64, i64* %PC, align 8
  %2955 = add i64 %2954, 3
  store i64 %2955, i64* %PC, align 8
  %2956 = inttoptr i64 %2953 to i32*
  %2957 = load i32, i32* %2956, align 4
  %2958 = shl i32 %2957, 3
  %2959 = zext i32 %2958 to i64
  store i64 %2959, i64* %RAX, align 8, !tbaa !2428
  %2960 = lshr i32 %2957, 29
  %2961 = trunc i32 %2960 to i8
  %2962 = and i8 %2961, 1
  store i8 %2962, i8* %50, align 1, !tbaa !2453
  %2963 = and i32 %2958, 248
  %2964 = tail call i32 @llvm.ctpop.i32(i32 %2963) #11
  %2965 = trunc i32 %2964 to i8
  %2966 = and i8 %2965, 1
  %2967 = xor i8 %2966, 1
  store i8 %2967, i8* %51, align 1, !tbaa !2453
  store i8 0, i8* %52, align 1, !tbaa !2453
  %2968 = icmp eq i32 %2958, 0
  %2969 = zext i1 %2968 to i8
  store i8 %2969, i8* %53, align 1, !tbaa !2453
  %2970 = lshr i32 %2957, 28
  %2971 = trunc i32 %2970 to i8
  %2972 = and i8 %2971, 1
  store i8 %2972, i8* %54, align 1, !tbaa !2453
  store i8 0, i8* %55, align 1, !tbaa !2453
  %2973 = add i64 %2952, -44
  %2974 = add i64 %2954, 9
  store i64 %2974, i64* %PC, align 8
  %2975 = inttoptr i64 %2973 to i32*
  %2976 = load i32, i32* %2975, align 4
  %2977 = sub i32 %2958, %2976
  %2978 = icmp ult i32 %2958, %2976
  %2979 = zext i1 %2978 to i8
  store i8 %2979, i8* %50, align 1, !tbaa !2432
  %2980 = and i32 %2977, 255
  %2981 = tail call i32 @llvm.ctpop.i32(i32 %2980) #11
  %2982 = trunc i32 %2981 to i8
  %2983 = and i8 %2982, 1
  %2984 = xor i8 %2983, 1
  store i8 %2984, i8* %51, align 1, !tbaa !2446
  %2985 = xor i32 %2976, %2958
  %2986 = xor i32 %2985, %2977
  %2987 = lshr i32 %2986, 4
  %2988 = trunc i32 %2987 to i8
  %2989 = and i8 %2988, 1
  store i8 %2989, i8* %52, align 1, !tbaa !2447
  %2990 = icmp eq i32 %2977, 0
  %2991 = zext i1 %2990 to i8
  store i8 %2991, i8* %53, align 1, !tbaa !2448
  %2992 = lshr i32 %2977, 31
  %2993 = trunc i32 %2992 to i8
  store i8 %2993, i8* %54, align 1, !tbaa !2449
  %2994 = and i32 %2970, 1
  %2995 = lshr i32 %2976, 31
  %2996 = xor i32 %2995, %2994
  %2997 = xor i32 %2992, %2994
  %2998 = add nuw nsw i32 %2997, %2996
  %2999 = icmp eq i32 %2998, 2
  %3000 = zext i1 %2999 to i8
  store i8 %3000, i8* %55, align 1, !tbaa !2450
  %.v = select i1 %2990, i64 15, i64 1040
  %3001 = add i64 %2952, -36
  %3002 = add i64 %2954, 7
  %3003 = add i64 %3002, %.v
  store i64 %3003, i64* %PC, align 8
  %3004 = inttoptr i64 %3001 to i32*
  br i1 %2990, label %block_401293, label %block_401694

block_401241:                                     ; preds = %block_401235
  %3005 = add i64 %1902, -16
  %3006 = add i64 %1938, 4
  store i64 %3006, i64* %PC, align 8
  %3007 = inttoptr i64 %3005 to i64*
  %3008 = load i64, i64* %3007, align 8
  store i64 %3008, i64* %RAX, align 8, !tbaa !2428
  %3009 = add i64 %1938, 8
  store i64 %3009, i64* %PC, align 8
  %3010 = load i32, i32* %1905, align 4
  %3011 = sext i32 %3010 to i64
  store i64 %3011, i64* %RCX, align 8, !tbaa !2428
  %3012 = shl nsw i64 %3011, 2
  %3013 = add i64 %3012, %3008
  %3014 = add i64 %1938, 11
  store i64 %3014, i64* %PC, align 8
  %3015 = inttoptr i64 %3013 to i32*
  %3016 = load i32, i32* %3015, align 4
  %3017 = zext i32 %3016 to i64
  store i64 %3017, i64* %RDX, align 8, !tbaa !2428
  %3018 = add i64 %1902, -44
  %3019 = add i64 %1938, 14
  store i64 %3019, i64* %PC, align 8
  %3020 = inttoptr i64 %3018 to i32*
  %3021 = load i32, i32* %3020, align 4
  %3022 = add i32 %3021, %3016
  %3023 = zext i32 %3022 to i64
  store i64 %3023, i64* %RDX, align 8, !tbaa !2428
  %3024 = icmp ult i32 %3022, %3016
  %3025 = icmp ult i32 %3022, %3021
  %3026 = or i1 %3024, %3025
  %3027 = zext i1 %3026 to i8
  store i8 %3027, i8* %50, align 1, !tbaa !2432
  %3028 = and i32 %3022, 255
  %3029 = tail call i32 @llvm.ctpop.i32(i32 %3028) #11
  %3030 = trunc i32 %3029 to i8
  %3031 = and i8 %3030, 1
  %3032 = xor i8 %3031, 1
  store i8 %3032, i8* %51, align 1, !tbaa !2446
  %3033 = xor i32 %3021, %3016
  %3034 = xor i32 %3033, %3022
  %3035 = lshr i32 %3034, 4
  %3036 = trunc i32 %3035 to i8
  %3037 = and i8 %3036, 1
  store i8 %3037, i8* %52, align 1, !tbaa !2447
  %3038 = icmp eq i32 %3022, 0
  %3039 = zext i1 %3038 to i8
  store i8 %3039, i8* %53, align 1, !tbaa !2448
  %3040 = lshr i32 %3022, 31
  %3041 = trunc i32 %3040 to i8
  store i8 %3041, i8* %54, align 1, !tbaa !2449
  %3042 = lshr i32 %3016, 31
  %3043 = lshr i32 %3021, 31
  %3044 = xor i32 %3040, %3042
  %3045 = xor i32 %3040, %3043
  %3046 = add nuw nsw i32 %3044, %3045
  %3047 = icmp eq i32 %3046, 2
  %3048 = zext i1 %3047 to i8
  store i8 %3048, i8* %55, align 1, !tbaa !2450
  %3049 = add i64 %1938, 18
  store i64 %3049, i64* %PC, align 8
  %3050 = load i64, i64* %3007, align 8
  store i64 %3050, i64* %RAX, align 8, !tbaa !2428
  %3051 = add i64 %1938, 21
  store i64 %3051, i64* %PC, align 8
  %3052 = load i32, i32* %1910, align 4
  %3053 = zext i32 %3052 to i64
  store i64 %3053, i64* %RSI, align 8, !tbaa !2428
  %3054 = add i64 %1938, 24
  store i64 %3054, i64* %PC, align 8
  %3055 = load i32, i32* %1905, align 4
  %3056 = add i32 %3055, %3052
  %3057 = zext i32 %3056 to i64
  store i64 %3057, i64* %RSI, align 8, !tbaa !2428
  %3058 = icmp ult i32 %3056, %3052
  %3059 = icmp ult i32 %3056, %3055
  %3060 = or i1 %3058, %3059
  %3061 = zext i1 %3060 to i8
  store i8 %3061, i8* %50, align 1, !tbaa !2432
  %3062 = and i32 %3056, 255
  %3063 = tail call i32 @llvm.ctpop.i32(i32 %3062) #11
  %3064 = trunc i32 %3063 to i8
  %3065 = and i8 %3064, 1
  %3066 = xor i8 %3065, 1
  store i8 %3066, i8* %51, align 1, !tbaa !2446
  %3067 = xor i32 %3055, %3052
  %3068 = xor i32 %3067, %3056
  %3069 = lshr i32 %3068, 4
  %3070 = trunc i32 %3069 to i8
  %3071 = and i8 %3070, 1
  store i8 %3071, i8* %52, align 1, !tbaa !2447
  %3072 = icmp eq i32 %3056, 0
  %3073 = zext i1 %3072 to i8
  store i8 %3073, i8* %53, align 1, !tbaa !2448
  %3074 = lshr i32 %3056, 31
  %3075 = trunc i32 %3074 to i8
  store i8 %3075, i8* %54, align 1, !tbaa !2449
  %3076 = lshr i32 %3052, 31
  %3077 = lshr i32 %3055, 31
  %3078 = xor i32 %3074, %3076
  %3079 = xor i32 %3074, %3077
  %3080 = add nuw nsw i32 %3078, %3079
  %3081 = icmp eq i32 %3080, 2
  %3082 = zext i1 %3081 to i8
  store i8 %3082, i8* %55, align 1, !tbaa !2450
  %3083 = sext i32 %3056 to i64
  store i64 %3083, i64* %RCX, align 8, !tbaa !2428
  %3084 = shl nsw i64 %3083, 2
  %3085 = add i64 %3084, %3050
  %3086 = add i64 %1938, 30
  store i64 %3086, i64* %PC, align 8
  %3087 = inttoptr i64 %3085 to i32*
  store i32 %3022, i32* %3087, align 4
  %3088 = load i64, i64* %RBP, align 8
  %3089 = add i64 %3088, -28
  %3090 = load i64, i64* %PC, align 8
  %3091 = add i64 %3090, 3
  store i64 %3091, i64* %PC, align 8
  %3092 = inttoptr i64 %3089 to i32*
  %3093 = load i32, i32* %3092, align 4
  %3094 = add i32 %3093, 1
  %3095 = zext i32 %3094 to i64
  store i64 %3095, i64* %RAX, align 8, !tbaa !2428
  %3096 = icmp eq i32 %3093, -1
  %3097 = icmp eq i32 %3094, 0
  %3098 = or i1 %3096, %3097
  %3099 = zext i1 %3098 to i8
  store i8 %3099, i8* %50, align 1, !tbaa !2432
  %3100 = and i32 %3094, 255
  %3101 = tail call i32 @llvm.ctpop.i32(i32 %3100) #11
  %3102 = trunc i32 %3101 to i8
  %3103 = and i8 %3102, 1
  %3104 = xor i8 %3103, 1
  store i8 %3104, i8* %51, align 1, !tbaa !2446
  %3105 = xor i32 %3094, %3093
  %3106 = lshr i32 %3105, 4
  %3107 = trunc i32 %3106 to i8
  %3108 = and i8 %3107, 1
  store i8 %3108, i8* %52, align 1, !tbaa !2447
  %3109 = zext i1 %3097 to i8
  store i8 %3109, i8* %53, align 1, !tbaa !2448
  %3110 = lshr i32 %3094, 31
  %3111 = trunc i32 %3110 to i8
  store i8 %3111, i8* %54, align 1, !tbaa !2449
  %3112 = lshr i32 %3093, 31
  %3113 = xor i32 %3110, %3112
  %3114 = add nuw nsw i32 %3113, %3110
  %3115 = icmp eq i32 %3114, 2
  %3116 = zext i1 %3115 to i8
  store i8 %3116, i8* %55, align 1, !tbaa !2450
  %3117 = add i64 %3090, 9
  store i64 %3117, i64* %PC, align 8
  store i32 %3094, i32* %3092, align 4
  %3118 = load i64, i64* %PC, align 8
  %3119 = add i64 %3118, -51
  store i64 %3119, i64* %PC, align 8, !tbaa !2428
  br label %block_401235
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400760__start(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400760:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  store i64 0, i64* %RBP, align 8, !tbaa !2428
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %3, align 1, !tbaa !2432
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %4, align 1, !tbaa !2446
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %5, align 1, !tbaa !2448
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %6, align 1, !tbaa !2449
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %7, align 1, !tbaa !2450
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %8, align 1, !tbaa !2447
  %9 = load i64, i64* %RDX, align 8
  store i64 %9, i64* %R9, align 8, !tbaa !2428
  %10 = add i64 %1, 6
  store i64 %10, i64* %PC, align 8
  %11 = load i64, i64* %RSP, align 8, !tbaa !2428
  %12 = add i64 %11, 8
  %13 = inttoptr i64 %11 to i64*
  %14 = load i64, i64* %13, align 8
  store i64 %14, i64* %RSI, align 8, !tbaa !2428
  store i64 %12, i64* %RDX, align 8, !tbaa !2428
  %15 = and i64 %12, -16
  store i8 0, i8* %3, align 1, !tbaa !2432
  %16 = trunc i64 %12 to i32
  %17 = and i32 %16, 240
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17) #11
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  store i8 %21, i8* %4, align 1, !tbaa !2446
  %22 = icmp eq i64 %15, 0
  %23 = zext i1 %22 to i8
  store i8 %23, i8* %5, align 1, !tbaa !2448
  %24 = lshr i64 %12, 63
  %25 = trunc i64 %24 to i8
  store i8 %25, i8* %6, align 1, !tbaa !2449
  store i8 0, i8* %7, align 1, !tbaa !2450
  store i8 0, i8* %8, align 1, !tbaa !2447
  %26 = load i64, i64* %RAX, align 8
  %27 = add i64 %1, 14
  store i64 %27, i64* %PC, align 8
  %28 = add i64 %15, -8
  %29 = inttoptr i64 %28 to i64*
  store i64 %26, i64* %29, align 8
  %30 = load i64, i64* %PC, align 8
  %31 = add i64 %30, 1
  store i64 %31, i64* %PC, align 8
  %32 = add i64 %15, -16
  %33 = inttoptr i64 %32 to i64*
  store i64 %28, i64* %33, align 16
  %34 = load i64, i64* %PC, align 8
  store i64 ptrtoint (void ()* @callback_sub_404090___libc_csu_fini to i64), i64* %R8, align 8, !tbaa !2428
  store i64 ptrtoint (void ()* @callback_sub_404020___libc_csu_init to i64), i64* %RCX, align 8, !tbaa !2428
  store i64 ptrtoint (void ()* @main to i64), i64* %RDI, align 8, !tbaa !2428
  %35 = add i64 %34, 27
  %36 = add i64 %15, -24
  %37 = inttoptr i64 %36 to i64*
  store i64 %35, i64* %37, align 8
  store i64 %36, i64* %RSP, align 8, !tbaa !2428
  %38 = load i64, i64* getelementptr inbounds (%seg_604ff0__got_type, %seg_604ff0__got_type* @seg_604ff0__got, i64 0, i32 0), align 8
  store i64 %38, i64* %PC, align 8, !tbaa !2428
  %39 = tail call fastcc %struct.Memory* @ext_605120___libc_start_main(%struct.State* nonnull %0, %struct.Memory* %2)
  %40 = load i64, i64* %PC, align 8
  %41 = add i64 %40, 1
  store i64 %41, i64* %PC, align 8
  %42 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull %0, i64 %41, %struct.Memory* %39)
  ret %struct.Memory* %42
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_401100_errorcheck(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_401100:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0
  %ECX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %5 to i32*
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %6 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %6, i64 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %10 = load i64, i64* %RBP, align 8
  %11 = add i64 %1, 1
  store i64 %11, i64* %PC, align 8
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %13 = load i64, i64* %12, align 8, !tbaa !2428
  %14 = add i64 %13, -8
  %15 = inttoptr i64 %14 to i64*
  store i64 %10, i64* %15, align 8
  store i64 %14, i64* %12, align 8, !tbaa !2428
  %16 = load i64, i64* %PC, align 8
  store i64 %14, i64* %RBP, align 8, !tbaa !2428
  %17 = bitcast %union.VectorReg* %8 to i8*
  %18 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %8, i64 0, i32 0, i32 0, i32 0, i64 0
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %20 = bitcast %union.VectorReg* %8 to i32*
  %21 = getelementptr inbounds i8, i8* %17, i64 4
  %22 = bitcast i8* %21 to i32*
  %23 = bitcast i64* %19 to i32*
  %24 = getelementptr inbounds i8, i8* %17, i64 12
  %25 = bitcast i8* %24 to i32*
  %26 = bitcast %union.VectorReg* %8 to <4 x i32>*
  store <4 x i32> zeroinitializer, <4 x i32>* %26, align 1, !tbaa !2469
  %27 = add i64 %13, -12
  %28 = load i32, i32* %EDI, align 4
  %29 = add i64 %16, 9
  store i64 %29, i64* %PC, align 8
  %30 = inttoptr i64 %27 to i32*
  store i32 %28, i32* %30, align 4
  %31 = load i64, i64* %RBP, align 8
  %32 = add i64 %31, -8
  %33 = load i32, i32* %ESI, align 4
  %34 = load i64, i64* %PC, align 8
  %35 = add i64 %34, 3
  store i64 %35, i64* %PC, align 8
  %36 = inttoptr i64 %32 to i32*
  store i32 %33, i32* %36, align 4
  %37 = load i64, i64* %RBP, align 8
  %38 = add i64 %37, -16
  %39 = load i64, i64* %PC, align 8
  %40 = add i64 %39, 5
  store i64 %40, i64* %PC, align 8
  %41 = bitcast [32 x %union.VectorReg]* %7 to double*
  %42 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %7, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %43 = load i64, i64* %42, align 1
  %44 = inttoptr i64 %38 to i64*
  store i64 %43, i64* %44, align 8
  %45 = load i64, i64* %RBP, align 8
  %46 = add i64 %45, -24
  %47 = load i64, i64* %RDX, align 8
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 4
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %46 to i64*
  store i64 %47, i64* %50, align 8
  %51 = load i64, i64* %RBP, align 8
  %52 = add i64 %51, -32
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 7
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %52 to i32*
  store i32 0, i32* %55, align 4
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -40
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 5
  store i64 %59, i64* %PC, align 8
  %60 = bitcast %union.VectorReg* %8 to double*
  %61 = load i64, i64* %18, align 1
  %62 = inttoptr i64 %57 to i64*
  store i64 %61, i64* %62, align 8
  %63 = load i64, i64* %RBP, align 8
  %64 = add i64 %63, -4
  %65 = load i64, i64* %PC, align 8
  %66 = add i64 %65, 3
  store i64 %66, i64* %PC, align 8
  %67 = inttoptr i64 %64 to i32*
  %68 = load i32, i32* %67, align 4
  %69 = zext i32 %68 to i64
  store i64 %69, i64* %RSI, align 8, !tbaa !2428
  %70 = add i64 %63, -28
  %71 = add i64 %65, 6
  store i64 %71, i64* %PC, align 8
  %72 = inttoptr i64 %70 to i32*
  store i32 %68, i32* %72, align 4
  %73 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %74 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %75 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %76 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %77 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %78 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %79 = bitcast [32 x %union.VectorReg]* %7 to i8*
  %80 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %81 = bitcast i64* %80 to double*
  %82 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %83 = bitcast %union.VectorReg* %9 to i8*
  %84 = bitcast %union.VectorReg* %9 to i32*
  %85 = getelementptr inbounds i8, i8* %83, i64 4
  %86 = bitcast i8* %85 to i32*
  %87 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %88 = bitcast i64* %87 to i32*
  %89 = getelementptr inbounds i8, i8* %83, i64 12
  %90 = bitcast i8* %89 to i32*
  %91 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %9, i64 0, i32 0, i32 0, i32 0, i64 0
  %92 = bitcast [32 x %union.VectorReg]* %7 to i32*
  %93 = getelementptr inbounds i8, i8* %79, i64 4
  %94 = bitcast i8* %93 to i32*
  %95 = bitcast i64* %80 to i32*
  %96 = getelementptr inbounds i8, i8* %79, i64 12
  %97 = bitcast i8* %96 to i32*
  %.pre = load i64, i64* %PC, align 8
  br label %block_401128

block_40119e:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %98 = add i64 %259, -40
  %99 = add i64 %266, 5
  store i64 %99, i64* %PC, align 8
  %100 = inttoptr i64 %98 to i64*
  %101 = load i64, i64* %100, align 8
  store i64 %101, i64* %42, align 1, !tbaa !2451
  store double 0.000000e+00, double* %81, align 1, !tbaa !2451
  %102 = add i64 %259, -64
  %103 = add i64 %266, 10
  store i64 %103, i64* %PC, align 8
  %104 = inttoptr i64 %102 to i64*
  store i64 %101, i64* %104, align 8
  %105 = load i64, i64* %PC, align 8
  %106 = add i64 %105, 26
  store i64 %106, i64* %PC, align 8, !tbaa !2428
  br label %block_4011c2

block_4011da:                                     ; preds = %block_401128
  %107 = add i64 %285, -40
  %108 = add i64 %321, 5
  store i64 %108, i64* %PC, align 8
  %109 = inttoptr i64 %107 to i64*
  %110 = load i64, i64* %109, align 8
  store i64 %110, i64* %42, align 1, !tbaa !2451
  store double 0.000000e+00, double* %81, align 1, !tbaa !2451
  %111 = add i64 %321, 6
  store i64 %111, i64* %PC, align 8
  %112 = load i64, i64* %12, align 8, !tbaa !2428
  %113 = add i64 %112, 8
  %114 = inttoptr i64 %112 to i64*
  %115 = load i64, i64* %114, align 8
  store i64 %115, i64* %RBP, align 8, !tbaa !2428
  store i64 %113, i64* %12, align 8, !tbaa !2428
  %116 = add i64 %321, 7
  store i64 %116, i64* %PC, align 8
  %117 = inttoptr i64 %113 to i64*
  %118 = load i64, i64* %117, align 8
  store i64 %118, i64* %PC, align 8, !tbaa !2428
  %119 = add i64 %112, 16
  store i64 %119, i64* %12, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_401134:                                     ; preds = %block_401128
  %120 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 72) to i64*), align 8
  store i64 %120, i64* %42, align 1, !tbaa !2451
  store double 0.000000e+00, double* %81, align 1, !tbaa !2451
  store i64 259200, i64* %RAX, align 8, !tbaa !2428
  %121 = add i64 %285, -32
  %122 = add i64 %321, 20
  store i64 %122, i64* %PC, align 8
  %123 = inttoptr i64 %121 to i32*
  %124 = load i32, i32* %123, align 4
  %125 = mul i32 %124, 7141
  %126 = add i32 %125, 54773
  %127 = zext i32 %126 to i64
  store i64 %127, i64* %RCX, align 8, !tbaa !2428
  %128 = icmp ugt i32 %125, -54774
  %129 = zext i1 %128 to i8
  store i8 %129, i8* %73, align 1, !tbaa !2432
  %130 = and i32 %126, 255
  %131 = tail call i32 @llvm.ctpop.i32(i32 %130) #11
  %132 = trunc i32 %131 to i8
  %133 = and i8 %132, 1
  %134 = xor i8 %133, 1
  store i8 %134, i8* %74, align 1, !tbaa !2446
  %135 = xor i32 %125, 16
  %136 = xor i32 %135, %126
  %137 = lshr i32 %136, 4
  %138 = trunc i32 %137 to i8
  %139 = and i8 %138, 1
  store i8 %139, i8* %75, align 1, !tbaa !2447
  %140 = icmp eq i32 %126, 0
  %141 = zext i1 %140 to i8
  store i8 %141, i8* %76, align 1, !tbaa !2448
  %142 = lshr i32 %126, 31
  %143 = trunc i32 %142 to i8
  store i8 %143, i8* %77, align 1, !tbaa !2449
  %144 = lshr i32 %125, 31
  %145 = xor i32 %142, %144
  %146 = add nuw nsw i32 %145, %142
  %147 = icmp eq i32 %146, 2
  %148 = zext i1 %147 to i8
  store i8 %148, i8* %78, align 1, !tbaa !2450
  %149 = add i64 %285, -52
  %150 = add i64 %321, 29
  store i64 %150, i64* %PC, align 8
  %151 = inttoptr i64 %149 to i32*
  store i32 259200, i32* %151, align 4
  %152 = load i32, i32* %ECX, align 4
  %153 = zext i32 %152 to i64
  %154 = load i64, i64* %PC, align 8
  store i64 %153, i64* %RAX, align 8, !tbaa !2428
  %155 = sext i32 %152 to i64
  %156 = lshr i64 %155, 32
  store i64 %156, i64* %82, align 8, !tbaa !2428
  %157 = load i64, i64* %RBP, align 8
  %158 = add i64 %157, -52
  %159 = add i64 %154, 6
  store i64 %159, i64* %PC, align 8
  %160 = inttoptr i64 %158 to i32*
  %161 = load i32, i32* %160, align 4
  %162 = zext i32 %161 to i64
  store i64 %162, i64* %RCX, align 8, !tbaa !2428
  %163 = add i64 %154, 8
  store i64 %163, i64* %PC, align 8
  %164 = sext i32 %161 to i64
  %165 = shl nuw i64 %156, 32
  %166 = or i64 %165, %153
  %167 = sdiv i64 %166, %164
  %168 = shl i64 %167, 32
  %169 = ashr exact i64 %168, 32
  %170 = icmp eq i64 %167, %169
  br i1 %170, label %173, label %171

; <label>:171:                                    ; preds = %block_401134
  %172 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %163, %struct.Memory* %MEMORY.0) #16
  %.pre2 = load i64, i64* %RBP, align 8
  %.pre3 = load i32, i32* %EDX, align 4
  %.pre4 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:173:                                    ; preds = %block_401134
  %174 = srem i64 %166, %164
  %175 = and i64 %167, 4294967295
  store i64 %175, i64* %RAX, align 8, !tbaa !2428
  %176 = and i64 %174, 4294967295
  store i64 %176, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %73, align 1, !tbaa !2432
  store i8 0, i8* %74, align 1, !tbaa !2446
  store i8 0, i8* %75, align 1, !tbaa !2447
  store i8 0, i8* %76, align 1, !tbaa !2448
  store i8 0, i8* %77, align 1, !tbaa !2449
  store i8 0, i8* %78, align 1, !tbaa !2450
  %177 = trunc i64 %174 to i32
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %173, %171
  %178 = phi i64 [ %.pre4, %171 ], [ %163, %173 ]
  %179 = phi i32 [ %.pre3, %171 ], [ %177, %173 ]
  %180 = phi i64 [ %.pre2, %171 ], [ %157, %173 ]
  %181 = phi %struct.Memory* [ %172, %171 ], [ %MEMORY.0, %173 ]
  %182 = add i64 %180, -32
  %183 = add i64 %178, 3
  store i64 %183, i64* %PC, align 8
  %184 = inttoptr i64 %182 to i32*
  store i32 %179, i32* %184, align 4
  %185 = load i32, i32* %EDX, align 4
  %186 = load i64, i64* %PC, align 8
  %187 = sitofp i32 %185 to double
  %188 = load double, double* %41, align 1
  %189 = fmul double %187, %188
  store double %189, double* %60, align 1, !tbaa !2451
  %190 = load i64, i64* %RBP, align 8
  %191 = add i64 %190, -24
  %192 = add i64 %186, 12
  store i64 %192, i64* %PC, align 8
  %193 = inttoptr i64 %191 to i64*
  %194 = load i64, i64* %193, align 8
  store i64 %194, i64* %RSI, align 8, !tbaa !2428
  %195 = add i64 %190, -28
  %196 = add i64 %186, 16
  store i64 %196, i64* %PC, align 8
  %197 = inttoptr i64 %195 to i32*
  %198 = load i32, i32* %197, align 4
  %199 = sext i32 %198 to i64
  store i64 %199, i64* %RDI, align 8, !tbaa !2428
  %200 = shl nsw i64 %199, 3
  %201 = add i64 %200, %194
  %202 = add i64 %186, 21
  store i64 %202, i64* %PC, align 8
  %203 = inttoptr i64 %201 to i64*
  %204 = load i64, i64* %203, align 8
  store i64 %204, i64* %42, align 1, !tbaa !2451
  store double 0.000000e+00, double* %81, align 1, !tbaa !2451
  %205 = add i64 %190, -16
  %206 = add i64 %186, 26
  store i64 %206, i64* %PC, align 8
  %207 = bitcast i64 %204 to double
  %208 = inttoptr i64 %205 to double*
  %209 = load double, double* %208, align 8
  %210 = fmul double %207, %209
  store double %210, double* %41, align 1, !tbaa !2451
  store i64 0, i64* %80, align 1, !tbaa !2451
  %211 = fsub double %189, %210
  store double %211, double* %60, align 1, !tbaa !2451
  %212 = add i64 %190, -48
  %213 = add i64 %186, 35
  store i64 %213, i64* %PC, align 8
  %214 = inttoptr i64 %212 to double*
  store double %211, double* %214, align 8
  %215 = load i64, i64* %RBP, align 8
  %216 = add i64 %215, -40
  %217 = load i64, i64* %PC, align 8
  %218 = add i64 %217, 5
  store i64 %218, i64* %PC, align 8
  %219 = inttoptr i64 %216 to i64*
  %220 = load i64, i64* %219, align 8
  store i64 %220, i64* %42, align 1, !tbaa !2451
  store double 0.000000e+00, double* %81, align 1, !tbaa !2451
  %221 = add i64 %215, -48
  %222 = add i64 %217, 10
  store i64 %222, i64* %PC, align 8
  %223 = inttoptr i64 %221 to i64*
  %224 = load i64, i64* %223, align 8
  %225 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 96) to i32*), align 16
  %226 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 100) to i32*), align 4
  %227 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 104) to i32*), align 8
  %228 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 108) to i32*), align 4
  store i32 %225, i32* %84, align 1, !tbaa !2475
  store i32 %226, i32* %86, align 1, !tbaa !2475
  store i32 %227, i32* %88, align 1, !tbaa !2475
  store i32 %228, i32* %90, align 1, !tbaa !2475
  %229 = load i64, i64* %91, align 1
  %230 = and i64 %229, %224
  %231 = trunc i64 %230 to i32
  %232 = lshr i64 %230, 32
  %233 = trunc i64 %232 to i32
  store i32 %231, i32* %20, align 1, !tbaa !2469
  store i32 %233, i32* %22, align 1, !tbaa !2469
  store i32 0, i32* %23, align 1, !tbaa !2469
  store i32 0, i32* %25, align 1, !tbaa !2469
  %234 = add i64 %217, 25
  store i64 %234, i64* %PC, align 8
  %235 = bitcast i64 %220 to double
  %236 = load double, double* %60, align 1
  %237 = fcmp uno double %235, %236
  br i1 %237, label %238, label %248

; <label>:238:                                    ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit
  %239 = fadd double %235, %236
  %240 = bitcast double %239 to i64
  %241 = and i64 %240, 9221120237041090560
  %242 = icmp eq i64 %241, 9218868437227405312
  %243 = and i64 %240, 2251799813685247
  %244 = icmp ne i64 %243, 0
  %245 = and i1 %242, %244
  br i1 %245, label %246, label %254

; <label>:246:                                    ; preds = %238
  %247 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %234, %struct.Memory* %181) #16
  %.pre5 = load i64, i64* %PC, align 8
  %.pre6 = load i64, i64* %RBP, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

; <label>:248:                                    ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit
  %249 = fcmp ogt double %235, %236
  br i1 %249, label %254, label %250

; <label>:250:                                    ; preds = %248
  %251 = fcmp olt double %235, %236
  br i1 %251, label %254, label %252

; <label>:252:                                    ; preds = %250
  %253 = fcmp oeq double %235, %236
  br i1 %253, label %254, label %258

; <label>:254:                                    ; preds = %252, %250, %248, %238
  %255 = phi i8 [ 0, %248 ], [ 0, %250 ], [ 1, %252 ], [ 1, %238 ]
  %256 = phi i8 [ 0, %248 ], [ 0, %250 ], [ 0, %252 ], [ 1, %238 ]
  %257 = phi i8 [ 0, %248 ], [ 1, %250 ], [ 0, %252 ], [ 1, %238 ]
  store i8 %255, i8* %76, align 1, !tbaa !2453
  store i8 %256, i8* %74, align 1, !tbaa !2453
  store i8 %257, i8* %73, align 1, !tbaa !2453
  br label %258

; <label>:258:                                    ; preds = %254, %252
  store i8 0, i8* %78, align 1, !tbaa !2453
  store i8 0, i8* %77, align 1, !tbaa !2453
  store i8 0, i8* %75, align 1, !tbaa !2453
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit: ; preds = %258, %246
  %259 = phi i64 [ %.pre6, %246 ], [ %215, %258 ]
  %260 = phi i64 [ %.pre5, %246 ], [ %234, %258 ]
  %261 = phi %struct.Memory* [ %247, %246 ], [ %181, %258 ]
  %262 = load i8, i8* %73, align 1, !tbaa !2432
  %263 = load i8, i8* %76, align 1, !tbaa !2448
  %264 = or i8 %263, %262
  %265 = icmp ne i8 %264, 0
  %.v9 = select i1 %265, i64 21, i64 6
  %266 = add i64 %.v9, %260
  store i64 %266, i64* %PC, align 8, !tbaa !2428
  br i1 %265, label %block_4011ad, label %block_40119e

block_4011ad:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %267 = add i64 %259, -48
  %268 = add i64 %266, 5
  store i64 %268, i64* %PC, align 8
  %269 = inttoptr i64 %267 to i64*
  %270 = load i64, i64* %269, align 8
  %271 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 96) to i32*), align 16
  %272 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 100) to i32*), align 4
  %273 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 104) to i32*), align 8
  %274 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 108) to i32*), align 4
  store i32 %271, i32* %20, align 1, !tbaa !2475
  store i32 %272, i32* %22, align 1, !tbaa !2475
  store i32 %273, i32* %23, align 1, !tbaa !2475
  store i32 %274, i32* %25, align 1, !tbaa !2475
  %275 = load i64, i64* %18, align 1
  %276 = and i64 %275, %270
  %277 = trunc i64 %276 to i32
  %278 = lshr i64 %276, 32
  %279 = trunc i64 %278 to i32
  store i32 %277, i32* %92, align 1, !tbaa !2469
  store i32 %279, i32* %94, align 1, !tbaa !2469
  store i32 0, i32* %95, align 1, !tbaa !2469
  store i32 0, i32* %97, align 1, !tbaa !2469
  %280 = add i64 %259, -64
  %281 = add i64 %266, 21
  store i64 %281, i64* %PC, align 8
  %282 = load i64, i64* %42, align 1
  %283 = inttoptr i64 %280 to i64*
  store i64 %282, i64* %283, align 8
  %.pre7 = load i64, i64* %PC, align 8
  br label %block_4011c2

block_401128:                                     ; preds = %block_4011c2, %block_401100
  %284 = phi i64 [ %.pre, %block_401100 ], [ %362, %block_4011c2 ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_401100 ], [ %261, %block_4011c2 ]
  %285 = load i64, i64* %RBP, align 8
  %286 = add i64 %285, -28
  %287 = add i64 %284, 3
  store i64 %287, i64* %PC, align 8
  %288 = inttoptr i64 %286 to i32*
  %289 = load i32, i32* %288, align 4
  %290 = zext i32 %289 to i64
  store i64 %290, i64* %RAX, align 8, !tbaa !2428
  %291 = add i64 %285, -8
  %292 = add i64 %284, 6
  store i64 %292, i64* %PC, align 8
  %293 = inttoptr i64 %291 to i32*
  %294 = load i32, i32* %293, align 4
  %295 = sub i32 %289, %294
  %296 = icmp ult i32 %289, %294
  %297 = zext i1 %296 to i8
  store i8 %297, i8* %73, align 1, !tbaa !2432
  %298 = and i32 %295, 255
  %299 = tail call i32 @llvm.ctpop.i32(i32 %298) #11
  %300 = trunc i32 %299 to i8
  %301 = and i8 %300, 1
  %302 = xor i8 %301, 1
  store i8 %302, i8* %74, align 1, !tbaa !2446
  %303 = xor i32 %294, %289
  %304 = xor i32 %303, %295
  %305 = lshr i32 %304, 4
  %306 = trunc i32 %305 to i8
  %307 = and i8 %306, 1
  store i8 %307, i8* %75, align 1, !tbaa !2447
  %308 = icmp eq i32 %295, 0
  %309 = zext i1 %308 to i8
  store i8 %309, i8* %76, align 1, !tbaa !2448
  %310 = lshr i32 %295, 31
  %311 = trunc i32 %310 to i8
  store i8 %311, i8* %77, align 1, !tbaa !2449
  %312 = lshr i32 %289, 31
  %313 = lshr i32 %294, 31
  %314 = xor i32 %313, %312
  %315 = xor i32 %310, %312
  %316 = add nuw nsw i32 %315, %314
  %317 = icmp eq i32 %316, 2
  %318 = zext i1 %317 to i8
  store i8 %318, i8* %78, align 1, !tbaa !2450
  %319 = icmp ne i8 %311, 0
  %320 = xor i1 %319, %317
  %.demorgan = or i1 %308, %320
  %.v = select i1 %.demorgan, i64 12, i64 178
  %321 = add i64 %.v, %284
  store i64 %321, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan, label %block_401134, label %block_4011da

block_4011c2:                                     ; preds = %block_4011ad, %block_40119e
  %322 = phi i64 [ %.pre7, %block_4011ad ], [ %106, %block_40119e ]
  %323 = load i64, i64* %RBP, align 8
  %324 = add i64 %323, -64
  %325 = add i64 %322, 5
  store i64 %325, i64* %PC, align 8
  %326 = inttoptr i64 %324 to i64*
  %327 = load i64, i64* %326, align 8
  store i64 %327, i64* %42, align 1, !tbaa !2451
  store double 0.000000e+00, double* %81, align 1, !tbaa !2451
  %328 = add i64 %323, -40
  %329 = add i64 %322, 10
  store i64 %329, i64* %PC, align 8
  %330 = inttoptr i64 %328 to i64*
  store i64 %327, i64* %330, align 8
  %331 = load i64, i64* %RBP, align 8
  %332 = add i64 %331, -28
  %333 = load i64, i64* %PC, align 8
  %334 = add i64 %333, 3
  store i64 %334, i64* %PC, align 8
  %335 = inttoptr i64 %332 to i32*
  %336 = load i32, i32* %335, align 4
  %337 = add i32 %336, 1
  %338 = zext i32 %337 to i64
  store i64 %338, i64* %RAX, align 8, !tbaa !2428
  %339 = icmp eq i32 %336, -1
  %340 = icmp eq i32 %337, 0
  %341 = or i1 %339, %340
  %342 = zext i1 %341 to i8
  store i8 %342, i8* %73, align 1, !tbaa !2432
  %343 = and i32 %337, 255
  %344 = tail call i32 @llvm.ctpop.i32(i32 %343) #11
  %345 = trunc i32 %344 to i8
  %346 = and i8 %345, 1
  %347 = xor i8 %346, 1
  store i8 %347, i8* %74, align 1, !tbaa !2446
  %348 = xor i32 %337, %336
  %349 = lshr i32 %348, 4
  %350 = trunc i32 %349 to i8
  %351 = and i8 %350, 1
  store i8 %351, i8* %75, align 1, !tbaa !2447
  %352 = zext i1 %340 to i8
  store i8 %352, i8* %76, align 1, !tbaa !2448
  %353 = lshr i32 %337, 31
  %354 = trunc i32 %353 to i8
  store i8 %354, i8* %77, align 1, !tbaa !2449
  %355 = lshr i32 %336, 31
  %356 = xor i32 %353, %355
  %357 = add nuw nsw i32 %356, %353
  %358 = icmp eq i32 %357, 2
  %359 = zext i1 %358 to i8
  store i8 %359, i8* %78, align 1, !tbaa !2450
  %360 = add i64 %333, 9
  store i64 %360, i64* %PC, align 8
  store i32 %337, i32* %335, align 4
  %361 = load i64, i64* %PC, align 8
  %362 = add i64 %361, -173
  store i64 %362, i64* %PC, align 8, !tbaa !2428
  br label %block_401128
}

; Function Attrs: noinline norecurse nounwind
define %struct.Memory* @sub_401c10_bitrv2conj(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #9 {
block_401c10:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %var_2_52 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %.pre = load i64, i64* %PC, align 8
  %var_2_1638.pre = load i64, i64* %RBP, align 8
  %var_2_1639 = add i64 %var_2_1638.pre, -48
  %var_2_1641 = inttoptr i64 %var_2_1639 to i32*
  %var_2_1658 = add i64 %var_2_1638.pre, -44
  %var_2_1660 = inttoptr i64 %var_2_1658 to i32*
  %var_2_2042 = add i64 %var_2_1638.pre, -28
  %var_2_2044 = inttoptr i64 %var_2_2042 to i32*
  br label %block_401c36

block_401c61:                                     ; preds = %block_401c61.preheader, %block_401c61
  %var_2_207759 = phi i64 [ %var_2_2077, %block_401c61 ], [ %var_2_207758, %block_401c61.preheader ]
  %var_2_60 = add i64 %var_2_207759, 8
  store i64 %var_2_60, i64* %PC, align 8
  %var_2_170 = add i64 %var_2_207759, -43
  %var_2_2045 = load i32, i32* %var_2_2044, align 4
  %var_2_2050 = load i32, i32* %var_2_1641, align 4
  %var_2_2051 = sub i32 %var_2_2045, %var_2_2050
  %var_2_2066 = lshr i32 %var_2_2051, 31
  %var_2_2068 = lshr i32 %var_2_2045, 31
  %var_2_2069 = lshr i32 %var_2_2050, 31
  %var_2_2070 = xor i32 %var_2_2069, %var_2_2068
  %var_2_2071 = xor i32 %var_2_2066, %var_2_2068
  %var_2_2072 = add nuw nsw i32 %var_2_2071, %var_2_2070
  %var_2_2073 = icmp eq i32 %var_2_2072, 2
  %var_2_2075 = icmp ne i32 %var_2_2066, 0
  %var_2_2076 = xor i1 %var_2_2075, %var_2_2073
  %.v50 = select i1 %var_2_2076, i64 12, i64 56
  %var_2_2077 = add i64 %var_2_170, %.v50
  br i1 %var_2_2076, label %block_401c61, label %block_401c8d.loopexit

block_40204f:                                     ; preds = %block_401ccd
  %var_2_233 = add i64 %var_2_2611, -24
  %var_2_236 = inttoptr i64 %var_2_233 to i64*
  %var_2_237 = load i64, i64* %var_2_236, align 8
  %var_2_238 = add i64 %var_2_2611, -40
  %var_2_240 = inttoptr i64 %var_2_238 to i32*
  %var_2_241 = load i32, i32* %var_2_240, align 4
  %var_2_242 = add i32 %var_2_241, 1
  %var_2_265 = sext i32 %var_2_242 to i64
  %var_2_266 = shl nsw i64 %var_2_265, 3
  %var_2_267 = add i64 %var_2_266, %var_2_237
  %var_2_269 = inttoptr i64 %var_2_267 to i64*
  %var_2_270 = load i64, i64* %var_2_269, align 8
  %var_2_272 = xor i64 %var_2_270, -9223372036854775808
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_272, i64* %var_2_1808, align 1
  %var_2_357 = add i64 %var_2_2611, -32
  %var_2_360 = inttoptr i64 %var_2_357 to i32*
  %var_2_402 = load i64, i64* %var_2_236, align 8
  %var_2_404 = add i64 %var_2_856, 38
  store i64 %var_2_404, i64* %PC, align 8
  %var_2_406 = load i32, i32* %var_2_360, align 4
  %var_2_407 = sext i32 %var_2_406 to i64
  %var_2_408 = shl nsw i64 %var_2_407, 3
  %var_2_409 = add i64 %var_2_408, %var_2_402
  %var_2_410 = add i64 %var_2_856, 43
  store i64 %var_2_410, i64* %PC, align 8
  %var_2_411 = inttoptr i64 %var_2_409 to i64*
  %var_2_412 = load i64, i64* %var_2_411, align 8
  store i64 %var_2_412, i64* %var_2_1808, align 1
  %var_2_421 = load i64, i64* %var_2_236, align 8
  %var_2_425 = load i32, i32* %var_2_360, align 4
  %var_2_426 = add i32 %var_2_425, 1
  %var_2_449 = sext i32 %var_2_426 to i64
  %var_2_450 = shl nsw i64 %var_2_449, 3
  %var_2_451 = add i64 %var_2_450, %var_2_421
  %var_2_453 = inttoptr i64 %var_2_451 to i64*
  %var_2_454 = load i64, i64* %var_2_453, align 8
  %var_2_456 = xor i64 %var_2_454, -9223372036854775808
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_456, i64* %var_2_1808, align 1
  %var_2_475 = load i64, i64* %var_2_236, align 8
  %var_2_477 = add i64 %var_2_856, 51
  store i64 %var_2_477, i64* %PC, align 8
  %var_2_479 = load i32, i32* %var_2_240, align 4
  %var_2_480 = sext i32 %var_2_479 to i64
  %var_2_481 = shl nsw i64 %var_2_480, 3
  %var_2_482 = add i64 %var_2_481, %var_2_475
  %var_2_483 = add i64 %var_2_856, 56
  store i64 %var_2_483, i64* %PC, align 8
  %var_2_484 = inttoptr i64 %var_2_482 to i64*
  %var_2_485 = load i64, i64* %var_2_484, align 8
  store i64 %var_2_485, i64* %var_2_1808, align 1
  %var_2_494 = load i64, i64* %var_2_236, align 8
  %var_2_498 = load i32, i32* %var_2_240, align 4
  %var_2_499 = add i32 %var_2_498, 1
  %var_2_522 = sext i32 %var_2_499 to i64
  %var_2_523 = shl nsw i64 %var_2_522, 3
  %var_2_524 = add i64 %var_2_523, %var_2_494
  %var_2_526 = inttoptr i64 %var_2_524 to i64*
  %var_2_527 = load i64, i64* %var_2_526, align 8
  %var_2_529 = xor i64 %var_2_527, -9223372036854775808
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_529, i64* %var_2_1808, align 1
  %var_2_544 = add i64 %var_2_2611, -80
  %var_2_547 = inttoptr i64 %var_2_544 to i64*
  %var_2_548 = load i64, i64* %var_2_547, align 8
  store i64 %var_2_548, i64* %var_2_1808, align 1
  %var_2_554 = add i64 %var_2_856, 69
  store i64 %var_2_554, i64* %PC, align 8
  %var_2_563 = add i64 %var_2_2611, -88
  %var_2_566 = inttoptr i64 %var_2_563 to i64*
  %var_2_567 = load i64, i64* %var_2_566, align 8
  store i64 %var_2_567, i64* %var_2_1808, align 1
  %var_2_573 = add i64 %var_2_856, 81
  store i64 %var_2_573, i64* %PC, align 8
  %var_2_605 = add i64 %var_2_2611, -64
  %var_2_608 = inttoptr i64 %var_2_605 to i64*
  %var_2_609 = load i64, i64* %var_2_608, align 8
  store i64 %var_2_609, i64* %var_2_1808, align 1
  %var_2_615 = add i64 %var_2_856, 94
  store i64 %var_2_615, i64* %PC, align 8
  %var_2_624 = add i64 %var_2_2611, -72
  %var_2_627 = inttoptr i64 %var_2_624 to i64*
  %var_2_628 = load i64, i64* %var_2_627, align 8
  store i64 %var_2_628, i64* %var_2_1808, align 1
  %var_2_634 = add i64 %var_2_856, 106
  store i64 %var_2_634, i64* %PC, align 8
  %var_2_675 = load i32, i32* %var_2_240, align 4
  %var_2_709 = load i64, i64* %var_2_236, align 8
  %var_2_714 = add i32 %var_2_675, 1
  %var_2_737 = sext i32 %var_2_714 to i64
  %var_2_738 = shl nsw i64 %var_2_737, 3
  %var_2_739 = add i64 %var_2_738, %var_2_709
  %var_2_741 = inttoptr i64 %var_2_739 to i64*
  %var_2_742 = load i64, i64* %var_2_741, align 8
  %var_2_743 = load i64, i64* %RAX, align 8
  %var_2_744 = xor i64 %var_2_743, %var_2_742
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_744, i64* %var_2_1808, align 1
  %var_2_1859 = load i32, i32* %var_2_828, align 4
  %var_2_1861 = add i64 %var_2_2611, -48
  %var_2_1863 = inttoptr i64 %var_2_1861 to i32*
  %var_2_1864 = load i32, i32* %var_2_1863, align 4
  %var_2_1865 = sub i32 %var_2_1859, %var_2_1864
  %var_2_1880 = lshr i32 %var_2_1865, 31
  %var_2_1882 = lshr i32 %var_2_1859, 31
  %var_2_1883 = lshr i32 %var_2_1864, 31
  %var_2_1884 = xor i32 %var_2_1883, %var_2_1882
  %var_2_1885 = xor i32 %var_2_1880, %var_2_1882
  %var_2_1886 = add nuw nsw i32 %var_2_1885, %var_2_1884
  %var_2_1887 = icmp eq i32 %var_2_1886, 2
  %var_2_1889 = icmp ne i32 %var_2_1880, 0
  %var_2_1890 = xor i1 %var_2_1889, %var_2_1887
  br i1 %var_2_1890, label %block_40204f.block_401cc6_crit_edge, label %block_401cba.block_4024a2.loopexit_crit_edge

block_40204f.block_401cc6_crit_edge:              ; preds = %block_40204f
  %var_2_820.pre.pre = load i64, i64* %RBP, align 8
  br label %block_401cc6

block_401ccd:                                     ; preds = %block_401cd9, %block_401cc6
  %var_2_2611 = phi i64 [ %var_2_3082, %block_401cd9 ], [ %var_2_820.pre, %block_401cc6 ]
  %var_2_819 = phi i64 [ %var_2_3598, %block_401cd9 ], [ %.pre41, %block_401cc6 ]
  %var_2_821 = add i64 %var_2_2611, -28
  %var_2_823 = inttoptr i64 %var_2_821 to i32*
  %var_2_824 = load i32, i32* %var_2_823, align 4
  %var_2_826 = add i64 %var_2_2611, -36
  %var_2_828 = inttoptr i64 %var_2_826 to i32*
  %var_2_829 = load i32, i32* %var_2_828, align 4
  %var_2_830 = sub i32 %var_2_824, %var_2_829
  %var_2_845 = lshr i32 %var_2_830, 31
  %var_2_847 = lshr i32 %var_2_824, 31
  %var_2_848 = lshr i32 %var_2_829, 31
  %var_2_849 = xor i32 %var_2_848, %var_2_847
  %var_2_850 = xor i32 %var_2_845, %var_2_847
  %var_2_851 = add nuw nsw i32 %var_2_850, %var_2_849
  %var_2_852 = icmp eq i32 %var_2_851, 2
  %var_2_854 = icmp ne i32 %var_2_845, 0
  %var_2_855 = xor i1 %var_2_854, %var_2_852
  %.v49 = select i1 %var_2_855, i64 12, i64 898
  %var_2_856 = add i64 %.v49, %var_2_819
  store i8 0, i8* %var_2_52, align 1
  %var_2_2159 = add i64 %var_2_856, 30
  store i64 %var_2_2159, i64* %PC, align 8
  br i1 %var_2_855, label %block_401cd9, label %block_40204f

block_401cc6:                                     ; preds = %block_401cc6.preheader, %block_40204f.block_401cc6_crit_edge
  %var_2_820.pre = phi i64 [ %var_2_820.pre.pre, %block_40204f.block_401cc6_crit_edge ], [ %var_2_1638.pre, %block_401cc6.preheader ]
  %.pre41 = phi i64 [ %var_2_634, %block_40204f.block_401cc6_crit_edge ], [ %var_2_1987, %block_401cc6.preheader ]
  br label %block_401ccd

block_40223b:                                     ; preds = %block_40222f
  store i8 0, i8* %var_2_52, align 1
  %var_2_989 = add i64 %var_2_1848, 50
  store i64 %var_2_989, i64* %PC, align 8
  %var_2_992 = add i64 %var_2_1356, -24
  %var_2_995 = inttoptr i64 %var_2_992 to i64*
  %var_2_996 = load i64, i64* %var_2_995, align 8
  %var_2_997 = add i64 %var_2_1356, -32
  %var_2_998 = add i64 %var_2_1848, 58
  store i64 %var_2_998, i64* %PC, align 8
  %var_2_999 = inttoptr i64 %var_2_997 to i32*
  %var_2_1000 = load i32, i32* %var_2_999, align 4
  %var_2_1001 = sext i32 %var_2_1000 to i64
  %var_2_1002 = shl nsw i64 %var_2_1001, 3
  %var_2_1003 = add i64 %var_2_1002, %var_2_996
  %var_2_1004 = add i64 %var_2_1848, 63
  store i64 %var_2_1004, i64* %PC, align 8
  %var_2_1005 = inttoptr i64 %var_2_1003 to i64*
  %var_2_1006 = load i64, i64* %var_2_1005, align 8
  store i64 %var_2_1006, i64* %var_2_1698, align 1
  %var_2_1015 = load i64, i64* %var_2_995, align 8
  %var_2_1019 = load i32, i32* %var_2_999, align 4
  %var_2_1020 = add i32 %var_2_1019, 1
  %var_2_1043 = sext i32 %var_2_1020 to i64
  %var_2_1044 = shl nsw i64 %var_2_1043, 3
  %var_2_1045 = add i64 %var_2_1044, %var_2_1015
  %var_2_1047 = inttoptr i64 %var_2_1045 to i64*
  %var_2_1048 = load i64, i64* %var_2_1047, align 8
  %var_2_1050 = xor i64 %var_2_1048, -9223372036854775808
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_1050, i64* %var_2_1698, align 1
  %var_2_1069 = load i64, i64* %var_2_995, align 8
  %var_2_1070 = add i64 %var_2_1356, -40
  %var_2_1071 = add i64 %var_2_1848, 71
  store i64 %var_2_1071, i64* %PC, align 8
  %var_2_1072 = inttoptr i64 %var_2_1070 to i32*
  %var_2_1073 = load i32, i32* %var_2_1072, align 4
  %var_2_1074 = sext i32 %var_2_1073 to i64
  %var_2_1075 = shl nsw i64 %var_2_1074, 3
  %var_2_1076 = add i64 %var_2_1075, %var_2_1069
  %var_2_1077 = add i64 %var_2_1848, 76
  store i64 %var_2_1077, i64* %PC, align 8
  %var_2_1078 = inttoptr i64 %var_2_1076 to i64*
  %var_2_1079 = load i64, i64* %var_2_1078, align 8
  store i64 %var_2_1079, i64* %var_2_1698, align 1
  %var_2_1088 = load i64, i64* %var_2_995, align 8
  %var_2_1092 = load i32, i32* %var_2_1072, align 4
  %var_2_1093 = add i32 %var_2_1092, 1
  %var_2_1116 = sext i32 %var_2_1093 to i64
  %var_2_1117 = shl nsw i64 %var_2_1116, 3
  %var_2_1118 = add i64 %var_2_1117, %var_2_1088
  %var_2_1120 = inttoptr i64 %var_2_1118 to i64*
  %var_2_1121 = load i64, i64* %var_2_1120, align 8
  %var_2_1123 = xor i64 %var_2_1121, -9223372036854775808
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_1123, i64* %var_2_1698, align 1
  %var_2_1138 = add i64 %var_2_1356, -80
  %var_2_1141 = inttoptr i64 %var_2_1138 to i64*
  %var_2_1142 = load i64, i64* %var_2_1141, align 8
  store i64 %var_2_1142, i64* %var_2_1698, align 1
  %var_2_1148 = add i64 %var_2_1848, 89
  store i64 %var_2_1148, i64* %PC, align 8
  %var_2_1157 = add i64 %var_2_1356, -88
  %var_2_1160 = inttoptr i64 %var_2_1157 to i64*
  %var_2_1161 = load i64, i64* %var_2_1160, align 8
  store i64 %var_2_1161, i64* %var_2_1698, align 1
  %var_2_1167 = add i64 %var_2_1848, 101
  store i64 %var_2_1167, i64* %PC, align 8
  %var_2_1199 = add i64 %var_2_1356, -64
  %var_2_1202 = inttoptr i64 %var_2_1199 to i64*
  %var_2_1203 = load i64, i64* %var_2_1202, align 8
  store i64 %var_2_1203, i64* %var_2_1698, align 1
  %var_2_1209 = add i64 %var_2_1848, 114
  store i64 %var_2_1209, i64* %PC, align 8
  %var_2_1218 = add i64 %var_2_1356, -72
  %var_2_1221 = inttoptr i64 %var_2_1218 to i64*
  %var_2_1222 = load i64, i64* %var_2_1221, align 8
  store i64 %var_2_1222, i64* %var_2_1698, align 1
  %var_2_1228 = add i64 %var_2_1848, 126
  store i64 %var_2_1228, i64* %PC, align 8
  %var_2_1342 = load i64, i64* %var_2_995, align 8
  %var_2_1344 = add i64 %var_2_1848, 134
  store i64 %var_2_1344, i64* %PC, align 8
  %var_2_1346 = load i32, i32* %var_2_999, align 4
  %var_2_1347 = sext i32 %var_2_1346 to i64
  %var_2_1348 = shl nsw i64 %var_2_1347, 3
  %var_2_1349 = add i64 %var_2_1348, %var_2_1342
  %var_2_1350 = add i64 %var_2_1848, 139
  store i64 %var_2_1350, i64* %PC, align 8
  %var_2_1351 = inttoptr i64 %var_2_1349 to i64*
  %var_2_1352 = load i64, i64* %var_2_1351, align 8
  store i64 %var_2_1352, i64* %var_2_1698, align 1
  %var_2_1361 = load i64, i64* %var_2_995, align 8
  %var_2_1365 = load i32, i32* %var_2_999, align 4
  %var_2_1366 = add i32 %var_2_1365, 1
  %var_2_1389 = sext i32 %var_2_1366 to i64
  %var_2_1390 = shl nsw i64 %var_2_1389, 3
  %var_2_1391 = add i64 %var_2_1390, %var_2_1361
  %var_2_1393 = inttoptr i64 %var_2_1391 to i64*
  %var_2_1394 = load i64, i64* %var_2_1393, align 8
  %var_2_1395 = load i64, i64* %RAX, align 8
  %var_2_1396 = xor i64 %var_2_1395, %var_2_1394
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_1396, i64* %var_2_1698, align 1
  %var_2_1410 = load i64, i64* %RBP, align 8
  %var_2_1411 = add i64 %var_2_1410, -24
  %var_2_1414 = inttoptr i64 %var_2_1411 to i64*
  %var_2_1415 = load i64, i64* %var_2_1414, align 8
  %var_2_1416 = add i64 %var_2_1410, -40
  %var_2_1417 = add i64 %var_2_1848, 147
  store i64 %var_2_1417, i64* %PC, align 8
  %var_2_1418 = inttoptr i64 %var_2_1416 to i32*
  %var_2_1419 = load i32, i32* %var_2_1418, align 4
  %var_2_1420 = sext i32 %var_2_1419 to i64
  %var_2_1421 = shl nsw i64 %var_2_1420, 3
  %var_2_1422 = add i64 %var_2_1421, %var_2_1415
  %var_2_1423 = add i64 %var_2_1848, 152
  store i64 %var_2_1423, i64* %PC, align 8
  %var_2_1424 = inttoptr i64 %var_2_1422 to i64*
  %var_2_1425 = load i64, i64* %var_2_1424, align 8
  store i64 %var_2_1425, i64* %var_2_1698, align 1
  %var_2_1434 = load i64, i64* %var_2_1414, align 8
  %var_2_1438 = load i32, i32* %var_2_1418, align 4
  %var_2_1439 = add i32 %var_2_1438, 1
  %var_2_1462 = sext i32 %var_2_1439 to i64
  %var_2_1463 = shl nsw i64 %var_2_1462, 3
  %var_2_1464 = add i64 %var_2_1463, %var_2_1434
  %var_2_1466 = inttoptr i64 %var_2_1464 to i64*
  %var_2_1467 = load i64, i64* %var_2_1466, align 8
  %var_2_1469 = xor i64 %var_2_1467, %var_2_1395
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_1469, i64* %var_2_1698, align 1
  %var_2_1484 = add i64 %var_2_1410, -80
  %var_2_1487 = inttoptr i64 %var_2_1484 to i64*
  %var_2_1488 = load i64, i64* %var_2_1487, align 8
  store i64 %var_2_1488, i64* %var_2_1698, align 1
  %var_2_1494 = add i64 %var_2_1848, 165
  store i64 %var_2_1494, i64* %PC, align 8
  %var_2_1503 = add i64 %var_2_1410, -88
  %var_2_1506 = inttoptr i64 %var_2_1503 to i64*
  %var_2_1507 = load i64, i64* %var_2_1506, align 8
  store i64 %var_2_1507, i64* %var_2_1698, align 1
  %var_2_1513 = add i64 %var_2_1848, 177
  store i64 %var_2_1513, i64* %PC, align 8
  %var_2_1545 = add i64 %var_2_1410, -64
  %var_2_1548 = inttoptr i64 %var_2_1545 to i64*
  %var_2_1549 = load i64, i64* %var_2_1548, align 8
  store i64 %var_2_1549, i64* %var_2_1698, align 1
  %var_2_1555 = add i64 %var_2_1848, 190
  store i64 %var_2_1555, i64* %PC, align 8
  %var_2_1564 = add i64 %var_2_1410, -72
  %var_2_1567 = inttoptr i64 %var_2_1564 to i64*
  %var_2_1568 = load i64, i64* %var_2_1567, align 8
  store i64 %var_2_1568, i64* %var_2_1698, align 1
  %var_2_1574 = add i64 %var_2_1848, 202
  store i64 %var_2_1574, i64* %PC, align 8
  %var_2_1636 = add i64 %var_2_1848, -267
  br label %block_40222f

block_401c36:                                     ; preds = %block_401c8d, %block_401c10
  %var_2_1637 = phi i64 [ %var_2_2099, %block_401c8d ], [ %.pre, %block_401c10 ]
  %var_2_1642 = load i32, i32* %var_2_1641, align 4
  %var_2_1643 = shl i32 %var_2_1642, 3
  store i8 0, i8* %var_2_52, align 1
  %var_2_1661 = load i32, i32* %var_2_1660, align 4
  %var_2_1662 = sub i32 %var_2_1643, %var_2_1661
  %var_2_1677 = lshr i32 %var_2_1662, 31
  %var_2_1679 = lshr i32 %var_2_1642, 28
  %var_2_1680 = and i32 %var_2_1679, 1
  %var_2_1681 = lshr i32 %var_2_1661, 31
  %var_2_1682 = xor i32 %var_2_1681, %var_2_1680
  %var_2_1683 = xor i32 %var_2_1677, %var_2_1680
  %var_2_1684 = add nuw nsw i32 %var_2_1683, %var_2_1682
  %var_2_1685 = icmp eq i32 %var_2_1684, 2
  %var_2_1687 = icmp ne i32 %var_2_1677, 0
  %var_2_1688 = xor i1 %var_2_1687, %var_2_1685
  %.v = select i1 %var_2_1688, i64 15, i64 101
  %var_2_1689 = add i64 %.v, %var_2_1637
  store i64 %var_2_1689, i64* %PC, align 8
  br i1 %var_2_1688, label %block_401c45, label %block_401c9b

block_4021bb:                                     ; preds = %block_401c9b
  %var_2_1690 = add i64 %var_2_1638.pre, -24
  %var_2_1692 = inttoptr i64 %var_2_1690 to i64*
  %var_2_1693 = load i64, i64* %var_2_1692, align 8
  %var_2_1694 = add i64 %var_2_1693, 8
  %var_2_1696 = inttoptr i64 %var_2_1694 to i64*
  %var_2_1697 = load i64, i64* %var_2_1696, align 8
  %var_2_1698 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %var_2_1966, i64 0, i32 0, i32 0, i32 0, i64 0
  %var_2_1701 = xor i64 %var_2_1697, -9223372036854775808
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_1701, i64* %var_2_1698, align 1
  %var_2_1722 = load i64, i64* %var_2_1692, align 8
  %var_2_1723 = add i64 %var_2_1638.pre, -52
  %var_2_1725 = inttoptr i64 %var_2_1723 to i32*
  %var_2_1726 = load i32, i32* %var_2_1725, align 4
  %var_2_1727 = add i32 %var_2_1726, 1
  %var_2_1750 = sext i32 %var_2_1727 to i64
  %var_2_1751 = shl nsw i64 %var_2_1750, 3
  %var_2_1752 = add i64 %var_2_1751, %var_2_1722
  %var_2_1754 = inttoptr i64 %var_2_1752 to i64*
  %var_2_1755 = load i64, i64* %var_2_1754, align 8
  %var_2_1757 = xor i64 %var_2_1755, -9223372036854775808
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_1757, i64* %var_2_1698, align 1
  %var_2_193027 = add i64 %var_2_1638.pre, -36
  %var_2_193228 = inttoptr i64 %var_2_193027 to i32*
  %var_2_193329 = load i32, i32* %var_2_193228, align 4
  %var_2_193832 = load i32, i32* %var_2_1641, align 4
  %var_2_193933 = sub i32 %var_2_193329, %var_2_193832
  %var_2_195434 = lshr i32 %var_2_193933, 31
  %var_2_195635 = lshr i32 %var_2_193329, 31
  %var_2_195736 = lshr i32 %var_2_193832, 31
  %var_2_195837 = xor i32 %var_2_195736, %var_2_195635
  %var_2_195938 = xor i32 %var_2_195434, %var_2_195635
  %var_2_196039 = add nuw nsw i32 %var_2_195938, %var_2_195837
  %var_2_196140 = icmp eq i32 %var_2_196039, 2
  %var_2_196341 = icmp ne i32 %var_2_195434, 0
  %var_2_196442 = xor i1 %var_2_196341, %var_2_196140
  br i1 %var_2_196442, label %block_402228.preheader, label %block_4024a2

block_402228.preheader:                           ; preds = %block_4021bb
  br label %block_402228

block_401cb3:                                     ; preds = %block_401c9b
  %var_2_1808 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %var_2_1966, i64 0, i32 0, i32 0, i32 0, i64 0
  %var_2_185610 = add i64 %var_2_1638.pre, -36
  %var_2_185811 = inttoptr i64 %var_2_185610 to i32*
  %var_2_185912 = load i32, i32* %var_2_185811, align 4
  %var_2_186415 = load i32, i32* %var_2_1641, align 4
  %var_2_186516 = sub i32 %var_2_185912, %var_2_186415
  %var_2_188017 = lshr i32 %var_2_186516, 31
  %var_2_188218 = lshr i32 %var_2_185912, 31
  %var_2_188319 = lshr i32 %var_2_186415, 31
  %var_2_188420 = xor i32 %var_2_188319, %var_2_188218
  %var_2_188521 = xor i32 %var_2_188017, %var_2_188218
  %var_2_188622 = add nuw nsw i32 %var_2_188521, %var_2_188420
  %var_2_188723 = icmp eq i32 %var_2_188622, 2
  %var_2_188924 = icmp ne i32 %var_2_188017, 0
  %var_2_189025 = xor i1 %var_2_188924, %var_2_188723
  br i1 %var_2_189025, label %block_401cc6.preheader, label %block_4024a2

block_401cc6.preheader:                           ; preds = %block_401cb3
  br label %block_401cc6

block_40222f:                                     ; preds = %block_402228, %block_40223b
  %var_2_1356 = phi i64 [ %var_2_1812.pre, %block_402228 ], [ %var_2_1410, %block_40223b ]
  %var_2_1811 = phi i64 [ %.pre43, %block_402228 ], [ %var_2_1636, %block_40223b ]
  %var_2_1813 = add i64 %var_2_1356, -28
  %var_2_1815 = inttoptr i64 %var_2_1813 to i32*
  %var_2_1816 = load i32, i32* %var_2_1815, align 4
  %var_2_1818 = add i64 %var_2_1356, -36
  %var_2_1820 = inttoptr i64 %var_2_1818 to i32*
  %var_2_1821 = load i32, i32* %var_2_1820, align 4
  %var_2_1822 = sub i32 %var_2_1816, %var_2_1821
  %var_2_1837 = lshr i32 %var_2_1822, 31
  %var_2_1839 = lshr i32 %var_2_1816, 31
  %var_2_1840 = lshr i32 %var_2_1821, 31
  %var_2_1841 = xor i32 %var_2_1840, %var_2_1839
  %var_2_1842 = xor i32 %var_2_1837, %var_2_1839
  %var_2_1843 = add nuw nsw i32 %var_2_1842, %var_2_1841
  %var_2_1844 = icmp eq i32 %var_2_1843, 2
  %var_2_1846 = icmp ne i32 %var_2_1837, 0
  %var_2_1847 = xor i1 %var_2_1846, %var_2_1844
  %.v47 = select i1 %var_2_1847, i64 12, i64 474
  %var_2_1848 = add i64 %.v47, %var_2_1811
  store i8 0, i8* %var_2_52, align 1
  %var_2_921 = add i64 %var_2_1848, 30
  store i64 %var_2_921, i64* %PC, align 8
  br i1 %var_2_1847, label %block_40223b, label %block_402409

block_402228:                                     ; preds = %block_402228.preheader, %block_402409
  %var_2_1812.pre = phi i64 [ %var_2_1356, %block_402409 ], [ %var_2_1638.pre, %block_402228.preheader ]
  %.pre43 = phi i64 [ %var_2_3755, %block_402409 ], [ %var_2_1987, %block_402228.preheader ]
  br label %block_40222f

block_401cba.block_4024a2.loopexit_crit_edge:     ; preds = %block_40204f
  %var_2_818 = add i64 %var_2_856, -1165
  br label %block_4024a2

block_40221c.block_4024a2.loopexit9_crit_edge:    ; preds = %block_402409
  %var_2_3874 = add i64 %var_2_1848, -596
  br label %block_4024a2

block_4024a2:                                     ; preds = %block_40221c.block_4024a2.loopexit9_crit_edge, %block_401cba.block_4024a2.loopexit_crit_edge, %block_401cb3, %block_4021bb
  %var_2_1928.lcssa.sink = phi i64 [ %var_2_818, %block_401cba.block_4024a2.loopexit_crit_edge ], [ %var_2_1987, %block_401cb3 ], [ %var_2_3874, %block_40221c.block_4024a2.loopexit9_crit_edge ], [ %var_2_1987, %block_4021bb ]
  %.v46.le.sink = phi i64 [ 1276, %block_401cba.block_4024a2.loopexit_crit_edge ], [ 1276, %block_401cb3 ], [ 641, %block_40221c.block_4024a2.loopexit9_crit_edge ], [ 641, %block_4021bb ]
  %.sink5 = phi i64 [ 749, %block_401cba.block_4024a2.loopexit_crit_edge ], [ 749, %block_401cb3 ], [ 6, %block_40221c.block_4024a2.loopexit9_crit_edge ], [ 6, %block_4021bb ]
  %var_2_1965.le = add i64 %var_2_1928.lcssa.sink, 1
  %var_2_1893 = add i64 %var_2_1965.le, %.v46.le.sink
  %var_2_1898 = add i64 %var_2_1893, %.sink5
  store i64 %var_2_1898, i64* %PC, align 8
; Matched:\<badref\>:  ret %struct.Memory* %2
; ret %struct.Memory* %2
ret %struct.Memory* %2


block_401c45:                                     ; preds = %block_401c36
  store i8 0, i8* %var_2_52, align 1
  %var_2_1922 = add i64 %var_2_1689, 9
  store i64 %var_2_1922, i64* %PC, align 8
  %var_2_204545 = load i32, i32* %var_2_2044, align 4
  %var_2_205046 = load i32, i32* %var_2_1641, align 4
  %var_2_205147 = sub i32 %var_2_204545, %var_2_205046
  %var_2_206648 = lshr i32 %var_2_205147, 31
  %var_2_206849 = lshr i32 %var_2_204545, 31
  %var_2_206950 = lshr i32 %var_2_205046, 31
  %var_2_207051 = xor i32 %var_2_206950, %var_2_206849
  %var_2_207152 = xor i32 %var_2_206648, %var_2_206849
  %var_2_207253 = add nuw nsw i32 %var_2_207152, %var_2_207051
  %var_2_207354 = icmp eq i32 %var_2_207253, 2
  %var_2_207555 = icmp ne i32 %var_2_206648, 0
  %var_2_207656 = xor i1 %var_2_207555, %var_2_207354
  %.v5057 = select i1 %var_2_207656, i64 12, i64 56
  %var_2_207758 = add i64 %.v5057, %var_2_1922
  br i1 %var_2_207656, label %block_401c61.preheader, label %block_401c8d

block_401c61.preheader:                           ; preds = %block_401c45
  br label %block_401c61

block_401c9b:                                     ; preds = %block_401c36
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %var_2_1966 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  store i8 0, i8* %var_2_52, align 1
  %var_2_1987 = add i64 %var_2_1689, 9
  store i64 %var_2_1987, i64* %PC, align 8
  %var_2_1994 = load i32, i32* %var_2_1641, align 4
  %var_2_1995 = shl i32 %var_2_1994, 3
  store i8 0, i8* %var_2_52, align 1
  %var_2_2013 = load i32, i32* %var_2_1660, align 4
  %var_2_2027 = icmp eq i32 %var_2_1995, %var_2_2013
  br i1 %var_2_2027, label %block_401cb3, label %block_4021bb

block_401c8d.loopexit:                            ; preds = %block_401c61
  br label %block_401c8d

block_401c8d:                                     ; preds = %block_401c8d.loopexit, %block_401c45
  %var_2_2077.lcssa = phi i64 [ %var_2_207758, %block_401c45 ], [ %var_2_2077, %block_401c8d.loopexit ]
  store i8 0, i8* %var_2_52, align 1
  %var_2_2097 = add i64 %var_2_2077.lcssa, 9
  store i64 %var_2_2097, i64* %PC, align 8
  %var_2_2099 = add i64 %var_2_2077.lcssa, -87
  br label %block_401c36

block_401cd9:                                     ; preds = %block_401ccd
  store i8 0, i8* %var_2_52, align 1
  %var_2_2227 = add i64 %var_2_856, 50
  store i64 %var_2_2227, i64* %PC, align 8
  %var_2_2230 = add i64 %var_2_2611, -24
  %var_2_2233 = inttoptr i64 %var_2_2230 to i64*
  %var_2_2234 = load i64, i64* %var_2_2233, align 8
  %var_2_2235 = add i64 %var_2_2611, -32
  %var_2_2236 = add i64 %var_2_856, 58
  store i64 %var_2_2236, i64* %PC, align 8
  %var_2_2237 = inttoptr i64 %var_2_2235 to i32*
  %var_2_2238 = load i32, i32* %var_2_2237, align 4
  %var_2_2239 = sext i32 %var_2_2238 to i64
  %var_2_2240 = shl nsw i64 %var_2_2239, 3
  %var_2_2241 = add i64 %var_2_2240, %var_2_2234
  %var_2_2242 = add i64 %var_2_856, 63
  store i64 %var_2_2242, i64* %PC, align 8
  %var_2_2243 = inttoptr i64 %var_2_2241 to i64*
  %var_2_2244 = load i64, i64* %var_2_2243, align 8
  store i64 %var_2_2244, i64* %var_2_1808, align 1
  %var_2_2253 = load i64, i64* %var_2_2233, align 8
  %var_2_2257 = load i32, i32* %var_2_2237, align 4
  %var_2_2258 = add i32 %var_2_2257, 1
  %var_2_2281 = sext i32 %var_2_2258 to i64
  %var_2_2282 = shl nsw i64 %var_2_2281, 3
  %var_2_2283 = add i64 %var_2_2282, %var_2_2253
  %var_2_2285 = inttoptr i64 %var_2_2283 to i64*
  %var_2_2286 = load i64, i64* %var_2_2285, align 8
  %var_2_2288 = xor i64 %var_2_2286, -9223372036854775808
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_2288, i64* %var_2_1808, align 1
  %var_2_2307 = load i64, i64* %var_2_2233, align 8
  %var_2_2308 = add i64 %var_2_2611, -40
  %var_2_2309 = add i64 %var_2_856, 71
  store i64 %var_2_2309, i64* %PC, align 8
  %var_2_2310 = inttoptr i64 %var_2_2308 to i32*
  %var_2_2311 = load i32, i32* %var_2_2310, align 4
  %var_2_2312 = sext i32 %var_2_2311 to i64
  %var_2_2313 = shl nsw i64 %var_2_2312, 3
  %var_2_2314 = add i64 %var_2_2313, %var_2_2307
  %var_2_2315 = add i64 %var_2_856, 76
  store i64 %var_2_2315, i64* %PC, align 8
  %var_2_2316 = inttoptr i64 %var_2_2314 to i64*
  %var_2_2317 = load i64, i64* %var_2_2316, align 8
  store i64 %var_2_2317, i64* %var_2_1808, align 1
  %var_2_2326 = load i64, i64* %var_2_2233, align 8
  %var_2_2330 = load i32, i32* %var_2_2310, align 4
  %var_2_2331 = add i32 %var_2_2330, 1
  %var_2_2354 = sext i32 %var_2_2331 to i64
  %var_2_2355 = shl nsw i64 %var_2_2354, 3
  %var_2_2356 = add i64 %var_2_2355, %var_2_2326
  %var_2_2358 = inttoptr i64 %var_2_2356 to i64*
  %var_2_2359 = load i64, i64* %var_2_2358, align 8
  %var_2_2361 = xor i64 %var_2_2359, -9223372036854775808
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_2361, i64* %var_2_1808, align 1
  %var_2_2376 = add i64 %var_2_2611, -80
  %var_2_2379 = inttoptr i64 %var_2_2376 to i64*
  %var_2_2380 = load i64, i64* %var_2_2379, align 8
  store i64 %var_2_2380, i64* %var_2_1808, align 1
  %var_2_2386 = add i64 %var_2_856, 89
  store i64 %var_2_2386, i64* %PC, align 8
  %var_2_2395 = add i64 %var_2_2611, -88
  %var_2_2398 = inttoptr i64 %var_2_2395 to i64*
  %var_2_2399 = load i64, i64* %var_2_2398, align 8
  store i64 %var_2_2399, i64* %var_2_1808, align 1
  %var_2_2405 = add i64 %var_2_856, 101
  store i64 %var_2_2405, i64* %PC, align 8
  %var_2_2437 = add i64 %var_2_2611, -64
  %var_2_2440 = inttoptr i64 %var_2_2437 to i64*
  %var_2_2441 = load i64, i64* %var_2_2440, align 8
  store i64 %var_2_2441, i64* %var_2_1808, align 1
  %var_2_2447 = add i64 %var_2_856, 114
  store i64 %var_2_2447, i64* %PC, align 8
  %var_2_2456 = add i64 %var_2_2611, -72
  %var_2_2459 = inttoptr i64 %var_2_2456 to i64*
  %var_2_2460 = load i64, i64* %var_2_2459, align 8
  store i64 %var_2_2460, i64* %var_2_1808, align 1
  store i8 0, i8* %var_2_52, align 1
  %var_2_2591 = add i64 %var_2_856, 138
  store i64 %var_2_2591, i64* %PC, align 8
  %var_2_2597 = load i64, i64* %var_2_2233, align 8
  %var_2_2599 = add i64 %var_2_856, 146
  store i64 %var_2_2599, i64* %PC, align 8
  %var_2_2601 = load i32, i32* %var_2_2237, align 4
  %var_2_2602 = sext i32 %var_2_2601 to i64
  %var_2_2603 = shl nsw i64 %var_2_2602, 3
  %var_2_2604 = add i64 %var_2_2603, %var_2_2597
  %var_2_2605 = add i64 %var_2_856, 151
  store i64 %var_2_2605, i64* %PC, align 8
  %var_2_2606 = inttoptr i64 %var_2_2604 to i64*
  %var_2_2607 = load i64, i64* %var_2_2606, align 8
  store i64 %var_2_2607, i64* %var_2_1808, align 1
  %var_2_2616 = load i64, i64* %var_2_2233, align 8
  %var_2_2620 = load i32, i32* %var_2_2237, align 4
  %var_2_2621 = add i32 %var_2_2620, 1
  %var_2_2644 = sext i32 %var_2_2621 to i64
  %var_2_2645 = shl nsw i64 %var_2_2644, 3
  %var_2_2646 = add i64 %var_2_2645, %var_2_2616
  %var_2_2648 = inttoptr i64 %var_2_2646 to i64*
  %var_2_2649 = load i64, i64* %var_2_2648, align 8
  %var_2_2650 = load i64, i64* %RAX, align 8
  %var_2_2651 = xor i64 %var_2_2650, %var_2_2649
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_2651, i64* %var_2_1808, align 1
  %var_2_2665 = load i64, i64* %RBP, align 8
  %var_2_2666 = add i64 %var_2_2665, -24
  %var_2_2669 = inttoptr i64 %var_2_2666 to i64*
  %var_2_2670 = load i64, i64* %var_2_2669, align 8
  %var_2_2671 = add i64 %var_2_2665, -40
  %var_2_2672 = add i64 %var_2_856, 159
  store i64 %var_2_2672, i64* %PC, align 8
  %var_2_2673 = inttoptr i64 %var_2_2671 to i32*
  %var_2_2674 = load i32, i32* %var_2_2673, align 4
  %var_2_2675 = sext i32 %var_2_2674 to i64
  %var_2_2676 = shl nsw i64 %var_2_2675, 3
  %var_2_2677 = add i64 %var_2_2676, %var_2_2670
  %var_2_2678 = add i64 %var_2_856, 164
  store i64 %var_2_2678, i64* %PC, align 8
  %var_2_2679 = inttoptr i64 %var_2_2677 to i64*
  %var_2_2680 = load i64, i64* %var_2_2679, align 8
  store i64 %var_2_2680, i64* %var_2_1808, align 1
  %var_2_2689 = load i64, i64* %var_2_2669, align 8
  %var_2_2693 = load i32, i32* %var_2_2673, align 4
  %var_2_2694 = add i32 %var_2_2693, 1
  %var_2_2717 = sext i32 %var_2_2694 to i64
  %var_2_2718 = shl nsw i64 %var_2_2717, 3
  %var_2_2719 = add i64 %var_2_2718, %var_2_2689
  %var_2_2721 = inttoptr i64 %var_2_2719 to i64*
  %var_2_2722 = load i64, i64* %var_2_2721, align 8
  %var_2_2724 = xor i64 %var_2_2722, %var_2_2650
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_2724, i64* %var_2_1808, align 1
  %var_2_2739 = add i64 %var_2_2665, -80
  %var_2_2742 = inttoptr i64 %var_2_2739 to i64*
  %var_2_2743 = load i64, i64* %var_2_2742, align 8
  store i64 %var_2_2743, i64* %var_2_1808, align 1
  %var_2_2749 = add i64 %var_2_856, 177
  store i64 %var_2_2749, i64* %PC, align 8
  %var_2_2758 = add i64 %var_2_2665, -88
  %var_2_2761 = inttoptr i64 %var_2_2758 to i64*
  %var_2_2762 = load i64, i64* %var_2_2761, align 8
  store i64 %var_2_2762, i64* %var_2_1808, align 1
  %var_2_2768 = add i64 %var_2_856, 189
  store i64 %var_2_2768, i64* %PC, align 8
  %var_2_2800 = add i64 %var_2_2665, -64
  %var_2_2803 = inttoptr i64 %var_2_2800 to i64*
  %var_2_2804 = load i64, i64* %var_2_2803, align 8
  store i64 %var_2_2804, i64* %var_2_1808, align 1
  %var_2_2810 = add i64 %var_2_856, 202
  store i64 %var_2_2810, i64* %PC, align 8
  %var_2_2819 = add i64 %var_2_2665, -72
  %var_2_2822 = inttoptr i64 %var_2_2819 to i64*
  %var_2_2823 = load i64, i64* %var_2_2822, align 8
  store i64 %var_2_2823, i64* %var_2_1808, align 1
  %var_2_2935 = add i64 %var_2_856, 225
  store i64 %var_2_2935, i64* %PC, align 8
  %var_2_2941 = load i64, i64* %var_2_2669, align 8
  %var_2_2942 = add i64 %var_2_2665, -32
  %var_2_2943 = add i64 %var_2_856, 233
  store i64 %var_2_2943, i64* %PC, align 8
  %var_2_2944 = inttoptr i64 %var_2_2942 to i32*
  %var_2_2945 = load i32, i32* %var_2_2944, align 4
  %var_2_2946 = sext i32 %var_2_2945 to i64
  %var_2_2947 = shl nsw i64 %var_2_2946, 3
  %var_2_2948 = add i64 %var_2_2947, %var_2_2941
  %var_2_2949 = add i64 %var_2_856, 238
  store i64 %var_2_2949, i64* %PC, align 8
  %var_2_2950 = inttoptr i64 %var_2_2948 to i64*
  %var_2_2951 = load i64, i64* %var_2_2950, align 8
  store i64 %var_2_2951, i64* %var_2_1808, align 1
  %var_2_2960 = load i64, i64* %var_2_2669, align 8
  %var_2_2964 = load i32, i32* %var_2_2944, align 4
  %var_2_2965 = add i32 %var_2_2964, 1
  %var_2_2988 = sext i32 %var_2_2965 to i64
  %var_2_2989 = shl nsw i64 %var_2_2988, 3
  %var_2_2990 = add i64 %var_2_2989, %var_2_2960
  %var_2_2992 = inttoptr i64 %var_2_2990 to i64*
  %var_2_2993 = load i64, i64* %var_2_2992, align 8
  %var_2_2995 = xor i64 %var_2_2993, %var_2_2650
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_2995, i64* %var_2_1808, align 1
  %var_2_3014 = load i64, i64* %var_2_2669, align 8
  %var_2_3016 = add i64 %var_2_856, 246
  store i64 %var_2_3016, i64* %PC, align 8
  %var_2_3018 = load i32, i32* %var_2_2673, align 4
  %var_2_3019 = sext i32 %var_2_3018 to i64
  %var_2_3020 = shl nsw i64 %var_2_3019, 3
  %var_2_3021 = add i64 %var_2_3020, %var_2_3014
  %var_2_3022 = add i64 %var_2_856, 251
  store i64 %var_2_3022, i64* %PC, align 8
  %var_2_3023 = inttoptr i64 %var_2_3021 to i64*
  %var_2_3024 = load i64, i64* %var_2_3023, align 8
  store i64 %var_2_3024, i64* %var_2_1808, align 1
  %var_2_3033 = load i64, i64* %var_2_2669, align 8
  %var_2_3037 = load i32, i32* %var_2_2673, align 4
  %var_2_3038 = add i32 %var_2_3037, 1
  %var_2_3061 = sext i32 %var_2_3038 to i64
  %var_2_3062 = shl nsw i64 %var_2_3061, 3
  %var_2_3063 = add i64 %var_2_3062, %var_2_3033
  %var_2_3065 = inttoptr i64 %var_2_3063 to i64*
  %var_2_3066 = load i64, i64* %var_2_3065, align 8
  %var_2_3067 = load i64, i64* %RAX, align 8
  %var_2_3068 = xor i64 %var_2_3067, %var_2_3066
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_3068, i64* %var_2_1808, align 1
  %var_2_3082 = load i64, i64* %RBP, align 8
  %var_2_3083 = add i64 %var_2_3082, -80
  %var_2_3086 = inttoptr i64 %var_2_3083 to i64*
  %var_2_3087 = load i64, i64* %var_2_3086, align 8
  store i64 %var_2_3087, i64* %var_2_1808, align 1
  %var_2_3093 = add i64 %var_2_856, 264
  store i64 %var_2_3093, i64* %PC, align 8
  %var_2_3102 = add i64 %var_2_3082, -88
  %var_2_3105 = inttoptr i64 %var_2_3102 to i64*
  %var_2_3106 = load i64, i64* %var_2_3105, align 8
  store i64 %var_2_3106, i64* %var_2_1808, align 1
  %var_2_3112 = add i64 %var_2_856, 276
  store i64 %var_2_3112, i64* %PC, align 8
  %var_2_3144 = add i64 %var_2_3082, -64
  %var_2_3147 = inttoptr i64 %var_2_3144 to i64*
  %var_2_3148 = load i64, i64* %var_2_3147, align 8
  store i64 %var_2_3148, i64* %var_2_1808, align 1
  %var_2_3154 = add i64 %var_2_856, 289
  store i64 %var_2_3154, i64* %PC, align 8
  %var_2_3163 = add i64 %var_2_3082, -72
  %var_2_3166 = inttoptr i64 %var_2_3163 to i64*
  %var_2_3167 = load i64, i64* %var_2_3166, align 8
  store i64 %var_2_3167, i64* %var_2_1808, align 1
  store i8 0, i8* %var_2_52, align 1
  %var_2_3298 = add i64 %var_2_856, 313
  store i64 %var_2_3298, i64* %PC, align 8
  %var_2_3300 = add i64 %var_2_3082, -24
  %var_2_3303 = inttoptr i64 %var_2_3300 to i64*
  %var_2_3304 = load i64, i64* %var_2_3303, align 8
  %var_2_3305 = add i64 %var_2_3082, -32
  %var_2_3306 = add i64 %var_2_856, 321
  store i64 %var_2_3306, i64* %PC, align 8
  %var_2_3307 = inttoptr i64 %var_2_3305 to i32*
  %var_2_3308 = load i32, i32* %var_2_3307, align 4
  %var_2_3309 = sext i32 %var_2_3308 to i64
  %var_2_3310 = shl nsw i64 %var_2_3309, 3
  %var_2_3311 = add i64 %var_2_3310, %var_2_3304
  %var_2_3312 = add i64 %var_2_856, 326
  store i64 %var_2_3312, i64* %PC, align 8
  %var_2_3313 = inttoptr i64 %var_2_3311 to i64*
  %var_2_3314 = load i64, i64* %var_2_3313, align 8
  store i64 %var_2_3314, i64* %var_2_1808, align 1
  %var_2_3323 = load i64, i64* %var_2_3303, align 8
  %var_2_3327 = load i32, i32* %var_2_3307, align 4
  %var_2_3328 = add i32 %var_2_3327, 1
  %var_2_3351 = sext i32 %var_2_3328 to i64
  %var_2_3352 = shl nsw i64 %var_2_3351, 3
  %var_2_3353 = add i64 %var_2_3352, %var_2_3323
  %var_2_3355 = inttoptr i64 %var_2_3353 to i64*
  %var_2_3356 = load i64, i64* %var_2_3355, align 8
  %var_2_3358 = xor i64 %var_2_3356, %var_2_3067
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_3358, i64* %var_2_1808, align 1
  %var_2_3377 = load i64, i64* %var_2_3303, align 8
  %var_2_3378 = add i64 %var_2_3082, -40
  %var_2_3379 = add i64 %var_2_856, 334
  store i64 %var_2_3379, i64* %PC, align 8
  %var_2_3380 = inttoptr i64 %var_2_3378 to i32*
  %var_2_3381 = load i32, i32* %var_2_3380, align 4
  %var_2_3382 = sext i32 %var_2_3381 to i64
  %var_2_3383 = shl nsw i64 %var_2_3382, 3
  %var_2_3384 = add i64 %var_2_3383, %var_2_3377
  %var_2_3385 = add i64 %var_2_856, 339
  store i64 %var_2_3385, i64* %PC, align 8
  %var_2_3386 = inttoptr i64 %var_2_3384 to i64*
  %var_2_3387 = load i64, i64* %var_2_3386, align 8
  store i64 %var_2_3387, i64* %var_2_1808, align 1
  %var_2_3396 = load i64, i64* %var_2_3303, align 8
  %var_2_3400 = load i32, i32* %var_2_3380, align 4
  %var_2_3401 = add i32 %var_2_3400, 1
  %var_2_3424 = sext i32 %var_2_3401 to i64
  %var_2_3425 = shl nsw i64 %var_2_3424, 3
  %var_2_3426 = add i64 %var_2_3425, %var_2_3396
  %var_2_3428 = inttoptr i64 %var_2_3426 to i64*
  %var_2_3429 = load i64, i64* %var_2_3428, align 8
  %var_2_3431 = xor i64 %var_2_3429, %var_2_3067
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_3431, i64* %var_2_1808, align 1
  %var_2_3450 = load i64, i64* %var_2_3086, align 8
  store i64 %var_2_3450, i64* %var_2_1808, align 1
  %var_2_3456 = add i64 %var_2_856, 352
  store i64 %var_2_3456, i64* %PC, align 8
  %var_2_3469 = load i64, i64* %var_2_3105, align 8
  store i64 %var_2_3469, i64* %var_2_1808, align 1
  %var_2_3475 = add i64 %var_2_856, 364
  store i64 %var_2_3475, i64* %PC, align 8
  %var_2_3511 = load i64, i64* %var_2_3147, align 8
  store i64 %var_2_3511, i64* %var_2_1808, align 1
  %var_2_3517 = add i64 %var_2_856, 377
  store i64 %var_2_3517, i64* %PC, align 8
  %var_2_3530 = load i64, i64* %var_2_3166, align 8
  store i64 %var_2_3530, i64* %var_2_1808, align 1
  %var_2_3536 = add i64 %var_2_856, 389
  store i64 %var_2_3536, i64* %PC, align 8
  %var_2_3598 = add i64 %var_2_856, -504
  br label %block_401ccd

block_402409:                                     ; preds = %block_40222f
  %var_2_3661 = add i64 %var_2_1356, -24
  %var_2_3664 = inttoptr i64 %var_2_3661 to i64*
  %var_2_3665 = load i64, i64* %var_2_3664, align 8
  %var_2_3666 = add i64 %var_2_1356, -40
  %var_2_3668 = inttoptr i64 %var_2_3666 to i32*
  %var_2_3669 = load i32, i32* %var_2_3668, align 4
  %var_2_3670 = add i32 %var_2_3669, 1
  %var_2_3693 = sext i32 %var_2_3670 to i64
  %var_2_3694 = shl nsw i64 %var_2_3693, 3
  %var_2_3695 = add i64 %var_2_3694, %var_2_3665
  %var_2_3697 = inttoptr i64 %var_2_3695 to i64*
  %var_2_3698 = load i64, i64* %var_2_3697, align 8
  %var_2_3700 = xor i64 %var_2_3698, -9223372036854775808
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_3700, i64* %var_2_1698, align 1
  %var_2_3748 = load i64, i64* %var_2_3664, align 8
  %var_2_3752 = load i32, i32* %var_2_3668, align 4
  %var_2_3754 = add i64 %var_2_1356, -52
  %var_2_3755 = add i64 %var_2_1848, 40
  store i64 %var_2_3755, i64* %PC, align 8
  %var_2_3756 = inttoptr i64 %var_2_3754 to i32*
  %var_2_3757 = load i32, i32* %var_2_3756, align 4
  %var_2_3758 = add i32 %var_2_3752, 1
  %var_2_3760 = add i32 %var_2_3758, %var_2_3757
  %var_2_3782 = sext i32 %var_2_3760 to i64
  %var_2_3783 = shl nsw i64 %var_2_3782, 3
  %var_2_3784 = add i64 %var_2_3783, %var_2_3748
  %var_2_3786 = inttoptr i64 %var_2_3784 to i64*
  %var_2_3787 = load i64, i64* %var_2_3786, align 8
  %var_2_3789 = xor i64 %var_2_3787, -9223372036854775808
  store i8 0, i8* %var_2_52, align 1
  store i64 %var_2_3789, i64* %var_2_1698, align 1
  %var_2_1933 = load i32, i32* %var_2_1820, align 4
  %var_2_1935 = add i64 %var_2_1356, -48
  %var_2_1937 = inttoptr i64 %var_2_1935 to i32*
  %var_2_1938 = load i32, i32* %var_2_1937, align 4
  %var_2_1939 = sub i32 %var_2_1933, %var_2_1938
  %var_2_1954 = lshr i32 %var_2_1939, 31
  %var_2_1956 = lshr i32 %var_2_1933, 31
  %var_2_1957 = lshr i32 %var_2_1938, 31
  %var_2_1958 = xor i32 %var_2_1957, %var_2_1956
  %var_2_1959 = xor i32 %var_2_1954, %var_2_1956
  %var_2_1960 = add nuw nsw i32 %var_2_1959, %var_2_1958
  %var_2_1961 = icmp eq i32 %var_2_1960, 2
  %var_2_1963 = icmp ne i32 %var_2_1954, 0
  %var_2_1964 = xor i1 %var_2_1963, %var_2_1961
  br i1 %var_2_1964, label %block_402228, label %block_40221c.block_4024a2.loopexit9_crit_edge
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400840_frame_dummy(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_400840:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  store i64 %7, i64* %5, align 8, !tbaa !2428
  %9 = load i64, i64* %PC, align 8
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = load i64, i64* %8, align 8
  store i64 %11, i64* %RBP, align 8, !tbaa !2428
  store i64 %6, i64* %5, align 8, !tbaa !2428
  %12 = add i64 %9, -113
  store i64 %12, i64* %PC, align 8, !tbaa !2428
  %13 = tail call %struct.Memory* @sub_4007d0_register_tm_clones(%struct.State* nonnull %0, i64 %12, %struct.Memory* %2)
  ret %struct.Memory* %13
}

; Function Attrs: noinline norecurse nounwind
define %struct.Memory* @sub_400790__dl_relocate_static_pie(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #9 {
block_400790:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = add i64 %1, 2
  store i64 %3, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !2428
  %6 = inttoptr i64 %5 to i64*
  %7 = load i64, i64* %6, align 8
  store i64 %7, i64* %PC, align 8, !tbaa !2428
  %8 = add i64 %5, 8
  store i64 %8, i64* %4, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_401060_cdft(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone) local_unnamed_addr #8 {
block_401060:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %4 to i32*
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -40
  store i64 %11, i64* %RSP, align 8, !tbaa !2428
  %12 = icmp ult i64 %8, 32
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1, !tbaa !2432
  %15 = trunc i64 %11 to i32
  %16 = and i32 %15, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16) #11
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1, !tbaa !2446
  %22 = xor i64 %8, %11
  %23 = lshr i64 %22, 4
  %24 = trunc i64 %23 to i8
  %25 = and i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %25, i8* %26, align 1, !tbaa !2447
  %27 = icmp eq i64 %11, 0
  %28 = zext i1 %27 to i8
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %28, i8* %29, align 1, !tbaa !2448
  %30 = lshr i64 %11, 63
  %31 = trunc i64 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %31, i8* %32, align 1, !tbaa !2449
  %33 = lshr i64 %8, 63
  %34 = xor i64 %30, %33
  %35 = add nuw nsw i64 %34, %33
  %36 = icmp eq i64 %35, 2
  %37 = zext i1 %36 to i8
  %38 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %37, i8* %38, align 1, !tbaa !2450
  %39 = add i64 %7, -12
  %40 = load i32, i32* %EDI, align 4
  %41 = add i64 %10, 10
  store i64 %41, i64* %PC, align 8
  %42 = inttoptr i64 %39 to i32*
  store i32 %40, i32* %42, align 4
  %43 = load i64, i64* %RBP, align 8
  %44 = add i64 %43, -8
  %45 = load i32, i32* %ESI, align 4
  %46 = load i64, i64* %PC, align 8
  %47 = add i64 %46, 3
  store i64 %47, i64* %PC, align 8
  %48 = inttoptr i64 %44 to i32*
  store i32 %45, i32* %48, align 4
  %49 = load i64, i64* %RBP, align 8
  %50 = add i64 %49, -16
  %51 = load i64, i64* %RDX, align 8
  %52 = load i64, i64* %PC, align 8
  %53 = add i64 %52, 4
  store i64 %53, i64* %PC, align 8
  %54 = inttoptr i64 %50 to i64*
  store i64 %51, i64* %54, align 8
  %55 = load i64, i64* %RBP, align 8
  %56 = add i64 %55, -24
  %57 = load i64, i64* %RCX, align 8
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 4
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %56 to i64*
  store i64 %57, i64* %60, align 8
  %61 = load i64, i64* %RBP, align 8
  %62 = add i64 %61, -32
  %63 = load i64, i64* %R8, align 8
  %64 = load i64, i64* %PC, align 8
  %65 = add i64 %64, 4
  store i64 %65, i64* %PC, align 8
  %66 = inttoptr i64 %62 to i64*
  store i64 %63, i64* %66, align 8
  %67 = load i64, i64* %RBP, align 8
  %68 = add i64 %67, -4
  %69 = load i64, i64* %PC, align 8
  %70 = add i64 %69, 4
  store i64 %70, i64* %PC, align 8
  %71 = inttoptr i64 %68 to i32*
  %72 = load i32, i32* %71, align 4
  %73 = add i32 %72, -4
  %74 = icmp ult i32 %72, 4
  %75 = zext i1 %74 to i8
  store i8 %75, i8* %14, align 1, !tbaa !2432
  %76 = and i32 %73, 255
  %77 = tail call i32 @llvm.ctpop.i32(i32 %76) #11
  %78 = trunc i32 %77 to i8
  %79 = and i8 %78, 1
  %80 = xor i8 %79, 1
  store i8 %80, i8* %21, align 1, !tbaa !2446
  %81 = xor i32 %73, %72
  %82 = lshr i32 %81, 4
  %83 = trunc i32 %82 to i8
  %84 = and i8 %83, 1
  store i8 %84, i8* %26, align 1, !tbaa !2447
  %85 = icmp eq i32 %73, 0
  %86 = zext i1 %85 to i8
  store i8 %86, i8* %29, align 1, !tbaa !2448
  %87 = lshr i32 %73, 31
  %88 = trunc i32 %87 to i8
  store i8 %88, i8* %32, align 1, !tbaa !2449
  %89 = lshr i32 %72, 31
  %90 = xor i32 %87, %89
  %91 = add nuw nsw i32 %90, %89
  %92 = icmp eq i32 %91, 2
  %93 = zext i1 %92 to i8
  store i8 %93, i8* %38, align 1, !tbaa !2450
  %94 = icmp ne i8 %88, 0
  %95 = xor i1 %94, %92
  %96 = or i1 %85, %95
  %.v8 = select i1 %96, i64 94, i64 10
  %97 = add i64 %.v8, %69
  store i64 %97, i64* %PC, align 8, !tbaa !2428
  br i1 %96, label %block_4010d8, label %block_401084

block_4010d8:                                     ; preds = %block_401060
  %98 = add i64 %97, 4
  store i64 %98, i64* %PC, align 8
  %99 = load i32, i32* %71, align 4
  %100 = add i32 %99, -4
  %101 = icmp ult i32 %99, 4
  %102 = zext i1 %101 to i8
  store i8 %102, i8* %14, align 1, !tbaa !2432
  %103 = and i32 %100, 255
  %104 = tail call i32 @llvm.ctpop.i32(i32 %103) #11
  %105 = trunc i32 %104 to i8
  %106 = and i8 %105, 1
  %107 = xor i8 %106, 1
  store i8 %107, i8* %21, align 1, !tbaa !2446
  %108 = xor i32 %100, %99
  %109 = lshr i32 %108, 4
  %110 = trunc i32 %109 to i8
  %111 = and i8 %110, 1
  store i8 %111, i8* %26, align 1, !tbaa !2447
  %112 = icmp eq i32 %100, 0
  %113 = zext i1 %112 to i8
  store i8 %113, i8* %29, align 1, !tbaa !2448
  %114 = lshr i32 %100, 31
  %115 = trunc i32 %114 to i8
  store i8 %115, i8* %32, align 1, !tbaa !2449
  %116 = lshr i32 %99, 31
  %117 = xor i32 %114, %116
  %118 = add nuw nsw i32 %117, %116
  %119 = icmp eq i32 %118, 2
  %120 = zext i1 %119 to i8
  store i8 %120, i8* %38, align 1, !tbaa !2450
  %.v9 = select i1 %112, i64 10, i64 26
  %121 = add i64 %.v9, %97
  store i64 %121, i64* %PC, align 8, !tbaa !2428
  br i1 %112, label %block_4010e2, label %block_4010f7

block_4010f7:                                     ; preds = %block_4010e2, %block_4010b3, %block_40108e, %block_4010d8
  %.sink5 = phi i64 [ 5, %block_4010e2 ], [ 5, %block_4010d8 ], [ 36, %block_4010b3 ], [ 36, %block_40108e ]
  %MEMORY.0 = phi %struct.Memory* [ %253, %block_4010e2 ], [ %2, %block_4010d8 ], [ %210, %block_4010b3 ], [ %181, %block_40108e ]
  %122 = load i64, i64* %PC, align 8
  %123 = add i64 %122, %.sink5
  %124 = load i64, i64* %RSP, align 8
  %125 = add i64 %124, 32
  store i64 %125, i64* %RSP, align 8, !tbaa !2428
  %126 = icmp ugt i64 %124, -33
  %127 = zext i1 %126 to i8
  store i8 %127, i8* %14, align 1, !tbaa !2432
  %128 = trunc i64 %125 to i32
  %129 = and i32 %128, 255
  %130 = tail call i32 @llvm.ctpop.i32(i32 %129) #11
  %131 = trunc i32 %130 to i8
  %132 = and i8 %131, 1
  %133 = xor i8 %132, 1
  store i8 %133, i8* %21, align 1, !tbaa !2446
  %134 = xor i64 %125, %124
  %135 = lshr i64 %134, 4
  %136 = trunc i64 %135 to i8
  %137 = and i8 %136, 1
  store i8 %137, i8* %26, align 1, !tbaa !2447
  %138 = icmp eq i64 %125, 0
  %139 = zext i1 %138 to i8
  store i8 %139, i8* %29, align 1, !tbaa !2448
  %140 = lshr i64 %125, 63
  %141 = trunc i64 %140 to i8
  store i8 %141, i8* %32, align 1, !tbaa !2449
  %142 = lshr i64 %124, 63
  %143 = xor i64 %140, %142
  %144 = add nuw nsw i64 %143, %140
  %145 = icmp eq i64 %144, 2
  %146 = zext i1 %145 to i8
  store i8 %146, i8* %38, align 1, !tbaa !2450
  %147 = add i64 %123, 5
  store i64 %147, i64* %PC, align 8
  %148 = add i64 %124, 40
  %149 = inttoptr i64 %125 to i64*
  %150 = load i64, i64* %149, align 8
  store i64 %150, i64* %RBP, align 8, !tbaa !2428
  store i64 %148, i64* %RSP, align 8, !tbaa !2428
  %151 = add i64 %123, 6
  store i64 %151, i64* %PC, align 8
  %152 = inttoptr i64 %148 to i64*
  %153 = load i64, i64* %152, align 8
  store i64 %153, i64* %PC, align 8, !tbaa !2428
  %154 = add i64 %124, 48
  store i64 %154, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_40108e:                                     ; preds = %block_401084
  %155 = add i64 %225, 354
  %156 = add i64 %225, 16
  %157 = load i64, i64* %RSP, align 8, !tbaa !2428
  %158 = add i64 %157, -8
  %159 = inttoptr i64 %158 to i64*
  store i64 %156, i64* %159, align 8
  store i64 %158, i64* %RSP, align 8, !tbaa !2428
  store i64 %155, i64* %PC, align 8, !tbaa !2428
  %160 = tail call %struct.Memory* @sub_4011f0_bitrv2_renamed_(%struct.State* nonnull %0, i64 %155, %struct.Memory* %2)
  %161 = load i64, i64* %RBP, align 8
  %162 = add i64 %161, -4
  %163 = load i64, i64* %PC, align 8
  %164 = add i64 %163, 3
  store i64 %164, i64* %PC, align 8
  %165 = inttoptr i64 %162 to i32*
  %166 = load i32, i32* %165, align 4
  %167 = zext i32 %166 to i64
  store i64 %167, i64* %RDI, align 8, !tbaa !2428
  %168 = add i64 %161, -16
  %169 = add i64 %163, 7
  store i64 %169, i64* %PC, align 8
  %170 = inttoptr i64 %168 to i64*
  %171 = load i64, i64* %170, align 8
  store i64 %171, i64* %RSI, align 8, !tbaa !2428
  %172 = add i64 %161, -32
  %173 = add i64 %163, 11
  store i64 %173, i64* %PC, align 8
  %174 = inttoptr i64 %172 to i64*
  %175 = load i64, i64* %174, align 8
  store i64 %175, i64* %RDX, align 8, !tbaa !2428
  %176 = add i64 %163, 2002
  %177 = add i64 %163, 16
  %178 = load i64, i64* %RSP, align 8, !tbaa !2428
  %179 = add i64 %178, -8
  %180 = inttoptr i64 %179 to i64*
  store i64 %177, i64* %180, align 8
  store i64 %179, i64* %RSP, align 8, !tbaa !2428
  store i64 %176, i64* %PC, align 8, !tbaa !2428
  %181 = tail call %struct.Memory* @sub_401870_cftfsub_renamed_(%struct.State* nonnull %0, i64 %176, %struct.Memory* %160)
  %182 = load i64, i64* %PC, align 8
  %183 = add i64 %182, 37
  store i64 %183, i64* %PC, align 8, !tbaa !2428
  br label %block_4010f7

block_4010b3:                                     ; preds = %block_401084
  %184 = add i64 %225, 2909
  %185 = add i64 %225, 16
  %186 = load i64, i64* %RSP, align 8, !tbaa !2428
  %187 = add i64 %186, -8
  %188 = inttoptr i64 %187 to i64*
  store i64 %185, i64* %188, align 8
  store i64 %187, i64* %RSP, align 8, !tbaa !2428
  store i64 %184, i64* %PC, align 8, !tbaa !2428
  %189 = tail call %struct.Memory* @sub_401c10_bitrv2conj_renamed_(%struct.State* nonnull %0, i64 %184, %struct.Memory* %2)
  %190 = load i64, i64* %RBP, align 8
  %191 = add i64 %190, -4
  %192 = load i64, i64* %PC, align 8
  %193 = add i64 %192, 3
  store i64 %193, i64* %PC, align 8
  %194 = inttoptr i64 %191 to i32*
  %195 = load i32, i32* %194, align 4
  %196 = zext i32 %195 to i64
  store i64 %196, i64* %RDI, align 8, !tbaa !2428
  %197 = add i64 %190, -16
  %198 = add i64 %192, 7
  store i64 %198, i64* %PC, align 8
  %199 = inttoptr i64 %197 to i64*
  %200 = load i64, i64* %199, align 8
  store i64 %200, i64* %RSI, align 8, !tbaa !2428
  %201 = add i64 %190, -32
  %202 = add i64 %192, 11
  store i64 %202, i64* %PC, align 8
  %203 = inttoptr i64 %201 to i64*
  %204 = load i64, i64* %203, align 8
  store i64 %204, i64* %RDX, align 8, !tbaa !2428
  %205 = add i64 %192, 5101
  %206 = add i64 %192, 16
  %207 = load i64, i64* %RSP, align 8, !tbaa !2428
  %208 = add i64 %207, -8
  %209 = inttoptr i64 %208 to i64*
  store i64 %206, i64* %209, align 8
  store i64 %208, i64* %RSP, align 8, !tbaa !2428
  store i64 %205, i64* %PC, align 8, !tbaa !2428
  %210 = tail call %struct.Memory* @sub_4024b0_cftbsub_renamed_(%struct.State* nonnull %0, i64 %205, %struct.Memory* %189)
  br label %block_4010f7

block_401084:                                     ; preds = %block_401060
  %211 = add i64 %67, -8
  %212 = add i64 %97, 4
  store i64 %212, i64* %PC, align 8
  %213 = inttoptr i64 %211 to i32*
  %214 = load i32, i32* %213, align 4
  store i8 0, i8* %14, align 1, !tbaa !2432
  %215 = and i32 %214, 255
  %216 = tail call i32 @llvm.ctpop.i32(i32 %215) #11
  %217 = trunc i32 %216 to i8
  %218 = and i8 %217, 1
  %219 = xor i8 %218, 1
  store i8 %219, i8* %21, align 1, !tbaa !2446
  store i8 0, i8* %26, align 1, !tbaa !2447
  %220 = icmp eq i32 %214, 0
  %221 = zext i1 %220 to i8
  store i8 %221, i8* %29, align 1, !tbaa !2448
  %222 = lshr i32 %214, 31
  %223 = trunc i32 %222 to i8
  store i8 %223, i8* %32, align 1, !tbaa !2449
  store i8 0, i8* %38, align 1, !tbaa !2450
  %224 = icmp ne i8 %223, 0
  %.v = select i1 %224, i64 43, i64 6
  %225 = add i64 %.v, %212
  %226 = add i64 %225, 3
  store i64 %226, i64* %PC, align 8
  %227 = load i32, i32* %71, align 4
  %228 = zext i32 %227 to i64
  store i64 %228, i64* %RDI, align 8, !tbaa !2428
  %229 = add i64 %67, -24
  %230 = add i64 %225, 7
  store i64 %230, i64* %PC, align 8
  %231 = inttoptr i64 %229 to i64*
  %232 = load i64, i64* %231, align 8
  store i64 %232, i64* %RSI, align 8, !tbaa !2428
  %233 = add i64 %67, -16
  %234 = add i64 %225, 11
  store i64 %234, i64* %PC, align 8
  %235 = inttoptr i64 %233 to i64*
  %236 = load i64, i64* %235, align 8
  store i64 %236, i64* %RDX, align 8, !tbaa !2428
  br i1 %224, label %block_4010b3, label %block_40108e

block_4010e2:                                     ; preds = %block_4010d8
  %237 = add i64 %121, 3
  store i64 %237, i64* %PC, align 8
  %238 = load i32, i32* %71, align 4
  %239 = zext i32 %238 to i64
  store i64 %239, i64* %RDI, align 8, !tbaa !2428
  %240 = add i64 %67, -16
  %241 = add i64 %121, 7
  store i64 %241, i64* %PC, align 8
  %242 = inttoptr i64 %240 to i64*
  %243 = load i64, i64* %242, align 8
  store i64 %243, i64* %RSI, align 8, !tbaa !2428
  %244 = add i64 %67, -32
  %245 = add i64 %121, 11
  store i64 %245, i64* %PC, align 8
  %246 = inttoptr i64 %244 to i64*
  %247 = load i64, i64* %246, align 8
  store i64 %247, i64* %RDX, align 8, !tbaa !2428
  %248 = add i64 %121, 1934
  %249 = add i64 %121, 16
  %250 = load i64, i64* %RSP, align 8, !tbaa !2428
  %251 = add i64 %250, -8
  %252 = inttoptr i64 %251 to i64*
  store i64 %249, i64* %252, align 8
  store i64 %251, i64* %RSP, align 8, !tbaa !2428
  store i64 %248, i64* %PC, align 8, !tbaa !2428
  %253 = tail call %struct.Memory* @sub_401870_cftfsub_renamed_(%struct.State* nonnull %0, i64 %248, %struct.Memory* %2)
  br label %block_4010f7
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_4028a0_cft1st(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_4028a0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %7 = load i64, i64* %RBP, align 8
  %8 = add i64 %1, 1
  store i64 %8, i64* %PC, align 8
  %9 = load i64, i64* %RSP, align 8, !tbaa !2428
  %10 = add i64 %9, -8
  %11 = inttoptr i64 %10 to i64*
  store i64 %7, i64* %11, align 8
  %12 = load i64, i64* %PC, align 8
  store i64 %10, i64* %RBP, align 8, !tbaa !2428
  %13 = add i64 %9, -32
  store i64 %13, i64* %RSP, align 8, !tbaa !2428
  %14 = icmp ult i64 %10, 24
  %15 = zext i1 %14 to i8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %15, i8* %16, align 1, !tbaa !2432
  %17 = trunc i64 %13 to i32
  %18 = and i32 %17, 255
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18) #11
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %22, i8* %23, align 1, !tbaa !2446
  %24 = xor i64 %10, 16
  %25 = xor i64 %24, %13
  %26 = lshr i64 %25, 4
  %27 = trunc i64 %26 to i8
  %28 = and i8 %27, 1
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %28, i8* %29, align 1, !tbaa !2447
  %30 = icmp eq i64 %13, 0
  %31 = zext i1 %30 to i8
  %32 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %31, i8* %32, align 1, !tbaa !2448
  %33 = lshr i64 %13, 63
  %34 = trunc i64 %33 to i8
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %34, i8* %35, align 1, !tbaa !2449
  %36 = lshr i64 %10, 63
  %37 = xor i64 %33, %36
  %38 = add nuw nsw i64 %37, %36
  %39 = icmp eq i64 %38, 2
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %40, i8* %41, align 1, !tbaa !2450
  %42 = add i64 %9, -12
  %43 = load i32, i32* %EDI, align 4
  %44 = add i64 %12, 10
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %42 to i32*
  store i32 %43, i32* %45, align 4
  %46 = load i64, i64* %RBP, align 8
  %47 = add i64 %46, -16
  %48 = load i64, i64* %RSI, align 8
  %49 = load i64, i64* %PC, align 8
  %50 = add i64 %49, 4
  store i64 %50, i64* %PC, align 8
  %51 = inttoptr i64 %47 to i64*
  store i64 %48, i64* %51, align 8
  %52 = load i64, i64* %RBP, align 8
  %53 = add i64 %52, -24
  %54 = load i64, i64* %RDX, align 8
  %55 = load i64, i64* %PC, align 8
  %56 = add i64 %55, 4
  store i64 %56, i64* %PC, align 8
  %57 = inttoptr i64 %53 to i64*
  store i64 %54, i64* %57, align 8
  %58 = load i64, i64* %RBP, align 8
  %59 = add i64 %58, -16
  %60 = load i64, i64* %PC, align 8
  %61 = add i64 %60, 4
  store i64 %61, i64* %PC, align 8
  %62 = inttoptr i64 %59 to i64*
  %63 = load i64, i64* %62, align 8
  store i64 %63, i64* %RDX, align 8, !tbaa !2428
  %64 = add i64 %60, 8
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %63 to i64*
  %66 = load i64, i64* %65, align 8
  %67 = bitcast [32 x %union.VectorReg]* %4 to double*
  %68 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %66, i64* %68, align 1, !tbaa !2451
  %69 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %70 = bitcast i64* %69 to double*
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %71 = add i64 %60, 12
  store i64 %71, i64* %PC, align 8
  %72 = load i64, i64* %62, align 8
  store i64 %72, i64* %RDX, align 8, !tbaa !2428
  %73 = add i64 %72, 16
  %74 = add i64 %60, 17
  store i64 %74, i64* %PC, align 8
  %75 = bitcast i64 %66 to double
  %76 = inttoptr i64 %73 to double*
  %77 = load double, double* %76, align 8
  %78 = fadd double %75, %77
  store double %78, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %79 = add i64 %58, -96
  %80 = add i64 %60, 22
  store i64 %80, i64* %PC, align 8
  %81 = inttoptr i64 %79 to double*
  store double %78, double* %81, align 8
  %82 = load i64, i64* %RBP, align 8
  %83 = add i64 %82, -16
  %84 = load i64, i64* %PC, align 8
  %85 = add i64 %84, 4
  store i64 %85, i64* %PC, align 8
  %86 = inttoptr i64 %83 to i64*
  %87 = load i64, i64* %86, align 8
  store i64 %87, i64* %RDX, align 8, !tbaa !2428
  %88 = add i64 %87, 8
  %89 = add i64 %84, 9
  store i64 %89, i64* %PC, align 8
  %90 = inttoptr i64 %88 to i64*
  %91 = load i64, i64* %90, align 8
  store i64 %91, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %92 = add i64 %84, 13
  store i64 %92, i64* %PC, align 8
  %93 = load i64, i64* %86, align 8
  store i64 %93, i64* %RDX, align 8, !tbaa !2428
  %94 = add i64 %93, 24
  %95 = add i64 %84, 18
  store i64 %95, i64* %PC, align 8
  %96 = bitcast i64 %91 to double
  %97 = inttoptr i64 %94 to double*
  %98 = load double, double* %97, align 8
  %99 = fadd double %96, %98
  store double %99, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %100 = add i64 %82, -104
  %101 = add i64 %84, 23
  store i64 %101, i64* %PC, align 8
  %102 = inttoptr i64 %100 to double*
  store double %99, double* %102, align 8
  %103 = load i64, i64* %RBP, align 8
  %104 = add i64 %103, -16
  %105 = load i64, i64* %PC, align 8
  %106 = add i64 %105, 4
  store i64 %106, i64* %PC, align 8
  %107 = inttoptr i64 %104 to i64*
  %108 = load i64, i64* %107, align 8
  store i64 %108, i64* %RDX, align 8, !tbaa !2428
  %109 = add i64 %105, 8
  store i64 %109, i64* %PC, align 8
  %110 = inttoptr i64 %108 to i64*
  %111 = load i64, i64* %110, align 8
  store i64 %111, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %112 = add i64 %105, 12
  store i64 %112, i64* %PC, align 8
  %113 = load i64, i64* %107, align 8
  store i64 %113, i64* %RDX, align 8, !tbaa !2428
  %114 = add i64 %113, 16
  %115 = add i64 %105, 17
  store i64 %115, i64* %PC, align 8
  %116 = bitcast i64 %111 to double
  %117 = inttoptr i64 %114 to double*
  %118 = load double, double* %117, align 8
  %119 = fsub double %116, %118
  store double %119, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %120 = add i64 %103, -112
  %121 = add i64 %105, 22
  store i64 %121, i64* %PC, align 8
  %122 = inttoptr i64 %120 to double*
  store double %119, double* %122, align 8
  %123 = load i64, i64* %RBP, align 8
  %124 = add i64 %123, -16
  %125 = load i64, i64* %PC, align 8
  %126 = add i64 %125, 4
  store i64 %126, i64* %PC, align 8
  %127 = inttoptr i64 %124 to i64*
  %128 = load i64, i64* %127, align 8
  store i64 %128, i64* %RDX, align 8, !tbaa !2428
  %129 = add i64 %128, 8
  %130 = add i64 %125, 9
  store i64 %130, i64* %PC, align 8
  %131 = inttoptr i64 %129 to i64*
  %132 = load i64, i64* %131, align 8
  store i64 %132, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %133 = add i64 %125, 13
  store i64 %133, i64* %PC, align 8
  %134 = load i64, i64* %127, align 8
  store i64 %134, i64* %RDX, align 8, !tbaa !2428
  %135 = add i64 %134, 24
  %136 = add i64 %125, 18
  store i64 %136, i64* %PC, align 8
  %137 = bitcast i64 %132 to double
  %138 = inttoptr i64 %135 to double*
  %139 = load double, double* %138, align 8
  %140 = fsub double %137, %139
  store double %140, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %141 = add i64 %123, -120
  %142 = add i64 %125, 23
  store i64 %142, i64* %PC, align 8
  %143 = inttoptr i64 %141 to double*
  store double %140, double* %143, align 8
  %144 = load i64, i64* %RBP, align 8
  %145 = add i64 %144, -16
  %146 = load i64, i64* %PC, align 8
  %147 = add i64 %146, 4
  store i64 %147, i64* %PC, align 8
  %148 = inttoptr i64 %145 to i64*
  %149 = load i64, i64* %148, align 8
  store i64 %149, i64* %RDX, align 8, !tbaa !2428
  %150 = add i64 %149, 32
  %151 = add i64 %146, 9
  store i64 %151, i64* %PC, align 8
  %152 = inttoptr i64 %150 to i64*
  %153 = load i64, i64* %152, align 8
  store i64 %153, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %154 = add i64 %146, 13
  store i64 %154, i64* %PC, align 8
  %155 = load i64, i64* %148, align 8
  store i64 %155, i64* %RDX, align 8, !tbaa !2428
  %156 = add i64 %155, 48
  %157 = add i64 %146, 18
  store i64 %157, i64* %PC, align 8
  %158 = bitcast i64 %153 to double
  %159 = inttoptr i64 %156 to double*
  %160 = load double, double* %159, align 8
  %161 = fadd double %158, %160
  store double %161, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %162 = add i64 %144, -128
  %163 = add i64 %146, 23
  store i64 %163, i64* %PC, align 8
  %164 = inttoptr i64 %162 to double*
  store double %161, double* %164, align 8
  %165 = load i64, i64* %RBP, align 8
  %166 = add i64 %165, -16
  %167 = load i64, i64* %PC, align 8
  %168 = add i64 %167, 4
  store i64 %168, i64* %PC, align 8
  %169 = inttoptr i64 %166 to i64*
  %170 = load i64, i64* %169, align 8
  store i64 %170, i64* %RDX, align 8, !tbaa !2428
  %171 = add i64 %170, 40
  %172 = add i64 %167, 9
  store i64 %172, i64* %PC, align 8
  %173 = inttoptr i64 %171 to i64*
  %174 = load i64, i64* %173, align 8
  store i64 %174, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %175 = add i64 %167, 13
  store i64 %175, i64* %PC, align 8
  %176 = load i64, i64* %169, align 8
  store i64 %176, i64* %RDX, align 8, !tbaa !2428
  %177 = add i64 %176, 56
  %178 = add i64 %167, 18
  store i64 %178, i64* %PC, align 8
  %179 = bitcast i64 %174 to double
  %180 = inttoptr i64 %177 to double*
  %181 = load double, double* %180, align 8
  %182 = fadd double %179, %181
  store double %182, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %183 = add i64 %165, -136
  %184 = add i64 %167, 26
  store i64 %184, i64* %PC, align 8
  %185 = inttoptr i64 %183 to double*
  store double %182, double* %185, align 8
  %186 = load i64, i64* %RBP, align 8
  %187 = add i64 %186, -16
  %188 = load i64, i64* %PC, align 8
  %189 = add i64 %188, 4
  store i64 %189, i64* %PC, align 8
  %190 = inttoptr i64 %187 to i64*
  %191 = load i64, i64* %190, align 8
  store i64 %191, i64* %RDX, align 8, !tbaa !2428
  %192 = add i64 %191, 32
  %193 = add i64 %188, 9
  store i64 %193, i64* %PC, align 8
  %194 = inttoptr i64 %192 to i64*
  %195 = load i64, i64* %194, align 8
  store i64 %195, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %196 = add i64 %188, 13
  store i64 %196, i64* %PC, align 8
  %197 = load i64, i64* %190, align 8
  store i64 %197, i64* %RDX, align 8, !tbaa !2428
  %198 = add i64 %197, 48
  %199 = add i64 %188, 18
  store i64 %199, i64* %PC, align 8
  %200 = bitcast i64 %195 to double
  %201 = inttoptr i64 %198 to double*
  %202 = load double, double* %201, align 8
  %203 = fsub double %200, %202
  store double %203, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %204 = add i64 %186, -144
  %205 = add i64 %188, 26
  store i64 %205, i64* %PC, align 8
  %206 = inttoptr i64 %204 to double*
  store double %203, double* %206, align 8
  %207 = load i64, i64* %RBP, align 8
  %208 = add i64 %207, -16
  %209 = load i64, i64* %PC, align 8
  %210 = add i64 %209, 4
  store i64 %210, i64* %PC, align 8
  %211 = inttoptr i64 %208 to i64*
  %212 = load i64, i64* %211, align 8
  store i64 %212, i64* %RDX, align 8, !tbaa !2428
  %213 = add i64 %212, 40
  %214 = add i64 %209, 9
  store i64 %214, i64* %PC, align 8
  %215 = inttoptr i64 %213 to i64*
  %216 = load i64, i64* %215, align 8
  store i64 %216, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %217 = add i64 %209, 13
  store i64 %217, i64* %PC, align 8
  %218 = load i64, i64* %211, align 8
  store i64 %218, i64* %RDX, align 8, !tbaa !2428
  %219 = add i64 %218, 56
  %220 = add i64 %209, 18
  store i64 %220, i64* %PC, align 8
  %221 = bitcast i64 %216 to double
  %222 = inttoptr i64 %219 to double*
  %223 = load double, double* %222, align 8
  %224 = fsub double %221, %223
  store double %224, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %225 = add i64 %207, -152
  %226 = add i64 %209, 26
  store i64 %226, i64* %PC, align 8
  %227 = inttoptr i64 %225 to double*
  store double %224, double* %227, align 8
  %228 = load i64, i64* %RBP, align 8
  %229 = add i64 %228, -96
  %230 = load i64, i64* %PC, align 8
  %231 = add i64 %230, 5
  store i64 %231, i64* %PC, align 8
  %232 = inttoptr i64 %229 to i64*
  %233 = load i64, i64* %232, align 8
  store i64 %233, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %234 = add i64 %228, -128
  %235 = add i64 %230, 10
  store i64 %235, i64* %PC, align 8
  %236 = bitcast i64 %233 to double
  %237 = inttoptr i64 %234 to double*
  %238 = load double, double* %237, align 8
  %239 = fadd double %236, %238
  store double %239, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %240 = add i64 %228, -16
  %241 = add i64 %230, 14
  store i64 %241, i64* %PC, align 8
  %242 = inttoptr i64 %240 to i64*
  %243 = load i64, i64* %242, align 8
  store i64 %243, i64* %RDX, align 8, !tbaa !2428
  %244 = add i64 %230, 18
  store i64 %244, i64* %PC, align 8
  %245 = inttoptr i64 %243 to double*
  store double %239, double* %245, align 8
  %246 = load i64, i64* %RBP, align 8
  %247 = add i64 %246, -104
  %248 = load i64, i64* %PC, align 8
  %249 = add i64 %248, 5
  store i64 %249, i64* %PC, align 8
  %250 = inttoptr i64 %247 to i64*
  %251 = load i64, i64* %250, align 8
  store i64 %251, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %252 = add i64 %246, -136
  %253 = add i64 %248, 13
  store i64 %253, i64* %PC, align 8
  %254 = bitcast i64 %251 to double
  %255 = inttoptr i64 %252 to double*
  %256 = load double, double* %255, align 8
  %257 = fadd double %254, %256
  store double %257, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %258 = add i64 %246, -16
  %259 = add i64 %248, 17
  store i64 %259, i64* %PC, align 8
  %260 = inttoptr i64 %258 to i64*
  %261 = load i64, i64* %260, align 8
  store i64 %261, i64* %RDX, align 8, !tbaa !2428
  %262 = add i64 %261, 8
  %263 = add i64 %248, 22
  store i64 %263, i64* %PC, align 8
  %264 = inttoptr i64 %262 to double*
  store double %257, double* %264, align 8
  %265 = load i64, i64* %RBP, align 8
  %266 = add i64 %265, -96
  %267 = load i64, i64* %PC, align 8
  %268 = add i64 %267, 5
  store i64 %268, i64* %PC, align 8
  %269 = inttoptr i64 %266 to i64*
  %270 = load i64, i64* %269, align 8
  store i64 %270, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %271 = add i64 %265, -128
  %272 = add i64 %267, 10
  store i64 %272, i64* %PC, align 8
  %273 = bitcast i64 %270 to double
  %274 = inttoptr i64 %271 to double*
  %275 = load double, double* %274, align 8
  %276 = fsub double %273, %275
  store double %276, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %277 = add i64 %265, -16
  %278 = add i64 %267, 14
  store i64 %278, i64* %PC, align 8
  %279 = inttoptr i64 %277 to i64*
  %280 = load i64, i64* %279, align 8
  store i64 %280, i64* %RDX, align 8, !tbaa !2428
  %281 = add i64 %280, 32
  %282 = add i64 %267, 19
  store i64 %282, i64* %PC, align 8
  %283 = inttoptr i64 %281 to double*
  store double %276, double* %283, align 8
  %284 = load i64, i64* %RBP, align 8
  %285 = add i64 %284, -104
  %286 = load i64, i64* %PC, align 8
  %287 = add i64 %286, 5
  store i64 %287, i64* %PC, align 8
  %288 = inttoptr i64 %285 to i64*
  %289 = load i64, i64* %288, align 8
  store i64 %289, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %290 = add i64 %284, -136
  %291 = add i64 %286, 13
  store i64 %291, i64* %PC, align 8
  %292 = bitcast i64 %289 to double
  %293 = inttoptr i64 %290 to double*
  %294 = load double, double* %293, align 8
  %295 = fsub double %292, %294
  store double %295, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %296 = add i64 %284, -16
  %297 = add i64 %286, 17
  store i64 %297, i64* %PC, align 8
  %298 = inttoptr i64 %296 to i64*
  %299 = load i64, i64* %298, align 8
  store i64 %299, i64* %RDX, align 8, !tbaa !2428
  %300 = add i64 %299, 40
  %301 = add i64 %286, 22
  store i64 %301, i64* %PC, align 8
  %302 = inttoptr i64 %300 to double*
  store double %295, double* %302, align 8
  %303 = load i64, i64* %RBP, align 8
  %304 = add i64 %303, -112
  %305 = load i64, i64* %PC, align 8
  %306 = add i64 %305, 5
  store i64 %306, i64* %PC, align 8
  %307 = inttoptr i64 %304 to i64*
  %308 = load i64, i64* %307, align 8
  store i64 %308, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %309 = add i64 %303, -152
  %310 = add i64 %305, 13
  store i64 %310, i64* %PC, align 8
  %311 = bitcast i64 %308 to double
  %312 = inttoptr i64 %309 to double*
  %313 = load double, double* %312, align 8
  %314 = fsub double %311, %313
  store double %314, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %315 = add i64 %303, -16
  %316 = add i64 %305, 17
  store i64 %316, i64* %PC, align 8
  %317 = inttoptr i64 %315 to i64*
  %318 = load i64, i64* %317, align 8
  store i64 %318, i64* %RDX, align 8, !tbaa !2428
  %319 = add i64 %318, 16
  %320 = add i64 %305, 22
  store i64 %320, i64* %PC, align 8
  %321 = inttoptr i64 %319 to double*
  store double %314, double* %321, align 8
  %322 = load i64, i64* %RBP, align 8
  %323 = add i64 %322, -120
  %324 = load i64, i64* %PC, align 8
  %325 = add i64 %324, 5
  store i64 %325, i64* %PC, align 8
  %326 = inttoptr i64 %323 to i64*
  %327 = load i64, i64* %326, align 8
  store i64 %327, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %328 = add i64 %322, -144
  %329 = add i64 %324, 13
  store i64 %329, i64* %PC, align 8
  %330 = bitcast i64 %327 to double
  %331 = inttoptr i64 %328 to double*
  %332 = load double, double* %331, align 8
  %333 = fadd double %330, %332
  store double %333, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %334 = add i64 %322, -16
  %335 = add i64 %324, 17
  store i64 %335, i64* %PC, align 8
  %336 = inttoptr i64 %334 to i64*
  %337 = load i64, i64* %336, align 8
  store i64 %337, i64* %RDX, align 8, !tbaa !2428
  %338 = add i64 %337, 24
  %339 = add i64 %324, 22
  store i64 %339, i64* %PC, align 8
  %340 = inttoptr i64 %338 to double*
  store double %333, double* %340, align 8
  %341 = load i64, i64* %RBP, align 8
  %342 = add i64 %341, -112
  %343 = load i64, i64* %PC, align 8
  %344 = add i64 %343, 5
  store i64 %344, i64* %PC, align 8
  %345 = inttoptr i64 %342 to i64*
  %346 = load i64, i64* %345, align 8
  store i64 %346, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %347 = add i64 %341, -152
  %348 = add i64 %343, 13
  store i64 %348, i64* %PC, align 8
  %349 = bitcast i64 %346 to double
  %350 = inttoptr i64 %347 to double*
  %351 = load double, double* %350, align 8
  %352 = fadd double %349, %351
  store double %352, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %353 = add i64 %341, -16
  %354 = add i64 %343, 17
  store i64 %354, i64* %PC, align 8
  %355 = inttoptr i64 %353 to i64*
  %356 = load i64, i64* %355, align 8
  store i64 %356, i64* %RDX, align 8, !tbaa !2428
  %357 = add i64 %356, 48
  %358 = add i64 %343, 22
  store i64 %358, i64* %PC, align 8
  %359 = inttoptr i64 %357 to double*
  store double %352, double* %359, align 8
  %360 = load i64, i64* %RBP, align 8
  %361 = add i64 %360, -120
  %362 = load i64, i64* %PC, align 8
  %363 = add i64 %362, 5
  store i64 %363, i64* %PC, align 8
  %364 = inttoptr i64 %361 to i64*
  %365 = load i64, i64* %364, align 8
  store i64 %365, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %366 = add i64 %360, -144
  %367 = add i64 %362, 13
  store i64 %367, i64* %PC, align 8
  %368 = bitcast i64 %365 to double
  %369 = inttoptr i64 %366 to double*
  %370 = load double, double* %369, align 8
  %371 = fsub double %368, %370
  store double %371, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %372 = add i64 %360, -16
  %373 = add i64 %362, 17
  store i64 %373, i64* %PC, align 8
  %374 = inttoptr i64 %372 to i64*
  %375 = load i64, i64* %374, align 8
  store i64 %375, i64* %RDX, align 8, !tbaa !2428
  %376 = add i64 %375, 56
  %377 = add i64 %362, 22
  store i64 %377, i64* %PC, align 8
  %378 = inttoptr i64 %376 to double*
  store double %371, double* %378, align 8
  %379 = load i64, i64* %RBP, align 8
  %380 = add i64 %379, -24
  %381 = load i64, i64* %PC, align 8
  %382 = add i64 %381, 4
  store i64 %382, i64* %PC, align 8
  %383 = inttoptr i64 %380 to i64*
  %384 = load i64, i64* %383, align 8
  store i64 %384, i64* %RDX, align 8, !tbaa !2428
  %385 = add i64 %384, 16
  %386 = add i64 %381, 9
  store i64 %386, i64* %PC, align 8
  %387 = inttoptr i64 %385 to i64*
  %388 = load i64, i64* %387, align 8
  store i64 %388, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %389 = add i64 %379, -48
  %390 = add i64 %381, 14
  store i64 %390, i64* %PC, align 8
  %391 = inttoptr i64 %389 to i64*
  store i64 %388, i64* %391, align 8
  %392 = load i64, i64* %RBP, align 8
  %393 = add i64 %392, -16
  %394 = load i64, i64* %PC, align 8
  %395 = add i64 %394, 4
  store i64 %395, i64* %PC, align 8
  %396 = inttoptr i64 %393 to i64*
  %397 = load i64, i64* %396, align 8
  store i64 %397, i64* %RDX, align 8, !tbaa !2428
  %398 = add i64 %397, 64
  %399 = add i64 %394, 9
  store i64 %399, i64* %PC, align 8
  %400 = inttoptr i64 %398 to i64*
  %401 = load i64, i64* %400, align 8
  store i64 %401, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %402 = add i64 %394, 13
  store i64 %402, i64* %PC, align 8
  %403 = load i64, i64* %396, align 8
  store i64 %403, i64* %RDX, align 8, !tbaa !2428
  %404 = add i64 %403, 80
  %405 = add i64 %394, 18
  store i64 %405, i64* %PC, align 8
  %406 = bitcast i64 %401 to double
  %407 = inttoptr i64 %404 to double*
  %408 = load double, double* %407, align 8
  %409 = fadd double %406, %408
  store double %409, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %410 = add i64 %392, -96
  %411 = add i64 %394, 23
  store i64 %411, i64* %PC, align 8
  %412 = inttoptr i64 %410 to double*
  store double %409, double* %412, align 8
  %413 = load i64, i64* %RBP, align 8
  %414 = add i64 %413, -16
  %415 = load i64, i64* %PC, align 8
  %416 = add i64 %415, 4
  store i64 %416, i64* %PC, align 8
  %417 = inttoptr i64 %414 to i64*
  %418 = load i64, i64* %417, align 8
  store i64 %418, i64* %RDX, align 8, !tbaa !2428
  %419 = add i64 %418, 72
  %420 = add i64 %415, 9
  store i64 %420, i64* %PC, align 8
  %421 = inttoptr i64 %419 to i64*
  %422 = load i64, i64* %421, align 8
  store i64 %422, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %423 = add i64 %415, 13
  store i64 %423, i64* %PC, align 8
  %424 = load i64, i64* %417, align 8
  store i64 %424, i64* %RDX, align 8, !tbaa !2428
  %425 = add i64 %424, 88
  %426 = add i64 %415, 18
  store i64 %426, i64* %PC, align 8
  %427 = bitcast i64 %422 to double
  %428 = inttoptr i64 %425 to double*
  %429 = load double, double* %428, align 8
  %430 = fadd double %427, %429
  store double %430, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %431 = add i64 %413, -104
  %432 = add i64 %415, 23
  store i64 %432, i64* %PC, align 8
  %433 = inttoptr i64 %431 to double*
  store double %430, double* %433, align 8
  %434 = load i64, i64* %RBP, align 8
  %435 = add i64 %434, -16
  %436 = load i64, i64* %PC, align 8
  %437 = add i64 %436, 4
  store i64 %437, i64* %PC, align 8
  %438 = inttoptr i64 %435 to i64*
  %439 = load i64, i64* %438, align 8
  store i64 %439, i64* %RDX, align 8, !tbaa !2428
  %440 = add i64 %439, 64
  %441 = add i64 %436, 9
  store i64 %441, i64* %PC, align 8
  %442 = inttoptr i64 %440 to i64*
  %443 = load i64, i64* %442, align 8
  store i64 %443, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %444 = add i64 %436, 13
  store i64 %444, i64* %PC, align 8
  %445 = load i64, i64* %438, align 8
  store i64 %445, i64* %RDX, align 8, !tbaa !2428
  %446 = add i64 %445, 80
  %447 = add i64 %436, 18
  store i64 %447, i64* %PC, align 8
  %448 = bitcast i64 %443 to double
  %449 = inttoptr i64 %446 to double*
  %450 = load double, double* %449, align 8
  %451 = fsub double %448, %450
  store double %451, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %452 = add i64 %434, -112
  %453 = add i64 %436, 23
  store i64 %453, i64* %PC, align 8
  %454 = inttoptr i64 %452 to double*
  store double %451, double* %454, align 8
  %455 = load i64, i64* %RBP, align 8
  %456 = add i64 %455, -16
  %457 = load i64, i64* %PC, align 8
  %458 = add i64 %457, 4
  store i64 %458, i64* %PC, align 8
  %459 = inttoptr i64 %456 to i64*
  %460 = load i64, i64* %459, align 8
  store i64 %460, i64* %RDX, align 8, !tbaa !2428
  %461 = add i64 %460, 72
  %462 = add i64 %457, 9
  store i64 %462, i64* %PC, align 8
  %463 = inttoptr i64 %461 to i64*
  %464 = load i64, i64* %463, align 8
  store i64 %464, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %465 = add i64 %457, 13
  store i64 %465, i64* %PC, align 8
  %466 = load i64, i64* %459, align 8
  store i64 %466, i64* %RDX, align 8, !tbaa !2428
  %467 = add i64 %466, 88
  %468 = add i64 %457, 18
  store i64 %468, i64* %PC, align 8
  %469 = bitcast i64 %464 to double
  %470 = inttoptr i64 %467 to double*
  %471 = load double, double* %470, align 8
  %472 = fsub double %469, %471
  store double %472, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %473 = add i64 %455, -120
  %474 = add i64 %457, 23
  store i64 %474, i64* %PC, align 8
  %475 = inttoptr i64 %473 to double*
  store double %472, double* %475, align 8
  %476 = load i64, i64* %RBP, align 8
  %477 = add i64 %476, -16
  %478 = load i64, i64* %PC, align 8
  %479 = add i64 %478, 4
  store i64 %479, i64* %PC, align 8
  %480 = inttoptr i64 %477 to i64*
  %481 = load i64, i64* %480, align 8
  store i64 %481, i64* %RDX, align 8, !tbaa !2428
  %482 = add i64 %481, 96
  %483 = add i64 %478, 9
  store i64 %483, i64* %PC, align 8
  %484 = inttoptr i64 %482 to i64*
  %485 = load i64, i64* %484, align 8
  store i64 %485, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %486 = add i64 %478, 13
  store i64 %486, i64* %PC, align 8
  %487 = load i64, i64* %480, align 8
  store i64 %487, i64* %RDX, align 8, !tbaa !2428
  %488 = add i64 %487, 112
  %489 = add i64 %478, 18
  store i64 %489, i64* %PC, align 8
  %490 = bitcast i64 %485 to double
  %491 = inttoptr i64 %488 to double*
  %492 = load double, double* %491, align 8
  %493 = fadd double %490, %492
  store double %493, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %494 = add i64 %476, -128
  %495 = add i64 %478, 23
  store i64 %495, i64* %PC, align 8
  %496 = inttoptr i64 %494 to double*
  store double %493, double* %496, align 8
  %497 = load i64, i64* %RBP, align 8
  %498 = add i64 %497, -16
  %499 = load i64, i64* %PC, align 8
  %500 = add i64 %499, 4
  store i64 %500, i64* %PC, align 8
  %501 = inttoptr i64 %498 to i64*
  %502 = load i64, i64* %501, align 8
  store i64 %502, i64* %RDX, align 8, !tbaa !2428
  %503 = add i64 %502, 104
  %504 = add i64 %499, 9
  store i64 %504, i64* %PC, align 8
  %505 = inttoptr i64 %503 to i64*
  %506 = load i64, i64* %505, align 8
  store i64 %506, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %507 = add i64 %499, 13
  store i64 %507, i64* %PC, align 8
  %508 = load i64, i64* %501, align 8
  store i64 %508, i64* %RDX, align 8, !tbaa !2428
  %509 = add i64 %508, 120
  %510 = add i64 %499, 18
  store i64 %510, i64* %PC, align 8
  %511 = bitcast i64 %506 to double
  %512 = inttoptr i64 %509 to double*
  %513 = load double, double* %512, align 8
  %514 = fadd double %511, %513
  store double %514, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %515 = add i64 %497, -136
  %516 = add i64 %499, 26
  store i64 %516, i64* %PC, align 8
  %517 = inttoptr i64 %515 to double*
  store double %514, double* %517, align 8
  %518 = load i64, i64* %RBP, align 8
  %519 = add i64 %518, -16
  %520 = load i64, i64* %PC, align 8
  %521 = add i64 %520, 4
  store i64 %521, i64* %PC, align 8
  %522 = inttoptr i64 %519 to i64*
  %523 = load i64, i64* %522, align 8
  store i64 %523, i64* %RDX, align 8, !tbaa !2428
  %524 = add i64 %523, 96
  %525 = add i64 %520, 9
  store i64 %525, i64* %PC, align 8
  %526 = inttoptr i64 %524 to i64*
  %527 = load i64, i64* %526, align 8
  store i64 %527, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %528 = add i64 %520, 13
  store i64 %528, i64* %PC, align 8
  %529 = load i64, i64* %522, align 8
  store i64 %529, i64* %RDX, align 8, !tbaa !2428
  %530 = add i64 %529, 112
  %531 = add i64 %520, 18
  store i64 %531, i64* %PC, align 8
  %532 = bitcast i64 %527 to double
  %533 = inttoptr i64 %530 to double*
  %534 = load double, double* %533, align 8
  %535 = fsub double %532, %534
  store double %535, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %536 = add i64 %518, -144
  %537 = add i64 %520, 26
  store i64 %537, i64* %PC, align 8
  %538 = inttoptr i64 %536 to double*
  store double %535, double* %538, align 8
  %539 = load i64, i64* %RBP, align 8
  %540 = add i64 %539, -16
  %541 = load i64, i64* %PC, align 8
  %542 = add i64 %541, 4
  store i64 %542, i64* %PC, align 8
  %543 = inttoptr i64 %540 to i64*
  %544 = load i64, i64* %543, align 8
  store i64 %544, i64* %RDX, align 8, !tbaa !2428
  %545 = add i64 %544, 104
  %546 = add i64 %541, 9
  store i64 %546, i64* %PC, align 8
  %547 = inttoptr i64 %545 to i64*
  %548 = load i64, i64* %547, align 8
  store i64 %548, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %549 = add i64 %541, 13
  store i64 %549, i64* %PC, align 8
  %550 = load i64, i64* %543, align 8
  store i64 %550, i64* %RDX, align 8, !tbaa !2428
  %551 = add i64 %550, 120
  %552 = add i64 %541, 18
  store i64 %552, i64* %PC, align 8
  %553 = bitcast i64 %548 to double
  %554 = inttoptr i64 %551 to double*
  %555 = load double, double* %554, align 8
  %556 = fsub double %553, %555
  store double %556, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %557 = add i64 %539, -152
  %558 = add i64 %541, 26
  store i64 %558, i64* %PC, align 8
  %559 = inttoptr i64 %557 to double*
  store double %556, double* %559, align 8
  %560 = load i64, i64* %RBP, align 8
  %561 = add i64 %560, -96
  %562 = load i64, i64* %PC, align 8
  %563 = add i64 %562, 5
  store i64 %563, i64* %PC, align 8
  %564 = inttoptr i64 %561 to i64*
  %565 = load i64, i64* %564, align 8
  store i64 %565, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %566 = add i64 %560, -128
  %567 = add i64 %562, 10
  store i64 %567, i64* %PC, align 8
  %568 = bitcast i64 %565 to double
  %569 = inttoptr i64 %566 to double*
  %570 = load double, double* %569, align 8
  %571 = fadd double %568, %570
  store double %571, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %572 = add i64 %560, -16
  %573 = add i64 %562, 14
  store i64 %573, i64* %PC, align 8
  %574 = inttoptr i64 %572 to i64*
  %575 = load i64, i64* %574, align 8
  store i64 %575, i64* %RDX, align 8, !tbaa !2428
  %576 = add i64 %575, 64
  %577 = add i64 %562, 19
  store i64 %577, i64* %PC, align 8
  %578 = inttoptr i64 %576 to double*
  store double %571, double* %578, align 8
  %579 = load i64, i64* %RBP, align 8
  %580 = add i64 %579, -104
  %581 = load i64, i64* %PC, align 8
  %582 = add i64 %581, 5
  store i64 %582, i64* %PC, align 8
  %583 = inttoptr i64 %580 to i64*
  %584 = load i64, i64* %583, align 8
  store i64 %584, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %585 = add i64 %579, -136
  %586 = add i64 %581, 13
  store i64 %586, i64* %PC, align 8
  %587 = bitcast i64 %584 to double
  %588 = inttoptr i64 %585 to double*
  %589 = load double, double* %588, align 8
  %590 = fadd double %587, %589
  store double %590, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %591 = add i64 %579, -16
  %592 = add i64 %581, 17
  store i64 %592, i64* %PC, align 8
  %593 = inttoptr i64 %591 to i64*
  %594 = load i64, i64* %593, align 8
  store i64 %594, i64* %RDX, align 8, !tbaa !2428
  %595 = add i64 %594, 72
  %596 = add i64 %581, 22
  store i64 %596, i64* %PC, align 8
  %597 = inttoptr i64 %595 to double*
  store double %590, double* %597, align 8
  %598 = load i64, i64* %RBP, align 8
  %599 = add i64 %598, -136
  %600 = load i64, i64* %PC, align 8
  %601 = add i64 %600, 8
  store i64 %601, i64* %PC, align 8
  %602 = inttoptr i64 %599 to i64*
  %603 = load i64, i64* %602, align 8
  store i64 %603, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %604 = add i64 %598, -104
  %605 = add i64 %600, 13
  store i64 %605, i64* %PC, align 8
  %606 = bitcast i64 %603 to double
  %607 = inttoptr i64 %604 to double*
  %608 = load double, double* %607, align 8
  %609 = fsub double %606, %608
  store double %609, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %610 = add i64 %598, -16
  %611 = add i64 %600, 17
  store i64 %611, i64* %PC, align 8
  %612 = inttoptr i64 %610 to i64*
  %613 = load i64, i64* %612, align 8
  store i64 %613, i64* %RDX, align 8, !tbaa !2428
  %614 = add i64 %613, 96
  %615 = add i64 %600, 22
  store i64 %615, i64* %PC, align 8
  %616 = inttoptr i64 %614 to double*
  store double %609, double* %616, align 8
  %617 = load i64, i64* %RBP, align 8
  %618 = add i64 %617, -96
  %619 = load i64, i64* %PC, align 8
  %620 = add i64 %619, 5
  store i64 %620, i64* %PC, align 8
  %621 = inttoptr i64 %618 to i64*
  %622 = load i64, i64* %621, align 8
  store i64 %622, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %623 = add i64 %617, -128
  %624 = add i64 %619, 10
  store i64 %624, i64* %PC, align 8
  %625 = bitcast i64 %622 to double
  %626 = inttoptr i64 %623 to double*
  %627 = load double, double* %626, align 8
  %628 = fsub double %625, %627
  store double %628, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %629 = add i64 %617, -16
  %630 = add i64 %619, 14
  store i64 %630, i64* %PC, align 8
  %631 = inttoptr i64 %629 to i64*
  %632 = load i64, i64* %631, align 8
  store i64 %632, i64* %RDX, align 8, !tbaa !2428
  %633 = add i64 %632, 104
  %634 = add i64 %619, 19
  store i64 %634, i64* %PC, align 8
  %635 = inttoptr i64 %633 to double*
  store double %628, double* %635, align 8
  %636 = load i64, i64* %RBP, align 8
  %637 = add i64 %636, -112
  %638 = load i64, i64* %PC, align 8
  %639 = add i64 %638, 5
  store i64 %639, i64* %PC, align 8
  %640 = inttoptr i64 %637 to i64*
  %641 = load i64, i64* %640, align 8
  store i64 %641, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %642 = add i64 %636, -152
  %643 = add i64 %638, 13
  store i64 %643, i64* %PC, align 8
  %644 = bitcast i64 %641 to double
  %645 = inttoptr i64 %642 to double*
  %646 = load double, double* %645, align 8
  %647 = fsub double %644, %646
  store double %647, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %648 = add i64 %636, -96
  %649 = add i64 %638, 18
  store i64 %649, i64* %PC, align 8
  %650 = inttoptr i64 %648 to double*
  store double %647, double* %650, align 8
  %651 = load i64, i64* %RBP, align 8
  %652 = add i64 %651, -120
  %653 = load i64, i64* %PC, align 8
  %654 = add i64 %653, 5
  store i64 %654, i64* %PC, align 8
  %655 = inttoptr i64 %652 to i64*
  %656 = load i64, i64* %655, align 8
  store i64 %656, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %657 = add i64 %651, -144
  %658 = add i64 %653, 13
  store i64 %658, i64* %PC, align 8
  %659 = bitcast i64 %656 to double
  %660 = inttoptr i64 %657 to double*
  %661 = load double, double* %660, align 8
  %662 = fadd double %659, %661
  store double %662, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %663 = add i64 %651, -104
  %664 = add i64 %653, 18
  store i64 %664, i64* %PC, align 8
  %665 = inttoptr i64 %663 to double*
  store double %662, double* %665, align 8
  %666 = load i64, i64* %RBP, align 8
  %667 = add i64 %666, -48
  %668 = load i64, i64* %PC, align 8
  %669 = add i64 %668, 5
  store i64 %669, i64* %PC, align 8
  %670 = inttoptr i64 %667 to i64*
  %671 = load i64, i64* %670, align 8
  store i64 %671, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %672 = bitcast %union.VectorReg* %5 to i8*
  %673 = add i64 %666, -96
  %674 = add i64 %668, 10
  store i64 %674, i64* %PC, align 8
  %675 = inttoptr i64 %673 to i64*
  %676 = load i64, i64* %675, align 8
  %677 = bitcast %union.VectorReg* %5 to double*
  %678 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %5, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %676, i64* %678, align 1, !tbaa !2451
  %679 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %680 = bitcast i64* %679 to double*
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %681 = add i64 %666, -104
  %682 = add i64 %668, 15
  store i64 %682, i64* %PC, align 8
  %683 = bitcast i64 %676 to double
  %684 = inttoptr i64 %681 to double*
  %685 = load double, double* %684, align 8
  %686 = fsub double %683, %685
  store double %686, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %687 = bitcast i64 %671 to double
  %688 = fmul double %687, %686
  store double %688, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %689 = add i64 %666, -16
  %690 = add i64 %668, 23
  store i64 %690, i64* %PC, align 8
  %691 = inttoptr i64 %689 to i64*
  %692 = load i64, i64* %691, align 8
  store i64 %692, i64* %RDX, align 8, !tbaa !2428
  %693 = add i64 %692, 80
  %694 = add i64 %668, 28
  store i64 %694, i64* %PC, align 8
  %695 = inttoptr i64 %693 to double*
  store double %688, double* %695, align 8
  %696 = load i64, i64* %RBP, align 8
  %697 = add i64 %696, -48
  %698 = load i64, i64* %PC, align 8
  %699 = add i64 %698, 5
  store i64 %699, i64* %PC, align 8
  %700 = inttoptr i64 %697 to i64*
  %701 = load i64, i64* %700, align 8
  store i64 %701, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %702 = add i64 %696, -96
  %703 = add i64 %698, 10
  store i64 %703, i64* %PC, align 8
  %704 = inttoptr i64 %702 to i64*
  %705 = load i64, i64* %704, align 8
  store i64 %705, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %706 = add i64 %696, -104
  %707 = add i64 %698, 15
  store i64 %707, i64* %PC, align 8
  %708 = bitcast i64 %705 to double
  %709 = inttoptr i64 %706 to double*
  %710 = load double, double* %709, align 8
  %711 = fadd double %708, %710
  store double %711, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %712 = bitcast i64 %701 to double
  %713 = fmul double %712, %711
  store double %713, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %714 = add i64 %696, -16
  %715 = add i64 %698, 23
  store i64 %715, i64* %PC, align 8
  %716 = inttoptr i64 %714 to i64*
  %717 = load i64, i64* %716, align 8
  store i64 %717, i64* %RDX, align 8, !tbaa !2428
  %718 = add i64 %717, 88
  %719 = add i64 %698, 28
  store i64 %719, i64* %PC, align 8
  %720 = inttoptr i64 %718 to double*
  store double %713, double* %720, align 8
  %721 = load i64, i64* %RBP, align 8
  %722 = add i64 %721, -152
  %723 = load i64, i64* %PC, align 8
  %724 = add i64 %723, 8
  store i64 %724, i64* %PC, align 8
  %725 = inttoptr i64 %722 to i64*
  %726 = load i64, i64* %725, align 8
  store i64 %726, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %727 = add i64 %721, -112
  %728 = add i64 %723, 13
  store i64 %728, i64* %PC, align 8
  %729 = bitcast i64 %726 to double
  %730 = inttoptr i64 %727 to double*
  %731 = load double, double* %730, align 8
  %732 = fadd double %729, %731
  store double %732, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %733 = add i64 %721, -96
  %734 = add i64 %723, 18
  store i64 %734, i64* %PC, align 8
  %735 = inttoptr i64 %733 to double*
  store double %732, double* %735, align 8
  %736 = load i64, i64* %RBP, align 8
  %737 = add i64 %736, -144
  %738 = load i64, i64* %PC, align 8
  %739 = add i64 %738, 8
  store i64 %739, i64* %PC, align 8
  %740 = inttoptr i64 %737 to i64*
  %741 = load i64, i64* %740, align 8
  store i64 %741, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %742 = add i64 %736, -120
  %743 = add i64 %738, 13
  store i64 %743, i64* %PC, align 8
  %744 = bitcast i64 %741 to double
  %745 = inttoptr i64 %742 to double*
  %746 = load double, double* %745, align 8
  %747 = fsub double %744, %746
  store double %747, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %748 = add i64 %736, -104
  %749 = add i64 %738, 18
  store i64 %749, i64* %PC, align 8
  %750 = inttoptr i64 %748 to double*
  store double %747, double* %750, align 8
  %751 = load i64, i64* %RBP, align 8
  %752 = add i64 %751, -48
  %753 = load i64, i64* %PC, align 8
  %754 = add i64 %753, 5
  store i64 %754, i64* %PC, align 8
  %755 = inttoptr i64 %752 to i64*
  %756 = load i64, i64* %755, align 8
  store i64 %756, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %757 = add i64 %751, -104
  %758 = add i64 %753, 10
  store i64 %758, i64* %PC, align 8
  %759 = inttoptr i64 %757 to i64*
  %760 = load i64, i64* %759, align 8
  store i64 %760, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %761 = add i64 %751, -96
  %762 = add i64 %753, 15
  store i64 %762, i64* %PC, align 8
  %763 = bitcast i64 %760 to double
  %764 = inttoptr i64 %761 to double*
  %765 = load double, double* %764, align 8
  %766 = fsub double %763, %765
  store double %766, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %767 = bitcast i64 %756 to double
  %768 = fmul double %767, %766
  store double %768, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %769 = add i64 %751, -16
  %770 = add i64 %753, 23
  store i64 %770, i64* %PC, align 8
  %771 = inttoptr i64 %769 to i64*
  %772 = load i64, i64* %771, align 8
  store i64 %772, i64* %RDX, align 8, !tbaa !2428
  %773 = add i64 %772, 112
  %774 = add i64 %753, 28
  store i64 %774, i64* %PC, align 8
  %775 = inttoptr i64 %773 to double*
  store double %768, double* %775, align 8
  %776 = load i64, i64* %RBP, align 8
  %777 = add i64 %776, -48
  %778 = load i64, i64* %PC, align 8
  %779 = add i64 %778, 5
  store i64 %779, i64* %PC, align 8
  %780 = inttoptr i64 %777 to i64*
  %781 = load i64, i64* %780, align 8
  store i64 %781, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %782 = add i64 %776, -104
  %783 = add i64 %778, 10
  store i64 %783, i64* %PC, align 8
  %784 = inttoptr i64 %782 to i64*
  %785 = load i64, i64* %784, align 8
  store i64 %785, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %786 = add i64 %776, -96
  %787 = add i64 %778, 15
  store i64 %787, i64* %PC, align 8
  %788 = bitcast i64 %785 to double
  %789 = inttoptr i64 %786 to double*
  %790 = load double, double* %789, align 8
  %791 = fadd double %788, %790
  store double %791, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %792 = bitcast i64 %781 to double
  %793 = fmul double %792, %791
  store double %793, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %794 = add i64 %776, -16
  %795 = add i64 %778, 23
  store i64 %795, i64* %PC, align 8
  %796 = inttoptr i64 %794 to i64*
  %797 = load i64, i64* %796, align 8
  store i64 %797, i64* %RDX, align 8, !tbaa !2428
  %798 = add i64 %797, 120
  %799 = add i64 %778, 28
  store i64 %799, i64* %PC, align 8
  %800 = inttoptr i64 %798 to double*
  store double %793, double* %800, align 8
  %801 = load i64, i64* %RBP, align 8
  %802 = add i64 %801, -32
  %803 = load i64, i64* %PC, align 8
  %804 = add i64 %803, 7
  store i64 %804, i64* %PC, align 8
  %805 = inttoptr i64 %802 to i32*
  store i32 0, i32* %805, align 4
  %806 = load i64, i64* %RBP, align 8
  %807 = add i64 %806, -28
  %808 = load i64, i64* %PC, align 8
  %809 = add i64 %808, 7
  store i64 %809, i64* %PC, align 8
  %810 = inttoptr i64 %807 to i32*
  store i32 16, i32* %810, align 4
  %811 = bitcast %union.VectorReg* %6 to i8*
  %812 = bitcast [32 x %union.VectorReg]* %4 to <2 x i32>*
  %813 = bitcast i64* %69 to <2 x i32>*
  %814 = bitcast %union.VectorReg* %6 to i32*
  %815 = getelementptr inbounds i8, i8* %811, i64 4
  %816 = bitcast i8* %815 to i32*
  %817 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %818 = bitcast i64* %817 to i32*
  %819 = getelementptr inbounds i8, i8* %811, i64 12
  %820 = bitcast i8* %819 to i32*
  %821 = bitcast %union.VectorReg* %6 to double*
  %822 = bitcast %union.VectorReg* %5 to i32*
  %823 = getelementptr inbounds i8, i8* %672, i64 4
  %824 = bitcast i8* %823 to i32*
  %825 = bitcast i64* %679 to i32*
  %826 = getelementptr inbounds i8, i8* %672, i64 12
  %827 = bitcast i8* %826 to i32*
  %828 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  %829 = bitcast i64* %817 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_402c02

block_402c0e:                                     ; preds = %block_402c02
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %830 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 80) to i64*), align 16
  store i64 %830, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %831 = add i64 %3486, -32
  %832 = add i64 %3522, 21
  store i64 %832, i64* %PC, align 8
  %833 = inttoptr i64 %831 to i32*
  %834 = load i32, i32* %833, align 4
  %835 = add i32 %834, 2
  %836 = zext i32 %835 to i64
  store i64 %836, i64* %RCX, align 8, !tbaa !2428
  %837 = icmp ugt i32 %834, -3
  %838 = zext i1 %837 to i8
  store i8 %838, i8* %16, align 1, !tbaa !2432
  %839 = and i32 %835, 255
  %840 = tail call i32 @llvm.ctpop.i32(i32 %839) #11
  %841 = trunc i32 %840 to i8
  %842 = and i8 %841, 1
  %843 = xor i8 %842, 1
  store i8 %843, i8* %23, align 1, !tbaa !2446
  %844 = xor i32 %835, %834
  %845 = lshr i32 %844, 4
  %846 = trunc i32 %845 to i8
  %847 = and i8 %846, 1
  store i8 %847, i8* %29, align 1, !tbaa !2447
  %848 = icmp eq i32 %835, 0
  %849 = zext i1 %848 to i8
  store i8 %849, i8* %32, align 1, !tbaa !2448
  %850 = lshr i32 %835, 31
  %851 = trunc i32 %850 to i8
  store i8 %851, i8* %35, align 1, !tbaa !2449
  %852 = lshr i32 %834, 31
  %853 = xor i32 %850, %852
  %854 = add nuw nsw i32 %853, %850
  %855 = icmp eq i32 %854, 2
  %856 = zext i1 %855 to i8
  store i8 %856, i8* %41, align 1, !tbaa !2450
  %857 = add i64 %3522, 27
  store i64 %857, i64* %PC, align 8
  store i32 %835, i32* %833, align 4
  %858 = load i64, i64* %RBP, align 8
  %859 = add i64 %858, -32
  %860 = load i64, i64* %PC, align 8
  %861 = add i64 %860, 3
  store i64 %861, i64* %PC, align 8
  %862 = inttoptr i64 %859 to i32*
  %863 = load i32, i32* %862, align 4
  %864 = shl i32 %863, 1
  %865 = icmp slt i32 %863, 0
  %866 = icmp slt i32 %864, 0
  %867 = xor i1 %865, %866
  %868 = zext i32 %864 to i64
  store i64 %868, i64* %RCX, align 8, !tbaa !2428
  %.lobit = lshr i32 %863, 31
  %869 = trunc i32 %.lobit to i8
  store i8 %869, i8* %16, align 1, !tbaa !2453
  %870 = and i32 %864, 254
  %871 = tail call i32 @llvm.ctpop.i32(i32 %870) #11
  %872 = trunc i32 %871 to i8
  %873 = and i8 %872, 1
  %874 = xor i8 %873, 1
  store i8 %874, i8* %23, align 1, !tbaa !2453
  store i8 0, i8* %29, align 1, !tbaa !2453
  %875 = icmp eq i32 %864, 0
  %876 = zext i1 %875 to i8
  store i8 %876, i8* %32, align 1, !tbaa !2453
  %877 = lshr i32 %863, 30
  %878 = trunc i32 %877 to i8
  %879 = and i8 %878, 1
  store i8 %879, i8* %35, align 1, !tbaa !2453
  %880 = zext i1 %867 to i8
  store i8 %880, i8* %41, align 1, !tbaa !2453
  %881 = add i64 %858, -36
  %882 = add i64 %860, 9
  store i64 %882, i64* %PC, align 8
  %883 = inttoptr i64 %881 to i32*
  store i32 %864, i32* %883, align 4
  %884 = load i64, i64* %RBP, align 8
  %885 = add i64 %884, -24
  %886 = load i64, i64* %PC, align 8
  %887 = add i64 %886, 4
  store i64 %887, i64* %PC, align 8
  %888 = inttoptr i64 %885 to i64*
  %889 = load i64, i64* %888, align 8
  store i64 %889, i64* %RDX, align 8, !tbaa !2428
  %890 = add i64 %884, -32
  %891 = add i64 %886, 8
  store i64 %891, i64* %PC, align 8
  %892 = inttoptr i64 %890 to i32*
  %893 = load i32, i32* %892, align 4
  %894 = sext i32 %893 to i64
  store i64 %894, i64* %RSI, align 8, !tbaa !2428
  %895 = shl nsw i64 %894, 3
  %896 = add i64 %895, %889
  %897 = add i64 %886, 13
  store i64 %897, i64* %PC, align 8
  %898 = inttoptr i64 %896 to i64*
  %899 = load i64, i64* %898, align 8
  store i64 %899, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %900 = add i64 %884, -64
  %901 = add i64 %886, 18
  store i64 %901, i64* %PC, align 8
  %902 = inttoptr i64 %900 to i64*
  store i64 %899, i64* %902, align 8
  %903 = load i64, i64* %RBP, align 8
  %904 = add i64 %903, -24
  %905 = load i64, i64* %PC, align 8
  %906 = add i64 %905, 4
  store i64 %906, i64* %PC, align 8
  %907 = inttoptr i64 %904 to i64*
  %908 = load i64, i64* %907, align 8
  store i64 %908, i64* %RDX, align 8, !tbaa !2428
  %909 = add i64 %903, -32
  %910 = add i64 %905, 7
  store i64 %910, i64* %PC, align 8
  %911 = inttoptr i64 %909 to i32*
  %912 = load i32, i32* %911, align 4
  %913 = add i32 %912, 1
  %914 = zext i32 %913 to i64
  store i64 %914, i64* %RCX, align 8, !tbaa !2428
  %915 = icmp eq i32 %912, -1
  %916 = icmp eq i32 %913, 0
  %917 = or i1 %915, %916
  %918 = zext i1 %917 to i8
  store i8 %918, i8* %16, align 1, !tbaa !2432
  %919 = and i32 %913, 255
  %920 = tail call i32 @llvm.ctpop.i32(i32 %919) #11
  %921 = trunc i32 %920 to i8
  %922 = and i8 %921, 1
  %923 = xor i8 %922, 1
  store i8 %923, i8* %23, align 1, !tbaa !2446
  %924 = xor i32 %913, %912
  %925 = lshr i32 %924, 4
  %926 = trunc i32 %925 to i8
  %927 = and i8 %926, 1
  store i8 %927, i8* %29, align 1, !tbaa !2447
  %928 = zext i1 %916 to i8
  store i8 %928, i8* %32, align 1, !tbaa !2448
  %929 = lshr i32 %913, 31
  %930 = trunc i32 %929 to i8
  store i8 %930, i8* %35, align 1, !tbaa !2449
  %931 = lshr i32 %912, 31
  %932 = xor i32 %929, %931
  %933 = add nuw nsw i32 %932, %929
  %934 = icmp eq i32 %933, 2
  %935 = zext i1 %934 to i8
  store i8 %935, i8* %41, align 1, !tbaa !2450
  %936 = sext i32 %913 to i64
  store i64 %936, i64* %RSI, align 8, !tbaa !2428
  %937 = shl nsw i64 %936, 3
  %938 = add i64 %937, %908
  %939 = add i64 %905, 18
  store i64 %939, i64* %PC, align 8
  %940 = inttoptr i64 %938 to i64*
  %941 = load i64, i64* %940, align 8
  store i64 %941, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %942 = add i64 %903, -72
  %943 = add i64 %905, 23
  store i64 %943, i64* %PC, align 8
  %944 = inttoptr i64 %942 to i64*
  store i64 %941, i64* %944, align 8
  %945 = load i64, i64* %RBP, align 8
  %946 = add i64 %945, -24
  %947 = load i64, i64* %PC, align 8
  %948 = add i64 %947, 4
  store i64 %948, i64* %PC, align 8
  %949 = inttoptr i64 %946 to i64*
  %950 = load i64, i64* %949, align 8
  store i64 %950, i64* %RDX, align 8, !tbaa !2428
  %951 = add i64 %945, -36
  %952 = add i64 %947, 8
  store i64 %952, i64* %PC, align 8
  %953 = inttoptr i64 %951 to i32*
  %954 = load i32, i32* %953, align 4
  %955 = sext i32 %954 to i64
  store i64 %955, i64* %RSI, align 8, !tbaa !2428
  %956 = shl nsw i64 %955, 3
  %957 = add i64 %956, %950
  %958 = add i64 %947, 13
  store i64 %958, i64* %PC, align 8
  %959 = inttoptr i64 %957 to i64*
  %960 = load i64, i64* %959, align 8
  store i64 %960, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %961 = add i64 %945, -48
  %962 = add i64 %947, 18
  store i64 %962, i64* %PC, align 8
  %963 = inttoptr i64 %961 to i64*
  store i64 %960, i64* %963, align 8
  %964 = load i64, i64* %RBP, align 8
  %965 = add i64 %964, -24
  %966 = load i64, i64* %PC, align 8
  %967 = add i64 %966, 4
  store i64 %967, i64* %PC, align 8
  %968 = inttoptr i64 %965 to i64*
  %969 = load i64, i64* %968, align 8
  store i64 %969, i64* %RDX, align 8, !tbaa !2428
  %970 = add i64 %964, -36
  %971 = add i64 %966, 7
  store i64 %971, i64* %PC, align 8
  %972 = inttoptr i64 %970 to i32*
  %973 = load i32, i32* %972, align 4
  %974 = add i32 %973, 1
  %975 = zext i32 %974 to i64
  store i64 %975, i64* %RCX, align 8, !tbaa !2428
  %976 = icmp eq i32 %973, -1
  %977 = icmp eq i32 %974, 0
  %978 = or i1 %976, %977
  %979 = zext i1 %978 to i8
  store i8 %979, i8* %16, align 1, !tbaa !2432
  %980 = and i32 %974, 255
  %981 = tail call i32 @llvm.ctpop.i32(i32 %980) #11
  %982 = trunc i32 %981 to i8
  %983 = and i8 %982, 1
  %984 = xor i8 %983, 1
  store i8 %984, i8* %23, align 1, !tbaa !2446
  %985 = xor i32 %974, %973
  %986 = lshr i32 %985, 4
  %987 = trunc i32 %986 to i8
  %988 = and i8 %987, 1
  store i8 %988, i8* %29, align 1, !tbaa !2447
  %989 = zext i1 %977 to i8
  store i8 %989, i8* %32, align 1, !tbaa !2448
  %990 = lshr i32 %974, 31
  %991 = trunc i32 %990 to i8
  store i8 %991, i8* %35, align 1, !tbaa !2449
  %992 = lshr i32 %973, 31
  %993 = xor i32 %990, %992
  %994 = add nuw nsw i32 %993, %990
  %995 = icmp eq i32 %994, 2
  %996 = zext i1 %995 to i8
  store i8 %996, i8* %41, align 1, !tbaa !2450
  %997 = sext i32 %974 to i64
  store i64 %997, i64* %RSI, align 8, !tbaa !2428
  %998 = shl nsw i64 %997, 3
  %999 = add i64 %998, %969
  %1000 = add i64 %966, 18
  store i64 %1000, i64* %PC, align 8
  %1001 = inttoptr i64 %999 to i64*
  %1002 = load i64, i64* %1001, align 8
  store i64 %1002, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1003 = add i64 %964, -56
  %1004 = add i64 %966, 23
  store i64 %1004, i64* %PC, align 8
  %1005 = inttoptr i64 %1003 to i64*
  store i64 %1002, i64* %1005, align 8
  %1006 = load i64, i64* %RBP, align 8
  %1007 = add i64 %1006, -48
  %1008 = load i64, i64* %PC, align 8
  %1009 = add i64 %1008, 5
  store i64 %1009, i64* %PC, align 8
  %1010 = inttoptr i64 %1007 to i64*
  %1011 = load i64, i64* %1010, align 8
  store i64 %1011, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1012 = load <2 x i32>, <2 x i32>* %812, align 1
  %1013 = load <2 x i32>, <2 x i32>* %813, align 1
  %1014 = extractelement <2 x i32> %1012, i32 0
  store i32 %1014, i32* %814, align 1, !tbaa !2475
  %1015 = extractelement <2 x i32> %1012, i32 1
  store i32 %1015, i32* %816, align 1, !tbaa !2475
  %1016 = extractelement <2 x i32> %1013, i32 0
  store i32 %1016, i32* %818, align 1, !tbaa !2475
  %1017 = extractelement <2 x i32> %1013, i32 1
  store i32 %1017, i32* %820, align 1, !tbaa !2475
  %1018 = add i64 %1006, -72
  %1019 = add i64 %1008, 13
  store i64 %1019, i64* %PC, align 8
  %1020 = load double, double* %821, align 1
  %1021 = inttoptr i64 %1018 to double*
  %1022 = load double, double* %1021, align 8
  %1023 = fmul double %1020, %1022
  store double %1023, double* %821, align 1, !tbaa !2451
  %1024 = add i64 %1006, -56
  %1025 = add i64 %1008, 18
  store i64 %1025, i64* %PC, align 8
  %1026 = inttoptr i64 %1024 to double*
  %1027 = load double, double* %1026, align 8
  %1028 = fmul double %1023, %1027
  store double %1028, double* %821, align 1, !tbaa !2451
  %1029 = bitcast i64 %1011 to double
  %1030 = fsub double %1029, %1028
  %1031 = add i64 %1006, -80
  %1032 = add i64 %1008, 27
  store i64 %1032, i64* %PC, align 8
  %1033 = inttoptr i64 %1031 to double*
  store double %1030, double* %1033, align 8
  %1034 = load i64, i64* %PC, align 8
  %1035 = load <2 x i32>, <2 x i32>* %812, align 1
  %1036 = load <2 x i32>, <2 x i32>* %813, align 1
  %1037 = extractelement <2 x i32> %1035, i32 0
  store i32 %1037, i32* %822, align 1, !tbaa !2475
  %1038 = extractelement <2 x i32> %1035, i32 1
  store i32 %1038, i32* %824, align 1, !tbaa !2475
  %1039 = extractelement <2 x i32> %1036, i32 0
  store i32 %1039, i32* %825, align 1, !tbaa !2475
  %1040 = extractelement <2 x i32> %1036, i32 1
  store i32 %1040, i32* %827, align 1, !tbaa !2475
  %1041 = load i64, i64* %RBP, align 8
  %1042 = add i64 %1041, -72
  %1043 = add i64 %1034, 8
  store i64 %1043, i64* %PC, align 8
  %1044 = load double, double* %677, align 1
  %1045 = inttoptr i64 %1042 to double*
  %1046 = load double, double* %1045, align 8
  %1047 = fmul double %1044, %1046
  store double %1047, double* %677, align 1, !tbaa !2451
  %1048 = add i64 %1041, -48
  %1049 = add i64 %1034, 13
  store i64 %1049, i64* %PC, align 8
  %1050 = inttoptr i64 %1048 to double*
  %1051 = load double, double* %1050, align 8
  %1052 = fmul double %1047, %1051
  store double %1052, double* %677, align 1, !tbaa !2451
  %1053 = add i64 %1041, -56
  %1054 = add i64 %1034, 18
  store i64 %1054, i64* %PC, align 8
  %1055 = inttoptr i64 %1053 to double*
  %1056 = load double, double* %1055, align 8
  %1057 = fsub double %1052, %1056
  store double %1057, double* %677, align 1, !tbaa !2451
  %1058 = add i64 %1041, -88
  %1059 = add i64 %1034, 23
  store i64 %1059, i64* %PC, align 8
  %1060 = inttoptr i64 %1058 to double*
  store double %1057, double* %1060, align 8
  %1061 = load i64, i64* %RBP, align 8
  %1062 = add i64 %1061, -16
  %1063 = load i64, i64* %PC, align 8
  %1064 = add i64 %1063, 4
  store i64 %1064, i64* %PC, align 8
  %1065 = inttoptr i64 %1062 to i64*
  %1066 = load i64, i64* %1065, align 8
  store i64 %1066, i64* %RDX, align 8, !tbaa !2428
  %1067 = add i64 %1061, -28
  %1068 = add i64 %1063, 8
  store i64 %1068, i64* %PC, align 8
  %1069 = inttoptr i64 %1067 to i32*
  %1070 = load i32, i32* %1069, align 4
  %1071 = sext i32 %1070 to i64
  store i64 %1071, i64* %RSI, align 8, !tbaa !2428
  %1072 = shl nsw i64 %1071, 3
  %1073 = add i64 %1072, %1066
  %1074 = add i64 %1063, 13
  store i64 %1074, i64* %PC, align 8
  %1075 = inttoptr i64 %1073 to i64*
  %1076 = load i64, i64* %1075, align 8
  store i64 %1076, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1077 = add i64 %1063, 17
  store i64 %1077, i64* %PC, align 8
  %1078 = load i64, i64* %1065, align 8
  store i64 %1078, i64* %RDX, align 8, !tbaa !2428
  %1079 = add i64 %1063, 20
  store i64 %1079, i64* %PC, align 8
  %1080 = load i32, i32* %1069, align 4
  %1081 = add i32 %1080, 2
  %1082 = zext i32 %1081 to i64
  store i64 %1082, i64* %RCX, align 8, !tbaa !2428
  %1083 = icmp ugt i32 %1080, -3
  %1084 = zext i1 %1083 to i8
  store i8 %1084, i8* %16, align 1, !tbaa !2432
  %1085 = and i32 %1081, 255
  %1086 = tail call i32 @llvm.ctpop.i32(i32 %1085) #11
  %1087 = trunc i32 %1086 to i8
  %1088 = and i8 %1087, 1
  %1089 = xor i8 %1088, 1
  store i8 %1089, i8* %23, align 1, !tbaa !2446
  %1090 = xor i32 %1081, %1080
  %1091 = lshr i32 %1090, 4
  %1092 = trunc i32 %1091 to i8
  %1093 = and i8 %1092, 1
  store i8 %1093, i8* %29, align 1, !tbaa !2447
  %1094 = icmp eq i32 %1081, 0
  %1095 = zext i1 %1094 to i8
  store i8 %1095, i8* %32, align 1, !tbaa !2448
  %1096 = lshr i32 %1081, 31
  %1097 = trunc i32 %1096 to i8
  store i8 %1097, i8* %35, align 1, !tbaa !2449
  %1098 = lshr i32 %1080, 31
  %1099 = xor i32 %1096, %1098
  %1100 = add nuw nsw i32 %1099, %1096
  %1101 = icmp eq i32 %1100, 2
  %1102 = zext i1 %1101 to i8
  store i8 %1102, i8* %41, align 1, !tbaa !2450
  %1103 = sext i32 %1081 to i64
  store i64 %1103, i64* %RSI, align 8, !tbaa !2428
  %1104 = shl nsw i64 %1103, 3
  %1105 = add i64 %1104, %1078
  %1106 = add i64 %1063, 31
  store i64 %1106, i64* %PC, align 8
  %1107 = bitcast i64 %1076 to double
  %1108 = inttoptr i64 %1105 to double*
  %1109 = load double, double* %1108, align 8
  %1110 = fadd double %1107, %1109
  store double %1110, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1111 = add i64 %1061, -96
  %1112 = add i64 %1063, 36
  store i64 %1112, i64* %PC, align 8
  %1113 = inttoptr i64 %1111 to double*
  store double %1110, double* %1113, align 8
  %1114 = load i64, i64* %RBP, align 8
  %1115 = add i64 %1114, -16
  %1116 = load i64, i64* %PC, align 8
  %1117 = add i64 %1116, 4
  store i64 %1117, i64* %PC, align 8
  %1118 = inttoptr i64 %1115 to i64*
  %1119 = load i64, i64* %1118, align 8
  store i64 %1119, i64* %RDX, align 8, !tbaa !2428
  %1120 = add i64 %1114, -28
  %1121 = add i64 %1116, 7
  store i64 %1121, i64* %PC, align 8
  %1122 = inttoptr i64 %1120 to i32*
  %1123 = load i32, i32* %1122, align 4
  %1124 = add i32 %1123, 1
  %1125 = zext i32 %1124 to i64
  store i64 %1125, i64* %RCX, align 8, !tbaa !2428
  %1126 = icmp eq i32 %1123, -1
  %1127 = icmp eq i32 %1124, 0
  %1128 = or i1 %1126, %1127
  %1129 = zext i1 %1128 to i8
  store i8 %1129, i8* %16, align 1, !tbaa !2432
  %1130 = and i32 %1124, 255
  %1131 = tail call i32 @llvm.ctpop.i32(i32 %1130) #11
  %1132 = trunc i32 %1131 to i8
  %1133 = and i8 %1132, 1
  %1134 = xor i8 %1133, 1
  store i8 %1134, i8* %23, align 1, !tbaa !2446
  %1135 = xor i32 %1124, %1123
  %1136 = lshr i32 %1135, 4
  %1137 = trunc i32 %1136 to i8
  %1138 = and i8 %1137, 1
  store i8 %1138, i8* %29, align 1, !tbaa !2447
  %1139 = zext i1 %1127 to i8
  store i8 %1139, i8* %32, align 1, !tbaa !2448
  %1140 = lshr i32 %1124, 31
  %1141 = trunc i32 %1140 to i8
  store i8 %1141, i8* %35, align 1, !tbaa !2449
  %1142 = lshr i32 %1123, 31
  %1143 = xor i32 %1140, %1142
  %1144 = add nuw nsw i32 %1143, %1140
  %1145 = icmp eq i32 %1144, 2
  %1146 = zext i1 %1145 to i8
  store i8 %1146, i8* %41, align 1, !tbaa !2450
  %1147 = sext i32 %1124 to i64
  store i64 %1147, i64* %RSI, align 8, !tbaa !2428
  %1148 = shl nsw i64 %1147, 3
  %1149 = add i64 %1148, %1119
  %1150 = add i64 %1116, 18
  store i64 %1150, i64* %PC, align 8
  %1151 = inttoptr i64 %1149 to i64*
  %1152 = load i64, i64* %1151, align 8
  store i64 %1152, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1153 = add i64 %1116, 22
  store i64 %1153, i64* %PC, align 8
  %1154 = load i64, i64* %1118, align 8
  store i64 %1154, i64* %RDX, align 8, !tbaa !2428
  %1155 = add i64 %1116, 25
  store i64 %1155, i64* %PC, align 8
  %1156 = load i32, i32* %1122, align 4
  %1157 = add i32 %1156, 3
  %1158 = zext i32 %1157 to i64
  store i64 %1158, i64* %RCX, align 8, !tbaa !2428
  %1159 = icmp ugt i32 %1156, -4
  %1160 = zext i1 %1159 to i8
  store i8 %1160, i8* %16, align 1, !tbaa !2432
  %1161 = and i32 %1157, 255
  %1162 = tail call i32 @llvm.ctpop.i32(i32 %1161) #11
  %1163 = trunc i32 %1162 to i8
  %1164 = and i8 %1163, 1
  %1165 = xor i8 %1164, 1
  store i8 %1165, i8* %23, align 1, !tbaa !2446
  %1166 = xor i32 %1157, %1156
  %1167 = lshr i32 %1166, 4
  %1168 = trunc i32 %1167 to i8
  %1169 = and i8 %1168, 1
  store i8 %1169, i8* %29, align 1, !tbaa !2447
  %1170 = icmp eq i32 %1157, 0
  %1171 = zext i1 %1170 to i8
  store i8 %1171, i8* %32, align 1, !tbaa !2448
  %1172 = lshr i32 %1157, 31
  %1173 = trunc i32 %1172 to i8
  store i8 %1173, i8* %35, align 1, !tbaa !2449
  %1174 = lshr i32 %1156, 31
  %1175 = xor i32 %1172, %1174
  %1176 = add nuw nsw i32 %1175, %1172
  %1177 = icmp eq i32 %1176, 2
  %1178 = zext i1 %1177 to i8
  store i8 %1178, i8* %41, align 1, !tbaa !2450
  %1179 = sext i32 %1157 to i64
  store i64 %1179, i64* %RSI, align 8, !tbaa !2428
  %1180 = shl nsw i64 %1179, 3
  %1181 = add i64 %1180, %1154
  %1182 = add i64 %1116, 36
  store i64 %1182, i64* %PC, align 8
  %1183 = bitcast i64 %1152 to double
  %1184 = inttoptr i64 %1181 to double*
  %1185 = load double, double* %1184, align 8
  %1186 = fadd double %1183, %1185
  store double %1186, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1187 = load i64, i64* %RBP, align 8
  %1188 = add i64 %1187, -104
  %1189 = add i64 %1116, 41
  store i64 %1189, i64* %PC, align 8
  %1190 = inttoptr i64 %1188 to double*
  store double %1186, double* %1190, align 8
  %1191 = load i64, i64* %RBP, align 8
  %1192 = add i64 %1191, -16
  %1193 = load i64, i64* %PC, align 8
  %1194 = add i64 %1193, 4
  store i64 %1194, i64* %PC, align 8
  %1195 = inttoptr i64 %1192 to i64*
  %1196 = load i64, i64* %1195, align 8
  store i64 %1196, i64* %RDX, align 8, !tbaa !2428
  %1197 = add i64 %1191, -28
  %1198 = add i64 %1193, 8
  store i64 %1198, i64* %PC, align 8
  %1199 = inttoptr i64 %1197 to i32*
  %1200 = load i32, i32* %1199, align 4
  %1201 = sext i32 %1200 to i64
  store i64 %1201, i64* %RSI, align 8, !tbaa !2428
  %1202 = shl nsw i64 %1201, 3
  %1203 = add i64 %1202, %1196
  %1204 = add i64 %1193, 13
  store i64 %1204, i64* %PC, align 8
  %1205 = inttoptr i64 %1203 to i64*
  %1206 = load i64, i64* %1205, align 8
  store i64 %1206, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1207 = add i64 %1193, 17
  store i64 %1207, i64* %PC, align 8
  %1208 = load i64, i64* %1195, align 8
  store i64 %1208, i64* %RDX, align 8, !tbaa !2428
  %1209 = add i64 %1193, 20
  store i64 %1209, i64* %PC, align 8
  %1210 = load i32, i32* %1199, align 4
  %1211 = add i32 %1210, 2
  %1212 = zext i32 %1211 to i64
  store i64 %1212, i64* %RCX, align 8, !tbaa !2428
  %1213 = icmp ugt i32 %1210, -3
  %1214 = zext i1 %1213 to i8
  store i8 %1214, i8* %16, align 1, !tbaa !2432
  %1215 = and i32 %1211, 255
  %1216 = tail call i32 @llvm.ctpop.i32(i32 %1215) #11
  %1217 = trunc i32 %1216 to i8
  %1218 = and i8 %1217, 1
  %1219 = xor i8 %1218, 1
  store i8 %1219, i8* %23, align 1, !tbaa !2446
  %1220 = xor i32 %1211, %1210
  %1221 = lshr i32 %1220, 4
  %1222 = trunc i32 %1221 to i8
  %1223 = and i8 %1222, 1
  store i8 %1223, i8* %29, align 1, !tbaa !2447
  %1224 = icmp eq i32 %1211, 0
  %1225 = zext i1 %1224 to i8
  store i8 %1225, i8* %32, align 1, !tbaa !2448
  %1226 = lshr i32 %1211, 31
  %1227 = trunc i32 %1226 to i8
  store i8 %1227, i8* %35, align 1, !tbaa !2449
  %1228 = lshr i32 %1210, 31
  %1229 = xor i32 %1226, %1228
  %1230 = add nuw nsw i32 %1229, %1226
  %1231 = icmp eq i32 %1230, 2
  %1232 = zext i1 %1231 to i8
  store i8 %1232, i8* %41, align 1, !tbaa !2450
  %1233 = sext i32 %1211 to i64
  store i64 %1233, i64* %RSI, align 8, !tbaa !2428
  %1234 = shl nsw i64 %1233, 3
  %1235 = add i64 %1234, %1208
  %1236 = add i64 %1193, 31
  store i64 %1236, i64* %PC, align 8
  %1237 = bitcast i64 %1206 to double
  %1238 = inttoptr i64 %1235 to double*
  %1239 = load double, double* %1238, align 8
  %1240 = fsub double %1237, %1239
  store double %1240, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1241 = add i64 %1191, -112
  %1242 = add i64 %1193, 36
  store i64 %1242, i64* %PC, align 8
  %1243 = inttoptr i64 %1241 to double*
  store double %1240, double* %1243, align 8
  %1244 = load i64, i64* %RBP, align 8
  %1245 = add i64 %1244, -16
  %1246 = load i64, i64* %PC, align 8
  %1247 = add i64 %1246, 4
  store i64 %1247, i64* %PC, align 8
  %1248 = inttoptr i64 %1245 to i64*
  %1249 = load i64, i64* %1248, align 8
  store i64 %1249, i64* %RDX, align 8, !tbaa !2428
  %1250 = add i64 %1244, -28
  %1251 = add i64 %1246, 7
  store i64 %1251, i64* %PC, align 8
  %1252 = inttoptr i64 %1250 to i32*
  %1253 = load i32, i32* %1252, align 4
  %1254 = add i32 %1253, 1
  %1255 = zext i32 %1254 to i64
  store i64 %1255, i64* %RCX, align 8, !tbaa !2428
  %1256 = icmp eq i32 %1253, -1
  %1257 = icmp eq i32 %1254, 0
  %1258 = or i1 %1256, %1257
  %1259 = zext i1 %1258 to i8
  store i8 %1259, i8* %16, align 1, !tbaa !2432
  %1260 = and i32 %1254, 255
  %1261 = tail call i32 @llvm.ctpop.i32(i32 %1260) #11
  %1262 = trunc i32 %1261 to i8
  %1263 = and i8 %1262, 1
  %1264 = xor i8 %1263, 1
  store i8 %1264, i8* %23, align 1, !tbaa !2446
  %1265 = xor i32 %1254, %1253
  %1266 = lshr i32 %1265, 4
  %1267 = trunc i32 %1266 to i8
  %1268 = and i8 %1267, 1
  store i8 %1268, i8* %29, align 1, !tbaa !2447
  %1269 = zext i1 %1257 to i8
  store i8 %1269, i8* %32, align 1, !tbaa !2448
  %1270 = lshr i32 %1254, 31
  %1271 = trunc i32 %1270 to i8
  store i8 %1271, i8* %35, align 1, !tbaa !2449
  %1272 = lshr i32 %1253, 31
  %1273 = xor i32 %1270, %1272
  %1274 = add nuw nsw i32 %1273, %1270
  %1275 = icmp eq i32 %1274, 2
  %1276 = zext i1 %1275 to i8
  store i8 %1276, i8* %41, align 1, !tbaa !2450
  %1277 = sext i32 %1254 to i64
  store i64 %1277, i64* %RSI, align 8, !tbaa !2428
  %1278 = shl nsw i64 %1277, 3
  %1279 = add i64 %1278, %1249
  %1280 = add i64 %1246, 18
  store i64 %1280, i64* %PC, align 8
  %1281 = inttoptr i64 %1279 to i64*
  %1282 = load i64, i64* %1281, align 8
  store i64 %1282, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1283 = add i64 %1246, 22
  store i64 %1283, i64* %PC, align 8
  %1284 = load i64, i64* %1248, align 8
  store i64 %1284, i64* %RDX, align 8, !tbaa !2428
  %1285 = add i64 %1246, 25
  store i64 %1285, i64* %PC, align 8
  %1286 = load i32, i32* %1252, align 4
  %1287 = add i32 %1286, 3
  %1288 = zext i32 %1287 to i64
  store i64 %1288, i64* %RCX, align 8, !tbaa !2428
  %1289 = icmp ugt i32 %1286, -4
  %1290 = zext i1 %1289 to i8
  store i8 %1290, i8* %16, align 1, !tbaa !2432
  %1291 = and i32 %1287, 255
  %1292 = tail call i32 @llvm.ctpop.i32(i32 %1291) #11
  %1293 = trunc i32 %1292 to i8
  %1294 = and i8 %1293, 1
  %1295 = xor i8 %1294, 1
  store i8 %1295, i8* %23, align 1, !tbaa !2446
  %1296 = xor i32 %1287, %1286
  %1297 = lshr i32 %1296, 4
  %1298 = trunc i32 %1297 to i8
  %1299 = and i8 %1298, 1
  store i8 %1299, i8* %29, align 1, !tbaa !2447
  %1300 = icmp eq i32 %1287, 0
  %1301 = zext i1 %1300 to i8
  store i8 %1301, i8* %32, align 1, !tbaa !2448
  %1302 = lshr i32 %1287, 31
  %1303 = trunc i32 %1302 to i8
  store i8 %1303, i8* %35, align 1, !tbaa !2449
  %1304 = lshr i32 %1286, 31
  %1305 = xor i32 %1302, %1304
  %1306 = add nuw nsw i32 %1305, %1302
  %1307 = icmp eq i32 %1306, 2
  %1308 = zext i1 %1307 to i8
  store i8 %1308, i8* %41, align 1, !tbaa !2450
  %1309 = sext i32 %1287 to i64
  store i64 %1309, i64* %RSI, align 8, !tbaa !2428
  %1310 = shl nsw i64 %1309, 3
  %1311 = add i64 %1310, %1284
  %1312 = add i64 %1246, 36
  store i64 %1312, i64* %PC, align 8
  %1313 = bitcast i64 %1282 to double
  %1314 = inttoptr i64 %1311 to double*
  %1315 = load double, double* %1314, align 8
  %1316 = fsub double %1313, %1315
  store double %1316, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1317 = load i64, i64* %RBP, align 8
  %1318 = add i64 %1317, -120
  %1319 = add i64 %1246, 41
  store i64 %1319, i64* %PC, align 8
  %1320 = inttoptr i64 %1318 to double*
  store double %1316, double* %1320, align 8
  %1321 = load i64, i64* %RBP, align 8
  %1322 = add i64 %1321, -16
  %1323 = load i64, i64* %PC, align 8
  %1324 = add i64 %1323, 4
  store i64 %1324, i64* %PC, align 8
  %1325 = inttoptr i64 %1322 to i64*
  %1326 = load i64, i64* %1325, align 8
  store i64 %1326, i64* %RDX, align 8, !tbaa !2428
  %1327 = add i64 %1321, -28
  %1328 = add i64 %1323, 7
  store i64 %1328, i64* %PC, align 8
  %1329 = inttoptr i64 %1327 to i32*
  %1330 = load i32, i32* %1329, align 4
  %1331 = add i32 %1330, 4
  %1332 = zext i32 %1331 to i64
  store i64 %1332, i64* %RCX, align 8, !tbaa !2428
  %1333 = icmp ugt i32 %1330, -5
  %1334 = zext i1 %1333 to i8
  store i8 %1334, i8* %16, align 1, !tbaa !2432
  %1335 = and i32 %1331, 255
  %1336 = tail call i32 @llvm.ctpop.i32(i32 %1335) #11
  %1337 = trunc i32 %1336 to i8
  %1338 = and i8 %1337, 1
  %1339 = xor i8 %1338, 1
  store i8 %1339, i8* %23, align 1, !tbaa !2446
  %1340 = xor i32 %1331, %1330
  %1341 = lshr i32 %1340, 4
  %1342 = trunc i32 %1341 to i8
  %1343 = and i8 %1342, 1
  store i8 %1343, i8* %29, align 1, !tbaa !2447
  %1344 = icmp eq i32 %1331, 0
  %1345 = zext i1 %1344 to i8
  store i8 %1345, i8* %32, align 1, !tbaa !2448
  %1346 = lshr i32 %1331, 31
  %1347 = trunc i32 %1346 to i8
  store i8 %1347, i8* %35, align 1, !tbaa !2449
  %1348 = lshr i32 %1330, 31
  %1349 = xor i32 %1346, %1348
  %1350 = add nuw nsw i32 %1349, %1346
  %1351 = icmp eq i32 %1350, 2
  %1352 = zext i1 %1351 to i8
  store i8 %1352, i8* %41, align 1, !tbaa !2450
  %1353 = sext i32 %1331 to i64
  store i64 %1353, i64* %RSI, align 8, !tbaa !2428
  %1354 = shl nsw i64 %1353, 3
  %1355 = add i64 %1354, %1326
  %1356 = add i64 %1323, 18
  store i64 %1356, i64* %PC, align 8
  %1357 = inttoptr i64 %1355 to i64*
  %1358 = load i64, i64* %1357, align 8
  store i64 %1358, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1359 = add i64 %1323, 22
  store i64 %1359, i64* %PC, align 8
  %1360 = load i64, i64* %1325, align 8
  store i64 %1360, i64* %RDX, align 8, !tbaa !2428
  %1361 = add i64 %1323, 25
  store i64 %1361, i64* %PC, align 8
  %1362 = load i32, i32* %1329, align 4
  %1363 = add i32 %1362, 6
  %1364 = zext i32 %1363 to i64
  store i64 %1364, i64* %RCX, align 8, !tbaa !2428
  %1365 = icmp ugt i32 %1362, -7
  %1366 = zext i1 %1365 to i8
  store i8 %1366, i8* %16, align 1, !tbaa !2432
  %1367 = and i32 %1363, 255
  %1368 = tail call i32 @llvm.ctpop.i32(i32 %1367) #11
  %1369 = trunc i32 %1368 to i8
  %1370 = and i8 %1369, 1
  %1371 = xor i8 %1370, 1
  store i8 %1371, i8* %23, align 1, !tbaa !2446
  %1372 = xor i32 %1363, %1362
  %1373 = lshr i32 %1372, 4
  %1374 = trunc i32 %1373 to i8
  %1375 = and i8 %1374, 1
  store i8 %1375, i8* %29, align 1, !tbaa !2447
  %1376 = icmp eq i32 %1363, 0
  %1377 = zext i1 %1376 to i8
  store i8 %1377, i8* %32, align 1, !tbaa !2448
  %1378 = lshr i32 %1363, 31
  %1379 = trunc i32 %1378 to i8
  store i8 %1379, i8* %35, align 1, !tbaa !2449
  %1380 = lshr i32 %1362, 31
  %1381 = xor i32 %1378, %1380
  %1382 = add nuw nsw i32 %1381, %1378
  %1383 = icmp eq i32 %1382, 2
  %1384 = zext i1 %1383 to i8
  store i8 %1384, i8* %41, align 1, !tbaa !2450
  %1385 = sext i32 %1363 to i64
  store i64 %1385, i64* %RSI, align 8, !tbaa !2428
  %1386 = shl nsw i64 %1385, 3
  %1387 = add i64 %1386, %1360
  %1388 = add i64 %1323, 36
  store i64 %1388, i64* %PC, align 8
  %1389 = bitcast i64 %1358 to double
  %1390 = inttoptr i64 %1387 to double*
  %1391 = load double, double* %1390, align 8
  %1392 = fadd double %1389, %1391
  store double %1392, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1393 = load i64, i64* %RBP, align 8
  %1394 = add i64 %1393, -128
  %1395 = add i64 %1323, 41
  store i64 %1395, i64* %PC, align 8
  %1396 = inttoptr i64 %1394 to double*
  store double %1392, double* %1396, align 8
  %1397 = load i64, i64* %RBP, align 8
  %1398 = add i64 %1397, -16
  %1399 = load i64, i64* %PC, align 8
  %1400 = add i64 %1399, 4
  store i64 %1400, i64* %PC, align 8
  %1401 = inttoptr i64 %1398 to i64*
  %1402 = load i64, i64* %1401, align 8
  store i64 %1402, i64* %RDX, align 8, !tbaa !2428
  %1403 = add i64 %1397, -28
  %1404 = add i64 %1399, 7
  store i64 %1404, i64* %PC, align 8
  %1405 = inttoptr i64 %1403 to i32*
  %1406 = load i32, i32* %1405, align 4
  %1407 = add i32 %1406, 5
  %1408 = zext i32 %1407 to i64
  store i64 %1408, i64* %RCX, align 8, !tbaa !2428
  %1409 = icmp ugt i32 %1406, -6
  %1410 = zext i1 %1409 to i8
  store i8 %1410, i8* %16, align 1, !tbaa !2432
  %1411 = and i32 %1407, 255
  %1412 = tail call i32 @llvm.ctpop.i32(i32 %1411) #11
  %1413 = trunc i32 %1412 to i8
  %1414 = and i8 %1413, 1
  %1415 = xor i8 %1414, 1
  store i8 %1415, i8* %23, align 1, !tbaa !2446
  %1416 = xor i32 %1407, %1406
  %1417 = lshr i32 %1416, 4
  %1418 = trunc i32 %1417 to i8
  %1419 = and i8 %1418, 1
  store i8 %1419, i8* %29, align 1, !tbaa !2447
  %1420 = icmp eq i32 %1407, 0
  %1421 = zext i1 %1420 to i8
  store i8 %1421, i8* %32, align 1, !tbaa !2448
  %1422 = lshr i32 %1407, 31
  %1423 = trunc i32 %1422 to i8
  store i8 %1423, i8* %35, align 1, !tbaa !2449
  %1424 = lshr i32 %1406, 31
  %1425 = xor i32 %1422, %1424
  %1426 = add nuw nsw i32 %1425, %1422
  %1427 = icmp eq i32 %1426, 2
  %1428 = zext i1 %1427 to i8
  store i8 %1428, i8* %41, align 1, !tbaa !2450
  %1429 = sext i32 %1407 to i64
  store i64 %1429, i64* %RSI, align 8, !tbaa !2428
  %1430 = shl nsw i64 %1429, 3
  %1431 = add i64 %1430, %1402
  %1432 = add i64 %1399, 18
  store i64 %1432, i64* %PC, align 8
  %1433 = inttoptr i64 %1431 to i64*
  %1434 = load i64, i64* %1433, align 8
  store i64 %1434, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1435 = add i64 %1399, 22
  store i64 %1435, i64* %PC, align 8
  %1436 = load i64, i64* %1401, align 8
  store i64 %1436, i64* %RDX, align 8, !tbaa !2428
  %1437 = add i64 %1399, 25
  store i64 %1437, i64* %PC, align 8
  %1438 = load i32, i32* %1405, align 4
  %1439 = add i32 %1438, 7
  %1440 = zext i32 %1439 to i64
  store i64 %1440, i64* %RCX, align 8, !tbaa !2428
  %1441 = icmp ugt i32 %1438, -8
  %1442 = zext i1 %1441 to i8
  store i8 %1442, i8* %16, align 1, !tbaa !2432
  %1443 = and i32 %1439, 255
  %1444 = tail call i32 @llvm.ctpop.i32(i32 %1443) #11
  %1445 = trunc i32 %1444 to i8
  %1446 = and i8 %1445, 1
  %1447 = xor i8 %1446, 1
  store i8 %1447, i8* %23, align 1, !tbaa !2446
  %1448 = xor i32 %1439, %1438
  %1449 = lshr i32 %1448, 4
  %1450 = trunc i32 %1449 to i8
  %1451 = and i8 %1450, 1
  store i8 %1451, i8* %29, align 1, !tbaa !2447
  %1452 = icmp eq i32 %1439, 0
  %1453 = zext i1 %1452 to i8
  store i8 %1453, i8* %32, align 1, !tbaa !2448
  %1454 = lshr i32 %1439, 31
  %1455 = trunc i32 %1454 to i8
  store i8 %1455, i8* %35, align 1, !tbaa !2449
  %1456 = lshr i32 %1438, 31
  %1457 = xor i32 %1454, %1456
  %1458 = add nuw nsw i32 %1457, %1454
  %1459 = icmp eq i32 %1458, 2
  %1460 = zext i1 %1459 to i8
  store i8 %1460, i8* %41, align 1, !tbaa !2450
  %1461 = sext i32 %1439 to i64
  store i64 %1461, i64* %RSI, align 8, !tbaa !2428
  %1462 = shl nsw i64 %1461, 3
  %1463 = add i64 %1462, %1436
  %1464 = add i64 %1399, 36
  store i64 %1464, i64* %PC, align 8
  %1465 = bitcast i64 %1434 to double
  %1466 = inttoptr i64 %1463 to double*
  %1467 = load double, double* %1466, align 8
  %1468 = fadd double %1465, %1467
  store double %1468, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1469 = load i64, i64* %RBP, align 8
  %1470 = add i64 %1469, -136
  %1471 = add i64 %1399, 44
  store i64 %1471, i64* %PC, align 8
  %1472 = inttoptr i64 %1470 to double*
  store double %1468, double* %1472, align 8
  %1473 = load i64, i64* %RBP, align 8
  %1474 = add i64 %1473, -16
  %1475 = load i64, i64* %PC, align 8
  %1476 = add i64 %1475, 4
  store i64 %1476, i64* %PC, align 8
  %1477 = inttoptr i64 %1474 to i64*
  %1478 = load i64, i64* %1477, align 8
  store i64 %1478, i64* %RDX, align 8, !tbaa !2428
  %1479 = add i64 %1473, -28
  %1480 = add i64 %1475, 7
  store i64 %1480, i64* %PC, align 8
  %1481 = inttoptr i64 %1479 to i32*
  %1482 = load i32, i32* %1481, align 4
  %1483 = add i32 %1482, 4
  %1484 = zext i32 %1483 to i64
  store i64 %1484, i64* %RCX, align 8, !tbaa !2428
  %1485 = icmp ugt i32 %1482, -5
  %1486 = zext i1 %1485 to i8
  store i8 %1486, i8* %16, align 1, !tbaa !2432
  %1487 = and i32 %1483, 255
  %1488 = tail call i32 @llvm.ctpop.i32(i32 %1487) #11
  %1489 = trunc i32 %1488 to i8
  %1490 = and i8 %1489, 1
  %1491 = xor i8 %1490, 1
  store i8 %1491, i8* %23, align 1, !tbaa !2446
  %1492 = xor i32 %1483, %1482
  %1493 = lshr i32 %1492, 4
  %1494 = trunc i32 %1493 to i8
  %1495 = and i8 %1494, 1
  store i8 %1495, i8* %29, align 1, !tbaa !2447
  %1496 = icmp eq i32 %1483, 0
  %1497 = zext i1 %1496 to i8
  store i8 %1497, i8* %32, align 1, !tbaa !2448
  %1498 = lshr i32 %1483, 31
  %1499 = trunc i32 %1498 to i8
  store i8 %1499, i8* %35, align 1, !tbaa !2449
  %1500 = lshr i32 %1482, 31
  %1501 = xor i32 %1498, %1500
  %1502 = add nuw nsw i32 %1501, %1498
  %1503 = icmp eq i32 %1502, 2
  %1504 = zext i1 %1503 to i8
  store i8 %1504, i8* %41, align 1, !tbaa !2450
  %1505 = sext i32 %1483 to i64
  store i64 %1505, i64* %RSI, align 8, !tbaa !2428
  %1506 = shl nsw i64 %1505, 3
  %1507 = add i64 %1506, %1478
  %1508 = add i64 %1475, 18
  store i64 %1508, i64* %PC, align 8
  %1509 = inttoptr i64 %1507 to i64*
  %1510 = load i64, i64* %1509, align 8
  store i64 %1510, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1511 = add i64 %1475, 22
  store i64 %1511, i64* %PC, align 8
  %1512 = load i64, i64* %1477, align 8
  store i64 %1512, i64* %RDX, align 8, !tbaa !2428
  %1513 = add i64 %1475, 25
  store i64 %1513, i64* %PC, align 8
  %1514 = load i32, i32* %1481, align 4
  %1515 = add i32 %1514, 6
  %1516 = zext i32 %1515 to i64
  store i64 %1516, i64* %RCX, align 8, !tbaa !2428
  %1517 = icmp ugt i32 %1514, -7
  %1518 = zext i1 %1517 to i8
  store i8 %1518, i8* %16, align 1, !tbaa !2432
  %1519 = and i32 %1515, 255
  %1520 = tail call i32 @llvm.ctpop.i32(i32 %1519) #11
  %1521 = trunc i32 %1520 to i8
  %1522 = and i8 %1521, 1
  %1523 = xor i8 %1522, 1
  store i8 %1523, i8* %23, align 1, !tbaa !2446
  %1524 = xor i32 %1515, %1514
  %1525 = lshr i32 %1524, 4
  %1526 = trunc i32 %1525 to i8
  %1527 = and i8 %1526, 1
  store i8 %1527, i8* %29, align 1, !tbaa !2447
  %1528 = icmp eq i32 %1515, 0
  %1529 = zext i1 %1528 to i8
  store i8 %1529, i8* %32, align 1, !tbaa !2448
  %1530 = lshr i32 %1515, 31
  %1531 = trunc i32 %1530 to i8
  store i8 %1531, i8* %35, align 1, !tbaa !2449
  %1532 = lshr i32 %1514, 31
  %1533 = xor i32 %1530, %1532
  %1534 = add nuw nsw i32 %1533, %1530
  %1535 = icmp eq i32 %1534, 2
  %1536 = zext i1 %1535 to i8
  store i8 %1536, i8* %41, align 1, !tbaa !2450
  %1537 = sext i32 %1515 to i64
  store i64 %1537, i64* %RSI, align 8, !tbaa !2428
  %1538 = shl nsw i64 %1537, 3
  %1539 = add i64 %1538, %1512
  %1540 = add i64 %1475, 36
  store i64 %1540, i64* %PC, align 8
  %1541 = bitcast i64 %1510 to double
  %1542 = inttoptr i64 %1539 to double*
  %1543 = load double, double* %1542, align 8
  %1544 = fsub double %1541, %1543
  store double %1544, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1545 = load i64, i64* %RBP, align 8
  %1546 = add i64 %1545, -144
  %1547 = add i64 %1475, 44
  store i64 %1547, i64* %PC, align 8
  %1548 = inttoptr i64 %1546 to double*
  store double %1544, double* %1548, align 8
  %1549 = load i64, i64* %RBP, align 8
  %1550 = add i64 %1549, -16
  %1551 = load i64, i64* %PC, align 8
  %1552 = add i64 %1551, 4
  store i64 %1552, i64* %PC, align 8
  %1553 = inttoptr i64 %1550 to i64*
  %1554 = load i64, i64* %1553, align 8
  store i64 %1554, i64* %RDX, align 8, !tbaa !2428
  %1555 = add i64 %1549, -28
  %1556 = add i64 %1551, 7
  store i64 %1556, i64* %PC, align 8
  %1557 = inttoptr i64 %1555 to i32*
  %1558 = load i32, i32* %1557, align 4
  %1559 = add i32 %1558, 5
  %1560 = zext i32 %1559 to i64
  store i64 %1560, i64* %RCX, align 8, !tbaa !2428
  %1561 = icmp ugt i32 %1558, -6
  %1562 = zext i1 %1561 to i8
  store i8 %1562, i8* %16, align 1, !tbaa !2432
  %1563 = and i32 %1559, 255
  %1564 = tail call i32 @llvm.ctpop.i32(i32 %1563) #11
  %1565 = trunc i32 %1564 to i8
  %1566 = and i8 %1565, 1
  %1567 = xor i8 %1566, 1
  store i8 %1567, i8* %23, align 1, !tbaa !2446
  %1568 = xor i32 %1559, %1558
  %1569 = lshr i32 %1568, 4
  %1570 = trunc i32 %1569 to i8
  %1571 = and i8 %1570, 1
  store i8 %1571, i8* %29, align 1, !tbaa !2447
  %1572 = icmp eq i32 %1559, 0
  %1573 = zext i1 %1572 to i8
  store i8 %1573, i8* %32, align 1, !tbaa !2448
  %1574 = lshr i32 %1559, 31
  %1575 = trunc i32 %1574 to i8
  store i8 %1575, i8* %35, align 1, !tbaa !2449
  %1576 = lshr i32 %1558, 31
  %1577 = xor i32 %1574, %1576
  %1578 = add nuw nsw i32 %1577, %1574
  %1579 = icmp eq i32 %1578, 2
  %1580 = zext i1 %1579 to i8
  store i8 %1580, i8* %41, align 1, !tbaa !2450
  %1581 = sext i32 %1559 to i64
  store i64 %1581, i64* %RSI, align 8, !tbaa !2428
  %1582 = shl nsw i64 %1581, 3
  %1583 = add i64 %1582, %1554
  %1584 = add i64 %1551, 18
  store i64 %1584, i64* %PC, align 8
  %1585 = inttoptr i64 %1583 to i64*
  %1586 = load i64, i64* %1585, align 8
  store i64 %1586, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1587 = add i64 %1551, 22
  store i64 %1587, i64* %PC, align 8
  %1588 = load i64, i64* %1553, align 8
  store i64 %1588, i64* %RDX, align 8, !tbaa !2428
  %1589 = add i64 %1551, 25
  store i64 %1589, i64* %PC, align 8
  %1590 = load i32, i32* %1557, align 4
  %1591 = add i32 %1590, 7
  %1592 = zext i32 %1591 to i64
  store i64 %1592, i64* %RCX, align 8, !tbaa !2428
  %1593 = icmp ugt i32 %1590, -8
  %1594 = zext i1 %1593 to i8
  store i8 %1594, i8* %16, align 1, !tbaa !2432
  %1595 = and i32 %1591, 255
  %1596 = tail call i32 @llvm.ctpop.i32(i32 %1595) #11
  %1597 = trunc i32 %1596 to i8
  %1598 = and i8 %1597, 1
  %1599 = xor i8 %1598, 1
  store i8 %1599, i8* %23, align 1, !tbaa !2446
  %1600 = xor i32 %1591, %1590
  %1601 = lshr i32 %1600, 4
  %1602 = trunc i32 %1601 to i8
  %1603 = and i8 %1602, 1
  store i8 %1603, i8* %29, align 1, !tbaa !2447
  %1604 = icmp eq i32 %1591, 0
  %1605 = zext i1 %1604 to i8
  store i8 %1605, i8* %32, align 1, !tbaa !2448
  %1606 = lshr i32 %1591, 31
  %1607 = trunc i32 %1606 to i8
  store i8 %1607, i8* %35, align 1, !tbaa !2449
  %1608 = lshr i32 %1590, 31
  %1609 = xor i32 %1606, %1608
  %1610 = add nuw nsw i32 %1609, %1606
  %1611 = icmp eq i32 %1610, 2
  %1612 = zext i1 %1611 to i8
  store i8 %1612, i8* %41, align 1, !tbaa !2450
  %1613 = sext i32 %1591 to i64
  store i64 %1613, i64* %RSI, align 8, !tbaa !2428
  %1614 = shl nsw i64 %1613, 3
  %1615 = add i64 %1614, %1588
  %1616 = add i64 %1551, 36
  store i64 %1616, i64* %PC, align 8
  %1617 = bitcast i64 %1586 to double
  %1618 = inttoptr i64 %1615 to double*
  %1619 = load double, double* %1618, align 8
  %1620 = fsub double %1617, %1619
  store double %1620, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1621 = load i64, i64* %RBP, align 8
  %1622 = add i64 %1621, -152
  %1623 = add i64 %1551, 44
  store i64 %1623, i64* %PC, align 8
  %1624 = inttoptr i64 %1622 to double*
  store double %1620, double* %1624, align 8
  %1625 = load i64, i64* %RBP, align 8
  %1626 = add i64 %1625, -96
  %1627 = load i64, i64* %PC, align 8
  %1628 = add i64 %1627, 5
  store i64 %1628, i64* %PC, align 8
  %1629 = inttoptr i64 %1626 to i64*
  %1630 = load i64, i64* %1629, align 8
  store i64 %1630, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1631 = add i64 %1625, -128
  %1632 = add i64 %1627, 10
  store i64 %1632, i64* %PC, align 8
  %1633 = bitcast i64 %1630 to double
  %1634 = inttoptr i64 %1631 to double*
  %1635 = load double, double* %1634, align 8
  %1636 = fadd double %1633, %1635
  store double %1636, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1637 = add i64 %1625, -16
  %1638 = add i64 %1627, 14
  store i64 %1638, i64* %PC, align 8
  %1639 = inttoptr i64 %1637 to i64*
  %1640 = load i64, i64* %1639, align 8
  store i64 %1640, i64* %RDX, align 8, !tbaa !2428
  %1641 = add i64 %1625, -28
  %1642 = add i64 %1627, 18
  store i64 %1642, i64* %PC, align 8
  %1643 = inttoptr i64 %1641 to i32*
  %1644 = load i32, i32* %1643, align 4
  %1645 = sext i32 %1644 to i64
  store i64 %1645, i64* %RSI, align 8, !tbaa !2428
  %1646 = shl nsw i64 %1645, 3
  %1647 = add i64 %1646, %1640
  %1648 = add i64 %1627, 23
  store i64 %1648, i64* %PC, align 8
  %1649 = inttoptr i64 %1647 to double*
  store double %1636, double* %1649, align 8
  %1650 = load i64, i64* %RBP, align 8
  %1651 = add i64 %1650, -104
  %1652 = load i64, i64* %PC, align 8
  %1653 = add i64 %1652, 5
  store i64 %1653, i64* %PC, align 8
  %1654 = inttoptr i64 %1651 to i64*
  %1655 = load i64, i64* %1654, align 8
  store i64 %1655, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1656 = add i64 %1650, -136
  %1657 = add i64 %1652, 13
  store i64 %1657, i64* %PC, align 8
  %1658 = bitcast i64 %1655 to double
  %1659 = inttoptr i64 %1656 to double*
  %1660 = load double, double* %1659, align 8
  %1661 = fadd double %1658, %1660
  store double %1661, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1662 = add i64 %1650, -16
  %1663 = add i64 %1652, 17
  store i64 %1663, i64* %PC, align 8
  %1664 = inttoptr i64 %1662 to i64*
  %1665 = load i64, i64* %1664, align 8
  store i64 %1665, i64* %RDX, align 8, !tbaa !2428
  %1666 = add i64 %1650, -28
  %1667 = add i64 %1652, 20
  store i64 %1667, i64* %PC, align 8
  %1668 = inttoptr i64 %1666 to i32*
  %1669 = load i32, i32* %1668, align 4
  %1670 = add i32 %1669, 1
  %1671 = zext i32 %1670 to i64
  store i64 %1671, i64* %RCX, align 8, !tbaa !2428
  %1672 = icmp eq i32 %1669, -1
  %1673 = icmp eq i32 %1670, 0
  %1674 = or i1 %1672, %1673
  %1675 = zext i1 %1674 to i8
  store i8 %1675, i8* %16, align 1, !tbaa !2432
  %1676 = and i32 %1670, 255
  %1677 = tail call i32 @llvm.ctpop.i32(i32 %1676) #11
  %1678 = trunc i32 %1677 to i8
  %1679 = and i8 %1678, 1
  %1680 = xor i8 %1679, 1
  store i8 %1680, i8* %23, align 1, !tbaa !2446
  %1681 = xor i32 %1670, %1669
  %1682 = lshr i32 %1681, 4
  %1683 = trunc i32 %1682 to i8
  %1684 = and i8 %1683, 1
  store i8 %1684, i8* %29, align 1, !tbaa !2447
  %1685 = zext i1 %1673 to i8
  store i8 %1685, i8* %32, align 1, !tbaa !2448
  %1686 = lshr i32 %1670, 31
  %1687 = trunc i32 %1686 to i8
  store i8 %1687, i8* %35, align 1, !tbaa !2449
  %1688 = lshr i32 %1669, 31
  %1689 = xor i32 %1686, %1688
  %1690 = add nuw nsw i32 %1689, %1686
  %1691 = icmp eq i32 %1690, 2
  %1692 = zext i1 %1691 to i8
  store i8 %1692, i8* %41, align 1, !tbaa !2450
  %1693 = sext i32 %1670 to i64
  store i64 %1693, i64* %RSI, align 8, !tbaa !2428
  %1694 = shl nsw i64 %1693, 3
  %1695 = add i64 %1694, %1665
  %1696 = add i64 %1652, 31
  store i64 %1696, i64* %PC, align 8
  %1697 = inttoptr i64 %1695 to double*
  store double %1661, double* %1697, align 8
  %1698 = load i64, i64* %RBP, align 8
  %1699 = add i64 %1698, -128
  %1700 = load i64, i64* %PC, align 8
  %1701 = add i64 %1700, 5
  store i64 %1701, i64* %PC, align 8
  %1702 = inttoptr i64 %1699 to i64*
  %1703 = load i64, i64* %1702, align 8
  store i64 %1703, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1704 = add i64 %1698, -96
  %1705 = add i64 %1700, 10
  store i64 %1705, i64* %PC, align 8
  %1706 = inttoptr i64 %1704 to double*
  %1707 = load double, double* %1706, align 8
  %1708 = bitcast i64 %1703 to double
  %1709 = fsub double %1707, %1708
  store double %1709, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %1710 = add i64 %1700, 19
  store i64 %1710, i64* %PC, align 8
  store double %1709, double* %1706, align 8
  %1711 = load i64, i64* %RBP, align 8
  %1712 = add i64 %1711, -136
  %1713 = load i64, i64* %PC, align 8
  %1714 = add i64 %1713, 8
  store i64 %1714, i64* %PC, align 8
  %1715 = inttoptr i64 %1712 to i64*
  %1716 = load i64, i64* %1715, align 8
  store i64 %1716, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1717 = add i64 %1711, -104
  %1718 = add i64 %1713, 13
  store i64 %1718, i64* %PC, align 8
  %1719 = inttoptr i64 %1717 to double*
  %1720 = load double, double* %1719, align 8
  %1721 = bitcast i64 %1716 to double
  %1722 = fsub double %1720, %1721
  store double %1722, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %1723 = add i64 %1713, 22
  store i64 %1723, i64* %PC, align 8
  store double %1722, double* %1719, align 8
  %1724 = load i64, i64* %RBP, align 8
  %1725 = add i64 %1724, -64
  %1726 = load i64, i64* %PC, align 8
  %1727 = add i64 %1726, 5
  store i64 %1727, i64* %PC, align 8
  %1728 = inttoptr i64 %1725 to i64*
  %1729 = load i64, i64* %1728, align 8
  store i64 %1729, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1730 = add i64 %1724, -96
  %1731 = add i64 %1726, 10
  store i64 %1731, i64* %PC, align 8
  %1732 = bitcast i64 %1729 to double
  %1733 = inttoptr i64 %1730 to double*
  %1734 = load double, double* %1733, align 8
  %1735 = fmul double %1732, %1734
  store double %1735, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1736 = add i64 %1724, -72
  %1737 = add i64 %1726, 15
  store i64 %1737, i64* %PC, align 8
  %1738 = inttoptr i64 %1736 to i64*
  %1739 = load i64, i64* %1738, align 8
  store i64 %1739, i64* %828, align 1, !tbaa !2451
  store double 0.000000e+00, double* %829, align 1, !tbaa !2451
  %1740 = add i64 %1724, -104
  %1741 = add i64 %1726, 20
  store i64 %1741, i64* %PC, align 8
  %1742 = bitcast i64 %1739 to double
  %1743 = inttoptr i64 %1740 to double*
  %1744 = load double, double* %1743, align 8
  %1745 = fmul double %1742, %1744
  store double %1745, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %1746 = fsub double %1735, %1745
  store double %1746, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1747 = add i64 %1724, -16
  %1748 = add i64 %1726, 28
  store i64 %1748, i64* %PC, align 8
  %1749 = inttoptr i64 %1747 to i64*
  %1750 = load i64, i64* %1749, align 8
  store i64 %1750, i64* %RDX, align 8, !tbaa !2428
  %1751 = add i64 %1724, -28
  %1752 = add i64 %1726, 31
  store i64 %1752, i64* %PC, align 8
  %1753 = inttoptr i64 %1751 to i32*
  %1754 = load i32, i32* %1753, align 4
  %1755 = add i32 %1754, 4
  %1756 = zext i32 %1755 to i64
  store i64 %1756, i64* %RCX, align 8, !tbaa !2428
  %1757 = icmp ugt i32 %1754, -5
  %1758 = zext i1 %1757 to i8
  store i8 %1758, i8* %16, align 1, !tbaa !2432
  %1759 = and i32 %1755, 255
  %1760 = tail call i32 @llvm.ctpop.i32(i32 %1759) #11
  %1761 = trunc i32 %1760 to i8
  %1762 = and i8 %1761, 1
  %1763 = xor i8 %1762, 1
  store i8 %1763, i8* %23, align 1, !tbaa !2446
  %1764 = xor i32 %1755, %1754
  %1765 = lshr i32 %1764, 4
  %1766 = trunc i32 %1765 to i8
  %1767 = and i8 %1766, 1
  store i8 %1767, i8* %29, align 1, !tbaa !2447
  %1768 = icmp eq i32 %1755, 0
  %1769 = zext i1 %1768 to i8
  store i8 %1769, i8* %32, align 1, !tbaa !2448
  %1770 = lshr i32 %1755, 31
  %1771 = trunc i32 %1770 to i8
  store i8 %1771, i8* %35, align 1, !tbaa !2449
  %1772 = lshr i32 %1754, 31
  %1773 = xor i32 %1770, %1772
  %1774 = add nuw nsw i32 %1773, %1770
  %1775 = icmp eq i32 %1774, 2
  %1776 = zext i1 %1775 to i8
  store i8 %1776, i8* %41, align 1, !tbaa !2450
  %1777 = sext i32 %1755 to i64
  store i64 %1777, i64* %RSI, align 8, !tbaa !2428
  %1778 = shl nsw i64 %1777, 3
  %1779 = add i64 %1778, %1750
  %1780 = add i64 %1726, 42
  store i64 %1780, i64* %PC, align 8
  %1781 = inttoptr i64 %1779 to double*
  store double %1746, double* %1781, align 8
  %1782 = load i64, i64* %RBP, align 8
  %1783 = add i64 %1782, -64
  %1784 = load i64, i64* %PC, align 8
  %1785 = add i64 %1784, 5
  store i64 %1785, i64* %PC, align 8
  %1786 = inttoptr i64 %1783 to i64*
  %1787 = load i64, i64* %1786, align 8
  store i64 %1787, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1788 = add i64 %1782, -104
  %1789 = add i64 %1784, 10
  store i64 %1789, i64* %PC, align 8
  %1790 = bitcast i64 %1787 to double
  %1791 = inttoptr i64 %1788 to double*
  %1792 = load double, double* %1791, align 8
  %1793 = fmul double %1790, %1792
  store double %1793, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1794 = add i64 %1782, -72
  %1795 = add i64 %1784, 15
  store i64 %1795, i64* %PC, align 8
  %1796 = inttoptr i64 %1794 to i64*
  %1797 = load i64, i64* %1796, align 8
  store i64 %1797, i64* %828, align 1, !tbaa !2451
  store double 0.000000e+00, double* %829, align 1, !tbaa !2451
  %1798 = add i64 %1782, -96
  %1799 = add i64 %1784, 20
  store i64 %1799, i64* %PC, align 8
  %1800 = bitcast i64 %1797 to double
  %1801 = inttoptr i64 %1798 to double*
  %1802 = load double, double* %1801, align 8
  %1803 = fmul double %1800, %1802
  store double %1803, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %1804 = fadd double %1793, %1803
  store double %1804, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1805 = add i64 %1782, -16
  %1806 = add i64 %1784, 28
  store i64 %1806, i64* %PC, align 8
  %1807 = inttoptr i64 %1805 to i64*
  %1808 = load i64, i64* %1807, align 8
  store i64 %1808, i64* %RDX, align 8, !tbaa !2428
  %1809 = add i64 %1782, -28
  %1810 = add i64 %1784, 31
  store i64 %1810, i64* %PC, align 8
  %1811 = inttoptr i64 %1809 to i32*
  %1812 = load i32, i32* %1811, align 4
  %1813 = add i32 %1812, 5
  %1814 = zext i32 %1813 to i64
  store i64 %1814, i64* %RCX, align 8, !tbaa !2428
  %1815 = icmp ugt i32 %1812, -6
  %1816 = zext i1 %1815 to i8
  store i8 %1816, i8* %16, align 1, !tbaa !2432
  %1817 = and i32 %1813, 255
  %1818 = tail call i32 @llvm.ctpop.i32(i32 %1817) #11
  %1819 = trunc i32 %1818 to i8
  %1820 = and i8 %1819, 1
  %1821 = xor i8 %1820, 1
  store i8 %1821, i8* %23, align 1, !tbaa !2446
  %1822 = xor i32 %1813, %1812
  %1823 = lshr i32 %1822, 4
  %1824 = trunc i32 %1823 to i8
  %1825 = and i8 %1824, 1
  store i8 %1825, i8* %29, align 1, !tbaa !2447
  %1826 = icmp eq i32 %1813, 0
  %1827 = zext i1 %1826 to i8
  store i8 %1827, i8* %32, align 1, !tbaa !2448
  %1828 = lshr i32 %1813, 31
  %1829 = trunc i32 %1828 to i8
  store i8 %1829, i8* %35, align 1, !tbaa !2449
  %1830 = lshr i32 %1812, 31
  %1831 = xor i32 %1828, %1830
  %1832 = add nuw nsw i32 %1831, %1828
  %1833 = icmp eq i32 %1832, 2
  %1834 = zext i1 %1833 to i8
  store i8 %1834, i8* %41, align 1, !tbaa !2450
  %1835 = sext i32 %1813 to i64
  store i64 %1835, i64* %RSI, align 8, !tbaa !2428
  %1836 = shl nsw i64 %1835, 3
  %1837 = add i64 %1836, %1808
  %1838 = add i64 %1784, 42
  store i64 %1838, i64* %PC, align 8
  %1839 = inttoptr i64 %1837 to double*
  store double %1804, double* %1839, align 8
  %1840 = load i64, i64* %RBP, align 8
  %1841 = add i64 %1840, -112
  %1842 = load i64, i64* %PC, align 8
  %1843 = add i64 %1842, 5
  store i64 %1843, i64* %PC, align 8
  %1844 = inttoptr i64 %1841 to i64*
  %1845 = load i64, i64* %1844, align 8
  store i64 %1845, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1846 = add i64 %1840, -152
  %1847 = add i64 %1842, 13
  store i64 %1847, i64* %PC, align 8
  %1848 = bitcast i64 %1845 to double
  %1849 = inttoptr i64 %1846 to double*
  %1850 = load double, double* %1849, align 8
  %1851 = fsub double %1848, %1850
  store double %1851, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1852 = add i64 %1840, -96
  %1853 = add i64 %1842, 18
  store i64 %1853, i64* %PC, align 8
  %1854 = inttoptr i64 %1852 to double*
  store double %1851, double* %1854, align 8
  %1855 = load i64, i64* %RBP, align 8
  %1856 = add i64 %1855, -120
  %1857 = load i64, i64* %PC, align 8
  %1858 = add i64 %1857, 5
  store i64 %1858, i64* %PC, align 8
  %1859 = inttoptr i64 %1856 to i64*
  %1860 = load i64, i64* %1859, align 8
  store i64 %1860, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1861 = add i64 %1855, -144
  %1862 = add i64 %1857, 13
  store i64 %1862, i64* %PC, align 8
  %1863 = bitcast i64 %1860 to double
  %1864 = inttoptr i64 %1861 to double*
  %1865 = load double, double* %1864, align 8
  %1866 = fadd double %1863, %1865
  store double %1866, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1867 = add i64 %1855, -104
  %1868 = add i64 %1857, 18
  store i64 %1868, i64* %PC, align 8
  %1869 = inttoptr i64 %1867 to double*
  store double %1866, double* %1869, align 8
  %1870 = load i64, i64* %RBP, align 8
  %1871 = add i64 %1870, -48
  %1872 = load i64, i64* %PC, align 8
  %1873 = add i64 %1872, 5
  store i64 %1873, i64* %PC, align 8
  %1874 = inttoptr i64 %1871 to i64*
  %1875 = load i64, i64* %1874, align 8
  store i64 %1875, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1876 = add i64 %1870, -96
  %1877 = add i64 %1872, 10
  store i64 %1877, i64* %PC, align 8
  %1878 = bitcast i64 %1875 to double
  %1879 = inttoptr i64 %1876 to double*
  %1880 = load double, double* %1879, align 8
  %1881 = fmul double %1878, %1880
  store double %1881, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1882 = add i64 %1870, -56
  %1883 = add i64 %1872, 15
  store i64 %1883, i64* %PC, align 8
  %1884 = inttoptr i64 %1882 to i64*
  %1885 = load i64, i64* %1884, align 8
  store i64 %1885, i64* %828, align 1, !tbaa !2451
  store double 0.000000e+00, double* %829, align 1, !tbaa !2451
  %1886 = add i64 %1870, -104
  %1887 = add i64 %1872, 20
  store i64 %1887, i64* %PC, align 8
  %1888 = bitcast i64 %1885 to double
  %1889 = inttoptr i64 %1886 to double*
  %1890 = load double, double* %1889, align 8
  %1891 = fmul double %1888, %1890
  store double %1891, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %1892 = fsub double %1881, %1891
  store double %1892, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1893 = add i64 %1870, -16
  %1894 = add i64 %1872, 28
  store i64 %1894, i64* %PC, align 8
  %1895 = inttoptr i64 %1893 to i64*
  %1896 = load i64, i64* %1895, align 8
  store i64 %1896, i64* %RDX, align 8, !tbaa !2428
  %1897 = add i64 %1870, -28
  %1898 = add i64 %1872, 31
  store i64 %1898, i64* %PC, align 8
  %1899 = inttoptr i64 %1897 to i32*
  %1900 = load i32, i32* %1899, align 4
  %1901 = add i32 %1900, 2
  %1902 = zext i32 %1901 to i64
  store i64 %1902, i64* %RCX, align 8, !tbaa !2428
  %1903 = icmp ugt i32 %1900, -3
  %1904 = zext i1 %1903 to i8
  store i8 %1904, i8* %16, align 1, !tbaa !2432
  %1905 = and i32 %1901, 255
  %1906 = tail call i32 @llvm.ctpop.i32(i32 %1905) #11
  %1907 = trunc i32 %1906 to i8
  %1908 = and i8 %1907, 1
  %1909 = xor i8 %1908, 1
  store i8 %1909, i8* %23, align 1, !tbaa !2446
  %1910 = xor i32 %1901, %1900
  %1911 = lshr i32 %1910, 4
  %1912 = trunc i32 %1911 to i8
  %1913 = and i8 %1912, 1
  store i8 %1913, i8* %29, align 1, !tbaa !2447
  %1914 = icmp eq i32 %1901, 0
  %1915 = zext i1 %1914 to i8
  store i8 %1915, i8* %32, align 1, !tbaa !2448
  %1916 = lshr i32 %1901, 31
  %1917 = trunc i32 %1916 to i8
  store i8 %1917, i8* %35, align 1, !tbaa !2449
  %1918 = lshr i32 %1900, 31
  %1919 = xor i32 %1916, %1918
  %1920 = add nuw nsw i32 %1919, %1916
  %1921 = icmp eq i32 %1920, 2
  %1922 = zext i1 %1921 to i8
  store i8 %1922, i8* %41, align 1, !tbaa !2450
  %1923 = sext i32 %1901 to i64
  store i64 %1923, i64* %RSI, align 8, !tbaa !2428
  %1924 = shl nsw i64 %1923, 3
  %1925 = add i64 %1924, %1896
  %1926 = add i64 %1872, 42
  store i64 %1926, i64* %PC, align 8
  %1927 = inttoptr i64 %1925 to double*
  store double %1892, double* %1927, align 8
  %1928 = load i64, i64* %RBP, align 8
  %1929 = add i64 %1928, -48
  %1930 = load i64, i64* %PC, align 8
  %1931 = add i64 %1930, 5
  store i64 %1931, i64* %PC, align 8
  %1932 = inttoptr i64 %1929 to i64*
  %1933 = load i64, i64* %1932, align 8
  store i64 %1933, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1934 = add i64 %1928, -104
  %1935 = add i64 %1930, 10
  store i64 %1935, i64* %PC, align 8
  %1936 = bitcast i64 %1933 to double
  %1937 = inttoptr i64 %1934 to double*
  %1938 = load double, double* %1937, align 8
  %1939 = fmul double %1936, %1938
  store double %1939, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1940 = add i64 %1928, -56
  %1941 = add i64 %1930, 15
  store i64 %1941, i64* %PC, align 8
  %1942 = inttoptr i64 %1940 to i64*
  %1943 = load i64, i64* %1942, align 8
  store i64 %1943, i64* %828, align 1, !tbaa !2451
  store double 0.000000e+00, double* %829, align 1, !tbaa !2451
  %1944 = add i64 %1928, -96
  %1945 = add i64 %1930, 20
  store i64 %1945, i64* %PC, align 8
  %1946 = bitcast i64 %1943 to double
  %1947 = inttoptr i64 %1944 to double*
  %1948 = load double, double* %1947, align 8
  %1949 = fmul double %1946, %1948
  store double %1949, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %1950 = fadd double %1939, %1949
  store double %1950, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1951 = add i64 %1928, -16
  %1952 = add i64 %1930, 28
  store i64 %1952, i64* %PC, align 8
  %1953 = inttoptr i64 %1951 to i64*
  %1954 = load i64, i64* %1953, align 8
  store i64 %1954, i64* %RDX, align 8, !tbaa !2428
  %1955 = add i64 %1928, -28
  %1956 = add i64 %1930, 31
  store i64 %1956, i64* %PC, align 8
  %1957 = inttoptr i64 %1955 to i32*
  %1958 = load i32, i32* %1957, align 4
  %1959 = add i32 %1958, 3
  %1960 = zext i32 %1959 to i64
  store i64 %1960, i64* %RCX, align 8, !tbaa !2428
  %1961 = icmp ugt i32 %1958, -4
  %1962 = zext i1 %1961 to i8
  store i8 %1962, i8* %16, align 1, !tbaa !2432
  %1963 = and i32 %1959, 255
  %1964 = tail call i32 @llvm.ctpop.i32(i32 %1963) #11
  %1965 = trunc i32 %1964 to i8
  %1966 = and i8 %1965, 1
  %1967 = xor i8 %1966, 1
  store i8 %1967, i8* %23, align 1, !tbaa !2446
  %1968 = xor i32 %1959, %1958
  %1969 = lshr i32 %1968, 4
  %1970 = trunc i32 %1969 to i8
  %1971 = and i8 %1970, 1
  store i8 %1971, i8* %29, align 1, !tbaa !2447
  %1972 = icmp eq i32 %1959, 0
  %1973 = zext i1 %1972 to i8
  store i8 %1973, i8* %32, align 1, !tbaa !2448
  %1974 = lshr i32 %1959, 31
  %1975 = trunc i32 %1974 to i8
  store i8 %1975, i8* %35, align 1, !tbaa !2449
  %1976 = lshr i32 %1958, 31
  %1977 = xor i32 %1974, %1976
  %1978 = add nuw nsw i32 %1977, %1974
  %1979 = icmp eq i32 %1978, 2
  %1980 = zext i1 %1979 to i8
  store i8 %1980, i8* %41, align 1, !tbaa !2450
  %1981 = sext i32 %1959 to i64
  store i64 %1981, i64* %RSI, align 8, !tbaa !2428
  %1982 = shl nsw i64 %1981, 3
  %1983 = add i64 %1982, %1954
  %1984 = add i64 %1930, 42
  store i64 %1984, i64* %PC, align 8
  %1985 = inttoptr i64 %1983 to double*
  store double %1950, double* %1985, align 8
  %1986 = load i64, i64* %RBP, align 8
  %1987 = add i64 %1986, -112
  %1988 = load i64, i64* %PC, align 8
  %1989 = add i64 %1988, 5
  store i64 %1989, i64* %PC, align 8
  %1990 = inttoptr i64 %1987 to i64*
  %1991 = load i64, i64* %1990, align 8
  store i64 %1991, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %1992 = add i64 %1986, -152
  %1993 = add i64 %1988, 13
  store i64 %1993, i64* %PC, align 8
  %1994 = bitcast i64 %1991 to double
  %1995 = inttoptr i64 %1992 to double*
  %1996 = load double, double* %1995, align 8
  %1997 = fadd double %1994, %1996
  store double %1997, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %1998 = add i64 %1986, -96
  %1999 = add i64 %1988, 18
  store i64 %1999, i64* %PC, align 8
  %2000 = inttoptr i64 %1998 to double*
  store double %1997, double* %2000, align 8
  %2001 = load i64, i64* %RBP, align 8
  %2002 = add i64 %2001, -120
  %2003 = load i64, i64* %PC, align 8
  %2004 = add i64 %2003, 5
  store i64 %2004, i64* %PC, align 8
  %2005 = inttoptr i64 %2002 to i64*
  %2006 = load i64, i64* %2005, align 8
  store i64 %2006, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %2007 = add i64 %2001, -144
  %2008 = add i64 %2003, 13
  store i64 %2008, i64* %PC, align 8
  %2009 = bitcast i64 %2006 to double
  %2010 = inttoptr i64 %2007 to double*
  %2011 = load double, double* %2010, align 8
  %2012 = fsub double %2009, %2011
  store double %2012, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2013 = add i64 %2001, -104
  %2014 = add i64 %2003, 18
  store i64 %2014, i64* %PC, align 8
  %2015 = inttoptr i64 %2013 to double*
  store double %2012, double* %2015, align 8
  %2016 = load i64, i64* %RBP, align 8
  %2017 = add i64 %2016, -80
  %2018 = load i64, i64* %PC, align 8
  %2019 = add i64 %2018, 5
  store i64 %2019, i64* %PC, align 8
  %2020 = inttoptr i64 %2017 to i64*
  %2021 = load i64, i64* %2020, align 8
  store i64 %2021, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %2022 = add i64 %2016, -96
  %2023 = add i64 %2018, 10
  store i64 %2023, i64* %PC, align 8
  %2024 = bitcast i64 %2021 to double
  %2025 = inttoptr i64 %2022 to double*
  %2026 = load double, double* %2025, align 8
  %2027 = fmul double %2024, %2026
  store double %2027, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2028 = add i64 %2016, -88
  %2029 = add i64 %2018, 15
  store i64 %2029, i64* %PC, align 8
  %2030 = inttoptr i64 %2028 to i64*
  %2031 = load i64, i64* %2030, align 8
  store i64 %2031, i64* %828, align 1, !tbaa !2451
  store double 0.000000e+00, double* %829, align 1, !tbaa !2451
  %2032 = add i64 %2016, -104
  %2033 = add i64 %2018, 20
  store i64 %2033, i64* %PC, align 8
  %2034 = bitcast i64 %2031 to double
  %2035 = inttoptr i64 %2032 to double*
  %2036 = load double, double* %2035, align 8
  %2037 = fmul double %2034, %2036
  store double %2037, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %2038 = fsub double %2027, %2037
  store double %2038, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2039 = add i64 %2016, -16
  %2040 = add i64 %2018, 28
  store i64 %2040, i64* %PC, align 8
  %2041 = inttoptr i64 %2039 to i64*
  %2042 = load i64, i64* %2041, align 8
  store i64 %2042, i64* %RDX, align 8, !tbaa !2428
  %2043 = add i64 %2016, -28
  %2044 = add i64 %2018, 31
  store i64 %2044, i64* %PC, align 8
  %2045 = inttoptr i64 %2043 to i32*
  %2046 = load i32, i32* %2045, align 4
  %2047 = add i32 %2046, 6
  %2048 = zext i32 %2047 to i64
  store i64 %2048, i64* %RCX, align 8, !tbaa !2428
  %2049 = icmp ugt i32 %2046, -7
  %2050 = zext i1 %2049 to i8
  store i8 %2050, i8* %16, align 1, !tbaa !2432
  %2051 = and i32 %2047, 255
  %2052 = tail call i32 @llvm.ctpop.i32(i32 %2051) #11
  %2053 = trunc i32 %2052 to i8
  %2054 = and i8 %2053, 1
  %2055 = xor i8 %2054, 1
  store i8 %2055, i8* %23, align 1, !tbaa !2446
  %2056 = xor i32 %2047, %2046
  %2057 = lshr i32 %2056, 4
  %2058 = trunc i32 %2057 to i8
  %2059 = and i8 %2058, 1
  store i8 %2059, i8* %29, align 1, !tbaa !2447
  %2060 = icmp eq i32 %2047, 0
  %2061 = zext i1 %2060 to i8
  store i8 %2061, i8* %32, align 1, !tbaa !2448
  %2062 = lshr i32 %2047, 31
  %2063 = trunc i32 %2062 to i8
  store i8 %2063, i8* %35, align 1, !tbaa !2449
  %2064 = lshr i32 %2046, 31
  %2065 = xor i32 %2062, %2064
  %2066 = add nuw nsw i32 %2065, %2062
  %2067 = icmp eq i32 %2066, 2
  %2068 = zext i1 %2067 to i8
  store i8 %2068, i8* %41, align 1, !tbaa !2450
  %2069 = sext i32 %2047 to i64
  store i64 %2069, i64* %RSI, align 8, !tbaa !2428
  %2070 = shl nsw i64 %2069, 3
  %2071 = add i64 %2070, %2042
  %2072 = add i64 %2018, 42
  store i64 %2072, i64* %PC, align 8
  %2073 = inttoptr i64 %2071 to double*
  store double %2038, double* %2073, align 8
  %2074 = load i64, i64* %RBP, align 8
  %2075 = add i64 %2074, -80
  %2076 = load i64, i64* %PC, align 8
  %2077 = add i64 %2076, 5
  store i64 %2077, i64* %PC, align 8
  %2078 = inttoptr i64 %2075 to i64*
  %2079 = load i64, i64* %2078, align 8
  store i64 %2079, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %2080 = add i64 %2074, -104
  %2081 = add i64 %2076, 10
  store i64 %2081, i64* %PC, align 8
  %2082 = bitcast i64 %2079 to double
  %2083 = inttoptr i64 %2080 to double*
  %2084 = load double, double* %2083, align 8
  %2085 = fmul double %2082, %2084
  store double %2085, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2086 = add i64 %2074, -88
  %2087 = add i64 %2076, 15
  store i64 %2087, i64* %PC, align 8
  %2088 = inttoptr i64 %2086 to i64*
  %2089 = load i64, i64* %2088, align 8
  store i64 %2089, i64* %828, align 1, !tbaa !2451
  store double 0.000000e+00, double* %829, align 1, !tbaa !2451
  %2090 = add i64 %2074, -96
  %2091 = add i64 %2076, 20
  store i64 %2091, i64* %PC, align 8
  %2092 = bitcast i64 %2089 to double
  %2093 = inttoptr i64 %2090 to double*
  %2094 = load double, double* %2093, align 8
  %2095 = fmul double %2092, %2094
  store double %2095, double* %821, align 1, !tbaa !2451
  store i64 0, i64* %817, align 1, !tbaa !2451
  %2096 = fadd double %2085, %2095
  store double %2096, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2097 = add i64 %2074, -16
  %2098 = add i64 %2076, 28
  store i64 %2098, i64* %PC, align 8
  %2099 = inttoptr i64 %2097 to i64*
  %2100 = load i64, i64* %2099, align 8
  store i64 %2100, i64* %RDX, align 8, !tbaa !2428
  %2101 = add i64 %2074, -28
  %2102 = add i64 %2076, 31
  store i64 %2102, i64* %PC, align 8
  %2103 = inttoptr i64 %2101 to i32*
  %2104 = load i32, i32* %2103, align 4
  %2105 = add i32 %2104, 7
  %2106 = zext i32 %2105 to i64
  store i64 %2106, i64* %RCX, align 8, !tbaa !2428
  %2107 = icmp ugt i32 %2104, -8
  %2108 = zext i1 %2107 to i8
  store i8 %2108, i8* %16, align 1, !tbaa !2432
  %2109 = and i32 %2105, 255
  %2110 = tail call i32 @llvm.ctpop.i32(i32 %2109) #11
  %2111 = trunc i32 %2110 to i8
  %2112 = and i8 %2111, 1
  %2113 = xor i8 %2112, 1
  store i8 %2113, i8* %23, align 1, !tbaa !2446
  %2114 = xor i32 %2105, %2104
  %2115 = lshr i32 %2114, 4
  %2116 = trunc i32 %2115 to i8
  %2117 = and i8 %2116, 1
  store i8 %2117, i8* %29, align 1, !tbaa !2447
  %2118 = icmp eq i32 %2105, 0
  %2119 = zext i1 %2118 to i8
  store i8 %2119, i8* %32, align 1, !tbaa !2448
  %2120 = lshr i32 %2105, 31
  %2121 = trunc i32 %2120 to i8
  store i8 %2121, i8* %35, align 1, !tbaa !2449
  %2122 = lshr i32 %2104, 31
  %2123 = xor i32 %2120, %2122
  %2124 = add nuw nsw i32 %2123, %2120
  %2125 = icmp eq i32 %2124, 2
  %2126 = zext i1 %2125 to i8
  store i8 %2126, i8* %41, align 1, !tbaa !2450
  %2127 = sext i32 %2105 to i64
  store i64 %2127, i64* %RSI, align 8, !tbaa !2428
  %2128 = shl nsw i64 %2127, 3
  %2129 = add i64 %2128, %2100
  %2130 = add i64 %2076, 42
  store i64 %2130, i64* %PC, align 8
  %2131 = inttoptr i64 %2129 to double*
  store double %2096, double* %2131, align 8
  %2132 = load i64, i64* %RBP, align 8
  %2133 = add i64 %2132, -24
  %2134 = load i64, i64* %PC, align 8
  %2135 = add i64 %2134, 4
  store i64 %2135, i64* %PC, align 8
  %2136 = inttoptr i64 %2133 to i64*
  %2137 = load i64, i64* %2136, align 8
  store i64 %2137, i64* %RDX, align 8, !tbaa !2428
  %2138 = add i64 %2132, -36
  %2139 = add i64 %2134, 7
  store i64 %2139, i64* %PC, align 8
  %2140 = inttoptr i64 %2138 to i32*
  %2141 = load i32, i32* %2140, align 4
  %2142 = add i32 %2141, 2
  %2143 = zext i32 %2142 to i64
  store i64 %2143, i64* %RCX, align 8, !tbaa !2428
  %2144 = icmp ugt i32 %2141, -3
  %2145 = zext i1 %2144 to i8
  store i8 %2145, i8* %16, align 1, !tbaa !2432
  %2146 = and i32 %2142, 255
  %2147 = tail call i32 @llvm.ctpop.i32(i32 %2146) #11
  %2148 = trunc i32 %2147 to i8
  %2149 = and i8 %2148, 1
  %2150 = xor i8 %2149, 1
  store i8 %2150, i8* %23, align 1, !tbaa !2446
  %2151 = xor i32 %2142, %2141
  %2152 = lshr i32 %2151, 4
  %2153 = trunc i32 %2152 to i8
  %2154 = and i8 %2153, 1
  store i8 %2154, i8* %29, align 1, !tbaa !2447
  %2155 = icmp eq i32 %2142, 0
  %2156 = zext i1 %2155 to i8
  store i8 %2156, i8* %32, align 1, !tbaa !2448
  %2157 = lshr i32 %2142, 31
  %2158 = trunc i32 %2157 to i8
  store i8 %2158, i8* %35, align 1, !tbaa !2449
  %2159 = lshr i32 %2141, 31
  %2160 = xor i32 %2157, %2159
  %2161 = add nuw nsw i32 %2160, %2157
  %2162 = icmp eq i32 %2161, 2
  %2163 = zext i1 %2162 to i8
  store i8 %2163, i8* %41, align 1, !tbaa !2450
  %2164 = sext i32 %2142 to i64
  store i64 %2164, i64* %RSI, align 8, !tbaa !2428
  %2165 = shl nsw i64 %2164, 3
  %2166 = add i64 %2165, %2137
  %2167 = add i64 %2134, 18
  store i64 %2167, i64* %PC, align 8
  %2168 = inttoptr i64 %2166 to i64*
  %2169 = load i64, i64* %2168, align 8
  store i64 %2169, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %2170 = add i64 %2132, -48
  %2171 = add i64 %2134, 23
  store i64 %2171, i64* %PC, align 8
  %2172 = inttoptr i64 %2170 to i64*
  store i64 %2169, i64* %2172, align 8
  %2173 = load i64, i64* %RBP, align 8
  %2174 = add i64 %2173, -24
  %2175 = load i64, i64* %PC, align 8
  %2176 = add i64 %2175, 4
  store i64 %2176, i64* %PC, align 8
  %2177 = inttoptr i64 %2174 to i64*
  %2178 = load i64, i64* %2177, align 8
  store i64 %2178, i64* %RDX, align 8, !tbaa !2428
  %2179 = add i64 %2173, -36
  %2180 = add i64 %2175, 7
  store i64 %2180, i64* %PC, align 8
  %2181 = inttoptr i64 %2179 to i32*
  %2182 = load i32, i32* %2181, align 4
  %2183 = add i32 %2182, 3
  %2184 = zext i32 %2183 to i64
  store i64 %2184, i64* %RCX, align 8, !tbaa !2428
  %2185 = icmp ugt i32 %2182, -4
  %2186 = zext i1 %2185 to i8
  store i8 %2186, i8* %16, align 1, !tbaa !2432
  %2187 = and i32 %2183, 255
  %2188 = tail call i32 @llvm.ctpop.i32(i32 %2187) #11
  %2189 = trunc i32 %2188 to i8
  %2190 = and i8 %2189, 1
  %2191 = xor i8 %2190, 1
  store i8 %2191, i8* %23, align 1, !tbaa !2446
  %2192 = xor i32 %2183, %2182
  %2193 = lshr i32 %2192, 4
  %2194 = trunc i32 %2193 to i8
  %2195 = and i8 %2194, 1
  store i8 %2195, i8* %29, align 1, !tbaa !2447
  %2196 = icmp eq i32 %2183, 0
  %2197 = zext i1 %2196 to i8
  store i8 %2197, i8* %32, align 1, !tbaa !2448
  %2198 = lshr i32 %2183, 31
  %2199 = trunc i32 %2198 to i8
  store i8 %2199, i8* %35, align 1, !tbaa !2449
  %2200 = lshr i32 %2182, 31
  %2201 = xor i32 %2198, %2200
  %2202 = add nuw nsw i32 %2201, %2198
  %2203 = icmp eq i32 %2202, 2
  %2204 = zext i1 %2203 to i8
  store i8 %2204, i8* %41, align 1, !tbaa !2450
  %2205 = sext i32 %2183 to i64
  store i64 %2205, i64* %RSI, align 8, !tbaa !2428
  %2206 = shl nsw i64 %2205, 3
  %2207 = add i64 %2206, %2178
  %2208 = add i64 %2175, 18
  store i64 %2208, i64* %PC, align 8
  %2209 = inttoptr i64 %2207 to i64*
  %2210 = load i64, i64* %2209, align 8
  store i64 %2210, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %2211 = add i64 %2173, -56
  %2212 = add i64 %2175, 23
  store i64 %2212, i64* %PC, align 8
  %2213 = inttoptr i64 %2211 to i64*
  store i64 %2210, i64* %2213, align 8
  %2214 = load i64, i64* %RBP, align 8
  %2215 = add i64 %2214, -48
  %2216 = load i64, i64* %PC, align 8
  %2217 = add i64 %2216, 5
  store i64 %2217, i64* %PC, align 8
  %2218 = inttoptr i64 %2215 to i64*
  %2219 = load i64, i64* %2218, align 8
  store i64 %2219, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %2220 = load <2 x i32>, <2 x i32>* %812, align 1
  %2221 = load <2 x i32>, <2 x i32>* %813, align 1
  %2222 = extractelement <2 x i32> %2220, i32 0
  store i32 %2222, i32* %814, align 1, !tbaa !2475
  %2223 = extractelement <2 x i32> %2220, i32 1
  store i32 %2223, i32* %816, align 1, !tbaa !2475
  %2224 = extractelement <2 x i32> %2221, i32 0
  store i32 %2224, i32* %818, align 1, !tbaa !2475
  %2225 = extractelement <2 x i32> %2221, i32 1
  store i32 %2225, i32* %820, align 1, !tbaa !2475
  %2226 = add i64 %2214, -64
  %2227 = add i64 %2216, 13
  store i64 %2227, i64* %PC, align 8
  %2228 = load double, double* %821, align 1
  %2229 = inttoptr i64 %2226 to double*
  %2230 = load double, double* %2229, align 8
  %2231 = fmul double %2228, %2230
  store double %2231, double* %821, align 1, !tbaa !2451
  %2232 = add i64 %2214, -56
  %2233 = add i64 %2216, 18
  store i64 %2233, i64* %PC, align 8
  %2234 = inttoptr i64 %2232 to double*
  %2235 = load double, double* %2234, align 8
  %2236 = fmul double %2231, %2235
  store double %2236, double* %821, align 1, !tbaa !2451
  %2237 = bitcast i64 %2219 to double
  %2238 = fsub double %2237, %2236
  store double %2238, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2239 = add i64 %2214, -80
  %2240 = add i64 %2216, 27
  store i64 %2240, i64* %PC, align 8
  %2241 = inttoptr i64 %2239 to double*
  store double %2238, double* %2241, align 8
  %2242 = load i64, i64* %RBP, align 8
  %2243 = add i64 %2242, -64
  %2244 = load i64, i64* %PC, align 8
  %2245 = add i64 %2244, 5
  store i64 %2245, i64* %PC, align 8
  %2246 = load double, double* %67, align 1
  %2247 = inttoptr i64 %2243 to double*
  %2248 = load double, double* %2247, align 8
  %2249 = fmul double %2246, %2248
  store double %2249, double* %67, align 1, !tbaa !2451
  %2250 = add i64 %2242, -48
  %2251 = add i64 %2244, 10
  store i64 %2251, i64* %PC, align 8
  %2252 = inttoptr i64 %2250 to double*
  %2253 = load double, double* %2252, align 8
  %2254 = fmul double %2249, %2253
  store double %2254, double* %67, align 1, !tbaa !2451
  %2255 = add i64 %2242, -56
  %2256 = add i64 %2244, 15
  store i64 %2256, i64* %PC, align 8
  %2257 = inttoptr i64 %2255 to double*
  %2258 = load double, double* %2257, align 8
  %2259 = fsub double %2254, %2258
  store double %2259, double* %67, align 1, !tbaa !2451
  %2260 = add i64 %2242, -88
  %2261 = add i64 %2244, 20
  store i64 %2261, i64* %PC, align 8
  %2262 = inttoptr i64 %2260 to double*
  store double %2259, double* %2262, align 8
  %2263 = load i64, i64* %RBP, align 8
  %2264 = add i64 %2263, -16
  %2265 = load i64, i64* %PC, align 8
  %2266 = add i64 %2265, 4
  store i64 %2266, i64* %PC, align 8
  %2267 = inttoptr i64 %2264 to i64*
  %2268 = load i64, i64* %2267, align 8
  store i64 %2268, i64* %RDX, align 8, !tbaa !2428
  %2269 = add i64 %2263, -28
  %2270 = add i64 %2265, 7
  store i64 %2270, i64* %PC, align 8
  %2271 = inttoptr i64 %2269 to i32*
  %2272 = load i32, i32* %2271, align 4
  %2273 = add i32 %2272, 8
  %2274 = zext i32 %2273 to i64
  store i64 %2274, i64* %RCX, align 8, !tbaa !2428
  %2275 = icmp ugt i32 %2272, -9
  %2276 = zext i1 %2275 to i8
  store i8 %2276, i8* %16, align 1, !tbaa !2432
  %2277 = and i32 %2273, 255
  %2278 = tail call i32 @llvm.ctpop.i32(i32 %2277) #11
  %2279 = trunc i32 %2278 to i8
  %2280 = and i8 %2279, 1
  %2281 = xor i8 %2280, 1
  store i8 %2281, i8* %23, align 1, !tbaa !2446
  %2282 = xor i32 %2273, %2272
  %2283 = lshr i32 %2282, 4
  %2284 = trunc i32 %2283 to i8
  %2285 = and i8 %2284, 1
  store i8 %2285, i8* %29, align 1, !tbaa !2447
  %2286 = icmp eq i32 %2273, 0
  %2287 = zext i1 %2286 to i8
  store i8 %2287, i8* %32, align 1, !tbaa !2448
  %2288 = lshr i32 %2273, 31
  %2289 = trunc i32 %2288 to i8
  store i8 %2289, i8* %35, align 1, !tbaa !2449
  %2290 = lshr i32 %2272, 31
  %2291 = xor i32 %2288, %2290
  %2292 = add nuw nsw i32 %2291, %2288
  %2293 = icmp eq i32 %2292, 2
  %2294 = zext i1 %2293 to i8
  store i8 %2294, i8* %41, align 1, !tbaa !2450
  %2295 = sext i32 %2273 to i64
  store i64 %2295, i64* %RSI, align 8, !tbaa !2428
  %2296 = shl nsw i64 %2295, 3
  %2297 = add i64 %2296, %2268
  %2298 = add i64 %2265, 18
  store i64 %2298, i64* %PC, align 8
  %2299 = inttoptr i64 %2297 to i64*
  %2300 = load i64, i64* %2299, align 8
  store i64 %2300, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2301 = add i64 %2265, 22
  store i64 %2301, i64* %PC, align 8
  %2302 = load i64, i64* %2267, align 8
  store i64 %2302, i64* %RDX, align 8, !tbaa !2428
  %2303 = add i64 %2265, 25
  store i64 %2303, i64* %PC, align 8
  %2304 = load i32, i32* %2271, align 4
  %2305 = add i32 %2304, 10
  %2306 = zext i32 %2305 to i64
  store i64 %2306, i64* %RCX, align 8, !tbaa !2428
  %2307 = icmp ugt i32 %2304, -11
  %2308 = zext i1 %2307 to i8
  store i8 %2308, i8* %16, align 1, !tbaa !2432
  %2309 = and i32 %2305, 255
  %2310 = tail call i32 @llvm.ctpop.i32(i32 %2309) #11
  %2311 = trunc i32 %2310 to i8
  %2312 = and i8 %2311, 1
  %2313 = xor i8 %2312, 1
  store i8 %2313, i8* %23, align 1, !tbaa !2446
  %2314 = xor i32 %2305, %2304
  %2315 = lshr i32 %2314, 4
  %2316 = trunc i32 %2315 to i8
  %2317 = and i8 %2316, 1
  store i8 %2317, i8* %29, align 1, !tbaa !2447
  %2318 = icmp eq i32 %2305, 0
  %2319 = zext i1 %2318 to i8
  store i8 %2319, i8* %32, align 1, !tbaa !2448
  %2320 = lshr i32 %2305, 31
  %2321 = trunc i32 %2320 to i8
  store i8 %2321, i8* %35, align 1, !tbaa !2449
  %2322 = lshr i32 %2304, 31
  %2323 = xor i32 %2320, %2322
  %2324 = add nuw nsw i32 %2323, %2320
  %2325 = icmp eq i32 %2324, 2
  %2326 = zext i1 %2325 to i8
  store i8 %2326, i8* %41, align 1, !tbaa !2450
  %2327 = sext i32 %2305 to i64
  store i64 %2327, i64* %RSI, align 8, !tbaa !2428
  %2328 = shl nsw i64 %2327, 3
  %2329 = add i64 %2328, %2302
  %2330 = add i64 %2265, 36
  store i64 %2330, i64* %PC, align 8
  %2331 = bitcast i64 %2300 to double
  %2332 = inttoptr i64 %2329 to double*
  %2333 = load double, double* %2332, align 8
  %2334 = fadd double %2331, %2333
  store double %2334, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2335 = load i64, i64* %RBP, align 8
  %2336 = add i64 %2335, -96
  %2337 = add i64 %2265, 41
  store i64 %2337, i64* %PC, align 8
  %2338 = inttoptr i64 %2336 to double*
  store double %2334, double* %2338, align 8
  %2339 = load i64, i64* %RBP, align 8
  %2340 = add i64 %2339, -16
  %2341 = load i64, i64* %PC, align 8
  %2342 = add i64 %2341, 4
  store i64 %2342, i64* %PC, align 8
  %2343 = inttoptr i64 %2340 to i64*
  %2344 = load i64, i64* %2343, align 8
  store i64 %2344, i64* %RDX, align 8, !tbaa !2428
  %2345 = add i64 %2339, -28
  %2346 = add i64 %2341, 7
  store i64 %2346, i64* %PC, align 8
  %2347 = inttoptr i64 %2345 to i32*
  %2348 = load i32, i32* %2347, align 4
  %2349 = add i32 %2348, 9
  %2350 = zext i32 %2349 to i64
  store i64 %2350, i64* %RCX, align 8, !tbaa !2428
  %2351 = icmp ugt i32 %2348, -10
  %2352 = zext i1 %2351 to i8
  store i8 %2352, i8* %16, align 1, !tbaa !2432
  %2353 = and i32 %2349, 255
  %2354 = tail call i32 @llvm.ctpop.i32(i32 %2353) #11
  %2355 = trunc i32 %2354 to i8
  %2356 = and i8 %2355, 1
  %2357 = xor i8 %2356, 1
  store i8 %2357, i8* %23, align 1, !tbaa !2446
  %2358 = xor i32 %2349, %2348
  %2359 = lshr i32 %2358, 4
  %2360 = trunc i32 %2359 to i8
  %2361 = and i8 %2360, 1
  store i8 %2361, i8* %29, align 1, !tbaa !2447
  %2362 = icmp eq i32 %2349, 0
  %2363 = zext i1 %2362 to i8
  store i8 %2363, i8* %32, align 1, !tbaa !2448
  %2364 = lshr i32 %2349, 31
  %2365 = trunc i32 %2364 to i8
  store i8 %2365, i8* %35, align 1, !tbaa !2449
  %2366 = lshr i32 %2348, 31
  %2367 = xor i32 %2364, %2366
  %2368 = add nuw nsw i32 %2367, %2364
  %2369 = icmp eq i32 %2368, 2
  %2370 = zext i1 %2369 to i8
  store i8 %2370, i8* %41, align 1, !tbaa !2450
  %2371 = sext i32 %2349 to i64
  store i64 %2371, i64* %RSI, align 8, !tbaa !2428
  %2372 = shl nsw i64 %2371, 3
  %2373 = add i64 %2372, %2344
  %2374 = add i64 %2341, 18
  store i64 %2374, i64* %PC, align 8
  %2375 = inttoptr i64 %2373 to i64*
  %2376 = load i64, i64* %2375, align 8
  store i64 %2376, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2377 = add i64 %2341, 22
  store i64 %2377, i64* %PC, align 8
  %2378 = load i64, i64* %2343, align 8
  store i64 %2378, i64* %RDX, align 8, !tbaa !2428
  %2379 = add i64 %2341, 25
  store i64 %2379, i64* %PC, align 8
  %2380 = load i32, i32* %2347, align 4
  %2381 = add i32 %2380, 11
  %2382 = zext i32 %2381 to i64
  store i64 %2382, i64* %RCX, align 8, !tbaa !2428
  %2383 = icmp ugt i32 %2380, -12
  %2384 = zext i1 %2383 to i8
  store i8 %2384, i8* %16, align 1, !tbaa !2432
  %2385 = and i32 %2381, 255
  %2386 = tail call i32 @llvm.ctpop.i32(i32 %2385) #11
  %2387 = trunc i32 %2386 to i8
  %2388 = and i8 %2387, 1
  %2389 = xor i8 %2388, 1
  store i8 %2389, i8* %23, align 1, !tbaa !2446
  %2390 = xor i32 %2381, %2380
  %2391 = lshr i32 %2390, 4
  %2392 = trunc i32 %2391 to i8
  %2393 = and i8 %2392, 1
  store i8 %2393, i8* %29, align 1, !tbaa !2447
  %2394 = icmp eq i32 %2381, 0
  %2395 = zext i1 %2394 to i8
  store i8 %2395, i8* %32, align 1, !tbaa !2448
  %2396 = lshr i32 %2381, 31
  %2397 = trunc i32 %2396 to i8
  store i8 %2397, i8* %35, align 1, !tbaa !2449
  %2398 = lshr i32 %2380, 31
  %2399 = xor i32 %2396, %2398
  %2400 = add nuw nsw i32 %2399, %2396
  %2401 = icmp eq i32 %2400, 2
  %2402 = zext i1 %2401 to i8
  store i8 %2402, i8* %41, align 1, !tbaa !2450
  %2403 = sext i32 %2381 to i64
  store i64 %2403, i64* %RSI, align 8, !tbaa !2428
  %2404 = shl nsw i64 %2403, 3
  %2405 = add i64 %2404, %2378
  %2406 = add i64 %2341, 36
  store i64 %2406, i64* %PC, align 8
  %2407 = bitcast i64 %2376 to double
  %2408 = inttoptr i64 %2405 to double*
  %2409 = load double, double* %2408, align 8
  %2410 = fadd double %2407, %2409
  store double %2410, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2411 = load i64, i64* %RBP, align 8
  %2412 = add i64 %2411, -104
  %2413 = add i64 %2341, 41
  store i64 %2413, i64* %PC, align 8
  %2414 = inttoptr i64 %2412 to double*
  store double %2410, double* %2414, align 8
  %2415 = load i64, i64* %RBP, align 8
  %2416 = add i64 %2415, -16
  %2417 = load i64, i64* %PC, align 8
  %2418 = add i64 %2417, 4
  store i64 %2418, i64* %PC, align 8
  %2419 = inttoptr i64 %2416 to i64*
  %2420 = load i64, i64* %2419, align 8
  store i64 %2420, i64* %RDX, align 8, !tbaa !2428
  %2421 = add i64 %2415, -28
  %2422 = add i64 %2417, 7
  store i64 %2422, i64* %PC, align 8
  %2423 = inttoptr i64 %2421 to i32*
  %2424 = load i32, i32* %2423, align 4
  %2425 = add i32 %2424, 8
  %2426 = zext i32 %2425 to i64
  store i64 %2426, i64* %RCX, align 8, !tbaa !2428
  %2427 = icmp ugt i32 %2424, -9
  %2428 = zext i1 %2427 to i8
  store i8 %2428, i8* %16, align 1, !tbaa !2432
  %2429 = and i32 %2425, 255
  %2430 = tail call i32 @llvm.ctpop.i32(i32 %2429) #11
  %2431 = trunc i32 %2430 to i8
  %2432 = and i8 %2431, 1
  %2433 = xor i8 %2432, 1
  store i8 %2433, i8* %23, align 1, !tbaa !2446
  %2434 = xor i32 %2425, %2424
  %2435 = lshr i32 %2434, 4
  %2436 = trunc i32 %2435 to i8
  %2437 = and i8 %2436, 1
  store i8 %2437, i8* %29, align 1, !tbaa !2447
  %2438 = icmp eq i32 %2425, 0
  %2439 = zext i1 %2438 to i8
  store i8 %2439, i8* %32, align 1, !tbaa !2448
  %2440 = lshr i32 %2425, 31
  %2441 = trunc i32 %2440 to i8
  store i8 %2441, i8* %35, align 1, !tbaa !2449
  %2442 = lshr i32 %2424, 31
  %2443 = xor i32 %2440, %2442
  %2444 = add nuw nsw i32 %2443, %2440
  %2445 = icmp eq i32 %2444, 2
  %2446 = zext i1 %2445 to i8
  store i8 %2446, i8* %41, align 1, !tbaa !2450
  %2447 = sext i32 %2425 to i64
  store i64 %2447, i64* %RSI, align 8, !tbaa !2428
  %2448 = shl nsw i64 %2447, 3
  %2449 = add i64 %2448, %2420
  %2450 = add i64 %2417, 18
  store i64 %2450, i64* %PC, align 8
  %2451 = inttoptr i64 %2449 to i64*
  %2452 = load i64, i64* %2451, align 8
  store i64 %2452, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2453 = add i64 %2417, 22
  store i64 %2453, i64* %PC, align 8
  %2454 = load i64, i64* %2419, align 8
  store i64 %2454, i64* %RDX, align 8, !tbaa !2428
  %2455 = add i64 %2417, 25
  store i64 %2455, i64* %PC, align 8
  %2456 = load i32, i32* %2423, align 4
  %2457 = add i32 %2456, 10
  %2458 = zext i32 %2457 to i64
  store i64 %2458, i64* %RCX, align 8, !tbaa !2428
  %2459 = icmp ugt i32 %2456, -11
  %2460 = zext i1 %2459 to i8
  store i8 %2460, i8* %16, align 1, !tbaa !2432
  %2461 = and i32 %2457, 255
  %2462 = tail call i32 @llvm.ctpop.i32(i32 %2461) #11
  %2463 = trunc i32 %2462 to i8
  %2464 = and i8 %2463, 1
  %2465 = xor i8 %2464, 1
  store i8 %2465, i8* %23, align 1, !tbaa !2446
  %2466 = xor i32 %2457, %2456
  %2467 = lshr i32 %2466, 4
  %2468 = trunc i32 %2467 to i8
  %2469 = and i8 %2468, 1
  store i8 %2469, i8* %29, align 1, !tbaa !2447
  %2470 = icmp eq i32 %2457, 0
  %2471 = zext i1 %2470 to i8
  store i8 %2471, i8* %32, align 1, !tbaa !2448
  %2472 = lshr i32 %2457, 31
  %2473 = trunc i32 %2472 to i8
  store i8 %2473, i8* %35, align 1, !tbaa !2449
  %2474 = lshr i32 %2456, 31
  %2475 = xor i32 %2472, %2474
  %2476 = add nuw nsw i32 %2475, %2472
  %2477 = icmp eq i32 %2476, 2
  %2478 = zext i1 %2477 to i8
  store i8 %2478, i8* %41, align 1, !tbaa !2450
  %2479 = sext i32 %2457 to i64
  store i64 %2479, i64* %RSI, align 8, !tbaa !2428
  %2480 = shl nsw i64 %2479, 3
  %2481 = add i64 %2480, %2454
  %2482 = add i64 %2417, 36
  store i64 %2482, i64* %PC, align 8
  %2483 = bitcast i64 %2452 to double
  %2484 = inttoptr i64 %2481 to double*
  %2485 = load double, double* %2484, align 8
  %2486 = fsub double %2483, %2485
  store double %2486, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2487 = load i64, i64* %RBP, align 8
  %2488 = add i64 %2487, -112
  %2489 = add i64 %2417, 41
  store i64 %2489, i64* %PC, align 8
  %2490 = inttoptr i64 %2488 to double*
  store double %2486, double* %2490, align 8
  %2491 = load i64, i64* %RBP, align 8
  %2492 = add i64 %2491, -16
  %2493 = load i64, i64* %PC, align 8
  %2494 = add i64 %2493, 4
  store i64 %2494, i64* %PC, align 8
  %2495 = inttoptr i64 %2492 to i64*
  %2496 = load i64, i64* %2495, align 8
  store i64 %2496, i64* %RDX, align 8, !tbaa !2428
  %2497 = add i64 %2491, -28
  %2498 = add i64 %2493, 7
  store i64 %2498, i64* %PC, align 8
  %2499 = inttoptr i64 %2497 to i32*
  %2500 = load i32, i32* %2499, align 4
  %2501 = add i32 %2500, 9
  %2502 = zext i32 %2501 to i64
  store i64 %2502, i64* %RCX, align 8, !tbaa !2428
  %2503 = icmp ugt i32 %2500, -10
  %2504 = zext i1 %2503 to i8
  store i8 %2504, i8* %16, align 1, !tbaa !2432
  %2505 = and i32 %2501, 255
  %2506 = tail call i32 @llvm.ctpop.i32(i32 %2505) #11
  %2507 = trunc i32 %2506 to i8
  %2508 = and i8 %2507, 1
  %2509 = xor i8 %2508, 1
  store i8 %2509, i8* %23, align 1, !tbaa !2446
  %2510 = xor i32 %2501, %2500
  %2511 = lshr i32 %2510, 4
  %2512 = trunc i32 %2511 to i8
  %2513 = and i8 %2512, 1
  store i8 %2513, i8* %29, align 1, !tbaa !2447
  %2514 = icmp eq i32 %2501, 0
  %2515 = zext i1 %2514 to i8
  store i8 %2515, i8* %32, align 1, !tbaa !2448
  %2516 = lshr i32 %2501, 31
  %2517 = trunc i32 %2516 to i8
  store i8 %2517, i8* %35, align 1, !tbaa !2449
  %2518 = lshr i32 %2500, 31
  %2519 = xor i32 %2516, %2518
  %2520 = add nuw nsw i32 %2519, %2516
  %2521 = icmp eq i32 %2520, 2
  %2522 = zext i1 %2521 to i8
  store i8 %2522, i8* %41, align 1, !tbaa !2450
  %2523 = sext i32 %2501 to i64
  store i64 %2523, i64* %RSI, align 8, !tbaa !2428
  %2524 = shl nsw i64 %2523, 3
  %2525 = add i64 %2524, %2496
  %2526 = add i64 %2493, 18
  store i64 %2526, i64* %PC, align 8
  %2527 = inttoptr i64 %2525 to i64*
  %2528 = load i64, i64* %2527, align 8
  store i64 %2528, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2529 = add i64 %2493, 22
  store i64 %2529, i64* %PC, align 8
  %2530 = load i64, i64* %2495, align 8
  store i64 %2530, i64* %RDX, align 8, !tbaa !2428
  %2531 = add i64 %2493, 25
  store i64 %2531, i64* %PC, align 8
  %2532 = load i32, i32* %2499, align 4
  %2533 = add i32 %2532, 11
  %2534 = zext i32 %2533 to i64
  store i64 %2534, i64* %RCX, align 8, !tbaa !2428
  %2535 = icmp ugt i32 %2532, -12
  %2536 = zext i1 %2535 to i8
  store i8 %2536, i8* %16, align 1, !tbaa !2432
  %2537 = and i32 %2533, 255
  %2538 = tail call i32 @llvm.ctpop.i32(i32 %2537) #11
  %2539 = trunc i32 %2538 to i8
  %2540 = and i8 %2539, 1
  %2541 = xor i8 %2540, 1
  store i8 %2541, i8* %23, align 1, !tbaa !2446
  %2542 = xor i32 %2533, %2532
  %2543 = lshr i32 %2542, 4
  %2544 = trunc i32 %2543 to i8
  %2545 = and i8 %2544, 1
  store i8 %2545, i8* %29, align 1, !tbaa !2447
  %2546 = icmp eq i32 %2533, 0
  %2547 = zext i1 %2546 to i8
  store i8 %2547, i8* %32, align 1, !tbaa !2448
  %2548 = lshr i32 %2533, 31
  %2549 = trunc i32 %2548 to i8
  store i8 %2549, i8* %35, align 1, !tbaa !2449
  %2550 = lshr i32 %2532, 31
  %2551 = xor i32 %2548, %2550
  %2552 = add nuw nsw i32 %2551, %2548
  %2553 = icmp eq i32 %2552, 2
  %2554 = zext i1 %2553 to i8
  store i8 %2554, i8* %41, align 1, !tbaa !2450
  %2555 = sext i32 %2533 to i64
  store i64 %2555, i64* %RSI, align 8, !tbaa !2428
  %2556 = shl nsw i64 %2555, 3
  %2557 = add i64 %2556, %2530
  %2558 = add i64 %2493, 36
  store i64 %2558, i64* %PC, align 8
  %2559 = bitcast i64 %2528 to double
  %2560 = inttoptr i64 %2557 to double*
  %2561 = load double, double* %2560, align 8
  %2562 = fsub double %2559, %2561
  store double %2562, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2563 = load i64, i64* %RBP, align 8
  %2564 = add i64 %2563, -120
  %2565 = add i64 %2493, 41
  store i64 %2565, i64* %PC, align 8
  %2566 = inttoptr i64 %2564 to double*
  store double %2562, double* %2566, align 8
  %2567 = load i64, i64* %RBP, align 8
  %2568 = add i64 %2567, -16
  %2569 = load i64, i64* %PC, align 8
  %2570 = add i64 %2569, 4
  store i64 %2570, i64* %PC, align 8
  %2571 = inttoptr i64 %2568 to i64*
  %2572 = load i64, i64* %2571, align 8
  store i64 %2572, i64* %RDX, align 8, !tbaa !2428
  %2573 = add i64 %2567, -28
  %2574 = add i64 %2569, 7
  store i64 %2574, i64* %PC, align 8
  %2575 = inttoptr i64 %2573 to i32*
  %2576 = load i32, i32* %2575, align 4
  %2577 = add i32 %2576, 12
  %2578 = zext i32 %2577 to i64
  store i64 %2578, i64* %RCX, align 8, !tbaa !2428
  %2579 = icmp ugt i32 %2576, -13
  %2580 = zext i1 %2579 to i8
  store i8 %2580, i8* %16, align 1, !tbaa !2432
  %2581 = and i32 %2577, 255
  %2582 = tail call i32 @llvm.ctpop.i32(i32 %2581) #11
  %2583 = trunc i32 %2582 to i8
  %2584 = and i8 %2583, 1
  %2585 = xor i8 %2584, 1
  store i8 %2585, i8* %23, align 1, !tbaa !2446
  %2586 = xor i32 %2577, %2576
  %2587 = lshr i32 %2586, 4
  %2588 = trunc i32 %2587 to i8
  %2589 = and i8 %2588, 1
  store i8 %2589, i8* %29, align 1, !tbaa !2447
  %2590 = icmp eq i32 %2577, 0
  %2591 = zext i1 %2590 to i8
  store i8 %2591, i8* %32, align 1, !tbaa !2448
  %2592 = lshr i32 %2577, 31
  %2593 = trunc i32 %2592 to i8
  store i8 %2593, i8* %35, align 1, !tbaa !2449
  %2594 = lshr i32 %2576, 31
  %2595 = xor i32 %2592, %2594
  %2596 = add nuw nsw i32 %2595, %2592
  %2597 = icmp eq i32 %2596, 2
  %2598 = zext i1 %2597 to i8
  store i8 %2598, i8* %41, align 1, !tbaa !2450
  %2599 = sext i32 %2577 to i64
  store i64 %2599, i64* %RSI, align 8, !tbaa !2428
  %2600 = shl nsw i64 %2599, 3
  %2601 = add i64 %2600, %2572
  %2602 = add i64 %2569, 18
  store i64 %2602, i64* %PC, align 8
  %2603 = inttoptr i64 %2601 to i64*
  %2604 = load i64, i64* %2603, align 8
  store i64 %2604, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2605 = add i64 %2569, 22
  store i64 %2605, i64* %PC, align 8
  %2606 = load i64, i64* %2571, align 8
  store i64 %2606, i64* %RDX, align 8, !tbaa !2428
  %2607 = add i64 %2569, 25
  store i64 %2607, i64* %PC, align 8
  %2608 = load i32, i32* %2575, align 4
  %2609 = add i32 %2608, 14
  %2610 = zext i32 %2609 to i64
  store i64 %2610, i64* %RCX, align 8, !tbaa !2428
  %2611 = icmp ugt i32 %2608, -15
  %2612 = zext i1 %2611 to i8
  store i8 %2612, i8* %16, align 1, !tbaa !2432
  %2613 = and i32 %2609, 255
  %2614 = tail call i32 @llvm.ctpop.i32(i32 %2613) #11
  %2615 = trunc i32 %2614 to i8
  %2616 = and i8 %2615, 1
  %2617 = xor i8 %2616, 1
  store i8 %2617, i8* %23, align 1, !tbaa !2446
  %2618 = xor i32 %2609, %2608
  %2619 = lshr i32 %2618, 4
  %2620 = trunc i32 %2619 to i8
  %2621 = and i8 %2620, 1
  store i8 %2621, i8* %29, align 1, !tbaa !2447
  %2622 = icmp eq i32 %2609, 0
  %2623 = zext i1 %2622 to i8
  store i8 %2623, i8* %32, align 1, !tbaa !2448
  %2624 = lshr i32 %2609, 31
  %2625 = trunc i32 %2624 to i8
  store i8 %2625, i8* %35, align 1, !tbaa !2449
  %2626 = lshr i32 %2608, 31
  %2627 = xor i32 %2624, %2626
  %2628 = add nuw nsw i32 %2627, %2624
  %2629 = icmp eq i32 %2628, 2
  %2630 = zext i1 %2629 to i8
  store i8 %2630, i8* %41, align 1, !tbaa !2450
  %2631 = sext i32 %2609 to i64
  store i64 %2631, i64* %RSI, align 8, !tbaa !2428
  %2632 = shl nsw i64 %2631, 3
  %2633 = add i64 %2632, %2606
  %2634 = add i64 %2569, 36
  store i64 %2634, i64* %PC, align 8
  %2635 = bitcast i64 %2604 to double
  %2636 = inttoptr i64 %2633 to double*
  %2637 = load double, double* %2636, align 8
  %2638 = fadd double %2635, %2637
  store double %2638, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2639 = load i64, i64* %RBP, align 8
  %2640 = add i64 %2639, -128
  %2641 = add i64 %2569, 41
  store i64 %2641, i64* %PC, align 8
  %2642 = inttoptr i64 %2640 to double*
  store double %2638, double* %2642, align 8
  %2643 = load i64, i64* %RBP, align 8
  %2644 = add i64 %2643, -16
  %2645 = load i64, i64* %PC, align 8
  %2646 = add i64 %2645, 4
  store i64 %2646, i64* %PC, align 8
  %2647 = inttoptr i64 %2644 to i64*
  %2648 = load i64, i64* %2647, align 8
  store i64 %2648, i64* %RDX, align 8, !tbaa !2428
  %2649 = add i64 %2643, -28
  %2650 = add i64 %2645, 7
  store i64 %2650, i64* %PC, align 8
  %2651 = inttoptr i64 %2649 to i32*
  %2652 = load i32, i32* %2651, align 4
  %2653 = add i32 %2652, 13
  %2654 = zext i32 %2653 to i64
  store i64 %2654, i64* %RCX, align 8, !tbaa !2428
  %2655 = icmp ugt i32 %2652, -14
  %2656 = zext i1 %2655 to i8
  store i8 %2656, i8* %16, align 1, !tbaa !2432
  %2657 = and i32 %2653, 255
  %2658 = tail call i32 @llvm.ctpop.i32(i32 %2657) #11
  %2659 = trunc i32 %2658 to i8
  %2660 = and i8 %2659, 1
  %2661 = xor i8 %2660, 1
  store i8 %2661, i8* %23, align 1, !tbaa !2446
  %2662 = xor i32 %2653, %2652
  %2663 = lshr i32 %2662, 4
  %2664 = trunc i32 %2663 to i8
  %2665 = and i8 %2664, 1
  store i8 %2665, i8* %29, align 1, !tbaa !2447
  %2666 = icmp eq i32 %2653, 0
  %2667 = zext i1 %2666 to i8
  store i8 %2667, i8* %32, align 1, !tbaa !2448
  %2668 = lshr i32 %2653, 31
  %2669 = trunc i32 %2668 to i8
  store i8 %2669, i8* %35, align 1, !tbaa !2449
  %2670 = lshr i32 %2652, 31
  %2671 = xor i32 %2668, %2670
  %2672 = add nuw nsw i32 %2671, %2668
  %2673 = icmp eq i32 %2672, 2
  %2674 = zext i1 %2673 to i8
  store i8 %2674, i8* %41, align 1, !tbaa !2450
  %2675 = sext i32 %2653 to i64
  store i64 %2675, i64* %RSI, align 8, !tbaa !2428
  %2676 = shl nsw i64 %2675, 3
  %2677 = add i64 %2676, %2648
  %2678 = add i64 %2645, 18
  store i64 %2678, i64* %PC, align 8
  %2679 = inttoptr i64 %2677 to i64*
  %2680 = load i64, i64* %2679, align 8
  store i64 %2680, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2681 = add i64 %2645, 22
  store i64 %2681, i64* %PC, align 8
  %2682 = load i64, i64* %2647, align 8
  store i64 %2682, i64* %RDX, align 8, !tbaa !2428
  %2683 = add i64 %2645, 25
  store i64 %2683, i64* %PC, align 8
  %2684 = load i32, i32* %2651, align 4
  %2685 = add i32 %2684, 15
  %2686 = zext i32 %2685 to i64
  store i64 %2686, i64* %RCX, align 8, !tbaa !2428
  %2687 = icmp ugt i32 %2684, -16
  %2688 = zext i1 %2687 to i8
  store i8 %2688, i8* %16, align 1, !tbaa !2432
  %2689 = and i32 %2685, 255
  %2690 = tail call i32 @llvm.ctpop.i32(i32 %2689) #11
  %2691 = trunc i32 %2690 to i8
  %2692 = and i8 %2691, 1
  %2693 = xor i8 %2692, 1
  store i8 %2693, i8* %23, align 1, !tbaa !2446
  %2694 = xor i32 %2685, %2684
  %2695 = lshr i32 %2694, 4
  %2696 = trunc i32 %2695 to i8
  %2697 = and i8 %2696, 1
  store i8 %2697, i8* %29, align 1, !tbaa !2447
  %2698 = icmp eq i32 %2685, 0
  %2699 = zext i1 %2698 to i8
  store i8 %2699, i8* %32, align 1, !tbaa !2448
  %2700 = lshr i32 %2685, 31
  %2701 = trunc i32 %2700 to i8
  store i8 %2701, i8* %35, align 1, !tbaa !2449
  %2702 = lshr i32 %2684, 31
  %2703 = xor i32 %2700, %2702
  %2704 = add nuw nsw i32 %2703, %2700
  %2705 = icmp eq i32 %2704, 2
  %2706 = zext i1 %2705 to i8
  store i8 %2706, i8* %41, align 1, !tbaa !2450
  %2707 = sext i32 %2685 to i64
  store i64 %2707, i64* %RSI, align 8, !tbaa !2428
  %2708 = shl nsw i64 %2707, 3
  %2709 = add i64 %2708, %2682
  %2710 = add i64 %2645, 36
  store i64 %2710, i64* %PC, align 8
  %2711 = bitcast i64 %2680 to double
  %2712 = inttoptr i64 %2709 to double*
  %2713 = load double, double* %2712, align 8
  %2714 = fadd double %2711, %2713
  store double %2714, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2715 = load i64, i64* %RBP, align 8
  %2716 = add i64 %2715, -136
  %2717 = add i64 %2645, 44
  store i64 %2717, i64* %PC, align 8
  %2718 = inttoptr i64 %2716 to double*
  store double %2714, double* %2718, align 8
  %2719 = load i64, i64* %RBP, align 8
  %2720 = add i64 %2719, -16
  %2721 = load i64, i64* %PC, align 8
  %2722 = add i64 %2721, 4
  store i64 %2722, i64* %PC, align 8
  %2723 = inttoptr i64 %2720 to i64*
  %2724 = load i64, i64* %2723, align 8
  store i64 %2724, i64* %RDX, align 8, !tbaa !2428
  %2725 = add i64 %2719, -28
  %2726 = add i64 %2721, 7
  store i64 %2726, i64* %PC, align 8
  %2727 = inttoptr i64 %2725 to i32*
  %2728 = load i32, i32* %2727, align 4
  %2729 = add i32 %2728, 12
  %2730 = zext i32 %2729 to i64
  store i64 %2730, i64* %RCX, align 8, !tbaa !2428
  %2731 = icmp ugt i32 %2728, -13
  %2732 = zext i1 %2731 to i8
  store i8 %2732, i8* %16, align 1, !tbaa !2432
  %2733 = and i32 %2729, 255
  %2734 = tail call i32 @llvm.ctpop.i32(i32 %2733) #11
  %2735 = trunc i32 %2734 to i8
  %2736 = and i8 %2735, 1
  %2737 = xor i8 %2736, 1
  store i8 %2737, i8* %23, align 1, !tbaa !2446
  %2738 = xor i32 %2729, %2728
  %2739 = lshr i32 %2738, 4
  %2740 = trunc i32 %2739 to i8
  %2741 = and i8 %2740, 1
  store i8 %2741, i8* %29, align 1, !tbaa !2447
  %2742 = icmp eq i32 %2729, 0
  %2743 = zext i1 %2742 to i8
  store i8 %2743, i8* %32, align 1, !tbaa !2448
  %2744 = lshr i32 %2729, 31
  %2745 = trunc i32 %2744 to i8
  store i8 %2745, i8* %35, align 1, !tbaa !2449
  %2746 = lshr i32 %2728, 31
  %2747 = xor i32 %2744, %2746
  %2748 = add nuw nsw i32 %2747, %2744
  %2749 = icmp eq i32 %2748, 2
  %2750 = zext i1 %2749 to i8
  store i8 %2750, i8* %41, align 1, !tbaa !2450
  %2751 = sext i32 %2729 to i64
  store i64 %2751, i64* %RSI, align 8, !tbaa !2428
  %2752 = shl nsw i64 %2751, 3
  %2753 = add i64 %2752, %2724
  %2754 = add i64 %2721, 18
  store i64 %2754, i64* %PC, align 8
  %2755 = inttoptr i64 %2753 to i64*
  %2756 = load i64, i64* %2755, align 8
  store i64 %2756, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2757 = add i64 %2721, 22
  store i64 %2757, i64* %PC, align 8
  %2758 = load i64, i64* %2723, align 8
  store i64 %2758, i64* %RDX, align 8, !tbaa !2428
  %2759 = add i64 %2721, 25
  store i64 %2759, i64* %PC, align 8
  %2760 = load i32, i32* %2727, align 4
  %2761 = add i32 %2760, 14
  %2762 = zext i32 %2761 to i64
  store i64 %2762, i64* %RCX, align 8, !tbaa !2428
  %2763 = icmp ugt i32 %2760, -15
  %2764 = zext i1 %2763 to i8
  store i8 %2764, i8* %16, align 1, !tbaa !2432
  %2765 = and i32 %2761, 255
  %2766 = tail call i32 @llvm.ctpop.i32(i32 %2765) #11
  %2767 = trunc i32 %2766 to i8
  %2768 = and i8 %2767, 1
  %2769 = xor i8 %2768, 1
  store i8 %2769, i8* %23, align 1, !tbaa !2446
  %2770 = xor i32 %2761, %2760
  %2771 = lshr i32 %2770, 4
  %2772 = trunc i32 %2771 to i8
  %2773 = and i8 %2772, 1
  store i8 %2773, i8* %29, align 1, !tbaa !2447
  %2774 = icmp eq i32 %2761, 0
  %2775 = zext i1 %2774 to i8
  store i8 %2775, i8* %32, align 1, !tbaa !2448
  %2776 = lshr i32 %2761, 31
  %2777 = trunc i32 %2776 to i8
  store i8 %2777, i8* %35, align 1, !tbaa !2449
  %2778 = lshr i32 %2760, 31
  %2779 = xor i32 %2776, %2778
  %2780 = add nuw nsw i32 %2779, %2776
  %2781 = icmp eq i32 %2780, 2
  %2782 = zext i1 %2781 to i8
  store i8 %2782, i8* %41, align 1, !tbaa !2450
  %2783 = sext i32 %2761 to i64
  store i64 %2783, i64* %RSI, align 8, !tbaa !2428
  %2784 = shl nsw i64 %2783, 3
  %2785 = add i64 %2784, %2758
  %2786 = add i64 %2721, 36
  store i64 %2786, i64* %PC, align 8
  %2787 = bitcast i64 %2756 to double
  %2788 = inttoptr i64 %2785 to double*
  %2789 = load double, double* %2788, align 8
  %2790 = fsub double %2787, %2789
  store double %2790, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2791 = load i64, i64* %RBP, align 8
  %2792 = add i64 %2791, -144
  %2793 = add i64 %2721, 44
  store i64 %2793, i64* %PC, align 8
  %2794 = inttoptr i64 %2792 to double*
  store double %2790, double* %2794, align 8
  %2795 = load i64, i64* %RBP, align 8
  %2796 = add i64 %2795, -16
  %2797 = load i64, i64* %PC, align 8
  %2798 = add i64 %2797, 4
  store i64 %2798, i64* %PC, align 8
  %2799 = inttoptr i64 %2796 to i64*
  %2800 = load i64, i64* %2799, align 8
  store i64 %2800, i64* %RDX, align 8, !tbaa !2428
  %2801 = add i64 %2795, -28
  %2802 = add i64 %2797, 7
  store i64 %2802, i64* %PC, align 8
  %2803 = inttoptr i64 %2801 to i32*
  %2804 = load i32, i32* %2803, align 4
  %2805 = add i32 %2804, 13
  %2806 = zext i32 %2805 to i64
  store i64 %2806, i64* %RCX, align 8, !tbaa !2428
  %2807 = icmp ugt i32 %2804, -14
  %2808 = zext i1 %2807 to i8
  store i8 %2808, i8* %16, align 1, !tbaa !2432
  %2809 = and i32 %2805, 255
  %2810 = tail call i32 @llvm.ctpop.i32(i32 %2809) #11
  %2811 = trunc i32 %2810 to i8
  %2812 = and i8 %2811, 1
  %2813 = xor i8 %2812, 1
  store i8 %2813, i8* %23, align 1, !tbaa !2446
  %2814 = xor i32 %2805, %2804
  %2815 = lshr i32 %2814, 4
  %2816 = trunc i32 %2815 to i8
  %2817 = and i8 %2816, 1
  store i8 %2817, i8* %29, align 1, !tbaa !2447
  %2818 = icmp eq i32 %2805, 0
  %2819 = zext i1 %2818 to i8
  store i8 %2819, i8* %32, align 1, !tbaa !2448
  %2820 = lshr i32 %2805, 31
  %2821 = trunc i32 %2820 to i8
  store i8 %2821, i8* %35, align 1, !tbaa !2449
  %2822 = lshr i32 %2804, 31
  %2823 = xor i32 %2820, %2822
  %2824 = add nuw nsw i32 %2823, %2820
  %2825 = icmp eq i32 %2824, 2
  %2826 = zext i1 %2825 to i8
  store i8 %2826, i8* %41, align 1, !tbaa !2450
  %2827 = sext i32 %2805 to i64
  store i64 %2827, i64* %RSI, align 8, !tbaa !2428
  %2828 = shl nsw i64 %2827, 3
  %2829 = add i64 %2828, %2800
  %2830 = add i64 %2797, 18
  store i64 %2830, i64* %PC, align 8
  %2831 = inttoptr i64 %2829 to i64*
  %2832 = load i64, i64* %2831, align 8
  store i64 %2832, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2833 = add i64 %2797, 22
  store i64 %2833, i64* %PC, align 8
  %2834 = load i64, i64* %2799, align 8
  store i64 %2834, i64* %RDX, align 8, !tbaa !2428
  %2835 = add i64 %2797, 25
  store i64 %2835, i64* %PC, align 8
  %2836 = load i32, i32* %2803, align 4
  %2837 = add i32 %2836, 15
  %2838 = zext i32 %2837 to i64
  store i64 %2838, i64* %RCX, align 8, !tbaa !2428
  %2839 = icmp ugt i32 %2836, -16
  %2840 = zext i1 %2839 to i8
  store i8 %2840, i8* %16, align 1, !tbaa !2432
  %2841 = and i32 %2837, 255
  %2842 = tail call i32 @llvm.ctpop.i32(i32 %2841) #11
  %2843 = trunc i32 %2842 to i8
  %2844 = and i8 %2843, 1
  %2845 = xor i8 %2844, 1
  store i8 %2845, i8* %23, align 1, !tbaa !2446
  %2846 = xor i32 %2837, %2836
  %2847 = lshr i32 %2846, 4
  %2848 = trunc i32 %2847 to i8
  %2849 = and i8 %2848, 1
  store i8 %2849, i8* %29, align 1, !tbaa !2447
  %2850 = icmp eq i32 %2837, 0
  %2851 = zext i1 %2850 to i8
  store i8 %2851, i8* %32, align 1, !tbaa !2448
  %2852 = lshr i32 %2837, 31
  %2853 = trunc i32 %2852 to i8
  store i8 %2853, i8* %35, align 1, !tbaa !2449
  %2854 = lshr i32 %2836, 31
  %2855 = xor i32 %2852, %2854
  %2856 = add nuw nsw i32 %2855, %2852
  %2857 = icmp eq i32 %2856, 2
  %2858 = zext i1 %2857 to i8
  store i8 %2858, i8* %41, align 1, !tbaa !2450
  %2859 = sext i32 %2837 to i64
  store i64 %2859, i64* %RSI, align 8, !tbaa !2428
  %2860 = shl nsw i64 %2859, 3
  %2861 = add i64 %2860, %2834
  %2862 = add i64 %2797, 36
  store i64 %2862, i64* %PC, align 8
  %2863 = bitcast i64 %2832 to double
  %2864 = inttoptr i64 %2861 to double*
  %2865 = load double, double* %2864, align 8
  %2866 = fsub double %2863, %2865
  store double %2866, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2867 = load i64, i64* %RBP, align 8
  %2868 = add i64 %2867, -152
  %2869 = add i64 %2797, 44
  store i64 %2869, i64* %PC, align 8
  %2870 = inttoptr i64 %2868 to double*
  store double %2866, double* %2870, align 8
  %2871 = load i64, i64* %RBP, align 8
  %2872 = add i64 %2871, -96
  %2873 = load i64, i64* %PC, align 8
  %2874 = add i64 %2873, 5
  store i64 %2874, i64* %PC, align 8
  %2875 = inttoptr i64 %2872 to i64*
  %2876 = load i64, i64* %2875, align 8
  store i64 %2876, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2877 = add i64 %2871, -128
  %2878 = add i64 %2873, 10
  store i64 %2878, i64* %PC, align 8
  %2879 = bitcast i64 %2876 to double
  %2880 = inttoptr i64 %2877 to double*
  %2881 = load double, double* %2880, align 8
  %2882 = fadd double %2879, %2881
  store double %2882, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2883 = add i64 %2871, -16
  %2884 = add i64 %2873, 14
  store i64 %2884, i64* %PC, align 8
  %2885 = inttoptr i64 %2883 to i64*
  %2886 = load i64, i64* %2885, align 8
  store i64 %2886, i64* %RDX, align 8, !tbaa !2428
  %2887 = add i64 %2871, -28
  %2888 = add i64 %2873, 17
  store i64 %2888, i64* %PC, align 8
  %2889 = inttoptr i64 %2887 to i32*
  %2890 = load i32, i32* %2889, align 4
  %2891 = add i32 %2890, 8
  %2892 = zext i32 %2891 to i64
  store i64 %2892, i64* %RCX, align 8, !tbaa !2428
  %2893 = icmp ugt i32 %2890, -9
  %2894 = zext i1 %2893 to i8
  store i8 %2894, i8* %16, align 1, !tbaa !2432
  %2895 = and i32 %2891, 255
  %2896 = tail call i32 @llvm.ctpop.i32(i32 %2895) #11
  %2897 = trunc i32 %2896 to i8
  %2898 = and i8 %2897, 1
  %2899 = xor i8 %2898, 1
  store i8 %2899, i8* %23, align 1, !tbaa !2446
  %2900 = xor i32 %2891, %2890
  %2901 = lshr i32 %2900, 4
  %2902 = trunc i32 %2901 to i8
  %2903 = and i8 %2902, 1
  store i8 %2903, i8* %29, align 1, !tbaa !2447
  %2904 = icmp eq i32 %2891, 0
  %2905 = zext i1 %2904 to i8
  store i8 %2905, i8* %32, align 1, !tbaa !2448
  %2906 = lshr i32 %2891, 31
  %2907 = trunc i32 %2906 to i8
  store i8 %2907, i8* %35, align 1, !tbaa !2449
  %2908 = lshr i32 %2890, 31
  %2909 = xor i32 %2906, %2908
  %2910 = add nuw nsw i32 %2909, %2906
  %2911 = icmp eq i32 %2910, 2
  %2912 = zext i1 %2911 to i8
  store i8 %2912, i8* %41, align 1, !tbaa !2450
  %2913 = sext i32 %2891 to i64
  store i64 %2913, i64* %RSI, align 8, !tbaa !2428
  %2914 = shl nsw i64 %2913, 3
  %2915 = add i64 %2914, %2886
  %2916 = add i64 %2873, 28
  store i64 %2916, i64* %PC, align 8
  %2917 = inttoptr i64 %2915 to double*
  store double %2882, double* %2917, align 8
  %2918 = load i64, i64* %RBP, align 8
  %2919 = add i64 %2918, -104
  %2920 = load i64, i64* %PC, align 8
  %2921 = add i64 %2920, 5
  store i64 %2921, i64* %PC, align 8
  %2922 = inttoptr i64 %2919 to i64*
  %2923 = load i64, i64* %2922, align 8
  store i64 %2923, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2924 = add i64 %2918, -136
  %2925 = add i64 %2920, 13
  store i64 %2925, i64* %PC, align 8
  %2926 = bitcast i64 %2923 to double
  %2927 = inttoptr i64 %2924 to double*
  %2928 = load double, double* %2927, align 8
  %2929 = fadd double %2926, %2928
  store double %2929, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %2930 = add i64 %2918, -16
  %2931 = add i64 %2920, 17
  store i64 %2931, i64* %PC, align 8
  %2932 = inttoptr i64 %2930 to i64*
  %2933 = load i64, i64* %2932, align 8
  store i64 %2933, i64* %RDX, align 8, !tbaa !2428
  %2934 = add i64 %2918, -28
  %2935 = add i64 %2920, 20
  store i64 %2935, i64* %PC, align 8
  %2936 = inttoptr i64 %2934 to i32*
  %2937 = load i32, i32* %2936, align 4
  %2938 = add i32 %2937, 9
  %2939 = zext i32 %2938 to i64
  store i64 %2939, i64* %RCX, align 8, !tbaa !2428
  %2940 = icmp ugt i32 %2937, -10
  %2941 = zext i1 %2940 to i8
  store i8 %2941, i8* %16, align 1, !tbaa !2432
  %2942 = and i32 %2938, 255
  %2943 = tail call i32 @llvm.ctpop.i32(i32 %2942) #11
  %2944 = trunc i32 %2943 to i8
  %2945 = and i8 %2944, 1
  %2946 = xor i8 %2945, 1
  store i8 %2946, i8* %23, align 1, !tbaa !2446
  %2947 = xor i32 %2938, %2937
  %2948 = lshr i32 %2947, 4
  %2949 = trunc i32 %2948 to i8
  %2950 = and i8 %2949, 1
  store i8 %2950, i8* %29, align 1, !tbaa !2447
  %2951 = icmp eq i32 %2938, 0
  %2952 = zext i1 %2951 to i8
  store i8 %2952, i8* %32, align 1, !tbaa !2448
  %2953 = lshr i32 %2938, 31
  %2954 = trunc i32 %2953 to i8
  store i8 %2954, i8* %35, align 1, !tbaa !2449
  %2955 = lshr i32 %2937, 31
  %2956 = xor i32 %2953, %2955
  %2957 = add nuw nsw i32 %2956, %2953
  %2958 = icmp eq i32 %2957, 2
  %2959 = zext i1 %2958 to i8
  store i8 %2959, i8* %41, align 1, !tbaa !2450
  %2960 = sext i32 %2938 to i64
  store i64 %2960, i64* %RSI, align 8, !tbaa !2428
  %2961 = shl nsw i64 %2960, 3
  %2962 = add i64 %2961, %2933
  %2963 = add i64 %2920, 31
  store i64 %2963, i64* %PC, align 8
  %2964 = inttoptr i64 %2962 to double*
  store double %2929, double* %2964, align 8
  %2965 = load i64, i64* %RBP, align 8
  %2966 = add i64 %2965, -128
  %2967 = load i64, i64* %PC, align 8
  %2968 = add i64 %2967, 5
  store i64 %2968, i64* %PC, align 8
  %2969 = inttoptr i64 %2966 to i64*
  %2970 = load i64, i64* %2969, align 8
  store i64 %2970, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2971 = add i64 %2965, -96
  %2972 = add i64 %2967, 10
  store i64 %2972, i64* %PC, align 8
  %2973 = inttoptr i64 %2971 to double*
  %2974 = load double, double* %2973, align 8
  %2975 = bitcast i64 %2970 to double
  %2976 = fsub double %2974, %2975
  store double %2976, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2977 = add i64 %2967, 19
  store i64 %2977, i64* %PC, align 8
  store double %2976, double* %2973, align 8
  %2978 = load i64, i64* %RBP, align 8
  %2979 = add i64 %2978, -136
  %2980 = load i64, i64* %PC, align 8
  %2981 = add i64 %2980, 8
  store i64 %2981, i64* %PC, align 8
  %2982 = inttoptr i64 %2979 to i64*
  %2983 = load i64, i64* %2982, align 8
  store i64 %2983, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %2984 = add i64 %2978, -104
  %2985 = add i64 %2980, 13
  store i64 %2985, i64* %PC, align 8
  %2986 = inttoptr i64 %2984 to double*
  %2987 = load double, double* %2986, align 8
  %2988 = bitcast i64 %2983 to double
  %2989 = fsub double %2987, %2988
  store double %2989, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %2990 = add i64 %2980, 22
  store i64 %2990, i64* %PC, align 8
  store double %2989, double* %2986, align 8
  %2991 = load i64, i64* %RBP, align 8
  %2992 = add i64 %2991, -72
  %2993 = load i64, i64* %PC, align 8
  %2994 = add i64 %2993, 5
  store i64 %2994, i64* %PC, align 8
  %2995 = inttoptr i64 %2992 to i64*
  %2996 = load i64, i64* %2995, align 8
  %2997 = load i64, i64* %RAX, align 8
  %2998 = xor i64 %2997, %2996
  store i64 %2998, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %16, align 1, !tbaa !2432
  %2999 = trunc i64 %2998 to i32
  %3000 = and i32 %2999, 255
  %3001 = tail call i32 @llvm.ctpop.i32(i32 %3000) #11
  %3002 = trunc i32 %3001 to i8
  %3003 = and i8 %3002, 1
  %3004 = xor i8 %3003, 1
  store i8 %3004, i8* %23, align 1, !tbaa !2446
  %3005 = icmp eq i64 %2998, 0
  %3006 = zext i1 %3005 to i8
  store i8 %3006, i8* %32, align 1, !tbaa !2448
  %3007 = lshr i64 %2998, 63
  %3008 = trunc i64 %3007 to i8
  store i8 %3008, i8* %35, align 1, !tbaa !2449
  store i8 0, i8* %41, align 1, !tbaa !2450
  store i8 0, i8* %29, align 1, !tbaa !2447
  store i64 %2998, i64* %68, align 1, !tbaa !2428
  store i64 0, i64* %69, align 1, !tbaa !2428
  %3009 = add i64 %2991, -96
  %3010 = add i64 %2993, 23
  store i64 %3010, i64* %PC, align 8
  %.cast4 = bitcast i64 %2998 to double
  %3011 = inttoptr i64 %3009 to double*
  %3012 = load double, double* %3011, align 8
  %3013 = fmul double %.cast4, %3012
  store double %3013, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3014 = add i64 %2991, -64
  %3015 = add i64 %2993, 28
  store i64 %3015, i64* %PC, align 8
  %3016 = inttoptr i64 %3014 to i64*
  %3017 = load i64, i64* %3016, align 8
  store i64 %3017, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %3018 = add i64 %2991, -104
  %3019 = add i64 %2993, 33
  store i64 %3019, i64* %PC, align 8
  %3020 = bitcast i64 %3017 to double
  %3021 = inttoptr i64 %3018 to double*
  %3022 = load double, double* %3021, align 8
  %3023 = fmul double %3020, %3022
  store double %3023, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %3024 = fsub double %3013, %3023
  store double %3024, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3025 = add i64 %2991, -16
  %3026 = add i64 %2993, 41
  store i64 %3026, i64* %PC, align 8
  %3027 = inttoptr i64 %3025 to i64*
  %3028 = load i64, i64* %3027, align 8
  store i64 %3028, i64* %RDX, align 8, !tbaa !2428
  %3029 = add i64 %2991, -28
  %3030 = add i64 %2993, 44
  store i64 %3030, i64* %PC, align 8
  %3031 = inttoptr i64 %3029 to i32*
  %3032 = load i32, i32* %3031, align 4
  %3033 = add i32 %3032, 12
  %3034 = zext i32 %3033 to i64
  store i64 %3034, i64* %RCX, align 8, !tbaa !2428
  %3035 = icmp ugt i32 %3032, -13
  %3036 = zext i1 %3035 to i8
  store i8 %3036, i8* %16, align 1, !tbaa !2432
  %3037 = and i32 %3033, 255
  %3038 = tail call i32 @llvm.ctpop.i32(i32 %3037) #11
  %3039 = trunc i32 %3038 to i8
  %3040 = and i8 %3039, 1
  %3041 = xor i8 %3040, 1
  store i8 %3041, i8* %23, align 1, !tbaa !2446
  %3042 = xor i32 %3033, %3032
  %3043 = lshr i32 %3042, 4
  %3044 = trunc i32 %3043 to i8
  %3045 = and i8 %3044, 1
  store i8 %3045, i8* %29, align 1, !tbaa !2447
  %3046 = icmp eq i32 %3033, 0
  %3047 = zext i1 %3046 to i8
  store i8 %3047, i8* %32, align 1, !tbaa !2448
  %3048 = lshr i32 %3033, 31
  %3049 = trunc i32 %3048 to i8
  store i8 %3049, i8* %35, align 1, !tbaa !2449
  %3050 = lshr i32 %3032, 31
  %3051 = xor i32 %3048, %3050
  %3052 = add nuw nsw i32 %3051, %3048
  %3053 = icmp eq i32 %3052, 2
  %3054 = zext i1 %3053 to i8
  store i8 %3054, i8* %41, align 1, !tbaa !2450
  %3055 = sext i32 %3033 to i64
  store i64 %3055, i64* %RSI, align 8, !tbaa !2428
  %3056 = shl nsw i64 %3055, 3
  %3057 = add i64 %3056, %3028
  %3058 = add i64 %2993, 55
  store i64 %3058, i64* %PC, align 8
  %3059 = inttoptr i64 %3057 to double*
  store double %3024, double* %3059, align 8
  %3060 = load i64, i64* %RBP, align 8
  %3061 = add i64 %3060, -72
  %3062 = load i64, i64* %PC, align 8
  %3063 = add i64 %3062, 5
  store i64 %3063, i64* %PC, align 8
  %3064 = inttoptr i64 %3061 to i64*
  %3065 = load i64, i64* %3064, align 8
  %3066 = load i64, i64* %RAX, align 8
  %3067 = xor i64 %3066, %3065
  store i64 %3067, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %16, align 1, !tbaa !2432
  %3068 = trunc i64 %3067 to i32
  %3069 = and i32 %3068, 255
  %3070 = tail call i32 @llvm.ctpop.i32(i32 %3069) #11
  %3071 = trunc i32 %3070 to i8
  %3072 = and i8 %3071, 1
  %3073 = xor i8 %3072, 1
  store i8 %3073, i8* %23, align 1, !tbaa !2446
  %3074 = icmp eq i64 %3067, 0
  %3075 = zext i1 %3074 to i8
  store i8 %3075, i8* %32, align 1, !tbaa !2448
  %3076 = lshr i64 %3067, 63
  %3077 = trunc i64 %3076 to i8
  store i8 %3077, i8* %35, align 1, !tbaa !2449
  store i8 0, i8* %41, align 1, !tbaa !2450
  store i8 0, i8* %29, align 1, !tbaa !2447
  store i64 %3067, i64* %68, align 1, !tbaa !2428
  store i64 0, i64* %69, align 1, !tbaa !2428
  %3078 = add i64 %3060, -104
  %3079 = add i64 %3062, 23
  store i64 %3079, i64* %PC, align 8
  %.cast5 = bitcast i64 %3067 to double
  %3080 = inttoptr i64 %3078 to double*
  %3081 = load double, double* %3080, align 8
  %3082 = fmul double %.cast5, %3081
  store double %3082, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3083 = add i64 %3060, -64
  %3084 = add i64 %3062, 28
  store i64 %3084, i64* %PC, align 8
  %3085 = inttoptr i64 %3083 to i64*
  %3086 = load i64, i64* %3085, align 8
  store i64 %3086, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %3087 = add i64 %3060, -96
  %3088 = add i64 %3062, 33
  store i64 %3088, i64* %PC, align 8
  %3089 = bitcast i64 %3086 to double
  %3090 = inttoptr i64 %3087 to double*
  %3091 = load double, double* %3090, align 8
  %3092 = fmul double %3089, %3091
  store double %3092, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %3093 = fadd double %3082, %3092
  store double %3093, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3094 = add i64 %3060, -16
  %3095 = add i64 %3062, 41
  store i64 %3095, i64* %PC, align 8
  %3096 = inttoptr i64 %3094 to i64*
  %3097 = load i64, i64* %3096, align 8
  store i64 %3097, i64* %RAX, align 8, !tbaa !2428
  %3098 = add i64 %3060, -28
  %3099 = add i64 %3062, 44
  store i64 %3099, i64* %PC, align 8
  %3100 = inttoptr i64 %3098 to i32*
  %3101 = load i32, i32* %3100, align 4
  %3102 = add i32 %3101, 13
  %3103 = zext i32 %3102 to i64
  store i64 %3103, i64* %RCX, align 8, !tbaa !2428
  %3104 = icmp ugt i32 %3101, -14
  %3105 = zext i1 %3104 to i8
  store i8 %3105, i8* %16, align 1, !tbaa !2432
  %3106 = and i32 %3102, 255
  %3107 = tail call i32 @llvm.ctpop.i32(i32 %3106) #11
  %3108 = trunc i32 %3107 to i8
  %3109 = and i8 %3108, 1
  %3110 = xor i8 %3109, 1
  store i8 %3110, i8* %23, align 1, !tbaa !2446
  %3111 = xor i32 %3102, %3101
  %3112 = lshr i32 %3111, 4
  %3113 = trunc i32 %3112 to i8
  %3114 = and i8 %3113, 1
  store i8 %3114, i8* %29, align 1, !tbaa !2447
  %3115 = icmp eq i32 %3102, 0
  %3116 = zext i1 %3115 to i8
  store i8 %3116, i8* %32, align 1, !tbaa !2448
  %3117 = lshr i32 %3102, 31
  %3118 = trunc i32 %3117 to i8
  store i8 %3118, i8* %35, align 1, !tbaa !2449
  %3119 = lshr i32 %3101, 31
  %3120 = xor i32 %3117, %3119
  %3121 = add nuw nsw i32 %3120, %3117
  %3122 = icmp eq i32 %3121, 2
  %3123 = zext i1 %3122 to i8
  store i8 %3123, i8* %41, align 1, !tbaa !2450
  %3124 = sext i32 %3102 to i64
  store i64 %3124, i64* %RDX, align 8, !tbaa !2428
  %3125 = shl nsw i64 %3124, 3
  %3126 = add i64 %3125, %3097
  %3127 = add i64 %3062, 55
  store i64 %3127, i64* %PC, align 8
  %3128 = inttoptr i64 %3126 to double*
  store double %3093, double* %3128, align 8
  %3129 = load i64, i64* %RBP, align 8
  %3130 = add i64 %3129, -112
  %3131 = load i64, i64* %PC, align 8
  %3132 = add i64 %3131, 5
  store i64 %3132, i64* %PC, align 8
  %3133 = inttoptr i64 %3130 to i64*
  %3134 = load i64, i64* %3133, align 8
  store i64 %3134, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3135 = add i64 %3129, -152
  %3136 = add i64 %3131, 13
  store i64 %3136, i64* %PC, align 8
  %3137 = bitcast i64 %3134 to double
  %3138 = inttoptr i64 %3135 to double*
  %3139 = load double, double* %3138, align 8
  %3140 = fsub double %3137, %3139
  store double %3140, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3141 = add i64 %3129, -96
  %3142 = add i64 %3131, 18
  store i64 %3142, i64* %PC, align 8
  %3143 = inttoptr i64 %3141 to double*
  store double %3140, double* %3143, align 8
  %3144 = load i64, i64* %RBP, align 8
  %3145 = add i64 %3144, -120
  %3146 = load i64, i64* %PC, align 8
  %3147 = add i64 %3146, 5
  store i64 %3147, i64* %PC, align 8
  %3148 = inttoptr i64 %3145 to i64*
  %3149 = load i64, i64* %3148, align 8
  store i64 %3149, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3150 = add i64 %3144, -144
  %3151 = add i64 %3146, 13
  store i64 %3151, i64* %PC, align 8
  %3152 = bitcast i64 %3149 to double
  %3153 = inttoptr i64 %3150 to double*
  %3154 = load double, double* %3153, align 8
  %3155 = fadd double %3152, %3154
  store double %3155, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3156 = add i64 %3144, -104
  %3157 = add i64 %3146, 18
  store i64 %3157, i64* %PC, align 8
  %3158 = inttoptr i64 %3156 to double*
  store double %3155, double* %3158, align 8
  %3159 = load i64, i64* %RBP, align 8
  %3160 = add i64 %3159, -48
  %3161 = load i64, i64* %PC, align 8
  %3162 = add i64 %3161, 5
  store i64 %3162, i64* %PC, align 8
  %3163 = inttoptr i64 %3160 to i64*
  %3164 = load i64, i64* %3163, align 8
  store i64 %3164, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3165 = add i64 %3159, -96
  %3166 = add i64 %3161, 10
  store i64 %3166, i64* %PC, align 8
  %3167 = bitcast i64 %3164 to double
  %3168 = inttoptr i64 %3165 to double*
  %3169 = load double, double* %3168, align 8
  %3170 = fmul double %3167, %3169
  store double %3170, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3171 = add i64 %3159, -56
  %3172 = add i64 %3161, 15
  store i64 %3172, i64* %PC, align 8
  %3173 = inttoptr i64 %3171 to i64*
  %3174 = load i64, i64* %3173, align 8
  store i64 %3174, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %3175 = add i64 %3159, -104
  %3176 = add i64 %3161, 20
  store i64 %3176, i64* %PC, align 8
  %3177 = bitcast i64 %3174 to double
  %3178 = inttoptr i64 %3175 to double*
  %3179 = load double, double* %3178, align 8
  %3180 = fmul double %3177, %3179
  store double %3180, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %3181 = fsub double %3170, %3180
  store double %3181, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3182 = add i64 %3159, -16
  %3183 = add i64 %3161, 28
  store i64 %3183, i64* %PC, align 8
  %3184 = inttoptr i64 %3182 to i64*
  %3185 = load i64, i64* %3184, align 8
  store i64 %3185, i64* %RAX, align 8, !tbaa !2428
  %3186 = add i64 %3159, -28
  %3187 = add i64 %3161, 31
  store i64 %3187, i64* %PC, align 8
  %3188 = inttoptr i64 %3186 to i32*
  %3189 = load i32, i32* %3188, align 4
  %3190 = add i32 %3189, 10
  %3191 = zext i32 %3190 to i64
  store i64 %3191, i64* %RCX, align 8, !tbaa !2428
  %3192 = icmp ugt i32 %3189, -11
  %3193 = zext i1 %3192 to i8
  store i8 %3193, i8* %16, align 1, !tbaa !2432
  %3194 = and i32 %3190, 255
  %3195 = tail call i32 @llvm.ctpop.i32(i32 %3194) #11
  %3196 = trunc i32 %3195 to i8
  %3197 = and i8 %3196, 1
  %3198 = xor i8 %3197, 1
  store i8 %3198, i8* %23, align 1, !tbaa !2446
  %3199 = xor i32 %3190, %3189
  %3200 = lshr i32 %3199, 4
  %3201 = trunc i32 %3200 to i8
  %3202 = and i8 %3201, 1
  store i8 %3202, i8* %29, align 1, !tbaa !2447
  %3203 = icmp eq i32 %3190, 0
  %3204 = zext i1 %3203 to i8
  store i8 %3204, i8* %32, align 1, !tbaa !2448
  %3205 = lshr i32 %3190, 31
  %3206 = trunc i32 %3205 to i8
  store i8 %3206, i8* %35, align 1, !tbaa !2449
  %3207 = lshr i32 %3189, 31
  %3208 = xor i32 %3205, %3207
  %3209 = add nuw nsw i32 %3208, %3205
  %3210 = icmp eq i32 %3209, 2
  %3211 = zext i1 %3210 to i8
  store i8 %3211, i8* %41, align 1, !tbaa !2450
  %3212 = sext i32 %3190 to i64
  store i64 %3212, i64* %RDX, align 8, !tbaa !2428
  %3213 = shl nsw i64 %3212, 3
  %3214 = add i64 %3213, %3185
  %3215 = add i64 %3161, 42
  store i64 %3215, i64* %PC, align 8
  %3216 = inttoptr i64 %3214 to double*
  store double %3181, double* %3216, align 8
  %3217 = load i64, i64* %RBP, align 8
  %3218 = add i64 %3217, -48
  %3219 = load i64, i64* %PC, align 8
  %3220 = add i64 %3219, 5
  store i64 %3220, i64* %PC, align 8
  %3221 = inttoptr i64 %3218 to i64*
  %3222 = load i64, i64* %3221, align 8
  store i64 %3222, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3223 = add i64 %3217, -104
  %3224 = add i64 %3219, 10
  store i64 %3224, i64* %PC, align 8
  %3225 = bitcast i64 %3222 to double
  %3226 = inttoptr i64 %3223 to double*
  %3227 = load double, double* %3226, align 8
  %3228 = fmul double %3225, %3227
  store double %3228, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3229 = add i64 %3217, -56
  %3230 = add i64 %3219, 15
  store i64 %3230, i64* %PC, align 8
  %3231 = inttoptr i64 %3229 to i64*
  %3232 = load i64, i64* %3231, align 8
  store i64 %3232, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %3233 = add i64 %3217, -96
  %3234 = add i64 %3219, 20
  store i64 %3234, i64* %PC, align 8
  %3235 = bitcast i64 %3232 to double
  %3236 = inttoptr i64 %3233 to double*
  %3237 = load double, double* %3236, align 8
  %3238 = fmul double %3235, %3237
  store double %3238, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %3239 = fadd double %3228, %3238
  store double %3239, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3240 = add i64 %3217, -16
  %3241 = add i64 %3219, 28
  store i64 %3241, i64* %PC, align 8
  %3242 = inttoptr i64 %3240 to i64*
  %3243 = load i64, i64* %3242, align 8
  store i64 %3243, i64* %RAX, align 8, !tbaa !2428
  %3244 = add i64 %3217, -28
  %3245 = add i64 %3219, 31
  store i64 %3245, i64* %PC, align 8
  %3246 = inttoptr i64 %3244 to i32*
  %3247 = load i32, i32* %3246, align 4
  %3248 = add i32 %3247, 11
  %3249 = zext i32 %3248 to i64
  store i64 %3249, i64* %RCX, align 8, !tbaa !2428
  %3250 = icmp ugt i32 %3247, -12
  %3251 = zext i1 %3250 to i8
  store i8 %3251, i8* %16, align 1, !tbaa !2432
  %3252 = and i32 %3248, 255
  %3253 = tail call i32 @llvm.ctpop.i32(i32 %3252) #11
  %3254 = trunc i32 %3253 to i8
  %3255 = and i8 %3254, 1
  %3256 = xor i8 %3255, 1
  store i8 %3256, i8* %23, align 1, !tbaa !2446
  %3257 = xor i32 %3248, %3247
  %3258 = lshr i32 %3257, 4
  %3259 = trunc i32 %3258 to i8
  %3260 = and i8 %3259, 1
  store i8 %3260, i8* %29, align 1, !tbaa !2447
  %3261 = icmp eq i32 %3248, 0
  %3262 = zext i1 %3261 to i8
  store i8 %3262, i8* %32, align 1, !tbaa !2448
  %3263 = lshr i32 %3248, 31
  %3264 = trunc i32 %3263 to i8
  store i8 %3264, i8* %35, align 1, !tbaa !2449
  %3265 = lshr i32 %3247, 31
  %3266 = xor i32 %3263, %3265
  %3267 = add nuw nsw i32 %3266, %3263
  %3268 = icmp eq i32 %3267, 2
  %3269 = zext i1 %3268 to i8
  store i8 %3269, i8* %41, align 1, !tbaa !2450
  %3270 = sext i32 %3248 to i64
  store i64 %3270, i64* %RDX, align 8, !tbaa !2428
  %3271 = shl nsw i64 %3270, 3
  %3272 = add i64 %3271, %3243
  %3273 = add i64 %3219, 42
  store i64 %3273, i64* %PC, align 8
  %3274 = inttoptr i64 %3272 to double*
  store double %3239, double* %3274, align 8
  %3275 = load i64, i64* %RBP, align 8
  %3276 = add i64 %3275, -112
  %3277 = load i64, i64* %PC, align 8
  %3278 = add i64 %3277, 5
  store i64 %3278, i64* %PC, align 8
  %3279 = inttoptr i64 %3276 to i64*
  %3280 = load i64, i64* %3279, align 8
  store i64 %3280, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3281 = add i64 %3275, -152
  %3282 = add i64 %3277, 13
  store i64 %3282, i64* %PC, align 8
  %3283 = bitcast i64 %3280 to double
  %3284 = inttoptr i64 %3281 to double*
  %3285 = load double, double* %3284, align 8
  %3286 = fadd double %3283, %3285
  store double %3286, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3287 = add i64 %3275, -96
  %3288 = add i64 %3277, 18
  store i64 %3288, i64* %PC, align 8
  %3289 = inttoptr i64 %3287 to double*
  store double %3286, double* %3289, align 8
  %3290 = load i64, i64* %RBP, align 8
  %3291 = add i64 %3290, -120
  %3292 = load i64, i64* %PC, align 8
  %3293 = add i64 %3292, 5
  store i64 %3293, i64* %PC, align 8
  %3294 = inttoptr i64 %3291 to i64*
  %3295 = load i64, i64* %3294, align 8
  store i64 %3295, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3296 = add i64 %3290, -144
  %3297 = add i64 %3292, 13
  store i64 %3297, i64* %PC, align 8
  %3298 = bitcast i64 %3295 to double
  %3299 = inttoptr i64 %3296 to double*
  %3300 = load double, double* %3299, align 8
  %3301 = fsub double %3298, %3300
  store double %3301, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3302 = add i64 %3290, -104
  %3303 = add i64 %3292, 18
  store i64 %3303, i64* %PC, align 8
  %3304 = inttoptr i64 %3302 to double*
  store double %3301, double* %3304, align 8
  %3305 = load i64, i64* %RBP, align 8
  %3306 = add i64 %3305, -80
  %3307 = load i64, i64* %PC, align 8
  %3308 = add i64 %3307, 5
  store i64 %3308, i64* %PC, align 8
  %3309 = inttoptr i64 %3306 to i64*
  %3310 = load i64, i64* %3309, align 8
  store i64 %3310, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3311 = add i64 %3305, -96
  %3312 = add i64 %3307, 10
  store i64 %3312, i64* %PC, align 8
  %3313 = bitcast i64 %3310 to double
  %3314 = inttoptr i64 %3311 to double*
  %3315 = load double, double* %3314, align 8
  %3316 = fmul double %3313, %3315
  store double %3316, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3317 = add i64 %3305, -88
  %3318 = add i64 %3307, 15
  store i64 %3318, i64* %PC, align 8
  %3319 = inttoptr i64 %3317 to i64*
  %3320 = load i64, i64* %3319, align 8
  store i64 %3320, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %3321 = add i64 %3305, -104
  %3322 = add i64 %3307, 20
  store i64 %3322, i64* %PC, align 8
  %3323 = bitcast i64 %3320 to double
  %3324 = inttoptr i64 %3321 to double*
  %3325 = load double, double* %3324, align 8
  %3326 = fmul double %3323, %3325
  store double %3326, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %3327 = fsub double %3316, %3326
  store double %3327, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3328 = add i64 %3305, -16
  %3329 = add i64 %3307, 28
  store i64 %3329, i64* %PC, align 8
  %3330 = inttoptr i64 %3328 to i64*
  %3331 = load i64, i64* %3330, align 8
  store i64 %3331, i64* %RAX, align 8, !tbaa !2428
  %3332 = add i64 %3305, -28
  %3333 = add i64 %3307, 31
  store i64 %3333, i64* %PC, align 8
  %3334 = inttoptr i64 %3332 to i32*
  %3335 = load i32, i32* %3334, align 4
  %3336 = add i32 %3335, 14
  %3337 = zext i32 %3336 to i64
  store i64 %3337, i64* %RCX, align 8, !tbaa !2428
  %3338 = icmp ugt i32 %3335, -15
  %3339 = zext i1 %3338 to i8
  store i8 %3339, i8* %16, align 1, !tbaa !2432
  %3340 = and i32 %3336, 255
  %3341 = tail call i32 @llvm.ctpop.i32(i32 %3340) #11
  %3342 = trunc i32 %3341 to i8
  %3343 = and i8 %3342, 1
  %3344 = xor i8 %3343, 1
  store i8 %3344, i8* %23, align 1, !tbaa !2446
  %3345 = xor i32 %3336, %3335
  %3346 = lshr i32 %3345, 4
  %3347 = trunc i32 %3346 to i8
  %3348 = and i8 %3347, 1
  store i8 %3348, i8* %29, align 1, !tbaa !2447
  %3349 = icmp eq i32 %3336, 0
  %3350 = zext i1 %3349 to i8
  store i8 %3350, i8* %32, align 1, !tbaa !2448
  %3351 = lshr i32 %3336, 31
  %3352 = trunc i32 %3351 to i8
  store i8 %3352, i8* %35, align 1, !tbaa !2449
  %3353 = lshr i32 %3335, 31
  %3354 = xor i32 %3351, %3353
  %3355 = add nuw nsw i32 %3354, %3351
  %3356 = icmp eq i32 %3355, 2
  %3357 = zext i1 %3356 to i8
  store i8 %3357, i8* %41, align 1, !tbaa !2450
  %3358 = sext i32 %3336 to i64
  store i64 %3358, i64* %RDX, align 8, !tbaa !2428
  %3359 = shl nsw i64 %3358, 3
  %3360 = add i64 %3359, %3331
  %3361 = add i64 %3307, 42
  store i64 %3361, i64* %PC, align 8
  %3362 = inttoptr i64 %3360 to double*
  store double %3327, double* %3362, align 8
  %3363 = load i64, i64* %RBP, align 8
  %3364 = add i64 %3363, -80
  %3365 = load i64, i64* %PC, align 8
  %3366 = add i64 %3365, 5
  store i64 %3366, i64* %PC, align 8
  %3367 = inttoptr i64 %3364 to i64*
  %3368 = load i64, i64* %3367, align 8
  store i64 %3368, i64* %68, align 1, !tbaa !2451
  store double 0.000000e+00, double* %70, align 1, !tbaa !2451
  %3369 = add i64 %3363, -104
  %3370 = add i64 %3365, 10
  store i64 %3370, i64* %PC, align 8
  %3371 = bitcast i64 %3368 to double
  %3372 = inttoptr i64 %3369 to double*
  %3373 = load double, double* %3372, align 8
  %3374 = fmul double %3371, %3373
  store double %3374, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3375 = add i64 %3363, -88
  %3376 = add i64 %3365, 15
  store i64 %3376, i64* %PC, align 8
  %3377 = inttoptr i64 %3375 to i64*
  %3378 = load i64, i64* %3377, align 8
  store i64 %3378, i64* %678, align 1, !tbaa !2451
  store double 0.000000e+00, double* %680, align 1, !tbaa !2451
  %3379 = add i64 %3363, -96
  %3380 = add i64 %3365, 20
  store i64 %3380, i64* %PC, align 8
  %3381 = bitcast i64 %3378 to double
  %3382 = inttoptr i64 %3379 to double*
  %3383 = load double, double* %3382, align 8
  %3384 = fmul double %3381, %3383
  store double %3384, double* %677, align 1, !tbaa !2451
  store i64 0, i64* %679, align 1, !tbaa !2451
  %3385 = fadd double %3374, %3384
  store double %3385, double* %67, align 1, !tbaa !2451
  store i64 0, i64* %69, align 1, !tbaa !2451
  %3386 = add i64 %3363, -16
  %3387 = add i64 %3365, 28
  store i64 %3387, i64* %PC, align 8
  %3388 = inttoptr i64 %3386 to i64*
  %3389 = load i64, i64* %3388, align 8
  store i64 %3389, i64* %RAX, align 8, !tbaa !2428
  %3390 = add i64 %3363, -28
  %3391 = add i64 %3365, 31
  store i64 %3391, i64* %PC, align 8
  %3392 = inttoptr i64 %3390 to i32*
  %3393 = load i32, i32* %3392, align 4
  %3394 = add i32 %3393, 15
  %3395 = zext i32 %3394 to i64
  store i64 %3395, i64* %RCX, align 8, !tbaa !2428
  %3396 = icmp ugt i32 %3393, -16
  %3397 = zext i1 %3396 to i8
  store i8 %3397, i8* %16, align 1, !tbaa !2432
  %3398 = and i32 %3394, 255
  %3399 = tail call i32 @llvm.ctpop.i32(i32 %3398) #11
  %3400 = trunc i32 %3399 to i8
  %3401 = and i8 %3400, 1
  %3402 = xor i8 %3401, 1
  store i8 %3402, i8* %23, align 1, !tbaa !2446
  %3403 = xor i32 %3394, %3393
  %3404 = lshr i32 %3403, 4
  %3405 = trunc i32 %3404 to i8
  %3406 = and i8 %3405, 1
  store i8 %3406, i8* %29, align 1, !tbaa !2447
  %3407 = icmp eq i32 %3394, 0
  %3408 = zext i1 %3407 to i8
  store i8 %3408, i8* %32, align 1, !tbaa !2448
  %3409 = lshr i32 %3394, 31
  %3410 = trunc i32 %3409 to i8
  store i8 %3410, i8* %35, align 1, !tbaa !2449
  %3411 = lshr i32 %3393, 31
  %3412 = xor i32 %3409, %3411
  %3413 = add nuw nsw i32 %3412, %3409
  %3414 = icmp eq i32 %3413, 2
  %3415 = zext i1 %3414 to i8
  store i8 %3415, i8* %41, align 1, !tbaa !2450
  %3416 = sext i32 %3394 to i64
  store i64 %3416, i64* %RDX, align 8, !tbaa !2428
  %3417 = shl nsw i64 %3416, 3
  %3418 = add i64 %3417, %3389
  %3419 = add i64 %3365, 42
  store i64 %3419, i64* %PC, align 8
  %3420 = inttoptr i64 %3418 to double*
  store double %3385, double* %3420, align 8
  %3421 = load i64, i64* %RBP, align 8
  %3422 = add i64 %3421, -28
  %3423 = load i64, i64* %PC, align 8
  %3424 = add i64 %3423, 3
  store i64 %3424, i64* %PC, align 8
  %3425 = inttoptr i64 %3422 to i32*
  %3426 = load i32, i32* %3425, align 4
  %3427 = add i32 %3426, 16
  %3428 = zext i32 %3427 to i64
  store i64 %3428, i64* %RAX, align 8, !tbaa !2428
  %3429 = icmp ugt i32 %3426, -17
  %3430 = zext i1 %3429 to i8
  store i8 %3430, i8* %16, align 1, !tbaa !2432
  %3431 = and i32 %3427, 255
  %3432 = tail call i32 @llvm.ctpop.i32(i32 %3431) #11
  %3433 = trunc i32 %3432 to i8
  %3434 = and i8 %3433, 1
  %3435 = xor i8 %3434, 1
  store i8 %3435, i8* %23, align 1, !tbaa !2446
  %3436 = xor i32 %3426, 16
  %3437 = xor i32 %3436, %3427
  %3438 = lshr i32 %3437, 4
  %3439 = trunc i32 %3438 to i8
  %3440 = and i8 %3439, 1
  store i8 %3440, i8* %29, align 1, !tbaa !2447
  %3441 = icmp eq i32 %3427, 0
  %3442 = zext i1 %3441 to i8
  store i8 %3442, i8* %32, align 1, !tbaa !2448
  %3443 = lshr i32 %3427, 31
  %3444 = trunc i32 %3443 to i8
  store i8 %3444, i8* %35, align 1, !tbaa !2449
  %3445 = lshr i32 %3426, 31
  %3446 = xor i32 %3443, %3445
  %3447 = add nuw nsw i32 %3446, %3443
  %3448 = icmp eq i32 %3447, 2
  %3449 = zext i1 %3448 to i8
  store i8 %3449, i8* %41, align 1, !tbaa !2450
  %3450 = add i64 %3423, 9
  store i64 %3450, i64* %PC, align 8
  store i32 %3427, i32* %3425, align 4
  %3451 = load i64, i64* %PC, align 8
  %3452 = add i64 %3451, -1815
  store i64 %3452, i64* %PC, align 8, !tbaa !2428
  br label %block_402c02

block_40331e:                                     ; preds = %block_402c02
  %3453 = load i64, i64* %RSP, align 8
  %3454 = add i64 %3453, 24
  store i64 %3454, i64* %RSP, align 8, !tbaa !2428
  %3455 = icmp ugt i64 %3453, -25
  %3456 = zext i1 %3455 to i8
  store i8 %3456, i8* %16, align 1, !tbaa !2432
  %3457 = trunc i64 %3454 to i32
  %3458 = and i32 %3457, 255
  %3459 = tail call i32 @llvm.ctpop.i32(i32 %3458) #11
  %3460 = trunc i32 %3459 to i8
  %3461 = and i8 %3460, 1
  %3462 = xor i8 %3461, 1
  store i8 %3462, i8* %23, align 1, !tbaa !2446
  %3463 = xor i64 %3453, 16
  %3464 = xor i64 %3463, %3454
  %3465 = lshr i64 %3464, 4
  %3466 = trunc i64 %3465 to i8
  %3467 = and i8 %3466, 1
  store i8 %3467, i8* %29, align 1, !tbaa !2447
  %3468 = icmp eq i64 %3454, 0
  %3469 = zext i1 %3468 to i8
  store i8 %3469, i8* %32, align 1, !tbaa !2448
  %3470 = lshr i64 %3454, 63
  %3471 = trunc i64 %3470 to i8
  store i8 %3471, i8* %35, align 1, !tbaa !2449
  %3472 = lshr i64 %3453, 63
  %3473 = xor i64 %3470, %3472
  %3474 = add nuw nsw i64 %3473, %3470
  %3475 = icmp eq i64 %3474, 2
  %3476 = zext i1 %3475 to i8
  store i8 %3476, i8* %41, align 1, !tbaa !2450
  %3477 = add i64 %3522, 5
  store i64 %3477, i64* %PC, align 8
  %3478 = add i64 %3453, 32
  %3479 = inttoptr i64 %3454 to i64*
  %3480 = load i64, i64* %3479, align 8
  store i64 %3480, i64* %RBP, align 8, !tbaa !2428
  store i64 %3478, i64* %RSP, align 8, !tbaa !2428
  %3481 = add i64 %3522, 6
  store i64 %3481, i64* %PC, align 8
  %3482 = inttoptr i64 %3478 to i64*
  %3483 = load i64, i64* %3482, align 8
  store i64 %3483, i64* %PC, align 8, !tbaa !2428
  %3484 = add i64 %3453, 40
  store i64 %3484, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_402c02:                                     ; preds = %block_402c0e, %block_4028a0
  %3485 = phi i64 [ %3452, %block_402c0e ], [ %.pre, %block_4028a0 ]
  %3486 = load i64, i64* %RBP, align 8
  %3487 = add i64 %3486, -28
  %3488 = add i64 %3485, 3
  store i64 %3488, i64* %PC, align 8
  %3489 = inttoptr i64 %3487 to i32*
  %3490 = load i32, i32* %3489, align 4
  %3491 = zext i32 %3490 to i64
  store i64 %3491, i64* %RAX, align 8, !tbaa !2428
  %3492 = add i64 %3486, -4
  %3493 = add i64 %3485, 6
  store i64 %3493, i64* %PC, align 8
  %3494 = inttoptr i64 %3492 to i32*
  %3495 = load i32, i32* %3494, align 4
  %3496 = sub i32 %3490, %3495
  %3497 = icmp ult i32 %3490, %3495
  %3498 = zext i1 %3497 to i8
  store i8 %3498, i8* %16, align 1, !tbaa !2432
  %3499 = and i32 %3496, 255
  %3500 = tail call i32 @llvm.ctpop.i32(i32 %3499) #11
  %3501 = trunc i32 %3500 to i8
  %3502 = and i8 %3501, 1
  %3503 = xor i8 %3502, 1
  store i8 %3503, i8* %23, align 1, !tbaa !2446
  %3504 = xor i32 %3495, %3490
  %3505 = xor i32 %3504, %3496
  %3506 = lshr i32 %3505, 4
  %3507 = trunc i32 %3506 to i8
  %3508 = and i8 %3507, 1
  store i8 %3508, i8* %29, align 1, !tbaa !2447
  %3509 = icmp eq i32 %3496, 0
  %3510 = zext i1 %3509 to i8
  store i8 %3510, i8* %32, align 1, !tbaa !2448
  %3511 = lshr i32 %3496, 31
  %3512 = trunc i32 %3511 to i8
  store i8 %3512, i8* %35, align 1, !tbaa !2449
  %3513 = lshr i32 %3490, 31
  %3514 = lshr i32 %3495, 31
  %3515 = xor i32 %3514, %3513
  %3516 = xor i32 %3511, %3513
  %3517 = add nuw nsw i32 %3516, %3515
  %3518 = icmp eq i32 %3517, 2
  %3519 = zext i1 %3518 to i8
  store i8 %3519, i8* %41, align 1, !tbaa !2450
  %3520 = icmp ne i8 %3512, 0
  %3521 = xor i1 %3520, %3518
  %.v = select i1 %3521, i64 12, i64 1820
  %3522 = add i64 %.v, %3485
  store i64 %3522, i64* %PC, align 8, !tbaa !2428
  br i1 %3521, label %block_402c0e, label %block_40331e
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_4007d0_register_tm_clones(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_4007d0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  store i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64* %RSI, align 8, !tbaa !2428
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 6
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* %RSP, align 8, !tbaa !2428
  %6 = add i64 %5, -8
  %7 = inttoptr i64 %6 to i64*
  store i64 %3, i64* %7, align 8
  store i64 %6, i64* %RSP, align 8, !tbaa !2428
  %8 = load i64, i64* %RSI, align 8
  %9 = load i64, i64* %PC, align 8
  %10 = sub i64 %8, ptrtoint (%__bss_start_type* @__bss_start to i64)
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i64 %6, i64* %RBP, align 8, !tbaa !2428
  %17 = ashr i64 %10, 3
  %18 = lshr i64 %17, 63
  store i64 %18, i64* %RAX, align 8, !tbaa !2428
  %19 = add nsw i64 %18, %17
  %20 = trunc i64 %19 to i8
  %21 = and i8 %20, 1
  %22 = ashr i64 %19, 1
  store i64 %22, i64* %RSI, align 8, !tbaa !2428
  store i8 %21, i8* %11, align 1, !tbaa !2453
  %23 = trunc i64 %22 to i32
  %24 = and i32 %23, 255
  %25 = tail call i32 @llvm.ctpop.i32(i32 %24) #11
  %26 = trunc i32 %25 to i8
  %27 = and i8 %26, 1
  %28 = xor i8 %27, 1
  store i8 %28, i8* %12, align 1, !tbaa !2453
  store i8 0, i8* %13, align 1, !tbaa !2453
  %29 = icmp eq i64 %22, 0
  %30 = zext i1 %29 to i8
  store i8 %30, i8* %14, align 1, !tbaa !2453
  %31 = lshr i64 %22, 63
  %32 = trunc i64 %31 to i8
  store i8 %32, i8* %15, align 1, !tbaa !2453
  store i8 0, i8* %16, align 1, !tbaa !2453
  %.v = select i1 %29, i64 50, i64 29
  %33 = add i64 %.v, %9
  store i64 %33, i64* %PC, align 8, !tbaa !2428
  br i1 %29, label %block_400808, label %block_4007f3

block_4007f3:                                     ; preds = %block_4007d0
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %11, align 1, !tbaa !2432
  store i8 1, i8* %12, align 1, !tbaa !2446
  store i8 1, i8* %14, align 1, !tbaa !2448
  store i8 0, i8* %15, align 1, !tbaa !2449
  store i8 0, i8* %16, align 1, !tbaa !2450
  store i8 0, i8* %13, align 1, !tbaa !2447
  %34 = add i64 %33, 21
  store i64 %34, i64* %PC, align 8, !tbaa !2428
  br label %block_400808

block_400808:                                     ; preds = %block_4007f3, %block_4007d0
  %35 = phi i64 [ %34, %block_4007f3 ], [ %33, %block_4007d0 ]
  %36 = add i64 %35, 1
  store i64 %36, i64* %PC, align 8
  %37 = load i64, i64* %7, align 8
  store i64 %37, i64* %RBP, align 8, !tbaa !2428
  store i64 %5, i64* %RSP, align 8, !tbaa !2428
  %38 = add i64 %35, 2
  store i64 %38, i64* %PC, align 8
  %39 = inttoptr i64 %5 to i64*
  %40 = load i64, i64* %39, align 8
  store i64 %40, i64* %PC, align 8, !tbaa !2428
  %41 = add i64 %5, 8
  store i64 %41, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_400e30_get_time(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #7 {
block_400e30:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %7 = load i64, i64* %RBP, align 8
  %8 = add i64 %1, 1
  store i64 %8, i64* %PC, align 8
  %9 = load i64, i64* %RSP, align 8, !tbaa !2428
  %10 = add i64 %9, -8
  %11 = inttoptr i64 %10 to i64*
  store i64 %7, i64* %11, align 8
  %12 = load i64, i64* %PC, align 8
  store i64 %10, i64* %RBP, align 8, !tbaa !2428
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %19 = add i64 %9, -24
  store i64 %19, i64* %RDI, align 8, !tbaa !2428
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %13, align 1, !tbaa !2432
  store i8 1, i8* %14, align 1, !tbaa !2446
  store i8 1, i8* %16, align 1, !tbaa !2448
  store i8 0, i8* %17, align 1, !tbaa !2449
  store i8 0, i8* %18, align 1, !tbaa !2450
  store i8 0, i8* %15, align 1, !tbaa !2447
  store i64 0, i64* %RSI, align 8, !tbaa !2428
  %20 = add i64 %12, -1857
  %21 = add i64 %12, 20
  %22 = add i64 %9, -48
  %23 = inttoptr i64 %22 to i64*
  store i64 %21, i64* %23, align 8
  store i64 %22, i64* %RSP, align 8, !tbaa !2428
  store i64 %20, i64* %PC, align 8, !tbaa !2428
  %24 = tail call fastcc %struct.Memory* @ext_4006f0_gettimeofday(%struct.State* nonnull %0, %struct.Memory* %2)
  %25 = bitcast [32 x %union.VectorReg]* %4 to i8*
  %26 = load i64, i64* %PC, align 8
  %27 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 56) to i64*), align 8
  %28 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %4, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %27, i64* %28, align 1, !tbaa !2451
  %29 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %30 = bitcast i64* %29 to double*
  store double 0.000000e+00, double* %30, align 1, !tbaa !2451
  %31 = load i64, i64* %RBP, align 8
  %32 = add i64 %31, -16
  %33 = add i64 %26, 14
  store i64 %33, i64* %PC, align 8
  %34 = inttoptr i64 %32 to i64*
  %35 = load i64, i64* %34, align 8
  %36 = sitofp i64 %35 to double
  %37 = bitcast %union.VectorReg* %5 to double*
  store double %36, double* %37, align 1, !tbaa !2451
  %38 = add i64 %31, -8
  %39 = add i64 %26, 20
  store i64 %39, i64* %PC, align 8
  %40 = inttoptr i64 %38 to i64*
  %41 = load i64, i64* %40, align 8
  %42 = sitofp i64 %41 to double
  %43 = bitcast %union.VectorReg* %6 to double*
  %44 = bitcast i64 %27 to double
  %45 = fmul double %44, %42
  store double %45, double* %43, align 1, !tbaa !2451
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %47 = bitcast i64* %46 to <2 x i32>*
  %48 = load <2 x i32>, <2 x i32>* %47, align 1
  %49 = fadd double %36, %45
  store double %49, double* %37, align 1, !tbaa !2451
  %.cast = bitcast double %49 to <2 x i32>
  %50 = extractelement <2 x i32> %.cast, i32 0
  %51 = bitcast [32 x %union.VectorReg]* %4 to i32*
  store i32 %50, i32* %51, align 1, !tbaa !2475
  %52 = extractelement <2 x i32> %.cast, i32 1
  %53 = getelementptr inbounds i8, i8* %25, i64 4
  %54 = bitcast i8* %53 to i32*
  store i32 %52, i32* %54, align 1, !tbaa !2475
  %55 = extractelement <2 x i32> %48, i32 0
  %56 = bitcast i64* %29 to i32*
  store i32 %55, i32* %56, align 1, !tbaa !2475
  %57 = extractelement <2 x i32> %48, i32 1
  %58 = getelementptr inbounds i8, i8* %25, i64 12
  %59 = bitcast i8* %58 to i32*
  store i32 %57, i32* %59, align 1, !tbaa !2475
  %60 = add i64 %31, -20
  %61 = load i32, i32* %EAX, align 4
  %62 = add i64 %26, 34
  store i64 %62, i64* %PC, align 8
  %63 = inttoptr i64 %60 to i32*
  store i32 %61, i32* %63, align 4
  %64 = load i64, i64* %RSP, align 8
  %65 = load i64, i64* %PC, align 8
  %66 = add i64 %64, 32
  store i64 %66, i64* %RSP, align 8, !tbaa !2428
  %67 = icmp ugt i64 %64, -33
  %68 = zext i1 %67 to i8
  store i8 %68, i8* %13, align 1, !tbaa !2432
  %69 = trunc i64 %66 to i32
  %70 = and i32 %69, 255
  %71 = tail call i32 @llvm.ctpop.i32(i32 %70) #11
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  %74 = xor i8 %73, 1
  store i8 %74, i8* %14, align 1, !tbaa !2446
  %75 = xor i64 %66, %64
  %76 = lshr i64 %75, 4
  %77 = trunc i64 %76 to i8
  %78 = and i8 %77, 1
  store i8 %78, i8* %15, align 1, !tbaa !2447
  %79 = icmp eq i64 %66, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %16, align 1, !tbaa !2448
  %81 = lshr i64 %66, 63
  %82 = trunc i64 %81 to i8
  store i8 %82, i8* %17, align 1, !tbaa !2449
  %83 = lshr i64 %64, 63
  %84 = xor i64 %81, %83
  %85 = add nuw nsw i64 %84, %81
  %86 = icmp eq i64 %85, 2
  %87 = zext i1 %86 to i8
  store i8 %87, i8* %18, align 1, !tbaa !2450
  %88 = add i64 %65, 5
  store i64 %88, i64* %PC, align 8
  %89 = add i64 %64, 40
  %90 = inttoptr i64 %66 to i64*
  %91 = load i64, i64* %90, align 8
  store i64 %91, i64* %RBP, align 8, !tbaa !2428
  store i64 %89, i64* %RSP, align 8, !tbaa !2428
  %92 = add i64 %65, 6
  store i64 %92, i64* %PC, align 8
  %93 = inttoptr i64 %89 to i64*
  %94 = load i64, i64* %93, align 8
  store i64 %94, i64* %PC, align 8, !tbaa !2428
  %95 = add i64 %64, 48
  store i64 %95, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %24
}

; Function Attrs: noinline
define %struct.Memory* @sub_400850_main(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #8 {
block_400850:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %4 to i32*
  %RAX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3
  %9 = load i64, i64* %RBP, align 8
  %10 = add i64 %1, 1
  store i64 %10, i64* %PC, align 8
  %11 = load i64, i64* %RSP, align 8, !tbaa !2428
  %12 = add i64 %11, -8
  %13 = inttoptr i64 %12 to i64*
  store i64 %9, i64* %13, align 8
  %14 = load i64, i64* %PC, align 8
  store i64 %12, i64* %RBP, align 8, !tbaa !2428
  %15 = add i64 %11, -232
  store i64 %15, i64* %RSP, align 8, !tbaa !2428
  %16 = icmp ult i64 %12, 224
  %17 = zext i1 %16 to i8
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %17, i8* %18, align 1, !tbaa !2432
  %19 = trunc i64 %15 to i32
  %20 = and i32 %19, 255
  %21 = tail call i32 @llvm.ctpop.i32(i32 %20) #11
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = xor i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %24, i8* %25, align 1, !tbaa !2446
  %26 = xor i64 %12, %15
  %27 = lshr i64 %26, 4
  %28 = trunc i64 %27 to i8
  %29 = and i8 %28, 1
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %29, i8* %30, align 1, !tbaa !2447
  %31 = icmp eq i64 %15, 0
  %32 = zext i1 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %32, i8* %33, align 1, !tbaa !2448
  %34 = lshr i64 %15, 63
  %35 = trunc i64 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %35, i8* %36, align 1, !tbaa !2449
  %37 = lshr i64 %12, 63
  %38 = xor i64 %34, %37
  %39 = add nuw nsw i64 %38, %37
  %40 = icmp eq i64 %39, 2
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %41, i8* %42, align 1, !tbaa !2450
  store i64 16, i64* %RAX, align 8, !tbaa !2428
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  %43 = add i64 %11, -12
  %44 = add i64 %14, 24
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %43 to i32*
  store i32 0, i32* %45, align 4
  %46 = load i64, i64* %RBP, align 8
  %47 = add i64 %46, -88
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 8
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %47 to i64*
  store i64 0, i64* %50, align 8
  %51 = load i64, i64* %RBP, align 8
  %52 = add i64 %51, -144
  %53 = load i64, i64* %RDI, align 8
  %54 = load i64, i64* %PC, align 8
  %55 = add i64 %54, 7
  store i64 %55, i64* %PC, align 8
  %56 = inttoptr i64 %52 to i64*
  store i64 %53, i64* %56, align 8
  %57 = load i64, i64* %PC, align 8
  %58 = add i64 %57, 1464
  %59 = add i64 %57, 5
  %60 = load i64, i64* %RSP, align 8, !tbaa !2428
  %61 = add i64 %60, -8
  %62 = inttoptr i64 %61 to i64*
  store i64 %59, i64* %62, align 8
  store i64 %61, i64* %RSP, align 8, !tbaa !2428
  store i64 %58, i64* %PC, align 8, !tbaa !2428
  %63 = tail call %struct.Memory* @sub_400e30_get_time_renamed_(%struct.State* nonnull %0, i64 %58, %struct.Memory* %2)
  %64 = load i64, i64* %RBP, align 8
  %65 = add i64 %64, -64
  %66 = load i64, i64* %PC, align 8
  %67 = add i64 %66, 5
  store i64 %67, i64* %PC, align 8
  %68 = bitcast [32 x %union.VectorReg]* %5 to double*
  %69 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %5, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %70 = load i64, i64* %69, align 1
  %71 = inttoptr i64 %65 to i64*
  store i64 %70, i64* %71, align 8
  %72 = load i64, i64* %PC, align 8
  %73 = add i64 %72, 1454
  %74 = add i64 %72, 5
  %75 = load i64, i64* %RSP, align 8, !tbaa !2428
  %76 = add i64 %75, -8
  %77 = inttoptr i64 %76 to i64*
  store i64 %74, i64* %77, align 8
  store i64 %76, i64* %RSP, align 8, !tbaa !2428
  store i64 %73, i64* %PC, align 8, !tbaa !2428
  %78 = tail call %struct.Memory* @sub_400e30_get_time_renamed_(%struct.State* nonnull %0, i64 %73, %struct.Memory* %63)
  %79 = load i64, i64* %RBP, align 8
  %80 = add i64 %79, -72
  %81 = load i64, i64* %PC, align 8
  %82 = add i64 %81, 5
  store i64 %82, i64* %PC, align 8
  %83 = load i64, i64* %69, align 1
  %84 = inttoptr i64 %80 to i64*
  store i64 %83, i64* %84, align 8
  %85 = bitcast [32 x %union.VectorReg]* %5 to i8*
  %86 = load i64, i64* %RBP, align 8
  %87 = add i64 %86, -72
  %88 = load i64, i64* %PC, align 8
  %89 = add i64 %88, 5
  store i64 %89, i64* %PC, align 8
  %90 = inttoptr i64 %87 to i64*
  %91 = load i64, i64* %90, align 8
  store i64 %91, i64* %69, align 1, !tbaa !2451
  %92 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %93 = bitcast i64* %92 to double*
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %94 = bitcast %union.VectorReg* %6 to i8*
  %95 = add i64 %86, -64
  %96 = add i64 %88, 10
  store i64 %96, i64* %PC, align 8
  %97 = inttoptr i64 %95 to i64*
  %98 = load i64, i64* %97, align 8
  %99 = bitcast %union.VectorReg* %6 to double*
  %100 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %98, i64* %100, align 1, !tbaa !2451
  %101 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %102 = bitcast i64* %101 to double*
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  %103 = bitcast i64 %91 to double
  %104 = bitcast i64 %98 to double
  %105 = fsub double %103, %104
  %106 = add i64 %86, -80
  %107 = add i64 %88, 19
  store i64 %107, i64* %PC, align 8
  %108 = inttoptr i64 %106 to double*
  store double %105, double* %108, align 8
  %109 = load i64, i64* %PC, align 8
  %110 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 24) to i64*), align 8
  store i64 %110, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %111 = add i64 %109, -335
  %112 = add i64 %109, 13
  %113 = load i64, i64* %RSP, align 8, !tbaa !2428
  %114 = add i64 %113, -8
  %115 = inttoptr i64 %114 to i64*
  store i64 %112, i64* %115, align 8
  store i64 %114, i64* %RSP, align 8, !tbaa !2428
  store i64 %111, i64* %PC, align 8, !tbaa !2428
  %116 = load double, double* %68, align 8, !alias.scope !2477, !noalias !2480
  %117 = load i64, i64* %115, align 8
  store i64 %113, i64* %RSP, align 8, !alias.scope !2477, !noalias !2480
  %118 = tail call double @sqrt(double %116)
  %119 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 2
  %120 = bitcast i64* %119 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* %120, i8 0, i64 16, i32 8, i1 false)
  %121 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 32) to double*), align 16
  %122 = fmul double %118, %121
  store double %122, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %123 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 40) to i64*), align 8
  store i64 %123, i64* %100, align 1, !tbaa !2451
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  %124 = bitcast %union.VectorReg* %7 to i8*
  %125 = bitcast double %122 to <2 x i32>
  %126 = extractelement <2 x i32> %125, i32 0
  %127 = bitcast %union.VectorReg* %7 to i32*
  store i32 %126, i32* %127, align 1, !tbaa !2475
  %128 = extractelement <2 x i32> %125, i32 1
  %129 = getelementptr inbounds i8, i8* %124, i64 4
  %130 = bitcast i8* %129 to i32*
  store i32 %128, i32* %130, align 1, !tbaa !2475
  %131 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %132 = bitcast i64* %131 to i32*
  store i32 0, i32* %132, align 1, !tbaa !2475
  %133 = getelementptr inbounds i8, i8* %124, i64 12
  %134 = bitcast i8* %133 to i32*
  store i32 0, i32* %134, align 1, !tbaa !2475
  %135 = bitcast %union.VectorReg* %7 to double*
  %136 = load double, double* %135, align 1
  %137 = bitcast i64 %123 to double
  %138 = fsub double %136, %137
  store double %138, double* %135, align 1, !tbaa !2451
  %139 = tail call double @llvm.trunc.f64(double %138) #11
  %140 = tail call double @llvm.fabs.f64(double %139) #11
  %141 = fcmp ogt double %140, 0x43E0000000000000
  %142 = fptosi double %139 to i64
  %143 = select i1 %141, i64 -9223372036854775808, i64 %142
  %144 = xor i64 %143, -9223372036854775808
  store i64 %144, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %145 = trunc i64 %143 to i32
  %146 = and i32 %145, 255
  %147 = tail call i32 @llvm.ctpop.i32(i32 %146) #11
  %148 = trunc i32 %147 to i8
  %149 = and i8 %148, 1
  %150 = xor i8 %149, 1
  store i8 %150, i8* %25, align 1, !tbaa !2446
  %151 = icmp eq i64 %144, 0
  %152 = zext i1 %151 to i8
  store i8 %152, i8* %33, align 1, !tbaa !2448
  %153 = lshr i64 %144, 63
  %154 = trunc i64 %153 to i8
  store i8 %154, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2447
  %155 = tail call double @llvm.trunc.f64(double %122) #11
  %156 = tail call double @llvm.fabs.f64(double %155) #11
  %157 = fcmp ogt double %156, 0x43E0000000000000
  %158 = fptosi double %155 to i64
  %159 = select i1 %157, i64 -9223372036854775808, i64 %158
  store i64 %159, i64* %RCX, align 8, !tbaa !2428
  %160 = add i64 %117, 54
  store i64 %160, i64* %PC, align 8
  %161 = fcmp uno double %122, %137
  br i1 %161, label %162, label %172

; <label>:162:                                    ; preds = %block_400850
  %163 = fadd double %122, %137
  %164 = bitcast double %163 to i64
  %165 = and i64 %164, 9221120237041090560
  %166 = icmp eq i64 %165, 9218868437227405312
  %167 = and i64 %164, 2251799813685247
  %168 = icmp ne i64 %167, 0
  %169 = and i1 %166, %168
  br i1 %169, label %170, label %178

; <label>:170:                                    ; preds = %162
  %171 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %160, %struct.Memory* %78) #16
  %.pre = load i64, i64* %RCX, align 8
  %.pre71 = load i64, i64* %PC, align 8
  %.pre72 = load i8, i8* %18, align 1, !tbaa !2432
  %.pre73 = load i64, i64* %RDI, align 8, !tbaa !2428
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3

; <label>:172:                                    ; preds = %block_400850
  %173 = fcmp ogt double %122, %137
  br i1 %173, label %178, label %174

; <label>:174:                                    ; preds = %172
  %175 = fcmp olt double %122, %137
  br i1 %175, label %178, label %176

; <label>:176:                                    ; preds = %174
  %177 = fcmp oeq double %122, %137
  br i1 %177, label %178, label %182

; <label>:178:                                    ; preds = %176, %174, %172, %162
  %179 = phi i8 [ 0, %172 ], [ 0, %174 ], [ 1, %176 ], [ 1, %162 ]
  %180 = phi i8 [ 0, %172 ], [ 0, %174 ], [ 0, %176 ], [ 1, %162 ]
  %181 = phi i8 [ 0, %172 ], [ 1, %174 ], [ 0, %176 ], [ 1, %162 ]
  store i8 %179, i8* %33, align 1, !tbaa !2453
  store i8 %180, i8* %25, align 1, !tbaa !2453
  store i8 %181, i8* %18, align 1, !tbaa !2453
  br label %182

; <label>:182:                                    ; preds = %178, %176
  %183 = phi i8 [ %181, %178 ], [ 0, %176 ]
  store i8 0, i8* %42, align 1, !tbaa !2453
  store i8 0, i8* %36, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3: ; preds = %182, %170
  %184 = phi i64 [ %.pre73, %170 ], [ %144, %182 ]
  %185 = phi i8 [ %.pre72, %170 ], [ %183, %182 ]
  %186 = phi i64 [ %.pre71, %170 ], [ %160, %182 ]
  %187 = phi i64 [ %.pre, %170 ], [ %159, %182 ]
  %188 = phi %struct.Memory* [ %171, %170 ], [ %78, %182 ]
  %189 = icmp ne i8 %185, 0
  %190 = select i1 %189, i64 %187, i64 %184
  store i64 %190, i64* %RDI, align 8, !tbaa !2428
  %191 = load i64, i64* %RBP, align 8
  %192 = add i64 %191, -144
  %193 = add i64 %186, 11
  store i64 %193, i64* %PC, align 8
  %194 = inttoptr i64 %192 to i64*
  %195 = load i64, i64* %194, align 8
  store i64 %195, i64* %RCX, align 8, !tbaa !2428
  %196 = add i64 %191, -152
  %197 = add i64 %186, 18
  store i64 %197, i64* %PC, align 8
  %198 = inttoptr i64 %196 to i64*
  store i64 %190, i64* %198, align 8
  %199 = load i64, i64* %RCX, align 8
  %200 = load i64, i64* %PC, align 8
  store i64 %199, i64* %RDI, align 8, !tbaa !2428
  %201 = load i64, i64* %RBP, align 8
  %202 = add i64 %201, -152
  %203 = add i64 %200, 10
  store i64 %203, i64* %PC, align 8
  %204 = inttoptr i64 %202 to i64*
  %205 = load i64, i64* %204, align 8
  store i64 %205, i64* %RSI, align 8, !tbaa !2428
  %206 = add i64 %200, -452
  %207 = add i64 %200, 15
  %208 = load i64, i64* %RSP, align 8, !tbaa !2428
  %209 = add i64 %208, -8
  %210 = inttoptr i64 %209 to i64*
  store i64 %207, i64* %210, align 8
  store i64 %209, i64* %RSP, align 8, !tbaa !2428
  store i64 %206, i64* %PC, align 8, !tbaa !2428
  %211 = tail call fastcc %struct.Memory* @ext_6050d0_memalign(%struct.State* nonnull %0, %struct.Memory* %188)
  %212 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 20480, i64* %RDX, align 8, !tbaa !2428
  store i64 20480, i64* %RSI, align 8, !tbaa !2428
  %213 = load i64, i64* %RBP, align 8
  %214 = add i64 %213, -24
  %215 = load i64, i64* %RAX, align 8
  %216 = add i64 %212, 18
  store i64 %216, i64* %PC, align 8
  %217 = inttoptr i64 %214 to i64*
  store i64 %215, i64* %217, align 8
  %218 = load i64, i64* %PC, align 8
  %219 = add i64 %218, -485
  %220 = add i64 %218, 5
  %221 = load i64, i64* %RSP, align 8, !tbaa !2428
  %222 = add i64 %221, -8
  %223 = inttoptr i64 %222 to i64*
  store i64 %220, i64* %223, align 8
  store i64 %222, i64* %RSP, align 8, !tbaa !2428
  store i64 %219, i64* %PC, align 8, !tbaa !2428
  %224 = tail call fastcc %struct.Memory* @ext_6050d0_memalign(%struct.State* nonnull %0, %struct.Memory* %211)
  %225 = load i64, i64* %PC, align 8
  store i64 512, i64* %RDI, align 8, !tbaa !2428
  %226 = load i64, i64* %RBP, align 8
  %227 = add i64 %226, -56
  %228 = load i64, i64* %RAX, align 8
  %229 = add i64 %225, 9
  store i64 %229, i64* %PC, align 8
  %230 = inttoptr i64 %227 to i64*
  store i64 %228, i64* %230, align 8
  %231 = load i64, i64* %RBP, align 8
  %232 = add i64 %231, -24
  %233 = load i64, i64* %PC, align 8
  %234 = add i64 %233, 4
  store i64 %234, i64* %PC, align 8
  %235 = inttoptr i64 %232 to i64*
  %236 = load i64, i64* %235, align 8
  store i64 %236, i64* %RSI, align 8, !tbaa !2428
  %237 = add i64 %231, -56
  %238 = add i64 %233, 8
  store i64 %238, i64* %PC, align 8
  %239 = inttoptr i64 %237 to i64*
  %240 = load i64, i64* %239, align 8
  store i64 %240, i64* %RDX, align 8, !tbaa !2428
  %241 = add i64 %233, 1357
  %242 = add i64 %233, 13
  %243 = load i64, i64* %RSP, align 8, !tbaa !2428
  %244 = add i64 %243, -8
  %245 = inttoptr i64 %244 to i64*
  store i64 %242, i64* %245, align 8
  store i64 %244, i64* %RSP, align 8, !tbaa !2428
  store i64 %241, i64* %PC, align 8, !tbaa !2428
  %246 = tail call %struct.Memory* @sub_400e70_makewt_renamed_(%struct.State* nonnull %0, i64 %241, %struct.Memory* %224)
  %247 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 16384, i64* %R8, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %248 = add i64 %247, -512
  %249 = add i64 %247, 19
  %250 = load i64, i64* %RSP, align 8, !tbaa !2428
  %251 = add i64 %250, -8
  %252 = inttoptr i64 %251 to i64*
  store i64 %249, i64* %252, align 8
  store i64 %251, i64* %RSP, align 8, !tbaa !2428
  store i64 %248, i64* %PC, align 8, !tbaa !2428
  %253 = tail call fastcc %struct.Memory* @ext_6050d0_memalign(%struct.State* nonnull %0, %struct.Memory* %246)
  %254 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 16384, i64* %R8, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %255 = load i64, i64* %RBP, align 8
  %256 = add i64 %255, -32
  %257 = load i64, i64* %RAX, align 8
  %258 = add i64 %254, 22
  store i64 %258, i64* %PC, align 8
  %259 = inttoptr i64 %256 to i64*
  store i64 %257, i64* %259, align 8
  %260 = load i64, i64* %PC, align 8
  %261 = add i64 %260, -553
  %262 = add i64 %260, 5
  %263 = load i64, i64* %RSP, align 8, !tbaa !2428
  %264 = add i64 %263, -8
  %265 = inttoptr i64 %264 to i64*
  store i64 %262, i64* %265, align 8
  store i64 %264, i64* %RSP, align 8, !tbaa !2428
  store i64 %261, i64* %PC, align 8, !tbaa !2428
  %266 = tail call fastcc %struct.Memory* @ext_6050d0_memalign(%struct.State* nonnull %0, %struct.Memory* %253)
  %267 = load i64, i64* %PC, align 8
  store i64 16, i64* %RDI, align 8, !tbaa !2428
  store i64 16384, i64* %R8, align 8, !tbaa !2428
  store i64 16384, i64* %RSI, align 8, !tbaa !2428
  %268 = load i64, i64* %RBP, align 8
  %269 = add i64 %268, -40
  %270 = load i64, i64* %RAX, align 8
  %271 = add i64 %267, 22
  store i64 %271, i64* %PC, align 8
  %272 = inttoptr i64 %269 to i64*
  store i64 %270, i64* %272, align 8
  %273 = load i64, i64* %PC, align 8
  %274 = add i64 %273, -580
  %275 = add i64 %273, 5
  %276 = load i64, i64* %RSP, align 8, !tbaa !2428
  %277 = add i64 %276, -8
  %278 = inttoptr i64 %277 to i64*
  store i64 %275, i64* %278, align 8
  store i64 %277, i64* %RSP, align 8, !tbaa !2428
  store i64 %274, i64* %PC, align 8, !tbaa !2428
  %279 = tail call fastcc %struct.Memory* @ext_6050d0_memalign(%struct.State* nonnull %0, %struct.Memory* %266)
  %280 = load i64, i64* %PC, align 8
  store i64 0, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  store i8 1, i8* %25, align 1, !tbaa !2446
  store i8 1, i8* %33, align 1, !tbaa !2448
  store i8 0, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i64 2047, i64* %RSI, align 8, !tbaa !2428
  %281 = load i64, i64* %RBP, align 8
  %282 = add i64 %281, -48
  %283 = load i64, i64* %RAX, align 8
  %284 = add i64 %280, 11
  store i64 %284, i64* %PC, align 8
  %285 = inttoptr i64 %282 to i64*
  store i64 %283, i64* %285, align 8
  %286 = load i64, i64* %RBP, align 8
  %287 = add i64 %286, -32
  %288 = load i64, i64* %PC, align 8
  %289 = add i64 %288, 4
  store i64 %289, i64* %PC, align 8
  %290 = inttoptr i64 %287 to i64*
  %291 = load i64, i64* %290, align 8
  store i64 %291, i64* %RDX, align 8, !tbaa !2428
  %292 = add i64 %288, 1628
  %293 = add i64 %288, 9
  %294 = load i64, i64* %RSP, align 8, !tbaa !2428
  %295 = add i64 %294, -8
  %296 = inttoptr i64 %295 to i64*
  store i64 %293, i64* %296, align 8
  store i64 %295, i64* %RSP, align 8, !tbaa !2428
  store i64 %292, i64* %PC, align 8, !tbaa !2428
  %297 = tail call %struct.Memory* @sub_400fe0_putdata_renamed_(%struct.State* nonnull %0, i64 %292, %struct.Memory* %279)
  %298 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  %299 = load i64, i64* %RBP, align 8
  %300 = add i64 %299, -32
  %301 = add i64 %298, 14
  store i64 %301, i64* %PC, align 8
  %302 = inttoptr i64 %300 to i64*
  %303 = load i64, i64* %302, align 8
  store i64 %303, i64* %RDX, align 8, !tbaa !2428
  %304 = add i64 %299, -24
  %305 = add i64 %298, 18
  store i64 %305, i64* %PC, align 8
  %306 = inttoptr i64 %304 to i64*
  %307 = load i64, i64* %306, align 8
  store i64 %307, i64* %RCX, align 8, !tbaa !2428
  %308 = add i64 %299, -56
  %309 = add i64 %298, 22
  store i64 %309, i64* %PC, align 8
  %310 = inttoptr i64 %308 to i64*
  %311 = load i64, i64* %310, align 8
  store i64 %311, i64* %R8, align 8, !tbaa !2428
  %312 = add i64 %298, 1747
  %313 = add i64 %298, 27
  %314 = load i64, i64* %RSP, align 8, !tbaa !2428
  %315 = add i64 %314, -8
  %316 = inttoptr i64 %315 to i64*
  store i64 %313, i64* %316, align 8
  store i64 %315, i64* %RSP, align 8, !tbaa !2428
  store i64 %312, i64* %PC, align 8, !tbaa !2428
  %317 = tail call %struct.Memory* @sub_401060_cdft_renamed_(%struct.State* nonnull %0, i64 %312, %struct.Memory* %297)
  %318 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 4294967295, i64* %RSI, align 8, !tbaa !2428
  %319 = load i64, i64* %RBP, align 8
  %320 = add i64 %319, -32
  %321 = add i64 %318, 14
  store i64 %321, i64* %PC, align 8
  %322 = inttoptr i64 %320 to i64*
  %323 = load i64, i64* %322, align 8
  store i64 %323, i64* %RDX, align 8, !tbaa !2428
  %324 = add i64 %319, -24
  %325 = add i64 %318, 18
  store i64 %325, i64* %PC, align 8
  %326 = inttoptr i64 %324 to i64*
  %327 = load i64, i64* %326, align 8
  store i64 %327, i64* %RCX, align 8, !tbaa !2428
  %328 = add i64 %319, -56
  %329 = add i64 %318, 22
  store i64 %329, i64* %PC, align 8
  %330 = inttoptr i64 %328 to i64*
  %331 = load i64, i64* %330, align 8
  store i64 %331, i64* %R8, align 8, !tbaa !2428
  %332 = add i64 %318, 1720
  %333 = add i64 %318, 27
  %334 = load i64, i64* %RSP, align 8, !tbaa !2428
  %335 = add i64 %334, -8
  %336 = inttoptr i64 %335 to i64*
  store i64 %333, i64* %336, align 8
  store i64 %335, i64* %RSP, align 8, !tbaa !2428
  store i64 %332, i64* %PC, align 8, !tbaa !2428
  %337 = tail call %struct.Memory* @sub_401060_cdft_renamed_(%struct.State* nonnull %0, i64 %332, %struct.Memory* %317)
  %338 = load i64, i64* %PC, align 8
  store i64 0, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  store i8 1, i8* %25, align 1, !tbaa !2446
  store i8 1, i8* %33, align 1, !tbaa !2448
  store i8 0, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i64 2047, i64* %RSI, align 8, !tbaa !2428
  %339 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 16) to i64*), align 16
  store i64 %339, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %340 = load i64, i64* %RBP, align 8
  %341 = add i64 %340, -32
  %342 = add i64 %338, 19
  store i64 %342, i64* %PC, align 8
  %343 = inttoptr i64 %341 to i64*
  %344 = load i64, i64* %343, align 8
  store i64 %344, i64* %RDX, align 8, !tbaa !2428
  %345 = add i64 %338, 1853
  %346 = add i64 %338, 24
  %347 = load i64, i64* %RSP, align 8, !tbaa !2428
  %348 = add i64 %347, -8
  %349 = inttoptr i64 %348 to i64*
  store i64 %346, i64* %349, align 8
  store i64 %348, i64* %RSP, align 8, !tbaa !2428
  store i64 %345, i64* %PC, align 8, !tbaa !2428
  %350 = tail call %struct.Memory* @sub_401100_errorcheck_renamed_(%struct.State* nonnull %0, i64 %345, %struct.Memory* %337)
  %351 = load i64, i64* %PC, align 8
  %352 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 8) to i64*), align 8
  store i64 %352, i64* %100, align 1, !tbaa !2451
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  %353 = load i64, i64* %RBP, align 8
  %354 = add i64 %353, -96
  %355 = add i64 %351, 13
  store i64 %355, i64* %PC, align 8
  %356 = load i64, i64* %69, align 1
  %357 = inttoptr i64 %354 to i64*
  store i64 %356, i64* %357, align 8
  %358 = load i64, i64* %RBP, align 8
  %359 = add i64 %358, -96
  %360 = load i64, i64* %PC, align 8
  %361 = add i64 %360, 5
  store i64 %361, i64* %PC, align 8
  %362 = inttoptr i64 %359 to i64*
  %363 = load i64, i64* %362, align 8
  %364 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 96) to i32*), align 16
  %365 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 100) to i32*), align 4
  %366 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 104) to i32*), align 8
  %367 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 108) to i32*), align 4
  store i32 %364, i32* %127, align 1, !tbaa !2475
  store i32 %365, i32* %130, align 1, !tbaa !2475
  store i32 %366, i32* %132, align 1, !tbaa !2475
  store i32 %367, i32* %134, align 1, !tbaa !2475
  %368 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %7, i64 0, i32 0, i32 0, i32 0, i64 0
  %369 = load i64, i64* %368, align 1
  %370 = and i64 %369, %363
  %371 = trunc i64 %370 to i32
  %372 = lshr i64 %370, 32
  %373 = trunc i64 %372 to i32
  %374 = bitcast [32 x %union.VectorReg]* %5 to i32*
  store i32 %371, i32* %374, align 1, !tbaa !2469
  %375 = getelementptr inbounds i8, i8* %85, i64 4
  %376 = bitcast i8* %375 to i32*
  store i32 %373, i32* %376, align 1, !tbaa !2469
  %377 = bitcast i64* %92 to i32*
  store i32 0, i32* %377, align 1, !tbaa !2469
  %378 = getelementptr inbounds i8, i8* %85, i64 12
  %379 = bitcast i8* %378 to i32*
  store i32 0, i32* %379, align 1, !tbaa !2469
  %380 = add i64 %360, 20
  store i64 %380, i64* %PC, align 8
  %381 = load double, double* %68, align 1
  %382 = load double, double* %99, align 1
  %383 = fcmp uno double %381, %382
  br i1 %383, label %384, label %394

; <label>:384:                                    ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3
  %385 = fadd double %381, %382
  %386 = bitcast double %385 to i64
  %387 = and i64 %386, 9221120237041090560
  %388 = icmp eq i64 %387, 9218868437227405312
  %389 = and i64 %386, 2251799813685247
  %390 = icmp ne i64 %389, 0
  %391 = and i1 %388, %390
  br i1 %391, label %392, label %400

; <label>:392:                                    ; preds = %384
  %393 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %380, %struct.Memory* %350) #16
  %.pre74 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2

; <label>:394:                                    ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit3
  %395 = fcmp ogt double %381, %382
  br i1 %395, label %400, label %396

; <label>:396:                                    ; preds = %394
  %397 = fcmp olt double %381, %382
  br i1 %397, label %400, label %398

; <label>:398:                                    ; preds = %396
  %399 = fcmp oeq double %381, %382
  br i1 %399, label %400, label %404

; <label>:400:                                    ; preds = %398, %396, %394, %384
  %401 = phi i8 [ 0, %394 ], [ 0, %396 ], [ 1, %398 ], [ 1, %384 ]
  %402 = phi i8 [ 0, %394 ], [ 0, %396 ], [ 0, %398 ], [ 1, %384 ]
  %403 = phi i8 [ 0, %394 ], [ 1, %396 ], [ 0, %398 ], [ 1, %384 ]
  store i8 %401, i8* %33, align 1, !tbaa !2453
  store i8 %402, i8* %25, align 1, !tbaa !2453
  store i8 %403, i8* %18, align 1, !tbaa !2453
  br label %404

; <label>:404:                                    ; preds = %400, %398
  store i8 0, i8* %42, align 1, !tbaa !2453
  store i8 0, i8* %36, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2: ; preds = %404, %392
  %405 = phi i64 [ %.pre74, %392 ], [ %380, %404 ]
  %406 = phi %struct.Memory* [ %393, %392 ], [ %350, %404 ]
  %407 = load i8, i8* %18, align 1, !tbaa !2432
  %408 = load i8, i8* %33, align 1, !tbaa !2448
  %409 = or i8 %408, %407
  %410 = icmp ne i8 %409, 0
  %.v97 = select i1 %410, i64 39, i64 6
  %411 = add i64 %.v97, %405
  store i64 %411, i64* %PC, align 8, !tbaa !2428
  br i1 %410, label %block_400a23, label %block_400a02

block_400cf3:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1
  %412 = load i64, i64* %RBP, align 8
  %413 = add i64 %412, -40
  %414 = add i64 %743, 4
  store i64 %414, i64* %PC, align 8
  %415 = inttoptr i64 %413 to i64*
  %416 = load i64, i64* %415, align 8
  store i64 %416, i64* %RAX, align 8, !tbaa !2428
  %417 = add i64 %412, -12
  %418 = add i64 %743, 7
  store i64 %418, i64* %PC, align 8
  %419 = inttoptr i64 %417 to i32*
  %420 = load i32, i32* %419, align 4
  %421 = shl i32 %420, 1
  %422 = icmp slt i32 %420, 0
  %423 = icmp slt i32 %421, 0
  %424 = xor i1 %422, %423
  %425 = zext i32 %421 to i64
  store i64 %425, i64* %RCX, align 8, !tbaa !2428
  %.lobit62 = lshr i32 %420, 31
  %426 = trunc i32 %.lobit62 to i8
  store i8 %426, i8* %18, align 1, !tbaa !2453
  %427 = and i32 %421, 254
  %428 = tail call i32 @llvm.ctpop.i32(i32 %427) #11
  %429 = trunc i32 %428 to i8
  %430 = and i8 %429, 1
  %431 = xor i8 %430, 1
  store i8 %431, i8* %25, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  %432 = icmp eq i32 %421, 0
  %433 = zext i1 %432 to i8
  store i8 %433, i8* %33, align 1, !tbaa !2453
  %434 = lshr i32 %420, 30
  %435 = trunc i32 %434 to i8
  %436 = and i8 %435, 1
  store i8 %436, i8* %36, align 1, !tbaa !2453
  %437 = zext i1 %424 to i8
  store i8 %437, i8* %42, align 1, !tbaa !2453
  %438 = sext i32 %421 to i64
  store i64 %438, i64* %RDX, align 8, !tbaa !2428
  %439 = shl nsw i64 %438, 3
  %440 = add i64 %439, %416
  %441 = add i64 %743, 18
  store i64 %441, i64* %PC, align 8
  %442 = inttoptr i64 %440 to i64*
  %443 = load i64, i64* %442, align 8
  store i64 %443, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  br label %block_400d22

block_400c64:                                     ; preds = %block_400b87
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 4294967295, i64* %RSI, align 8, !tbaa !2428
  %444 = add i64 %1417, -40
  %445 = add i64 %1445, 14
  store i64 %445, i64* %PC, align 8
  %446 = inttoptr i64 %444 to i64*
  %447 = load i64, i64* %446, align 8
  store i64 %447, i64* %RDX, align 8, !tbaa !2428
  %448 = add i64 %1417, -24
  %449 = add i64 %1445, 18
  store i64 %449, i64* %PC, align 8
  %450 = inttoptr i64 %448 to i64*
  %451 = load i64, i64* %450, align 8
  store i64 %451, i64* %RCX, align 8, !tbaa !2428
  %452 = add i64 %1417, -56
  %453 = add i64 %1445, 22
  store i64 %453, i64* %PC, align 8
  %454 = inttoptr i64 %452 to i64*
  %455 = load i64, i64* %454, align 8
  store i64 %455, i64* %R8, align 8, !tbaa !2428
  %456 = add i64 %1445, 1020
  %457 = add i64 %1445, 27
  %458 = load i64, i64* %RSP, align 8, !tbaa !2428
  %459 = add i64 %458, -8
  %460 = inttoptr i64 %459 to i64*
  store i64 %457, i64* %460, align 8
  store i64 %459, i64* %RSP, align 8, !tbaa !2428
  store i64 %456, i64* %PC, align 8, !tbaa !2428
  %461 = tail call %struct.Memory* @sub_401060_cdft_renamed_(%struct.State* nonnull %0, i64 %456, %struct.Memory* %665)
  %462 = load i64, i64* %RBP, align 8
  %463 = add i64 %462, -8
  %464 = load i64, i64* %PC, align 8
  %465 = add i64 %464, 3
  store i64 %465, i64* %PC, align 8
  %466 = inttoptr i64 %463 to i32*
  %467 = load i32, i32* %466, align 4
  %468 = add i32 %467, 1
  %469 = zext i32 %468 to i64
  store i64 %469, i64* %RAX, align 8, !tbaa !2428
  %470 = icmp eq i32 %467, -1
  %471 = icmp eq i32 %468, 0
  %472 = or i1 %470, %471
  %473 = zext i1 %472 to i8
  store i8 %473, i8* %18, align 1, !tbaa !2432
  %474 = and i32 %468, 255
  %475 = tail call i32 @llvm.ctpop.i32(i32 %474) #11
  %476 = trunc i32 %475 to i8
  %477 = and i8 %476, 1
  %478 = xor i8 %477, 1
  store i8 %478, i8* %25, align 1, !tbaa !2446
  %479 = xor i32 %468, %467
  %480 = lshr i32 %479, 4
  %481 = trunc i32 %480 to i8
  %482 = and i8 %481, 1
  store i8 %482, i8* %30, align 1, !tbaa !2447
  %483 = zext i1 %471 to i8
  store i8 %483, i8* %33, align 1, !tbaa !2448
  %484 = lshr i32 %468, 31
  %485 = trunc i32 %484 to i8
  store i8 %485, i8* %36, align 1, !tbaa !2449
  %486 = lshr i32 %467, 31
  %487 = xor i32 %484, %486
  %488 = add nuw nsw i32 %487, %484
  %489 = icmp eq i32 %488, 2
  %490 = zext i1 %489 to i8
  store i8 %490, i8* %42, align 1, !tbaa !2450
  %491 = add i64 %464, 9
  store i64 %491, i64* %PC, align 8
  store i32 %468, i32* %466, align 4
  %492 = load i64, i64* %PC, align 8
  %493 = add i64 %492, -354
  store i64 %493, i64* %PC, align 8, !tbaa !2428
  br label %block_400b26

block_400dde:                                     ; preds = %block_400cb7
  %494 = add i64 %1447, -32
  %495 = add i64 %1475, 4
  store i64 %495, i64* %PC, align 8
  %496 = inttoptr i64 %494 to i64*
  %497 = load i64, i64* %496, align 8
  store i64 %497, i64* %RAX, align 8, !tbaa !2428
  store i64 %497, i64* %RDI, align 8, !tbaa !2428
  %498 = add i64 %1475, -1838
  %499 = add i64 %1475, 12
  %500 = load i64, i64* %RSP, align 8, !tbaa !2428
  %501 = add i64 %500, -8
  %502 = inttoptr i64 %501 to i64*
  store i64 %499, i64* %502, align 8
  store i64 %501, i64* %RSP, align 8, !tbaa !2428
  store i64 %498, i64* %PC, align 8, !tbaa !2428
  %503 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %MEMORY.5)
  %504 = load i64, i64* %RBP, align 8
  %505 = add i64 %504, -56
  %506 = load i64, i64* %PC, align 8
  %507 = add i64 %506, 4
  store i64 %507, i64* %PC, align 8
  %508 = inttoptr i64 %505 to i64*
  %509 = load i64, i64* %508, align 8
  store i64 %509, i64* %RAX, align 8, !tbaa !2428
  store i64 %509, i64* %RDI, align 8, !tbaa !2428
  %510 = add i64 %506, -1850
  %511 = add i64 %506, 12
  %512 = load i64, i64* %RSP, align 8, !tbaa !2428
  %513 = add i64 %512, -8
  %514 = inttoptr i64 %513 to i64*
  store i64 %511, i64* %514, align 8
  store i64 %513, i64* %RSP, align 8, !tbaa !2428
  store i64 %510, i64* %PC, align 8, !tbaa !2428
  %515 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %503)
  %516 = load i64, i64* %RBP, align 8
  %517 = add i64 %516, -24
  %518 = load i64, i64* %PC, align 8
  %519 = add i64 %518, 4
  store i64 %519, i64* %PC, align 8
  %520 = inttoptr i64 %517 to i64*
  %521 = load i64, i64* %520, align 8
  store i64 %521, i64* %RAX, align 8, !tbaa !2428
  store i64 %521, i64* %RDI, align 8, !tbaa !2428
  %522 = add i64 %518, -1862
  %523 = add i64 %518, 12
  %524 = load i64, i64* %RSP, align 8, !tbaa !2428
  %525 = add i64 %524, -8
  %526 = inttoptr i64 %525 to i64*
  store i64 %523, i64* %526, align 8
  store i64 %525, i64* %RSP, align 8, !tbaa !2428
  store i64 %522, i64* %PC, align 8, !tbaa !2428
  %527 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %515)
  %528 = load i64, i64* %RBP, align 8
  %529 = add i64 %528, -40
  %530 = load i64, i64* %PC, align 8
  %531 = add i64 %530, 4
  store i64 %531, i64* %PC, align 8
  %532 = inttoptr i64 %529 to i64*
  %533 = load i64, i64* %532, align 8
  store i64 %533, i64* %RAX, align 8, !tbaa !2428
  store i64 %533, i64* %RDI, align 8, !tbaa !2428
  %534 = add i64 %530, -1874
  %535 = add i64 %530, 12
  %536 = load i64, i64* %RSP, align 8, !tbaa !2428
  %537 = add i64 %536, -8
  %538 = inttoptr i64 %537 to i64*
  store i64 %535, i64* %538, align 8
  store i64 %537, i64* %RSP, align 8, !tbaa !2428
  store i64 %534, i64* %PC, align 8, !tbaa !2428
  %539 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %527)
  %540 = load i64, i64* %RBP, align 8
  %541 = add i64 %540, -48
  %542 = load i64, i64* %PC, align 8
  %543 = add i64 %542, 4
  store i64 %543, i64* %PC, align 8
  %544 = inttoptr i64 %541 to i64*
  %545 = load i64, i64* %544, align 8
  store i64 %545, i64* %RAX, align 8, !tbaa !2428
  store i64 %545, i64* %RDI, align 8, !tbaa !2428
  %546 = add i64 %542, -1886
  %547 = add i64 %542, 12
  %548 = load i64, i64* %RSP, align 8, !tbaa !2428
  %549 = add i64 %548, -8
  %550 = inttoptr i64 %549 to i64*
  store i64 %547, i64* %550, align 8
  store i64 %549, i64* %RSP, align 8, !tbaa !2428
  store i64 %546, i64* %PC, align 8, !tbaa !2428
  %551 = tail call fastcc %struct.Memory* @ext_6050e8_free(%struct.State* nonnull %0, %struct.Memory* %539)
  %552 = load i64, i64* %PC, align 8
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  %553 = load i64, i64* %RSP, align 8
  %554 = add i64 %553, 224
  store i64 %554, i64* %RSP, align 8, !tbaa !2428
  %555 = icmp ugt i64 %553, -225
  %556 = zext i1 %555 to i8
  store i8 %556, i8* %18, align 1, !tbaa !2432
  %557 = trunc i64 %554 to i32
  %558 = and i32 %557, 255
  %559 = tail call i32 @llvm.ctpop.i32(i32 %558) #11
  %560 = trunc i32 %559 to i8
  %561 = and i8 %560, 1
  %562 = xor i8 %561, 1
  store i8 %562, i8* %25, align 1, !tbaa !2446
  %563 = xor i64 %554, %553
  %564 = lshr i64 %563, 4
  %565 = trunc i64 %564 to i8
  %566 = and i8 %565, 1
  store i8 %566, i8* %30, align 1, !tbaa !2447
  %567 = icmp eq i64 %554, 0
  %568 = zext i1 %567 to i8
  store i8 %568, i8* %33, align 1, !tbaa !2448
  %569 = lshr i64 %554, 63
  %570 = trunc i64 %569 to i8
  store i8 %570, i8* %36, align 1, !tbaa !2449
  %571 = lshr i64 %553, 63
  %572 = xor i64 %569, %571
  %573 = add nuw nsw i64 %572, %569
  %574 = icmp eq i64 %573, 2
  %575 = zext i1 %574 to i8
  store i8 %575, i8* %42, align 1, !tbaa !2450
  %576 = add i64 %552, 10
  store i64 %576, i64* %PC, align 8
  %577 = add i64 %553, 232
  %578 = inttoptr i64 %554 to i64*
  %579 = load i64, i64* %578, align 8
  store i64 %579, i64* %RBP, align 8, !tbaa !2428
  store i64 %577, i64* %RSP, align 8, !tbaa !2428
  %580 = add i64 %552, 11
  store i64 %580, i64* %PC, align 8
  %581 = inttoptr i64 %577 to i64*
  %582 = load i64, i64* %581, align 8
  store i64 %582, i64* %PC, align 8, !tbaa !2428
  %583 = add i64 %553, 240
  store i64 %583, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %551

block_400d64:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %584 = load i64, i64* %RBP, align 8
  %585 = add i64 %584, -40
  %586 = add i64 %1020, 4
  store i64 %586, i64* %PC, align 8
  %587 = inttoptr i64 %585 to i64*
  %588 = load i64, i64* %587, align 8
  store i64 %588, i64* %RAX, align 8, !tbaa !2428
  %589 = add i64 %584, -12
  %590 = add i64 %1020, 7
  store i64 %590, i64* %PC, align 8
  %591 = inttoptr i64 %589 to i32*
  %592 = load i32, i32* %591, align 4
  %593 = shl i32 %592, 1
  %594 = or i32 %593, 1
  %595 = zext i32 %594 to i64
  store i64 %595, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %596 = and i32 %594, 255
  %597 = tail call i32 @llvm.ctpop.i32(i32 %596) #11
  %598 = trunc i32 %597 to i8
  %599 = and i8 %598, 1
  %600 = xor i8 %599, 1
  store i8 %600, i8* %25, align 1, !tbaa !2446
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i8 0, i8* %33, align 1, !tbaa !2448
  %601 = lshr i32 %592, 30
  %602 = trunc i32 %601 to i8
  %603 = and i8 %602, 1
  store i8 %603, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  %604 = sext i32 %594 to i64
  store i64 %604, i64* %RDX, align 8, !tbaa !2428
  %605 = shl nsw i64 %604, 3
  %606 = add i64 %605, %588
  %607 = add i64 %1020, 21
  store i64 %607, i64* %PC, align 8
  %608 = inttoptr i64 %606 to i64*
  %609 = load i64, i64* %608, align 8
  store i64 %609, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  br label %block_400d96

block_400b33:                                     ; preds = %block_400b26
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RAX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %610 = add i64 %745, -40
  %611 = add i64 %774, 21
  store i64 %611, i64* %PC, align 8
  %612 = inttoptr i64 %610 to i64*
  %613 = load i64, i64* %612, align 8
  store i64 %613, i64* %RCX, align 8, !tbaa !2428
  %614 = add i64 %745, -48
  %615 = add i64 %774, 25
  store i64 %615, i64* %PC, align 8
  %616 = inttoptr i64 %614 to i64*
  %617 = load i64, i64* %616, align 8
  store i64 %617, i64* %R8, align 8, !tbaa !2428
  %618 = add i64 %745, -176
  %619 = add i64 %774, 31
  store i64 %619, i64* %PC, align 8
  %620 = inttoptr i64 %618 to i32*
  store i32 2048, i32* %620, align 4
  %621 = load i64, i64* %RCX, align 8
  %622 = load i64, i64* %PC, align 8
  store i64 %621, i64* %RDI, align 8, !tbaa !2428
  %623 = load i64, i64* %RBP, align 8
  %624 = add i64 %623, -180
  %625 = load i32, i32* %ESI, align 4
  %626 = add i64 %622, 9
  store i64 %626, i64* %PC, align 8
  %627 = inttoptr i64 %624 to i32*
  store i32 %625, i32* %627, align 4
  %628 = load i64, i64* %R8, align 8
  %629 = load i64, i64* %PC, align 8
  store i64 %628, i64* %RSI, align 8, !tbaa !2428
  %630 = add i64 %629, -1083
  %631 = add i64 %629, 8
  %632 = load i64, i64* %RSP, align 8, !tbaa !2428
  %633 = add i64 %632, -8
  %634 = inttoptr i64 %633 to i64*
  store i64 %631, i64* %634, align 8
  store i64 %633, i64* %RSP, align 8, !tbaa !2428
  store i64 %630, i64* %PC, align 8, !tbaa !2428
  %635 = tail call fastcc %struct.Memory* @ext_605128_memcpy(%struct.State* nonnull %0, %struct.Memory* %MEMORY.0)
  %636 = load i64, i64* %RBP, align 8
  %637 = add i64 %636, -40
  %638 = load i64, i64* %PC, align 8
  %639 = add i64 %638, 4
  store i64 %639, i64* %PC, align 8
  %640 = inttoptr i64 %637 to i64*
  %641 = load i64, i64* %640, align 8
  store i64 %641, i64* %RDX, align 8, !tbaa !2428
  %642 = add i64 %636, -24
  %643 = add i64 %638, 8
  store i64 %643, i64* %PC, align 8
  %644 = inttoptr i64 %642 to i64*
  %645 = load i64, i64* %644, align 8
  store i64 %645, i64* %RCX, align 8, !tbaa !2428
  %646 = add i64 %636, -56
  %647 = add i64 %638, 12
  store i64 %647, i64* %PC, align 8
  %648 = inttoptr i64 %646 to i64*
  %649 = load i64, i64* %648, align 8
  store i64 %649, i64* %R8, align 8, !tbaa !2428
  %650 = add i64 %636, -176
  %651 = add i64 %638, 18
  store i64 %651, i64* %PC, align 8
  %652 = inttoptr i64 %650 to i32*
  %653 = load i32, i32* %652, align 4
  %654 = zext i32 %653 to i64
  store i64 %654, i64* %RDI, align 8, !tbaa !2428
  %655 = add i64 %636, -180
  %656 = add i64 %638, 24
  store i64 %656, i64* %PC, align 8
  %657 = inttoptr i64 %655 to i32*
  %658 = load i32, i32* %657, align 4
  %659 = zext i32 %658 to i64
  store i64 %659, i64* %RSI, align 8, !tbaa !2428
  %660 = add i64 %638, 1277
  %661 = add i64 %638, 29
  %662 = load i64, i64* %RSP, align 8, !tbaa !2428
  %663 = add i64 %662, -8
  %664 = inttoptr i64 %663 to i64*
  store i64 %661, i64* %664, align 8
  store i64 %663, i64* %RSP, align 8, !tbaa !2428
  store i64 %660, i64* %PC, align 8, !tbaa !2428
  %665 = tail call %struct.Memory* @sub_401060_cdft_renamed_(%struct.State* nonnull %0, i64 %660, %struct.Memory* %635)
  %666 = load i64, i64* %RBP, align 8
  %667 = add i64 %666, -100
  %668 = load i64, i64* %PC, align 8
  %669 = add i64 %668, 7
  store i64 %669, i64* %PC, align 8
  %670 = inttoptr i64 %667 to i32*
  store i32 0, i32* %670, align 4
  %.pre86 = load i64, i64* %PC, align 8
  br label %block_400b87

block_400cc4:                                     ; preds = %block_400cb7
  %671 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 48) to i64*), align 16
  store i64 %671, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %672 = add i64 %1447, -40
  %673 = add i64 %1475, 12
  store i64 %673, i64* %PC, align 8
  %674 = inttoptr i64 %672 to i64*
  %675 = load i64, i64* %674, align 8
  store i64 %675, i64* %RAX, align 8, !tbaa !2428
  %676 = add i64 %1475, 15
  store i64 %676, i64* %PC, align 8
  %677 = load i32, i32* %1450, align 4
  %678 = shl i32 %677, 1
  %679 = icmp slt i32 %677, 0
  %680 = icmp slt i32 %678, 0
  %681 = xor i1 %679, %680
  %682 = zext i32 %678 to i64
  store i64 %682, i64* %RCX, align 8, !tbaa !2428
  %.lobit61 = lshr i32 %677, 31
  %683 = trunc i32 %.lobit61 to i8
  store i8 %683, i8* %18, align 1, !tbaa !2453
  %684 = and i32 %678, 254
  %685 = tail call i32 @llvm.ctpop.i32(i32 %684) #11
  %686 = trunc i32 %685 to i8
  %687 = and i8 %686, 1
  %688 = xor i8 %687, 1
  store i8 %688, i8* %25, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  %689 = icmp eq i32 %678, 0
  %690 = zext i1 %689 to i8
  store i8 %690, i8* %33, align 1, !tbaa !2453
  %691 = lshr i32 %677, 30
  %692 = trunc i32 %691 to i8
  %693 = and i8 %692, 1
  store i8 %693, i8* %36, align 1, !tbaa !2453
  %694 = zext i1 %681 to i8
  store i8 %694, i8* %42, align 1, !tbaa !2453
  %695 = sext i32 %678 to i64
  store i64 %695, i64* %RDX, align 8, !tbaa !2428
  %696 = shl nsw i64 %695, 3
  %697 = add i64 %696, %675
  %698 = add i64 %1475, 26
  store i64 %698, i64* %PC, align 8
  %699 = inttoptr i64 %697 to i64*
  %700 = load i64, i64* %699, align 8
  %701 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 96) to i32*), align 16
  %702 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 100) to i32*), align 4
  %703 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 104) to i32*), align 8
  %704 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 108) to i32*), align 4
  store i32 %701, i32* %127, align 1, !tbaa !2475
  store i32 %702, i32* %130, align 1, !tbaa !2475
  store i32 %703, i32* %132, align 1, !tbaa !2475
  store i32 %704, i32* %134, align 1, !tbaa !2475
  %705 = load i64, i64* %368, align 1
  %706 = and i64 %705, %700
  %707 = trunc i64 %706 to i32
  %708 = lshr i64 %706, 32
  %709 = trunc i64 %708 to i32
  store i32 %707, i32* %1398, align 1, !tbaa !2469
  store i32 %709, i32* %1400, align 1, !tbaa !2469
  store i32 0, i32* %1401, align 1, !tbaa !2469
  store i32 0, i32* %1403, align 1, !tbaa !2469
  %710 = add i64 %1475, 41
  store i64 %710, i64* %PC, align 8
  %711 = load double, double* %99, align 1
  %712 = bitcast i64 %671 to double
  %713 = fcmp uno double %711, %712
  br i1 %713, label %714, label %724

; <label>:714:                                    ; preds = %block_400cc4
  %715 = fadd double %712, %711
  %716 = bitcast double %715 to i64
  %717 = and i64 %716, 9221120237041090560
  %718 = icmp eq i64 %717, 9218868437227405312
  %719 = and i64 %716, 2251799813685247
  %720 = icmp ne i64 %719, 0
  %721 = and i1 %718, %720
  br i1 %721, label %722, label %730

; <label>:722:                                    ; preds = %714
  %723 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %710, %struct.Memory* %MEMORY.5) #16
  %.pre78 = load i64, i64* %PC, align 8
  %.pre79 = load i8, i8* %18, align 1, !tbaa !2432
  %.pre80 = load i8, i8* %33, align 1, !tbaa !2448
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1

; <label>:724:                                    ; preds = %block_400cc4
  %725 = fcmp ogt double %711, %712
  br i1 %725, label %730, label %726

; <label>:726:                                    ; preds = %724
  %727 = fcmp olt double %711, %712
  br i1 %727, label %730, label %728

; <label>:728:                                    ; preds = %726
  %729 = fcmp oeq double %711, %712
  br i1 %729, label %730, label %734

; <label>:730:                                    ; preds = %728, %726, %724, %714
  %731 = phi i8 [ 0, %724 ], [ 0, %726 ], [ 1, %728 ], [ 1, %714 ]
  %732 = phi i8 [ 0, %724 ], [ 0, %726 ], [ 0, %728 ], [ 1, %714 ]
  %733 = phi i8 [ 0, %724 ], [ 1, %726 ], [ 0, %728 ], [ 1, %714 ]
  store i8 %731, i8* %33, align 1, !tbaa !2453
  store i8 %732, i8* %25, align 1, !tbaa !2453
  store i8 %733, i8* %18, align 1, !tbaa !2453
  br label %734

; <label>:734:                                    ; preds = %730, %728
  %735 = phi i8 [ %731, %730 ], [ %690, %728 ]
  %736 = phi i8 [ %733, %730 ], [ %683, %728 ]
  store i8 0, i8* %42, align 1, !tbaa !2453
  store i8 0, i8* %36, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1: ; preds = %734, %722
  %737 = phi i8 [ %.pre80, %722 ], [ %735, %734 ]
  %738 = phi i8 [ %.pre79, %722 ], [ %736, %734 ]
  %739 = phi i64 [ %.pre78, %722 ], [ %710, %734 ]
  %740 = phi %struct.Memory* [ %723, %722 ], [ %MEMORY.5, %734 ]
  %741 = or i8 %738, %737
  %742 = icmp ne i8 %741, 0
  %.v89 = select i1 %742, i64 37, i64 6
  %743 = add i64 %.v89, %739
  store i64 %743, i64* %PC, align 8, !tbaa !2428
  br i1 %742, label %block_400d12, label %block_400cf3

block_400b26:                                     ; preds = %block_400adb, %block_400c64
  %744 = phi i64 [ %.pre76, %block_400adb ], [ %493, %block_400c64 ]
  %MEMORY.0 = phi %struct.Memory* [ %854, %block_400adb ], [ %461, %block_400c64 ]
  %745 = load i64, i64* %RBP, align 8
  %746 = add i64 %745, -8
  %747 = add i64 %744, 7
  store i64 %747, i64* %PC, align 8
  %748 = inttoptr i64 %746 to i32*
  %749 = load i32, i32* %748, align 4
  %750 = add i32 %749, -150000
  %751 = icmp ult i32 %749, 150000
  %752 = zext i1 %751 to i8
  store i8 %752, i8* %18, align 1, !tbaa !2432
  %753 = and i32 %750, 255
  %754 = tail call i32 @llvm.ctpop.i32(i32 %753) #11
  %755 = trunc i32 %754 to i8
  %756 = and i8 %755, 1
  %757 = xor i8 %756, 1
  store i8 %757, i8* %25, align 1, !tbaa !2446
  %758 = xor i32 %749, 16
  %759 = xor i32 %758, %750
  %760 = lshr i32 %759, 4
  %761 = trunc i32 %760 to i8
  %762 = and i8 %761, 1
  store i8 %762, i8* %30, align 1, !tbaa !2447
  %763 = icmp eq i32 %750, 0
  %764 = zext i1 %763 to i8
  store i8 %764, i8* %33, align 1, !tbaa !2448
  %765 = lshr i32 %750, 31
  %766 = trunc i32 %765 to i8
  store i8 %766, i8* %36, align 1, !tbaa !2449
  %767 = lshr i32 %749, 31
  %768 = xor i32 %765, %767
  %769 = add nuw nsw i32 %768, %767
  %770 = icmp eq i32 %769, 2
  %771 = zext i1 %770 to i8
  store i8 %771, i8* %42, align 1, !tbaa !2450
  %772 = icmp ne i8 %766, 0
  %773 = xor i1 %772, %770
  %.v87 = select i1 %773, i64 13, i64 359
  %774 = add i64 %.v87, %744
  store i64 %774, i64* %PC, align 8, !tbaa !2428
  br i1 %773, label %block_400b33, label %block_400c8d

block_400a7f:                                     ; preds = %block_400a8c, %block_400a23
  %775 = phi i64 [ %1562, %block_400a8c ], [ %.pre75, %block_400a23 ]
  %776 = load i64, i64* %RBP, align 8
  %777 = add i64 %776, -12
  %778 = add i64 %775, 7
  store i64 %778, i64* %PC, align 8
  %779 = inttoptr i64 %777 to i32*
  %780 = load i32, i32* %779, align 4
  %781 = add i32 %780, -1024
  %782 = icmp ult i32 %780, 1024
  %783 = zext i1 %782 to i8
  store i8 %783, i8* %18, align 1, !tbaa !2432
  %784 = and i32 %781, 255
  %785 = tail call i32 @llvm.ctpop.i32(i32 %784) #11
  %786 = trunc i32 %785 to i8
  %787 = and i8 %786, 1
  %788 = xor i8 %787, 1
  store i8 %788, i8* %25, align 1, !tbaa !2446
  %789 = xor i32 %781, %780
  %790 = lshr i32 %789, 4
  %791 = trunc i32 %790 to i8
  %792 = and i8 %791, 1
  store i8 %792, i8* %30, align 1, !tbaa !2447
  %793 = icmp eq i32 %781, 0
  %794 = zext i1 %793 to i8
  store i8 %794, i8* %33, align 1, !tbaa !2448
  %795 = lshr i32 %781, 31
  %796 = trunc i32 %795 to i8
  store i8 %796, i8* %36, align 1, !tbaa !2449
  %797 = lshr i32 %780, 31
  %798 = xor i32 %795, %797
  %799 = add nuw nsw i32 %798, %797
  %800 = icmp eq i32 %799, 2
  %801 = zext i1 %800 to i8
  store i8 %801, i8* %42, align 1, !tbaa !2450
  %802 = icmp ne i8 %796, 0
  %803 = xor i1 %802, %800
  %.v = select i1 %803, i64 13, i64 92
  %804 = add i64 %.v, %775
  store i64 %804, i64* %PC, align 8, !tbaa !2428
  br i1 %803, label %block_400a8c, label %block_400adb

block_400adb:                                     ; preds = %block_400a7f
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  store i8 1, i8* %25, align 1, !tbaa !2446
  store i8 1, i8* %33, align 1, !tbaa !2448
  store i8 0, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i64 1023, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RCX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %805 = add i64 %776, -48
  %806 = add i64 %804, 18
  store i64 %806, i64* %PC, align 8
  %807 = inttoptr i64 %805 to i64*
  %808 = load i64, i64* %807, align 8
  store i64 %808, i64* %RDI, align 8, !tbaa !2428
  %809 = add i64 %776, -168
  %810 = add i64 %804, 24
  store i64 %810, i64* %PC, align 8
  %811 = inttoptr i64 %809 to i32*
  store i32 1023, i32* %811, align 4
  %812 = load i32, i32* %EAX, align 4
  %813 = zext i32 %812 to i64
  %814 = load i64, i64* %PC, align 8
  store i64 %813, i64* %RSI, align 8, !tbaa !2428
  %815 = load i64, i64* %RBP, align 8
  %816 = add i64 %815, -172
  %817 = add i64 %814, 8
  store i64 %817, i64* %PC, align 8
  %818 = inttoptr i64 %816 to i32*
  store i32 %812, i32* %818, align 4
  %819 = load i64, i64* %PC, align 8
  %820 = add i64 %819, -1019
  %821 = add i64 %819, 5
  %822 = load i64, i64* %RSP, align 8, !tbaa !2428
  %823 = add i64 %822, -8
  %824 = inttoptr i64 %823 to i64*
  store i64 %821, i64* %824, align 8
  store i64 %823, i64* %RSP, align 8, !tbaa !2428
  store i64 %820, i64* %PC, align 8, !tbaa !2428
  %825 = tail call fastcc %struct.Memory* @ext_605110_memset(%struct.State* nonnull %0, %struct.Memory* %929)
  %826 = load i64, i64* %RBP, align 8
  %827 = add i64 %826, -48
  %828 = load i64, i64* %PC, align 8
  %829 = add i64 %828, 4
  store i64 %829, i64* %PC, align 8
  %830 = inttoptr i64 %827 to i64*
  %831 = load i64, i64* %830, align 8
  store i64 %831, i64* %RDX, align 8, !tbaa !2428
  %832 = add i64 %826, -172
  %833 = add i64 %828, 10
  store i64 %833, i64* %PC, align 8
  %834 = inttoptr i64 %832 to i32*
  %835 = load i32, i32* %834, align 4
  %836 = zext i32 %835 to i64
  store i64 %836, i64* %RDI, align 8, !tbaa !2428
  %837 = add i64 %826, -168
  %838 = add i64 %828, 16
  store i64 %838, i64* %PC, align 8
  %839 = inttoptr i64 %837 to i32*
  %840 = load i32, i32* %839, align 4
  %841 = zext i32 %840 to i64
  store i64 %841, i64* %RSI, align 8, !tbaa !2428
  %842 = add i64 %828, 1248
  %843 = add i64 %828, 21
  %844 = load i64, i64* %RSP, align 8, !tbaa !2428
  %845 = add i64 %844, -8
  %846 = inttoptr i64 %845 to i64*
  store i64 %843, i64* %846, align 8
  store i64 %845, i64* %RSP, align 8, !tbaa !2428
  store i64 %842, i64* %PC, align 8, !tbaa !2428
  %847 = tail call %struct.Memory* @sub_400fe0_putdata_renamed_(%struct.State* nonnull %0, i64 %842, %struct.Memory* %825)
  %848 = load i64, i64* %PC, align 8
  %849 = add i64 %848, 795
  %850 = add i64 %848, 5
  %851 = load i64, i64* %RSP, align 8, !tbaa !2428
  %852 = add i64 %851, -8
  %853 = inttoptr i64 %852 to i64*
  store i64 %850, i64* %853, align 8
  store i64 %852, i64* %RSP, align 8, !tbaa !2428
  store i64 %849, i64* %PC, align 8, !tbaa !2428
  %854 = tail call %struct.Memory* @sub_400e30_get_time_renamed_(%struct.State* nonnull %0, i64 %849, %struct.Memory* %847)
  %855 = load i64, i64* %RBP, align 8
  %856 = add i64 %855, -64
  %857 = load i64, i64* %PC, align 8
  %858 = add i64 %857, 5
  store i64 %858, i64* %PC, align 8
  %859 = load i64, i64* %69, align 1
  %860 = inttoptr i64 %856 to i64*
  store i64 %859, i64* %860, align 8
  %861 = load i64, i64* %RBP, align 8
  %862 = add i64 %861, -8
  %863 = load i64, i64* %PC, align 8
  %864 = add i64 %863, 7
  store i64 %864, i64* %PC, align 8
  %865 = inttoptr i64 %862 to i32*
  store i32 0, i32* %865, align 4
  %.pre76 = load i64, i64* %PC, align 8
  br label %block_400b26

block_400a23:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  store i8 1, i8* %25, align 1, !tbaa !2446
  store i8 1, i8* %33, align 1, !tbaa !2448
  store i8 0, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i64 1023, i64* %RSI, align 8, !tbaa !2428
  store i64 16384, i64* %RCX, align 8, !tbaa !2428
  store i64 16384, i64* %RDX, align 8, !tbaa !2428
  %866 = load i64, i64* %RBP, align 8
  %867 = add i64 %866, -32
  %868 = add i64 %411, 18
  store i64 %868, i64* %PC, align 8
  %869 = inttoptr i64 %867 to i64*
  %870 = load i64, i64* %869, align 8
  store i64 %870, i64* %RDI, align 8, !tbaa !2428
  %871 = add i64 %866, -160
  %872 = add i64 %411, 24
  store i64 %872, i64* %PC, align 8
  %873 = inttoptr i64 %871 to i32*
  store i32 1023, i32* %873, align 4
  %874 = load i32, i32* %EAX, align 4
  %875 = zext i32 %874 to i64
  %876 = load i64, i64* %PC, align 8
  store i64 %875, i64* %RSI, align 8, !tbaa !2428
  %877 = load i64, i64* %RBP, align 8
  %878 = add i64 %877, -164
  %879 = add i64 %876, 8
  store i64 %879, i64* %PC, align 8
  %880 = inttoptr i64 %878 to i32*
  store i32 %874, i32* %880, align 4
  %881 = load i64, i64* %PC, align 8
  %882 = add i64 %881, -835
  %883 = add i64 %881, 5
  %884 = load i64, i64* %RSP, align 8, !tbaa !2428
  %885 = add i64 %884, -8
  %886 = inttoptr i64 %885 to i64*
  store i64 %883, i64* %886, align 8
  store i64 %885, i64* %RSP, align 8, !tbaa !2428
  store i64 %882, i64* %PC, align 8, !tbaa !2428
  %887 = tail call fastcc %struct.Memory* @ext_605110_memset(%struct.State* nonnull %0, %struct.Memory* %406)
  %888 = load i64, i64* %RBP, align 8
  %889 = add i64 %888, -32
  %890 = load i64, i64* %PC, align 8
  %891 = add i64 %890, 4
  store i64 %891, i64* %PC, align 8
  %892 = inttoptr i64 %889 to i64*
  %893 = load i64, i64* %892, align 8
  store i64 %893, i64* %RDX, align 8, !tbaa !2428
  %894 = add i64 %888, -164
  %895 = add i64 %890, 10
  store i64 %895, i64* %PC, align 8
  %896 = inttoptr i64 %894 to i32*
  %897 = load i32, i32* %896, align 4
  %898 = zext i32 %897 to i64
  store i64 %898, i64* %RDI, align 8, !tbaa !2428
  %899 = add i64 %888, -160
  %900 = add i64 %890, 16
  store i64 %900, i64* %PC, align 8
  %901 = inttoptr i64 %899 to i32*
  %902 = load i32, i32* %901, align 4
  %903 = zext i32 %902 to i64
  store i64 %903, i64* %RSI, align 8, !tbaa !2428
  %904 = add i64 %890, 1432
  %905 = add i64 %890, 21
  %906 = load i64, i64* %RSP, align 8, !tbaa !2428
  %907 = add i64 %906, -8
  %908 = inttoptr i64 %907 to i64*
  store i64 %905, i64* %908, align 8
  store i64 %907, i64* %RSP, align 8, !tbaa !2428
  store i64 %904, i64* %PC, align 8, !tbaa !2428
  %909 = tail call %struct.Memory* @sub_400fe0_putdata_renamed_(%struct.State* nonnull %0, i64 %904, %struct.Memory* %887)
  %910 = load i64, i64* %PC, align 8
  store i64 2048, i64* %RDI, align 8, !tbaa !2428
  store i64 1, i64* %RSI, align 8, !tbaa !2428
  %911 = load i64, i64* %RBP, align 8
  %912 = add i64 %911, -32
  %913 = add i64 %910, 14
  store i64 %913, i64* %PC, align 8
  %914 = inttoptr i64 %912 to i64*
  %915 = load i64, i64* %914, align 8
  store i64 %915, i64* %RDX, align 8, !tbaa !2428
  %916 = add i64 %911, -24
  %917 = add i64 %910, 18
  store i64 %917, i64* %PC, align 8
  %918 = inttoptr i64 %916 to i64*
  %919 = load i64, i64* %918, align 8
  store i64 %919, i64* %RCX, align 8, !tbaa !2428
  %920 = add i64 %911, -56
  %921 = add i64 %910, 22
  store i64 %921, i64* %PC, align 8
  %922 = inttoptr i64 %920 to i64*
  %923 = load i64, i64* %922, align 8
  store i64 %923, i64* %R8, align 8, !tbaa !2428
  %924 = add i64 %910, 1539
  %925 = add i64 %910, 27
  %926 = load i64, i64* %RSP, align 8, !tbaa !2428
  %927 = add i64 %926, -8
  %928 = inttoptr i64 %927 to i64*
  store i64 %925, i64* %928, align 8
  store i64 %927, i64* %RSP, align 8, !tbaa !2428
  store i64 %924, i64* %PC, align 8, !tbaa !2428
  %929 = tail call %struct.Memory* @sub_401060_cdft_renamed_(%struct.State* nonnull %0, i64 %924, %struct.Memory* %909)
  %930 = load i64, i64* %RBP, align 8
  %931 = add i64 %930, -12
  %932 = load i64, i64* %PC, align 8
  %933 = add i64 %932, 7
  store i64 %933, i64* %PC, align 8
  %934 = inttoptr i64 %931 to i32*
  store i32 0, i32* %934, align 4
  %.pre75 = load i64, i64* %PC, align 8
  br label %block_400a7f

block_400d22:                                     ; preds = %block_400d12, %block_400cf3
  %935 = phi i64 [ 0, %block_400d12 ], [ %443, %block_400cf3 ]
  %936 = phi i64 [ %1357, %block_400d12 ], [ %441, %block_400cf3 ]
  %937 = phi i64 [ %.pre81, %block_400d12 ], [ %412, %block_400cf3 ]
  %.sink5 = phi i64 [ 5, %block_400d12 ], [ 21, %block_400cf3 ]
  %938 = add i64 %937, -192
  %939 = add i64 %936, 8
  store i64 %939, i64* %PC, align 8
  %940 = inttoptr i64 %938 to i64*
  store i64 %935, i64* %940, align 8
  %941 = load i64, i64* %PC, align 8
  %942 = add i64 %941, %.sink5
  %943 = load i64, i64* %RBP, align 8
  %944 = add i64 %943, -192
  %945 = add i64 %942, 8
  store i64 %945, i64* %PC, align 8
  %946 = inttoptr i64 %944 to i64*
  %947 = load i64, i64* %946, align 8
  store i64 %947, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %948 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 48) to i64*), align 16
  store i64 %948, i64* %100, align 1, !tbaa !2451
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  %949 = add i64 %943, -40
  %950 = add i64 %942, 20
  store i64 %950, i64* %PC, align 8
  %951 = inttoptr i64 %949 to i64*
  %952 = load i64, i64* %951, align 8
  store i64 %952, i64* %RAX, align 8, !tbaa !2428
  %953 = add i64 %943, -12
  %954 = add i64 %942, 23
  store i64 %954, i64* %PC, align 8
  %955 = inttoptr i64 %953 to i32*
  %956 = load i32, i32* %955, align 4
  %957 = shl i32 %956, 1
  %958 = or i32 %957, 1
  %959 = zext i32 %958 to i64
  store i64 %959, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %960 = and i32 %958, 255
  %961 = tail call i32 @llvm.ctpop.i32(i32 %960) #11
  %962 = trunc i32 %961 to i8
  %963 = and i8 %962, 1
  %964 = xor i8 %963, 1
  store i8 %964, i8* %25, align 1, !tbaa !2446
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i8 0, i8* %33, align 1, !tbaa !2448
  %965 = lshr i32 %956, 30
  %966 = trunc i32 %965 to i8
  %967 = and i8 %966, 1
  store i8 %967, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  %968 = sext i32 %958 to i64
  store i64 %968, i64* %RDX, align 8, !tbaa !2428
  %969 = shl nsw i64 %968, 3
  %970 = add i64 %969, %952
  %971 = add i64 %942, 37
  store i64 %971, i64* %PC, align 8
  %972 = inttoptr i64 %970 to i64*
  %973 = load i64, i64* %972, align 8
  %974 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 96) to i32*), align 16
  %975 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 100) to i32*), align 4
  %976 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 104) to i32*), align 8
  %977 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 108) to i32*), align 4
  store i32 %974, i32* %1405, align 1, !tbaa !2475
  store i32 %975, i32* %1407, align 1, !tbaa !2475
  store i32 %976, i32* %1409, align 1, !tbaa !2475
  store i32 %977, i32* %1411, align 1, !tbaa !2475
  %978 = load i64, i64* %1412, align 1
  %979 = and i64 %978, %973
  %980 = trunc i64 %979 to i32
  %981 = lshr i64 %979, 32
  %982 = trunc i64 %981 to i32
  store i32 %980, i32* %127, align 1, !tbaa !2469
  store i32 %982, i32* %130, align 1, !tbaa !2469
  store i32 0, i32* %132, align 1, !tbaa !2469
  store i32 0, i32* %134, align 1, !tbaa !2469
  %983 = add i64 %942, 52
  store i64 %983, i64* %PC, align 8
  %984 = load double, double* %135, align 1
  %985 = bitcast i64 %948 to double
  %986 = fcmp uno double %984, %985
  br i1 %986, label %987, label %997

; <label>:987:                                    ; preds = %block_400d22
  %988 = fadd double %985, %984
  %989 = bitcast double %988 to i64
  %990 = and i64 %989, 9221120237041090560
  %991 = icmp eq i64 %990, 9218868437227405312
  %992 = and i64 %989, 2251799813685247
  %993 = icmp ne i64 %992, 0
  %994 = and i1 %991, %993
  br i1 %994, label %995, label %1003

; <label>:995:                                    ; preds = %987
  %996 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %983, %struct.Memory* %740) #16
  %.pre83 = load i64, i64* %PC, align 8
  %.pre13 = load i64, i64* %RBP, align 8
  %.pre14 = load i64, i64* %69, align 1
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

; <label>:997:                                    ; preds = %block_400d22
  %998 = fcmp ogt double %984, %985
  br i1 %998, label %1003, label %999

; <label>:999:                                    ; preds = %997
  %1000 = fcmp olt double %984, %985
  br i1 %1000, label %1003, label %1001

; <label>:1001:                                   ; preds = %999
  %1002 = fcmp oeq double %984, %985
  br i1 %1002, label %1003, label %1007

; <label>:1003:                                   ; preds = %1001, %999, %997, %987
  %1004 = phi i8 [ 0, %997 ], [ 0, %999 ], [ 1, %1001 ], [ 1, %987 ]
  %1005 = phi i8 [ 0, %997 ], [ 0, %999 ], [ 0, %1001 ], [ 1, %987 ]
  %1006 = phi i8 [ 0, %997 ], [ 1, %999 ], [ 0, %1001 ], [ 1, %987 ]
  store i8 %1004, i8* %33, align 1, !tbaa !2453
  store i8 %1005, i8* %25, align 1, !tbaa !2453
  store i8 %1006, i8* %18, align 1, !tbaa !2453
  br label %1007

; <label>:1007:                                   ; preds = %1003, %1001
  store i8 0, i8* %42, align 1, !tbaa !2453
  store i8 0, i8* %36, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit: ; preds = %1007, %995
  %1008 = phi i64 [ %.pre14, %995 ], [ %947, %1007 ]
  %1009 = phi i64 [ %.pre13, %995 ], [ %943, %1007 ]
  %1010 = phi i64 [ %.pre83, %995 ], [ %983, %1007 ]
  %1011 = phi %struct.Memory* [ %996, %995 ], [ %740, %1007 ]
  %1012 = add i64 %1009, -200
  %1013 = add i64 %1010, 8
  store i64 %1013, i64* %PC, align 8
  %1014 = inttoptr i64 %1012 to i64*
  store i64 %1008, i64* %1014, align 8
  %1015 = load i64, i64* %PC, align 8
  %1016 = load i8, i8* %18, align 1, !tbaa !2432
  %1017 = load i8, i8* %33, align 1, !tbaa !2448
  %1018 = or i8 %1017, %1016
  %1019 = icmp ne i8 %1018, 0
  %.v98 = select i1 %1019, i64 40, i64 6
  %1020 = add i64 %.v98, %1015
  store i64 %1020, i64* %PC, align 8, !tbaa !2428
  br i1 %1019, label %block_400d86, label %block_400d64

block_400d96:                                     ; preds = %block_400d86, %block_400d64
  %1021 = phi i64 [ 0, %block_400d86 ], [ %609, %block_400d64 ]
  %1022 = phi i64 [ %1476, %block_400d86 ], [ %607, %block_400d64 ]
  %1023 = phi i64 [ %.pre84, %block_400d86 ], [ %584, %block_400d64 ]
  %.sink15 = phi i64 [ 5, %block_400d86 ], [ 21, %block_400d64 ]
  %1024 = add i64 %1023, -208
  %1025 = add i64 %1022, 8
  store i64 %1025, i64* %PC, align 8
  %1026 = inttoptr i64 %1024 to i64*
  store i64 %1021, i64* %1026, align 8
  %1027 = load i64, i64* %PC, align 8
  %1028 = add i64 %1027, %.sink15
  %1029 = load i64, i64* %RBP, align 8
  %1030 = add i64 %1029, -208
  %1031 = add i64 %1028, 8
  store i64 %1031, i64* %PC, align 8
  %1032 = inttoptr i64 %1030 to i64*
  %1033 = load i64, i64* %1032, align 8
  store i64 %1033, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  store i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 157), i64* %RDI, align 8, !tbaa !2428
  %1034 = add i64 %1029, -200
  %1035 = add i64 %1028, 26
  store i64 %1035, i64* %PC, align 8
  %1036 = inttoptr i64 %1034 to i64*
  %1037 = load i64, i64* %1036, align 8
  store i64 %1037, i64* %100, align 1, !tbaa !2451
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  %1038 = add i64 %1029, -216
  %1039 = add i64 %1028, 34
  store i64 %1039, i64* %PC, align 8
  %1040 = inttoptr i64 %1038 to i64*
  store i64 %1033, i64* %1040, align 8
  %1041 = load i64, i64* %PC, align 8
  %1042 = load <2 x i32>, <2 x i32>* %1413, align 1
  %1043 = load <2 x i32>, <2 x i32>* %1414, align 1
  %1044 = extractelement <2 x i32> %1042, i32 0
  store i32 %1044, i32* %374, align 1, !tbaa !2475
  %1045 = extractelement <2 x i32> %1042, i32 1
  store i32 %1045, i32* %376, align 1, !tbaa !2475
  %1046 = extractelement <2 x i32> %1043, i32 0
  store i32 %1046, i32* %377, align 1, !tbaa !2475
  %1047 = extractelement <2 x i32> %1043, i32 1
  store i32 %1047, i32* %379, align 1, !tbaa !2475
  %1048 = load i64, i64* %RBP, align 8
  %1049 = add i64 %1048, -216
  %1050 = add i64 %1041, 11
  store i64 %1050, i64* %PC, align 8
  %1051 = inttoptr i64 %1049 to i64*
  %1052 = load i64, i64* %1051, align 8
  store i64 %1052, i64* %100, align 1, !tbaa !2451
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  store i8 2, i8* %AL, align 1, !tbaa !2453
  %1053 = add i64 %1041, -1752
  %1054 = add i64 %1041, 18
  %1055 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1056 = add i64 %1055, -8
  %1057 = inttoptr i64 %1056 to i64*
  store i64 %1054, i64* %1057, align 8
  store i64 %1056, i64* %RSP, align 8, !tbaa !2428
  store i64 %1053, i64* %PC, align 8, !tbaa !2428
  %1058 = tail call fastcc %struct.Memory* @ext_4006e0_printf(%struct.State* nonnull %0, %struct.Memory* %1011)
  %1059 = load i64, i64* %RBP, align 8
  %1060 = add i64 %1059, -220
  %1061 = load i32, i32* %EAX, align 4
  %1062 = load i64, i64* %PC, align 8
  %1063 = add i64 %1062, 6
  store i64 %1063, i64* %PC, align 8
  %1064 = inttoptr i64 %1060 to i32*
  store i32 %1061, i32* %1064, align 4
  %1065 = load i64, i64* %RBP, align 8
  %1066 = add i64 %1065, -12
  %1067 = load i64, i64* %PC, align 8
  %1068 = add i64 %1067, 3
  store i64 %1068, i64* %PC, align 8
  %1069 = inttoptr i64 %1066 to i32*
  %1070 = load i32, i32* %1069, align 4
  %1071 = add i32 %1070, 1
  %1072 = zext i32 %1071 to i64
  store i64 %1072, i64* %RAX, align 8, !tbaa !2428
  %1073 = icmp eq i32 %1070, -1
  %1074 = icmp eq i32 %1071, 0
  %1075 = or i1 %1073, %1074
  %1076 = zext i1 %1075 to i8
  store i8 %1076, i8* %18, align 1, !tbaa !2432
  %1077 = and i32 %1071, 255
  %1078 = tail call i32 @llvm.ctpop.i32(i32 %1077) #11
  %1079 = trunc i32 %1078 to i8
  %1080 = and i8 %1079, 1
  %1081 = xor i8 %1080, 1
  store i8 %1081, i8* %25, align 1, !tbaa !2446
  %1082 = xor i32 %1071, %1070
  %1083 = lshr i32 %1082, 4
  %1084 = trunc i32 %1083 to i8
  %1085 = and i8 %1084, 1
  store i8 %1085, i8* %30, align 1, !tbaa !2447
  %1086 = zext i1 %1074 to i8
  store i8 %1086, i8* %33, align 1, !tbaa !2448
  %1087 = lshr i32 %1071, 31
  %1088 = trunc i32 %1087 to i8
  store i8 %1088, i8* %36, align 1, !tbaa !2449
  %1089 = lshr i32 %1070, 31
  %1090 = xor i32 %1087, %1089
  %1091 = add nuw nsw i32 %1090, %1087
  %1092 = icmp eq i32 %1091, 2
  %1093 = zext i1 %1092 to i8
  store i8 %1093, i8* %42, align 1, !tbaa !2450
  %1094 = add i64 %1067, 9
  store i64 %1094, i64* %PC, align 8
  store i32 %1071, i32* %1069, align 4
  %1095 = load i64, i64* %PC, align 8
  %1096 = add i64 %1095, -290
  store i64 %1096, i64* %PC, align 8, !tbaa !2428
  br label %block_400cb7

block_400b94:                                     ; preds = %block_400b87
  %1097 = add i64 %1417, -40
  %1098 = add i64 %1445, 4
  store i64 %1098, i64* %PC, align 8
  %1099 = inttoptr i64 %1097 to i64*
  %1100 = load i64, i64* %1099, align 8
  store i64 %1100, i64* %RAX, align 8, !tbaa !2428
  %1101 = add i64 %1445, 7
  store i64 %1101, i64* %PC, align 8
  %1102 = load i32, i32* %1420, align 4
  %1103 = shl i32 %1102, 1
  %1104 = icmp slt i32 %1102, 0
  %1105 = icmp slt i32 %1103, 0
  %1106 = xor i1 %1104, %1105
  %1107 = zext i32 %1103 to i64
  store i64 %1107, i64* %RCX, align 8, !tbaa !2428
  %.lobit55 = lshr i32 %1102, 31
  %1108 = trunc i32 %.lobit55 to i8
  store i8 %1108, i8* %18, align 1, !tbaa !2453
  %1109 = and i32 %1103, 254
  %1110 = tail call i32 @llvm.ctpop.i32(i32 %1109) #11
  %1111 = trunc i32 %1110 to i8
  %1112 = and i8 %1111, 1
  %1113 = xor i8 %1112, 1
  store i8 %1113, i8* %25, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  %1114 = icmp eq i32 %1103, 0
  %1115 = zext i1 %1114 to i8
  store i8 %1115, i8* %33, align 1, !tbaa !2453
  %1116 = lshr i32 %1102, 30
  %1117 = trunc i32 %1116 to i8
  %1118 = and i8 %1117, 1
  store i8 %1118, i8* %36, align 1, !tbaa !2453
  %1119 = zext i1 %1106 to i8
  store i8 %1119, i8* %42, align 1, !tbaa !2453
  %1120 = sext i32 %1103 to i64
  store i64 %1120, i64* %RDX, align 8, !tbaa !2428
  %1121 = shl nsw i64 %1120, 3
  %1122 = add i64 %1121, %1100
  %1123 = add i64 %1445, 18
  store i64 %1123, i64* %PC, align 8
  %1124 = inttoptr i64 %1122 to i64*
  %1125 = load i64, i64* %1124, align 8
  store i64 %1125, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %1126 = add i64 %1417, -112
  %1127 = add i64 %1445, 23
  store i64 %1127, i64* %PC, align 8
  %1128 = inttoptr i64 %1126 to i64*
  store i64 %1125, i64* %1128, align 8
  %1129 = load i64, i64* %RBP, align 8
  %1130 = add i64 %1129, -32
  %1131 = load i64, i64* %PC, align 8
  %1132 = add i64 %1131, 4
  store i64 %1132, i64* %PC, align 8
  %1133 = inttoptr i64 %1130 to i64*
  %1134 = load i64, i64* %1133, align 8
  store i64 %1134, i64* %RAX, align 8, !tbaa !2428
  %1135 = add i64 %1129, -100
  %1136 = add i64 %1131, 7
  store i64 %1136, i64* %PC, align 8
  %1137 = inttoptr i64 %1135 to i32*
  %1138 = load i32, i32* %1137, align 4
  %1139 = shl i32 %1138, 1
  %1140 = icmp slt i32 %1138, 0
  %1141 = icmp slt i32 %1139, 0
  %1142 = xor i1 %1140, %1141
  %1143 = zext i32 %1139 to i64
  store i64 %1143, i64* %RCX, align 8, !tbaa !2428
  %.lobit56 = lshr i32 %1138, 31
  %1144 = trunc i32 %.lobit56 to i8
  store i8 %1144, i8* %18, align 1, !tbaa !2453
  %1145 = and i32 %1139, 254
  %1146 = tail call i32 @llvm.ctpop.i32(i32 %1145) #11
  %1147 = trunc i32 %1146 to i8
  %1148 = and i8 %1147, 1
  %1149 = xor i8 %1148, 1
  store i8 %1149, i8* %25, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  %1150 = icmp eq i32 %1139, 0
  %1151 = zext i1 %1150 to i8
  store i8 %1151, i8* %33, align 1, !tbaa !2453
  %1152 = lshr i32 %1138, 30
  %1153 = trunc i32 %1152 to i8
  %1154 = and i8 %1153, 1
  store i8 %1154, i8* %36, align 1, !tbaa !2453
  %1155 = zext i1 %1142 to i8
  store i8 %1155, i8* %42, align 1, !tbaa !2453
  %1156 = sext i32 %1139 to i64
  store i64 %1156, i64* %RDX, align 8, !tbaa !2428
  %1157 = shl nsw i64 %1156, 3
  %1158 = add i64 %1157, %1134
  %1159 = add i64 %1131, 18
  store i64 %1159, i64* %PC, align 8
  %1160 = inttoptr i64 %1158 to i64*
  %1161 = load i64, i64* %1160, align 8
  store i64 %1161, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %1162 = add i64 %1129, -120
  %1163 = add i64 %1131, 23
  store i64 %1163, i64* %PC, align 8
  %1164 = inttoptr i64 %1162 to i64*
  store i64 %1161, i64* %1164, align 8
  %1165 = load i64, i64* %RBP, align 8
  %1166 = add i64 %1165, -40
  %1167 = load i64, i64* %PC, align 8
  %1168 = add i64 %1167, 4
  store i64 %1168, i64* %PC, align 8
  %1169 = inttoptr i64 %1166 to i64*
  %1170 = load i64, i64* %1169, align 8
  store i64 %1170, i64* %RAX, align 8, !tbaa !2428
  %1171 = add i64 %1165, -100
  %1172 = add i64 %1167, 7
  store i64 %1172, i64* %PC, align 8
  %1173 = inttoptr i64 %1171 to i32*
  %1174 = load i32, i32* %1173, align 4
  %1175 = shl i32 %1174, 1
  %1176 = or i32 %1175, 1
  %1177 = zext i32 %1176 to i64
  store i64 %1177, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %1178 = and i32 %1176, 255
  %1179 = tail call i32 @llvm.ctpop.i32(i32 %1178) #11
  %1180 = trunc i32 %1179 to i8
  %1181 = and i8 %1180, 1
  %1182 = xor i8 %1181, 1
  store i8 %1182, i8* %25, align 1, !tbaa !2446
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i8 0, i8* %33, align 1, !tbaa !2448
  %1183 = lshr i32 %1174, 30
  %1184 = trunc i32 %1183 to i8
  %1185 = and i8 %1184, 1
  store i8 %1185, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  %1186 = sext i32 %1176 to i64
  store i64 %1186, i64* %RDX, align 8, !tbaa !2428
  %1187 = shl nsw i64 %1186, 3
  %1188 = add i64 %1187, %1170
  %1189 = add i64 %1167, 21
  store i64 %1189, i64* %PC, align 8
  %1190 = inttoptr i64 %1188 to i64*
  %1191 = load i64, i64* %1190, align 8
  store i64 %1191, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %1192 = add i64 %1165, -128
  %1193 = add i64 %1167, 26
  store i64 %1193, i64* %PC, align 8
  %1194 = inttoptr i64 %1192 to i64*
  store i64 %1191, i64* %1194, align 8
  %1195 = load i64, i64* %RBP, align 8
  %1196 = add i64 %1195, -32
  %1197 = load i64, i64* %PC, align 8
  %1198 = add i64 %1197, 4
  store i64 %1198, i64* %PC, align 8
  %1199 = inttoptr i64 %1196 to i64*
  %1200 = load i64, i64* %1199, align 8
  store i64 %1200, i64* %RAX, align 8, !tbaa !2428
  %1201 = add i64 %1195, -100
  %1202 = add i64 %1197, 7
  store i64 %1202, i64* %PC, align 8
  %1203 = inttoptr i64 %1201 to i32*
  %1204 = load i32, i32* %1203, align 4
  %1205 = shl i32 %1204, 1
  %1206 = or i32 %1205, 1
  %1207 = zext i32 %1206 to i64
  store i64 %1207, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %1208 = and i32 %1206, 255
  %1209 = tail call i32 @llvm.ctpop.i32(i32 %1208) #11
  %1210 = trunc i32 %1209 to i8
  %1211 = and i8 %1210, 1
  %1212 = xor i8 %1211, 1
  store i8 %1212, i8* %25, align 1, !tbaa !2446
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i8 0, i8* %33, align 1, !tbaa !2448
  %1213 = lshr i32 %1204, 30
  %1214 = trunc i32 %1213 to i8
  %1215 = and i8 %1214, 1
  store i8 %1215, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  %1216 = sext i32 %1206 to i64
  store i64 %1216, i64* %RDX, align 8, !tbaa !2428
  %1217 = shl nsw i64 %1216, 3
  %1218 = add i64 %1217, %1200
  %1219 = add i64 %1197, 21
  store i64 %1219, i64* %PC, align 8
  %1220 = inttoptr i64 %1218 to i64*
  %1221 = load i64, i64* %1220, align 8
  store i64 %1221, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %1222 = add i64 %1195, -136
  %1223 = add i64 %1197, 29
  store i64 %1223, i64* %PC, align 8
  %1224 = inttoptr i64 %1222 to i64*
  store i64 %1221, i64* %1224, align 8
  %1225 = load i64, i64* %RBP, align 8
  %1226 = add i64 %1225, -112
  %1227 = load i64, i64* %PC, align 8
  %1228 = add i64 %1227, 5
  store i64 %1228, i64* %PC, align 8
  %1229 = inttoptr i64 %1226 to i64*
  %1230 = load i64, i64* %1229, align 8
  store i64 %1230, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %1231 = add i64 %1225, -120
  %1232 = add i64 %1227, 10
  store i64 %1232, i64* %PC, align 8
  %1233 = bitcast i64 %1230 to double
  %1234 = inttoptr i64 %1231 to double*
  %1235 = load double, double* %1234, align 8
  %1236 = fmul double %1233, %1235
  store double %1236, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %1237 = add i64 %1225, -128
  %1238 = add i64 %1227, 15
  store i64 %1238, i64* %PC, align 8
  %1239 = inttoptr i64 %1237 to i64*
  %1240 = load i64, i64* %1239, align 8
  store i64 %1240, i64* %100, align 1, !tbaa !2451
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  %1241 = add i64 %1225, -136
  %1242 = add i64 %1227, 23
  store i64 %1242, i64* %PC, align 8
  %1243 = bitcast i64 %1240 to double
  %1244 = inttoptr i64 %1241 to double*
  %1245 = load double, double* %1244, align 8
  %1246 = fmul double %1243, %1245
  store double %1246, double* %99, align 1, !tbaa !2451
  store i64 0, i64* %101, align 1, !tbaa !2451
  %1247 = fsub double %1236, %1246
  store double %1247, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %1248 = add i64 %1225, -40
  %1249 = add i64 %1227, 31
  store i64 %1249, i64* %PC, align 8
  %1250 = inttoptr i64 %1248 to i64*
  %1251 = load i64, i64* %1250, align 8
  store i64 %1251, i64* %RAX, align 8, !tbaa !2428
  %1252 = add i64 %1225, -100
  %1253 = add i64 %1227, 34
  store i64 %1253, i64* %PC, align 8
  %1254 = inttoptr i64 %1252 to i32*
  %1255 = load i32, i32* %1254, align 4
  %1256 = shl i32 %1255, 1
  %1257 = icmp slt i32 %1255, 0
  %1258 = icmp slt i32 %1256, 0
  %1259 = xor i1 %1257, %1258
  %1260 = zext i32 %1256 to i64
  store i64 %1260, i64* %RCX, align 8, !tbaa !2428
  %.lobit59 = lshr i32 %1255, 31
  %1261 = trunc i32 %.lobit59 to i8
  store i8 %1261, i8* %18, align 1, !tbaa !2453
  %1262 = and i32 %1256, 254
  %1263 = tail call i32 @llvm.ctpop.i32(i32 %1262) #11
  %1264 = trunc i32 %1263 to i8
  %1265 = and i8 %1264, 1
  %1266 = xor i8 %1265, 1
  store i8 %1266, i8* %25, align 1, !tbaa !2453
  store i8 0, i8* %30, align 1, !tbaa !2453
  %1267 = icmp eq i32 %1256, 0
  %1268 = zext i1 %1267 to i8
  store i8 %1268, i8* %33, align 1, !tbaa !2453
  %1269 = lshr i32 %1255, 30
  %1270 = trunc i32 %1269 to i8
  %1271 = and i8 %1270, 1
  store i8 %1271, i8* %36, align 1, !tbaa !2453
  %1272 = zext i1 %1259 to i8
  store i8 %1272, i8* %42, align 1, !tbaa !2453
  %1273 = sext i32 %1256 to i64
  store i64 %1273, i64* %RDX, align 8, !tbaa !2428
  %1274 = shl nsw i64 %1273, 3
  %1275 = add i64 %1274, %1251
  %1276 = add i64 %1227, 45
  store i64 %1276, i64* %PC, align 8
  %1277 = inttoptr i64 %1275 to double*
  store double %1247, double* %1277, align 8
  %1278 = load i64, i64* %RBP, align 8
  %1279 = add i64 %1278, -112
  %1280 = load i64, i64* %PC, align 8
  %1281 = add i64 %1280, 5
  store i64 %1281, i64* %PC, align 8
  %1282 = inttoptr i64 %1279 to i64*
  %1283 = load i64, i64* %1282, align 8
  store i64 %1283, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %1284 = add i64 %1278, -136
  %1285 = add i64 %1280, 13
  store i64 %1285, i64* %PC, align 8
  %1286 = bitcast i64 %1283 to double
  %1287 = inttoptr i64 %1284 to double*
  %1288 = load double, double* %1287, align 8
  %1289 = fmul double %1286, %1288
  store double %1289, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %1290 = add i64 %1278, -128
  %1291 = add i64 %1280, 18
  store i64 %1291, i64* %PC, align 8
  %1292 = inttoptr i64 %1290 to i64*
  %1293 = load i64, i64* %1292, align 8
  store i64 %1293, i64* %100, align 1, !tbaa !2451
  store double 0.000000e+00, double* %102, align 1, !tbaa !2451
  %1294 = add i64 %1278, -120
  %1295 = add i64 %1280, 23
  store i64 %1295, i64* %PC, align 8
  %1296 = bitcast i64 %1293 to double
  %1297 = inttoptr i64 %1294 to double*
  %1298 = load double, double* %1297, align 8
  %1299 = fmul double %1296, %1298
  store double %1299, double* %99, align 1, !tbaa !2451
  store i64 0, i64* %101, align 1, !tbaa !2451
  %1300 = fadd double %1289, %1299
  store double %1300, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %1301 = add i64 %1278, -40
  %1302 = add i64 %1280, 31
  store i64 %1302, i64* %PC, align 8
  %1303 = inttoptr i64 %1301 to i64*
  %1304 = load i64, i64* %1303, align 8
  store i64 %1304, i64* %RAX, align 8, !tbaa !2428
  %1305 = add i64 %1278, -100
  %1306 = add i64 %1280, 34
  store i64 %1306, i64* %PC, align 8
  %1307 = inttoptr i64 %1305 to i32*
  %1308 = load i32, i32* %1307, align 4
  %1309 = shl i32 %1308, 1
  %1310 = or i32 %1309, 1
  %1311 = zext i32 %1310 to i64
  store i64 %1311, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %1312 = and i32 %1310, 255
  %1313 = tail call i32 @llvm.ctpop.i32(i32 %1312) #11
  %1314 = trunc i32 %1313 to i8
  %1315 = and i8 %1314, 1
  %1316 = xor i8 %1315, 1
  store i8 %1316, i8* %25, align 1, !tbaa !2446
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i8 0, i8* %33, align 1, !tbaa !2448
  %1317 = lshr i32 %1308, 30
  %1318 = trunc i32 %1317 to i8
  %1319 = and i8 %1318, 1
  store i8 %1319, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  %1320 = sext i32 %1310 to i64
  store i64 %1320, i64* %RDX, align 8, !tbaa !2428
  %1321 = shl nsw i64 %1320, 3
  %1322 = add i64 %1321, %1304
  %1323 = add i64 %1280, 48
  store i64 %1323, i64* %PC, align 8
  %1324 = inttoptr i64 %1322 to double*
  store double %1300, double* %1324, align 8
  %1325 = load i64, i64* %RBP, align 8
  %1326 = add i64 %1325, -100
  %1327 = load i64, i64* %PC, align 8
  %1328 = add i64 %1327, 3
  store i64 %1328, i64* %PC, align 8
  %1329 = inttoptr i64 %1326 to i32*
  %1330 = load i32, i32* %1329, align 4
  %1331 = add i32 %1330, 1
  %1332 = zext i32 %1331 to i64
  store i64 %1332, i64* %RAX, align 8, !tbaa !2428
  %1333 = icmp eq i32 %1330, -1
  %1334 = icmp eq i32 %1331, 0
  %1335 = or i1 %1333, %1334
  %1336 = zext i1 %1335 to i8
  store i8 %1336, i8* %18, align 1, !tbaa !2432
  %1337 = and i32 %1331, 255
  %1338 = tail call i32 @llvm.ctpop.i32(i32 %1337) #11
  %1339 = trunc i32 %1338 to i8
  %1340 = and i8 %1339, 1
  %1341 = xor i8 %1340, 1
  store i8 %1341, i8* %25, align 1, !tbaa !2446
  %1342 = xor i32 %1331, %1330
  %1343 = lshr i32 %1342, 4
  %1344 = trunc i32 %1343 to i8
  %1345 = and i8 %1344, 1
  store i8 %1345, i8* %30, align 1, !tbaa !2447
  %1346 = zext i1 %1334 to i8
  store i8 %1346, i8* %33, align 1, !tbaa !2448
  %1347 = lshr i32 %1331, 31
  %1348 = trunc i32 %1347 to i8
  store i8 %1348, i8* %36, align 1, !tbaa !2449
  %1349 = lshr i32 %1330, 31
  %1350 = xor i32 %1347, %1349
  %1351 = add nuw nsw i32 %1350, %1347
  %1352 = icmp eq i32 %1351, 2
  %1353 = zext i1 %1352 to i8
  store i8 %1353, i8* %42, align 1, !tbaa !2450
  %1354 = add i64 %1327, 9
  store i64 %1354, i64* %PC, align 8
  store i32 %1331, i32* %1329, align 4
  %1355 = load i64, i64* %PC, align 8
  %1356 = add i64 %1355, -216
  store i64 %1356, i64* %PC, align 8, !tbaa !2428
  br label %block_400b87

block_400d12:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit1
  %1357 = add i64 %743, 3
  store i64 %1357, i64* %PC, align 8
  store <4 x i32> zeroinitializer, <4 x i32>* %1415, align 1, !tbaa !2469
  %.pre81 = load i64, i64* %RBP, align 8
  br label %block_400d22

block_400c8d:                                     ; preds = %block_400b26
  %1358 = add i64 %774, 419
  %1359 = add i64 %774, 5
  %1360 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1361 = add i64 %1360, -8
  %1362 = inttoptr i64 %1361 to i64*
  store i64 %1359, i64* %1362, align 8
  store i64 %1361, i64* %RSP, align 8, !tbaa !2428
  store i64 %1358, i64* %PC, align 8, !tbaa !2428
  %1363 = tail call %struct.Memory* @sub_400e30_get_time_renamed_(%struct.State* nonnull %0, i64 %1358, %struct.Memory* %MEMORY.0)
  %1364 = load i64, i64* %RBP, align 8
  %1365 = add i64 %1364, -72
  %1366 = load i64, i64* %PC, align 8
  %1367 = add i64 %1366, 5
  store i64 %1367, i64* %PC, align 8
  %1368 = load i64, i64* %69, align 1
  %1369 = inttoptr i64 %1365 to i64*
  store i64 %1368, i64* %1369, align 8
  %1370 = load i64, i64* %RBP, align 8
  %1371 = add i64 %1370, -72
  %1372 = load i64, i64* %PC, align 8
  %1373 = add i64 %1372, 5
  store i64 %1373, i64* %PC, align 8
  %1374 = inttoptr i64 %1371 to i64*
  %1375 = load i64, i64* %1374, align 8
  store i64 %1375, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  %1376 = add i64 %1370, -64
  %1377 = add i64 %1372, 10
  store i64 %1377, i64* %PC, align 8
  %1378 = bitcast i64 %1375 to double
  %1379 = inttoptr i64 %1376 to double*
  %1380 = load double, double* %1379, align 8
  %1381 = fsub double %1378, %1380
  store double %1381, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %1382 = add i64 %1370, -80
  %1383 = add i64 %1372, 15
  store i64 %1383, i64* %PC, align 8
  %1384 = inttoptr i64 %1382 to double*
  %1385 = load double, double* %1384, align 8
  %1386 = fsub double %1381, %1385
  store double %1386, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %1387 = add i64 %1370, -88
  %1388 = add i64 %1372, 20
  store i64 %1388, i64* %PC, align 8
  %1389 = inttoptr i64 %1387 to double*
  %1390 = load double, double* %1389, align 8
  %1391 = fadd double %1386, %1390
  store double %1391, double* %68, align 1, !tbaa !2451
  store i64 0, i64* %92, align 1, !tbaa !2451
  %1392 = add i64 %1372, 25
  store i64 %1392, i64* %PC, align 8
  store double %1391, double* %1389, align 8
  %1393 = load i64, i64* %RBP, align 8
  %1394 = add i64 %1393, -12
  %1395 = load i64, i64* %PC, align 8
  %1396 = add i64 %1395, 7
  store i64 %1396, i64* %PC, align 8
  %1397 = inttoptr i64 %1394 to i32*
  store i32 0, i32* %1397, align 4
  %1398 = bitcast %union.VectorReg* %6 to i32*
  %1399 = getelementptr inbounds i8, i8* %94, i64 4
  %1400 = bitcast i8* %1399 to i32*
  %1401 = bitcast i64* %101 to i32*
  %1402 = getelementptr inbounds i8, i8* %94, i64 12
  %1403 = bitcast i8* %1402 to i32*
  %1404 = bitcast %union.VectorReg* %8 to i8*
  %1405 = bitcast %union.VectorReg* %8 to i32*
  %1406 = getelementptr inbounds i8, i8* %1404, i64 4
  %1407 = bitcast i8* %1406 to i32*
  %1408 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3, i32 0, i32 0, i32 0, i64 1
  %1409 = bitcast i64* %1408 to i32*
  %1410 = getelementptr inbounds i8, i8* %1404, i64 12
  %1411 = bitcast i8* %1410 to i32*
  %1412 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %8, i64 0, i32 0, i32 0, i32 0, i64 0
  %1413 = bitcast %union.VectorReg* %6 to <2 x i32>*
  %1414 = bitcast i64* %101 to <2 x i32>*
  %.pre77 = load i64, i64* %PC, align 8
  %1415 = bitcast [32 x %union.VectorReg]* %5 to <4 x i32>*
  br label %block_400cb7

block_400b87:                                     ; preds = %block_400b94, %block_400b33
  %1416 = phi i64 [ %1356, %block_400b94 ], [ %.pre86, %block_400b33 ]
  %1417 = load i64, i64* %RBP, align 8
  %1418 = add i64 %1417, -100
  %1419 = add i64 %1416, 7
  store i64 %1419, i64* %PC, align 8
  %1420 = inttoptr i64 %1418 to i32*
  %1421 = load i32, i32* %1420, align 4
  %1422 = add i32 %1421, -1024
  %1423 = icmp ult i32 %1421, 1024
  %1424 = zext i1 %1423 to i8
  store i8 %1424, i8* %18, align 1, !tbaa !2432
  %1425 = and i32 %1422, 255
  %1426 = tail call i32 @llvm.ctpop.i32(i32 %1425) #11
  %1427 = trunc i32 %1426 to i8
  %1428 = and i8 %1427, 1
  %1429 = xor i8 %1428, 1
  store i8 %1429, i8* %25, align 1, !tbaa !2446
  %1430 = xor i32 %1422, %1421
  %1431 = lshr i32 %1430, 4
  %1432 = trunc i32 %1431 to i8
  %1433 = and i8 %1432, 1
  store i8 %1433, i8* %30, align 1, !tbaa !2447
  %1434 = icmp eq i32 %1422, 0
  %1435 = zext i1 %1434 to i8
  store i8 %1435, i8* %33, align 1, !tbaa !2448
  %1436 = lshr i32 %1422, 31
  %1437 = trunc i32 %1436 to i8
  store i8 %1437, i8* %36, align 1, !tbaa !2449
  %1438 = lshr i32 %1421, 31
  %1439 = xor i32 %1436, %1438
  %1440 = add nuw nsw i32 %1439, %1438
  %1441 = icmp eq i32 %1440, 2
  %1442 = zext i1 %1441 to i8
  store i8 %1442, i8* %42, align 1, !tbaa !2450
  %1443 = icmp ne i8 %1437, 0
  %1444 = xor i1 %1443, %1441
  %.v90 = select i1 %1444, i64 13, i64 221
  %1445 = add i64 %.v90, %1416
  store i64 %1445, i64* %PC, align 8, !tbaa !2428
  br i1 %1444, label %block_400b94, label %block_400c64

block_400cb7:                                     ; preds = %block_400c8d, %block_400d96
  %1446 = phi i64 [ %.pre77, %block_400c8d ], [ %1096, %block_400d96 ]
  %MEMORY.5 = phi %struct.Memory* [ %1363, %block_400c8d ], [ %1058, %block_400d96 ]
  %1447 = load i64, i64* %RBP, align 8
  %1448 = add i64 %1447, -12
  %1449 = add i64 %1446, 7
  store i64 %1449, i64* %PC, align 8
  %1450 = inttoptr i64 %1448 to i32*
  %1451 = load i32, i32* %1450, align 4
  %1452 = add i32 %1451, -1024
  %1453 = icmp ult i32 %1451, 1024
  %1454 = zext i1 %1453 to i8
  store i8 %1454, i8* %18, align 1, !tbaa !2432
  %1455 = and i32 %1452, 255
  %1456 = tail call i32 @llvm.ctpop.i32(i32 %1455) #11
  %1457 = trunc i32 %1456 to i8
  %1458 = and i8 %1457, 1
  %1459 = xor i8 %1458, 1
  store i8 %1459, i8* %25, align 1, !tbaa !2446
  %1460 = xor i32 %1452, %1451
  %1461 = lshr i32 %1460, 4
  %1462 = trunc i32 %1461 to i8
  %1463 = and i8 %1462, 1
  store i8 %1463, i8* %30, align 1, !tbaa !2447
  %1464 = icmp eq i32 %1452, 0
  %1465 = zext i1 %1464 to i8
  store i8 %1465, i8* %33, align 1, !tbaa !2448
  %1466 = lshr i32 %1452, 31
  %1467 = trunc i32 %1466 to i8
  store i8 %1467, i8* %36, align 1, !tbaa !2449
  %1468 = lshr i32 %1451, 31
  %1469 = xor i32 %1466, %1468
  %1470 = add nuw nsw i32 %1469, %1468
  %1471 = icmp eq i32 %1470, 2
  %1472 = zext i1 %1471 to i8
  store i8 %1472, i8* %42, align 1, !tbaa !2450
  %1473 = icmp ne i8 %1467, 0
  %1474 = xor i1 %1473, %1471
  %.v88 = select i1 %1474, i64 13, i64 295
  %1475 = add i64 %.v88, %1446
  store i64 %1475, i64* %PC, align 8, !tbaa !2428
  br i1 %1474, label %block_400cc4, label %block_400dde

block_400d86:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit
  %1476 = add i64 %1020, 3
  store i64 %1476, i64* %PC, align 8
  store <4 x i32> zeroinitializer, <4 x i32>* %1415, align 1, !tbaa !2469
  %.pre84 = load i64, i64* %RBP, align 8
  br label %block_400d96

block_400a8c:                                     ; preds = %block_400a7f
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %1477 = add i64 %776, -32
  %1478 = add i64 %804, 14
  store i64 %1478, i64* %PC, align 8
  %1479 = inttoptr i64 %1477 to i64*
  %1480 = load i64, i64* %1479, align 8
  store i64 %1480, i64* %RCX, align 8, !tbaa !2428
  %1481 = add i64 %804, 17
  store i64 %1481, i64* %PC, align 8
  %1482 = load i32, i32* %779, align 4
  %1483 = shl i32 %1482, 1
  %1484 = or i32 %1483, 1
  %1485 = zext i32 %1484 to i64
  store i64 %1485, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %1486 = and i32 %1484, 255
  %1487 = tail call i32 @llvm.ctpop.i32(i32 %1486) #11
  %1488 = trunc i32 %1487 to i8
  %1489 = and i8 %1488, 1
  %1490 = xor i8 %1489, 1
  store i8 %1490, i8* %25, align 1, !tbaa !2446
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i8 0, i8* %33, align 1, !tbaa !2448
  %1491 = lshr i32 %1482, 30
  %1492 = trunc i32 %1491 to i8
  %1493 = and i8 %1492, 1
  store i8 %1493, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  %1494 = sext i32 %1484 to i64
  store i64 %1494, i64* %RSI, align 8, !tbaa !2428
  %1495 = shl nsw i64 %1494, 3
  %1496 = add i64 %1495, %1480
  %1497 = add i64 %804, 31
  store i64 %1497, i64* %PC, align 8
  %1498 = inttoptr i64 %1496 to i64*
  %1499 = load i64, i64* %1498, align 8
  %1500 = xor i64 %1499, -9223372036854775808
  store i64 %1500, i64* %RCX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %1501 = trunc i64 %1499 to i32
  %1502 = and i32 %1501, 255
  %1503 = tail call i32 @llvm.ctpop.i32(i32 %1502) #11
  %1504 = trunc i32 %1503 to i8
  %1505 = and i8 %1504, 1
  %1506 = xor i8 %1505, 1
  store i8 %1506, i8* %25, align 1, !tbaa !2446
  %1507 = icmp eq i64 %1500, 0
  %1508 = zext i1 %1507 to i8
  store i8 %1508, i8* %33, align 1, !tbaa !2448
  %1509 = lshr i64 %1500, 63
  %1510 = trunc i64 %1509 to i8
  store i8 %1510, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i64 %1500, i64* %69, align 1, !tbaa !2428
  store i64 0, i64* %92, align 1, !tbaa !2428
  %1511 = add i64 %804, 48
  store i64 %1511, i64* %PC, align 8
  %1512 = load i64, i64* %1479, align 8
  store i64 %1512, i64* %RAX, align 8, !tbaa !2428
  %1513 = add i64 %804, 51
  store i64 %1513, i64* %PC, align 8
  %1514 = load i32, i32* %779, align 4
  %1515 = shl i32 %1514, 1
  %1516 = or i32 %1515, 1
  %1517 = zext i32 %1516 to i64
  store i64 %1517, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %18, align 1, !tbaa !2432
  %1518 = and i32 %1516, 255
  %1519 = tail call i32 @llvm.ctpop.i32(i32 %1518) #11
  %1520 = trunc i32 %1519 to i8
  %1521 = and i8 %1520, 1
  %1522 = xor i8 %1521, 1
  store i8 %1522, i8* %25, align 1, !tbaa !2446
  store i8 0, i8* %30, align 1, !tbaa !2447
  store i8 0, i8* %33, align 1, !tbaa !2448
  %1523 = lshr i32 %1514, 30
  %1524 = trunc i32 %1523 to i8
  %1525 = and i8 %1524, 1
  store i8 %1525, i8* %36, align 1, !tbaa !2449
  store i8 0, i8* %42, align 1, !tbaa !2450
  %1526 = sext i32 %1516 to i64
  store i64 %1526, i64* %RCX, align 8, !tbaa !2428
  %1527 = shl nsw i64 %1526, 3
  %1528 = add i64 %1527, %1512
  %1529 = add i64 %804, 65
  store i64 %1529, i64* %PC, align 8
  %1530 = inttoptr i64 %1528 to i64*
  store i64 %1500, i64* %1530, align 8
  %1531 = load i64, i64* %RBP, align 8
  %1532 = add i64 %1531, -12
  %1533 = load i64, i64* %PC, align 8
  %1534 = add i64 %1533, 3
  store i64 %1534, i64* %PC, align 8
  %1535 = inttoptr i64 %1532 to i32*
  %1536 = load i32, i32* %1535, align 4
  %1537 = add i32 %1536, 1
  %1538 = zext i32 %1537 to i64
  store i64 %1538, i64* %RAX, align 8, !tbaa !2428
  %1539 = icmp eq i32 %1536, -1
  %1540 = icmp eq i32 %1537, 0
  %1541 = or i1 %1539, %1540
  %1542 = zext i1 %1541 to i8
  store i8 %1542, i8* %18, align 1, !tbaa !2432
  %1543 = and i32 %1537, 255
  %1544 = tail call i32 @llvm.ctpop.i32(i32 %1543) #11
  %1545 = trunc i32 %1544 to i8
  %1546 = and i8 %1545, 1
  %1547 = xor i8 %1546, 1
  store i8 %1547, i8* %25, align 1, !tbaa !2446
  %1548 = xor i32 %1537, %1536
  %1549 = lshr i32 %1548, 4
  %1550 = trunc i32 %1549 to i8
  %1551 = and i8 %1550, 1
  store i8 %1551, i8* %30, align 1, !tbaa !2447
  %1552 = zext i1 %1540 to i8
  store i8 %1552, i8* %33, align 1, !tbaa !2448
  %1553 = lshr i32 %1537, 31
  %1554 = trunc i32 %1553 to i8
  store i8 %1554, i8* %36, align 1, !tbaa !2449
  %1555 = lshr i32 %1536, 31
  %1556 = xor i32 %1553, %1555
  %1557 = add nuw nsw i32 %1556, %1553
  %1558 = icmp eq i32 %1557, 2
  %1559 = zext i1 %1558 to i8
  store i8 %1559, i8* %42, align 1, !tbaa !2450
  %1560 = add i64 %1533, 9
  store i64 %1560, i64* %PC, align 8
  store i32 %1537, i32* %1535, align 4
  %1561 = load i64, i64* %PC, align 8
  %1562 = add i64 %1561, -87
  store i64 %1562, i64* %PC, align 8, !tbaa !2428
  br label %block_400a7f

block_400a02:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tES3_EEP6MemoryS5_R5StateT_T0_.exit2
  store i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 112), i64* %RDI, align 8, !tbaa !2428
  %1563 = load i64, i64* %RBP, align 8
  %1564 = add i64 %1563, -96
  %1565 = add i64 %411, 15
  store i64 %1565, i64* %PC, align 8
  %1566 = inttoptr i64 %1564 to i64*
  %1567 = load i64, i64* %1566, align 8
  store i64 %1567, i64* %69, align 1, !tbaa !2451
  store double 0.000000e+00, double* %93, align 1, !tbaa !2451
  store i8 1, i8* %AL, align 1, !tbaa !2453
  %1568 = add i64 %411, -802
  %1569 = add i64 %411, 22
  %1570 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1571 = add i64 %1570, -8
  %1572 = inttoptr i64 %1571 to i64*
  store i64 %1569, i64* %1572, align 8
  store i64 %1571, i64* %RSP, align 8, !tbaa !2428
  store i64 %1568, i64* %PC, align 8, !tbaa !2428
  %1573 = tail call fastcc %struct.Memory* @ext_4006e0_printf(%struct.State* nonnull %0, %struct.Memory* %406)
  %1574 = load i64, i64* %RBP, align 8
  %1575 = add i64 %1574, -156
  %1576 = load i32, i32* %EAX, align 4
  %1577 = load i64, i64* %PC, align 8
  %1578 = add i64 %1577, 6
  store i64 %1578, i64* %PC, align 8
  %1579 = inttoptr i64 %1575 to i32*
  store i32 %1576, i32* %1579, align 4
  %1580 = load i64, i64* %PC, align 8
  %1581 = add i64 %1580, -862
  %1582 = add i64 %1580, 5
  %1583 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1584 = add i64 %1583, -8
  %1585 = inttoptr i64 %1584 to i64*
  store i64 %1582, i64* %1585, align 8
  store i64 %1584, i64* %RSP, align 8, !tbaa !2428
  store i64 %1581, i64* %PC, align 8, !tbaa !2428
  %1586 = tail call fastcc %struct.Memory* @ext_4006c0_abort(%struct.State* nonnull %0, %struct.Memory* %1573)
  %1587 = load i64, i64* %PC, align 8
  %1588 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull %0, i64 %1587, %struct.Memory* %1586)
  ret %struct.Memory* %1588
}

; Function Attrs: noinline norecurse nounwind
define %struct.Memory* @sub_404090___libc_csu_fini(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #9 {
block_404090:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = add i64 %1, 2
  store i64 %3, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !2428
  %6 = inttoptr i64 %5 to i64*
  %7 = load i64, i64* %6, align 8
  store i64 %7, i64* %PC, align 8, !tbaa !2428
  %8 = add i64 %5, 8
  store i64 %8, i64* %4, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_401870_cftfsub(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone) local_unnamed_addr #8 {
block_401870:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -120
  store i64 %11, i64* %RSP, align 8, !tbaa !2428
  %12 = icmp ult i64 %8, 112
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1, !tbaa !2432
  %15 = trunc i64 %11 to i32
  %16 = and i32 %15, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16) #11
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1, !tbaa !2446
  %22 = xor i64 %8, 16
  %23 = xor i64 %22, %11
  %24 = lshr i64 %23, 4
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1, !tbaa !2447
  %28 = icmp eq i64 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1, !tbaa !2448
  %31 = lshr i64 %11, 63
  %32 = trunc i64 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1, !tbaa !2449
  %34 = lshr i64 %8, 63
  %35 = xor i64 %31, %34
  %36 = add nuw nsw i64 %35, %34
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1, !tbaa !2450
  %40 = add i64 %7, -12
  %41 = load i32, i32* %EDI, align 4
  %42 = add i64 %10, 10
  store i64 %42, i64* %PC, align 8
  %43 = inttoptr i64 %40 to i32*
  store i32 %41, i32* %43, align 4
  %44 = load i64, i64* %RBP, align 8
  %45 = add i64 %44, -16
  %46 = load i64, i64* %RSI, align 8
  %47 = load i64, i64* %PC, align 8
  %48 = add i64 %47, 4
  store i64 %48, i64* %PC, align 8
  %49 = inttoptr i64 %45 to i64*
  store i64 %46, i64* %49, align 8
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -24
  %52 = load i64, i64* %RDX, align 8
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 4
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %51 to i64*
  store i64 %52, i64* %55, align 8
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -44
  %58 = load i64, i64* %PC, align 8
  %59 = add i64 %58, 7
  store i64 %59, i64* %PC, align 8
  %60 = inttoptr i64 %57 to i32*
  store i32 2, i32* %60, align 4
  %61 = load i64, i64* %RBP, align 8
  %62 = add i64 %61, -4
  %63 = load i64, i64* %PC, align 8
  %64 = add i64 %63, 4
  store i64 %64, i64* %PC, align 8
  %65 = inttoptr i64 %62 to i32*
  %66 = load i32, i32* %65, align 4
  %67 = add i32 %66, -8
  %68 = icmp ult i32 %66, 8
  %69 = zext i1 %68 to i8
  store i8 %69, i8* %14, align 1, !tbaa !2432
  %70 = and i32 %67, 255
  %71 = tail call i32 @llvm.ctpop.i32(i32 %70) #11
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  %74 = xor i8 %73, 1
  store i8 %74, i8* %21, align 1, !tbaa !2446
  %75 = xor i32 %67, %66
  %76 = lshr i32 %75, 4
  %77 = trunc i32 %76 to i8
  %78 = and i8 %77, 1
  store i8 %78, i8* %27, align 1, !tbaa !2447
  %79 = icmp eq i32 %67, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %30, align 1, !tbaa !2448
  %81 = lshr i32 %67, 31
  %82 = trunc i32 %81 to i8
  store i8 %82, i8* %33, align 1, !tbaa !2449
  %83 = lshr i32 %66, 31
  %84 = xor i32 %81, %83
  %85 = add nuw nsw i32 %84, %83
  %86 = icmp eq i32 %85, 2
  %87 = zext i1 %86 to i8
  store i8 %87, i8* %39, align 1, !tbaa !2450
  %88 = icmp ne i8 %82, 0
  %89 = xor i1 %88, %86
  %90 = or i1 %79, %89
  %.v14 = select i1 %90, i64 86, i64 10
  %91 = add i64 %.v14, %63
  store i64 %91, i64* %PC, align 8, !tbaa !2428
  br i1 %90, label %block_4018e0, label %block_401894

block_4018db:                                     ; preds = %block_4018ab
  %92 = add i64 %558, 5
  store i64 %92, i64* %PC, align 8, !tbaa !2428
  br label %block_4018e0

block_401894:                                     ; preds = %block_401870
  %93 = add i64 %91, 3
  store i64 %93, i64* %PC, align 8
  %94 = load i32, i32* %65, align 4
  %95 = zext i32 %94 to i64
  store i64 %95, i64* %RDI, align 8, !tbaa !2428
  %96 = add i64 %61, -16
  %97 = add i64 %91, 7
  store i64 %97, i64* %PC, align 8
  %98 = inttoptr i64 %96 to i64*
  %99 = load i64, i64* %98, align 8
  store i64 %99, i64* %RSI, align 8, !tbaa !2428
  %100 = add i64 %61, -24
  %101 = add i64 %91, 11
  store i64 %101, i64* %PC, align 8
  %102 = inttoptr i64 %100 to i64*
  %103 = load i64, i64* %102, align 8
  store i64 %103, i64* %RDX, align 8, !tbaa !2428
  %104 = add i64 %91, 4108
  %105 = add i64 %91, 16
  %106 = load i64, i64* %RSP, align 8, !tbaa !2428
  %107 = add i64 %106, -8
  %108 = inttoptr i64 %107 to i64*
  store i64 %105, i64* %108, align 8
  store i64 %107, i64* %RSP, align 8, !tbaa !2428
  store i64 %104, i64* %PC, align 8, !tbaa !2428
  %109 = tail call %struct.Memory* @sub_4028a0_cft1st_renamed_(%struct.State* nonnull %0, i64 %104, %struct.Memory* %2)
  %110 = load i64, i64* %RBP, align 8
  %111 = add i64 %110, -44
  %112 = load i64, i64* %PC, align 8
  %113 = add i64 %112, 7
  store i64 %113, i64* %PC, align 8
  %114 = inttoptr i64 %111 to i32*
  store i32 8, i32* %114, align 4
  %.pre = load i64, i64* %PC, align 8
  br label %block_4018ab

block_4018ba:                                     ; preds = %block_4018ab
  %115 = add i64 %558, 3
  store i64 %115, i64* %PC, align 8
  %116 = load i32, i32* %530, align 4
  %117 = zext i32 %116 to i64
  store i64 %117, i64* %RDI, align 8, !tbaa !2428
  %118 = add i64 %558, 6
  store i64 %118, i64* %PC, align 8
  %119 = load i32, i32* %511, align 4
  %120 = zext i32 %119 to i64
  store i64 %120, i64* %RSI, align 8, !tbaa !2428
  %121 = add i64 %508, -16
  %122 = add i64 %558, 10
  store i64 %122, i64* %PC, align 8
  %123 = inttoptr i64 %121 to i64*
  %124 = load i64, i64* %123, align 8
  store i64 %124, i64* %RDX, align 8, !tbaa !2428
  %125 = add i64 %508, -24
  %126 = add i64 %558, 14
  store i64 %126, i64* %PC, align 8
  %127 = inttoptr i64 %125 to i64*
  %128 = load i64, i64* %127, align 8
  store i64 %128, i64* %RCX, align 8, !tbaa !2428
  %129 = add i64 %558, 6774
  %130 = add i64 %558, 19
  %131 = load i64, i64* %RSP, align 8, !tbaa !2428
  %132 = add i64 %131, -8
  %133 = inttoptr i64 %132 to i64*
  store i64 %130, i64* %133, align 8
  store i64 %132, i64* %RSP, align 8, !tbaa !2428
  store i64 %129, i64* %PC, align 8, !tbaa !2428
  %134 = tail call %struct.Memory* @sub_403330_cftmdl_renamed_(%struct.State* nonnull %0, i64 %129, %struct.Memory* %109)
  %135 = load i64, i64* %RBP, align 8
  %136 = add i64 %135, -44
  %137 = load i64, i64* %PC, align 8
  %138 = add i64 %137, 3
  store i64 %138, i64* %PC, align 8
  %139 = inttoptr i64 %136 to i32*
  %140 = load i32, i32* %139, align 4
  %141 = shl i32 %140, 2
  %142 = zext i32 %141 to i64
  store i64 %142, i64* %RSI, align 8, !tbaa !2428
  %143 = lshr i32 %140, 30
  %144 = trunc i32 %143 to i8
  %145 = and i8 %144, 1
  store i8 %145, i8* %14, align 1, !tbaa !2453
  %146 = and i32 %141, 252
  %147 = tail call i32 @llvm.ctpop.i32(i32 %146) #11
  %148 = trunc i32 %147 to i8
  %149 = and i8 %148, 1
  %150 = xor i8 %149, 1
  store i8 %150, i8* %21, align 1, !tbaa !2453
  store i8 0, i8* %27, align 1, !tbaa !2453
  %151 = icmp eq i32 %141, 0
  %152 = zext i1 %151 to i8
  store i8 %152, i8* %30, align 1, !tbaa !2453
  %153 = lshr i32 %140, 29
  %154 = trunc i32 %153 to i8
  %155 = and i8 %154, 1
  store i8 %155, i8* %33, align 1, !tbaa !2453
  store i8 0, i8* %39, align 1, !tbaa !2453
  %156 = add i64 %137, 9
  store i64 %156, i64* %PC, align 8
  store i32 %141, i32* %139, align 4
  %157 = load i64, i64* %PC, align 8
  %158 = add i64 %157, -43
  store i64 %158, i64* %PC, align 8, !tbaa !2428
  br label %block_4018ab

block_401b2f:                                     ; preds = %block_401b23
  %159 = add i64 %668, 3
  store i64 %159, i64* %PC, align 8
  %160 = load i32, i32* %635, align 4
  %161 = zext i32 %160 to i64
  store i64 %161, i64* %RAX, align 8, !tbaa !2428
  %162 = add i64 %668, 6
  store i64 %162, i64* %PC, align 8
  %163 = load i32, i32* %640, align 4
  %164 = add i32 %163, %160
  %165 = zext i32 %164 to i64
  store i64 %165, i64* %RAX, align 8, !tbaa !2428
  %166 = icmp ult i32 %164, %160
  %167 = icmp ult i32 %164, %163
  %168 = or i1 %166, %167
  %169 = zext i1 %168 to i8
  store i8 %169, i8* %14, align 1, !tbaa !2432
  %170 = and i32 %164, 255
  %171 = tail call i32 @llvm.ctpop.i32(i32 %170) #11
  %172 = trunc i32 %171 to i8
  %173 = and i8 %172, 1
  %174 = xor i8 %173, 1
  store i8 %174, i8* %21, align 1, !tbaa !2446
  %175 = xor i32 %163, %160
  %176 = xor i32 %175, %164
  %177 = lshr i32 %176, 4
  %178 = trunc i32 %177 to i8
  %179 = and i8 %178, 1
  store i8 %179, i8* %27, align 1, !tbaa !2447
  %180 = icmp eq i32 %164, 0
  %181 = zext i1 %180 to i8
  store i8 %181, i8* %30, align 1, !tbaa !2448
  %182 = lshr i32 %164, 31
  %183 = trunc i32 %182 to i8
  store i8 %183, i8* %33, align 1, !tbaa !2449
  %184 = lshr i32 %160, 31
  %185 = lshr i32 %163, 31
  %186 = xor i32 %182, %184
  %187 = xor i32 %182, %185
  %188 = add nuw nsw i32 %186, %187
  %189 = icmp eq i32 %188, 2
  %190 = zext i1 %189 to i8
  store i8 %190, i8* %39, align 1, !tbaa !2450
  %191 = add i64 %632, -32
  %192 = add i64 %668, 9
  store i64 %192, i64* %PC, align 8
  %193 = inttoptr i64 %191 to i32*
  store i32 %164, i32* %193, align 4
  %194 = load i64, i64* %RBP, align 8
  %195 = add i64 %194, -16
  %196 = load i64, i64* %PC, align 8
  %197 = add i64 %196, 4
  store i64 %197, i64* %PC, align 8
  %198 = inttoptr i64 %195 to i64*
  %199 = load i64, i64* %198, align 8
  store i64 %199, i64* %RCX, align 8, !tbaa !2428
  %200 = add i64 %194, -28
  %201 = add i64 %196, 8
  store i64 %201, i64* %PC, align 8
  %202 = inttoptr i64 %200 to i32*
  %203 = load i32, i32* %202, align 4
  %204 = sext i32 %203 to i64
  store i64 %204, i64* %RDX, align 8, !tbaa !2428
  %205 = shl nsw i64 %204, 3
  %206 = add i64 %205, %199
  %207 = add i64 %196, 13
  store i64 %207, i64* %PC, align 8
  %208 = inttoptr i64 %206 to i64*
  %209 = load i64, i64* %208, align 8
  store i64 %209, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %210 = add i64 %196, 17
  store i64 %210, i64* %PC, align 8
  %211 = load i64, i64* %198, align 8
  store i64 %211, i64* %RCX, align 8, !tbaa !2428
  %212 = add i64 %194, -32
  %213 = add i64 %196, 21
  store i64 %213, i64* %PC, align 8
  %214 = inttoptr i64 %212 to i32*
  %215 = load i32, i32* %214, align 4
  %216 = sext i32 %215 to i64
  store i64 %216, i64* %RDX, align 8, !tbaa !2428
  %217 = shl nsw i64 %216, 3
  %218 = add i64 %217, %211
  %219 = add i64 %196, 26
  store i64 %219, i64* %PC, align 8
  %220 = bitcast i64 %209 to double
  %221 = inttoptr i64 %218 to double*
  %222 = load double, double* %221, align 8
  %223 = fsub double %220, %222
  store double %223, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %224 = add i64 %194, -56
  %225 = add i64 %196, 31
  store i64 %225, i64* %PC, align 8
  %226 = inttoptr i64 %224 to double*
  store double %223, double* %226, align 8
  %227 = load i64, i64* %RBP, align 8
  %228 = add i64 %227, -16
  %229 = load i64, i64* %PC, align 8
  %230 = add i64 %229, 4
  store i64 %230, i64* %PC, align 8
  %231 = inttoptr i64 %228 to i64*
  %232 = load i64, i64* %231, align 8
  store i64 %232, i64* %RCX, align 8, !tbaa !2428
  %233 = add i64 %227, -28
  %234 = add i64 %229, 7
  store i64 %234, i64* %PC, align 8
  %235 = inttoptr i64 %233 to i32*
  %236 = load i32, i32* %235, align 4
  %237 = add i32 %236, 1
  %238 = zext i32 %237 to i64
  store i64 %238, i64* %RAX, align 8, !tbaa !2428
  %239 = icmp eq i32 %236, -1
  %240 = icmp eq i32 %237, 0
  %241 = or i1 %239, %240
  %242 = zext i1 %241 to i8
  store i8 %242, i8* %14, align 1, !tbaa !2432
  %243 = and i32 %237, 255
  %244 = tail call i32 @llvm.ctpop.i32(i32 %243) #11
  %245 = trunc i32 %244 to i8
  %246 = and i8 %245, 1
  %247 = xor i8 %246, 1
  store i8 %247, i8* %21, align 1, !tbaa !2446
  %248 = xor i32 %237, %236
  %249 = lshr i32 %248, 4
  %250 = trunc i32 %249 to i8
  %251 = and i8 %250, 1
  store i8 %251, i8* %27, align 1, !tbaa !2447
  %252 = zext i1 %240 to i8
  store i8 %252, i8* %30, align 1, !tbaa !2448
  %253 = lshr i32 %237, 31
  %254 = trunc i32 %253 to i8
  store i8 %254, i8* %33, align 1, !tbaa !2449
  %255 = lshr i32 %236, 31
  %256 = xor i32 %253, %255
  %257 = add nuw nsw i32 %256, %253
  %258 = icmp eq i32 %257, 2
  %259 = zext i1 %258 to i8
  store i8 %259, i8* %39, align 1, !tbaa !2450
  %260 = sext i32 %237 to i64
  store i64 %260, i64* %RDX, align 8, !tbaa !2428
  %261 = shl nsw i64 %260, 3
  %262 = add i64 %261, %232
  %263 = add i64 %229, 18
  store i64 %263, i64* %PC, align 8
  %264 = inttoptr i64 %262 to i64*
  %265 = load i64, i64* %264, align 8
  store i64 %265, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %266 = add i64 %229, 22
  store i64 %266, i64* %PC, align 8
  %267 = load i64, i64* %231, align 8
  store i64 %267, i64* %RCX, align 8, !tbaa !2428
  %268 = add i64 %227, -32
  %269 = add i64 %229, 25
  store i64 %269, i64* %PC, align 8
  %270 = inttoptr i64 %268 to i32*
  %271 = load i32, i32* %270, align 4
  %272 = add i32 %271, 1
  %273 = zext i32 %272 to i64
  store i64 %273, i64* %RAX, align 8, !tbaa !2428
  %274 = icmp eq i32 %271, -1
  %275 = icmp eq i32 %272, 0
  %276 = or i1 %274, %275
  %277 = zext i1 %276 to i8
  store i8 %277, i8* %14, align 1, !tbaa !2432
  %278 = and i32 %272, 255
  %279 = tail call i32 @llvm.ctpop.i32(i32 %278) #11
  %280 = trunc i32 %279 to i8
  %281 = and i8 %280, 1
  %282 = xor i8 %281, 1
  store i8 %282, i8* %21, align 1, !tbaa !2446
  %283 = xor i32 %272, %271
  %284 = lshr i32 %283, 4
  %285 = trunc i32 %284 to i8
  %286 = and i8 %285, 1
  store i8 %286, i8* %27, align 1, !tbaa !2447
  %287 = zext i1 %275 to i8
  store i8 %287, i8* %30, align 1, !tbaa !2448
  %288 = lshr i32 %272, 31
  %289 = trunc i32 %288 to i8
  store i8 %289, i8* %33, align 1, !tbaa !2449
  %290 = lshr i32 %271, 31
  %291 = xor i32 %288, %290
  %292 = add nuw nsw i32 %291, %288
  %293 = icmp eq i32 %292, 2
  %294 = zext i1 %293 to i8
  store i8 %294, i8* %39, align 1, !tbaa !2450
  %295 = sext i32 %272 to i64
  store i64 %295, i64* %RDX, align 8, !tbaa !2428
  %296 = shl nsw i64 %295, 3
  %297 = add i64 %296, %267
  %298 = add i64 %229, 36
  store i64 %298, i64* %PC, align 8
  %299 = bitcast i64 %265 to double
  %300 = inttoptr i64 %297 to double*
  %301 = load double, double* %300, align 8
  %302 = fsub double %299, %301
  store double %302, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %303 = load i64, i64* %RBP, align 8
  %304 = add i64 %303, -64
  %305 = add i64 %229, 41
  store i64 %305, i64* %PC, align 8
  %306 = inttoptr i64 %304 to double*
  store double %302, double* %306, align 8
  %307 = load i64, i64* %RBP, align 8
  %308 = add i64 %307, -16
  %309 = load i64, i64* %PC, align 8
  %310 = add i64 %309, 4
  store i64 %310, i64* %PC, align 8
  %311 = inttoptr i64 %308 to i64*
  %312 = load i64, i64* %311, align 8
  store i64 %312, i64* %RCX, align 8, !tbaa !2428
  %313 = add i64 %307, -32
  %314 = add i64 %309, 8
  store i64 %314, i64* %PC, align 8
  %315 = inttoptr i64 %313 to i32*
  %316 = load i32, i32* %315, align 4
  %317 = sext i32 %316 to i64
  store i64 %317, i64* %RDX, align 8, !tbaa !2428
  %318 = shl nsw i64 %317, 3
  %319 = add i64 %318, %312
  %320 = add i64 %309, 13
  store i64 %320, i64* %PC, align 8
  %321 = inttoptr i64 %319 to i64*
  %322 = load i64, i64* %321, align 8
  store i64 %322, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %323 = add i64 %309, 17
  store i64 %323, i64* %PC, align 8
  %324 = load i64, i64* %311, align 8
  store i64 %324, i64* %RCX, align 8, !tbaa !2428
  %325 = add i64 %307, -28
  %326 = add i64 %309, 21
  store i64 %326, i64* %PC, align 8
  %327 = inttoptr i64 %325 to i32*
  %328 = load i32, i32* %327, align 4
  %329 = sext i32 %328 to i64
  store i64 %329, i64* %RDX, align 8, !tbaa !2428
  %330 = shl nsw i64 %329, 3
  %331 = add i64 %330, %324
  %332 = add i64 %309, 26
  store i64 %332, i64* %PC, align 8
  %333 = bitcast i64 %322 to double
  %334 = inttoptr i64 %331 to double*
  %335 = load double, double* %334, align 8
  %336 = fadd double %333, %335
  store double %336, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %337 = add i64 %309, 31
  store i64 %337, i64* %PC, align 8
  store double %336, double* %334, align 8
  %338 = load i64, i64* %RBP, align 8
  %339 = add i64 %338, -16
  %340 = load i64, i64* %PC, align 8
  %341 = add i64 %340, 4
  store i64 %341, i64* %PC, align 8
  %342 = inttoptr i64 %339 to i64*
  %343 = load i64, i64* %342, align 8
  store i64 %343, i64* %RCX, align 8, !tbaa !2428
  %344 = add i64 %338, -32
  %345 = add i64 %340, 7
  store i64 %345, i64* %PC, align 8
  %346 = inttoptr i64 %344 to i32*
  %347 = load i32, i32* %346, align 4
  %348 = add i32 %347, 1
  %349 = zext i32 %348 to i64
  store i64 %349, i64* %RAX, align 8, !tbaa !2428
  %350 = icmp eq i32 %347, -1
  %351 = icmp eq i32 %348, 0
  %352 = or i1 %350, %351
  %353 = zext i1 %352 to i8
  store i8 %353, i8* %14, align 1, !tbaa !2432
  %354 = and i32 %348, 255
  %355 = tail call i32 @llvm.ctpop.i32(i32 %354) #11
  %356 = trunc i32 %355 to i8
  %357 = and i8 %356, 1
  %358 = xor i8 %357, 1
  store i8 %358, i8* %21, align 1, !tbaa !2446
  %359 = xor i32 %348, %347
  %360 = lshr i32 %359, 4
  %361 = trunc i32 %360 to i8
  %362 = and i8 %361, 1
  store i8 %362, i8* %27, align 1, !tbaa !2447
  %363 = zext i1 %351 to i8
  store i8 %363, i8* %30, align 1, !tbaa !2448
  %364 = lshr i32 %348, 31
  %365 = trunc i32 %364 to i8
  store i8 %365, i8* %33, align 1, !tbaa !2449
  %366 = lshr i32 %347, 31
  %367 = xor i32 %364, %366
  %368 = add nuw nsw i32 %367, %364
  %369 = icmp eq i32 %368, 2
  %370 = zext i1 %369 to i8
  store i8 %370, i8* %39, align 1, !tbaa !2450
  %371 = sext i32 %348 to i64
  store i64 %371, i64* %RDX, align 8, !tbaa !2428
  %372 = shl nsw i64 %371, 3
  %373 = add i64 %372, %343
  %374 = add i64 %340, 18
  store i64 %374, i64* %PC, align 8
  %375 = inttoptr i64 %373 to i64*
  %376 = load i64, i64* %375, align 8
  store i64 %376, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %377 = add i64 %340, 22
  store i64 %377, i64* %PC, align 8
  %378 = load i64, i64* %342, align 8
  store i64 %378, i64* %RCX, align 8, !tbaa !2428
  %379 = add i64 %338, -28
  %380 = add i64 %340, 25
  store i64 %380, i64* %PC, align 8
  %381 = inttoptr i64 %379 to i32*
  %382 = load i32, i32* %381, align 4
  %383 = add i32 %382, 1
  %384 = zext i32 %383 to i64
  store i64 %384, i64* %RAX, align 8, !tbaa !2428
  %385 = icmp eq i32 %382, -1
  %386 = icmp eq i32 %383, 0
  %387 = or i1 %385, %386
  %388 = zext i1 %387 to i8
  store i8 %388, i8* %14, align 1, !tbaa !2432
  %389 = and i32 %383, 255
  %390 = tail call i32 @llvm.ctpop.i32(i32 %389) #11
  %391 = trunc i32 %390 to i8
  %392 = and i8 %391, 1
  %393 = xor i8 %392, 1
  store i8 %393, i8* %21, align 1, !tbaa !2446
  %394 = xor i32 %383, %382
  %395 = lshr i32 %394, 4
  %396 = trunc i32 %395 to i8
  %397 = and i8 %396, 1
  store i8 %397, i8* %27, align 1, !tbaa !2447
  %398 = zext i1 %386 to i8
  store i8 %398, i8* %30, align 1, !tbaa !2448
  %399 = lshr i32 %383, 31
  %400 = trunc i32 %399 to i8
  store i8 %400, i8* %33, align 1, !tbaa !2449
  %401 = lshr i32 %382, 31
  %402 = xor i32 %399, %401
  %403 = add nuw nsw i32 %402, %399
  %404 = icmp eq i32 %403, 2
  %405 = zext i1 %404 to i8
  store i8 %405, i8* %39, align 1, !tbaa !2450
  %406 = sext i32 %383 to i64
  store i64 %406, i64* %RDX, align 8, !tbaa !2428
  %407 = shl nsw i64 %406, 3
  %408 = add i64 %407, %378
  %409 = add i64 %340, 36
  store i64 %409, i64* %PC, align 8
  %410 = bitcast i64 %376 to double
  %411 = inttoptr i64 %408 to double*
  %412 = load double, double* %411, align 8
  %413 = fadd double %410, %412
  store double %413, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %414 = add i64 %340, 41
  store i64 %414, i64* %PC, align 8
  store double %413, double* %411, align 8
  %415 = load i64, i64* %RBP, align 8
  %416 = add i64 %415, -56
  %417 = load i64, i64* %PC, align 8
  %418 = add i64 %417, 5
  store i64 %418, i64* %PC, align 8
  %419 = inttoptr i64 %416 to i64*
  %420 = load i64, i64* %419, align 8
  store i64 %420, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %421 = add i64 %415, -16
  %422 = add i64 %417, 9
  store i64 %422, i64* %PC, align 8
  %423 = inttoptr i64 %421 to i64*
  %424 = load i64, i64* %423, align 8
  store i64 %424, i64* %RCX, align 8, !tbaa !2428
  %425 = add i64 %415, -32
  %426 = add i64 %417, 13
  store i64 %426, i64* %PC, align 8
  %427 = inttoptr i64 %425 to i32*
  %428 = load i32, i32* %427, align 4
  %429 = sext i32 %428 to i64
  store i64 %429, i64* %RDX, align 8, !tbaa !2428
  %430 = shl nsw i64 %429, 3
  %431 = add i64 %430, %424
  %432 = add i64 %417, 18
  store i64 %432, i64* %PC, align 8
  %433 = inttoptr i64 %431 to i64*
  store i64 %420, i64* %433, align 8
  %434 = load i64, i64* %RBP, align 8
  %435 = add i64 %434, -64
  %436 = load i64, i64* %PC, align 8
  %437 = add i64 %436, 5
  store i64 %437, i64* %PC, align 8
  %438 = inttoptr i64 %435 to i64*
  %439 = load i64, i64* %438, align 8
  store i64 %439, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %440 = add i64 %434, -16
  %441 = add i64 %436, 9
  store i64 %441, i64* %PC, align 8
  %442 = inttoptr i64 %440 to i64*
  %443 = load i64, i64* %442, align 8
  store i64 %443, i64* %RCX, align 8, !tbaa !2428
  %444 = add i64 %434, -32
  %445 = add i64 %436, 12
  store i64 %445, i64* %PC, align 8
  %446 = inttoptr i64 %444 to i32*
  %447 = load i32, i32* %446, align 4
  %448 = add i32 %447, 1
  %449 = zext i32 %448 to i64
  store i64 %449, i64* %RAX, align 8, !tbaa !2428
  %450 = icmp eq i32 %447, -1
  %451 = icmp eq i32 %448, 0
  %452 = or i1 %450, %451
  %453 = zext i1 %452 to i8
  store i8 %453, i8* %14, align 1, !tbaa !2432
  %454 = and i32 %448, 255
  %455 = tail call i32 @llvm.ctpop.i32(i32 %454) #11
  %456 = trunc i32 %455 to i8
  %457 = and i8 %456, 1
  %458 = xor i8 %457, 1
  store i8 %458, i8* %21, align 1, !tbaa !2446
  %459 = xor i32 %448, %447
  %460 = lshr i32 %459, 4
  %461 = trunc i32 %460 to i8
  %462 = and i8 %461, 1
  store i8 %462, i8* %27, align 1, !tbaa !2447
  %463 = zext i1 %451 to i8
  store i8 %463, i8* %30, align 1, !tbaa !2448
  %464 = lshr i32 %448, 31
  %465 = trunc i32 %464 to i8
  store i8 %465, i8* %33, align 1, !tbaa !2449
  %466 = lshr i32 %447, 31
  %467 = xor i32 %464, %466
  %468 = add nuw nsw i32 %467, %464
  %469 = icmp eq i32 %468, 2
  %470 = zext i1 %469 to i8
  store i8 %470, i8* %39, align 1, !tbaa !2450
  %471 = sext i32 %448 to i64
  store i64 %471, i64* %RDX, align 8, !tbaa !2428
  %472 = shl nsw i64 %471, 3
  %473 = add i64 %472, %443
  %474 = add i64 %436, 23
  store i64 %474, i64* %PC, align 8
  %475 = inttoptr i64 %473 to i64*
  store i64 %439, i64* %475, align 8
  %476 = load i64, i64* %RBP, align 8
  %477 = add i64 %476, -28
  %478 = load i64, i64* %PC, align 8
  %479 = add i64 %478, 3
  store i64 %479, i64* %PC, align 8
  %480 = inttoptr i64 %477 to i32*
  %481 = load i32, i32* %480, align 4
  %482 = add i32 %481, 2
  %483 = zext i32 %482 to i64
  store i64 %483, i64* %RAX, align 8, !tbaa !2428
  %484 = icmp ugt i32 %481, -3
  %485 = zext i1 %484 to i8
  store i8 %485, i8* %14, align 1, !tbaa !2432
  %486 = and i32 %482, 255
  %487 = tail call i32 @llvm.ctpop.i32(i32 %486) #11
  %488 = trunc i32 %487 to i8
  %489 = and i8 %488, 1
  %490 = xor i8 %489, 1
  store i8 %490, i8* %21, align 1, !tbaa !2446
  %491 = xor i32 %482, %481
  %492 = lshr i32 %491, 4
  %493 = trunc i32 %492 to i8
  %494 = and i8 %493, 1
  store i8 %494, i8* %27, align 1, !tbaa !2447
  %495 = icmp eq i32 %482, 0
  %496 = zext i1 %495 to i8
  store i8 %496, i8* %30, align 1, !tbaa !2448
  %497 = lshr i32 %482, 31
  %498 = trunc i32 %497 to i8
  store i8 %498, i8* %33, align 1, !tbaa !2449
  %499 = lshr i32 %481, 31
  %500 = xor i32 %497, %499
  %501 = add nuw nsw i32 %500, %497
  %502 = icmp eq i32 %501, 2
  %503 = zext i1 %502 to i8
  store i8 %503, i8* %39, align 1, !tbaa !2450
  %504 = add i64 %478, 9
  store i64 %504, i64* %PC, align 8
  store i32 %482, i32* %480, align 4
  %505 = load i64, i64* %PC, align 8
  %506 = add i64 %505, -215
  store i64 %506, i64* %PC, align 8, !tbaa !2428
  br label %block_401b23

block_4018ab:                                     ; preds = %block_4018ba, %block_401894
  %507 = phi i64 [ %158, %block_4018ba ], [ %.pre, %block_401894 ]
  %508 = load i64, i64* %RBP, align 8
  %509 = add i64 %508, -44
  %510 = add i64 %507, 3
  store i64 %510, i64* %PC, align 8
  %511 = inttoptr i64 %509 to i32*
  %512 = load i32, i32* %511, align 4
  %513 = shl i32 %512, 2
  %514 = zext i32 %513 to i64
  store i64 %514, i64* %RAX, align 8, !tbaa !2428
  %515 = lshr i32 %512, 30
  %516 = trunc i32 %515 to i8
  %517 = and i8 %516, 1
  store i8 %517, i8* %14, align 1, !tbaa !2453
  %518 = and i32 %513, 252
  %519 = tail call i32 @llvm.ctpop.i32(i32 %518) #11
  %520 = trunc i32 %519 to i8
  %521 = and i8 %520, 1
  %522 = xor i8 %521, 1
  store i8 %522, i8* %21, align 1, !tbaa !2453
  store i8 0, i8* %27, align 1, !tbaa !2453
  %523 = icmp eq i32 %513, 0
  %524 = zext i1 %523 to i8
  store i8 %524, i8* %30, align 1, !tbaa !2453
  %525 = lshr i32 %512, 29
  %526 = trunc i32 %525 to i8
  %527 = and i8 %526, 1
  store i8 %527, i8* %33, align 1, !tbaa !2453
  store i8 0, i8* %39, align 1, !tbaa !2453
  %528 = add i64 %508, -4
  %529 = add i64 %507, 9
  store i64 %529, i64* %PC, align 8
  %530 = inttoptr i64 %528 to i32*
  %531 = load i32, i32* %530, align 4
  %532 = sub i32 %513, %531
  %533 = icmp ult i32 %513, %531
  %534 = zext i1 %533 to i8
  store i8 %534, i8* %14, align 1, !tbaa !2432
  %535 = and i32 %532, 255
  %536 = tail call i32 @llvm.ctpop.i32(i32 %535) #11
  %537 = trunc i32 %536 to i8
  %538 = and i8 %537, 1
  %539 = xor i8 %538, 1
  store i8 %539, i8* %21, align 1, !tbaa !2446
  %540 = xor i32 %531, %513
  %541 = xor i32 %540, %532
  %542 = lshr i32 %541, 4
  %543 = trunc i32 %542 to i8
  %544 = and i8 %543, 1
  store i8 %544, i8* %27, align 1, !tbaa !2447
  %545 = icmp eq i32 %532, 0
  %546 = zext i1 %545 to i8
  store i8 %546, i8* %30, align 1, !tbaa !2448
  %547 = lshr i32 %532, 31
  %548 = trunc i32 %547 to i8
  store i8 %548, i8* %33, align 1, !tbaa !2449
  %549 = and i32 %525, 1
  %550 = lshr i32 %531, 31
  %551 = xor i32 %550, %549
  %552 = xor i32 %547, %549
  %553 = add nuw nsw i32 %552, %551
  %554 = icmp eq i32 %553, 2
  %555 = zext i1 %554 to i8
  store i8 %555, i8* %39, align 1, !tbaa !2450
  %556 = icmp ne i8 %548, 0
  %557 = xor i1 %556, %554
  %.v15 = select i1 %557, i64 15, i64 48
  %558 = add i64 %.v15, %507
  store i64 %558, i64* %PC, align 8, !tbaa !2428
  br i1 %557, label %block_4018ba, label %block_4018db

block_4018f6:                                     ; preds = %block_4018f6.preheader, %block_401902
  %559 = phi i64 [ %1560, %block_401902 ], [ %.pre12, %block_4018f6.preheader ]
  %560 = load i64, i64* %RBP, align 8
  %561 = add i64 %560, -28
  %562 = add i64 %559, 3
  store i64 %562, i64* %PC, align 8
  %563 = inttoptr i64 %561 to i32*
  %564 = load i32, i32* %563, align 4
  %565 = zext i32 %564 to i64
  store i64 %565, i64* %RAX, align 8, !tbaa !2428
  %566 = add i64 %560, -44
  %567 = add i64 %559, 6
  store i64 %567, i64* %PC, align 8
  %568 = inttoptr i64 %566 to i32*
  %569 = load i32, i32* %568, align 4
  %570 = sub i32 %564, %569
  %571 = icmp ult i32 %564, %569
  %572 = zext i1 %571 to i8
  store i8 %572, i8* %14, align 1, !tbaa !2432
  %573 = and i32 %570, 255
  %574 = tail call i32 @llvm.ctpop.i32(i32 %573) #11
  %575 = trunc i32 %574 to i8
  %576 = and i8 %575, 1
  %577 = xor i8 %576, 1
  store i8 %577, i8* %21, align 1, !tbaa !2446
  %578 = xor i32 %569, %564
  %579 = xor i32 %578, %570
  %580 = lshr i32 %579, 4
  %581 = trunc i32 %580 to i8
  %582 = and i8 %581, 1
  store i8 %582, i8* %27, align 1, !tbaa !2447
  %583 = icmp eq i32 %570, 0
  %584 = zext i1 %583 to i8
  store i8 %584, i8* %30, align 1, !tbaa !2448
  %585 = lshr i32 %570, 31
  %586 = trunc i32 %585 to i8
  store i8 %586, i8* %33, align 1, !tbaa !2449
  %587 = lshr i32 %564, 31
  %588 = lshr i32 %569, 31
  %589 = xor i32 %588, %587
  %590 = xor i32 %585, %587
  %591 = add nuw nsw i32 %590, %589
  %592 = icmp eq i32 %591, 2
  %593 = zext i1 %592 to i8
  store i8 %593, i8* %39, align 1, !tbaa !2450
  %594 = icmp ne i8 %586, 0
  %595 = xor i1 %594, %592
  %.v17 = select i1 %595, i64 12, i64 545
  %596 = add i64 %.v17, %559
  store i64 %596, i64* %PC, align 8, !tbaa !2428
  br i1 %595, label %block_401902, label %block_401c04.loopexit

block_401c04.loopexit:                            ; preds = %block_4018f6
  br label %block_401c04

block_401c04.loopexit17:                          ; preds = %block_401b23
  br label %block_401c04

block_401c04:                                     ; preds = %block_401c04.loopexit17, %block_401c04.loopexit
  %597 = phi i64 [ %596, %block_401c04.loopexit ], [ %668, %block_401c04.loopexit17 ]
  %.sink5 = phi i64 [ 237, %block_401c04.loopexit ], [ 5, %block_401c04.loopexit17 ]
  %598 = add i64 %.sink5, %597
  %599 = load i64, i64* %RSP, align 8
  %600 = add i64 %599, 112
  store i64 %600, i64* %RSP, align 8, !tbaa !2428
  %601 = icmp ugt i64 %599, -113
  %602 = zext i1 %601 to i8
  store i8 %602, i8* %14, align 1, !tbaa !2432
  %603 = trunc i64 %600 to i32
  %604 = and i32 %603, 255
  %605 = tail call i32 @llvm.ctpop.i32(i32 %604) #11
  %606 = trunc i32 %605 to i8
  %607 = and i8 %606, 1
  %608 = xor i8 %607, 1
  store i8 %608, i8* %21, align 1, !tbaa !2446
  %609 = xor i64 %599, 16
  %610 = xor i64 %609, %600
  %611 = lshr i64 %610, 4
  %612 = trunc i64 %611 to i8
  %613 = and i8 %612, 1
  store i8 %613, i8* %27, align 1, !tbaa !2447
  %614 = icmp eq i64 %600, 0
  %615 = zext i1 %614 to i8
  store i8 %615, i8* %30, align 1, !tbaa !2448
  %616 = lshr i64 %600, 63
  %617 = trunc i64 %616 to i8
  store i8 %617, i8* %33, align 1, !tbaa !2449
  %618 = lshr i64 %599, 63
  %619 = xor i64 %616, %618
  %620 = add nuw nsw i64 %619, %616
  %621 = icmp eq i64 %620, 2
  %622 = zext i1 %621 to i8
  store i8 %622, i8* %39, align 1, !tbaa !2450
  %623 = add i64 %598, 5
  store i64 %623, i64* %PC, align 8
  %624 = add i64 %599, 120
  %625 = inttoptr i64 %600 to i64*
  %626 = load i64, i64* %625, align 8
  store i64 %626, i64* %RBP, align 8, !tbaa !2428
  store i64 %624, i64* %RSP, align 8, !tbaa !2428
  %627 = add i64 %598, 6
  store i64 %627, i64* %PC, align 8
  %628 = inttoptr i64 %624 to i64*
  %629 = load i64, i64* %628, align 8
  store i64 %629, i64* %PC, align 8, !tbaa !2428
  %630 = add i64 %599, 128
  store i64 %630, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.4

block_401b23:                                     ; preds = %block_401b23.preheader, %block_401b2f
  %631 = phi i64 [ %506, %block_401b2f ], [ %.pre12, %block_401b23.preheader ]
  %632 = load i64, i64* %RBP, align 8
  %633 = add i64 %632, -28
  %634 = add i64 %631, 3
  store i64 %634, i64* %PC, align 8
  %635 = inttoptr i64 %633 to i32*
  %636 = load i32, i32* %635, align 4
  %637 = zext i32 %636 to i64
  store i64 %637, i64* %RAX, align 8, !tbaa !2428
  %638 = add i64 %632, -44
  %639 = add i64 %631, 6
  store i64 %639, i64* %PC, align 8
  %640 = inttoptr i64 %638 to i32*
  %641 = load i32, i32* %640, align 4
  %642 = sub i32 %636, %641
  %643 = icmp ult i32 %636, %641
  %644 = zext i1 %643 to i8
  store i8 %644, i8* %14, align 1, !tbaa !2432
  %645 = and i32 %642, 255
  %646 = tail call i32 @llvm.ctpop.i32(i32 %645) #11
  %647 = trunc i32 %646 to i8
  %648 = and i8 %647, 1
  %649 = xor i8 %648, 1
  store i8 %649, i8* %21, align 1, !tbaa !2446
  %650 = xor i32 %641, %636
  %651 = xor i32 %650, %642
  %652 = lshr i32 %651, 4
  %653 = trunc i32 %652 to i8
  %654 = and i8 %653, 1
  store i8 %654, i8* %27, align 1, !tbaa !2447
  %655 = icmp eq i32 %642, 0
  %656 = zext i1 %655 to i8
  store i8 %656, i8* %30, align 1, !tbaa !2448
  %657 = lshr i32 %642, 31
  %658 = trunc i32 %657 to i8
  store i8 %658, i8* %33, align 1, !tbaa !2449
  %659 = lshr i32 %636, 31
  %660 = lshr i32 %641, 31
  %661 = xor i32 %660, %659
  %662 = xor i32 %657, %659
  %663 = add nuw nsw i32 %662, %661
  %664 = icmp eq i32 %663, 2
  %665 = zext i1 %664 to i8
  store i8 %665, i8* %39, align 1, !tbaa !2450
  %666 = icmp ne i8 %658, 0
  %667 = xor i1 %666, %664
  %.v16 = select i1 %667, i64 12, i64 220
  %668 = add i64 %.v16, %631
  store i64 %668, i64* %PC, align 8, !tbaa !2428
  br i1 %667, label %block_401b2f, label %block_401c04.loopexit17

block_401902:                                     ; preds = %block_4018f6
  %669 = add i64 %596, 3
  store i64 %669, i64* %PC, align 8
  %670 = load i32, i32* %563, align 4
  %671 = zext i32 %670 to i64
  store i64 %671, i64* %RAX, align 8, !tbaa !2428
  %672 = add i64 %596, 6
  store i64 %672, i64* %PC, align 8
  %673 = load i32, i32* %568, align 4
  %674 = add i32 %673, %670
  %675 = zext i32 %674 to i64
  store i64 %675, i64* %RAX, align 8, !tbaa !2428
  %676 = icmp ult i32 %674, %670
  %677 = icmp ult i32 %674, %673
  %678 = or i1 %676, %677
  %679 = zext i1 %678 to i8
  store i8 %679, i8* %14, align 1, !tbaa !2432
  %680 = and i32 %674, 255
  %681 = tail call i32 @llvm.ctpop.i32(i32 %680) #11
  %682 = trunc i32 %681 to i8
  %683 = and i8 %682, 1
  %684 = xor i8 %683, 1
  store i8 %684, i8* %21, align 1, !tbaa !2446
  %685 = xor i32 %673, %670
  %686 = xor i32 %685, %674
  %687 = lshr i32 %686, 4
  %688 = trunc i32 %687 to i8
  %689 = and i8 %688, 1
  store i8 %689, i8* %27, align 1, !tbaa !2447
  %690 = icmp eq i32 %674, 0
  %691 = zext i1 %690 to i8
  store i8 %691, i8* %30, align 1, !tbaa !2448
  %692 = lshr i32 %674, 31
  %693 = trunc i32 %692 to i8
  store i8 %693, i8* %33, align 1, !tbaa !2449
  %694 = lshr i32 %670, 31
  %695 = lshr i32 %673, 31
  %696 = xor i32 %692, %694
  %697 = xor i32 %692, %695
  %698 = add nuw nsw i32 %696, %697
  %699 = icmp eq i32 %698, 2
  %700 = zext i1 %699 to i8
  store i8 %700, i8* %39, align 1, !tbaa !2450
  %701 = add i64 %560, -32
  %702 = add i64 %596, 9
  store i64 %702, i64* %PC, align 8
  %703 = inttoptr i64 %701 to i32*
  store i32 %674, i32* %703, align 4
  %704 = load i64, i64* %RBP, align 8
  %705 = add i64 %704, -32
  %706 = load i64, i64* %PC, align 8
  %707 = add i64 %706, 3
  store i64 %707, i64* %PC, align 8
  %708 = inttoptr i64 %705 to i32*
  %709 = load i32, i32* %708, align 4
  %710 = zext i32 %709 to i64
  store i64 %710, i64* %RAX, align 8, !tbaa !2428
  %711 = add i64 %704, -44
  %712 = add i64 %706, 6
  store i64 %712, i64* %PC, align 8
  %713 = inttoptr i64 %711 to i32*
  %714 = load i32, i32* %713, align 4
  %715 = add i32 %714, %709
  %716 = zext i32 %715 to i64
  store i64 %716, i64* %RAX, align 8, !tbaa !2428
  %717 = icmp ult i32 %715, %709
  %718 = icmp ult i32 %715, %714
  %719 = or i1 %717, %718
  %720 = zext i1 %719 to i8
  store i8 %720, i8* %14, align 1, !tbaa !2432
  %721 = and i32 %715, 255
  %722 = tail call i32 @llvm.ctpop.i32(i32 %721) #11
  %723 = trunc i32 %722 to i8
  %724 = and i8 %723, 1
  %725 = xor i8 %724, 1
  store i8 %725, i8* %21, align 1, !tbaa !2446
  %726 = xor i32 %714, %709
  %727 = xor i32 %726, %715
  %728 = lshr i32 %727, 4
  %729 = trunc i32 %728 to i8
  %730 = and i8 %729, 1
  store i8 %730, i8* %27, align 1, !tbaa !2447
  %731 = icmp eq i32 %715, 0
  %732 = zext i1 %731 to i8
  store i8 %732, i8* %30, align 1, !tbaa !2448
  %733 = lshr i32 %715, 31
  %734 = trunc i32 %733 to i8
  store i8 %734, i8* %33, align 1, !tbaa !2449
  %735 = lshr i32 %709, 31
  %736 = lshr i32 %714, 31
  %737 = xor i32 %733, %735
  %738 = xor i32 %733, %736
  %739 = add nuw nsw i32 %737, %738
  %740 = icmp eq i32 %739, 2
  %741 = zext i1 %740 to i8
  store i8 %741, i8* %39, align 1, !tbaa !2450
  %742 = add i64 %704, -36
  %743 = add i64 %706, 9
  store i64 %743, i64* %PC, align 8
  %744 = inttoptr i64 %742 to i32*
  store i32 %715, i32* %744, align 4
  %745 = load i64, i64* %RBP, align 8
  %746 = add i64 %745, -36
  %747 = load i64, i64* %PC, align 8
  %748 = add i64 %747, 3
  store i64 %748, i64* %PC, align 8
  %749 = inttoptr i64 %746 to i32*
  %750 = load i32, i32* %749, align 4
  %751 = zext i32 %750 to i64
  store i64 %751, i64* %RAX, align 8, !tbaa !2428
  %752 = add i64 %745, -44
  %753 = add i64 %747, 6
  store i64 %753, i64* %PC, align 8
  %754 = inttoptr i64 %752 to i32*
  %755 = load i32, i32* %754, align 4
  %756 = add i32 %755, %750
  %757 = zext i32 %756 to i64
  store i64 %757, i64* %RAX, align 8, !tbaa !2428
  %758 = icmp ult i32 %756, %750
  %759 = icmp ult i32 %756, %755
  %760 = or i1 %758, %759
  %761 = zext i1 %760 to i8
  store i8 %761, i8* %14, align 1, !tbaa !2432
  %762 = and i32 %756, 255
  %763 = tail call i32 @llvm.ctpop.i32(i32 %762) #11
  %764 = trunc i32 %763 to i8
  %765 = and i8 %764, 1
  %766 = xor i8 %765, 1
  store i8 %766, i8* %21, align 1, !tbaa !2446
  %767 = xor i32 %755, %750
  %768 = xor i32 %767, %756
  %769 = lshr i32 %768, 4
  %770 = trunc i32 %769 to i8
  %771 = and i8 %770, 1
  store i8 %771, i8* %27, align 1, !tbaa !2447
  %772 = icmp eq i32 %756, 0
  %773 = zext i1 %772 to i8
  store i8 %773, i8* %30, align 1, !tbaa !2448
  %774 = lshr i32 %756, 31
  %775 = trunc i32 %774 to i8
  store i8 %775, i8* %33, align 1, !tbaa !2449
  %776 = lshr i32 %750, 31
  %777 = lshr i32 %755, 31
  %778 = xor i32 %774, %776
  %779 = xor i32 %774, %777
  %780 = add nuw nsw i32 %778, %779
  %781 = icmp eq i32 %780, 2
  %782 = zext i1 %781 to i8
  store i8 %782, i8* %39, align 1, !tbaa !2450
  %783 = add i64 %745, -40
  %784 = add i64 %747, 9
  store i64 %784, i64* %PC, align 8
  %785 = inttoptr i64 %783 to i32*
  store i32 %756, i32* %785, align 4
  %786 = load i64, i64* %RBP, align 8
  %787 = add i64 %786, -16
  %788 = load i64, i64* %PC, align 8
  %789 = add i64 %788, 4
  store i64 %789, i64* %PC, align 8
  %790 = inttoptr i64 %787 to i64*
  %791 = load i64, i64* %790, align 8
  store i64 %791, i64* %RCX, align 8, !tbaa !2428
  %792 = add i64 %786, -28
  %793 = add i64 %788, 8
  store i64 %793, i64* %PC, align 8
  %794 = inttoptr i64 %792 to i32*
  %795 = load i32, i32* %794, align 4
  %796 = sext i32 %795 to i64
  store i64 %796, i64* %RDX, align 8, !tbaa !2428
  %797 = shl nsw i64 %796, 3
  %798 = add i64 %797, %791
  %799 = add i64 %788, 13
  store i64 %799, i64* %PC, align 8
  %800 = inttoptr i64 %798 to i64*
  %801 = load i64, i64* %800, align 8
  store i64 %801, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %802 = add i64 %788, 17
  store i64 %802, i64* %PC, align 8
  %803 = load i64, i64* %790, align 8
  store i64 %803, i64* %RCX, align 8, !tbaa !2428
  %804 = add i64 %786, -32
  %805 = add i64 %788, 21
  store i64 %805, i64* %PC, align 8
  %806 = inttoptr i64 %804 to i32*
  %807 = load i32, i32* %806, align 4
  %808 = sext i32 %807 to i64
  store i64 %808, i64* %RDX, align 8, !tbaa !2428
  %809 = shl nsw i64 %808, 3
  %810 = add i64 %809, %803
  %811 = add i64 %788, 26
  store i64 %811, i64* %PC, align 8
  %812 = bitcast i64 %801 to double
  %813 = inttoptr i64 %810 to double*
  %814 = load double, double* %813, align 8
  %815 = fadd double %812, %814
  store double %815, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %816 = add i64 %786, -56
  %817 = add i64 %788, 31
  store i64 %817, i64* %PC, align 8
  %818 = inttoptr i64 %816 to double*
  store double %815, double* %818, align 8
  %819 = load i64, i64* %RBP, align 8
  %820 = add i64 %819, -16
  %821 = load i64, i64* %PC, align 8
  %822 = add i64 %821, 4
  store i64 %822, i64* %PC, align 8
  %823 = inttoptr i64 %820 to i64*
  %824 = load i64, i64* %823, align 8
  store i64 %824, i64* %RCX, align 8, !tbaa !2428
  %825 = add i64 %819, -28
  %826 = add i64 %821, 7
  store i64 %826, i64* %PC, align 8
  %827 = inttoptr i64 %825 to i32*
  %828 = load i32, i32* %827, align 4
  %829 = add i32 %828, 1
  %830 = zext i32 %829 to i64
  store i64 %830, i64* %RAX, align 8, !tbaa !2428
  %831 = icmp eq i32 %828, -1
  %832 = icmp eq i32 %829, 0
  %833 = or i1 %831, %832
  %834 = zext i1 %833 to i8
  store i8 %834, i8* %14, align 1, !tbaa !2432
  %835 = and i32 %829, 255
  %836 = tail call i32 @llvm.ctpop.i32(i32 %835) #11
  %837 = trunc i32 %836 to i8
  %838 = and i8 %837, 1
  %839 = xor i8 %838, 1
  store i8 %839, i8* %21, align 1, !tbaa !2446
  %840 = xor i32 %829, %828
  %841 = lshr i32 %840, 4
  %842 = trunc i32 %841 to i8
  %843 = and i8 %842, 1
  store i8 %843, i8* %27, align 1, !tbaa !2447
  %844 = zext i1 %832 to i8
  store i8 %844, i8* %30, align 1, !tbaa !2448
  %845 = lshr i32 %829, 31
  %846 = trunc i32 %845 to i8
  store i8 %846, i8* %33, align 1, !tbaa !2449
  %847 = lshr i32 %828, 31
  %848 = xor i32 %845, %847
  %849 = add nuw nsw i32 %848, %845
  %850 = icmp eq i32 %849, 2
  %851 = zext i1 %850 to i8
  store i8 %851, i8* %39, align 1, !tbaa !2450
  %852 = sext i32 %829 to i64
  store i64 %852, i64* %RDX, align 8, !tbaa !2428
  %853 = shl nsw i64 %852, 3
  %854 = add i64 %853, %824
  %855 = add i64 %821, 18
  store i64 %855, i64* %PC, align 8
  %856 = inttoptr i64 %854 to i64*
  %857 = load i64, i64* %856, align 8
  store i64 %857, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %858 = add i64 %821, 22
  store i64 %858, i64* %PC, align 8
  %859 = load i64, i64* %823, align 8
  store i64 %859, i64* %RCX, align 8, !tbaa !2428
  %860 = add i64 %819, -32
  %861 = add i64 %821, 25
  store i64 %861, i64* %PC, align 8
  %862 = inttoptr i64 %860 to i32*
  %863 = load i32, i32* %862, align 4
  %864 = add i32 %863, 1
  %865 = zext i32 %864 to i64
  store i64 %865, i64* %RAX, align 8, !tbaa !2428
  %866 = icmp eq i32 %863, -1
  %867 = icmp eq i32 %864, 0
  %868 = or i1 %866, %867
  %869 = zext i1 %868 to i8
  store i8 %869, i8* %14, align 1, !tbaa !2432
  %870 = and i32 %864, 255
  %871 = tail call i32 @llvm.ctpop.i32(i32 %870) #11
  %872 = trunc i32 %871 to i8
  %873 = and i8 %872, 1
  %874 = xor i8 %873, 1
  store i8 %874, i8* %21, align 1, !tbaa !2446
  %875 = xor i32 %864, %863
  %876 = lshr i32 %875, 4
  %877 = trunc i32 %876 to i8
  %878 = and i8 %877, 1
  store i8 %878, i8* %27, align 1, !tbaa !2447
  %879 = zext i1 %867 to i8
  store i8 %879, i8* %30, align 1, !tbaa !2448
  %880 = lshr i32 %864, 31
  %881 = trunc i32 %880 to i8
  store i8 %881, i8* %33, align 1, !tbaa !2449
  %882 = lshr i32 %863, 31
  %883 = xor i32 %880, %882
  %884 = add nuw nsw i32 %883, %880
  %885 = icmp eq i32 %884, 2
  %886 = zext i1 %885 to i8
  store i8 %886, i8* %39, align 1, !tbaa !2450
  %887 = sext i32 %864 to i64
  store i64 %887, i64* %RDX, align 8, !tbaa !2428
  %888 = shl nsw i64 %887, 3
  %889 = add i64 %888, %859
  %890 = add i64 %821, 36
  store i64 %890, i64* %PC, align 8
  %891 = bitcast i64 %857 to double
  %892 = inttoptr i64 %889 to double*
  %893 = load double, double* %892, align 8
  %894 = fadd double %891, %893
  store double %894, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %895 = load i64, i64* %RBP, align 8
  %896 = add i64 %895, -64
  %897 = add i64 %821, 41
  store i64 %897, i64* %PC, align 8
  %898 = inttoptr i64 %896 to double*
  store double %894, double* %898, align 8
  %899 = load i64, i64* %RBP, align 8
  %900 = add i64 %899, -16
  %901 = load i64, i64* %PC, align 8
  %902 = add i64 %901, 4
  store i64 %902, i64* %PC, align 8
  %903 = inttoptr i64 %900 to i64*
  %904 = load i64, i64* %903, align 8
  store i64 %904, i64* %RCX, align 8, !tbaa !2428
  %905 = add i64 %899, -28
  %906 = add i64 %901, 8
  store i64 %906, i64* %PC, align 8
  %907 = inttoptr i64 %905 to i32*
  %908 = load i32, i32* %907, align 4
  %909 = sext i32 %908 to i64
  store i64 %909, i64* %RDX, align 8, !tbaa !2428
  %910 = shl nsw i64 %909, 3
  %911 = add i64 %910, %904
  %912 = add i64 %901, 13
  store i64 %912, i64* %PC, align 8
  %913 = inttoptr i64 %911 to i64*
  %914 = load i64, i64* %913, align 8
  store i64 %914, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %915 = add i64 %901, 17
  store i64 %915, i64* %PC, align 8
  %916 = load i64, i64* %903, align 8
  store i64 %916, i64* %RCX, align 8, !tbaa !2428
  %917 = add i64 %899, -32
  %918 = add i64 %901, 21
  store i64 %918, i64* %PC, align 8
  %919 = inttoptr i64 %917 to i32*
  %920 = load i32, i32* %919, align 4
  %921 = sext i32 %920 to i64
  store i64 %921, i64* %RDX, align 8, !tbaa !2428
  %922 = shl nsw i64 %921, 3
  %923 = add i64 %922, %916
  %924 = add i64 %901, 26
  store i64 %924, i64* %PC, align 8
  %925 = bitcast i64 %914 to double
  %926 = inttoptr i64 %923 to double*
  %927 = load double, double* %926, align 8
  %928 = fsub double %925, %927
  store double %928, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %929 = add i64 %899, -72
  %930 = add i64 %901, 31
  store i64 %930, i64* %PC, align 8
  %931 = inttoptr i64 %929 to double*
  store double %928, double* %931, align 8
  %932 = load i64, i64* %RBP, align 8
  %933 = add i64 %932, -16
  %934 = load i64, i64* %PC, align 8
  %935 = add i64 %934, 4
  store i64 %935, i64* %PC, align 8
  %936 = inttoptr i64 %933 to i64*
  %937 = load i64, i64* %936, align 8
  store i64 %937, i64* %RCX, align 8, !tbaa !2428
  %938 = add i64 %932, -28
  %939 = add i64 %934, 7
  store i64 %939, i64* %PC, align 8
  %940 = inttoptr i64 %938 to i32*
  %941 = load i32, i32* %940, align 4
  %942 = add i32 %941, 1
  %943 = zext i32 %942 to i64
  store i64 %943, i64* %RAX, align 8, !tbaa !2428
  %944 = icmp eq i32 %941, -1
  %945 = icmp eq i32 %942, 0
  %946 = or i1 %944, %945
  %947 = zext i1 %946 to i8
  store i8 %947, i8* %14, align 1, !tbaa !2432
  %948 = and i32 %942, 255
  %949 = tail call i32 @llvm.ctpop.i32(i32 %948) #11
  %950 = trunc i32 %949 to i8
  %951 = and i8 %950, 1
  %952 = xor i8 %951, 1
  store i8 %952, i8* %21, align 1, !tbaa !2446
  %953 = xor i32 %942, %941
  %954 = lshr i32 %953, 4
  %955 = trunc i32 %954 to i8
  %956 = and i8 %955, 1
  store i8 %956, i8* %27, align 1, !tbaa !2447
  %957 = zext i1 %945 to i8
  store i8 %957, i8* %30, align 1, !tbaa !2448
  %958 = lshr i32 %942, 31
  %959 = trunc i32 %958 to i8
  store i8 %959, i8* %33, align 1, !tbaa !2449
  %960 = lshr i32 %941, 31
  %961 = xor i32 %958, %960
  %962 = add nuw nsw i32 %961, %958
  %963 = icmp eq i32 %962, 2
  %964 = zext i1 %963 to i8
  store i8 %964, i8* %39, align 1, !tbaa !2450
  %965 = sext i32 %942 to i64
  store i64 %965, i64* %RDX, align 8, !tbaa !2428
  %966 = shl nsw i64 %965, 3
  %967 = add i64 %966, %937
  %968 = add i64 %934, 18
  store i64 %968, i64* %PC, align 8
  %969 = inttoptr i64 %967 to i64*
  %970 = load i64, i64* %969, align 8
  store i64 %970, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %971 = add i64 %934, 22
  store i64 %971, i64* %PC, align 8
  %972 = load i64, i64* %936, align 8
  store i64 %972, i64* %RCX, align 8, !tbaa !2428
  %973 = add i64 %932, -32
  %974 = add i64 %934, 25
  store i64 %974, i64* %PC, align 8
  %975 = inttoptr i64 %973 to i32*
  %976 = load i32, i32* %975, align 4
  %977 = add i32 %976, 1
  %978 = zext i32 %977 to i64
  store i64 %978, i64* %RAX, align 8, !tbaa !2428
  %979 = icmp eq i32 %976, -1
  %980 = icmp eq i32 %977, 0
  %981 = or i1 %979, %980
  %982 = zext i1 %981 to i8
  store i8 %982, i8* %14, align 1, !tbaa !2432
  %983 = and i32 %977, 255
  %984 = tail call i32 @llvm.ctpop.i32(i32 %983) #11
  %985 = trunc i32 %984 to i8
  %986 = and i8 %985, 1
  %987 = xor i8 %986, 1
  store i8 %987, i8* %21, align 1, !tbaa !2446
  %988 = xor i32 %977, %976
  %989 = lshr i32 %988, 4
  %990 = trunc i32 %989 to i8
  %991 = and i8 %990, 1
  store i8 %991, i8* %27, align 1, !tbaa !2447
  %992 = zext i1 %980 to i8
  store i8 %992, i8* %30, align 1, !tbaa !2448
  %993 = lshr i32 %977, 31
  %994 = trunc i32 %993 to i8
  store i8 %994, i8* %33, align 1, !tbaa !2449
  %995 = lshr i32 %976, 31
  %996 = xor i32 %993, %995
  %997 = add nuw nsw i32 %996, %993
  %998 = icmp eq i32 %997, 2
  %999 = zext i1 %998 to i8
  store i8 %999, i8* %39, align 1, !tbaa !2450
  %1000 = sext i32 %977 to i64
  store i64 %1000, i64* %RDX, align 8, !tbaa !2428
  %1001 = shl nsw i64 %1000, 3
  %1002 = add i64 %1001, %972
  %1003 = add i64 %934, 36
  store i64 %1003, i64* %PC, align 8
  %1004 = bitcast i64 %970 to double
  %1005 = inttoptr i64 %1002 to double*
  %1006 = load double, double* %1005, align 8
  %1007 = fsub double %1004, %1006
  store double %1007, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %1008 = load i64, i64* %RBP, align 8
  %1009 = add i64 %1008, -80
  %1010 = add i64 %934, 41
  store i64 %1010, i64* %PC, align 8
  %1011 = inttoptr i64 %1009 to double*
  store double %1007, double* %1011, align 8
  %1012 = load i64, i64* %RBP, align 8
  %1013 = add i64 %1012, -16
  %1014 = load i64, i64* %PC, align 8
  %1015 = add i64 %1014, 4
  store i64 %1015, i64* %PC, align 8
  %1016 = inttoptr i64 %1013 to i64*
  %1017 = load i64, i64* %1016, align 8
  store i64 %1017, i64* %RCX, align 8, !tbaa !2428
  %1018 = add i64 %1012, -36
  %1019 = add i64 %1014, 8
  store i64 %1019, i64* %PC, align 8
  %1020 = inttoptr i64 %1018 to i32*
  %1021 = load i32, i32* %1020, align 4
  %1022 = sext i32 %1021 to i64
  store i64 %1022, i64* %RDX, align 8, !tbaa !2428
  %1023 = shl nsw i64 %1022, 3
  %1024 = add i64 %1023, %1017
  %1025 = add i64 %1014, 13
  store i64 %1025, i64* %PC, align 8
  %1026 = inttoptr i64 %1024 to i64*
  %1027 = load i64, i64* %1026, align 8
  store i64 %1027, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %1028 = add i64 %1014, 17
  store i64 %1028, i64* %PC, align 8
  %1029 = load i64, i64* %1016, align 8
  store i64 %1029, i64* %RCX, align 8, !tbaa !2428
  %1030 = add i64 %1012, -40
  %1031 = add i64 %1014, 21
  store i64 %1031, i64* %PC, align 8
  %1032 = inttoptr i64 %1030 to i32*
  %1033 = load i32, i32* %1032, align 4
  %1034 = sext i32 %1033 to i64
  store i64 %1034, i64* %RDX, align 8, !tbaa !2428
  %1035 = shl nsw i64 %1034, 3
  %1036 = add i64 %1035, %1029
  %1037 = add i64 %1014, 26
  store i64 %1037, i64* %PC, align 8
  %1038 = bitcast i64 %1027 to double
  %1039 = inttoptr i64 %1036 to double*
  %1040 = load double, double* %1039, align 8
  %1041 = fadd double %1038, %1040
  store double %1041, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %1042 = add i64 %1012, -88
  %1043 = add i64 %1014, 31
  store i64 %1043, i64* %PC, align 8
  %1044 = inttoptr i64 %1042 to double*
  store double %1041, double* %1044, align 8
  %1045 = load i64, i64* %RBP, align 8
  %1046 = add i64 %1045, -16
  %1047 = load i64, i64* %PC, align 8
  %1048 = add i64 %1047, 4
  store i64 %1048, i64* %PC, align 8
  %1049 = inttoptr i64 %1046 to i64*
  %1050 = load i64, i64* %1049, align 8
  store i64 %1050, i64* %RCX, align 8, !tbaa !2428
  %1051 = add i64 %1045, -36
  %1052 = add i64 %1047, 7
  store i64 %1052, i64* %PC, align 8
  %1053 = inttoptr i64 %1051 to i32*
  %1054 = load i32, i32* %1053, align 4
  %1055 = add i32 %1054, 1
  %1056 = zext i32 %1055 to i64
  store i64 %1056, i64* %RAX, align 8, !tbaa !2428
  %1057 = icmp eq i32 %1054, -1
  %1058 = icmp eq i32 %1055, 0
  %1059 = or i1 %1057, %1058
  %1060 = zext i1 %1059 to i8
  store i8 %1060, i8* %14, align 1, !tbaa !2432
  %1061 = and i32 %1055, 255
  %1062 = tail call i32 @llvm.ctpop.i32(i32 %1061) #11
  %1063 = trunc i32 %1062 to i8
  %1064 = and i8 %1063, 1
  %1065 = xor i8 %1064, 1
  store i8 %1065, i8* %21, align 1, !tbaa !2446
  %1066 = xor i32 %1055, %1054
  %1067 = lshr i32 %1066, 4
  %1068 = trunc i32 %1067 to i8
  %1069 = and i8 %1068, 1
  store i8 %1069, i8* %27, align 1, !tbaa !2447
  %1070 = zext i1 %1058 to i8
  store i8 %1070, i8* %30, align 1, !tbaa !2448
  %1071 = lshr i32 %1055, 31
  %1072 = trunc i32 %1071 to i8
  store i8 %1072, i8* %33, align 1, !tbaa !2449
  %1073 = lshr i32 %1054, 31
  %1074 = xor i32 %1071, %1073
  %1075 = add nuw nsw i32 %1074, %1071
  %1076 = icmp eq i32 %1075, 2
  %1077 = zext i1 %1076 to i8
  store i8 %1077, i8* %39, align 1, !tbaa !2450
  %1078 = sext i32 %1055 to i64
  store i64 %1078, i64* %RDX, align 8, !tbaa !2428
  %1079 = shl nsw i64 %1078, 3
  %1080 = add i64 %1079, %1050
  %1081 = add i64 %1047, 18
  store i64 %1081, i64* %PC, align 8
  %1082 = inttoptr i64 %1080 to i64*
  %1083 = load i64, i64* %1082, align 8
  store i64 %1083, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %1084 = add i64 %1047, 22
  store i64 %1084, i64* %PC, align 8
  %1085 = load i64, i64* %1049, align 8
  store i64 %1085, i64* %RCX, align 8, !tbaa !2428
  %1086 = add i64 %1045, -40
  %1087 = add i64 %1047, 25
  store i64 %1087, i64* %PC, align 8
  %1088 = inttoptr i64 %1086 to i32*
  %1089 = load i32, i32* %1088, align 4
  %1090 = add i32 %1089, 1
  %1091 = zext i32 %1090 to i64
  store i64 %1091, i64* %RAX, align 8, !tbaa !2428
  %1092 = icmp eq i32 %1089, -1
  %1093 = icmp eq i32 %1090, 0
  %1094 = or i1 %1092, %1093
  %1095 = zext i1 %1094 to i8
  store i8 %1095, i8* %14, align 1, !tbaa !2432
  %1096 = and i32 %1090, 255
  %1097 = tail call i32 @llvm.ctpop.i32(i32 %1096) #11
  %1098 = trunc i32 %1097 to i8
  %1099 = and i8 %1098, 1
  %1100 = xor i8 %1099, 1
  store i8 %1100, i8* %21, align 1, !tbaa !2446
  %1101 = xor i32 %1090, %1089
  %1102 = lshr i32 %1101, 4
  %1103 = trunc i32 %1102 to i8
  %1104 = and i8 %1103, 1
  store i8 %1104, i8* %27, align 1, !tbaa !2447
  %1105 = zext i1 %1093 to i8
  store i8 %1105, i8* %30, align 1, !tbaa !2448
  %1106 = lshr i32 %1090, 31
  %1107 = trunc i32 %1106 to i8
  store i8 %1107, i8* %33, align 1, !tbaa !2449
  %1108 = lshr i32 %1089, 31
  %1109 = xor i32 %1106, %1108
  %1110 = add nuw nsw i32 %1109, %1106
  %1111 = icmp eq i32 %1110, 2
  %1112 = zext i1 %1111 to i8
  store i8 %1112, i8* %39, align 1, !tbaa !2450
  %1113 = sext i32 %1090 to i64
  store i64 %1113, i64* %RDX, align 8, !tbaa !2428
  %1114 = shl nsw i64 %1113, 3
  %1115 = add i64 %1114, %1085
  %1116 = add i64 %1047, 36
  store i64 %1116, i64* %PC, align 8
  %1117 = bitcast i64 %1083 to double
  %1118 = inttoptr i64 %1115 to double*
  %1119 = load double, double* %1118, align 8
  %1120 = fadd double %1117, %1119
  store double %1120, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %1121 = load i64, i64* %RBP, align 8
  %1122 = add i64 %1121, -96
  %1123 = add i64 %1047, 41
  store i64 %1123, i64* %PC, align 8
  %1124 = inttoptr i64 %1122 to double*
  store double %1120, double* %1124, align 8
  %1125 = load i64, i64* %RBP, align 8
  %1126 = add i64 %1125, -16
  %1127 = load i64, i64* %PC, align 8
  %1128 = add i64 %1127, 4
  store i64 %1128, i64* %PC, align 8
  %1129 = inttoptr i64 %1126 to i64*
  %1130 = load i64, i64* %1129, align 8
  store i64 %1130, i64* %RCX, align 8, !tbaa !2428
  %1131 = add i64 %1125, -36
  %1132 = add i64 %1127, 8
  store i64 %1132, i64* %PC, align 8
  %1133 = inttoptr i64 %1131 to i32*
  %1134 = load i32, i32* %1133, align 4
  %1135 = sext i32 %1134 to i64
  store i64 %1135, i64* %RDX, align 8, !tbaa !2428
  %1136 = shl nsw i64 %1135, 3
  %1137 = add i64 %1136, %1130
  %1138 = add i64 %1127, 13
  store i64 %1138, i64* %PC, align 8
  %1139 = inttoptr i64 %1137 to i64*
  %1140 = load i64, i64* %1139, align 8
  store i64 %1140, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %1141 = add i64 %1127, 17
  store i64 %1141, i64* %PC, align 8
  %1142 = load i64, i64* %1129, align 8
  store i64 %1142, i64* %RCX, align 8, !tbaa !2428
  %1143 = add i64 %1125, -40
  %1144 = add i64 %1127, 21
  store i64 %1144, i64* %PC, align 8
  %1145 = inttoptr i64 %1143 to i32*
  %1146 = load i32, i32* %1145, align 4
  %1147 = sext i32 %1146 to i64
  store i64 %1147, i64* %RDX, align 8, !tbaa !2428
  %1148 = shl nsw i64 %1147, 3
  %1149 = add i64 %1148, %1142
  %1150 = add i64 %1127, 26
  store i64 %1150, i64* %PC, align 8
  %1151 = bitcast i64 %1140 to double
  %1152 = inttoptr i64 %1149 to double*
  %1153 = load double, double* %1152, align 8
  %1154 = fsub double %1151, %1153
  store double %1154, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %1155 = add i64 %1125, -104
  %1156 = add i64 %1127, 31
  store i64 %1156, i64* %PC, align 8
  %1157 = inttoptr i64 %1155 to double*
  store double %1154, double* %1157, align 8
  %1158 = load i64, i64* %RBP, align 8
  %1159 = add i64 %1158, -16
  %1160 = load i64, i64* %PC, align 8
  %1161 = add i64 %1160, 4
  store i64 %1161, i64* %PC, align 8
  %1162 = inttoptr i64 %1159 to i64*
  %1163 = load i64, i64* %1162, align 8
  store i64 %1163, i64* %RCX, align 8, !tbaa !2428
  %1164 = add i64 %1158, -36
  %1165 = add i64 %1160, 7
  store i64 %1165, i64* %PC, align 8
  %1166 = inttoptr i64 %1164 to i32*
  %1167 = load i32, i32* %1166, align 4
  %1168 = add i32 %1167, 1
  %1169 = zext i32 %1168 to i64
  store i64 %1169, i64* %RAX, align 8, !tbaa !2428
  %1170 = icmp eq i32 %1167, -1
  %1171 = icmp eq i32 %1168, 0
  %1172 = or i1 %1170, %1171
  %1173 = zext i1 %1172 to i8
  store i8 %1173, i8* %14, align 1, !tbaa !2432
  %1174 = and i32 %1168, 255
  %1175 = tail call i32 @llvm.ctpop.i32(i32 %1174) #11
  %1176 = trunc i32 %1175 to i8
  %1177 = and i8 %1176, 1
  %1178 = xor i8 %1177, 1
  store i8 %1178, i8* %21, align 1, !tbaa !2446
  %1179 = xor i32 %1168, %1167
  %1180 = lshr i32 %1179, 4
  %1181 = trunc i32 %1180 to i8
  %1182 = and i8 %1181, 1
  store i8 %1182, i8* %27, align 1, !tbaa !2447
  %1183 = zext i1 %1171 to i8
  store i8 %1183, i8* %30, align 1, !tbaa !2448
  %1184 = lshr i32 %1168, 31
  %1185 = trunc i32 %1184 to i8
  store i8 %1185, i8* %33, align 1, !tbaa !2449
  %1186 = lshr i32 %1167, 31
  %1187 = xor i32 %1184, %1186
  %1188 = add nuw nsw i32 %1187, %1184
  %1189 = icmp eq i32 %1188, 2
  %1190 = zext i1 %1189 to i8
  store i8 %1190, i8* %39, align 1, !tbaa !2450
  %1191 = sext i32 %1168 to i64
  store i64 %1191, i64* %RDX, align 8, !tbaa !2428
  %1192 = shl nsw i64 %1191, 3
  %1193 = add i64 %1192, %1163
  %1194 = add i64 %1160, 18
  store i64 %1194, i64* %PC, align 8
  %1195 = inttoptr i64 %1193 to i64*
  %1196 = load i64, i64* %1195, align 8
  store i64 %1196, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %1197 = add i64 %1160, 22
  store i64 %1197, i64* %PC, align 8
  %1198 = load i64, i64* %1162, align 8
  store i64 %1198, i64* %RCX, align 8, !tbaa !2428
  %1199 = add i64 %1158, -40
  %1200 = add i64 %1160, 25
  store i64 %1200, i64* %PC, align 8
  %1201 = inttoptr i64 %1199 to i32*
  %1202 = load i32, i32* %1201, align 4
  %1203 = add i32 %1202, 1
  %1204 = zext i32 %1203 to i64
  store i64 %1204, i64* %RAX, align 8, !tbaa !2428
  %1205 = icmp eq i32 %1202, -1
  %1206 = icmp eq i32 %1203, 0
  %1207 = or i1 %1205, %1206
  %1208 = zext i1 %1207 to i8
  store i8 %1208, i8* %14, align 1, !tbaa !2432
  %1209 = and i32 %1203, 255
  %1210 = tail call i32 @llvm.ctpop.i32(i32 %1209) #11
  %1211 = trunc i32 %1210 to i8
  %1212 = and i8 %1211, 1
  %1213 = xor i8 %1212, 1
  store i8 %1213, i8* %21, align 1, !tbaa !2446
  %1214 = xor i32 %1203, %1202
  %1215 = lshr i32 %1214, 4
  %1216 = trunc i32 %1215 to i8
  %1217 = and i8 %1216, 1
  store i8 %1217, i8* %27, align 1, !tbaa !2447
  %1218 = zext i1 %1206 to i8
  store i8 %1218, i8* %30, align 1, !tbaa !2448
  %1219 = lshr i32 %1203, 31
  %1220 = trunc i32 %1219 to i8
  store i8 %1220, i8* %33, align 1, !tbaa !2449
  %1221 = lshr i32 %1202, 31
  %1222 = xor i32 %1219, %1221
  %1223 = add nuw nsw i32 %1222, %1219
  %1224 = icmp eq i32 %1223, 2
  %1225 = zext i1 %1224 to i8
  store i8 %1225, i8* %39, align 1, !tbaa !2450
  %1226 = sext i32 %1203 to i64
  store i64 %1226, i64* %RDX, align 8, !tbaa !2428
  %1227 = shl nsw i64 %1226, 3
  %1228 = add i64 %1227, %1198
  %1229 = add i64 %1160, 36
  store i64 %1229, i64* %PC, align 8
  %1230 = bitcast i64 %1196 to double
  %1231 = inttoptr i64 %1228 to double*
  %1232 = load double, double* %1231, align 8
  %1233 = fsub double %1230, %1232
  store double %1233, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %1234 = load i64, i64* %RBP, align 8
  %1235 = add i64 %1234, -112
  %1236 = add i64 %1160, 41
  store i64 %1236, i64* %PC, align 8
  %1237 = inttoptr i64 %1235 to double*
  store double %1233, double* %1237, align 8
  %1238 = load i64, i64* %RBP, align 8
  %1239 = add i64 %1238, -56
  %1240 = load i64, i64* %PC, align 8
  %1241 = add i64 %1240, 5
  store i64 %1241, i64* %PC, align 8
  %1242 = inttoptr i64 %1239 to i64*
  %1243 = load i64, i64* %1242, align 8
  store i64 %1243, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %1244 = add i64 %1238, -88
  %1245 = add i64 %1240, 10
  store i64 %1245, i64* %PC, align 8
  %1246 = bitcast i64 %1243 to double
  %1247 = inttoptr i64 %1244 to double*
  %1248 = load double, double* %1247, align 8
  %1249 = fadd double %1246, %1248
  store double %1249, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %1250 = add i64 %1238, -16
  %1251 = add i64 %1240, 14
  store i64 %1251, i64* %PC, align 8
  %1252 = inttoptr i64 %1250 to i64*
  %1253 = load i64, i64* %1252, align 8
  store i64 %1253, i64* %RCX, align 8, !tbaa !2428
  %1254 = add i64 %1238, -28
  %1255 = add i64 %1240, 18
  store i64 %1255, i64* %PC, align 8
  %1256 = inttoptr i64 %1254 to i32*
  %1257 = load i32, i32* %1256, align 4
  %1258 = sext i32 %1257 to i64
  store i64 %1258, i64* %RDX, align 8, !tbaa !2428
  %1259 = shl nsw i64 %1258, 3
  %1260 = add i64 %1259, %1253
  %1261 = add i64 %1240, 23
  store i64 %1261, i64* %PC, align 8
  %1262 = inttoptr i64 %1260 to double*
  store double %1249, double* %1262, align 8
  %1263 = load i64, i64* %RBP, align 8
  %1264 = add i64 %1263, -64
  %1265 = load i64, i64* %PC, align 8
  %1266 = add i64 %1265, 5
  store i64 %1266, i64* %PC, align 8
  %1267 = inttoptr i64 %1264 to i64*
  %1268 = load i64, i64* %1267, align 8
  store i64 %1268, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %1269 = add i64 %1263, -96
  %1270 = add i64 %1265, 10
  store i64 %1270, i64* %PC, align 8
  %1271 = bitcast i64 %1268 to double
  %1272 = inttoptr i64 %1269 to double*
  %1273 = load double, double* %1272, align 8
  %1274 = fadd double %1271, %1273
  store double %1274, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %1275 = add i64 %1263, -16
  %1276 = add i64 %1265, 14
  store i64 %1276, i64* %PC, align 8
  %1277 = inttoptr i64 %1275 to i64*
  %1278 = load i64, i64* %1277, align 8
  store i64 %1278, i64* %RCX, align 8, !tbaa !2428
  %1279 = add i64 %1263, -28
  %1280 = add i64 %1265, 17
  store i64 %1280, i64* %PC, align 8
  %1281 = inttoptr i64 %1279 to i32*
  %1282 = load i32, i32* %1281, align 4
  %1283 = add i32 %1282, 1
  %1284 = zext i32 %1283 to i64
  store i64 %1284, i64* %RAX, align 8, !tbaa !2428
  %1285 = icmp eq i32 %1282, -1
  %1286 = icmp eq i32 %1283, 0
  %1287 = or i1 %1285, %1286
  %1288 = zext i1 %1287 to i8
  store i8 %1288, i8* %14, align 1, !tbaa !2432
  %1289 = and i32 %1283, 255
  %1290 = tail call i32 @llvm.ctpop.i32(i32 %1289) #11
  %1291 = trunc i32 %1290 to i8
  %1292 = and i8 %1291, 1
  %1293 = xor i8 %1292, 1
  store i8 %1293, i8* %21, align 1, !tbaa !2446
  %1294 = xor i32 %1283, %1282
  %1295 = lshr i32 %1294, 4
  %1296 = trunc i32 %1295 to i8
  %1297 = and i8 %1296, 1
  store i8 %1297, i8* %27, align 1, !tbaa !2447
  %1298 = zext i1 %1286 to i8
  store i8 %1298, i8* %30, align 1, !tbaa !2448
  %1299 = lshr i32 %1283, 31
  %1300 = trunc i32 %1299 to i8
  store i8 %1300, i8* %33, align 1, !tbaa !2449
  %1301 = lshr i32 %1282, 31
  %1302 = xor i32 %1299, %1301
  %1303 = add nuw nsw i32 %1302, %1299
  %1304 = icmp eq i32 %1303, 2
  %1305 = zext i1 %1304 to i8
  store i8 %1305, i8* %39, align 1, !tbaa !2450
  %1306 = sext i32 %1283 to i64
  store i64 %1306, i64* %RDX, align 8, !tbaa !2428
  %1307 = shl nsw i64 %1306, 3
  %1308 = add i64 %1307, %1278
  %1309 = add i64 %1265, 28
  store i64 %1309, i64* %PC, align 8
  %1310 = inttoptr i64 %1308 to double*
  store double %1274, double* %1310, align 8
  %1311 = load i64, i64* %RBP, align 8
  %1312 = add i64 %1311, -56
  %1313 = load i64, i64* %PC, align 8
  %1314 = add i64 %1313, 5
  store i64 %1314, i64* %PC, align 8
  %1315 = inttoptr i64 %1312 to i64*
  %1316 = load i64, i64* %1315, align 8
  store i64 %1316, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %1317 = add i64 %1311, -88
  %1318 = add i64 %1313, 10
  store i64 %1318, i64* %PC, align 8
  %1319 = bitcast i64 %1316 to double
  %1320 = inttoptr i64 %1317 to double*
  %1321 = load double, double* %1320, align 8
  %1322 = fsub double %1319, %1321
  store double %1322, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %1323 = add i64 %1311, -16
  %1324 = add i64 %1313, 14
  store i64 %1324, i64* %PC, align 8
  %1325 = inttoptr i64 %1323 to i64*
  %1326 = load i64, i64* %1325, align 8
  store i64 %1326, i64* %RCX, align 8, !tbaa !2428
  %1327 = add i64 %1311, -36
  %1328 = add i64 %1313, 18
  store i64 %1328, i64* %PC, align 8
  %1329 = inttoptr i64 %1327 to i32*
  %1330 = load i32, i32* %1329, align 4
  %1331 = sext i32 %1330 to i64
  store i64 %1331, i64* %RDX, align 8, !tbaa !2428
  %1332 = shl nsw i64 %1331, 3
  %1333 = add i64 %1332, %1326
  %1334 = add i64 %1313, 23
  store i64 %1334, i64* %PC, align 8
  %1335 = inttoptr i64 %1333 to double*
  store double %1322, double* %1335, align 8
  %1336 = load i64, i64* %RBP, align 8
  %1337 = add i64 %1336, -64
  %1338 = load i64, i64* %PC, align 8
  %1339 = add i64 %1338, 5
  store i64 %1339, i64* %PC, align 8
  %1340 = inttoptr i64 %1337 to i64*
  %1341 = load i64, i64* %1340, align 8
  store i64 %1341, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %1342 = add i64 %1336, -96
  %1343 = add i64 %1338, 10
  store i64 %1343, i64* %PC, align 8
  %1344 = bitcast i64 %1341 to double
  %1345 = inttoptr i64 %1342 to double*
  %1346 = load double, double* %1345, align 8
  %1347 = fsub double %1344, %1346
  store double %1347, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %1348 = add i64 %1336, -16
  %1349 = add i64 %1338, 14
  store i64 %1349, i64* %PC, align 8
  %1350 = inttoptr i64 %1348 to i64*
  %1351 = load i64, i64* %1350, align 8
  store i64 %1351, i64* %RCX, align 8, !tbaa !2428
  %1352 = add i64 %1336, -36
  %1353 = add i64 %1338, 17
  store i64 %1353, i64* %PC, align 8
  %1354 = inttoptr i64 %1352 to i32*
  %1355 = load i32, i32* %1354, align 4
  %1356 = add i32 %1355, 1
  %1357 = zext i32 %1356 to i64
  store i64 %1357, i64* %RAX, align 8, !tbaa !2428
  %1358 = icmp eq i32 %1355, -1
  %1359 = icmp eq i32 %1356, 0
  %1360 = or i1 %1358, %1359
  %1361 = zext i1 %1360 to i8
  store i8 %1361, i8* %14, align 1, !tbaa !2432
  %1362 = and i32 %1356, 255
  %1363 = tail call i32 @llvm.ctpop.i32(i32 %1362) #11
  %1364 = trunc i32 %1363 to i8
  %1365 = and i8 %1364, 1
  %1366 = xor i8 %1365, 1
  store i8 %1366, i8* %21, align 1, !tbaa !2446
  %1367 = xor i32 %1356, %1355
  %1368 = lshr i32 %1367, 4
  %1369 = trunc i32 %1368 to i8
  %1370 = and i8 %1369, 1
  store i8 %1370, i8* %27, align 1, !tbaa !2447
  %1371 = zext i1 %1359 to i8
  store i8 %1371, i8* %30, align 1, !tbaa !2448
  %1372 = lshr i32 %1356, 31
  %1373 = trunc i32 %1372 to i8
  store i8 %1373, i8* %33, align 1, !tbaa !2449
  %1374 = lshr i32 %1355, 31
  %1375 = xor i32 %1372, %1374
  %1376 = add nuw nsw i32 %1375, %1372
  %1377 = icmp eq i32 %1376, 2
  %1378 = zext i1 %1377 to i8
  store i8 %1378, i8* %39, align 1, !tbaa !2450
  %1379 = sext i32 %1356 to i64
  store i64 %1379, i64* %RDX, align 8, !tbaa !2428
  %1380 = shl nsw i64 %1379, 3
  %1381 = add i64 %1380, %1351
  %1382 = add i64 %1338, 28
  store i64 %1382, i64* %PC, align 8
  %1383 = inttoptr i64 %1381 to double*
  store double %1347, double* %1383, align 8
  %1384 = load i64, i64* %RBP, align 8
  %1385 = add i64 %1384, -72
  %1386 = load i64, i64* %PC, align 8
  %1387 = add i64 %1386, 5
  store i64 %1387, i64* %PC, align 8
  %1388 = inttoptr i64 %1385 to i64*
  %1389 = load i64, i64* %1388, align 8
  store i64 %1389, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %1390 = add i64 %1384, -112
  %1391 = add i64 %1386, 10
  store i64 %1391, i64* %PC, align 8
  %1392 = bitcast i64 %1389 to double
  %1393 = inttoptr i64 %1390 to double*
  %1394 = load double, double* %1393, align 8
  %1395 = fsub double %1392, %1394
  store double %1395, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %1396 = add i64 %1384, -16
  %1397 = add i64 %1386, 14
  store i64 %1397, i64* %PC, align 8
  %1398 = inttoptr i64 %1396 to i64*
  %1399 = load i64, i64* %1398, align 8
  store i64 %1399, i64* %RCX, align 8, !tbaa !2428
  %1400 = add i64 %1384, -32
  %1401 = add i64 %1386, 18
  store i64 %1401, i64* %PC, align 8
  %1402 = inttoptr i64 %1400 to i32*
  %1403 = load i32, i32* %1402, align 4
  %1404 = sext i32 %1403 to i64
  store i64 %1404, i64* %RDX, align 8, !tbaa !2428
  %1405 = shl nsw i64 %1404, 3
  %1406 = add i64 %1405, %1399
  %1407 = add i64 %1386, 23
  store i64 %1407, i64* %PC, align 8
  %1408 = inttoptr i64 %1406 to double*
  store double %1395, double* %1408, align 8
  %1409 = load i64, i64* %RBP, align 8
  %1410 = add i64 %1409, -80
  %1411 = load i64, i64* %PC, align 8
  %1412 = add i64 %1411, 5
  store i64 %1412, i64* %PC, align 8
  %1413 = inttoptr i64 %1410 to i64*
  %1414 = load i64, i64* %1413, align 8
  store i64 %1414, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %1415 = add i64 %1409, -104
  %1416 = add i64 %1411, 10
  store i64 %1416, i64* %PC, align 8
  %1417 = bitcast i64 %1414 to double
  %1418 = inttoptr i64 %1415 to double*
  %1419 = load double, double* %1418, align 8
  %1420 = fadd double %1417, %1419
  store double %1420, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %1421 = add i64 %1409, -16
  %1422 = add i64 %1411, 14
  store i64 %1422, i64* %PC, align 8
  %1423 = inttoptr i64 %1421 to i64*
  %1424 = load i64, i64* %1423, align 8
  store i64 %1424, i64* %RCX, align 8, !tbaa !2428
  %1425 = add i64 %1409, -32
  %1426 = add i64 %1411, 17
  store i64 %1426, i64* %PC, align 8
  %1427 = inttoptr i64 %1425 to i32*
  %1428 = load i32, i32* %1427, align 4
  %1429 = add i32 %1428, 1
  %1430 = zext i32 %1429 to i64
  store i64 %1430, i64* %RAX, align 8, !tbaa !2428
  %1431 = icmp eq i32 %1428, -1
  %1432 = icmp eq i32 %1429, 0
  %1433 = or i1 %1431, %1432
  %1434 = zext i1 %1433 to i8
  store i8 %1434, i8* %14, align 1, !tbaa !2432
  %1435 = and i32 %1429, 255
  %1436 = tail call i32 @llvm.ctpop.i32(i32 %1435) #11
  %1437 = trunc i32 %1436 to i8
  %1438 = and i8 %1437, 1
  %1439 = xor i8 %1438, 1
  store i8 %1439, i8* %21, align 1, !tbaa !2446
  %1440 = xor i32 %1429, %1428
  %1441 = lshr i32 %1440, 4
  %1442 = trunc i32 %1441 to i8
  %1443 = and i8 %1442, 1
  store i8 %1443, i8* %27, align 1, !tbaa !2447
  %1444 = zext i1 %1432 to i8
  store i8 %1444, i8* %30, align 1, !tbaa !2448
  %1445 = lshr i32 %1429, 31
  %1446 = trunc i32 %1445 to i8
  store i8 %1446, i8* %33, align 1, !tbaa !2449
  %1447 = lshr i32 %1428, 31
  %1448 = xor i32 %1445, %1447
  %1449 = add nuw nsw i32 %1448, %1445
  %1450 = icmp eq i32 %1449, 2
  %1451 = zext i1 %1450 to i8
  store i8 %1451, i8* %39, align 1, !tbaa !2450
  %1452 = sext i32 %1429 to i64
  store i64 %1452, i64* %RDX, align 8, !tbaa !2428
  %1453 = shl nsw i64 %1452, 3
  %1454 = add i64 %1453, %1424
  %1455 = add i64 %1411, 28
  store i64 %1455, i64* %PC, align 8
  %1456 = inttoptr i64 %1454 to double*
  store double %1420, double* %1456, align 8
  %1457 = load i64, i64* %RBP, align 8
  %1458 = add i64 %1457, -72
  %1459 = load i64, i64* %PC, align 8
  %1460 = add i64 %1459, 5
  store i64 %1460, i64* %PC, align 8
  %1461 = inttoptr i64 %1458 to i64*
  %1462 = load i64, i64* %1461, align 8
  store i64 %1462, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %1463 = add i64 %1457, -112
  %1464 = add i64 %1459, 10
  store i64 %1464, i64* %PC, align 8
  %1465 = bitcast i64 %1462 to double
  %1466 = inttoptr i64 %1463 to double*
  %1467 = load double, double* %1466, align 8
  %1468 = fadd double %1465, %1467
  store double %1468, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %1469 = add i64 %1457, -16
  %1470 = add i64 %1459, 14
  store i64 %1470, i64* %PC, align 8
  %1471 = inttoptr i64 %1469 to i64*
  %1472 = load i64, i64* %1471, align 8
  store i64 %1472, i64* %RCX, align 8, !tbaa !2428
  %1473 = add i64 %1457, -40
  %1474 = add i64 %1459, 18
  store i64 %1474, i64* %PC, align 8
  %1475 = inttoptr i64 %1473 to i32*
  %1476 = load i32, i32* %1475, align 4
  %1477 = sext i32 %1476 to i64
  store i64 %1477, i64* %RDX, align 8, !tbaa !2428
  %1478 = shl nsw i64 %1477, 3
  %1479 = add i64 %1478, %1472
  %1480 = add i64 %1459, 23
  store i64 %1480, i64* %PC, align 8
  %1481 = inttoptr i64 %1479 to double*
  store double %1468, double* %1481, align 8
  %1482 = load i64, i64* %RBP, align 8
  %1483 = add i64 %1482, -80
  %1484 = load i64, i64* %PC, align 8
  %1485 = add i64 %1484, 5
  store i64 %1485, i64* %PC, align 8
  %1486 = inttoptr i64 %1483 to i64*
  %1487 = load i64, i64* %1486, align 8
  store i64 %1487, i64* %1615, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1617, align 1, !tbaa !2451
  %1488 = add i64 %1482, -104
  %1489 = add i64 %1484, 10
  store i64 %1489, i64* %PC, align 8
  %1490 = bitcast i64 %1487 to double
  %1491 = inttoptr i64 %1488 to double*
  %1492 = load double, double* %1491, align 8
  %1493 = fsub double %1490, %1492
  store double %1493, double* %1614, align 1, !tbaa !2451
  store i64 0, i64* %1616, align 1, !tbaa !2451
  %1494 = add i64 %1482, -16
  %1495 = add i64 %1484, 14
  store i64 %1495, i64* %PC, align 8
  %1496 = inttoptr i64 %1494 to i64*
  %1497 = load i64, i64* %1496, align 8
  store i64 %1497, i64* %RCX, align 8, !tbaa !2428
  %1498 = add i64 %1482, -40
  %1499 = add i64 %1484, 17
  store i64 %1499, i64* %PC, align 8
  %1500 = inttoptr i64 %1498 to i32*
  %1501 = load i32, i32* %1500, align 4
  %1502 = add i32 %1501, 1
  %1503 = zext i32 %1502 to i64
  store i64 %1503, i64* %RAX, align 8, !tbaa !2428
  %1504 = icmp eq i32 %1501, -1
  %1505 = icmp eq i32 %1502, 0
  %1506 = or i1 %1504, %1505
  %1507 = zext i1 %1506 to i8
  store i8 %1507, i8* %14, align 1, !tbaa !2432
  %1508 = and i32 %1502, 255
  %1509 = tail call i32 @llvm.ctpop.i32(i32 %1508) #11
  %1510 = trunc i32 %1509 to i8
  %1511 = and i8 %1510, 1
  %1512 = xor i8 %1511, 1
  store i8 %1512, i8* %21, align 1, !tbaa !2446
  %1513 = xor i32 %1502, %1501
  %1514 = lshr i32 %1513, 4
  %1515 = trunc i32 %1514 to i8
  %1516 = and i8 %1515, 1
  store i8 %1516, i8* %27, align 1, !tbaa !2447
  %1517 = zext i1 %1505 to i8
  store i8 %1517, i8* %30, align 1, !tbaa !2448
  %1518 = lshr i32 %1502, 31
  %1519 = trunc i32 %1518 to i8
  store i8 %1519, i8* %33, align 1, !tbaa !2449
  %1520 = lshr i32 %1501, 31
  %1521 = xor i32 %1518, %1520
  %1522 = add nuw nsw i32 %1521, %1518
  %1523 = icmp eq i32 %1522, 2
  %1524 = zext i1 %1523 to i8
  store i8 %1524, i8* %39, align 1, !tbaa !2450
  %1525 = sext i32 %1502 to i64
  store i64 %1525, i64* %RDX, align 8, !tbaa !2428
  %1526 = shl nsw i64 %1525, 3
  %1527 = add i64 %1526, %1497
  %1528 = add i64 %1484, 28
  store i64 %1528, i64* %PC, align 8
  %1529 = inttoptr i64 %1527 to double*
  store double %1493, double* %1529, align 8
  %1530 = load i64, i64* %RBP, align 8
  %1531 = add i64 %1530, -28
  %1532 = load i64, i64* %PC, align 8
  %1533 = add i64 %1532, 3
  store i64 %1533, i64* %PC, align 8
  %1534 = inttoptr i64 %1531 to i32*
  %1535 = load i32, i32* %1534, align 4
  %1536 = add i32 %1535, 2
  %1537 = zext i32 %1536 to i64
  store i64 %1537, i64* %RAX, align 8, !tbaa !2428
  %1538 = icmp ugt i32 %1535, -3
  %1539 = zext i1 %1538 to i8
  store i8 %1539, i8* %14, align 1, !tbaa !2432
  %1540 = and i32 %1536, 255
  %1541 = tail call i32 @llvm.ctpop.i32(i32 %1540) #11
  %1542 = trunc i32 %1541 to i8
  %1543 = and i8 %1542, 1
  %1544 = xor i8 %1543, 1
  store i8 %1544, i8* %21, align 1, !tbaa !2446
  %1545 = xor i32 %1536, %1535
  %1546 = lshr i32 %1545, 4
  %1547 = trunc i32 %1546 to i8
  %1548 = and i8 %1547, 1
  store i8 %1548, i8* %27, align 1, !tbaa !2447
  %1549 = icmp eq i32 %1536, 0
  %1550 = zext i1 %1549 to i8
  store i8 %1550, i8* %30, align 1, !tbaa !2448
  %1551 = lshr i32 %1536, 31
  %1552 = trunc i32 %1551 to i8
  store i8 %1552, i8* %33, align 1, !tbaa !2449
  %1553 = lshr i32 %1535, 31
  %1554 = xor i32 %1551, %1553
  %1555 = add nuw nsw i32 %1554, %1551
  %1556 = icmp eq i32 %1555, 2
  %1557 = zext i1 %1556 to i8
  store i8 %1557, i8* %39, align 1, !tbaa !2450
  %1558 = add i64 %1532, 9
  store i64 %1558, i64* %PC, align 8
  store i32 %1536, i32* %1534, align 4
  %1559 = load i64, i64* %PC, align 8
  %1560 = add i64 %1559, -540
  store i64 %1560, i64* %PC, align 8, !tbaa !2428
  br label %block_4018f6

block_4018e0:                                     ; preds = %block_4018db, %block_401870
  %1561 = phi i64 [ %91, %block_401870 ], [ %92, %block_4018db ]
  %1562 = phi i64 [ %61, %block_401870 ], [ %508, %block_4018db ]
  %MEMORY.4 = phi %struct.Memory* [ %2, %block_401870 ], [ %109, %block_4018db ]
  %1563 = add i64 %1562, -44
  %1564 = add i64 %1561, 3
  store i64 %1564, i64* %PC, align 8
  %1565 = inttoptr i64 %1563 to i32*
  %1566 = load i32, i32* %1565, align 4
  %1567 = shl i32 %1566, 2
  %1568 = zext i32 %1567 to i64
  store i64 %1568, i64* %RAX, align 8, !tbaa !2428
  %1569 = lshr i32 %1566, 30
  %1570 = trunc i32 %1569 to i8
  %1571 = and i8 %1570, 1
  store i8 %1571, i8* %14, align 1, !tbaa !2453
  %1572 = and i32 %1567, 252
  %1573 = tail call i32 @llvm.ctpop.i32(i32 %1572) #11
  %1574 = trunc i32 %1573 to i8
  %1575 = and i8 %1574, 1
  %1576 = xor i8 %1575, 1
  store i8 %1576, i8* %21, align 1, !tbaa !2453
  store i8 0, i8* %27, align 1, !tbaa !2453
  %1577 = icmp eq i32 %1567, 0
  %1578 = zext i1 %1577 to i8
  store i8 %1578, i8* %30, align 1, !tbaa !2453
  %1579 = lshr i32 %1566, 29
  %1580 = trunc i32 %1579 to i8
  %1581 = and i8 %1580, 1
  store i8 %1581, i8* %33, align 1, !tbaa !2453
  store i8 0, i8* %39, align 1, !tbaa !2453
  %1582 = add i64 %1562, -4
  %1583 = add i64 %1561, 9
  store i64 %1583, i64* %PC, align 8
  %1584 = inttoptr i64 %1582 to i32*
  %1585 = load i32, i32* %1584, align 4
  %1586 = sub i32 %1567, %1585
  %1587 = icmp ult i32 %1567, %1585
  %1588 = zext i1 %1587 to i8
  store i8 %1588, i8* %14, align 1, !tbaa !2432
  %1589 = and i32 %1586, 255
  %1590 = tail call i32 @llvm.ctpop.i32(i32 %1589) #11
  %1591 = trunc i32 %1590 to i8
  %1592 = and i8 %1591, 1
  %1593 = xor i8 %1592, 1
  store i8 %1593, i8* %21, align 1, !tbaa !2446
  %1594 = xor i32 %1585, %1567
  %1595 = xor i32 %1594, %1586
  %1596 = lshr i32 %1595, 4
  %1597 = trunc i32 %1596 to i8
  %1598 = and i8 %1597, 1
  store i8 %1598, i8* %27, align 1, !tbaa !2447
  %1599 = icmp eq i32 %1586, 0
  %1600 = zext i1 %1599 to i8
  store i8 %1600, i8* %30, align 1, !tbaa !2448
  %1601 = lshr i32 %1586, 31
  %1602 = trunc i32 %1601 to i8
  store i8 %1602, i8* %33, align 1, !tbaa !2449
  %1603 = and i32 %1579, 1
  %1604 = lshr i32 %1585, 31
  %1605 = xor i32 %1604, %1603
  %1606 = xor i32 %1601, %1603
  %1607 = add nuw nsw i32 %1606, %1605
  %1608 = icmp eq i32 %1607, 2
  %1609 = zext i1 %1608 to i8
  store i8 %1609, i8* %39, align 1, !tbaa !2450
  %.v = select i1 %1599, i64 15, i64 572
  %1610 = add i64 %1562, -28
  %1611 = add i64 %1561, 7
  %1612 = add i64 %1611, %.v
  store i64 %1612, i64* %PC, align 8
  %1613 = inttoptr i64 %1610 to i32*
  store i32 0, i32* %1613, align 4
  %1614 = bitcast %union.VectorReg* %4 to double*
  %1615 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %4, i64 0, i32 0, i32 0, i32 0, i64 0
  %1616 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %1617 = bitcast i64* %1616 to double*
  %.pre12 = load i64, i64* %PC, align 8
  br i1 %1599, label %block_4018f6.preheader, label %block_401b23.preheader

block_401b23.preheader:                           ; preds = %block_4018e0
  br label %block_401b23

block_4018f6.preheader:                           ; preds = %block_4018e0
  br label %block_4018f6
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_403330_cftmdl(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_403330:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %4 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %6 = load i64, i64* %RBP, align 8
  %7 = add i64 %1, 1
  store i64 %7, i64* %PC, align 8
  %8 = load i64, i64* %RSP, align 8, !tbaa !2428
  %9 = add i64 %8, -8
  %10 = inttoptr i64 %9 to i64*
  store i64 %6, i64* %10, align 8
  %11 = load i64, i64* %PC, align 8
  store i64 %9, i64* %RBP, align 8, !tbaa !2428
  %12 = add i64 %8, -56
  store i64 %12, i64* %RSP, align 8, !tbaa !2428
  %13 = icmp ult i64 %9, 48
  %14 = zext i1 %13 to i8
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %14, i8* %15, align 1, !tbaa !2432
  %16 = trunc i64 %12 to i32
  %17 = and i32 %16, 255
  %18 = tail call i32 @llvm.ctpop.i32(i32 %17) #11
  %19 = trunc i32 %18 to i8
  %20 = and i8 %19, 1
  %21 = xor i8 %20, 1
  %22 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %21, i8* %22, align 1, !tbaa !2446
  %23 = xor i64 %9, 16
  %24 = xor i64 %23, %12
  %25 = lshr i64 %24, 4
  %26 = trunc i64 %25 to i8
  %27 = and i8 %26, 1
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %27, i8* %28, align 1, !tbaa !2447
  %29 = icmp eq i64 %12, 0
  %30 = zext i1 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %30, i8* %31, align 1, !tbaa !2448
  %32 = lshr i64 %12, 63
  %33 = trunc i64 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %33, i8* %34, align 1, !tbaa !2449
  %35 = lshr i64 %9, 63
  %36 = xor i64 %32, %35
  %37 = add nuw nsw i64 %36, %35
  %38 = icmp eq i64 %37, 2
  %39 = zext i1 %38 to i8
  %40 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %39, i8* %40, align 1, !tbaa !2450
  %41 = add i64 %8, -12
  %42 = load i32, i32* %EDI, align 4
  %43 = add i64 %11, 10
  store i64 %43, i64* %PC, align 8
  %44 = inttoptr i64 %41 to i32*
  store i32 %42, i32* %44, align 4
  %45 = load i64, i64* %RBP, align 8
  %46 = add i64 %45, -8
  %47 = load i32, i32* %ESI, align 4
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 3
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %46 to i32*
  store i32 %47, i32* %50, align 4
  %51 = load i64, i64* %RBP, align 8
  %52 = add i64 %51, -16
  %53 = load i64, i64* %RDX, align 8
  %54 = load i64, i64* %PC, align 8
  %55 = add i64 %54, 4
  store i64 %55, i64* %PC, align 8
  %56 = inttoptr i64 %52 to i64*
  store i64 %53, i64* %56, align 8
  %57 = load i64, i64* %RBP, align 8
  %58 = add i64 %57, -24
  %59 = load i64, i64* %RCX, align 8
  %60 = load i64, i64* %PC, align 8
  %61 = add i64 %60, 4
  store i64 %61, i64* %PC, align 8
  %62 = inttoptr i64 %58 to i64*
  store i64 %59, i64* %62, align 8
  %63 = load i64, i64* %RBP, align 8
  %64 = add i64 %63, -8
  %65 = load i64, i64* %PC, align 8
  %66 = add i64 %65, 3
  store i64 %66, i64* %PC, align 8
  %67 = inttoptr i64 %64 to i32*
  %68 = load i32, i32* %67, align 4
  %69 = shl i32 %68, 2
  %70 = zext i32 %69 to i64
  store i64 %70, i64* %RSI, align 8, !tbaa !2428
  %71 = lshr i32 %68, 30
  %72 = trunc i32 %71 to i8
  %73 = and i8 %72, 1
  store i8 %73, i8* %15, align 1, !tbaa !2453
  %74 = and i32 %69, 252
  %75 = tail call i32 @llvm.ctpop.i32(i32 %74) #11
  %76 = trunc i32 %75 to i8
  %77 = and i8 %76, 1
  %78 = xor i8 %77, 1
  store i8 %78, i8* %22, align 1, !tbaa !2453
  store i8 0, i8* %28, align 1, !tbaa !2453
  %79 = icmp eq i32 %69, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %31, align 1, !tbaa !2453
  %81 = lshr i32 %68, 29
  %82 = trunc i32 %81 to i8
  %83 = and i8 %82, 1
  store i8 %83, i8* %34, align 1, !tbaa !2453
  store i8 0, i8* %40, align 1, !tbaa !2453
  %84 = add i64 %63, -56
  %85 = add i64 %65, 9
  store i64 %85, i64* %PC, align 8
  %86 = inttoptr i64 %84 to i32*
  store i32 %69, i32* %86, align 4
  %87 = load i64, i64* %RBP, align 8
  %88 = add i64 %87, -28
  %89 = load i64, i64* %PC, align 8
  %90 = add i64 %89, 7
  store i64 %90, i64* %PC, align 8
  %91 = inttoptr i64 %88 to i32*
  store i32 0, i32* %91, align 4
  %92 = bitcast [32 x %union.VectorReg]* %5 to double*
  %93 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %5, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %94 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %95 = bitcast i64* %94 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_403356

block_40389f:                                     ; preds = %block_403893
  %96 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 80) to i64*), align 16
  store i64 %96, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %97 = add i64 %3673, -48
  %98 = add i64 %3709, 11
  store i64 %98, i64* %PC, align 8
  %99 = inttoptr i64 %97 to i32*
  %100 = load i32, i32* %99, align 4
  %101 = add i32 %100, 2
  %102 = zext i32 %101 to i64
  store i64 %102, i64* %RAX, align 8, !tbaa !2428
  %103 = icmp ugt i32 %100, -3
  %104 = zext i1 %103 to i8
  store i8 %104, i8* %15, align 1, !tbaa !2432
  %105 = and i32 %101, 255
  %106 = tail call i32 @llvm.ctpop.i32(i32 %105) #11
  %107 = trunc i32 %106 to i8
  %108 = and i8 %107, 1
  %109 = xor i8 %108, 1
  store i8 %109, i8* %22, align 1, !tbaa !2446
  %110 = xor i32 %101, %100
  %111 = lshr i32 %110, 4
  %112 = trunc i32 %111 to i8
  %113 = and i8 %112, 1
  store i8 %113, i8* %28, align 1, !tbaa !2447
  %114 = icmp eq i32 %101, 0
  %115 = zext i1 %114 to i8
  store i8 %115, i8* %31, align 1, !tbaa !2448
  %116 = lshr i32 %101, 31
  %117 = trunc i32 %116 to i8
  store i8 %117, i8* %34, align 1, !tbaa !2449
  %118 = lshr i32 %100, 31
  %119 = xor i32 %116, %118
  %120 = add nuw nsw i32 %119, %116
  %121 = icmp eq i32 %120, 2
  %122 = zext i1 %121 to i8
  store i8 %122, i8* %40, align 1, !tbaa !2450
  %123 = add i64 %3709, 17
  store i64 %123, i64* %PC, align 8
  store i32 %101, i32* %99, align 4
  %124 = load i64, i64* %RBP, align 8
  %125 = add i64 %124, -48
  %126 = load i64, i64* %PC, align 8
  %127 = add i64 %126, 3
  store i64 %127, i64* %PC, align 8
  %128 = inttoptr i64 %125 to i32*
  %129 = load i32, i32* %128, align 4
  %130 = shl i32 %129, 1
  %131 = icmp slt i32 %129, 0
  %132 = icmp slt i32 %130, 0
  %133 = xor i1 %131, %132
  %134 = zext i32 %130 to i64
  store i64 %134, i64* %RAX, align 8, !tbaa !2428
  %.lobit5 = lshr i32 %129, 31
  %135 = trunc i32 %.lobit5 to i8
  store i8 %135, i8* %15, align 1, !tbaa !2453
  %136 = and i32 %130, 254
  %137 = tail call i32 @llvm.ctpop.i32(i32 %136) #11
  %138 = trunc i32 %137 to i8
  %139 = and i8 %138, 1
  %140 = xor i8 %139, 1
  store i8 %140, i8* %22, align 1, !tbaa !2453
  store i8 0, i8* %28, align 1, !tbaa !2453
  %141 = icmp eq i32 %130, 0
  %142 = zext i1 %141 to i8
  store i8 %142, i8* %31, align 1, !tbaa !2453
  %143 = lshr i32 %129, 30
  %144 = trunc i32 %143 to i8
  %145 = and i8 %144, 1
  store i8 %145, i8* %34, align 1, !tbaa !2453
  %146 = zext i1 %133 to i8
  store i8 %146, i8* %40, align 1, !tbaa !2453
  %147 = add i64 %124, -52
  %148 = add i64 %126, 9
  store i64 %148, i64* %PC, align 8
  %149 = inttoptr i64 %147 to i32*
  store i32 %130, i32* %149, align 4
  %150 = load i64, i64* %RBP, align 8
  %151 = add i64 %150, -24
  %152 = load i64, i64* %PC, align 8
  %153 = add i64 %152, 4
  store i64 %153, i64* %PC, align 8
  %154 = inttoptr i64 %151 to i64*
  %155 = load i64, i64* %154, align 8
  store i64 %155, i64* %RCX, align 8, !tbaa !2428
  %156 = add i64 %150, -48
  %157 = add i64 %152, 8
  store i64 %157, i64* %PC, align 8
  %158 = inttoptr i64 %156 to i32*
  %159 = load i32, i32* %158, align 4
  %160 = sext i32 %159 to i64
  store i64 %160, i64* %RDX, align 8, !tbaa !2428
  %161 = shl nsw i64 %160, 3
  %162 = add i64 %161, %155
  %163 = add i64 %152, 13
  store i64 %163, i64* %PC, align 8
  %164 = inttoptr i64 %162 to i64*
  %165 = load i64, i64* %164, align 8
  store i64 %165, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %166 = add i64 %150, -88
  %167 = add i64 %152, 18
  store i64 %167, i64* %PC, align 8
  %168 = inttoptr i64 %166 to i64*
  store i64 %165, i64* %168, align 8
  %169 = load i64, i64* %RBP, align 8
  %170 = add i64 %169, -24
  %171 = load i64, i64* %PC, align 8
  %172 = add i64 %171, 4
  store i64 %172, i64* %PC, align 8
  %173 = inttoptr i64 %170 to i64*
  %174 = load i64, i64* %173, align 8
  store i64 %174, i64* %RCX, align 8, !tbaa !2428
  %175 = add i64 %169, -48
  %176 = add i64 %171, 7
  store i64 %176, i64* %PC, align 8
  %177 = inttoptr i64 %175 to i32*
  %178 = load i32, i32* %177, align 4
  %179 = add i32 %178, 1
  %180 = zext i32 %179 to i64
  store i64 %180, i64* %RAX, align 8, !tbaa !2428
  %181 = icmp eq i32 %178, -1
  %182 = icmp eq i32 %179, 0
  %183 = or i1 %181, %182
  %184 = zext i1 %183 to i8
  store i8 %184, i8* %15, align 1, !tbaa !2432
  %185 = and i32 %179, 255
  %186 = tail call i32 @llvm.ctpop.i32(i32 %185) #11
  %187 = trunc i32 %186 to i8
  %188 = and i8 %187, 1
  %189 = xor i8 %188, 1
  store i8 %189, i8* %22, align 1, !tbaa !2446
  %190 = xor i32 %179, %178
  %191 = lshr i32 %190, 4
  %192 = trunc i32 %191 to i8
  %193 = and i8 %192, 1
  store i8 %193, i8* %28, align 1, !tbaa !2447
  %194 = zext i1 %182 to i8
  store i8 %194, i8* %31, align 1, !tbaa !2448
  %195 = lshr i32 %179, 31
  %196 = trunc i32 %195 to i8
  store i8 %196, i8* %34, align 1, !tbaa !2449
  %197 = lshr i32 %178, 31
  %198 = xor i32 %195, %197
  %199 = add nuw nsw i32 %198, %195
  %200 = icmp eq i32 %199, 2
  %201 = zext i1 %200 to i8
  store i8 %201, i8* %40, align 1, !tbaa !2450
  %202 = sext i32 %179 to i64
  store i64 %202, i64* %RDX, align 8, !tbaa !2428
  %203 = shl nsw i64 %202, 3
  %204 = add i64 %203, %174
  %205 = add i64 %171, 18
  store i64 %205, i64* %PC, align 8
  %206 = inttoptr i64 %204 to i64*
  %207 = load i64, i64* %206, align 8
  store i64 %207, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %208 = add i64 %169, -96
  %209 = add i64 %171, 23
  store i64 %209, i64* %PC, align 8
  %210 = inttoptr i64 %208 to i64*
  store i64 %207, i64* %210, align 8
  %211 = load i64, i64* %RBP, align 8
  %212 = add i64 %211, -24
  %213 = load i64, i64* %PC, align 8
  %214 = add i64 %213, 4
  store i64 %214, i64* %PC, align 8
  %215 = inttoptr i64 %212 to i64*
  %216 = load i64, i64* %215, align 8
  store i64 %216, i64* %RCX, align 8, !tbaa !2428
  %217 = add i64 %211, -52
  %218 = add i64 %213, 8
  store i64 %218, i64* %PC, align 8
  %219 = inttoptr i64 %217 to i32*
  %220 = load i32, i32* %219, align 4
  %221 = sext i32 %220 to i64
  store i64 %221, i64* %RDX, align 8, !tbaa !2428
  %222 = shl nsw i64 %221, 3
  %223 = add i64 %222, %216
  %224 = add i64 %213, 13
  store i64 %224, i64* %PC, align 8
  %225 = inttoptr i64 %223 to i64*
  %226 = load i64, i64* %225, align 8
  store i64 %226, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %227 = add i64 %211, -72
  %228 = add i64 %213, 18
  store i64 %228, i64* %PC, align 8
  %229 = inttoptr i64 %227 to i64*
  store i64 %226, i64* %229, align 8
  %230 = load i64, i64* %RBP, align 8
  %231 = add i64 %230, -24
  %232 = load i64, i64* %PC, align 8
  %233 = add i64 %232, 4
  store i64 %233, i64* %PC, align 8
  %234 = inttoptr i64 %231 to i64*
  %235 = load i64, i64* %234, align 8
  store i64 %235, i64* %RCX, align 8, !tbaa !2428
  %236 = add i64 %230, -52
  %237 = add i64 %232, 7
  store i64 %237, i64* %PC, align 8
  %238 = inttoptr i64 %236 to i32*
  %239 = load i32, i32* %238, align 4
  %240 = add i32 %239, 1
  %241 = zext i32 %240 to i64
  store i64 %241, i64* %RAX, align 8, !tbaa !2428
  %242 = icmp eq i32 %239, -1
  %243 = icmp eq i32 %240, 0
  %244 = or i1 %242, %243
  %245 = zext i1 %244 to i8
  store i8 %245, i8* %15, align 1, !tbaa !2432
  %246 = and i32 %240, 255
  %247 = tail call i32 @llvm.ctpop.i32(i32 %246) #11
  %248 = trunc i32 %247 to i8
  %249 = and i8 %248, 1
  %250 = xor i8 %249, 1
  store i8 %250, i8* %22, align 1, !tbaa !2446
  %251 = xor i32 %240, %239
  %252 = lshr i32 %251, 4
  %253 = trunc i32 %252 to i8
  %254 = and i8 %253, 1
  store i8 %254, i8* %28, align 1, !tbaa !2447
  %255 = zext i1 %243 to i8
  store i8 %255, i8* %31, align 1, !tbaa !2448
  %256 = lshr i32 %240, 31
  %257 = trunc i32 %256 to i8
  store i8 %257, i8* %34, align 1, !tbaa !2449
  %258 = lshr i32 %239, 31
  %259 = xor i32 %256, %258
  %260 = add nuw nsw i32 %259, %256
  %261 = icmp eq i32 %260, 2
  %262 = zext i1 %261 to i8
  store i8 %262, i8* %40, align 1, !tbaa !2450
  %263 = sext i32 %240 to i64
  store i64 %263, i64* %RDX, align 8, !tbaa !2428
  %264 = shl nsw i64 %263, 3
  %265 = add i64 %264, %235
  %266 = add i64 %232, 18
  store i64 %266, i64* %PC, align 8
  %267 = inttoptr i64 %265 to i64*
  %268 = load i64, i64* %267, align 8
  store i64 %268, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %269 = add i64 %230, -80
  %270 = add i64 %232, 23
  store i64 %270, i64* %PC, align 8
  %271 = inttoptr i64 %269 to i64*
  store i64 %268, i64* %271, align 8
  %272 = load i64, i64* %RBP, align 8
  %273 = add i64 %272, -72
  %274 = load i64, i64* %PC, align 8
  %275 = add i64 %274, 5
  store i64 %275, i64* %PC, align 8
  %276 = inttoptr i64 %273 to i64*
  %277 = load i64, i64* %276, align 8
  store i64 %277, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %278 = load <2 x i32>, <2 x i32>* %1348, align 1
  %279 = load <2 x i32>, <2 x i32>* %1349, align 1
  %280 = extractelement <2 x i32> %278, i32 0
  store i32 %280, i32* %1350, align 1, !tbaa !2475
  %281 = extractelement <2 x i32> %278, i32 1
  store i32 %281, i32* %1352, align 1, !tbaa !2475
  %282 = extractelement <2 x i32> %279, i32 0
  store i32 %282, i32* %1354, align 1, !tbaa !2475
  %283 = extractelement <2 x i32> %279, i32 1
  store i32 %283, i32* %1356, align 1, !tbaa !2475
  %284 = add i64 %272, -96
  %285 = add i64 %274, 13
  store i64 %285, i64* %PC, align 8
  %286 = load double, double* %1357, align 1
  %287 = inttoptr i64 %284 to double*
  %288 = load double, double* %287, align 8
  %289 = fmul double %286, %288
  store double %289, double* %1357, align 1, !tbaa !2451
  %290 = add i64 %272, -80
  %291 = add i64 %274, 18
  store i64 %291, i64* %PC, align 8
  %292 = inttoptr i64 %290 to double*
  %293 = load double, double* %292, align 8
  %294 = fmul double %289, %293
  store double %294, double* %1357, align 1, !tbaa !2451
  %295 = bitcast i64 %277 to double
  %296 = fsub double %295, %294
  store double %296, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %297 = add i64 %272, -104
  %298 = add i64 %274, 27
  store i64 %298, i64* %PC, align 8
  %299 = inttoptr i64 %297 to double*
  store double %296, double* %299, align 8
  %300 = load i64, i64* %RBP, align 8
  %301 = add i64 %300, -96
  %302 = load i64, i64* %PC, align 8
  %303 = add i64 %302, 5
  store i64 %303, i64* %PC, align 8
  %304 = load double, double* %92, align 1
  %305 = inttoptr i64 %301 to double*
  %306 = load double, double* %305, align 8
  %307 = fmul double %304, %306
  store double %307, double* %92, align 1, !tbaa !2451
  %308 = add i64 %300, -72
  %309 = add i64 %302, 10
  store i64 %309, i64* %PC, align 8
  %310 = inttoptr i64 %308 to double*
  %311 = load double, double* %310, align 8
  %312 = fmul double %307, %311
  store double %312, double* %92, align 1, !tbaa !2451
  %313 = add i64 %300, -80
  %314 = add i64 %302, 15
  store i64 %314, i64* %PC, align 8
  %315 = inttoptr i64 %313 to double*
  %316 = load double, double* %315, align 8
  %317 = fsub double %312, %316
  store double %317, double* %92, align 1, !tbaa !2451
  %318 = add i64 %300, -112
  %319 = add i64 %302, 20
  store i64 %319, i64* %PC, align 8
  %320 = inttoptr i64 %318 to double*
  store double %317, double* %320, align 8
  %321 = load i64, i64* %RBP, align 8
  %322 = add i64 %321, -44
  %323 = load i64, i64* %PC, align 8
  %324 = add i64 %323, 3
  store i64 %324, i64* %PC, align 8
  %325 = inttoptr i64 %322 to i32*
  %326 = load i32, i32* %325, align 4
  %327 = zext i32 %326 to i64
  store i64 %327, i64* %RAX, align 8, !tbaa !2428
  %328 = add i64 %321, -28
  %329 = add i64 %323, 6
  store i64 %329, i64* %PC, align 8
  %330 = inttoptr i64 %328 to i32*
  store i32 %326, i32* %330, align 4
  %.pre25 = load i64, i64* %PC, align 8
  br label %block_403940

block_4035d2:                                     ; preds = %block_4035c1
  %331 = add i64 %4798, 3
  store i64 %331, i64* %PC, align 8
  %332 = load i32, i32* %4758, align 4
  %333 = zext i32 %332 to i64
  store i64 %333, i64* %RAX, align 8, !tbaa !2428
  %334 = add i64 %4798, 6
  store i64 %334, i64* %PC, align 8
  %335 = load i32, i32* %4763, align 4
  %336 = add i32 %335, %332
  %337 = zext i32 %336 to i64
  store i64 %337, i64* %RAX, align 8, !tbaa !2428
  %338 = icmp ult i32 %336, %332
  %339 = icmp ult i32 %336, %335
  %340 = or i1 %338, %339
  %341 = zext i1 %340 to i8
  store i8 %341, i8* %15, align 1, !tbaa !2432
  %342 = and i32 %336, 255
  %343 = tail call i32 @llvm.ctpop.i32(i32 %342) #11
  %344 = trunc i32 %343 to i8
  %345 = and i8 %344, 1
  %346 = xor i8 %345, 1
  store i8 %346, i8* %22, align 1, !tbaa !2446
  %347 = xor i32 %335, %332
  %348 = xor i32 %347, %336
  %349 = lshr i32 %348, 4
  %350 = trunc i32 %349 to i8
  %351 = and i8 %350, 1
  store i8 %351, i8* %28, align 1, !tbaa !2447
  %352 = icmp eq i32 %336, 0
  %353 = zext i1 %352 to i8
  store i8 %353, i8* %31, align 1, !tbaa !2448
  %354 = lshr i32 %336, 31
  %355 = trunc i32 %354 to i8
  store i8 %355, i8* %34, align 1, !tbaa !2449
  %356 = lshr i32 %332, 31
  %357 = lshr i32 %335, 31
  %358 = xor i32 %354, %356
  %359 = xor i32 %354, %357
  %360 = add nuw nsw i32 %358, %359
  %361 = icmp eq i32 %360, 2
  %362 = zext i1 %361 to i8
  store i8 %362, i8* %40, align 1, !tbaa !2450
  %363 = add i64 %4755, -32
  %364 = add i64 %4798, 9
  store i64 %364, i64* %PC, align 8
  %365 = inttoptr i64 %363 to i32*
  store i32 %336, i32* %365, align 4
  %366 = load i64, i64* %RBP, align 8
  %367 = add i64 %366, -32
  %368 = load i64, i64* %PC, align 8
  %369 = add i64 %368, 3
  store i64 %369, i64* %PC, align 8
  %370 = inttoptr i64 %367 to i32*
  %371 = load i32, i32* %370, align 4
  %372 = zext i32 %371 to i64
  store i64 %372, i64* %RAX, align 8, !tbaa !2428
  %373 = add i64 %366, -8
  %374 = add i64 %368, 6
  store i64 %374, i64* %PC, align 8
  %375 = inttoptr i64 %373 to i32*
  %376 = load i32, i32* %375, align 4
  %377 = add i32 %376, %371
  %378 = zext i32 %377 to i64
  store i64 %378, i64* %RAX, align 8, !tbaa !2428
  %379 = icmp ult i32 %377, %371
  %380 = icmp ult i32 %377, %376
  %381 = or i1 %379, %380
  %382 = zext i1 %381 to i8
  store i8 %382, i8* %15, align 1, !tbaa !2432
  %383 = and i32 %377, 255
  %384 = tail call i32 @llvm.ctpop.i32(i32 %383) #11
  %385 = trunc i32 %384 to i8
  %386 = and i8 %385, 1
  %387 = xor i8 %386, 1
  store i8 %387, i8* %22, align 1, !tbaa !2446
  %388 = xor i32 %376, %371
  %389 = xor i32 %388, %377
  %390 = lshr i32 %389, 4
  %391 = trunc i32 %390 to i8
  %392 = and i8 %391, 1
  store i8 %392, i8* %28, align 1, !tbaa !2447
  %393 = icmp eq i32 %377, 0
  %394 = zext i1 %393 to i8
  store i8 %394, i8* %31, align 1, !tbaa !2448
  %395 = lshr i32 %377, 31
  %396 = trunc i32 %395 to i8
  store i8 %396, i8* %34, align 1, !tbaa !2449
  %397 = lshr i32 %371, 31
  %398 = lshr i32 %376, 31
  %399 = xor i32 %395, %397
  %400 = xor i32 %395, %398
  %401 = add nuw nsw i32 %399, %400
  %402 = icmp eq i32 %401, 2
  %403 = zext i1 %402 to i8
  store i8 %403, i8* %40, align 1, !tbaa !2450
  %404 = add i64 %366, -36
  %405 = add i64 %368, 9
  store i64 %405, i64* %PC, align 8
  %406 = inttoptr i64 %404 to i32*
  store i32 %377, i32* %406, align 4
  %407 = load i64, i64* %RBP, align 8
  %408 = add i64 %407, -36
  %409 = load i64, i64* %PC, align 8
  %410 = add i64 %409, 3
  store i64 %410, i64* %PC, align 8
  %411 = inttoptr i64 %408 to i32*
  %412 = load i32, i32* %411, align 4
  %413 = zext i32 %412 to i64
  store i64 %413, i64* %RAX, align 8, !tbaa !2428
  %414 = add i64 %407, -8
  %415 = add i64 %409, 6
  store i64 %415, i64* %PC, align 8
  %416 = inttoptr i64 %414 to i32*
  %417 = load i32, i32* %416, align 4
  %418 = add i32 %417, %412
  %419 = zext i32 %418 to i64
  store i64 %419, i64* %RAX, align 8, !tbaa !2428
  %420 = icmp ult i32 %418, %412
  %421 = icmp ult i32 %418, %417
  %422 = or i1 %420, %421
  %423 = zext i1 %422 to i8
  store i8 %423, i8* %15, align 1, !tbaa !2432
  %424 = and i32 %418, 255
  %425 = tail call i32 @llvm.ctpop.i32(i32 %424) #11
  %426 = trunc i32 %425 to i8
  %427 = and i8 %426, 1
  %428 = xor i8 %427, 1
  store i8 %428, i8* %22, align 1, !tbaa !2446
  %429 = xor i32 %417, %412
  %430 = xor i32 %429, %418
  %431 = lshr i32 %430, 4
  %432 = trunc i32 %431 to i8
  %433 = and i8 %432, 1
  store i8 %433, i8* %28, align 1, !tbaa !2447
  %434 = icmp eq i32 %418, 0
  %435 = zext i1 %434 to i8
  store i8 %435, i8* %31, align 1, !tbaa !2448
  %436 = lshr i32 %418, 31
  %437 = trunc i32 %436 to i8
  store i8 %437, i8* %34, align 1, !tbaa !2449
  %438 = lshr i32 %412, 31
  %439 = lshr i32 %417, 31
  %440 = xor i32 %436, %438
  %441 = xor i32 %436, %439
  %442 = add nuw nsw i32 %440, %441
  %443 = icmp eq i32 %442, 2
  %444 = zext i1 %443 to i8
  store i8 %444, i8* %40, align 1, !tbaa !2450
  %445 = add i64 %407, -40
  %446 = add i64 %409, 9
  store i64 %446, i64* %PC, align 8
  %447 = inttoptr i64 %445 to i32*
  store i32 %418, i32* %447, align 4
  %448 = load i64, i64* %RBP, align 8
  %449 = add i64 %448, -16
  %450 = load i64, i64* %PC, align 8
  %451 = add i64 %450, 4
  store i64 %451, i64* %PC, align 8
  %452 = inttoptr i64 %449 to i64*
  %453 = load i64, i64* %452, align 8
  store i64 %453, i64* %RCX, align 8, !tbaa !2428
  %454 = add i64 %448, -28
  %455 = add i64 %450, 8
  store i64 %455, i64* %PC, align 8
  %456 = inttoptr i64 %454 to i32*
  %457 = load i32, i32* %456, align 4
  %458 = sext i32 %457 to i64
  store i64 %458, i64* %RDX, align 8, !tbaa !2428
  %459 = shl nsw i64 %458, 3
  %460 = add i64 %459, %453
  %461 = add i64 %450, 13
  store i64 %461, i64* %PC, align 8
  %462 = inttoptr i64 %460 to i64*
  %463 = load i64, i64* %462, align 8
  store i64 %463, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %464 = add i64 %450, 17
  store i64 %464, i64* %PC, align 8
  %465 = load i64, i64* %452, align 8
  store i64 %465, i64* %RCX, align 8, !tbaa !2428
  %466 = add i64 %448, -32
  %467 = add i64 %450, 21
  store i64 %467, i64* %PC, align 8
  %468 = inttoptr i64 %466 to i32*
  %469 = load i32, i32* %468, align 4
  %470 = sext i32 %469 to i64
  store i64 %470, i64* %RDX, align 8, !tbaa !2428
  %471 = shl nsw i64 %470, 3
  %472 = add i64 %471, %465
  %473 = add i64 %450, 26
  store i64 %473, i64* %PC, align 8
  %474 = bitcast i64 %463 to double
  %475 = inttoptr i64 %472 to double*
  %476 = load double, double* %475, align 8
  %477 = fadd double %474, %476
  store double %477, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %478 = add i64 %448, -120
  %479 = add i64 %450, 31
  store i64 %479, i64* %PC, align 8
  %480 = inttoptr i64 %478 to double*
  store double %477, double* %480, align 8
  %481 = load i64, i64* %RBP, align 8
  %482 = add i64 %481, -16
  %483 = load i64, i64* %PC, align 8
  %484 = add i64 %483, 4
  store i64 %484, i64* %PC, align 8
  %485 = inttoptr i64 %482 to i64*
  %486 = load i64, i64* %485, align 8
  store i64 %486, i64* %RCX, align 8, !tbaa !2428
  %487 = add i64 %481, -28
  %488 = add i64 %483, 7
  store i64 %488, i64* %PC, align 8
  %489 = inttoptr i64 %487 to i32*
  %490 = load i32, i32* %489, align 4
  %491 = add i32 %490, 1
  %492 = zext i32 %491 to i64
  store i64 %492, i64* %RAX, align 8, !tbaa !2428
  %493 = icmp eq i32 %490, -1
  %494 = icmp eq i32 %491, 0
  %495 = or i1 %493, %494
  %496 = zext i1 %495 to i8
  store i8 %496, i8* %15, align 1, !tbaa !2432
  %497 = and i32 %491, 255
  %498 = tail call i32 @llvm.ctpop.i32(i32 %497) #11
  %499 = trunc i32 %498 to i8
  %500 = and i8 %499, 1
  %501 = xor i8 %500, 1
  store i8 %501, i8* %22, align 1, !tbaa !2446
  %502 = xor i32 %491, %490
  %503 = lshr i32 %502, 4
  %504 = trunc i32 %503 to i8
  %505 = and i8 %504, 1
  store i8 %505, i8* %28, align 1, !tbaa !2447
  %506 = zext i1 %494 to i8
  store i8 %506, i8* %31, align 1, !tbaa !2448
  %507 = lshr i32 %491, 31
  %508 = trunc i32 %507 to i8
  store i8 %508, i8* %34, align 1, !tbaa !2449
  %509 = lshr i32 %490, 31
  %510 = xor i32 %507, %509
  %511 = add nuw nsw i32 %510, %507
  %512 = icmp eq i32 %511, 2
  %513 = zext i1 %512 to i8
  store i8 %513, i8* %40, align 1, !tbaa !2450
  %514 = sext i32 %491 to i64
  store i64 %514, i64* %RDX, align 8, !tbaa !2428
  %515 = shl nsw i64 %514, 3
  %516 = add i64 %515, %486
  %517 = add i64 %483, 18
  store i64 %517, i64* %PC, align 8
  %518 = inttoptr i64 %516 to i64*
  %519 = load i64, i64* %518, align 8
  store i64 %519, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %520 = add i64 %483, 22
  store i64 %520, i64* %PC, align 8
  %521 = load i64, i64* %485, align 8
  store i64 %521, i64* %RCX, align 8, !tbaa !2428
  %522 = add i64 %481, -32
  %523 = add i64 %483, 25
  store i64 %523, i64* %PC, align 8
  %524 = inttoptr i64 %522 to i32*
  %525 = load i32, i32* %524, align 4
  %526 = add i32 %525, 1
  %527 = zext i32 %526 to i64
  store i64 %527, i64* %RAX, align 8, !tbaa !2428
  %528 = icmp eq i32 %525, -1
  %529 = icmp eq i32 %526, 0
  %530 = or i1 %528, %529
  %531 = zext i1 %530 to i8
  store i8 %531, i8* %15, align 1, !tbaa !2432
  %532 = and i32 %526, 255
  %533 = tail call i32 @llvm.ctpop.i32(i32 %532) #11
  %534 = trunc i32 %533 to i8
  %535 = and i8 %534, 1
  %536 = xor i8 %535, 1
  store i8 %536, i8* %22, align 1, !tbaa !2446
  %537 = xor i32 %526, %525
  %538 = lshr i32 %537, 4
  %539 = trunc i32 %538 to i8
  %540 = and i8 %539, 1
  store i8 %540, i8* %28, align 1, !tbaa !2447
  %541 = zext i1 %529 to i8
  store i8 %541, i8* %31, align 1, !tbaa !2448
  %542 = lshr i32 %526, 31
  %543 = trunc i32 %542 to i8
  store i8 %543, i8* %34, align 1, !tbaa !2449
  %544 = lshr i32 %525, 31
  %545 = xor i32 %542, %544
  %546 = add nuw nsw i32 %545, %542
  %547 = icmp eq i32 %546, 2
  %548 = zext i1 %547 to i8
  store i8 %548, i8* %40, align 1, !tbaa !2450
  %549 = sext i32 %526 to i64
  store i64 %549, i64* %RDX, align 8, !tbaa !2428
  %550 = shl nsw i64 %549, 3
  %551 = add i64 %550, %521
  %552 = add i64 %483, 36
  store i64 %552, i64* %PC, align 8
  %553 = bitcast i64 %519 to double
  %554 = inttoptr i64 %551 to double*
  %555 = load double, double* %554, align 8
  %556 = fadd double %553, %555
  store double %556, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %557 = load i64, i64* %RBP, align 8
  %558 = add i64 %557, -128
  %559 = add i64 %483, 41
  store i64 %559, i64* %PC, align 8
  %560 = inttoptr i64 %558 to double*
  store double %556, double* %560, align 8
  %561 = load i64, i64* %RBP, align 8
  %562 = add i64 %561, -16
  %563 = load i64, i64* %PC, align 8
  %564 = add i64 %563, 4
  store i64 %564, i64* %PC, align 8
  %565 = inttoptr i64 %562 to i64*
  %566 = load i64, i64* %565, align 8
  store i64 %566, i64* %RCX, align 8, !tbaa !2428
  %567 = add i64 %561, -28
  %568 = add i64 %563, 8
  store i64 %568, i64* %PC, align 8
  %569 = inttoptr i64 %567 to i32*
  %570 = load i32, i32* %569, align 4
  %571 = sext i32 %570 to i64
  store i64 %571, i64* %RDX, align 8, !tbaa !2428
  %572 = shl nsw i64 %571, 3
  %573 = add i64 %572, %566
  %574 = add i64 %563, 13
  store i64 %574, i64* %PC, align 8
  %575 = inttoptr i64 %573 to i64*
  %576 = load i64, i64* %575, align 8
  store i64 %576, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %577 = add i64 %563, 17
  store i64 %577, i64* %PC, align 8
  %578 = load i64, i64* %565, align 8
  store i64 %578, i64* %RCX, align 8, !tbaa !2428
  %579 = add i64 %561, -32
  %580 = add i64 %563, 21
  store i64 %580, i64* %PC, align 8
  %581 = inttoptr i64 %579 to i32*
  %582 = load i32, i32* %581, align 4
  %583 = sext i32 %582 to i64
  store i64 %583, i64* %RDX, align 8, !tbaa !2428
  %584 = shl nsw i64 %583, 3
  %585 = add i64 %584, %578
  %586 = add i64 %563, 26
  store i64 %586, i64* %PC, align 8
  %587 = bitcast i64 %576 to double
  %588 = inttoptr i64 %585 to double*
  %589 = load double, double* %588, align 8
  %590 = fsub double %587, %589
  store double %590, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %591 = add i64 %561, -136
  %592 = add i64 %563, 34
  store i64 %592, i64* %PC, align 8
  %593 = inttoptr i64 %591 to double*
  store double %590, double* %593, align 8
  %594 = load i64, i64* %RBP, align 8
  %595 = add i64 %594, -16
  %596 = load i64, i64* %PC, align 8
  %597 = add i64 %596, 4
  store i64 %597, i64* %PC, align 8
  %598 = inttoptr i64 %595 to i64*
  %599 = load i64, i64* %598, align 8
  store i64 %599, i64* %RCX, align 8, !tbaa !2428
  %600 = add i64 %594, -28
  %601 = add i64 %596, 7
  store i64 %601, i64* %PC, align 8
  %602 = inttoptr i64 %600 to i32*
  %603 = load i32, i32* %602, align 4
  %604 = add i32 %603, 1
  %605 = zext i32 %604 to i64
  store i64 %605, i64* %RAX, align 8, !tbaa !2428
  %606 = icmp eq i32 %603, -1
  %607 = icmp eq i32 %604, 0
  %608 = or i1 %606, %607
  %609 = zext i1 %608 to i8
  store i8 %609, i8* %15, align 1, !tbaa !2432
  %610 = and i32 %604, 255
  %611 = tail call i32 @llvm.ctpop.i32(i32 %610) #11
  %612 = trunc i32 %611 to i8
  %613 = and i8 %612, 1
  %614 = xor i8 %613, 1
  store i8 %614, i8* %22, align 1, !tbaa !2446
  %615 = xor i32 %604, %603
  %616 = lshr i32 %615, 4
  %617 = trunc i32 %616 to i8
  %618 = and i8 %617, 1
  store i8 %618, i8* %28, align 1, !tbaa !2447
  %619 = zext i1 %607 to i8
  store i8 %619, i8* %31, align 1, !tbaa !2448
  %620 = lshr i32 %604, 31
  %621 = trunc i32 %620 to i8
  store i8 %621, i8* %34, align 1, !tbaa !2449
  %622 = lshr i32 %603, 31
  %623 = xor i32 %620, %622
  %624 = add nuw nsw i32 %623, %620
  %625 = icmp eq i32 %624, 2
  %626 = zext i1 %625 to i8
  store i8 %626, i8* %40, align 1, !tbaa !2450
  %627 = sext i32 %604 to i64
  store i64 %627, i64* %RDX, align 8, !tbaa !2428
  %628 = shl nsw i64 %627, 3
  %629 = add i64 %628, %599
  %630 = add i64 %596, 18
  store i64 %630, i64* %PC, align 8
  %631 = inttoptr i64 %629 to i64*
  %632 = load i64, i64* %631, align 8
  store i64 %632, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %633 = add i64 %596, 22
  store i64 %633, i64* %PC, align 8
  %634 = load i64, i64* %598, align 8
  store i64 %634, i64* %RCX, align 8, !tbaa !2428
  %635 = add i64 %594, -32
  %636 = add i64 %596, 25
  store i64 %636, i64* %PC, align 8
  %637 = inttoptr i64 %635 to i32*
  %638 = load i32, i32* %637, align 4
  %639 = add i32 %638, 1
  %640 = zext i32 %639 to i64
  store i64 %640, i64* %RAX, align 8, !tbaa !2428
  %641 = icmp eq i32 %638, -1
  %642 = icmp eq i32 %639, 0
  %643 = or i1 %641, %642
  %644 = zext i1 %643 to i8
  store i8 %644, i8* %15, align 1, !tbaa !2432
  %645 = and i32 %639, 255
  %646 = tail call i32 @llvm.ctpop.i32(i32 %645) #11
  %647 = trunc i32 %646 to i8
  %648 = and i8 %647, 1
  %649 = xor i8 %648, 1
  store i8 %649, i8* %22, align 1, !tbaa !2446
  %650 = xor i32 %639, %638
  %651 = lshr i32 %650, 4
  %652 = trunc i32 %651 to i8
  %653 = and i8 %652, 1
  store i8 %653, i8* %28, align 1, !tbaa !2447
  %654 = zext i1 %642 to i8
  store i8 %654, i8* %31, align 1, !tbaa !2448
  %655 = lshr i32 %639, 31
  %656 = trunc i32 %655 to i8
  store i8 %656, i8* %34, align 1, !tbaa !2449
  %657 = lshr i32 %638, 31
  %658 = xor i32 %655, %657
  %659 = add nuw nsw i32 %658, %655
  %660 = icmp eq i32 %659, 2
  %661 = zext i1 %660 to i8
  store i8 %661, i8* %40, align 1, !tbaa !2450
  %662 = sext i32 %639 to i64
  store i64 %662, i64* %RDX, align 8, !tbaa !2428
  %663 = shl nsw i64 %662, 3
  %664 = add i64 %663, %634
  %665 = add i64 %596, 36
  store i64 %665, i64* %PC, align 8
  %666 = bitcast i64 %632 to double
  %667 = inttoptr i64 %664 to double*
  %668 = load double, double* %667, align 8
  %669 = fsub double %666, %668
  store double %669, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %670 = load i64, i64* %RBP, align 8
  %671 = add i64 %670, -144
  %672 = add i64 %596, 44
  store i64 %672, i64* %PC, align 8
  %673 = inttoptr i64 %671 to double*
  store double %669, double* %673, align 8
  %674 = load i64, i64* %RBP, align 8
  %675 = add i64 %674, -16
  %676 = load i64, i64* %PC, align 8
  %677 = add i64 %676, 4
  store i64 %677, i64* %PC, align 8
  %678 = inttoptr i64 %675 to i64*
  %679 = load i64, i64* %678, align 8
  store i64 %679, i64* %RCX, align 8, !tbaa !2428
  %680 = add i64 %674, -36
  %681 = add i64 %676, 8
  store i64 %681, i64* %PC, align 8
  %682 = inttoptr i64 %680 to i32*
  %683 = load i32, i32* %682, align 4
  %684 = sext i32 %683 to i64
  store i64 %684, i64* %RDX, align 8, !tbaa !2428
  %685 = shl nsw i64 %684, 3
  %686 = add i64 %685, %679
  %687 = add i64 %676, 13
  store i64 %687, i64* %PC, align 8
  %688 = inttoptr i64 %686 to i64*
  %689 = load i64, i64* %688, align 8
  store i64 %689, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %690 = add i64 %676, 17
  store i64 %690, i64* %PC, align 8
  %691 = load i64, i64* %678, align 8
  store i64 %691, i64* %RCX, align 8, !tbaa !2428
  %692 = add i64 %674, -40
  %693 = add i64 %676, 21
  store i64 %693, i64* %PC, align 8
  %694 = inttoptr i64 %692 to i32*
  %695 = load i32, i32* %694, align 4
  %696 = sext i32 %695 to i64
  store i64 %696, i64* %RDX, align 8, !tbaa !2428
  %697 = shl nsw i64 %696, 3
  %698 = add i64 %697, %691
  %699 = add i64 %676, 26
  store i64 %699, i64* %PC, align 8
  %700 = bitcast i64 %689 to double
  %701 = inttoptr i64 %698 to double*
  %702 = load double, double* %701, align 8
  %703 = fadd double %700, %702
  store double %703, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %704 = add i64 %674, -152
  %705 = add i64 %676, 34
  store i64 %705, i64* %PC, align 8
  %706 = inttoptr i64 %704 to double*
  store double %703, double* %706, align 8
  %707 = load i64, i64* %RBP, align 8
  %708 = add i64 %707, -16
  %709 = load i64, i64* %PC, align 8
  %710 = add i64 %709, 4
  store i64 %710, i64* %PC, align 8
  %711 = inttoptr i64 %708 to i64*
  %712 = load i64, i64* %711, align 8
  store i64 %712, i64* %RCX, align 8, !tbaa !2428
  %713 = add i64 %707, -36
  %714 = add i64 %709, 7
  store i64 %714, i64* %PC, align 8
  %715 = inttoptr i64 %713 to i32*
  %716 = load i32, i32* %715, align 4
  %717 = add i32 %716, 1
  %718 = zext i32 %717 to i64
  store i64 %718, i64* %RAX, align 8, !tbaa !2428
  %719 = icmp eq i32 %716, -1
  %720 = icmp eq i32 %717, 0
  %721 = or i1 %719, %720
  %722 = zext i1 %721 to i8
  store i8 %722, i8* %15, align 1, !tbaa !2432
  %723 = and i32 %717, 255
  %724 = tail call i32 @llvm.ctpop.i32(i32 %723) #11
  %725 = trunc i32 %724 to i8
  %726 = and i8 %725, 1
  %727 = xor i8 %726, 1
  store i8 %727, i8* %22, align 1, !tbaa !2446
  %728 = xor i32 %717, %716
  %729 = lshr i32 %728, 4
  %730 = trunc i32 %729 to i8
  %731 = and i8 %730, 1
  store i8 %731, i8* %28, align 1, !tbaa !2447
  %732 = zext i1 %720 to i8
  store i8 %732, i8* %31, align 1, !tbaa !2448
  %733 = lshr i32 %717, 31
  %734 = trunc i32 %733 to i8
  store i8 %734, i8* %34, align 1, !tbaa !2449
  %735 = lshr i32 %716, 31
  %736 = xor i32 %733, %735
  %737 = add nuw nsw i32 %736, %733
  %738 = icmp eq i32 %737, 2
  %739 = zext i1 %738 to i8
  store i8 %739, i8* %40, align 1, !tbaa !2450
  %740 = sext i32 %717 to i64
  store i64 %740, i64* %RDX, align 8, !tbaa !2428
  %741 = shl nsw i64 %740, 3
  %742 = add i64 %741, %712
  %743 = add i64 %709, 18
  store i64 %743, i64* %PC, align 8
  %744 = inttoptr i64 %742 to i64*
  %745 = load i64, i64* %744, align 8
  store i64 %745, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %746 = add i64 %709, 22
  store i64 %746, i64* %PC, align 8
  %747 = load i64, i64* %711, align 8
  store i64 %747, i64* %RCX, align 8, !tbaa !2428
  %748 = add i64 %707, -40
  %749 = add i64 %709, 25
  store i64 %749, i64* %PC, align 8
  %750 = inttoptr i64 %748 to i32*
  %751 = load i32, i32* %750, align 4
  %752 = add i32 %751, 1
  %753 = zext i32 %752 to i64
  store i64 %753, i64* %RAX, align 8, !tbaa !2428
  %754 = icmp eq i32 %751, -1
  %755 = icmp eq i32 %752, 0
  %756 = or i1 %754, %755
  %757 = zext i1 %756 to i8
  store i8 %757, i8* %15, align 1, !tbaa !2432
  %758 = and i32 %752, 255
  %759 = tail call i32 @llvm.ctpop.i32(i32 %758) #11
  %760 = trunc i32 %759 to i8
  %761 = and i8 %760, 1
  %762 = xor i8 %761, 1
  store i8 %762, i8* %22, align 1, !tbaa !2446
  %763 = xor i32 %752, %751
  %764 = lshr i32 %763, 4
  %765 = trunc i32 %764 to i8
  %766 = and i8 %765, 1
  store i8 %766, i8* %28, align 1, !tbaa !2447
  %767 = zext i1 %755 to i8
  store i8 %767, i8* %31, align 1, !tbaa !2448
  %768 = lshr i32 %752, 31
  %769 = trunc i32 %768 to i8
  store i8 %769, i8* %34, align 1, !tbaa !2449
  %770 = lshr i32 %751, 31
  %771 = xor i32 %768, %770
  %772 = add nuw nsw i32 %771, %768
  %773 = icmp eq i32 %772, 2
  %774 = zext i1 %773 to i8
  store i8 %774, i8* %40, align 1, !tbaa !2450
  %775 = sext i32 %752 to i64
  store i64 %775, i64* %RDX, align 8, !tbaa !2428
  %776 = shl nsw i64 %775, 3
  %777 = add i64 %776, %747
  %778 = add i64 %709, 36
  store i64 %778, i64* %PC, align 8
  %779 = bitcast i64 %745 to double
  %780 = inttoptr i64 %777 to double*
  %781 = load double, double* %780, align 8
  %782 = fadd double %779, %781
  store double %782, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %783 = load i64, i64* %RBP, align 8
  %784 = add i64 %783, -160
  %785 = add i64 %709, 44
  store i64 %785, i64* %PC, align 8
  %786 = inttoptr i64 %784 to double*
  store double %782, double* %786, align 8
  %787 = load i64, i64* %RBP, align 8
  %788 = add i64 %787, -16
  %789 = load i64, i64* %PC, align 8
  %790 = add i64 %789, 4
  store i64 %790, i64* %PC, align 8
  %791 = inttoptr i64 %788 to i64*
  %792 = load i64, i64* %791, align 8
  store i64 %792, i64* %RCX, align 8, !tbaa !2428
  %793 = add i64 %787, -36
  %794 = add i64 %789, 8
  store i64 %794, i64* %PC, align 8
  %795 = inttoptr i64 %793 to i32*
  %796 = load i32, i32* %795, align 4
  %797 = sext i32 %796 to i64
  store i64 %797, i64* %RDX, align 8, !tbaa !2428
  %798 = shl nsw i64 %797, 3
  %799 = add i64 %798, %792
  %800 = add i64 %789, 13
  store i64 %800, i64* %PC, align 8
  %801 = inttoptr i64 %799 to i64*
  %802 = load i64, i64* %801, align 8
  store i64 %802, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %803 = add i64 %789, 17
  store i64 %803, i64* %PC, align 8
  %804 = load i64, i64* %791, align 8
  store i64 %804, i64* %RCX, align 8, !tbaa !2428
  %805 = add i64 %787, -40
  %806 = add i64 %789, 21
  store i64 %806, i64* %PC, align 8
  %807 = inttoptr i64 %805 to i32*
  %808 = load i32, i32* %807, align 4
  %809 = sext i32 %808 to i64
  store i64 %809, i64* %RDX, align 8, !tbaa !2428
  %810 = shl nsw i64 %809, 3
  %811 = add i64 %810, %804
  %812 = add i64 %789, 26
  store i64 %812, i64* %PC, align 8
  %813 = bitcast i64 %802 to double
  %814 = inttoptr i64 %811 to double*
  %815 = load double, double* %814, align 8
  %816 = fsub double %813, %815
  store double %816, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %817 = add i64 %787, -168
  %818 = add i64 %789, 34
  store i64 %818, i64* %PC, align 8
  %819 = inttoptr i64 %817 to double*
  store double %816, double* %819, align 8
  %820 = load i64, i64* %RBP, align 8
  %821 = add i64 %820, -16
  %822 = load i64, i64* %PC, align 8
  %823 = add i64 %822, 4
  store i64 %823, i64* %PC, align 8
  %824 = inttoptr i64 %821 to i64*
  %825 = load i64, i64* %824, align 8
  store i64 %825, i64* %RCX, align 8, !tbaa !2428
  %826 = add i64 %820, -36
  %827 = add i64 %822, 7
  store i64 %827, i64* %PC, align 8
  %828 = inttoptr i64 %826 to i32*
  %829 = load i32, i32* %828, align 4
  %830 = add i32 %829, 1
  %831 = zext i32 %830 to i64
  store i64 %831, i64* %RAX, align 8, !tbaa !2428
  %832 = icmp eq i32 %829, -1
  %833 = icmp eq i32 %830, 0
  %834 = or i1 %832, %833
  %835 = zext i1 %834 to i8
  store i8 %835, i8* %15, align 1, !tbaa !2432
  %836 = and i32 %830, 255
  %837 = tail call i32 @llvm.ctpop.i32(i32 %836) #11
  %838 = trunc i32 %837 to i8
  %839 = and i8 %838, 1
  %840 = xor i8 %839, 1
  store i8 %840, i8* %22, align 1, !tbaa !2446
  %841 = xor i32 %830, %829
  %842 = lshr i32 %841, 4
  %843 = trunc i32 %842 to i8
  %844 = and i8 %843, 1
  store i8 %844, i8* %28, align 1, !tbaa !2447
  %845 = zext i1 %833 to i8
  store i8 %845, i8* %31, align 1, !tbaa !2448
  %846 = lshr i32 %830, 31
  %847 = trunc i32 %846 to i8
  store i8 %847, i8* %34, align 1, !tbaa !2449
  %848 = lshr i32 %829, 31
  %849 = xor i32 %846, %848
  %850 = add nuw nsw i32 %849, %846
  %851 = icmp eq i32 %850, 2
  %852 = zext i1 %851 to i8
  store i8 %852, i8* %40, align 1, !tbaa !2450
  %853 = sext i32 %830 to i64
  store i64 %853, i64* %RDX, align 8, !tbaa !2428
  %854 = shl nsw i64 %853, 3
  %855 = add i64 %854, %825
  %856 = add i64 %822, 18
  store i64 %856, i64* %PC, align 8
  %857 = inttoptr i64 %855 to i64*
  %858 = load i64, i64* %857, align 8
  store i64 %858, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %859 = add i64 %822, 22
  store i64 %859, i64* %PC, align 8
  %860 = load i64, i64* %824, align 8
  store i64 %860, i64* %RCX, align 8, !tbaa !2428
  %861 = add i64 %820, -40
  %862 = add i64 %822, 25
  store i64 %862, i64* %PC, align 8
  %863 = inttoptr i64 %861 to i32*
  %864 = load i32, i32* %863, align 4
  %865 = add i32 %864, 1
  %866 = zext i32 %865 to i64
  store i64 %866, i64* %RAX, align 8, !tbaa !2428
  %867 = icmp eq i32 %864, -1
  %868 = icmp eq i32 %865, 0
  %869 = or i1 %867, %868
  %870 = zext i1 %869 to i8
  store i8 %870, i8* %15, align 1, !tbaa !2432
  %871 = and i32 %865, 255
  %872 = tail call i32 @llvm.ctpop.i32(i32 %871) #11
  %873 = trunc i32 %872 to i8
  %874 = and i8 %873, 1
  %875 = xor i8 %874, 1
  store i8 %875, i8* %22, align 1, !tbaa !2446
  %876 = xor i32 %865, %864
  %877 = lshr i32 %876, 4
  %878 = trunc i32 %877 to i8
  %879 = and i8 %878, 1
  store i8 %879, i8* %28, align 1, !tbaa !2447
  %880 = zext i1 %868 to i8
  store i8 %880, i8* %31, align 1, !tbaa !2448
  %881 = lshr i32 %865, 31
  %882 = trunc i32 %881 to i8
  store i8 %882, i8* %34, align 1, !tbaa !2449
  %883 = lshr i32 %864, 31
  %884 = xor i32 %881, %883
  %885 = add nuw nsw i32 %884, %881
  %886 = icmp eq i32 %885, 2
  %887 = zext i1 %886 to i8
  store i8 %887, i8* %40, align 1, !tbaa !2450
  %888 = sext i32 %865 to i64
  store i64 %888, i64* %RDX, align 8, !tbaa !2428
  %889 = shl nsw i64 %888, 3
  %890 = add i64 %889, %860
  %891 = add i64 %822, 36
  store i64 %891, i64* %PC, align 8
  %892 = bitcast i64 %858 to double
  %893 = inttoptr i64 %890 to double*
  %894 = load double, double* %893, align 8
  %895 = fsub double %892, %894
  store double %895, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %896 = load i64, i64* %RBP, align 8
  %897 = add i64 %896, -176
  %898 = add i64 %822, 44
  store i64 %898, i64* %PC, align 8
  %899 = inttoptr i64 %897 to double*
  store double %895, double* %899, align 8
  %900 = load i64, i64* %RBP, align 8
  %901 = add i64 %900, -120
  %902 = load i64, i64* %PC, align 8
  %903 = add i64 %902, 5
  store i64 %903, i64* %PC, align 8
  %904 = inttoptr i64 %901 to i64*
  %905 = load i64, i64* %904, align 8
  store i64 %905, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %906 = add i64 %900, -152
  %907 = add i64 %902, 13
  store i64 %907, i64* %PC, align 8
  %908 = bitcast i64 %905 to double
  %909 = inttoptr i64 %906 to double*
  %910 = load double, double* %909, align 8
  %911 = fadd double %908, %910
  store double %911, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %912 = add i64 %900, -16
  %913 = add i64 %902, 17
  store i64 %913, i64* %PC, align 8
  %914 = inttoptr i64 %912 to i64*
  %915 = load i64, i64* %914, align 8
  store i64 %915, i64* %RCX, align 8, !tbaa !2428
  %916 = add i64 %900, -28
  %917 = add i64 %902, 21
  store i64 %917, i64* %PC, align 8
  %918 = inttoptr i64 %916 to i32*
  %919 = load i32, i32* %918, align 4
  %920 = sext i32 %919 to i64
  store i64 %920, i64* %RDX, align 8, !tbaa !2428
  %921 = shl nsw i64 %920, 3
  %922 = add i64 %921, %915
  %923 = add i64 %902, 26
  store i64 %923, i64* %PC, align 8
  %924 = inttoptr i64 %922 to double*
  store double %911, double* %924, align 8
  %925 = load i64, i64* %RBP, align 8
  %926 = add i64 %925, -128
  %927 = load i64, i64* %PC, align 8
  %928 = add i64 %927, 5
  store i64 %928, i64* %PC, align 8
  %929 = inttoptr i64 %926 to i64*
  %930 = load i64, i64* %929, align 8
  store i64 %930, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %931 = add i64 %925, -160
  %932 = add i64 %927, 13
  store i64 %932, i64* %PC, align 8
  %933 = bitcast i64 %930 to double
  %934 = inttoptr i64 %931 to double*
  %935 = load double, double* %934, align 8
  %936 = fadd double %933, %935
  store double %936, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %937 = add i64 %925, -16
  %938 = add i64 %927, 17
  store i64 %938, i64* %PC, align 8
  %939 = inttoptr i64 %937 to i64*
  %940 = load i64, i64* %939, align 8
  store i64 %940, i64* %RCX, align 8, !tbaa !2428
  %941 = add i64 %925, -28
  %942 = add i64 %927, 20
  store i64 %942, i64* %PC, align 8
  %943 = inttoptr i64 %941 to i32*
  %944 = load i32, i32* %943, align 4
  %945 = add i32 %944, 1
  %946 = zext i32 %945 to i64
  store i64 %946, i64* %RAX, align 8, !tbaa !2428
  %947 = icmp eq i32 %944, -1
  %948 = icmp eq i32 %945, 0
  %949 = or i1 %947, %948
  %950 = zext i1 %949 to i8
  store i8 %950, i8* %15, align 1, !tbaa !2432
  %951 = and i32 %945, 255
  %952 = tail call i32 @llvm.ctpop.i32(i32 %951) #11
  %953 = trunc i32 %952 to i8
  %954 = and i8 %953, 1
  %955 = xor i8 %954, 1
  store i8 %955, i8* %22, align 1, !tbaa !2446
  %956 = xor i32 %945, %944
  %957 = lshr i32 %956, 4
  %958 = trunc i32 %957 to i8
  %959 = and i8 %958, 1
  store i8 %959, i8* %28, align 1, !tbaa !2447
  %960 = zext i1 %948 to i8
  store i8 %960, i8* %31, align 1, !tbaa !2448
  %961 = lshr i32 %945, 31
  %962 = trunc i32 %961 to i8
  store i8 %962, i8* %34, align 1, !tbaa !2449
  %963 = lshr i32 %944, 31
  %964 = xor i32 %961, %963
  %965 = add nuw nsw i32 %964, %961
  %966 = icmp eq i32 %965, 2
  %967 = zext i1 %966 to i8
  store i8 %967, i8* %40, align 1, !tbaa !2450
  %968 = sext i32 %945 to i64
  store i64 %968, i64* %RDX, align 8, !tbaa !2428
  %969 = shl nsw i64 %968, 3
  %970 = add i64 %969, %940
  %971 = add i64 %927, 31
  store i64 %971, i64* %PC, align 8
  %972 = inttoptr i64 %970 to double*
  store double %936, double* %972, align 8
  %973 = load i64, i64* %RBP, align 8
  %974 = add i64 %973, -160
  %975 = load i64, i64* %PC, align 8
  %976 = add i64 %975, 8
  store i64 %976, i64* %PC, align 8
  %977 = inttoptr i64 %974 to i64*
  %978 = load i64, i64* %977, align 8
  store i64 %978, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %979 = add i64 %973, -128
  %980 = add i64 %975, 13
  store i64 %980, i64* %PC, align 8
  %981 = bitcast i64 %978 to double
  %982 = inttoptr i64 %979 to double*
  %983 = load double, double* %982, align 8
  %984 = fsub double %981, %983
  store double %984, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %985 = add i64 %973, -16
  %986 = add i64 %975, 17
  store i64 %986, i64* %PC, align 8
  %987 = inttoptr i64 %985 to i64*
  %988 = load i64, i64* %987, align 8
  store i64 %988, i64* %RCX, align 8, !tbaa !2428
  %989 = add i64 %973, -36
  %990 = add i64 %975, 21
  store i64 %990, i64* %PC, align 8
  %991 = inttoptr i64 %989 to i32*
  %992 = load i32, i32* %991, align 4
  %993 = sext i32 %992 to i64
  store i64 %993, i64* %RDX, align 8, !tbaa !2428
  %994 = shl nsw i64 %993, 3
  %995 = add i64 %994, %988
  %996 = add i64 %975, 26
  store i64 %996, i64* %PC, align 8
  %997 = inttoptr i64 %995 to double*
  store double %984, double* %997, align 8
  %998 = load i64, i64* %RBP, align 8
  %999 = add i64 %998, -120
  %1000 = load i64, i64* %PC, align 8
  %1001 = add i64 %1000, 5
  store i64 %1001, i64* %PC, align 8
  %1002 = inttoptr i64 %999 to i64*
  %1003 = load i64, i64* %1002, align 8
  store i64 %1003, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1004 = add i64 %998, -152
  %1005 = add i64 %1000, 13
  store i64 %1005, i64* %PC, align 8
  %1006 = bitcast i64 %1003 to double
  %1007 = inttoptr i64 %1004 to double*
  %1008 = load double, double* %1007, align 8
  %1009 = fsub double %1006, %1008
  store double %1009, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %1010 = add i64 %998, -16
  %1011 = add i64 %1000, 17
  store i64 %1011, i64* %PC, align 8
  %1012 = inttoptr i64 %1010 to i64*
  %1013 = load i64, i64* %1012, align 8
  store i64 %1013, i64* %RCX, align 8, !tbaa !2428
  %1014 = add i64 %998, -36
  %1015 = add i64 %1000, 20
  store i64 %1015, i64* %PC, align 8
  %1016 = inttoptr i64 %1014 to i32*
  %1017 = load i32, i32* %1016, align 4
  %1018 = add i32 %1017, 1
  %1019 = zext i32 %1018 to i64
  store i64 %1019, i64* %RAX, align 8, !tbaa !2428
  %1020 = icmp eq i32 %1017, -1
  %1021 = icmp eq i32 %1018, 0
  %1022 = or i1 %1020, %1021
  %1023 = zext i1 %1022 to i8
  store i8 %1023, i8* %15, align 1, !tbaa !2432
  %1024 = and i32 %1018, 255
  %1025 = tail call i32 @llvm.ctpop.i32(i32 %1024) #11
  %1026 = trunc i32 %1025 to i8
  %1027 = and i8 %1026, 1
  %1028 = xor i8 %1027, 1
  store i8 %1028, i8* %22, align 1, !tbaa !2446
  %1029 = xor i32 %1018, %1017
  %1030 = lshr i32 %1029, 4
  %1031 = trunc i32 %1030 to i8
  %1032 = and i8 %1031, 1
  store i8 %1032, i8* %28, align 1, !tbaa !2447
  %1033 = zext i1 %1021 to i8
  store i8 %1033, i8* %31, align 1, !tbaa !2448
  %1034 = lshr i32 %1018, 31
  %1035 = trunc i32 %1034 to i8
  store i8 %1035, i8* %34, align 1, !tbaa !2449
  %1036 = lshr i32 %1017, 31
  %1037 = xor i32 %1034, %1036
  %1038 = add nuw nsw i32 %1037, %1034
  %1039 = icmp eq i32 %1038, 2
  %1040 = zext i1 %1039 to i8
  store i8 %1040, i8* %40, align 1, !tbaa !2450
  %1041 = sext i32 %1018 to i64
  store i64 %1041, i64* %RDX, align 8, !tbaa !2428
  %1042 = shl nsw i64 %1041, 3
  %1043 = add i64 %1042, %1013
  %1044 = add i64 %1000, 31
  store i64 %1044, i64* %PC, align 8
  %1045 = inttoptr i64 %1043 to double*
  store double %1009, double* %1045, align 8
  %1046 = load i64, i64* %RBP, align 8
  %1047 = add i64 %1046, -136
  %1048 = load i64, i64* %PC, align 8
  %1049 = add i64 %1048, 8
  store i64 %1049, i64* %PC, align 8
  %1050 = inttoptr i64 %1047 to i64*
  %1051 = load i64, i64* %1050, align 8
  store i64 %1051, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1052 = add i64 %1046, -176
  %1053 = add i64 %1048, 16
  store i64 %1053, i64* %PC, align 8
  %1054 = bitcast i64 %1051 to double
  %1055 = inttoptr i64 %1052 to double*
  %1056 = load double, double* %1055, align 8
  %1057 = fsub double %1054, %1056
  store double %1057, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %1058 = add i64 %1046, -120
  %1059 = add i64 %1048, 21
  store i64 %1059, i64* %PC, align 8
  %1060 = inttoptr i64 %1058 to double*
  store double %1057, double* %1060, align 8
  %1061 = load i64, i64* %RBP, align 8
  %1062 = add i64 %1061, -144
  %1063 = load i64, i64* %PC, align 8
  %1064 = add i64 %1063, 8
  store i64 %1064, i64* %PC, align 8
  %1065 = inttoptr i64 %1062 to i64*
  %1066 = load i64, i64* %1065, align 8
  store i64 %1066, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1067 = add i64 %1061, -168
  %1068 = add i64 %1063, 16
  store i64 %1068, i64* %PC, align 8
  %1069 = bitcast i64 %1066 to double
  %1070 = inttoptr i64 %1067 to double*
  %1071 = load double, double* %1070, align 8
  %1072 = fadd double %1069, %1071
  store double %1072, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %1073 = add i64 %1061, -128
  %1074 = add i64 %1063, 21
  store i64 %1074, i64* %PC, align 8
  %1075 = inttoptr i64 %1073 to double*
  store double %1072, double* %1075, align 8
  %1076 = load i64, i64* %RBP, align 8
  %1077 = add i64 %1076, -72
  %1078 = load i64, i64* %PC, align 8
  %1079 = add i64 %1078, 5
  store i64 %1079, i64* %PC, align 8
  %1080 = inttoptr i64 %1077 to i64*
  %1081 = load i64, i64* %1080, align 8
  store i64 %1081, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1082 = add i64 %1076, -120
  %1083 = add i64 %1078, 10
  store i64 %1083, i64* %PC, align 8
  %1084 = inttoptr i64 %1082 to i64*
  %1085 = load i64, i64* %1084, align 8
  store i64 %1085, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %1086 = add i64 %1076, -128
  %1087 = add i64 %1078, 15
  store i64 %1087, i64* %PC, align 8
  %1088 = bitcast i64 %1085 to double
  %1089 = inttoptr i64 %1086 to double*
  %1090 = load double, double* %1089, align 8
  %1091 = fsub double %1088, %1090
  store double %1091, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %1092 = bitcast i64 %1081 to double
  %1093 = fmul double %1092, %1091
  store double %1093, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %1094 = add i64 %1076, -16
  %1095 = add i64 %1078, 23
  store i64 %1095, i64* %PC, align 8
  %1096 = inttoptr i64 %1094 to i64*
  %1097 = load i64, i64* %1096, align 8
  store i64 %1097, i64* %RCX, align 8, !tbaa !2428
  %1098 = add i64 %1076, -32
  %1099 = add i64 %1078, 27
  store i64 %1099, i64* %PC, align 8
  %1100 = inttoptr i64 %1098 to i32*
  %1101 = load i32, i32* %1100, align 4
  %1102 = sext i32 %1101 to i64
  store i64 %1102, i64* %RDX, align 8, !tbaa !2428
  %1103 = shl nsw i64 %1102, 3
  %1104 = add i64 %1103, %1097
  %1105 = add i64 %1078, 32
  store i64 %1105, i64* %PC, align 8
  %1106 = inttoptr i64 %1104 to double*
  store double %1093, double* %1106, align 8
  %1107 = load i64, i64* %RBP, align 8
  %1108 = add i64 %1107, -72
  %1109 = load i64, i64* %PC, align 8
  %1110 = add i64 %1109, 5
  store i64 %1110, i64* %PC, align 8
  %1111 = inttoptr i64 %1108 to i64*
  %1112 = load i64, i64* %1111, align 8
  store i64 %1112, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1113 = add i64 %1107, -120
  %1114 = add i64 %1109, 10
  store i64 %1114, i64* %PC, align 8
  %1115 = inttoptr i64 %1113 to i64*
  %1116 = load i64, i64* %1115, align 8
  store i64 %1116, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %1117 = add i64 %1107, -128
  %1118 = add i64 %1109, 15
  store i64 %1118, i64* %PC, align 8
  %1119 = bitcast i64 %1116 to double
  %1120 = inttoptr i64 %1117 to double*
  %1121 = load double, double* %1120, align 8
  %1122 = fadd double %1119, %1121
  store double %1122, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %1123 = bitcast i64 %1112 to double
  %1124 = fmul double %1123, %1122
  store double %1124, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %1125 = add i64 %1107, -16
  %1126 = add i64 %1109, 23
  store i64 %1126, i64* %PC, align 8
  %1127 = inttoptr i64 %1125 to i64*
  %1128 = load i64, i64* %1127, align 8
  store i64 %1128, i64* %RCX, align 8, !tbaa !2428
  %1129 = add i64 %1107, -32
  %1130 = add i64 %1109, 26
  store i64 %1130, i64* %PC, align 8
  %1131 = inttoptr i64 %1129 to i32*
  %1132 = load i32, i32* %1131, align 4
  %1133 = add i32 %1132, 1
  %1134 = zext i32 %1133 to i64
  store i64 %1134, i64* %RAX, align 8, !tbaa !2428
  %1135 = icmp eq i32 %1132, -1
  %1136 = icmp eq i32 %1133, 0
  %1137 = or i1 %1135, %1136
  %1138 = zext i1 %1137 to i8
  store i8 %1138, i8* %15, align 1, !tbaa !2432
  %1139 = and i32 %1133, 255
  %1140 = tail call i32 @llvm.ctpop.i32(i32 %1139) #11
  %1141 = trunc i32 %1140 to i8
  %1142 = and i8 %1141, 1
  %1143 = xor i8 %1142, 1
  store i8 %1143, i8* %22, align 1, !tbaa !2446
  %1144 = xor i32 %1133, %1132
  %1145 = lshr i32 %1144, 4
  %1146 = trunc i32 %1145 to i8
  %1147 = and i8 %1146, 1
  store i8 %1147, i8* %28, align 1, !tbaa !2447
  %1148 = zext i1 %1136 to i8
  store i8 %1148, i8* %31, align 1, !tbaa !2448
  %1149 = lshr i32 %1133, 31
  %1150 = trunc i32 %1149 to i8
  store i8 %1150, i8* %34, align 1, !tbaa !2449
  %1151 = lshr i32 %1132, 31
  %1152 = xor i32 %1149, %1151
  %1153 = add nuw nsw i32 %1152, %1149
  %1154 = icmp eq i32 %1153, 2
  %1155 = zext i1 %1154 to i8
  store i8 %1155, i8* %40, align 1, !tbaa !2450
  %1156 = sext i32 %1133 to i64
  store i64 %1156, i64* %RDX, align 8, !tbaa !2428
  %1157 = shl nsw i64 %1156, 3
  %1158 = add i64 %1157, %1128
  %1159 = add i64 %1109, 37
  store i64 %1159, i64* %PC, align 8
  %1160 = inttoptr i64 %1158 to double*
  store double %1124, double* %1160, align 8
  %1161 = load i64, i64* %RBP, align 8
  %1162 = add i64 %1161, -176
  %1163 = load i64, i64* %PC, align 8
  %1164 = add i64 %1163, 8
  store i64 %1164, i64* %PC, align 8
  %1165 = inttoptr i64 %1162 to i64*
  %1166 = load i64, i64* %1165, align 8
  store i64 %1166, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1167 = add i64 %1161, -136
  %1168 = add i64 %1163, 16
  store i64 %1168, i64* %PC, align 8
  %1169 = bitcast i64 %1166 to double
  %1170 = inttoptr i64 %1167 to double*
  %1171 = load double, double* %1170, align 8
  %1172 = fadd double %1169, %1171
  store double %1172, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %1173 = add i64 %1161, -120
  %1174 = add i64 %1163, 21
  store i64 %1174, i64* %PC, align 8
  %1175 = inttoptr i64 %1173 to double*
  store double %1172, double* %1175, align 8
  %1176 = load i64, i64* %RBP, align 8
  %1177 = add i64 %1176, -168
  %1178 = load i64, i64* %PC, align 8
  %1179 = add i64 %1178, 8
  store i64 %1179, i64* %PC, align 8
  %1180 = inttoptr i64 %1177 to i64*
  %1181 = load i64, i64* %1180, align 8
  store i64 %1181, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1182 = add i64 %1176, -144
  %1183 = add i64 %1178, 16
  store i64 %1183, i64* %PC, align 8
  %1184 = bitcast i64 %1181 to double
  %1185 = inttoptr i64 %1182 to double*
  %1186 = load double, double* %1185, align 8
  %1187 = fsub double %1184, %1186
  store double %1187, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %1188 = add i64 %1176, -128
  %1189 = add i64 %1178, 21
  store i64 %1189, i64* %PC, align 8
  %1190 = inttoptr i64 %1188 to double*
  store double %1187, double* %1190, align 8
  %1191 = load i64, i64* %RBP, align 8
  %1192 = add i64 %1191, -72
  %1193 = load i64, i64* %PC, align 8
  %1194 = add i64 %1193, 5
  store i64 %1194, i64* %PC, align 8
  %1195 = inttoptr i64 %1192 to i64*
  %1196 = load i64, i64* %1195, align 8
  store i64 %1196, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1197 = add i64 %1191, -128
  %1198 = add i64 %1193, 10
  store i64 %1198, i64* %PC, align 8
  %1199 = inttoptr i64 %1197 to i64*
  %1200 = load i64, i64* %1199, align 8
  store i64 %1200, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %1201 = add i64 %1191, -120
  %1202 = add i64 %1193, 15
  store i64 %1202, i64* %PC, align 8
  %1203 = bitcast i64 %1200 to double
  %1204 = inttoptr i64 %1201 to double*
  %1205 = load double, double* %1204, align 8
  %1206 = fsub double %1203, %1205
  store double %1206, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %1207 = bitcast i64 %1196 to double
  %1208 = fmul double %1207, %1206
  store double %1208, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %1209 = add i64 %1191, -16
  %1210 = add i64 %1193, 23
  store i64 %1210, i64* %PC, align 8
  %1211 = inttoptr i64 %1209 to i64*
  %1212 = load i64, i64* %1211, align 8
  store i64 %1212, i64* %RCX, align 8, !tbaa !2428
  %1213 = add i64 %1191, -40
  %1214 = add i64 %1193, 27
  store i64 %1214, i64* %PC, align 8
  %1215 = inttoptr i64 %1213 to i32*
  %1216 = load i32, i32* %1215, align 4
  %1217 = sext i32 %1216 to i64
  store i64 %1217, i64* %RDX, align 8, !tbaa !2428
  %1218 = shl nsw i64 %1217, 3
  %1219 = add i64 %1218, %1212
  %1220 = add i64 %1193, 32
  store i64 %1220, i64* %PC, align 8
  %1221 = inttoptr i64 %1219 to double*
  store double %1208, double* %1221, align 8
  %1222 = load i64, i64* %RBP, align 8
  %1223 = add i64 %1222, -72
  %1224 = load i64, i64* %PC, align 8
  %1225 = add i64 %1224, 5
  store i64 %1225, i64* %PC, align 8
  %1226 = inttoptr i64 %1223 to i64*
  %1227 = load i64, i64* %1226, align 8
  store i64 %1227, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1228 = add i64 %1222, -128
  %1229 = add i64 %1224, 10
  store i64 %1229, i64* %PC, align 8
  %1230 = inttoptr i64 %1228 to i64*
  %1231 = load i64, i64* %1230, align 8
  store i64 %1231, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %1232 = add i64 %1222, -120
  %1233 = add i64 %1224, 15
  store i64 %1233, i64* %PC, align 8
  %1234 = bitcast i64 %1231 to double
  %1235 = inttoptr i64 %1232 to double*
  %1236 = load double, double* %1235, align 8
  %1237 = fadd double %1234, %1236
  store double %1237, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %1238 = bitcast i64 %1227 to double
  %1239 = fmul double %1238, %1237
  store double %1239, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %1240 = add i64 %1222, -16
  %1241 = add i64 %1224, 23
  store i64 %1241, i64* %PC, align 8
  %1242 = inttoptr i64 %1240 to i64*
  %1243 = load i64, i64* %1242, align 8
  store i64 %1243, i64* %RCX, align 8, !tbaa !2428
  %1244 = add i64 %1222, -40
  %1245 = add i64 %1224, 26
  store i64 %1245, i64* %PC, align 8
  %1246 = inttoptr i64 %1244 to i32*
  %1247 = load i32, i32* %1246, align 4
  %1248 = add i32 %1247, 1
  %1249 = zext i32 %1248 to i64
  store i64 %1249, i64* %RAX, align 8, !tbaa !2428
  %1250 = icmp eq i32 %1247, -1
  %1251 = icmp eq i32 %1248, 0
  %1252 = or i1 %1250, %1251
  %1253 = zext i1 %1252 to i8
  store i8 %1253, i8* %15, align 1, !tbaa !2432
  %1254 = and i32 %1248, 255
  %1255 = tail call i32 @llvm.ctpop.i32(i32 %1254) #11
  %1256 = trunc i32 %1255 to i8
  %1257 = and i8 %1256, 1
  %1258 = xor i8 %1257, 1
  store i8 %1258, i8* %22, align 1, !tbaa !2446
  %1259 = xor i32 %1248, %1247
  %1260 = lshr i32 %1259, 4
  %1261 = trunc i32 %1260 to i8
  %1262 = and i8 %1261, 1
  store i8 %1262, i8* %28, align 1, !tbaa !2447
  %1263 = zext i1 %1251 to i8
  store i8 %1263, i8* %31, align 1, !tbaa !2448
  %1264 = lshr i32 %1248, 31
  %1265 = trunc i32 %1264 to i8
  store i8 %1265, i8* %34, align 1, !tbaa !2449
  %1266 = lshr i32 %1247, 31
  %1267 = xor i32 %1264, %1266
  %1268 = add nuw nsw i32 %1267, %1264
  %1269 = icmp eq i32 %1268, 2
  %1270 = zext i1 %1269 to i8
  store i8 %1270, i8* %40, align 1, !tbaa !2450
  %1271 = sext i32 %1248 to i64
  store i64 %1271, i64* %RDX, align 8, !tbaa !2428
  %1272 = shl nsw i64 %1271, 3
  %1273 = add i64 %1272, %1243
  %1274 = add i64 %1224, 37
  store i64 %1274, i64* %PC, align 8
  %1275 = inttoptr i64 %1273 to double*
  store double %1239, double* %1275, align 8
  %1276 = load i64, i64* %RBP, align 8
  %1277 = add i64 %1276, -28
  %1278 = load i64, i64* %PC, align 8
  %1279 = add i64 %1278, 3
  store i64 %1279, i64* %PC, align 8
  %1280 = inttoptr i64 %1277 to i32*
  %1281 = load i32, i32* %1280, align 4
  %1282 = add i32 %1281, 2
  %1283 = zext i32 %1282 to i64
  store i64 %1283, i64* %RAX, align 8, !tbaa !2428
  %1284 = icmp ugt i32 %1281, -3
  %1285 = zext i1 %1284 to i8
  store i8 %1285, i8* %15, align 1, !tbaa !2432
  %1286 = and i32 %1282, 255
  %1287 = tail call i32 @llvm.ctpop.i32(i32 %1286) #11
  %1288 = trunc i32 %1287 to i8
  %1289 = and i8 %1288, 1
  %1290 = xor i8 %1289, 1
  store i8 %1290, i8* %22, align 1, !tbaa !2446
  %1291 = xor i32 %1282, %1281
  %1292 = lshr i32 %1291, 4
  %1293 = trunc i32 %1292 to i8
  %1294 = and i8 %1293, 1
  store i8 %1294, i8* %28, align 1, !tbaa !2447
  %1295 = icmp eq i32 %1282, 0
  %1296 = zext i1 %1295 to i8
  store i8 %1296, i8* %31, align 1, !tbaa !2448
  %1297 = lshr i32 %1282, 31
  %1298 = trunc i32 %1297 to i8
  store i8 %1298, i8* %34, align 1, !tbaa !2449
  %1299 = lshr i32 %1281, 31
  %1300 = xor i32 %1297, %1299
  %1301 = add nuw nsw i32 %1300, %1297
  %1302 = icmp eq i32 %1301, 2
  %1303 = zext i1 %1302 to i8
  store i8 %1303, i8* %40, align 1, !tbaa !2450
  %1304 = add i64 %1278, 9
  store i64 %1304, i64* %PC, align 8
  store i32 %1282, i32* %1280, align 4
  %1305 = load i64, i64* %PC, align 8
  %1306 = add i64 %1305, -695
  store i64 %1306, i64* %PC, align 8, !tbaa !2428
  br label %block_4035c1

block_40387d:                                     ; preds = %block_4035c1
  %1307 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %1308 = add i64 %4755, -48
  %1309 = add i64 %4798, 7
  store i64 %1309, i64* %PC, align 8
  %1310 = inttoptr i64 %1308 to i32*
  store i32 0, i32* %1310, align 4
  %1311 = load i64, i64* %RBP, align 8
  %1312 = add i64 %1311, -56
  %1313 = load i64, i64* %PC, align 8
  %1314 = add i64 %1313, 3
  store i64 %1314, i64* %PC, align 8
  %1315 = inttoptr i64 %1312 to i32*
  %1316 = load i32, i32* %1315, align 4
  %1317 = shl i32 %1316, 1
  %1318 = icmp slt i32 %1316, 0
  %1319 = icmp slt i32 %1317, 0
  %1320 = xor i1 %1318, %1319
  %1321 = zext i32 %1317 to i64
  store i64 %1321, i64* %RAX, align 8, !tbaa !2428
  %.lobit = lshr i32 %1316, 31
  %1322 = trunc i32 %.lobit to i8
  store i8 %1322, i8* %15, align 1, !tbaa !2453
  %1323 = and i32 %1317, 254
  %1324 = tail call i32 @llvm.ctpop.i32(i32 %1323) #11
  %1325 = trunc i32 %1324 to i8
  %1326 = and i8 %1325, 1
  %1327 = xor i8 %1326, 1
  store i8 %1327, i8* %22, align 1, !tbaa !2453
  store i8 0, i8* %28, align 1, !tbaa !2453
  %1328 = icmp eq i32 %1317, 0
  %1329 = zext i1 %1328 to i8
  store i8 %1329, i8* %31, align 1, !tbaa !2453
  %1330 = lshr i32 %1316, 30
  %1331 = trunc i32 %1330 to i8
  %1332 = and i8 %1331, 1
  store i8 %1332, i8* %34, align 1, !tbaa !2453
  %1333 = zext i1 %1320 to i8
  store i8 %1333, i8* %40, align 1, !tbaa !2453
  %1334 = add i64 %1311, -60
  %1335 = add i64 %1313, 9
  store i64 %1335, i64* %PC, align 8
  %1336 = inttoptr i64 %1334 to i32*
  store i32 %1317, i32* %1336, align 4
  %1337 = load i64, i64* %RBP, align 8
  %1338 = add i64 %1337, -60
  %1339 = load i64, i64* %PC, align 8
  %1340 = add i64 %1339, 3
  store i64 %1340, i64* %PC, align 8
  %1341 = inttoptr i64 %1338 to i32*
  %1342 = load i32, i32* %1341, align 4
  %1343 = zext i32 %1342 to i64
  store i64 %1343, i64* %RAX, align 8, !tbaa !2428
  %1344 = add i64 %1337, -44
  %1345 = add i64 %1339, 6
  store i64 %1345, i64* %PC, align 8
  %1346 = inttoptr i64 %1344 to i32*
  store i32 %1342, i32* %1346, align 4
  %1347 = bitcast %union.VectorReg* %1307 to i8*
  %1348 = bitcast [32 x %union.VectorReg]* %5 to <2 x i32>*
  %1349 = bitcast i64* %94 to <2 x i32>*
  %1350 = bitcast %union.VectorReg* %1307 to i32*
  %1351 = getelementptr inbounds i8, i8* %1347, i64 4
  %1352 = bitcast i8* %1351 to i32*
  %1353 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %1354 = bitcast i64* %1353 to i32*
  %1355 = getelementptr inbounds i8, i8* %1347, i64 12
  %1356 = bitcast i8* %1355 to i32*
  %1357 = bitcast %union.VectorReg* %1307 to double*
  %.pre24 = load i64, i64* %PC, align 8
  br label %block_403893

block_403c52:                                     ; preds = %block_403940
  %1358 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_4040a0__rodata_type* @seg_4040a0__rodata to i64), i64 80) to i64*), align 16
  store i64 %1358, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1359 = add i64 %4800, -24
  %1360 = add i64 %4843, 12
  store i64 %1360, i64* %PC, align 8
  %1361 = inttoptr i64 %1359 to i64*
  %1362 = load i64, i64* %1361, align 8
  store i64 %1362, i64* %RAX, align 8, !tbaa !2428
  %1363 = add i64 %4800, -52
  %1364 = add i64 %4843, 15
  store i64 %1364, i64* %PC, align 8
  %1365 = inttoptr i64 %1363 to i32*
  %1366 = load i32, i32* %1365, align 4
  %1367 = add i32 %1366, 2
  %1368 = zext i32 %1367 to i64
  store i64 %1368, i64* %RCX, align 8, !tbaa !2428
  %1369 = icmp ugt i32 %1366, -3
  %1370 = zext i1 %1369 to i8
  store i8 %1370, i8* %15, align 1, !tbaa !2432
  %1371 = and i32 %1367, 255
  %1372 = tail call i32 @llvm.ctpop.i32(i32 %1371) #11
  %1373 = trunc i32 %1372 to i8
  %1374 = and i8 %1373, 1
  %1375 = xor i8 %1374, 1
  store i8 %1375, i8* %22, align 1, !tbaa !2446
  %1376 = xor i32 %1367, %1366
  %1377 = lshr i32 %1376, 4
  %1378 = trunc i32 %1377 to i8
  %1379 = and i8 %1378, 1
  store i8 %1379, i8* %28, align 1, !tbaa !2447
  %1380 = icmp eq i32 %1367, 0
  %1381 = zext i1 %1380 to i8
  store i8 %1381, i8* %31, align 1, !tbaa !2448
  %1382 = lshr i32 %1367, 31
  %1383 = trunc i32 %1382 to i8
  store i8 %1383, i8* %34, align 1, !tbaa !2449
  %1384 = lshr i32 %1366, 31
  %1385 = xor i32 %1382, %1384
  %1386 = add nuw nsw i32 %1385, %1382
  %1387 = icmp eq i32 %1386, 2
  %1388 = zext i1 %1387 to i8
  store i8 %1388, i8* %40, align 1, !tbaa !2450
  %1389 = sext i32 %1367 to i64
  store i64 %1389, i64* %RDX, align 8, !tbaa !2428
  %1390 = shl nsw i64 %1389, 3
  %1391 = add i64 %1390, %1362
  %1392 = add i64 %4843, 26
  store i64 %1392, i64* %PC, align 8
  %1393 = inttoptr i64 %1391 to i64*
  %1394 = load i64, i64* %1393, align 8
  store i64 %1394, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %1395 = add i64 %4800, -72
  %1396 = add i64 %4843, 31
  store i64 %1396, i64* %PC, align 8
  %1397 = inttoptr i64 %1395 to i64*
  store i64 %1394, i64* %1397, align 8
  %1398 = load i64, i64* %RBP, align 8
  %1399 = add i64 %1398, -24
  %1400 = load i64, i64* %PC, align 8
  %1401 = add i64 %1400, 4
  store i64 %1401, i64* %PC, align 8
  %1402 = inttoptr i64 %1399 to i64*
  %1403 = load i64, i64* %1402, align 8
  store i64 %1403, i64* %RAX, align 8, !tbaa !2428
  %1404 = add i64 %1398, -52
  %1405 = add i64 %1400, 7
  store i64 %1405, i64* %PC, align 8
  %1406 = inttoptr i64 %1404 to i32*
  %1407 = load i32, i32* %1406, align 4
  %1408 = add i32 %1407, 3
  %1409 = zext i32 %1408 to i64
  store i64 %1409, i64* %RCX, align 8, !tbaa !2428
  %1410 = icmp ugt i32 %1407, -4
  %1411 = zext i1 %1410 to i8
  store i8 %1411, i8* %15, align 1, !tbaa !2432
  %1412 = and i32 %1408, 255
  %1413 = tail call i32 @llvm.ctpop.i32(i32 %1412) #11
  %1414 = trunc i32 %1413 to i8
  %1415 = and i8 %1414, 1
  %1416 = xor i8 %1415, 1
  store i8 %1416, i8* %22, align 1, !tbaa !2446
  %1417 = xor i32 %1408, %1407
  %1418 = lshr i32 %1417, 4
  %1419 = trunc i32 %1418 to i8
  %1420 = and i8 %1419, 1
  store i8 %1420, i8* %28, align 1, !tbaa !2447
  %1421 = icmp eq i32 %1408, 0
  %1422 = zext i1 %1421 to i8
  store i8 %1422, i8* %31, align 1, !tbaa !2448
  %1423 = lshr i32 %1408, 31
  %1424 = trunc i32 %1423 to i8
  store i8 %1424, i8* %34, align 1, !tbaa !2449
  %1425 = lshr i32 %1407, 31
  %1426 = xor i32 %1423, %1425
  %1427 = add nuw nsw i32 %1426, %1423
  %1428 = icmp eq i32 %1427, 2
  %1429 = zext i1 %1428 to i8
  store i8 %1429, i8* %40, align 1, !tbaa !2450
  %1430 = sext i32 %1408 to i64
  store i64 %1430, i64* %RDX, align 8, !tbaa !2428
  %1431 = shl nsw i64 %1430, 3
  %1432 = add i64 %1431, %1403
  %1433 = add i64 %1400, 18
  store i64 %1433, i64* %PC, align 8
  %1434 = inttoptr i64 %1432 to i64*
  %1435 = load i64, i64* %1434, align 8
  store i64 %1435, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %1436 = add i64 %1398, -80
  %1437 = add i64 %1400, 23
  store i64 %1437, i64* %PC, align 8
  %1438 = inttoptr i64 %1436 to i64*
  store i64 %1435, i64* %1438, align 8
  %1439 = load i64, i64* %RBP, align 8
  %1440 = add i64 %1439, -72
  %1441 = load i64, i64* %PC, align 8
  %1442 = add i64 %1441, 5
  store i64 %1442, i64* %PC, align 8
  %1443 = inttoptr i64 %1440 to i64*
  %1444 = load i64, i64* %1443, align 8
  store i64 %1444, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %1445 = load <2 x i32>, <2 x i32>* %1348, align 1
  %1446 = load <2 x i32>, <2 x i32>* %1349, align 1
  %1447 = extractelement <2 x i32> %1445, i32 0
  store i32 %1447, i32* %1350, align 1, !tbaa !2475
  %1448 = extractelement <2 x i32> %1445, i32 1
  store i32 %1448, i32* %1352, align 1, !tbaa !2475
  %1449 = extractelement <2 x i32> %1446, i32 0
  store i32 %1449, i32* %1354, align 1, !tbaa !2475
  %1450 = extractelement <2 x i32> %1446, i32 1
  store i32 %1450, i32* %1356, align 1, !tbaa !2475
  %1451 = add i64 %1439, -88
  %1452 = add i64 %1441, 13
  store i64 %1452, i64* %PC, align 8
  %1453 = load double, double* %1357, align 1
  %1454 = inttoptr i64 %1451 to double*
  %1455 = load double, double* %1454, align 8
  %1456 = fmul double %1453, %1455
  store double %1456, double* %1357, align 1, !tbaa !2451
  %1457 = add i64 %1439, -80
  %1458 = add i64 %1441, 18
  store i64 %1458, i64* %PC, align 8
  %1459 = inttoptr i64 %1457 to double*
  %1460 = load double, double* %1459, align 8
  %1461 = fmul double %1456, %1460
  store double %1461, double* %1357, align 1, !tbaa !2451
  %1462 = bitcast i64 %1444 to double
  %1463 = fsub double %1462, %1461
  store double %1463, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %1464 = add i64 %1439, -104
  %1465 = add i64 %1441, 27
  store i64 %1465, i64* %PC, align 8
  %1466 = inttoptr i64 %1464 to double*
  store double %1463, double* %1466, align 8
  %1467 = load i64, i64* %RBP, align 8
  %1468 = add i64 %1467, -88
  %1469 = load i64, i64* %PC, align 8
  %1470 = add i64 %1469, 5
  store i64 %1470, i64* %PC, align 8
  %1471 = load double, double* %92, align 1
  %1472 = inttoptr i64 %1468 to double*
  %1473 = load double, double* %1472, align 8
  %1474 = fmul double %1471, %1473
  store double %1474, double* %92, align 1, !tbaa !2451
  %1475 = add i64 %1467, -72
  %1476 = add i64 %1469, 10
  store i64 %1476, i64* %PC, align 8
  %1477 = inttoptr i64 %1475 to double*
  %1478 = load double, double* %1477, align 8
  %1479 = fmul double %1474, %1478
  store double %1479, double* %92, align 1, !tbaa !2451
  %1480 = add i64 %1467, -80
  %1481 = add i64 %1469, 15
  store i64 %1481, i64* %PC, align 8
  %1482 = inttoptr i64 %1480 to double*
  %1483 = load double, double* %1482, align 8
  %1484 = fsub double %1479, %1483
  store double %1484, double* %92, align 1, !tbaa !2451
  %1485 = add i64 %1467, -112
  %1486 = add i64 %1469, 20
  store i64 %1486, i64* %PC, align 8
  %1487 = inttoptr i64 %1485 to double*
  store double %1484, double* %1487, align 8
  %1488 = load i64, i64* %RBP, align 8
  %1489 = add i64 %1488, -44
  %1490 = load i64, i64* %PC, align 8
  %1491 = add i64 %1490, 3
  store i64 %1491, i64* %PC, align 8
  %1492 = inttoptr i64 %1489 to i32*
  %1493 = load i32, i32* %1492, align 4
  %1494 = zext i32 %1493 to i64
  store i64 %1494, i64* %RCX, align 8, !tbaa !2428
  %1495 = add i64 %1488, -56
  %1496 = add i64 %1490, 6
  store i64 %1496, i64* %PC, align 8
  %1497 = inttoptr i64 %1495 to i32*
  %1498 = load i32, i32* %1497, align 4
  %1499 = add i32 %1498, %1493
  %1500 = zext i32 %1499 to i64
  store i64 %1500, i64* %RCX, align 8, !tbaa !2428
  %1501 = icmp ult i32 %1499, %1493
  %1502 = icmp ult i32 %1499, %1498
  %1503 = or i1 %1501, %1502
  %1504 = zext i1 %1503 to i8
  store i8 %1504, i8* %15, align 1, !tbaa !2432
  %1505 = and i32 %1499, 255
  %1506 = tail call i32 @llvm.ctpop.i32(i32 %1505) #11
  %1507 = trunc i32 %1506 to i8
  %1508 = and i8 %1507, 1
  %1509 = xor i8 %1508, 1
  store i8 %1509, i8* %22, align 1, !tbaa !2446
  %1510 = xor i32 %1498, %1493
  %1511 = xor i32 %1510, %1499
  %1512 = lshr i32 %1511, 4
  %1513 = trunc i32 %1512 to i8
  %1514 = and i8 %1513, 1
  store i8 %1514, i8* %28, align 1, !tbaa !2447
  %1515 = icmp eq i32 %1499, 0
  %1516 = zext i1 %1515 to i8
  store i8 %1516, i8* %31, align 1, !tbaa !2448
  %1517 = lshr i32 %1499, 31
  %1518 = trunc i32 %1517 to i8
  store i8 %1518, i8* %34, align 1, !tbaa !2449
  %1519 = lshr i32 %1493, 31
  %1520 = lshr i32 %1498, 31
  %1521 = xor i32 %1517, %1519
  %1522 = xor i32 %1517, %1520
  %1523 = add nuw nsw i32 %1521, %1522
  %1524 = icmp eq i32 %1523, 2
  %1525 = zext i1 %1524 to i8
  store i8 %1525, i8* %40, align 1, !tbaa !2450
  %1526 = add i64 %1488, -28
  %1527 = add i64 %1490, 9
  store i64 %1527, i64* %PC, align 8
  %1528 = inttoptr i64 %1526 to i32*
  store i32 %1499, i32* %1528, align 4
  %.pre26 = load i64, i64* %PC, align 8
  br label %block_403cc0

block_403ffb:                                     ; preds = %block_403cc0
  %1529 = add i64 %1625, -60
  %1530 = add i64 %1675, 8
  store i64 %1530, i64* %PC, align 8
  %1531 = inttoptr i64 %1529 to i32*
  %1532 = load i32, i32* %1531, align 4
  %1533 = zext i32 %1532 to i64
  store i64 %1533, i64* %RAX, align 8, !tbaa !2428
  %1534 = add i64 %1675, 11
  store i64 %1534, i64* %PC, align 8
  %1535 = load i32, i32* %1638, align 4
  %1536 = add i32 %1535, %1532
  %1537 = zext i32 %1536 to i64
  store i64 %1537, i64* %RAX, align 8, !tbaa !2428
  %1538 = icmp ult i32 %1536, %1532
  %1539 = icmp ult i32 %1536, %1535
  %1540 = or i1 %1538, %1539
  %1541 = zext i1 %1540 to i8
  store i8 %1541, i8* %15, align 1, !tbaa !2432
  %1542 = and i32 %1536, 255
  %1543 = tail call i32 @llvm.ctpop.i32(i32 %1542) #11
  %1544 = trunc i32 %1543 to i8
  %1545 = and i8 %1544, 1
  %1546 = xor i8 %1545, 1
  store i8 %1546, i8* %22, align 1, !tbaa !2446
  %1547 = xor i32 %1535, %1532
  %1548 = xor i32 %1547, %1536
  %1549 = lshr i32 %1548, 4
  %1550 = trunc i32 %1549 to i8
  %1551 = and i8 %1550, 1
  store i8 %1551, i8* %28, align 1, !tbaa !2447
  %1552 = icmp eq i32 %1536, 0
  %1553 = zext i1 %1552 to i8
  store i8 %1553, i8* %31, align 1, !tbaa !2448
  %1554 = lshr i32 %1536, 31
  %1555 = trunc i32 %1554 to i8
  store i8 %1555, i8* %34, align 1, !tbaa !2449
  %1556 = lshr i32 %1532, 31
  %1557 = lshr i32 %1535, 31
  %1558 = xor i32 %1554, %1556
  %1559 = xor i32 %1554, %1557
  %1560 = add nuw nsw i32 %1558, %1559
  %1561 = icmp eq i32 %1560, 2
  %1562 = zext i1 %1561 to i8
  store i8 %1562, i8* %40, align 1, !tbaa !2450
  %1563 = add i64 %1675, 14
  store i64 %1563, i64* %PC, align 8
  store i32 %1536, i32* %1638, align 4
  %1564 = load i64, i64* %PC, align 8
  %1565 = add i64 %1564, -1910
  store i64 %1565, i64* %PC, align 8, !tbaa !2428
  br label %block_403893

block_40400e:                                     ; preds = %block_403893
  %1566 = load i64, i64* %RSP, align 8
  %1567 = add i64 %1566, 48
  store i64 %1567, i64* %RSP, align 8, !tbaa !2428
  %1568 = icmp ugt i64 %1566, -49
  %1569 = zext i1 %1568 to i8
  store i8 %1569, i8* %15, align 1, !tbaa !2432
  %1570 = trunc i64 %1567 to i32
  %1571 = and i32 %1570, 255
  %1572 = tail call i32 @llvm.ctpop.i32(i32 %1571) #11
  %1573 = trunc i32 %1572 to i8
  %1574 = and i8 %1573, 1
  %1575 = xor i8 %1574, 1
  store i8 %1575, i8* %22, align 1, !tbaa !2446
  %1576 = xor i64 %1566, 16
  %1577 = xor i64 %1576, %1567
  %1578 = lshr i64 %1577, 4
  %1579 = trunc i64 %1578 to i8
  %1580 = and i8 %1579, 1
  store i8 %1580, i8* %28, align 1, !tbaa !2447
  %1581 = icmp eq i64 %1567, 0
  %1582 = zext i1 %1581 to i8
  store i8 %1582, i8* %31, align 1, !tbaa !2448
  %1583 = lshr i64 %1567, 63
  %1584 = trunc i64 %1583 to i8
  store i8 %1584, i8* %34, align 1, !tbaa !2449
  %1585 = lshr i64 %1566, 63
  %1586 = xor i64 %1583, %1585
  %1587 = add nuw nsw i64 %1586, %1583
  %1588 = icmp eq i64 %1587, 2
  %1589 = zext i1 %1588 to i8
  store i8 %1589, i8* %40, align 1, !tbaa !2450
  %1590 = add i64 %3709, 5
  store i64 %1590, i64* %PC, align 8
  %1591 = add i64 %1566, 56
  %1592 = inttoptr i64 %1567 to i64*
  %1593 = load i64, i64* %1592, align 8
  store i64 %1593, i64* %RBP, align 8, !tbaa !2428
  store i64 %1591, i64* %RSP, align 8, !tbaa !2428
  %1594 = add i64 %3709, 6
  store i64 %1594, i64* %PC, align 8
  %1595 = inttoptr i64 %1591 to i64*
  %1596 = load i64, i64* %1595, align 8
  store i64 %1596, i64* %PC, align 8, !tbaa !2428
  %1597 = add i64 %1566, 64
  store i64 %1597, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_4035ad:                                     ; preds = %block_403356
  %1598 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %1599 = add i64 %2743, -24
  %1600 = add i64 %2779, 4
  store i64 %1600, i64* %PC, align 8
  %1601 = inttoptr i64 %1599 to i64*
  %1602 = load i64, i64* %1601, align 8
  store i64 %1602, i64* %RAX, align 8, !tbaa !2428
  %1603 = add i64 %1602, 16
  %1604 = add i64 %2779, 9
  store i64 %1604, i64* %PC, align 8
  %1605 = inttoptr i64 %1603 to i64*
  %1606 = load i64, i64* %1605, align 8
  store i64 %1606, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1607 = add i64 %2743, -72
  %1608 = add i64 %2779, 14
  store i64 %1608, i64* %PC, align 8
  %1609 = inttoptr i64 %1607 to i64*
  store i64 %1606, i64* %1609, align 8
  %1610 = load i64, i64* %RBP, align 8
  %1611 = add i64 %1610, -56
  %1612 = load i64, i64* %PC, align 8
  %1613 = add i64 %1612, 3
  store i64 %1613, i64* %PC, align 8
  %1614 = inttoptr i64 %1611 to i32*
  %1615 = load i32, i32* %1614, align 4
  %1616 = zext i32 %1615 to i64
  store i64 %1616, i64* %RCX, align 8, !tbaa !2428
  %1617 = add i64 %1610, -28
  %1618 = add i64 %1612, 6
  store i64 %1618, i64* %PC, align 8
  %1619 = inttoptr i64 %1617 to i32*
  store i32 %1615, i32* %1619, align 4
  %1620 = bitcast %union.VectorReg* %1598 to double*
  %1621 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %1598, i64 0, i32 0, i32 0, i32 0, i64 0
  %1622 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %1623 = bitcast i64* %1622 to double*
  %.pre23 = load i64, i64* %PC, align 8
  br label %block_4035c1

block_403cc0:                                     ; preds = %block_403cd6, %block_403c52
  %1624 = phi i64 [ %2741, %block_403cd6 ], [ %.pre26, %block_403c52 ]
  %1625 = load i64, i64* %RBP, align 8
  %1626 = add i64 %1625, -28
  %1627 = add i64 %1624, 3
  store i64 %1627, i64* %PC, align 8
  %1628 = inttoptr i64 %1626 to i32*
  %1629 = load i32, i32* %1628, align 4
  %1630 = zext i32 %1629 to i64
  store i64 %1630, i64* %RAX, align 8, !tbaa !2428
  %1631 = add i64 %1625, -8
  %1632 = add i64 %1624, 6
  store i64 %1632, i64* %PC, align 8
  %1633 = inttoptr i64 %1631 to i32*
  %1634 = load i32, i32* %1633, align 4
  %1635 = zext i32 %1634 to i64
  store i64 %1635, i64* %RCX, align 8, !tbaa !2428
  %1636 = add i64 %1625, -44
  %1637 = add i64 %1624, 9
  store i64 %1637, i64* %PC, align 8
  %1638 = inttoptr i64 %1636 to i32*
  %1639 = load i32, i32* %1638, align 4
  %1640 = zext i32 %1639 to i64
  store i64 %1640, i64* %RDX, align 8, !tbaa !2428
  %1641 = add i64 %1625, -56
  %1642 = add i64 %1624, 12
  store i64 %1642, i64* %PC, align 8
  %1643 = inttoptr i64 %1641 to i32*
  %1644 = load i32, i32* %1643, align 4
  %1645 = add i32 %1644, %1639
  %1646 = zext i32 %1645 to i64
  store i64 %1646, i64* %RDX, align 8, !tbaa !2428
  %1647 = add i32 %1645, %1634
  %1648 = zext i32 %1647 to i64
  store i64 %1648, i64* %RCX, align 8, !tbaa !2428
  %1649 = lshr i32 %1647, 31
  %1650 = sub i32 %1629, %1647
  %1651 = icmp ult i32 %1629, %1647
  %1652 = zext i1 %1651 to i8
  store i8 %1652, i8* %15, align 1, !tbaa !2432
  %1653 = and i32 %1650, 255
  %1654 = tail call i32 @llvm.ctpop.i32(i32 %1653) #11
  %1655 = trunc i32 %1654 to i8
  %1656 = and i8 %1655, 1
  %1657 = xor i8 %1656, 1
  store i8 %1657, i8* %22, align 1, !tbaa !2446
  %1658 = xor i32 %1647, %1629
  %1659 = xor i32 %1658, %1650
  %1660 = lshr i32 %1659, 4
  %1661 = trunc i32 %1660 to i8
  %1662 = and i8 %1661, 1
  store i8 %1662, i8* %28, align 1, !tbaa !2447
  %1663 = icmp eq i32 %1650, 0
  %1664 = zext i1 %1663 to i8
  store i8 %1664, i8* %31, align 1, !tbaa !2448
  %1665 = lshr i32 %1650, 31
  %1666 = trunc i32 %1665 to i8
  store i8 %1666, i8* %34, align 1, !tbaa !2449
  %1667 = lshr i32 %1629, 31
  %1668 = xor i32 %1649, %1667
  %1669 = xor i32 %1665, %1667
  %1670 = add nuw nsw i32 %1669, %1668
  %1671 = icmp eq i32 %1670, 2
  %1672 = zext i1 %1671 to i8
  store i8 %1672, i8* %40, align 1, !tbaa !2450
  %1673 = icmp ne i8 %1666, 0
  %1674 = xor i1 %1673, %1671
  %.v30 = select i1 %1674, i64 22, i64 827
  %1675 = add i64 %.v30, %1624
  store i64 %1675, i64* %PC, align 8, !tbaa !2428
  br i1 %1674, label %block_403cd6, label %block_403ffb

block_403cd6:                                     ; preds = %block_403cc0
  store i64 -9223372036854775808, i64* %RAX, align 8, !tbaa !2428
  %1676 = add i64 %1675, 13
  store i64 %1676, i64* %PC, align 8
  %1677 = load i32, i32* %1628, align 4
  %1678 = zext i32 %1677 to i64
  store i64 %1678, i64* %RCX, align 8, !tbaa !2428
  %1679 = add i64 %1675, 16
  store i64 %1679, i64* %PC, align 8
  %1680 = load i32, i32* %1633, align 4
  %1681 = add i32 %1680, %1677
  %1682 = zext i32 %1681 to i64
  store i64 %1682, i64* %RCX, align 8, !tbaa !2428
  %1683 = icmp ult i32 %1681, %1677
  %1684 = icmp ult i32 %1681, %1680
  %1685 = or i1 %1683, %1684
  %1686 = zext i1 %1685 to i8
  store i8 %1686, i8* %15, align 1, !tbaa !2432
  %1687 = and i32 %1681, 255
  %1688 = tail call i32 @llvm.ctpop.i32(i32 %1687) #11
  %1689 = trunc i32 %1688 to i8
  %1690 = and i8 %1689, 1
  %1691 = xor i8 %1690, 1
  store i8 %1691, i8* %22, align 1, !tbaa !2446
  %1692 = xor i32 %1680, %1677
  %1693 = xor i32 %1692, %1681
  %1694 = lshr i32 %1693, 4
  %1695 = trunc i32 %1694 to i8
  %1696 = and i8 %1695, 1
  store i8 %1696, i8* %28, align 1, !tbaa !2447
  %1697 = icmp eq i32 %1681, 0
  %1698 = zext i1 %1697 to i8
  store i8 %1698, i8* %31, align 1, !tbaa !2448
  %1699 = lshr i32 %1681, 31
  %1700 = trunc i32 %1699 to i8
  store i8 %1700, i8* %34, align 1, !tbaa !2449
  %1701 = lshr i32 %1677, 31
  %1702 = lshr i32 %1680, 31
  %1703 = xor i32 %1699, %1701
  %1704 = xor i32 %1699, %1702
  %1705 = add nuw nsw i32 %1703, %1704
  %1706 = icmp eq i32 %1705, 2
  %1707 = zext i1 %1706 to i8
  store i8 %1707, i8* %40, align 1, !tbaa !2450
  %1708 = add i64 %1625, -32
  %1709 = add i64 %1675, 19
  store i64 %1709, i64* %PC, align 8
  %1710 = inttoptr i64 %1708 to i32*
  store i32 %1681, i32* %1710, align 4
  %1711 = load i64, i64* %RBP, align 8
  %1712 = add i64 %1711, -32
  %1713 = load i64, i64* %PC, align 8
  %1714 = add i64 %1713, 3
  store i64 %1714, i64* %PC, align 8
  %1715 = inttoptr i64 %1712 to i32*
  %1716 = load i32, i32* %1715, align 4
  %1717 = zext i32 %1716 to i64
  store i64 %1717, i64* %RCX, align 8, !tbaa !2428
  %1718 = add i64 %1711, -8
  %1719 = add i64 %1713, 6
  store i64 %1719, i64* %PC, align 8
  %1720 = inttoptr i64 %1718 to i32*
  %1721 = load i32, i32* %1720, align 4
  %1722 = add i32 %1721, %1716
  %1723 = zext i32 %1722 to i64
  store i64 %1723, i64* %RCX, align 8, !tbaa !2428
  %1724 = icmp ult i32 %1722, %1716
  %1725 = icmp ult i32 %1722, %1721
  %1726 = or i1 %1724, %1725
  %1727 = zext i1 %1726 to i8
  store i8 %1727, i8* %15, align 1, !tbaa !2432
  %1728 = and i32 %1722, 255
  %1729 = tail call i32 @llvm.ctpop.i32(i32 %1728) #11
  %1730 = trunc i32 %1729 to i8
  %1731 = and i8 %1730, 1
  %1732 = xor i8 %1731, 1
  store i8 %1732, i8* %22, align 1, !tbaa !2446
  %1733 = xor i32 %1721, %1716
  %1734 = xor i32 %1733, %1722
  %1735 = lshr i32 %1734, 4
  %1736 = trunc i32 %1735 to i8
  %1737 = and i8 %1736, 1
  store i8 %1737, i8* %28, align 1, !tbaa !2447
  %1738 = icmp eq i32 %1722, 0
  %1739 = zext i1 %1738 to i8
  store i8 %1739, i8* %31, align 1, !tbaa !2448
  %1740 = lshr i32 %1722, 31
  %1741 = trunc i32 %1740 to i8
  store i8 %1741, i8* %34, align 1, !tbaa !2449
  %1742 = lshr i32 %1716, 31
  %1743 = lshr i32 %1721, 31
  %1744 = xor i32 %1740, %1742
  %1745 = xor i32 %1740, %1743
  %1746 = add nuw nsw i32 %1744, %1745
  %1747 = icmp eq i32 %1746, 2
  %1748 = zext i1 %1747 to i8
  store i8 %1748, i8* %40, align 1, !tbaa !2450
  %1749 = add i64 %1711, -36
  %1750 = add i64 %1713, 9
  store i64 %1750, i64* %PC, align 8
  %1751 = inttoptr i64 %1749 to i32*
  store i32 %1722, i32* %1751, align 4
  %1752 = load i64, i64* %RBP, align 8
  %1753 = add i64 %1752, -36
  %1754 = load i64, i64* %PC, align 8
  %1755 = add i64 %1754, 3
  store i64 %1755, i64* %PC, align 8
  %1756 = inttoptr i64 %1753 to i32*
  %1757 = load i32, i32* %1756, align 4
  %1758 = zext i32 %1757 to i64
  store i64 %1758, i64* %RCX, align 8, !tbaa !2428
  %1759 = add i64 %1752, -8
  %1760 = add i64 %1754, 6
  store i64 %1760, i64* %PC, align 8
  %1761 = inttoptr i64 %1759 to i32*
  %1762 = load i32, i32* %1761, align 4
  %1763 = add i32 %1762, %1757
  %1764 = zext i32 %1763 to i64
  store i64 %1764, i64* %RCX, align 8, !tbaa !2428
  %1765 = icmp ult i32 %1763, %1757
  %1766 = icmp ult i32 %1763, %1762
  %1767 = or i1 %1765, %1766
  %1768 = zext i1 %1767 to i8
  store i8 %1768, i8* %15, align 1, !tbaa !2432
  %1769 = and i32 %1763, 255
  %1770 = tail call i32 @llvm.ctpop.i32(i32 %1769) #11
  %1771 = trunc i32 %1770 to i8
  %1772 = and i8 %1771, 1
  %1773 = xor i8 %1772, 1
  store i8 %1773, i8* %22, align 1, !tbaa !2446
  %1774 = xor i32 %1762, %1757
  %1775 = xor i32 %1774, %1763
  %1776 = lshr i32 %1775, 4
  %1777 = trunc i32 %1776 to i8
  %1778 = and i8 %1777, 1
  store i8 %1778, i8* %28, align 1, !tbaa !2447
  %1779 = icmp eq i32 %1763, 0
  %1780 = zext i1 %1779 to i8
  store i8 %1780, i8* %31, align 1, !tbaa !2448
  %1781 = lshr i32 %1763, 31
  %1782 = trunc i32 %1781 to i8
  store i8 %1782, i8* %34, align 1, !tbaa !2449
  %1783 = lshr i32 %1757, 31
  %1784 = lshr i32 %1762, 31
  %1785 = xor i32 %1781, %1783
  %1786 = xor i32 %1781, %1784
  %1787 = add nuw nsw i32 %1785, %1786
  %1788 = icmp eq i32 %1787, 2
  %1789 = zext i1 %1788 to i8
  store i8 %1789, i8* %40, align 1, !tbaa !2450
  %1790 = add i64 %1752, -40
  %1791 = add i64 %1754, 9
  store i64 %1791, i64* %PC, align 8
  %1792 = inttoptr i64 %1790 to i32*
  store i32 %1763, i32* %1792, align 4
  %1793 = load i64, i64* %RBP, align 8
  %1794 = add i64 %1793, -16
  %1795 = load i64, i64* %PC, align 8
  %1796 = add i64 %1795, 4
  store i64 %1796, i64* %PC, align 8
  %1797 = inttoptr i64 %1794 to i64*
  %1798 = load i64, i64* %1797, align 8
  store i64 %1798, i64* %RDX, align 8, !tbaa !2428
  %1799 = add i64 %1793, -28
  %1800 = add i64 %1795, 8
  store i64 %1800, i64* %PC, align 8
  %1801 = inttoptr i64 %1799 to i32*
  %1802 = load i32, i32* %1801, align 4
  %1803 = sext i32 %1802 to i64
  store i64 %1803, i64* %RSI, align 8, !tbaa !2428
  %1804 = shl nsw i64 %1803, 3
  %1805 = add i64 %1804, %1798
  %1806 = add i64 %1795, 13
  store i64 %1806, i64* %PC, align 8
  %1807 = inttoptr i64 %1805 to i64*
  %1808 = load i64, i64* %1807, align 8
  store i64 %1808, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1809 = add i64 %1795, 17
  store i64 %1809, i64* %PC, align 8
  %1810 = load i64, i64* %1797, align 8
  store i64 %1810, i64* %RDX, align 8, !tbaa !2428
  %1811 = add i64 %1793, -32
  %1812 = add i64 %1795, 21
  store i64 %1812, i64* %PC, align 8
  %1813 = inttoptr i64 %1811 to i32*
  %1814 = load i32, i32* %1813, align 4
  %1815 = sext i32 %1814 to i64
  store i64 %1815, i64* %RSI, align 8, !tbaa !2428
  %1816 = shl nsw i64 %1815, 3
  %1817 = add i64 %1816, %1810
  %1818 = add i64 %1795, 26
  store i64 %1818, i64* %PC, align 8
  %1819 = bitcast i64 %1808 to double
  %1820 = inttoptr i64 %1817 to double*
  %1821 = load double, double* %1820, align 8
  %1822 = fadd double %1819, %1821
  store double %1822, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %1823 = add i64 %1793, -120
  %1824 = add i64 %1795, 31
  store i64 %1824, i64* %PC, align 8
  %1825 = inttoptr i64 %1823 to double*
  store double %1822, double* %1825, align 8
  %1826 = load i64, i64* %RBP, align 8
  %1827 = add i64 %1826, -16
  %1828 = load i64, i64* %PC, align 8
  %1829 = add i64 %1828, 4
  store i64 %1829, i64* %PC, align 8
  %1830 = inttoptr i64 %1827 to i64*
  %1831 = load i64, i64* %1830, align 8
  store i64 %1831, i64* %RDX, align 8, !tbaa !2428
  %1832 = add i64 %1826, -28
  %1833 = add i64 %1828, 7
  store i64 %1833, i64* %PC, align 8
  %1834 = inttoptr i64 %1832 to i32*
  %1835 = load i32, i32* %1834, align 4
  %1836 = add i32 %1835, 1
  %1837 = zext i32 %1836 to i64
  store i64 %1837, i64* %RCX, align 8, !tbaa !2428
  %1838 = icmp eq i32 %1835, -1
  %1839 = icmp eq i32 %1836, 0
  %1840 = or i1 %1838, %1839
  %1841 = zext i1 %1840 to i8
  store i8 %1841, i8* %15, align 1, !tbaa !2432
  %1842 = and i32 %1836, 255
  %1843 = tail call i32 @llvm.ctpop.i32(i32 %1842) #11
  %1844 = trunc i32 %1843 to i8
  %1845 = and i8 %1844, 1
  %1846 = xor i8 %1845, 1
  store i8 %1846, i8* %22, align 1, !tbaa !2446
  %1847 = xor i32 %1836, %1835
  %1848 = lshr i32 %1847, 4
  %1849 = trunc i32 %1848 to i8
  %1850 = and i8 %1849, 1
  store i8 %1850, i8* %28, align 1, !tbaa !2447
  %1851 = zext i1 %1839 to i8
  store i8 %1851, i8* %31, align 1, !tbaa !2448
  %1852 = lshr i32 %1836, 31
  %1853 = trunc i32 %1852 to i8
  store i8 %1853, i8* %34, align 1, !tbaa !2449
  %1854 = lshr i32 %1835, 31
  %1855 = xor i32 %1852, %1854
  %1856 = add nuw nsw i32 %1855, %1852
  %1857 = icmp eq i32 %1856, 2
  %1858 = zext i1 %1857 to i8
  store i8 %1858, i8* %40, align 1, !tbaa !2450
  %1859 = sext i32 %1836 to i64
  store i64 %1859, i64* %RSI, align 8, !tbaa !2428
  %1860 = shl nsw i64 %1859, 3
  %1861 = add i64 %1860, %1831
  %1862 = add i64 %1828, 18
  store i64 %1862, i64* %PC, align 8
  %1863 = inttoptr i64 %1861 to i64*
  %1864 = load i64, i64* %1863, align 8
  store i64 %1864, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1865 = add i64 %1828, 22
  store i64 %1865, i64* %PC, align 8
  %1866 = load i64, i64* %1830, align 8
  store i64 %1866, i64* %RDX, align 8, !tbaa !2428
  %1867 = add i64 %1826, -32
  %1868 = add i64 %1828, 25
  store i64 %1868, i64* %PC, align 8
  %1869 = inttoptr i64 %1867 to i32*
  %1870 = load i32, i32* %1869, align 4
  %1871 = add i32 %1870, 1
  %1872 = zext i32 %1871 to i64
  store i64 %1872, i64* %RCX, align 8, !tbaa !2428
  %1873 = icmp eq i32 %1870, -1
  %1874 = icmp eq i32 %1871, 0
  %1875 = or i1 %1873, %1874
  %1876 = zext i1 %1875 to i8
  store i8 %1876, i8* %15, align 1, !tbaa !2432
  %1877 = and i32 %1871, 255
  %1878 = tail call i32 @llvm.ctpop.i32(i32 %1877) #11
  %1879 = trunc i32 %1878 to i8
  %1880 = and i8 %1879, 1
  %1881 = xor i8 %1880, 1
  store i8 %1881, i8* %22, align 1, !tbaa !2446
  %1882 = xor i32 %1871, %1870
  %1883 = lshr i32 %1882, 4
  %1884 = trunc i32 %1883 to i8
  %1885 = and i8 %1884, 1
  store i8 %1885, i8* %28, align 1, !tbaa !2447
  %1886 = zext i1 %1874 to i8
  store i8 %1886, i8* %31, align 1, !tbaa !2448
  %1887 = lshr i32 %1871, 31
  %1888 = trunc i32 %1887 to i8
  store i8 %1888, i8* %34, align 1, !tbaa !2449
  %1889 = lshr i32 %1870, 31
  %1890 = xor i32 %1887, %1889
  %1891 = add nuw nsw i32 %1890, %1887
  %1892 = icmp eq i32 %1891, 2
  %1893 = zext i1 %1892 to i8
  store i8 %1893, i8* %40, align 1, !tbaa !2450
  %1894 = sext i32 %1871 to i64
  store i64 %1894, i64* %RSI, align 8, !tbaa !2428
  %1895 = shl nsw i64 %1894, 3
  %1896 = add i64 %1895, %1866
  %1897 = add i64 %1828, 36
  store i64 %1897, i64* %PC, align 8
  %1898 = bitcast i64 %1864 to double
  %1899 = inttoptr i64 %1896 to double*
  %1900 = load double, double* %1899, align 8
  %1901 = fadd double %1898, %1900
  store double %1901, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %1902 = load i64, i64* %RBP, align 8
  %1903 = add i64 %1902, -128
  %1904 = add i64 %1828, 41
  store i64 %1904, i64* %PC, align 8
  %1905 = inttoptr i64 %1903 to double*
  store double %1901, double* %1905, align 8
  %1906 = load i64, i64* %RBP, align 8
  %1907 = add i64 %1906, -16
  %1908 = load i64, i64* %PC, align 8
  %1909 = add i64 %1908, 4
  store i64 %1909, i64* %PC, align 8
  %1910 = inttoptr i64 %1907 to i64*
  %1911 = load i64, i64* %1910, align 8
  store i64 %1911, i64* %RDX, align 8, !tbaa !2428
  %1912 = add i64 %1906, -28
  %1913 = add i64 %1908, 8
  store i64 %1913, i64* %PC, align 8
  %1914 = inttoptr i64 %1912 to i32*
  %1915 = load i32, i32* %1914, align 4
  %1916 = sext i32 %1915 to i64
  store i64 %1916, i64* %RSI, align 8, !tbaa !2428
  %1917 = shl nsw i64 %1916, 3
  %1918 = add i64 %1917, %1911
  %1919 = add i64 %1908, 13
  store i64 %1919, i64* %PC, align 8
  %1920 = inttoptr i64 %1918 to i64*
  %1921 = load i64, i64* %1920, align 8
  store i64 %1921, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1922 = add i64 %1908, 17
  store i64 %1922, i64* %PC, align 8
  %1923 = load i64, i64* %1910, align 8
  store i64 %1923, i64* %RDX, align 8, !tbaa !2428
  %1924 = add i64 %1906, -32
  %1925 = add i64 %1908, 21
  store i64 %1925, i64* %PC, align 8
  %1926 = inttoptr i64 %1924 to i32*
  %1927 = load i32, i32* %1926, align 4
  %1928 = sext i32 %1927 to i64
  store i64 %1928, i64* %RSI, align 8, !tbaa !2428
  %1929 = shl nsw i64 %1928, 3
  %1930 = add i64 %1929, %1923
  %1931 = add i64 %1908, 26
  store i64 %1931, i64* %PC, align 8
  %1932 = bitcast i64 %1921 to double
  %1933 = inttoptr i64 %1930 to double*
  %1934 = load double, double* %1933, align 8
  %1935 = fsub double %1932, %1934
  store double %1935, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %1936 = add i64 %1906, -136
  %1937 = add i64 %1908, 34
  store i64 %1937, i64* %PC, align 8
  %1938 = inttoptr i64 %1936 to double*
  store double %1935, double* %1938, align 8
  %1939 = load i64, i64* %RBP, align 8
  %1940 = add i64 %1939, -16
  %1941 = load i64, i64* %PC, align 8
  %1942 = add i64 %1941, 4
  store i64 %1942, i64* %PC, align 8
  %1943 = inttoptr i64 %1940 to i64*
  %1944 = load i64, i64* %1943, align 8
  store i64 %1944, i64* %RDX, align 8, !tbaa !2428
  %1945 = add i64 %1939, -28
  %1946 = add i64 %1941, 7
  store i64 %1946, i64* %PC, align 8
  %1947 = inttoptr i64 %1945 to i32*
  %1948 = load i32, i32* %1947, align 4
  %1949 = add i32 %1948, 1
  %1950 = zext i32 %1949 to i64
  store i64 %1950, i64* %RCX, align 8, !tbaa !2428
  %1951 = icmp eq i32 %1948, -1
  %1952 = icmp eq i32 %1949, 0
  %1953 = or i1 %1951, %1952
  %1954 = zext i1 %1953 to i8
  store i8 %1954, i8* %15, align 1, !tbaa !2432
  %1955 = and i32 %1949, 255
  %1956 = tail call i32 @llvm.ctpop.i32(i32 %1955) #11
  %1957 = trunc i32 %1956 to i8
  %1958 = and i8 %1957, 1
  %1959 = xor i8 %1958, 1
  store i8 %1959, i8* %22, align 1, !tbaa !2446
  %1960 = xor i32 %1949, %1948
  %1961 = lshr i32 %1960, 4
  %1962 = trunc i32 %1961 to i8
  %1963 = and i8 %1962, 1
  store i8 %1963, i8* %28, align 1, !tbaa !2447
  %1964 = zext i1 %1952 to i8
  store i8 %1964, i8* %31, align 1, !tbaa !2448
  %1965 = lshr i32 %1949, 31
  %1966 = trunc i32 %1965 to i8
  store i8 %1966, i8* %34, align 1, !tbaa !2449
  %1967 = lshr i32 %1948, 31
  %1968 = xor i32 %1965, %1967
  %1969 = add nuw nsw i32 %1968, %1965
  %1970 = icmp eq i32 %1969, 2
  %1971 = zext i1 %1970 to i8
  store i8 %1971, i8* %40, align 1, !tbaa !2450
  %1972 = sext i32 %1949 to i64
  store i64 %1972, i64* %RSI, align 8, !tbaa !2428
  %1973 = shl nsw i64 %1972, 3
  %1974 = add i64 %1973, %1944
  %1975 = add i64 %1941, 18
  store i64 %1975, i64* %PC, align 8
  %1976 = inttoptr i64 %1974 to i64*
  %1977 = load i64, i64* %1976, align 8
  store i64 %1977, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %1978 = add i64 %1941, 22
  store i64 %1978, i64* %PC, align 8
  %1979 = load i64, i64* %1943, align 8
  store i64 %1979, i64* %RDX, align 8, !tbaa !2428
  %1980 = add i64 %1939, -32
  %1981 = add i64 %1941, 25
  store i64 %1981, i64* %PC, align 8
  %1982 = inttoptr i64 %1980 to i32*
  %1983 = load i32, i32* %1982, align 4
  %1984 = add i32 %1983, 1
  %1985 = zext i32 %1984 to i64
  store i64 %1985, i64* %RCX, align 8, !tbaa !2428
  %1986 = icmp eq i32 %1983, -1
  %1987 = icmp eq i32 %1984, 0
  %1988 = or i1 %1986, %1987
  %1989 = zext i1 %1988 to i8
  store i8 %1989, i8* %15, align 1, !tbaa !2432
  %1990 = and i32 %1984, 255
  %1991 = tail call i32 @llvm.ctpop.i32(i32 %1990) #11
  %1992 = trunc i32 %1991 to i8
  %1993 = and i8 %1992, 1
  %1994 = xor i8 %1993, 1
  store i8 %1994, i8* %22, align 1, !tbaa !2446
  %1995 = xor i32 %1984, %1983
  %1996 = lshr i32 %1995, 4
  %1997 = trunc i32 %1996 to i8
  %1998 = and i8 %1997, 1
  store i8 %1998, i8* %28, align 1, !tbaa !2447
  %1999 = zext i1 %1987 to i8
  store i8 %1999, i8* %31, align 1, !tbaa !2448
  %2000 = lshr i32 %1984, 31
  %2001 = trunc i32 %2000 to i8
  store i8 %2001, i8* %34, align 1, !tbaa !2449
  %2002 = lshr i32 %1983, 31
  %2003 = xor i32 %2000, %2002
  %2004 = add nuw nsw i32 %2003, %2000
  %2005 = icmp eq i32 %2004, 2
  %2006 = zext i1 %2005 to i8
  store i8 %2006, i8* %40, align 1, !tbaa !2450
  %2007 = sext i32 %1984 to i64
  store i64 %2007, i64* %RSI, align 8, !tbaa !2428
  %2008 = shl nsw i64 %2007, 3
  %2009 = add i64 %2008, %1979
  %2010 = add i64 %1941, 36
  store i64 %2010, i64* %PC, align 8
  %2011 = bitcast i64 %1977 to double
  %2012 = inttoptr i64 %2009 to double*
  %2013 = load double, double* %2012, align 8
  %2014 = fsub double %2011, %2013
  store double %2014, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2015 = load i64, i64* %RBP, align 8
  %2016 = add i64 %2015, -144
  %2017 = add i64 %1941, 44
  store i64 %2017, i64* %PC, align 8
  %2018 = inttoptr i64 %2016 to double*
  store double %2014, double* %2018, align 8
  %2019 = load i64, i64* %RBP, align 8
  %2020 = add i64 %2019, -16
  %2021 = load i64, i64* %PC, align 8
  %2022 = add i64 %2021, 4
  store i64 %2022, i64* %PC, align 8
  %2023 = inttoptr i64 %2020 to i64*
  %2024 = load i64, i64* %2023, align 8
  store i64 %2024, i64* %RDX, align 8, !tbaa !2428
  %2025 = add i64 %2019, -36
  %2026 = add i64 %2021, 8
  store i64 %2026, i64* %PC, align 8
  %2027 = inttoptr i64 %2025 to i32*
  %2028 = load i32, i32* %2027, align 4
  %2029 = sext i32 %2028 to i64
  store i64 %2029, i64* %RSI, align 8, !tbaa !2428
  %2030 = shl nsw i64 %2029, 3
  %2031 = add i64 %2030, %2024
  %2032 = add i64 %2021, 13
  store i64 %2032, i64* %PC, align 8
  %2033 = inttoptr i64 %2031 to i64*
  %2034 = load i64, i64* %2033, align 8
  store i64 %2034, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2035 = add i64 %2021, 17
  store i64 %2035, i64* %PC, align 8
  %2036 = load i64, i64* %2023, align 8
  store i64 %2036, i64* %RDX, align 8, !tbaa !2428
  %2037 = add i64 %2019, -40
  %2038 = add i64 %2021, 21
  store i64 %2038, i64* %PC, align 8
  %2039 = inttoptr i64 %2037 to i32*
  %2040 = load i32, i32* %2039, align 4
  %2041 = sext i32 %2040 to i64
  store i64 %2041, i64* %RSI, align 8, !tbaa !2428
  %2042 = shl nsw i64 %2041, 3
  %2043 = add i64 %2042, %2036
  %2044 = add i64 %2021, 26
  store i64 %2044, i64* %PC, align 8
  %2045 = bitcast i64 %2034 to double
  %2046 = inttoptr i64 %2043 to double*
  %2047 = load double, double* %2046, align 8
  %2048 = fadd double %2045, %2047
  store double %2048, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2049 = add i64 %2019, -152
  %2050 = add i64 %2021, 34
  store i64 %2050, i64* %PC, align 8
  %2051 = inttoptr i64 %2049 to double*
  store double %2048, double* %2051, align 8
  %2052 = load i64, i64* %RBP, align 8
  %2053 = add i64 %2052, -16
  %2054 = load i64, i64* %PC, align 8
  %2055 = add i64 %2054, 4
  store i64 %2055, i64* %PC, align 8
  %2056 = inttoptr i64 %2053 to i64*
  %2057 = load i64, i64* %2056, align 8
  store i64 %2057, i64* %RDX, align 8, !tbaa !2428
  %2058 = add i64 %2052, -36
  %2059 = add i64 %2054, 7
  store i64 %2059, i64* %PC, align 8
  %2060 = inttoptr i64 %2058 to i32*
  %2061 = load i32, i32* %2060, align 4
  %2062 = add i32 %2061, 1
  %2063 = zext i32 %2062 to i64
  store i64 %2063, i64* %RCX, align 8, !tbaa !2428
  %2064 = icmp eq i32 %2061, -1
  %2065 = icmp eq i32 %2062, 0
  %2066 = or i1 %2064, %2065
  %2067 = zext i1 %2066 to i8
  store i8 %2067, i8* %15, align 1, !tbaa !2432
  %2068 = and i32 %2062, 255
  %2069 = tail call i32 @llvm.ctpop.i32(i32 %2068) #11
  %2070 = trunc i32 %2069 to i8
  %2071 = and i8 %2070, 1
  %2072 = xor i8 %2071, 1
  store i8 %2072, i8* %22, align 1, !tbaa !2446
  %2073 = xor i32 %2062, %2061
  %2074 = lshr i32 %2073, 4
  %2075 = trunc i32 %2074 to i8
  %2076 = and i8 %2075, 1
  store i8 %2076, i8* %28, align 1, !tbaa !2447
  %2077 = zext i1 %2065 to i8
  store i8 %2077, i8* %31, align 1, !tbaa !2448
  %2078 = lshr i32 %2062, 31
  %2079 = trunc i32 %2078 to i8
  store i8 %2079, i8* %34, align 1, !tbaa !2449
  %2080 = lshr i32 %2061, 31
  %2081 = xor i32 %2078, %2080
  %2082 = add nuw nsw i32 %2081, %2078
  %2083 = icmp eq i32 %2082, 2
  %2084 = zext i1 %2083 to i8
  store i8 %2084, i8* %40, align 1, !tbaa !2450
  %2085 = sext i32 %2062 to i64
  store i64 %2085, i64* %RSI, align 8, !tbaa !2428
  %2086 = shl nsw i64 %2085, 3
  %2087 = add i64 %2086, %2057
  %2088 = add i64 %2054, 18
  store i64 %2088, i64* %PC, align 8
  %2089 = inttoptr i64 %2087 to i64*
  %2090 = load i64, i64* %2089, align 8
  store i64 %2090, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2091 = add i64 %2054, 22
  store i64 %2091, i64* %PC, align 8
  %2092 = load i64, i64* %2056, align 8
  store i64 %2092, i64* %RDX, align 8, !tbaa !2428
  %2093 = add i64 %2052, -40
  %2094 = add i64 %2054, 25
  store i64 %2094, i64* %PC, align 8
  %2095 = inttoptr i64 %2093 to i32*
  %2096 = load i32, i32* %2095, align 4
  %2097 = add i32 %2096, 1
  %2098 = zext i32 %2097 to i64
  store i64 %2098, i64* %RCX, align 8, !tbaa !2428
  %2099 = icmp eq i32 %2096, -1
  %2100 = icmp eq i32 %2097, 0
  %2101 = or i1 %2099, %2100
  %2102 = zext i1 %2101 to i8
  store i8 %2102, i8* %15, align 1, !tbaa !2432
  %2103 = and i32 %2097, 255
  %2104 = tail call i32 @llvm.ctpop.i32(i32 %2103) #11
  %2105 = trunc i32 %2104 to i8
  %2106 = and i8 %2105, 1
  %2107 = xor i8 %2106, 1
  store i8 %2107, i8* %22, align 1, !tbaa !2446
  %2108 = xor i32 %2097, %2096
  %2109 = lshr i32 %2108, 4
  %2110 = trunc i32 %2109 to i8
  %2111 = and i8 %2110, 1
  store i8 %2111, i8* %28, align 1, !tbaa !2447
  %2112 = zext i1 %2100 to i8
  store i8 %2112, i8* %31, align 1, !tbaa !2448
  %2113 = lshr i32 %2097, 31
  %2114 = trunc i32 %2113 to i8
  store i8 %2114, i8* %34, align 1, !tbaa !2449
  %2115 = lshr i32 %2096, 31
  %2116 = xor i32 %2113, %2115
  %2117 = add nuw nsw i32 %2116, %2113
  %2118 = icmp eq i32 %2117, 2
  %2119 = zext i1 %2118 to i8
  store i8 %2119, i8* %40, align 1, !tbaa !2450
  %2120 = sext i32 %2097 to i64
  store i64 %2120, i64* %RSI, align 8, !tbaa !2428
  %2121 = shl nsw i64 %2120, 3
  %2122 = add i64 %2121, %2092
  %2123 = add i64 %2054, 36
  store i64 %2123, i64* %PC, align 8
  %2124 = bitcast i64 %2090 to double
  %2125 = inttoptr i64 %2122 to double*
  %2126 = load double, double* %2125, align 8
  %2127 = fadd double %2124, %2126
  store double %2127, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2128 = load i64, i64* %RBP, align 8
  %2129 = add i64 %2128, -160
  %2130 = add i64 %2054, 44
  store i64 %2130, i64* %PC, align 8
  %2131 = inttoptr i64 %2129 to double*
  store double %2127, double* %2131, align 8
  %2132 = load i64, i64* %RBP, align 8
  %2133 = add i64 %2132, -16
  %2134 = load i64, i64* %PC, align 8
  %2135 = add i64 %2134, 4
  store i64 %2135, i64* %PC, align 8
  %2136 = inttoptr i64 %2133 to i64*
  %2137 = load i64, i64* %2136, align 8
  store i64 %2137, i64* %RDX, align 8, !tbaa !2428
  %2138 = add i64 %2132, -36
  %2139 = add i64 %2134, 8
  store i64 %2139, i64* %PC, align 8
  %2140 = inttoptr i64 %2138 to i32*
  %2141 = load i32, i32* %2140, align 4
  %2142 = sext i32 %2141 to i64
  store i64 %2142, i64* %RSI, align 8, !tbaa !2428
  %2143 = shl nsw i64 %2142, 3
  %2144 = add i64 %2143, %2137
  %2145 = add i64 %2134, 13
  store i64 %2145, i64* %PC, align 8
  %2146 = inttoptr i64 %2144 to i64*
  %2147 = load i64, i64* %2146, align 8
  store i64 %2147, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2148 = add i64 %2134, 17
  store i64 %2148, i64* %PC, align 8
  %2149 = load i64, i64* %2136, align 8
  store i64 %2149, i64* %RDX, align 8, !tbaa !2428
  %2150 = add i64 %2132, -40
  %2151 = add i64 %2134, 21
  store i64 %2151, i64* %PC, align 8
  %2152 = inttoptr i64 %2150 to i32*
  %2153 = load i32, i32* %2152, align 4
  %2154 = sext i32 %2153 to i64
  store i64 %2154, i64* %RSI, align 8, !tbaa !2428
  %2155 = shl nsw i64 %2154, 3
  %2156 = add i64 %2155, %2149
  %2157 = add i64 %2134, 26
  store i64 %2157, i64* %PC, align 8
  %2158 = bitcast i64 %2147 to double
  %2159 = inttoptr i64 %2156 to double*
  %2160 = load double, double* %2159, align 8
  %2161 = fsub double %2158, %2160
  store double %2161, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2162 = add i64 %2132, -168
  %2163 = add i64 %2134, 34
  store i64 %2163, i64* %PC, align 8
  %2164 = inttoptr i64 %2162 to double*
  store double %2161, double* %2164, align 8
  %2165 = load i64, i64* %RBP, align 8
  %2166 = add i64 %2165, -16
  %2167 = load i64, i64* %PC, align 8
  %2168 = add i64 %2167, 4
  store i64 %2168, i64* %PC, align 8
  %2169 = inttoptr i64 %2166 to i64*
  %2170 = load i64, i64* %2169, align 8
  store i64 %2170, i64* %RDX, align 8, !tbaa !2428
  %2171 = add i64 %2165, -36
  %2172 = add i64 %2167, 7
  store i64 %2172, i64* %PC, align 8
  %2173 = inttoptr i64 %2171 to i32*
  %2174 = load i32, i32* %2173, align 4
  %2175 = add i32 %2174, 1
  %2176 = zext i32 %2175 to i64
  store i64 %2176, i64* %RCX, align 8, !tbaa !2428
  %2177 = icmp eq i32 %2174, -1
  %2178 = icmp eq i32 %2175, 0
  %2179 = or i1 %2177, %2178
  %2180 = zext i1 %2179 to i8
  store i8 %2180, i8* %15, align 1, !tbaa !2432
  %2181 = and i32 %2175, 255
  %2182 = tail call i32 @llvm.ctpop.i32(i32 %2181) #11
  %2183 = trunc i32 %2182 to i8
  %2184 = and i8 %2183, 1
  %2185 = xor i8 %2184, 1
  store i8 %2185, i8* %22, align 1, !tbaa !2446
  %2186 = xor i32 %2175, %2174
  %2187 = lshr i32 %2186, 4
  %2188 = trunc i32 %2187 to i8
  %2189 = and i8 %2188, 1
  store i8 %2189, i8* %28, align 1, !tbaa !2447
  %2190 = zext i1 %2178 to i8
  store i8 %2190, i8* %31, align 1, !tbaa !2448
  %2191 = lshr i32 %2175, 31
  %2192 = trunc i32 %2191 to i8
  store i8 %2192, i8* %34, align 1, !tbaa !2449
  %2193 = lshr i32 %2174, 31
  %2194 = xor i32 %2191, %2193
  %2195 = add nuw nsw i32 %2194, %2191
  %2196 = icmp eq i32 %2195, 2
  %2197 = zext i1 %2196 to i8
  store i8 %2197, i8* %40, align 1, !tbaa !2450
  %2198 = sext i32 %2175 to i64
  store i64 %2198, i64* %RSI, align 8, !tbaa !2428
  %2199 = shl nsw i64 %2198, 3
  %2200 = add i64 %2199, %2170
  %2201 = add i64 %2167, 18
  store i64 %2201, i64* %PC, align 8
  %2202 = inttoptr i64 %2200 to i64*
  %2203 = load i64, i64* %2202, align 8
  store i64 %2203, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2204 = add i64 %2167, 22
  store i64 %2204, i64* %PC, align 8
  %2205 = load i64, i64* %2169, align 8
  store i64 %2205, i64* %RDX, align 8, !tbaa !2428
  %2206 = add i64 %2165, -40
  %2207 = add i64 %2167, 25
  store i64 %2207, i64* %PC, align 8
  %2208 = inttoptr i64 %2206 to i32*
  %2209 = load i32, i32* %2208, align 4
  %2210 = add i32 %2209, 1
  %2211 = zext i32 %2210 to i64
  store i64 %2211, i64* %RCX, align 8, !tbaa !2428
  %2212 = icmp eq i32 %2209, -1
  %2213 = icmp eq i32 %2210, 0
  %2214 = or i1 %2212, %2213
  %2215 = zext i1 %2214 to i8
  store i8 %2215, i8* %15, align 1, !tbaa !2432
  %2216 = and i32 %2210, 255
  %2217 = tail call i32 @llvm.ctpop.i32(i32 %2216) #11
  %2218 = trunc i32 %2217 to i8
  %2219 = and i8 %2218, 1
  %2220 = xor i8 %2219, 1
  store i8 %2220, i8* %22, align 1, !tbaa !2446
  %2221 = xor i32 %2210, %2209
  %2222 = lshr i32 %2221, 4
  %2223 = trunc i32 %2222 to i8
  %2224 = and i8 %2223, 1
  store i8 %2224, i8* %28, align 1, !tbaa !2447
  %2225 = zext i1 %2213 to i8
  store i8 %2225, i8* %31, align 1, !tbaa !2448
  %2226 = lshr i32 %2210, 31
  %2227 = trunc i32 %2226 to i8
  store i8 %2227, i8* %34, align 1, !tbaa !2449
  %2228 = lshr i32 %2209, 31
  %2229 = xor i32 %2226, %2228
  %2230 = add nuw nsw i32 %2229, %2226
  %2231 = icmp eq i32 %2230, 2
  %2232 = zext i1 %2231 to i8
  store i8 %2232, i8* %40, align 1, !tbaa !2450
  %2233 = sext i32 %2210 to i64
  store i64 %2233, i64* %RSI, align 8, !tbaa !2428
  %2234 = shl nsw i64 %2233, 3
  %2235 = add i64 %2234, %2205
  %2236 = add i64 %2167, 36
  store i64 %2236, i64* %PC, align 8
  %2237 = bitcast i64 %2203 to double
  %2238 = inttoptr i64 %2235 to double*
  %2239 = load double, double* %2238, align 8
  %2240 = fsub double %2237, %2239
  store double %2240, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2241 = load i64, i64* %RBP, align 8
  %2242 = add i64 %2241, -176
  %2243 = add i64 %2167, 44
  store i64 %2243, i64* %PC, align 8
  %2244 = inttoptr i64 %2242 to double*
  store double %2240, double* %2244, align 8
  %2245 = load i64, i64* %RBP, align 8
  %2246 = add i64 %2245, -120
  %2247 = load i64, i64* %PC, align 8
  %2248 = add i64 %2247, 5
  store i64 %2248, i64* %PC, align 8
  %2249 = inttoptr i64 %2246 to i64*
  %2250 = load i64, i64* %2249, align 8
  store i64 %2250, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2251 = add i64 %2245, -152
  %2252 = add i64 %2247, 13
  store i64 %2252, i64* %PC, align 8
  %2253 = bitcast i64 %2250 to double
  %2254 = inttoptr i64 %2251 to double*
  %2255 = load double, double* %2254, align 8
  %2256 = fadd double %2253, %2255
  store double %2256, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2257 = add i64 %2245, -16
  %2258 = add i64 %2247, 17
  store i64 %2258, i64* %PC, align 8
  %2259 = inttoptr i64 %2257 to i64*
  %2260 = load i64, i64* %2259, align 8
  store i64 %2260, i64* %RDX, align 8, !tbaa !2428
  %2261 = add i64 %2245, -28
  %2262 = add i64 %2247, 21
  store i64 %2262, i64* %PC, align 8
  %2263 = inttoptr i64 %2261 to i32*
  %2264 = load i32, i32* %2263, align 4
  %2265 = sext i32 %2264 to i64
  store i64 %2265, i64* %RSI, align 8, !tbaa !2428
  %2266 = shl nsw i64 %2265, 3
  %2267 = add i64 %2266, %2260
  %2268 = add i64 %2247, 26
  store i64 %2268, i64* %PC, align 8
  %2269 = inttoptr i64 %2267 to double*
  store double %2256, double* %2269, align 8
  %2270 = load i64, i64* %RBP, align 8
  %2271 = add i64 %2270, -128
  %2272 = load i64, i64* %PC, align 8
  %2273 = add i64 %2272, 5
  store i64 %2273, i64* %PC, align 8
  %2274 = inttoptr i64 %2271 to i64*
  %2275 = load i64, i64* %2274, align 8
  store i64 %2275, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2276 = add i64 %2270, -160
  %2277 = add i64 %2272, 13
  store i64 %2277, i64* %PC, align 8
  %2278 = bitcast i64 %2275 to double
  %2279 = inttoptr i64 %2276 to double*
  %2280 = load double, double* %2279, align 8
  %2281 = fadd double %2278, %2280
  store double %2281, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2282 = add i64 %2270, -16
  %2283 = add i64 %2272, 17
  store i64 %2283, i64* %PC, align 8
  %2284 = inttoptr i64 %2282 to i64*
  %2285 = load i64, i64* %2284, align 8
  store i64 %2285, i64* %RDX, align 8, !tbaa !2428
  %2286 = add i64 %2270, -28
  %2287 = add i64 %2272, 20
  store i64 %2287, i64* %PC, align 8
  %2288 = inttoptr i64 %2286 to i32*
  %2289 = load i32, i32* %2288, align 4
  %2290 = add i32 %2289, 1
  %2291 = zext i32 %2290 to i64
  store i64 %2291, i64* %RCX, align 8, !tbaa !2428
  %2292 = icmp eq i32 %2289, -1
  %2293 = icmp eq i32 %2290, 0
  %2294 = or i1 %2292, %2293
  %2295 = zext i1 %2294 to i8
  store i8 %2295, i8* %15, align 1, !tbaa !2432
  %2296 = and i32 %2290, 255
  %2297 = tail call i32 @llvm.ctpop.i32(i32 %2296) #11
  %2298 = trunc i32 %2297 to i8
  %2299 = and i8 %2298, 1
  %2300 = xor i8 %2299, 1
  store i8 %2300, i8* %22, align 1, !tbaa !2446
  %2301 = xor i32 %2290, %2289
  %2302 = lshr i32 %2301, 4
  %2303 = trunc i32 %2302 to i8
  %2304 = and i8 %2303, 1
  store i8 %2304, i8* %28, align 1, !tbaa !2447
  %2305 = zext i1 %2293 to i8
  store i8 %2305, i8* %31, align 1, !tbaa !2448
  %2306 = lshr i32 %2290, 31
  %2307 = trunc i32 %2306 to i8
  store i8 %2307, i8* %34, align 1, !tbaa !2449
  %2308 = lshr i32 %2289, 31
  %2309 = xor i32 %2306, %2308
  %2310 = add nuw nsw i32 %2309, %2306
  %2311 = icmp eq i32 %2310, 2
  %2312 = zext i1 %2311 to i8
  store i8 %2312, i8* %40, align 1, !tbaa !2450
  %2313 = sext i32 %2290 to i64
  store i64 %2313, i64* %RSI, align 8, !tbaa !2428
  %2314 = shl nsw i64 %2313, 3
  %2315 = add i64 %2314, %2285
  %2316 = add i64 %2272, 31
  store i64 %2316, i64* %PC, align 8
  %2317 = inttoptr i64 %2315 to double*
  store double %2281, double* %2317, align 8
  %2318 = load i64, i64* %RBP, align 8
  %2319 = add i64 %2318, -152
  %2320 = load i64, i64* %PC, align 8
  %2321 = add i64 %2320, 8
  store i64 %2321, i64* %PC, align 8
  %2322 = inttoptr i64 %2319 to i64*
  %2323 = load i64, i64* %2322, align 8
  store i64 %2323, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2324 = add i64 %2318, -120
  %2325 = add i64 %2320, 13
  store i64 %2325, i64* %PC, align 8
  %2326 = inttoptr i64 %2324 to double*
  %2327 = load double, double* %2326, align 8
  %2328 = bitcast i64 %2323 to double
  %2329 = fsub double %2327, %2328
  store double %2329, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %2330 = add i64 %2320, 22
  store i64 %2330, i64* %PC, align 8
  store double %2329, double* %2326, align 8
  %2331 = load i64, i64* %RBP, align 8
  %2332 = add i64 %2331, -160
  %2333 = load i64, i64* %PC, align 8
  %2334 = add i64 %2333, 8
  store i64 %2334, i64* %PC, align 8
  %2335 = inttoptr i64 %2332 to i64*
  %2336 = load i64, i64* %2335, align 8
  store i64 %2336, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2337 = add i64 %2331, -128
  %2338 = add i64 %2333, 13
  store i64 %2338, i64* %PC, align 8
  %2339 = inttoptr i64 %2337 to double*
  %2340 = load double, double* %2339, align 8
  %2341 = bitcast i64 %2336 to double
  %2342 = fsub double %2340, %2341
  store double %2342, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %2343 = add i64 %2333, 22
  store i64 %2343, i64* %PC, align 8
  store double %2342, double* %2339, align 8
  %2344 = load i64, i64* %RBP, align 8
  %2345 = add i64 %2344, -96
  %2346 = load i64, i64* %PC, align 8
  %2347 = add i64 %2346, 5
  store i64 %2347, i64* %PC, align 8
  %2348 = inttoptr i64 %2345 to i64*
  %2349 = load i64, i64* %2348, align 8
  %2350 = load i64, i64* %RAX, align 8
  %2351 = xor i64 %2350, %2349
  store i64 %2351, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %15, align 1, !tbaa !2432
  %2352 = trunc i64 %2351 to i32
  %2353 = and i32 %2352, 255
  %2354 = tail call i32 @llvm.ctpop.i32(i32 %2353) #11
  %2355 = trunc i32 %2354 to i8
  %2356 = and i8 %2355, 1
  %2357 = xor i8 %2356, 1
  store i8 %2357, i8* %22, align 1, !tbaa !2446
  %2358 = icmp eq i64 %2351, 0
  %2359 = zext i1 %2358 to i8
  store i8 %2359, i8* %31, align 1, !tbaa !2448
  %2360 = lshr i64 %2351, 63
  %2361 = trunc i64 %2360 to i8
  store i8 %2361, i8* %34, align 1, !tbaa !2449
  store i8 0, i8* %40, align 1, !tbaa !2450
  store i8 0, i8* %28, align 1, !tbaa !2447
  store i64 %2351, i64* %93, align 1, !tbaa !2428
  store i64 0, i64* %94, align 1, !tbaa !2428
  %2362 = add i64 %2344, -120
  %2363 = add i64 %2346, 23
  store i64 %2363, i64* %PC, align 8
  %.cast9 = bitcast i64 %2351 to double
  %2364 = inttoptr i64 %2362 to double*
  %2365 = load double, double* %2364, align 8
  %2366 = fmul double %.cast9, %2365
  store double %2366, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2367 = add i64 %2344, -88
  %2368 = add i64 %2346, 28
  store i64 %2368, i64* %PC, align 8
  %2369 = inttoptr i64 %2367 to i64*
  %2370 = load i64, i64* %2369, align 8
  store i64 %2370, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %2371 = add i64 %2344, -128
  %2372 = add i64 %2346, 33
  store i64 %2372, i64* %PC, align 8
  %2373 = bitcast i64 %2370 to double
  %2374 = inttoptr i64 %2371 to double*
  %2375 = load double, double* %2374, align 8
  %2376 = fmul double %2373, %2375
  store double %2376, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %2377 = fsub double %2366, %2376
  store double %2377, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2378 = add i64 %2344, -16
  %2379 = add i64 %2346, 41
  store i64 %2379, i64* %PC, align 8
  %2380 = inttoptr i64 %2378 to i64*
  %2381 = load i64, i64* %2380, align 8
  store i64 %2381, i64* %RDX, align 8, !tbaa !2428
  %2382 = add i64 %2344, -36
  %2383 = add i64 %2346, 45
  store i64 %2383, i64* %PC, align 8
  %2384 = inttoptr i64 %2382 to i32*
  %2385 = load i32, i32* %2384, align 4
  %2386 = sext i32 %2385 to i64
  store i64 %2386, i64* %RSI, align 8, !tbaa !2428
  %2387 = shl nsw i64 %2386, 3
  %2388 = add i64 %2387, %2381
  %2389 = add i64 %2346, 50
  store i64 %2389, i64* %PC, align 8
  %2390 = inttoptr i64 %2388 to double*
  store double %2377, double* %2390, align 8
  %2391 = load i64, i64* %RBP, align 8
  %2392 = add i64 %2391, -96
  %2393 = load i64, i64* %PC, align 8
  %2394 = add i64 %2393, 5
  store i64 %2394, i64* %PC, align 8
  %2395 = inttoptr i64 %2392 to i64*
  %2396 = load i64, i64* %2395, align 8
  %2397 = load i64, i64* %RAX, align 8
  %2398 = xor i64 %2397, %2396
  store i64 %2398, i64* %RDX, align 8, !tbaa !2428
  store i8 0, i8* %15, align 1, !tbaa !2432
  %2399 = trunc i64 %2398 to i32
  %2400 = and i32 %2399, 255
  %2401 = tail call i32 @llvm.ctpop.i32(i32 %2400) #11
  %2402 = trunc i32 %2401 to i8
  %2403 = and i8 %2402, 1
  %2404 = xor i8 %2403, 1
  store i8 %2404, i8* %22, align 1, !tbaa !2446
  %2405 = icmp eq i64 %2398, 0
  %2406 = zext i1 %2405 to i8
  store i8 %2406, i8* %31, align 1, !tbaa !2448
  %2407 = lshr i64 %2398, 63
  %2408 = trunc i64 %2407 to i8
  store i8 %2408, i8* %34, align 1, !tbaa !2449
  store i8 0, i8* %40, align 1, !tbaa !2450
  store i8 0, i8* %28, align 1, !tbaa !2447
  store i64 %2398, i64* %93, align 1, !tbaa !2428
  store i64 0, i64* %94, align 1, !tbaa !2428
  %2409 = add i64 %2391, -128
  %2410 = add i64 %2393, 23
  store i64 %2410, i64* %PC, align 8
  %.cast10 = bitcast i64 %2398 to double
  %2411 = inttoptr i64 %2409 to double*
  %2412 = load double, double* %2411, align 8
  %2413 = fmul double %.cast10, %2412
  store double %2413, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2414 = add i64 %2391, -88
  %2415 = add i64 %2393, 28
  store i64 %2415, i64* %PC, align 8
  %2416 = inttoptr i64 %2414 to i64*
  %2417 = load i64, i64* %2416, align 8
  store i64 %2417, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %2418 = add i64 %2391, -120
  %2419 = add i64 %2393, 33
  store i64 %2419, i64* %PC, align 8
  %2420 = bitcast i64 %2417 to double
  %2421 = inttoptr i64 %2418 to double*
  %2422 = load double, double* %2421, align 8
  %2423 = fmul double %2420, %2422
  store double %2423, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %2424 = fadd double %2413, %2423
  store double %2424, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2425 = add i64 %2391, -16
  %2426 = add i64 %2393, 41
  store i64 %2426, i64* %PC, align 8
  %2427 = inttoptr i64 %2425 to i64*
  %2428 = load i64, i64* %2427, align 8
  store i64 %2428, i64* %RAX, align 8, !tbaa !2428
  %2429 = add i64 %2391, -36
  %2430 = add i64 %2393, 44
  store i64 %2430, i64* %PC, align 8
  %2431 = inttoptr i64 %2429 to i32*
  %2432 = load i32, i32* %2431, align 4
  %2433 = add i32 %2432, 1
  %2434 = zext i32 %2433 to i64
  store i64 %2434, i64* %RCX, align 8, !tbaa !2428
  %2435 = icmp eq i32 %2432, -1
  %2436 = icmp eq i32 %2433, 0
  %2437 = or i1 %2435, %2436
  %2438 = zext i1 %2437 to i8
  store i8 %2438, i8* %15, align 1, !tbaa !2432
  %2439 = and i32 %2433, 255
  %2440 = tail call i32 @llvm.ctpop.i32(i32 %2439) #11
  %2441 = trunc i32 %2440 to i8
  %2442 = and i8 %2441, 1
  %2443 = xor i8 %2442, 1
  store i8 %2443, i8* %22, align 1, !tbaa !2446
  %2444 = xor i32 %2433, %2432
  %2445 = lshr i32 %2444, 4
  %2446 = trunc i32 %2445 to i8
  %2447 = and i8 %2446, 1
  store i8 %2447, i8* %28, align 1, !tbaa !2447
  %2448 = zext i1 %2436 to i8
  store i8 %2448, i8* %31, align 1, !tbaa !2448
  %2449 = lshr i32 %2433, 31
  %2450 = trunc i32 %2449 to i8
  store i8 %2450, i8* %34, align 1, !tbaa !2449
  %2451 = lshr i32 %2432, 31
  %2452 = xor i32 %2449, %2451
  %2453 = add nuw nsw i32 %2452, %2449
  %2454 = icmp eq i32 %2453, 2
  %2455 = zext i1 %2454 to i8
  store i8 %2455, i8* %40, align 1, !tbaa !2450
  %2456 = sext i32 %2433 to i64
  store i64 %2456, i64* %RDX, align 8, !tbaa !2428
  %2457 = shl nsw i64 %2456, 3
  %2458 = add i64 %2457, %2428
  %2459 = add i64 %2393, 55
  store i64 %2459, i64* %PC, align 8
  %2460 = inttoptr i64 %2458 to double*
  store double %2424, double* %2460, align 8
  %2461 = load i64, i64* %RBP, align 8
  %2462 = add i64 %2461, -136
  %2463 = load i64, i64* %PC, align 8
  %2464 = add i64 %2463, 8
  store i64 %2464, i64* %PC, align 8
  %2465 = inttoptr i64 %2462 to i64*
  %2466 = load i64, i64* %2465, align 8
  store i64 %2466, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2467 = add i64 %2461, -176
  %2468 = add i64 %2463, 16
  store i64 %2468, i64* %PC, align 8
  %2469 = bitcast i64 %2466 to double
  %2470 = inttoptr i64 %2467 to double*
  %2471 = load double, double* %2470, align 8
  %2472 = fsub double %2469, %2471
  store double %2472, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2473 = add i64 %2461, -120
  %2474 = add i64 %2463, 21
  store i64 %2474, i64* %PC, align 8
  %2475 = inttoptr i64 %2473 to double*
  store double %2472, double* %2475, align 8
  %2476 = load i64, i64* %RBP, align 8
  %2477 = add i64 %2476, -144
  %2478 = load i64, i64* %PC, align 8
  %2479 = add i64 %2478, 8
  store i64 %2479, i64* %PC, align 8
  %2480 = inttoptr i64 %2477 to i64*
  %2481 = load i64, i64* %2480, align 8
  store i64 %2481, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2482 = add i64 %2476, -168
  %2483 = add i64 %2478, 16
  store i64 %2483, i64* %PC, align 8
  %2484 = bitcast i64 %2481 to double
  %2485 = inttoptr i64 %2482 to double*
  %2486 = load double, double* %2485, align 8
  %2487 = fadd double %2484, %2486
  store double %2487, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2488 = add i64 %2476, -128
  %2489 = add i64 %2478, 21
  store i64 %2489, i64* %PC, align 8
  %2490 = inttoptr i64 %2488 to double*
  store double %2487, double* %2490, align 8
  %2491 = load i64, i64* %RBP, align 8
  %2492 = add i64 %2491, -72
  %2493 = load i64, i64* %PC, align 8
  %2494 = add i64 %2493, 5
  store i64 %2494, i64* %PC, align 8
  %2495 = inttoptr i64 %2492 to i64*
  %2496 = load i64, i64* %2495, align 8
  store i64 %2496, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2497 = add i64 %2491, -120
  %2498 = add i64 %2493, 10
  store i64 %2498, i64* %PC, align 8
  %2499 = bitcast i64 %2496 to double
  %2500 = inttoptr i64 %2497 to double*
  %2501 = load double, double* %2500, align 8
  %2502 = fmul double %2499, %2501
  store double %2502, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2503 = add i64 %2491, -80
  %2504 = add i64 %2493, 15
  store i64 %2504, i64* %PC, align 8
  %2505 = inttoptr i64 %2503 to i64*
  %2506 = load i64, i64* %2505, align 8
  store i64 %2506, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %2507 = add i64 %2491, -128
  %2508 = add i64 %2493, 20
  store i64 %2508, i64* %PC, align 8
  %2509 = bitcast i64 %2506 to double
  %2510 = inttoptr i64 %2507 to double*
  %2511 = load double, double* %2510, align 8
  %2512 = fmul double %2509, %2511
  store double %2512, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %2513 = fsub double %2502, %2512
  store double %2513, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2514 = add i64 %2491, -16
  %2515 = add i64 %2493, 28
  store i64 %2515, i64* %PC, align 8
  %2516 = inttoptr i64 %2514 to i64*
  %2517 = load i64, i64* %2516, align 8
  store i64 %2517, i64* %RAX, align 8, !tbaa !2428
  %2518 = add i64 %2491, -32
  %2519 = add i64 %2493, 32
  store i64 %2519, i64* %PC, align 8
  %2520 = inttoptr i64 %2518 to i32*
  %2521 = load i32, i32* %2520, align 4
  %2522 = sext i32 %2521 to i64
  store i64 %2522, i64* %RDX, align 8, !tbaa !2428
  %2523 = shl nsw i64 %2522, 3
  %2524 = add i64 %2523, %2517
  %2525 = add i64 %2493, 37
  store i64 %2525, i64* %PC, align 8
  %2526 = inttoptr i64 %2524 to double*
  store double %2513, double* %2526, align 8
  %2527 = load i64, i64* %RBP, align 8
  %2528 = add i64 %2527, -72
  %2529 = load i64, i64* %PC, align 8
  %2530 = add i64 %2529, 5
  store i64 %2530, i64* %PC, align 8
  %2531 = inttoptr i64 %2528 to i64*
  %2532 = load i64, i64* %2531, align 8
  store i64 %2532, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2533 = add i64 %2527, -128
  %2534 = add i64 %2529, 10
  store i64 %2534, i64* %PC, align 8
  %2535 = bitcast i64 %2532 to double
  %2536 = inttoptr i64 %2533 to double*
  %2537 = load double, double* %2536, align 8
  %2538 = fmul double %2535, %2537
  store double %2538, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2539 = add i64 %2527, -80
  %2540 = add i64 %2529, 15
  store i64 %2540, i64* %PC, align 8
  %2541 = inttoptr i64 %2539 to i64*
  %2542 = load i64, i64* %2541, align 8
  store i64 %2542, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %2543 = add i64 %2527, -120
  %2544 = add i64 %2529, 20
  store i64 %2544, i64* %PC, align 8
  %2545 = bitcast i64 %2542 to double
  %2546 = inttoptr i64 %2543 to double*
  %2547 = load double, double* %2546, align 8
  %2548 = fmul double %2545, %2547
  store double %2548, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %2549 = fadd double %2538, %2548
  store double %2549, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2550 = add i64 %2527, -16
  %2551 = add i64 %2529, 28
  store i64 %2551, i64* %PC, align 8
  %2552 = inttoptr i64 %2550 to i64*
  %2553 = load i64, i64* %2552, align 8
  store i64 %2553, i64* %RAX, align 8, !tbaa !2428
  %2554 = add i64 %2527, -32
  %2555 = add i64 %2529, 31
  store i64 %2555, i64* %PC, align 8
  %2556 = inttoptr i64 %2554 to i32*
  %2557 = load i32, i32* %2556, align 4
  %2558 = add i32 %2557, 1
  %2559 = zext i32 %2558 to i64
  store i64 %2559, i64* %RCX, align 8, !tbaa !2428
  %2560 = icmp eq i32 %2557, -1
  %2561 = icmp eq i32 %2558, 0
  %2562 = or i1 %2560, %2561
  %2563 = zext i1 %2562 to i8
  store i8 %2563, i8* %15, align 1, !tbaa !2432
  %2564 = and i32 %2558, 255
  %2565 = tail call i32 @llvm.ctpop.i32(i32 %2564) #11
  %2566 = trunc i32 %2565 to i8
  %2567 = and i8 %2566, 1
  %2568 = xor i8 %2567, 1
  store i8 %2568, i8* %22, align 1, !tbaa !2446
  %2569 = xor i32 %2558, %2557
  %2570 = lshr i32 %2569, 4
  %2571 = trunc i32 %2570 to i8
  %2572 = and i8 %2571, 1
  store i8 %2572, i8* %28, align 1, !tbaa !2447
  %2573 = zext i1 %2561 to i8
  store i8 %2573, i8* %31, align 1, !tbaa !2448
  %2574 = lshr i32 %2558, 31
  %2575 = trunc i32 %2574 to i8
  store i8 %2575, i8* %34, align 1, !tbaa !2449
  %2576 = lshr i32 %2557, 31
  %2577 = xor i32 %2574, %2576
  %2578 = add nuw nsw i32 %2577, %2574
  %2579 = icmp eq i32 %2578, 2
  %2580 = zext i1 %2579 to i8
  store i8 %2580, i8* %40, align 1, !tbaa !2450
  %2581 = sext i32 %2558 to i64
  store i64 %2581, i64* %RDX, align 8, !tbaa !2428
  %2582 = shl nsw i64 %2581, 3
  %2583 = add i64 %2582, %2553
  %2584 = add i64 %2529, 42
  store i64 %2584, i64* %PC, align 8
  %2585 = inttoptr i64 %2583 to double*
  store double %2549, double* %2585, align 8
  %2586 = load i64, i64* %RBP, align 8
  %2587 = add i64 %2586, -136
  %2588 = load i64, i64* %PC, align 8
  %2589 = add i64 %2588, 8
  store i64 %2589, i64* %PC, align 8
  %2590 = inttoptr i64 %2587 to i64*
  %2591 = load i64, i64* %2590, align 8
  store i64 %2591, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2592 = add i64 %2586, -176
  %2593 = add i64 %2588, 16
  store i64 %2593, i64* %PC, align 8
  %2594 = bitcast i64 %2591 to double
  %2595 = inttoptr i64 %2592 to double*
  %2596 = load double, double* %2595, align 8
  %2597 = fadd double %2594, %2596
  store double %2597, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2598 = add i64 %2586, -120
  %2599 = add i64 %2588, 21
  store i64 %2599, i64* %PC, align 8
  %2600 = inttoptr i64 %2598 to double*
  store double %2597, double* %2600, align 8
  %2601 = load i64, i64* %RBP, align 8
  %2602 = add i64 %2601, -144
  %2603 = load i64, i64* %PC, align 8
  %2604 = add i64 %2603, 8
  store i64 %2604, i64* %PC, align 8
  %2605 = inttoptr i64 %2602 to i64*
  %2606 = load i64, i64* %2605, align 8
  store i64 %2606, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2607 = add i64 %2601, -168
  %2608 = add i64 %2603, 16
  store i64 %2608, i64* %PC, align 8
  %2609 = bitcast i64 %2606 to double
  %2610 = inttoptr i64 %2607 to double*
  %2611 = load double, double* %2610, align 8
  %2612 = fsub double %2609, %2611
  store double %2612, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2613 = add i64 %2601, -128
  %2614 = add i64 %2603, 21
  store i64 %2614, i64* %PC, align 8
  %2615 = inttoptr i64 %2613 to double*
  store double %2612, double* %2615, align 8
  %2616 = load i64, i64* %RBP, align 8
  %2617 = add i64 %2616, -104
  %2618 = load i64, i64* %PC, align 8
  %2619 = add i64 %2618, 5
  store i64 %2619, i64* %PC, align 8
  %2620 = inttoptr i64 %2617 to i64*
  %2621 = load i64, i64* %2620, align 8
  store i64 %2621, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2622 = add i64 %2616, -120
  %2623 = add i64 %2618, 10
  store i64 %2623, i64* %PC, align 8
  %2624 = bitcast i64 %2621 to double
  %2625 = inttoptr i64 %2622 to double*
  %2626 = load double, double* %2625, align 8
  %2627 = fmul double %2624, %2626
  store double %2627, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2628 = add i64 %2616, -112
  %2629 = add i64 %2618, 15
  store i64 %2629, i64* %PC, align 8
  %2630 = inttoptr i64 %2628 to i64*
  %2631 = load i64, i64* %2630, align 8
  store i64 %2631, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %2632 = add i64 %2616, -128
  %2633 = add i64 %2618, 20
  store i64 %2633, i64* %PC, align 8
  %2634 = bitcast i64 %2631 to double
  %2635 = inttoptr i64 %2632 to double*
  %2636 = load double, double* %2635, align 8
  %2637 = fmul double %2634, %2636
  store double %2637, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %2638 = fsub double %2627, %2637
  store double %2638, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2639 = add i64 %2616, -16
  %2640 = add i64 %2618, 28
  store i64 %2640, i64* %PC, align 8
  %2641 = inttoptr i64 %2639 to i64*
  %2642 = load i64, i64* %2641, align 8
  store i64 %2642, i64* %RAX, align 8, !tbaa !2428
  %2643 = add i64 %2616, -40
  %2644 = add i64 %2618, 32
  store i64 %2644, i64* %PC, align 8
  %2645 = inttoptr i64 %2643 to i32*
  %2646 = load i32, i32* %2645, align 4
  %2647 = sext i32 %2646 to i64
  store i64 %2647, i64* %RDX, align 8, !tbaa !2428
  %2648 = shl nsw i64 %2647, 3
  %2649 = add i64 %2648, %2642
  %2650 = add i64 %2618, 37
  store i64 %2650, i64* %PC, align 8
  %2651 = inttoptr i64 %2649 to double*
  store double %2638, double* %2651, align 8
  %2652 = load i64, i64* %RBP, align 8
  %2653 = add i64 %2652, -104
  %2654 = load i64, i64* %PC, align 8
  %2655 = add i64 %2654, 5
  store i64 %2655, i64* %PC, align 8
  %2656 = inttoptr i64 %2653 to i64*
  %2657 = load i64, i64* %2656, align 8
  store i64 %2657, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2658 = add i64 %2652, -128
  %2659 = add i64 %2654, 10
  store i64 %2659, i64* %PC, align 8
  %2660 = bitcast i64 %2657 to double
  %2661 = inttoptr i64 %2658 to double*
  %2662 = load double, double* %2661, align 8
  %2663 = fmul double %2660, %2662
  store double %2663, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2664 = add i64 %2652, -112
  %2665 = add i64 %2654, 15
  store i64 %2665, i64* %PC, align 8
  %2666 = inttoptr i64 %2664 to i64*
  %2667 = load i64, i64* %2666, align 8
  store i64 %2667, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %2668 = add i64 %2652, -120
  %2669 = add i64 %2654, 20
  store i64 %2669, i64* %PC, align 8
  %2670 = bitcast i64 %2667 to double
  %2671 = inttoptr i64 %2668 to double*
  %2672 = load double, double* %2671, align 8
  %2673 = fmul double %2670, %2672
  store double %2673, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %2674 = fadd double %2663, %2673
  store double %2674, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2675 = add i64 %2652, -16
  %2676 = add i64 %2654, 28
  store i64 %2676, i64* %PC, align 8
  %2677 = inttoptr i64 %2675 to i64*
  %2678 = load i64, i64* %2677, align 8
  store i64 %2678, i64* %RAX, align 8, !tbaa !2428
  %2679 = add i64 %2652, -40
  %2680 = add i64 %2654, 31
  store i64 %2680, i64* %PC, align 8
  %2681 = inttoptr i64 %2679 to i32*
  %2682 = load i32, i32* %2681, align 4
  %2683 = add i32 %2682, 1
  %2684 = zext i32 %2683 to i64
  store i64 %2684, i64* %RCX, align 8, !tbaa !2428
  %2685 = icmp eq i32 %2682, -1
  %2686 = icmp eq i32 %2683, 0
  %2687 = or i1 %2685, %2686
  %2688 = zext i1 %2687 to i8
  store i8 %2688, i8* %15, align 1, !tbaa !2432
  %2689 = and i32 %2683, 255
  %2690 = tail call i32 @llvm.ctpop.i32(i32 %2689) #11
  %2691 = trunc i32 %2690 to i8
  %2692 = and i8 %2691, 1
  %2693 = xor i8 %2692, 1
  store i8 %2693, i8* %22, align 1, !tbaa !2446
  %2694 = xor i32 %2683, %2682
  %2695 = lshr i32 %2694, 4
  %2696 = trunc i32 %2695 to i8
  %2697 = and i8 %2696, 1
  store i8 %2697, i8* %28, align 1, !tbaa !2447
  %2698 = zext i1 %2686 to i8
  store i8 %2698, i8* %31, align 1, !tbaa !2448
  %2699 = lshr i32 %2683, 31
  %2700 = trunc i32 %2699 to i8
  store i8 %2700, i8* %34, align 1, !tbaa !2449
  %2701 = lshr i32 %2682, 31
  %2702 = xor i32 %2699, %2701
  %2703 = add nuw nsw i32 %2702, %2699
  %2704 = icmp eq i32 %2703, 2
  %2705 = zext i1 %2704 to i8
  store i8 %2705, i8* %40, align 1, !tbaa !2450
  %2706 = sext i32 %2683 to i64
  store i64 %2706, i64* %RDX, align 8, !tbaa !2428
  %2707 = shl nsw i64 %2706, 3
  %2708 = add i64 %2707, %2678
  %2709 = add i64 %2654, 42
  store i64 %2709, i64* %PC, align 8
  %2710 = inttoptr i64 %2708 to double*
  store double %2674, double* %2710, align 8
  %2711 = load i64, i64* %RBP, align 8
  %2712 = add i64 %2711, -28
  %2713 = load i64, i64* %PC, align 8
  %2714 = add i64 %2713, 3
  store i64 %2714, i64* %PC, align 8
  %2715 = inttoptr i64 %2712 to i32*
  %2716 = load i32, i32* %2715, align 4
  %2717 = add i32 %2716, 2
  %2718 = zext i32 %2717 to i64
  store i64 %2718, i64* %RAX, align 8, !tbaa !2428
  %2719 = icmp ugt i32 %2716, -3
  %2720 = zext i1 %2719 to i8
  store i8 %2720, i8* %15, align 1, !tbaa !2432
  %2721 = and i32 %2717, 255
  %2722 = tail call i32 @llvm.ctpop.i32(i32 %2721) #11
  %2723 = trunc i32 %2722 to i8
  %2724 = and i8 %2723, 1
  %2725 = xor i8 %2724, 1
  store i8 %2725, i8* %22, align 1, !tbaa !2446
  %2726 = xor i32 %2717, %2716
  %2727 = lshr i32 %2726, 4
  %2728 = trunc i32 %2727 to i8
  %2729 = and i8 %2728, 1
  store i8 %2729, i8* %28, align 1, !tbaa !2447
  %2730 = icmp eq i32 %2717, 0
  %2731 = zext i1 %2730 to i8
  store i8 %2731, i8* %31, align 1, !tbaa !2448
  %2732 = lshr i32 %2717, 31
  %2733 = trunc i32 %2732 to i8
  store i8 %2733, i8* %34, align 1, !tbaa !2449
  %2734 = lshr i32 %2716, 31
  %2735 = xor i32 %2732, %2734
  %2736 = add nuw nsw i32 %2735, %2732
  %2737 = icmp eq i32 %2736, 2
  %2738 = zext i1 %2737 to i8
  store i8 %2738, i8* %40, align 1, !tbaa !2450
  %2739 = add i64 %2713, 9
  store i64 %2739, i64* %PC, align 8
  store i32 %2717, i32* %2715, align 4
  %2740 = load i64, i64* %PC, align 8
  %2741 = add i64 %2740, -822
  store i64 %2741, i64* %PC, align 8, !tbaa !2428
  br label %block_403cc0

block_403356:                                     ; preds = %block_403362, %block_403330
  %2742 = phi i64 [ %3671, %block_403362 ], [ %.pre, %block_403330 ]
  %2743 = load i64, i64* %RBP, align 8
  %2744 = add i64 %2743, -28
  %2745 = add i64 %2742, 3
  store i64 %2745, i64* %PC, align 8
  %2746 = inttoptr i64 %2744 to i32*
  %2747 = load i32, i32* %2746, align 4
  %2748 = zext i32 %2747 to i64
  store i64 %2748, i64* %RAX, align 8, !tbaa !2428
  %2749 = add i64 %2743, -8
  %2750 = add i64 %2742, 6
  store i64 %2750, i64* %PC, align 8
  %2751 = inttoptr i64 %2749 to i32*
  %2752 = load i32, i32* %2751, align 4
  %2753 = sub i32 %2747, %2752
  %2754 = icmp ult i32 %2747, %2752
  %2755 = zext i1 %2754 to i8
  store i8 %2755, i8* %15, align 1, !tbaa !2432
  %2756 = and i32 %2753, 255
  %2757 = tail call i32 @llvm.ctpop.i32(i32 %2756) #11
  %2758 = trunc i32 %2757 to i8
  %2759 = and i8 %2758, 1
  %2760 = xor i8 %2759, 1
  store i8 %2760, i8* %22, align 1, !tbaa !2446
  %2761 = xor i32 %2752, %2747
  %2762 = xor i32 %2761, %2753
  %2763 = lshr i32 %2762, 4
  %2764 = trunc i32 %2763 to i8
  %2765 = and i8 %2764, 1
  store i8 %2765, i8* %28, align 1, !tbaa !2447
  %2766 = icmp eq i32 %2753, 0
  %2767 = zext i1 %2766 to i8
  store i8 %2767, i8* %31, align 1, !tbaa !2448
  %2768 = lshr i32 %2753, 31
  %2769 = trunc i32 %2768 to i8
  store i8 %2769, i8* %34, align 1, !tbaa !2449
  %2770 = lshr i32 %2747, 31
  %2771 = lshr i32 %2752, 31
  %2772 = xor i32 %2771, %2770
  %2773 = xor i32 %2768, %2770
  %2774 = add nuw nsw i32 %2773, %2772
  %2775 = icmp eq i32 %2774, 2
  %2776 = zext i1 %2775 to i8
  store i8 %2776, i8* %40, align 1, !tbaa !2450
  %2777 = icmp ne i8 %2769, 0
  %2778 = xor i1 %2777, %2775
  %.v = select i1 %2778, i64 12, i64 599
  %2779 = add i64 %.v, %2742
  store i64 %2779, i64* %PC, align 8, !tbaa !2428
  br i1 %2778, label %block_403362, label %block_4035ad

block_403362:                                     ; preds = %block_403356
  %2780 = add i64 %2779, 3
  store i64 %2780, i64* %PC, align 8
  %2781 = load i32, i32* %2746, align 4
  %2782 = zext i32 %2781 to i64
  store i64 %2782, i64* %RAX, align 8, !tbaa !2428
  %2783 = add i64 %2779, 6
  store i64 %2783, i64* %PC, align 8
  %2784 = load i32, i32* %2751, align 4
  %2785 = add i32 %2784, %2781
  %2786 = zext i32 %2785 to i64
  store i64 %2786, i64* %RAX, align 8, !tbaa !2428
  %2787 = icmp ult i32 %2785, %2781
  %2788 = icmp ult i32 %2785, %2784
  %2789 = or i1 %2787, %2788
  %2790 = zext i1 %2789 to i8
  store i8 %2790, i8* %15, align 1, !tbaa !2432
  %2791 = and i32 %2785, 255
  %2792 = tail call i32 @llvm.ctpop.i32(i32 %2791) #11
  %2793 = trunc i32 %2792 to i8
  %2794 = and i8 %2793, 1
  %2795 = xor i8 %2794, 1
  store i8 %2795, i8* %22, align 1, !tbaa !2446
  %2796 = xor i32 %2784, %2781
  %2797 = xor i32 %2796, %2785
  %2798 = lshr i32 %2797, 4
  %2799 = trunc i32 %2798 to i8
  %2800 = and i8 %2799, 1
  store i8 %2800, i8* %28, align 1, !tbaa !2447
  %2801 = icmp eq i32 %2785, 0
  %2802 = zext i1 %2801 to i8
  store i8 %2802, i8* %31, align 1, !tbaa !2448
  %2803 = lshr i32 %2785, 31
  %2804 = trunc i32 %2803 to i8
  store i8 %2804, i8* %34, align 1, !tbaa !2449
  %2805 = lshr i32 %2781, 31
  %2806 = lshr i32 %2784, 31
  %2807 = xor i32 %2803, %2805
  %2808 = xor i32 %2803, %2806
  %2809 = add nuw nsw i32 %2807, %2808
  %2810 = icmp eq i32 %2809, 2
  %2811 = zext i1 %2810 to i8
  store i8 %2811, i8* %40, align 1, !tbaa !2450
  %2812 = add i64 %2743, -32
  %2813 = add i64 %2779, 9
  store i64 %2813, i64* %PC, align 8
  %2814 = inttoptr i64 %2812 to i32*
  store i32 %2785, i32* %2814, align 4
  %2815 = load i64, i64* %RBP, align 8
  %2816 = add i64 %2815, -32
  %2817 = load i64, i64* %PC, align 8
  %2818 = add i64 %2817, 3
  store i64 %2818, i64* %PC, align 8
  %2819 = inttoptr i64 %2816 to i32*
  %2820 = load i32, i32* %2819, align 4
  %2821 = zext i32 %2820 to i64
  store i64 %2821, i64* %RAX, align 8, !tbaa !2428
  %2822 = add i64 %2815, -8
  %2823 = add i64 %2817, 6
  store i64 %2823, i64* %PC, align 8
  %2824 = inttoptr i64 %2822 to i32*
  %2825 = load i32, i32* %2824, align 4
  %2826 = add i32 %2825, %2820
  %2827 = zext i32 %2826 to i64
  store i64 %2827, i64* %RAX, align 8, !tbaa !2428
  %2828 = icmp ult i32 %2826, %2820
  %2829 = icmp ult i32 %2826, %2825
  %2830 = or i1 %2828, %2829
  %2831 = zext i1 %2830 to i8
  store i8 %2831, i8* %15, align 1, !tbaa !2432
  %2832 = and i32 %2826, 255
  %2833 = tail call i32 @llvm.ctpop.i32(i32 %2832) #11
  %2834 = trunc i32 %2833 to i8
  %2835 = and i8 %2834, 1
  %2836 = xor i8 %2835, 1
  store i8 %2836, i8* %22, align 1, !tbaa !2446
  %2837 = xor i32 %2825, %2820
  %2838 = xor i32 %2837, %2826
  %2839 = lshr i32 %2838, 4
  %2840 = trunc i32 %2839 to i8
  %2841 = and i8 %2840, 1
  store i8 %2841, i8* %28, align 1, !tbaa !2447
  %2842 = icmp eq i32 %2826, 0
  %2843 = zext i1 %2842 to i8
  store i8 %2843, i8* %31, align 1, !tbaa !2448
  %2844 = lshr i32 %2826, 31
  %2845 = trunc i32 %2844 to i8
  store i8 %2845, i8* %34, align 1, !tbaa !2449
  %2846 = lshr i32 %2820, 31
  %2847 = lshr i32 %2825, 31
  %2848 = xor i32 %2844, %2846
  %2849 = xor i32 %2844, %2847
  %2850 = add nuw nsw i32 %2848, %2849
  %2851 = icmp eq i32 %2850, 2
  %2852 = zext i1 %2851 to i8
  store i8 %2852, i8* %40, align 1, !tbaa !2450
  %2853 = add i64 %2815, -36
  %2854 = add i64 %2817, 9
  store i64 %2854, i64* %PC, align 8
  %2855 = inttoptr i64 %2853 to i32*
  store i32 %2826, i32* %2855, align 4
  %2856 = load i64, i64* %RBP, align 8
  %2857 = add i64 %2856, -36
  %2858 = load i64, i64* %PC, align 8
  %2859 = add i64 %2858, 3
  store i64 %2859, i64* %PC, align 8
  %2860 = inttoptr i64 %2857 to i32*
  %2861 = load i32, i32* %2860, align 4
  %2862 = zext i32 %2861 to i64
  store i64 %2862, i64* %RAX, align 8, !tbaa !2428
  %2863 = add i64 %2856, -8
  %2864 = add i64 %2858, 6
  store i64 %2864, i64* %PC, align 8
  %2865 = inttoptr i64 %2863 to i32*
  %2866 = load i32, i32* %2865, align 4
  %2867 = add i32 %2866, %2861
  %2868 = zext i32 %2867 to i64
  store i64 %2868, i64* %RAX, align 8, !tbaa !2428
  %2869 = icmp ult i32 %2867, %2861
  %2870 = icmp ult i32 %2867, %2866
  %2871 = or i1 %2869, %2870
  %2872 = zext i1 %2871 to i8
  store i8 %2872, i8* %15, align 1, !tbaa !2432
  %2873 = and i32 %2867, 255
  %2874 = tail call i32 @llvm.ctpop.i32(i32 %2873) #11
  %2875 = trunc i32 %2874 to i8
  %2876 = and i8 %2875, 1
  %2877 = xor i8 %2876, 1
  store i8 %2877, i8* %22, align 1, !tbaa !2446
  %2878 = xor i32 %2866, %2861
  %2879 = xor i32 %2878, %2867
  %2880 = lshr i32 %2879, 4
  %2881 = trunc i32 %2880 to i8
  %2882 = and i8 %2881, 1
  store i8 %2882, i8* %28, align 1, !tbaa !2447
  %2883 = icmp eq i32 %2867, 0
  %2884 = zext i1 %2883 to i8
  store i8 %2884, i8* %31, align 1, !tbaa !2448
  %2885 = lshr i32 %2867, 31
  %2886 = trunc i32 %2885 to i8
  store i8 %2886, i8* %34, align 1, !tbaa !2449
  %2887 = lshr i32 %2861, 31
  %2888 = lshr i32 %2866, 31
  %2889 = xor i32 %2885, %2887
  %2890 = xor i32 %2885, %2888
  %2891 = add nuw nsw i32 %2889, %2890
  %2892 = icmp eq i32 %2891, 2
  %2893 = zext i1 %2892 to i8
  store i8 %2893, i8* %40, align 1, !tbaa !2450
  %2894 = add i64 %2856, -40
  %2895 = add i64 %2858, 9
  store i64 %2895, i64* %PC, align 8
  %2896 = inttoptr i64 %2894 to i32*
  store i32 %2867, i32* %2896, align 4
  %2897 = load i64, i64* %RBP, align 8
  %2898 = add i64 %2897, -16
  %2899 = load i64, i64* %PC, align 8
  %2900 = add i64 %2899, 4
  store i64 %2900, i64* %PC, align 8
  %2901 = inttoptr i64 %2898 to i64*
  %2902 = load i64, i64* %2901, align 8
  store i64 %2902, i64* %RCX, align 8, !tbaa !2428
  %2903 = add i64 %2897, -28
  %2904 = add i64 %2899, 8
  store i64 %2904, i64* %PC, align 8
  %2905 = inttoptr i64 %2903 to i32*
  %2906 = load i32, i32* %2905, align 4
  %2907 = sext i32 %2906 to i64
  store i64 %2907, i64* %RDX, align 8, !tbaa !2428
  %2908 = shl nsw i64 %2907, 3
  %2909 = add i64 %2908, %2902
  %2910 = add i64 %2899, 13
  store i64 %2910, i64* %PC, align 8
  %2911 = inttoptr i64 %2909 to i64*
  %2912 = load i64, i64* %2911, align 8
  store i64 %2912, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2913 = add i64 %2899, 17
  store i64 %2913, i64* %PC, align 8
  %2914 = load i64, i64* %2901, align 8
  store i64 %2914, i64* %RCX, align 8, !tbaa !2428
  %2915 = add i64 %2897, -32
  %2916 = add i64 %2899, 21
  store i64 %2916, i64* %PC, align 8
  %2917 = inttoptr i64 %2915 to i32*
  %2918 = load i32, i32* %2917, align 4
  %2919 = sext i32 %2918 to i64
  store i64 %2919, i64* %RDX, align 8, !tbaa !2428
  %2920 = shl nsw i64 %2919, 3
  %2921 = add i64 %2920, %2914
  %2922 = add i64 %2899, 26
  store i64 %2922, i64* %PC, align 8
  %2923 = bitcast i64 %2912 to double
  %2924 = inttoptr i64 %2921 to double*
  %2925 = load double, double* %2924, align 8
  %2926 = fadd double %2923, %2925
  store double %2926, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %2927 = add i64 %2897, -120
  %2928 = add i64 %2899, 31
  store i64 %2928, i64* %PC, align 8
  %2929 = inttoptr i64 %2927 to double*
  store double %2926, double* %2929, align 8
  %2930 = load i64, i64* %RBP, align 8
  %2931 = add i64 %2930, -16
  %2932 = load i64, i64* %PC, align 8
  %2933 = add i64 %2932, 4
  store i64 %2933, i64* %PC, align 8
  %2934 = inttoptr i64 %2931 to i64*
  %2935 = load i64, i64* %2934, align 8
  store i64 %2935, i64* %RCX, align 8, !tbaa !2428
  %2936 = add i64 %2930, -28
  %2937 = add i64 %2932, 7
  store i64 %2937, i64* %PC, align 8
  %2938 = inttoptr i64 %2936 to i32*
  %2939 = load i32, i32* %2938, align 4
  %2940 = add i32 %2939, 1
  %2941 = zext i32 %2940 to i64
  store i64 %2941, i64* %RAX, align 8, !tbaa !2428
  %2942 = icmp eq i32 %2939, -1
  %2943 = icmp eq i32 %2940, 0
  %2944 = or i1 %2942, %2943
  %2945 = zext i1 %2944 to i8
  store i8 %2945, i8* %15, align 1, !tbaa !2432
  %2946 = and i32 %2940, 255
  %2947 = tail call i32 @llvm.ctpop.i32(i32 %2946) #11
  %2948 = trunc i32 %2947 to i8
  %2949 = and i8 %2948, 1
  %2950 = xor i8 %2949, 1
  store i8 %2950, i8* %22, align 1, !tbaa !2446
  %2951 = xor i32 %2940, %2939
  %2952 = lshr i32 %2951, 4
  %2953 = trunc i32 %2952 to i8
  %2954 = and i8 %2953, 1
  store i8 %2954, i8* %28, align 1, !tbaa !2447
  %2955 = zext i1 %2943 to i8
  store i8 %2955, i8* %31, align 1, !tbaa !2448
  %2956 = lshr i32 %2940, 31
  %2957 = trunc i32 %2956 to i8
  store i8 %2957, i8* %34, align 1, !tbaa !2449
  %2958 = lshr i32 %2939, 31
  %2959 = xor i32 %2956, %2958
  %2960 = add nuw nsw i32 %2959, %2956
  %2961 = icmp eq i32 %2960, 2
  %2962 = zext i1 %2961 to i8
  store i8 %2962, i8* %40, align 1, !tbaa !2450
  %2963 = sext i32 %2940 to i64
  store i64 %2963, i64* %RDX, align 8, !tbaa !2428
  %2964 = shl nsw i64 %2963, 3
  %2965 = add i64 %2964, %2935
  %2966 = add i64 %2932, 18
  store i64 %2966, i64* %PC, align 8
  %2967 = inttoptr i64 %2965 to i64*
  %2968 = load i64, i64* %2967, align 8
  store i64 %2968, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %2969 = add i64 %2932, 22
  store i64 %2969, i64* %PC, align 8
  %2970 = load i64, i64* %2934, align 8
  store i64 %2970, i64* %RCX, align 8, !tbaa !2428
  %2971 = add i64 %2930, -32
  %2972 = add i64 %2932, 25
  store i64 %2972, i64* %PC, align 8
  %2973 = inttoptr i64 %2971 to i32*
  %2974 = load i32, i32* %2973, align 4
  %2975 = add i32 %2974, 1
  %2976 = zext i32 %2975 to i64
  store i64 %2976, i64* %RAX, align 8, !tbaa !2428
  %2977 = icmp eq i32 %2974, -1
  %2978 = icmp eq i32 %2975, 0
  %2979 = or i1 %2977, %2978
  %2980 = zext i1 %2979 to i8
  store i8 %2980, i8* %15, align 1, !tbaa !2432
  %2981 = and i32 %2975, 255
  %2982 = tail call i32 @llvm.ctpop.i32(i32 %2981) #11
  %2983 = trunc i32 %2982 to i8
  %2984 = and i8 %2983, 1
  %2985 = xor i8 %2984, 1
  store i8 %2985, i8* %22, align 1, !tbaa !2446
  %2986 = xor i32 %2975, %2974
  %2987 = lshr i32 %2986, 4
  %2988 = trunc i32 %2987 to i8
  %2989 = and i8 %2988, 1
  store i8 %2989, i8* %28, align 1, !tbaa !2447
  %2990 = zext i1 %2978 to i8
  store i8 %2990, i8* %31, align 1, !tbaa !2448
  %2991 = lshr i32 %2975, 31
  %2992 = trunc i32 %2991 to i8
  store i8 %2992, i8* %34, align 1, !tbaa !2449
  %2993 = lshr i32 %2974, 31
  %2994 = xor i32 %2991, %2993
  %2995 = add nuw nsw i32 %2994, %2991
  %2996 = icmp eq i32 %2995, 2
  %2997 = zext i1 %2996 to i8
  store i8 %2997, i8* %40, align 1, !tbaa !2450
  %2998 = sext i32 %2975 to i64
  store i64 %2998, i64* %RDX, align 8, !tbaa !2428
  %2999 = shl nsw i64 %2998, 3
  %3000 = add i64 %2999, %2970
  %3001 = add i64 %2932, 36
  store i64 %3001, i64* %PC, align 8
  %3002 = bitcast i64 %2968 to double
  %3003 = inttoptr i64 %3000 to double*
  %3004 = load double, double* %3003, align 8
  %3005 = fadd double %3002, %3004
  store double %3005, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3006 = load i64, i64* %RBP, align 8
  %3007 = add i64 %3006, -128
  %3008 = add i64 %2932, 41
  store i64 %3008, i64* %PC, align 8
  %3009 = inttoptr i64 %3007 to double*
  store double %3005, double* %3009, align 8
  %3010 = load i64, i64* %RBP, align 8
  %3011 = add i64 %3010, -16
  %3012 = load i64, i64* %PC, align 8
  %3013 = add i64 %3012, 4
  store i64 %3013, i64* %PC, align 8
  %3014 = inttoptr i64 %3011 to i64*
  %3015 = load i64, i64* %3014, align 8
  store i64 %3015, i64* %RCX, align 8, !tbaa !2428
  %3016 = add i64 %3010, -28
  %3017 = add i64 %3012, 8
  store i64 %3017, i64* %PC, align 8
  %3018 = inttoptr i64 %3016 to i32*
  %3019 = load i32, i32* %3018, align 4
  %3020 = sext i32 %3019 to i64
  store i64 %3020, i64* %RDX, align 8, !tbaa !2428
  %3021 = shl nsw i64 %3020, 3
  %3022 = add i64 %3021, %3015
  %3023 = add i64 %3012, 13
  store i64 %3023, i64* %PC, align 8
  %3024 = inttoptr i64 %3022 to i64*
  %3025 = load i64, i64* %3024, align 8
  store i64 %3025, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3026 = add i64 %3012, 17
  store i64 %3026, i64* %PC, align 8
  %3027 = load i64, i64* %3014, align 8
  store i64 %3027, i64* %RCX, align 8, !tbaa !2428
  %3028 = add i64 %3010, -32
  %3029 = add i64 %3012, 21
  store i64 %3029, i64* %PC, align 8
  %3030 = inttoptr i64 %3028 to i32*
  %3031 = load i32, i32* %3030, align 4
  %3032 = sext i32 %3031 to i64
  store i64 %3032, i64* %RDX, align 8, !tbaa !2428
  %3033 = shl nsw i64 %3032, 3
  %3034 = add i64 %3033, %3027
  %3035 = add i64 %3012, 26
  store i64 %3035, i64* %PC, align 8
  %3036 = bitcast i64 %3025 to double
  %3037 = inttoptr i64 %3034 to double*
  %3038 = load double, double* %3037, align 8
  %3039 = fsub double %3036, %3038
  store double %3039, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3040 = add i64 %3010, -136
  %3041 = add i64 %3012, 34
  store i64 %3041, i64* %PC, align 8
  %3042 = inttoptr i64 %3040 to double*
  store double %3039, double* %3042, align 8
  %3043 = load i64, i64* %RBP, align 8
  %3044 = add i64 %3043, -16
  %3045 = load i64, i64* %PC, align 8
  %3046 = add i64 %3045, 4
  store i64 %3046, i64* %PC, align 8
  %3047 = inttoptr i64 %3044 to i64*
  %3048 = load i64, i64* %3047, align 8
  store i64 %3048, i64* %RCX, align 8, !tbaa !2428
  %3049 = add i64 %3043, -28
  %3050 = add i64 %3045, 7
  store i64 %3050, i64* %PC, align 8
  %3051 = inttoptr i64 %3049 to i32*
  %3052 = load i32, i32* %3051, align 4
  %3053 = add i32 %3052, 1
  %3054 = zext i32 %3053 to i64
  store i64 %3054, i64* %RAX, align 8, !tbaa !2428
  %3055 = icmp eq i32 %3052, -1
  %3056 = icmp eq i32 %3053, 0
  %3057 = or i1 %3055, %3056
  %3058 = zext i1 %3057 to i8
  store i8 %3058, i8* %15, align 1, !tbaa !2432
  %3059 = and i32 %3053, 255
  %3060 = tail call i32 @llvm.ctpop.i32(i32 %3059) #11
  %3061 = trunc i32 %3060 to i8
  %3062 = and i8 %3061, 1
  %3063 = xor i8 %3062, 1
  store i8 %3063, i8* %22, align 1, !tbaa !2446
  %3064 = xor i32 %3053, %3052
  %3065 = lshr i32 %3064, 4
  %3066 = trunc i32 %3065 to i8
  %3067 = and i8 %3066, 1
  store i8 %3067, i8* %28, align 1, !tbaa !2447
  %3068 = zext i1 %3056 to i8
  store i8 %3068, i8* %31, align 1, !tbaa !2448
  %3069 = lshr i32 %3053, 31
  %3070 = trunc i32 %3069 to i8
  store i8 %3070, i8* %34, align 1, !tbaa !2449
  %3071 = lshr i32 %3052, 31
  %3072 = xor i32 %3069, %3071
  %3073 = add nuw nsw i32 %3072, %3069
  %3074 = icmp eq i32 %3073, 2
  %3075 = zext i1 %3074 to i8
  store i8 %3075, i8* %40, align 1, !tbaa !2450
  %3076 = sext i32 %3053 to i64
  store i64 %3076, i64* %RDX, align 8, !tbaa !2428
  %3077 = shl nsw i64 %3076, 3
  %3078 = add i64 %3077, %3048
  %3079 = add i64 %3045, 18
  store i64 %3079, i64* %PC, align 8
  %3080 = inttoptr i64 %3078 to i64*
  %3081 = load i64, i64* %3080, align 8
  store i64 %3081, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3082 = add i64 %3045, 22
  store i64 %3082, i64* %PC, align 8
  %3083 = load i64, i64* %3047, align 8
  store i64 %3083, i64* %RCX, align 8, !tbaa !2428
  %3084 = add i64 %3043, -32
  %3085 = add i64 %3045, 25
  store i64 %3085, i64* %PC, align 8
  %3086 = inttoptr i64 %3084 to i32*
  %3087 = load i32, i32* %3086, align 4
  %3088 = add i32 %3087, 1
  %3089 = zext i32 %3088 to i64
  store i64 %3089, i64* %RAX, align 8, !tbaa !2428
  %3090 = icmp eq i32 %3087, -1
  %3091 = icmp eq i32 %3088, 0
  %3092 = or i1 %3090, %3091
  %3093 = zext i1 %3092 to i8
  store i8 %3093, i8* %15, align 1, !tbaa !2432
  %3094 = and i32 %3088, 255
  %3095 = tail call i32 @llvm.ctpop.i32(i32 %3094) #11
  %3096 = trunc i32 %3095 to i8
  %3097 = and i8 %3096, 1
  %3098 = xor i8 %3097, 1
  store i8 %3098, i8* %22, align 1, !tbaa !2446
  %3099 = xor i32 %3088, %3087
  %3100 = lshr i32 %3099, 4
  %3101 = trunc i32 %3100 to i8
  %3102 = and i8 %3101, 1
  store i8 %3102, i8* %28, align 1, !tbaa !2447
  %3103 = zext i1 %3091 to i8
  store i8 %3103, i8* %31, align 1, !tbaa !2448
  %3104 = lshr i32 %3088, 31
  %3105 = trunc i32 %3104 to i8
  store i8 %3105, i8* %34, align 1, !tbaa !2449
  %3106 = lshr i32 %3087, 31
  %3107 = xor i32 %3104, %3106
  %3108 = add nuw nsw i32 %3107, %3104
  %3109 = icmp eq i32 %3108, 2
  %3110 = zext i1 %3109 to i8
  store i8 %3110, i8* %40, align 1, !tbaa !2450
  %3111 = sext i32 %3088 to i64
  store i64 %3111, i64* %RDX, align 8, !tbaa !2428
  %3112 = shl nsw i64 %3111, 3
  %3113 = add i64 %3112, %3083
  %3114 = add i64 %3045, 36
  store i64 %3114, i64* %PC, align 8
  %3115 = bitcast i64 %3081 to double
  %3116 = inttoptr i64 %3113 to double*
  %3117 = load double, double* %3116, align 8
  %3118 = fsub double %3115, %3117
  store double %3118, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3119 = load i64, i64* %RBP, align 8
  %3120 = add i64 %3119, -144
  %3121 = add i64 %3045, 44
  store i64 %3121, i64* %PC, align 8
  %3122 = inttoptr i64 %3120 to double*
  store double %3118, double* %3122, align 8
  %3123 = load i64, i64* %RBP, align 8
  %3124 = add i64 %3123, -16
  %3125 = load i64, i64* %PC, align 8
  %3126 = add i64 %3125, 4
  store i64 %3126, i64* %PC, align 8
  %3127 = inttoptr i64 %3124 to i64*
  %3128 = load i64, i64* %3127, align 8
  store i64 %3128, i64* %RCX, align 8, !tbaa !2428
  %3129 = add i64 %3123, -36
  %3130 = add i64 %3125, 8
  store i64 %3130, i64* %PC, align 8
  %3131 = inttoptr i64 %3129 to i32*
  %3132 = load i32, i32* %3131, align 4
  %3133 = sext i32 %3132 to i64
  store i64 %3133, i64* %RDX, align 8, !tbaa !2428
  %3134 = shl nsw i64 %3133, 3
  %3135 = add i64 %3134, %3128
  %3136 = add i64 %3125, 13
  store i64 %3136, i64* %PC, align 8
  %3137 = inttoptr i64 %3135 to i64*
  %3138 = load i64, i64* %3137, align 8
  store i64 %3138, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3139 = add i64 %3125, 17
  store i64 %3139, i64* %PC, align 8
  %3140 = load i64, i64* %3127, align 8
  store i64 %3140, i64* %RCX, align 8, !tbaa !2428
  %3141 = add i64 %3123, -40
  %3142 = add i64 %3125, 21
  store i64 %3142, i64* %PC, align 8
  %3143 = inttoptr i64 %3141 to i32*
  %3144 = load i32, i32* %3143, align 4
  %3145 = sext i32 %3144 to i64
  store i64 %3145, i64* %RDX, align 8, !tbaa !2428
  %3146 = shl nsw i64 %3145, 3
  %3147 = add i64 %3146, %3140
  %3148 = add i64 %3125, 26
  store i64 %3148, i64* %PC, align 8
  %3149 = bitcast i64 %3138 to double
  %3150 = inttoptr i64 %3147 to double*
  %3151 = load double, double* %3150, align 8
  %3152 = fadd double %3149, %3151
  store double %3152, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3153 = add i64 %3123, -152
  %3154 = add i64 %3125, 34
  store i64 %3154, i64* %PC, align 8
  %3155 = inttoptr i64 %3153 to double*
  store double %3152, double* %3155, align 8
  %3156 = load i64, i64* %RBP, align 8
  %3157 = add i64 %3156, -16
  %3158 = load i64, i64* %PC, align 8
  %3159 = add i64 %3158, 4
  store i64 %3159, i64* %PC, align 8
  %3160 = inttoptr i64 %3157 to i64*
  %3161 = load i64, i64* %3160, align 8
  store i64 %3161, i64* %RCX, align 8, !tbaa !2428
  %3162 = add i64 %3156, -36
  %3163 = add i64 %3158, 7
  store i64 %3163, i64* %PC, align 8
  %3164 = inttoptr i64 %3162 to i32*
  %3165 = load i32, i32* %3164, align 4
  %3166 = add i32 %3165, 1
  %3167 = zext i32 %3166 to i64
  store i64 %3167, i64* %RAX, align 8, !tbaa !2428
  %3168 = icmp eq i32 %3165, -1
  %3169 = icmp eq i32 %3166, 0
  %3170 = or i1 %3168, %3169
  %3171 = zext i1 %3170 to i8
  store i8 %3171, i8* %15, align 1, !tbaa !2432
  %3172 = and i32 %3166, 255
  %3173 = tail call i32 @llvm.ctpop.i32(i32 %3172) #11
  %3174 = trunc i32 %3173 to i8
  %3175 = and i8 %3174, 1
  %3176 = xor i8 %3175, 1
  store i8 %3176, i8* %22, align 1, !tbaa !2446
  %3177 = xor i32 %3166, %3165
  %3178 = lshr i32 %3177, 4
  %3179 = trunc i32 %3178 to i8
  %3180 = and i8 %3179, 1
  store i8 %3180, i8* %28, align 1, !tbaa !2447
  %3181 = zext i1 %3169 to i8
  store i8 %3181, i8* %31, align 1, !tbaa !2448
  %3182 = lshr i32 %3166, 31
  %3183 = trunc i32 %3182 to i8
  store i8 %3183, i8* %34, align 1, !tbaa !2449
  %3184 = lshr i32 %3165, 31
  %3185 = xor i32 %3182, %3184
  %3186 = add nuw nsw i32 %3185, %3182
  %3187 = icmp eq i32 %3186, 2
  %3188 = zext i1 %3187 to i8
  store i8 %3188, i8* %40, align 1, !tbaa !2450
  %3189 = sext i32 %3166 to i64
  store i64 %3189, i64* %RDX, align 8, !tbaa !2428
  %3190 = shl nsw i64 %3189, 3
  %3191 = add i64 %3190, %3161
  %3192 = add i64 %3158, 18
  store i64 %3192, i64* %PC, align 8
  %3193 = inttoptr i64 %3191 to i64*
  %3194 = load i64, i64* %3193, align 8
  store i64 %3194, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3195 = add i64 %3158, 22
  store i64 %3195, i64* %PC, align 8
  %3196 = load i64, i64* %3160, align 8
  store i64 %3196, i64* %RCX, align 8, !tbaa !2428
  %3197 = add i64 %3156, -40
  %3198 = add i64 %3158, 25
  store i64 %3198, i64* %PC, align 8
  %3199 = inttoptr i64 %3197 to i32*
  %3200 = load i32, i32* %3199, align 4
  %3201 = add i32 %3200, 1
  %3202 = zext i32 %3201 to i64
  store i64 %3202, i64* %RAX, align 8, !tbaa !2428
  %3203 = icmp eq i32 %3200, -1
  %3204 = icmp eq i32 %3201, 0
  %3205 = or i1 %3203, %3204
  %3206 = zext i1 %3205 to i8
  store i8 %3206, i8* %15, align 1, !tbaa !2432
  %3207 = and i32 %3201, 255
  %3208 = tail call i32 @llvm.ctpop.i32(i32 %3207) #11
  %3209 = trunc i32 %3208 to i8
  %3210 = and i8 %3209, 1
  %3211 = xor i8 %3210, 1
  store i8 %3211, i8* %22, align 1, !tbaa !2446
  %3212 = xor i32 %3201, %3200
  %3213 = lshr i32 %3212, 4
  %3214 = trunc i32 %3213 to i8
  %3215 = and i8 %3214, 1
  store i8 %3215, i8* %28, align 1, !tbaa !2447
  %3216 = zext i1 %3204 to i8
  store i8 %3216, i8* %31, align 1, !tbaa !2448
  %3217 = lshr i32 %3201, 31
  %3218 = trunc i32 %3217 to i8
  store i8 %3218, i8* %34, align 1, !tbaa !2449
  %3219 = lshr i32 %3200, 31
  %3220 = xor i32 %3217, %3219
  %3221 = add nuw nsw i32 %3220, %3217
  %3222 = icmp eq i32 %3221, 2
  %3223 = zext i1 %3222 to i8
  store i8 %3223, i8* %40, align 1, !tbaa !2450
  %3224 = sext i32 %3201 to i64
  store i64 %3224, i64* %RDX, align 8, !tbaa !2428
  %3225 = shl nsw i64 %3224, 3
  %3226 = add i64 %3225, %3196
  %3227 = add i64 %3158, 36
  store i64 %3227, i64* %PC, align 8
  %3228 = bitcast i64 %3194 to double
  %3229 = inttoptr i64 %3226 to double*
  %3230 = load double, double* %3229, align 8
  %3231 = fadd double %3228, %3230
  store double %3231, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3232 = load i64, i64* %RBP, align 8
  %3233 = add i64 %3232, -160
  %3234 = add i64 %3158, 44
  store i64 %3234, i64* %PC, align 8
  %3235 = inttoptr i64 %3233 to double*
  store double %3231, double* %3235, align 8
  %3236 = load i64, i64* %RBP, align 8
  %3237 = add i64 %3236, -16
  %3238 = load i64, i64* %PC, align 8
  %3239 = add i64 %3238, 4
  store i64 %3239, i64* %PC, align 8
  %3240 = inttoptr i64 %3237 to i64*
  %3241 = load i64, i64* %3240, align 8
  store i64 %3241, i64* %RCX, align 8, !tbaa !2428
  %3242 = add i64 %3236, -36
  %3243 = add i64 %3238, 8
  store i64 %3243, i64* %PC, align 8
  %3244 = inttoptr i64 %3242 to i32*
  %3245 = load i32, i32* %3244, align 4
  %3246 = sext i32 %3245 to i64
  store i64 %3246, i64* %RDX, align 8, !tbaa !2428
  %3247 = shl nsw i64 %3246, 3
  %3248 = add i64 %3247, %3241
  %3249 = add i64 %3238, 13
  store i64 %3249, i64* %PC, align 8
  %3250 = inttoptr i64 %3248 to i64*
  %3251 = load i64, i64* %3250, align 8
  store i64 %3251, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3252 = add i64 %3238, 17
  store i64 %3252, i64* %PC, align 8
  %3253 = load i64, i64* %3240, align 8
  store i64 %3253, i64* %RCX, align 8, !tbaa !2428
  %3254 = add i64 %3236, -40
  %3255 = add i64 %3238, 21
  store i64 %3255, i64* %PC, align 8
  %3256 = inttoptr i64 %3254 to i32*
  %3257 = load i32, i32* %3256, align 4
  %3258 = sext i32 %3257 to i64
  store i64 %3258, i64* %RDX, align 8, !tbaa !2428
  %3259 = shl nsw i64 %3258, 3
  %3260 = add i64 %3259, %3253
  %3261 = add i64 %3238, 26
  store i64 %3261, i64* %PC, align 8
  %3262 = bitcast i64 %3251 to double
  %3263 = inttoptr i64 %3260 to double*
  %3264 = load double, double* %3263, align 8
  %3265 = fsub double %3262, %3264
  store double %3265, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3266 = add i64 %3236, -168
  %3267 = add i64 %3238, 34
  store i64 %3267, i64* %PC, align 8
  %3268 = inttoptr i64 %3266 to double*
  store double %3265, double* %3268, align 8
  %3269 = load i64, i64* %RBP, align 8
  %3270 = add i64 %3269, -16
  %3271 = load i64, i64* %PC, align 8
  %3272 = add i64 %3271, 4
  store i64 %3272, i64* %PC, align 8
  %3273 = inttoptr i64 %3270 to i64*
  %3274 = load i64, i64* %3273, align 8
  store i64 %3274, i64* %RCX, align 8, !tbaa !2428
  %3275 = add i64 %3269, -36
  %3276 = add i64 %3271, 7
  store i64 %3276, i64* %PC, align 8
  %3277 = inttoptr i64 %3275 to i32*
  %3278 = load i32, i32* %3277, align 4
  %3279 = add i32 %3278, 1
  %3280 = zext i32 %3279 to i64
  store i64 %3280, i64* %RAX, align 8, !tbaa !2428
  %3281 = icmp eq i32 %3278, -1
  %3282 = icmp eq i32 %3279, 0
  %3283 = or i1 %3281, %3282
  %3284 = zext i1 %3283 to i8
  store i8 %3284, i8* %15, align 1, !tbaa !2432
  %3285 = and i32 %3279, 255
  %3286 = tail call i32 @llvm.ctpop.i32(i32 %3285) #11
  %3287 = trunc i32 %3286 to i8
  %3288 = and i8 %3287, 1
  %3289 = xor i8 %3288, 1
  store i8 %3289, i8* %22, align 1, !tbaa !2446
  %3290 = xor i32 %3279, %3278
  %3291 = lshr i32 %3290, 4
  %3292 = trunc i32 %3291 to i8
  %3293 = and i8 %3292, 1
  store i8 %3293, i8* %28, align 1, !tbaa !2447
  %3294 = zext i1 %3282 to i8
  store i8 %3294, i8* %31, align 1, !tbaa !2448
  %3295 = lshr i32 %3279, 31
  %3296 = trunc i32 %3295 to i8
  store i8 %3296, i8* %34, align 1, !tbaa !2449
  %3297 = lshr i32 %3278, 31
  %3298 = xor i32 %3295, %3297
  %3299 = add nuw nsw i32 %3298, %3295
  %3300 = icmp eq i32 %3299, 2
  %3301 = zext i1 %3300 to i8
  store i8 %3301, i8* %40, align 1, !tbaa !2450
  %3302 = sext i32 %3279 to i64
  store i64 %3302, i64* %RDX, align 8, !tbaa !2428
  %3303 = shl nsw i64 %3302, 3
  %3304 = add i64 %3303, %3274
  %3305 = add i64 %3271, 18
  store i64 %3305, i64* %PC, align 8
  %3306 = inttoptr i64 %3304 to i64*
  %3307 = load i64, i64* %3306, align 8
  store i64 %3307, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3308 = add i64 %3271, 22
  store i64 %3308, i64* %PC, align 8
  %3309 = load i64, i64* %3273, align 8
  store i64 %3309, i64* %RCX, align 8, !tbaa !2428
  %3310 = add i64 %3269, -40
  %3311 = add i64 %3271, 25
  store i64 %3311, i64* %PC, align 8
  %3312 = inttoptr i64 %3310 to i32*
  %3313 = load i32, i32* %3312, align 4
  %3314 = add i32 %3313, 1
  %3315 = zext i32 %3314 to i64
  store i64 %3315, i64* %RAX, align 8, !tbaa !2428
  %3316 = icmp eq i32 %3313, -1
  %3317 = icmp eq i32 %3314, 0
  %3318 = or i1 %3316, %3317
  %3319 = zext i1 %3318 to i8
  store i8 %3319, i8* %15, align 1, !tbaa !2432
  %3320 = and i32 %3314, 255
  %3321 = tail call i32 @llvm.ctpop.i32(i32 %3320) #11
  %3322 = trunc i32 %3321 to i8
  %3323 = and i8 %3322, 1
  %3324 = xor i8 %3323, 1
  store i8 %3324, i8* %22, align 1, !tbaa !2446
  %3325 = xor i32 %3314, %3313
  %3326 = lshr i32 %3325, 4
  %3327 = trunc i32 %3326 to i8
  %3328 = and i8 %3327, 1
  store i8 %3328, i8* %28, align 1, !tbaa !2447
  %3329 = zext i1 %3317 to i8
  store i8 %3329, i8* %31, align 1, !tbaa !2448
  %3330 = lshr i32 %3314, 31
  %3331 = trunc i32 %3330 to i8
  store i8 %3331, i8* %34, align 1, !tbaa !2449
  %3332 = lshr i32 %3313, 31
  %3333 = xor i32 %3330, %3332
  %3334 = add nuw nsw i32 %3333, %3330
  %3335 = icmp eq i32 %3334, 2
  %3336 = zext i1 %3335 to i8
  store i8 %3336, i8* %40, align 1, !tbaa !2450
  %3337 = sext i32 %3314 to i64
  store i64 %3337, i64* %RDX, align 8, !tbaa !2428
  %3338 = shl nsw i64 %3337, 3
  %3339 = add i64 %3338, %3309
  %3340 = add i64 %3271, 36
  store i64 %3340, i64* %PC, align 8
  %3341 = bitcast i64 %3307 to double
  %3342 = inttoptr i64 %3339 to double*
  %3343 = load double, double* %3342, align 8
  %3344 = fsub double %3341, %3343
  store double %3344, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3345 = load i64, i64* %RBP, align 8
  %3346 = add i64 %3345, -176
  %3347 = add i64 %3271, 44
  store i64 %3347, i64* %PC, align 8
  %3348 = inttoptr i64 %3346 to double*
  store double %3344, double* %3348, align 8
  %3349 = load i64, i64* %RBP, align 8
  %3350 = add i64 %3349, -120
  %3351 = load i64, i64* %PC, align 8
  %3352 = add i64 %3351, 5
  store i64 %3352, i64* %PC, align 8
  %3353 = inttoptr i64 %3350 to i64*
  %3354 = load i64, i64* %3353, align 8
  store i64 %3354, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3355 = add i64 %3349, -152
  %3356 = add i64 %3351, 13
  store i64 %3356, i64* %PC, align 8
  %3357 = bitcast i64 %3354 to double
  %3358 = inttoptr i64 %3355 to double*
  %3359 = load double, double* %3358, align 8
  %3360 = fadd double %3357, %3359
  store double %3360, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3361 = add i64 %3349, -16
  %3362 = add i64 %3351, 17
  store i64 %3362, i64* %PC, align 8
  %3363 = inttoptr i64 %3361 to i64*
  %3364 = load i64, i64* %3363, align 8
  store i64 %3364, i64* %RCX, align 8, !tbaa !2428
  %3365 = add i64 %3349, -28
  %3366 = add i64 %3351, 21
  store i64 %3366, i64* %PC, align 8
  %3367 = inttoptr i64 %3365 to i32*
  %3368 = load i32, i32* %3367, align 4
  %3369 = sext i32 %3368 to i64
  store i64 %3369, i64* %RDX, align 8, !tbaa !2428
  %3370 = shl nsw i64 %3369, 3
  %3371 = add i64 %3370, %3364
  %3372 = add i64 %3351, 26
  store i64 %3372, i64* %PC, align 8
  %3373 = inttoptr i64 %3371 to double*
  store double %3360, double* %3373, align 8
  %3374 = load i64, i64* %RBP, align 8
  %3375 = add i64 %3374, -128
  %3376 = load i64, i64* %PC, align 8
  %3377 = add i64 %3376, 5
  store i64 %3377, i64* %PC, align 8
  %3378 = inttoptr i64 %3375 to i64*
  %3379 = load i64, i64* %3378, align 8
  store i64 %3379, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3380 = add i64 %3374, -160
  %3381 = add i64 %3376, 13
  store i64 %3381, i64* %PC, align 8
  %3382 = bitcast i64 %3379 to double
  %3383 = inttoptr i64 %3380 to double*
  %3384 = load double, double* %3383, align 8
  %3385 = fadd double %3382, %3384
  store double %3385, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3386 = add i64 %3374, -16
  %3387 = add i64 %3376, 17
  store i64 %3387, i64* %PC, align 8
  %3388 = inttoptr i64 %3386 to i64*
  %3389 = load i64, i64* %3388, align 8
  store i64 %3389, i64* %RCX, align 8, !tbaa !2428
  %3390 = add i64 %3374, -28
  %3391 = add i64 %3376, 20
  store i64 %3391, i64* %PC, align 8
  %3392 = inttoptr i64 %3390 to i32*
  %3393 = load i32, i32* %3392, align 4
  %3394 = add i32 %3393, 1
  %3395 = zext i32 %3394 to i64
  store i64 %3395, i64* %RAX, align 8, !tbaa !2428
  %3396 = icmp eq i32 %3393, -1
  %3397 = icmp eq i32 %3394, 0
  %3398 = or i1 %3396, %3397
  %3399 = zext i1 %3398 to i8
  store i8 %3399, i8* %15, align 1, !tbaa !2432
  %3400 = and i32 %3394, 255
  %3401 = tail call i32 @llvm.ctpop.i32(i32 %3400) #11
  %3402 = trunc i32 %3401 to i8
  %3403 = and i8 %3402, 1
  %3404 = xor i8 %3403, 1
  store i8 %3404, i8* %22, align 1, !tbaa !2446
  %3405 = xor i32 %3394, %3393
  %3406 = lshr i32 %3405, 4
  %3407 = trunc i32 %3406 to i8
  %3408 = and i8 %3407, 1
  store i8 %3408, i8* %28, align 1, !tbaa !2447
  %3409 = zext i1 %3397 to i8
  store i8 %3409, i8* %31, align 1, !tbaa !2448
  %3410 = lshr i32 %3394, 31
  %3411 = trunc i32 %3410 to i8
  store i8 %3411, i8* %34, align 1, !tbaa !2449
  %3412 = lshr i32 %3393, 31
  %3413 = xor i32 %3410, %3412
  %3414 = add nuw nsw i32 %3413, %3410
  %3415 = icmp eq i32 %3414, 2
  %3416 = zext i1 %3415 to i8
  store i8 %3416, i8* %40, align 1, !tbaa !2450
  %3417 = sext i32 %3394 to i64
  store i64 %3417, i64* %RDX, align 8, !tbaa !2428
  %3418 = shl nsw i64 %3417, 3
  %3419 = add i64 %3418, %3389
  %3420 = add i64 %3376, 31
  store i64 %3420, i64* %PC, align 8
  %3421 = inttoptr i64 %3419 to double*
  store double %3385, double* %3421, align 8
  %3422 = load i64, i64* %RBP, align 8
  %3423 = add i64 %3422, -120
  %3424 = load i64, i64* %PC, align 8
  %3425 = add i64 %3424, 5
  store i64 %3425, i64* %PC, align 8
  %3426 = inttoptr i64 %3423 to i64*
  %3427 = load i64, i64* %3426, align 8
  store i64 %3427, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3428 = add i64 %3422, -152
  %3429 = add i64 %3424, 13
  store i64 %3429, i64* %PC, align 8
  %3430 = bitcast i64 %3427 to double
  %3431 = inttoptr i64 %3428 to double*
  %3432 = load double, double* %3431, align 8
  %3433 = fsub double %3430, %3432
  store double %3433, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3434 = add i64 %3422, -16
  %3435 = add i64 %3424, 17
  store i64 %3435, i64* %PC, align 8
  %3436 = inttoptr i64 %3434 to i64*
  %3437 = load i64, i64* %3436, align 8
  store i64 %3437, i64* %RCX, align 8, !tbaa !2428
  %3438 = add i64 %3422, -36
  %3439 = add i64 %3424, 21
  store i64 %3439, i64* %PC, align 8
  %3440 = inttoptr i64 %3438 to i32*
  %3441 = load i32, i32* %3440, align 4
  %3442 = sext i32 %3441 to i64
  store i64 %3442, i64* %RDX, align 8, !tbaa !2428
  %3443 = shl nsw i64 %3442, 3
  %3444 = add i64 %3443, %3437
  %3445 = add i64 %3424, 26
  store i64 %3445, i64* %PC, align 8
  %3446 = inttoptr i64 %3444 to double*
  store double %3433, double* %3446, align 8
  %3447 = load i64, i64* %RBP, align 8
  %3448 = add i64 %3447, -128
  %3449 = load i64, i64* %PC, align 8
  %3450 = add i64 %3449, 5
  store i64 %3450, i64* %PC, align 8
  %3451 = inttoptr i64 %3448 to i64*
  %3452 = load i64, i64* %3451, align 8
  store i64 %3452, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3453 = add i64 %3447, -160
  %3454 = add i64 %3449, 13
  store i64 %3454, i64* %PC, align 8
  %3455 = bitcast i64 %3452 to double
  %3456 = inttoptr i64 %3453 to double*
  %3457 = load double, double* %3456, align 8
  %3458 = fsub double %3455, %3457
  store double %3458, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3459 = add i64 %3447, -16
  %3460 = add i64 %3449, 17
  store i64 %3460, i64* %PC, align 8
  %3461 = inttoptr i64 %3459 to i64*
  %3462 = load i64, i64* %3461, align 8
  store i64 %3462, i64* %RCX, align 8, !tbaa !2428
  %3463 = add i64 %3447, -36
  %3464 = add i64 %3449, 20
  store i64 %3464, i64* %PC, align 8
  %3465 = inttoptr i64 %3463 to i32*
  %3466 = load i32, i32* %3465, align 4
  %3467 = add i32 %3466, 1
  %3468 = zext i32 %3467 to i64
  store i64 %3468, i64* %RAX, align 8, !tbaa !2428
  %3469 = icmp eq i32 %3466, -1
  %3470 = icmp eq i32 %3467, 0
  %3471 = or i1 %3469, %3470
  %3472 = zext i1 %3471 to i8
  store i8 %3472, i8* %15, align 1, !tbaa !2432
  %3473 = and i32 %3467, 255
  %3474 = tail call i32 @llvm.ctpop.i32(i32 %3473) #11
  %3475 = trunc i32 %3474 to i8
  %3476 = and i8 %3475, 1
  %3477 = xor i8 %3476, 1
  store i8 %3477, i8* %22, align 1, !tbaa !2446
  %3478 = xor i32 %3467, %3466
  %3479 = lshr i32 %3478, 4
  %3480 = trunc i32 %3479 to i8
  %3481 = and i8 %3480, 1
  store i8 %3481, i8* %28, align 1, !tbaa !2447
  %3482 = zext i1 %3470 to i8
  store i8 %3482, i8* %31, align 1, !tbaa !2448
  %3483 = lshr i32 %3467, 31
  %3484 = trunc i32 %3483 to i8
  store i8 %3484, i8* %34, align 1, !tbaa !2449
  %3485 = lshr i32 %3466, 31
  %3486 = xor i32 %3483, %3485
  %3487 = add nuw nsw i32 %3486, %3483
  %3488 = icmp eq i32 %3487, 2
  %3489 = zext i1 %3488 to i8
  store i8 %3489, i8* %40, align 1, !tbaa !2450
  %3490 = sext i32 %3467 to i64
  store i64 %3490, i64* %RDX, align 8, !tbaa !2428
  %3491 = shl nsw i64 %3490, 3
  %3492 = add i64 %3491, %3462
  %3493 = add i64 %3449, 31
  store i64 %3493, i64* %PC, align 8
  %3494 = inttoptr i64 %3492 to double*
  store double %3458, double* %3494, align 8
  %3495 = load i64, i64* %RBP, align 8
  %3496 = add i64 %3495, -136
  %3497 = load i64, i64* %PC, align 8
  %3498 = add i64 %3497, 8
  store i64 %3498, i64* %PC, align 8
  %3499 = inttoptr i64 %3496 to i64*
  %3500 = load i64, i64* %3499, align 8
  store i64 %3500, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3501 = add i64 %3495, -176
  %3502 = add i64 %3497, 16
  store i64 %3502, i64* %PC, align 8
  %3503 = bitcast i64 %3500 to double
  %3504 = inttoptr i64 %3501 to double*
  %3505 = load double, double* %3504, align 8
  %3506 = fsub double %3503, %3505
  store double %3506, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3507 = add i64 %3495, -16
  %3508 = add i64 %3497, 20
  store i64 %3508, i64* %PC, align 8
  %3509 = inttoptr i64 %3507 to i64*
  %3510 = load i64, i64* %3509, align 8
  store i64 %3510, i64* %RCX, align 8, !tbaa !2428
  %3511 = add i64 %3495, -32
  %3512 = add i64 %3497, 24
  store i64 %3512, i64* %PC, align 8
  %3513 = inttoptr i64 %3511 to i32*
  %3514 = load i32, i32* %3513, align 4
  %3515 = sext i32 %3514 to i64
  store i64 %3515, i64* %RDX, align 8, !tbaa !2428
  %3516 = shl nsw i64 %3515, 3
  %3517 = add i64 %3516, %3510
  %3518 = add i64 %3497, 29
  store i64 %3518, i64* %PC, align 8
  %3519 = inttoptr i64 %3517 to double*
  store double %3506, double* %3519, align 8
  %3520 = load i64, i64* %RBP, align 8
  %3521 = add i64 %3520, -144
  %3522 = load i64, i64* %PC, align 8
  %3523 = add i64 %3522, 8
  store i64 %3523, i64* %PC, align 8
  %3524 = inttoptr i64 %3521 to i64*
  %3525 = load i64, i64* %3524, align 8
  store i64 %3525, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3526 = add i64 %3520, -168
  %3527 = add i64 %3522, 16
  store i64 %3527, i64* %PC, align 8
  %3528 = bitcast i64 %3525 to double
  %3529 = inttoptr i64 %3526 to double*
  %3530 = load double, double* %3529, align 8
  %3531 = fadd double %3528, %3530
  store double %3531, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3532 = add i64 %3520, -16
  %3533 = add i64 %3522, 20
  store i64 %3533, i64* %PC, align 8
  %3534 = inttoptr i64 %3532 to i64*
  %3535 = load i64, i64* %3534, align 8
  store i64 %3535, i64* %RCX, align 8, !tbaa !2428
  %3536 = add i64 %3520, -32
  %3537 = add i64 %3522, 23
  store i64 %3537, i64* %PC, align 8
  %3538 = inttoptr i64 %3536 to i32*
  %3539 = load i32, i32* %3538, align 4
  %3540 = add i32 %3539, 1
  %3541 = zext i32 %3540 to i64
  store i64 %3541, i64* %RAX, align 8, !tbaa !2428
  %3542 = icmp eq i32 %3539, -1
  %3543 = icmp eq i32 %3540, 0
  %3544 = or i1 %3542, %3543
  %3545 = zext i1 %3544 to i8
  store i8 %3545, i8* %15, align 1, !tbaa !2432
  %3546 = and i32 %3540, 255
  %3547 = tail call i32 @llvm.ctpop.i32(i32 %3546) #11
  %3548 = trunc i32 %3547 to i8
  %3549 = and i8 %3548, 1
  %3550 = xor i8 %3549, 1
  store i8 %3550, i8* %22, align 1, !tbaa !2446
  %3551 = xor i32 %3540, %3539
  %3552 = lshr i32 %3551, 4
  %3553 = trunc i32 %3552 to i8
  %3554 = and i8 %3553, 1
  store i8 %3554, i8* %28, align 1, !tbaa !2447
  %3555 = zext i1 %3543 to i8
  store i8 %3555, i8* %31, align 1, !tbaa !2448
  %3556 = lshr i32 %3540, 31
  %3557 = trunc i32 %3556 to i8
  store i8 %3557, i8* %34, align 1, !tbaa !2449
  %3558 = lshr i32 %3539, 31
  %3559 = xor i32 %3556, %3558
  %3560 = add nuw nsw i32 %3559, %3556
  %3561 = icmp eq i32 %3560, 2
  %3562 = zext i1 %3561 to i8
  store i8 %3562, i8* %40, align 1, !tbaa !2450
  %3563 = sext i32 %3540 to i64
  store i64 %3563, i64* %RDX, align 8, !tbaa !2428
  %3564 = shl nsw i64 %3563, 3
  %3565 = add i64 %3564, %3535
  %3566 = add i64 %3522, 34
  store i64 %3566, i64* %PC, align 8
  %3567 = inttoptr i64 %3565 to double*
  store double %3531, double* %3567, align 8
  %3568 = load i64, i64* %RBP, align 8
  %3569 = add i64 %3568, -136
  %3570 = load i64, i64* %PC, align 8
  %3571 = add i64 %3570, 8
  store i64 %3571, i64* %PC, align 8
  %3572 = inttoptr i64 %3569 to i64*
  %3573 = load i64, i64* %3572, align 8
  store i64 %3573, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3574 = add i64 %3568, -176
  %3575 = add i64 %3570, 16
  store i64 %3575, i64* %PC, align 8
  %3576 = bitcast i64 %3573 to double
  %3577 = inttoptr i64 %3574 to double*
  %3578 = load double, double* %3577, align 8
  %3579 = fadd double %3576, %3578
  store double %3579, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3580 = add i64 %3568, -16
  %3581 = add i64 %3570, 20
  store i64 %3581, i64* %PC, align 8
  %3582 = inttoptr i64 %3580 to i64*
  %3583 = load i64, i64* %3582, align 8
  store i64 %3583, i64* %RCX, align 8, !tbaa !2428
  %3584 = add i64 %3568, -40
  %3585 = add i64 %3570, 24
  store i64 %3585, i64* %PC, align 8
  %3586 = inttoptr i64 %3584 to i32*
  %3587 = load i32, i32* %3586, align 4
  %3588 = sext i32 %3587 to i64
  store i64 %3588, i64* %RDX, align 8, !tbaa !2428
  %3589 = shl nsw i64 %3588, 3
  %3590 = add i64 %3589, %3583
  %3591 = add i64 %3570, 29
  store i64 %3591, i64* %PC, align 8
  %3592 = inttoptr i64 %3590 to double*
  store double %3579, double* %3592, align 8
  %3593 = load i64, i64* %RBP, align 8
  %3594 = add i64 %3593, -144
  %3595 = load i64, i64* %PC, align 8
  %3596 = add i64 %3595, 8
  store i64 %3596, i64* %PC, align 8
  %3597 = inttoptr i64 %3594 to i64*
  %3598 = load i64, i64* %3597, align 8
  store i64 %3598, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3599 = add i64 %3593, -168
  %3600 = add i64 %3595, 16
  store i64 %3600, i64* %PC, align 8
  %3601 = bitcast i64 %3598 to double
  %3602 = inttoptr i64 %3599 to double*
  %3603 = load double, double* %3602, align 8
  %3604 = fsub double %3601, %3603
  store double %3604, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3605 = add i64 %3593, -16
  %3606 = add i64 %3595, 20
  store i64 %3606, i64* %PC, align 8
  %3607 = inttoptr i64 %3605 to i64*
  %3608 = load i64, i64* %3607, align 8
  store i64 %3608, i64* %RCX, align 8, !tbaa !2428
  %3609 = add i64 %3593, -40
  %3610 = add i64 %3595, 23
  store i64 %3610, i64* %PC, align 8
  %3611 = inttoptr i64 %3609 to i32*
  %3612 = load i32, i32* %3611, align 4
  %3613 = add i32 %3612, 1
  %3614 = zext i32 %3613 to i64
  store i64 %3614, i64* %RAX, align 8, !tbaa !2428
  %3615 = icmp eq i32 %3612, -1
  %3616 = icmp eq i32 %3613, 0
  %3617 = or i1 %3615, %3616
  %3618 = zext i1 %3617 to i8
  store i8 %3618, i8* %15, align 1, !tbaa !2432
  %3619 = and i32 %3613, 255
  %3620 = tail call i32 @llvm.ctpop.i32(i32 %3619) #11
  %3621 = trunc i32 %3620 to i8
  %3622 = and i8 %3621, 1
  %3623 = xor i8 %3622, 1
  store i8 %3623, i8* %22, align 1, !tbaa !2446
  %3624 = xor i32 %3613, %3612
  %3625 = lshr i32 %3624, 4
  %3626 = trunc i32 %3625 to i8
  %3627 = and i8 %3626, 1
  store i8 %3627, i8* %28, align 1, !tbaa !2447
  %3628 = zext i1 %3616 to i8
  store i8 %3628, i8* %31, align 1, !tbaa !2448
  %3629 = lshr i32 %3613, 31
  %3630 = trunc i32 %3629 to i8
  store i8 %3630, i8* %34, align 1, !tbaa !2449
  %3631 = lshr i32 %3612, 31
  %3632 = xor i32 %3629, %3631
  %3633 = add nuw nsw i32 %3632, %3629
  %3634 = icmp eq i32 %3633, 2
  %3635 = zext i1 %3634 to i8
  store i8 %3635, i8* %40, align 1, !tbaa !2450
  %3636 = sext i32 %3613 to i64
  store i64 %3636, i64* %RDX, align 8, !tbaa !2428
  %3637 = shl nsw i64 %3636, 3
  %3638 = add i64 %3637, %3608
  %3639 = add i64 %3595, 34
  store i64 %3639, i64* %PC, align 8
  %3640 = inttoptr i64 %3638 to double*
  store double %3604, double* %3640, align 8
  %3641 = load i64, i64* %RBP, align 8
  %3642 = add i64 %3641, -28
  %3643 = load i64, i64* %PC, align 8
  %3644 = add i64 %3643, 3
  store i64 %3644, i64* %PC, align 8
  %3645 = inttoptr i64 %3642 to i32*
  %3646 = load i32, i32* %3645, align 4
  %3647 = add i32 %3646, 2
  %3648 = zext i32 %3647 to i64
  store i64 %3648, i64* %RAX, align 8, !tbaa !2428
  %3649 = icmp ugt i32 %3646, -3
  %3650 = zext i1 %3649 to i8
  store i8 %3650, i8* %15, align 1, !tbaa !2432
  %3651 = and i32 %3647, 255
  %3652 = tail call i32 @llvm.ctpop.i32(i32 %3651) #11
  %3653 = trunc i32 %3652 to i8
  %3654 = and i8 %3653, 1
  %3655 = xor i8 %3654, 1
  store i8 %3655, i8* %22, align 1, !tbaa !2446
  %3656 = xor i32 %3647, %3646
  %3657 = lshr i32 %3656, 4
  %3658 = trunc i32 %3657 to i8
  %3659 = and i8 %3658, 1
  store i8 %3659, i8* %28, align 1, !tbaa !2447
  %3660 = icmp eq i32 %3647, 0
  %3661 = zext i1 %3660 to i8
  store i8 %3661, i8* %31, align 1, !tbaa !2448
  %3662 = lshr i32 %3647, 31
  %3663 = trunc i32 %3662 to i8
  store i8 %3663, i8* %34, align 1, !tbaa !2449
  %3664 = lshr i32 %3646, 31
  %3665 = xor i32 %3662, %3664
  %3666 = add nuw nsw i32 %3665, %3662
  %3667 = icmp eq i32 %3666, 2
  %3668 = zext i1 %3667 to i8
  store i8 %3668, i8* %40, align 1, !tbaa !2450
  %3669 = add i64 %3643, 9
  store i64 %3669, i64* %PC, align 8
  store i32 %3647, i32* %3645, align 4
  %3670 = load i64, i64* %PC, align 8
  %3671 = add i64 %3670, -594
  store i64 %3671, i64* %PC, align 8, !tbaa !2428
  br label %block_403356

block_403893:                                     ; preds = %block_403ffb, %block_40387d
  %3672 = phi i64 [ %1565, %block_403ffb ], [ %.pre24, %block_40387d ]
  %3673 = load i64, i64* %RBP, align 8
  %3674 = add i64 %3673, -44
  %3675 = add i64 %3672, 3
  store i64 %3675, i64* %PC, align 8
  %3676 = inttoptr i64 %3674 to i32*
  %3677 = load i32, i32* %3676, align 4
  %3678 = zext i32 %3677 to i64
  store i64 %3678, i64* %RAX, align 8, !tbaa !2428
  %3679 = add i64 %3673, -4
  %3680 = add i64 %3672, 6
  store i64 %3680, i64* %PC, align 8
  %3681 = inttoptr i64 %3679 to i32*
  %3682 = load i32, i32* %3681, align 4
  %3683 = sub i32 %3677, %3682
  %3684 = icmp ult i32 %3677, %3682
  %3685 = zext i1 %3684 to i8
  store i8 %3685, i8* %15, align 1, !tbaa !2432
  %3686 = and i32 %3683, 255
  %3687 = tail call i32 @llvm.ctpop.i32(i32 %3686) #11
  %3688 = trunc i32 %3687 to i8
  %3689 = and i8 %3688, 1
  %3690 = xor i8 %3689, 1
  store i8 %3690, i8* %22, align 1, !tbaa !2446
  %3691 = xor i32 %3682, %3677
  %3692 = xor i32 %3691, %3683
  %3693 = lshr i32 %3692, 4
  %3694 = trunc i32 %3693 to i8
  %3695 = and i8 %3694, 1
  store i8 %3695, i8* %28, align 1, !tbaa !2447
  %3696 = icmp eq i32 %3683, 0
  %3697 = zext i1 %3696 to i8
  store i8 %3697, i8* %31, align 1, !tbaa !2448
  %3698 = lshr i32 %3683, 31
  %3699 = trunc i32 %3698 to i8
  store i8 %3699, i8* %34, align 1, !tbaa !2449
  %3700 = lshr i32 %3677, 31
  %3701 = lshr i32 %3682, 31
  %3702 = xor i32 %3701, %3700
  %3703 = xor i32 %3698, %3700
  %3704 = add nuw nsw i32 %3703, %3702
  %3705 = icmp eq i32 %3704, 2
  %3706 = zext i1 %3705 to i8
  store i8 %3706, i8* %40, align 1, !tbaa !2450
  %3707 = icmp ne i8 %3699, 0
  %3708 = xor i1 %3707, %3705
  %.v28 = select i1 %3708, i64 12, i64 1915
  %3709 = add i64 %.v28, %3672
  store i64 %3709, i64* %PC, align 8, !tbaa !2428
  br i1 %3708, label %block_40389f, label %block_40400e

block_403951:                                     ; preds = %block_403940
  %3710 = add i64 %4843, 3
  store i64 %3710, i64* %PC, align 8
  %3711 = load i32, i32* %4803, align 4
  %3712 = zext i32 %3711 to i64
  store i64 %3712, i64* %RAX, align 8, !tbaa !2428
  %3713 = add i64 %4843, 6
  store i64 %3713, i64* %PC, align 8
  %3714 = load i32, i32* %4808, align 4
  %3715 = add i32 %3714, %3711
  %3716 = zext i32 %3715 to i64
  store i64 %3716, i64* %RAX, align 8, !tbaa !2428
  %3717 = icmp ult i32 %3715, %3711
  %3718 = icmp ult i32 %3715, %3714
  %3719 = or i1 %3717, %3718
  %3720 = zext i1 %3719 to i8
  store i8 %3720, i8* %15, align 1, !tbaa !2432
  %3721 = and i32 %3715, 255
  %3722 = tail call i32 @llvm.ctpop.i32(i32 %3721) #11
  %3723 = trunc i32 %3722 to i8
  %3724 = and i8 %3723, 1
  %3725 = xor i8 %3724, 1
  store i8 %3725, i8* %22, align 1, !tbaa !2446
  %3726 = xor i32 %3714, %3711
  %3727 = xor i32 %3726, %3715
  %3728 = lshr i32 %3727, 4
  %3729 = trunc i32 %3728 to i8
  %3730 = and i8 %3729, 1
  store i8 %3730, i8* %28, align 1, !tbaa !2447
  %3731 = icmp eq i32 %3715, 0
  %3732 = zext i1 %3731 to i8
  store i8 %3732, i8* %31, align 1, !tbaa !2448
  %3733 = lshr i32 %3715, 31
  %3734 = trunc i32 %3733 to i8
  store i8 %3734, i8* %34, align 1, !tbaa !2449
  %3735 = lshr i32 %3711, 31
  %3736 = lshr i32 %3714, 31
  %3737 = xor i32 %3733, %3735
  %3738 = xor i32 %3733, %3736
  %3739 = add nuw nsw i32 %3737, %3738
  %3740 = icmp eq i32 %3739, 2
  %3741 = zext i1 %3740 to i8
  store i8 %3741, i8* %40, align 1, !tbaa !2450
  %3742 = add i64 %4800, -32
  %3743 = add i64 %4843, 9
  store i64 %3743, i64* %PC, align 8
  %3744 = inttoptr i64 %3742 to i32*
  store i32 %3715, i32* %3744, align 4
  %3745 = load i64, i64* %RBP, align 8
  %3746 = add i64 %3745, -32
  %3747 = load i64, i64* %PC, align 8
  %3748 = add i64 %3747, 3
  store i64 %3748, i64* %PC, align 8
  %3749 = inttoptr i64 %3746 to i32*
  %3750 = load i32, i32* %3749, align 4
  %3751 = zext i32 %3750 to i64
  store i64 %3751, i64* %RAX, align 8, !tbaa !2428
  %3752 = add i64 %3745, -8
  %3753 = add i64 %3747, 6
  store i64 %3753, i64* %PC, align 8
  %3754 = inttoptr i64 %3752 to i32*
  %3755 = load i32, i32* %3754, align 4
  %3756 = add i32 %3755, %3750
  %3757 = zext i32 %3756 to i64
  store i64 %3757, i64* %RAX, align 8, !tbaa !2428
  %3758 = icmp ult i32 %3756, %3750
  %3759 = icmp ult i32 %3756, %3755
  %3760 = or i1 %3758, %3759
  %3761 = zext i1 %3760 to i8
  store i8 %3761, i8* %15, align 1, !tbaa !2432
  %3762 = and i32 %3756, 255
  %3763 = tail call i32 @llvm.ctpop.i32(i32 %3762) #11
  %3764 = trunc i32 %3763 to i8
  %3765 = and i8 %3764, 1
  %3766 = xor i8 %3765, 1
  store i8 %3766, i8* %22, align 1, !tbaa !2446
  %3767 = xor i32 %3755, %3750
  %3768 = xor i32 %3767, %3756
  %3769 = lshr i32 %3768, 4
  %3770 = trunc i32 %3769 to i8
  %3771 = and i8 %3770, 1
  store i8 %3771, i8* %28, align 1, !tbaa !2447
  %3772 = icmp eq i32 %3756, 0
  %3773 = zext i1 %3772 to i8
  store i8 %3773, i8* %31, align 1, !tbaa !2448
  %3774 = lshr i32 %3756, 31
  %3775 = trunc i32 %3774 to i8
  store i8 %3775, i8* %34, align 1, !tbaa !2449
  %3776 = lshr i32 %3750, 31
  %3777 = lshr i32 %3755, 31
  %3778 = xor i32 %3774, %3776
  %3779 = xor i32 %3774, %3777
  %3780 = add nuw nsw i32 %3778, %3779
  %3781 = icmp eq i32 %3780, 2
  %3782 = zext i1 %3781 to i8
  store i8 %3782, i8* %40, align 1, !tbaa !2450
  %3783 = add i64 %3745, -36
  %3784 = add i64 %3747, 9
  store i64 %3784, i64* %PC, align 8
  %3785 = inttoptr i64 %3783 to i32*
  store i32 %3756, i32* %3785, align 4
  %3786 = load i64, i64* %RBP, align 8
  %3787 = add i64 %3786, -36
  %3788 = load i64, i64* %PC, align 8
  %3789 = add i64 %3788, 3
  store i64 %3789, i64* %PC, align 8
  %3790 = inttoptr i64 %3787 to i32*
  %3791 = load i32, i32* %3790, align 4
  %3792 = zext i32 %3791 to i64
  store i64 %3792, i64* %RAX, align 8, !tbaa !2428
  %3793 = add i64 %3786, -8
  %3794 = add i64 %3788, 6
  store i64 %3794, i64* %PC, align 8
  %3795 = inttoptr i64 %3793 to i32*
  %3796 = load i32, i32* %3795, align 4
  %3797 = add i32 %3796, %3791
  %3798 = zext i32 %3797 to i64
  store i64 %3798, i64* %RAX, align 8, !tbaa !2428
  %3799 = icmp ult i32 %3797, %3791
  %3800 = icmp ult i32 %3797, %3796
  %3801 = or i1 %3799, %3800
  %3802 = zext i1 %3801 to i8
  store i8 %3802, i8* %15, align 1, !tbaa !2432
  %3803 = and i32 %3797, 255
  %3804 = tail call i32 @llvm.ctpop.i32(i32 %3803) #11
  %3805 = trunc i32 %3804 to i8
  %3806 = and i8 %3805, 1
  %3807 = xor i8 %3806, 1
  store i8 %3807, i8* %22, align 1, !tbaa !2446
  %3808 = xor i32 %3796, %3791
  %3809 = xor i32 %3808, %3797
  %3810 = lshr i32 %3809, 4
  %3811 = trunc i32 %3810 to i8
  %3812 = and i8 %3811, 1
  store i8 %3812, i8* %28, align 1, !tbaa !2447
  %3813 = icmp eq i32 %3797, 0
  %3814 = zext i1 %3813 to i8
  store i8 %3814, i8* %31, align 1, !tbaa !2448
  %3815 = lshr i32 %3797, 31
  %3816 = trunc i32 %3815 to i8
  store i8 %3816, i8* %34, align 1, !tbaa !2449
  %3817 = lshr i32 %3791, 31
  %3818 = lshr i32 %3796, 31
  %3819 = xor i32 %3815, %3817
  %3820 = xor i32 %3815, %3818
  %3821 = add nuw nsw i32 %3819, %3820
  %3822 = icmp eq i32 %3821, 2
  %3823 = zext i1 %3822 to i8
  store i8 %3823, i8* %40, align 1, !tbaa !2450
  %3824 = add i64 %3786, -40
  %3825 = add i64 %3788, 9
  store i64 %3825, i64* %PC, align 8
  %3826 = inttoptr i64 %3824 to i32*
  store i32 %3797, i32* %3826, align 4
  %3827 = load i64, i64* %RBP, align 8
  %3828 = add i64 %3827, -16
  %3829 = load i64, i64* %PC, align 8
  %3830 = add i64 %3829, 4
  store i64 %3830, i64* %PC, align 8
  %3831 = inttoptr i64 %3828 to i64*
  %3832 = load i64, i64* %3831, align 8
  store i64 %3832, i64* %RCX, align 8, !tbaa !2428
  %3833 = add i64 %3827, -28
  %3834 = add i64 %3829, 8
  store i64 %3834, i64* %PC, align 8
  %3835 = inttoptr i64 %3833 to i32*
  %3836 = load i32, i32* %3835, align 4
  %3837 = sext i32 %3836 to i64
  store i64 %3837, i64* %RDX, align 8, !tbaa !2428
  %3838 = shl nsw i64 %3837, 3
  %3839 = add i64 %3838, %3832
  %3840 = add i64 %3829, 13
  store i64 %3840, i64* %PC, align 8
  %3841 = inttoptr i64 %3839 to i64*
  %3842 = load i64, i64* %3841, align 8
  store i64 %3842, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3843 = add i64 %3829, 17
  store i64 %3843, i64* %PC, align 8
  %3844 = load i64, i64* %3831, align 8
  store i64 %3844, i64* %RCX, align 8, !tbaa !2428
  %3845 = add i64 %3827, -32
  %3846 = add i64 %3829, 21
  store i64 %3846, i64* %PC, align 8
  %3847 = inttoptr i64 %3845 to i32*
  %3848 = load i32, i32* %3847, align 4
  %3849 = sext i32 %3848 to i64
  store i64 %3849, i64* %RDX, align 8, !tbaa !2428
  %3850 = shl nsw i64 %3849, 3
  %3851 = add i64 %3850, %3844
  %3852 = add i64 %3829, 26
  store i64 %3852, i64* %PC, align 8
  %3853 = bitcast i64 %3842 to double
  %3854 = inttoptr i64 %3851 to double*
  %3855 = load double, double* %3854, align 8
  %3856 = fadd double %3853, %3855
  store double %3856, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3857 = add i64 %3827, -120
  %3858 = add i64 %3829, 31
  store i64 %3858, i64* %PC, align 8
  %3859 = inttoptr i64 %3857 to double*
  store double %3856, double* %3859, align 8
  %3860 = load i64, i64* %RBP, align 8
  %3861 = add i64 %3860, -16
  %3862 = load i64, i64* %PC, align 8
  %3863 = add i64 %3862, 4
  store i64 %3863, i64* %PC, align 8
  %3864 = inttoptr i64 %3861 to i64*
  %3865 = load i64, i64* %3864, align 8
  store i64 %3865, i64* %RCX, align 8, !tbaa !2428
  %3866 = add i64 %3860, -28
  %3867 = add i64 %3862, 7
  store i64 %3867, i64* %PC, align 8
  %3868 = inttoptr i64 %3866 to i32*
  %3869 = load i32, i32* %3868, align 4
  %3870 = add i32 %3869, 1
  %3871 = zext i32 %3870 to i64
  store i64 %3871, i64* %RAX, align 8, !tbaa !2428
  %3872 = icmp eq i32 %3869, -1
  %3873 = icmp eq i32 %3870, 0
  %3874 = or i1 %3872, %3873
  %3875 = zext i1 %3874 to i8
  store i8 %3875, i8* %15, align 1, !tbaa !2432
  %3876 = and i32 %3870, 255
  %3877 = tail call i32 @llvm.ctpop.i32(i32 %3876) #11
  %3878 = trunc i32 %3877 to i8
  %3879 = and i8 %3878, 1
  %3880 = xor i8 %3879, 1
  store i8 %3880, i8* %22, align 1, !tbaa !2446
  %3881 = xor i32 %3870, %3869
  %3882 = lshr i32 %3881, 4
  %3883 = trunc i32 %3882 to i8
  %3884 = and i8 %3883, 1
  store i8 %3884, i8* %28, align 1, !tbaa !2447
  %3885 = zext i1 %3873 to i8
  store i8 %3885, i8* %31, align 1, !tbaa !2448
  %3886 = lshr i32 %3870, 31
  %3887 = trunc i32 %3886 to i8
  store i8 %3887, i8* %34, align 1, !tbaa !2449
  %3888 = lshr i32 %3869, 31
  %3889 = xor i32 %3886, %3888
  %3890 = add nuw nsw i32 %3889, %3886
  %3891 = icmp eq i32 %3890, 2
  %3892 = zext i1 %3891 to i8
  store i8 %3892, i8* %40, align 1, !tbaa !2450
  %3893 = sext i32 %3870 to i64
  store i64 %3893, i64* %RDX, align 8, !tbaa !2428
  %3894 = shl nsw i64 %3893, 3
  %3895 = add i64 %3894, %3865
  %3896 = add i64 %3862, 18
  store i64 %3896, i64* %PC, align 8
  %3897 = inttoptr i64 %3895 to i64*
  %3898 = load i64, i64* %3897, align 8
  store i64 %3898, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3899 = add i64 %3862, 22
  store i64 %3899, i64* %PC, align 8
  %3900 = load i64, i64* %3864, align 8
  store i64 %3900, i64* %RCX, align 8, !tbaa !2428
  %3901 = add i64 %3860, -32
  %3902 = add i64 %3862, 25
  store i64 %3902, i64* %PC, align 8
  %3903 = inttoptr i64 %3901 to i32*
  %3904 = load i32, i32* %3903, align 4
  %3905 = add i32 %3904, 1
  %3906 = zext i32 %3905 to i64
  store i64 %3906, i64* %RAX, align 8, !tbaa !2428
  %3907 = icmp eq i32 %3904, -1
  %3908 = icmp eq i32 %3905, 0
  %3909 = or i1 %3907, %3908
  %3910 = zext i1 %3909 to i8
  store i8 %3910, i8* %15, align 1, !tbaa !2432
  %3911 = and i32 %3905, 255
  %3912 = tail call i32 @llvm.ctpop.i32(i32 %3911) #11
  %3913 = trunc i32 %3912 to i8
  %3914 = and i8 %3913, 1
  %3915 = xor i8 %3914, 1
  store i8 %3915, i8* %22, align 1, !tbaa !2446
  %3916 = xor i32 %3905, %3904
  %3917 = lshr i32 %3916, 4
  %3918 = trunc i32 %3917 to i8
  %3919 = and i8 %3918, 1
  store i8 %3919, i8* %28, align 1, !tbaa !2447
  %3920 = zext i1 %3908 to i8
  store i8 %3920, i8* %31, align 1, !tbaa !2448
  %3921 = lshr i32 %3905, 31
  %3922 = trunc i32 %3921 to i8
  store i8 %3922, i8* %34, align 1, !tbaa !2449
  %3923 = lshr i32 %3904, 31
  %3924 = xor i32 %3921, %3923
  %3925 = add nuw nsw i32 %3924, %3921
  %3926 = icmp eq i32 %3925, 2
  %3927 = zext i1 %3926 to i8
  store i8 %3927, i8* %40, align 1, !tbaa !2450
  %3928 = sext i32 %3905 to i64
  store i64 %3928, i64* %RDX, align 8, !tbaa !2428
  %3929 = shl nsw i64 %3928, 3
  %3930 = add i64 %3929, %3900
  %3931 = add i64 %3862, 36
  store i64 %3931, i64* %PC, align 8
  %3932 = bitcast i64 %3898 to double
  %3933 = inttoptr i64 %3930 to double*
  %3934 = load double, double* %3933, align 8
  %3935 = fadd double %3932, %3934
  store double %3935, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3936 = load i64, i64* %RBP, align 8
  %3937 = add i64 %3936, -128
  %3938 = add i64 %3862, 41
  store i64 %3938, i64* %PC, align 8
  %3939 = inttoptr i64 %3937 to double*
  store double %3935, double* %3939, align 8
  %3940 = load i64, i64* %RBP, align 8
  %3941 = add i64 %3940, -16
  %3942 = load i64, i64* %PC, align 8
  %3943 = add i64 %3942, 4
  store i64 %3943, i64* %PC, align 8
  %3944 = inttoptr i64 %3941 to i64*
  %3945 = load i64, i64* %3944, align 8
  store i64 %3945, i64* %RCX, align 8, !tbaa !2428
  %3946 = add i64 %3940, -28
  %3947 = add i64 %3942, 8
  store i64 %3947, i64* %PC, align 8
  %3948 = inttoptr i64 %3946 to i32*
  %3949 = load i32, i32* %3948, align 4
  %3950 = sext i32 %3949 to i64
  store i64 %3950, i64* %RDX, align 8, !tbaa !2428
  %3951 = shl nsw i64 %3950, 3
  %3952 = add i64 %3951, %3945
  %3953 = add i64 %3942, 13
  store i64 %3953, i64* %PC, align 8
  %3954 = inttoptr i64 %3952 to i64*
  %3955 = load i64, i64* %3954, align 8
  store i64 %3955, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %3956 = add i64 %3942, 17
  store i64 %3956, i64* %PC, align 8
  %3957 = load i64, i64* %3944, align 8
  store i64 %3957, i64* %RCX, align 8, !tbaa !2428
  %3958 = add i64 %3940, -32
  %3959 = add i64 %3942, 21
  store i64 %3959, i64* %PC, align 8
  %3960 = inttoptr i64 %3958 to i32*
  %3961 = load i32, i32* %3960, align 4
  %3962 = sext i32 %3961 to i64
  store i64 %3962, i64* %RDX, align 8, !tbaa !2428
  %3963 = shl nsw i64 %3962, 3
  %3964 = add i64 %3963, %3957
  %3965 = add i64 %3942, 26
  store i64 %3965, i64* %PC, align 8
  %3966 = bitcast i64 %3955 to double
  %3967 = inttoptr i64 %3964 to double*
  %3968 = load double, double* %3967, align 8
  %3969 = fsub double %3966, %3968
  store double %3969, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %3970 = add i64 %3940, -136
  %3971 = add i64 %3942, 34
  store i64 %3971, i64* %PC, align 8
  %3972 = inttoptr i64 %3970 to double*
  store double %3969, double* %3972, align 8
  %3973 = load i64, i64* %RBP, align 8
  %3974 = add i64 %3973, -16
  %3975 = load i64, i64* %PC, align 8
  %3976 = add i64 %3975, 4
  store i64 %3976, i64* %PC, align 8
  %3977 = inttoptr i64 %3974 to i64*
  %3978 = load i64, i64* %3977, align 8
  store i64 %3978, i64* %RCX, align 8, !tbaa !2428
  %3979 = add i64 %3973, -28
  %3980 = add i64 %3975, 7
  store i64 %3980, i64* %PC, align 8
  %3981 = inttoptr i64 %3979 to i32*
  %3982 = load i32, i32* %3981, align 4
  %3983 = add i32 %3982, 1
  %3984 = zext i32 %3983 to i64
  store i64 %3984, i64* %RAX, align 8, !tbaa !2428
  %3985 = icmp eq i32 %3982, -1
  %3986 = icmp eq i32 %3983, 0
  %3987 = or i1 %3985, %3986
  %3988 = zext i1 %3987 to i8
  store i8 %3988, i8* %15, align 1, !tbaa !2432
  %3989 = and i32 %3983, 255
  %3990 = tail call i32 @llvm.ctpop.i32(i32 %3989) #11
  %3991 = trunc i32 %3990 to i8
  %3992 = and i8 %3991, 1
  %3993 = xor i8 %3992, 1
  store i8 %3993, i8* %22, align 1, !tbaa !2446
  %3994 = xor i32 %3983, %3982
  %3995 = lshr i32 %3994, 4
  %3996 = trunc i32 %3995 to i8
  %3997 = and i8 %3996, 1
  store i8 %3997, i8* %28, align 1, !tbaa !2447
  %3998 = zext i1 %3986 to i8
  store i8 %3998, i8* %31, align 1, !tbaa !2448
  %3999 = lshr i32 %3983, 31
  %4000 = trunc i32 %3999 to i8
  store i8 %4000, i8* %34, align 1, !tbaa !2449
  %4001 = lshr i32 %3982, 31
  %4002 = xor i32 %3999, %4001
  %4003 = add nuw nsw i32 %4002, %3999
  %4004 = icmp eq i32 %4003, 2
  %4005 = zext i1 %4004 to i8
  store i8 %4005, i8* %40, align 1, !tbaa !2450
  %4006 = sext i32 %3983 to i64
  store i64 %4006, i64* %RDX, align 8, !tbaa !2428
  %4007 = shl nsw i64 %4006, 3
  %4008 = add i64 %4007, %3978
  %4009 = add i64 %3975, 18
  store i64 %4009, i64* %PC, align 8
  %4010 = inttoptr i64 %4008 to i64*
  %4011 = load i64, i64* %4010, align 8
  store i64 %4011, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4012 = add i64 %3975, 22
  store i64 %4012, i64* %PC, align 8
  %4013 = load i64, i64* %3977, align 8
  store i64 %4013, i64* %RCX, align 8, !tbaa !2428
  %4014 = add i64 %3973, -32
  %4015 = add i64 %3975, 25
  store i64 %4015, i64* %PC, align 8
  %4016 = inttoptr i64 %4014 to i32*
  %4017 = load i32, i32* %4016, align 4
  %4018 = add i32 %4017, 1
  %4019 = zext i32 %4018 to i64
  store i64 %4019, i64* %RAX, align 8, !tbaa !2428
  %4020 = icmp eq i32 %4017, -1
  %4021 = icmp eq i32 %4018, 0
  %4022 = or i1 %4020, %4021
  %4023 = zext i1 %4022 to i8
  store i8 %4023, i8* %15, align 1, !tbaa !2432
  %4024 = and i32 %4018, 255
  %4025 = tail call i32 @llvm.ctpop.i32(i32 %4024) #11
  %4026 = trunc i32 %4025 to i8
  %4027 = and i8 %4026, 1
  %4028 = xor i8 %4027, 1
  store i8 %4028, i8* %22, align 1, !tbaa !2446
  %4029 = xor i32 %4018, %4017
  %4030 = lshr i32 %4029, 4
  %4031 = trunc i32 %4030 to i8
  %4032 = and i8 %4031, 1
  store i8 %4032, i8* %28, align 1, !tbaa !2447
  %4033 = zext i1 %4021 to i8
  store i8 %4033, i8* %31, align 1, !tbaa !2448
  %4034 = lshr i32 %4018, 31
  %4035 = trunc i32 %4034 to i8
  store i8 %4035, i8* %34, align 1, !tbaa !2449
  %4036 = lshr i32 %4017, 31
  %4037 = xor i32 %4034, %4036
  %4038 = add nuw nsw i32 %4037, %4034
  %4039 = icmp eq i32 %4038, 2
  %4040 = zext i1 %4039 to i8
  store i8 %4040, i8* %40, align 1, !tbaa !2450
  %4041 = sext i32 %4018 to i64
  store i64 %4041, i64* %RDX, align 8, !tbaa !2428
  %4042 = shl nsw i64 %4041, 3
  %4043 = add i64 %4042, %4013
  %4044 = add i64 %3975, 36
  store i64 %4044, i64* %PC, align 8
  %4045 = bitcast i64 %4011 to double
  %4046 = inttoptr i64 %4043 to double*
  %4047 = load double, double* %4046, align 8
  %4048 = fsub double %4045, %4047
  store double %4048, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4049 = load i64, i64* %RBP, align 8
  %4050 = add i64 %4049, -144
  %4051 = add i64 %3975, 44
  store i64 %4051, i64* %PC, align 8
  %4052 = inttoptr i64 %4050 to double*
  store double %4048, double* %4052, align 8
  %4053 = load i64, i64* %RBP, align 8
  %4054 = add i64 %4053, -16
  %4055 = load i64, i64* %PC, align 8
  %4056 = add i64 %4055, 4
  store i64 %4056, i64* %PC, align 8
  %4057 = inttoptr i64 %4054 to i64*
  %4058 = load i64, i64* %4057, align 8
  store i64 %4058, i64* %RCX, align 8, !tbaa !2428
  %4059 = add i64 %4053, -36
  %4060 = add i64 %4055, 8
  store i64 %4060, i64* %PC, align 8
  %4061 = inttoptr i64 %4059 to i32*
  %4062 = load i32, i32* %4061, align 4
  %4063 = sext i32 %4062 to i64
  store i64 %4063, i64* %RDX, align 8, !tbaa !2428
  %4064 = shl nsw i64 %4063, 3
  %4065 = add i64 %4064, %4058
  %4066 = add i64 %4055, 13
  store i64 %4066, i64* %PC, align 8
  %4067 = inttoptr i64 %4065 to i64*
  %4068 = load i64, i64* %4067, align 8
  store i64 %4068, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4069 = add i64 %4055, 17
  store i64 %4069, i64* %PC, align 8
  %4070 = load i64, i64* %4057, align 8
  store i64 %4070, i64* %RCX, align 8, !tbaa !2428
  %4071 = add i64 %4053, -40
  %4072 = add i64 %4055, 21
  store i64 %4072, i64* %PC, align 8
  %4073 = inttoptr i64 %4071 to i32*
  %4074 = load i32, i32* %4073, align 4
  %4075 = sext i32 %4074 to i64
  store i64 %4075, i64* %RDX, align 8, !tbaa !2428
  %4076 = shl nsw i64 %4075, 3
  %4077 = add i64 %4076, %4070
  %4078 = add i64 %4055, 26
  store i64 %4078, i64* %PC, align 8
  %4079 = bitcast i64 %4068 to double
  %4080 = inttoptr i64 %4077 to double*
  %4081 = load double, double* %4080, align 8
  %4082 = fadd double %4079, %4081
  store double %4082, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4083 = add i64 %4053, -152
  %4084 = add i64 %4055, 34
  store i64 %4084, i64* %PC, align 8
  %4085 = inttoptr i64 %4083 to double*
  store double %4082, double* %4085, align 8
  %4086 = load i64, i64* %RBP, align 8
  %4087 = add i64 %4086, -16
  %4088 = load i64, i64* %PC, align 8
  %4089 = add i64 %4088, 4
  store i64 %4089, i64* %PC, align 8
  %4090 = inttoptr i64 %4087 to i64*
  %4091 = load i64, i64* %4090, align 8
  store i64 %4091, i64* %RCX, align 8, !tbaa !2428
  %4092 = add i64 %4086, -36
  %4093 = add i64 %4088, 7
  store i64 %4093, i64* %PC, align 8
  %4094 = inttoptr i64 %4092 to i32*
  %4095 = load i32, i32* %4094, align 4
  %4096 = add i32 %4095, 1
  %4097 = zext i32 %4096 to i64
  store i64 %4097, i64* %RAX, align 8, !tbaa !2428
  %4098 = icmp eq i32 %4095, -1
  %4099 = icmp eq i32 %4096, 0
  %4100 = or i1 %4098, %4099
  %4101 = zext i1 %4100 to i8
  store i8 %4101, i8* %15, align 1, !tbaa !2432
  %4102 = and i32 %4096, 255
  %4103 = tail call i32 @llvm.ctpop.i32(i32 %4102) #11
  %4104 = trunc i32 %4103 to i8
  %4105 = and i8 %4104, 1
  %4106 = xor i8 %4105, 1
  store i8 %4106, i8* %22, align 1, !tbaa !2446
  %4107 = xor i32 %4096, %4095
  %4108 = lshr i32 %4107, 4
  %4109 = trunc i32 %4108 to i8
  %4110 = and i8 %4109, 1
  store i8 %4110, i8* %28, align 1, !tbaa !2447
  %4111 = zext i1 %4099 to i8
  store i8 %4111, i8* %31, align 1, !tbaa !2448
  %4112 = lshr i32 %4096, 31
  %4113 = trunc i32 %4112 to i8
  store i8 %4113, i8* %34, align 1, !tbaa !2449
  %4114 = lshr i32 %4095, 31
  %4115 = xor i32 %4112, %4114
  %4116 = add nuw nsw i32 %4115, %4112
  %4117 = icmp eq i32 %4116, 2
  %4118 = zext i1 %4117 to i8
  store i8 %4118, i8* %40, align 1, !tbaa !2450
  %4119 = sext i32 %4096 to i64
  store i64 %4119, i64* %RDX, align 8, !tbaa !2428
  %4120 = shl nsw i64 %4119, 3
  %4121 = add i64 %4120, %4091
  %4122 = add i64 %4088, 18
  store i64 %4122, i64* %PC, align 8
  %4123 = inttoptr i64 %4121 to i64*
  %4124 = load i64, i64* %4123, align 8
  store i64 %4124, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4125 = add i64 %4088, 22
  store i64 %4125, i64* %PC, align 8
  %4126 = load i64, i64* %4090, align 8
  store i64 %4126, i64* %RCX, align 8, !tbaa !2428
  %4127 = add i64 %4086, -40
  %4128 = add i64 %4088, 25
  store i64 %4128, i64* %PC, align 8
  %4129 = inttoptr i64 %4127 to i32*
  %4130 = load i32, i32* %4129, align 4
  %4131 = add i32 %4130, 1
  %4132 = zext i32 %4131 to i64
  store i64 %4132, i64* %RAX, align 8, !tbaa !2428
  %4133 = icmp eq i32 %4130, -1
  %4134 = icmp eq i32 %4131, 0
  %4135 = or i1 %4133, %4134
  %4136 = zext i1 %4135 to i8
  store i8 %4136, i8* %15, align 1, !tbaa !2432
  %4137 = and i32 %4131, 255
  %4138 = tail call i32 @llvm.ctpop.i32(i32 %4137) #11
  %4139 = trunc i32 %4138 to i8
  %4140 = and i8 %4139, 1
  %4141 = xor i8 %4140, 1
  store i8 %4141, i8* %22, align 1, !tbaa !2446
  %4142 = xor i32 %4131, %4130
  %4143 = lshr i32 %4142, 4
  %4144 = trunc i32 %4143 to i8
  %4145 = and i8 %4144, 1
  store i8 %4145, i8* %28, align 1, !tbaa !2447
  %4146 = zext i1 %4134 to i8
  store i8 %4146, i8* %31, align 1, !tbaa !2448
  %4147 = lshr i32 %4131, 31
  %4148 = trunc i32 %4147 to i8
  store i8 %4148, i8* %34, align 1, !tbaa !2449
  %4149 = lshr i32 %4130, 31
  %4150 = xor i32 %4147, %4149
  %4151 = add nuw nsw i32 %4150, %4147
  %4152 = icmp eq i32 %4151, 2
  %4153 = zext i1 %4152 to i8
  store i8 %4153, i8* %40, align 1, !tbaa !2450
  %4154 = sext i32 %4131 to i64
  store i64 %4154, i64* %RDX, align 8, !tbaa !2428
  %4155 = shl nsw i64 %4154, 3
  %4156 = add i64 %4155, %4126
  %4157 = add i64 %4088, 36
  store i64 %4157, i64* %PC, align 8
  %4158 = bitcast i64 %4124 to double
  %4159 = inttoptr i64 %4156 to double*
  %4160 = load double, double* %4159, align 8
  %4161 = fadd double %4158, %4160
  store double %4161, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4162 = load i64, i64* %RBP, align 8
  %4163 = add i64 %4162, -160
  %4164 = add i64 %4088, 44
  store i64 %4164, i64* %PC, align 8
  %4165 = inttoptr i64 %4163 to double*
  store double %4161, double* %4165, align 8
  %4166 = load i64, i64* %RBP, align 8
  %4167 = add i64 %4166, -16
  %4168 = load i64, i64* %PC, align 8
  %4169 = add i64 %4168, 4
  store i64 %4169, i64* %PC, align 8
  %4170 = inttoptr i64 %4167 to i64*
  %4171 = load i64, i64* %4170, align 8
  store i64 %4171, i64* %RCX, align 8, !tbaa !2428
  %4172 = add i64 %4166, -36
  %4173 = add i64 %4168, 8
  store i64 %4173, i64* %PC, align 8
  %4174 = inttoptr i64 %4172 to i32*
  %4175 = load i32, i32* %4174, align 4
  %4176 = sext i32 %4175 to i64
  store i64 %4176, i64* %RDX, align 8, !tbaa !2428
  %4177 = shl nsw i64 %4176, 3
  %4178 = add i64 %4177, %4171
  %4179 = add i64 %4168, 13
  store i64 %4179, i64* %PC, align 8
  %4180 = inttoptr i64 %4178 to i64*
  %4181 = load i64, i64* %4180, align 8
  store i64 %4181, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4182 = add i64 %4168, 17
  store i64 %4182, i64* %PC, align 8
  %4183 = load i64, i64* %4170, align 8
  store i64 %4183, i64* %RCX, align 8, !tbaa !2428
  %4184 = add i64 %4166, -40
  %4185 = add i64 %4168, 21
  store i64 %4185, i64* %PC, align 8
  %4186 = inttoptr i64 %4184 to i32*
  %4187 = load i32, i32* %4186, align 4
  %4188 = sext i32 %4187 to i64
  store i64 %4188, i64* %RDX, align 8, !tbaa !2428
  %4189 = shl nsw i64 %4188, 3
  %4190 = add i64 %4189, %4183
  %4191 = add i64 %4168, 26
  store i64 %4191, i64* %PC, align 8
  %4192 = bitcast i64 %4181 to double
  %4193 = inttoptr i64 %4190 to double*
  %4194 = load double, double* %4193, align 8
  %4195 = fsub double %4192, %4194
  store double %4195, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4196 = add i64 %4166, -168
  %4197 = add i64 %4168, 34
  store i64 %4197, i64* %PC, align 8
  %4198 = inttoptr i64 %4196 to double*
  store double %4195, double* %4198, align 8
  %4199 = load i64, i64* %RBP, align 8
  %4200 = add i64 %4199, -16
  %4201 = load i64, i64* %PC, align 8
  %4202 = add i64 %4201, 4
  store i64 %4202, i64* %PC, align 8
  %4203 = inttoptr i64 %4200 to i64*
  %4204 = load i64, i64* %4203, align 8
  store i64 %4204, i64* %RCX, align 8, !tbaa !2428
  %4205 = add i64 %4199, -36
  %4206 = add i64 %4201, 7
  store i64 %4206, i64* %PC, align 8
  %4207 = inttoptr i64 %4205 to i32*
  %4208 = load i32, i32* %4207, align 4
  %4209 = add i32 %4208, 1
  %4210 = zext i32 %4209 to i64
  store i64 %4210, i64* %RAX, align 8, !tbaa !2428
  %4211 = icmp eq i32 %4208, -1
  %4212 = icmp eq i32 %4209, 0
  %4213 = or i1 %4211, %4212
  %4214 = zext i1 %4213 to i8
  store i8 %4214, i8* %15, align 1, !tbaa !2432
  %4215 = and i32 %4209, 255
  %4216 = tail call i32 @llvm.ctpop.i32(i32 %4215) #11
  %4217 = trunc i32 %4216 to i8
  %4218 = and i8 %4217, 1
  %4219 = xor i8 %4218, 1
  store i8 %4219, i8* %22, align 1, !tbaa !2446
  %4220 = xor i32 %4209, %4208
  %4221 = lshr i32 %4220, 4
  %4222 = trunc i32 %4221 to i8
  %4223 = and i8 %4222, 1
  store i8 %4223, i8* %28, align 1, !tbaa !2447
  %4224 = zext i1 %4212 to i8
  store i8 %4224, i8* %31, align 1, !tbaa !2448
  %4225 = lshr i32 %4209, 31
  %4226 = trunc i32 %4225 to i8
  store i8 %4226, i8* %34, align 1, !tbaa !2449
  %4227 = lshr i32 %4208, 31
  %4228 = xor i32 %4225, %4227
  %4229 = add nuw nsw i32 %4228, %4225
  %4230 = icmp eq i32 %4229, 2
  %4231 = zext i1 %4230 to i8
  store i8 %4231, i8* %40, align 1, !tbaa !2450
  %4232 = sext i32 %4209 to i64
  store i64 %4232, i64* %RDX, align 8, !tbaa !2428
  %4233 = shl nsw i64 %4232, 3
  %4234 = add i64 %4233, %4204
  %4235 = add i64 %4201, 18
  store i64 %4235, i64* %PC, align 8
  %4236 = inttoptr i64 %4234 to i64*
  %4237 = load i64, i64* %4236, align 8
  store i64 %4237, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4238 = add i64 %4201, 22
  store i64 %4238, i64* %PC, align 8
  %4239 = load i64, i64* %4203, align 8
  store i64 %4239, i64* %RCX, align 8, !tbaa !2428
  %4240 = add i64 %4199, -40
  %4241 = add i64 %4201, 25
  store i64 %4241, i64* %PC, align 8
  %4242 = inttoptr i64 %4240 to i32*
  %4243 = load i32, i32* %4242, align 4
  %4244 = add i32 %4243, 1
  %4245 = zext i32 %4244 to i64
  store i64 %4245, i64* %RAX, align 8, !tbaa !2428
  %4246 = icmp eq i32 %4243, -1
  %4247 = icmp eq i32 %4244, 0
  %4248 = or i1 %4246, %4247
  %4249 = zext i1 %4248 to i8
  store i8 %4249, i8* %15, align 1, !tbaa !2432
  %4250 = and i32 %4244, 255
  %4251 = tail call i32 @llvm.ctpop.i32(i32 %4250) #11
  %4252 = trunc i32 %4251 to i8
  %4253 = and i8 %4252, 1
  %4254 = xor i8 %4253, 1
  store i8 %4254, i8* %22, align 1, !tbaa !2446
  %4255 = xor i32 %4244, %4243
  %4256 = lshr i32 %4255, 4
  %4257 = trunc i32 %4256 to i8
  %4258 = and i8 %4257, 1
  store i8 %4258, i8* %28, align 1, !tbaa !2447
  %4259 = zext i1 %4247 to i8
  store i8 %4259, i8* %31, align 1, !tbaa !2448
  %4260 = lshr i32 %4244, 31
  %4261 = trunc i32 %4260 to i8
  store i8 %4261, i8* %34, align 1, !tbaa !2449
  %4262 = lshr i32 %4243, 31
  %4263 = xor i32 %4260, %4262
  %4264 = add nuw nsw i32 %4263, %4260
  %4265 = icmp eq i32 %4264, 2
  %4266 = zext i1 %4265 to i8
  store i8 %4266, i8* %40, align 1, !tbaa !2450
  %4267 = sext i32 %4244 to i64
  store i64 %4267, i64* %RDX, align 8, !tbaa !2428
  %4268 = shl nsw i64 %4267, 3
  %4269 = add i64 %4268, %4239
  %4270 = add i64 %4201, 36
  store i64 %4270, i64* %PC, align 8
  %4271 = bitcast i64 %4237 to double
  %4272 = inttoptr i64 %4269 to double*
  %4273 = load double, double* %4272, align 8
  %4274 = fsub double %4271, %4273
  store double %4274, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4275 = load i64, i64* %RBP, align 8
  %4276 = add i64 %4275, -176
  %4277 = add i64 %4201, 44
  store i64 %4277, i64* %PC, align 8
  %4278 = inttoptr i64 %4276 to double*
  store double %4274, double* %4278, align 8
  %4279 = load i64, i64* %RBP, align 8
  %4280 = add i64 %4279, -120
  %4281 = load i64, i64* %PC, align 8
  %4282 = add i64 %4281, 5
  store i64 %4282, i64* %PC, align 8
  %4283 = inttoptr i64 %4280 to i64*
  %4284 = load i64, i64* %4283, align 8
  store i64 %4284, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4285 = add i64 %4279, -152
  %4286 = add i64 %4281, 13
  store i64 %4286, i64* %PC, align 8
  %4287 = bitcast i64 %4284 to double
  %4288 = inttoptr i64 %4285 to double*
  %4289 = load double, double* %4288, align 8
  %4290 = fadd double %4287, %4289
  store double %4290, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4291 = add i64 %4279, -16
  %4292 = add i64 %4281, 17
  store i64 %4292, i64* %PC, align 8
  %4293 = inttoptr i64 %4291 to i64*
  %4294 = load i64, i64* %4293, align 8
  store i64 %4294, i64* %RCX, align 8, !tbaa !2428
  %4295 = add i64 %4279, -28
  %4296 = add i64 %4281, 21
  store i64 %4296, i64* %PC, align 8
  %4297 = inttoptr i64 %4295 to i32*
  %4298 = load i32, i32* %4297, align 4
  %4299 = sext i32 %4298 to i64
  store i64 %4299, i64* %RDX, align 8, !tbaa !2428
  %4300 = shl nsw i64 %4299, 3
  %4301 = add i64 %4300, %4294
  %4302 = add i64 %4281, 26
  store i64 %4302, i64* %PC, align 8
  %4303 = inttoptr i64 %4301 to double*
  store double %4290, double* %4303, align 8
  %4304 = load i64, i64* %RBP, align 8
  %4305 = add i64 %4304, -128
  %4306 = load i64, i64* %PC, align 8
  %4307 = add i64 %4306, 5
  store i64 %4307, i64* %PC, align 8
  %4308 = inttoptr i64 %4305 to i64*
  %4309 = load i64, i64* %4308, align 8
  store i64 %4309, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4310 = add i64 %4304, -160
  %4311 = add i64 %4306, 13
  store i64 %4311, i64* %PC, align 8
  %4312 = bitcast i64 %4309 to double
  %4313 = inttoptr i64 %4310 to double*
  %4314 = load double, double* %4313, align 8
  %4315 = fadd double %4312, %4314
  store double %4315, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4316 = add i64 %4304, -16
  %4317 = add i64 %4306, 17
  store i64 %4317, i64* %PC, align 8
  %4318 = inttoptr i64 %4316 to i64*
  %4319 = load i64, i64* %4318, align 8
  store i64 %4319, i64* %RCX, align 8, !tbaa !2428
  %4320 = add i64 %4304, -28
  %4321 = add i64 %4306, 20
  store i64 %4321, i64* %PC, align 8
  %4322 = inttoptr i64 %4320 to i32*
  %4323 = load i32, i32* %4322, align 4
  %4324 = add i32 %4323, 1
  %4325 = zext i32 %4324 to i64
  store i64 %4325, i64* %RAX, align 8, !tbaa !2428
  %4326 = icmp eq i32 %4323, -1
  %4327 = icmp eq i32 %4324, 0
  %4328 = or i1 %4326, %4327
  %4329 = zext i1 %4328 to i8
  store i8 %4329, i8* %15, align 1, !tbaa !2432
  %4330 = and i32 %4324, 255
  %4331 = tail call i32 @llvm.ctpop.i32(i32 %4330) #11
  %4332 = trunc i32 %4331 to i8
  %4333 = and i8 %4332, 1
  %4334 = xor i8 %4333, 1
  store i8 %4334, i8* %22, align 1, !tbaa !2446
  %4335 = xor i32 %4324, %4323
  %4336 = lshr i32 %4335, 4
  %4337 = trunc i32 %4336 to i8
  %4338 = and i8 %4337, 1
  store i8 %4338, i8* %28, align 1, !tbaa !2447
  %4339 = zext i1 %4327 to i8
  store i8 %4339, i8* %31, align 1, !tbaa !2448
  %4340 = lshr i32 %4324, 31
  %4341 = trunc i32 %4340 to i8
  store i8 %4341, i8* %34, align 1, !tbaa !2449
  %4342 = lshr i32 %4323, 31
  %4343 = xor i32 %4340, %4342
  %4344 = add nuw nsw i32 %4343, %4340
  %4345 = icmp eq i32 %4344, 2
  %4346 = zext i1 %4345 to i8
  store i8 %4346, i8* %40, align 1, !tbaa !2450
  %4347 = sext i32 %4324 to i64
  store i64 %4347, i64* %RDX, align 8, !tbaa !2428
  %4348 = shl nsw i64 %4347, 3
  %4349 = add i64 %4348, %4319
  %4350 = add i64 %4306, 31
  store i64 %4350, i64* %PC, align 8
  %4351 = inttoptr i64 %4349 to double*
  store double %4315, double* %4351, align 8
  %4352 = load i64, i64* %RBP, align 8
  %4353 = add i64 %4352, -152
  %4354 = load i64, i64* %PC, align 8
  %4355 = add i64 %4354, 8
  store i64 %4355, i64* %PC, align 8
  %4356 = inttoptr i64 %4353 to i64*
  %4357 = load i64, i64* %4356, align 8
  store i64 %4357, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4358 = add i64 %4352, -120
  %4359 = add i64 %4354, 13
  store i64 %4359, i64* %PC, align 8
  %4360 = inttoptr i64 %4358 to double*
  %4361 = load double, double* %4360, align 8
  %4362 = bitcast i64 %4357 to double
  %4363 = fsub double %4361, %4362
  store double %4363, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %4364 = add i64 %4354, 22
  store i64 %4364, i64* %PC, align 8
  store double %4363, double* %4360, align 8
  %4365 = load i64, i64* %RBP, align 8
  %4366 = add i64 %4365, -160
  %4367 = load i64, i64* %PC, align 8
  %4368 = add i64 %4367, 8
  store i64 %4368, i64* %PC, align 8
  %4369 = inttoptr i64 %4366 to i64*
  %4370 = load i64, i64* %4369, align 8
  store i64 %4370, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4371 = add i64 %4365, -128
  %4372 = add i64 %4367, 13
  store i64 %4372, i64* %PC, align 8
  %4373 = inttoptr i64 %4371 to double*
  %4374 = load double, double* %4373, align 8
  %4375 = bitcast i64 %4370 to double
  %4376 = fsub double %4374, %4375
  store double %4376, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %4377 = add i64 %4367, 22
  store i64 %4377, i64* %PC, align 8
  store double %4376, double* %4373, align 8
  %4378 = load i64, i64* %RBP, align 8
  %4379 = add i64 %4378, -88
  %4380 = load i64, i64* %PC, align 8
  %4381 = add i64 %4380, 5
  store i64 %4381, i64* %PC, align 8
  %4382 = inttoptr i64 %4379 to i64*
  %4383 = load i64, i64* %4382, align 8
  store i64 %4383, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4384 = add i64 %4378, -120
  %4385 = add i64 %4380, 10
  store i64 %4385, i64* %PC, align 8
  %4386 = bitcast i64 %4383 to double
  %4387 = inttoptr i64 %4384 to double*
  %4388 = load double, double* %4387, align 8
  %4389 = fmul double %4386, %4388
  store double %4389, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4390 = add i64 %4378, -96
  %4391 = add i64 %4380, 15
  store i64 %4391, i64* %PC, align 8
  %4392 = inttoptr i64 %4390 to i64*
  %4393 = load i64, i64* %4392, align 8
  store i64 %4393, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %4394 = add i64 %4378, -128
  %4395 = add i64 %4380, 20
  store i64 %4395, i64* %PC, align 8
  %4396 = bitcast i64 %4393 to double
  %4397 = inttoptr i64 %4394 to double*
  %4398 = load double, double* %4397, align 8
  %4399 = fmul double %4396, %4398
  store double %4399, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %4400 = fsub double %4389, %4399
  store double %4400, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4401 = add i64 %4378, -16
  %4402 = add i64 %4380, 28
  store i64 %4402, i64* %PC, align 8
  %4403 = inttoptr i64 %4401 to i64*
  %4404 = load i64, i64* %4403, align 8
  store i64 %4404, i64* %RCX, align 8, !tbaa !2428
  %4405 = add i64 %4378, -36
  %4406 = add i64 %4380, 32
  store i64 %4406, i64* %PC, align 8
  %4407 = inttoptr i64 %4405 to i32*
  %4408 = load i32, i32* %4407, align 4
  %4409 = sext i32 %4408 to i64
  store i64 %4409, i64* %RDX, align 8, !tbaa !2428
  %4410 = shl nsw i64 %4409, 3
  %4411 = add i64 %4410, %4404
  %4412 = add i64 %4380, 37
  store i64 %4412, i64* %PC, align 8
  %4413 = inttoptr i64 %4411 to double*
  store double %4400, double* %4413, align 8
  %4414 = load i64, i64* %RBP, align 8
  %4415 = add i64 %4414, -88
  %4416 = load i64, i64* %PC, align 8
  %4417 = add i64 %4416, 5
  store i64 %4417, i64* %PC, align 8
  %4418 = inttoptr i64 %4415 to i64*
  %4419 = load i64, i64* %4418, align 8
  store i64 %4419, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4420 = add i64 %4414, -128
  %4421 = add i64 %4416, 10
  store i64 %4421, i64* %PC, align 8
  %4422 = bitcast i64 %4419 to double
  %4423 = inttoptr i64 %4420 to double*
  %4424 = load double, double* %4423, align 8
  %4425 = fmul double %4422, %4424
  store double %4425, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4426 = add i64 %4414, -96
  %4427 = add i64 %4416, 15
  store i64 %4427, i64* %PC, align 8
  %4428 = inttoptr i64 %4426 to i64*
  %4429 = load i64, i64* %4428, align 8
  store i64 %4429, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %4430 = add i64 %4414, -120
  %4431 = add i64 %4416, 20
  store i64 %4431, i64* %PC, align 8
  %4432 = bitcast i64 %4429 to double
  %4433 = inttoptr i64 %4430 to double*
  %4434 = load double, double* %4433, align 8
  %4435 = fmul double %4432, %4434
  store double %4435, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %4436 = fadd double %4425, %4435
  store double %4436, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4437 = add i64 %4414, -16
  %4438 = add i64 %4416, 28
  store i64 %4438, i64* %PC, align 8
  %4439 = inttoptr i64 %4437 to i64*
  %4440 = load i64, i64* %4439, align 8
  store i64 %4440, i64* %RCX, align 8, !tbaa !2428
  %4441 = add i64 %4414, -36
  %4442 = add i64 %4416, 31
  store i64 %4442, i64* %PC, align 8
  %4443 = inttoptr i64 %4441 to i32*
  %4444 = load i32, i32* %4443, align 4
  %4445 = add i32 %4444, 1
  %4446 = zext i32 %4445 to i64
  store i64 %4446, i64* %RAX, align 8, !tbaa !2428
  %4447 = icmp eq i32 %4444, -1
  %4448 = icmp eq i32 %4445, 0
  %4449 = or i1 %4447, %4448
  %4450 = zext i1 %4449 to i8
  store i8 %4450, i8* %15, align 1, !tbaa !2432
  %4451 = and i32 %4445, 255
  %4452 = tail call i32 @llvm.ctpop.i32(i32 %4451) #11
  %4453 = trunc i32 %4452 to i8
  %4454 = and i8 %4453, 1
  %4455 = xor i8 %4454, 1
  store i8 %4455, i8* %22, align 1, !tbaa !2446
  %4456 = xor i32 %4445, %4444
  %4457 = lshr i32 %4456, 4
  %4458 = trunc i32 %4457 to i8
  %4459 = and i8 %4458, 1
  store i8 %4459, i8* %28, align 1, !tbaa !2447
  %4460 = zext i1 %4448 to i8
  store i8 %4460, i8* %31, align 1, !tbaa !2448
  %4461 = lshr i32 %4445, 31
  %4462 = trunc i32 %4461 to i8
  store i8 %4462, i8* %34, align 1, !tbaa !2449
  %4463 = lshr i32 %4444, 31
  %4464 = xor i32 %4461, %4463
  %4465 = add nuw nsw i32 %4464, %4461
  %4466 = icmp eq i32 %4465, 2
  %4467 = zext i1 %4466 to i8
  store i8 %4467, i8* %40, align 1, !tbaa !2450
  %4468 = sext i32 %4445 to i64
  store i64 %4468, i64* %RDX, align 8, !tbaa !2428
  %4469 = shl nsw i64 %4468, 3
  %4470 = add i64 %4469, %4440
  %4471 = add i64 %4416, 42
  store i64 %4471, i64* %PC, align 8
  %4472 = inttoptr i64 %4470 to double*
  store double %4436, double* %4472, align 8
  %4473 = load i64, i64* %RBP, align 8
  %4474 = add i64 %4473, -136
  %4475 = load i64, i64* %PC, align 8
  %4476 = add i64 %4475, 8
  store i64 %4476, i64* %PC, align 8
  %4477 = inttoptr i64 %4474 to i64*
  %4478 = load i64, i64* %4477, align 8
  store i64 %4478, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4479 = add i64 %4473, -176
  %4480 = add i64 %4475, 16
  store i64 %4480, i64* %PC, align 8
  %4481 = bitcast i64 %4478 to double
  %4482 = inttoptr i64 %4479 to double*
  %4483 = load double, double* %4482, align 8
  %4484 = fsub double %4481, %4483
  store double %4484, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4485 = add i64 %4473, -120
  %4486 = add i64 %4475, 21
  store i64 %4486, i64* %PC, align 8
  %4487 = inttoptr i64 %4485 to double*
  store double %4484, double* %4487, align 8
  %4488 = load i64, i64* %RBP, align 8
  %4489 = add i64 %4488, -144
  %4490 = load i64, i64* %PC, align 8
  %4491 = add i64 %4490, 8
  store i64 %4491, i64* %PC, align 8
  %4492 = inttoptr i64 %4489 to i64*
  %4493 = load i64, i64* %4492, align 8
  store i64 %4493, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4494 = add i64 %4488, -168
  %4495 = add i64 %4490, 16
  store i64 %4495, i64* %PC, align 8
  %4496 = bitcast i64 %4493 to double
  %4497 = inttoptr i64 %4494 to double*
  %4498 = load double, double* %4497, align 8
  %4499 = fadd double %4496, %4498
  store double %4499, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4500 = add i64 %4488, -128
  %4501 = add i64 %4490, 21
  store i64 %4501, i64* %PC, align 8
  %4502 = inttoptr i64 %4500 to double*
  store double %4499, double* %4502, align 8
  %4503 = load i64, i64* %RBP, align 8
  %4504 = add i64 %4503, -72
  %4505 = load i64, i64* %PC, align 8
  %4506 = add i64 %4505, 5
  store i64 %4506, i64* %PC, align 8
  %4507 = inttoptr i64 %4504 to i64*
  %4508 = load i64, i64* %4507, align 8
  store i64 %4508, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4509 = add i64 %4503, -120
  %4510 = add i64 %4505, 10
  store i64 %4510, i64* %PC, align 8
  %4511 = bitcast i64 %4508 to double
  %4512 = inttoptr i64 %4509 to double*
  %4513 = load double, double* %4512, align 8
  %4514 = fmul double %4511, %4513
  store double %4514, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4515 = add i64 %4503, -80
  %4516 = add i64 %4505, 15
  store i64 %4516, i64* %PC, align 8
  %4517 = inttoptr i64 %4515 to i64*
  %4518 = load i64, i64* %4517, align 8
  store i64 %4518, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %4519 = add i64 %4503, -128
  %4520 = add i64 %4505, 20
  store i64 %4520, i64* %PC, align 8
  %4521 = bitcast i64 %4518 to double
  %4522 = inttoptr i64 %4519 to double*
  %4523 = load double, double* %4522, align 8
  %4524 = fmul double %4521, %4523
  store double %4524, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %4525 = fsub double %4514, %4524
  store double %4525, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4526 = add i64 %4503, -16
  %4527 = add i64 %4505, 28
  store i64 %4527, i64* %PC, align 8
  %4528 = inttoptr i64 %4526 to i64*
  %4529 = load i64, i64* %4528, align 8
  store i64 %4529, i64* %RCX, align 8, !tbaa !2428
  %4530 = add i64 %4503, -32
  %4531 = add i64 %4505, 32
  store i64 %4531, i64* %PC, align 8
  %4532 = inttoptr i64 %4530 to i32*
  %4533 = load i32, i32* %4532, align 4
  %4534 = sext i32 %4533 to i64
  store i64 %4534, i64* %RDX, align 8, !tbaa !2428
  %4535 = shl nsw i64 %4534, 3
  %4536 = add i64 %4535, %4529
  %4537 = add i64 %4505, 37
  store i64 %4537, i64* %PC, align 8
  %4538 = inttoptr i64 %4536 to double*
  store double %4525, double* %4538, align 8
  %4539 = load i64, i64* %RBP, align 8
  %4540 = add i64 %4539, -72
  %4541 = load i64, i64* %PC, align 8
  %4542 = add i64 %4541, 5
  store i64 %4542, i64* %PC, align 8
  %4543 = inttoptr i64 %4540 to i64*
  %4544 = load i64, i64* %4543, align 8
  store i64 %4544, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4545 = add i64 %4539, -128
  %4546 = add i64 %4541, 10
  store i64 %4546, i64* %PC, align 8
  %4547 = bitcast i64 %4544 to double
  %4548 = inttoptr i64 %4545 to double*
  %4549 = load double, double* %4548, align 8
  %4550 = fmul double %4547, %4549
  store double %4550, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4551 = add i64 %4539, -80
  %4552 = add i64 %4541, 15
  store i64 %4552, i64* %PC, align 8
  %4553 = inttoptr i64 %4551 to i64*
  %4554 = load i64, i64* %4553, align 8
  store i64 %4554, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %4555 = add i64 %4539, -120
  %4556 = add i64 %4541, 20
  store i64 %4556, i64* %PC, align 8
  %4557 = bitcast i64 %4554 to double
  %4558 = inttoptr i64 %4555 to double*
  %4559 = load double, double* %4558, align 8
  %4560 = fmul double %4557, %4559
  store double %4560, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %4561 = fadd double %4550, %4560
  store double %4561, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4562 = add i64 %4539, -16
  %4563 = add i64 %4541, 28
  store i64 %4563, i64* %PC, align 8
  %4564 = inttoptr i64 %4562 to i64*
  %4565 = load i64, i64* %4564, align 8
  store i64 %4565, i64* %RCX, align 8, !tbaa !2428
  %4566 = add i64 %4539, -32
  %4567 = add i64 %4541, 31
  store i64 %4567, i64* %PC, align 8
  %4568 = inttoptr i64 %4566 to i32*
  %4569 = load i32, i32* %4568, align 4
  %4570 = add i32 %4569, 1
  %4571 = zext i32 %4570 to i64
  store i64 %4571, i64* %RAX, align 8, !tbaa !2428
  %4572 = icmp eq i32 %4569, -1
  %4573 = icmp eq i32 %4570, 0
  %4574 = or i1 %4572, %4573
  %4575 = zext i1 %4574 to i8
  store i8 %4575, i8* %15, align 1, !tbaa !2432
  %4576 = and i32 %4570, 255
  %4577 = tail call i32 @llvm.ctpop.i32(i32 %4576) #11
  %4578 = trunc i32 %4577 to i8
  %4579 = and i8 %4578, 1
  %4580 = xor i8 %4579, 1
  store i8 %4580, i8* %22, align 1, !tbaa !2446
  %4581 = xor i32 %4570, %4569
  %4582 = lshr i32 %4581, 4
  %4583 = trunc i32 %4582 to i8
  %4584 = and i8 %4583, 1
  store i8 %4584, i8* %28, align 1, !tbaa !2447
  %4585 = zext i1 %4573 to i8
  store i8 %4585, i8* %31, align 1, !tbaa !2448
  %4586 = lshr i32 %4570, 31
  %4587 = trunc i32 %4586 to i8
  store i8 %4587, i8* %34, align 1, !tbaa !2449
  %4588 = lshr i32 %4569, 31
  %4589 = xor i32 %4586, %4588
  %4590 = add nuw nsw i32 %4589, %4586
  %4591 = icmp eq i32 %4590, 2
  %4592 = zext i1 %4591 to i8
  store i8 %4592, i8* %40, align 1, !tbaa !2450
  %4593 = sext i32 %4570 to i64
  store i64 %4593, i64* %RDX, align 8, !tbaa !2428
  %4594 = shl nsw i64 %4593, 3
  %4595 = add i64 %4594, %4565
  %4596 = add i64 %4541, 42
  store i64 %4596, i64* %PC, align 8
  %4597 = inttoptr i64 %4595 to double*
  store double %4561, double* %4597, align 8
  %4598 = load i64, i64* %RBP, align 8
  %4599 = add i64 %4598, -136
  %4600 = load i64, i64* %PC, align 8
  %4601 = add i64 %4600, 8
  store i64 %4601, i64* %PC, align 8
  %4602 = inttoptr i64 %4599 to i64*
  %4603 = load i64, i64* %4602, align 8
  store i64 %4603, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4604 = add i64 %4598, -176
  %4605 = add i64 %4600, 16
  store i64 %4605, i64* %PC, align 8
  %4606 = bitcast i64 %4603 to double
  %4607 = inttoptr i64 %4604 to double*
  %4608 = load double, double* %4607, align 8
  %4609 = fadd double %4606, %4608
  store double %4609, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4610 = add i64 %4598, -120
  %4611 = add i64 %4600, 21
  store i64 %4611, i64* %PC, align 8
  %4612 = inttoptr i64 %4610 to double*
  store double %4609, double* %4612, align 8
  %4613 = load i64, i64* %RBP, align 8
  %4614 = add i64 %4613, -144
  %4615 = load i64, i64* %PC, align 8
  %4616 = add i64 %4615, 8
  store i64 %4616, i64* %PC, align 8
  %4617 = inttoptr i64 %4614 to i64*
  %4618 = load i64, i64* %4617, align 8
  store i64 %4618, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4619 = add i64 %4613, -168
  %4620 = add i64 %4615, 16
  store i64 %4620, i64* %PC, align 8
  %4621 = bitcast i64 %4618 to double
  %4622 = inttoptr i64 %4619 to double*
  %4623 = load double, double* %4622, align 8
  %4624 = fsub double %4621, %4623
  store double %4624, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4625 = add i64 %4613, -128
  %4626 = add i64 %4615, 21
  store i64 %4626, i64* %PC, align 8
  %4627 = inttoptr i64 %4625 to double*
  store double %4624, double* %4627, align 8
  %4628 = load i64, i64* %RBP, align 8
  %4629 = add i64 %4628, -104
  %4630 = load i64, i64* %PC, align 8
  %4631 = add i64 %4630, 5
  store i64 %4631, i64* %PC, align 8
  %4632 = inttoptr i64 %4629 to i64*
  %4633 = load i64, i64* %4632, align 8
  store i64 %4633, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4634 = add i64 %4628, -120
  %4635 = add i64 %4630, 10
  store i64 %4635, i64* %PC, align 8
  %4636 = bitcast i64 %4633 to double
  %4637 = inttoptr i64 %4634 to double*
  %4638 = load double, double* %4637, align 8
  %4639 = fmul double %4636, %4638
  store double %4639, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4640 = add i64 %4628, -112
  %4641 = add i64 %4630, 15
  store i64 %4641, i64* %PC, align 8
  %4642 = inttoptr i64 %4640 to i64*
  %4643 = load i64, i64* %4642, align 8
  store i64 %4643, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %4644 = add i64 %4628, -128
  %4645 = add i64 %4630, 20
  store i64 %4645, i64* %PC, align 8
  %4646 = bitcast i64 %4643 to double
  %4647 = inttoptr i64 %4644 to double*
  %4648 = load double, double* %4647, align 8
  %4649 = fmul double %4646, %4648
  store double %4649, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %4650 = fsub double %4639, %4649
  store double %4650, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4651 = add i64 %4628, -16
  %4652 = add i64 %4630, 28
  store i64 %4652, i64* %PC, align 8
  %4653 = inttoptr i64 %4651 to i64*
  %4654 = load i64, i64* %4653, align 8
  store i64 %4654, i64* %RCX, align 8, !tbaa !2428
  %4655 = add i64 %4628, -40
  %4656 = add i64 %4630, 32
  store i64 %4656, i64* %PC, align 8
  %4657 = inttoptr i64 %4655 to i32*
  %4658 = load i32, i32* %4657, align 4
  %4659 = sext i32 %4658 to i64
  store i64 %4659, i64* %RDX, align 8, !tbaa !2428
  %4660 = shl nsw i64 %4659, 3
  %4661 = add i64 %4660, %4654
  %4662 = add i64 %4630, 37
  store i64 %4662, i64* %PC, align 8
  %4663 = inttoptr i64 %4661 to double*
  store double %4650, double* %4663, align 8
  %4664 = load i64, i64* %RBP, align 8
  %4665 = add i64 %4664, -104
  %4666 = load i64, i64* %PC, align 8
  %4667 = add i64 %4666, 5
  store i64 %4667, i64* %PC, align 8
  %4668 = inttoptr i64 %4665 to i64*
  %4669 = load i64, i64* %4668, align 8
  store i64 %4669, i64* %93, align 1, !tbaa !2451
  store double 0.000000e+00, double* %95, align 1, !tbaa !2451
  %4670 = add i64 %4664, -128
  %4671 = add i64 %4666, 10
  store i64 %4671, i64* %PC, align 8
  %4672 = bitcast i64 %4669 to double
  %4673 = inttoptr i64 %4670 to double*
  %4674 = load double, double* %4673, align 8
  %4675 = fmul double %4672, %4674
  store double %4675, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4676 = add i64 %4664, -112
  %4677 = add i64 %4666, 15
  store i64 %4677, i64* %PC, align 8
  %4678 = inttoptr i64 %4676 to i64*
  %4679 = load i64, i64* %4678, align 8
  store i64 %4679, i64* %1621, align 1, !tbaa !2451
  store double 0.000000e+00, double* %1623, align 1, !tbaa !2451
  %4680 = add i64 %4664, -120
  %4681 = add i64 %4666, 20
  store i64 %4681, i64* %PC, align 8
  %4682 = bitcast i64 %4679 to double
  %4683 = inttoptr i64 %4680 to double*
  %4684 = load double, double* %4683, align 8
  %4685 = fmul double %4682, %4684
  store double %4685, double* %1620, align 1, !tbaa !2451
  store i64 0, i64* %1622, align 1, !tbaa !2451
  %4686 = fadd double %4675, %4685
  store double %4686, double* %92, align 1, !tbaa !2451
  store i64 0, i64* %94, align 1, !tbaa !2451
  %4687 = add i64 %4664, -16
  %4688 = add i64 %4666, 28
  store i64 %4688, i64* %PC, align 8
  %4689 = inttoptr i64 %4687 to i64*
  %4690 = load i64, i64* %4689, align 8
  store i64 %4690, i64* %RCX, align 8, !tbaa !2428
  %4691 = add i64 %4664, -40
  %4692 = add i64 %4666, 31
  store i64 %4692, i64* %PC, align 8
  %4693 = inttoptr i64 %4691 to i32*
  %4694 = load i32, i32* %4693, align 4
  %4695 = add i32 %4694, 1
  %4696 = zext i32 %4695 to i64
  store i64 %4696, i64* %RAX, align 8, !tbaa !2428
  %4697 = icmp eq i32 %4694, -1
  %4698 = icmp eq i32 %4695, 0
  %4699 = or i1 %4697, %4698
  %4700 = zext i1 %4699 to i8
  store i8 %4700, i8* %15, align 1, !tbaa !2432
  %4701 = and i32 %4695, 255
  %4702 = tail call i32 @llvm.ctpop.i32(i32 %4701) #11
  %4703 = trunc i32 %4702 to i8
  %4704 = and i8 %4703, 1
  %4705 = xor i8 %4704, 1
  store i8 %4705, i8* %22, align 1, !tbaa !2446
  %4706 = xor i32 %4695, %4694
  %4707 = lshr i32 %4706, 4
  %4708 = trunc i32 %4707 to i8
  %4709 = and i8 %4708, 1
  store i8 %4709, i8* %28, align 1, !tbaa !2447
  %4710 = zext i1 %4698 to i8
  store i8 %4710, i8* %31, align 1, !tbaa !2448
  %4711 = lshr i32 %4695, 31
  %4712 = trunc i32 %4711 to i8
  store i8 %4712, i8* %34, align 1, !tbaa !2449
  %4713 = lshr i32 %4694, 31
  %4714 = xor i32 %4711, %4713
  %4715 = add nuw nsw i32 %4714, %4711
  %4716 = icmp eq i32 %4715, 2
  %4717 = zext i1 %4716 to i8
  store i8 %4717, i8* %40, align 1, !tbaa !2450
  %4718 = sext i32 %4695 to i64
  store i64 %4718, i64* %RDX, align 8, !tbaa !2428
  %4719 = shl nsw i64 %4718, 3
  %4720 = add i64 %4719, %4690
  %4721 = add i64 %4666, 42
  store i64 %4721, i64* %PC, align 8
  %4722 = inttoptr i64 %4720 to double*
  store double %4686, double* %4722, align 8
  %4723 = load i64, i64* %RBP, align 8
  %4724 = add i64 %4723, -28
  %4725 = load i64, i64* %PC, align 8
  %4726 = add i64 %4725, 3
  store i64 %4726, i64* %PC, align 8
  %4727 = inttoptr i64 %4724 to i32*
  %4728 = load i32, i32* %4727, align 4
  %4729 = add i32 %4728, 2
  %4730 = zext i32 %4729 to i64
  store i64 %4730, i64* %RAX, align 8, !tbaa !2428
  %4731 = icmp ugt i32 %4728, -3
  %4732 = zext i1 %4731 to i8
  store i8 %4732, i8* %15, align 1, !tbaa !2432
  %4733 = and i32 %4729, 255
  %4734 = tail call i32 @llvm.ctpop.i32(i32 %4733) #11
  %4735 = trunc i32 %4734 to i8
  %4736 = and i8 %4735, 1
  %4737 = xor i8 %4736, 1
  store i8 %4737, i8* %22, align 1, !tbaa !2446
  %4738 = xor i32 %4729, %4728
  %4739 = lshr i32 %4738, 4
  %4740 = trunc i32 %4739 to i8
  %4741 = and i8 %4740, 1
  store i8 %4741, i8* %28, align 1, !tbaa !2447
  %4742 = icmp eq i32 %4729, 0
  %4743 = zext i1 %4742 to i8
  store i8 %4743, i8* %31, align 1, !tbaa !2448
  %4744 = lshr i32 %4729, 31
  %4745 = trunc i32 %4744 to i8
  store i8 %4745, i8* %34, align 1, !tbaa !2449
  %4746 = lshr i32 %4728, 31
  %4747 = xor i32 %4744, %4746
  %4748 = add nuw nsw i32 %4747, %4744
  %4749 = icmp eq i32 %4748, 2
  %4750 = zext i1 %4749 to i8
  store i8 %4750, i8* %40, align 1, !tbaa !2450
  %4751 = add i64 %4725, 9
  store i64 %4751, i64* %PC, align 8
  store i32 %4729, i32* %4727, align 4
  %4752 = load i64, i64* %PC, align 8
  %4753 = add i64 %4752, -781
  store i64 %4753, i64* %PC, align 8, !tbaa !2428
  br label %block_403940

block_4035c1:                                     ; preds = %block_4035ad, %block_4035d2
  %4754 = phi i64 [ %.pre23, %block_4035ad ], [ %1306, %block_4035d2 ]
  %4755 = load i64, i64* %RBP, align 8
  %4756 = add i64 %4755, -28
  %4757 = add i64 %4754, 3
  store i64 %4757, i64* %PC, align 8
  %4758 = inttoptr i64 %4756 to i32*
  %4759 = load i32, i32* %4758, align 4
  %4760 = zext i32 %4759 to i64
  store i64 %4760, i64* %RAX, align 8, !tbaa !2428
  %4761 = add i64 %4755, -8
  %4762 = add i64 %4754, 6
  store i64 %4762, i64* %PC, align 8
  %4763 = inttoptr i64 %4761 to i32*
  %4764 = load i32, i32* %4763, align 4
  %4765 = zext i32 %4764 to i64
  store i64 %4765, i64* %RCX, align 8, !tbaa !2428
  %4766 = add i64 %4755, -56
  %4767 = add i64 %4754, 9
  store i64 %4767, i64* %PC, align 8
  %4768 = inttoptr i64 %4766 to i32*
  %4769 = load i32, i32* %4768, align 4
  %4770 = add i32 %4769, %4764
  %4771 = zext i32 %4770 to i64
  store i64 %4771, i64* %RCX, align 8, !tbaa !2428
  %4772 = lshr i32 %4770, 31
  %4773 = sub i32 %4759, %4770
  %4774 = icmp ult i32 %4759, %4770
  %4775 = zext i1 %4774 to i8
  store i8 %4775, i8* %15, align 1, !tbaa !2432
  %4776 = and i32 %4773, 255
  %4777 = tail call i32 @llvm.ctpop.i32(i32 %4776) #11
  %4778 = trunc i32 %4777 to i8
  %4779 = and i8 %4778, 1
  %4780 = xor i8 %4779, 1
  store i8 %4780, i8* %22, align 1, !tbaa !2446
  %4781 = xor i32 %4770, %4759
  %4782 = xor i32 %4781, %4773
  %4783 = lshr i32 %4782, 4
  %4784 = trunc i32 %4783 to i8
  %4785 = and i8 %4784, 1
  store i8 %4785, i8* %28, align 1, !tbaa !2447
  %4786 = icmp eq i32 %4773, 0
  %4787 = zext i1 %4786 to i8
  store i8 %4787, i8* %31, align 1, !tbaa !2448
  %4788 = lshr i32 %4773, 31
  %4789 = trunc i32 %4788 to i8
  store i8 %4789, i8* %34, align 1, !tbaa !2449
  %4790 = lshr i32 %4759, 31
  %4791 = xor i32 %4772, %4790
  %4792 = xor i32 %4788, %4790
  %4793 = add nuw nsw i32 %4792, %4791
  %4794 = icmp eq i32 %4793, 2
  %4795 = zext i1 %4794 to i8
  store i8 %4795, i8* %40, align 1, !tbaa !2450
  %4796 = icmp ne i8 %4789, 0
  %4797 = xor i1 %4796, %4794
  %.v27 = select i1 %4797, i64 17, i64 700
  %4798 = add i64 %.v27, %4754
  store i64 %4798, i64* %PC, align 8, !tbaa !2428
  br i1 %4797, label %block_4035d2, label %block_40387d

block_403940:                                     ; preds = %block_403951, %block_40389f
  %4799 = phi i64 [ %4753, %block_403951 ], [ %.pre25, %block_40389f ]
  %4800 = load i64, i64* %RBP, align 8
  %4801 = add i64 %4800, -28
  %4802 = add i64 %4799, 3
  store i64 %4802, i64* %PC, align 8
  %4803 = inttoptr i64 %4801 to i32*
  %4804 = load i32, i32* %4803, align 4
  %4805 = zext i32 %4804 to i64
  store i64 %4805, i64* %RAX, align 8, !tbaa !2428
  %4806 = add i64 %4800, -8
  %4807 = add i64 %4799, 6
  store i64 %4807, i64* %PC, align 8
  %4808 = inttoptr i64 %4806 to i32*
  %4809 = load i32, i32* %4808, align 4
  %4810 = zext i32 %4809 to i64
  store i64 %4810, i64* %RCX, align 8, !tbaa !2428
  %4811 = add i64 %4800, -44
  %4812 = add i64 %4799, 9
  store i64 %4812, i64* %PC, align 8
  %4813 = inttoptr i64 %4811 to i32*
  %4814 = load i32, i32* %4813, align 4
  %4815 = add i32 %4814, %4809
  %4816 = zext i32 %4815 to i64
  store i64 %4816, i64* %RCX, align 8, !tbaa !2428
  %4817 = lshr i32 %4815, 31
  %4818 = sub i32 %4804, %4815
  %4819 = icmp ult i32 %4804, %4815
  %4820 = zext i1 %4819 to i8
  store i8 %4820, i8* %15, align 1, !tbaa !2432
  %4821 = and i32 %4818, 255
  %4822 = tail call i32 @llvm.ctpop.i32(i32 %4821) #11
  %4823 = trunc i32 %4822 to i8
  %4824 = and i8 %4823, 1
  %4825 = xor i8 %4824, 1
  store i8 %4825, i8* %22, align 1, !tbaa !2446
  %4826 = xor i32 %4815, %4804
  %4827 = xor i32 %4826, %4818
  %4828 = lshr i32 %4827, 4
  %4829 = trunc i32 %4828 to i8
  %4830 = and i8 %4829, 1
  store i8 %4830, i8* %28, align 1, !tbaa !2447
  %4831 = icmp eq i32 %4818, 0
  %4832 = zext i1 %4831 to i8
  store i8 %4832, i8* %31, align 1, !tbaa !2448
  %4833 = lshr i32 %4818, 31
  %4834 = trunc i32 %4833 to i8
  store i8 %4834, i8* %34, align 1, !tbaa !2449
  %4835 = lshr i32 %4804, 31
  %4836 = xor i32 %4817, %4835
  %4837 = xor i32 %4833, %4835
  %4838 = add nuw nsw i32 %4837, %4836
  %4839 = icmp eq i32 %4838, 2
  %4840 = zext i1 %4839 to i8
  store i8 %4840, i8* %40, align 1, !tbaa !2450
  %4841 = icmp ne i8 %4834, 0
  %4842 = xor i1 %4841, %4839
  %.v29 = select i1 %4842, i64 17, i64 786
  %4843 = add i64 %.v29, %4799
  store i64 %4843, i64* %PC, align 8, !tbaa !2428
  br i1 %4842, label %block_403951, label %block_403c52
}

; Function Attrs: noinline nounwind
define %struct.Memory* @sub_4007a0_deregister_tm_clones(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #7 {
block_4007a0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = load i64, i64* %RSP, align 8, !tbaa !2428
  %6 = add i64 %5, -8
  %7 = inttoptr i64 %6 to i64*
  store i64 %3, i64* %7, align 8
  store i64 %6, i64* %RSP, align 8, !tbaa !2428
  %8 = load i64, i64* %PC, align 8
  store i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64* %RAX, align 8, !tbaa !2428
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 zext (i1 icmp ult (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)) to i8), i8* %9, align 1, !tbaa !2432
  %10 = tail call i32 @llvm.ctpop.i32(i32 and (i32 trunc (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)) to i32), i32 255)) #11
  %11 = trunc i32 %10 to i8
  %12 = and i8 %11, 1
  %13 = xor i8 %12, 1
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %13, i8* %14, align 1, !tbaa !2446
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 and (i8 trunc (i64 lshr (i64 xor (i64 xor (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295)), i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64))), i64 4) to i8), i8 1), i8* %15, align 1, !tbaa !2447
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 zext (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0) to i8), i8* %16, align 1, !tbaa !2448
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 trunc (i64 lshr (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 63) to i8), i8* %17, align 1, !tbaa !2449
  %18 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 zext (i1 icmp eq (i64 add (i64 xor (i64 lshr (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 63), i64 lshr (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 63)), i64 xor (i64 lshr (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 63), i64 lshr (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 63))), i64 2) to i8), i8* %18, align 1, !tbaa !2450
  store i64 %6, i64* %RBP, align 8, !tbaa !2428
  %19 = add i64 %8, select (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), i64 39, i64 16)
  store i64 %19, i64* %PC, align 8, !tbaa !2428
  br i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), label %block_4007c8, label %block_4007b1

block_4007b1:                                     ; preds = %block_4007a0
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %9, align 1, !tbaa !2432
  store i8 1, i8* %14, align 1, !tbaa !2446
  store i8 1, i8* %16, align 1, !tbaa !2448
  store i8 0, i8* %17, align 1, !tbaa !2449
  store i8 0, i8* %18, align 1, !tbaa !2450
  store i8 0, i8* %15, align 1, !tbaa !2447
  %20 = add i64 %8, add (i64 select (i1 icmp eq (i64 sub (i64 and (i64 ptrtoint (%__bss_start_type* @__bss_start to i64), i64 4294967295), i64 ptrtoint (%__bss_start_type* @__bss_start to i64)), i64 0), i64 39, i64 16), i64 23)
  store i64 %20, i64* %PC, align 8, !tbaa !2428
  br label %block_4007c8

block_4007c8:                                     ; preds = %block_4007b1, %block_4007a0
  %21 = phi i64 [ %20, %block_4007b1 ], [ %19, %block_4007a0 ]
  %22 = add i64 %21, 1
  store i64 %22, i64* %PC, align 8
  %23 = load i64, i64* %7, align 8
  store i64 %23, i64* %RBP, align 8, !tbaa !2428
  store i64 %5, i64* %RSP, align 8, !tbaa !2428
  %24 = add i64 %21, 2
  store i64 %24, i64* %PC, align 8
  %25 = inttoptr i64 %5 to i64*
  %26 = load i64, i64* %25, align 8
  store i64 %26, i64* %PC, align 8, !tbaa !2428
  %27 = add i64 %5, 8
  store i64 %27, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
declare void @__mcsema_attach_call() #6

; Function Attrs: naked nobuiltin noinline nounwind
define internal void @callback_sub_400840_frame_dummy() #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400840;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @1, void ()** nonnull @2) #11
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @callback_sub_400840_frame_dummy_wrapper(%struct.State* nocapture, i64, %struct.Memory* readnone returned) #11 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %5, %3
  %6 = tail call %struct.Memory* @sub_400840_frame_dummy(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define internal void @callback_sub_400810___do_global_dtors_aux() #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400810;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @3, void ()** nonnull @2) #11
  ret void
}

define internal %struct.Memory* @callback_sub_400810___do_global_dtors_aux_wrapper(%struct.State*, i64, %struct.Memory* readnone returned) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %5, %3
  %6 = tail call %struct.Memory* @sub_400810___do_global_dtors_aux(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: alwaysinline inlinehint nounwind
define %struct.Memory* @ext_6050b8_cos(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #12 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @cos(double %6)
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %13 = bitcast i64* %12 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* %13, i8 0, i64 24, i32 8, i1 false)
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: alwaysinline inlinehint nounwind
define %struct.Memory* @ext_6050d8_sin(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #12 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @sin(double %6)
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %13 = bitcast i64* %12 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* %13, i8 0, i64 24, i32 8, i1 false)
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: alwaysinline inlinehint nounwind
define %struct.Memory* @ext_6050f8_atan(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #12 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @atan(double %6)
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %13 = bitcast i64* %12 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* %13, i8 0, i64 24, i32 8, i1 false)
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: naked nobuiltin noinline nounwind
define internal void @callback_sub_404090___libc_csu_fini() #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x404090;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @4, void ()** nonnull @2) #11
  ret void
}

; Function Attrs: norecurse nounwind
define internal %struct.Memory* @callback_sub_404090___libc_csu_fini_wrapper(%struct.State* nocapture, i64, %struct.Memory* readnone returned) #13 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %5, %3
  %6 = tail call %struct.Memory* @sub_404090___libc_csu_fini(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define internal void @callback_sub_404020___libc_csu_init() #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x404020;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @5, void ()** nonnull @2) #11
  ret void
}

define internal %struct.Memory* @callback_sub_404020___libc_csu_init_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %5, %3
  %6 = tail call %struct.Memory* @sub_404020___libc_csu_init(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @main() #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400850;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @6, void ()** nonnull @2) #11
  ret void
}

define internal %struct.Memory* @main_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %5, %3
  %6 = tail call %struct.Memory* @sub_400850_main(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_605120___libc_start_main(%struct.State*, %struct.Memory*) unnamed_addr #14 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64)* @__libc_start_main to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_4006f0_gettimeofday(%struct.State*, %struct.Memory*) unnamed_addr #14 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64)* @gettimeofday to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_6050e8_free(%struct.State*, %struct.Memory*) unnamed_addr #14 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64)* @free to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_605128_memcpy(%struct.State*, %struct.Memory*) unnamed_addr #14 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64)* @memcpy to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_605110_memset(%struct.State*, %struct.Memory*) unnamed_addr #14 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64)* @memset to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_4006e0_printf(%struct.State*, %struct.Memory*) unnamed_addr #14 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64)* @printf to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: alwaysinline inlinehint nounwind
define %struct.Memory* @ext_605140_sqrt(%struct.State* noalias nocapture dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr #12 {
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  store i64 %1, i64* %PC, align 8
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = bitcast %union.VectorReg* %4 to double*
  %6 = load double, double* %5, align 8
  %7 = load i64, i64* %RSP, align 8
  %8 = inttoptr i64 %7 to i64*
  %9 = load i64, i64* %8, align 8
  store i64 %9, i64* %PC, align 8
  %10 = add i64 %7, 8
  store i64 %10, i64* %RSP, align 8
  %11 = tail call double @sqrt(double %6)
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %13 = bitcast i64* %12 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* %13, i8 0, i64 24, i32 8, i1 false)
  store double %11, double* %5, align 8
  ret %struct.Memory* %2
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_6050d0_memalign(%struct.State*, %struct.Memory*) unnamed_addr #14 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64)* @memalign to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline nounwind
define internal fastcc %struct.Memory* @ext_4006c0_abort(%struct.State*, %struct.Memory*) unnamed_addr #14 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 ()* @abort to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @putdata() local_unnamed_addr #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400fe0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @7, void ()** nonnull @2) #11
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @putdata_wrapper(%struct.State*, i64, %struct.Memory*) #11 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %5, %3
  %6 = tail call %struct.Memory* @sub_400fe0_putdata(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @cdft() local_unnamed_addr #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x401060;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @8, void ()** nonnull @2) #11
  ret void
}

define internal %struct.Memory* @cdft_wrapper(%struct.State*, i64, %struct.Memory* readnone) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %5, %3
  %6 = tail call %struct.Memory* @sub_401060_cdft(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @errorcheck() local_unnamed_addr #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x401100;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @9, void ()** nonnull @2) #11
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @errorcheck_wrapper(%struct.State*, i64, %struct.Memory*) #11 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %5, %3
  %6 = tail call %struct.Memory* @sub_401100_errorcheck(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @.term_proc() local_unnamed_addr #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x404094;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @10, void ()** nonnull @2) #11
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @.term_proc_wrapper(%struct.State* nocapture, i64, %struct.Memory* readnone returned) #11 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %5, %3
  %6 = tail call %struct.Memory* @sub_404094__term_proc(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @get_time() local_unnamed_addr #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400e30;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @11, void ()** nonnull @2) #11
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @get_time_wrapper(%struct.State*, i64, %struct.Memory*) #11 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %5, %3
  %6 = tail call %struct.Memory* @sub_400e30_get_time(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @.init_proc() local_unnamed_addr #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400688;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @12, void ()** nonnull @2) #11
  ret void
}

; Function Attrs: nounwind
define internal %struct.Memory* @.init_proc_wrapper(%struct.State*, i64, %struct.Memory*) #11 {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %5, %3
  %6 = tail call %struct.Memory* @sub_400688__init_proc(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline nounwind
define dllexport void @makewt() local_unnamed_addr #10 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400e70;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @13, void ()** nonnull @2) #11
  ret void
}

define internal %struct.Memory* @makewt_wrapper(%struct.State*, i64, %struct.Memory* readnone) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %5, %3
  %6 = tail call %struct.Memory* @sub_400e70_makewt(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: nounwind
define internal void @__mcsema_constructor() #11 {
  %1 = load volatile i1, i1* @0, align 1
  br i1 %1, label %__mcsema_early_init.exit, label %2

; <label>:2:                                      ; preds = %0
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %2, %0
  tail call void @callback_sub_404020___libc_csu_init()
  ret void
}

; Function Attrs: nounwind
define internal void @__mcsema_destructor() #11 {
  tail call void @callback_sub_404090___libc_csu_fini()
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i32, i1) #15

attributes #0 = { nounwind readnone }
attributes #1 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind readnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { noinline }
attributes #7 = { noinline nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { noinline "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { noinline norecurse nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #10 = { naked nobuiltin noinline nounwind }
attributes #11 = { nounwind }
attributes #12 = { alwaysinline inlinehint nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #13 = { norecurse nounwind }
attributes #14 = { noinline nounwind }
attributes #15 = { argmemonly nounwind }
attributes #16 = { alwaysinline nobuiltin nounwind }

!llvm.ident = !{!0, !0}
!llvm.dbg.cu = !{!1}
!llvm.module.flags = !{!1259, !1260}

!0 = !{!"clang version 4.0.1 (tags/RELEASE_401/final)"}
!1 = distinct !DICompileUnit(language: DW_LANG_C_plus_plus, file: !2, producer: "clang version 4.0.1 (tags/RELEASE_401/final)", isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug, enums: !3, retainedTypes: !67, imports: !70)
!2 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/X86/Runtime/BasicBlock.cpp", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!3 = !{!4, !26, !35, !39, !45, !51, !55, !61}
!4 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "Name", scope: !6, file: !5, line: 70, baseType: !8, size: 32, elements: !11, identifier: "_ZTSN14AsyncHyperCall4NameE")
!5 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/HyperCall.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!6 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "AsyncHyperCall", file: !5, line: 68, size: 8, elements: !7, identifier: "_ZTS14AsyncHyperCall")
!7 = !{}
!8 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint32_t", file: !9, line: 183, baseType: !10)
!9 = !DIFile(filename: "/home/ubuntu/Github/remill/remill-build/libraries/llvm/bin/../lib/clang/4.0.1/include/stdint.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!10 = !DIBasicType(name: "unsigned int", size: 32, encoding: DW_ATE_unsigned)
!11 = !{!12, !13, !14, !15, !16, !17, !18, !19, !20, !21, !22, !23, !24, !25}
!12 = !DIEnumerator(name: "kInvalid", value: 0)
!13 = !DIEnumerator(name: "kX86Int1", value: 1)
!14 = !DIEnumerator(name: "kX86Int3", value: 2)
!15 = !DIEnumerator(name: "kX86IntO", value: 3)
!16 = !DIEnumerator(name: "kX86IntN", value: 4)
!17 = !DIEnumerator(name: "kX86Bound", value: 5)
!18 = !DIEnumerator(name: "kX86IRet", value: 6)
!19 = !DIEnumerator(name: "kX86SysCall", value: 7)
!20 = !DIEnumerator(name: "kX86SysRet", value: 8)
!21 = !DIEnumerator(name: "kX86SysEnter", value: 9)
!22 = !DIEnumerator(name: "kX86SysExit", value: 10)
!23 = !DIEnumerator(name: "kX86JmpFar", value: 11)
!24 = !DIEnumerator(name: "kAArch64SupervisorCall", value: 12)
!25 = !DIEnumerator(name: "kInvalidInstruction", value: 13)
!26 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "RequestPrivilegeLevel", file: !27, line: 64, baseType: !28, size: 16, elements: !30, identifier: "_ZTS21RequestPrivilegeLevel")
!27 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/X86/Runtime/State.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!28 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint16_t", file: !9, line: 218, baseType: !29)
!29 = !DIBasicType(name: "unsigned short", size: 16, encoding: DW_ATE_unsigned)
!30 = !{!31, !32, !33, !34}
!31 = !DIEnumerator(name: "kRPLRingZero", value: 0)
!32 = !DIEnumerator(name: "kRPLRingOne", value: 1)
!33 = !DIEnumerator(name: "kRPLRingTwo", value: 2)
!34 = !DIEnumerator(name: "kRPLRingThree", value: 3)
!35 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "TableIndicator", file: !27, line: 71, baseType: !28, size: 16, elements: !36, identifier: "_ZTS14TableIndicator")
!36 = !{!37, !38}
!37 = !DIEnumerator(name: "kGlobalDescriptorTable", value: 0)
!38 = !DIEnumerator(name: "kLocalDescriptorTable", value: 1)
!39 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUPrecisionControl", file: !27, line: 123, baseType: !28, size: 16, elements: !40, identifier: "_ZTS19FPUPrecisionControl")
!40 = !{!41, !42, !43, !44}
!41 = !DIEnumerator(name: "kPrecisionSingle", value: 0)
!42 = !DIEnumerator(name: "kPrecisionReserved", value: 1)
!43 = !DIEnumerator(name: "kPrecisionDouble", value: 2)
!44 = !DIEnumerator(name: "kPrecisionExtended", value: 3)
!45 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPURoundingControl", file: !27, line: 130, baseType: !28, size: 16, elements: !46, identifier: "_ZTS18FPURoundingControl")
!46 = !{!47, !48, !49, !50}
!47 = !DIEnumerator(name: "kFPURoundToNearestEven", value: 0)
!48 = !DIEnumerator(name: "kFPURoundDownNegInf", value: 1)
!49 = !DIEnumerator(name: "kFPURoundUpInf", value: 2)
!50 = !DIEnumerator(name: "kFPURoundToZero", value: 3)
!51 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUInfinityControl", file: !27, line: 137, baseType: !28, size: 16, elements: !52, identifier: "_ZTS18FPUInfinityControl")
!52 = !{!53, !54}
!53 = !DIEnumerator(name: "kInfinityProjective", value: 0)
!54 = !DIEnumerator(name: "kInfinityAffine", value: 1)
!55 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUTag", file: !27, line: 214, baseType: !28, size: 16, elements: !56, identifier: "_ZTS6FPUTag")
!56 = !{!57, !58, !59, !60}
!57 = !DIEnumerator(name: "kFPUTagNonZero", value: 0)
!58 = !DIEnumerator(name: "kFPUTagZero", value: 1)
!59 = !DIEnumerator(name: "kFPUTagSpecial", value: 2)
!60 = !DIEnumerator(name: "kFPUTagEmpty", value: 3)
!61 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUAbridgedTag", file: !27, line: 221, baseType: !62, size: 8, elements: !64, identifier: "_ZTS14FPUAbridgedTag")
!62 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint8_t", file: !9, line: 237, baseType: !63)
!63 = !DIBasicType(name: "unsigned char", size: 8, encoding: DW_ATE_unsigned_char)
!64 = !{!65, !66}
!65 = !DIEnumerator(name: "kFPUAbridgedTagEmpty", value: 0)
!66 = !DIEnumerator(name: "kFPUAbridgedTagValid", value: 1)
!67 = !{!68}
!68 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !69, size: 64)
!69 = !DIDerivedType(tag: DW_TAG_const_type, baseType: null)
!70 = !{!71, !77, !83, !86, !93, !97, !102, !104, !112, !116, !120, !132, !136, !140, !144, !148, !153, !157, !161, !165, !169, !177, !181, !185, !187, !191, !195, !199, !205, !209, !213, !215, !223, !227, !235, !237, !241, !245, !249, !253, !258, !263, !268, !269, !270, !271, !274, !275, !276, !277, !278, !279, !280, !335, !339, !355, !358, !363, !371, !376, !380, !384, !388, !392, !394, !396, !400, !406, !410, !416, !422, !424, !428, !432, !436, !440, !451, !453, !457, !461, !465, !467, !471, !475, !479, !481, !483, !487, !495, !499, !503, !507, !509, !515, !517, !523, !527, !531, !535, !539, !543, !547, !549, !551, !555, !559, !563, !565, !569, !573, !575, !577, !581, !585, !589, !593, !594, !595, !596, !597, !598, !599, !600, !601, !602, !603, !606, !609, !611, !613, !615, !617, !619, !621, !623, !625, !627, !629, !631, !633, !634, !635, !636, !638, !640, !642, !644, !646, !648, !650, !652, !654, !656, !658, !660, !662, !665, !669, !674, !677, !679, !681, !683, !685, !687, !689, !691, !693, !695, !697, !699, !701, !703, !706, !712, !717, !721, !723, !725, !727, !729, !736, !740, !744, !748, !752, !756, !761, !765, !767, !771, !777, !781, !786, !788, !790, !794, !798, !802, !804, !806, !808, !810, !814, !816, !818, !822, !826, !830, !834, !838, !840, !842, !846, !850, !854, !858, !860, !862, !866, !870, !871, !872, !873, !874, !875, !880, !882, !884, !888, !890, !892, !894, !896, !898, !900, !902, !907, !911, !913, !915, !920, !922, !924, !926, !928, !930, !932, !935, !937, !939, !943, !947, !949, !951, !953, !955, !957, !959, !961, !963, !965, !967, !971, !975, !977, !979, !981, !983, !985, !987, !989, !991, !993, !995, !997, !999, !1001, !1003, !1005, !1009, !1013, !1017, !1019, !1021, !1023, !1025, !1027, !1029, !1031, !1033, !1035, !1039, !1043, !1047, !1049, !1051, !1053, !1057, !1061, !1065, !1067, !1069, !1071, !1073, !1075, !1077, !1079, !1081, !1083, !1085, !1087, !1089, !1093, !1097, !1101, !1103, !1105, !1107, !1109, !1113, !1117, !1119, !1121, !1123, !1125, !1127, !1129, !1133, !1137, !1139, !1141, !1143, !1145, !1149, !1153, !1157, !1159, !1161, !1163, !1165, !1167, !1169, !1173, !1177, !1181, !1183, !1187, !1191, !1193, !1195, !1197, !1199, !1201, !1203, !1207, !1209, !1212, !1217, !1219, !1225, !1227, !1229, !1231, !1236, !1238, !1244, !1246, !1247, !1248, !1249, !1250, !1251, !1252, !1253, !1254, !1255, !1256, !1257, !1258}
!71 = !DIImportedEntity(tag: DW_TAG_imported_module, scope: !72, entity: !74, line: 58)
!72 = !DINamespace(name: "__gnu_debug", scope: null, file: !73, line: 56)
!73 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/debug/debug.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!74 = !DINamespace(name: "__debug", scope: !75, file: !73, line: 50)
!75 = !DINamespace(name: "std", scope: null, file: !76, line: 229)
!76 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/x86_64-linux-gnu/c++/7.4.0/bits/c++config.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!77 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !78, line: 52)
!78 = !DISubprogram(name: "abs", scope: !79, file: !79, line: 837, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!79 = !DIFile(filename: "/usr/include/stdlib.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!80 = !DISubroutineType(types: !81)
!81 = !{!82, !82}
!82 = !DIBasicType(name: "int", size: 32, encoding: DW_ATE_signed)
!83 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !84, line: 127)
!84 = !DIDerivedType(tag: DW_TAG_typedef, name: "div_t", file: !79, line: 62, baseType: !85)
!85 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 58, flags: DIFlagFwdDecl, identifier: "_ZTS5div_t")
!86 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !87, line: 128)
!87 = !DIDerivedType(tag: DW_TAG_typedef, name: "ldiv_t", file: !79, line: 70, baseType: !88)
!88 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 66, size: 128, elements: !89, identifier: "_ZTS6ldiv_t")
!89 = !{!90, !92}
!90 = !DIDerivedType(tag: DW_TAG_member, name: "quot", scope: !88, file: !79, line: 68, baseType: !91, size: 64)
!91 = !DIBasicType(name: "long int", size: 64, encoding: DW_ATE_signed)
!92 = !DIDerivedType(tag: DW_TAG_member, name: "rem", scope: !88, file: !79, line: 69, baseType: !91, size: 64, offset: 64)
!93 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !94, line: 130)
!94 = !DISubprogram(name: "abort", scope: !79, file: !79, line: 588, type: !95, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!95 = !DISubroutineType(types: !96)
!96 = !{null}
!97 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !98, line: 134)
!98 = !DISubprogram(name: "atexit", scope: !79, file: !79, line: 592, type: !99, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!99 = !DISubroutineType(types: !100)
!100 = !{!82, !101}
!101 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !95, size: 64)
!102 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !103, line: 137)
!103 = !DISubprogram(name: "at_quick_exit", scope: !79, file: !79, line: 597, type: !99, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!104 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !105, line: 140)
!105 = !DISubprogram(name: "atof", scope: !79, file: !79, line: 101, type: !106, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!106 = !DISubroutineType(types: !107)
!107 = !{!108, !109}
!108 = !DIBasicType(name: "double", size: 64, encoding: DW_ATE_float)
!109 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !110, size: 64)
!110 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !111)
!111 = !DIBasicType(name: "char", size: 8, encoding: DW_ATE_signed_char)
!112 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !113, line: 141)
!113 = !DISubprogram(name: "atoi", scope: !79, file: !79, line: 104, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!114 = !DISubroutineType(types: !115)
!115 = !{!82, !109}
!116 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !117, line: 142)
!117 = !DISubprogram(name: "atol", scope: !79, file: !79, line: 107, type: !118, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!118 = !DISubroutineType(types: !119)
!119 = !{!91, !109}
!120 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !121, line: 143)
!121 = !DISubprogram(name: "bsearch", scope: !79, file: !79, line: 817, type: !122, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!122 = !DISubroutineType(types: !123)
!123 = !{!124, !68, !68, !125, !125, !128}
!124 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: null, size: 64)
!125 = !DIDerivedType(tag: DW_TAG_typedef, name: "size_t", file: !126, line: 62, baseType: !127)
!126 = !DIFile(filename: "/home/ubuntu/Github/remill/remill-build/libraries/llvm/bin/../lib/clang/4.0.1/include/stddef.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!127 = !DIBasicType(name: "long unsigned int", size: 64, encoding: DW_ATE_unsigned)
!128 = !DIDerivedType(tag: DW_TAG_typedef, name: "__compar_fn_t", file: !79, line: 805, baseType: !129)
!129 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !130, size: 64)
!130 = !DISubroutineType(types: !131)
!131 = !{!82, !68, !68}
!132 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !133, line: 144)
!133 = !DISubprogram(name: "calloc", scope: !79, file: !79, line: 541, type: !134, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!134 = !DISubroutineType(types: !135)
!135 = !{!124, !125, !125}
!136 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !137, line: 145)
!137 = !DISubprogram(name: "div", scope: !79, file: !79, line: 849, type: !138, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!138 = !DISubroutineType(types: !139)
!139 = !{!84, !82, !82}
!140 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !141, line: 146)
!141 = !DISubprogram(name: "exit", scope: !79, file: !79, line: 614, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!142 = !DISubroutineType(types: !143)
!143 = !{null, !82}
!144 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !145, line: 147)
!145 = !DISubprogram(name: "free", scope: !79, file: !79, line: 563, type: !146, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!146 = !DISubroutineType(types: !147)
!147 = !{null, !124}
!148 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !149, line: 148)
!149 = !DISubprogram(name: "getenv", scope: !79, file: !79, line: 631, type: !150, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!150 = !DISubroutineType(types: !151)
!151 = !{!152, !109}
!152 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !111, size: 64)
!153 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !154, line: 149)
!154 = !DISubprogram(name: "labs", scope: !79, file: !79, line: 838, type: !155, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!155 = !DISubroutineType(types: !156)
!156 = !{!91, !91}
!157 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !158, line: 150)
!158 = !DISubprogram(name: "ldiv", scope: !79, file: !79, line: 851, type: !159, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!159 = !DISubroutineType(types: !160)
!160 = !{!87, !91, !91}
!161 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !162, line: 151)
!162 = !DISubprogram(name: "malloc", scope: !79, file: !79, line: 539, type: !163, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!163 = !DISubroutineType(types: !164)
!164 = !{!124, !125}
!165 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !166, line: 153)
!166 = !DISubprogram(name: "mblen", scope: !79, file: !79, line: 919, type: !167, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!167 = !DISubroutineType(types: !168)
!168 = !{!82, !109, !125}
!169 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !170, line: 154)
!170 = !DISubprogram(name: "mbstowcs", scope: !79, file: !79, line: 930, type: !171, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!171 = !DISubroutineType(types: !172)
!172 = !{!125, !173, !176, !125}
!173 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !174)
!174 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !175, size: 64)
!175 = !DIBasicType(name: "wchar_t", size: 32, encoding: DW_ATE_signed)
!176 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !109)
!177 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !178, line: 155)
!178 = !DISubprogram(name: "mbtowc", scope: !79, file: !79, line: 922, type: !179, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!179 = !DISubroutineType(types: !180)
!180 = !{!82, !173, !176, !125}
!181 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !182, line: 157)
!182 = !DISubprogram(name: "qsort", scope: !79, file: !79, line: 827, type: !183, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!183 = !DISubroutineType(types: !184)
!184 = !{null, !124, !125, !125, !128}
!185 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !186, line: 160)
!186 = !DISubprogram(name: "quick_exit", scope: !79, file: !79, line: 620, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!187 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !188, line: 163)
!188 = !DISubprogram(name: "rand", scope: !79, file: !79, line: 453, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!189 = !DISubroutineType(types: !190)
!190 = !{!82}
!191 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !192, line: 164)
!192 = !DISubprogram(name: "realloc", scope: !79, file: !79, line: 549, type: !193, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!193 = !DISubroutineType(types: !194)
!194 = !{!124, !124, !125}
!195 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !196, line: 165)
!196 = !DISubprogram(name: "srand", scope: !79, file: !79, line: 455, type: !197, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!197 = !DISubroutineType(types: !198)
!198 = !{null, !10}
!199 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !200, line: 166)
!200 = !DISubprogram(name: "strtod", scope: !79, file: !79, line: 117, type: !201, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!201 = !DISubroutineType(types: !202)
!202 = !{!108, !176, !203}
!203 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !204)
!204 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !152, size: 64)
!205 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !206, line: 167)
!206 = !DISubprogram(name: "strtol", scope: !79, file: !79, line: 176, type: !207, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!207 = !DISubroutineType(types: !208)
!208 = !{!91, !176, !203, !82}
!209 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !210, line: 168)
!210 = !DISubprogram(name: "strtoul", scope: !79, file: !79, line: 180, type: !211, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!211 = !DISubroutineType(types: !212)
!212 = !{!127, !176, !203, !82}
!213 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !214, line: 169)
!214 = !DISubprogram(name: "system", scope: !79, file: !79, line: 781, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!215 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !216, line: 171)
!216 = !DISubprogram(name: "wcstombs", scope: !79, file: !79, line: 933, type: !217, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!217 = !DISubroutineType(types: !218)
!218 = !{!125, !219, !220, !125}
!219 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !152)
!220 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !221)
!221 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !222, size: 64)
!222 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !175)
!223 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !224, line: 172)
!224 = !DISubprogram(name: "wctomb", scope: !79, file: !79, line: 926, type: !225, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!225 = !DISubroutineType(types: !226)
!226 = !{!82, !152, !175}
!227 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !229, line: 200)
!228 = !DINamespace(name: "__gnu_cxx", scope: null, file: !76, line: 255)
!229 = !DIDerivedType(tag: DW_TAG_typedef, name: "lldiv_t", file: !79, line: 80, baseType: !230)
!230 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 76, size: 128, elements: !231, identifier: "_ZTS7lldiv_t")
!231 = !{!232, !234}
!232 = !DIDerivedType(tag: DW_TAG_member, name: "quot", scope: !230, file: !79, line: 78, baseType: !233, size: 64)
!233 = !DIBasicType(name: "long long int", size: 64, encoding: DW_ATE_signed)
!234 = !DIDerivedType(tag: DW_TAG_member, name: "rem", scope: !230, file: !79, line: 79, baseType: !233, size: 64, offset: 64)
!235 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !236, line: 206)
!236 = !DISubprogram(name: "_Exit", scope: !79, file: !79, line: 626, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!237 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !238, line: 210)
!238 = !DISubprogram(name: "llabs", scope: !79, file: !79, line: 841, type: !239, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!239 = !DISubroutineType(types: !240)
!240 = !{!233, !233}
!241 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !242, line: 216)
!242 = !DISubprogram(name: "lldiv", scope: !79, file: !79, line: 855, type: !243, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!243 = !DISubroutineType(types: !244)
!244 = !{!229, !233, !233}
!245 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !246, line: 227)
!246 = !DISubprogram(name: "atoll", scope: !79, file: !79, line: 112, type: !247, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!247 = !DISubroutineType(types: !248)
!248 = !{!233, !109}
!249 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !250, line: 228)
!250 = !DISubprogram(name: "strtoll", scope: !79, file: !79, line: 200, type: !251, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!251 = !DISubroutineType(types: !252)
!252 = !{!233, !176, !203, !82}
!253 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !254, line: 229)
!254 = !DISubprogram(name: "strtoull", scope: !79, file: !79, line: 205, type: !255, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!255 = !DISubroutineType(types: !256)
!256 = !{!257, !176, !203, !82}
!257 = !DIBasicType(name: "long long unsigned int", size: 64, encoding: DW_ATE_unsigned)
!258 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !259, line: 231)
!259 = !DISubprogram(name: "strtof", scope: !79, file: !79, line: 123, type: !260, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!260 = !DISubroutineType(types: !261)
!261 = !{!262, !176, !203}
!262 = !DIBasicType(name: "float", size: 32, encoding: DW_ATE_float)
!263 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !264, line: 232)
!264 = !DISubprogram(name: "strtold", scope: !79, file: !79, line: 126, type: !265, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!265 = !DISubroutineType(types: !266)
!266 = !{!267, !176, !203}
!267 = !DIBasicType(name: "long double", size: 128, encoding: DW_ATE_float)
!268 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !229, line: 240)
!269 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !236, line: 242)
!270 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !238, line: 244)
!271 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !272, line: 245)
!272 = !DISubprogram(name: "div", linkageName: "_ZN9__gnu_cxx3divExx", scope: !228, file: !273, line: 213, type: !243, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!273 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/cstdlib", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!274 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !242, line: 246)
!275 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !246, line: 248)
!276 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !259, line: 249)
!277 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !250, line: 250)
!278 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !254, line: 251)
!279 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !264, line: 252)
!280 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !281, line: 57)
!281 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "exception_ptr", scope: !283, file: !282, line: 79, size: 64, elements: !284, identifier: "_ZTSNSt15__exception_ptr13exception_ptrE")
!282 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/bits/exception_ptr.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!283 = !DINamespace(name: "__exception_ptr", scope: !75, file: !282, line: 52)
!284 = !{!285, !286, !290, !293, !294, !299, !300, !304, !309, !313, !317, !320, !321, !324, !328}
!285 = !DIDerivedType(tag: DW_TAG_member, name: "_M_exception_object", scope: !281, file: !282, line: 81, baseType: !124, size: 64)
!286 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 83, type: !287, isLocal: false, isDefinition: false, scopeLine: 83, flags: DIFlagExplicit | DIFlagPrototyped, isOptimized: false)
!287 = !DISubroutineType(types: !288)
!288 = !{null, !289, !124}
!289 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !281, size: 64, flags: DIFlagArtificial | DIFlagObjectPointer)
!290 = !DISubprogram(name: "_M_addref", linkageName: "_ZNSt15__exception_ptr13exception_ptr9_M_addrefEv", scope: !281, file: !282, line: 85, type: !291, isLocal: false, isDefinition: false, scopeLine: 85, flags: DIFlagPrototyped, isOptimized: false)
!291 = !DISubroutineType(types: !292)
!292 = !{null, !289}
!293 = !DISubprogram(name: "_M_release", linkageName: "_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv", scope: !281, file: !282, line: 86, type: !291, isLocal: false, isDefinition: false, scopeLine: 86, flags: DIFlagPrototyped, isOptimized: false)
!294 = !DISubprogram(name: "_M_get", linkageName: "_ZNKSt15__exception_ptr13exception_ptr6_M_getEv", scope: !281, file: !282, line: 88, type: !295, isLocal: false, isDefinition: false, scopeLine: 88, flags: DIFlagPrototyped, isOptimized: false)
!295 = !DISubroutineType(types: !296)
!296 = !{!124, !297}
!297 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !298, size: 64, flags: DIFlagArtificial | DIFlagObjectPointer)
!298 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !281)
!299 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 96, type: !291, isLocal: false, isDefinition: false, scopeLine: 96, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!300 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 98, type: !301, isLocal: false, isDefinition: false, scopeLine: 98, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!301 = !DISubroutineType(types: !302)
!302 = !{null, !289, !303}
!303 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !298, size: 64)
!304 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 101, type: !305, isLocal: false, isDefinition: false, scopeLine: 101, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!305 = !DISubroutineType(types: !306)
!306 = !{null, !289, !307}
!307 = !DIDerivedType(tag: DW_TAG_typedef, name: "nullptr_t", scope: !75, file: !76, line: 235, baseType: !308)
!308 = !DIBasicType(tag: DW_TAG_unspecified_type, name: "decltype(nullptr)")
!309 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 105, type: !310, isLocal: false, isDefinition: false, scopeLine: 105, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!310 = !DISubroutineType(types: !311)
!311 = !{null, !289, !312}
!312 = !DIDerivedType(tag: DW_TAG_rvalue_reference_type, baseType: !281, size: 64)
!313 = !DISubprogram(name: "operator=", linkageName: "_ZNSt15__exception_ptr13exception_ptraSERKS0_", scope: !281, file: !282, line: 118, type: !314, isLocal: false, isDefinition: false, scopeLine: 118, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!314 = !DISubroutineType(types: !315)
!315 = !{!316, !289, !303}
!316 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !281, size: 64)
!317 = !DISubprogram(name: "operator=", linkageName: "_ZNSt15__exception_ptr13exception_ptraSEOS0_", scope: !281, file: !282, line: 122, type: !318, isLocal: false, isDefinition: false, scopeLine: 122, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!318 = !DISubroutineType(types: !319)
!319 = !{!316, !289, !312}
!320 = !DISubprogram(name: "~exception_ptr", scope: !281, file: !282, line: 129, type: !291, isLocal: false, isDefinition: false, scopeLine: 129, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!321 = !DISubprogram(name: "swap", linkageName: "_ZNSt15__exception_ptr13exception_ptr4swapERS0_", scope: !281, file: !282, line: 132, type: !322, isLocal: false, isDefinition: false, scopeLine: 132, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!322 = !DISubroutineType(types: !323)
!323 = !{null, !289, !316}
!324 = !DISubprogram(name: "operator bool", linkageName: "_ZNKSt15__exception_ptr13exception_ptrcvbEv", scope: !281, file: !282, line: 144, type: !325, isLocal: false, isDefinition: false, scopeLine: 144, flags: DIFlagPublic | DIFlagExplicit | DIFlagPrototyped, isOptimized: false)
!325 = !DISubroutineType(types: !326)
!326 = !{!327, !297}
!327 = !DIBasicType(name: "bool", size: 8, encoding: DW_ATE_boolean)
!328 = !DISubprogram(name: "__cxa_exception_type", linkageName: "_ZNKSt15__exception_ptr13exception_ptr20__cxa_exception_typeEv", scope: !281, file: !282, line: 153, type: !329, isLocal: false, isDefinition: false, scopeLine: 153, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!329 = !DISubroutineType(types: !330)
!330 = !{!331, !297}
!331 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !332, size: 64)
!332 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !333)
!333 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "type_info", scope: !75, file: !334, line: 88, flags: DIFlagFwdDecl, identifier: "_ZTSSt9type_info")
!334 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/typeinfo", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!335 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !283, entity: !336, line: 73)
!336 = !DISubprogram(name: "rethrow_exception", linkageName: "_ZSt17rethrow_exceptionNSt15__exception_ptr13exception_ptrE", scope: !75, file: !282, line: 69, type: !337, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!337 = !DISubroutineType(types: !338)
!338 = !{null, !281}
!339 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !340, line: 64)
!340 = !DIDerivedType(tag: DW_TAG_typedef, name: "mbstate_t", file: !341, line: 6, baseType: !342)
!341 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/mbstate_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!342 = !DIDerivedType(tag: DW_TAG_typedef, name: "__mbstate_t", file: !343, line: 21, baseType: !344)
!343 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/__mbstate_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!344 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !343, line: 13, size: 64, elements: !345, identifier: "_ZTS11__mbstate_t")
!345 = !{!346, !347}
!346 = !DIDerivedType(tag: DW_TAG_member, name: "__count", scope: !344, file: !343, line: 15, baseType: !82, size: 32)
!347 = !DIDerivedType(tag: DW_TAG_member, name: "__value", scope: !344, file: !343, line: 20, baseType: !348, size: 32, offset: 32)
!348 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !344, file: !343, line: 16, size: 32, elements: !349, identifier: "_ZTSN11__mbstate_tUt_E")
!349 = !{!350, !351}
!350 = !DIDerivedType(tag: DW_TAG_member, name: "__wch", scope: !348, file: !343, line: 18, baseType: !10, size: 32)
!351 = !DIDerivedType(tag: DW_TAG_member, name: "__wchb", scope: !348, file: !343, line: 19, baseType: !352, size: 32)
!352 = !DICompositeType(tag: DW_TAG_array_type, baseType: !111, size: 32, elements: !353)
!353 = !{!354}
!354 = !DISubrange(count: 4)
!355 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !356, line: 139)
!356 = !DIDerivedType(tag: DW_TAG_typedef, name: "wint_t", file: !357, line: 20, baseType: !10)
!357 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/wint_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!358 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !359, line: 141)
!359 = !DISubprogram(name: "btowc", scope: !360, file: !360, line: 284, type: !361, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!360 = !DIFile(filename: "/usr/include/wchar.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!361 = !DISubroutineType(types: !362)
!362 = !{!356, !82}
!363 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !364, line: 142)
!364 = !DISubprogram(name: "fgetwc", scope: !360, file: !360, line: 727, type: !365, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!365 = !DISubroutineType(types: !366)
!366 = !{!356, !367}
!367 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !368, size: 64)
!368 = !DIDerivedType(tag: DW_TAG_typedef, name: "__FILE", file: !369, line: 5, baseType: !370)
!369 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/__FILE.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!370 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "_IO_FILE", file: !369, line: 4, flags: DIFlagFwdDecl, identifier: "_ZTS8_IO_FILE")
!371 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !372, line: 143)
!372 = !DISubprogram(name: "fgetws", scope: !360, file: !360, line: 756, type: !373, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!373 = !DISubroutineType(types: !374)
!374 = !{!174, !173, !82, !375}
!375 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !367)
!376 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !377, line: 144)
!377 = !DISubprogram(name: "fputwc", scope: !360, file: !360, line: 741, type: !378, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!378 = !DISubroutineType(types: !379)
!379 = !{!356, !175, !367}
!380 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !381, line: 145)
!381 = !DISubprogram(name: "fputws", scope: !360, file: !360, line: 763, type: !382, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!382 = !DISubroutineType(types: !383)
!383 = !{!82, !220, !375}
!384 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !385, line: 146)
!385 = !DISubprogram(name: "fwide", scope: !360, file: !360, line: 573, type: !386, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!386 = !DISubroutineType(types: !387)
!387 = !{!82, !367, !82}
!388 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !389, line: 147)
!389 = !DISubprogram(name: "fwprintf", scope: !360, file: !360, line: 580, type: !390, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!390 = !DISubroutineType(types: !391)
!391 = !{!82, !375, !220, null}
!392 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !393, line: 148)
!393 = !DISubprogram(name: "fwscanf", scope: !360, file: !360, line: 621, type: !390, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!394 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !395, line: 149)
!395 = !DISubprogram(name: "getwc", scope: !360, file: !360, line: 728, type: !365, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!396 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !397, line: 150)
!397 = !DISubprogram(name: "getwchar", scope: !360, file: !360, line: 734, type: !398, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!398 = !DISubroutineType(types: !399)
!399 = !{!356}
!400 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !401, line: 151)
!401 = !DISubprogram(name: "mbrlen", scope: !360, file: !360, line: 307, type: !402, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!402 = !DISubroutineType(types: !403)
!403 = !{!125, !176, !125, !404}
!404 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !405)
!405 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !340, size: 64)
!406 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !407, line: 152)
!407 = !DISubprogram(name: "mbrtowc", scope: !360, file: !360, line: 296, type: !408, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!408 = !DISubroutineType(types: !409)
!409 = !{!125, !173, !176, !125, !404}
!410 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !411, line: 153)
!411 = !DISubprogram(name: "mbsinit", scope: !360, file: !360, line: 292, type: !412, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!412 = !DISubroutineType(types: !413)
!413 = !{!82, !414}
!414 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !415, size: 64)
!415 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !340)
!416 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !417, line: 154)
!417 = !DISubprogram(name: "mbsrtowcs", scope: !360, file: !360, line: 337, type: !418, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!418 = !DISubroutineType(types: !419)
!419 = !{!125, !173, !420, !125, !404}
!420 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !421)
!421 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !109, size: 64)
!422 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !423, line: 155)
!423 = !DISubprogram(name: "putwc", scope: !360, file: !360, line: 742, type: !378, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!424 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !425, line: 156)
!425 = !DISubprogram(name: "putwchar", scope: !360, file: !360, line: 748, type: !426, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!426 = !DISubroutineType(types: !427)
!427 = !{!356, !175}
!428 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !429, line: 158)
!429 = !DISubprogram(name: "swprintf", scope: !360, file: !360, line: 590, type: !430, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!430 = !DISubroutineType(types: !431)
!431 = !{!82, !173, !125, !220, null}
!432 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !433, line: 160)
!433 = !DISubprogram(name: "swscanf", scope: !360, file: !360, line: 631, type: !434, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!434 = !DISubroutineType(types: !435)
!435 = !{!82, !220, !220, null}
!436 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !437, line: 161)
!437 = !DISubprogram(name: "ungetwc", scope: !360, file: !360, line: 771, type: !438, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!438 = !DISubroutineType(types: !439)
!439 = !{!356, !356, !367}
!440 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !441, line: 162)
!441 = !DISubprogram(name: "vfwprintf", scope: !360, file: !360, line: 598, type: !442, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!442 = !DISubroutineType(types: !443)
!443 = !{!82, !375, !220, !444}
!444 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !445, size: 64)
!445 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "__va_list_tag", file: !2, size: 192, elements: !446, identifier: "_ZTS13__va_list_tag")
!446 = !{!447, !448, !449, !450}
!447 = !DIDerivedType(tag: DW_TAG_member, name: "gp_offset", scope: !445, file: !2, baseType: !10, size: 32)
!448 = !DIDerivedType(tag: DW_TAG_member, name: "fp_offset", scope: !445, file: !2, baseType: !10, size: 32, offset: 32)
!449 = !DIDerivedType(tag: DW_TAG_member, name: "overflow_arg_area", scope: !445, file: !2, baseType: !124, size: 64, offset: 64)
!450 = !DIDerivedType(tag: DW_TAG_member, name: "reg_save_area", scope: !445, file: !2, baseType: !124, size: 64, offset: 128)
!451 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !452, line: 164)
!452 = !DISubprogram(name: "vfwscanf", scope: !360, file: !360, line: 673, type: !442, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!453 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !454, line: 167)
!454 = !DISubprogram(name: "vswprintf", scope: !360, file: !360, line: 611, type: !455, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!455 = !DISubroutineType(types: !456)
!456 = !{!82, !173, !125, !220, !444}
!457 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !458, line: 170)
!458 = !DISubprogram(name: "vswscanf", scope: !360, file: !360, line: 685, type: !459, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!459 = !DISubroutineType(types: !460)
!460 = !{!82, !220, !220, !444}
!461 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !462, line: 172)
!462 = !DISubprogram(name: "vwprintf", scope: !360, file: !360, line: 606, type: !463, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!463 = !DISubroutineType(types: !464)
!464 = !{!82, !220, !444}
!465 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !466, line: 174)
!466 = !DISubprogram(name: "vwscanf", scope: !360, file: !360, line: 681, type: !463, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!467 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !468, line: 176)
!468 = !DISubprogram(name: "wcrtomb", scope: !360, file: !360, line: 301, type: !469, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!469 = !DISubroutineType(types: !470)
!470 = !{!125, !219, !175, !404}
!471 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !472, line: 177)
!472 = !DISubprogram(name: "wcscat", scope: !360, file: !360, line: 97, type: !473, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!473 = !DISubroutineType(types: !474)
!474 = !{!174, !173, !220}
!475 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !476, line: 178)
!476 = !DISubprogram(name: "wcscmp", scope: !360, file: !360, line: 106, type: !477, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!477 = !DISubroutineType(types: !478)
!478 = !{!82, !221, !221}
!479 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !480, line: 179)
!480 = !DISubprogram(name: "wcscoll", scope: !360, file: !360, line: 131, type: !477, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!481 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !482, line: 180)
!482 = !DISubprogram(name: "wcscpy", scope: !360, file: !360, line: 87, type: !473, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!483 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !484, line: 181)
!484 = !DISubprogram(name: "wcscspn", scope: !360, file: !360, line: 187, type: !485, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!485 = !DISubroutineType(types: !486)
!486 = !{!125, !221, !221}
!487 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !488, line: 182)
!488 = !DISubprogram(name: "wcsftime", scope: !360, file: !360, line: 835, type: !489, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!489 = !DISubroutineType(types: !490)
!490 = !{!125, !173, !125, !220, !491}
!491 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !492)
!492 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !493, size: 64)
!493 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !494)
!494 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "tm", file: !360, line: 83, flags: DIFlagFwdDecl, identifier: "_ZTS2tm")
!495 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !496, line: 183)
!496 = !DISubprogram(name: "wcslen", scope: !360, file: !360, line: 222, type: !497, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!497 = !DISubroutineType(types: !498)
!498 = !{!125, !221}
!499 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !500, line: 184)
!500 = !DISubprogram(name: "wcsncat", scope: !360, file: !360, line: 101, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!501 = !DISubroutineType(types: !502)
!502 = !{!174, !173, !220, !125}
!503 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !504, line: 185)
!504 = !DISubprogram(name: "wcsncmp", scope: !360, file: !360, line: 109, type: !505, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!505 = !DISubroutineType(types: !506)
!506 = !{!82, !221, !221, !125}
!507 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !508, line: 186)
!508 = !DISubprogram(name: "wcsncpy", scope: !360, file: !360, line: 92, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!509 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !510, line: 187)
!510 = !DISubprogram(name: "wcsrtombs", scope: !360, file: !360, line: 343, type: !511, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!511 = !DISubroutineType(types: !512)
!512 = !{!125, !219, !513, !125, !404}
!513 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !514)
!514 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !221, size: 64)
!515 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !516, line: 188)
!516 = !DISubprogram(name: "wcsspn", scope: !360, file: !360, line: 191, type: !485, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!517 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !518, line: 189)
!518 = !DISubprogram(name: "wcstod", scope: !360, file: !360, line: 377, type: !519, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!519 = !DISubroutineType(types: !520)
!520 = !{!108, !220, !521}
!521 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !522)
!522 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !174, size: 64)
!523 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !524, line: 191)
!524 = !DISubprogram(name: "wcstof", scope: !360, file: !360, line: 382, type: !525, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!525 = !DISubroutineType(types: !526)
!526 = !{!262, !220, !521}
!527 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !528, line: 193)
!528 = !DISubprogram(name: "wcstok", scope: !360, file: !360, line: 217, type: !529, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!529 = !DISubroutineType(types: !530)
!530 = !{!174, !173, !220, !521}
!531 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !532, line: 194)
!532 = !DISubprogram(name: "wcstol", scope: !360, file: !360, line: 428, type: !533, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!533 = !DISubroutineType(types: !534)
!534 = !{!91, !220, !521, !82}
!535 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !536, line: 195)
!536 = !DISubprogram(name: "wcstoul", scope: !360, file: !360, line: 433, type: !537, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!537 = !DISubroutineType(types: !538)
!538 = !{!127, !220, !521, !82}
!539 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !540, line: 196)
!540 = !DISubprogram(name: "wcsxfrm", scope: !360, file: !360, line: 135, type: !541, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!541 = !DISubroutineType(types: !542)
!542 = !{!125, !173, !220, !125}
!543 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !544, line: 197)
!544 = !DISubprogram(name: "wctob", scope: !360, file: !360, line: 288, type: !545, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!545 = !DISubroutineType(types: !546)
!546 = !{!82, !356}
!547 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !548, line: 198)
!548 = !DISubprogram(name: "wmemcmp", scope: !360, file: !360, line: 258, type: !505, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!549 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !550, line: 199)
!550 = !DISubprogram(name: "wmemcpy", scope: !360, file: !360, line: 262, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!551 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !552, line: 200)
!552 = !DISubprogram(name: "wmemmove", scope: !360, file: !360, line: 267, type: !553, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!553 = !DISubroutineType(types: !554)
!554 = !{!174, !174, !221, !125}
!555 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !556, line: 201)
!556 = !DISubprogram(name: "wmemset", scope: !360, file: !360, line: 271, type: !557, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!557 = !DISubroutineType(types: !558)
!558 = !{!174, !174, !175, !125}
!559 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !560, line: 202)
!560 = !DISubprogram(name: "wprintf", scope: !360, file: !360, line: 587, type: !561, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!561 = !DISubroutineType(types: !562)
!562 = !{!82, !220, null}
!563 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !564, line: 203)
!564 = !DISubprogram(name: "wscanf", scope: !360, file: !360, line: 628, type: !561, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!565 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !566, line: 204)
!566 = !DISubprogram(name: "wcschr", scope: !360, file: !360, line: 164, type: !567, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!567 = !DISubroutineType(types: !568)
!568 = !{!174, !221, !175}
!569 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !570, line: 205)
!570 = !DISubprogram(name: "wcspbrk", scope: !360, file: !360, line: 201, type: !571, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!571 = !DISubroutineType(types: !572)
!572 = !{!174, !221, !221}
!573 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !574, line: 206)
!574 = !DISubprogram(name: "wcsrchr", scope: !360, file: !360, line: 174, type: !567, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!575 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !576, line: 207)
!576 = !DISubprogram(name: "wcsstr", scope: !360, file: !360, line: 212, type: !571, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!577 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !578, line: 208)
!578 = !DISubprogram(name: "wmemchr", scope: !360, file: !360, line: 253, type: !579, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!579 = !DISubroutineType(types: !580)
!580 = !{!174, !221, !175, !125}
!581 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !582, line: 248)
!582 = !DISubprogram(name: "wcstold", scope: !360, file: !360, line: 384, type: !583, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!583 = !DISubroutineType(types: !584)
!584 = !{!267, !220, !521}
!585 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !586, line: 257)
!586 = !DISubprogram(name: "wcstoll", scope: !360, file: !360, line: 441, type: !587, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!587 = !DISubroutineType(types: !588)
!588 = !{!233, !220, !521, !82}
!589 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !590, line: 258)
!590 = !DISubprogram(name: "wcstoull", scope: !360, file: !360, line: 448, type: !591, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!591 = !DISubroutineType(types: !592)
!592 = !{!257, !220, !521, !82}
!593 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !582, line: 264)
!594 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !586, line: 265)
!595 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !590, line: 266)
!596 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !524, line: 280)
!597 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !452, line: 283)
!598 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !458, line: 286)
!599 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !466, line: 289)
!600 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !582, line: 293)
!601 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !586, line: 294)
!602 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !590, line: 295)
!603 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !604, line: 48)
!604 = !DIDerivedType(tag: DW_TAG_typedef, name: "int8_t", file: !9, line: 235, baseType: !605)
!605 = !DIBasicType(name: "signed char", size: 8, encoding: DW_ATE_signed_char)
!606 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !607, line: 49)
!607 = !DIDerivedType(tag: DW_TAG_typedef, name: "int16_t", file: !9, line: 216, baseType: !608)
!608 = !DIBasicType(name: "short", size: 16, encoding: DW_ATE_signed)
!609 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !610, line: 50)
!610 = !DIDerivedType(tag: DW_TAG_typedef, name: "int32_t", file: !9, line: 178, baseType: !82)
!611 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !612, line: 51)
!612 = !DIDerivedType(tag: DW_TAG_typedef, name: "int64_t", file: !9, line: 107, baseType: !91)
!613 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !614, line: 53)
!614 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast8_t", file: !9, line: 245, baseType: !604)
!615 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !616, line: 54)
!616 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast16_t", file: !9, line: 228, baseType: !607)
!617 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !618, line: 55)
!618 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast32_t", file: !9, line: 197, baseType: !610)
!619 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !620, line: 56)
!620 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast64_t", file: !9, line: 123, baseType: !612)
!621 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !622, line: 58)
!622 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least8_t", file: !9, line: 243, baseType: !604)
!623 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !624, line: 59)
!624 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least16_t", file: !9, line: 226, baseType: !607)
!625 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !626, line: 60)
!626 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least32_t", file: !9, line: 195, baseType: !610)
!627 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !628, line: 61)
!628 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least64_t", file: !9, line: 121, baseType: !612)
!629 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !630, line: 63)
!630 = !DIDerivedType(tag: DW_TAG_typedef, name: "intmax_t", file: !9, line: 276, baseType: !91)
!631 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !632, line: 64)
!632 = !DIDerivedType(tag: DW_TAG_typedef, name: "intptr_t", file: !9, line: 263, baseType: !612)
!633 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !62, line: 66)
!634 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !28, line: 67)
!635 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !8, line: 68)
!636 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !637, line: 69)
!637 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint64_t", file: !9, line: 109, baseType: !127)
!638 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !639, line: 71)
!639 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast8_t", file: !9, line: 246, baseType: !62)
!640 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !641, line: 72)
!641 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast16_t", file: !9, line: 229, baseType: !28)
!642 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !643, line: 73)
!643 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast32_t", file: !9, line: 198, baseType: !8)
!644 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !645, line: 74)
!645 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast64_t", file: !9, line: 124, baseType: !637)
!646 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !647, line: 76)
!647 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least8_t", file: !9, line: 244, baseType: !62)
!648 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !649, line: 77)
!649 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least16_t", file: !9, line: 227, baseType: !28)
!650 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !651, line: 78)
!651 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least32_t", file: !9, line: 196, baseType: !8)
!652 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !653, line: 79)
!653 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least64_t", file: !9, line: 122, baseType: !637)
!654 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !655, line: 81)
!655 = !DIDerivedType(tag: DW_TAG_typedef, name: "uintmax_t", file: !9, line: 277, baseType: !127)
!656 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !657, line: 82)
!657 = !DIDerivedType(tag: DW_TAG_typedef, name: "uintptr_t", file: !9, line: 270, baseType: !637)
!658 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !659, line: 44)
!659 = !DIDerivedType(tag: DW_TAG_typedef, name: "size_t", scope: !75, file: !76, line: 231, baseType: !127)
!660 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !661, line: 45)
!661 = !DIDerivedType(tag: DW_TAG_typedef, name: "ptrdiff_t", scope: !75, file: !76, line: 232, baseType: !91)
!662 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !663, line: 53)
!663 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "lconv", file: !664, line: 51, flags: DIFlagFwdDecl, identifier: "_ZTS5lconv")
!664 = !DIFile(filename: "/usr/include/locale.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!665 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !666, line: 54)
!666 = !DISubprogram(name: "setlocale", scope: !664, file: !664, line: 122, type: !667, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!667 = !DISubroutineType(types: !668)
!668 = !{!152, !82, !109}
!669 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !670, line: 55)
!670 = !DISubprogram(name: "localeconv", scope: !664, file: !664, line: 125, type: !671, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!671 = !DISubroutineType(types: !672)
!672 = !{!673}
!673 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !663, size: 64)
!674 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !675, line: 64)
!675 = !DISubprogram(name: "isalnum", scope: !676, file: !676, line: 108, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!676 = !DIFile(filename: "/usr/include/ctype.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!677 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !678, line: 65)
!678 = !DISubprogram(name: "isalpha", scope: !676, file: !676, line: 109, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!679 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !680, line: 66)
!680 = !DISubprogram(name: "iscntrl", scope: !676, file: !676, line: 110, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!681 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !682, line: 67)
!682 = !DISubprogram(name: "isdigit", scope: !676, file: !676, line: 111, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!683 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !684, line: 68)
!684 = !DISubprogram(name: "isgraph", scope: !676, file: !676, line: 113, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!685 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !686, line: 69)
!686 = !DISubprogram(name: "islower", scope: !676, file: !676, line: 112, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!687 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !688, line: 70)
!688 = !DISubprogram(name: "isprint", scope: !676, file: !676, line: 114, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!689 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !690, line: 71)
!690 = !DISubprogram(name: "ispunct", scope: !676, file: !676, line: 115, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!691 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !692, line: 72)
!692 = !DISubprogram(name: "isspace", scope: !676, file: !676, line: 116, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!693 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !694, line: 73)
!694 = !DISubprogram(name: "isupper", scope: !676, file: !676, line: 117, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!695 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !696, line: 74)
!696 = !DISubprogram(name: "isxdigit", scope: !676, file: !676, line: 118, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!697 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !698, line: 75)
!698 = !DISubprogram(name: "tolower", scope: !676, file: !676, line: 122, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!699 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !700, line: 76)
!700 = !DISubprogram(name: "toupper", scope: !676, file: !676, line: 125, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!701 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !702, line: 87)
!702 = !DISubprogram(name: "isblank", scope: !676, file: !676, line: 130, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!703 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !704, line: 98)
!704 = !DIDerivedType(tag: DW_TAG_typedef, name: "FILE", file: !705, line: 7, baseType: !370)
!705 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/FILE.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!706 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !707, line: 99)
!707 = !DIDerivedType(tag: DW_TAG_typedef, name: "fpos_t", file: !708, line: 78, baseType: !709)
!708 = !DIFile(filename: "/usr/include/stdio.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!709 = !DIDerivedType(tag: DW_TAG_typedef, name: "_G_fpos_t", file: !710, line: 30, baseType: !711)
!710 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/_G_config.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!711 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !710, line: 26, flags: DIFlagFwdDecl, identifier: "_ZTS9_G_fpos_t")
!712 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !713, line: 101)
!713 = !DISubprogram(name: "clearerr", scope: !708, file: !708, line: 757, type: !714, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!714 = !DISubroutineType(types: !715)
!715 = !{null, !716}
!716 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !704, size: 64)
!717 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !718, line: 102)
!718 = !DISubprogram(name: "fclose", scope: !708, file: !708, line: 199, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!719 = !DISubroutineType(types: !720)
!720 = !{!82, !716}
!721 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !722, line: 103)
!722 = !DISubprogram(name: "feof", scope: !708, file: !708, line: 759, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!723 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !724, line: 104)
!724 = !DISubprogram(name: "ferror", scope: !708, file: !708, line: 761, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!725 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !726, line: 105)
!726 = !DISubprogram(name: "fflush", scope: !708, file: !708, line: 204, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!727 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !728, line: 106)
!728 = !DISubprogram(name: "fgetc", scope: !708, file: !708, line: 477, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!729 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !730, line: 107)
!730 = !DISubprogram(name: "fgetpos", scope: !708, file: !708, line: 731, type: !731, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!731 = !DISubroutineType(types: !732)
!732 = !{!82, !733, !734}
!733 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !716)
!734 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !735)
!735 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !707, size: 64)
!736 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !737, line: 108)
!737 = !DISubprogram(name: "fgets", scope: !708, file: !708, line: 564, type: !738, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!738 = !DISubroutineType(types: !739)
!739 = !{!152, !219, !82, !733}
!740 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !741, line: 109)
!741 = !DISubprogram(name: "fopen", scope: !708, file: !708, line: 232, type: !742, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!742 = !DISubroutineType(types: !743)
!743 = !{!716, !176, !176}
!744 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !745, line: 110)
!745 = !DISubprogram(name: "fprintf", scope: !708, file: !708, line: 312, type: !746, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!746 = !DISubroutineType(types: !747)
!747 = !{!82, !733, !176, null}
!748 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !749, line: 111)
!749 = !DISubprogram(name: "fputc", scope: !708, file: !708, line: 517, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!750 = !DISubroutineType(types: !751)
!751 = !{!82, !82, !716}
!752 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !753, line: 112)
!753 = !DISubprogram(name: "fputs", scope: !708, file: !708, line: 626, type: !754, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!754 = !DISubroutineType(types: !755)
!755 = !{!82, !176, !733}
!756 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !757, line: 113)
!757 = !DISubprogram(name: "fread", scope: !708, file: !708, line: 646, type: !758, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!758 = !DISubroutineType(types: !759)
!759 = !{!125, !760, !125, !125, !733}
!760 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !124)
!761 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !762, line: 114)
!762 = !DISubprogram(name: "freopen", scope: !708, file: !708, line: 238, type: !763, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!763 = !DISubroutineType(types: !764)
!764 = !{!716, !176, !176, !733}
!765 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !766, line: 115)
!766 = !DISubprogram(name: "fscanf", scope: !708, file: !708, line: 377, type: !746, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!767 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !768, line: 116)
!768 = !DISubprogram(name: "fseek", scope: !708, file: !708, line: 684, type: !769, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!769 = !DISubroutineType(types: !770)
!770 = !{!82, !716, !91, !82}
!771 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !772, line: 117)
!772 = !DISubprogram(name: "fsetpos", scope: !708, file: !708, line: 736, type: !773, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!773 = !DISubroutineType(types: !774)
!774 = !{!82, !716, !775}
!775 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !776, size: 64)
!776 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !707)
!777 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !778, line: 118)
!778 = !DISubprogram(name: "ftell", scope: !708, file: !708, line: 689, type: !779, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!779 = !DISubroutineType(types: !780)
!780 = !{!91, !716}
!781 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !782, line: 119)
!782 = !DISubprogram(name: "fwrite", scope: !708, file: !708, line: 652, type: !783, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!783 = !DISubroutineType(types: !784)
!784 = !{!125, !785, !125, !125, !733}
!785 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !68)
!786 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !787, line: 120)
!787 = !DISubprogram(name: "getc", scope: !708, file: !708, line: 478, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!788 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !789, line: 121)
!789 = !DISubprogram(name: "getchar", scope: !708, file: !708, line: 484, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!790 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !791, line: 124)
!791 = !DISubprogram(name: "gets", scope: !708, file: !708, line: 577, type: !792, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!792 = !DISubroutineType(types: !793)
!793 = !{!152, !152}
!794 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !795, line: 126)
!795 = !DISubprogram(name: "perror", scope: !708, file: !708, line: 775, type: !796, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!796 = !DISubroutineType(types: !797)
!797 = !{null, !109}
!798 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !799, line: 127)
!799 = !DISubprogram(name: "printf", scope: !708, file: !708, line: 318, type: !800, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!800 = !DISubroutineType(types: !801)
!801 = !{!82, !176, null}
!802 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !803, line: 128)
!803 = !DISubprogram(name: "putc", scope: !708, file: !708, line: 518, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!804 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !805, line: 129)
!805 = !DISubprogram(name: "putchar", scope: !708, file: !708, line: 524, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!806 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !807, line: 130)
!807 = !DISubprogram(name: "puts", scope: !708, file: !708, line: 632, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!808 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !809, line: 131)
!809 = !DISubprogram(name: "remove", scope: !708, file: !708, line: 144, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!810 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !811, line: 132)
!811 = !DISubprogram(name: "rename", scope: !708, file: !708, line: 146, type: !812, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!812 = !DISubroutineType(types: !813)
!813 = !{!82, !109, !109}
!814 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !815, line: 133)
!815 = !DISubprogram(name: "rewind", scope: !708, file: !708, line: 694, type: !714, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!816 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !817, line: 134)
!817 = !DISubprogram(name: "scanf", scope: !708, file: !708, line: 383, type: !800, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!818 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !819, line: 135)
!819 = !DISubprogram(name: "setbuf", scope: !708, file: !708, line: 290, type: !820, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!820 = !DISubroutineType(types: !821)
!821 = !{null, !733, !219}
!822 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !823, line: 136)
!823 = !DISubprogram(name: "setvbuf", scope: !708, file: !708, line: 294, type: !824, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!824 = !DISubroutineType(types: !825)
!825 = !{!82, !733, !219, !82, !125}
!826 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !827, line: 137)
!827 = !DISubprogram(name: "sprintf", scope: !708, file: !708, line: 320, type: !828, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!828 = !DISubroutineType(types: !829)
!829 = !{!82, !219, !176, null}
!830 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !831, line: 138)
!831 = !DISubprogram(name: "sscanf", scope: !708, file: !708, line: 385, type: !832, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!832 = !DISubroutineType(types: !833)
!833 = !{!82, !176, !176, null}
!834 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !835, line: 139)
!835 = !DISubprogram(name: "tmpfile", scope: !708, file: !708, line: 159, type: !836, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!836 = !DISubroutineType(types: !837)
!837 = !{!716}
!838 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !839, line: 141)
!839 = !DISubprogram(name: "tmpnam", scope: !708, file: !708, line: 173, type: !792, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!840 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !841, line: 143)
!841 = !DISubprogram(name: "ungetc", scope: !708, file: !708, line: 639, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!842 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !843, line: 144)
!843 = !DISubprogram(name: "vfprintf", scope: !708, file: !708, line: 327, type: !844, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!844 = !DISubroutineType(types: !845)
!845 = !{!82, !733, !176, !444}
!846 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !847, line: 145)
!847 = !DISubprogram(name: "vprintf", scope: !708, file: !708, line: 333, type: !848, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!848 = !DISubroutineType(types: !849)
!849 = !{!82, !176, !444}
!850 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !851, line: 146)
!851 = !DISubprogram(name: "vsprintf", scope: !708, file: !708, line: 335, type: !852, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!852 = !DISubroutineType(types: !853)
!853 = !{!82, !219, !176, !444}
!854 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !855, line: 175)
!855 = !DISubprogram(name: "snprintf", scope: !708, file: !708, line: 340, type: !856, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!856 = !DISubroutineType(types: !857)
!857 = !{!82, !219, !125, !176, null}
!858 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !859, line: 176)
!859 = !DISubprogram(name: "vfscanf", scope: !708, file: !708, line: 420, type: !844, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!860 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !861, line: 177)
!861 = !DISubprogram(name: "vscanf", scope: !708, file: !708, line: 428, type: !848, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!862 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !863, line: 178)
!863 = !DISubprogram(name: "vsnprintf", scope: !708, file: !708, line: 344, type: !864, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!864 = !DISubroutineType(types: !865)
!865 = !{!82, !219, !125, !176, !444}
!866 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !867, line: 179)
!867 = !DISubprogram(name: "vsscanf", scope: !708, file: !708, line: 432, type: !868, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!868 = !DISubroutineType(types: !869)
!869 = !{!82, !176, !176, !444}
!870 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !855, line: 185)
!871 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !859, line: 186)
!872 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !861, line: 187)
!873 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !863, line: 188)
!874 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !867, line: 189)
!875 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !876, line: 83)
!876 = !DISubprogram(name: "acos", scope: !877, file: !877, line: 53, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!877 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/mathcalls.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!878 = !DISubroutineType(types: !879)
!879 = !{!108, !108}
!880 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !881, line: 102)
!881 = !DISubprogram(name: "asin", scope: !877, file: !877, line: 55, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!882 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !883, line: 121)
!883 = !DISubprogram(name: "atan", scope: !877, file: !877, line: 57, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!884 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !885, line: 140)
!885 = !DISubprogram(name: "atan2", scope: !877, file: !877, line: 59, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!886 = !DISubroutineType(types: !887)
!887 = !{!108, !108, !108}
!888 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !889, line: 161)
!889 = !DISubprogram(name: "ceil", scope: !877, file: !877, line: 159, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!890 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !891, line: 180)
!891 = !DISubprogram(name: "cos", scope: !877, file: !877, line: 62, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!892 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !893, line: 199)
!893 = !DISubprogram(name: "cosh", scope: !877, file: !877, line: 71, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!894 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !895, line: 218)
!895 = !DISubprogram(name: "exp", scope: !877, file: !877, line: 95, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!896 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !897, line: 237)
!897 = !DISubprogram(name: "fabs", scope: !877, file: !877, line: 162, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!898 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !899, line: 256)
!899 = !DISubprogram(name: "floor", scope: !877, file: !877, line: 165, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!900 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !901, line: 275)
!901 = !DISubprogram(name: "fmod", scope: !877, file: !877, line: 168, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!902 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !903, line: 296)
!903 = !DISubprogram(name: "frexp", scope: !877, file: !877, line: 98, type: !904, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!904 = !DISubroutineType(types: !905)
!905 = !{!108, !108, !906}
!906 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !82, size: 64)
!907 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !908, line: 315)
!908 = !DISubprogram(name: "ldexp", scope: !877, file: !877, line: 101, type: !909, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!909 = !DISubroutineType(types: !910)
!910 = !{!108, !108, !82}
!911 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !912, line: 334)
!912 = !DISubprogram(name: "log", scope: !877, file: !877, line: 104, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!913 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !914, line: 353)
!914 = !DISubprogram(name: "log10", scope: !877, file: !877, line: 107, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!915 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !916, line: 372)
!916 = !DISubprogram(name: "modf", scope: !877, file: !877, line: 110, type: !917, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!917 = !DISubroutineType(types: !918)
!918 = !{!108, !108, !919}
!919 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !108, size: 64)
!920 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !921, line: 384)
!921 = !DISubprogram(name: "pow", scope: !877, file: !877, line: 140, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!922 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !923, line: 421)
!923 = !DISubprogram(name: "sin", scope: !877, file: !877, line: 64, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!924 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !925, line: 440)
!925 = !DISubprogram(name: "sinh", scope: !877, file: !877, line: 73, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!926 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !927, line: 459)
!927 = !DISubprogram(name: "sqrt", scope: !877, file: !877, line: 143, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!928 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !929, line: 478)
!929 = !DISubprogram(name: "tan", scope: !877, file: !877, line: 66, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!930 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !931, line: 497)
!931 = !DISubprogram(name: "tanh", scope: !877, file: !877, line: 75, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!932 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !933, line: 1080)
!933 = !DIDerivedType(tag: DW_TAG_typedef, name: "double_t", file: !934, line: 150, baseType: !108)
!934 = !DIFile(filename: "/usr/include/math.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!935 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !936, line: 1081)
!936 = !DIDerivedType(tag: DW_TAG_typedef, name: "float_t", file: !934, line: 149, baseType: !262)
!937 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !938, line: 1084)
!938 = !DISubprogram(name: "acosh", scope: !877, file: !877, line: 85, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!939 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !940, line: 1085)
!940 = !DISubprogram(name: "acoshf", scope: !877, file: !877, line: 85, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!941 = !DISubroutineType(types: !942)
!942 = !{!262, !262}
!943 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !944, line: 1086)
!944 = !DISubprogram(name: "acoshl", scope: !877, file: !877, line: 85, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!945 = !DISubroutineType(types: !946)
!946 = !{!267, !267}
!947 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !948, line: 1088)
!948 = !DISubprogram(name: "asinh", scope: !877, file: !877, line: 87, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!949 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !950, line: 1089)
!950 = !DISubprogram(name: "asinhf", scope: !877, file: !877, line: 87, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!951 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !952, line: 1090)
!952 = !DISubprogram(name: "asinhl", scope: !877, file: !877, line: 87, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!953 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !954, line: 1092)
!954 = !DISubprogram(name: "atanh", scope: !877, file: !877, line: 89, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!955 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !956, line: 1093)
!956 = !DISubprogram(name: "atanhf", scope: !877, file: !877, line: 89, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!957 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !958, line: 1094)
!958 = !DISubprogram(name: "atanhl", scope: !877, file: !877, line: 89, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!959 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !960, line: 1096)
!960 = !DISubprogram(name: "cbrt", scope: !877, file: !877, line: 152, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!961 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !962, line: 1097)
!962 = !DISubprogram(name: "cbrtf", scope: !877, file: !877, line: 152, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!963 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !964, line: 1098)
!964 = !DISubprogram(name: "cbrtl", scope: !877, file: !877, line: 152, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!965 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !966, line: 1100)
!966 = !DISubprogram(name: "copysign", scope: !877, file: !877, line: 196, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!967 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !968, line: 1101)
!968 = !DISubprogram(name: "copysignf", scope: !877, file: !877, line: 196, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!969 = !DISubroutineType(types: !970)
!970 = !{!262, !262, !262}
!971 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !972, line: 1102)
!972 = !DISubprogram(name: "copysignl", scope: !877, file: !877, line: 196, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!973 = !DISubroutineType(types: !974)
!974 = !{!267, !267, !267}
!975 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !976, line: 1104)
!976 = !DISubprogram(name: "erf", scope: !877, file: !877, line: 228, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!977 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !978, line: 1105)
!978 = !DISubprogram(name: "erff", scope: !877, file: !877, line: 228, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!979 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !980, line: 1106)
!980 = !DISubprogram(name: "erfl", scope: !877, file: !877, line: 228, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!981 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !982, line: 1108)
!982 = !DISubprogram(name: "erfc", scope: !877, file: !877, line: 229, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!983 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !984, line: 1109)
!984 = !DISubprogram(name: "erfcf", scope: !877, file: !877, line: 229, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!985 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !986, line: 1110)
!986 = !DISubprogram(name: "erfcl", scope: !877, file: !877, line: 229, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!987 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !988, line: 1112)
!988 = !DISubprogram(name: "exp2", scope: !877, file: !877, line: 130, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!989 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !990, line: 1113)
!990 = !DISubprogram(name: "exp2f", scope: !877, file: !877, line: 130, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!991 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !992, line: 1114)
!992 = !DISubprogram(name: "exp2l", scope: !877, file: !877, line: 130, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!993 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !994, line: 1116)
!994 = !DISubprogram(name: "expm1", scope: !877, file: !877, line: 119, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!995 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !996, line: 1117)
!996 = !DISubprogram(name: "expm1f", scope: !877, file: !877, line: 119, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!997 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !998, line: 1118)
!998 = !DISubprogram(name: "expm1l", scope: !877, file: !877, line: 119, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!999 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1000, line: 1120)
!1000 = !DISubprogram(name: "fdim", scope: !877, file: !877, line: 326, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1001 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1002, line: 1121)
!1002 = !DISubprogram(name: "fdimf", scope: !877, file: !877, line: 326, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1003 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1004, line: 1122)
!1004 = !DISubprogram(name: "fdiml", scope: !877, file: !877, line: 326, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1005 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1006, line: 1124)
!1006 = !DISubprogram(name: "fma", scope: !877, file: !877, line: 335, type: !1007, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1007 = !DISubroutineType(types: !1008)
!1008 = !{!108, !108, !108, !108}
!1009 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1010, line: 1125)
!1010 = !DISubprogram(name: "fmaf", scope: !877, file: !877, line: 335, type: !1011, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1011 = !DISubroutineType(types: !1012)
!1012 = !{!262, !262, !262, !262}
!1013 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1014, line: 1126)
!1014 = !DISubprogram(name: "fmal", scope: !877, file: !877, line: 335, type: !1015, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1015 = !DISubroutineType(types: !1016)
!1016 = !{!267, !267, !267, !267}
!1017 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1018, line: 1128)
!1018 = !DISubprogram(name: "fmax", scope: !877, file: !877, line: 329, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1019 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1020, line: 1129)
!1020 = !DISubprogram(name: "fmaxf", scope: !877, file: !877, line: 329, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1021 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1022, line: 1130)
!1022 = !DISubprogram(name: "fmaxl", scope: !877, file: !877, line: 329, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1023 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1024, line: 1132)
!1024 = !DISubprogram(name: "fmin", scope: !877, file: !877, line: 332, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1025 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1026, line: 1133)
!1026 = !DISubprogram(name: "fminf", scope: !877, file: !877, line: 332, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1027 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1028, line: 1134)
!1028 = !DISubprogram(name: "fminl", scope: !877, file: !877, line: 332, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1029 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1030, line: 1136)
!1030 = !DISubprogram(name: "hypot", scope: !877, file: !877, line: 147, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1031 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1032, line: 1137)
!1032 = !DISubprogram(name: "hypotf", scope: !877, file: !877, line: 147, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1033 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1034, line: 1138)
!1034 = !DISubprogram(name: "hypotl", scope: !877, file: !877, line: 147, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1035 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1036, line: 1140)
!1036 = !DISubprogram(name: "ilogb", scope: !877, file: !877, line: 280, type: !1037, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1037 = !DISubroutineType(types: !1038)
!1038 = !{!82, !108}
!1039 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1040, line: 1141)
!1040 = !DISubprogram(name: "ilogbf", scope: !877, file: !877, line: 280, type: !1041, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1041 = !DISubroutineType(types: !1042)
!1042 = !{!82, !262}
!1043 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1044, line: 1142)
!1044 = !DISubprogram(name: "ilogbl", scope: !877, file: !877, line: 280, type: !1045, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1045 = !DISubroutineType(types: !1046)
!1046 = !{!82, !267}
!1047 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1048, line: 1144)
!1048 = !DISubprogram(name: "lgamma", scope: !877, file: !877, line: 230, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1049 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1050, line: 1145)
!1050 = !DISubprogram(name: "lgammaf", scope: !877, file: !877, line: 230, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1051 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1052, line: 1146)
!1052 = !DISubprogram(name: "lgammal", scope: !877, file: !877, line: 230, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1053 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1054, line: 1149)
!1054 = !DISubprogram(name: "llrint", scope: !877, file: !877, line: 316, type: !1055, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1055 = !DISubroutineType(types: !1056)
!1056 = !{!233, !108}
!1057 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1058, line: 1150)
!1058 = !DISubprogram(name: "llrintf", scope: !877, file: !877, line: 316, type: !1059, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1059 = !DISubroutineType(types: !1060)
!1060 = !{!233, !262}
!1061 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1062, line: 1151)
!1062 = !DISubprogram(name: "llrintl", scope: !877, file: !877, line: 316, type: !1063, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1063 = !DISubroutineType(types: !1064)
!1064 = !{!233, !267}
!1065 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1066, line: 1153)
!1066 = !DISubprogram(name: "llround", scope: !877, file: !877, line: 322, type: !1055, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1067 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1068, line: 1154)
!1068 = !DISubprogram(name: "llroundf", scope: !877, file: !877, line: 322, type: !1059, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1069 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1070, line: 1155)
!1070 = !DISubprogram(name: "llroundl", scope: !877, file: !877, line: 322, type: !1063, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1071 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1072, line: 1158)
!1072 = !DISubprogram(name: "log1p", scope: !877, file: !877, line: 122, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1073 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1074, line: 1159)
!1074 = !DISubprogram(name: "log1pf", scope: !877, file: !877, line: 122, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1075 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1076, line: 1160)
!1076 = !DISubprogram(name: "log1pl", scope: !877, file: !877, line: 122, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1077 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1078, line: 1162)
!1078 = !DISubprogram(name: "log2", scope: !877, file: !877, line: 133, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1079 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1080, line: 1163)
!1080 = !DISubprogram(name: "log2f", scope: !877, file: !877, line: 133, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1081 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1082, line: 1164)
!1082 = !DISubprogram(name: "log2l", scope: !877, file: !877, line: 133, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1083 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1084, line: 1166)
!1084 = !DISubprogram(name: "logb", scope: !877, file: !877, line: 125, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1085 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1086, line: 1167)
!1086 = !DISubprogram(name: "logbf", scope: !877, file: !877, line: 125, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1087 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1088, line: 1168)
!1088 = !DISubprogram(name: "logbl", scope: !877, file: !877, line: 125, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1089 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1090, line: 1170)
!1090 = !DISubprogram(name: "lrint", scope: !877, file: !877, line: 314, type: !1091, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1091 = !DISubroutineType(types: !1092)
!1092 = !{!91, !108}
!1093 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1094, line: 1171)
!1094 = !DISubprogram(name: "lrintf", scope: !877, file: !877, line: 314, type: !1095, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1095 = !DISubroutineType(types: !1096)
!1096 = !{!91, !262}
!1097 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1098, line: 1172)
!1098 = !DISubprogram(name: "lrintl", scope: !877, file: !877, line: 314, type: !1099, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1099 = !DISubroutineType(types: !1100)
!1100 = !{!91, !267}
!1101 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1102, line: 1174)
!1102 = !DISubprogram(name: "lround", scope: !877, file: !877, line: 320, type: !1091, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1103 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1104, line: 1175)
!1104 = !DISubprogram(name: "lroundf", scope: !877, file: !877, line: 320, type: !1095, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1105 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1106, line: 1176)
!1106 = !DISubprogram(name: "lroundl", scope: !877, file: !877, line: 320, type: !1099, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1107 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1108, line: 1178)
!1108 = !DISubprogram(name: "nan", scope: !877, file: !877, line: 201, type: !106, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1109 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1110, line: 1179)
!1110 = !DISubprogram(name: "nanf", scope: !877, file: !877, line: 201, type: !1111, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1111 = !DISubroutineType(types: !1112)
!1112 = !{!262, !109}
!1113 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1114, line: 1180)
!1114 = !DISubprogram(name: "nanl", scope: !877, file: !877, line: 201, type: !1115, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1115 = !DISubroutineType(types: !1116)
!1116 = !{!267, !109}
!1117 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1118, line: 1182)
!1118 = !DISubprogram(name: "nearbyint", scope: !877, file: !877, line: 294, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1119 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1120, line: 1183)
!1120 = !DISubprogram(name: "nearbyintf", scope: !877, file: !877, line: 294, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1121 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1122, line: 1184)
!1122 = !DISubprogram(name: "nearbyintl", scope: !877, file: !877, line: 294, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1123 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1124, line: 1186)
!1124 = !DISubprogram(name: "nextafter", scope: !877, file: !877, line: 259, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1125 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1126, line: 1187)
!1126 = !DISubprogram(name: "nextafterf", scope: !877, file: !877, line: 259, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1127 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1128, line: 1188)
!1128 = !DISubprogram(name: "nextafterl", scope: !877, file: !877, line: 259, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1129 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1130, line: 1190)
!1130 = !DISubprogram(name: "nexttoward", scope: !877, file: !877, line: 261, type: !1131, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1131 = !DISubroutineType(types: !1132)
!1132 = !{!108, !108, !267}
!1133 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1134, line: 1191)
!1134 = !DISubprogram(name: "nexttowardf", scope: !877, file: !877, line: 261, type: !1135, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1135 = !DISubroutineType(types: !1136)
!1136 = !{!262, !262, !267}
!1137 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1138, line: 1192)
!1138 = !DISubprogram(name: "nexttowardl", scope: !877, file: !877, line: 261, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1139 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1140, line: 1194)
!1140 = !DISubprogram(name: "remainder", scope: !877, file: !877, line: 272, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1141 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1142, line: 1195)
!1142 = !DISubprogram(name: "remainderf", scope: !877, file: !877, line: 272, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1143 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1144, line: 1196)
!1144 = !DISubprogram(name: "remainderl", scope: !877, file: !877, line: 272, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1145 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1146, line: 1198)
!1146 = !DISubprogram(name: "remquo", scope: !877, file: !877, line: 307, type: !1147, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1147 = !DISubroutineType(types: !1148)
!1148 = !{!108, !108, !108, !906}
!1149 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1150, line: 1199)
!1150 = !DISubprogram(name: "remquof", scope: !877, file: !877, line: 307, type: !1151, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1151 = !DISubroutineType(types: !1152)
!1152 = !{!262, !262, !262, !906}
!1153 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1154, line: 1200)
!1154 = !DISubprogram(name: "remquol", scope: !877, file: !877, line: 307, type: !1155, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1155 = !DISubroutineType(types: !1156)
!1156 = !{!267, !267, !267, !906}
!1157 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1158, line: 1202)
!1158 = !DISubprogram(name: "rint", scope: !877, file: !877, line: 256, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1159 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1160, line: 1203)
!1160 = !DISubprogram(name: "rintf", scope: !877, file: !877, line: 256, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1161 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1162, line: 1204)
!1162 = !DISubprogram(name: "rintl", scope: !877, file: !877, line: 256, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1163 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1164, line: 1206)
!1164 = !DISubprogram(name: "round", scope: !877, file: !877, line: 298, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1165 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1166, line: 1207)
!1166 = !DISubprogram(name: "roundf", scope: !877, file: !877, line: 298, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1167 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1168, line: 1208)
!1168 = !DISubprogram(name: "roundl", scope: !877, file: !877, line: 298, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1169 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1170, line: 1210)
!1170 = !DISubprogram(name: "scalbln", scope: !877, file: !877, line: 290, type: !1171, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1171 = !DISubroutineType(types: !1172)
!1172 = !{!108, !108, !91}
!1173 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1174, line: 1211)
!1174 = !DISubprogram(name: "scalblnf", scope: !877, file: !877, line: 290, type: !1175, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1175 = !DISubroutineType(types: !1176)
!1176 = !{!262, !262, !91}
!1177 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1178, line: 1212)
!1178 = !DISubprogram(name: "scalblnl", scope: !877, file: !877, line: 290, type: !1179, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1179 = !DISubroutineType(types: !1180)
!1180 = !{!267, !267, !91}
!1181 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1182, line: 1214)
!1182 = !DISubprogram(name: "scalbn", scope: !877, file: !877, line: 276, type: !909, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1183 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1184, line: 1215)
!1184 = !DISubprogram(name: "scalbnf", scope: !877, file: !877, line: 276, type: !1185, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1185 = !DISubroutineType(types: !1186)
!1186 = !{!262, !262, !82}
!1187 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1188, line: 1216)
!1188 = !DISubprogram(name: "scalbnl", scope: !877, file: !877, line: 276, type: !1189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1189 = !DISubroutineType(types: !1190)
!1190 = !{!267, !267, !82}
!1191 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1192, line: 1218)
!1192 = !DISubprogram(name: "tgamma", scope: !877, file: !877, line: 235, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1193 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1194, line: 1219)
!1194 = !DISubprogram(name: "tgammaf", scope: !877, file: !877, line: 235, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1195 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1196, line: 1220)
!1196 = !DISubprogram(name: "tgammal", scope: !877, file: !877, line: 235, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1197 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1198, line: 1222)
!1198 = !DISubprogram(name: "trunc", scope: !877, file: !877, line: 302, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1199 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1200, line: 1223)
!1200 = !DISubprogram(name: "truncf", scope: !877, file: !877, line: 302, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1201 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1202, line: 1224)
!1202 = !DISubprogram(name: "truncl", scope: !877, file: !877, line: 302, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1203 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1204, line: 58)
!1204 = !DIDerivedType(tag: DW_TAG_typedef, name: "fenv_t", file: !1205, line: 94, baseType: !1206)
!1205 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/fenv.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1206 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !1205, line: 75, flags: DIFlagFwdDecl, identifier: "_ZTS6fenv_t")
!1207 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1208, line: 59)
!1208 = !DIDerivedType(tag: DW_TAG_typedef, name: "fexcept_t", file: !1205, line: 68, baseType: !29)
!1209 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1210, line: 62)
!1210 = !DISubprogram(name: "feclearexcept", scope: !1211, file: !1211, line: 71, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1211 = !DIFile(filename: "/usr/include/fenv.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1212 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1213, line: 63)
!1213 = !DISubprogram(name: "fegetexceptflag", scope: !1211, file: !1211, line: 75, type: !1214, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1214 = !DISubroutineType(types: !1215)
!1215 = !{!82, !1216, !82}
!1216 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1208, size: 64)
!1217 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1218, line: 64)
!1218 = !DISubprogram(name: "feraiseexcept", scope: !1211, file: !1211, line: 78, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1219 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1220, line: 65)
!1220 = !DISubprogram(name: "fesetexceptflag", scope: !1211, file: !1211, line: 88, type: !1221, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1221 = !DISubroutineType(types: !1222)
!1222 = !{!82, !1223, !82}
!1223 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1224, size: 64)
!1224 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !1208)
!1225 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1226, line: 66)
!1226 = !DISubprogram(name: "fetestexcept", scope: !1211, file: !1211, line: 92, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1227 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1228, line: 68)
!1228 = !DISubprogram(name: "fegetround", scope: !1211, file: !1211, line: 104, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1229 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1230, line: 69)
!1230 = !DISubprogram(name: "fesetround", scope: !1211, file: !1211, line: 107, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1231 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1232, line: 71)
!1232 = !DISubprogram(name: "fegetenv", scope: !1211, file: !1211, line: 114, type: !1233, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1233 = !DISubroutineType(types: !1234)
!1234 = !{!82, !1235}
!1235 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1204, size: 64)
!1236 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1237, line: 72)
!1237 = !DISubprogram(name: "feholdexcept", scope: !1211, file: !1211, line: 119, type: !1233, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1238 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1239, line: 73)
!1239 = !DISubprogram(name: "fesetenv", scope: !1211, file: !1211, line: 123, type: !1240, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1240 = !DISubroutineType(types: !1241)
!1241 = !{!82, !1242}
!1242 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1243, size: 64)
!1243 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !1204)
!1244 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1245, line: 74)
!1245 = !DISubprogram(name: "feupdateenv", scope: !1211, file: !1211, line: 128, type: !1240, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1246 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1204, line: 61)
!1247 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1208, line: 62)
!1248 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1210, line: 65)
!1249 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1213, line: 66)
!1250 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1218, line: 67)
!1251 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1220, line: 68)
!1252 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1226, line: 69)
!1253 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1228, line: 71)
!1254 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1230, line: 72)
!1255 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1232, line: 74)
!1256 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1237, line: 75)
!1257 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1239, line: 76)
!1258 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1245, line: 77)
!1259 = !{i32 2, !"Dwarf Version", i32 4}
!1260 = !{i32 2, !"Debug Info Version", i32 3}
!1261 = distinct !DISubprogram(name: "__remill_basic_block", scope: !2, file: !2, line: 52, type: !1262, isLocal: false, isDefinition: true, scopeLine: 52, flags: DIFlagPrototyped, isOptimized: false, unit: !1, variables: !7)
!1262 = !DISubroutineType(types: !1263)
!1263 = !{!1264, !1267, !1950, !1264}
!1264 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1265, size: 64)
!1265 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Memory", file: !1266, line: 36, flags: DIFlagFwdDecl, identifier: "_ZTS6Memory")
!1266 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/Types.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1267 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !1268, size: 64)
!1268 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "State", file: !27, line: 742, size: 27008, align: 128, elements: !1269, identifier: "_ZTS5State")
!1269 = !{!1270, !1282, !1491, !1511, !1541, !1566, !1595, !1632, !1642, !1703, !1728, !1752, !1932}
!1270 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1268, baseType: !1271)
!1271 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "ArchState", file: !1272, line: 21, size: 128, elements: !1273, identifier: "_ZTS9ArchState")
!1272 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/State.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1273 = !{!1274, !1275, !1276}
!1274 = !DIDerivedType(tag: DW_TAG_member, name: "hyper_call", scope: !1271, file: !1272, line: 23, baseType: !4, size: 32)
!1275 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1271, file: !1272, line: 25, baseType: !8, size: 32, offset: 32)
!1276 = !DIDerivedType(tag: DW_TAG_member, scope: !1271, file: !1272, line: 31, baseType: !1277, size: 64, offset: 64)
!1277 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1271, file: !1272, line: 31, size: 64, elements: !1278, identifier: "_ZTSN9ArchStateUt_E")
!1278 = !{!1279, !1280, !1281}
!1279 = !DIDerivedType(tag: DW_TAG_member, name: "addr_to_load", scope: !1277, file: !1272, line: 32, baseType: !637, size: 64)
!1280 = !DIDerivedType(tag: DW_TAG_member, name: "addr_to_store", scope: !1277, file: !1272, line: 33, baseType: !637, size: 64)
!1281 = !DIDerivedType(tag: DW_TAG_member, name: "hyper_call_vector", scope: !1277, file: !1272, line: 34, baseType: !8, size: 32)
!1282 = !DIDerivedType(tag: DW_TAG_member, name: "vec", scope: !1268, file: !27, line: 747, baseType: !1283, size: 16384, offset: 128)
!1283 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1284, size: 16384, elements: !1369)
!1284 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "VectorReg", file: !27, line: 636, size: 512, align: 128, elements: !1285, identifier: "_ZTS9VectorReg")
!1285 = !{!1286, !1361, !1426}
!1286 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1284, file: !27, line: 637, baseType: !1287, size: 128, align: 128)
!1287 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec128_t", file: !1266, line: 317, size: 128, elements: !1288, identifier: "_ZTS8vec128_t")
!1288 = !{!1289, !1298, !1305, !1312, !1317, !1324, !1329, !1334, !1339, !1344, !1349, !1354}
!1289 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1287, file: !1266, line: 321, baseType: !1290, size: 128)
!1290 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v1_t", file: !1266, line: 205, size: 128, elements: !1291, identifier: "_ZTS11uint128v1_t")
!1291 = !{!1292}
!1292 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1290, file: !1266, line: 205, baseType: !1293, size: 128)
!1293 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 128, elements: !1296)
!1294 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint128_t", file: !1266, line: 46, baseType: !1295)
!1295 = !DIBasicType(name: "unsigned __int128", size: 128, encoding: DW_ATE_unsigned)
!1296 = !{!1297}
!1297 = !DISubrange(count: 1)
!1298 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1287, file: !1266, line: 323, baseType: !1299, size: 128)
!1299 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v16_t", file: !1266, line: 182, size: 128, elements: !1300, identifier: "_ZTS10uint8v16_t")
!1300 = !{!1301}
!1301 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1299, file: !1266, line: 182, baseType: !1302, size: 128)
!1302 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 128, elements: !1303)
!1303 = !{!1304}
!1304 = !DISubrange(count: 16)
!1305 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1287, file: !1266, line: 324, baseType: !1306, size: 128)
!1306 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v8_t", file: !1266, line: 189, size: 128, elements: !1307, identifier: "_ZTS10uint16v8_t")
!1307 = !{!1308}
!1308 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1306, file: !1266, line: 189, baseType: !1309, size: 128)
!1309 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 128, elements: !1310)
!1310 = !{!1311}
!1311 = !DISubrange(count: 8)
!1312 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1287, file: !1266, line: 325, baseType: !1313, size: 128)
!1313 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v4_t", file: !1266, line: 195, size: 128, elements: !1314, identifier: "_ZTS10uint32v4_t")
!1314 = !{!1315}
!1315 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1313, file: !1266, line: 195, baseType: !1316, size: 128)
!1316 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 128, elements: !353)
!1317 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1287, file: !1266, line: 326, baseType: !1318, size: 128)
!1318 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v2_t", file: !1266, line: 200, size: 128, elements: !1319, identifier: "_ZTS10uint64v2_t")
!1319 = !{!1320}
!1320 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1318, file: !1266, line: 200, baseType: !1321, size: 128)
!1321 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 128, elements: !1322)
!1322 = !{!1323}
!1323 = !DISubrange(count: 2)
!1324 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1287, file: !1266, line: 327, baseType: !1325, size: 128)
!1325 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v4_t", file: !1266, line: 242, size: 128, elements: !1326, identifier: "_ZTS11float32v4_t")
!1326 = !{!1327}
!1327 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1325, file: !1266, line: 242, baseType: !1328, size: 128)
!1328 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 128, elements: !353)
!1329 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1287, file: !1266, line: 328, baseType: !1330, size: 128)
!1330 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v2_t", file: !1266, line: 247, size: 128, elements: !1331, identifier: "_ZTS11float64v2_t")
!1331 = !{!1332}
!1332 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1330, file: !1266, line: 247, baseType: !1333, size: 128)
!1333 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 128, elements: !1322)
!1334 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1287, file: !1266, line: 330, baseType: !1335, size: 128)
!1335 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v16_t", file: !1266, line: 213, size: 128, elements: !1336, identifier: "_ZTS9int8v16_t")
!1336 = !{!1337}
!1337 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1335, file: !1266, line: 213, baseType: !1338, size: 128)
!1338 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 128, elements: !1303)
!1339 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1287, file: !1266, line: 331, baseType: !1340, size: 128)
!1340 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v8_t", file: !1266, line: 220, size: 128, elements: !1341, identifier: "_ZTS9int16v8_t")
!1341 = !{!1342}
!1342 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1340, file: !1266, line: 220, baseType: !1343, size: 128)
!1343 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 128, elements: !1310)
!1344 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1287, file: !1266, line: 332, baseType: !1345, size: 128)
!1345 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v4_t", file: !1266, line: 226, size: 128, elements: !1346, identifier: "_ZTS9int32v4_t")
!1346 = !{!1347}
!1347 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1345, file: !1266, line: 226, baseType: !1348, size: 128)
!1348 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 128, elements: !353)
!1349 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1287, file: !1266, line: 333, baseType: !1350, size: 128)
!1350 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v2_t", file: !1266, line: 231, size: 128, elements: !1351, identifier: "_ZTS9int64v2_t")
!1351 = !{!1352}
!1352 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1350, file: !1266, line: 231, baseType: !1353, size: 128)
!1353 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 128, elements: !1322)
!1354 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1287, file: !1266, line: 334, baseType: !1355, size: 128)
!1355 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v1_t", file: !1266, line: 236, size: 128, elements: !1356, identifier: "_ZTS10int128v1_t")
!1356 = !{!1357}
!1357 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1355, file: !1266, line: 236, baseType: !1358, size: 128)
!1358 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 128, elements: !1296)
!1359 = !DIDerivedType(tag: DW_TAG_typedef, name: "int128_t", file: !1266, line: 47, baseType: !1360)
!1360 = !DIBasicType(name: "__int128", size: 128, encoding: DW_ATE_signed)
!1361 = !DIDerivedType(tag: DW_TAG_member, name: "ymm", scope: !1284, file: !27, line: 638, baseType: !1362, size: 256, align: 128)
!1362 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec256_t", file: !1266, line: 340, size: 256, elements: !1363, identifier: "_ZTS8vec256_t")
!1363 = !{!1364, !1371, !1376, !1381, !1386, !1391, !1396, !1401, !1406, !1411, !1416, !1421}
!1364 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1362, file: !1266, line: 341, baseType: !1365, size: 256)
!1365 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v32_t", file: !1266, line: 183, size: 256, elements: !1366, identifier: "_ZTS10uint8v32_t")
!1366 = !{!1367}
!1367 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1365, file: !1266, line: 183, baseType: !1368, size: 256)
!1368 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 256, elements: !1369)
!1369 = !{!1370}
!1370 = !DISubrange(count: 32)
!1371 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1362, file: !1266, line: 342, baseType: !1372, size: 256)
!1372 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v16_t", file: !1266, line: 190, size: 256, elements: !1373, identifier: "_ZTS11uint16v16_t")
!1373 = !{!1374}
!1374 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1372, file: !1266, line: 190, baseType: !1375, size: 256)
!1375 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 256, elements: !1303)
!1376 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1362, file: !1266, line: 343, baseType: !1377, size: 256)
!1377 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v8_t", file: !1266, line: 196, size: 256, elements: !1378, identifier: "_ZTS10uint32v8_t")
!1378 = !{!1379}
!1379 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1377, file: !1266, line: 196, baseType: !1380, size: 256)
!1380 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 256, elements: !1310)
!1381 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1362, file: !1266, line: 344, baseType: !1382, size: 256)
!1382 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v4_t", file: !1266, line: 201, size: 256, elements: !1383, identifier: "_ZTS10uint64v4_t")
!1383 = !{!1384}
!1384 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1382, file: !1266, line: 201, baseType: !1385, size: 256)
!1385 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 256, elements: !353)
!1386 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1362, file: !1266, line: 345, baseType: !1387, size: 256)
!1387 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v2_t", file: !1266, line: 206, size: 256, elements: !1388, identifier: "_ZTS11uint128v2_t")
!1388 = !{!1389}
!1389 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1387, file: !1266, line: 206, baseType: !1390, size: 256)
!1390 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 256, elements: !1322)
!1391 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1362, file: !1266, line: 346, baseType: !1392, size: 256)
!1392 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v8_t", file: !1266, line: 243, size: 256, elements: !1393, identifier: "_ZTS11float32v8_t")
!1393 = !{!1394}
!1394 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1392, file: !1266, line: 243, baseType: !1395, size: 256)
!1395 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 256, elements: !1310)
!1396 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1362, file: !1266, line: 347, baseType: !1397, size: 256)
!1397 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v4_t", file: !1266, line: 248, size: 256, elements: !1398, identifier: "_ZTS11float64v4_t")
!1398 = !{!1399}
!1399 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1397, file: !1266, line: 248, baseType: !1400, size: 256)
!1400 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 256, elements: !353)
!1401 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1362, file: !1266, line: 349, baseType: !1402, size: 256)
!1402 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v32_t", file: !1266, line: 214, size: 256, elements: !1403, identifier: "_ZTS9int8v32_t")
!1403 = !{!1404}
!1404 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1402, file: !1266, line: 214, baseType: !1405, size: 256)
!1405 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 256, elements: !1369)
!1406 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1362, file: !1266, line: 350, baseType: !1407, size: 256)
!1407 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v16_t", file: !1266, line: 221, size: 256, elements: !1408, identifier: "_ZTS10int16v16_t")
!1408 = !{!1409}
!1409 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1407, file: !1266, line: 221, baseType: !1410, size: 256)
!1410 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 256, elements: !1303)
!1411 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1362, file: !1266, line: 351, baseType: !1412, size: 256)
!1412 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v8_t", file: !1266, line: 227, size: 256, elements: !1413, identifier: "_ZTS9int32v8_t")
!1413 = !{!1414}
!1414 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1412, file: !1266, line: 227, baseType: !1415, size: 256)
!1415 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 256, elements: !1310)
!1416 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1362, file: !1266, line: 352, baseType: !1417, size: 256)
!1417 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v4_t", file: !1266, line: 232, size: 256, elements: !1418, identifier: "_ZTS9int64v4_t")
!1418 = !{!1419}
!1419 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1417, file: !1266, line: 232, baseType: !1420, size: 256)
!1420 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 256, elements: !353)
!1421 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1362, file: !1266, line: 353, baseType: !1422, size: 256)
!1422 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v2_t", file: !1266, line: 237, size: 256, elements: !1423, identifier: "_ZTS10int128v2_t")
!1423 = !{!1424}
!1424 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1422, file: !1266, line: 237, baseType: !1425, size: 256)
!1425 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 256, elements: !1322)
!1426 = !DIDerivedType(tag: DW_TAG_member, name: "zmm", scope: !1284, file: !27, line: 639, baseType: !1427, size: 512, align: 128)
!1427 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec512_t", file: !1266, line: 359, size: 512, elements: !1428, identifier: "_ZTS8vec512_t")
!1428 = !{!1429, !1436, !1441, !1446, !1451, !1456, !1461, !1466, !1471, !1476, !1481, !1486}
!1429 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1427, file: !1266, line: 360, baseType: !1430, size: 512)
!1430 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v64_t", file: !1266, line: 184, size: 512, elements: !1431, identifier: "_ZTS10uint8v64_t")
!1431 = !{!1432}
!1432 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1430, file: !1266, line: 184, baseType: !1433, size: 512)
!1433 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 512, elements: !1434)
!1434 = !{!1435}
!1435 = !DISubrange(count: 64)
!1436 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1427, file: !1266, line: 361, baseType: !1437, size: 512)
!1437 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v32_t", file: !1266, line: 191, size: 512, elements: !1438, identifier: "_ZTS11uint16v32_t")
!1438 = !{!1439}
!1439 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1437, file: !1266, line: 191, baseType: !1440, size: 512)
!1440 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 512, elements: !1369)
!1441 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1427, file: !1266, line: 362, baseType: !1442, size: 512)
!1442 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v16_t", file: !1266, line: 197, size: 512, elements: !1443, identifier: "_ZTS11uint32v16_t")
!1443 = !{!1444}
!1444 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1442, file: !1266, line: 197, baseType: !1445, size: 512)
!1445 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 512, elements: !1303)
!1446 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1427, file: !1266, line: 363, baseType: !1447, size: 512)
!1447 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v8_t", file: !1266, line: 202, size: 512, elements: !1448, identifier: "_ZTS10uint64v8_t")
!1448 = !{!1449}
!1449 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1447, file: !1266, line: 202, baseType: !1450, size: 512)
!1450 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 512, elements: !1310)
!1451 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1427, file: !1266, line: 364, baseType: !1452, size: 512)
!1452 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v4_t", file: !1266, line: 207, size: 512, elements: !1453, identifier: "_ZTS11uint128v4_t")
!1453 = !{!1454}
!1454 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1452, file: !1266, line: 207, baseType: !1455, size: 512)
!1455 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 512, elements: !353)
!1456 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1427, file: !1266, line: 365, baseType: !1457, size: 512)
!1457 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v16_t", file: !1266, line: 244, size: 512, elements: !1458, identifier: "_ZTS12float32v16_t")
!1458 = !{!1459}
!1459 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1457, file: !1266, line: 244, baseType: !1460, size: 512)
!1460 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 512, elements: !1303)
!1461 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1427, file: !1266, line: 366, baseType: !1462, size: 512)
!1462 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v8_t", file: !1266, line: 249, size: 512, elements: !1463, identifier: "_ZTS11float64v8_t")
!1463 = !{!1464}
!1464 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1462, file: !1266, line: 249, baseType: !1465, size: 512)
!1465 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 512, elements: !1310)
!1466 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1427, file: !1266, line: 368, baseType: !1467, size: 512)
!1467 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v64_t", file: !1266, line: 215, size: 512, elements: !1468, identifier: "_ZTS9int8v64_t")
!1468 = !{!1469}
!1469 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1467, file: !1266, line: 215, baseType: !1470, size: 512)
!1470 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 512, elements: !1434)
!1471 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1427, file: !1266, line: 369, baseType: !1472, size: 512)
!1472 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v32_t", file: !1266, line: 222, size: 512, elements: !1473, identifier: "_ZTS10int16v32_t")
!1473 = !{!1474}
!1474 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1472, file: !1266, line: 222, baseType: !1475, size: 512)
!1475 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 512, elements: !1369)
!1476 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1427, file: !1266, line: 370, baseType: !1477, size: 512)
!1477 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v16_t", file: !1266, line: 228, size: 512, elements: !1478, identifier: "_ZTS10int32v16_t")
!1478 = !{!1479}
!1479 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1477, file: !1266, line: 228, baseType: !1480, size: 512)
!1480 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 512, elements: !1303)
!1481 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1427, file: !1266, line: 371, baseType: !1482, size: 512)
!1482 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v8_t", file: !1266, line: 233, size: 512, elements: !1483, identifier: "_ZTS9int64v8_t")
!1483 = !{!1484}
!1484 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1482, file: !1266, line: 233, baseType: !1485, size: 512)
!1485 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 512, elements: !1310)
!1486 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1427, file: !1266, line: 372, baseType: !1487, size: 512)
!1487 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v4_t", file: !1266, line: 238, size: 512, elements: !1488, identifier: "_ZTS10int128v4_t")
!1488 = !{!1489}
!1489 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1487, file: !1266, line: 238, baseType: !1490, size: 512)
!1490 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 512, elements: !353)
!1491 = !DIDerivedType(tag: DW_TAG_member, name: "aflag", scope: !1268, file: !27, line: 751, baseType: !1492, size: 128, align: 64, offset: 16512)
!1492 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "ArithFlags", file: !27, line: 402, size: 128, align: 64, elements: !1493, identifier: "_ZTS10ArithFlags")
!1493 = !{!1494, !1496, !1497, !1498, !1499, !1500, !1501, !1502, !1503, !1504, !1505, !1506, !1507, !1508, !1509, !1510}
!1494 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1492, file: !27, line: 404, baseType: !1495, size: 8)
!1495 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !62)
!1496 = !DIDerivedType(tag: DW_TAG_member, name: "cf", scope: !1492, file: !27, line: 405, baseType: !62, size: 8, offset: 8)
!1497 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1492, file: !27, line: 406, baseType: !1495, size: 8, offset: 16)
!1498 = !DIDerivedType(tag: DW_TAG_member, name: "pf", scope: !1492, file: !27, line: 407, baseType: !62, size: 8, offset: 24)
!1499 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1492, file: !27, line: 408, baseType: !1495, size: 8, offset: 32)
!1500 = !DIDerivedType(tag: DW_TAG_member, name: "af", scope: !1492, file: !27, line: 409, baseType: !62, size: 8, offset: 40)
!1501 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1492, file: !27, line: 410, baseType: !1495, size: 8, offset: 48)
!1502 = !DIDerivedType(tag: DW_TAG_member, name: "zf", scope: !1492, file: !27, line: 411, baseType: !62, size: 8, offset: 56)
!1503 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1492, file: !27, line: 412, baseType: !1495, size: 8, offset: 64)
!1504 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1492, file: !27, line: 413, baseType: !62, size: 8, offset: 72)
!1505 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1492, file: !27, line: 414, baseType: !1495, size: 8, offset: 80)
!1506 = !DIDerivedType(tag: DW_TAG_member, name: "df", scope: !1492, file: !27, line: 415, baseType: !62, size: 8, offset: 88)
!1507 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1492, file: !27, line: 416, baseType: !1495, size: 8, offset: 96)
!1508 = !DIDerivedType(tag: DW_TAG_member, name: "of", scope: !1492, file: !27, line: 417, baseType: !62, size: 8, offset: 104)
!1509 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1492, file: !27, line: 418, baseType: !1495, size: 8, offset: 112)
!1510 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1492, file: !27, line: 419, baseType: !1495, size: 8, offset: 120)
!1511 = !DIDerivedType(tag: DW_TAG_member, name: "rflag", scope: !1268, file: !27, line: 752, baseType: !1512, size: 64, align: 64, offset: 16640)
!1512 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "Flags", file: !27, line: 366, size: 64, align: 64, elements: !1513, identifier: "_ZTS5Flags")
!1513 = !{!1514, !1515}
!1514 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1512, file: !27, line: 367, baseType: !637, size: 64)
!1515 = !DIDerivedType(tag: DW_TAG_member, scope: !1512, file: !27, line: 368, baseType: !1516, size: 64)
!1516 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1512, file: !27, line: 368, size: 64, elements: !1517, identifier: "_ZTSN5FlagsUt_E")
!1517 = !{!1518, !1519, !1520, !1521, !1522, !1523, !1524, !1525, !1526, !1527, !1528, !1529, !1530, !1531, !1532, !1533, !1534, !1535, !1536, !1537, !1538, !1539, !1540}
!1518 = !DIDerivedType(tag: DW_TAG_member, name: "cf", scope: !1516, file: !27, line: 369, baseType: !8, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1519 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_1", scope: !1516, file: !27, line: 370, baseType: !8, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1520 = !DIDerivedType(tag: DW_TAG_member, name: "pf", scope: !1516, file: !27, line: 371, baseType: !8, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1521 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0a", scope: !1516, file: !27, line: 372, baseType: !8, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1522 = !DIDerivedType(tag: DW_TAG_member, name: "af", scope: !1516, file: !27, line: 374, baseType: !8, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1523 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0b", scope: !1516, file: !27, line: 375, baseType: !8, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1524 = !DIDerivedType(tag: DW_TAG_member, name: "zf", scope: !1516, file: !27, line: 376, baseType: !8, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1525 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1516, file: !27, line: 377, baseType: !8, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1526 = !DIDerivedType(tag: DW_TAG_member, name: "tf", scope: !1516, file: !27, line: 379, baseType: !8, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1527 = !DIDerivedType(tag: DW_TAG_member, name: "_if", scope: !1516, file: !27, line: 380, baseType: !8, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1528 = !DIDerivedType(tag: DW_TAG_member, name: "df", scope: !1516, file: !27, line: 381, baseType: !8, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1529 = !DIDerivedType(tag: DW_TAG_member, name: "of", scope: !1516, file: !27, line: 382, baseType: !8, size: 1, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1530 = !DIDerivedType(tag: DW_TAG_member, name: "iopl", scope: !1516, file: !27, line: 384, baseType: !8, size: 2, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1531 = !DIDerivedType(tag: DW_TAG_member, name: "nt", scope: !1516, file: !27, line: 385, baseType: !8, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1532 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0c", scope: !1516, file: !27, line: 386, baseType: !8, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1533 = !DIDerivedType(tag: DW_TAG_member, name: "rf", scope: !1516, file: !27, line: 388, baseType: !8, size: 1, offset: 16, flags: DIFlagBitField, extraData: i64 0)
!1534 = !DIDerivedType(tag: DW_TAG_member, name: "vm", scope: !1516, file: !27, line: 389, baseType: !8, size: 1, offset: 17, flags: DIFlagBitField, extraData: i64 0)
!1535 = !DIDerivedType(tag: DW_TAG_member, name: "ac", scope: !1516, file: !27, line: 390, baseType: !8, size: 1, offset: 18, flags: DIFlagBitField, extraData: i64 0)
!1536 = !DIDerivedType(tag: DW_TAG_member, name: "vif", scope: !1516, file: !27, line: 391, baseType: !8, size: 1, offset: 19, flags: DIFlagBitField, extraData: i64 0)
!1537 = !DIDerivedType(tag: DW_TAG_member, name: "vip", scope: !1516, file: !27, line: 393, baseType: !8, size: 1, offset: 20, flags: DIFlagBitField, extraData: i64 0)
!1538 = !DIDerivedType(tag: DW_TAG_member, name: "id", scope: !1516, file: !27, line: 394, baseType: !8, size: 1, offset: 21, flags: DIFlagBitField, extraData: i64 0)
!1539 = !DIDerivedType(tag: DW_TAG_member, name: "reserved_eflags", scope: !1516, file: !27, line: 395, baseType: !8, size: 10, offset: 22, flags: DIFlagBitField, extraData: i64 0)
!1540 = !DIDerivedType(tag: DW_TAG_member, name: "reserved_rflags", scope: !1516, file: !27, line: 396, baseType: !8, size: 32, offset: 32)
!1541 = !DIDerivedType(tag: DW_TAG_member, name: "seg", scope: !1268, file: !27, line: 753, baseType: !1542, size: 192, align: 64, offset: 16704)
!1542 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Segments", file: !27, line: 451, size: 192, align: 64, elements: !1543, identifier: "_ZTS8Segments")
!1543 = !{!1544, !1546, !1556, !1557, !1558, !1559, !1560, !1561, !1562, !1563, !1564, !1565}
!1544 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1542, file: !27, line: 452, baseType: !1545, size: 16)
!1545 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !28)
!1546 = !DIDerivedType(tag: DW_TAG_member, name: "ss", scope: !1542, file: !27, line: 453, baseType: !1547, size: 16, offset: 16)
!1547 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "SegmentSelector", file: !27, line: 76, size: 16, elements: !1548, identifier: "_ZTS15SegmentSelector")
!1548 = !{!1549, !1550}
!1549 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1547, file: !27, line: 77, baseType: !28, size: 16)
!1550 = !DIDerivedType(tag: DW_TAG_member, scope: !1547, file: !27, line: 78, baseType: !1551, size: 16)
!1551 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1547, file: !27, line: 78, size: 16, elements: !1552, identifier: "_ZTSN15SegmentSelectorUt_E")
!1552 = !{!1553, !1554, !1555}
!1553 = !DIDerivedType(tag: DW_TAG_member, name: "rpi", scope: !1551, file: !27, line: 79, baseType: !26, size: 2, flags: DIFlagBitField, extraData: i64 0)
!1554 = !DIDerivedType(tag: DW_TAG_member, name: "ti", scope: !1551, file: !27, line: 80, baseType: !35, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1555 = !DIDerivedType(tag: DW_TAG_member, name: "index", scope: !1551, file: !27, line: 81, baseType: !28, size: 13, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1556 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1542, file: !27, line: 454, baseType: !1545, size: 16, offset: 32)
!1557 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1542, file: !27, line: 455, baseType: !1547, size: 16, offset: 48)
!1558 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1542, file: !27, line: 456, baseType: !1545, size: 16, offset: 64)
!1559 = !DIDerivedType(tag: DW_TAG_member, name: "gs", scope: !1542, file: !27, line: 457, baseType: !1547, size: 16, offset: 80)
!1560 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1542, file: !27, line: 458, baseType: !1545, size: 16, offset: 96)
!1561 = !DIDerivedType(tag: DW_TAG_member, name: "fs", scope: !1542, file: !27, line: 459, baseType: !1547, size: 16, offset: 112)
!1562 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1542, file: !27, line: 460, baseType: !1545, size: 16, offset: 128)
!1563 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1542, file: !27, line: 461, baseType: !1547, size: 16, offset: 144)
!1564 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1542, file: !27, line: 462, baseType: !1545, size: 16, offset: 160)
!1565 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1542, file: !27, line: 463, baseType: !1547, size: 16, offset: 176)
!1566 = !DIDerivedType(tag: DW_TAG_member, name: "addr", scope: !1268, file: !27, line: 754, baseType: !1567, size: 768, align: 64, offset: 16896)
!1567 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "AddressSpace", file: !27, line: 654, size: 768, align: 64, elements: !1568, identifier: "_ZTS12AddressSpace")
!1568 = !{!1569, !1571, !1585, !1586, !1587, !1588, !1589, !1590, !1591, !1592, !1593, !1594}
!1569 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1567, file: !27, line: 655, baseType: !1570, size: 64)
!1570 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !637)
!1571 = !DIDerivedType(tag: DW_TAG_member, name: "ss_base", scope: !1567, file: !27, line: 656, baseType: !1572, size: 64, offset: 64)
!1572 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Reg", file: !27, line: 610, size: 64, elements: !1573, identifier: "_ZTS3Reg")
!1573 = !{!1574}
!1574 = !DIDerivedType(tag: DW_TAG_member, scope: !1572, file: !27, line: 611, baseType: !1575, size: 64)
!1575 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1572, file: !27, line: 611, size: 64, elements: !1576, identifier: "_ZTSN3RegUt_E")
!1576 = !{!1577, !1582, !1583, !1584}
!1577 = !DIDerivedType(tag: DW_TAG_member, name: "byte", scope: !1575, file: !27, line: 615, baseType: !1578, size: 16, align: 8)
!1578 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1575, file: !27, line: 612, size: 16, elements: !1579, identifier: "_ZTSN3RegUt_Ut_E")
!1579 = !{!1580, !1581}
!1580 = !DIDerivedType(tag: DW_TAG_member, name: "low", scope: !1578, file: !27, line: 613, baseType: !62, size: 8)
!1581 = !DIDerivedType(tag: DW_TAG_member, name: "high", scope: !1578, file: !27, line: 614, baseType: !62, size: 8, offset: 8)
!1582 = !DIDerivedType(tag: DW_TAG_member, name: "word", scope: !1575, file: !27, line: 616, baseType: !28, size: 16, align: 16)
!1583 = !DIDerivedType(tag: DW_TAG_member, name: "dword", scope: !1575, file: !27, line: 617, baseType: !8, size: 32, align: 32)
!1584 = !DIDerivedType(tag: DW_TAG_member, name: "qword", scope: !1575, file: !27, line: 618, baseType: !637, size: 64, align: 64)
!1585 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1567, file: !27, line: 657, baseType: !1570, size: 64, offset: 128)
!1586 = !DIDerivedType(tag: DW_TAG_member, name: "es_base", scope: !1567, file: !27, line: 658, baseType: !1572, size: 64, offset: 192)
!1587 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1567, file: !27, line: 659, baseType: !1570, size: 64, offset: 256)
!1588 = !DIDerivedType(tag: DW_TAG_member, name: "gs_base", scope: !1567, file: !27, line: 660, baseType: !1572, size: 64, offset: 320)
!1589 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1567, file: !27, line: 661, baseType: !1570, size: 64, offset: 384)
!1590 = !DIDerivedType(tag: DW_TAG_member, name: "fs_base", scope: !1567, file: !27, line: 662, baseType: !1572, size: 64, offset: 448)
!1591 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1567, file: !27, line: 663, baseType: !1570, size: 64, offset: 512)
!1592 = !DIDerivedType(tag: DW_TAG_member, name: "ds_base", scope: !1567, file: !27, line: 664, baseType: !1572, size: 64, offset: 576)
!1593 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1567, file: !27, line: 665, baseType: !1570, size: 64, offset: 640)
!1594 = !DIDerivedType(tag: DW_TAG_member, name: "cs_base", scope: !1567, file: !27, line: 666, baseType: !1572, size: 64, offset: 704)
!1595 = !DIDerivedType(tag: DW_TAG_member, name: "gpr", scope: !1268, file: !27, line: 755, baseType: !1596, size: 2176, align: 64, offset: 17664)
!1596 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "GPR", file: !27, line: 677, size: 2176, align: 64, elements: !1597, identifier: "_ZTS3GPR")
!1597 = !{!1598, !1599, !1600, !1601, !1602, !1603, !1604, !1605, !1606, !1607, !1608, !1609, !1610, !1611, !1612, !1613, !1614, !1615, !1616, !1617, !1618, !1619, !1620, !1621, !1622, !1623, !1624, !1625, !1626, !1627, !1628, !1629, !1630, !1631}
!1598 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1596, file: !27, line: 679, baseType: !1570, size: 64)
!1599 = !DIDerivedType(tag: DW_TAG_member, name: "rax", scope: !1596, file: !27, line: 680, baseType: !1572, size: 64, offset: 64)
!1600 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1596, file: !27, line: 681, baseType: !1570, size: 64, offset: 128)
!1601 = !DIDerivedType(tag: DW_TAG_member, name: "rbx", scope: !1596, file: !27, line: 682, baseType: !1572, size: 64, offset: 192)
!1602 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1596, file: !27, line: 683, baseType: !1570, size: 64, offset: 256)
!1603 = !DIDerivedType(tag: DW_TAG_member, name: "rcx", scope: !1596, file: !27, line: 684, baseType: !1572, size: 64, offset: 320)
!1604 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1596, file: !27, line: 685, baseType: !1570, size: 64, offset: 384)
!1605 = !DIDerivedType(tag: DW_TAG_member, name: "rdx", scope: !1596, file: !27, line: 686, baseType: !1572, size: 64, offset: 448)
!1606 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1596, file: !27, line: 687, baseType: !1570, size: 64, offset: 512)
!1607 = !DIDerivedType(tag: DW_TAG_member, name: "rsi", scope: !1596, file: !27, line: 688, baseType: !1572, size: 64, offset: 576)
!1608 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1596, file: !27, line: 689, baseType: !1570, size: 64, offset: 640)
!1609 = !DIDerivedType(tag: DW_TAG_member, name: "rdi", scope: !1596, file: !27, line: 690, baseType: !1572, size: 64, offset: 704)
!1610 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1596, file: !27, line: 691, baseType: !1570, size: 64, offset: 768)
!1611 = !DIDerivedType(tag: DW_TAG_member, name: "rsp", scope: !1596, file: !27, line: 692, baseType: !1572, size: 64, offset: 832)
!1612 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1596, file: !27, line: 693, baseType: !1570, size: 64, offset: 896)
!1613 = !DIDerivedType(tag: DW_TAG_member, name: "rbp", scope: !1596, file: !27, line: 694, baseType: !1572, size: 64, offset: 960)
!1614 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1596, file: !27, line: 695, baseType: !1570, size: 64, offset: 1024)
!1615 = !DIDerivedType(tag: DW_TAG_member, name: "r8", scope: !1596, file: !27, line: 696, baseType: !1572, size: 64, offset: 1088)
!1616 = !DIDerivedType(tag: DW_TAG_member, name: "_9", scope: !1596, file: !27, line: 697, baseType: !1570, size: 64, offset: 1152)
!1617 = !DIDerivedType(tag: DW_TAG_member, name: "r9", scope: !1596, file: !27, line: 698, baseType: !1572, size: 64, offset: 1216)
!1618 = !DIDerivedType(tag: DW_TAG_member, name: "_10", scope: !1596, file: !27, line: 699, baseType: !1570, size: 64, offset: 1280)
!1619 = !DIDerivedType(tag: DW_TAG_member, name: "r10", scope: !1596, file: !27, line: 700, baseType: !1572, size: 64, offset: 1344)
!1620 = !DIDerivedType(tag: DW_TAG_member, name: "_11", scope: !1596, file: !27, line: 701, baseType: !1570, size: 64, offset: 1408)
!1621 = !DIDerivedType(tag: DW_TAG_member, name: "r11", scope: !1596, file: !27, line: 702, baseType: !1572, size: 64, offset: 1472)
!1622 = !DIDerivedType(tag: DW_TAG_member, name: "_12", scope: !1596, file: !27, line: 703, baseType: !1570, size: 64, offset: 1536)
!1623 = !DIDerivedType(tag: DW_TAG_member, name: "r12", scope: !1596, file: !27, line: 704, baseType: !1572, size: 64, offset: 1600)
!1624 = !DIDerivedType(tag: DW_TAG_member, name: "_13", scope: !1596, file: !27, line: 705, baseType: !1570, size: 64, offset: 1664)
!1625 = !DIDerivedType(tag: DW_TAG_member, name: "r13", scope: !1596, file: !27, line: 706, baseType: !1572, size: 64, offset: 1728)
!1626 = !DIDerivedType(tag: DW_TAG_member, name: "_14", scope: !1596, file: !27, line: 707, baseType: !1570, size: 64, offset: 1792)
!1627 = !DIDerivedType(tag: DW_TAG_member, name: "r14", scope: !1596, file: !27, line: 708, baseType: !1572, size: 64, offset: 1856)
!1628 = !DIDerivedType(tag: DW_TAG_member, name: "_15", scope: !1596, file: !27, line: 709, baseType: !1570, size: 64, offset: 1920)
!1629 = !DIDerivedType(tag: DW_TAG_member, name: "r15", scope: !1596, file: !27, line: 710, baseType: !1572, size: 64, offset: 1984)
!1630 = !DIDerivedType(tag: DW_TAG_member, name: "_16", scope: !1596, file: !27, line: 711, baseType: !1570, size: 64, offset: 2048)
!1631 = !DIDerivedType(tag: DW_TAG_member, name: "rip", scope: !1596, file: !27, line: 714, baseType: !1572, size: 64, offset: 2112)
!1632 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1268, file: !27, line: 756, baseType: !1633, size: 1024, align: 64, offset: 19840)
!1633 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "X87Stack", file: !27, line: 719, size: 1024, align: 64, elements: !1634, identifier: "_ZTS8X87Stack")
!1634 = !{!1635}
!1635 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1633, file: !27, line: 723, baseType: !1636, size: 1024)
!1636 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1637, size: 1024, elements: !1310)
!1637 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1633, file: !27, line: 720, size: 128, align: 64, elements: !1638, identifier: "_ZTSN8X87StackUt_E")
!1638 = !{!1639, !1640}
!1639 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1637, file: !27, line: 721, baseType: !637, size: 64)
!1640 = !DIDerivedType(tag: DW_TAG_member, name: "val", scope: !1637, file: !27, line: 722, baseType: !1641, size: 64, offset: 64)
!1641 = !DIDerivedType(tag: DW_TAG_typedef, name: "float64_t", file: !1266, line: 61, baseType: !108)
!1642 = !DIDerivedType(tag: DW_TAG_member, name: "mmx", scope: !1268, file: !27, line: 757, baseType: !1643, size: 1024, align: 64, offset: 20864)
!1643 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "MMX", file: !27, line: 729, size: 1024, align: 64, elements: !1644, identifier: "_ZTS3MMX")
!1644 = !{!1645}
!1645 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1643, file: !27, line: 733, baseType: !1646, size: 1024)
!1646 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1647, size: 1024, elements: !1310)
!1647 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1643, file: !27, line: 730, size: 128, align: 64, elements: !1648, identifier: "_ZTSN3MMXUt_E")
!1648 = !{!1649, !1650}
!1649 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1647, file: !27, line: 731, baseType: !637, size: 64)
!1650 = !DIDerivedType(tag: DW_TAG_member, name: "val", scope: !1647, file: !27, line: 732, baseType: !1651, size: 64, offset: 64)
!1651 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec64_t", file: !1266, line: 294, size: 64, elements: !1652, identifier: "_ZTS7vec64_t")
!1652 = !{!1653, !1658, !1663, !1668, !1673, !1678, !1683, !1688, !1693, !1698}
!1653 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1651, file: !1266, line: 298, baseType: !1654, size: 64)
!1654 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v1_t", file: !1266, line: 199, size: 64, elements: !1655, identifier: "_ZTS10uint64v1_t")
!1655 = !{!1656}
!1656 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1654, file: !1266, line: 199, baseType: !1657, size: 64)
!1657 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 64, elements: !1296)
!1658 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1651, file: !1266, line: 300, baseType: !1659, size: 64)
!1659 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v8_t", file: !1266, line: 181, size: 64, elements: !1660, identifier: "_ZTS9uint8v8_t")
!1660 = !{!1661}
!1661 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1659, file: !1266, line: 181, baseType: !1662, size: 64)
!1662 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 64, elements: !1310)
!1663 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1651, file: !1266, line: 301, baseType: !1664, size: 64)
!1664 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v4_t", file: !1266, line: 188, size: 64, elements: !1665, identifier: "_ZTS10uint16v4_t")
!1665 = !{!1666}
!1666 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1664, file: !1266, line: 188, baseType: !1667, size: 64)
!1667 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 64, elements: !353)
!1668 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1651, file: !1266, line: 302, baseType: !1669, size: 64)
!1669 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v2_t", file: !1266, line: 194, size: 64, elements: !1670, identifier: "_ZTS10uint32v2_t")
!1670 = !{!1671}
!1671 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1669, file: !1266, line: 194, baseType: !1672, size: 64)
!1672 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 64, elements: !1322)
!1673 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1651, file: !1266, line: 303, baseType: !1674, size: 64)
!1674 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v2_t", file: !1266, line: 241, size: 64, elements: !1675, identifier: "_ZTS11float32v2_t")
!1675 = !{!1676}
!1676 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1674, file: !1266, line: 241, baseType: !1677, size: 64)
!1677 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 64, elements: !1322)
!1678 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1651, file: !1266, line: 304, baseType: !1679, size: 64)
!1679 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v1_t", file: !1266, line: 246, size: 64, elements: !1680, identifier: "_ZTS11float64v1_t")
!1680 = !{!1681}
!1681 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1679, file: !1266, line: 246, baseType: !1682, size: 64)
!1682 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 64, elements: !1296)
!1683 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1651, file: !1266, line: 306, baseType: !1684, size: 64)
!1684 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v8_t", file: !1266, line: 212, size: 64, elements: !1685, identifier: "_ZTS8int8v8_t")
!1685 = !{!1686}
!1686 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1684, file: !1266, line: 212, baseType: !1687, size: 64)
!1687 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 64, elements: !1310)
!1688 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1651, file: !1266, line: 307, baseType: !1689, size: 64)
!1689 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v4_t", file: !1266, line: 219, size: 64, elements: !1690, identifier: "_ZTS9int16v4_t")
!1690 = !{!1691}
!1691 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1689, file: !1266, line: 219, baseType: !1692, size: 64)
!1692 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 64, elements: !353)
!1693 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1651, file: !1266, line: 308, baseType: !1694, size: 64)
!1694 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v2_t", file: !1266, line: 225, size: 64, elements: !1695, identifier: "_ZTS9int32v2_t")
!1695 = !{!1696}
!1696 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1694, file: !1266, line: 225, baseType: !1697, size: 64)
!1697 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 64, elements: !1322)
!1698 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1651, file: !1266, line: 309, baseType: !1699, size: 64)
!1699 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v1_t", file: !1266, line: 230, size: 64, elements: !1700, identifier: "_ZTS9int64v1_t")
!1700 = !{!1701}
!1701 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1699, file: !1266, line: 230, baseType: !1702, size: 64)
!1702 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 64, elements: !1296)
!1703 = !DIDerivedType(tag: DW_TAG_member, name: "sw", scope: !1268, file: !27, line: 758, baseType: !1704, size: 192, offset: 21888)
!1704 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FPUStatusFlags", file: !27, line: 332, size: 192, elements: !1705, identifier: "_ZTS14FPUStatusFlags")
!1705 = !{!1706, !1707, !1708, !1709, !1710, !1711, !1712, !1713, !1714, !1715, !1716, !1717, !1718, !1719, !1720, !1721, !1722, !1723, !1724, !1725, !1726}
!1706 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1704, file: !27, line: 333, baseType: !62, size: 8)
!1707 = !DIDerivedType(tag: DW_TAG_member, name: "c0", scope: !1704, file: !27, line: 334, baseType: !62, size: 8, offset: 8)
!1708 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1704, file: !27, line: 335, baseType: !62, size: 8, offset: 16)
!1709 = !DIDerivedType(tag: DW_TAG_member, name: "c1", scope: !1704, file: !27, line: 336, baseType: !62, size: 8, offset: 24)
!1710 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1704, file: !27, line: 337, baseType: !62, size: 8, offset: 32)
!1711 = !DIDerivedType(tag: DW_TAG_member, name: "c2", scope: !1704, file: !27, line: 338, baseType: !62, size: 8, offset: 40)
!1712 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1704, file: !27, line: 339, baseType: !62, size: 8, offset: 48)
!1713 = !DIDerivedType(tag: DW_TAG_member, name: "c3", scope: !1704, file: !27, line: 340, baseType: !62, size: 8, offset: 56)
!1714 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1704, file: !27, line: 342, baseType: !62, size: 8, offset: 64)
!1715 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1704, file: !27, line: 343, baseType: !62, size: 8, offset: 72)
!1716 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1704, file: !27, line: 345, baseType: !62, size: 8, offset: 80)
!1717 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1704, file: !27, line: 346, baseType: !62, size: 8, offset: 88)
!1718 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1704, file: !27, line: 348, baseType: !62, size: 8, offset: 96)
!1719 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1704, file: !27, line: 349, baseType: !62, size: 8, offset: 104)
!1720 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1704, file: !27, line: 351, baseType: !62, size: 8, offset: 112)
!1721 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1704, file: !27, line: 352, baseType: !62, size: 8, offset: 120)
!1722 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1704, file: !27, line: 354, baseType: !62, size: 8, offset: 128)
!1723 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1704, file: !27, line: 355, baseType: !62, size: 8, offset: 136)
!1724 = !DIDerivedType(tag: DW_TAG_member, name: "_9", scope: !1704, file: !27, line: 357, baseType: !62, size: 8, offset: 144)
!1725 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1704, file: !27, line: 358, baseType: !62, size: 8, offset: 152)
!1726 = !DIDerivedType(tag: DW_TAG_member, name: "_padding", scope: !1704, file: !27, line: 360, baseType: !1727, size: 32, offset: 160)
!1727 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 32, elements: !353)
!1728 = !DIDerivedType(tag: DW_TAG_member, name: "xcr0", scope: !1268, file: !27, line: 759, baseType: !1729, size: 64, offset: 22080)
!1729 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "XCR0", file: !27, line: 424, size: 64, elements: !1730, identifier: "_ZTS4XCR0")
!1730 = !{!1731, !1732, !1737}
!1731 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1729, file: !27, line: 425, baseType: !637, size: 64)
!1732 = !DIDerivedType(tag: DW_TAG_member, scope: !1729, file: !27, line: 427, baseType: !1733, size: 64)
!1733 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1729, file: !27, line: 427, size: 64, elements: !1734, identifier: "_ZTSN4XCR0Ut_E")
!1734 = !{!1735, !1736}
!1735 = !DIDerivedType(tag: DW_TAG_member, name: "eax", scope: !1733, file: !27, line: 428, baseType: !8, size: 32)
!1736 = !DIDerivedType(tag: DW_TAG_member, name: "edx", scope: !1733, file: !27, line: 429, baseType: !8, size: 32, offset: 32)
!1737 = !DIDerivedType(tag: DW_TAG_member, scope: !1729, file: !27, line: 433, baseType: !1738, size: 64)
!1738 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1729, file: !27, line: 433, size: 64, elements: !1739, identifier: "_ZTSN4XCR0Ut0_E")
!1739 = !{!1740, !1741, !1742, !1743, !1744, !1745, !1746, !1747, !1748, !1749, !1750, !1751}
!1740 = !DIDerivedType(tag: DW_TAG_member, name: "x87_fpu_mmx", scope: !1738, file: !27, line: 434, baseType: !637, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1741 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1738, file: !27, line: 435, baseType: !637, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1742 = !DIDerivedType(tag: DW_TAG_member, name: "ymm", scope: !1738, file: !27, line: 436, baseType: !637, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1743 = !DIDerivedType(tag: DW_TAG_member, name: "bndreg", scope: !1738, file: !27, line: 437, baseType: !637, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1744 = !DIDerivedType(tag: DW_TAG_member, name: "bndcsr", scope: !1738, file: !27, line: 438, baseType: !637, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1745 = !DIDerivedType(tag: DW_TAG_member, name: "opmask", scope: !1738, file: !27, line: 439, baseType: !637, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1746 = !DIDerivedType(tag: DW_TAG_member, name: "zmm_hi256", scope: !1738, file: !27, line: 440, baseType: !637, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1747 = !DIDerivedType(tag: DW_TAG_member, name: "hi16_zmm", scope: !1738, file: !27, line: 441, baseType: !637, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1748 = !DIDerivedType(tag: DW_TAG_member, name: "pkru", scope: !1738, file: !27, line: 442, baseType: !637, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1749 = !DIDerivedType(tag: DW_TAG_member, name: "_reserved0", scope: !1738, file: !27, line: 443, baseType: !637, size: 53, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1750 = !DIDerivedType(tag: DW_TAG_member, name: "lwp", scope: !1738, file: !27, line: 444, baseType: !637, size: 1, offset: 62, flags: DIFlagBitField, extraData: i64 0)
!1751 = !DIDerivedType(tag: DW_TAG_member, name: "_reserved1", scope: !1738, file: !27, line: 445, baseType: !637, size: 1, offset: 63, flags: DIFlagBitField, extraData: i64 0)
!1752 = !DIDerivedType(tag: DW_TAG_member, name: "x87", scope: !1268, file: !27, line: 760, baseType: !1753, size: 4096, align: 128, offset: 22144)
!1753 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPU", file: !27, line: 314, size: 4096, align: 128, elements: !1754, identifier: "_ZTS3FPU")
!1754 = !{!1755, !1851, !1914}
!1755 = !DIDerivedType(tag: DW_TAG_member, name: "fsave", scope: !1753, file: !27, line: 317, baseType: !1756, size: 4096)
!1756 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 315, size: 4096, elements: !1757, identifier: "_ZTSN3FPUUt_E")
!1757 = !{!1758, !1847}
!1758 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1756, baseType: !1759)
!1759 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFSAVE", file: !27, line: 263, size: 1248, elements: !1760, identifier: "_ZTS8FpuFSAVE")
!1760 = !{!1761, !1779, !1780, !1801, !1802, !1817, !1818, !1819, !1820, !1821, !1822, !1823, !1824}
!1761 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1759, file: !27, line: 264, baseType: !1762, size: 16)
!1762 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUControlWord", file: !27, line: 142, size: 16, elements: !1763, identifier: "_ZTS14FPUControlWord")
!1763 = !{!1764, !1765}
!1764 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1762, file: !27, line: 143, baseType: !28, size: 16)
!1765 = !DIDerivedType(tag: DW_TAG_member, scope: !1762, file: !27, line: 144, baseType: !1766, size: 16)
!1766 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1762, file: !27, line: 144, size: 16, elements: !1767, identifier: "_ZTSN14FPUControlWordUt_E")
!1767 = !{!1768, !1769, !1770, !1771, !1772, !1773, !1774, !1775, !1776, !1777, !1778}
!1768 = !DIDerivedType(tag: DW_TAG_member, name: "im", scope: !1766, file: !27, line: 145, baseType: !28, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1769 = !DIDerivedType(tag: DW_TAG_member, name: "dm", scope: !1766, file: !27, line: 146, baseType: !28, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1770 = !DIDerivedType(tag: DW_TAG_member, name: "zm", scope: !1766, file: !27, line: 147, baseType: !28, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1771 = !DIDerivedType(tag: DW_TAG_member, name: "om", scope: !1766, file: !27, line: 148, baseType: !28, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1772 = !DIDerivedType(tag: DW_TAG_member, name: "um", scope: !1766, file: !27, line: 149, baseType: !28, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1773 = !DIDerivedType(tag: DW_TAG_member, name: "pm", scope: !1766, file: !27, line: 150, baseType: !28, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1774 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1766, file: !27, line: 151, baseType: !28, size: 2, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1775 = !DIDerivedType(tag: DW_TAG_member, name: "pc", scope: !1766, file: !27, line: 152, baseType: !39, size: 2, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1776 = !DIDerivedType(tag: DW_TAG_member, name: "rc", scope: !1766, file: !27, line: 153, baseType: !45, size: 2, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1777 = !DIDerivedType(tag: DW_TAG_member, name: "x", scope: !1766, file: !27, line: 154, baseType: !51, size: 1, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1778 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1766, file: !27, line: 155, baseType: !28, size: 3, offset: 13, flags: DIFlagBitField, extraData: i64 0)
!1779 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1759, file: !27, line: 265, baseType: !28, size: 16, offset: 16)
!1780 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1759, file: !27, line: 266, baseType: !1781, size: 16, offset: 32)
!1781 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUStatusWord", file: !27, line: 100, size: 16, elements: !1782, identifier: "_ZTS13FPUStatusWord")
!1782 = !{!1783, !1784}
!1783 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1781, file: !27, line: 101, baseType: !28, size: 16)
!1784 = !DIDerivedType(tag: DW_TAG_member, scope: !1781, file: !27, line: 102, baseType: !1785, size: 16)
!1785 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1781, file: !27, line: 102, size: 16, elements: !1786, identifier: "_ZTSN13FPUStatusWordUt_E")
!1786 = !{!1787, !1788, !1789, !1790, !1791, !1792, !1793, !1794, !1795, !1796, !1797, !1798, !1799, !1800}
!1787 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1785, file: !27, line: 103, baseType: !28, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1788 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1785, file: !27, line: 104, baseType: !28, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1789 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1785, file: !27, line: 105, baseType: !28, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1790 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1785, file: !27, line: 106, baseType: !28, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1791 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1785, file: !27, line: 107, baseType: !28, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1792 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1785, file: !27, line: 108, baseType: !28, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1793 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1785, file: !27, line: 109, baseType: !28, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1794 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1785, file: !27, line: 110, baseType: !28, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1795 = !DIDerivedType(tag: DW_TAG_member, name: "c0", scope: !1785, file: !27, line: 111, baseType: !28, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1796 = !DIDerivedType(tag: DW_TAG_member, name: "c1", scope: !1785, file: !27, line: 112, baseType: !28, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1797 = !DIDerivedType(tag: DW_TAG_member, name: "c2", scope: !1785, file: !27, line: 113, baseType: !28, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1798 = !DIDerivedType(tag: DW_TAG_member, name: "top", scope: !1785, file: !27, line: 114, baseType: !28, size: 3, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1799 = !DIDerivedType(tag: DW_TAG_member, name: "c3", scope: !1785, file: !27, line: 115, baseType: !28, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1800 = !DIDerivedType(tag: DW_TAG_member, name: "b", scope: !1785, file: !27, line: 116, baseType: !28, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1801 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1759, file: !27, line: 267, baseType: !28, size: 16, offset: 48)
!1802 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1759, file: !27, line: 268, baseType: !1803, size: 16, offset: 64)
!1803 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUTagWord", file: !27, line: 227, size: 16, elements: !1804, identifier: "_ZTS10FPUTagWord")
!1804 = !{!1805, !1806}
!1805 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1803, file: !27, line: 228, baseType: !28, size: 16)
!1806 = !DIDerivedType(tag: DW_TAG_member, scope: !1803, file: !27, line: 229, baseType: !1807, size: 16)
!1807 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1803, file: !27, line: 229, size: 16, elements: !1808, identifier: "_ZTSN10FPUTagWordUt_E")
!1808 = !{!1809, !1810, !1811, !1812, !1813, !1814, !1815, !1816}
!1809 = !DIDerivedType(tag: DW_TAG_member, name: "tag0", scope: !1807, file: !27, line: 230, baseType: !55, size: 2, flags: DIFlagBitField, extraData: i64 0)
!1810 = !DIDerivedType(tag: DW_TAG_member, name: "tag1", scope: !1807, file: !27, line: 231, baseType: !55, size: 2, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1811 = !DIDerivedType(tag: DW_TAG_member, name: "tag2", scope: !1807, file: !27, line: 232, baseType: !55, size: 2, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1812 = !DIDerivedType(tag: DW_TAG_member, name: "tag3", scope: !1807, file: !27, line: 233, baseType: !55, size: 2, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1813 = !DIDerivedType(tag: DW_TAG_member, name: "tag4", scope: !1807, file: !27, line: 234, baseType: !55, size: 2, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1814 = !DIDerivedType(tag: DW_TAG_member, name: "tag5", scope: !1807, file: !27, line: 235, baseType: !55, size: 2, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1815 = !DIDerivedType(tag: DW_TAG_member, name: "tag6", scope: !1807, file: !27, line: 236, baseType: !55, size: 2, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1816 = !DIDerivedType(tag: DW_TAG_member, name: "tag7", scope: !1807, file: !27, line: 237, baseType: !55, size: 2, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1817 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1759, file: !27, line: 269, baseType: !28, size: 16, offset: 80)
!1818 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1759, file: !27, line: 270, baseType: !8, size: 32, offset: 96)
!1819 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1759, file: !27, line: 271, baseType: !1547, size: 16, offset: 128)
!1820 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd2", scope: !1759, file: !27, line: 272, baseType: !28, size: 16, offset: 144)
!1821 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1759, file: !27, line: 273, baseType: !8, size: 32, offset: 160)
!1822 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1759, file: !27, line: 274, baseType: !1547, size: 16, offset: 192)
!1823 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd3", scope: !1759, file: !27, line: 275, baseType: !28, size: 16, offset: 208)
!1824 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1759, file: !27, line: 276, baseType: !1825, size: 1024, offset: 224)
!1825 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1826, size: 1024, elements: !1310)
!1826 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FPUStackElem", file: !27, line: 162, size: 128, elements: !1827, identifier: "_ZTS12FPUStackElem")
!1827 = !{!1828, !1843}
!1828 = !DIDerivedType(tag: DW_TAG_member, scope: !1826, file: !27, line: 163, baseType: !1829, size: 80)
!1829 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1826, file: !27, line: 163, size: 80, elements: !1830, identifier: "_ZTSN12FPUStackElemUt_E")
!1830 = !{!1831, !1838}
!1831 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1829, file: !27, line: 164, baseType: !1832, size: 80)
!1832 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float80_t", file: !1266, line: 65, size: 80, elements: !1833, identifier: "_ZTS9float80_t")
!1833 = !{!1834}
!1834 = !DIDerivedType(tag: DW_TAG_member, name: "data", scope: !1832, file: !1266, line: 66, baseType: !1835, size: 80)
!1835 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 80, elements: !1836)
!1836 = !{!1837}
!1837 = !DISubrange(count: 10)
!1838 = !DIDerivedType(tag: DW_TAG_member, scope: !1829, file: !27, line: 165, baseType: !1839, size: 80)
!1839 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1829, file: !27, line: 165, size: 80, elements: !1840, identifier: "_ZTSN12FPUStackElemUt_Ut_E")
!1840 = !{!1841, !1842}
!1841 = !DIDerivedType(tag: DW_TAG_member, name: "mmx", scope: !1839, file: !27, line: 166, baseType: !637, size: 64)
!1842 = !DIDerivedType(tag: DW_TAG_member, name: "infinity", scope: !1839, file: !27, line: 167, baseType: !28, size: 16, offset: 64)
!1843 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd", scope: !1826, file: !27, line: 170, baseType: !1844, size: 48, offset: 80)
!1844 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 48, elements: !1845)
!1845 = !{!1846}
!1846 = !DISubrange(count: 6)
!1847 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1756, file: !27, line: 316, baseType: !1848, size: 2848, offset: 1248)
!1848 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 2848, elements: !1849)
!1849 = !{!1850}
!1850 = !DISubrange(count: 356)
!1851 = !DIDerivedType(tag: DW_TAG_member, name: "fxsave32", scope: !1753, file: !27, line: 321, baseType: !1852, size: 4096)
!1852 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 319, size: 4096, elements: !1853, identifier: "_ZTSN3FPUUt0_E")
!1853 = !{!1854, !1910}
!1854 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1852, baseType: !1855)
!1855 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFXSAVE", file: !27, line: 280, size: 3328, elements: !1856, identifier: "_ZTS9FpuFXSAVE")
!1856 = !{!1857, !1858, !1859, !1874, !1875, !1876, !1877, !1878, !1879, !1880, !1881, !1882, !1906, !1907, !1908}
!1857 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1855, file: !27, line: 281, baseType: !1762, size: 16)
!1858 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1855, file: !27, line: 282, baseType: !1781, size: 16, offset: 16)
!1859 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1855, file: !27, line: 283, baseType: !1860, size: 8, offset: 32)
!1860 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUAbridgedTagWord", file: !27, line: 245, size: 8, elements: !1861, identifier: "_ZTS18FPUAbridgedTagWord")
!1861 = !{!1862, !1863}
!1862 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1860, file: !27, line: 246, baseType: !62, size: 8)
!1863 = !DIDerivedType(tag: DW_TAG_member, scope: !1860, file: !27, line: 247, baseType: !1864, size: 8)
!1864 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1860, file: !27, line: 247, size: 8, elements: !1865, identifier: "_ZTSN18FPUAbridgedTagWordUt_E")
!1865 = !{!1866, !1867, !1868, !1869, !1870, !1871, !1872, !1873}
!1866 = !DIDerivedType(tag: DW_TAG_member, name: "r0", scope: !1864, file: !27, line: 248, baseType: !61, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1867 = !DIDerivedType(tag: DW_TAG_member, name: "r1", scope: !1864, file: !27, line: 249, baseType: !61, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1868 = !DIDerivedType(tag: DW_TAG_member, name: "r2", scope: !1864, file: !27, line: 250, baseType: !61, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1869 = !DIDerivedType(tag: DW_TAG_member, name: "r3", scope: !1864, file: !27, line: 251, baseType: !61, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1870 = !DIDerivedType(tag: DW_TAG_member, name: "r4", scope: !1864, file: !27, line: 252, baseType: !61, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1871 = !DIDerivedType(tag: DW_TAG_member, name: "r5", scope: !1864, file: !27, line: 253, baseType: !61, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1872 = !DIDerivedType(tag: DW_TAG_member, name: "r6", scope: !1864, file: !27, line: 254, baseType: !61, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1873 = !DIDerivedType(tag: DW_TAG_member, name: "r7", scope: !1864, file: !27, line: 255, baseType: !61, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1874 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1855, file: !27, line: 284, baseType: !62, size: 8, offset: 40)
!1875 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1855, file: !27, line: 285, baseType: !28, size: 16, offset: 48)
!1876 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1855, file: !27, line: 286, baseType: !8, size: 32, offset: 64)
!1877 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1855, file: !27, line: 287, baseType: !1547, size: 16, offset: 96)
!1878 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1855, file: !27, line: 288, baseType: !28, size: 16, offset: 112)
!1879 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1855, file: !27, line: 289, baseType: !8, size: 32, offset: 128)
!1880 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1855, file: !27, line: 290, baseType: !1547, size: 16, offset: 160)
!1881 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd2", scope: !1855, file: !27, line: 291, baseType: !28, size: 16, offset: 176)
!1882 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr", scope: !1855, file: !27, line: 292, baseType: !1883, size: 32, offset: 192)
!1883 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUControlStatus", file: !27, line: 188, size: 32, elements: !1884, identifier: "_ZTS16FPUControlStatus")
!1884 = !{!1885, !1886}
!1885 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1883, file: !27, line: 189, baseType: !8, size: 32)
!1886 = !DIDerivedType(tag: DW_TAG_member, scope: !1883, file: !27, line: 190, baseType: !1887, size: 32)
!1887 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1883, file: !27, line: 190, size: 32, elements: !1888, identifier: "_ZTSN16FPUControlStatusUt_E")
!1888 = !{!1889, !1890, !1891, !1892, !1893, !1894, !1895, !1896, !1897, !1898, !1899, !1900, !1901, !1902, !1903, !1904, !1905}
!1889 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1887, file: !27, line: 191, baseType: !8, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1890 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1887, file: !27, line: 192, baseType: !8, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1891 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1887, file: !27, line: 193, baseType: !8, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1892 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1887, file: !27, line: 194, baseType: !8, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1893 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1887, file: !27, line: 195, baseType: !8, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1894 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1887, file: !27, line: 196, baseType: !8, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1895 = !DIDerivedType(tag: DW_TAG_member, name: "daz", scope: !1887, file: !27, line: 197, baseType: !8, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1896 = !DIDerivedType(tag: DW_TAG_member, name: "im", scope: !1887, file: !27, line: 198, baseType: !8, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1897 = !DIDerivedType(tag: DW_TAG_member, name: "dm", scope: !1887, file: !27, line: 199, baseType: !8, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1898 = !DIDerivedType(tag: DW_TAG_member, name: "zm", scope: !1887, file: !27, line: 200, baseType: !8, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1899 = !DIDerivedType(tag: DW_TAG_member, name: "om", scope: !1887, file: !27, line: 201, baseType: !8, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1900 = !DIDerivedType(tag: DW_TAG_member, name: "um", scope: !1887, file: !27, line: 202, baseType: !8, size: 1, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1901 = !DIDerivedType(tag: DW_TAG_member, name: "pm", scope: !1887, file: !27, line: 203, baseType: !8, size: 1, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1902 = !DIDerivedType(tag: DW_TAG_member, name: "rn", scope: !1887, file: !27, line: 204, baseType: !8, size: 1, offset: 13, flags: DIFlagBitField, extraData: i64 0)
!1903 = !DIDerivedType(tag: DW_TAG_member, name: "rp", scope: !1887, file: !27, line: 205, baseType: !8, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1904 = !DIDerivedType(tag: DW_TAG_member, name: "fz", scope: !1887, file: !27, line: 206, baseType: !8, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1905 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd", scope: !1887, file: !27, line: 207, baseType: !8, size: 16, offset: 16, flags: DIFlagBitField, extraData: i64 0)
!1906 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr_mask", scope: !1855, file: !27, line: 293, baseType: !1883, size: 32, offset: 224)
!1907 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1855, file: !27, line: 294, baseType: !1825, size: 1024, offset: 256)
!1908 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1855, file: !27, line: 295, baseType: !1909, size: 2048, offset: 1280)
!1909 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1287, size: 2048, elements: !1303)
!1910 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1852, file: !27, line: 320, baseType: !1911, size: 768, offset: 3328)
!1911 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 768, elements: !1912)
!1912 = !{!1913}
!1913 = !DISubrange(count: 96)
!1914 = !DIDerivedType(tag: DW_TAG_member, name: "fxsave64", scope: !1753, file: !27, line: 325, baseType: !1915, size: 4096)
!1915 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 323, size: 4096, elements: !1916, identifier: "_ZTSN3FPUUt1_E")
!1916 = !{!1917, !1931}
!1917 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1915, baseType: !1918)
!1918 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFXSAVE64", file: !27, line: 299, size: 3328, elements: !1919, identifier: "_ZTS11FpuFXSAVE64")
!1919 = !{!1920, !1921, !1922, !1923, !1924, !1925, !1926, !1927, !1928, !1929, !1930}
!1920 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1918, file: !27, line: 300, baseType: !1762, size: 16)
!1921 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1918, file: !27, line: 301, baseType: !1781, size: 16, offset: 16)
!1922 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1918, file: !27, line: 302, baseType: !1860, size: 8, offset: 32)
!1923 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1918, file: !27, line: 303, baseType: !62, size: 8, offset: 40)
!1924 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1918, file: !27, line: 304, baseType: !28, size: 16, offset: 48)
!1925 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1918, file: !27, line: 305, baseType: !637, size: 64, offset: 64)
!1926 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1918, file: !27, line: 306, baseType: !637, size: 64, offset: 128)
!1927 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr", scope: !1918, file: !27, line: 307, baseType: !1883, size: 32, offset: 192)
!1928 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr_mask", scope: !1918, file: !27, line: 308, baseType: !1883, size: 32, offset: 224)
!1929 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1918, file: !27, line: 309, baseType: !1825, size: 1024, offset: 256)
!1930 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1918, file: !27, line: 310, baseType: !1909, size: 2048, offset: 1280)
!1931 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1915, file: !27, line: 324, baseType: !1911, size: 768, offset: 3328)
!1932 = !DIDerivedType(tag: DW_TAG_member, name: "seg_caches", scope: !1268, file: !27, line: 761, baseType: !1933, size: 768, align: 64, offset: 26240)
!1933 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "SegmentCaches", file: !27, line: 468, size: 768, align: 64, elements: !1934, identifier: "_ZTS13SegmentCaches")
!1934 = !{!1935, !1945, !1946, !1947, !1948, !1949}
!1935 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1933, file: !27, line: 469, baseType: !1936, size: 128)
!1936 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "SegmentShadow", file: !27, line: 88, size: 128, elements: !1937, identifier: "_ZTS13SegmentShadow")
!1937 = !{!1938, !1943, !1944}
!1938 = !DIDerivedType(tag: DW_TAG_member, name: "base", scope: !1936, file: !27, line: 92, baseType: !1939, size: 64)
!1939 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1936, file: !27, line: 89, size: 64, elements: !1940, identifier: "_ZTSN13SegmentShadowUt_E")
!1940 = !{!1941, !1942}
!1941 = !DIDerivedType(tag: DW_TAG_member, name: "dword", scope: !1939, file: !27, line: 90, baseType: !8, size: 32)
!1942 = !DIDerivedType(tag: DW_TAG_member, name: "qword", scope: !1939, file: !27, line: 91, baseType: !637, size: 64)
!1943 = !DIDerivedType(tag: DW_TAG_member, name: "limit", scope: !1936, file: !27, line: 93, baseType: !8, size: 32, offset: 64)
!1944 = !DIDerivedType(tag: DW_TAG_member, name: "flags", scope: !1936, file: !27, line: 94, baseType: !8, size: 32, offset: 96)
!1945 = !DIDerivedType(tag: DW_TAG_member, name: "ss", scope: !1933, file: !27, line: 470, baseType: !1936, size: 128, offset: 128)
!1946 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1933, file: !27, line: 471, baseType: !1936, size: 128, offset: 256)
!1947 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1933, file: !27, line: 472, baseType: !1936, size: 128, offset: 384)
!1948 = !DIDerivedType(tag: DW_TAG_member, name: "fs", scope: !1933, file: !27, line: 473, baseType: !1936, size: 128, offset: 512)
!1949 = !DIDerivedType(tag: DW_TAG_member, name: "gs", scope: !1933, file: !27, line: 474, baseType: !1936, size: 128, offset: 640)
!1950 = !DIDerivedType(tag: DW_TAG_typedef, name: "addr_t", file: !1266, line: 42, baseType: !1951)
!1951 = !DIDerivedType(tag: DW_TAG_typedef, name: "addr64_t", file: !1266, line: 41, baseType: !637)
!1952 = !DILocation(line: 54, column: 8, scope: !1261)
!1953 = !DILocation(line: 55, column: 10, scope: !1261)
!1954 = !DILocation(line: 56, column: 10, scope: !1261)
!1955 = !DILocation(line: 57, column: 10, scope: !1261)
!1956 = !DILocation(line: 58, column: 10, scope: !1261)
!1957 = !DILocation(line: 61, column: 9, scope: !1261)
!1958 = !DILocation(line: 62, column: 9, scope: !1261)
!1959 = !DILocation(line: 63, column: 20, scope: !1261)
!1960 = !DILocation(line: 63, column: 24, scope: !1261)
!1961 = !DILocation(line: 63, column: 28, scope: !1261)
!1962 = !DILocation(line: 69, column: 6, scope: !1261)
!1963 = !DILocation(line: 74, column: 20, scope: !1261)
!1964 = !DILocation(line: 74, column: 24, scope: !1261)
!1965 = !DILocation(line: 74, column: 28, scope: !1261)
!1966 = !DILocation(line: 74, column: 33, scope: !1261)
!1967 = !DILocation(line: 75, column: 20, scope: !1261)
!1968 = !DILocation(line: 75, column: 24, scope: !1261)
!1969 = !DILocation(line: 75, column: 28, scope: !1261)
!1970 = !DILocation(line: 75, column: 33, scope: !1261)
!1971 = !DILocation(line: 76, column: 20, scope: !1261)
!1972 = !DILocation(line: 76, column: 24, scope: !1261)
!1973 = !DILocation(line: 76, column: 28, scope: !1261)
!1974 = !DILocation(line: 76, column: 33, scope: !1261)
!1975 = !DILocation(line: 77, column: 20, scope: !1261)
!1976 = !DILocation(line: 77, column: 24, scope: !1261)
!1977 = !DILocation(line: 77, column: 28, scope: !1261)
!1978 = !DILocation(line: 77, column: 33, scope: !1261)
!1979 = !DILocation(line: 78, column: 20, scope: !1261)
!1980 = !DILocation(line: 78, column: 24, scope: !1261)
!1981 = !DILocation(line: 78, column: 28, scope: !1261)
!1982 = !DILocation(line: 78, column: 33, scope: !1261)
!1983 = !DILocation(line: 79, column: 20, scope: !1261)
!1984 = !DILocation(line: 79, column: 24, scope: !1261)
!1985 = !DILocation(line: 79, column: 28, scope: !1261)
!1986 = !DILocation(line: 79, column: 33, scope: !1261)
!1987 = !DILocation(line: 80, column: 20, scope: !1261)
!1988 = !DILocation(line: 80, column: 24, scope: !1261)
!1989 = !DILocation(line: 80, column: 28, scope: !1261)
!1990 = !DILocation(line: 80, column: 33, scope: !1261)
!1991 = !DILocation(line: 81, column: 20, scope: !1261)
!1992 = !DILocation(line: 81, column: 24, scope: !1261)
!1993 = !DILocation(line: 81, column: 28, scope: !1261)
!1994 = !DILocation(line: 81, column: 33, scope: !1261)
!1995 = !DILocation(line: 83, column: 21, scope: !1261)
!1996 = !DILocation(line: 83, column: 25, scope: !1261)
!1997 = !DILocation(line: 83, column: 29, scope: !1261)
!1998 = !DILocation(line: 83, column: 34, scope: !1261)
!1999 = !DILocation(line: 84, column: 21, scope: !1261)
!2000 = !DILocation(line: 84, column: 25, scope: !1261)
!2001 = !DILocation(line: 84, column: 29, scope: !1261)
!2002 = !DILocation(line: 84, column: 34, scope: !1261)
!2003 = !DILocation(line: 85, column: 21, scope: !1261)
!2004 = !DILocation(line: 85, column: 25, scope: !1261)
!2005 = !DILocation(line: 85, column: 29, scope: !1261)
!2006 = !DILocation(line: 85, column: 34, scope: !1261)
!2007 = !DILocation(line: 86, column: 21, scope: !1261)
!2008 = !DILocation(line: 86, column: 25, scope: !1261)
!2009 = !DILocation(line: 86, column: 29, scope: !1261)
!2010 = !DILocation(line: 86, column: 34, scope: !1261)
!2011 = !DILocation(line: 87, column: 21, scope: !1261)
!2012 = !DILocation(line: 87, column: 25, scope: !1261)
!2013 = !DILocation(line: 87, column: 28, scope: !1261)
!2014 = !DILocation(line: 87, column: 33, scope: !1261)
!2015 = !DILocation(line: 88, column: 21, scope: !1261)
!2016 = !DILocation(line: 88, column: 25, scope: !1261)
!2017 = !DILocation(line: 88, column: 28, scope: !1261)
!2018 = !DILocation(line: 88, column: 33, scope: !1261)
!2019 = !DILocation(line: 89, column: 22, scope: !1261)
!2020 = !DILocation(line: 89, column: 26, scope: !1261)
!2021 = !DILocation(line: 89, column: 30, scope: !1261)
!2022 = !DILocation(line: 89, column: 35, scope: !1261)
!2023 = !DILocation(line: 90, column: 22, scope: !1261)
!2024 = !DILocation(line: 90, column: 26, scope: !1261)
!2025 = !DILocation(line: 90, column: 30, scope: !1261)
!2026 = !DILocation(line: 90, column: 35, scope: !1261)
!2027 = !DILocation(line: 91, column: 22, scope: !1261)
!2028 = !DILocation(line: 91, column: 26, scope: !1261)
!2029 = !DILocation(line: 91, column: 30, scope: !1261)
!2030 = !DILocation(line: 91, column: 35, scope: !1261)
!2031 = !DILocation(line: 92, column: 22, scope: !1261)
!2032 = !DILocation(line: 92, column: 26, scope: !1261)
!2033 = !DILocation(line: 92, column: 30, scope: !1261)
!2034 = !DILocation(line: 92, column: 35, scope: !1261)
!2035 = !DILocation(line: 93, column: 22, scope: !1261)
!2036 = !DILocation(line: 93, column: 26, scope: !1261)
!2037 = !DILocation(line: 93, column: 30, scope: !1261)
!2038 = !DILocation(line: 93, column: 35, scope: !1261)
!2039 = !DILocation(line: 94, column: 22, scope: !1261)
!2040 = !DILocation(line: 94, column: 26, scope: !1261)
!2041 = !DILocation(line: 94, column: 30, scope: !1261)
!2042 = !DILocation(line: 94, column: 35, scope: !1261)
!2043 = !DILocation(line: 96, column: 20, scope: !1261)
!2044 = !DILocation(line: 96, column: 24, scope: !1261)
!2045 = !DILocation(line: 96, column: 28, scope: !1261)
!2046 = !DILocation(line: 97, column: 20, scope: !1261)
!2047 = !DILocation(line: 97, column: 24, scope: !1261)
!2048 = !DILocation(line: 97, column: 28, scope: !1261)
!2049 = !DILocation(line: 98, column: 20, scope: !1261)
!2050 = !DILocation(line: 98, column: 24, scope: !1261)
!2051 = !DILocation(line: 98, column: 28, scope: !1261)
!2052 = !DILocation(line: 99, column: 20, scope: !1261)
!2053 = !DILocation(line: 99, column: 24, scope: !1261)
!2054 = !DILocation(line: 99, column: 28, scope: !1261)
!2055 = !DILocation(line: 100, column: 20, scope: !1261)
!2056 = !DILocation(line: 100, column: 24, scope: !1261)
!2057 = !DILocation(line: 100, column: 28, scope: !1261)
!2058 = !DILocation(line: 101, column: 20, scope: !1261)
!2059 = !DILocation(line: 101, column: 24, scope: !1261)
!2060 = !DILocation(line: 101, column: 28, scope: !1261)
!2061 = !DILocation(line: 102, column: 20, scope: !1261)
!2062 = !DILocation(line: 102, column: 24, scope: !1261)
!2063 = !DILocation(line: 102, column: 28, scope: !1261)
!2064 = !DILocation(line: 103, column: 20, scope: !1261)
!2065 = !DILocation(line: 103, column: 24, scope: !1261)
!2066 = !DILocation(line: 103, column: 28, scope: !1261)
!2067 = !DILocation(line: 105, column: 21, scope: !1261)
!2068 = !DILocation(line: 105, column: 25, scope: !1261)
!2069 = !DILocation(line: 105, column: 28, scope: !1261)
!2070 = !DILocation(line: 106, column: 21, scope: !1261)
!2071 = !DILocation(line: 106, column: 25, scope: !1261)
!2072 = !DILocation(line: 106, column: 28, scope: !1261)
!2073 = !DILocation(line: 107, column: 22, scope: !1261)
!2074 = !DILocation(line: 107, column: 26, scope: !1261)
!2075 = !DILocation(line: 107, column: 30, scope: !1261)
!2076 = !DILocation(line: 108, column: 22, scope: !1261)
!2077 = !DILocation(line: 108, column: 26, scope: !1261)
!2078 = !DILocation(line: 108, column: 30, scope: !1261)
!2079 = !DILocation(line: 109, column: 22, scope: !1261)
!2080 = !DILocation(line: 109, column: 26, scope: !1261)
!2081 = !DILocation(line: 109, column: 30, scope: !1261)
!2082 = !DILocation(line: 110, column: 22, scope: !1261)
!2083 = !DILocation(line: 110, column: 26, scope: !1261)
!2084 = !DILocation(line: 110, column: 30, scope: !1261)
!2085 = !DILocation(line: 111, column: 22, scope: !1261)
!2086 = !DILocation(line: 111, column: 26, scope: !1261)
!2087 = !DILocation(line: 111, column: 30, scope: !1261)
!2088 = !DILocation(line: 112, column: 22, scope: !1261)
!2089 = !DILocation(line: 112, column: 26, scope: !1261)
!2090 = !DILocation(line: 112, column: 30, scope: !1261)
!2091 = !DILocation(line: 114, column: 20, scope: !1261)
!2092 = !DILocation(line: 114, column: 24, scope: !1261)
!2093 = !DILocation(line: 114, column: 28, scope: !1261)
!2094 = !DILocation(line: 116, column: 21, scope: !1261)
!2095 = !DILocation(line: 116, column: 25, scope: !1261)
!2096 = !DILocation(line: 116, column: 29, scope: !1261)
!2097 = !DILocation(line: 117, column: 21, scope: !1261)
!2098 = !DILocation(line: 117, column: 25, scope: !1261)
!2099 = !DILocation(line: 117, column: 29, scope: !1261)
!2100 = !DILocation(line: 118, column: 21, scope: !1261)
!2101 = !DILocation(line: 118, column: 25, scope: !1261)
!2102 = !DILocation(line: 118, column: 29, scope: !1261)
!2103 = !DILocation(line: 119, column: 21, scope: !1261)
!2104 = !DILocation(line: 119, column: 25, scope: !1261)
!2105 = !DILocation(line: 119, column: 29, scope: !1261)
!2106 = !DILocation(line: 120, column: 21, scope: !1261)
!2107 = !DILocation(line: 120, column: 25, scope: !1261)
!2108 = !DILocation(line: 120, column: 29, scope: !1261)
!2109 = !DILocation(line: 121, column: 21, scope: !1261)
!2110 = !DILocation(line: 121, column: 25, scope: !1261)
!2111 = !DILocation(line: 121, column: 29, scope: !1261)
!2112 = !DILocation(line: 122, column: 21, scope: !1261)
!2113 = !DILocation(line: 122, column: 25, scope: !1261)
!2114 = !DILocation(line: 122, column: 29, scope: !1261)
!2115 = !DILocation(line: 123, column: 21, scope: !1261)
!2116 = !DILocation(line: 123, column: 25, scope: !1261)
!2117 = !DILocation(line: 123, column: 29, scope: !1261)
!2118 = !DILocation(line: 124, column: 21, scope: !1261)
!2119 = !DILocation(line: 124, column: 25, scope: !1261)
!2120 = !DILocation(line: 124, column: 29, scope: !1261)
!2121 = !DILocation(line: 127, column: 21, scope: !1261)
!2122 = !DILocation(line: 127, column: 25, scope: !1261)
!2123 = !DILocation(line: 127, column: 28, scope: !1261)
!2124 = !DILocation(line: 128, column: 21, scope: !1261)
!2125 = !DILocation(line: 128, column: 25, scope: !1261)
!2126 = !DILocation(line: 128, column: 28, scope: !1261)
!2127 = !DILocation(line: 129, column: 22, scope: !1261)
!2128 = !DILocation(line: 129, column: 26, scope: !1261)
!2129 = !DILocation(line: 129, column: 30, scope: !1261)
!2130 = !DILocation(line: 130, column: 22, scope: !1261)
!2131 = !DILocation(line: 130, column: 26, scope: !1261)
!2132 = !DILocation(line: 130, column: 30, scope: !1261)
!2133 = !DILocation(line: 131, column: 22, scope: !1261)
!2134 = !DILocation(line: 131, column: 26, scope: !1261)
!2135 = !DILocation(line: 131, column: 30, scope: !1261)
!2136 = !DILocation(line: 132, column: 22, scope: !1261)
!2137 = !DILocation(line: 132, column: 26, scope: !1261)
!2138 = !DILocation(line: 132, column: 30, scope: !1261)
!2139 = !DILocation(line: 133, column: 22, scope: !1261)
!2140 = !DILocation(line: 133, column: 26, scope: !1261)
!2141 = !DILocation(line: 133, column: 30, scope: !1261)
!2142 = !DILocation(line: 134, column: 22, scope: !1261)
!2143 = !DILocation(line: 134, column: 26, scope: !1261)
!2144 = !DILocation(line: 134, column: 30, scope: !1261)
!2145 = !DILocation(line: 136, column: 21, scope: !1261)
!2146 = !DILocation(line: 136, column: 25, scope: !1261)
!2147 = !DILocation(line: 136, column: 29, scope: !1261)
!2148 = !DILocation(line: 137, column: 21, scope: !1261)
!2149 = !DILocation(line: 137, column: 25, scope: !1261)
!2150 = !DILocation(line: 137, column: 29, scope: !1261)
!2151 = !DILocation(line: 138, column: 21, scope: !1261)
!2152 = !DILocation(line: 138, column: 25, scope: !1261)
!2153 = !DILocation(line: 138, column: 29, scope: !1261)
!2154 = !DILocation(line: 139, column: 21, scope: !1261)
!2155 = !DILocation(line: 139, column: 25, scope: !1261)
!2156 = !DILocation(line: 139, column: 29, scope: !1261)
!2157 = !DILocation(line: 140, column: 21, scope: !1261)
!2158 = !DILocation(line: 140, column: 25, scope: !1261)
!2159 = !DILocation(line: 140, column: 29, scope: !1261)
!2160 = !DILocation(line: 141, column: 21, scope: !1261)
!2161 = !DILocation(line: 141, column: 25, scope: !1261)
!2162 = !DILocation(line: 141, column: 29, scope: !1261)
!2163 = !DILocation(line: 142, column: 21, scope: !1261)
!2164 = !DILocation(line: 142, column: 25, scope: !1261)
!2165 = !DILocation(line: 142, column: 29, scope: !1261)
!2166 = !DILocation(line: 143, column: 21, scope: !1261)
!2167 = !DILocation(line: 143, column: 25, scope: !1261)
!2168 = !DILocation(line: 143, column: 29, scope: !1261)
!2169 = !DILocation(line: 144, column: 20, scope: !1261)
!2170 = !DILocation(line: 144, column: 24, scope: !1261)
!2171 = !DILocation(line: 144, column: 27, scope: !1261)
!2172 = !DILocation(line: 145, column: 20, scope: !1261)
!2173 = !DILocation(line: 145, column: 24, scope: !1261)
!2174 = !DILocation(line: 145, column: 27, scope: !1261)
!2175 = !DILocation(line: 146, column: 21, scope: !1261)
!2176 = !DILocation(line: 146, column: 25, scope: !1261)
!2177 = !DILocation(line: 146, column: 29, scope: !1261)
!2178 = !DILocation(line: 147, column: 21, scope: !1261)
!2179 = !DILocation(line: 147, column: 25, scope: !1261)
!2180 = !DILocation(line: 147, column: 29, scope: !1261)
!2181 = !DILocation(line: 148, column: 21, scope: !1261)
!2182 = !DILocation(line: 148, column: 25, scope: !1261)
!2183 = !DILocation(line: 148, column: 29, scope: !1261)
!2184 = !DILocation(line: 149, column: 21, scope: !1261)
!2185 = !DILocation(line: 149, column: 25, scope: !1261)
!2186 = !DILocation(line: 149, column: 29, scope: !1261)
!2187 = !DILocation(line: 150, column: 21, scope: !1261)
!2188 = !DILocation(line: 150, column: 25, scope: !1261)
!2189 = !DILocation(line: 150, column: 29, scope: !1261)
!2190 = !DILocation(line: 151, column: 21, scope: !1261)
!2191 = !DILocation(line: 151, column: 25, scope: !1261)
!2192 = !DILocation(line: 151, column: 29, scope: !1261)
!2193 = !DILocation(line: 152, column: 21, scope: !1261)
!2194 = !DILocation(line: 152, column: 25, scope: !1261)
!2195 = !DILocation(line: 152, column: 29, scope: !1261)
!2196 = !DILocation(line: 155, column: 20, scope: !1261)
!2197 = !DILocation(line: 155, column: 24, scope: !1261)
!2198 = !DILocation(line: 155, column: 27, scope: !1261)
!2199 = !DILocation(line: 156, column: 20, scope: !1261)
!2200 = !DILocation(line: 156, column: 24, scope: !1261)
!2201 = !DILocation(line: 156, column: 27, scope: !1261)
!2202 = !DILocation(line: 157, column: 20, scope: !1261)
!2203 = !DILocation(line: 157, column: 24, scope: !1261)
!2204 = !DILocation(line: 157, column: 27, scope: !1261)
!2205 = !DILocation(line: 158, column: 20, scope: !1261)
!2206 = !DILocation(line: 158, column: 24, scope: !1261)
!2207 = !DILocation(line: 158, column: 27, scope: !1261)
!2208 = !DILocation(line: 159, column: 20, scope: !1261)
!2209 = !DILocation(line: 159, column: 24, scope: !1261)
!2210 = !DILocation(line: 159, column: 27, scope: !1261)
!2211 = !DILocation(line: 160, column: 20, scope: !1261)
!2212 = !DILocation(line: 160, column: 24, scope: !1261)
!2213 = !DILocation(line: 160, column: 27, scope: !1261)
!2214 = !DILocation(line: 164, column: 25, scope: !1261)
!2215 = !DILocation(line: 164, column: 30, scope: !1261)
!2216 = !DILocation(line: 164, column: 38, scope: !1261)
!2217 = !DILocation(line: 165, column: 25, scope: !1261)
!2218 = !DILocation(line: 165, column: 30, scope: !1261)
!2219 = !DILocation(line: 165, column: 38, scope: !1261)
!2220 = !DILocation(line: 205, column: 22, scope: !1261)
!2221 = !DILocation(line: 205, column: 16, scope: !1261)
!2222 = !DILocation(line: 205, column: 29, scope: !1261)
!2223 = !DILocation(line: 206, column: 22, scope: !1261)
!2224 = !DILocation(line: 206, column: 16, scope: !1261)
!2225 = !DILocation(line: 206, column: 29, scope: !1261)
!2226 = !DILocation(line: 207, column: 22, scope: !1261)
!2227 = !DILocation(line: 207, column: 16, scope: !1261)
!2228 = !DILocation(line: 207, column: 29, scope: !1261)
!2229 = !DILocation(line: 208, column: 22, scope: !1261)
!2230 = !DILocation(line: 208, column: 16, scope: !1261)
!2231 = !DILocation(line: 208, column: 29, scope: !1261)
!2232 = !DILocation(line: 209, column: 22, scope: !1261)
!2233 = !DILocation(line: 209, column: 16, scope: !1261)
!2234 = !DILocation(line: 209, column: 29, scope: !1261)
!2235 = !DILocation(line: 210, column: 22, scope: !1261)
!2236 = !DILocation(line: 210, column: 16, scope: !1261)
!2237 = !DILocation(line: 210, column: 29, scope: !1261)
!2238 = !DILocation(line: 211, column: 22, scope: !1261)
!2239 = !DILocation(line: 211, column: 16, scope: !1261)
!2240 = !DILocation(line: 211, column: 29, scope: !1261)
!2241 = !DILocation(line: 212, column: 22, scope: !1261)
!2242 = !DILocation(line: 212, column: 16, scope: !1261)
!2243 = !DILocation(line: 212, column: 29, scope: !1261)
!2244 = !DILocation(line: 214, column: 22, scope: !1261)
!2245 = !DILocation(line: 214, column: 16, scope: !1261)
!2246 = !DILocation(line: 214, column: 29, scope: !1261)
!2247 = !DILocation(line: 215, column: 22, scope: !1261)
!2248 = !DILocation(line: 215, column: 16, scope: !1261)
!2249 = !DILocation(line: 215, column: 29, scope: !1261)
!2250 = !DILocation(line: 216, column: 23, scope: !1261)
!2251 = !DILocation(line: 216, column: 17, scope: !1261)
!2252 = !DILocation(line: 216, column: 31, scope: !1261)
!2253 = !DILocation(line: 217, column: 23, scope: !1261)
!2254 = !DILocation(line: 217, column: 17, scope: !1261)
!2255 = !DILocation(line: 217, column: 31, scope: !1261)
!2256 = !DILocation(line: 218, column: 23, scope: !1261)
!2257 = !DILocation(line: 218, column: 17, scope: !1261)
!2258 = !DILocation(line: 218, column: 31, scope: !1261)
!2259 = !DILocation(line: 219, column: 23, scope: !1261)
!2260 = !DILocation(line: 219, column: 17, scope: !1261)
!2261 = !DILocation(line: 219, column: 31, scope: !1261)
!2262 = !DILocation(line: 220, column: 23, scope: !1261)
!2263 = !DILocation(line: 220, column: 17, scope: !1261)
!2264 = !DILocation(line: 220, column: 31, scope: !1261)
!2265 = !DILocation(line: 221, column: 23, scope: !1261)
!2266 = !DILocation(line: 221, column: 17, scope: !1261)
!2267 = !DILocation(line: 221, column: 31, scope: !1261)
!2268 = !DILocation(line: 245, column: 22, scope: !1261)
!2269 = !DILocation(line: 245, column: 16, scope: !1261)
!2270 = !DILocation(line: 245, column: 29, scope: !1261)
!2271 = !DILocation(line: 246, column: 22, scope: !1261)
!2272 = !DILocation(line: 246, column: 16, scope: !1261)
!2273 = !DILocation(line: 246, column: 29, scope: !1261)
!2274 = !DILocation(line: 247, column: 22, scope: !1261)
!2275 = !DILocation(line: 247, column: 16, scope: !1261)
!2276 = !DILocation(line: 247, column: 29, scope: !1261)
!2277 = !DILocation(line: 248, column: 22, scope: !1261)
!2278 = !DILocation(line: 248, column: 16, scope: !1261)
!2279 = !DILocation(line: 248, column: 29, scope: !1261)
!2280 = !DILocation(line: 249, column: 22, scope: !1261)
!2281 = !DILocation(line: 249, column: 16, scope: !1261)
!2282 = !DILocation(line: 249, column: 29, scope: !1261)
!2283 = !DILocation(line: 250, column: 22, scope: !1261)
!2284 = !DILocation(line: 250, column: 16, scope: !1261)
!2285 = !DILocation(line: 250, column: 29, scope: !1261)
!2286 = !DILocation(line: 251, column: 22, scope: !1261)
!2287 = !DILocation(line: 251, column: 16, scope: !1261)
!2288 = !DILocation(line: 251, column: 29, scope: !1261)
!2289 = !DILocation(line: 252, column: 22, scope: !1261)
!2290 = !DILocation(line: 252, column: 16, scope: !1261)
!2291 = !DILocation(line: 252, column: 29, scope: !1261)
!2292 = !DILocation(line: 255, column: 22, scope: !1261)
!2293 = !DILocation(line: 255, column: 16, scope: !1261)
!2294 = !DILocation(line: 255, column: 29, scope: !1261)
!2295 = !DILocation(line: 256, column: 22, scope: !1261)
!2296 = !DILocation(line: 256, column: 16, scope: !1261)
!2297 = !DILocation(line: 256, column: 29, scope: !1261)
!2298 = !DILocation(line: 257, column: 23, scope: !1261)
!2299 = !DILocation(line: 257, column: 17, scope: !1261)
!2300 = !DILocation(line: 257, column: 31, scope: !1261)
!2301 = !DILocation(line: 258, column: 23, scope: !1261)
!2302 = !DILocation(line: 258, column: 17, scope: !1261)
!2303 = !DILocation(line: 258, column: 31, scope: !1261)
!2304 = !DILocation(line: 259, column: 23, scope: !1261)
!2305 = !DILocation(line: 259, column: 17, scope: !1261)
!2306 = !DILocation(line: 259, column: 31, scope: !1261)
!2307 = !DILocation(line: 260, column: 23, scope: !1261)
!2308 = !DILocation(line: 260, column: 17, scope: !1261)
!2309 = !DILocation(line: 260, column: 31, scope: !1261)
!2310 = !DILocation(line: 261, column: 23, scope: !1261)
!2311 = !DILocation(line: 261, column: 17, scope: !1261)
!2312 = !DILocation(line: 261, column: 31, scope: !1261)
!2313 = !DILocation(line: 262, column: 23, scope: !1261)
!2314 = !DILocation(line: 262, column: 17, scope: !1261)
!2315 = !DILocation(line: 262, column: 31, scope: !1261)
!2316 = !DILocation(line: 285, column: 21, scope: !1261)
!2317 = !DILocation(line: 285, column: 24, scope: !1261)
!2318 = !DILocation(line: 285, column: 15, scope: !1261)
!2319 = !DILocation(line: 285, column: 33, scope: !1261)
!2320 = !DILocation(line: 286, column: 21, scope: !1261)
!2321 = !DILocation(line: 286, column: 24, scope: !1261)
!2322 = !DILocation(line: 286, column: 15, scope: !1261)
!2323 = !DILocation(line: 286, column: 33, scope: !1261)
!2324 = !DILocation(line: 287, column: 21, scope: !1261)
!2325 = !DILocation(line: 287, column: 24, scope: !1261)
!2326 = !DILocation(line: 287, column: 15, scope: !1261)
!2327 = !DILocation(line: 287, column: 33, scope: !1261)
!2328 = !DILocation(line: 288, column: 21, scope: !1261)
!2329 = !DILocation(line: 288, column: 24, scope: !1261)
!2330 = !DILocation(line: 288, column: 15, scope: !1261)
!2331 = !DILocation(line: 288, column: 33, scope: !1261)
!2332 = !DILocation(line: 289, column: 21, scope: !1261)
!2333 = !DILocation(line: 289, column: 24, scope: !1261)
!2334 = !DILocation(line: 289, column: 15, scope: !1261)
!2335 = !DILocation(line: 289, column: 33, scope: !1261)
!2336 = !DILocation(line: 290, column: 21, scope: !1261)
!2337 = !DILocation(line: 290, column: 24, scope: !1261)
!2338 = !DILocation(line: 290, column: 15, scope: !1261)
!2339 = !DILocation(line: 290, column: 33, scope: !1261)
!2340 = !DILocation(line: 291, column: 21, scope: !1261)
!2341 = !DILocation(line: 291, column: 24, scope: !1261)
!2342 = !DILocation(line: 291, column: 15, scope: !1261)
!2343 = !DILocation(line: 291, column: 33, scope: !1261)
!2344 = !DILocation(line: 292, column: 21, scope: !1261)
!2345 = !DILocation(line: 292, column: 24, scope: !1261)
!2346 = !DILocation(line: 292, column: 15, scope: !1261)
!2347 = !DILocation(line: 292, column: 33, scope: !1261)
!2348 = !DILocation(line: 318, column: 21, scope: !1261)
!2349 = !DILocation(line: 318, column: 25, scope: !1261)
!2350 = !DILocation(line: 318, column: 15, scope: !1261)
!2351 = !DILocation(line: 318, column: 34, scope: !1261)
!2352 = !DILocation(line: 318, column: 38, scope: !1261)
!2353 = !DILocation(line: 318, column: 45, scope: !1261)
!2354 = !DILocation(line: 319, column: 21, scope: !1261)
!2355 = !DILocation(line: 319, column: 25, scope: !1261)
!2356 = !DILocation(line: 319, column: 15, scope: !1261)
!2357 = !DILocation(line: 319, column: 34, scope: !1261)
!2358 = !DILocation(line: 319, column: 38, scope: !1261)
!2359 = !DILocation(line: 319, column: 45, scope: !1261)
!2360 = !DILocation(line: 320, column: 21, scope: !1261)
!2361 = !DILocation(line: 320, column: 25, scope: !1261)
!2362 = !DILocation(line: 320, column: 15, scope: !1261)
!2363 = !DILocation(line: 320, column: 34, scope: !1261)
!2364 = !DILocation(line: 320, column: 38, scope: !1261)
!2365 = !DILocation(line: 320, column: 45, scope: !1261)
!2366 = !DILocation(line: 321, column: 21, scope: !1261)
!2367 = !DILocation(line: 321, column: 25, scope: !1261)
!2368 = !DILocation(line: 321, column: 15, scope: !1261)
!2369 = !DILocation(line: 321, column: 34, scope: !1261)
!2370 = !DILocation(line: 321, column: 38, scope: !1261)
!2371 = !DILocation(line: 321, column: 45, scope: !1261)
!2372 = !DILocation(line: 322, column: 21, scope: !1261)
!2373 = !DILocation(line: 322, column: 25, scope: !1261)
!2374 = !DILocation(line: 322, column: 15, scope: !1261)
!2375 = !DILocation(line: 322, column: 34, scope: !1261)
!2376 = !DILocation(line: 322, column: 38, scope: !1261)
!2377 = !DILocation(line: 322, column: 45, scope: !1261)
!2378 = !DILocation(line: 323, column: 21, scope: !1261)
!2379 = !DILocation(line: 323, column: 25, scope: !1261)
!2380 = !DILocation(line: 323, column: 15, scope: !1261)
!2381 = !DILocation(line: 323, column: 34, scope: !1261)
!2382 = !DILocation(line: 323, column: 38, scope: !1261)
!2383 = !DILocation(line: 323, column: 45, scope: !1261)
!2384 = !DILocation(line: 324, column: 21, scope: !1261)
!2385 = !DILocation(line: 324, column: 25, scope: !1261)
!2386 = !DILocation(line: 324, column: 15, scope: !1261)
!2387 = !DILocation(line: 324, column: 34, scope: !1261)
!2388 = !DILocation(line: 324, column: 38, scope: !1261)
!2389 = !DILocation(line: 324, column: 45, scope: !1261)
!2390 = !DILocation(line: 325, column: 21, scope: !1261)
!2391 = !DILocation(line: 325, column: 25, scope: !1261)
!2392 = !DILocation(line: 325, column: 15, scope: !1261)
!2393 = !DILocation(line: 325, column: 34, scope: !1261)
!2394 = !DILocation(line: 325, column: 38, scope: !1261)
!2395 = !DILocation(line: 325, column: 45, scope: !1261)
!2396 = !DILocation(line: 328, column: 20, scope: !1261)
!2397 = !DILocation(line: 328, column: 26, scope: !1261)
!2398 = !DILocation(line: 329, column: 20, scope: !1261)
!2399 = !DILocation(line: 329, column: 26, scope: !1261)
!2400 = !DILocation(line: 330, column: 20, scope: !1261)
!2401 = !DILocation(line: 330, column: 26, scope: !1261)
!2402 = !DILocation(line: 331, column: 20, scope: !1261)
!2403 = !DILocation(line: 331, column: 26, scope: !1261)
!2404 = !DILocation(line: 332, column: 20, scope: !1261)
!2405 = !DILocation(line: 332, column: 26, scope: !1261)
!2406 = !DILocation(line: 333, column: 20, scope: !1261)
!2407 = !DILocation(line: 333, column: 26, scope: !1261)
!2408 = !DILocation(line: 334, column: 20, scope: !1261)
!2409 = !DILocation(line: 334, column: 26, scope: !1261)
!2410 = !DILocation(line: 337, column: 9, scope: !1261)
!2411 = !DILocation(line: 338, column: 9, scope: !1261)
!2412 = !DILocation(line: 339, column: 9, scope: !1261)
!2413 = !DILocation(line: 340, column: 9, scope: !1261)
!2414 = !DILocation(line: 341, column: 9, scope: !1261)
!2415 = !DILocation(line: 342, column: 9, scope: !1261)
!2416 = !DILocation(line: 343, column: 9, scope: !1261)
!2417 = !DILocation(line: 344, column: 9, scope: !1261)
!2418 = !DILocation(line: 347, column: 9, scope: !1261)
!2419 = !DILocation(line: 348, column: 9, scope: !1261)
!2420 = !DILocation(line: 349, column: 9, scope: !1261)
!2421 = !DILocation(line: 350, column: 9, scope: !1261)
!2422 = !DILocation(line: 351, column: 9, scope: !1261)
!2423 = !DILocation(line: 353, column: 9, scope: !1261)
!2424 = !DILocation(line: 357, column: 3, scope: !1261)
!2425 = distinct !DISubprogram(name: "__remill_intrinsics", scope: !2426, file: !2426, line: 35, type: !95, isLocal: false, isDefinition: true, scopeLine: 35, flags: DIFlagPrototyped, isOptimized: false, unit: !1, variables: !7)
!2426 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/Intrinsics.cpp", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!2427 = !DILocation(line: 116, column: 1, scope: !2425)
!2428 = !{!2429, !2429, i64 0}
!2429 = !{!"long", !2430, i64 0}
!2430 = !{!"omnipotent char", !2431, i64 0}
!2431 = !{!"Simple C++ TBAA"}
!2432 = !{!2433, !2430, i64 2065}
!2433 = !{!"_ZTS5State", !2430, i64 16, !2434, i64 2064, !2430, i64 2080, !2435, i64 2088, !2437, i64 2112, !2439, i64 2208, !2440, i64 2480, !2441, i64 2608, !2442, i64 2736, !2430, i64 2760, !2430, i64 2768, !2443, i64 3280}
!2434 = !{!"_ZTS10ArithFlags", !2430, i64 0, !2430, i64 1, !2430, i64 2, !2430, i64 3, !2430, i64 4, !2430, i64 5, !2430, i64 6, !2430, i64 7, !2430, i64 8, !2430, i64 9, !2430, i64 10, !2430, i64 11, !2430, i64 12, !2430, i64 13, !2430, i64 14, !2430, i64 15}
!2435 = !{!"_ZTS8Segments", !2436, i64 0, !2430, i64 2, !2436, i64 4, !2430, i64 6, !2436, i64 8, !2430, i64 10, !2436, i64 12, !2430, i64 14, !2436, i64 16, !2430, i64 18, !2436, i64 20, !2430, i64 22}
!2436 = !{!"short", !2430, i64 0}
!2437 = !{!"_ZTS12AddressSpace", !2429, i64 0, !2438, i64 8, !2429, i64 16, !2438, i64 24, !2429, i64 32, !2438, i64 40, !2429, i64 48, !2438, i64 56, !2429, i64 64, !2438, i64 72, !2429, i64 80, !2438, i64 88}
!2438 = !{!"_ZTS3Reg", !2430, i64 0}
!2439 = !{!"_ZTS3GPR", !2429, i64 0, !2438, i64 8, !2429, i64 16, !2438, i64 24, !2429, i64 32, !2438, i64 40, !2429, i64 48, !2438, i64 56, !2429, i64 64, !2438, i64 72, !2429, i64 80, !2438, i64 88, !2429, i64 96, !2438, i64 104, !2429, i64 112, !2438, i64 120, !2429, i64 128, !2438, i64 136, !2429, i64 144, !2438, i64 152, !2429, i64 160, !2438, i64 168, !2429, i64 176, !2438, i64 184, !2429, i64 192, !2438, i64 200, !2429, i64 208, !2438, i64 216, !2429, i64 224, !2438, i64 232, !2429, i64 240, !2438, i64 248, !2429, i64 256, !2438, i64 264}
!2440 = !{!"_ZTS8X87Stack", !2430, i64 0}
!2441 = !{!"_ZTS3MMX", !2430, i64 0}
!2442 = !{!"_ZTS14FPUStatusFlags", !2430, i64 0, !2430, i64 1, !2430, i64 2, !2430, i64 3, !2430, i64 4, !2430, i64 5, !2430, i64 6, !2430, i64 7, !2430, i64 8, !2430, i64 9, !2430, i64 10, !2430, i64 11, !2430, i64 12, !2430, i64 13, !2430, i64 14, !2430, i64 15, !2430, i64 16, !2430, i64 17, !2430, i64 18, !2430, i64 19, !2430, i64 20}
!2443 = !{!"_ZTS13SegmentCaches", !2444, i64 0, !2444, i64 16, !2444, i64 32, !2444, i64 48, !2444, i64 64, !2444, i64 80}
!2444 = !{!"_ZTS13SegmentShadow", !2430, i64 0, !2445, i64 8, !2445, i64 12}
!2445 = !{!"int", !2430, i64 0}
!2446 = !{!2433, !2430, i64 2067}
!2447 = !{!2433, !2430, i64 2069}
!2448 = !{!2433, !2430, i64 2071}
!2449 = !{!2433, !2430, i64 2073}
!2450 = !{!2433, !2430, i64 2077}
!2451 = !{!2452, !2452, i64 0}
!2452 = !{!"double", !2430, i64 0}
!2453 = !{!2430, !2430, i64 0}
!2454 = !{!2455}
!2455 = distinct !{!2455, !2456, !"ext_6050b8_cos: argument 0"}
!2456 = distinct !{!2456, !"ext_6050b8_cos"}
!2457 = !{!2458}
!2458 = distinct !{!2458, !2456, !"ext_6050b8_cos: argument 1"}
!2459 = !{!2460}
!2460 = distinct !{!2460, !2461, !"ext_6050d8_sin: argument 0"}
!2461 = distinct !{!2461, !"ext_6050d8_sin"}
!2462 = !{!2463}
!2463 = distinct !{!2463, !2461, !"ext_6050d8_sin: argument 1"}
!2464 = !{!2465}
!2465 = distinct !{!2465, !2466, !"ext_6050f8_atan: argument 0"}
!2466 = distinct !{!2466, !"ext_6050f8_atan"}
!2467 = !{!2468}
!2468 = distinct !{!2468, !2466, !"ext_6050f8_atan: argument 1"}
!2469 = !{!2445, !2445, i64 0}
!2470 = !{!2471}
!2471 = distinct !{!2471, !2472, !"ext_6050b8_cos: argument 0"}
!2472 = distinct !{!2472, !"ext_6050b8_cos"}
!2473 = !{!2474}
!2474 = distinct !{!2474, !2472, !"ext_6050b8_cos: argument 1"}
!2475 = !{!2476, !2476, i64 0}
!2476 = !{!"float", !2430, i64 0}
!2477 = !{!2478}
!2478 = distinct !{!2478, !2479, !"ext_605140_sqrt: argument 0"}
!2479 = distinct !{!2479, !"ext_605140_sqrt"}
!2480 = !{!2481}
!2481 = distinct !{!2481, !2479, !"ext_605140_sqrt: argument 1"}
