; ModuleID = 'binary/test.mcsema.inline.ll'
source_filename = "llvm-link"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu-elf"

%union.anon = type { i64 }
%seg_402e80__rodata_type = type <{ [112 x i8], [7 x i8], [51 x i8], [8 x i8], [84 x i8] }>
%seg_603df0__init_array_type = type <{ i64, i64 }>
%seg_603ff0__got_type = type <{ i64, i64 }>
%seg_604060__bss_type = type <{ [8 x i8], [8 x i8] }>
%polybench_papi_counters_threadid_type = type <{ [8 x i8] }>
%polybench_program_total_flops_type = type <{ [8 x i8] }>
%polybench_c_end_type = type <{ [8 x i8] }>
%polybench_t_end_type = type <{ [8 x i8] }>
%polybench_t_start_type = type <{ [8 x i8] }>
%polybench_c_start_type = type <{ [8 x i8] }>
%struct.State = type { %struct.ArchState, [32 x %union.VectorReg], %struct.ArithFlags, %union.anon, %struct.Segments, %struct.AddressSpace, %struct.GPR, %struct.X87Stack, %struct.MMX, %struct.FPUStatusFlags, %union.anon, %union.FPU, %struct.SegmentCaches }
%struct.ArchState = type { i32, i32, %union.anon }
%union.VectorReg = type { %union.vec512_t }
%union.vec512_t = type { %struct.uint64v8_t }
%struct.uint64v8_t = type { [8 x i64] }
%struct.ArithFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8 }
%struct.Segments = type { i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector, i16, %union.SegmentSelector }
%union.SegmentSelector = type { i16 }
%struct.AddressSpace = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.Reg = type { %union.anon }
%struct.GPR = type { i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg, i64, %struct.Reg }
%struct.X87Stack = type { [8 x %struct.anon.3] }
%struct.anon.3 = type { i64, double }
%struct.MMX = type { [8 x %struct.anon.4] }
%struct.anon.4 = type { i64, %union.vec64_t }
%union.vec64_t = type { %struct.uint64v1_t }
%struct.uint64v1_t = type { [1 x i64] }
%struct.FPUStatusFlags = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, [4 x i8] }
%union.FPU = type { %struct.anon.13 }
%struct.anon.13 = type { %struct.FpuFXSAVE, [96 x i8] }
%struct.FpuFXSAVE = type { %union.SegmentSelector, %union.SegmentSelector, %union.FPUAbridgedTagWord, i8, i16, i32, %union.SegmentSelector, i16, i32, %union.SegmentSelector, i16, %union.FPUControlStatus, %union.FPUControlStatus, [8 x %struct.FPUStackElem], [16 x %union.vec128_t] }
%union.FPUAbridgedTagWord = type { i8 }
%union.FPUControlStatus = type { i32 }
%struct.FPUStackElem = type { %union.anon.11, [6 x i8] }
%union.anon.11 = type { %struct.float80_t }
%struct.float80_t = type { [10 x i8] }
%union.vec128_t = type { %struct.uint128v1_t }
%struct.uint128v1_t = type { [1 x i128] }
%struct.SegmentCaches = type { %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow, %struct.SegmentShadow }
%struct.SegmentShadow = type { %union.anon, i32, i32 }
%struct.Memory = type opaque
%struct.anon.2 = type { i8, i8 }
%"class.std::bitset" = type { %struct.uint64v4_t }
%struct.uint64v4_t = type { [4 x i64] }

@DR0 = external global i64, align 8
@DR1 = external global i64, align 8
@DR2 = external global i64, align 8
@DR3 = external global i64, align 8
@DR4 = external global i64, align 8
@DR5 = external global i64, align 8
@DR6 = external global i64, align 8
@DR7 = external global i64, align 8
@gCR0 = external global %union.anon, align 1
@gCR1 = external global %union.anon, align 1
@gCR2 = external global %union.anon, align 1
@gCR3 = external global %union.anon, align 1
@gCR4 = external global %union.anon, align 1
@gCR8 = external global %union.anon, align 1
@stderr = external local_unnamed_addr global i64, align 32
@seg_402e80__rodata = internal constant %seg_402e80__rodata_type <{ [112 x i8] c"\01\00\02\00\00\00\00\00\00\00\00\00\00\00E@\00\00\00\00\00J\A2@\00\00\00\00\00\00&@\00\00\00\00\00\00$@\00\00\00\00\00\00\08@\00\00\00\00\00\00\00@\00\00\00\00\00\00\F0?\00\00\00\00\00\00\18@\00\00\00\00\00\00\14@\00\00\00\00\00\00\10@\F1h\E3\88\B5\F8\E4>\FF\FF\FF\FF\FF\FF\FF\7F\FF\FF\FF\FF\FF\FF\FF\7F", [7 x i8] c"%0.6f\0A\00", [51 x i8] c"[PolyBench] posix_memalign: cannot allocate memory\00", [8 x i8] c"%0.2lf \00", [84 x i8] c"A[%d][%d][%d] = %lf and B[%d][%d][%d] = %lf differ more than FP_ABSTOLERANCE = %lf\0A\00" }>
@seg_603df0__init_array = internal global %seg_603df0__init_array_type <{ i64 ptrtoint (void ()* @callback_sub_400690_frame_dummy to i64), i64 ptrtoint (void ()* @callback_sub_400660___do_global_dtors_aux to i64) }>
@seg_603ff0__got = internal global %seg_603ff0__got_type <{ i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64)* @__libc_start_main to i64), i64 ptrtoint (i64 ()* @__gmon_start__ to i64) }>
@seg_604060__bss = internal global %seg_604060__bss_type zeroinitializer
@polybench_papi_counters_threadid = local_unnamed_addr global %polybench_papi_counters_threadid_type zeroinitializer
@polybench_program_total_flops = local_unnamed_addr global %polybench_program_total_flops_type zeroinitializer
@polybench_c_end = local_unnamed_addr global %polybench_c_end_type zeroinitializer
@polybench_t_end = local_unnamed_addr global %polybench_t_end_type zeroinitializer
@polybench_t_start = local_unnamed_addr global %polybench_t_start_type zeroinitializer
@polybench_c_start = local_unnamed_addr global %polybench_c_start_type zeroinitializer
@0 = internal global i1 false
@1 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_400690_frame_dummy_wrapper
@2 = internal constant void ()* @__mcsema_attach_call
@3 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_400660___do_global_dtors_aux_wrapper
@4 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_402e70___libc_csu_fini_wrapper
@5 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @callback_sub_402e00___libc_csu_init_wrapper
@6 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @main_wrapper
@7 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @polybench_flush_cache_wrapper
@8 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @.term_proc_wrapper
@9 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @polybench_timer_stop_wrapper
@10 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @polybench_alloc_data_wrapper
@11 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @polybench_timer_print_wrapper
@12 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @.init_proc_wrapper
@13 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @polybench_timer_start_wrapper
@14 = internal constant %struct.Memory* (%struct.State*, i64, %struct.Memory*)* @polybench_prepare_instruments_wrapper
@llvm.global_ctors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 101, void ()* @__mcsema_constructor, i8* null }]
@llvm.global_dtors = appending global [1 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 101, void ()* @__mcsema_destructor, i8* null }]

declare %struct.Memory* @sub_400750_rtclock_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400800_xmalloc_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400720_polybench_prepare_instruments_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_401f10_kernel_fdtd_apml_StrictFP_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4006a0_polybench_flush_cache_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_402a50_check_FP_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_402bf0_print_array_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4005f0_deregister_tm_clones_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_4013d0_kernel_fdtd_apml_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400f90_init_array_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

declare %struct.Memory* @sub_400520__init_proc_renamed_(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias readnone returned) local_unnamed_addr

; Function Attrs: nounwind readnone
declare i32 @llvm.ctpop.i32(i32) #0

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_error(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #1

; Function Attrs: noinline nounwind optnone
define %struct.Memory* @__remill_basic_block(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #2 !dbg !1261 {
  %state = alloca %struct.State*, align 8
  %curr_pc = alloca i64, align 8
  %memory = alloca %struct.Memory*, align 8
  %BRANCH_TAKEN = alloca i8, align 1
  %SS_BASE = alloca i64, align 8
  %ES_BASE = alloca i64, align 8
  %DS_BASE = alloca i64, align 8
  %CS_BASE = alloca i64, align 8
  %STATE = alloca %struct.State*, align 8
  %MEMORY = alloca %struct.Memory*, align 8
  %_DR0 = alloca i64*, align 8
  %_DR1 = alloca i64*, align 8
  %_DR2 = alloca i64*, align 8
  %_DR3 = alloca i64*, align 8
  %_DR4 = alloca i64*, align 8
  %_DR5 = alloca i64*, align 8
  %_DR6 = alloca i64*, align 8
  %_DR7 = alloca i64*, align 8
  %CR0 = alloca i64*, align 8
  %CR1 = alloca i64*, align 8
  %CR2 = alloca i64*, align 8
  %CR3 = alloca i64*, align 8
  %CR4 = alloca i64*, align 8
  %CR8 = alloca i64*, align 8
  store %struct.State* %0, %struct.State** %state, align 8
  store i64 %1, i64* %curr_pc, align 8
  store %struct.Memory* %2, %struct.Memory** %memory, align 8
  store i8 0, i8* %BRANCH_TAKEN, align 1, !dbg !1952
  store i64 0, i64* %SS_BASE, align 8, !dbg !1953
  store i64 0, i64* %ES_BASE, align 8, !dbg !1954
  store i64 0, i64* %DS_BASE, align 8, !dbg !1955
  store i64 0, i64* %CS_BASE, align 8, !dbg !1956
  store %struct.State* %0, %struct.State** %STATE, align 8, !dbg !1957
  store %struct.Memory* %2, %struct.Memory** %MEMORY, align 8, !dbg !1958
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1959
  %5 = getelementptr inbounds %struct.GPR, %struct.GPR* %4, i32 0, i32 33, !dbg !1960
  %6 = getelementptr inbounds %struct.Reg, %struct.Reg* %5, i32 0, i32 0, !dbg !1961
  %PC = bitcast %union.anon* %6 to i64*, !dbg !1961
  store i64 %1, i64* %PC, align 8, !dbg !1962
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1963
  %8 = getelementptr inbounds %struct.GPR, %struct.GPR* %7, i32 0, i32 1, !dbg !1964
  %9 = getelementptr inbounds %struct.Reg, %struct.Reg* %8, i32 0, i32 0, !dbg !1965
  %10 = bitcast %union.anon* %9 to %struct.anon.2*, !dbg !1965
  %AH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %10, i32 0, i32 1, !dbg !1966
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1967
  %12 = getelementptr inbounds %struct.GPR, %struct.GPR* %11, i32 0, i32 3, !dbg !1968
  %13 = getelementptr inbounds %struct.Reg, %struct.Reg* %12, i32 0, i32 0, !dbg !1969
  %14 = bitcast %union.anon* %13 to %struct.anon.2*, !dbg !1969
  %BH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %14, i32 0, i32 1, !dbg !1970
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1971
  %16 = getelementptr inbounds %struct.GPR, %struct.GPR* %15, i32 0, i32 5, !dbg !1972
  %17 = getelementptr inbounds %struct.Reg, %struct.Reg* %16, i32 0, i32 0, !dbg !1973
  %18 = bitcast %union.anon* %17 to %struct.anon.2*, !dbg !1973
  %CH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %18, i32 0, i32 1, !dbg !1974
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1975
  %20 = getelementptr inbounds %struct.GPR, %struct.GPR* %19, i32 0, i32 7, !dbg !1976
  %21 = getelementptr inbounds %struct.Reg, %struct.Reg* %20, i32 0, i32 0, !dbg !1977
  %22 = bitcast %union.anon* %21 to %struct.anon.2*, !dbg !1977
  %DH = getelementptr inbounds %struct.anon.2, %struct.anon.2* %22, i32 0, i32 1, !dbg !1978
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1979
  %24 = getelementptr inbounds %struct.GPR, %struct.GPR* %23, i32 0, i32 1, !dbg !1980
  %25 = getelementptr inbounds %struct.Reg, %struct.Reg* %24, i32 0, i32 0, !dbg !1981
  %26 = bitcast %union.anon* %25 to %struct.anon.2*, !dbg !1981
  %AL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %26, i32 0, i32 0, !dbg !1982
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1983
  %28 = getelementptr inbounds %struct.GPR, %struct.GPR* %27, i32 0, i32 3, !dbg !1984
  %29 = getelementptr inbounds %struct.Reg, %struct.Reg* %28, i32 0, i32 0, !dbg !1985
  %30 = bitcast %union.anon* %29 to %struct.anon.2*, !dbg !1985
  %BL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %30, i32 0, i32 0, !dbg !1986
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1987
  %32 = getelementptr inbounds %struct.GPR, %struct.GPR* %31, i32 0, i32 5, !dbg !1988
  %33 = getelementptr inbounds %struct.Reg, %struct.Reg* %32, i32 0, i32 0, !dbg !1989
  %34 = bitcast %union.anon* %33 to %struct.anon.2*, !dbg !1989
  %CL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %34, i32 0, i32 0, !dbg !1990
  %35 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1991
  %36 = getelementptr inbounds %struct.GPR, %struct.GPR* %35, i32 0, i32 7, !dbg !1992
  %37 = getelementptr inbounds %struct.Reg, %struct.Reg* %36, i32 0, i32 0, !dbg !1993
  %38 = bitcast %union.anon* %37 to %struct.anon.2*, !dbg !1993
  %DL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %38, i32 0, i32 0, !dbg !1994
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1995
  %40 = getelementptr inbounds %struct.GPR, %struct.GPR* %39, i32 0, i32 9, !dbg !1996
  %41 = getelementptr inbounds %struct.Reg, %struct.Reg* %40, i32 0, i32 0, !dbg !1997
  %42 = bitcast %union.anon* %41 to %struct.anon.2*, !dbg !1997
  %SIL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %42, i32 0, i32 0, !dbg !1998
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !1999
  %44 = getelementptr inbounds %struct.GPR, %struct.GPR* %43, i32 0, i32 11, !dbg !2000
  %45 = getelementptr inbounds %struct.Reg, %struct.Reg* %44, i32 0, i32 0, !dbg !2001
  %46 = bitcast %union.anon* %45 to %struct.anon.2*, !dbg !2001
  %DIL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %46, i32 0, i32 0, !dbg !2002
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2003
  %48 = getelementptr inbounds %struct.GPR, %struct.GPR* %47, i32 0, i32 13, !dbg !2004
  %49 = getelementptr inbounds %struct.Reg, %struct.Reg* %48, i32 0, i32 0, !dbg !2005
  %50 = bitcast %union.anon* %49 to %struct.anon.2*, !dbg !2005
  %SPL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %50, i32 0, i32 0, !dbg !2006
  %51 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2007
  %52 = getelementptr inbounds %struct.GPR, %struct.GPR* %51, i32 0, i32 15, !dbg !2008
  %53 = getelementptr inbounds %struct.Reg, %struct.Reg* %52, i32 0, i32 0, !dbg !2009
  %54 = bitcast %union.anon* %53 to %struct.anon.2*, !dbg !2009
  %BPL = getelementptr inbounds %struct.anon.2, %struct.anon.2* %54, i32 0, i32 0, !dbg !2010
  %55 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2011
  %56 = getelementptr inbounds %struct.GPR, %struct.GPR* %55, i32 0, i32 17, !dbg !2012
  %57 = getelementptr inbounds %struct.Reg, %struct.Reg* %56, i32 0, i32 0, !dbg !2013
  %58 = bitcast %union.anon* %57 to %struct.anon.2*, !dbg !2013
  %R8B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %58, i32 0, i32 0, !dbg !2014
  %59 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2015
  %60 = getelementptr inbounds %struct.GPR, %struct.GPR* %59, i32 0, i32 19, !dbg !2016
  %61 = getelementptr inbounds %struct.Reg, %struct.Reg* %60, i32 0, i32 0, !dbg !2017
  %62 = bitcast %union.anon* %61 to %struct.anon.2*, !dbg !2017
  %R9B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %62, i32 0, i32 0, !dbg !2018
  %63 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2019
  %64 = getelementptr inbounds %struct.GPR, %struct.GPR* %63, i32 0, i32 21, !dbg !2020
  %65 = getelementptr inbounds %struct.Reg, %struct.Reg* %64, i32 0, i32 0, !dbg !2021
  %66 = bitcast %union.anon* %65 to %struct.anon.2*, !dbg !2021
  %R10B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %66, i32 0, i32 0, !dbg !2022
  %67 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2023
  %68 = getelementptr inbounds %struct.GPR, %struct.GPR* %67, i32 0, i32 23, !dbg !2024
  %69 = getelementptr inbounds %struct.Reg, %struct.Reg* %68, i32 0, i32 0, !dbg !2025
  %70 = bitcast %union.anon* %69 to %struct.anon.2*, !dbg !2025
  %R11B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %70, i32 0, i32 0, !dbg !2026
  %71 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2027
  %72 = getelementptr inbounds %struct.GPR, %struct.GPR* %71, i32 0, i32 25, !dbg !2028
  %73 = getelementptr inbounds %struct.Reg, %struct.Reg* %72, i32 0, i32 0, !dbg !2029
  %74 = bitcast %union.anon* %73 to %struct.anon.2*, !dbg !2029
  %R12B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %74, i32 0, i32 0, !dbg !2030
  %75 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2031
  %76 = getelementptr inbounds %struct.GPR, %struct.GPR* %75, i32 0, i32 27, !dbg !2032
  %77 = getelementptr inbounds %struct.Reg, %struct.Reg* %76, i32 0, i32 0, !dbg !2033
  %78 = bitcast %union.anon* %77 to %struct.anon.2*, !dbg !2033
  %R13B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %78, i32 0, i32 0, !dbg !2034
  %79 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2035
  %80 = getelementptr inbounds %struct.GPR, %struct.GPR* %79, i32 0, i32 29, !dbg !2036
  %81 = getelementptr inbounds %struct.Reg, %struct.Reg* %80, i32 0, i32 0, !dbg !2037
  %82 = bitcast %union.anon* %81 to %struct.anon.2*, !dbg !2037
  %R14B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %82, i32 0, i32 0, !dbg !2038
  %83 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2039
  %84 = getelementptr inbounds %struct.GPR, %struct.GPR* %83, i32 0, i32 31, !dbg !2040
  %85 = getelementptr inbounds %struct.Reg, %struct.Reg* %84, i32 0, i32 0, !dbg !2041
  %86 = bitcast %union.anon* %85 to %struct.anon.2*, !dbg !2041
  %R15B = getelementptr inbounds %struct.anon.2, %struct.anon.2* %86, i32 0, i32 0, !dbg !2042
  %87 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2043
  %88 = getelementptr inbounds %struct.GPR, %struct.GPR* %87, i32 0, i32 1, !dbg !2044
  %89 = getelementptr inbounds %struct.Reg, %struct.Reg* %88, i32 0, i32 0, !dbg !2045
  %AX = bitcast %union.anon* %89 to i16*, !dbg !2045
  %90 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2046
  %91 = getelementptr inbounds %struct.GPR, %struct.GPR* %90, i32 0, i32 3, !dbg !2047
  %92 = getelementptr inbounds %struct.Reg, %struct.Reg* %91, i32 0, i32 0, !dbg !2048
  %BX = bitcast %union.anon* %92 to i16*, !dbg !2048
  %93 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2049
  %94 = getelementptr inbounds %struct.GPR, %struct.GPR* %93, i32 0, i32 5, !dbg !2050
  %95 = getelementptr inbounds %struct.Reg, %struct.Reg* %94, i32 0, i32 0, !dbg !2051
  %CX = bitcast %union.anon* %95 to i16*, !dbg !2051
  %96 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2052
  %97 = getelementptr inbounds %struct.GPR, %struct.GPR* %96, i32 0, i32 7, !dbg !2053
  %98 = getelementptr inbounds %struct.Reg, %struct.Reg* %97, i32 0, i32 0, !dbg !2054
  %DX = bitcast %union.anon* %98 to i16*, !dbg !2054
  %99 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2055
  %100 = getelementptr inbounds %struct.GPR, %struct.GPR* %99, i32 0, i32 9, !dbg !2056
  %101 = getelementptr inbounds %struct.Reg, %struct.Reg* %100, i32 0, i32 0, !dbg !2057
  %SI = bitcast %union.anon* %101 to i16*, !dbg !2057
  %102 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2058
  %103 = getelementptr inbounds %struct.GPR, %struct.GPR* %102, i32 0, i32 11, !dbg !2059
  %104 = getelementptr inbounds %struct.Reg, %struct.Reg* %103, i32 0, i32 0, !dbg !2060
  %DI = bitcast %union.anon* %104 to i16*, !dbg !2060
  %105 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2061
  %106 = getelementptr inbounds %struct.GPR, %struct.GPR* %105, i32 0, i32 13, !dbg !2062
  %107 = getelementptr inbounds %struct.Reg, %struct.Reg* %106, i32 0, i32 0, !dbg !2063
  %SP = bitcast %union.anon* %107 to i16*, !dbg !2063
  %108 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2064
  %109 = getelementptr inbounds %struct.GPR, %struct.GPR* %108, i32 0, i32 15, !dbg !2065
  %110 = getelementptr inbounds %struct.Reg, %struct.Reg* %109, i32 0, i32 0, !dbg !2066
  %BP = bitcast %union.anon* %110 to i16*, !dbg !2066
  %111 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2067
  %112 = getelementptr inbounds %struct.GPR, %struct.GPR* %111, i32 0, i32 17, !dbg !2068
  %113 = getelementptr inbounds %struct.Reg, %struct.Reg* %112, i32 0, i32 0, !dbg !2069
  %R8W = bitcast %union.anon* %113 to i16*, !dbg !2069
  %114 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2070
  %115 = getelementptr inbounds %struct.GPR, %struct.GPR* %114, i32 0, i32 19, !dbg !2071
  %116 = getelementptr inbounds %struct.Reg, %struct.Reg* %115, i32 0, i32 0, !dbg !2072
  %R9W = bitcast %union.anon* %116 to i16*, !dbg !2072
  %117 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2073
  %118 = getelementptr inbounds %struct.GPR, %struct.GPR* %117, i32 0, i32 21, !dbg !2074
  %119 = getelementptr inbounds %struct.Reg, %struct.Reg* %118, i32 0, i32 0, !dbg !2075
  %R10W = bitcast %union.anon* %119 to i16*, !dbg !2075
  %120 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2076
  %121 = getelementptr inbounds %struct.GPR, %struct.GPR* %120, i32 0, i32 23, !dbg !2077
  %122 = getelementptr inbounds %struct.Reg, %struct.Reg* %121, i32 0, i32 0, !dbg !2078
  %R11W = bitcast %union.anon* %122 to i16*, !dbg !2078
  %123 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2079
  %124 = getelementptr inbounds %struct.GPR, %struct.GPR* %123, i32 0, i32 25, !dbg !2080
  %125 = getelementptr inbounds %struct.Reg, %struct.Reg* %124, i32 0, i32 0, !dbg !2081
  %R12W = bitcast %union.anon* %125 to i16*, !dbg !2081
  %126 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2082
  %127 = getelementptr inbounds %struct.GPR, %struct.GPR* %126, i32 0, i32 27, !dbg !2083
  %128 = getelementptr inbounds %struct.Reg, %struct.Reg* %127, i32 0, i32 0, !dbg !2084
  %R13W = bitcast %union.anon* %128 to i16*, !dbg !2084
  %129 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2085
  %130 = getelementptr inbounds %struct.GPR, %struct.GPR* %129, i32 0, i32 29, !dbg !2086
  %131 = getelementptr inbounds %struct.Reg, %struct.Reg* %130, i32 0, i32 0, !dbg !2087
  %R14W = bitcast %union.anon* %131 to i16*, !dbg !2087
  %132 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2088
  %133 = getelementptr inbounds %struct.GPR, %struct.GPR* %132, i32 0, i32 31, !dbg !2089
  %134 = getelementptr inbounds %struct.Reg, %struct.Reg* %133, i32 0, i32 0, !dbg !2090
  %R15W = bitcast %union.anon* %134 to i16*, !dbg !2090
  %135 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2091
  %136 = getelementptr inbounds %struct.GPR, %struct.GPR* %135, i32 0, i32 33, !dbg !2092
  %137 = getelementptr inbounds %struct.Reg, %struct.Reg* %136, i32 0, i32 0, !dbg !2093
  %IP = bitcast %union.anon* %137 to i16*, !dbg !2093
  %138 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2094
  %139 = getelementptr inbounds %struct.GPR, %struct.GPR* %138, i32 0, i32 1, !dbg !2095
  %140 = getelementptr inbounds %struct.Reg, %struct.Reg* %139, i32 0, i32 0, !dbg !2096
  %EAX = bitcast %union.anon* %140 to i32*, !dbg !2096
  %141 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2097
  %142 = getelementptr inbounds %struct.GPR, %struct.GPR* %141, i32 0, i32 3, !dbg !2098
  %143 = getelementptr inbounds %struct.Reg, %struct.Reg* %142, i32 0, i32 0, !dbg !2099
  %EBX = bitcast %union.anon* %143 to i32*, !dbg !2099
  %144 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2100
  %145 = getelementptr inbounds %struct.GPR, %struct.GPR* %144, i32 0, i32 5, !dbg !2101
  %146 = getelementptr inbounds %struct.Reg, %struct.Reg* %145, i32 0, i32 0, !dbg !2102
  %ECX = bitcast %union.anon* %146 to i32*, !dbg !2102
  %147 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2103
  %148 = getelementptr inbounds %struct.GPR, %struct.GPR* %147, i32 0, i32 7, !dbg !2104
  %149 = getelementptr inbounds %struct.Reg, %struct.Reg* %148, i32 0, i32 0, !dbg !2105
  %EDX = bitcast %union.anon* %149 to i32*, !dbg !2105
  %150 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2106
  %151 = getelementptr inbounds %struct.GPR, %struct.GPR* %150, i32 0, i32 9, !dbg !2107
  %152 = getelementptr inbounds %struct.Reg, %struct.Reg* %151, i32 0, i32 0, !dbg !2108
  %ESI = bitcast %union.anon* %152 to i32*, !dbg !2108
  %153 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2109
  %154 = getelementptr inbounds %struct.GPR, %struct.GPR* %153, i32 0, i32 11, !dbg !2110
  %155 = getelementptr inbounds %struct.Reg, %struct.Reg* %154, i32 0, i32 0, !dbg !2111
  %EDI = bitcast %union.anon* %155 to i32*, !dbg !2111
  %156 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2112
  %157 = getelementptr inbounds %struct.GPR, %struct.GPR* %156, i32 0, i32 13, !dbg !2113
  %158 = getelementptr inbounds %struct.Reg, %struct.Reg* %157, i32 0, i32 0, !dbg !2114
  %ESP = bitcast %union.anon* %158 to i32*, !dbg !2114
  %159 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2115
  %160 = getelementptr inbounds %struct.GPR, %struct.GPR* %159, i32 0, i32 15, !dbg !2116
  %161 = getelementptr inbounds %struct.Reg, %struct.Reg* %160, i32 0, i32 0, !dbg !2117
  %EBP = bitcast %union.anon* %161 to i32*, !dbg !2117
  %162 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2118
  %163 = getelementptr inbounds %struct.GPR, %struct.GPR* %162, i32 0, i32 33, !dbg !2119
  %164 = getelementptr inbounds %struct.Reg, %struct.Reg* %163, i32 0, i32 0, !dbg !2120
  %EIP = bitcast %union.anon* %164 to i32*, !dbg !2120
  %165 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2121
  %166 = getelementptr inbounds %struct.GPR, %struct.GPR* %165, i32 0, i32 17, !dbg !2122
  %167 = getelementptr inbounds %struct.Reg, %struct.Reg* %166, i32 0, i32 0, !dbg !2123
  %R8D = bitcast %union.anon* %167 to i32*, !dbg !2123
  %168 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2124
  %169 = getelementptr inbounds %struct.GPR, %struct.GPR* %168, i32 0, i32 19, !dbg !2125
  %170 = getelementptr inbounds %struct.Reg, %struct.Reg* %169, i32 0, i32 0, !dbg !2126
  %R9D = bitcast %union.anon* %170 to i32*, !dbg !2126
  %171 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2127
  %172 = getelementptr inbounds %struct.GPR, %struct.GPR* %171, i32 0, i32 21, !dbg !2128
  %173 = getelementptr inbounds %struct.Reg, %struct.Reg* %172, i32 0, i32 0, !dbg !2129
  %R10D = bitcast %union.anon* %173 to i32*, !dbg !2129
  %174 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2130
  %175 = getelementptr inbounds %struct.GPR, %struct.GPR* %174, i32 0, i32 23, !dbg !2131
  %176 = getelementptr inbounds %struct.Reg, %struct.Reg* %175, i32 0, i32 0, !dbg !2132
  %R11D = bitcast %union.anon* %176 to i32*, !dbg !2132
  %177 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2133
  %178 = getelementptr inbounds %struct.GPR, %struct.GPR* %177, i32 0, i32 25, !dbg !2134
  %179 = getelementptr inbounds %struct.Reg, %struct.Reg* %178, i32 0, i32 0, !dbg !2135
  %R12D = bitcast %union.anon* %179 to i32*, !dbg !2135
  %180 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2136
  %181 = getelementptr inbounds %struct.GPR, %struct.GPR* %180, i32 0, i32 27, !dbg !2137
  %182 = getelementptr inbounds %struct.Reg, %struct.Reg* %181, i32 0, i32 0, !dbg !2138
  %R13D = bitcast %union.anon* %182 to i32*, !dbg !2138
  %183 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2139
  %184 = getelementptr inbounds %struct.GPR, %struct.GPR* %183, i32 0, i32 29, !dbg !2140
  %185 = getelementptr inbounds %struct.Reg, %struct.Reg* %184, i32 0, i32 0, !dbg !2141
  %R14D = bitcast %union.anon* %185 to i32*, !dbg !2141
  %186 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2142
  %187 = getelementptr inbounds %struct.GPR, %struct.GPR* %186, i32 0, i32 31, !dbg !2143
  %188 = getelementptr inbounds %struct.Reg, %struct.Reg* %187, i32 0, i32 0, !dbg !2144
  %R15D = bitcast %union.anon* %188 to i32*, !dbg !2144
  %189 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2145
  %190 = getelementptr inbounds %struct.GPR, %struct.GPR* %189, i32 0, i32 1, !dbg !2146
  %191 = getelementptr inbounds %struct.Reg, %struct.Reg* %190, i32 0, i32 0, !dbg !2147
  %RAX = bitcast %union.anon* %191 to i64*, !dbg !2147
  %192 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2148
  %193 = getelementptr inbounds %struct.GPR, %struct.GPR* %192, i32 0, i32 3, !dbg !2149
  %194 = getelementptr inbounds %struct.Reg, %struct.Reg* %193, i32 0, i32 0, !dbg !2150
  %RBX = bitcast %union.anon* %194 to i64*, !dbg !2150
  %195 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2151
  %196 = getelementptr inbounds %struct.GPR, %struct.GPR* %195, i32 0, i32 5, !dbg !2152
  %197 = getelementptr inbounds %struct.Reg, %struct.Reg* %196, i32 0, i32 0, !dbg !2153
  %RCX = bitcast %union.anon* %197 to i64*, !dbg !2153
  %198 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2154
  %199 = getelementptr inbounds %struct.GPR, %struct.GPR* %198, i32 0, i32 7, !dbg !2155
  %200 = getelementptr inbounds %struct.Reg, %struct.Reg* %199, i32 0, i32 0, !dbg !2156
  %RDX = bitcast %union.anon* %200 to i64*, !dbg !2156
  %201 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2157
  %202 = getelementptr inbounds %struct.GPR, %struct.GPR* %201, i32 0, i32 9, !dbg !2158
  %203 = getelementptr inbounds %struct.Reg, %struct.Reg* %202, i32 0, i32 0, !dbg !2159
  %RSI = bitcast %union.anon* %203 to i64*, !dbg !2159
  %204 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2160
  %205 = getelementptr inbounds %struct.GPR, %struct.GPR* %204, i32 0, i32 11, !dbg !2161
  %206 = getelementptr inbounds %struct.Reg, %struct.Reg* %205, i32 0, i32 0, !dbg !2162
  %RDI = bitcast %union.anon* %206 to i64*, !dbg !2162
  %207 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2163
  %208 = getelementptr inbounds %struct.GPR, %struct.GPR* %207, i32 0, i32 13, !dbg !2164
  %209 = getelementptr inbounds %struct.Reg, %struct.Reg* %208, i32 0, i32 0, !dbg !2165
  %RSP = bitcast %union.anon* %209 to i64*, !dbg !2165
  %210 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2166
  %211 = getelementptr inbounds %struct.GPR, %struct.GPR* %210, i32 0, i32 15, !dbg !2167
  %212 = getelementptr inbounds %struct.Reg, %struct.Reg* %211, i32 0, i32 0, !dbg !2168
  %RBP = bitcast %union.anon* %212 to i64*, !dbg !2168
  %213 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2169
  %214 = getelementptr inbounds %struct.GPR, %struct.GPR* %213, i32 0, i32 17, !dbg !2170
  %215 = getelementptr inbounds %struct.Reg, %struct.Reg* %214, i32 0, i32 0, !dbg !2171
  %R8 = bitcast %union.anon* %215 to i64*, !dbg !2171
  %216 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2172
  %217 = getelementptr inbounds %struct.GPR, %struct.GPR* %216, i32 0, i32 19, !dbg !2173
  %218 = getelementptr inbounds %struct.Reg, %struct.Reg* %217, i32 0, i32 0, !dbg !2174
  %R9 = bitcast %union.anon* %218 to i64*, !dbg !2174
  %219 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2175
  %220 = getelementptr inbounds %struct.GPR, %struct.GPR* %219, i32 0, i32 21, !dbg !2176
  %221 = getelementptr inbounds %struct.Reg, %struct.Reg* %220, i32 0, i32 0, !dbg !2177
  %R10 = bitcast %union.anon* %221 to i64*, !dbg !2177
  %222 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2178
  %223 = getelementptr inbounds %struct.GPR, %struct.GPR* %222, i32 0, i32 23, !dbg !2179
  %224 = getelementptr inbounds %struct.Reg, %struct.Reg* %223, i32 0, i32 0, !dbg !2180
  %R11 = bitcast %union.anon* %224 to i64*, !dbg !2180
  %225 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2181
  %226 = getelementptr inbounds %struct.GPR, %struct.GPR* %225, i32 0, i32 25, !dbg !2182
  %227 = getelementptr inbounds %struct.Reg, %struct.Reg* %226, i32 0, i32 0, !dbg !2183
  %R12 = bitcast %union.anon* %227 to i64*, !dbg !2183
  %228 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2184
  %229 = getelementptr inbounds %struct.GPR, %struct.GPR* %228, i32 0, i32 27, !dbg !2185
  %230 = getelementptr inbounds %struct.Reg, %struct.Reg* %229, i32 0, i32 0, !dbg !2186
  %R13 = bitcast %union.anon* %230 to i64*, !dbg !2186
  %231 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2187
  %232 = getelementptr inbounds %struct.GPR, %struct.GPR* %231, i32 0, i32 29, !dbg !2188
  %233 = getelementptr inbounds %struct.Reg, %struct.Reg* %232, i32 0, i32 0, !dbg !2189
  %R14 = bitcast %union.anon* %233 to i64*, !dbg !2189
  %234 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2190
  %235 = getelementptr inbounds %struct.GPR, %struct.GPR* %234, i32 0, i32 31, !dbg !2191
  %236 = getelementptr inbounds %struct.Reg, %struct.Reg* %235, i32 0, i32 0, !dbg !2192
  %R15 = bitcast %union.anon* %236 to i64*, !dbg !2192
  %237 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 6, !dbg !2193
  %238 = getelementptr inbounds %struct.GPR, %struct.GPR* %237, i32 0, i32 33, !dbg !2194
  %239 = getelementptr inbounds %struct.Reg, %struct.Reg* %238, i32 0, i32 0, !dbg !2195
  %RIP = bitcast %union.anon* %239 to i64*, !dbg !2195
  %240 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2196
  %241 = getelementptr inbounds %struct.Segments, %struct.Segments* %240, i32 0, i32 1, !dbg !2197
  %SS = bitcast %union.SegmentSelector* %241 to i16*, !dbg !2198
  %242 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2199
  %243 = getelementptr inbounds %struct.Segments, %struct.Segments* %242, i32 0, i32 3, !dbg !2200
  %ES = bitcast %union.SegmentSelector* %243 to i16*, !dbg !2201
  %244 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2202
  %245 = getelementptr inbounds %struct.Segments, %struct.Segments* %244, i32 0, i32 5, !dbg !2203
  %GS = bitcast %union.SegmentSelector* %245 to i16*, !dbg !2204
  %246 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2205
  %247 = getelementptr inbounds %struct.Segments, %struct.Segments* %246, i32 0, i32 7, !dbg !2206
  %FS = bitcast %union.SegmentSelector* %247 to i16*, !dbg !2207
  %248 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2208
  %249 = getelementptr inbounds %struct.Segments, %struct.Segments* %248, i32 0, i32 9, !dbg !2209
  %DS = bitcast %union.SegmentSelector* %249 to i16*, !dbg !2210
  %250 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 4, !dbg !2211
  %251 = getelementptr inbounds %struct.Segments, %struct.Segments* %250, i32 0, i32 11, !dbg !2212
  %CS = bitcast %union.SegmentSelector* %251 to i16*, !dbg !2213
  %252 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 5, !dbg !2214
  %253 = getelementptr inbounds %struct.AddressSpace, %struct.AddressSpace* %252, i32 0, i32 5, !dbg !2215
  %254 = getelementptr inbounds %struct.Reg, %struct.Reg* %253, i32 0, i32 0, !dbg !2216
  %GS_BASE = bitcast %union.anon* %254 to i64*, !dbg !2216
  %255 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 5, !dbg !2217
  %256 = getelementptr inbounds %struct.AddressSpace, %struct.AddressSpace* %255, i32 0, i32 7, !dbg !2218
  %257 = getelementptr inbounds %struct.Reg, %struct.Reg* %256, i32 0, i32 0, !dbg !2219
  %FS_BASE = bitcast %union.anon* %257 to i64*, !dbg !2219
  %258 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2220
  %259 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %258, i64 0, i64 0, !dbg !2221
  %YMM0 = bitcast %union.VectorReg* %259 to %"class.std::bitset"*, !dbg !2222
  %260 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2223
  %261 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %260, i64 0, i64 1, !dbg !2224
  %YMM1 = bitcast %union.VectorReg* %261 to %"class.std::bitset"*, !dbg !2225
  %262 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2226
  %263 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %262, i64 0, i64 2, !dbg !2227
  %YMM2 = bitcast %union.VectorReg* %263 to %"class.std::bitset"*, !dbg !2228
  %264 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2229
  %265 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %264, i64 0, i64 3, !dbg !2230
  %YMM3 = bitcast %union.VectorReg* %265 to %"class.std::bitset"*, !dbg !2231
  %266 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2232
  %267 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %266, i64 0, i64 4, !dbg !2233
  %YMM4 = bitcast %union.VectorReg* %267 to %"class.std::bitset"*, !dbg !2234
  %268 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2235
  %269 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %268, i64 0, i64 5, !dbg !2236
  %YMM5 = bitcast %union.VectorReg* %269 to %"class.std::bitset"*, !dbg !2237
  %270 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2238
  %271 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %270, i64 0, i64 6, !dbg !2239
  %YMM6 = bitcast %union.VectorReg* %271 to %"class.std::bitset"*, !dbg !2240
  %272 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2241
  %273 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %272, i64 0, i64 7, !dbg !2242
  %YMM7 = bitcast %union.VectorReg* %273 to %"class.std::bitset"*, !dbg !2243
  %274 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2244
  %275 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %274, i64 0, i64 8, !dbg !2245
  %YMM8 = bitcast %union.VectorReg* %275 to %"class.std::bitset"*, !dbg !2246
  %276 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2247
  %277 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %276, i64 0, i64 9, !dbg !2248
  %YMM9 = bitcast %union.VectorReg* %277 to %"class.std::bitset"*, !dbg !2249
  %278 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2250
  %279 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %278, i64 0, i64 10, !dbg !2251
  %YMM10 = bitcast %union.VectorReg* %279 to %"class.std::bitset"*, !dbg !2252
  %280 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2253
  %281 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %280, i64 0, i64 11, !dbg !2254
  %YMM11 = bitcast %union.VectorReg* %281 to %"class.std::bitset"*, !dbg !2255
  %282 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2256
  %283 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %282, i64 0, i64 12, !dbg !2257
  %YMM12 = bitcast %union.VectorReg* %283 to %"class.std::bitset"*, !dbg !2258
  %284 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2259
  %285 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %284, i64 0, i64 13, !dbg !2260
  %YMM13 = bitcast %union.VectorReg* %285 to %"class.std::bitset"*, !dbg !2261
  %286 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2262
  %287 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %286, i64 0, i64 14, !dbg !2263
  %YMM14 = bitcast %union.VectorReg* %287 to %"class.std::bitset"*, !dbg !2264
  %288 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2265
  %289 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %288, i64 0, i64 15, !dbg !2266
  %YMM15 = bitcast %union.VectorReg* %289 to %"class.std::bitset"*, !dbg !2267
  %290 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2268
  %291 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %290, i64 0, i64 0, !dbg !2269
  %XMM0 = bitcast %union.VectorReg* %291 to %union.vec128_t*, !dbg !2270
  %292 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2271
  %293 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %292, i64 0, i64 1, !dbg !2272
  %XMM1 = bitcast %union.VectorReg* %293 to %union.vec128_t*, !dbg !2273
  %294 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2274
  %295 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %294, i64 0, i64 2, !dbg !2275
  %XMM2 = bitcast %union.VectorReg* %295 to %union.vec128_t*, !dbg !2276
  %296 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2277
  %297 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %296, i64 0, i64 3, !dbg !2278
  %XMM3 = bitcast %union.VectorReg* %297 to %union.vec128_t*, !dbg !2279
  %298 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2280
  %299 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %298, i64 0, i64 4, !dbg !2281
  %XMM4 = bitcast %union.VectorReg* %299 to %union.vec128_t*, !dbg !2282
  %300 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2283
  %301 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %300, i64 0, i64 5, !dbg !2284
  %XMM5 = bitcast %union.VectorReg* %301 to %union.vec128_t*, !dbg !2285
  %302 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2286
  %303 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %302, i64 0, i64 6, !dbg !2287
  %XMM6 = bitcast %union.VectorReg* %303 to %union.vec128_t*, !dbg !2288
  %304 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2289
  %305 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %304, i64 0, i64 7, !dbg !2290
  %XMM7 = bitcast %union.VectorReg* %305 to %union.vec128_t*, !dbg !2291
  %306 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2292
  %307 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %306, i64 0, i64 8, !dbg !2293
  %XMM8 = bitcast %union.VectorReg* %307 to %union.vec128_t*, !dbg !2294
  %308 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2295
  %309 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %308, i64 0, i64 9, !dbg !2296
  %XMM9 = bitcast %union.VectorReg* %309 to %union.vec128_t*, !dbg !2297
  %310 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2298
  %311 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %310, i64 0, i64 10, !dbg !2299
  %XMM10 = bitcast %union.VectorReg* %311 to %union.vec128_t*, !dbg !2300
  %312 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2301
  %313 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %312, i64 0, i64 11, !dbg !2302
  %XMM11 = bitcast %union.VectorReg* %313 to %union.vec128_t*, !dbg !2303
  %314 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2304
  %315 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %314, i64 0, i64 12, !dbg !2305
  %XMM12 = bitcast %union.VectorReg* %315 to %union.vec128_t*, !dbg !2306
  %316 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2307
  %317 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %316, i64 0, i64 13, !dbg !2308
  %XMM13 = bitcast %union.VectorReg* %317 to %union.vec128_t*, !dbg !2309
  %318 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2310
  %319 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %318, i64 0, i64 14, !dbg !2311
  %XMM14 = bitcast %union.VectorReg* %319 to %union.vec128_t*, !dbg !2312
  %320 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 1, !dbg !2313
  %321 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %320, i64 0, i64 15, !dbg !2314
  %XMM15 = bitcast %union.VectorReg* %321 to %union.vec128_t*, !dbg !2315
  %322 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2316
  %323 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %322, i32 0, i32 0, !dbg !2317
  %324 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %323, i64 0, i64 0, !dbg !2318
  %ST0 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %324, i32 0, i32 1, !dbg !2319
  %325 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2320
  %326 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %325, i32 0, i32 0, !dbg !2321
  %327 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %326, i64 0, i64 1, !dbg !2322
  %ST1 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %327, i32 0, i32 1, !dbg !2323
  %328 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2324
  %329 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %328, i32 0, i32 0, !dbg !2325
  %330 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %329, i64 0, i64 2, !dbg !2326
  %ST2 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %330, i32 0, i32 1, !dbg !2327
  %331 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2328
  %332 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %331, i32 0, i32 0, !dbg !2329
  %333 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %332, i64 0, i64 3, !dbg !2330
  %ST3 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %333, i32 0, i32 1, !dbg !2331
  %334 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2332
  %335 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %334, i32 0, i32 0, !dbg !2333
  %336 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %335, i64 0, i64 4, !dbg !2334
  %ST4 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %336, i32 0, i32 1, !dbg !2335
  %337 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2336
  %338 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %337, i32 0, i32 0, !dbg !2337
  %339 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %338, i64 0, i64 5, !dbg !2338
  %ST5 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %339, i32 0, i32 1, !dbg !2339
  %340 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2340
  %341 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %340, i32 0, i32 0, !dbg !2341
  %342 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %341, i64 0, i64 6, !dbg !2342
  %ST6 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %342, i32 0, i32 1, !dbg !2343
  %343 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 7, !dbg !2344
  %344 = getelementptr inbounds %struct.X87Stack, %struct.X87Stack* %343, i32 0, i32 0, !dbg !2345
  %345 = getelementptr inbounds [8 x %struct.anon.3], [8 x %struct.anon.3]* %344, i64 0, i64 7, !dbg !2346
  %ST7 = getelementptr inbounds %struct.anon.3, %struct.anon.3* %345, i32 0, i32 1, !dbg !2347
  %346 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2348
  %347 = getelementptr inbounds %struct.MMX, %struct.MMX* %346, i32 0, i32 0, !dbg !2349
  %348 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %347, i64 0, i64 0, !dbg !2350
  %349 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %348, i32 0, i32 1, !dbg !2351
  %350 = bitcast %union.vec64_t* %349 to %struct.uint64v1_t*, !dbg !2352
  %351 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %350, i32 0, i32 0, !dbg !2353
  %MM0 = getelementptr inbounds [1 x i64], [1 x i64]* %351, i64 0, i64 0, !dbg !2350
  %352 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2354
  %353 = getelementptr inbounds %struct.MMX, %struct.MMX* %352, i32 0, i32 0, !dbg !2355
  %354 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %353, i64 0, i64 1, !dbg !2356
  %355 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %354, i32 0, i32 1, !dbg !2357
  %356 = bitcast %union.vec64_t* %355 to %struct.uint64v1_t*, !dbg !2358
  %357 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %356, i32 0, i32 0, !dbg !2359
  %MM1 = getelementptr inbounds [1 x i64], [1 x i64]* %357, i64 0, i64 0, !dbg !2356
  %358 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2360
  %359 = getelementptr inbounds %struct.MMX, %struct.MMX* %358, i32 0, i32 0, !dbg !2361
  %360 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %359, i64 0, i64 2, !dbg !2362
  %361 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %360, i32 0, i32 1, !dbg !2363
  %362 = bitcast %union.vec64_t* %361 to %struct.uint64v1_t*, !dbg !2364
  %363 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %362, i32 0, i32 0, !dbg !2365
  %MM2 = getelementptr inbounds [1 x i64], [1 x i64]* %363, i64 0, i64 0, !dbg !2362
  %364 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2366
  %365 = getelementptr inbounds %struct.MMX, %struct.MMX* %364, i32 0, i32 0, !dbg !2367
  %366 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %365, i64 0, i64 3, !dbg !2368
  %367 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %366, i32 0, i32 1, !dbg !2369
  %368 = bitcast %union.vec64_t* %367 to %struct.uint64v1_t*, !dbg !2370
  %369 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %368, i32 0, i32 0, !dbg !2371
  %MM3 = getelementptr inbounds [1 x i64], [1 x i64]* %369, i64 0, i64 0, !dbg !2368
  %370 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2372
  %371 = getelementptr inbounds %struct.MMX, %struct.MMX* %370, i32 0, i32 0, !dbg !2373
  %372 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %371, i64 0, i64 4, !dbg !2374
  %373 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %372, i32 0, i32 1, !dbg !2375
  %374 = bitcast %union.vec64_t* %373 to %struct.uint64v1_t*, !dbg !2376
  %375 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %374, i32 0, i32 0, !dbg !2377
  %MM4 = getelementptr inbounds [1 x i64], [1 x i64]* %375, i64 0, i64 0, !dbg !2374
  %376 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2378
  %377 = getelementptr inbounds %struct.MMX, %struct.MMX* %376, i32 0, i32 0, !dbg !2379
  %378 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %377, i64 0, i64 5, !dbg !2380
  %379 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %378, i32 0, i32 1, !dbg !2381
  %380 = bitcast %union.vec64_t* %379 to %struct.uint64v1_t*, !dbg !2382
  %381 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %380, i32 0, i32 0, !dbg !2383
  %MM5 = getelementptr inbounds [1 x i64], [1 x i64]* %381, i64 0, i64 0, !dbg !2380
  %382 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2384
  %383 = getelementptr inbounds %struct.MMX, %struct.MMX* %382, i32 0, i32 0, !dbg !2385
  %384 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %383, i64 0, i64 6, !dbg !2386
  %385 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %384, i32 0, i32 1, !dbg !2387
  %386 = bitcast %union.vec64_t* %385 to %struct.uint64v1_t*, !dbg !2388
  %387 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %386, i32 0, i32 0, !dbg !2389
  %MM6 = getelementptr inbounds [1 x i64], [1 x i64]* %387, i64 0, i64 0, !dbg !2386
  %388 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 8, !dbg !2390
  %389 = getelementptr inbounds %struct.MMX, %struct.MMX* %388, i32 0, i32 0, !dbg !2391
  %390 = getelementptr inbounds [8 x %struct.anon.4], [8 x %struct.anon.4]* %389, i64 0, i64 7, !dbg !2392
  %391 = getelementptr inbounds %struct.anon.4, %struct.anon.4* %390, i32 0, i32 1, !dbg !2393
  %392 = bitcast %union.vec64_t* %391 to %struct.uint64v1_t*, !dbg !2394
  %393 = getelementptr inbounds %struct.uint64v1_t, %struct.uint64v1_t* %392, i32 0, i32 0, !dbg !2395
  %MM7 = getelementptr inbounds [1 x i64], [1 x i64]* %393, i64 0, i64 0, !dbg !2392
  %394 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2396
  %AF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %394, i32 0, i32 5, !dbg !2397
  %395 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2398
  %CF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %395, i32 0, i32 1, !dbg !2399
  %396 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2400
  %DF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %396, i32 0, i32 11, !dbg !2401
  %397 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2402
  %OF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %397, i32 0, i32 13, !dbg !2403
  %398 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2404
  %PF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %398, i32 0, i32 3, !dbg !2405
  %399 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2406
  %SF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %399, i32 0, i32 9, !dbg !2407
  %400 = getelementptr inbounds %struct.State, %struct.State* %0, i32 0, i32 2, !dbg !2408
  %ZF = getelementptr inbounds %struct.ArithFlags, %struct.ArithFlags* %400, i32 0, i32 7, !dbg !2409
  store i64* @DR0, i64** %_DR0, align 8, !dbg !2410
  store i64* @DR1, i64** %_DR1, align 8, !dbg !2411
  store i64* @DR2, i64** %_DR2, align 8, !dbg !2412
  store i64* @DR3, i64** %_DR3, align 8, !dbg !2413
  store i64* @DR4, i64** %_DR4, align 8, !dbg !2414
  store i64* @DR5, i64** %_DR5, align 8, !dbg !2415
  store i64* @DR6, i64** %_DR6, align 8, !dbg !2416
  store i64* @DR7, i64** %_DR7, align 8, !dbg !2417
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR0, i32 0, i32 0), i64** %CR0, align 8, !dbg !2418
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR1, i32 0, i32 0), i64** %CR1, align 8, !dbg !2419
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR2, i32 0, i32 0), i64** %CR2, align 8, !dbg !2420
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR3, i32 0, i32 0), i64** %CR3, align 8, !dbg !2421
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR4, i32 0, i32 0), i64** %CR4, align 8, !dbg !2422
  store i64* getelementptr inbounds (%union.anon, %union.anon* @gCR8, i32 0, i32 0), i64** %CR8, align 8, !dbg !2423
  ret %struct.Memory* %2, !dbg !2424
}

; Function Attrs: noduplicate noinline nounwind optnone
define void @__remill_intrinsics() local_unnamed_addr #3 !dbg !2425 {
  ret void, !dbg !2427
}

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_function_call(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #4

; Function Attrs: noduplicate noinline nounwind optnone
declare %struct.Memory* @__remill_jump(%struct.State* dereferenceable(3376), i64, %struct.Memory*) local_unnamed_addr #4

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @exit(i64) #5

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @calloc(i64, i64) #5

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @fprintf(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64) #5

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @__libc_start_main(i64, i64, i64, i64, i64, i64, i64, i64) #5

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @printf(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64) #5

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @__gmon_start__() #5

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @posix_memalign(i64, i64, i64) #5

; Function Attrs: noinline
declare extern_weak x86_64_sysvcc i64 @free(i64) #5

; Function Attrs: noinline
define %struct.Memory* @sub_4005e0__dl_relocate_static_pie(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_4005e0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = add i64 %1, 2
  store i64 %3, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !2428
  %6 = inttoptr i64 %5 to i64*
  %7 = load i64, i64* %6, align 8
  store i64 %7, i64* %PC, align 8, !tbaa !2428
  %8 = add i64 %5, 8
  store i64 %8, i64* %4, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_4006a0_polybench_flush_cache(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_4006a0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %1, 1
  store i64 %5, i64* %PC, align 8
  %6 = load i64, i64* %RSP, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %4, i64* %8, align 8
  %9 = load i64, i64* %PC, align 8
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %10 = add i64 %6, -40
  store i64 %10, i64* %RSP, align 8, !tbaa !2428
  %11 = icmp ult i64 %7, 32
  %12 = zext i1 %11 to i8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %13, align 1, !tbaa !2432
  %14 = trunc i64 %10 to i32
  %15 = and i32 %14, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15) #8
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1, !tbaa !2446
  %21 = xor i64 %7, %10
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1, !tbaa !2447
  %26 = icmp eq i64 %10, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1, !tbaa !2448
  %29 = lshr i64 %10, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1, !tbaa !2449
  %32 = lshr i64 %7, 63
  %33 = xor i64 %29, %32
  %34 = add nuw nsw i64 %33, %32
  %35 = icmp eq i64 %34, 2
  %36 = zext i1 %35 to i8
  %37 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %36, i8* %37, align 1, !tbaa !2450
  store i64 8, i64* %RAX, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %38 = add i64 %6, -12
  %39 = add i64 %9, 21
  store i64 %39, i64* %PC, align 8
  %40 = inttoptr i64 %38 to i32*
  store i32 4194560, i32* %40, align 4
  %41 = load i64, i64* %RBP, align 8
  %42 = add i64 %41, -4
  %43 = load i64, i64* %PC, align 8
  %44 = add i64 %43, 4
  store i64 %44, i64* %PC, align 8
  %45 = inttoptr i64 %42 to i32*
  %46 = load i32, i32* %45, align 4
  %47 = sext i32 %46 to i64
  store i64 %47, i64* %RDI, align 8, !tbaa !2428
  %48 = add i64 %43, -326
  %49 = add i64 %43, 9
  %50 = load i64, i64* %RSP, align 8, !tbaa !2428
  %51 = add i64 %50, -8
  %52 = inttoptr i64 %51 to i64*
  store i64 %49, i64* %52, align 8
  store i64 %51, i64* %RSP, align 8, !tbaa !2428
  store i64 %48, i64* %PC, align 8, !tbaa !2428
  %53 = tail call fastcc %struct.Memory* @ext_6040b8_calloc(%struct.State* nonnull %0, %struct.Memory* %2)
  %54 = bitcast %union.VectorReg* %3 to i8*
  %55 = load i64, i64* %PC, align 8
  %56 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %57 = bitcast %union.VectorReg* %3 to i32*
  store i32 0, i32* %57, align 1, !tbaa !2451
  %58 = getelementptr inbounds i8, i8* %54, i64 4
  %59 = bitcast i8* %58 to i32*
  store i32 0, i32* %59, align 1, !tbaa !2451
  %60 = bitcast i64* %56 to i32*
  store i32 0, i32* %60, align 1, !tbaa !2451
  %61 = getelementptr inbounds i8, i8* %54, i64 12
  %62 = bitcast i8* %61 to i32*
  store i32 0, i32* %62, align 1, !tbaa !2451
  %63 = load i64, i64* %RBP, align 8
  %64 = add i64 %63, -16
  %65 = load i64, i64* %RAX, align 8
  %66 = add i64 %55, 7
  store i64 %66, i64* %PC, align 8
  %67 = inttoptr i64 %64 to i64*
  store i64 %65, i64* %67, align 8
  %68 = load i64, i64* %RBP, align 8
  %69 = add i64 %68, -32
  %70 = load i64, i64* %PC, align 8
  %71 = add i64 %70, 5
  store i64 %71, i64* %PC, align 8
  %72 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %3, i64 0, i32 0, i32 0, i32 0, i64 0
  %73 = load i64, i64* %72, align 1
  %74 = inttoptr i64 %69 to i64*
  store i64 %73, i64* %74, align 8
  %75 = load i64, i64* %RBP, align 8
  %76 = add i64 %75, -20
  %77 = load i64, i64* %PC, align 8
  %78 = add i64 %77, 7
  store i64 %78, i64* %PC, align 8
  %79 = inttoptr i64 %76 to i32*
  store i32 0, i32* %79, align 4
  %80 = bitcast %union.VectorReg* %3 to double*
  %81 = bitcast i64* %56 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_4006d2

block_4006de:                                     ; preds = %block_4006d2
  %82 = add i64 %203, 8
  store i64 %82, i64* %PC, align 8
  %83 = load i32, i32* %170, align 4
  %84 = sext i32 %83 to i64
  store i64 %84, i64* %RCX, align 8, !tbaa !2428
  %85 = shl nsw i64 %84, 3
  %86 = add i64 %85, %207
  %87 = add i64 %203, 13
  store i64 %87, i64* %PC, align 8
  %88 = inttoptr i64 %86 to double*
  %89 = load double, double* %88, align 8
  store double %89, double* %80, align 1, !tbaa !2452
  store double 0.000000e+00, double* %81, align 1, !tbaa !2452
  %90 = add i64 %167, -32
  %91 = add i64 %203, 18
  store i64 %91, i64* %PC, align 8
  %92 = inttoptr i64 %90 to double*
  %93 = load double, double* %92, align 8
  %94 = fadd double %89, %93
  store double %94, double* %80, align 1, !tbaa !2452
  store i64 0, i64* %56, align 1, !tbaa !2452
  %95 = add i64 %203, 23
  store i64 %95, i64* %PC, align 8
  store double %94, double* %92, align 8
  %96 = load i64, i64* %RBP, align 8
  %97 = add i64 %96, -20
  %98 = load i64, i64* %PC, align 8
  %99 = add i64 %98, 3
  store i64 %99, i64* %PC, align 8
  %100 = inttoptr i64 %97 to i32*
  %101 = load i32, i32* %100, align 4
  %102 = add i32 %101, 1
  %103 = zext i32 %102 to i64
  store i64 %103, i64* %RAX, align 8, !tbaa !2428
  %104 = icmp eq i32 %101, -1
  %105 = icmp eq i32 %102, 0
  %106 = or i1 %104, %105
  %107 = zext i1 %106 to i8
  store i8 %107, i8* %13, align 1, !tbaa !2432
  %108 = and i32 %102, 255
  %109 = tail call i32 @llvm.ctpop.i32(i32 %108) #8
  %110 = trunc i32 %109 to i8
  %111 = and i8 %110, 1
  %112 = xor i8 %111, 1
  store i8 %112, i8* %20, align 1, !tbaa !2446
  %113 = xor i32 %101, %102
  %114 = lshr i32 %113, 4
  %115 = trunc i32 %114 to i8
  %116 = and i8 %115, 1
  store i8 %116, i8* %25, align 1, !tbaa !2447
  %117 = zext i1 %105 to i8
  store i8 %117, i8* %28, align 1, !tbaa !2448
  %118 = lshr i32 %102, 31
  %119 = trunc i32 %118 to i8
  store i8 %119, i8* %31, align 1, !tbaa !2449
  %120 = lshr i32 %101, 31
  %121 = xor i32 %118, %120
  %122 = add nuw nsw i32 %121, %118
  %123 = icmp eq i32 %122, 2
  %124 = zext i1 %123 to i8
  store i8 %124, i8* %37, align 1, !tbaa !2450
  %125 = add i64 %98, 9
  store i64 %125, i64* %PC, align 8
  store i32 %102, i32* %100, align 4
  %126 = load i64, i64* %PC, align 8
  %127 = add i64 %126, -44
  store i64 %127, i64* %PC, align 8, !tbaa !2428
  br label %block_4006d2

block_400703:                                     ; preds = %block_4006d2
  store i64 %207, i64* %RDI, align 8, !tbaa !2428
  %128 = add i64 %203, -435
  %129 = add i64 %203, 12
  %130 = load i64, i64* %RSP, align 8, !tbaa !2428
  %131 = add i64 %130, -8
  %132 = inttoptr i64 %131 to i64*
  store i64 %129, i64* %132, align 8
  store i64 %131, i64* %RSP, align 8, !tbaa !2428
  store i64 %128, i64* %PC, align 8, !tbaa !2428
  %133 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %53)
  %134 = load i64, i64* %RSP, align 8
  %135 = load i64, i64* %PC, align 8
  %136 = add i64 %134, 32
  store i64 %136, i64* %RSP, align 8, !tbaa !2428
  %137 = icmp ugt i64 %134, -33
  %138 = zext i1 %137 to i8
  store i8 %138, i8* %13, align 1, !tbaa !2432
  %139 = trunc i64 %136 to i32
  %140 = and i32 %139, 255
  %141 = tail call i32 @llvm.ctpop.i32(i32 %140) #8
  %142 = trunc i32 %141 to i8
  %143 = and i8 %142, 1
  %144 = xor i8 %143, 1
  store i8 %144, i8* %20, align 1, !tbaa !2446
  %145 = xor i64 %134, %136
  %146 = lshr i64 %145, 4
  %147 = trunc i64 %146 to i8
  %148 = and i8 %147, 1
  store i8 %148, i8* %25, align 1, !tbaa !2447
  %149 = icmp eq i64 %136, 0
  %150 = zext i1 %149 to i8
  store i8 %150, i8* %28, align 1, !tbaa !2448
  %151 = lshr i64 %136, 63
  %152 = trunc i64 %151 to i8
  store i8 %152, i8* %31, align 1, !tbaa !2449
  %153 = lshr i64 %134, 63
  %154 = xor i64 %151, %153
  %155 = add nuw nsw i64 %154, %151
  %156 = icmp eq i64 %155, 2
  %157 = zext i1 %156 to i8
  store i8 %157, i8* %37, align 1, !tbaa !2450
  %158 = add i64 %135, 5
  store i64 %158, i64* %PC, align 8
  %159 = add i64 %134, 40
  %160 = inttoptr i64 %136 to i64*
  %161 = load i64, i64* %160, align 8
  store i64 %161, i64* %RBP, align 8, !tbaa !2428
  store i64 %159, i64* %RSP, align 8, !tbaa !2428
  %162 = add i64 %135, 6
  store i64 %162, i64* %PC, align 8
  %163 = inttoptr i64 %159 to i64*
  %164 = load i64, i64* %163, align 8
  store i64 %164, i64* %PC, align 8, !tbaa !2428
  %165 = add i64 %134, 48
  store i64 %165, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %133

block_4006d2:                                     ; preds = %block_4006de, %block_4006a0
  %166 = phi i64 [ %127, %block_4006de ], [ %.pre, %block_4006a0 ]
  %167 = load i64, i64* %RBP, align 8
  %168 = add i64 %167, -20
  %169 = add i64 %166, 3
  store i64 %169, i64* %PC, align 8
  %170 = inttoptr i64 %168 to i32*
  %171 = load i32, i32* %170, align 4
  %172 = zext i32 %171 to i64
  store i64 %172, i64* %RAX, align 8, !tbaa !2428
  %173 = add i64 %167, -4
  %174 = add i64 %166, 6
  store i64 %174, i64* %PC, align 8
  %175 = inttoptr i64 %173 to i32*
  %176 = load i32, i32* %175, align 4
  %177 = sub i32 %171, %176
  %178 = icmp ult i32 %171, %176
  %179 = zext i1 %178 to i8
  store i8 %179, i8* %13, align 1, !tbaa !2432
  %180 = and i32 %177, 255
  %181 = tail call i32 @llvm.ctpop.i32(i32 %180) #8
  %182 = trunc i32 %181 to i8
  %183 = and i8 %182, 1
  %184 = xor i8 %183, 1
  store i8 %184, i8* %20, align 1, !tbaa !2446
  %185 = xor i32 %176, %171
  %186 = xor i32 %185, %177
  %187 = lshr i32 %186, 4
  %188 = trunc i32 %187 to i8
  %189 = and i8 %188, 1
  store i8 %189, i8* %25, align 1, !tbaa !2447
  %190 = icmp eq i32 %177, 0
  %191 = zext i1 %190 to i8
  store i8 %191, i8* %28, align 1, !tbaa !2448
  %192 = lshr i32 %177, 31
  %193 = trunc i32 %192 to i8
  store i8 %193, i8* %31, align 1, !tbaa !2449
  %194 = lshr i32 %171, 31
  %195 = lshr i32 %176, 31
  %196 = xor i32 %195, %194
  %197 = xor i32 %192, %194
  %198 = add nuw nsw i32 %197, %196
  %199 = icmp eq i32 %198, 2
  %200 = zext i1 %199 to i8
  store i8 %200, i8* %37, align 1, !tbaa !2450
  %201 = icmp ne i8 %193, 0
  %202 = xor i1 %201, %199
  %.v = select i1 %202, i64 12, i64 49
  %203 = add i64 %166, %.v
  %204 = add i64 %167, -16
  %205 = add i64 %203, 4
  store i64 %205, i64* %PC, align 8
  %206 = inttoptr i64 %204 to i64*
  %207 = load i64, i64* %206, align 8
  store i64 %207, i64* %RAX, align 8, !tbaa !2428
  br i1 %202, label %block_4006de, label %block_400703
}

; Function Attrs: noinline
define %struct.Memory* @sub_400660___do_global_dtors_aux(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_400660:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i8, i8* inttoptr (i64 add (i64 ptrtoint (%seg_604060__bss_type* @seg_604060__bss to i64), i64 8) to i8*), align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %4, align 1, !tbaa !2432
  %5 = zext i8 %3 to i32
  %6 = tail call i32 @llvm.ctpop.i32(i32 %5) #8
  %7 = trunc i32 %6 to i8
  %8 = and i8 %7, 1
  %9 = xor i8 %8, 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %9, i8* %10, align 1, !tbaa !2446
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %11, align 1, !tbaa !2447
  %12 = icmp eq i8 %3, 0
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %13, i8* %14, align 1, !tbaa !2448
  %15 = lshr i8 %3, 7
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %15, i8* %16, align 1, !tbaa !2449
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %17, align 1, !tbaa !2450
  %.v = select i1 %12, i64 9, i64 32
  %18 = add i64 %.v, %1
  store i64 %18, i64* %PC, align 8, !tbaa !2428
  br i1 %12, label %block_400669, label %block_400680

block_400680:                                     ; preds = %block_400660
  %19 = add i64 %18, 2
  store i64 %19, i64* %PC, align 8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %21 = load i64, i64* %20, align 8, !tbaa !2428
  %22 = inttoptr i64 %21 to i64*
  %23 = load i64, i64* %22, align 8
  store i64 %23, i64* %PC, align 8, !tbaa !2428
  %24 = add i64 %21, 8
  store i64 %24, i64* %20, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_400669:                                     ; preds = %block_400660
  %25 = load i64, i64* %RBP, align 8
  %26 = add i64 %18, 1
  store i64 %26, i64* %PC, align 8
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %28 = load i64, i64* %27, align 8, !tbaa !2428
  %29 = add i64 %28, -8
  %30 = inttoptr i64 %29 to i64*
  store i64 %25, i64* %30, align 8
  %31 = load i64, i64* %PC, align 8
  store i64 %29, i64* %RBP, align 8, !tbaa !2428
  %32 = add i64 %31, -122
  %33 = add i64 %31, 8
  %34 = add i64 %28, -16
  %35 = inttoptr i64 %34 to i64*
  store i64 %33, i64* %35, align 8
  store i64 %34, i64* %27, align 8, !tbaa !2428
  store i64 %32, i64* %PC, align 8, !tbaa !2428
  %36 = tail call %struct.Memory* @sub_4005f0_deregister_tm_clones_renamed_(%struct.State* nonnull %0, i64 %32, %struct.Memory* %2)
  %37 = load i64, i64* %PC, align 8
  store i8 1, i8* inttoptr (i64 add (i64 ptrtoint (%seg_604060__bss_type* @seg_604060__bss to i64), i64 8) to i8*), align 8
  %38 = add i64 %37, 8
  store i64 %38, i64* %PC, align 8
  %39 = load i64, i64* %27, align 8, !tbaa !2428
  %40 = add i64 %39, 8
  %41 = inttoptr i64 %39 to i64*
  %42 = load i64, i64* %41, align 8
  store i64 %42, i64* %RBP, align 8, !tbaa !2428
  store i64 %40, i64* %27, align 8, !tbaa !2428
  %43 = add i64 %37, 9
  store i64 %43, i64* %PC, align 8
  %44 = inttoptr i64 %40 to i64*
  %45 = load i64, i64* %44, align 8
  store i64 %45, i64* %PC, align 8, !tbaa !2428
  %46 = add i64 %39, 16
  store i64 %46, i64* %27, align 8, !tbaa !2428
  ret %struct.Memory* %36
}

; Function Attrs: noinline
define %struct.Memory* @sub_400760_polybench_timer_stop(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_400760:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  %9 = load i64, i64* %PC, align 8
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %10 = add i64 %9, -17
  %11 = add i64 %9, 8
  %12 = add i64 %6, -16
  %13 = inttoptr i64 %12 to i64*
  store i64 %11, i64* %13, align 8
  store i64 %12, i64* %5, align 8, !tbaa !2428
  store i64 %10, i64* %PC, align 8, !tbaa !2428
  %14 = tail call %struct.Memory* @sub_400750_rtclock_renamed_(%struct.State* nonnull %0, i64 %10, %struct.Memory* %2)
  %15 = load i64, i64* %PC, align 8
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 0
  %17 = load i64, i64* %16, align 1
  store i64 %17, i64* bitcast (%polybench_t_end_type* @polybench_t_end to i64*), align 8
  %18 = add i64 %15, 10
  store i64 %18, i64* %PC, align 8
  %19 = load i64, i64* %5, align 8, !tbaa !2428
  %20 = add i64 %19, 8
  %21 = inttoptr i64 %19 to i64*
  %22 = load i64, i64* %21, align 8
  store i64 %22, i64* %RBP, align 8, !tbaa !2428
  store i64 %20, i64* %5, align 8, !tbaa !2428
  %23 = add i64 %15, 11
  store i64 %23, i64* %PC, align 8
  %24 = inttoptr i64 %20 to i64*
  %25 = load i64, i64* %24, align 8
  store i64 %25, i64* %PC, align 8, !tbaa !2428
  %26 = add i64 %19, 16
  store i64 %26, i64* %5, align 8, !tbaa !2428
  ret %struct.Memory* %14
}

; Function Attrs: noinline
define %struct.Memory* @sub_400730_polybench_timer_start(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_400730:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  %9 = load i64, i64* %PC, align 8
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %10 = add i64 %9, -17
  %11 = add i64 %9, 8
  %12 = add i64 %6, -16
  %13 = inttoptr i64 %12 to i64*
  store i64 %11, i64* %13, align 8
  store i64 %12, i64* %5, align 8, !tbaa !2428
  store i64 %10, i64* %PC, align 8, !tbaa !2428
  %14 = tail call %struct.Memory* @sub_400720_polybench_prepare_instruments_renamed_(%struct.State* nonnull %0, i64 %10, %struct.Memory* %2)
  %15 = load i64, i64* %PC, align 8
  %16 = add i64 %15, 23
  %17 = add i64 %15, 5
  %18 = load i64, i64* %5, align 8, !tbaa !2428
  %19 = add i64 %18, -8
  %20 = inttoptr i64 %19 to i64*
  store i64 %17, i64* %20, align 8
  store i64 %19, i64* %5, align 8, !tbaa !2428
  store i64 %16, i64* %PC, align 8, !tbaa !2428
  %21 = tail call %struct.Memory* @sub_400750_rtclock_renamed_(%struct.State* nonnull %0, i64 %16, %struct.Memory* %14)
  %22 = load i64, i64* %PC, align 8
  %23 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 0
  %24 = load i64, i64* %23, align 1
  store i64 %24, i64* bitcast (%polybench_t_start_type* @polybench_t_start to i64*), align 8
  %25 = add i64 %22, 10
  store i64 %25, i64* %PC, align 8
  %26 = load i64, i64* %5, align 8, !tbaa !2428
  %27 = add i64 %26, 8
  %28 = inttoptr i64 %26 to i64*
  %29 = load i64, i64* %28, align 8
  store i64 %29, i64* %RBP, align 8, !tbaa !2428
  store i64 %27, i64* %5, align 8, !tbaa !2428
  %30 = add i64 %22, 11
  store i64 %30, i64* %PC, align 8
  %31 = inttoptr i64 %27 to i64*
  %32 = load i64, i64* %31, align 8
  store i64 %32, i64* %PC, align 8, !tbaa !2428
  %33 = add i64 %26, 16
  store i64 %33, i64* %5, align 8, !tbaa !2428
  ret %struct.Memory* %21
}

; Function Attrs: noinline
define %struct.Memory* @sub_400620_register_tm_clones(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_400620:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  store i64 6307928, i64* %RSI, align 8, !tbaa !2428
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 6
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  store i64 %7, i64* %5, align 8, !tbaa !2428
  %9 = load i64, i64* %RSI, align 8
  %10 = load i64, i64* %PC, align 8
  %11 = add i64 %9, -6307928
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %16 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %18 = ashr i64 %11, 3
  %19 = lshr i64 %18, 63
  store i64 %19, i64* %RAX, align 8, !tbaa !2428
  %20 = add nsw i64 %19, %18
  %21 = trunc i64 %20 to i8
  %22 = and i8 %21, 1
  %23 = ashr i64 %20, 1
  store i64 %23, i64* %RSI, align 8, !tbaa !2428
  store i8 %22, i8* %12, align 1, !tbaa !2454
  %24 = trunc i64 %23 to i32
  %25 = and i32 %24, 255
  %26 = tail call i32 @llvm.ctpop.i32(i32 %25) #8
  %27 = trunc i32 %26 to i8
  %28 = and i8 %27, 1
  %29 = xor i8 %28, 1
  store i8 %29, i8* %13, align 1, !tbaa !2454
  store i8 0, i8* %14, align 1, !tbaa !2454
  %30 = icmp eq i64 %23, 0
  %31 = zext i1 %30 to i8
  store i8 %31, i8* %15, align 1, !tbaa !2454
  %32 = lshr i64 %23, 63
  %33 = trunc i64 %32 to i8
  store i8 %33, i8* %16, align 1, !tbaa !2454
  store i8 0, i8* %17, align 1, !tbaa !2454
  %.v = select i1 %30, i64 50, i64 29
  %34 = add i64 %10, %.v
  store i64 %34, i64* %PC, align 8, !tbaa !2428
  br i1 %30, label %block_400658, label %block_400643

block_400658:                                     ; preds = %block_400643, %block_400620
  %35 = phi i64 [ %45, %block_400643 ], [ %34, %block_400620 ]
  %36 = add i64 %35, 1
  store i64 %36, i64* %PC, align 8
  %37 = load i64, i64* %5, align 8, !tbaa !2428
  %38 = add i64 %37, 8
  %39 = inttoptr i64 %37 to i64*
  %40 = load i64, i64* %39, align 8
  store i64 %40, i64* %RBP, align 8, !tbaa !2428
  store i64 %38, i64* %5, align 8, !tbaa !2428
  %41 = add i64 %35, 2
  store i64 %41, i64* %PC, align 8
  %42 = inttoptr i64 %38 to i64*
  %43 = load i64, i64* %42, align 8
  store i64 %43, i64* %PC, align 8, !tbaa !2428
  %44 = add i64 %37, 16
  store i64 %44, i64* %5, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_400643:                                     ; preds = %block_400620
  store i64 0, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %12, align 1, !tbaa !2432
  store i8 1, i8* %13, align 1, !tbaa !2446
  store i8 1, i8* %15, align 1, !tbaa !2448
  store i8 0, i8* %16, align 1, !tbaa !2449
  store i8 0, i8* %17, align 1, !tbaa !2450
  store i8 0, i8* %14, align 1, !tbaa !2447
  %45 = add i64 %34, 21
  store i64 %45, i64* %PC, align 8, !tbaa !2428
  br label %block_400658
}

; Function Attrs: noinline
define %struct.Memory* @sub_400750_rtclock(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_400750:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %1, 1
  store i64 %5, i64* %PC, align 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %7 = load i64, i64* %6, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %4, i64* %9, align 8
  store i64 %8, i64* %6, align 8, !tbaa !2428
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = bitcast %union.VectorReg* %3 to i8*
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %13 = bitcast %union.VectorReg* %3 to i32*
  store i32 0, i32* %13, align 1, !tbaa !2451
  %14 = getelementptr inbounds i8, i8* %11, i64 4
  %15 = bitcast i8* %14 to i32*
  store i32 0, i32* %15, align 1, !tbaa !2451
  %16 = bitcast i64* %12 to i32*
  store i32 0, i32* %16, align 1, !tbaa !2451
  %17 = getelementptr inbounds i8, i8* %11, i64 12
  %18 = bitcast i8* %17 to i32*
  store i32 0, i32* %18, align 1, !tbaa !2451
  %19 = add i64 %10, 7
  store i64 %19, i64* %PC, align 8
  %20 = load i64, i64* %9, align 8
  store i64 %20, i64* %RBP, align 8, !tbaa !2428
  store i64 %7, i64* %6, align 8, !tbaa !2428
  %21 = add i64 %10, 8
  store i64 %21, i64* %PC, align 8
  %22 = inttoptr i64 %7 to i64*
  %23 = load i64, i64* %22, align 8
  store i64 %23, i64* %PC, align 8, !tbaa !2428
  %24 = add i64 %7, 8
  store i64 %24, i64* %6, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_402e00___libc_csu_init(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_402e00:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 27, i32 0
  %R13D = bitcast %union.anon* %4 to i32*
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 25, i32 0, i32 0
  %R13 = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %R14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 29, i32 0, i32 0
  %R15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 31, i32 0, i32 0
  %5 = load i64, i64* %R15, align 8
  %6 = add i64 %1, 2
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %R14, align 8
  %11 = load i64, i64* %PC, align 8
  %12 = add i64 %11, 2
  store i64 %12, i64* %PC, align 8
  %13 = add i64 %7, -16
  %14 = inttoptr i64 %13 to i64*
  store i64 %10, i64* %14, align 8
  %15 = load i64, i64* %RDX, align 8
  %16 = load i64, i64* %PC, align 8
  store i64 %15, i64* %R15, align 8, !tbaa !2428
  %17 = load i64, i64* %R13, align 8
  %18 = add i64 %16, 5
  store i64 %18, i64* %PC, align 8
  %19 = add i64 %7, -24
  %20 = inttoptr i64 %19 to i64*
  store i64 %17, i64* %20, align 8
  %21 = load i64, i64* %R12, align 8
  %22 = load i64, i64* %PC, align 8
  %23 = add i64 %22, 2
  store i64 %23, i64* %PC, align 8
  %24 = add i64 %7, -32
  %25 = inttoptr i64 %24 to i64*
  store i64 %21, i64* %25, align 8
  %26 = load i64, i64* %PC, align 8
  store i64 ptrtoint (%seg_603df0__init_array_type* @seg_603df0__init_array to i64), i64* %R12, align 8, !tbaa !2428
  %27 = load i64, i64* %RBP, align 8
  %28 = add i64 %26, 8
  store i64 %28, i64* %PC, align 8
  %29 = add i64 %7, -40
  %30 = inttoptr i64 %29 to i64*
  store i64 %27, i64* %30, align 8
  %31 = load i64, i64* %PC, align 8
  store i64 add (i64 ptrtoint (%seg_603df0__init_array_type* @seg_603df0__init_array to i64), i64 8), i64* %RBP, align 8, !tbaa !2428
  %32 = load i64, i64* %RBX, align 8
  %33 = add i64 %31, 8
  store i64 %33, i64* %PC, align 8
  %34 = add i64 %7, -48
  %35 = inttoptr i64 %34 to i64*
  store i64 %32, i64* %35, align 8
  %36 = load i32, i32* %EDI, align 4
  %37 = zext i32 %36 to i64
  %38 = load i64, i64* %PC, align 8
  store i64 %37, i64* %R13, align 8, !tbaa !2428
  %39 = load i64, i64* %RSI, align 8
  store i64 %39, i64* %R14, align 8, !tbaa !2428
  %40 = load i64, i64* %RBP, align 8
  %41 = load i64, i64* %R12, align 8
  %42 = sub i64 %40, %41
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %44 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %45 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %46 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %47 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %48 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %49 = lshr i64 %42, 2
  %50 = trunc i64 %49 to i8
  %51 = and i8 %50, 1
  %52 = ashr i64 %42, 3
  store i64 %52, i64* %RBP, align 8, !tbaa !2428
  store i8 %51, i8* %43, align 1, !tbaa !2454
  %53 = trunc i64 %52 to i32
  %54 = and i32 %53, 255
  %55 = tail call i32 @llvm.ctpop.i32(i32 %54) #8
  %56 = trunc i32 %55 to i8
  %57 = and i8 %56, 1
  %58 = xor i8 %57, 1
  store i8 %58, i8* %44, align 1, !tbaa !2454
  store i8 0, i8* %45, align 1, !tbaa !2454
  %59 = icmp eq i64 %52, 0
  %60 = zext i1 %59 to i8
  store i8 %60, i8* %46, align 1, !tbaa !2454
  %61 = lshr i64 %52, 63
  %62 = trunc i64 %61 to i8
  store i8 %62, i8* %47, align 1, !tbaa !2454
  store i8 0, i8* %48, align 1, !tbaa !2454
  %63 = add i64 %38, -10491
  %64 = add i64 %38, 22
  %65 = add i64 %7, -64
  %66 = inttoptr i64 %65 to i64*
  store i64 %64, i64* %66, align 8
  store i64 %65, i64* %RSP, align 8, !tbaa !2428
  store i64 %63, i64* %PC, align 8, !tbaa !2428
  %67 = tail call %struct.Memory* @sub_400520__init_proc_renamed_(%struct.State* nonnull %0, i64 %63, %struct.Memory* %2)
  %68 = load i64, i64* %RBP, align 8
  %69 = load i64, i64* %PC, align 8
  store i8 0, i8* %43, align 1, !tbaa !2432
  %70 = trunc i64 %68 to i32
  %71 = and i32 %70, 255
  %72 = tail call i32 @llvm.ctpop.i32(i32 %71) #8
  %73 = trunc i32 %72 to i8
  %74 = and i8 %73, 1
  %75 = xor i8 %74, 1
  store i8 %75, i8* %44, align 1, !tbaa !2446
  %76 = icmp eq i64 %68, 0
  %77 = zext i1 %76 to i8
  store i8 %77, i8* %46, align 1, !tbaa !2448
  %78 = lshr i64 %68, 63
  %79 = trunc i64 %78 to i8
  store i8 %79, i8* %47, align 1, !tbaa !2449
  store i8 0, i8* %48, align 1, !tbaa !2450
  store i8 0, i8* %45, align 1, !tbaa !2447
  %.v = select i1 %76, i64 37, i64 5
  %80 = add i64 %69, %.v
  store i64 %80, i64* %PC, align 8, !tbaa !2428
  br i1 %76, label %block_402e56, label %block_402e36

block_402e56:                                     ; preds = %block_402e40, %block_402e00
  %81 = phi i64 [ %80, %block_402e00 ], [ %179, %block_402e40 ]
  %MEMORY.0 = phi %struct.Memory* [ %67, %block_402e00 ], [ %149, %block_402e40 ]
  %82 = load i64, i64* %RSP, align 8
  %83 = add i64 %82, 8
  store i64 %83, i64* %RSP, align 8, !tbaa !2428
  %84 = icmp ugt i64 %82, -9
  %85 = zext i1 %84 to i8
  store i8 %85, i8* %43, align 1, !tbaa !2432
  %86 = trunc i64 %83 to i32
  %87 = and i32 %86, 255
  %88 = tail call i32 @llvm.ctpop.i32(i32 %87) #8
  %89 = trunc i32 %88 to i8
  %90 = and i8 %89, 1
  %91 = xor i8 %90, 1
  store i8 %91, i8* %44, align 1, !tbaa !2446
  %92 = xor i64 %82, %83
  %93 = lshr i64 %92, 4
  %94 = trunc i64 %93 to i8
  %95 = and i8 %94, 1
  store i8 %95, i8* %45, align 1, !tbaa !2447
  %96 = icmp eq i64 %83, 0
  %97 = zext i1 %96 to i8
  store i8 %97, i8* %46, align 1, !tbaa !2448
  %98 = lshr i64 %83, 63
  %99 = trunc i64 %98 to i8
  store i8 %99, i8* %47, align 1, !tbaa !2449
  %100 = lshr i64 %82, 63
  %101 = xor i64 %98, %100
  %102 = add nuw nsw i64 %101, %98
  %103 = icmp eq i64 %102, 2
  %104 = zext i1 %103 to i8
  store i8 %104, i8* %48, align 1, !tbaa !2450
  %105 = add i64 %81, 5
  store i64 %105, i64* %PC, align 8
  %106 = add i64 %82, 16
  %107 = inttoptr i64 %83 to i64*
  %108 = load i64, i64* %107, align 8
  store i64 %108, i64* %RBX, align 8, !tbaa !2428
  store i64 %106, i64* %RSP, align 8, !tbaa !2428
  %109 = add i64 %81, 6
  store i64 %109, i64* %PC, align 8
  %110 = add i64 %82, 24
  %111 = inttoptr i64 %106 to i64*
  %112 = load i64, i64* %111, align 8
  store i64 %112, i64* %RBP, align 8, !tbaa !2428
  store i64 %110, i64* %RSP, align 8, !tbaa !2428
  %113 = add i64 %81, 8
  store i64 %113, i64* %PC, align 8
  %114 = add i64 %82, 32
  %115 = inttoptr i64 %110 to i64*
  %116 = load i64, i64* %115, align 8
  store i64 %116, i64* %R12, align 8, !tbaa !2428
  store i64 %114, i64* %RSP, align 8, !tbaa !2428
  %117 = add i64 %81, 10
  store i64 %117, i64* %PC, align 8
  %118 = add i64 %82, 40
  %119 = inttoptr i64 %114 to i64*
  %120 = load i64, i64* %119, align 8
  store i64 %120, i64* %R13, align 8, !tbaa !2428
  store i64 %118, i64* %RSP, align 8, !tbaa !2428
  %121 = add i64 %81, 12
  store i64 %121, i64* %PC, align 8
  %122 = add i64 %82, 48
  %123 = inttoptr i64 %118 to i64*
  %124 = load i64, i64* %123, align 8
  store i64 %124, i64* %R14, align 8, !tbaa !2428
  store i64 %122, i64* %RSP, align 8, !tbaa !2428
  %125 = add i64 %81, 14
  store i64 %125, i64* %PC, align 8
  %126 = add i64 %82, 56
  %127 = inttoptr i64 %122 to i64*
  %128 = load i64, i64* %127, align 8
  store i64 %128, i64* %R15, align 8, !tbaa !2428
  store i64 %126, i64* %RSP, align 8, !tbaa !2428
  %129 = add i64 %81, 15
  store i64 %129, i64* %PC, align 8
  %130 = inttoptr i64 %126 to i64*
  %131 = load i64, i64* %130, align 8
  store i64 %131, i64* %PC, align 8, !tbaa !2428
  %132 = add i64 %82, 64
  store i64 %132, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_402e36:                                     ; preds = %block_402e00
  store i64 0, i64* %RBX, align 8, !tbaa !2428
  store i8 0, i8* %43, align 1, !tbaa !2432
  store i8 1, i8* %44, align 1, !tbaa !2446
  store i8 1, i8* %46, align 1, !tbaa !2448
  store i8 0, i8* %47, align 1, !tbaa !2449
  store i8 0, i8* %48, align 1, !tbaa !2450
  store i8 0, i8* %45, align 1, !tbaa !2447
  %133 = add i64 %80, 10
  store i64 %133, i64* %PC, align 8
  br label %block_402e40

block_402e40:                                     ; preds = %block_402e40, %block_402e36
  %134 = phi i64 [ 0, %block_402e36 ], [ %152, %block_402e40 ]
  %135 = phi i64 [ %133, %block_402e36 ], [ %179, %block_402e40 ]
  %MEMORY.1 = phi %struct.Memory* [ %67, %block_402e36 ], [ %149, %block_402e40 ]
  %136 = load i64, i64* %R15, align 8
  store i64 %136, i64* %RDX, align 8, !tbaa !2428
  %137 = load i64, i64* %R14, align 8
  store i64 %137, i64* %RSI, align 8, !tbaa !2428
  %138 = load i32, i32* %R13D, align 4
  %139 = zext i32 %138 to i64
  store i64 %139, i64* %RDI, align 8, !tbaa !2428
  %140 = load i64, i64* %R12, align 8
  %141 = shl i64 %134, 3
  %142 = add i64 %141, %140
  %143 = add i64 %135, 13
  store i64 %143, i64* %PC, align 8
  %144 = load i64, i64* %RSP, align 8, !tbaa !2428
  %145 = add i64 %144, -8
  %146 = inttoptr i64 %145 to i64*
  store i64 %143, i64* %146, align 8
  store i64 %145, i64* %RSP, align 8, !tbaa !2428
  %147 = inttoptr i64 %142 to i64*
  %148 = load i64, i64* %147, align 8
  store i64 %148, i64* %PC, align 8, !tbaa !2428
  %149 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 %148, %struct.Memory* %MEMORY.1)
  %150 = load i64, i64* %RBX, align 8
  %151 = load i64, i64* %PC, align 8
  %152 = add i64 %150, 1
  store i64 %152, i64* %RBX, align 8, !tbaa !2428
  %153 = lshr i64 %152, 63
  %154 = load i64, i64* %RBP, align 8
  %155 = sub i64 %154, %152
  %156 = icmp ult i64 %154, %152
  %157 = zext i1 %156 to i8
  store i8 %157, i8* %43, align 1, !tbaa !2432
  %158 = trunc i64 %155 to i32
  %159 = and i32 %158, 255
  %160 = tail call i32 @llvm.ctpop.i32(i32 %159) #8
  %161 = trunc i32 %160 to i8
  %162 = and i8 %161, 1
  %163 = xor i8 %162, 1
  store i8 %163, i8* %44, align 1, !tbaa !2446
  %164 = xor i64 %152, %154
  %165 = xor i64 %164, %155
  %166 = lshr i64 %165, 4
  %167 = trunc i64 %166 to i8
  %168 = and i8 %167, 1
  store i8 %168, i8* %45, align 1, !tbaa !2447
  %169 = icmp eq i64 %155, 0
  %170 = zext i1 %169 to i8
  store i8 %170, i8* %46, align 1, !tbaa !2448
  %171 = lshr i64 %155, 63
  %172 = trunc i64 %171 to i8
  store i8 %172, i8* %47, align 1, !tbaa !2449
  %173 = lshr i64 %154, 63
  %174 = xor i64 %153, %173
  %175 = xor i64 %171, %173
  %176 = add nuw nsw i64 %175, %174
  %177 = icmp eq i64 %176, 2
  %178 = zext i1 %177 to i8
  store i8 %178, i8* %48, align 1, !tbaa !2450
  %.v1 = select i1 %169, i64 9, i64 -13
  %179 = add i64 %151, %.v1
  store i64 %179, i64* %PC, align 8, !tbaa !2428
  br i1 %169, label %block_402e56, label %block_402e40
}

; Function Attrs: noinline
define %struct.Memory* @sub_402a50_check_FP(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_402a50:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %5 to i32*
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %6 to i32*
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0
  %R10D = bitcast %union.anon* %8 to i32*
  %RAX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %6, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %11 = load i64, i64* %RBP, align 8
  %12 = add i64 %1, 1
  store i64 %12, i64* %PC, align 8
  %13 = load i64, i64* %RSP, align 8, !tbaa !2428
  %14 = add i64 %13, -8
  %15 = inttoptr i64 %14 to i64*
  store i64 %11, i64* %15, align 8
  %16 = load i64, i64* %PC, align 8
  store i64 %14, i64* %RBP, align 8, !tbaa !2428
  %17 = add i64 %13, -120
  store i64 %17, i64* %RSP, align 8, !tbaa !2428
  %18 = icmp ult i64 %14, 112
  %19 = zext i1 %18 to i8
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %19, i8* %20, align 1, !tbaa !2432
  %21 = trunc i64 %17 to i32
  %22 = and i32 %21, 255
  %23 = tail call i32 @llvm.ctpop.i32(i32 %22) #8
  %24 = trunc i32 %23 to i8
  %25 = and i8 %24, 1
  %26 = xor i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %26, i8* %27, align 1, !tbaa !2446
  %28 = xor i64 %14, 16
  %29 = xor i64 %28, %17
  %30 = lshr i64 %29, 4
  %31 = trunc i64 %30 to i8
  %32 = and i8 %31, 1
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %32, i8* %33, align 1, !tbaa !2447
  %34 = icmp eq i64 %17, 0
  %35 = zext i1 %34 to i8
  %36 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %35, i8* %36, align 1, !tbaa !2448
  %37 = lshr i64 %17, 63
  %38 = trunc i64 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %38, i8* %39, align 1, !tbaa !2449
  %40 = lshr i64 %14, 63
  %41 = xor i64 %37, %40
  %42 = add nuw nsw i64 %41, %40
  %43 = icmp eq i64 %42, 2
  %44 = zext i1 %43 to i8
  %45 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %44, i8* %45, align 1, !tbaa !2450
  %46 = bitcast [32 x %union.VectorReg]* %9 to i8*
  %47 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 88) to i64*), align 8
  %48 = bitcast [32 x %union.VectorReg]* %9 to double*
  %49 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %9, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %47, i64* %49, align 1, !tbaa !2452
  %50 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %51 = bitcast i64* %50 to double*
  store double 0.000000e+00, double* %51, align 1, !tbaa !2452
  %52 = add i64 %13, -16
  %53 = load i32, i32* %EDI, align 4
  %54 = add i64 %16, 18
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %52 to i32*
  store i32 %53, i32* %55, align 4
  %56 = load i64, i64* %RBP, align 8
  %57 = add i64 %56, -12
  %58 = load i32, i32* %ESI, align 4
  %59 = load i64, i64* %PC, align 8
  %60 = add i64 %59, 3
  store i64 %60, i64* %PC, align 8
  %61 = inttoptr i64 %57 to i32*
  store i32 %58, i32* %61, align 4
  %62 = load i64, i64* %RBP, align 8
  %63 = add i64 %62, -16
  %64 = load i32, i32* %EDX, align 4
  %65 = load i64, i64* %PC, align 8
  %66 = add i64 %65, 3
  store i64 %66, i64* %PC, align 8
  %67 = inttoptr i64 %63 to i32*
  store i32 %64, i32* %67, align 4
  %68 = load i64, i64* %RBP, align 8
  %69 = add i64 %68, -24
  %70 = load i64, i64* %RCX, align 8
  %71 = load i64, i64* %PC, align 8
  %72 = add i64 %71, 4
  store i64 %72, i64* %PC, align 8
  %73 = inttoptr i64 %69 to i64*
  store i64 %70, i64* %73, align 8
  %74 = load i64, i64* %RBP, align 8
  %75 = add i64 %74, -32
  %76 = load i64, i64* %R8, align 8
  %77 = load i64, i64* %PC, align 8
  %78 = add i64 %77, 4
  store i64 %78, i64* %PC, align 8
  %79 = inttoptr i64 %75 to i64*
  store i64 %76, i64* %79, align 8
  %80 = load i64, i64* %RBP, align 8
  %81 = add i64 %80, -56
  %82 = load i64, i64* %PC, align 8
  %83 = add i64 %82, 5
  store i64 %83, i64* %PC, align 8
  %84 = load i64, i64* %49, align 1
  %85 = inttoptr i64 %81 to i64*
  store i64 %84, i64* %85, align 8
  %86 = load i64, i64* %RBP, align 8
  %87 = add i64 %86, -36
  %88 = load i64, i64* %PC, align 8
  %89 = add i64 %88, 7
  store i64 %89, i64* %PC, align 8
  %90 = inttoptr i64 %87 to i32*
  store i32 0, i32* %90, align 4
  %91 = bitcast %union.VectorReg* %10 to i8*
  %92 = getelementptr inbounds i8, i8* %91, i64 4
  %93 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %94 = getelementptr inbounds i8, i8* %91, i64 12
  %95 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %10, i64 0, i32 0, i32 0, i32 0, i64 0
  %96 = bitcast [32 x %union.VectorReg]* %9 to i32*
  %97 = getelementptr inbounds i8, i8* %46, i64 4
  %98 = bitcast i8* %97 to i32*
  %99 = bitcast i64* %50 to i32*
  %100 = getelementptr inbounds i8, i8* %46, i64 12
  %101 = bitcast i8* %100 to i32*
  %.pre = load i64, i64* %PC, align 8
  br label %block_402a7d

block_402bbe:                                     ; preds = %block_402a95
  %102 = add i64 %555, -36
  %103 = add i64 %593, 8
  store i64 %103, i64* %PC, align 8
  %104 = inttoptr i64 %102 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = add i32 %105, 1
  %107 = zext i32 %106 to i64
  store i64 %107, i64* %RAX, align 8, !tbaa !2428
  %108 = icmp eq i32 %105, -1
  %109 = icmp eq i32 %106, 0
  %110 = or i1 %108, %109
  %111 = zext i1 %110 to i8
  store i8 %111, i8* %20, align 1, !tbaa !2432
  %112 = and i32 %106, 255
  %113 = tail call i32 @llvm.ctpop.i32(i32 %112) #8
  %114 = trunc i32 %113 to i8
  %115 = and i8 %114, 1
  %116 = xor i8 %115, 1
  store i8 %116, i8* %27, align 1, !tbaa !2446
  %117 = xor i32 %105, %106
  %118 = lshr i32 %117, 4
  %119 = trunc i32 %118 to i8
  %120 = and i8 %119, 1
  store i8 %120, i8* %33, align 1, !tbaa !2447
  %121 = zext i1 %109 to i8
  store i8 %121, i8* %36, align 1, !tbaa !2448
  %122 = lshr i32 %106, 31
  %123 = trunc i32 %122 to i8
  store i8 %123, i8* %39, align 1, !tbaa !2449
  %124 = lshr i32 %105, 31
  %125 = xor i32 %122, %124
  %126 = add nuw nsw i32 %125, %122
  %127 = icmp eq i32 %126, 2
  %128 = zext i1 %127 to i8
  store i8 %128, i8* %45, align 1, !tbaa !2450
  %129 = add i64 %593, 14
  store i64 %129, i64* %PC, align 8
  store i32 %106, i32* %104, align 4
  %130 = load i64, i64* %PC, align 8
  %131 = add i64 %130, -335
  store i64 %131, i64* %PC, align 8, !tbaa !2428
  br label %block_402a7d

block_402b98:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tE3MVnI7vec64_tEEEP6MemoryS8_R5StateT_T0_.exit
  %132 = load i64, i64* %RBP, align 8
  %133 = add i64 %132, -44
  %134 = add i64 %444, 8
  store i64 %134, i64* %PC, align 8
  %135 = inttoptr i64 %133 to i32*
  %136 = load i32, i32* %135, align 4
  %137 = add i32 %136, 1
  %138 = zext i32 %137 to i64
  store i64 %138, i64* %RAX, align 8, !tbaa !2428
  %139 = icmp eq i32 %136, -1
  %140 = icmp eq i32 %137, 0
  %141 = or i1 %139, %140
  %142 = zext i1 %141 to i8
  store i8 %142, i8* %20, align 1, !tbaa !2432
  %143 = and i32 %137, 255
  %144 = tail call i32 @llvm.ctpop.i32(i32 %143) #8
  %145 = trunc i32 %144 to i8
  %146 = and i8 %145, 1
  %147 = xor i8 %146, 1
  store i8 %147, i8* %27, align 1, !tbaa !2446
  %148 = xor i32 %136, %137
  %149 = lshr i32 %148, 4
  %150 = trunc i32 %149 to i8
  %151 = and i8 %150, 1
  store i8 %151, i8* %33, align 1, !tbaa !2447
  %152 = zext i1 %140 to i8
  store i8 %152, i8* %36, align 1, !tbaa !2448
  %153 = lshr i32 %137, 31
  %154 = trunc i32 %153 to i8
  store i8 %154, i8* %39, align 1, !tbaa !2449
  %155 = lshr i32 %136, 31
  %156 = xor i32 %153, %155
  %157 = add nuw nsw i32 %156, %153
  %158 = icmp eq i32 %157, 2
  %159 = zext i1 %158 to i8
  store i8 %159, i8* %45, align 1, !tbaa !2450
  %160 = add i64 %444, 14
  store i64 %160, i64* %PC, align 8
  store i32 %137, i32* %135, align 4
  %161 = load i64, i64* %PC, align 8
  %162 = add i64 %161, -249
  store i64 %162, i64* %PC, align 8, !tbaa !2428
  br label %block_402aad

block_402bd1:                                     ; preds = %block_402a7d
  %163 = add i64 %167, -4
  %164 = add i64 %205, 7
  store i64 %164, i64* %PC, align 8
  %165 = inttoptr i64 %163 to i32*
  store i32 1, i32* %165, align 4
  %.pre10 = load i64, i64* %PC, align 8
  br label %block_402bd8

block_402a7d:                                     ; preds = %block_402bbe, %block_402a50
  %166 = phi i64 [ %.pre, %block_402a50 ], [ %131, %block_402bbe ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_402a50 ], [ %MEMORY.3, %block_402bbe ]
  %167 = load i64, i64* %RBP, align 8
  %168 = add i64 %167, -36
  %169 = add i64 %166, 3
  store i64 %169, i64* %PC, align 8
  %170 = inttoptr i64 %168 to i32*
  %171 = load i32, i32* %170, align 4
  %172 = zext i32 %171 to i64
  store i64 %172, i64* %RAX, align 8, !tbaa !2428
  %173 = add i64 %167, -8
  %174 = add i64 %166, 6
  store i64 %174, i64* %PC, align 8
  %175 = inttoptr i64 %173 to i32*
  %176 = load i32, i32* %175, align 4
  %177 = add i32 %176, 1
  %178 = zext i32 %177 to i64
  store i64 %178, i64* %RCX, align 8, !tbaa !2428
  %179 = lshr i32 %177, 31
  %180 = sub i32 %171, %177
  %181 = icmp ult i32 %171, %177
  %182 = zext i1 %181 to i8
  store i8 %182, i8* %20, align 1, !tbaa !2432
  %183 = and i32 %180, 255
  %184 = tail call i32 @llvm.ctpop.i32(i32 %183) #8
  %185 = trunc i32 %184 to i8
  %186 = and i8 %185, 1
  %187 = xor i8 %186, 1
  store i8 %187, i8* %27, align 1, !tbaa !2446
  %188 = xor i32 %177, %171
  %189 = xor i32 %188, %180
  %190 = lshr i32 %189, 4
  %191 = trunc i32 %190 to i8
  %192 = and i8 %191, 1
  store i8 %192, i8* %33, align 1, !tbaa !2447
  %193 = icmp eq i32 %180, 0
  %194 = zext i1 %193 to i8
  store i8 %194, i8* %36, align 1, !tbaa !2448
  %195 = lshr i32 %180, 31
  %196 = trunc i32 %195 to i8
  store i8 %196, i8* %39, align 1, !tbaa !2449
  %197 = lshr i32 %171, 31
  %198 = xor i32 %179, %197
  %199 = xor i32 %195, %197
  %200 = add nuw nsw i32 %199, %198
  %201 = icmp eq i32 %200, 2
  %202 = zext i1 %201 to i8
  store i8 %202, i8* %45, align 1, !tbaa !2450
  %203 = icmp ne i8 %196, 0
  %204 = xor i1 %203, %201
  %.v = select i1 %204, i64 17, i64 340
  %205 = add i64 %166, %.v
  store i64 %205, i64* %PC, align 8, !tbaa !2428
  br i1 %204, label %block_402a8e, label %block_402bd1

block_402a8e:                                     ; preds = %block_402a7d
  %206 = add i64 %167, -40
  %207 = add i64 %205, 7
  store i64 %207, i64* %PC, align 8
  %208 = inttoptr i64 %206 to i32*
  store i32 0, i32* %208, align 4
  %.pre7 = load i64, i64* %PC, align 8
  br label %block_402a95

block_402abe:                                     ; preds = %block_402aad
  %209 = add i64 %446, -24
  %210 = add i64 %484, 4
  store i64 %210, i64* %PC, align 8
  %211 = inttoptr i64 %209 to i64*
  %212 = load i64, i64* %211, align 8
  store i64 %212, i64* %RAX, align 8, !tbaa !2428
  %213 = add i64 %446, -36
  %214 = add i64 %484, 8
  store i64 %214, i64* %PC, align 8
  %215 = inttoptr i64 %213 to i32*
  %216 = load i32, i32* %215, align 4
  %217 = sext i32 %216 to i64
  %218 = mul nsw i64 %217, 33800
  store i64 %218, i64* %RCX, align 8, !tbaa !2428
  %219 = lshr i64 %218, 63
  %220 = add i64 %218, %212
  store i64 %220, i64* %RAX, align 8, !tbaa !2428
  %221 = icmp ult i64 %220, %212
  %222 = icmp ult i64 %220, %218
  %223 = or i1 %221, %222
  %224 = zext i1 %223 to i8
  store i8 %224, i8* %20, align 1, !tbaa !2432
  %225 = trunc i64 %220 to i32
  %226 = and i32 %225, 255
  %227 = tail call i32 @llvm.ctpop.i32(i32 %226) #8
  %228 = trunc i32 %227 to i8
  %229 = and i8 %228, 1
  %230 = xor i8 %229, 1
  store i8 %230, i8* %27, align 1, !tbaa !2446
  %231 = xor i64 %218, %212
  %232 = xor i64 %231, %220
  %233 = lshr i64 %232, 4
  %234 = trunc i64 %233 to i8
  %235 = and i8 %234, 1
  store i8 %235, i8* %33, align 1, !tbaa !2447
  %236 = icmp eq i64 %220, 0
  %237 = zext i1 %236 to i8
  store i8 %237, i8* %36, align 1, !tbaa !2448
  %238 = lshr i64 %220, 63
  %239 = trunc i64 %238 to i8
  store i8 %239, i8* %39, align 1, !tbaa !2449
  %240 = lshr i64 %212, 63
  %241 = xor i64 %238, %240
  %242 = xor i64 %238, %219
  %243 = add nuw nsw i64 %241, %242
  %244 = icmp eq i64 %243, 2
  %245 = zext i1 %244 to i8
  store i8 %245, i8* %45, align 1, !tbaa !2450
  %246 = add i64 %446, -40
  %247 = add i64 %484, 22
  store i64 %247, i64* %PC, align 8
  %248 = inttoptr i64 %246 to i32*
  %249 = load i32, i32* %248, align 4
  %250 = sext i32 %249 to i64
  %251 = mul nsw i64 %250, 520
  store i64 %251, i64* %RCX, align 8, !tbaa !2428
  %252 = lshr i64 %251, 63
  %253 = add i64 %251, %220
  store i64 %253, i64* %RAX, align 8, !tbaa !2428
  %254 = icmp ult i64 %253, %220
  %255 = icmp ult i64 %253, %251
  %256 = or i1 %254, %255
  %257 = zext i1 %256 to i8
  store i8 %257, i8* %20, align 1, !tbaa !2432
  %258 = trunc i64 %253 to i32
  %259 = and i32 %258, 255
  %260 = tail call i32 @llvm.ctpop.i32(i32 %259) #8
  %261 = trunc i32 %260 to i8
  %262 = and i8 %261, 1
  %263 = xor i8 %262, 1
  store i8 %263, i8* %27, align 1, !tbaa !2446
  %264 = xor i64 %251, %220
  %265 = xor i64 %264, %253
  %266 = lshr i64 %265, 4
  %267 = trunc i64 %266 to i8
  %268 = and i8 %267, 1
  store i8 %268, i8* %33, align 1, !tbaa !2447
  %269 = icmp eq i64 %253, 0
  %270 = zext i1 %269 to i8
  store i8 %270, i8* %36, align 1, !tbaa !2448
  %271 = lshr i64 %253, 63
  %272 = trunc i64 %271 to i8
  store i8 %272, i8* %39, align 1, !tbaa !2449
  %273 = xor i64 %271, %238
  %274 = xor i64 %271, %252
  %275 = add nuw nsw i64 %273, %274
  %276 = icmp eq i64 %275, 2
  %277 = zext i1 %276 to i8
  store i8 %277, i8* %45, align 1, !tbaa !2450
  %278 = load i64, i64* %RBP, align 8
  %279 = add i64 %278, -44
  %280 = add i64 %484, 36
  store i64 %280, i64* %PC, align 8
  %281 = inttoptr i64 %279 to i32*
  %282 = load i32, i32* %281, align 4
  %283 = sext i32 %282 to i64
  store i64 %283, i64* %RCX, align 8, !tbaa !2428
  %284 = shl nsw i64 %283, 3
  %285 = add i64 %284, %253
  %286 = add i64 %484, 41
  store i64 %286, i64* %PC, align 8
  %287 = inttoptr i64 %285 to i64*
  %288 = load i64, i64* %287, align 8
  store i64 %288, i64* %49, align 1, !tbaa !2452
  store double 0.000000e+00, double* %51, align 1, !tbaa !2452
  %289 = add i64 %278, -64
  %290 = add i64 %484, 46
  store i64 %290, i64* %PC, align 8
  %291 = inttoptr i64 %289 to i64*
  store i64 %288, i64* %291, align 8
  %292 = load i64, i64* %RBP, align 8
  %293 = add i64 %292, -32
  %294 = load i64, i64* %PC, align 8
  %295 = add i64 %294, 4
  store i64 %295, i64* %PC, align 8
  %296 = inttoptr i64 %293 to i64*
  %297 = load i64, i64* %296, align 8
  store i64 %297, i64* %RAX, align 8, !tbaa !2428
  %298 = add i64 %292, -36
  %299 = add i64 %294, 8
  store i64 %299, i64* %PC, align 8
  %300 = inttoptr i64 %298 to i32*
  %301 = load i32, i32* %300, align 4
  %302 = sext i32 %301 to i64
  %303 = mul nsw i64 %302, 33800
  store i64 %303, i64* %RCX, align 8, !tbaa !2428
  %304 = lshr i64 %303, 63
  %305 = add i64 %303, %297
  store i64 %305, i64* %RAX, align 8, !tbaa !2428
  %306 = icmp ult i64 %305, %297
  %307 = icmp ult i64 %305, %303
  %308 = or i1 %306, %307
  %309 = zext i1 %308 to i8
  store i8 %309, i8* %20, align 1, !tbaa !2432
  %310 = trunc i64 %305 to i32
  %311 = and i32 %310, 255
  %312 = tail call i32 @llvm.ctpop.i32(i32 %311) #8
  %313 = trunc i32 %312 to i8
  %314 = and i8 %313, 1
  %315 = xor i8 %314, 1
  store i8 %315, i8* %27, align 1, !tbaa !2446
  %316 = xor i64 %303, %297
  %317 = xor i64 %316, %305
  %318 = lshr i64 %317, 4
  %319 = trunc i64 %318 to i8
  %320 = and i8 %319, 1
  store i8 %320, i8* %33, align 1, !tbaa !2447
  %321 = icmp eq i64 %305, 0
  %322 = zext i1 %321 to i8
  store i8 %322, i8* %36, align 1, !tbaa !2448
  %323 = lshr i64 %305, 63
  %324 = trunc i64 %323 to i8
  store i8 %324, i8* %39, align 1, !tbaa !2449
  %325 = lshr i64 %297, 63
  %326 = xor i64 %323, %325
  %327 = xor i64 %323, %304
  %328 = add nuw nsw i64 %326, %327
  %329 = icmp eq i64 %328, 2
  %330 = zext i1 %329 to i8
  store i8 %330, i8* %45, align 1, !tbaa !2450
  %331 = add i64 %292, -40
  %332 = add i64 %294, 22
  store i64 %332, i64* %PC, align 8
  %333 = inttoptr i64 %331 to i32*
  %334 = load i32, i32* %333, align 4
  %335 = sext i32 %334 to i64
  %336 = mul nsw i64 %335, 520
  store i64 %336, i64* %RCX, align 8, !tbaa !2428
  %337 = lshr i64 %336, 63
  %338 = add i64 %336, %305
  store i64 %338, i64* %RAX, align 8, !tbaa !2428
  %339 = icmp ult i64 %338, %305
  %340 = icmp ult i64 %338, %336
  %341 = or i1 %339, %340
  %342 = zext i1 %341 to i8
  store i8 %342, i8* %20, align 1, !tbaa !2432
  %343 = trunc i64 %338 to i32
  %344 = and i32 %343, 255
  %345 = tail call i32 @llvm.ctpop.i32(i32 %344) #8
  %346 = trunc i32 %345 to i8
  %347 = and i8 %346, 1
  %348 = xor i8 %347, 1
  store i8 %348, i8* %27, align 1, !tbaa !2446
  %349 = xor i64 %336, %305
  %350 = xor i64 %349, %338
  %351 = lshr i64 %350, 4
  %352 = trunc i64 %351 to i8
  %353 = and i8 %352, 1
  store i8 %353, i8* %33, align 1, !tbaa !2447
  %354 = icmp eq i64 %338, 0
  %355 = zext i1 %354 to i8
  store i8 %355, i8* %36, align 1, !tbaa !2448
  %356 = lshr i64 %338, 63
  %357 = trunc i64 %356 to i8
  store i8 %357, i8* %39, align 1, !tbaa !2449
  %358 = xor i64 %356, %323
  %359 = xor i64 %356, %337
  %360 = add nuw nsw i64 %358, %359
  %361 = icmp eq i64 %360, 2
  %362 = zext i1 %361 to i8
  store i8 %362, i8* %45, align 1, !tbaa !2450
  %363 = load i64, i64* %RBP, align 8
  %364 = add i64 %363, -44
  %365 = add i64 %294, 36
  store i64 %365, i64* %PC, align 8
  %366 = inttoptr i64 %364 to i32*
  %367 = load i32, i32* %366, align 4
  %368 = sext i32 %367 to i64
  store i64 %368, i64* %RCX, align 8, !tbaa !2428
  %369 = shl nsw i64 %368, 3
  %370 = add i64 %369, %338
  %371 = add i64 %294, 41
  store i64 %371, i64* %PC, align 8
  %372 = inttoptr i64 %370 to i64*
  %373 = load i64, i64* %372, align 8
  store i64 %373, i64* %49, align 1, !tbaa !2452
  store double 0.000000e+00, double* %51, align 1, !tbaa !2452
  %374 = add i64 %363, -72
  %375 = add i64 %294, 46
  store i64 %375, i64* %PC, align 8
  %376 = inttoptr i64 %374 to i64*
  store i64 %373, i64* %376, align 8
  %377 = load i64, i64* %RBP, align 8
  %378 = add i64 %377, -64
  %379 = load i64, i64* %PC, align 8
  %380 = add i64 %379, 5
  store i64 %380, i64* %PC, align 8
  %381 = inttoptr i64 %378 to double*
  %382 = load double, double* %381, align 8
  store double %382, double* %48, align 1, !tbaa !2452
  store double 0.000000e+00, double* %51, align 1, !tbaa !2452
  %383 = add i64 %377, -72
  %384 = add i64 %379, 10
  store i64 %384, i64* %PC, align 8
  %385 = inttoptr i64 %383 to double*
  %386 = load double, double* %385, align 8
  %387 = fsub double %382, %386
  %388 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 96) to i32*), align 16
  %389 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 100) to i32*), align 4
  %390 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 104) to i32*), align 8
  %391 = load i32, i32* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 108) to i32*), align 4
  %392 = bitcast %union.VectorReg* %10 to i32*
  store i32 %388, i32* %392, align 1, !tbaa !2455
  %393 = bitcast i8* %92 to i32*
  store i32 %389, i32* %393, align 1, !tbaa !2455
  %394 = bitcast i64* %93 to i32*
  store i32 %390, i32* %394, align 1, !tbaa !2455
  %395 = bitcast i8* %94 to i32*
  store i32 %391, i32* %395, align 1, !tbaa !2455
  %396 = bitcast double %387 to i64
  %397 = load i64, i64* %95, align 1
  %398 = and i64 %397, %396
  %399 = trunc i64 %398 to i32
  %400 = lshr i64 %398, 32
  %401 = trunc i64 %400 to i32
  store i32 %399, i32* %96, align 1, !tbaa !2451
  store i32 %401, i32* %98, align 1, !tbaa !2451
  store i32 0, i32* %99, align 1, !tbaa !2451
  store i32 0, i32* %101, align 1, !tbaa !2451
  %402 = add i64 %377, -80
  %403 = add i64 %379, 26
  store i64 %403, i64* %PC, align 8
  %404 = load i64, i64* %49, align 1
  %405 = inttoptr i64 %402 to i64*
  store i64 %404, i64* %405, align 8
  %406 = load i64, i64* %RBP, align 8
  %407 = add i64 %406, -80
  %408 = load i64, i64* %PC, align 8
  %409 = add i64 %408, 5
  store i64 %409, i64* %PC, align 8
  %410 = inttoptr i64 %407 to double*
  %411 = load double, double* %410, align 8
  store double %411, double* %48, align 1, !tbaa !2452
  store double 0.000000e+00, double* %51, align 1, !tbaa !2452
  %412 = add i64 %406, -56
  %413 = add i64 %408, 10
  store i64 %413, i64* %PC, align 8
  %414 = inttoptr i64 %412 to double*
  %415 = load double, double* %414, align 8
  %416 = fcmp uno double %411, %415
  br i1 %416, label %417, label %427

; <label>:417:                                    ; preds = %block_402abe
  %418 = fadd double %411, %415
  %419 = bitcast double %418 to i64
  %420 = and i64 %419, 9221120237041090560
  %421 = icmp eq i64 %420, 9218868437227405312
  %422 = and i64 %419, 2251799813685247
  %423 = icmp ne i64 %422, 0
  %424 = and i1 %421, %423
  br i1 %424, label %425, label %433

; <label>:425:                                    ; preds = %417
  %426 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %413, %struct.Memory* %MEMORY.1) #9
  %.pre9 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tE3MVnI7vec64_tEEEP6MemoryS8_R5StateT_T0_.exit

; <label>:427:                                    ; preds = %block_402abe
  %428 = fcmp ogt double %411, %415
  br i1 %428, label %433, label %429

; <label>:429:                                    ; preds = %427
  %430 = fcmp olt double %411, %415
  br i1 %430, label %433, label %431

; <label>:431:                                    ; preds = %429
  %432 = fcmp oeq double %411, %415
  br i1 %432, label %433, label %437

; <label>:433:                                    ; preds = %431, %429, %427, %417
  %434 = phi i8 [ 0, %427 ], [ 0, %429 ], [ 1, %431 ], [ 1, %417 ]
  %435 = phi i8 [ 0, %427 ], [ 0, %429 ], [ 0, %431 ], [ 1, %417 ]
  %436 = phi i8 [ 0, %427 ], [ 1, %429 ], [ 0, %431 ], [ 1, %417 ]
  store i8 %434, i8* %36, align 1, !tbaa !2454
  store i8 %435, i8* %27, align 1, !tbaa !2454
  store i8 %436, i8* %20, align 1, !tbaa !2454
  br label %437

; <label>:437:                                    ; preds = %433, %431
  store i8 0, i8* %45, align 1, !tbaa !2454
  store i8 0, i8* %39, align 1, !tbaa !2454
  store i8 0, i8* %33, align 1, !tbaa !2454
  br label %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tE3MVnI7vec64_tEEEP6MemoryS8_R5StateT_T0_.exit

_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tE3MVnI7vec64_tEEEP6MemoryS8_R5StateT_T0_.exit: ; preds = %437, %425
  %438 = phi i64 [ %.pre9, %425 ], [ %413, %437 ]
  %439 = phi %struct.Memory* [ %426, %425 ], [ %MEMORY.1, %437 ]
  %440 = load i8, i8* %20, align 1, !tbaa !2432
  %441 = load i8, i8* %36, align 1, !tbaa !2448
  %442 = or i8 %441, %440
  %443 = icmp ne i8 %442, 0
  %.v13 = select i1 %443, i64 90, i64 6
  %444 = add i64 %438, %.v13
  store i64 %444, i64* %PC, align 8, !tbaa !2428
  br i1 %443, label %block_402b98, label %block_402b44

block_402aad:                                     ; preds = %block_402aa6, %block_402b98
  %445 = phi i64 [ %.pre8, %block_402aa6 ], [ %162, %block_402b98 ]
  %MEMORY.1 = phi %struct.Memory* [ %MEMORY.3, %block_402aa6 ], [ %439, %block_402b98 ]
  %446 = load i64, i64* %RBP, align 8
  %447 = add i64 %446, -44
  %448 = add i64 %445, 3
  store i64 %448, i64* %PC, align 8
  %449 = inttoptr i64 %447 to i32*
  %450 = load i32, i32* %449, align 4
  %451 = zext i32 %450 to i64
  store i64 %451, i64* %RAX, align 8, !tbaa !2428
  %452 = add i64 %446, -12
  %453 = add i64 %445, 6
  store i64 %453, i64* %PC, align 8
  %454 = inttoptr i64 %452 to i32*
  %455 = load i32, i32* %454, align 4
  %456 = add i32 %455, 1
  %457 = zext i32 %456 to i64
  store i64 %457, i64* %RCX, align 8, !tbaa !2428
  %458 = lshr i32 %456, 31
  %459 = sub i32 %450, %456
  %460 = icmp ult i32 %450, %456
  %461 = zext i1 %460 to i8
  store i8 %461, i8* %20, align 1, !tbaa !2432
  %462 = and i32 %459, 255
  %463 = tail call i32 @llvm.ctpop.i32(i32 %462) #8
  %464 = trunc i32 %463 to i8
  %465 = and i8 %464, 1
  %466 = xor i8 %465, 1
  store i8 %466, i8* %27, align 1, !tbaa !2446
  %467 = xor i32 %456, %450
  %468 = xor i32 %467, %459
  %469 = lshr i32 %468, 4
  %470 = trunc i32 %469 to i8
  %471 = and i8 %470, 1
  store i8 %471, i8* %33, align 1, !tbaa !2447
  %472 = icmp eq i32 %459, 0
  %473 = zext i1 %472 to i8
  store i8 %473, i8* %36, align 1, !tbaa !2448
  %474 = lshr i32 %459, 31
  %475 = trunc i32 %474 to i8
  store i8 %475, i8* %39, align 1, !tbaa !2449
  %476 = lshr i32 %450, 31
  %477 = xor i32 %458, %476
  %478 = xor i32 %474, %476
  %479 = add nuw nsw i32 %478, %477
  %480 = icmp eq i32 %479, 2
  %481 = zext i1 %480 to i8
  store i8 %481, i8* %45, align 1, !tbaa !2450
  %482 = icmp ne i8 %475, 0
  %483 = xor i1 %482, %480
  %.v12 = select i1 %483, i64 17, i64 254
  %484 = add i64 %445, %.v12
  store i64 %484, i64* %PC, align 8, !tbaa !2428
  br i1 %483, label %block_402abe, label %block_402bab

block_402bab:                                     ; preds = %block_402aad
  %485 = add i64 %446, -40
  %486 = add i64 %484, 8
  store i64 %486, i64* %PC, align 8
  %487 = inttoptr i64 %485 to i32*
  %488 = load i32, i32* %487, align 4
  %489 = add i32 %488, 1
  %490 = zext i32 %489 to i64
  store i64 %490, i64* %RAX, align 8, !tbaa !2428
  %491 = icmp eq i32 %488, -1
  %492 = icmp eq i32 %489, 0
  %493 = or i1 %491, %492
  %494 = zext i1 %493 to i8
  store i8 %494, i8* %20, align 1, !tbaa !2432
  %495 = and i32 %489, 255
  %496 = tail call i32 @llvm.ctpop.i32(i32 %495) #8
  %497 = trunc i32 %496 to i8
  %498 = and i8 %497, 1
  %499 = xor i8 %498, 1
  store i8 %499, i8* %27, align 1, !tbaa !2446
  %500 = xor i32 %488, %489
  %501 = lshr i32 %500, 4
  %502 = trunc i32 %501 to i8
  %503 = and i8 %502, 1
  store i8 %503, i8* %33, align 1, !tbaa !2447
  %504 = zext i1 %492 to i8
  store i8 %504, i8* %36, align 1, !tbaa !2448
  %505 = lshr i32 %489, 31
  %506 = trunc i32 %505 to i8
  store i8 %506, i8* %39, align 1, !tbaa !2449
  %507 = lshr i32 %488, 31
  %508 = xor i32 %505, %507
  %509 = add nuw nsw i32 %508, %505
  %510 = icmp eq i32 %509, 2
  %511 = zext i1 %510 to i8
  store i8 %511, i8* %45, align 1, !tbaa !2450
  %512 = add i64 %484, 14
  store i64 %512, i64* %PC, align 8
  store i32 %489, i32* %487, align 4
  %513 = load i64, i64* %PC, align 8
  %514 = add i64 %513, -292
  store i64 %514, i64* %PC, align 8, !tbaa !2428
  br label %block_402a95

block_402bd8:                                     ; preds = %block_402b44, %block_402bd1
  %515 = phi i64 [ %.pre10, %block_402bd1 ], [ %669, %block_402b44 ]
  %MEMORY.2 = phi %struct.Memory* [ %MEMORY.0, %block_402bd1 ], [ %656, %block_402b44 ]
  %516 = load i64, i64* %RBP, align 8
  %517 = add i64 %516, -4
  %518 = add i64 %515, 3
  store i64 %518, i64* %PC, align 8
  %519 = inttoptr i64 %517 to i32*
  %520 = load i32, i32* %519, align 4
  %521 = zext i32 %520 to i64
  store i64 %521, i64* %RAX, align 8, !tbaa !2428
  %522 = load i64, i64* %RSP, align 8
  %523 = add i64 %522, 112
  store i64 %523, i64* %RSP, align 8, !tbaa !2428
  %524 = icmp ugt i64 %522, -113
  %525 = zext i1 %524 to i8
  store i8 %525, i8* %20, align 1, !tbaa !2432
  %526 = trunc i64 %523 to i32
  %527 = and i32 %526, 255
  %528 = tail call i32 @llvm.ctpop.i32(i32 %527) #8
  %529 = trunc i32 %528 to i8
  %530 = and i8 %529, 1
  %531 = xor i8 %530, 1
  store i8 %531, i8* %27, align 1, !tbaa !2446
  %532 = xor i64 %522, 16
  %533 = xor i64 %532, %523
  %534 = lshr i64 %533, 4
  %535 = trunc i64 %534 to i8
  %536 = and i8 %535, 1
  store i8 %536, i8* %33, align 1, !tbaa !2447
  %537 = icmp eq i64 %523, 0
  %538 = zext i1 %537 to i8
  store i8 %538, i8* %36, align 1, !tbaa !2448
  %539 = lshr i64 %523, 63
  %540 = trunc i64 %539 to i8
  store i8 %540, i8* %39, align 1, !tbaa !2449
  %541 = lshr i64 %522, 63
  %542 = xor i64 %539, %541
  %543 = add nuw nsw i64 %542, %539
  %544 = icmp eq i64 %543, 2
  %545 = zext i1 %544 to i8
  store i8 %545, i8* %45, align 1, !tbaa !2450
  %546 = add i64 %515, 8
  store i64 %546, i64* %PC, align 8
  %547 = add i64 %522, 120
  %548 = inttoptr i64 %523 to i64*
  %549 = load i64, i64* %548, align 8
  store i64 %549, i64* %RBP, align 8, !tbaa !2428
  store i64 %547, i64* %RSP, align 8, !tbaa !2428
  %550 = add i64 %515, 9
  store i64 %550, i64* %PC, align 8
  %551 = inttoptr i64 %547 to i64*
  %552 = load i64, i64* %551, align 8
  store i64 %552, i64* %PC, align 8, !tbaa !2428
  %553 = add i64 %522, 128
  store i64 %553, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.2

block_402a95:                                     ; preds = %block_402bab, %block_402a8e
  %554 = phi i64 [ %.pre7, %block_402a8e ], [ %514, %block_402bab ]
  %MEMORY.3 = phi %struct.Memory* [ %MEMORY.0, %block_402a8e ], [ %MEMORY.1, %block_402bab ]
  %555 = load i64, i64* %RBP, align 8
  %556 = add i64 %555, -40
  %557 = add i64 %554, 3
  store i64 %557, i64* %PC, align 8
  %558 = inttoptr i64 %556 to i32*
  %559 = load i32, i32* %558, align 4
  %560 = zext i32 %559 to i64
  store i64 %560, i64* %RAX, align 8, !tbaa !2428
  %561 = add i64 %555, -16
  %562 = add i64 %554, 6
  store i64 %562, i64* %PC, align 8
  %563 = inttoptr i64 %561 to i32*
  %564 = load i32, i32* %563, align 4
  %565 = add i32 %564, 1
  %566 = zext i32 %565 to i64
  store i64 %566, i64* %RCX, align 8, !tbaa !2428
  %567 = lshr i32 %565, 31
  %568 = sub i32 %559, %565
  %569 = icmp ult i32 %559, %565
  %570 = zext i1 %569 to i8
  store i8 %570, i8* %20, align 1, !tbaa !2432
  %571 = and i32 %568, 255
  %572 = tail call i32 @llvm.ctpop.i32(i32 %571) #8
  %573 = trunc i32 %572 to i8
  %574 = and i8 %573, 1
  %575 = xor i8 %574, 1
  store i8 %575, i8* %27, align 1, !tbaa !2446
  %576 = xor i32 %565, %559
  %577 = xor i32 %576, %568
  %578 = lshr i32 %577, 4
  %579 = trunc i32 %578 to i8
  %580 = and i8 %579, 1
  store i8 %580, i8* %33, align 1, !tbaa !2447
  %581 = icmp eq i32 %568, 0
  %582 = zext i1 %581 to i8
  store i8 %582, i8* %36, align 1, !tbaa !2448
  %583 = lshr i32 %568, 31
  %584 = trunc i32 %583 to i8
  store i8 %584, i8* %39, align 1, !tbaa !2449
  %585 = lshr i32 %559, 31
  %586 = xor i32 %567, %585
  %587 = xor i32 %583, %585
  %588 = add nuw nsw i32 %587, %586
  %589 = icmp eq i32 %588, 2
  %590 = zext i1 %589 to i8
  store i8 %590, i8* %45, align 1, !tbaa !2450
  %591 = icmp ne i8 %584, 0
  %592 = xor i1 %591, %589
  %.v11 = select i1 %592, i64 17, i64 297
  %593 = add i64 %554, %.v11
  store i64 %593, i64* %PC, align 8, !tbaa !2428
  br i1 %592, label %block_402aa6, label %block_402bbe

block_402aa6:                                     ; preds = %block_402a95
  %594 = add i64 %555, -44
  %595 = add i64 %593, 7
  store i64 %595, i64* %PC, align 8
  %596 = inttoptr i64 %594 to i32*
  store i32 0, i32* %596, align 4
  %.pre8 = load i64, i64* %PC, align 8
  br label %block_402aad

block_402b44:                                     ; preds = %_ZN12_GLOBAL__N_1L6COMISDI2VnI8vec128_tE3MVnI7vec64_tEEEP6MemoryS8_R5StateT_T0_.exit
  store i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 178), i64* %RSI, align 8, !tbaa !2428
  %597 = load i64, i64* @stderr, align 32
  store i64 %597, i64* %RDI, align 8, !tbaa !2428
  %598 = load i64, i64* %RBP, align 8
  %599 = add i64 %598, -36
  %600 = add i64 %444, 21
  store i64 %600, i64* %PC, align 8
  %601 = inttoptr i64 %599 to i32*
  %602 = load i32, i32* %601, align 4
  %603 = zext i32 %602 to i64
  store i64 %603, i64* %RDX, align 8, !tbaa !2428
  %604 = add i64 %598, -40
  %605 = add i64 %444, 24
  store i64 %605, i64* %PC, align 8
  %606 = inttoptr i64 %604 to i32*
  %607 = load i32, i32* %606, align 4
  %608 = zext i32 %607 to i64
  store i64 %608, i64* %RCX, align 8, !tbaa !2428
  %609 = add i64 %598, -44
  %610 = add i64 %444, 28
  store i64 %610, i64* %PC, align 8
  %611 = inttoptr i64 %609 to i32*
  %612 = load i32, i32* %611, align 4
  %613 = zext i32 %612 to i64
  store i64 %613, i64* %R8, align 8, !tbaa !2428
  %614 = add i64 %598, -64
  %615 = add i64 %444, 33
  store i64 %615, i64* %PC, align 8
  %616 = inttoptr i64 %614 to i64*
  %617 = load i64, i64* %616, align 8
  store i64 %617, i64* %49, align 1, !tbaa !2452
  store double 0.000000e+00, double* %51, align 1, !tbaa !2452
  %618 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %619 = add i64 %444, 37
  store i64 %619, i64* %PC, align 8
  %620 = load i32, i32* %601, align 4
  %621 = zext i32 %620 to i64
  store i64 %621, i64* %618, align 8, !tbaa !2428
  %622 = add i64 %444, 40
  store i64 %622, i64* %PC, align 8
  %623 = load i32, i32* %606, align 4
  %624 = zext i32 %623 to i64
  store i64 %624, i64* %RAX, align 8, !tbaa !2428
  %625 = getelementptr inbounds %union.anon, %union.anon* %8, i64 0, i32 0
  %626 = add i64 %444, 44
  store i64 %626, i64* %PC, align 8
  %627 = load i32, i32* %611, align 4
  %628 = zext i32 %627 to i64
  store i64 %628, i64* %625, align 8, !tbaa !2428
  %629 = add i64 %598, -72
  %630 = add i64 %444, 49
  store i64 %630, i64* %PC, align 8
  %631 = inttoptr i64 %629 to i64*
  %632 = load i64, i64* %631, align 8
  store i64 %632, i64* %95, align 1, !tbaa !2452
  %633 = bitcast i64* %93 to double*
  store double 0.000000e+00, double* %633, align 1, !tbaa !2452
  %634 = add i64 %598, -56
  %635 = add i64 %444, 54
  store i64 %635, i64* %PC, align 8
  %636 = inttoptr i64 %634 to i64*
  %637 = load i64, i64* %636, align 8
  %638 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 0
  store i64 %637, i64* %638, align 1, !tbaa !2452
  %639 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %640 = bitcast i64* %639 to double*
  store double 0.000000e+00, double* %640, align 1, !tbaa !2452
  %641 = bitcast i64* %RSP to i32**
  %642 = load i32*, i32** %641, align 8
  %643 = add i64 %444, 57
  store i64 %643, i64* %PC, align 8
  store i32 %623, i32* %642, align 4
  %644 = load i64, i64* %RSP, align 8
  %645 = add i64 %644, 8
  %646 = load i32, i32* %R10D, align 4
  %647 = load i64, i64* %PC, align 8
  %648 = add i64 %647, 5
  store i64 %648, i64* %PC, align 8
  %649 = inttoptr i64 %645 to i32*
  store i32 %646, i32* %649, align 4
  %650 = load i64, i64* %PC, align 8
  store i8 3, i8* %AL, align 1, !tbaa !2454
  %651 = add i64 %650, -9730
  %652 = add i64 %650, 7
  %653 = load i64, i64* %RSP, align 8, !tbaa !2428
  %654 = add i64 %653, -8
  %655 = inttoptr i64 %654 to i64*
  store i64 %652, i64* %655, align 8
  store i64 %654, i64* %RSP, align 8, !tbaa !2428
  store i64 %651, i64* %PC, align 8, !tbaa !2428
  %656 = tail call fastcc %struct.Memory* @ext_6040f8_fprintf(%struct.State* nonnull %0, %struct.Memory* %439)
  %657 = load i64, i64* %RBP, align 8
  %658 = add i64 %657, -4
  %659 = load i64, i64* %PC, align 8
  %660 = add i64 %659, 7
  store i64 %660, i64* %PC, align 8
  %661 = inttoptr i64 %658 to i32*
  store i32 0, i32* %661, align 4
  %662 = load i64, i64* %RBP, align 8
  %663 = add i64 %662, -84
  %664 = load i32, i32* %EAX, align 4
  %665 = load i64, i64* %PC, align 8
  %666 = add i64 %665, 3
  store i64 %666, i64* %PC, align 8
  %667 = inttoptr i64 %663 to i32*
  store i32 %664, i32* %667, align 4
  %668 = load i64, i64* %PC, align 8
  %669 = add i64 %668, 69
  store i64 %669, i64* %PC, align 8, !tbaa !2428
  br label %block_402bd8
}

; Function Attrs: noinline
define %struct.Memory* @sub_402e74__term_proc(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_402e74:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = add i64 %3, -8
  %5 = icmp ult i64 %3, 8
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %10 = lshr i64 %4, 63
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %12 = lshr i64 %3, 63
  %13 = xor i64 %10, %12
  %14 = add nuw nsw i64 %13, %12
  %15 = icmp eq i64 %14, 2
  %16 = zext i1 %15 to i8
  %17 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %18 = zext i1 %5 to i8
  store i8 %18, i8* %6, align 1, !tbaa !2432
  %19 = trunc i64 %3 to i32
  %20 = and i32 %19, 255
  %21 = tail call i32 @llvm.ctpop.i32(i32 %20) #8
  %22 = trunc i32 %21 to i8
  %23 = and i8 %22, 1
  %24 = xor i8 %23, 1
  store i8 %24, i8* %7, align 1, !tbaa !2446
  %25 = xor i64 %4, %3
  %26 = lshr i64 %25, 4
  %27 = trunc i64 %26 to i8
  %28 = and i8 %27, 1
  store i8 %28, i8* %8, align 1, !tbaa !2447
  %29 = icmp eq i64 %3, 0
  %30 = zext i1 %29 to i8
  store i8 %30, i8* %9, align 1, !tbaa !2448
  %31 = trunc i64 %12 to i8
  store i8 %31, i8* %11, align 1, !tbaa !2449
  store i8 %16, i8* %17, align 1, !tbaa !2450
  %32 = add i64 %1, 9
  store i64 %32, i64* %PC, align 8
  %33 = inttoptr i64 %3 to i64*
  %34 = load i64, i64* %33, align 8
  store i64 %34, i64* %PC, align 8, !tbaa !2428
  %35 = add i64 %3, 8
  store i64 %35, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_4005f0_deregister_tm_clones(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_4005f0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  store i64 %7, i64* %5, align 8, !tbaa !2428
  %9 = load i64, i64* %PC, align 8
  store i64 6307928, i64* %RAX, align 8, !tbaa !2428
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %10, align 1, !tbaa !2432
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %11, align 1, !tbaa !2446
  %12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %12, align 1, !tbaa !2447
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %13, align 1, !tbaa !2448
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %14, align 1, !tbaa !2449
  %15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %15, align 1, !tbaa !2450
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %16 = add i64 %9, 40
  store i64 %16, i64* %PC, align 8
  %17 = load i64, i64* %8, align 8
  store i64 %17, i64* %RBP, align 8, !tbaa !2428
  store i64 %6, i64* %5, align 8, !tbaa !2428
  %18 = add i64 %9, 41
  store i64 %18, i64* %PC, align 8
  %19 = inttoptr i64 %6 to i64*
  %20 = load i64, i64* %19, align 8
  store i64 %20, i64* %PC, align 8, !tbaa !2428
  %21 = add i64 %6, 8
  store i64 %21, i64* %5, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_400f90_init_array(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_400f90:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %5 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %R12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 25, i32 0, i32 0
  %R13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 27, i32 0, i32 0
  %R14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 29, i32 0, i32 0
  %R15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 31, i32 0, i32 0
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 3
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 4
  %11 = load i64, i64* %RBP, align 8
  %12 = add i64 %1, 1
  store i64 %12, i64* %PC, align 8
  %13 = load i64, i64* %RSP, align 8, !tbaa !2428
  %14 = add i64 %13, -8
  %15 = inttoptr i64 %14 to i64*
  store i64 %11, i64* %15, align 8
  %16 = load i64, i64* %PC, align 8
  store i64 %14, i64* %RBP, align 8, !tbaa !2428
  %17 = load i64, i64* %R15, align 8
  %18 = add i64 %16, 5
  store i64 %18, i64* %PC, align 8
  %19 = add i64 %13, -16
  %20 = inttoptr i64 %19 to i64*
  store i64 %17, i64* %20, align 8
  %21 = load i64, i64* %R14, align 8
  %22 = load i64, i64* %PC, align 8
  %23 = add i64 %22, 2
  store i64 %23, i64* %PC, align 8
  %24 = add i64 %13, -24
  %25 = inttoptr i64 %24 to i64*
  store i64 %21, i64* %25, align 8
  %26 = load i64, i64* %R13, align 8
  %27 = load i64, i64* %PC, align 8
  %28 = add i64 %27, 2
  store i64 %28, i64* %PC, align 8
  %29 = add i64 %13, -32
  %30 = inttoptr i64 %29 to i64*
  store i64 %26, i64* %30, align 8
  %31 = load i64, i64* %R12, align 8
  %32 = load i64, i64* %PC, align 8
  %33 = add i64 %32, 2
  store i64 %33, i64* %PC, align 8
  %34 = add i64 %13, -40
  %35 = inttoptr i64 %34 to i64*
  store i64 %31, i64* %35, align 8
  %36 = load i64, i64* %RBX, align 8
  %37 = load i64, i64* %PC, align 8
  %38 = add i64 %37, 1
  store i64 %38, i64* %PC, align 8
  %39 = add i64 %13, -48
  %40 = inttoptr i64 %39 to i64*
  store i64 %36, i64* %40, align 8
  %41 = load i64, i64* %RAX, align 8
  %42 = load i64, i64* %PC, align 8
  %43 = add i64 %42, 1
  store i64 %43, i64* %PC, align 8
  %44 = add i64 %13, -56
  %45 = inttoptr i64 %44 to i64*
  store i64 %41, i64* %45, align 8
  store i64 %44, i64* %RSP, align 8, !tbaa !2428
  %46 = load i64, i64* %RBP, align 8
  %47 = add i64 %46, 88
  %48 = load i64, i64* %PC, align 8
  %49 = add i64 %48, 4
  store i64 %49, i64* %PC, align 8
  %50 = inttoptr i64 %47 to i64*
  %51 = load i64, i64* %50, align 8
  store i64 %51, i64* %RAX, align 8, !tbaa !2428
  %52 = add i64 %46, 80
  %53 = add i64 %48, 8
  store i64 %53, i64* %PC, align 8
  %54 = inttoptr i64 %52 to i64*
  %55 = load i64, i64* %54, align 8
  store i64 %55, i64* %R10, align 8, !tbaa !2428
  %56 = add i64 %46, 72
  %57 = add i64 %48, 12
  store i64 %57, i64* %PC, align 8
  %58 = inttoptr i64 %56 to i64*
  %59 = load i64, i64* %58, align 8
  store i64 %59, i64* %R11, align 8, !tbaa !2428
  %60 = add i64 %46, 64
  %61 = add i64 %48, 16
  store i64 %61, i64* %PC, align 8
  %62 = inttoptr i64 %60 to i64*
  %63 = load i64, i64* %62, align 8
  store i64 %63, i64* %RBX, align 8, !tbaa !2428
  %64 = add i64 %46, 56
  %65 = add i64 %48, 20
  store i64 %65, i64* %PC, align 8
  %66 = inttoptr i64 %64 to i64*
  %67 = load i64, i64* %66, align 8
  store i64 %67, i64* %R14, align 8, !tbaa !2428
  %68 = add i64 %46, 48
  %69 = add i64 %48, 24
  store i64 %69, i64* %PC, align 8
  %70 = inttoptr i64 %68 to i64*
  %71 = load i64, i64* %70, align 8
  store i64 %71, i64* %R15, align 8, !tbaa !2428
  %72 = add i64 %46, 40
  %73 = add i64 %48, 28
  store i64 %73, i64* %PC, align 8
  %74 = inttoptr i64 %72 to i64*
  %75 = load i64, i64* %74, align 8
  store i64 %75, i64* %R12, align 8, !tbaa !2428
  %76 = add i64 %46, 32
  %77 = add i64 %48, 32
  store i64 %77, i64* %PC, align 8
  %78 = inttoptr i64 %76 to i64*
  %79 = load i64, i64* %78, align 8
  store i64 %79, i64* %R13, align 8, !tbaa !2428
  %80 = add i64 %46, -104
  %81 = add i64 %48, 36
  store i64 %81, i64* %PC, align 8
  %82 = inttoptr i64 %80 to i64*
  store i64 %51, i64* %82, align 8
  %83 = load i64, i64* %RBP, align 8
  %84 = add i64 %83, 24
  %85 = load i64, i64* %PC, align 8
  %86 = add i64 %85, 4
  store i64 %86, i64* %PC, align 8
  %87 = inttoptr i64 %84 to i64*
  %88 = load i64, i64* %87, align 8
  store i64 %88, i64* %RAX, align 8, !tbaa !2428
  %89 = add i64 %83, -112
  %90 = add i64 %85, 8
  store i64 %90, i64* %PC, align 8
  %91 = inttoptr i64 %89 to i64*
  store i64 %88, i64* %91, align 8
  %92 = load i64, i64* %RBP, align 8
  %93 = add i64 %92, 16
  %94 = load i64, i64* %PC, align 8
  %95 = add i64 %94, 4
  store i64 %95, i64* %PC, align 8
  %96 = inttoptr i64 %93 to i64*
  %97 = load i64, i64* %96, align 8
  store i64 %97, i64* %RAX, align 8, !tbaa !2428
  %98 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 8) to i64*), align 8
  %99 = bitcast [32 x %union.VectorReg]* %6 to double*
  %100 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %98, i64* %100, align 1, !tbaa !2452
  %101 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %102 = bitcast i64* %101 to double*
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %103 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 16) to i64*), align 16
  %104 = bitcast %union.VectorReg* %7 to double*
  %105 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %7, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %103, i64* %105, align 1, !tbaa !2452
  %106 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %107 = bitcast i64* %106 to double*
  store double 0.000000e+00, double* %107, align 1, !tbaa !2452
  %108 = add i64 %92, -44
  %109 = load i32, i32* %EDI, align 4
  %110 = add i64 %94, 23
  store i64 %110, i64* %PC, align 8
  %111 = inttoptr i64 %108 to i32*
  store i32 %109, i32* %111, align 4
  %112 = load i64, i64* %RBP, align 8
  %113 = add i64 %112, -48
  %114 = load i32, i32* %ESI, align 4
  %115 = load i64, i64* %PC, align 8
  %116 = add i64 %115, 3
  store i64 %116, i64* %PC, align 8
  %117 = inttoptr i64 %113 to i32*
  store i32 %114, i32* %117, align 4
  %118 = load i64, i64* %RBP, align 8
  %119 = add i64 %118, -52
  %120 = load i32, i32* %EDX, align 4
  %121 = load i64, i64* %PC, align 8
  %122 = add i64 %121, 3
  store i64 %122, i64* %PC, align 8
  %123 = inttoptr i64 %119 to i32*
  store i32 %120, i32* %123, align 4
  %124 = load i64, i64* %RBP, align 8
  %125 = add i64 %124, -64
  %126 = load i64, i64* %RCX, align 8
  %127 = load i64, i64* %PC, align 8
  %128 = add i64 %127, 4
  store i64 %128, i64* %PC, align 8
  %129 = inttoptr i64 %125 to i64*
  store i64 %126, i64* %129, align 8
  %130 = load i64, i64* %RBP, align 8
  %131 = add i64 %130, -72
  %132 = load i64, i64* %R8, align 8
  %133 = load i64, i64* %PC, align 8
  %134 = add i64 %133, 4
  store i64 %134, i64* %PC, align 8
  %135 = inttoptr i64 %131 to i64*
  store i64 %132, i64* %135, align 8
  %136 = load i64, i64* %RBP, align 8
  %137 = add i64 %136, -80
  %138 = load i64, i64* %R9, align 8
  %139 = load i64, i64* %PC, align 8
  %140 = add i64 %139, 4
  store i64 %140, i64* %PC, align 8
  %141 = inttoptr i64 %137 to i64*
  store i64 %138, i64* %141, align 8
  %142 = load i64, i64* %RBP, align 8
  %143 = add i64 %142, -64
  %144 = load i64, i64* %PC, align 8
  %145 = add i64 %144, 4
  store i64 %145, i64* %PC, align 8
  %146 = inttoptr i64 %143 to i64*
  %147 = load i64, i64* %146, align 8
  store i64 %147, i64* %RCX, align 8, !tbaa !2428
  %148 = add i64 %144, 8
  store i64 %148, i64* %PC, align 8
  %149 = load i64, i64* %105, align 1
  %150 = inttoptr i64 %147 to i64*
  store i64 %149, i64* %150, align 8
  %151 = load i64, i64* %RBP, align 8
  %152 = add i64 %151, -72
  %153 = load i64, i64* %PC, align 8
  %154 = add i64 %153, 4
  store i64 %154, i64* %PC, align 8
  %155 = inttoptr i64 %152 to i64*
  %156 = load i64, i64* %155, align 8
  store i64 %156, i64* %RCX, align 8, !tbaa !2428
  %157 = add i64 %153, 8
  store i64 %157, i64* %PC, align 8
  %158 = load i64, i64* %100, align 1
  %159 = inttoptr i64 %156 to i64*
  store i64 %158, i64* %159, align 8
  %160 = load i64, i64* %RBP, align 8
  %161 = add i64 %160, -84
  %162 = load i64, i64* %PC, align 8
  %163 = add i64 %162, 7
  store i64 %163, i64* %PC, align 8
  %164 = inttoptr i64 %161 to i32*
  store i32 0, i32* %164, align 4
  %165 = load i64, i64* %RBP, align 8
  %166 = add i64 %165, -120
  %167 = load i64, i64* %R13, align 8
  %168 = load i64, i64* %PC, align 8
  %169 = add i64 %168, 4
  store i64 %169, i64* %PC, align 8
  %170 = inttoptr i64 %166 to i64*
  store i64 %167, i64* %170, align 8
  %171 = load i64, i64* %RBP, align 8
  %172 = add i64 %171, -128
  %173 = load i64, i64* %R14, align 8
  %174 = load i64, i64* %PC, align 8
  %175 = add i64 %174, 4
  store i64 %175, i64* %PC, align 8
  %176 = inttoptr i64 %172 to i64*
  store i64 %173, i64* %176, align 8
  %177 = load i64, i64* %RBP, align 8
  %178 = add i64 %177, -136
  %179 = load i64, i64* %R15, align 8
  %180 = load i64, i64* %PC, align 8
  %181 = add i64 %180, 7
  store i64 %181, i64* %PC, align 8
  %182 = inttoptr i64 %178 to i64*
  store i64 %179, i64* %182, align 8
  %183 = load i64, i64* %RBP, align 8
  %184 = add i64 %183, -144
  %185 = load i64, i64* %R12, align 8
  %186 = load i64, i64* %PC, align 8
  %187 = add i64 %186, 7
  store i64 %187, i64* %PC, align 8
  %188 = inttoptr i64 %184 to i64*
  store i64 %185, i64* %188, align 8
  %189 = load i64, i64* %RBP, align 8
  %190 = add i64 %189, -152
  %191 = load i64, i64* %RBX, align 8
  %192 = load i64, i64* %PC, align 8
  %193 = add i64 %192, 7
  store i64 %193, i64* %PC, align 8
  %194 = inttoptr i64 %190 to i64*
  store i64 %191, i64* %194, align 8
  %195 = load i64, i64* %RBP, align 8
  %196 = add i64 %195, -160
  %197 = load i64, i64* %R11, align 8
  %198 = load i64, i64* %PC, align 8
  %199 = add i64 %198, 7
  store i64 %199, i64* %PC, align 8
  %200 = inttoptr i64 %196 to i64*
  store i64 %197, i64* %200, align 8
  %201 = load i64, i64* %RBP, align 8
  %202 = add i64 %201, -168
  %203 = load i64, i64* %RAX, align 8
  %204 = load i64, i64* %PC, align 8
  %205 = add i64 %204, 7
  store i64 %205, i64* %PC, align 8
  %206 = inttoptr i64 %202 to i64*
  store i64 %203, i64* %206, align 8
  %207 = load i64, i64* %RBP, align 8
  %208 = add i64 %207, -176
  %209 = load i64, i64* %R10, align 8
  %210 = load i64, i64* %PC, align 8
  %211 = add i64 %210, 7
  store i64 %211, i64* %PC, align 8
  %212 = inttoptr i64 %208 to i64*
  store i64 %209, i64* %212, align 8
  %213 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %214 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %215 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %216 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %217 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %218 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %219 = bitcast %union.VectorReg* %8 to double*
  %220 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 2, i32 0, i32 0, i32 0, i64 1
  %.pre = load i64, i64* %PC, align 8
  br label %block_40103c

block_4010bf:                                     ; preds = %block_4010b3
  %221 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 80) to i64*), align 16
  store i64 %221, i64* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %222 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 40) to double*), align 8
  store double %222, double* %104, align 1, !tbaa !2452
  store double 0.000000e+00, double* %107, align 1, !tbaa !2452
  %223 = add i64 %392, 19
  store i64 %223, i64* %PC, align 8
  %224 = load i32, i32* %359, align 4
  %225 = zext i32 %224 to i64
  store i64 %225, i64* %RAX, align 8, !tbaa !2428
  %226 = sitofp i32 %224 to double
  %227 = fadd double %226, %222
  store double %227, double* %219, align 1, !tbaa !2452
  %228 = add i64 %392, 30
  store i64 %228, i64* %PC, align 8
  %229 = load i32, i32* %364, align 4
  %230 = zext i32 %229 to i64
  store i64 %230, i64* %RAX, align 8, !tbaa !2428
  %231 = sitofp i32 %229 to double
  store double %231, double* %104, align 1, !tbaa !2452
  %232 = fdiv double %227, %231
  store double %232, double* %219, align 1, !tbaa !2452
  %233 = add i64 %356, 64
  %234 = add i64 %392, 42
  store i64 %234, i64* %PC, align 8
  %235 = inttoptr i64 %233 to i64*
  %236 = load i64, i64* %235, align 8
  store i64 %236, i64* %RCX, align 8, !tbaa !2428
  %237 = add i64 %392, 46
  store i64 %237, i64* %PC, align 8
  %238 = load i32, i32* %359, align 4
  %239 = sext i32 %238 to i64
  store i64 %239, i64* %RDX, align 8, !tbaa !2428
  %240 = shl nsw i64 %239, 3
  %241 = add i64 %240, %236
  %242 = add i64 %392, 51
  store i64 %242, i64* %PC, align 8
  %243 = inttoptr i64 %241 to double*
  store double %232, double* %243, align 8
  %244 = load i64, i64* %RBP, align 8
  %245 = add i64 %244, -84
  %246 = load i64, i64* %PC, align 8
  %247 = add i64 %246, 3
  store i64 %247, i64* %PC, align 8
  %248 = inttoptr i64 %245 to i32*
  %249 = load i32, i32* %248, align 4
  %250 = zext i32 %249 to i64
  store i64 %250, i64* %RAX, align 8, !tbaa !2428
  %251 = sitofp i32 %249 to double
  %252 = load double, double* %99, align 1
  %253 = fadd double %251, %252
  store double %253, double* %104, align 1, !tbaa !2452
  %254 = add i64 %244, -48
  %255 = add i64 %246, 14
  store i64 %255, i64* %PC, align 8
  %256 = inttoptr i64 %254 to i32*
  %257 = load i32, i32* %256, align 4
  %258 = zext i32 %257 to i64
  store i64 %258, i64* %RAX, align 8, !tbaa !2428
  %259 = sitofp i32 %257 to double
  store double %259, double* %99, align 1, !tbaa !2452
  %260 = fdiv double %253, %259
  store double %260, double* %104, align 1, !tbaa !2452
  %261 = add i64 %244, 72
  %262 = add i64 %246, 26
  store i64 %262, i64* %PC, align 8
  %263 = inttoptr i64 %261 to i64*
  %264 = load i64, i64* %263, align 8
  store i64 %264, i64* %RCX, align 8, !tbaa !2428
  %265 = add i64 %246, 30
  store i64 %265, i64* %PC, align 8
  %266 = load i32, i32* %248, align 4
  %267 = sext i32 %266 to i64
  store i64 %267, i64* %RDX, align 8, !tbaa !2428
  %268 = shl nsw i64 %267, 3
  %269 = add i64 %268, %264
  %270 = add i64 %246, 35
  store i64 %270, i64* %PC, align 8
  %271 = inttoptr i64 %269 to double*
  store double %260, double* %271, align 8
  %272 = load i64, i64* %RBP, align 8
  %273 = add i64 %272, -84
  %274 = load i64, i64* %PC, align 8
  %275 = add i64 %274, 3
  store i64 %275, i64* %PC, align 8
  %276 = inttoptr i64 %273 to i32*
  %277 = load i32, i32* %276, align 4
  %278 = add i32 %277, 1
  %279 = zext i32 %278 to i64
  store i64 %279, i64* %RAX, align 8, !tbaa !2428
  %280 = icmp eq i32 %277, -1
  %281 = icmp eq i32 %278, 0
  %282 = or i1 %280, %281
  %283 = zext i1 %282 to i8
  store i8 %283, i8* %213, align 1, !tbaa !2432
  %284 = and i32 %278, 255
  %285 = tail call i32 @llvm.ctpop.i32(i32 %284) #8
  %286 = trunc i32 %285 to i8
  %287 = and i8 %286, 1
  %288 = xor i8 %287, 1
  store i8 %288, i8* %214, align 1, !tbaa !2446
  %289 = xor i32 %277, %278
  %290 = lshr i32 %289, 4
  %291 = trunc i32 %290 to i8
  %292 = and i8 %291, 1
  store i8 %292, i8* %215, align 1, !tbaa !2447
  %293 = zext i1 %281 to i8
  store i8 %293, i8* %216, align 1, !tbaa !2448
  %294 = lshr i32 %278, 31
  %295 = trunc i32 %294 to i8
  store i8 %295, i8* %217, align 1, !tbaa !2449
  %296 = lshr i32 %277, 31
  %297 = xor i32 %294, %296
  %298 = add nuw nsw i32 %297, %294
  %299 = icmp eq i32 %298, 2
  %300 = zext i1 %299 to i8
  store i8 %300, i8* %218, align 1, !tbaa !2450
  %301 = add i64 %274, 9
  store i64 %301, i64* %PC, align 8
  store i32 %278, i32* %276, align 4
  %302 = load i64, i64* %PC, align 8
  %303 = add i64 %302, -107
  store i64 %303, i64* %PC, align 8, !tbaa !2428
  br label %block_4010b3

block_4013b5:                                     ; preds = %block_4011a1
  %304 = load i64, i64* %RSP, align 8
  %305 = add i64 %304, 8
  store i64 %305, i64* %RSP, align 8, !tbaa !2428
  %306 = icmp ugt i64 %304, -9
  %307 = zext i1 %306 to i8
  store i8 %307, i8* %213, align 1, !tbaa !2432
  %308 = trunc i64 %305 to i32
  %309 = and i32 %308, 255
  %310 = tail call i32 @llvm.ctpop.i32(i32 %309) #8
  %311 = trunc i32 %310 to i8
  %312 = and i8 %311, 1
  %313 = xor i8 %312, 1
  store i8 %313, i8* %214, align 1, !tbaa !2446
  %314 = xor i64 %304, %305
  %315 = lshr i64 %314, 4
  %316 = trunc i64 %315 to i8
  %317 = and i8 %316, 1
  store i8 %317, i8* %215, align 1, !tbaa !2447
  %318 = icmp eq i64 %305, 0
  %319 = zext i1 %318 to i8
  store i8 %319, i8* %216, align 1, !tbaa !2448
  %320 = lshr i64 %305, 63
  %321 = trunc i64 %320 to i8
  store i8 %321, i8* %217, align 1, !tbaa !2449
  %322 = lshr i64 %304, 63
  %323 = xor i64 %320, %322
  %324 = add nuw nsw i64 %323, %320
  %325 = icmp eq i64 %324, 2
  %326 = zext i1 %325 to i8
  store i8 %326, i8* %218, align 1, !tbaa !2450
  %327 = add i64 %1365, 5
  store i64 %327, i64* %PC, align 8
  %328 = add i64 %304, 16
  %329 = inttoptr i64 %305 to i64*
  %330 = load i64, i64* %329, align 8
  store i64 %330, i64* %RBX, align 8, !tbaa !2428
  store i64 %328, i64* %RSP, align 8, !tbaa !2428
  %331 = add i64 %1365, 7
  store i64 %331, i64* %PC, align 8
  %332 = add i64 %304, 24
  %333 = inttoptr i64 %328 to i64*
  %334 = load i64, i64* %333, align 8
  store i64 %334, i64* %R12, align 8, !tbaa !2428
  store i64 %332, i64* %RSP, align 8, !tbaa !2428
  %335 = add i64 %1365, 9
  store i64 %335, i64* %PC, align 8
  %336 = add i64 %304, 32
  %337 = inttoptr i64 %332 to i64*
  %338 = load i64, i64* %337, align 8
  store i64 %338, i64* %R13, align 8, !tbaa !2428
  store i64 %336, i64* %RSP, align 8, !tbaa !2428
  %339 = add i64 %1365, 11
  store i64 %339, i64* %PC, align 8
  %340 = add i64 %304, 40
  %341 = inttoptr i64 %336 to i64*
  %342 = load i64, i64* %341, align 8
  store i64 %342, i64* %R14, align 8, !tbaa !2428
  store i64 %340, i64* %RSP, align 8, !tbaa !2428
  %343 = add i64 %1365, 13
  store i64 %343, i64* %PC, align 8
  %344 = add i64 %304, 48
  %345 = inttoptr i64 %340 to i64*
  %346 = load i64, i64* %345, align 8
  store i64 %346, i64* %R15, align 8, !tbaa !2428
  store i64 %344, i64* %RSP, align 8, !tbaa !2428
  %347 = add i64 %1365, 14
  store i64 %347, i64* %PC, align 8
  %348 = add i64 %304, 56
  %349 = inttoptr i64 %344 to i64*
  %350 = load i64, i64* %349, align 8
  store i64 %350, i64* %RBP, align 8, !tbaa !2428
  store i64 %348, i64* %RSP, align 8, !tbaa !2428
  %351 = add i64 %1365, 15
  store i64 %351, i64* %PC, align 8
  %352 = inttoptr i64 %348 to i64*
  %353 = load i64, i64* %352, align 8
  store i64 %353, i64* %PC, align 8, !tbaa !2428
  %354 = add i64 %304, 64
  store i64 %354, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_4010b3:                                     ; preds = %block_4010ac, %block_4010bf
  %355 = phi i64 [ %.pre1, %block_4010ac ], [ %303, %block_4010bf ]
  %356 = load i64, i64* %RBP, align 8
  %357 = add i64 %356, -84
  %358 = add i64 %355, 3
  store i64 %358, i64* %PC, align 8
  %359 = inttoptr i64 %357 to i32*
  %360 = load i32, i32* %359, align 4
  %361 = zext i32 %360 to i64
  store i64 %361, i64* %RAX, align 8, !tbaa !2428
  %362 = add i64 %356, -48
  %363 = add i64 %355, 6
  store i64 %363, i64* %PC, align 8
  %364 = inttoptr i64 %362 to i32*
  %365 = load i32, i32* %364, align 4
  %366 = sub i32 %360, %365
  %367 = icmp ult i32 %360, %365
  %368 = zext i1 %367 to i8
  store i8 %368, i8* %213, align 1, !tbaa !2432
  %369 = and i32 %366, 255
  %370 = tail call i32 @llvm.ctpop.i32(i32 %369) #8
  %371 = trunc i32 %370 to i8
  %372 = and i8 %371, 1
  %373 = xor i8 %372, 1
  store i8 %373, i8* %214, align 1, !tbaa !2446
  %374 = xor i32 %365, %360
  %375 = xor i32 %374, %366
  %376 = lshr i32 %375, 4
  %377 = trunc i32 %376 to i8
  %378 = and i8 %377, 1
  store i8 %378, i8* %215, align 1, !tbaa !2447
  %379 = icmp eq i32 %366, 0
  %380 = zext i1 %379 to i8
  store i8 %380, i8* %216, align 1, !tbaa !2448
  %381 = lshr i32 %366, 31
  %382 = trunc i32 %381 to i8
  store i8 %382, i8* %217, align 1, !tbaa !2449
  %383 = lshr i32 %360, 31
  %384 = lshr i32 %365, 31
  %385 = xor i32 %384, %383
  %386 = xor i32 %381, %383
  %387 = add nuw nsw i32 %386, %385
  %388 = icmp eq i32 %387, 2
  %389 = zext i1 %388 to i8
  store i8 %389, i8* %218, align 1, !tbaa !2450
  %390 = icmp ne i8 %382, 0
  %391 = xor i1 %390, %388
  %.demorgan6 = or i1 %379, %391
  %.v7 = select i1 %.demorgan6, i64 12, i64 112
  %392 = add i64 %355, %.v7
  store i64 %392, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan6, label %block_4010bf, label %block_401123

block_401261:                                     ; preds = %block_401255
  %393 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 40) to i64*), align 8
  store i64 %393, i64* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %394 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 48) to i64*), align 16
  store i64 %394, i64* %105, align 1, !tbaa !2452
  store double 0.000000e+00, double* %107, align 1, !tbaa !2452
  %395 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 56) to double*), align 8
  store double %395, double* %219, align 1, !tbaa !2452
  store double 0.000000e+00, double* %1241, align 1, !tbaa !2452
  %396 = add i64 %1092, -84
  %397 = add i64 %1128, 27
  store i64 %397, i64* %PC, align 8
  %398 = inttoptr i64 %396 to i32*
  %399 = load i32, i32* %398, align 4
  %400 = zext i32 %399 to i64
  store i64 %400, i64* %RAX, align 8, !tbaa !2428
  %401 = sitofp i32 %399 to double
  store double %401, double* %1240, align 1, !tbaa !2452
  %402 = add i64 %1092, -88
  %403 = add i64 %1128, 34
  store i64 %403, i64* %PC, align 8
  %404 = inttoptr i64 %402 to i32*
  %405 = load i32, i32* %404, align 4
  %406 = add i32 %405, 3
  %407 = zext i32 %406 to i64
  store i64 %407, i64* %RAX, align 8, !tbaa !2428
  %408 = icmp ugt i32 %405, -4
  %409 = zext i1 %408 to i8
  store i8 %409, i8* %213, align 1, !tbaa !2432
  %410 = and i32 %406, 255
  %411 = tail call i32 @llvm.ctpop.i32(i32 %410) #8
  %412 = trunc i32 %411 to i8
  %413 = and i8 %412, 1
  %414 = xor i8 %413, 1
  store i8 %414, i8* %214, align 1, !tbaa !2446
  %415 = xor i32 %405, %406
  %416 = lshr i32 %415, 4
  %417 = trunc i32 %416 to i8
  %418 = and i8 %417, 1
  store i8 %418, i8* %215, align 1, !tbaa !2447
  %419 = icmp eq i32 %406, 0
  %420 = zext i1 %419 to i8
  store i8 %420, i8* %216, align 1, !tbaa !2448
  %421 = lshr i32 %406, 31
  %422 = trunc i32 %421 to i8
  store i8 %422, i8* %217, align 1, !tbaa !2449
  %423 = lshr i32 %405, 31
  %424 = xor i32 %421, %423
  %425 = add nuw nsw i32 %424, %421
  %426 = icmp eq i32 %425, 2
  %427 = zext i1 %426 to i8
  store i8 %427, i8* %218, align 1, !tbaa !2450
  %428 = sitofp i32 %406 to double
  store double %428, double* %1242, align 1, !tbaa !2452
  %429 = fmul double %401, %428
  store double %429, double* %1240, align 1, !tbaa !2452
  %430 = add i64 %1128, 48
  store i64 %430, i64* %PC, align 8
  %431 = load i32, i32* %1095, align 4
  %432 = zext i32 %431 to i64
  store i64 %432, i64* %RAX, align 8, !tbaa !2428
  %433 = sitofp i32 %431 to double
  store double %433, double* %1242, align 1, !tbaa !2452
  %434 = fadd double %429, %433
  %435 = fadd double %434, %395
  store double %435, double* %1240, align 1, !tbaa !2452
  %436 = load i64, i64* %RBP, align 8
  %437 = add i64 %436, -48
  %438 = add i64 %1128, 63
  store i64 %438, i64* %PC, align 8
  %439 = inttoptr i64 %437 to i32*
  %440 = load i32, i32* %439, align 4
  %441 = zext i32 %440 to i64
  store i64 %441, i64* %RAX, align 8, !tbaa !2428
  %442 = sitofp i32 %440 to double
  store double %442, double* %219, align 1, !tbaa !2452
  %443 = fdiv double %435, %442
  store double %443, double* %1240, align 1, !tbaa !2452
  %444 = add i64 %436, 24
  %445 = add i64 %1128, 75
  store i64 %445, i64* %PC, align 8
  %446 = inttoptr i64 %444 to i64*
  %447 = load i64, i64* %446, align 8
  store i64 %447, i64* %RCX, align 8, !tbaa !2428
  %448 = add i64 %436, -84
  %449 = add i64 %1128, 79
  store i64 %449, i64* %PC, align 8
  %450 = inttoptr i64 %448 to i32*
  %451 = load i32, i32* %450, align 4
  %452 = sext i32 %451 to i64
  %453 = mul nsw i64 %452, 33800
  store i64 %453, i64* %RDX, align 8, !tbaa !2428
  %454 = lshr i64 %453, 63
  %455 = add i64 %453, %447
  store i64 %455, i64* %RCX, align 8, !tbaa !2428
  %456 = icmp ult i64 %455, %447
  %457 = icmp ult i64 %455, %453
  %458 = or i1 %456, %457
  %459 = zext i1 %458 to i8
  store i8 %459, i8* %213, align 1, !tbaa !2432
  %460 = trunc i64 %455 to i32
  %461 = and i32 %460, 255
  %462 = tail call i32 @llvm.ctpop.i32(i32 %461) #8
  %463 = trunc i32 %462 to i8
  %464 = and i8 %463, 1
  %465 = xor i8 %464, 1
  store i8 %465, i8* %214, align 1, !tbaa !2446
  %466 = xor i64 %453, %447
  %467 = xor i64 %466, %455
  %468 = lshr i64 %467, 4
  %469 = trunc i64 %468 to i8
  %470 = and i8 %469, 1
  store i8 %470, i8* %215, align 1, !tbaa !2447
  %471 = icmp eq i64 %455, 0
  %472 = zext i1 %471 to i8
  store i8 %472, i8* %216, align 1, !tbaa !2448
  %473 = lshr i64 %455, 63
  %474 = trunc i64 %473 to i8
  store i8 %474, i8* %217, align 1, !tbaa !2449
  %475 = lshr i64 %447, 63
  %476 = xor i64 %473, %475
  %477 = xor i64 %473, %454
  %478 = add nuw nsw i64 %476, %477
  %479 = icmp eq i64 %478, 2
  %480 = zext i1 %479 to i8
  store i8 %480, i8* %218, align 1, !tbaa !2450
  %481 = add i64 %436, -88
  %482 = add i64 %1128, 93
  store i64 %482, i64* %PC, align 8
  %483 = inttoptr i64 %481 to i32*
  %484 = load i32, i32* %483, align 4
  %485 = sext i32 %484 to i64
  %486 = mul nsw i64 %485, 520
  store i64 %486, i64* %RDX, align 8, !tbaa !2428
  %487 = lshr i64 %486, 63
  %488 = add i64 %486, %455
  store i64 %488, i64* %RCX, align 8, !tbaa !2428
  %489 = icmp ult i64 %488, %455
  %490 = icmp ult i64 %488, %486
  %491 = or i1 %489, %490
  %492 = zext i1 %491 to i8
  store i8 %492, i8* %213, align 1, !tbaa !2432
  %493 = trunc i64 %488 to i32
  %494 = and i32 %493, 255
  %495 = tail call i32 @llvm.ctpop.i32(i32 %494) #8
  %496 = trunc i32 %495 to i8
  %497 = and i8 %496, 1
  %498 = xor i8 %497, 1
  store i8 %498, i8* %214, align 1, !tbaa !2446
  %499 = xor i64 %486, %455
  %500 = xor i64 %499, %488
  %501 = lshr i64 %500, 4
  %502 = trunc i64 %501 to i8
  %503 = and i8 %502, 1
  store i8 %503, i8* %215, align 1, !tbaa !2447
  %504 = icmp eq i64 %488, 0
  %505 = zext i1 %504 to i8
  store i8 %505, i8* %216, align 1, !tbaa !2448
  %506 = lshr i64 %488, 63
  %507 = trunc i64 %506 to i8
  store i8 %507, i8* %217, align 1, !tbaa !2449
  %508 = xor i64 %506, %473
  %509 = xor i64 %506, %487
  %510 = add nuw nsw i64 %508, %509
  %511 = icmp eq i64 %510, 2
  %512 = zext i1 %511 to i8
  store i8 %512, i8* %218, align 1, !tbaa !2450
  %513 = load i64, i64* %RBP, align 8
  %514 = add i64 %513, -92
  %515 = add i64 %1128, 107
  store i64 %515, i64* %PC, align 8
  %516 = inttoptr i64 %514 to i32*
  %517 = load i32, i32* %516, align 4
  %518 = sext i32 %517 to i64
  store i64 %518, i64* %RDX, align 8, !tbaa !2428
  %519 = shl nsw i64 %518, 3
  %520 = add i64 %519, %488
  %521 = add i64 %1128, 112
  store i64 %521, i64* %PC, align 8
  %522 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %9, i64 0, i32 0, i32 0, i32 0, i64 0
  %523 = load i64, i64* %522, align 1
  %524 = inttoptr i64 %520 to i64*
  store i64 %523, i64* %524, align 8
  %525 = load i64, i64* %RBP, align 8
  %526 = add i64 %525, -84
  %527 = load i64, i64* %PC, align 8
  %528 = add i64 %527, 3
  store i64 %528, i64* %PC, align 8
  %529 = inttoptr i64 %526 to i32*
  %530 = load i32, i32* %529, align 4
  %531 = zext i32 %530 to i64
  store i64 %531, i64* %RAX, align 8, !tbaa !2428
  %532 = sitofp i32 %530 to double
  store double %532, double* %219, align 1, !tbaa !2452
  %533 = add i64 %525, -88
  %534 = add i64 %527, 10
  store i64 %534, i64* %PC, align 8
  %535 = inttoptr i64 %533 to i32*
  %536 = load i32, i32* %535, align 4
  %537 = add i32 %536, 4
  %538 = zext i32 %537 to i64
  store i64 %538, i64* %RAX, align 8, !tbaa !2428
  %539 = icmp ugt i32 %536, -5
  %540 = zext i1 %539 to i8
  store i8 %540, i8* %213, align 1, !tbaa !2432
  %541 = and i32 %537, 255
  %542 = tail call i32 @llvm.ctpop.i32(i32 %541) #8
  %543 = trunc i32 %542 to i8
  %544 = and i8 %543, 1
  %545 = xor i8 %544, 1
  store i8 %545, i8* %214, align 1, !tbaa !2446
  %546 = xor i32 %536, %537
  %547 = lshr i32 %546, 4
  %548 = trunc i32 %547 to i8
  %549 = and i8 %548, 1
  store i8 %549, i8* %215, align 1, !tbaa !2447
  %550 = icmp eq i32 %537, 0
  %551 = zext i1 %550 to i8
  store i8 %551, i8* %216, align 1, !tbaa !2448
  %552 = lshr i32 %537, 31
  %553 = trunc i32 %552 to i8
  store i8 %553, i8* %217, align 1, !tbaa !2449
  %554 = lshr i32 %536, 31
  %555 = xor i32 %552, %554
  %556 = add nuw nsw i32 %555, %552
  %557 = icmp eq i32 %556, 2
  %558 = zext i1 %557 to i8
  store i8 %558, i8* %218, align 1, !tbaa !2450
  %559 = sitofp i32 %537 to double
  store double %559, double* %1240, align 1, !tbaa !2452
  %560 = fmul double %532, %559
  store double %560, double* %219, align 1, !tbaa !2452
  %561 = add i64 %525, -92
  %562 = add i64 %527, 24
  store i64 %562, i64* %PC, align 8
  %563 = inttoptr i64 %561 to i32*
  %564 = load i32, i32* %563, align 4
  %565 = zext i32 %564 to i64
  store i64 %565, i64* %RAX, align 8, !tbaa !2428
  %566 = sitofp i32 %564 to double
  store double %566, double* %1240, align 1, !tbaa !2452
  %567 = fadd double %560, %566
  %568 = load double, double* %104, align 1
  %569 = fadd double %567, %568
  store double %569, double* %219, align 1, !tbaa !2452
  %570 = add i64 %525, -52
  %571 = add i64 %527, 39
  store i64 %571, i64* %PC, align 8
  %572 = inttoptr i64 %570 to i32*
  %573 = load i32, i32* %572, align 4
  %574 = zext i32 %573 to i64
  store i64 %574, i64* %RAX, align 8, !tbaa !2428
  %575 = sitofp i32 %573 to double
  store double %575, double* %104, align 1, !tbaa !2452
  %576 = fdiv double %569, %575
  store double %576, double* %219, align 1, !tbaa !2452
  %577 = load i64, i64* %RBP, align 8
  %578 = add i64 %577, 32
  %579 = add i64 %527, 51
  store i64 %579, i64* %PC, align 8
  %580 = inttoptr i64 %578 to i64*
  %581 = load i64, i64* %580, align 8
  store i64 %581, i64* %RCX, align 8, !tbaa !2428
  %582 = add i64 %577, -84
  %583 = add i64 %527, 55
  store i64 %583, i64* %PC, align 8
  %584 = inttoptr i64 %582 to i32*
  %585 = load i32, i32* %584, align 4
  %586 = sext i32 %585 to i64
  %587 = mul nsw i64 %586, 33800
  store i64 %587, i64* %RDX, align 8, !tbaa !2428
  %588 = lshr i64 %587, 63
  %589 = add i64 %587, %581
  store i64 %589, i64* %RCX, align 8, !tbaa !2428
  %590 = icmp ult i64 %589, %581
  %591 = icmp ult i64 %589, %587
  %592 = or i1 %590, %591
  %593 = zext i1 %592 to i8
  store i8 %593, i8* %213, align 1, !tbaa !2432
  %594 = trunc i64 %589 to i32
  %595 = and i32 %594, 255
  %596 = tail call i32 @llvm.ctpop.i32(i32 %595) #8
  %597 = trunc i32 %596 to i8
  %598 = and i8 %597, 1
  %599 = xor i8 %598, 1
  store i8 %599, i8* %214, align 1, !tbaa !2446
  %600 = xor i64 %587, %581
  %601 = xor i64 %600, %589
  %602 = lshr i64 %601, 4
  %603 = trunc i64 %602 to i8
  %604 = and i8 %603, 1
  store i8 %604, i8* %215, align 1, !tbaa !2447
  %605 = icmp eq i64 %589, 0
  %606 = zext i1 %605 to i8
  store i8 %606, i8* %216, align 1, !tbaa !2448
  %607 = lshr i64 %589, 63
  %608 = trunc i64 %607 to i8
  store i8 %608, i8* %217, align 1, !tbaa !2449
  %609 = lshr i64 %581, 63
  %610 = xor i64 %607, %609
  %611 = xor i64 %607, %588
  %612 = add nuw nsw i64 %610, %611
  %613 = icmp eq i64 %612, 2
  %614 = zext i1 %613 to i8
  store i8 %614, i8* %218, align 1, !tbaa !2450
  %615 = add i64 %577, -88
  %616 = add i64 %527, 69
  store i64 %616, i64* %PC, align 8
  %617 = inttoptr i64 %615 to i32*
  %618 = load i32, i32* %617, align 4
  %619 = sext i32 %618 to i64
  %620 = mul nsw i64 %619, 520
  store i64 %620, i64* %RDX, align 8, !tbaa !2428
  %621 = lshr i64 %620, 63
  %622 = add i64 %620, %589
  store i64 %622, i64* %RCX, align 8, !tbaa !2428
  %623 = icmp ult i64 %622, %589
  %624 = icmp ult i64 %622, %620
  %625 = or i1 %623, %624
  %626 = zext i1 %625 to i8
  store i8 %626, i8* %213, align 1, !tbaa !2432
  %627 = trunc i64 %622 to i32
  %628 = and i32 %627, 255
  %629 = tail call i32 @llvm.ctpop.i32(i32 %628) #8
  %630 = trunc i32 %629 to i8
  %631 = and i8 %630, 1
  %632 = xor i8 %631, 1
  store i8 %632, i8* %214, align 1, !tbaa !2446
  %633 = xor i64 %620, %589
  %634 = xor i64 %633, %622
  %635 = lshr i64 %634, 4
  %636 = trunc i64 %635 to i8
  %637 = and i8 %636, 1
  store i8 %637, i8* %215, align 1, !tbaa !2447
  %638 = icmp eq i64 %622, 0
  %639 = zext i1 %638 to i8
  store i8 %639, i8* %216, align 1, !tbaa !2448
  %640 = lshr i64 %622, 63
  %641 = trunc i64 %640 to i8
  store i8 %641, i8* %217, align 1, !tbaa !2449
  %642 = xor i64 %640, %607
  %643 = xor i64 %640, %621
  %644 = add nuw nsw i64 %642, %643
  %645 = icmp eq i64 %644, 2
  %646 = zext i1 %645 to i8
  store i8 %646, i8* %218, align 1, !tbaa !2450
  %647 = load i64, i64* %RBP, align 8
  %648 = add i64 %647, -92
  %649 = add i64 %527, 83
  store i64 %649, i64* %PC, align 8
  %650 = inttoptr i64 %648 to i32*
  %651 = load i32, i32* %650, align 4
  %652 = sext i32 %651 to i64
  store i64 %652, i64* %RDX, align 8, !tbaa !2428
  %653 = shl nsw i64 %652, 3
  %654 = add i64 %653, %622
  %655 = add i64 %527, 88
  store i64 %655, i64* %PC, align 8
  %656 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %8, i64 0, i32 0, i32 0, i32 0, i64 0
  %657 = load i64, i64* %656, align 1
  %658 = inttoptr i64 %654 to i64*
  store i64 %657, i64* %658, align 8
  %659 = load i64, i64* %RBP, align 8
  %660 = add i64 %659, -84
  %661 = load i64, i64* %PC, align 8
  %662 = add i64 %661, 3
  store i64 %662, i64* %PC, align 8
  %663 = inttoptr i64 %660 to i32*
  %664 = load i32, i32* %663, align 4
  %665 = zext i32 %664 to i64
  store i64 %665, i64* %RAX, align 8, !tbaa !2428
  %666 = sitofp i32 %664 to double
  store double %666, double* %104, align 1, !tbaa !2452
  %667 = add i64 %659, -88
  %668 = add i64 %661, 10
  store i64 %668, i64* %PC, align 8
  %669 = inttoptr i64 %667 to i32*
  %670 = load i32, i32* %669, align 4
  %671 = add i32 %670, 5
  %672 = zext i32 %671 to i64
  store i64 %672, i64* %RAX, align 8, !tbaa !2428
  %673 = icmp ugt i32 %670, -6
  %674 = zext i1 %673 to i8
  store i8 %674, i8* %213, align 1, !tbaa !2432
  %675 = and i32 %671, 255
  %676 = tail call i32 @llvm.ctpop.i32(i32 %675) #8
  %677 = trunc i32 %676 to i8
  %678 = and i8 %677, 1
  %679 = xor i8 %678, 1
  store i8 %679, i8* %214, align 1, !tbaa !2446
  %680 = xor i32 %670, %671
  %681 = lshr i32 %680, 4
  %682 = trunc i32 %681 to i8
  %683 = and i8 %682, 1
  store i8 %683, i8* %215, align 1, !tbaa !2447
  %684 = icmp eq i32 %671, 0
  %685 = zext i1 %684 to i8
  store i8 %685, i8* %216, align 1, !tbaa !2448
  %686 = lshr i32 %671, 31
  %687 = trunc i32 %686 to i8
  store i8 %687, i8* %217, align 1, !tbaa !2449
  %688 = lshr i32 %670, 31
  %689 = xor i32 %686, %688
  %690 = add nuw nsw i32 %689, %686
  %691 = icmp eq i32 %690, 2
  %692 = zext i1 %691 to i8
  store i8 %692, i8* %218, align 1, !tbaa !2450
  %693 = sitofp i32 %671 to double
  store double %693, double* %219, align 1, !tbaa !2452
  %694 = fmul double %666, %693
  store double %694, double* %104, align 1, !tbaa !2452
  %695 = add i64 %659, -92
  %696 = add i64 %661, 24
  store i64 %696, i64* %PC, align 8
  %697 = inttoptr i64 %695 to i32*
  %698 = load i32, i32* %697, align 4
  %699 = zext i32 %698 to i64
  store i64 %699, i64* %RAX, align 8, !tbaa !2428
  %700 = sitofp i32 %698 to double
  store double %700, double* %219, align 1, !tbaa !2452
  %701 = fadd double %694, %700
  %702 = load double, double* %99, align 1
  %703 = fadd double %701, %702
  store double %703, double* %104, align 1, !tbaa !2452
  %704 = add i64 %659, -44
  %705 = add i64 %661, 39
  store i64 %705, i64* %PC, align 8
  %706 = inttoptr i64 %704 to i32*
  %707 = load i32, i32* %706, align 4
  %708 = zext i32 %707 to i64
  store i64 %708, i64* %RAX, align 8, !tbaa !2428
  %709 = sitofp i32 %707 to double
  store double %709, double* %99, align 1, !tbaa !2452
  %710 = fdiv double %703, %709
  store double %710, double* %104, align 1, !tbaa !2452
  %711 = load i64, i64* %RBP, align 8
  %712 = add i64 %711, 40
  %713 = add i64 %661, 51
  store i64 %713, i64* %PC, align 8
  %714 = inttoptr i64 %712 to i64*
  %715 = load i64, i64* %714, align 8
  store i64 %715, i64* %RCX, align 8, !tbaa !2428
  %716 = add i64 %711, -84
  %717 = add i64 %661, 55
  store i64 %717, i64* %PC, align 8
  %718 = inttoptr i64 %716 to i32*
  %719 = load i32, i32* %718, align 4
  %720 = sext i32 %719 to i64
  %721 = mul nsw i64 %720, 33800
  store i64 %721, i64* %RDX, align 8, !tbaa !2428
  %722 = lshr i64 %721, 63
  %723 = add i64 %721, %715
  store i64 %723, i64* %RCX, align 8, !tbaa !2428
  %724 = icmp ult i64 %723, %715
  %725 = icmp ult i64 %723, %721
  %726 = or i1 %724, %725
  %727 = zext i1 %726 to i8
  store i8 %727, i8* %213, align 1, !tbaa !2432
  %728 = trunc i64 %723 to i32
  %729 = and i32 %728, 255
  %730 = tail call i32 @llvm.ctpop.i32(i32 %729) #8
  %731 = trunc i32 %730 to i8
  %732 = and i8 %731, 1
  %733 = xor i8 %732, 1
  store i8 %733, i8* %214, align 1, !tbaa !2446
  %734 = xor i64 %721, %715
  %735 = xor i64 %734, %723
  %736 = lshr i64 %735, 4
  %737 = trunc i64 %736 to i8
  %738 = and i8 %737, 1
  store i8 %738, i8* %215, align 1, !tbaa !2447
  %739 = icmp eq i64 %723, 0
  %740 = zext i1 %739 to i8
  store i8 %740, i8* %216, align 1, !tbaa !2448
  %741 = lshr i64 %723, 63
  %742 = trunc i64 %741 to i8
  store i8 %742, i8* %217, align 1, !tbaa !2449
  %743 = lshr i64 %715, 63
  %744 = xor i64 %741, %743
  %745 = xor i64 %741, %722
  %746 = add nuw nsw i64 %744, %745
  %747 = icmp eq i64 %746, 2
  %748 = zext i1 %747 to i8
  store i8 %748, i8* %218, align 1, !tbaa !2450
  %749 = add i64 %711, -88
  %750 = add i64 %661, 69
  store i64 %750, i64* %PC, align 8
  %751 = inttoptr i64 %749 to i32*
  %752 = load i32, i32* %751, align 4
  %753 = sext i32 %752 to i64
  %754 = mul nsw i64 %753, 520
  store i64 %754, i64* %RDX, align 8, !tbaa !2428
  %755 = lshr i64 %754, 63
  %756 = add i64 %754, %723
  store i64 %756, i64* %RCX, align 8, !tbaa !2428
  %757 = icmp ult i64 %756, %723
  %758 = icmp ult i64 %756, %754
  %759 = or i1 %757, %758
  %760 = zext i1 %759 to i8
  store i8 %760, i8* %213, align 1, !tbaa !2432
  %761 = trunc i64 %756 to i32
  %762 = and i32 %761, 255
  %763 = tail call i32 @llvm.ctpop.i32(i32 %762) #8
  %764 = trunc i32 %763 to i8
  %765 = and i8 %764, 1
  %766 = xor i8 %765, 1
  store i8 %766, i8* %214, align 1, !tbaa !2446
  %767 = xor i64 %754, %723
  %768 = xor i64 %767, %756
  %769 = lshr i64 %768, 4
  %770 = trunc i64 %769 to i8
  %771 = and i8 %770, 1
  store i8 %771, i8* %215, align 1, !tbaa !2447
  %772 = icmp eq i64 %756, 0
  %773 = zext i1 %772 to i8
  store i8 %773, i8* %216, align 1, !tbaa !2448
  %774 = lshr i64 %756, 63
  %775 = trunc i64 %774 to i8
  store i8 %775, i8* %217, align 1, !tbaa !2449
  %776 = xor i64 %774, %741
  %777 = xor i64 %774, %755
  %778 = add nuw nsw i64 %776, %777
  %779 = icmp eq i64 %778, 2
  %780 = zext i1 %779 to i8
  store i8 %780, i8* %218, align 1, !tbaa !2450
  %781 = load i64, i64* %RBP, align 8
  %782 = add i64 %781, -92
  %783 = add i64 %661, 83
  store i64 %783, i64* %PC, align 8
  %784 = inttoptr i64 %782 to i32*
  %785 = load i32, i32* %784, align 4
  %786 = sext i32 %785 to i64
  store i64 %786, i64* %RDX, align 8, !tbaa !2428
  %787 = shl nsw i64 %786, 3
  %788 = add i64 %787, %756
  %789 = add i64 %661, 88
  store i64 %789, i64* %PC, align 8
  %790 = load i64, i64* %105, align 1
  %791 = inttoptr i64 %788 to i64*
  store i64 %790, i64* %791, align 8
  %792 = load i64, i64* %RBP, align 8
  %793 = add i64 %792, -92
  %794 = load i64, i64* %PC, align 8
  %795 = add i64 %794, 3
  store i64 %795, i64* %PC, align 8
  %796 = inttoptr i64 %793 to i32*
  %797 = load i32, i32* %796, align 4
  %798 = add i32 %797, 1
  %799 = zext i32 %798 to i64
  store i64 %799, i64* %RAX, align 8, !tbaa !2428
  %800 = icmp eq i32 %797, -1
  %801 = icmp eq i32 %798, 0
  %802 = or i1 %800, %801
  %803 = zext i1 %802 to i8
  store i8 %803, i8* %213, align 1, !tbaa !2432
  %804 = and i32 %798, 255
  %805 = tail call i32 @llvm.ctpop.i32(i32 %804) #8
  %806 = trunc i32 %805 to i8
  %807 = and i8 %806, 1
  %808 = xor i8 %807, 1
  store i8 %808, i8* %214, align 1, !tbaa !2446
  %809 = xor i32 %797, %798
  %810 = lshr i32 %809, 4
  %811 = trunc i32 %810 to i8
  %812 = and i8 %811, 1
  store i8 %812, i8* %215, align 1, !tbaa !2447
  %813 = zext i1 %801 to i8
  store i8 %813, i8* %216, align 1, !tbaa !2448
  %814 = lshr i32 %798, 31
  %815 = trunc i32 %814 to i8
  store i8 %815, i8* %217, align 1, !tbaa !2449
  %816 = lshr i32 %797, 31
  %817 = xor i32 %814, %816
  %818 = add nuw nsw i32 %817, %814
  %819 = icmp eq i32 %818, 2
  %820 = zext i1 %819 to i8
  store i8 %820, i8* %218, align 1, !tbaa !2450
  %821 = add i64 %794, 9
  store i64 %821, i64* %PC, align 8
  store i32 %798, i32* %796, align 4
  %822 = load i64, i64* %PC, align 8
  %823 = add i64 %822, -309
  store i64 %823, i64* %PC, align 8, !tbaa !2428
  br label %block_401255

block_4011c0:                                     ; preds = %block_4011b4
  %824 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 24) to i64*), align 8
  store i64 %824, i64* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %825 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 32) to double*), align 16
  store double %825, double* %104, align 1, !tbaa !2452
  store double 0.000000e+00, double* %107, align 1, !tbaa !2452
  %826 = add i64 %1130, -84
  %827 = add i64 %1166, 19
  store i64 %827, i64* %PC, align 8
  %828 = inttoptr i64 %826 to i32*
  %829 = load i32, i32* %828, align 4
  %830 = zext i32 %829 to i64
  store i64 %830, i64* %RAX, align 8, !tbaa !2428
  %831 = sitofp i32 %829 to double
  store double %831, double* %219, align 1, !tbaa !2452
  %832 = add i64 %1166, 26
  store i64 %832, i64* %PC, align 8
  %833 = load i32, i32* %1133, align 4
  %834 = add i32 %833, 1
  %835 = zext i32 %834 to i64
  store i64 %835, i64* %RAX, align 8, !tbaa !2428
  %836 = icmp eq i32 %833, -1
  %837 = icmp eq i32 %834, 0
  %838 = or i1 %836, %837
  %839 = zext i1 %838 to i8
  store i8 %839, i8* %213, align 1, !tbaa !2432
  %840 = and i32 %834, 255
  %841 = tail call i32 @llvm.ctpop.i32(i32 %840) #8
  %842 = trunc i32 %841 to i8
  %843 = and i8 %842, 1
  %844 = xor i8 %843, 1
  store i8 %844, i8* %214, align 1, !tbaa !2446
  %845 = xor i32 %833, %834
  %846 = lshr i32 %845, 4
  %847 = trunc i32 %846 to i8
  %848 = and i8 %847, 1
  store i8 %848, i8* %215, align 1, !tbaa !2447
  %849 = zext i1 %837 to i8
  store i8 %849, i8* %216, align 1, !tbaa !2448
  %850 = lshr i32 %834, 31
  %851 = trunc i32 %850 to i8
  store i8 %851, i8* %217, align 1, !tbaa !2449
  %852 = lshr i32 %833, 31
  %853 = xor i32 %850, %852
  %854 = add nuw nsw i32 %853, %850
  %855 = icmp eq i32 %854, 2
  %856 = zext i1 %855 to i8
  store i8 %856, i8* %218, align 1, !tbaa !2450
  %857 = sitofp i32 %834 to double
  store double %857, double* %1240, align 1, !tbaa !2452
  %858 = fmul double %831, %857
  %859 = fadd double %858, %825
  store double %859, double* %219, align 1, !tbaa !2452
  %860 = add i64 %1166, 44
  store i64 %860, i64* %PC, align 8
  %861 = load i32, i32* %1138, align 4
  %862 = zext i32 %861 to i64
  store i64 %862, i64* %RAX, align 8, !tbaa !2428
  %863 = sitofp i32 %861 to double
  store double %863, double* %104, align 1, !tbaa !2452
  %864 = fdiv double %859, %863
  store double %864, double* %219, align 1, !tbaa !2452
  %865 = add i64 %1130, 16
  %866 = add i64 %1166, 56
  store i64 %866, i64* %PC, align 8
  %867 = inttoptr i64 %865 to i64*
  %868 = load i64, i64* %867, align 8
  store i64 %868, i64* %RCX, align 8, !tbaa !2428
  %869 = add i64 %1166, 60
  store i64 %869, i64* %PC, align 8
  %870 = load i32, i32* %828, align 4
  %871 = sext i32 %870 to i64
  %872 = mul nsw i64 %871, 520
  store i64 %872, i64* %RDX, align 8, !tbaa !2428
  %873 = lshr i64 %872, 63
  %874 = add i64 %872, %868
  store i64 %874, i64* %RCX, align 8, !tbaa !2428
  %875 = icmp ult i64 %874, %868
  %876 = icmp ult i64 %874, %872
  %877 = or i1 %875, %876
  %878 = zext i1 %877 to i8
  store i8 %878, i8* %213, align 1, !tbaa !2432
  %879 = trunc i64 %874 to i32
  %880 = and i32 %879, 255
  %881 = tail call i32 @llvm.ctpop.i32(i32 %880) #8
  %882 = trunc i32 %881 to i8
  %883 = and i8 %882, 1
  %884 = xor i8 %883, 1
  store i8 %884, i8* %214, align 1, !tbaa !2446
  %885 = xor i64 %872, %868
  %886 = xor i64 %885, %874
  %887 = lshr i64 %886, 4
  %888 = trunc i64 %887 to i8
  %889 = and i8 %888, 1
  store i8 %889, i8* %215, align 1, !tbaa !2447
  %890 = icmp eq i64 %874, 0
  %891 = zext i1 %890 to i8
  store i8 %891, i8* %216, align 1, !tbaa !2448
  %892 = lshr i64 %874, 63
  %893 = trunc i64 %892 to i8
  store i8 %893, i8* %217, align 1, !tbaa !2449
  %894 = lshr i64 %868, 63
  %895 = xor i64 %892, %894
  %896 = xor i64 %892, %873
  %897 = add nuw nsw i64 %895, %896
  %898 = icmp eq i64 %897, 2
  %899 = zext i1 %898 to i8
  store i8 %899, i8* %218, align 1, !tbaa !2450
  %900 = load i64, i64* %RBP, align 8
  %901 = add i64 %900, -88
  %902 = add i64 %1166, 74
  store i64 %902, i64* %PC, align 8
  %903 = inttoptr i64 %901 to i32*
  %904 = load i32, i32* %903, align 4
  %905 = sext i32 %904 to i64
  store i64 %905, i64* %RDX, align 8, !tbaa !2428
  %906 = shl nsw i64 %905, 3
  %907 = add i64 %906, %874
  %908 = add i64 %1166, 79
  store i64 %908, i64* %PC, align 8
  %909 = inttoptr i64 %907 to double*
  store double %864, double* %909, align 8
  %910 = load i64, i64* %RBP, align 8
  %911 = add i64 %910, -84
  %912 = load i64, i64* %PC, align 8
  %913 = add i64 %912, 3
  store i64 %913, i64* %PC, align 8
  %914 = inttoptr i64 %911 to i32*
  %915 = load i32, i32* %914, align 4
  %916 = zext i32 %915 to i64
  store i64 %916, i64* %RAX, align 8, !tbaa !2428
  %917 = sitofp i32 %915 to double
  store double %917, double* %104, align 1, !tbaa !2452
  %918 = add i64 %910, -88
  %919 = add i64 %912, 10
  store i64 %919, i64* %PC, align 8
  %920 = inttoptr i64 %918 to i32*
  %921 = load i32, i32* %920, align 4
  %922 = add i32 %921, 2
  %923 = zext i32 %922 to i64
  store i64 %923, i64* %RAX, align 8, !tbaa !2428
  %924 = icmp ugt i32 %921, -3
  %925 = zext i1 %924 to i8
  store i8 %925, i8* %213, align 1, !tbaa !2432
  %926 = and i32 %922, 255
  %927 = tail call i32 @llvm.ctpop.i32(i32 %926) #8
  %928 = trunc i32 %927 to i8
  %929 = and i8 %928, 1
  %930 = xor i8 %929, 1
  store i8 %930, i8* %214, align 1, !tbaa !2446
  %931 = xor i32 %921, %922
  %932 = lshr i32 %931, 4
  %933 = trunc i32 %932 to i8
  %934 = and i8 %933, 1
  store i8 %934, i8* %215, align 1, !tbaa !2447
  %935 = icmp eq i32 %922, 0
  %936 = zext i1 %935 to i8
  store i8 %936, i8* %216, align 1, !tbaa !2448
  %937 = lshr i32 %922, 31
  %938 = trunc i32 %937 to i8
  store i8 %938, i8* %217, align 1, !tbaa !2449
  %939 = lshr i32 %921, 31
  %940 = xor i32 %937, %939
  %941 = add nuw nsw i32 %940, %937
  %942 = icmp eq i32 %941, 2
  %943 = zext i1 %942 to i8
  store i8 %943, i8* %218, align 1, !tbaa !2450
  %944 = sitofp i32 %922 to double
  store double %944, double* %219, align 1, !tbaa !2452
  %945 = fmul double %917, %944
  %946 = load double, double* %99, align 1
  %947 = fadd double %945, %946
  store double %947, double* %104, align 1, !tbaa !2452
  %948 = add i64 %910, -52
  %949 = add i64 %912, 28
  store i64 %949, i64* %PC, align 8
  %950 = inttoptr i64 %948 to i32*
  %951 = load i32, i32* %950, align 4
  %952 = zext i32 %951 to i64
  store i64 %952, i64* %RAX, align 8, !tbaa !2428
  %953 = sitofp i32 %951 to double
  store double %953, double* %99, align 1, !tbaa !2452
  %954 = fdiv double %947, %953
  store double %954, double* %104, align 1, !tbaa !2452
  %955 = add i64 %910, -80
  %956 = add i64 %912, 40
  store i64 %956, i64* %PC, align 8
  %957 = inttoptr i64 %955 to i64*
  %958 = load i64, i64* %957, align 8
  store i64 %958, i64* %RCX, align 8, !tbaa !2428
  %959 = add i64 %912, 44
  store i64 %959, i64* %PC, align 8
  %960 = load i32, i32* %914, align 4
  %961 = sext i32 %960 to i64
  %962 = mul nsw i64 %961, 520
  store i64 %962, i64* %RDX, align 8, !tbaa !2428
  %963 = lshr i64 %962, 63
  %964 = add i64 %962, %958
  store i64 %964, i64* %RCX, align 8, !tbaa !2428
  %965 = icmp ult i64 %964, %958
  %966 = icmp ult i64 %964, %962
  %967 = or i1 %965, %966
  %968 = zext i1 %967 to i8
  store i8 %968, i8* %213, align 1, !tbaa !2432
  %969 = trunc i64 %964 to i32
  %970 = and i32 %969, 255
  %971 = tail call i32 @llvm.ctpop.i32(i32 %970) #8
  %972 = trunc i32 %971 to i8
  %973 = and i8 %972, 1
  %974 = xor i8 %973, 1
  store i8 %974, i8* %214, align 1, !tbaa !2446
  %975 = xor i64 %962, %958
  %976 = xor i64 %975, %964
  %977 = lshr i64 %976, 4
  %978 = trunc i64 %977 to i8
  %979 = and i8 %978, 1
  store i8 %979, i8* %215, align 1, !tbaa !2447
  %980 = icmp eq i64 %964, 0
  %981 = zext i1 %980 to i8
  store i8 %981, i8* %216, align 1, !tbaa !2448
  %982 = lshr i64 %964, 63
  %983 = trunc i64 %982 to i8
  store i8 %983, i8* %217, align 1, !tbaa !2449
  %984 = lshr i64 %958, 63
  %985 = xor i64 %982, %984
  %986 = xor i64 %982, %963
  %987 = add nuw nsw i64 %985, %986
  %988 = icmp eq i64 %987, 2
  %989 = zext i1 %988 to i8
  store i8 %989, i8* %218, align 1, !tbaa !2450
  %990 = load i64, i64* %RBP, align 8
  %991 = add i64 %990, -88
  %992 = add i64 %912, 58
  store i64 %992, i64* %PC, align 8
  %993 = inttoptr i64 %991 to i32*
  %994 = load i32, i32* %993, align 4
  %995 = sext i32 %994 to i64
  store i64 %995, i64* %RDX, align 8, !tbaa !2428
  %996 = shl nsw i64 %995, 3
  %997 = add i64 %996, %964
  %998 = add i64 %912, 63
  store i64 %998, i64* %PC, align 8
  %999 = inttoptr i64 %997 to double*
  store double %954, double* %999, align 8
  %1000 = load i64, i64* %RBP, align 8
  %1001 = add i64 %1000, -92
  %1002 = load i64, i64* %PC, align 8
  %1003 = add i64 %1002, 7
  store i64 %1003, i64* %PC, align 8
  %1004 = inttoptr i64 %1001 to i32*
  store i32 0, i32* %1004, align 4
  %.pre5 = load i64, i64* %PC, align 8
  br label %block_401255

block_401136:                                     ; preds = %block_40112a
  %1005 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 64) to i64*), align 16
  store i64 %1005, i64* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %1006 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 72) to double*), align 8
  store double %1006, double* %104, align 1, !tbaa !2452
  store double 0.000000e+00, double* %107, align 1, !tbaa !2452
  %1007 = add i64 %1204, 19
  store i64 %1007, i64* %PC, align 8
  %1008 = load i32, i32* %1171, align 4
  %1009 = zext i32 %1008 to i64
  store i64 %1009, i64* %RAX, align 8, !tbaa !2428
  %1010 = sitofp i32 %1008 to double
  %1011 = fadd double %1010, %1006
  store double %1011, double* %219, align 1, !tbaa !2452
  %1012 = add i64 %1168, -48
  %1013 = add i64 %1204, 30
  store i64 %1013, i64* %PC, align 8
  %1014 = inttoptr i64 %1012 to i32*
  %1015 = load i32, i32* %1014, align 4
  %1016 = zext i32 %1015 to i64
  store i64 %1016, i64* %RAX, align 8, !tbaa !2428
  %1017 = sitofp i32 %1015 to double
  store double %1017, double* %104, align 1, !tbaa !2452
  %1018 = fdiv double %1011, %1017
  store double %1018, double* %219, align 1, !tbaa !2452
  %1019 = add i64 %1168, 80
  %1020 = add i64 %1204, 42
  store i64 %1020, i64* %PC, align 8
  %1021 = inttoptr i64 %1019 to i64*
  %1022 = load i64, i64* %1021, align 8
  store i64 %1022, i64* %RCX, align 8, !tbaa !2428
  %1023 = add i64 %1204, 46
  store i64 %1023, i64* %PC, align 8
  %1024 = load i32, i32* %1171, align 4
  %1025 = sext i32 %1024 to i64
  store i64 %1025, i64* %RDX, align 8, !tbaa !2428
  %1026 = shl nsw i64 %1025, 3
  %1027 = add i64 %1026, %1022
  %1028 = add i64 %1204, 51
  store i64 %1028, i64* %PC, align 8
  %1029 = inttoptr i64 %1027 to double*
  store double %1018, double* %1029, align 8
  %1030 = load i64, i64* %RBP, align 8
  %1031 = add i64 %1030, -84
  %1032 = load i64, i64* %PC, align 8
  %1033 = add i64 %1032, 3
  store i64 %1033, i64* %PC, align 8
  %1034 = inttoptr i64 %1031 to i32*
  %1035 = load i32, i32* %1034, align 4
  %1036 = zext i32 %1035 to i64
  store i64 %1036, i64* %RAX, align 8, !tbaa !2428
  %1037 = sitofp i32 %1035 to double
  %1038 = load double, double* %99, align 1
  %1039 = fadd double %1037, %1038
  store double %1039, double* %104, align 1, !tbaa !2452
  %1040 = add i64 %1030, -48
  %1041 = add i64 %1032, 14
  store i64 %1041, i64* %PC, align 8
  %1042 = inttoptr i64 %1040 to i32*
  %1043 = load i32, i32* %1042, align 4
  %1044 = zext i32 %1043 to i64
  store i64 %1044, i64* %RAX, align 8, !tbaa !2428
  %1045 = sitofp i32 %1043 to double
  store double %1045, double* %99, align 1, !tbaa !2452
  %1046 = fdiv double %1039, %1045
  store double %1046, double* %104, align 1, !tbaa !2452
  %1047 = add i64 %1030, 88
  %1048 = add i64 %1032, 26
  store i64 %1048, i64* %PC, align 8
  %1049 = inttoptr i64 %1047 to i64*
  %1050 = load i64, i64* %1049, align 8
  store i64 %1050, i64* %RCX, align 8, !tbaa !2428
  %1051 = add i64 %1032, 30
  store i64 %1051, i64* %PC, align 8
  %1052 = load i32, i32* %1034, align 4
  %1053 = sext i32 %1052 to i64
  store i64 %1053, i64* %RDX, align 8, !tbaa !2428
  %1054 = shl nsw i64 %1053, 3
  %1055 = add i64 %1054, %1050
  %1056 = add i64 %1032, 35
  store i64 %1056, i64* %PC, align 8
  %1057 = inttoptr i64 %1055 to double*
  store double %1046, double* %1057, align 8
  %1058 = load i64, i64* %RBP, align 8
  %1059 = add i64 %1058, -84
  %1060 = load i64, i64* %PC, align 8
  %1061 = add i64 %1060, 3
  store i64 %1061, i64* %PC, align 8
  %1062 = inttoptr i64 %1059 to i32*
  %1063 = load i32, i32* %1062, align 4
  %1064 = add i32 %1063, 1
  %1065 = zext i32 %1064 to i64
  store i64 %1065, i64* %RAX, align 8, !tbaa !2428
  %1066 = icmp eq i32 %1063, -1
  %1067 = icmp eq i32 %1064, 0
  %1068 = or i1 %1066, %1067
  %1069 = zext i1 %1068 to i8
  store i8 %1069, i8* %213, align 1, !tbaa !2432
  %1070 = and i32 %1064, 255
  %1071 = tail call i32 @llvm.ctpop.i32(i32 %1070) #8
  %1072 = trunc i32 %1071 to i8
  %1073 = and i8 %1072, 1
  %1074 = xor i8 %1073, 1
  store i8 %1074, i8* %214, align 1, !tbaa !2446
  %1075 = xor i32 %1063, %1064
  %1076 = lshr i32 %1075, 4
  %1077 = trunc i32 %1076 to i8
  %1078 = and i8 %1077, 1
  store i8 %1078, i8* %215, align 1, !tbaa !2447
  %1079 = zext i1 %1067 to i8
  store i8 %1079, i8* %216, align 1, !tbaa !2448
  %1080 = lshr i32 %1064, 31
  %1081 = trunc i32 %1080 to i8
  store i8 %1081, i8* %217, align 1, !tbaa !2449
  %1082 = lshr i32 %1063, 31
  %1083 = xor i32 %1080, %1082
  %1084 = add nuw nsw i32 %1083, %1080
  %1085 = icmp eq i32 %1084, 2
  %1086 = zext i1 %1085 to i8
  store i8 %1086, i8* %218, align 1, !tbaa !2450
  %1087 = add i64 %1060, 9
  store i64 %1087, i64* %PC, align 8
  store i32 %1064, i32* %1062, align 4
  %1088 = load i64, i64* %PC, align 8
  %1089 = add i64 %1088, -107
  store i64 %1089, i64* %PC, align 8, !tbaa !2428
  br label %block_40112a

block_4010ac:                                     ; preds = %block_40103c
  %1090 = add i64 %1403, 7
  store i64 %1090, i64* %PC, align 8
  store i32 0, i32* %1370, align 4
  %.pre1 = load i64, i64* %PC, align 8
  br label %block_4010b3

block_401255:                                     ; preds = %block_4011c0, %block_401261
  %1091 = phi i64 [ %.pre5, %block_4011c0 ], [ %823, %block_401261 ]
  %1092 = load i64, i64* %RBP, align 8
  %1093 = add i64 %1092, -92
  %1094 = add i64 %1091, 3
  store i64 %1094, i64* %PC, align 8
  %1095 = inttoptr i64 %1093 to i32*
  %1096 = load i32, i32* %1095, align 4
  %1097 = zext i32 %1096 to i64
  store i64 %1097, i64* %RAX, align 8, !tbaa !2428
  %1098 = add i64 %1092, -48
  %1099 = add i64 %1091, 6
  store i64 %1099, i64* %PC, align 8
  %1100 = inttoptr i64 %1098 to i32*
  %1101 = load i32, i32* %1100, align 4
  %1102 = sub i32 %1096, %1101
  %1103 = icmp ult i32 %1096, %1101
  %1104 = zext i1 %1103 to i8
  store i8 %1104, i8* %213, align 1, !tbaa !2432
  %1105 = and i32 %1102, 255
  %1106 = tail call i32 @llvm.ctpop.i32(i32 %1105) #8
  %1107 = trunc i32 %1106 to i8
  %1108 = and i8 %1107, 1
  %1109 = xor i8 %1108, 1
  store i8 %1109, i8* %214, align 1, !tbaa !2446
  %1110 = xor i32 %1101, %1096
  %1111 = xor i32 %1110, %1102
  %1112 = lshr i32 %1111, 4
  %1113 = trunc i32 %1112 to i8
  %1114 = and i8 %1113, 1
  store i8 %1114, i8* %215, align 1, !tbaa !2447
  %1115 = icmp eq i32 %1102, 0
  %1116 = zext i1 %1115 to i8
  store i8 %1116, i8* %216, align 1, !tbaa !2448
  %1117 = lshr i32 %1102, 31
  %1118 = trunc i32 %1117 to i8
  store i8 %1118, i8* %217, align 1, !tbaa !2449
  %1119 = lshr i32 %1096, 31
  %1120 = lshr i32 %1101, 31
  %1121 = xor i32 %1120, %1119
  %1122 = xor i32 %1117, %1119
  %1123 = add nuw nsw i32 %1122, %1121
  %1124 = icmp eq i32 %1123, 2
  %1125 = zext i1 %1124 to i8
  store i8 %1125, i8* %218, align 1, !tbaa !2450
  %1126 = icmp ne i8 %1118, 0
  %1127 = xor i1 %1126, %1124
  %.demorgan14 = or i1 %1115, %1127
  %.v15 = select i1 %.demorgan14, i64 12, i64 314
  %1128 = add i64 %1091, %.v15
  store i64 %1128, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan14, label %block_401261, label %block_40138f

block_4011b4:                                     ; preds = %block_40138f, %block_4011ad
  %1129 = phi i64 [ %1433, %block_40138f ], [ %.pre4, %block_4011ad ]
  %1130 = load i64, i64* %RBP, align 8
  %1131 = add i64 %1130, -88
  %1132 = add i64 %1129, 3
  store i64 %1132, i64* %PC, align 8
  %1133 = inttoptr i64 %1131 to i32*
  %1134 = load i32, i32* %1133, align 4
  %1135 = zext i32 %1134 to i64
  store i64 %1135, i64* %RAX, align 8, !tbaa !2428
  %1136 = add i64 %1130, -52
  %1137 = add i64 %1129, 6
  store i64 %1137, i64* %PC, align 8
  %1138 = inttoptr i64 %1136 to i32*
  %1139 = load i32, i32* %1138, align 4
  %1140 = sub i32 %1134, %1139
  %1141 = icmp ult i32 %1134, %1139
  %1142 = zext i1 %1141 to i8
  store i8 %1142, i8* %213, align 1, !tbaa !2432
  %1143 = and i32 %1140, 255
  %1144 = tail call i32 @llvm.ctpop.i32(i32 %1143) #8
  %1145 = trunc i32 %1144 to i8
  %1146 = and i8 %1145, 1
  %1147 = xor i8 %1146, 1
  store i8 %1147, i8* %214, align 1, !tbaa !2446
  %1148 = xor i32 %1139, %1134
  %1149 = xor i32 %1148, %1140
  %1150 = lshr i32 %1149, 4
  %1151 = trunc i32 %1150 to i8
  %1152 = and i8 %1151, 1
  store i8 %1152, i8* %215, align 1, !tbaa !2447
  %1153 = icmp eq i32 %1140, 0
  %1154 = zext i1 %1153 to i8
  store i8 %1154, i8* %216, align 1, !tbaa !2448
  %1155 = lshr i32 %1140, 31
  %1156 = trunc i32 %1155 to i8
  store i8 %1156, i8* %217, align 1, !tbaa !2449
  %1157 = lshr i32 %1134, 31
  %1158 = lshr i32 %1139, 31
  %1159 = xor i32 %1158, %1157
  %1160 = xor i32 %1155, %1157
  %1161 = add nuw nsw i32 %1160, %1159
  %1162 = icmp eq i32 %1161, 2
  %1163 = zext i1 %1162 to i8
  store i8 %1163, i8* %218, align 1, !tbaa !2450
  %1164 = icmp ne i8 %1156, 0
  %1165 = xor i1 %1164, %1162
  %.demorgan12 = or i1 %1153, %1165
  %.v13 = select i1 %.demorgan12, i64 12, i64 494
  %1166 = add i64 %1129, %.v13
  store i64 %1166, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan12, label %block_4011c0, label %block_4013a2

block_40112a:                                     ; preds = %block_401123, %block_401136
  %1167 = phi i64 [ %.pre2, %block_401123 ], [ %1089, %block_401136 ]
  %1168 = load i64, i64* %RBP, align 8
  %1169 = add i64 %1168, -84
  %1170 = add i64 %1167, 3
  store i64 %1170, i64* %PC, align 8
  %1171 = inttoptr i64 %1169 to i32*
  %1172 = load i32, i32* %1171, align 4
  %1173 = zext i32 %1172 to i64
  store i64 %1173, i64* %RAX, align 8, !tbaa !2428
  %1174 = add i64 %1168, -52
  %1175 = add i64 %1167, 6
  store i64 %1175, i64* %PC, align 8
  %1176 = inttoptr i64 %1174 to i32*
  %1177 = load i32, i32* %1176, align 4
  %1178 = sub i32 %1172, %1177
  %1179 = icmp ult i32 %1172, %1177
  %1180 = zext i1 %1179 to i8
  store i8 %1180, i8* %213, align 1, !tbaa !2432
  %1181 = and i32 %1178, 255
  %1182 = tail call i32 @llvm.ctpop.i32(i32 %1181) #8
  %1183 = trunc i32 %1182 to i8
  %1184 = and i8 %1183, 1
  %1185 = xor i8 %1184, 1
  store i8 %1185, i8* %214, align 1, !tbaa !2446
  %1186 = xor i32 %1177, %1172
  %1187 = xor i32 %1186, %1178
  %1188 = lshr i32 %1187, 4
  %1189 = trunc i32 %1188 to i8
  %1190 = and i8 %1189, 1
  store i8 %1190, i8* %215, align 1, !tbaa !2447
  %1191 = icmp eq i32 %1178, 0
  %1192 = zext i1 %1191 to i8
  store i8 %1192, i8* %216, align 1, !tbaa !2448
  %1193 = lshr i32 %1178, 31
  %1194 = trunc i32 %1193 to i8
  store i8 %1194, i8* %217, align 1, !tbaa !2449
  %1195 = lshr i32 %1172, 31
  %1196 = lshr i32 %1177, 31
  %1197 = xor i32 %1196, %1195
  %1198 = xor i32 %1193, %1195
  %1199 = add nuw nsw i32 %1198, %1197
  %1200 = icmp eq i32 %1199, 2
  %1201 = zext i1 %1200 to i8
  store i8 %1201, i8* %218, align 1, !tbaa !2450
  %1202 = icmp ne i8 %1194, 0
  %1203 = xor i1 %1202, %1200
  %.demorgan8 = or i1 %1191, %1203
  %.v9 = select i1 %.demorgan8, i64 12, i64 112
  %1204 = add i64 %1167, %.v9
  store i64 %1204, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan8, label %block_401136, label %block_40119a

block_4011ad:                                     ; preds = %block_4011a1
  %1205 = add i64 %1329, -88
  %1206 = add i64 %1365, 7
  store i64 %1206, i64* %PC, align 8
  %1207 = inttoptr i64 %1205 to i32*
  store i32 0, i32* %1207, align 4
  %.pre4 = load i64, i64* %PC, align 8
  br label %block_4011b4

block_401123:                                     ; preds = %block_4010b3
  %1208 = add i64 %392, 7
  store i64 %1208, i64* %PC, align 8
  store i32 0, i32* %359, align 4
  %.pre2 = load i64, i64* %PC, align 8
  br label %block_40112a

block_4013a2:                                     ; preds = %block_4011b4
  %1209 = add i64 %1130, -84
  %1210 = add i64 %1166, 8
  store i64 %1210, i64* %PC, align 8
  %1211 = inttoptr i64 %1209 to i32*
  %1212 = load i32, i32* %1211, align 4
  %1213 = add i32 %1212, 1
  %1214 = zext i32 %1213 to i64
  store i64 %1214, i64* %RAX, align 8, !tbaa !2428
  %1215 = icmp eq i32 %1212, -1
  %1216 = icmp eq i32 %1213, 0
  %1217 = or i1 %1215, %1216
  %1218 = zext i1 %1217 to i8
  store i8 %1218, i8* %213, align 1, !tbaa !2432
  %1219 = and i32 %1213, 255
  %1220 = tail call i32 @llvm.ctpop.i32(i32 %1219) #8
  %1221 = trunc i32 %1220 to i8
  %1222 = and i8 %1221, 1
  %1223 = xor i8 %1222, 1
  store i8 %1223, i8* %214, align 1, !tbaa !2446
  %1224 = xor i32 %1212, %1213
  %1225 = lshr i32 %1224, 4
  %1226 = trunc i32 %1225 to i8
  %1227 = and i8 %1226, 1
  store i8 %1227, i8* %215, align 1, !tbaa !2447
  %1228 = zext i1 %1216 to i8
  store i8 %1228, i8* %216, align 1, !tbaa !2448
  %1229 = lshr i32 %1213, 31
  %1230 = trunc i32 %1229 to i8
  store i8 %1230, i8* %217, align 1, !tbaa !2449
  %1231 = lshr i32 %1212, 31
  %1232 = xor i32 %1229, %1231
  %1233 = add nuw nsw i32 %1232, %1229
  %1234 = icmp eq i32 %1233, 2
  %1235 = zext i1 %1234 to i8
  store i8 %1235, i8* %218, align 1, !tbaa !2450
  %1236 = add i64 %1166, 14
  store i64 %1236, i64* %PC, align 8
  store i32 %1213, i32* %1211, align 4
  %1237 = load i64, i64* %PC, align 8
  %1238 = add i64 %1237, -527
  store i64 %1238, i64* %PC, align 8, !tbaa !2428
  br label %block_4011a1

block_40119a:                                     ; preds = %block_40112a
  %1239 = add i64 %1204, 7
  store i64 %1239, i64* %PC, align 8
  store i32 0, i32* %1171, align 4
  %1240 = bitcast %union.VectorReg* %9 to double*
  %1241 = bitcast i64* %220 to double*
  %1242 = bitcast %union.VectorReg* %10 to double*
  %.pre3 = load i64, i64* %PC, align 8
  br label %block_4011a1

block_401048:                                     ; preds = %block_40103c
  %1243 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 48) to i64*), align 16
  store i64 %1243, i64* %100, align 1, !tbaa !2452
  store double 0.000000e+00, double* %102, align 1, !tbaa !2452
  %1244 = load double, double* inttoptr (i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 56) to double*), align 8
  store double %1244, double* %104, align 1, !tbaa !2452
  store double 0.000000e+00, double* %107, align 1, !tbaa !2452
  %1245 = add i64 %1403, 19
  store i64 %1245, i64* %PC, align 8
  %1246 = load i32, i32* %1370, align 4
  %1247 = zext i32 %1246 to i64
  store i64 %1247, i64* %RAX, align 8, !tbaa !2428
  %1248 = sitofp i32 %1246 to double
  %1249 = fadd double %1248, %1244
  store double %1249, double* %219, align 1, !tbaa !2452
  %1250 = add i64 %1367, -48
  %1251 = add i64 %1403, 30
  store i64 %1251, i64* %PC, align 8
  %1252 = inttoptr i64 %1250 to i32*
  %1253 = load i32, i32* %1252, align 4
  %1254 = zext i32 %1253 to i64
  store i64 %1254, i64* %RAX, align 8, !tbaa !2428
  %1255 = sitofp i32 %1253 to double
  store double %1255, double* %104, align 1, !tbaa !2452
  %1256 = fdiv double %1249, %1255
  store double %1256, double* %219, align 1, !tbaa !2452
  %1257 = add i64 %1367, 48
  %1258 = add i64 %1403, 42
  store i64 %1258, i64* %PC, align 8
  %1259 = inttoptr i64 %1257 to i64*
  %1260 = load i64, i64* %1259, align 8
  store i64 %1260, i64* %RCX, align 8, !tbaa !2428
  %1261 = add i64 %1403, 46
  store i64 %1261, i64* %PC, align 8
  %1262 = load i32, i32* %1370, align 4
  %1263 = sext i32 %1262 to i64
  store i64 %1263, i64* %RDX, align 8, !tbaa !2428
  %1264 = shl nsw i64 %1263, 3
  %1265 = add i64 %1264, %1260
  %1266 = add i64 %1403, 51
  store i64 %1266, i64* %PC, align 8
  %1267 = inttoptr i64 %1265 to double*
  store double %1256, double* %1267, align 8
  %1268 = load i64, i64* %RBP, align 8
  %1269 = add i64 %1268, -84
  %1270 = load i64, i64* %PC, align 8
  %1271 = add i64 %1270, 3
  store i64 %1271, i64* %PC, align 8
  %1272 = inttoptr i64 %1269 to i32*
  %1273 = load i32, i32* %1272, align 4
  %1274 = zext i32 %1273 to i64
  store i64 %1274, i64* %RAX, align 8, !tbaa !2428
  %1275 = sitofp i32 %1273 to double
  %1276 = load double, double* %99, align 1
  %1277 = fadd double %1275, %1276
  store double %1277, double* %104, align 1, !tbaa !2452
  %1278 = add i64 %1268, -48
  %1279 = add i64 %1270, 14
  store i64 %1279, i64* %PC, align 8
  %1280 = inttoptr i64 %1278 to i32*
  %1281 = load i32, i32* %1280, align 4
  %1282 = zext i32 %1281 to i64
  store i64 %1282, i64* %RAX, align 8, !tbaa !2428
  %1283 = sitofp i32 %1281 to double
  store double %1283, double* %99, align 1, !tbaa !2452
  %1284 = fdiv double %1277, %1283
  store double %1284, double* %104, align 1, !tbaa !2452
  %1285 = add i64 %1268, 56
  %1286 = add i64 %1270, 26
  store i64 %1286, i64* %PC, align 8
  %1287 = inttoptr i64 %1285 to i64*
  %1288 = load i64, i64* %1287, align 8
  store i64 %1288, i64* %RCX, align 8, !tbaa !2428
  %1289 = add i64 %1270, 30
  store i64 %1289, i64* %PC, align 8
  %1290 = load i32, i32* %1272, align 4
  %1291 = sext i32 %1290 to i64
  store i64 %1291, i64* %RDX, align 8, !tbaa !2428
  %1292 = shl nsw i64 %1291, 3
  %1293 = add i64 %1292, %1288
  %1294 = add i64 %1270, 35
  store i64 %1294, i64* %PC, align 8
  %1295 = inttoptr i64 %1293 to double*
  store double %1284, double* %1295, align 8
  %1296 = load i64, i64* %RBP, align 8
  %1297 = add i64 %1296, -84
  %1298 = load i64, i64* %PC, align 8
  %1299 = add i64 %1298, 3
  store i64 %1299, i64* %PC, align 8
  %1300 = inttoptr i64 %1297 to i32*
  %1301 = load i32, i32* %1300, align 4
  %1302 = add i32 %1301, 1
  %1303 = zext i32 %1302 to i64
  store i64 %1303, i64* %RAX, align 8, !tbaa !2428
  %1304 = icmp eq i32 %1301, -1
  %1305 = icmp eq i32 %1302, 0
  %1306 = or i1 %1304, %1305
  %1307 = zext i1 %1306 to i8
  store i8 %1307, i8* %213, align 1, !tbaa !2432
  %1308 = and i32 %1302, 255
  %1309 = tail call i32 @llvm.ctpop.i32(i32 %1308) #8
  %1310 = trunc i32 %1309 to i8
  %1311 = and i8 %1310, 1
  %1312 = xor i8 %1311, 1
  store i8 %1312, i8* %214, align 1, !tbaa !2446
  %1313 = xor i32 %1301, %1302
  %1314 = lshr i32 %1313, 4
  %1315 = trunc i32 %1314 to i8
  %1316 = and i8 %1315, 1
  store i8 %1316, i8* %215, align 1, !tbaa !2447
  %1317 = zext i1 %1305 to i8
  store i8 %1317, i8* %216, align 1, !tbaa !2448
  %1318 = lshr i32 %1302, 31
  %1319 = trunc i32 %1318 to i8
  store i8 %1319, i8* %217, align 1, !tbaa !2449
  %1320 = lshr i32 %1301, 31
  %1321 = xor i32 %1318, %1320
  %1322 = add nuw nsw i32 %1321, %1318
  %1323 = icmp eq i32 %1322, 2
  %1324 = zext i1 %1323 to i8
  store i8 %1324, i8* %218, align 1, !tbaa !2450
  %1325 = add i64 %1298, 9
  store i64 %1325, i64* %PC, align 8
  store i32 %1302, i32* %1300, align 4
  %1326 = load i64, i64* %PC, align 8
  %1327 = add i64 %1326, -107
  store i64 %1327, i64* %PC, align 8, !tbaa !2428
  br label %block_40103c

block_4011a1:                                     ; preds = %block_40119a, %block_4013a2
  %1328 = phi i64 [ %.pre3, %block_40119a ], [ %1238, %block_4013a2 ]
  %1329 = load i64, i64* %RBP, align 8
  %1330 = add i64 %1329, -84
  %1331 = add i64 %1328, 3
  store i64 %1331, i64* %PC, align 8
  %1332 = inttoptr i64 %1330 to i32*
  %1333 = load i32, i32* %1332, align 4
  %1334 = zext i32 %1333 to i64
  store i64 %1334, i64* %RAX, align 8, !tbaa !2428
  %1335 = add i64 %1329, -44
  %1336 = add i64 %1328, 6
  store i64 %1336, i64* %PC, align 8
  %1337 = inttoptr i64 %1335 to i32*
  %1338 = load i32, i32* %1337, align 4
  %1339 = sub i32 %1333, %1338
  %1340 = icmp ult i32 %1333, %1338
  %1341 = zext i1 %1340 to i8
  store i8 %1341, i8* %213, align 1, !tbaa !2432
  %1342 = and i32 %1339, 255
  %1343 = tail call i32 @llvm.ctpop.i32(i32 %1342) #8
  %1344 = trunc i32 %1343 to i8
  %1345 = and i8 %1344, 1
  %1346 = xor i8 %1345, 1
  store i8 %1346, i8* %214, align 1, !tbaa !2446
  %1347 = xor i32 %1338, %1333
  %1348 = xor i32 %1347, %1339
  %1349 = lshr i32 %1348, 4
  %1350 = trunc i32 %1349 to i8
  %1351 = and i8 %1350, 1
  store i8 %1351, i8* %215, align 1, !tbaa !2447
  %1352 = icmp eq i32 %1339, 0
  %1353 = zext i1 %1352 to i8
  store i8 %1353, i8* %216, align 1, !tbaa !2448
  %1354 = lshr i32 %1339, 31
  %1355 = trunc i32 %1354 to i8
  store i8 %1355, i8* %217, align 1, !tbaa !2449
  %1356 = lshr i32 %1333, 31
  %1357 = lshr i32 %1338, 31
  %1358 = xor i32 %1357, %1356
  %1359 = xor i32 %1354, %1356
  %1360 = add nuw nsw i32 %1359, %1358
  %1361 = icmp eq i32 %1360, 2
  %1362 = zext i1 %1361 to i8
  store i8 %1362, i8* %218, align 1, !tbaa !2450
  %1363 = icmp ne i8 %1355, 0
  %1364 = xor i1 %1363, %1361
  %.demorgan10 = or i1 %1352, %1364
  %.v11 = select i1 %.demorgan10, i64 12, i64 532
  %1365 = add i64 %1328, %.v11
  store i64 %1365, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan10, label %block_4011ad, label %block_4013b5

block_40103c:                                     ; preds = %block_401048, %block_400f90
  %1366 = phi i64 [ %1327, %block_401048 ], [ %.pre, %block_400f90 ]
  %1367 = load i64, i64* %RBP, align 8
  %1368 = add i64 %1367, -84
  %1369 = add i64 %1366, 3
  store i64 %1369, i64* %PC, align 8
  %1370 = inttoptr i64 %1368 to i32*
  %1371 = load i32, i32* %1370, align 4
  %1372 = zext i32 %1371 to i64
  store i64 %1372, i64* %RAX, align 8, !tbaa !2428
  %1373 = add i64 %1367, -44
  %1374 = add i64 %1366, 6
  store i64 %1374, i64* %PC, align 8
  %1375 = inttoptr i64 %1373 to i32*
  %1376 = load i32, i32* %1375, align 4
  %1377 = sub i32 %1371, %1376
  %1378 = icmp ult i32 %1371, %1376
  %1379 = zext i1 %1378 to i8
  store i8 %1379, i8* %213, align 1, !tbaa !2432
  %1380 = and i32 %1377, 255
  %1381 = tail call i32 @llvm.ctpop.i32(i32 %1380) #8
  %1382 = trunc i32 %1381 to i8
  %1383 = and i8 %1382, 1
  %1384 = xor i8 %1383, 1
  store i8 %1384, i8* %214, align 1, !tbaa !2446
  %1385 = xor i32 %1376, %1371
  %1386 = xor i32 %1385, %1377
  %1387 = lshr i32 %1386, 4
  %1388 = trunc i32 %1387 to i8
  %1389 = and i8 %1388, 1
  store i8 %1389, i8* %215, align 1, !tbaa !2447
  %1390 = icmp eq i32 %1377, 0
  %1391 = zext i1 %1390 to i8
  store i8 %1391, i8* %216, align 1, !tbaa !2448
  %1392 = lshr i32 %1377, 31
  %1393 = trunc i32 %1392 to i8
  store i8 %1393, i8* %217, align 1, !tbaa !2449
  %1394 = lshr i32 %1371, 31
  %1395 = lshr i32 %1376, 31
  %1396 = xor i32 %1395, %1394
  %1397 = xor i32 %1392, %1394
  %1398 = add nuw nsw i32 %1397, %1396
  %1399 = icmp eq i32 %1398, 2
  %1400 = zext i1 %1399 to i8
  store i8 %1400, i8* %218, align 1, !tbaa !2450
  %1401 = icmp ne i8 %1393, 0
  %1402 = xor i1 %1401, %1399
  %.demorgan = or i1 %1390, %1402
  %.v = select i1 %.demorgan, i64 12, i64 112
  %1403 = add i64 %1366, %.v
  store i64 %1403, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan, label %block_401048, label %block_4010ac

block_40138f:                                     ; preds = %block_401255
  %1404 = add i64 %1092, -88
  %1405 = add i64 %1128, 8
  store i64 %1405, i64* %PC, align 8
  %1406 = inttoptr i64 %1404 to i32*
  %1407 = load i32, i32* %1406, align 4
  %1408 = add i32 %1407, 1
  %1409 = zext i32 %1408 to i64
  store i64 %1409, i64* %RAX, align 8, !tbaa !2428
  %1410 = icmp eq i32 %1407, -1
  %1411 = icmp eq i32 %1408, 0
  %1412 = or i1 %1410, %1411
  %1413 = zext i1 %1412 to i8
  store i8 %1413, i8* %213, align 1, !tbaa !2432
  %1414 = and i32 %1408, 255
  %1415 = tail call i32 @llvm.ctpop.i32(i32 %1414) #8
  %1416 = trunc i32 %1415 to i8
  %1417 = and i8 %1416, 1
  %1418 = xor i8 %1417, 1
  store i8 %1418, i8* %214, align 1, !tbaa !2446
  %1419 = xor i32 %1407, %1408
  %1420 = lshr i32 %1419, 4
  %1421 = trunc i32 %1420 to i8
  %1422 = and i8 %1421, 1
  store i8 %1422, i8* %215, align 1, !tbaa !2447
  %1423 = zext i1 %1411 to i8
  store i8 %1423, i8* %216, align 1, !tbaa !2448
  %1424 = lshr i32 %1408, 31
  %1425 = trunc i32 %1424 to i8
  store i8 %1425, i8* %217, align 1, !tbaa !2449
  %1426 = lshr i32 %1407, 31
  %1427 = xor i32 %1424, %1426
  %1428 = add nuw nsw i32 %1427, %1424
  %1429 = icmp eq i32 %1428, 2
  %1430 = zext i1 %1429 to i8
  store i8 %1430, i8* %218, align 1, !tbaa !2450
  %1431 = add i64 %1128, 14
  store i64 %1431, i64* %PC, align 8
  store i32 %1408, i32* %1406, align 4
  %1432 = load i64, i64* %PC, align 8
  %1433 = add i64 %1432, -489
  store i64 %1433, i64* %PC, align 8, !tbaa !2428
  br label %block_4011b4
}

; Function Attrs: noinline
define %struct.Memory* @sub_4007c0_polybench_alloc_data(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_4007c0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %1, 1
  store i64 %5, i64* %PC, align 8
  %6 = load i64, i64* %RSP, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %4, i64* %8, align 8
  %9 = load i64, i64* %PC, align 8
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %10 = add i64 %6, -40
  store i64 %10, i64* %RSP, align 8, !tbaa !2428
  %11 = icmp ult i64 %7, 32
  %12 = zext i1 %11 to i8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %13, align 1, !tbaa !2432
  %14 = trunc i64 %10 to i32
  %15 = and i32 %14, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15) #8
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1, !tbaa !2446
  %21 = xor i64 %7, %10
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1, !tbaa !2447
  %26 = icmp eq i64 %10, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1, !tbaa !2448
  %29 = lshr i64 %10, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1, !tbaa !2449
  %32 = lshr i64 %7, 63
  %33 = xor i64 %29, %32
  %34 = add nuw nsw i64 %33, %32
  %35 = icmp eq i64 %34, 2
  %36 = zext i1 %35 to i8
  %37 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %36, i8* %37, align 1, !tbaa !2450
  %38 = add i64 %6, -16
  %39 = load i64, i64* %RDI, align 8
  %40 = add i64 %9, 11
  store i64 %40, i64* %PC, align 8
  %41 = inttoptr i64 %38 to i64*
  store i64 %39, i64* %41, align 8
  %42 = load i64, i64* %RBP, align 8
  %43 = add i64 %42, -12
  %44 = load i32, i32* %ESI, align 4
  %45 = load i64, i64* %PC, align 8
  %46 = add i64 %45, 3
  store i64 %46, i64* %PC, align 8
  %47 = inttoptr i64 %43 to i32*
  store i32 %44, i32* %47, align 4
  %48 = load i64, i64* %RBP, align 8
  %49 = add i64 %48, -8
  %50 = load i64, i64* %PC, align 8
  %51 = add i64 %50, 4
  store i64 %51, i64* %PC, align 8
  %52 = inttoptr i64 %49 to i64*
  %53 = load i64, i64* %52, align 8
  store i64 %53, i64* %RDI, align 8, !tbaa !2428
  %54 = add i64 %48, -24
  %55 = add i64 %50, 8
  store i64 %55, i64* %PC, align 8
  %56 = inttoptr i64 %54 to i64*
  store i64 %53, i64* %56, align 8
  %57 = load i64, i64* %RBP, align 8
  %58 = add i64 %57, -12
  %59 = load i64, i64* %PC, align 8
  %60 = add i64 %59, 4
  store i64 %60, i64* %PC, align 8
  %61 = inttoptr i64 %58 to i32*
  %62 = load i32, i32* %61, align 4
  %63 = sext i32 %62 to i64
  store i64 %63, i64* %RDI, align 8, !tbaa !2428
  %64 = add i64 %57, -24
  %65 = add i64 %59, 9
  store i64 %65, i64* %PC, align 8
  %66 = inttoptr i64 %64 to i64*
  %67 = load i64, i64* %66, align 8
  %68 = sext i32 %62 to i128
  %69 = and i128 %68, -18446744073709551616
  %70 = sext i64 %67 to i128
  %71 = and i128 %70, -18446744073709551616
  %72 = zext i64 %63 to i128
  %73 = or i128 %69, %72
  %74 = zext i64 %67 to i128
  %75 = or i128 %71, %74
  %76 = mul nsw i128 %75, %73
  %77 = trunc i128 %76 to i64
  store i64 %77, i64* %RDI, align 8, !tbaa !2428
  %78 = sext i64 %77 to i128
  %79 = icmp ne i128 %78, %76
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %13, align 1, !tbaa !2432
  %81 = trunc i128 %76 to i32
  %82 = and i32 %81, 255
  %83 = tail call i32 @llvm.ctpop.i32(i32 %82) #8
  %84 = trunc i32 %83 to i8
  %85 = and i8 %84, 1
  %86 = xor i8 %85, 1
  store i8 %86, i8* %20, align 1, !tbaa !2446
  store i8 0, i8* %25, align 1, !tbaa !2447
  store i8 0, i8* %28, align 1, !tbaa !2448
  %87 = lshr i64 %77, 63
  %88 = trunc i64 %87 to i8
  store i8 %88, i8* %31, align 1, !tbaa !2449
  store i8 %80, i8* %37, align 1, !tbaa !2450
  %89 = add i64 %59, 13
  store i64 %89, i64* %PC, align 8
  store i64 %77, i64* %66, align 8
  %90 = load i64, i64* %RBP, align 8
  %91 = add i64 %90, -24
  %92 = load i64, i64* %PC, align 8
  %93 = add i64 %92, 4
  store i64 %93, i64* %PC, align 8
  %94 = inttoptr i64 %91 to i64*
  %95 = load i64, i64* %94, align 8
  store i64 %95, i64* %RDI, align 8, !tbaa !2428
  %96 = add i64 %92, 28
  %97 = add i64 %92, 9
  %98 = load i64, i64* %RSP, align 8, !tbaa !2428
  %99 = add i64 %98, -8
  %100 = inttoptr i64 %99 to i64*
  store i64 %97, i64* %100, align 8
  store i64 %99, i64* %RSP, align 8, !tbaa !2428
  store i64 %96, i64* %PC, align 8, !tbaa !2428
  %101 = tail call %struct.Memory* @sub_400800_xmalloc_renamed_(%struct.State* nonnull %0, i64 %96, %struct.Memory* %2)
  %102 = load i64, i64* %RBP, align 8
  %103 = add i64 %102, -32
  %104 = load i64, i64* %RAX, align 8
  %105 = load i64, i64* %PC, align 8
  %106 = add i64 %105, 4
  store i64 %106, i64* %PC, align 8
  %107 = inttoptr i64 %103 to i64*
  store i64 %104, i64* %107, align 8
  %108 = load i64, i64* %RBP, align 8
  %109 = add i64 %108, -32
  %110 = load i64, i64* %PC, align 8
  %111 = add i64 %110, 4
  store i64 %111, i64* %PC, align 8
  %112 = inttoptr i64 %109 to i64*
  %113 = load i64, i64* %112, align 8
  store i64 %113, i64* %RAX, align 8, !tbaa !2428
  %114 = load i64, i64* %RSP, align 8
  %115 = add i64 %114, 32
  store i64 %115, i64* %RSP, align 8, !tbaa !2428
  %116 = icmp ugt i64 %114, -33
  %117 = zext i1 %116 to i8
  store i8 %117, i8* %13, align 1, !tbaa !2432
  %118 = trunc i64 %115 to i32
  %119 = and i32 %118, 255
  %120 = tail call i32 @llvm.ctpop.i32(i32 %119) #8
  %121 = trunc i32 %120 to i8
  %122 = and i8 %121, 1
  %123 = xor i8 %122, 1
  store i8 %123, i8* %20, align 1, !tbaa !2446
  %124 = xor i64 %114, %115
  %125 = lshr i64 %124, 4
  %126 = trunc i64 %125 to i8
  %127 = and i8 %126, 1
  store i8 %127, i8* %25, align 1, !tbaa !2447
  %128 = icmp eq i64 %115, 0
  %129 = zext i1 %128 to i8
  store i8 %129, i8* %28, align 1, !tbaa !2448
  %130 = lshr i64 %115, 63
  %131 = trunc i64 %130 to i8
  store i8 %131, i8* %31, align 1, !tbaa !2449
  %132 = lshr i64 %114, 63
  %133 = xor i64 %130, %132
  %134 = add nuw nsw i64 %133, %130
  %135 = icmp eq i64 %134, 2
  %136 = zext i1 %135 to i8
  store i8 %136, i8* %37, align 1, !tbaa !2450
  %137 = add i64 %110, 9
  store i64 %137, i64* %PC, align 8
  %138 = add i64 %114, 40
  %139 = inttoptr i64 %115 to i64*
  %140 = load i64, i64* %139, align 8
  store i64 %140, i64* %RBP, align 8, !tbaa !2428
  store i64 %138, i64* %RSP, align 8, !tbaa !2428
  %141 = add i64 %110, 10
  store i64 %141, i64* %PC, align 8
  %142 = inttoptr i64 %138 to i64*
  %143 = load i64, i64* %142, align 8
  store i64 %143, i64* %PC, align 8, !tbaa !2428
  %144 = add i64 %114, 48
  store i64 %144, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %101
}

; Function Attrs: noinline
define %struct.Memory* @sub_401f10_kernel_fdtd_apml_StrictFP(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_401f10:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %5 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %R12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 25, i32 0, i32 0
  %R13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 27, i32 0, i32 0
  %R14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 29, i32 0, i32 0
  %R15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 31, i32 0, i32 0
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %8 = load i64, i64* %RBP, align 8
  %9 = add i64 %1, 1
  store i64 %9, i64* %PC, align 8
  %10 = load i64, i64* %RSP, align 8, !tbaa !2428
  %11 = add i64 %10, -8
  %12 = inttoptr i64 %11 to i64*
  store i64 %8, i64* %12, align 8
  %13 = load i64, i64* %PC, align 8
  store i64 %11, i64* %RBP, align 8, !tbaa !2428
  %14 = load i64, i64* %R15, align 8
  %15 = add i64 %13, 5
  store i64 %15, i64* %PC, align 8
  %16 = add i64 %10, -16
  %17 = inttoptr i64 %16 to i64*
  store i64 %14, i64* %17, align 8
  %18 = load i64, i64* %R14, align 8
  %19 = load i64, i64* %PC, align 8
  %20 = add i64 %19, 2
  store i64 %20, i64* %PC, align 8
  %21 = add i64 %10, -24
  %22 = inttoptr i64 %21 to i64*
  store i64 %18, i64* %22, align 8
  %23 = load i64, i64* %R13, align 8
  %24 = load i64, i64* %PC, align 8
  %25 = add i64 %24, 2
  store i64 %25, i64* %PC, align 8
  %26 = add i64 %10, -32
  %27 = inttoptr i64 %26 to i64*
  store i64 %23, i64* %27, align 8
  %28 = load i64, i64* %R12, align 8
  %29 = load i64, i64* %PC, align 8
  %30 = add i64 %29, 2
  store i64 %30, i64* %PC, align 8
  %31 = add i64 %10, -40
  %32 = inttoptr i64 %31 to i64*
  store i64 %28, i64* %32, align 8
  %33 = load i64, i64* %RBX, align 8
  %34 = load i64, i64* %PC, align 8
  %35 = add i64 %34, 1
  store i64 %35, i64* %PC, align 8
  %36 = add i64 %10, -48
  %37 = inttoptr i64 %36 to i64*
  store i64 %33, i64* %37, align 8
  %38 = load i64, i64* %PC, align 8
  %39 = add i64 %10, -80
  store i64 %39, i64* %RSP, align 8, !tbaa !2428
  %40 = icmp ult i64 %36, 32
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %41, i8* %42, align 1, !tbaa !2432
  %43 = trunc i64 %39 to i32
  %44 = and i32 %43, 255
  %45 = tail call i32 @llvm.ctpop.i32(i32 %44) #8
  %46 = trunc i32 %45 to i8
  %47 = and i8 %46, 1
  %48 = xor i8 %47, 1
  %49 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %48, i8* %49, align 1, !tbaa !2446
  %50 = xor i64 %36, %39
  %51 = lshr i64 %50, 4
  %52 = trunc i64 %51 to i8
  %53 = and i8 %52, 1
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %53, i8* %54, align 1, !tbaa !2447
  %55 = icmp eq i64 %39, 0
  %56 = zext i1 %55 to i8
  %57 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %56, i8* %57, align 1, !tbaa !2448
  %58 = lshr i64 %39, 63
  %59 = trunc i64 %58 to i8
  %60 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %59, i8* %60, align 1, !tbaa !2449
  %61 = lshr i64 %36, 63
  %62 = xor i64 %58, %61
  %63 = add nuw nsw i64 %62, %61
  %64 = icmp eq i64 %63, 2
  %65 = zext i1 %64 to i8
  %66 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %65, i8* %66, align 1, !tbaa !2450
  %67 = load i64, i64* %RBP, align 8
  %68 = add i64 %67, 96
  %69 = add i64 %38, 8
  store i64 %69, i64* %PC, align 8
  %70 = inttoptr i64 %68 to i64*
  %71 = load i64, i64* %70, align 8
  store i64 %71, i64* %RAX, align 8, !tbaa !2428
  %72 = add i64 %67, 88
  %73 = add i64 %38, 12
  store i64 %73, i64* %PC, align 8
  %74 = inttoptr i64 %72 to i64*
  %75 = load i64, i64* %74, align 8
  store i64 %75, i64* %R10, align 8, !tbaa !2428
  %76 = add i64 %67, 80
  %77 = add i64 %38, 16
  store i64 %77, i64* %PC, align 8
  %78 = inttoptr i64 %76 to i64*
  %79 = load i64, i64* %78, align 8
  store i64 %79, i64* %R11, align 8, !tbaa !2428
  %80 = add i64 %67, 72
  %81 = add i64 %38, 20
  store i64 %81, i64* %PC, align 8
  %82 = inttoptr i64 %80 to i64*
  %83 = load i64, i64* %82, align 8
  store i64 %83, i64* %RBX, align 8, !tbaa !2428
  %84 = add i64 %67, 64
  %85 = add i64 %38, 24
  store i64 %85, i64* %PC, align 8
  %86 = inttoptr i64 %84 to i64*
  %87 = load i64, i64* %86, align 8
  store i64 %87, i64* %R14, align 8, !tbaa !2428
  %88 = add i64 %67, 56
  %89 = add i64 %38, 28
  store i64 %89, i64* %PC, align 8
  %90 = inttoptr i64 %88 to i64*
  %91 = load i64, i64* %90, align 8
  store i64 %91, i64* %R15, align 8, !tbaa !2428
  %92 = add i64 %67, 48
  %93 = add i64 %38, 32
  store i64 %93, i64* %PC, align 8
  %94 = inttoptr i64 %92 to i64*
  %95 = load i64, i64* %94, align 8
  store i64 %95, i64* %R12, align 8, !tbaa !2428
  %96 = add i64 %67, 40
  %97 = add i64 %38, 36
  store i64 %97, i64* %PC, align 8
  %98 = inttoptr i64 %96 to i64*
  %99 = load i64, i64* %98, align 8
  store i64 %99, i64* %R13, align 8, !tbaa !2428
  %100 = add i64 %67, -120
  %101 = add i64 %38, 40
  store i64 %101, i64* %PC, align 8
  %102 = inttoptr i64 %100 to i64*
  store i64 %71, i64* %102, align 8
  %103 = load i64, i64* %RBP, align 8
  %104 = add i64 %103, 32
  %105 = load i64, i64* %PC, align 8
  %106 = add i64 %105, 4
  store i64 %106, i64* %PC, align 8
  %107 = inttoptr i64 %104 to i64*
  %108 = load i64, i64* %107, align 8
  store i64 %108, i64* %RAX, align 8, !tbaa !2428
  %109 = add i64 %103, -128
  %110 = add i64 %105, 8
  store i64 %110, i64* %PC, align 8
  %111 = inttoptr i64 %109 to i64*
  store i64 %108, i64* %111, align 8
  %112 = load i64, i64* %RBP, align 8
  %113 = add i64 %112, 24
  %114 = load i64, i64* %PC, align 8
  %115 = add i64 %114, 4
  store i64 %115, i64* %PC, align 8
  %116 = inttoptr i64 %113 to i64*
  %117 = load i64, i64* %116, align 8
  store i64 %117, i64* %RAX, align 8, !tbaa !2428
  %118 = add i64 %112, -136
  %119 = add i64 %114, 11
  store i64 %119, i64* %PC, align 8
  %120 = inttoptr i64 %118 to i64*
  store i64 %117, i64* %120, align 8
  %121 = load i64, i64* %RBP, align 8
  %122 = add i64 %121, 16
  %123 = load i64, i64* %PC, align 8
  %124 = add i64 %123, 4
  store i64 %124, i64* %PC, align 8
  %125 = inttoptr i64 %122 to i64*
  %126 = load i64, i64* %125, align 8
  store i64 %126, i64* %RAX, align 8, !tbaa !2428
  %127 = add i64 %121, -44
  %128 = load i32, i32* %EDI, align 4
  %129 = add i64 %123, 7
  store i64 %129, i64* %PC, align 8
  %130 = inttoptr i64 %127 to i32*
  store i32 %128, i32* %130, align 4
  %131 = load i64, i64* %RBP, align 8
  %132 = add i64 %131, -48
  %133 = load i32, i32* %ESI, align 4
  %134 = load i64, i64* %PC, align 8
  %135 = add i64 %134, 3
  store i64 %135, i64* %PC, align 8
  %136 = inttoptr i64 %132 to i32*
  store i32 %133, i32* %136, align 4
  %137 = load i64, i64* %RBP, align 8
  %138 = add i64 %137, -52
  %139 = load i32, i32* %EDX, align 4
  %140 = load i64, i64* %PC, align 8
  %141 = add i64 %140, 3
  store i64 %141, i64* %PC, align 8
  %142 = inttoptr i64 %138 to i32*
  store i32 %139, i32* %142, align 4
  %143 = load i64, i64* %RBP, align 8
  %144 = add i64 %143, -64
  %145 = load i64, i64* %PC, align 8
  %146 = add i64 %145, 5
  store i64 %146, i64* %PC, align 8
  %147 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %148 = load i64, i64* %147, align 1
  %149 = inttoptr i64 %144 to i64*
  store i64 %148, i64* %149, align 8
  %150 = load i64, i64* %RBP, align 8
  %151 = add i64 %150, -72
  %152 = load i64, i64* %PC, align 8
  %153 = add i64 %152, 5
  store i64 %153, i64* %PC, align 8
  %154 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %7, i64 0, i32 0, i32 0, i32 0, i64 0
  %155 = load i64, i64* %154, align 1
  %156 = inttoptr i64 %151 to i64*
  store i64 %155, i64* %156, align 8
  %157 = load i64, i64* %RBP, align 8
  %158 = add i64 %157, -80
  %159 = load i64, i64* %RCX, align 8
  %160 = load i64, i64* %PC, align 8
  %161 = add i64 %160, 4
  store i64 %161, i64* %PC, align 8
  %162 = inttoptr i64 %158 to i64*
  store i64 %159, i64* %162, align 8
  %163 = load i64, i64* %RBP, align 8
  %164 = add i64 %163, -88
  %165 = load i64, i64* %R8, align 8
  %166 = load i64, i64* %PC, align 8
  %167 = add i64 %166, 4
  store i64 %167, i64* %PC, align 8
  %168 = inttoptr i64 %164 to i64*
  store i64 %165, i64* %168, align 8
  %169 = load i64, i64* %RBP, align 8
  %170 = add i64 %169, -96
  %171 = load i64, i64* %R9, align 8
  %172 = load i64, i64* %PC, align 8
  %173 = add i64 %172, 4
  store i64 %173, i64* %PC, align 8
  %174 = inttoptr i64 %170 to i64*
  store i64 %171, i64* %174, align 8
  %175 = load i64, i64* %RBP, align 8
  %176 = add i64 %175, -100
  %177 = load i64, i64* %PC, align 8
  %178 = add i64 %177, 7
  store i64 %178, i64* %PC, align 8
  %179 = inttoptr i64 %176 to i32*
  store i32 0, i32* %179, align 4
  %180 = load i64, i64* %RBP, align 8
  %181 = add i64 %180, -144
  %182 = load i64, i64* %R13, align 8
  %183 = load i64, i64* %PC, align 8
  %184 = add i64 %183, 7
  store i64 %184, i64* %PC, align 8
  %185 = inttoptr i64 %181 to i64*
  store i64 %182, i64* %185, align 8
  %186 = load i64, i64* %RBP, align 8
  %187 = add i64 %186, -152
  %188 = load i64, i64* %RAX, align 8
  %189 = load i64, i64* %PC, align 8
  %190 = add i64 %189, 7
  store i64 %190, i64* %PC, align 8
  %191 = inttoptr i64 %187 to i64*
  store i64 %188, i64* %191, align 8
  %192 = load i64, i64* %RBP, align 8
  %193 = add i64 %192, -160
  %194 = load i64, i64* %R10, align 8
  %195 = load i64, i64* %PC, align 8
  %196 = add i64 %195, 7
  store i64 %196, i64* %PC, align 8
  %197 = inttoptr i64 %193 to i64*
  store i64 %194, i64* %197, align 8
  %198 = load i64, i64* %RBP, align 8
  %199 = add i64 %198, -168
  %200 = load i64, i64* %R11, align 8
  %201 = load i64, i64* %PC, align 8
  %202 = add i64 %201, 7
  store i64 %202, i64* %PC, align 8
  %203 = inttoptr i64 %199 to i64*
  store i64 %200, i64* %203, align 8
  %204 = load i64, i64* %RBP, align 8
  %205 = add i64 %204, -176
  %206 = load i64, i64* %RBX, align 8
  %207 = load i64, i64* %PC, align 8
  %208 = add i64 %207, 7
  store i64 %208, i64* %PC, align 8
  %209 = inttoptr i64 %205 to i64*
  store i64 %206, i64* %209, align 8
  %210 = load i64, i64* %RBP, align 8
  %211 = add i64 %210, -184
  %212 = load i64, i64* %R14, align 8
  %213 = load i64, i64* %PC, align 8
  %214 = add i64 %213, 7
  store i64 %214, i64* %PC, align 8
  %215 = inttoptr i64 %211 to i64*
  store i64 %212, i64* %215, align 8
  %216 = load i64, i64* %RBP, align 8
  %217 = add i64 %216, -192
  %218 = load i64, i64* %R15, align 8
  %219 = load i64, i64* %PC, align 8
  %220 = add i64 %219, 7
  store i64 %220, i64* %PC, align 8
  %221 = inttoptr i64 %217 to i64*
  store i64 %218, i64* %221, align 8
  %222 = load i64, i64* %RBP, align 8
  %223 = add i64 %222, -200
  %224 = load i64, i64* %R12, align 8
  %225 = load i64, i64* %PC, align 8
  %226 = add i64 %225, 7
  store i64 %226, i64* %PC, align 8
  %227 = inttoptr i64 %223 to i64*
  store i64 %224, i64* %227, align 8
  %228 = bitcast [32 x %union.VectorReg]* %6 to double*
  %229 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %230 = bitcast i64* %229 to double*
  %231 = bitcast %union.VectorReg* %7 to double*
  %232 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %233 = bitcast i64* %232 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_401fba

block_401fd9:                                     ; preds = %block_401fcd
  %234 = add i64 %327, -108
  %235 = add i64 %363, 7
  store i64 %235, i64* %PC, align 8
  %236 = inttoptr i64 %234 to i32*
  store i32 0, i32* %236, align 4
  %.pre3 = load i64, i64* %PC, align 8
  br label %block_401fe0

block_401fba:                                     ; preds = %block_402a25, %block_401f10
  %237 = phi i64 [ %4714, %block_402a25 ], [ %.pre, %block_401f10 ]
  %238 = load i64, i64* %RBP, align 8
  %239 = add i64 %238, -100
  %240 = add i64 %237, 3
  store i64 %240, i64* %PC, align 8
  %241 = inttoptr i64 %239 to i32*
  %242 = load i32, i32* %241, align 4
  %243 = zext i32 %242 to i64
  store i64 %243, i64* %RAX, align 8, !tbaa !2428
  %244 = add i64 %238, -44
  %245 = add i64 %237, 6
  store i64 %245, i64* %PC, align 8
  %246 = inttoptr i64 %244 to i32*
  %247 = load i32, i32* %246, align 4
  %248 = sub i32 %242, %247
  %249 = icmp ult i32 %242, %247
  %250 = zext i1 %249 to i8
  store i8 %250, i8* %42, align 1, !tbaa !2432
  %251 = and i32 %248, 255
  %252 = tail call i32 @llvm.ctpop.i32(i32 %251) #8
  %253 = trunc i32 %252 to i8
  %254 = and i8 %253, 1
  %255 = xor i8 %254, 1
  store i8 %255, i8* %49, align 1, !tbaa !2446
  %256 = xor i32 %247, %242
  %257 = xor i32 %256, %248
  %258 = lshr i32 %257, 4
  %259 = trunc i32 %258 to i8
  %260 = and i8 %259, 1
  store i8 %260, i8* %54, align 1, !tbaa !2447
  %261 = icmp eq i32 %248, 0
  %262 = zext i1 %261 to i8
  store i8 %262, i8* %57, align 1, !tbaa !2448
  %263 = lshr i32 %248, 31
  %264 = trunc i32 %263 to i8
  store i8 %264, i8* %60, align 1, !tbaa !2449
  %265 = lshr i32 %242, 31
  %266 = lshr i32 %247, 31
  %267 = xor i32 %266, %265
  %268 = xor i32 %263, %265
  %269 = add nuw nsw i32 %268, %267
  %270 = icmp eq i32 %269, 2
  %271 = zext i1 %270 to i8
  store i8 %271, i8* %66, align 1, !tbaa !2450
  %272 = icmp ne i8 %264, 0
  %273 = xor i1 %272, %270
  %.v = select i1 %273, i64 12, i64 2686
  %274 = add i64 %237, %.v
  store i64 %274, i64* %PC, align 8, !tbaa !2428
  br i1 %273, label %block_401fc6, label %block_402a38

block_402a38:                                     ; preds = %block_401fba
  %275 = load i64, i64* %RSP, align 8
  %276 = add i64 %275, 32
  store i64 %276, i64* %RSP, align 8, !tbaa !2428
  %277 = icmp ugt i64 %275, -33
  %278 = zext i1 %277 to i8
  store i8 %278, i8* %42, align 1, !tbaa !2432
  %279 = trunc i64 %276 to i32
  %280 = and i32 %279, 255
  %281 = tail call i32 @llvm.ctpop.i32(i32 %280) #8
  %282 = trunc i32 %281 to i8
  %283 = and i8 %282, 1
  %284 = xor i8 %283, 1
  store i8 %284, i8* %49, align 1, !tbaa !2446
  %285 = xor i64 %275, %276
  %286 = lshr i64 %285, 4
  %287 = trunc i64 %286 to i8
  %288 = and i8 %287, 1
  store i8 %288, i8* %54, align 1, !tbaa !2447
  %289 = icmp eq i64 %276, 0
  %290 = zext i1 %289 to i8
  store i8 %290, i8* %57, align 1, !tbaa !2448
  %291 = lshr i64 %276, 63
  %292 = trunc i64 %291 to i8
  store i8 %292, i8* %60, align 1, !tbaa !2449
  %293 = lshr i64 %275, 63
  %294 = xor i64 %291, %293
  %295 = add nuw nsw i64 %294, %291
  %296 = icmp eq i64 %295, 2
  %297 = zext i1 %296 to i8
  store i8 %297, i8* %66, align 1, !tbaa !2450
  %298 = add i64 %274, 5
  store i64 %298, i64* %PC, align 8
  %299 = add i64 %275, 40
  %300 = inttoptr i64 %276 to i64*
  %301 = load i64, i64* %300, align 8
  store i64 %301, i64* %RBX, align 8, !tbaa !2428
  store i64 %299, i64* %RSP, align 8, !tbaa !2428
  %302 = add i64 %274, 7
  store i64 %302, i64* %PC, align 8
  %303 = add i64 %275, 48
  %304 = inttoptr i64 %299 to i64*
  %305 = load i64, i64* %304, align 8
  store i64 %305, i64* %R12, align 8, !tbaa !2428
  store i64 %303, i64* %RSP, align 8, !tbaa !2428
  %306 = add i64 %274, 9
  store i64 %306, i64* %PC, align 8
  %307 = add i64 %275, 56
  %308 = inttoptr i64 %303 to i64*
  %309 = load i64, i64* %308, align 8
  store i64 %309, i64* %R13, align 8, !tbaa !2428
  store i64 %307, i64* %RSP, align 8, !tbaa !2428
  %310 = add i64 %274, 11
  store i64 %310, i64* %PC, align 8
  %311 = add i64 %275, 64
  %312 = inttoptr i64 %307 to i64*
  %313 = load i64, i64* %312, align 8
  store i64 %313, i64* %R14, align 8, !tbaa !2428
  store i64 %311, i64* %RSP, align 8, !tbaa !2428
  %314 = add i64 %274, 13
  store i64 %314, i64* %PC, align 8
  %315 = add i64 %275, 72
  %316 = inttoptr i64 %311 to i64*
  %317 = load i64, i64* %316, align 8
  store i64 %317, i64* %R15, align 8, !tbaa !2428
  store i64 %315, i64* %RSP, align 8, !tbaa !2428
  %318 = add i64 %274, 14
  store i64 %318, i64* %PC, align 8
  %319 = add i64 %275, 80
  %320 = inttoptr i64 %315 to i64*
  %321 = load i64, i64* %320, align 8
  store i64 %321, i64* %RBP, align 8, !tbaa !2428
  store i64 %319, i64* %RSP, align 8, !tbaa !2428
  %322 = add i64 %274, 15
  store i64 %322, i64* %PC, align 8
  %323 = inttoptr i64 %319 to i64*
  %324 = load i64, i64* %323, align 8
  store i64 %324, i64* %PC, align 8, !tbaa !2428
  %325 = add i64 %275, 88
  store i64 %325, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_401fcd:                                     ; preds = %block_401fc6, %block_4027ab
  %326 = phi i64 [ %.pre2, %block_401fc6 ], [ %2504, %block_4027ab ]
  %327 = load i64, i64* %RBP, align 8
  %328 = add i64 %327, -104
  %329 = add i64 %326, 3
  store i64 %329, i64* %PC, align 8
  %330 = inttoptr i64 %328 to i32*
  %331 = load i32, i32* %330, align 4
  %332 = zext i32 %331 to i64
  store i64 %332, i64* %RAX, align 8, !tbaa !2428
  %333 = add i64 %327, -52
  %334 = add i64 %326, 6
  store i64 %334, i64* %PC, align 8
  %335 = inttoptr i64 %333 to i32*
  %336 = load i32, i32* %335, align 4
  %337 = sub i32 %331, %336
  %338 = icmp ult i32 %331, %336
  %339 = zext i1 %338 to i8
  store i8 %339, i8* %42, align 1, !tbaa !2432
  %340 = and i32 %337, 255
  %341 = tail call i32 @llvm.ctpop.i32(i32 %340) #8
  %342 = trunc i32 %341 to i8
  %343 = and i8 %342, 1
  %344 = xor i8 %343, 1
  store i8 %344, i8* %49, align 1, !tbaa !2446
  %345 = xor i32 %336, %331
  %346 = xor i32 %345, %337
  %347 = lshr i32 %346, 4
  %348 = trunc i32 %347 to i8
  %349 = and i8 %348, 1
  store i8 %349, i8* %54, align 1, !tbaa !2447
  %350 = icmp eq i32 %337, 0
  %351 = zext i1 %350 to i8
  store i8 %351, i8* %57, align 1, !tbaa !2448
  %352 = lshr i32 %337, 31
  %353 = trunc i32 %352 to i8
  store i8 %353, i8* %60, align 1, !tbaa !2449
  %354 = lshr i32 %331, 31
  %355 = lshr i32 %336, 31
  %356 = xor i32 %355, %354
  %357 = xor i32 %352, %354
  %358 = add nuw nsw i32 %357, %356
  %359 = icmp eq i32 %358, 2
  %360 = zext i1 %359 to i8
  store i8 %360, i8* %66, align 1, !tbaa !2450
  %361 = icmp ne i8 %353, 0
  %362 = xor i1 %361, %359
  %.v5 = select i1 %362, i64 12, i64 2648
  %363 = add i64 %326, %.v5
  store i64 %363, i64* %PC, align 8, !tbaa !2428
  br i1 %362, label %block_401fd9, label %block_402a25

block_402512:                                     ; preds = %block_40251e, %block_40228c
  %364 = phi i64 [ %3575, %block_40251e ], [ %.pre4, %block_40228c ]
  %365 = load i64, i64* %RBP, align 8
  %366 = add i64 %365, -108
  %367 = add i64 %364, 3
  store i64 %367, i64* %PC, align 8
  %368 = inttoptr i64 %366 to i32*
  %369 = load i32, i32* %368, align 4
  %370 = zext i32 %369 to i64
  store i64 %370, i64* %RAX, align 8, !tbaa !2428
  %371 = add i64 %365, -48
  %372 = add i64 %364, 6
  store i64 %372, i64* %PC, align 8
  %373 = inttoptr i64 %371 to i32*
  %374 = load i32, i32* %373, align 4
  %375 = sub i32 %369, %374
  %376 = icmp ult i32 %369, %374
  %377 = zext i1 %376 to i8
  store i8 %377, i8* %42, align 1, !tbaa !2432
  %378 = and i32 %375, 255
  %379 = tail call i32 @llvm.ctpop.i32(i32 %378) #8
  %380 = trunc i32 %379 to i8
  %381 = and i8 %380, 1
  %382 = xor i8 %381, 1
  store i8 %382, i8* %49, align 1, !tbaa !2446
  %383 = xor i32 %374, %369
  %384 = xor i32 %383, %375
  %385 = lshr i32 %384, 4
  %386 = trunc i32 %385 to i8
  %387 = and i8 %386, 1
  store i8 %387, i8* %54, align 1, !tbaa !2447
  %388 = icmp eq i32 %375, 0
  %389 = zext i1 %388 to i8
  store i8 %389, i8* %57, align 1, !tbaa !2448
  %390 = lshr i32 %375, 31
  %391 = trunc i32 %390 to i8
  store i8 %391, i8* %60, align 1, !tbaa !2449
  %392 = lshr i32 %369, 31
  %393 = lshr i32 %374, 31
  %394 = xor i32 %393, %392
  %395 = xor i32 %390, %392
  %396 = add nuw nsw i32 %395, %394
  %397 = icmp eq i32 %396, 2
  %398 = zext i1 %397 to i8
  store i8 %398, i8* %66, align 1, !tbaa !2450
  %399 = icmp ne i8 %391, 0
  %400 = xor i1 %399, %397
  %.v7 = select i1 %400, i64 12, i64 665
  %401 = add i64 %364, %.v7
  %402 = add i64 %365, 32
  %403 = add i64 %401, 4
  store i64 %403, i64* %PC, align 8
  %404 = inttoptr i64 %402 to i64*
  %405 = load i64, i64* %404, align 8
  store i64 %405, i64* %RAX, align 8, !tbaa !2428
  %406 = add i64 %365, -100
  %407 = add i64 %401, 8
  store i64 %407, i64* %PC, align 8
  %408 = inttoptr i64 %406 to i32*
  %409 = load i32, i32* %408, align 4
  %410 = sext i32 %409 to i64
  %411 = mul nsw i64 %410, 33800
  store i64 %411, i64* %RCX, align 8, !tbaa !2428
  %412 = lshr i64 %411, 63
  %413 = add i64 %411, %405
  store i64 %413, i64* %RAX, align 8, !tbaa !2428
  %414 = icmp ult i64 %413, %405
  %415 = icmp ult i64 %413, %411
  %416 = or i1 %414, %415
  %417 = zext i1 %416 to i8
  store i8 %417, i8* %42, align 1, !tbaa !2432
  %418 = trunc i64 %413 to i32
  %419 = and i32 %418, 255
  %420 = tail call i32 @llvm.ctpop.i32(i32 %419) #8
  %421 = trunc i32 %420 to i8
  %422 = and i8 %421, 1
  %423 = xor i8 %422, 1
  store i8 %423, i8* %49, align 1, !tbaa !2446
  %424 = xor i64 %411, %405
  %425 = xor i64 %424, %413
  %426 = lshr i64 %425, 4
  %427 = trunc i64 %426 to i8
  %428 = and i8 %427, 1
  store i8 %428, i8* %54, align 1, !tbaa !2447
  %429 = icmp eq i64 %413, 0
  %430 = zext i1 %429 to i8
  store i8 %430, i8* %57, align 1, !tbaa !2448
  %431 = lshr i64 %413, 63
  %432 = trunc i64 %431 to i8
  store i8 %432, i8* %60, align 1, !tbaa !2449
  %433 = lshr i64 %405, 63
  %434 = xor i64 %431, %433
  %435 = xor i64 %431, %412
  %436 = add nuw nsw i64 %434, %435
  %437 = icmp eq i64 %436, 2
  %438 = zext i1 %437 to i8
  store i8 %438, i8* %66, align 1, !tbaa !2450
  %439 = load i64, i64* %RBP, align 8
  %440 = add i64 %439, -52
  %441 = add i64 %401, 22
  store i64 %441, i64* %PC, align 8
  %442 = inttoptr i64 %440 to i32*
  %443 = load i32, i32* %442, align 4
  %444 = sext i32 %443 to i64
  %445 = mul nsw i64 %444, 520
  store i64 %445, i64* %RCX, align 8, !tbaa !2428
  %446 = lshr i64 %445, 63
  %447 = add i64 %401, 32
  store i64 %447, i64* %PC, align 8
  %448 = add i64 %445, %413
  store i64 %448, i64* %RAX, align 8, !tbaa !2428
  %449 = icmp ult i64 %448, %413
  %450 = icmp ult i64 %448, %445
  %451 = or i1 %449, %450
  %452 = zext i1 %451 to i8
  store i8 %452, i8* %42, align 1, !tbaa !2432
  %453 = trunc i64 %448 to i32
  %454 = and i32 %453, 255
  %455 = tail call i32 @llvm.ctpop.i32(i32 %454) #8
  %456 = trunc i32 %455 to i8
  %457 = and i8 %456, 1
  %458 = xor i8 %457, 1
  store i8 %458, i8* %49, align 1, !tbaa !2446
  %459 = xor i64 %445, %413
  %460 = xor i64 %459, %448
  %461 = lshr i64 %460, 4
  %462 = trunc i64 %461 to i8
  %463 = and i8 %462, 1
  store i8 %463, i8* %54, align 1, !tbaa !2447
  %464 = icmp eq i64 %448, 0
  %465 = zext i1 %464 to i8
  store i8 %465, i8* %57, align 1, !tbaa !2448
  %466 = lshr i64 %448, 63
  %467 = trunc i64 %466 to i8
  store i8 %467, i8* %60, align 1, !tbaa !2449
  %468 = xor i64 %466, %431
  %469 = xor i64 %466, %446
  %470 = add nuw nsw i64 %468, %469
  %471 = icmp eq i64 %470, 2
  %472 = zext i1 %471 to i8
  store i8 %472, i8* %66, align 1, !tbaa !2450
  br i1 %400, label %block_40251e, label %block_4027ab

block_40228c:                                     ; preds = %block_401fe0
  %473 = add i64 %4790, -48
  %474 = add i64 %4752, 36
  store i64 %474, i64* %PC, align 8
  %475 = inttoptr i64 %473 to i32*
  %476 = load i32, i32* %475, align 4
  %477 = sext i32 %476 to i64
  store i64 %477, i64* %RCX, align 8, !tbaa !2428
  %478 = shl nsw i64 %477, 3
  %479 = add i64 %478, %4799
  %480 = add i64 %4752, 41
  store i64 %480, i64* %PC, align 8
  %481 = inttoptr i64 %479 to i64*
  %482 = load i64, i64* %481, align 8
  store i64 %482, i64* %147, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %483 = add i64 %4790, 32
  %484 = add i64 %4752, 45
  store i64 %484, i64* %PC, align 8
  %485 = inttoptr i64 %483 to i64*
  %486 = load i64, i64* %485, align 8
  store i64 %486, i64* %RAX, align 8, !tbaa !2428
  %487 = add i64 %4790, -100
  %488 = add i64 %4752, 49
  store i64 %488, i64* %PC, align 8
  %489 = inttoptr i64 %487 to i32*
  %490 = load i32, i32* %489, align 4
  %491 = sext i32 %490 to i64
  %492 = mul nsw i64 %491, 33800
  store i64 %492, i64* %RCX, align 8, !tbaa !2428
  %493 = lshr i64 %492, 63
  %494 = add i64 %492, %486
  store i64 %494, i64* %RAX, align 8, !tbaa !2428
  %495 = icmp ult i64 %494, %486
  %496 = icmp ult i64 %494, %492
  %497 = or i1 %495, %496
  %498 = zext i1 %497 to i8
  store i8 %498, i8* %42, align 1, !tbaa !2432
  %499 = trunc i64 %494 to i32
  %500 = and i32 %499, 255
  %501 = tail call i32 @llvm.ctpop.i32(i32 %500) #8
  %502 = trunc i32 %501 to i8
  %503 = and i8 %502, 1
  %504 = xor i8 %503, 1
  store i8 %504, i8* %49, align 1, !tbaa !2446
  %505 = xor i64 %492, %486
  %506 = xor i64 %505, %494
  %507 = lshr i64 %506, 4
  %508 = trunc i64 %507 to i8
  %509 = and i8 %508, 1
  store i8 %509, i8* %54, align 1, !tbaa !2447
  %510 = icmp eq i64 %494, 0
  %511 = zext i1 %510 to i8
  store i8 %511, i8* %57, align 1, !tbaa !2448
  %512 = lshr i64 %494, 63
  %513 = trunc i64 %512 to i8
  store i8 %513, i8* %60, align 1, !tbaa !2449
  %514 = lshr i64 %486, 63
  %515 = xor i64 %512, %514
  %516 = xor i64 %512, %493
  %517 = add nuw nsw i64 %515, %516
  %518 = icmp eq i64 %517, 2
  %519 = zext i1 %518 to i8
  store i8 %519, i8* %66, align 1, !tbaa !2450
  %520 = add i64 %4752, 62
  store i64 %520, i64* %PC, align 8
  %521 = load i32, i32* %4793, align 4
  %522 = add i32 %521, 1
  %523 = zext i32 %522 to i64
  store i64 %523, i64* %RDX, align 8, !tbaa !2428
  %524 = sext i32 %522 to i64
  %525 = mul nsw i64 %524, 520
  store i64 %525, i64* %RCX, align 8, !tbaa !2428
  %526 = lshr i64 %525, 63
  %527 = load i64, i64* %RAX, align 8
  %528 = add i64 %525, %527
  store i64 %528, i64* %RAX, align 8, !tbaa !2428
  %529 = icmp ult i64 %528, %527
  %530 = icmp ult i64 %528, %525
  %531 = or i1 %529, %530
  %532 = zext i1 %531 to i8
  store i8 %532, i8* %42, align 1, !tbaa !2432
  %533 = trunc i64 %528 to i32
  %534 = and i32 %533, 255
  %535 = tail call i32 @llvm.ctpop.i32(i32 %534) #8
  %536 = trunc i32 %535 to i8
  %537 = and i8 %536, 1
  %538 = xor i8 %537, 1
  store i8 %538, i8* %49, align 1, !tbaa !2446
  %539 = xor i64 %525, %527
  %540 = xor i64 %539, %528
  %541 = lshr i64 %540, 4
  %542 = trunc i64 %541 to i8
  %543 = and i8 %542, 1
  store i8 %543, i8* %54, align 1, !tbaa !2447
  %544 = icmp eq i64 %528, 0
  %545 = zext i1 %544 to i8
  store i8 %545, i8* %57, align 1, !tbaa !2448
  %546 = lshr i64 %528, 63
  %547 = trunc i64 %546 to i8
  store i8 %547, i8* %60, align 1, !tbaa !2449
  %548 = lshr i64 %527, 63
  %549 = xor i64 %546, %548
  %550 = xor i64 %546, %526
  %551 = add nuw nsw i64 %549, %550
  %552 = icmp eq i64 %551, 2
  %553 = zext i1 %552 to i8
  store i8 %553, i8* %66, align 1, !tbaa !2450
  %554 = load i64, i64* %RBP, align 8
  %555 = add i64 %554, -48
  %556 = add i64 %4752, 82
  store i64 %556, i64* %PC, align 8
  %557 = inttoptr i64 %555 to i32*
  %558 = load i32, i32* %557, align 4
  %559 = sext i32 %558 to i64
  store i64 %559, i64* %RCX, align 8, !tbaa !2428
  %560 = shl nsw i64 %559, 3
  %561 = add i64 %560, %528
  %562 = add i64 %4752, 87
  store i64 %562, i64* %PC, align 8
  %563 = load double, double* %228, align 1
  %564 = inttoptr i64 %561 to double*
  %565 = load double, double* %564, align 8
  %566 = fsub double %563, %565
  store double %566, double* %228, align 1, !tbaa !2452
  %567 = add i64 %554, -88
  %568 = add i64 %4752, 91
  store i64 %568, i64* %PC, align 8
  %569 = inttoptr i64 %567 to i64*
  %570 = load i64, i64* %569, align 8
  store i64 %570, i64* %RAX, align 8, !tbaa !2428
  %571 = add i64 %554, -100
  %572 = add i64 %4752, 95
  store i64 %572, i64* %PC, align 8
  %573 = inttoptr i64 %571 to i32*
  %574 = load i32, i32* %573, align 4
  %575 = sext i32 %574 to i64
  %576 = mul nsw i64 %575, 520
  store i64 %576, i64* %RCX, align 8, !tbaa !2428
  %577 = lshr i64 %576, 63
  %578 = add i64 %576, %570
  store i64 %578, i64* %RAX, align 8, !tbaa !2428
  %579 = icmp ult i64 %578, %570
  %580 = icmp ult i64 %578, %576
  %581 = or i1 %579, %580
  %582 = zext i1 %581 to i8
  store i8 %582, i8* %42, align 1, !tbaa !2432
  %583 = trunc i64 %578 to i32
  %584 = and i32 %583, 255
  %585 = tail call i32 @llvm.ctpop.i32(i32 %584) #8
  %586 = trunc i32 %585 to i8
  %587 = and i8 %586, 1
  %588 = xor i8 %587, 1
  store i8 %588, i8* %49, align 1, !tbaa !2446
  %589 = xor i64 %576, %570
  %590 = xor i64 %589, %578
  %591 = lshr i64 %590, 4
  %592 = trunc i64 %591 to i8
  %593 = and i8 %592, 1
  store i8 %593, i8* %54, align 1, !tbaa !2447
  %594 = icmp eq i64 %578, 0
  %595 = zext i1 %594 to i8
  store i8 %595, i8* %57, align 1, !tbaa !2448
  %596 = lshr i64 %578, 63
  %597 = trunc i64 %596 to i8
  store i8 %597, i8* %60, align 1, !tbaa !2449
  %598 = lshr i64 %570, 63
  %599 = xor i64 %596, %598
  %600 = xor i64 %596, %577
  %601 = add nuw nsw i64 %599, %600
  %602 = icmp eq i64 %601, 2
  %603 = zext i1 %602 to i8
  store i8 %603, i8* %66, align 1, !tbaa !2450
  %604 = add i64 %554, -104
  %605 = add i64 %4752, 109
  store i64 %605, i64* %PC, align 8
  %606 = inttoptr i64 %604 to i32*
  %607 = load i32, i32* %606, align 4
  %608 = sext i32 %607 to i64
  store i64 %608, i64* %RCX, align 8, !tbaa !2428
  %609 = shl nsw i64 %608, 3
  %610 = add i64 %609, %578
  %611 = add i64 %4752, 114
  store i64 %611, i64* %PC, align 8
  %612 = inttoptr i64 %610 to double*
  %613 = load double, double* %612, align 8
  %614 = fadd double %566, %613
  store double %614, double* %228, align 1, !tbaa !2452
  %615 = load i64, i64* %RBP, align 8
  %616 = add i64 %615, 40
  %617 = add i64 %4752, 118
  store i64 %617, i64* %PC, align 8
  %618 = inttoptr i64 %616 to i64*
  %619 = load i64, i64* %618, align 8
  store i64 %619, i64* %RAX, align 8, !tbaa !2428
  %620 = add i64 %615, -100
  %621 = add i64 %4752, 122
  store i64 %621, i64* %PC, align 8
  %622 = inttoptr i64 %620 to i32*
  %623 = load i32, i32* %622, align 4
  %624 = sext i32 %623 to i64
  %625 = mul nsw i64 %624, 33800
  store i64 %625, i64* %RCX, align 8, !tbaa !2428
  %626 = lshr i64 %625, 63
  %627 = add i64 %625, %619
  store i64 %627, i64* %RAX, align 8, !tbaa !2428
  %628 = icmp ult i64 %627, %619
  %629 = icmp ult i64 %627, %625
  %630 = or i1 %628, %629
  %631 = zext i1 %630 to i8
  store i8 %631, i8* %42, align 1, !tbaa !2432
  %632 = trunc i64 %627 to i32
  %633 = and i32 %632, 255
  %634 = tail call i32 @llvm.ctpop.i32(i32 %633) #8
  %635 = trunc i32 %634 to i8
  %636 = and i8 %635, 1
  %637 = xor i8 %636, 1
  store i8 %637, i8* %49, align 1, !tbaa !2446
  %638 = xor i64 %625, %619
  %639 = xor i64 %638, %627
  %640 = lshr i64 %639, 4
  %641 = trunc i64 %640 to i8
  %642 = and i8 %641, 1
  store i8 %642, i8* %54, align 1, !tbaa !2447
  %643 = icmp eq i64 %627, 0
  %644 = zext i1 %643 to i8
  store i8 %644, i8* %57, align 1, !tbaa !2448
  %645 = lshr i64 %627, 63
  %646 = trunc i64 %645 to i8
  store i8 %646, i8* %60, align 1, !tbaa !2449
  %647 = lshr i64 %619, 63
  %648 = xor i64 %645, %647
  %649 = xor i64 %645, %626
  %650 = add nuw nsw i64 %648, %649
  %651 = icmp eq i64 %650, 2
  %652 = zext i1 %651 to i8
  store i8 %652, i8* %66, align 1, !tbaa !2450
  %653 = add i64 %615, -104
  %654 = add i64 %4752, 136
  store i64 %654, i64* %PC, align 8
  %655 = inttoptr i64 %653 to i32*
  %656 = load i32, i32* %655, align 4
  %657 = sext i32 %656 to i64
  %658 = mul nsw i64 %657, 520
  store i64 %658, i64* %RCX, align 8, !tbaa !2428
  %659 = lshr i64 %658, 63
  %660 = add i64 %658, %627
  store i64 %660, i64* %RAX, align 8, !tbaa !2428
  %661 = icmp ult i64 %660, %627
  %662 = icmp ult i64 %660, %658
  %663 = or i1 %661, %662
  %664 = zext i1 %663 to i8
  store i8 %664, i8* %42, align 1, !tbaa !2432
  %665 = trunc i64 %660 to i32
  %666 = and i32 %665, 255
  %667 = tail call i32 @llvm.ctpop.i32(i32 %666) #8
  %668 = trunc i32 %667 to i8
  %669 = and i8 %668, 1
  %670 = xor i8 %669, 1
  store i8 %670, i8* %49, align 1, !tbaa !2446
  %671 = xor i64 %658, %627
  %672 = xor i64 %671, %660
  %673 = lshr i64 %672, 4
  %674 = trunc i64 %673 to i8
  %675 = and i8 %674, 1
  store i8 %675, i8* %54, align 1, !tbaa !2447
  %676 = icmp eq i64 %660, 0
  %677 = zext i1 %676 to i8
  store i8 %677, i8* %57, align 1, !tbaa !2448
  %678 = lshr i64 %660, 63
  %679 = trunc i64 %678 to i8
  store i8 %679, i8* %60, align 1, !tbaa !2449
  %680 = xor i64 %678, %645
  %681 = xor i64 %678, %659
  %682 = add nuw nsw i64 %680, %681
  %683 = icmp eq i64 %682, 2
  %684 = zext i1 %683 to i8
  store i8 %684, i8* %66, align 1, !tbaa !2450
  %685 = load i64, i64* %RBP, align 8
  %686 = add i64 %685, -48
  %687 = add i64 %4752, 150
  store i64 %687, i64* %PC, align 8
  %688 = inttoptr i64 %686 to i32*
  %689 = load i32, i32* %688, align 4
  %690 = sext i32 %689 to i64
  store i64 %690, i64* %RCX, align 8, !tbaa !2428
  %691 = shl nsw i64 %690, 3
  %692 = add i64 %691, %660
  %693 = add i64 %4752, 155
  store i64 %693, i64* %PC, align 8
  %694 = load double, double* %228, align 1
  %695 = inttoptr i64 %692 to double*
  %696 = load double, double* %695, align 8
  %697 = fsub double %694, %696
  store double %697, double* %228, align 1, !tbaa !2452
  %698 = add i64 %685, -96
  %699 = add i64 %4752, 159
  store i64 %699, i64* %PC, align 8
  %700 = inttoptr i64 %698 to i64*
  %701 = load i64, i64* %700, align 8
  store i64 %701, i64* %RAX, align 8, !tbaa !2428
  %702 = add i64 %685, -100
  %703 = add i64 %4752, 163
  store i64 %703, i64* %PC, align 8
  %704 = inttoptr i64 %702 to i32*
  %705 = load i32, i32* %704, align 4
  %706 = sext i32 %705 to i64
  %707 = mul nsw i64 %706, 520
  store i64 %707, i64* %RCX, align 8, !tbaa !2428
  %708 = lshr i64 %707, 63
  %709 = add i64 %707, %701
  store i64 %709, i64* %RAX, align 8, !tbaa !2428
  %710 = icmp ult i64 %709, %701
  %711 = icmp ult i64 %709, %707
  %712 = or i1 %710, %711
  %713 = zext i1 %712 to i8
  store i8 %713, i8* %42, align 1, !tbaa !2432
  %714 = trunc i64 %709 to i32
  %715 = and i32 %714, 255
  %716 = tail call i32 @llvm.ctpop.i32(i32 %715) #8
  %717 = trunc i32 %716 to i8
  %718 = and i8 %717, 1
  %719 = xor i8 %718, 1
  store i8 %719, i8* %49, align 1, !tbaa !2446
  %720 = xor i64 %707, %701
  %721 = xor i64 %720, %709
  %722 = lshr i64 %721, 4
  %723 = trunc i64 %722 to i8
  %724 = and i8 %723, 1
  store i8 %724, i8* %54, align 1, !tbaa !2447
  %725 = icmp eq i64 %709, 0
  %726 = zext i1 %725 to i8
  store i8 %726, i8* %57, align 1, !tbaa !2448
  %727 = lshr i64 %709, 63
  %728 = trunc i64 %727 to i8
  store i8 %728, i8* %60, align 1, !tbaa !2449
  %729 = lshr i64 %701, 63
  %730 = xor i64 %727, %729
  %731 = xor i64 %727, %708
  %732 = add nuw nsw i64 %730, %731
  %733 = icmp eq i64 %732, 2
  %734 = zext i1 %733 to i8
  store i8 %734, i8* %66, align 1, !tbaa !2450
  %735 = add i64 %685, -104
  %736 = add i64 %4752, 177
  store i64 %736, i64* %PC, align 8
  %737 = inttoptr i64 %735 to i32*
  %738 = load i32, i32* %737, align 4
  %739 = sext i32 %738 to i64
  store i64 %739, i64* %RCX, align 8, !tbaa !2428
  %740 = shl nsw i64 %739, 3
  %741 = add i64 %740, %709
  %742 = add i64 %4752, 182
  store i64 %742, i64* %PC, align 8
  %743 = inttoptr i64 %741 to double*
  store double %697, double* %743, align 8
  %744 = load i64, i64* %RBP, align 8
  %745 = add i64 %744, 88
  %746 = load i64, i64* %PC, align 8
  %747 = add i64 %746, 4
  store i64 %747, i64* %PC, align 8
  %748 = inttoptr i64 %745 to i64*
  %749 = load i64, i64* %748, align 8
  store i64 %749, i64* %RAX, align 8, !tbaa !2428
  %750 = add i64 %744, -104
  %751 = add i64 %746, 8
  store i64 %751, i64* %PC, align 8
  %752 = inttoptr i64 %750 to i32*
  %753 = load i32, i32* %752, align 4
  %754 = sext i32 %753 to i64
  store i64 %754, i64* %RCX, align 8, !tbaa !2428
  %755 = shl nsw i64 %754, 3
  %756 = add i64 %755, %749
  %757 = add i64 %746, 13
  store i64 %757, i64* %PC, align 8
  %758 = inttoptr i64 %756 to double*
  %759 = load double, double* %758, align 8
  store double %759, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %760 = add i64 %744, 96
  %761 = add i64 %746, 17
  store i64 %761, i64* %PC, align 8
  %762 = inttoptr i64 %760 to i64*
  %763 = load i64, i64* %762, align 8
  store i64 %763, i64* %RAX, align 8, !tbaa !2428
  %764 = add i64 %746, 21
  store i64 %764, i64* %PC, align 8
  %765 = load i32, i32* %752, align 4
  %766 = sext i32 %765 to i64
  store i64 %766, i64* %RCX, align 8, !tbaa !2428
  %767 = shl nsw i64 %766, 3
  %768 = add i64 %767, %763
  %769 = add i64 %746, 26
  store i64 %769, i64* %PC, align 8
  %770 = inttoptr i64 %768 to double*
  %771 = load double, double* %770, align 8
  %772 = fdiv double %759, %771
  store double %772, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %773 = add i64 %744, 24
  %774 = add i64 %746, 30
  store i64 %774, i64* %PC, align 8
  %775 = inttoptr i64 %773 to i64*
  %776 = load i64, i64* %775, align 8
  store i64 %776, i64* %RAX, align 8, !tbaa !2428
  %777 = add i64 %744, -100
  %778 = add i64 %746, 34
  store i64 %778, i64* %PC, align 8
  %779 = inttoptr i64 %777 to i32*
  %780 = load i32, i32* %779, align 4
  %781 = sext i32 %780 to i64
  %782 = mul nsw i64 %781, 33800
  store i64 %782, i64* %RCX, align 8, !tbaa !2428
  %783 = lshr i64 %782, 63
  %784 = add i64 %782, %776
  store i64 %784, i64* %RAX, align 8, !tbaa !2428
  %785 = icmp ult i64 %784, %776
  %786 = icmp ult i64 %784, %782
  %787 = or i1 %785, %786
  %788 = zext i1 %787 to i8
  store i8 %788, i8* %42, align 1, !tbaa !2432
  %789 = trunc i64 %784 to i32
  %790 = and i32 %789, 255
  %791 = tail call i32 @llvm.ctpop.i32(i32 %790) #8
  %792 = trunc i32 %791 to i8
  %793 = and i8 %792, 1
  %794 = xor i8 %793, 1
  store i8 %794, i8* %49, align 1, !tbaa !2446
  %795 = xor i64 %782, %776
  %796 = xor i64 %795, %784
  %797 = lshr i64 %796, 4
  %798 = trunc i64 %797 to i8
  %799 = and i8 %798, 1
  store i8 %799, i8* %54, align 1, !tbaa !2447
  %800 = icmp eq i64 %784, 0
  %801 = zext i1 %800 to i8
  store i8 %801, i8* %57, align 1, !tbaa !2448
  %802 = lshr i64 %784, 63
  %803 = trunc i64 %802 to i8
  store i8 %803, i8* %60, align 1, !tbaa !2449
  %804 = lshr i64 %776, 63
  %805 = xor i64 %802, %804
  %806 = xor i64 %802, %783
  %807 = add nuw nsw i64 %805, %806
  %808 = icmp eq i64 %807, 2
  %809 = zext i1 %808 to i8
  store i8 %809, i8* %66, align 1, !tbaa !2450
  %810 = load i64, i64* %RBP, align 8
  %811 = add i64 %810, -104
  %812 = add i64 %746, 48
  store i64 %812, i64* %PC, align 8
  %813 = inttoptr i64 %811 to i32*
  %814 = load i32, i32* %813, align 4
  %815 = sext i32 %814 to i64
  %816 = mul nsw i64 %815, 520
  store i64 %816, i64* %RCX, align 8, !tbaa !2428
  %817 = lshr i64 %816, 63
  %818 = add i64 %816, %784
  store i64 %818, i64* %RAX, align 8, !tbaa !2428
  %819 = icmp ult i64 %818, %784
  %820 = icmp ult i64 %818, %816
  %821 = or i1 %819, %820
  %822 = zext i1 %821 to i8
  store i8 %822, i8* %42, align 1, !tbaa !2432
  %823 = trunc i64 %818 to i32
  %824 = and i32 %823, 255
  %825 = tail call i32 @llvm.ctpop.i32(i32 %824) #8
  %826 = trunc i32 %825 to i8
  %827 = and i8 %826, 1
  %828 = xor i8 %827, 1
  store i8 %828, i8* %49, align 1, !tbaa !2446
  %829 = xor i64 %816, %784
  %830 = xor i64 %829, %818
  %831 = lshr i64 %830, 4
  %832 = trunc i64 %831 to i8
  %833 = and i8 %832, 1
  store i8 %833, i8* %54, align 1, !tbaa !2447
  %834 = icmp eq i64 %818, 0
  %835 = zext i1 %834 to i8
  store i8 %835, i8* %57, align 1, !tbaa !2448
  %836 = lshr i64 %818, 63
  %837 = trunc i64 %836 to i8
  store i8 %837, i8* %60, align 1, !tbaa !2449
  %838 = xor i64 %836, %802
  %839 = xor i64 %836, %817
  %840 = add nuw nsw i64 %838, %839
  %841 = icmp eq i64 %840, 2
  %842 = zext i1 %841 to i8
  store i8 %842, i8* %66, align 1, !tbaa !2450
  %843 = add i64 %810, -48
  %844 = add i64 %746, 62
  store i64 %844, i64* %PC, align 8
  %845 = inttoptr i64 %843 to i32*
  %846 = load i32, i32* %845, align 4
  %847 = sext i32 %846 to i64
  store i64 %847, i64* %RCX, align 8, !tbaa !2428
  %848 = shl nsw i64 %847, 3
  %849 = add i64 %848, %818
  %850 = add i64 %746, 67
  store i64 %850, i64* %PC, align 8
  %851 = load double, double* %228, align 1
  %852 = inttoptr i64 %849 to double*
  %853 = load double, double* %852, align 8
  %854 = fmul double %851, %853
  store double %854, double* %228, align 1, !tbaa !2452
  %855 = add i64 %810, -72
  %856 = add i64 %746, 72
  store i64 %856, i64* %PC, align 8
  %857 = inttoptr i64 %855 to double*
  %858 = load double, double* %857, align 8
  store double %858, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %859 = add i64 %810, 96
  %860 = add i64 %746, 76
  store i64 %860, i64* %PC, align 8
  %861 = inttoptr i64 %859 to i64*
  %862 = load i64, i64* %861, align 8
  store i64 %862, i64* %RAX, align 8, !tbaa !2428
  %863 = add i64 %746, 80
  store i64 %863, i64* %PC, align 8
  %864 = load i32, i32* %813, align 4
  %865 = sext i32 %864 to i64
  store i64 %865, i64* %RCX, align 8, !tbaa !2428
  %866 = shl nsw i64 %865, 3
  %867 = add i64 %866, %862
  %868 = add i64 %746, 85
  store i64 %868, i64* %PC, align 8
  %869 = inttoptr i64 %867 to double*
  %870 = load double, double* %869, align 8
  %871 = fdiv double %858, %870
  store double %871, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %872 = load i64, i64* %RBP, align 8
  %873 = add i64 %872, -96
  %874 = add i64 %746, 89
  store i64 %874, i64* %PC, align 8
  %875 = inttoptr i64 %873 to i64*
  %876 = load i64, i64* %875, align 8
  store i64 %876, i64* %RAX, align 8, !tbaa !2428
  %877 = add i64 %872, -100
  %878 = add i64 %746, 93
  store i64 %878, i64* %PC, align 8
  %879 = inttoptr i64 %877 to i32*
  %880 = load i32, i32* %879, align 4
  %881 = sext i32 %880 to i64
  %882 = mul nsw i64 %881, 520
  store i64 %882, i64* %RCX, align 8, !tbaa !2428
  %883 = lshr i64 %882, 63
  %884 = add i64 %882, %876
  store i64 %884, i64* %RAX, align 8, !tbaa !2428
  %885 = icmp ult i64 %884, %876
  %886 = icmp ult i64 %884, %882
  %887 = or i1 %885, %886
  %888 = zext i1 %887 to i8
  store i8 %888, i8* %42, align 1, !tbaa !2432
  %889 = trunc i64 %884 to i32
  %890 = and i32 %889, 255
  %891 = tail call i32 @llvm.ctpop.i32(i32 %890) #8
  %892 = trunc i32 %891 to i8
  %893 = and i8 %892, 1
  %894 = xor i8 %893, 1
  store i8 %894, i8* %49, align 1, !tbaa !2446
  %895 = xor i64 %882, %876
  %896 = xor i64 %895, %884
  %897 = lshr i64 %896, 4
  %898 = trunc i64 %897 to i8
  %899 = and i8 %898, 1
  store i8 %899, i8* %54, align 1, !tbaa !2447
  %900 = icmp eq i64 %884, 0
  %901 = zext i1 %900 to i8
  store i8 %901, i8* %57, align 1, !tbaa !2448
  %902 = lshr i64 %884, 63
  %903 = trunc i64 %902 to i8
  store i8 %903, i8* %60, align 1, !tbaa !2449
  %904 = lshr i64 %876, 63
  %905 = xor i64 %902, %904
  %906 = xor i64 %902, %883
  %907 = add nuw nsw i64 %905, %906
  %908 = icmp eq i64 %907, 2
  %909 = zext i1 %908 to i8
  store i8 %909, i8* %66, align 1, !tbaa !2450
  %910 = add i64 %872, -104
  %911 = add i64 %746, 107
  store i64 %911, i64* %PC, align 8
  %912 = inttoptr i64 %910 to i32*
  %913 = load i32, i32* %912, align 4
  %914 = sext i32 %913 to i64
  store i64 %914, i64* %RCX, align 8, !tbaa !2428
  %915 = shl nsw i64 %914, 3
  %916 = add i64 %915, %884
  %917 = add i64 %746, 112
  store i64 %917, i64* %PC, align 8
  %918 = inttoptr i64 %916 to double*
  %919 = load double, double* %918, align 8
  %920 = fmul double %871, %919
  store double %920, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %921 = load double, double* %228, align 1
  %922 = fsub double %921, %920
  store double %922, double* %228, align 1, !tbaa !2452
  %923 = add i64 %872, 16
  %924 = add i64 %746, 120
  store i64 %924, i64* %PC, align 8
  %925 = inttoptr i64 %923 to i64*
  %926 = load i64, i64* %925, align 8
  store i64 %926, i64* %RAX, align 8, !tbaa !2428
  %927 = load i64, i64* %RBP, align 8
  %928 = add i64 %927, -100
  %929 = add i64 %746, 124
  store i64 %929, i64* %PC, align 8
  %930 = inttoptr i64 %928 to i32*
  %931 = load i32, i32* %930, align 4
  %932 = sext i32 %931 to i64
  %933 = mul nsw i64 %932, 520
  store i64 %933, i64* %RCX, align 8, !tbaa !2428
  %934 = lshr i64 %933, 63
  %935 = add i64 %933, %926
  store i64 %935, i64* %RAX, align 8, !tbaa !2428
  %936 = icmp ult i64 %935, %926
  %937 = icmp ult i64 %935, %933
  %938 = or i1 %936, %937
  %939 = zext i1 %938 to i8
  store i8 %939, i8* %42, align 1, !tbaa !2432
  %940 = trunc i64 %935 to i32
  %941 = and i32 %940, 255
  %942 = tail call i32 @llvm.ctpop.i32(i32 %941) #8
  %943 = trunc i32 %942 to i8
  %944 = and i8 %943, 1
  %945 = xor i8 %944, 1
  store i8 %945, i8* %49, align 1, !tbaa !2446
  %946 = xor i64 %933, %926
  %947 = xor i64 %946, %935
  %948 = lshr i64 %947, 4
  %949 = trunc i64 %948 to i8
  %950 = and i8 %949, 1
  store i8 %950, i8* %54, align 1, !tbaa !2447
  %951 = icmp eq i64 %935, 0
  %952 = zext i1 %951 to i8
  store i8 %952, i8* %57, align 1, !tbaa !2448
  %953 = lshr i64 %935, 63
  %954 = trunc i64 %953 to i8
  store i8 %954, i8* %60, align 1, !tbaa !2449
  %955 = lshr i64 %926, 63
  %956 = xor i64 %953, %955
  %957 = xor i64 %953, %934
  %958 = add nuw nsw i64 %956, %957
  %959 = icmp eq i64 %958, 2
  %960 = zext i1 %959 to i8
  store i8 %960, i8* %66, align 1, !tbaa !2450
  %961 = add i64 %927, -104
  %962 = add i64 %746, 138
  store i64 %962, i64* %PC, align 8
  %963 = inttoptr i64 %961 to i32*
  %964 = load i32, i32* %963, align 4
  %965 = sext i32 %964 to i64
  store i64 %965, i64* %RCX, align 8, !tbaa !2428
  %966 = shl nsw i64 %965, 3
  %967 = add i64 %966, %935
  %968 = add i64 %746, 143
  store i64 %968, i64* %PC, align 8
  %969 = inttoptr i64 %967 to double*
  store double %922, double* %969, align 8
  %970 = load i64, i64* %RBP, align 8
  %971 = add i64 %970, 72
  %972 = load i64, i64* %PC, align 8
  %973 = add i64 %972, 4
  store i64 %973, i64* %PC, align 8
  %974 = inttoptr i64 %971 to i64*
  %975 = load i64, i64* %974, align 8
  store i64 %975, i64* %RAX, align 8, !tbaa !2428
  %976 = add i64 %970, -48
  %977 = add i64 %972, 8
  store i64 %977, i64* %PC, align 8
  %978 = inttoptr i64 %976 to i32*
  %979 = load i32, i32* %978, align 4
  %980 = sext i32 %979 to i64
  store i64 %980, i64* %RCX, align 8, !tbaa !2428
  %981 = shl nsw i64 %980, 3
  %982 = add i64 %981, %975
  %983 = add i64 %972, 13
  store i64 %983, i64* %PC, align 8
  %984 = inttoptr i64 %982 to double*
  %985 = load double, double* %984, align 8
  store double %985, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %986 = add i64 %970, 80
  %987 = add i64 %972, 17
  store i64 %987, i64* %PC, align 8
  %988 = inttoptr i64 %986 to i64*
  %989 = load i64, i64* %988, align 8
  store i64 %989, i64* %RAX, align 8, !tbaa !2428
  %990 = add i64 %972, 21
  store i64 %990, i64* %PC, align 8
  %991 = load i32, i32* %978, align 4
  %992 = sext i32 %991 to i64
  store i64 %992, i64* %RCX, align 8, !tbaa !2428
  %993 = shl nsw i64 %992, 3
  %994 = add i64 %993, %989
  %995 = add i64 %972, 26
  store i64 %995, i64* %PC, align 8
  %996 = inttoptr i64 %994 to double*
  %997 = load double, double* %996, align 8
  %998 = fdiv double %985, %997
  store double %998, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %999 = add i64 %970, 48
  %1000 = add i64 %972, 30
  store i64 %1000, i64* %PC, align 8
  %1001 = inttoptr i64 %999 to i64*
  %1002 = load i64, i64* %1001, align 8
  store i64 %1002, i64* %RAX, align 8, !tbaa !2428
  %1003 = add i64 %970, -100
  %1004 = add i64 %972, 34
  store i64 %1004, i64* %PC, align 8
  %1005 = inttoptr i64 %1003 to i32*
  %1006 = load i32, i32* %1005, align 4
  %1007 = sext i32 %1006 to i64
  %1008 = mul nsw i64 %1007, 33800
  store i64 %1008, i64* %RCX, align 8, !tbaa !2428
  %1009 = lshr i64 %1008, 63
  %1010 = add i64 %1008, %1002
  store i64 %1010, i64* %RAX, align 8, !tbaa !2428
  %1011 = icmp ult i64 %1010, %1002
  %1012 = icmp ult i64 %1010, %1008
  %1013 = or i1 %1011, %1012
  %1014 = zext i1 %1013 to i8
  store i8 %1014, i8* %42, align 1, !tbaa !2432
  %1015 = trunc i64 %1010 to i32
  %1016 = and i32 %1015, 255
  %1017 = tail call i32 @llvm.ctpop.i32(i32 %1016) #8
  %1018 = trunc i32 %1017 to i8
  %1019 = and i8 %1018, 1
  %1020 = xor i8 %1019, 1
  store i8 %1020, i8* %49, align 1, !tbaa !2446
  %1021 = xor i64 %1008, %1002
  %1022 = xor i64 %1021, %1010
  %1023 = lshr i64 %1022, 4
  %1024 = trunc i64 %1023 to i8
  %1025 = and i8 %1024, 1
  store i8 %1025, i8* %54, align 1, !tbaa !2447
  %1026 = icmp eq i64 %1010, 0
  %1027 = zext i1 %1026 to i8
  store i8 %1027, i8* %57, align 1, !tbaa !2448
  %1028 = lshr i64 %1010, 63
  %1029 = trunc i64 %1028 to i8
  store i8 %1029, i8* %60, align 1, !tbaa !2449
  %1030 = lshr i64 %1002, 63
  %1031 = xor i64 %1028, %1030
  %1032 = xor i64 %1028, %1009
  %1033 = add nuw nsw i64 %1031, %1032
  %1034 = icmp eq i64 %1033, 2
  %1035 = zext i1 %1034 to i8
  store i8 %1035, i8* %66, align 1, !tbaa !2450
  %1036 = load i64, i64* %RBP, align 8
  %1037 = add i64 %1036, -104
  %1038 = add i64 %972, 48
  store i64 %1038, i64* %PC, align 8
  %1039 = inttoptr i64 %1037 to i32*
  %1040 = load i32, i32* %1039, align 4
  %1041 = sext i32 %1040 to i64
  %1042 = mul nsw i64 %1041, 520
  store i64 %1042, i64* %RCX, align 8, !tbaa !2428
  %1043 = lshr i64 %1042, 63
  %1044 = add i64 %1042, %1010
  store i64 %1044, i64* %RAX, align 8, !tbaa !2428
  %1045 = icmp ult i64 %1044, %1010
  %1046 = icmp ult i64 %1044, %1042
  %1047 = or i1 %1045, %1046
  %1048 = zext i1 %1047 to i8
  store i8 %1048, i8* %42, align 1, !tbaa !2432
  %1049 = trunc i64 %1044 to i32
  %1050 = and i32 %1049, 255
  %1051 = tail call i32 @llvm.ctpop.i32(i32 %1050) #8
  %1052 = trunc i32 %1051 to i8
  %1053 = and i8 %1052, 1
  %1054 = xor i8 %1053, 1
  store i8 %1054, i8* %49, align 1, !tbaa !2446
  %1055 = xor i64 %1042, %1010
  %1056 = xor i64 %1055, %1044
  %1057 = lshr i64 %1056, 4
  %1058 = trunc i64 %1057 to i8
  %1059 = and i8 %1058, 1
  store i8 %1059, i8* %54, align 1, !tbaa !2447
  %1060 = icmp eq i64 %1044, 0
  %1061 = zext i1 %1060 to i8
  store i8 %1061, i8* %57, align 1, !tbaa !2448
  %1062 = lshr i64 %1044, 63
  %1063 = trunc i64 %1062 to i8
  store i8 %1063, i8* %60, align 1, !tbaa !2449
  %1064 = xor i64 %1062, %1028
  %1065 = xor i64 %1062, %1043
  %1066 = add nuw nsw i64 %1064, %1065
  %1067 = icmp eq i64 %1066, 2
  %1068 = zext i1 %1067 to i8
  store i8 %1068, i8* %66, align 1, !tbaa !2450
  %1069 = add i64 %1036, -48
  %1070 = add i64 %972, 62
  store i64 %1070, i64* %PC, align 8
  %1071 = inttoptr i64 %1069 to i32*
  %1072 = load i32, i32* %1071, align 4
  %1073 = sext i32 %1072 to i64
  store i64 %1073, i64* %RCX, align 8, !tbaa !2428
  %1074 = shl nsw i64 %1073, 3
  %1075 = add i64 %1074, %1044
  %1076 = add i64 %972, 67
  store i64 %1076, i64* %PC, align 8
  %1077 = load double, double* %228, align 1
  %1078 = inttoptr i64 %1075 to double*
  %1079 = load double, double* %1078, align 8
  %1080 = fmul double %1077, %1079
  store double %1080, double* %228, align 1, !tbaa !2452
  %1081 = add i64 %1036, -64
  %1082 = add i64 %972, 72
  store i64 %1082, i64* %PC, align 8
  %1083 = inttoptr i64 %1081 to double*
  %1084 = load double, double* %1083, align 8
  store double %1084, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %1085 = add i64 %1036, 64
  %1086 = add i64 %972, 76
  store i64 %1086, i64* %PC, align 8
  %1087 = inttoptr i64 %1085 to i64*
  %1088 = load i64, i64* %1087, align 8
  store i64 %1088, i64* %RAX, align 8, !tbaa !2428
  %1089 = add i64 %1036, -100
  %1090 = add i64 %972, 80
  store i64 %1090, i64* %PC, align 8
  %1091 = inttoptr i64 %1089 to i32*
  %1092 = load i32, i32* %1091, align 4
  %1093 = sext i32 %1092 to i64
  store i64 %1093, i64* %RCX, align 8, !tbaa !2428
  %1094 = shl nsw i64 %1093, 3
  %1095 = add i64 %1094, %1088
  %1096 = add i64 %972, 85
  store i64 %1096, i64* %PC, align 8
  %1097 = inttoptr i64 %1095 to double*
  %1098 = load double, double* %1097, align 8
  %1099 = fmul double %1084, %1098
  store double %1099, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %1100 = load i64, i64* %RBP, align 8
  %1101 = add i64 %1100, 80
  %1102 = add i64 %972, 89
  store i64 %1102, i64* %PC, align 8
  %1103 = inttoptr i64 %1101 to i64*
  %1104 = load i64, i64* %1103, align 8
  store i64 %1104, i64* %RAX, align 8, !tbaa !2428
  %1105 = add i64 %1100, -48
  %1106 = add i64 %972, 93
  store i64 %1106, i64* %PC, align 8
  %1107 = inttoptr i64 %1105 to i32*
  %1108 = load i32, i32* %1107, align 4
  %1109 = sext i32 %1108 to i64
  store i64 %1109, i64* %RCX, align 8, !tbaa !2428
  %1110 = shl nsw i64 %1109, 3
  %1111 = add i64 %1110, %1104
  %1112 = add i64 %972, 98
  store i64 %1112, i64* %PC, align 8
  %1113 = inttoptr i64 %1111 to double*
  %1114 = load double, double* %1113, align 8
  %1115 = fdiv double %1099, %1114
  store double %1115, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %1116 = add i64 %1100, 16
  %1117 = add i64 %972, 102
  store i64 %1117, i64* %PC, align 8
  %1118 = inttoptr i64 %1116 to i64*
  %1119 = load i64, i64* %1118, align 8
  store i64 %1119, i64* %RAX, align 8, !tbaa !2428
  %1120 = add i64 %1100, -100
  %1121 = add i64 %972, 106
  store i64 %1121, i64* %PC, align 8
  %1122 = inttoptr i64 %1120 to i32*
  %1123 = load i32, i32* %1122, align 4
  %1124 = sext i32 %1123 to i64
  %1125 = mul nsw i64 %1124, 520
  store i64 %1125, i64* %RCX, align 8, !tbaa !2428
  %1126 = lshr i64 %1125, 63
  %1127 = add i64 %1125, %1119
  store i64 %1127, i64* %RAX, align 8, !tbaa !2428
  %1128 = icmp ult i64 %1127, %1119
  %1129 = icmp ult i64 %1127, %1125
  %1130 = or i1 %1128, %1129
  %1131 = zext i1 %1130 to i8
  store i8 %1131, i8* %42, align 1, !tbaa !2432
  %1132 = trunc i64 %1127 to i32
  %1133 = and i32 %1132, 255
  %1134 = tail call i32 @llvm.ctpop.i32(i32 %1133) #8
  %1135 = trunc i32 %1134 to i8
  %1136 = and i8 %1135, 1
  %1137 = xor i8 %1136, 1
  store i8 %1137, i8* %49, align 1, !tbaa !2446
  %1138 = xor i64 %1125, %1119
  %1139 = xor i64 %1138, %1127
  %1140 = lshr i64 %1139, 4
  %1141 = trunc i64 %1140 to i8
  %1142 = and i8 %1141, 1
  store i8 %1142, i8* %54, align 1, !tbaa !2447
  %1143 = icmp eq i64 %1127, 0
  %1144 = zext i1 %1143 to i8
  store i8 %1144, i8* %57, align 1, !tbaa !2448
  %1145 = lshr i64 %1127, 63
  %1146 = trunc i64 %1145 to i8
  store i8 %1146, i8* %60, align 1, !tbaa !2449
  %1147 = lshr i64 %1119, 63
  %1148 = xor i64 %1145, %1147
  %1149 = xor i64 %1145, %1126
  %1150 = add nuw nsw i64 %1148, %1149
  %1151 = icmp eq i64 %1150, 2
  %1152 = zext i1 %1151 to i8
  store i8 %1152, i8* %66, align 1, !tbaa !2450
  %1153 = add i64 %1100, -104
  %1154 = add i64 %972, 120
  store i64 %1154, i64* %PC, align 8
  %1155 = inttoptr i64 %1153 to i32*
  %1156 = load i32, i32* %1155, align 4
  %1157 = sext i32 %1156 to i64
  store i64 %1157, i64* %RCX, align 8, !tbaa !2428
  %1158 = shl nsw i64 %1157, 3
  %1159 = add i64 %1158, %1127
  %1160 = add i64 %972, 125
  store i64 %1160, i64* %PC, align 8
  %1161 = inttoptr i64 %1159 to double*
  %1162 = load double, double* %1161, align 8
  %1163 = fmul double %1115, %1162
  store double %1163, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %1164 = load double, double* %228, align 1
  %1165 = fadd double %1164, %1163
  store double %1165, double* %228, align 1, !tbaa !2452
  %1166 = load i64, i64* %RBP, align 8
  %1167 = add i64 %1166, -64
  %1168 = add i64 %972, 134
  store i64 %1168, i64* %PC, align 8
  %1169 = inttoptr i64 %1167 to double*
  %1170 = load double, double* %1169, align 8
  store double %1170, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %1171 = add i64 %1166, 56
  %1172 = add i64 %972, 138
  store i64 %1172, i64* %PC, align 8
  %1173 = inttoptr i64 %1171 to i64*
  %1174 = load i64, i64* %1173, align 8
  store i64 %1174, i64* %RAX, align 8, !tbaa !2428
  %1175 = add i64 %1166, -100
  %1176 = add i64 %972, 142
  store i64 %1176, i64* %PC, align 8
  %1177 = inttoptr i64 %1175 to i32*
  %1178 = load i32, i32* %1177, align 4
  %1179 = sext i32 %1178 to i64
  store i64 %1179, i64* %RCX, align 8, !tbaa !2428
  %1180 = shl nsw i64 %1179, 3
  %1181 = add i64 %1180, %1174
  %1182 = add i64 %972, 147
  store i64 %1182, i64* %PC, align 8
  %1183 = inttoptr i64 %1181 to double*
  %1184 = load double, double* %1183, align 8
  %1185 = fmul double %1170, %1184
  store double %1185, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %1186 = add i64 %1166, 80
  %1187 = add i64 %972, 151
  store i64 %1187, i64* %PC, align 8
  %1188 = inttoptr i64 %1186 to i64*
  %1189 = load i64, i64* %1188, align 8
  store i64 %1189, i64* %RAX, align 8, !tbaa !2428
  %1190 = add i64 %1166, -48
  %1191 = add i64 %972, 155
  store i64 %1191, i64* %PC, align 8
  %1192 = inttoptr i64 %1190 to i32*
  %1193 = load i32, i32* %1192, align 4
  %1194 = sext i32 %1193 to i64
  store i64 %1194, i64* %RCX, align 8, !tbaa !2428
  %1195 = shl nsw i64 %1194, 3
  %1196 = add i64 %1195, %1189
  %1197 = add i64 %972, 160
  store i64 %1197, i64* %PC, align 8
  %1198 = inttoptr i64 %1196 to double*
  %1199 = load double, double* %1198, align 8
  %1200 = fdiv double %1185, %1199
  store double %1200, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %1201 = add i64 %1166, 24
  %1202 = add i64 %972, 164
  store i64 %1202, i64* %PC, align 8
  %1203 = inttoptr i64 %1201 to i64*
  %1204 = load i64, i64* %1203, align 8
  store i64 %1204, i64* %RAX, align 8, !tbaa !2428
  %1205 = add i64 %972, 168
  store i64 %1205, i64* %PC, align 8
  %1206 = load i32, i32* %1177, align 4
  %1207 = sext i32 %1206 to i64
  %1208 = mul nsw i64 %1207, 33800
  store i64 %1208, i64* %RCX, align 8, !tbaa !2428
  %1209 = lshr i64 %1208, 63
  %1210 = add i64 %1208, %1204
  store i64 %1210, i64* %RAX, align 8, !tbaa !2428
  %1211 = icmp ult i64 %1210, %1204
  %1212 = icmp ult i64 %1210, %1208
  %1213 = or i1 %1211, %1212
  %1214 = zext i1 %1213 to i8
  store i8 %1214, i8* %42, align 1, !tbaa !2432
  %1215 = trunc i64 %1210 to i32
  %1216 = and i32 %1215, 255
  %1217 = tail call i32 @llvm.ctpop.i32(i32 %1216) #8
  %1218 = trunc i32 %1217 to i8
  %1219 = and i8 %1218, 1
  %1220 = xor i8 %1219, 1
  store i8 %1220, i8* %49, align 1, !tbaa !2446
  %1221 = xor i64 %1208, %1204
  %1222 = xor i64 %1221, %1210
  %1223 = lshr i64 %1222, 4
  %1224 = trunc i64 %1223 to i8
  %1225 = and i8 %1224, 1
  store i8 %1225, i8* %54, align 1, !tbaa !2447
  %1226 = icmp eq i64 %1210, 0
  %1227 = zext i1 %1226 to i8
  store i8 %1227, i8* %57, align 1, !tbaa !2448
  %1228 = lshr i64 %1210, 63
  %1229 = trunc i64 %1228 to i8
  store i8 %1229, i8* %60, align 1, !tbaa !2449
  %1230 = lshr i64 %1204, 63
  %1231 = xor i64 %1228, %1230
  %1232 = xor i64 %1228, %1209
  %1233 = add nuw nsw i64 %1231, %1232
  %1234 = icmp eq i64 %1233, 2
  %1235 = zext i1 %1234 to i8
  store i8 %1235, i8* %66, align 1, !tbaa !2450
  %1236 = load i64, i64* %RBP, align 8
  %1237 = add i64 %1236, -104
  %1238 = add i64 %972, 182
  store i64 %1238, i64* %PC, align 8
  %1239 = inttoptr i64 %1237 to i32*
  %1240 = load i32, i32* %1239, align 4
  %1241 = sext i32 %1240 to i64
  %1242 = mul nsw i64 %1241, 520
  store i64 %1242, i64* %RCX, align 8, !tbaa !2428
  %1243 = lshr i64 %1242, 63
  %1244 = add i64 %1242, %1210
  store i64 %1244, i64* %RAX, align 8, !tbaa !2428
  %1245 = icmp ult i64 %1244, %1210
  %1246 = icmp ult i64 %1244, %1242
  %1247 = or i1 %1245, %1246
  %1248 = zext i1 %1247 to i8
  store i8 %1248, i8* %42, align 1, !tbaa !2432
  %1249 = trunc i64 %1244 to i32
  %1250 = and i32 %1249, 255
  %1251 = tail call i32 @llvm.ctpop.i32(i32 %1250) #8
  %1252 = trunc i32 %1251 to i8
  %1253 = and i8 %1252, 1
  %1254 = xor i8 %1253, 1
  store i8 %1254, i8* %49, align 1, !tbaa !2446
  %1255 = xor i64 %1242, %1210
  %1256 = xor i64 %1255, %1244
  %1257 = lshr i64 %1256, 4
  %1258 = trunc i64 %1257 to i8
  %1259 = and i8 %1258, 1
  store i8 %1259, i8* %54, align 1, !tbaa !2447
  %1260 = icmp eq i64 %1244, 0
  %1261 = zext i1 %1260 to i8
  store i8 %1261, i8* %57, align 1, !tbaa !2448
  %1262 = lshr i64 %1244, 63
  %1263 = trunc i64 %1262 to i8
  store i8 %1263, i8* %60, align 1, !tbaa !2449
  %1264 = xor i64 %1262, %1228
  %1265 = xor i64 %1262, %1243
  %1266 = add nuw nsw i64 %1264, %1265
  %1267 = icmp eq i64 %1266, 2
  %1268 = zext i1 %1267 to i8
  store i8 %1268, i8* %66, align 1, !tbaa !2450
  %1269 = add i64 %1236, -48
  %1270 = add i64 %972, 196
  store i64 %1270, i64* %PC, align 8
  %1271 = inttoptr i64 %1269 to i32*
  %1272 = load i32, i32* %1271, align 4
  %1273 = sext i32 %1272 to i64
  store i64 %1273, i64* %RCX, align 8, !tbaa !2428
  %1274 = shl nsw i64 %1273, 3
  %1275 = add i64 %1274, %1244
  %1276 = add i64 %972, 201
  store i64 %1276, i64* %PC, align 8
  %1277 = load double, double* %231, align 1
  %1278 = inttoptr i64 %1275 to double*
  %1279 = load double, double* %1278, align 8
  %1280 = fmul double %1277, %1279
  store double %1280, double* %231, align 1, !tbaa !2452
  %1281 = load double, double* %228, align 1
  %1282 = fsub double %1281, %1280
  store double %1282, double* %228, align 1, !tbaa !2452
  %1283 = add i64 %1236, 48
  %1284 = add i64 %972, 209
  store i64 %1284, i64* %PC, align 8
  %1285 = inttoptr i64 %1283 to i64*
  %1286 = load i64, i64* %1285, align 8
  store i64 %1286, i64* %RAX, align 8, !tbaa !2428
  %1287 = add i64 %1236, -100
  %1288 = add i64 %972, 213
  store i64 %1288, i64* %PC, align 8
  %1289 = inttoptr i64 %1287 to i32*
  %1290 = load i32, i32* %1289, align 4
  %1291 = sext i32 %1290 to i64
  %1292 = mul nsw i64 %1291, 33800
  store i64 %1292, i64* %RCX, align 8, !tbaa !2428
  %1293 = lshr i64 %1292, 63
  %1294 = add i64 %1292, %1286
  store i64 %1294, i64* %RAX, align 8, !tbaa !2428
  %1295 = icmp ult i64 %1294, %1286
  %1296 = icmp ult i64 %1294, %1292
  %1297 = or i1 %1295, %1296
  %1298 = zext i1 %1297 to i8
  store i8 %1298, i8* %42, align 1, !tbaa !2432
  %1299 = trunc i64 %1294 to i32
  %1300 = and i32 %1299, 255
  %1301 = tail call i32 @llvm.ctpop.i32(i32 %1300) #8
  %1302 = trunc i32 %1301 to i8
  %1303 = and i8 %1302, 1
  %1304 = xor i8 %1303, 1
  store i8 %1304, i8* %49, align 1, !tbaa !2446
  %1305 = xor i64 %1292, %1286
  %1306 = xor i64 %1305, %1294
  %1307 = lshr i64 %1306, 4
  %1308 = trunc i64 %1307 to i8
  %1309 = and i8 %1308, 1
  store i8 %1309, i8* %54, align 1, !tbaa !2447
  %1310 = icmp eq i64 %1294, 0
  %1311 = zext i1 %1310 to i8
  store i8 %1311, i8* %57, align 1, !tbaa !2448
  %1312 = lshr i64 %1294, 63
  %1313 = trunc i64 %1312 to i8
  store i8 %1313, i8* %60, align 1, !tbaa !2449
  %1314 = lshr i64 %1286, 63
  %1315 = xor i64 %1312, %1314
  %1316 = xor i64 %1312, %1293
  %1317 = add nuw nsw i64 %1315, %1316
  %1318 = icmp eq i64 %1317, 2
  %1319 = zext i1 %1318 to i8
  store i8 %1319, i8* %66, align 1, !tbaa !2450
  %1320 = load i64, i64* %RBP, align 8
  %1321 = add i64 %1320, -104
  %1322 = add i64 %972, 227
  store i64 %1322, i64* %PC, align 8
  %1323 = inttoptr i64 %1321 to i32*
  %1324 = load i32, i32* %1323, align 4
  %1325 = sext i32 %1324 to i64
  %1326 = mul nsw i64 %1325, 520
  store i64 %1326, i64* %RCX, align 8, !tbaa !2428
  %1327 = lshr i64 %1326, 63
  %1328 = add i64 %1326, %1294
  store i64 %1328, i64* %RAX, align 8, !tbaa !2428
  %1329 = icmp ult i64 %1328, %1294
  %1330 = icmp ult i64 %1328, %1326
  %1331 = or i1 %1329, %1330
  %1332 = zext i1 %1331 to i8
  store i8 %1332, i8* %42, align 1, !tbaa !2432
  %1333 = trunc i64 %1328 to i32
  %1334 = and i32 %1333, 255
  %1335 = tail call i32 @llvm.ctpop.i32(i32 %1334) #8
  %1336 = trunc i32 %1335 to i8
  %1337 = and i8 %1336, 1
  %1338 = xor i8 %1337, 1
  store i8 %1338, i8* %49, align 1, !tbaa !2446
  %1339 = xor i64 %1326, %1294
  %1340 = xor i64 %1339, %1328
  %1341 = lshr i64 %1340, 4
  %1342 = trunc i64 %1341 to i8
  %1343 = and i8 %1342, 1
  store i8 %1343, i8* %54, align 1, !tbaa !2447
  %1344 = icmp eq i64 %1328, 0
  %1345 = zext i1 %1344 to i8
  store i8 %1345, i8* %57, align 1, !tbaa !2448
  %1346 = lshr i64 %1328, 63
  %1347 = trunc i64 %1346 to i8
  store i8 %1347, i8* %60, align 1, !tbaa !2449
  %1348 = xor i64 %1346, %1312
  %1349 = xor i64 %1346, %1327
  %1350 = add nuw nsw i64 %1348, %1349
  %1351 = icmp eq i64 %1350, 2
  %1352 = zext i1 %1351 to i8
  store i8 %1352, i8* %66, align 1, !tbaa !2450
  %1353 = add i64 %1320, -48
  %1354 = add i64 %972, 241
  store i64 %1354, i64* %PC, align 8
  %1355 = inttoptr i64 %1353 to i32*
  %1356 = load i32, i32* %1355, align 4
  %1357 = sext i32 %1356 to i64
  store i64 %1357, i64* %RCX, align 8, !tbaa !2428
  %1358 = shl nsw i64 %1357, 3
  %1359 = add i64 %1358, %1328
  %1360 = add i64 %972, 246
  store i64 %1360, i64* %PC, align 8
  %1361 = load i64, i64* %147, align 1
  %1362 = inttoptr i64 %1359 to i64*
  store i64 %1361, i64* %1362, align 8
  %1363 = load i64, i64* %RBP, align 8
  %1364 = add i64 %1363, 16
  %1365 = load i64, i64* %PC, align 8
  %1366 = add i64 %1365, 4
  store i64 %1366, i64* %PC, align 8
  %1367 = inttoptr i64 %1364 to i64*
  %1368 = load i64, i64* %1367, align 8
  store i64 %1368, i64* %RAX, align 8, !tbaa !2428
  %1369 = add i64 %1363, -100
  %1370 = add i64 %1365, 8
  store i64 %1370, i64* %PC, align 8
  %1371 = inttoptr i64 %1369 to i32*
  %1372 = load i32, i32* %1371, align 4
  %1373 = sext i32 %1372 to i64
  %1374 = mul nsw i64 %1373, 520
  store i64 %1374, i64* %RCX, align 8, !tbaa !2428
  %1375 = lshr i64 %1374, 63
  %1376 = add i64 %1374, %1368
  store i64 %1376, i64* %RAX, align 8, !tbaa !2428
  %1377 = icmp ult i64 %1376, %1368
  %1378 = icmp ult i64 %1376, %1374
  %1379 = or i1 %1377, %1378
  %1380 = zext i1 %1379 to i8
  store i8 %1380, i8* %42, align 1, !tbaa !2432
  %1381 = trunc i64 %1376 to i32
  %1382 = and i32 %1381, 255
  %1383 = tail call i32 @llvm.ctpop.i32(i32 %1382) #8
  %1384 = trunc i32 %1383 to i8
  %1385 = and i8 %1384, 1
  %1386 = xor i8 %1385, 1
  store i8 %1386, i8* %49, align 1, !tbaa !2446
  %1387 = xor i64 %1374, %1368
  %1388 = xor i64 %1387, %1376
  %1389 = lshr i64 %1388, 4
  %1390 = trunc i64 %1389 to i8
  %1391 = and i8 %1390, 1
  store i8 %1391, i8* %54, align 1, !tbaa !2447
  %1392 = icmp eq i64 %1376, 0
  %1393 = zext i1 %1392 to i8
  store i8 %1393, i8* %57, align 1, !tbaa !2448
  %1394 = lshr i64 %1376, 63
  %1395 = trunc i64 %1394 to i8
  store i8 %1395, i8* %60, align 1, !tbaa !2449
  %1396 = lshr i64 %1368, 63
  %1397 = xor i64 %1394, %1396
  %1398 = xor i64 %1394, %1375
  %1399 = add nuw nsw i64 %1397, %1398
  %1400 = icmp eq i64 %1399, 2
  %1401 = zext i1 %1400 to i8
  store i8 %1401, i8* %66, align 1, !tbaa !2450
  %1402 = add i64 %1363, -104
  %1403 = add i64 %1365, 22
  store i64 %1403, i64* %PC, align 8
  %1404 = inttoptr i64 %1402 to i32*
  %1405 = load i32, i32* %1404, align 4
  %1406 = sext i32 %1405 to i64
  store i64 %1406, i64* %RCX, align 8, !tbaa !2428
  %1407 = shl nsw i64 %1406, 3
  %1408 = add i64 %1407, %1376
  %1409 = add i64 %1365, 27
  store i64 %1409, i64* %PC, align 8
  %1410 = inttoptr i64 %1408 to i64*
  %1411 = load i64, i64* %1410, align 8
  store i64 %1411, i64* %147, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %1412 = add i64 %1363, 24
  %1413 = add i64 %1365, 31
  store i64 %1413, i64* %PC, align 8
  %1414 = inttoptr i64 %1412 to i64*
  %1415 = load i64, i64* %1414, align 8
  store i64 %1415, i64* %RAX, align 8, !tbaa !2428
  %1416 = add i64 %1365, 35
  store i64 %1416, i64* %PC, align 8
  %1417 = load i32, i32* %1371, align 4
  %1418 = sext i32 %1417 to i64
  %1419 = mul nsw i64 %1418, 33800
  store i64 %1419, i64* %RCX, align 8, !tbaa !2428
  %1420 = lshr i64 %1419, 63
  %1421 = add i64 %1419, %1415
  store i64 %1421, i64* %RAX, align 8, !tbaa !2428
  %1422 = icmp ult i64 %1421, %1415
  %1423 = icmp ult i64 %1421, %1419
  %1424 = or i1 %1422, %1423
  %1425 = zext i1 %1424 to i8
  store i8 %1425, i8* %42, align 1, !tbaa !2432
  %1426 = trunc i64 %1421 to i32
  %1427 = and i32 %1426, 255
  %1428 = tail call i32 @llvm.ctpop.i32(i32 %1427) #8
  %1429 = trunc i32 %1428 to i8
  %1430 = and i8 %1429, 1
  %1431 = xor i8 %1430, 1
  store i8 %1431, i8* %49, align 1, !tbaa !2446
  %1432 = xor i64 %1419, %1415
  %1433 = xor i64 %1432, %1421
  %1434 = lshr i64 %1433, 4
  %1435 = trunc i64 %1434 to i8
  %1436 = and i8 %1435, 1
  store i8 %1436, i8* %54, align 1, !tbaa !2447
  %1437 = icmp eq i64 %1421, 0
  %1438 = zext i1 %1437 to i8
  store i8 %1438, i8* %57, align 1, !tbaa !2448
  %1439 = lshr i64 %1421, 63
  %1440 = trunc i64 %1439 to i8
  store i8 %1440, i8* %60, align 1, !tbaa !2449
  %1441 = lshr i64 %1415, 63
  %1442 = xor i64 %1439, %1441
  %1443 = xor i64 %1439, %1420
  %1444 = add nuw nsw i64 %1442, %1443
  %1445 = icmp eq i64 %1444, 2
  %1446 = zext i1 %1445 to i8
  store i8 %1446, i8* %66, align 1, !tbaa !2450
  %1447 = load i64, i64* %RBP, align 8
  %1448 = add i64 %1447, -104
  %1449 = add i64 %1365, 49
  store i64 %1449, i64* %PC, align 8
  %1450 = inttoptr i64 %1448 to i32*
  %1451 = load i32, i32* %1450, align 4
  %1452 = sext i32 %1451 to i64
  %1453 = mul nsw i64 %1452, 520
  store i64 %1453, i64* %RCX, align 8, !tbaa !2428
  %1454 = lshr i64 %1453, 63
  %1455 = add i64 %1453, %1421
  store i64 %1455, i64* %RAX, align 8, !tbaa !2428
  %1456 = icmp ult i64 %1455, %1421
  %1457 = icmp ult i64 %1455, %1453
  %1458 = or i1 %1456, %1457
  %1459 = zext i1 %1458 to i8
  store i8 %1459, i8* %42, align 1, !tbaa !2432
  %1460 = trunc i64 %1455 to i32
  %1461 = and i32 %1460, 255
  %1462 = tail call i32 @llvm.ctpop.i32(i32 %1461) #8
  %1463 = trunc i32 %1462 to i8
  %1464 = and i8 %1463, 1
  %1465 = xor i8 %1464, 1
  store i8 %1465, i8* %49, align 1, !tbaa !2446
  %1466 = xor i64 %1453, %1421
  %1467 = xor i64 %1466, %1455
  %1468 = lshr i64 %1467, 4
  %1469 = trunc i64 %1468 to i8
  %1470 = and i8 %1469, 1
  store i8 %1470, i8* %54, align 1, !tbaa !2447
  %1471 = icmp eq i64 %1455, 0
  %1472 = zext i1 %1471 to i8
  store i8 %1472, i8* %57, align 1, !tbaa !2448
  %1473 = lshr i64 %1455, 63
  %1474 = trunc i64 %1473 to i8
  store i8 %1474, i8* %60, align 1, !tbaa !2449
  %1475 = xor i64 %1473, %1439
  %1476 = xor i64 %1473, %1454
  %1477 = add nuw nsw i64 %1475, %1476
  %1478 = icmp eq i64 %1477, 2
  %1479 = zext i1 %1478 to i8
  store i8 %1479, i8* %66, align 1, !tbaa !2450
  %1480 = add i64 %1447, -48
  %1481 = add i64 %1365, 63
  store i64 %1481, i64* %PC, align 8
  %1482 = inttoptr i64 %1480 to i32*
  %1483 = load i32, i32* %1482, align 4
  %1484 = sext i32 %1483 to i64
  store i64 %1484, i64* %RCX, align 8, !tbaa !2428
  %1485 = shl nsw i64 %1484, 3
  %1486 = add i64 %1485, %1455
  %1487 = add i64 %1365, 68
  store i64 %1487, i64* %PC, align 8
  %1488 = load i64, i64* %147, align 1
  %1489 = inttoptr i64 %1486 to i64*
  store i64 %1488, i64* %1489, align 8
  %1490 = load i64, i64* %RBP, align 8
  %1491 = add i64 %1490, -108
  %1492 = load i64, i64* %PC, align 8
  %1493 = add i64 %1492, 7
  store i64 %1493, i64* %PC, align 8
  %1494 = inttoptr i64 %1491 to i32*
  store i32 0, i32* %1494, align 4
  %.pre4 = load i64, i64* %PC, align 8
  br label %block_402512

block_4027ab:                                     ; preds = %block_402512
  %1495 = add i64 %439, -48
  %1496 = add i64 %401, 36
  store i64 %1496, i64* %PC, align 8
  %1497 = inttoptr i64 %1495 to i32*
  %1498 = load i32, i32* %1497, align 4
  %1499 = sext i32 %1498 to i64
  store i64 %1499, i64* %RCX, align 8, !tbaa !2428
  %1500 = shl nsw i64 %1499, 3
  %1501 = add i64 %1500, %448
  %1502 = add i64 %401, 41
  store i64 %1502, i64* %PC, align 8
  %1503 = inttoptr i64 %1501 to double*
  %1504 = load double, double* %1503, align 8
  store double %1504, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %1505 = add i64 %439, -80
  %1506 = add i64 %401, 45
  store i64 %1506, i64* %PC, align 8
  %1507 = inttoptr i64 %1505 to i64*
  %1508 = load i64, i64* %1507, align 8
  store i64 %1508, i64* %RAX, align 8, !tbaa !2428
  %1509 = add i64 %439, -100
  %1510 = add i64 %401, 49
  store i64 %1510, i64* %PC, align 8
  %1511 = inttoptr i64 %1509 to i32*
  %1512 = load i32, i32* %1511, align 4
  %1513 = sext i32 %1512 to i64
  %1514 = mul nsw i64 %1513, 520
  store i64 %1514, i64* %RCX, align 8, !tbaa !2428
  %1515 = lshr i64 %1514, 63
  %1516 = add i64 %1514, %1508
  store i64 %1516, i64* %RAX, align 8, !tbaa !2428
  %1517 = icmp ult i64 %1516, %1508
  %1518 = icmp ult i64 %1516, %1514
  %1519 = or i1 %1517, %1518
  %1520 = zext i1 %1519 to i8
  store i8 %1520, i8* %42, align 1, !tbaa !2432
  %1521 = trunc i64 %1516 to i32
  %1522 = and i32 %1521, 255
  %1523 = tail call i32 @llvm.ctpop.i32(i32 %1522) #8
  %1524 = trunc i32 %1523 to i8
  %1525 = and i8 %1524, 1
  %1526 = xor i8 %1525, 1
  store i8 %1526, i8* %49, align 1, !tbaa !2446
  %1527 = xor i64 %1514, %1508
  %1528 = xor i64 %1527, %1516
  %1529 = lshr i64 %1528, 4
  %1530 = trunc i64 %1529 to i8
  %1531 = and i8 %1530, 1
  store i8 %1531, i8* %54, align 1, !tbaa !2447
  %1532 = icmp eq i64 %1516, 0
  %1533 = zext i1 %1532 to i8
  store i8 %1533, i8* %57, align 1, !tbaa !2448
  %1534 = lshr i64 %1516, 63
  %1535 = trunc i64 %1534 to i8
  store i8 %1535, i8* %60, align 1, !tbaa !2449
  %1536 = lshr i64 %1508, 63
  %1537 = xor i64 %1534, %1536
  %1538 = xor i64 %1534, %1515
  %1539 = add nuw nsw i64 %1537, %1538
  %1540 = icmp eq i64 %1539, 2
  %1541 = zext i1 %1540 to i8
  store i8 %1541, i8* %66, align 1, !tbaa !2450
  %1542 = add i64 %401, 63
  store i64 %1542, i64* %PC, align 8
  %1543 = load i32, i32* %1497, align 4
  %1544 = sext i32 %1543 to i64
  store i64 %1544, i64* %RCX, align 8, !tbaa !2428
  %1545 = shl nsw i64 %1544, 3
  %1546 = add i64 %1545, %1516
  %1547 = add i64 %401, 68
  store i64 %1547, i64* %PC, align 8
  %1548 = inttoptr i64 %1546 to double*
  %1549 = load double, double* %1548, align 8
  %1550 = fsub double %1504, %1549
  store double %1550, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %1551 = load i64, i64* %RBP, align 8
  %1552 = add i64 %1551, -88
  %1553 = add i64 %401, 72
  store i64 %1553, i64* %PC, align 8
  %1554 = inttoptr i64 %1552 to i64*
  %1555 = load i64, i64* %1554, align 8
  store i64 %1555, i64* %RAX, align 8, !tbaa !2428
  %1556 = add i64 %1551, -100
  %1557 = add i64 %401, 76
  store i64 %1557, i64* %PC, align 8
  %1558 = inttoptr i64 %1556 to i32*
  %1559 = load i32, i32* %1558, align 4
  %1560 = sext i32 %1559 to i64
  %1561 = mul nsw i64 %1560, 520
  store i64 %1561, i64* %RCX, align 8, !tbaa !2428
  %1562 = lshr i64 %1561, 63
  %1563 = add i64 %1561, %1555
  store i64 %1563, i64* %RAX, align 8, !tbaa !2428
  %1564 = icmp ult i64 %1563, %1555
  %1565 = icmp ult i64 %1563, %1561
  %1566 = or i1 %1564, %1565
  %1567 = zext i1 %1566 to i8
  store i8 %1567, i8* %42, align 1, !tbaa !2432
  %1568 = trunc i64 %1563 to i32
  %1569 = and i32 %1568, 255
  %1570 = tail call i32 @llvm.ctpop.i32(i32 %1569) #8
  %1571 = trunc i32 %1570 to i8
  %1572 = and i8 %1571, 1
  %1573 = xor i8 %1572, 1
  store i8 %1573, i8* %49, align 1, !tbaa !2446
  %1574 = xor i64 %1561, %1555
  %1575 = xor i64 %1574, %1563
  %1576 = lshr i64 %1575, 4
  %1577 = trunc i64 %1576 to i8
  %1578 = and i8 %1577, 1
  store i8 %1578, i8* %54, align 1, !tbaa !2447
  %1579 = icmp eq i64 %1563, 0
  %1580 = zext i1 %1579 to i8
  store i8 %1580, i8* %57, align 1, !tbaa !2448
  %1581 = lshr i64 %1563, 63
  %1582 = trunc i64 %1581 to i8
  store i8 %1582, i8* %60, align 1, !tbaa !2449
  %1583 = lshr i64 %1555, 63
  %1584 = xor i64 %1581, %1583
  %1585 = xor i64 %1581, %1562
  %1586 = add nuw nsw i64 %1584, %1585
  %1587 = icmp eq i64 %1586, 2
  %1588 = zext i1 %1587 to i8
  store i8 %1588, i8* %66, align 1, !tbaa !2450
  %1589 = add i64 %1551, -52
  %1590 = add i64 %401, 90
  store i64 %1590, i64* %PC, align 8
  %1591 = inttoptr i64 %1589 to i32*
  %1592 = load i32, i32* %1591, align 4
  %1593 = sext i32 %1592 to i64
  store i64 %1593, i64* %RCX, align 8, !tbaa !2428
  %1594 = shl nsw i64 %1593, 3
  %1595 = add i64 %1594, %1563
  %1596 = add i64 %401, 95
  store i64 %1596, i64* %PC, align 8
  %1597 = inttoptr i64 %1595 to double*
  %1598 = load double, double* %1597, align 8
  %1599 = fadd double %1550, %1598
  store double %1599, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %1600 = add i64 %1551, 40
  %1601 = add i64 %401, 99
  store i64 %1601, i64* %PC, align 8
  %1602 = inttoptr i64 %1600 to i64*
  %1603 = load i64, i64* %1602, align 8
  store i64 %1603, i64* %RAX, align 8, !tbaa !2428
  %1604 = add i64 %401, 103
  store i64 %1604, i64* %PC, align 8
  %1605 = load i32, i32* %1558, align 4
  %1606 = sext i32 %1605 to i64
  %1607 = mul nsw i64 %1606, 33800
  store i64 %1607, i64* %RCX, align 8, !tbaa !2428
  %1608 = lshr i64 %1607, 63
  %1609 = add i64 %1607, %1603
  store i64 %1609, i64* %RAX, align 8, !tbaa !2428
  %1610 = icmp ult i64 %1609, %1603
  %1611 = icmp ult i64 %1609, %1607
  %1612 = or i1 %1610, %1611
  %1613 = zext i1 %1612 to i8
  store i8 %1613, i8* %42, align 1, !tbaa !2432
  %1614 = trunc i64 %1609 to i32
  %1615 = and i32 %1614, 255
  %1616 = tail call i32 @llvm.ctpop.i32(i32 %1615) #8
  %1617 = trunc i32 %1616 to i8
  %1618 = and i8 %1617, 1
  %1619 = xor i8 %1618, 1
  store i8 %1619, i8* %49, align 1, !tbaa !2446
  %1620 = xor i64 %1607, %1603
  %1621 = xor i64 %1620, %1609
  %1622 = lshr i64 %1621, 4
  %1623 = trunc i64 %1622 to i8
  %1624 = and i8 %1623, 1
  store i8 %1624, i8* %54, align 1, !tbaa !2447
  %1625 = icmp eq i64 %1609, 0
  %1626 = zext i1 %1625 to i8
  store i8 %1626, i8* %57, align 1, !tbaa !2448
  %1627 = lshr i64 %1609, 63
  %1628 = trunc i64 %1627 to i8
  store i8 %1628, i8* %60, align 1, !tbaa !2449
  %1629 = lshr i64 %1603, 63
  %1630 = xor i64 %1627, %1629
  %1631 = xor i64 %1627, %1608
  %1632 = add nuw nsw i64 %1630, %1631
  %1633 = icmp eq i64 %1632, 2
  %1634 = zext i1 %1633 to i8
  store i8 %1634, i8* %66, align 1, !tbaa !2450
  %1635 = load i64, i64* %RBP, align 8
  %1636 = add i64 %1635, -52
  %1637 = add i64 %401, 117
  store i64 %1637, i64* %PC, align 8
  %1638 = inttoptr i64 %1636 to i32*
  %1639 = load i32, i32* %1638, align 4
  %1640 = sext i32 %1639 to i64
  %1641 = mul nsw i64 %1640, 520
  store i64 %1641, i64* %RCX, align 8, !tbaa !2428
  %1642 = lshr i64 %1641, 63
  %1643 = add i64 %1641, %1609
  store i64 %1643, i64* %RAX, align 8, !tbaa !2428
  %1644 = icmp ult i64 %1643, %1609
  %1645 = icmp ult i64 %1643, %1641
  %1646 = or i1 %1644, %1645
  %1647 = zext i1 %1646 to i8
  store i8 %1647, i8* %42, align 1, !tbaa !2432
  %1648 = trunc i64 %1643 to i32
  %1649 = and i32 %1648, 255
  %1650 = tail call i32 @llvm.ctpop.i32(i32 %1649) #8
  %1651 = trunc i32 %1650 to i8
  %1652 = and i8 %1651, 1
  %1653 = xor i8 %1652, 1
  store i8 %1653, i8* %49, align 1, !tbaa !2446
  %1654 = xor i64 %1641, %1609
  %1655 = xor i64 %1654, %1643
  %1656 = lshr i64 %1655, 4
  %1657 = trunc i64 %1656 to i8
  %1658 = and i8 %1657, 1
  store i8 %1658, i8* %54, align 1, !tbaa !2447
  %1659 = icmp eq i64 %1643, 0
  %1660 = zext i1 %1659 to i8
  store i8 %1660, i8* %57, align 1, !tbaa !2448
  %1661 = lshr i64 %1643, 63
  %1662 = trunc i64 %1661 to i8
  store i8 %1662, i8* %60, align 1, !tbaa !2449
  %1663 = xor i64 %1661, %1627
  %1664 = xor i64 %1661, %1642
  %1665 = add nuw nsw i64 %1663, %1664
  %1666 = icmp eq i64 %1665, 2
  %1667 = zext i1 %1666 to i8
  store i8 %1667, i8* %66, align 1, !tbaa !2450
  %1668 = add i64 %1635, -48
  %1669 = add i64 %401, 131
  store i64 %1669, i64* %PC, align 8
  %1670 = inttoptr i64 %1668 to i32*
  %1671 = load i32, i32* %1670, align 4
  %1672 = sext i32 %1671 to i64
  store i64 %1672, i64* %RCX, align 8, !tbaa !2428
  %1673 = shl nsw i64 %1672, 3
  %1674 = add i64 %1673, %1643
  %1675 = add i64 %401, 136
  store i64 %1675, i64* %PC, align 8
  %1676 = load double, double* %228, align 1
  %1677 = inttoptr i64 %1674 to double*
  %1678 = load double, double* %1677, align 8
  %1679 = fsub double %1676, %1678
  store double %1679, double* %228, align 1, !tbaa !2452
  %1680 = add i64 %1635, -96
  %1681 = add i64 %401, 140
  store i64 %1681, i64* %PC, align 8
  %1682 = inttoptr i64 %1680 to i64*
  %1683 = load i64, i64* %1682, align 8
  store i64 %1683, i64* %RAX, align 8, !tbaa !2428
  %1684 = add i64 %1635, -100
  %1685 = add i64 %401, 144
  store i64 %1685, i64* %PC, align 8
  %1686 = inttoptr i64 %1684 to i32*
  %1687 = load i32, i32* %1686, align 4
  %1688 = sext i32 %1687 to i64
  %1689 = mul nsw i64 %1688, 520
  store i64 %1689, i64* %RCX, align 8, !tbaa !2428
  %1690 = lshr i64 %1689, 63
  %1691 = add i64 %1689, %1683
  store i64 %1691, i64* %RAX, align 8, !tbaa !2428
  %1692 = icmp ult i64 %1691, %1683
  %1693 = icmp ult i64 %1691, %1689
  %1694 = or i1 %1692, %1693
  %1695 = zext i1 %1694 to i8
  store i8 %1695, i8* %42, align 1, !tbaa !2432
  %1696 = trunc i64 %1691 to i32
  %1697 = and i32 %1696, 255
  %1698 = tail call i32 @llvm.ctpop.i32(i32 %1697) #8
  %1699 = trunc i32 %1698 to i8
  %1700 = and i8 %1699, 1
  %1701 = xor i8 %1700, 1
  store i8 %1701, i8* %49, align 1, !tbaa !2446
  %1702 = xor i64 %1689, %1683
  %1703 = xor i64 %1702, %1691
  %1704 = lshr i64 %1703, 4
  %1705 = trunc i64 %1704 to i8
  %1706 = and i8 %1705, 1
  store i8 %1706, i8* %54, align 1, !tbaa !2447
  %1707 = icmp eq i64 %1691, 0
  %1708 = zext i1 %1707 to i8
  store i8 %1708, i8* %57, align 1, !tbaa !2448
  %1709 = lshr i64 %1691, 63
  %1710 = trunc i64 %1709 to i8
  store i8 %1710, i8* %60, align 1, !tbaa !2449
  %1711 = lshr i64 %1683, 63
  %1712 = xor i64 %1709, %1711
  %1713 = xor i64 %1709, %1690
  %1714 = add nuw nsw i64 %1712, %1713
  %1715 = icmp eq i64 %1714, 2
  %1716 = zext i1 %1715 to i8
  store i8 %1716, i8* %66, align 1, !tbaa !2450
  %1717 = load i64, i64* %RBP, align 8
  %1718 = add i64 %1717, -104
  %1719 = add i64 %401, 158
  store i64 %1719, i64* %PC, align 8
  %1720 = inttoptr i64 %1718 to i32*
  %1721 = load i32, i32* %1720, align 4
  %1722 = sext i32 %1721 to i64
  store i64 %1722, i64* %RCX, align 8, !tbaa !2428
  %1723 = shl nsw i64 %1722, 3
  %1724 = add i64 %1723, %1691
  %1725 = add i64 %401, 163
  store i64 %1725, i64* %PC, align 8
  %1726 = inttoptr i64 %1724 to double*
  store double %1679, double* %1726, align 8
  %1727 = load i64, i64* %RBP, align 8
  %1728 = add i64 %1727, 88
  %1729 = load i64, i64* %PC, align 8
  %1730 = add i64 %1729, 4
  store i64 %1730, i64* %PC, align 8
  %1731 = inttoptr i64 %1728 to i64*
  %1732 = load i64, i64* %1731, align 8
  store i64 %1732, i64* %RAX, align 8, !tbaa !2428
  %1733 = add i64 %1727, -52
  %1734 = add i64 %1729, 8
  store i64 %1734, i64* %PC, align 8
  %1735 = inttoptr i64 %1733 to i32*
  %1736 = load i32, i32* %1735, align 4
  %1737 = sext i32 %1736 to i64
  store i64 %1737, i64* %RCX, align 8, !tbaa !2428
  %1738 = shl nsw i64 %1737, 3
  %1739 = add i64 %1738, %1732
  %1740 = add i64 %1729, 13
  store i64 %1740, i64* %PC, align 8
  %1741 = inttoptr i64 %1739 to double*
  %1742 = load double, double* %1741, align 8
  store double %1742, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %1743 = add i64 %1727, 96
  %1744 = add i64 %1729, 17
  store i64 %1744, i64* %PC, align 8
  %1745 = inttoptr i64 %1743 to i64*
  %1746 = load i64, i64* %1745, align 8
  store i64 %1746, i64* %RAX, align 8, !tbaa !2428
  %1747 = add i64 %1729, 21
  store i64 %1747, i64* %PC, align 8
  %1748 = load i32, i32* %1735, align 4
  %1749 = sext i32 %1748 to i64
  store i64 %1749, i64* %RCX, align 8, !tbaa !2428
  %1750 = shl nsw i64 %1749, 3
  %1751 = add i64 %1750, %1746
  %1752 = add i64 %1729, 26
  store i64 %1752, i64* %PC, align 8
  %1753 = inttoptr i64 %1751 to double*
  %1754 = load double, double* %1753, align 8
  %1755 = fdiv double %1742, %1754
  store double %1755, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %1756 = add i64 %1727, 24
  %1757 = add i64 %1729, 30
  store i64 %1757, i64* %PC, align 8
  %1758 = inttoptr i64 %1756 to i64*
  %1759 = load i64, i64* %1758, align 8
  store i64 %1759, i64* %RAX, align 8, !tbaa !2428
  %1760 = add i64 %1727, -100
  %1761 = add i64 %1729, 34
  store i64 %1761, i64* %PC, align 8
  %1762 = inttoptr i64 %1760 to i32*
  %1763 = load i32, i32* %1762, align 4
  %1764 = sext i32 %1763 to i64
  %1765 = mul nsw i64 %1764, 33800
  store i64 %1765, i64* %RCX, align 8, !tbaa !2428
  %1766 = lshr i64 %1765, 63
  %1767 = add i64 %1765, %1759
  store i64 %1767, i64* %RAX, align 8, !tbaa !2428
  %1768 = icmp ult i64 %1767, %1759
  %1769 = icmp ult i64 %1767, %1765
  %1770 = or i1 %1768, %1769
  %1771 = zext i1 %1770 to i8
  store i8 %1771, i8* %42, align 1, !tbaa !2432
  %1772 = trunc i64 %1767 to i32
  %1773 = and i32 %1772, 255
  %1774 = tail call i32 @llvm.ctpop.i32(i32 %1773) #8
  %1775 = trunc i32 %1774 to i8
  %1776 = and i8 %1775, 1
  %1777 = xor i8 %1776, 1
  store i8 %1777, i8* %49, align 1, !tbaa !2446
  %1778 = xor i64 %1765, %1759
  %1779 = xor i64 %1778, %1767
  %1780 = lshr i64 %1779, 4
  %1781 = trunc i64 %1780 to i8
  %1782 = and i8 %1781, 1
  store i8 %1782, i8* %54, align 1, !tbaa !2447
  %1783 = icmp eq i64 %1767, 0
  %1784 = zext i1 %1783 to i8
  store i8 %1784, i8* %57, align 1, !tbaa !2448
  %1785 = lshr i64 %1767, 63
  %1786 = trunc i64 %1785 to i8
  store i8 %1786, i8* %60, align 1, !tbaa !2449
  %1787 = lshr i64 %1759, 63
  %1788 = xor i64 %1785, %1787
  %1789 = xor i64 %1785, %1766
  %1790 = add nuw nsw i64 %1788, %1789
  %1791 = icmp eq i64 %1790, 2
  %1792 = zext i1 %1791 to i8
  store i8 %1792, i8* %66, align 1, !tbaa !2450
  %1793 = load i64, i64* %RBP, align 8
  %1794 = add i64 %1793, -52
  %1795 = add i64 %1729, 48
  store i64 %1795, i64* %PC, align 8
  %1796 = inttoptr i64 %1794 to i32*
  %1797 = load i32, i32* %1796, align 4
  %1798 = sext i32 %1797 to i64
  %1799 = mul nsw i64 %1798, 520
  store i64 %1799, i64* %RCX, align 8, !tbaa !2428
  %1800 = lshr i64 %1799, 63
  %1801 = add i64 %1799, %1767
  store i64 %1801, i64* %RAX, align 8, !tbaa !2428
  %1802 = icmp ult i64 %1801, %1767
  %1803 = icmp ult i64 %1801, %1799
  %1804 = or i1 %1802, %1803
  %1805 = zext i1 %1804 to i8
  store i8 %1805, i8* %42, align 1, !tbaa !2432
  %1806 = trunc i64 %1801 to i32
  %1807 = and i32 %1806, 255
  %1808 = tail call i32 @llvm.ctpop.i32(i32 %1807) #8
  %1809 = trunc i32 %1808 to i8
  %1810 = and i8 %1809, 1
  %1811 = xor i8 %1810, 1
  store i8 %1811, i8* %49, align 1, !tbaa !2446
  %1812 = xor i64 %1799, %1767
  %1813 = xor i64 %1812, %1801
  %1814 = lshr i64 %1813, 4
  %1815 = trunc i64 %1814 to i8
  %1816 = and i8 %1815, 1
  store i8 %1816, i8* %54, align 1, !tbaa !2447
  %1817 = icmp eq i64 %1801, 0
  %1818 = zext i1 %1817 to i8
  store i8 %1818, i8* %57, align 1, !tbaa !2448
  %1819 = lshr i64 %1801, 63
  %1820 = trunc i64 %1819 to i8
  store i8 %1820, i8* %60, align 1, !tbaa !2449
  %1821 = xor i64 %1819, %1785
  %1822 = xor i64 %1819, %1800
  %1823 = add nuw nsw i64 %1821, %1822
  %1824 = icmp eq i64 %1823, 2
  %1825 = zext i1 %1824 to i8
  store i8 %1825, i8* %66, align 1, !tbaa !2450
  %1826 = add i64 %1793, -48
  %1827 = add i64 %1729, 62
  store i64 %1827, i64* %PC, align 8
  %1828 = inttoptr i64 %1826 to i32*
  %1829 = load i32, i32* %1828, align 4
  %1830 = sext i32 %1829 to i64
  store i64 %1830, i64* %RCX, align 8, !tbaa !2428
  %1831 = shl nsw i64 %1830, 3
  %1832 = add i64 %1831, %1801
  %1833 = add i64 %1729, 67
  store i64 %1833, i64* %PC, align 8
  %1834 = load double, double* %228, align 1
  %1835 = inttoptr i64 %1832 to double*
  %1836 = load double, double* %1835, align 8
  %1837 = fmul double %1834, %1836
  store double %1837, double* %228, align 1, !tbaa !2452
  %1838 = add i64 %1793, -72
  %1839 = add i64 %1729, 72
  store i64 %1839, i64* %PC, align 8
  %1840 = inttoptr i64 %1838 to double*
  %1841 = load double, double* %1840, align 8
  store double %1841, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %1842 = add i64 %1793, 96
  %1843 = add i64 %1729, 76
  store i64 %1843, i64* %PC, align 8
  %1844 = inttoptr i64 %1842 to i64*
  %1845 = load i64, i64* %1844, align 8
  store i64 %1845, i64* %RAX, align 8, !tbaa !2428
  %1846 = add i64 %1729, 80
  store i64 %1846, i64* %PC, align 8
  %1847 = load i32, i32* %1796, align 4
  %1848 = sext i32 %1847 to i64
  store i64 %1848, i64* %RCX, align 8, !tbaa !2428
  %1849 = shl nsw i64 %1848, 3
  %1850 = add i64 %1849, %1845
  %1851 = add i64 %1729, 85
  store i64 %1851, i64* %PC, align 8
  %1852 = inttoptr i64 %1850 to double*
  %1853 = load double, double* %1852, align 8
  %1854 = fdiv double %1841, %1853
  store double %1854, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %1855 = load i64, i64* %RBP, align 8
  %1856 = add i64 %1855, -96
  %1857 = add i64 %1729, 89
  store i64 %1857, i64* %PC, align 8
  %1858 = inttoptr i64 %1856 to i64*
  %1859 = load i64, i64* %1858, align 8
  store i64 %1859, i64* %RAX, align 8, !tbaa !2428
  %1860 = add i64 %1855, -100
  %1861 = add i64 %1729, 93
  store i64 %1861, i64* %PC, align 8
  %1862 = inttoptr i64 %1860 to i32*
  %1863 = load i32, i32* %1862, align 4
  %1864 = sext i32 %1863 to i64
  %1865 = mul nsw i64 %1864, 520
  store i64 %1865, i64* %RCX, align 8, !tbaa !2428
  %1866 = lshr i64 %1865, 63
  %1867 = add i64 %1865, %1859
  store i64 %1867, i64* %RAX, align 8, !tbaa !2428
  %1868 = icmp ult i64 %1867, %1859
  %1869 = icmp ult i64 %1867, %1865
  %1870 = or i1 %1868, %1869
  %1871 = zext i1 %1870 to i8
  store i8 %1871, i8* %42, align 1, !tbaa !2432
  %1872 = trunc i64 %1867 to i32
  %1873 = and i32 %1872, 255
  %1874 = tail call i32 @llvm.ctpop.i32(i32 %1873) #8
  %1875 = trunc i32 %1874 to i8
  %1876 = and i8 %1875, 1
  %1877 = xor i8 %1876, 1
  store i8 %1877, i8* %49, align 1, !tbaa !2446
  %1878 = xor i64 %1865, %1859
  %1879 = xor i64 %1878, %1867
  %1880 = lshr i64 %1879, 4
  %1881 = trunc i64 %1880 to i8
  %1882 = and i8 %1881, 1
  store i8 %1882, i8* %54, align 1, !tbaa !2447
  %1883 = icmp eq i64 %1867, 0
  %1884 = zext i1 %1883 to i8
  store i8 %1884, i8* %57, align 1, !tbaa !2448
  %1885 = lshr i64 %1867, 63
  %1886 = trunc i64 %1885 to i8
  store i8 %1886, i8* %60, align 1, !tbaa !2449
  %1887 = lshr i64 %1859, 63
  %1888 = xor i64 %1885, %1887
  %1889 = xor i64 %1885, %1866
  %1890 = add nuw nsw i64 %1888, %1889
  %1891 = icmp eq i64 %1890, 2
  %1892 = zext i1 %1891 to i8
  store i8 %1892, i8* %66, align 1, !tbaa !2450
  %1893 = add i64 %1855, -104
  %1894 = add i64 %1729, 107
  store i64 %1894, i64* %PC, align 8
  %1895 = inttoptr i64 %1893 to i32*
  %1896 = load i32, i32* %1895, align 4
  %1897 = sext i32 %1896 to i64
  store i64 %1897, i64* %RCX, align 8, !tbaa !2428
  %1898 = shl nsw i64 %1897, 3
  %1899 = add i64 %1898, %1867
  %1900 = add i64 %1729, 112
  store i64 %1900, i64* %PC, align 8
  %1901 = inttoptr i64 %1899 to double*
  %1902 = load double, double* %1901, align 8
  %1903 = fmul double %1854, %1902
  store double %1903, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %1904 = load double, double* %228, align 1
  %1905 = fsub double %1904, %1903
  store double %1905, double* %228, align 1, !tbaa !2452
  %1906 = add i64 %1855, 16
  %1907 = add i64 %1729, 120
  store i64 %1907, i64* %PC, align 8
  %1908 = inttoptr i64 %1906 to i64*
  %1909 = load i64, i64* %1908, align 8
  store i64 %1909, i64* %RAX, align 8, !tbaa !2428
  %1910 = load i64, i64* %RBP, align 8
  %1911 = add i64 %1910, -100
  %1912 = add i64 %1729, 124
  store i64 %1912, i64* %PC, align 8
  %1913 = inttoptr i64 %1911 to i32*
  %1914 = load i32, i32* %1913, align 4
  %1915 = sext i32 %1914 to i64
  %1916 = mul nsw i64 %1915, 520
  store i64 %1916, i64* %RCX, align 8, !tbaa !2428
  %1917 = lshr i64 %1916, 63
  %1918 = add i64 %1916, %1909
  store i64 %1918, i64* %RAX, align 8, !tbaa !2428
  %1919 = icmp ult i64 %1918, %1909
  %1920 = icmp ult i64 %1918, %1916
  %1921 = or i1 %1919, %1920
  %1922 = zext i1 %1921 to i8
  store i8 %1922, i8* %42, align 1, !tbaa !2432
  %1923 = trunc i64 %1918 to i32
  %1924 = and i32 %1923, 255
  %1925 = tail call i32 @llvm.ctpop.i32(i32 %1924) #8
  %1926 = trunc i32 %1925 to i8
  %1927 = and i8 %1926, 1
  %1928 = xor i8 %1927, 1
  store i8 %1928, i8* %49, align 1, !tbaa !2446
  %1929 = xor i64 %1916, %1909
  %1930 = xor i64 %1929, %1918
  %1931 = lshr i64 %1930, 4
  %1932 = trunc i64 %1931 to i8
  %1933 = and i8 %1932, 1
  store i8 %1933, i8* %54, align 1, !tbaa !2447
  %1934 = icmp eq i64 %1918, 0
  %1935 = zext i1 %1934 to i8
  store i8 %1935, i8* %57, align 1, !tbaa !2448
  %1936 = lshr i64 %1918, 63
  %1937 = trunc i64 %1936 to i8
  store i8 %1937, i8* %60, align 1, !tbaa !2449
  %1938 = lshr i64 %1909, 63
  %1939 = xor i64 %1936, %1938
  %1940 = xor i64 %1936, %1917
  %1941 = add nuw nsw i64 %1939, %1940
  %1942 = icmp eq i64 %1941, 2
  %1943 = zext i1 %1942 to i8
  store i8 %1943, i8* %66, align 1, !tbaa !2450
  %1944 = add i64 %1910, -104
  %1945 = add i64 %1729, 138
  store i64 %1945, i64* %PC, align 8
  %1946 = inttoptr i64 %1944 to i32*
  %1947 = load i32, i32* %1946, align 4
  %1948 = sext i32 %1947 to i64
  store i64 %1948, i64* %RCX, align 8, !tbaa !2428
  %1949 = shl nsw i64 %1948, 3
  %1950 = add i64 %1949, %1918
  %1951 = add i64 %1729, 143
  store i64 %1951, i64* %PC, align 8
  %1952 = inttoptr i64 %1950 to double*
  store double %1905, double* %1952, align 8
  %1953 = load i64, i64* %RBP, align 8
  %1954 = add i64 %1953, 72
  %1955 = load i64, i64* %PC, align 8
  %1956 = add i64 %1955, 4
  store i64 %1956, i64* %PC, align 8
  %1957 = inttoptr i64 %1954 to i64*
  %1958 = load i64, i64* %1957, align 8
  store i64 %1958, i64* %RAX, align 8, !tbaa !2428
  %1959 = add i64 %1953, -48
  %1960 = add i64 %1955, 8
  store i64 %1960, i64* %PC, align 8
  %1961 = inttoptr i64 %1959 to i32*
  %1962 = load i32, i32* %1961, align 4
  %1963 = sext i32 %1962 to i64
  store i64 %1963, i64* %RCX, align 8, !tbaa !2428
  %1964 = shl nsw i64 %1963, 3
  %1965 = add i64 %1964, %1958
  %1966 = add i64 %1955, 13
  store i64 %1966, i64* %PC, align 8
  %1967 = inttoptr i64 %1965 to double*
  %1968 = load double, double* %1967, align 8
  store double %1968, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %1969 = add i64 %1953, 80
  %1970 = add i64 %1955, 17
  store i64 %1970, i64* %PC, align 8
  %1971 = inttoptr i64 %1969 to i64*
  %1972 = load i64, i64* %1971, align 8
  store i64 %1972, i64* %RAX, align 8, !tbaa !2428
  %1973 = add i64 %1955, 21
  store i64 %1973, i64* %PC, align 8
  %1974 = load i32, i32* %1961, align 4
  %1975 = sext i32 %1974 to i64
  store i64 %1975, i64* %RCX, align 8, !tbaa !2428
  %1976 = shl nsw i64 %1975, 3
  %1977 = add i64 %1976, %1972
  %1978 = add i64 %1955, 26
  store i64 %1978, i64* %PC, align 8
  %1979 = inttoptr i64 %1977 to double*
  %1980 = load double, double* %1979, align 8
  %1981 = fdiv double %1968, %1980
  store double %1981, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %1982 = add i64 %1953, 48
  %1983 = add i64 %1955, 30
  store i64 %1983, i64* %PC, align 8
  %1984 = inttoptr i64 %1982 to i64*
  %1985 = load i64, i64* %1984, align 8
  store i64 %1985, i64* %RAX, align 8, !tbaa !2428
  %1986 = add i64 %1953, -100
  %1987 = add i64 %1955, 34
  store i64 %1987, i64* %PC, align 8
  %1988 = inttoptr i64 %1986 to i32*
  %1989 = load i32, i32* %1988, align 4
  %1990 = sext i32 %1989 to i64
  %1991 = mul nsw i64 %1990, 33800
  store i64 %1991, i64* %RCX, align 8, !tbaa !2428
  %1992 = lshr i64 %1991, 63
  %1993 = add i64 %1991, %1985
  store i64 %1993, i64* %RAX, align 8, !tbaa !2428
  %1994 = icmp ult i64 %1993, %1985
  %1995 = icmp ult i64 %1993, %1991
  %1996 = or i1 %1994, %1995
  %1997 = zext i1 %1996 to i8
  store i8 %1997, i8* %42, align 1, !tbaa !2432
  %1998 = trunc i64 %1993 to i32
  %1999 = and i32 %1998, 255
  %2000 = tail call i32 @llvm.ctpop.i32(i32 %1999) #8
  %2001 = trunc i32 %2000 to i8
  %2002 = and i8 %2001, 1
  %2003 = xor i8 %2002, 1
  store i8 %2003, i8* %49, align 1, !tbaa !2446
  %2004 = xor i64 %1991, %1985
  %2005 = xor i64 %2004, %1993
  %2006 = lshr i64 %2005, 4
  %2007 = trunc i64 %2006 to i8
  %2008 = and i8 %2007, 1
  store i8 %2008, i8* %54, align 1, !tbaa !2447
  %2009 = icmp eq i64 %1993, 0
  %2010 = zext i1 %2009 to i8
  store i8 %2010, i8* %57, align 1, !tbaa !2448
  %2011 = lshr i64 %1993, 63
  %2012 = trunc i64 %2011 to i8
  store i8 %2012, i8* %60, align 1, !tbaa !2449
  %2013 = lshr i64 %1985, 63
  %2014 = xor i64 %2011, %2013
  %2015 = xor i64 %2011, %1992
  %2016 = add nuw nsw i64 %2014, %2015
  %2017 = icmp eq i64 %2016, 2
  %2018 = zext i1 %2017 to i8
  store i8 %2018, i8* %66, align 1, !tbaa !2450
  %2019 = load i64, i64* %RBP, align 8
  %2020 = add i64 %2019, -52
  %2021 = add i64 %1955, 48
  store i64 %2021, i64* %PC, align 8
  %2022 = inttoptr i64 %2020 to i32*
  %2023 = load i32, i32* %2022, align 4
  %2024 = sext i32 %2023 to i64
  %2025 = mul nsw i64 %2024, 520
  store i64 %2025, i64* %RCX, align 8, !tbaa !2428
  %2026 = lshr i64 %2025, 63
  %2027 = add i64 %2025, %1993
  store i64 %2027, i64* %RAX, align 8, !tbaa !2428
  %2028 = icmp ult i64 %2027, %1993
  %2029 = icmp ult i64 %2027, %2025
  %2030 = or i1 %2028, %2029
  %2031 = zext i1 %2030 to i8
  store i8 %2031, i8* %42, align 1, !tbaa !2432
  %2032 = trunc i64 %2027 to i32
  %2033 = and i32 %2032, 255
  %2034 = tail call i32 @llvm.ctpop.i32(i32 %2033) #8
  %2035 = trunc i32 %2034 to i8
  %2036 = and i8 %2035, 1
  %2037 = xor i8 %2036, 1
  store i8 %2037, i8* %49, align 1, !tbaa !2446
  %2038 = xor i64 %2025, %1993
  %2039 = xor i64 %2038, %2027
  %2040 = lshr i64 %2039, 4
  %2041 = trunc i64 %2040 to i8
  %2042 = and i8 %2041, 1
  store i8 %2042, i8* %54, align 1, !tbaa !2447
  %2043 = icmp eq i64 %2027, 0
  %2044 = zext i1 %2043 to i8
  store i8 %2044, i8* %57, align 1, !tbaa !2448
  %2045 = lshr i64 %2027, 63
  %2046 = trunc i64 %2045 to i8
  store i8 %2046, i8* %60, align 1, !tbaa !2449
  %2047 = xor i64 %2045, %2011
  %2048 = xor i64 %2045, %2026
  %2049 = add nuw nsw i64 %2047, %2048
  %2050 = icmp eq i64 %2049, 2
  %2051 = zext i1 %2050 to i8
  store i8 %2051, i8* %66, align 1, !tbaa !2450
  %2052 = add i64 %2019, -48
  %2053 = add i64 %1955, 62
  store i64 %2053, i64* %PC, align 8
  %2054 = inttoptr i64 %2052 to i32*
  %2055 = load i32, i32* %2054, align 4
  %2056 = sext i32 %2055 to i64
  store i64 %2056, i64* %RCX, align 8, !tbaa !2428
  %2057 = shl nsw i64 %2056, 3
  %2058 = add i64 %2057, %2027
  %2059 = add i64 %1955, 67
  store i64 %2059, i64* %PC, align 8
  %2060 = load double, double* %228, align 1
  %2061 = inttoptr i64 %2058 to double*
  %2062 = load double, double* %2061, align 8
  %2063 = fmul double %2060, %2062
  store double %2063, double* %228, align 1, !tbaa !2452
  %2064 = add i64 %2019, -64
  %2065 = add i64 %1955, 72
  store i64 %2065, i64* %PC, align 8
  %2066 = inttoptr i64 %2064 to double*
  %2067 = load double, double* %2066, align 8
  store double %2067, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %2068 = add i64 %2019, 64
  %2069 = add i64 %1955, 76
  store i64 %2069, i64* %PC, align 8
  %2070 = inttoptr i64 %2068 to i64*
  %2071 = load i64, i64* %2070, align 8
  store i64 %2071, i64* %RAX, align 8, !tbaa !2428
  %2072 = add i64 %2019, -100
  %2073 = add i64 %1955, 80
  store i64 %2073, i64* %PC, align 8
  %2074 = inttoptr i64 %2072 to i32*
  %2075 = load i32, i32* %2074, align 4
  %2076 = sext i32 %2075 to i64
  store i64 %2076, i64* %RCX, align 8, !tbaa !2428
  %2077 = shl nsw i64 %2076, 3
  %2078 = add i64 %2077, %2071
  %2079 = add i64 %1955, 85
  store i64 %2079, i64* %PC, align 8
  %2080 = inttoptr i64 %2078 to double*
  %2081 = load double, double* %2080, align 8
  %2082 = fmul double %2067, %2081
  store double %2082, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %2083 = load i64, i64* %RBP, align 8
  %2084 = add i64 %2083, 80
  %2085 = add i64 %1955, 89
  store i64 %2085, i64* %PC, align 8
  %2086 = inttoptr i64 %2084 to i64*
  %2087 = load i64, i64* %2086, align 8
  store i64 %2087, i64* %RAX, align 8, !tbaa !2428
  %2088 = add i64 %2083, -48
  %2089 = add i64 %1955, 93
  store i64 %2089, i64* %PC, align 8
  %2090 = inttoptr i64 %2088 to i32*
  %2091 = load i32, i32* %2090, align 4
  %2092 = sext i32 %2091 to i64
  store i64 %2092, i64* %RCX, align 8, !tbaa !2428
  %2093 = shl nsw i64 %2092, 3
  %2094 = add i64 %2093, %2087
  %2095 = add i64 %1955, 98
  store i64 %2095, i64* %PC, align 8
  %2096 = inttoptr i64 %2094 to double*
  %2097 = load double, double* %2096, align 8
  %2098 = fdiv double %2082, %2097
  store double %2098, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %2099 = add i64 %2083, 16
  %2100 = add i64 %1955, 102
  store i64 %2100, i64* %PC, align 8
  %2101 = inttoptr i64 %2099 to i64*
  %2102 = load i64, i64* %2101, align 8
  store i64 %2102, i64* %RAX, align 8, !tbaa !2428
  %2103 = add i64 %2083, -100
  %2104 = add i64 %1955, 106
  store i64 %2104, i64* %PC, align 8
  %2105 = inttoptr i64 %2103 to i32*
  %2106 = load i32, i32* %2105, align 4
  %2107 = sext i32 %2106 to i64
  %2108 = mul nsw i64 %2107, 520
  store i64 %2108, i64* %RCX, align 8, !tbaa !2428
  %2109 = lshr i64 %2108, 63
  %2110 = add i64 %2108, %2102
  store i64 %2110, i64* %RAX, align 8, !tbaa !2428
  %2111 = icmp ult i64 %2110, %2102
  %2112 = icmp ult i64 %2110, %2108
  %2113 = or i1 %2111, %2112
  %2114 = zext i1 %2113 to i8
  store i8 %2114, i8* %42, align 1, !tbaa !2432
  %2115 = trunc i64 %2110 to i32
  %2116 = and i32 %2115, 255
  %2117 = tail call i32 @llvm.ctpop.i32(i32 %2116) #8
  %2118 = trunc i32 %2117 to i8
  %2119 = and i8 %2118, 1
  %2120 = xor i8 %2119, 1
  store i8 %2120, i8* %49, align 1, !tbaa !2446
  %2121 = xor i64 %2108, %2102
  %2122 = xor i64 %2121, %2110
  %2123 = lshr i64 %2122, 4
  %2124 = trunc i64 %2123 to i8
  %2125 = and i8 %2124, 1
  store i8 %2125, i8* %54, align 1, !tbaa !2447
  %2126 = icmp eq i64 %2110, 0
  %2127 = zext i1 %2126 to i8
  store i8 %2127, i8* %57, align 1, !tbaa !2448
  %2128 = lshr i64 %2110, 63
  %2129 = trunc i64 %2128 to i8
  store i8 %2129, i8* %60, align 1, !tbaa !2449
  %2130 = lshr i64 %2102, 63
  %2131 = xor i64 %2128, %2130
  %2132 = xor i64 %2128, %2109
  %2133 = add nuw nsw i64 %2131, %2132
  %2134 = icmp eq i64 %2133, 2
  %2135 = zext i1 %2134 to i8
  store i8 %2135, i8* %66, align 1, !tbaa !2450
  %2136 = add i64 %2083, -104
  %2137 = add i64 %1955, 120
  store i64 %2137, i64* %PC, align 8
  %2138 = inttoptr i64 %2136 to i32*
  %2139 = load i32, i32* %2138, align 4
  %2140 = sext i32 %2139 to i64
  store i64 %2140, i64* %RCX, align 8, !tbaa !2428
  %2141 = shl nsw i64 %2140, 3
  %2142 = add i64 %2141, %2110
  %2143 = add i64 %1955, 125
  store i64 %2143, i64* %PC, align 8
  %2144 = inttoptr i64 %2142 to double*
  %2145 = load double, double* %2144, align 8
  %2146 = fmul double %2098, %2145
  store double %2146, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %2147 = load double, double* %228, align 1
  %2148 = fadd double %2147, %2146
  store double %2148, double* %228, align 1, !tbaa !2452
  %2149 = load i64, i64* %RBP, align 8
  %2150 = add i64 %2149, -64
  %2151 = add i64 %1955, 134
  store i64 %2151, i64* %PC, align 8
  %2152 = inttoptr i64 %2150 to double*
  %2153 = load double, double* %2152, align 8
  store double %2153, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %2154 = add i64 %2149, 56
  %2155 = add i64 %1955, 138
  store i64 %2155, i64* %PC, align 8
  %2156 = inttoptr i64 %2154 to i64*
  %2157 = load i64, i64* %2156, align 8
  store i64 %2157, i64* %RAX, align 8, !tbaa !2428
  %2158 = add i64 %2149, -100
  %2159 = add i64 %1955, 142
  store i64 %2159, i64* %PC, align 8
  %2160 = inttoptr i64 %2158 to i32*
  %2161 = load i32, i32* %2160, align 4
  %2162 = sext i32 %2161 to i64
  store i64 %2162, i64* %RCX, align 8, !tbaa !2428
  %2163 = shl nsw i64 %2162, 3
  %2164 = add i64 %2163, %2157
  %2165 = add i64 %1955, 147
  store i64 %2165, i64* %PC, align 8
  %2166 = inttoptr i64 %2164 to double*
  %2167 = load double, double* %2166, align 8
  %2168 = fmul double %2153, %2167
  store double %2168, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %2169 = add i64 %2149, 80
  %2170 = add i64 %1955, 151
  store i64 %2170, i64* %PC, align 8
  %2171 = inttoptr i64 %2169 to i64*
  %2172 = load i64, i64* %2171, align 8
  store i64 %2172, i64* %RAX, align 8, !tbaa !2428
  %2173 = add i64 %2149, -48
  %2174 = add i64 %1955, 155
  store i64 %2174, i64* %PC, align 8
  %2175 = inttoptr i64 %2173 to i32*
  %2176 = load i32, i32* %2175, align 4
  %2177 = sext i32 %2176 to i64
  store i64 %2177, i64* %RCX, align 8, !tbaa !2428
  %2178 = shl nsw i64 %2177, 3
  %2179 = add i64 %2178, %2172
  %2180 = add i64 %1955, 160
  store i64 %2180, i64* %PC, align 8
  %2181 = inttoptr i64 %2179 to double*
  %2182 = load double, double* %2181, align 8
  %2183 = fdiv double %2168, %2182
  store double %2183, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %2184 = add i64 %2149, 24
  %2185 = add i64 %1955, 164
  store i64 %2185, i64* %PC, align 8
  %2186 = inttoptr i64 %2184 to i64*
  %2187 = load i64, i64* %2186, align 8
  store i64 %2187, i64* %RAX, align 8, !tbaa !2428
  %2188 = add i64 %1955, 168
  store i64 %2188, i64* %PC, align 8
  %2189 = load i32, i32* %2160, align 4
  %2190 = sext i32 %2189 to i64
  %2191 = mul nsw i64 %2190, 33800
  store i64 %2191, i64* %RCX, align 8, !tbaa !2428
  %2192 = lshr i64 %2191, 63
  %2193 = add i64 %2191, %2187
  store i64 %2193, i64* %RAX, align 8, !tbaa !2428
  %2194 = icmp ult i64 %2193, %2187
  %2195 = icmp ult i64 %2193, %2191
  %2196 = or i1 %2194, %2195
  %2197 = zext i1 %2196 to i8
  store i8 %2197, i8* %42, align 1, !tbaa !2432
  %2198 = trunc i64 %2193 to i32
  %2199 = and i32 %2198, 255
  %2200 = tail call i32 @llvm.ctpop.i32(i32 %2199) #8
  %2201 = trunc i32 %2200 to i8
  %2202 = and i8 %2201, 1
  %2203 = xor i8 %2202, 1
  store i8 %2203, i8* %49, align 1, !tbaa !2446
  %2204 = xor i64 %2191, %2187
  %2205 = xor i64 %2204, %2193
  %2206 = lshr i64 %2205, 4
  %2207 = trunc i64 %2206 to i8
  %2208 = and i8 %2207, 1
  store i8 %2208, i8* %54, align 1, !tbaa !2447
  %2209 = icmp eq i64 %2193, 0
  %2210 = zext i1 %2209 to i8
  store i8 %2210, i8* %57, align 1, !tbaa !2448
  %2211 = lshr i64 %2193, 63
  %2212 = trunc i64 %2211 to i8
  store i8 %2212, i8* %60, align 1, !tbaa !2449
  %2213 = lshr i64 %2187, 63
  %2214 = xor i64 %2211, %2213
  %2215 = xor i64 %2211, %2192
  %2216 = add nuw nsw i64 %2214, %2215
  %2217 = icmp eq i64 %2216, 2
  %2218 = zext i1 %2217 to i8
  store i8 %2218, i8* %66, align 1, !tbaa !2450
  %2219 = load i64, i64* %RBP, align 8
  %2220 = add i64 %2219, -52
  %2221 = add i64 %1955, 182
  store i64 %2221, i64* %PC, align 8
  %2222 = inttoptr i64 %2220 to i32*
  %2223 = load i32, i32* %2222, align 4
  %2224 = sext i32 %2223 to i64
  %2225 = mul nsw i64 %2224, 520
  store i64 %2225, i64* %RCX, align 8, !tbaa !2428
  %2226 = lshr i64 %2225, 63
  %2227 = add i64 %2225, %2193
  store i64 %2227, i64* %RAX, align 8, !tbaa !2428
  %2228 = icmp ult i64 %2227, %2193
  %2229 = icmp ult i64 %2227, %2225
  %2230 = or i1 %2228, %2229
  %2231 = zext i1 %2230 to i8
  store i8 %2231, i8* %42, align 1, !tbaa !2432
  %2232 = trunc i64 %2227 to i32
  %2233 = and i32 %2232, 255
  %2234 = tail call i32 @llvm.ctpop.i32(i32 %2233) #8
  %2235 = trunc i32 %2234 to i8
  %2236 = and i8 %2235, 1
  %2237 = xor i8 %2236, 1
  store i8 %2237, i8* %49, align 1, !tbaa !2446
  %2238 = xor i64 %2225, %2193
  %2239 = xor i64 %2238, %2227
  %2240 = lshr i64 %2239, 4
  %2241 = trunc i64 %2240 to i8
  %2242 = and i8 %2241, 1
  store i8 %2242, i8* %54, align 1, !tbaa !2447
  %2243 = icmp eq i64 %2227, 0
  %2244 = zext i1 %2243 to i8
  store i8 %2244, i8* %57, align 1, !tbaa !2448
  %2245 = lshr i64 %2227, 63
  %2246 = trunc i64 %2245 to i8
  store i8 %2246, i8* %60, align 1, !tbaa !2449
  %2247 = xor i64 %2245, %2211
  %2248 = xor i64 %2245, %2226
  %2249 = add nuw nsw i64 %2247, %2248
  %2250 = icmp eq i64 %2249, 2
  %2251 = zext i1 %2250 to i8
  store i8 %2251, i8* %66, align 1, !tbaa !2450
  %2252 = add i64 %2219, -48
  %2253 = add i64 %1955, 196
  store i64 %2253, i64* %PC, align 8
  %2254 = inttoptr i64 %2252 to i32*
  %2255 = load i32, i32* %2254, align 4
  %2256 = sext i32 %2255 to i64
  store i64 %2256, i64* %RCX, align 8, !tbaa !2428
  %2257 = shl nsw i64 %2256, 3
  %2258 = add i64 %2257, %2227
  %2259 = add i64 %1955, 201
  store i64 %2259, i64* %PC, align 8
  %2260 = load double, double* %231, align 1
  %2261 = inttoptr i64 %2258 to double*
  %2262 = load double, double* %2261, align 8
  %2263 = fmul double %2260, %2262
  store double %2263, double* %231, align 1, !tbaa !2452
  %2264 = load double, double* %228, align 1
  %2265 = fsub double %2264, %2263
  store double %2265, double* %228, align 1, !tbaa !2452
  %2266 = add i64 %2219, 48
  %2267 = add i64 %1955, 209
  store i64 %2267, i64* %PC, align 8
  %2268 = inttoptr i64 %2266 to i64*
  %2269 = load i64, i64* %2268, align 8
  store i64 %2269, i64* %RAX, align 8, !tbaa !2428
  %2270 = add i64 %2219, -100
  %2271 = add i64 %1955, 213
  store i64 %2271, i64* %PC, align 8
  %2272 = inttoptr i64 %2270 to i32*
  %2273 = load i32, i32* %2272, align 4
  %2274 = sext i32 %2273 to i64
  %2275 = mul nsw i64 %2274, 33800
  store i64 %2275, i64* %RCX, align 8, !tbaa !2428
  %2276 = lshr i64 %2275, 63
  %2277 = add i64 %2275, %2269
  store i64 %2277, i64* %RAX, align 8, !tbaa !2428
  %2278 = icmp ult i64 %2277, %2269
  %2279 = icmp ult i64 %2277, %2275
  %2280 = or i1 %2278, %2279
  %2281 = zext i1 %2280 to i8
  store i8 %2281, i8* %42, align 1, !tbaa !2432
  %2282 = trunc i64 %2277 to i32
  %2283 = and i32 %2282, 255
  %2284 = tail call i32 @llvm.ctpop.i32(i32 %2283) #8
  %2285 = trunc i32 %2284 to i8
  %2286 = and i8 %2285, 1
  %2287 = xor i8 %2286, 1
  store i8 %2287, i8* %49, align 1, !tbaa !2446
  %2288 = xor i64 %2275, %2269
  %2289 = xor i64 %2288, %2277
  %2290 = lshr i64 %2289, 4
  %2291 = trunc i64 %2290 to i8
  %2292 = and i8 %2291, 1
  store i8 %2292, i8* %54, align 1, !tbaa !2447
  %2293 = icmp eq i64 %2277, 0
  %2294 = zext i1 %2293 to i8
  store i8 %2294, i8* %57, align 1, !tbaa !2448
  %2295 = lshr i64 %2277, 63
  %2296 = trunc i64 %2295 to i8
  store i8 %2296, i8* %60, align 1, !tbaa !2449
  %2297 = lshr i64 %2269, 63
  %2298 = xor i64 %2295, %2297
  %2299 = xor i64 %2295, %2276
  %2300 = add nuw nsw i64 %2298, %2299
  %2301 = icmp eq i64 %2300, 2
  %2302 = zext i1 %2301 to i8
  store i8 %2302, i8* %66, align 1, !tbaa !2450
  %2303 = load i64, i64* %RBP, align 8
  %2304 = add i64 %2303, -52
  %2305 = add i64 %1955, 227
  store i64 %2305, i64* %PC, align 8
  %2306 = inttoptr i64 %2304 to i32*
  %2307 = load i32, i32* %2306, align 4
  %2308 = sext i32 %2307 to i64
  %2309 = mul nsw i64 %2308, 520
  store i64 %2309, i64* %RCX, align 8, !tbaa !2428
  %2310 = lshr i64 %2309, 63
  %2311 = add i64 %2309, %2277
  store i64 %2311, i64* %RAX, align 8, !tbaa !2428
  %2312 = icmp ult i64 %2311, %2277
  %2313 = icmp ult i64 %2311, %2309
  %2314 = or i1 %2312, %2313
  %2315 = zext i1 %2314 to i8
  store i8 %2315, i8* %42, align 1, !tbaa !2432
  %2316 = trunc i64 %2311 to i32
  %2317 = and i32 %2316, 255
  %2318 = tail call i32 @llvm.ctpop.i32(i32 %2317) #8
  %2319 = trunc i32 %2318 to i8
  %2320 = and i8 %2319, 1
  %2321 = xor i8 %2320, 1
  store i8 %2321, i8* %49, align 1, !tbaa !2446
  %2322 = xor i64 %2309, %2277
  %2323 = xor i64 %2322, %2311
  %2324 = lshr i64 %2323, 4
  %2325 = trunc i64 %2324 to i8
  %2326 = and i8 %2325, 1
  store i8 %2326, i8* %54, align 1, !tbaa !2447
  %2327 = icmp eq i64 %2311, 0
  %2328 = zext i1 %2327 to i8
  store i8 %2328, i8* %57, align 1, !tbaa !2448
  %2329 = lshr i64 %2311, 63
  %2330 = trunc i64 %2329 to i8
  store i8 %2330, i8* %60, align 1, !tbaa !2449
  %2331 = xor i64 %2329, %2295
  %2332 = xor i64 %2329, %2310
  %2333 = add nuw nsw i64 %2331, %2332
  %2334 = icmp eq i64 %2333, 2
  %2335 = zext i1 %2334 to i8
  store i8 %2335, i8* %66, align 1, !tbaa !2450
  %2336 = add i64 %2303, -48
  %2337 = add i64 %1955, 241
  store i64 %2337, i64* %PC, align 8
  %2338 = inttoptr i64 %2336 to i32*
  %2339 = load i32, i32* %2338, align 4
  %2340 = sext i32 %2339 to i64
  store i64 %2340, i64* %RCX, align 8, !tbaa !2428
  %2341 = shl nsw i64 %2340, 3
  %2342 = add i64 %2341, %2311
  %2343 = add i64 %1955, 246
  store i64 %2343, i64* %PC, align 8
  %2344 = load i64, i64* %147, align 1
  %2345 = inttoptr i64 %2342 to i64*
  store i64 %2344, i64* %2345, align 8
  %2346 = load i64, i64* %RBP, align 8
  %2347 = add i64 %2346, 16
  %2348 = load i64, i64* %PC, align 8
  %2349 = add i64 %2348, 4
  store i64 %2349, i64* %PC, align 8
  %2350 = inttoptr i64 %2347 to i64*
  %2351 = load i64, i64* %2350, align 8
  store i64 %2351, i64* %RAX, align 8, !tbaa !2428
  %2352 = add i64 %2346, -100
  %2353 = add i64 %2348, 8
  store i64 %2353, i64* %PC, align 8
  %2354 = inttoptr i64 %2352 to i32*
  %2355 = load i32, i32* %2354, align 4
  %2356 = sext i32 %2355 to i64
  %2357 = mul nsw i64 %2356, 520
  store i64 %2357, i64* %RCX, align 8, !tbaa !2428
  %2358 = lshr i64 %2357, 63
  %2359 = add i64 %2357, %2351
  store i64 %2359, i64* %RAX, align 8, !tbaa !2428
  %2360 = icmp ult i64 %2359, %2351
  %2361 = icmp ult i64 %2359, %2357
  %2362 = or i1 %2360, %2361
  %2363 = zext i1 %2362 to i8
  store i8 %2363, i8* %42, align 1, !tbaa !2432
  %2364 = trunc i64 %2359 to i32
  %2365 = and i32 %2364, 255
  %2366 = tail call i32 @llvm.ctpop.i32(i32 %2365) #8
  %2367 = trunc i32 %2366 to i8
  %2368 = and i8 %2367, 1
  %2369 = xor i8 %2368, 1
  store i8 %2369, i8* %49, align 1, !tbaa !2446
  %2370 = xor i64 %2357, %2351
  %2371 = xor i64 %2370, %2359
  %2372 = lshr i64 %2371, 4
  %2373 = trunc i64 %2372 to i8
  %2374 = and i8 %2373, 1
  store i8 %2374, i8* %54, align 1, !tbaa !2447
  %2375 = icmp eq i64 %2359, 0
  %2376 = zext i1 %2375 to i8
  store i8 %2376, i8* %57, align 1, !tbaa !2448
  %2377 = lshr i64 %2359, 63
  %2378 = trunc i64 %2377 to i8
  store i8 %2378, i8* %60, align 1, !tbaa !2449
  %2379 = lshr i64 %2351, 63
  %2380 = xor i64 %2377, %2379
  %2381 = xor i64 %2377, %2358
  %2382 = add nuw nsw i64 %2380, %2381
  %2383 = icmp eq i64 %2382, 2
  %2384 = zext i1 %2383 to i8
  store i8 %2384, i8* %66, align 1, !tbaa !2450
  %2385 = add i64 %2346, -104
  %2386 = add i64 %2348, 22
  store i64 %2386, i64* %PC, align 8
  %2387 = inttoptr i64 %2385 to i32*
  %2388 = load i32, i32* %2387, align 4
  %2389 = sext i32 %2388 to i64
  store i64 %2389, i64* %RCX, align 8, !tbaa !2428
  %2390 = shl nsw i64 %2389, 3
  %2391 = add i64 %2390, %2359
  %2392 = add i64 %2348, 27
  store i64 %2392, i64* %PC, align 8
  %2393 = inttoptr i64 %2391 to i64*
  %2394 = load i64, i64* %2393, align 8
  store i64 %2394, i64* %147, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %2395 = add i64 %2346, 24
  %2396 = add i64 %2348, 31
  store i64 %2396, i64* %PC, align 8
  %2397 = inttoptr i64 %2395 to i64*
  %2398 = load i64, i64* %2397, align 8
  store i64 %2398, i64* %RAX, align 8, !tbaa !2428
  %2399 = add i64 %2348, 35
  store i64 %2399, i64* %PC, align 8
  %2400 = load i32, i32* %2354, align 4
  %2401 = sext i32 %2400 to i64
  %2402 = mul nsw i64 %2401, 33800
  store i64 %2402, i64* %RCX, align 8, !tbaa !2428
  %2403 = lshr i64 %2402, 63
  %2404 = add i64 %2402, %2398
  store i64 %2404, i64* %RAX, align 8, !tbaa !2428
  %2405 = icmp ult i64 %2404, %2398
  %2406 = icmp ult i64 %2404, %2402
  %2407 = or i1 %2405, %2406
  %2408 = zext i1 %2407 to i8
  store i8 %2408, i8* %42, align 1, !tbaa !2432
  %2409 = trunc i64 %2404 to i32
  %2410 = and i32 %2409, 255
  %2411 = tail call i32 @llvm.ctpop.i32(i32 %2410) #8
  %2412 = trunc i32 %2411 to i8
  %2413 = and i8 %2412, 1
  %2414 = xor i8 %2413, 1
  store i8 %2414, i8* %49, align 1, !tbaa !2446
  %2415 = xor i64 %2402, %2398
  %2416 = xor i64 %2415, %2404
  %2417 = lshr i64 %2416, 4
  %2418 = trunc i64 %2417 to i8
  %2419 = and i8 %2418, 1
  store i8 %2419, i8* %54, align 1, !tbaa !2447
  %2420 = icmp eq i64 %2404, 0
  %2421 = zext i1 %2420 to i8
  store i8 %2421, i8* %57, align 1, !tbaa !2448
  %2422 = lshr i64 %2404, 63
  %2423 = trunc i64 %2422 to i8
  store i8 %2423, i8* %60, align 1, !tbaa !2449
  %2424 = lshr i64 %2398, 63
  %2425 = xor i64 %2422, %2424
  %2426 = xor i64 %2422, %2403
  %2427 = add nuw nsw i64 %2425, %2426
  %2428 = icmp eq i64 %2427, 2
  %2429 = zext i1 %2428 to i8
  store i8 %2429, i8* %66, align 1, !tbaa !2450
  %2430 = load i64, i64* %RBP, align 8
  %2431 = add i64 %2430, -52
  %2432 = add i64 %2348, 49
  store i64 %2432, i64* %PC, align 8
  %2433 = inttoptr i64 %2431 to i32*
  %2434 = load i32, i32* %2433, align 4
  %2435 = sext i32 %2434 to i64
  %2436 = mul nsw i64 %2435, 520
  store i64 %2436, i64* %RCX, align 8, !tbaa !2428
  %2437 = lshr i64 %2436, 63
  %2438 = add i64 %2436, %2404
  store i64 %2438, i64* %RAX, align 8, !tbaa !2428
  %2439 = icmp ult i64 %2438, %2404
  %2440 = icmp ult i64 %2438, %2436
  %2441 = or i1 %2439, %2440
  %2442 = zext i1 %2441 to i8
  store i8 %2442, i8* %42, align 1, !tbaa !2432
  %2443 = trunc i64 %2438 to i32
  %2444 = and i32 %2443, 255
  %2445 = tail call i32 @llvm.ctpop.i32(i32 %2444) #8
  %2446 = trunc i32 %2445 to i8
  %2447 = and i8 %2446, 1
  %2448 = xor i8 %2447, 1
  store i8 %2448, i8* %49, align 1, !tbaa !2446
  %2449 = xor i64 %2436, %2404
  %2450 = xor i64 %2449, %2438
  %2451 = lshr i64 %2450, 4
  %2452 = trunc i64 %2451 to i8
  %2453 = and i8 %2452, 1
  store i8 %2453, i8* %54, align 1, !tbaa !2447
  %2454 = icmp eq i64 %2438, 0
  %2455 = zext i1 %2454 to i8
  store i8 %2455, i8* %57, align 1, !tbaa !2448
  %2456 = lshr i64 %2438, 63
  %2457 = trunc i64 %2456 to i8
  store i8 %2457, i8* %60, align 1, !tbaa !2449
  %2458 = xor i64 %2456, %2422
  %2459 = xor i64 %2456, %2437
  %2460 = add nuw nsw i64 %2458, %2459
  %2461 = icmp eq i64 %2460, 2
  %2462 = zext i1 %2461 to i8
  store i8 %2462, i8* %66, align 1, !tbaa !2450
  %2463 = add i64 %2430, -48
  %2464 = add i64 %2348, 63
  store i64 %2464, i64* %PC, align 8
  %2465 = inttoptr i64 %2463 to i32*
  %2466 = load i32, i32* %2465, align 4
  %2467 = sext i32 %2466 to i64
  store i64 %2467, i64* %RCX, align 8, !tbaa !2428
  %2468 = shl nsw i64 %2467, 3
  %2469 = add i64 %2468, %2438
  %2470 = add i64 %2348, 68
  store i64 %2470, i64* %PC, align 8
  %2471 = load i64, i64* %147, align 1
  %2472 = inttoptr i64 %2469 to i64*
  store i64 %2471, i64* %2472, align 8
  %2473 = load i64, i64* %RBP, align 8
  %2474 = add i64 %2473, -104
  %2475 = load i64, i64* %PC, align 8
  %2476 = add i64 %2475, 3
  store i64 %2476, i64* %PC, align 8
  %2477 = inttoptr i64 %2474 to i32*
  %2478 = load i32, i32* %2477, align 4
  %2479 = add i32 %2478, 1
  %2480 = zext i32 %2479 to i64
  store i64 %2480, i64* %RAX, align 8, !tbaa !2428
  %2481 = icmp eq i32 %2478, -1
  %2482 = icmp eq i32 %2479, 0
  %2483 = or i1 %2481, %2482
  %2484 = zext i1 %2483 to i8
  store i8 %2484, i8* %42, align 1, !tbaa !2432
  %2485 = and i32 %2479, 255
  %2486 = tail call i32 @llvm.ctpop.i32(i32 %2485) #8
  %2487 = trunc i32 %2486 to i8
  %2488 = and i8 %2487, 1
  %2489 = xor i8 %2488, 1
  store i8 %2489, i8* %49, align 1, !tbaa !2446
  %2490 = xor i32 %2478, %2479
  %2491 = lshr i32 %2490, 4
  %2492 = trunc i32 %2491 to i8
  %2493 = and i8 %2492, 1
  store i8 %2493, i8* %54, align 1, !tbaa !2447
  %2494 = zext i1 %2482 to i8
  store i8 %2494, i8* %57, align 1, !tbaa !2448
  %2495 = lshr i32 %2479, 31
  %2496 = trunc i32 %2495 to i8
  store i8 %2496, i8* %60, align 1, !tbaa !2449
  %2497 = lshr i32 %2478, 31
  %2498 = xor i32 %2495, %2497
  %2499 = add nuw nsw i32 %2498, %2495
  %2500 = icmp eq i32 %2499, 2
  %2501 = zext i1 %2500 to i8
  store i8 %2501, i8* %66, align 1, !tbaa !2450
  %2502 = add i64 %2475, 9
  store i64 %2502, i64* %PC, align 8
  store i32 %2479, i32* %2477, align 4
  %2503 = load i64, i64* %PC, align 8
  %2504 = add i64 %2503, -2643
  store i64 %2504, i64* %PC, align 8, !tbaa !2428
  br label %block_401fcd

block_40251e:                                     ; preds = %block_402512
  %2505 = add i64 %439, -108
  %2506 = add i64 %401, 36
  store i64 %2506, i64* %PC, align 8
  %2507 = inttoptr i64 %2505 to i32*
  %2508 = load i32, i32* %2507, align 4
  %2509 = sext i32 %2508 to i64
  store i64 %2509, i64* %RCX, align 8, !tbaa !2428
  %2510 = shl nsw i64 %2509, 3
  %2511 = add i64 %2510, %448
  %2512 = add i64 %401, 41
  store i64 %2512, i64* %PC, align 8
  %2513 = inttoptr i64 %2511 to double*
  %2514 = load double, double* %2513, align 8
  store double %2514, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %2515 = add i64 %439, -80
  %2516 = add i64 %401, 45
  store i64 %2516, i64* %PC, align 8
  %2517 = inttoptr i64 %2515 to i64*
  %2518 = load i64, i64* %2517, align 8
  store i64 %2518, i64* %RAX, align 8, !tbaa !2428
  %2519 = add i64 %439, -100
  %2520 = add i64 %401, 49
  store i64 %2520, i64* %PC, align 8
  %2521 = inttoptr i64 %2519 to i32*
  %2522 = load i32, i32* %2521, align 4
  %2523 = sext i32 %2522 to i64
  %2524 = mul nsw i64 %2523, 520
  store i64 %2524, i64* %RCX, align 8, !tbaa !2428
  %2525 = lshr i64 %2524, 63
  %2526 = add i64 %2524, %2518
  store i64 %2526, i64* %RAX, align 8, !tbaa !2428
  %2527 = icmp ult i64 %2526, %2518
  %2528 = icmp ult i64 %2526, %2524
  %2529 = or i1 %2527, %2528
  %2530 = zext i1 %2529 to i8
  store i8 %2530, i8* %42, align 1, !tbaa !2432
  %2531 = trunc i64 %2526 to i32
  %2532 = and i32 %2531, 255
  %2533 = tail call i32 @llvm.ctpop.i32(i32 %2532) #8
  %2534 = trunc i32 %2533 to i8
  %2535 = and i8 %2534, 1
  %2536 = xor i8 %2535, 1
  store i8 %2536, i8* %49, align 1, !tbaa !2446
  %2537 = xor i64 %2524, %2518
  %2538 = xor i64 %2537, %2526
  %2539 = lshr i64 %2538, 4
  %2540 = trunc i64 %2539 to i8
  %2541 = and i8 %2540, 1
  store i8 %2541, i8* %54, align 1, !tbaa !2447
  %2542 = icmp eq i64 %2526, 0
  %2543 = zext i1 %2542 to i8
  store i8 %2543, i8* %57, align 1, !tbaa !2448
  %2544 = lshr i64 %2526, 63
  %2545 = trunc i64 %2544 to i8
  store i8 %2545, i8* %60, align 1, !tbaa !2449
  %2546 = lshr i64 %2518, 63
  %2547 = xor i64 %2544, %2546
  %2548 = xor i64 %2544, %2525
  %2549 = add nuw nsw i64 %2547, %2548
  %2550 = icmp eq i64 %2549, 2
  %2551 = zext i1 %2550 to i8
  store i8 %2551, i8* %66, align 1, !tbaa !2450
  %2552 = add i64 %401, 63
  store i64 %2552, i64* %PC, align 8
  %2553 = load i32, i32* %2507, align 4
  %2554 = sext i32 %2553 to i64
  store i64 %2554, i64* %RCX, align 8, !tbaa !2428
  %2555 = shl nsw i64 %2554, 3
  %2556 = add i64 %2555, %2526
  %2557 = add i64 %401, 68
  store i64 %2557, i64* %PC, align 8
  %2558 = inttoptr i64 %2556 to double*
  %2559 = load double, double* %2558, align 8
  %2560 = fsub double %2514, %2559
  store double %2560, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %2561 = load i64, i64* %RBP, align 8
  %2562 = add i64 %2561, 40
  %2563 = add i64 %401, 72
  store i64 %2563, i64* %PC, align 8
  %2564 = inttoptr i64 %2562 to i64*
  %2565 = load i64, i64* %2564, align 8
  store i64 %2565, i64* %RAX, align 8, !tbaa !2428
  %2566 = add i64 %2561, -100
  %2567 = add i64 %401, 76
  store i64 %2567, i64* %PC, align 8
  %2568 = inttoptr i64 %2566 to i32*
  %2569 = load i32, i32* %2568, align 4
  %2570 = sext i32 %2569 to i64
  %2571 = mul nsw i64 %2570, 33800
  store i64 %2571, i64* %RCX, align 8, !tbaa !2428
  %2572 = lshr i64 %2571, 63
  %2573 = add i64 %2571, %2565
  store i64 %2573, i64* %RAX, align 8, !tbaa !2428
  %2574 = icmp ult i64 %2573, %2565
  %2575 = icmp ult i64 %2573, %2571
  %2576 = or i1 %2574, %2575
  %2577 = zext i1 %2576 to i8
  store i8 %2577, i8* %42, align 1, !tbaa !2432
  %2578 = trunc i64 %2573 to i32
  %2579 = and i32 %2578, 255
  %2580 = tail call i32 @llvm.ctpop.i32(i32 %2579) #8
  %2581 = trunc i32 %2580 to i8
  %2582 = and i8 %2581, 1
  %2583 = xor i8 %2582, 1
  store i8 %2583, i8* %49, align 1, !tbaa !2446
  %2584 = xor i64 %2571, %2565
  %2585 = xor i64 %2584, %2573
  %2586 = lshr i64 %2585, 4
  %2587 = trunc i64 %2586 to i8
  %2588 = and i8 %2587, 1
  store i8 %2588, i8* %54, align 1, !tbaa !2447
  %2589 = icmp eq i64 %2573, 0
  %2590 = zext i1 %2589 to i8
  store i8 %2590, i8* %57, align 1, !tbaa !2448
  %2591 = lshr i64 %2573, 63
  %2592 = trunc i64 %2591 to i8
  store i8 %2592, i8* %60, align 1, !tbaa !2449
  %2593 = lshr i64 %2565, 63
  %2594 = xor i64 %2591, %2593
  %2595 = xor i64 %2591, %2572
  %2596 = add nuw nsw i64 %2594, %2595
  %2597 = icmp eq i64 %2596, 2
  %2598 = zext i1 %2597 to i8
  store i8 %2598, i8* %66, align 1, !tbaa !2450
  %2599 = add i64 %2561, -52
  %2600 = add i64 %401, 90
  store i64 %2600, i64* %PC, align 8
  %2601 = inttoptr i64 %2599 to i32*
  %2602 = load i32, i32* %2601, align 4
  %2603 = sext i32 %2602 to i64
  %2604 = mul nsw i64 %2603, 520
  store i64 %2604, i64* %RCX, align 8, !tbaa !2428
  %2605 = lshr i64 %2604, 63
  %2606 = add i64 %2604, %2573
  store i64 %2606, i64* %RAX, align 8, !tbaa !2428
  %2607 = icmp ult i64 %2606, %2573
  %2608 = icmp ult i64 %2606, %2604
  %2609 = or i1 %2607, %2608
  %2610 = zext i1 %2609 to i8
  store i8 %2610, i8* %42, align 1, !tbaa !2432
  %2611 = trunc i64 %2606 to i32
  %2612 = and i32 %2611, 255
  %2613 = tail call i32 @llvm.ctpop.i32(i32 %2612) #8
  %2614 = trunc i32 %2613 to i8
  %2615 = and i8 %2614, 1
  %2616 = xor i8 %2615, 1
  store i8 %2616, i8* %49, align 1, !tbaa !2446
  %2617 = xor i64 %2604, %2573
  %2618 = xor i64 %2617, %2606
  %2619 = lshr i64 %2618, 4
  %2620 = trunc i64 %2619 to i8
  %2621 = and i8 %2620, 1
  store i8 %2621, i8* %54, align 1, !tbaa !2447
  %2622 = icmp eq i64 %2606, 0
  %2623 = zext i1 %2622 to i8
  store i8 %2623, i8* %57, align 1, !tbaa !2448
  %2624 = lshr i64 %2606, 63
  %2625 = trunc i64 %2624 to i8
  store i8 %2625, i8* %60, align 1, !tbaa !2449
  %2626 = xor i64 %2624, %2591
  %2627 = xor i64 %2624, %2605
  %2628 = add nuw nsw i64 %2626, %2627
  %2629 = icmp eq i64 %2628, 2
  %2630 = zext i1 %2629 to i8
  store i8 %2630, i8* %66, align 1, !tbaa !2450
  %2631 = load i64, i64* %RBP, align 8
  %2632 = add i64 %2631, -108
  %2633 = add i64 %401, 103
  store i64 %2633, i64* %PC, align 8
  %2634 = inttoptr i64 %2632 to i32*
  %2635 = load i32, i32* %2634, align 4
  %2636 = add i32 %2635, 1
  %2637 = zext i32 %2636 to i64
  store i64 %2637, i64* %RDX, align 8, !tbaa !2428
  %2638 = icmp eq i32 %2635, -1
  %2639 = icmp eq i32 %2636, 0
  %2640 = or i1 %2638, %2639
  %2641 = zext i1 %2640 to i8
  store i8 %2641, i8* %42, align 1, !tbaa !2432
  %2642 = and i32 %2636, 255
  %2643 = tail call i32 @llvm.ctpop.i32(i32 %2642) #8
  %2644 = trunc i32 %2643 to i8
  %2645 = and i8 %2644, 1
  %2646 = xor i8 %2645, 1
  store i8 %2646, i8* %49, align 1, !tbaa !2446
  %2647 = xor i32 %2635, %2636
  %2648 = lshr i32 %2647, 4
  %2649 = trunc i32 %2648 to i8
  %2650 = and i8 %2649, 1
  store i8 %2650, i8* %54, align 1, !tbaa !2447
  %2651 = zext i1 %2639 to i8
  store i8 %2651, i8* %57, align 1, !tbaa !2448
  %2652 = lshr i32 %2636, 31
  %2653 = trunc i32 %2652 to i8
  store i8 %2653, i8* %60, align 1, !tbaa !2449
  %2654 = lshr i32 %2635, 31
  %2655 = xor i32 %2652, %2654
  %2656 = add nuw nsw i32 %2655, %2652
  %2657 = icmp eq i32 %2656, 2
  %2658 = zext i1 %2657 to i8
  store i8 %2658, i8* %66, align 1, !tbaa !2450
  %2659 = sext i32 %2636 to i64
  store i64 %2659, i64* %RCX, align 8, !tbaa !2428
  %2660 = shl nsw i64 %2659, 3
  %2661 = add i64 %2660, %2606
  %2662 = add i64 %401, 114
  store i64 %2662, i64* %PC, align 8
  %2663 = load double, double* %228, align 1
  %2664 = inttoptr i64 %2661 to double*
  %2665 = load double, double* %2664, align 8
  %2666 = fadd double %2663, %2665
  store double %2666, double* %228, align 1, !tbaa !2452
  %2667 = add i64 %2631, 40
  %2668 = add i64 %401, 118
  store i64 %2668, i64* %PC, align 8
  %2669 = inttoptr i64 %2667 to i64*
  %2670 = load i64, i64* %2669, align 8
  store i64 %2670, i64* %RAX, align 8, !tbaa !2428
  %2671 = add i64 %2631, -100
  %2672 = add i64 %401, 122
  store i64 %2672, i64* %PC, align 8
  %2673 = inttoptr i64 %2671 to i32*
  %2674 = load i32, i32* %2673, align 4
  %2675 = sext i32 %2674 to i64
  %2676 = mul nsw i64 %2675, 33800
  store i64 %2676, i64* %RCX, align 8, !tbaa !2428
  %2677 = lshr i64 %2676, 63
  %2678 = add i64 %2676, %2670
  store i64 %2678, i64* %RAX, align 8, !tbaa !2428
  %2679 = icmp ult i64 %2678, %2670
  %2680 = icmp ult i64 %2678, %2676
  %2681 = or i1 %2679, %2680
  %2682 = zext i1 %2681 to i8
  store i8 %2682, i8* %42, align 1, !tbaa !2432
  %2683 = trunc i64 %2678 to i32
  %2684 = and i32 %2683, 255
  %2685 = tail call i32 @llvm.ctpop.i32(i32 %2684) #8
  %2686 = trunc i32 %2685 to i8
  %2687 = and i8 %2686, 1
  %2688 = xor i8 %2687, 1
  store i8 %2688, i8* %49, align 1, !tbaa !2446
  %2689 = xor i64 %2676, %2670
  %2690 = xor i64 %2689, %2678
  %2691 = lshr i64 %2690, 4
  %2692 = trunc i64 %2691 to i8
  %2693 = and i8 %2692, 1
  store i8 %2693, i8* %54, align 1, !tbaa !2447
  %2694 = icmp eq i64 %2678, 0
  %2695 = zext i1 %2694 to i8
  store i8 %2695, i8* %57, align 1, !tbaa !2448
  %2696 = lshr i64 %2678, 63
  %2697 = trunc i64 %2696 to i8
  store i8 %2697, i8* %60, align 1, !tbaa !2449
  %2698 = lshr i64 %2670, 63
  %2699 = xor i64 %2696, %2698
  %2700 = xor i64 %2696, %2677
  %2701 = add nuw nsw i64 %2699, %2700
  %2702 = icmp eq i64 %2701, 2
  %2703 = zext i1 %2702 to i8
  store i8 %2703, i8* %66, align 1, !tbaa !2450
  %2704 = load i64, i64* %RBP, align 8
  %2705 = add i64 %2704, -52
  %2706 = add i64 %401, 136
  store i64 %2706, i64* %PC, align 8
  %2707 = inttoptr i64 %2705 to i32*
  %2708 = load i32, i32* %2707, align 4
  %2709 = sext i32 %2708 to i64
  %2710 = mul nsw i64 %2709, 520
  store i64 %2710, i64* %RCX, align 8, !tbaa !2428
  %2711 = lshr i64 %2710, 63
  %2712 = add i64 %2710, %2678
  store i64 %2712, i64* %RAX, align 8, !tbaa !2428
  %2713 = icmp ult i64 %2712, %2678
  %2714 = icmp ult i64 %2712, %2710
  %2715 = or i1 %2713, %2714
  %2716 = zext i1 %2715 to i8
  store i8 %2716, i8* %42, align 1, !tbaa !2432
  %2717 = trunc i64 %2712 to i32
  %2718 = and i32 %2717, 255
  %2719 = tail call i32 @llvm.ctpop.i32(i32 %2718) #8
  %2720 = trunc i32 %2719 to i8
  %2721 = and i8 %2720, 1
  %2722 = xor i8 %2721, 1
  store i8 %2722, i8* %49, align 1, !tbaa !2446
  %2723 = xor i64 %2710, %2678
  %2724 = xor i64 %2723, %2712
  %2725 = lshr i64 %2724, 4
  %2726 = trunc i64 %2725 to i8
  %2727 = and i8 %2726, 1
  store i8 %2727, i8* %54, align 1, !tbaa !2447
  %2728 = icmp eq i64 %2712, 0
  %2729 = zext i1 %2728 to i8
  store i8 %2729, i8* %57, align 1, !tbaa !2448
  %2730 = lshr i64 %2712, 63
  %2731 = trunc i64 %2730 to i8
  store i8 %2731, i8* %60, align 1, !tbaa !2449
  %2732 = xor i64 %2730, %2696
  %2733 = xor i64 %2730, %2711
  %2734 = add nuw nsw i64 %2732, %2733
  %2735 = icmp eq i64 %2734, 2
  %2736 = zext i1 %2735 to i8
  store i8 %2736, i8* %66, align 1, !tbaa !2450
  %2737 = add i64 %2704, -108
  %2738 = add i64 %401, 150
  store i64 %2738, i64* %PC, align 8
  %2739 = inttoptr i64 %2737 to i32*
  %2740 = load i32, i32* %2739, align 4
  %2741 = sext i32 %2740 to i64
  store i64 %2741, i64* %RCX, align 8, !tbaa !2428
  %2742 = shl nsw i64 %2741, 3
  %2743 = add i64 %2742, %2712
  %2744 = add i64 %401, 155
  store i64 %2744, i64* %PC, align 8
  %2745 = load double, double* %228, align 1
  %2746 = inttoptr i64 %2743 to double*
  %2747 = load double, double* %2746, align 8
  %2748 = fsub double %2745, %2747
  store double %2748, double* %228, align 1, !tbaa !2452
  %2749 = add i64 %2704, -96
  %2750 = add i64 %401, 159
  store i64 %2750, i64* %PC, align 8
  %2751 = inttoptr i64 %2749 to i64*
  %2752 = load i64, i64* %2751, align 8
  store i64 %2752, i64* %RAX, align 8, !tbaa !2428
  %2753 = add i64 %2704, -100
  %2754 = add i64 %401, 163
  store i64 %2754, i64* %PC, align 8
  %2755 = inttoptr i64 %2753 to i32*
  %2756 = load i32, i32* %2755, align 4
  %2757 = sext i32 %2756 to i64
  %2758 = mul nsw i64 %2757, 520
  store i64 %2758, i64* %RCX, align 8, !tbaa !2428
  %2759 = lshr i64 %2758, 63
  %2760 = add i64 %2758, %2752
  store i64 %2760, i64* %RAX, align 8, !tbaa !2428
  %2761 = icmp ult i64 %2760, %2752
  %2762 = icmp ult i64 %2760, %2758
  %2763 = or i1 %2761, %2762
  %2764 = zext i1 %2763 to i8
  store i8 %2764, i8* %42, align 1, !tbaa !2432
  %2765 = trunc i64 %2760 to i32
  %2766 = and i32 %2765, 255
  %2767 = tail call i32 @llvm.ctpop.i32(i32 %2766) #8
  %2768 = trunc i32 %2767 to i8
  %2769 = and i8 %2768, 1
  %2770 = xor i8 %2769, 1
  store i8 %2770, i8* %49, align 1, !tbaa !2446
  %2771 = xor i64 %2758, %2752
  %2772 = xor i64 %2771, %2760
  %2773 = lshr i64 %2772, 4
  %2774 = trunc i64 %2773 to i8
  %2775 = and i8 %2774, 1
  store i8 %2775, i8* %54, align 1, !tbaa !2447
  %2776 = icmp eq i64 %2760, 0
  %2777 = zext i1 %2776 to i8
  store i8 %2777, i8* %57, align 1, !tbaa !2448
  %2778 = lshr i64 %2760, 63
  %2779 = trunc i64 %2778 to i8
  store i8 %2779, i8* %60, align 1, !tbaa !2449
  %2780 = lshr i64 %2752, 63
  %2781 = xor i64 %2778, %2780
  %2782 = xor i64 %2778, %2759
  %2783 = add nuw nsw i64 %2781, %2782
  %2784 = icmp eq i64 %2783, 2
  %2785 = zext i1 %2784 to i8
  store i8 %2785, i8* %66, align 1, !tbaa !2450
  %2786 = load i64, i64* %RBP, align 8
  %2787 = add i64 %2786, -104
  %2788 = add i64 %401, 177
  store i64 %2788, i64* %PC, align 8
  %2789 = inttoptr i64 %2787 to i32*
  %2790 = load i32, i32* %2789, align 4
  %2791 = sext i32 %2790 to i64
  store i64 %2791, i64* %RCX, align 8, !tbaa !2428
  %2792 = shl nsw i64 %2791, 3
  %2793 = add i64 %2792, %2760
  %2794 = add i64 %401, 182
  store i64 %2794, i64* %PC, align 8
  %2795 = inttoptr i64 %2793 to double*
  store double %2748, double* %2795, align 8
  %2796 = load i64, i64* %RBP, align 8
  %2797 = add i64 %2796, 88
  %2798 = load i64, i64* %PC, align 8
  %2799 = add i64 %2798, 4
  store i64 %2799, i64* %PC, align 8
  %2800 = inttoptr i64 %2797 to i64*
  %2801 = load i64, i64* %2800, align 8
  store i64 %2801, i64* %RAX, align 8, !tbaa !2428
  %2802 = add i64 %2796, -52
  %2803 = add i64 %2798, 8
  store i64 %2803, i64* %PC, align 8
  %2804 = inttoptr i64 %2802 to i32*
  %2805 = load i32, i32* %2804, align 4
  %2806 = sext i32 %2805 to i64
  store i64 %2806, i64* %RCX, align 8, !tbaa !2428
  %2807 = shl nsw i64 %2806, 3
  %2808 = add i64 %2807, %2801
  %2809 = add i64 %2798, 13
  store i64 %2809, i64* %PC, align 8
  %2810 = inttoptr i64 %2808 to double*
  %2811 = load double, double* %2810, align 8
  store double %2811, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %2812 = add i64 %2796, 96
  %2813 = add i64 %2798, 17
  store i64 %2813, i64* %PC, align 8
  %2814 = inttoptr i64 %2812 to i64*
  %2815 = load i64, i64* %2814, align 8
  store i64 %2815, i64* %RAX, align 8, !tbaa !2428
  %2816 = add i64 %2796, -104
  %2817 = add i64 %2798, 21
  store i64 %2817, i64* %PC, align 8
  %2818 = inttoptr i64 %2816 to i32*
  %2819 = load i32, i32* %2818, align 4
  %2820 = sext i32 %2819 to i64
  store i64 %2820, i64* %RCX, align 8, !tbaa !2428
  %2821 = shl nsw i64 %2820, 3
  %2822 = add i64 %2821, %2815
  %2823 = add i64 %2798, 26
  store i64 %2823, i64* %PC, align 8
  %2824 = inttoptr i64 %2822 to double*
  %2825 = load double, double* %2824, align 8
  %2826 = fdiv double %2811, %2825
  store double %2826, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %2827 = add i64 %2796, 24
  %2828 = add i64 %2798, 30
  store i64 %2828, i64* %PC, align 8
  %2829 = inttoptr i64 %2827 to i64*
  %2830 = load i64, i64* %2829, align 8
  store i64 %2830, i64* %RAX, align 8, !tbaa !2428
  %2831 = add i64 %2796, -100
  %2832 = add i64 %2798, 34
  store i64 %2832, i64* %PC, align 8
  %2833 = inttoptr i64 %2831 to i32*
  %2834 = load i32, i32* %2833, align 4
  %2835 = sext i32 %2834 to i64
  %2836 = mul nsw i64 %2835, 33800
  store i64 %2836, i64* %RCX, align 8, !tbaa !2428
  %2837 = lshr i64 %2836, 63
  %2838 = add i64 %2836, %2830
  store i64 %2838, i64* %RAX, align 8, !tbaa !2428
  %2839 = icmp ult i64 %2838, %2830
  %2840 = icmp ult i64 %2838, %2836
  %2841 = or i1 %2839, %2840
  %2842 = zext i1 %2841 to i8
  store i8 %2842, i8* %42, align 1, !tbaa !2432
  %2843 = trunc i64 %2838 to i32
  %2844 = and i32 %2843, 255
  %2845 = tail call i32 @llvm.ctpop.i32(i32 %2844) #8
  %2846 = trunc i32 %2845 to i8
  %2847 = and i8 %2846, 1
  %2848 = xor i8 %2847, 1
  store i8 %2848, i8* %49, align 1, !tbaa !2446
  %2849 = xor i64 %2836, %2830
  %2850 = xor i64 %2849, %2838
  %2851 = lshr i64 %2850, 4
  %2852 = trunc i64 %2851 to i8
  %2853 = and i8 %2852, 1
  store i8 %2853, i8* %54, align 1, !tbaa !2447
  %2854 = icmp eq i64 %2838, 0
  %2855 = zext i1 %2854 to i8
  store i8 %2855, i8* %57, align 1, !tbaa !2448
  %2856 = lshr i64 %2838, 63
  %2857 = trunc i64 %2856 to i8
  store i8 %2857, i8* %60, align 1, !tbaa !2449
  %2858 = lshr i64 %2830, 63
  %2859 = xor i64 %2856, %2858
  %2860 = xor i64 %2856, %2837
  %2861 = add nuw nsw i64 %2859, %2860
  %2862 = icmp eq i64 %2861, 2
  %2863 = zext i1 %2862 to i8
  store i8 %2863, i8* %66, align 1, !tbaa !2450
  %2864 = load i64, i64* %RBP, align 8
  %2865 = add i64 %2864, -104
  %2866 = add i64 %2798, 48
  store i64 %2866, i64* %PC, align 8
  %2867 = inttoptr i64 %2865 to i32*
  %2868 = load i32, i32* %2867, align 4
  %2869 = sext i32 %2868 to i64
  %2870 = mul nsw i64 %2869, 520
  store i64 %2870, i64* %RCX, align 8, !tbaa !2428
  %2871 = lshr i64 %2870, 63
  %2872 = add i64 %2870, %2838
  store i64 %2872, i64* %RAX, align 8, !tbaa !2428
  %2873 = icmp ult i64 %2872, %2838
  %2874 = icmp ult i64 %2872, %2870
  %2875 = or i1 %2873, %2874
  %2876 = zext i1 %2875 to i8
  store i8 %2876, i8* %42, align 1, !tbaa !2432
  %2877 = trunc i64 %2872 to i32
  %2878 = and i32 %2877, 255
  %2879 = tail call i32 @llvm.ctpop.i32(i32 %2878) #8
  %2880 = trunc i32 %2879 to i8
  %2881 = and i8 %2880, 1
  %2882 = xor i8 %2881, 1
  store i8 %2882, i8* %49, align 1, !tbaa !2446
  %2883 = xor i64 %2870, %2838
  %2884 = xor i64 %2883, %2872
  %2885 = lshr i64 %2884, 4
  %2886 = trunc i64 %2885 to i8
  %2887 = and i8 %2886, 1
  store i8 %2887, i8* %54, align 1, !tbaa !2447
  %2888 = icmp eq i64 %2872, 0
  %2889 = zext i1 %2888 to i8
  store i8 %2889, i8* %57, align 1, !tbaa !2448
  %2890 = lshr i64 %2872, 63
  %2891 = trunc i64 %2890 to i8
  store i8 %2891, i8* %60, align 1, !tbaa !2449
  %2892 = xor i64 %2890, %2856
  %2893 = xor i64 %2890, %2871
  %2894 = add nuw nsw i64 %2892, %2893
  %2895 = icmp eq i64 %2894, 2
  %2896 = zext i1 %2895 to i8
  store i8 %2896, i8* %66, align 1, !tbaa !2450
  %2897 = add i64 %2864, -108
  %2898 = add i64 %2798, 62
  store i64 %2898, i64* %PC, align 8
  %2899 = inttoptr i64 %2897 to i32*
  %2900 = load i32, i32* %2899, align 4
  %2901 = sext i32 %2900 to i64
  store i64 %2901, i64* %RCX, align 8, !tbaa !2428
  %2902 = shl nsw i64 %2901, 3
  %2903 = add i64 %2902, %2872
  %2904 = add i64 %2798, 67
  store i64 %2904, i64* %PC, align 8
  %2905 = load double, double* %228, align 1
  %2906 = inttoptr i64 %2903 to double*
  %2907 = load double, double* %2906, align 8
  %2908 = fmul double %2905, %2907
  store double %2908, double* %228, align 1, !tbaa !2452
  %2909 = add i64 %2864, -72
  %2910 = add i64 %2798, 72
  store i64 %2910, i64* %PC, align 8
  %2911 = inttoptr i64 %2909 to double*
  %2912 = load double, double* %2911, align 8
  store double %2912, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %2913 = add i64 %2864, 96
  %2914 = add i64 %2798, 76
  store i64 %2914, i64* %PC, align 8
  %2915 = inttoptr i64 %2913 to i64*
  %2916 = load i64, i64* %2915, align 8
  store i64 %2916, i64* %RAX, align 8, !tbaa !2428
  %2917 = add i64 %2798, 80
  store i64 %2917, i64* %PC, align 8
  %2918 = load i32, i32* %2867, align 4
  %2919 = sext i32 %2918 to i64
  store i64 %2919, i64* %RCX, align 8, !tbaa !2428
  %2920 = shl nsw i64 %2919, 3
  %2921 = add i64 %2920, %2916
  %2922 = add i64 %2798, 85
  store i64 %2922, i64* %PC, align 8
  %2923 = inttoptr i64 %2921 to double*
  %2924 = load double, double* %2923, align 8
  %2925 = fdiv double %2912, %2924
  store double %2925, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %2926 = load i64, i64* %RBP, align 8
  %2927 = add i64 %2926, -96
  %2928 = add i64 %2798, 89
  store i64 %2928, i64* %PC, align 8
  %2929 = inttoptr i64 %2927 to i64*
  %2930 = load i64, i64* %2929, align 8
  store i64 %2930, i64* %RAX, align 8, !tbaa !2428
  %2931 = add i64 %2926, -100
  %2932 = add i64 %2798, 93
  store i64 %2932, i64* %PC, align 8
  %2933 = inttoptr i64 %2931 to i32*
  %2934 = load i32, i32* %2933, align 4
  %2935 = sext i32 %2934 to i64
  %2936 = mul nsw i64 %2935, 520
  store i64 %2936, i64* %RCX, align 8, !tbaa !2428
  %2937 = lshr i64 %2936, 63
  %2938 = add i64 %2936, %2930
  store i64 %2938, i64* %RAX, align 8, !tbaa !2428
  %2939 = icmp ult i64 %2938, %2930
  %2940 = icmp ult i64 %2938, %2936
  %2941 = or i1 %2939, %2940
  %2942 = zext i1 %2941 to i8
  store i8 %2942, i8* %42, align 1, !tbaa !2432
  %2943 = trunc i64 %2938 to i32
  %2944 = and i32 %2943, 255
  %2945 = tail call i32 @llvm.ctpop.i32(i32 %2944) #8
  %2946 = trunc i32 %2945 to i8
  %2947 = and i8 %2946, 1
  %2948 = xor i8 %2947, 1
  store i8 %2948, i8* %49, align 1, !tbaa !2446
  %2949 = xor i64 %2936, %2930
  %2950 = xor i64 %2949, %2938
  %2951 = lshr i64 %2950, 4
  %2952 = trunc i64 %2951 to i8
  %2953 = and i8 %2952, 1
  store i8 %2953, i8* %54, align 1, !tbaa !2447
  %2954 = icmp eq i64 %2938, 0
  %2955 = zext i1 %2954 to i8
  store i8 %2955, i8* %57, align 1, !tbaa !2448
  %2956 = lshr i64 %2938, 63
  %2957 = trunc i64 %2956 to i8
  store i8 %2957, i8* %60, align 1, !tbaa !2449
  %2958 = lshr i64 %2930, 63
  %2959 = xor i64 %2956, %2958
  %2960 = xor i64 %2956, %2937
  %2961 = add nuw nsw i64 %2959, %2960
  %2962 = icmp eq i64 %2961, 2
  %2963 = zext i1 %2962 to i8
  store i8 %2963, i8* %66, align 1, !tbaa !2450
  %2964 = add i64 %2926, -104
  %2965 = add i64 %2798, 107
  store i64 %2965, i64* %PC, align 8
  %2966 = inttoptr i64 %2964 to i32*
  %2967 = load i32, i32* %2966, align 4
  %2968 = sext i32 %2967 to i64
  store i64 %2968, i64* %RCX, align 8, !tbaa !2428
  %2969 = shl nsw i64 %2968, 3
  %2970 = add i64 %2969, %2938
  %2971 = add i64 %2798, 112
  store i64 %2971, i64* %PC, align 8
  %2972 = inttoptr i64 %2970 to double*
  %2973 = load double, double* %2972, align 8
  %2974 = fmul double %2925, %2973
  store double %2974, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %2975 = load double, double* %228, align 1
  %2976 = fsub double %2975, %2974
  store double %2976, double* %228, align 1, !tbaa !2452
  %2977 = add i64 %2926, 16
  %2978 = add i64 %2798, 120
  store i64 %2978, i64* %PC, align 8
  %2979 = inttoptr i64 %2977 to i64*
  %2980 = load i64, i64* %2979, align 8
  store i64 %2980, i64* %RAX, align 8, !tbaa !2428
  %2981 = load i64, i64* %RBP, align 8
  %2982 = add i64 %2981, -100
  %2983 = add i64 %2798, 124
  store i64 %2983, i64* %PC, align 8
  %2984 = inttoptr i64 %2982 to i32*
  %2985 = load i32, i32* %2984, align 4
  %2986 = sext i32 %2985 to i64
  %2987 = mul nsw i64 %2986, 520
  store i64 %2987, i64* %RCX, align 8, !tbaa !2428
  %2988 = lshr i64 %2987, 63
  %2989 = add i64 %2987, %2980
  store i64 %2989, i64* %RAX, align 8, !tbaa !2428
  %2990 = icmp ult i64 %2989, %2980
  %2991 = icmp ult i64 %2989, %2987
  %2992 = or i1 %2990, %2991
  %2993 = zext i1 %2992 to i8
  store i8 %2993, i8* %42, align 1, !tbaa !2432
  %2994 = trunc i64 %2989 to i32
  %2995 = and i32 %2994, 255
  %2996 = tail call i32 @llvm.ctpop.i32(i32 %2995) #8
  %2997 = trunc i32 %2996 to i8
  %2998 = and i8 %2997, 1
  %2999 = xor i8 %2998, 1
  store i8 %2999, i8* %49, align 1, !tbaa !2446
  %3000 = xor i64 %2987, %2980
  %3001 = xor i64 %3000, %2989
  %3002 = lshr i64 %3001, 4
  %3003 = trunc i64 %3002 to i8
  %3004 = and i8 %3003, 1
  store i8 %3004, i8* %54, align 1, !tbaa !2447
  %3005 = icmp eq i64 %2989, 0
  %3006 = zext i1 %3005 to i8
  store i8 %3006, i8* %57, align 1, !tbaa !2448
  %3007 = lshr i64 %2989, 63
  %3008 = trunc i64 %3007 to i8
  store i8 %3008, i8* %60, align 1, !tbaa !2449
  %3009 = lshr i64 %2980, 63
  %3010 = xor i64 %3007, %3009
  %3011 = xor i64 %3007, %2988
  %3012 = add nuw nsw i64 %3010, %3011
  %3013 = icmp eq i64 %3012, 2
  %3014 = zext i1 %3013 to i8
  store i8 %3014, i8* %66, align 1, !tbaa !2450
  %3015 = add i64 %2981, -104
  %3016 = add i64 %2798, 138
  store i64 %3016, i64* %PC, align 8
  %3017 = inttoptr i64 %3015 to i32*
  %3018 = load i32, i32* %3017, align 4
  %3019 = sext i32 %3018 to i64
  store i64 %3019, i64* %RCX, align 8, !tbaa !2428
  %3020 = shl nsw i64 %3019, 3
  %3021 = add i64 %3020, %2989
  %3022 = add i64 %2798, 143
  store i64 %3022, i64* %PC, align 8
  %3023 = inttoptr i64 %3021 to double*
  store double %2976, double* %3023, align 8
  %3024 = load i64, i64* %RBP, align 8
  %3025 = add i64 %3024, 72
  %3026 = load i64, i64* %PC, align 8
  %3027 = add i64 %3026, 4
  store i64 %3027, i64* %PC, align 8
  %3028 = inttoptr i64 %3025 to i64*
  %3029 = load i64, i64* %3028, align 8
  store i64 %3029, i64* %RAX, align 8, !tbaa !2428
  %3030 = add i64 %3024, -108
  %3031 = add i64 %3026, 8
  store i64 %3031, i64* %PC, align 8
  %3032 = inttoptr i64 %3030 to i32*
  %3033 = load i32, i32* %3032, align 4
  %3034 = sext i32 %3033 to i64
  store i64 %3034, i64* %RCX, align 8, !tbaa !2428
  %3035 = shl nsw i64 %3034, 3
  %3036 = add i64 %3035, %3029
  %3037 = add i64 %3026, 13
  store i64 %3037, i64* %PC, align 8
  %3038 = inttoptr i64 %3036 to double*
  %3039 = load double, double* %3038, align 8
  store double %3039, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %3040 = add i64 %3024, 80
  %3041 = add i64 %3026, 17
  store i64 %3041, i64* %PC, align 8
  %3042 = inttoptr i64 %3040 to i64*
  %3043 = load i64, i64* %3042, align 8
  store i64 %3043, i64* %RAX, align 8, !tbaa !2428
  %3044 = add i64 %3026, 21
  store i64 %3044, i64* %PC, align 8
  %3045 = load i32, i32* %3032, align 4
  %3046 = sext i32 %3045 to i64
  store i64 %3046, i64* %RCX, align 8, !tbaa !2428
  %3047 = shl nsw i64 %3046, 3
  %3048 = add i64 %3047, %3043
  %3049 = add i64 %3026, 26
  store i64 %3049, i64* %PC, align 8
  %3050 = inttoptr i64 %3048 to double*
  %3051 = load double, double* %3050, align 8
  %3052 = fdiv double %3039, %3051
  store double %3052, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %3053 = add i64 %3024, 48
  %3054 = add i64 %3026, 30
  store i64 %3054, i64* %PC, align 8
  %3055 = inttoptr i64 %3053 to i64*
  %3056 = load i64, i64* %3055, align 8
  store i64 %3056, i64* %RAX, align 8, !tbaa !2428
  %3057 = add i64 %3024, -100
  %3058 = add i64 %3026, 34
  store i64 %3058, i64* %PC, align 8
  %3059 = inttoptr i64 %3057 to i32*
  %3060 = load i32, i32* %3059, align 4
  %3061 = sext i32 %3060 to i64
  %3062 = mul nsw i64 %3061, 33800
  store i64 %3062, i64* %RCX, align 8, !tbaa !2428
  %3063 = lshr i64 %3062, 63
  %3064 = add i64 %3062, %3056
  store i64 %3064, i64* %RAX, align 8, !tbaa !2428
  %3065 = icmp ult i64 %3064, %3056
  %3066 = icmp ult i64 %3064, %3062
  %3067 = or i1 %3065, %3066
  %3068 = zext i1 %3067 to i8
  store i8 %3068, i8* %42, align 1, !tbaa !2432
  %3069 = trunc i64 %3064 to i32
  %3070 = and i32 %3069, 255
  %3071 = tail call i32 @llvm.ctpop.i32(i32 %3070) #8
  %3072 = trunc i32 %3071 to i8
  %3073 = and i8 %3072, 1
  %3074 = xor i8 %3073, 1
  store i8 %3074, i8* %49, align 1, !tbaa !2446
  %3075 = xor i64 %3062, %3056
  %3076 = xor i64 %3075, %3064
  %3077 = lshr i64 %3076, 4
  %3078 = trunc i64 %3077 to i8
  %3079 = and i8 %3078, 1
  store i8 %3079, i8* %54, align 1, !tbaa !2447
  %3080 = icmp eq i64 %3064, 0
  %3081 = zext i1 %3080 to i8
  store i8 %3081, i8* %57, align 1, !tbaa !2448
  %3082 = lshr i64 %3064, 63
  %3083 = trunc i64 %3082 to i8
  store i8 %3083, i8* %60, align 1, !tbaa !2449
  %3084 = lshr i64 %3056, 63
  %3085 = xor i64 %3082, %3084
  %3086 = xor i64 %3082, %3063
  %3087 = add nuw nsw i64 %3085, %3086
  %3088 = icmp eq i64 %3087, 2
  %3089 = zext i1 %3088 to i8
  store i8 %3089, i8* %66, align 1, !tbaa !2450
  %3090 = load i64, i64* %RBP, align 8
  %3091 = add i64 %3090, -52
  %3092 = add i64 %3026, 48
  store i64 %3092, i64* %PC, align 8
  %3093 = inttoptr i64 %3091 to i32*
  %3094 = load i32, i32* %3093, align 4
  %3095 = sext i32 %3094 to i64
  %3096 = mul nsw i64 %3095, 520
  store i64 %3096, i64* %RCX, align 8, !tbaa !2428
  %3097 = lshr i64 %3096, 63
  %3098 = add i64 %3096, %3064
  store i64 %3098, i64* %RAX, align 8, !tbaa !2428
  %3099 = icmp ult i64 %3098, %3064
  %3100 = icmp ult i64 %3098, %3096
  %3101 = or i1 %3099, %3100
  %3102 = zext i1 %3101 to i8
  store i8 %3102, i8* %42, align 1, !tbaa !2432
  %3103 = trunc i64 %3098 to i32
  %3104 = and i32 %3103, 255
  %3105 = tail call i32 @llvm.ctpop.i32(i32 %3104) #8
  %3106 = trunc i32 %3105 to i8
  %3107 = and i8 %3106, 1
  %3108 = xor i8 %3107, 1
  store i8 %3108, i8* %49, align 1, !tbaa !2446
  %3109 = xor i64 %3096, %3064
  %3110 = xor i64 %3109, %3098
  %3111 = lshr i64 %3110, 4
  %3112 = trunc i64 %3111 to i8
  %3113 = and i8 %3112, 1
  store i8 %3113, i8* %54, align 1, !tbaa !2447
  %3114 = icmp eq i64 %3098, 0
  %3115 = zext i1 %3114 to i8
  store i8 %3115, i8* %57, align 1, !tbaa !2448
  %3116 = lshr i64 %3098, 63
  %3117 = trunc i64 %3116 to i8
  store i8 %3117, i8* %60, align 1, !tbaa !2449
  %3118 = xor i64 %3116, %3082
  %3119 = xor i64 %3116, %3097
  %3120 = add nuw nsw i64 %3118, %3119
  %3121 = icmp eq i64 %3120, 2
  %3122 = zext i1 %3121 to i8
  store i8 %3122, i8* %66, align 1, !tbaa !2450
  %3123 = add i64 %3090, -108
  %3124 = add i64 %3026, 62
  store i64 %3124, i64* %PC, align 8
  %3125 = inttoptr i64 %3123 to i32*
  %3126 = load i32, i32* %3125, align 4
  %3127 = sext i32 %3126 to i64
  store i64 %3127, i64* %RCX, align 8, !tbaa !2428
  %3128 = shl nsw i64 %3127, 3
  %3129 = add i64 %3128, %3098
  %3130 = add i64 %3026, 67
  store i64 %3130, i64* %PC, align 8
  %3131 = load double, double* %228, align 1
  %3132 = inttoptr i64 %3129 to double*
  %3133 = load double, double* %3132, align 8
  %3134 = fmul double %3131, %3133
  store double %3134, double* %228, align 1, !tbaa !2452
  %3135 = add i64 %3090, -64
  %3136 = add i64 %3026, 72
  store i64 %3136, i64* %PC, align 8
  %3137 = inttoptr i64 %3135 to double*
  %3138 = load double, double* %3137, align 8
  store double %3138, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %3139 = add i64 %3090, 64
  %3140 = add i64 %3026, 76
  store i64 %3140, i64* %PC, align 8
  %3141 = inttoptr i64 %3139 to i64*
  %3142 = load i64, i64* %3141, align 8
  store i64 %3142, i64* %RAX, align 8, !tbaa !2428
  %3143 = add i64 %3090, -100
  %3144 = add i64 %3026, 80
  store i64 %3144, i64* %PC, align 8
  %3145 = inttoptr i64 %3143 to i32*
  %3146 = load i32, i32* %3145, align 4
  %3147 = sext i32 %3146 to i64
  store i64 %3147, i64* %RCX, align 8, !tbaa !2428
  %3148 = shl nsw i64 %3147, 3
  %3149 = add i64 %3148, %3142
  %3150 = add i64 %3026, 85
  store i64 %3150, i64* %PC, align 8
  %3151 = inttoptr i64 %3149 to double*
  %3152 = load double, double* %3151, align 8
  %3153 = fmul double %3138, %3152
  store double %3153, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %3154 = load i64, i64* %RBP, align 8
  %3155 = add i64 %3154, 80
  %3156 = add i64 %3026, 89
  store i64 %3156, i64* %PC, align 8
  %3157 = inttoptr i64 %3155 to i64*
  %3158 = load i64, i64* %3157, align 8
  store i64 %3158, i64* %RAX, align 8, !tbaa !2428
  %3159 = add i64 %3154, -108
  %3160 = add i64 %3026, 93
  store i64 %3160, i64* %PC, align 8
  %3161 = inttoptr i64 %3159 to i32*
  %3162 = load i32, i32* %3161, align 4
  %3163 = sext i32 %3162 to i64
  store i64 %3163, i64* %RCX, align 8, !tbaa !2428
  %3164 = shl nsw i64 %3163, 3
  %3165 = add i64 %3164, %3158
  %3166 = add i64 %3026, 98
  store i64 %3166, i64* %PC, align 8
  %3167 = inttoptr i64 %3165 to double*
  %3168 = load double, double* %3167, align 8
  %3169 = fdiv double %3153, %3168
  store double %3169, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %3170 = add i64 %3154, 16
  %3171 = add i64 %3026, 102
  store i64 %3171, i64* %PC, align 8
  %3172 = inttoptr i64 %3170 to i64*
  %3173 = load i64, i64* %3172, align 8
  store i64 %3173, i64* %RAX, align 8, !tbaa !2428
  %3174 = add i64 %3154, -100
  %3175 = add i64 %3026, 106
  store i64 %3175, i64* %PC, align 8
  %3176 = inttoptr i64 %3174 to i32*
  %3177 = load i32, i32* %3176, align 4
  %3178 = sext i32 %3177 to i64
  %3179 = mul nsw i64 %3178, 520
  store i64 %3179, i64* %RCX, align 8, !tbaa !2428
  %3180 = lshr i64 %3179, 63
  %3181 = add i64 %3179, %3173
  store i64 %3181, i64* %RAX, align 8, !tbaa !2428
  %3182 = icmp ult i64 %3181, %3173
  %3183 = icmp ult i64 %3181, %3179
  %3184 = or i1 %3182, %3183
  %3185 = zext i1 %3184 to i8
  store i8 %3185, i8* %42, align 1, !tbaa !2432
  %3186 = trunc i64 %3181 to i32
  %3187 = and i32 %3186, 255
  %3188 = tail call i32 @llvm.ctpop.i32(i32 %3187) #8
  %3189 = trunc i32 %3188 to i8
  %3190 = and i8 %3189, 1
  %3191 = xor i8 %3190, 1
  store i8 %3191, i8* %49, align 1, !tbaa !2446
  %3192 = xor i64 %3179, %3173
  %3193 = xor i64 %3192, %3181
  %3194 = lshr i64 %3193, 4
  %3195 = trunc i64 %3194 to i8
  %3196 = and i8 %3195, 1
  store i8 %3196, i8* %54, align 1, !tbaa !2447
  %3197 = icmp eq i64 %3181, 0
  %3198 = zext i1 %3197 to i8
  store i8 %3198, i8* %57, align 1, !tbaa !2448
  %3199 = lshr i64 %3181, 63
  %3200 = trunc i64 %3199 to i8
  store i8 %3200, i8* %60, align 1, !tbaa !2449
  %3201 = lshr i64 %3173, 63
  %3202 = xor i64 %3199, %3201
  %3203 = xor i64 %3199, %3180
  %3204 = add nuw nsw i64 %3202, %3203
  %3205 = icmp eq i64 %3204, 2
  %3206 = zext i1 %3205 to i8
  store i8 %3206, i8* %66, align 1, !tbaa !2450
  %3207 = add i64 %3154, -104
  %3208 = add i64 %3026, 120
  store i64 %3208, i64* %PC, align 8
  %3209 = inttoptr i64 %3207 to i32*
  %3210 = load i32, i32* %3209, align 4
  %3211 = sext i32 %3210 to i64
  store i64 %3211, i64* %RCX, align 8, !tbaa !2428
  %3212 = shl nsw i64 %3211, 3
  %3213 = add i64 %3212, %3181
  %3214 = add i64 %3026, 125
  store i64 %3214, i64* %PC, align 8
  %3215 = inttoptr i64 %3213 to double*
  %3216 = load double, double* %3215, align 8
  %3217 = fmul double %3169, %3216
  store double %3217, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %3218 = load double, double* %228, align 1
  %3219 = fadd double %3218, %3217
  store double %3219, double* %228, align 1, !tbaa !2452
  %3220 = load i64, i64* %RBP, align 8
  %3221 = add i64 %3220, -64
  %3222 = add i64 %3026, 134
  store i64 %3222, i64* %PC, align 8
  %3223 = inttoptr i64 %3221 to double*
  %3224 = load double, double* %3223, align 8
  store double %3224, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %3225 = add i64 %3220, 56
  %3226 = add i64 %3026, 138
  store i64 %3226, i64* %PC, align 8
  %3227 = inttoptr i64 %3225 to i64*
  %3228 = load i64, i64* %3227, align 8
  store i64 %3228, i64* %RAX, align 8, !tbaa !2428
  %3229 = add i64 %3220, -100
  %3230 = add i64 %3026, 142
  store i64 %3230, i64* %PC, align 8
  %3231 = inttoptr i64 %3229 to i32*
  %3232 = load i32, i32* %3231, align 4
  %3233 = sext i32 %3232 to i64
  store i64 %3233, i64* %RCX, align 8, !tbaa !2428
  %3234 = shl nsw i64 %3233, 3
  %3235 = add i64 %3234, %3228
  %3236 = add i64 %3026, 147
  store i64 %3236, i64* %PC, align 8
  %3237 = inttoptr i64 %3235 to double*
  %3238 = load double, double* %3237, align 8
  %3239 = fmul double %3224, %3238
  store double %3239, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %3240 = add i64 %3220, 80
  %3241 = add i64 %3026, 151
  store i64 %3241, i64* %PC, align 8
  %3242 = inttoptr i64 %3240 to i64*
  %3243 = load i64, i64* %3242, align 8
  store i64 %3243, i64* %RAX, align 8, !tbaa !2428
  %3244 = add i64 %3220, -108
  %3245 = add i64 %3026, 155
  store i64 %3245, i64* %PC, align 8
  %3246 = inttoptr i64 %3244 to i32*
  %3247 = load i32, i32* %3246, align 4
  %3248 = sext i32 %3247 to i64
  store i64 %3248, i64* %RCX, align 8, !tbaa !2428
  %3249 = shl nsw i64 %3248, 3
  %3250 = add i64 %3249, %3243
  %3251 = add i64 %3026, 160
  store i64 %3251, i64* %PC, align 8
  %3252 = inttoptr i64 %3250 to double*
  %3253 = load double, double* %3252, align 8
  %3254 = fdiv double %3239, %3253
  store double %3254, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %3255 = add i64 %3220, 24
  %3256 = add i64 %3026, 164
  store i64 %3256, i64* %PC, align 8
  %3257 = inttoptr i64 %3255 to i64*
  %3258 = load i64, i64* %3257, align 8
  store i64 %3258, i64* %RAX, align 8, !tbaa !2428
  %3259 = add i64 %3026, 168
  store i64 %3259, i64* %PC, align 8
  %3260 = load i32, i32* %3231, align 4
  %3261 = sext i32 %3260 to i64
  %3262 = mul nsw i64 %3261, 33800
  store i64 %3262, i64* %RCX, align 8, !tbaa !2428
  %3263 = lshr i64 %3262, 63
  %3264 = add i64 %3262, %3258
  store i64 %3264, i64* %RAX, align 8, !tbaa !2428
  %3265 = icmp ult i64 %3264, %3258
  %3266 = icmp ult i64 %3264, %3262
  %3267 = or i1 %3265, %3266
  %3268 = zext i1 %3267 to i8
  store i8 %3268, i8* %42, align 1, !tbaa !2432
  %3269 = trunc i64 %3264 to i32
  %3270 = and i32 %3269, 255
  %3271 = tail call i32 @llvm.ctpop.i32(i32 %3270) #8
  %3272 = trunc i32 %3271 to i8
  %3273 = and i8 %3272, 1
  %3274 = xor i8 %3273, 1
  store i8 %3274, i8* %49, align 1, !tbaa !2446
  %3275 = xor i64 %3262, %3258
  %3276 = xor i64 %3275, %3264
  %3277 = lshr i64 %3276, 4
  %3278 = trunc i64 %3277 to i8
  %3279 = and i8 %3278, 1
  store i8 %3279, i8* %54, align 1, !tbaa !2447
  %3280 = icmp eq i64 %3264, 0
  %3281 = zext i1 %3280 to i8
  store i8 %3281, i8* %57, align 1, !tbaa !2448
  %3282 = lshr i64 %3264, 63
  %3283 = trunc i64 %3282 to i8
  store i8 %3283, i8* %60, align 1, !tbaa !2449
  %3284 = lshr i64 %3258, 63
  %3285 = xor i64 %3282, %3284
  %3286 = xor i64 %3282, %3263
  %3287 = add nuw nsw i64 %3285, %3286
  %3288 = icmp eq i64 %3287, 2
  %3289 = zext i1 %3288 to i8
  store i8 %3289, i8* %66, align 1, !tbaa !2450
  %3290 = load i64, i64* %RBP, align 8
  %3291 = add i64 %3290, -52
  %3292 = add i64 %3026, 182
  store i64 %3292, i64* %PC, align 8
  %3293 = inttoptr i64 %3291 to i32*
  %3294 = load i32, i32* %3293, align 4
  %3295 = sext i32 %3294 to i64
  %3296 = mul nsw i64 %3295, 520
  store i64 %3296, i64* %RCX, align 8, !tbaa !2428
  %3297 = lshr i64 %3296, 63
  %3298 = add i64 %3296, %3264
  store i64 %3298, i64* %RAX, align 8, !tbaa !2428
  %3299 = icmp ult i64 %3298, %3264
  %3300 = icmp ult i64 %3298, %3296
  %3301 = or i1 %3299, %3300
  %3302 = zext i1 %3301 to i8
  store i8 %3302, i8* %42, align 1, !tbaa !2432
  %3303 = trunc i64 %3298 to i32
  %3304 = and i32 %3303, 255
  %3305 = tail call i32 @llvm.ctpop.i32(i32 %3304) #8
  %3306 = trunc i32 %3305 to i8
  %3307 = and i8 %3306, 1
  %3308 = xor i8 %3307, 1
  store i8 %3308, i8* %49, align 1, !tbaa !2446
  %3309 = xor i64 %3296, %3264
  %3310 = xor i64 %3309, %3298
  %3311 = lshr i64 %3310, 4
  %3312 = trunc i64 %3311 to i8
  %3313 = and i8 %3312, 1
  store i8 %3313, i8* %54, align 1, !tbaa !2447
  %3314 = icmp eq i64 %3298, 0
  %3315 = zext i1 %3314 to i8
  store i8 %3315, i8* %57, align 1, !tbaa !2448
  %3316 = lshr i64 %3298, 63
  %3317 = trunc i64 %3316 to i8
  store i8 %3317, i8* %60, align 1, !tbaa !2449
  %3318 = xor i64 %3316, %3282
  %3319 = xor i64 %3316, %3297
  %3320 = add nuw nsw i64 %3318, %3319
  %3321 = icmp eq i64 %3320, 2
  %3322 = zext i1 %3321 to i8
  store i8 %3322, i8* %66, align 1, !tbaa !2450
  %3323 = add i64 %3290, -108
  %3324 = add i64 %3026, 196
  store i64 %3324, i64* %PC, align 8
  %3325 = inttoptr i64 %3323 to i32*
  %3326 = load i32, i32* %3325, align 4
  %3327 = sext i32 %3326 to i64
  store i64 %3327, i64* %RCX, align 8, !tbaa !2428
  %3328 = shl nsw i64 %3327, 3
  %3329 = add i64 %3328, %3298
  %3330 = add i64 %3026, 201
  store i64 %3330, i64* %PC, align 8
  %3331 = load double, double* %231, align 1
  %3332 = inttoptr i64 %3329 to double*
  %3333 = load double, double* %3332, align 8
  %3334 = fmul double %3331, %3333
  store double %3334, double* %231, align 1, !tbaa !2452
  %3335 = load double, double* %228, align 1
  %3336 = fsub double %3335, %3334
  store double %3336, double* %228, align 1, !tbaa !2452
  %3337 = add i64 %3290, 48
  %3338 = add i64 %3026, 209
  store i64 %3338, i64* %PC, align 8
  %3339 = inttoptr i64 %3337 to i64*
  %3340 = load i64, i64* %3339, align 8
  store i64 %3340, i64* %RAX, align 8, !tbaa !2428
  %3341 = add i64 %3290, -100
  %3342 = add i64 %3026, 213
  store i64 %3342, i64* %PC, align 8
  %3343 = inttoptr i64 %3341 to i32*
  %3344 = load i32, i32* %3343, align 4
  %3345 = sext i32 %3344 to i64
  %3346 = mul nsw i64 %3345, 33800
  store i64 %3346, i64* %RCX, align 8, !tbaa !2428
  %3347 = lshr i64 %3346, 63
  %3348 = add i64 %3346, %3340
  store i64 %3348, i64* %RAX, align 8, !tbaa !2428
  %3349 = icmp ult i64 %3348, %3340
  %3350 = icmp ult i64 %3348, %3346
  %3351 = or i1 %3349, %3350
  %3352 = zext i1 %3351 to i8
  store i8 %3352, i8* %42, align 1, !tbaa !2432
  %3353 = trunc i64 %3348 to i32
  %3354 = and i32 %3353, 255
  %3355 = tail call i32 @llvm.ctpop.i32(i32 %3354) #8
  %3356 = trunc i32 %3355 to i8
  %3357 = and i8 %3356, 1
  %3358 = xor i8 %3357, 1
  store i8 %3358, i8* %49, align 1, !tbaa !2446
  %3359 = xor i64 %3346, %3340
  %3360 = xor i64 %3359, %3348
  %3361 = lshr i64 %3360, 4
  %3362 = trunc i64 %3361 to i8
  %3363 = and i8 %3362, 1
  store i8 %3363, i8* %54, align 1, !tbaa !2447
  %3364 = icmp eq i64 %3348, 0
  %3365 = zext i1 %3364 to i8
  store i8 %3365, i8* %57, align 1, !tbaa !2448
  %3366 = lshr i64 %3348, 63
  %3367 = trunc i64 %3366 to i8
  store i8 %3367, i8* %60, align 1, !tbaa !2449
  %3368 = lshr i64 %3340, 63
  %3369 = xor i64 %3366, %3368
  %3370 = xor i64 %3366, %3347
  %3371 = add nuw nsw i64 %3369, %3370
  %3372 = icmp eq i64 %3371, 2
  %3373 = zext i1 %3372 to i8
  store i8 %3373, i8* %66, align 1, !tbaa !2450
  %3374 = load i64, i64* %RBP, align 8
  %3375 = add i64 %3374, -52
  %3376 = add i64 %3026, 227
  store i64 %3376, i64* %PC, align 8
  %3377 = inttoptr i64 %3375 to i32*
  %3378 = load i32, i32* %3377, align 4
  %3379 = sext i32 %3378 to i64
  %3380 = mul nsw i64 %3379, 520
  store i64 %3380, i64* %RCX, align 8, !tbaa !2428
  %3381 = lshr i64 %3380, 63
  %3382 = add i64 %3380, %3348
  store i64 %3382, i64* %RAX, align 8, !tbaa !2428
  %3383 = icmp ult i64 %3382, %3348
  %3384 = icmp ult i64 %3382, %3380
  %3385 = or i1 %3383, %3384
  %3386 = zext i1 %3385 to i8
  store i8 %3386, i8* %42, align 1, !tbaa !2432
  %3387 = trunc i64 %3382 to i32
  %3388 = and i32 %3387, 255
  %3389 = tail call i32 @llvm.ctpop.i32(i32 %3388) #8
  %3390 = trunc i32 %3389 to i8
  %3391 = and i8 %3390, 1
  %3392 = xor i8 %3391, 1
  store i8 %3392, i8* %49, align 1, !tbaa !2446
  %3393 = xor i64 %3380, %3348
  %3394 = xor i64 %3393, %3382
  %3395 = lshr i64 %3394, 4
  %3396 = trunc i64 %3395 to i8
  %3397 = and i8 %3396, 1
  store i8 %3397, i8* %54, align 1, !tbaa !2447
  %3398 = icmp eq i64 %3382, 0
  %3399 = zext i1 %3398 to i8
  store i8 %3399, i8* %57, align 1, !tbaa !2448
  %3400 = lshr i64 %3382, 63
  %3401 = trunc i64 %3400 to i8
  store i8 %3401, i8* %60, align 1, !tbaa !2449
  %3402 = xor i64 %3400, %3366
  %3403 = xor i64 %3400, %3381
  %3404 = add nuw nsw i64 %3402, %3403
  %3405 = icmp eq i64 %3404, 2
  %3406 = zext i1 %3405 to i8
  store i8 %3406, i8* %66, align 1, !tbaa !2450
  %3407 = add i64 %3374, -108
  %3408 = add i64 %3026, 241
  store i64 %3408, i64* %PC, align 8
  %3409 = inttoptr i64 %3407 to i32*
  %3410 = load i32, i32* %3409, align 4
  %3411 = sext i32 %3410 to i64
  store i64 %3411, i64* %RCX, align 8, !tbaa !2428
  %3412 = shl nsw i64 %3411, 3
  %3413 = add i64 %3412, %3382
  %3414 = add i64 %3026, 246
  store i64 %3414, i64* %PC, align 8
  %3415 = load i64, i64* %147, align 1
  %3416 = inttoptr i64 %3413 to i64*
  store i64 %3415, i64* %3416, align 8
  %3417 = load i64, i64* %RBP, align 8
  %3418 = add i64 %3417, 16
  %3419 = load i64, i64* %PC, align 8
  %3420 = add i64 %3419, 4
  store i64 %3420, i64* %PC, align 8
  %3421 = inttoptr i64 %3418 to i64*
  %3422 = load i64, i64* %3421, align 8
  store i64 %3422, i64* %RAX, align 8, !tbaa !2428
  %3423 = add i64 %3417, -100
  %3424 = add i64 %3419, 8
  store i64 %3424, i64* %PC, align 8
  %3425 = inttoptr i64 %3423 to i32*
  %3426 = load i32, i32* %3425, align 4
  %3427 = sext i32 %3426 to i64
  %3428 = mul nsw i64 %3427, 520
  store i64 %3428, i64* %RCX, align 8, !tbaa !2428
  %3429 = lshr i64 %3428, 63
  %3430 = add i64 %3428, %3422
  store i64 %3430, i64* %RAX, align 8, !tbaa !2428
  %3431 = icmp ult i64 %3430, %3422
  %3432 = icmp ult i64 %3430, %3428
  %3433 = or i1 %3431, %3432
  %3434 = zext i1 %3433 to i8
  store i8 %3434, i8* %42, align 1, !tbaa !2432
  %3435 = trunc i64 %3430 to i32
  %3436 = and i32 %3435, 255
  %3437 = tail call i32 @llvm.ctpop.i32(i32 %3436) #8
  %3438 = trunc i32 %3437 to i8
  %3439 = and i8 %3438, 1
  %3440 = xor i8 %3439, 1
  store i8 %3440, i8* %49, align 1, !tbaa !2446
  %3441 = xor i64 %3428, %3422
  %3442 = xor i64 %3441, %3430
  %3443 = lshr i64 %3442, 4
  %3444 = trunc i64 %3443 to i8
  %3445 = and i8 %3444, 1
  store i8 %3445, i8* %54, align 1, !tbaa !2447
  %3446 = icmp eq i64 %3430, 0
  %3447 = zext i1 %3446 to i8
  store i8 %3447, i8* %57, align 1, !tbaa !2448
  %3448 = lshr i64 %3430, 63
  %3449 = trunc i64 %3448 to i8
  store i8 %3449, i8* %60, align 1, !tbaa !2449
  %3450 = lshr i64 %3422, 63
  %3451 = xor i64 %3448, %3450
  %3452 = xor i64 %3448, %3429
  %3453 = add nuw nsw i64 %3451, %3452
  %3454 = icmp eq i64 %3453, 2
  %3455 = zext i1 %3454 to i8
  store i8 %3455, i8* %66, align 1, !tbaa !2450
  %3456 = add i64 %3417, -104
  %3457 = add i64 %3419, 22
  store i64 %3457, i64* %PC, align 8
  %3458 = inttoptr i64 %3456 to i32*
  %3459 = load i32, i32* %3458, align 4
  %3460 = sext i32 %3459 to i64
  store i64 %3460, i64* %RCX, align 8, !tbaa !2428
  %3461 = shl nsw i64 %3460, 3
  %3462 = add i64 %3461, %3430
  %3463 = add i64 %3419, 27
  store i64 %3463, i64* %PC, align 8
  %3464 = inttoptr i64 %3462 to i64*
  %3465 = load i64, i64* %3464, align 8
  store i64 %3465, i64* %147, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %3466 = add i64 %3417, 24
  %3467 = add i64 %3419, 31
  store i64 %3467, i64* %PC, align 8
  %3468 = inttoptr i64 %3466 to i64*
  %3469 = load i64, i64* %3468, align 8
  store i64 %3469, i64* %RAX, align 8, !tbaa !2428
  %3470 = add i64 %3419, 35
  store i64 %3470, i64* %PC, align 8
  %3471 = load i32, i32* %3425, align 4
  %3472 = sext i32 %3471 to i64
  %3473 = mul nsw i64 %3472, 33800
  store i64 %3473, i64* %RCX, align 8, !tbaa !2428
  %3474 = lshr i64 %3473, 63
  %3475 = add i64 %3473, %3469
  store i64 %3475, i64* %RAX, align 8, !tbaa !2428
  %3476 = icmp ult i64 %3475, %3469
  %3477 = icmp ult i64 %3475, %3473
  %3478 = or i1 %3476, %3477
  %3479 = zext i1 %3478 to i8
  store i8 %3479, i8* %42, align 1, !tbaa !2432
  %3480 = trunc i64 %3475 to i32
  %3481 = and i32 %3480, 255
  %3482 = tail call i32 @llvm.ctpop.i32(i32 %3481) #8
  %3483 = trunc i32 %3482 to i8
  %3484 = and i8 %3483, 1
  %3485 = xor i8 %3484, 1
  store i8 %3485, i8* %49, align 1, !tbaa !2446
  %3486 = xor i64 %3473, %3469
  %3487 = xor i64 %3486, %3475
  %3488 = lshr i64 %3487, 4
  %3489 = trunc i64 %3488 to i8
  %3490 = and i8 %3489, 1
  store i8 %3490, i8* %54, align 1, !tbaa !2447
  %3491 = icmp eq i64 %3475, 0
  %3492 = zext i1 %3491 to i8
  store i8 %3492, i8* %57, align 1, !tbaa !2448
  %3493 = lshr i64 %3475, 63
  %3494 = trunc i64 %3493 to i8
  store i8 %3494, i8* %60, align 1, !tbaa !2449
  %3495 = lshr i64 %3469, 63
  %3496 = xor i64 %3493, %3495
  %3497 = xor i64 %3493, %3474
  %3498 = add nuw nsw i64 %3496, %3497
  %3499 = icmp eq i64 %3498, 2
  %3500 = zext i1 %3499 to i8
  store i8 %3500, i8* %66, align 1, !tbaa !2450
  %3501 = load i64, i64* %RBP, align 8
  %3502 = add i64 %3501, -52
  %3503 = add i64 %3419, 49
  store i64 %3503, i64* %PC, align 8
  %3504 = inttoptr i64 %3502 to i32*
  %3505 = load i32, i32* %3504, align 4
  %3506 = sext i32 %3505 to i64
  %3507 = mul nsw i64 %3506, 520
  store i64 %3507, i64* %RCX, align 8, !tbaa !2428
  %3508 = lshr i64 %3507, 63
  %3509 = add i64 %3507, %3475
  store i64 %3509, i64* %RAX, align 8, !tbaa !2428
  %3510 = icmp ult i64 %3509, %3475
  %3511 = icmp ult i64 %3509, %3507
  %3512 = or i1 %3510, %3511
  %3513 = zext i1 %3512 to i8
  store i8 %3513, i8* %42, align 1, !tbaa !2432
  %3514 = trunc i64 %3509 to i32
  %3515 = and i32 %3514, 255
  %3516 = tail call i32 @llvm.ctpop.i32(i32 %3515) #8
  %3517 = trunc i32 %3516 to i8
  %3518 = and i8 %3517, 1
  %3519 = xor i8 %3518, 1
  store i8 %3519, i8* %49, align 1, !tbaa !2446
  %3520 = xor i64 %3507, %3475
  %3521 = xor i64 %3520, %3509
  %3522 = lshr i64 %3521, 4
  %3523 = trunc i64 %3522 to i8
  %3524 = and i8 %3523, 1
  store i8 %3524, i8* %54, align 1, !tbaa !2447
  %3525 = icmp eq i64 %3509, 0
  %3526 = zext i1 %3525 to i8
  store i8 %3526, i8* %57, align 1, !tbaa !2448
  %3527 = lshr i64 %3509, 63
  %3528 = trunc i64 %3527 to i8
  store i8 %3528, i8* %60, align 1, !tbaa !2449
  %3529 = xor i64 %3527, %3493
  %3530 = xor i64 %3527, %3508
  %3531 = add nuw nsw i64 %3529, %3530
  %3532 = icmp eq i64 %3531, 2
  %3533 = zext i1 %3532 to i8
  store i8 %3533, i8* %66, align 1, !tbaa !2450
  %3534 = add i64 %3501, -108
  %3535 = add i64 %3419, 63
  store i64 %3535, i64* %PC, align 8
  %3536 = inttoptr i64 %3534 to i32*
  %3537 = load i32, i32* %3536, align 4
  %3538 = sext i32 %3537 to i64
  store i64 %3538, i64* %RCX, align 8, !tbaa !2428
  %3539 = shl nsw i64 %3538, 3
  %3540 = add i64 %3539, %3509
  %3541 = add i64 %3419, 68
  store i64 %3541, i64* %PC, align 8
  %3542 = load i64, i64* %147, align 1
  %3543 = inttoptr i64 %3540 to i64*
  store i64 %3542, i64* %3543, align 8
  %3544 = load i64, i64* %RBP, align 8
  %3545 = add i64 %3544, -108
  %3546 = load i64, i64* %PC, align 8
  %3547 = add i64 %3546, 3
  store i64 %3547, i64* %PC, align 8
  %3548 = inttoptr i64 %3545 to i32*
  %3549 = load i32, i32* %3548, align 4
  %3550 = add i32 %3549, 1
  %3551 = zext i32 %3550 to i64
  store i64 %3551, i64* %RAX, align 8, !tbaa !2428
  %3552 = icmp eq i32 %3549, -1
  %3553 = icmp eq i32 %3550, 0
  %3554 = or i1 %3552, %3553
  %3555 = zext i1 %3554 to i8
  store i8 %3555, i8* %42, align 1, !tbaa !2432
  %3556 = and i32 %3550, 255
  %3557 = tail call i32 @llvm.ctpop.i32(i32 %3556) #8
  %3558 = trunc i32 %3557 to i8
  %3559 = and i8 %3558, 1
  %3560 = xor i8 %3559, 1
  store i8 %3560, i8* %49, align 1, !tbaa !2446
  %3561 = xor i32 %3549, %3550
  %3562 = lshr i32 %3561, 4
  %3563 = trunc i32 %3562 to i8
  %3564 = and i8 %3563, 1
  store i8 %3564, i8* %54, align 1, !tbaa !2447
  %3565 = zext i1 %3553 to i8
  store i8 %3565, i8* %57, align 1, !tbaa !2448
  %3566 = lshr i32 %3550, 31
  %3567 = trunc i32 %3566 to i8
  store i8 %3567, i8* %60, align 1, !tbaa !2449
  %3568 = lshr i32 %3549, 31
  %3569 = xor i32 %3566, %3568
  %3570 = add nuw nsw i32 %3569, %3566
  %3571 = icmp eq i32 %3570, 2
  %3572 = zext i1 %3571 to i8
  store i8 %3572, i8* %66, align 1, !tbaa !2450
  %3573 = add i64 %3546, 9
  store i64 %3573, i64* %PC, align 8
  store i32 %3550, i32* %3548, align 4
  %3574 = load i64, i64* %PC, align 8
  %3575 = add i64 %3574, -660
  store i64 %3575, i64* %PC, align 8, !tbaa !2428
  br label %block_402512

block_401fec:                                     ; preds = %block_401fe0
  %3576 = add i64 %4790, -108
  %3577 = add i64 %4752, 36
  store i64 %3577, i64* %PC, align 8
  %3578 = inttoptr i64 %3576 to i32*
  %3579 = load i32, i32* %3578, align 4
  %3580 = sext i32 %3579 to i64
  store i64 %3580, i64* %RCX, align 8, !tbaa !2428
  %3581 = shl nsw i64 %3580, 3
  %3582 = add i64 %3581, %4799
  %3583 = add i64 %4752, 41
  store i64 %3583, i64* %PC, align 8
  %3584 = inttoptr i64 %3582 to i64*
  %3585 = load i64, i64* %3584, align 8
  store i64 %3585, i64* %147, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %3586 = add i64 %4790, 32
  %3587 = add i64 %4752, 45
  store i64 %3587, i64* %PC, align 8
  %3588 = inttoptr i64 %3586 to i64*
  %3589 = load i64, i64* %3588, align 8
  store i64 %3589, i64* %RAX, align 8, !tbaa !2428
  %3590 = add i64 %4790, -100
  %3591 = add i64 %4752, 49
  store i64 %3591, i64* %PC, align 8
  %3592 = inttoptr i64 %3590 to i32*
  %3593 = load i32, i32* %3592, align 4
  %3594 = sext i32 %3593 to i64
  %3595 = mul nsw i64 %3594, 33800
  store i64 %3595, i64* %RCX, align 8, !tbaa !2428
  %3596 = lshr i64 %3595, 63
  %3597 = add i64 %3595, %3589
  store i64 %3597, i64* %RAX, align 8, !tbaa !2428
  %3598 = icmp ult i64 %3597, %3589
  %3599 = icmp ult i64 %3597, %3595
  %3600 = or i1 %3598, %3599
  %3601 = zext i1 %3600 to i8
  store i8 %3601, i8* %42, align 1, !tbaa !2432
  %3602 = trunc i64 %3597 to i32
  %3603 = and i32 %3602, 255
  %3604 = tail call i32 @llvm.ctpop.i32(i32 %3603) #8
  %3605 = trunc i32 %3604 to i8
  %3606 = and i8 %3605, 1
  %3607 = xor i8 %3606, 1
  store i8 %3607, i8* %49, align 1, !tbaa !2446
  %3608 = xor i64 %3595, %3589
  %3609 = xor i64 %3608, %3597
  %3610 = lshr i64 %3609, 4
  %3611 = trunc i64 %3610 to i8
  %3612 = and i8 %3611, 1
  store i8 %3612, i8* %54, align 1, !tbaa !2447
  %3613 = icmp eq i64 %3597, 0
  %3614 = zext i1 %3613 to i8
  store i8 %3614, i8* %57, align 1, !tbaa !2448
  %3615 = lshr i64 %3597, 63
  %3616 = trunc i64 %3615 to i8
  store i8 %3616, i8* %60, align 1, !tbaa !2449
  %3617 = lshr i64 %3589, 63
  %3618 = xor i64 %3615, %3617
  %3619 = xor i64 %3615, %3596
  %3620 = add nuw nsw i64 %3618, %3619
  %3621 = icmp eq i64 %3620, 2
  %3622 = zext i1 %3621 to i8
  store i8 %3622, i8* %66, align 1, !tbaa !2450
  %3623 = add i64 %4752, 62
  store i64 %3623, i64* %PC, align 8
  %3624 = load i32, i32* %4793, align 4
  %3625 = add i32 %3624, 1
  %3626 = zext i32 %3625 to i64
  store i64 %3626, i64* %RDX, align 8, !tbaa !2428
  %3627 = sext i32 %3625 to i64
  %3628 = mul nsw i64 %3627, 520
  store i64 %3628, i64* %RCX, align 8, !tbaa !2428
  %3629 = lshr i64 %3628, 63
  %3630 = load i64, i64* %RAX, align 8
  %3631 = add i64 %3628, %3630
  store i64 %3631, i64* %RAX, align 8, !tbaa !2428
  %3632 = icmp ult i64 %3631, %3630
  %3633 = icmp ult i64 %3631, %3628
  %3634 = or i1 %3632, %3633
  %3635 = zext i1 %3634 to i8
  store i8 %3635, i8* %42, align 1, !tbaa !2432
  %3636 = trunc i64 %3631 to i32
  %3637 = and i32 %3636, 255
  %3638 = tail call i32 @llvm.ctpop.i32(i32 %3637) #8
  %3639 = trunc i32 %3638 to i8
  %3640 = and i8 %3639, 1
  %3641 = xor i8 %3640, 1
  store i8 %3641, i8* %49, align 1, !tbaa !2446
  %3642 = xor i64 %3628, %3630
  %3643 = xor i64 %3642, %3631
  %3644 = lshr i64 %3643, 4
  %3645 = trunc i64 %3644 to i8
  %3646 = and i8 %3645, 1
  store i8 %3646, i8* %54, align 1, !tbaa !2447
  %3647 = icmp eq i64 %3631, 0
  %3648 = zext i1 %3647 to i8
  store i8 %3648, i8* %57, align 1, !tbaa !2448
  %3649 = lshr i64 %3631, 63
  %3650 = trunc i64 %3649 to i8
  store i8 %3650, i8* %60, align 1, !tbaa !2449
  %3651 = lshr i64 %3630, 63
  %3652 = xor i64 %3649, %3651
  %3653 = xor i64 %3649, %3629
  %3654 = add nuw nsw i64 %3652, %3653
  %3655 = icmp eq i64 %3654, 2
  %3656 = zext i1 %3655 to i8
  store i8 %3656, i8* %66, align 1, !tbaa !2450
  %3657 = load i64, i64* %RBP, align 8
  %3658 = add i64 %3657, -108
  %3659 = add i64 %4752, 82
  store i64 %3659, i64* %PC, align 8
  %3660 = inttoptr i64 %3658 to i32*
  %3661 = load i32, i32* %3660, align 4
  %3662 = sext i32 %3661 to i64
  store i64 %3662, i64* %RCX, align 8, !tbaa !2428
  %3663 = shl nsw i64 %3662, 3
  %3664 = add i64 %3663, %3631
  %3665 = add i64 %4752, 87
  store i64 %3665, i64* %PC, align 8
  %3666 = load double, double* %228, align 1
  %3667 = inttoptr i64 %3664 to double*
  %3668 = load double, double* %3667, align 8
  %3669 = fsub double %3666, %3668
  store double %3669, double* %228, align 1, !tbaa !2452
  %3670 = add i64 %3657, 40
  %3671 = add i64 %4752, 91
  store i64 %3671, i64* %PC, align 8
  %3672 = inttoptr i64 %3670 to i64*
  %3673 = load i64, i64* %3672, align 8
  store i64 %3673, i64* %RAX, align 8, !tbaa !2428
  %3674 = add i64 %3657, -100
  %3675 = add i64 %4752, 95
  store i64 %3675, i64* %PC, align 8
  %3676 = inttoptr i64 %3674 to i32*
  %3677 = load i32, i32* %3676, align 4
  %3678 = sext i32 %3677 to i64
  %3679 = mul nsw i64 %3678, 33800
  store i64 %3679, i64* %RCX, align 8, !tbaa !2428
  %3680 = lshr i64 %3679, 63
  %3681 = add i64 %3679, %3673
  store i64 %3681, i64* %RAX, align 8, !tbaa !2428
  %3682 = icmp ult i64 %3681, %3673
  %3683 = icmp ult i64 %3681, %3679
  %3684 = or i1 %3682, %3683
  %3685 = zext i1 %3684 to i8
  store i8 %3685, i8* %42, align 1, !tbaa !2432
  %3686 = trunc i64 %3681 to i32
  %3687 = and i32 %3686, 255
  %3688 = tail call i32 @llvm.ctpop.i32(i32 %3687) #8
  %3689 = trunc i32 %3688 to i8
  %3690 = and i8 %3689, 1
  %3691 = xor i8 %3690, 1
  store i8 %3691, i8* %49, align 1, !tbaa !2446
  %3692 = xor i64 %3679, %3673
  %3693 = xor i64 %3692, %3681
  %3694 = lshr i64 %3693, 4
  %3695 = trunc i64 %3694 to i8
  %3696 = and i8 %3695, 1
  store i8 %3696, i8* %54, align 1, !tbaa !2447
  %3697 = icmp eq i64 %3681, 0
  %3698 = zext i1 %3697 to i8
  store i8 %3698, i8* %57, align 1, !tbaa !2448
  %3699 = lshr i64 %3681, 63
  %3700 = trunc i64 %3699 to i8
  store i8 %3700, i8* %60, align 1, !tbaa !2449
  %3701 = lshr i64 %3673, 63
  %3702 = xor i64 %3699, %3701
  %3703 = xor i64 %3699, %3680
  %3704 = add nuw nsw i64 %3702, %3703
  %3705 = icmp eq i64 %3704, 2
  %3706 = zext i1 %3705 to i8
  store i8 %3706, i8* %66, align 1, !tbaa !2450
  %3707 = add i64 %3657, -104
  %3708 = add i64 %4752, 109
  store i64 %3708, i64* %PC, align 8
  %3709 = inttoptr i64 %3707 to i32*
  %3710 = load i32, i32* %3709, align 4
  %3711 = sext i32 %3710 to i64
  %3712 = mul nsw i64 %3711, 520
  store i64 %3712, i64* %RCX, align 8, !tbaa !2428
  %3713 = lshr i64 %3712, 63
  %3714 = add i64 %3712, %3681
  store i64 %3714, i64* %RAX, align 8, !tbaa !2428
  %3715 = icmp ult i64 %3714, %3681
  %3716 = icmp ult i64 %3714, %3712
  %3717 = or i1 %3715, %3716
  %3718 = zext i1 %3717 to i8
  store i8 %3718, i8* %42, align 1, !tbaa !2432
  %3719 = trunc i64 %3714 to i32
  %3720 = and i32 %3719, 255
  %3721 = tail call i32 @llvm.ctpop.i32(i32 %3720) #8
  %3722 = trunc i32 %3721 to i8
  %3723 = and i8 %3722, 1
  %3724 = xor i8 %3723, 1
  store i8 %3724, i8* %49, align 1, !tbaa !2446
  %3725 = xor i64 %3712, %3681
  %3726 = xor i64 %3725, %3714
  %3727 = lshr i64 %3726, 4
  %3728 = trunc i64 %3727 to i8
  %3729 = and i8 %3728, 1
  store i8 %3729, i8* %54, align 1, !tbaa !2447
  %3730 = icmp eq i64 %3714, 0
  %3731 = zext i1 %3730 to i8
  store i8 %3731, i8* %57, align 1, !tbaa !2448
  %3732 = lshr i64 %3714, 63
  %3733 = trunc i64 %3732 to i8
  store i8 %3733, i8* %60, align 1, !tbaa !2449
  %3734 = xor i64 %3732, %3699
  %3735 = xor i64 %3732, %3713
  %3736 = add nuw nsw i64 %3734, %3735
  %3737 = icmp eq i64 %3736, 2
  %3738 = zext i1 %3737 to i8
  store i8 %3738, i8* %66, align 1, !tbaa !2450
  %3739 = load i64, i64* %RBP, align 8
  %3740 = add i64 %3739, -108
  %3741 = add i64 %4752, 122
  store i64 %3741, i64* %PC, align 8
  %3742 = inttoptr i64 %3740 to i32*
  %3743 = load i32, i32* %3742, align 4
  %3744 = add i32 %3743, 1
  %3745 = zext i32 %3744 to i64
  store i64 %3745, i64* %RDX, align 8, !tbaa !2428
  %3746 = icmp eq i32 %3743, -1
  %3747 = icmp eq i32 %3744, 0
  %3748 = or i1 %3746, %3747
  %3749 = zext i1 %3748 to i8
  store i8 %3749, i8* %42, align 1, !tbaa !2432
  %3750 = and i32 %3744, 255
  %3751 = tail call i32 @llvm.ctpop.i32(i32 %3750) #8
  %3752 = trunc i32 %3751 to i8
  %3753 = and i8 %3752, 1
  %3754 = xor i8 %3753, 1
  store i8 %3754, i8* %49, align 1, !tbaa !2446
  %3755 = xor i32 %3743, %3744
  %3756 = lshr i32 %3755, 4
  %3757 = trunc i32 %3756 to i8
  %3758 = and i8 %3757, 1
  store i8 %3758, i8* %54, align 1, !tbaa !2447
  %3759 = zext i1 %3747 to i8
  store i8 %3759, i8* %57, align 1, !tbaa !2448
  %3760 = lshr i32 %3744, 31
  %3761 = trunc i32 %3760 to i8
  store i8 %3761, i8* %60, align 1, !tbaa !2449
  %3762 = lshr i32 %3743, 31
  %3763 = xor i32 %3760, %3762
  %3764 = add nuw nsw i32 %3763, %3760
  %3765 = icmp eq i32 %3764, 2
  %3766 = zext i1 %3765 to i8
  store i8 %3766, i8* %66, align 1, !tbaa !2450
  %3767 = sext i32 %3744 to i64
  store i64 %3767, i64* %RCX, align 8, !tbaa !2428
  %3768 = shl nsw i64 %3767, 3
  %3769 = add i64 %3768, %3714
  %3770 = add i64 %4752, 133
  store i64 %3770, i64* %PC, align 8
  %3771 = load double, double* %228, align 1
  %3772 = inttoptr i64 %3769 to double*
  %3773 = load double, double* %3772, align 8
  %3774 = fadd double %3771, %3773
  store double %3774, double* %228, align 1, !tbaa !2452
  %3775 = add i64 %3739, 40
  %3776 = add i64 %4752, 137
  store i64 %3776, i64* %PC, align 8
  %3777 = inttoptr i64 %3775 to i64*
  %3778 = load i64, i64* %3777, align 8
  store i64 %3778, i64* %RAX, align 8, !tbaa !2428
  %3779 = add i64 %3739, -100
  %3780 = add i64 %4752, 141
  store i64 %3780, i64* %PC, align 8
  %3781 = inttoptr i64 %3779 to i32*
  %3782 = load i32, i32* %3781, align 4
  %3783 = sext i32 %3782 to i64
  %3784 = mul nsw i64 %3783, 33800
  store i64 %3784, i64* %RCX, align 8, !tbaa !2428
  %3785 = lshr i64 %3784, 63
  %3786 = add i64 %3784, %3778
  store i64 %3786, i64* %RAX, align 8, !tbaa !2428
  %3787 = icmp ult i64 %3786, %3778
  %3788 = icmp ult i64 %3786, %3784
  %3789 = or i1 %3787, %3788
  %3790 = zext i1 %3789 to i8
  store i8 %3790, i8* %42, align 1, !tbaa !2432
  %3791 = trunc i64 %3786 to i32
  %3792 = and i32 %3791, 255
  %3793 = tail call i32 @llvm.ctpop.i32(i32 %3792) #8
  %3794 = trunc i32 %3793 to i8
  %3795 = and i8 %3794, 1
  %3796 = xor i8 %3795, 1
  store i8 %3796, i8* %49, align 1, !tbaa !2446
  %3797 = xor i64 %3784, %3778
  %3798 = xor i64 %3797, %3786
  %3799 = lshr i64 %3798, 4
  %3800 = trunc i64 %3799 to i8
  %3801 = and i8 %3800, 1
  store i8 %3801, i8* %54, align 1, !tbaa !2447
  %3802 = icmp eq i64 %3786, 0
  %3803 = zext i1 %3802 to i8
  store i8 %3803, i8* %57, align 1, !tbaa !2448
  %3804 = lshr i64 %3786, 63
  %3805 = trunc i64 %3804 to i8
  store i8 %3805, i8* %60, align 1, !tbaa !2449
  %3806 = lshr i64 %3778, 63
  %3807 = xor i64 %3804, %3806
  %3808 = xor i64 %3804, %3785
  %3809 = add nuw nsw i64 %3807, %3808
  %3810 = icmp eq i64 %3809, 2
  %3811 = zext i1 %3810 to i8
  store i8 %3811, i8* %66, align 1, !tbaa !2450
  %3812 = load i64, i64* %RBP, align 8
  %3813 = add i64 %3812, -104
  %3814 = add i64 %4752, 155
  store i64 %3814, i64* %PC, align 8
  %3815 = inttoptr i64 %3813 to i32*
  %3816 = load i32, i32* %3815, align 4
  %3817 = sext i32 %3816 to i64
  %3818 = mul nsw i64 %3817, 520
  store i64 %3818, i64* %RCX, align 8, !tbaa !2428
  %3819 = lshr i64 %3818, 63
  %3820 = add i64 %3818, %3786
  store i64 %3820, i64* %RAX, align 8, !tbaa !2428
  %3821 = icmp ult i64 %3820, %3786
  %3822 = icmp ult i64 %3820, %3818
  %3823 = or i1 %3821, %3822
  %3824 = zext i1 %3823 to i8
  store i8 %3824, i8* %42, align 1, !tbaa !2432
  %3825 = trunc i64 %3820 to i32
  %3826 = and i32 %3825, 255
  %3827 = tail call i32 @llvm.ctpop.i32(i32 %3826) #8
  %3828 = trunc i32 %3827 to i8
  %3829 = and i8 %3828, 1
  %3830 = xor i8 %3829, 1
  store i8 %3830, i8* %49, align 1, !tbaa !2446
  %3831 = xor i64 %3818, %3786
  %3832 = xor i64 %3831, %3820
  %3833 = lshr i64 %3832, 4
  %3834 = trunc i64 %3833 to i8
  %3835 = and i8 %3834, 1
  store i8 %3835, i8* %54, align 1, !tbaa !2447
  %3836 = icmp eq i64 %3820, 0
  %3837 = zext i1 %3836 to i8
  store i8 %3837, i8* %57, align 1, !tbaa !2448
  %3838 = lshr i64 %3820, 63
  %3839 = trunc i64 %3838 to i8
  store i8 %3839, i8* %60, align 1, !tbaa !2449
  %3840 = xor i64 %3838, %3804
  %3841 = xor i64 %3838, %3819
  %3842 = add nuw nsw i64 %3840, %3841
  %3843 = icmp eq i64 %3842, 2
  %3844 = zext i1 %3843 to i8
  store i8 %3844, i8* %66, align 1, !tbaa !2450
  %3845 = add i64 %3812, -108
  %3846 = add i64 %4752, 169
  store i64 %3846, i64* %PC, align 8
  %3847 = inttoptr i64 %3845 to i32*
  %3848 = load i32, i32* %3847, align 4
  %3849 = sext i32 %3848 to i64
  store i64 %3849, i64* %RCX, align 8, !tbaa !2428
  %3850 = shl nsw i64 %3849, 3
  %3851 = add i64 %3850, %3820
  %3852 = add i64 %4752, 174
  store i64 %3852, i64* %PC, align 8
  %3853 = load double, double* %228, align 1
  %3854 = inttoptr i64 %3851 to double*
  %3855 = load double, double* %3854, align 8
  %3856 = fsub double %3853, %3855
  store double %3856, double* %228, align 1, !tbaa !2452
  %3857 = add i64 %3812, -96
  %3858 = add i64 %4752, 178
  store i64 %3858, i64* %PC, align 8
  %3859 = inttoptr i64 %3857 to i64*
  %3860 = load i64, i64* %3859, align 8
  store i64 %3860, i64* %RAX, align 8, !tbaa !2428
  %3861 = add i64 %3812, -100
  %3862 = add i64 %4752, 182
  store i64 %3862, i64* %PC, align 8
  %3863 = inttoptr i64 %3861 to i32*
  %3864 = load i32, i32* %3863, align 4
  %3865 = sext i32 %3864 to i64
  %3866 = mul nsw i64 %3865, 520
  store i64 %3866, i64* %RCX, align 8, !tbaa !2428
  %3867 = lshr i64 %3866, 63
  %3868 = add i64 %3866, %3860
  store i64 %3868, i64* %RAX, align 8, !tbaa !2428
  %3869 = icmp ult i64 %3868, %3860
  %3870 = icmp ult i64 %3868, %3866
  %3871 = or i1 %3869, %3870
  %3872 = zext i1 %3871 to i8
  store i8 %3872, i8* %42, align 1, !tbaa !2432
  %3873 = trunc i64 %3868 to i32
  %3874 = and i32 %3873, 255
  %3875 = tail call i32 @llvm.ctpop.i32(i32 %3874) #8
  %3876 = trunc i32 %3875 to i8
  %3877 = and i8 %3876, 1
  %3878 = xor i8 %3877, 1
  store i8 %3878, i8* %49, align 1, !tbaa !2446
  %3879 = xor i64 %3866, %3860
  %3880 = xor i64 %3879, %3868
  %3881 = lshr i64 %3880, 4
  %3882 = trunc i64 %3881 to i8
  %3883 = and i8 %3882, 1
  store i8 %3883, i8* %54, align 1, !tbaa !2447
  %3884 = icmp eq i64 %3868, 0
  %3885 = zext i1 %3884 to i8
  store i8 %3885, i8* %57, align 1, !tbaa !2448
  %3886 = lshr i64 %3868, 63
  %3887 = trunc i64 %3886 to i8
  store i8 %3887, i8* %60, align 1, !tbaa !2449
  %3888 = lshr i64 %3860, 63
  %3889 = xor i64 %3886, %3888
  %3890 = xor i64 %3886, %3867
  %3891 = add nuw nsw i64 %3889, %3890
  %3892 = icmp eq i64 %3891, 2
  %3893 = zext i1 %3892 to i8
  store i8 %3893, i8* %66, align 1, !tbaa !2450
  %3894 = load i64, i64* %RBP, align 8
  %3895 = add i64 %3894, -104
  %3896 = add i64 %4752, 196
  store i64 %3896, i64* %PC, align 8
  %3897 = inttoptr i64 %3895 to i32*
  %3898 = load i32, i32* %3897, align 4
  %3899 = sext i32 %3898 to i64
  store i64 %3899, i64* %RCX, align 8, !tbaa !2428
  %3900 = shl nsw i64 %3899, 3
  %3901 = add i64 %3900, %3868
  %3902 = add i64 %4752, 201
  store i64 %3902, i64* %PC, align 8
  %3903 = inttoptr i64 %3901 to double*
  store double %3856, double* %3903, align 8
  %3904 = load i64, i64* %RBP, align 8
  %3905 = add i64 %3904, 88
  %3906 = load i64, i64* %PC, align 8
  %3907 = add i64 %3906, 4
  store i64 %3907, i64* %PC, align 8
  %3908 = inttoptr i64 %3905 to i64*
  %3909 = load i64, i64* %3908, align 8
  store i64 %3909, i64* %RAX, align 8, !tbaa !2428
  %3910 = add i64 %3904, -104
  %3911 = add i64 %3906, 8
  store i64 %3911, i64* %PC, align 8
  %3912 = inttoptr i64 %3910 to i32*
  %3913 = load i32, i32* %3912, align 4
  %3914 = sext i32 %3913 to i64
  store i64 %3914, i64* %RCX, align 8, !tbaa !2428
  %3915 = shl nsw i64 %3914, 3
  %3916 = add i64 %3915, %3909
  %3917 = add i64 %3906, 13
  store i64 %3917, i64* %PC, align 8
  %3918 = inttoptr i64 %3916 to double*
  %3919 = load double, double* %3918, align 8
  store double %3919, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %3920 = add i64 %3904, 96
  %3921 = add i64 %3906, 17
  store i64 %3921, i64* %PC, align 8
  %3922 = inttoptr i64 %3920 to i64*
  %3923 = load i64, i64* %3922, align 8
  store i64 %3923, i64* %RAX, align 8, !tbaa !2428
  %3924 = add i64 %3906, 21
  store i64 %3924, i64* %PC, align 8
  %3925 = load i32, i32* %3912, align 4
  %3926 = sext i32 %3925 to i64
  store i64 %3926, i64* %RCX, align 8, !tbaa !2428
  %3927 = shl nsw i64 %3926, 3
  %3928 = add i64 %3927, %3923
  %3929 = add i64 %3906, 26
  store i64 %3929, i64* %PC, align 8
  %3930 = inttoptr i64 %3928 to double*
  %3931 = load double, double* %3930, align 8
  %3932 = fdiv double %3919, %3931
  store double %3932, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %3933 = add i64 %3904, 24
  %3934 = add i64 %3906, 30
  store i64 %3934, i64* %PC, align 8
  %3935 = inttoptr i64 %3933 to i64*
  %3936 = load i64, i64* %3935, align 8
  store i64 %3936, i64* %RAX, align 8, !tbaa !2428
  %3937 = add i64 %3904, -100
  %3938 = add i64 %3906, 34
  store i64 %3938, i64* %PC, align 8
  %3939 = inttoptr i64 %3937 to i32*
  %3940 = load i32, i32* %3939, align 4
  %3941 = sext i32 %3940 to i64
  %3942 = mul nsw i64 %3941, 33800
  store i64 %3942, i64* %RCX, align 8, !tbaa !2428
  %3943 = lshr i64 %3942, 63
  %3944 = add i64 %3942, %3936
  store i64 %3944, i64* %RAX, align 8, !tbaa !2428
  %3945 = icmp ult i64 %3944, %3936
  %3946 = icmp ult i64 %3944, %3942
  %3947 = or i1 %3945, %3946
  %3948 = zext i1 %3947 to i8
  store i8 %3948, i8* %42, align 1, !tbaa !2432
  %3949 = trunc i64 %3944 to i32
  %3950 = and i32 %3949, 255
  %3951 = tail call i32 @llvm.ctpop.i32(i32 %3950) #8
  %3952 = trunc i32 %3951 to i8
  %3953 = and i8 %3952, 1
  %3954 = xor i8 %3953, 1
  store i8 %3954, i8* %49, align 1, !tbaa !2446
  %3955 = xor i64 %3942, %3936
  %3956 = xor i64 %3955, %3944
  %3957 = lshr i64 %3956, 4
  %3958 = trunc i64 %3957 to i8
  %3959 = and i8 %3958, 1
  store i8 %3959, i8* %54, align 1, !tbaa !2447
  %3960 = icmp eq i64 %3944, 0
  %3961 = zext i1 %3960 to i8
  store i8 %3961, i8* %57, align 1, !tbaa !2448
  %3962 = lshr i64 %3944, 63
  %3963 = trunc i64 %3962 to i8
  store i8 %3963, i8* %60, align 1, !tbaa !2449
  %3964 = lshr i64 %3936, 63
  %3965 = xor i64 %3962, %3964
  %3966 = xor i64 %3962, %3943
  %3967 = add nuw nsw i64 %3965, %3966
  %3968 = icmp eq i64 %3967, 2
  %3969 = zext i1 %3968 to i8
  store i8 %3969, i8* %66, align 1, !tbaa !2450
  %3970 = load i64, i64* %RBP, align 8
  %3971 = add i64 %3970, -104
  %3972 = add i64 %3906, 48
  store i64 %3972, i64* %PC, align 8
  %3973 = inttoptr i64 %3971 to i32*
  %3974 = load i32, i32* %3973, align 4
  %3975 = sext i32 %3974 to i64
  %3976 = mul nsw i64 %3975, 520
  store i64 %3976, i64* %RCX, align 8, !tbaa !2428
  %3977 = lshr i64 %3976, 63
  %3978 = add i64 %3976, %3944
  store i64 %3978, i64* %RAX, align 8, !tbaa !2428
  %3979 = icmp ult i64 %3978, %3944
  %3980 = icmp ult i64 %3978, %3976
  %3981 = or i1 %3979, %3980
  %3982 = zext i1 %3981 to i8
  store i8 %3982, i8* %42, align 1, !tbaa !2432
  %3983 = trunc i64 %3978 to i32
  %3984 = and i32 %3983, 255
  %3985 = tail call i32 @llvm.ctpop.i32(i32 %3984) #8
  %3986 = trunc i32 %3985 to i8
  %3987 = and i8 %3986, 1
  %3988 = xor i8 %3987, 1
  store i8 %3988, i8* %49, align 1, !tbaa !2446
  %3989 = xor i64 %3976, %3944
  %3990 = xor i64 %3989, %3978
  %3991 = lshr i64 %3990, 4
  %3992 = trunc i64 %3991 to i8
  %3993 = and i8 %3992, 1
  store i8 %3993, i8* %54, align 1, !tbaa !2447
  %3994 = icmp eq i64 %3978, 0
  %3995 = zext i1 %3994 to i8
  store i8 %3995, i8* %57, align 1, !tbaa !2448
  %3996 = lshr i64 %3978, 63
  %3997 = trunc i64 %3996 to i8
  store i8 %3997, i8* %60, align 1, !tbaa !2449
  %3998 = xor i64 %3996, %3962
  %3999 = xor i64 %3996, %3977
  %4000 = add nuw nsw i64 %3998, %3999
  %4001 = icmp eq i64 %4000, 2
  %4002 = zext i1 %4001 to i8
  store i8 %4002, i8* %66, align 1, !tbaa !2450
  %4003 = add i64 %3970, -108
  %4004 = add i64 %3906, 62
  store i64 %4004, i64* %PC, align 8
  %4005 = inttoptr i64 %4003 to i32*
  %4006 = load i32, i32* %4005, align 4
  %4007 = sext i32 %4006 to i64
  store i64 %4007, i64* %RCX, align 8, !tbaa !2428
  %4008 = shl nsw i64 %4007, 3
  %4009 = add i64 %4008, %3978
  %4010 = add i64 %3906, 67
  store i64 %4010, i64* %PC, align 8
  %4011 = load double, double* %228, align 1
  %4012 = inttoptr i64 %4009 to double*
  %4013 = load double, double* %4012, align 8
  %4014 = fmul double %4011, %4013
  store double %4014, double* %228, align 1, !tbaa !2452
  %4015 = add i64 %3970, -72
  %4016 = add i64 %3906, 72
  store i64 %4016, i64* %PC, align 8
  %4017 = inttoptr i64 %4015 to double*
  %4018 = load double, double* %4017, align 8
  store double %4018, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %4019 = add i64 %3970, 96
  %4020 = add i64 %3906, 76
  store i64 %4020, i64* %PC, align 8
  %4021 = inttoptr i64 %4019 to i64*
  %4022 = load i64, i64* %4021, align 8
  store i64 %4022, i64* %RAX, align 8, !tbaa !2428
  %4023 = add i64 %3906, 80
  store i64 %4023, i64* %PC, align 8
  %4024 = load i32, i32* %3973, align 4
  %4025 = sext i32 %4024 to i64
  store i64 %4025, i64* %RCX, align 8, !tbaa !2428
  %4026 = shl nsw i64 %4025, 3
  %4027 = add i64 %4026, %4022
  %4028 = add i64 %3906, 85
  store i64 %4028, i64* %PC, align 8
  %4029 = inttoptr i64 %4027 to double*
  %4030 = load double, double* %4029, align 8
  %4031 = fdiv double %4018, %4030
  store double %4031, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %4032 = load i64, i64* %RBP, align 8
  %4033 = add i64 %4032, -96
  %4034 = add i64 %3906, 89
  store i64 %4034, i64* %PC, align 8
  %4035 = inttoptr i64 %4033 to i64*
  %4036 = load i64, i64* %4035, align 8
  store i64 %4036, i64* %RAX, align 8, !tbaa !2428
  %4037 = add i64 %4032, -100
  %4038 = add i64 %3906, 93
  store i64 %4038, i64* %PC, align 8
  %4039 = inttoptr i64 %4037 to i32*
  %4040 = load i32, i32* %4039, align 4
  %4041 = sext i32 %4040 to i64
  %4042 = mul nsw i64 %4041, 520
  store i64 %4042, i64* %RCX, align 8, !tbaa !2428
  %4043 = lshr i64 %4042, 63
  %4044 = add i64 %4042, %4036
  store i64 %4044, i64* %RAX, align 8, !tbaa !2428
  %4045 = icmp ult i64 %4044, %4036
  %4046 = icmp ult i64 %4044, %4042
  %4047 = or i1 %4045, %4046
  %4048 = zext i1 %4047 to i8
  store i8 %4048, i8* %42, align 1, !tbaa !2432
  %4049 = trunc i64 %4044 to i32
  %4050 = and i32 %4049, 255
  %4051 = tail call i32 @llvm.ctpop.i32(i32 %4050) #8
  %4052 = trunc i32 %4051 to i8
  %4053 = and i8 %4052, 1
  %4054 = xor i8 %4053, 1
  store i8 %4054, i8* %49, align 1, !tbaa !2446
  %4055 = xor i64 %4042, %4036
  %4056 = xor i64 %4055, %4044
  %4057 = lshr i64 %4056, 4
  %4058 = trunc i64 %4057 to i8
  %4059 = and i8 %4058, 1
  store i8 %4059, i8* %54, align 1, !tbaa !2447
  %4060 = icmp eq i64 %4044, 0
  %4061 = zext i1 %4060 to i8
  store i8 %4061, i8* %57, align 1, !tbaa !2448
  %4062 = lshr i64 %4044, 63
  %4063 = trunc i64 %4062 to i8
  store i8 %4063, i8* %60, align 1, !tbaa !2449
  %4064 = lshr i64 %4036, 63
  %4065 = xor i64 %4062, %4064
  %4066 = xor i64 %4062, %4043
  %4067 = add nuw nsw i64 %4065, %4066
  %4068 = icmp eq i64 %4067, 2
  %4069 = zext i1 %4068 to i8
  store i8 %4069, i8* %66, align 1, !tbaa !2450
  %4070 = add i64 %4032, -104
  %4071 = add i64 %3906, 107
  store i64 %4071, i64* %PC, align 8
  %4072 = inttoptr i64 %4070 to i32*
  %4073 = load i32, i32* %4072, align 4
  %4074 = sext i32 %4073 to i64
  store i64 %4074, i64* %RCX, align 8, !tbaa !2428
  %4075 = shl nsw i64 %4074, 3
  %4076 = add i64 %4075, %4044
  %4077 = add i64 %3906, 112
  store i64 %4077, i64* %PC, align 8
  %4078 = inttoptr i64 %4076 to double*
  %4079 = load double, double* %4078, align 8
  %4080 = fmul double %4031, %4079
  store double %4080, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %4081 = load double, double* %228, align 1
  %4082 = fsub double %4081, %4080
  store double %4082, double* %228, align 1, !tbaa !2452
  %4083 = add i64 %4032, 16
  %4084 = add i64 %3906, 120
  store i64 %4084, i64* %PC, align 8
  %4085 = inttoptr i64 %4083 to i64*
  %4086 = load i64, i64* %4085, align 8
  store i64 %4086, i64* %RAX, align 8, !tbaa !2428
  %4087 = load i64, i64* %RBP, align 8
  %4088 = add i64 %4087, -100
  %4089 = add i64 %3906, 124
  store i64 %4089, i64* %PC, align 8
  %4090 = inttoptr i64 %4088 to i32*
  %4091 = load i32, i32* %4090, align 4
  %4092 = sext i32 %4091 to i64
  %4093 = mul nsw i64 %4092, 520
  store i64 %4093, i64* %RCX, align 8, !tbaa !2428
  %4094 = lshr i64 %4093, 63
  %4095 = add i64 %4093, %4086
  store i64 %4095, i64* %RAX, align 8, !tbaa !2428
  %4096 = icmp ult i64 %4095, %4086
  %4097 = icmp ult i64 %4095, %4093
  %4098 = or i1 %4096, %4097
  %4099 = zext i1 %4098 to i8
  store i8 %4099, i8* %42, align 1, !tbaa !2432
  %4100 = trunc i64 %4095 to i32
  %4101 = and i32 %4100, 255
  %4102 = tail call i32 @llvm.ctpop.i32(i32 %4101) #8
  %4103 = trunc i32 %4102 to i8
  %4104 = and i8 %4103, 1
  %4105 = xor i8 %4104, 1
  store i8 %4105, i8* %49, align 1, !tbaa !2446
  %4106 = xor i64 %4093, %4086
  %4107 = xor i64 %4106, %4095
  %4108 = lshr i64 %4107, 4
  %4109 = trunc i64 %4108 to i8
  %4110 = and i8 %4109, 1
  store i8 %4110, i8* %54, align 1, !tbaa !2447
  %4111 = icmp eq i64 %4095, 0
  %4112 = zext i1 %4111 to i8
  store i8 %4112, i8* %57, align 1, !tbaa !2448
  %4113 = lshr i64 %4095, 63
  %4114 = trunc i64 %4113 to i8
  store i8 %4114, i8* %60, align 1, !tbaa !2449
  %4115 = lshr i64 %4086, 63
  %4116 = xor i64 %4113, %4115
  %4117 = xor i64 %4113, %4094
  %4118 = add nuw nsw i64 %4116, %4117
  %4119 = icmp eq i64 %4118, 2
  %4120 = zext i1 %4119 to i8
  store i8 %4120, i8* %66, align 1, !tbaa !2450
  %4121 = add i64 %4087, -104
  %4122 = add i64 %3906, 138
  store i64 %4122, i64* %PC, align 8
  %4123 = inttoptr i64 %4121 to i32*
  %4124 = load i32, i32* %4123, align 4
  %4125 = sext i32 %4124 to i64
  store i64 %4125, i64* %RCX, align 8, !tbaa !2428
  %4126 = shl nsw i64 %4125, 3
  %4127 = add i64 %4126, %4095
  %4128 = add i64 %3906, 143
  store i64 %4128, i64* %PC, align 8
  %4129 = inttoptr i64 %4127 to double*
  store double %4082, double* %4129, align 8
  %4130 = load i64, i64* %RBP, align 8
  %4131 = add i64 %4130, 72
  %4132 = load i64, i64* %PC, align 8
  %4133 = add i64 %4132, 4
  store i64 %4133, i64* %PC, align 8
  %4134 = inttoptr i64 %4131 to i64*
  %4135 = load i64, i64* %4134, align 8
  store i64 %4135, i64* %RAX, align 8, !tbaa !2428
  %4136 = add i64 %4130, -108
  %4137 = add i64 %4132, 8
  store i64 %4137, i64* %PC, align 8
  %4138 = inttoptr i64 %4136 to i32*
  %4139 = load i32, i32* %4138, align 4
  %4140 = sext i32 %4139 to i64
  store i64 %4140, i64* %RCX, align 8, !tbaa !2428
  %4141 = shl nsw i64 %4140, 3
  %4142 = add i64 %4141, %4135
  %4143 = add i64 %4132, 13
  store i64 %4143, i64* %PC, align 8
  %4144 = inttoptr i64 %4142 to double*
  %4145 = load double, double* %4144, align 8
  store double %4145, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %4146 = add i64 %4130, 80
  %4147 = add i64 %4132, 17
  store i64 %4147, i64* %PC, align 8
  %4148 = inttoptr i64 %4146 to i64*
  %4149 = load i64, i64* %4148, align 8
  store i64 %4149, i64* %RAX, align 8, !tbaa !2428
  %4150 = add i64 %4132, 21
  store i64 %4150, i64* %PC, align 8
  %4151 = load i32, i32* %4138, align 4
  %4152 = sext i32 %4151 to i64
  store i64 %4152, i64* %RCX, align 8, !tbaa !2428
  %4153 = shl nsw i64 %4152, 3
  %4154 = add i64 %4153, %4149
  %4155 = add i64 %4132, 26
  store i64 %4155, i64* %PC, align 8
  %4156 = inttoptr i64 %4154 to double*
  %4157 = load double, double* %4156, align 8
  %4158 = fdiv double %4145, %4157
  store double %4158, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %4159 = add i64 %4130, 48
  %4160 = add i64 %4132, 30
  store i64 %4160, i64* %PC, align 8
  %4161 = inttoptr i64 %4159 to i64*
  %4162 = load i64, i64* %4161, align 8
  store i64 %4162, i64* %RAX, align 8, !tbaa !2428
  %4163 = add i64 %4130, -100
  %4164 = add i64 %4132, 34
  store i64 %4164, i64* %PC, align 8
  %4165 = inttoptr i64 %4163 to i32*
  %4166 = load i32, i32* %4165, align 4
  %4167 = sext i32 %4166 to i64
  %4168 = mul nsw i64 %4167, 33800
  store i64 %4168, i64* %RCX, align 8, !tbaa !2428
  %4169 = lshr i64 %4168, 63
  %4170 = add i64 %4168, %4162
  store i64 %4170, i64* %RAX, align 8, !tbaa !2428
  %4171 = icmp ult i64 %4170, %4162
  %4172 = icmp ult i64 %4170, %4168
  %4173 = or i1 %4171, %4172
  %4174 = zext i1 %4173 to i8
  store i8 %4174, i8* %42, align 1, !tbaa !2432
  %4175 = trunc i64 %4170 to i32
  %4176 = and i32 %4175, 255
  %4177 = tail call i32 @llvm.ctpop.i32(i32 %4176) #8
  %4178 = trunc i32 %4177 to i8
  %4179 = and i8 %4178, 1
  %4180 = xor i8 %4179, 1
  store i8 %4180, i8* %49, align 1, !tbaa !2446
  %4181 = xor i64 %4168, %4162
  %4182 = xor i64 %4181, %4170
  %4183 = lshr i64 %4182, 4
  %4184 = trunc i64 %4183 to i8
  %4185 = and i8 %4184, 1
  store i8 %4185, i8* %54, align 1, !tbaa !2447
  %4186 = icmp eq i64 %4170, 0
  %4187 = zext i1 %4186 to i8
  store i8 %4187, i8* %57, align 1, !tbaa !2448
  %4188 = lshr i64 %4170, 63
  %4189 = trunc i64 %4188 to i8
  store i8 %4189, i8* %60, align 1, !tbaa !2449
  %4190 = lshr i64 %4162, 63
  %4191 = xor i64 %4188, %4190
  %4192 = xor i64 %4188, %4169
  %4193 = add nuw nsw i64 %4191, %4192
  %4194 = icmp eq i64 %4193, 2
  %4195 = zext i1 %4194 to i8
  store i8 %4195, i8* %66, align 1, !tbaa !2450
  %4196 = load i64, i64* %RBP, align 8
  %4197 = add i64 %4196, -104
  %4198 = add i64 %4132, 48
  store i64 %4198, i64* %PC, align 8
  %4199 = inttoptr i64 %4197 to i32*
  %4200 = load i32, i32* %4199, align 4
  %4201 = sext i32 %4200 to i64
  %4202 = mul nsw i64 %4201, 520
  store i64 %4202, i64* %RCX, align 8, !tbaa !2428
  %4203 = lshr i64 %4202, 63
  %4204 = add i64 %4202, %4170
  store i64 %4204, i64* %RAX, align 8, !tbaa !2428
  %4205 = icmp ult i64 %4204, %4170
  %4206 = icmp ult i64 %4204, %4202
  %4207 = or i1 %4205, %4206
  %4208 = zext i1 %4207 to i8
  store i8 %4208, i8* %42, align 1, !tbaa !2432
  %4209 = trunc i64 %4204 to i32
  %4210 = and i32 %4209, 255
  %4211 = tail call i32 @llvm.ctpop.i32(i32 %4210) #8
  %4212 = trunc i32 %4211 to i8
  %4213 = and i8 %4212, 1
  %4214 = xor i8 %4213, 1
  store i8 %4214, i8* %49, align 1, !tbaa !2446
  %4215 = xor i64 %4202, %4170
  %4216 = xor i64 %4215, %4204
  %4217 = lshr i64 %4216, 4
  %4218 = trunc i64 %4217 to i8
  %4219 = and i8 %4218, 1
  store i8 %4219, i8* %54, align 1, !tbaa !2447
  %4220 = icmp eq i64 %4204, 0
  %4221 = zext i1 %4220 to i8
  store i8 %4221, i8* %57, align 1, !tbaa !2448
  %4222 = lshr i64 %4204, 63
  %4223 = trunc i64 %4222 to i8
  store i8 %4223, i8* %60, align 1, !tbaa !2449
  %4224 = xor i64 %4222, %4188
  %4225 = xor i64 %4222, %4203
  %4226 = add nuw nsw i64 %4224, %4225
  %4227 = icmp eq i64 %4226, 2
  %4228 = zext i1 %4227 to i8
  store i8 %4228, i8* %66, align 1, !tbaa !2450
  %4229 = add i64 %4196, -108
  %4230 = add i64 %4132, 62
  store i64 %4230, i64* %PC, align 8
  %4231 = inttoptr i64 %4229 to i32*
  %4232 = load i32, i32* %4231, align 4
  %4233 = sext i32 %4232 to i64
  store i64 %4233, i64* %RCX, align 8, !tbaa !2428
  %4234 = shl nsw i64 %4233, 3
  %4235 = add i64 %4234, %4204
  %4236 = add i64 %4132, 67
  store i64 %4236, i64* %PC, align 8
  %4237 = load double, double* %228, align 1
  %4238 = inttoptr i64 %4235 to double*
  %4239 = load double, double* %4238, align 8
  %4240 = fmul double %4237, %4239
  store double %4240, double* %228, align 1, !tbaa !2452
  %4241 = add i64 %4196, -64
  %4242 = add i64 %4132, 72
  store i64 %4242, i64* %PC, align 8
  %4243 = inttoptr i64 %4241 to double*
  %4244 = load double, double* %4243, align 8
  store double %4244, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %4245 = add i64 %4196, 64
  %4246 = add i64 %4132, 76
  store i64 %4246, i64* %PC, align 8
  %4247 = inttoptr i64 %4245 to i64*
  %4248 = load i64, i64* %4247, align 8
  store i64 %4248, i64* %RAX, align 8, !tbaa !2428
  %4249 = add i64 %4196, -100
  %4250 = add i64 %4132, 80
  store i64 %4250, i64* %PC, align 8
  %4251 = inttoptr i64 %4249 to i32*
  %4252 = load i32, i32* %4251, align 4
  %4253 = sext i32 %4252 to i64
  store i64 %4253, i64* %RCX, align 8, !tbaa !2428
  %4254 = shl nsw i64 %4253, 3
  %4255 = add i64 %4254, %4248
  %4256 = add i64 %4132, 85
  store i64 %4256, i64* %PC, align 8
  %4257 = inttoptr i64 %4255 to double*
  %4258 = load double, double* %4257, align 8
  %4259 = fmul double %4244, %4258
  store double %4259, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %4260 = load i64, i64* %RBP, align 8
  %4261 = add i64 %4260, 80
  %4262 = add i64 %4132, 89
  store i64 %4262, i64* %PC, align 8
  %4263 = inttoptr i64 %4261 to i64*
  %4264 = load i64, i64* %4263, align 8
  store i64 %4264, i64* %RAX, align 8, !tbaa !2428
  %4265 = add i64 %4260, -108
  %4266 = add i64 %4132, 93
  store i64 %4266, i64* %PC, align 8
  %4267 = inttoptr i64 %4265 to i32*
  %4268 = load i32, i32* %4267, align 4
  %4269 = sext i32 %4268 to i64
  store i64 %4269, i64* %RCX, align 8, !tbaa !2428
  %4270 = shl nsw i64 %4269, 3
  %4271 = add i64 %4270, %4264
  %4272 = add i64 %4132, 98
  store i64 %4272, i64* %PC, align 8
  %4273 = inttoptr i64 %4271 to double*
  %4274 = load double, double* %4273, align 8
  %4275 = fdiv double %4259, %4274
  store double %4275, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %4276 = add i64 %4260, 16
  %4277 = add i64 %4132, 102
  store i64 %4277, i64* %PC, align 8
  %4278 = inttoptr i64 %4276 to i64*
  %4279 = load i64, i64* %4278, align 8
  store i64 %4279, i64* %RAX, align 8, !tbaa !2428
  %4280 = add i64 %4260, -100
  %4281 = add i64 %4132, 106
  store i64 %4281, i64* %PC, align 8
  %4282 = inttoptr i64 %4280 to i32*
  %4283 = load i32, i32* %4282, align 4
  %4284 = sext i32 %4283 to i64
  %4285 = mul nsw i64 %4284, 520
  store i64 %4285, i64* %RCX, align 8, !tbaa !2428
  %4286 = lshr i64 %4285, 63
  %4287 = add i64 %4285, %4279
  store i64 %4287, i64* %RAX, align 8, !tbaa !2428
  %4288 = icmp ult i64 %4287, %4279
  %4289 = icmp ult i64 %4287, %4285
  %4290 = or i1 %4288, %4289
  %4291 = zext i1 %4290 to i8
  store i8 %4291, i8* %42, align 1, !tbaa !2432
  %4292 = trunc i64 %4287 to i32
  %4293 = and i32 %4292, 255
  %4294 = tail call i32 @llvm.ctpop.i32(i32 %4293) #8
  %4295 = trunc i32 %4294 to i8
  %4296 = and i8 %4295, 1
  %4297 = xor i8 %4296, 1
  store i8 %4297, i8* %49, align 1, !tbaa !2446
  %4298 = xor i64 %4285, %4279
  %4299 = xor i64 %4298, %4287
  %4300 = lshr i64 %4299, 4
  %4301 = trunc i64 %4300 to i8
  %4302 = and i8 %4301, 1
  store i8 %4302, i8* %54, align 1, !tbaa !2447
  %4303 = icmp eq i64 %4287, 0
  %4304 = zext i1 %4303 to i8
  store i8 %4304, i8* %57, align 1, !tbaa !2448
  %4305 = lshr i64 %4287, 63
  %4306 = trunc i64 %4305 to i8
  store i8 %4306, i8* %60, align 1, !tbaa !2449
  %4307 = lshr i64 %4279, 63
  %4308 = xor i64 %4305, %4307
  %4309 = xor i64 %4305, %4286
  %4310 = add nuw nsw i64 %4308, %4309
  %4311 = icmp eq i64 %4310, 2
  %4312 = zext i1 %4311 to i8
  store i8 %4312, i8* %66, align 1, !tbaa !2450
  %4313 = add i64 %4260, -104
  %4314 = add i64 %4132, 120
  store i64 %4314, i64* %PC, align 8
  %4315 = inttoptr i64 %4313 to i32*
  %4316 = load i32, i32* %4315, align 4
  %4317 = sext i32 %4316 to i64
  store i64 %4317, i64* %RCX, align 8, !tbaa !2428
  %4318 = shl nsw i64 %4317, 3
  %4319 = add i64 %4318, %4287
  %4320 = add i64 %4132, 125
  store i64 %4320, i64* %PC, align 8
  %4321 = inttoptr i64 %4319 to double*
  %4322 = load double, double* %4321, align 8
  %4323 = fmul double %4275, %4322
  store double %4323, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %4324 = load double, double* %228, align 1
  %4325 = fadd double %4324, %4323
  store double %4325, double* %228, align 1, !tbaa !2452
  %4326 = load i64, i64* %RBP, align 8
  %4327 = add i64 %4326, -64
  %4328 = add i64 %4132, 134
  store i64 %4328, i64* %PC, align 8
  %4329 = inttoptr i64 %4327 to double*
  %4330 = load double, double* %4329, align 8
  store double %4330, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %4331 = add i64 %4326, 56
  %4332 = add i64 %4132, 138
  store i64 %4332, i64* %PC, align 8
  %4333 = inttoptr i64 %4331 to i64*
  %4334 = load i64, i64* %4333, align 8
  store i64 %4334, i64* %RAX, align 8, !tbaa !2428
  %4335 = add i64 %4326, -100
  %4336 = add i64 %4132, 142
  store i64 %4336, i64* %PC, align 8
  %4337 = inttoptr i64 %4335 to i32*
  %4338 = load i32, i32* %4337, align 4
  %4339 = sext i32 %4338 to i64
  store i64 %4339, i64* %RCX, align 8, !tbaa !2428
  %4340 = shl nsw i64 %4339, 3
  %4341 = add i64 %4340, %4334
  %4342 = add i64 %4132, 147
  store i64 %4342, i64* %PC, align 8
  %4343 = inttoptr i64 %4341 to double*
  %4344 = load double, double* %4343, align 8
  %4345 = fmul double %4330, %4344
  store double %4345, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %4346 = add i64 %4326, 80
  %4347 = add i64 %4132, 151
  store i64 %4347, i64* %PC, align 8
  %4348 = inttoptr i64 %4346 to i64*
  %4349 = load i64, i64* %4348, align 8
  store i64 %4349, i64* %RAX, align 8, !tbaa !2428
  %4350 = add i64 %4326, -108
  %4351 = add i64 %4132, 155
  store i64 %4351, i64* %PC, align 8
  %4352 = inttoptr i64 %4350 to i32*
  %4353 = load i32, i32* %4352, align 4
  %4354 = sext i32 %4353 to i64
  store i64 %4354, i64* %RCX, align 8, !tbaa !2428
  %4355 = shl nsw i64 %4354, 3
  %4356 = add i64 %4355, %4349
  %4357 = add i64 %4132, 160
  store i64 %4357, i64* %PC, align 8
  %4358 = inttoptr i64 %4356 to double*
  %4359 = load double, double* %4358, align 8
  %4360 = fdiv double %4345, %4359
  store double %4360, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %4361 = add i64 %4326, 24
  %4362 = add i64 %4132, 164
  store i64 %4362, i64* %PC, align 8
  %4363 = inttoptr i64 %4361 to i64*
  %4364 = load i64, i64* %4363, align 8
  store i64 %4364, i64* %RAX, align 8, !tbaa !2428
  %4365 = add i64 %4132, 168
  store i64 %4365, i64* %PC, align 8
  %4366 = load i32, i32* %4337, align 4
  %4367 = sext i32 %4366 to i64
  %4368 = mul nsw i64 %4367, 33800
  store i64 %4368, i64* %RCX, align 8, !tbaa !2428
  %4369 = lshr i64 %4368, 63
  %4370 = add i64 %4368, %4364
  store i64 %4370, i64* %RAX, align 8, !tbaa !2428
  %4371 = icmp ult i64 %4370, %4364
  %4372 = icmp ult i64 %4370, %4368
  %4373 = or i1 %4371, %4372
  %4374 = zext i1 %4373 to i8
  store i8 %4374, i8* %42, align 1, !tbaa !2432
  %4375 = trunc i64 %4370 to i32
  %4376 = and i32 %4375, 255
  %4377 = tail call i32 @llvm.ctpop.i32(i32 %4376) #8
  %4378 = trunc i32 %4377 to i8
  %4379 = and i8 %4378, 1
  %4380 = xor i8 %4379, 1
  store i8 %4380, i8* %49, align 1, !tbaa !2446
  %4381 = xor i64 %4368, %4364
  %4382 = xor i64 %4381, %4370
  %4383 = lshr i64 %4382, 4
  %4384 = trunc i64 %4383 to i8
  %4385 = and i8 %4384, 1
  store i8 %4385, i8* %54, align 1, !tbaa !2447
  %4386 = icmp eq i64 %4370, 0
  %4387 = zext i1 %4386 to i8
  store i8 %4387, i8* %57, align 1, !tbaa !2448
  %4388 = lshr i64 %4370, 63
  %4389 = trunc i64 %4388 to i8
  store i8 %4389, i8* %60, align 1, !tbaa !2449
  %4390 = lshr i64 %4364, 63
  %4391 = xor i64 %4388, %4390
  %4392 = xor i64 %4388, %4369
  %4393 = add nuw nsw i64 %4391, %4392
  %4394 = icmp eq i64 %4393, 2
  %4395 = zext i1 %4394 to i8
  store i8 %4395, i8* %66, align 1, !tbaa !2450
  %4396 = load i64, i64* %RBP, align 8
  %4397 = add i64 %4396, -104
  %4398 = add i64 %4132, 182
  store i64 %4398, i64* %PC, align 8
  %4399 = inttoptr i64 %4397 to i32*
  %4400 = load i32, i32* %4399, align 4
  %4401 = sext i32 %4400 to i64
  %4402 = mul nsw i64 %4401, 520
  store i64 %4402, i64* %RCX, align 8, !tbaa !2428
  %4403 = lshr i64 %4402, 63
  %4404 = add i64 %4402, %4370
  store i64 %4404, i64* %RAX, align 8, !tbaa !2428
  %4405 = icmp ult i64 %4404, %4370
  %4406 = icmp ult i64 %4404, %4402
  %4407 = or i1 %4405, %4406
  %4408 = zext i1 %4407 to i8
  store i8 %4408, i8* %42, align 1, !tbaa !2432
  %4409 = trunc i64 %4404 to i32
  %4410 = and i32 %4409, 255
  %4411 = tail call i32 @llvm.ctpop.i32(i32 %4410) #8
  %4412 = trunc i32 %4411 to i8
  %4413 = and i8 %4412, 1
  %4414 = xor i8 %4413, 1
  store i8 %4414, i8* %49, align 1, !tbaa !2446
  %4415 = xor i64 %4402, %4370
  %4416 = xor i64 %4415, %4404
  %4417 = lshr i64 %4416, 4
  %4418 = trunc i64 %4417 to i8
  %4419 = and i8 %4418, 1
  store i8 %4419, i8* %54, align 1, !tbaa !2447
  %4420 = icmp eq i64 %4404, 0
  %4421 = zext i1 %4420 to i8
  store i8 %4421, i8* %57, align 1, !tbaa !2448
  %4422 = lshr i64 %4404, 63
  %4423 = trunc i64 %4422 to i8
  store i8 %4423, i8* %60, align 1, !tbaa !2449
  %4424 = xor i64 %4422, %4388
  %4425 = xor i64 %4422, %4403
  %4426 = add nuw nsw i64 %4424, %4425
  %4427 = icmp eq i64 %4426, 2
  %4428 = zext i1 %4427 to i8
  store i8 %4428, i8* %66, align 1, !tbaa !2450
  %4429 = add i64 %4396, -108
  %4430 = add i64 %4132, 196
  store i64 %4430, i64* %PC, align 8
  %4431 = inttoptr i64 %4429 to i32*
  %4432 = load i32, i32* %4431, align 4
  %4433 = sext i32 %4432 to i64
  store i64 %4433, i64* %RCX, align 8, !tbaa !2428
  %4434 = shl nsw i64 %4433, 3
  %4435 = add i64 %4434, %4404
  %4436 = add i64 %4132, 201
  store i64 %4436, i64* %PC, align 8
  %4437 = load double, double* %231, align 1
  %4438 = inttoptr i64 %4435 to double*
  %4439 = load double, double* %4438, align 8
  %4440 = fmul double %4437, %4439
  store double %4440, double* %231, align 1, !tbaa !2452
  %4441 = load double, double* %228, align 1
  %4442 = fsub double %4441, %4440
  store double %4442, double* %228, align 1, !tbaa !2452
  %4443 = add i64 %4396, 48
  %4444 = add i64 %4132, 209
  store i64 %4444, i64* %PC, align 8
  %4445 = inttoptr i64 %4443 to i64*
  %4446 = load i64, i64* %4445, align 8
  store i64 %4446, i64* %RAX, align 8, !tbaa !2428
  %4447 = add i64 %4396, -100
  %4448 = add i64 %4132, 213
  store i64 %4448, i64* %PC, align 8
  %4449 = inttoptr i64 %4447 to i32*
  %4450 = load i32, i32* %4449, align 4
  %4451 = sext i32 %4450 to i64
  %4452 = mul nsw i64 %4451, 33800
  store i64 %4452, i64* %RCX, align 8, !tbaa !2428
  %4453 = lshr i64 %4452, 63
  %4454 = add i64 %4452, %4446
  store i64 %4454, i64* %RAX, align 8, !tbaa !2428
  %4455 = icmp ult i64 %4454, %4446
  %4456 = icmp ult i64 %4454, %4452
  %4457 = or i1 %4455, %4456
  %4458 = zext i1 %4457 to i8
  store i8 %4458, i8* %42, align 1, !tbaa !2432
  %4459 = trunc i64 %4454 to i32
  %4460 = and i32 %4459, 255
  %4461 = tail call i32 @llvm.ctpop.i32(i32 %4460) #8
  %4462 = trunc i32 %4461 to i8
  %4463 = and i8 %4462, 1
  %4464 = xor i8 %4463, 1
  store i8 %4464, i8* %49, align 1, !tbaa !2446
  %4465 = xor i64 %4452, %4446
  %4466 = xor i64 %4465, %4454
  %4467 = lshr i64 %4466, 4
  %4468 = trunc i64 %4467 to i8
  %4469 = and i8 %4468, 1
  store i8 %4469, i8* %54, align 1, !tbaa !2447
  %4470 = icmp eq i64 %4454, 0
  %4471 = zext i1 %4470 to i8
  store i8 %4471, i8* %57, align 1, !tbaa !2448
  %4472 = lshr i64 %4454, 63
  %4473 = trunc i64 %4472 to i8
  store i8 %4473, i8* %60, align 1, !tbaa !2449
  %4474 = lshr i64 %4446, 63
  %4475 = xor i64 %4472, %4474
  %4476 = xor i64 %4472, %4453
  %4477 = add nuw nsw i64 %4475, %4476
  %4478 = icmp eq i64 %4477, 2
  %4479 = zext i1 %4478 to i8
  store i8 %4479, i8* %66, align 1, !tbaa !2450
  %4480 = load i64, i64* %RBP, align 8
  %4481 = add i64 %4480, -104
  %4482 = add i64 %4132, 227
  store i64 %4482, i64* %PC, align 8
  %4483 = inttoptr i64 %4481 to i32*
  %4484 = load i32, i32* %4483, align 4
  %4485 = sext i32 %4484 to i64
  %4486 = mul nsw i64 %4485, 520
  store i64 %4486, i64* %RCX, align 8, !tbaa !2428
  %4487 = lshr i64 %4486, 63
  %4488 = add i64 %4486, %4454
  store i64 %4488, i64* %RAX, align 8, !tbaa !2428
  %4489 = icmp ult i64 %4488, %4454
  %4490 = icmp ult i64 %4488, %4486
  %4491 = or i1 %4489, %4490
  %4492 = zext i1 %4491 to i8
  store i8 %4492, i8* %42, align 1, !tbaa !2432
  %4493 = trunc i64 %4488 to i32
  %4494 = and i32 %4493, 255
  %4495 = tail call i32 @llvm.ctpop.i32(i32 %4494) #8
  %4496 = trunc i32 %4495 to i8
  %4497 = and i8 %4496, 1
  %4498 = xor i8 %4497, 1
  store i8 %4498, i8* %49, align 1, !tbaa !2446
  %4499 = xor i64 %4486, %4454
  %4500 = xor i64 %4499, %4488
  %4501 = lshr i64 %4500, 4
  %4502 = trunc i64 %4501 to i8
  %4503 = and i8 %4502, 1
  store i8 %4503, i8* %54, align 1, !tbaa !2447
  %4504 = icmp eq i64 %4488, 0
  %4505 = zext i1 %4504 to i8
  store i8 %4505, i8* %57, align 1, !tbaa !2448
  %4506 = lshr i64 %4488, 63
  %4507 = trunc i64 %4506 to i8
  store i8 %4507, i8* %60, align 1, !tbaa !2449
  %4508 = xor i64 %4506, %4472
  %4509 = xor i64 %4506, %4487
  %4510 = add nuw nsw i64 %4508, %4509
  %4511 = icmp eq i64 %4510, 2
  %4512 = zext i1 %4511 to i8
  store i8 %4512, i8* %66, align 1, !tbaa !2450
  %4513 = add i64 %4480, -108
  %4514 = add i64 %4132, 241
  store i64 %4514, i64* %PC, align 8
  %4515 = inttoptr i64 %4513 to i32*
  %4516 = load i32, i32* %4515, align 4
  %4517 = sext i32 %4516 to i64
  store i64 %4517, i64* %RCX, align 8, !tbaa !2428
  %4518 = shl nsw i64 %4517, 3
  %4519 = add i64 %4518, %4488
  %4520 = add i64 %4132, 246
  store i64 %4520, i64* %PC, align 8
  %4521 = load i64, i64* %147, align 1
  %4522 = inttoptr i64 %4519 to i64*
  store i64 %4521, i64* %4522, align 8
  %4523 = load i64, i64* %RBP, align 8
  %4524 = add i64 %4523, 16
  %4525 = load i64, i64* %PC, align 8
  %4526 = add i64 %4525, 4
  store i64 %4526, i64* %PC, align 8
  %4527 = inttoptr i64 %4524 to i64*
  %4528 = load i64, i64* %4527, align 8
  store i64 %4528, i64* %RAX, align 8, !tbaa !2428
  %4529 = add i64 %4523, -100
  %4530 = add i64 %4525, 8
  store i64 %4530, i64* %PC, align 8
  %4531 = inttoptr i64 %4529 to i32*
  %4532 = load i32, i32* %4531, align 4
  %4533 = sext i32 %4532 to i64
  %4534 = mul nsw i64 %4533, 520
  store i64 %4534, i64* %RCX, align 8, !tbaa !2428
  %4535 = lshr i64 %4534, 63
  %4536 = add i64 %4534, %4528
  store i64 %4536, i64* %RAX, align 8, !tbaa !2428
  %4537 = icmp ult i64 %4536, %4528
  %4538 = icmp ult i64 %4536, %4534
  %4539 = or i1 %4537, %4538
  %4540 = zext i1 %4539 to i8
  store i8 %4540, i8* %42, align 1, !tbaa !2432
  %4541 = trunc i64 %4536 to i32
  %4542 = and i32 %4541, 255
  %4543 = tail call i32 @llvm.ctpop.i32(i32 %4542) #8
  %4544 = trunc i32 %4543 to i8
  %4545 = and i8 %4544, 1
  %4546 = xor i8 %4545, 1
  store i8 %4546, i8* %49, align 1, !tbaa !2446
  %4547 = xor i64 %4534, %4528
  %4548 = xor i64 %4547, %4536
  %4549 = lshr i64 %4548, 4
  %4550 = trunc i64 %4549 to i8
  %4551 = and i8 %4550, 1
  store i8 %4551, i8* %54, align 1, !tbaa !2447
  %4552 = icmp eq i64 %4536, 0
  %4553 = zext i1 %4552 to i8
  store i8 %4553, i8* %57, align 1, !tbaa !2448
  %4554 = lshr i64 %4536, 63
  %4555 = trunc i64 %4554 to i8
  store i8 %4555, i8* %60, align 1, !tbaa !2449
  %4556 = lshr i64 %4528, 63
  %4557 = xor i64 %4554, %4556
  %4558 = xor i64 %4554, %4535
  %4559 = add nuw nsw i64 %4557, %4558
  %4560 = icmp eq i64 %4559, 2
  %4561 = zext i1 %4560 to i8
  store i8 %4561, i8* %66, align 1, !tbaa !2450
  %4562 = add i64 %4523, -104
  %4563 = add i64 %4525, 22
  store i64 %4563, i64* %PC, align 8
  %4564 = inttoptr i64 %4562 to i32*
  %4565 = load i32, i32* %4564, align 4
  %4566 = sext i32 %4565 to i64
  store i64 %4566, i64* %RCX, align 8, !tbaa !2428
  %4567 = shl nsw i64 %4566, 3
  %4568 = add i64 %4567, %4536
  %4569 = add i64 %4525, 27
  store i64 %4569, i64* %PC, align 8
  %4570 = inttoptr i64 %4568 to i64*
  %4571 = load i64, i64* %4570, align 8
  store i64 %4571, i64* %147, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %4572 = add i64 %4523, 24
  %4573 = add i64 %4525, 31
  store i64 %4573, i64* %PC, align 8
  %4574 = inttoptr i64 %4572 to i64*
  %4575 = load i64, i64* %4574, align 8
  store i64 %4575, i64* %RAX, align 8, !tbaa !2428
  %4576 = add i64 %4525, 35
  store i64 %4576, i64* %PC, align 8
  %4577 = load i32, i32* %4531, align 4
  %4578 = sext i32 %4577 to i64
  %4579 = mul nsw i64 %4578, 33800
  store i64 %4579, i64* %RCX, align 8, !tbaa !2428
  %4580 = lshr i64 %4579, 63
  %4581 = add i64 %4579, %4575
  store i64 %4581, i64* %RAX, align 8, !tbaa !2428
  %4582 = icmp ult i64 %4581, %4575
  %4583 = icmp ult i64 %4581, %4579
  %4584 = or i1 %4582, %4583
  %4585 = zext i1 %4584 to i8
  store i8 %4585, i8* %42, align 1, !tbaa !2432
  %4586 = trunc i64 %4581 to i32
  %4587 = and i32 %4586, 255
  %4588 = tail call i32 @llvm.ctpop.i32(i32 %4587) #8
  %4589 = trunc i32 %4588 to i8
  %4590 = and i8 %4589, 1
  %4591 = xor i8 %4590, 1
  store i8 %4591, i8* %49, align 1, !tbaa !2446
  %4592 = xor i64 %4579, %4575
  %4593 = xor i64 %4592, %4581
  %4594 = lshr i64 %4593, 4
  %4595 = trunc i64 %4594 to i8
  %4596 = and i8 %4595, 1
  store i8 %4596, i8* %54, align 1, !tbaa !2447
  %4597 = icmp eq i64 %4581, 0
  %4598 = zext i1 %4597 to i8
  store i8 %4598, i8* %57, align 1, !tbaa !2448
  %4599 = lshr i64 %4581, 63
  %4600 = trunc i64 %4599 to i8
  store i8 %4600, i8* %60, align 1, !tbaa !2449
  %4601 = lshr i64 %4575, 63
  %4602 = xor i64 %4599, %4601
  %4603 = xor i64 %4599, %4580
  %4604 = add nuw nsw i64 %4602, %4603
  %4605 = icmp eq i64 %4604, 2
  %4606 = zext i1 %4605 to i8
  store i8 %4606, i8* %66, align 1, !tbaa !2450
  %4607 = load i64, i64* %RBP, align 8
  %4608 = add i64 %4607, -104
  %4609 = add i64 %4525, 49
  store i64 %4609, i64* %PC, align 8
  %4610 = inttoptr i64 %4608 to i32*
  %4611 = load i32, i32* %4610, align 4
  %4612 = sext i32 %4611 to i64
  %4613 = mul nsw i64 %4612, 520
  store i64 %4613, i64* %RCX, align 8, !tbaa !2428
  %4614 = lshr i64 %4613, 63
  %4615 = add i64 %4613, %4581
  store i64 %4615, i64* %RAX, align 8, !tbaa !2428
  %4616 = icmp ult i64 %4615, %4581
  %4617 = icmp ult i64 %4615, %4613
  %4618 = or i1 %4616, %4617
  %4619 = zext i1 %4618 to i8
  store i8 %4619, i8* %42, align 1, !tbaa !2432
  %4620 = trunc i64 %4615 to i32
  %4621 = and i32 %4620, 255
  %4622 = tail call i32 @llvm.ctpop.i32(i32 %4621) #8
  %4623 = trunc i32 %4622 to i8
  %4624 = and i8 %4623, 1
  %4625 = xor i8 %4624, 1
  store i8 %4625, i8* %49, align 1, !tbaa !2446
  %4626 = xor i64 %4613, %4581
  %4627 = xor i64 %4626, %4615
  %4628 = lshr i64 %4627, 4
  %4629 = trunc i64 %4628 to i8
  %4630 = and i8 %4629, 1
  store i8 %4630, i8* %54, align 1, !tbaa !2447
  %4631 = icmp eq i64 %4615, 0
  %4632 = zext i1 %4631 to i8
  store i8 %4632, i8* %57, align 1, !tbaa !2448
  %4633 = lshr i64 %4615, 63
  %4634 = trunc i64 %4633 to i8
  store i8 %4634, i8* %60, align 1, !tbaa !2449
  %4635 = xor i64 %4633, %4599
  %4636 = xor i64 %4633, %4614
  %4637 = add nuw nsw i64 %4635, %4636
  %4638 = icmp eq i64 %4637, 2
  %4639 = zext i1 %4638 to i8
  store i8 %4639, i8* %66, align 1, !tbaa !2450
  %4640 = add i64 %4607, -108
  %4641 = add i64 %4525, 63
  store i64 %4641, i64* %PC, align 8
  %4642 = inttoptr i64 %4640 to i32*
  %4643 = load i32, i32* %4642, align 4
  %4644 = sext i32 %4643 to i64
  store i64 %4644, i64* %RCX, align 8, !tbaa !2428
  %4645 = shl nsw i64 %4644, 3
  %4646 = add i64 %4645, %4615
  %4647 = add i64 %4525, 68
  store i64 %4647, i64* %PC, align 8
  %4648 = load i64, i64* %147, align 1
  %4649 = inttoptr i64 %4646 to i64*
  store i64 %4648, i64* %4649, align 8
  %4650 = load i64, i64* %RBP, align 8
  %4651 = add i64 %4650, -108
  %4652 = load i64, i64* %PC, align 8
  %4653 = add i64 %4652, 3
  store i64 %4653, i64* %PC, align 8
  %4654 = inttoptr i64 %4651 to i32*
  %4655 = load i32, i32* %4654, align 4
  %4656 = add i32 %4655, 1
  %4657 = zext i32 %4656 to i64
  store i64 %4657, i64* %RAX, align 8, !tbaa !2428
  %4658 = icmp eq i32 %4655, -1
  %4659 = icmp eq i32 %4656, 0
  %4660 = or i1 %4658, %4659
  %4661 = zext i1 %4660 to i8
  store i8 %4661, i8* %42, align 1, !tbaa !2432
  %4662 = and i32 %4656, 255
  %4663 = tail call i32 @llvm.ctpop.i32(i32 %4662) #8
  %4664 = trunc i32 %4663 to i8
  %4665 = and i8 %4664, 1
  %4666 = xor i8 %4665, 1
  store i8 %4666, i8* %49, align 1, !tbaa !2446
  %4667 = xor i32 %4655, %4656
  %4668 = lshr i32 %4667, 4
  %4669 = trunc i32 %4668 to i8
  %4670 = and i8 %4669, 1
  store i8 %4670, i8* %54, align 1, !tbaa !2447
  %4671 = zext i1 %4659 to i8
  store i8 %4671, i8* %57, align 1, !tbaa !2448
  %4672 = lshr i32 %4656, 31
  %4673 = trunc i32 %4672 to i8
  store i8 %4673, i8* %60, align 1, !tbaa !2449
  %4674 = lshr i32 %4655, 31
  %4675 = xor i32 %4672, %4674
  %4676 = add nuw nsw i32 %4675, %4672
  %4677 = icmp eq i32 %4676, 2
  %4678 = zext i1 %4677 to i8
  store i8 %4678, i8* %66, align 1, !tbaa !2450
  %4679 = add i64 %4652, 9
  store i64 %4679, i64* %PC, align 8
  store i32 %4656, i32* %4654, align 4
  %4680 = load i64, i64* %PC, align 8
  %4681 = add i64 %4680, -679
  store i64 %4681, i64* %PC, align 8, !tbaa !2428
  br label %block_401fe0

block_401fc6:                                     ; preds = %block_401fba
  %4682 = add i64 %238, -104
  %4683 = add i64 %274, 7
  store i64 %4683, i64* %PC, align 8
  %4684 = inttoptr i64 %4682 to i32*
  store i32 0, i32* %4684, align 4
  %.pre2 = load i64, i64* %PC, align 8
  br label %block_401fcd

block_402a25:                                     ; preds = %block_401fcd
  %4685 = add i64 %327, -100
  %4686 = add i64 %363, 8
  store i64 %4686, i64* %PC, align 8
  %4687 = inttoptr i64 %4685 to i32*
  %4688 = load i32, i32* %4687, align 4
  %4689 = add i32 %4688, 1
  %4690 = zext i32 %4689 to i64
  store i64 %4690, i64* %RAX, align 8, !tbaa !2428
  %4691 = icmp eq i32 %4688, -1
  %4692 = icmp eq i32 %4689, 0
  %4693 = or i1 %4691, %4692
  %4694 = zext i1 %4693 to i8
  store i8 %4694, i8* %42, align 1, !tbaa !2432
  %4695 = and i32 %4689, 255
  %4696 = tail call i32 @llvm.ctpop.i32(i32 %4695) #8
  %4697 = trunc i32 %4696 to i8
  %4698 = and i8 %4697, 1
  %4699 = xor i8 %4698, 1
  store i8 %4699, i8* %49, align 1, !tbaa !2446
  %4700 = xor i32 %4688, %4689
  %4701 = lshr i32 %4700, 4
  %4702 = trunc i32 %4701 to i8
  %4703 = and i8 %4702, 1
  store i8 %4703, i8* %54, align 1, !tbaa !2447
  %4704 = zext i1 %4692 to i8
  store i8 %4704, i8* %57, align 1, !tbaa !2448
  %4705 = lshr i32 %4689, 31
  %4706 = trunc i32 %4705 to i8
  store i8 %4706, i8* %60, align 1, !tbaa !2449
  %4707 = lshr i32 %4688, 31
  %4708 = xor i32 %4705, %4707
  %4709 = add nuw nsw i32 %4708, %4705
  %4710 = icmp eq i32 %4709, 2
  %4711 = zext i1 %4710 to i8
  store i8 %4711, i8* %66, align 1, !tbaa !2450
  %4712 = add i64 %363, 14
  store i64 %4712, i64* %PC, align 8
  store i32 %4689, i32* %4687, align 4
  %4713 = load i64, i64* %PC, align 8
  %4714 = add i64 %4713, -2681
  store i64 %4714, i64* %PC, align 8, !tbaa !2428
  br label %block_401fba

block_401fe0:                                     ; preds = %block_401fec, %block_401fd9
  %4715 = phi i64 [ %4681, %block_401fec ], [ %.pre3, %block_401fd9 ]
  %4716 = load i64, i64* %RBP, align 8
  %4717 = add i64 %4716, -108
  %4718 = add i64 %4715, 3
  store i64 %4718, i64* %PC, align 8
  %4719 = inttoptr i64 %4717 to i32*
  %4720 = load i32, i32* %4719, align 4
  %4721 = zext i32 %4720 to i64
  store i64 %4721, i64* %RAX, align 8, !tbaa !2428
  %4722 = add i64 %4716, -48
  %4723 = add i64 %4715, 6
  store i64 %4723, i64* %PC, align 8
  %4724 = inttoptr i64 %4722 to i32*
  %4725 = load i32, i32* %4724, align 4
  %4726 = sub i32 %4720, %4725
  %4727 = icmp ult i32 %4720, %4725
  %4728 = zext i1 %4727 to i8
  store i8 %4728, i8* %42, align 1, !tbaa !2432
  %4729 = and i32 %4726, 255
  %4730 = tail call i32 @llvm.ctpop.i32(i32 %4729) #8
  %4731 = trunc i32 %4730 to i8
  %4732 = and i8 %4731, 1
  %4733 = xor i8 %4732, 1
  store i8 %4733, i8* %49, align 1, !tbaa !2446
  %4734 = xor i32 %4725, %4720
  %4735 = xor i32 %4734, %4726
  %4736 = lshr i32 %4735, 4
  %4737 = trunc i32 %4736 to i8
  %4738 = and i8 %4737, 1
  store i8 %4738, i8* %54, align 1, !tbaa !2447
  %4739 = icmp eq i32 %4726, 0
  %4740 = zext i1 %4739 to i8
  store i8 %4740, i8* %57, align 1, !tbaa !2448
  %4741 = lshr i32 %4726, 31
  %4742 = trunc i32 %4741 to i8
  store i8 %4742, i8* %60, align 1, !tbaa !2449
  %4743 = lshr i32 %4720, 31
  %4744 = lshr i32 %4725, 31
  %4745 = xor i32 %4744, %4743
  %4746 = xor i32 %4741, %4743
  %4747 = add nuw nsw i32 %4746, %4745
  %4748 = icmp eq i32 %4747, 2
  %4749 = zext i1 %4748 to i8
  store i8 %4749, i8* %66, align 1, !tbaa !2450
  %4750 = icmp ne i8 %4742, 0
  %4751 = xor i1 %4750, %4748
  %.v6 = select i1 %4751, i64 12, i64 684
  %4752 = add i64 %4715, %.v6
  %4753 = add i64 %4716, 32
  %4754 = add i64 %4752, 4
  store i64 %4754, i64* %PC, align 8
  %4755 = inttoptr i64 %4753 to i64*
  %4756 = load i64, i64* %4755, align 8
  store i64 %4756, i64* %RAX, align 8, !tbaa !2428
  %4757 = add i64 %4716, -100
  %4758 = add i64 %4752, 8
  store i64 %4758, i64* %PC, align 8
  %4759 = inttoptr i64 %4757 to i32*
  %4760 = load i32, i32* %4759, align 4
  %4761 = sext i32 %4760 to i64
  %4762 = mul nsw i64 %4761, 33800
  store i64 %4762, i64* %RCX, align 8, !tbaa !2428
  %4763 = lshr i64 %4762, 63
  %4764 = add i64 %4762, %4756
  store i64 %4764, i64* %RAX, align 8, !tbaa !2428
  %4765 = icmp ult i64 %4764, %4756
  %4766 = icmp ult i64 %4764, %4762
  %4767 = or i1 %4765, %4766
  %4768 = zext i1 %4767 to i8
  store i8 %4768, i8* %42, align 1, !tbaa !2432
  %4769 = trunc i64 %4764 to i32
  %4770 = and i32 %4769, 255
  %4771 = tail call i32 @llvm.ctpop.i32(i32 %4770) #8
  %4772 = trunc i32 %4771 to i8
  %4773 = and i8 %4772, 1
  %4774 = xor i8 %4773, 1
  store i8 %4774, i8* %49, align 1, !tbaa !2446
  %4775 = xor i64 %4762, %4756
  %4776 = xor i64 %4775, %4764
  %4777 = lshr i64 %4776, 4
  %4778 = trunc i64 %4777 to i8
  %4779 = and i8 %4778, 1
  store i8 %4779, i8* %54, align 1, !tbaa !2447
  %4780 = icmp eq i64 %4764, 0
  %4781 = zext i1 %4780 to i8
  store i8 %4781, i8* %57, align 1, !tbaa !2448
  %4782 = lshr i64 %4764, 63
  %4783 = trunc i64 %4782 to i8
  store i8 %4783, i8* %60, align 1, !tbaa !2449
  %4784 = lshr i64 %4756, 63
  %4785 = xor i64 %4782, %4784
  %4786 = xor i64 %4782, %4763
  %4787 = add nuw nsw i64 %4785, %4786
  %4788 = icmp eq i64 %4787, 2
  %4789 = zext i1 %4788 to i8
  store i8 %4789, i8* %66, align 1, !tbaa !2450
  %4790 = load i64, i64* %RBP, align 8
  %4791 = add i64 %4790, -104
  %4792 = add i64 %4752, 22
  store i64 %4792, i64* %PC, align 8
  %4793 = inttoptr i64 %4791 to i32*
  %4794 = load i32, i32* %4793, align 4
  %4795 = sext i32 %4794 to i64
  %4796 = mul nsw i64 %4795, 520
  store i64 %4796, i64* %RCX, align 8, !tbaa !2428
  %4797 = lshr i64 %4796, 63
  %4798 = add i64 %4752, 32
  store i64 %4798, i64* %PC, align 8
  %4799 = add i64 %4796, %4764
  store i64 %4799, i64* %RAX, align 8, !tbaa !2428
  %4800 = icmp ult i64 %4799, %4764
  %4801 = icmp ult i64 %4799, %4796
  %4802 = or i1 %4800, %4801
  %4803 = zext i1 %4802 to i8
  store i8 %4803, i8* %42, align 1, !tbaa !2432
  %4804 = trunc i64 %4799 to i32
  %4805 = and i32 %4804, 255
  %4806 = tail call i32 @llvm.ctpop.i32(i32 %4805) #8
  %4807 = trunc i32 %4806 to i8
  %4808 = and i8 %4807, 1
  %4809 = xor i8 %4808, 1
  store i8 %4809, i8* %49, align 1, !tbaa !2446
  %4810 = xor i64 %4796, %4764
  %4811 = xor i64 %4810, %4799
  %4812 = lshr i64 %4811, 4
  %4813 = trunc i64 %4812 to i8
  %4814 = and i8 %4813, 1
  store i8 %4814, i8* %54, align 1, !tbaa !2447
  %4815 = icmp eq i64 %4799, 0
  %4816 = zext i1 %4815 to i8
  store i8 %4816, i8* %57, align 1, !tbaa !2448
  %4817 = lshr i64 %4799, 63
  %4818 = trunc i64 %4817 to i8
  store i8 %4818, i8* %60, align 1, !tbaa !2449
  %4819 = xor i64 %4817, %4782
  %4820 = xor i64 %4817, %4797
  %4821 = add nuw nsw i64 %4819, %4820
  %4822 = icmp eq i64 %4821, 2
  %4823 = zext i1 %4822 to i8
  store i8 %4823, i8* %66, align 1, !tbaa !2450
  br i1 %4751, label %block_401fec, label %block_40228c
}

; Function Attrs: noinline
define %struct.Memory* @sub_400780_polybench_timer_print(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_400780:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %EAX = bitcast %union.anon* %3 to i32*
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %5 = load i64, i64* %RBP, align 8
  %6 = add i64 %1, 1
  store i64 %6, i64* %PC, align 8
  %7 = load i64, i64* %RSP, align 8, !tbaa !2428
  %8 = add i64 %7, -8
  %9 = inttoptr i64 %8 to i64*
  store i64 %5, i64* %9, align 8
  %10 = load i64, i64* %PC, align 8
  store i64 %8, i64* %RBP, align 8, !tbaa !2428
  %11 = add i64 %7, -24
  %12 = icmp ult i64 %8, 16
  %13 = zext i1 %12 to i8
  %14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %13, i8* %14, align 1, !tbaa !2432
  %15 = trunc i64 %11 to i32
  %16 = and i32 %15, 255
  %17 = tail call i32 @llvm.ctpop.i32(i32 %16) #8
  %18 = trunc i32 %17 to i8
  %19 = and i8 %18, 1
  %20 = xor i8 %19, 1
  %21 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %20, i8* %21, align 1, !tbaa !2446
  %22 = xor i64 %8, 16
  %23 = xor i64 %22, %11
  %24 = lshr i64 %23, 4
  %25 = trunc i64 %24 to i8
  %26 = and i8 %25, 1
  %27 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %26, i8* %27, align 1, !tbaa !2447
  %28 = icmp eq i64 %11, 0
  %29 = zext i1 %28 to i8
  %30 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %29, i8* %30, align 1, !tbaa !2448
  %31 = lshr i64 %11, 63
  %32 = trunc i64 %31 to i8
  %33 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %32, i8* %33, align 1, !tbaa !2449
  %34 = lshr i64 %8, 63
  %35 = xor i64 %31, %34
  %36 = add nuw nsw i64 %35, %34
  %37 = icmp eq i64 %36, 2
  %38 = zext i1 %37 to i8
  %39 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %38, i8* %39, align 1, !tbaa !2450
  store i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 112), i64* %RDI, align 8, !tbaa !2428
  %40 = load double, double* bitcast (%polybench_t_end_type* @polybench_t_end to double*), align 8
  %41 = bitcast %union.VectorReg* %4 to double*
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %43 = load double, double* bitcast (%polybench_t_start_type* @polybench_t_start to double*), align 8
  %44 = fsub double %40, %43
  store double %44, double* %41, align 1, !tbaa !2452
  store i64 0, i64* %42, align 1, !tbaa !2452
  store i8 1, i8* %AL, align 1, !tbaa !2454
  %45 = add i64 %10, -545
  %46 = add i64 %10, 42
  %47 = add i64 %7, -32
  %48 = inttoptr i64 %47 to i64*
  store i64 %46, i64* %48, align 8
  store i64 %47, i64* %RSP, align 8, !tbaa !2428
  store i64 %45, i64* %PC, align 8, !tbaa !2428
  %49 = tail call fastcc %struct.Memory* @ext_6040e0_printf(%struct.State* nonnull %0, %struct.Memory* %2)
  %50 = load i64, i64* %RBP, align 8
  %51 = add i64 %50, -4
  %52 = load i32, i32* %EAX, align 4
  %53 = load i64, i64* %PC, align 8
  %54 = add i64 %53, 3
  store i64 %54, i64* %PC, align 8
  %55 = inttoptr i64 %51 to i32*
  store i32 %52, i32* %55, align 4
  %56 = load i64, i64* %RSP, align 8
  %57 = load i64, i64* %PC, align 8
  %58 = add i64 %56, 16
  store i64 %58, i64* %RSP, align 8, !tbaa !2428
  %59 = icmp ugt i64 %56, -17
  %60 = zext i1 %59 to i8
  store i8 %60, i8* %14, align 1, !tbaa !2432
  %61 = trunc i64 %58 to i32
  %62 = and i32 %61, 255
  %63 = tail call i32 @llvm.ctpop.i32(i32 %62) #8
  %64 = trunc i32 %63 to i8
  %65 = and i8 %64, 1
  %66 = xor i8 %65, 1
  store i8 %66, i8* %21, align 1, !tbaa !2446
  %67 = xor i64 %56, 16
  %68 = xor i64 %67, %58
  %69 = lshr i64 %68, 4
  %70 = trunc i64 %69 to i8
  %71 = and i8 %70, 1
  store i8 %71, i8* %27, align 1, !tbaa !2447
  %72 = icmp eq i64 %58, 0
  %73 = zext i1 %72 to i8
  store i8 %73, i8* %30, align 1, !tbaa !2448
  %74 = lshr i64 %58, 63
  %75 = trunc i64 %74 to i8
  store i8 %75, i8* %33, align 1, !tbaa !2449
  %76 = lshr i64 %56, 63
  %77 = xor i64 %74, %76
  %78 = add nuw nsw i64 %77, %74
  %79 = icmp eq i64 %78, 2
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %39, align 1, !tbaa !2450
  %81 = add i64 %57, 5
  store i64 %81, i64* %PC, align 8
  %82 = add i64 %56, 24
  %83 = inttoptr i64 %58 to i64*
  %84 = load i64, i64* %83, align 8
  store i64 %84, i64* %RBP, align 8, !tbaa !2428
  store i64 %82, i64* %RSP, align 8, !tbaa !2428
  %85 = add i64 %57, 6
  store i64 %85, i64* %PC, align 8
  %86 = inttoptr i64 %82 to i64*
  %87 = load i64, i64* %86, align 8
  store i64 %87, i64* %PC, align 8, !tbaa !2428
  %88 = add i64 %56, 32
  store i64 %88, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %49
}

; Function Attrs: noinline
define %struct.Memory* @sub_4005b0__start(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_4005b0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  store i64 0, i64* %RBP, align 8, !tbaa !2428
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 0, i8* %3, align 1, !tbaa !2432
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 1, i8* %4, align 1, !tbaa !2446
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 1, i8* %5, align 1, !tbaa !2448
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 0, i8* %6, align 1, !tbaa !2449
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 0, i8* %7, align 1, !tbaa !2450
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 0, i8* %8, align 1, !tbaa !2447
  %9 = load i64, i64* %RDX, align 8
  store i64 %9, i64* %R9, align 8, !tbaa !2428
  %10 = add i64 %1, 6
  store i64 %10, i64* %PC, align 8
  %11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %12 = load i64, i64* %11, align 8, !tbaa !2428
  %13 = add i64 %12, 8
  %14 = inttoptr i64 %12 to i64*
  %15 = load i64, i64* %14, align 8
  store i64 %15, i64* %RSI, align 8, !tbaa !2428
  store i64 %13, i64* %RDX, align 8, !tbaa !2428
  %16 = and i64 %13, -16
  store i8 0, i8* %3, align 1, !tbaa !2432
  %17 = trunc i64 %13 to i32
  %18 = and i32 %17, 240
  %19 = tail call i32 @llvm.ctpop.i32(i32 %18) #8
  %20 = trunc i32 %19 to i8
  %21 = and i8 %20, 1
  %22 = xor i8 %21, 1
  store i8 %22, i8* %4, align 1, !tbaa !2446
  %23 = icmp eq i64 %16, 0
  %24 = zext i1 %23 to i8
  store i8 %24, i8* %5, align 1, !tbaa !2448
  %25 = lshr i64 %13, 63
  %26 = trunc i64 %25 to i8
  store i8 %26, i8* %6, align 1, !tbaa !2449
  store i8 0, i8* %7, align 1, !tbaa !2450
  store i8 0, i8* %8, align 1, !tbaa !2447
  %27 = load i64, i64* %RAX, align 8
  %28 = add i64 %1, 14
  store i64 %28, i64* %PC, align 8
  %29 = add i64 %16, -8
  %30 = inttoptr i64 %29 to i64*
  store i64 %27, i64* %30, align 8
  %31 = load i64, i64* %PC, align 8
  %32 = add i64 %31, 1
  store i64 %32, i64* %PC, align 8
  %33 = add i64 %16, -16
  %34 = inttoptr i64 %33 to i64*
  store i64 %29, i64* %34, align 16
  %35 = load i64, i64* %PC, align 8
  store i64 ptrtoint (void ()* @callback_sub_402e70___libc_csu_fini to i64), i64* %R8, align 8, !tbaa !2428
  store i64 ptrtoint (void ()* @callback_sub_402e00___libc_csu_init to i64), i64* %RCX, align 8, !tbaa !2428
  store i64 ptrtoint (void ()* @main to i64), i64* %RDI, align 8, !tbaa !2428
  %36 = add i64 %35, 27
  %37 = add i64 %16, -24
  %38 = inttoptr i64 %37 to i64*
  store i64 %36, i64* %38, align 8
  store i64 %37, i64* %11, align 8, !tbaa !2428
  %39 = load i64, i64* getelementptr inbounds (%seg_603ff0__got_type, %seg_603ff0__got_type* @seg_603ff0__got, i64 0, i32 0), align 8
  store i64 %39, i64* %PC, align 8, !tbaa !2428
  %40 = tail call fastcc %struct.Memory* @ext_6040b0___libc_start_main(%struct.State* nonnull %0, %struct.Memory* %2)
  %41 = load i64, i64* %PC, align 8
  %42 = add i64 %41, 1
  store i64 %42, i64* %PC, align 8
  %43 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull %0, i64 %42, %struct.Memory* %40)
  ret %struct.Memory* %43
}

; Function Attrs: noinline
define %struct.Memory* @sub_400690_frame_dummy(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_400690:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  store i64 %7, i64* %5, align 8, !tbaa !2428
  %9 = load i64, i64* %PC, align 8
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %10 = add i64 %9, 4
  store i64 %10, i64* %PC, align 8
  %11 = load i64, i64* %8, align 8
  store i64 %11, i64* %RBP, align 8, !tbaa !2428
  store i64 %6, i64* %5, align 8, !tbaa !2428
  %12 = add i64 %9, -113
  store i64 %12, i64* %PC, align 8, !tbaa !2428
  %13 = tail call %struct.Memory* @sub_400620_register_tm_clones(%struct.State* nonnull %0, i64 %12, %struct.Memory* %2)
  ret %struct.Memory* %13
}

; Function Attrs: noinline
define %struct.Memory* @sub_402bf0_print_array(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_402bf0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %5 to i32*
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %6 to i32*
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0
  %R8D = bitcast %union.anon* %7 to i32*
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0
  %R9D = bitcast %union.anon* %8 to i32*
  %RAX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSI = getelementptr inbounds %union.anon, %union.anon* %5, i64 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %6, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %union.anon, %union.anon* %7, i64 0, i32 0
  %R9 = getelementptr inbounds %union.anon, %union.anon* %8, i64 0, i32 0
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0
  %10 = load i64, i64* %RBP, align 8
  %11 = add i64 %1, 1
  store i64 %11, i64* %PC, align 8
  %12 = load i64, i64* %RSP, align 8, !tbaa !2428
  %13 = add i64 %12, -8
  %14 = inttoptr i64 %13 to i64*
  store i64 %10, i64* %14, align 8
  %15 = load i64, i64* %PC, align 8
  store i64 %13, i64* %RBP, align 8, !tbaa !2428
  %16 = add i64 %12, -104
  store i64 %16, i64* %RSP, align 8, !tbaa !2428
  %17 = icmp ult i64 %13, 96
  %18 = zext i1 %17 to i8
  %19 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %18, i8* %19, align 1, !tbaa !2432
  %20 = trunc i64 %16 to i32
  %21 = and i32 %20, 255
  %22 = tail call i32 @llvm.ctpop.i32(i32 %21) #8
  %23 = trunc i32 %22 to i8
  %24 = and i8 %23, 1
  %25 = xor i8 %24, 1
  %26 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %25, i8* %26, align 1, !tbaa !2446
  %27 = xor i64 %13, %16
  %28 = lshr i64 %27, 4
  %29 = trunc i64 %28 to i8
  %30 = and i8 %29, 1
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %30, i8* %31, align 1, !tbaa !2447
  %32 = icmp eq i64 %16, 0
  %33 = zext i1 %32 to i8
  %34 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %33, i8* %34, align 1, !tbaa !2448
  %35 = lshr i64 %16, 63
  %36 = trunc i64 %35 to i8
  %37 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %36, i8* %37, align 1, !tbaa !2449
  %38 = lshr i64 %13, 63
  %39 = xor i64 %35, %38
  %40 = add nuw nsw i64 %39, %38
  %41 = icmp eq i64 %40, 2
  %42 = zext i1 %41 to i8
  %43 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %42, i8* %43, align 1, !tbaa !2450
  %44 = add i64 %12, 8
  %45 = add i64 %15, 11
  store i64 %45, i64* %PC, align 8
  %46 = inttoptr i64 %44 to i64*
  %47 = load i64, i64* %46, align 8
  store i64 %47, i64* %RAX, align 8, !tbaa !2428
  %48 = add i64 %12, -12
  %49 = load i32, i32* %EDI, align 4
  %50 = add i64 %15, 14
  store i64 %50, i64* %PC, align 8
  %51 = inttoptr i64 %48 to i32*
  store i32 %49, i32* %51, align 4
  %52 = load i64, i64* %RBP, align 8
  %53 = add i64 %52, -8
  %54 = load i32, i32* %ESI, align 4
  %55 = load i64, i64* %PC, align 8
  %56 = add i64 %55, 3
  store i64 %56, i64* %PC, align 8
  %57 = inttoptr i64 %53 to i32*
  store i32 %54, i32* %57, align 4
  %58 = load i64, i64* %RBP, align 8
  %59 = add i64 %58, -12
  %60 = load i32, i32* %EDX, align 4
  %61 = load i64, i64* %PC, align 8
  %62 = add i64 %61, 3
  store i64 %62, i64* %PC, align 8
  %63 = inttoptr i64 %59 to i32*
  store i32 %60, i32* %63, align 4
  %64 = load i64, i64* %RBP, align 8
  %65 = add i64 %64, -24
  %66 = load i64, i64* %RCX, align 8
  %67 = load i64, i64* %PC, align 8
  %68 = add i64 %67, 4
  store i64 %68, i64* %PC, align 8
  %69 = inttoptr i64 %65 to i64*
  store i64 %66, i64* %69, align 8
  %70 = load i64, i64* %RBP, align 8
  %71 = add i64 %70, -32
  %72 = load i64, i64* %R8, align 8
  %73 = load i64, i64* %PC, align 8
  %74 = add i64 %73, 4
  store i64 %74, i64* %PC, align 8
  %75 = inttoptr i64 %71 to i64*
  store i64 %72, i64* %75, align 8
  %76 = load i64, i64* %RBP, align 8
  %77 = add i64 %76, -40
  %78 = load i64, i64* %R9, align 8
  %79 = load i64, i64* %PC, align 8
  %80 = add i64 %79, 4
  store i64 %80, i64* %PC, align 8
  %81 = inttoptr i64 %77 to i64*
  store i64 %78, i64* %81, align 8
  %82 = load i64, i64* %RBP, align 8
  %83 = add i64 %82, -44
  %84 = load i64, i64* %PC, align 8
  %85 = add i64 %84, 7
  store i64 %85, i64* %PC, align 8
  %86 = inttoptr i64 %83 to i32*
  store i32 0, i32* %86, align 4
  %87 = load i64, i64* %RBP, align 8
  %88 = add i64 %87, -64
  %89 = load i64, i64* %RAX, align 8
  %90 = load i64, i64* %PC, align 8
  %91 = add i64 %90, 4
  store i64 %91, i64* %PC, align 8
  %92 = inttoptr i64 %88 to i64*
  store i64 %89, i64* %92, align 8
  %93 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %94 = bitcast i64* %93 to double*
  %95 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %96 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %.pre = load i64, i64* %PC, align 8
  br label %block_402c1c

block_402c3b:                                     ; preds = %block_402c2f
  %97 = add i64 %637, -52
  %98 = add i64 %673, 7
  store i64 %98, i64* %PC, align 8
  %99 = inttoptr i64 %97 to i32*
  store i32 0, i32* %99, align 4
  %.pre2 = load i64, i64* %PC, align 8
  br label %block_402c42

block_402c1c:                                     ; preds = %block_402dc7, %block_402bf0
  %100 = phi i64 [ %.pre, %block_402bf0 ], [ %703, %block_402dc7 ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_402bf0 ], [ %MEMORY.1, %block_402dc7 ]
  %101 = load i64, i64* %RBP, align 8
  %102 = add i64 %101, -44
  %103 = add i64 %100, 3
  store i64 %103, i64* %PC, align 8
  %104 = inttoptr i64 %102 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = zext i32 %105 to i64
  store i64 %106, i64* %RAX, align 8, !tbaa !2428
  %107 = add i64 %101, -4
  %108 = add i64 %100, 6
  store i64 %108, i64* %PC, align 8
  %109 = inttoptr i64 %107 to i32*
  %110 = load i32, i32* %109, align 4
  %111 = sub i32 %105, %110
  %112 = icmp ult i32 %105, %110
  %113 = zext i1 %112 to i8
  store i8 %113, i8* %19, align 1, !tbaa !2432
  %114 = and i32 %111, 255
  %115 = tail call i32 @llvm.ctpop.i32(i32 %114) #8
  %116 = trunc i32 %115 to i8
  %117 = and i8 %116, 1
  %118 = xor i8 %117, 1
  store i8 %118, i8* %26, align 1, !tbaa !2446
  %119 = xor i32 %110, %105
  %120 = xor i32 %119, %111
  %121 = lshr i32 %120, 4
  %122 = trunc i32 %121 to i8
  %123 = and i8 %122, 1
  store i8 %123, i8* %31, align 1, !tbaa !2447
  %124 = icmp eq i32 %111, 0
  %125 = zext i1 %124 to i8
  store i8 %125, i8* %34, align 1, !tbaa !2448
  %126 = lshr i32 %111, 31
  %127 = trunc i32 %126 to i8
  store i8 %127, i8* %37, align 1, !tbaa !2449
  %128 = lshr i32 %105, 31
  %129 = lshr i32 %110, 31
  %130 = xor i32 %129, %128
  %131 = xor i32 %126, %128
  %132 = add nuw nsw i32 %131, %130
  %133 = icmp eq i32 %132, 2
  %134 = zext i1 %133 to i8
  store i8 %134, i8* %43, align 1, !tbaa !2450
  %135 = icmp ne i8 %127, 0
  %136 = xor i1 %135, %133
  %.demorgan = or i1 %124, %136
  %.v = select i1 %.demorgan, i64 12, i64 446
  %137 = add i64 %100, %.v
  store i64 %137, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan, label %block_402c28, label %block_402dda

block_402db4:                                     ; preds = %block_402c42
  %138 = add i64 %763, -48
  %139 = add i64 %799, 8
  store i64 %139, i64* %PC, align 8
  %140 = inttoptr i64 %138 to i32*
  %141 = load i32, i32* %140, align 4
  %142 = add i32 %141, 1
  %143 = zext i32 %142 to i64
  store i64 %143, i64* %RAX, align 8, !tbaa !2428
  %144 = icmp eq i32 %141, -1
  %145 = icmp eq i32 %142, 0
  %146 = or i1 %144, %145
  %147 = zext i1 %146 to i8
  store i8 %147, i8* %19, align 1, !tbaa !2432
  %148 = and i32 %142, 255
  %149 = tail call i32 @llvm.ctpop.i32(i32 %148) #8
  %150 = trunc i32 %149 to i8
  %151 = and i8 %150, 1
  %152 = xor i8 %151, 1
  store i8 %152, i8* %26, align 1, !tbaa !2446
  %153 = xor i32 %141, %142
  %154 = lshr i32 %153, 4
  %155 = trunc i32 %154 to i8
  %156 = and i8 %155, 1
  store i8 %156, i8* %31, align 1, !tbaa !2447
  %157 = zext i1 %145 to i8
  store i8 %157, i8* %34, align 1, !tbaa !2448
  %158 = lshr i32 %142, 31
  %159 = trunc i32 %158 to i8
  store i8 %159, i8* %37, align 1, !tbaa !2449
  %160 = lshr i32 %141, 31
  %161 = xor i32 %158, %160
  %162 = add nuw nsw i32 %161, %158
  %163 = icmp eq i32 %162, 2
  %164 = zext i1 %163 to i8
  store i8 %164, i8* %43, align 1, !tbaa !2450
  %165 = add i64 %799, 14
  store i64 %165, i64* %PC, align 8
  store i32 %142, i32* %140, align 4
  %166 = load i64, i64* %PC, align 8
  %167 = add i64 %166, -403
  store i64 %167, i64* %PC, align 8, !tbaa !2428
  br label %block_402c2f

block_402c4e:                                     ; preds = %block_402c42
  store i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 170), i64* %RSI, align 8, !tbaa !2428
  %168 = load i64, i64* @stderr, align 32
  store i64 %168, i64* %RDI, align 8, !tbaa !2428
  %169 = add i64 %763, -24
  %170 = add i64 %799, 22
  store i64 %170, i64* %PC, align 8
  %171 = inttoptr i64 %169 to i64*
  %172 = load i64, i64* %171, align 8
  store i64 %172, i64* %RAX, align 8, !tbaa !2428
  %173 = add i64 %763, -44
  %174 = add i64 %799, 26
  store i64 %174, i64* %PC, align 8
  %175 = inttoptr i64 %173 to i32*
  %176 = load i32, i32* %175, align 4
  %177 = sext i32 %176 to i64
  %178 = mul nsw i64 %177, 33800
  store i64 %178, i64* %RCX, align 8, !tbaa !2428
  %179 = lshr i64 %178, 63
  %180 = add i64 %178, %172
  store i64 %180, i64* %RAX, align 8, !tbaa !2428
  %181 = icmp ult i64 %180, %172
  %182 = icmp ult i64 %180, %178
  %183 = or i1 %181, %182
  %184 = zext i1 %183 to i8
  store i8 %184, i8* %19, align 1, !tbaa !2432
  %185 = trunc i64 %180 to i32
  %186 = and i32 %185, 255
  %187 = tail call i32 @llvm.ctpop.i32(i32 %186) #8
  %188 = trunc i32 %187 to i8
  %189 = and i8 %188, 1
  %190 = xor i8 %189, 1
  store i8 %190, i8* %26, align 1, !tbaa !2446
  %191 = xor i64 %178, %172
  %192 = xor i64 %191, %180
  %193 = lshr i64 %192, 4
  %194 = trunc i64 %193 to i8
  %195 = and i8 %194, 1
  store i8 %195, i8* %31, align 1, !tbaa !2447
  %196 = icmp eq i64 %180, 0
  %197 = zext i1 %196 to i8
  store i8 %197, i8* %34, align 1, !tbaa !2448
  %198 = lshr i64 %180, 63
  %199 = trunc i64 %198 to i8
  store i8 %199, i8* %37, align 1, !tbaa !2449
  %200 = lshr i64 %172, 63
  %201 = xor i64 %198, %200
  %202 = xor i64 %198, %179
  %203 = add nuw nsw i64 %201, %202
  %204 = icmp eq i64 %203, 2
  %205 = zext i1 %204 to i8
  store i8 %205, i8* %43, align 1, !tbaa !2450
  %206 = add i64 %763, -48
  %207 = add i64 %799, 40
  store i64 %207, i64* %PC, align 8
  %208 = inttoptr i64 %206 to i32*
  %209 = load i32, i32* %208, align 4
  %210 = sext i32 %209 to i64
  %211 = mul nsw i64 %210, 520
  store i64 %211, i64* %RCX, align 8, !tbaa !2428
  %212 = lshr i64 %211, 63
  %213 = add i64 %211, %180
  store i64 %213, i64* %RAX, align 8, !tbaa !2428
  %214 = icmp ult i64 %213, %180
  %215 = icmp ult i64 %213, %211
  %216 = or i1 %214, %215
  %217 = zext i1 %216 to i8
  store i8 %217, i8* %19, align 1, !tbaa !2432
  %218 = trunc i64 %213 to i32
  %219 = and i32 %218, 255
  %220 = tail call i32 @llvm.ctpop.i32(i32 %219) #8
  %221 = trunc i32 %220 to i8
  %222 = and i8 %221, 1
  %223 = xor i8 %222, 1
  store i8 %223, i8* %26, align 1, !tbaa !2446
  %224 = xor i64 %211, %180
  %225 = xor i64 %224, %213
  %226 = lshr i64 %225, 4
  %227 = trunc i64 %226 to i8
  %228 = and i8 %227, 1
  store i8 %228, i8* %31, align 1, !tbaa !2447
  %229 = icmp eq i64 %213, 0
  %230 = zext i1 %229 to i8
  store i8 %230, i8* %34, align 1, !tbaa !2448
  %231 = lshr i64 %213, 63
  %232 = trunc i64 %231 to i8
  store i8 %232, i8* %37, align 1, !tbaa !2449
  %233 = xor i64 %231, %198
  %234 = xor i64 %231, %212
  %235 = add nuw nsw i64 %233, %234
  %236 = icmp eq i64 %235, 2
  %237 = zext i1 %236 to i8
  store i8 %237, i8* %43, align 1, !tbaa !2450
  %238 = load i64, i64* %RBP, align 8
  %239 = add i64 %238, -52
  %240 = add i64 %799, 54
  store i64 %240, i64* %PC, align 8
  %241 = inttoptr i64 %239 to i32*
  %242 = load i32, i32* %241, align 4
  %243 = sext i32 %242 to i64
  store i64 %243, i64* %RCX, align 8, !tbaa !2428
  %244 = shl nsw i64 %243, 3
  %245 = add i64 %244, %213
  %246 = add i64 %799, 59
  store i64 %246, i64* %PC, align 8
  %247 = inttoptr i64 %245 to i64*
  %248 = load i64, i64* %247, align 8
  %249 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %9, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %248, i64* %249, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  store i8 1, i8* %AL, align 1, !tbaa !2454
  %250 = add i64 %799, -9934
  %251 = add i64 %799, 66
  %252 = load i64, i64* %RSP, align 8, !tbaa !2428
  %253 = add i64 %252, -8
  %254 = inttoptr i64 %253 to i64*
  store i64 %251, i64* %254, align 8
  store i64 %253, i64* %RSP, align 8, !tbaa !2428
  store i64 %250, i64* %PC, align 8, !tbaa !2428
  %255 = tail call fastcc %struct.Memory* @ext_6040f8_fprintf(%struct.State* nonnull %0, %struct.Memory* %MEMORY.2)
  %256 = load i64, i64* %PC, align 8
  store i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 170), i64* %RSI, align 8, !tbaa !2428
  %257 = load i64, i64* @stderr, align 32
  store i64 %257, i64* %RDI, align 8, !tbaa !2428
  %258 = load i64, i64* %RBP, align 8
  %259 = add i64 %258, -32
  %260 = add i64 %256, 22
  store i64 %260, i64* %PC, align 8
  %261 = inttoptr i64 %259 to i64*
  %262 = load i64, i64* %261, align 8
  store i64 %262, i64* %RCX, align 8, !tbaa !2428
  %263 = add i64 %258, -44
  %264 = add i64 %256, 26
  store i64 %264, i64* %PC, align 8
  %265 = inttoptr i64 %263 to i32*
  %266 = load i32, i32* %265, align 4
  %267 = sext i32 %266 to i64
  %268 = mul nsw i64 %267, 33800
  store i64 %268, i64* %RDX, align 8, !tbaa !2428
  %269 = lshr i64 %268, 63
  %270 = add i64 %268, %262
  store i64 %270, i64* %RCX, align 8, !tbaa !2428
  %271 = icmp ult i64 %270, %262
  %272 = icmp ult i64 %270, %268
  %273 = or i1 %271, %272
  %274 = zext i1 %273 to i8
  store i8 %274, i8* %19, align 1, !tbaa !2432
  %275 = trunc i64 %270 to i32
  %276 = and i32 %275, 255
  %277 = tail call i32 @llvm.ctpop.i32(i32 %276) #8
  %278 = trunc i32 %277 to i8
  %279 = and i8 %278, 1
  %280 = xor i8 %279, 1
  store i8 %280, i8* %26, align 1, !tbaa !2446
  %281 = xor i64 %268, %262
  %282 = xor i64 %281, %270
  %283 = lshr i64 %282, 4
  %284 = trunc i64 %283 to i8
  %285 = and i8 %284, 1
  store i8 %285, i8* %31, align 1, !tbaa !2447
  %286 = icmp eq i64 %270, 0
  %287 = zext i1 %286 to i8
  store i8 %287, i8* %34, align 1, !tbaa !2448
  %288 = lshr i64 %270, 63
  %289 = trunc i64 %288 to i8
  store i8 %289, i8* %37, align 1, !tbaa !2449
  %290 = lshr i64 %262, 63
  %291 = xor i64 %288, %290
  %292 = xor i64 %288, %269
  %293 = add nuw nsw i64 %291, %292
  %294 = icmp eq i64 %293, 2
  %295 = zext i1 %294 to i8
  store i8 %295, i8* %43, align 1, !tbaa !2450
  %296 = add i64 %258, -48
  %297 = add i64 %256, 40
  store i64 %297, i64* %PC, align 8
  %298 = inttoptr i64 %296 to i32*
  %299 = load i32, i32* %298, align 4
  %300 = sext i32 %299 to i64
  %301 = mul nsw i64 %300, 520
  store i64 %301, i64* %RDX, align 8, !tbaa !2428
  %302 = lshr i64 %301, 63
  %303 = add i64 %301, %270
  store i64 %303, i64* %RCX, align 8, !tbaa !2428
  %304 = icmp ult i64 %303, %270
  %305 = icmp ult i64 %303, %301
  %306 = or i1 %304, %305
  %307 = zext i1 %306 to i8
  store i8 %307, i8* %19, align 1, !tbaa !2432
  %308 = trunc i64 %303 to i32
  %309 = and i32 %308, 255
  %310 = tail call i32 @llvm.ctpop.i32(i32 %309) #8
  %311 = trunc i32 %310 to i8
  %312 = and i8 %311, 1
  %313 = xor i8 %312, 1
  store i8 %313, i8* %26, align 1, !tbaa !2446
  %314 = xor i64 %301, %270
  %315 = xor i64 %314, %303
  %316 = lshr i64 %315, 4
  %317 = trunc i64 %316 to i8
  %318 = and i8 %317, 1
  store i8 %318, i8* %31, align 1, !tbaa !2447
  %319 = icmp eq i64 %303, 0
  %320 = zext i1 %319 to i8
  store i8 %320, i8* %34, align 1, !tbaa !2448
  %321 = lshr i64 %303, 63
  %322 = trunc i64 %321 to i8
  store i8 %322, i8* %37, align 1, !tbaa !2449
  %323 = xor i64 %321, %288
  %324 = xor i64 %321, %302
  %325 = add nuw nsw i64 %323, %324
  %326 = icmp eq i64 %325, 2
  %327 = zext i1 %326 to i8
  store i8 %327, i8* %43, align 1, !tbaa !2450
  %328 = load i64, i64* %RBP, align 8
  %329 = add i64 %328, -52
  %330 = add i64 %256, 54
  store i64 %330, i64* %PC, align 8
  %331 = inttoptr i64 %329 to i32*
  %332 = load i32, i32* %331, align 4
  %333 = sext i32 %332 to i64
  store i64 %333, i64* %RDX, align 8, !tbaa !2428
  %334 = shl nsw i64 %333, 3
  %335 = add i64 %334, %303
  %336 = add i64 %256, 59
  store i64 %336, i64* %PC, align 8
  %337 = inttoptr i64 %335 to i64*
  %338 = load i64, i64* %337, align 8
  store i64 %338, i64* %249, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %339 = add i64 %328, -68
  %340 = load i32, i32* %EAX, align 4
  %341 = add i64 %256, 62
  store i64 %341, i64* %PC, align 8
  %342 = inttoptr i64 %339 to i32*
  store i32 %340, i32* %342, align 4
  %343 = load i64, i64* %PC, align 8
  store i8 1, i8* %AL, align 1, !tbaa !2454
  %344 = add i64 %343, -10062
  %345 = add i64 %343, 7
  %346 = load i64, i64* %RSP, align 8, !tbaa !2428
  %347 = add i64 %346, -8
  %348 = inttoptr i64 %347 to i64*
  store i64 %345, i64* %348, align 8
  store i64 %347, i64* %RSP, align 8, !tbaa !2428
  store i64 %344, i64* %PC, align 8, !tbaa !2428
  %349 = tail call fastcc %struct.Memory* @ext_6040f8_fprintf(%struct.State* nonnull %0, %struct.Memory* %255)
  %350 = load i64, i64* %PC, align 8
  store i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 170), i64* %RSI, align 8, !tbaa !2428
  %351 = load i64, i64* @stderr, align 32
  store i64 %351, i64* %RDI, align 8, !tbaa !2428
  %352 = load i64, i64* %RBP, align 8
  %353 = add i64 %352, -40
  %354 = add i64 %350, 22
  store i64 %354, i64* %PC, align 8
  %355 = inttoptr i64 %353 to i64*
  %356 = load i64, i64* %355, align 8
  store i64 %356, i64* %RCX, align 8, !tbaa !2428
  %357 = add i64 %352, -44
  %358 = add i64 %350, 26
  store i64 %358, i64* %PC, align 8
  %359 = inttoptr i64 %357 to i32*
  %360 = load i32, i32* %359, align 4
  %361 = sext i32 %360 to i64
  %362 = mul nsw i64 %361, 33800
  store i64 %362, i64* %RDX, align 8, !tbaa !2428
  %363 = lshr i64 %362, 63
  %364 = add i64 %362, %356
  store i64 %364, i64* %RCX, align 8, !tbaa !2428
  %365 = icmp ult i64 %364, %356
  %366 = icmp ult i64 %364, %362
  %367 = or i1 %365, %366
  %368 = zext i1 %367 to i8
  store i8 %368, i8* %19, align 1, !tbaa !2432
  %369 = trunc i64 %364 to i32
  %370 = and i32 %369, 255
  %371 = tail call i32 @llvm.ctpop.i32(i32 %370) #8
  %372 = trunc i32 %371 to i8
  %373 = and i8 %372, 1
  %374 = xor i8 %373, 1
  store i8 %374, i8* %26, align 1, !tbaa !2446
  %375 = xor i64 %362, %356
  %376 = xor i64 %375, %364
  %377 = lshr i64 %376, 4
  %378 = trunc i64 %377 to i8
  %379 = and i8 %378, 1
  store i8 %379, i8* %31, align 1, !tbaa !2447
  %380 = icmp eq i64 %364, 0
  %381 = zext i1 %380 to i8
  store i8 %381, i8* %34, align 1, !tbaa !2448
  %382 = lshr i64 %364, 63
  %383 = trunc i64 %382 to i8
  store i8 %383, i8* %37, align 1, !tbaa !2449
  %384 = lshr i64 %356, 63
  %385 = xor i64 %382, %384
  %386 = xor i64 %382, %363
  %387 = add nuw nsw i64 %385, %386
  %388 = icmp eq i64 %387, 2
  %389 = zext i1 %388 to i8
  store i8 %389, i8* %43, align 1, !tbaa !2450
  %390 = add i64 %352, -48
  %391 = add i64 %350, 40
  store i64 %391, i64* %PC, align 8
  %392 = inttoptr i64 %390 to i32*
  %393 = load i32, i32* %392, align 4
  %394 = sext i32 %393 to i64
  %395 = mul nsw i64 %394, 520
  store i64 %395, i64* %RDX, align 8, !tbaa !2428
  %396 = lshr i64 %395, 63
  %397 = add i64 %395, %364
  store i64 %397, i64* %RCX, align 8, !tbaa !2428
  %398 = icmp ult i64 %397, %364
  %399 = icmp ult i64 %397, %395
  %400 = or i1 %398, %399
  %401 = zext i1 %400 to i8
  store i8 %401, i8* %19, align 1, !tbaa !2432
  %402 = trunc i64 %397 to i32
  %403 = and i32 %402, 255
  %404 = tail call i32 @llvm.ctpop.i32(i32 %403) #8
  %405 = trunc i32 %404 to i8
  %406 = and i8 %405, 1
  %407 = xor i8 %406, 1
  store i8 %407, i8* %26, align 1, !tbaa !2446
  %408 = xor i64 %395, %364
  %409 = xor i64 %408, %397
  %410 = lshr i64 %409, 4
  %411 = trunc i64 %410 to i8
  %412 = and i8 %411, 1
  store i8 %412, i8* %31, align 1, !tbaa !2447
  %413 = icmp eq i64 %397, 0
  %414 = zext i1 %413 to i8
  store i8 %414, i8* %34, align 1, !tbaa !2448
  %415 = lshr i64 %397, 63
  %416 = trunc i64 %415 to i8
  store i8 %416, i8* %37, align 1, !tbaa !2449
  %417 = xor i64 %415, %382
  %418 = xor i64 %415, %396
  %419 = add nuw nsw i64 %417, %418
  %420 = icmp eq i64 %419, 2
  %421 = zext i1 %420 to i8
  store i8 %421, i8* %43, align 1, !tbaa !2450
  %422 = load i64, i64* %RBP, align 8
  %423 = add i64 %422, -52
  %424 = add i64 %350, 54
  store i64 %424, i64* %PC, align 8
  %425 = inttoptr i64 %423 to i32*
  %426 = load i32, i32* %425, align 4
  %427 = sext i32 %426 to i64
  store i64 %427, i64* %RDX, align 8, !tbaa !2428
  %428 = shl nsw i64 %427, 3
  %429 = add i64 %428, %397
  %430 = add i64 %350, 59
  store i64 %430, i64* %PC, align 8
  %431 = inttoptr i64 %429 to i64*
  %432 = load i64, i64* %431, align 8
  store i64 %432, i64* %249, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %433 = add i64 %422, -72
  %434 = load i32, i32* %EAX, align 4
  %435 = add i64 %350, 62
  store i64 %435, i64* %PC, align 8
  %436 = inttoptr i64 %433 to i32*
  store i32 %434, i32* %436, align 4
  %437 = load i64, i64* %PC, align 8
  store i8 1, i8* %AL, align 1, !tbaa !2454
  %438 = add i64 %437, -10131
  %439 = add i64 %437, 7
  %440 = load i64, i64* %RSP, align 8, !tbaa !2428
  %441 = add i64 %440, -8
  %442 = inttoptr i64 %441 to i64*
  store i64 %439, i64* %442, align 8
  store i64 %441, i64* %RSP, align 8, !tbaa !2428
  store i64 %438, i64* %PC, align 8, !tbaa !2428
  %443 = tail call fastcc %struct.Memory* @ext_6040f8_fprintf(%struct.State* nonnull %0, %struct.Memory* %349)
  %444 = load i64, i64* %PC, align 8
  store i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 170), i64* %RSI, align 8, !tbaa !2428
  %445 = load i64, i64* @stderr, align 32
  store i64 %445, i64* %RDI, align 8, !tbaa !2428
  %446 = load i64, i64* %RBP, align 8
  %447 = add i64 %446, 16
  %448 = add i64 %444, 22
  store i64 %448, i64* %PC, align 8
  %449 = inttoptr i64 %447 to i64*
  %450 = load i64, i64* %449, align 8
  store i64 %450, i64* %RCX, align 8, !tbaa !2428
  %451 = add i64 %446, -44
  %452 = add i64 %444, 26
  store i64 %452, i64* %PC, align 8
  %453 = inttoptr i64 %451 to i32*
  %454 = load i32, i32* %453, align 4
  %455 = sext i32 %454 to i64
  %456 = mul nsw i64 %455, 33800
  store i64 %456, i64* %RDX, align 8, !tbaa !2428
  %457 = lshr i64 %456, 63
  %458 = add i64 %456, %450
  store i64 %458, i64* %RCX, align 8, !tbaa !2428
  %459 = icmp ult i64 %458, %450
  %460 = icmp ult i64 %458, %456
  %461 = or i1 %459, %460
  %462 = zext i1 %461 to i8
  store i8 %462, i8* %19, align 1, !tbaa !2432
  %463 = trunc i64 %458 to i32
  %464 = and i32 %463, 255
  %465 = tail call i32 @llvm.ctpop.i32(i32 %464) #8
  %466 = trunc i32 %465 to i8
  %467 = and i8 %466, 1
  %468 = xor i8 %467, 1
  store i8 %468, i8* %26, align 1, !tbaa !2446
  %469 = xor i64 %456, %450
  %470 = xor i64 %469, %458
  %471 = lshr i64 %470, 4
  %472 = trunc i64 %471 to i8
  %473 = and i8 %472, 1
  store i8 %473, i8* %31, align 1, !tbaa !2447
  %474 = icmp eq i64 %458, 0
  %475 = zext i1 %474 to i8
  store i8 %475, i8* %34, align 1, !tbaa !2448
  %476 = lshr i64 %458, 63
  %477 = trunc i64 %476 to i8
  store i8 %477, i8* %37, align 1, !tbaa !2449
  %478 = lshr i64 %450, 63
  %479 = xor i64 %476, %478
  %480 = xor i64 %476, %457
  %481 = add nuw nsw i64 %479, %480
  %482 = icmp eq i64 %481, 2
  %483 = zext i1 %482 to i8
  store i8 %483, i8* %43, align 1, !tbaa !2450
  %484 = add i64 %446, -48
  %485 = add i64 %444, 40
  store i64 %485, i64* %PC, align 8
  %486 = inttoptr i64 %484 to i32*
  %487 = load i32, i32* %486, align 4
  %488 = sext i32 %487 to i64
  %489 = mul nsw i64 %488, 520
  store i64 %489, i64* %RDX, align 8, !tbaa !2428
  %490 = lshr i64 %489, 63
  %491 = add i64 %489, %458
  store i64 %491, i64* %RCX, align 8, !tbaa !2428
  %492 = icmp ult i64 %491, %458
  %493 = icmp ult i64 %491, %489
  %494 = or i1 %492, %493
  %495 = zext i1 %494 to i8
  store i8 %495, i8* %19, align 1, !tbaa !2432
  %496 = trunc i64 %491 to i32
  %497 = and i32 %496, 255
  %498 = tail call i32 @llvm.ctpop.i32(i32 %497) #8
  %499 = trunc i32 %498 to i8
  %500 = and i8 %499, 1
  %501 = xor i8 %500, 1
  store i8 %501, i8* %26, align 1, !tbaa !2446
  %502 = xor i64 %489, %458
  %503 = xor i64 %502, %491
  %504 = lshr i64 %503, 4
  %505 = trunc i64 %504 to i8
  %506 = and i8 %505, 1
  store i8 %506, i8* %31, align 1, !tbaa !2447
  %507 = icmp eq i64 %491, 0
  %508 = zext i1 %507 to i8
  store i8 %508, i8* %34, align 1, !tbaa !2448
  %509 = lshr i64 %491, 63
  %510 = trunc i64 %509 to i8
  store i8 %510, i8* %37, align 1, !tbaa !2449
  %511 = xor i64 %509, %476
  %512 = xor i64 %509, %490
  %513 = add nuw nsw i64 %511, %512
  %514 = icmp eq i64 %513, 2
  %515 = zext i1 %514 to i8
  store i8 %515, i8* %43, align 1, !tbaa !2450
  %516 = load i64, i64* %RBP, align 8
  %517 = add i64 %516, -52
  %518 = add i64 %444, 54
  store i64 %518, i64* %PC, align 8
  %519 = inttoptr i64 %517 to i32*
  %520 = load i32, i32* %519, align 4
  %521 = sext i32 %520 to i64
  store i64 %521, i64* %RDX, align 8, !tbaa !2428
  %522 = shl nsw i64 %521, 3
  %523 = add i64 %522, %491
  %524 = add i64 %444, 59
  store i64 %524, i64* %PC, align 8
  %525 = inttoptr i64 %523 to i64*
  %526 = load i64, i64* %525, align 8
  store i64 %526, i64* %249, align 1, !tbaa !2452
  store double 0.000000e+00, double* %94, align 1, !tbaa !2452
  %527 = add i64 %516, -76
  %528 = load i32, i32* %EAX, align 4
  %529 = add i64 %444, 62
  store i64 %529, i64* %PC, align 8
  %530 = inttoptr i64 %527 to i32*
  store i32 %528, i32* %530, align 4
  %531 = load i64, i64* %PC, align 8
  store i8 1, i8* %AL, align 1, !tbaa !2454
  %532 = add i64 %531, -10200
  %533 = add i64 %531, 7
  %534 = load i64, i64* %RSP, align 8, !tbaa !2428
  %535 = add i64 %534, -8
  %536 = inttoptr i64 %535 to i64*
  store i64 %533, i64* %536, align 8
  store i64 %535, i64* %RSP, align 8, !tbaa !2428
  store i64 %532, i64* %PC, align 8, !tbaa !2428
  %537 = tail call fastcc %struct.Memory* @ext_6040f8_fprintf(%struct.State* nonnull %0, %struct.Memory* %443)
  %538 = load i64, i64* %PC, align 8
  store i64 20, i64* %R8, align 8, !tbaa !2428
  %539 = load i64, i64* %RBP, align 8
  %540 = add i64 %539, -44
  %541 = add i64 %538, 10
  store i64 %541, i64* %PC, align 8
  %542 = inttoptr i64 %540 to i32*
  %543 = load i32, i32* %542, align 4
  %544 = zext i32 %543 to i64
  store i64 %544, i64* %R9, align 8, !tbaa !2428
  %545 = add i64 %539, -8
  %546 = add i64 %538, 15
  store i64 %546, i64* %PC, align 8
  %547 = inttoptr i64 %545 to i32*
  %548 = load i32, i32* %547, align 4
  %549 = sext i32 %543 to i64
  %550 = sext i32 %548 to i64
  %551 = mul nsw i64 %550, %549
  %552 = trunc i64 %551 to i32
  %553 = and i64 %551, 4294967295
  store i64 %553, i64* %R9, align 8, !tbaa !2428
  %554 = shl i64 %551, 32
  %555 = ashr exact i64 %554, 32
  %556 = icmp ne i64 %555, %551
  %557 = zext i1 %556 to i8
  store i8 %557, i8* %19, align 1, !tbaa !2432
  %558 = and i32 %552, 255
  %559 = tail call i32 @llvm.ctpop.i32(i32 %558) #8
  %560 = trunc i32 %559 to i8
  %561 = and i8 %560, 1
  %562 = xor i8 %561, 1
  store i8 %562, i8* %26, align 1, !tbaa !2446
  store i8 0, i8* %31, align 1, !tbaa !2447
  store i8 0, i8* %34, align 1, !tbaa !2448
  %563 = lshr i32 %552, 31
  %564 = trunc i32 %563 to i8
  store i8 %564, i8* %37, align 1, !tbaa !2449
  store i8 %557, i8* %43, align 1, !tbaa !2450
  %565 = add i64 %539, -48
  %566 = add i64 %538, 19
  store i64 %566, i64* %PC, align 8
  %567 = inttoptr i64 %565 to i32*
  %568 = load i32, i32* %567, align 4
  %569 = add i32 %568, %552
  %570 = zext i32 %569 to i64
  store i64 %570, i64* %R9, align 8, !tbaa !2428
  %571 = icmp ult i32 %569, %552
  %572 = icmp ult i32 %569, %568
  %573 = or i1 %571, %572
  %574 = zext i1 %573 to i8
  store i8 %574, i8* %19, align 1, !tbaa !2432
  %575 = and i32 %569, 255
  %576 = tail call i32 @llvm.ctpop.i32(i32 %575) #8
  %577 = trunc i32 %576 to i8
  %578 = and i8 %577, 1
  %579 = xor i8 %578, 1
  store i8 %579, i8* %26, align 1, !tbaa !2446
  %580 = xor i32 %568, %552
  %581 = xor i32 %580, %569
  %582 = lshr i32 %581, 4
  %583 = trunc i32 %582 to i8
  %584 = and i8 %583, 1
  store i8 %584, i8* %31, align 1, !tbaa !2447
  %585 = icmp eq i32 %569, 0
  %586 = zext i1 %585 to i8
  store i8 %586, i8* %34, align 1, !tbaa !2448
  %587 = lshr i32 %569, 31
  %588 = trunc i32 %587 to i8
  store i8 %588, i8* %37, align 1, !tbaa !2449
  %589 = lshr i32 %568, 31
  %590 = xor i32 %587, %563
  %591 = xor i32 %587, %589
  %592 = add nuw nsw i32 %590, %591
  %593 = icmp eq i32 %592, 2
  %594 = zext i1 %593 to i8
  store i8 %594, i8* %43, align 1, !tbaa !2450
  %595 = add i64 %539, -80
  %596 = load i32, i32* %EAX, align 4
  %597 = add i64 %538, 22
  store i64 %597, i64* %PC, align 8
  %598 = inttoptr i64 %595 to i32*
  store i32 %596, i32* %598, align 4
  %599 = load i32, i32* %R9D, align 4
  %600 = zext i32 %599 to i64
  %601 = load i64, i64* %PC, align 8
  store i64 %600, i64* %RAX, align 8, !tbaa !2428
  %602 = sext i32 %599 to i64
  %603 = lshr i64 %602, 32
  store i64 %603, i64* %95, align 8, !tbaa !2428
  %604 = load i32, i32* %R8D, align 4
  %605 = add i64 %601, 7
  store i64 %605, i64* %PC, align 8
  %606 = sext i32 %604 to i64
  %607 = shl nuw i64 %603, 32
  %608 = or i64 %607, %600
  %609 = sdiv i64 %608, %606
  %610 = shl i64 %609, 32
  %611 = ashr exact i64 %610, 32
  %612 = icmp eq i64 %609, %611
  br i1 %612, label %615, label %613

; <label>:613:                                    ; preds = %block_402c4e
  %614 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull dereferenceable(3376) %0, i64 %605, %struct.Memory* %537) #9
  %.pre3 = load i32, i32* %EDX, align 4
  %.pre4 = load i64, i64* %PC, align 8
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

; <label>:615:                                    ; preds = %block_402c4e
  %616 = srem i64 %608, %606
  %617 = and i64 %609, 4294967295
  store i64 %617, i64* %96, align 8, !tbaa !2428
  %618 = and i64 %616, 4294967295
  store i64 %618, i64* %95, align 8, !tbaa !2428
  store i8 0, i8* %19, align 1, !tbaa !2432
  store i8 0, i8* %26, align 1, !tbaa !2446
  store i8 0, i8* %31, align 1, !tbaa !2447
  store i8 0, i8* %34, align 1, !tbaa !2448
  store i8 0, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  %619 = trunc i64 %616 to i32
  br label %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit

_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit: ; preds = %615, %613
  %620 = phi i64 [ %.pre4, %613 ], [ %605, %615 ]
  %621 = phi i32 [ %.pre3, %613 ], [ %619, %615 ]
  %622 = phi %struct.Memory* [ %614, %613 ], [ %537, %615 ]
  store i8 0, i8* %19, align 1, !tbaa !2432
  %623 = and i32 %621, 255
  %624 = tail call i32 @llvm.ctpop.i32(i32 %623) #8
  %625 = trunc i32 %624 to i8
  %626 = and i8 %625, 1
  %627 = xor i8 %626, 1
  store i8 %627, i8* %26, align 1, !tbaa !2446
  store i8 0, i8* %31, align 1, !tbaa !2447
  %628 = icmp eq i32 %621, 0
  %629 = zext i1 %628 to i8
  store i8 %629, i8* %34, align 1, !tbaa !2448
  %630 = lshr i32 %621, 31
  %631 = trunc i32 %630 to i8
  store i8 %631, i8* %37, align 1, !tbaa !2449
  store i8 0, i8* %43, align 1, !tbaa !2450
  %.v10 = select i1 %628, i64 9, i64 37
  %632 = add i64 %620, %.v10
  store i64 %632, i64* %PC, align 8, !tbaa !2428
  br i1 %628, label %block_402d85, label %block_402da1

block_402c28:                                     ; preds = %block_402c1c
  %633 = add i64 %101, -48
  %634 = add i64 %137, 7
  store i64 %634, i64* %PC, align 8
  %635 = inttoptr i64 %633 to i32*
  store i32 0, i32* %635, align 4
  %.pre1 = load i64, i64* %PC, align 8
  br label %block_402c2f

block_402c2f:                                     ; preds = %block_402c28, %block_402db4
  %636 = phi i64 [ %.pre1, %block_402c28 ], [ %167, %block_402db4 ]
  %MEMORY.1 = phi %struct.Memory* [ %MEMORY.0, %block_402c28 ], [ %MEMORY.2, %block_402db4 ]
  %637 = load i64, i64* %RBP, align 8
  %638 = add i64 %637, -48
  %639 = add i64 %636, 3
  store i64 %639, i64* %PC, align 8
  %640 = inttoptr i64 %638 to i32*
  %641 = load i32, i32* %640, align 4
  %642 = zext i32 %641 to i64
  store i64 %642, i64* %RAX, align 8, !tbaa !2428
  %643 = add i64 %637, -12
  %644 = add i64 %636, 6
  store i64 %644, i64* %PC, align 8
  %645 = inttoptr i64 %643 to i32*
  %646 = load i32, i32* %645, align 4
  %647 = sub i32 %641, %646
  %648 = icmp ult i32 %641, %646
  %649 = zext i1 %648 to i8
  store i8 %649, i8* %19, align 1, !tbaa !2432
  %650 = and i32 %647, 255
  %651 = tail call i32 @llvm.ctpop.i32(i32 %650) #8
  %652 = trunc i32 %651 to i8
  %653 = and i8 %652, 1
  %654 = xor i8 %653, 1
  store i8 %654, i8* %26, align 1, !tbaa !2446
  %655 = xor i32 %646, %641
  %656 = xor i32 %655, %647
  %657 = lshr i32 %656, 4
  %658 = trunc i32 %657 to i8
  %659 = and i8 %658, 1
  store i8 %659, i8* %31, align 1, !tbaa !2447
  %660 = icmp eq i32 %647, 0
  %661 = zext i1 %660 to i8
  store i8 %661, i8* %34, align 1, !tbaa !2448
  %662 = lshr i32 %647, 31
  %663 = trunc i32 %662 to i8
  store i8 %663, i8* %37, align 1, !tbaa !2449
  %664 = lshr i32 %641, 31
  %665 = lshr i32 %646, 31
  %666 = xor i32 %665, %664
  %667 = xor i32 %662, %664
  %668 = add nuw nsw i32 %667, %666
  %669 = icmp eq i32 %668, 2
  %670 = zext i1 %669 to i8
  store i8 %670, i8* %43, align 1, !tbaa !2450
  %671 = icmp ne i8 %663, 0
  %672 = xor i1 %671, %669
  %.demorgan6 = or i1 %660, %672
  %.v7 = select i1 %.demorgan6, i64 12, i64 408
  %673 = add i64 %636, %.v7
  store i64 %673, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan6, label %block_402c3b, label %block_402dc7

block_402dc7:                                     ; preds = %block_402c2f
  %674 = add i64 %637, -44
  %675 = add i64 %673, 8
  store i64 %675, i64* %PC, align 8
  %676 = inttoptr i64 %674 to i32*
  %677 = load i32, i32* %676, align 4
  %678 = add i32 %677, 1
  %679 = zext i32 %678 to i64
  store i64 %679, i64* %RAX, align 8, !tbaa !2428
  %680 = icmp eq i32 %677, -1
  %681 = icmp eq i32 %678, 0
  %682 = or i1 %680, %681
  %683 = zext i1 %682 to i8
  store i8 %683, i8* %19, align 1, !tbaa !2432
  %684 = and i32 %678, 255
  %685 = tail call i32 @llvm.ctpop.i32(i32 %684) #8
  %686 = trunc i32 %685 to i8
  %687 = and i8 %686, 1
  %688 = xor i8 %687, 1
  store i8 %688, i8* %26, align 1, !tbaa !2446
  %689 = xor i32 %677, %678
  %690 = lshr i32 %689, 4
  %691 = trunc i32 %690 to i8
  %692 = and i8 %691, 1
  store i8 %692, i8* %31, align 1, !tbaa !2447
  %693 = zext i1 %681 to i8
  store i8 %693, i8* %34, align 1, !tbaa !2448
  %694 = lshr i32 %678, 31
  %695 = trunc i32 %694 to i8
  store i8 %695, i8* %37, align 1, !tbaa !2449
  %696 = lshr i32 %677, 31
  %697 = xor i32 %694, %696
  %698 = add nuw nsw i32 %697, %694
  %699 = icmp eq i32 %698, 2
  %700 = zext i1 %699 to i8
  store i8 %700, i8* %43, align 1, !tbaa !2450
  %701 = add i64 %673, 14
  store i64 %701, i64* %PC, align 8
  store i32 %678, i32* %676, align 4
  %702 = load i64, i64* %PC, align 8
  %703 = add i64 %702, -441
  store i64 %703, i64* %PC, align 8, !tbaa !2428
  br label %block_402c1c

block_402dda:                                     ; preds = %block_402c1c
  store i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 117), i64* %RSI, align 8, !tbaa !2428
  %704 = load i64, i64* @stderr, align 32
  store i64 %704, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %AL, align 1, !tbaa !2454
  %705 = add i64 %137, -10330
  %706 = add i64 %137, 25
  %707 = load i64, i64* %RSP, align 8, !tbaa !2428
  %708 = add i64 %707, -8
  %709 = inttoptr i64 %708 to i64*
  store i64 %706, i64* %709, align 8
  store i64 %708, i64* %RSP, align 8, !tbaa !2428
  store i64 %705, i64* %PC, align 8, !tbaa !2428
  %710 = tail call fastcc %struct.Memory* @ext_6040f8_fprintf(%struct.State* nonnull %0, %struct.Memory* %MEMORY.0)
  %711 = load i64, i64* %RBP, align 8
  %712 = add i64 %711, -88
  %713 = load i32, i32* %EAX, align 4
  %714 = load i64, i64* %PC, align 8
  %715 = add i64 %714, 3
  store i64 %715, i64* %PC, align 8
  %716 = inttoptr i64 %712 to i32*
  store i32 %713, i32* %716, align 4
  %717 = load i64, i64* %RSP, align 8
  %718 = load i64, i64* %PC, align 8
  %719 = add i64 %717, 96
  store i64 %719, i64* %RSP, align 8, !tbaa !2428
  %720 = icmp ugt i64 %717, -97
  %721 = zext i1 %720 to i8
  store i8 %721, i8* %19, align 1, !tbaa !2432
  %722 = trunc i64 %719 to i32
  %723 = and i32 %722, 255
  %724 = tail call i32 @llvm.ctpop.i32(i32 %723) #8
  %725 = trunc i32 %724 to i8
  %726 = and i8 %725, 1
  %727 = xor i8 %726, 1
  store i8 %727, i8* %26, align 1, !tbaa !2446
  %728 = xor i64 %717, %719
  %729 = lshr i64 %728, 4
  %730 = trunc i64 %729 to i8
  %731 = and i8 %730, 1
  store i8 %731, i8* %31, align 1, !tbaa !2447
  %732 = icmp eq i64 %719, 0
  %733 = zext i1 %732 to i8
  store i8 %733, i8* %34, align 1, !tbaa !2448
  %734 = lshr i64 %719, 63
  %735 = trunc i64 %734 to i8
  store i8 %735, i8* %37, align 1, !tbaa !2449
  %736 = lshr i64 %717, 63
  %737 = xor i64 %734, %736
  %738 = add nuw nsw i64 %737, %734
  %739 = icmp eq i64 %738, 2
  %740 = zext i1 %739 to i8
  store i8 %740, i8* %43, align 1, !tbaa !2450
  %741 = add i64 %718, 5
  store i64 %741, i64* %PC, align 8
  %742 = add i64 %717, 104
  %743 = inttoptr i64 %719 to i64*
  %744 = load i64, i64* %743, align 8
  store i64 %744, i64* %RBP, align 8, !tbaa !2428
  store i64 %742, i64* %RSP, align 8, !tbaa !2428
  %745 = add i64 %718, 6
  store i64 %745, i64* %PC, align 8
  %746 = inttoptr i64 %742 to i64*
  %747 = load i64, i64* %746, align 8
  store i64 %747, i64* %PC, align 8, !tbaa !2428
  %748 = add i64 %717, 112
  store i64 %748, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %710

block_402d85:                                     ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit
  store i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 117), i64* %RSI, align 8, !tbaa !2428
  %749 = load i64, i64* @stderr, align 32
  store i64 %749, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %AL, align 1, !tbaa !2454
  %750 = add i64 %632, -10245
  %751 = add i64 %632, 25
  %752 = load i64, i64* %RSP, align 8, !tbaa !2428
  %753 = add i64 %752, -8
  %754 = inttoptr i64 %753 to i64*
  store i64 %751, i64* %754, align 8
  store i64 %753, i64* %RSP, align 8, !tbaa !2428
  store i64 %750, i64* %PC, align 8, !tbaa !2428
  %755 = tail call fastcc %struct.Memory* @ext_6040f8_fprintf(%struct.State* nonnull %0, %struct.Memory* %622)
  %756 = load i64, i64* %RBP, align 8
  %757 = add i64 %756, -84
  %758 = load i32, i32* %EAX, align 4
  %759 = load i64, i64* %PC, align 8
  %760 = add i64 %759, 3
  store i64 %760, i64* %PC, align 8
  %761 = inttoptr i64 %757 to i32*
  store i32 %758, i32* %761, align 4
  %.pre5 = load i64, i64* %PC, align 8
  br label %block_402da1

block_402c42:                                     ; preds = %block_402da1, %block_402c3b
  %762 = phi i64 [ %.pre2, %block_402c3b ], [ %831, %block_402da1 ]
  %MEMORY.2 = phi %struct.Memory* [ %MEMORY.1, %block_402c3b ], [ %MEMORY.3, %block_402da1 ]
  %763 = load i64, i64* %RBP, align 8
  %764 = add i64 %763, -52
  %765 = add i64 %762, 3
  store i64 %765, i64* %PC, align 8
  %766 = inttoptr i64 %764 to i32*
  %767 = load i32, i32* %766, align 4
  %768 = zext i32 %767 to i64
  store i64 %768, i64* %RAX, align 8, !tbaa !2428
  %769 = add i64 %763, -8
  %770 = add i64 %762, 6
  store i64 %770, i64* %PC, align 8
  %771 = inttoptr i64 %769 to i32*
  %772 = load i32, i32* %771, align 4
  %773 = sub i32 %767, %772
  %774 = icmp ult i32 %767, %772
  %775 = zext i1 %774 to i8
  store i8 %775, i8* %19, align 1, !tbaa !2432
  %776 = and i32 %773, 255
  %777 = tail call i32 @llvm.ctpop.i32(i32 %776) #8
  %778 = trunc i32 %777 to i8
  %779 = and i8 %778, 1
  %780 = xor i8 %779, 1
  store i8 %780, i8* %26, align 1, !tbaa !2446
  %781 = xor i32 %772, %767
  %782 = xor i32 %781, %773
  %783 = lshr i32 %782, 4
  %784 = trunc i32 %783 to i8
  %785 = and i8 %784, 1
  store i8 %785, i8* %31, align 1, !tbaa !2447
  %786 = icmp eq i32 %773, 0
  %787 = zext i1 %786 to i8
  store i8 %787, i8* %34, align 1, !tbaa !2448
  %788 = lshr i32 %773, 31
  %789 = trunc i32 %788 to i8
  store i8 %789, i8* %37, align 1, !tbaa !2449
  %790 = lshr i32 %767, 31
  %791 = lshr i32 %772, 31
  %792 = xor i32 %791, %790
  %793 = xor i32 %788, %790
  %794 = add nuw nsw i32 %793, %792
  %795 = icmp eq i32 %794, 2
  %796 = zext i1 %795 to i8
  store i8 %796, i8* %43, align 1, !tbaa !2450
  %797 = icmp ne i8 %789, 0
  %798 = xor i1 %797, %795
  %.demorgan8 = or i1 %786, %798
  %.v9 = select i1 %.demorgan8, i64 12, i64 370
  %799 = add i64 %762, %.v9
  store i64 %799, i64* %PC, align 8, !tbaa !2428
  br i1 %.demorgan8, label %block_402c4e, label %block_402db4

block_402da1:                                     ; preds = %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit, %block_402d85
  %800 = phi i64 [ %632, %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit ], [ %.pre5, %block_402d85 ]
  %MEMORY.3 = phi %struct.Memory* [ %622, %_ZN12_GLOBAL__N_1L10IDIVedxeaxI2RnIjEEEP6MemoryS4_R5StateT_.exit ], [ %755, %block_402d85 ]
  %801 = load i64, i64* %RBP, align 8
  %802 = add i64 %801, -52
  %803 = add i64 %800, 8
  store i64 %803, i64* %PC, align 8
  %804 = inttoptr i64 %802 to i32*
  %805 = load i32, i32* %804, align 4
  %806 = add i32 %805, 1
  %807 = zext i32 %806 to i64
  store i64 %807, i64* %RAX, align 8, !tbaa !2428
  %808 = icmp eq i32 %805, -1
  %809 = icmp eq i32 %806, 0
  %810 = or i1 %808, %809
  %811 = zext i1 %810 to i8
  store i8 %811, i8* %19, align 1, !tbaa !2432
  %812 = and i32 %806, 255
  %813 = tail call i32 @llvm.ctpop.i32(i32 %812) #8
  %814 = trunc i32 %813 to i8
  %815 = and i8 %814, 1
  %816 = xor i8 %815, 1
  store i8 %816, i8* %26, align 1, !tbaa !2446
  %817 = xor i32 %805, %806
  %818 = lshr i32 %817, 4
  %819 = trunc i32 %818 to i8
  %820 = and i8 %819, 1
  store i8 %820, i8* %31, align 1, !tbaa !2447
  %821 = zext i1 %809 to i8
  store i8 %821, i8* %34, align 1, !tbaa !2448
  %822 = lshr i32 %806, 31
  %823 = trunc i32 %822 to i8
  store i8 %823, i8* %37, align 1, !tbaa !2449
  %824 = lshr i32 %805, 31
  %825 = xor i32 %822, %824
  %826 = add nuw nsw i32 %825, %822
  %827 = icmp eq i32 %826, 2
  %828 = zext i1 %827 to i8
  store i8 %828, i8* %43, align 1, !tbaa !2450
  %829 = add i64 %800, 14
  store i64 %829, i64* %PC, align 8
  store i32 %806, i32* %804, align 4
  %830 = load i64, i64* %PC, align 8
  %831 = add i64 %830, -365
  store i64 %831, i64* %PC, align 8, !tbaa !2428
  br label %block_402c42
}

; Function Attrs: noinline
define %struct.Memory* @sub_400720_polybench_prepare_instruments(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_400720:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %3 = load i64, i64* %RBP, align 8
  %4 = add i64 %1, 1
  store i64 %4, i64* %PC, align 8
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %6 = load i64, i64* %5, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %3, i64* %8, align 8
  %9 = load i64, i64* %PC, align 8
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %10 = add i64 %9, -129
  %11 = add i64 %9, 8
  %12 = add i64 %6, -16
  %13 = inttoptr i64 %12 to i64*
  store i64 %11, i64* %13, align 8
  store i64 %12, i64* %5, align 8, !tbaa !2428
  store i64 %10, i64* %PC, align 8, !tbaa !2428
  %14 = tail call %struct.Memory* @sub_4006a0_polybench_flush_cache_renamed_(%struct.State* nonnull %0, i64 %10, %struct.Memory* %2)
  %15 = load i64, i64* %PC, align 8
  %16 = add i64 %15, 1
  store i64 %16, i64* %PC, align 8
  %17 = load i64, i64* %5, align 8, !tbaa !2428
  %18 = add i64 %17, 8
  %19 = inttoptr i64 %17 to i64*
  %20 = load i64, i64* %19, align 8
  store i64 %20, i64* %RBP, align 8, !tbaa !2428
  store i64 %18, i64* %5, align 8, !tbaa !2428
  %21 = add i64 %15, 2
  store i64 %21, i64* %PC, align 8
  %22 = inttoptr i64 %18 to i64*
  %23 = load i64, i64* %22, align 8
  store i64 %23, i64* %PC, align 8, !tbaa !2428
  %24 = add i64 %17, 16
  store i64 %24, i64* %5, align 8, !tbaa !2428
  ret %struct.Memory* %14
}

; Function Attrs: noinline
define %struct.Memory* @sub_400520__init_proc(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_400520:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %3 = load i64, i64* %RSP, align 8
  %4 = add i64 %3, -8
  store i64 %4, i64* %RSP, align 8, !tbaa !2428
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  %8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  %9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  %10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  %11 = load i64, i64* inttoptr (i64 add (i64 ptrtoint (%seg_603ff0__got_type* @seg_603ff0__got to i64), i64 8) to i64*), align 8
  store i64 %11, i64* %RAX, align 8, !tbaa !2428
  store i8 0, i8* %5, align 1, !tbaa !2432
  %12 = trunc i64 %11 to i32
  %13 = and i32 %12, 255
  %14 = tail call i32 @llvm.ctpop.i32(i32 %13) #8
  %15 = trunc i32 %14 to i8
  %16 = and i8 %15, 1
  %17 = xor i8 %16, 1
  store i8 %17, i8* %6, align 1, !tbaa !2446
  %18 = icmp eq i64 %11, 0
  %19 = zext i1 %18 to i8
  store i8 %19, i8* %8, align 1, !tbaa !2448
  %20 = lshr i64 %11, 63
  %21 = trunc i64 %20 to i8
  store i8 %21, i8* %9, align 1, !tbaa !2449
  store i8 0, i8* %10, align 1, !tbaa !2450
  store i8 0, i8* %7, align 1, !tbaa !2447
  %.v = select i1 %18, i64 18, i64 16
  %22 = add i64 %.v, %1
  store i64 %22, i64* %PC, align 8, !tbaa !2428
  br i1 %18, label %block_400520.block_400532_crit_edge, label %block_400530

block_400520.block_400532_crit_edge:              ; preds = %block_400520
  br label %block_400532

block_400530:                                     ; preds = %block_400520
  %23 = add i64 %22, 2
  %24 = add i64 %3, -16
  %25 = inttoptr i64 %24 to i64*
  store i64 %23, i64* %25, align 8
  store i64 %24, i64* %RSP, align 8, !tbaa !2428
  store i64 %11, i64* %PC, align 8, !tbaa !2428
  %26 = tail call %struct.Memory* @__remill_function_call(%struct.State* nonnull %0, i64 %11, %struct.Memory* %2)
  %.pre = load i64, i64* %RSP, align 8
  %.pre1 = load i64, i64* %PC, align 8
  br label %block_400532

block_400532:                                     ; preds = %block_400520.block_400532_crit_edge, %block_400530
  %.pre-phi = phi i64* [ %RSP, %block_400520.block_400532_crit_edge ], [ %RSP, %block_400530 ]
  %27 = phi i64 [ %22, %block_400520.block_400532_crit_edge ], [ %.pre1, %block_400530 ]
  %28 = phi i64 [ %4, %block_400520.block_400532_crit_edge ], [ %.pre, %block_400530 ]
  %MEMORY.0 = phi %struct.Memory* [ %2, %block_400520.block_400532_crit_edge ], [ %26, %block_400530 ]
  %29 = add i64 %28, 8
  store i64 %29, i64* %RSP, align 8, !tbaa !2428
  %30 = icmp ugt i64 %28, -9
  %31 = zext i1 %30 to i8
  store i8 %31, i8* %5, align 1, !tbaa !2432
  %32 = trunc i64 %29 to i32
  %33 = and i32 %32, 255
  %34 = tail call i32 @llvm.ctpop.i32(i32 %33) #8
  %35 = trunc i32 %34 to i8
  %36 = and i8 %35, 1
  %37 = xor i8 %36, 1
  store i8 %37, i8* %6, align 1, !tbaa !2446
  %38 = xor i64 %28, %29
  %39 = lshr i64 %38, 4
  %40 = trunc i64 %39 to i8
  %41 = and i8 %40, 1
  store i8 %41, i8* %7, align 1, !tbaa !2447
  %42 = icmp eq i64 %29, 0
  %43 = zext i1 %42 to i8
  store i8 %43, i8* %8, align 1, !tbaa !2448
  %44 = lshr i64 %29, 63
  %45 = trunc i64 %44 to i8
  store i8 %45, i8* %9, align 1, !tbaa !2449
  %46 = lshr i64 %28, 63
  %47 = xor i64 %44, %46
  %48 = add nuw nsw i64 %47, %44
  %49 = icmp eq i64 %48, 2
  %50 = zext i1 %49 to i8
  store i8 %50, i8* %10, align 1, !tbaa !2450
  %51 = add i64 %27, 5
  store i64 %51, i64* %PC, align 8
  %52 = inttoptr i64 %29 to i64*
  %53 = load i64, i64* %52, align 8
  store i64 %53, i64* %PC, align 8, !tbaa !2428
  %54 = add i64 %28, 16
  store i64 %54, i64* %.pre-phi, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0
}

; Function Attrs: noinline
define %struct.Memory* @sub_4013d0_kernel_fdtd_apml(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_4013d0:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0
  %EDX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0
  %ESI = bitcast %union.anon* %4 to i32*
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %5 to i32*
  %RAX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %R12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 25, i32 0, i32 0
  %R13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 27, i32 0, i32 0
  %R14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 29, i32 0, i32 0
  %R15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 31, i32 0, i32 0
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %7 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %8 = load i64, i64* %RBP, align 8
  %9 = add i64 %1, 1
  store i64 %9, i64* %PC, align 8
  %10 = load i64, i64* %RSP, align 8, !tbaa !2428
  %11 = add i64 %10, -8
  %12 = inttoptr i64 %11 to i64*
  store i64 %8, i64* %12, align 8
  %13 = load i64, i64* %PC, align 8
  store i64 %11, i64* %RBP, align 8, !tbaa !2428
  %14 = load i64, i64* %R15, align 8
  %15 = add i64 %13, 5
  store i64 %15, i64* %PC, align 8
  %16 = add i64 %10, -16
  %17 = inttoptr i64 %16 to i64*
  store i64 %14, i64* %17, align 8
  %18 = load i64, i64* %R14, align 8
  %19 = load i64, i64* %PC, align 8
  %20 = add i64 %19, 2
  store i64 %20, i64* %PC, align 8
  %21 = add i64 %10, -24
  %22 = inttoptr i64 %21 to i64*
  store i64 %18, i64* %22, align 8
  %23 = load i64, i64* %R13, align 8
  %24 = load i64, i64* %PC, align 8
  %25 = add i64 %24, 2
  store i64 %25, i64* %PC, align 8
  %26 = add i64 %10, -32
  %27 = inttoptr i64 %26 to i64*
  store i64 %23, i64* %27, align 8
  %28 = load i64, i64* %R12, align 8
  %29 = load i64, i64* %PC, align 8
  %30 = add i64 %29, 2
  store i64 %30, i64* %PC, align 8
  %31 = add i64 %10, -40
  %32 = inttoptr i64 %31 to i64*
  store i64 %28, i64* %32, align 8
  %33 = load i64, i64* %RBX, align 8
  %34 = load i64, i64* %PC, align 8
  %35 = add i64 %34, 1
  store i64 %35, i64* %PC, align 8
  %36 = add i64 %10, -48
  %37 = inttoptr i64 %36 to i64*
  store i64 %33, i64* %37, align 8
  %38 = load i64, i64* %PC, align 8
  %39 = add i64 %10, -80
  store i64 %39, i64* %RSP, align 8, !tbaa !2428
  %40 = icmp ult i64 %36, 32
  %41 = zext i1 %40 to i8
  %42 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %41, i8* %42, align 1, !tbaa !2432
  %43 = trunc i64 %39 to i32
  %44 = and i32 %43, 255
  %45 = tail call i32 @llvm.ctpop.i32(i32 %44) #8
  %46 = trunc i32 %45 to i8
  %47 = and i8 %46, 1
  %48 = xor i8 %47, 1
  %49 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %48, i8* %49, align 1, !tbaa !2446
  %50 = xor i64 %36, %39
  %51 = lshr i64 %50, 4
  %52 = trunc i64 %51 to i8
  %53 = and i8 %52, 1
  %54 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %53, i8* %54, align 1, !tbaa !2447
  %55 = icmp eq i64 %39, 0
  %56 = zext i1 %55 to i8
  %57 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %56, i8* %57, align 1, !tbaa !2448
  %58 = lshr i64 %39, 63
  %59 = trunc i64 %58 to i8
  %60 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %59, i8* %60, align 1, !tbaa !2449
  %61 = lshr i64 %36, 63
  %62 = xor i64 %58, %61
  %63 = add nuw nsw i64 %62, %61
  %64 = icmp eq i64 %63, 2
  %65 = zext i1 %64 to i8
  %66 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %65, i8* %66, align 1, !tbaa !2450
  %67 = load i64, i64* %RBP, align 8
  %68 = add i64 %67, 96
  %69 = add i64 %38, 8
  store i64 %69, i64* %PC, align 8
  %70 = inttoptr i64 %68 to i64*
  %71 = load i64, i64* %70, align 8
  store i64 %71, i64* %RAX, align 8, !tbaa !2428
  %72 = add i64 %67, 88
  %73 = add i64 %38, 12
  store i64 %73, i64* %PC, align 8
  %74 = inttoptr i64 %72 to i64*
  %75 = load i64, i64* %74, align 8
  store i64 %75, i64* %R10, align 8, !tbaa !2428
  %76 = add i64 %67, 80
  %77 = add i64 %38, 16
  store i64 %77, i64* %PC, align 8
  %78 = inttoptr i64 %76 to i64*
  %79 = load i64, i64* %78, align 8
  store i64 %79, i64* %R11, align 8, !tbaa !2428
  %80 = add i64 %67, 72
  %81 = add i64 %38, 20
  store i64 %81, i64* %PC, align 8
  %82 = inttoptr i64 %80 to i64*
  %83 = load i64, i64* %82, align 8
  store i64 %83, i64* %RBX, align 8, !tbaa !2428
  %84 = add i64 %67, 64
  %85 = add i64 %38, 24
  store i64 %85, i64* %PC, align 8
  %86 = inttoptr i64 %84 to i64*
  %87 = load i64, i64* %86, align 8
  store i64 %87, i64* %R14, align 8, !tbaa !2428
  %88 = add i64 %67, 56
  %89 = add i64 %38, 28
  store i64 %89, i64* %PC, align 8
  %90 = inttoptr i64 %88 to i64*
  %91 = load i64, i64* %90, align 8
  store i64 %91, i64* %R15, align 8, !tbaa !2428
  %92 = add i64 %67, 48
  %93 = add i64 %38, 32
  store i64 %93, i64* %PC, align 8
  %94 = inttoptr i64 %92 to i64*
  %95 = load i64, i64* %94, align 8
  store i64 %95, i64* %R12, align 8, !tbaa !2428
  %96 = add i64 %67, 40
  %97 = add i64 %38, 36
  store i64 %97, i64* %PC, align 8
  %98 = inttoptr i64 %96 to i64*
  %99 = load i64, i64* %98, align 8
  store i64 %99, i64* %R13, align 8, !tbaa !2428
  %100 = add i64 %67, -120
  %101 = add i64 %38, 40
  store i64 %101, i64* %PC, align 8
  %102 = inttoptr i64 %100 to i64*
  store i64 %71, i64* %102, align 8
  %103 = load i64, i64* %RBP, align 8
  %104 = add i64 %103, 32
  %105 = load i64, i64* %PC, align 8
  %106 = add i64 %105, 4
  store i64 %106, i64* %PC, align 8
  %107 = inttoptr i64 %104 to i64*
  %108 = load i64, i64* %107, align 8
  store i64 %108, i64* %RAX, align 8, !tbaa !2428
  %109 = add i64 %103, -128
  %110 = add i64 %105, 8
  store i64 %110, i64* %PC, align 8
  %111 = inttoptr i64 %109 to i64*
  store i64 %108, i64* %111, align 8
  %112 = load i64, i64* %RBP, align 8
  %113 = add i64 %112, 24
  %114 = load i64, i64* %PC, align 8
  %115 = add i64 %114, 4
  store i64 %115, i64* %PC, align 8
  %116 = inttoptr i64 %113 to i64*
  %117 = load i64, i64* %116, align 8
  store i64 %117, i64* %RAX, align 8, !tbaa !2428
  %118 = add i64 %112, -136
  %119 = add i64 %114, 11
  store i64 %119, i64* %PC, align 8
  %120 = inttoptr i64 %118 to i64*
  store i64 %117, i64* %120, align 8
  %121 = load i64, i64* %RBP, align 8
  %122 = add i64 %121, 16
  %123 = load i64, i64* %PC, align 8
  %124 = add i64 %123, 4
  store i64 %124, i64* %PC, align 8
  %125 = inttoptr i64 %122 to i64*
  %126 = load i64, i64* %125, align 8
  store i64 %126, i64* %RAX, align 8, !tbaa !2428
  %127 = add i64 %121, -44
  %128 = load i32, i32* %EDI, align 4
  %129 = add i64 %123, 7
  store i64 %129, i64* %PC, align 8
  %130 = inttoptr i64 %127 to i32*
  store i32 %128, i32* %130, align 4
  %131 = load i64, i64* %RBP, align 8
  %132 = add i64 %131, -48
  %133 = load i32, i32* %ESI, align 4
  %134 = load i64, i64* %PC, align 8
  %135 = add i64 %134, 3
  store i64 %135, i64* %PC, align 8
  %136 = inttoptr i64 %132 to i32*
  store i32 %133, i32* %136, align 4
  %137 = load i64, i64* %RBP, align 8
  %138 = add i64 %137, -52
  %139 = load i32, i32* %EDX, align 4
  %140 = load i64, i64* %PC, align 8
  %141 = add i64 %140, 3
  store i64 %141, i64* %PC, align 8
  %142 = inttoptr i64 %138 to i32*
  store i32 %139, i32* %142, align 4
  %143 = load i64, i64* %RBP, align 8
  %144 = add i64 %143, -64
  %145 = load i64, i64* %PC, align 8
  %146 = add i64 %145, 5
  store i64 %146, i64* %PC, align 8
  %147 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %6, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  %148 = load i64, i64* %147, align 1
  %149 = inttoptr i64 %144 to i64*
  store i64 %148, i64* %149, align 8
  %150 = load i64, i64* %RBP, align 8
  %151 = add i64 %150, -72
  %152 = load i64, i64* %PC, align 8
  %153 = add i64 %152, 5
  store i64 %153, i64* %PC, align 8
  %154 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %7, i64 0, i32 0, i32 0, i32 0, i64 0
  %155 = load i64, i64* %154, align 1
  %156 = inttoptr i64 %151 to i64*
  store i64 %155, i64* %156, align 8
  %157 = load i64, i64* %RBP, align 8
  %158 = add i64 %157, -80
  %159 = load i64, i64* %RCX, align 8
  %160 = load i64, i64* %PC, align 8
  %161 = add i64 %160, 4
  store i64 %161, i64* %PC, align 8
  %162 = inttoptr i64 %158 to i64*
  store i64 %159, i64* %162, align 8
  %163 = load i64, i64* %RBP, align 8
  %164 = add i64 %163, -88
  %165 = load i64, i64* %R8, align 8
  %166 = load i64, i64* %PC, align 8
  %167 = add i64 %166, 4
  store i64 %167, i64* %PC, align 8
  %168 = inttoptr i64 %164 to i64*
  store i64 %165, i64* %168, align 8
  %169 = load i64, i64* %RBP, align 8
  %170 = add i64 %169, -96
  %171 = load i64, i64* %R9, align 8
  %172 = load i64, i64* %PC, align 8
  %173 = add i64 %172, 4
  store i64 %173, i64* %PC, align 8
  %174 = inttoptr i64 %170 to i64*
  store i64 %171, i64* %174, align 8
  %175 = load i64, i64* %RBP, align 8
  %176 = add i64 %175, -100
  %177 = load i64, i64* %PC, align 8
  %178 = add i64 %177, 7
  store i64 %178, i64* %PC, align 8
  %179 = inttoptr i64 %176 to i32*
  store i32 0, i32* %179, align 4
  %180 = load i64, i64* %RBP, align 8
  %181 = add i64 %180, -144
  %182 = load i64, i64* %R13, align 8
  %183 = load i64, i64* %PC, align 8
  %184 = add i64 %183, 7
  store i64 %184, i64* %PC, align 8
  %185 = inttoptr i64 %181 to i64*
  store i64 %182, i64* %185, align 8
  %186 = load i64, i64* %RBP, align 8
  %187 = add i64 %186, -152
  %188 = load i64, i64* %RAX, align 8
  %189 = load i64, i64* %PC, align 8
  %190 = add i64 %189, 7
  store i64 %190, i64* %PC, align 8
  %191 = inttoptr i64 %187 to i64*
  store i64 %188, i64* %191, align 8
  %192 = load i64, i64* %RBP, align 8
  %193 = add i64 %192, -160
  %194 = load i64, i64* %R10, align 8
  %195 = load i64, i64* %PC, align 8
  %196 = add i64 %195, 7
  store i64 %196, i64* %PC, align 8
  %197 = inttoptr i64 %193 to i64*
  store i64 %194, i64* %197, align 8
  %198 = load i64, i64* %RBP, align 8
  %199 = add i64 %198, -168
  %200 = load i64, i64* %R11, align 8
  %201 = load i64, i64* %PC, align 8
  %202 = add i64 %201, 7
  store i64 %202, i64* %PC, align 8
  %203 = inttoptr i64 %199 to i64*
  store i64 %200, i64* %203, align 8
  %204 = load i64, i64* %RBP, align 8
  %205 = add i64 %204, -176
  %206 = load i64, i64* %RBX, align 8
  %207 = load i64, i64* %PC, align 8
  %208 = add i64 %207, 7
  store i64 %208, i64* %PC, align 8
  %209 = inttoptr i64 %205 to i64*
  store i64 %206, i64* %209, align 8
  %210 = load i64, i64* %RBP, align 8
  %211 = add i64 %210, -184
  %212 = load i64, i64* %R14, align 8
  %213 = load i64, i64* %PC, align 8
  %214 = add i64 %213, 7
  store i64 %214, i64* %PC, align 8
  %215 = inttoptr i64 %211 to i64*
  store i64 %212, i64* %215, align 8
  %216 = load i64, i64* %RBP, align 8
  %217 = add i64 %216, -192
  %218 = load i64, i64* %R15, align 8
  %219 = load i64, i64* %PC, align 8
  %220 = add i64 %219, 7
  store i64 %220, i64* %PC, align 8
  %221 = inttoptr i64 %217 to i64*
  store i64 %218, i64* %221, align 8
  %222 = load i64, i64* %RBP, align 8
  %223 = add i64 %222, -200
  %224 = load i64, i64* %R12, align 8
  %225 = load i64, i64* %PC, align 8
  %226 = add i64 %225, 7
  store i64 %226, i64* %PC, align 8
  %227 = inttoptr i64 %223 to i64*
  store i64 %224, i64* %227, align 8
  %228 = bitcast [32 x %union.VectorReg]* %6 to double*
  %229 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %230 = bitcast i64* %229 to double*
  %231 = bitcast %union.VectorReg* %7 to double*
  %232 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %233 = bitcast i64* %232 to double*
  %.pre = load i64, i64* %PC, align 8
  br label %block_40147a

block_401499:                                     ; preds = %block_40148d
  %234 = add i64 %327, -108
  %235 = add i64 %363, 7
  store i64 %235, i64* %PC, align 8
  %236 = inttoptr i64 %234 to i32*
  store i32 0, i32* %236, align 4
  %.pre3 = load i64, i64* %PC, align 8
  br label %block_4014a0

block_40147a:                                     ; preds = %block_401ee5, %block_4013d0
  %237 = phi i64 [ %4714, %block_401ee5 ], [ %.pre, %block_4013d0 ]
  %238 = load i64, i64* %RBP, align 8
  %239 = add i64 %238, -100
  %240 = add i64 %237, 3
  store i64 %240, i64* %PC, align 8
  %241 = inttoptr i64 %239 to i32*
  %242 = load i32, i32* %241, align 4
  %243 = zext i32 %242 to i64
  store i64 %243, i64* %RAX, align 8, !tbaa !2428
  %244 = add i64 %238, -44
  %245 = add i64 %237, 6
  store i64 %245, i64* %PC, align 8
  %246 = inttoptr i64 %244 to i32*
  %247 = load i32, i32* %246, align 4
  %248 = sub i32 %242, %247
  %249 = icmp ult i32 %242, %247
  %250 = zext i1 %249 to i8
  store i8 %250, i8* %42, align 1, !tbaa !2432
  %251 = and i32 %248, 255
  %252 = tail call i32 @llvm.ctpop.i32(i32 %251) #8
  %253 = trunc i32 %252 to i8
  %254 = and i8 %253, 1
  %255 = xor i8 %254, 1
  store i8 %255, i8* %49, align 1, !tbaa !2446
  %256 = xor i32 %247, %242
  %257 = xor i32 %256, %248
  %258 = lshr i32 %257, 4
  %259 = trunc i32 %258 to i8
  %260 = and i8 %259, 1
  store i8 %260, i8* %54, align 1, !tbaa !2447
  %261 = icmp eq i32 %248, 0
  %262 = zext i1 %261 to i8
  store i8 %262, i8* %57, align 1, !tbaa !2448
  %263 = lshr i32 %248, 31
  %264 = trunc i32 %263 to i8
  store i8 %264, i8* %60, align 1, !tbaa !2449
  %265 = lshr i32 %242, 31
  %266 = lshr i32 %247, 31
  %267 = xor i32 %266, %265
  %268 = xor i32 %263, %265
  %269 = add nuw nsw i32 %268, %267
  %270 = icmp eq i32 %269, 2
  %271 = zext i1 %270 to i8
  store i8 %271, i8* %66, align 1, !tbaa !2450
  %272 = icmp ne i8 %264, 0
  %273 = xor i1 %272, %270
  %.v = select i1 %273, i64 12, i64 2686
  %274 = add i64 %237, %.v
  store i64 %274, i64* %PC, align 8, !tbaa !2428
  br i1 %273, label %block_401486, label %block_401ef8

block_401ef8:                                     ; preds = %block_40147a
  %275 = load i64, i64* %RSP, align 8
  %276 = add i64 %275, 32
  store i64 %276, i64* %RSP, align 8, !tbaa !2428
  %277 = icmp ugt i64 %275, -33
  %278 = zext i1 %277 to i8
  store i8 %278, i8* %42, align 1, !tbaa !2432
  %279 = trunc i64 %276 to i32
  %280 = and i32 %279, 255
  %281 = tail call i32 @llvm.ctpop.i32(i32 %280) #8
  %282 = trunc i32 %281 to i8
  %283 = and i8 %282, 1
  %284 = xor i8 %283, 1
  store i8 %284, i8* %49, align 1, !tbaa !2446
  %285 = xor i64 %275, %276
  %286 = lshr i64 %285, 4
  %287 = trunc i64 %286 to i8
  %288 = and i8 %287, 1
  store i8 %288, i8* %54, align 1, !tbaa !2447
  %289 = icmp eq i64 %276, 0
  %290 = zext i1 %289 to i8
  store i8 %290, i8* %57, align 1, !tbaa !2448
  %291 = lshr i64 %276, 63
  %292 = trunc i64 %291 to i8
  store i8 %292, i8* %60, align 1, !tbaa !2449
  %293 = lshr i64 %275, 63
  %294 = xor i64 %291, %293
  %295 = add nuw nsw i64 %294, %291
  %296 = icmp eq i64 %295, 2
  %297 = zext i1 %296 to i8
  store i8 %297, i8* %66, align 1, !tbaa !2450
  %298 = add i64 %274, 5
  store i64 %298, i64* %PC, align 8
  %299 = add i64 %275, 40
  %300 = inttoptr i64 %276 to i64*
  %301 = load i64, i64* %300, align 8
  store i64 %301, i64* %RBX, align 8, !tbaa !2428
  store i64 %299, i64* %RSP, align 8, !tbaa !2428
  %302 = add i64 %274, 7
  store i64 %302, i64* %PC, align 8
  %303 = add i64 %275, 48
  %304 = inttoptr i64 %299 to i64*
  %305 = load i64, i64* %304, align 8
  store i64 %305, i64* %R12, align 8, !tbaa !2428
  store i64 %303, i64* %RSP, align 8, !tbaa !2428
  %306 = add i64 %274, 9
  store i64 %306, i64* %PC, align 8
  %307 = add i64 %275, 56
  %308 = inttoptr i64 %303 to i64*
  %309 = load i64, i64* %308, align 8
  store i64 %309, i64* %R13, align 8, !tbaa !2428
  store i64 %307, i64* %RSP, align 8, !tbaa !2428
  %310 = add i64 %274, 11
  store i64 %310, i64* %PC, align 8
  %311 = add i64 %275, 64
  %312 = inttoptr i64 %307 to i64*
  %313 = load i64, i64* %312, align 8
  store i64 %313, i64* %R14, align 8, !tbaa !2428
  store i64 %311, i64* %RSP, align 8, !tbaa !2428
  %314 = add i64 %274, 13
  store i64 %314, i64* %PC, align 8
  %315 = add i64 %275, 72
  %316 = inttoptr i64 %311 to i64*
  %317 = load i64, i64* %316, align 8
  store i64 %317, i64* %R15, align 8, !tbaa !2428
  store i64 %315, i64* %RSP, align 8, !tbaa !2428
  %318 = add i64 %274, 14
  store i64 %318, i64* %PC, align 8
  %319 = add i64 %275, 80
  %320 = inttoptr i64 %315 to i64*
  %321 = load i64, i64* %320, align 8
  store i64 %321, i64* %RBP, align 8, !tbaa !2428
  store i64 %319, i64* %RSP, align 8, !tbaa !2428
  %322 = add i64 %274, 15
  store i64 %322, i64* %PC, align 8
  %323 = inttoptr i64 %319 to i64*
  %324 = load i64, i64* %323, align 8
  store i64 %324, i64* %PC, align 8, !tbaa !2428
  %325 = add i64 %275, 88
  store i64 %325, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %2

block_40148d:                                     ; preds = %block_401486, %block_401c6b
  %326 = phi i64 [ %.pre2, %block_401486 ], [ %2504, %block_401c6b ]
  %327 = load i64, i64* %RBP, align 8
  %328 = add i64 %327, -104
  %329 = add i64 %326, 3
  store i64 %329, i64* %PC, align 8
  %330 = inttoptr i64 %328 to i32*
  %331 = load i32, i32* %330, align 4
  %332 = zext i32 %331 to i64
  store i64 %332, i64* %RAX, align 8, !tbaa !2428
  %333 = add i64 %327, -52
  %334 = add i64 %326, 6
  store i64 %334, i64* %PC, align 8
  %335 = inttoptr i64 %333 to i32*
  %336 = load i32, i32* %335, align 4
  %337 = sub i32 %331, %336
  %338 = icmp ult i32 %331, %336
  %339 = zext i1 %338 to i8
  store i8 %339, i8* %42, align 1, !tbaa !2432
  %340 = and i32 %337, 255
  %341 = tail call i32 @llvm.ctpop.i32(i32 %340) #8
  %342 = trunc i32 %341 to i8
  %343 = and i8 %342, 1
  %344 = xor i8 %343, 1
  store i8 %344, i8* %49, align 1, !tbaa !2446
  %345 = xor i32 %336, %331
  %346 = xor i32 %345, %337
  %347 = lshr i32 %346, 4
  %348 = trunc i32 %347 to i8
  %349 = and i8 %348, 1
  store i8 %349, i8* %54, align 1, !tbaa !2447
  %350 = icmp eq i32 %337, 0
  %351 = zext i1 %350 to i8
  store i8 %351, i8* %57, align 1, !tbaa !2448
  %352 = lshr i32 %337, 31
  %353 = trunc i32 %352 to i8
  store i8 %353, i8* %60, align 1, !tbaa !2449
  %354 = lshr i32 %331, 31
  %355 = lshr i32 %336, 31
  %356 = xor i32 %355, %354
  %357 = xor i32 %352, %354
  %358 = add nuw nsw i32 %357, %356
  %359 = icmp eq i32 %358, 2
  %360 = zext i1 %359 to i8
  store i8 %360, i8* %66, align 1, !tbaa !2450
  %361 = icmp ne i8 %353, 0
  %362 = xor i1 %361, %359
  %.v5 = select i1 %362, i64 12, i64 2648
  %363 = add i64 %326, %.v5
  store i64 %363, i64* %PC, align 8, !tbaa !2428
  br i1 %362, label %block_401499, label %block_401ee5

block_4019d2:                                     ; preds = %block_4019de, %block_40174c
  %364 = phi i64 [ %3575, %block_4019de ], [ %.pre4, %block_40174c ]
  %365 = load i64, i64* %RBP, align 8
  %366 = add i64 %365, -108
  %367 = add i64 %364, 3
  store i64 %367, i64* %PC, align 8
  %368 = inttoptr i64 %366 to i32*
  %369 = load i32, i32* %368, align 4
  %370 = zext i32 %369 to i64
  store i64 %370, i64* %RAX, align 8, !tbaa !2428
  %371 = add i64 %365, -48
  %372 = add i64 %364, 6
  store i64 %372, i64* %PC, align 8
  %373 = inttoptr i64 %371 to i32*
  %374 = load i32, i32* %373, align 4
  %375 = sub i32 %369, %374
  %376 = icmp ult i32 %369, %374
  %377 = zext i1 %376 to i8
  store i8 %377, i8* %42, align 1, !tbaa !2432
  %378 = and i32 %375, 255
  %379 = tail call i32 @llvm.ctpop.i32(i32 %378) #8
  %380 = trunc i32 %379 to i8
  %381 = and i8 %380, 1
  %382 = xor i8 %381, 1
  store i8 %382, i8* %49, align 1, !tbaa !2446
  %383 = xor i32 %374, %369
  %384 = xor i32 %383, %375
  %385 = lshr i32 %384, 4
  %386 = trunc i32 %385 to i8
  %387 = and i8 %386, 1
  store i8 %387, i8* %54, align 1, !tbaa !2447
  %388 = icmp eq i32 %375, 0
  %389 = zext i1 %388 to i8
  store i8 %389, i8* %57, align 1, !tbaa !2448
  %390 = lshr i32 %375, 31
  %391 = trunc i32 %390 to i8
  store i8 %391, i8* %60, align 1, !tbaa !2449
  %392 = lshr i32 %369, 31
  %393 = lshr i32 %374, 31
  %394 = xor i32 %393, %392
  %395 = xor i32 %390, %392
  %396 = add nuw nsw i32 %395, %394
  %397 = icmp eq i32 %396, 2
  %398 = zext i1 %397 to i8
  store i8 %398, i8* %66, align 1, !tbaa !2450
  %399 = icmp ne i8 %391, 0
  %400 = xor i1 %399, %397
  %.v7 = select i1 %400, i64 12, i64 665
  %401 = add i64 %364, %.v7
  %402 = add i64 %365, 32
  %403 = add i64 %401, 4
  store i64 %403, i64* %PC, align 8
  %404 = inttoptr i64 %402 to i64*
  %405 = load i64, i64* %404, align 8
  store i64 %405, i64* %RAX, align 8, !tbaa !2428
  %406 = add i64 %365, -100
  %407 = add i64 %401, 8
  store i64 %407, i64* %PC, align 8
  %408 = inttoptr i64 %406 to i32*
  %409 = load i32, i32* %408, align 4
  %410 = sext i32 %409 to i64
  %411 = mul nsw i64 %410, 33800
  store i64 %411, i64* %RCX, align 8, !tbaa !2428
  %412 = lshr i64 %411, 63
  %413 = add i64 %411, %405
  store i64 %413, i64* %RAX, align 8, !tbaa !2428
  %414 = icmp ult i64 %413, %405
  %415 = icmp ult i64 %413, %411
  %416 = or i1 %414, %415
  %417 = zext i1 %416 to i8
  store i8 %417, i8* %42, align 1, !tbaa !2432
  %418 = trunc i64 %413 to i32
  %419 = and i32 %418, 255
  %420 = tail call i32 @llvm.ctpop.i32(i32 %419) #8
  %421 = trunc i32 %420 to i8
  %422 = and i8 %421, 1
  %423 = xor i8 %422, 1
  store i8 %423, i8* %49, align 1, !tbaa !2446
  %424 = xor i64 %411, %405
  %425 = xor i64 %424, %413
  %426 = lshr i64 %425, 4
  %427 = trunc i64 %426 to i8
  %428 = and i8 %427, 1
  store i8 %428, i8* %54, align 1, !tbaa !2447
  %429 = icmp eq i64 %413, 0
  %430 = zext i1 %429 to i8
  store i8 %430, i8* %57, align 1, !tbaa !2448
  %431 = lshr i64 %413, 63
  %432 = trunc i64 %431 to i8
  store i8 %432, i8* %60, align 1, !tbaa !2449
  %433 = lshr i64 %405, 63
  %434 = xor i64 %431, %433
  %435 = xor i64 %431, %412
  %436 = add nuw nsw i64 %434, %435
  %437 = icmp eq i64 %436, 2
  %438 = zext i1 %437 to i8
  store i8 %438, i8* %66, align 1, !tbaa !2450
  %439 = load i64, i64* %RBP, align 8
  %440 = add i64 %439, -52
  %441 = add i64 %401, 22
  store i64 %441, i64* %PC, align 8
  %442 = inttoptr i64 %440 to i32*
  %443 = load i32, i32* %442, align 4
  %444 = sext i32 %443 to i64
  %445 = mul nsw i64 %444, 520
  store i64 %445, i64* %RCX, align 8, !tbaa !2428
  %446 = lshr i64 %445, 63
  %447 = add i64 %401, 32
  store i64 %447, i64* %PC, align 8
  %448 = add i64 %445, %413
  store i64 %448, i64* %RAX, align 8, !tbaa !2428
  %449 = icmp ult i64 %448, %413
  %450 = icmp ult i64 %448, %445
  %451 = or i1 %449, %450
  %452 = zext i1 %451 to i8
  store i8 %452, i8* %42, align 1, !tbaa !2432
  %453 = trunc i64 %448 to i32
  %454 = and i32 %453, 255
  %455 = tail call i32 @llvm.ctpop.i32(i32 %454) #8
  %456 = trunc i32 %455 to i8
  %457 = and i8 %456, 1
  %458 = xor i8 %457, 1
  store i8 %458, i8* %49, align 1, !tbaa !2446
  %459 = xor i64 %445, %413
  %460 = xor i64 %459, %448
  %461 = lshr i64 %460, 4
  %462 = trunc i64 %461 to i8
  %463 = and i8 %462, 1
  store i8 %463, i8* %54, align 1, !tbaa !2447
  %464 = icmp eq i64 %448, 0
  %465 = zext i1 %464 to i8
  store i8 %465, i8* %57, align 1, !tbaa !2448
  %466 = lshr i64 %448, 63
  %467 = trunc i64 %466 to i8
  store i8 %467, i8* %60, align 1, !tbaa !2449
  %468 = xor i64 %466, %431
  %469 = xor i64 %466, %446
  %470 = add nuw nsw i64 %468, %469
  %471 = icmp eq i64 %470, 2
  %472 = zext i1 %471 to i8
  store i8 %472, i8* %66, align 1, !tbaa !2450
  br i1 %400, label %block_4019de, label %block_401c6b

block_40174c:                                     ; preds = %block_4014a0
  %473 = add i64 %4790, -48
  %474 = add i64 %4752, 36
  store i64 %474, i64* %PC, align 8
  %475 = inttoptr i64 %473 to i32*
  %476 = load i32, i32* %475, align 4
  %477 = sext i32 %476 to i64
  store i64 %477, i64* %RCX, align 8, !tbaa !2428
  %478 = shl nsw i64 %477, 3
  %479 = add i64 %478, %4799
  %480 = add i64 %4752, 41
  store i64 %480, i64* %PC, align 8
  %481 = inttoptr i64 %479 to i64*
  %482 = load i64, i64* %481, align 8
  store i64 %482, i64* %147, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %483 = add i64 %4790, 32
  %484 = add i64 %4752, 45
  store i64 %484, i64* %PC, align 8
  %485 = inttoptr i64 %483 to i64*
  %486 = load i64, i64* %485, align 8
  store i64 %486, i64* %RAX, align 8, !tbaa !2428
  %487 = add i64 %4790, -100
  %488 = add i64 %4752, 49
  store i64 %488, i64* %PC, align 8
  %489 = inttoptr i64 %487 to i32*
  %490 = load i32, i32* %489, align 4
  %491 = sext i32 %490 to i64
  %492 = mul nsw i64 %491, 33800
  store i64 %492, i64* %RCX, align 8, !tbaa !2428
  %493 = lshr i64 %492, 63
  %494 = add i64 %492, %486
  store i64 %494, i64* %RAX, align 8, !tbaa !2428
  %495 = icmp ult i64 %494, %486
  %496 = icmp ult i64 %494, %492
  %497 = or i1 %495, %496
  %498 = zext i1 %497 to i8
  store i8 %498, i8* %42, align 1, !tbaa !2432
  %499 = trunc i64 %494 to i32
  %500 = and i32 %499, 255
  %501 = tail call i32 @llvm.ctpop.i32(i32 %500) #8
  %502 = trunc i32 %501 to i8
  %503 = and i8 %502, 1
  %504 = xor i8 %503, 1
  store i8 %504, i8* %49, align 1, !tbaa !2446
  %505 = xor i64 %492, %486
  %506 = xor i64 %505, %494
  %507 = lshr i64 %506, 4
  %508 = trunc i64 %507 to i8
  %509 = and i8 %508, 1
  store i8 %509, i8* %54, align 1, !tbaa !2447
  %510 = icmp eq i64 %494, 0
  %511 = zext i1 %510 to i8
  store i8 %511, i8* %57, align 1, !tbaa !2448
  %512 = lshr i64 %494, 63
  %513 = trunc i64 %512 to i8
  store i8 %513, i8* %60, align 1, !tbaa !2449
  %514 = lshr i64 %486, 63
  %515 = xor i64 %512, %514
  %516 = xor i64 %512, %493
  %517 = add nuw nsw i64 %515, %516
  %518 = icmp eq i64 %517, 2
  %519 = zext i1 %518 to i8
  store i8 %519, i8* %66, align 1, !tbaa !2450
  %520 = add i64 %4752, 62
  store i64 %520, i64* %PC, align 8
  %521 = load i32, i32* %4793, align 4
  %522 = add i32 %521, 1
  %523 = zext i32 %522 to i64
  store i64 %523, i64* %RDX, align 8, !tbaa !2428
  %524 = sext i32 %522 to i64
  %525 = mul nsw i64 %524, 520
  store i64 %525, i64* %RCX, align 8, !tbaa !2428
  %526 = lshr i64 %525, 63
  %527 = load i64, i64* %RAX, align 8
  %528 = add i64 %525, %527
  store i64 %528, i64* %RAX, align 8, !tbaa !2428
  %529 = icmp ult i64 %528, %527
  %530 = icmp ult i64 %528, %525
  %531 = or i1 %529, %530
  %532 = zext i1 %531 to i8
  store i8 %532, i8* %42, align 1, !tbaa !2432
  %533 = trunc i64 %528 to i32
  %534 = and i32 %533, 255
  %535 = tail call i32 @llvm.ctpop.i32(i32 %534) #8
  %536 = trunc i32 %535 to i8
  %537 = and i8 %536, 1
  %538 = xor i8 %537, 1
  store i8 %538, i8* %49, align 1, !tbaa !2446
  %539 = xor i64 %525, %527
  %540 = xor i64 %539, %528
  %541 = lshr i64 %540, 4
  %542 = trunc i64 %541 to i8
  %543 = and i8 %542, 1
  store i8 %543, i8* %54, align 1, !tbaa !2447
  %544 = icmp eq i64 %528, 0
  %545 = zext i1 %544 to i8
  store i8 %545, i8* %57, align 1, !tbaa !2448
  %546 = lshr i64 %528, 63
  %547 = trunc i64 %546 to i8
  store i8 %547, i8* %60, align 1, !tbaa !2449
  %548 = lshr i64 %527, 63
  %549 = xor i64 %546, %548
  %550 = xor i64 %546, %526
  %551 = add nuw nsw i64 %549, %550
  %552 = icmp eq i64 %551, 2
  %553 = zext i1 %552 to i8
  store i8 %553, i8* %66, align 1, !tbaa !2450
  %554 = load i64, i64* %RBP, align 8
  %555 = add i64 %554, -48
  %556 = add i64 %4752, 82
  store i64 %556, i64* %PC, align 8
  %557 = inttoptr i64 %555 to i32*
  %558 = load i32, i32* %557, align 4
  %559 = sext i32 %558 to i64
  store i64 %559, i64* %RCX, align 8, !tbaa !2428
  %560 = shl nsw i64 %559, 3
  %561 = add i64 %560, %528
  %562 = add i64 %4752, 87
  store i64 %562, i64* %PC, align 8
  %563 = load double, double* %228, align 1
  %564 = inttoptr i64 %561 to double*
  %565 = load double, double* %564, align 8
  %566 = fsub double %563, %565
  store double %566, double* %228, align 1, !tbaa !2452
  %567 = add i64 %554, -88
  %568 = add i64 %4752, 91
  store i64 %568, i64* %PC, align 8
  %569 = inttoptr i64 %567 to i64*
  %570 = load i64, i64* %569, align 8
  store i64 %570, i64* %RAX, align 8, !tbaa !2428
  %571 = add i64 %554, -100
  %572 = add i64 %4752, 95
  store i64 %572, i64* %PC, align 8
  %573 = inttoptr i64 %571 to i32*
  %574 = load i32, i32* %573, align 4
  %575 = sext i32 %574 to i64
  %576 = mul nsw i64 %575, 520
  store i64 %576, i64* %RCX, align 8, !tbaa !2428
  %577 = lshr i64 %576, 63
  %578 = add i64 %576, %570
  store i64 %578, i64* %RAX, align 8, !tbaa !2428
  %579 = icmp ult i64 %578, %570
  %580 = icmp ult i64 %578, %576
  %581 = or i1 %579, %580
  %582 = zext i1 %581 to i8
  store i8 %582, i8* %42, align 1, !tbaa !2432
  %583 = trunc i64 %578 to i32
  %584 = and i32 %583, 255
  %585 = tail call i32 @llvm.ctpop.i32(i32 %584) #8
  %586 = trunc i32 %585 to i8
  %587 = and i8 %586, 1
  %588 = xor i8 %587, 1
  store i8 %588, i8* %49, align 1, !tbaa !2446
  %589 = xor i64 %576, %570
  %590 = xor i64 %589, %578
  %591 = lshr i64 %590, 4
  %592 = trunc i64 %591 to i8
  %593 = and i8 %592, 1
  store i8 %593, i8* %54, align 1, !tbaa !2447
  %594 = icmp eq i64 %578, 0
  %595 = zext i1 %594 to i8
  store i8 %595, i8* %57, align 1, !tbaa !2448
  %596 = lshr i64 %578, 63
  %597 = trunc i64 %596 to i8
  store i8 %597, i8* %60, align 1, !tbaa !2449
  %598 = lshr i64 %570, 63
  %599 = xor i64 %596, %598
  %600 = xor i64 %596, %577
  %601 = add nuw nsw i64 %599, %600
  %602 = icmp eq i64 %601, 2
  %603 = zext i1 %602 to i8
  store i8 %603, i8* %66, align 1, !tbaa !2450
  %604 = add i64 %554, -104
  %605 = add i64 %4752, 109
  store i64 %605, i64* %PC, align 8
  %606 = inttoptr i64 %604 to i32*
  %607 = load i32, i32* %606, align 4
  %608 = sext i32 %607 to i64
  store i64 %608, i64* %RCX, align 8, !tbaa !2428
  %609 = shl nsw i64 %608, 3
  %610 = add i64 %609, %578
  %611 = add i64 %4752, 114
  store i64 %611, i64* %PC, align 8
  %612 = inttoptr i64 %610 to double*
  %613 = load double, double* %612, align 8
  %614 = fadd double %566, %613
  store double %614, double* %228, align 1, !tbaa !2452
  %615 = load i64, i64* %RBP, align 8
  %616 = add i64 %615, 40
  %617 = add i64 %4752, 118
  store i64 %617, i64* %PC, align 8
  %618 = inttoptr i64 %616 to i64*
  %619 = load i64, i64* %618, align 8
  store i64 %619, i64* %RAX, align 8, !tbaa !2428
  %620 = add i64 %615, -100
  %621 = add i64 %4752, 122
  store i64 %621, i64* %PC, align 8
  %622 = inttoptr i64 %620 to i32*
  %623 = load i32, i32* %622, align 4
  %624 = sext i32 %623 to i64
  %625 = mul nsw i64 %624, 33800
  store i64 %625, i64* %RCX, align 8, !tbaa !2428
  %626 = lshr i64 %625, 63
  %627 = add i64 %625, %619
  store i64 %627, i64* %RAX, align 8, !tbaa !2428
  %628 = icmp ult i64 %627, %619
  %629 = icmp ult i64 %627, %625
  %630 = or i1 %628, %629
  %631 = zext i1 %630 to i8
  store i8 %631, i8* %42, align 1, !tbaa !2432
  %632 = trunc i64 %627 to i32
  %633 = and i32 %632, 255
  %634 = tail call i32 @llvm.ctpop.i32(i32 %633) #8
  %635 = trunc i32 %634 to i8
  %636 = and i8 %635, 1
  %637 = xor i8 %636, 1
  store i8 %637, i8* %49, align 1, !tbaa !2446
  %638 = xor i64 %625, %619
  %639 = xor i64 %638, %627
  %640 = lshr i64 %639, 4
  %641 = trunc i64 %640 to i8
  %642 = and i8 %641, 1
  store i8 %642, i8* %54, align 1, !tbaa !2447
  %643 = icmp eq i64 %627, 0
  %644 = zext i1 %643 to i8
  store i8 %644, i8* %57, align 1, !tbaa !2448
  %645 = lshr i64 %627, 63
  %646 = trunc i64 %645 to i8
  store i8 %646, i8* %60, align 1, !tbaa !2449
  %647 = lshr i64 %619, 63
  %648 = xor i64 %645, %647
  %649 = xor i64 %645, %626
  %650 = add nuw nsw i64 %648, %649
  %651 = icmp eq i64 %650, 2
  %652 = zext i1 %651 to i8
  store i8 %652, i8* %66, align 1, !tbaa !2450
  %653 = add i64 %615, -104
  %654 = add i64 %4752, 136
  store i64 %654, i64* %PC, align 8
  %655 = inttoptr i64 %653 to i32*
  %656 = load i32, i32* %655, align 4
  %657 = sext i32 %656 to i64
  %658 = mul nsw i64 %657, 520
  store i64 %658, i64* %RCX, align 8, !tbaa !2428
  %659 = lshr i64 %658, 63
  %660 = add i64 %658, %627
  store i64 %660, i64* %RAX, align 8, !tbaa !2428
  %661 = icmp ult i64 %660, %627
  %662 = icmp ult i64 %660, %658
  %663 = or i1 %661, %662
  %664 = zext i1 %663 to i8
  store i8 %664, i8* %42, align 1, !tbaa !2432
  %665 = trunc i64 %660 to i32
  %666 = and i32 %665, 255
  %667 = tail call i32 @llvm.ctpop.i32(i32 %666) #8
  %668 = trunc i32 %667 to i8
  %669 = and i8 %668, 1
  %670 = xor i8 %669, 1
  store i8 %670, i8* %49, align 1, !tbaa !2446
  %671 = xor i64 %658, %627
  %672 = xor i64 %671, %660
  %673 = lshr i64 %672, 4
  %674 = trunc i64 %673 to i8
  %675 = and i8 %674, 1
  store i8 %675, i8* %54, align 1, !tbaa !2447
  %676 = icmp eq i64 %660, 0
  %677 = zext i1 %676 to i8
  store i8 %677, i8* %57, align 1, !tbaa !2448
  %678 = lshr i64 %660, 63
  %679 = trunc i64 %678 to i8
  store i8 %679, i8* %60, align 1, !tbaa !2449
  %680 = xor i64 %678, %645
  %681 = xor i64 %678, %659
  %682 = add nuw nsw i64 %680, %681
  %683 = icmp eq i64 %682, 2
  %684 = zext i1 %683 to i8
  store i8 %684, i8* %66, align 1, !tbaa !2450
  %685 = load i64, i64* %RBP, align 8
  %686 = add i64 %685, -48
  %687 = add i64 %4752, 150
  store i64 %687, i64* %PC, align 8
  %688 = inttoptr i64 %686 to i32*
  %689 = load i32, i32* %688, align 4
  %690 = sext i32 %689 to i64
  store i64 %690, i64* %RCX, align 8, !tbaa !2428
  %691 = shl nsw i64 %690, 3
  %692 = add i64 %691, %660
  %693 = add i64 %4752, 155
  store i64 %693, i64* %PC, align 8
  %694 = load double, double* %228, align 1
  %695 = inttoptr i64 %692 to double*
  %696 = load double, double* %695, align 8
  %697 = fsub double %694, %696
  store double %697, double* %228, align 1, !tbaa !2452
  %698 = add i64 %685, -96
  %699 = add i64 %4752, 159
  store i64 %699, i64* %PC, align 8
  %700 = inttoptr i64 %698 to i64*
  %701 = load i64, i64* %700, align 8
  store i64 %701, i64* %RAX, align 8, !tbaa !2428
  %702 = add i64 %685, -100
  %703 = add i64 %4752, 163
  store i64 %703, i64* %PC, align 8
  %704 = inttoptr i64 %702 to i32*
  %705 = load i32, i32* %704, align 4
  %706 = sext i32 %705 to i64
  %707 = mul nsw i64 %706, 520
  store i64 %707, i64* %RCX, align 8, !tbaa !2428
  %708 = lshr i64 %707, 63
  %709 = add i64 %707, %701
  store i64 %709, i64* %RAX, align 8, !tbaa !2428
  %710 = icmp ult i64 %709, %701
  %711 = icmp ult i64 %709, %707
  %712 = or i1 %710, %711
  %713 = zext i1 %712 to i8
  store i8 %713, i8* %42, align 1, !tbaa !2432
  %714 = trunc i64 %709 to i32
  %715 = and i32 %714, 255
  %716 = tail call i32 @llvm.ctpop.i32(i32 %715) #8
  %717 = trunc i32 %716 to i8
  %718 = and i8 %717, 1
  %719 = xor i8 %718, 1
  store i8 %719, i8* %49, align 1, !tbaa !2446
  %720 = xor i64 %707, %701
  %721 = xor i64 %720, %709
  %722 = lshr i64 %721, 4
  %723 = trunc i64 %722 to i8
  %724 = and i8 %723, 1
  store i8 %724, i8* %54, align 1, !tbaa !2447
  %725 = icmp eq i64 %709, 0
  %726 = zext i1 %725 to i8
  store i8 %726, i8* %57, align 1, !tbaa !2448
  %727 = lshr i64 %709, 63
  %728 = trunc i64 %727 to i8
  store i8 %728, i8* %60, align 1, !tbaa !2449
  %729 = lshr i64 %701, 63
  %730 = xor i64 %727, %729
  %731 = xor i64 %727, %708
  %732 = add nuw nsw i64 %730, %731
  %733 = icmp eq i64 %732, 2
  %734 = zext i1 %733 to i8
  store i8 %734, i8* %66, align 1, !tbaa !2450
  %735 = add i64 %685, -104
  %736 = add i64 %4752, 177
  store i64 %736, i64* %PC, align 8
  %737 = inttoptr i64 %735 to i32*
  %738 = load i32, i32* %737, align 4
  %739 = sext i32 %738 to i64
  store i64 %739, i64* %RCX, align 8, !tbaa !2428
  %740 = shl nsw i64 %739, 3
  %741 = add i64 %740, %709
  %742 = add i64 %4752, 182
  store i64 %742, i64* %PC, align 8
  %743 = inttoptr i64 %741 to double*
  store double %697, double* %743, align 8
  %744 = load i64, i64* %RBP, align 8
  %745 = add i64 %744, 88
  %746 = load i64, i64* %PC, align 8
  %747 = add i64 %746, 4
  store i64 %747, i64* %PC, align 8
  %748 = inttoptr i64 %745 to i64*
  %749 = load i64, i64* %748, align 8
  store i64 %749, i64* %RAX, align 8, !tbaa !2428
  %750 = add i64 %744, -104
  %751 = add i64 %746, 8
  store i64 %751, i64* %PC, align 8
  %752 = inttoptr i64 %750 to i32*
  %753 = load i32, i32* %752, align 4
  %754 = sext i32 %753 to i64
  store i64 %754, i64* %RCX, align 8, !tbaa !2428
  %755 = shl nsw i64 %754, 3
  %756 = add i64 %755, %749
  %757 = add i64 %746, 13
  store i64 %757, i64* %PC, align 8
  %758 = inttoptr i64 %756 to double*
  %759 = load double, double* %758, align 8
  store double %759, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %760 = add i64 %744, 96
  %761 = add i64 %746, 17
  store i64 %761, i64* %PC, align 8
  %762 = inttoptr i64 %760 to i64*
  %763 = load i64, i64* %762, align 8
  store i64 %763, i64* %RAX, align 8, !tbaa !2428
  %764 = add i64 %746, 21
  store i64 %764, i64* %PC, align 8
  %765 = load i32, i32* %752, align 4
  %766 = sext i32 %765 to i64
  store i64 %766, i64* %RCX, align 8, !tbaa !2428
  %767 = shl nsw i64 %766, 3
  %768 = add i64 %767, %763
  %769 = add i64 %746, 26
  store i64 %769, i64* %PC, align 8
  %770 = inttoptr i64 %768 to double*
  %771 = load double, double* %770, align 8
  %772 = fdiv double %759, %771
  store double %772, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %773 = add i64 %744, 24
  %774 = add i64 %746, 30
  store i64 %774, i64* %PC, align 8
  %775 = inttoptr i64 %773 to i64*
  %776 = load i64, i64* %775, align 8
  store i64 %776, i64* %RAX, align 8, !tbaa !2428
  %777 = add i64 %744, -100
  %778 = add i64 %746, 34
  store i64 %778, i64* %PC, align 8
  %779 = inttoptr i64 %777 to i32*
  %780 = load i32, i32* %779, align 4
  %781 = sext i32 %780 to i64
  %782 = mul nsw i64 %781, 33800
  store i64 %782, i64* %RCX, align 8, !tbaa !2428
  %783 = lshr i64 %782, 63
  %784 = add i64 %782, %776
  store i64 %784, i64* %RAX, align 8, !tbaa !2428
  %785 = icmp ult i64 %784, %776
  %786 = icmp ult i64 %784, %782
  %787 = or i1 %785, %786
  %788 = zext i1 %787 to i8
  store i8 %788, i8* %42, align 1, !tbaa !2432
  %789 = trunc i64 %784 to i32
  %790 = and i32 %789, 255
  %791 = tail call i32 @llvm.ctpop.i32(i32 %790) #8
  %792 = trunc i32 %791 to i8
  %793 = and i8 %792, 1
  %794 = xor i8 %793, 1
  store i8 %794, i8* %49, align 1, !tbaa !2446
  %795 = xor i64 %782, %776
  %796 = xor i64 %795, %784
  %797 = lshr i64 %796, 4
  %798 = trunc i64 %797 to i8
  %799 = and i8 %798, 1
  store i8 %799, i8* %54, align 1, !tbaa !2447
  %800 = icmp eq i64 %784, 0
  %801 = zext i1 %800 to i8
  store i8 %801, i8* %57, align 1, !tbaa !2448
  %802 = lshr i64 %784, 63
  %803 = trunc i64 %802 to i8
  store i8 %803, i8* %60, align 1, !tbaa !2449
  %804 = lshr i64 %776, 63
  %805 = xor i64 %802, %804
  %806 = xor i64 %802, %783
  %807 = add nuw nsw i64 %805, %806
  %808 = icmp eq i64 %807, 2
  %809 = zext i1 %808 to i8
  store i8 %809, i8* %66, align 1, !tbaa !2450
  %810 = load i64, i64* %RBP, align 8
  %811 = add i64 %810, -104
  %812 = add i64 %746, 48
  store i64 %812, i64* %PC, align 8
  %813 = inttoptr i64 %811 to i32*
  %814 = load i32, i32* %813, align 4
  %815 = sext i32 %814 to i64
  %816 = mul nsw i64 %815, 520
  store i64 %816, i64* %RCX, align 8, !tbaa !2428
  %817 = lshr i64 %816, 63
  %818 = add i64 %816, %784
  store i64 %818, i64* %RAX, align 8, !tbaa !2428
  %819 = icmp ult i64 %818, %784
  %820 = icmp ult i64 %818, %816
  %821 = or i1 %819, %820
  %822 = zext i1 %821 to i8
  store i8 %822, i8* %42, align 1, !tbaa !2432
  %823 = trunc i64 %818 to i32
  %824 = and i32 %823, 255
  %825 = tail call i32 @llvm.ctpop.i32(i32 %824) #8
  %826 = trunc i32 %825 to i8
  %827 = and i8 %826, 1
  %828 = xor i8 %827, 1
  store i8 %828, i8* %49, align 1, !tbaa !2446
  %829 = xor i64 %816, %784
  %830 = xor i64 %829, %818
  %831 = lshr i64 %830, 4
  %832 = trunc i64 %831 to i8
  %833 = and i8 %832, 1
  store i8 %833, i8* %54, align 1, !tbaa !2447
  %834 = icmp eq i64 %818, 0
  %835 = zext i1 %834 to i8
  store i8 %835, i8* %57, align 1, !tbaa !2448
  %836 = lshr i64 %818, 63
  %837 = trunc i64 %836 to i8
  store i8 %837, i8* %60, align 1, !tbaa !2449
  %838 = xor i64 %836, %802
  %839 = xor i64 %836, %817
  %840 = add nuw nsw i64 %838, %839
  %841 = icmp eq i64 %840, 2
  %842 = zext i1 %841 to i8
  store i8 %842, i8* %66, align 1, !tbaa !2450
  %843 = add i64 %810, -48
  %844 = add i64 %746, 62
  store i64 %844, i64* %PC, align 8
  %845 = inttoptr i64 %843 to i32*
  %846 = load i32, i32* %845, align 4
  %847 = sext i32 %846 to i64
  store i64 %847, i64* %RCX, align 8, !tbaa !2428
  %848 = shl nsw i64 %847, 3
  %849 = add i64 %848, %818
  %850 = add i64 %746, 67
  store i64 %850, i64* %PC, align 8
  %851 = load double, double* %228, align 1
  %852 = inttoptr i64 %849 to double*
  %853 = load double, double* %852, align 8
  %854 = fmul double %851, %853
  store double %854, double* %228, align 1, !tbaa !2452
  %855 = add i64 %810, -72
  %856 = add i64 %746, 72
  store i64 %856, i64* %PC, align 8
  %857 = inttoptr i64 %855 to double*
  %858 = load double, double* %857, align 8
  store double %858, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %859 = add i64 %810, 96
  %860 = add i64 %746, 76
  store i64 %860, i64* %PC, align 8
  %861 = inttoptr i64 %859 to i64*
  %862 = load i64, i64* %861, align 8
  store i64 %862, i64* %RAX, align 8, !tbaa !2428
  %863 = add i64 %746, 80
  store i64 %863, i64* %PC, align 8
  %864 = load i32, i32* %813, align 4
  %865 = sext i32 %864 to i64
  store i64 %865, i64* %RCX, align 8, !tbaa !2428
  %866 = shl nsw i64 %865, 3
  %867 = add i64 %866, %862
  %868 = add i64 %746, 85
  store i64 %868, i64* %PC, align 8
  %869 = inttoptr i64 %867 to double*
  %870 = load double, double* %869, align 8
  %871 = fdiv double %858, %870
  store double %871, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %872 = load i64, i64* %RBP, align 8
  %873 = add i64 %872, -96
  %874 = add i64 %746, 89
  store i64 %874, i64* %PC, align 8
  %875 = inttoptr i64 %873 to i64*
  %876 = load i64, i64* %875, align 8
  store i64 %876, i64* %RAX, align 8, !tbaa !2428
  %877 = add i64 %872, -100
  %878 = add i64 %746, 93
  store i64 %878, i64* %PC, align 8
  %879 = inttoptr i64 %877 to i32*
  %880 = load i32, i32* %879, align 4
  %881 = sext i32 %880 to i64
  %882 = mul nsw i64 %881, 520
  store i64 %882, i64* %RCX, align 8, !tbaa !2428
  %883 = lshr i64 %882, 63
  %884 = add i64 %882, %876
  store i64 %884, i64* %RAX, align 8, !tbaa !2428
  %885 = icmp ult i64 %884, %876
  %886 = icmp ult i64 %884, %882
  %887 = or i1 %885, %886
  %888 = zext i1 %887 to i8
  store i8 %888, i8* %42, align 1, !tbaa !2432
  %889 = trunc i64 %884 to i32
  %890 = and i32 %889, 255
  %891 = tail call i32 @llvm.ctpop.i32(i32 %890) #8
  %892 = trunc i32 %891 to i8
  %893 = and i8 %892, 1
  %894 = xor i8 %893, 1
  store i8 %894, i8* %49, align 1, !tbaa !2446
  %895 = xor i64 %882, %876
  %896 = xor i64 %895, %884
  %897 = lshr i64 %896, 4
  %898 = trunc i64 %897 to i8
  %899 = and i8 %898, 1
  store i8 %899, i8* %54, align 1, !tbaa !2447
  %900 = icmp eq i64 %884, 0
  %901 = zext i1 %900 to i8
  store i8 %901, i8* %57, align 1, !tbaa !2448
  %902 = lshr i64 %884, 63
  %903 = trunc i64 %902 to i8
  store i8 %903, i8* %60, align 1, !tbaa !2449
  %904 = lshr i64 %876, 63
  %905 = xor i64 %902, %904
  %906 = xor i64 %902, %883
  %907 = add nuw nsw i64 %905, %906
  %908 = icmp eq i64 %907, 2
  %909 = zext i1 %908 to i8
  store i8 %909, i8* %66, align 1, !tbaa !2450
  %910 = add i64 %872, -104
  %911 = add i64 %746, 107
  store i64 %911, i64* %PC, align 8
  %912 = inttoptr i64 %910 to i32*
  %913 = load i32, i32* %912, align 4
  %914 = sext i32 %913 to i64
  store i64 %914, i64* %RCX, align 8, !tbaa !2428
  %915 = shl nsw i64 %914, 3
  %916 = add i64 %915, %884
  %917 = add i64 %746, 112
  store i64 %917, i64* %PC, align 8
  %918 = inttoptr i64 %916 to double*
  %919 = load double, double* %918, align 8
  %920 = fmul double %871, %919
  store double %920, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %921 = load double, double* %228, align 1
  %922 = fsub double %921, %920
  store double %922, double* %228, align 1, !tbaa !2452
  %923 = add i64 %872, 16
  %924 = add i64 %746, 120
  store i64 %924, i64* %PC, align 8
  %925 = inttoptr i64 %923 to i64*
  %926 = load i64, i64* %925, align 8
  store i64 %926, i64* %RAX, align 8, !tbaa !2428
  %927 = load i64, i64* %RBP, align 8
  %928 = add i64 %927, -100
  %929 = add i64 %746, 124
  store i64 %929, i64* %PC, align 8
  %930 = inttoptr i64 %928 to i32*
  %931 = load i32, i32* %930, align 4
  %932 = sext i32 %931 to i64
  %933 = mul nsw i64 %932, 520
  store i64 %933, i64* %RCX, align 8, !tbaa !2428
  %934 = lshr i64 %933, 63
  %935 = add i64 %933, %926
  store i64 %935, i64* %RAX, align 8, !tbaa !2428
  %936 = icmp ult i64 %935, %926
  %937 = icmp ult i64 %935, %933
  %938 = or i1 %936, %937
  %939 = zext i1 %938 to i8
  store i8 %939, i8* %42, align 1, !tbaa !2432
  %940 = trunc i64 %935 to i32
  %941 = and i32 %940, 255
  %942 = tail call i32 @llvm.ctpop.i32(i32 %941) #8
  %943 = trunc i32 %942 to i8
  %944 = and i8 %943, 1
  %945 = xor i8 %944, 1
  store i8 %945, i8* %49, align 1, !tbaa !2446
  %946 = xor i64 %933, %926
  %947 = xor i64 %946, %935
  %948 = lshr i64 %947, 4
  %949 = trunc i64 %948 to i8
  %950 = and i8 %949, 1
  store i8 %950, i8* %54, align 1, !tbaa !2447
  %951 = icmp eq i64 %935, 0
  %952 = zext i1 %951 to i8
  store i8 %952, i8* %57, align 1, !tbaa !2448
  %953 = lshr i64 %935, 63
  %954 = trunc i64 %953 to i8
  store i8 %954, i8* %60, align 1, !tbaa !2449
  %955 = lshr i64 %926, 63
  %956 = xor i64 %953, %955
  %957 = xor i64 %953, %934
  %958 = add nuw nsw i64 %956, %957
  %959 = icmp eq i64 %958, 2
  %960 = zext i1 %959 to i8
  store i8 %960, i8* %66, align 1, !tbaa !2450
  %961 = add i64 %927, -104
  %962 = add i64 %746, 138
  store i64 %962, i64* %PC, align 8
  %963 = inttoptr i64 %961 to i32*
  %964 = load i32, i32* %963, align 4
  %965 = sext i32 %964 to i64
  store i64 %965, i64* %RCX, align 8, !tbaa !2428
  %966 = shl nsw i64 %965, 3
  %967 = add i64 %966, %935
  %968 = add i64 %746, 143
  store i64 %968, i64* %PC, align 8
  %969 = inttoptr i64 %967 to double*
  store double %922, double* %969, align 8
  %970 = load i64, i64* %RBP, align 8
  %971 = add i64 %970, 72
  %972 = load i64, i64* %PC, align 8
  %973 = add i64 %972, 4
  store i64 %973, i64* %PC, align 8
  %974 = inttoptr i64 %971 to i64*
  %975 = load i64, i64* %974, align 8
  store i64 %975, i64* %RAX, align 8, !tbaa !2428
  %976 = add i64 %970, -48
  %977 = add i64 %972, 8
  store i64 %977, i64* %PC, align 8
  %978 = inttoptr i64 %976 to i32*
  %979 = load i32, i32* %978, align 4
  %980 = sext i32 %979 to i64
  store i64 %980, i64* %RCX, align 8, !tbaa !2428
  %981 = shl nsw i64 %980, 3
  %982 = add i64 %981, %975
  %983 = add i64 %972, 13
  store i64 %983, i64* %PC, align 8
  %984 = inttoptr i64 %982 to double*
  %985 = load double, double* %984, align 8
  store double %985, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %986 = add i64 %970, 80
  %987 = add i64 %972, 17
  store i64 %987, i64* %PC, align 8
  %988 = inttoptr i64 %986 to i64*
  %989 = load i64, i64* %988, align 8
  store i64 %989, i64* %RAX, align 8, !tbaa !2428
  %990 = add i64 %972, 21
  store i64 %990, i64* %PC, align 8
  %991 = load i32, i32* %978, align 4
  %992 = sext i32 %991 to i64
  store i64 %992, i64* %RCX, align 8, !tbaa !2428
  %993 = shl nsw i64 %992, 3
  %994 = add i64 %993, %989
  %995 = add i64 %972, 26
  store i64 %995, i64* %PC, align 8
  %996 = inttoptr i64 %994 to double*
  %997 = load double, double* %996, align 8
  %998 = fdiv double %985, %997
  store double %998, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %999 = add i64 %970, 48
  %1000 = add i64 %972, 30
  store i64 %1000, i64* %PC, align 8
  %1001 = inttoptr i64 %999 to i64*
  %1002 = load i64, i64* %1001, align 8
  store i64 %1002, i64* %RAX, align 8, !tbaa !2428
  %1003 = add i64 %970, -100
  %1004 = add i64 %972, 34
  store i64 %1004, i64* %PC, align 8
  %1005 = inttoptr i64 %1003 to i32*
  %1006 = load i32, i32* %1005, align 4
  %1007 = sext i32 %1006 to i64
  %1008 = mul nsw i64 %1007, 33800
  store i64 %1008, i64* %RCX, align 8, !tbaa !2428
  %1009 = lshr i64 %1008, 63
  %1010 = add i64 %1008, %1002
  store i64 %1010, i64* %RAX, align 8, !tbaa !2428
  %1011 = icmp ult i64 %1010, %1002
  %1012 = icmp ult i64 %1010, %1008
  %1013 = or i1 %1011, %1012
  %1014 = zext i1 %1013 to i8
  store i8 %1014, i8* %42, align 1, !tbaa !2432
  %1015 = trunc i64 %1010 to i32
  %1016 = and i32 %1015, 255
  %1017 = tail call i32 @llvm.ctpop.i32(i32 %1016) #8
  %1018 = trunc i32 %1017 to i8
  %1019 = and i8 %1018, 1
  %1020 = xor i8 %1019, 1
  store i8 %1020, i8* %49, align 1, !tbaa !2446
  %1021 = xor i64 %1008, %1002
  %1022 = xor i64 %1021, %1010
  %1023 = lshr i64 %1022, 4
  %1024 = trunc i64 %1023 to i8
  %1025 = and i8 %1024, 1
  store i8 %1025, i8* %54, align 1, !tbaa !2447
  %1026 = icmp eq i64 %1010, 0
  %1027 = zext i1 %1026 to i8
  store i8 %1027, i8* %57, align 1, !tbaa !2448
  %1028 = lshr i64 %1010, 63
  %1029 = trunc i64 %1028 to i8
  store i8 %1029, i8* %60, align 1, !tbaa !2449
  %1030 = lshr i64 %1002, 63
  %1031 = xor i64 %1028, %1030
  %1032 = xor i64 %1028, %1009
  %1033 = add nuw nsw i64 %1031, %1032
  %1034 = icmp eq i64 %1033, 2
  %1035 = zext i1 %1034 to i8
  store i8 %1035, i8* %66, align 1, !tbaa !2450
  %1036 = load i64, i64* %RBP, align 8
  %1037 = add i64 %1036, -104
  %1038 = add i64 %972, 48
  store i64 %1038, i64* %PC, align 8
  %1039 = inttoptr i64 %1037 to i32*
  %1040 = load i32, i32* %1039, align 4
  %1041 = sext i32 %1040 to i64
  %1042 = mul nsw i64 %1041, 520
  store i64 %1042, i64* %RCX, align 8, !tbaa !2428
  %1043 = lshr i64 %1042, 63
  %1044 = add i64 %1042, %1010
  store i64 %1044, i64* %RAX, align 8, !tbaa !2428
  %1045 = icmp ult i64 %1044, %1010
  %1046 = icmp ult i64 %1044, %1042
  %1047 = or i1 %1045, %1046
  %1048 = zext i1 %1047 to i8
  store i8 %1048, i8* %42, align 1, !tbaa !2432
  %1049 = trunc i64 %1044 to i32
  %1050 = and i32 %1049, 255
  %1051 = tail call i32 @llvm.ctpop.i32(i32 %1050) #8
  %1052 = trunc i32 %1051 to i8
  %1053 = and i8 %1052, 1
  %1054 = xor i8 %1053, 1
  store i8 %1054, i8* %49, align 1, !tbaa !2446
  %1055 = xor i64 %1042, %1010
  %1056 = xor i64 %1055, %1044
  %1057 = lshr i64 %1056, 4
  %1058 = trunc i64 %1057 to i8
  %1059 = and i8 %1058, 1
  store i8 %1059, i8* %54, align 1, !tbaa !2447
  %1060 = icmp eq i64 %1044, 0
  %1061 = zext i1 %1060 to i8
  store i8 %1061, i8* %57, align 1, !tbaa !2448
  %1062 = lshr i64 %1044, 63
  %1063 = trunc i64 %1062 to i8
  store i8 %1063, i8* %60, align 1, !tbaa !2449
  %1064 = xor i64 %1062, %1028
  %1065 = xor i64 %1062, %1043
  %1066 = add nuw nsw i64 %1064, %1065
  %1067 = icmp eq i64 %1066, 2
  %1068 = zext i1 %1067 to i8
  store i8 %1068, i8* %66, align 1, !tbaa !2450
  %1069 = add i64 %1036, -48
  %1070 = add i64 %972, 62
  store i64 %1070, i64* %PC, align 8
  %1071 = inttoptr i64 %1069 to i32*
  %1072 = load i32, i32* %1071, align 4
  %1073 = sext i32 %1072 to i64
  store i64 %1073, i64* %RCX, align 8, !tbaa !2428
  %1074 = shl nsw i64 %1073, 3
  %1075 = add i64 %1074, %1044
  %1076 = add i64 %972, 67
  store i64 %1076, i64* %PC, align 8
  %1077 = load double, double* %228, align 1
  %1078 = inttoptr i64 %1075 to double*
  %1079 = load double, double* %1078, align 8
  %1080 = fmul double %1077, %1079
  store double %1080, double* %228, align 1, !tbaa !2452
  %1081 = add i64 %1036, -64
  %1082 = add i64 %972, 72
  store i64 %1082, i64* %PC, align 8
  %1083 = inttoptr i64 %1081 to double*
  %1084 = load double, double* %1083, align 8
  store double %1084, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %1085 = add i64 %1036, 64
  %1086 = add i64 %972, 76
  store i64 %1086, i64* %PC, align 8
  %1087 = inttoptr i64 %1085 to i64*
  %1088 = load i64, i64* %1087, align 8
  store i64 %1088, i64* %RAX, align 8, !tbaa !2428
  %1089 = add i64 %1036, -100
  %1090 = add i64 %972, 80
  store i64 %1090, i64* %PC, align 8
  %1091 = inttoptr i64 %1089 to i32*
  %1092 = load i32, i32* %1091, align 4
  %1093 = sext i32 %1092 to i64
  store i64 %1093, i64* %RCX, align 8, !tbaa !2428
  %1094 = shl nsw i64 %1093, 3
  %1095 = add i64 %1094, %1088
  %1096 = add i64 %972, 85
  store i64 %1096, i64* %PC, align 8
  %1097 = inttoptr i64 %1095 to double*
  %1098 = load double, double* %1097, align 8
  %1099 = fmul double %1084, %1098
  store double %1099, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %1100 = load i64, i64* %RBP, align 8
  %1101 = add i64 %1100, 80
  %1102 = add i64 %972, 89
  store i64 %1102, i64* %PC, align 8
  %1103 = inttoptr i64 %1101 to i64*
  %1104 = load i64, i64* %1103, align 8
  store i64 %1104, i64* %RAX, align 8, !tbaa !2428
  %1105 = add i64 %1100, -48
  %1106 = add i64 %972, 93
  store i64 %1106, i64* %PC, align 8
  %1107 = inttoptr i64 %1105 to i32*
  %1108 = load i32, i32* %1107, align 4
  %1109 = sext i32 %1108 to i64
  store i64 %1109, i64* %RCX, align 8, !tbaa !2428
  %1110 = shl nsw i64 %1109, 3
  %1111 = add i64 %1110, %1104
  %1112 = add i64 %972, 98
  store i64 %1112, i64* %PC, align 8
  %1113 = inttoptr i64 %1111 to double*
  %1114 = load double, double* %1113, align 8
  %1115 = fdiv double %1099, %1114
  store double %1115, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %1116 = add i64 %1100, 16
  %1117 = add i64 %972, 102
  store i64 %1117, i64* %PC, align 8
  %1118 = inttoptr i64 %1116 to i64*
  %1119 = load i64, i64* %1118, align 8
  store i64 %1119, i64* %RAX, align 8, !tbaa !2428
  %1120 = add i64 %1100, -100
  %1121 = add i64 %972, 106
  store i64 %1121, i64* %PC, align 8
  %1122 = inttoptr i64 %1120 to i32*
  %1123 = load i32, i32* %1122, align 4
  %1124 = sext i32 %1123 to i64
  %1125 = mul nsw i64 %1124, 520
  store i64 %1125, i64* %RCX, align 8, !tbaa !2428
  %1126 = lshr i64 %1125, 63
  %1127 = add i64 %1125, %1119
  store i64 %1127, i64* %RAX, align 8, !tbaa !2428
  %1128 = icmp ult i64 %1127, %1119
  %1129 = icmp ult i64 %1127, %1125
  %1130 = or i1 %1128, %1129
  %1131 = zext i1 %1130 to i8
  store i8 %1131, i8* %42, align 1, !tbaa !2432
  %1132 = trunc i64 %1127 to i32
  %1133 = and i32 %1132, 255
  %1134 = tail call i32 @llvm.ctpop.i32(i32 %1133) #8
  %1135 = trunc i32 %1134 to i8
  %1136 = and i8 %1135, 1
  %1137 = xor i8 %1136, 1
  store i8 %1137, i8* %49, align 1, !tbaa !2446
  %1138 = xor i64 %1125, %1119
  %1139 = xor i64 %1138, %1127
  %1140 = lshr i64 %1139, 4
  %1141 = trunc i64 %1140 to i8
  %1142 = and i8 %1141, 1
  store i8 %1142, i8* %54, align 1, !tbaa !2447
  %1143 = icmp eq i64 %1127, 0
  %1144 = zext i1 %1143 to i8
  store i8 %1144, i8* %57, align 1, !tbaa !2448
  %1145 = lshr i64 %1127, 63
  %1146 = trunc i64 %1145 to i8
  store i8 %1146, i8* %60, align 1, !tbaa !2449
  %1147 = lshr i64 %1119, 63
  %1148 = xor i64 %1145, %1147
  %1149 = xor i64 %1145, %1126
  %1150 = add nuw nsw i64 %1148, %1149
  %1151 = icmp eq i64 %1150, 2
  %1152 = zext i1 %1151 to i8
  store i8 %1152, i8* %66, align 1, !tbaa !2450
  %1153 = add i64 %1100, -104
  %1154 = add i64 %972, 120
  store i64 %1154, i64* %PC, align 8
  %1155 = inttoptr i64 %1153 to i32*
  %1156 = load i32, i32* %1155, align 4
  %1157 = sext i32 %1156 to i64
  store i64 %1157, i64* %RCX, align 8, !tbaa !2428
  %1158 = shl nsw i64 %1157, 3
  %1159 = add i64 %1158, %1127
  %1160 = add i64 %972, 125
  store i64 %1160, i64* %PC, align 8
  %1161 = inttoptr i64 %1159 to double*
  %1162 = load double, double* %1161, align 8
  %1163 = fmul double %1115, %1162
  store double %1163, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %1164 = load double, double* %228, align 1
  %1165 = fadd double %1164, %1163
  store double %1165, double* %228, align 1, !tbaa !2452
  %1166 = load i64, i64* %RBP, align 8
  %1167 = add i64 %1166, -64
  %1168 = add i64 %972, 134
  store i64 %1168, i64* %PC, align 8
  %1169 = inttoptr i64 %1167 to double*
  %1170 = load double, double* %1169, align 8
  store double %1170, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %1171 = add i64 %1166, 56
  %1172 = add i64 %972, 138
  store i64 %1172, i64* %PC, align 8
  %1173 = inttoptr i64 %1171 to i64*
  %1174 = load i64, i64* %1173, align 8
  store i64 %1174, i64* %RAX, align 8, !tbaa !2428
  %1175 = add i64 %1166, -100
  %1176 = add i64 %972, 142
  store i64 %1176, i64* %PC, align 8
  %1177 = inttoptr i64 %1175 to i32*
  %1178 = load i32, i32* %1177, align 4
  %1179 = sext i32 %1178 to i64
  store i64 %1179, i64* %RCX, align 8, !tbaa !2428
  %1180 = shl nsw i64 %1179, 3
  %1181 = add i64 %1180, %1174
  %1182 = add i64 %972, 147
  store i64 %1182, i64* %PC, align 8
  %1183 = inttoptr i64 %1181 to double*
  %1184 = load double, double* %1183, align 8
  %1185 = fmul double %1170, %1184
  store double %1185, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %1186 = add i64 %1166, 80
  %1187 = add i64 %972, 151
  store i64 %1187, i64* %PC, align 8
  %1188 = inttoptr i64 %1186 to i64*
  %1189 = load i64, i64* %1188, align 8
  store i64 %1189, i64* %RAX, align 8, !tbaa !2428
  %1190 = add i64 %1166, -48
  %1191 = add i64 %972, 155
  store i64 %1191, i64* %PC, align 8
  %1192 = inttoptr i64 %1190 to i32*
  %1193 = load i32, i32* %1192, align 4
  %1194 = sext i32 %1193 to i64
  store i64 %1194, i64* %RCX, align 8, !tbaa !2428
  %1195 = shl nsw i64 %1194, 3
  %1196 = add i64 %1195, %1189
  %1197 = add i64 %972, 160
  store i64 %1197, i64* %PC, align 8
  %1198 = inttoptr i64 %1196 to double*
  %1199 = load double, double* %1198, align 8
  %1200 = fdiv double %1185, %1199
  store double %1200, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %1201 = add i64 %1166, 24
  %1202 = add i64 %972, 164
  store i64 %1202, i64* %PC, align 8
  %1203 = inttoptr i64 %1201 to i64*
  %1204 = load i64, i64* %1203, align 8
  store i64 %1204, i64* %RAX, align 8, !tbaa !2428
  %1205 = add i64 %972, 168
  store i64 %1205, i64* %PC, align 8
  %1206 = load i32, i32* %1177, align 4
  %1207 = sext i32 %1206 to i64
  %1208 = mul nsw i64 %1207, 33800
  store i64 %1208, i64* %RCX, align 8, !tbaa !2428
  %1209 = lshr i64 %1208, 63
  %1210 = add i64 %1208, %1204
  store i64 %1210, i64* %RAX, align 8, !tbaa !2428
  %1211 = icmp ult i64 %1210, %1204
  %1212 = icmp ult i64 %1210, %1208
  %1213 = or i1 %1211, %1212
  %1214 = zext i1 %1213 to i8
  store i8 %1214, i8* %42, align 1, !tbaa !2432
  %1215 = trunc i64 %1210 to i32
  %1216 = and i32 %1215, 255
  %1217 = tail call i32 @llvm.ctpop.i32(i32 %1216) #8
  %1218 = trunc i32 %1217 to i8
  %1219 = and i8 %1218, 1
  %1220 = xor i8 %1219, 1
  store i8 %1220, i8* %49, align 1, !tbaa !2446
  %1221 = xor i64 %1208, %1204
  %1222 = xor i64 %1221, %1210
  %1223 = lshr i64 %1222, 4
  %1224 = trunc i64 %1223 to i8
  %1225 = and i8 %1224, 1
  store i8 %1225, i8* %54, align 1, !tbaa !2447
  %1226 = icmp eq i64 %1210, 0
  %1227 = zext i1 %1226 to i8
  store i8 %1227, i8* %57, align 1, !tbaa !2448
  %1228 = lshr i64 %1210, 63
  %1229 = trunc i64 %1228 to i8
  store i8 %1229, i8* %60, align 1, !tbaa !2449
  %1230 = lshr i64 %1204, 63
  %1231 = xor i64 %1228, %1230
  %1232 = xor i64 %1228, %1209
  %1233 = add nuw nsw i64 %1231, %1232
  %1234 = icmp eq i64 %1233, 2
  %1235 = zext i1 %1234 to i8
  store i8 %1235, i8* %66, align 1, !tbaa !2450
  %1236 = load i64, i64* %RBP, align 8
  %1237 = add i64 %1236, -104
  %1238 = add i64 %972, 182
  store i64 %1238, i64* %PC, align 8
  %1239 = inttoptr i64 %1237 to i32*
  %1240 = load i32, i32* %1239, align 4
  %1241 = sext i32 %1240 to i64
  %1242 = mul nsw i64 %1241, 520
  store i64 %1242, i64* %RCX, align 8, !tbaa !2428
  %1243 = lshr i64 %1242, 63
  %1244 = add i64 %1242, %1210
  store i64 %1244, i64* %RAX, align 8, !tbaa !2428
  %1245 = icmp ult i64 %1244, %1210
  %1246 = icmp ult i64 %1244, %1242
  %1247 = or i1 %1245, %1246
  %1248 = zext i1 %1247 to i8
  store i8 %1248, i8* %42, align 1, !tbaa !2432
  %1249 = trunc i64 %1244 to i32
  %1250 = and i32 %1249, 255
  %1251 = tail call i32 @llvm.ctpop.i32(i32 %1250) #8
  %1252 = trunc i32 %1251 to i8
  %1253 = and i8 %1252, 1
  %1254 = xor i8 %1253, 1
  store i8 %1254, i8* %49, align 1, !tbaa !2446
  %1255 = xor i64 %1242, %1210
  %1256 = xor i64 %1255, %1244
  %1257 = lshr i64 %1256, 4
  %1258 = trunc i64 %1257 to i8
  %1259 = and i8 %1258, 1
  store i8 %1259, i8* %54, align 1, !tbaa !2447
  %1260 = icmp eq i64 %1244, 0
  %1261 = zext i1 %1260 to i8
  store i8 %1261, i8* %57, align 1, !tbaa !2448
  %1262 = lshr i64 %1244, 63
  %1263 = trunc i64 %1262 to i8
  store i8 %1263, i8* %60, align 1, !tbaa !2449
  %1264 = xor i64 %1262, %1228
  %1265 = xor i64 %1262, %1243
  %1266 = add nuw nsw i64 %1264, %1265
  %1267 = icmp eq i64 %1266, 2
  %1268 = zext i1 %1267 to i8
  store i8 %1268, i8* %66, align 1, !tbaa !2450
  %1269 = add i64 %1236, -48
  %1270 = add i64 %972, 196
  store i64 %1270, i64* %PC, align 8
  %1271 = inttoptr i64 %1269 to i32*
  %1272 = load i32, i32* %1271, align 4
  %1273 = sext i32 %1272 to i64
  store i64 %1273, i64* %RCX, align 8, !tbaa !2428
  %1274 = shl nsw i64 %1273, 3
  %1275 = add i64 %1274, %1244
  %1276 = add i64 %972, 201
  store i64 %1276, i64* %PC, align 8
  %1277 = load double, double* %231, align 1
  %1278 = inttoptr i64 %1275 to double*
  %1279 = load double, double* %1278, align 8
  %1280 = fmul double %1277, %1279
  store double %1280, double* %231, align 1, !tbaa !2452
  %1281 = load double, double* %228, align 1
  %1282 = fsub double %1281, %1280
  store double %1282, double* %228, align 1, !tbaa !2452
  %1283 = add i64 %1236, 48
  %1284 = add i64 %972, 209
  store i64 %1284, i64* %PC, align 8
  %1285 = inttoptr i64 %1283 to i64*
  %1286 = load i64, i64* %1285, align 8
  store i64 %1286, i64* %RAX, align 8, !tbaa !2428
  %1287 = add i64 %1236, -100
  %1288 = add i64 %972, 213
  store i64 %1288, i64* %PC, align 8
  %1289 = inttoptr i64 %1287 to i32*
  %1290 = load i32, i32* %1289, align 4
  %1291 = sext i32 %1290 to i64
  %1292 = mul nsw i64 %1291, 33800
  store i64 %1292, i64* %RCX, align 8, !tbaa !2428
  %1293 = lshr i64 %1292, 63
  %1294 = add i64 %1292, %1286
  store i64 %1294, i64* %RAX, align 8, !tbaa !2428
  %1295 = icmp ult i64 %1294, %1286
  %1296 = icmp ult i64 %1294, %1292
  %1297 = or i1 %1295, %1296
  %1298 = zext i1 %1297 to i8
  store i8 %1298, i8* %42, align 1, !tbaa !2432
  %1299 = trunc i64 %1294 to i32
  %1300 = and i32 %1299, 255
  %1301 = tail call i32 @llvm.ctpop.i32(i32 %1300) #8
  %1302 = trunc i32 %1301 to i8
  %1303 = and i8 %1302, 1
  %1304 = xor i8 %1303, 1
  store i8 %1304, i8* %49, align 1, !tbaa !2446
  %1305 = xor i64 %1292, %1286
  %1306 = xor i64 %1305, %1294
  %1307 = lshr i64 %1306, 4
  %1308 = trunc i64 %1307 to i8
  %1309 = and i8 %1308, 1
  store i8 %1309, i8* %54, align 1, !tbaa !2447
  %1310 = icmp eq i64 %1294, 0
  %1311 = zext i1 %1310 to i8
  store i8 %1311, i8* %57, align 1, !tbaa !2448
  %1312 = lshr i64 %1294, 63
  %1313 = trunc i64 %1312 to i8
  store i8 %1313, i8* %60, align 1, !tbaa !2449
  %1314 = lshr i64 %1286, 63
  %1315 = xor i64 %1312, %1314
  %1316 = xor i64 %1312, %1293
  %1317 = add nuw nsw i64 %1315, %1316
  %1318 = icmp eq i64 %1317, 2
  %1319 = zext i1 %1318 to i8
  store i8 %1319, i8* %66, align 1, !tbaa !2450
  %1320 = load i64, i64* %RBP, align 8
  %1321 = add i64 %1320, -104
  %1322 = add i64 %972, 227
  store i64 %1322, i64* %PC, align 8
  %1323 = inttoptr i64 %1321 to i32*
  %1324 = load i32, i32* %1323, align 4
  %1325 = sext i32 %1324 to i64
  %1326 = mul nsw i64 %1325, 520
  store i64 %1326, i64* %RCX, align 8, !tbaa !2428
  %1327 = lshr i64 %1326, 63
  %1328 = add i64 %1326, %1294
  store i64 %1328, i64* %RAX, align 8, !tbaa !2428
  %1329 = icmp ult i64 %1328, %1294
  %1330 = icmp ult i64 %1328, %1326
  %1331 = or i1 %1329, %1330
  %1332 = zext i1 %1331 to i8
  store i8 %1332, i8* %42, align 1, !tbaa !2432
  %1333 = trunc i64 %1328 to i32
  %1334 = and i32 %1333, 255
  %1335 = tail call i32 @llvm.ctpop.i32(i32 %1334) #8
  %1336 = trunc i32 %1335 to i8
  %1337 = and i8 %1336, 1
  %1338 = xor i8 %1337, 1
  store i8 %1338, i8* %49, align 1, !tbaa !2446
  %1339 = xor i64 %1326, %1294
  %1340 = xor i64 %1339, %1328
  %1341 = lshr i64 %1340, 4
  %1342 = trunc i64 %1341 to i8
  %1343 = and i8 %1342, 1
  store i8 %1343, i8* %54, align 1, !tbaa !2447
  %1344 = icmp eq i64 %1328, 0
  %1345 = zext i1 %1344 to i8
  store i8 %1345, i8* %57, align 1, !tbaa !2448
  %1346 = lshr i64 %1328, 63
  %1347 = trunc i64 %1346 to i8
  store i8 %1347, i8* %60, align 1, !tbaa !2449
  %1348 = xor i64 %1346, %1312
  %1349 = xor i64 %1346, %1327
  %1350 = add nuw nsw i64 %1348, %1349
  %1351 = icmp eq i64 %1350, 2
  %1352 = zext i1 %1351 to i8
  store i8 %1352, i8* %66, align 1, !tbaa !2450
  %1353 = add i64 %1320, -48
  %1354 = add i64 %972, 241
  store i64 %1354, i64* %PC, align 8
  %1355 = inttoptr i64 %1353 to i32*
  %1356 = load i32, i32* %1355, align 4
  %1357 = sext i32 %1356 to i64
  store i64 %1357, i64* %RCX, align 8, !tbaa !2428
  %1358 = shl nsw i64 %1357, 3
  %1359 = add i64 %1358, %1328
  %1360 = add i64 %972, 246
  store i64 %1360, i64* %PC, align 8
  %1361 = load i64, i64* %147, align 1
  %1362 = inttoptr i64 %1359 to i64*
  store i64 %1361, i64* %1362, align 8
  %1363 = load i64, i64* %RBP, align 8
  %1364 = add i64 %1363, 16
  %1365 = load i64, i64* %PC, align 8
  %1366 = add i64 %1365, 4
  store i64 %1366, i64* %PC, align 8
  %1367 = inttoptr i64 %1364 to i64*
  %1368 = load i64, i64* %1367, align 8
  store i64 %1368, i64* %RAX, align 8, !tbaa !2428
  %1369 = add i64 %1363, -100
  %1370 = add i64 %1365, 8
  store i64 %1370, i64* %PC, align 8
  %1371 = inttoptr i64 %1369 to i32*
  %1372 = load i32, i32* %1371, align 4
  %1373 = sext i32 %1372 to i64
  %1374 = mul nsw i64 %1373, 520
  store i64 %1374, i64* %RCX, align 8, !tbaa !2428
  %1375 = lshr i64 %1374, 63
  %1376 = add i64 %1374, %1368
  store i64 %1376, i64* %RAX, align 8, !tbaa !2428
  %1377 = icmp ult i64 %1376, %1368
  %1378 = icmp ult i64 %1376, %1374
  %1379 = or i1 %1377, %1378
  %1380 = zext i1 %1379 to i8
  store i8 %1380, i8* %42, align 1, !tbaa !2432
  %1381 = trunc i64 %1376 to i32
  %1382 = and i32 %1381, 255
  %1383 = tail call i32 @llvm.ctpop.i32(i32 %1382) #8
  %1384 = trunc i32 %1383 to i8
  %1385 = and i8 %1384, 1
  %1386 = xor i8 %1385, 1
  store i8 %1386, i8* %49, align 1, !tbaa !2446
  %1387 = xor i64 %1374, %1368
  %1388 = xor i64 %1387, %1376
  %1389 = lshr i64 %1388, 4
  %1390 = trunc i64 %1389 to i8
  %1391 = and i8 %1390, 1
  store i8 %1391, i8* %54, align 1, !tbaa !2447
  %1392 = icmp eq i64 %1376, 0
  %1393 = zext i1 %1392 to i8
  store i8 %1393, i8* %57, align 1, !tbaa !2448
  %1394 = lshr i64 %1376, 63
  %1395 = trunc i64 %1394 to i8
  store i8 %1395, i8* %60, align 1, !tbaa !2449
  %1396 = lshr i64 %1368, 63
  %1397 = xor i64 %1394, %1396
  %1398 = xor i64 %1394, %1375
  %1399 = add nuw nsw i64 %1397, %1398
  %1400 = icmp eq i64 %1399, 2
  %1401 = zext i1 %1400 to i8
  store i8 %1401, i8* %66, align 1, !tbaa !2450
  %1402 = add i64 %1363, -104
  %1403 = add i64 %1365, 22
  store i64 %1403, i64* %PC, align 8
  %1404 = inttoptr i64 %1402 to i32*
  %1405 = load i32, i32* %1404, align 4
  %1406 = sext i32 %1405 to i64
  store i64 %1406, i64* %RCX, align 8, !tbaa !2428
  %1407 = shl nsw i64 %1406, 3
  %1408 = add i64 %1407, %1376
  %1409 = add i64 %1365, 27
  store i64 %1409, i64* %PC, align 8
  %1410 = inttoptr i64 %1408 to i64*
  %1411 = load i64, i64* %1410, align 8
  store i64 %1411, i64* %147, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %1412 = add i64 %1363, 24
  %1413 = add i64 %1365, 31
  store i64 %1413, i64* %PC, align 8
  %1414 = inttoptr i64 %1412 to i64*
  %1415 = load i64, i64* %1414, align 8
  store i64 %1415, i64* %RAX, align 8, !tbaa !2428
  %1416 = add i64 %1365, 35
  store i64 %1416, i64* %PC, align 8
  %1417 = load i32, i32* %1371, align 4
  %1418 = sext i32 %1417 to i64
  %1419 = mul nsw i64 %1418, 33800
  store i64 %1419, i64* %RCX, align 8, !tbaa !2428
  %1420 = lshr i64 %1419, 63
  %1421 = add i64 %1419, %1415
  store i64 %1421, i64* %RAX, align 8, !tbaa !2428
  %1422 = icmp ult i64 %1421, %1415
  %1423 = icmp ult i64 %1421, %1419
  %1424 = or i1 %1422, %1423
  %1425 = zext i1 %1424 to i8
  store i8 %1425, i8* %42, align 1, !tbaa !2432
  %1426 = trunc i64 %1421 to i32
  %1427 = and i32 %1426, 255
  %1428 = tail call i32 @llvm.ctpop.i32(i32 %1427) #8
  %1429 = trunc i32 %1428 to i8
  %1430 = and i8 %1429, 1
  %1431 = xor i8 %1430, 1
  store i8 %1431, i8* %49, align 1, !tbaa !2446
  %1432 = xor i64 %1419, %1415
  %1433 = xor i64 %1432, %1421
  %1434 = lshr i64 %1433, 4
  %1435 = trunc i64 %1434 to i8
  %1436 = and i8 %1435, 1
  store i8 %1436, i8* %54, align 1, !tbaa !2447
  %1437 = icmp eq i64 %1421, 0
  %1438 = zext i1 %1437 to i8
  store i8 %1438, i8* %57, align 1, !tbaa !2448
  %1439 = lshr i64 %1421, 63
  %1440 = trunc i64 %1439 to i8
  store i8 %1440, i8* %60, align 1, !tbaa !2449
  %1441 = lshr i64 %1415, 63
  %1442 = xor i64 %1439, %1441
  %1443 = xor i64 %1439, %1420
  %1444 = add nuw nsw i64 %1442, %1443
  %1445 = icmp eq i64 %1444, 2
  %1446 = zext i1 %1445 to i8
  store i8 %1446, i8* %66, align 1, !tbaa !2450
  %1447 = load i64, i64* %RBP, align 8
  %1448 = add i64 %1447, -104
  %1449 = add i64 %1365, 49
  store i64 %1449, i64* %PC, align 8
  %1450 = inttoptr i64 %1448 to i32*
  %1451 = load i32, i32* %1450, align 4
  %1452 = sext i32 %1451 to i64
  %1453 = mul nsw i64 %1452, 520
  store i64 %1453, i64* %RCX, align 8, !tbaa !2428
  %1454 = lshr i64 %1453, 63
  %1455 = add i64 %1453, %1421
  store i64 %1455, i64* %RAX, align 8, !tbaa !2428
  %1456 = icmp ult i64 %1455, %1421
  %1457 = icmp ult i64 %1455, %1453
  %1458 = or i1 %1456, %1457
  %1459 = zext i1 %1458 to i8
  store i8 %1459, i8* %42, align 1, !tbaa !2432
  %1460 = trunc i64 %1455 to i32
  %1461 = and i32 %1460, 255
  %1462 = tail call i32 @llvm.ctpop.i32(i32 %1461) #8
  %1463 = trunc i32 %1462 to i8
  %1464 = and i8 %1463, 1
  %1465 = xor i8 %1464, 1
  store i8 %1465, i8* %49, align 1, !tbaa !2446
  %1466 = xor i64 %1453, %1421
  %1467 = xor i64 %1466, %1455
  %1468 = lshr i64 %1467, 4
  %1469 = trunc i64 %1468 to i8
  %1470 = and i8 %1469, 1
  store i8 %1470, i8* %54, align 1, !tbaa !2447
  %1471 = icmp eq i64 %1455, 0
  %1472 = zext i1 %1471 to i8
  store i8 %1472, i8* %57, align 1, !tbaa !2448
  %1473 = lshr i64 %1455, 63
  %1474 = trunc i64 %1473 to i8
  store i8 %1474, i8* %60, align 1, !tbaa !2449
  %1475 = xor i64 %1473, %1439
  %1476 = xor i64 %1473, %1454
  %1477 = add nuw nsw i64 %1475, %1476
  %1478 = icmp eq i64 %1477, 2
  %1479 = zext i1 %1478 to i8
  store i8 %1479, i8* %66, align 1, !tbaa !2450
  %1480 = add i64 %1447, -48
  %1481 = add i64 %1365, 63
  store i64 %1481, i64* %PC, align 8
  %1482 = inttoptr i64 %1480 to i32*
  %1483 = load i32, i32* %1482, align 4
  %1484 = sext i32 %1483 to i64
  store i64 %1484, i64* %RCX, align 8, !tbaa !2428
  %1485 = shl nsw i64 %1484, 3
  %1486 = add i64 %1485, %1455
  %1487 = add i64 %1365, 68
  store i64 %1487, i64* %PC, align 8
  %1488 = load i64, i64* %147, align 1
  %1489 = inttoptr i64 %1486 to i64*
  store i64 %1488, i64* %1489, align 8
  %1490 = load i64, i64* %RBP, align 8
  %1491 = add i64 %1490, -108
  %1492 = load i64, i64* %PC, align 8
  %1493 = add i64 %1492, 7
  store i64 %1493, i64* %PC, align 8
  %1494 = inttoptr i64 %1491 to i32*
  store i32 0, i32* %1494, align 4
  %.pre4 = load i64, i64* %PC, align 8
  br label %block_4019d2

block_401c6b:                                     ; preds = %block_4019d2
  %1495 = add i64 %439, -48
  %1496 = add i64 %401, 36
  store i64 %1496, i64* %PC, align 8
  %1497 = inttoptr i64 %1495 to i32*
  %1498 = load i32, i32* %1497, align 4
  %1499 = sext i32 %1498 to i64
  store i64 %1499, i64* %RCX, align 8, !tbaa !2428
  %1500 = shl nsw i64 %1499, 3
  %1501 = add i64 %1500, %448
  %1502 = add i64 %401, 41
  store i64 %1502, i64* %PC, align 8
  %1503 = inttoptr i64 %1501 to double*
  %1504 = load double, double* %1503, align 8
  store double %1504, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %1505 = add i64 %439, -80
  %1506 = add i64 %401, 45
  store i64 %1506, i64* %PC, align 8
  %1507 = inttoptr i64 %1505 to i64*
  %1508 = load i64, i64* %1507, align 8
  store i64 %1508, i64* %RAX, align 8, !tbaa !2428
  %1509 = add i64 %439, -100
  %1510 = add i64 %401, 49
  store i64 %1510, i64* %PC, align 8
  %1511 = inttoptr i64 %1509 to i32*
  %1512 = load i32, i32* %1511, align 4
  %1513 = sext i32 %1512 to i64
  %1514 = mul nsw i64 %1513, 520
  store i64 %1514, i64* %RCX, align 8, !tbaa !2428
  %1515 = lshr i64 %1514, 63
  %1516 = add i64 %1514, %1508
  store i64 %1516, i64* %RAX, align 8, !tbaa !2428
  %1517 = icmp ult i64 %1516, %1508
  %1518 = icmp ult i64 %1516, %1514
  %1519 = or i1 %1517, %1518
  %1520 = zext i1 %1519 to i8
  store i8 %1520, i8* %42, align 1, !tbaa !2432
  %1521 = trunc i64 %1516 to i32
  %1522 = and i32 %1521, 255
  %1523 = tail call i32 @llvm.ctpop.i32(i32 %1522) #8
  %1524 = trunc i32 %1523 to i8
  %1525 = and i8 %1524, 1
  %1526 = xor i8 %1525, 1
  store i8 %1526, i8* %49, align 1, !tbaa !2446
  %1527 = xor i64 %1514, %1508
  %1528 = xor i64 %1527, %1516
  %1529 = lshr i64 %1528, 4
  %1530 = trunc i64 %1529 to i8
  %1531 = and i8 %1530, 1
  store i8 %1531, i8* %54, align 1, !tbaa !2447
  %1532 = icmp eq i64 %1516, 0
  %1533 = zext i1 %1532 to i8
  store i8 %1533, i8* %57, align 1, !tbaa !2448
  %1534 = lshr i64 %1516, 63
  %1535 = trunc i64 %1534 to i8
  store i8 %1535, i8* %60, align 1, !tbaa !2449
  %1536 = lshr i64 %1508, 63
  %1537 = xor i64 %1534, %1536
  %1538 = xor i64 %1534, %1515
  %1539 = add nuw nsw i64 %1537, %1538
  %1540 = icmp eq i64 %1539, 2
  %1541 = zext i1 %1540 to i8
  store i8 %1541, i8* %66, align 1, !tbaa !2450
  %1542 = add i64 %401, 63
  store i64 %1542, i64* %PC, align 8
  %1543 = load i32, i32* %1497, align 4
  %1544 = sext i32 %1543 to i64
  store i64 %1544, i64* %RCX, align 8, !tbaa !2428
  %1545 = shl nsw i64 %1544, 3
  %1546 = add i64 %1545, %1516
  %1547 = add i64 %401, 68
  store i64 %1547, i64* %PC, align 8
  %1548 = inttoptr i64 %1546 to double*
  %1549 = load double, double* %1548, align 8
  %1550 = fsub double %1504, %1549
  store double %1550, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %1551 = load i64, i64* %RBP, align 8
  %1552 = add i64 %1551, -88
  %1553 = add i64 %401, 72
  store i64 %1553, i64* %PC, align 8
  %1554 = inttoptr i64 %1552 to i64*
  %1555 = load i64, i64* %1554, align 8
  store i64 %1555, i64* %RAX, align 8, !tbaa !2428
  %1556 = add i64 %1551, -100
  %1557 = add i64 %401, 76
  store i64 %1557, i64* %PC, align 8
  %1558 = inttoptr i64 %1556 to i32*
  %1559 = load i32, i32* %1558, align 4
  %1560 = sext i32 %1559 to i64
  %1561 = mul nsw i64 %1560, 520
  store i64 %1561, i64* %RCX, align 8, !tbaa !2428
  %1562 = lshr i64 %1561, 63
  %1563 = add i64 %1561, %1555
  store i64 %1563, i64* %RAX, align 8, !tbaa !2428
  %1564 = icmp ult i64 %1563, %1555
  %1565 = icmp ult i64 %1563, %1561
  %1566 = or i1 %1564, %1565
  %1567 = zext i1 %1566 to i8
  store i8 %1567, i8* %42, align 1, !tbaa !2432
  %1568 = trunc i64 %1563 to i32
  %1569 = and i32 %1568, 255
  %1570 = tail call i32 @llvm.ctpop.i32(i32 %1569) #8
  %1571 = trunc i32 %1570 to i8
  %1572 = and i8 %1571, 1
  %1573 = xor i8 %1572, 1
  store i8 %1573, i8* %49, align 1, !tbaa !2446
  %1574 = xor i64 %1561, %1555
  %1575 = xor i64 %1574, %1563
  %1576 = lshr i64 %1575, 4
  %1577 = trunc i64 %1576 to i8
  %1578 = and i8 %1577, 1
  store i8 %1578, i8* %54, align 1, !tbaa !2447
  %1579 = icmp eq i64 %1563, 0
  %1580 = zext i1 %1579 to i8
  store i8 %1580, i8* %57, align 1, !tbaa !2448
  %1581 = lshr i64 %1563, 63
  %1582 = trunc i64 %1581 to i8
  store i8 %1582, i8* %60, align 1, !tbaa !2449
  %1583 = lshr i64 %1555, 63
  %1584 = xor i64 %1581, %1583
  %1585 = xor i64 %1581, %1562
  %1586 = add nuw nsw i64 %1584, %1585
  %1587 = icmp eq i64 %1586, 2
  %1588 = zext i1 %1587 to i8
  store i8 %1588, i8* %66, align 1, !tbaa !2450
  %1589 = add i64 %1551, -52
  %1590 = add i64 %401, 90
  store i64 %1590, i64* %PC, align 8
  %1591 = inttoptr i64 %1589 to i32*
  %1592 = load i32, i32* %1591, align 4
  %1593 = sext i32 %1592 to i64
  store i64 %1593, i64* %RCX, align 8, !tbaa !2428
  %1594 = shl nsw i64 %1593, 3
  %1595 = add i64 %1594, %1563
  %1596 = add i64 %401, 95
  store i64 %1596, i64* %PC, align 8
  %1597 = inttoptr i64 %1595 to double*
  %1598 = load double, double* %1597, align 8
  %1599 = fadd double %1550, %1598
  store double %1599, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %1600 = add i64 %1551, 40
  %1601 = add i64 %401, 99
  store i64 %1601, i64* %PC, align 8
  %1602 = inttoptr i64 %1600 to i64*
  %1603 = load i64, i64* %1602, align 8
  store i64 %1603, i64* %RAX, align 8, !tbaa !2428
  %1604 = add i64 %401, 103
  store i64 %1604, i64* %PC, align 8
  %1605 = load i32, i32* %1558, align 4
  %1606 = sext i32 %1605 to i64
  %1607 = mul nsw i64 %1606, 33800
  store i64 %1607, i64* %RCX, align 8, !tbaa !2428
  %1608 = lshr i64 %1607, 63
  %1609 = add i64 %1607, %1603
  store i64 %1609, i64* %RAX, align 8, !tbaa !2428
  %1610 = icmp ult i64 %1609, %1603
  %1611 = icmp ult i64 %1609, %1607
  %1612 = or i1 %1610, %1611
  %1613 = zext i1 %1612 to i8
  store i8 %1613, i8* %42, align 1, !tbaa !2432
  %1614 = trunc i64 %1609 to i32
  %1615 = and i32 %1614, 255
  %1616 = tail call i32 @llvm.ctpop.i32(i32 %1615) #8
  %1617 = trunc i32 %1616 to i8
  %1618 = and i8 %1617, 1
  %1619 = xor i8 %1618, 1
  store i8 %1619, i8* %49, align 1, !tbaa !2446
  %1620 = xor i64 %1607, %1603
  %1621 = xor i64 %1620, %1609
  %1622 = lshr i64 %1621, 4
  %1623 = trunc i64 %1622 to i8
  %1624 = and i8 %1623, 1
  store i8 %1624, i8* %54, align 1, !tbaa !2447
  %1625 = icmp eq i64 %1609, 0
  %1626 = zext i1 %1625 to i8
  store i8 %1626, i8* %57, align 1, !tbaa !2448
  %1627 = lshr i64 %1609, 63
  %1628 = trunc i64 %1627 to i8
  store i8 %1628, i8* %60, align 1, !tbaa !2449
  %1629 = lshr i64 %1603, 63
  %1630 = xor i64 %1627, %1629
  %1631 = xor i64 %1627, %1608
  %1632 = add nuw nsw i64 %1630, %1631
  %1633 = icmp eq i64 %1632, 2
  %1634 = zext i1 %1633 to i8
  store i8 %1634, i8* %66, align 1, !tbaa !2450
  %1635 = load i64, i64* %RBP, align 8
  %1636 = add i64 %1635, -52
  %1637 = add i64 %401, 117
  store i64 %1637, i64* %PC, align 8
  %1638 = inttoptr i64 %1636 to i32*
  %1639 = load i32, i32* %1638, align 4
  %1640 = sext i32 %1639 to i64
  %1641 = mul nsw i64 %1640, 520
  store i64 %1641, i64* %RCX, align 8, !tbaa !2428
  %1642 = lshr i64 %1641, 63
  %1643 = add i64 %1641, %1609
  store i64 %1643, i64* %RAX, align 8, !tbaa !2428
  %1644 = icmp ult i64 %1643, %1609
  %1645 = icmp ult i64 %1643, %1641
  %1646 = or i1 %1644, %1645
  %1647 = zext i1 %1646 to i8
  store i8 %1647, i8* %42, align 1, !tbaa !2432
  %1648 = trunc i64 %1643 to i32
  %1649 = and i32 %1648, 255
  %1650 = tail call i32 @llvm.ctpop.i32(i32 %1649) #8
  %1651 = trunc i32 %1650 to i8
  %1652 = and i8 %1651, 1
  %1653 = xor i8 %1652, 1
  store i8 %1653, i8* %49, align 1, !tbaa !2446
  %1654 = xor i64 %1641, %1609
  %1655 = xor i64 %1654, %1643
  %1656 = lshr i64 %1655, 4
  %1657 = trunc i64 %1656 to i8
  %1658 = and i8 %1657, 1
  store i8 %1658, i8* %54, align 1, !tbaa !2447
  %1659 = icmp eq i64 %1643, 0
  %1660 = zext i1 %1659 to i8
  store i8 %1660, i8* %57, align 1, !tbaa !2448
  %1661 = lshr i64 %1643, 63
  %1662 = trunc i64 %1661 to i8
  store i8 %1662, i8* %60, align 1, !tbaa !2449
  %1663 = xor i64 %1661, %1627
  %1664 = xor i64 %1661, %1642
  %1665 = add nuw nsw i64 %1663, %1664
  %1666 = icmp eq i64 %1665, 2
  %1667 = zext i1 %1666 to i8
  store i8 %1667, i8* %66, align 1, !tbaa !2450
  %1668 = add i64 %1635, -48
  %1669 = add i64 %401, 131
  store i64 %1669, i64* %PC, align 8
  %1670 = inttoptr i64 %1668 to i32*
  %1671 = load i32, i32* %1670, align 4
  %1672 = sext i32 %1671 to i64
  store i64 %1672, i64* %RCX, align 8, !tbaa !2428
  %1673 = shl nsw i64 %1672, 3
  %1674 = add i64 %1673, %1643
  %1675 = add i64 %401, 136
  store i64 %1675, i64* %PC, align 8
  %1676 = load double, double* %228, align 1
  %1677 = inttoptr i64 %1674 to double*
  %1678 = load double, double* %1677, align 8
  %1679 = fsub double %1676, %1678
  store double %1679, double* %228, align 1, !tbaa !2452
  %1680 = add i64 %1635, -96
  %1681 = add i64 %401, 140
  store i64 %1681, i64* %PC, align 8
  %1682 = inttoptr i64 %1680 to i64*
  %1683 = load i64, i64* %1682, align 8
  store i64 %1683, i64* %RAX, align 8, !tbaa !2428
  %1684 = add i64 %1635, -100
  %1685 = add i64 %401, 144
  store i64 %1685, i64* %PC, align 8
  %1686 = inttoptr i64 %1684 to i32*
  %1687 = load i32, i32* %1686, align 4
  %1688 = sext i32 %1687 to i64
  %1689 = mul nsw i64 %1688, 520
  store i64 %1689, i64* %RCX, align 8, !tbaa !2428
  %1690 = lshr i64 %1689, 63
  %1691 = add i64 %1689, %1683
  store i64 %1691, i64* %RAX, align 8, !tbaa !2428
  %1692 = icmp ult i64 %1691, %1683
  %1693 = icmp ult i64 %1691, %1689
  %1694 = or i1 %1692, %1693
  %1695 = zext i1 %1694 to i8
  store i8 %1695, i8* %42, align 1, !tbaa !2432
  %1696 = trunc i64 %1691 to i32
  %1697 = and i32 %1696, 255
  %1698 = tail call i32 @llvm.ctpop.i32(i32 %1697) #8
  %1699 = trunc i32 %1698 to i8
  %1700 = and i8 %1699, 1
  %1701 = xor i8 %1700, 1
  store i8 %1701, i8* %49, align 1, !tbaa !2446
  %1702 = xor i64 %1689, %1683
  %1703 = xor i64 %1702, %1691
  %1704 = lshr i64 %1703, 4
  %1705 = trunc i64 %1704 to i8
  %1706 = and i8 %1705, 1
  store i8 %1706, i8* %54, align 1, !tbaa !2447
  %1707 = icmp eq i64 %1691, 0
  %1708 = zext i1 %1707 to i8
  store i8 %1708, i8* %57, align 1, !tbaa !2448
  %1709 = lshr i64 %1691, 63
  %1710 = trunc i64 %1709 to i8
  store i8 %1710, i8* %60, align 1, !tbaa !2449
  %1711 = lshr i64 %1683, 63
  %1712 = xor i64 %1709, %1711
  %1713 = xor i64 %1709, %1690
  %1714 = add nuw nsw i64 %1712, %1713
  %1715 = icmp eq i64 %1714, 2
  %1716 = zext i1 %1715 to i8
  store i8 %1716, i8* %66, align 1, !tbaa !2450
  %1717 = load i64, i64* %RBP, align 8
  %1718 = add i64 %1717, -104
  %1719 = add i64 %401, 158
  store i64 %1719, i64* %PC, align 8
  %1720 = inttoptr i64 %1718 to i32*
  %1721 = load i32, i32* %1720, align 4
  %1722 = sext i32 %1721 to i64
  store i64 %1722, i64* %RCX, align 8, !tbaa !2428
  %1723 = shl nsw i64 %1722, 3
  %1724 = add i64 %1723, %1691
  %1725 = add i64 %401, 163
  store i64 %1725, i64* %PC, align 8
  %1726 = inttoptr i64 %1724 to double*
  store double %1679, double* %1726, align 8
  %1727 = load i64, i64* %RBP, align 8
  %1728 = add i64 %1727, 88
  %1729 = load i64, i64* %PC, align 8
  %1730 = add i64 %1729, 4
  store i64 %1730, i64* %PC, align 8
  %1731 = inttoptr i64 %1728 to i64*
  %1732 = load i64, i64* %1731, align 8
  store i64 %1732, i64* %RAX, align 8, !tbaa !2428
  %1733 = add i64 %1727, -52
  %1734 = add i64 %1729, 8
  store i64 %1734, i64* %PC, align 8
  %1735 = inttoptr i64 %1733 to i32*
  %1736 = load i32, i32* %1735, align 4
  %1737 = sext i32 %1736 to i64
  store i64 %1737, i64* %RCX, align 8, !tbaa !2428
  %1738 = shl nsw i64 %1737, 3
  %1739 = add i64 %1738, %1732
  %1740 = add i64 %1729, 13
  store i64 %1740, i64* %PC, align 8
  %1741 = inttoptr i64 %1739 to double*
  %1742 = load double, double* %1741, align 8
  store double %1742, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %1743 = add i64 %1727, 96
  %1744 = add i64 %1729, 17
  store i64 %1744, i64* %PC, align 8
  %1745 = inttoptr i64 %1743 to i64*
  %1746 = load i64, i64* %1745, align 8
  store i64 %1746, i64* %RAX, align 8, !tbaa !2428
  %1747 = add i64 %1729, 21
  store i64 %1747, i64* %PC, align 8
  %1748 = load i32, i32* %1735, align 4
  %1749 = sext i32 %1748 to i64
  store i64 %1749, i64* %RCX, align 8, !tbaa !2428
  %1750 = shl nsw i64 %1749, 3
  %1751 = add i64 %1750, %1746
  %1752 = add i64 %1729, 26
  store i64 %1752, i64* %PC, align 8
  %1753 = inttoptr i64 %1751 to double*
  %1754 = load double, double* %1753, align 8
  %1755 = fdiv double %1742, %1754
  store double %1755, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %1756 = add i64 %1727, 24
  %1757 = add i64 %1729, 30
  store i64 %1757, i64* %PC, align 8
  %1758 = inttoptr i64 %1756 to i64*
  %1759 = load i64, i64* %1758, align 8
  store i64 %1759, i64* %RAX, align 8, !tbaa !2428
  %1760 = add i64 %1727, -100
  %1761 = add i64 %1729, 34
  store i64 %1761, i64* %PC, align 8
  %1762 = inttoptr i64 %1760 to i32*
  %1763 = load i32, i32* %1762, align 4
  %1764 = sext i32 %1763 to i64
  %1765 = mul nsw i64 %1764, 33800
  store i64 %1765, i64* %RCX, align 8, !tbaa !2428
  %1766 = lshr i64 %1765, 63
  %1767 = add i64 %1765, %1759
  store i64 %1767, i64* %RAX, align 8, !tbaa !2428
  %1768 = icmp ult i64 %1767, %1759
  %1769 = icmp ult i64 %1767, %1765
  %1770 = or i1 %1768, %1769
  %1771 = zext i1 %1770 to i8
  store i8 %1771, i8* %42, align 1, !tbaa !2432
  %1772 = trunc i64 %1767 to i32
  %1773 = and i32 %1772, 255
  %1774 = tail call i32 @llvm.ctpop.i32(i32 %1773) #8
  %1775 = trunc i32 %1774 to i8
  %1776 = and i8 %1775, 1
  %1777 = xor i8 %1776, 1
  store i8 %1777, i8* %49, align 1, !tbaa !2446
  %1778 = xor i64 %1765, %1759
  %1779 = xor i64 %1778, %1767
  %1780 = lshr i64 %1779, 4
  %1781 = trunc i64 %1780 to i8
  %1782 = and i8 %1781, 1
  store i8 %1782, i8* %54, align 1, !tbaa !2447
  %1783 = icmp eq i64 %1767, 0
  %1784 = zext i1 %1783 to i8
  store i8 %1784, i8* %57, align 1, !tbaa !2448
  %1785 = lshr i64 %1767, 63
  %1786 = trunc i64 %1785 to i8
  store i8 %1786, i8* %60, align 1, !tbaa !2449
  %1787 = lshr i64 %1759, 63
  %1788 = xor i64 %1785, %1787
  %1789 = xor i64 %1785, %1766
  %1790 = add nuw nsw i64 %1788, %1789
  %1791 = icmp eq i64 %1790, 2
  %1792 = zext i1 %1791 to i8
  store i8 %1792, i8* %66, align 1, !tbaa !2450
  %1793 = load i64, i64* %RBP, align 8
  %1794 = add i64 %1793, -52
  %1795 = add i64 %1729, 48
  store i64 %1795, i64* %PC, align 8
  %1796 = inttoptr i64 %1794 to i32*
  %1797 = load i32, i32* %1796, align 4
  %1798 = sext i32 %1797 to i64
  %1799 = mul nsw i64 %1798, 520
  store i64 %1799, i64* %RCX, align 8, !tbaa !2428
  %1800 = lshr i64 %1799, 63
  %1801 = add i64 %1799, %1767
  store i64 %1801, i64* %RAX, align 8, !tbaa !2428
  %1802 = icmp ult i64 %1801, %1767
  %1803 = icmp ult i64 %1801, %1799
  %1804 = or i1 %1802, %1803
  %1805 = zext i1 %1804 to i8
  store i8 %1805, i8* %42, align 1, !tbaa !2432
  %1806 = trunc i64 %1801 to i32
  %1807 = and i32 %1806, 255
  %1808 = tail call i32 @llvm.ctpop.i32(i32 %1807) #8
  %1809 = trunc i32 %1808 to i8
  %1810 = and i8 %1809, 1
  %1811 = xor i8 %1810, 1
  store i8 %1811, i8* %49, align 1, !tbaa !2446
  %1812 = xor i64 %1799, %1767
  %1813 = xor i64 %1812, %1801
  %1814 = lshr i64 %1813, 4
  %1815 = trunc i64 %1814 to i8
  %1816 = and i8 %1815, 1
  store i8 %1816, i8* %54, align 1, !tbaa !2447
  %1817 = icmp eq i64 %1801, 0
  %1818 = zext i1 %1817 to i8
  store i8 %1818, i8* %57, align 1, !tbaa !2448
  %1819 = lshr i64 %1801, 63
  %1820 = trunc i64 %1819 to i8
  store i8 %1820, i8* %60, align 1, !tbaa !2449
  %1821 = xor i64 %1819, %1785
  %1822 = xor i64 %1819, %1800
  %1823 = add nuw nsw i64 %1821, %1822
  %1824 = icmp eq i64 %1823, 2
  %1825 = zext i1 %1824 to i8
  store i8 %1825, i8* %66, align 1, !tbaa !2450
  %1826 = add i64 %1793, -48
  %1827 = add i64 %1729, 62
  store i64 %1827, i64* %PC, align 8
  %1828 = inttoptr i64 %1826 to i32*
  %1829 = load i32, i32* %1828, align 4
  %1830 = sext i32 %1829 to i64
  store i64 %1830, i64* %RCX, align 8, !tbaa !2428
  %1831 = shl nsw i64 %1830, 3
  %1832 = add i64 %1831, %1801
  %1833 = add i64 %1729, 67
  store i64 %1833, i64* %PC, align 8
  %1834 = load double, double* %228, align 1
  %1835 = inttoptr i64 %1832 to double*
  %1836 = load double, double* %1835, align 8
  %1837 = fmul double %1834, %1836
  store double %1837, double* %228, align 1, !tbaa !2452
  %1838 = add i64 %1793, -72
  %1839 = add i64 %1729, 72
  store i64 %1839, i64* %PC, align 8
  %1840 = inttoptr i64 %1838 to double*
  %1841 = load double, double* %1840, align 8
  store double %1841, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %1842 = add i64 %1793, 96
  %1843 = add i64 %1729, 76
  store i64 %1843, i64* %PC, align 8
  %1844 = inttoptr i64 %1842 to i64*
  %1845 = load i64, i64* %1844, align 8
  store i64 %1845, i64* %RAX, align 8, !tbaa !2428
  %1846 = add i64 %1729, 80
  store i64 %1846, i64* %PC, align 8
  %1847 = load i32, i32* %1796, align 4
  %1848 = sext i32 %1847 to i64
  store i64 %1848, i64* %RCX, align 8, !tbaa !2428
  %1849 = shl nsw i64 %1848, 3
  %1850 = add i64 %1849, %1845
  %1851 = add i64 %1729, 85
  store i64 %1851, i64* %PC, align 8
  %1852 = inttoptr i64 %1850 to double*
  %1853 = load double, double* %1852, align 8
  %1854 = fdiv double %1841, %1853
  store double %1854, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %1855 = load i64, i64* %RBP, align 8
  %1856 = add i64 %1855, -96
  %1857 = add i64 %1729, 89
  store i64 %1857, i64* %PC, align 8
  %1858 = inttoptr i64 %1856 to i64*
  %1859 = load i64, i64* %1858, align 8
  store i64 %1859, i64* %RAX, align 8, !tbaa !2428
  %1860 = add i64 %1855, -100
  %1861 = add i64 %1729, 93
  store i64 %1861, i64* %PC, align 8
  %1862 = inttoptr i64 %1860 to i32*
  %1863 = load i32, i32* %1862, align 4
  %1864 = sext i32 %1863 to i64
  %1865 = mul nsw i64 %1864, 520
  store i64 %1865, i64* %RCX, align 8, !tbaa !2428
  %1866 = lshr i64 %1865, 63
  %1867 = add i64 %1865, %1859
  store i64 %1867, i64* %RAX, align 8, !tbaa !2428
  %1868 = icmp ult i64 %1867, %1859
  %1869 = icmp ult i64 %1867, %1865
  %1870 = or i1 %1868, %1869
  %1871 = zext i1 %1870 to i8
  store i8 %1871, i8* %42, align 1, !tbaa !2432
  %1872 = trunc i64 %1867 to i32
  %1873 = and i32 %1872, 255
  %1874 = tail call i32 @llvm.ctpop.i32(i32 %1873) #8
  %1875 = trunc i32 %1874 to i8
  %1876 = and i8 %1875, 1
  %1877 = xor i8 %1876, 1
  store i8 %1877, i8* %49, align 1, !tbaa !2446
  %1878 = xor i64 %1865, %1859
  %1879 = xor i64 %1878, %1867
  %1880 = lshr i64 %1879, 4
  %1881 = trunc i64 %1880 to i8
  %1882 = and i8 %1881, 1
  store i8 %1882, i8* %54, align 1, !tbaa !2447
  %1883 = icmp eq i64 %1867, 0
  %1884 = zext i1 %1883 to i8
  store i8 %1884, i8* %57, align 1, !tbaa !2448
  %1885 = lshr i64 %1867, 63
  %1886 = trunc i64 %1885 to i8
  store i8 %1886, i8* %60, align 1, !tbaa !2449
  %1887 = lshr i64 %1859, 63
  %1888 = xor i64 %1885, %1887
  %1889 = xor i64 %1885, %1866
  %1890 = add nuw nsw i64 %1888, %1889
  %1891 = icmp eq i64 %1890, 2
  %1892 = zext i1 %1891 to i8
  store i8 %1892, i8* %66, align 1, !tbaa !2450
  %1893 = add i64 %1855, -104
  %1894 = add i64 %1729, 107
  store i64 %1894, i64* %PC, align 8
  %1895 = inttoptr i64 %1893 to i32*
  %1896 = load i32, i32* %1895, align 4
  %1897 = sext i32 %1896 to i64
  store i64 %1897, i64* %RCX, align 8, !tbaa !2428
  %1898 = shl nsw i64 %1897, 3
  %1899 = add i64 %1898, %1867
  %1900 = add i64 %1729, 112
  store i64 %1900, i64* %PC, align 8
  %1901 = inttoptr i64 %1899 to double*
  %1902 = load double, double* %1901, align 8
  %1903 = fmul double %1854, %1902
  store double %1903, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %1904 = load double, double* %228, align 1
  %1905 = fsub double %1904, %1903
  store double %1905, double* %228, align 1, !tbaa !2452
  %1906 = add i64 %1855, 16
  %1907 = add i64 %1729, 120
  store i64 %1907, i64* %PC, align 8
  %1908 = inttoptr i64 %1906 to i64*
  %1909 = load i64, i64* %1908, align 8
  store i64 %1909, i64* %RAX, align 8, !tbaa !2428
  %1910 = load i64, i64* %RBP, align 8
  %1911 = add i64 %1910, -100
  %1912 = add i64 %1729, 124
  store i64 %1912, i64* %PC, align 8
  %1913 = inttoptr i64 %1911 to i32*
  %1914 = load i32, i32* %1913, align 4
  %1915 = sext i32 %1914 to i64
  %1916 = mul nsw i64 %1915, 520
  store i64 %1916, i64* %RCX, align 8, !tbaa !2428
  %1917 = lshr i64 %1916, 63
  %1918 = add i64 %1916, %1909
  store i64 %1918, i64* %RAX, align 8, !tbaa !2428
  %1919 = icmp ult i64 %1918, %1909
  %1920 = icmp ult i64 %1918, %1916
  %1921 = or i1 %1919, %1920
  %1922 = zext i1 %1921 to i8
  store i8 %1922, i8* %42, align 1, !tbaa !2432
  %1923 = trunc i64 %1918 to i32
  %1924 = and i32 %1923, 255
  %1925 = tail call i32 @llvm.ctpop.i32(i32 %1924) #8
  %1926 = trunc i32 %1925 to i8
  %1927 = and i8 %1926, 1
  %1928 = xor i8 %1927, 1
  store i8 %1928, i8* %49, align 1, !tbaa !2446
  %1929 = xor i64 %1916, %1909
  %1930 = xor i64 %1929, %1918
  %1931 = lshr i64 %1930, 4
  %1932 = trunc i64 %1931 to i8
  %1933 = and i8 %1932, 1
  store i8 %1933, i8* %54, align 1, !tbaa !2447
  %1934 = icmp eq i64 %1918, 0
  %1935 = zext i1 %1934 to i8
  store i8 %1935, i8* %57, align 1, !tbaa !2448
  %1936 = lshr i64 %1918, 63
  %1937 = trunc i64 %1936 to i8
  store i8 %1937, i8* %60, align 1, !tbaa !2449
  %1938 = lshr i64 %1909, 63
  %1939 = xor i64 %1936, %1938
  %1940 = xor i64 %1936, %1917
  %1941 = add nuw nsw i64 %1939, %1940
  %1942 = icmp eq i64 %1941, 2
  %1943 = zext i1 %1942 to i8
  store i8 %1943, i8* %66, align 1, !tbaa !2450
  %1944 = add i64 %1910, -104
  %1945 = add i64 %1729, 138
  store i64 %1945, i64* %PC, align 8
  %1946 = inttoptr i64 %1944 to i32*
  %1947 = load i32, i32* %1946, align 4
  %1948 = sext i32 %1947 to i64
  store i64 %1948, i64* %RCX, align 8, !tbaa !2428
  %1949 = shl nsw i64 %1948, 3
  %1950 = add i64 %1949, %1918
  %1951 = add i64 %1729, 143
  store i64 %1951, i64* %PC, align 8
  %1952 = inttoptr i64 %1950 to double*
  store double %1905, double* %1952, align 8
  %1953 = load i64, i64* %RBP, align 8
  %1954 = add i64 %1953, 72
  %1955 = load i64, i64* %PC, align 8
  %1956 = add i64 %1955, 4
  store i64 %1956, i64* %PC, align 8
  %1957 = inttoptr i64 %1954 to i64*
  %1958 = load i64, i64* %1957, align 8
  store i64 %1958, i64* %RAX, align 8, !tbaa !2428
  %1959 = add i64 %1953, -48
  %1960 = add i64 %1955, 8
  store i64 %1960, i64* %PC, align 8
  %1961 = inttoptr i64 %1959 to i32*
  %1962 = load i32, i32* %1961, align 4
  %1963 = sext i32 %1962 to i64
  store i64 %1963, i64* %RCX, align 8, !tbaa !2428
  %1964 = shl nsw i64 %1963, 3
  %1965 = add i64 %1964, %1958
  %1966 = add i64 %1955, 13
  store i64 %1966, i64* %PC, align 8
  %1967 = inttoptr i64 %1965 to double*
  %1968 = load double, double* %1967, align 8
  store double %1968, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %1969 = add i64 %1953, 80
  %1970 = add i64 %1955, 17
  store i64 %1970, i64* %PC, align 8
  %1971 = inttoptr i64 %1969 to i64*
  %1972 = load i64, i64* %1971, align 8
  store i64 %1972, i64* %RAX, align 8, !tbaa !2428
  %1973 = add i64 %1955, 21
  store i64 %1973, i64* %PC, align 8
  %1974 = load i32, i32* %1961, align 4
  %1975 = sext i32 %1974 to i64
  store i64 %1975, i64* %RCX, align 8, !tbaa !2428
  %1976 = shl nsw i64 %1975, 3
  %1977 = add i64 %1976, %1972
  %1978 = add i64 %1955, 26
  store i64 %1978, i64* %PC, align 8
  %1979 = inttoptr i64 %1977 to double*
  %1980 = load double, double* %1979, align 8
  %1981 = fdiv double %1968, %1980
  store double %1981, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %1982 = add i64 %1953, 48
  %1983 = add i64 %1955, 30
  store i64 %1983, i64* %PC, align 8
  %1984 = inttoptr i64 %1982 to i64*
  %1985 = load i64, i64* %1984, align 8
  store i64 %1985, i64* %RAX, align 8, !tbaa !2428
  %1986 = add i64 %1953, -100
  %1987 = add i64 %1955, 34
  store i64 %1987, i64* %PC, align 8
  %1988 = inttoptr i64 %1986 to i32*
  %1989 = load i32, i32* %1988, align 4
  %1990 = sext i32 %1989 to i64
  %1991 = mul nsw i64 %1990, 33800
  store i64 %1991, i64* %RCX, align 8, !tbaa !2428
  %1992 = lshr i64 %1991, 63
  %1993 = add i64 %1991, %1985
  store i64 %1993, i64* %RAX, align 8, !tbaa !2428
  %1994 = icmp ult i64 %1993, %1985
  %1995 = icmp ult i64 %1993, %1991
  %1996 = or i1 %1994, %1995
  %1997 = zext i1 %1996 to i8
  store i8 %1997, i8* %42, align 1, !tbaa !2432
  %1998 = trunc i64 %1993 to i32
  %1999 = and i32 %1998, 255
  %2000 = tail call i32 @llvm.ctpop.i32(i32 %1999) #8
  %2001 = trunc i32 %2000 to i8
  %2002 = and i8 %2001, 1
  %2003 = xor i8 %2002, 1
  store i8 %2003, i8* %49, align 1, !tbaa !2446
  %2004 = xor i64 %1991, %1985
  %2005 = xor i64 %2004, %1993
  %2006 = lshr i64 %2005, 4
  %2007 = trunc i64 %2006 to i8
  %2008 = and i8 %2007, 1
  store i8 %2008, i8* %54, align 1, !tbaa !2447
  %2009 = icmp eq i64 %1993, 0
  %2010 = zext i1 %2009 to i8
  store i8 %2010, i8* %57, align 1, !tbaa !2448
  %2011 = lshr i64 %1993, 63
  %2012 = trunc i64 %2011 to i8
  store i8 %2012, i8* %60, align 1, !tbaa !2449
  %2013 = lshr i64 %1985, 63
  %2014 = xor i64 %2011, %2013
  %2015 = xor i64 %2011, %1992
  %2016 = add nuw nsw i64 %2014, %2015
  %2017 = icmp eq i64 %2016, 2
  %2018 = zext i1 %2017 to i8
  store i8 %2018, i8* %66, align 1, !tbaa !2450
  %2019 = load i64, i64* %RBP, align 8
  %2020 = add i64 %2019, -52
  %2021 = add i64 %1955, 48
  store i64 %2021, i64* %PC, align 8
  %2022 = inttoptr i64 %2020 to i32*
  %2023 = load i32, i32* %2022, align 4
  %2024 = sext i32 %2023 to i64
  %2025 = mul nsw i64 %2024, 520
  store i64 %2025, i64* %RCX, align 8, !tbaa !2428
  %2026 = lshr i64 %2025, 63
  %2027 = add i64 %2025, %1993
  store i64 %2027, i64* %RAX, align 8, !tbaa !2428
  %2028 = icmp ult i64 %2027, %1993
  %2029 = icmp ult i64 %2027, %2025
  %2030 = or i1 %2028, %2029
  %2031 = zext i1 %2030 to i8
  store i8 %2031, i8* %42, align 1, !tbaa !2432
  %2032 = trunc i64 %2027 to i32
  %2033 = and i32 %2032, 255
  %2034 = tail call i32 @llvm.ctpop.i32(i32 %2033) #8
  %2035 = trunc i32 %2034 to i8
  %2036 = and i8 %2035, 1
  %2037 = xor i8 %2036, 1
  store i8 %2037, i8* %49, align 1, !tbaa !2446
  %2038 = xor i64 %2025, %1993
  %2039 = xor i64 %2038, %2027
  %2040 = lshr i64 %2039, 4
  %2041 = trunc i64 %2040 to i8
  %2042 = and i8 %2041, 1
  store i8 %2042, i8* %54, align 1, !tbaa !2447
  %2043 = icmp eq i64 %2027, 0
  %2044 = zext i1 %2043 to i8
  store i8 %2044, i8* %57, align 1, !tbaa !2448
  %2045 = lshr i64 %2027, 63
  %2046 = trunc i64 %2045 to i8
  store i8 %2046, i8* %60, align 1, !tbaa !2449
  %2047 = xor i64 %2045, %2011
  %2048 = xor i64 %2045, %2026
  %2049 = add nuw nsw i64 %2047, %2048
  %2050 = icmp eq i64 %2049, 2
  %2051 = zext i1 %2050 to i8
  store i8 %2051, i8* %66, align 1, !tbaa !2450
  %2052 = add i64 %2019, -48
  %2053 = add i64 %1955, 62
  store i64 %2053, i64* %PC, align 8
  %2054 = inttoptr i64 %2052 to i32*
  %2055 = load i32, i32* %2054, align 4
  %2056 = sext i32 %2055 to i64
  store i64 %2056, i64* %RCX, align 8, !tbaa !2428
  %2057 = shl nsw i64 %2056, 3
  %2058 = add i64 %2057, %2027
  %2059 = add i64 %1955, 67
  store i64 %2059, i64* %PC, align 8
  %2060 = load double, double* %228, align 1
  %2061 = inttoptr i64 %2058 to double*
  %2062 = load double, double* %2061, align 8
  %2063 = fmul double %2060, %2062
  store double %2063, double* %228, align 1, !tbaa !2452
  %2064 = add i64 %2019, -64
  %2065 = add i64 %1955, 72
  store i64 %2065, i64* %PC, align 8
  %2066 = inttoptr i64 %2064 to double*
  %2067 = load double, double* %2066, align 8
  store double %2067, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %2068 = add i64 %2019, 64
  %2069 = add i64 %1955, 76
  store i64 %2069, i64* %PC, align 8
  %2070 = inttoptr i64 %2068 to i64*
  %2071 = load i64, i64* %2070, align 8
  store i64 %2071, i64* %RAX, align 8, !tbaa !2428
  %2072 = add i64 %2019, -100
  %2073 = add i64 %1955, 80
  store i64 %2073, i64* %PC, align 8
  %2074 = inttoptr i64 %2072 to i32*
  %2075 = load i32, i32* %2074, align 4
  %2076 = sext i32 %2075 to i64
  store i64 %2076, i64* %RCX, align 8, !tbaa !2428
  %2077 = shl nsw i64 %2076, 3
  %2078 = add i64 %2077, %2071
  %2079 = add i64 %1955, 85
  store i64 %2079, i64* %PC, align 8
  %2080 = inttoptr i64 %2078 to double*
  %2081 = load double, double* %2080, align 8
  %2082 = fmul double %2067, %2081
  store double %2082, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %2083 = load i64, i64* %RBP, align 8
  %2084 = add i64 %2083, 80
  %2085 = add i64 %1955, 89
  store i64 %2085, i64* %PC, align 8
  %2086 = inttoptr i64 %2084 to i64*
  %2087 = load i64, i64* %2086, align 8
  store i64 %2087, i64* %RAX, align 8, !tbaa !2428
  %2088 = add i64 %2083, -48
  %2089 = add i64 %1955, 93
  store i64 %2089, i64* %PC, align 8
  %2090 = inttoptr i64 %2088 to i32*
  %2091 = load i32, i32* %2090, align 4
  %2092 = sext i32 %2091 to i64
  store i64 %2092, i64* %RCX, align 8, !tbaa !2428
  %2093 = shl nsw i64 %2092, 3
  %2094 = add i64 %2093, %2087
  %2095 = add i64 %1955, 98
  store i64 %2095, i64* %PC, align 8
  %2096 = inttoptr i64 %2094 to double*
  %2097 = load double, double* %2096, align 8
  %2098 = fdiv double %2082, %2097
  store double %2098, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %2099 = add i64 %2083, 16
  %2100 = add i64 %1955, 102
  store i64 %2100, i64* %PC, align 8
  %2101 = inttoptr i64 %2099 to i64*
  %2102 = load i64, i64* %2101, align 8
  store i64 %2102, i64* %RAX, align 8, !tbaa !2428
  %2103 = add i64 %2083, -100
  %2104 = add i64 %1955, 106
  store i64 %2104, i64* %PC, align 8
  %2105 = inttoptr i64 %2103 to i32*
  %2106 = load i32, i32* %2105, align 4
  %2107 = sext i32 %2106 to i64
  %2108 = mul nsw i64 %2107, 520
  store i64 %2108, i64* %RCX, align 8, !tbaa !2428
  %2109 = lshr i64 %2108, 63
  %2110 = add i64 %2108, %2102
  store i64 %2110, i64* %RAX, align 8, !tbaa !2428
  %2111 = icmp ult i64 %2110, %2102
  %2112 = icmp ult i64 %2110, %2108
  %2113 = or i1 %2111, %2112
  %2114 = zext i1 %2113 to i8
  store i8 %2114, i8* %42, align 1, !tbaa !2432
  %2115 = trunc i64 %2110 to i32
  %2116 = and i32 %2115, 255
  %2117 = tail call i32 @llvm.ctpop.i32(i32 %2116) #8
  %2118 = trunc i32 %2117 to i8
  %2119 = and i8 %2118, 1
  %2120 = xor i8 %2119, 1
  store i8 %2120, i8* %49, align 1, !tbaa !2446
  %2121 = xor i64 %2108, %2102
  %2122 = xor i64 %2121, %2110
  %2123 = lshr i64 %2122, 4
  %2124 = trunc i64 %2123 to i8
  %2125 = and i8 %2124, 1
  store i8 %2125, i8* %54, align 1, !tbaa !2447
  %2126 = icmp eq i64 %2110, 0
  %2127 = zext i1 %2126 to i8
  store i8 %2127, i8* %57, align 1, !tbaa !2448
  %2128 = lshr i64 %2110, 63
  %2129 = trunc i64 %2128 to i8
  store i8 %2129, i8* %60, align 1, !tbaa !2449
  %2130 = lshr i64 %2102, 63
  %2131 = xor i64 %2128, %2130
  %2132 = xor i64 %2128, %2109
  %2133 = add nuw nsw i64 %2131, %2132
  %2134 = icmp eq i64 %2133, 2
  %2135 = zext i1 %2134 to i8
  store i8 %2135, i8* %66, align 1, !tbaa !2450
  %2136 = add i64 %2083, -104
  %2137 = add i64 %1955, 120
  store i64 %2137, i64* %PC, align 8
  %2138 = inttoptr i64 %2136 to i32*
  %2139 = load i32, i32* %2138, align 4
  %2140 = sext i32 %2139 to i64
  store i64 %2140, i64* %RCX, align 8, !tbaa !2428
  %2141 = shl nsw i64 %2140, 3
  %2142 = add i64 %2141, %2110
  %2143 = add i64 %1955, 125
  store i64 %2143, i64* %PC, align 8
  %2144 = inttoptr i64 %2142 to double*
  %2145 = load double, double* %2144, align 8
  %2146 = fmul double %2098, %2145
  store double %2146, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %2147 = load double, double* %228, align 1
  %2148 = fadd double %2147, %2146
  store double %2148, double* %228, align 1, !tbaa !2452
  %2149 = load i64, i64* %RBP, align 8
  %2150 = add i64 %2149, -64
  %2151 = add i64 %1955, 134
  store i64 %2151, i64* %PC, align 8
  %2152 = inttoptr i64 %2150 to double*
  %2153 = load double, double* %2152, align 8
  store double %2153, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %2154 = add i64 %2149, 56
  %2155 = add i64 %1955, 138
  store i64 %2155, i64* %PC, align 8
  %2156 = inttoptr i64 %2154 to i64*
  %2157 = load i64, i64* %2156, align 8
  store i64 %2157, i64* %RAX, align 8, !tbaa !2428
  %2158 = add i64 %2149, -100
  %2159 = add i64 %1955, 142
  store i64 %2159, i64* %PC, align 8
  %2160 = inttoptr i64 %2158 to i32*
  %2161 = load i32, i32* %2160, align 4
  %2162 = sext i32 %2161 to i64
  store i64 %2162, i64* %RCX, align 8, !tbaa !2428
  %2163 = shl nsw i64 %2162, 3
  %2164 = add i64 %2163, %2157
  %2165 = add i64 %1955, 147
  store i64 %2165, i64* %PC, align 8
  %2166 = inttoptr i64 %2164 to double*
  %2167 = load double, double* %2166, align 8
  %2168 = fmul double %2153, %2167
  store double %2168, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %2169 = add i64 %2149, 80
  %2170 = add i64 %1955, 151
  store i64 %2170, i64* %PC, align 8
  %2171 = inttoptr i64 %2169 to i64*
  %2172 = load i64, i64* %2171, align 8
  store i64 %2172, i64* %RAX, align 8, !tbaa !2428
  %2173 = add i64 %2149, -48
  %2174 = add i64 %1955, 155
  store i64 %2174, i64* %PC, align 8
  %2175 = inttoptr i64 %2173 to i32*
  %2176 = load i32, i32* %2175, align 4
  %2177 = sext i32 %2176 to i64
  store i64 %2177, i64* %RCX, align 8, !tbaa !2428
  %2178 = shl nsw i64 %2177, 3
  %2179 = add i64 %2178, %2172
  %2180 = add i64 %1955, 160
  store i64 %2180, i64* %PC, align 8
  %2181 = inttoptr i64 %2179 to double*
  %2182 = load double, double* %2181, align 8
  %2183 = fdiv double %2168, %2182
  store double %2183, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %2184 = add i64 %2149, 24
  %2185 = add i64 %1955, 164
  store i64 %2185, i64* %PC, align 8
  %2186 = inttoptr i64 %2184 to i64*
  %2187 = load i64, i64* %2186, align 8
  store i64 %2187, i64* %RAX, align 8, !tbaa !2428
  %2188 = add i64 %1955, 168
  store i64 %2188, i64* %PC, align 8
  %2189 = load i32, i32* %2160, align 4
  %2190 = sext i32 %2189 to i64
  %2191 = mul nsw i64 %2190, 33800
  store i64 %2191, i64* %RCX, align 8, !tbaa !2428
  %2192 = lshr i64 %2191, 63
  %2193 = add i64 %2191, %2187
  store i64 %2193, i64* %RAX, align 8, !tbaa !2428
  %2194 = icmp ult i64 %2193, %2187
  %2195 = icmp ult i64 %2193, %2191
  %2196 = or i1 %2194, %2195
  %2197 = zext i1 %2196 to i8
  store i8 %2197, i8* %42, align 1, !tbaa !2432
  %2198 = trunc i64 %2193 to i32
  %2199 = and i32 %2198, 255
  %2200 = tail call i32 @llvm.ctpop.i32(i32 %2199) #8
  %2201 = trunc i32 %2200 to i8
  %2202 = and i8 %2201, 1
  %2203 = xor i8 %2202, 1
  store i8 %2203, i8* %49, align 1, !tbaa !2446
  %2204 = xor i64 %2191, %2187
  %2205 = xor i64 %2204, %2193
  %2206 = lshr i64 %2205, 4
  %2207 = trunc i64 %2206 to i8
  %2208 = and i8 %2207, 1
  store i8 %2208, i8* %54, align 1, !tbaa !2447
  %2209 = icmp eq i64 %2193, 0
  %2210 = zext i1 %2209 to i8
  store i8 %2210, i8* %57, align 1, !tbaa !2448
  %2211 = lshr i64 %2193, 63
  %2212 = trunc i64 %2211 to i8
  store i8 %2212, i8* %60, align 1, !tbaa !2449
  %2213 = lshr i64 %2187, 63
  %2214 = xor i64 %2211, %2213
  %2215 = xor i64 %2211, %2192
  %2216 = add nuw nsw i64 %2214, %2215
  %2217 = icmp eq i64 %2216, 2
  %2218 = zext i1 %2217 to i8
  store i8 %2218, i8* %66, align 1, !tbaa !2450
  %2219 = load i64, i64* %RBP, align 8
  %2220 = add i64 %2219, -52
  %2221 = add i64 %1955, 182
  store i64 %2221, i64* %PC, align 8
  %2222 = inttoptr i64 %2220 to i32*
  %2223 = load i32, i32* %2222, align 4
  %2224 = sext i32 %2223 to i64
  %2225 = mul nsw i64 %2224, 520
  store i64 %2225, i64* %RCX, align 8, !tbaa !2428
  %2226 = lshr i64 %2225, 63
  %2227 = add i64 %2225, %2193
  store i64 %2227, i64* %RAX, align 8, !tbaa !2428
  %2228 = icmp ult i64 %2227, %2193
  %2229 = icmp ult i64 %2227, %2225
  %2230 = or i1 %2228, %2229
  %2231 = zext i1 %2230 to i8
  store i8 %2231, i8* %42, align 1, !tbaa !2432
  %2232 = trunc i64 %2227 to i32
  %2233 = and i32 %2232, 255
  %2234 = tail call i32 @llvm.ctpop.i32(i32 %2233) #8
  %2235 = trunc i32 %2234 to i8
  %2236 = and i8 %2235, 1
  %2237 = xor i8 %2236, 1
  store i8 %2237, i8* %49, align 1, !tbaa !2446
  %2238 = xor i64 %2225, %2193
  %2239 = xor i64 %2238, %2227
  %2240 = lshr i64 %2239, 4
  %2241 = trunc i64 %2240 to i8
  %2242 = and i8 %2241, 1
  store i8 %2242, i8* %54, align 1, !tbaa !2447
  %2243 = icmp eq i64 %2227, 0
  %2244 = zext i1 %2243 to i8
  store i8 %2244, i8* %57, align 1, !tbaa !2448
  %2245 = lshr i64 %2227, 63
  %2246 = trunc i64 %2245 to i8
  store i8 %2246, i8* %60, align 1, !tbaa !2449
  %2247 = xor i64 %2245, %2211
  %2248 = xor i64 %2245, %2226
  %2249 = add nuw nsw i64 %2247, %2248
  %2250 = icmp eq i64 %2249, 2
  %2251 = zext i1 %2250 to i8
  store i8 %2251, i8* %66, align 1, !tbaa !2450
  %2252 = add i64 %2219, -48
  %2253 = add i64 %1955, 196
  store i64 %2253, i64* %PC, align 8
  %2254 = inttoptr i64 %2252 to i32*
  %2255 = load i32, i32* %2254, align 4
  %2256 = sext i32 %2255 to i64
  store i64 %2256, i64* %RCX, align 8, !tbaa !2428
  %2257 = shl nsw i64 %2256, 3
  %2258 = add i64 %2257, %2227
  %2259 = add i64 %1955, 201
  store i64 %2259, i64* %PC, align 8
  %2260 = load double, double* %231, align 1
  %2261 = inttoptr i64 %2258 to double*
  %2262 = load double, double* %2261, align 8
  %2263 = fmul double %2260, %2262
  store double %2263, double* %231, align 1, !tbaa !2452
  %2264 = load double, double* %228, align 1
  %2265 = fsub double %2264, %2263
  store double %2265, double* %228, align 1, !tbaa !2452
  %2266 = add i64 %2219, 48
  %2267 = add i64 %1955, 209
  store i64 %2267, i64* %PC, align 8
  %2268 = inttoptr i64 %2266 to i64*
  %2269 = load i64, i64* %2268, align 8
  store i64 %2269, i64* %RAX, align 8, !tbaa !2428
  %2270 = add i64 %2219, -100
  %2271 = add i64 %1955, 213
  store i64 %2271, i64* %PC, align 8
  %2272 = inttoptr i64 %2270 to i32*
  %2273 = load i32, i32* %2272, align 4
  %2274 = sext i32 %2273 to i64
  %2275 = mul nsw i64 %2274, 33800
  store i64 %2275, i64* %RCX, align 8, !tbaa !2428
  %2276 = lshr i64 %2275, 63
  %2277 = add i64 %2275, %2269
  store i64 %2277, i64* %RAX, align 8, !tbaa !2428
  %2278 = icmp ult i64 %2277, %2269
  %2279 = icmp ult i64 %2277, %2275
  %2280 = or i1 %2278, %2279
  %2281 = zext i1 %2280 to i8
  store i8 %2281, i8* %42, align 1, !tbaa !2432
  %2282 = trunc i64 %2277 to i32
  %2283 = and i32 %2282, 255
  %2284 = tail call i32 @llvm.ctpop.i32(i32 %2283) #8
  %2285 = trunc i32 %2284 to i8
  %2286 = and i8 %2285, 1
  %2287 = xor i8 %2286, 1
  store i8 %2287, i8* %49, align 1, !tbaa !2446
  %2288 = xor i64 %2275, %2269
  %2289 = xor i64 %2288, %2277
  %2290 = lshr i64 %2289, 4
  %2291 = trunc i64 %2290 to i8
  %2292 = and i8 %2291, 1
  store i8 %2292, i8* %54, align 1, !tbaa !2447
  %2293 = icmp eq i64 %2277, 0
  %2294 = zext i1 %2293 to i8
  store i8 %2294, i8* %57, align 1, !tbaa !2448
  %2295 = lshr i64 %2277, 63
  %2296 = trunc i64 %2295 to i8
  store i8 %2296, i8* %60, align 1, !tbaa !2449
  %2297 = lshr i64 %2269, 63
  %2298 = xor i64 %2295, %2297
  %2299 = xor i64 %2295, %2276
  %2300 = add nuw nsw i64 %2298, %2299
  %2301 = icmp eq i64 %2300, 2
  %2302 = zext i1 %2301 to i8
  store i8 %2302, i8* %66, align 1, !tbaa !2450
  %2303 = load i64, i64* %RBP, align 8
  %2304 = add i64 %2303, -52
  %2305 = add i64 %1955, 227
  store i64 %2305, i64* %PC, align 8
  %2306 = inttoptr i64 %2304 to i32*
  %2307 = load i32, i32* %2306, align 4
  %2308 = sext i32 %2307 to i64
  %2309 = mul nsw i64 %2308, 520
  store i64 %2309, i64* %RCX, align 8, !tbaa !2428
  %2310 = lshr i64 %2309, 63
  %2311 = add i64 %2309, %2277
  store i64 %2311, i64* %RAX, align 8, !tbaa !2428
  %2312 = icmp ult i64 %2311, %2277
  %2313 = icmp ult i64 %2311, %2309
  %2314 = or i1 %2312, %2313
  %2315 = zext i1 %2314 to i8
  store i8 %2315, i8* %42, align 1, !tbaa !2432
  %2316 = trunc i64 %2311 to i32
  %2317 = and i32 %2316, 255
  %2318 = tail call i32 @llvm.ctpop.i32(i32 %2317) #8
  %2319 = trunc i32 %2318 to i8
  %2320 = and i8 %2319, 1
  %2321 = xor i8 %2320, 1
  store i8 %2321, i8* %49, align 1, !tbaa !2446
  %2322 = xor i64 %2309, %2277
  %2323 = xor i64 %2322, %2311
  %2324 = lshr i64 %2323, 4
  %2325 = trunc i64 %2324 to i8
  %2326 = and i8 %2325, 1
  store i8 %2326, i8* %54, align 1, !tbaa !2447
  %2327 = icmp eq i64 %2311, 0
  %2328 = zext i1 %2327 to i8
  store i8 %2328, i8* %57, align 1, !tbaa !2448
  %2329 = lshr i64 %2311, 63
  %2330 = trunc i64 %2329 to i8
  store i8 %2330, i8* %60, align 1, !tbaa !2449
  %2331 = xor i64 %2329, %2295
  %2332 = xor i64 %2329, %2310
  %2333 = add nuw nsw i64 %2331, %2332
  %2334 = icmp eq i64 %2333, 2
  %2335 = zext i1 %2334 to i8
  store i8 %2335, i8* %66, align 1, !tbaa !2450
  %2336 = add i64 %2303, -48
  %2337 = add i64 %1955, 241
  store i64 %2337, i64* %PC, align 8
  %2338 = inttoptr i64 %2336 to i32*
  %2339 = load i32, i32* %2338, align 4
  %2340 = sext i32 %2339 to i64
  store i64 %2340, i64* %RCX, align 8, !tbaa !2428
  %2341 = shl nsw i64 %2340, 3
  %2342 = add i64 %2341, %2311
  %2343 = add i64 %1955, 246
  store i64 %2343, i64* %PC, align 8
  %2344 = load i64, i64* %147, align 1
  %2345 = inttoptr i64 %2342 to i64*
  store i64 %2344, i64* %2345, align 8
  %2346 = load i64, i64* %RBP, align 8
  %2347 = add i64 %2346, 16
  %2348 = load i64, i64* %PC, align 8
  %2349 = add i64 %2348, 4
  store i64 %2349, i64* %PC, align 8
  %2350 = inttoptr i64 %2347 to i64*
  %2351 = load i64, i64* %2350, align 8
  store i64 %2351, i64* %RAX, align 8, !tbaa !2428
  %2352 = add i64 %2346, -100
  %2353 = add i64 %2348, 8
  store i64 %2353, i64* %PC, align 8
  %2354 = inttoptr i64 %2352 to i32*
  %2355 = load i32, i32* %2354, align 4
  %2356 = sext i32 %2355 to i64
  %2357 = mul nsw i64 %2356, 520
  store i64 %2357, i64* %RCX, align 8, !tbaa !2428
  %2358 = lshr i64 %2357, 63
  %2359 = add i64 %2357, %2351
  store i64 %2359, i64* %RAX, align 8, !tbaa !2428
  %2360 = icmp ult i64 %2359, %2351
  %2361 = icmp ult i64 %2359, %2357
  %2362 = or i1 %2360, %2361
  %2363 = zext i1 %2362 to i8
  store i8 %2363, i8* %42, align 1, !tbaa !2432
  %2364 = trunc i64 %2359 to i32
  %2365 = and i32 %2364, 255
  %2366 = tail call i32 @llvm.ctpop.i32(i32 %2365) #8
  %2367 = trunc i32 %2366 to i8
  %2368 = and i8 %2367, 1
  %2369 = xor i8 %2368, 1
  store i8 %2369, i8* %49, align 1, !tbaa !2446
  %2370 = xor i64 %2357, %2351
  %2371 = xor i64 %2370, %2359
  %2372 = lshr i64 %2371, 4
  %2373 = trunc i64 %2372 to i8
  %2374 = and i8 %2373, 1
  store i8 %2374, i8* %54, align 1, !tbaa !2447
  %2375 = icmp eq i64 %2359, 0
  %2376 = zext i1 %2375 to i8
  store i8 %2376, i8* %57, align 1, !tbaa !2448
  %2377 = lshr i64 %2359, 63
  %2378 = trunc i64 %2377 to i8
  store i8 %2378, i8* %60, align 1, !tbaa !2449
  %2379 = lshr i64 %2351, 63
  %2380 = xor i64 %2377, %2379
  %2381 = xor i64 %2377, %2358
  %2382 = add nuw nsw i64 %2380, %2381
  %2383 = icmp eq i64 %2382, 2
  %2384 = zext i1 %2383 to i8
  store i8 %2384, i8* %66, align 1, !tbaa !2450
  %2385 = add i64 %2346, -104
  %2386 = add i64 %2348, 22
  store i64 %2386, i64* %PC, align 8
  %2387 = inttoptr i64 %2385 to i32*
  %2388 = load i32, i32* %2387, align 4
  %2389 = sext i32 %2388 to i64
  store i64 %2389, i64* %RCX, align 8, !tbaa !2428
  %2390 = shl nsw i64 %2389, 3
  %2391 = add i64 %2390, %2359
  %2392 = add i64 %2348, 27
  store i64 %2392, i64* %PC, align 8
  %2393 = inttoptr i64 %2391 to i64*
  %2394 = load i64, i64* %2393, align 8
  store i64 %2394, i64* %147, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %2395 = add i64 %2346, 24
  %2396 = add i64 %2348, 31
  store i64 %2396, i64* %PC, align 8
  %2397 = inttoptr i64 %2395 to i64*
  %2398 = load i64, i64* %2397, align 8
  store i64 %2398, i64* %RAX, align 8, !tbaa !2428
  %2399 = add i64 %2348, 35
  store i64 %2399, i64* %PC, align 8
  %2400 = load i32, i32* %2354, align 4
  %2401 = sext i32 %2400 to i64
  %2402 = mul nsw i64 %2401, 33800
  store i64 %2402, i64* %RCX, align 8, !tbaa !2428
  %2403 = lshr i64 %2402, 63
  %2404 = add i64 %2402, %2398
  store i64 %2404, i64* %RAX, align 8, !tbaa !2428
  %2405 = icmp ult i64 %2404, %2398
  %2406 = icmp ult i64 %2404, %2402
  %2407 = or i1 %2405, %2406
  %2408 = zext i1 %2407 to i8
  store i8 %2408, i8* %42, align 1, !tbaa !2432
  %2409 = trunc i64 %2404 to i32
  %2410 = and i32 %2409, 255
  %2411 = tail call i32 @llvm.ctpop.i32(i32 %2410) #8
  %2412 = trunc i32 %2411 to i8
  %2413 = and i8 %2412, 1
  %2414 = xor i8 %2413, 1
  store i8 %2414, i8* %49, align 1, !tbaa !2446
  %2415 = xor i64 %2402, %2398
  %2416 = xor i64 %2415, %2404
  %2417 = lshr i64 %2416, 4
  %2418 = trunc i64 %2417 to i8
  %2419 = and i8 %2418, 1
  store i8 %2419, i8* %54, align 1, !tbaa !2447
  %2420 = icmp eq i64 %2404, 0
  %2421 = zext i1 %2420 to i8
  store i8 %2421, i8* %57, align 1, !tbaa !2448
  %2422 = lshr i64 %2404, 63
  %2423 = trunc i64 %2422 to i8
  store i8 %2423, i8* %60, align 1, !tbaa !2449
  %2424 = lshr i64 %2398, 63
  %2425 = xor i64 %2422, %2424
  %2426 = xor i64 %2422, %2403
  %2427 = add nuw nsw i64 %2425, %2426
  %2428 = icmp eq i64 %2427, 2
  %2429 = zext i1 %2428 to i8
  store i8 %2429, i8* %66, align 1, !tbaa !2450
  %2430 = load i64, i64* %RBP, align 8
  %2431 = add i64 %2430, -52
  %2432 = add i64 %2348, 49
  store i64 %2432, i64* %PC, align 8
  %2433 = inttoptr i64 %2431 to i32*
  %2434 = load i32, i32* %2433, align 4
  %2435 = sext i32 %2434 to i64
  %2436 = mul nsw i64 %2435, 520
  store i64 %2436, i64* %RCX, align 8, !tbaa !2428
  %2437 = lshr i64 %2436, 63
  %2438 = add i64 %2436, %2404
  store i64 %2438, i64* %RAX, align 8, !tbaa !2428
  %2439 = icmp ult i64 %2438, %2404
  %2440 = icmp ult i64 %2438, %2436
  %2441 = or i1 %2439, %2440
  %2442 = zext i1 %2441 to i8
  store i8 %2442, i8* %42, align 1, !tbaa !2432
  %2443 = trunc i64 %2438 to i32
  %2444 = and i32 %2443, 255
  %2445 = tail call i32 @llvm.ctpop.i32(i32 %2444) #8
  %2446 = trunc i32 %2445 to i8
  %2447 = and i8 %2446, 1
  %2448 = xor i8 %2447, 1
  store i8 %2448, i8* %49, align 1, !tbaa !2446
  %2449 = xor i64 %2436, %2404
  %2450 = xor i64 %2449, %2438
  %2451 = lshr i64 %2450, 4
  %2452 = trunc i64 %2451 to i8
  %2453 = and i8 %2452, 1
  store i8 %2453, i8* %54, align 1, !tbaa !2447
  %2454 = icmp eq i64 %2438, 0
  %2455 = zext i1 %2454 to i8
  store i8 %2455, i8* %57, align 1, !tbaa !2448
  %2456 = lshr i64 %2438, 63
  %2457 = trunc i64 %2456 to i8
  store i8 %2457, i8* %60, align 1, !tbaa !2449
  %2458 = xor i64 %2456, %2422
  %2459 = xor i64 %2456, %2437
  %2460 = add nuw nsw i64 %2458, %2459
  %2461 = icmp eq i64 %2460, 2
  %2462 = zext i1 %2461 to i8
  store i8 %2462, i8* %66, align 1, !tbaa !2450
  %2463 = add i64 %2430, -48
  %2464 = add i64 %2348, 63
  store i64 %2464, i64* %PC, align 8
  %2465 = inttoptr i64 %2463 to i32*
  %2466 = load i32, i32* %2465, align 4
  %2467 = sext i32 %2466 to i64
  store i64 %2467, i64* %RCX, align 8, !tbaa !2428
  %2468 = shl nsw i64 %2467, 3
  %2469 = add i64 %2468, %2438
  %2470 = add i64 %2348, 68
  store i64 %2470, i64* %PC, align 8
  %2471 = load i64, i64* %147, align 1
  %2472 = inttoptr i64 %2469 to i64*
  store i64 %2471, i64* %2472, align 8
  %2473 = load i64, i64* %RBP, align 8
  %2474 = add i64 %2473, -104
  %2475 = load i64, i64* %PC, align 8
  %2476 = add i64 %2475, 3
  store i64 %2476, i64* %PC, align 8
  %2477 = inttoptr i64 %2474 to i32*
  %2478 = load i32, i32* %2477, align 4
  %2479 = add i32 %2478, 1
  %2480 = zext i32 %2479 to i64
  store i64 %2480, i64* %RAX, align 8, !tbaa !2428
  %2481 = icmp eq i32 %2478, -1
  %2482 = icmp eq i32 %2479, 0
  %2483 = or i1 %2481, %2482
  %2484 = zext i1 %2483 to i8
  store i8 %2484, i8* %42, align 1, !tbaa !2432
  %2485 = and i32 %2479, 255
  %2486 = tail call i32 @llvm.ctpop.i32(i32 %2485) #8
  %2487 = trunc i32 %2486 to i8
  %2488 = and i8 %2487, 1
  %2489 = xor i8 %2488, 1
  store i8 %2489, i8* %49, align 1, !tbaa !2446
  %2490 = xor i32 %2478, %2479
  %2491 = lshr i32 %2490, 4
  %2492 = trunc i32 %2491 to i8
  %2493 = and i8 %2492, 1
  store i8 %2493, i8* %54, align 1, !tbaa !2447
  %2494 = zext i1 %2482 to i8
  store i8 %2494, i8* %57, align 1, !tbaa !2448
  %2495 = lshr i32 %2479, 31
  %2496 = trunc i32 %2495 to i8
  store i8 %2496, i8* %60, align 1, !tbaa !2449
  %2497 = lshr i32 %2478, 31
  %2498 = xor i32 %2495, %2497
  %2499 = add nuw nsw i32 %2498, %2495
  %2500 = icmp eq i32 %2499, 2
  %2501 = zext i1 %2500 to i8
  store i8 %2501, i8* %66, align 1, !tbaa !2450
  %2502 = add i64 %2475, 9
  store i64 %2502, i64* %PC, align 8
  store i32 %2479, i32* %2477, align 4
  %2503 = load i64, i64* %PC, align 8
  %2504 = add i64 %2503, -2643
  store i64 %2504, i64* %PC, align 8, !tbaa !2428
  br label %block_40148d

block_4019de:                                     ; preds = %block_4019d2
  %2505 = add i64 %439, -108
  %2506 = add i64 %401, 36
  store i64 %2506, i64* %PC, align 8
  %2507 = inttoptr i64 %2505 to i32*
  %2508 = load i32, i32* %2507, align 4
  %2509 = sext i32 %2508 to i64
  store i64 %2509, i64* %RCX, align 8, !tbaa !2428
  %2510 = shl nsw i64 %2509, 3
  %2511 = add i64 %2510, %448
  %2512 = add i64 %401, 41
  store i64 %2512, i64* %PC, align 8
  %2513 = inttoptr i64 %2511 to double*
  %2514 = load double, double* %2513, align 8
  store double %2514, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %2515 = add i64 %439, -80
  %2516 = add i64 %401, 45
  store i64 %2516, i64* %PC, align 8
  %2517 = inttoptr i64 %2515 to i64*
  %2518 = load i64, i64* %2517, align 8
  store i64 %2518, i64* %RAX, align 8, !tbaa !2428
  %2519 = add i64 %439, -100
  %2520 = add i64 %401, 49
  store i64 %2520, i64* %PC, align 8
  %2521 = inttoptr i64 %2519 to i32*
  %2522 = load i32, i32* %2521, align 4
  %2523 = sext i32 %2522 to i64
  %2524 = mul nsw i64 %2523, 520
  store i64 %2524, i64* %RCX, align 8, !tbaa !2428
  %2525 = lshr i64 %2524, 63
  %2526 = add i64 %2524, %2518
  store i64 %2526, i64* %RAX, align 8, !tbaa !2428
  %2527 = icmp ult i64 %2526, %2518
  %2528 = icmp ult i64 %2526, %2524
  %2529 = or i1 %2527, %2528
  %2530 = zext i1 %2529 to i8
  store i8 %2530, i8* %42, align 1, !tbaa !2432
  %2531 = trunc i64 %2526 to i32
  %2532 = and i32 %2531, 255
  %2533 = tail call i32 @llvm.ctpop.i32(i32 %2532) #8
  %2534 = trunc i32 %2533 to i8
  %2535 = and i8 %2534, 1
  %2536 = xor i8 %2535, 1
  store i8 %2536, i8* %49, align 1, !tbaa !2446
  %2537 = xor i64 %2524, %2518
  %2538 = xor i64 %2537, %2526
  %2539 = lshr i64 %2538, 4
  %2540 = trunc i64 %2539 to i8
  %2541 = and i8 %2540, 1
  store i8 %2541, i8* %54, align 1, !tbaa !2447
  %2542 = icmp eq i64 %2526, 0
  %2543 = zext i1 %2542 to i8
  store i8 %2543, i8* %57, align 1, !tbaa !2448
  %2544 = lshr i64 %2526, 63
  %2545 = trunc i64 %2544 to i8
  store i8 %2545, i8* %60, align 1, !tbaa !2449
  %2546 = lshr i64 %2518, 63
  %2547 = xor i64 %2544, %2546
  %2548 = xor i64 %2544, %2525
  %2549 = add nuw nsw i64 %2547, %2548
  %2550 = icmp eq i64 %2549, 2
  %2551 = zext i1 %2550 to i8
  store i8 %2551, i8* %66, align 1, !tbaa !2450
  %2552 = add i64 %401, 63
  store i64 %2552, i64* %PC, align 8
  %2553 = load i32, i32* %2507, align 4
  %2554 = sext i32 %2553 to i64
  store i64 %2554, i64* %RCX, align 8, !tbaa !2428
  %2555 = shl nsw i64 %2554, 3
  %2556 = add i64 %2555, %2526
  %2557 = add i64 %401, 68
  store i64 %2557, i64* %PC, align 8
  %2558 = inttoptr i64 %2556 to double*
  %2559 = load double, double* %2558, align 8
  %2560 = fsub double %2514, %2559
  store double %2560, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %2561 = load i64, i64* %RBP, align 8
  %2562 = add i64 %2561, 40
  %2563 = add i64 %401, 72
  store i64 %2563, i64* %PC, align 8
  %2564 = inttoptr i64 %2562 to i64*
  %2565 = load i64, i64* %2564, align 8
  store i64 %2565, i64* %RAX, align 8, !tbaa !2428
  %2566 = add i64 %2561, -100
  %2567 = add i64 %401, 76
  store i64 %2567, i64* %PC, align 8
  %2568 = inttoptr i64 %2566 to i32*
  %2569 = load i32, i32* %2568, align 4
  %2570 = sext i32 %2569 to i64
  %2571 = mul nsw i64 %2570, 33800
  store i64 %2571, i64* %RCX, align 8, !tbaa !2428
  %2572 = lshr i64 %2571, 63
  %2573 = add i64 %2571, %2565
  store i64 %2573, i64* %RAX, align 8, !tbaa !2428
  %2574 = icmp ult i64 %2573, %2565
  %2575 = icmp ult i64 %2573, %2571
  %2576 = or i1 %2574, %2575
  %2577 = zext i1 %2576 to i8
  store i8 %2577, i8* %42, align 1, !tbaa !2432
  %2578 = trunc i64 %2573 to i32
  %2579 = and i32 %2578, 255
  %2580 = tail call i32 @llvm.ctpop.i32(i32 %2579) #8
  %2581 = trunc i32 %2580 to i8
  %2582 = and i8 %2581, 1
  %2583 = xor i8 %2582, 1
  store i8 %2583, i8* %49, align 1, !tbaa !2446
  %2584 = xor i64 %2571, %2565
  %2585 = xor i64 %2584, %2573
  %2586 = lshr i64 %2585, 4
  %2587 = trunc i64 %2586 to i8
  %2588 = and i8 %2587, 1
  store i8 %2588, i8* %54, align 1, !tbaa !2447
  %2589 = icmp eq i64 %2573, 0
  %2590 = zext i1 %2589 to i8
  store i8 %2590, i8* %57, align 1, !tbaa !2448
  %2591 = lshr i64 %2573, 63
  %2592 = trunc i64 %2591 to i8
  store i8 %2592, i8* %60, align 1, !tbaa !2449
  %2593 = lshr i64 %2565, 63
  %2594 = xor i64 %2591, %2593
  %2595 = xor i64 %2591, %2572
  %2596 = add nuw nsw i64 %2594, %2595
  %2597 = icmp eq i64 %2596, 2
  %2598 = zext i1 %2597 to i8
  store i8 %2598, i8* %66, align 1, !tbaa !2450
  %2599 = add i64 %2561, -52
  %2600 = add i64 %401, 90
  store i64 %2600, i64* %PC, align 8
  %2601 = inttoptr i64 %2599 to i32*
  %2602 = load i32, i32* %2601, align 4
  %2603 = sext i32 %2602 to i64
  %2604 = mul nsw i64 %2603, 520
  store i64 %2604, i64* %RCX, align 8, !tbaa !2428
  %2605 = lshr i64 %2604, 63
  %2606 = add i64 %2604, %2573
  store i64 %2606, i64* %RAX, align 8, !tbaa !2428
  %2607 = icmp ult i64 %2606, %2573
  %2608 = icmp ult i64 %2606, %2604
  %2609 = or i1 %2607, %2608
  %2610 = zext i1 %2609 to i8
  store i8 %2610, i8* %42, align 1, !tbaa !2432
  %2611 = trunc i64 %2606 to i32
  %2612 = and i32 %2611, 255
  %2613 = tail call i32 @llvm.ctpop.i32(i32 %2612) #8
  %2614 = trunc i32 %2613 to i8
  %2615 = and i8 %2614, 1
  %2616 = xor i8 %2615, 1
  store i8 %2616, i8* %49, align 1, !tbaa !2446
  %2617 = xor i64 %2604, %2573
  %2618 = xor i64 %2617, %2606
  %2619 = lshr i64 %2618, 4
  %2620 = trunc i64 %2619 to i8
  %2621 = and i8 %2620, 1
  store i8 %2621, i8* %54, align 1, !tbaa !2447
  %2622 = icmp eq i64 %2606, 0
  %2623 = zext i1 %2622 to i8
  store i8 %2623, i8* %57, align 1, !tbaa !2448
  %2624 = lshr i64 %2606, 63
  %2625 = trunc i64 %2624 to i8
  store i8 %2625, i8* %60, align 1, !tbaa !2449
  %2626 = xor i64 %2624, %2591
  %2627 = xor i64 %2624, %2605
  %2628 = add nuw nsw i64 %2626, %2627
  %2629 = icmp eq i64 %2628, 2
  %2630 = zext i1 %2629 to i8
  store i8 %2630, i8* %66, align 1, !tbaa !2450
  %2631 = load i64, i64* %RBP, align 8
  %2632 = add i64 %2631, -108
  %2633 = add i64 %401, 103
  store i64 %2633, i64* %PC, align 8
  %2634 = inttoptr i64 %2632 to i32*
  %2635 = load i32, i32* %2634, align 4
  %2636 = add i32 %2635, 1
  %2637 = zext i32 %2636 to i64
  store i64 %2637, i64* %RDX, align 8, !tbaa !2428
  %2638 = icmp eq i32 %2635, -1
  %2639 = icmp eq i32 %2636, 0
  %2640 = or i1 %2638, %2639
  %2641 = zext i1 %2640 to i8
  store i8 %2641, i8* %42, align 1, !tbaa !2432
  %2642 = and i32 %2636, 255
  %2643 = tail call i32 @llvm.ctpop.i32(i32 %2642) #8
  %2644 = trunc i32 %2643 to i8
  %2645 = and i8 %2644, 1
  %2646 = xor i8 %2645, 1
  store i8 %2646, i8* %49, align 1, !tbaa !2446
  %2647 = xor i32 %2635, %2636
  %2648 = lshr i32 %2647, 4
  %2649 = trunc i32 %2648 to i8
  %2650 = and i8 %2649, 1
  store i8 %2650, i8* %54, align 1, !tbaa !2447
  %2651 = zext i1 %2639 to i8
  store i8 %2651, i8* %57, align 1, !tbaa !2448
  %2652 = lshr i32 %2636, 31
  %2653 = trunc i32 %2652 to i8
  store i8 %2653, i8* %60, align 1, !tbaa !2449
  %2654 = lshr i32 %2635, 31
  %2655 = xor i32 %2652, %2654
  %2656 = add nuw nsw i32 %2655, %2652
  %2657 = icmp eq i32 %2656, 2
  %2658 = zext i1 %2657 to i8
  store i8 %2658, i8* %66, align 1, !tbaa !2450
  %2659 = sext i32 %2636 to i64
  store i64 %2659, i64* %RCX, align 8, !tbaa !2428
  %2660 = shl nsw i64 %2659, 3
  %2661 = add i64 %2660, %2606
  %2662 = add i64 %401, 114
  store i64 %2662, i64* %PC, align 8
  %2663 = load double, double* %228, align 1
  %2664 = inttoptr i64 %2661 to double*
  %2665 = load double, double* %2664, align 8
  %2666 = fadd double %2663, %2665
  store double %2666, double* %228, align 1, !tbaa !2452
  %2667 = add i64 %2631, 40
  %2668 = add i64 %401, 118
  store i64 %2668, i64* %PC, align 8
  %2669 = inttoptr i64 %2667 to i64*
  %2670 = load i64, i64* %2669, align 8
  store i64 %2670, i64* %RAX, align 8, !tbaa !2428
  %2671 = add i64 %2631, -100
  %2672 = add i64 %401, 122
  store i64 %2672, i64* %PC, align 8
  %2673 = inttoptr i64 %2671 to i32*
  %2674 = load i32, i32* %2673, align 4
  %2675 = sext i32 %2674 to i64
  %2676 = mul nsw i64 %2675, 33800
  store i64 %2676, i64* %RCX, align 8, !tbaa !2428
  %2677 = lshr i64 %2676, 63
  %2678 = add i64 %2676, %2670
  store i64 %2678, i64* %RAX, align 8, !tbaa !2428
  %2679 = icmp ult i64 %2678, %2670
  %2680 = icmp ult i64 %2678, %2676
  %2681 = or i1 %2679, %2680
  %2682 = zext i1 %2681 to i8
  store i8 %2682, i8* %42, align 1, !tbaa !2432
  %2683 = trunc i64 %2678 to i32
  %2684 = and i32 %2683, 255
  %2685 = tail call i32 @llvm.ctpop.i32(i32 %2684) #8
  %2686 = trunc i32 %2685 to i8
  %2687 = and i8 %2686, 1
  %2688 = xor i8 %2687, 1
  store i8 %2688, i8* %49, align 1, !tbaa !2446
  %2689 = xor i64 %2676, %2670
  %2690 = xor i64 %2689, %2678
  %2691 = lshr i64 %2690, 4
  %2692 = trunc i64 %2691 to i8
  %2693 = and i8 %2692, 1
  store i8 %2693, i8* %54, align 1, !tbaa !2447
  %2694 = icmp eq i64 %2678, 0
  %2695 = zext i1 %2694 to i8
  store i8 %2695, i8* %57, align 1, !tbaa !2448
  %2696 = lshr i64 %2678, 63
  %2697 = trunc i64 %2696 to i8
  store i8 %2697, i8* %60, align 1, !tbaa !2449
  %2698 = lshr i64 %2670, 63
  %2699 = xor i64 %2696, %2698
  %2700 = xor i64 %2696, %2677
  %2701 = add nuw nsw i64 %2699, %2700
  %2702 = icmp eq i64 %2701, 2
  %2703 = zext i1 %2702 to i8
  store i8 %2703, i8* %66, align 1, !tbaa !2450
  %2704 = load i64, i64* %RBP, align 8
  %2705 = add i64 %2704, -52
  %2706 = add i64 %401, 136
  store i64 %2706, i64* %PC, align 8
  %2707 = inttoptr i64 %2705 to i32*
  %2708 = load i32, i32* %2707, align 4
  %2709 = sext i32 %2708 to i64
  %2710 = mul nsw i64 %2709, 520
  store i64 %2710, i64* %RCX, align 8, !tbaa !2428
  %2711 = lshr i64 %2710, 63
  %2712 = add i64 %2710, %2678
  store i64 %2712, i64* %RAX, align 8, !tbaa !2428
  %2713 = icmp ult i64 %2712, %2678
  %2714 = icmp ult i64 %2712, %2710
  %2715 = or i1 %2713, %2714
  %2716 = zext i1 %2715 to i8
  store i8 %2716, i8* %42, align 1, !tbaa !2432
  %2717 = trunc i64 %2712 to i32
  %2718 = and i32 %2717, 255
  %2719 = tail call i32 @llvm.ctpop.i32(i32 %2718) #8
  %2720 = trunc i32 %2719 to i8
  %2721 = and i8 %2720, 1
  %2722 = xor i8 %2721, 1
  store i8 %2722, i8* %49, align 1, !tbaa !2446
  %2723 = xor i64 %2710, %2678
  %2724 = xor i64 %2723, %2712
  %2725 = lshr i64 %2724, 4
  %2726 = trunc i64 %2725 to i8
  %2727 = and i8 %2726, 1
  store i8 %2727, i8* %54, align 1, !tbaa !2447
  %2728 = icmp eq i64 %2712, 0
  %2729 = zext i1 %2728 to i8
  store i8 %2729, i8* %57, align 1, !tbaa !2448
  %2730 = lshr i64 %2712, 63
  %2731 = trunc i64 %2730 to i8
  store i8 %2731, i8* %60, align 1, !tbaa !2449
  %2732 = xor i64 %2730, %2696
  %2733 = xor i64 %2730, %2711
  %2734 = add nuw nsw i64 %2732, %2733
  %2735 = icmp eq i64 %2734, 2
  %2736 = zext i1 %2735 to i8
  store i8 %2736, i8* %66, align 1, !tbaa !2450
  %2737 = add i64 %2704, -108
  %2738 = add i64 %401, 150
  store i64 %2738, i64* %PC, align 8
  %2739 = inttoptr i64 %2737 to i32*
  %2740 = load i32, i32* %2739, align 4
  %2741 = sext i32 %2740 to i64
  store i64 %2741, i64* %RCX, align 8, !tbaa !2428
  %2742 = shl nsw i64 %2741, 3
  %2743 = add i64 %2742, %2712
  %2744 = add i64 %401, 155
  store i64 %2744, i64* %PC, align 8
  %2745 = load double, double* %228, align 1
  %2746 = inttoptr i64 %2743 to double*
  %2747 = load double, double* %2746, align 8
  %2748 = fsub double %2745, %2747
  store double %2748, double* %228, align 1, !tbaa !2452
  %2749 = add i64 %2704, -96
  %2750 = add i64 %401, 159
  store i64 %2750, i64* %PC, align 8
  %2751 = inttoptr i64 %2749 to i64*
  %2752 = load i64, i64* %2751, align 8
  store i64 %2752, i64* %RAX, align 8, !tbaa !2428
  %2753 = add i64 %2704, -100
  %2754 = add i64 %401, 163
  store i64 %2754, i64* %PC, align 8
  %2755 = inttoptr i64 %2753 to i32*
  %2756 = load i32, i32* %2755, align 4
  %2757 = sext i32 %2756 to i64
  %2758 = mul nsw i64 %2757, 520
  store i64 %2758, i64* %RCX, align 8, !tbaa !2428
  %2759 = lshr i64 %2758, 63
  %2760 = add i64 %2758, %2752
  store i64 %2760, i64* %RAX, align 8, !tbaa !2428
  %2761 = icmp ult i64 %2760, %2752
  %2762 = icmp ult i64 %2760, %2758
  %2763 = or i1 %2761, %2762
  %2764 = zext i1 %2763 to i8
  store i8 %2764, i8* %42, align 1, !tbaa !2432
  %2765 = trunc i64 %2760 to i32
  %2766 = and i32 %2765, 255
  %2767 = tail call i32 @llvm.ctpop.i32(i32 %2766) #8
  %2768 = trunc i32 %2767 to i8
  %2769 = and i8 %2768, 1
  %2770 = xor i8 %2769, 1
  store i8 %2770, i8* %49, align 1, !tbaa !2446
  %2771 = xor i64 %2758, %2752
  %2772 = xor i64 %2771, %2760
  %2773 = lshr i64 %2772, 4
  %2774 = trunc i64 %2773 to i8
  %2775 = and i8 %2774, 1
  store i8 %2775, i8* %54, align 1, !tbaa !2447
  %2776 = icmp eq i64 %2760, 0
  %2777 = zext i1 %2776 to i8
  store i8 %2777, i8* %57, align 1, !tbaa !2448
  %2778 = lshr i64 %2760, 63
  %2779 = trunc i64 %2778 to i8
  store i8 %2779, i8* %60, align 1, !tbaa !2449
  %2780 = lshr i64 %2752, 63
  %2781 = xor i64 %2778, %2780
  %2782 = xor i64 %2778, %2759
  %2783 = add nuw nsw i64 %2781, %2782
  %2784 = icmp eq i64 %2783, 2
  %2785 = zext i1 %2784 to i8
  store i8 %2785, i8* %66, align 1, !tbaa !2450
  %2786 = load i64, i64* %RBP, align 8
  %2787 = add i64 %2786, -104
  %2788 = add i64 %401, 177
  store i64 %2788, i64* %PC, align 8
  %2789 = inttoptr i64 %2787 to i32*
  %2790 = load i32, i32* %2789, align 4
  %2791 = sext i32 %2790 to i64
  store i64 %2791, i64* %RCX, align 8, !tbaa !2428
  %2792 = shl nsw i64 %2791, 3
  %2793 = add i64 %2792, %2760
  %2794 = add i64 %401, 182
  store i64 %2794, i64* %PC, align 8
  %2795 = inttoptr i64 %2793 to double*
  store double %2748, double* %2795, align 8
  %2796 = load i64, i64* %RBP, align 8
  %2797 = add i64 %2796, 88
  %2798 = load i64, i64* %PC, align 8
  %2799 = add i64 %2798, 4
  store i64 %2799, i64* %PC, align 8
  %2800 = inttoptr i64 %2797 to i64*
  %2801 = load i64, i64* %2800, align 8
  store i64 %2801, i64* %RAX, align 8, !tbaa !2428
  %2802 = add i64 %2796, -52
  %2803 = add i64 %2798, 8
  store i64 %2803, i64* %PC, align 8
  %2804 = inttoptr i64 %2802 to i32*
  %2805 = load i32, i32* %2804, align 4
  %2806 = sext i32 %2805 to i64
  store i64 %2806, i64* %RCX, align 8, !tbaa !2428
  %2807 = shl nsw i64 %2806, 3
  %2808 = add i64 %2807, %2801
  %2809 = add i64 %2798, 13
  store i64 %2809, i64* %PC, align 8
  %2810 = inttoptr i64 %2808 to double*
  %2811 = load double, double* %2810, align 8
  store double %2811, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %2812 = add i64 %2796, 96
  %2813 = add i64 %2798, 17
  store i64 %2813, i64* %PC, align 8
  %2814 = inttoptr i64 %2812 to i64*
  %2815 = load i64, i64* %2814, align 8
  store i64 %2815, i64* %RAX, align 8, !tbaa !2428
  %2816 = add i64 %2796, -104
  %2817 = add i64 %2798, 21
  store i64 %2817, i64* %PC, align 8
  %2818 = inttoptr i64 %2816 to i32*
  %2819 = load i32, i32* %2818, align 4
  %2820 = sext i32 %2819 to i64
  store i64 %2820, i64* %RCX, align 8, !tbaa !2428
  %2821 = shl nsw i64 %2820, 3
  %2822 = add i64 %2821, %2815
  %2823 = add i64 %2798, 26
  store i64 %2823, i64* %PC, align 8
  %2824 = inttoptr i64 %2822 to double*
  %2825 = load double, double* %2824, align 8
  %2826 = fdiv double %2811, %2825
  store double %2826, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %2827 = add i64 %2796, 24
  %2828 = add i64 %2798, 30
  store i64 %2828, i64* %PC, align 8
  %2829 = inttoptr i64 %2827 to i64*
  %2830 = load i64, i64* %2829, align 8
  store i64 %2830, i64* %RAX, align 8, !tbaa !2428
  %2831 = add i64 %2796, -100
  %2832 = add i64 %2798, 34
  store i64 %2832, i64* %PC, align 8
  %2833 = inttoptr i64 %2831 to i32*
  %2834 = load i32, i32* %2833, align 4
  %2835 = sext i32 %2834 to i64
  %2836 = mul nsw i64 %2835, 33800
  store i64 %2836, i64* %RCX, align 8, !tbaa !2428
  %2837 = lshr i64 %2836, 63
  %2838 = add i64 %2836, %2830
  store i64 %2838, i64* %RAX, align 8, !tbaa !2428
  %2839 = icmp ult i64 %2838, %2830
  %2840 = icmp ult i64 %2838, %2836
  %2841 = or i1 %2839, %2840
  %2842 = zext i1 %2841 to i8
  store i8 %2842, i8* %42, align 1, !tbaa !2432
  %2843 = trunc i64 %2838 to i32
  %2844 = and i32 %2843, 255
  %2845 = tail call i32 @llvm.ctpop.i32(i32 %2844) #8
  %2846 = trunc i32 %2845 to i8
  %2847 = and i8 %2846, 1
  %2848 = xor i8 %2847, 1
  store i8 %2848, i8* %49, align 1, !tbaa !2446
  %2849 = xor i64 %2836, %2830
  %2850 = xor i64 %2849, %2838
  %2851 = lshr i64 %2850, 4
  %2852 = trunc i64 %2851 to i8
  %2853 = and i8 %2852, 1
  store i8 %2853, i8* %54, align 1, !tbaa !2447
  %2854 = icmp eq i64 %2838, 0
  %2855 = zext i1 %2854 to i8
  store i8 %2855, i8* %57, align 1, !tbaa !2448
  %2856 = lshr i64 %2838, 63
  %2857 = trunc i64 %2856 to i8
  store i8 %2857, i8* %60, align 1, !tbaa !2449
  %2858 = lshr i64 %2830, 63
  %2859 = xor i64 %2856, %2858
  %2860 = xor i64 %2856, %2837
  %2861 = add nuw nsw i64 %2859, %2860
  %2862 = icmp eq i64 %2861, 2
  %2863 = zext i1 %2862 to i8
  store i8 %2863, i8* %66, align 1, !tbaa !2450
  %2864 = load i64, i64* %RBP, align 8
  %2865 = add i64 %2864, -104
  %2866 = add i64 %2798, 48
  store i64 %2866, i64* %PC, align 8
  %2867 = inttoptr i64 %2865 to i32*
  %2868 = load i32, i32* %2867, align 4
  %2869 = sext i32 %2868 to i64
  %2870 = mul nsw i64 %2869, 520
  store i64 %2870, i64* %RCX, align 8, !tbaa !2428
  %2871 = lshr i64 %2870, 63
  %2872 = add i64 %2870, %2838
  store i64 %2872, i64* %RAX, align 8, !tbaa !2428
  %2873 = icmp ult i64 %2872, %2838
  %2874 = icmp ult i64 %2872, %2870
  %2875 = or i1 %2873, %2874
  %2876 = zext i1 %2875 to i8
  store i8 %2876, i8* %42, align 1, !tbaa !2432
  %2877 = trunc i64 %2872 to i32
  %2878 = and i32 %2877, 255
  %2879 = tail call i32 @llvm.ctpop.i32(i32 %2878) #8
  %2880 = trunc i32 %2879 to i8
  %2881 = and i8 %2880, 1
  %2882 = xor i8 %2881, 1
  store i8 %2882, i8* %49, align 1, !tbaa !2446
  %2883 = xor i64 %2870, %2838
  %2884 = xor i64 %2883, %2872
  %2885 = lshr i64 %2884, 4
  %2886 = trunc i64 %2885 to i8
  %2887 = and i8 %2886, 1
  store i8 %2887, i8* %54, align 1, !tbaa !2447
  %2888 = icmp eq i64 %2872, 0
  %2889 = zext i1 %2888 to i8
  store i8 %2889, i8* %57, align 1, !tbaa !2448
  %2890 = lshr i64 %2872, 63
  %2891 = trunc i64 %2890 to i8
  store i8 %2891, i8* %60, align 1, !tbaa !2449
  %2892 = xor i64 %2890, %2856
  %2893 = xor i64 %2890, %2871
  %2894 = add nuw nsw i64 %2892, %2893
  %2895 = icmp eq i64 %2894, 2
  %2896 = zext i1 %2895 to i8
  store i8 %2896, i8* %66, align 1, !tbaa !2450
  %2897 = add i64 %2864, -108
  %2898 = add i64 %2798, 62
  store i64 %2898, i64* %PC, align 8
  %2899 = inttoptr i64 %2897 to i32*
  %2900 = load i32, i32* %2899, align 4
  %2901 = sext i32 %2900 to i64
  store i64 %2901, i64* %RCX, align 8, !tbaa !2428
  %2902 = shl nsw i64 %2901, 3
  %2903 = add i64 %2902, %2872
  %2904 = add i64 %2798, 67
  store i64 %2904, i64* %PC, align 8
  %2905 = load double, double* %228, align 1
  %2906 = inttoptr i64 %2903 to double*
  %2907 = load double, double* %2906, align 8
  %2908 = fmul double %2905, %2907
  store double %2908, double* %228, align 1, !tbaa !2452
  %2909 = add i64 %2864, -72
  %2910 = add i64 %2798, 72
  store i64 %2910, i64* %PC, align 8
  %2911 = inttoptr i64 %2909 to double*
  %2912 = load double, double* %2911, align 8
  store double %2912, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %2913 = add i64 %2864, 96
  %2914 = add i64 %2798, 76
  store i64 %2914, i64* %PC, align 8
  %2915 = inttoptr i64 %2913 to i64*
  %2916 = load i64, i64* %2915, align 8
  store i64 %2916, i64* %RAX, align 8, !tbaa !2428
  %2917 = add i64 %2798, 80
  store i64 %2917, i64* %PC, align 8
  %2918 = load i32, i32* %2867, align 4
  %2919 = sext i32 %2918 to i64
  store i64 %2919, i64* %RCX, align 8, !tbaa !2428
  %2920 = shl nsw i64 %2919, 3
  %2921 = add i64 %2920, %2916
  %2922 = add i64 %2798, 85
  store i64 %2922, i64* %PC, align 8
  %2923 = inttoptr i64 %2921 to double*
  %2924 = load double, double* %2923, align 8
  %2925 = fdiv double %2912, %2924
  store double %2925, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %2926 = load i64, i64* %RBP, align 8
  %2927 = add i64 %2926, -96
  %2928 = add i64 %2798, 89
  store i64 %2928, i64* %PC, align 8
  %2929 = inttoptr i64 %2927 to i64*
  %2930 = load i64, i64* %2929, align 8
  store i64 %2930, i64* %RAX, align 8, !tbaa !2428
  %2931 = add i64 %2926, -100
  %2932 = add i64 %2798, 93
  store i64 %2932, i64* %PC, align 8
  %2933 = inttoptr i64 %2931 to i32*
  %2934 = load i32, i32* %2933, align 4
  %2935 = sext i32 %2934 to i64
  %2936 = mul nsw i64 %2935, 520
  store i64 %2936, i64* %RCX, align 8, !tbaa !2428
  %2937 = lshr i64 %2936, 63
  %2938 = add i64 %2936, %2930
  store i64 %2938, i64* %RAX, align 8, !tbaa !2428
  %2939 = icmp ult i64 %2938, %2930
  %2940 = icmp ult i64 %2938, %2936
  %2941 = or i1 %2939, %2940
  %2942 = zext i1 %2941 to i8
  store i8 %2942, i8* %42, align 1, !tbaa !2432
  %2943 = trunc i64 %2938 to i32
  %2944 = and i32 %2943, 255
  %2945 = tail call i32 @llvm.ctpop.i32(i32 %2944) #8
  %2946 = trunc i32 %2945 to i8
  %2947 = and i8 %2946, 1
  %2948 = xor i8 %2947, 1
  store i8 %2948, i8* %49, align 1, !tbaa !2446
  %2949 = xor i64 %2936, %2930
  %2950 = xor i64 %2949, %2938
  %2951 = lshr i64 %2950, 4
  %2952 = trunc i64 %2951 to i8
  %2953 = and i8 %2952, 1
  store i8 %2953, i8* %54, align 1, !tbaa !2447
  %2954 = icmp eq i64 %2938, 0
  %2955 = zext i1 %2954 to i8
  store i8 %2955, i8* %57, align 1, !tbaa !2448
  %2956 = lshr i64 %2938, 63
  %2957 = trunc i64 %2956 to i8
  store i8 %2957, i8* %60, align 1, !tbaa !2449
  %2958 = lshr i64 %2930, 63
  %2959 = xor i64 %2956, %2958
  %2960 = xor i64 %2956, %2937
  %2961 = add nuw nsw i64 %2959, %2960
  %2962 = icmp eq i64 %2961, 2
  %2963 = zext i1 %2962 to i8
  store i8 %2963, i8* %66, align 1, !tbaa !2450
  %2964 = add i64 %2926, -104
  %2965 = add i64 %2798, 107
  store i64 %2965, i64* %PC, align 8
  %2966 = inttoptr i64 %2964 to i32*
  %2967 = load i32, i32* %2966, align 4
  %2968 = sext i32 %2967 to i64
  store i64 %2968, i64* %RCX, align 8, !tbaa !2428
  %2969 = shl nsw i64 %2968, 3
  %2970 = add i64 %2969, %2938
  %2971 = add i64 %2798, 112
  store i64 %2971, i64* %PC, align 8
  %2972 = inttoptr i64 %2970 to double*
  %2973 = load double, double* %2972, align 8
  %2974 = fmul double %2925, %2973
  store double %2974, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %2975 = load double, double* %228, align 1
  %2976 = fsub double %2975, %2974
  store double %2976, double* %228, align 1, !tbaa !2452
  %2977 = add i64 %2926, 16
  %2978 = add i64 %2798, 120
  store i64 %2978, i64* %PC, align 8
  %2979 = inttoptr i64 %2977 to i64*
  %2980 = load i64, i64* %2979, align 8
  store i64 %2980, i64* %RAX, align 8, !tbaa !2428
  %2981 = load i64, i64* %RBP, align 8
  %2982 = add i64 %2981, -100
  %2983 = add i64 %2798, 124
  store i64 %2983, i64* %PC, align 8
  %2984 = inttoptr i64 %2982 to i32*
  %2985 = load i32, i32* %2984, align 4
  %2986 = sext i32 %2985 to i64
  %2987 = mul nsw i64 %2986, 520
  store i64 %2987, i64* %RCX, align 8, !tbaa !2428
  %2988 = lshr i64 %2987, 63
  %2989 = add i64 %2987, %2980
  store i64 %2989, i64* %RAX, align 8, !tbaa !2428
  %2990 = icmp ult i64 %2989, %2980
  %2991 = icmp ult i64 %2989, %2987
  %2992 = or i1 %2990, %2991
  %2993 = zext i1 %2992 to i8
  store i8 %2993, i8* %42, align 1, !tbaa !2432
  %2994 = trunc i64 %2989 to i32
  %2995 = and i32 %2994, 255
  %2996 = tail call i32 @llvm.ctpop.i32(i32 %2995) #8
  %2997 = trunc i32 %2996 to i8
  %2998 = and i8 %2997, 1
  %2999 = xor i8 %2998, 1
  store i8 %2999, i8* %49, align 1, !tbaa !2446
  %3000 = xor i64 %2987, %2980
  %3001 = xor i64 %3000, %2989
  %3002 = lshr i64 %3001, 4
  %3003 = trunc i64 %3002 to i8
  %3004 = and i8 %3003, 1
  store i8 %3004, i8* %54, align 1, !tbaa !2447
  %3005 = icmp eq i64 %2989, 0
  %3006 = zext i1 %3005 to i8
  store i8 %3006, i8* %57, align 1, !tbaa !2448
  %3007 = lshr i64 %2989, 63
  %3008 = trunc i64 %3007 to i8
  store i8 %3008, i8* %60, align 1, !tbaa !2449
  %3009 = lshr i64 %2980, 63
  %3010 = xor i64 %3007, %3009
  %3011 = xor i64 %3007, %2988
  %3012 = add nuw nsw i64 %3010, %3011
  %3013 = icmp eq i64 %3012, 2
  %3014 = zext i1 %3013 to i8
  store i8 %3014, i8* %66, align 1, !tbaa !2450
  %3015 = add i64 %2981, -104
  %3016 = add i64 %2798, 138
  store i64 %3016, i64* %PC, align 8
  %3017 = inttoptr i64 %3015 to i32*
  %3018 = load i32, i32* %3017, align 4
  %3019 = sext i32 %3018 to i64
  store i64 %3019, i64* %RCX, align 8, !tbaa !2428
  %3020 = shl nsw i64 %3019, 3
  %3021 = add i64 %3020, %2989
  %3022 = add i64 %2798, 143
  store i64 %3022, i64* %PC, align 8
  %3023 = inttoptr i64 %3021 to double*
  store double %2976, double* %3023, align 8
  %3024 = load i64, i64* %RBP, align 8
  %3025 = add i64 %3024, 72
  %3026 = load i64, i64* %PC, align 8
  %3027 = add i64 %3026, 4
  store i64 %3027, i64* %PC, align 8
  %3028 = inttoptr i64 %3025 to i64*
  %3029 = load i64, i64* %3028, align 8
  store i64 %3029, i64* %RAX, align 8, !tbaa !2428
  %3030 = add i64 %3024, -108
  %3031 = add i64 %3026, 8
  store i64 %3031, i64* %PC, align 8
  %3032 = inttoptr i64 %3030 to i32*
  %3033 = load i32, i32* %3032, align 4
  %3034 = sext i32 %3033 to i64
  store i64 %3034, i64* %RCX, align 8, !tbaa !2428
  %3035 = shl nsw i64 %3034, 3
  %3036 = add i64 %3035, %3029
  %3037 = add i64 %3026, 13
  store i64 %3037, i64* %PC, align 8
  %3038 = inttoptr i64 %3036 to double*
  %3039 = load double, double* %3038, align 8
  store double %3039, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %3040 = add i64 %3024, 80
  %3041 = add i64 %3026, 17
  store i64 %3041, i64* %PC, align 8
  %3042 = inttoptr i64 %3040 to i64*
  %3043 = load i64, i64* %3042, align 8
  store i64 %3043, i64* %RAX, align 8, !tbaa !2428
  %3044 = add i64 %3026, 21
  store i64 %3044, i64* %PC, align 8
  %3045 = load i32, i32* %3032, align 4
  %3046 = sext i32 %3045 to i64
  store i64 %3046, i64* %RCX, align 8, !tbaa !2428
  %3047 = shl nsw i64 %3046, 3
  %3048 = add i64 %3047, %3043
  %3049 = add i64 %3026, 26
  store i64 %3049, i64* %PC, align 8
  %3050 = inttoptr i64 %3048 to double*
  %3051 = load double, double* %3050, align 8
  %3052 = fdiv double %3039, %3051
  store double %3052, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %3053 = add i64 %3024, 48
  %3054 = add i64 %3026, 30
  store i64 %3054, i64* %PC, align 8
  %3055 = inttoptr i64 %3053 to i64*
  %3056 = load i64, i64* %3055, align 8
  store i64 %3056, i64* %RAX, align 8, !tbaa !2428
  %3057 = add i64 %3024, -100
  %3058 = add i64 %3026, 34
  store i64 %3058, i64* %PC, align 8
  %3059 = inttoptr i64 %3057 to i32*
  %3060 = load i32, i32* %3059, align 4
  %3061 = sext i32 %3060 to i64
  %3062 = mul nsw i64 %3061, 33800
  store i64 %3062, i64* %RCX, align 8, !tbaa !2428
  %3063 = lshr i64 %3062, 63
  %3064 = add i64 %3062, %3056
  store i64 %3064, i64* %RAX, align 8, !tbaa !2428
  %3065 = icmp ult i64 %3064, %3056
  %3066 = icmp ult i64 %3064, %3062
  %3067 = or i1 %3065, %3066
  %3068 = zext i1 %3067 to i8
  store i8 %3068, i8* %42, align 1, !tbaa !2432
  %3069 = trunc i64 %3064 to i32
  %3070 = and i32 %3069, 255
  %3071 = tail call i32 @llvm.ctpop.i32(i32 %3070) #8
  %3072 = trunc i32 %3071 to i8
  %3073 = and i8 %3072, 1
  %3074 = xor i8 %3073, 1
  store i8 %3074, i8* %49, align 1, !tbaa !2446
  %3075 = xor i64 %3062, %3056
  %3076 = xor i64 %3075, %3064
  %3077 = lshr i64 %3076, 4
  %3078 = trunc i64 %3077 to i8
  %3079 = and i8 %3078, 1
  store i8 %3079, i8* %54, align 1, !tbaa !2447
  %3080 = icmp eq i64 %3064, 0
  %3081 = zext i1 %3080 to i8
  store i8 %3081, i8* %57, align 1, !tbaa !2448
  %3082 = lshr i64 %3064, 63
  %3083 = trunc i64 %3082 to i8
  store i8 %3083, i8* %60, align 1, !tbaa !2449
  %3084 = lshr i64 %3056, 63
  %3085 = xor i64 %3082, %3084
  %3086 = xor i64 %3082, %3063
  %3087 = add nuw nsw i64 %3085, %3086
  %3088 = icmp eq i64 %3087, 2
  %3089 = zext i1 %3088 to i8
  store i8 %3089, i8* %66, align 1, !tbaa !2450
  %3090 = load i64, i64* %RBP, align 8
  %3091 = add i64 %3090, -52
  %3092 = add i64 %3026, 48
  store i64 %3092, i64* %PC, align 8
  %3093 = inttoptr i64 %3091 to i32*
  %3094 = load i32, i32* %3093, align 4
  %3095 = sext i32 %3094 to i64
  %3096 = mul nsw i64 %3095, 520
  store i64 %3096, i64* %RCX, align 8, !tbaa !2428
  %3097 = lshr i64 %3096, 63
  %3098 = add i64 %3096, %3064
  store i64 %3098, i64* %RAX, align 8, !tbaa !2428
  %3099 = icmp ult i64 %3098, %3064
  %3100 = icmp ult i64 %3098, %3096
  %3101 = or i1 %3099, %3100
  %3102 = zext i1 %3101 to i8
  store i8 %3102, i8* %42, align 1, !tbaa !2432
  %3103 = trunc i64 %3098 to i32
  %3104 = and i32 %3103, 255
  %3105 = tail call i32 @llvm.ctpop.i32(i32 %3104) #8
  %3106 = trunc i32 %3105 to i8
  %3107 = and i8 %3106, 1
  %3108 = xor i8 %3107, 1
  store i8 %3108, i8* %49, align 1, !tbaa !2446
  %3109 = xor i64 %3096, %3064
  %3110 = xor i64 %3109, %3098
  %3111 = lshr i64 %3110, 4
  %3112 = trunc i64 %3111 to i8
  %3113 = and i8 %3112, 1
  store i8 %3113, i8* %54, align 1, !tbaa !2447
  %3114 = icmp eq i64 %3098, 0
  %3115 = zext i1 %3114 to i8
  store i8 %3115, i8* %57, align 1, !tbaa !2448
  %3116 = lshr i64 %3098, 63
  %3117 = trunc i64 %3116 to i8
  store i8 %3117, i8* %60, align 1, !tbaa !2449
  %3118 = xor i64 %3116, %3082
  %3119 = xor i64 %3116, %3097
  %3120 = add nuw nsw i64 %3118, %3119
  %3121 = icmp eq i64 %3120, 2
  %3122 = zext i1 %3121 to i8
  store i8 %3122, i8* %66, align 1, !tbaa !2450
  %3123 = add i64 %3090, -108
  %3124 = add i64 %3026, 62
  store i64 %3124, i64* %PC, align 8
  %3125 = inttoptr i64 %3123 to i32*
  %3126 = load i32, i32* %3125, align 4
  %3127 = sext i32 %3126 to i64
  store i64 %3127, i64* %RCX, align 8, !tbaa !2428
  %3128 = shl nsw i64 %3127, 3
  %3129 = add i64 %3128, %3098
  %3130 = add i64 %3026, 67
  store i64 %3130, i64* %PC, align 8
  %3131 = load double, double* %228, align 1
  %3132 = inttoptr i64 %3129 to double*
  %3133 = load double, double* %3132, align 8
  %3134 = fmul double %3131, %3133
  store double %3134, double* %228, align 1, !tbaa !2452
  %3135 = add i64 %3090, -64
  %3136 = add i64 %3026, 72
  store i64 %3136, i64* %PC, align 8
  %3137 = inttoptr i64 %3135 to double*
  %3138 = load double, double* %3137, align 8
  store double %3138, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %3139 = add i64 %3090, 64
  %3140 = add i64 %3026, 76
  store i64 %3140, i64* %PC, align 8
  %3141 = inttoptr i64 %3139 to i64*
  %3142 = load i64, i64* %3141, align 8
  store i64 %3142, i64* %RAX, align 8, !tbaa !2428
  %3143 = add i64 %3090, -100
  %3144 = add i64 %3026, 80
  store i64 %3144, i64* %PC, align 8
  %3145 = inttoptr i64 %3143 to i32*
  %3146 = load i32, i32* %3145, align 4
  %3147 = sext i32 %3146 to i64
  store i64 %3147, i64* %RCX, align 8, !tbaa !2428
  %3148 = shl nsw i64 %3147, 3
  %3149 = add i64 %3148, %3142
  %3150 = add i64 %3026, 85
  store i64 %3150, i64* %PC, align 8
  %3151 = inttoptr i64 %3149 to double*
  %3152 = load double, double* %3151, align 8
  %3153 = fmul double %3138, %3152
  store double %3153, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %3154 = load i64, i64* %RBP, align 8
  %3155 = add i64 %3154, 80
  %3156 = add i64 %3026, 89
  store i64 %3156, i64* %PC, align 8
  %3157 = inttoptr i64 %3155 to i64*
  %3158 = load i64, i64* %3157, align 8
  store i64 %3158, i64* %RAX, align 8, !tbaa !2428
  %3159 = add i64 %3154, -108
  %3160 = add i64 %3026, 93
  store i64 %3160, i64* %PC, align 8
  %3161 = inttoptr i64 %3159 to i32*
  %3162 = load i32, i32* %3161, align 4
  %3163 = sext i32 %3162 to i64
  store i64 %3163, i64* %RCX, align 8, !tbaa !2428
  %3164 = shl nsw i64 %3163, 3
  %3165 = add i64 %3164, %3158
  %3166 = add i64 %3026, 98
  store i64 %3166, i64* %PC, align 8
  %3167 = inttoptr i64 %3165 to double*
  %3168 = load double, double* %3167, align 8
  %3169 = fdiv double %3153, %3168
  store double %3169, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %3170 = add i64 %3154, 16
  %3171 = add i64 %3026, 102
  store i64 %3171, i64* %PC, align 8
  %3172 = inttoptr i64 %3170 to i64*
  %3173 = load i64, i64* %3172, align 8
  store i64 %3173, i64* %RAX, align 8, !tbaa !2428
  %3174 = add i64 %3154, -100
  %3175 = add i64 %3026, 106
  store i64 %3175, i64* %PC, align 8
  %3176 = inttoptr i64 %3174 to i32*
  %3177 = load i32, i32* %3176, align 4
  %3178 = sext i32 %3177 to i64
  %3179 = mul nsw i64 %3178, 520
  store i64 %3179, i64* %RCX, align 8, !tbaa !2428
  %3180 = lshr i64 %3179, 63
  %3181 = add i64 %3179, %3173
  store i64 %3181, i64* %RAX, align 8, !tbaa !2428
  %3182 = icmp ult i64 %3181, %3173
  %3183 = icmp ult i64 %3181, %3179
  %3184 = or i1 %3182, %3183
  %3185 = zext i1 %3184 to i8
  store i8 %3185, i8* %42, align 1, !tbaa !2432
  %3186 = trunc i64 %3181 to i32
  %3187 = and i32 %3186, 255
  %3188 = tail call i32 @llvm.ctpop.i32(i32 %3187) #8
  %3189 = trunc i32 %3188 to i8
  %3190 = and i8 %3189, 1
  %3191 = xor i8 %3190, 1
  store i8 %3191, i8* %49, align 1, !tbaa !2446
  %3192 = xor i64 %3179, %3173
  %3193 = xor i64 %3192, %3181
  %3194 = lshr i64 %3193, 4
  %3195 = trunc i64 %3194 to i8
  %3196 = and i8 %3195, 1
  store i8 %3196, i8* %54, align 1, !tbaa !2447
  %3197 = icmp eq i64 %3181, 0
  %3198 = zext i1 %3197 to i8
  store i8 %3198, i8* %57, align 1, !tbaa !2448
  %3199 = lshr i64 %3181, 63
  %3200 = trunc i64 %3199 to i8
  store i8 %3200, i8* %60, align 1, !tbaa !2449
  %3201 = lshr i64 %3173, 63
  %3202 = xor i64 %3199, %3201
  %3203 = xor i64 %3199, %3180
  %3204 = add nuw nsw i64 %3202, %3203
  %3205 = icmp eq i64 %3204, 2
  %3206 = zext i1 %3205 to i8
  store i8 %3206, i8* %66, align 1, !tbaa !2450
  %3207 = add i64 %3154, -104
  %3208 = add i64 %3026, 120
  store i64 %3208, i64* %PC, align 8
  %3209 = inttoptr i64 %3207 to i32*
  %3210 = load i32, i32* %3209, align 4
  %3211 = sext i32 %3210 to i64
  store i64 %3211, i64* %RCX, align 8, !tbaa !2428
  %3212 = shl nsw i64 %3211, 3
  %3213 = add i64 %3212, %3181
  %3214 = add i64 %3026, 125
  store i64 %3214, i64* %PC, align 8
  %3215 = inttoptr i64 %3213 to double*
  %3216 = load double, double* %3215, align 8
  %3217 = fmul double %3169, %3216
  store double %3217, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %3218 = load double, double* %228, align 1
  %3219 = fadd double %3218, %3217
  store double %3219, double* %228, align 1, !tbaa !2452
  %3220 = load i64, i64* %RBP, align 8
  %3221 = add i64 %3220, -64
  %3222 = add i64 %3026, 134
  store i64 %3222, i64* %PC, align 8
  %3223 = inttoptr i64 %3221 to double*
  %3224 = load double, double* %3223, align 8
  store double %3224, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %3225 = add i64 %3220, 56
  %3226 = add i64 %3026, 138
  store i64 %3226, i64* %PC, align 8
  %3227 = inttoptr i64 %3225 to i64*
  %3228 = load i64, i64* %3227, align 8
  store i64 %3228, i64* %RAX, align 8, !tbaa !2428
  %3229 = add i64 %3220, -100
  %3230 = add i64 %3026, 142
  store i64 %3230, i64* %PC, align 8
  %3231 = inttoptr i64 %3229 to i32*
  %3232 = load i32, i32* %3231, align 4
  %3233 = sext i32 %3232 to i64
  store i64 %3233, i64* %RCX, align 8, !tbaa !2428
  %3234 = shl nsw i64 %3233, 3
  %3235 = add i64 %3234, %3228
  %3236 = add i64 %3026, 147
  store i64 %3236, i64* %PC, align 8
  %3237 = inttoptr i64 %3235 to double*
  %3238 = load double, double* %3237, align 8
  %3239 = fmul double %3224, %3238
  store double %3239, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %3240 = add i64 %3220, 80
  %3241 = add i64 %3026, 151
  store i64 %3241, i64* %PC, align 8
  %3242 = inttoptr i64 %3240 to i64*
  %3243 = load i64, i64* %3242, align 8
  store i64 %3243, i64* %RAX, align 8, !tbaa !2428
  %3244 = add i64 %3220, -108
  %3245 = add i64 %3026, 155
  store i64 %3245, i64* %PC, align 8
  %3246 = inttoptr i64 %3244 to i32*
  %3247 = load i32, i32* %3246, align 4
  %3248 = sext i32 %3247 to i64
  store i64 %3248, i64* %RCX, align 8, !tbaa !2428
  %3249 = shl nsw i64 %3248, 3
  %3250 = add i64 %3249, %3243
  %3251 = add i64 %3026, 160
  store i64 %3251, i64* %PC, align 8
  %3252 = inttoptr i64 %3250 to double*
  %3253 = load double, double* %3252, align 8
  %3254 = fdiv double %3239, %3253
  store double %3254, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %3255 = add i64 %3220, 24
  %3256 = add i64 %3026, 164
  store i64 %3256, i64* %PC, align 8
  %3257 = inttoptr i64 %3255 to i64*
  %3258 = load i64, i64* %3257, align 8
  store i64 %3258, i64* %RAX, align 8, !tbaa !2428
  %3259 = add i64 %3026, 168
  store i64 %3259, i64* %PC, align 8
  %3260 = load i32, i32* %3231, align 4
  %3261 = sext i32 %3260 to i64
  %3262 = mul nsw i64 %3261, 33800
  store i64 %3262, i64* %RCX, align 8, !tbaa !2428
  %3263 = lshr i64 %3262, 63
  %3264 = add i64 %3262, %3258
  store i64 %3264, i64* %RAX, align 8, !tbaa !2428
  %3265 = icmp ult i64 %3264, %3258
  %3266 = icmp ult i64 %3264, %3262
  %3267 = or i1 %3265, %3266
  %3268 = zext i1 %3267 to i8
  store i8 %3268, i8* %42, align 1, !tbaa !2432
  %3269 = trunc i64 %3264 to i32
  %3270 = and i32 %3269, 255
  %3271 = tail call i32 @llvm.ctpop.i32(i32 %3270) #8
  %3272 = trunc i32 %3271 to i8
  %3273 = and i8 %3272, 1
  %3274 = xor i8 %3273, 1
  store i8 %3274, i8* %49, align 1, !tbaa !2446
  %3275 = xor i64 %3262, %3258
  %3276 = xor i64 %3275, %3264
  %3277 = lshr i64 %3276, 4
  %3278 = trunc i64 %3277 to i8
  %3279 = and i8 %3278, 1
  store i8 %3279, i8* %54, align 1, !tbaa !2447
  %3280 = icmp eq i64 %3264, 0
  %3281 = zext i1 %3280 to i8
  store i8 %3281, i8* %57, align 1, !tbaa !2448
  %3282 = lshr i64 %3264, 63
  %3283 = trunc i64 %3282 to i8
  store i8 %3283, i8* %60, align 1, !tbaa !2449
  %3284 = lshr i64 %3258, 63
  %3285 = xor i64 %3282, %3284
  %3286 = xor i64 %3282, %3263
  %3287 = add nuw nsw i64 %3285, %3286
  %3288 = icmp eq i64 %3287, 2
  %3289 = zext i1 %3288 to i8
  store i8 %3289, i8* %66, align 1, !tbaa !2450
  %3290 = load i64, i64* %RBP, align 8
  %3291 = add i64 %3290, -52
  %3292 = add i64 %3026, 182
  store i64 %3292, i64* %PC, align 8
  %3293 = inttoptr i64 %3291 to i32*
  %3294 = load i32, i32* %3293, align 4
  %3295 = sext i32 %3294 to i64
  %3296 = mul nsw i64 %3295, 520
  store i64 %3296, i64* %RCX, align 8, !tbaa !2428
  %3297 = lshr i64 %3296, 63
  %3298 = add i64 %3296, %3264
  store i64 %3298, i64* %RAX, align 8, !tbaa !2428
  %3299 = icmp ult i64 %3298, %3264
  %3300 = icmp ult i64 %3298, %3296
  %3301 = or i1 %3299, %3300
  %3302 = zext i1 %3301 to i8
  store i8 %3302, i8* %42, align 1, !tbaa !2432
  %3303 = trunc i64 %3298 to i32
  %3304 = and i32 %3303, 255
  %3305 = tail call i32 @llvm.ctpop.i32(i32 %3304) #8
  %3306 = trunc i32 %3305 to i8
  %3307 = and i8 %3306, 1
  %3308 = xor i8 %3307, 1
  store i8 %3308, i8* %49, align 1, !tbaa !2446
  %3309 = xor i64 %3296, %3264
  %3310 = xor i64 %3309, %3298
  %3311 = lshr i64 %3310, 4
  %3312 = trunc i64 %3311 to i8
  %3313 = and i8 %3312, 1
  store i8 %3313, i8* %54, align 1, !tbaa !2447
  %3314 = icmp eq i64 %3298, 0
  %3315 = zext i1 %3314 to i8
  store i8 %3315, i8* %57, align 1, !tbaa !2448
  %3316 = lshr i64 %3298, 63
  %3317 = trunc i64 %3316 to i8
  store i8 %3317, i8* %60, align 1, !tbaa !2449
  %3318 = xor i64 %3316, %3282
  %3319 = xor i64 %3316, %3297
  %3320 = add nuw nsw i64 %3318, %3319
  %3321 = icmp eq i64 %3320, 2
  %3322 = zext i1 %3321 to i8
  store i8 %3322, i8* %66, align 1, !tbaa !2450
  %3323 = add i64 %3290, -108
  %3324 = add i64 %3026, 196
  store i64 %3324, i64* %PC, align 8
  %3325 = inttoptr i64 %3323 to i32*
  %3326 = load i32, i32* %3325, align 4
  %3327 = sext i32 %3326 to i64
  store i64 %3327, i64* %RCX, align 8, !tbaa !2428
  %3328 = shl nsw i64 %3327, 3
  %3329 = add i64 %3328, %3298
  %3330 = add i64 %3026, 201
  store i64 %3330, i64* %PC, align 8
  %3331 = load double, double* %231, align 1
  %3332 = inttoptr i64 %3329 to double*
  %3333 = load double, double* %3332, align 8
  %3334 = fmul double %3331, %3333
  store double %3334, double* %231, align 1, !tbaa !2452
  %3335 = load double, double* %228, align 1
  %3336 = fsub double %3335, %3334
  store double %3336, double* %228, align 1, !tbaa !2452
  %3337 = add i64 %3290, 48
  %3338 = add i64 %3026, 209
  store i64 %3338, i64* %PC, align 8
  %3339 = inttoptr i64 %3337 to i64*
  %3340 = load i64, i64* %3339, align 8
  store i64 %3340, i64* %RAX, align 8, !tbaa !2428
  %3341 = add i64 %3290, -100
  %3342 = add i64 %3026, 213
  store i64 %3342, i64* %PC, align 8
  %3343 = inttoptr i64 %3341 to i32*
  %3344 = load i32, i32* %3343, align 4
  %3345 = sext i32 %3344 to i64
  %3346 = mul nsw i64 %3345, 33800
  store i64 %3346, i64* %RCX, align 8, !tbaa !2428
  %3347 = lshr i64 %3346, 63
  %3348 = add i64 %3346, %3340
  store i64 %3348, i64* %RAX, align 8, !tbaa !2428
  %3349 = icmp ult i64 %3348, %3340
  %3350 = icmp ult i64 %3348, %3346
  %3351 = or i1 %3349, %3350
  %3352 = zext i1 %3351 to i8
  store i8 %3352, i8* %42, align 1, !tbaa !2432
  %3353 = trunc i64 %3348 to i32
  %3354 = and i32 %3353, 255
  %3355 = tail call i32 @llvm.ctpop.i32(i32 %3354) #8
  %3356 = trunc i32 %3355 to i8
  %3357 = and i8 %3356, 1
  %3358 = xor i8 %3357, 1
  store i8 %3358, i8* %49, align 1, !tbaa !2446
  %3359 = xor i64 %3346, %3340
  %3360 = xor i64 %3359, %3348
  %3361 = lshr i64 %3360, 4
  %3362 = trunc i64 %3361 to i8
  %3363 = and i8 %3362, 1
  store i8 %3363, i8* %54, align 1, !tbaa !2447
  %3364 = icmp eq i64 %3348, 0
  %3365 = zext i1 %3364 to i8
  store i8 %3365, i8* %57, align 1, !tbaa !2448
  %3366 = lshr i64 %3348, 63
  %3367 = trunc i64 %3366 to i8
  store i8 %3367, i8* %60, align 1, !tbaa !2449
  %3368 = lshr i64 %3340, 63
  %3369 = xor i64 %3366, %3368
  %3370 = xor i64 %3366, %3347
  %3371 = add nuw nsw i64 %3369, %3370
  %3372 = icmp eq i64 %3371, 2
  %3373 = zext i1 %3372 to i8
  store i8 %3373, i8* %66, align 1, !tbaa !2450
  %3374 = load i64, i64* %RBP, align 8
  %3375 = add i64 %3374, -52
  %3376 = add i64 %3026, 227
  store i64 %3376, i64* %PC, align 8
  %3377 = inttoptr i64 %3375 to i32*
  %3378 = load i32, i32* %3377, align 4
  %3379 = sext i32 %3378 to i64
  %3380 = mul nsw i64 %3379, 520
  store i64 %3380, i64* %RCX, align 8, !tbaa !2428
  %3381 = lshr i64 %3380, 63
  %3382 = add i64 %3380, %3348
  store i64 %3382, i64* %RAX, align 8, !tbaa !2428
  %3383 = icmp ult i64 %3382, %3348
  %3384 = icmp ult i64 %3382, %3380
  %3385 = or i1 %3383, %3384
  %3386 = zext i1 %3385 to i8
  store i8 %3386, i8* %42, align 1, !tbaa !2432
  %3387 = trunc i64 %3382 to i32
  %3388 = and i32 %3387, 255
  %3389 = tail call i32 @llvm.ctpop.i32(i32 %3388) #8
  %3390 = trunc i32 %3389 to i8
  %3391 = and i8 %3390, 1
  %3392 = xor i8 %3391, 1
  store i8 %3392, i8* %49, align 1, !tbaa !2446
  %3393 = xor i64 %3380, %3348
  %3394 = xor i64 %3393, %3382
  %3395 = lshr i64 %3394, 4
  %3396 = trunc i64 %3395 to i8
  %3397 = and i8 %3396, 1
  store i8 %3397, i8* %54, align 1, !tbaa !2447
  %3398 = icmp eq i64 %3382, 0
  %3399 = zext i1 %3398 to i8
  store i8 %3399, i8* %57, align 1, !tbaa !2448
  %3400 = lshr i64 %3382, 63
  %3401 = trunc i64 %3400 to i8
  store i8 %3401, i8* %60, align 1, !tbaa !2449
  %3402 = xor i64 %3400, %3366
  %3403 = xor i64 %3400, %3381
  %3404 = add nuw nsw i64 %3402, %3403
  %3405 = icmp eq i64 %3404, 2
  %3406 = zext i1 %3405 to i8
  store i8 %3406, i8* %66, align 1, !tbaa !2450
  %3407 = add i64 %3374, -108
  %3408 = add i64 %3026, 241
  store i64 %3408, i64* %PC, align 8
  %3409 = inttoptr i64 %3407 to i32*
  %3410 = load i32, i32* %3409, align 4
  %3411 = sext i32 %3410 to i64
  store i64 %3411, i64* %RCX, align 8, !tbaa !2428
  %3412 = shl nsw i64 %3411, 3
  %3413 = add i64 %3412, %3382
  %3414 = add i64 %3026, 246
  store i64 %3414, i64* %PC, align 8
  %3415 = load i64, i64* %147, align 1
  %3416 = inttoptr i64 %3413 to i64*
  store i64 %3415, i64* %3416, align 8
  %3417 = load i64, i64* %RBP, align 8
  %3418 = add i64 %3417, 16
  %3419 = load i64, i64* %PC, align 8
  %3420 = add i64 %3419, 4
  store i64 %3420, i64* %PC, align 8
  %3421 = inttoptr i64 %3418 to i64*
  %3422 = load i64, i64* %3421, align 8
  store i64 %3422, i64* %RAX, align 8, !tbaa !2428
  %3423 = add i64 %3417, -100
  %3424 = add i64 %3419, 8
  store i64 %3424, i64* %PC, align 8
  %3425 = inttoptr i64 %3423 to i32*
  %3426 = load i32, i32* %3425, align 4
  %3427 = sext i32 %3426 to i64
  %3428 = mul nsw i64 %3427, 520
  store i64 %3428, i64* %RCX, align 8, !tbaa !2428
  %3429 = lshr i64 %3428, 63
  %3430 = add i64 %3428, %3422
  store i64 %3430, i64* %RAX, align 8, !tbaa !2428
  %3431 = icmp ult i64 %3430, %3422
  %3432 = icmp ult i64 %3430, %3428
  %3433 = or i1 %3431, %3432
  %3434 = zext i1 %3433 to i8
  store i8 %3434, i8* %42, align 1, !tbaa !2432
  %3435 = trunc i64 %3430 to i32
  %3436 = and i32 %3435, 255
  %3437 = tail call i32 @llvm.ctpop.i32(i32 %3436) #8
  %3438 = trunc i32 %3437 to i8
  %3439 = and i8 %3438, 1
  %3440 = xor i8 %3439, 1
  store i8 %3440, i8* %49, align 1, !tbaa !2446
  %3441 = xor i64 %3428, %3422
  %3442 = xor i64 %3441, %3430
  %3443 = lshr i64 %3442, 4
  %3444 = trunc i64 %3443 to i8
  %3445 = and i8 %3444, 1
  store i8 %3445, i8* %54, align 1, !tbaa !2447
  %3446 = icmp eq i64 %3430, 0
  %3447 = zext i1 %3446 to i8
  store i8 %3447, i8* %57, align 1, !tbaa !2448
  %3448 = lshr i64 %3430, 63
  %3449 = trunc i64 %3448 to i8
  store i8 %3449, i8* %60, align 1, !tbaa !2449
  %3450 = lshr i64 %3422, 63
  %3451 = xor i64 %3448, %3450
  %3452 = xor i64 %3448, %3429
  %3453 = add nuw nsw i64 %3451, %3452
  %3454 = icmp eq i64 %3453, 2
  %3455 = zext i1 %3454 to i8
  store i8 %3455, i8* %66, align 1, !tbaa !2450
  %3456 = add i64 %3417, -104
  %3457 = add i64 %3419, 22
  store i64 %3457, i64* %PC, align 8
  %3458 = inttoptr i64 %3456 to i32*
  %3459 = load i32, i32* %3458, align 4
  %3460 = sext i32 %3459 to i64
  store i64 %3460, i64* %RCX, align 8, !tbaa !2428
  %3461 = shl nsw i64 %3460, 3
  %3462 = add i64 %3461, %3430
  %3463 = add i64 %3419, 27
  store i64 %3463, i64* %PC, align 8
  %3464 = inttoptr i64 %3462 to i64*
  %3465 = load i64, i64* %3464, align 8
  store i64 %3465, i64* %147, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %3466 = add i64 %3417, 24
  %3467 = add i64 %3419, 31
  store i64 %3467, i64* %PC, align 8
  %3468 = inttoptr i64 %3466 to i64*
  %3469 = load i64, i64* %3468, align 8
  store i64 %3469, i64* %RAX, align 8, !tbaa !2428
  %3470 = add i64 %3419, 35
  store i64 %3470, i64* %PC, align 8
  %3471 = load i32, i32* %3425, align 4
  %3472 = sext i32 %3471 to i64
  %3473 = mul nsw i64 %3472, 33800
  store i64 %3473, i64* %RCX, align 8, !tbaa !2428
  %3474 = lshr i64 %3473, 63
  %3475 = add i64 %3473, %3469
  store i64 %3475, i64* %RAX, align 8, !tbaa !2428
  %3476 = icmp ult i64 %3475, %3469
  %3477 = icmp ult i64 %3475, %3473
  %3478 = or i1 %3476, %3477
  %3479 = zext i1 %3478 to i8
  store i8 %3479, i8* %42, align 1, !tbaa !2432
  %3480 = trunc i64 %3475 to i32
  %3481 = and i32 %3480, 255
  %3482 = tail call i32 @llvm.ctpop.i32(i32 %3481) #8
  %3483 = trunc i32 %3482 to i8
  %3484 = and i8 %3483, 1
  %3485 = xor i8 %3484, 1
  store i8 %3485, i8* %49, align 1, !tbaa !2446
  %3486 = xor i64 %3473, %3469
  %3487 = xor i64 %3486, %3475
  %3488 = lshr i64 %3487, 4
  %3489 = trunc i64 %3488 to i8
  %3490 = and i8 %3489, 1
  store i8 %3490, i8* %54, align 1, !tbaa !2447
  %3491 = icmp eq i64 %3475, 0
  %3492 = zext i1 %3491 to i8
  store i8 %3492, i8* %57, align 1, !tbaa !2448
  %3493 = lshr i64 %3475, 63
  %3494 = trunc i64 %3493 to i8
  store i8 %3494, i8* %60, align 1, !tbaa !2449
  %3495 = lshr i64 %3469, 63
  %3496 = xor i64 %3493, %3495
  %3497 = xor i64 %3493, %3474
  %3498 = add nuw nsw i64 %3496, %3497
  %3499 = icmp eq i64 %3498, 2
  %3500 = zext i1 %3499 to i8
  store i8 %3500, i8* %66, align 1, !tbaa !2450
  %3501 = load i64, i64* %RBP, align 8
  %3502 = add i64 %3501, -52
  %3503 = add i64 %3419, 49
  store i64 %3503, i64* %PC, align 8
  %3504 = inttoptr i64 %3502 to i32*
  %3505 = load i32, i32* %3504, align 4
  %3506 = sext i32 %3505 to i64
  %3507 = mul nsw i64 %3506, 520
  store i64 %3507, i64* %RCX, align 8, !tbaa !2428
  %3508 = lshr i64 %3507, 63
  %3509 = add i64 %3507, %3475
  store i64 %3509, i64* %RAX, align 8, !tbaa !2428
  %3510 = icmp ult i64 %3509, %3475
  %3511 = icmp ult i64 %3509, %3507
  %3512 = or i1 %3510, %3511
  %3513 = zext i1 %3512 to i8
  store i8 %3513, i8* %42, align 1, !tbaa !2432
  %3514 = trunc i64 %3509 to i32
  %3515 = and i32 %3514, 255
  %3516 = tail call i32 @llvm.ctpop.i32(i32 %3515) #8
  %3517 = trunc i32 %3516 to i8
  %3518 = and i8 %3517, 1
  %3519 = xor i8 %3518, 1
  store i8 %3519, i8* %49, align 1, !tbaa !2446
  %3520 = xor i64 %3507, %3475
  %3521 = xor i64 %3520, %3509
  %3522 = lshr i64 %3521, 4
  %3523 = trunc i64 %3522 to i8
  %3524 = and i8 %3523, 1
  store i8 %3524, i8* %54, align 1, !tbaa !2447
  %3525 = icmp eq i64 %3509, 0
  %3526 = zext i1 %3525 to i8
  store i8 %3526, i8* %57, align 1, !tbaa !2448
  %3527 = lshr i64 %3509, 63
  %3528 = trunc i64 %3527 to i8
  store i8 %3528, i8* %60, align 1, !tbaa !2449
  %3529 = xor i64 %3527, %3493
  %3530 = xor i64 %3527, %3508
  %3531 = add nuw nsw i64 %3529, %3530
  %3532 = icmp eq i64 %3531, 2
  %3533 = zext i1 %3532 to i8
  store i8 %3533, i8* %66, align 1, !tbaa !2450
  %3534 = add i64 %3501, -108
  %3535 = add i64 %3419, 63
  store i64 %3535, i64* %PC, align 8
  %3536 = inttoptr i64 %3534 to i32*
  %3537 = load i32, i32* %3536, align 4
  %3538 = sext i32 %3537 to i64
  store i64 %3538, i64* %RCX, align 8, !tbaa !2428
  %3539 = shl nsw i64 %3538, 3
  %3540 = add i64 %3539, %3509
  %3541 = add i64 %3419, 68
  store i64 %3541, i64* %PC, align 8
  %3542 = load i64, i64* %147, align 1
  %3543 = inttoptr i64 %3540 to i64*
  store i64 %3542, i64* %3543, align 8
  %3544 = load i64, i64* %RBP, align 8
  %3545 = add i64 %3544, -108
  %3546 = load i64, i64* %PC, align 8
  %3547 = add i64 %3546, 3
  store i64 %3547, i64* %PC, align 8
  %3548 = inttoptr i64 %3545 to i32*
  %3549 = load i32, i32* %3548, align 4
  %3550 = add i32 %3549, 1
  %3551 = zext i32 %3550 to i64
  store i64 %3551, i64* %RAX, align 8, !tbaa !2428
  %3552 = icmp eq i32 %3549, -1
  %3553 = icmp eq i32 %3550, 0
  %3554 = or i1 %3552, %3553
  %3555 = zext i1 %3554 to i8
  store i8 %3555, i8* %42, align 1, !tbaa !2432
  %3556 = and i32 %3550, 255
  %3557 = tail call i32 @llvm.ctpop.i32(i32 %3556) #8
  %3558 = trunc i32 %3557 to i8
  %3559 = and i8 %3558, 1
  %3560 = xor i8 %3559, 1
  store i8 %3560, i8* %49, align 1, !tbaa !2446
  %3561 = xor i32 %3549, %3550
  %3562 = lshr i32 %3561, 4
  %3563 = trunc i32 %3562 to i8
  %3564 = and i8 %3563, 1
  store i8 %3564, i8* %54, align 1, !tbaa !2447
  %3565 = zext i1 %3553 to i8
  store i8 %3565, i8* %57, align 1, !tbaa !2448
  %3566 = lshr i32 %3550, 31
  %3567 = trunc i32 %3566 to i8
  store i8 %3567, i8* %60, align 1, !tbaa !2449
  %3568 = lshr i32 %3549, 31
  %3569 = xor i32 %3566, %3568
  %3570 = add nuw nsw i32 %3569, %3566
  %3571 = icmp eq i32 %3570, 2
  %3572 = zext i1 %3571 to i8
  store i8 %3572, i8* %66, align 1, !tbaa !2450
  %3573 = add i64 %3546, 9
  store i64 %3573, i64* %PC, align 8
  store i32 %3550, i32* %3548, align 4
  %3574 = load i64, i64* %PC, align 8
  %3575 = add i64 %3574, -660
  store i64 %3575, i64* %PC, align 8, !tbaa !2428
  br label %block_4019d2

block_4014ac:                                     ; preds = %block_4014a0
  %3576 = add i64 %4790, -108
  %3577 = add i64 %4752, 36
  store i64 %3577, i64* %PC, align 8
  %3578 = inttoptr i64 %3576 to i32*
  %3579 = load i32, i32* %3578, align 4
  %3580 = sext i32 %3579 to i64
  store i64 %3580, i64* %RCX, align 8, !tbaa !2428
  %3581 = shl nsw i64 %3580, 3
  %3582 = add i64 %3581, %4799
  %3583 = add i64 %4752, 41
  store i64 %3583, i64* %PC, align 8
  %3584 = inttoptr i64 %3582 to i64*
  %3585 = load i64, i64* %3584, align 8
  store i64 %3585, i64* %147, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %3586 = add i64 %4790, 32
  %3587 = add i64 %4752, 45
  store i64 %3587, i64* %PC, align 8
  %3588 = inttoptr i64 %3586 to i64*
  %3589 = load i64, i64* %3588, align 8
  store i64 %3589, i64* %RAX, align 8, !tbaa !2428
  %3590 = add i64 %4790, -100
  %3591 = add i64 %4752, 49
  store i64 %3591, i64* %PC, align 8
  %3592 = inttoptr i64 %3590 to i32*
  %3593 = load i32, i32* %3592, align 4
  %3594 = sext i32 %3593 to i64
  %3595 = mul nsw i64 %3594, 33800
  store i64 %3595, i64* %RCX, align 8, !tbaa !2428
  %3596 = lshr i64 %3595, 63
  %3597 = add i64 %3595, %3589
  store i64 %3597, i64* %RAX, align 8, !tbaa !2428
  %3598 = icmp ult i64 %3597, %3589
  %3599 = icmp ult i64 %3597, %3595
  %3600 = or i1 %3598, %3599
  %3601 = zext i1 %3600 to i8
  store i8 %3601, i8* %42, align 1, !tbaa !2432
  %3602 = trunc i64 %3597 to i32
  %3603 = and i32 %3602, 255
  %3604 = tail call i32 @llvm.ctpop.i32(i32 %3603) #8
  %3605 = trunc i32 %3604 to i8
  %3606 = and i8 %3605, 1
  %3607 = xor i8 %3606, 1
  store i8 %3607, i8* %49, align 1, !tbaa !2446
  %3608 = xor i64 %3595, %3589
  %3609 = xor i64 %3608, %3597
  %3610 = lshr i64 %3609, 4
  %3611 = trunc i64 %3610 to i8
  %3612 = and i8 %3611, 1
  store i8 %3612, i8* %54, align 1, !tbaa !2447
  %3613 = icmp eq i64 %3597, 0
  %3614 = zext i1 %3613 to i8
  store i8 %3614, i8* %57, align 1, !tbaa !2448
  %3615 = lshr i64 %3597, 63
  %3616 = trunc i64 %3615 to i8
  store i8 %3616, i8* %60, align 1, !tbaa !2449
  %3617 = lshr i64 %3589, 63
  %3618 = xor i64 %3615, %3617
  %3619 = xor i64 %3615, %3596
  %3620 = add nuw nsw i64 %3618, %3619
  %3621 = icmp eq i64 %3620, 2
  %3622 = zext i1 %3621 to i8
  store i8 %3622, i8* %66, align 1, !tbaa !2450
  %3623 = add i64 %4752, 62
  store i64 %3623, i64* %PC, align 8
  %3624 = load i32, i32* %4793, align 4
  %3625 = add i32 %3624, 1
  %3626 = zext i32 %3625 to i64
  store i64 %3626, i64* %RDX, align 8, !tbaa !2428
  %3627 = sext i32 %3625 to i64
  %3628 = mul nsw i64 %3627, 520
  store i64 %3628, i64* %RCX, align 8, !tbaa !2428
  %3629 = lshr i64 %3628, 63
  %3630 = load i64, i64* %RAX, align 8
  %3631 = add i64 %3628, %3630
  store i64 %3631, i64* %RAX, align 8, !tbaa !2428
  %3632 = icmp ult i64 %3631, %3630
  %3633 = icmp ult i64 %3631, %3628
  %3634 = or i1 %3632, %3633
  %3635 = zext i1 %3634 to i8
  store i8 %3635, i8* %42, align 1, !tbaa !2432
  %3636 = trunc i64 %3631 to i32
  %3637 = and i32 %3636, 255
  %3638 = tail call i32 @llvm.ctpop.i32(i32 %3637) #8
  %3639 = trunc i32 %3638 to i8
  %3640 = and i8 %3639, 1
  %3641 = xor i8 %3640, 1
  store i8 %3641, i8* %49, align 1, !tbaa !2446
  %3642 = xor i64 %3628, %3630
  %3643 = xor i64 %3642, %3631
  %3644 = lshr i64 %3643, 4
  %3645 = trunc i64 %3644 to i8
  %3646 = and i8 %3645, 1
  store i8 %3646, i8* %54, align 1, !tbaa !2447
  %3647 = icmp eq i64 %3631, 0
  %3648 = zext i1 %3647 to i8
  store i8 %3648, i8* %57, align 1, !tbaa !2448
  %3649 = lshr i64 %3631, 63
  %3650 = trunc i64 %3649 to i8
  store i8 %3650, i8* %60, align 1, !tbaa !2449
  %3651 = lshr i64 %3630, 63
  %3652 = xor i64 %3649, %3651
  %3653 = xor i64 %3649, %3629
  %3654 = add nuw nsw i64 %3652, %3653
  %3655 = icmp eq i64 %3654, 2
  %3656 = zext i1 %3655 to i8
  store i8 %3656, i8* %66, align 1, !tbaa !2450
  %3657 = load i64, i64* %RBP, align 8
  %3658 = add i64 %3657, -108
  %3659 = add i64 %4752, 82
  store i64 %3659, i64* %PC, align 8
  %3660 = inttoptr i64 %3658 to i32*
  %3661 = load i32, i32* %3660, align 4
  %3662 = sext i32 %3661 to i64
  store i64 %3662, i64* %RCX, align 8, !tbaa !2428
  %3663 = shl nsw i64 %3662, 3
  %3664 = add i64 %3663, %3631
  %3665 = add i64 %4752, 87
  store i64 %3665, i64* %PC, align 8
  %3666 = load double, double* %228, align 1
  %3667 = inttoptr i64 %3664 to double*
  %3668 = load double, double* %3667, align 8
  %3669 = fsub double %3666, %3668
  store double %3669, double* %228, align 1, !tbaa !2452
  %3670 = add i64 %3657, 40
  %3671 = add i64 %4752, 91
  store i64 %3671, i64* %PC, align 8
  %3672 = inttoptr i64 %3670 to i64*
  %3673 = load i64, i64* %3672, align 8
  store i64 %3673, i64* %RAX, align 8, !tbaa !2428
  %3674 = add i64 %3657, -100
  %3675 = add i64 %4752, 95
  store i64 %3675, i64* %PC, align 8
  %3676 = inttoptr i64 %3674 to i32*
  %3677 = load i32, i32* %3676, align 4
  %3678 = sext i32 %3677 to i64
  %3679 = mul nsw i64 %3678, 33800
  store i64 %3679, i64* %RCX, align 8, !tbaa !2428
  %3680 = lshr i64 %3679, 63
  %3681 = add i64 %3679, %3673
  store i64 %3681, i64* %RAX, align 8, !tbaa !2428
  %3682 = icmp ult i64 %3681, %3673
  %3683 = icmp ult i64 %3681, %3679
  %3684 = or i1 %3682, %3683
  %3685 = zext i1 %3684 to i8
  store i8 %3685, i8* %42, align 1, !tbaa !2432
  %3686 = trunc i64 %3681 to i32
  %3687 = and i32 %3686, 255
  %3688 = tail call i32 @llvm.ctpop.i32(i32 %3687) #8
  %3689 = trunc i32 %3688 to i8
  %3690 = and i8 %3689, 1
  %3691 = xor i8 %3690, 1
  store i8 %3691, i8* %49, align 1, !tbaa !2446
  %3692 = xor i64 %3679, %3673
  %3693 = xor i64 %3692, %3681
  %3694 = lshr i64 %3693, 4
  %3695 = trunc i64 %3694 to i8
  %3696 = and i8 %3695, 1
  store i8 %3696, i8* %54, align 1, !tbaa !2447
  %3697 = icmp eq i64 %3681, 0
  %3698 = zext i1 %3697 to i8
  store i8 %3698, i8* %57, align 1, !tbaa !2448
  %3699 = lshr i64 %3681, 63
  %3700 = trunc i64 %3699 to i8
  store i8 %3700, i8* %60, align 1, !tbaa !2449
  %3701 = lshr i64 %3673, 63
  %3702 = xor i64 %3699, %3701
  %3703 = xor i64 %3699, %3680
  %3704 = add nuw nsw i64 %3702, %3703
  %3705 = icmp eq i64 %3704, 2
  %3706 = zext i1 %3705 to i8
  store i8 %3706, i8* %66, align 1, !tbaa !2450
  %3707 = add i64 %3657, -104
  %3708 = add i64 %4752, 109
  store i64 %3708, i64* %PC, align 8
  %3709 = inttoptr i64 %3707 to i32*
  %3710 = load i32, i32* %3709, align 4
  %3711 = sext i32 %3710 to i64
  %3712 = mul nsw i64 %3711, 520
  store i64 %3712, i64* %RCX, align 8, !tbaa !2428
  %3713 = lshr i64 %3712, 63
  %3714 = add i64 %3712, %3681
  store i64 %3714, i64* %RAX, align 8, !tbaa !2428
  %3715 = icmp ult i64 %3714, %3681
  %3716 = icmp ult i64 %3714, %3712
  %3717 = or i1 %3715, %3716
  %3718 = zext i1 %3717 to i8
  store i8 %3718, i8* %42, align 1, !tbaa !2432
  %3719 = trunc i64 %3714 to i32
  %3720 = and i32 %3719, 255
  %3721 = tail call i32 @llvm.ctpop.i32(i32 %3720) #8
  %3722 = trunc i32 %3721 to i8
  %3723 = and i8 %3722, 1
  %3724 = xor i8 %3723, 1
  store i8 %3724, i8* %49, align 1, !tbaa !2446
  %3725 = xor i64 %3712, %3681
  %3726 = xor i64 %3725, %3714
  %3727 = lshr i64 %3726, 4
  %3728 = trunc i64 %3727 to i8
  %3729 = and i8 %3728, 1
  store i8 %3729, i8* %54, align 1, !tbaa !2447
  %3730 = icmp eq i64 %3714, 0
  %3731 = zext i1 %3730 to i8
  store i8 %3731, i8* %57, align 1, !tbaa !2448
  %3732 = lshr i64 %3714, 63
  %3733 = trunc i64 %3732 to i8
  store i8 %3733, i8* %60, align 1, !tbaa !2449
  %3734 = xor i64 %3732, %3699
  %3735 = xor i64 %3732, %3713
  %3736 = add nuw nsw i64 %3734, %3735
  %3737 = icmp eq i64 %3736, 2
  %3738 = zext i1 %3737 to i8
  store i8 %3738, i8* %66, align 1, !tbaa !2450
  %3739 = load i64, i64* %RBP, align 8
  %3740 = add i64 %3739, -108
  %3741 = add i64 %4752, 122
  store i64 %3741, i64* %PC, align 8
  %3742 = inttoptr i64 %3740 to i32*
  %3743 = load i32, i32* %3742, align 4
  %3744 = add i32 %3743, 1
  %3745 = zext i32 %3744 to i64
  store i64 %3745, i64* %RDX, align 8, !tbaa !2428
  %3746 = icmp eq i32 %3743, -1
  %3747 = icmp eq i32 %3744, 0
  %3748 = or i1 %3746, %3747
  %3749 = zext i1 %3748 to i8
  store i8 %3749, i8* %42, align 1, !tbaa !2432
  %3750 = and i32 %3744, 255
  %3751 = tail call i32 @llvm.ctpop.i32(i32 %3750) #8
  %3752 = trunc i32 %3751 to i8
  %3753 = and i8 %3752, 1
  %3754 = xor i8 %3753, 1
  store i8 %3754, i8* %49, align 1, !tbaa !2446
  %3755 = xor i32 %3743, %3744
  %3756 = lshr i32 %3755, 4
  %3757 = trunc i32 %3756 to i8
  %3758 = and i8 %3757, 1
  store i8 %3758, i8* %54, align 1, !tbaa !2447
  %3759 = zext i1 %3747 to i8
  store i8 %3759, i8* %57, align 1, !tbaa !2448
  %3760 = lshr i32 %3744, 31
  %3761 = trunc i32 %3760 to i8
  store i8 %3761, i8* %60, align 1, !tbaa !2449
  %3762 = lshr i32 %3743, 31
  %3763 = xor i32 %3760, %3762
  %3764 = add nuw nsw i32 %3763, %3760
  %3765 = icmp eq i32 %3764, 2
  %3766 = zext i1 %3765 to i8
  store i8 %3766, i8* %66, align 1, !tbaa !2450
  %3767 = sext i32 %3744 to i64
  store i64 %3767, i64* %RCX, align 8, !tbaa !2428
  %3768 = shl nsw i64 %3767, 3
  %3769 = add i64 %3768, %3714
  %3770 = add i64 %4752, 133
  store i64 %3770, i64* %PC, align 8
  %3771 = load double, double* %228, align 1
  %3772 = inttoptr i64 %3769 to double*
  %3773 = load double, double* %3772, align 8
  %3774 = fadd double %3771, %3773
  store double %3774, double* %228, align 1, !tbaa !2452
  %3775 = add i64 %3739, 40
  %3776 = add i64 %4752, 137
  store i64 %3776, i64* %PC, align 8
  %3777 = inttoptr i64 %3775 to i64*
  %3778 = load i64, i64* %3777, align 8
  store i64 %3778, i64* %RAX, align 8, !tbaa !2428
  %3779 = add i64 %3739, -100
  %3780 = add i64 %4752, 141
  store i64 %3780, i64* %PC, align 8
  %3781 = inttoptr i64 %3779 to i32*
  %3782 = load i32, i32* %3781, align 4
  %3783 = sext i32 %3782 to i64
  %3784 = mul nsw i64 %3783, 33800
  store i64 %3784, i64* %RCX, align 8, !tbaa !2428
  %3785 = lshr i64 %3784, 63
  %3786 = add i64 %3784, %3778
  store i64 %3786, i64* %RAX, align 8, !tbaa !2428
  %3787 = icmp ult i64 %3786, %3778
  %3788 = icmp ult i64 %3786, %3784
  %3789 = or i1 %3787, %3788
  %3790 = zext i1 %3789 to i8
  store i8 %3790, i8* %42, align 1, !tbaa !2432
  %3791 = trunc i64 %3786 to i32
  %3792 = and i32 %3791, 255
  %3793 = tail call i32 @llvm.ctpop.i32(i32 %3792) #8
  %3794 = trunc i32 %3793 to i8
  %3795 = and i8 %3794, 1
  %3796 = xor i8 %3795, 1
  store i8 %3796, i8* %49, align 1, !tbaa !2446
  %3797 = xor i64 %3784, %3778
  %3798 = xor i64 %3797, %3786
  %3799 = lshr i64 %3798, 4
  %3800 = trunc i64 %3799 to i8
  %3801 = and i8 %3800, 1
  store i8 %3801, i8* %54, align 1, !tbaa !2447
  %3802 = icmp eq i64 %3786, 0
  %3803 = zext i1 %3802 to i8
  store i8 %3803, i8* %57, align 1, !tbaa !2448
  %3804 = lshr i64 %3786, 63
  %3805 = trunc i64 %3804 to i8
  store i8 %3805, i8* %60, align 1, !tbaa !2449
  %3806 = lshr i64 %3778, 63
  %3807 = xor i64 %3804, %3806
  %3808 = xor i64 %3804, %3785
  %3809 = add nuw nsw i64 %3807, %3808
  %3810 = icmp eq i64 %3809, 2
  %3811 = zext i1 %3810 to i8
  store i8 %3811, i8* %66, align 1, !tbaa !2450
  %3812 = load i64, i64* %RBP, align 8
  %3813 = add i64 %3812, -104
  %3814 = add i64 %4752, 155
  store i64 %3814, i64* %PC, align 8
  %3815 = inttoptr i64 %3813 to i32*
  %3816 = load i32, i32* %3815, align 4
  %3817 = sext i32 %3816 to i64
  %3818 = mul nsw i64 %3817, 520
  store i64 %3818, i64* %RCX, align 8, !tbaa !2428
  %3819 = lshr i64 %3818, 63
  %3820 = add i64 %3818, %3786
  store i64 %3820, i64* %RAX, align 8, !tbaa !2428
  %3821 = icmp ult i64 %3820, %3786
  %3822 = icmp ult i64 %3820, %3818
  %3823 = or i1 %3821, %3822
  %3824 = zext i1 %3823 to i8
  store i8 %3824, i8* %42, align 1, !tbaa !2432
  %3825 = trunc i64 %3820 to i32
  %3826 = and i32 %3825, 255
  %3827 = tail call i32 @llvm.ctpop.i32(i32 %3826) #8
  %3828 = trunc i32 %3827 to i8
  %3829 = and i8 %3828, 1
  %3830 = xor i8 %3829, 1
  store i8 %3830, i8* %49, align 1, !tbaa !2446
  %3831 = xor i64 %3818, %3786
  %3832 = xor i64 %3831, %3820
  %3833 = lshr i64 %3832, 4
  %3834 = trunc i64 %3833 to i8
  %3835 = and i8 %3834, 1
  store i8 %3835, i8* %54, align 1, !tbaa !2447
  %3836 = icmp eq i64 %3820, 0
  %3837 = zext i1 %3836 to i8
  store i8 %3837, i8* %57, align 1, !tbaa !2448
  %3838 = lshr i64 %3820, 63
  %3839 = trunc i64 %3838 to i8
  store i8 %3839, i8* %60, align 1, !tbaa !2449
  %3840 = xor i64 %3838, %3804
  %3841 = xor i64 %3838, %3819
  %3842 = add nuw nsw i64 %3840, %3841
  %3843 = icmp eq i64 %3842, 2
  %3844 = zext i1 %3843 to i8
  store i8 %3844, i8* %66, align 1, !tbaa !2450
  %3845 = add i64 %3812, -108
  %3846 = add i64 %4752, 169
  store i64 %3846, i64* %PC, align 8
  %3847 = inttoptr i64 %3845 to i32*
  %3848 = load i32, i32* %3847, align 4
  %3849 = sext i32 %3848 to i64
  store i64 %3849, i64* %RCX, align 8, !tbaa !2428
  %3850 = shl nsw i64 %3849, 3
  %3851 = add i64 %3850, %3820
  %3852 = add i64 %4752, 174
  store i64 %3852, i64* %PC, align 8
  %3853 = load double, double* %228, align 1
  %3854 = inttoptr i64 %3851 to double*
  %3855 = load double, double* %3854, align 8
  %3856 = fsub double %3853, %3855
  store double %3856, double* %228, align 1, !tbaa !2452
  %3857 = add i64 %3812, -96
  %3858 = add i64 %4752, 178
  store i64 %3858, i64* %PC, align 8
  %3859 = inttoptr i64 %3857 to i64*
  %3860 = load i64, i64* %3859, align 8
  store i64 %3860, i64* %RAX, align 8, !tbaa !2428
  %3861 = add i64 %3812, -100
  %3862 = add i64 %4752, 182
  store i64 %3862, i64* %PC, align 8
  %3863 = inttoptr i64 %3861 to i32*
  %3864 = load i32, i32* %3863, align 4
  %3865 = sext i32 %3864 to i64
  %3866 = mul nsw i64 %3865, 520
  store i64 %3866, i64* %RCX, align 8, !tbaa !2428
  %3867 = lshr i64 %3866, 63
  %3868 = add i64 %3866, %3860
  store i64 %3868, i64* %RAX, align 8, !tbaa !2428
  %3869 = icmp ult i64 %3868, %3860
  %3870 = icmp ult i64 %3868, %3866
  %3871 = or i1 %3869, %3870
  %3872 = zext i1 %3871 to i8
  store i8 %3872, i8* %42, align 1, !tbaa !2432
  %3873 = trunc i64 %3868 to i32
  %3874 = and i32 %3873, 255
  %3875 = tail call i32 @llvm.ctpop.i32(i32 %3874) #8
  %3876 = trunc i32 %3875 to i8
  %3877 = and i8 %3876, 1
  %3878 = xor i8 %3877, 1
  store i8 %3878, i8* %49, align 1, !tbaa !2446
  %3879 = xor i64 %3866, %3860
  %3880 = xor i64 %3879, %3868
  %3881 = lshr i64 %3880, 4
  %3882 = trunc i64 %3881 to i8
  %3883 = and i8 %3882, 1
  store i8 %3883, i8* %54, align 1, !tbaa !2447
  %3884 = icmp eq i64 %3868, 0
  %3885 = zext i1 %3884 to i8
  store i8 %3885, i8* %57, align 1, !tbaa !2448
  %3886 = lshr i64 %3868, 63
  %3887 = trunc i64 %3886 to i8
  store i8 %3887, i8* %60, align 1, !tbaa !2449
  %3888 = lshr i64 %3860, 63
  %3889 = xor i64 %3886, %3888
  %3890 = xor i64 %3886, %3867
  %3891 = add nuw nsw i64 %3889, %3890
  %3892 = icmp eq i64 %3891, 2
  %3893 = zext i1 %3892 to i8
  store i8 %3893, i8* %66, align 1, !tbaa !2450
  %3894 = load i64, i64* %RBP, align 8
  %3895 = add i64 %3894, -104
  %3896 = add i64 %4752, 196
  store i64 %3896, i64* %PC, align 8
  %3897 = inttoptr i64 %3895 to i32*
  %3898 = load i32, i32* %3897, align 4
  %3899 = sext i32 %3898 to i64
  store i64 %3899, i64* %RCX, align 8, !tbaa !2428
  %3900 = shl nsw i64 %3899, 3
  %3901 = add i64 %3900, %3868
  %3902 = add i64 %4752, 201
  store i64 %3902, i64* %PC, align 8
  %3903 = inttoptr i64 %3901 to double*
  store double %3856, double* %3903, align 8
  %3904 = load i64, i64* %RBP, align 8
  %3905 = add i64 %3904, 88
  %3906 = load i64, i64* %PC, align 8
  %3907 = add i64 %3906, 4
  store i64 %3907, i64* %PC, align 8
  %3908 = inttoptr i64 %3905 to i64*
  %3909 = load i64, i64* %3908, align 8
  store i64 %3909, i64* %RAX, align 8, !tbaa !2428
  %3910 = add i64 %3904, -104
  %3911 = add i64 %3906, 8
  store i64 %3911, i64* %PC, align 8
  %3912 = inttoptr i64 %3910 to i32*
  %3913 = load i32, i32* %3912, align 4
  %3914 = sext i32 %3913 to i64
  store i64 %3914, i64* %RCX, align 8, !tbaa !2428
  %3915 = shl nsw i64 %3914, 3
  %3916 = add i64 %3915, %3909
  %3917 = add i64 %3906, 13
  store i64 %3917, i64* %PC, align 8
  %3918 = inttoptr i64 %3916 to double*
  %3919 = load double, double* %3918, align 8
  store double %3919, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %3920 = add i64 %3904, 96
  %3921 = add i64 %3906, 17
  store i64 %3921, i64* %PC, align 8
  %3922 = inttoptr i64 %3920 to i64*
  %3923 = load i64, i64* %3922, align 8
  store i64 %3923, i64* %RAX, align 8, !tbaa !2428
  %3924 = add i64 %3906, 21
  store i64 %3924, i64* %PC, align 8
  %3925 = load i32, i32* %3912, align 4
  %3926 = sext i32 %3925 to i64
  store i64 %3926, i64* %RCX, align 8, !tbaa !2428
  %3927 = shl nsw i64 %3926, 3
  %3928 = add i64 %3927, %3923
  %3929 = add i64 %3906, 26
  store i64 %3929, i64* %PC, align 8
  %3930 = inttoptr i64 %3928 to double*
  %3931 = load double, double* %3930, align 8
  %3932 = fdiv double %3919, %3931
  store double %3932, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %3933 = add i64 %3904, 24
  %3934 = add i64 %3906, 30
  store i64 %3934, i64* %PC, align 8
  %3935 = inttoptr i64 %3933 to i64*
  %3936 = load i64, i64* %3935, align 8
  store i64 %3936, i64* %RAX, align 8, !tbaa !2428
  %3937 = add i64 %3904, -100
  %3938 = add i64 %3906, 34
  store i64 %3938, i64* %PC, align 8
  %3939 = inttoptr i64 %3937 to i32*
  %3940 = load i32, i32* %3939, align 4
  %3941 = sext i32 %3940 to i64
  %3942 = mul nsw i64 %3941, 33800
  store i64 %3942, i64* %RCX, align 8, !tbaa !2428
  %3943 = lshr i64 %3942, 63
  %3944 = add i64 %3942, %3936
  store i64 %3944, i64* %RAX, align 8, !tbaa !2428
  %3945 = icmp ult i64 %3944, %3936
  %3946 = icmp ult i64 %3944, %3942
  %3947 = or i1 %3945, %3946
  %3948 = zext i1 %3947 to i8
  store i8 %3948, i8* %42, align 1, !tbaa !2432
  %3949 = trunc i64 %3944 to i32
  %3950 = and i32 %3949, 255
  %3951 = tail call i32 @llvm.ctpop.i32(i32 %3950) #8
  %3952 = trunc i32 %3951 to i8
  %3953 = and i8 %3952, 1
  %3954 = xor i8 %3953, 1
  store i8 %3954, i8* %49, align 1, !tbaa !2446
  %3955 = xor i64 %3942, %3936
  %3956 = xor i64 %3955, %3944
  %3957 = lshr i64 %3956, 4
  %3958 = trunc i64 %3957 to i8
  %3959 = and i8 %3958, 1
  store i8 %3959, i8* %54, align 1, !tbaa !2447
  %3960 = icmp eq i64 %3944, 0
  %3961 = zext i1 %3960 to i8
  store i8 %3961, i8* %57, align 1, !tbaa !2448
  %3962 = lshr i64 %3944, 63
  %3963 = trunc i64 %3962 to i8
  store i8 %3963, i8* %60, align 1, !tbaa !2449
  %3964 = lshr i64 %3936, 63
  %3965 = xor i64 %3962, %3964
  %3966 = xor i64 %3962, %3943
  %3967 = add nuw nsw i64 %3965, %3966
  %3968 = icmp eq i64 %3967, 2
  %3969 = zext i1 %3968 to i8
  store i8 %3969, i8* %66, align 1, !tbaa !2450
  %3970 = load i64, i64* %RBP, align 8
  %3971 = add i64 %3970, -104
  %3972 = add i64 %3906, 48
  store i64 %3972, i64* %PC, align 8
  %3973 = inttoptr i64 %3971 to i32*
  %3974 = load i32, i32* %3973, align 4
  %3975 = sext i32 %3974 to i64
  %3976 = mul nsw i64 %3975, 520
  store i64 %3976, i64* %RCX, align 8, !tbaa !2428
  %3977 = lshr i64 %3976, 63
  %3978 = add i64 %3976, %3944
  store i64 %3978, i64* %RAX, align 8, !tbaa !2428
  %3979 = icmp ult i64 %3978, %3944
  %3980 = icmp ult i64 %3978, %3976
  %3981 = or i1 %3979, %3980
  %3982 = zext i1 %3981 to i8
  store i8 %3982, i8* %42, align 1, !tbaa !2432
  %3983 = trunc i64 %3978 to i32
  %3984 = and i32 %3983, 255
  %3985 = tail call i32 @llvm.ctpop.i32(i32 %3984) #8
  %3986 = trunc i32 %3985 to i8
  %3987 = and i8 %3986, 1
  %3988 = xor i8 %3987, 1
  store i8 %3988, i8* %49, align 1, !tbaa !2446
  %3989 = xor i64 %3976, %3944
  %3990 = xor i64 %3989, %3978
  %3991 = lshr i64 %3990, 4
  %3992 = trunc i64 %3991 to i8
  %3993 = and i8 %3992, 1
  store i8 %3993, i8* %54, align 1, !tbaa !2447
  %3994 = icmp eq i64 %3978, 0
  %3995 = zext i1 %3994 to i8
  store i8 %3995, i8* %57, align 1, !tbaa !2448
  %3996 = lshr i64 %3978, 63
  %3997 = trunc i64 %3996 to i8
  store i8 %3997, i8* %60, align 1, !tbaa !2449
  %3998 = xor i64 %3996, %3962
  %3999 = xor i64 %3996, %3977
  %4000 = add nuw nsw i64 %3998, %3999
  %4001 = icmp eq i64 %4000, 2
  %4002 = zext i1 %4001 to i8
  store i8 %4002, i8* %66, align 1, !tbaa !2450
  %4003 = add i64 %3970, -108
  %4004 = add i64 %3906, 62
  store i64 %4004, i64* %PC, align 8
  %4005 = inttoptr i64 %4003 to i32*
  %4006 = load i32, i32* %4005, align 4
  %4007 = sext i32 %4006 to i64
  store i64 %4007, i64* %RCX, align 8, !tbaa !2428
  %4008 = shl nsw i64 %4007, 3
  %4009 = add i64 %4008, %3978
  %4010 = add i64 %3906, 67
  store i64 %4010, i64* %PC, align 8
  %4011 = load double, double* %228, align 1
  %4012 = inttoptr i64 %4009 to double*
  %4013 = load double, double* %4012, align 8
  %4014 = fmul double %4011, %4013
  store double %4014, double* %228, align 1, !tbaa !2452
  %4015 = add i64 %3970, -72
  %4016 = add i64 %3906, 72
  store i64 %4016, i64* %PC, align 8
  %4017 = inttoptr i64 %4015 to double*
  %4018 = load double, double* %4017, align 8
  store double %4018, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %4019 = add i64 %3970, 96
  %4020 = add i64 %3906, 76
  store i64 %4020, i64* %PC, align 8
  %4021 = inttoptr i64 %4019 to i64*
  %4022 = load i64, i64* %4021, align 8
  store i64 %4022, i64* %RAX, align 8, !tbaa !2428
  %4023 = add i64 %3906, 80
  store i64 %4023, i64* %PC, align 8
  %4024 = load i32, i32* %3973, align 4
  %4025 = sext i32 %4024 to i64
  store i64 %4025, i64* %RCX, align 8, !tbaa !2428
  %4026 = shl nsw i64 %4025, 3
  %4027 = add i64 %4026, %4022
  %4028 = add i64 %3906, 85
  store i64 %4028, i64* %PC, align 8
  %4029 = inttoptr i64 %4027 to double*
  %4030 = load double, double* %4029, align 8
  %4031 = fdiv double %4018, %4030
  store double %4031, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %4032 = load i64, i64* %RBP, align 8
  %4033 = add i64 %4032, -96
  %4034 = add i64 %3906, 89
  store i64 %4034, i64* %PC, align 8
  %4035 = inttoptr i64 %4033 to i64*
  %4036 = load i64, i64* %4035, align 8
  store i64 %4036, i64* %RAX, align 8, !tbaa !2428
  %4037 = add i64 %4032, -100
  %4038 = add i64 %3906, 93
  store i64 %4038, i64* %PC, align 8
  %4039 = inttoptr i64 %4037 to i32*
  %4040 = load i32, i32* %4039, align 4
  %4041 = sext i32 %4040 to i64
  %4042 = mul nsw i64 %4041, 520
  store i64 %4042, i64* %RCX, align 8, !tbaa !2428
  %4043 = lshr i64 %4042, 63
  %4044 = add i64 %4042, %4036
  store i64 %4044, i64* %RAX, align 8, !tbaa !2428
  %4045 = icmp ult i64 %4044, %4036
  %4046 = icmp ult i64 %4044, %4042
  %4047 = or i1 %4045, %4046
  %4048 = zext i1 %4047 to i8
  store i8 %4048, i8* %42, align 1, !tbaa !2432
  %4049 = trunc i64 %4044 to i32
  %4050 = and i32 %4049, 255
  %4051 = tail call i32 @llvm.ctpop.i32(i32 %4050) #8
  %4052 = trunc i32 %4051 to i8
  %4053 = and i8 %4052, 1
  %4054 = xor i8 %4053, 1
  store i8 %4054, i8* %49, align 1, !tbaa !2446
  %4055 = xor i64 %4042, %4036
  %4056 = xor i64 %4055, %4044
  %4057 = lshr i64 %4056, 4
  %4058 = trunc i64 %4057 to i8
  %4059 = and i8 %4058, 1
  store i8 %4059, i8* %54, align 1, !tbaa !2447
  %4060 = icmp eq i64 %4044, 0
  %4061 = zext i1 %4060 to i8
  store i8 %4061, i8* %57, align 1, !tbaa !2448
  %4062 = lshr i64 %4044, 63
  %4063 = trunc i64 %4062 to i8
  store i8 %4063, i8* %60, align 1, !tbaa !2449
  %4064 = lshr i64 %4036, 63
  %4065 = xor i64 %4062, %4064
  %4066 = xor i64 %4062, %4043
  %4067 = add nuw nsw i64 %4065, %4066
  %4068 = icmp eq i64 %4067, 2
  %4069 = zext i1 %4068 to i8
  store i8 %4069, i8* %66, align 1, !tbaa !2450
  %4070 = add i64 %4032, -104
  %4071 = add i64 %3906, 107
  store i64 %4071, i64* %PC, align 8
  %4072 = inttoptr i64 %4070 to i32*
  %4073 = load i32, i32* %4072, align 4
  %4074 = sext i32 %4073 to i64
  store i64 %4074, i64* %RCX, align 8, !tbaa !2428
  %4075 = shl nsw i64 %4074, 3
  %4076 = add i64 %4075, %4044
  %4077 = add i64 %3906, 112
  store i64 %4077, i64* %PC, align 8
  %4078 = inttoptr i64 %4076 to double*
  %4079 = load double, double* %4078, align 8
  %4080 = fmul double %4031, %4079
  store double %4080, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %4081 = load double, double* %228, align 1
  %4082 = fsub double %4081, %4080
  store double %4082, double* %228, align 1, !tbaa !2452
  %4083 = add i64 %4032, 16
  %4084 = add i64 %3906, 120
  store i64 %4084, i64* %PC, align 8
  %4085 = inttoptr i64 %4083 to i64*
  %4086 = load i64, i64* %4085, align 8
  store i64 %4086, i64* %RAX, align 8, !tbaa !2428
  %4087 = load i64, i64* %RBP, align 8
  %4088 = add i64 %4087, -100
  %4089 = add i64 %3906, 124
  store i64 %4089, i64* %PC, align 8
  %4090 = inttoptr i64 %4088 to i32*
  %4091 = load i32, i32* %4090, align 4
  %4092 = sext i32 %4091 to i64
  %4093 = mul nsw i64 %4092, 520
  store i64 %4093, i64* %RCX, align 8, !tbaa !2428
  %4094 = lshr i64 %4093, 63
  %4095 = add i64 %4093, %4086
  store i64 %4095, i64* %RAX, align 8, !tbaa !2428
  %4096 = icmp ult i64 %4095, %4086
  %4097 = icmp ult i64 %4095, %4093
  %4098 = or i1 %4096, %4097
  %4099 = zext i1 %4098 to i8
  store i8 %4099, i8* %42, align 1, !tbaa !2432
  %4100 = trunc i64 %4095 to i32
  %4101 = and i32 %4100, 255
  %4102 = tail call i32 @llvm.ctpop.i32(i32 %4101) #8
  %4103 = trunc i32 %4102 to i8
  %4104 = and i8 %4103, 1
  %4105 = xor i8 %4104, 1
  store i8 %4105, i8* %49, align 1, !tbaa !2446
  %4106 = xor i64 %4093, %4086
  %4107 = xor i64 %4106, %4095
  %4108 = lshr i64 %4107, 4
  %4109 = trunc i64 %4108 to i8
  %4110 = and i8 %4109, 1
  store i8 %4110, i8* %54, align 1, !tbaa !2447
  %4111 = icmp eq i64 %4095, 0
  %4112 = zext i1 %4111 to i8
  store i8 %4112, i8* %57, align 1, !tbaa !2448
  %4113 = lshr i64 %4095, 63
  %4114 = trunc i64 %4113 to i8
  store i8 %4114, i8* %60, align 1, !tbaa !2449
  %4115 = lshr i64 %4086, 63
  %4116 = xor i64 %4113, %4115
  %4117 = xor i64 %4113, %4094
  %4118 = add nuw nsw i64 %4116, %4117
  %4119 = icmp eq i64 %4118, 2
  %4120 = zext i1 %4119 to i8
  store i8 %4120, i8* %66, align 1, !tbaa !2450
  %4121 = add i64 %4087, -104
  %4122 = add i64 %3906, 138
  store i64 %4122, i64* %PC, align 8
  %4123 = inttoptr i64 %4121 to i32*
  %4124 = load i32, i32* %4123, align 4
  %4125 = sext i32 %4124 to i64
  store i64 %4125, i64* %RCX, align 8, !tbaa !2428
  %4126 = shl nsw i64 %4125, 3
  %4127 = add i64 %4126, %4095
  %4128 = add i64 %3906, 143
  store i64 %4128, i64* %PC, align 8
  %4129 = inttoptr i64 %4127 to double*
  store double %4082, double* %4129, align 8
  %4130 = load i64, i64* %RBP, align 8
  %4131 = add i64 %4130, 72
  %4132 = load i64, i64* %PC, align 8
  %4133 = add i64 %4132, 4
  store i64 %4133, i64* %PC, align 8
  %4134 = inttoptr i64 %4131 to i64*
  %4135 = load i64, i64* %4134, align 8
  store i64 %4135, i64* %RAX, align 8, !tbaa !2428
  %4136 = add i64 %4130, -108
  %4137 = add i64 %4132, 8
  store i64 %4137, i64* %PC, align 8
  %4138 = inttoptr i64 %4136 to i32*
  %4139 = load i32, i32* %4138, align 4
  %4140 = sext i32 %4139 to i64
  store i64 %4140, i64* %RCX, align 8, !tbaa !2428
  %4141 = shl nsw i64 %4140, 3
  %4142 = add i64 %4141, %4135
  %4143 = add i64 %4132, 13
  store i64 %4143, i64* %PC, align 8
  %4144 = inttoptr i64 %4142 to double*
  %4145 = load double, double* %4144, align 8
  store double %4145, double* %228, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %4146 = add i64 %4130, 80
  %4147 = add i64 %4132, 17
  store i64 %4147, i64* %PC, align 8
  %4148 = inttoptr i64 %4146 to i64*
  %4149 = load i64, i64* %4148, align 8
  store i64 %4149, i64* %RAX, align 8, !tbaa !2428
  %4150 = add i64 %4132, 21
  store i64 %4150, i64* %PC, align 8
  %4151 = load i32, i32* %4138, align 4
  %4152 = sext i32 %4151 to i64
  store i64 %4152, i64* %RCX, align 8, !tbaa !2428
  %4153 = shl nsw i64 %4152, 3
  %4154 = add i64 %4153, %4149
  %4155 = add i64 %4132, 26
  store i64 %4155, i64* %PC, align 8
  %4156 = inttoptr i64 %4154 to double*
  %4157 = load double, double* %4156, align 8
  %4158 = fdiv double %4145, %4157
  store double %4158, double* %228, align 1, !tbaa !2452
  store i64 0, i64* %229, align 1, !tbaa !2452
  %4159 = add i64 %4130, 48
  %4160 = add i64 %4132, 30
  store i64 %4160, i64* %PC, align 8
  %4161 = inttoptr i64 %4159 to i64*
  %4162 = load i64, i64* %4161, align 8
  store i64 %4162, i64* %RAX, align 8, !tbaa !2428
  %4163 = add i64 %4130, -100
  %4164 = add i64 %4132, 34
  store i64 %4164, i64* %PC, align 8
  %4165 = inttoptr i64 %4163 to i32*
  %4166 = load i32, i32* %4165, align 4
  %4167 = sext i32 %4166 to i64
  %4168 = mul nsw i64 %4167, 33800
  store i64 %4168, i64* %RCX, align 8, !tbaa !2428
  %4169 = lshr i64 %4168, 63
  %4170 = add i64 %4168, %4162
  store i64 %4170, i64* %RAX, align 8, !tbaa !2428
  %4171 = icmp ult i64 %4170, %4162
  %4172 = icmp ult i64 %4170, %4168
  %4173 = or i1 %4171, %4172
  %4174 = zext i1 %4173 to i8
  store i8 %4174, i8* %42, align 1, !tbaa !2432
  %4175 = trunc i64 %4170 to i32
  %4176 = and i32 %4175, 255
  %4177 = tail call i32 @llvm.ctpop.i32(i32 %4176) #8
  %4178 = trunc i32 %4177 to i8
  %4179 = and i8 %4178, 1
  %4180 = xor i8 %4179, 1
  store i8 %4180, i8* %49, align 1, !tbaa !2446
  %4181 = xor i64 %4168, %4162
  %4182 = xor i64 %4181, %4170
  %4183 = lshr i64 %4182, 4
  %4184 = trunc i64 %4183 to i8
  %4185 = and i8 %4184, 1
  store i8 %4185, i8* %54, align 1, !tbaa !2447
  %4186 = icmp eq i64 %4170, 0
  %4187 = zext i1 %4186 to i8
  store i8 %4187, i8* %57, align 1, !tbaa !2448
  %4188 = lshr i64 %4170, 63
  %4189 = trunc i64 %4188 to i8
  store i8 %4189, i8* %60, align 1, !tbaa !2449
  %4190 = lshr i64 %4162, 63
  %4191 = xor i64 %4188, %4190
  %4192 = xor i64 %4188, %4169
  %4193 = add nuw nsw i64 %4191, %4192
  %4194 = icmp eq i64 %4193, 2
  %4195 = zext i1 %4194 to i8
  store i8 %4195, i8* %66, align 1, !tbaa !2450
  %4196 = load i64, i64* %RBP, align 8
  %4197 = add i64 %4196, -104
  %4198 = add i64 %4132, 48
  store i64 %4198, i64* %PC, align 8
  %4199 = inttoptr i64 %4197 to i32*
  %4200 = load i32, i32* %4199, align 4
  %4201 = sext i32 %4200 to i64
  %4202 = mul nsw i64 %4201, 520
  store i64 %4202, i64* %RCX, align 8, !tbaa !2428
  %4203 = lshr i64 %4202, 63
  %4204 = add i64 %4202, %4170
  store i64 %4204, i64* %RAX, align 8, !tbaa !2428
  %4205 = icmp ult i64 %4204, %4170
  %4206 = icmp ult i64 %4204, %4202
  %4207 = or i1 %4205, %4206
  %4208 = zext i1 %4207 to i8
  store i8 %4208, i8* %42, align 1, !tbaa !2432
  %4209 = trunc i64 %4204 to i32
  %4210 = and i32 %4209, 255
  %4211 = tail call i32 @llvm.ctpop.i32(i32 %4210) #8
  %4212 = trunc i32 %4211 to i8
  %4213 = and i8 %4212, 1
  %4214 = xor i8 %4213, 1
  store i8 %4214, i8* %49, align 1, !tbaa !2446
  %4215 = xor i64 %4202, %4170
  %4216 = xor i64 %4215, %4204
  %4217 = lshr i64 %4216, 4
  %4218 = trunc i64 %4217 to i8
  %4219 = and i8 %4218, 1
  store i8 %4219, i8* %54, align 1, !tbaa !2447
  %4220 = icmp eq i64 %4204, 0
  %4221 = zext i1 %4220 to i8
  store i8 %4221, i8* %57, align 1, !tbaa !2448
  %4222 = lshr i64 %4204, 63
  %4223 = trunc i64 %4222 to i8
  store i8 %4223, i8* %60, align 1, !tbaa !2449
  %4224 = xor i64 %4222, %4188
  %4225 = xor i64 %4222, %4203
  %4226 = add nuw nsw i64 %4224, %4225
  %4227 = icmp eq i64 %4226, 2
  %4228 = zext i1 %4227 to i8
  store i8 %4228, i8* %66, align 1, !tbaa !2450
  %4229 = add i64 %4196, -108
  %4230 = add i64 %4132, 62
  store i64 %4230, i64* %PC, align 8
  %4231 = inttoptr i64 %4229 to i32*
  %4232 = load i32, i32* %4231, align 4
  %4233 = sext i32 %4232 to i64
  store i64 %4233, i64* %RCX, align 8, !tbaa !2428
  %4234 = shl nsw i64 %4233, 3
  %4235 = add i64 %4234, %4204
  %4236 = add i64 %4132, 67
  store i64 %4236, i64* %PC, align 8
  %4237 = load double, double* %228, align 1
  %4238 = inttoptr i64 %4235 to double*
  %4239 = load double, double* %4238, align 8
  %4240 = fmul double %4237, %4239
  store double %4240, double* %228, align 1, !tbaa !2452
  %4241 = add i64 %4196, -64
  %4242 = add i64 %4132, 72
  store i64 %4242, i64* %PC, align 8
  %4243 = inttoptr i64 %4241 to double*
  %4244 = load double, double* %4243, align 8
  store double %4244, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %4245 = add i64 %4196, 64
  %4246 = add i64 %4132, 76
  store i64 %4246, i64* %PC, align 8
  %4247 = inttoptr i64 %4245 to i64*
  %4248 = load i64, i64* %4247, align 8
  store i64 %4248, i64* %RAX, align 8, !tbaa !2428
  %4249 = add i64 %4196, -100
  %4250 = add i64 %4132, 80
  store i64 %4250, i64* %PC, align 8
  %4251 = inttoptr i64 %4249 to i32*
  %4252 = load i32, i32* %4251, align 4
  %4253 = sext i32 %4252 to i64
  store i64 %4253, i64* %RCX, align 8, !tbaa !2428
  %4254 = shl nsw i64 %4253, 3
  %4255 = add i64 %4254, %4248
  %4256 = add i64 %4132, 85
  store i64 %4256, i64* %PC, align 8
  %4257 = inttoptr i64 %4255 to double*
  %4258 = load double, double* %4257, align 8
  %4259 = fmul double %4244, %4258
  store double %4259, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %4260 = load i64, i64* %RBP, align 8
  %4261 = add i64 %4260, 80
  %4262 = add i64 %4132, 89
  store i64 %4262, i64* %PC, align 8
  %4263 = inttoptr i64 %4261 to i64*
  %4264 = load i64, i64* %4263, align 8
  store i64 %4264, i64* %RAX, align 8, !tbaa !2428
  %4265 = add i64 %4260, -108
  %4266 = add i64 %4132, 93
  store i64 %4266, i64* %PC, align 8
  %4267 = inttoptr i64 %4265 to i32*
  %4268 = load i32, i32* %4267, align 4
  %4269 = sext i32 %4268 to i64
  store i64 %4269, i64* %RCX, align 8, !tbaa !2428
  %4270 = shl nsw i64 %4269, 3
  %4271 = add i64 %4270, %4264
  %4272 = add i64 %4132, 98
  store i64 %4272, i64* %PC, align 8
  %4273 = inttoptr i64 %4271 to double*
  %4274 = load double, double* %4273, align 8
  %4275 = fdiv double %4259, %4274
  store double %4275, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %4276 = add i64 %4260, 16
  %4277 = add i64 %4132, 102
  store i64 %4277, i64* %PC, align 8
  %4278 = inttoptr i64 %4276 to i64*
  %4279 = load i64, i64* %4278, align 8
  store i64 %4279, i64* %RAX, align 8, !tbaa !2428
  %4280 = add i64 %4260, -100
  %4281 = add i64 %4132, 106
  store i64 %4281, i64* %PC, align 8
  %4282 = inttoptr i64 %4280 to i32*
  %4283 = load i32, i32* %4282, align 4
  %4284 = sext i32 %4283 to i64
  %4285 = mul nsw i64 %4284, 520
  store i64 %4285, i64* %RCX, align 8, !tbaa !2428
  %4286 = lshr i64 %4285, 63
  %4287 = add i64 %4285, %4279
  store i64 %4287, i64* %RAX, align 8, !tbaa !2428
  %4288 = icmp ult i64 %4287, %4279
  %4289 = icmp ult i64 %4287, %4285
  %4290 = or i1 %4288, %4289
  %4291 = zext i1 %4290 to i8
  store i8 %4291, i8* %42, align 1, !tbaa !2432
  %4292 = trunc i64 %4287 to i32
  %4293 = and i32 %4292, 255
  %4294 = tail call i32 @llvm.ctpop.i32(i32 %4293) #8
  %4295 = trunc i32 %4294 to i8
  %4296 = and i8 %4295, 1
  %4297 = xor i8 %4296, 1
  store i8 %4297, i8* %49, align 1, !tbaa !2446
  %4298 = xor i64 %4285, %4279
  %4299 = xor i64 %4298, %4287
  %4300 = lshr i64 %4299, 4
  %4301 = trunc i64 %4300 to i8
  %4302 = and i8 %4301, 1
  store i8 %4302, i8* %54, align 1, !tbaa !2447
  %4303 = icmp eq i64 %4287, 0
  %4304 = zext i1 %4303 to i8
  store i8 %4304, i8* %57, align 1, !tbaa !2448
  %4305 = lshr i64 %4287, 63
  %4306 = trunc i64 %4305 to i8
  store i8 %4306, i8* %60, align 1, !tbaa !2449
  %4307 = lshr i64 %4279, 63
  %4308 = xor i64 %4305, %4307
  %4309 = xor i64 %4305, %4286
  %4310 = add nuw nsw i64 %4308, %4309
  %4311 = icmp eq i64 %4310, 2
  %4312 = zext i1 %4311 to i8
  store i8 %4312, i8* %66, align 1, !tbaa !2450
  %4313 = add i64 %4260, -104
  %4314 = add i64 %4132, 120
  store i64 %4314, i64* %PC, align 8
  %4315 = inttoptr i64 %4313 to i32*
  %4316 = load i32, i32* %4315, align 4
  %4317 = sext i32 %4316 to i64
  store i64 %4317, i64* %RCX, align 8, !tbaa !2428
  %4318 = shl nsw i64 %4317, 3
  %4319 = add i64 %4318, %4287
  %4320 = add i64 %4132, 125
  store i64 %4320, i64* %PC, align 8
  %4321 = inttoptr i64 %4319 to double*
  %4322 = load double, double* %4321, align 8
  %4323 = fmul double %4275, %4322
  store double %4323, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %4324 = load double, double* %228, align 1
  %4325 = fadd double %4324, %4323
  store double %4325, double* %228, align 1, !tbaa !2452
  %4326 = load i64, i64* %RBP, align 8
  %4327 = add i64 %4326, -64
  %4328 = add i64 %4132, 134
  store i64 %4328, i64* %PC, align 8
  %4329 = inttoptr i64 %4327 to double*
  %4330 = load double, double* %4329, align 8
  store double %4330, double* %231, align 1, !tbaa !2452
  store double 0.000000e+00, double* %233, align 1, !tbaa !2452
  %4331 = add i64 %4326, 56
  %4332 = add i64 %4132, 138
  store i64 %4332, i64* %PC, align 8
  %4333 = inttoptr i64 %4331 to i64*
  %4334 = load i64, i64* %4333, align 8
  store i64 %4334, i64* %RAX, align 8, !tbaa !2428
  %4335 = add i64 %4326, -100
  %4336 = add i64 %4132, 142
  store i64 %4336, i64* %PC, align 8
  %4337 = inttoptr i64 %4335 to i32*
  %4338 = load i32, i32* %4337, align 4
  %4339 = sext i32 %4338 to i64
  store i64 %4339, i64* %RCX, align 8, !tbaa !2428
  %4340 = shl nsw i64 %4339, 3
  %4341 = add i64 %4340, %4334
  %4342 = add i64 %4132, 147
  store i64 %4342, i64* %PC, align 8
  %4343 = inttoptr i64 %4341 to double*
  %4344 = load double, double* %4343, align 8
  %4345 = fmul double %4330, %4344
  store double %4345, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %4346 = add i64 %4326, 80
  %4347 = add i64 %4132, 151
  store i64 %4347, i64* %PC, align 8
  %4348 = inttoptr i64 %4346 to i64*
  %4349 = load i64, i64* %4348, align 8
  store i64 %4349, i64* %RAX, align 8, !tbaa !2428
  %4350 = add i64 %4326, -108
  %4351 = add i64 %4132, 155
  store i64 %4351, i64* %PC, align 8
  %4352 = inttoptr i64 %4350 to i32*
  %4353 = load i32, i32* %4352, align 4
  %4354 = sext i32 %4353 to i64
  store i64 %4354, i64* %RCX, align 8, !tbaa !2428
  %4355 = shl nsw i64 %4354, 3
  %4356 = add i64 %4355, %4349
  %4357 = add i64 %4132, 160
  store i64 %4357, i64* %PC, align 8
  %4358 = inttoptr i64 %4356 to double*
  %4359 = load double, double* %4358, align 8
  %4360 = fdiv double %4345, %4359
  store double %4360, double* %231, align 1, !tbaa !2452
  store i64 0, i64* %232, align 1, !tbaa !2452
  %4361 = add i64 %4326, 24
  %4362 = add i64 %4132, 164
  store i64 %4362, i64* %PC, align 8
  %4363 = inttoptr i64 %4361 to i64*
  %4364 = load i64, i64* %4363, align 8
  store i64 %4364, i64* %RAX, align 8, !tbaa !2428
  %4365 = add i64 %4132, 168
  store i64 %4365, i64* %PC, align 8
  %4366 = load i32, i32* %4337, align 4
  %4367 = sext i32 %4366 to i64
  %4368 = mul nsw i64 %4367, 33800
  store i64 %4368, i64* %RCX, align 8, !tbaa !2428
  %4369 = lshr i64 %4368, 63
  %4370 = add i64 %4368, %4364
  store i64 %4370, i64* %RAX, align 8, !tbaa !2428
  %4371 = icmp ult i64 %4370, %4364
  %4372 = icmp ult i64 %4370, %4368
  %4373 = or i1 %4371, %4372
  %4374 = zext i1 %4373 to i8
  store i8 %4374, i8* %42, align 1, !tbaa !2432
  %4375 = trunc i64 %4370 to i32
  %4376 = and i32 %4375, 255
  %4377 = tail call i32 @llvm.ctpop.i32(i32 %4376) #8
  %4378 = trunc i32 %4377 to i8
  %4379 = and i8 %4378, 1
  %4380 = xor i8 %4379, 1
  store i8 %4380, i8* %49, align 1, !tbaa !2446
  %4381 = xor i64 %4368, %4364
  %4382 = xor i64 %4381, %4370
  %4383 = lshr i64 %4382, 4
  %4384 = trunc i64 %4383 to i8
  %4385 = and i8 %4384, 1
  store i8 %4385, i8* %54, align 1, !tbaa !2447
  %4386 = icmp eq i64 %4370, 0
  %4387 = zext i1 %4386 to i8
  store i8 %4387, i8* %57, align 1, !tbaa !2448
  %4388 = lshr i64 %4370, 63
  %4389 = trunc i64 %4388 to i8
  store i8 %4389, i8* %60, align 1, !tbaa !2449
  %4390 = lshr i64 %4364, 63
  %4391 = xor i64 %4388, %4390
  %4392 = xor i64 %4388, %4369
  %4393 = add nuw nsw i64 %4391, %4392
  %4394 = icmp eq i64 %4393, 2
  %4395 = zext i1 %4394 to i8
  store i8 %4395, i8* %66, align 1, !tbaa !2450
  %4396 = load i64, i64* %RBP, align 8
  %4397 = add i64 %4396, -104
  %4398 = add i64 %4132, 182
  store i64 %4398, i64* %PC, align 8
  %4399 = inttoptr i64 %4397 to i32*
  %4400 = load i32, i32* %4399, align 4
  %4401 = sext i32 %4400 to i64
  %4402 = mul nsw i64 %4401, 520
  store i64 %4402, i64* %RCX, align 8, !tbaa !2428
  %4403 = lshr i64 %4402, 63
  %4404 = add i64 %4402, %4370
  store i64 %4404, i64* %RAX, align 8, !tbaa !2428
  %4405 = icmp ult i64 %4404, %4370
  %4406 = icmp ult i64 %4404, %4402
  %4407 = or i1 %4405, %4406
  %4408 = zext i1 %4407 to i8
  store i8 %4408, i8* %42, align 1, !tbaa !2432
  %4409 = trunc i64 %4404 to i32
  %4410 = and i32 %4409, 255
  %4411 = tail call i32 @llvm.ctpop.i32(i32 %4410) #8
  %4412 = trunc i32 %4411 to i8
  %4413 = and i8 %4412, 1
  %4414 = xor i8 %4413, 1
  store i8 %4414, i8* %49, align 1, !tbaa !2446
  %4415 = xor i64 %4402, %4370
  %4416 = xor i64 %4415, %4404
  %4417 = lshr i64 %4416, 4
  %4418 = trunc i64 %4417 to i8
  %4419 = and i8 %4418, 1
  store i8 %4419, i8* %54, align 1, !tbaa !2447
  %4420 = icmp eq i64 %4404, 0
  %4421 = zext i1 %4420 to i8
  store i8 %4421, i8* %57, align 1, !tbaa !2448
  %4422 = lshr i64 %4404, 63
  %4423 = trunc i64 %4422 to i8
  store i8 %4423, i8* %60, align 1, !tbaa !2449
  %4424 = xor i64 %4422, %4388
  %4425 = xor i64 %4422, %4403
  %4426 = add nuw nsw i64 %4424, %4425
  %4427 = icmp eq i64 %4426, 2
  %4428 = zext i1 %4427 to i8
  store i8 %4428, i8* %66, align 1, !tbaa !2450
  %4429 = add i64 %4396, -108
  %4430 = add i64 %4132, 196
  store i64 %4430, i64* %PC, align 8
  %4431 = inttoptr i64 %4429 to i32*
  %4432 = load i32, i32* %4431, align 4
  %4433 = sext i32 %4432 to i64
  store i64 %4433, i64* %RCX, align 8, !tbaa !2428
  %4434 = shl nsw i64 %4433, 3
  %4435 = add i64 %4434, %4404
  %4436 = add i64 %4132, 201
  store i64 %4436, i64* %PC, align 8
  %4437 = load double, double* %231, align 1
  %4438 = inttoptr i64 %4435 to double*
  %4439 = load double, double* %4438, align 8
  %4440 = fmul double %4437, %4439
  store double %4440, double* %231, align 1, !tbaa !2452
  %4441 = load double, double* %228, align 1
  %4442 = fsub double %4441, %4440
  store double %4442, double* %228, align 1, !tbaa !2452
  %4443 = add i64 %4396, 48
  %4444 = add i64 %4132, 209
  store i64 %4444, i64* %PC, align 8
  %4445 = inttoptr i64 %4443 to i64*
  %4446 = load i64, i64* %4445, align 8
  store i64 %4446, i64* %RAX, align 8, !tbaa !2428
  %4447 = add i64 %4396, -100
  %4448 = add i64 %4132, 213
  store i64 %4448, i64* %PC, align 8
  %4449 = inttoptr i64 %4447 to i32*
  %4450 = load i32, i32* %4449, align 4
  %4451 = sext i32 %4450 to i64
  %4452 = mul nsw i64 %4451, 33800
  store i64 %4452, i64* %RCX, align 8, !tbaa !2428
  %4453 = lshr i64 %4452, 63
  %4454 = add i64 %4452, %4446
  store i64 %4454, i64* %RAX, align 8, !tbaa !2428
  %4455 = icmp ult i64 %4454, %4446
  %4456 = icmp ult i64 %4454, %4452
  %4457 = or i1 %4455, %4456
  %4458 = zext i1 %4457 to i8
  store i8 %4458, i8* %42, align 1, !tbaa !2432
  %4459 = trunc i64 %4454 to i32
  %4460 = and i32 %4459, 255
  %4461 = tail call i32 @llvm.ctpop.i32(i32 %4460) #8
  %4462 = trunc i32 %4461 to i8
  %4463 = and i8 %4462, 1
  %4464 = xor i8 %4463, 1
  store i8 %4464, i8* %49, align 1, !tbaa !2446
  %4465 = xor i64 %4452, %4446
  %4466 = xor i64 %4465, %4454
  %4467 = lshr i64 %4466, 4
  %4468 = trunc i64 %4467 to i8
  %4469 = and i8 %4468, 1
  store i8 %4469, i8* %54, align 1, !tbaa !2447
  %4470 = icmp eq i64 %4454, 0
  %4471 = zext i1 %4470 to i8
  store i8 %4471, i8* %57, align 1, !tbaa !2448
  %4472 = lshr i64 %4454, 63
  %4473 = trunc i64 %4472 to i8
  store i8 %4473, i8* %60, align 1, !tbaa !2449
  %4474 = lshr i64 %4446, 63
  %4475 = xor i64 %4472, %4474
  %4476 = xor i64 %4472, %4453
  %4477 = add nuw nsw i64 %4475, %4476
  %4478 = icmp eq i64 %4477, 2
  %4479 = zext i1 %4478 to i8
  store i8 %4479, i8* %66, align 1, !tbaa !2450
  %4480 = load i64, i64* %RBP, align 8
  %4481 = add i64 %4480, -104
  %4482 = add i64 %4132, 227
  store i64 %4482, i64* %PC, align 8
  %4483 = inttoptr i64 %4481 to i32*
  %4484 = load i32, i32* %4483, align 4
  %4485 = sext i32 %4484 to i64
  %4486 = mul nsw i64 %4485, 520
  store i64 %4486, i64* %RCX, align 8, !tbaa !2428
  %4487 = lshr i64 %4486, 63
  %4488 = add i64 %4486, %4454
  store i64 %4488, i64* %RAX, align 8, !tbaa !2428
  %4489 = icmp ult i64 %4488, %4454
  %4490 = icmp ult i64 %4488, %4486
  %4491 = or i1 %4489, %4490
  %4492 = zext i1 %4491 to i8
  store i8 %4492, i8* %42, align 1, !tbaa !2432
  %4493 = trunc i64 %4488 to i32
  %4494 = and i32 %4493, 255
  %4495 = tail call i32 @llvm.ctpop.i32(i32 %4494) #8
  %4496 = trunc i32 %4495 to i8
  %4497 = and i8 %4496, 1
  %4498 = xor i8 %4497, 1
  store i8 %4498, i8* %49, align 1, !tbaa !2446
  %4499 = xor i64 %4486, %4454
  %4500 = xor i64 %4499, %4488
  %4501 = lshr i64 %4500, 4
  %4502 = trunc i64 %4501 to i8
  %4503 = and i8 %4502, 1
  store i8 %4503, i8* %54, align 1, !tbaa !2447
  %4504 = icmp eq i64 %4488, 0
  %4505 = zext i1 %4504 to i8
  store i8 %4505, i8* %57, align 1, !tbaa !2448
  %4506 = lshr i64 %4488, 63
  %4507 = trunc i64 %4506 to i8
  store i8 %4507, i8* %60, align 1, !tbaa !2449
  %4508 = xor i64 %4506, %4472
  %4509 = xor i64 %4506, %4487
  %4510 = add nuw nsw i64 %4508, %4509
  %4511 = icmp eq i64 %4510, 2
  %4512 = zext i1 %4511 to i8
  store i8 %4512, i8* %66, align 1, !tbaa !2450
  %4513 = add i64 %4480, -108
  %4514 = add i64 %4132, 241
  store i64 %4514, i64* %PC, align 8
  %4515 = inttoptr i64 %4513 to i32*
  %4516 = load i32, i32* %4515, align 4
  %4517 = sext i32 %4516 to i64
  store i64 %4517, i64* %RCX, align 8, !tbaa !2428
  %4518 = shl nsw i64 %4517, 3
  %4519 = add i64 %4518, %4488
  %4520 = add i64 %4132, 246
  store i64 %4520, i64* %PC, align 8
  %4521 = load i64, i64* %147, align 1
  %4522 = inttoptr i64 %4519 to i64*
  store i64 %4521, i64* %4522, align 8
  %4523 = load i64, i64* %RBP, align 8
  %4524 = add i64 %4523, 16
  %4525 = load i64, i64* %PC, align 8
  %4526 = add i64 %4525, 4
  store i64 %4526, i64* %PC, align 8
  %4527 = inttoptr i64 %4524 to i64*
  %4528 = load i64, i64* %4527, align 8
  store i64 %4528, i64* %RAX, align 8, !tbaa !2428
  %4529 = add i64 %4523, -100
  %4530 = add i64 %4525, 8
  store i64 %4530, i64* %PC, align 8
  %4531 = inttoptr i64 %4529 to i32*
  %4532 = load i32, i32* %4531, align 4
  %4533 = sext i32 %4532 to i64
  %4534 = mul nsw i64 %4533, 520
  store i64 %4534, i64* %RCX, align 8, !tbaa !2428
  %4535 = lshr i64 %4534, 63
  %4536 = add i64 %4534, %4528
  store i64 %4536, i64* %RAX, align 8, !tbaa !2428
  %4537 = icmp ult i64 %4536, %4528
  %4538 = icmp ult i64 %4536, %4534
  %4539 = or i1 %4537, %4538
  %4540 = zext i1 %4539 to i8
  store i8 %4540, i8* %42, align 1, !tbaa !2432
  %4541 = trunc i64 %4536 to i32
  %4542 = and i32 %4541, 255
  %4543 = tail call i32 @llvm.ctpop.i32(i32 %4542) #8
  %4544 = trunc i32 %4543 to i8
  %4545 = and i8 %4544, 1
  %4546 = xor i8 %4545, 1
  store i8 %4546, i8* %49, align 1, !tbaa !2446
  %4547 = xor i64 %4534, %4528
  %4548 = xor i64 %4547, %4536
  %4549 = lshr i64 %4548, 4
  %4550 = trunc i64 %4549 to i8
  %4551 = and i8 %4550, 1
  store i8 %4551, i8* %54, align 1, !tbaa !2447
  %4552 = icmp eq i64 %4536, 0
  %4553 = zext i1 %4552 to i8
  store i8 %4553, i8* %57, align 1, !tbaa !2448
  %4554 = lshr i64 %4536, 63
  %4555 = trunc i64 %4554 to i8
  store i8 %4555, i8* %60, align 1, !tbaa !2449
  %4556 = lshr i64 %4528, 63
  %4557 = xor i64 %4554, %4556
  %4558 = xor i64 %4554, %4535
  %4559 = add nuw nsw i64 %4557, %4558
  %4560 = icmp eq i64 %4559, 2
  %4561 = zext i1 %4560 to i8
  store i8 %4561, i8* %66, align 1, !tbaa !2450
  %4562 = add i64 %4523, -104
  %4563 = add i64 %4525, 22
  store i64 %4563, i64* %PC, align 8
  %4564 = inttoptr i64 %4562 to i32*
  %4565 = load i32, i32* %4564, align 4
  %4566 = sext i32 %4565 to i64
  store i64 %4566, i64* %RCX, align 8, !tbaa !2428
  %4567 = shl nsw i64 %4566, 3
  %4568 = add i64 %4567, %4536
  %4569 = add i64 %4525, 27
  store i64 %4569, i64* %PC, align 8
  %4570 = inttoptr i64 %4568 to i64*
  %4571 = load i64, i64* %4570, align 8
  store i64 %4571, i64* %147, align 1, !tbaa !2452
  store double 0.000000e+00, double* %230, align 1, !tbaa !2452
  %4572 = add i64 %4523, 24
  %4573 = add i64 %4525, 31
  store i64 %4573, i64* %PC, align 8
  %4574 = inttoptr i64 %4572 to i64*
  %4575 = load i64, i64* %4574, align 8
  store i64 %4575, i64* %RAX, align 8, !tbaa !2428
  %4576 = add i64 %4525, 35
  store i64 %4576, i64* %PC, align 8
  %4577 = load i32, i32* %4531, align 4
  %4578 = sext i32 %4577 to i64
  %4579 = mul nsw i64 %4578, 33800
  store i64 %4579, i64* %RCX, align 8, !tbaa !2428
  %4580 = lshr i64 %4579, 63
  %4581 = add i64 %4579, %4575
  store i64 %4581, i64* %RAX, align 8, !tbaa !2428
  %4582 = icmp ult i64 %4581, %4575
  %4583 = icmp ult i64 %4581, %4579
  %4584 = or i1 %4582, %4583
  %4585 = zext i1 %4584 to i8
  store i8 %4585, i8* %42, align 1, !tbaa !2432
  %4586 = trunc i64 %4581 to i32
  %4587 = and i32 %4586, 255
  %4588 = tail call i32 @llvm.ctpop.i32(i32 %4587) #8
  %4589 = trunc i32 %4588 to i8
  %4590 = and i8 %4589, 1
  %4591 = xor i8 %4590, 1
  store i8 %4591, i8* %49, align 1, !tbaa !2446
  %4592 = xor i64 %4579, %4575
  %4593 = xor i64 %4592, %4581
  %4594 = lshr i64 %4593, 4
  %4595 = trunc i64 %4594 to i8
  %4596 = and i8 %4595, 1
  store i8 %4596, i8* %54, align 1, !tbaa !2447
  %4597 = icmp eq i64 %4581, 0
  %4598 = zext i1 %4597 to i8
  store i8 %4598, i8* %57, align 1, !tbaa !2448
  %4599 = lshr i64 %4581, 63
  %4600 = trunc i64 %4599 to i8
  store i8 %4600, i8* %60, align 1, !tbaa !2449
  %4601 = lshr i64 %4575, 63
  %4602 = xor i64 %4599, %4601
  %4603 = xor i64 %4599, %4580
  %4604 = add nuw nsw i64 %4602, %4603
  %4605 = icmp eq i64 %4604, 2
  %4606 = zext i1 %4605 to i8
  store i8 %4606, i8* %66, align 1, !tbaa !2450
  %4607 = load i64, i64* %RBP, align 8
  %4608 = add i64 %4607, -104
  %4609 = add i64 %4525, 49
  store i64 %4609, i64* %PC, align 8
  %4610 = inttoptr i64 %4608 to i32*
  %4611 = load i32, i32* %4610, align 4
  %4612 = sext i32 %4611 to i64
  %4613 = mul nsw i64 %4612, 520
  store i64 %4613, i64* %RCX, align 8, !tbaa !2428
  %4614 = lshr i64 %4613, 63
  %4615 = add i64 %4613, %4581
  store i64 %4615, i64* %RAX, align 8, !tbaa !2428
  %4616 = icmp ult i64 %4615, %4581
  %4617 = icmp ult i64 %4615, %4613
  %4618 = or i1 %4616, %4617
  %4619 = zext i1 %4618 to i8
  store i8 %4619, i8* %42, align 1, !tbaa !2432
  %4620 = trunc i64 %4615 to i32
  %4621 = and i32 %4620, 255
  %4622 = tail call i32 @llvm.ctpop.i32(i32 %4621) #8
  %4623 = trunc i32 %4622 to i8
  %4624 = and i8 %4623, 1
  %4625 = xor i8 %4624, 1
  store i8 %4625, i8* %49, align 1, !tbaa !2446
  %4626 = xor i64 %4613, %4581
  %4627 = xor i64 %4626, %4615
  %4628 = lshr i64 %4627, 4
  %4629 = trunc i64 %4628 to i8
  %4630 = and i8 %4629, 1
  store i8 %4630, i8* %54, align 1, !tbaa !2447
  %4631 = icmp eq i64 %4615, 0
  %4632 = zext i1 %4631 to i8
  store i8 %4632, i8* %57, align 1, !tbaa !2448
  %4633 = lshr i64 %4615, 63
  %4634 = trunc i64 %4633 to i8
  store i8 %4634, i8* %60, align 1, !tbaa !2449
  %4635 = xor i64 %4633, %4599
  %4636 = xor i64 %4633, %4614
  %4637 = add nuw nsw i64 %4635, %4636
  %4638 = icmp eq i64 %4637, 2
  %4639 = zext i1 %4638 to i8
  store i8 %4639, i8* %66, align 1, !tbaa !2450
  %4640 = add i64 %4607, -108
  %4641 = add i64 %4525, 63
  store i64 %4641, i64* %PC, align 8
  %4642 = inttoptr i64 %4640 to i32*
  %4643 = load i32, i32* %4642, align 4
  %4644 = sext i32 %4643 to i64
  store i64 %4644, i64* %RCX, align 8, !tbaa !2428
  %4645 = shl nsw i64 %4644, 3
  %4646 = add i64 %4645, %4615
  %4647 = add i64 %4525, 68
  store i64 %4647, i64* %PC, align 8
  %4648 = load i64, i64* %147, align 1
  %4649 = inttoptr i64 %4646 to i64*
  store i64 %4648, i64* %4649, align 8
  %4650 = load i64, i64* %RBP, align 8
  %4651 = add i64 %4650, -108
  %4652 = load i64, i64* %PC, align 8
  %4653 = add i64 %4652, 3
  store i64 %4653, i64* %PC, align 8
  %4654 = inttoptr i64 %4651 to i32*
  %4655 = load i32, i32* %4654, align 4
  %4656 = add i32 %4655, 1
  %4657 = zext i32 %4656 to i64
  store i64 %4657, i64* %RAX, align 8, !tbaa !2428
  %4658 = icmp eq i32 %4655, -1
  %4659 = icmp eq i32 %4656, 0
  %4660 = or i1 %4658, %4659
  %4661 = zext i1 %4660 to i8
  store i8 %4661, i8* %42, align 1, !tbaa !2432
  %4662 = and i32 %4656, 255
  %4663 = tail call i32 @llvm.ctpop.i32(i32 %4662) #8
  %4664 = trunc i32 %4663 to i8
  %4665 = and i8 %4664, 1
  %4666 = xor i8 %4665, 1
  store i8 %4666, i8* %49, align 1, !tbaa !2446
  %4667 = xor i32 %4655, %4656
  %4668 = lshr i32 %4667, 4
  %4669 = trunc i32 %4668 to i8
  %4670 = and i8 %4669, 1
  store i8 %4670, i8* %54, align 1, !tbaa !2447
  %4671 = zext i1 %4659 to i8
  store i8 %4671, i8* %57, align 1, !tbaa !2448
  %4672 = lshr i32 %4656, 31
  %4673 = trunc i32 %4672 to i8
  store i8 %4673, i8* %60, align 1, !tbaa !2449
  %4674 = lshr i32 %4655, 31
  %4675 = xor i32 %4672, %4674
  %4676 = add nuw nsw i32 %4675, %4672
  %4677 = icmp eq i32 %4676, 2
  %4678 = zext i1 %4677 to i8
  store i8 %4678, i8* %66, align 1, !tbaa !2450
  %4679 = add i64 %4652, 9
  store i64 %4679, i64* %PC, align 8
  store i32 %4656, i32* %4654, align 4
  %4680 = load i64, i64* %PC, align 8
  %4681 = add i64 %4680, -679
  store i64 %4681, i64* %PC, align 8, !tbaa !2428
  br label %block_4014a0

block_401486:                                     ; preds = %block_40147a
  %4682 = add i64 %238, -104
  %4683 = add i64 %274, 7
  store i64 %4683, i64* %PC, align 8
  %4684 = inttoptr i64 %4682 to i32*
  store i32 0, i32* %4684, align 4
  %.pre2 = load i64, i64* %PC, align 8
  br label %block_40148d

block_401ee5:                                     ; preds = %block_40148d
  %4685 = add i64 %327, -100
  %4686 = add i64 %363, 8
  store i64 %4686, i64* %PC, align 8
  %4687 = inttoptr i64 %4685 to i32*
  %4688 = load i32, i32* %4687, align 4
  %4689 = add i32 %4688, 1
  %4690 = zext i32 %4689 to i64
  store i64 %4690, i64* %RAX, align 8, !tbaa !2428
  %4691 = icmp eq i32 %4688, -1
  %4692 = icmp eq i32 %4689, 0
  %4693 = or i1 %4691, %4692
  %4694 = zext i1 %4693 to i8
  store i8 %4694, i8* %42, align 1, !tbaa !2432
  %4695 = and i32 %4689, 255
  %4696 = tail call i32 @llvm.ctpop.i32(i32 %4695) #8
  %4697 = trunc i32 %4696 to i8
  %4698 = and i8 %4697, 1
  %4699 = xor i8 %4698, 1
  store i8 %4699, i8* %49, align 1, !tbaa !2446
  %4700 = xor i32 %4688, %4689
  %4701 = lshr i32 %4700, 4
  %4702 = trunc i32 %4701 to i8
  %4703 = and i8 %4702, 1
  store i8 %4703, i8* %54, align 1, !tbaa !2447
  %4704 = zext i1 %4692 to i8
  store i8 %4704, i8* %57, align 1, !tbaa !2448
  %4705 = lshr i32 %4689, 31
  %4706 = trunc i32 %4705 to i8
  store i8 %4706, i8* %60, align 1, !tbaa !2449
  %4707 = lshr i32 %4688, 31
  %4708 = xor i32 %4705, %4707
  %4709 = add nuw nsw i32 %4708, %4705
  %4710 = icmp eq i32 %4709, 2
  %4711 = zext i1 %4710 to i8
  store i8 %4711, i8* %66, align 1, !tbaa !2450
  %4712 = add i64 %363, 14
  store i64 %4712, i64* %PC, align 8
  store i32 %4689, i32* %4687, align 4
  %4713 = load i64, i64* %PC, align 8
  %4714 = add i64 %4713, -2681
  store i64 %4714, i64* %PC, align 8, !tbaa !2428
  br label %block_40147a

block_4014a0:                                     ; preds = %block_4014ac, %block_401499
  %4715 = phi i64 [ %4681, %block_4014ac ], [ %.pre3, %block_401499 ]
  %4716 = load i64, i64* %RBP, align 8
  %4717 = add i64 %4716, -108
  %4718 = add i64 %4715, 3
  store i64 %4718, i64* %PC, align 8
  %4719 = inttoptr i64 %4717 to i32*
  %4720 = load i32, i32* %4719, align 4
  %4721 = zext i32 %4720 to i64
  store i64 %4721, i64* %RAX, align 8, !tbaa !2428
  %4722 = add i64 %4716, -48
  %4723 = add i64 %4715, 6
  store i64 %4723, i64* %PC, align 8
  %4724 = inttoptr i64 %4722 to i32*
  %4725 = load i32, i32* %4724, align 4
  %4726 = sub i32 %4720, %4725
  %4727 = icmp ult i32 %4720, %4725
  %4728 = zext i1 %4727 to i8
  store i8 %4728, i8* %42, align 1, !tbaa !2432
  %4729 = and i32 %4726, 255
  %4730 = tail call i32 @llvm.ctpop.i32(i32 %4729) #8
  %4731 = trunc i32 %4730 to i8
  %4732 = and i8 %4731, 1
  %4733 = xor i8 %4732, 1
  store i8 %4733, i8* %49, align 1, !tbaa !2446
  %4734 = xor i32 %4725, %4720
  %4735 = xor i32 %4734, %4726
  %4736 = lshr i32 %4735, 4
  %4737 = trunc i32 %4736 to i8
  %4738 = and i8 %4737, 1
  store i8 %4738, i8* %54, align 1, !tbaa !2447
  %4739 = icmp eq i32 %4726, 0
  %4740 = zext i1 %4739 to i8
  store i8 %4740, i8* %57, align 1, !tbaa !2448
  %4741 = lshr i32 %4726, 31
  %4742 = trunc i32 %4741 to i8
  store i8 %4742, i8* %60, align 1, !tbaa !2449
  %4743 = lshr i32 %4720, 31
  %4744 = lshr i32 %4725, 31
  %4745 = xor i32 %4744, %4743
  %4746 = xor i32 %4741, %4743
  %4747 = add nuw nsw i32 %4746, %4745
  %4748 = icmp eq i32 %4747, 2
  %4749 = zext i1 %4748 to i8
  store i8 %4749, i8* %66, align 1, !tbaa !2450
  %4750 = icmp ne i8 %4742, 0
  %4751 = xor i1 %4750, %4748
  %.v6 = select i1 %4751, i64 12, i64 684
  %4752 = add i64 %4715, %.v6
  %4753 = add i64 %4716, 32
  %4754 = add i64 %4752, 4
  store i64 %4754, i64* %PC, align 8
  %4755 = inttoptr i64 %4753 to i64*
  %4756 = load i64, i64* %4755, align 8
  store i64 %4756, i64* %RAX, align 8, !tbaa !2428
  %4757 = add i64 %4716, -100
  %4758 = add i64 %4752, 8
  store i64 %4758, i64* %PC, align 8
  %4759 = inttoptr i64 %4757 to i32*
  %4760 = load i32, i32* %4759, align 4
  %4761 = sext i32 %4760 to i64
  %4762 = mul nsw i64 %4761, 33800
  store i64 %4762, i64* %RCX, align 8, !tbaa !2428
  %4763 = lshr i64 %4762, 63
  %4764 = add i64 %4762, %4756
  store i64 %4764, i64* %RAX, align 8, !tbaa !2428
  %4765 = icmp ult i64 %4764, %4756
  %4766 = icmp ult i64 %4764, %4762
  %4767 = or i1 %4765, %4766
  %4768 = zext i1 %4767 to i8
  store i8 %4768, i8* %42, align 1, !tbaa !2432
  %4769 = trunc i64 %4764 to i32
  %4770 = and i32 %4769, 255
  %4771 = tail call i32 @llvm.ctpop.i32(i32 %4770) #8
  %4772 = trunc i32 %4771 to i8
  %4773 = and i8 %4772, 1
  %4774 = xor i8 %4773, 1
  store i8 %4774, i8* %49, align 1, !tbaa !2446
  %4775 = xor i64 %4762, %4756
  %4776 = xor i64 %4775, %4764
  %4777 = lshr i64 %4776, 4
  %4778 = trunc i64 %4777 to i8
  %4779 = and i8 %4778, 1
  store i8 %4779, i8* %54, align 1, !tbaa !2447
  %4780 = icmp eq i64 %4764, 0
  %4781 = zext i1 %4780 to i8
  store i8 %4781, i8* %57, align 1, !tbaa !2448
  %4782 = lshr i64 %4764, 63
  %4783 = trunc i64 %4782 to i8
  store i8 %4783, i8* %60, align 1, !tbaa !2449
  %4784 = lshr i64 %4756, 63
  %4785 = xor i64 %4782, %4784
  %4786 = xor i64 %4782, %4763
  %4787 = add nuw nsw i64 %4785, %4786
  %4788 = icmp eq i64 %4787, 2
  %4789 = zext i1 %4788 to i8
  store i8 %4789, i8* %66, align 1, !tbaa !2450
  %4790 = load i64, i64* %RBP, align 8
  %4791 = add i64 %4790, -104
  %4792 = add i64 %4752, 22
  store i64 %4792, i64* %PC, align 8
  %4793 = inttoptr i64 %4791 to i32*
  %4794 = load i32, i32* %4793, align 4
  %4795 = sext i32 %4794 to i64
  %4796 = mul nsw i64 %4795, 520
  store i64 %4796, i64* %RCX, align 8, !tbaa !2428
  %4797 = lshr i64 %4796, 63
  %4798 = add i64 %4752, 32
  store i64 %4798, i64* %PC, align 8
  %4799 = add i64 %4796, %4764
  store i64 %4799, i64* %RAX, align 8, !tbaa !2428
  %4800 = icmp ult i64 %4799, %4764
  %4801 = icmp ult i64 %4799, %4796
  %4802 = or i1 %4800, %4801
  %4803 = zext i1 %4802 to i8
  store i8 %4803, i8* %42, align 1, !tbaa !2432
  %4804 = trunc i64 %4799 to i32
  %4805 = and i32 %4804, 255
  %4806 = tail call i32 @llvm.ctpop.i32(i32 %4805) #8
  %4807 = trunc i32 %4806 to i8
  %4808 = and i8 %4807, 1
  %4809 = xor i8 %4808, 1
  store i8 %4809, i8* %49, align 1, !tbaa !2446
  %4810 = xor i64 %4796, %4764
  %4811 = xor i64 %4810, %4799
  %4812 = lshr i64 %4811, 4
  %4813 = trunc i64 %4812 to i8
  %4814 = and i8 %4813, 1
  store i8 %4814, i8* %54, align 1, !tbaa !2447
  %4815 = icmp eq i64 %4799, 0
  %4816 = zext i1 %4815 to i8
  store i8 %4816, i8* %57, align 1, !tbaa !2448
  %4817 = lshr i64 %4799, 63
  %4818 = trunc i64 %4817 to i8
  store i8 %4818, i8* %60, align 1, !tbaa !2449
  %4819 = xor i64 %4817, %4782
  %4820 = xor i64 %4817, %4797
  %4821 = add nuw nsw i64 %4819, %4820
  %4822 = icmp eq i64 %4821, 2
  %4823 = zext i1 %4822 to i8
  store i8 %4823, i8* %66, align 1, !tbaa !2450
  br i1 %4751, label %block_4014ac, label %block_40174c
}

; Function Attrs: noinline
define %struct.Memory* @sub_400800_xmalloc(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_400800:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %AL = bitcast %union.anon* %3 to i8*
  %EAX = bitcast %union.anon* %3 to i32*
  %RAX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %4 = load i64, i64* %RBP, align 8
  %5 = add i64 %1, 1
  store i64 %5, i64* %PC, align 8
  %6 = load i64, i64* %RSP, align 8, !tbaa !2428
  %7 = add i64 %6, -8
  %8 = inttoptr i64 %7 to i64*
  store i64 %4, i64* %8, align 8
  %9 = load i64, i64* %PC, align 8
  store i64 %7, i64* %RBP, align 8, !tbaa !2428
  %10 = add i64 %6, -40
  store i64 %10, i64* %RSP, align 8, !tbaa !2428
  %11 = icmp ult i64 %7, 32
  %12 = zext i1 %11 to i8
  %13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %12, i8* %13, align 1, !tbaa !2432
  %14 = trunc i64 %10 to i32
  %15 = and i32 %14, 255
  %16 = tail call i32 @llvm.ctpop.i32(i32 %15) #8
  %17 = trunc i32 %16 to i8
  %18 = and i8 %17, 1
  %19 = xor i8 %18, 1
  %20 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %19, i8* %20, align 1, !tbaa !2446
  %21 = xor i64 %7, %10
  %22 = lshr i64 %21, 4
  %23 = trunc i64 %22 to i8
  %24 = and i8 %23, 1
  %25 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %24, i8* %25, align 1, !tbaa !2447
  %26 = icmp eq i64 %10, 0
  %27 = zext i1 %26 to i8
  %28 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %27, i8* %28, align 1, !tbaa !2448
  %29 = lshr i64 %10, 63
  %30 = trunc i64 %29 to i8
  %31 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %30, i8* %31, align 1, !tbaa !2449
  %32 = lshr i64 %7, 63
  %33 = xor i64 %29, %32
  %34 = add nuw nsw i64 %33, %32
  %35 = icmp eq i64 %34, 2
  %36 = zext i1 %35 to i8
  %37 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %36, i8* %37, align 1, !tbaa !2450
  %38 = add i64 %6, -24
  store i64 %38, i64* %RAX, align 8, !tbaa !2428
  store i64 32, i64* %RCX, align 8, !tbaa !2428
  store i64 32, i64* %RSI, align 8, !tbaa !2428
  %39 = add i64 %6, -16
  %40 = load i64, i64* %RDI, align 8
  %41 = add i64 %9, 22
  store i64 %41, i64* %PC, align 8
  %42 = inttoptr i64 %39 to i64*
  store i64 %40, i64* %42, align 8
  %43 = load i64, i64* %RBP, align 8
  %44 = add i64 %43, -16
  %45 = load i64, i64* %PC, align 8
  %46 = add i64 %45, 8
  store i64 %46, i64* %PC, align 8
  %47 = inttoptr i64 %44 to i64*
  store i64 0, i64* %47, align 8
  %48 = load i64, i64* %RBP, align 8
  %49 = add i64 %48, -8
  %50 = load i64, i64* %PC, align 8
  %51 = add i64 %50, 4
  store i64 %51, i64* %PC, align 8
  %52 = inttoptr i64 %49 to i64*
  %53 = load i64, i64* %52, align 8
  store i64 %53, i64* %RDX, align 8, !tbaa !2428
  %54 = load i64, i64* %RAX, align 8
  store i64 %54, i64* %RDI, align 8, !tbaa !2428
  %55 = add i64 %50, -639
  %56 = add i64 %50, 12
  %57 = load i64, i64* %RSP, align 8, !tbaa !2428
  %58 = add i64 %57, -8
  %59 = inttoptr i64 %58 to i64*
  store i64 %56, i64* %59, align 8
  store i64 %58, i64* %RSP, align 8, !tbaa !2428
  store i64 %55, i64* %PC, align 8, !tbaa !2428
  %60 = tail call fastcc %struct.Memory* @ext_4005a0_posix_memalign(%struct.State* nonnull %0, %struct.Memory* %2)
  %61 = load i64, i64* %RBP, align 8
  %62 = add i64 %61, -20
  %63 = load i32, i32* %EAX, align 4
  %64 = load i64, i64* %PC, align 8
  %65 = add i64 %64, 3
  store i64 %65, i64* %PC, align 8
  %66 = inttoptr i64 %62 to i32*
  store i32 %63, i32* %66, align 4
  %67 = load i64, i64* %RBP, align 8
  %68 = add i64 %67, -16
  %69 = load i64, i64* %PC, align 8
  %70 = add i64 %69, 5
  store i64 %70, i64* %PC, align 8
  %71 = inttoptr i64 %68 to i64*
  %72 = load i64, i64* %71, align 8
  store i8 0, i8* %13, align 1, !tbaa !2432
  %73 = trunc i64 %72 to i32
  %74 = and i32 %73, 255
  %75 = tail call i32 @llvm.ctpop.i32(i32 %74) #8
  %76 = trunc i32 %75 to i8
  %77 = and i8 %76, 1
  %78 = xor i8 %77, 1
  store i8 %78, i8* %20, align 1, !tbaa !2446
  store i8 0, i8* %25, align 1, !tbaa !2447
  %79 = icmp eq i64 %72, 0
  %80 = zext i1 %79 to i8
  store i8 %80, i8* %28, align 1, !tbaa !2448
  %81 = lshr i64 %72, 63
  %82 = trunc i64 %81 to i8
  store i8 %82, i8* %31, align 1, !tbaa !2449
  store i8 0, i8* %37, align 1, !tbaa !2450
  %.v = select i1 %79, i64 21, i64 11
  %83 = add i64 %69, %.v
  store i64 %83, i64* %PC, align 8, !tbaa !2428
  br i1 %79, label %block_400843, label %block_400839

block_400843:                                     ; preds = %block_400839, %block_400800
  %84 = phi i64 [ %120, %block_400839 ], [ %83, %block_400800 ]
  store i64 add (i64 ptrtoint (%seg_402e80__rodata_type* @seg_402e80__rodata to i64), i64 119), i64* %RSI, align 8, !tbaa !2428
  %85 = load i64, i64* @stderr, align 32
  store i64 %85, i64* %RDI, align 8, !tbaa !2428
  store i8 0, i8* %AL, align 1, !tbaa !2454
  %86 = add i64 %84, -707
  %87 = add i64 %84, 25
  %88 = load i64, i64* %RSP, align 8, !tbaa !2428
  %89 = add i64 %88, -8
  %90 = inttoptr i64 %89 to i64*
  store i64 %87, i64* %90, align 8
  store i64 %89, i64* %RSP, align 8, !tbaa !2428
  store i64 %86, i64* %PC, align 8, !tbaa !2428
  %91 = tail call fastcc %struct.Memory* @ext_6040f8_fprintf(%struct.State* nonnull %0, %struct.Memory* %60)
  %92 = load i64, i64* %PC, align 8
  store i64 1, i64* %RDI, align 8, !tbaa !2428
  %93 = load i64, i64* %RBP, align 8
  %94 = add i64 %93, -24
  %95 = load i32, i32* %EAX, align 4
  %96 = add i64 %92, 8
  store i64 %96, i64* %PC, align 8
  %97 = inttoptr i64 %94 to i32*
  store i32 %95, i32* %97, align 4
  %98 = load i64, i64* %PC, align 8
  %99 = add i64 %98, -724
  %100 = add i64 %98, 5
  %101 = load i64, i64* %RSP, align 8, !tbaa !2428
  %102 = add i64 %101, -8
  %103 = inttoptr i64 %102 to i64*
  store i64 %100, i64* %103, align 8
  store i64 %102, i64* %RSP, align 8, !tbaa !2428
  store i64 %99, i64* %PC, align 8, !tbaa !2428
  %104 = tail call fastcc %struct.Memory* @ext_6040c8_exit(%struct.State* nonnull %0, %struct.Memory* %91)
  %105 = load i64, i64* %PC, align 8
  %106 = tail call %struct.Memory* @__remill_error(%struct.State* nonnull %0, i64 %105, %struct.Memory* %104)
  ret %struct.Memory* %106

block_400839:                                     ; preds = %block_400800
  %107 = add i64 %67, -20
  %108 = add i64 %83, 4
  store i64 %108, i64* %PC, align 8
  %109 = inttoptr i64 %107 to i32*
  %110 = load i32, i32* %109, align 4
  store i8 0, i8* %13, align 1, !tbaa !2432
  %111 = and i32 %110, 255
  %112 = tail call i32 @llvm.ctpop.i32(i32 %111) #8
  %113 = trunc i32 %112 to i8
  %114 = and i8 %113, 1
  %115 = xor i8 %114, 1
  store i8 %115, i8* %20, align 1, !tbaa !2446
  store i8 0, i8* %25, align 1, !tbaa !2447
  %116 = icmp eq i32 %110, 0
  %117 = zext i1 %116 to i8
  store i8 %117, i8* %28, align 1, !tbaa !2448
  %118 = lshr i32 %110, 31
  %119 = trunc i32 %118 to i8
  store i8 %119, i8* %31, align 1, !tbaa !2449
  store i8 0, i8* %37, align 1, !tbaa !2450
  %.v1 = select i1 %116, i64 48, i64 10
  %120 = add i64 %83, %.v1
  store i64 %120, i64* %PC, align 8, !tbaa !2428
  br i1 %116, label %block_400869, label %block_400843

block_400869:                                     ; preds = %block_400839
  %121 = add i64 %120, 4
  store i64 %121, i64* %PC, align 8
  %122 = load i64, i64* %71, align 8
  store i64 %122, i64* %RAX, align 8, !tbaa !2428
  %123 = load i64, i64* %RSP, align 8
  %124 = add i64 %123, 32
  store i64 %124, i64* %RSP, align 8, !tbaa !2428
  %125 = icmp ugt i64 %123, -33
  %126 = zext i1 %125 to i8
  store i8 %126, i8* %13, align 1, !tbaa !2432
  %127 = trunc i64 %124 to i32
  %128 = and i32 %127, 255
  %129 = tail call i32 @llvm.ctpop.i32(i32 %128) #8
  %130 = trunc i32 %129 to i8
  %131 = and i8 %130, 1
  %132 = xor i8 %131, 1
  store i8 %132, i8* %20, align 1, !tbaa !2446
  %133 = xor i64 %123, %124
  %134 = lshr i64 %133, 4
  %135 = trunc i64 %134 to i8
  %136 = and i8 %135, 1
  store i8 %136, i8* %25, align 1, !tbaa !2447
  %137 = icmp eq i64 %124, 0
  %138 = zext i1 %137 to i8
  store i8 %138, i8* %28, align 1, !tbaa !2448
  %139 = lshr i64 %124, 63
  %140 = trunc i64 %139 to i8
  store i8 %140, i8* %31, align 1, !tbaa !2449
  %141 = lshr i64 %123, 63
  %142 = xor i64 %139, %141
  %143 = add nuw nsw i64 %142, %139
  %144 = icmp eq i64 %143, 2
  %145 = zext i1 %144 to i8
  store i8 %145, i8* %37, align 1, !tbaa !2450
  %146 = add i64 %120, 9
  store i64 %146, i64* %PC, align 8
  %147 = add i64 %123, 40
  %148 = inttoptr i64 %124 to i64*
  %149 = load i64, i64* %148, align 8
  store i64 %149, i64* %RBP, align 8, !tbaa !2428
  store i64 %147, i64* %RSP, align 8, !tbaa !2428
  %150 = add i64 %120, 10
  store i64 %150, i64* %PC, align 8
  %151 = inttoptr i64 %147 to i64*
  %152 = load i64, i64* %151, align 8
  store i64 %152, i64* %PC, align 8, !tbaa !2428
  %153 = add i64 %123, 48
  store i64 %153, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %60
}

; Function Attrs: noinline
define %struct.Memory* @sub_402e70___libc_csu_fini(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_402e70:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = add i64 %1, 2
  store i64 %3, i64* %PC, align 8
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %5 = load i64, i64* %4, align 8, !tbaa !2428
  %6 = inttoptr i64 %5 to i64*
  %7 = load i64, i64* %6, align 8
  store i64 %7, i64* %PC, align 8, !tbaa !2428
  %8 = add i64 %5, 8
  store i64 %8, i64* %4, align 8, !tbaa !2428
  ret %struct.Memory* %2
}

; Function Attrs: noinline
define %struct.Memory* @sub_400880_main(%struct.State* noalias dereferenceable(3376), i64, %struct.Memory* noalias) local_unnamed_addr #6 {
block_400880:
  %PC = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 33, i32 0, i32 0
  %3 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 1, i32 0
  %EAX = bitcast %union.anon* %3 to i32*
  %4 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 11, i32 0
  %EDI = bitcast %union.anon* %4 to i32*
  %RAX = getelementptr inbounds %union.anon, %union.anon* %3, i64 0, i32 0
  %RBX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 3, i32 0, i32 0
  %RCX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 5, i32 0, i32 0
  %RDX = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 7, i32 0, i32 0
  %RSI = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 9, i32 0, i32 0
  %RDI = getelementptr inbounds %union.anon, %union.anon* %4, i64 0, i32 0
  %RSP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 13, i32 0, i32 0
  %RBP = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 15, i32 0, i32 0
  %R8 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 17, i32 0, i32 0
  %R9 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 19, i32 0, i32 0
  %R10 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 21, i32 0, i32 0
  %R11 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 23, i32 0, i32 0
  %R12 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 25, i32 0, i32 0
  %R13 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 27, i32 0, i32 0
  %R14 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 29, i32 0, i32 0
  %R15 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 6, i32 31, i32 0, i32 0
  %5 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1
  %6 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1
  %7 = load i64, i64* %RBP, align 8
  %8 = add i64 %1, 1
  store i64 %8, i64* %PC, align 8
  %9 = load i64, i64* %RSP, align 8, !tbaa !2428
  %10 = add i64 %9, -8
  %11 = inttoptr i64 %10 to i64*
  store i64 %7, i64* %11, align 8
  %12 = load i64, i64* %PC, align 8
  store i64 %10, i64* %RBP, align 8, !tbaa !2428
  %13 = load i64, i64* %R15, align 8
  %14 = add i64 %12, 5
  store i64 %14, i64* %PC, align 8
  %15 = add i64 %9, -16
  %16 = inttoptr i64 %15 to i64*
  store i64 %13, i64* %16, align 8
  %17 = load i64, i64* %R14, align 8
  %18 = load i64, i64* %PC, align 8
  %19 = add i64 %18, 2
  store i64 %19, i64* %PC, align 8
  %20 = add i64 %9, -24
  %21 = inttoptr i64 %20 to i64*
  store i64 %17, i64* %21, align 8
  %22 = load i64, i64* %R13, align 8
  %23 = load i64, i64* %PC, align 8
  %24 = add i64 %23, 2
  store i64 %24, i64* %PC, align 8
  %25 = add i64 %9, -32
  %26 = inttoptr i64 %25 to i64*
  store i64 %22, i64* %26, align 8
  %27 = load i64, i64* %R12, align 8
  %28 = load i64, i64* %PC, align 8
  %29 = add i64 %28, 2
  store i64 %29, i64* %PC, align 8
  %30 = add i64 %9, -40
  %31 = inttoptr i64 %30 to i64*
  store i64 %27, i64* %31, align 8
  %32 = load i64, i64* %RBX, align 8
  %33 = load i64, i64* %PC, align 8
  %34 = add i64 %33, 1
  store i64 %34, i64* %PC, align 8
  %35 = add i64 %9, -48
  %36 = inttoptr i64 %35 to i64*
  store i64 %32, i64* %36, align 8
  %37 = load i64, i64* %PC, align 8
  %38 = add i64 %9, -440
  store i64 %38, i64* %RSP, align 8, !tbaa !2428
  %39 = icmp ult i64 %35, 392
  %40 = zext i1 %39 to i8
  %41 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 1
  store i8 %40, i8* %41, align 1, !tbaa !2432
  %42 = trunc i64 %38 to i32
  %43 = and i32 %42, 255
  %44 = tail call i32 @llvm.ctpop.i32(i32 %43) #8
  %45 = trunc i32 %44 to i8
  %46 = and i8 %45, 1
  %47 = xor i8 %46, 1
  %48 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 3
  store i8 %47, i8* %48, align 1, !tbaa !2446
  %49 = xor i64 %35, %38
  %50 = lshr i64 %49, 4
  %51 = trunc i64 %50 to i8
  %52 = and i8 %51, 1
  %53 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 5
  store i8 %52, i8* %53, align 1, !tbaa !2447
  %54 = icmp eq i64 %38, 0
  %55 = zext i1 %54 to i8
  %56 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 7
  store i8 %55, i8* %56, align 1, !tbaa !2448
  %57 = lshr i64 %38, 63
  %58 = trunc i64 %57 to i8
  %59 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 9
  store i8 %58, i8* %59, align 1, !tbaa !2449
  %60 = lshr i64 %35, 63
  %61 = xor i64 %57, %60
  %62 = add nuw nsw i64 %61, %60
  %63 = icmp eq i64 %62, 2
  %64 = zext i1 %63 to i8
  %65 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 2, i32 13
  store i8 %64, i8* %65, align 1, !tbaa !2450
  store i64 4225, i64* %RCX, align 8, !tbaa !2428
  store i64 8, i64* %RAX, align 8, !tbaa !2428
  %66 = load i64, i64* %RBP, align 8
  %67 = add i64 %66, -44
  %68 = add i64 %37, 26
  store i64 %68, i64* %PC, align 8
  %69 = inttoptr i64 %67 to i32*
  store i32 0, i32* %69, align 4
  %70 = load i64, i64* %RBP, align 8
  %71 = add i64 %70, -48
  %72 = load i32, i32* %EDI, align 4
  %73 = load i64, i64* %PC, align 8
  %74 = add i64 %73, 3
  store i64 %74, i64* %PC, align 8
  %75 = inttoptr i64 %71 to i32*
  store i32 %72, i32* %75, align 4
  %76 = load i64, i64* %RBP, align 8
  %77 = add i64 %76, -56
  %78 = load i64, i64* %RSI, align 8
  %79 = load i64, i64* %PC, align 8
  %80 = add i64 %79, 4
  store i64 %80, i64* %PC, align 8
  %81 = inttoptr i64 %77 to i64*
  store i64 %78, i64* %81, align 8
  %82 = load i64, i64* %RBP, align 8
  %83 = add i64 %82, -60
  %84 = load i64, i64* %PC, align 8
  %85 = add i64 %84, 7
  store i64 %85, i64* %PC, align 8
  %86 = inttoptr i64 %83 to i32*
  store i32 64, i32* %86, align 4
  %87 = load i64, i64* %RBP, align 8
  %88 = add i64 %87, -64
  %89 = load i64, i64* %PC, align 8
  %90 = add i64 %89, 7
  store i64 %90, i64* %PC, align 8
  %91 = inttoptr i64 %88 to i32*
  store i32 64, i32* %91, align 4
  %92 = load i64, i64* %RBP, align 8
  %93 = add i64 %92, -68
  %94 = load i64, i64* %PC, align 8
  %95 = add i64 %94, 7
  store i64 %95, i64* %PC, align 8
  %96 = inttoptr i64 %93 to i32*
  store i32 64, i32* %96, align 4
  %97 = load i64, i64* %RCX, align 8
  %98 = load i64, i64* %PC, align 8
  store i64 %97, i64* %RDI, align 8, !tbaa !2428
  %99 = load i32, i32* %EAX, align 4
  %100 = zext i32 %99 to i64
  store i64 %100, i64* %RSI, align 8, !tbaa !2428
  %101 = add i64 %98, -259
  %102 = add i64 %98, 10
  %103 = load i64, i64* %RSP, align 8, !tbaa !2428
  %104 = add i64 %103, -8
  %105 = inttoptr i64 %104 to i64*
  store i64 %102, i64* %105, align 8
  store i64 %104, i64* %RSP, align 8, !tbaa !2428
  store i64 %101, i64* %PC, align 8, !tbaa !2428
  %106 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %101, %struct.Memory* %2)
  %107 = load i64, i64* %PC, align 8
  store i64 4225, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %108 = load i64, i64* %RBP, align 8
  %109 = add i64 %108, -96
  %110 = load i64, i64* %RAX, align 8
  %111 = add i64 %107, 16
  store i64 %111, i64* %PC, align 8
  %112 = inttoptr i64 %109 to i64*
  store i64 %110, i64* %112, align 8
  %113 = load i64, i64* %PC, align 8
  %114 = add i64 %113, -285
  %115 = add i64 %113, 5
  %116 = load i64, i64* %RSP, align 8, !tbaa !2428
  %117 = add i64 %116, -8
  %118 = inttoptr i64 %117 to i64*
  store i64 %115, i64* %118, align 8
  store i64 %117, i64* %RSP, align 8, !tbaa !2428
  store i64 %114, i64* %PC, align 8, !tbaa !2428
  %119 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %114, %struct.Memory* %106)
  %120 = load i64, i64* %PC, align 8
  store i64 4225, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %121 = load i64, i64* %RBP, align 8
  %122 = add i64 %121, -104
  %123 = load i64, i64* %RAX, align 8
  %124 = add i64 %120, 16
  store i64 %124, i64* %PC, align 8
  %125 = inttoptr i64 %122 to i64*
  store i64 %123, i64* %125, align 8
  %126 = load i64, i64* %PC, align 8
  %127 = add i64 %126, -306
  %128 = add i64 %126, 5
  %129 = load i64, i64* %RSP, align 8, !tbaa !2428
  %130 = add i64 %129, -8
  %131 = inttoptr i64 %130 to i64*
  store i64 %128, i64* %131, align 8
  store i64 %130, i64* %RSP, align 8, !tbaa !2428
  store i64 %127, i64* %PC, align 8, !tbaa !2428
  %132 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %127, %struct.Memory* %119)
  %133 = load i64, i64* %PC, align 8
  store i64 4225, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %134 = load i64, i64* %RBP, align 8
  %135 = add i64 %134, -112
  %136 = load i64, i64* %RAX, align 8
  %137 = add i64 %133, 16
  store i64 %137, i64* %PC, align 8
  %138 = inttoptr i64 %135 to i64*
  store i64 %136, i64* %138, align 8
  %139 = load i64, i64* %PC, align 8
  %140 = add i64 %139, -327
  %141 = add i64 %139, 5
  %142 = load i64, i64* %RSP, align 8, !tbaa !2428
  %143 = add i64 %142, -8
  %144 = inttoptr i64 %143 to i64*
  store i64 %141, i64* %144, align 8
  store i64 %143, i64* %RSP, align 8, !tbaa !2428
  store i64 %140, i64* %PC, align 8, !tbaa !2428
  %145 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %140, %struct.Memory* %132)
  %146 = load i64, i64* %PC, align 8
  store i64 274625, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %147 = load i64, i64* %RBP, align 8
  %148 = add i64 %147, -120
  %149 = load i64, i64* %RAX, align 8
  %150 = add i64 %146, 16
  store i64 %150, i64* %PC, align 8
  %151 = inttoptr i64 %148 to i64*
  store i64 %149, i64* %151, align 8
  %152 = load i64, i64* %PC, align 8
  %153 = add i64 %152, -348
  %154 = add i64 %152, 5
  %155 = load i64, i64* %RSP, align 8, !tbaa !2428
  %156 = add i64 %155, -8
  %157 = inttoptr i64 %156 to i64*
  store i64 %154, i64* %157, align 8
  store i64 %156, i64* %RSP, align 8, !tbaa !2428
  store i64 %153, i64* %PC, align 8, !tbaa !2428
  %158 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %153, %struct.Memory* %145)
  %159 = load i64, i64* %PC, align 8
  store i64 274625, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %160 = load i64, i64* %RBP, align 8
  %161 = add i64 %160, -128
  %162 = load i64, i64* %RAX, align 8
  %163 = add i64 %159, 16
  store i64 %163, i64* %PC, align 8
  %164 = inttoptr i64 %161 to i64*
  store i64 %162, i64* %164, align 8
  %165 = load i64, i64* %PC, align 8
  %166 = add i64 %165, -369
  %167 = add i64 %165, 5
  %168 = load i64, i64* %RSP, align 8, !tbaa !2428
  %169 = add i64 %168, -8
  %170 = inttoptr i64 %169 to i64*
  store i64 %167, i64* %170, align 8
  store i64 %169, i64* %RSP, align 8, !tbaa !2428
  store i64 %166, i64* %PC, align 8, !tbaa !2428
  %171 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %166, %struct.Memory* %158)
  %172 = load i64, i64* %PC, align 8
  store i64 274625, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %173 = load i64, i64* %RBP, align 8
  %174 = add i64 %173, -136
  %175 = load i64, i64* %RAX, align 8
  %176 = add i64 %172, 19
  store i64 %176, i64* %PC, align 8
  %177 = inttoptr i64 %174 to i64*
  store i64 %175, i64* %177, align 8
  %178 = load i64, i64* %PC, align 8
  %179 = add i64 %178, -393
  %180 = add i64 %178, 5
  %181 = load i64, i64* %RSP, align 8, !tbaa !2428
  %182 = add i64 %181, -8
  %183 = inttoptr i64 %182 to i64*
  store i64 %180, i64* %183, align 8
  store i64 %182, i64* %RSP, align 8, !tbaa !2428
  store i64 %179, i64* %PC, align 8, !tbaa !2428
  %184 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %179, %struct.Memory* %171)
  %185 = load i64, i64* %PC, align 8
  store i64 274625, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %186 = load i64, i64* %RBP, align 8
  %187 = add i64 %186, -144
  %188 = load i64, i64* %RAX, align 8
  %189 = add i64 %185, 19
  store i64 %189, i64* %PC, align 8
  %190 = inttoptr i64 %187 to i64*
  store i64 %188, i64* %190, align 8
  %191 = load i64, i64* %PC, align 8
  %192 = add i64 %191, -417
  %193 = add i64 %191, 5
  %194 = load i64, i64* %RSP, align 8, !tbaa !2428
  %195 = add i64 %194, -8
  %196 = inttoptr i64 %195 to i64*
  store i64 %193, i64* %196, align 8
  store i64 %195, i64* %RSP, align 8, !tbaa !2428
  store i64 %192, i64* %PC, align 8, !tbaa !2428
  %197 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %192, %struct.Memory* %184)
  %198 = load i64, i64* %PC, align 8
  store i64 274625, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %199 = load i64, i64* %RBP, align 8
  %200 = add i64 %199, -152
  %201 = load i64, i64* %RAX, align 8
  %202 = add i64 %198, 19
  store i64 %202, i64* %PC, align 8
  %203 = inttoptr i64 %200 to i64*
  store i64 %201, i64* %203, align 8
  %204 = load i64, i64* %PC, align 8
  %205 = add i64 %204, -441
  %206 = add i64 %204, 5
  %207 = load i64, i64* %RSP, align 8, !tbaa !2428
  %208 = add i64 %207, -8
  %209 = inttoptr i64 %208 to i64*
  store i64 %206, i64* %209, align 8
  store i64 %208, i64* %RSP, align 8, !tbaa !2428
  store i64 %205, i64* %PC, align 8, !tbaa !2428
  %210 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %205, %struct.Memory* %197)
  %211 = load i64, i64* %PC, align 8
  store i64 274625, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %212 = load i64, i64* %RBP, align 8
  %213 = add i64 %212, -160
  %214 = load i64, i64* %RAX, align 8
  %215 = add i64 %211, 19
  store i64 %215, i64* %PC, align 8
  %216 = inttoptr i64 %213 to i64*
  store i64 %214, i64* %216, align 8
  %217 = load i64, i64* %PC, align 8
  %218 = add i64 %217, -465
  %219 = add i64 %217, 5
  %220 = load i64, i64* %RSP, align 8, !tbaa !2428
  %221 = add i64 %220, -8
  %222 = inttoptr i64 %221 to i64*
  store i64 %219, i64* %222, align 8
  store i64 %221, i64* %RSP, align 8, !tbaa !2428
  store i64 %218, i64* %PC, align 8, !tbaa !2428
  %223 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %218, %struct.Memory* %210)
  %224 = load i64, i64* %PC, align 8
  store i64 274625, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %225 = load i64, i64* %RBP, align 8
  %226 = add i64 %225, -168
  %227 = load i64, i64* %RAX, align 8
  %228 = add i64 %224, 19
  store i64 %228, i64* %PC, align 8
  %229 = inttoptr i64 %226 to i64*
  store i64 %227, i64* %229, align 8
  %230 = load i64, i64* %PC, align 8
  %231 = add i64 %230, -489
  %232 = add i64 %230, 5
  %233 = load i64, i64* %RSP, align 8, !tbaa !2428
  %234 = add i64 %233, -8
  %235 = inttoptr i64 %234 to i64*
  store i64 %232, i64* %235, align 8
  store i64 %234, i64* %RSP, align 8, !tbaa !2428
  store i64 %231, i64* %PC, align 8, !tbaa !2428
  %236 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %231, %struct.Memory* %223)
  %237 = load i64, i64* %PC, align 8
  store i64 274625, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %238 = load i64, i64* %RBP, align 8
  %239 = add i64 %238, -176
  %240 = load i64, i64* %RAX, align 8
  %241 = add i64 %237, 19
  store i64 %241, i64* %PC, align 8
  %242 = inttoptr i64 %239 to i64*
  store i64 %240, i64* %242, align 8
  %243 = load i64, i64* %PC, align 8
  %244 = add i64 %243, -513
  %245 = add i64 %243, 5
  %246 = load i64, i64* %RSP, align 8, !tbaa !2428
  %247 = add i64 %246, -8
  %248 = inttoptr i64 %247 to i64*
  store i64 %245, i64* %248, align 8
  store i64 %247, i64* %RSP, align 8, !tbaa !2428
  store i64 %244, i64* %PC, align 8, !tbaa !2428
  %249 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %244, %struct.Memory* %236)
  %250 = load i64, i64* %PC, align 8
  store i64 65, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %251 = load i64, i64* %RBP, align 8
  %252 = add i64 %251, -184
  %253 = load i64, i64* %RAX, align 8
  %254 = add i64 %250, 19
  store i64 %254, i64* %PC, align 8
  %255 = inttoptr i64 %252 to i64*
  store i64 %253, i64* %255, align 8
  %256 = load i64, i64* %PC, align 8
  %257 = add i64 %256, -537
  %258 = add i64 %256, 5
  %259 = load i64, i64* %RSP, align 8, !tbaa !2428
  %260 = add i64 %259, -8
  %261 = inttoptr i64 %260 to i64*
  store i64 %258, i64* %261, align 8
  store i64 %260, i64* %RSP, align 8, !tbaa !2428
  store i64 %257, i64* %PC, align 8, !tbaa !2428
  %262 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %257, %struct.Memory* %249)
  %263 = load i64, i64* %PC, align 8
  store i64 65, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %264 = load i64, i64* %RBP, align 8
  %265 = add i64 %264, -192
  %266 = load i64, i64* %RAX, align 8
  %267 = add i64 %263, 19
  store i64 %267, i64* %PC, align 8
  %268 = inttoptr i64 %265 to i64*
  store i64 %266, i64* %268, align 8
  %269 = load i64, i64* %PC, align 8
  %270 = add i64 %269, -561
  %271 = add i64 %269, 5
  %272 = load i64, i64* %RSP, align 8, !tbaa !2428
  %273 = add i64 %272, -8
  %274 = inttoptr i64 %273 to i64*
  store i64 %271, i64* %274, align 8
  store i64 %273, i64* %RSP, align 8, !tbaa !2428
  store i64 %270, i64* %PC, align 8, !tbaa !2428
  %275 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %270, %struct.Memory* %262)
  %276 = load i64, i64* %PC, align 8
  store i64 65, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %277 = load i64, i64* %RBP, align 8
  %278 = add i64 %277, -200
  %279 = load i64, i64* %RAX, align 8
  %280 = add i64 %276, 19
  store i64 %280, i64* %PC, align 8
  %281 = inttoptr i64 %278 to i64*
  store i64 %279, i64* %281, align 8
  %282 = load i64, i64* %PC, align 8
  %283 = add i64 %282, -585
  %284 = add i64 %282, 5
  %285 = load i64, i64* %RSP, align 8, !tbaa !2428
  %286 = add i64 %285, -8
  %287 = inttoptr i64 %286 to i64*
  store i64 %284, i64* %287, align 8
  store i64 %286, i64* %RSP, align 8, !tbaa !2428
  store i64 %283, i64* %PC, align 8, !tbaa !2428
  %288 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %283, %struct.Memory* %275)
  %289 = load i64, i64* %PC, align 8
  store i64 65, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %290 = load i64, i64* %RBP, align 8
  %291 = add i64 %290, -208
  %292 = load i64, i64* %RAX, align 8
  %293 = add i64 %289, 19
  store i64 %293, i64* %PC, align 8
  %294 = inttoptr i64 %291 to i64*
  store i64 %292, i64* %294, align 8
  %295 = load i64, i64* %PC, align 8
  %296 = add i64 %295, -609
  %297 = add i64 %295, 5
  %298 = load i64, i64* %RSP, align 8, !tbaa !2428
  %299 = add i64 %298, -8
  %300 = inttoptr i64 %299 to i64*
  store i64 %297, i64* %300, align 8
  store i64 %299, i64* %RSP, align 8, !tbaa !2428
  store i64 %296, i64* %PC, align 8, !tbaa !2428
  %301 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %296, %struct.Memory* %288)
  %302 = load i64, i64* %PC, align 8
  store i64 65, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %303 = load i64, i64* %RBP, align 8
  %304 = add i64 %303, -216
  %305 = load i64, i64* %RAX, align 8
  %306 = add i64 %302, 19
  store i64 %306, i64* %PC, align 8
  %307 = inttoptr i64 %304 to i64*
  store i64 %305, i64* %307, align 8
  %308 = load i64, i64* %PC, align 8
  %309 = add i64 %308, -633
  %310 = add i64 %308, 5
  %311 = load i64, i64* %RSP, align 8, !tbaa !2428
  %312 = add i64 %311, -8
  %313 = inttoptr i64 %312 to i64*
  store i64 %310, i64* %313, align 8
  store i64 %312, i64* %RSP, align 8, !tbaa !2428
  store i64 %309, i64* %PC, align 8, !tbaa !2428
  %314 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %309, %struct.Memory* %301)
  %315 = load i64, i64* %PC, align 8
  store i64 65, i64* %RDI, align 8, !tbaa !2428
  store i64 8, i64* %RSI, align 8, !tbaa !2428
  %316 = load i64, i64* %RBP, align 8
  %317 = add i64 %316, -224
  %318 = load i64, i64* %RAX, align 8
  %319 = add i64 %315, 19
  store i64 %319, i64* %PC, align 8
  %320 = inttoptr i64 %317 to i64*
  store i64 %318, i64* %320, align 8
  %321 = load i64, i64* %PC, align 8
  %322 = add i64 %321, -657
  %323 = add i64 %321, 5
  %324 = load i64, i64* %RSP, align 8, !tbaa !2428
  %325 = add i64 %324, -8
  %326 = inttoptr i64 %325 to i64*
  store i64 %323, i64* %326, align 8
  store i64 %325, i64* %RSP, align 8, !tbaa !2428
  store i64 %322, i64* %PC, align 8, !tbaa !2428
  %327 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data_renamed_(%struct.State* nonnull %0, i64 %322, %struct.Memory* %314)
  %328 = load i64, i64* %RBP, align 8
  %329 = add i64 %328, -80
  %330 = load i64, i64* %PC, align 8
  store i64 %329, i64* %RCX, align 8, !tbaa !2428
  %331 = add i64 %328, -88
  store i64 %331, i64* %R8, align 8, !tbaa !2428
  %332 = add i64 %328, -232
  %333 = load i64, i64* %RAX, align 8
  %334 = add i64 %330, 15
  store i64 %334, i64* %PC, align 8
  %335 = inttoptr i64 %332 to i64*
  store i64 %333, i64* %335, align 8
  %336 = load i64, i64* %RBP, align 8
  %337 = add i64 %336, -60
  %338 = load i64, i64* %PC, align 8
  %339 = add i64 %338, 3
  store i64 %339, i64* %PC, align 8
  %340 = inttoptr i64 %337 to i32*
  %341 = load i32, i32* %340, align 4
  %342 = zext i32 %341 to i64
  store i64 %342, i64* %RDI, align 8, !tbaa !2428
  %343 = add i64 %336, -68
  %344 = add i64 %338, 6
  store i64 %344, i64* %PC, align 8
  %345 = inttoptr i64 %343 to i32*
  %346 = load i32, i32* %345, align 4
  %347 = zext i32 %346 to i64
  store i64 %347, i64* %RSI, align 8, !tbaa !2428
  %348 = add i64 %336, -64
  %349 = add i64 %338, 9
  store i64 %349, i64* %PC, align 8
  %350 = inttoptr i64 %348 to i32*
  %351 = load i32, i32* %350, align 4
  %352 = zext i32 %351 to i64
  store i64 %352, i64* %RDX, align 8, !tbaa !2428
  %353 = add i64 %336, -96
  %354 = add i64 %338, 13
  store i64 %354, i64* %PC, align 8
  %355 = inttoptr i64 %353 to i64*
  %356 = load i64, i64* %355, align 8
  store i64 %356, i64* %R9, align 8, !tbaa !2428
  %357 = add i64 %336, -104
  %358 = add i64 %338, 17
  store i64 %358, i64* %PC, align 8
  %359 = inttoptr i64 %357 to i64*
  %360 = load i64, i64* %359, align 8
  store i64 %360, i64* %RAX, align 8, !tbaa !2428
  %361 = add i64 %336, -136
  %362 = add i64 %338, 24
  store i64 %362, i64* %PC, align 8
  %363 = inttoptr i64 %361 to i64*
  %364 = load i64, i64* %363, align 8
  store i64 %364, i64* %R10, align 8, !tbaa !2428
  %365 = add i64 %336, -144
  %366 = add i64 %338, 31
  store i64 %366, i64* %PC, align 8
  %367 = inttoptr i64 %365 to i64*
  %368 = load i64, i64* %367, align 8
  store i64 %368, i64* %R11, align 8, !tbaa !2428
  %369 = add i64 %336, -152
  %370 = add i64 %338, 38
  store i64 %370, i64* %PC, align 8
  %371 = inttoptr i64 %369 to i64*
  %372 = load i64, i64* %371, align 8
  store i64 %372, i64* %RBX, align 8, !tbaa !2428
  %373 = add i64 %336, -192
  %374 = add i64 %338, 45
  store i64 %374, i64* %PC, align 8
  %375 = inttoptr i64 %373 to i64*
  %376 = load i64, i64* %375, align 8
  store i64 %376, i64* %R14, align 8, !tbaa !2428
  %377 = add i64 %336, -200
  %378 = add i64 %338, 52
  store i64 %378, i64* %PC, align 8
  %379 = inttoptr i64 %377 to i64*
  %380 = load i64, i64* %379, align 8
  store i64 %380, i64* %R15, align 8, !tbaa !2428
  %381 = add i64 %336, -208
  %382 = add i64 %338, 59
  store i64 %382, i64* %PC, align 8
  %383 = inttoptr i64 %381 to i64*
  %384 = load i64, i64* %383, align 8
  store i64 %384, i64* %R12, align 8, !tbaa !2428
  %385 = add i64 %336, -216
  %386 = add i64 %338, 66
  store i64 %386, i64* %PC, align 8
  %387 = inttoptr i64 %385 to i64*
  %388 = load i64, i64* %387, align 8
  store i64 %388, i64* %R13, align 8, !tbaa !2428
  %389 = add i64 %336, -240
  %390 = add i64 %338, 73
  store i64 %390, i64* %PC, align 8
  %391 = inttoptr i64 %389 to i64*
  store i64 %360, i64* %391, align 8
  %392 = load i64, i64* %RBP, align 8
  %393 = add i64 %392, -224
  %394 = load i64, i64* %PC, align 8
  %395 = add i64 %394, 7
  store i64 %395, i64* %PC, align 8
  %396 = inttoptr i64 %393 to i64*
  %397 = load i64, i64* %396, align 8
  store i64 %397, i64* %RAX, align 8, !tbaa !2428
  %398 = add i64 %392, -248
  %399 = add i64 %394, 14
  store i64 %399, i64* %PC, align 8
  %400 = inttoptr i64 %398 to i64*
  store i64 %397, i64* %400, align 8
  %401 = load i64, i64* %RBP, align 8
  %402 = add i64 %401, -232
  %403 = load i64, i64* %PC, align 8
  %404 = add i64 %403, 7
  store i64 %404, i64* %PC, align 8
  %405 = inttoptr i64 %402 to i64*
  %406 = load i64, i64* %405, align 8
  store i64 %406, i64* %RAX, align 8, !tbaa !2428
  %407 = add i64 %401, -256
  %408 = add i64 %403, 14
  store i64 %408, i64* %PC, align 8
  %409 = inttoptr i64 %407 to i64*
  store i64 %406, i64* %409, align 8
  %410 = load i64, i64* %RBP, align 8
  %411 = add i64 %410, -240
  %412 = load i64, i64* %PC, align 8
  %413 = add i64 %412, 7
  store i64 %413, i64* %PC, align 8
  %414 = inttoptr i64 %411 to i64*
  %415 = load i64, i64* %414, align 8
  store i64 %415, i64* %RAX, align 8, !tbaa !2428
  %416 = bitcast i64* %RSP to i64**
  %417 = load i64*, i64** %416, align 8
  %418 = add i64 %412, 11
  store i64 %418, i64* %PC, align 8
  store i64 %415, i64* %417, align 8
  %419 = load i64, i64* %RSP, align 8
  %420 = add i64 %419, 8
  %421 = load i64, i64* %R10, align 8
  %422 = load i64, i64* %PC, align 8
  %423 = add i64 %422, 5
  store i64 %423, i64* %PC, align 8
  %424 = inttoptr i64 %420 to i64*
  store i64 %421, i64* %424, align 8
  %425 = load i64, i64* %RSP, align 8
  %426 = add i64 %425, 16
  %427 = load i64, i64* %R11, align 8
  %428 = load i64, i64* %PC, align 8
  %429 = add i64 %428, 5
  store i64 %429, i64* %PC, align 8
  %430 = inttoptr i64 %426 to i64*
  store i64 %427, i64* %430, align 8
  %431 = load i64, i64* %RSP, align 8
  %432 = add i64 %431, 24
  %433 = load i64, i64* %RBX, align 8
  %434 = load i64, i64* %PC, align 8
  %435 = add i64 %434, 5
  store i64 %435, i64* %PC, align 8
  %436 = inttoptr i64 %432 to i64*
  store i64 %433, i64* %436, align 8
  %437 = load i64, i64* %RSP, align 8
  %438 = add i64 %437, 32
  %439 = load i64, i64* %R14, align 8
  %440 = load i64, i64* %PC, align 8
  %441 = add i64 %440, 5
  store i64 %441, i64* %PC, align 8
  %442 = inttoptr i64 %438 to i64*
  store i64 %439, i64* %442, align 8
  %443 = load i64, i64* %RSP, align 8
  %444 = add i64 %443, 40
  %445 = load i64, i64* %R15, align 8
  %446 = load i64, i64* %PC, align 8
  %447 = add i64 %446, 5
  store i64 %447, i64* %PC, align 8
  %448 = inttoptr i64 %444 to i64*
  store i64 %445, i64* %448, align 8
  %449 = load i64, i64* %RSP, align 8
  %450 = add i64 %449, 48
  %451 = load i64, i64* %R12, align 8
  %452 = load i64, i64* %PC, align 8
  %453 = add i64 %452, 5
  store i64 %453, i64* %PC, align 8
  %454 = inttoptr i64 %450 to i64*
  store i64 %451, i64* %454, align 8
  %455 = load i64, i64* %RSP, align 8
  %456 = add i64 %455, 56
  %457 = load i64, i64* %R13, align 8
  %458 = load i64, i64* %PC, align 8
  %459 = add i64 %458, 5
  store i64 %459, i64* %PC, align 8
  %460 = inttoptr i64 %456 to i64*
  store i64 %457, i64* %460, align 8
  %461 = load i64, i64* %RBP, align 8
  %462 = add i64 %461, -248
  %463 = load i64, i64* %PC, align 8
  %464 = add i64 %463, 7
  store i64 %464, i64* %PC, align 8
  %465 = inttoptr i64 %462 to i64*
  %466 = load i64, i64* %465, align 8
  store i64 %466, i64* %RAX, align 8, !tbaa !2428
  %467 = load i64, i64* %RSP, align 8
  %468 = add i64 %467, 64
  %469 = add i64 %463, 12
  store i64 %469, i64* %PC, align 8
  %470 = inttoptr i64 %468 to i64*
  store i64 %466, i64* %470, align 8
  %471 = load i64, i64* %RBP, align 8
  %472 = add i64 %471, -256
  %473 = load i64, i64* %PC, align 8
  %474 = add i64 %473, 7
  store i64 %474, i64* %PC, align 8
  %475 = inttoptr i64 %472 to i64*
  %476 = load i64, i64* %475, align 8
  store i64 %476, i64* %RAX, align 8, !tbaa !2428
  %477 = load i64, i64* %RSP, align 8
  %478 = add i64 %477, 72
  %479 = add i64 %473, 12
  store i64 %479, i64* %PC, align 8
  %480 = inttoptr i64 %478 to i64*
  store i64 %476, i64* %480, align 8
  %481 = load i64, i64* %PC, align 8
  %482 = add i64 %481, 1152
  %483 = add i64 %481, 5
  %484 = load i64, i64* %RSP, align 8, !tbaa !2428
  %485 = add i64 %484, -8
  %486 = inttoptr i64 %485 to i64*
  store i64 %483, i64* %486, align 8
  store i64 %485, i64* %RSP, align 8, !tbaa !2428
  store i64 %482, i64* %PC, align 8, !tbaa !2428
  %487 = tail call %struct.Memory* @sub_400f90_init_array_renamed_(%struct.State* nonnull %0, i64 %482, %struct.Memory* %327)
  %488 = load i64, i64* %RBP, align 8
  %489 = add i64 %488, -60
  %490 = load i64, i64* %PC, align 8
  %491 = add i64 %490, 3
  store i64 %491, i64* %PC, align 8
  %492 = inttoptr i64 %489 to i32*
  %493 = load i32, i32* %492, align 4
  %494 = zext i32 %493 to i64
  store i64 %494, i64* %RDI, align 8, !tbaa !2428
  %495 = add i64 %488, -68
  %496 = add i64 %490, 6
  store i64 %496, i64* %PC, align 8
  %497 = inttoptr i64 %495 to i32*
  %498 = load i32, i32* %497, align 4
  %499 = zext i32 %498 to i64
  store i64 %499, i64* %RSI, align 8, !tbaa !2428
  %500 = add i64 %488, -64
  %501 = add i64 %490, 9
  store i64 %501, i64* %PC, align 8
  %502 = inttoptr i64 %500 to i32*
  %503 = load i32, i32* %502, align 4
  %504 = zext i32 %503 to i64
  store i64 %504, i64* %RDX, align 8, !tbaa !2428
  %505 = add i64 %488, -80
  %506 = add i64 %490, 14
  store i64 %506, i64* %PC, align 8
  %507 = inttoptr i64 %505 to i64*
  %508 = load i64, i64* %507, align 8
  %509 = getelementptr inbounds [32 x %union.VectorReg], [32 x %union.VectorReg]* %5, i64 0, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %508, i64* %509, align 1, !tbaa !2452
  %510 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 0, i32 0, i32 0, i32 0, i64 1
  %511 = bitcast i64* %510 to double*
  store double 0.000000e+00, double* %511, align 1, !tbaa !2452
  %512 = add i64 %488, -88
  %513 = add i64 %490, 19
  store i64 %513, i64* %PC, align 8
  %514 = inttoptr i64 %512 to i64*
  %515 = load i64, i64* %514, align 8
  %516 = getelementptr inbounds %union.VectorReg, %union.VectorReg* %6, i64 0, i32 0, i32 0, i32 0, i64 0
  store i64 %515, i64* %516, align 1, !tbaa !2452
  %517 = getelementptr inbounds %struct.State, %struct.State* %0, i64 0, i32 1, i64 1, i32 0, i32 0, i32 0, i64 1
  %518 = bitcast i64* %517 to double*
  store double 0.000000e+00, double* %518, align 1, !tbaa !2452
  %519 = add i64 %488, -96
  %520 = add i64 %490, 23
  store i64 %520, i64* %PC, align 8
  %521 = inttoptr i64 %519 to i64*
  %522 = load i64, i64* %521, align 8
  store i64 %522, i64* %RCX, align 8, !tbaa !2428
  %523 = add i64 %488, -104
  %524 = add i64 %490, 27
  store i64 %524, i64* %PC, align 8
  %525 = inttoptr i64 %523 to i64*
  %526 = load i64, i64* %525, align 8
  store i64 %526, i64* %R8, align 8, !tbaa !2428
  %527 = add i64 %488, -112
  %528 = add i64 %490, 31
  store i64 %528, i64* %PC, align 8
  %529 = inttoptr i64 %527 to i64*
  %530 = load i64, i64* %529, align 8
  store i64 %530, i64* %R9, align 8, !tbaa !2428
  %531 = add i64 %488, -120
  %532 = add i64 %490, 35
  store i64 %532, i64* %PC, align 8
  %533 = inttoptr i64 %531 to i64*
  %534 = load i64, i64* %533, align 8
  store i64 %534, i64* %RAX, align 8, !tbaa !2428
  %535 = add i64 %488, -128
  %536 = add i64 %490, 39
  store i64 %536, i64* %PC, align 8
  %537 = inttoptr i64 %535 to i64*
  %538 = load i64, i64* %537, align 8
  store i64 %538, i64* %R10, align 8, !tbaa !2428
  %539 = add i64 %488, -136
  %540 = add i64 %490, 46
  store i64 %540, i64* %PC, align 8
  %541 = inttoptr i64 %539 to i64*
  %542 = load i64, i64* %541, align 8
  store i64 %542, i64* %R11, align 8, !tbaa !2428
  %543 = add i64 %488, -144
  %544 = add i64 %490, 53
  store i64 %544, i64* %PC, align 8
  %545 = inttoptr i64 %543 to i64*
  %546 = load i64, i64* %545, align 8
  store i64 %546, i64* %RBX, align 8, !tbaa !2428
  %547 = add i64 %488, -152
  %548 = add i64 %490, 60
  store i64 %548, i64* %PC, align 8
  %549 = inttoptr i64 %547 to i64*
  %550 = load i64, i64* %549, align 8
  store i64 %550, i64* %R14, align 8, !tbaa !2428
  %551 = add i64 %488, -192
  %552 = add i64 %490, 67
  store i64 %552, i64* %PC, align 8
  %553 = inttoptr i64 %551 to i64*
  %554 = load i64, i64* %553, align 8
  store i64 %554, i64* %R15, align 8, !tbaa !2428
  %555 = add i64 %488, -200
  %556 = add i64 %490, 74
  store i64 %556, i64* %PC, align 8
  %557 = inttoptr i64 %555 to i64*
  %558 = load i64, i64* %557, align 8
  store i64 %558, i64* %R12, align 8, !tbaa !2428
  %559 = load i64, i64* %RBP, align 8
  %560 = add i64 %559, -208
  %561 = add i64 %490, 81
  store i64 %561, i64* %PC, align 8
  %562 = inttoptr i64 %560 to i64*
  %563 = load i64, i64* %562, align 8
  store i64 %563, i64* %R13, align 8, !tbaa !2428
  %564 = add i64 %559, -264
  %565 = add i64 %490, 88
  store i64 %565, i64* %PC, align 8
  %566 = inttoptr i64 %564 to i64*
  store i64 %534, i64* %566, align 8
  %567 = load i64, i64* %RBP, align 8
  %568 = add i64 %567, -216
  %569 = load i64, i64* %PC, align 8
  %570 = add i64 %569, 7
  store i64 %570, i64* %PC, align 8
  %571 = inttoptr i64 %568 to i64*
  %572 = load i64, i64* %571, align 8
  store i64 %572, i64* %RAX, align 8, !tbaa !2428
  %573 = add i64 %567, -272
  %574 = add i64 %569, 14
  store i64 %574, i64* %PC, align 8
  %575 = inttoptr i64 %573 to i64*
  store i64 %572, i64* %575, align 8
  %576 = load i64, i64* %RBP, align 8
  %577 = add i64 %576, -224
  %578 = load i64, i64* %PC, align 8
  %579 = add i64 %578, 7
  store i64 %579, i64* %PC, align 8
  %580 = inttoptr i64 %577 to i64*
  %581 = load i64, i64* %580, align 8
  store i64 %581, i64* %RAX, align 8, !tbaa !2428
  %582 = add i64 %576, -280
  %583 = add i64 %578, 14
  store i64 %583, i64* %PC, align 8
  %584 = inttoptr i64 %582 to i64*
  store i64 %581, i64* %584, align 8
  %585 = load i64, i64* %RBP, align 8
  %586 = add i64 %585, -232
  %587 = load i64, i64* %PC, align 8
  %588 = add i64 %587, 7
  store i64 %588, i64* %PC, align 8
  %589 = inttoptr i64 %586 to i64*
  %590 = load i64, i64* %589, align 8
  store i64 %590, i64* %RAX, align 8, !tbaa !2428
  %591 = add i64 %585, -288
  %592 = add i64 %587, 14
  store i64 %592, i64* %PC, align 8
  %593 = inttoptr i64 %591 to i64*
  store i64 %590, i64* %593, align 8
  %594 = load i64, i64* %RBP, align 8
  %595 = add i64 %594, -264
  %596 = load i64, i64* %PC, align 8
  %597 = add i64 %596, 7
  store i64 %597, i64* %PC, align 8
  %598 = inttoptr i64 %595 to i64*
  %599 = load i64, i64* %598, align 8
  store i64 %599, i64* %RAX, align 8, !tbaa !2428
  %600 = load i64*, i64** %416, align 8
  %601 = add i64 %596, 11
  store i64 %601, i64* %PC, align 8
  store i64 %599, i64* %600, align 8
  %602 = load i64, i64* %RSP, align 8
  %603 = add i64 %602, 8
  %604 = load i64, i64* %R10, align 8
  %605 = load i64, i64* %PC, align 8
  %606 = add i64 %605, 5
  store i64 %606, i64* %PC, align 8
  %607 = inttoptr i64 %603 to i64*
  store i64 %604, i64* %607, align 8
  %608 = load i64, i64* %RSP, align 8
  %609 = add i64 %608, 16
  %610 = load i64, i64* %R11, align 8
  %611 = load i64, i64* %PC, align 8
  %612 = add i64 %611, 5
  store i64 %612, i64* %PC, align 8
  %613 = inttoptr i64 %609 to i64*
  store i64 %610, i64* %613, align 8
  %614 = load i64, i64* %RSP, align 8
  %615 = add i64 %614, 24
  %616 = load i64, i64* %RBX, align 8
  %617 = load i64, i64* %PC, align 8
  %618 = add i64 %617, 5
  store i64 %618, i64* %PC, align 8
  %619 = inttoptr i64 %615 to i64*
  store i64 %616, i64* %619, align 8
  %620 = load i64, i64* %RSP, align 8
  %621 = add i64 %620, 32
  %622 = load i64, i64* %R14, align 8
  %623 = load i64, i64* %PC, align 8
  %624 = add i64 %623, 5
  store i64 %624, i64* %PC, align 8
  %625 = inttoptr i64 %621 to i64*
  store i64 %622, i64* %625, align 8
  %626 = load i64, i64* %RSP, align 8
  %627 = add i64 %626, 40
  %628 = load i64, i64* %R15, align 8
  %629 = load i64, i64* %PC, align 8
  %630 = add i64 %629, 5
  store i64 %630, i64* %PC, align 8
  %631 = inttoptr i64 %627 to i64*
  store i64 %628, i64* %631, align 8
  %632 = load i64, i64* %RSP, align 8
  %633 = add i64 %632, 48
  %634 = load i64, i64* %R12, align 8
  %635 = load i64, i64* %PC, align 8
  %636 = add i64 %635, 5
  store i64 %636, i64* %PC, align 8
  %637 = inttoptr i64 %633 to i64*
  store i64 %634, i64* %637, align 8
  %638 = load i64, i64* %RSP, align 8
  %639 = add i64 %638, 56
  %640 = load i64, i64* %R13, align 8
  %641 = load i64, i64* %PC, align 8
  %642 = add i64 %641, 5
  store i64 %642, i64* %PC, align 8
  %643 = inttoptr i64 %639 to i64*
  store i64 %640, i64* %643, align 8
  %644 = load i64, i64* %RBP, align 8
  %645 = add i64 %644, -272
  %646 = load i64, i64* %PC, align 8
  %647 = add i64 %646, 7
  store i64 %647, i64* %PC, align 8
  %648 = inttoptr i64 %645 to i64*
  %649 = load i64, i64* %648, align 8
  store i64 %649, i64* %RAX, align 8, !tbaa !2428
  %650 = load i64, i64* %RSP, align 8
  %651 = add i64 %650, 64
  %652 = add i64 %646, 12
  store i64 %652, i64* %PC, align 8
  %653 = inttoptr i64 %651 to i64*
  store i64 %649, i64* %653, align 8
  %654 = load i64, i64* %RBP, align 8
  %655 = add i64 %654, -280
  %656 = load i64, i64* %PC, align 8
  %657 = add i64 %656, 7
  store i64 %657, i64* %PC, align 8
  %658 = inttoptr i64 %655 to i64*
  %659 = load i64, i64* %658, align 8
  store i64 %659, i64* %RAX, align 8, !tbaa !2428
  %660 = load i64, i64* %RSP, align 8
  %661 = add i64 %660, 72
  %662 = add i64 %656, 12
  store i64 %662, i64* %PC, align 8
  %663 = inttoptr i64 %661 to i64*
  store i64 %659, i64* %663, align 8
  %664 = load i64, i64* %RBP, align 8
  %665 = add i64 %664, -288
  %666 = load i64, i64* %PC, align 8
  %667 = add i64 %666, 7
  store i64 %667, i64* %PC, align 8
  %668 = inttoptr i64 %665 to i64*
  %669 = load i64, i64* %668, align 8
  store i64 %669, i64* %RAX, align 8, !tbaa !2428
  %670 = load i64, i64* %RSP, align 8
  %671 = add i64 %670, 80
  %672 = add i64 %666, 12
  store i64 %672, i64* %PC, align 8
  %673 = inttoptr i64 %671 to i64*
  store i64 %669, i64* %673, align 8
  %674 = load i64, i64* %PC, align 8
  %675 = add i64 %674, 2023
  %676 = add i64 %674, 5
  %677 = load i64, i64* %RSP, align 8, !tbaa !2428
  %678 = add i64 %677, -8
  %679 = inttoptr i64 %678 to i64*
  store i64 %676, i64* %679, align 8
  store i64 %678, i64* %RSP, align 8, !tbaa !2428
  store i64 %675, i64* %PC, align 8, !tbaa !2428
  %680 = tail call %struct.Memory* @sub_4013d0_kernel_fdtd_apml_renamed_(%struct.State* nonnull %0, i64 %675, %struct.Memory* %487)
  %681 = load i64, i64* %RBP, align 8
  %682 = add i64 %681, -80
  %683 = load i64, i64* %PC, align 8
  store i64 %682, i64* %RCX, align 8, !tbaa !2428
  %684 = add i64 %681, -88
  store i64 %684, i64* %R8, align 8, !tbaa !2428
  %685 = add i64 %681, -60
  %686 = add i64 %683, 11
  store i64 %686, i64* %PC, align 8
  %687 = inttoptr i64 %685 to i32*
  %688 = load i32, i32* %687, align 4
  %689 = zext i32 %688 to i64
  store i64 %689, i64* %RDI, align 8, !tbaa !2428
  %690 = add i64 %681, -68
  %691 = add i64 %683, 14
  store i64 %691, i64* %PC, align 8
  %692 = inttoptr i64 %690 to i32*
  %693 = load i32, i32* %692, align 4
  %694 = zext i32 %693 to i64
  store i64 %694, i64* %RSI, align 8, !tbaa !2428
  %695 = add i64 %681, -64
  %696 = add i64 %683, 17
  store i64 %696, i64* %PC, align 8
  %697 = inttoptr i64 %695 to i32*
  %698 = load i32, i32* %697, align 4
  %699 = zext i32 %698 to i64
  store i64 %699, i64* %RDX, align 8, !tbaa !2428
  %700 = add i64 %681, -96
  %701 = add i64 %683, 21
  store i64 %701, i64* %PC, align 8
  %702 = inttoptr i64 %700 to i64*
  %703 = load i64, i64* %702, align 8
  store i64 %703, i64* %R9, align 8, !tbaa !2428
  %704 = add i64 %681, -104
  %705 = add i64 %683, 25
  store i64 %705, i64* %PC, align 8
  %706 = inttoptr i64 %704 to i64*
  %707 = load i64, i64* %706, align 8
  store i64 %707, i64* %RAX, align 8, !tbaa !2428
  %708 = add i64 %681, -168
  %709 = add i64 %683, 32
  store i64 %709, i64* %PC, align 8
  %710 = inttoptr i64 %708 to i64*
  %711 = load i64, i64* %710, align 8
  store i64 %711, i64* %R10, align 8, !tbaa !2428
  %712 = add i64 %681, -176
  %713 = add i64 %683, 39
  store i64 %713, i64* %PC, align 8
  %714 = inttoptr i64 %712 to i64*
  %715 = load i64, i64* %714, align 8
  store i64 %715, i64* %R11, align 8, !tbaa !2428
  %716 = add i64 %681, -184
  %717 = add i64 %683, 46
  store i64 %717, i64* %PC, align 8
  %718 = inttoptr i64 %716 to i64*
  %719 = load i64, i64* %718, align 8
  store i64 %719, i64* %RBX, align 8, !tbaa !2428
  %720 = add i64 %681, -192
  %721 = add i64 %683, 53
  store i64 %721, i64* %PC, align 8
  %722 = inttoptr i64 %720 to i64*
  %723 = load i64, i64* %722, align 8
  store i64 %723, i64* %R14, align 8, !tbaa !2428
  %724 = add i64 %681, -200
  %725 = add i64 %683, 60
  store i64 %725, i64* %PC, align 8
  %726 = inttoptr i64 %724 to i64*
  %727 = load i64, i64* %726, align 8
  store i64 %727, i64* %R15, align 8, !tbaa !2428
  %728 = add i64 %681, -208
  %729 = add i64 %683, 67
  store i64 %729, i64* %PC, align 8
  %730 = inttoptr i64 %728 to i64*
  %731 = load i64, i64* %730, align 8
  store i64 %731, i64* %R12, align 8, !tbaa !2428
  %732 = add i64 %681, -216
  %733 = add i64 %683, 74
  store i64 %733, i64* %PC, align 8
  %734 = inttoptr i64 %732 to i64*
  %735 = load i64, i64* %734, align 8
  store i64 %735, i64* %R13, align 8, !tbaa !2428
  %736 = add i64 %681, -296
  %737 = add i64 %683, 81
  store i64 %737, i64* %PC, align 8
  %738 = inttoptr i64 %736 to i64*
  store i64 %707, i64* %738, align 8
  %739 = load i64, i64* %RBP, align 8
  %740 = add i64 %739, -224
  %741 = load i64, i64* %PC, align 8
  %742 = add i64 %741, 7
  store i64 %742, i64* %PC, align 8
  %743 = inttoptr i64 %740 to i64*
  %744 = load i64, i64* %743, align 8
  store i64 %744, i64* %RAX, align 8, !tbaa !2428
  %745 = add i64 %739, -304
  %746 = add i64 %741, 14
  store i64 %746, i64* %PC, align 8
  %747 = inttoptr i64 %745 to i64*
  store i64 %744, i64* %747, align 8
  %748 = load i64, i64* %RBP, align 8
  %749 = add i64 %748, -232
  %750 = load i64, i64* %PC, align 8
  %751 = add i64 %750, 7
  store i64 %751, i64* %PC, align 8
  %752 = inttoptr i64 %749 to i64*
  %753 = load i64, i64* %752, align 8
  store i64 %753, i64* %RAX, align 8, !tbaa !2428
  %754 = add i64 %748, -312
  %755 = add i64 %750, 14
  store i64 %755, i64* %PC, align 8
  %756 = inttoptr i64 %754 to i64*
  store i64 %753, i64* %756, align 8
  %757 = load i64, i64* %RBP, align 8
  %758 = add i64 %757, -296
  %759 = load i64, i64* %PC, align 8
  %760 = add i64 %759, 7
  store i64 %760, i64* %PC, align 8
  %761 = inttoptr i64 %758 to i64*
  %762 = load i64, i64* %761, align 8
  store i64 %762, i64* %RAX, align 8, !tbaa !2428
  %763 = load i64*, i64** %416, align 8
  %764 = add i64 %759, 11
  store i64 %764, i64* %PC, align 8
  store i64 %762, i64* %763, align 8
  %765 = load i64, i64* %RSP, align 8
  %766 = add i64 %765, 8
  %767 = load i64, i64* %R10, align 8
  %768 = load i64, i64* %PC, align 8
  %769 = add i64 %768, 5
  store i64 %769, i64* %PC, align 8
  %770 = inttoptr i64 %766 to i64*
  store i64 %767, i64* %770, align 8
  %771 = load i64, i64* %RSP, align 8
  %772 = add i64 %771, 16
  %773 = load i64, i64* %R11, align 8
  %774 = load i64, i64* %PC, align 8
  %775 = add i64 %774, 5
  store i64 %775, i64* %PC, align 8
  %776 = inttoptr i64 %772 to i64*
  store i64 %773, i64* %776, align 8
  %777 = load i64, i64* %RSP, align 8
  %778 = add i64 %777, 24
  %779 = load i64, i64* %RBX, align 8
  %780 = load i64, i64* %PC, align 8
  %781 = add i64 %780, 5
  store i64 %781, i64* %PC, align 8
  %782 = inttoptr i64 %778 to i64*
  store i64 %779, i64* %782, align 8
  %783 = load i64, i64* %RSP, align 8
  %784 = add i64 %783, 32
  %785 = load i64, i64* %R14, align 8
  %786 = load i64, i64* %PC, align 8
  %787 = add i64 %786, 5
  store i64 %787, i64* %PC, align 8
  %788 = inttoptr i64 %784 to i64*
  store i64 %785, i64* %788, align 8
  %789 = load i64, i64* %RSP, align 8
  %790 = add i64 %789, 40
  %791 = load i64, i64* %R15, align 8
  %792 = load i64, i64* %PC, align 8
  %793 = add i64 %792, 5
  store i64 %793, i64* %PC, align 8
  %794 = inttoptr i64 %790 to i64*
  store i64 %791, i64* %794, align 8
  %795 = load i64, i64* %RSP, align 8
  %796 = add i64 %795, 48
  %797 = load i64, i64* %R12, align 8
  %798 = load i64, i64* %PC, align 8
  %799 = add i64 %798, 5
  store i64 %799, i64* %PC, align 8
  %800 = inttoptr i64 %796 to i64*
  store i64 %797, i64* %800, align 8
  %801 = load i64, i64* %RSP, align 8
  %802 = add i64 %801, 56
  %803 = load i64, i64* %R13, align 8
  %804 = load i64, i64* %PC, align 8
  %805 = add i64 %804, 5
  store i64 %805, i64* %PC, align 8
  %806 = inttoptr i64 %802 to i64*
  store i64 %803, i64* %806, align 8
  %807 = load i64, i64* %RBP, align 8
  %808 = add i64 %807, -304
  %809 = load i64, i64* %PC, align 8
  %810 = add i64 %809, 7
  store i64 %810, i64* %PC, align 8
  %811 = inttoptr i64 %808 to i64*
  %812 = load i64, i64* %811, align 8
  store i64 %812, i64* %RAX, align 8, !tbaa !2428
  %813 = load i64, i64* %RSP, align 8
  %814 = add i64 %813, 64
  %815 = add i64 %809, 12
  store i64 %815, i64* %PC, align 8
  %816 = inttoptr i64 %814 to i64*
  store i64 %812, i64* %816, align 8
  %817 = load i64, i64* %RBP, align 8
  %818 = add i64 %817, -312
  %819 = load i64, i64* %PC, align 8
  %820 = add i64 %819, 7
  store i64 %820, i64* %PC, align 8
  %821 = inttoptr i64 %818 to i64*
  %822 = load i64, i64* %821, align 8
  store i64 %822, i64* %RAX, align 8, !tbaa !2428
  %823 = load i64, i64* %RSP, align 8
  %824 = add i64 %823, 72
  %825 = add i64 %819, 12
  store i64 %825, i64* %PC, align 8
  %826 = inttoptr i64 %824 to i64*
  store i64 %822, i64* %826, align 8
  %827 = load i64, i64* %PC, align 8
  %828 = add i64 %827, 751
  %829 = add i64 %827, 5
  %830 = load i64, i64* %RSP, align 8, !tbaa !2428
  %831 = add i64 %830, -8
  %832 = inttoptr i64 %831 to i64*
  store i64 %829, i64* %832, align 8
  store i64 %831, i64* %RSP, align 8, !tbaa !2428
  store i64 %828, i64* %PC, align 8, !tbaa !2428
  %833 = tail call %struct.Memory* @sub_400f90_init_array_renamed_(%struct.State* nonnull %0, i64 %828, %struct.Memory* %680)
  %834 = load i64, i64* %RBP, align 8
  %835 = add i64 %834, -60
  %836 = load i64, i64* %PC, align 8
  %837 = add i64 %836, 3
  store i64 %837, i64* %PC, align 8
  %838 = inttoptr i64 %835 to i32*
  %839 = load i32, i32* %838, align 4
  %840 = zext i32 %839 to i64
  store i64 %840, i64* %RDI, align 8, !tbaa !2428
  %841 = add i64 %834, -68
  %842 = add i64 %836, 6
  store i64 %842, i64* %PC, align 8
  %843 = inttoptr i64 %841 to i32*
  %844 = load i32, i32* %843, align 4
  %845 = zext i32 %844 to i64
  store i64 %845, i64* %RSI, align 8, !tbaa !2428
  %846 = add i64 %834, -64
  %847 = add i64 %836, 9
  store i64 %847, i64* %PC, align 8
  %848 = inttoptr i64 %846 to i32*
  %849 = load i32, i32* %848, align 4
  %850 = zext i32 %849 to i64
  store i64 %850, i64* %RDX, align 8, !tbaa !2428
  %851 = add i64 %834, -80
  %852 = add i64 %836, 14
  store i64 %852, i64* %PC, align 8
  %853 = inttoptr i64 %851 to i64*
  %854 = load i64, i64* %853, align 8
  store i64 %854, i64* %509, align 1, !tbaa !2452
  store double 0.000000e+00, double* %511, align 1, !tbaa !2452
  %855 = add i64 %834, -88
  %856 = add i64 %836, 19
  store i64 %856, i64* %PC, align 8
  %857 = inttoptr i64 %855 to i64*
  %858 = load i64, i64* %857, align 8
  store i64 %858, i64* %516, align 1, !tbaa !2452
  store double 0.000000e+00, double* %518, align 1, !tbaa !2452
  %859 = add i64 %834, -96
  %860 = add i64 %836, 23
  store i64 %860, i64* %PC, align 8
  %861 = inttoptr i64 %859 to i64*
  %862 = load i64, i64* %861, align 8
  store i64 %862, i64* %RCX, align 8, !tbaa !2428
  %863 = add i64 %834, -104
  %864 = add i64 %836, 27
  store i64 %864, i64* %PC, align 8
  %865 = inttoptr i64 %863 to i64*
  %866 = load i64, i64* %865, align 8
  store i64 %866, i64* %R8, align 8, !tbaa !2428
  %867 = add i64 %834, -112
  %868 = add i64 %836, 31
  store i64 %868, i64* %PC, align 8
  %869 = inttoptr i64 %867 to i64*
  %870 = load i64, i64* %869, align 8
  store i64 %870, i64* %R9, align 8, !tbaa !2428
  %871 = add i64 %834, -120
  %872 = add i64 %836, 35
  store i64 %872, i64* %PC, align 8
  %873 = inttoptr i64 %871 to i64*
  %874 = load i64, i64* %873, align 8
  store i64 %874, i64* %RAX, align 8, !tbaa !2428
  %875 = add i64 %834, -160
  %876 = add i64 %836, 42
  store i64 %876, i64* %PC, align 8
  %877 = inttoptr i64 %875 to i64*
  %878 = load i64, i64* %877, align 8
  store i64 %878, i64* %R10, align 8, !tbaa !2428
  %879 = add i64 %834, -168
  %880 = add i64 %836, 49
  store i64 %880, i64* %PC, align 8
  %881 = inttoptr i64 %879 to i64*
  %882 = load i64, i64* %881, align 8
  store i64 %882, i64* %R11, align 8, !tbaa !2428
  %883 = add i64 %834, -176
  %884 = add i64 %836, 56
  store i64 %884, i64* %PC, align 8
  %885 = inttoptr i64 %883 to i64*
  %886 = load i64, i64* %885, align 8
  store i64 %886, i64* %RBX, align 8, !tbaa !2428
  %887 = add i64 %834, -184
  %888 = add i64 %836, 63
  store i64 %888, i64* %PC, align 8
  %889 = inttoptr i64 %887 to i64*
  %890 = load i64, i64* %889, align 8
  store i64 %890, i64* %R14, align 8, !tbaa !2428
  %891 = add i64 %834, -192
  %892 = add i64 %836, 70
  store i64 %892, i64* %PC, align 8
  %893 = inttoptr i64 %891 to i64*
  %894 = load i64, i64* %893, align 8
  store i64 %894, i64* %R15, align 8, !tbaa !2428
  %895 = add i64 %834, -200
  %896 = add i64 %836, 77
  store i64 %896, i64* %PC, align 8
  %897 = inttoptr i64 %895 to i64*
  %898 = load i64, i64* %897, align 8
  store i64 %898, i64* %R12, align 8, !tbaa !2428
  %899 = add i64 %834, -208
  %900 = add i64 %836, 84
  store i64 %900, i64* %PC, align 8
  %901 = inttoptr i64 %899 to i64*
  %902 = load i64, i64* %901, align 8
  store i64 %902, i64* %R13, align 8, !tbaa !2428
  %903 = load i64, i64* %RBP, align 8
  %904 = add i64 %903, -320
  %905 = add i64 %836, 91
  store i64 %905, i64* %PC, align 8
  %906 = inttoptr i64 %904 to i64*
  store i64 %874, i64* %906, align 8
  %907 = load i64, i64* %RBP, align 8
  %908 = add i64 %907, -216
  %909 = load i64, i64* %PC, align 8
  %910 = add i64 %909, 7
  store i64 %910, i64* %PC, align 8
  %911 = inttoptr i64 %908 to i64*
  %912 = load i64, i64* %911, align 8
  store i64 %912, i64* %RAX, align 8, !tbaa !2428
  %913 = add i64 %907, -328
  %914 = add i64 %909, 14
  store i64 %914, i64* %PC, align 8
  %915 = inttoptr i64 %913 to i64*
  store i64 %912, i64* %915, align 8
  %916 = load i64, i64* %RBP, align 8
  %917 = add i64 %916, -224
  %918 = load i64, i64* %PC, align 8
  %919 = add i64 %918, 7
  store i64 %919, i64* %PC, align 8
  %920 = inttoptr i64 %917 to i64*
  %921 = load i64, i64* %920, align 8
  store i64 %921, i64* %RAX, align 8, !tbaa !2428
  %922 = add i64 %916, -336
  %923 = add i64 %918, 14
  store i64 %923, i64* %PC, align 8
  %924 = inttoptr i64 %922 to i64*
  store i64 %921, i64* %924, align 8
  %925 = load i64, i64* %RBP, align 8
  %926 = add i64 %925, -232
  %927 = load i64, i64* %PC, align 8
  %928 = add i64 %927, 7
  store i64 %928, i64* %PC, align 8
  %929 = inttoptr i64 %926 to i64*
  %930 = load i64, i64* %929, align 8
  store i64 %930, i64* %RAX, align 8, !tbaa !2428
  %931 = add i64 %925, -344
  %932 = add i64 %927, 14
  store i64 %932, i64* %PC, align 8
  %933 = inttoptr i64 %931 to i64*
  store i64 %930, i64* %933, align 8
  %934 = load i64, i64* %RBP, align 8
  %935 = add i64 %934, -320
  %936 = load i64, i64* %PC, align 8
  %937 = add i64 %936, 7
  store i64 %937, i64* %PC, align 8
  %938 = inttoptr i64 %935 to i64*
  %939 = load i64, i64* %938, align 8
  store i64 %939, i64* %RAX, align 8, !tbaa !2428
  %940 = load i64*, i64** %416, align 8
  %941 = add i64 %936, 11
  store i64 %941, i64* %PC, align 8
  store i64 %939, i64* %940, align 8
  %942 = load i64, i64* %RSP, align 8
  %943 = add i64 %942, 8
  %944 = load i64, i64* %R10, align 8
  %945 = load i64, i64* %PC, align 8
  %946 = add i64 %945, 5
  store i64 %946, i64* %PC, align 8
  %947 = inttoptr i64 %943 to i64*
  store i64 %944, i64* %947, align 8
  %948 = load i64, i64* %RSP, align 8
  %949 = add i64 %948, 16
  %950 = load i64, i64* %R11, align 8
  %951 = load i64, i64* %PC, align 8
  %952 = add i64 %951, 5
  store i64 %952, i64* %PC, align 8
  %953 = inttoptr i64 %949 to i64*
  store i64 %950, i64* %953, align 8
  %954 = load i64, i64* %RSP, align 8
  %955 = add i64 %954, 24
  %956 = load i64, i64* %RBX, align 8
  %957 = load i64, i64* %PC, align 8
  %958 = add i64 %957, 5
  store i64 %958, i64* %PC, align 8
  %959 = inttoptr i64 %955 to i64*
  store i64 %956, i64* %959, align 8
  %960 = load i64, i64* %RSP, align 8
  %961 = add i64 %960, 32
  %962 = load i64, i64* %R14, align 8
  %963 = load i64, i64* %PC, align 8
  %964 = add i64 %963, 5
  store i64 %964, i64* %PC, align 8
  %965 = inttoptr i64 %961 to i64*
  store i64 %962, i64* %965, align 8
  %966 = load i64, i64* %RSP, align 8
  %967 = add i64 %966, 40
  %968 = load i64, i64* %R15, align 8
  %969 = load i64, i64* %PC, align 8
  %970 = add i64 %969, 5
  store i64 %970, i64* %PC, align 8
  %971 = inttoptr i64 %967 to i64*
  store i64 %968, i64* %971, align 8
  %972 = load i64, i64* %RSP, align 8
  %973 = add i64 %972, 48
  %974 = load i64, i64* %R12, align 8
  %975 = load i64, i64* %PC, align 8
  %976 = add i64 %975, 5
  store i64 %976, i64* %PC, align 8
  %977 = inttoptr i64 %973 to i64*
  store i64 %974, i64* %977, align 8
  %978 = load i64, i64* %RSP, align 8
  %979 = add i64 %978, 56
  %980 = load i64, i64* %R13, align 8
  %981 = load i64, i64* %PC, align 8
  %982 = add i64 %981, 5
  store i64 %982, i64* %PC, align 8
  %983 = inttoptr i64 %979 to i64*
  store i64 %980, i64* %983, align 8
  %984 = load i64, i64* %RBP, align 8
  %985 = add i64 %984, -328
  %986 = load i64, i64* %PC, align 8
  %987 = add i64 %986, 7
  store i64 %987, i64* %PC, align 8
  %988 = inttoptr i64 %985 to i64*
  %989 = load i64, i64* %988, align 8
  store i64 %989, i64* %RAX, align 8, !tbaa !2428
  %990 = load i64, i64* %RSP, align 8
  %991 = add i64 %990, 64
  %992 = add i64 %986, 12
  store i64 %992, i64* %PC, align 8
  %993 = inttoptr i64 %991 to i64*
  store i64 %989, i64* %993, align 8
  %994 = load i64, i64* %RBP, align 8
  %995 = add i64 %994, -336
  %996 = load i64, i64* %PC, align 8
  %997 = add i64 %996, 7
  store i64 %997, i64* %PC, align 8
  %998 = inttoptr i64 %995 to i64*
  %999 = load i64, i64* %998, align 8
  store i64 %999, i64* %RAX, align 8, !tbaa !2428
  %1000 = load i64, i64* %RSP, align 8
  %1001 = add i64 %1000, 72
  %1002 = add i64 %996, 12
  store i64 %1002, i64* %PC, align 8
  %1003 = inttoptr i64 %1001 to i64*
  store i64 %999, i64* %1003, align 8
  %1004 = load i64, i64* %RBP, align 8
  %1005 = add i64 %1004, -344
  %1006 = load i64, i64* %PC, align 8
  %1007 = add i64 %1006, 7
  store i64 %1007, i64* %PC, align 8
  %1008 = inttoptr i64 %1005 to i64*
  %1009 = load i64, i64* %1008, align 8
  store i64 %1009, i64* %RAX, align 8, !tbaa !2428
  %1010 = load i64, i64* %RSP, align 8
  %1011 = add i64 %1010, 80
  %1012 = add i64 %1006, 12
  store i64 %1012, i64* %PC, align 8
  %1013 = inttoptr i64 %1011 to i64*
  store i64 %1009, i64* %1013, align 8
  %1014 = load i64, i64* %PC, align 8
  %1015 = add i64 %1014, 4499
  %1016 = add i64 %1014, 5
  %1017 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1018 = add i64 %1017, -8
  %1019 = inttoptr i64 %1018 to i64*
  store i64 %1016, i64* %1019, align 8
  store i64 %1018, i64* %RSP, align 8, !tbaa !2428
  store i64 %1015, i64* %PC, align 8, !tbaa !2428
  %1020 = tail call %struct.Memory* @sub_401f10_kernel_fdtd_apml_StrictFP_renamed_(%struct.State* nonnull %0, i64 %1015, %struct.Memory* %833)
  %1021 = load i64, i64* %RBP, align 8
  %1022 = add i64 %1021, -60
  %1023 = load i64, i64* %PC, align 8
  %1024 = add i64 %1023, 3
  store i64 %1024, i64* %PC, align 8
  %1025 = inttoptr i64 %1022 to i32*
  %1026 = load i32, i32* %1025, align 4
  %1027 = zext i32 %1026 to i64
  store i64 %1027, i64* %RDI, align 8, !tbaa !2428
  %1028 = add i64 %1021, -68
  %1029 = add i64 %1023, 6
  store i64 %1029, i64* %PC, align 8
  %1030 = inttoptr i64 %1028 to i32*
  %1031 = load i32, i32* %1030, align 4
  %1032 = zext i32 %1031 to i64
  store i64 %1032, i64* %RSI, align 8, !tbaa !2428
  %1033 = add i64 %1021, -64
  %1034 = add i64 %1023, 9
  store i64 %1034, i64* %PC, align 8
  %1035 = inttoptr i64 %1033 to i32*
  %1036 = load i32, i32* %1035, align 4
  %1037 = zext i32 %1036 to i64
  store i64 %1037, i64* %RDX, align 8, !tbaa !2428
  %1038 = add i64 %1021, -128
  %1039 = add i64 %1023, 13
  store i64 %1039, i64* %PC, align 8
  %1040 = inttoptr i64 %1038 to i64*
  %1041 = load i64, i64* %1040, align 8
  store i64 %1041, i64* %RCX, align 8, !tbaa !2428
  %1042 = add i64 %1021, -160
  %1043 = add i64 %1023, 20
  store i64 %1043, i64* %PC, align 8
  %1044 = inttoptr i64 %1042 to i64*
  %1045 = load i64, i64* %1044, align 8
  store i64 %1045, i64* %R8, align 8, !tbaa !2428
  %1046 = add i64 %1023, 7374
  %1047 = add i64 %1023, 25
  %1048 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1049 = add i64 %1048, -8
  %1050 = inttoptr i64 %1049 to i64*
  store i64 %1047, i64* %1050, align 8
  store i64 %1049, i64* %RSP, align 8, !tbaa !2428
  store i64 %1046, i64* %PC, align 8, !tbaa !2428
  %1051 = tail call %struct.Memory* @sub_402a50_check_FP_renamed_(%struct.State* nonnull %0, i64 %1046, %struct.Memory* %1020)
  %1052 = load i32, i32* %EAX, align 4
  %1053 = load i64, i64* %PC, align 8
  store i8 0, i8* %41, align 1, !tbaa !2432
  %1054 = and i32 %1052, 255
  %1055 = tail call i32 @llvm.ctpop.i32(i32 %1054) #8
  %1056 = trunc i32 %1055 to i8
  %1057 = and i8 %1056, 1
  %1058 = xor i8 %1057, 1
  store i8 %1058, i8* %48, align 1, !tbaa !2446
  store i8 0, i8* %53, align 1, !tbaa !2447
  %1059 = icmp eq i32 %1052, 0
  %1060 = zext i1 %1059 to i8
  store i8 %1060, i8* %56, align 1, !tbaa !2448
  %1061 = lshr i32 %1052, 31
  %1062 = trunc i32 %1061 to i8
  store i8 %1062, i8* %59, align 1, !tbaa !2449
  store i8 0, i8* %65, align 1, !tbaa !2450
  %.v = select i1 %1059, i64 9, i64 21
  %1063 = add i64 %1053, %.v
  store i64 %1063, i64* %PC, align 8, !tbaa !2428
  %1064 = load i64, i64* %RBP, align 8
  br i1 %1059, label %block_400da4, label %block_400db0

block_400e12:                                     ; preds = %block_400de1
  %1065 = add i64 %1524, -60
  %1066 = add i64 %1523, 3
  store i64 %1066, i64* %PC, align 8
  %1067 = inttoptr i64 %1065 to i32*
  %1068 = load i32, i32* %1067, align 4
  %1069 = zext i32 %1068 to i64
  store i64 %1069, i64* %RDI, align 8, !tbaa !2428
  %1070 = add i64 %1524, -68
  %1071 = add i64 %1523, 6
  store i64 %1071, i64* %PC, align 8
  %1072 = inttoptr i64 %1070 to i32*
  %1073 = load i32, i32* %1072, align 4
  %1074 = zext i32 %1073 to i64
  store i64 %1074, i64* %RSI, align 8, !tbaa !2428
  %1075 = add i64 %1524, -64
  %1076 = add i64 %1523, 9
  store i64 %1076, i64* %PC, align 8
  %1077 = inttoptr i64 %1075 to i32*
  %1078 = load i32, i32* %1077, align 4
  %1079 = zext i32 %1078 to i64
  store i64 %1079, i64* %RDX, align 8, !tbaa !2428
  %1080 = add i64 %1524, -152
  %1081 = add i64 %1523, 16
  store i64 %1081, i64* %PC, align 8
  %1082 = inttoptr i64 %1080 to i64*
  %1083 = load i64, i64* %1082, align 8
  store i64 %1083, i64* %RCX, align 8, !tbaa !2428
  %1084 = add i64 %1524, -184
  %1085 = add i64 %1523, 23
  store i64 %1085, i64* %PC, align 8
  %1086 = inttoptr i64 %1084 to i64*
  %1087 = load i64, i64* %1086, align 8
  store i64 %1087, i64* %R8, align 8, !tbaa !2428
  %1088 = add i64 %1523, 7230
  %1089 = add i64 %1523, 28
  %1090 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1091 = add i64 %1090, -8
  %1092 = inttoptr i64 %1091 to i64*
  store i64 %1089, i64* %1092, align 8
  store i64 %1091, i64* %RSP, align 8, !tbaa !2428
  store i64 %1088, i64* %PC, align 8, !tbaa !2428
  %1093 = tail call %struct.Memory* @sub_402a50_check_FP_renamed_(%struct.State* nonnull %0, i64 %1088, %struct.Memory* %1511)
  %1094 = load i32, i32* %EAX, align 4
  %1095 = load i64, i64* %PC, align 8
  store i8 0, i8* %41, align 1, !tbaa !2432
  %1096 = and i32 %1094, 255
  %1097 = tail call i32 @llvm.ctpop.i32(i32 %1096) #8
  %1098 = trunc i32 %1097 to i8
  %1099 = and i8 %1098, 1
  %1100 = xor i8 %1099, 1
  store i8 %1100, i8* %48, align 1, !tbaa !2446
  store i8 0, i8* %53, align 1, !tbaa !2447
  %1101 = icmp eq i32 %1094, 0
  %1102 = zext i1 %1101 to i8
  store i8 %1102, i8* %56, align 1, !tbaa !2448
  %1103 = lshr i32 %1094, 31
  %1104 = trunc i32 %1103 to i8
  store i8 %1104, i8* %59, align 1, !tbaa !2449
  store i8 0, i8* %65, align 1, !tbaa !2450
  %.v3 = select i1 %1101, i64 9, i64 21
  %1105 = add i64 %1095, %.v3
  store i64 %1105, i64* %PC, align 8, !tbaa !2428
  %1106 = load i64, i64* %RBP, align 8
  br i1 %1101, label %block_400e37, label %block_400e43

block_400f77:                                     ; preds = %block_400dd5, %block_400e43, %block_400da4, %block_400e06, %block_400e37
  %1107 = phi i64 [ %.pre, %block_400e43 ], [ %1211, %block_400e37 ], [ %1216, %block_400e06 ], [ %1529, %block_400dd5 ], [ %1221, %block_400da4 ]
  %MEMORY.0 = phi %struct.Memory* [ %1477, %block_400e43 ], [ %1093, %block_400e37 ], [ %1511, %block_400e06 ], [ %1193, %block_400dd5 ], [ %1051, %block_400da4 ]
  %1108 = load i64, i64* %RBP, align 8
  %1109 = add i64 %1108, -44
  %1110 = add i64 %1107, 3
  store i64 %1110, i64* %PC, align 8
  %1111 = inttoptr i64 %1109 to i32*
  %1112 = load i32, i32* %1111, align 4
  %1113 = zext i32 %1112 to i64
  store i64 %1113, i64* %RAX, align 8, !tbaa !2428
  %1114 = load i64, i64* %RSP, align 8
  %1115 = add i64 %1114, 392
  store i64 %1115, i64* %RSP, align 8, !tbaa !2428
  %1116 = icmp ugt i64 %1114, -393
  %1117 = zext i1 %1116 to i8
  store i8 %1117, i8* %41, align 1, !tbaa !2432
  %1118 = trunc i64 %1115 to i32
  %1119 = and i32 %1118, 255
  %1120 = tail call i32 @llvm.ctpop.i32(i32 %1119) #8
  %1121 = trunc i32 %1120 to i8
  %1122 = and i8 %1121, 1
  %1123 = xor i8 %1122, 1
  store i8 %1123, i8* %48, align 1, !tbaa !2446
  %1124 = xor i64 %1114, %1115
  %1125 = lshr i64 %1124, 4
  %1126 = trunc i64 %1125 to i8
  %1127 = and i8 %1126, 1
  store i8 %1127, i8* %53, align 1, !tbaa !2447
  %1128 = icmp eq i64 %1115, 0
  %1129 = zext i1 %1128 to i8
  store i8 %1129, i8* %56, align 1, !tbaa !2448
  %1130 = lshr i64 %1115, 63
  %1131 = trunc i64 %1130 to i8
  store i8 %1131, i8* %59, align 1, !tbaa !2449
  %1132 = lshr i64 %1114, 63
  %1133 = xor i64 %1130, %1132
  %1134 = add nuw nsw i64 %1133, %1130
  %1135 = icmp eq i64 %1134, 2
  %1136 = zext i1 %1135 to i8
  store i8 %1136, i8* %65, align 1, !tbaa !2450
  %1137 = add i64 %1107, 11
  store i64 %1137, i64* %PC, align 8
  %1138 = add i64 %1114, 400
  %1139 = inttoptr i64 %1115 to i64*
  %1140 = load i64, i64* %1139, align 8
  store i64 %1140, i64* %RBX, align 8, !tbaa !2428
  store i64 %1138, i64* %RSP, align 8, !tbaa !2428
  %1141 = add i64 %1107, 13
  store i64 %1141, i64* %PC, align 8
  %1142 = add i64 %1114, 408
  %1143 = inttoptr i64 %1138 to i64*
  %1144 = load i64, i64* %1143, align 8
  store i64 %1144, i64* %R12, align 8, !tbaa !2428
  store i64 %1142, i64* %RSP, align 8, !tbaa !2428
  %1145 = add i64 %1107, 15
  store i64 %1145, i64* %PC, align 8
  %1146 = add i64 %1114, 416
  %1147 = inttoptr i64 %1142 to i64*
  %1148 = load i64, i64* %1147, align 8
  store i64 %1148, i64* %R13, align 8, !tbaa !2428
  store i64 %1146, i64* %RSP, align 8, !tbaa !2428
  %1149 = add i64 %1107, 17
  store i64 %1149, i64* %PC, align 8
  %1150 = add i64 %1114, 424
  %1151 = inttoptr i64 %1146 to i64*
  %1152 = load i64, i64* %1151, align 8
  store i64 %1152, i64* %R14, align 8, !tbaa !2428
  store i64 %1150, i64* %RSP, align 8, !tbaa !2428
  %1153 = add i64 %1107, 19
  store i64 %1153, i64* %PC, align 8
  %1154 = add i64 %1114, 432
  %1155 = inttoptr i64 %1150 to i64*
  %1156 = load i64, i64* %1155, align 8
  store i64 %1156, i64* %R15, align 8, !tbaa !2428
  store i64 %1154, i64* %RSP, align 8, !tbaa !2428
  %1157 = add i64 %1107, 20
  store i64 %1157, i64* %PC, align 8
  %1158 = add i64 %1114, 440
  %1159 = inttoptr i64 %1154 to i64*
  %1160 = load i64, i64* %1159, align 8
  store i64 %1160, i64* %RBP, align 8, !tbaa !2428
  store i64 %1158, i64* %RSP, align 8, !tbaa !2428
  %1161 = add i64 %1107, 21
  store i64 %1161, i64* %PC, align 8
  %1162 = inttoptr i64 %1158 to i64*
  %1163 = load i64, i64* %1162, align 8
  store i64 %1163, i64* %PC, align 8, !tbaa !2428
  %1164 = add i64 %1114, 448
  store i64 %1164, i64* %RSP, align 8, !tbaa !2428
  ret %struct.Memory* %MEMORY.0

block_400db0:                                     ; preds = %block_400880
  %1165 = add i64 %1064, -60
  %1166 = add i64 %1063, 3
  store i64 %1166, i64* %PC, align 8
  %1167 = inttoptr i64 %1165 to i32*
  %1168 = load i32, i32* %1167, align 4
  %1169 = zext i32 %1168 to i64
  store i64 %1169, i64* %RDI, align 8, !tbaa !2428
  %1170 = add i64 %1064, -68
  %1171 = add i64 %1063, 6
  store i64 %1171, i64* %PC, align 8
  %1172 = inttoptr i64 %1170 to i32*
  %1173 = load i32, i32* %1172, align 4
  %1174 = zext i32 %1173 to i64
  store i64 %1174, i64* %RSI, align 8, !tbaa !2428
  %1175 = add i64 %1064, -64
  %1176 = add i64 %1063, 9
  store i64 %1176, i64* %PC, align 8
  %1177 = inttoptr i64 %1175 to i32*
  %1178 = load i32, i32* %1177, align 4
  %1179 = zext i32 %1178 to i64
  store i64 %1179, i64* %RDX, align 8, !tbaa !2428
  %1180 = add i64 %1064, -136
  %1181 = add i64 %1063, 16
  store i64 %1181, i64* %PC, align 8
  %1182 = inttoptr i64 %1180 to i64*
  %1183 = load i64, i64* %1182, align 8
  store i64 %1183, i64* %RCX, align 8, !tbaa !2428
  %1184 = add i64 %1064, -168
  %1185 = add i64 %1063, 23
  store i64 %1185, i64* %PC, align 8
  %1186 = inttoptr i64 %1184 to i64*
  %1187 = load i64, i64* %1186, align 8
  store i64 %1187, i64* %R8, align 8, !tbaa !2428
  %1188 = add i64 %1063, 7328
  %1189 = add i64 %1063, 28
  %1190 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1191 = add i64 %1190, -8
  %1192 = inttoptr i64 %1191 to i64*
  store i64 %1189, i64* %1192, align 8
  store i64 %1191, i64* %RSP, align 8, !tbaa !2428
  store i64 %1188, i64* %PC, align 8, !tbaa !2428
  %1193 = tail call %struct.Memory* @sub_402a50_check_FP_renamed_(%struct.State* nonnull %0, i64 %1188, %struct.Memory* %1051)
  %1194 = load i32, i32* %EAX, align 4
  %1195 = load i64, i64* %PC, align 8
  store i8 0, i8* %41, align 1, !tbaa !2432
  %1196 = and i32 %1194, 255
  %1197 = tail call i32 @llvm.ctpop.i32(i32 %1196) #8
  %1198 = trunc i32 %1197 to i8
  %1199 = and i8 %1198, 1
  %1200 = xor i8 %1199, 1
  store i8 %1200, i8* %48, align 1, !tbaa !2446
  store i8 0, i8* %53, align 1, !tbaa !2447
  %1201 = icmp eq i32 %1194, 0
  %1202 = zext i1 %1201 to i8
  store i8 %1202, i8* %56, align 1, !tbaa !2448
  %1203 = lshr i32 %1194, 31
  %1204 = trunc i32 %1203 to i8
  store i8 %1204, i8* %59, align 1, !tbaa !2449
  store i8 0, i8* %65, align 1, !tbaa !2450
  %.v1 = select i1 %1201, i64 9, i64 21
  %1205 = add i64 %1195, %.v1
  store i64 %1205, i64* %PC, align 8, !tbaa !2428
  %1206 = load i64, i64* %RBP, align 8
  br i1 %1201, label %block_400dd5, label %block_400de1

block_400e37:                                     ; preds = %block_400e12
  %1207 = add i64 %1106, -44
  %1208 = add i64 %1105, 7
  store i64 %1208, i64* %PC, align 8
  %1209 = inttoptr i64 %1207 to i32*
  store i32 1, i32* %1209, align 4
  %1210 = load i64, i64* %PC, align 8
  %1211 = add i64 %1210, 313
  store i64 %1211, i64* %PC, align 8, !tbaa !2428
  br label %block_400f77

block_400e06:                                     ; preds = %block_400de1
  %1212 = add i64 %1524, -44
  %1213 = add i64 %1523, 7
  store i64 %1213, i64* %PC, align 8
  %1214 = inttoptr i64 %1212 to i32*
  store i32 1, i32* %1214, align 4
  %1215 = load i64, i64* %PC, align 8
  %1216 = add i64 %1215, 362
  store i64 %1216, i64* %PC, align 8, !tbaa !2428
  br label %block_400f77

block_400da4:                                     ; preds = %block_400880
  %1217 = add i64 %1064, -44
  %1218 = add i64 %1063, 7
  store i64 %1218, i64* %PC, align 8
  %1219 = inttoptr i64 %1217 to i32*
  store i32 1, i32* %1219, align 4
  %1220 = load i64, i64* %PC, align 8
  %1221 = add i64 %1220, 460
  store i64 %1221, i64* %PC, align 8, !tbaa !2428
  br label %block_400f77

block_400e43:                                     ; preds = %block_400e12
  %1222 = add i64 %1106, -60
  %1223 = add i64 %1105, 3
  store i64 %1223, i64* %PC, align 8
  %1224 = inttoptr i64 %1222 to i32*
  %1225 = load i32, i32* %1224, align 4
  %1226 = zext i32 %1225 to i64
  store i64 %1226, i64* %RDI, align 8, !tbaa !2428
  %1227 = add i64 %1106, -68
  %1228 = add i64 %1105, 6
  store i64 %1228, i64* %PC, align 8
  %1229 = inttoptr i64 %1227 to i32*
  %1230 = load i32, i32* %1229, align 4
  %1231 = zext i32 %1230 to i64
  store i64 %1231, i64* %RSI, align 8, !tbaa !2428
  %1232 = add i64 %1106, -64
  %1233 = add i64 %1105, 9
  store i64 %1233, i64* %PC, align 8
  %1234 = inttoptr i64 %1232 to i32*
  %1235 = load i32, i32* %1234, align 4
  %1236 = zext i32 %1235 to i64
  store i64 %1236, i64* %RDX, align 8, !tbaa !2428
  %1237 = add i64 %1106, -160
  %1238 = add i64 %1105, 16
  store i64 %1238, i64* %PC, align 8
  %1239 = inttoptr i64 %1237 to i64*
  %1240 = load i64, i64* %1239, align 8
  store i64 %1240, i64* %RCX, align 8, !tbaa !2428
  %1241 = add i64 %1106, -168
  %1242 = add i64 %1105, 23
  store i64 %1242, i64* %PC, align 8
  %1243 = inttoptr i64 %1241 to i64*
  %1244 = load i64, i64* %1243, align 8
  store i64 %1244, i64* %R8, align 8, !tbaa !2428
  %1245 = add i64 %1106, -176
  %1246 = add i64 %1105, 30
  store i64 %1246, i64* %PC, align 8
  %1247 = inttoptr i64 %1245 to i64*
  %1248 = load i64, i64* %1247, align 8
  store i64 %1248, i64* %R9, align 8, !tbaa !2428
  %1249 = add i64 %1106, -184
  %1250 = add i64 %1105, 37
  store i64 %1250, i64* %PC, align 8
  %1251 = inttoptr i64 %1249 to i64*
  %1252 = load i64, i64* %1251, align 8
  store i64 %1252, i64* %RAX, align 8, !tbaa !2428
  %1253 = load i64*, i64** %416, align 8
  %1254 = add i64 %1105, 41
  store i64 %1254, i64* %PC, align 8
  store i64 %1252, i64* %1253, align 8
  %1255 = load i64, i64* %PC, align 8
  %1256 = add i64 %1255, 7556
  %1257 = add i64 %1255, 5
  %1258 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1259 = add i64 %1258, -8
  %1260 = inttoptr i64 %1259 to i64*
  store i64 %1257, i64* %1260, align 8
  store i64 %1259, i64* %RSP, align 8, !tbaa !2428
  store i64 %1256, i64* %PC, align 8, !tbaa !2428
  %1261 = tail call %struct.Memory* @sub_402bf0_print_array_renamed_(%struct.State* nonnull %0, i64 %1256, %struct.Memory* %1093)
  %1262 = load i64, i64* %RBP, align 8
  %1263 = add i64 %1262, -96
  %1264 = load i64, i64* %PC, align 8
  %1265 = add i64 %1264, 4
  store i64 %1265, i64* %PC, align 8
  %1266 = inttoptr i64 %1263 to i64*
  %1267 = load i64, i64* %1266, align 8
  store i64 %1267, i64* %RAX, align 8, !tbaa !2428
  store i64 %1267, i64* %RDI, align 8, !tbaa !2428
  %1268 = add i64 %1264, -2337
  %1269 = add i64 %1264, 12
  %1270 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1271 = add i64 %1270, -8
  %1272 = inttoptr i64 %1271 to i64*
  store i64 %1269, i64* %1272, align 8
  store i64 %1271, i64* %RSP, align 8, !tbaa !2428
  store i64 %1268, i64* %PC, align 8, !tbaa !2428
  %1273 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1261)
  %1274 = load i64, i64* %RBP, align 8
  %1275 = add i64 %1274, -104
  %1276 = load i64, i64* %PC, align 8
  %1277 = add i64 %1276, 4
  store i64 %1277, i64* %PC, align 8
  %1278 = inttoptr i64 %1275 to i64*
  %1279 = load i64, i64* %1278, align 8
  store i64 %1279, i64* %RAX, align 8, !tbaa !2428
  store i64 %1279, i64* %RDI, align 8, !tbaa !2428
  %1280 = add i64 %1276, -2349
  %1281 = add i64 %1276, 12
  %1282 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1283 = add i64 %1282, -8
  %1284 = inttoptr i64 %1283 to i64*
  store i64 %1281, i64* %1284, align 8
  store i64 %1283, i64* %RSP, align 8, !tbaa !2428
  store i64 %1280, i64* %PC, align 8, !tbaa !2428
  %1285 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1273)
  %1286 = load i64, i64* %RBP, align 8
  %1287 = add i64 %1286, -112
  %1288 = load i64, i64* %PC, align 8
  %1289 = add i64 %1288, 4
  store i64 %1289, i64* %PC, align 8
  %1290 = inttoptr i64 %1287 to i64*
  %1291 = load i64, i64* %1290, align 8
  store i64 %1291, i64* %RAX, align 8, !tbaa !2428
  store i64 %1291, i64* %RDI, align 8, !tbaa !2428
  %1292 = add i64 %1288, -2361
  %1293 = add i64 %1288, 12
  %1294 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1295 = add i64 %1294, -8
  %1296 = inttoptr i64 %1295 to i64*
  store i64 %1293, i64* %1296, align 8
  store i64 %1295, i64* %RSP, align 8, !tbaa !2428
  store i64 %1292, i64* %PC, align 8, !tbaa !2428
  %1297 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1285)
  %1298 = load i64, i64* %RBP, align 8
  %1299 = add i64 %1298, -120
  %1300 = load i64, i64* %PC, align 8
  %1301 = add i64 %1300, 4
  store i64 %1301, i64* %PC, align 8
  %1302 = inttoptr i64 %1299 to i64*
  %1303 = load i64, i64* %1302, align 8
  store i64 %1303, i64* %RAX, align 8, !tbaa !2428
  store i64 %1303, i64* %RDI, align 8, !tbaa !2428
  %1304 = add i64 %1300, -2373
  %1305 = add i64 %1300, 12
  %1306 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1307 = add i64 %1306, -8
  %1308 = inttoptr i64 %1307 to i64*
  store i64 %1305, i64* %1308, align 8
  store i64 %1307, i64* %RSP, align 8, !tbaa !2428
  store i64 %1304, i64* %PC, align 8, !tbaa !2428
  %1309 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1297)
  %1310 = load i64, i64* %RBP, align 8
  %1311 = add i64 %1310, -128
  %1312 = load i64, i64* %PC, align 8
  %1313 = add i64 %1312, 4
  store i64 %1313, i64* %PC, align 8
  %1314 = inttoptr i64 %1311 to i64*
  %1315 = load i64, i64* %1314, align 8
  store i64 %1315, i64* %RAX, align 8, !tbaa !2428
  store i64 %1315, i64* %RDI, align 8, !tbaa !2428
  %1316 = add i64 %1312, -2385
  %1317 = add i64 %1312, 12
  %1318 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1319 = add i64 %1318, -8
  %1320 = inttoptr i64 %1319 to i64*
  store i64 %1317, i64* %1320, align 8
  store i64 %1319, i64* %RSP, align 8, !tbaa !2428
  store i64 %1316, i64* %PC, align 8, !tbaa !2428
  %1321 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1309)
  %1322 = load i64, i64* %RBP, align 8
  %1323 = add i64 %1322, -136
  %1324 = load i64, i64* %PC, align 8
  %1325 = add i64 %1324, 7
  store i64 %1325, i64* %PC, align 8
  %1326 = inttoptr i64 %1323 to i64*
  %1327 = load i64, i64* %1326, align 8
  store i64 %1327, i64* %RAX, align 8, !tbaa !2428
  store i64 %1327, i64* %RDI, align 8, !tbaa !2428
  %1328 = add i64 %1324, -2397
  %1329 = add i64 %1324, 15
  %1330 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1331 = add i64 %1330, -8
  %1332 = inttoptr i64 %1331 to i64*
  store i64 %1329, i64* %1332, align 8
  store i64 %1331, i64* %RSP, align 8, !tbaa !2428
  store i64 %1328, i64* %PC, align 8, !tbaa !2428
  %1333 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1321)
  %1334 = load i64, i64* %RBP, align 8
  %1335 = add i64 %1334, -144
  %1336 = load i64, i64* %PC, align 8
  %1337 = add i64 %1336, 7
  store i64 %1337, i64* %PC, align 8
  %1338 = inttoptr i64 %1335 to i64*
  %1339 = load i64, i64* %1338, align 8
  store i64 %1339, i64* %RAX, align 8, !tbaa !2428
  store i64 %1339, i64* %RDI, align 8, !tbaa !2428
  %1340 = add i64 %1336, -2412
  %1341 = add i64 %1336, 15
  %1342 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1343 = add i64 %1342, -8
  %1344 = inttoptr i64 %1343 to i64*
  store i64 %1341, i64* %1344, align 8
  store i64 %1343, i64* %RSP, align 8, !tbaa !2428
  store i64 %1340, i64* %PC, align 8, !tbaa !2428
  %1345 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1333)
  %1346 = load i64, i64* %RBP, align 8
  %1347 = add i64 %1346, -152
  %1348 = load i64, i64* %PC, align 8
  %1349 = add i64 %1348, 7
  store i64 %1349, i64* %PC, align 8
  %1350 = inttoptr i64 %1347 to i64*
  %1351 = load i64, i64* %1350, align 8
  store i64 %1351, i64* %RAX, align 8, !tbaa !2428
  store i64 %1351, i64* %RDI, align 8, !tbaa !2428
  %1352 = add i64 %1348, -2427
  %1353 = add i64 %1348, 15
  %1354 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1355 = add i64 %1354, -8
  %1356 = inttoptr i64 %1355 to i64*
  store i64 %1353, i64* %1356, align 8
  store i64 %1355, i64* %RSP, align 8, !tbaa !2428
  store i64 %1352, i64* %PC, align 8, !tbaa !2428
  %1357 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1345)
  %1358 = load i64, i64* %RBP, align 8
  %1359 = add i64 %1358, -160
  %1360 = load i64, i64* %PC, align 8
  %1361 = add i64 %1360, 7
  store i64 %1361, i64* %PC, align 8
  %1362 = inttoptr i64 %1359 to i64*
  %1363 = load i64, i64* %1362, align 8
  store i64 %1363, i64* %RAX, align 8, !tbaa !2428
  store i64 %1363, i64* %RDI, align 8, !tbaa !2428
  %1364 = add i64 %1360, -2442
  %1365 = add i64 %1360, 15
  %1366 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1367 = add i64 %1366, -8
  %1368 = inttoptr i64 %1367 to i64*
  store i64 %1365, i64* %1368, align 8
  store i64 %1367, i64* %RSP, align 8, !tbaa !2428
  store i64 %1364, i64* %PC, align 8, !tbaa !2428
  %1369 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1357)
  %1370 = load i64, i64* %RBP, align 8
  %1371 = add i64 %1370, -168
  %1372 = load i64, i64* %PC, align 8
  %1373 = add i64 %1372, 7
  store i64 %1373, i64* %PC, align 8
  %1374 = inttoptr i64 %1371 to i64*
  %1375 = load i64, i64* %1374, align 8
  store i64 %1375, i64* %RAX, align 8, !tbaa !2428
  store i64 %1375, i64* %RDI, align 8, !tbaa !2428
  %1376 = add i64 %1372, -2457
  %1377 = add i64 %1372, 15
  %1378 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1379 = add i64 %1378, -8
  %1380 = inttoptr i64 %1379 to i64*
  store i64 %1377, i64* %1380, align 8
  store i64 %1379, i64* %RSP, align 8, !tbaa !2428
  store i64 %1376, i64* %PC, align 8, !tbaa !2428
  %1381 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1369)
  %1382 = load i64, i64* %RBP, align 8
  %1383 = add i64 %1382, -176
  %1384 = load i64, i64* %PC, align 8
  %1385 = add i64 %1384, 7
  store i64 %1385, i64* %PC, align 8
  %1386 = inttoptr i64 %1383 to i64*
  %1387 = load i64, i64* %1386, align 8
  store i64 %1387, i64* %RAX, align 8, !tbaa !2428
  store i64 %1387, i64* %RDI, align 8, !tbaa !2428
  %1388 = add i64 %1384, -2472
  %1389 = add i64 %1384, 15
  %1390 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1391 = add i64 %1390, -8
  %1392 = inttoptr i64 %1391 to i64*
  store i64 %1389, i64* %1392, align 8
  store i64 %1391, i64* %RSP, align 8, !tbaa !2428
  store i64 %1388, i64* %PC, align 8, !tbaa !2428
  %1393 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1381)
  %1394 = load i64, i64* %RBP, align 8
  %1395 = add i64 %1394, -184
  %1396 = load i64, i64* %PC, align 8
  %1397 = add i64 %1396, 7
  store i64 %1397, i64* %PC, align 8
  %1398 = inttoptr i64 %1395 to i64*
  %1399 = load i64, i64* %1398, align 8
  store i64 %1399, i64* %RAX, align 8, !tbaa !2428
  store i64 %1399, i64* %RDI, align 8, !tbaa !2428
  %1400 = add i64 %1396, -2487
  %1401 = add i64 %1396, 15
  %1402 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1403 = add i64 %1402, -8
  %1404 = inttoptr i64 %1403 to i64*
  store i64 %1401, i64* %1404, align 8
  store i64 %1403, i64* %RSP, align 8, !tbaa !2428
  store i64 %1400, i64* %PC, align 8, !tbaa !2428
  %1405 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1393)
  %1406 = load i64, i64* %RBP, align 8
  %1407 = add i64 %1406, -192
  %1408 = load i64, i64* %PC, align 8
  %1409 = add i64 %1408, 7
  store i64 %1409, i64* %PC, align 8
  %1410 = inttoptr i64 %1407 to i64*
  %1411 = load i64, i64* %1410, align 8
  store i64 %1411, i64* %RAX, align 8, !tbaa !2428
  store i64 %1411, i64* %RDI, align 8, !tbaa !2428
  %1412 = add i64 %1408, -2502
  %1413 = add i64 %1408, 15
  %1414 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1415 = add i64 %1414, -8
  %1416 = inttoptr i64 %1415 to i64*
  store i64 %1413, i64* %1416, align 8
  store i64 %1415, i64* %RSP, align 8, !tbaa !2428
  store i64 %1412, i64* %PC, align 8, !tbaa !2428
  %1417 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1405)
  %1418 = load i64, i64* %RBP, align 8
  %1419 = add i64 %1418, -200
  %1420 = load i64, i64* %PC, align 8
  %1421 = add i64 %1420, 7
  store i64 %1421, i64* %PC, align 8
  %1422 = inttoptr i64 %1419 to i64*
  %1423 = load i64, i64* %1422, align 8
  store i64 %1423, i64* %RAX, align 8, !tbaa !2428
  store i64 %1423, i64* %RDI, align 8, !tbaa !2428
  %1424 = add i64 %1420, -2517
  %1425 = add i64 %1420, 15
  %1426 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1427 = add i64 %1426, -8
  %1428 = inttoptr i64 %1427 to i64*
  store i64 %1425, i64* %1428, align 8
  store i64 %1427, i64* %RSP, align 8, !tbaa !2428
  store i64 %1424, i64* %PC, align 8, !tbaa !2428
  %1429 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1417)
  %1430 = load i64, i64* %RBP, align 8
  %1431 = add i64 %1430, -208
  %1432 = load i64, i64* %PC, align 8
  %1433 = add i64 %1432, 7
  store i64 %1433, i64* %PC, align 8
  %1434 = inttoptr i64 %1431 to i64*
  %1435 = load i64, i64* %1434, align 8
  store i64 %1435, i64* %RAX, align 8, !tbaa !2428
  store i64 %1435, i64* %RDI, align 8, !tbaa !2428
  %1436 = add i64 %1432, -2532
  %1437 = add i64 %1432, 15
  %1438 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1439 = add i64 %1438, -8
  %1440 = inttoptr i64 %1439 to i64*
  store i64 %1437, i64* %1440, align 8
  store i64 %1439, i64* %RSP, align 8, !tbaa !2428
  store i64 %1436, i64* %PC, align 8, !tbaa !2428
  %1441 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1429)
  %1442 = load i64, i64* %RBP, align 8
  %1443 = add i64 %1442, -216
  %1444 = load i64, i64* %PC, align 8
  %1445 = add i64 %1444, 7
  store i64 %1445, i64* %PC, align 8
  %1446 = inttoptr i64 %1443 to i64*
  %1447 = load i64, i64* %1446, align 8
  store i64 %1447, i64* %RAX, align 8, !tbaa !2428
  store i64 %1447, i64* %RDI, align 8, !tbaa !2428
  %1448 = add i64 %1444, -2547
  %1449 = add i64 %1444, 15
  %1450 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1451 = add i64 %1450, -8
  %1452 = inttoptr i64 %1451 to i64*
  store i64 %1449, i64* %1452, align 8
  store i64 %1451, i64* %RSP, align 8, !tbaa !2428
  store i64 %1448, i64* %PC, align 8, !tbaa !2428
  %1453 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1441)
  %1454 = load i64, i64* %RBP, align 8
  %1455 = add i64 %1454, -224
  %1456 = load i64, i64* %PC, align 8
  %1457 = add i64 %1456, 7
  store i64 %1457, i64* %PC, align 8
  %1458 = inttoptr i64 %1455 to i64*
  %1459 = load i64, i64* %1458, align 8
  store i64 %1459, i64* %RAX, align 8, !tbaa !2428
  store i64 %1459, i64* %RDI, align 8, !tbaa !2428
  %1460 = add i64 %1456, -2562
  %1461 = add i64 %1456, 15
  %1462 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1463 = add i64 %1462, -8
  %1464 = inttoptr i64 %1463 to i64*
  store i64 %1461, i64* %1464, align 8
  store i64 %1463, i64* %RSP, align 8, !tbaa !2428
  store i64 %1460, i64* %PC, align 8, !tbaa !2428
  %1465 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1453)
  %1466 = load i64, i64* %RBP, align 8
  %1467 = add i64 %1466, -232
  %1468 = load i64, i64* %PC, align 8
  %1469 = add i64 %1468, 7
  store i64 %1469, i64* %PC, align 8
  %1470 = inttoptr i64 %1467 to i64*
  %1471 = load i64, i64* %1470, align 8
  store i64 %1471, i64* %RAX, align 8, !tbaa !2428
  store i64 %1471, i64* %RDI, align 8, !tbaa !2428
  %1472 = add i64 %1468, -2577
  %1473 = add i64 %1468, 15
  %1474 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1475 = add i64 %1474, -8
  %1476 = inttoptr i64 %1475 to i64*
  store i64 %1473, i64* %1476, align 8
  store i64 %1475, i64* %RSP, align 8, !tbaa !2428
  store i64 %1472, i64* %PC, align 8, !tbaa !2428
  %1477 = tail call fastcc %struct.Memory* @ext_6040d8_free(%struct.State* nonnull %0, %struct.Memory* %1465)
  %1478 = load i64, i64* %RBP, align 8
  %1479 = add i64 %1478, -44
  %1480 = load i64, i64* %PC, align 8
  %1481 = add i64 %1480, 7
  store i64 %1481, i64* %PC, align 8
  %1482 = inttoptr i64 %1479 to i32*
  store i32 0, i32* %1482, align 4
  %.pre = load i64, i64* %PC, align 8
  br label %block_400f77

block_400de1:                                     ; preds = %block_400db0
  %1483 = add i64 %1206, -60
  %1484 = add i64 %1205, 3
  store i64 %1484, i64* %PC, align 8
  %1485 = inttoptr i64 %1483 to i32*
  %1486 = load i32, i32* %1485, align 4
  %1487 = zext i32 %1486 to i64
  store i64 %1487, i64* %RDI, align 8, !tbaa !2428
  %1488 = add i64 %1206, -68
  %1489 = add i64 %1205, 6
  store i64 %1489, i64* %PC, align 8
  %1490 = inttoptr i64 %1488 to i32*
  %1491 = load i32, i32* %1490, align 4
  %1492 = zext i32 %1491 to i64
  store i64 %1492, i64* %RSI, align 8, !tbaa !2428
  %1493 = add i64 %1206, -64
  %1494 = add i64 %1205, 9
  store i64 %1494, i64* %PC, align 8
  %1495 = inttoptr i64 %1493 to i32*
  %1496 = load i32, i32* %1495, align 4
  %1497 = zext i32 %1496 to i64
  store i64 %1497, i64* %RDX, align 8, !tbaa !2428
  %1498 = add i64 %1206, -144
  %1499 = add i64 %1205, 16
  store i64 %1499, i64* %PC, align 8
  %1500 = inttoptr i64 %1498 to i64*
  %1501 = load i64, i64* %1500, align 8
  store i64 %1501, i64* %RCX, align 8, !tbaa !2428
  %1502 = add i64 %1206, -176
  %1503 = add i64 %1205, 23
  store i64 %1503, i64* %PC, align 8
  %1504 = inttoptr i64 %1502 to i64*
  %1505 = load i64, i64* %1504, align 8
  store i64 %1505, i64* %R8, align 8, !tbaa !2428
  %1506 = add i64 %1205, 7279
  %1507 = add i64 %1205, 28
  %1508 = load i64, i64* %RSP, align 8, !tbaa !2428
  %1509 = add i64 %1508, -8
  %1510 = inttoptr i64 %1509 to i64*
  store i64 %1507, i64* %1510, align 8
  store i64 %1509, i64* %RSP, align 8, !tbaa !2428
  store i64 %1506, i64* %PC, align 8, !tbaa !2428
  %1511 = tail call %struct.Memory* @sub_402a50_check_FP_renamed_(%struct.State* nonnull %0, i64 %1506, %struct.Memory* %1193)
  %1512 = load i32, i32* %EAX, align 4
  %1513 = load i64, i64* %PC, align 8
  store i8 0, i8* %41, align 1, !tbaa !2432
  %1514 = and i32 %1512, 255
  %1515 = tail call i32 @llvm.ctpop.i32(i32 %1514) #8
  %1516 = trunc i32 %1515 to i8
  %1517 = and i8 %1516, 1
  %1518 = xor i8 %1517, 1
  store i8 %1518, i8* %48, align 1, !tbaa !2446
  store i8 0, i8* %53, align 1, !tbaa !2447
  %1519 = icmp eq i32 %1512, 0
  %1520 = zext i1 %1519 to i8
  store i8 %1520, i8* %56, align 1, !tbaa !2448
  %1521 = lshr i32 %1512, 31
  %1522 = trunc i32 %1521 to i8
  store i8 %1522, i8* %59, align 1, !tbaa !2449
  store i8 0, i8* %65, align 1, !tbaa !2450
  %.v2 = select i1 %1519, i64 9, i64 21
  %1523 = add i64 %1513, %.v2
  store i64 %1523, i64* %PC, align 8, !tbaa !2428
  %1524 = load i64, i64* %RBP, align 8
  br i1 %1519, label %block_400e06, label %block_400e12

block_400dd5:                                     ; preds = %block_400db0
  %1525 = add i64 %1206, -44
  %1526 = add i64 %1205, 7
  store i64 %1526, i64* %PC, align 8
  %1527 = inttoptr i64 %1525 to i32*
  store i32 1, i32* %1527, align 4
  %1528 = load i64, i64* %PC, align 8
  %1529 = add i64 %1528, 411
  store i64 %1529, i64* %PC, align 8, !tbaa !2428
  br label %block_400f77
}

; Function Attrs: noinline
declare void @__mcsema_attach_call() #5

; Function Attrs: naked nobuiltin noinline
define internal void @callback_sub_400690_frame_dummy() #7 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400690;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @1, void ()** nonnull @2) #8
  ret void
}

define internal %struct.Memory* @callback_sub_400690_frame_dummy_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400690_frame_dummy(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define internal void @callback_sub_400660___do_global_dtors_aux() #7 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400660;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @3, void ()** nonnull @2) #8
  ret void
}

define internal %struct.Memory* @callback_sub_400660___do_global_dtors_aux_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400660___do_global_dtors_aux(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_6040d8_free(%struct.State*, %struct.Memory*) unnamed_addr #5 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64)* @free to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_6040b8_calloc(%struct.State*, %struct.Memory*) unnamed_addr #5 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64)* @calloc to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_6040f8_fprintf(%struct.State*, %struct.Memory*) unnamed_addr #5 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64)* @fprintf to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_6040e0_printf(%struct.State*, %struct.Memory*) unnamed_addr #5 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64)* @printf to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: naked nobuiltin noinline
define internal void @callback_sub_402e70___libc_csu_fini() #7 {
  tail call void asm sideeffect "pushq $0;pushq $$0x402e70;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @4, void ()** nonnull @2) #8
  ret void
}

define internal %struct.Memory* @callback_sub_402e70___libc_csu_fini_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_402e70___libc_csu_fini(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define internal void @callback_sub_402e00___libc_csu_init() #7 {
  tail call void asm sideeffect "pushq $0;pushq $$0x402e00;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @5, void ()** nonnull @2) #8
  ret void
}

define internal %struct.Memory* @callback_sub_402e00___libc_csu_init_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_402e00___libc_csu_init(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @main() #7 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400880;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @6, void ()** nonnull @2) #8
  ret void
}

define internal %struct.Memory* @main_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400880_main(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_6040b0___libc_start_main(%struct.State*, %struct.Memory*) unnamed_addr #5 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64, i64, i64, i64, i64, i64)* @__libc_start_main to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_6040c8_exit(%struct.State*, %struct.Memory*) unnamed_addr #5 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64)* @exit to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: noinline
define internal fastcc %struct.Memory* @ext_4005a0_posix_memalign(%struct.State*, %struct.Memory*) unnamed_addr #5 {
  %3 = tail call %struct.Memory* @__remill_function_call(%struct.State* %0, i64 ptrtoint (i64 (i64, i64, i64)* @posix_memalign to i64), %struct.Memory* %1)
  ret %struct.Memory* %3
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @polybench_flush_cache() local_unnamed_addr #7 {
  tail call void asm sideeffect "pushq $0;pushq $$0x4006a0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @7, void ()** nonnull @2) #8
  ret void
}

define internal %struct.Memory* @polybench_flush_cache_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_4006a0_polybench_flush_cache(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @.term_proc() local_unnamed_addr #7 {
  tail call void asm sideeffect "pushq $0;pushq $$0x402e74;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @8, void ()** nonnull @2) #8
  ret void
}

define internal %struct.Memory* @.term_proc_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_402e74__term_proc(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @polybench_timer_stop() local_unnamed_addr #7 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400760;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @9, void ()** nonnull @2) #8
  ret void
}

define internal %struct.Memory* @polybench_timer_stop_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400760_polybench_timer_stop(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @polybench_alloc_data() local_unnamed_addr #7 {
  tail call void asm sideeffect "pushq $0;pushq $$0x4007c0;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @10, void ()** nonnull @2) #8
  ret void
}

define internal %struct.Memory* @polybench_alloc_data_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_4007c0_polybench_alloc_data(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @polybench_timer_print() local_unnamed_addr #7 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400780;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @11, void ()** nonnull @2) #8
  ret void
}

define internal %struct.Memory* @polybench_timer_print_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400780_polybench_timer_print(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @.init_proc() local_unnamed_addr #7 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400520;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @12, void ()** nonnull @2) #8
  ret void
}

define internal %struct.Memory* @.init_proc_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400520__init_proc(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @polybench_timer_start() local_unnamed_addr #7 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400730;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @13, void ()** nonnull @2) #8
  ret void
}

define internal %struct.Memory* @polybench_timer_start_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400730_polybench_timer_start(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

; Function Attrs: naked nobuiltin noinline
define dllexport void @polybench_prepare_instruments() local_unnamed_addr #7 {
  tail call void asm sideeffect "pushq $0;pushq $$0x400720;jmpq *$1;", "*m,*m,~{dirflag},~{fpsr},~{flags}"(%struct.Memory* (%struct.State*, i64, %struct.Memory*)** nonnull @14, void ()** nonnull @2) #8
  ret void
}

define internal %struct.Memory* @polybench_prepare_instruments_wrapper(%struct.State*, i64, %struct.Memory*) {
  %4 = load volatile i1, i1* @0, align 1
  br i1 %4, label %__mcsema_early_init.exit, label %5

; <label>:5:                                      ; preds = %3
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %3, %5
  %6 = tail call %struct.Memory* @sub_400720_polybench_prepare_instruments(%struct.State* %0, i64 %1, %struct.Memory* %2)
  ret %struct.Memory* %6
}

define internal void @__mcsema_constructor() {
  %1 = load volatile i1, i1* @0, align 1
  br i1 %1, label %__mcsema_early_init.exit, label %2

; <label>:2:                                      ; preds = %0
  store volatile i1 true, i1* @0, align 1
  br label %__mcsema_early_init.exit

__mcsema_early_init.exit:                         ; preds = %0, %2
  tail call void @callback_sub_402e00___libc_csu_init()
  ret void
}

define internal void @__mcsema_destructor() {
  tail call void @callback_sub_402e70___libc_csu_fini()
  ret void
}

attributes #0 = { nounwind readnone }
attributes #1 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { noduplicate noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { noinline }
attributes #6 = { noinline "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { naked nobuiltin noinline }
attributes #8 = { nounwind }
attributes #9 = { alwaysinline nobuiltin nounwind }

!llvm.ident = !{!0, !0}
!llvm.dbg.cu = !{!1}
!llvm.module.flags = !{!1259, !1260}

!0 = !{!"clang version 4.0.1 (tags/RELEASE_401/final)"}
!1 = distinct !DICompileUnit(language: DW_LANG_C_plus_plus, file: !2, producer: "clang version 4.0.1 (tags/RELEASE_401/final)", isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug, enums: !3, retainedTypes: !67, imports: !70)
!2 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/X86/Runtime/BasicBlock.cpp", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!3 = !{!4, !26, !35, !39, !45, !51, !55, !61}
!4 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "Name", scope: !6, file: !5, line: 70, baseType: !8, size: 32, elements: !11, identifier: "_ZTSN14AsyncHyperCall4NameE")
!5 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/HyperCall.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!6 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "AsyncHyperCall", file: !5, line: 68, size: 8, elements: !7, identifier: "_ZTS14AsyncHyperCall")
!7 = !{}
!8 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint32_t", file: !9, line: 183, baseType: !10)
!9 = !DIFile(filename: "/home/ubuntu/Github/remill/remill-build/libraries/llvm/bin/../lib/clang/4.0.1/include/stdint.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!10 = !DIBasicType(name: "unsigned int", size: 32, encoding: DW_ATE_unsigned)
!11 = !{!12, !13, !14, !15, !16, !17, !18, !19, !20, !21, !22, !23, !24, !25}
!12 = !DIEnumerator(name: "kInvalid", value: 0)
!13 = !DIEnumerator(name: "kX86Int1", value: 1)
!14 = !DIEnumerator(name: "kX86Int3", value: 2)
!15 = !DIEnumerator(name: "kX86IntO", value: 3)
!16 = !DIEnumerator(name: "kX86IntN", value: 4)
!17 = !DIEnumerator(name: "kX86Bound", value: 5)
!18 = !DIEnumerator(name: "kX86IRet", value: 6)
!19 = !DIEnumerator(name: "kX86SysCall", value: 7)
!20 = !DIEnumerator(name: "kX86SysRet", value: 8)
!21 = !DIEnumerator(name: "kX86SysEnter", value: 9)
!22 = !DIEnumerator(name: "kX86SysExit", value: 10)
!23 = !DIEnumerator(name: "kX86JmpFar", value: 11)
!24 = !DIEnumerator(name: "kAArch64SupervisorCall", value: 12)
!25 = !DIEnumerator(name: "kInvalidInstruction", value: 13)
!26 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "RequestPrivilegeLevel", file: !27, line: 64, baseType: !28, size: 16, elements: !30, identifier: "_ZTS21RequestPrivilegeLevel")
!27 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/X86/Runtime/State.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!28 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint16_t", file: !9, line: 218, baseType: !29)
!29 = !DIBasicType(name: "unsigned short", size: 16, encoding: DW_ATE_unsigned)
!30 = !{!31, !32, !33, !34}
!31 = !DIEnumerator(name: "kRPLRingZero", value: 0)
!32 = !DIEnumerator(name: "kRPLRingOne", value: 1)
!33 = !DIEnumerator(name: "kRPLRingTwo", value: 2)
!34 = !DIEnumerator(name: "kRPLRingThree", value: 3)
!35 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "TableIndicator", file: !27, line: 71, baseType: !28, size: 16, elements: !36, identifier: "_ZTS14TableIndicator")
!36 = !{!37, !38}
!37 = !DIEnumerator(name: "kGlobalDescriptorTable", value: 0)
!38 = !DIEnumerator(name: "kLocalDescriptorTable", value: 1)
!39 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUPrecisionControl", file: !27, line: 123, baseType: !28, size: 16, elements: !40, identifier: "_ZTS19FPUPrecisionControl")
!40 = !{!41, !42, !43, !44}
!41 = !DIEnumerator(name: "kPrecisionSingle", value: 0)
!42 = !DIEnumerator(name: "kPrecisionReserved", value: 1)
!43 = !DIEnumerator(name: "kPrecisionDouble", value: 2)
!44 = !DIEnumerator(name: "kPrecisionExtended", value: 3)
!45 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPURoundingControl", file: !27, line: 130, baseType: !28, size: 16, elements: !46, identifier: "_ZTS18FPURoundingControl")
!46 = !{!47, !48, !49, !50}
!47 = !DIEnumerator(name: "kFPURoundToNearestEven", value: 0)
!48 = !DIEnumerator(name: "kFPURoundDownNegInf", value: 1)
!49 = !DIEnumerator(name: "kFPURoundUpInf", value: 2)
!50 = !DIEnumerator(name: "kFPURoundToZero", value: 3)
!51 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUInfinityControl", file: !27, line: 137, baseType: !28, size: 16, elements: !52, identifier: "_ZTS18FPUInfinityControl")
!52 = !{!53, !54}
!53 = !DIEnumerator(name: "kInfinityProjective", value: 0)
!54 = !DIEnumerator(name: "kInfinityAffine", value: 1)
!55 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUTag", file: !27, line: 214, baseType: !28, size: 16, elements: !56, identifier: "_ZTS6FPUTag")
!56 = !{!57, !58, !59, !60}
!57 = !DIEnumerator(name: "kFPUTagNonZero", value: 0)
!58 = !DIEnumerator(name: "kFPUTagZero", value: 1)
!59 = !DIEnumerator(name: "kFPUTagSpecial", value: 2)
!60 = !DIEnumerator(name: "kFPUTagEmpty", value: 3)
!61 = distinct !DICompositeType(tag: DW_TAG_enumeration_type, name: "FPUAbridgedTag", file: !27, line: 221, baseType: !62, size: 8, elements: !64, identifier: "_ZTS14FPUAbridgedTag")
!62 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint8_t", file: !9, line: 237, baseType: !63)
!63 = !DIBasicType(name: "unsigned char", size: 8, encoding: DW_ATE_unsigned_char)
!64 = !{!65, !66}
!65 = !DIEnumerator(name: "kFPUAbridgedTagEmpty", value: 0)
!66 = !DIEnumerator(name: "kFPUAbridgedTagValid", value: 1)
!67 = !{!68}
!68 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !69, size: 64)
!69 = !DIDerivedType(tag: DW_TAG_const_type, baseType: null)
!70 = !{!71, !77, !83, !86, !93, !97, !102, !104, !112, !116, !120, !132, !136, !140, !144, !148, !153, !157, !161, !165, !169, !177, !181, !185, !187, !191, !195, !199, !205, !209, !213, !215, !223, !227, !235, !237, !241, !245, !249, !253, !258, !263, !268, !269, !270, !271, !274, !275, !276, !277, !278, !279, !280, !335, !339, !355, !358, !363, !371, !376, !380, !384, !388, !392, !394, !396, !400, !406, !410, !416, !422, !424, !428, !432, !436, !440, !451, !453, !457, !461, !465, !467, !471, !475, !479, !481, !483, !487, !495, !499, !503, !507, !509, !515, !517, !523, !527, !531, !535, !539, !543, !547, !549, !551, !555, !559, !563, !565, !569, !573, !575, !577, !581, !585, !589, !593, !594, !595, !596, !597, !598, !599, !600, !601, !602, !603, !606, !609, !611, !613, !615, !617, !619, !621, !623, !625, !627, !629, !631, !633, !634, !635, !636, !638, !640, !642, !644, !646, !648, !650, !652, !654, !656, !658, !660, !662, !665, !669, !674, !677, !679, !681, !683, !685, !687, !689, !691, !693, !695, !697, !699, !701, !703, !706, !712, !717, !721, !723, !725, !727, !729, !736, !740, !744, !748, !752, !756, !761, !765, !767, !771, !777, !781, !786, !788, !790, !794, !798, !802, !804, !806, !808, !810, !814, !816, !818, !822, !826, !830, !834, !838, !840, !842, !846, !850, !854, !858, !860, !862, !866, !870, !871, !872, !873, !874, !875, !880, !882, !884, !888, !890, !892, !894, !896, !898, !900, !902, !907, !911, !913, !915, !920, !922, !924, !926, !928, !930, !932, !935, !937, !939, !943, !947, !949, !951, !953, !955, !957, !959, !961, !963, !965, !967, !971, !975, !977, !979, !981, !983, !985, !987, !989, !991, !993, !995, !997, !999, !1001, !1003, !1005, !1009, !1013, !1017, !1019, !1021, !1023, !1025, !1027, !1029, !1031, !1033, !1035, !1039, !1043, !1047, !1049, !1051, !1053, !1057, !1061, !1065, !1067, !1069, !1071, !1073, !1075, !1077, !1079, !1081, !1083, !1085, !1087, !1089, !1093, !1097, !1101, !1103, !1105, !1107, !1109, !1113, !1117, !1119, !1121, !1123, !1125, !1127, !1129, !1133, !1137, !1139, !1141, !1143, !1145, !1149, !1153, !1157, !1159, !1161, !1163, !1165, !1167, !1169, !1173, !1177, !1181, !1183, !1187, !1191, !1193, !1195, !1197, !1199, !1201, !1203, !1207, !1209, !1212, !1217, !1219, !1225, !1227, !1229, !1231, !1236, !1238, !1244, !1246, !1247, !1248, !1249, !1250, !1251, !1252, !1253, !1254, !1255, !1256, !1257, !1258}
!71 = !DIImportedEntity(tag: DW_TAG_imported_module, scope: !72, entity: !74, line: 58)
!72 = !DINamespace(name: "__gnu_debug", scope: null, file: !73, line: 56)
!73 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/debug/debug.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!74 = !DINamespace(name: "__debug", scope: !75, file: !73, line: 50)
!75 = !DINamespace(name: "std", scope: null, file: !76, line: 229)
!76 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/x86_64-linux-gnu/c++/7.4.0/bits/c++config.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!77 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !78, line: 52)
!78 = !DISubprogram(name: "abs", scope: !79, file: !79, line: 837, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!79 = !DIFile(filename: "/usr/include/stdlib.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!80 = !DISubroutineType(types: !81)
!81 = !{!82, !82}
!82 = !DIBasicType(name: "int", size: 32, encoding: DW_ATE_signed)
!83 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !84, line: 127)
!84 = !DIDerivedType(tag: DW_TAG_typedef, name: "div_t", file: !79, line: 62, baseType: !85)
!85 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 58, flags: DIFlagFwdDecl, identifier: "_ZTS5div_t")
!86 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !87, line: 128)
!87 = !DIDerivedType(tag: DW_TAG_typedef, name: "ldiv_t", file: !79, line: 70, baseType: !88)
!88 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 66, size: 128, elements: !89, identifier: "_ZTS6ldiv_t")
!89 = !{!90, !92}
!90 = !DIDerivedType(tag: DW_TAG_member, name: "quot", scope: !88, file: !79, line: 68, baseType: !91, size: 64)
!91 = !DIBasicType(name: "long int", size: 64, encoding: DW_ATE_signed)
!92 = !DIDerivedType(tag: DW_TAG_member, name: "rem", scope: !88, file: !79, line: 69, baseType: !91, size: 64, offset: 64)
!93 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !94, line: 130)
!94 = !DISubprogram(name: "abort", scope: !79, file: !79, line: 588, type: !95, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!95 = !DISubroutineType(types: !96)
!96 = !{null}
!97 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !98, line: 134)
!98 = !DISubprogram(name: "atexit", scope: !79, file: !79, line: 592, type: !99, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!99 = !DISubroutineType(types: !100)
!100 = !{!82, !101}
!101 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !95, size: 64)
!102 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !103, line: 137)
!103 = !DISubprogram(name: "at_quick_exit", scope: !79, file: !79, line: 597, type: !99, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!104 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !105, line: 140)
!105 = !DISubprogram(name: "atof", scope: !79, file: !79, line: 101, type: !106, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!106 = !DISubroutineType(types: !107)
!107 = !{!108, !109}
!108 = !DIBasicType(name: "double", size: 64, encoding: DW_ATE_float)
!109 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !110, size: 64)
!110 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !111)
!111 = !DIBasicType(name: "char", size: 8, encoding: DW_ATE_signed_char)
!112 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !113, line: 141)
!113 = !DISubprogram(name: "atoi", scope: !79, file: !79, line: 104, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!114 = !DISubroutineType(types: !115)
!115 = !{!82, !109}
!116 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !117, line: 142)
!117 = !DISubprogram(name: "atol", scope: !79, file: !79, line: 107, type: !118, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!118 = !DISubroutineType(types: !119)
!119 = !{!91, !109}
!120 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !121, line: 143)
!121 = !DISubprogram(name: "bsearch", scope: !79, file: !79, line: 817, type: !122, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!122 = !DISubroutineType(types: !123)
!123 = !{!124, !68, !68, !125, !125, !128}
!124 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: null, size: 64)
!125 = !DIDerivedType(tag: DW_TAG_typedef, name: "size_t", file: !126, line: 62, baseType: !127)
!126 = !DIFile(filename: "/home/ubuntu/Github/remill/remill-build/libraries/llvm/bin/../lib/clang/4.0.1/include/stddef.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!127 = !DIBasicType(name: "long unsigned int", size: 64, encoding: DW_ATE_unsigned)
!128 = !DIDerivedType(tag: DW_TAG_typedef, name: "__compar_fn_t", file: !79, line: 805, baseType: !129)
!129 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !130, size: 64)
!130 = !DISubroutineType(types: !131)
!131 = !{!82, !68, !68}
!132 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !133, line: 144)
!133 = !DISubprogram(name: "calloc", scope: !79, file: !79, line: 541, type: !134, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!134 = !DISubroutineType(types: !135)
!135 = !{!124, !125, !125}
!136 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !137, line: 145)
!137 = !DISubprogram(name: "div", scope: !79, file: !79, line: 849, type: !138, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!138 = !DISubroutineType(types: !139)
!139 = !{!84, !82, !82}
!140 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !141, line: 146)
!141 = !DISubprogram(name: "exit", scope: !79, file: !79, line: 614, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!142 = !DISubroutineType(types: !143)
!143 = !{null, !82}
!144 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !145, line: 147)
!145 = !DISubprogram(name: "free", scope: !79, file: !79, line: 563, type: !146, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!146 = !DISubroutineType(types: !147)
!147 = !{null, !124}
!148 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !149, line: 148)
!149 = !DISubprogram(name: "getenv", scope: !79, file: !79, line: 631, type: !150, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!150 = !DISubroutineType(types: !151)
!151 = !{!152, !109}
!152 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !111, size: 64)
!153 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !154, line: 149)
!154 = !DISubprogram(name: "labs", scope: !79, file: !79, line: 838, type: !155, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!155 = !DISubroutineType(types: !156)
!156 = !{!91, !91}
!157 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !158, line: 150)
!158 = !DISubprogram(name: "ldiv", scope: !79, file: !79, line: 851, type: !159, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!159 = !DISubroutineType(types: !160)
!160 = !{!87, !91, !91}
!161 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !162, line: 151)
!162 = !DISubprogram(name: "malloc", scope: !79, file: !79, line: 539, type: !163, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!163 = !DISubroutineType(types: !164)
!164 = !{!124, !125}
!165 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !166, line: 153)
!166 = !DISubprogram(name: "mblen", scope: !79, file: !79, line: 919, type: !167, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!167 = !DISubroutineType(types: !168)
!168 = !{!82, !109, !125}
!169 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !170, line: 154)
!170 = !DISubprogram(name: "mbstowcs", scope: !79, file: !79, line: 930, type: !171, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!171 = !DISubroutineType(types: !172)
!172 = !{!125, !173, !176, !125}
!173 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !174)
!174 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !175, size: 64)
!175 = !DIBasicType(name: "wchar_t", size: 32, encoding: DW_ATE_signed)
!176 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !109)
!177 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !178, line: 155)
!178 = !DISubprogram(name: "mbtowc", scope: !79, file: !79, line: 922, type: !179, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!179 = !DISubroutineType(types: !180)
!180 = !{!82, !173, !176, !125}
!181 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !182, line: 157)
!182 = !DISubprogram(name: "qsort", scope: !79, file: !79, line: 827, type: !183, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!183 = !DISubroutineType(types: !184)
!184 = !{null, !124, !125, !125, !128}
!185 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !186, line: 160)
!186 = !DISubprogram(name: "quick_exit", scope: !79, file: !79, line: 620, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!187 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !188, line: 163)
!188 = !DISubprogram(name: "rand", scope: !79, file: !79, line: 453, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!189 = !DISubroutineType(types: !190)
!190 = !{!82}
!191 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !192, line: 164)
!192 = !DISubprogram(name: "realloc", scope: !79, file: !79, line: 549, type: !193, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!193 = !DISubroutineType(types: !194)
!194 = !{!124, !124, !125}
!195 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !196, line: 165)
!196 = !DISubprogram(name: "srand", scope: !79, file: !79, line: 455, type: !197, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!197 = !DISubroutineType(types: !198)
!198 = !{null, !10}
!199 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !200, line: 166)
!200 = !DISubprogram(name: "strtod", scope: !79, file: !79, line: 117, type: !201, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!201 = !DISubroutineType(types: !202)
!202 = !{!108, !176, !203}
!203 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !204)
!204 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !152, size: 64)
!205 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !206, line: 167)
!206 = !DISubprogram(name: "strtol", scope: !79, file: !79, line: 176, type: !207, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!207 = !DISubroutineType(types: !208)
!208 = !{!91, !176, !203, !82}
!209 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !210, line: 168)
!210 = !DISubprogram(name: "strtoul", scope: !79, file: !79, line: 180, type: !211, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!211 = !DISubroutineType(types: !212)
!212 = !{!127, !176, !203, !82}
!213 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !214, line: 169)
!214 = !DISubprogram(name: "system", scope: !79, file: !79, line: 781, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!215 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !216, line: 171)
!216 = !DISubprogram(name: "wcstombs", scope: !79, file: !79, line: 933, type: !217, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!217 = !DISubroutineType(types: !218)
!218 = !{!125, !219, !220, !125}
!219 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !152)
!220 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !221)
!221 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !222, size: 64)
!222 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !175)
!223 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !224, line: 172)
!224 = !DISubprogram(name: "wctomb", scope: !79, file: !79, line: 926, type: !225, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!225 = !DISubroutineType(types: !226)
!226 = !{!82, !152, !175}
!227 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !229, line: 200)
!228 = !DINamespace(name: "__gnu_cxx", scope: null, file: !76, line: 255)
!229 = !DIDerivedType(tag: DW_TAG_typedef, name: "lldiv_t", file: !79, line: 80, baseType: !230)
!230 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !79, line: 76, size: 128, elements: !231, identifier: "_ZTS7lldiv_t")
!231 = !{!232, !234}
!232 = !DIDerivedType(tag: DW_TAG_member, name: "quot", scope: !230, file: !79, line: 78, baseType: !233, size: 64)
!233 = !DIBasicType(name: "long long int", size: 64, encoding: DW_ATE_signed)
!234 = !DIDerivedType(tag: DW_TAG_member, name: "rem", scope: !230, file: !79, line: 79, baseType: !233, size: 64, offset: 64)
!235 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !236, line: 206)
!236 = !DISubprogram(name: "_Exit", scope: !79, file: !79, line: 626, type: !142, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!237 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !238, line: 210)
!238 = !DISubprogram(name: "llabs", scope: !79, file: !79, line: 841, type: !239, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!239 = !DISubroutineType(types: !240)
!240 = !{!233, !233}
!241 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !242, line: 216)
!242 = !DISubprogram(name: "lldiv", scope: !79, file: !79, line: 855, type: !243, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!243 = !DISubroutineType(types: !244)
!244 = !{!229, !233, !233}
!245 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !246, line: 227)
!246 = !DISubprogram(name: "atoll", scope: !79, file: !79, line: 112, type: !247, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!247 = !DISubroutineType(types: !248)
!248 = !{!233, !109}
!249 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !250, line: 228)
!250 = !DISubprogram(name: "strtoll", scope: !79, file: !79, line: 200, type: !251, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!251 = !DISubroutineType(types: !252)
!252 = !{!233, !176, !203, !82}
!253 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !254, line: 229)
!254 = !DISubprogram(name: "strtoull", scope: !79, file: !79, line: 205, type: !255, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!255 = !DISubroutineType(types: !256)
!256 = !{!257, !176, !203, !82}
!257 = !DIBasicType(name: "long long unsigned int", size: 64, encoding: DW_ATE_unsigned)
!258 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !259, line: 231)
!259 = !DISubprogram(name: "strtof", scope: !79, file: !79, line: 123, type: !260, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!260 = !DISubroutineType(types: !261)
!261 = !{!262, !176, !203}
!262 = !DIBasicType(name: "float", size: 32, encoding: DW_ATE_float)
!263 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !264, line: 232)
!264 = !DISubprogram(name: "strtold", scope: !79, file: !79, line: 126, type: !265, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!265 = !DISubroutineType(types: !266)
!266 = !{!267, !176, !203}
!267 = !DIBasicType(name: "long double", size: 128, encoding: DW_ATE_float)
!268 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !229, line: 240)
!269 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !236, line: 242)
!270 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !238, line: 244)
!271 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !272, line: 245)
!272 = !DISubprogram(name: "div", linkageName: "_ZN9__gnu_cxx3divExx", scope: !228, file: !273, line: 213, type: !243, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!273 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/cstdlib", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!274 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !242, line: 246)
!275 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !246, line: 248)
!276 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !259, line: 249)
!277 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !250, line: 250)
!278 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !254, line: 251)
!279 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !264, line: 252)
!280 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !281, line: 57)
!281 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "exception_ptr", scope: !283, file: !282, line: 79, size: 64, elements: !284, identifier: "_ZTSNSt15__exception_ptr13exception_ptrE")
!282 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/bits/exception_ptr.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!283 = !DINamespace(name: "__exception_ptr", scope: !75, file: !282, line: 52)
!284 = !{!285, !286, !290, !293, !294, !299, !300, !304, !309, !313, !317, !320, !321, !324, !328}
!285 = !DIDerivedType(tag: DW_TAG_member, name: "_M_exception_object", scope: !281, file: !282, line: 81, baseType: !124, size: 64)
!286 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 83, type: !287, isLocal: false, isDefinition: false, scopeLine: 83, flags: DIFlagExplicit | DIFlagPrototyped, isOptimized: false)
!287 = !DISubroutineType(types: !288)
!288 = !{null, !289, !124}
!289 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !281, size: 64, flags: DIFlagArtificial | DIFlagObjectPointer)
!290 = !DISubprogram(name: "_M_addref", linkageName: "_ZNSt15__exception_ptr13exception_ptr9_M_addrefEv", scope: !281, file: !282, line: 85, type: !291, isLocal: false, isDefinition: false, scopeLine: 85, flags: DIFlagPrototyped, isOptimized: false)
!291 = !DISubroutineType(types: !292)
!292 = !{null, !289}
!293 = !DISubprogram(name: "_M_release", linkageName: "_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv", scope: !281, file: !282, line: 86, type: !291, isLocal: false, isDefinition: false, scopeLine: 86, flags: DIFlagPrototyped, isOptimized: false)
!294 = !DISubprogram(name: "_M_get", linkageName: "_ZNKSt15__exception_ptr13exception_ptr6_M_getEv", scope: !281, file: !282, line: 88, type: !295, isLocal: false, isDefinition: false, scopeLine: 88, flags: DIFlagPrototyped, isOptimized: false)
!295 = !DISubroutineType(types: !296)
!296 = !{!124, !297}
!297 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !298, size: 64, flags: DIFlagArtificial | DIFlagObjectPointer)
!298 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !281)
!299 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 96, type: !291, isLocal: false, isDefinition: false, scopeLine: 96, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!300 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 98, type: !301, isLocal: false, isDefinition: false, scopeLine: 98, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!301 = !DISubroutineType(types: !302)
!302 = !{null, !289, !303}
!303 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !298, size: 64)
!304 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 101, type: !305, isLocal: false, isDefinition: false, scopeLine: 101, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!305 = !DISubroutineType(types: !306)
!306 = !{null, !289, !307}
!307 = !DIDerivedType(tag: DW_TAG_typedef, name: "nullptr_t", scope: !75, file: !76, line: 235, baseType: !308)
!308 = !DIBasicType(tag: DW_TAG_unspecified_type, name: "decltype(nullptr)")
!309 = !DISubprogram(name: "exception_ptr", scope: !281, file: !282, line: 105, type: !310, isLocal: false, isDefinition: false, scopeLine: 105, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!310 = !DISubroutineType(types: !311)
!311 = !{null, !289, !312}
!312 = !DIDerivedType(tag: DW_TAG_rvalue_reference_type, baseType: !281, size: 64)
!313 = !DISubprogram(name: "operator=", linkageName: "_ZNSt15__exception_ptr13exception_ptraSERKS0_", scope: !281, file: !282, line: 118, type: !314, isLocal: false, isDefinition: false, scopeLine: 118, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!314 = !DISubroutineType(types: !315)
!315 = !{!316, !289, !303}
!316 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !281, size: 64)
!317 = !DISubprogram(name: "operator=", linkageName: "_ZNSt15__exception_ptr13exception_ptraSEOS0_", scope: !281, file: !282, line: 122, type: !318, isLocal: false, isDefinition: false, scopeLine: 122, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!318 = !DISubroutineType(types: !319)
!319 = !{!316, !289, !312}
!320 = !DISubprogram(name: "~exception_ptr", scope: !281, file: !282, line: 129, type: !291, isLocal: false, isDefinition: false, scopeLine: 129, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!321 = !DISubprogram(name: "swap", linkageName: "_ZNSt15__exception_ptr13exception_ptr4swapERS0_", scope: !281, file: !282, line: 132, type: !322, isLocal: false, isDefinition: false, scopeLine: 132, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!322 = !DISubroutineType(types: !323)
!323 = !{null, !289, !316}
!324 = !DISubprogram(name: "operator bool", linkageName: "_ZNKSt15__exception_ptr13exception_ptrcvbEv", scope: !281, file: !282, line: 144, type: !325, isLocal: false, isDefinition: false, scopeLine: 144, flags: DIFlagPublic | DIFlagExplicit | DIFlagPrototyped, isOptimized: false)
!325 = !DISubroutineType(types: !326)
!326 = !{!327, !297}
!327 = !DIBasicType(name: "bool", size: 8, encoding: DW_ATE_boolean)
!328 = !DISubprogram(name: "__cxa_exception_type", linkageName: "_ZNKSt15__exception_ptr13exception_ptr20__cxa_exception_typeEv", scope: !281, file: !282, line: 153, type: !329, isLocal: false, isDefinition: false, scopeLine: 153, flags: DIFlagPublic | DIFlagPrototyped, isOptimized: false)
!329 = !DISubroutineType(types: !330)
!330 = !{!331, !297}
!331 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !332, size: 64)
!332 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !333)
!333 = distinct !DICompositeType(tag: DW_TAG_class_type, name: "type_info", scope: !75, file: !334, line: 88, flags: DIFlagFwdDecl, identifier: "_ZTSSt9type_info")
!334 = !DIFile(filename: "/usr/lib/gcc/x86_64-linux-gnu/7.4.0/../../../../include/c++/7.4.0/typeinfo", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!335 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !283, entity: !336, line: 73)
!336 = !DISubprogram(name: "rethrow_exception", linkageName: "_ZSt17rethrow_exceptionNSt15__exception_ptr13exception_ptrE", scope: !75, file: !282, line: 69, type: !337, isLocal: false, isDefinition: false, flags: DIFlagPrototyped | DIFlagNoReturn, isOptimized: false)
!337 = !DISubroutineType(types: !338)
!338 = !{null, !281}
!339 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !340, line: 64)
!340 = !DIDerivedType(tag: DW_TAG_typedef, name: "mbstate_t", file: !341, line: 6, baseType: !342)
!341 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/mbstate_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!342 = !DIDerivedType(tag: DW_TAG_typedef, name: "__mbstate_t", file: !343, line: 21, baseType: !344)
!343 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/__mbstate_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!344 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !343, line: 13, size: 64, elements: !345, identifier: "_ZTS11__mbstate_t")
!345 = !{!346, !347}
!346 = !DIDerivedType(tag: DW_TAG_member, name: "__count", scope: !344, file: !343, line: 15, baseType: !82, size: 32)
!347 = !DIDerivedType(tag: DW_TAG_member, name: "__value", scope: !344, file: !343, line: 20, baseType: !348, size: 32, offset: 32)
!348 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !344, file: !343, line: 16, size: 32, elements: !349, identifier: "_ZTSN11__mbstate_tUt_E")
!349 = !{!350, !351}
!350 = !DIDerivedType(tag: DW_TAG_member, name: "__wch", scope: !348, file: !343, line: 18, baseType: !10, size: 32)
!351 = !DIDerivedType(tag: DW_TAG_member, name: "__wchb", scope: !348, file: !343, line: 19, baseType: !352, size: 32)
!352 = !DICompositeType(tag: DW_TAG_array_type, baseType: !111, size: 32, elements: !353)
!353 = !{!354}
!354 = !DISubrange(count: 4)
!355 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !356, line: 139)
!356 = !DIDerivedType(tag: DW_TAG_typedef, name: "wint_t", file: !357, line: 20, baseType: !10)
!357 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/wint_t.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!358 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !359, line: 141)
!359 = !DISubprogram(name: "btowc", scope: !360, file: !360, line: 284, type: !361, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!360 = !DIFile(filename: "/usr/include/wchar.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!361 = !DISubroutineType(types: !362)
!362 = !{!356, !82}
!363 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !364, line: 142)
!364 = !DISubprogram(name: "fgetwc", scope: !360, file: !360, line: 727, type: !365, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!365 = !DISubroutineType(types: !366)
!366 = !{!356, !367}
!367 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !368, size: 64)
!368 = !DIDerivedType(tag: DW_TAG_typedef, name: "__FILE", file: !369, line: 5, baseType: !370)
!369 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/__FILE.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!370 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "_IO_FILE", file: !369, line: 4, flags: DIFlagFwdDecl, identifier: "_ZTS8_IO_FILE")
!371 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !372, line: 143)
!372 = !DISubprogram(name: "fgetws", scope: !360, file: !360, line: 756, type: !373, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!373 = !DISubroutineType(types: !374)
!374 = !{!174, !173, !82, !375}
!375 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !367)
!376 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !377, line: 144)
!377 = !DISubprogram(name: "fputwc", scope: !360, file: !360, line: 741, type: !378, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!378 = !DISubroutineType(types: !379)
!379 = !{!356, !175, !367}
!380 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !381, line: 145)
!381 = !DISubprogram(name: "fputws", scope: !360, file: !360, line: 763, type: !382, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!382 = !DISubroutineType(types: !383)
!383 = !{!82, !220, !375}
!384 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !385, line: 146)
!385 = !DISubprogram(name: "fwide", scope: !360, file: !360, line: 573, type: !386, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!386 = !DISubroutineType(types: !387)
!387 = !{!82, !367, !82}
!388 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !389, line: 147)
!389 = !DISubprogram(name: "fwprintf", scope: !360, file: !360, line: 580, type: !390, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!390 = !DISubroutineType(types: !391)
!391 = !{!82, !375, !220, null}
!392 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !393, line: 148)
!393 = !DISubprogram(name: "fwscanf", scope: !360, file: !360, line: 621, type: !390, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!394 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !395, line: 149)
!395 = !DISubprogram(name: "getwc", scope: !360, file: !360, line: 728, type: !365, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!396 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !397, line: 150)
!397 = !DISubprogram(name: "getwchar", scope: !360, file: !360, line: 734, type: !398, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!398 = !DISubroutineType(types: !399)
!399 = !{!356}
!400 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !401, line: 151)
!401 = !DISubprogram(name: "mbrlen", scope: !360, file: !360, line: 307, type: !402, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!402 = !DISubroutineType(types: !403)
!403 = !{!125, !176, !125, !404}
!404 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !405)
!405 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !340, size: 64)
!406 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !407, line: 152)
!407 = !DISubprogram(name: "mbrtowc", scope: !360, file: !360, line: 296, type: !408, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!408 = !DISubroutineType(types: !409)
!409 = !{!125, !173, !176, !125, !404}
!410 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !411, line: 153)
!411 = !DISubprogram(name: "mbsinit", scope: !360, file: !360, line: 292, type: !412, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!412 = !DISubroutineType(types: !413)
!413 = !{!82, !414}
!414 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !415, size: 64)
!415 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !340)
!416 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !417, line: 154)
!417 = !DISubprogram(name: "mbsrtowcs", scope: !360, file: !360, line: 337, type: !418, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!418 = !DISubroutineType(types: !419)
!419 = !{!125, !173, !420, !125, !404}
!420 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !421)
!421 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !109, size: 64)
!422 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !423, line: 155)
!423 = !DISubprogram(name: "putwc", scope: !360, file: !360, line: 742, type: !378, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!424 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !425, line: 156)
!425 = !DISubprogram(name: "putwchar", scope: !360, file: !360, line: 748, type: !426, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!426 = !DISubroutineType(types: !427)
!427 = !{!356, !175}
!428 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !429, line: 158)
!429 = !DISubprogram(name: "swprintf", scope: !360, file: !360, line: 590, type: !430, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!430 = !DISubroutineType(types: !431)
!431 = !{!82, !173, !125, !220, null}
!432 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !433, line: 160)
!433 = !DISubprogram(name: "swscanf", scope: !360, file: !360, line: 631, type: !434, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!434 = !DISubroutineType(types: !435)
!435 = !{!82, !220, !220, null}
!436 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !437, line: 161)
!437 = !DISubprogram(name: "ungetwc", scope: !360, file: !360, line: 771, type: !438, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!438 = !DISubroutineType(types: !439)
!439 = !{!356, !356, !367}
!440 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !441, line: 162)
!441 = !DISubprogram(name: "vfwprintf", scope: !360, file: !360, line: 598, type: !442, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!442 = !DISubroutineType(types: !443)
!443 = !{!82, !375, !220, !444}
!444 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !445, size: 64)
!445 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "__va_list_tag", file: !2, size: 192, elements: !446, identifier: "_ZTS13__va_list_tag")
!446 = !{!447, !448, !449, !450}
!447 = !DIDerivedType(tag: DW_TAG_member, name: "gp_offset", scope: !445, file: !2, baseType: !10, size: 32)
!448 = !DIDerivedType(tag: DW_TAG_member, name: "fp_offset", scope: !445, file: !2, baseType: !10, size: 32, offset: 32)
!449 = !DIDerivedType(tag: DW_TAG_member, name: "overflow_arg_area", scope: !445, file: !2, baseType: !124, size: 64, offset: 64)
!450 = !DIDerivedType(tag: DW_TAG_member, name: "reg_save_area", scope: !445, file: !2, baseType: !124, size: 64, offset: 128)
!451 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !452, line: 164)
!452 = !DISubprogram(name: "vfwscanf", scope: !360, file: !360, line: 673, type: !442, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!453 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !454, line: 167)
!454 = !DISubprogram(name: "vswprintf", scope: !360, file: !360, line: 611, type: !455, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!455 = !DISubroutineType(types: !456)
!456 = !{!82, !173, !125, !220, !444}
!457 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !458, line: 170)
!458 = !DISubprogram(name: "vswscanf", scope: !360, file: !360, line: 685, type: !459, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!459 = !DISubroutineType(types: !460)
!460 = !{!82, !220, !220, !444}
!461 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !462, line: 172)
!462 = !DISubprogram(name: "vwprintf", scope: !360, file: !360, line: 606, type: !463, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!463 = !DISubroutineType(types: !464)
!464 = !{!82, !220, !444}
!465 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !466, line: 174)
!466 = !DISubprogram(name: "vwscanf", scope: !360, file: !360, line: 681, type: !463, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!467 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !468, line: 176)
!468 = !DISubprogram(name: "wcrtomb", scope: !360, file: !360, line: 301, type: !469, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!469 = !DISubroutineType(types: !470)
!470 = !{!125, !219, !175, !404}
!471 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !472, line: 177)
!472 = !DISubprogram(name: "wcscat", scope: !360, file: !360, line: 97, type: !473, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!473 = !DISubroutineType(types: !474)
!474 = !{!174, !173, !220}
!475 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !476, line: 178)
!476 = !DISubprogram(name: "wcscmp", scope: !360, file: !360, line: 106, type: !477, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!477 = !DISubroutineType(types: !478)
!478 = !{!82, !221, !221}
!479 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !480, line: 179)
!480 = !DISubprogram(name: "wcscoll", scope: !360, file: !360, line: 131, type: !477, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!481 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !482, line: 180)
!482 = !DISubprogram(name: "wcscpy", scope: !360, file: !360, line: 87, type: !473, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!483 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !484, line: 181)
!484 = !DISubprogram(name: "wcscspn", scope: !360, file: !360, line: 187, type: !485, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!485 = !DISubroutineType(types: !486)
!486 = !{!125, !221, !221}
!487 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !488, line: 182)
!488 = !DISubprogram(name: "wcsftime", scope: !360, file: !360, line: 835, type: !489, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!489 = !DISubroutineType(types: !490)
!490 = !{!125, !173, !125, !220, !491}
!491 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !492)
!492 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !493, size: 64)
!493 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !494)
!494 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "tm", file: !360, line: 83, flags: DIFlagFwdDecl, identifier: "_ZTS2tm")
!495 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !496, line: 183)
!496 = !DISubprogram(name: "wcslen", scope: !360, file: !360, line: 222, type: !497, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!497 = !DISubroutineType(types: !498)
!498 = !{!125, !221}
!499 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !500, line: 184)
!500 = !DISubprogram(name: "wcsncat", scope: !360, file: !360, line: 101, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!501 = !DISubroutineType(types: !502)
!502 = !{!174, !173, !220, !125}
!503 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !504, line: 185)
!504 = !DISubprogram(name: "wcsncmp", scope: !360, file: !360, line: 109, type: !505, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!505 = !DISubroutineType(types: !506)
!506 = !{!82, !221, !221, !125}
!507 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !508, line: 186)
!508 = !DISubprogram(name: "wcsncpy", scope: !360, file: !360, line: 92, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!509 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !510, line: 187)
!510 = !DISubprogram(name: "wcsrtombs", scope: !360, file: !360, line: 343, type: !511, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!511 = !DISubroutineType(types: !512)
!512 = !{!125, !219, !513, !125, !404}
!513 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !514)
!514 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !221, size: 64)
!515 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !516, line: 188)
!516 = !DISubprogram(name: "wcsspn", scope: !360, file: !360, line: 191, type: !485, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!517 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !518, line: 189)
!518 = !DISubprogram(name: "wcstod", scope: !360, file: !360, line: 377, type: !519, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!519 = !DISubroutineType(types: !520)
!520 = !{!108, !220, !521}
!521 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !522)
!522 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !174, size: 64)
!523 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !524, line: 191)
!524 = !DISubprogram(name: "wcstof", scope: !360, file: !360, line: 382, type: !525, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!525 = !DISubroutineType(types: !526)
!526 = !{!262, !220, !521}
!527 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !528, line: 193)
!528 = !DISubprogram(name: "wcstok", scope: !360, file: !360, line: 217, type: !529, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!529 = !DISubroutineType(types: !530)
!530 = !{!174, !173, !220, !521}
!531 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !532, line: 194)
!532 = !DISubprogram(name: "wcstol", scope: !360, file: !360, line: 428, type: !533, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!533 = !DISubroutineType(types: !534)
!534 = !{!91, !220, !521, !82}
!535 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !536, line: 195)
!536 = !DISubprogram(name: "wcstoul", scope: !360, file: !360, line: 433, type: !537, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!537 = !DISubroutineType(types: !538)
!538 = !{!127, !220, !521, !82}
!539 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !540, line: 196)
!540 = !DISubprogram(name: "wcsxfrm", scope: !360, file: !360, line: 135, type: !541, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!541 = !DISubroutineType(types: !542)
!542 = !{!125, !173, !220, !125}
!543 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !544, line: 197)
!544 = !DISubprogram(name: "wctob", scope: !360, file: !360, line: 288, type: !545, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!545 = !DISubroutineType(types: !546)
!546 = !{!82, !356}
!547 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !548, line: 198)
!548 = !DISubprogram(name: "wmemcmp", scope: !360, file: !360, line: 258, type: !505, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!549 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !550, line: 199)
!550 = !DISubprogram(name: "wmemcpy", scope: !360, file: !360, line: 262, type: !501, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!551 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !552, line: 200)
!552 = !DISubprogram(name: "wmemmove", scope: !360, file: !360, line: 267, type: !553, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!553 = !DISubroutineType(types: !554)
!554 = !{!174, !174, !221, !125}
!555 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !556, line: 201)
!556 = !DISubprogram(name: "wmemset", scope: !360, file: !360, line: 271, type: !557, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!557 = !DISubroutineType(types: !558)
!558 = !{!174, !174, !175, !125}
!559 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !560, line: 202)
!560 = !DISubprogram(name: "wprintf", scope: !360, file: !360, line: 587, type: !561, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!561 = !DISubroutineType(types: !562)
!562 = !{!82, !220, null}
!563 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !564, line: 203)
!564 = !DISubprogram(name: "wscanf", scope: !360, file: !360, line: 628, type: !561, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!565 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !566, line: 204)
!566 = !DISubprogram(name: "wcschr", scope: !360, file: !360, line: 164, type: !567, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!567 = !DISubroutineType(types: !568)
!568 = !{!174, !221, !175}
!569 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !570, line: 205)
!570 = !DISubprogram(name: "wcspbrk", scope: !360, file: !360, line: 201, type: !571, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!571 = !DISubroutineType(types: !572)
!572 = !{!174, !221, !221}
!573 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !574, line: 206)
!574 = !DISubprogram(name: "wcsrchr", scope: !360, file: !360, line: 174, type: !567, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!575 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !576, line: 207)
!576 = !DISubprogram(name: "wcsstr", scope: !360, file: !360, line: 212, type: !571, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!577 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !578, line: 208)
!578 = !DISubprogram(name: "wmemchr", scope: !360, file: !360, line: 253, type: !579, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!579 = !DISubroutineType(types: !580)
!580 = !{!174, !221, !175, !125}
!581 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !582, line: 248)
!582 = !DISubprogram(name: "wcstold", scope: !360, file: !360, line: 384, type: !583, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!583 = !DISubroutineType(types: !584)
!584 = !{!267, !220, !521}
!585 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !586, line: 257)
!586 = !DISubprogram(name: "wcstoll", scope: !360, file: !360, line: 441, type: !587, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!587 = !DISubroutineType(types: !588)
!588 = !{!233, !220, !521, !82}
!589 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !590, line: 258)
!590 = !DISubprogram(name: "wcstoull", scope: !360, file: !360, line: 448, type: !591, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!591 = !DISubroutineType(types: !592)
!592 = !{!257, !220, !521, !82}
!593 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !582, line: 264)
!594 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !586, line: 265)
!595 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !590, line: 266)
!596 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !524, line: 280)
!597 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !452, line: 283)
!598 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !458, line: 286)
!599 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !466, line: 289)
!600 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !582, line: 293)
!601 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !586, line: 294)
!602 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !590, line: 295)
!603 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !604, line: 48)
!604 = !DIDerivedType(tag: DW_TAG_typedef, name: "int8_t", file: !9, line: 235, baseType: !605)
!605 = !DIBasicType(name: "signed char", size: 8, encoding: DW_ATE_signed_char)
!606 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !607, line: 49)
!607 = !DIDerivedType(tag: DW_TAG_typedef, name: "int16_t", file: !9, line: 216, baseType: !608)
!608 = !DIBasicType(name: "short", size: 16, encoding: DW_ATE_signed)
!609 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !610, line: 50)
!610 = !DIDerivedType(tag: DW_TAG_typedef, name: "int32_t", file: !9, line: 178, baseType: !82)
!611 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !612, line: 51)
!612 = !DIDerivedType(tag: DW_TAG_typedef, name: "int64_t", file: !9, line: 107, baseType: !91)
!613 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !614, line: 53)
!614 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast8_t", file: !9, line: 245, baseType: !604)
!615 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !616, line: 54)
!616 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast16_t", file: !9, line: 228, baseType: !607)
!617 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !618, line: 55)
!618 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast32_t", file: !9, line: 197, baseType: !610)
!619 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !620, line: 56)
!620 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_fast64_t", file: !9, line: 123, baseType: !612)
!621 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !622, line: 58)
!622 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least8_t", file: !9, line: 243, baseType: !604)
!623 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !624, line: 59)
!624 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least16_t", file: !9, line: 226, baseType: !607)
!625 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !626, line: 60)
!626 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least32_t", file: !9, line: 195, baseType: !610)
!627 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !628, line: 61)
!628 = !DIDerivedType(tag: DW_TAG_typedef, name: "int_least64_t", file: !9, line: 121, baseType: !612)
!629 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !630, line: 63)
!630 = !DIDerivedType(tag: DW_TAG_typedef, name: "intmax_t", file: !9, line: 276, baseType: !91)
!631 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !632, line: 64)
!632 = !DIDerivedType(tag: DW_TAG_typedef, name: "intptr_t", file: !9, line: 263, baseType: !612)
!633 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !62, line: 66)
!634 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !28, line: 67)
!635 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !8, line: 68)
!636 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !637, line: 69)
!637 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint64_t", file: !9, line: 109, baseType: !127)
!638 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !639, line: 71)
!639 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast8_t", file: !9, line: 246, baseType: !62)
!640 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !641, line: 72)
!641 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast16_t", file: !9, line: 229, baseType: !28)
!642 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !643, line: 73)
!643 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast32_t", file: !9, line: 198, baseType: !8)
!644 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !645, line: 74)
!645 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_fast64_t", file: !9, line: 124, baseType: !637)
!646 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !647, line: 76)
!647 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least8_t", file: !9, line: 244, baseType: !62)
!648 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !649, line: 77)
!649 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least16_t", file: !9, line: 227, baseType: !28)
!650 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !651, line: 78)
!651 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least32_t", file: !9, line: 196, baseType: !8)
!652 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !653, line: 79)
!653 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint_least64_t", file: !9, line: 122, baseType: !637)
!654 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !655, line: 81)
!655 = !DIDerivedType(tag: DW_TAG_typedef, name: "uintmax_t", file: !9, line: 277, baseType: !127)
!656 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !657, line: 82)
!657 = !DIDerivedType(tag: DW_TAG_typedef, name: "uintptr_t", file: !9, line: 270, baseType: !637)
!658 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !659, line: 44)
!659 = !DIDerivedType(tag: DW_TAG_typedef, name: "size_t", scope: !75, file: !76, line: 231, baseType: !127)
!660 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !661, line: 45)
!661 = !DIDerivedType(tag: DW_TAG_typedef, name: "ptrdiff_t", scope: !75, file: !76, line: 232, baseType: !91)
!662 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !663, line: 53)
!663 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "lconv", file: !664, line: 51, flags: DIFlagFwdDecl, identifier: "_ZTS5lconv")
!664 = !DIFile(filename: "/usr/include/locale.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!665 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !666, line: 54)
!666 = !DISubprogram(name: "setlocale", scope: !664, file: !664, line: 122, type: !667, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!667 = !DISubroutineType(types: !668)
!668 = !{!152, !82, !109}
!669 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !670, line: 55)
!670 = !DISubprogram(name: "localeconv", scope: !664, file: !664, line: 125, type: !671, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!671 = !DISubroutineType(types: !672)
!672 = !{!673}
!673 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !663, size: 64)
!674 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !675, line: 64)
!675 = !DISubprogram(name: "isalnum", scope: !676, file: !676, line: 108, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!676 = !DIFile(filename: "/usr/include/ctype.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!677 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !678, line: 65)
!678 = !DISubprogram(name: "isalpha", scope: !676, file: !676, line: 109, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!679 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !680, line: 66)
!680 = !DISubprogram(name: "iscntrl", scope: !676, file: !676, line: 110, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!681 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !682, line: 67)
!682 = !DISubprogram(name: "isdigit", scope: !676, file: !676, line: 111, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!683 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !684, line: 68)
!684 = !DISubprogram(name: "isgraph", scope: !676, file: !676, line: 113, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!685 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !686, line: 69)
!686 = !DISubprogram(name: "islower", scope: !676, file: !676, line: 112, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!687 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !688, line: 70)
!688 = !DISubprogram(name: "isprint", scope: !676, file: !676, line: 114, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!689 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !690, line: 71)
!690 = !DISubprogram(name: "ispunct", scope: !676, file: !676, line: 115, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!691 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !692, line: 72)
!692 = !DISubprogram(name: "isspace", scope: !676, file: !676, line: 116, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!693 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !694, line: 73)
!694 = !DISubprogram(name: "isupper", scope: !676, file: !676, line: 117, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!695 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !696, line: 74)
!696 = !DISubprogram(name: "isxdigit", scope: !676, file: !676, line: 118, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!697 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !698, line: 75)
!698 = !DISubprogram(name: "tolower", scope: !676, file: !676, line: 122, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!699 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !700, line: 76)
!700 = !DISubprogram(name: "toupper", scope: !676, file: !676, line: 125, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!701 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !702, line: 87)
!702 = !DISubprogram(name: "isblank", scope: !676, file: !676, line: 130, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!703 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !704, line: 98)
!704 = !DIDerivedType(tag: DW_TAG_typedef, name: "FILE", file: !705, line: 7, baseType: !370)
!705 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/types/FILE.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!706 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !707, line: 99)
!707 = !DIDerivedType(tag: DW_TAG_typedef, name: "fpos_t", file: !708, line: 78, baseType: !709)
!708 = !DIFile(filename: "/usr/include/stdio.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!709 = !DIDerivedType(tag: DW_TAG_typedef, name: "_G_fpos_t", file: !710, line: 30, baseType: !711)
!710 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/_G_config.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!711 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !710, line: 26, flags: DIFlagFwdDecl, identifier: "_ZTS9_G_fpos_t")
!712 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !713, line: 101)
!713 = !DISubprogram(name: "clearerr", scope: !708, file: !708, line: 757, type: !714, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!714 = !DISubroutineType(types: !715)
!715 = !{null, !716}
!716 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !704, size: 64)
!717 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !718, line: 102)
!718 = !DISubprogram(name: "fclose", scope: !708, file: !708, line: 199, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!719 = !DISubroutineType(types: !720)
!720 = !{!82, !716}
!721 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !722, line: 103)
!722 = !DISubprogram(name: "feof", scope: !708, file: !708, line: 759, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!723 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !724, line: 104)
!724 = !DISubprogram(name: "ferror", scope: !708, file: !708, line: 761, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!725 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !726, line: 105)
!726 = !DISubprogram(name: "fflush", scope: !708, file: !708, line: 204, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!727 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !728, line: 106)
!728 = !DISubprogram(name: "fgetc", scope: !708, file: !708, line: 477, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!729 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !730, line: 107)
!730 = !DISubprogram(name: "fgetpos", scope: !708, file: !708, line: 731, type: !731, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!731 = !DISubroutineType(types: !732)
!732 = !{!82, !733, !734}
!733 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !716)
!734 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !735)
!735 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !707, size: 64)
!736 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !737, line: 108)
!737 = !DISubprogram(name: "fgets", scope: !708, file: !708, line: 564, type: !738, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!738 = !DISubroutineType(types: !739)
!739 = !{!152, !219, !82, !733}
!740 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !741, line: 109)
!741 = !DISubprogram(name: "fopen", scope: !708, file: !708, line: 232, type: !742, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!742 = !DISubroutineType(types: !743)
!743 = !{!716, !176, !176}
!744 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !745, line: 110)
!745 = !DISubprogram(name: "fprintf", scope: !708, file: !708, line: 312, type: !746, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!746 = !DISubroutineType(types: !747)
!747 = !{!82, !733, !176, null}
!748 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !749, line: 111)
!749 = !DISubprogram(name: "fputc", scope: !708, file: !708, line: 517, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!750 = !DISubroutineType(types: !751)
!751 = !{!82, !82, !716}
!752 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !753, line: 112)
!753 = !DISubprogram(name: "fputs", scope: !708, file: !708, line: 626, type: !754, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!754 = !DISubroutineType(types: !755)
!755 = !{!82, !176, !733}
!756 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !757, line: 113)
!757 = !DISubprogram(name: "fread", scope: !708, file: !708, line: 646, type: !758, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!758 = !DISubroutineType(types: !759)
!759 = !{!125, !760, !125, !125, !733}
!760 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !124)
!761 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !762, line: 114)
!762 = !DISubprogram(name: "freopen", scope: !708, file: !708, line: 238, type: !763, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!763 = !DISubroutineType(types: !764)
!764 = !{!716, !176, !176, !733}
!765 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !766, line: 115)
!766 = !DISubprogram(name: "fscanf", scope: !708, file: !708, line: 377, type: !746, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!767 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !768, line: 116)
!768 = !DISubprogram(name: "fseek", scope: !708, file: !708, line: 684, type: !769, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!769 = !DISubroutineType(types: !770)
!770 = !{!82, !716, !91, !82}
!771 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !772, line: 117)
!772 = !DISubprogram(name: "fsetpos", scope: !708, file: !708, line: 736, type: !773, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!773 = !DISubroutineType(types: !774)
!774 = !{!82, !716, !775}
!775 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !776, size: 64)
!776 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !707)
!777 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !778, line: 118)
!778 = !DISubprogram(name: "ftell", scope: !708, file: !708, line: 689, type: !779, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!779 = !DISubroutineType(types: !780)
!780 = !{!91, !716}
!781 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !782, line: 119)
!782 = !DISubprogram(name: "fwrite", scope: !708, file: !708, line: 652, type: !783, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!783 = !DISubroutineType(types: !784)
!784 = !{!125, !785, !125, !125, !733}
!785 = !DIDerivedType(tag: DW_TAG_restrict_type, baseType: !68)
!786 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !787, line: 120)
!787 = !DISubprogram(name: "getc", scope: !708, file: !708, line: 478, type: !719, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!788 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !789, line: 121)
!789 = !DISubprogram(name: "getchar", scope: !708, file: !708, line: 484, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!790 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !791, line: 124)
!791 = !DISubprogram(name: "gets", scope: !708, file: !708, line: 577, type: !792, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!792 = !DISubroutineType(types: !793)
!793 = !{!152, !152}
!794 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !795, line: 126)
!795 = !DISubprogram(name: "perror", scope: !708, file: !708, line: 775, type: !796, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!796 = !DISubroutineType(types: !797)
!797 = !{null, !109}
!798 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !799, line: 127)
!799 = !DISubprogram(name: "printf", scope: !708, file: !708, line: 318, type: !800, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!800 = !DISubroutineType(types: !801)
!801 = !{!82, !176, null}
!802 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !803, line: 128)
!803 = !DISubprogram(name: "putc", scope: !708, file: !708, line: 518, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!804 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !805, line: 129)
!805 = !DISubprogram(name: "putchar", scope: !708, file: !708, line: 524, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!806 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !807, line: 130)
!807 = !DISubprogram(name: "puts", scope: !708, file: !708, line: 632, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!808 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !809, line: 131)
!809 = !DISubprogram(name: "remove", scope: !708, file: !708, line: 144, type: !114, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!810 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !811, line: 132)
!811 = !DISubprogram(name: "rename", scope: !708, file: !708, line: 146, type: !812, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!812 = !DISubroutineType(types: !813)
!813 = !{!82, !109, !109}
!814 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !815, line: 133)
!815 = !DISubprogram(name: "rewind", scope: !708, file: !708, line: 694, type: !714, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!816 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !817, line: 134)
!817 = !DISubprogram(name: "scanf", scope: !708, file: !708, line: 383, type: !800, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!818 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !819, line: 135)
!819 = !DISubprogram(name: "setbuf", scope: !708, file: !708, line: 290, type: !820, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!820 = !DISubroutineType(types: !821)
!821 = !{null, !733, !219}
!822 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !823, line: 136)
!823 = !DISubprogram(name: "setvbuf", scope: !708, file: !708, line: 294, type: !824, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!824 = !DISubroutineType(types: !825)
!825 = !{!82, !733, !219, !82, !125}
!826 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !827, line: 137)
!827 = !DISubprogram(name: "sprintf", scope: !708, file: !708, line: 320, type: !828, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!828 = !DISubroutineType(types: !829)
!829 = !{!82, !219, !176, null}
!830 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !831, line: 138)
!831 = !DISubprogram(name: "sscanf", scope: !708, file: !708, line: 385, type: !832, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!832 = !DISubroutineType(types: !833)
!833 = !{!82, !176, !176, null}
!834 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !835, line: 139)
!835 = !DISubprogram(name: "tmpfile", scope: !708, file: !708, line: 159, type: !836, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!836 = !DISubroutineType(types: !837)
!837 = !{!716}
!838 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !839, line: 141)
!839 = !DISubprogram(name: "tmpnam", scope: !708, file: !708, line: 173, type: !792, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!840 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !841, line: 143)
!841 = !DISubprogram(name: "ungetc", scope: !708, file: !708, line: 639, type: !750, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!842 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !843, line: 144)
!843 = !DISubprogram(name: "vfprintf", scope: !708, file: !708, line: 327, type: !844, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!844 = !DISubroutineType(types: !845)
!845 = !{!82, !733, !176, !444}
!846 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !847, line: 145)
!847 = !DISubprogram(name: "vprintf", scope: !708, file: !708, line: 333, type: !848, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!848 = !DISubroutineType(types: !849)
!849 = !{!82, !176, !444}
!850 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !851, line: 146)
!851 = !DISubprogram(name: "vsprintf", scope: !708, file: !708, line: 335, type: !852, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!852 = !DISubroutineType(types: !853)
!853 = !{!82, !219, !176, !444}
!854 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !855, line: 175)
!855 = !DISubprogram(name: "snprintf", scope: !708, file: !708, line: 340, type: !856, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!856 = !DISubroutineType(types: !857)
!857 = !{!82, !219, !125, !176, null}
!858 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !859, line: 176)
!859 = !DISubprogram(name: "vfscanf", scope: !708, file: !708, line: 420, type: !844, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!860 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !861, line: 177)
!861 = !DISubprogram(name: "vscanf", scope: !708, file: !708, line: 428, type: !848, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!862 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !863, line: 178)
!863 = !DISubprogram(name: "vsnprintf", scope: !708, file: !708, line: 344, type: !864, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!864 = !DISubroutineType(types: !865)
!865 = !{!82, !219, !125, !176, !444}
!866 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !228, entity: !867, line: 179)
!867 = !DISubprogram(name: "vsscanf", scope: !708, file: !708, line: 432, type: !868, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!868 = !DISubroutineType(types: !869)
!869 = !{!82, !176, !176, !444}
!870 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !855, line: 185)
!871 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !859, line: 186)
!872 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !861, line: 187)
!873 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !863, line: 188)
!874 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !867, line: 189)
!875 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !876, line: 83)
!876 = !DISubprogram(name: "acos", scope: !877, file: !877, line: 53, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!877 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/mathcalls.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!878 = !DISubroutineType(types: !879)
!879 = !{!108, !108}
!880 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !881, line: 102)
!881 = !DISubprogram(name: "asin", scope: !877, file: !877, line: 55, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!882 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !883, line: 121)
!883 = !DISubprogram(name: "atan", scope: !877, file: !877, line: 57, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!884 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !885, line: 140)
!885 = !DISubprogram(name: "atan2", scope: !877, file: !877, line: 59, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!886 = !DISubroutineType(types: !887)
!887 = !{!108, !108, !108}
!888 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !889, line: 161)
!889 = !DISubprogram(name: "ceil", scope: !877, file: !877, line: 159, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!890 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !891, line: 180)
!891 = !DISubprogram(name: "cos", scope: !877, file: !877, line: 62, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!892 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !893, line: 199)
!893 = !DISubprogram(name: "cosh", scope: !877, file: !877, line: 71, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!894 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !895, line: 218)
!895 = !DISubprogram(name: "exp", scope: !877, file: !877, line: 95, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!896 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !897, line: 237)
!897 = !DISubprogram(name: "fabs", scope: !877, file: !877, line: 162, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!898 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !899, line: 256)
!899 = !DISubprogram(name: "floor", scope: !877, file: !877, line: 165, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!900 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !901, line: 275)
!901 = !DISubprogram(name: "fmod", scope: !877, file: !877, line: 168, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!902 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !903, line: 296)
!903 = !DISubprogram(name: "frexp", scope: !877, file: !877, line: 98, type: !904, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!904 = !DISubroutineType(types: !905)
!905 = !{!108, !108, !906}
!906 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !82, size: 64)
!907 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !908, line: 315)
!908 = !DISubprogram(name: "ldexp", scope: !877, file: !877, line: 101, type: !909, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!909 = !DISubroutineType(types: !910)
!910 = !{!108, !108, !82}
!911 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !912, line: 334)
!912 = !DISubprogram(name: "log", scope: !877, file: !877, line: 104, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!913 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !914, line: 353)
!914 = !DISubprogram(name: "log10", scope: !877, file: !877, line: 107, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!915 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !916, line: 372)
!916 = !DISubprogram(name: "modf", scope: !877, file: !877, line: 110, type: !917, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!917 = !DISubroutineType(types: !918)
!918 = !{!108, !108, !919}
!919 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !108, size: 64)
!920 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !921, line: 384)
!921 = !DISubprogram(name: "pow", scope: !877, file: !877, line: 140, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!922 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !923, line: 421)
!923 = !DISubprogram(name: "sin", scope: !877, file: !877, line: 64, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!924 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !925, line: 440)
!925 = !DISubprogram(name: "sinh", scope: !877, file: !877, line: 73, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!926 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !927, line: 459)
!927 = !DISubprogram(name: "sqrt", scope: !877, file: !877, line: 143, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!928 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !929, line: 478)
!929 = !DISubprogram(name: "tan", scope: !877, file: !877, line: 66, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!930 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !931, line: 497)
!931 = !DISubprogram(name: "tanh", scope: !877, file: !877, line: 75, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!932 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !933, line: 1080)
!933 = !DIDerivedType(tag: DW_TAG_typedef, name: "double_t", file: !934, line: 150, baseType: !108)
!934 = !DIFile(filename: "/usr/include/math.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!935 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !936, line: 1081)
!936 = !DIDerivedType(tag: DW_TAG_typedef, name: "float_t", file: !934, line: 149, baseType: !262)
!937 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !938, line: 1084)
!938 = !DISubprogram(name: "acosh", scope: !877, file: !877, line: 85, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!939 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !940, line: 1085)
!940 = !DISubprogram(name: "acoshf", scope: !877, file: !877, line: 85, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!941 = !DISubroutineType(types: !942)
!942 = !{!262, !262}
!943 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !944, line: 1086)
!944 = !DISubprogram(name: "acoshl", scope: !877, file: !877, line: 85, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!945 = !DISubroutineType(types: !946)
!946 = !{!267, !267}
!947 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !948, line: 1088)
!948 = !DISubprogram(name: "asinh", scope: !877, file: !877, line: 87, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!949 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !950, line: 1089)
!950 = !DISubprogram(name: "asinhf", scope: !877, file: !877, line: 87, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!951 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !952, line: 1090)
!952 = !DISubprogram(name: "asinhl", scope: !877, file: !877, line: 87, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!953 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !954, line: 1092)
!954 = !DISubprogram(name: "atanh", scope: !877, file: !877, line: 89, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!955 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !956, line: 1093)
!956 = !DISubprogram(name: "atanhf", scope: !877, file: !877, line: 89, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!957 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !958, line: 1094)
!958 = !DISubprogram(name: "atanhl", scope: !877, file: !877, line: 89, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!959 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !960, line: 1096)
!960 = !DISubprogram(name: "cbrt", scope: !877, file: !877, line: 152, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!961 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !962, line: 1097)
!962 = !DISubprogram(name: "cbrtf", scope: !877, file: !877, line: 152, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!963 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !964, line: 1098)
!964 = !DISubprogram(name: "cbrtl", scope: !877, file: !877, line: 152, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!965 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !966, line: 1100)
!966 = !DISubprogram(name: "copysign", scope: !877, file: !877, line: 196, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!967 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !968, line: 1101)
!968 = !DISubprogram(name: "copysignf", scope: !877, file: !877, line: 196, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!969 = !DISubroutineType(types: !970)
!970 = !{!262, !262, !262}
!971 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !972, line: 1102)
!972 = !DISubprogram(name: "copysignl", scope: !877, file: !877, line: 196, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!973 = !DISubroutineType(types: !974)
!974 = !{!267, !267, !267}
!975 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !976, line: 1104)
!976 = !DISubprogram(name: "erf", scope: !877, file: !877, line: 228, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!977 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !978, line: 1105)
!978 = !DISubprogram(name: "erff", scope: !877, file: !877, line: 228, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!979 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !980, line: 1106)
!980 = !DISubprogram(name: "erfl", scope: !877, file: !877, line: 228, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!981 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !982, line: 1108)
!982 = !DISubprogram(name: "erfc", scope: !877, file: !877, line: 229, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!983 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !984, line: 1109)
!984 = !DISubprogram(name: "erfcf", scope: !877, file: !877, line: 229, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!985 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !986, line: 1110)
!986 = !DISubprogram(name: "erfcl", scope: !877, file: !877, line: 229, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!987 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !988, line: 1112)
!988 = !DISubprogram(name: "exp2", scope: !877, file: !877, line: 130, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!989 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !990, line: 1113)
!990 = !DISubprogram(name: "exp2f", scope: !877, file: !877, line: 130, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!991 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !992, line: 1114)
!992 = !DISubprogram(name: "exp2l", scope: !877, file: !877, line: 130, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!993 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !994, line: 1116)
!994 = !DISubprogram(name: "expm1", scope: !877, file: !877, line: 119, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!995 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !996, line: 1117)
!996 = !DISubprogram(name: "expm1f", scope: !877, file: !877, line: 119, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!997 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !998, line: 1118)
!998 = !DISubprogram(name: "expm1l", scope: !877, file: !877, line: 119, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!999 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1000, line: 1120)
!1000 = !DISubprogram(name: "fdim", scope: !877, file: !877, line: 326, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1001 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1002, line: 1121)
!1002 = !DISubprogram(name: "fdimf", scope: !877, file: !877, line: 326, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1003 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1004, line: 1122)
!1004 = !DISubprogram(name: "fdiml", scope: !877, file: !877, line: 326, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1005 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1006, line: 1124)
!1006 = !DISubprogram(name: "fma", scope: !877, file: !877, line: 335, type: !1007, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1007 = !DISubroutineType(types: !1008)
!1008 = !{!108, !108, !108, !108}
!1009 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1010, line: 1125)
!1010 = !DISubprogram(name: "fmaf", scope: !877, file: !877, line: 335, type: !1011, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1011 = !DISubroutineType(types: !1012)
!1012 = !{!262, !262, !262, !262}
!1013 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1014, line: 1126)
!1014 = !DISubprogram(name: "fmal", scope: !877, file: !877, line: 335, type: !1015, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1015 = !DISubroutineType(types: !1016)
!1016 = !{!267, !267, !267, !267}
!1017 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1018, line: 1128)
!1018 = !DISubprogram(name: "fmax", scope: !877, file: !877, line: 329, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1019 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1020, line: 1129)
!1020 = !DISubprogram(name: "fmaxf", scope: !877, file: !877, line: 329, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1021 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1022, line: 1130)
!1022 = !DISubprogram(name: "fmaxl", scope: !877, file: !877, line: 329, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1023 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1024, line: 1132)
!1024 = !DISubprogram(name: "fmin", scope: !877, file: !877, line: 332, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1025 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1026, line: 1133)
!1026 = !DISubprogram(name: "fminf", scope: !877, file: !877, line: 332, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1027 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1028, line: 1134)
!1028 = !DISubprogram(name: "fminl", scope: !877, file: !877, line: 332, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1029 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1030, line: 1136)
!1030 = !DISubprogram(name: "hypot", scope: !877, file: !877, line: 147, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1031 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1032, line: 1137)
!1032 = !DISubprogram(name: "hypotf", scope: !877, file: !877, line: 147, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1033 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1034, line: 1138)
!1034 = !DISubprogram(name: "hypotl", scope: !877, file: !877, line: 147, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1035 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1036, line: 1140)
!1036 = !DISubprogram(name: "ilogb", scope: !877, file: !877, line: 280, type: !1037, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1037 = !DISubroutineType(types: !1038)
!1038 = !{!82, !108}
!1039 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1040, line: 1141)
!1040 = !DISubprogram(name: "ilogbf", scope: !877, file: !877, line: 280, type: !1041, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1041 = !DISubroutineType(types: !1042)
!1042 = !{!82, !262}
!1043 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1044, line: 1142)
!1044 = !DISubprogram(name: "ilogbl", scope: !877, file: !877, line: 280, type: !1045, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1045 = !DISubroutineType(types: !1046)
!1046 = !{!82, !267}
!1047 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1048, line: 1144)
!1048 = !DISubprogram(name: "lgamma", scope: !877, file: !877, line: 230, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1049 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1050, line: 1145)
!1050 = !DISubprogram(name: "lgammaf", scope: !877, file: !877, line: 230, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1051 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1052, line: 1146)
!1052 = !DISubprogram(name: "lgammal", scope: !877, file: !877, line: 230, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1053 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1054, line: 1149)
!1054 = !DISubprogram(name: "llrint", scope: !877, file: !877, line: 316, type: !1055, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1055 = !DISubroutineType(types: !1056)
!1056 = !{!233, !108}
!1057 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1058, line: 1150)
!1058 = !DISubprogram(name: "llrintf", scope: !877, file: !877, line: 316, type: !1059, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1059 = !DISubroutineType(types: !1060)
!1060 = !{!233, !262}
!1061 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1062, line: 1151)
!1062 = !DISubprogram(name: "llrintl", scope: !877, file: !877, line: 316, type: !1063, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1063 = !DISubroutineType(types: !1064)
!1064 = !{!233, !267}
!1065 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1066, line: 1153)
!1066 = !DISubprogram(name: "llround", scope: !877, file: !877, line: 322, type: !1055, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1067 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1068, line: 1154)
!1068 = !DISubprogram(name: "llroundf", scope: !877, file: !877, line: 322, type: !1059, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1069 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1070, line: 1155)
!1070 = !DISubprogram(name: "llroundl", scope: !877, file: !877, line: 322, type: !1063, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1071 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1072, line: 1158)
!1072 = !DISubprogram(name: "log1p", scope: !877, file: !877, line: 122, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1073 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1074, line: 1159)
!1074 = !DISubprogram(name: "log1pf", scope: !877, file: !877, line: 122, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1075 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1076, line: 1160)
!1076 = !DISubprogram(name: "log1pl", scope: !877, file: !877, line: 122, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1077 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1078, line: 1162)
!1078 = !DISubprogram(name: "log2", scope: !877, file: !877, line: 133, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1079 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1080, line: 1163)
!1080 = !DISubprogram(name: "log2f", scope: !877, file: !877, line: 133, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1081 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1082, line: 1164)
!1082 = !DISubprogram(name: "log2l", scope: !877, file: !877, line: 133, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1083 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1084, line: 1166)
!1084 = !DISubprogram(name: "logb", scope: !877, file: !877, line: 125, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1085 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1086, line: 1167)
!1086 = !DISubprogram(name: "logbf", scope: !877, file: !877, line: 125, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1087 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1088, line: 1168)
!1088 = !DISubprogram(name: "logbl", scope: !877, file: !877, line: 125, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1089 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1090, line: 1170)
!1090 = !DISubprogram(name: "lrint", scope: !877, file: !877, line: 314, type: !1091, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1091 = !DISubroutineType(types: !1092)
!1092 = !{!91, !108}
!1093 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1094, line: 1171)
!1094 = !DISubprogram(name: "lrintf", scope: !877, file: !877, line: 314, type: !1095, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1095 = !DISubroutineType(types: !1096)
!1096 = !{!91, !262}
!1097 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1098, line: 1172)
!1098 = !DISubprogram(name: "lrintl", scope: !877, file: !877, line: 314, type: !1099, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1099 = !DISubroutineType(types: !1100)
!1100 = !{!91, !267}
!1101 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1102, line: 1174)
!1102 = !DISubprogram(name: "lround", scope: !877, file: !877, line: 320, type: !1091, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1103 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1104, line: 1175)
!1104 = !DISubprogram(name: "lroundf", scope: !877, file: !877, line: 320, type: !1095, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1105 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1106, line: 1176)
!1106 = !DISubprogram(name: "lroundl", scope: !877, file: !877, line: 320, type: !1099, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1107 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1108, line: 1178)
!1108 = !DISubprogram(name: "nan", scope: !877, file: !877, line: 201, type: !106, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1109 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1110, line: 1179)
!1110 = !DISubprogram(name: "nanf", scope: !877, file: !877, line: 201, type: !1111, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1111 = !DISubroutineType(types: !1112)
!1112 = !{!262, !109}
!1113 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1114, line: 1180)
!1114 = !DISubprogram(name: "nanl", scope: !877, file: !877, line: 201, type: !1115, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1115 = !DISubroutineType(types: !1116)
!1116 = !{!267, !109}
!1117 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1118, line: 1182)
!1118 = !DISubprogram(name: "nearbyint", scope: !877, file: !877, line: 294, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1119 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1120, line: 1183)
!1120 = !DISubprogram(name: "nearbyintf", scope: !877, file: !877, line: 294, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1121 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1122, line: 1184)
!1122 = !DISubprogram(name: "nearbyintl", scope: !877, file: !877, line: 294, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1123 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1124, line: 1186)
!1124 = !DISubprogram(name: "nextafter", scope: !877, file: !877, line: 259, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1125 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1126, line: 1187)
!1126 = !DISubprogram(name: "nextafterf", scope: !877, file: !877, line: 259, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1127 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1128, line: 1188)
!1128 = !DISubprogram(name: "nextafterl", scope: !877, file: !877, line: 259, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1129 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1130, line: 1190)
!1130 = !DISubprogram(name: "nexttoward", scope: !877, file: !877, line: 261, type: !1131, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1131 = !DISubroutineType(types: !1132)
!1132 = !{!108, !108, !267}
!1133 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1134, line: 1191)
!1134 = !DISubprogram(name: "nexttowardf", scope: !877, file: !877, line: 261, type: !1135, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1135 = !DISubroutineType(types: !1136)
!1136 = !{!262, !262, !267}
!1137 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1138, line: 1192)
!1138 = !DISubprogram(name: "nexttowardl", scope: !877, file: !877, line: 261, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1139 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1140, line: 1194)
!1140 = !DISubprogram(name: "remainder", scope: !877, file: !877, line: 272, type: !886, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1141 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1142, line: 1195)
!1142 = !DISubprogram(name: "remainderf", scope: !877, file: !877, line: 272, type: !969, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1143 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1144, line: 1196)
!1144 = !DISubprogram(name: "remainderl", scope: !877, file: !877, line: 272, type: !973, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1145 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1146, line: 1198)
!1146 = !DISubprogram(name: "remquo", scope: !877, file: !877, line: 307, type: !1147, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1147 = !DISubroutineType(types: !1148)
!1148 = !{!108, !108, !108, !906}
!1149 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1150, line: 1199)
!1150 = !DISubprogram(name: "remquof", scope: !877, file: !877, line: 307, type: !1151, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1151 = !DISubroutineType(types: !1152)
!1152 = !{!262, !262, !262, !906}
!1153 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1154, line: 1200)
!1154 = !DISubprogram(name: "remquol", scope: !877, file: !877, line: 307, type: !1155, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1155 = !DISubroutineType(types: !1156)
!1156 = !{!267, !267, !267, !906}
!1157 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1158, line: 1202)
!1158 = !DISubprogram(name: "rint", scope: !877, file: !877, line: 256, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1159 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1160, line: 1203)
!1160 = !DISubprogram(name: "rintf", scope: !877, file: !877, line: 256, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1161 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1162, line: 1204)
!1162 = !DISubprogram(name: "rintl", scope: !877, file: !877, line: 256, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1163 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1164, line: 1206)
!1164 = !DISubprogram(name: "round", scope: !877, file: !877, line: 298, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1165 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1166, line: 1207)
!1166 = !DISubprogram(name: "roundf", scope: !877, file: !877, line: 298, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1167 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1168, line: 1208)
!1168 = !DISubprogram(name: "roundl", scope: !877, file: !877, line: 298, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1169 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1170, line: 1210)
!1170 = !DISubprogram(name: "scalbln", scope: !877, file: !877, line: 290, type: !1171, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1171 = !DISubroutineType(types: !1172)
!1172 = !{!108, !108, !91}
!1173 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1174, line: 1211)
!1174 = !DISubprogram(name: "scalblnf", scope: !877, file: !877, line: 290, type: !1175, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1175 = !DISubroutineType(types: !1176)
!1176 = !{!262, !262, !91}
!1177 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1178, line: 1212)
!1178 = !DISubprogram(name: "scalblnl", scope: !877, file: !877, line: 290, type: !1179, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1179 = !DISubroutineType(types: !1180)
!1180 = !{!267, !267, !91}
!1181 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1182, line: 1214)
!1182 = !DISubprogram(name: "scalbn", scope: !877, file: !877, line: 276, type: !909, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1183 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1184, line: 1215)
!1184 = !DISubprogram(name: "scalbnf", scope: !877, file: !877, line: 276, type: !1185, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1185 = !DISubroutineType(types: !1186)
!1186 = !{!262, !262, !82}
!1187 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1188, line: 1216)
!1188 = !DISubprogram(name: "scalbnl", scope: !877, file: !877, line: 276, type: !1189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1189 = !DISubroutineType(types: !1190)
!1190 = !{!267, !267, !82}
!1191 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1192, line: 1218)
!1192 = !DISubprogram(name: "tgamma", scope: !877, file: !877, line: 235, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1193 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1194, line: 1219)
!1194 = !DISubprogram(name: "tgammaf", scope: !877, file: !877, line: 235, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1195 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1196, line: 1220)
!1196 = !DISubprogram(name: "tgammal", scope: !877, file: !877, line: 235, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1197 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1198, line: 1222)
!1198 = !DISubprogram(name: "trunc", scope: !877, file: !877, line: 302, type: !878, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1199 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1200, line: 1223)
!1200 = !DISubprogram(name: "truncf", scope: !877, file: !877, line: 302, type: !941, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1201 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1202, line: 1224)
!1202 = !DISubprogram(name: "truncl", scope: !877, file: !877, line: 302, type: !945, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1203 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1204, line: 58)
!1204 = !DIDerivedType(tag: DW_TAG_typedef, name: "fenv_t", file: !1205, line: 94, baseType: !1206)
!1205 = !DIFile(filename: "/usr/include/x86_64-linux-gnu/bits/fenv.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1206 = distinct !DICompositeType(tag: DW_TAG_structure_type, file: !1205, line: 75, flags: DIFlagFwdDecl, identifier: "_ZTS6fenv_t")
!1207 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1208, line: 59)
!1208 = !DIDerivedType(tag: DW_TAG_typedef, name: "fexcept_t", file: !1205, line: 68, baseType: !29)
!1209 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1210, line: 62)
!1210 = !DISubprogram(name: "feclearexcept", scope: !1211, file: !1211, line: 71, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1211 = !DIFile(filename: "/usr/include/fenv.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1212 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1213, line: 63)
!1213 = !DISubprogram(name: "fegetexceptflag", scope: !1211, file: !1211, line: 75, type: !1214, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1214 = !DISubroutineType(types: !1215)
!1215 = !{!82, !1216, !82}
!1216 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1208, size: 64)
!1217 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1218, line: 64)
!1218 = !DISubprogram(name: "feraiseexcept", scope: !1211, file: !1211, line: 78, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1219 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1220, line: 65)
!1220 = !DISubprogram(name: "fesetexceptflag", scope: !1211, file: !1211, line: 88, type: !1221, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1221 = !DISubroutineType(types: !1222)
!1222 = !{!82, !1223, !82}
!1223 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1224, size: 64)
!1224 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !1208)
!1225 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1226, line: 66)
!1226 = !DISubprogram(name: "fetestexcept", scope: !1211, file: !1211, line: 92, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1227 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1228, line: 68)
!1228 = !DISubprogram(name: "fegetround", scope: !1211, file: !1211, line: 104, type: !189, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1229 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1230, line: 69)
!1230 = !DISubprogram(name: "fesetround", scope: !1211, file: !1211, line: 107, type: !80, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1231 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1232, line: 71)
!1232 = !DISubprogram(name: "fegetenv", scope: !1211, file: !1211, line: 114, type: !1233, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1233 = !DISubroutineType(types: !1234)
!1234 = !{!82, !1235}
!1235 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1204, size: 64)
!1236 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1237, line: 72)
!1237 = !DISubprogram(name: "feholdexcept", scope: !1211, file: !1211, line: 119, type: !1233, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1238 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1239, line: 73)
!1239 = !DISubprogram(name: "fesetenv", scope: !1211, file: !1211, line: 123, type: !1240, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1240 = !DISubroutineType(types: !1241)
!1241 = !{!82, !1242}
!1242 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1243, size: 64)
!1243 = !DIDerivedType(tag: DW_TAG_const_type, baseType: !1204)
!1244 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1245, line: 74)
!1245 = !DISubprogram(name: "feupdateenv", scope: !1211, file: !1211, line: 128, type: !1240, isLocal: false, isDefinition: false, flags: DIFlagPrototyped, isOptimized: false)
!1246 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1204, line: 61)
!1247 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1208, line: 62)
!1248 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1210, line: 65)
!1249 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1213, line: 66)
!1250 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1218, line: 67)
!1251 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1220, line: 68)
!1252 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1226, line: 69)
!1253 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1228, line: 71)
!1254 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1230, line: 72)
!1255 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1232, line: 74)
!1256 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1237, line: 75)
!1257 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1239, line: 76)
!1258 = !DIImportedEntity(tag: DW_TAG_imported_declaration, scope: !75, entity: !1245, line: 77)
!1259 = !{i32 2, !"Dwarf Version", i32 4}
!1260 = !{i32 2, !"Debug Info Version", i32 3}
!1261 = distinct !DISubprogram(name: "__remill_basic_block", scope: !2, file: !2, line: 52, type: !1262, isLocal: false, isDefinition: true, scopeLine: 52, flags: DIFlagPrototyped, isOptimized: false, unit: !1, variables: !7)
!1262 = !DISubroutineType(types: !1263)
!1263 = !{!1264, !1267, !1950, !1264}
!1264 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !1265, size: 64)
!1265 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Memory", file: !1266, line: 36, flags: DIFlagFwdDecl, identifier: "_ZTS6Memory")
!1266 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/Types.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1267 = !DIDerivedType(tag: DW_TAG_reference_type, baseType: !1268, size: 64)
!1268 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "State", file: !27, line: 742, size: 27008, align: 128, elements: !1269, identifier: "_ZTS5State")
!1269 = !{!1270, !1282, !1491, !1511, !1541, !1566, !1595, !1632, !1642, !1703, !1728, !1752, !1932}
!1270 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1268, baseType: !1271)
!1271 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "ArchState", file: !1272, line: 21, size: 128, elements: !1273, identifier: "_ZTS9ArchState")
!1272 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/State.h", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!1273 = !{!1274, !1275, !1276}
!1274 = !DIDerivedType(tag: DW_TAG_member, name: "hyper_call", scope: !1271, file: !1272, line: 23, baseType: !4, size: 32)
!1275 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1271, file: !1272, line: 25, baseType: !8, size: 32, offset: 32)
!1276 = !DIDerivedType(tag: DW_TAG_member, scope: !1271, file: !1272, line: 31, baseType: !1277, size: 64, offset: 64)
!1277 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1271, file: !1272, line: 31, size: 64, elements: !1278, identifier: "_ZTSN9ArchStateUt_E")
!1278 = !{!1279, !1280, !1281}
!1279 = !DIDerivedType(tag: DW_TAG_member, name: "addr_to_load", scope: !1277, file: !1272, line: 32, baseType: !637, size: 64)
!1280 = !DIDerivedType(tag: DW_TAG_member, name: "addr_to_store", scope: !1277, file: !1272, line: 33, baseType: !637, size: 64)
!1281 = !DIDerivedType(tag: DW_TAG_member, name: "hyper_call_vector", scope: !1277, file: !1272, line: 34, baseType: !8, size: 32)
!1282 = !DIDerivedType(tag: DW_TAG_member, name: "vec", scope: !1268, file: !27, line: 747, baseType: !1283, size: 16384, offset: 128)
!1283 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1284, size: 16384, elements: !1369)
!1284 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "VectorReg", file: !27, line: 636, size: 512, align: 128, elements: !1285, identifier: "_ZTS9VectorReg")
!1285 = !{!1286, !1361, !1426}
!1286 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1284, file: !27, line: 637, baseType: !1287, size: 128, align: 128)
!1287 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec128_t", file: !1266, line: 317, size: 128, elements: !1288, identifier: "_ZTS8vec128_t")
!1288 = !{!1289, !1298, !1305, !1312, !1317, !1324, !1329, !1334, !1339, !1344, !1349, !1354}
!1289 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1287, file: !1266, line: 321, baseType: !1290, size: 128)
!1290 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v1_t", file: !1266, line: 205, size: 128, elements: !1291, identifier: "_ZTS11uint128v1_t")
!1291 = !{!1292}
!1292 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1290, file: !1266, line: 205, baseType: !1293, size: 128)
!1293 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 128, elements: !1296)
!1294 = !DIDerivedType(tag: DW_TAG_typedef, name: "uint128_t", file: !1266, line: 46, baseType: !1295)
!1295 = !DIBasicType(name: "unsigned __int128", size: 128, encoding: DW_ATE_unsigned)
!1296 = !{!1297}
!1297 = !DISubrange(count: 1)
!1298 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1287, file: !1266, line: 323, baseType: !1299, size: 128)
!1299 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v16_t", file: !1266, line: 182, size: 128, elements: !1300, identifier: "_ZTS10uint8v16_t")
!1300 = !{!1301}
!1301 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1299, file: !1266, line: 182, baseType: !1302, size: 128)
!1302 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 128, elements: !1303)
!1303 = !{!1304}
!1304 = !DISubrange(count: 16)
!1305 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1287, file: !1266, line: 324, baseType: !1306, size: 128)
!1306 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v8_t", file: !1266, line: 189, size: 128, elements: !1307, identifier: "_ZTS10uint16v8_t")
!1307 = !{!1308}
!1308 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1306, file: !1266, line: 189, baseType: !1309, size: 128)
!1309 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 128, elements: !1310)
!1310 = !{!1311}
!1311 = !DISubrange(count: 8)
!1312 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1287, file: !1266, line: 325, baseType: !1313, size: 128)
!1313 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v4_t", file: !1266, line: 195, size: 128, elements: !1314, identifier: "_ZTS10uint32v4_t")
!1314 = !{!1315}
!1315 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1313, file: !1266, line: 195, baseType: !1316, size: 128)
!1316 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 128, elements: !353)
!1317 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1287, file: !1266, line: 326, baseType: !1318, size: 128)
!1318 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v2_t", file: !1266, line: 200, size: 128, elements: !1319, identifier: "_ZTS10uint64v2_t")
!1319 = !{!1320}
!1320 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1318, file: !1266, line: 200, baseType: !1321, size: 128)
!1321 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 128, elements: !1322)
!1322 = !{!1323}
!1323 = !DISubrange(count: 2)
!1324 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1287, file: !1266, line: 327, baseType: !1325, size: 128)
!1325 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v4_t", file: !1266, line: 242, size: 128, elements: !1326, identifier: "_ZTS11float32v4_t")
!1326 = !{!1327}
!1327 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1325, file: !1266, line: 242, baseType: !1328, size: 128)
!1328 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 128, elements: !353)
!1329 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1287, file: !1266, line: 328, baseType: !1330, size: 128)
!1330 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v2_t", file: !1266, line: 247, size: 128, elements: !1331, identifier: "_ZTS11float64v2_t")
!1331 = !{!1332}
!1332 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1330, file: !1266, line: 247, baseType: !1333, size: 128)
!1333 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 128, elements: !1322)
!1334 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1287, file: !1266, line: 330, baseType: !1335, size: 128)
!1335 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v16_t", file: !1266, line: 213, size: 128, elements: !1336, identifier: "_ZTS9int8v16_t")
!1336 = !{!1337}
!1337 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1335, file: !1266, line: 213, baseType: !1338, size: 128)
!1338 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 128, elements: !1303)
!1339 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1287, file: !1266, line: 331, baseType: !1340, size: 128)
!1340 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v8_t", file: !1266, line: 220, size: 128, elements: !1341, identifier: "_ZTS9int16v8_t")
!1341 = !{!1342}
!1342 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1340, file: !1266, line: 220, baseType: !1343, size: 128)
!1343 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 128, elements: !1310)
!1344 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1287, file: !1266, line: 332, baseType: !1345, size: 128)
!1345 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v4_t", file: !1266, line: 226, size: 128, elements: !1346, identifier: "_ZTS9int32v4_t")
!1346 = !{!1347}
!1347 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1345, file: !1266, line: 226, baseType: !1348, size: 128)
!1348 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 128, elements: !353)
!1349 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1287, file: !1266, line: 333, baseType: !1350, size: 128)
!1350 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v2_t", file: !1266, line: 231, size: 128, elements: !1351, identifier: "_ZTS9int64v2_t")
!1351 = !{!1352}
!1352 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1350, file: !1266, line: 231, baseType: !1353, size: 128)
!1353 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 128, elements: !1322)
!1354 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1287, file: !1266, line: 334, baseType: !1355, size: 128)
!1355 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v1_t", file: !1266, line: 236, size: 128, elements: !1356, identifier: "_ZTS10int128v1_t")
!1356 = !{!1357}
!1357 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1355, file: !1266, line: 236, baseType: !1358, size: 128)
!1358 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 128, elements: !1296)
!1359 = !DIDerivedType(tag: DW_TAG_typedef, name: "int128_t", file: !1266, line: 47, baseType: !1360)
!1360 = !DIBasicType(name: "__int128", size: 128, encoding: DW_ATE_signed)
!1361 = !DIDerivedType(tag: DW_TAG_member, name: "ymm", scope: !1284, file: !27, line: 638, baseType: !1362, size: 256, align: 128)
!1362 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec256_t", file: !1266, line: 340, size: 256, elements: !1363, identifier: "_ZTS8vec256_t")
!1363 = !{!1364, !1371, !1376, !1381, !1386, !1391, !1396, !1401, !1406, !1411, !1416, !1421}
!1364 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1362, file: !1266, line: 341, baseType: !1365, size: 256)
!1365 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v32_t", file: !1266, line: 183, size: 256, elements: !1366, identifier: "_ZTS10uint8v32_t")
!1366 = !{!1367}
!1367 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1365, file: !1266, line: 183, baseType: !1368, size: 256)
!1368 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 256, elements: !1369)
!1369 = !{!1370}
!1370 = !DISubrange(count: 32)
!1371 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1362, file: !1266, line: 342, baseType: !1372, size: 256)
!1372 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v16_t", file: !1266, line: 190, size: 256, elements: !1373, identifier: "_ZTS11uint16v16_t")
!1373 = !{!1374}
!1374 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1372, file: !1266, line: 190, baseType: !1375, size: 256)
!1375 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 256, elements: !1303)
!1376 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1362, file: !1266, line: 343, baseType: !1377, size: 256)
!1377 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v8_t", file: !1266, line: 196, size: 256, elements: !1378, identifier: "_ZTS10uint32v8_t")
!1378 = !{!1379}
!1379 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1377, file: !1266, line: 196, baseType: !1380, size: 256)
!1380 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 256, elements: !1310)
!1381 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1362, file: !1266, line: 344, baseType: !1382, size: 256)
!1382 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v4_t", file: !1266, line: 201, size: 256, elements: !1383, identifier: "_ZTS10uint64v4_t")
!1383 = !{!1384}
!1384 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1382, file: !1266, line: 201, baseType: !1385, size: 256)
!1385 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 256, elements: !353)
!1386 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1362, file: !1266, line: 345, baseType: !1387, size: 256)
!1387 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v2_t", file: !1266, line: 206, size: 256, elements: !1388, identifier: "_ZTS11uint128v2_t")
!1388 = !{!1389}
!1389 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1387, file: !1266, line: 206, baseType: !1390, size: 256)
!1390 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 256, elements: !1322)
!1391 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1362, file: !1266, line: 346, baseType: !1392, size: 256)
!1392 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v8_t", file: !1266, line: 243, size: 256, elements: !1393, identifier: "_ZTS11float32v8_t")
!1393 = !{!1394}
!1394 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1392, file: !1266, line: 243, baseType: !1395, size: 256)
!1395 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 256, elements: !1310)
!1396 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1362, file: !1266, line: 347, baseType: !1397, size: 256)
!1397 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v4_t", file: !1266, line: 248, size: 256, elements: !1398, identifier: "_ZTS11float64v4_t")
!1398 = !{!1399}
!1399 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1397, file: !1266, line: 248, baseType: !1400, size: 256)
!1400 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 256, elements: !353)
!1401 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1362, file: !1266, line: 349, baseType: !1402, size: 256)
!1402 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v32_t", file: !1266, line: 214, size: 256, elements: !1403, identifier: "_ZTS9int8v32_t")
!1403 = !{!1404}
!1404 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1402, file: !1266, line: 214, baseType: !1405, size: 256)
!1405 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 256, elements: !1369)
!1406 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1362, file: !1266, line: 350, baseType: !1407, size: 256)
!1407 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v16_t", file: !1266, line: 221, size: 256, elements: !1408, identifier: "_ZTS10int16v16_t")
!1408 = !{!1409}
!1409 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1407, file: !1266, line: 221, baseType: !1410, size: 256)
!1410 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 256, elements: !1303)
!1411 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1362, file: !1266, line: 351, baseType: !1412, size: 256)
!1412 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v8_t", file: !1266, line: 227, size: 256, elements: !1413, identifier: "_ZTS9int32v8_t")
!1413 = !{!1414}
!1414 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1412, file: !1266, line: 227, baseType: !1415, size: 256)
!1415 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 256, elements: !1310)
!1416 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1362, file: !1266, line: 352, baseType: !1417, size: 256)
!1417 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v4_t", file: !1266, line: 232, size: 256, elements: !1418, identifier: "_ZTS9int64v4_t")
!1418 = !{!1419}
!1419 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1417, file: !1266, line: 232, baseType: !1420, size: 256)
!1420 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 256, elements: !353)
!1421 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1362, file: !1266, line: 353, baseType: !1422, size: 256)
!1422 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v2_t", file: !1266, line: 237, size: 256, elements: !1423, identifier: "_ZTS10int128v2_t")
!1423 = !{!1424}
!1424 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1422, file: !1266, line: 237, baseType: !1425, size: 256)
!1425 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 256, elements: !1322)
!1426 = !DIDerivedType(tag: DW_TAG_member, name: "zmm", scope: !1284, file: !27, line: 639, baseType: !1427, size: 512, align: 128)
!1427 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec512_t", file: !1266, line: 359, size: 512, elements: !1428, identifier: "_ZTS8vec512_t")
!1428 = !{!1429, !1436, !1441, !1446, !1451, !1456, !1461, !1466, !1471, !1476, !1481, !1486}
!1429 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1427, file: !1266, line: 360, baseType: !1430, size: 512)
!1430 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v64_t", file: !1266, line: 184, size: 512, elements: !1431, identifier: "_ZTS10uint8v64_t")
!1431 = !{!1432}
!1432 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1430, file: !1266, line: 184, baseType: !1433, size: 512)
!1433 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 512, elements: !1434)
!1434 = !{!1435}
!1435 = !DISubrange(count: 64)
!1436 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1427, file: !1266, line: 361, baseType: !1437, size: 512)
!1437 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v32_t", file: !1266, line: 191, size: 512, elements: !1438, identifier: "_ZTS11uint16v32_t")
!1438 = !{!1439}
!1439 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1437, file: !1266, line: 191, baseType: !1440, size: 512)
!1440 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 512, elements: !1369)
!1441 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1427, file: !1266, line: 362, baseType: !1442, size: 512)
!1442 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v16_t", file: !1266, line: 197, size: 512, elements: !1443, identifier: "_ZTS11uint32v16_t")
!1443 = !{!1444}
!1444 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1442, file: !1266, line: 197, baseType: !1445, size: 512)
!1445 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 512, elements: !1303)
!1446 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1427, file: !1266, line: 363, baseType: !1447, size: 512)
!1447 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v8_t", file: !1266, line: 202, size: 512, elements: !1448, identifier: "_ZTS10uint64v8_t")
!1448 = !{!1449}
!1449 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1447, file: !1266, line: 202, baseType: !1450, size: 512)
!1450 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 512, elements: !1310)
!1451 = !DIDerivedType(tag: DW_TAG_member, name: "dqwords", scope: !1427, file: !1266, line: 364, baseType: !1452, size: 512)
!1452 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint128v4_t", file: !1266, line: 207, size: 512, elements: !1453, identifier: "_ZTS11uint128v4_t")
!1453 = !{!1454}
!1454 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1452, file: !1266, line: 207, baseType: !1455, size: 512)
!1455 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1294, size: 512, elements: !353)
!1456 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1427, file: !1266, line: 365, baseType: !1457, size: 512)
!1457 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v16_t", file: !1266, line: 244, size: 512, elements: !1458, identifier: "_ZTS12float32v16_t")
!1458 = !{!1459}
!1459 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1457, file: !1266, line: 244, baseType: !1460, size: 512)
!1460 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 512, elements: !1303)
!1461 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1427, file: !1266, line: 366, baseType: !1462, size: 512)
!1462 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v8_t", file: !1266, line: 249, size: 512, elements: !1463, identifier: "_ZTS11float64v8_t")
!1463 = !{!1464}
!1464 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1462, file: !1266, line: 249, baseType: !1465, size: 512)
!1465 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 512, elements: !1310)
!1466 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1427, file: !1266, line: 368, baseType: !1467, size: 512)
!1467 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v64_t", file: !1266, line: 215, size: 512, elements: !1468, identifier: "_ZTS9int8v64_t")
!1468 = !{!1469}
!1469 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1467, file: !1266, line: 215, baseType: !1470, size: 512)
!1470 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 512, elements: !1434)
!1471 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1427, file: !1266, line: 369, baseType: !1472, size: 512)
!1472 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v32_t", file: !1266, line: 222, size: 512, elements: !1473, identifier: "_ZTS10int16v32_t")
!1473 = !{!1474}
!1474 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1472, file: !1266, line: 222, baseType: !1475, size: 512)
!1475 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 512, elements: !1369)
!1476 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1427, file: !1266, line: 370, baseType: !1477, size: 512)
!1477 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v16_t", file: !1266, line: 228, size: 512, elements: !1478, identifier: "_ZTS10int32v16_t")
!1478 = !{!1479}
!1479 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1477, file: !1266, line: 228, baseType: !1480, size: 512)
!1480 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 512, elements: !1303)
!1481 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1427, file: !1266, line: 371, baseType: !1482, size: 512)
!1482 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v8_t", file: !1266, line: 233, size: 512, elements: !1483, identifier: "_ZTS9int64v8_t")
!1483 = !{!1484}
!1484 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1482, file: !1266, line: 233, baseType: !1485, size: 512)
!1485 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 512, elements: !1310)
!1486 = !DIDerivedType(tag: DW_TAG_member, name: "sdqwords", scope: !1427, file: !1266, line: 372, baseType: !1487, size: 512)
!1487 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int128v4_t", file: !1266, line: 238, size: 512, elements: !1488, identifier: "_ZTS10int128v4_t")
!1488 = !{!1489}
!1489 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1487, file: !1266, line: 238, baseType: !1490, size: 512)
!1490 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1359, size: 512, elements: !353)
!1491 = !DIDerivedType(tag: DW_TAG_member, name: "aflag", scope: !1268, file: !27, line: 751, baseType: !1492, size: 128, align: 64, offset: 16512)
!1492 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "ArithFlags", file: !27, line: 402, size: 128, align: 64, elements: !1493, identifier: "_ZTS10ArithFlags")
!1493 = !{!1494, !1496, !1497, !1498, !1499, !1500, !1501, !1502, !1503, !1504, !1505, !1506, !1507, !1508, !1509, !1510}
!1494 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1492, file: !27, line: 404, baseType: !1495, size: 8)
!1495 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !62)
!1496 = !DIDerivedType(tag: DW_TAG_member, name: "cf", scope: !1492, file: !27, line: 405, baseType: !62, size: 8, offset: 8)
!1497 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1492, file: !27, line: 406, baseType: !1495, size: 8, offset: 16)
!1498 = !DIDerivedType(tag: DW_TAG_member, name: "pf", scope: !1492, file: !27, line: 407, baseType: !62, size: 8, offset: 24)
!1499 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1492, file: !27, line: 408, baseType: !1495, size: 8, offset: 32)
!1500 = !DIDerivedType(tag: DW_TAG_member, name: "af", scope: !1492, file: !27, line: 409, baseType: !62, size: 8, offset: 40)
!1501 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1492, file: !27, line: 410, baseType: !1495, size: 8, offset: 48)
!1502 = !DIDerivedType(tag: DW_TAG_member, name: "zf", scope: !1492, file: !27, line: 411, baseType: !62, size: 8, offset: 56)
!1503 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1492, file: !27, line: 412, baseType: !1495, size: 8, offset: 64)
!1504 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1492, file: !27, line: 413, baseType: !62, size: 8, offset: 72)
!1505 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1492, file: !27, line: 414, baseType: !1495, size: 8, offset: 80)
!1506 = !DIDerivedType(tag: DW_TAG_member, name: "df", scope: !1492, file: !27, line: 415, baseType: !62, size: 8, offset: 88)
!1507 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1492, file: !27, line: 416, baseType: !1495, size: 8, offset: 96)
!1508 = !DIDerivedType(tag: DW_TAG_member, name: "of", scope: !1492, file: !27, line: 417, baseType: !62, size: 8, offset: 104)
!1509 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1492, file: !27, line: 418, baseType: !1495, size: 8, offset: 112)
!1510 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1492, file: !27, line: 419, baseType: !1495, size: 8, offset: 120)
!1511 = !DIDerivedType(tag: DW_TAG_member, name: "rflag", scope: !1268, file: !27, line: 752, baseType: !1512, size: 64, align: 64, offset: 16640)
!1512 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "Flags", file: !27, line: 366, size: 64, align: 64, elements: !1513, identifier: "_ZTS5Flags")
!1513 = !{!1514, !1515}
!1514 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1512, file: !27, line: 367, baseType: !637, size: 64)
!1515 = !DIDerivedType(tag: DW_TAG_member, scope: !1512, file: !27, line: 368, baseType: !1516, size: 64)
!1516 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1512, file: !27, line: 368, size: 64, elements: !1517, identifier: "_ZTSN5FlagsUt_E")
!1517 = !{!1518, !1519, !1520, !1521, !1522, !1523, !1524, !1525, !1526, !1527, !1528, !1529, !1530, !1531, !1532, !1533, !1534, !1535, !1536, !1537, !1538, !1539, !1540}
!1518 = !DIDerivedType(tag: DW_TAG_member, name: "cf", scope: !1516, file: !27, line: 369, baseType: !8, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1519 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_1", scope: !1516, file: !27, line: 370, baseType: !8, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1520 = !DIDerivedType(tag: DW_TAG_member, name: "pf", scope: !1516, file: !27, line: 371, baseType: !8, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1521 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0a", scope: !1516, file: !27, line: 372, baseType: !8, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1522 = !DIDerivedType(tag: DW_TAG_member, name: "af", scope: !1516, file: !27, line: 374, baseType: !8, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1523 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0b", scope: !1516, file: !27, line: 375, baseType: !8, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1524 = !DIDerivedType(tag: DW_TAG_member, name: "zf", scope: !1516, file: !27, line: 376, baseType: !8, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1525 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1516, file: !27, line: 377, baseType: !8, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1526 = !DIDerivedType(tag: DW_TAG_member, name: "tf", scope: !1516, file: !27, line: 379, baseType: !8, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1527 = !DIDerivedType(tag: DW_TAG_member, name: "_if", scope: !1516, file: !27, line: 380, baseType: !8, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1528 = !DIDerivedType(tag: DW_TAG_member, name: "df", scope: !1516, file: !27, line: 381, baseType: !8, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1529 = !DIDerivedType(tag: DW_TAG_member, name: "of", scope: !1516, file: !27, line: 382, baseType: !8, size: 1, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1530 = !DIDerivedType(tag: DW_TAG_member, name: "iopl", scope: !1516, file: !27, line: 384, baseType: !8, size: 2, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1531 = !DIDerivedType(tag: DW_TAG_member, name: "nt", scope: !1516, file: !27, line: 385, baseType: !8, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1532 = !DIDerivedType(tag: DW_TAG_member, name: "must_be_0c", scope: !1516, file: !27, line: 386, baseType: !8, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1533 = !DIDerivedType(tag: DW_TAG_member, name: "rf", scope: !1516, file: !27, line: 388, baseType: !8, size: 1, offset: 16, flags: DIFlagBitField, extraData: i64 0)
!1534 = !DIDerivedType(tag: DW_TAG_member, name: "vm", scope: !1516, file: !27, line: 389, baseType: !8, size: 1, offset: 17, flags: DIFlagBitField, extraData: i64 0)
!1535 = !DIDerivedType(tag: DW_TAG_member, name: "ac", scope: !1516, file: !27, line: 390, baseType: !8, size: 1, offset: 18, flags: DIFlagBitField, extraData: i64 0)
!1536 = !DIDerivedType(tag: DW_TAG_member, name: "vif", scope: !1516, file: !27, line: 391, baseType: !8, size: 1, offset: 19, flags: DIFlagBitField, extraData: i64 0)
!1537 = !DIDerivedType(tag: DW_TAG_member, name: "vip", scope: !1516, file: !27, line: 393, baseType: !8, size: 1, offset: 20, flags: DIFlagBitField, extraData: i64 0)
!1538 = !DIDerivedType(tag: DW_TAG_member, name: "id", scope: !1516, file: !27, line: 394, baseType: !8, size: 1, offset: 21, flags: DIFlagBitField, extraData: i64 0)
!1539 = !DIDerivedType(tag: DW_TAG_member, name: "reserved_eflags", scope: !1516, file: !27, line: 395, baseType: !8, size: 10, offset: 22, flags: DIFlagBitField, extraData: i64 0)
!1540 = !DIDerivedType(tag: DW_TAG_member, name: "reserved_rflags", scope: !1516, file: !27, line: 396, baseType: !8, size: 32, offset: 32)
!1541 = !DIDerivedType(tag: DW_TAG_member, name: "seg", scope: !1268, file: !27, line: 753, baseType: !1542, size: 192, align: 64, offset: 16704)
!1542 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Segments", file: !27, line: 451, size: 192, align: 64, elements: !1543, identifier: "_ZTS8Segments")
!1543 = !{!1544, !1546, !1556, !1557, !1558, !1559, !1560, !1561, !1562, !1563, !1564, !1565}
!1544 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1542, file: !27, line: 452, baseType: !1545, size: 16)
!1545 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !28)
!1546 = !DIDerivedType(tag: DW_TAG_member, name: "ss", scope: !1542, file: !27, line: 453, baseType: !1547, size: 16, offset: 16)
!1547 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "SegmentSelector", file: !27, line: 76, size: 16, elements: !1548, identifier: "_ZTS15SegmentSelector")
!1548 = !{!1549, !1550}
!1549 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1547, file: !27, line: 77, baseType: !28, size: 16)
!1550 = !DIDerivedType(tag: DW_TAG_member, scope: !1547, file: !27, line: 78, baseType: !1551, size: 16)
!1551 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1547, file: !27, line: 78, size: 16, elements: !1552, identifier: "_ZTSN15SegmentSelectorUt_E")
!1552 = !{!1553, !1554, !1555}
!1553 = !DIDerivedType(tag: DW_TAG_member, name: "rpi", scope: !1551, file: !27, line: 79, baseType: !26, size: 2, flags: DIFlagBitField, extraData: i64 0)
!1554 = !DIDerivedType(tag: DW_TAG_member, name: "ti", scope: !1551, file: !27, line: 80, baseType: !35, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1555 = !DIDerivedType(tag: DW_TAG_member, name: "index", scope: !1551, file: !27, line: 81, baseType: !28, size: 13, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1556 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1542, file: !27, line: 454, baseType: !1545, size: 16, offset: 32)
!1557 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1542, file: !27, line: 455, baseType: !1547, size: 16, offset: 48)
!1558 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1542, file: !27, line: 456, baseType: !1545, size: 16, offset: 64)
!1559 = !DIDerivedType(tag: DW_TAG_member, name: "gs", scope: !1542, file: !27, line: 457, baseType: !1547, size: 16, offset: 80)
!1560 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1542, file: !27, line: 458, baseType: !1545, size: 16, offset: 96)
!1561 = !DIDerivedType(tag: DW_TAG_member, name: "fs", scope: !1542, file: !27, line: 459, baseType: !1547, size: 16, offset: 112)
!1562 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1542, file: !27, line: 460, baseType: !1545, size: 16, offset: 128)
!1563 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1542, file: !27, line: 461, baseType: !1547, size: 16, offset: 144)
!1564 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1542, file: !27, line: 462, baseType: !1545, size: 16, offset: 160)
!1565 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1542, file: !27, line: 463, baseType: !1547, size: 16, offset: 176)
!1566 = !DIDerivedType(tag: DW_TAG_member, name: "addr", scope: !1268, file: !27, line: 754, baseType: !1567, size: 768, align: 64, offset: 16896)
!1567 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "AddressSpace", file: !27, line: 654, size: 768, align: 64, elements: !1568, identifier: "_ZTS12AddressSpace")
!1568 = !{!1569, !1571, !1585, !1586, !1587, !1588, !1589, !1590, !1591, !1592, !1593, !1594}
!1569 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1567, file: !27, line: 655, baseType: !1570, size: 64)
!1570 = !DIDerivedType(tag: DW_TAG_volatile_type, baseType: !637)
!1571 = !DIDerivedType(tag: DW_TAG_member, name: "ss_base", scope: !1567, file: !27, line: 656, baseType: !1572, size: 64, offset: 64)
!1572 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Reg", file: !27, line: 610, size: 64, elements: !1573, identifier: "_ZTS3Reg")
!1573 = !{!1574}
!1574 = !DIDerivedType(tag: DW_TAG_member, scope: !1572, file: !27, line: 611, baseType: !1575, size: 64)
!1575 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1572, file: !27, line: 611, size: 64, elements: !1576, identifier: "_ZTSN3RegUt_E")
!1576 = !{!1577, !1582, !1583, !1584}
!1577 = !DIDerivedType(tag: DW_TAG_member, name: "byte", scope: !1575, file: !27, line: 615, baseType: !1578, size: 16, align: 8)
!1578 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1575, file: !27, line: 612, size: 16, elements: !1579, identifier: "_ZTSN3RegUt_Ut_E")
!1579 = !{!1580, !1581}
!1580 = !DIDerivedType(tag: DW_TAG_member, name: "low", scope: !1578, file: !27, line: 613, baseType: !62, size: 8)
!1581 = !DIDerivedType(tag: DW_TAG_member, name: "high", scope: !1578, file: !27, line: 614, baseType: !62, size: 8, offset: 8)
!1582 = !DIDerivedType(tag: DW_TAG_member, name: "word", scope: !1575, file: !27, line: 616, baseType: !28, size: 16, align: 16)
!1583 = !DIDerivedType(tag: DW_TAG_member, name: "dword", scope: !1575, file: !27, line: 617, baseType: !8, size: 32, align: 32)
!1584 = !DIDerivedType(tag: DW_TAG_member, name: "qword", scope: !1575, file: !27, line: 618, baseType: !637, size: 64, align: 64)
!1585 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1567, file: !27, line: 657, baseType: !1570, size: 64, offset: 128)
!1586 = !DIDerivedType(tag: DW_TAG_member, name: "es_base", scope: !1567, file: !27, line: 658, baseType: !1572, size: 64, offset: 192)
!1587 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1567, file: !27, line: 659, baseType: !1570, size: 64, offset: 256)
!1588 = !DIDerivedType(tag: DW_TAG_member, name: "gs_base", scope: !1567, file: !27, line: 660, baseType: !1572, size: 64, offset: 320)
!1589 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1567, file: !27, line: 661, baseType: !1570, size: 64, offset: 384)
!1590 = !DIDerivedType(tag: DW_TAG_member, name: "fs_base", scope: !1567, file: !27, line: 662, baseType: !1572, size: 64, offset: 448)
!1591 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1567, file: !27, line: 663, baseType: !1570, size: 64, offset: 512)
!1592 = !DIDerivedType(tag: DW_TAG_member, name: "ds_base", scope: !1567, file: !27, line: 664, baseType: !1572, size: 64, offset: 576)
!1593 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1567, file: !27, line: 665, baseType: !1570, size: 64, offset: 640)
!1594 = !DIDerivedType(tag: DW_TAG_member, name: "cs_base", scope: !1567, file: !27, line: 666, baseType: !1572, size: 64, offset: 704)
!1595 = !DIDerivedType(tag: DW_TAG_member, name: "gpr", scope: !1268, file: !27, line: 755, baseType: !1596, size: 2176, align: 64, offset: 17664)
!1596 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "GPR", file: !27, line: 677, size: 2176, align: 64, elements: !1597, identifier: "_ZTS3GPR")
!1597 = !{!1598, !1599, !1600, !1601, !1602, !1603, !1604, !1605, !1606, !1607, !1608, !1609, !1610, !1611, !1612, !1613, !1614, !1615, !1616, !1617, !1618, !1619, !1620, !1621, !1622, !1623, !1624, !1625, !1626, !1627, !1628, !1629, !1630, !1631}
!1598 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1596, file: !27, line: 679, baseType: !1570, size: 64)
!1599 = !DIDerivedType(tag: DW_TAG_member, name: "rax", scope: !1596, file: !27, line: 680, baseType: !1572, size: 64, offset: 64)
!1600 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1596, file: !27, line: 681, baseType: !1570, size: 64, offset: 128)
!1601 = !DIDerivedType(tag: DW_TAG_member, name: "rbx", scope: !1596, file: !27, line: 682, baseType: !1572, size: 64, offset: 192)
!1602 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1596, file: !27, line: 683, baseType: !1570, size: 64, offset: 256)
!1603 = !DIDerivedType(tag: DW_TAG_member, name: "rcx", scope: !1596, file: !27, line: 684, baseType: !1572, size: 64, offset: 320)
!1604 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1596, file: !27, line: 685, baseType: !1570, size: 64, offset: 384)
!1605 = !DIDerivedType(tag: DW_TAG_member, name: "rdx", scope: !1596, file: !27, line: 686, baseType: !1572, size: 64, offset: 448)
!1606 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1596, file: !27, line: 687, baseType: !1570, size: 64, offset: 512)
!1607 = !DIDerivedType(tag: DW_TAG_member, name: "rsi", scope: !1596, file: !27, line: 688, baseType: !1572, size: 64, offset: 576)
!1608 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1596, file: !27, line: 689, baseType: !1570, size: 64, offset: 640)
!1609 = !DIDerivedType(tag: DW_TAG_member, name: "rdi", scope: !1596, file: !27, line: 690, baseType: !1572, size: 64, offset: 704)
!1610 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1596, file: !27, line: 691, baseType: !1570, size: 64, offset: 768)
!1611 = !DIDerivedType(tag: DW_TAG_member, name: "rsp", scope: !1596, file: !27, line: 692, baseType: !1572, size: 64, offset: 832)
!1612 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1596, file: !27, line: 693, baseType: !1570, size: 64, offset: 896)
!1613 = !DIDerivedType(tag: DW_TAG_member, name: "rbp", scope: !1596, file: !27, line: 694, baseType: !1572, size: 64, offset: 960)
!1614 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1596, file: !27, line: 695, baseType: !1570, size: 64, offset: 1024)
!1615 = !DIDerivedType(tag: DW_TAG_member, name: "r8", scope: !1596, file: !27, line: 696, baseType: !1572, size: 64, offset: 1088)
!1616 = !DIDerivedType(tag: DW_TAG_member, name: "_9", scope: !1596, file: !27, line: 697, baseType: !1570, size: 64, offset: 1152)
!1617 = !DIDerivedType(tag: DW_TAG_member, name: "r9", scope: !1596, file: !27, line: 698, baseType: !1572, size: 64, offset: 1216)
!1618 = !DIDerivedType(tag: DW_TAG_member, name: "_10", scope: !1596, file: !27, line: 699, baseType: !1570, size: 64, offset: 1280)
!1619 = !DIDerivedType(tag: DW_TAG_member, name: "r10", scope: !1596, file: !27, line: 700, baseType: !1572, size: 64, offset: 1344)
!1620 = !DIDerivedType(tag: DW_TAG_member, name: "_11", scope: !1596, file: !27, line: 701, baseType: !1570, size: 64, offset: 1408)
!1621 = !DIDerivedType(tag: DW_TAG_member, name: "r11", scope: !1596, file: !27, line: 702, baseType: !1572, size: 64, offset: 1472)
!1622 = !DIDerivedType(tag: DW_TAG_member, name: "_12", scope: !1596, file: !27, line: 703, baseType: !1570, size: 64, offset: 1536)
!1623 = !DIDerivedType(tag: DW_TAG_member, name: "r12", scope: !1596, file: !27, line: 704, baseType: !1572, size: 64, offset: 1600)
!1624 = !DIDerivedType(tag: DW_TAG_member, name: "_13", scope: !1596, file: !27, line: 705, baseType: !1570, size: 64, offset: 1664)
!1625 = !DIDerivedType(tag: DW_TAG_member, name: "r13", scope: !1596, file: !27, line: 706, baseType: !1572, size: 64, offset: 1728)
!1626 = !DIDerivedType(tag: DW_TAG_member, name: "_14", scope: !1596, file: !27, line: 707, baseType: !1570, size: 64, offset: 1792)
!1627 = !DIDerivedType(tag: DW_TAG_member, name: "r14", scope: !1596, file: !27, line: 708, baseType: !1572, size: 64, offset: 1856)
!1628 = !DIDerivedType(tag: DW_TAG_member, name: "_15", scope: !1596, file: !27, line: 709, baseType: !1570, size: 64, offset: 1920)
!1629 = !DIDerivedType(tag: DW_TAG_member, name: "r15", scope: !1596, file: !27, line: 710, baseType: !1572, size: 64, offset: 1984)
!1630 = !DIDerivedType(tag: DW_TAG_member, name: "_16", scope: !1596, file: !27, line: 711, baseType: !1570, size: 64, offset: 2048)
!1631 = !DIDerivedType(tag: DW_TAG_member, name: "rip", scope: !1596, file: !27, line: 714, baseType: !1572, size: 64, offset: 2112)
!1632 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1268, file: !27, line: 756, baseType: !1633, size: 1024, align: 64, offset: 19840)
!1633 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "X87Stack", file: !27, line: 719, size: 1024, align: 64, elements: !1634, identifier: "_ZTS8X87Stack")
!1634 = !{!1635}
!1635 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1633, file: !27, line: 723, baseType: !1636, size: 1024)
!1636 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1637, size: 1024, elements: !1310)
!1637 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1633, file: !27, line: 720, size: 128, align: 64, elements: !1638, identifier: "_ZTSN8X87StackUt_E")
!1638 = !{!1639, !1640}
!1639 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1637, file: !27, line: 721, baseType: !637, size: 64)
!1640 = !DIDerivedType(tag: DW_TAG_member, name: "val", scope: !1637, file: !27, line: 722, baseType: !1641, size: 64, offset: 64)
!1641 = !DIDerivedType(tag: DW_TAG_typedef, name: "float64_t", file: !1266, line: 61, baseType: !108)
!1642 = !DIDerivedType(tag: DW_TAG_member, name: "mmx", scope: !1268, file: !27, line: 757, baseType: !1643, size: 1024, align: 64, offset: 20864)
!1643 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "MMX", file: !27, line: 729, size: 1024, align: 64, elements: !1644, identifier: "_ZTS3MMX")
!1644 = !{!1645}
!1645 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1643, file: !27, line: 733, baseType: !1646, size: 1024)
!1646 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1647, size: 1024, elements: !1310)
!1647 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1643, file: !27, line: 730, size: 128, align: 64, elements: !1648, identifier: "_ZTSN3MMXUt_E")
!1648 = !{!1649, !1650}
!1649 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1647, file: !27, line: 731, baseType: !637, size: 64)
!1650 = !DIDerivedType(tag: DW_TAG_member, name: "val", scope: !1647, file: !27, line: 732, baseType: !1651, size: 64, offset: 64)
!1651 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "vec64_t", file: !1266, line: 294, size: 64, elements: !1652, identifier: "_ZTS7vec64_t")
!1652 = !{!1653, !1658, !1663, !1668, !1673, !1678, !1683, !1688, !1693, !1698}
!1653 = !DIDerivedType(tag: DW_TAG_member, name: "qwords", scope: !1651, file: !1266, line: 298, baseType: !1654, size: 64)
!1654 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint64v1_t", file: !1266, line: 199, size: 64, elements: !1655, identifier: "_ZTS10uint64v1_t")
!1655 = !{!1656}
!1656 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1654, file: !1266, line: 199, baseType: !1657, size: 64)
!1657 = !DICompositeType(tag: DW_TAG_array_type, baseType: !637, size: 64, elements: !1296)
!1658 = !DIDerivedType(tag: DW_TAG_member, name: "bytes", scope: !1651, file: !1266, line: 300, baseType: !1659, size: 64)
!1659 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint8v8_t", file: !1266, line: 181, size: 64, elements: !1660, identifier: "_ZTS9uint8v8_t")
!1660 = !{!1661}
!1661 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1659, file: !1266, line: 181, baseType: !1662, size: 64)
!1662 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 64, elements: !1310)
!1663 = !DIDerivedType(tag: DW_TAG_member, name: "words", scope: !1651, file: !1266, line: 301, baseType: !1664, size: 64)
!1664 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint16v4_t", file: !1266, line: 188, size: 64, elements: !1665, identifier: "_ZTS10uint16v4_t")
!1665 = !{!1666}
!1666 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1664, file: !1266, line: 188, baseType: !1667, size: 64)
!1667 = !DICompositeType(tag: DW_TAG_array_type, baseType: !28, size: 64, elements: !353)
!1668 = !DIDerivedType(tag: DW_TAG_member, name: "dwords", scope: !1651, file: !1266, line: 302, baseType: !1669, size: 64)
!1669 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "uint32v2_t", file: !1266, line: 194, size: 64, elements: !1670, identifier: "_ZTS10uint32v2_t")
!1670 = !{!1671}
!1671 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1669, file: !1266, line: 194, baseType: !1672, size: 64)
!1672 = !DICompositeType(tag: DW_TAG_array_type, baseType: !8, size: 64, elements: !1322)
!1673 = !DIDerivedType(tag: DW_TAG_member, name: "floats", scope: !1651, file: !1266, line: 303, baseType: !1674, size: 64)
!1674 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float32v2_t", file: !1266, line: 241, size: 64, elements: !1675, identifier: "_ZTS11float32v2_t")
!1675 = !{!1676}
!1676 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1674, file: !1266, line: 241, baseType: !1677, size: 64)
!1677 = !DICompositeType(tag: DW_TAG_array_type, baseType: !262, size: 64, elements: !1322)
!1678 = !DIDerivedType(tag: DW_TAG_member, name: "doubles", scope: !1651, file: !1266, line: 304, baseType: !1679, size: 64)
!1679 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float64v1_t", file: !1266, line: 246, size: 64, elements: !1680, identifier: "_ZTS11float64v1_t")
!1680 = !{!1681}
!1681 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1679, file: !1266, line: 246, baseType: !1682, size: 64)
!1682 = !DICompositeType(tag: DW_TAG_array_type, baseType: !108, size: 64, elements: !1296)
!1683 = !DIDerivedType(tag: DW_TAG_member, name: "sbytes", scope: !1651, file: !1266, line: 306, baseType: !1684, size: 64)
!1684 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int8v8_t", file: !1266, line: 212, size: 64, elements: !1685, identifier: "_ZTS8int8v8_t")
!1685 = !{!1686}
!1686 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1684, file: !1266, line: 212, baseType: !1687, size: 64)
!1687 = !DICompositeType(tag: DW_TAG_array_type, baseType: !604, size: 64, elements: !1310)
!1688 = !DIDerivedType(tag: DW_TAG_member, name: "swords", scope: !1651, file: !1266, line: 307, baseType: !1689, size: 64)
!1689 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int16v4_t", file: !1266, line: 219, size: 64, elements: !1690, identifier: "_ZTS9int16v4_t")
!1690 = !{!1691}
!1691 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1689, file: !1266, line: 219, baseType: !1692, size: 64)
!1692 = !DICompositeType(tag: DW_TAG_array_type, baseType: !607, size: 64, elements: !353)
!1693 = !DIDerivedType(tag: DW_TAG_member, name: "sdwords", scope: !1651, file: !1266, line: 308, baseType: !1694, size: 64)
!1694 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int32v2_t", file: !1266, line: 225, size: 64, elements: !1695, identifier: "_ZTS9int32v2_t")
!1695 = !{!1696}
!1696 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1694, file: !1266, line: 225, baseType: !1697, size: 64)
!1697 = !DICompositeType(tag: DW_TAG_array_type, baseType: !610, size: 64, elements: !1322)
!1698 = !DIDerivedType(tag: DW_TAG_member, name: "sqwords", scope: !1651, file: !1266, line: 309, baseType: !1699, size: 64)
!1699 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "int64v1_t", file: !1266, line: 230, size: 64, elements: !1700, identifier: "_ZTS9int64v1_t")
!1700 = !{!1701}
!1701 = !DIDerivedType(tag: DW_TAG_member, name: "elems", scope: !1699, file: !1266, line: 230, baseType: !1702, size: 64)
!1702 = !DICompositeType(tag: DW_TAG_array_type, baseType: !612, size: 64, elements: !1296)
!1703 = !DIDerivedType(tag: DW_TAG_member, name: "sw", scope: !1268, file: !27, line: 758, baseType: !1704, size: 192, offset: 21888)
!1704 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FPUStatusFlags", file: !27, line: 332, size: 192, elements: !1705, identifier: "_ZTS14FPUStatusFlags")
!1705 = !{!1706, !1707, !1708, !1709, !1710, !1711, !1712, !1713, !1714, !1715, !1716, !1717, !1718, !1719, !1720, !1721, !1722, !1723, !1724, !1725, !1726}
!1706 = !DIDerivedType(tag: DW_TAG_member, name: "_0", scope: !1704, file: !27, line: 333, baseType: !62, size: 8)
!1707 = !DIDerivedType(tag: DW_TAG_member, name: "c0", scope: !1704, file: !27, line: 334, baseType: !62, size: 8, offset: 8)
!1708 = !DIDerivedType(tag: DW_TAG_member, name: "_1", scope: !1704, file: !27, line: 335, baseType: !62, size: 8, offset: 16)
!1709 = !DIDerivedType(tag: DW_TAG_member, name: "c1", scope: !1704, file: !27, line: 336, baseType: !62, size: 8, offset: 24)
!1710 = !DIDerivedType(tag: DW_TAG_member, name: "_2", scope: !1704, file: !27, line: 337, baseType: !62, size: 8, offset: 32)
!1711 = !DIDerivedType(tag: DW_TAG_member, name: "c2", scope: !1704, file: !27, line: 338, baseType: !62, size: 8, offset: 40)
!1712 = !DIDerivedType(tag: DW_TAG_member, name: "_3", scope: !1704, file: !27, line: 339, baseType: !62, size: 8, offset: 48)
!1713 = !DIDerivedType(tag: DW_TAG_member, name: "c3", scope: !1704, file: !27, line: 340, baseType: !62, size: 8, offset: 56)
!1714 = !DIDerivedType(tag: DW_TAG_member, name: "_4", scope: !1704, file: !27, line: 342, baseType: !62, size: 8, offset: 64)
!1715 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1704, file: !27, line: 343, baseType: !62, size: 8, offset: 72)
!1716 = !DIDerivedType(tag: DW_TAG_member, name: "_5", scope: !1704, file: !27, line: 345, baseType: !62, size: 8, offset: 80)
!1717 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1704, file: !27, line: 346, baseType: !62, size: 8, offset: 88)
!1718 = !DIDerivedType(tag: DW_TAG_member, name: "_6", scope: !1704, file: !27, line: 348, baseType: !62, size: 8, offset: 96)
!1719 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1704, file: !27, line: 349, baseType: !62, size: 8, offset: 104)
!1720 = !DIDerivedType(tag: DW_TAG_member, name: "_7", scope: !1704, file: !27, line: 351, baseType: !62, size: 8, offset: 112)
!1721 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1704, file: !27, line: 352, baseType: !62, size: 8, offset: 120)
!1722 = !DIDerivedType(tag: DW_TAG_member, name: "_8", scope: !1704, file: !27, line: 354, baseType: !62, size: 8, offset: 128)
!1723 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1704, file: !27, line: 355, baseType: !62, size: 8, offset: 136)
!1724 = !DIDerivedType(tag: DW_TAG_member, name: "_9", scope: !1704, file: !27, line: 357, baseType: !62, size: 8, offset: 144)
!1725 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1704, file: !27, line: 358, baseType: !62, size: 8, offset: 152)
!1726 = !DIDerivedType(tag: DW_TAG_member, name: "_padding", scope: !1704, file: !27, line: 360, baseType: !1727, size: 32, offset: 160)
!1727 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 32, elements: !353)
!1728 = !DIDerivedType(tag: DW_TAG_member, name: "xcr0", scope: !1268, file: !27, line: 759, baseType: !1729, size: 64, offset: 22080)
!1729 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "XCR0", file: !27, line: 424, size: 64, elements: !1730, identifier: "_ZTS4XCR0")
!1730 = !{!1731, !1732, !1737}
!1731 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1729, file: !27, line: 425, baseType: !637, size: 64)
!1732 = !DIDerivedType(tag: DW_TAG_member, scope: !1729, file: !27, line: 427, baseType: !1733, size: 64)
!1733 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1729, file: !27, line: 427, size: 64, elements: !1734, identifier: "_ZTSN4XCR0Ut_E")
!1734 = !{!1735, !1736}
!1735 = !DIDerivedType(tag: DW_TAG_member, name: "eax", scope: !1733, file: !27, line: 428, baseType: !8, size: 32)
!1736 = !DIDerivedType(tag: DW_TAG_member, name: "edx", scope: !1733, file: !27, line: 429, baseType: !8, size: 32, offset: 32)
!1737 = !DIDerivedType(tag: DW_TAG_member, scope: !1729, file: !27, line: 433, baseType: !1738, size: 64)
!1738 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1729, file: !27, line: 433, size: 64, elements: !1739, identifier: "_ZTSN4XCR0Ut0_E")
!1739 = !{!1740, !1741, !1742, !1743, !1744, !1745, !1746, !1747, !1748, !1749, !1750, !1751}
!1740 = !DIDerivedType(tag: DW_TAG_member, name: "x87_fpu_mmx", scope: !1738, file: !27, line: 434, baseType: !637, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1741 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1738, file: !27, line: 435, baseType: !637, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1742 = !DIDerivedType(tag: DW_TAG_member, name: "ymm", scope: !1738, file: !27, line: 436, baseType: !637, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1743 = !DIDerivedType(tag: DW_TAG_member, name: "bndreg", scope: !1738, file: !27, line: 437, baseType: !637, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1744 = !DIDerivedType(tag: DW_TAG_member, name: "bndcsr", scope: !1738, file: !27, line: 438, baseType: !637, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1745 = !DIDerivedType(tag: DW_TAG_member, name: "opmask", scope: !1738, file: !27, line: 439, baseType: !637, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1746 = !DIDerivedType(tag: DW_TAG_member, name: "zmm_hi256", scope: !1738, file: !27, line: 440, baseType: !637, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1747 = !DIDerivedType(tag: DW_TAG_member, name: "hi16_zmm", scope: !1738, file: !27, line: 441, baseType: !637, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1748 = !DIDerivedType(tag: DW_TAG_member, name: "pkru", scope: !1738, file: !27, line: 442, baseType: !637, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1749 = !DIDerivedType(tag: DW_TAG_member, name: "_reserved0", scope: !1738, file: !27, line: 443, baseType: !637, size: 53, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1750 = !DIDerivedType(tag: DW_TAG_member, name: "lwp", scope: !1738, file: !27, line: 444, baseType: !637, size: 1, offset: 62, flags: DIFlagBitField, extraData: i64 0)
!1751 = !DIDerivedType(tag: DW_TAG_member, name: "_reserved1", scope: !1738, file: !27, line: 445, baseType: !637, size: 1, offset: 63, flags: DIFlagBitField, extraData: i64 0)
!1752 = !DIDerivedType(tag: DW_TAG_member, name: "x87", scope: !1268, file: !27, line: 760, baseType: !1753, size: 4096, align: 128, offset: 22144)
!1753 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPU", file: !27, line: 314, size: 4096, align: 128, elements: !1754, identifier: "_ZTS3FPU")
!1754 = !{!1755, !1851, !1914}
!1755 = !DIDerivedType(tag: DW_TAG_member, name: "fsave", scope: !1753, file: !27, line: 317, baseType: !1756, size: 4096)
!1756 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 315, size: 4096, elements: !1757, identifier: "_ZTSN3FPUUt_E")
!1757 = !{!1758, !1847}
!1758 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1756, baseType: !1759)
!1759 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFSAVE", file: !27, line: 263, size: 1248, elements: !1760, identifier: "_ZTS8FpuFSAVE")
!1760 = !{!1761, !1779, !1780, !1801, !1802, !1817, !1818, !1819, !1820, !1821, !1822, !1823, !1824}
!1761 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1759, file: !27, line: 264, baseType: !1762, size: 16)
!1762 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUControlWord", file: !27, line: 142, size: 16, elements: !1763, identifier: "_ZTS14FPUControlWord")
!1763 = !{!1764, !1765}
!1764 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1762, file: !27, line: 143, baseType: !28, size: 16)
!1765 = !DIDerivedType(tag: DW_TAG_member, scope: !1762, file: !27, line: 144, baseType: !1766, size: 16)
!1766 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1762, file: !27, line: 144, size: 16, elements: !1767, identifier: "_ZTSN14FPUControlWordUt_E")
!1767 = !{!1768, !1769, !1770, !1771, !1772, !1773, !1774, !1775, !1776, !1777, !1778}
!1768 = !DIDerivedType(tag: DW_TAG_member, name: "im", scope: !1766, file: !27, line: 145, baseType: !28, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1769 = !DIDerivedType(tag: DW_TAG_member, name: "dm", scope: !1766, file: !27, line: 146, baseType: !28, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1770 = !DIDerivedType(tag: DW_TAG_member, name: "zm", scope: !1766, file: !27, line: 147, baseType: !28, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1771 = !DIDerivedType(tag: DW_TAG_member, name: "om", scope: !1766, file: !27, line: 148, baseType: !28, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1772 = !DIDerivedType(tag: DW_TAG_member, name: "um", scope: !1766, file: !27, line: 149, baseType: !28, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1773 = !DIDerivedType(tag: DW_TAG_member, name: "pm", scope: !1766, file: !27, line: 150, baseType: !28, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1774 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1766, file: !27, line: 151, baseType: !28, size: 2, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1775 = !DIDerivedType(tag: DW_TAG_member, name: "pc", scope: !1766, file: !27, line: 152, baseType: !39, size: 2, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1776 = !DIDerivedType(tag: DW_TAG_member, name: "rc", scope: !1766, file: !27, line: 153, baseType: !45, size: 2, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1777 = !DIDerivedType(tag: DW_TAG_member, name: "x", scope: !1766, file: !27, line: 154, baseType: !51, size: 1, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1778 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1766, file: !27, line: 155, baseType: !28, size: 3, offset: 13, flags: DIFlagBitField, extraData: i64 0)
!1779 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1759, file: !27, line: 265, baseType: !28, size: 16, offset: 16)
!1780 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1759, file: !27, line: 266, baseType: !1781, size: 16, offset: 32)
!1781 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUStatusWord", file: !27, line: 100, size: 16, elements: !1782, identifier: "_ZTS13FPUStatusWord")
!1782 = !{!1783, !1784}
!1783 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1781, file: !27, line: 101, baseType: !28, size: 16)
!1784 = !DIDerivedType(tag: DW_TAG_member, scope: !1781, file: !27, line: 102, baseType: !1785, size: 16)
!1785 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1781, file: !27, line: 102, size: 16, elements: !1786, identifier: "_ZTSN13FPUStatusWordUt_E")
!1786 = !{!1787, !1788, !1789, !1790, !1791, !1792, !1793, !1794, !1795, !1796, !1797, !1798, !1799, !1800}
!1787 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1785, file: !27, line: 103, baseType: !28, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1788 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1785, file: !27, line: 104, baseType: !28, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1789 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1785, file: !27, line: 105, baseType: !28, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1790 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1785, file: !27, line: 106, baseType: !28, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1791 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1785, file: !27, line: 107, baseType: !28, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1792 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1785, file: !27, line: 108, baseType: !28, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1793 = !DIDerivedType(tag: DW_TAG_member, name: "sf", scope: !1785, file: !27, line: 109, baseType: !28, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1794 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1785, file: !27, line: 110, baseType: !28, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1795 = !DIDerivedType(tag: DW_TAG_member, name: "c0", scope: !1785, file: !27, line: 111, baseType: !28, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1796 = !DIDerivedType(tag: DW_TAG_member, name: "c1", scope: !1785, file: !27, line: 112, baseType: !28, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1797 = !DIDerivedType(tag: DW_TAG_member, name: "c2", scope: !1785, file: !27, line: 113, baseType: !28, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1798 = !DIDerivedType(tag: DW_TAG_member, name: "top", scope: !1785, file: !27, line: 114, baseType: !28, size: 3, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1799 = !DIDerivedType(tag: DW_TAG_member, name: "c3", scope: !1785, file: !27, line: 115, baseType: !28, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1800 = !DIDerivedType(tag: DW_TAG_member, name: "b", scope: !1785, file: !27, line: 116, baseType: !28, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1801 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1759, file: !27, line: 267, baseType: !28, size: 16, offset: 48)
!1802 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1759, file: !27, line: 268, baseType: !1803, size: 16, offset: 64)
!1803 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUTagWord", file: !27, line: 227, size: 16, elements: !1804, identifier: "_ZTS10FPUTagWord")
!1804 = !{!1805, !1806}
!1805 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1803, file: !27, line: 228, baseType: !28, size: 16)
!1806 = !DIDerivedType(tag: DW_TAG_member, scope: !1803, file: !27, line: 229, baseType: !1807, size: 16)
!1807 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1803, file: !27, line: 229, size: 16, elements: !1808, identifier: "_ZTSN10FPUTagWordUt_E")
!1808 = !{!1809, !1810, !1811, !1812, !1813, !1814, !1815, !1816}
!1809 = !DIDerivedType(tag: DW_TAG_member, name: "tag0", scope: !1807, file: !27, line: 230, baseType: !55, size: 2, flags: DIFlagBitField, extraData: i64 0)
!1810 = !DIDerivedType(tag: DW_TAG_member, name: "tag1", scope: !1807, file: !27, line: 231, baseType: !55, size: 2, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1811 = !DIDerivedType(tag: DW_TAG_member, name: "tag2", scope: !1807, file: !27, line: 232, baseType: !55, size: 2, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1812 = !DIDerivedType(tag: DW_TAG_member, name: "tag3", scope: !1807, file: !27, line: 233, baseType: !55, size: 2, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1813 = !DIDerivedType(tag: DW_TAG_member, name: "tag4", scope: !1807, file: !27, line: 234, baseType: !55, size: 2, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1814 = !DIDerivedType(tag: DW_TAG_member, name: "tag5", scope: !1807, file: !27, line: 235, baseType: !55, size: 2, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1815 = !DIDerivedType(tag: DW_TAG_member, name: "tag6", scope: !1807, file: !27, line: 236, baseType: !55, size: 2, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1816 = !DIDerivedType(tag: DW_TAG_member, name: "tag7", scope: !1807, file: !27, line: 237, baseType: !55, size: 2, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1817 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1759, file: !27, line: 269, baseType: !28, size: 16, offset: 80)
!1818 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1759, file: !27, line: 270, baseType: !8, size: 32, offset: 96)
!1819 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1759, file: !27, line: 271, baseType: !1547, size: 16, offset: 128)
!1820 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd2", scope: !1759, file: !27, line: 272, baseType: !28, size: 16, offset: 144)
!1821 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1759, file: !27, line: 273, baseType: !8, size: 32, offset: 160)
!1822 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1759, file: !27, line: 274, baseType: !1547, size: 16, offset: 192)
!1823 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd3", scope: !1759, file: !27, line: 275, baseType: !28, size: 16, offset: 208)
!1824 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1759, file: !27, line: 276, baseType: !1825, size: 1024, offset: 224)
!1825 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1826, size: 1024, elements: !1310)
!1826 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FPUStackElem", file: !27, line: 162, size: 128, elements: !1827, identifier: "_ZTS12FPUStackElem")
!1827 = !{!1828, !1843}
!1828 = !DIDerivedType(tag: DW_TAG_member, scope: !1826, file: !27, line: 163, baseType: !1829, size: 80)
!1829 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1826, file: !27, line: 163, size: 80, elements: !1830, identifier: "_ZTSN12FPUStackElemUt_E")
!1830 = !{!1831, !1838}
!1831 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1829, file: !27, line: 164, baseType: !1832, size: 80)
!1832 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "float80_t", file: !1266, line: 65, size: 80, elements: !1833, identifier: "_ZTS9float80_t")
!1833 = !{!1834}
!1834 = !DIDerivedType(tag: DW_TAG_member, name: "data", scope: !1832, file: !1266, line: 66, baseType: !1835, size: 80)
!1835 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 80, elements: !1836)
!1836 = !{!1837}
!1837 = !DISubrange(count: 10)
!1838 = !DIDerivedType(tag: DW_TAG_member, scope: !1829, file: !27, line: 165, baseType: !1839, size: 80)
!1839 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1829, file: !27, line: 165, size: 80, elements: !1840, identifier: "_ZTSN12FPUStackElemUt_Ut_E")
!1840 = !{!1841, !1842}
!1841 = !DIDerivedType(tag: DW_TAG_member, name: "mmx", scope: !1839, file: !27, line: 166, baseType: !637, size: 64)
!1842 = !DIDerivedType(tag: DW_TAG_member, name: "infinity", scope: !1839, file: !27, line: 167, baseType: !28, size: 16, offset: 64)
!1843 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd", scope: !1826, file: !27, line: 170, baseType: !1844, size: 48, offset: 80)
!1844 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 48, elements: !1845)
!1845 = !{!1846}
!1846 = !DISubrange(count: 6)
!1847 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1756, file: !27, line: 316, baseType: !1848, size: 2848, offset: 1248)
!1848 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 2848, elements: !1849)
!1849 = !{!1850}
!1850 = !DISubrange(count: 356)
!1851 = !DIDerivedType(tag: DW_TAG_member, name: "fxsave32", scope: !1753, file: !27, line: 321, baseType: !1852, size: 4096)
!1852 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 319, size: 4096, elements: !1853, identifier: "_ZTSN3FPUUt0_E")
!1853 = !{!1854, !1910}
!1854 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1852, baseType: !1855)
!1855 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFXSAVE", file: !27, line: 280, size: 3328, elements: !1856, identifier: "_ZTS9FpuFXSAVE")
!1856 = !{!1857, !1858, !1859, !1874, !1875, !1876, !1877, !1878, !1879, !1880, !1881, !1882, !1906, !1907, !1908}
!1857 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1855, file: !27, line: 281, baseType: !1762, size: 16)
!1858 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1855, file: !27, line: 282, baseType: !1781, size: 16, offset: 16)
!1859 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1855, file: !27, line: 283, baseType: !1860, size: 8, offset: 32)
!1860 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUAbridgedTagWord", file: !27, line: 245, size: 8, elements: !1861, identifier: "_ZTS18FPUAbridgedTagWord")
!1861 = !{!1862, !1863}
!1862 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1860, file: !27, line: 246, baseType: !62, size: 8)
!1863 = !DIDerivedType(tag: DW_TAG_member, scope: !1860, file: !27, line: 247, baseType: !1864, size: 8)
!1864 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1860, file: !27, line: 247, size: 8, elements: !1865, identifier: "_ZTSN18FPUAbridgedTagWordUt_E")
!1865 = !{!1866, !1867, !1868, !1869, !1870, !1871, !1872, !1873}
!1866 = !DIDerivedType(tag: DW_TAG_member, name: "r0", scope: !1864, file: !27, line: 248, baseType: !61, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1867 = !DIDerivedType(tag: DW_TAG_member, name: "r1", scope: !1864, file: !27, line: 249, baseType: !61, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1868 = !DIDerivedType(tag: DW_TAG_member, name: "r2", scope: !1864, file: !27, line: 250, baseType: !61, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1869 = !DIDerivedType(tag: DW_TAG_member, name: "r3", scope: !1864, file: !27, line: 251, baseType: !61, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1870 = !DIDerivedType(tag: DW_TAG_member, name: "r4", scope: !1864, file: !27, line: 252, baseType: !61, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1871 = !DIDerivedType(tag: DW_TAG_member, name: "r5", scope: !1864, file: !27, line: 253, baseType: !61, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1872 = !DIDerivedType(tag: DW_TAG_member, name: "r6", scope: !1864, file: !27, line: 254, baseType: !61, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1873 = !DIDerivedType(tag: DW_TAG_member, name: "r7", scope: !1864, file: !27, line: 255, baseType: !61, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1874 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1855, file: !27, line: 284, baseType: !62, size: 8, offset: 40)
!1875 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1855, file: !27, line: 285, baseType: !28, size: 16, offset: 48)
!1876 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1855, file: !27, line: 286, baseType: !8, size: 32, offset: 64)
!1877 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1855, file: !27, line: 287, baseType: !1547, size: 16, offset: 96)
!1878 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd1", scope: !1855, file: !27, line: 288, baseType: !28, size: 16, offset: 112)
!1879 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1855, file: !27, line: 289, baseType: !8, size: 32, offset: 128)
!1880 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1855, file: !27, line: 290, baseType: !1547, size: 16, offset: 160)
!1881 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd2", scope: !1855, file: !27, line: 291, baseType: !28, size: 16, offset: 176)
!1882 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr", scope: !1855, file: !27, line: 292, baseType: !1883, size: 32, offset: 192)
!1883 = distinct !DICompositeType(tag: DW_TAG_union_type, name: "FPUControlStatus", file: !27, line: 188, size: 32, elements: !1884, identifier: "_ZTS16FPUControlStatus")
!1884 = !{!1885, !1886}
!1885 = !DIDerivedType(tag: DW_TAG_member, name: "flat", scope: !1883, file: !27, line: 189, baseType: !8, size: 32)
!1886 = !DIDerivedType(tag: DW_TAG_member, scope: !1883, file: !27, line: 190, baseType: !1887, size: 32)
!1887 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1883, file: !27, line: 190, size: 32, elements: !1888, identifier: "_ZTSN16FPUControlStatusUt_E")
!1888 = !{!1889, !1890, !1891, !1892, !1893, !1894, !1895, !1896, !1897, !1898, !1899, !1900, !1901, !1902, !1903, !1904, !1905}
!1889 = !DIDerivedType(tag: DW_TAG_member, name: "ie", scope: !1887, file: !27, line: 191, baseType: !8, size: 1, flags: DIFlagBitField, extraData: i64 0)
!1890 = !DIDerivedType(tag: DW_TAG_member, name: "de", scope: !1887, file: !27, line: 192, baseType: !8, size: 1, offset: 1, flags: DIFlagBitField, extraData: i64 0)
!1891 = !DIDerivedType(tag: DW_TAG_member, name: "ze", scope: !1887, file: !27, line: 193, baseType: !8, size: 1, offset: 2, flags: DIFlagBitField, extraData: i64 0)
!1892 = !DIDerivedType(tag: DW_TAG_member, name: "oe", scope: !1887, file: !27, line: 194, baseType: !8, size: 1, offset: 3, flags: DIFlagBitField, extraData: i64 0)
!1893 = !DIDerivedType(tag: DW_TAG_member, name: "ue", scope: !1887, file: !27, line: 195, baseType: !8, size: 1, offset: 4, flags: DIFlagBitField, extraData: i64 0)
!1894 = !DIDerivedType(tag: DW_TAG_member, name: "pe", scope: !1887, file: !27, line: 196, baseType: !8, size: 1, offset: 5, flags: DIFlagBitField, extraData: i64 0)
!1895 = !DIDerivedType(tag: DW_TAG_member, name: "daz", scope: !1887, file: !27, line: 197, baseType: !8, size: 1, offset: 6, flags: DIFlagBitField, extraData: i64 0)
!1896 = !DIDerivedType(tag: DW_TAG_member, name: "im", scope: !1887, file: !27, line: 198, baseType: !8, size: 1, offset: 7, flags: DIFlagBitField, extraData: i64 0)
!1897 = !DIDerivedType(tag: DW_TAG_member, name: "dm", scope: !1887, file: !27, line: 199, baseType: !8, size: 1, offset: 8, flags: DIFlagBitField, extraData: i64 0)
!1898 = !DIDerivedType(tag: DW_TAG_member, name: "zm", scope: !1887, file: !27, line: 200, baseType: !8, size: 1, offset: 9, flags: DIFlagBitField, extraData: i64 0)
!1899 = !DIDerivedType(tag: DW_TAG_member, name: "om", scope: !1887, file: !27, line: 201, baseType: !8, size: 1, offset: 10, flags: DIFlagBitField, extraData: i64 0)
!1900 = !DIDerivedType(tag: DW_TAG_member, name: "um", scope: !1887, file: !27, line: 202, baseType: !8, size: 1, offset: 11, flags: DIFlagBitField, extraData: i64 0)
!1901 = !DIDerivedType(tag: DW_TAG_member, name: "pm", scope: !1887, file: !27, line: 203, baseType: !8, size: 1, offset: 12, flags: DIFlagBitField, extraData: i64 0)
!1902 = !DIDerivedType(tag: DW_TAG_member, name: "rn", scope: !1887, file: !27, line: 204, baseType: !8, size: 1, offset: 13, flags: DIFlagBitField, extraData: i64 0)
!1903 = !DIDerivedType(tag: DW_TAG_member, name: "rp", scope: !1887, file: !27, line: 205, baseType: !8, size: 1, offset: 14, flags: DIFlagBitField, extraData: i64 0)
!1904 = !DIDerivedType(tag: DW_TAG_member, name: "fz", scope: !1887, file: !27, line: 206, baseType: !8, size: 1, offset: 15, flags: DIFlagBitField, extraData: i64 0)
!1905 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd", scope: !1887, file: !27, line: 207, baseType: !8, size: 16, offset: 16, flags: DIFlagBitField, extraData: i64 0)
!1906 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr_mask", scope: !1855, file: !27, line: 293, baseType: !1883, size: 32, offset: 224)
!1907 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1855, file: !27, line: 294, baseType: !1825, size: 1024, offset: 256)
!1908 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1855, file: !27, line: 295, baseType: !1909, size: 2048, offset: 1280)
!1909 = !DICompositeType(tag: DW_TAG_array_type, baseType: !1287, size: 2048, elements: !1303)
!1910 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1852, file: !27, line: 320, baseType: !1911, size: 768, offset: 3328)
!1911 = !DICompositeType(tag: DW_TAG_array_type, baseType: !62, size: 768, elements: !1912)
!1912 = !{!1913}
!1913 = !DISubrange(count: 96)
!1914 = !DIDerivedType(tag: DW_TAG_member, name: "fxsave64", scope: !1753, file: !27, line: 325, baseType: !1915, size: 4096)
!1915 = distinct !DICompositeType(tag: DW_TAG_structure_type, scope: !1753, file: !27, line: 323, size: 4096, elements: !1916, identifier: "_ZTSN3FPUUt1_E")
!1916 = !{!1917, !1931}
!1917 = !DIDerivedType(tag: DW_TAG_inheritance, scope: !1915, baseType: !1918)
!1918 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "FpuFXSAVE64", file: !27, line: 299, size: 3328, elements: !1919, identifier: "_ZTS11FpuFXSAVE64")
!1919 = !{!1920, !1921, !1922, !1923, !1924, !1925, !1926, !1927, !1928, !1929, !1930}
!1920 = !DIDerivedType(tag: DW_TAG_member, name: "cwd", scope: !1918, file: !27, line: 300, baseType: !1762, size: 16)
!1921 = !DIDerivedType(tag: DW_TAG_member, name: "swd", scope: !1918, file: !27, line: 301, baseType: !1781, size: 16, offset: 16)
!1922 = !DIDerivedType(tag: DW_TAG_member, name: "ftw", scope: !1918, file: !27, line: 302, baseType: !1860, size: 8, offset: 32)
!1923 = !DIDerivedType(tag: DW_TAG_member, name: "_rsvd0", scope: !1918, file: !27, line: 303, baseType: !62, size: 8, offset: 40)
!1924 = !DIDerivedType(tag: DW_TAG_member, name: "fop", scope: !1918, file: !27, line: 304, baseType: !28, size: 16, offset: 48)
!1925 = !DIDerivedType(tag: DW_TAG_member, name: "ip", scope: !1918, file: !27, line: 305, baseType: !637, size: 64, offset: 64)
!1926 = !DIDerivedType(tag: DW_TAG_member, name: "dp", scope: !1918, file: !27, line: 306, baseType: !637, size: 64, offset: 128)
!1927 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr", scope: !1918, file: !27, line: 307, baseType: !1883, size: 32, offset: 192)
!1928 = !DIDerivedType(tag: DW_TAG_member, name: "mxcsr_mask", scope: !1918, file: !27, line: 308, baseType: !1883, size: 32, offset: 224)
!1929 = !DIDerivedType(tag: DW_TAG_member, name: "st", scope: !1918, file: !27, line: 309, baseType: !1825, size: 1024, offset: 256)
!1930 = !DIDerivedType(tag: DW_TAG_member, name: "xmm", scope: !1918, file: !27, line: 310, baseType: !1909, size: 2048, offset: 1280)
!1931 = !DIDerivedType(tag: DW_TAG_member, name: "_padding0", scope: !1915, file: !27, line: 324, baseType: !1911, size: 768, offset: 3328)
!1932 = !DIDerivedType(tag: DW_TAG_member, name: "seg_caches", scope: !1268, file: !27, line: 761, baseType: !1933, size: 768, align: 64, offset: 26240)
!1933 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "SegmentCaches", file: !27, line: 468, size: 768, align: 64, elements: !1934, identifier: "_ZTS13SegmentCaches")
!1934 = !{!1935, !1945, !1946, !1947, !1948, !1949}
!1935 = !DIDerivedType(tag: DW_TAG_member, name: "cs", scope: !1933, file: !27, line: 469, baseType: !1936, size: 128)
!1936 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "SegmentShadow", file: !27, line: 88, size: 128, elements: !1937, identifier: "_ZTS13SegmentShadow")
!1937 = !{!1938, !1943, !1944}
!1938 = !DIDerivedType(tag: DW_TAG_member, name: "base", scope: !1936, file: !27, line: 92, baseType: !1939, size: 64)
!1939 = distinct !DICompositeType(tag: DW_TAG_union_type, scope: !1936, file: !27, line: 89, size: 64, elements: !1940, identifier: "_ZTSN13SegmentShadowUt_E")
!1940 = !{!1941, !1942}
!1941 = !DIDerivedType(tag: DW_TAG_member, name: "dword", scope: !1939, file: !27, line: 90, baseType: !8, size: 32)
!1942 = !DIDerivedType(tag: DW_TAG_member, name: "qword", scope: !1939, file: !27, line: 91, baseType: !637, size: 64)
!1943 = !DIDerivedType(tag: DW_TAG_member, name: "limit", scope: !1936, file: !27, line: 93, baseType: !8, size: 32, offset: 64)
!1944 = !DIDerivedType(tag: DW_TAG_member, name: "flags", scope: !1936, file: !27, line: 94, baseType: !8, size: 32, offset: 96)
!1945 = !DIDerivedType(tag: DW_TAG_member, name: "ss", scope: !1933, file: !27, line: 470, baseType: !1936, size: 128, offset: 128)
!1946 = !DIDerivedType(tag: DW_TAG_member, name: "ds", scope: !1933, file: !27, line: 471, baseType: !1936, size: 128, offset: 256)
!1947 = !DIDerivedType(tag: DW_TAG_member, name: "es", scope: !1933, file: !27, line: 472, baseType: !1936, size: 128, offset: 384)
!1948 = !DIDerivedType(tag: DW_TAG_member, name: "fs", scope: !1933, file: !27, line: 473, baseType: !1936, size: 128, offset: 512)
!1949 = !DIDerivedType(tag: DW_TAG_member, name: "gs", scope: !1933, file: !27, line: 474, baseType: !1936, size: 128, offset: 640)
!1950 = !DIDerivedType(tag: DW_TAG_typedef, name: "addr_t", file: !1266, line: 42, baseType: !1951)
!1951 = !DIDerivedType(tag: DW_TAG_typedef, name: "addr64_t", file: !1266, line: 41, baseType: !637)
!1952 = !DILocation(line: 54, column: 8, scope: !1261)
!1953 = !DILocation(line: 55, column: 10, scope: !1261)
!1954 = !DILocation(line: 56, column: 10, scope: !1261)
!1955 = !DILocation(line: 57, column: 10, scope: !1261)
!1956 = !DILocation(line: 58, column: 10, scope: !1261)
!1957 = !DILocation(line: 61, column: 9, scope: !1261)
!1958 = !DILocation(line: 62, column: 9, scope: !1261)
!1959 = !DILocation(line: 63, column: 20, scope: !1261)
!1960 = !DILocation(line: 63, column: 24, scope: !1261)
!1961 = !DILocation(line: 63, column: 28, scope: !1261)
!1962 = !DILocation(line: 69, column: 6, scope: !1261)
!1963 = !DILocation(line: 74, column: 20, scope: !1261)
!1964 = !DILocation(line: 74, column: 24, scope: !1261)
!1965 = !DILocation(line: 74, column: 28, scope: !1261)
!1966 = !DILocation(line: 74, column: 33, scope: !1261)
!1967 = !DILocation(line: 75, column: 20, scope: !1261)
!1968 = !DILocation(line: 75, column: 24, scope: !1261)
!1969 = !DILocation(line: 75, column: 28, scope: !1261)
!1970 = !DILocation(line: 75, column: 33, scope: !1261)
!1971 = !DILocation(line: 76, column: 20, scope: !1261)
!1972 = !DILocation(line: 76, column: 24, scope: !1261)
!1973 = !DILocation(line: 76, column: 28, scope: !1261)
!1974 = !DILocation(line: 76, column: 33, scope: !1261)
!1975 = !DILocation(line: 77, column: 20, scope: !1261)
!1976 = !DILocation(line: 77, column: 24, scope: !1261)
!1977 = !DILocation(line: 77, column: 28, scope: !1261)
!1978 = !DILocation(line: 77, column: 33, scope: !1261)
!1979 = !DILocation(line: 78, column: 20, scope: !1261)
!1980 = !DILocation(line: 78, column: 24, scope: !1261)
!1981 = !DILocation(line: 78, column: 28, scope: !1261)
!1982 = !DILocation(line: 78, column: 33, scope: !1261)
!1983 = !DILocation(line: 79, column: 20, scope: !1261)
!1984 = !DILocation(line: 79, column: 24, scope: !1261)
!1985 = !DILocation(line: 79, column: 28, scope: !1261)
!1986 = !DILocation(line: 79, column: 33, scope: !1261)
!1987 = !DILocation(line: 80, column: 20, scope: !1261)
!1988 = !DILocation(line: 80, column: 24, scope: !1261)
!1989 = !DILocation(line: 80, column: 28, scope: !1261)
!1990 = !DILocation(line: 80, column: 33, scope: !1261)
!1991 = !DILocation(line: 81, column: 20, scope: !1261)
!1992 = !DILocation(line: 81, column: 24, scope: !1261)
!1993 = !DILocation(line: 81, column: 28, scope: !1261)
!1994 = !DILocation(line: 81, column: 33, scope: !1261)
!1995 = !DILocation(line: 83, column: 21, scope: !1261)
!1996 = !DILocation(line: 83, column: 25, scope: !1261)
!1997 = !DILocation(line: 83, column: 29, scope: !1261)
!1998 = !DILocation(line: 83, column: 34, scope: !1261)
!1999 = !DILocation(line: 84, column: 21, scope: !1261)
!2000 = !DILocation(line: 84, column: 25, scope: !1261)
!2001 = !DILocation(line: 84, column: 29, scope: !1261)
!2002 = !DILocation(line: 84, column: 34, scope: !1261)
!2003 = !DILocation(line: 85, column: 21, scope: !1261)
!2004 = !DILocation(line: 85, column: 25, scope: !1261)
!2005 = !DILocation(line: 85, column: 29, scope: !1261)
!2006 = !DILocation(line: 85, column: 34, scope: !1261)
!2007 = !DILocation(line: 86, column: 21, scope: !1261)
!2008 = !DILocation(line: 86, column: 25, scope: !1261)
!2009 = !DILocation(line: 86, column: 29, scope: !1261)
!2010 = !DILocation(line: 86, column: 34, scope: !1261)
!2011 = !DILocation(line: 87, column: 21, scope: !1261)
!2012 = !DILocation(line: 87, column: 25, scope: !1261)
!2013 = !DILocation(line: 87, column: 28, scope: !1261)
!2014 = !DILocation(line: 87, column: 33, scope: !1261)
!2015 = !DILocation(line: 88, column: 21, scope: !1261)
!2016 = !DILocation(line: 88, column: 25, scope: !1261)
!2017 = !DILocation(line: 88, column: 28, scope: !1261)
!2018 = !DILocation(line: 88, column: 33, scope: !1261)
!2019 = !DILocation(line: 89, column: 22, scope: !1261)
!2020 = !DILocation(line: 89, column: 26, scope: !1261)
!2021 = !DILocation(line: 89, column: 30, scope: !1261)
!2022 = !DILocation(line: 89, column: 35, scope: !1261)
!2023 = !DILocation(line: 90, column: 22, scope: !1261)
!2024 = !DILocation(line: 90, column: 26, scope: !1261)
!2025 = !DILocation(line: 90, column: 30, scope: !1261)
!2026 = !DILocation(line: 90, column: 35, scope: !1261)
!2027 = !DILocation(line: 91, column: 22, scope: !1261)
!2028 = !DILocation(line: 91, column: 26, scope: !1261)
!2029 = !DILocation(line: 91, column: 30, scope: !1261)
!2030 = !DILocation(line: 91, column: 35, scope: !1261)
!2031 = !DILocation(line: 92, column: 22, scope: !1261)
!2032 = !DILocation(line: 92, column: 26, scope: !1261)
!2033 = !DILocation(line: 92, column: 30, scope: !1261)
!2034 = !DILocation(line: 92, column: 35, scope: !1261)
!2035 = !DILocation(line: 93, column: 22, scope: !1261)
!2036 = !DILocation(line: 93, column: 26, scope: !1261)
!2037 = !DILocation(line: 93, column: 30, scope: !1261)
!2038 = !DILocation(line: 93, column: 35, scope: !1261)
!2039 = !DILocation(line: 94, column: 22, scope: !1261)
!2040 = !DILocation(line: 94, column: 26, scope: !1261)
!2041 = !DILocation(line: 94, column: 30, scope: !1261)
!2042 = !DILocation(line: 94, column: 35, scope: !1261)
!2043 = !DILocation(line: 96, column: 20, scope: !1261)
!2044 = !DILocation(line: 96, column: 24, scope: !1261)
!2045 = !DILocation(line: 96, column: 28, scope: !1261)
!2046 = !DILocation(line: 97, column: 20, scope: !1261)
!2047 = !DILocation(line: 97, column: 24, scope: !1261)
!2048 = !DILocation(line: 97, column: 28, scope: !1261)
!2049 = !DILocation(line: 98, column: 20, scope: !1261)
!2050 = !DILocation(line: 98, column: 24, scope: !1261)
!2051 = !DILocation(line: 98, column: 28, scope: !1261)
!2052 = !DILocation(line: 99, column: 20, scope: !1261)
!2053 = !DILocation(line: 99, column: 24, scope: !1261)
!2054 = !DILocation(line: 99, column: 28, scope: !1261)
!2055 = !DILocation(line: 100, column: 20, scope: !1261)
!2056 = !DILocation(line: 100, column: 24, scope: !1261)
!2057 = !DILocation(line: 100, column: 28, scope: !1261)
!2058 = !DILocation(line: 101, column: 20, scope: !1261)
!2059 = !DILocation(line: 101, column: 24, scope: !1261)
!2060 = !DILocation(line: 101, column: 28, scope: !1261)
!2061 = !DILocation(line: 102, column: 20, scope: !1261)
!2062 = !DILocation(line: 102, column: 24, scope: !1261)
!2063 = !DILocation(line: 102, column: 28, scope: !1261)
!2064 = !DILocation(line: 103, column: 20, scope: !1261)
!2065 = !DILocation(line: 103, column: 24, scope: !1261)
!2066 = !DILocation(line: 103, column: 28, scope: !1261)
!2067 = !DILocation(line: 105, column: 21, scope: !1261)
!2068 = !DILocation(line: 105, column: 25, scope: !1261)
!2069 = !DILocation(line: 105, column: 28, scope: !1261)
!2070 = !DILocation(line: 106, column: 21, scope: !1261)
!2071 = !DILocation(line: 106, column: 25, scope: !1261)
!2072 = !DILocation(line: 106, column: 28, scope: !1261)
!2073 = !DILocation(line: 107, column: 22, scope: !1261)
!2074 = !DILocation(line: 107, column: 26, scope: !1261)
!2075 = !DILocation(line: 107, column: 30, scope: !1261)
!2076 = !DILocation(line: 108, column: 22, scope: !1261)
!2077 = !DILocation(line: 108, column: 26, scope: !1261)
!2078 = !DILocation(line: 108, column: 30, scope: !1261)
!2079 = !DILocation(line: 109, column: 22, scope: !1261)
!2080 = !DILocation(line: 109, column: 26, scope: !1261)
!2081 = !DILocation(line: 109, column: 30, scope: !1261)
!2082 = !DILocation(line: 110, column: 22, scope: !1261)
!2083 = !DILocation(line: 110, column: 26, scope: !1261)
!2084 = !DILocation(line: 110, column: 30, scope: !1261)
!2085 = !DILocation(line: 111, column: 22, scope: !1261)
!2086 = !DILocation(line: 111, column: 26, scope: !1261)
!2087 = !DILocation(line: 111, column: 30, scope: !1261)
!2088 = !DILocation(line: 112, column: 22, scope: !1261)
!2089 = !DILocation(line: 112, column: 26, scope: !1261)
!2090 = !DILocation(line: 112, column: 30, scope: !1261)
!2091 = !DILocation(line: 114, column: 20, scope: !1261)
!2092 = !DILocation(line: 114, column: 24, scope: !1261)
!2093 = !DILocation(line: 114, column: 28, scope: !1261)
!2094 = !DILocation(line: 116, column: 21, scope: !1261)
!2095 = !DILocation(line: 116, column: 25, scope: !1261)
!2096 = !DILocation(line: 116, column: 29, scope: !1261)
!2097 = !DILocation(line: 117, column: 21, scope: !1261)
!2098 = !DILocation(line: 117, column: 25, scope: !1261)
!2099 = !DILocation(line: 117, column: 29, scope: !1261)
!2100 = !DILocation(line: 118, column: 21, scope: !1261)
!2101 = !DILocation(line: 118, column: 25, scope: !1261)
!2102 = !DILocation(line: 118, column: 29, scope: !1261)
!2103 = !DILocation(line: 119, column: 21, scope: !1261)
!2104 = !DILocation(line: 119, column: 25, scope: !1261)
!2105 = !DILocation(line: 119, column: 29, scope: !1261)
!2106 = !DILocation(line: 120, column: 21, scope: !1261)
!2107 = !DILocation(line: 120, column: 25, scope: !1261)
!2108 = !DILocation(line: 120, column: 29, scope: !1261)
!2109 = !DILocation(line: 121, column: 21, scope: !1261)
!2110 = !DILocation(line: 121, column: 25, scope: !1261)
!2111 = !DILocation(line: 121, column: 29, scope: !1261)
!2112 = !DILocation(line: 122, column: 21, scope: !1261)
!2113 = !DILocation(line: 122, column: 25, scope: !1261)
!2114 = !DILocation(line: 122, column: 29, scope: !1261)
!2115 = !DILocation(line: 123, column: 21, scope: !1261)
!2116 = !DILocation(line: 123, column: 25, scope: !1261)
!2117 = !DILocation(line: 123, column: 29, scope: !1261)
!2118 = !DILocation(line: 124, column: 21, scope: !1261)
!2119 = !DILocation(line: 124, column: 25, scope: !1261)
!2120 = !DILocation(line: 124, column: 29, scope: !1261)
!2121 = !DILocation(line: 127, column: 21, scope: !1261)
!2122 = !DILocation(line: 127, column: 25, scope: !1261)
!2123 = !DILocation(line: 127, column: 28, scope: !1261)
!2124 = !DILocation(line: 128, column: 21, scope: !1261)
!2125 = !DILocation(line: 128, column: 25, scope: !1261)
!2126 = !DILocation(line: 128, column: 28, scope: !1261)
!2127 = !DILocation(line: 129, column: 22, scope: !1261)
!2128 = !DILocation(line: 129, column: 26, scope: !1261)
!2129 = !DILocation(line: 129, column: 30, scope: !1261)
!2130 = !DILocation(line: 130, column: 22, scope: !1261)
!2131 = !DILocation(line: 130, column: 26, scope: !1261)
!2132 = !DILocation(line: 130, column: 30, scope: !1261)
!2133 = !DILocation(line: 131, column: 22, scope: !1261)
!2134 = !DILocation(line: 131, column: 26, scope: !1261)
!2135 = !DILocation(line: 131, column: 30, scope: !1261)
!2136 = !DILocation(line: 132, column: 22, scope: !1261)
!2137 = !DILocation(line: 132, column: 26, scope: !1261)
!2138 = !DILocation(line: 132, column: 30, scope: !1261)
!2139 = !DILocation(line: 133, column: 22, scope: !1261)
!2140 = !DILocation(line: 133, column: 26, scope: !1261)
!2141 = !DILocation(line: 133, column: 30, scope: !1261)
!2142 = !DILocation(line: 134, column: 22, scope: !1261)
!2143 = !DILocation(line: 134, column: 26, scope: !1261)
!2144 = !DILocation(line: 134, column: 30, scope: !1261)
!2145 = !DILocation(line: 136, column: 21, scope: !1261)
!2146 = !DILocation(line: 136, column: 25, scope: !1261)
!2147 = !DILocation(line: 136, column: 29, scope: !1261)
!2148 = !DILocation(line: 137, column: 21, scope: !1261)
!2149 = !DILocation(line: 137, column: 25, scope: !1261)
!2150 = !DILocation(line: 137, column: 29, scope: !1261)
!2151 = !DILocation(line: 138, column: 21, scope: !1261)
!2152 = !DILocation(line: 138, column: 25, scope: !1261)
!2153 = !DILocation(line: 138, column: 29, scope: !1261)
!2154 = !DILocation(line: 139, column: 21, scope: !1261)
!2155 = !DILocation(line: 139, column: 25, scope: !1261)
!2156 = !DILocation(line: 139, column: 29, scope: !1261)
!2157 = !DILocation(line: 140, column: 21, scope: !1261)
!2158 = !DILocation(line: 140, column: 25, scope: !1261)
!2159 = !DILocation(line: 140, column: 29, scope: !1261)
!2160 = !DILocation(line: 141, column: 21, scope: !1261)
!2161 = !DILocation(line: 141, column: 25, scope: !1261)
!2162 = !DILocation(line: 141, column: 29, scope: !1261)
!2163 = !DILocation(line: 142, column: 21, scope: !1261)
!2164 = !DILocation(line: 142, column: 25, scope: !1261)
!2165 = !DILocation(line: 142, column: 29, scope: !1261)
!2166 = !DILocation(line: 143, column: 21, scope: !1261)
!2167 = !DILocation(line: 143, column: 25, scope: !1261)
!2168 = !DILocation(line: 143, column: 29, scope: !1261)
!2169 = !DILocation(line: 144, column: 20, scope: !1261)
!2170 = !DILocation(line: 144, column: 24, scope: !1261)
!2171 = !DILocation(line: 144, column: 27, scope: !1261)
!2172 = !DILocation(line: 145, column: 20, scope: !1261)
!2173 = !DILocation(line: 145, column: 24, scope: !1261)
!2174 = !DILocation(line: 145, column: 27, scope: !1261)
!2175 = !DILocation(line: 146, column: 21, scope: !1261)
!2176 = !DILocation(line: 146, column: 25, scope: !1261)
!2177 = !DILocation(line: 146, column: 29, scope: !1261)
!2178 = !DILocation(line: 147, column: 21, scope: !1261)
!2179 = !DILocation(line: 147, column: 25, scope: !1261)
!2180 = !DILocation(line: 147, column: 29, scope: !1261)
!2181 = !DILocation(line: 148, column: 21, scope: !1261)
!2182 = !DILocation(line: 148, column: 25, scope: !1261)
!2183 = !DILocation(line: 148, column: 29, scope: !1261)
!2184 = !DILocation(line: 149, column: 21, scope: !1261)
!2185 = !DILocation(line: 149, column: 25, scope: !1261)
!2186 = !DILocation(line: 149, column: 29, scope: !1261)
!2187 = !DILocation(line: 150, column: 21, scope: !1261)
!2188 = !DILocation(line: 150, column: 25, scope: !1261)
!2189 = !DILocation(line: 150, column: 29, scope: !1261)
!2190 = !DILocation(line: 151, column: 21, scope: !1261)
!2191 = !DILocation(line: 151, column: 25, scope: !1261)
!2192 = !DILocation(line: 151, column: 29, scope: !1261)
!2193 = !DILocation(line: 152, column: 21, scope: !1261)
!2194 = !DILocation(line: 152, column: 25, scope: !1261)
!2195 = !DILocation(line: 152, column: 29, scope: !1261)
!2196 = !DILocation(line: 155, column: 20, scope: !1261)
!2197 = !DILocation(line: 155, column: 24, scope: !1261)
!2198 = !DILocation(line: 155, column: 27, scope: !1261)
!2199 = !DILocation(line: 156, column: 20, scope: !1261)
!2200 = !DILocation(line: 156, column: 24, scope: !1261)
!2201 = !DILocation(line: 156, column: 27, scope: !1261)
!2202 = !DILocation(line: 157, column: 20, scope: !1261)
!2203 = !DILocation(line: 157, column: 24, scope: !1261)
!2204 = !DILocation(line: 157, column: 27, scope: !1261)
!2205 = !DILocation(line: 158, column: 20, scope: !1261)
!2206 = !DILocation(line: 158, column: 24, scope: !1261)
!2207 = !DILocation(line: 158, column: 27, scope: !1261)
!2208 = !DILocation(line: 159, column: 20, scope: !1261)
!2209 = !DILocation(line: 159, column: 24, scope: !1261)
!2210 = !DILocation(line: 159, column: 27, scope: !1261)
!2211 = !DILocation(line: 160, column: 20, scope: !1261)
!2212 = !DILocation(line: 160, column: 24, scope: !1261)
!2213 = !DILocation(line: 160, column: 27, scope: !1261)
!2214 = !DILocation(line: 164, column: 25, scope: !1261)
!2215 = !DILocation(line: 164, column: 30, scope: !1261)
!2216 = !DILocation(line: 164, column: 38, scope: !1261)
!2217 = !DILocation(line: 165, column: 25, scope: !1261)
!2218 = !DILocation(line: 165, column: 30, scope: !1261)
!2219 = !DILocation(line: 165, column: 38, scope: !1261)
!2220 = !DILocation(line: 205, column: 22, scope: !1261)
!2221 = !DILocation(line: 205, column: 16, scope: !1261)
!2222 = !DILocation(line: 205, column: 29, scope: !1261)
!2223 = !DILocation(line: 206, column: 22, scope: !1261)
!2224 = !DILocation(line: 206, column: 16, scope: !1261)
!2225 = !DILocation(line: 206, column: 29, scope: !1261)
!2226 = !DILocation(line: 207, column: 22, scope: !1261)
!2227 = !DILocation(line: 207, column: 16, scope: !1261)
!2228 = !DILocation(line: 207, column: 29, scope: !1261)
!2229 = !DILocation(line: 208, column: 22, scope: !1261)
!2230 = !DILocation(line: 208, column: 16, scope: !1261)
!2231 = !DILocation(line: 208, column: 29, scope: !1261)
!2232 = !DILocation(line: 209, column: 22, scope: !1261)
!2233 = !DILocation(line: 209, column: 16, scope: !1261)
!2234 = !DILocation(line: 209, column: 29, scope: !1261)
!2235 = !DILocation(line: 210, column: 22, scope: !1261)
!2236 = !DILocation(line: 210, column: 16, scope: !1261)
!2237 = !DILocation(line: 210, column: 29, scope: !1261)
!2238 = !DILocation(line: 211, column: 22, scope: !1261)
!2239 = !DILocation(line: 211, column: 16, scope: !1261)
!2240 = !DILocation(line: 211, column: 29, scope: !1261)
!2241 = !DILocation(line: 212, column: 22, scope: !1261)
!2242 = !DILocation(line: 212, column: 16, scope: !1261)
!2243 = !DILocation(line: 212, column: 29, scope: !1261)
!2244 = !DILocation(line: 214, column: 22, scope: !1261)
!2245 = !DILocation(line: 214, column: 16, scope: !1261)
!2246 = !DILocation(line: 214, column: 29, scope: !1261)
!2247 = !DILocation(line: 215, column: 22, scope: !1261)
!2248 = !DILocation(line: 215, column: 16, scope: !1261)
!2249 = !DILocation(line: 215, column: 29, scope: !1261)
!2250 = !DILocation(line: 216, column: 23, scope: !1261)
!2251 = !DILocation(line: 216, column: 17, scope: !1261)
!2252 = !DILocation(line: 216, column: 31, scope: !1261)
!2253 = !DILocation(line: 217, column: 23, scope: !1261)
!2254 = !DILocation(line: 217, column: 17, scope: !1261)
!2255 = !DILocation(line: 217, column: 31, scope: !1261)
!2256 = !DILocation(line: 218, column: 23, scope: !1261)
!2257 = !DILocation(line: 218, column: 17, scope: !1261)
!2258 = !DILocation(line: 218, column: 31, scope: !1261)
!2259 = !DILocation(line: 219, column: 23, scope: !1261)
!2260 = !DILocation(line: 219, column: 17, scope: !1261)
!2261 = !DILocation(line: 219, column: 31, scope: !1261)
!2262 = !DILocation(line: 220, column: 23, scope: !1261)
!2263 = !DILocation(line: 220, column: 17, scope: !1261)
!2264 = !DILocation(line: 220, column: 31, scope: !1261)
!2265 = !DILocation(line: 221, column: 23, scope: !1261)
!2266 = !DILocation(line: 221, column: 17, scope: !1261)
!2267 = !DILocation(line: 221, column: 31, scope: !1261)
!2268 = !DILocation(line: 245, column: 22, scope: !1261)
!2269 = !DILocation(line: 245, column: 16, scope: !1261)
!2270 = !DILocation(line: 245, column: 29, scope: !1261)
!2271 = !DILocation(line: 246, column: 22, scope: !1261)
!2272 = !DILocation(line: 246, column: 16, scope: !1261)
!2273 = !DILocation(line: 246, column: 29, scope: !1261)
!2274 = !DILocation(line: 247, column: 22, scope: !1261)
!2275 = !DILocation(line: 247, column: 16, scope: !1261)
!2276 = !DILocation(line: 247, column: 29, scope: !1261)
!2277 = !DILocation(line: 248, column: 22, scope: !1261)
!2278 = !DILocation(line: 248, column: 16, scope: !1261)
!2279 = !DILocation(line: 248, column: 29, scope: !1261)
!2280 = !DILocation(line: 249, column: 22, scope: !1261)
!2281 = !DILocation(line: 249, column: 16, scope: !1261)
!2282 = !DILocation(line: 249, column: 29, scope: !1261)
!2283 = !DILocation(line: 250, column: 22, scope: !1261)
!2284 = !DILocation(line: 250, column: 16, scope: !1261)
!2285 = !DILocation(line: 250, column: 29, scope: !1261)
!2286 = !DILocation(line: 251, column: 22, scope: !1261)
!2287 = !DILocation(line: 251, column: 16, scope: !1261)
!2288 = !DILocation(line: 251, column: 29, scope: !1261)
!2289 = !DILocation(line: 252, column: 22, scope: !1261)
!2290 = !DILocation(line: 252, column: 16, scope: !1261)
!2291 = !DILocation(line: 252, column: 29, scope: !1261)
!2292 = !DILocation(line: 255, column: 22, scope: !1261)
!2293 = !DILocation(line: 255, column: 16, scope: !1261)
!2294 = !DILocation(line: 255, column: 29, scope: !1261)
!2295 = !DILocation(line: 256, column: 22, scope: !1261)
!2296 = !DILocation(line: 256, column: 16, scope: !1261)
!2297 = !DILocation(line: 256, column: 29, scope: !1261)
!2298 = !DILocation(line: 257, column: 23, scope: !1261)
!2299 = !DILocation(line: 257, column: 17, scope: !1261)
!2300 = !DILocation(line: 257, column: 31, scope: !1261)
!2301 = !DILocation(line: 258, column: 23, scope: !1261)
!2302 = !DILocation(line: 258, column: 17, scope: !1261)
!2303 = !DILocation(line: 258, column: 31, scope: !1261)
!2304 = !DILocation(line: 259, column: 23, scope: !1261)
!2305 = !DILocation(line: 259, column: 17, scope: !1261)
!2306 = !DILocation(line: 259, column: 31, scope: !1261)
!2307 = !DILocation(line: 260, column: 23, scope: !1261)
!2308 = !DILocation(line: 260, column: 17, scope: !1261)
!2309 = !DILocation(line: 260, column: 31, scope: !1261)
!2310 = !DILocation(line: 261, column: 23, scope: !1261)
!2311 = !DILocation(line: 261, column: 17, scope: !1261)
!2312 = !DILocation(line: 261, column: 31, scope: !1261)
!2313 = !DILocation(line: 262, column: 23, scope: !1261)
!2314 = !DILocation(line: 262, column: 17, scope: !1261)
!2315 = !DILocation(line: 262, column: 31, scope: !1261)
!2316 = !DILocation(line: 285, column: 21, scope: !1261)
!2317 = !DILocation(line: 285, column: 24, scope: !1261)
!2318 = !DILocation(line: 285, column: 15, scope: !1261)
!2319 = !DILocation(line: 285, column: 33, scope: !1261)
!2320 = !DILocation(line: 286, column: 21, scope: !1261)
!2321 = !DILocation(line: 286, column: 24, scope: !1261)
!2322 = !DILocation(line: 286, column: 15, scope: !1261)
!2323 = !DILocation(line: 286, column: 33, scope: !1261)
!2324 = !DILocation(line: 287, column: 21, scope: !1261)
!2325 = !DILocation(line: 287, column: 24, scope: !1261)
!2326 = !DILocation(line: 287, column: 15, scope: !1261)
!2327 = !DILocation(line: 287, column: 33, scope: !1261)
!2328 = !DILocation(line: 288, column: 21, scope: !1261)
!2329 = !DILocation(line: 288, column: 24, scope: !1261)
!2330 = !DILocation(line: 288, column: 15, scope: !1261)
!2331 = !DILocation(line: 288, column: 33, scope: !1261)
!2332 = !DILocation(line: 289, column: 21, scope: !1261)
!2333 = !DILocation(line: 289, column: 24, scope: !1261)
!2334 = !DILocation(line: 289, column: 15, scope: !1261)
!2335 = !DILocation(line: 289, column: 33, scope: !1261)
!2336 = !DILocation(line: 290, column: 21, scope: !1261)
!2337 = !DILocation(line: 290, column: 24, scope: !1261)
!2338 = !DILocation(line: 290, column: 15, scope: !1261)
!2339 = !DILocation(line: 290, column: 33, scope: !1261)
!2340 = !DILocation(line: 291, column: 21, scope: !1261)
!2341 = !DILocation(line: 291, column: 24, scope: !1261)
!2342 = !DILocation(line: 291, column: 15, scope: !1261)
!2343 = !DILocation(line: 291, column: 33, scope: !1261)
!2344 = !DILocation(line: 292, column: 21, scope: !1261)
!2345 = !DILocation(line: 292, column: 24, scope: !1261)
!2346 = !DILocation(line: 292, column: 15, scope: !1261)
!2347 = !DILocation(line: 292, column: 33, scope: !1261)
!2348 = !DILocation(line: 318, column: 21, scope: !1261)
!2349 = !DILocation(line: 318, column: 25, scope: !1261)
!2350 = !DILocation(line: 318, column: 15, scope: !1261)
!2351 = !DILocation(line: 318, column: 34, scope: !1261)
!2352 = !DILocation(line: 318, column: 38, scope: !1261)
!2353 = !DILocation(line: 318, column: 45, scope: !1261)
!2354 = !DILocation(line: 319, column: 21, scope: !1261)
!2355 = !DILocation(line: 319, column: 25, scope: !1261)
!2356 = !DILocation(line: 319, column: 15, scope: !1261)
!2357 = !DILocation(line: 319, column: 34, scope: !1261)
!2358 = !DILocation(line: 319, column: 38, scope: !1261)
!2359 = !DILocation(line: 319, column: 45, scope: !1261)
!2360 = !DILocation(line: 320, column: 21, scope: !1261)
!2361 = !DILocation(line: 320, column: 25, scope: !1261)
!2362 = !DILocation(line: 320, column: 15, scope: !1261)
!2363 = !DILocation(line: 320, column: 34, scope: !1261)
!2364 = !DILocation(line: 320, column: 38, scope: !1261)
!2365 = !DILocation(line: 320, column: 45, scope: !1261)
!2366 = !DILocation(line: 321, column: 21, scope: !1261)
!2367 = !DILocation(line: 321, column: 25, scope: !1261)
!2368 = !DILocation(line: 321, column: 15, scope: !1261)
!2369 = !DILocation(line: 321, column: 34, scope: !1261)
!2370 = !DILocation(line: 321, column: 38, scope: !1261)
!2371 = !DILocation(line: 321, column: 45, scope: !1261)
!2372 = !DILocation(line: 322, column: 21, scope: !1261)
!2373 = !DILocation(line: 322, column: 25, scope: !1261)
!2374 = !DILocation(line: 322, column: 15, scope: !1261)
!2375 = !DILocation(line: 322, column: 34, scope: !1261)
!2376 = !DILocation(line: 322, column: 38, scope: !1261)
!2377 = !DILocation(line: 322, column: 45, scope: !1261)
!2378 = !DILocation(line: 323, column: 21, scope: !1261)
!2379 = !DILocation(line: 323, column: 25, scope: !1261)
!2380 = !DILocation(line: 323, column: 15, scope: !1261)
!2381 = !DILocation(line: 323, column: 34, scope: !1261)
!2382 = !DILocation(line: 323, column: 38, scope: !1261)
!2383 = !DILocation(line: 323, column: 45, scope: !1261)
!2384 = !DILocation(line: 324, column: 21, scope: !1261)
!2385 = !DILocation(line: 324, column: 25, scope: !1261)
!2386 = !DILocation(line: 324, column: 15, scope: !1261)
!2387 = !DILocation(line: 324, column: 34, scope: !1261)
!2388 = !DILocation(line: 324, column: 38, scope: !1261)
!2389 = !DILocation(line: 324, column: 45, scope: !1261)
!2390 = !DILocation(line: 325, column: 21, scope: !1261)
!2391 = !DILocation(line: 325, column: 25, scope: !1261)
!2392 = !DILocation(line: 325, column: 15, scope: !1261)
!2393 = !DILocation(line: 325, column: 34, scope: !1261)
!2394 = !DILocation(line: 325, column: 38, scope: !1261)
!2395 = !DILocation(line: 325, column: 45, scope: !1261)
!2396 = !DILocation(line: 328, column: 20, scope: !1261)
!2397 = !DILocation(line: 328, column: 26, scope: !1261)
!2398 = !DILocation(line: 329, column: 20, scope: !1261)
!2399 = !DILocation(line: 329, column: 26, scope: !1261)
!2400 = !DILocation(line: 330, column: 20, scope: !1261)
!2401 = !DILocation(line: 330, column: 26, scope: !1261)
!2402 = !DILocation(line: 331, column: 20, scope: !1261)
!2403 = !DILocation(line: 331, column: 26, scope: !1261)
!2404 = !DILocation(line: 332, column: 20, scope: !1261)
!2405 = !DILocation(line: 332, column: 26, scope: !1261)
!2406 = !DILocation(line: 333, column: 20, scope: !1261)
!2407 = !DILocation(line: 333, column: 26, scope: !1261)
!2408 = !DILocation(line: 334, column: 20, scope: !1261)
!2409 = !DILocation(line: 334, column: 26, scope: !1261)
!2410 = !DILocation(line: 337, column: 9, scope: !1261)
!2411 = !DILocation(line: 338, column: 9, scope: !1261)
!2412 = !DILocation(line: 339, column: 9, scope: !1261)
!2413 = !DILocation(line: 340, column: 9, scope: !1261)
!2414 = !DILocation(line: 341, column: 9, scope: !1261)
!2415 = !DILocation(line: 342, column: 9, scope: !1261)
!2416 = !DILocation(line: 343, column: 9, scope: !1261)
!2417 = !DILocation(line: 344, column: 9, scope: !1261)
!2418 = !DILocation(line: 347, column: 9, scope: !1261)
!2419 = !DILocation(line: 348, column: 9, scope: !1261)
!2420 = !DILocation(line: 349, column: 9, scope: !1261)
!2421 = !DILocation(line: 350, column: 9, scope: !1261)
!2422 = !DILocation(line: 351, column: 9, scope: !1261)
!2423 = !DILocation(line: 353, column: 9, scope: !1261)
!2424 = !DILocation(line: 357, column: 3, scope: !1261)
!2425 = distinct !DISubprogram(name: "__remill_intrinsics", scope: !2426, file: !2426, line: 35, type: !95, isLocal: false, isDefinition: true, scopeLine: 35, flags: DIFlagPrototyped, isOptimized: false, unit: !1, variables: !7)
!2426 = !DIFile(filename: "/home/ubuntu/Github/remill/remill/Arch/Runtime/Intrinsics.cpp", directory: "/home/ubuntu/Github/remill/remill-build/remill/Arch/X86/Runtime")
!2427 = !DILocation(line: 116, column: 1, scope: !2425)
!2428 = !{!2429, !2429, i64 0}
!2429 = !{!"long", !2430, i64 0}
!2430 = !{!"omnipotent char", !2431, i64 0}
!2431 = !{!"Simple C++ TBAA"}
!2432 = !{!2433, !2430, i64 2065}
!2433 = !{!"_ZTS5State", !2430, i64 16, !2434, i64 2064, !2430, i64 2080, !2435, i64 2088, !2437, i64 2112, !2439, i64 2208, !2440, i64 2480, !2441, i64 2608, !2442, i64 2736, !2430, i64 2760, !2430, i64 2768, !2443, i64 3280}
!2434 = !{!"_ZTS10ArithFlags", !2430, i64 0, !2430, i64 1, !2430, i64 2, !2430, i64 3, !2430, i64 4, !2430, i64 5, !2430, i64 6, !2430, i64 7, !2430, i64 8, !2430, i64 9, !2430, i64 10, !2430, i64 11, !2430, i64 12, !2430, i64 13, !2430, i64 14, !2430, i64 15}
!2435 = !{!"_ZTS8Segments", !2436, i64 0, !2430, i64 2, !2436, i64 4, !2430, i64 6, !2436, i64 8, !2430, i64 10, !2436, i64 12, !2430, i64 14, !2436, i64 16, !2430, i64 18, !2436, i64 20, !2430, i64 22}
!2436 = !{!"short", !2430, i64 0}
!2437 = !{!"_ZTS12AddressSpace", !2429, i64 0, !2438, i64 8, !2429, i64 16, !2438, i64 24, !2429, i64 32, !2438, i64 40, !2429, i64 48, !2438, i64 56, !2429, i64 64, !2438, i64 72, !2429, i64 80, !2438, i64 88}
!2438 = !{!"_ZTS3Reg", !2430, i64 0}
!2439 = !{!"_ZTS3GPR", !2429, i64 0, !2438, i64 8, !2429, i64 16, !2438, i64 24, !2429, i64 32, !2438, i64 40, !2429, i64 48, !2438, i64 56, !2429, i64 64, !2438, i64 72, !2429, i64 80, !2438, i64 88, !2429, i64 96, !2438, i64 104, !2429, i64 112, !2438, i64 120, !2429, i64 128, !2438, i64 136, !2429, i64 144, !2438, i64 152, !2429, i64 160, !2438, i64 168, !2429, i64 176, !2438, i64 184, !2429, i64 192, !2438, i64 200, !2429, i64 208, !2438, i64 216, !2429, i64 224, !2438, i64 232, !2429, i64 240, !2438, i64 248, !2429, i64 256, !2438, i64 264}
!2440 = !{!"_ZTS8X87Stack", !2430, i64 0}
!2441 = !{!"_ZTS3MMX", !2430, i64 0}
!2442 = !{!"_ZTS14FPUStatusFlags", !2430, i64 0, !2430, i64 1, !2430, i64 2, !2430, i64 3, !2430, i64 4, !2430, i64 5, !2430, i64 6, !2430, i64 7, !2430, i64 8, !2430, i64 9, !2430, i64 10, !2430, i64 11, !2430, i64 12, !2430, i64 13, !2430, i64 14, !2430, i64 15, !2430, i64 16, !2430, i64 17, !2430, i64 18, !2430, i64 19, !2430, i64 20}
!2443 = !{!"_ZTS13SegmentCaches", !2444, i64 0, !2444, i64 16, !2444, i64 32, !2444, i64 48, !2444, i64 64, !2444, i64 80}
!2444 = !{!"_ZTS13SegmentShadow", !2430, i64 0, !2445, i64 8, !2445, i64 12}
!2445 = !{!"int", !2430, i64 0}
!2446 = !{!2433, !2430, i64 2067}
!2447 = !{!2433, !2430, i64 2069}
!2448 = !{!2433, !2430, i64 2071}
!2449 = !{!2433, !2430, i64 2073}
!2450 = !{!2433, !2430, i64 2077}
!2451 = !{!2445, !2445, i64 0}
!2452 = !{!2453, !2453, i64 0}
!2453 = !{!"double", !2430, i64 0}
!2454 = !{!2430, !2430, i64 0}
!2455 = !{!2456, !2456, i64 0}
!2456 = !{!"float", !2430, i64 0}
